
Le choix bayésien
Principes et pratique

Springer
Paris
Berlin
Heidelberg
New York
Hong Kong
London
Milan
Tokyo

Le choix bayésien
Principes et pratique
Christian P. Robert

ISBN-10 : 2-287-25173-1 Springer Paris Berlin Heidelberg New York
ISBN-13 : 978-2-287-25173-3 Springer Paris Berlin Heidelberg New York
© Springer-Verlag France, Paris, 2006
Imprimé en France
Springer-Verlag France est membre du groupe Springer Science + Business Media
Cet ouvrage est soumis au copyright. Tous droits réservés, notamment la reproduction et la représentation la
traduction, la réimpression, l’exposé, la reproduction des illustrations et des tableaux, la transmission par voie
d’enregistrement sonore ou visuel, la reproduction par microfilm ou tout autre moyen ainsi que la conserva-
tion des banques de données. La loi française sur le copyright du 9 septembre 1965 dans la version en vigueur
n’autorise une reproduction intégrale ou partielle que dans certains cas, et en principe moyennant le paiement
de droits. Toute représentation, reproduction, contrefaçon ou conservation dans une banque de données par
quelque procédé que ce soit est sanctionnée par la loi pénale sur le copyright.
L’utilisation dans cet ouvrage de désignations, dénominations commerciales, marques de fabrique, etc. même
sans spécification ne signifie pas que ces termes soient libres de la législation sur les marques de fabrique et la
protection des marques et qu’ils puissent être utilisés par chacun.
La maison d’édition décline toute responsabilité quant à l’exactitude des indications de dosage et des modes
d’emploi. Dans chaque cas, il incombe à l’usager de vérifier les informations données par comparaison à la
littérature existante.
SPIN : 11402 848
Maquette de couverture : Jean-François Montmarché
Dessin de couverture : détail d’un tableau de Michel Marin
Christian P. Robert
CEREMADE, Université Paris Dauphine et
CREST, INSEE, Paris

`A mon a priori de r´ef´erence, Brigitte,
et `a mes deux updates les plus importants,
Joachim et Rachel.

Collection
Statistiques et probabilités appliquées
dirigée par Yadolah Dodge
Professeur Honoraire
Université de Neuchâtel
2002 Neuchâtel
Suisse
Comité éditorial :
Christian Genest
Département de Mathématiques
et de statistique
Université de Laval
Québec GIK 7P4
Canada
Marc Hallin
Université libre de Bruxelles
Campus de la Plaine CP 210
1050 Bruxelles
Belgique
Ludovic Lebart
École Nationale Supérieure
des Télécommunications
46, rue Barrault
75634 Paris Cedex 13
France
Stephan Morgenthaler
École Polytechnique Fédérale
de Lausanne
Département des Mathématiques
1015 Lausanne
Suisse
Gilbert Saporta
Conservatoire national
des arts et métiers
292, rue Saint-Martin
75141 Paris Cedex 3
France
Dans la même collection :
– Statistique. La théorie et ses applications
Michel Lejeune, avril 2004

Pr´eface
“The ﬁrst lesson is what questions to ask.”
Robert Jordan, Knife of Dreams.
Quinze ans plus tard...
La toute premi`ere version de ce livre a ´et´e publi´ee en 1992 chez Eco-
nomica, sous le titre L’Analyse Statistique Bay´esienne, comme premier titre
d’une collection de Statistique dirig´ee par Paul Deheuvels. Le livre a ensuite
´et´e remani´e `a deux reprises pour donner les ´editions de The Bayesian Choice,
publi´ees chez Springer-Verlag (New York) en 1994 et 2001. Les changements
par rapport `a la premi`ere version fran¸caise sont trop nombreux pour ˆetre
d´ecrits ici, d’autant que cette ´edition initiale est ´epuis´ee et n’est donc plus
disponible qu’en biblioth`eque. Si je me suis d´ecid´e `a compl´eter le cercle et
`a entreprendre la retraduction du Bayesian Choice, c’est, d’une part, parce
que la premi`ere ´edition fran¸caise n’est plus disponible alors qu’il est toujours
un peu d´elicat de sugg´erer un livre de r´ef´erence r´edig´e en anglais en troisi`eme
(L3) et en quatri`eme (M1) ann´ees d’un cursus francophone... D’autre part, The
Bayesian Choice ayant ´et´e distingu´e par la Soci´et´e Internationale de Statis-
tique Bay´esienne (ISBA) en 2004 en obtenant le prix De Groot, il me semblait
qu’une version en fran¸cais pouvait pr´esenter un int´erˆet pour les bay´esien(ne)s
francophones. Comme j’avais ´egar´e le ﬁchier TEX de la version fran¸caise de
1992 ( !) et que les modiﬁcations apport´ees dans les versions anglaises me sem-
blaient globalement positives, je me suis fond´e sur la seconde ´edition anglaise.
(J’ai d’ailleurs choisi de garder les citations tir´ees de The Wheel of Time de

VIII
Pr´eface
Robert Jordan, plutˆot que de chercher de nouveau des citations en fran¸cais
ou, pire, de les traduire lit´eralement...)
Programmes de Cours
Sans tr`es grande originalit´e, je sugg`ere que, dans un premier cours d’ana-
lyse bay´esienne (par exemple, en L3 ou en M1), les chapitres de base (Cha-
pitres 1 `a 6) devraient ˆetre trait´es presque enti`erement `a l’exception des Notes
et des Sections 4.5 et 5.4, alors qu’un cours centr´e plutˆot sur la Th´eorie de la
D´ecision peut omettre quelques parties des Chapitres 1 `a 3, et les Chapitres
4 et 6 enti`erement, pour couvrir `a la place les Chapitres 7 `a 9.
Pour un programme d’´etudes plus avanc´e concernant des ´etudiant(e)s d´ej`a
familiaris´e(e)s avec la Statistique bay´esienne (en M1 ou en M2), ma suggestion
est de traiter d’abord l’impropri´et´e abord´ee dans la Section 1.5, les lois a priori
non informatives de la Section 3.5, les mod`eles dynamiques de la Section 4.5 et
des Notes 4.7.3 et 4.7.4. Je passerais aussi du temps sur les tests abord´es dans
le Chapitre 5 (except´e ´eventuellement les Sections 5.3 et 5.4). Puis, apr`es une
pr´esentation approfondie des m´ethodes de simulation `a travers le Chapitre 6,
je passerais au sujet plus controvers´e du choix de mod`ele dans le Chapitre 7,
aux r´esultats r´ecents d’admissibilit´e de la Section 8.2.5 et la Note 8.7.1, et `a
la mod´elisation hi´erarchique et empirique du Chapitre 10.
Une alternative pour un cours de cinqui`eme ann´ee (M2) d’un semestre est
de couvrir ce livre et celui de M´ethodes de Monte Carlo par Chaˆınes de Mar-
kov en simultan´e : on pourrait ainsi traiter les Chapitres 1 `a 3 du pr´esent ou-
vrage, disposant ainsi d’un mat´eriel d’illustration suﬃsant pour l’introduction
des m´ethodes de Monte Carlo et de Monte Carlo par chaˆınes de Markov. On
peut ensuite revenir aux Chapitres 4, 5 et 7 du pr´esent ouvrage, en ´eliminant
bien entendu le Chapitre 6. La disponibilit´e des outils MCMC1 permet ainsi de
traiter des mod`eles beaucoup plus ambitieux et on peut s’appuyer en parall`ele
sur la derni`ere ´edition de Monte Carlo Statistical Methods pour les techniques
les plus r´ecentes dans ce domaine. (Il est en eﬀet tr`es vraisemblable que je
n’entreprendrai pas une (re-)traduction de cet ouvrage en fran¸cais!)
Remerciements
J’ai traduit ci-apr`es la pr´eface de l’´edition de 2001 du Bayesian Choice,
principalement `a cause de sa section de remerciements, que je r´eit`ere ici. (Je
n’ai pas voulu reprendre l’ensemble des trois pr´efaces pour ne pas surcharger
l’introduction et surtout pour ´eviter les r´ep´etitions!) Je dois quand mˆeme
rajouter quelques nouvelles “tˆetes” (et dettes) `a ma liste de cr´editeurs. En
particulier, travailler avec Jean-Michel Marin depuis son arriv´ee `a l’Universit´e
Paris Dauphine m’a beaucoup apport´e et, mˆeme si cette traduction n’a pas
1MCMC signiﬁe Markov chain Monte Carlo ; il s’agit d’une m´ethode de simula-
tion (re)d´ecouverte aux d´ebuts des ann´ees 1990 par la communaut´e bay´esienne.

Pr´eface
IX
int´egr´e nos derniers travaux communs sur le choix de mod`eles et la s´election
coh´erente de lois a priori, cette perspective se retrouve dans The Bayesian
Core, ouvrage que nous avons r´edig´e en commun `a l’intention d’un public
plus pragmatique (`a l’origine, les ´etudiant(e)s du DESS MD de Dauphine),
reprenant les fondements de l’analyse bay´esienne dans un contexte d’´etudes
de cas et d’impl´ementation en langage R. Qui plus est, Jean-Michel est aussi
`a l’origine de la couverture de ce livre puisqu’elle a ´et´e r´ealis´ee par son p`ere,
Michel. Je les remercie vivement tous les deux.
Cette traduction n’aurait tout simplement pas ´et´e entam´ee sans un support
ﬁnancier initial de l’Universit´e Paris Dauphine, obtenu grˆace `a l’insistance de
Maria Esteban, directrice du CEREMADE, que je remercie tr`es chaleureuse-
ment. La premi`ere partie du livre a ´et´e traduite avec brio par Claudia Lagos–
Chopin, qui a su g´erer son trilinguisme avec eﬃcacit´e, et `a qui j’exprime ma
gratitude, ainsi qu’`a son mari Nicolas, pour leur travail. Suite `a l’arriv´ee de
leur ﬁlle Alice et au bouleversement cons´ecutif de leur emploi du temps, ils
n’ont pas pu continuer cette traduction comme ils le d´esiraient et Lo¨ıs Ri-
gouste de T´el´ecom Paris a bien voulu reprendre le ﬂambeau, accomplissant
la traduction des quatre derniers chapitres avec eﬃcacit´e et rapidit´e, tout en
poursuivant sa th`ese en parall`ele. Je suis tr`es reconnaissant `a tous les trois
de leur travail, les modiﬁcations apport´ees par mes soins ´etant simplement
des actualisations de la seconde version anglaise. La relecture de parties du
livre par Lo¨ıs Rigouste, Joachim et Rachel Robert, et Arafat Tayeb ont aussi
permis de d´ebusquer de nombreuses fautes de frappe qui m’avaient ´echapp´e2.
Anne-Fran¸coise Dutaud, secr´etaire du laboratoire de Statistique du CREST,
a ´egalement repris la traduction de la liste de r´ef´erence en Bibtex (tout comme
Manuella Delbois l’avait fait en son temps pour Monte Carlo Statistical Me-
thods) et de l’actualisation des r´ef´erences dans le texte. Qu’elle ait pu s’acqui-
ter de ce travail ingrat en quelques mois sans avoir fait de TEX auparavant
est une mesure de son d´evouement. (Comme toujours, la TEXpertise d’Olivier
Capp´e m’a ´et´e d’une aide pr´ecieuse.)
Des remerciements vont aussi `a Nathalie Huilleret, de Springer-Verlag (Pa-
ris), qui a su g´erer contretemps, gestion des droits et probl`emes de production
avec une grande eﬃcacit´e.
Paris, France
Christian P. Robert
23 novembre 2005
2Il reste encore, avec une forte probabilit´e, des fautes de frappe que les lecteurs
et lectrices sont invit´e(e)s `a me signaler et qui seront aﬃch´ees sur ma page web, `a
la rubrique Books. Merci.

Pr´eface `a la seconde ´edition de The Bayesian
Choice
“You can never know everything,” Lan said quietly, “and part of
what you know is always wrong. Perhaps even the most important
part. A portion of wisdom lies in knowing that. A portion of courage
lies in going on anyway.”
Robert Jordan, Winter’s Heart.
Aperc¸u des Changements
Pourquoi une deuxi`eme ´edition ? Quand on y r´eﬂ´echit bien, il s’agit plutˆot
d’une troisi`eme ´edition, car la version pr´ec´edente, The Bayesian Choice, ´etait
en fait la traduction de la version fran¸caise et incluait d´ej`a des mises `a jour
et des corrections. Les raisons de cette nouvelle ´edition sont multiples. Depuis
1994, la communaut´e bay´esienne a ´enorm´ement ´evolu´e. La version pr´ec´edente
n’a pas seulement n´eglig´e d’importantes parties du domaine, mais elle a omis
des avanc´ees signiﬁcatives survenues lors des sept derni`eres ann´ees.
Ainsi, la r´evolution MCMCa consid´erablement attis´e les progr`es de la
mod´elisation bay´esienne, avec des applications qui vont de la Statistique
m´edicale au traitement du signal et `a la Finance. Ces progr`es n’´etaient pas suf-
ﬁsamment soulign´es dans l’´edition de 1994. Par exemple, les m´ethodes MCMC
n’y ´etaient pr´esent´ees qu’`a partir de l’avant-dernier chapitre.
Une autre avanc´ee signiﬁcative qui m´erite notre attention est le d´eveloppe-
ment de nouvelles approches pour les tests statistiques et, plus g´en´eralement,
des outils de choix de mod`eles en connexion avec, et r´esultant des techniques
MCMC, comme celle de saut r´eversible. D’autres avanc´ees importantes in-
cluent les mod`eles hi´erarchiques et dynamiques dont le d´eveloppement a com-
menc´e au d´ebut des ann´ees 1990.

XII
Pr´eface `a la seconde ´edition
Cette seconde ´edition est malgr´e tout loin d’ˆetre r´evolutionnaire par rap-
port `a celle de 1994. Elle inclut cependant d’importantes avanc´ees qui ont eu
lieu depuis. Le seul chapitre v´eritablement nouveau traite du choix du mod`ele
(Chap. 9), ind´ependamment de la th´eorie g´en´erale des tests (Chap. 5), parce
que le choix de mod`ele se pr´esente eﬀectivement comme un probl`eme diﬀ´erent
et aussi parce qu’il exige des outils nouveaux, principalement informatiques.
Pour cette raison, mais aussi pour souligner l’importance des techniques infor-
matiques, le Chapitre 6, Chapitre 9 pr´ec´edemment, a ´et´e plac´e plus haut dans
le livre, apr`es la pr´esentation des fondements de la Statistique bay´esienne. Le
Chapitre 6 pourrait en fait ˆetre consid´er´e comme un nouveau chapitre dans le
sens o`u sa pr´esentation a ´et´e profond´ement renouvel´ee `a la lumi`ere de dix ans
de pratique des MCMC. Dans le Chapitre 3, la pr´esentation des proc´edures
non informatives a ´et´e ´elargie et inclut en particulier les a priori d’ad´equation,
puisque l’activit´e de recherche dans ce domaine a ´et´e assez intense ces derni`eres
ann´ees. Le Chapitre 4 fait toujours r´ef´erence aux probl`emes g´en´eraux d’esti-
mation mais j’ai ajout´e une nouvelle section sur les mod`eles dynamiques, car
ceux-ci font partie int´egrante du d´eveloppement de la Statistique bay´esienne
dans des domaines appliqu´es tels que le traitement du signal, la Finance et
l’´Econom´etrie.
Malgr´e une critique assez n´egative du Chapitre 11 par Mohan Delampady
dans The Mathematical Reviews, j’ai d´ecid´e de maintenir ce chapitre de conclu-
sion, car je consid`ere qu’il oﬀre un aper¸cu d’ensemble plus philosophique sur
le sujet, le lecteur ayant tr`es vraisemblablement d´ej`a acquis une perspective
suﬃsante pour comprendre de tels arguments. (En terme de programme de
cours, ce chapitre peut ˆetre sugg´er´e comme une lecture compl´ementaire, `a
l’instar des notes de ﬁn de chapitre.)
Un autre changement notable, par comparaison avec l’´edition pr´ec´edente,
est l’emphase moindre sur les principes de la Th´eorie de la D´ecision. ´Etant
arriv´e `a la Statistique bay´esienne par un chemin d´ecisionnel, je crois toujours
que les proc´edures statistiques doivent ˆetre fond´ees sur de tels principes. Ce-
pendant les d´eveloppements des dix derni`eres ann´ees se sont principalement
concentr´es sur la m´ethodologie, y compris computationnelle, plus que sur la
r´esolution plus large et plus ambitieuse des probl`emes de d´ecision (une fois de
plus, m´ethodologie informatique comprise). Une partie du livre (qui comprend
les Chapitres 6 et 7) est donc moins orient´ee vers la Th´eorie de la D´ecision,
et, pour les Chapitres 8 `a 10, a `a peine chang´e.
En ce qui concerne la mise en page, des sous-sections et des s´eparations
ont ´et´e introduites dans plusieurs sections aﬁn d’am´eliorer la visibilit´e et la
lecture. Un plus grand nombre de parties avanc´ees ou incompl`etes ont ´et´e
d´eplac´ees en notes de ﬁn de chapitre, suivant l’approche adopt´ee dans Monte
Carlo Statistical Methods, ´ecrit avec George Casella. La ﬁn d’un exemple est
associ´ee au symbole ∥, tandis que la ﬁn d’une d´emonstration est indiqu´ee par
le symbole □.
Plusieurs livres sur la Statistique bay´esienne sont apparus entre-temps,
parmi lesquels Bernardo et Smith (1994), Carlin et Louis (2001), Gelman

Pr´eface `a la seconde ´edition
XIII
et al. (2003), O’Hagan (1994), O’Hagan et Forster (2002) et Schervish (1995).
Cependant chacun de ces livres a soit mis l’accent sur l’approfondissement des
aspects th´eoriques `a un niveau math´ematique tr`es ´elev´e (Bernardo et Smith,
1994, O’Hagan, 1994, O’Hagan et Forster, 2002, Schervish, 1995) et a ainsi
vis´e une audience plus mˆure que celle de ce livre, soit fait ressortir une vision
diﬀ´erente de la pratique de la Statistique bay´esienne (Carlin et Louis, 2001,
Gelman et al., 2003), en perdant par exemple le lien avec la Th´eorie de la
D´ecision d´evelopp´ee dans ce livre.
Remerciements
J’ai toujours ´eprouv´e des sentiments mˆel´es sur le fait d’ajouter une section
de remerciements dans un livre. En fait, cette section ne dira pas grand-chose
`a l’immense majorit´e des lecteurs, sauf `a r´ev´eler certaines idiosyncrasies de
l’auteur qui feraient sans doute mieux de rester cach´ees! Elle pourrait aussi
contrarier certaines personnes concern´ees parce qu’elles ne sont pas cit´ees, ou
parce qu’elles ne sont pas cit´ees selon leurs attentes, ou mˆeme parce qu’elles
le sont ! En revanche, une exigence ´ethique de base de tout travail intellectuel
est de reconnaˆıtre ses sources. Cela s’´etend `a mon avis aux suggestions qui ont
contribu´e `a am´eliorer ce travail, `a le rendre plus clair ou simplement diﬀ´erent.
Il s’agit d’un petit t´emoignage de gratitude envers les personnes suivantes,
pour le temps qu’ils et elles ont consacr´e aux versions successives de cette
´edition, pour que leurs eﬀorts soient vus et connus de tous !
Bien que cette ´edition soit “juste” une r´evision, le temps pass´e sur cet
ouvrage a ´et´e, en grande partie, vol´e aux soirs, aux matins (tr`es tˆot) et aux
week-ends revenant normalement `a Brigitte, Joachim et Rachel ! Je leur suis
ainsi tr`es reconnaissant pour avoir lu et jou´e (presque) sans faire de bruit
pendant que je tapais furieusement sur mon clavier et cherchais d´esesp´er´ement
dans des piles de papiers telle ou telle r´ef´erence. Et aussi pour ´ecouter Bartoli
et Gudj´onsson, plutˆot que Manau ou Diana Krall! Je ne peux pas promettre
que cette exp´erience ne se r´ep´etera jamais, mais en attendant je m’engage `a
trouver plus de temps disponible pour lire les aventures de Mister Bear to the
Rescue, assi´eger le chˆateau Playmobil au complet, jouer aux ´echecs ou faire
du v´elo les dimanches apr`es-midi!
Je suis reconnaissant `a de nombreuses personnes pour les am´eliorations
de cette ´edition. Pour commencer, j’ai eu un ﬂot constant de retours et de
suggestions de la part de ceux qui enseignent `a partir de ce livre. Ce groupe
inclut Ed Green, Tatsuya Kubokawa, et Marty Wells. En particulier, Judith
Rousseau, cycliste radicale et Jordanienne autant que bay´esienne, a contribu´e
`a la r´eorganisation du Chapitre 3. J’ai eu aussi beaucoup de commentaires
utiles de plusieurs personnes, en particulier des deux “Cambridge Frenchies”
Christophe Andrieu et Arnaud Doucet (sans compter un m´emorable accueil
pendant une semaine de retraite `a Cambridge pour ﬁnir le Chapitre 6), ainsi
que de Jim Berger (pour son soutien en g´en´eral et pour m’avoir fourni des
preprints sur le choix de mod`ele en particulier), d’Olivier Capp´e (qui a aussi

XIV
Pr´eface `a la seconde ´edition
install´e Linux sur mon portable et par cons´equent m’a apport´e une immense
libert´e pour travailler sur le livre n’importe o`u, du bac `a sable au m´etro et
plus tard au CREST, d’o`u Unix est d´esormais banni !), de Maria De Iorio,
de Jean-Louis Fouley, de Malay Ghosh (pour sa critique du livre tr`es po-
sitive dans JASA), de Jim Hobert (qui m’a aid´e `a clariﬁer les Chapitres 6
et 10), d’Ana Justel, de Stephen Lauritzen (pour avoir signal´e des erreurs
sur les distributions de Wishart), d’Anne Philippe, de Walter Racugno (qui
m’a donn´e l’opportunit´e de faire un cours concernant le choix des mod`eles
`a Cagliari l’automne dernier, cours qui constitue l’essentiel du Chapitre 7),
d’Adrian Raftery, d’Anne Sullivan Rosen (pour le style de cette pr´eface) et
Jean-Michel Zakoian (pour ses conseils sur les nouvelles parties concernant
les mod`eles dynamiques). Je proﬁte aussi de cette occasion pour remercier
d’autres ami(e)s et coll`egues comme George Casella, J´erˆome Dupuis, Merrilee
Hurn, Kerrie Mengersen, Eric Moulines, Alain Monfort, et Mike Titterington.
Depuis que je travaille avec eux et avec elles, ils et elles m’ont donn´e une
vision plus large du domaine, qui est, esp´erons-le, incluse dans cette version.
En particulier, l’exp´erience de l’´ecriture de Monte Carlo Statistical Methods
avec George Casella ces derni`eres ann´ees a laiss´e ses marques dans ce livre
non seulement `a travers le ﬁchier de style et l’inclusion de notes en ﬁn de
chapitre, mais aussi pour un sens plus aigu de l’essentiel. Manuela Delbois
m’a aid´e tr`es aimablement `a transformer le texte de TEX `a LATEX, puis `a in-
clure les additions ult´erieures et l’index. Et, last but not least !, John Kimmel
et Jenny Wolkowicki de Springer-Verlag ont ´et´e tr`es eﬃcaces, en m’encoura-
geant `a ´ecrire cette nouvelle ´edition pour le premier, en gardant le contrˆole
du calendrier et en faisant publier le livre `a temps pour la seconde. Inutile de
dire que l’avertissement d’usage s’applique : toute coquille, erreur, confusion,
formulation obscure restante est de ma responsabilit´e et rien que de la mienne !
In Memoriam
Une pens´ee tr`es ´emue pour deux personnes dont l’absence a marqu´e cette
nouvelle ´edition. Durant l’´et´e 1997, j’ai perdu mon ami Costas Goutis lors d’un
accident de plong´ee `a Seattle. Je ne suis pas, et de loin, le seul `a regretter
profond´ement son d´epart, mais sans aucun doute ce livre aurait b´en´eﬁci´e de
sa vision des choses s’il avait ´et´e l`a... Deux ´et´es plus tard, en 1999, Bernhard
K. Flury est mort dans un accident de montagne dans les Dolomites. Bien
que la critique de nos livres respectifs se soit toujours limit´ee aux couleurs
de couverture, au point de s’envoyer l’un `a l’autre une version pirat´ee de nos
livres avec les “bonnes” couleurs, le monde est moins drˆole sans son sens de
l’humour `a nul autre pareil...
Paris, France
Christian P. Robert
Mars 2001

Table des mati`eres
Pr´eface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . VII
Pr´eface `a la seconde ´edition anglaise . . . . . . . . . . . . . . . . . . . . . . . . . . . XI
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Probl`emes statistiques et mod`eles statistiques . . . . . . . . . . . . . . .
1
1.2
Le paradigme bay´esien et le principe de dualit´e. . . . . . . . . . . . . .
9
1.3
Principes de vraisemblance et d’exhaustivit´e . . . . . . . . . . . . . . . . 15
1.3.1
Exhaustivit´e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
1.3.2
Principe de vraisemblance . . . . . . . . . . . . . . . . . . . . . . . . . . 17
1.3.3
D´erivation du principe de vraisemblance. . . . . . . . . . . . . . 20
1.3.4
Mise en œuvre du principe de vraisemblance . . . . . . . . . . 21
1.3.5
Estimation par maximum de vraisemblance . . . . . . . . . . . 23
1.4
Distributions a priori et a posteriori . . . . . . . . . . . . . . . . . . . . . . . 24
1.5
Distributions a priori impropres . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
1.6
Le choix bay´esien . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
1.7
Exercices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
1.8
Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
2
Les bases de la Th´eorie de la D´ecision . . . . . . . . . . . . . . . . . . . . . 55
2.1
´Evaluation des estimateurs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
2.2
La fonction d’utilit´e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
2.3
Utilit´e et coˆut . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
2.4
Deux optimalit´es : minimaxit´e et admissibilit´e . . . . . . . . . . . . . . 71
2.4.1
Estimateurs randomis´es . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
2.4.2
Minimaxit´e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
2.4.3
Existence d’une r`egle minimax et d’une strat´egie
maximin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
2.4.4
Admissibilit´e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
2.5
Fonctions de coˆut usuelles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
2.5.1
Le coˆut quadratique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85

XVI
Table des mati`eres
2.5.2
L’erreur de coˆut absolu. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
2.5.3
Le coˆut 0 −1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
2.5.4
Coˆuts intrins`eques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
2.6
Critiques et alternatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
2.7
Exercices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94
2.8
Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
3
Des informations a priori aux lois a priori . . . . . . . . . . . . . . . . . 113
3.1
La diﬃcult´e du choix d’une loi a priori . . . . . . . . . . . . . . . . . . . . . 113
3.2
D´etermination subjective et approximations . . . . . . . . . . . . . . . . 115
3.2.1
Existence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
3.2.2
Approximations de la loi a priori . . . . . . . . . . . . . . . . . . . . 117
3.2.3
Lois a priori d’entropie maximale . . . . . . . . . . . . . . . . . . . . 118
3.2.4
Approximations param´etriques . . . . . . . . . . . . . . . . . . . . . . 119
3.2.5
Autres techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
3.3
Lois a priori conjugu´ees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
3.3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
3.3.2
Justiﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
3.3.3
Familles exponentielles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
3.3.4
Lois conjugu´ees des familles exponentielles . . . . . . . . . . . . 130
3.4
Critiques et extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
3.5
Lois a priori non informatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
3.5.1
Les lois a priori de Laplace . . . . . . . . . . . . . . . . . . . . . . . . . 137
3.5.2
Lois invariantes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
3.5.3
La loi a priori de Jeﬀreys . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
3.5.4
Lois de r´ef´erence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
3.5.5
Lois a priori co¨ıncidantes . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
3.5.6
D’autres approches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
3.6
Validation a posteriori et robustesse . . . . . . . . . . . . . . . . . . . . . . . 152
3.7
Exercices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156
3.8
Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
4
Estimation bay´esienne ponctuelle . . . . . . . . . . . . . . . . . . . . . . . . . . 175
4.1
Inf´erence bay´esienne . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
4.1.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
4.1.2
Estimateur MAP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176
4.1.3
Principe de vraisemblance . . . . . . . . . . . . . . . . . . . . . . . . . . 177
4.1.4
Espace des param`etres restreint . . . . . . . . . . . . . . . . . . . . . 179
4.1.5
Pr´ecision des estimateurs de Bayes . . . . . . . . . . . . . . . . . . 181
4.1.6
Pr´evision . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
4.1.7
Retour `a la d´ecision . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
4.2
Th´eorie bay´esienne de la d´ecision . . . . . . . . . . . . . . . . . . . . . . . . . . 184
4.2.1
Estimateurs de Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
4.2.2
Les lois a priori conjugu´ees . . . . . . . . . . . . . . . . . . . . . . . . . 187
4.2.3
Estimation du coˆut . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190

Table des mati`eres
XVII
4.3
Mod`eles d’´echantillonnage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
4.3.1
R`egle de succession de Laplace . . . . . . . . . . . . . . . . . . . . . . 192
4.3.2
Le probl`eme du tramway . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
4.3.3
Mod`eles de capture-recapture . . . . . . . . . . . . . . . . . . . . . . . 194
4.4
Le cas particulier du mod`ele normal . . . . . . . . . . . . . . . . . . . . . . . 198
4.4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
4.4.2
Estimation de la variance. . . . . . . . . . . . . . . . . . . . . . . . . . . 199
4.4.3
Mod`eles lin´eaires et G-priors . . . . . . . . . . . . . . . . . . . . . . . . 203
4.5
Mod`eles dynamiques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
4.5.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
4.5.2
Le mod`ele AR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
4.5.3
Le mod`ele MA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
4.5.4
Le mod`ele ARMA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
4.6
Exercices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
4.7
Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
5
Tests et r´egions de conﬁance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
5.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
5.2
Une premi`ere approche de la th´eorie des tests . . . . . . . . . . . . . . . 238
5.2.1
Tests d´ecisionnels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
5.2.2
Le facteur de Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
5.2.3
Modiﬁcation de la loi a priori . . . . . . . . . . . . . . . . . . . . . . . 244
5.2.4
Hypoth`eses nulles ponctuelles . . . . . . . . . . . . . . . . . . . . . . . 245
5.2.5
Lois a priori impropres . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
5.2.6
Pseudo-facteurs de Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . 251
5.3
Comparaisons avec l’approche classique . . . . . . . . . . . . . . . . . . . . 258
5.3.1
Tests UPP et UPPS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
5.3.2
Lois a priori les moins favorables . . . . . . . . . . . . . . . . . . . . 262
5.3.3
Critiques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
5.3.4
Les p-values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
5.3.5
R´eponses bay´esiennes moins favorables . . . . . . . . . . . . . . . 268
5.3.6
Le cas unilat´eral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
5.4
Une deuxi`eme approche d´ecisionnelle. . . . . . . . . . . . . . . . . . . . . . . 273
5.5
R´egions de conﬁance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
5.5.1
Intervalles de cr´edibilit´e . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
5.5.2
Intervalles de conﬁance classiques. . . . . . . . . . . . . . . . . . . . 280
5.5.3
´Evaluation d´ecisionnelle des ensembles de conﬁance . . . . 283
5.6
Exercices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
5.7
Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
6
M´ethodes de calcul bay´esien . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
6.1
Diﬃcult´es de mise en œuvre . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
6.2
M´ethodes classiques d’approximation . . . . . . . . . . . . . . . . . . . . . . 313
6.2.1
Int´egration num´erique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314
6.2.2
Les m´ethodes de Monte Carlo . . . . . . . . . . . . . . . . . . . . . . . 314

XVIII
Table des mati`eres
6.2.3
L’approximation analytique de Laplace . . . . . . . . . . . . . . . 319
6.3
M´ethodes de Monte Carlo par chaˆınes de Markov . . . . . . . . . . . . 322
6.3.1
Les MCMC en pratique . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
6.3.2
Algorithmes de Metropolis-Hastings . . . . . . . . . . . . . . . . . 325
6.3.3
L’´echantillonnage de Gibbs . . . . . . . . . . . . . . . . . . . . . . . . . 329
6.3.4
Rao-Blackwellisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332
6.3.5
L’´echantillonnage de Gibbs g´en´eral . . . . . . . . . . . . . . . . . . 334
6.3.6
L’´echantillonnage par tranche . . . . . . . . . . . . . . . . . . . . . . . 339
6.3.7
Impact sur la statistique bay´esienne . . . . . . . . . . . . . . . . . 341
6.4
Estimation bay´esienne de m´elanges . . . . . . . . . . . . . . . . . . . . . . . . 342
6.5
Exercices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
6.6
Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360
7
Choix et comparaison de mod`eles . . . . . . . . . . . . . . . . . . . . . . . . . . 369
7.1
Motivations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369
7.1.1
Choix entre plusieurs mod`eles . . . . . . . . . . . . . . . . . . . . . . . 371
7.1.2
Champs d’application . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374
7.2
Comparaison bay´esienne de mod`eles . . . . . . . . . . . . . . . . . . . . . . . 375
7.2.1
Mod´elisation sp´eciﬁque de l’a priori . . . . . . . . . . . . . . . . . . 375
7.2.2
Facteurs de Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378
7.2.3
Le crit`ere de Schwarz . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 380
7.2.4
D´eviance bay´esienne . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382
7.3
Aspects num´eriques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384
7.3.1
´Echantillonnage d’importance pour facteurs de Bayes . . 385
7.3.2
´Echantillonnage par passerelle. . . . . . . . . . . . . . . . . . . . . . . 387
7.3.3
M´ethodes MCMC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 388
7.3.4
MCMC `a sauts r´eversibles . . . . . . . . . . . . . . . . . . . . . . . . . . 393
7.4
Moyenne de mod`eles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395
7.5
Projections de mod`eles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399
7.6
Ad´equation `a une famille de lois . . . . . . . . . . . . . . . . . . . . . . . . . . . 405
7.7
Exercices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 408
7.8
Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 418
8
Admissibilit´e et classes compl`etes . . . . . . . . . . . . . . . . . . . . . . . . . . 423
8.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 423
8.2
Admissibilit´e des estimateurs de Bayes . . . . . . . . . . . . . . . . . . . . . 424
8.2.1
Caract´erisations g´en´erales . . . . . . . . . . . . . . . . . . . . . . . . . . 424
8.2.2
Conditions aux limites . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 426
8.2.3
Estimateurs de Bayes g´en´eralis´es inadmissibles . . . . . . . . 428
8.2.4
Repr´esentations diﬀ´erentielles . . . . . . . . . . . . . . . . . . . . . . . 429
8.2.5
Conditions de r´ecurrence . . . . . . . . . . . . . . . . . . . . . . . . . . . 431
8.3
Conditions n´ecessaires et suﬃsantes d’admissibilit´e . . . . . . . . . . 433
8.3.1
Risques continus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 434
8.3.2
Condition suﬃsante de Blyth . . . . . . . . . . . . . . . . . . . . . . . 436
8.3.3
Condition n´ecessaire et suﬃsante de Stein . . . . . . . . . . . . 441

Table des mati`eres
XIX
8.3.4
Un autre th´eor`eme limite . . . . . . . . . . . . . . . . . . . . . . . . . . . 441
8.4
Classes compl`etes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 443
8.5
Conditions n´ecessaires d’admissibilit´e . . . . . . . . . . . . . . . . . . . . . . 446
8.6
Exercices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 450
8.7
Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 460
9
Invariance, mesures de Haar et estimateurs ´equivariants . . . 463
9.1
Principes d’invariance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 463
9.2
Le cas particulier des param`etres de position . . . . . . . . . . . . . . . . 465
9.3
Probl`emes de d´ecision invariants. . . . . . . . . . . . . . . . . . . . . . . . . . . 468
9.4
Distributions non informatives ´equivariantes . . . . . . . . . . . . . . . . 473
9.5
Le th´eor`eme de Hunt-Stein . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 479
9.6
L’invariance en Statistique bay´esienne . . . . . . . . . . . . . . . . . . . . . . 483
9.7
Exercices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 484
9.8
Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 492
10
Extensions hi´erarchique et empirique . . . . . . . . . . . . . . . . . . . . . . 495
10.1 Lois a priori incompl`etes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 495
10.2 Analyse bay´esienne hi´erarchique . . . . . . . . . . . . . . . . . . . . . . . . . . . 498
10.2.1 Mod`eles hi´erarchiques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 498
10.2.2 Justiﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 501
10.2.3 D´ecompositions conditionnelles . . . . . . . . . . . . . . . . . . . . . . 504
10.2.4 Probl`emes num´eriques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 507
10.2.5 Extensions hi´erarchiques du mod`ele normal . . . . . . . . . . . 509
10.3 Optimalit´e des estimateurs bay´esiens hi´erarchiques . . . . . . . . . . 514
10.4 L’alternative bay´esienne empirique. . . . . . . . . . . . . . . . . . . . . . . . . 518
10.4.1 Le principe bay´esien empirique non param´etrique. . . . . . 519
10.4.2 Principe bay´esien empirique param´etrique . . . . . . . . . . . . 521
10.5 Justiﬁcations bay´esiennes empiriques de l’eﬀet Stein . . . . . . . . . 525
10.5.1 Estimation ponctuelle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 525
10.5.2 ´Evaluation de la variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 528
10.5.3 R´egions de conﬁance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 529
10.5.4 Commentaires . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 531
10.6 Exercices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 532
10.7 Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 544
11
Une d´efense du choix bay´esien . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 549
A
Distributions de probabilit´e. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 563
B
Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 567
R´ef´erences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 571
Index des noms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 611

XX
Table des mati`eres
Index des mati`eres. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 621

Liste des tableaux
2.1
Fonction d’utilit´e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
3.1
Information a priori de capture et de survie . . . . . . . . . . . . . . . . . . 115
3.2
Loi a priori de capture et de survie . . . . . . . . . . . . . . . . . . . . . . . . . 116
3.3
´Etendue des valeurs des moments a posteriori . . . . . . . . . . . . . . . . 121
3.4
Lois a priori conjugu´ees naturelles . . . . . . . . . . . . . . . . . . . . . . . . . . 131
3.5
Lois a priori de r´ef´erence co¨ıncidantes . . . . . . . . . . . . . . . . . . . . . . . 151
3.6
Approximation par m´elange de lois conjugu´ees . . . . . . . . . . . . . . . 172
4.1
Estimateurs de Bayes pour familles exponentielles . . . . . . . . . . . . 187
4.2
Probabilit´es de capture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
4.3
Partition de la population de capture . . . . . . . . . . . . . . . . . . . . . . . 195
4.4
Loi a posteriori de la population de cerfs . . . . . . . . . . . . . . . . . . . . 197
4.5
Esp´erance a posteriori de la population de cerfs . . . . . . . . . . . . . . 197
4.6
Population de cerfs estim´ee . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
5.1
Probabilit´es a posteriori de p = 1/2 . . . . . . . . . . . . . . . . . . . . . . . . . 247
5.2
Probabilit´es a posteriori de θ = 0 . . . . . . . . . . . . . . . . . . . . . . . . . . . 247
5.3
Probabilit´es a posteriori de θ = 0 . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
5.4
Probabilit´es a posteriori de |θ| < 1 . . . . . . . . . . . . . . . . . . . . . . . . . . 249
5.5
Probabilit´es a posteriori de θ = 0 . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
5.6
Probabilit´es a posteriori de θ = 0 . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
5.7
Comparaison entre p-values et r´eponses bay´esiennes. . . . . . . . . . . 269
5.8
Comparaison entre p-values et r´eponses bay´esiennes. . . . . . . . . . . 270
5.9
Facteurs de Bayes et probabilit´es a posteriori . . . . . . . . . . . . . . . . 271
5.10 Comparaison entre p-values et probabilit´es a posteriori . . . . . . . . 272
5.11 Intervalles α-cr´edibles pour la loi B(n, p) . . . . . . . . . . . . . . . . . . . . 279
6.1
Param`etres de radiographies des poumons . . . . . . . . . . . . . . . . . . . 311
6.2
Fr´equences de passages de voitures . . . . . . . . . . . . . . . . . . . . . . . . . 359

XXII
Liste des tableaux
7.1
Circonf´erences d’orangers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373
7.2
Ad´equation des mod`eles d’orangers . . . . . . . . . . . . . . . . . . . . . . . . . 390
7.3
Param`etres pour divergences de Kullback-Leibler . . . . . . . . . . . . . 402
7.4
Sous-mod`eles pour le cancer du sein . . . . . . . . . . . . . . . . . . . . . . . . 404
7.5
Nombre de femmes dans une ﬁle d’attente . . . . . . . . . . . . . . . . . . . 416
10.1
Probabilit´es a posteriori et intervalles de conﬁance . . . . . . . . . . 509
10.2
Intentions d’achat de voiture par foyer . . . . . . . . . . . . . . . . . . . . . 537
10.3
Achats de voitures et intentions . . . . . . . . . . . . . . . . . . . . . . . . . . . 537

Table des ﬁgures
1.1
Taux de chˆomage mensuel et accidents . . . . . . . . . . . . . . . . . . . . . .
5
1.2
Histogramme d’une poitrine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.1
Utilit´e moyenne . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
2.2
Comparaison des risques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
2.3
Ensemble de risques de Bernoulli . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
3.1
Deux estimateurs de la moyenne . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
3.2
Densit´es I N (α, μ, τ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
3.3
Trois lois a priori de pile ou face. . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
3.4
Lois a posteriori de pile ou face . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
3.5
Lois a posteriori pour cinquante observations . . . . . . . . . . . . . . . . 135
4.1
´Evaluations de l’erreur bay´esienne et fr´equentiste . . . . . . . . . . . . . 183
4.2
Cours de l’action IBM moyenn´ee . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
4.3
Deux lois a priori sur ϱ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
4.4
´Echantillon du mod`ele de volatilit´e stochastique . . . . . . . . . . . . . . 234
4.5
Allocations pour le mod`ele de volatilit´e stochastique . . . . . . . . . . 235
5.1
Loi a priori intrins`eque pour test exponentiel . . . . . . . . . . . . . . . . 255
6.1
Variation des approximations de Monte Carlo . . . . . . . . . . . . . . . . 318
6.2
Chaˆıne de Markov pour mod`ele normal r´epulsif . . . . . . . . . . . . . . 328
6.3
Histogrammes de la loi bˆeta-binomiale . . . . . . . . . . . . . . . . . . . . . . 332
7.1
Histogramme des donn´ees galactiques . . . . . . . . . . . . . . . . . . . . . . . 372
7.2
Simulations du nombre de composantes . . . . . . . . . . . . . . . . . . . . . 396
8.1
Ensemble de risque et estimateurs admissibles. . . . . . . . . . . . . . . . 444
10.1
DAG pour le mod`ele HIV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 498
10.2
Convergences pour l’exp´erience des rats . . . . . . . . . . . . . . . . . . . . 508

XXIV
Table des ﬁgures
10.3
´Echantillons de Gibbs pour l’exp´erience des rats . . . . . . . . . . . . 509

1
Introduction
“Sometimes the Pattern has a randomness to it—to our eyes, at
least—but what chance that you should meet a man who could guide
you in this thing, and he one who could follow the guiding ?”
Robert Jordan, The Eye of the World.
1.1 Probl`emes statistiques et mod`eles statistiques
L’objet principal de la Statistique est de mener, grˆace `a l’observation d’un
ph´enom`ene al´eatoire, une inf´erence sur la distribution probabiliste `a l’origine
de ce ph´enom`ene, c’est-`a-dire de fournir une analyse (ou une description) d’un
ph´enom`ene pass´e, ou une pr´ediction d’un ph´enom`ene `a venir de nature simi-
laire3. Dans ce livre nous insistons sur les aspects d´ecisionnels de l’inf´erence
statistique parce que, tout d’abord, ces analyses et pr´edictions sont la plupart
du temps motiv´ees par un but objectif (une entreprise devrait-elle lancer un
nouveau produit ? un bateau de course modiﬁer sa trajectoire? un nouveau
m´edicament ˆetre mis sur le march´e ou `a la vente ? un individu vendre ses
actions ? etc.) ayant des cons´equences mesurables (r´esultats ﬁnanciers, clas-
sement `a la ﬁn de la course, taux de gu´erison des patients, b´en´eﬁces, etc).
Ensuite, parce que proposer des proc´edures inf´erentielles implique qu’on doit
3Comme la plupart des d´eﬁnitions formelles, cette vision de la Statistique laisse
de cˆot´e quelques aspects suppl´ementaires de la Statistique appliqu´ee tels que la
collecte de donn´ees (sondages, plans d’exp´erience, etc). C’est le cas aussi de cet
ouvrage, mˆeme si nous ne voulons pas m´esestimer l’importance de ces sujets, non
couverts ici.

2
1 Introduction
ˆetre prˆet `a les d´efendre, c’est-`a-dire `a justiﬁer le fait qu’elles soient pr´ef´erables
`a d’autres. Il est donc n´ecessaire d’avoir un outil d’´evaluation adapt´e `a la com-
paraison de diverses proc´edures. Cette tˆache est la raison d’ˆetre de la Th´eorie
de la D´ecision.
Nous insistons ´egalement sur le fait que la Statistique doit ˆetre consid´er´ee
comme l’interpr´etation d’un ph´enom`ene naturel, plutˆot que son explication.
En eﬀet, l’inf´erence statistique s’accompagne d’une mod´elisation probabiliste
du ph´enom`ene observ´e et implique n´ecessairement une ´etape de formalisation
r´eductrice. Sans cette base probabiliste, aucune conclusion utile ne pourra ˆetre
tir´ee.
Exemple 1.1. Les feux de forˆet apparaissent g´en´eralement au hasard. Ce-
pendant, certains facteurs ´ecologiques et atmosph´eriques favorisent leur d´e-
clenchement. Une d´etermination de la probabilit´e p d’apparition d’un feu
comme fonction de ces divers facteurs devrait aider `a la pr´evention des feux de
forˆet, mˆeme si une telle mod´elisation est ´evidemment incapable de conduire
`a l’´eradication de ces feux et ne peut prendre en compte tous les facteurs im-
pliqu´es. Une approche plus r´eductrice est d’imposer une forme param´etrique
`a la fonction p, prenant en compte des contraintes physiques sur les facteurs
explicatifs. Par exemple, notant h le taux d’humidit´e, t la temp´erature, x le
degr´e de gestion de la forˆet, un mod`ele logistique peut ˆetre propos´e, de la
forme
p = exp(α1h + α2t + α3x)/ [1 + exp(α1h + α2t + α3x)] ,
la phase statistique se chargeant de l’´evaluation des param`etres α1, α2, α3. ∥
Apposer un mod`ele probabiliste sur un ph´enom`ene inexpliqu´e peut paraˆıtre
dans certains cas trop r´educteur, car il est possible que le ph´enom`ene observ´e
soit enti`erement d´eterministe, sans que la fonction r´egulatrice du processus
soit connue ni qu’il soit possible de la reconstruire `a partir des observations.
C’est le cas par exemple des ph´enom`enes chaotiques o`u, d’un point de vue sta-
tistique, une suite d’observations ne peut pas ˆetre distingu´ee d’une suite de
variables al´eatoires (voir Berg´e et al., 1984 et Gleick, 1987). Les g´en´erateurs
pseudo-al´eatoires sont en fait fond´es sur cette propri´et´e. Bien qu’ils reposent
sur des algorithmes it´eratifs d´eterministes de la forme
at+1 = f(at),
ils imitent–simulent–de fa¸con satisfaisante le comportement d’une suite de
variables al´eatoires (voir Devroye, 1985, Gentle, 1998, Robert et Casella, 2004
pour une description des g´en´erateurs les plus courants).
Cependant, mˆeme si elle est valable d’un point de vue philosophique, cette
critique de la mod´elisation probabiliste ne tient pas si nous consid´erons celle-
ci sous l’angle de l’interpr´etation, ´evoqu´ee ci-dessus. Ces mod`eles permettent
d’incorporer simultan´ement les informations disponibles sur le ph´enom`ene
(facteurs d´eterminants, fr´equence, amplitude, etc.) et les incertitudes inh´e-
rentes `a ces informations. Ils autorisent donc un discours qualitatif sur le

1.1 Probl`emes statistiques et mod`eles statistiques
3
probl`eme en fournissant, `a travers la th´eorie des probabilit´es, un v´eritable
calcul de l’incertain qui permet de d´epasser le stade descriptif des mod`eles
d´eterministes. C’est d’ailleurs la raison pour laquelle une interpr´etation pro-
babiliste est n´ecessaire pour conduire une inf´erence statistique : elle donne un
cadre qui permet de replacer le ph´enom`ene singulier observ´e dans la globa-
lit´e d’un mod`ele et autorise ainsi les analyses et les g´en´eralisations. Loin de
repr´esenter un d´etournement des objectifs inf´erentiels, imposer une structure
probabiliste qui n’est qu’une simple approximation de la r´ealit´e est essentiel
pour que le traitement statistique qui en d´ecoule permette une compr´ehension
plus profonde et plus proche du ph´enom`ene consid´er´e.
´Evidemment la mod´elisation probabiliste ne peut ˆetre d´efendue que si elle
fournit une repr´esentation suﬃsamment proche du ph´enom`ene observ´e. Une
critique plus prosa¨ıque de la mod´elisation probabiliste est qu’il est diﬃcile de
connaˆıtre exactement la distribution probabiliste sous-jacente de la g´en´eration
des observations, c’est-`a-dire savoir s’il s’agit de la loi normale, exponentielle,
binomiale, etc., sauf dans des cas exceptionnels.
Exemple 1.2. On observe une substance radioactive de demi-vie H incon-
nue. Pour une particule donn´ee de cette substance, le temps pass´e avant
d´esint´egration suit exactement une loi exponentielle4 de param`etre log(2)/H.
L’observation de plusieurs de ces particules permettra ainsi de mener une
inf´erence sur H.
∥
Exemple 1.3.
Pour d´eterminer le nombre N de bus dans une ville, on
peut suivre la strat´egie inf´erentielle suivante : observer les bus pendant toute
une journ´ee et noter leurs num´eros. Ensuite on r´ep`ete la mˆeme exp´erience
le lendemain en relevant les num´eros des bus d´ej`a r´epertori´es la veille, n.
Si vingt bus ont ´et´e observ´es la premi`ere journ´ee et trente la deuxi`eme, n
suit une loi hyperg´eom´etrique,H(30, N, 20/N), et la connaissance des pro-
pri´et´es de cette distribution permet, par exemple, l’approximation de N par
20(30/n). Cette m´ethode dite de capture-recapture, a donn´e lieu `a de nom-
breux d´eveloppements moins anecdotiques en ´ecologie et dynamique des po-
pulations (voir le Chapitre 4).
∥
Nous pourrions citer d’autres exemples o`u la distribution des observations
est parfaitement connue, grˆace `a des consid´erations physiques, ´economiques
ou autres. Cependant, dans la plupart des cas, la mod´elisation statistique
est bien r´eductrice au sens o`u elle n’est qu’une approximation de la r´ealit´e,
perdant une partie de sa richesse mais gagnant en eﬃcacit´e.
Exemple 1.4. Les variations des prix et des salaires sont fortement reli´ees.
Une fa¸con de repr´esenter cette d´ependance est de supposer une relation
lin´eaire
4Voir Appendice A pour une liste des distributions les plus courantes.

4
1 Introduction
ΔP = a + b ΔS + ϵ,
o`u ΔP et ΔS sont les variations de prix et de salaires, a et b les coeﬃ-
cients inconnus et ϵ le terme d’erreur. Une fa¸con, drastique, de simpliﬁer plus
avant cette relation est de supposer que ϵ est normalement distribu´e. Bien
que ϵ soit eﬀectivement une variable al´eatoire, de nombreux facteurs doivent
ˆetre consid´er´es dans la d´etermination des prix et des salaires et il est im-
possible d’´etablir la distribution de ϵ. N´eanmoins, outre une justiﬁcation par
le Th´eor`eme Central Limit (soit l’eﬀet additionnel d’une multitude de petits
facteurs de mˆeme magnitude), cette mod´elisation avanc´ee permet aussi une
analyse statistique plus minutieuse, qui est valide mˆeme si la distribution de
ϵ n’est pas exactement normale. (Voir aussi Exercice 1.3.)
∥
Exemple 1.5. Consid´erons le jeu de donn´ees de la Figure 1.1, qui repr´esente
le taux mensuel de chˆomage en fonction du nombre d’accidents (en milliers)
dans le Michigan entre 1978 et 1987. Lenk (1999) soutient l’existence d’une
relation entre ces deux variations : un taux plus ´elev´e de chˆomage entraˆıne une
diminution de la circulation sur les routes, et donc du nombre d’accidents. Une
simpliﬁcation suppl´ementaire est alors de postuler une structure param´etrique
de d´ependance, comme le mod`ele de r´egression de Poisson
N|ϱ ∼P(exp{β0 + β1 log(ϱ)}) ,
(1.1)
o`u N repr´esente le nombre d’accidents et ϱ le taux de chˆomage pour le mˆeme
mois. La Figure 1.1 donne ainsi l’esp´erance estim´ee E[N|ϱ], qui a tendance `a
conﬁrmer l’impact d´ecroissant du chˆomage sur les accidents. Mais la validit´e
de la mod´elisation (1.1) demande d’abord `a ˆetre ´evalu´ee en utilisant des tests
d’ad´equation ou d’autres techniques de choix de mod`eles. (Voir le Chapitre
7.)
∥
Dans certains cas, l’eﬀet r´educteur est volontairement recherch´e pour ses
cons´equences positives de lissage des donn´ees. Il peut aussi enlever en partie
les perturbations moins importantes d’un ph´enom`ene et souvent am´eliorer son
analyse en mettant en ´evidence les facteurs essentiels comme dans l’exemple
suivant.
Exemple 1.6. Les radiographies m´edicales peuvent ˆetre repr´esent´ees comme
une grille de 1 000 × 1 200 points fondamentaux appel´es pixels, qui prennent
un niveau de gris associ´e `a un nombre compris entre 0 et 256. Par exemple,
la Figure 1.2 donne l’histogramme des niveaux de gris pour une radiogra-
phie typique des poumons. Si nous consid´erons un pixel comme une variable
al´eatoire `a valeurs dans {0, 1, . . ., 256}, donc discr`ete, l’histogramme donne
une approximation de la distribution de cette variable al´eatoire. Comme le
montre la ﬁgure, cette distribution est plutˆot complexe, mais approximative-
ment bimodale. Cette particularit´e a ´et´e observ´ee dans la plupart des radio-
graphies et sugg`ere une mod´elisation de la distribution via une approximation
continue par un m´elange de deux distributions normales de densit´e

1.1 Probl`emes statistiques et mod`eles statistiques
5
8
10
12
14
16
15
20
25
30
35
40
45
Fig. 1.1. Taux de chˆomage mensuel en fonction du nombre d’accidents (en milliers)
dans le Michigan, de 1978 `a 1987. (Source : Lenk, 1999.)
f(x) =
p
√
2πσ1
exp

−(x −μ1)2
2σ2
1

+ 1 −p
√
2πσ2
exp

−(x −μ2)2
2σ2
2

.
(1.2)
0
50
100
150
200
0.000
0.005
0.010
Niveaux de gris
Fig. 1.2.
Histogramme de niveau de gris d’une radiographie de la poitrine et sa
mod´elisation par un m´elange `a deux composantes. (Source : Plessis, 1989.)
´Evidemment cette mod´elisation a consid´erablement liss´e l’histogramme (voir
la Figure 1.2), mais permet aussi une description de l’image avec cinq pa-
ram`etres, sans perte substantielle d’information. Il a ´et´e d´etermin´e que les
deux modes importants de la vraie distribution correspondent en fait aux deux

6
1 Introduction
r´egions de la poitrine, les poumons et le mediastinum. Cette technique de lis-
sage est utilis´ee dans un algorithme d’am´elioration des radiographies appel´e
Parametric Histogram Speciﬁcation (voir Plessis, 1989). Nous consacrerons la
Section 6.4 `a l’estimation bay´esienne des m´elanges.
∥
Face `a cette r´eduction de la complexit´e du ph´enom`ene observ´e, deux ap-
proches statistiques s’opposent. La premi`ere approche suppose que l’inf´erence
statistique doit prendre en compte cette complexit´e autant que possible et
cherche donc `a estimer la distribution sous-jacente du ph´enom`ene sous des
hypoth`eses minimales, en ayant recours en g´en´eral `a l’estimation fonction-
nelle (densit´e, fonction de r´egression, etc.). Cette approche est dite non pa-
ram´etrique. Par opposition, l’approche param´etrique repr´esente la distribution
des observations par une fonction de densit´e f(x|θ), o`u seul le param`etre θ
(de dimension ﬁnie) est inconnu.
Nous consid´erons cette seconde approche comme plus pragmatique dans
la mesure o`u elle prend en compte le fait qu’un nombre ﬁni d’observations
ne peut estimer qu’un nombre ﬁni de param`etres. De plus, la mod´elisation
param´etrique permet une ´evaluation des outils inf´erentiels pour une taille
d’´echantillon ﬁnie, au contraire des m´ethodes non param´etriques, plus ´elabo-
r´ees, dont la principale justiﬁcation est asymptotique et qui ne peuvent donc
s’appliquer que lorsque la taille de l’´echantillon devient inﬁnie (voir Field
et Ronchetti, 1990, qui ´etudient l’applicabilit´e des r´esultats asymptotiques
pour des ´echantillons `a taille ﬁnie). Bien entendu, certaines approches non pa-
ram´etriques, comme les tests (H`ajek et Sid`ak, 1968), ´evacuent compl`etement
l’aspect d’estimation et les probl`emes de tailles d’´echantillons inﬁnies en
construisant des statistiques de test ind´ependantes des distributions, mais
leurs applications restent limit´ees.
Les deux approches ont leurs avantages respectifs et nous ne justiﬁerons
pas d’avantage le choix param´etrique. Naturellement, il existe aussi toute une
litt´erature sur la construction de mod`eles. Voir par exemple Cox (1990) et
Lehmann (1990) pour des r´ef´erences ainsi que pour des r´eﬂexions sur la no-
tion mˆeme de mod`ele statistique. Nous verrons dans le Chapitre 7 quelques
approches pour la comparaison de mod`eles qui peuvent ˆetre utilis´ees dans
l’´etape de mod´elisation, c’est-`a-dire quand plusieurs mod`eles potentiels ‘s’af-
frontent”.
Nous ne consid´erons dans ce livre que l’approche param´etrique. Nous sup-
posons que les observations x1, . . . , xn, sur lesquelles l’analyse statistique
se fonde, proviennent de lois de probabilit´e param´etriques, donc que xi
(1 ≤i ≤n) a une distribution de densit´e fi(xi|θi, x1, . . . , xi−1) sur Rp, telle
que le param`etre θi soit inconnu et la fonction fi soit connue (voir l’Exercice
1.2 sur l’ambigu¨ıt´e formelle de cette d´eﬁnition et la Note 1.8.2 pour des in-
dications sur l’approche bay´esienne de la statistique non param´etrique). Ce
mod`ele peut ˆetre repr´esent´e plus succinctement par
x ∼f(x|θ),

1.1 Probl`emes statistiques et mod`eles statistiques
7
o`u x est le vecteur des observations et θ l’ensemble des param`etres, θ1, . . . , θn,
´eventuellement tous ´egaux. Cette repr´esentation est uniﬁcatrice dans le sens
o`u elle aborde de mani`ere similaire une observation isol´ee, des observations
d´ependantes, et des observations distribu´ees de fa¸con ind´ependante et iden-
tiquement distribu´ees (iid) x1, . . . , xn de mˆeme loi, f(x1|θ). Dans le dernier
cas, x = (x1, . . . , xn) et
f(x|θ) =
n

i=1
f(xi|θ).
Notons que dans ce livre nous ´ecrirons de mani`ere identique les densit´es de
variables al´eatoires continues et discr`etes, la mesure de r´ef´erence ´etant four-
nie naturellement par le contexte. De plus, nous utiliserons la notation “x est
distribu´e selon f” ou “x ∼f” au lieu de “x est une observation de la distribu-
tion de densit´e f” par souci de concision1. La plupart du temps, l’´echantillon
est r´eduit `a une observation unique pour des raisons de simpliﬁcation mais
aussi parce que souvent nous avons aﬀaire `a des distributions pour lesquelles
la taille de l’´echantillon ne compte pas, car elles admettent une statistique
exhaustive de dimension constante (voir la Section 1.3 et le Chapitre 3).
D´eﬁnition 1.7. Un mod`ele param´etrique statistique consiste en l’observation
d’une variable al´eatoire x distribu´ee selon f(x|θ), o`u seulement le param`etre
θ est inconnu et appartient `a un espace de dimension ﬁnie.
Une fois le mod`ele statistique identiﬁ´e, l’objectif principal de l’analyse
statistique est de nous conduire `a une inf´erence sur le param`etre θ. C’est
`a dire que nous utilisons l’observation de x pour am´eliorer notre connais-
sance du param`etre θ, aﬁn de pouvoir prendre une d´ecision concernant le
param`etre, c’est `a dire d’estimer une fonction de θ ou un futur ´ev´enement
dont la distribution d´epend de θ. L’inf´erence peut concerner certaines com-
posantes de θ, pr´ecis´ement (“Quelle est la valeur de θ1 ?”) ou non (“θ2 est-t-
il plus grand que θ3 ?”). Une distinction est souvent faite entre probl`emes
d’estimation et probl`emes de tests, suivant qu’on cherche la valeur exacte
des param`etres (ou de certaines fonctions des param`etres) ou seulement la
v´eriﬁcation d’une hypoth`ese sur ces param`etres. Par exemple, les deux livres
1Ce livre ne suit pas la convention probabiliste habituelle, qui note les variables
al´eatoires par des lettres majuscules, par exemple X, et leur r´ealisation, qui n’est
autre que leur valeur observ´ee, par la lettre minuscule correspondante, soit x, comme
dans P(X ≤x). Ceci s’explique par le fait que, d’un point de vue bay´esien, nous
conditionnons en la valeur r´ealis´ee x et consid´erons le param`etre θ comme une
variable al´eatoire. L’utilisation d’une majuscule grecque peut amener `a une confusion
extrˆeme puisque Θ est plutˆot, par convention, l’espace des param`etres. Cela rend
aussi plus facile l’utilisation des expressions conditionnelles, nombreuses dans les
calculs bay´esiens. Dans les quelques cas o`u cette pratique prˆete `a confusion, nous
reviendrons `a la convention usuelle.

8
1 Introduction
de r´ef´erence de la Statistique classique, Lehmann (1983) et Lehmann et Ca-
sella (1998), sont consacr´es respectivement `a chacun de ces sujets. D’autres
auteurs ont propos´e une distinction plus subtile entre estimation et ´evaluation
des proc´edures d’estimation (voir, par exemple, Casella et Berger, 2001). Plus
g´en´eralement l’inf´erence recouvre tout ph´enom`ene al´eatoire li´e `a θ et inclut
aussi la pr´evision, qui est l’´evaluation de la distribution d’une future obser-
vation y d´ependante de θ (et probablement de l’observation courante de x),
y ∼g(y|θ, x). Nous verrons par la suite que ces divisions sont un peu artiﬁ-
cielles, car tous les probl`emes inf´erentiels peuvent se ramener `a des probl`emes
d’estimation quand ils sont consid´er´es dans une perspective de Th´eorie de la
D´ecision.
Le choix du “tout param´etrique” fait dans ce livre est bien entendu cri-
tiquable, puisque nous ne pouvons pas toujours supposer que la distribution
des observations est connue `a un param`etre (de dimension ﬁnie) pr`es. Ce-
pendant, outre le fait qu’un traitement rigoureux des m´ethodes bay´esiennes
non param´etriques demande un bagage th´eorique plus important, nous insis-
tons sur le fait que cette r´eduction permet des d´eveloppements plus profonds
du processus inf´erentiel, mˆeme si cela peut paraˆıtre paradoxal. Les critiques
sur le caract`ere r´educteur de l’approche statistique et, a fortiori, du choix
param´etrique, s’accompagnent en r´ealit´e d’autres critiques sur le choix des
crit`eres d’´evaluation et de l’objectif mˆeme de la Th´eorie de la D´ecision, comme
nous le verrons dans le Chapitre 2. Cependant, nous soutenons ces choix sur
la base que ces ´etapes de plus en plus r´eductrices sont des exigences minimales
pour qu’une approche statistique soit coh´erente (c’est-`a-dire fasse preuve de
coh´erence interne). Eﬀectivement le but ultime de l’analyse statistique, dans
l’´enorme majorit´e des cas, est de d´efendre le choix d’une d´ecision comme
optimale (ou au moins raisonnable). Il est donc n´ecessaire de pouvoir com-
parer les diﬀ´erents processus inf´erentiels disponibles. Les sections qui suivent
pr´esentent les bases de l’analyse statistique bay´esienne, laquelle nous paraˆıt
ˆetre l’approche la plus appropri´ee pour cette d´etermination des proc´edures
optimales2. Il s’agit aussi de la m´ethode la plus coh´erente, car elle construit
ces proc´edures en partant des propri´et´es requises plutˆot que l’inverse, c’est-
`a-dire en v´eriﬁant le bon comportement de proc´edures choisies sans principe.
Le choix bay´esien, tel qu’il est pr´esent´e dans ce livre, peut apparaˆıtre comme
une r´eduction inutile de la port´ee du cadre inf´erentiel, et a ´et´e souvent cri-
tiqu´e pour cette raison. Mais nous verrons dans les chapitres suivants que
cette r´eduction est `a la fois n´ecessaire et b´en´eﬁque. Le Chapitre 11 r´esume
2Comme le signalent Robins et Wasserman (2000), il existe plusieurs d´eﬁnitions
formelles de la coh´erence, de Savage (1954) `a Heath et Sudderth (1989), lesquels
sont arriv´es `a la conclusion qu’une proc´edure est coh´erente si et seulement si elle est
bay´esienne.

1.2 Le paradigme bay´esien et le principe de dualit´e
9
plusieurs points de vue d´efendant le choix bay´esien qui peuvent ˆetre lus en
perspective avec les arguments pr´ec´edents3.
Notons qu’il existe aussi une approche bay´esienne de la statistique non pa-
ram´etrique. Elle met g´en´eralement en œuvre des distributions a priori sur des
espaces fonctionnels comme les processus de Dirichlet. Voir Ferguson (1973,
1974), Escobar (1989), Escobar et West (1995), Dey et al. (1998), et la Note
1.8.2 pour des r´ef´erences sur ce domaine. L’Exemple 1.23 donne une illustra-
tion de l’int´erˆet de l’approche bay´esienne dans ce cadre.
1.2 Le paradigme bay´esien et le principe de dualit´e
Compar´ee4 `a la mod´elisation probabiliste, l’analyse statistique se ram`ene
fondamentalement `a une inversion, car elle doit d´eterminer les causes–r´eduites
aux param`etres du m´ecanisme probabiliste g´en´erateur–`a partir des eﬀets–
r´esum´es par les observations5. En d’autres termes, quand nous observons un
ph´enom`ene al´eatoire contrˆol´e par le param`etre θ, une m´ethode statistique
permet de d´eduire de ces observations une inf´erence (c’est-`a-dire, en r´esum´e,
une caract´erisation) sur θ, alors que la mod´elisation probabiliste caract´erise le
comportement des observations futures conditionnellement `a θ. Ce caract`ere
d’inversion propre `a la Statistique apparaˆıt de fa¸con ´evidente dans la notion de
fonction de vraisemblance, car, d’un point de vue formel, il s’agit simplement
d’une densit´e r´e´ecrite dans le bon ordre,
ℓ(θ|x) = f(x|θ),
(1.3)
soit donc comme fonction de θ, qui est inconnu, d´ependant de la valeur ob-
serv´ee x. Historiquement l’approche ﬁduciaire de Fisher (1956) se fonde aussi
sur cette inversion (voir la Note 1.8.1).
Une description g´en´erale de l’inversion des probabilit´es est donn´ee par le
th´eor`eme de Bayes : Si A et E sont des ´ev´enements tels que P(E) ̸= 0, P(A|E)
et P(E|A) sont reli´es par
P(A|E) =
P(E|A)P(A)
P(E|A)P(A) + P(E|Ac)P(Ac)
= P(E|A)P(A)
P(E)
.
3Ce chapitre et le Chapitre 11 m´eritent d’ˆetre relus une fois qu’on a bien compris
les points les plus techniques du processus inf´erentiel bay´esien et les probl`emes qui
s’y rattachent.
4Le mot paradigme, qui est un terme grammatical, est utilis´e ici abusivement
comme synonyme de mod`ele ou principes.
5 `A l’´epoque de Bayes et de Laplace, c’est-`a-dire `a la ﬁn du XVIII`eme si`ecle, la
Statistique ´etait souvent appel´ee Probabilit´es inverses, `a cause de cette perspective.
(Voir Stigler, 1986, Chapitre 3.)

10
1 Introduction
En particulier,
P(A|E)
P(B|E) = P(E|A)
P(E|B) ,
(1.4)
quand P(B) = P(A). Obtenir ce r´esultat `a partir des axiomes de la Th´eorie
des Probabilit´es est trivial. Il s’agit cependant de l’´etape conceptuelle la plus
importante dans l’histoire de la Statistique, constituant la premi`ere inversion
des probabilit´es. L’´equation (1.4) exprime le fait fondamental que, pour deux
causes ´equiprobables, le rapport des probabilit´es pour un eﬀet donn´e est ´egal
au rapport des probabilit´es de ces deux causes. Ce th´eor`eme est aussi un
principe d’actualisation, car il d´ecrit la mise `a jour de la vraisemblance de
A de P(A) vers P(A|E), une fois que E a ´et´e observ´e. Bayes (1763) donne
en r´ealit´e une version continue de ces r´esultats, `a savoir, pour deux variables
al´eatoires x et y, de distributions conditionnelle6 f(x|y) et marginale g(y), la
distribution conditionnelle de y sachant x est
g(y|x) =
f(x|y)g(y)

f(x|y)g(y) dy .
Bien que ce th´eor`eme d’inversion soit naturel d’un point de vue probabi-
liste, Bayes et Laplace sont all´es plus loin et ont consid´er´e que l’incertitude sur
le param`etre θ d’un mod`ele peut ˆetre d´ecrite par une distribution de probabi-
lit´e π sur Θ, appel´ee distribution a priori. L’inf´erence est alors fond´ee sur la
distribution de θ conditionnelle `a x, π(θ|x), appel´ee distribution a posteriori
et d´eﬁnie par
π(θ|x) =
f(x|θ)π(θ)

f(x|θ)π(θ) dθ .
(1.5)
Notons que π(θ|x) est ainsi proportionnelle `a la distribution de x condition-
nellement `a θ, qui est aussi la vraisemblance, multipli´ee par la distribution a
priori de θ. (Il semble que la g´en´eralit´e de (1.5) n’ait pas ´et´e per¸cue par Bayes,
mais par Laplace, qui la d´eveloppera plus avant.) La contribution principale
apport´ee par un mod`ele statistique bay´esien est donc de consid´erer en sus une
distribution al´eatoire pour les param`etres.
D´eﬁnition 1.8. Un mod`ele statistique bay´esien est constitu´e d’un mod`ele
statistique param´etrique, f(x|θ), et d’une distribution a priori pour les pa-
ram`etres, π(θ).
En termes statistiques, le th´eor`eme de Bayes actualise donc l’information
sur θ en extrayant l’information contenue dans l’observation x. Son impact
6Souvent nous remplacerons distribution par densit´e, supposant que plus tard le
concept sera mieux d´eﬁni par rapport `a la mesure naturelle dominante, comme la
mesure de Lebesgue. C’est seulement dans un contexte plus avanc´e, comme pour
la mesure de Haar dans le Chapitre 6, qu’une connaissance plus approfondie de la
th´eorie de la mesure sera n´ecessaire.

1.2 Le paradigme bay´esien et le principe de dualit´e
11
provient de la d´ecision audacieuse de mettre causes et eﬀets sur le mˆeme
niveau conceptuel, puisque les deux sont al´eatoires. Du point de vue de la
mod´elisation statistique, il y a donc peu de diﬀ´erences entre observations et pa-
ram`etres, car les manipulations conditionnelles permettent l’´echange de leurs
rˆoles respectifs. Notons que, historiquement, cette id´ee que les param`etres
sont al´eatoires peut ˆetre per¸cue comme allant `a l’encontre du d´eterminisme
ath´ee de Laplace7, ainsi que des conceptions religieuses de Bayes, qui ´etait un
eccl´esiastique non-conformiste. En imposant cette modiﬁcation fondamentale
de la perception du ph´enom`ene al´eatoire, ces deux math´ematiciens ont cr´e´e
l’analyse statistique moderne et, plus particuli`erement, l’analyse bay´esienne.
En eﬀet, le recours `a une distribution a priori π pour les param`etres
d’un mod`ele est vraiment r´evolutionnaire. Elle repr´esente de fait une avanc´ee
majeure, passant de la notion de param`etre inconnu `a celle de param`etre
al´eatoire ; de nombreux statisticiens tracent une fronti`ere herm´etique entre
ces deux concepts, bien qu’ils acceptent une mod´elisation probabiliste des
observations. Ils d´efendent ce point de vue sur la base que, mˆeme si dans
certains cadres, le param`etre est obtenu sous l’action simultan´ee de plusieurs
facteurs et peut ainsi apparaˆıtre comme (partiellement) al´eatoire, comme par
exemple en physique quantique, dans la plupart des cas il ne peut ˆetre per¸cu
comme le r´esultat d’une exp´erience al´eatoire. Un cas typique est l’estimation
de quantit´es physiques comme la vitesse de la lumi`ere c. Une r´eponse dans
ce cas particulier est que la pr´ecision limit´ee des instruments de mesure im-
plique que la vraie valeur de c ne sera jamais connue et justiﬁe le fait de
consid´erer c comme uniform´ement distribu´e sur [c0 −ϵ, c0 + ϵ], o`u ϵ est la
pr´ecision maximale des instruments de mesure et c0 la valeur obtenue.
Nous consid´erons dans le Chapitre 3 diﬀ´erentes approches au probl`eme
d´elicat de d´etermination de la distribution a priori. Cependant, et plus fon-
damentalement, nous voulons insister sur le fait que l’importance de la dis-
tribution a priori dans l’analyse statistique bay´esienne ne r´eside en aucun cas
dans le fait que le param`etre d’int´erˆet θ puisse (ou ne puisse pas) ˆetre per¸cu
comme ´etant distribu´e selon π, ou mˆeme comme ´etant une variable al´eatoire,
mais plutˆot que l’utilisation de la distribution a priori est la meilleure fa¸con
de r´esumer l’information disponible (et le manque d’information) sur ce pa-
ram`etre ainsi que l’incertitude r´esiduelle, et qu’elle permet de cette fa¸con
l’incorporation de cette information inexacte dans le processus de d´ecision.
(Un raisonnement similaire a conduit Laplace `a d´evelopper des mod`eles sta-
tistiques, malgr´e son d´eterminisme.) Un point plus technique est que le seul
moyen de construire une approche math´ematiquement justiﬁ´ee op´erant condi-
tionnellement aux observations est d’introduire une distribution correspon-
dante pour les param`etres. Voir aussi Lindley (1990) pour une justiﬁcation
axiomatique d´etaill´ee sur l’utilisation des distributions a priori.
7“Nous devons envisager l’´etat pr´esent de l’Univers comme un eﬀet de l’´etat
ant´erieur et comme la cause de l’´etat suivant.” – Laplace (1795).

12
1 Introduction
Nous terminons cette section par des exemples historiques de Bayes et de
Laplace.
Exemple 1.9. (Bayes, 1763) Une boule de billard W roule sur une ligne de
longueur un, avec une probabilit´e uniforme de s’arrˆeter n’importe o`u. Suppo-
sons qu’elle s’arrˆete en p. Une deuxi`eme boule O roule alors n fois dans les
mˆemes conditions, et on note X le nombre de fois que la boule O s’arrˆete `a
gauche de W. Connaissant X, quelle inf´erence pouvons-nous mener sur p ?
Dans la terminologie moderne, le probl`eme est de d´eterminer la distribu-
tion a posteriori de p conditionnellement `a X, quand la distribution a priori
de p est uniforme sur [0, 1] et X ∼B(n, p), variable al´eatoire binomiale (voir
l’Appendice A). Comme
P(X = x|p) =
n
x

px(1 −p)n−x,
P(a < p < b et X = x) =
 b
a
n
x

px(1 −p)n−xdp
et
P(X = x) =
 1
0
n
x

px(1 −p)n−x dp,
nous trouvons que
P(a < p < b|X = x) =
 b
a
	n
x

px(1 −p)n−x dp
 1
0
	n
x

px(1 −p)n−x dp
=
 b
a px(1 −p)n−x dp
B(x + 1, n −x + 1) ,
donc que la distribution de p conditionnellement `a X = x est une distribution
bˆeta, Be(x + 1, n −x + 1) (voir l’Appendice A).
∥
Dans le mˆeme esprit, Laplace introduit une mod´elisation probabiliste de
l’espace des param`etres. Mais ses exemples sont plus avanc´es que ceux de
Bayes au sens o`u les distributions a priori qu’il prend en compte sont fond´ees
sur un raisonnement abstrait, plutˆot que sur une justiﬁcation physique8.
Exemple 1.10. (Laplace, 1773) Une urne contient un nombre n de cartes
noires et blanches. Si la premi`ere carte sortie de l’urne est blanche, quelle est
la probabilit´e que la proportion p de cartes blanches soit p0 ? Pour r´esoudre
ce probl`eme, Laplace suppose que tous les nombres de 2 `a n −1 sont
8On peut aussi imaginer un Bayes plus machiav´elique qui choisit cet exemple
particulier aﬁn de passer outre les critiques potentielles sur ce choix d’a priori. Mais
il semble que ce ne soit pas le cas et qu’en r´ealit´e Bayes ait ´etudi´e cet exemple pour
son int´erˆet propre. Voir Stigler (1986) pour plus de d´etails.

1.2 Le paradigme bay´esien et le principe de dualit´e
13
´equiprobables comme valeurs de pn, donc que p soit uniform´ement distribu´e
sur {2/n, . . ., (n −1)/n}. La distribution a posteriori de p peut ˆetre alors
calcul´ee en utilisant le th´eor`eme de Bayes,
P(p = p0| donn´ees) =
p0 × 1/(n −2)
(n−1)/n
p=2/n
p × 1/(n −2)
=
n p0
n(n −1)/2 −1.
∥
´Evidemment le choix pr´ec´edent de la distribution a priori peut ˆetre
contest´e comme ´etant partiellement arbitraire. Cependant, dans la perspective
de la th´eorie des probabilit´es de Laplace, la plupart des ´ev´enements peuvent
ˆetre d´ecompos´es en ´ev´enements ´equiprobables ´el´ementaires et par cons´equent,
dans ce cas particulier, il semble raisonnable de consid´erer les ´ev´enements
{p = i/n} (2 ≤i ≤n −1) comme ´el´ementaires. Un raisonnement similaire
justiﬁe l’exemple suivant.
Exemple 1.11. (Laplace, 1786)
Consid´erant la proportion de naissances
masculines `a Paris, Laplace veut v´eriﬁer que la probabilit´e x d’une naissance
masculine d´epasse 1/2. Observant 251 527 naissances masculines et 241 945
naissances f´eminines en 1785 et supposant que x a pour distribution a priori
la loi uniforme sur [0, 1], Laplace obtient9
P(x ≤1/2|(251 527; 241 945)) = 1.15 × 10−42.
(Voir Stigler, 1986, p. 134 et l’Exercice 1.8.) Il d´eduit alors que cette probabi-
lit´e x est tr`es vraisemblablement sup´erieure `a 50%. Utilisant de nouveau une
distribution a priori uniforme, il compare aussi les naissances masculines `a
Londres et `a Paris et en d´eduit que la probabilit´e d’une naissance masculine
est aussi signiﬁcativement sup´erieure `a 50% en Angleterre.
∥
L’exemple suivant r´esolu par Laplace est plus int´eressant encore car, d’un
point de vue pratique, il propose une m´ethode pour obtenir une proc´edure
optimale, et d’un point de vue th´eorique, il s’agit de la premi`ere construction
formelle d’un estimateur de Bayes (d´etaill´ee dans le Chapitre 2).
Exemple 1.12. En astronomie, il est fr´equent d’obtenir plusieurs observa-
tions d’une quantit´e ξ. Ces mesures sont distribu´ees ind´ependamment selon
une distribution suppos´ee unimodale et sym´etrique autour de ξ. Si nous as-
signons une distribution a priori uniforme au param`etre ξ, il devrait s’agir
d’une “distribution uniforme sur (−∞, +∞)”, qui n’est pas d´eﬁnie en tant
que distribution de probabilit´e. Cependant, si nous acceptons cette extension
9Les nombres d´ecimaux sont indiqu´es dans ce livre en notation anglo-saxone et
non fran¸caise.

14
1 Introduction
formelle (voir la Section 1.5 pour une justiﬁcation), nous pouvons travailler
plutˆot avec la mesure de Lebesgue sur (−∞, +∞).
En utilisant cette distribution g´en´eralis´ee, Laplace (1773) a ´etabli que la
m´ediane a posteriori de ξ, c’est-`a-dire la m´ediane de la distribution de ξ
conditionnellement aux observations, est un estimateur optimal au sens o`u il
minimise l’erreur moyenne absolue
Eξ[ |ξ −δ| ]
(1.6)
en δ, o`u Eξ[·] est l’esp´erance sous la distribution de ξ (voir l’Appendice B
pour une liste des notations usuelles). Ce r´esultat justiﬁe l’utilisation de la
m´ediane a posteriori comme un estimateur de ξ, quelle que soit la distribu-
tion de l’observation. Bien qu’´etabli il y a plus de deux si`ecles, ce r´esultat
est incroyablement moderne (g´en´eralit´e de la distribution et choix de la fonc-
tion de perte pour ´evaluer les estimateurs) et Laplace l’a ´etendu en 1810 en
´etablissant un r´esultat similaire pour l’erreur quadratique.
Curieusement, Laplace ´etait plutˆot d´e¸cu par ce r´esultat, parce qu’il avait
encore besoin de la distribution de l’erreur d’observation pour calculer l’esti-
mateur r´esultant. En 1774, il consid´era la distribution double exponentielle
ϕξ(x) = ξ
2e−ξ|x|,
x ∈R, ξ > 0,
(1.7)
appel´ee aussi distribution de Laplace, qui impliquait en th´eorie la r´esolution
d’une ´equation du quinzi`eme degr´e pour trois observations. (En r´ealit´e Laplace
a fait une erreur et l’´equation correcte est cubique, comme le montre Stigler,
1986.) Puis, en 1777, il consid´era l’alternative plus compliqu´ee encore
ϕξ(x) = 1
2ξ log (ξ/|x|) I|x|≤ξ,
ξ > 0,
o`u I est la fonction indicatrice. Ce fut seulement en 1810, lorsque Legendre
et Gauss expos`erent de fa¸con ind´ependante l’importance de la distribution
normale, que Laplace fut capable de calculer ses estimateurs de Bayes expli-
citement, d´esormais persuad´e qu’il s’agissait de la distribution d’erreur id´eale
(ou “normale”).
∥
Nous consid´ererons de nouveau cet exemple, ainsi que d’autres r´esultats
d’optimalit´e, dans le Chapitre 2, lorsque nous ´etudierons les diﬀ´erentes fonc-
tions de perte pour ´evaluer les proc´edures d’estimation et les estimateurs de
Bayes associ´es. Nous insistons ici sur le fait que la cons´equence principale
des travaux de Bayes et de Laplace a ´et´e d’introduire le concept de perspec-
tive conditionnelle en Statistique, c’est-`a-dire de s’ˆetre rendu compte que pa-
ram`etres et observations sont fondamentalement des objets identiques, mˆeme
s’ils sont per¸cus de fa¸con diﬀ´erente10. Construire en parall`ele une distribu-
tion de probabilit´e sur l’espace des param`etres compl`ete cette ´equivalence,
10Encore une fois, c’est la raison pour laquelle ce livre note indistinctement va-
riables al´eatoires, observations et param`etres en minuscules.

1.3 Principes de vraisemblance et d’exhaustivit´e
15
grˆace au Th´eor`eme de Bayes, et permet un discours quantitatif sur les causes,
c’est-`a-dire, dans notre cadre param´etrique, une inf´erence sur les param`etres.
Comme nous l’avons d´ej`a ´evoqu´e auparavant, le choix de la distribution a
priori est d´elicat, mais sa d´etermination devrait ˆetre incluse dans le processus
statistique, en parall`ele `a la d´etermination de la distribution de l’observation.
Une distribution a priori est eﬀectivement la meilleure fa¸con d’inclure de l’in-
formation r´esiduelle dans un mod`ele. De plus, l’analyse statistique bay´esienne
fournit des outils naturels pour prendre en compte l’incertitude associ´ee `a
l’information r´esiduelle dans le mod`ele (´eventuellement via la mod´elisation
hi´erarchique, voir le Chapitre 10). Pour ﬁnir, comme soulign´e par Lindley
(1971), le paradigme bay´esien est intrins`equement logique : pour un ensemble
donn´e de propri´et´es requises, repr´esent´ees par la fonction de perte et la distri-
bution a priori, l’approche bay´esienne fournit les estimateurs qui satisfont ces
propri´et´es, alors que d’autres approches ´evaluent les propri´et´es d’estimateurs
construits ind´ependamment du processus inf´erentiel.
1.3 Principes de vraisemblance et d’exhaustivit´e
1.3.1 Exhaustivit´e
La Statistique classique peut ˆetre d´ecrite comme ´etant guid´ee par des prin-
cipes souvent justiﬁ´es par le “bon sens” ou par des axiomes suppl´ementaires.
L’approche bay´esienne permet d’incorporer naturellement une majorit´e de ces
principes sans imposer de restrictions suppl´ementaires sur les proc´edures de
d´ecision, et d’en rejeter d’autres de fa¸con tout aussi syst´ematique, comme la
notion d’estimation sans biais. Cette notion ´etait `a une ´epoque la pierre an-
gulaire de la Statistique classique et limitait le choix des estimateurs `a ceux
corrects en moyenne (voir Lehmann et Casella, 1998). Bien qu’intuitivement
acceptable, l’estimation sans biais impose des conditions trop strictes sur le
choix des proc´edures et m`ene souvent `a des solutions peu performantes. (Voir,
par exemple, le cas de l’eﬀet Stein d´ecrit dans la Note 2.8.2.) Plus importants
encore, les probl`emes qui peuvent ˆetre r´esolus `a travers l’estimation sans biais
repr´esentent un pourcentage inﬁme de l’ensemble des probl`emes d’estimation
(Exercice 1.17). Malgr´e ces inconv´enients, une technique statistique r´ecente
appel´ee bootstrap (Efron, 1982, Hall, 1992) a ´et´e pr´esent´ee pour r´eduire le biais
(asymptotiquement).
Deux principes fondamentaux sont respect´es par le paradigme bay´esien :
le principe de vraisemblance et le principe d’exhaustivit´e.
D´eﬁnition 1.13. Quand x ∼f(x|θ), une fonction T de x (aussi appel´ee
statistique) est exhaustive si la distribution de x conditionnellement `a T (x)
ne d´epend pas de θ.

16
1 Introduction
Une statistique exhaustive T (x) contient toute l’information apport´ee par
x sur θ. Selon le th´eor`eme de factorisation, sous certaines conditions de
r´egularit´e (voir Lehmann et Casella, 1998), la densit´e de x s’´ecrit alors
f(x|θ) = g(T (x)|θ)h(x|T (x)),
si g est la densit´e de T (x). Nous verrons dans le Chapitre 2 que, quand un
estimateur est ´evalu´e sous un coˆut convexe, la proc´edure optimale d´epend
uniquement de la statistique exhaustive (th´eor`eme de Rao-Blackwell). En par-
ticulier, quand le mod`ele admet une statistique exhaustive minimale (c’est-`a-
dire fonction de toute autre statistique exhaustive), nous devons ne consid´erer
que les proc´edures d´ependant de cette statistique ou, de fa¸con ´equivalente, du
mod`ele statistique restreint `a cette statistique. Le concept d’exhaustivit´e a
´et´e d´evelopp´e par Fisher et conduit au principe suivant.
Principe d’exhaustivit´e Deux observations x et y donnant la mˆeme
valeur d’une statistique exhaustive T , c’est-`a-dire telles que T (x) =
T (y), doivent conduire `a la mˆeme inf´erence sur θ.
Exemple 1.14. Soient x1, . . . , xn des observations ind´ependantes d’une dis-
tribution normale N(μ, σ2) (voir l’Appendice A). Le th´eor`eme de factorisation
implique alors que le couple T (x) = (¯x, s2), o`u
¯x = 1
n
n

i=1
xi
et
s2 =
n

i=1
(xi −¯x)2,
forme une statistique exhaustive pour le param`etre (μ, σ), de densit´e
g(T (x)|θ) =

n
2πσ2 e−(¯x−θ)2n/2σ2 (s2)(n−3)/2e−s2/2σ2
σnΓ(n −1/2)2n−1/2 .
Par cons´equent, suivant le principe d’exhaustivit´e, l’inf´erence sur μ ne de-
vrait d´ependre que de ce vecteur bidimensionnel, quelle que soit la taille de
l’´echantillon n. Nous verrons dans le Chapitre 3 que l’existence d’une sta-
tistique exhaustive de dimension constante est caract´eristique des familles
exponentielles11.
∥
Exemple 1.15. Soient x1 ∼B(n1, p), x2 ∼B(n2, p), et x3 ∼B(n3, p), trois
observations binomiales ind´ependantes o`u les tailles des ´echantillons n1, n2 et
n3 sont connues. La fonction de vraisemblance est alors
11Pour les autres distributions, l’exhaustivit´e n’est pas un concept int´eressant
car la dimension de la statistique exhaustive est alors de l’ordre de la dimension de
l’observation x (ou de l’´echantillon correspondant), comme expliqu´e dans le Chapitre
3.

1.3 Principes de vraisemblance et d’exhaustivit´e
17
f(x1, x2, x3|p) =
n1
x1
n2
x2
n3
x3

px1+x2+x3(1 −p)n1+n2+n3−x1−x2−x3
et les statistiques
T1(x1, x2, x3) = x1 + x2 + x3
ou
T2(x1, x2, x3) = x1 + x2 + x3
n1 + n2 + n3
sont exhaustives, contrairement `a, par exemple, x1/n1 + x2/n2 + x3/n3.
∥
Le principe d’exhaustivit´e est g´en´eralement accept´e par la plupart des sta-
tisticiens, en particulier `a cause du th´eor`eme de Rao-Blackwell, qui ´ecarte tout
estimateur ne d´ependant pas uniquement de statistiques exhaustives. Dans
un cadre de choix de mod`ele, ce principe est parfois critiqu´e, pour ˆetre trop
r´educteur. Soulignons cependant que le principe d’exhaustivit´e n’est l´egitime
que lorsque les observations sont v´eritablement g´en´er´ees par le mod`ele statis-
tique consid´er´e. Toute incertitude sur la distribution des observations devrait
ˆetre incorpor´ee dans le mod`ele, une modiﬁcation qui conduirait certainement
`a un changement des statistiques exhaustives. La mˆeme remarque s’applique
d’ailleurs au principe de vraisemblance.
1.3.2 Principe de vraisemblance
Ce deuxi`eme principe est en partie une cons´equence du principe d’exhaus-
tivit´e. Il peut ˆetre attribu´e `a Fisher (1959) ou mˆeme `a Barnard (1949), mais
il a ´et´e formalis´e par Birnbaum (1962). Il est fortement d´efendu par Berger
et Wolpert (1988) qui ont fourni une ´etude approfondie du sujet. Dans la
d´eﬁnition suivante, la notion d’information doit ˆetre consid´er´ee au sens large
et non dans le sens math´ematique d’information avanc´e par Fisher, d´eﬁnie au
Chapitre 3. Elle d´esigne, de fa¸con g´en´erale, l’ensemble des inf´erences possibles
sur θ.
Principe de vraisemblance
L’information apport´ee par une ob-
servation de x sur θ est enti`erement contenue dans la fonction de
vraisemblance ℓ(θ|x). De plus, si x1 et x2 sont deux observations qui
d´ependent du mˆeme param`etre θ, et telles qu’il existe une constante c
satisfaisant
ℓ1(θ|x1) = cℓ2(θ|x2)
pour tout θ, elles apportent la mˆeme information sur θ et doivent
conduire `a la mˆeme inf´erence.
Notons que le principe de vraisemblance n’est valide que lorsque
(i) l’inf´erence concerne le mˆeme param`etre θ ; et
(ii) θ prend en compte tous les facteurs inconnus du mod`ele.
L’exemple suivant donne une illustration devenue “classique” de ce principe.

18
1 Introduction
Exemple 1.16. Soit l’´etude de taux d’audience d’une ´emission de t´el´evision,
0 ≤θ ≤1 repr´esentant la part d’audience. Un enquˆeteur a trouv´e neuf
t´el´espectateurs et trois personnes n’ayant pas vu l’´emission. Si nous ne dispo-
sons pas de plus d’information, au moins deux mod`eles probabilistes peuvent
ˆetre envisag´es :
(1) l’enquˆeteur a interrog´e 12 personnes, et a donc observ´e x ∼B(12, θ)
avec x = 9 ;
(2) l’enquˆeteur a interrog´e N personnes jusqu’`a obtenir 3 non t´el´especta-
teurs, avec N ∼Neg(3, 1 −θ) et N = 12.
En d’autres termes, la quantit´e al´eatoire dans cette ´etude peut ˆetre soit 9, soit
12. (Notons qu’elles pourraient aussi ˆetre toutes deux al´eatoires.) Le point `a
souligner est que, pour les deux mod`eles, la vraisemblance est proportionnelle
`a
θ3(1 −θ)9.
Par cons´equent, le principe de vraisemblance aﬃrme que l’inf´erence sur θ
devrait ˆetre la mˆeme pour les deux mod`eles. Comme on verra dans l’Exercice
1.29, ceci n’est pas le cas dans l’approche classique.
∥
Puisque l’approche bay´esienne est enti`erement fond´ee sur la distribution
a posteriori
π(θ|x) =
ℓ(θ|x)π(θ)

ℓ(θ|x)π(θ)dθ
(voir ´equation (1.5) et la Section 1.4), qui ne d´epend de x qu’`a travers ℓ(θ|x),
le principe de vraisemblance est automatiquement satisfait dans un cadre
bay´esien.
Au contraire, l’approche classique ou fr´equentiste12 est fond´ee sur des pro-
pri´et´es de comportement moyen des proc´edures et justiﬁe donc l’utilisation
d’un estimateur pour des raisons qui peuvent contredire le principe de vrai-
semblance. Cette perspective est particuli`erement frappante en th´eorie des
tests, trait´ee au Chapitre 5. Par exemple, si x ∼N (θ, 1) et si nous cher-
chons `a v´eriﬁer l’hypoth`ese H0 : θ = 0, la proc´edure de test classique de
Neyman-Pearson au seuil 5% rejettera l’hypoth`ese si x = 1.96, sur la base
que P(|x −θ| ≥1.96) = 0.05, donc conditionn´e par l’´ev´enement |x| > 1.96
plutˆot que par x = 1.96 (ce qui est impossible pour la th´eorie fr´equentiste).
L’argument fr´equentiste associ´e `a cette proc´edure est alors que, dans 5% des
cas o`u H0 est vrai, l’hypoth`ese nulle est rejet´ee `a tort. De tels arguments
contredisent le principe de vraisemblance, car les comportements des queues
12La th´eorie avanc´ee par Wald, Neymann et Pearson dans les ann´ees 50 est dite
fr´equentiste, car elle ´evalue les proc´edures par rapport `a leurs performances sur le
long terme, c’est-`a-dire en moyenne (ou en fr´equence) plutˆot que de se concentrer
sur la performance de la proc´edure pour l’observation obtenue, comme le ferait une
approche conditionnelle. L’approche fr´equentiste sera abord´ee en d´etail dans les
Chapitres 2 et 5.

1.3 Principes de vraisemblance et d’exhaustivit´e
19
de distributions peuvent varier pour les mˆemes vraisemblances (voir les Exer-
cices 1.24 et 1.29). L’opposition entre paradigmes fr´equentiste et bay´esien est
plus forte en th´eorie des tests que pour l’estimation ponctuelle, o`u l’approche
fr´equentiste apparaˆıt souvent comme un cas limite de l’approche bay´esienne
(voir le Chapitre 5).
Exemple 1.17. Soient x1, x2 i.i.d. N (θ, 1). La fonction de vraisemblance est
alors
ℓ(θ|x1, x2) ∝exp{−(¯x −θ)2}
avec ¯x = (x1 + x2)/2. Soit maintenant la distribution alternative
g(x1, x2|θ) = π−3/2 e−(x1+x2−2θ)2/4
1 + (x1 −x2)2 .
Cette distribution donne une fonction de vraisemblance proportionnelle `a
ℓ(θ|x1, x2) et par cons´equent devrait conduire `a la mˆeme inf´erence sur θ. Ce-
pendant, la distribution g est tout `a fait diﬀ´erente de f(x1, x2|θ) ; par exemple,
l’esp´erance de (x1 −x2) n’est pas d´eﬁnie. Les estimateurs de θ auront donc
des propri´et´es fr´equentistes diﬀ´erentes s’ils ne d´ependent pas que de ¯x. En
particulier, les r´egions de conﬁance pour θ peuvent diﬀ´erer signiﬁcativement,
`a cause des queues plus ´epaisses de g.
∥
Exemple 1.18. Une autre implication du principe de vraisemblance est le
principe des r`egles d’arrˆet en analyse s´equentielle. Une r`egle d’arrˆet τ peut ˆetre
d´eﬁnie comme suit : si les exp´eriences Ei produisent des observations xi ∈Xi,
avec xi ∼f(xi|θ), consid´erons la suite correspondante Ai ⊂X1 × . . . × Xi
telle que le crit`ere τ prend la valeur n si (x1, . . . , xn) ∈An, i.e., l’exp´erience
s’arrˆete apr`es la n-i`eme observation seulement si les n premi`eres observations
sont en An. La vraisemblance de (x1, . . . , xn) est alors
ℓ(θ|x1, . . . , xn) = f(x1|θ)f(x2|x1, θ)
. . . f(xn|x1, . . . , xn−1, θ)IAn(x1, . . . , xn),
et donc d´epend seulement de τ via l’´echantillon x1, . . . , xn. Ceci implique le
principe suivant.
Principe des r`egles d’arrˆet Si une suite d’exp´eriences, E1, E2, . . .,
admet une r`egle d’arrˆet, τ, qui indique quand doivent s’arrˆeter les
exp´eriences, l’inf´erence sur θ ne doit d´ependre de τ qu’`a travers
l’´echantillon r´esultant.
L’Exemple 1.16 illustre le cas de deux crit`eres d’arrˆet diﬀ´erents qui
conduisent au mˆeme ´echantillon : ou bien on ﬁxe la taille de l’´echantillon
`a douze, ou bien l’exp´erience s’arrˆete quand on a obtenu neuf r´eponses po-
sitives. Un autre exemple frappant (mˆeme s’il est artiﬁciel) de r`egle d’arrˆet

20
1 Introduction
consiste `a observer des xi ∼N (θ, 1) et `a prendre τ comme le premier entier
n tel que
|¯xn| =

n

i=1
xi/n
 > 1.96/√n.
Dans ce cas, la r`egle d’arrˆet est ´evidemment incompatible avec la mod´elisation
fr´equentiste, parce que avec un tel ´echantillon on rejettera toujours l’hypoth`ese
nulle H0 :
θ = 0 au seuil de 5% (voir le Chapitre 5). En revanche, une
approche bay´esienne ´evite cette diﬃcult´e (voir Raiﬀa et Schlaifer, 1961 et
Berger et Wolpert, 1988, p. 81).
∥
1.3.3 D´erivation du principe de vraisemblance
Une justiﬁcation du principe de vraisemblance a ´et´e avanc´ee par Birnbaum
(1962) qui a ´etabli que le principe de vraisemblance est une cons´equence du
principe d’exhaustivit´e, `a condition d’accepter un second principe.
Principe de conditionnement
Si deux exp´eriences sur le pa-
ram`etre θ, not´ees E1 et E2, sont possibles et si on choisit une de ces
exp´eriences avec probabilit´e p, l’inf´erence sur θ ne doit d´ependre que
de l’exp´erience choisie.
Il semble diﬃcile de refuser ce principe quand l’exp´erience choisie est
connue, comme on peut le constater dans l’exemple (classique) suivant.
Exemple 1.19. (Cox, 1958) Dans un laboratoire de recherche, une quantit´e
physique θ doit ˆetre mesur´ee par un appareil eﬃcace, mais tr`es souvent utilis´e,
qui donne une mesure x1 ∼N (θ, 0.1), avec une probabilit´e p = 0.5, ou
grˆace `a un autre appareil, moins pr´ecis mais plus disponible, qui donne x2 ∼
N (θ, 10). L’appareil a ´et´e choisi au hasard selon la disponibilit´e de l’appareil
le plus pr´ecis. L’inf´erence sur θ ne devrait donc pas d´ependre du fait que le
second appareil aurait pu ˆetre choisi. Cependant, un intervalle de conﬁance
classique au seuil 5% prenant en compte cette s´election, soit donc moyennant
entre toutes les exp´eriences possibles, est de demi-longueur 5.19, tandis que
l’intervalle associ´e `a E1 est de demi-longueur 0.62 (Exercice 1.26).
∥
Le r´esultat ´equivalent de Birnbaum (1962) est alors le suivant.
Th´eor`eme 1.20. Le principe de vraisemblance est ´equivalent `a la conjonc-
tion des principes d’exhaustivit´e et de conditionnement.
Preuve. D´eﬁnissons d’abord l’´evidence associ´ee `a une exp´erience E , Ev(E , x),
comme l’ensemble des inf´erences possibles sur le param`etre θ pour cette
exp´erience. Soit E ∗l’exp´erience mixte correspondant `a Ei avec probabilit´e 0.5

1.3 Principes de vraisemblance et d’exhaustivit´e
21
(i = 1, 2), qui a donc comme r´esultat (i, xi). Sous ces notations, le principe
de conditionnement peut ˆetre ´enonc´e ainsi : pour tout j = 1, 2,
Ev(E ∗, (j, xj)) = Ev(Ej, xj) .
(1.8)
Soient x0
1 et x0
2 tels que
ℓ(·|x0
1) = cℓ(·|x0
2).
(1.9)
Le principe de vraisemblance est alors ´equivalent `a
Ev(E1, x0
1) = Ev(E2, x0
2) .
(1.10)
Supposons que (1.9) est v´eriﬁ´ee. Pour l’exp´erience mixte E ∗construite `a partir
des deux exp´eriences initiales, consid´erons la statistique
T (j, xj) =

(1, x0
1)
si j = 2, x2 = x0
2,
(j, xj)
sinon,
qui prend la mˆeme valeur pour (1, x0
1) et pour (2, x0
2). Alors, cette statistique
est exhaustive puisque, si t ̸= (1, x0
1),
Pθ(X∗= (j, xj)|T = t) = It(j, xj)
et
Pθ(X∗= (1, x0
1)|T = (1, x0
1)) =
c
1 + c,
de par la proportionnalit´e des fonctions de vraisemblance. Le principe d’ex-
haustivit´e implique alors que
Ev(E ∗, (1, x1)) = Ev(E ∗, (2, x2))
(1.11)
et, combin´e avec (1.8), donne (1.10), soit donc le principe de vraisemblance.
La r´eciproque de ce th´eor`eme se d´eduit du principe de vraisemblance, du
fait que les fonctions de vraisemblance de (j, xj) et de xj sont proportionnelles
et, pour le principe d’exhaustivit´e, du th´eor`eme de factorisation.
⊓⊔
Evans et al. (1986) ont d´emontr´e que le principe de vraisemblance peut
ˆetre aussi obtenu comme une cons´equence d’une version plus forte du principe
de conditionnement.
1.3.4 Mise en œuvre du principe de vraisemblance
Il paraˆıt donc tout `a fait justiﬁ´e de suivre le principe de vraisemblance,
puisque celui-ci s’obtient `a partir des principes irr´efutables d’exhaustivit´e et
de conditionnement. Cependant, ce principe est, somme toute, assez vague,
puisqu’il ne m`ene pas `a la s´election d’une proc´edure particuli`ere pour un
probl`eme inf´erentiel donn´e. D’aucuns ont soutenu que le rˆole du statisticien
devrait s’arrˆeter `a la d´etermination de la fonction de vraisemblance (Box et

22
1 Introduction
Tiao, 1973) puisqu’elle suﬃt au client pour mener l’inf´erence, mais ce point
de vue extrˆeme n’est tenable que dans les cas les plus simples (ou d’un point
de vue bay´esien d´ecisionnel, si le preneur de d´ecision fournit aussi une dis-
tribution a priori et une fonction de perte). Pour de grandes dimensions (du
param`etre), la fonction de vraisemblance est aussi diﬃcile `a manipuler `a cause
du manque d’outils de repr´esentation ad´equats.
Le caract`ere vague du principe de vraisemblance exige un renforcement
des bases axiomatiques du processus inf´erentiel, c’est-`a-dire l’ajout de struc-
tures dans la construction des proc´edures statistiques. Par exemple, une mise
en œuvre eﬃcace du principe de vraisemblance est l’estimateur du maximum
de vraisemblance, comme d´ecrit bri`evement en Section 1.3.5. De fa¸con simi-
laire, le paradigme bay´esien permet la mise en œuvre pratique du principe
de vraisemblance, avec comme avantage suppl´ementaire la prise en compte
des exigences d´ecisionnelles du probl`eme inf´erentiel, et mˆeme l’obtention de
proc´edures optimales d’un point de vue fr´equentiste (voir plus bas).
Si nous gardons `a l’esprit l’aspect d’inversion de la Statistique pr´esent´e
en Section 1.2, il est tentant de consid´erer la vraisemblance comme une den-
sit´e g´en´eralis´ee en θ, dont le mode serait alors l’estimateur du maximum de
vraisemblance, et de travailler avec cette densit´e comme une distribution or-
dinaire. Cette approche semble avoir ´et´e soutenue par Laplace qui propo-
sait d’utiliser une distribution a priori uniforme lorsque aucune information
n’´etait disponible sur θ (voir les Exemples 1.9-1.12). De mˆeme, Fisher intro-
duisit l’approche ﬁduciaire (voir la Note 1.8.1) pour tenter de circonvenir la
d´etermination de la distribution a priori lors de la mise en pratique du prin-
cipe de vraisemblance, le choix de cette distribution ´etant subjectif (puisque
ne d´ependant que de la distribution des observations). Cependant, cette ap-
proche est surtout d´efendable quand θ est un param`etre de position (voir aussi
l’Exemple 1.25), puisqu’il entraˆıne en g´en´eral des paradoxes et des contradic-
tions. L’exemple le plus frappant est le fait que ℓ(θ|x) n’est pas n´ecessairement
int´egrable comme fonction de θ (Exercice 1.25). L’obtention de distributions
a posteriori objectives exige en fait une th´eorie plus avanc´ee des distributions
non informatives (voir le Chapitre 3), qui montre que la fonction de vraisem-
blance ne peut pas toujours ˆetre consid´er´ee comme la distribution a posteriori
la plus naturelle.
Beaucoup d’approches ont ´et´e propos´ees pour mettre en œuvre le principe
de vraisemblance, comme par exemple la th´eorie de la vraisemblance p´enalis´ee
(Akaike, 1978, 1983) ou la th´eorie de la complexit´e stochastique (Rissanen,
1983, 1990). Voir aussi Bjørnstad (1990) pour une revue des m´ethodes non
bay´esiennes fond´ees sur le principe de vraisemblance dans le domaine de la
pr´evision. La conclusion g´en´erale de cette section est que, malgr´e tout, mis
`a part le fait que plusieurs de ces th´eories ont une teneur bay´esienne, une
approche v´eritablement bay´esienne est la plus ad´equate pour tirer parti du
principe de vraisemblance. (Voir Berger et Wolpert, 1988, Chapitre 5, pour
une discussion approfondie sur ce point.)

1.3 Principes de vraisemblance et d’exhaustivit´e
23
1.3.5 Estimation par maximum de vraisemblance
Le principe de vraisemblance est en soi distinct de l’approche de l’estima-
tion par maximum de vraisemblance, qui n’est qu’une fa¸con parmi d’autres
de mettre en œuvre ce principe. Puisque nous rencontrerons assez souvent
cette technique dans les prochains chapitres, et qu’elle se situe `a la lisi`ere du
paradigme bay´esien, nous rappelons bri`evement quelques faits ´el´ementaires
concernant le maximum de vraisemblance. Un traitement plus ´etendu peut
ˆetre trouv´e dans Lehmann et Casella (1998).
Lorsqu’on observe x ∼f(x|θ), l’approche par maximum de vraisemblance
consid`ere l’estimateur suivant de θ,
ˆθ = arg sup
θ
ℓ(θ|x),
(1.12)
qui est donc la valeur de θ qui maximise la densit´e en x, f(x|θ), ou, exprim´e
de mani`ere informelle, la probabilit´e d’observer la valeur donn´ee x. La maxi-
misation (1.12) n’est pas toujours possible (voir, par exemple, le cas d’un
m´elange de deux distributions normales, d´etaill´e au Chapitre 6), ou bien elle
peut mener `a plusieurs maxima globaux ´equivalents (voir notamment le cas
d’une loi de Cauchy, C (0, 1), avec deux observations bien s´epar´ees). Cepen-
dant, l’estimation par maximum de vraisemblance est largement utilis´ee, `a
cause d’une part de la motivation intuitive de maximiser la probabilit´e d’oc-
currence et d’autre part de ses propri´et´es asymptotiques fortes (convergence
et eﬃcacit´e). Une autre caract´eristique int´eressante de l’estimateur du maxi-
mum de vraisemblance est son invariance par reparam´etrisation. En eﬀet,
pour toute fonction h(θ), l’estimateur de maximum de vraisemblance est h(ˆθ)
(mˆeme quand h n’est pas bijective). Cette propri´et´e n’est partag´ee par aucune
autre approche statistique (mis `a part les estimateurs bay´esiens dans le cas
particulier des fonctions de coˆut intrins`eques, voir la Section 2.5.4.)
La m´ethode du maximum de vraisemblance a aussi ses d´efauts. Premi`e-
rement, la maximisation de ℓ(θ|x) peut ˆetre assez complexe en pratique,
particuli`erement dans les cas multidimensionnels ou contraints. Prenons les
exemples d’un m´elange de distributions normales, d’une distribution de Wei-
bull tronqu´ee
ℓ(θ1, θ2|x1, . . . , xn) = (θ1θ2)n(x1 . . . xn)θ1 exp

−θ2
n

i=1
xθ1
i

(voir l’Exercice 1.28), ou d’une table 10 × 10 o`u xij ∼N (θij, 1) et θij croˆıt
en i et j (voir Robert et Hwang, 1996, et les Exercices 1.29 et 1.30). Certaines
proc´edures num´eriques, comme l’algorithme EM de Dempster et al. (1977),
pour des mod`eles `a donn´ees manquantes, ou l’algorithme de Robertson et al.
(1988) pour des espaces param´etriques restreints par ordre, ont ´et´e adapt´ees
`a cette approche, mais des probl`emes non r´esolus demeurent (MacLachlan et
Krishnan, 1997, Robert et Casella, 2004).

24
1 Introduction
Deuxi`emement, une technique de maximisation donne forc´ement des esti-
mateurs peu lisses, par opposition `a l’int´egration par exemple. Cela est par-
ticuli`erement vrai lorsque l’espace des param`etres est restreint. Par exemple
Saxena et Alam (1982) montrent que, si x ∼χ2
p(λ), loi du khi deux d´ecentr´e
`a p degr´es de libert´e13, l’estimateur du maximum de vraisemblance de λ
est ´egal `a 0 pour x < p. De mˆeme, les estimateurs du maximum de vrai-
semblance peuvent ˆetre num´eriquement instables, c’est-`a-dire peuvent varier
consid´erablement pour de petites variations des observations, du moins pour
des tailles d’´echantillon r´eduites (Exercice 1.31).
Un dernier d´efaut, mais non des moindres, de l’approche du maximum
de vraisemblance est qu’elle n’admet pas de justiﬁcations probabiliste et
d´ecisionnelle. De fait, elle ne r´epond pas aux exigences d’une analyse d´eci-
sionnelle et ´echoue ainsi `a fournir des outils d’´evaluation pour les estimateurs
qu’elle propose. Par exemple, il n’est pas possible de faire des tests dans un
contexte de maximum de vraisemblance pur : il est n´ecessaire de recourir `a des
justiﬁcations fr´equentistes, mˆeme pour des tests du rapport de vraisemblance
(voir la Section 5.3).
De mˆeme, les r´egions de conﬁance de la forme C = {θ; ℓ(θ)/ℓ(ˆθ) ≥c}, qui
sont les plus petites asymptotiquement, ne d´ependront pas uniquement de la
fonction de vraisemblance si la borne c doit ˆetre choisie de mani`ere `a obtenir
un niveau de conﬁance α.
1.4 Distributions a priori et a posteriori
Supposons d´esormais que, en plus d’une distribution d’´echantillonnage,
f(x|θ), une distribution a priori sur θ, π(θ), soit disponible, c’est-`a-dire que
nous disposions d’un mod`ele compl`etement bay´esien. Le Chapitre 3 traite du
probl`eme pr´eliminaire d’obtention de cette distribution `a partir de l’infor-
mation a priori. Une fois donn´ees ces deux distributions, nous pouvons en
construire plusieurs autres, `a savoir :
(a) la distribution jointe de (θ, x),
ϕ(θ, x) = f(x|θ)π(θ) ;
(b) la distribution marginale de x,
m(x) =

ϕ(θ, x) dθ
=

f(x|θ)π(θ) dθ ;
13Cet exemple montre aussi la limite de l’invariance mentionn´ee ci-dessus : lorsque
y ∼Np(θ, Ip), l’estimateur maximum de vraisemblance de λ = ||θ||2 est ||y||2 = x ∼
χ2
p(λ), qui diﬀ`ere de l’estimateur du maximum de vraisemblance fond´e sur x (voir
l’Exercice 3.56).

1.4 Distributions a priori et a posteriori
25
(c) la distribution a posteriori de θ, obtenue par la formule de Bayes,
π(θ|x) =
f(x|θ)π(θ)

f(x|θ)π(θ) dθ
= f(x|θ)π(θ)
m(x)
;
(d) la distribution pr´edictive de y, o`u y ∼g(y|θ, x), obtenue par
g(y|x) =

g(y|θ, x)π(θ|x)dθ .
Exemple 1.21. (Suite de l’Exemple 1.9) Si x ∼B(n, p) et p ∼Be(α, β)
(avec α = β = 1 dans le cas particulier de Bayes),
f(x|p) =
n
x

px(1 −p)n−x,
x = 0, 1, ..., n,
π(p) =
1
B(α, β)pα−1(1 −p)β−1,
0 ≤p ≤1.
La distribution jointe de (x, p) est alors
ϕ(x, p) =
	n
x

B(α, β)pα+x−1(1 −p)n−x+β−1
et la distribution marginale de x est
m(x) =
	n
x

B(α, β)B(α + x, n −x + β)
=
n
x
 Γ(α + β)
Γ(α)Γ(β)
Γ(α + x)Γ(n −x + β)
Γ(α + β + n)
,
puisque la distribution a posteriori de p est
π(p|x) = pα+x−1(1 −p)β+n−x−1
B(α + x, β + n −x) ,
qui est une loi bˆeta Be(α + x, β + n −x).
∥
Parmi ces distributions, le concept fondamental du paradigme bay´esien
est la distribution a posteriori. En eﬀet, cette distribution op`ere de fa¸con
conditionnelle sur les observations, et met donc en œuvre automatiquement
l’inversion des probabilit´es d´eﬁnie dans la Section 1.2, tout en incluant les
exigences du principe de vraisemblance. On ´evite ainsi de moyenner sur des
valeurs de x non observ´ees, ce qui est l’essence de l’approche fr´equentiste. La
distribution a posteriori repr´esente l’actualisation de l’information disponible

26
1 Introduction
sur θ, au vu de l’information contenue dans ℓ(θ|x), tandis que π(θ) repr´esente
l’information disponible a priori, c’est-`a-dire pr´ealable `a l’observation de x.
Notons que l’approche bay´esienne jouit d’un type sp´eciﬁque de coh´erence
(nous devrions en voir d’autres exemples dans les chapitres suivants) en ce
que l’ordre suivant lequel des observations i.i.d. sont collect´ees n’a pas d’im-
portance (il s’agit d’une cons´equence du principe de vraisemblance), mais
aussi que mettre `a jour l’a priori une observation apr`es l’autre, ou toutes les
observations d’un coup, revient au mˆeme. En d’autres termes,
π(θ|x1, . . . , xn) =
f(xn|θ)π(θ|x1, . . . , xn−1)

f(xn|θ)π(θ|x1, . . . , xn−1)dθ
=
f(xn|θ)f(xn−1|θ)π(θ|x1, . . . , xn−2)

f(xn|θ)f(xn−1|θ)π(θ|x1, . . . , xn−2)dθ
= . . .
(1.13)
=
f(xn|θ)f(xn−1|θ) . . . f(x1|θ)π(θ)

f(xn|θ)f(xn−1|θ) . . . f(x1|θ)π(θ)dθ .
Il peut arriver que les observations ne modiﬁent pas les distributions de
certains param`etres. C’est ´evidemment le cas quand la loi de x ne d´epend pas
de ces param`etres, comme dans certains cas non identiﬁables.
Exemple 1.22. Consid´erons une observation x d’une distribution
N
θ1 + θ2
2
, 1

avec un a priori π sur (θ1, θ2) tel que π(θ1, θ2) = π1(θ1 + θ2)π2(θ1 −θ2). Si
nous r´ealisons le changement de variables
ξ1 = θ1 + θ2
2
,
ξ2 = θ1 −θ2
2
,
la distribution a posteriori de ξ2 est alors
π(ξ2) ∝

R
exp

−(x −ξ1)2/2

2π1(2ξ1)2π2(2ξ2)dξ1
∝π2(2ξ2)

R
exp

−(x −ξ1)2/2

π1(2ξ1)dξ1
∝π2(2ξ2)
pour chaque observation x. L’observation n’apporte donc pas d’information
sur ξ2.
∥
Nous devons avertir le lecteur ou la lectrice14 que tous les cas non iden-
tiﬁables ne m`enent pas `a cette conclusion simple : suivant le choix de la
14Dans la suite de l’ouvrage, le fait que le lectorat de cet ouvrage est mixte sera
pris en compte de mani`ere implicite par un pluriel neutre aﬁn de ne pas surcharger
le style.

1.4 Distributions a priori et a posteriori
27
distribution a priori et de la reparam´etrisation du param`etre θ en (θ1, θ2), o`u
la distribution de x ne d´epend que de θ1, la distribution marginale a poste-
riori de θ2 peut d´ependre ou non de x (Exercice 1.44). Un aspect important
du paradigme bay´esien dans un cadre non identiﬁable est cependant que la
distribution a priori peut ˆetre utilis´ee comme un outil pour identiﬁer les com-
posantes du param`etre qui ne sont pas couvertes par la vraisemblance, mˆeme
si un tel choix d’a priori peut avoir un impact sur la partie identiﬁable.
Cette invariance entre distributions a priori et distributions a posteriori
peut aussi aﬀecter certains param`etres quand le nombre de ceux-ci devient
trop important par rapport `a la taille de l’´echantillon (Exercice 1.38).
Exemple 1.23. Une telle situation a lieu lorsque le nombre de param`etres
est inﬁni, par exemple quand l’inf´erence concerne une distribution enti`ere.
Dette et Studden (1997) consid`erent n observations x1, . . . , xn provenant d’un
m´elange de distributions g´eom´etriques,
x ∼
 1
0
θx(1 −θ) dG(θ),
x prenant ses valeurs dans N et la distribution probabiliste G ´etant incon-
nue. Dans ce cadre, G peut ˆetre repr´esent´e par la suite de ses moments non
centr´es c1, c2, . . . La fonction de vraisemblance est alors obtenue `a partir de
P(X = k) = ck −ck+1. Dette et Studden (1997) montrent (Exercice 1.45) que,
bien que les ci soient li´es par un nombre inﬁni d’in´egalit´es (commen¸cant par
c1 > c2 > c2
1), il est possible de construire de fa¸con analytique des fonctions
ind´ependantes entre elles des ci, p1, p2, . . ., prenant leurs valeurs dans [0, 1]
et telles que ci ne d´epende que de (p1, . . . , pi) (voir l’Exercice 1.45 pour les
d´etails). Par cons´equent, si la distribution a priori de (p1, p2, . . .) est
π(p1, p2, . . .) =
+∞

i=1
πi(pi)
et si la plus grande observation dans l’´echantillon est k, la distribution a
posteriori de (pk+2, pk+3, . . .) ne d´epend pas des observations :
π(pk+2, . . . |x1, . . . , xn) = π(pk+2, . . .) =
+∞

i=k+2
πi(pi).
∥
`A l’inverse, la distribution marginale ne fait pas intervenir le param`etre
d’int´erˆet θ. Il est donc rare de s’en servir directement, sauf dans l’approche
bay´esienne empirique (voir le Chapitre 10), car la distribution a posteriori
est beaucoup mieux adapt´ee aux objectifs inf´erentiels. La distribution mar-
ginale peut cependant ˆetre utilis´ee pour construire la distribution a priori,
si l’information disponible a ´et´e obtenue `a partir de diﬀ´erentes exp´eriences,

28
1 Introduction
c’est-`a-dire lorsqu’on traite diﬀ´erents θ dans une m´eta analyse (voir Mosteller
et Chalmers, 1992, Mengersen et Tweedie, 1995, et Givens et al., 1997).
Pour une distribution π sur θ donn´ee, la port´ee de l’approche bay´esienne
est bien plus ´etendue que celle de la perspective classique. Par exemple, non
seulement la moyenne, la m´ediane ou le mode de π(θ|x) peuvent ˆetre calcul´es,
mais en plus la performance de ces estimateurs (comme la variance et les
moments d’ordres plus ´elev´es) peut ˆetre ´evalu´ee. De plus, la connaissance de
la distribution a posteriori permet la d´etermination des r´egions de conﬁance
sous la forme de r´egions de plus forte densit´e a posteriori (highest posterior
density, HPD), c’est-`a-dire des r´egions de la forme
{θ; π(θ|x) ≥k},
dans le cas unidimensionnel comme dans le cas multidimensionnel. De la mˆeme
mani`ere, il est possible de calculer assez naturellement la probabilit´e d’une hy-
poth`ese H0, en conditionnant sur les observations, soit P π(θ ∈H0|x). Notons
que l’approche bay´esienne est la seule permettant ce type d’interpr´etation,
car l’expression P(θ = θ0) = 0.95 n’a aucun sens si θ n’est pas une va-
riable al´eatoire. D’un point de vue bay´esien, cette expression signiﬁe que nous
sommes prˆets `a parier que θ est ´egal `a θ0 `a 19 contre 1. Les Chapitres 4
et 5 sont consacr´es `a l’´etude des techniques d’estimation qui incluent des exi-
gences d´ecisionnelles. Nous nous contentons ici d’illustrer la simplicit´e de cette
approche en construisant un intervalle de conﬁance dans l’exemple suivant.
Exemple 1.24. Soient x ∼N(θ, 1) et θ ∼N(0, 10). Par cons´equent, pour15
x donn´e,
π(θ|x) ∝f(x|θ)π(θ) ∝exp

−(x −θ)2
2
−θ2
20

∝exp

−11θ2
20
+ θx

∝exp

−11
20 {θ −(10x/11)}2

et donc θ|x ∼N( 10
11x, 10
11). Une r´egion de conﬁance naturelle est alors
15Le symbole de proportionnalit´e s’entend en termes de fonctions de θ (et non de
x). Tout en restant tout `a fait rigoureux, les calculs qui reposent sur des relations
proportionnelles permettent en g´en´eral une plus grande eﬃcacit´e dans l’obtention
de la distribution a posteriori. En eﬀet, les densit´es de probabilit´e sont uniquement
d´etermin´ees par leur forme fonctionnelle et la constante de normalisation peut ˆetre
retrouv´ee, si n´ecessaire, `a la ﬁn du calcul. Cette technique sera donc utilis´ee abon-
damment dans cet ouvrage. ´Evidemment, elle n’est pas toujours appropri´ee, par
exemple quand la constante de proportionnalit´e est nulle ou inﬁnie, comme on le
verra dans la Section 1.5.

1.4 Distributions a priori et a posteriori
29
C = {θ; π(θ|x) > k}
=

θ;
θ −10
11x
 > k′

.
Nous pouvons aussi associer un niveau de conﬁance α `a cette r´egion, dans le
sens o`u, si zα/2 est le fractile α/2 de N(0, 1),
Cα =

10
11x −zα/2

10
11, 10
11x + zα/2

10
11

a une probabilit´e a posteriori (1 −α) de contenir θ.
∥
Nous verrons dans le Chapitre 10 que la distribution a posteriori peut par-
fois ˆetre d´ecompos´ee en plusieurs niveaux selon une structure hi´erarchique, les
param`etres des premiers niveaux ´etant trait´es comme des variables al´eatoires,
suivant des distributions a priori suppl´ementaires. Mais cette d´ecomposition
est purement utilitaire et ne modiﬁe pas la structure fondamentale du mod`ele
bay´esien.
Un probl`eme que nous n’avons pas ´evoqu´e ci-dessus est le fait que, bien que
toutes les quantit´es a posteriori soient d´eﬁnies automatiquement d’un point
de vue conceptuel comme int´egrales par rapport `a la distribution a posteriori,
il est assez diﬃcile dans la pratique de fournir une valeur num´erique. En parti-
culier, une forme explicite de la distribution a posteriori ne peut pas toujours
ˆetre obtenue. En fait, la complexit´e de la distribution a posteriori augmente
quand les param`etres sont continus et la dimension de Θ est importante.
Ces diﬃcult´es de calcul sont ´etudi´ees dans le Chapitre 6, o`u nous four-
nissons quelques solutions g´en´erales. Cependant, elles ne doivent pas ˆetre
consid´er´ees comme un inconv´enient majeur de l’approche bay´esienne. En eﬀet,
la Statistique num´erique16 est actuellement en train de subir un d´eveloppe-
ment tr`es rapide et elle nous permet de rejeter la notion de distribution a priori
choisie pour la simplicit´e des calculs, mˆeme si nous pouvons toujours compter
sur ces distributions particuli`eres pour pr´esenter les exemples de fa¸con claire
et simple dans cet ouvrage. Au contraire, il est encourageant de voir que nous
nous approchons de l’objectif de fournir un outil statistique plus performant
et plus eﬃcace grˆace `a ces nouvelles techniques de calcul qui permettent l’uti-
lisation de distributions a priori plus complexes et aussi plus repr´esentatives
de l’information a priori.
16Nous avons pr´ef´er´e traduire computational en num´erique, plutˆot que d’employer
le n´eologisme computationnel, assez lourd, mˆeme si comput et computer ont exist´e
en ancien fran¸cais... En particulier, avant la Renaissance, comput ´etait employ´e `a la
place de math´ematique en tant que mati`ere scolaire.

30
1 Introduction
1.5 Distributions a priori impropres
Lorsque le param`etre θ peut ˆetre trait´e comme une variable al´eatoire avec
une distribution de probabilit´e π connue, nous avons vu dans la section ci-
dessus que le th´eor`eme de Bayes est la base de l’inf´erence bay´esienne, car
il donne la distribution a posteriori. Cependant, dans de nombreux cas, la
distribution a priori est d´etermin´ee par des crit`eres subjectifs ou th´eoriques
qui conduisent `a une mesure σ-ﬁnie sur l’espace des param`etres Θ plutˆot qu’`a
une mesure de probabilit´e, c’est-`a-dire une mesure π telle que

Θ
π(θ) dθ = +∞.
Dans de tels cas, on dit que la distribution a priori est impropre (ou g´en´eralis´ee).
(Une d´eﬁnition alternative des estimateurs de Bayes g´en´eralis´es est consid´er´ee
dans le Chapitre 2.)
Lorsque cette distribution d´ecoule de raisons subjectives, le d´ecideur
´evaluant par exemple la vraisemblance relative des diﬀ´erentes parties de l’es-
pace des param`etres Θ (voir le Chapitre 3), il est logique que, pour de grands
espaces de param`etres, par exemple lorsque Θ n’est pas d´enombrable, la
somme des poids, c’est-`a-dire la mesure de Θ, soit inﬁnie.
Exemple 1.25. Soit une distribution f(x −θ) telle que le param`etre de po-
sition θ appartient `a R sans restriction. Si aucune information a priori n’est
disponible sur le param`etre θ, il est assez raisonnable de consid´erer que la vrai-
semblance d’un intervalle [a, b] doit ˆetre proportionnelle `a sa longueur b −a :
l’a priori est donc proportionnel `a la mesure de Lebesgue sur R. C’est aussi la
distribution choisie par Laplace (voir l’Exemple 1.12).
∥
Quand une telle loi a priori impropre a ´et´e obtenue par des m´ethodes
automatiques, `a partir de la densit´e f(x|θ) (voir le Chapitre 3), elle paraˆıt
plus susceptible aux critiques, mais soulignons les points suivants.
(1) Ces approches automatiques sont souvent la seule fa¸con d’obtenir
une distribution a priori dans un cadre non informatif. Dans certains
cas, l’unique information disponible (ou retenue) est la connaissance de
la distribution d’´echantillon f(x|θ). Cette g´en´eralisation du paradigme
bay´esien rend ainsi possible une extension suppl´ementaire de l’applica-
bilit´e des techniques bay´esiennes.
(2) Les performances des estimateurs obtenus `a partir de ces distribu-
tions g´en´eralis´ees sont en g´en´eral suﬃsamment bonnes pour justiﬁer
leur utilisation. De plus, elles permettent souvent l’obtention d’estima-
teurs classiques comme l’estimateur du maximum de vraisemblance, et
garantissent donc une fermeture du champ inf´erentiel en proposant une
approche alternative situ´ee aux fronti`eres du paradigme bay´esien.

1.5 Distributions a priori impropres
31
(3) Les lois a priori g´en´eralis´ees se situent souvent `a la limite des distribu-
tions propres (suivant plusieurs topologies). Elles peuvent ˆetre donc in-
terpr´et´ees comme un cas extrˆeme o`u la pr´ecision de l’information a priori
a compl`etement disparu et elles semblent donner une r´eponse plus ro-
buste (ou plus objective) en termes d’une possible erreur de sp´eciﬁcation
de la loi a priori (interpr´etation erron´ee de la faible information a priori).
(4) Ce type de distributions est g´en´eralement plus acceptable par les non-
bay´esiens, en partie pour les raisons ´evoqu´ees aux points (2) et (3),
mais aussi parce qu’elles peuvent avoir des justiﬁcations fr´equentistes,
comme :
(i) la minimaxit´e, qui conduit habituellement aux distributions les moins
favorables d´eﬁnies dans le Chapitre 2 ;
(ii) l’admissibilit´e, les lois propres et certaines lois impropres engen-
drant des estimateurs admissibles et, r´eciproquement, les estimateurs
de Bayes ´etant parfois les seuls estimateurs admissibles (voir le Cha-
pitre 8) ; et
(iii) l’invariance, le meilleur estimateur ´equivariant ´etant un estimateur
de Bayes pour la mesure de Haar (g´en´eralement impropre) d´eﬁnie
pour le groupe de transformations correspondant (voir le Chapitre 9).
(5) Une perspective r´ecente (voir par exemple Berger, 2000) est que les
lois a priori impropres devraient ˆetre privil´egi´ees par rapport aux lois
a priori propres vagues, comme une distribution N (0, 1002), car ces
derni`eres donnent une fausse impression de s´ecurit´e due `a leur caract`ere
propre tout en manquant de robustesse en termes d’inﬂuence sur les
r´esultats d’inf´erence.
Ces raisons ne convainquent pas tous les bay´esiens (voir, par exemple, Lindley,
1965), mais l’introduction de distributions impropres dans le sch´ema bay´esien
permet une fermeture du cadre inf´erentiel au sens topologique.
D’un point de vue plus pratique, le fait que la distribution a priori soit
impropre aﬀaiblit la sym´etrie entre observations et param`etres, mais tant que
la distribution a posteriori est d´eﬁnie, les m´ethodes bay´esiennes restent appli-
cables. En fait, la notion de mesure conditionnelle n’est pas clairement d´eﬁnie
en th´eorie de la mesure, bien que Hartigan (1983) l’ait pr´econis´ee comme
une extension. Cependant, la convention est de consid´erer la distribution a
posteriori π(θ|x) d´eﬁnie par la formule de Bayes
π(θ|x) =
f(x|θ)π(θ)

Θ f(x|θ)π(θ) dθ ,
pourvu que la pseudo-distribution marginale

Θ f(x|θ)π(θ) dθ soit correcte-
ment d´eﬁnie. C’est une condition imp´erative pour utiliser les lois a priori
impropres, qui est (presque) toujours v´eriﬁ´ee par les lois a priori propres
(Exercice 1.46).
Exemple 1.26. (Suite de l’Exemple 1.25) Si f(x −θ) est la densit´e de
la distribution normale N (θ, 1) et π(θ) = ϖ, une constante arbitraire, la

32
1 Introduction
pseudo-distribution marginale est la mesure
m(x) = ϖ
 +∞
−∞
1
√
2π exp

−(x −θ)2/2

dθ = ϖ
et, par la formule de Bayes, la distribution a posteriori de θ est
π(θ | x) =
1
√
2π exp

−(x −θ)2
2

,
c’est-`a-dire qu’elle correspond `a N(x, 1). Notons que la constante ϖ ne joue
pas un rˆole dans la distribution a posteriori, et que cette derni`ere est en fait la
fonction de vraisemblance. Par cons´equent, mˆeme si les lois a priori impropres
ne peuvent pas ˆetre normalis´ees, ceci n’a pas d’importance, car la constante
n’a pas d’int´erˆet pour l’inf´erence statistique (cependant, voir le Chapitre 5
pour une exception importante).
∥
Dans la version bay´esienne du principe de vraisemblance, seule importe
la distribution a posteriori. La g´en´eralisation `a des distributions a priori im-
propres ne devrait donc pas poser de probl`emes, au sens o`u une distribution
a posteriori correspondant `a une loi (a priori) impropre peut ˆetre utilis´ee
de la mˆeme fa¸con qu’une distribution a posteriori normale quand elles sont
d´eﬁnies. ´Evidemment, l’interpr´etation de la loi a priori est plus d´elicate. Par
exemple, dans l’Exemple 1.25, le poids a priori relatif de tout intervalle est
nul, mais cela ne veut pas dire qu’un intervalle est invraisemblable a priori.
En r´ealit´e, traiter des lois a priori impropres comme des lois a priori standard
peut conduire `a des diﬃcult´es comme les paradoxes de marginalisation (voir
le Chapitre 3), car le calcul habituel des probabilit´es conditionnelles ne peut
pas s’appliquer dans ce cadre. Comme l’aﬃrme Lindley (1990), l’erreur est de
les interpr´eter [les lois a priori non informatives] comme des repr´esentations
d’une compl`ete ignorance.
Il peut arriver que pour certaines observations x, la distribution a poste-
riori ne soit pas d´eﬁnie (Exercices 1.48-1.51). La solution la plus habituelle
est de d´eterminer la r´eponse impropre comme une limite d´eﬁnie `a partir de
lois a priori propres (tout en s’assurant que la distribution impropre obtenue
est justiﬁ´ee).
Exemple 1.27. Soit une observation binomiale, x ∼B(n, p), comme dans
l’exemple originel de Bayes. Quelques auteurs (voir Novick et Hall, 1965, et
Villegas, 1977) contestent le choix de Laplace de la loi uniforme sur [0, 1]
comme distribution a priori automatique, car celle-ci apparaˆıt comme ´etant
biais´ee contre les valeurs extrˆemes 0 et 1. Ils proposent de consid´erer plutˆot
l’a priori de Haldane (1931)
π∗(p) ∝[p(1 −p)]−1.
Dans ce cas, la loi marginale,

1.5 Distributions a priori impropres
33
m(x) =
 1
0
[p(1 −p)]−1
n
x

px(1 −p)n−xdp
= B(x, n −x),
n’est d´eﬁnie que pour x ̸= 0, n. En cons´equence, π(p|x) n’existe pas pour ces
deux valeurs extrˆemes de x, car le produit π∗(p)px(1 −p)n−x ne peut pas ˆetre
normalis´e pour ces deux valeurs. Pour les autres valeurs de x, la distribution
a posteriori est Be(x, n−x), avec une moyenne a posteriori x/n, qui est aussi
l’estimateur du maximum de vraisemblance.
La diﬃcult´e en 0 et n peut ˆetre r´esolue de la fa¸con suivante ; la mesure a
priori π∗apparaˆıt comme une limite de lois bˆeta d´enormalis´ees,
πα,β(p) = pα−1(1 −p)β−1,
lorsque α et β tendent vers 0. Ces distributions πα,β donnent comme lois
a posteriori Be(α + x, β + n −x), malgr´e l’absence de facteur normalisant,
puisque le choix de cette constante n’a pas d’impact. La distribution a poste-
riori πα,β(p|x) a pour esp´erance
δπ
α,β(x) =
x + α
α + β + n,
qui tend vers x/n quand α et β tendent vers 0. Si la moyenne a posteriori
est la quantit´e d’int´erˆet, nous pouvons alors ´etendre la proc´edure inf´erentielle
aux cas x = 0 et x = n en consid´erant ´egalement x/n comme un estimateur
bay´esien (uniquement) formel.
∥
Exemple 1.28. Soit x ∼N (0, σ2). Il d´ecoule de consid´erations d’invariance
qu’une distribution a priori int´eressante pour σ est la mesure π(σ) = 1/σ (voir
le Chapitre 6). Ceci donne comme loi a posteriori
π(σ2|x) ∝e−x2/2σ2
σ2
,
qui n’est pas d´eﬁnie pour x = 0. Cependant, de par la continuit´e de la variable
al´eatoire x, cette diﬃcult´e a beaucoup moins d’importance que dans l’Exemple
1.27.
∥
´Evidemment, ces arguments limites sur mesure ne sont pas toujours jus-
tiﬁ´es, en particulier parce que l’estimateur r´esultant peut d´ependre du choix
de la suite convergente. Un exemple de ce ph´enom`ene est fourni par Richard
(1973) (voir aussi Bauwens, 1991) dans le cas d’une distribution normale
N (θ, σ2), lorsque π(θ) est la mesure de Lebesgue et σ−2 est distribu´e selon
une loi gamma G (α, s2
0), c’est-`a-dire quand
π(θ, σ2) ∝
1
σ2(α+1) e−s2
0/2σ2 ;

34
1 Introduction
l’estimateur de θ d´epend alors du comportement du rapport s2
0/(α−1) quand
num´erateur et d´enominateur tendent simultan´ement vers 0.
De plus, lorsqu’on estime une fonction discontinue de θ, l’estimateur pour
la loi limite peut diﬀ´erer de la limite des estimateurs. C’est le cas par exemple,
en th´eorie des tests, pour le paradoxe de Jeﬀreys-Lindley (voir le Chapitre 5).
Enﬁn, dans certains cadres, la distribution a priori impropre ne peut pas ˆetre
utilis´ee si facilement, comme dans l’estimation des mod`eles de m´elange (voir
l’Exercice 1.56 et le Chapitre 6) ou en th´eorie des tests lorsqu’on teste des
hypoth`eses bilat´erales (voir les Exercices 1.60-1.62 et le Chapitre 5).
Il est donc important de prendre plus de pr´ecautions quand on a aﬀaire
`a des lois impropres, aﬁn d’´eviter les distributions mal d´eﬁnies. Dans cet ou-
vrage, les lois impropres seront toujours utilis´ees en supposant implicitement
que la distribution a posteriori correspondante existe, mˆeme s’il existe des
situations o`u cette condition peut ˆetre relˆach´ee (voir la Note 1.8.3).
La diﬃcult´e pratique est de v´eriﬁer la condition d’int´egrabilit´e

f(x|θ)π(θ) dθ < ∞
dans des situations complexes, comme les mod`eles hi´erarchiques (voir l’Exer-
cice 1.66 et le Chapitre 10), o`u l’utilisation de lois a priori impropres au niveau
sup´erieur de la hi´erarchie est assez commune. Le probl`eme y est mˆeme plus
aigu parce que les nouveaux outils de calcul comme les algorithmes MCMC
(Chapitre 6) ne n´ecessitent pas dans la pratique de v´eriﬁer cette condition.
(Voir Note 1.8.3 et Hobert et Casella, 1996, 1998.)
Nous voudrions insister de nouveau sur le fait que la principale justiﬁcation
des distributions a priori impropres est de vouloir clore le champ inf´erentiel
bay´esien pour des raisons subjectives, axiomatiques (li´ees aux r´esultats sur les
classes compl`etes, voir le Chapitre 8) et pratiques. Cette extension ne modiﬁe
pas la complexit´e de l’inf´erence, cependant, puisque la distribution a posteriori
est bien une distribution de probabilit´e.
1.6 Le choix bay´esien
Pour clore cette introduction, nous voudrions attirer l’attention des lec-
teurs sur le fait qu’il existe un choix bay´esien. Il est donc toujours possible
d’adh´erer ou non `a ce choix. Bien que nous le d´efendions avec vigueur, ce
n’est pas une excuse pour devenir trop v´eh´ement. La plupart des th´eories
statistiques, comme celles pr´esent´ees par Lehmann et Casella (1998), ont un
niveau raisonnable de coh´erence et donnent le plus souvent des r´esultats si-
milaires lorsque le nombre d’observations devient grand en regard du nombre
de param`etres (voir la Note 1.8.4).
Si nous ne pr´esentons pas ces autres th´eories dans ce livre, c’est pour
des raisons `a la fois philosophiques et pratiques (expos´ees dans le Chapitre
11), et aussi par souci de pr´esenter un discours uniﬁ´e sur la Statistique,

1.7 Exercices
35
tel que toute proc´edure soit une cons´equence logique d’un ensemble donn´e
d’axiomes. Tel est sans doute pour nous l’argument premier pour adh´erer au
choix bay´esien, `a savoir la coh´erence fondamentale des axiomes de l’inf´erence
statistique bay´esienne. En mod´elisant des param`etres inconnus de la distri-
bution d’´echantillonnage `a travers une structure probabiliste, donc en pro-
babilisant l’inconnu, l’approche bay´esienne autorise un discours quantitatif
sur ces param`etres. Elle permet aussi l’incorporation de l’information a priori
et de l’impr´ecision de cette information dans la proc´edure inf´erentielle. En
outre, `a part des arguments subjectifs et axiomatiques en faveur de l’approche
bay´esienne, qui reste le seul syst`eme permettant de conditionner sur les ob-
servations (et donc de mettre en œuvre le principe de vraisemblance), il faut
prendre en compte le fait que les estimateurs de Bayes sont aussi essentiels
pour les notions d’optimalit´e fr´equentiste en Th´eorie de la D´ecision. De fait,
ils peuvent fournir des outils essentiels mˆeme pour les statisticiens qui refusent
l’´elicitation a priori et l’interpr´etation bay´esienne de la r´ealit´e.
1.7 Exercices
Section17 1.1
1.1
⋆(Kelker, 1970)
Un vecteur x ∈Rp est distribu´e selon une distribution `a
sym´etrie sph´erique
si e.x a la mˆeme distribution que x pour toute transfor-
mation orthogonale e.
a. Montrer que, lorsqu’une distribution `a sym´etrie sph´erique admet une densit´e,
celle-ci est fonction de xtx uniquement.
b. Montrer que, si la densit´e de x est ϕ(xtx), la densit´e de r = ||x|| est propor-
tionnelle `a
rp−1 ϕ(r2),
et donner le coeﬃcient de proportionnalit´e.
c. Montrer que, si x
=
(x′
1, x′
2)′ avec x1 ∈Rq et x2
∈
Rp−q, et ||x||2 =
||x1||2 + ||x2||2, la densit´e de (r1, r2) = (||x1||, ||x2||) est proportionnelle `a
rq−1
1
rp−q−1
2
ϕ
`
r2
1 + r2
2
´
.
d. En d´eduire que
U =
||x1||2
||x1||2 + ||x2||2
est distribu´ee selon une distribution bˆeta Be(q/2, (p −q)/2).
e. Conclure que
p −q
q
||x1||2
||x2||2
17Les exercices signal´es par une ´etoile sont plus avanc´es, mais ils oﬀrent une vision
plus g´en´erale des points trait´es dans chaque chapitre. Ils peuvent ˆetre pris comme
des compl´ements utiles, ou, pour la plupart des lecteurs, comme une lecture guid´ee
des articles pertinents.

36
1 Introduction
est distribu´ee selon la distribution Fp−q,q ind´ependamment de la distribution
`a sym´etrie sph´erique de x. En d´eduire que le rapport de F est robuste au sens
o`u sa distribution est constante sur l’ensemble des distributions `a sym´etrie
sph´erique.
1.2
⋆(Gouri´eroux et Monfort, 1996)
Cet exercice illustre le fait que la fronti`ere
entre mod`eles param´etriques et non param´etriques est relativement diﬃcile `a
d´eterminer. Cependant, le param`etre ne peut pas ˆetre identiﬁ´e dans le second
cas.
a. Montrer qu’une fonction de r´epartition se caract´erise par les valeurs qu’elle
prend en les nombres rationnels.
b. En d´eduire que la collection des fonctions de r´epartition sur R a la puissance
du continu (cardinal de l’ensemble des parties de N, ensemble des entiers
naturels) et donc que toutes les distributions de probabilit´e sur R peuvent
ˆetre index´ees par un param`etre r´eel.
1.3 Montrer que, si x1, . . . , xn sont des variables explicatives et y1, . . . , yn sont
distribu´es selon E[yi] = bxi, l’estimateur des moindres carr´es de b, solution
de
min
b
n
X
i=1
(yi −bxi)2,
est aussi estimateur du maximum de vraisemblance sous l’hypoth`ese de norma-
lit´e.
1.4 Dans l’Exemple 1.3, donner l’esp´erance de n. Est-ce que cela signiﬁe que 20 ×
30/n est un estimateur sans biais de N ?
1.5 Dans l’Exemple 1.6, montrer que les moments de x ∼f(x) peuvent s’´ecrire
E[xk] = pE[xk
1] + (1 −p)E[xk
2]. En d´eduire un estimateur des moments de
(p, μ1, μ2, σ2
1, σ2
2). [Note : Historiquement, il s’agit de l’estimateur de Pearson,
1894.]
Section 1.2
1.6 Calculer les probabilit´es de l’Exemple 1.11 pour l’approximation
Φ(−x) ≃
1
√
2πx
e−x2/2,
qui est valide lorsque x est grand.
1.7 Un examen comporte quinze questions, chacune ayant trois r´eponses pos-
sibles. Supposons que 70% des ´etudiants passant l’examen sont bien pr´epar´es et
r´epondent correctement `a chaque question avec une probabilit´e de 0.8 ; les 30%
restants r´epondent au hasard.
a. Caract´eriser la distribution de S, la note de chaque ´etudiant, si un point est
accord´e `a chaque bonne r´eponse.
b. Il faut huit bonnes r´eponses pour r´eussir l’examen. Conditionnellement au
fait qu’un ´etudiant r´eussisse un examen, quelle est la probabilit´e qu’il ´etait
bien pr´epar´e ?
1.8 D´emontrer les versions discr`etes et continues du th´eor`eme de Bayes.
1.9
⋆(Romano et Siegel, 1986) Le paradoxe de Simpson fournit une illustration de la
n´ecessit´e d’une approche conditionnelle en Statistique. Soient deux traitements
m´edicaux, T1 et T2, T1 ´etant appliqu´e `a cinquante patients et T2 `a cinquante

1.7 Exercices
37
autres. Le r´esultat de cette exp´erience donne les pourcentages de survie suivants :
40% pour le traitement T1, 32% pour le traitement T2. Donc le traitement T1
semble meilleur puisqu’il entraˆıne un taux de survie plus ´elev´e. Cependant, si
on prend l’ˆage en compte, et l’on s´epare les patients entre juniors (50) et seniors
(50), les taux de succ`es sont donn´es dans la table suivante :
T1 T2
junior 40 50
senior 10 35
et T1 est moins bon que T2 dans les deux cas. Expliquer ce paradoxe en utilisant
le th´eor`eme de Bayes.
1.10 Montrer que la quantit´e δ qui minimise (1.6) est la m´ediane de la distribution
de ξ. Donner la quantit´e δ qui minimise le coˆut quadratique moyen Eξ[(ξ −δ)2].
1.11 Calculer la m´ediane de la distribution a posteriori associ´ee `a la distribution
d’´echantillonnage (1.7) et l’a priori plat π(ξ) = 1 sur ξ. [Note : Voir Stigler,
1986, pour une solution.]
Section 1.3
1.12 Montrer que, pour un ´echantillon normal N (θ, σ2), il n’existe pas d’estimateur
sans biais de σ, mais seulement de puissances enti`eres de σ2.
1.13 Soit x ∼P(λ). Montrer que δ(x) = I0(x) est un estimateur sans biais de e−λ
qui est nul avec probabilit´e 1 −e−λ.
1.14
∗Une statistique S est dite libre si sa distribution ne d´epend pas du param`etre
θ et compl`ete si Eθ[g(S)] = 0 pour tout θ implique g(s) ≡0. Montrer que, si S
est compl`ete et exhaustive minimale, elle est ind´ependante de toute statistique
libre. [Note : Ce r´esultat est appel´e th´eor`eme de Basu. La r´eciproque est fausse.]
1.15 Soit un ´echantillon x1, . . . , xn de variables i.i.d. de fonction de r´epartition F.
a. Donner la densit´e de la statistique d’ordre.
b. Montrer que O = (X(1), ..., X(n)) est exhaustive. Quelle est la distribution
conditionnelle de (X1, ..., Xn) sachant O ?
c. Soient X1, ..., Xn i.i.d. de densit´e compl`etement inconnue. Montrer que O est
alors compl`ete.
1.16
Montrer qu’une statistique T est exhaustive si et seulement si
ℓ(θ|x) ∝ℓ(θ|T(x)).
1.17 (Berger et Wolpert, 1988, p. 21) Soit x de support {1, 2, 3} et de distribution
f(· | 0) ou f(· | 1), avec
x
1
2
3
f(x|0) 0.9 0.05 0.05
f(x|1) 0.1 0.05 0.85
Montrer que la proc´edure qui rejette l’hypoth`ese H0 : θ = 0 (pour accepter
H1 : θ = 1) est correcte avec une probabilit´e de 0.9 lorsque x = 2, 3 (sous H0 et
H1). Quelle est l’implication du principe de vraisemblance quand x = 2 ?

38
1 Introduction
1.18 Montrer que le principe de la r`egle d’arrˆet expos´e dans l’Exemple 1.18 est
une cons´equence du principe de vraisemblance dans le cas discret. [Note : Voir
Berger et Wolpert, 1988, pour une g´en´eralisation au cas continu.]
1.19 Pour l’Exemple 1.18, montrer que la r`egle d’arrˆet τ est ﬁnie avec probabilit´e
1. (Indication : Utiliser la loi du logarithme it´er´e. Voir Billingsley, 1995.)
1.20 (Berger et Wolpert, 1988) Montrer que, si z ∼f(z|θ) et si x = t(z), x est une
statistique exhaustive si et seulement si pour tout a priori π sur θ, π(θ|x) =
π(θ|z).
1.21 Soient x1, . . . , xn distribu´es selon E xp(λ). Ces donn´ees sont censur´ees au sens
o`u il existe n variables al´eatoires y1, . . . , yn distribu´ees selon f(y), ind´ependam-
ment de λ, et z1 = x1 ∧y1, . . . , zn = xn ∧yn sont les variables r´eellement
observ´ees.
a. Montrer que, selon le principe de vraisemblance, l’estimation de λ ne devrait
pas d´ependre de f.
b. ´Etendre ce r´esultat `a d’autres types de censures.
1.22 (Berger, 1985b) Dans le cadre de l’Exemple 1.16, montrer que, pour le test
UMPU H0 :
p = 1/2, l’hypoth`ese nulle sera accept´ee ou rejet´ee au niveau
5%, selon la distribution consid´er´ee. En d´eduire que la th´eorie fr´equentiste des
tests n’est pas compatible avec le principe de vraisemblance. (Indication : Voir
Chapitre 5 pour des d´eﬁnitions.)
1.23 Montrer que la densit´e g(x1, x2|θ) donn´ee dans l’Exemple 1.17 est eﬀective-
ment une densit´e de probabilit´e.
1.24 Cet exercice a pour but de g´en´eraliser les Exemples 1.16 et 1.17 au cas
continu, en d´emontrant qu’il peut y avoir aussi incompatibilit´e entre l’approche
fr´equentiste et le principe de vraisemblance dans ce cas.
a. Si f(x|θ) est une densit´e telle que x soit une statistique compl`ete, montrer
qu’il n’existe pas d’autre densit´e g(x|θ) telle que les deux fonctions de vrai-
semblance ℓf(θ|x) = f(x|θ) et ℓg(θ|x) = g(x|θ) sont proportionnelles (en tant
que fonctions de θ) pour tout x.
b. Soit maintenant un ´echantillon x1, . . . , xn distribu´e selon f(x|θ). Nous sup-
posons qu’il existe une statistique exhaustive compl`ete T(x1, . . . , xn) de di-
mension 1 et une statistique libre S(x1, . . . , xn) telle que le couple (T, S)
soit une fonction bijective de (x1, . . . , xn). Montrer que, s’il existe une autre
densit´e g(x1, . . . , xn|θ) telle que les deux fonctions de vraisemblance soient
proportionnelles,
ℓg(θ|x1, . . . , xn) = ω(x1, . . . , xn)ℓf(θ|x1, . . . , xn),
le facteur de proportionnalit´e ω ne d´epend que de S(x1, . . . , xn).
c. Dans le cas particulier o`u f(x|θ) est la densit´e exponentielle, f(x|θ) = θe−θx,
donner un exemple d’une densit´e g(x1, . . . , xn|θ) telle que les deux fonctions
de vraisemblance soient proportionnelles. (Indication : Trouver une statis-
tique libre S et construire une fonction h(x1, . . . , xn) ne d´ependant que de
S(x1, . . . , xn) telle que Eθ[h(x1, . . . , xn)] = 1.)
– Comparer les longueurs des intervalles de conﬁance au seuil 10% dans le cadre
de l’Exemple 1.19.
– Montrer que les intervalles de conﬁance de l’Exemple 1.19 sont corrects : pour
l’exp´erience mixte, x ∼0.5N (θ, 0.1) + 0.5N (θ, 10) et P(θ ∈[x −5.19, x +

1.7 Exercices
39
5.19]) = 0.95, tandis que pour l’exp´erience E1, x ∼N (θ, 0.1) et P(θ ∈[x −
0.62, x + 0.62]) = 0.95.
Les exercices suivants (1.25 `a 1.35) pr´esentent quelques aspects suppl´emen-
taires de l’estimation par maximum de vraisemblance.
1.25 Montrer que, si la fonction de vraisemblance ℓ(θ|x) est utilis´ee comme une
densit´e en θ, l’inf´erence r´esultante n’ob´eit pas au principe de vraisemblance.
(Indication : Montrer que la distribution a priori de h(θ), lorsque h est une
transformation bijective, n’est pas la transform´ee de ℓ(θ|x) selon la r`egle du
jacobien.)
1.26 Soit une variable al´eatoire de Bernoulli y ∼B([1 + eθ]−1).
a. Si y = 1, montrer qu’il n’existe pas d’estimateur du maximum de vraisem-
blance de θ.
b. Montrer qu’on a le mˆeme probl`eme lorsque y1, y2 ∼B([1 + eθ]−1) et y1 =
y2 = 0 ou y1 = y2 = 1. Donner l’estimateur du maximum de vraisemblance
dans les autres cas.
1.27 Soient x1, x2 deux observations ind´ependantes de C (θ, 1). Montrer que, lorsque
|x1 −x2| > 2, la fonction de vraisemblance est bimodale. Trouver des exemples
de x1, x2, x3 i.i.d. C (θ, 1) tels que la fonction de vraisemblance ait trois modes.
1.28 La loi de Weibull W e(α, c) est tr`es utilis´ee en ing´enierie et en ﬁabilit´e. Sa
densit´e est donn´ee par
f(x|α, c) = cα−1(x/α)c−1e−(x/α)c.
a. Montrer que, lorsque c est connu, ce mod`ele est ´equivalent `a un mod`ele
gamma.
b. Donner les ´equations de vraisemblance en α et c et montrer qu’elles n’ad-
mettent pas de solutions explicites.
c. Soit un ´echantillon i.i.d. x1, . . . , xn de W e(α, c) censur´e `a droite en y0. Don-
ner la fonction de vraisemblance correspondante lorsque α et c sont inconnus
et montrer qu’il n’existe pas d’estimateur du maximum de vraisemblance ex-
plicite dans ce cas.
1.29
∗(Robertson et al., 1988) Pour un ´echantillon x1, . . . , xn, et une fonction f
sur X , la r´egression isotonique de f avec les poids ωi est la solution de la
minimisation en g de
n
X
i=1
ωi(g(xi) −f(xi))2,
sous la contrainte g(x1) ≤· · · ≤g(xn).
a. Montrer que la solution `a ce probl`eme est obtenue par l’algorithme d’agr´egation
des mauvais classements :
Algorithme 1.1. Si f n’est pas isotonique,
(i) trouver i tel que f(xi−1) > f(xi) ;
(ii) remplacer f(xi−1) et f(xi) par
f ∗(xi) = f ∗(xi−1) = ωif(xi) + ωi−1f(xi−1)
ωi + ωi−1
,

40
1 Introduction
et r´ep´eter (i)-(ii) jusqu’`a ce que la contrainte soit satisfaite.
Prendre g = f ∗.
b. Appliquer au cas n = 4, f(x1) = 23, f(x2) = 27, f(x3) = 25, f(x4) = 28,
avec des poids tous ´egaux.
1.30
∗(Suite de l’Exercice 1.29) Le classement par arbre simple est obtenu en
comparant les eﬀets d’un traitement `a un ´etat test. La r´egression isotonique est
alors obtenue sous la contrainte g(xi) ≥g(x1) pour i = 2, . . . , n.
a. Montrer que l’algorithme suivant fournit la r´egression isotonique g∗:
Algorithme 1.2. Si f n’est pas isotonique,
(i) classer les f(xi) par ordre croissant (i ≥2) ;
(ii) trouver le plus petit j tel que
Aj = ω1f(x1) + . . . + ωjf(xj)
ω1 + . . . ωj
< f(xj+1)
(iii) poser g∗(x1) = Aj = g∗(x2) = . . . = g∗(xj), g∗(xj+1) = f(xj+1), . . ..
b. Appliquer au cas n = 5, f(x1) = 18, f(x2) = 17, f(x3) = 12, f(x4) = 21 et
f(x5) = 16, avec ω1 = ω2 = ω5 = 1 et ω3 = ω4 = 3.
1.31 (Olkin et al., 1981) Soient n observations x1, . . . , xn de B(k, p), k et p ´etant
inconnus.
a. Montrer que l’estimateur du maximum de vraisemblance de k, ˆk, est tel que
(ˆk(1 −ˆp))n ≥
n
Y
i=1
(ˆk −xi)
et
((ˆk + 1)(1 −ˆp))n <
n
Y
i=1
(ˆk + 1 −xi),
o`u ˆp est l’estimateur du maximum de vraisemblance de p.
b. Si l’´echantillon est 16, 18, 22, 25, 27, montrer que ˆk = 99.
c. Si l’´echantillon est 16, 18, 22, 25, 28, montrer que ˆk = 190 et conclure sur la
stabilit´e de l’estimateur du maximum de vraisemblance.
1.32 Donner l’estimateur du maximum de vraisemblance de p pour l’Exemple 1.6
lorsque les autres param`etres sont connus et deux observations sont disponibles.
Comparer avec la moyenne a posteriori lorsque p ∼U[0,1].
1.33 (Basu, 1988) Une urne contient 1 000 tickets ; 20 sont marqu´es θ et 980 sont
marqu´es 10θ. Un ticket est tir´e au hasard, et est marqu´e x.
a. Donner l’estimateur du maximum de vraisemblance de θ, δ(x), et montrer
que P(δ(x) = θ) = 0.98.
b. Supposons maintenant que 20 tickets soient marqu´es θ et 980 soient marqu´es
aiθ (i ≤980), avec ai ∈[10, 10.1] et ai ̸= aj (i ̸= j). Donner le nouvel esti-
mateur du maximum de vraisemblance, δ′, et montrer que P(δ′(x) < 10θ) =
0.02. Conclure sur l’attrait de l’estimateur du maximum de vraisemblance
dans ce cas.
1.34 (Romano et Siegel, 1986) Pour
f(x) = 1
x exp
"
−50
„ 1
x −1
«2#
(x > 0) ,

1.7 Exercices
41
montrer que f est int´egrable et qu’il existe a, b > 0 tels que
Z b
0
af(x)dx = 1
et
Z b
1
af(x)dx = 0.99.
Pour la distribution de densit´e
p(y|θ) = aθ−1f(yθ−1)I[0,bθ](y),
donner l’estimateur du maximum de vraisemblance, δ(y), et montrer que
P(δ(y) > 10θ) = 0.99.
1.35 (Romano et Siegel, 1986) Soient x1, x2, x3 i.i.d. N(θ, σ2).
a. Donner l’estimateur du maximum de vraisemblance de σ2 pour (x1, x2, x3) =
(9, 10, 11) et pour (x1, x2, x3) = (29, 30, 31).
b. Pour trois observations suppl´ementaires x4, x5, x6, donner l’estimateur du
maximum de vraisemblance lorsque (x1, . . . , x6) = (9, 10, 11, 29, 30, 31). Ce
r´esultat contredit-il le principe de vraisemblance ?
Section 1.4
1.36 Si x ∼N (θ, σ2), y ∼N (ϱx, σ2), comme dans un mod`ele autor´egressif, avec
ϱ connu, et π(θ, σ2) = 1/σ2, calculer la distribution pr´edictive de y sachant x.
1.37 Si y ∼B(n, θ), x ∼B(m, θ), et θ ∼Be(α, β), donner la distribution pr´edictive
de y sachant x.
1.38 Pour une distribution a priori propre π(θ) et une distribution d’´echantillon-
nage f(x|θ), montrer que π(θ|x) et π(θ) sont identiques si et seulement si f(x|θ)
ne d´epend pas de θ.
1.39 Consid´erons une distribution a priori π positive sur Θ et x ∼f(x|θ). Supposons
que la vraisemblance ℓ(θ|x) est born´ee, continue et admet un maximum unique
ˆθ(x).
a. Montrer que, pour un ´echantillon artiﬁciel xn = (x, . . . , x) fait de n r´eplica-
tions de l’observation initiale x, la distribution a posteriori π(θ|xn) converge
vers une masse de Dirac en ˆθ(x).
b. Construire un algorithme bay´esien pour calculer les estimateurs du maximum
de vraisemblance.
1.40
⋆Pour un couple (x, y) de variables al´eatoires, les distributions marginales
f(x) et f(y) ne suﬃsent pas `a caract´eriser la distribution jointe de (x, y).
a. Donner un exemple de deux distributions bivari´ees diﬀ´erentes admettant
les mˆemes distributions marginales. (Indication : Prendre des distributions
uniformes U ([0, 1]) pour les marginales et trouver une fonction de [0, 1]2 dans
[0, 1]2 croissante dans les deux dimensions.)
b. Montrer que, `a l’inverse, lorsque les deux distributions conditionnelles f(x|y)
et f(y|x) sont connues, la distribution du couple (x, y) est d´eﬁnie de mani`ere
unique.
c. ´Etendre b. `a un vecteur (x1, . . . , xn) tel que les conditionnelles compl`etes
fi(xi|xj, j ̸= i) soient connues. [Note : Ce r´esultat est le th´eor`eme de Ham-
mersley-Clifford, voir Robert et Casella, 2004.]
d. Montrer que la propri´et´e b. n’est pas forc´ement v´eriﬁ´ee lorsque f(x|y) et
f(x) sont connus, donc que plusieurs distributions f(y) peuvent relier f(x)
et f(x|y). (Indication : Trouver un contre-exemple.)

42
1 Introduction
e. Donner des conditions suﬃsantes sur f(x|y) pour que la propri´et´e ci-dessus
soit vraie. (Indication : Relier ce probl`eme `a la th´eorie des statistiques
compl`etes.)
1.41 Soient x1, . . . , xn i.i.d. P(λ). Montrer que Pn
i=1 xi est une statistique exhaus-
tive et donner une r´egion de conﬁance comme dans l’Exemple 1.24 lorsque π(λ)
est une distribution G (α, β). Pour un seuil α donn´e, comparer sa longueur avec
une r´egion de conﬁance sym´etrique.
1.42 Donner les distributions marginales et a posteriori dans les cas suivants :
(i)
x|σ ∼N(0, σ2),
1/σ2 ∼G (1, 2) ;
(ii)
x|λ ∼P(λ),
λ ∼G (2, 1) ;
(iii)
x|p ∼Neg(10, p),
p ∼Be(1/2, 1/2).
1.43 Montrer que, pour un ´echantillon x1, . . . , xn d’une distribution de densit´e
conditionnelle f(xi|θ, xi−1), la d´ecomposition d’actualisation (1.13) s’applique
aussi. [Note : La suite xi est alors une chaˆıne de Markov.]
1.44 Montrer que, dans le cadre de l’Exemple 1.22, la distribution a posteriori mar-
ginale de ξ2 est diﬀ´erente de la distribution a priori marginale lorsque π(ξ1, ξ2)
ne se factorise pas en π1(ξ1)π2(ξ2).
1.45
⋆(Dette et Studden, 1997) Dans le cadre de l’Exemple 1.23, nous d´eﬁnissons les
moments canoniques d’une distribution et montrons qu’ils peuvent ˆetre utilis´es
comme une repr´esentation de cette distribution.
a. Montrer que les deux premiers moments c1 et c2 sont reli´es par les in´egalit´es
suivantes :
c2
1 ≤c2 ≤c1
et que la suite (ck) est monotone d´ecroissante vers 0.
b. Soit un polynˆome de degr´e k
Pk(x) =
k
X
i=0
aixi.
D´eduire de
Z 1
0
P 2
k (x)g(x)dx ≥0
(1.14)
que
atCka ≥0,
∀a ∈Rk+1,
(1.15)
o`u
Ck =
0
B
B
@
1
c1
c2 . . .
ck
c1
c2
c3 . . . ck+1
. . . . . . . . . . . . . . .
ck ck+1
. . . c2k
1
C
C
A
et at = (a0, a1, . . . , ak).
c. Montrer que pour toute distribution g, les moments ck satisfont
˛˛˛˛˛˛˛˛
1
c1
c2 . . .
ck
c1
c2
c3 . . . ck+1
. . . . . . . . . . . . . . .
ck ck+1
. . . c2k
˛˛˛˛˛˛˛˛
> 0.
(1.16)
(Indication : Interpr´eter (1.15) comme une propri´et´e de Ck.)

1.7 Exercices
43
d. En utilisant des in´egalit´es semblables `a (1.14) pour les polynˆomes t(1 −
t)P 2
k (t), tP 2
k (t), et (1−t)P 2
k (t), prouver les in´egalit´es suivantes sur les moments
de g :
˛˛˛˛˛˛˛˛
c1 −c2
c2 −c3 . . . ck−1 −ck
c2 −c3
c3 −c4 . . . ck −ck+1
. . .
. . .
. . .
. . .
ck−1 −ck
. . .
. . . c2k−1 −c2k
˛˛˛˛˛˛˛˛
> 0,
(1.17)
˛˛˛˛˛˛˛˛
c1
c2
. . .
ck
c2
c3
. . . ck+1
. . . . . . . . .
. . .
ck ck+1 . . . c2k−1
˛˛˛˛˛˛˛˛
> 0,
(1.18)
˛˛˛˛˛˛˛˛
1 −c1
c1 −c2 . . .
ck−1 −ck
c1 −c2
c2 −c3 . . .
ck −ck+1
. . .
. . .
. . .
. . .
ck−1 −ck
. . .
. . . c2k−2 −c2k−1
˛˛˛˛˛˛˛˛
> 0.
(1.19)
e. Montrer que (1.16) (resp. (1.17)) permet de majorer (resp. de minorer) par
c2k (resp. ¯c2k) c2k et que (1.18) (resp. (1.19)) permet de majorer (resp. de
minorer) par c2k−1 (resp. ¯c2k−1) c2k−1.
f. D´eﬁnissant pk par
pk = ck −ck
¯ck −ck
,
montrer que la relation entre (p1, ..., pn) et (c1, ..., cn) est bijective pour tout
n et que les pi sont ind´ependants.
g. Montrer que la transformation inverse est donn´ee par les formules r´ecursives
suivantes. Soit
qi = 1 −pi,
ζ1 = p1,
ζi = piqi−1
(i ≥2).
Alors
8
>
<
>
:
S1,k = ζ1 + . . . + ζk
(k ≥1),
Sj,k = Pk−j+1
i=1
ζiSj−1,i+j−1
(j ≥2),
cn = Sn,n.
Section 1.5
1.46 La diﬃcult´e avec les lois a priori impropres, `a savoir la non-existence ´eventuelle
de l’int´egrale
R
Θ f(x|θ)π(θ) dθ, ne concerne pas les a priori propres.
a. Rappeler le th´eor`eme de Fubini et l’appliquer au couple de fonctions (f(x|θ),
π(θ)).
b. En d´eduire que, si π est une mesure positive ﬁnie,
Z
Θ
f(x|θ)π(θ) dθ < ∞
(1.20)
presque partout.
c. Montrer que, si π est impropre et f(x|θ) a un support ﬁni, alors π(θ|x) est
d´eﬁni si et seulement si (1.20) est ﬁni pour tout x dans le support de f(x|θ).
1.47 Montrer que, si π est une mesure positive sur Θ, l’int´egrale (1.20) est positive
presque partout.

44
1 Introduction
1.48 (Fernandez et Steel, 1999) Soient n observations i.i.d. x1, . . . , xn d’un m´elange
pN (μ0, σ2
0) + (1 −p)N (μ0, σ2
1) ,
o`u p, μ0 et σ0 sont connues. L’a priori sur σ1 est une distribution bˆeta Be(α, β).
Montrer que, si r ≥1 observations sont ´egales `a μ0, la distribution a posteriori
n’est d´eﬁnie que pour α > r. [Note : D’un point de vue de th´eorie de la mesure,
l’ensemble des xi ´egaux `a μ0 est de mesure nulle. Si une ou plusieurs observations
valent exactement μ0, cela signiﬁe que ce mod`ele de m´elange continu n’est pas
appropri´e.]
1.49 (Suite de l’Exercice 1.48)
Soit une observation x d’une loi normale
N (0, σ2).
a. Si la loi a priori sur σ est une distribution exponentielle E xp(λ), montrer
que la loi a posteriori n’est pas d´eﬁnie pour x = 0.
b. Si la loi a priori sur σ est la distribution impropre π(σ) = σ−1 exp(−ασ−2),
avec α > 0, montrer que la loi a posteriori est toujours d´eﬁnie.
1.50 (Suite de l’Exercice 1.49) Soit une observation y telle que y = x −λ, o`u
x suit la distribution de Laplace ,
f(x|θ) = θ−1 exp(−|x|/θ) ,
et λ est distribu´e selon
π(λ) = |λ|−1/2I[−1/2,1/2](λ) .
Si θ suit une loi gamma G (1/2, a) (a > 0), montrer que, si y = 0, la distribution
a posteriori n’est pas d´eﬁnie.
1.51 (Musio et Racugno, 1999) Soit le mod`ele de Poisson P(θ)
Pθ(X = x) = θx
x! e−θ,
x = 0, 1, . . . ,
θ > 0,
et la distribution a priori π(θ) = 1/θ. Montrer que pour x = 0, la distribution a
posteriori n’est pas d´eﬁnie.
1.52 (Raiﬀa et Schlaifer, 1961) Soit une loi a priori Be(αm, (1−m)α) sur p ∈[0, 1].
Montrer que, si m est ﬁxe et α tend vers 0, la loi a priori converge vers une
distribution concentr´ee en deux points, de poids m pour p = 1 et (1 −m) pour
p = 0. Commenter les inconv´enients d’une telle approche.
1.53 (Bauwens, 1991) Soient x1, . . . , xn i.i.d. N (θ, σ2) et
π(θ, σ2) = σ−2(α+1) exp(−s2
0/2σ2).
a. Calculer la distribution a posteriori π(θ, σ2|x1, . . . , xn) et montrer qu’elle ne
d´epend que de ¯x et s2 = Pn
i=1(xi −¯x)2.
b. Calculer l’esp´erance a posteriori Eπ[θ|x1, . . . , xn] et montrer que son compor-
tement lorsque α et s0 convergent simultan´ement vers 0 d´epend de la limite
du rapport s2
0/α −1.
1.54 Montrer que si l’a priori π(θ) est impropre et l’espace d’´echantillonnage X est
ﬁni, la distribution a posteriori π(θ|x) n’est pas d´eﬁnie pour certaines valeurs
de x.

1.7 Exercices
45
1.55 Soient x1, . . . , xn distribu´es selon N (θj, 1), avec θj ∼N (μ, σ2) (1 ≤j ≤n)
et π(μ, σ2) = σ−2. Montrer que la distribution a posteriori π(μ, σ2|x1, . . . , xn)
n’est pas d´eﬁnie.
1.56 Dans le cadre de l’Exemple 1.6, c’est-`a-dire pour un m´elange de distributions
normales,
a. Montrer que l’estimateur du maximum de vraisemblance n’est pas d´eﬁni
quand tous les param`etres sont inconnus.
b. De mˆeme, montrer qu’il n’est pas possible d’utiliser un a priori impropre de
la forme
π1(μ1, σ1)π2(μ2, σ2)π3(p)
pour estimer ces param`etres. (Indication : ´Ecrire la vraisemblance comme une
somme de n + 1 termes, d´ependant du nombre d’observations allou´ees `a la
premi`ere composante.)
[Note : Mengersen et Robert, 1996, montrent qu’il est possible d’utiliser cer-
taines lois a priori impropres en introduisant une d´ependance a priori entre les
composantes.]
1.57
∗(Suite de l’Exercice 1.56 ) Pour un m´elange de deux distributions nor-
males (1.2), si la distribution a priori sur les param`etres est de la forme
π1(μ1, σ1)π1(μ2, σ2)π3(p)
et π3(p) = π3(1 −p), montrer que la distribution a posteriori marginale de
(μ1, σ1) est identique `a la distribution a posteriori marginale de (μ2, σ2), quel
que soit l’´echantillon des observations. En d´eduire que l’esp´erance a posteriori
de (μ1, σ1) est ´egale `a l’esp´erance a posteriori de (μ2, σ2) et que ce n’est donc
pas un estimateur pertinent. [Note : Ce probl`eme est une cons´equence de la non-
identiﬁabilit´e des indices des composants dans un m´elange. Il peut ˆetre r´esolu
par des contraintes d’identiﬁcation, comme l’ordonnancement μ1 ≤μ2, ou par
l’utilisation de fonctions de perte invariantes par permutation des indices de
composantes. Voir Celeux et al., 2000.]
1.58 Construire un argument limite comme dans l’Exemple 1.27 aﬁn de r´esoudre
l’ind´etermination de l’Exemple 1.28. Calculer l’esp´erance a posteriori.
1.59 Montrer que, si la distribution a priori est impropre, la pseudo-distribution
marginale est aussi impropre.
1.60
∗(Hobert et Casella, 1998) Soit un mod`ele `a eﬀets al´eatoires.
yij = β + ui + εij,
i = 1, . . . , I, j = 1, . . . , J,
o`u ui ∼N (0, σ2) et εij ∼N (0, τ 2). Pour l’a priori
π(β, σ2, τ 2) =
1
σ2τ 2 ,
l’a posteriori n’existe pas.
a. En int´egrant sur les eﬀets al´eatoires (non observables) ui, montrer que la
distribution a posteriori jointe de (β, σ2, τ 2) est
π(β, σ2, τ 2|y) ∝σ−2−I τ −2−IJ exp
n
−
1
2τ2
P
i,j (yij −¯yi)2o
× exp
n
−
J P
i(¯yi−β)2
2(τ2+Jσ2)
o
(Jτ −2 + σ−2)−I/2 .

46
1 Introduction
b. Int´egrer sur β pour obtenir la densit´e marginale a posteriori
π(σ2, τ 2|y) ∝
σ−2−I τ −2−IJ
(Jτ −2 + σ−2)I/2 (τ 2 + Jσ2)1/2
× exp
(
−1
2τ 2
X
i,j
(yij −¯yi)2 −
J
2(τ 2 + Jσ2)
X
i
(¯yi −¯y)2
)
.
c. Montrer que la densit´e a posteriori jointe n’est pas int´egrable. (Indication :
Pour τ ̸= 0, π(σ2, τ 2|y) se comporte comme σ−2 au voisinage de 0.)
d. Montrer que les distributions conditionnelles
Ui|y, β, σ2, τ 2 ∼N
„ J(¯yi −β)
J + τ 2σ−2 , (Jτ −2 + σ−2)−1
«
,
β|u, y, σ2, τ 2 ∼N (¯y −¯u, τ 2/JI) ,
σ2|u, β, y, τ 2 ∼IG
 
I/2, (1/2)
X
i
u2
i
!
,
τ 2|u, β, y, σ2 ∼IG
 
IJ/2, (1/2)
X
i,j
(yij −ui −β)2
!
,
sont bien d´eﬁnies. [Note : Les cons´equences de cette d´eﬁnition de la densit´e
a posteriori jointe seront clariﬁ´ees dans le Chapitre 6.]
1.61
∗Soit un mod`ele probit dichotomique, o`u (1 ≤i ≤n)
P(di = 1) = 1 −P(di = 0) = P(zi ≥0) ,
(1.21)
avec zi ∼N(riβ, σ2), β ∈R, ri ´etant une variable explicative. (Noter que les zi
ne sont pas observ´es.)
a. Montrer que le param`etre (β, σ) n’est pas identiﬁable.
b. Pour la distribution a priori π(β, σ) = 1/σ, montrer que la distribution a
posteriori n’est pas d´eﬁnie.
c. Pour la distribution a priori
σ−2 ∼Ga(1.5, 1.5) ,
β|σ ∼N(0, 102) ,
montrer que la distribution a posteriori est bien d´eﬁnie.
d. Une contrainte d’identiﬁcation possible est σ = 1. Donner des conditions
suﬃsantes sur les observations (di, ri) pour que la distribution a posteriori
sur β soit d´eﬁnie si π(β) = 1.
e. Mˆeme question que d. lorsque la distribution normale sur les zi est remplac´ee
par la fonction logistique, c’est-`a-dire
P(di = 1) = 1 −P(di = 0) =
exp(riβ)
1 + exp(riβ) ,
ce qui donne le mod`ele logit dichotomique.

1.7 Exercices
47
1.62
∗(Kubokawa et Robert, 1994) Dans les mod`eles de calibration lin´eaire, on
s’int´eresse `a la d´etermination des valeurs du r´egresseur x, partant des valeurs ob-
serv´ees y, `a l’inverse de la r´egression lin´eaire standard. Une version simpliﬁ´ee de
ce probl`eme peut s’inscrire dans le cadre de l’observation de variables al´eatoires
ind´ependantes
y ∼Np(β, σ2Ip), z ∼Np(x0β, σ2Ip), s ∼σ2χ2
q ,
(1.22)
avec x0 ∈R, β ∈Rp. Le param`etre d’int´erˆet est x0.
a. Une distribution a priori de r´ef´erence sur (x0, β, σ) donne la distribution a
posteriori jointe
π(x0, β, σ2|y, z, s) ∝σ−(3p+q)−1
2 exp{−(s + ∥y −β∥2
+∥z −x0β∥2)/2σ2} (1 + x2
0)−1/2 .
Montrer que cet a posteriori est compatible avec la distribution d’´echantil-
lonnage (1.22).
b. Montrer que la distribution marginale a posteriori de x0 est
π(x0|y, z, s) ∝
(1 + x2
0)(p+q−1)/2
(„
x0 −
ytz
s + ∥y∥2
«2
+ ∥z∥2 + s
∥y∥2 + s −
(ytz)2
(s + ∥y∥2)2
)(2p+q)/2 .
c. En d´eduire que la distribution a posteriori de x0 est bien d´eﬁnie.
[Note : Voir Osborne, 1991, pour une introduction aux probl`emes de calibra-
tion. Le mod`ele (1.22) est aussi ´equivalent au probl`eme de Fieller, 1954. Voir,
notamment, Lehmann et Casella, 1998.]
Note 1.8.2
1.63
∗(Diaconis et Kemperman, 1996) Montrer que la d´eﬁnition du processus de
Dirichlet D(F0, α) donn´ee en Section 1.8.2 est compatible avec la d´eﬁnition
suivante : pour une suite de xi i.i.d. tir´es de F0 et une suite de poids ωi telles
que
ω1 ∼Be(1, α),
ω1 + ω2 ∼Be(1, α)I[ω1,1], . . .
la distribution al´eatoire
F =
∞
X
i=1
ωiδxi
suit D(F0, α).
1.64
∗(Suite de l’Exercice 1.63) Si F ∼D(F0, α), la quantit´e X =
R
xF(dx)
est une variable al´eatoire.
a. Si α = 1 et F0 est une distribution de Cauchy, montrer que X suit aussi une
distribution de Cauchy. [Note : Ceci est reli´e `a la propri´et´e caract´eristique
des distributions de Cauchy, qui est que la moyenne de variables al´eatoires
de Cauchy est aussi une variable de Cauchy, avec les mˆemes param`etres.]
b. Si α = 1 et F0 = ϱδ0+(1−ϱ)δ1, montrer que X suit une loi bˆeta Be(ϱ, 1−ϱ).

48
1 Introduction
c. Montrer que, si α = 1 et F0 est U[0,1], X a pour densit´e
e
π
sin(πy)
(1 −y)(1−y)yy .
[Note : Voir Diaconis et Kemperman, 1996 pour une formule g´en´erale reliant F0
`a la densit´e de X.]
1.65
∗(Diaconis et Kemperman, 1996) Le processus a priori de Dirichlet D(F0, α)
peut aussi se d´ecrire via le processus dit du restaurant chinois. Soit un restaurant
ayant beaucoup de grandes tables et assignons `a chaque table j une r´ealisation
yj de F0. Puis traitons les arriv´ees comme suit : la premi`ere personne qui arrive
s’assoit `a la premi`ere table. La (n + 1)-i`eme personne s’assoit `a une nouvelle
table avec probabilit´e α/(α + n), ou `a la droite d’une personne d´ej`a assise avec
probabilit´e n/(α + n).
a. Si xi est le num´ero zj de la table `a laquelle la personne i est assise, montrer
que la suite x1, x2, . . . est ´echangeable (c’est-`a-dire que la distribution est
invariante sous toute permutation d’indices).
b. Montrer que x1, x2, . . . peut ˆetre consid´er´ee comme une suite de r´eplications
i.i.d. tir´ees de F, o`u F est distribu´ee selon D(F0, α), en utilisant la distri-
bution conditionnelle donn´ee en Note 1.8.2.
c. Montrer que cette d´eﬁnition est aussi compatible avec celle de l’Exercice
1.63.
Note 1.8.3
1.66
∗(Hadjicostas et Berry, 1999) Soient des observations ind´ependantes xi (i =
1, . . . , n) de distributions de Poisson P(λiti), o`u les dur´ees ti sont connues.
Les λi suivent ind´ependamment la distribution a priori gamma G (α, β). Ce
mod`ele est hi´erarchique, car on suppose que les param`etres (α, β) suivent une
distribution a priori π(α, β) telle que
π(α, β) ∝αk1(α + s1)k2βk3(β + s2)k4 ,
(1.23)
o`u les valeurs ki sont sj > 0 connues (i = 1, . . . , 4, j = 1, 2).
a. Montrer que la distribution a priori (1.23) est propre, si et seulement si,
k1 + k2 + 1 < 0,
k1 + 1 > 0,
k3 + k4 + 1 < 0,
et
k3 + 1 > 0.
b. En int´egrant sur les λi la distribution jointe des λi’s et de (α, β), calculer
la distribution (marginale) a posteriori de (α, β).
c. Montrer que la distribution (marginale) a posteriori de (α, β) est d´eﬁnie
(propre) si et seulement si
k1 + y + 1 > 0,
k3 + r + 1 > 0,
k3 > k1 + k2
et, de plus, soit k3 + k4 + 1 < 0, soit k3 + k4 + 1 = 0 et k1 + y > 0, avec
y =
n
X
i=1
I0(xi),
r =
n
X
i=1
xi .

1.7 Exercices
49
d. V´eriﬁer que les conditions de a. impliquent les conditions de b. (comme
convenu).
e. Montrer que les conditions de b. sont satisfaites lorsque (k1, . . . , k4) =
(−8, 0, −5, 0) et (y, r) = (10, 337), et que les conditions de a. ne le sont
pas dans ce cas.
f. Montrer que les conditions de b. ne sont pas satisfaites lorsque (k1, . . . , k4) =
(−12, 0, 1, 1) et (y, r) = (10, 337).
Note 1.8.4
1.67
∗(Robins et Ritov, 1997) Soient des observations i.i.d. (xi, yi) dans (0, 1)k ×R
tir´ees du mod`ele suivant : x ∼f(x), y|x ∼N (θ(x), 1), o`u la fonction moyenne θ
est born´ee uniform´ement sur (0, 1)k et la densit´e f est telle que c < f(x) < 1/c
uniform´ement sur (0, 1)k, o`u c < 1 est une constante ﬁx´ee. Supposons que la
quantit´e d’int´erˆet est
ϕ =
Z
(0,1)k θ(x)dx .
a. Montrer que l’espace Θ des fonctions moyennes θ est de dimension inﬁnie.
b. Donner la vraisemblance ℓ(θ, f) et montrer qu’elle se factorise en une fonc-
tion de f multipli´ee par une fonction de θ.
c. Lorsque f est connue, montrer que (x1, . . . , xn) est une statistique libre.
d. Lorsque f est inconnue, montrer que (x1, . . . , xn) est θ-libre, au sens o`u la
vraisemblance conditionnelle en (x1, . . . , xn) est fonction de θ uniquement,
la distribution marginale de (x1, . . . , xn) est fonction de f uniquement, et
l’espace des param`etres est un espace produit. (Voir Cox et Hinkley, 1987,
et Robins et Wasserman, 2000, pour plus de d´etails sur cette notion.)
e. Lorsque f est connue, montrer que
1
n
n
X
i=1
yi
f(xi)
est un estimateur convergent de ϕ. (En fait, il s’agit d’un estimateur uni-
form´ement convergent en √n.)
f. Lorsque f est inconnue, Robins et Ritov (1997) ont d´emontr´e qu’il n’existe
pas d’estimateur uniform´ement convergent de ϕ. En d´eduire que, si la
distribution a posteriori sur (θ, f) se factorise en π1(θ)π2(f), l’inf´erence
bay´esienne sur θ (et donc sur ϕ) est la mˆeme quelle que soit la valeur de f.
g. Au contraire, si la distribution a priori sur (θ, f) rend θ et f d´ependants,
et si f est connue et vaut f0, la distribution a posteriori d´epend de f0. En
d´eduire que cette d´ependance viole le principe de vraisemblance.
[Note : La description simpliﬁ´ee ci-dessus de Robins et Ritov, 1997, est tir´ee de
Robins et Wasserman, 2000.]

50
1 Introduction
1.8 Notes
1.8.1 Une br`eve histoire de la Statistique bay´esienne
Diﬀ´erents livres ont ´et´e ´ecrits sur l’histoire de la Statistique bay´esienne, notam-
ment Stigler (1986), Dale (1991), Lad (1996) et Hald (1998). Nous ne faisons ici
que souligner quelques points forts du d´eveloppement de cette discipline durant
les deux cents derni`eres ann´ees.
Comme nous le d´etaillons dans ce chapitre, la formule de Bayes est apparue pour
la premi`ere fois en 1761, dans le cadre de l’exemple binomial de la Section 1.2,
expos´e par le r´ev´erend Thomas Bayes devant la “Royal Society”, et publi´e de
fa¸con posthume par son ami R. Price en 1763. Pierre Simon Laplace red´ecouvrit
ensuite cette formule dans une plus grande g´en´eralit´e en 1773, sans, semble-t-il,
avoir connaissance des travaux pr´ec´edents de Bayes. L’utilisation du principe
bay´esien devint alors courant pendant le si`ecle suivant, comme le rapporte Sti-
gler (1986), mais des critiques commenc`erent `a ´emerger vers la ﬁn du XIX`eme
si`ecle, comme par exemple dans Venn (1886) ou Bertrand (1889), en particulier
sur le choix de la loi a priori uniforme et des paradoxes de reparam´etrisation
qui en r´esultent, voir Zabell (1989).
Puis, malgr´e des formalisations plus pouss´ees du paradigme bay´esien par Edge-
worth et (Karl) Pearson au tournant du si`ecle et, plus tard, par Keynes (1921),
le d´ebut du XX`eme si`ecle fut surtout marqu´e par, tout d’abord, Kolmogorov, qui
proposa dans les ann´ees 1920 une axiomatisation de la th´eorie des probabilit´es
semblant contredire le paradigme bay´esien et la notion de probabilit´e subjec-
tive, ensuite par Fisher qui s’´eloigna de l’approche bay´esienne (Fisher, 1912) en
d´eﬁnissant la fonction de vraisemblance (Fisher, 1922), puis en d´eveloppant la
Statistique ﬁduciaire (Fisher, 1930), et qui ne r´evisa jamais son opinion n´egative
sur la Statistique bay´esienne. Cette opposition paraˆıt quelque peu paradoxale,
car la Statistique ﬁduciaire tentait, en un certain sens, de surmonter la diﬃ-
cult´e de choisir une loi a priori en la construisant `a partir de la fonction de
vraisemblance (Seidenfeld, 1992), dans le mˆeme esprit que les approches non
informatives de Jeﬀreys (1939) et Bernardo (1979).
Par exemple, consid´erant la relation O = P + ϵ o`u ϵ est un terme d’erreur,
la Statistique ﬁduciaire tient que, si P (la cause) est connu, O (l’eﬀet) suit
la loi d´eﬁnie par la relation ci-dessus. R´eciproquement, si O est connu, P =
O −ϵ est distribu´ee selon la distribution sym´etrique. De ce point de vue, les
observations et les param`etres jouent un rˆole sym´etrique, selon la fa¸con dont on
analyse le mod`ele, c’est-`a-dire suivant ce qui est connu et ce qui ne l’est pas.
Plus g´en´eralement, l’approche ﬁduciaire consiste `a renormaliser la vraisemblance
(1.3) aﬁn de la transformer en densit´e de θ lorsque
Z
Θ
ℓ(θ|x) dθ < +∞,
donc en inversant eﬀectivement les rˆoles de x et θ. Comme on peut le voir dans
l’exemple pr´ec´edent, le raisonnement sous-tendant cette inversion causale est
compl`etement conditionnel : sachant P, on a O = P +ϵ, et, sachant O, P = O−ϵ.
Bien entendu, ce raisonnement ne tient pas d’un point de vue probabiliste : si
O est une variable al´eatoire et P est un param`etre (constant), ´ecrire P = O −ϵ

1.8 Notes
51
n’implique pas que P soit une variable al´eatoire. De plus, transformer ℓ(θ|x) en
une densit´e n’est pas toujours possible. L’approche ﬁduciaire a ´et´e abandonn´ee
progressivement apr`es la mise en ´evidence de paradoxes fondamentaux (voir
Stein, 1959, Wilkinson, 1977, et les r´ef´erences dans Zabell, 1992).
Le livre de Jeﬀreys (1939) est le premier trait´e moderne de Statistique bay´e-
sienne : il couvre, en plus de la notion d’a priori non informatif, celles de loi
pr´edictive, de facteur de Bayes et d’a priori impropre. Mais cet ouvrage publi´e
au moment du d´eveloppement par Fisher de la Statistique de la vraisemblance
et des intervalles de conﬁance par Neyman (1934), ne rencontra pas le mˆeme
succ`es. Les approches alternatives `a la Statistique bay´esienne devinrent alors
standard dans les ann´ees 1930, avec l’introduction des estimateurs du maximum
de vraisemblance et le d´eveloppement d’une th´eorie formalis´ee de la Statistique
math´ematique, pour laquelle les lois a priori n’apparaissaient au mieux que
comme une fa¸con de construire des estimateurs optimaux, voir Wald (1950) ou
Ibragimov et Has’minskii (Ibragimov et Has’minskii, 1981, Chapitre 6).
Les tentatives d’une formalisation plus pouss´ee de l’approche bay´esienne par
Gini ou de Finetti, des ann´ees 1930 aux ann´ees 1970, ne se traduisirent pas
par une plus grande popularit´e face `a la th´eorie alors dominante de Neyman-
Pearson, mˆeme si la communaut´e bay´esienne s’accroissait et produisait des
trait´es tels que ceux de Savage (1954) et de Lindley (1965, 1971).
On peut avancer que ce n’est que tr`es r´ecemment que la Statistique bay´esienne
a pris un nouvel ´elan, grˆace au d´eveloppement de nouveaux outils num´eriques–
qui ont toujours jou´e un rˆole central pour le paradigme bay´esien–et l’int´erˆet
vite croissant des praticiens pour cette approche de mod´elisation statistique,
comme soulign´e dans l’article de Berger (2000) sur l’´etat pr´esent et futur de la
Statistique bay´esienne18.
La vitalit´e actuelle de la Statistique bay´esienne peut ˆetre mise en ´evidence par
le pourcentage ´elev´e d’articles bay´esiens publi´es dans les revues statistiques ou
concernant d’autres domaines scientiﬁques. Il semble donc que les praticiens de
ce si`ecle prendront mieux en compte les avantages de la Statistique bay´esienne
que leurs pr´ed´ecesseurs du XX`eme si`ecle.
1.8.2 Statistique bay´esienne non param´etrique
Bien que ce livre se cantonne `a l’approche param´etrique de la Statistique, il
existe une litt´erature (de plus en plus) importante sur la Statistique bay´esienne
non param´etrique. Premi`erement, les notions d’optimalit´e comme la minimaxit´e
jouent un rˆole central en estimation fonctionnelle ; de la mˆeme fa¸con que dans
le cadre param´etrique (voir le Chapitre 3), les estimateurs de Bayes peuvent
ˆetre utilis´es pour la d´etermination de bornes de minimaxit´e et d’estimateurs
minimax.
Deuxi`emement, et d’un point de vue nettement moins formel, il est parfois
n´ecessaire de concevoir une mod´elisation bay´esienne a priori dans un espace
de dimension inﬁnie. C’est bien entendu plus diﬃcile, tant pour des raisons
math´ematiques que pour des raisons de construction de l’a priori. Mais une
18On pourra aussi consulter la revue de Fienberg (2005) sur la question historique
suivante : `a partir de quelle ´epoque la m´ethodologie utilisant les principes bay´esiens
a-t-elle pris la d´enomination de “bay´esienne” ?

52
1 Introduction
premi`ere solution est de se situer dans la zone grise entre Statistique pa-
ram´etrique et non param´etrique comme dans l’Exemple 1.23 : le nombre de
param`etres est ﬁni mais croˆıt vers l’inﬁni avec le nombre d’observations. C’est
le cas notamment pour l’estimation par noyau, o`u une densit´e est approch´ee par
un m´elange
1
nσ
n
X
i=1
K
“x −xi
σ
”
,
o`u K est une densit´e, et σ peut ˆetre estim´e d’une fa¸con bay´esienne, par des
d´eveloppements d’Hermite (Hjort, 1996), ou des bases d’ondelettes (M¨uller et
Vidakovic, 1999, Chap. 1). Dans ce dernier cas, une fonction f est d´ecompos´ee
sur une base fonctionnelle,
f(x) =
X
i
X
j
ωijΨ
„x −μi
σj
«
,
o`u Ψ est une fonction particuli`ere appel´ee ondelette m`ere, comme par exemple
l’ondelette de Haar
Ψ(x) = I[0,1/2) −I[1/2,1) ,
les param`etres de position et d’´echelle μi et σj ´etant ﬁx´es et connus. Les coeﬃ-
cients ωij peuvent ˆetre associ´es `a une distribution a priori telle que (Abramovich
et al., 1998)
ωij ∼ϱiN (0, τ 2
i ) + (1 −ϱi)δ0 ,
o`u δ0 est la masse de Dirac en 0.
Une deuxi`eme solution, lorsqu’on cherche `a estimer une fonction de r´epartition
F, est d’assigner une distribution a priori `a celle-ci. Le choix le plus cou-
rant est la distribution de Dirichlet D(F0, α), F0 ´etant la moyenne a priori
et α la pr´ecision, comme introduit par Ferguson (1974). Cette loi a priori
jouit d’une propri´et´e de coh´erence, c’est-`a-dire si F ∼D(F0, α), le vecteur
(F(A1), . . . , F (Ap)) est distribu´e selon une loi de Dirichlet au sens usuel du
terme, Dp(αF0(A1), . . . , αF0(Ap)) pour toute partition (A1, . . . , Ap). Elle g´en`ere
cependant des distributions a posteriori qui sont partiellement discr`etes : si
x1, . . . , xn sont distribu´es selon F et F ∼D(F0, α), la distribution marginale de
x1 conditionnellement `a (x2, . . . , xn) est
α
α + n −1F0 +
1
α + n −1
n
X
i=2
δxi .
(Voir aussi les Exercices 1.63 et 1.65 pour d’autres caract´erisations.) L’approxi-
mation de la distribution a posteriori n´ecessite des outils num´eriques avanc´es
que nous traiterons dans le Chapitre 6. (Voir Note 6.6.7 pour plus de d´etails.)
D’autres types de distributions a priori ont ´et´e propos´es dans la litt´erature
comme les distributions g´en´eralis´ees de Dirichlet (Hjort, 1996), les arbres de
P´olya (Fabius, 1964, Lavine, 1992), les processus bˆeta (Hjort, 1996), et les pro-
cessus de L´evy (Phillips et Smith, 1996).
Pour conclure, mentionnons qu’une tendance r´ecente de la Statistique bay´esienne
est de consid´erer des mod`eles de dimension variable, comme les m´elanges, les
mod`eles de chaˆınes de Markov cach´ees et d’autres mod`eles dynamiques, ainsi que
les r´eseaux neuronaux, grˆace `a de nouveaux outils num´eriques d´evelopp´es par

1.8 Notes
53
Grenander et Miller (1994), Green (1995), Phillips et Smith (1996) ou Stephens
(1997). C’est le cas, par exemple, pour les mod`eles de m´elange,
k
X
i=1
pikϕ(x|θik)
o`u ϕ(·|θ) est une densit´e param´etrique, la somme des poids pik vaut 1 et le
nombre de composants k est inconnu. Bien qu’il s’agisse d’un probl`eme pa-
ram´etrique bien d´eﬁni, il s’approche plus des imp´eratifs non param´etriques que
de l’estimation param´etrique standard (voir Richardson et Green, 1997 ou Marin
et al., 2004).
1.8.3 Lois a posteriori propres
Nous savons depuis la Section 1.5 qu’un a priori impropre π ne peut ˆetre utilis´e
dans un but inf´erentiel que si (1.20) est v´eriﬁ´ee pour l’observation x disponible.
Si ce n’est pas le cas, les quantit´es a posteriori telles que moyenne ou m´ediane
n’ont pas de sens, puisque, par exemple, le rapport
R
Θ f(x|θ)π(θ) dθ
R
Θ θf(x|θ)π(θ) dθ
n’est pas d´eﬁni. V´eriﬁer la condition (1.20) peut se r´ev´eler relativement diﬃcile
pour des mod`eles complexes (voir les Exercices 1.60 et 1.61) ou mˆeme simple-
ment impossible. Malheureusement, l’av`enement de techniques informatiques
comme l’´echantillonnage de Gibbs (voir le Chapitre 6) autorise `a ne se tenir
qu’`a la relation π(θ|x) ∝f(x|θ)π(θ) aﬁn de simuler des valeurs de l’a poste-
riori π(θ|x) et les r´esultats de cette simulation ne mettent h´elas pas toujours en
´evidence le fait que cet a posteriori n’existe pas (voir Hobert et Casella, 1996). Il
existe eﬀectivement des exemples dans la litt´erature de donn´ees analys´ees avec
de telles lois a posteriori non d´eﬁnies, ce probl`eme n’ayant ´et´e d´ecouvert que
plusieurs ann´ees apr`es.
Nous verrons cependant dans la Note 6.6.4 qu’il existe de bonnes raisons pour
utiliser des a posteriori impropres sur des espaces ´etendus, c’est-`a-dire pour une
compl´etion de θ en (α, θ), tant que la distribution π(θ|x) reste propre.
1.8.4 Propri´et´es asymptotiques des estimateurs de Bayes
Nous ne d´eveloppons pas le point de vue asymptotique dans ce livre pour
deux raisons principales, la premi`ere ´etant que l’approche bay´esienne est in-
trins`equement conditionnelle. Lorsqu’on conditionne en x, qui peut ˆetre un
´echantillon (x1, . . . , xn), il n’y a aucune raison de se demander ce qui pour-
rait arriver si n tendait vers l’inﬁni, puisque n est d´etermin´e par la taille
de l’´echantillon. Conjecturer sur des valeurs futures des observations revient
`a mener une analyse fr´equentiste, `a l’oppos´e des imp´eratifs de la perspective
bay´esienne. La seconde raison est que, mˆeme si elles ne sont pas construites
dans ce but, les proc´edures bay´esiennes ont de bonnes performances asympto-
tiques dans une large majorit´e des cas. Il n’est pas si paradoxal que la perspective
bay´esienne, et en particulier le choix d’un a priori, cessent le plus souvent de
produire des r´esultats v´eritablement diﬀ´erents de ceux du maximum de vrai-
semblance lorsque le nombre d’observations devient inﬁniment plus grand que
le nombre de param`etres. (Ce cadre id´eal souﬀre d’exceptions bien connues,

54
1 Introduction
comme le probl`eme de Neyman-Scott de l’Exemple 3.35, voir Diaconis et Freed-
man, 1986, o`u le nombre de param`etres croˆıt avec le nombre d’observations et
donne des estimateurs de Bayes non convergents, voir aussi Robins et Ritov,
1997, et l’Exercice 1.67 qui s’y rapporte.)
Ibragimov et Has’minskii (1981, Chap. 1) d´emontrent que les estimateurs de
Bayes sont convergents dans un cadre g´en´eral, c’est-`a-dire qu’ils convergent
presque sˆurement vers la vraie valeur du param`etre lorsque le nombre d’observa-
tions tend vers l’inﬁni. C’est le cas notamment pour les estimateurs δα (α ≥1)
qui minimisent le coˆut a posteriori (voir le Chapitre 2) associ´e `a la fonction de
perte L(δ, θ) = |θ −δ|α, sous des conditions assez faibles sur la distribution a
priori π et la densit´e d’´echantillonnage f(x|θ). Ibragimov et Has’minskii (1981,
Chap. 3) ´etablissent aussi (sous des conditions plus fortes) l’eﬃcacit´e asympto-
tique de certains estimateurs de Bayes, c’est-`a-dire le fait que la distribution a
posteriori converge vers la vraie valeur `a la vitesse n−1/2 ; voir Schervish (1995)
pour plus de d´etails.
Barron et al. (1999) donnent des conditions g´en´erales pour la convergence d’une
distribution a posteriori dans le sens suivant : la probabilit´e a posteriori de tout
voisinage de Hellinger de la vraie distribution tend vers 1 presque sˆurement
lorsque la taille de l’´echantillon tend vers l’inﬁni. (La distance de Hellinger entre
deux densit´es f1 et f2 (ou les distributions correspondantes) est d´eﬁnie par
d(f1, f2) =
Z “
f1(x)1/2 −f2(x)1/2”2
dx .
Nous l’utiliserons dans le cadre de la Th´eorie de la D´ecision dans le Chapitre 2.)
L’hypoth`ese de base sur la distribution a priori π est qu’elle attribue une masse
positive `a tout voisinage de Kullback-Leibler de la vraie distribution. (Nous
utiliserons aussi la pseudo-distance de Kullback-Leibler dans le Chapitre 2.)
Nous reviendrons cependant `a l’asymptotique, dans le Chapitre 3, pour la
d´eﬁnition de lois a priori non informatives via l’approximation asymptotique
des comportements de queue et, dans le Chapitre 6, pour l’approximation de
Laplace des int´egrales de densit´es a posteriori.

2
Les bases de la Th´eorie de la D´ecision
“Today would run out according to the Pattern. But over and over
he mulled over the decisions he had made since he ﬁrst entered the
Waste. Could he have done something diﬀerent, something that would
have avoided this day, this place ? Next time, perhaps.”
Robert Jordan, The Fires of Heaven.
2.1 ´Evaluation des estimateurs
Consid´erant que l’objectif g´en´eral de la plupart des ´etudes inf´erentielles
est de fournir une d´ecision au statisticien (ou au client), il semble raison-
nable d’exiger un crit`ere d’´evaluation des proc´edures de d´ecision qui prenne
en compte les cons´equences de chaque d´ecision et d´epende des param`etres du
mod`ele, c’est-`a-dire du vrai ´etat du monde (ou de la nature). Ces d´ecisions
peuvent ˆetre de diﬀ´erents types, par exemple acheter des capitaux selon leurs
futurs rendements θ, interrompre une exp´erience agricole sur une nouvelle
culture de productivit´e θ, estimer la contribution de l’´economie souterraine
θ au PIB des ´Etats-Unis, d´eterminer si le nombre θ des sans domicile ﬁxe
a augment´e depuis le dernier recensement. Un autre type de d´ecision est
d’´evaluer si une nouvelle th´eorie scientiﬁque est compatible avec les donn´ees
exp´erimentales disponibles. Si aucun crit`ere d’´evaluation n’est disponible, il
est impossible de comparer diﬀ´erentes proc´edures d´ecisionnelles et des so-
lutions absurdes, comme l’estimateur ˆθ = 3 ou pis encore, la r´eponse que
quelqu’un veut imposer, ne peuvent ˆetre ´elimin´ees que par un raisonnement

56
2 Les bases de la Th´eorie de la D´ecision
ad hoc. ´Eviter ce type de raisonnement n´ecessite un renforcement de l’axioma-
tisation du cadre inf´erentiel statistique, appel´e Th´eorie de la D´ecision. Cette
structure th´eorique augment´ee est n´ecessaire `a la Statistique pour aboutir `a
une coh´erence autrement inatteignable19.
Bien que presque tout le monde s’accorde sur le besoin de tels crit`eres
d’´evaluation, il existe une controverse importante autour du choix de ces
crit`eres, car les cons´equences de cette d´ecision ne sont pas n´egligeables. Ces dif-
ﬁcult´es am`enent mˆeme certains statisticiens `a rejeter compl`etement la Th´eorie
de la D´ecision, en s’appuyant sur l’argument qu’une d´etermination pratique
des crit`eres d’´evaluation du d´ecideur est totalement impossible dans la plupart
des cas.
Ce crit`ere est habituellement appel´e coˆut et est d´eﬁni ci-dessous. L’en-
semble des d´ecisions possibles, D, est appel´e espace de d´ecision et la plupart
des exemples th´eoriques se concentrent sur le cas D = Θ, qui repr´esente le
cadre d’estimation standard.
D´eﬁnition 2.1. Une fonction de coˆut est une fonction L de Θ × D dans
[0, +∞).
La fonction de coˆut est cens´ee ´evaluer la p´enalit´e (ou l’erreur) L(θ, d)
associ´ee `a la d´ecision d quand le param`etre prend la valeur θ. Dans un cadre
traditionnel d’estimation du param`etre, lorsque D est Θ ou h(Θ), la fonction
de coˆut L(θ, δ) mesure l’erreur commise en ´evaluant h(θ) par δ. La Section
2.2 pr´esente un ensemble d’axiomes de rationalit´e qui garantissent l’existence
d’une telle fonction dans un cadre d´ecisionnel.
Dans la pratique, la d´etermination mˆeme de la fonction de coˆut est sou-
vent diﬃcile, en particulier parce que les cons´equences de chaque action pour
chaque valeur de θ sont souvent impossibles `a d´eterminer quand D ou Θ
sont de grands ensembles, par exemple quand ils contiennent un nombre in-
ﬁni d’´el´ements. De plus, dans les mod`eles qualitatifs, il peut ˆetre d´elicat de
quantiﬁer les cons´equences de chaque d´ecision. Nous verrons `a travers des
paradoxes comme le paradoxe de Saint-P´etersbourg que, mˆeme quand la fonc-
tion de coˆut semble ´evidente, par exemple lorsque des erreurs peuvent ˆetre
exprim´ees comme pertes mon´etaires, la fonction de coˆut r´eelle peut ˆetre assez
diﬀ´erente de son approximation lin´eaire et intuitive.
La complexit´e de la d´etermination de la fonction de coˆut subjective du
d´ecideur incite souvent le statisticien `a recourir aux fonctions de coˆut clas-
siques ou canoniques, choisies pour leur simplicit´e et leur souplesse math´e-
matique. Ce type de fonction de coˆut est aussi n´ecessaire pour un traite-
ment th´eorique de l’obtention des proc´edures optimales, quand il n’y a pas
de motivation pratique pour le choix d’une fonction de coˆut en particulier.
19L’approche bay´esienne est, de notre point de vue, l’´etape ultime de cette re-
cherche de coh´erence.

2.1 ´Evaluation des estimateurs
57
Le terme classique est li´e `a une longue histoire qui remonte jusqu’`a La-
place (1773) pour le coˆut absolu (2.4) et `a Gauss (1810) pour le coˆut qua-
dratique (2.2), `a l’´epoque o`u l’erreur en termes de performance des estima-
teurs ou de cons´equences des d´ecisions ´etait confondue avec l’erreur au sens
de l’irr´eductible variabilit´e des variables al´eatoires (variance). Mais cette ca-
ract´eristique ne devrait pas ˆetre prise comme une quelconque validation, car
une utilisation plus g´en´erale de ces coˆuts ne les l´egitime pas davantage. En
r´ealit´e, le recours `a ces coˆuts automatiques (ou g´en´eriques), bien que jus-
tiﬁ´e dans la pratique–il vaut mieux malgr´e tout, prendre une d´ecision en un
temps ﬁni en utilisant un crit`ere approximatif que de passer un temps inﬁni
`a d´eterminer exactement la fonction de coˆut correcte–a g´en´er´e une grande
partie des critiques envers la Th´eorie de la D´ecision.
Une base fondamentale de la Th´eorie de la D´ecision bay´esienne est que
l’inf´erence statistique devrait commencer par la d´etermination de trois fac-
teurs :
(1) la famille des distributions pour les observations, f(x|θ) ;
(2) la distribution a priori pour les param`etres, π(θ) ;
(3) le coˆut associ´e aux d´ecisions, L(θ, δ) ;
les distributions a priori et la fonction de coˆut, et parfois mˆeme la distribu-
tion d’´echantillonnage r´esultant de consid´erations partiellement subjectives.
Les partisans de la Th´eorie de la D´ecision classique omettent le deuxi`eme
point mais les critiques fr´equentistes du paradigme bay´esien ´echouent souvent
`a prendre en compte le probl`eme de la construction de la fonction de coˆut,
mˆeme si celle-ci est aussi compliqu´ee que l’obtention de la distribution a priori.
De plus, pr´esupposer l’existence d’une fonction de coˆut implique qu’une cer-
taine information sur le probl`eme consid´er´e est disponible. Cette information
peut donc ˆetre utilis´ee plus eﬃcacement pour d´evelopper une distribution a
priori. En r´ealit´e, coˆut et a priori sont diﬃciles `a dissocier et devraient ˆetre
analys´es simultan´ement (Lindley, 1985). Nous verrons dans la Section 2.4 un
exemple de la dualit´e qui existe entre ces deux facteurs. Nous verrons aussi
dans la Section 2.5.4 comment les coˆuts classiques peuvent ˆetre remplac´es
par des coˆuts plus intrins`eques (similaires aux lois a priori non informatives
pr´esent´ees dans le Chapitre 3), quand il n’y a aucune information disponible
sur la p´enalit´e associ´ee `a des d´ecisions erron´ees ou mˆeme sur la param´etrisation
d’int´erˆet.
Dans certains cas il est possible de r´eduire la classe des fonctions de
coˆut acceptables par des consid´erations d’invariance, par exemple quand le
mod`ele est invariant sous l’action d’un groupe de transformations. Ce type de
consid´erations s’applique aussi au choix de la distribution a priori, comme on
le verra dans le Chapitre 9. Il est important de souligner que ces motivations
d’invariance sont souvent utilis´ees dans d’autres approches d´ecisionnelles, lors-
qu’une r´eduction drastique de la classe des proc´edures inf´erentielles se r´ev´ele
n´ecessaire pour obtenir la “meilleure” solution.

58
2 Les bases de la Th´eorie de la D´ecision
Exemple 2.2. Soit le probl`eme de l’estimation de la moyenne θ d’un vecteur
normal, x ∼Nn(θ, Σ), o`u Σ est une matrice diagonale connue avec pour
´el´ements diagonaux σ2
i (1 ≤i ≤n). Dans ce cas, D = Θ = Rp et δ repr´esente
une ´evaluation de θ. S’il n’y a pas d’information additionnelle disponible sur le
mod`ele, il paraˆıt logique de choisir une fonction de coˆut qui attribue le mˆeme
poids `a chaque composante, soit donc un coˆut de la forme
n

i=1
L
δi −θi
σi

,
o`u L prend son minimum en 0. Eﬀectivement, pour ce type de coˆut, les com-
posantes ayant une grande variance ne biaisent pas fortement la s´election de
l’estimateur r´esultant. En d’autres termes, les composantes avec une grande
variance n’ont pas un poids trop important d`es que les erreurs d’estimation
(δi−θi) sont normalis´ees par σi. Le choix habituel de L est le coˆut quadratique
L(t) = t2, ce qui signiﬁe que l’erreur d’estimation globale est la somme des
carr´es des erreurs de chaque composante.
∥
2.2 La fonction d’utilit´e
La notion d’utilit´e (d´eﬁnie comme l’oppos´e d’une fonction de coˆut) est
utilis´ee non seulement en Statistique, mais aussi en ´economie et dans d’autres
domaines comme la Th´eorie des Jeux o`u il est n´ecessaire d’ordonner les
cons´equences d’actions ou de d´ecisions. Cons´equences (ou r´ecompenses) sont
des notions g´en´eriques qui r´esument l’ensemble des r´esultats ´emanant de l’ac-
tion du d´ecideur. Dans les cas les plus simples, il peut s’agir d’un gain ou
d’un coˆut ﬁnancier dus `a cette d´ecision. Dans le cas de l’estimation, l’uti-
lit´e peut ˆetre une mesure de la distance entre l’´evaluation et la vraie valeur
du param`etre, comme dans l’Exemple 2.2. Les bases axiomatiques de l’uti-
lit´e ont ´et´e attribu´ees `a von Neumann et Morgenstern (1947) et ont men´e
`a de nombreuses extensions, particuli`erement en Th´eorie des Jeux. Dans un
cadre statistique, cette approche a ´et´e consid´er´ee par Wald (1950) et Ferguson
(1967). Des extensions et des commentaires additionnels peuvent ˆetre trouv´es
dans (DeGroot, 1970, Chapitre 7) ; pour des r´ef´erences sur la th´eorie de l’uti-
lit´e, voir Fishburn (1988) et Machina (1982, 1987). Voir aussi Chamberlain
(2000) pour une connexion avec l’´Econom´etrie.
Le cadre g´en´eral sous-tendant la th´eorie de l’utilit´e consid`ere R, l’espace
des r´ecompenses, suppos´e compl`etement connu ; par exemple, R = R. Nous
supposons aussi qu’il est possible d’ordonner les r´ecompenses, donc qu’il existe
un ordre total, not´e ⪯, sur R tel que, si r1 et r2 sont dans R,
(1) r1 ⪯r2 ou r2 ⪯r1 ; et
(2) si r1 ⪯r2 et r2 ⪯r3, alors r1 ⪯r3.

2.2 La fonction d’utilit´e
59
Ces deux propri´et´es paraissent ˆetre des conditions minimales dans un cadre
d´ecisionnel. En particulier, la transitivit´e (2) est absolument n´ecessaire pour
permettre une comparaison entre les proc´edures de d´ecision. Sinon, nous pou-
vons nous retrouver avec des cycles tels que r1 ⪯r2 ⪯r3 ⪯r1 et ˆetre dans
l’incapacit´e de s´electionner la meilleure r´ecompense parmi ces trois choix. (La
Note 2.8.3 pr´esente un crit`ere qui est intransitif et ne se rapporte donc pas `a
la Th´eorie de la D´ecision.) Nous notons respectivement ≺et ∼l’ordre strict
et la relation d’´equivalence d´eriv´es de ⪯. Cependant, une et seulement une
des trois relations suivantes est satisfaite par tout couple (r1, r2) dans R2
r1 ≺r2,
r2 ≺r1,
r1 ∼r2.
Pour avancer davantage dans la construction de la fonction d’utilit´e, il
est n´ecessaire d’´etendre l’espace des r´ecompenses de R `a P, l’espace des
distributions de probabilit´e dans R. Ceci permet aussi au d´ecideur de prendre
des d´ecisions partiellement al´eatoires; de plus, l’espace des r´ecompenses ainsi
´etendu est convexe.
Exemple 2.3. Dans toute situation r´ealiste, les r´ecompenses associ´ees `a une
action ne sont pas exactement connues au moment o`u la d´ecision est prise ou,
d’une fa¸con ´equivalente, certaines d´ecisions comportent une part de risque.
Par exemple, en ﬁnance, le revenu ﬁnancier r ∈R = R d’actions cot´ees en
Bourse n’est pas garanti au moment o`u les actionnaires doivent d´eterminer les
entreprises dont ils devront acheter des actions. Dans ce cas, D = {d1, . . . , dn},
o`u dk repr´esente l’action “acheter des actions de la compagnie k”. Au moment
de la d´ecision, les gains associ´es aux diﬀ´erentes actions sont des dividendes
al´eatoires, connus seulement `a la ﬁn de l’ann´ee.
∥
La relation d’ordre ⪯est suppos´ee disponible ´egalement dans P. Par
exemple, quand la r´ecompense est mon´etaire, la relation d’ordre dans P peut
ˆetre obtenue en comparant la moyenne des rendements associ´es `a la distri-
bution P. Il est donc possible de comparer deux distributions de probabilit´e
dans R, P1 et P2. Nous supposons ainsi que ⪯satisfait les extensions des deux
hypoth`eses (1) et (2) sur P :
(A1)
P1 ⪯P2 ou P2 ⪯P1 ; et
(A2)
si P1 ⪯P2 et P2 ⪯P3, alors P1 ⪯P3.
La relation d’ordre sur R apparaˆıt alors comme un cas particulier d’ordre sur
P, via la consid´eration des masses de Dirac δr (r ∈R).
L’existence de l’ordre ⪯sur P est fond´ee sur l’hypoth`ese qu’il existe une
r´ecompense optimale, et donc qu’il existe au moins un ordre partiel sur les
cons´equences, mˆeme quand elles sont al´eatoires. C’est ´evidemment le cas lors-
qu’il existe une fonction U de R associ´ee `a ⪯, telle que P1 ⪯P2 est ´equivalente
`a
EP1[U(r)] ≤EP2[U(r)],

60
2 Les bases de la Th´eorie de la D´ecision
comme dans l’exemple mon´etaire ci-dessus. Cette fonction U est dite fonction
d’utilit´e. Nous pr´esentons maintenant un syst`eme axiomatique portant sur ⪯
qui assure l’existence de la fonction d’utilit´e.
Par souci de simplicit´e, nous consid´erons ici seulement le groupe des distri-
butions born´ees, PB, correspondant aux distributions `a support born´e, pour
lesquelles il existe r1 et r2 tels que
[r1, r2] = {r : r1 ⪯r ⪯r2}
et
P([r1, r2]) = 1.
Pour P1, P2 dans PB, nous d´eﬁnirons le m´elange P = αP1 +(1−α)P2 comme
la distribution qui g´en`ere une r´ecompense de P1 avec probabilit´e α et une
r´ecompense de P2 avec probabilit´e (1 −α). Par exemple, αδr1 + (1 −α)δr2 est
la distribution qui donne comme r´esultat la r´ecompense r1 avec probabilit´e α
et la r´ecompense r2 avec probabilit´e (1−α). Deux hypoth`eses suppl´ementaires
(ou axiomes) sont n´ecessaires pour obtenir l’existence d’une fonction d’utilit´e
dans R. Tout d’abord, il doit y avoir respect de l’ordre sous des alternatives
indiﬀ´erentes :
(A3)
si P1 ⪯P2, αP1 + (1 −α)P ⪯αP2 + (1 −α)P pour tout P ∈P.
Par exemple, si les actionnaires de l’Exemple 2.3 peuvent comparer deux com-
pagnies avec des distributions de dividendes P1 et P2, ils doivent pouvoir gar-
der le mˆeme classement s’il y a une probabilit´e (1−α) que les deux dividendes
soient remplac´es par des bons du Tr´esor avec une distribution de dividendes
P. La relation d’ordre doit ˆetre aussi connexe (ou ferm´ee) :
(A4)
si P1 ⪯P2 ⪯P3, il existe α et β ∈]0, 1[ tel que
αP1 + (1 −α)P3 ⪯P2 ⪯βP1 + (1 −β)P3.
La derni`ere hypoth`ese implique alors le r´esultat suivant.
Lemme 2.4. Si r1, r2, et r sont des r´ecompenses dans R avec r1 ≺r2 et
r1 ⪯r ⪯r2, il existe un seul v (0 ≤v ≤1) tel que r ∼vr1 + (1 −v)r2.
Le Lemme 2.4 est en r´ealit´e le point essentiel pour la construction de
la fonction d’utilit´e, U, dans R. En eﬀet, pour r1 et r2, deux r´ecompenses
arbitraires telles que r2 ≺r1, nous pouvons d´eﬁnir U de la fa¸con suivante.
Pour chaque r ∈R, soit
(i) U(r) = v si r2 ⪯r ⪯r1 et r ∼vr1 + (1 −v)r2 ;
(ii) U(r) =
−v
1−v
si r ⪯r2 et r2 ∼vr1 + (1 −v)r ; et
(iii) U(r) = 1
v
si r1 ⪯r et r1 ∼vr + (1 −v)r2.
En particulier, U(r1) = 1 et U(r2) = 0. De plus, cette fonction U conserve la
relation d’ordre sur R (voir DeGroot, 1970, p.105, pour une d´emonstration).
Lemme 2.5. Si r1, r2 et r3 sont trois r´ecompenses dans R telles que r2 ∼
αr1 + (1 −α)r3
U(r2) = αU(r1) + (1 −α)U(r3).

2.2 La fonction d’utilit´e
61
En r´ealit´e, les axiomes (A3) et (A4) peuvent ˆetre davantage aﬀaiblis. Il
est eﬀectivement suﬃsant qu’ils ne soient satisfaits que dans R. L’exten-
sion de la d´eﬁnition de fonction d’utilit´e pour PB n´ecessite une hypoth`ese
suppl´ementaire. Soit P tel que P([r1, r2]) = 1, d´eﬁnissons
α(r) = U(r) −U(r1)
U(r2) −U(r1)
et
β =

[r1,r2]
α(r) dP(r).
Alors, l’axiome additionnel
(A5)
P ∼βδr2 + (1 −β)δr1
implique que, si r est ´equivalent `a α(r)r1+(1−α(r))r2 pour chaque r ∈[r1, r2],
cette ´equivalence doit ˆetre vraie en moyenne. En eﬀet, notons que β est obtenu
`a partir d’une utilit´e moyenne,
β = EP [U(r)] −U(r1)
U(r2) −U(r1)
,
et cette hypoth`ese fournit une d´eﬁnition de U dans PB. Comme dans le
Lemme 2.5 o`u U est restreint `a R, et comme le montre le r´esultat suivant,
l’axiome (A5) indique que U permet une lin´earisation (ou une param´etrisation
lin´eaire) de la relation d’ordre ⪯dans PB. Bien que l´eg`erement tautologique
–puisqu’elle d´epend dans sa formulation de la fonction d’utilit´e que nous es-
sayons de construire–, (A5) nous conduit eﬀectivement `a l’extension suivante
du Lemme 2.5 `a PB.
Th´eor`eme 2.6. Soient P1 et P2 sur PB. Alors,
P1 ⪯P2
si et seulement si
EP1[U(r)] ≤EP2[U(r)].
De plus, si U ∗est une autre fonction d’utilit´e qui satisfait la relation d’´equi-
valence pr´esent´ee ci-dessus, il existe a > 0 et b tels que
U ∗(r) = aU(r) + b.
Preuve.
Soient r1 et r2 tels que
P1([r1, r2]) = P2([r1, r2]) = 1
(avec r1 ≺r2). Comme

62
2 Les bases de la Th´eorie de la D´ecision
P1 ∼EP1[U(r)] −U(r1)
U(r2) −U(r1)
δr2 + U(r2) −EP1[U(r)]
U(r2) −U(r1)
δr1
et
P2 ∼EP2[U(r)] −U(r1)
U(r2) −U(r1)
δr2 + U(r2) −EP2[U(r)]
U(r2) −U(r1)
δr1 ,
P1 ⪯P2 est eﬀectivement ´equivalent `a
EP1[U(r)] −U(r1)
U(r2) −U(r1)
≤EP2[U(r)] −U(r1)
U(r2) −U(r1)
,
soit encore EP1[U(r)] ≤EP2[U(r)]. De plus, pour toute autre fonction d’utilit´e
U ∗, il existe a et b tels que U ∗(r1) = aU(r1) + b, U ∗(r2) = aU(r2) + b.
L’extension de cette relation `a chaque r ∈R d´ecoule du Lemme 2.5.
⊓⊔
Notons que la construction ci-dessus n’implique aucune restriction sur la
fonction U. Donc, celle-ci n’a pas besoin d’ˆetre born´ee, bien que cette condition
soit souvent mentionn´ee dans les livres. On peut avancer que cette g´en´eralit´e
est artiﬁcielle et formelle, car les fonctions d’utilit´e subjectives sont toujours
born´ees. Par exemple, quand on consid`ere une r´ecompense mon´etaire, il existe
un seuil psychologique, disons de 100 000 000 euros, au-dessus duquel (la
plupart) des individus ont une fonction d’utilit´e presque constante.
Cependant, cette limite sup´erieure varie d’individu `a individu, et la varia-
tion est encore plus grande entre des individus et des entreprises ou des ´Etats.
Il est aussi important d’inclure les r´ecompenses inacceptables, bien que l’hy-
poth`ese (A4) empˆeche les r´ecompenses d’utilit´e ´egale `a −∞. (Cette restriction
implique que la mort d’un patient pendant une ´etude pharmaceutique ou un
accident grave dans une centrale nucl´eaire ont une utilit´e ﬁnie.) De plus, la
plupart des fonctions de coˆut th´eoriques ne sont pas born´ees. Une contrepartie
de cette g´en´eralit´e est que les r´esultats ci-dessus n’ont ´et´e ´etablis que pour
PB. En r´ealit´e, ils peuvent ˆetre ´etendus `a PE , l’ensemble des distributions
P dans P telles que EP [U(r)] soit ﬁnie, sous l’hypoth`ese que (A1)–(A5) et
deux conditions suppl´ementaires sont satisfaites par PE (voir l’Exercice 2.3).
Th´eor`eme 2.7. Soient P et Q, deux distributions sur PE . Alors, P ⪯Q si
et seulement si
EP [U(r)] ≤EQ[U(r)].
´Evidemment, le Th´eor`eme 2.7 ne parvient pas `a traiter des distributions
d’utilit´e inﬁnies. Si de telles distributions existent, elles doivent ˆetre com-
par´ees entre elles et une fonction d’utilit´e doit ˆetre construite sur cette classe
restreinte, puisque dans un sens il s’agit des seules distributions int´eressantes.
Cependant, les fonctions de coˆut consid´er´ees par la suite seront minor´ees,
le plus souvent par 0. Les fonctions d’utilit´e correspondantes, oppos´ees aux
fonctions de coˆut, sont donc toujours major´ees et les paradoxes de r´ecompense
inﬁnie peuvent ˆetre ´evit´es. (Rubin, 1984 et Fishburn, 1988, fournissent des

2.2 La fonction d’utilit´e
63
syst`emes axiomatiques plus faibles assurant l’existence d’une fonction d’uti-
lit´e.)
Plusieurs critiques ont ´et´e formul´ees, d’ordre th´eorique et psychologique,
contre la notion de rationalit´e des d´ecideurs et les axiomes associ´es (A1)–(A4).
Premi`erement, il paraˆıt illusoire de croire que les individus peuvent comparer
toutes les r´ecompenses, c’est-`a-dire qu’ils peuvent fournir un ordre total de P
(ou mˆeme de R), car leurs capacit´es de discernement sont forc´ement limit´ees,
en particulier en ce qui concerne les alternatives contig¨ues ou extrˆemes.
L’hypoth`ese de transitivit´e est aussi trop forte, car les exemples en sport
ou en politique montrent que l’ordre des pr´ef´erences conduit souvent dans la
pratique `a une intransitivit´e, comme on le voit dans les paradoxes de Condor-
cet et de Simpson (voir Casella et Wells, 1993, et les Exercices 1.9 et 2.2).
Plus fondamentalement, l’hypoth`ese que l’ordre peut ˆetre ´etendu de R `a P a
´et´e fortement contest´ee, car elle implique que l’ordre social puisse ˆetre obtenu
`a partir d’un ensemble d’ordres individuels, et en g´en´eral cela n’est pas pos-
sible (voir Arrow, 1956 ou Blyth, 1972a). Cependant, bien que reconnaissant
ce fait, Rubin (1984) remarque que cette impossibilit´e implique simplement
que l’utilit´e et l’a priori soient ins´eparables, non pas qu’une d´ecision opti-
male (bay´esienne) ne puisse pas ˆetre obtenue, et il donne une s´erie restreinte
d’axiomes se rapportant `a cet objectif. En g´en´eral, les critiques exprim´ees
ci-dessus sont absolument valables, mais ne peuvent r´esister `a l’argument de
la n´ecessit´e absolue d’un cadre axiomatique qui valide la prise de d´ecision
dans un cadre incertain. Comme cela est d´ej`a ´evoqu´e dans le Chapitre 1, la
mod´elisation statistique est et doit ˆetre r´eductrice. Mˆeme si elle passe `a cˆot´e
d’une partie de la complexit´e du monde, cette repr´esentation simpliﬁ´ee du
monde permet aux statisticiens et aux autres de prendre des d´ecisions. La
Th´eorie de la D´ecision d´ecrit ainsi un cadre id´ealis´e, sous une rationalit´e fon-
damentale que les vrais d´ecideurs n’arrivent pas `a atteindre, mais qu’ils visent
n´eanmoins20.
D’un point de vue plus pratique, la construction de la fonction d’utilit´e
d´ecrite au-dessus peut ˆetre critiqu´ee comme irr´ealiste. Berger (1985b) four-
nit quelques exemples fond´es sur DeGroot (1970), o`u la fonction d’utilit´e
est construite par des divisions successives de l’espace des r´ecompenses (voir
aussi Raiﬀa et Schlaifer, 1961). Cependant, si R est grand (par exemple, non
d´enombrable), U ne peut pas ˆetre ´evalu´ee pour chaque r´ecompense r, mˆeme
si la lin´earit´e mise en avant dans le Lemme 2.5 permet des approximations
quand R ⊂R. Dans un cadre multidimensionnel, les approximations lin´eaires
ne sont plus possibles, sauf si on utilise une combinaison lin´eaire d’utilit´es
r´eelles, soit
20Pour emprunter `a Smith (1984), critiquer les structures id´eales de la Th´eorie de
la D´ecision `a cause des limitations humaines revient, d’une fa¸con ou d’une autre, `a
remettre en cause l’int´egration parce que quelques int´egrales ne peuvent ˆetre r´esolues
que num´eriquement.

64
2 Les bases de la Th´eorie de la D´ecision
U(r1, r2, . . . , rn) =
n

i=1
αiUi(ri)
(voir Raiﬀa, 1968, Keeney et Raiﬀa, 1976, ou Smith, 1988, pour une discus-
sion). En g´en´eral, les fonctions d’utilit´e pratiques ne seront que des approxi-
mations des vraies fonctions d’utilit´e.
Mˆeme quand la r´ecompense est purement ﬁnanci`ere, une d´etermination ri-
goureuse de la fonction d’utilit´e s’impose, car U peut ˆetre loin d’ˆetre lin´eaire,
en particulier pour de grandes r´ecompenses. Cela signiﬁe qu’un gain de
3 000 avec une probabilit´e de 1/2 n’´equivaut pas forc´ement `a gagner
1 500
sˆurement. Pour r´esoudre ce paradoxe, Laplace (1795) introduit la notion
d’attente morale, d´eriv´ee de la valeur relative d’une augmentation du gain
“la valeur absolue divis´ee par le gain total de la personne concern´ee”. Laplace
inf`ere que l’attente morale “co¨ıncide avec l’attente math´ematique quand le
gain devient inﬁni en comparaison avec les variations dues `a l’incertitude”, ce
qui signiﬁe que l’utilit´e n’est eﬀectivement lin´eaire qu’au voisinage de 0. Sinon,
les attitudes d’aversion au risque ralentissent la courbe d’utilit´e, qui est typi-
quement concave et major´ee pour de grandes valeurs des r´ecompenses. (Les
personnes avec une fonction d’utilit´e convexe sont dites amateurs de risque,
car elles pr´ef`erent un gain al´eatoire `a l’esp´erance de ce gain. Notons que cette
attitude est assez compr´ehensible au voisinage de 0.) Construire une fonction
d’utilit´e mon´etaire est ´evidemment plus compliqu´e que d’utiliser une utilit´e
lin´eaire, mais cette construction fournit une repr´esentation plus pr´ecise de la
r´ealit´e et peut mˆeme ´eviter des paradoxes comme celui pr´esent´e ci-dessous.
Exemple 2.8. (Paradoxe de Saint-P´etersbourg) Soit un jeu o`u une pi`ece est
lanc´ee jusqu’`a ce que le cˆot´e face apparaisse. Quand cela arrive au n-i`eme jet,
le gain du joueur est 3n, ce qui donne un gain moyen de
+∞

n=1
3n 1
2n = +∞.
Chaque joueur devrait donc ˆetre prˆet `a payer un droit d’entr´ee arbitrairement
´elev´e pour jouer ce jeu, mˆeme s’il a moins de 0.05 de probabilit´e d’aller au-
del`a du cinqui`eme jet ! Cette mod´elisation ne prend pas en compte le fait
que la fortune d’un joueur est n´ecessairement born´ee et qu’il ne peut jouer
qu’un nombre limit´e de fois. Une solution `a ce paradoxe est de substituer une
fonction d’utilit´e born´ee `a la fonction d’utilit´e lin´eaire, comme
U(r) =
r
δ + r
(δ > 0, r > −δ),
et U(r) = −∞sinon. Cette construction est assez similaire `a l’attente morale
de Laplace. Un droit d’entr´ee acceptable e sera alors tel que l’utilit´e moyenne
du jeu est aussi grande que l’utilit´e de ne rien faire, soit
E[U(r −e)] ≥U(0) = 0.

2.2 La fonction d’utilit´e
65
La Figure 2.1 repr´esente l’utilit´e moyenne en fonction de δ, calcul´ee par ap-
proximation num´erique de la s´erie
+∞

n=1
3n
δ + 3n 2−n .
0
2
4
6
8
10
0.5
0.6
0.7
0.8
0.9
1.0
δ
Utilité
Fig. 2.1. Utilit´e moyenne pour le paradoxe de Saint-P´etersbourg.
Consid´erons maintenant une modiﬁcation du jeu o`u le joueur peut se re-
tirer `a n’importe quel moment n et prendre le gain 3n si le cˆot´e pile n’est pas
encore apparu. Le gain moyen au temps n est alors
3n
δ + 3n 2−n,
qui peut fournir un temps optimal n0 pour quitter le jeu, d´ependant du pa-
ram`etre d’utilit´e δ, qui caract´erise en quelque sorte l’aversion au risque du
joueur (voir Smith, 1988, pour une description plus minutieuse). Par exemple,
δ peut repr´esenter la chance du joueur, car U(τ) tend vers −∞quand τ
tend vers −δ. Ce choix particulier de U peut bien sˆur ˆetre critiqu´e, mais
une repr´esentation plus pr´ecise de la fonction d’utilit´e n´ecessite une analyse
d´etaill´ee des motivations du joueur (voir aussi l’Exercice 2.9).
∥
Voir ´egalement Bernardo et Smith (1994) pour une analyse d´etaill´ee des
bases de la th´eorie de l’utilit´e, avec une description particuli`ere des arbres
de d´ecision.

66
2 Les bases de la Th´eorie de la D´ecision
2.3 Utilit´e et coˆut
Revenons `a un cadre purement statistique. D’un point de vue d´ecisionnel,
le mod`ele statistique inclut maintenant trois espaces : X , espace des ob-
servations, Θ, espace des param`etres, et D, espace des d´ecisions (ou espace
d’action). L’inf´erence statistique consiste alors `a prendre une d´ecision d ∈D
par rapport au param`etre θ ∈Θ, fond´ee sur l’observation x ∈X , x et θ
´etant reli´es par la distribution f(x|θ). Dans la plupart des cas, la d´ecision d
devra ´evaluer (ou estimer) une fonction de θ, h(θ), le plus pr´ecis´ement pos-
sible. La Th´eorie de la D´ecision suppose de plus que chaque action d peut ˆetre
´evalu´ee (ce qui signiﬁe que la pr´ecision peut ˆetre quantiﬁ´ee) et conduit `a une
r´ecompense r, avec une utilit´e U(r) (qui existe sous l’hypoth`ese de rationa-
lit´e des d´ecideurs). Dor´enavant, cette utilit´e sera not´ee U(θ, d) pour insister
sur le fait qu’elle d´epend uniquement de ces deux facteurs. Quand d’autres
facteurs al´eatoires r interviennent dans U, nous ´ecrirons U(θ, d) = Eθ,d[U(r)].
Donc, U(θ, d) peut ˆetre vue comme une mesure de proximit´e entre l’estimation
propos´ee d et la vraie valeur h(θ).
Une fois que la fonction d’utilit´e a ´et´e construite (ou approch´ee), nous
construisons la fonction de coˆut correspondante
L(θ, d) = −U(θ, d).
En g´en´eral, la fonction de coˆut est suppos´ee positive, ce qui implique U(θ, d) ≤
0, et donc il n’existe pas de d´ecision ayant une utilit´e inﬁnie. L’hypoth`ese de
l’existence d’un minorant pour L peut ˆetre critiqu´ee comme trop stricte, mais
elle ´evite des paradoxes comme ceux mentionn´es ci-dessus. On peut aussi
soutenir que, d’un point de vue statistique, la fonction de coˆut L repr´esente
bien le coˆut (ou l’erreur) dˆu `a une mauvaise ´evaluation de la fonction de θ
d’int´erˆet, et donc que mˆeme la meilleure ´evaluation possible de cette fonction,
soit, lorsque θ est connu, peut entraˆıner au mieux un coˆut nul. Dans le cas
contraire, la fonction de coˆut perdrait sa continuit´e en d = θ , ce qui pourrait
mˆeme empˆecher le choix d’une proc´edure de d´ecision.
´Evidemment, sauf pour les cas les plus triviaux, il est g´en´eralement impos-
sible de minimiser uniform´ement (en d) la fonction de coˆut L(θ, d) quand θ
est inconnu. Pour obtenir un crit`ere de comparaison utilisable `a partir d’une
fonction de coˆut dans un contexte al´eatoire, l’approche fr´equentiste propose
de consid´erer plutˆot le coˆut moyen (ou risque fr´equentiste)
R(θ, δ) = Eθ[L(θ, δ(x))]
=

X
L(θ, δ(x))f(x|θ) dx,
o`u δ(x) est la r`egle de d´ecision, soit l’attribution d’une d´ecision `a chaque
r´esultat x ∼f(x|θ) de l’exp´erience al´eatoire. La fonction δ, de X dans D,
est habituellement appel´ee estimateur (tandis que la valeur δ(x) est appel´ee

2.3 Utilit´e et coˆut
67
estimation de θ). Quand il n’y a pas de risque de confusion, nous noterons
aussi D l’ensemble des estimateurs.
Le paradigme fr´equentiste repose sur cette notion pour comparer les esti-
mateurs et, si possible, choisir le meilleur d’entre eux. Le raisonnement est que
ces estimateurs sont ´evalu´es selon leurs performances `a long terme pour toutes
les valeurs possibles du param`etre θ. Notons cependant qu’il existe plusieurs
diﬃcult´es li´ees `a cette approche.
(1) L’erreur (coˆut) est moyenn´ee sur toutes les valeurs de x, proportionnelle-
ment `a la densit´e f(x|θ). Il semble donc que l’observation x ne soit plus
prise en compte par la suite. Le crit`ere de risque ´evalue les proc´edures
selon leurs performances de long terme et non directement pour une ob-
servation x donn´ee. Une telle ´evaluation peut ˆetre satisfaisante pour un(e)
statisticien(ne), mais elle n’est pas tr`es convaincante pour un(e) client(e)
qui cherche un r´esultat optimal pour ses donn´ees x, pas pour celles des
autres !
(2) L’analyse fr´equentiste du probl`eme de d´ecision suppose tacitement que le
mˆeme probl`eme sera rencontr´e de nombreuses fois pour que l’´evaluation
en fr´equence ait un sens. En eﬀet, R(θ, δ) est approximativement le coˆut
moyen sur les r´ep´etitions i.i.d. de la mˆeme exp´erience, selon la Loi des
Grands Nombres. Cependant, d’un point de vue philosophique et pra-
tique, il existe beaucoup de controverses sur la notion mˆeme de r´ep´etabilit´e
des exp´eriences (voir Jeﬀreys, 1961). En fait, si de nouvelles observations
parviennent `a un statisticien, celui-ci devrait les utiliser, ce qui pourrait
modiﬁer la fa¸con dont l’exp´erience est conduite, comme par exemple dans
les exp´eriences m´edicales.
(3) Pour une proc´edure δ, le risque R(θ, δ) est une fonction du param`etre
θ. L’approche fr´equentiste n’induit donc pas un ordre total sur l’en-
semble des proc´edures. Il est g´en´eralement impossible de comparer les
proc´edures de d´ecision avec ces crit`eres, car deux fonctions de risque qui
se croisent empˆechent la comparaison entre les estimateurs correspon-
dants. Au mieux, on peut esp´erer trouver une proc´edure δ0 qui minimise
(en δ) uniform´ement (en θ) R(θ, δ), mais ce type de situation se produit
rarement, `a moins que l’espace des proc´edures de d´ecision ne soit tr`es
restreint. Les proc´edures optimales ne peuvent ˆetre obtenues que par une
restriction plutˆot artiﬁcielle `a un ensemble de proc´edures autoris´ees.
Exemple 2.9. Soient x1 et x2, deux observations de
Pθ(x = θ −1) = Pθ(x = θ + 1) = 0.5,
θ ∈R.
Le param`etre d’int´erˆet est θ (donc D = Θ) et il est estim´e par δ sous le coˆut
L(θ, δ) = 1 −Iθ(δ),
appel´ee le plus souvent coˆut 0−1, qui p´enalise les erreurs d’estimation, quelle
que soit leur magnitude, par 1. Consid´erons en particulier l’estimateur

68
2 Les bases de la Th´eorie de la D´ecision
δ0(x1, x2) = x1 + x2
2
,
dont la fonction de risque est
R(θ, δ0) = 1 −Pθ(δ0(x1, x2) = θ)
= 1 −Pθ(x1 ̸= x2) = 0.5.
Ce calcul montre que l’estimateur δ0 est correct la moiti´e du temps. En r´ealit´e,
cet estimateur est toujours correct quand x1 ̸= x2, et toujours faux autrement.
Cependant l’estimateur δ1(x1, x2) = x1+1 a aussi une fonction de risque ´egale
`a 0.5, comme δ2(x1, x2) = x2−1. Donc, δ0, δ1 et δ2 ne peuvent pas ˆetre class´es
sous le coˆut 0 −1.
∥
En revanche, l’approche bay´esienne de la Th´eorie de la D´ecision int`egre
sur l’espace Θ, car θ est inconnu, plutˆot que de le faire sur l’espace X , x ´etant
connu. Il est fond´e sur le coˆut moyenne a posteriori
ϱ(π, d|x) = Eπ[L(θ, d)|x] =

Θ
L(θ, d)π(θ|x) dθ ,
qui moyenne l’erreur (c’est-`a-dire le coˆut) selon la distribution a posteriori
du param`etre θ, conditionnellement `a la valeur observ´ee x. Pour un x donn´e,
l’erreur moyenne r´esultant de la d´ecision d est en r´ealit´e ϱ(π, d|x). Le coˆut
moyen a posteriori est ainsi une fonction de x mais cette d´ependance n’est pas
gˆenante, contrairement `a la d´ependance fr´equentiste du risque au param`etre
puisque x, `a la diﬀ´erence de θ, est connu.
En se donnant une distribution a priori π, il est aussi possible de d´eﬁnir
le risque int´egr´e, qui est le risque fr´equentiste moyenn´e sur les valeurs de θ
selon leur distribution a priori
r(π, δ) = Eπ[R(θ, δ)]
=

Θ

X
L(θ, δ(x)) f(x|θ) dx π(θ) dθ.
Un int´erˆet particulier de ce deuxi`eme concept est qu’il associe un nombre
r´eel `a chaque estimateur, et non une fonction de θ. Il induit donc un ordre
total sur l’ensemble des estimateurs et permet une comparaison directe entre
ces estimateurs. Cela implique que, quoique prenant en compte l’information
a priori via la distribution a priori, l’approche bay´esienne est suﬃsamment
r´eductrice (dans un sens positif) pour atteindre une d´ecision eﬃcace. De plus,
les deux notions ci-dessus sont ´equivalentes puisqu’elles conduisent `a la mˆeme
d´ecision.
Th´eor`eme 2.10. Un estimateur minimisant le risque int´egr´e r(π, δ) est ob-
tenu par s´election, pour chaque x ∈X , de la valeur δ(x) qui minimise le coˆut
moyen a posteriori, ϱ(π, δ|x), puisque

2.3 Utilit´e et coˆut
69
r(π, δ) =

X
ϱ(π, δ(x)|x)m(x) dx.
(2.1)
Preuve.
L’´egalit´e (2.1) d´ecoule directement du Th´eor`eme de Fubini, car,
comme L(θ, δ) ≥0,
r(π, δ) =

Θ

X
L(θ, δ(x))f(x|θ) dx π(θ) dθ
=

X

Θ
L(θ, δ(x))f(x|θ)π(θ) dθ dx
=

X

Θ
L(θ, δ(x))π(θ|x) dθ m(x) dx .
⊓⊔
Ce r´esultat m`ene `a la d´eﬁnition suivante d’un estimateur de Bayes.
D´eﬁnition 2.11. Un estimateur de Bayes associ´e `a une distribution a priori
π et une fonction de coˆut L est un estimateur δπ minimisant r(π, δ). Pour
chaque x ∈X , ce dernier est donn´e par
δπ(x) = arg min
d ϱ(π, d|x) .
La valeur r(π) = r(π, δπ) est alors appel´ee risque de Bayes.
Le Th´eor`eme 2.10 fournit ainsi un outil constructif pour la d´etermination
des estimateurs de Bayes. Notons que, d’un point de vue strictement bay´esien,
seul le coˆut moyen a posteriori ϱ(π, δ|x) compte, puisque le paradigme bay´esien
est fond´e sur une approche conditionnelle. Faire la moyenne sur toutes les
valeurs possibles de x, alors que nous connaissons la valeur observ´ee de
x, semble ˆetre une perte d’information. N´eanmoins, l’´equivalence pr´esent´ee
par le Th´eor`eme 2.10 est importante parce que, premi`erement, elle montre
que l’approche conditionnelle n’est pas n´ecessairement aussi dangereuse que
les critiques fr´equentistes peuvent l’indiquer. En eﬀet, bien que l’approche
bay´esienne fonctionne de fa¸con conditionnelle `a l’observation pr´esente x, elle
inclut aussi les propri´et´es probabilistes de la distribution de l’observation,
f(x|θ). Deuxi`emement, cette ´equivalence fournit une connection entre les
r´esultats classiques de la Th´eorie des Jeux (voir la Section 2.4) et l’approche
axiomatique bay´esienne, fond´ee sur la distribution a posteriori. Ceci explique
aussi pourquoi les estimateurs de Bayes jouent un rˆole important pour les
crit`eres d’optimalit´e fr´equentistes.
Le r´esultat pr´esent´e ci-dessus est valable pour des a priori propres et im-
propres, du moment que le risque de Bayes r(π) est ﬁni. Dans le cas contraire,
la notion d’estimateur (d´ecisionnel) de Bayes est aﬀaiblie. Nous d´eﬁnissons
alors un estimateur de Bayes g´en´eralis´e comme la quantit´e minimisant, pour

70
2 Les bases de la Th´eorie de la D´ecision
chaque x, le coˆut moyen a posteriori. En terme d’optimalit´e fr´equentiste, nous
verrons que la distinction entre a priori propres et impropres est beaucoup
moins importante que celle entre estimateurs de Bayes r´eguliers et g´en´eralis´es,
puisque les premiers sont admissibles. Notons que, pour des fonctions de coˆut
strictement convexes, les estimateurs de Bayes sont uniques.
Nous terminons cette partie par un exemple de construction d’une fonction
de coˆut dans un cadre de calibrage d’expert. Les r´ef´erences dans ce domaine
sont DeGroot et Fienberg (1983), Murphy (1984), Bayarri et DeGroot (1988)
et Schervish (1989). Smith (1988) montre aussi comment l’´evaluation d’un
pr´evisionniste peut aider `a am´eliorer l’estimation des probabilit´es a priori.
Voir la Note 2.8.1 pour une illustration diﬀ´erente en traitement d’image.
Exemple 2.12. Les pr´evisions m´et´eorologiques aux ´Etats-Unis sont souvent
donn´ees sous la forme de probabilit´es. Par exemple “la probabilit´e de pluie
pour demain est estim´ee `a 0.4”. De telles pr´evisions ´etant quantiﬁ´ees, il est
int´eressant (pour leurs employeurs autant que pour les utilisateurs) d’´evaluer
les m´et´eorologistes `a travers une fonction de coˆut.
Pour un m´et´eorologiste donn´e, soit N le nombre des diﬀ´erents pourcen-
tages annonc´es au moins une fois par an et soient pi (1 ≤i ≤N) les diﬀ´erents
pourcentages. Par exemple, nous pouvons avoir N = 5 et
p1 = 0,
p2 = 0.45,
p3 = 0.7,
p4 = 0.9,
et p5 = 0.95.
Dans ce cas, on observe eﬀectivement les param`etres θi, soit
θi = nombre de jours pluvieux pour lesquels pi est pr´edite
nombre de jours pour lesquels pi est pr´edite
(plus exactement, ce rapport est une bonne approximation de θi).
Si qi indique la proportion de jours o`u pi est pr´edite, une fonction de coˆut
possible pour les experts est
L(θ, p) =
N

i=1
qi(pi −θi)2 +
N

i=1
qi log(qi).
Pour un ensemble donn´e de θi (1 ≤i ≤N), le meilleur m´et´eorologiste est celui
qui est parfaitement calibr´e, donc celui qui satisfait pi = θi (1 ≤i ≤N). De
plus, parmi ces m´et´eorologistes parfaits, le meilleur est le mieux ´equir´eparti,
satisfaisant qi = 1/N (1 ≤i ≤N), c’est-`a-dire le m´et´eorologiste le plus
audacieux, par opposition `a celui qui veut donner toujours le mˆeme pronostic
pi0, par cons´equence du terme d’entropie, E(q) = 
i qi log(qi). Cependant,
la distance (pi −θi)2 peut ˆetre remplac´ee par n’importe quelle autre fonction
prenant son minimum en pi = θi (voir les Exercices 2.12 et 2.14). Le poids
qi dans la premi`ere somme est aussi utilis´e pour calibrer plus eﬃcacement les
m´et´eorologistes, aﬁn de pr´evenir la sur p´enalisation de pr´evisions plus rares.

2.4 Deux optimalit´es : minimaxit´e et admissibilit´e
71
Ce coˆut a ´et´e construit avec un biais en faveur des experts utilisant un
grand N, car l’entropie E(N) augmente avec N. Cependant, une meilleure
performance pour un plus grand N n´ecessite que pi soit (presque) ´egal `a θi et
que qi soit proche de 1/N.
∥
2.4 Deux optimalit´es : minimaxit´e et admissibilit´e
Cette section est consacr´ee `a deux notions fondamentales de la Th´eorie de
la D´ecision fr´equentiste, pr´esent´ees par Wald (1950) et Neyman et Pearson
(1933a,b). Comme il a ´et´e mentionn´e auparavant, et contrairement `a l’ap-
proche bay´esienne, le paradigme fr´equentiste n’est pas assez r´educteur pour
conduire `a un seul estimateur optimal. Bien que dans ce livre nous nous
int´eressions surtout aux aspects bay´esiens de la Th´eorie de la D´ecision, il
est n´ecessaire malgr´e tout d’´etudier ces notions fr´equentistes en d´etail, parce
qu’elles montrent que les estimateurs de Bayes sont souvent optimaux pour
les concepts fr´equentistes d’optimalit´e et devraient donc ˆetre utilis´es mˆeme
lorsque l’information a priori est omise. En d’autres termes, on peut re-
fuser le paradigme bay´esien et ignorer la signiﬁcation d’une distribution a
priori, tout en obtenant malgr´e tout des estimateurs corrects d’un point de
vue fr´equentiste par l’utilisation de cette distribution a priori. Donc, dans
ce sens technique, les fr´equentistes devraient aussi prendre en compte l’ap-
proche bay´esienne, car elle fournit un outil pour la construction d’estimateurs
optimaux (voir Brown, 1971, 2000, Strawderman, 1971, Berger, 1985b, ou
Berger et Robert, 1990, pour des exemples). De plus, ces propri´et´es peuvent
ˆetre utiles pour la s´election d’une distribution a priori, quand l’information a
priori n’est pas suﬃsamment pr´ecise pour conduire `a une distribution a priori
unique (Chapitre 3).
2.4.1 Estimateurs randomis´es
De mˆeme que pour l’´etude de la fonction d’utilit´e, o`u nous ´etendons l’es-
pace de r´ecompense de R `a P, nous avons besoin d’´etendre aussi l’espace de
d´ecision `a l’ensemble des estimateurs randomis´es, prenant leurs valeurs dans
D∗, l’espace des distributions de probabilit´e sur D. Utiliser un estimateur
randomis´e δ∗signiﬁe que l’action est g´en´er´ee selon la distribution de densit´e
de probabilit´e δ∗(x, .), une fois que l’observation x a ´et´e recueillie. Le coˆut de
l’estimateur randomis´e δ∗est alors d´eﬁni comme le coˆut moyen
L(θ, δ∗(x)) =

D
L(θ, a)δ∗(x, a) da.
Cette extension est n´ecessaire au traitement des notions de minimaxit´e et
d’admissibilit´e. ´Evidemment, de tels estimateurs n’en sont pas moins `a pres-
crire, en particulier parce qu’ils contredisent le principe de vraisemblance, en

72
2 Les bases de la Th´eorie de la D´ecision
donnant plusieurs r´eponses possibles pour la mˆeme valeur de x (et donc de
ℓ(θ|x)). De plus, il semble assez paradoxal d’ajouter du bruit au ph´enom`ene
´etudi´e pour prendre une d´ecision dans l’incertain !
Exemple 2.13. (Suite de l’Exemple 2.9) Soit l’estimateur randomis´e
δ∗(x1, x2)(t) =

I(x1+x2)/2(t)
si x1 ̸= x2,
[I(x1−1)(t) + I(x1+1)(t)]/2
sinon,
o`u Iv est la masse de Dirac sur v. En r´ealit´e, si x1 = x2, les deux valeurs
θ1 = x1 −1 et θ2 = x1 + 1 ont la mˆeme vraisemblance. Compar´e avec δ0
qui n’estime jamais correctement θ lorsque x1 = x2, δ∗est exact avec une
probabilit´e de 1/2. Cependant, quand δ∗n’estime pas correctement θ, il est
plus loin de θ que δ0. Le choix de l’estimateur d´epend alors de la fonction de
coˆut, donc de la mani`ere dont la distance (ou l’erreur) entre l’estimateur et le
param`etre θ est mesur´ee.
∥
D’un point de vue fr´equentiste, les estimateurs randomis´es sont n´eanmoins
n´ecessaires, par exemple pour la th´eorie des tests fr´equentistes, car ils per-
mettent d’obtenir des niveaux de conﬁance qui ne peuvent ˆetre atteints
autrement (voir le Chapitre 5). L’ensemble D∗apparaˆıt ainsi comme une
compl´etion topologique de D. Cependant, cette modiﬁcation de l’espace de
d´ecision ne modiﬁe aucunement les r´eponses bay´esiennes, comme le montre
le r´esultat suivant (o`u l’ensemble des fonctions prenant leurs valeurs dans D∗
est aussi not´e D∗).
Th´eor`eme 2.14. Pour toute distribution a priori π sur Θ, le risque de Bayes
pour l’ensemble des estimateurs randomis´es est le mˆeme que celui pour l’en-
semble des estimateurs non randomis´es, soit
inf
δ∈D r(π, δ) =
inf
δ∗∈D∗r(π, δ∗) = r(π).
Preuve.
Pour tout x ∈X et tout δ∗∈D∗, nous avons

Θ

D
L(θ, a)δ∗(x, a)da π(θ|x)dθ
=

D

Θ
L(θ, a)π(θ|x)dθ δ∗(x, a)da
≥

D
inf
a

Θ
L(θ, a)π(θ|x)dθ

δ∗(x, a)da
= ϱ(π, δπ|x).
⊓⊔

2.4 Deux optimalit´es : minimaxit´e et admissibilit´e
73
Ce r´esultat reste vrai mˆeme quand le risque de Bayes r(π) est inﬁni. La
d´emonstration est fond´ee sur le fait qu’une proc´edure randomis´ee moyennise
le risque des estimateurs non randomis´es et ne peut ainsi faire mieux que ces
derniers. Cependant, le fait qu’utiliser des proc´edures randomis´ees n’a pas de
sens n’est pas pris en compte par le risque fr´equentiste `a moins que certaines
conditions, comme la convexit´e, ne soient impos´ees `a la fonction de coˆut.
2.4.2 Minimaxit´e
Le crit`ere de minimaxit´e que nous pr´esentons maintenant apparaˆıt comme
une assurance contre le pire, car il vise `a minimiser le coˆut moyen dans le
cas le moins favorable. Il repr´esente aussi un eﬀort fr´equentiste pour ´eviter de
recourir au paradigme bay´esien, tout en engendrant un ordre (faible) sur D∗.
D´eﬁnition 2.15. On appelle risque minimax associ´e `a la fonction de coˆut L
la valeur
¯R = inf
δ∈D∗sup
θ
R(θ, δ) = inf
δ∈D∗sup
θ
Eθ[L(θ, δ(x))],
et estimateur minimax tout estimateur (´eventuellement randomis´e) δ0 tel que
sup
θ
R(θ, δ0) = ¯R.
Cette notion est valid´ee par la Th´eorie des Jeux, o`u deux adversaires (“le
statisticien” et la “Nature”) s’aﬀrontent. Une fois que le statisticien a choisi
une proc´edure, la Nature choisit l’´etat de la nature (c’est-`a-dire le param`etre
θ) qui maximise l’erreur du statisticien. (Nous verrons ci-apr`es que ce choix
est en g´en´eral ´equivalent `a celui de la distribution a priori π. L’approche
bay´esienne n’entre donc pas dans ce cadre conﬂictuel, car la distribution a
priori est aussi suppos´ee connue.) En g´en´eral, cette perspective antagoniste
apparaˆıt comme regrettable dans une analyse statistique. En eﬀet, consid´erer
la Nature (ou la r´ealit´e) comme un ennemi ne peut que biaiser vers les pires
cas et empˆecher le statisticien d’utiliser l’information disponible (pour une
analyse et une d´efense de la minimaxit´e, voir Brown, 1993, et Strawderman,
2000.)
La notion de minimaxit´e fournit une bonne illustration des aspects conser-
vateurs du paradigme fr´equentiste. Puisque cette approche refuse de faire la
moindre hypoth`ese sur le param`etre θ, elle doit consid´erer les pires cas comme
´egalement probables et n´ecessite alors de se ﬁxer sur le risque maximal. En
r´ealit´e, d’un point de vue bay´esien, cela ´equivaut souvent `a prendre une dis-
tribution a priori concentr´ee sur ces pires cas (voir la Section 2.4.3). Dans
la plupart des cas, ce point de vue est trop conservateur parce que certaines
valeurs du param`etre sont moins vraisemblables que d’autres.

74
2 Les bases de la Th´eorie de la D´ecision
Exemple 2.16. Les premi`eres plates-formes p´etroli`eres en mer du Nord ont
´et´e construites selon un principe de minimaxit´e. En eﬀet, elles ´etaient sup-
pos´ees r´esister `a l’action conjugu´ee des plus fortes houles et des plus fortes
tempˆetes jamais observ´ees, sous une temp´erature minimale record. Cette
strat´egie donne ´evidemment une marge confortable de s´ecurit´e, mais elle est
tr`es coˆuteuse. Pour des plates-formes plus r´ecentes, les ing´enieurs ont pris en
compte la distribution de ces ph´enom`enes climatiques aﬁn de r´eduire les coˆuts
de construction.
∥
Exemple 2.17. Une ﬁle d’attente `a un feu rouge est en g´en´eral correctement
repr´esent´ee par une loi de Poisson. Le nombre de voitures qui arrivent durant le
temps d’observation, N, est donc distribu´e selon P(λ), avec un param`etre de
moyenne λ devant ˆetre estim´e. ´Evidemment, les valeurs de λ au-dessus d’une
certaine limite sont assez invraisemblables. Par exemple, si λ0 est le nombre
de voitures dans toute la ville, le nombre moyen de voitures qui attendent `a
un feu n’exc´edera pas λ0. Cependant, il peut arriver que certains estimateurs
ne soient pas minimax parce que leur risque d´epasse ¯R pour les plus grandes
valeurs de λ.
∥
L’exemple ci-dessus n’est pas forc´ement une critique du principe minimax,
mais illustre plutˆot le fait qu’une certaine information r´esiduelle est disponible
dans la plupart des probl`emes et pourrait ˆetre utilis´ee, mˆeme de mani`ere
marginale. De la mˆeme fa¸con, l’Exemple 2.18 exhibe deux estimateurs, δ1 et
δ2, tels que δ1 a un risque minimax constant de ¯R et δ2 a un risque qui peut
ˆetre aussi bas que ¯R/10 mais d´epasse l´eg`erement ¯R pour des valeurs plus larges
du param`etre (voir la Figure 2.2). Donc, selon le principe minimax, δ1 devrait
ˆetre pr´ef´er´e `a δ2, mˆeme si les valeurs de θ pour lesquelles δ1 domine δ2 sont
plus invraisemblables (voir l’Exercice 2.28 pour un autre exemple frappant).
Exemple 2.18. Pour des raisons expos´ees dans la Note 2.8.2, nous consid´e-
rons l’estimateur suivant
δ2(x) =
⎧
⎨
⎩

1 −2p −1
||x||2

x
si ||x||2 ≥2p −1,
0
sinon,
pour estimer θ ∈Rp quand x ∼Np(θ, Ip). Cet estimateur, dit partie positive
de l’estimateur de James-Stein, est ´evalu´e sous le coˆut quadratrique,
L(θ, d) = ||θ −d||2.
La Figure 2.2 donne une comparaison des fonctions de risque respectives de δ2
et δ1(x) = x, estimateur du maximum de vraisemblance, pour p = 10. Cette
ﬁgure montre que δ2 ne peut pas ˆetre minimax, car le risque maximum de δ2 est

2.4 Deux optimalit´es : minimaxit´e et admissibilit´e
75
sup´erieur au risque (constant) de δ1, c’est-`a-dire R(θ, δ2) = Eθ[||θ−δ2(x)||2] =
p. (Nous montrerons dans la Section 2.4.3 que δ1 est en eﬀet un estimateur
minimax dans ce cas.) Mais l’estimateur δ2 est clairement sup´erieur dans la
partie la plus int´eressante de l’espace des param`etres, le coˆut suppl´ementaire
´etant d’ailleurs relativement minime.
∥
0
2
4
6
8
10
0
2
4
6
8
10
theta
Fig. 2.2. Comparaison des risques des estimateurs δ1 et δ2.
Les divergences entre l’analyse bay´esienne et l’analyse minimax sont
illustr´ees par l’exemple suivant, emprunt´e `a la Th´eorie des Jeux (puisqu’il
n’y a ni observation ni mod`ele statistique).
Exemple 2.19. Deux personnes, A et B, suspect´ees d’ˆetre complices d’un
cambriolage, sont arrˆet´ees et plac´ees dans des cellules s´epar´ees. Les deux sus-
pects ont ´et´e interrog´es et on leur a sugg´er´e d’avouer le cambriolage. Bien
qu’ils ne puissent pas ˆetre condamn´es sans que l’un d’entre eux ait avou´e,
celui qui avoue le premier verra sa peine r´eduite. Le Tableau 2.1 fournit la
perception de la r´ecompense selon A (en ann´ees de libert´e), o`u a1 (resp. θ1)
repr´esente le fait que A (resp. B) avoue. Les deux suspects ont un gain maxi-
mal s’ils se taisent tous les deux. Cependant, du point de vue de A, la strat´egie
minimax d’ˆetre le premier `a parler, soit donc a1, puisque maxθ R(a1, θ) = 4
et maxθ R(a2, θ) = 10. Par cons´equent, les deux cambrioleurs se retrouveront
en prison !
Tab. 2.1. Fonction d’utilit´e U(θi, aj).
a1
a2
θ1
−4
−10
θ2
8
30
Au contraire, si π est la probabilit´e (subjective) que A associe `a l’´ev´enement
“B parle”, soit, `a θ1, le risque de Bayes de a1 est

76
2 Les bases de la Th´eorie de la D´ecision
r(π, a1) = Eπ[−U(θ, a1)] = 4π −8(1 −π) = 12π −8
et pour a2,
r(π, a2) = Eπ[−U(θ, a2)] = 10π −30(1 −π) = 40π −30 .
On v´eriﬁe simplement que, pour π ≤11/14, r(π, a2) est plus petit que r(π, a1).
Par cons´equent, `a moins que A ne soit persuad´e que B va parler, il vaut mieux
pour A ne rien dire.
∥
2.4.3 Existence d’une r`egle minimax et d’une strat´egie maximin
Une diﬃcult´e importante li´ee `a la notion de minimaxit´e est que les es-
timateurs minimax n’existent pas n´ecessairement. Ferguson (1967) et Ber-
ger (1985b, Chapitre 5) donnent des conditions suﬃsantes. En particulier, il
existe une strat´egie minimax quand Θ est ﬁni et la fonction de coˆut est conti-
nue. Plus g´en´eralement, Brown (1976) (voir aussi Le Cam, 1986, et Strasser,
1985) consid`ere l’espace de d´ecision D comme plong´e dans un autre espace de
mani`ere telle que l’ensemble des fonctions de risque sur D est compact dans ce
grand espace. Dans cette perspective et sous des hypoth`eses suppl´ementaires,
il est alors possible de construire des estimateurs minimax lorsque la fonc-
tion de coˆut est continue. Cependant, ces extensions impliquent l’utilisation
de techniques topologiques trop avanc´ees pour ˆetre consid´er´ees dans cet ou-
vrage. Par cons´equent, nous ne donnerons ici que le r´esultat suivant (voir
Blackwell et Girshick, 1954, pour une d´emonstration).
Th´eor`eme 2.20. Si D ⊂Rk est convexe et compact et si L(θ, d) est conti-
nue et convexe en tant que fonction de d, pour chaque θ ∈Θ, il existe un
estimateur minimax non randomis´e.
La restriction `a des estimateurs non randomis´es d´ecoule de l’in´egalit´e de
Jensen, puisque, lorsque la fonction de coˆut est convexe,
L(θ, δ∗) = Eδ∗[L(θ, δ)] ≥L(θ, Eδ∗(δ)).
Ce r´esultat est un cas particulier du th´eor`eme de Rao-Blackwell (voir Lehmann
et Casella, 1998).
Exemple 2.21. (Suite de l’Exemple 2.13) L’estimateur randomis´e δ∗est
uniform´ement domin´e pour toute fonction de coˆut convexe par l’estimateur
non randomis´e Eδ∗[δ∗(x1, x2)], soit
˜δ(x1, x2) =

1
2(x1 + x2)
si x1 ̸= x2,
1
2(x1 −1) + 1
2(x1 + 1) = x1
sinon,
qui est en fait identique `a l’estimateur δ0 consid´er´e initialement. Notons que
cela n’est pas vrai pour le coˆut 0 −1, pour lequel δ∗domine ˜δ.
∥

2.4 Deux optimalit´es : minimaxit´e et admissibilit´e
77
Le r´esultat suivant met en avant la connexion entre approche bay´esienne
et principe minimax, dont la d´emonstration est imm´ediate.
Lemme 2.22. Le risque de Bayes est toujours plus petit que le risque mini-
max,
R = sup
π r(π) = sup
π
inf
δ∈D r(π, δ) ≤¯R = inf
δ∈D∗sup
θ
R(θ, δ).
La premi`ere valeur est dite risque maximin et une distribution π∗telle
que r(π∗) = R est appel´ee distribution a priori la moins favorable, quand
de telles distributions existent. En g´en´eral, la borne sup´erieure r(π∗) est at-
teinte plutˆot par une distribution impropre pouvant s’exprimer comme une
limite de distributions a priori propres πn. Mais ce ph´enom`ene n’empˆeche pas
n´ecessairement la construction d’estimateurs minimax (voir le Lemme 2.27).
Quand elles existent, les distributions les moins favorables sont celles qui ont
le risque de Bayes le plus grand, donc aussi les moins int´eressantes en terme
de coˆut lorsqu’elles ne sont pas sugg´er´ees par l’information a priori disponible.
Le r´esultat ci-dessus est assez logique au sens o`u l’information a priori ne peut
qu’am´eliorer l’erreur d’estimation, mˆeme dans le pire des cas.
Un cas particuli`erement int´eressant correspond `a la d´eﬁnition suivante.
D´eﬁnition 2.23. Un probl`eme d’estimation est dit admettre une valeur si
R = ¯R, c’est-`a-dire quand
sup
π
inf
δ∈D r(π, δ) = inf
δ∈D∗sup
θ
R(θ, δ).
Quand le probl`eme admet une valeur, certains estimateurs minimax sont
des estimateurs de Bayes correspondant aux lois a priori les moins favorables.
Cependant, ils peuvent ˆetre randomis´es comme le d´emontre l’exemple suivant.
Par cons´equent le principe minimax ne fournit pas toujours des estimateurs
acceptables.
Exemple 2.24. Soit21 une observation de Bernoulli, x ∼Be(θ) avec θ ∈
{0.1, 0.5}. Quatre estimateurs non randomis´es sont disponibles,
δ1(x) = 0.1,
δ2(x) = 0.5,
δ3(x) = 0.1 Ix=0 + 0.5 Ix=1,
δ4(x) = 0.5 Ix=0 + 0.1 Ix=1.
Nous supposons de plus que la p´enalit´e pour une r´eponse incorrecte est 2
quand θ = 0.1 et 1 quand θ = 0.5. Les vecteurs de risque (R(0.1, δ), R(0.5, δ))
des quatre estimateurs sont alors, respectivement, (0, 1), (2, 0), (0.2, 0.5), et
(1.8, 0.5). Il est simple de voir que le vecteur de risque de chaque estimateur
randomis´e est une combinaison convexe de ces quatre estimateurs ou, d’une
21Les calculs dans cet exemple sont assez simples. Si besoin, voir le Chapitre 8
pour les d´etails.

78
2 Les bases de la Th´eorie de la D´ecision
fa¸con ´equivalente, que l’ensemble de risques, R, est l’enveloppe convexe des
quatre vecteurs ci-dessus, comme le repr´esente la Figure 2.3.
Dans ce cas, l’estimateur minimax est obtenu `a l’intersection de la diago-
nale de R2 avec la fronti`ere inf´erieure de R. Comme le montre la Figure 2.3,
cet estimateur δ∗est randomis´e et prend la valeur δ3(x) avec une probabilit´e
α = 0.87 et δ2(x) avec une probabilit´e 1 −α. Le poids α est en eﬀet obtenu
par l’´equation
0.2α + 2(1 −α) = 0.5α.
Cet estimateur δ∗est aussi un estimateur (randomis´e) de Bayes pour la loi a
priori
π(θ) = 0.22 I0.1(θ) + 0.78 I0.5(θ);
la probabilit´e a priori π1 = 0.22 correspond `a la pente entre (0.2, 0.5) et (2, 0),
soit,
π1
1 −π1
=
0.5
2 −0.2.
Notons que tout estimateur randomis´e qui est une combinaison de δ2 et de δ3
est un estimateur de Bayes pour cette distribution, mais que seul δ∗est aussi
un estimateur minimax.
∥
0.0
0.5
1.0
1.5
2.0
0.0
0.2
0.4
0.6
0.8
1.0
R(0.1, δ)
R(0.5, δ)
δ1
δ2
δ3
δ4
Δ
Fig. 2.3.
Ensemble de risques pour l’estimation du param`etre de la distribution
de Bernoulli et diagonale Δ.

2.4 Deux optimalit´es : minimaxit´e et admissibilit´e
79
`A l’instar des estimateurs minimax, une distribution la moins favorable
n’existe pas forc´ement, car son existence d´epend d’un th´eor`eme d’hyperplan
s´eparateur qui n’est pas toujours v´eriﬁ´e (voir Pierce, 1973, Brown, 1976, Ber-
ger, 1985b, et le Chapitre 8). De plus, Strawderman (1971) montre que, dans le
cas particulier o`u x ∼Np(θ, Ip), il n’existe pas d’estimateur de Bayes r´egulier
qui soit minimax lorsque p ≤4.
D’un point de vue plus pratique, le Lemme 2.22 fournit des conditions
suﬃsantes de minimaxit´e.
Lemme 2.25. Si δ0 est un estimateur de Bayes pour π0 et si R(θ, δ0) ≤r(π0)
pour tout θ dans le support de π0, δ0 est minimax et π0 est la distribution la
moins favorable.
Exemple 2.26. (Berger, 1985b) Soit x ∼B(n, θ) o`u θ est `a estimer sous un
coˆut quadratique,
L(θ, δ) = (δ −θ)2 .
L’estimateur de Bayes est alors donn´e par les esp´erances a posteriori (voir la
Section 2.5) et quand θ ∼Be
 √n
2 ,
√n
2

, l’esp´erance a posteriori est
δ∗(x) = x + √n/2
n + √n .
De plus, cet estimateur a un risque constant, R(θ, δ∗) = 1/4(1 + √n)2. Par
cons´equent, en int´egrant sur θ, r(π) = R(θ, δ∗) et δ∗est minimax selon le
Lemme 2.25. Notons la diﬀ´erence avec l’estimateur du maximum de vraisem-
blance, δ0(x) = x/n, pour des petites valeurs de n et la concentration irr´ealiste
de l’a priori dans un voisinage de 0.5 pour les valeurs les plus grandes de n. ∥
Puisque les estimateurs minimax correspondent g´en´eralement `a des esti-
mateurs de Bayes g´en´eralis´es, on doit souvent recourir `a un argument limite
pour ´etablir la minimaxit´e, plutˆot que de calculer directement le risque de
Bayes comme dans le Lemme 2.25.
Lemme 2.27. S’il existe une suite (πn) de lois a priori propres telles que
l’estimateur de Bayes g´en´eralis´e δ0 satisfasse
R(θ, δ0) ≤lim
n→∞r(πn) < +∞
pour tout θ ∈Θ, alors δ0 est minimax.
Exemple 2.28. Quand x ∼N (θ, 1), l’estimateur de maximum de vraisem-
blance δ0(x) = x est un estimateur de Bayes g´en´eralis´e par rapport `a la mesure
de Lebesgue sur R, pour le coˆut quadratique. Puisque
R(δ0, θ) = Eθ(x −θ)2 = 1 ,

80
2 Les bases de la Th´eorie de la D´ecision
ce risque est la limite du risque de Bayes r(πn) quand πn est ´egal `a N (0, n),
comme
r(πn) =
n
n + 1 .
Par cons´equent, l’estimateur de maximum de vraisemblance δ0 est minimax.
Notons que cet argument peut ˆetre ´etendu directement au cas x ∼Np(θ, Ip)
pour ´etablir que δ0 est minimax pour tout p.
∥
Quand l’espace Θ est compact, une description exacte des r`egles (ou des
estimateurs) de Bayes minimax est disponible. Ceci d´ecoule du principe des
z´eros s´epar´es pour les nombres complexes : si la fonction R(θ, δπ) n’est pas
constante et est analytique, l’ensemble des θ tels que R(θ, δπ) est maximal est
un ensemble s´epar´e et, dans le cas d’un ensemble compact Θ, forc´ement ﬁni.
Th´eor`eme 2.29. Consid´erons un probl`eme statistique admettant simultan´e-
ment une valeur, une loi la moins favorable π0, et un estimateur minimax
δπ0. Alors, si Θ ⊂R est compact et si R(θ, δπ0) est une fonction analytique
de θ, soit π0 a un support ﬁni, soit R(θ, δπ0) est constant.
Exemple 2.30. Soit x ∼N (θ, 1), avec |θ| ≤m, c’est-`a-dire θ ∈[−m, m].
Alors, selon le Th´eor`eme 2.29, les lois les moins favorables ont n´ecessairement
un support ﬁni, {±θi, 1 ≤i ≤ω}, avec un cardinal 2ω ou 2ω −1 et des points
de support θi d´ependant de m. En eﬀet, le seul estimateur `a risque constant est
δ0(x) = x, qui n’est pas minimax dans ce cas. En g´en´eral, la d´etermination
exacte de n et des points de θi ne peut ˆetre faite que num´eriquement. Par
exemple, quand m ≤1.06, la loi a priori avec pour poids 1/2 en ±m est la
seule distribution a priori la moins favorable. Pour 1.06 ≤m ≤2, le support de
π contient −m, 0, et m. Voir Casella et Strawderman (1981) et Bickel (1981)
pour plus de d´etails, et Johnstone et MacGibbon (1992) pour un traitement
similaire du mod`ele de Poisson.
∥
Les exemples ci-dessus montrent pourquoi le principe minimax, bien
qu’´etroitement li´e au paradigme bay´esien, n’est pas n´ecessairement attirant
d’un point de vue bay´esien. En eﬀet, mis `a part le fait que les estimateurs
minimax sont parfois randomis´es, comme dans l’Exemple 2.24, les Exemples
2.26 et 2.30 montrent que les lois a priori les moins favorables sont souvent
irr´ealistes, car conduisant `a un fort biais a priori vers quelques points de
l’espace d’´echantillonnage. Pour l’Exemple 2.30, Gatsonis et al. (1987) ont
montr´e que les lois a priori uniformes sont de bons substituts `a des lois a
priori `a support discret, mˆeme si elles ne sont pas minimax.
Des extensions du Th´eor`eme 2.29 au cas non compact sont donn´ees dans
Kempthorne (1988). Dans un cadre multidimensionnel, quand le probl`eme est
invariant par rotation, les lois les moins favorables sont uniformes sur une suite
de sph`eres imbriqu´ees (voir Robert et al., 1990). Le probl`eme pratique de la

2.4 Deux optimalit´es : minimaxit´e et admissibilit´e
81
d´etermination des points du support est consid´er´e par Kempthorne (1988) et
Eichenauer et Lehn (1989).
Lorsqu’un probl`eme admet une valeur, il est souvent diﬃcile de construire
la loi la moins favorable. Des m´ethodes alternatives pour obtenir un esti-
mateur minimax sont alors n´ecessaires. Le Chapitre 9 montre comment la
d´etermination de certaines structures d’invariance du mod`ele peut conduire `a
l’identiﬁcation du meilleur estimateur ´equivariant et `a un estimateur minimax
(th´eor`eme de Hunt-Stein). Malheureusement, les conditions sous lesquelles ce
th´eor`eme peut s’appliquer sont diﬃciles `a v´eriﬁer et sont rarement satisfaites.
Finalement, une fois qu’on a obtenu un estimateur minimax, il reste `a
d´eterminer s’il est optimal ou non : plusieurs estimateurs minimax peuvent
exister simultan´ement et certains d’entre eux peuvent dominer uniform´ement
d’autres. Il est alors n´ecessaire de pr´esenter un deuxi`eme crit`ere, plus local,
pour comparer les estimateurs minimax, qui sont des estimateurs ayant de
bonnes performances globales.
2.4.4 Admissibilit´e
Ce deuxi`eme crit`ere fr´equentiste induit un ordre partiel sur D∗en compa-
rant les risques fr´equentistes des estimateurs R(θ, δ).
D´eﬁnition 2.31. Un estimateur δ0 est inadmissible s’il existe un estimateur
δ1 qui domine δ0, c’est-`a-dire tel que pour tout θ,
R(θ, δ0) ≥R(θ, δ1)
et, pour au moins une valeur θ0 du param`etre,
R(θ0, δ0) > R(θ0, δ1) .
Sinon, δ0 est dit admissible.
Ce crit`ere est particuli`erement int´eressant pour son action r´eductrice. Ef-
fectivement, du moins en th´eorie, il semble logique de soutenir que les estima-
teurs inadmissibles ne devraient pas ˆetre consid´er´es du tout, puisqu’ils peuvent
ˆetre am´elior´es uniform´ement. Par exemple, le th´eor`eme de Rao-Blackwell im-
plique alors que, pour des fonctions de coˆut convexes, les estimateurs rando-
mis´es et plus g´en´eralement ceux d´ependant d’autres quantit´es que les statis-
tiques exhaustives sont inadmissibles. Cependant, l’admissibilit´e `a elle seule
n’est pas suﬃsante pour valider l’utilisation d’un estimateur. Par exemple,
les estimateurs constants δ(x) = θ0 sont en g´en´eral admissibles parce qu’ils
fournissent une valeur exacte pour θ = θ0. D’un point de vue fr´equentiste, il
est donc important de chercher des estimateurs qui satisfassent les deux opti-
malit´es : minimaxit´e et admissibilit´e. Dans cette optique, on peut mentionner
les r´esultats suivants.

82
2 Les bases de la Th´eorie de la D´ecision
Proposition 2.32. S’il existe un unique estimateur minimax, cet estimateur
est admissible.
Preuve.
Si δ∗est le seul estimateur minimax, pour tout estimateur ˜δ ̸= δ∗,
sup
θ
R(θ, ˜δ) > sup
θ
R(θ, δ∗).
Donc, ˜δ ne peut pas dominer δ∗.
⊓⊔
Notons que la r´eciproque de ce r´esultat est fausse, car il peut exister plusieurs
estimateurs minimax admissibles. Par exemple, dans le cas Np(θ, Ip), il existe
des estimateurs de Bayes r´eguliers minimax pour p ≥5 (Strawderman, 1971 et
Fourdrinier et al., 1998). Quand la fonction de coˆut L est absolument convexe
(en d), la caract´erisation suivante est aussi possible.
Proposition 2.33. Si δ0 est admissible de risque constant, δ0 est l’unique
estimateur minimax.
Preuve.
Pour tout θ0 ∈Θ, supθ R(θ, δ0) = R(θ0, δ0). Alors, s’il existe δ1 tel
que ¯R ≤supθ R(θ, δ1) < R(θ0, δ0), δ0 ne peut pas ˆetre admissible. De la mˆeme
fa¸con, si
¯R = sup
θ
R(θ, δ1) = R(θ0, δ0)
et si θ1 est tel que R(θ1, δ1) < ¯R, δ1 domine δ0. Par cons´equent, quand δ0 est
admissible, le seul cas possible est qu’il existe δ1 tel que R(θ, δ1) = R(θ, δ0)
pour tout θ ∈Θ. Ce qui est aussi impossible quand δ0 est admissible (voir
l’Exercice 2.36).
⊓⊔
Remarquons `a nouveau que la r´eciproque de ce r´esultat est fausse. Il peut
exister des estimateurs minimax ayant un risque constant qui soient inad-
missibles. En fait, ils sont inadmissibles d`es qu’il existe d’autres estimateurs
minimax. C’est le cas par exemple pour δ0(x) = x quand x ∼Np(θ, Ip) et
p ≥3 (voir la Note 2.8.2 et l’Exercice 2.57). Il y a aussi des cas o`u il n’existe
pas d’estimateur minimax admissible (il faut pour cela qu’il n’existe pas de
classe minimale compl`ete, voir le Chapitre 8).
Nous avons vu dans la section pr´ec´edente que la minimaxit´e pouvait ˆetre
parfois consid´er´ee, dans une perspective bay´esienne, comme un choix par la
“Nature” d’une strat´egie maximin (loi la moins favorable), π, donc que cer-
tains estimateurs minimax sont des estimateurs de Bayes. La notion d’admis-
sibilit´e est encore plus fortement li´ee au paradigme bay´esien au sens o`u, dans
la plupart des probl`emes statistiques, les estimateurs de Bayes “engendrent”
la classe des estimateurs admissibles, c’est-`a-dire que ces derniers peuvent ˆetre
´ecrits comme des estimateurs de Bayes (ou estimateurs de Bayes g´en´eralis´es)
ou comme limites d’estimateurs de Bayes. Le Chapitre 8 est consacr´e plus
en d´etail aux relations entre estimateurs de Bayes et admissibilit´e. Nous ne
donnerons ici que deux r´esultats importants.

2.4 Deux optimalit´es : minimaxit´e et admissibilit´e
83
Proposition 2.34. Si la distribution a priori π est strictement positive sur
Θ, de risque de Bayes ﬁni, et la fonction de risque R(θ, δ) est une fonction
continue de θ pour tout δ, l’estimateur de Bayes δπ est admissible.
Preuve.
Supposons δπ inadmissible. Soit δ′ un estimateur dominant uni-
form´ement δπ. Alors, pour tout θ, R(θ, δ′) ≤R(θ, δπ) et, dans tout ensemble
ouvert C de Θ, R(θ, δ′) < R(θ, δπ). Par int´egration de cette in´egalit´e, on
obtient
r(π, δ′) < r(π, δπ) =

Θ
R(θ, δπ)π(θ) dθ,
ce qui est impossible.
⊓⊔
Proposition 2.35. Si l’estimateur de Bayes associ´e `a une loi a priori π est
unique, il est admissible.
La d´emonstration de ce r´esultat est similaire `a celle de la Proposition 2.32.
Mˆeme si l’estimateur de Bayes n’est pas unique, il reste possible de pr´esenter
au moins un estimateur de Bayes admissible. Quand la fonction de coˆut est
strictement convexe, l’estimateur de Bayes est n´ecessairement unique et donc
admissible, selon la proposition ci-dessous.
Exemple 2.36. (Suite de l’Exemple 2.26) L’estimateur δ∗est un estima-
teur de Bayes r´egulier, donc admissible, et de risque constant. Par cons´equent,
il est l’estimateur minimax unique sous le coˆut quadratique.
∥
Notons que la Proposition 2.34 fait intervenir l’hypoth`ese d’un risque de
Bayes ﬁni. Autrement, tout estimateur est, dans un certain sens, un estimateur
de Bayes (voir l’Exercice 2.43). D’un autre cˆot´e, quelques r´esultats d’admis-
sibilit´e peuvent ˆetre ´etablis pour des lois a priori impropres. C’est la raison
pour laquelle nous pr´ef´erons appeler estimateurs de Bayes g´en´eralis´es ceux
associ´es `a un risque de Bayes inﬁni, plutˆot que les estimateurs correspondant
`a une loi a priori impropre. Ce choix implique que les estimateurs de Bayes
de diﬀ´erentes quantit´es associ´es `a la mˆeme loi a priori peuvent ˆetre respec-
tivement estimateurs de Bayes r´eguliers et estimateurs de Bayes g´en´eralis´es,
suivant ce qu’ils estiment. Ceci assure aussi que les estimateurs de Bayes
r´eguliers seront toujours admissibles, comme le d´emontre le r´esultat suivant.
Proposition 2.37. Si un estimateur de Bayes, δπ, associ´e `a une loi a priori
(propre ou impropre) π, est tel que le risque de Bayes,
r(π) =

Θ
R(θ, δπ)π(θ) dθ,
soit ﬁni, δπ est admissible.

84
2 Les bases de la Th´eorie de la D´ecision
Exemple 2.38.
Soit x ∼N (θ, 1), et on veut tester l’hypoth`ese nulle
H0 : θ ≤0 contre l’hypoth`ese alternative H1 : θ > 0. Ce probl`eme de test
est un probl`eme d’estimation si nous consid´erons l’estimation de la fonction
indicatrice IH0(θ). Sous le coˆut quadratique
(IH0(θ) −δ(x))2 ,
nous pouvons proposer l’estimateur suivant
p(x) = P0(X > x)
(X ∼N (0, 1))
= 1 −Φ(x),
dit p-value, qui est consid´er´e comme une bonne r´eponse fr´equentiste au
probl`eme de test (voir Kiefer, 1977 et Casella et Berger, 1987). En utilisant
l’Exemple 1.25, il est facile de montrer que p est un estimateur de Bayes sous
la mesure de Lebesgue et un coˆut quadratique, car π(θ|x) est la distribution
N (x, 1) et
p(x) = Eπ[IH0(θ)|x] = P π(θ < 0|x)
= P π(θ −x < −x|x) = 1 −Φ(x).
De plus, le risque de Bayes de p est ﬁni (Exercice 2.34). Par cons´equent la
p-value, en tant qu’estimateur de IH0, est admissible. (Voir la Section 5.4 pour
une analyse approfondie des propri´et´es de la p-value.)
∥
Exemple 2.39. Dans le cadre de l’exemple pr´ec´edent, si θ est le param`etre
d’int´erˆet, δ0(x) = x est un estimateur de Bayes g´en´eralis´e sous le coˆut qua-
dratique, car
r(π, δ0) =
 +∞
−∞
R(θ, δ0) dθ =
 +∞
−∞
1 dθ = +∞.
La Proposition 2.35 ne permet donc pas dans ce cas de d´eterminer l’admissi-
bilit´e de δ0. Bien que δ0 soit en r´ealit´e admissible, son admissibilit´e doit ˆetre
´etablie `a l’aide d’une suite de lois a priori propres, comme nous le montrerons
dans le Chapitre 8.
∥
Exemple 2.40. Soit x ∼Np(θ, Ip). Si le param`etre d’int´erˆet est ||θ||2 et la
loi a priori est la mesure de Lebesgue sur Rp, puisque Eπ[||θ||2|x] = E[||y||2],
avec y ∼Np(x, Ip), l’estimateur de Bayes sous le coˆut quadratique est
δπ(x) = ||x||2 + p.
Cet estimateur de Bayes g´en´eralis´e n’est pas admissible parce qu’il est do-
min´e par δ0(x) = ||x||2 −p (Exercice 2.35). (Puisque le risque classique est
R(θ, δπ) = var(∥x∥2) + 4p2, le risque de Bayes est bien inﬁni.) Ce ph´enom`ene
montre que la mesure de Lebesgue n’est pas n´ecessairement le meilleur choix
d’une mesure a priori non informative quand le param`etre d’int´erˆet est un
sous-vecteur du param`etre (voir le Chapitre 3).
∥

2.5 Fonctions de coˆut usuelles
85
2.5 Fonctions de coˆut usuelles
Quand le contexte d’une exp´erience ne permet pas une d´etermination
de la fonction d’utilit´e (manque de temps, information, etc.), une alterna-
tive courante est de faire appel `a des fonctions de coˆut classiques, qui sont
math´ematiquement simples et de propri´et´es connues. Bien entendu, cette ap-
proche est une approximation sous-jacente du mod`ele statistique et ne devrait
ˆetre utilis´ee que quand la fonction d’utilit´e n’est pas disponible. Nous ﬁnissons
cette section par une note sur des fonctions de coˆut plus intrins`eques, mˆeme
si celles-ci sont rarement utilis´ees en pratique. (Voir aussi la Note 2.8.1 pour
une description des fonctions de coˆut utilis´ees en analyse d’image.)
2.5.1 Le coˆut quadratique
Introduit par Legendre (1805) et Gauss (1810), ce coˆut est sans conteste
le crit`ere d’´evaluation le plus commun. Fondant sa validit´e sur l’ambigu¨ıt´e de
la notion d’erreur dans un contexte statistique (soit erreur de mesure, soit
variation al´eatoire), il a aussi donn´e lieu `a de nombreuses critiques, la plus
fr´equente ´etant sans doute le fait que le coˆut quadratique
L(θ, d) = (θ −d)2
(2.2)
p´enalise trop fortement les grandes erreurs.
Cependant, les fonctions de coˆut convexes comme (2.2) ont l’avantage in-
comparable d’´eviter le paradoxe des amateurs de risque (traduction de risk
lovers) et d’exclure les estimateurs randomis´es. Une autre justiﬁcation ha-
bituelle pour le coˆut quadratique est que celui-ci peut ˆetre vu comme le
d´eveloppement limit´e d’un coˆut sym´etrique plus complexe (voir l’Exercice
4.15 pour un contre-exemple). Dans son article de 1810, Gauss reconnaissait
d´ej`a l’arbitraire du coˆut quadratique mais le d´efendait au nom de la simplicit´e.
Bien que les critiques concernant l’utilisation syst´ematique de la fonction de
coˆut quadratique soient fond´ees, son usage est n´eanmoins tr`es r´epandu, car
il donne en g´en´eral des solutions bay´esiennes qui sont celles naturellement
fournies comme estimateurs pour une inf´erence non d´ecisionnelle fond´ee sur
une distribution a priori. En eﬀet, les estimateurs de Bayes associ´es au coˆut
quadratique sont les moyennes a posteriori. Cependant, notons que le coˆut
quadratique n’est pas le seul coˆut `a avoir cette caract´eristique. Les fonctions
de coˆut conduisant `a la moyenne a posteriori comme estimateur de Bayes sont
appel´ees fonctions de coˆut propres et ont ´et´e identiﬁ´ees par Lindley (1985),
Schervish (1989), der Meulen B. (1992), et Hwang et Pemantle (1994) (voir
aussi l’Exercice 2.15).
Proposition 2.41. L’estimateur de Bayes δπ associ´e `a la loi a priori π et
au coˆut quadratique (2.2) est la moyenne a posteriori

86
2 Les bases de la Th´eorie de la D´ecision
δπ(x) = Eπ[θ|x] =

Θ θf(x|θ)π(θ) dθ

Θ f(x|θ)π(θ) dθ .
Preuve.
Comme
Eπ[(θ −δ)2|x] = Eπ[θ2|x] −2δEπ[θ|x] + δ2,
le minimum du coˆut a posteriori est eﬀectivement atteint par δπ(x) = Eπ[θ |
x].
⊓⊔
Les corollaires suivants se d´eduisent de mani`ere imm´ediate.
Corollaire 2.42. L’estimateur de Bayes δπ associ´e `a π et au coˆut quadra-
tique pond´er´e
L(θ, δ) = ω(θ)(θ −δ)2,
(2.3)
o`u ω(θ) est une fonction positive, est
δπ(x) = Eπ[ω(θ)θ|x]
Eπ[ω(θ)|x] .
Corollaire 2.43. Quand Θ ∈Rp, l’estimateur de Bayes δπ associ´e `a π et au
coˆut quadratique,
L(θ, δ) = (θ −δ)tQ(θ −δ),
est la moyenne a posteriori, δπ(x) = Eπ[θ|x], pour toute matrice Q p × p
sym´etrique d´eﬁnie positive.
Le Corollaire 2.42 exhibe une dualit´e (faible) entre coˆut et loi a priori, au
sens o`u il revient au mˆeme d’estimer θ sous (2.3) avec la loi π, ou sous (2.2)
avec la loi πω(θ) ∝π(θ)ω(θ). De plus, bien que la notion d’admissibilit´e soit
ind´ependante de la fonction ω, l’estimateur de Bayes en d´epend fortement. Par
exemple, δπ peut ne pas exister si ω croˆıt trop vite vers +∞. D’un autre cˆot´e,
le Corollaire 2.43 montre la robustesse de l’estimateur de Bayes par rapport `a
la forme quadratique de Q. (Shinozaki, 1975, a aussi montr´e que le caract`ere
admissible ne d´epend pas de Q.)
Le coˆut quadratique est particuli`erement int´eressant lorsque l’espace des
param`etres est born´e et le choix d’un coˆut plus subjectif est impossible. En
eﬀet, ce coˆut est assez simple d’utilisation et l’erreur d’approximation est
alors de faible importance. L’ind´etermination de la fonction de coˆut (et son
remplacement par une approximation quadratique) est fr´equente en ´evaluation
de la pr´ecision, qui inclut par exemple l’estimation du coˆut (Rukhin, 1988a,b,
Lu et Berger, 1989a,b, Hwang et al., 1992, Robert et Casella, 1993, 1994, et
Fourdrinier et Wells, 1993).
Exemple 2.44. (Suite de l’Exemple 2.21)
Nous cherchons `a ´evaluer la
performance de l’estimateur

2.5 Fonctions de coˆut usuelles
87
δ(x1, x2) =
⎧
⎨
⎩
x1 + x2
2
si x1 ̸= x2,
x1 + 1
sinon,
par α(x1, x2) sous le crit`ere quadratique
[Iθ(δ(x1, x2)) −α(x1, x2)]2 ,
o`u Iθ(v) vaut 1 si v = θ, 0 sinon ; la fonction α estime donc d’une certaine
fa¸con la probabilit´e que δ prenne la vraie valeur θ. (Ceci est un cas particulier
d’estimation de coˆut, pour la fonction de coˆut 1 −Iθ(δ).) Deux estimateurs
peuvent ˆetre consid´er´es :
(i) α0(x1, x2) = 0.75, qui donne l’esp´erance de Iθ(δ(x1, x2)) ; et
(ii) α1(x1, x2) =

1
si x1 ̸= x2,
0.50
si x1 = x2.
Le risque des deux estimateurs est alors
R(θ, α0) = Eθ (Iθ(δ(x1, x2)) −0.75)2
= 0.75 −(0.75)2 = 0.1875
et
R(θ, α1) = Eθ (Iθ(δ(x1, x2)) −α1(x1, x2))2
= (0.5)2 1
2 = 0.125 .
Par cons´equent, α1 est un meilleur estimateur des performances de δ que α0.
Pr´esent´e dans Berger et Wolpert (1988), ce r´esultat de domination est assez
logique et sugg`ere qu’une ´evaluation conditionnelle des estimateurs est plus
appropri´ee.
∥
2.5.2 L’erreur de coˆut absolu
Une solution alternative au coˆut quadratique en dimension un est d’utiliser
le coˆut absolu,
L(θ, d) =| θ −d |,
(2.4)
d´ej`a consid´er´e par Laplace (1773) ou, plus g´en´eralement, une fonction lin´eaire
par morceaux
Lk1,k2(θ, d) =

k2(θ −d)
si θ > d,
k1(d −θ)
sinon.
(2.5)
De telles fonctions croissent plus lentement que le coˆut quadratique. Par
cons´equent, tout en restant convexes, elles ne surp´enalisent pas des erreurs

88
2 Les bases de la Th´eorie de la D´ecision
grandes mais peu vraisemblables. Huber (1964a) propose aussi un m´elange
des fonctions coˆuts absolues et quadratiques, pour maintenir une p´enalisation
quadratique aux alentours de 0,
˜L(θ, d) =

(d −θ)2
si | d −θ |< k,
2k | d −θ | −k2
sinon.
Bien que convexe22, le coˆut mixte ralentit la progression du coˆut quadratique
pour des grandes erreurs et robustiﬁe son eﬀet. Malheureusement, il n’existe
pas en g´en´eral de formule explicite des estimateurs de Bayes sous cette fonction
de coˆut.
Proposition 2.45. L’estimateur de Bayes associ´e `a la loi a priori π et `a la
fonction de coˆut lin´eaire par morceaux (2.5) est le fractile (k2/(k1 + k2)) de
π(θ|x).
Preuve.
L’´equation classique suivante,
Eπ[Lk1,k2(θ, d)|x] = k1
 d
−∞
(d −θ)π(θ|x) dθ + k2
 +∞
d
(θ −d)π(θ|x) dθ
= k1
 d
−∞
P π(θ < y|x) dy + k2
 +∞
d
P π(θ > y|x) dy,
est obtenue par une int´egration par parties. D´erivant en d, on obtient
k1P π(θ < d|x) −k2P π(θ > d|x) = 0,
soit encore
P π(θ < d|x) =
k2
k1 + k2
.
⊓⊔
En particulier, si k1 = k2, soit, dans le cas du coˆut absolu, l’estimateur
de Bayes est la m´ediane a posteriori, qui est l’estimateur obtenu par Laplace
(voir l’Exemple 1.11). Notons que, quand π a un support non connexe, la
Proposition 2.45 fournit des exemples d’estimateurs de Bayes multiples pour
certaines valeurs de x (voir l’Exercice 2.40).
22De nouveau, si nous insistons sur la convexit´e, c’est parce qu’elle assure que
les estimateurs randomis´es sont sous-optimaux d’un point de vue fr´equentiste. Par
cons´equent, une approche d´ecisionnelle statistique qui voudrait rester le plus ﬁd`ele
possible au principe de vraisemblance impose n´ecessairement d’avoir une fonction de
coˆut convexe. Bien ´evidemment, cette exigence exclut les fonctions de coˆut born´ees.

2.5 Fonctions de coˆut usuelles
89
2.5.3 Le coˆut 0 −1
Ce coˆut est surtout utilis´e dans l’approche classique des tests d’hypoth`ese,
propos´ee par Neyman et Pearson (voir la Section 5.3). Plus g´en´eralement,
c’est un exemple typique d’un coˆut non quantitatif. En eﬀet, pour ce coˆut, la
p´enalit´e associ´ee `a un estimateur δ est 0 si la r´eponse est correcte et 1 sinon.
Exemple 2.46. Soit le test de H0 : θ ∈Θ0 contre H1 : θ ̸∈Θ0. Alors
D = {0, 1}, o`u 1 repr´esente l’acceptation de H0 et 0 son rejet. (En d’autres
termes, la fonction de θ estim´ee est IΘ0(θ).) Pour la fonction de coˆut 0 −1,
qui vaut
L(θ, d) =

1 −d
si θ ∈Θ0
d
sinon,
(2.6)
le risque associ´e est
R(θ, δ) = Eθ[L(θ, δ(x))]
=

Pθ(δ(x) = 0)
si θ ∈Θ0,
Pθ(δ(x) = 1)
sinon,
ce qui donne exactement les erreurs de premi`ere et deuxi`eme esp`ece qui sous-
tendent la Th´eorie de Neyman-Pearson .
∥
Ce coˆut n’est pas tr`es int´eressant, de par son caract`ere non quantitatif, et
nous verrons au Chapitre 5 quelques th´eories alternatives pour le test d’hy-
poth`eses. Les estimateurs de Bayes associ´es reﬂ`etent aussi l’aspect primitif
d’un tel coˆut (voir aussi l’Exercice 2.41).
Proposition 2.47. L’estimateur de Bayes associ´e `a π et au coˆut (2.6) est
δπ(x) =

1
si P(θ ∈Θ0|x) > P(θ ̸∈Θ0|x),
0
sinon,
donc δπ(x) vaut 1 si et seulement si P(θ ∈Θ0|x) > 1/2.
2.5.4 Coˆuts intrins`eques
Il peut arriver que certains probl`emes soient tellement non informatifs que
non seulement la fonction de coˆut soit inconnue, mais aussi que le mod`ele
n’admette pas une param´etrisation naturelle. Ce type de situation apparaˆıt
quand c’est la loi f(x|θ) elle-mˆeme qui nous int´eresse, par exemple dans un
contexte de pr´evision.

90
2 Les bases de la Th´eorie de la D´ecision
Cependant, comme nous l’avons ´evoqu´e dans la section pr´ec´edente, le choix
de la param´etrisation est important, car, contrairement `a l’approche du maxi-
mum de vraisemblance, si g est une transformation bijective de θ, l’estima-
teur de Bayes de g(θ) est g´en´eralement diﬀ´erent de la transformation par
g de l’estimateur de Bayes de θ sous le mˆeme coˆut (voir l’Exercice 2.36).
Ce manque d’invariance, bien qu’il soit perturbant pour les n´eophytes, n’est
g´en´eralement pas pr´eoccupant pour les d´ecideurs, car il montre comment le
paradigme bay´esien peut s’adapter `a un probl`eme d’estimation donn´e et `a
une fonction de coˆut donn´ee, tandis que l’estimation par maximum de vrai-
semblance n’est pas capable de tenir compte de la notion de coˆut. Mais les
quelques cas o`u la fonction de coˆut et la param´etrisation naturelle sont ab-
solument indisponibles peuvent n´ecessiter ce type d’invariance ultime. (Voir
Wallace et Boulton, 1975, pour une autre approche.)
Dans un tel contexte non informatif, il semble naturel d’utiliser des coˆuts
comparant directement les distributions f(·|θ) et f(·|δ) associ´ees au vrai pa-
ram`etre θ et l’estimateur δ. De telles fonctions de coˆut,
L(θ, δ) = d(f(·|θ), f(·|δ)),
sont eﬀectivement ind´ependantes de la param´etrisation. Deux distances stan-
dard pour les distributions sont
(1) la distance entropique
Le(θ, δ) = Eθ

log
f(x|θ)
f(x|δ)

,
(2.7)
dite aussi divergence de Kullback-Leibler et qui n’est pas une distance
au sens math´ematique `a cause de son asym´etrie; et
(2) la distance de Hellinger
LH(θ, δ) = 1
2 Eθ
⎡
⎣

f(x|δ)
f(x|θ) −1
 2⎤
⎦.
(2.8)
Exemple 2.48. Soit x ∼N (θ, 1). On a alors
Le(θ, δ) = 1
2Eθ[−(x −θ)2 + (x −δ)2] = 1
2(δ −θ)2,
LH(θ, δ) = 1 −exp{−(δ −θ)2/8}.
Dans le cas normal o`u π(θ|x) est une loi N (μ(x), σ2), il est trivial de
d´emontrer que l’estimateur de Bayes est μ(x) dans les deux cas.
∥
Le coˆut de Hellinger est sans doute plus intrins`eque que le coˆut entropique,
ne serait-ce que parce qu’il existe toujours (notons que (2.8) est major´e par
1). Malheureusement, bien qu’il m`ene `a des expressions explicites de LH(θ, δ)

2.6 Critiques et alternatives
91
pour les familles de distributions usuelles, il ne permet pas de calcul expli-
cite des estimateurs de Bayes, sauf dans le cas particulier trait´e ci-dessus. En
revanche, pour les familles exponentielles, le coˆut entropique fournit un esti-
mateur explicite qui est la moyenne a posteriori du param`etre naturel (voir le
Chapitre 3). De plus, bien qu’il soit assez diﬀ´erent du coˆut de Hellinger, le
coˆut entropique fournit des r´eponses similaires pour les familles de distribu-
tions habituelles (voir Robert, 1996b). Il y a aussi plusieurs raisons th´eoriques
pour d´efendre l’utilisation de la distance de Kullback-Leibler, allant de la
th´eorie de l’information (Exercice 2.48) `a l’importance de la r`egle du score
logarithmique et de l’invariance de position et d’´echelle, comme le d´etaillent
Bernardo et Smith (1994).
2.6 Critiques et alternatives
Quelques critiques des notions fr´equentistes de minimaxit´e et d’admissi-
bilit´e ont ´et´e mentionn´ees dans les sections pr´ec´edentes. Ces concepts ont en
r´ealit´e peu d’importance d’un point de vue purement bay´esien. D’une part,
l’admissibilit´e est automatiquement satisfaite par la plupart des estimateurs
de Bayes. D’autre part, la minimaxit´e est en quelque sorte incompatible avec
le paradigme bay´esien, car, sous une loi a priori, les valeurs du param`etre ne
peuvent pas ˆetre pond´er´ees de fa¸con ´egale. Cependant, la minimaxit´e peut
ˆetre pertinente en termes de robustesse, c’est-`a-dire quand l’information a
priori n’est pas suﬃsamment pr´ecise pour d´eterminer la loi a priori.
Il arrive parfois que le d´ecideur soit incapable de construire pr´ecis´ement la
fonction de coˆut. Par exemple, quand le d´ecideur est un comit´e compos´e de
plusieurs experts, il n’est pas rare que ceux-ci soient en d´esaccord sur le choix
de la fonction de coˆut (et parfois mˆeme de la distribution a priori). Partant
d’Arrow (1956), la litt´erature sur ces extensions de la Th´eorie de la D´ecision
est assez vaste (voir Genest et Zidek, 1986, Rubin, 1984, et Van Eeden et
Zidek, 1993, pour des d´etails et r´ef´erences).
Lorsque la fonction de coˆut n’a pu ˆetre enti`erement d´etermin´ee, on peut
supposer qu’elle appartient `a une famille param´etrique de fonctions de coˆut,
le d´ecideur choisissant le param`etre le plus appropri´e. Mis `a part les coˆuts Lp,
deux autres possibilit´es sont
L1(θ, δ) = log(α||θ −δ||2 + 1),
L2(θ, δ) = 1 −exp{−c||θ −δ||2}.
Une approche alternative plus en accord avec le paradigme bay´esien est de
consid´erer que, du moment que le coˆut est partiellement inconnu, cette in-
certitude peut ˆetre repr´esent´ee par une fonction de coˆut al´eatoire L(θ, δ).
L’´evaluation des estimateurs est alors obtenue en int´egrant par rapport `a
cette variable additionnelle : si F est la distribution du coˆut, la fonction `a
minimiser (en δ) est

92
2 Les bases de la Th´eorie de la D´ecision

Θ

Ω
L(θ, δ, ω)dF(ω) dπ(θ|x),
(2.9)
o`u F d´epend ´eventuellement de θ ou mˆeme de x. En r´ealit´e, ce cas est la seule
extension int´eressante, car, sinon, minimiser (2.9) revient `a utiliser le coˆut
moyen
¯L(θ, δ) =

Ω
L(θ, δ, ω) dF(ω).
Une autre approche du probl`eme de manque de pr´ecision de la fonction
de coˆut consiste `a consid´erer simultan´ement un ensemble de fonctions de coˆut
et `a construire des estimateurs ayant de bonnes performances pour toutes ces
fonctions. ´Evidemment, ce crit`ere multidimensionnel n’engendre qu’un ordre
partiel sur les estimateurs. On pourra consulter Abraham et Daur´es (2000)
et Abraham (2001) pour des perspectives int´eressantes sur cette approche
robuste des coˆuts.
Exemple 2.49. Soit x ∼Np(θ, Ip). Le param`etre θ est estim´e sous un coˆut
quadratique. Si la matrice des coˆuts Q n’est pas d´etermin´ee exactement, une
alternative robuste est de consid´erer les coˆuts associ´es aux matrices Q telles
que Q1 ⪯Q ⪯Q1 (o`u A ⪯B signiﬁe que la matrice B−A est d´eﬁnie positive).
Notons que, selon le Corollaire 2.43, l’estimateur de Bayes est le mˆeme pour
tous les Q.
∥
Exemple 2.50. Dans le cadre de l’exemple ci-dessus, Brown (1975) montre
qu’un estimateur `a r´etr´ecisseur de la forme (1−h(x))x domine δ0(x) = x pour
une classe de coˆuts quadratiques, c’est-`a-dire une classe de matrices Q, si et
seulement si
tr(Q) −2λmax(Q) > 0
(2.10)
pour toute matrice dans la classe (o`u λmax(Q) d´esigne la plus grande valeur
propre de la matrice Q). Notons que cette condition exclut le cas p ≤2, pour
lequel δ0 est en r´ealit´e admissible. La constante tr(Q) −2λmax(Q) apparaˆıt
aussi dans la constante de majoration de ||x||2h(||x||2) (voir le Th´eor`eme 2.52).
Par cons´equent, (2.10) est `a la fois une condition n´ecessaire et suﬃsante pour
avoir un ph´enom`ene de Stein (voir l’Exemple 2.18 et la Note 2.8.2).
∥
Le crit`ere ultime pour la robustesse de la fonction de coˆut est celui de la do-
mination universelle introduit par Hwang (1985). En eﬀet, ce crit`ere consid`ere
l’ensemble de toutes les fonctions de coˆut ℓ(||δ−θ||Q), pour une norme donn´ee
||x||Q = xtQx et toutes les fonctions croissantes ℓ. Un estimateur δ1 est dit
dominer universellement un autre estimateur δ2 si, pour tout ℓ,
Eθ[ℓ(||δ1(x) −θ||Q)] ≤Eθ[ℓ(||δ2(x) −θ||Q)].
Un deuxi`eme crit`ere est celui de la domination stochastique : δ1 domine sto-
chastiquement δ2 si, pour tout c > 0,

2.6 Critiques et alternatives
93
Pθ(||δ1(x) −θ||Q ≤c) ≥Pθ(||δ2(x) −θ||Q ≤c).
Bien que ce crit`ere paraisse plus intrins`eque et moins li´e `a la Th´eorie de la
D´ecision que la domination universelle, Hwang (1985) a montr´e que les deux
crit`eres sont en r´ealit´e ´equivalents.
Th´eor`eme 2.51. Un estimateur δ1 domine universellement un estimateur
δ2 si et seulement si δ1 domine stochastiquement δ2.
Preuve.
L’estimateur δ1 domine stochastiquement δ2 si, pour tout c > 0,
Pθ(||δ1(x) −θ||Q ≤c) ≥Pθ(||δ2(x) −θ||Q ≤c).
Ce qui s’´ecrit
Eθ
#
I[c,+∞[(||δ1(x) −θ||Q)
$
≤Eθ
#
I[c,+∞[(||δ2(x) −θ||Q)
$
.
Comme ℓ(t) = I[c,+∞[(t) est une fonction croissante de t, la domination uni-
verselle implique la domination stochastique. La r´eciproque d´ecoule du fait
que deux variables al´eatoires stochastiquement ordonn´ees ont ´egalement leurs
premiers moments ordonn´es.
⊓⊔
De plus, ces deux crit`eres ne sont pas vides, car Hwang (1985) a ´etablit
le r´esultat de domination suivant : Si x ∼Tα(μ, σ2), loi de Student `a α
degr´es de libert´e, certains estimateurs `a r´etr´ecisseur dominent universelle-
ment δ0(x) = x. Si la dimension n’est pas trop petite (normalement, p = 4
suﬃt), Brown et Hwang (1989) ont prouv´e que, si x ∼Np(θ, Σ), l’estimateur
δ0(x) est admissible par domination universelle si et seulement si Q = Σ. Pour
d’autres choix de la matrice Q et p assez grand, δ0 est domin´e stochastique-
ment. Cependant, mˆeme si ces crit`eres sont moins discriminants que les coˆuts
habituels, ils permettent d’eﬀectuer des comparaisons, et mˆeme de faire ap-
paraˆıtre des ph´enom`enes de Stein (Note 2.8.2), car les estimateurs classiques
ne sont pas n´ecessairement optimaux.
L’´etude des fonctions de coˆut multiples n’est pas tr`es d´evelopp´ee d’un point
de vue bay´esien, car les estimateurs de Bayes varient en g´en´eral avec un chan-
gement de fonction de coˆut. Cependant, dans des cas tr`es particuliers, Rukhin
(1978) a montr´e que les estimateurs de Bayes peuvent ˆetre ind´ependants de la
fonction de coˆut. Sous certaines hypoth`eses de r´egularit´e, ce cas correspond
aux densit´es v´eriﬁant des ´equations de la forme
log f(x|θ) + log π(θ) = A1(x)eαθ + A2(x)e−αθ + A3(x),
o`u π est la distribution a priori. Donc, pour cette famille exponentielle (voir
la Section 3.3.3),
f(x|θ) = B(x)
π(θ) exp{A1(x)eαθ + A2(x)e−αθ},
(2.11)
les estimateurs de Bayes sont universels, parce qu’ils ne d´ependent pas de la
fonction de coˆut choisie.

94
2 Les bases de la Th´eorie de la D´ecision
2.7 Exercices
Section 2.2
2.1 Montrer que, si la fonction d’utilit´e de U est convexe, tout P ∈PE satisfait
EP [r] =
Z
R
r dP(r) ⪯P.
En d´eduire qu’une fonction de coˆut concave n’est pas r´ealiste.
2.2 Soient quatre d´es avec les chiﬀres suivants sur leurs faces respectives : (4, 4, 4,
4, 0, 0), (3, 3, 3, 3, 3, 3), (6, 6, 2, 2, 2, 2), (1, 1, 1, 5, 5, 5). Deux joueurs lancent un d´e
chacun et comparent leurs r´esultats. Montrer que la relation le d´e [i] l’emporte
sur le d´e [j] est intransitive, c’est-`a-dire pour chaque choix du premier joueur,
le deuxi`eme peut choisir un d´e de mani`ere `a ce que la probabilit´e de gagner soit
sup´erieure `a 0.5. Relier cet exemple au concept de proximit´e de Pitman pr´esent´e
dans la Note 2.8.3.
2.3
∗Montrer que PB ⊂PE , c’est-`a-dire que les distributions born´ees ont une
utilit´e moyenne ﬁnie.
2.4 D´emontrer les Lemmes 2.4 et 2.5.
2.5
∗(DeGroot, 1970) Aﬁn de d´emontrer l’extension du Th´eor`eme 2.6 de PB `a
PE , consid´erons une suite d´ecroissante sm (pour ⪯) dans R telle que, pour
tout r ∈R, il existe m avec sm ⪯r. Si P ∈PE et si P({sm ⪯r}) > 0, on note
Pm la distribution conditionnelle
Pm(A) = P(A ∩{sm ⪯r})
P({sm ⪯r})
.
De mˆeme, si tn est une suite croissante de R telle que, pour tout r ∈R, il existe
n tel que r ⪯tn, on d´eﬁnit P n par
P n(A) = P(A ∩{r ⪯tn})
P({r ⪯tn})
,
pour P({r ⪯tn}) > 0. On supposera que de telles suites existent dans R.
a. Montrer que P n et Pm sont inclus dans PB.
On ajoute l’hypoth`ese suppl´ementaire :
(A6) Pour tous P, Q ∈PE , tels qu’il existe r0 ∈R v´eriﬁant P({r ⪯r0}) =
Q({r0 ⪯r}) = 1, l’ordre P ⪯Q est n´ecessairement satisfait.
b. Montrer que (A6) est en fait satisfait par PB.
c. Montrer que, pour tout P ∈PE ,
EP [U(r)] =
lim
m→+∞EPm[U(r)] =
lim
n→+∞EP n[U(r)].
d. Soient P ∈PE et m < m1, n < n1 tels que P({sm ⪯r}) > 0 et P({r ⪯
tn}) > 0. Montrer que
P n ⪯P n1 ⪯P ⪯Pm1 ⪯Pm.
La deuxi`eme hypoth`ese additionnelle :

2.7 Exercices
95
(A7) Soient P et Q dans PE . S’il existe m0 tel que Pm ⪰Q pour m ≥m0,
alors P ⪰Q. De plus, il existe n0 tel que P n ⪯Q pour n ≥n0, alors
P ⪯Q,
est suppos´ee vraie ci-dessous.
e. Soient P et Q dans PE avec r1, r2 dans R tels que
P({r1 ⪯r}) = Q({r2 ⪯r}) = 1.
Montrer que P ⪯Q si et seulement si EP [U(r)] ≤EQ[U(r)]. (Indication :
Soient les suites P n, Pm, et am = EPm[U(r)], bn = EP n[U(r)]. Utiliser l’hy-
poth`ese (A4) et les questions c. et d.)
f. D´eduire de la question ci-dessus que, si P, Q ∈PE , P ⪯Q si et seulement
si EP [U(r)] ≤EQ[U(r)].
2.6 Dans le cadre de l’Exemple 2.8 sur le paradoxe de Saint-P´etersbourg, d´eterminer
l’utilit´e moyenne d’un joueur pour δ = 1 et δ = 10. Calculer le nombre moyen
de jeux qu’un joueur est prˆet `a jouer dans le jeu modiﬁ´e.
2.7
∗(Smith, 1988)
Un expert a un ordre de pr´ef´erence tel que les r´ecompenses
αδ(x+h)+(1−α)δ(x−h) et x sont ´equivalentes, avec α ind´ependant de x. Montrer
que la fonction d’utilit´e est, soit lin´eaire (quand α = 1/2), soit de la forme ecx
(c > 0) (α < 1/2), soit de la forme 1 −e−cx (α > 1/2).
2.8 (Raiﬀa, 1968)
Dans un premier cas, une personne doit choisir entre un gain
certain de
10 000 (a1) et un gain al´eatoire de
50 000 avec probabilit´e 0.89 et
0 sinon (a2). Le deuxi`eme cas est tel qu’un gain de
50 000 avec une probabilit´e
0.1 (a3) est oppos´e `a un gain de
10 000 avec probabilit´e 0.11 (a4). Montrer
que, mˆeme s’il paraˆıt naturel de pr´ef´erer a1 `a a2 et a3 `a a4, il n’existe pas de
fonction d’utilit´e qui garantisse l’ordre a1 ⪯a2 et a3 ⪯a4.
2.9 Dans le cadre du paradoxe de Saint-P´etersbourg, d´eﬁni dans l’Exemple 2.8,
consid´erer les trois classes de fonction d’utilit´e suivantes :
(i) U(r) = log(δ + r) ;
(ii) U(r) = (δ + r)ϱ (0 < ϱ < 1) ; et
(iii) U(r) = 1 −eδ+r.
Pour chaque classe, d´eterminer les prix d’entr´ee maximaux et le nombre optimal
de jeux.
Section 2.3
2.10 (Casella, 1990)
Montrer que, si la fonction r, de R+ dans R+, est concave,
alors r(t) est strictement d´ecroissante et r(t)/t d´ecroissante.
2.11 Consid´erant la fonction de coˆut propos´ee dans l’Exemple 2.12, montrer qu’un
expert parfait pour N = 2 domine un expert parfait pour N = 1. Ce mˆeme
ph´enom`ene peut-il se produire pour N = 3 ?
2.12 (Smith, 1988) En utilisant les notations de l’Exemple 2.12, le score de Brier
est d´eﬁni comme la fonction de coˆut
L(θ, p) =
N
X
i=1
qi(pi −θi)2 + ¯q(1 −¯q) −
N
X
i=1
qi(pi −¯q)2,
avec ¯q = PN
i=1 qiθi, la proportion de jours pluvieux. Montrer qu’un expert
parfait P1 est meilleur qu’un expert parfait P2 si sa “r´esolution”

96
2 Les bases de la Th´eorie de la D´ecision
R =
N
X
i=1
qi(θi −¯q)2
est plus grande. Discuter l’expression de la fonction de coˆut.
2.13
Montrer que, pour une fonction de coˆut L(θ, d) strictement croissante dans
|d−θ| telle que L(θ, θ) = 0, il n’existe pas de proc´edure statistique uniform´ement
optimale. Donner un contre-exemple quand
L(θ, ϕ) = θ(IR∗(θ) −ϕ)2.
2.14 En relation avec l’Exemple 2.12, le score d’un m´et´eorologiste est la somme,
tout au long de l’ann´ee, des erreurs (IAij −pi)2 pour tous les jours dont la
probabilit´e pi a ´et´e annonc´ee et pour lesquels Aij est l’´ev`enement qu’il pleuve
eﬀectivement. Si ni est le nombre de jours o`u pi a ´et´e pr´evu, montrer que le
score se d´ecompose en
N
X
i=1
ni
X
j=1
(IAij −θi)2 +
N
X
i=1
ni(θi −pi)2.
2.15
∗(Schervish, 1989)
Soit un probl`eme inf´erentiel o`u la probabilit´e p d’un
´ev`enement E doit ˆetre pr´edite, comme par exemple la probabilit´e de pluie.
La r´eponse δ ∈[0, 1] d’un m´et´eorologiste est ´evalu´ee via un score L(E, δ), qui
prend la valeur gi(δ) ≥0 si IE = i (i = 0, 1). Le score est dit correct si l’erreur
moyenne
m(δ) = pg1(δ) + (1 −p)g0(δ)
est minimis´ee en δ = p.
a. Montrer que, pour un score correct, g0 est croissante et g1 est d´ecroissante.
b. Montrer que, si les gi sont d´erivables, le score est correct si et seulement si
−pg′
1(p) = (1 −p)g′
0(1 −p)
pour tout p dans [0, 1].
c. En d´eduire que, quand le score est correct, il existe une fonction positive h,
int´egrable sur [0, 1], telle que
g0(r) =
Z
[0,r]
h(t) dt
et
g1(r) =
Z
[1−r,1]
t
1 −th(t) dt.
2.16 Montrer `a l’aide d’exemples discrets et continus qu’un estimateur de Bayes
peut correspondre `a plusieurs distributions a priori pour la mˆeme fonction de
coˆut et, sym´etriquement, `a plusieurs fonctions de coˆut pour une mˆeme loi a
priori.
2.17 Deux experts doivent fournir une estimation de p ∈[0, 1] sous la fonction de
coˆut (δ −p)2. Ils ont pour distributions a priori respectivement π1 et π2, ´egales
`a Be(1, 2) et Be(2, 3).
a. Donner les deux estimations δ1 et δ2 quand les experts r´epondent s´epar´ement
(sans observation).

2.7 Exercices
97
b. L’expert 1 connaˆıt la valeur de δ2. On suppose que la quantit´e p est ob-
serv´ee apr`es coup et que le meilleur expert re¸coit une amende de (δi −p)2,
et l’autre une amende d’un montant ﬁxe A. Montrer que la fonction de coˆut
pour l’expert 1 est
(δ1 −p)2I|δ1 −p| ≤|δ2 −p| + AI|δ1 −p| > |δ2 −p|.
D´eduire que, si A est suﬃsamment grand, la r´eponse optimale pour l’expert
1 est δ1 = δ2.
c. Modiﬁer la fonction de coˆut ci-dessus aﬁn de forcer l’expert 1 `a donner une
r´eponse honnˆete, qui est la valeur initiale δ1.
2.18 (Raiﬀa et Schlaifer, 1961) Pour une fonction de coˆut L(θ, d) donn´ee, d´eﬁnir la
d´ecision optimale comme la d´ecision dθ qui minimise L(θ, d) pour un θ donn´e.
Le coˆut d’opportunit´e est alors d´eﬁni comme L∗(θ, d) = L(θ, d) −L(θ, dθ).
a. Montrer que ceci est ´equivalent `a supposer que infθ L(θ, d) = 0 pour tout θ.
b. Montrer que l’ensemble des proc´edures classiques (fr´equentistes) optimales
(au sens, respectivement, de l’admissibilit´e et de la minimaxit´e) est le mˆeme
pour L et L∗.
c. Montrer que les proc´edures de Bayes sont les mˆemes pour L et L∗.
2.19 (Raiﬀa et Schlaifer, 1961) Pour une fonction de coˆut L(θ, d) et une distribution
a priori π donn´ees, la d´ecision a priori optimale est dπ qui minimise Eπ[L(θ, d)].
a. Soit D = {d1, d2} et L(θ, d1) = 0.5 + θ, L(θ, d2) = 2 −θ. Donner les d´ecisions
a priori optimales quand π est Be(1, 1) et Be(2, 2).
b. La valeur de l’information de l’´echantillon x est d´eﬁnie comme
ν(x) = Eπ[L(θ, dπ)|x] −Eπ[L(θ, δπ(x))|x],
o`u δπ(x) est un estimateur de Bayes r´egulier de θ. Indiquer pourquoi ν(x) ≥0
et donner la valeur de l’information de l’´echantillon quand x ∼B(n, θ) pour
les fonctions de coˆut et a priori ci-dessus.
c. Quand Θ = D = R, x ∼N (θ, 1), et θ ∼N (θ0, 102), montrer que la d´ecision
a priori optimale sous l’erreur quadratique est dπ = θ0 et que la valeur de l’in-
formation de l’´echantillon est (θ0 −x)2. Conclure en commentant la coh´erence
de cette notion.
2.20 Une strat´egie d’investissement peut ˆetre mise en œuvre selon deux strat´egies
diﬀ´erentes, d1 et d2. Le proﬁt (ou utilit´e) de l’investissement d´epend d’un pa-
ram`etre de rentabilit´e θ ∈R et vaut U(θ, di) = ki + Kiθ.
a. Pour une loi a priori donn´ee π sur θ, quelle est la d´ecision a priori optimale ?
b. Soit x ∼N (θ, 1) et θ ∼N (0, 10). Donner les strat´egies a priori et a pos-
teriori optimales. Exprimer l’am´elioration apport´ee par l’observation de x en
termes d’utilit´e et d’utilit´e esp´er´ee.
c. Si l’observation de x a un coˆut cs, d´eterminer le coˆut cs `a partir duquel
observer x n’est plus avantageux.
2.21 (Raiﬀa et Schlaifer, 1961)
Dans un cadre semblable `a celui de l’exercice
pr´ec´edent, on consid`ere l’espace de d´ecision D = {d1, d2} et le param`etre
θ ∈[0, 1]. La fonction d’utilit´e est L(θ, di) = ki + Kiθ.
a. Si on d´eﬁnit ϕ = (k1 −k2)/(K1 −K2), montrer que ϕ ̸∈(0, 1) implique que
l’une des deux d´ecisions est toujours optimale. Dans les questions suivantes,
nous supposons que ϕ ∈(0, 1).

98
2 Les bases de la Th´eorie de la D´ecision
b. Soit x|θ ∼B(n, θ) et soit θ ∼Be(r, n′ −r). Calculer les d´ecisions a priori
et a posteriori optimales et l’am´elioration moyenne (de l’utilit´e) obtenue par
l’observation de x.
c. Pour un coˆut d’observation K donn´e pour chaque variable al´eatoire de Ber-
noulli, d´eterminer la taille d’´echantillon optimale pour l’esp´erance moyenne.
Section 2.4.1
2.22 D´emontrer le Th´eor`eme 2.14 lorsque r(π) est ﬁni.
2.23 Comparer δ0 et δ∗dans l’Exemple 2.9 sous le coˆut 0−1. Est-ce que ce r´esultat
contredit le th´eor`eme de Rao-Blackwell (Th´eor`eme 2.20) ?
Section 2.4.2
2.24 Construire un exemple semblable `a l’Exemple 2.19, mais o`u A serait forc´e de
se confesser d’un point de vue bay´esien.
2.25 Consid´erer le cas o`u Θ = {θ1, θ2} et D = {d1, d2, d3}, pour la fonction de coˆut
suivante
d1
d2
d3
θ1
2
0
0.5
θ2
0
2
1
a. D´eterminer les proc´edures minimax.
b. Identiﬁer la distribution a priori la moins favorable. (Indication : Repr´esenter
l’espace des risques associ´e aux trois actions de la mˆeme fa¸con que dans
l’Exemple 2.24.)
2.26 Consid´erer la fonction de risque suivante pour Θ = {θ1, θ2} et D = {d1, d2, d3}
d1
d2
d3
θ1
1
2
1.75
θ2
2
1
1.75
a. Dessiner le diagramme des risques de la mˆeme fa¸con que dans l’Exemple 2.24
et en d´eduire les estimateurs minimax.
b. D´eduire de cet exemple que la minimaxit´e n’est pas coh´erente au sens sui-
vant : d1, d2, d3 peuvent ˆetre telles que maxθ R(θ, d1) ≥maxθ R(θ, d3) et
maxθ R(θ, d2) ≥maxθ R(θ, d3), alors que l’estimateur minimax est de la forme
αd1 + (1 −α)d2.
Section 2.4.3
2.27 D´emontrer le Lemme 2.22.
2.28 Consid´erer x ∼B(n, θ), avec n connu.
a. Si π(θ) est la distribution bˆeta Be(√n/2, √n/2), donner la distribution a
posteriori associ´ee π(θ|x) et l’esp´erance a posteriori δπ(x).
b. Montrer que, lorsque L(δ, θ) = (θ−δ)2, la fonction de risque δπ est constante.
Conclure que δπ est minimax.
c. Comparer la fonction de risque pour δπ avec celle de δ0(x) = x/n pour
n = 10, 50 et 100. Conclure sur l’int´erˆet de δπ.
2.29 D´emontrer les Lemmes 2.25 et 2.27.
2.30 Soient x ∼N (θ, 1) et θ ∼N (0, n). Montrer que le risque quadratique
bay´esien vaut n/(n + 1). Conclure sur la minimaxit´e de δ0(x) = x.

2.7 Exercices
99
2.31
∗Donner la densit´e de la distribution uniforme sur la sph`ere de rayon c et
calculer la distribution marginale de x ∼Np(θ, Ip), lorsque θ est distribu´e uni-
form´ement sur cette sph`ere. Calculer l’esp´erance a posteriori δπ(x) et ´etudier
ses propri´et´es.
2.32 Construire un exemple ´equivalent `a l’Exemple 2.28 lorsque x ∼P(λ), c’est-`a-
dire lorsque δ0(x) = x est minimax. (Indication : Noter que δ0 est un estimateur
de Bayes g´en´eralis´e pour π(λ) = 1/λ et utiliser une suite de lois a priori G (α, β).)
2.33 ´Etablir les Propositions 2.32, 2.35 et 2.37.
Section 2.4.4
2.34
Dans l’Exemple 2.38, nous souhaitons prouver que le risque bay´esien de p(x)
est ﬁni.
a. Montrer que
τ(π) =
Z
R2
˘
Φ2(x) −2Φ(x)Iθ≤0 + Iθ≤0
¯ e−(x−θ)2/2
√
2π
dθdx
quand π(θ) = 1.
b. En d´eduire que
τ(π) =
Z +∞
−∞
Φ(x)Φ(−x)dx
= 2
Z +∞
0
Φ(x)Φ(−x)dx
en int´egrant d’abord par rapport θ.
c. Montrer que
Z +∞
0
Φ(−x)dx =
Z +∞
0
y e−y2
√
2π
dy.
d. En d´eduire que τ(π) est ﬁni.
2.35 Soit x ∼Np(θ, Ip). Une classe d’estimateurs de ||θ||2 est donn´ee par
δc(x) = ||x||2 + c,
c ∈R.
a. Montrer que, sous le coˆut quadratique, δ−p minimise la fonction de risque
pour tout θ, au sein des estimateurs δc. Est-ce que ce probl`eme d’estimation
a un int´erˆet pratique ?
b. Comment choisir ω(θ) de fa¸con telle que la fonction de risque de δ−p soit
born´ee uniform´ement pour le coˆut quadratique pond´er´e par ω(θ) ? Conclure
sur la minimaxit´e de δ−p.
c. Montrer que δ−p n’est pas admissible, et proposer un estimateur qui domine
δ−p uniform´ement.
2.36 Montrer que, sous la fonction de coˆut quadratique, si deux estimateurs `a va-
leurs r´eelles δ1 et δ2 sont distincts et satisfont
R(θ, δ1) = (θ −δ1(x))2 = R(θ, δ2) = (θ −δ2(x))2,
l’estimateur δ1 n’est pas admissible. (Indication : Consid´erer δ3 = (δ1 + δ2)/2
ou δ4 = δα
1 δ1−α
2
.) ´Etendre ce r´esultat `a toutes les fonctions de coˆut strictement
convexes et construire un contre-exemple pour une fonction de coˆut non convexe.

100
2 Les bases de la Th´eorie de la D´ecision
2.37 Soit Θ = {θ1, θ2}. On consid`ere le cas o`u l’ensemble des risques est R =
{(r1, r2); (r1 −2)2 + (r2 −2)2 < 2, r1 ≤2, r2 ≤2}.
a. Tracer R et en d´eduire l’existence d’un point de minimaxit´e.
b. Donner les deux r`egles de d´ecision admissibles pour ce probl`eme.
c. Que peut-on dire sur l’existence de proc´edures bay´esiennes ?
2.38 Deux experts ont des fonctions de coˆut diﬀ´erentes, donn´ees dans la table sui-
vante pour D = {d1, d2, d3} et Θ = {θ1, θ2}.
L1/L2
d1
d2
d3
θ1
1/1 2.5/1.5 2/2.5
θ2
1.5/4 2/3.5
3/3
a. Tracer les ensembles des risques pour les deux experts et identiﬁer les
proc´edures minimax et admissibles dans les deux cas.
b. Il y a plusieurs fa¸cons de combiner les opinions d’expert, c’est-`a-dire de
construire une fonction de coˆut unique. Pour chacun des choix suivants, don-
ner l’ensemble des risques et les r`egles de d´ecision optimales :
(i) L = (L1 + L2)/2
(ii) L = sup(L1, L2)
(iii) L =
√
L1L2.
c. Pour quel choix de L les r`egles admissibles le sont aussi pour l’un des deux
coˆuts initiaux ? Sous quelles conditions l’ensemble des risques est-il convexe ?
Section 2.5
2.39
∗´Etablir les Propositions 2.41, 2.42, et 2.43. D´emontrer le lemme de Shinozaki
(1975) : si δ est admissible pour le coˆut quadratique usuel, il l’est aussi pour tout
coˆut quadratique.
2.40 Soient π(θ) = (1/3)(U[0,1](θ)+U[2,3](θ)+U[4,5](θ)) et f(x|θ) = θe−θx. Montrer
que, sous le coˆut (2.5), il existe, pour tout x, des valeurs de k1 et k2 telles que
l’estimateur de Bayes ne soit pas unique.
2.41 ´Etablir la Proposition 2.47 et montrer que la fonction de coˆut L consid´er´ee
dans l’Exemple 2.48 est ´equivalente `a l’estimateur IH0(θ) sous le coˆut absolu,
L(θ, δ) = |θ −δ|.
Calculer l’estimateur de Bayes associ´e au coˆut quadratique.
2.42
∗(Zellner, 1986a) Soit la fonction de coˆut dite LINEX sur R, d´eﬁnie par
L(θ, d) = ec(θ−d) −c(θ −d) −1.
a. Montrer que L(θ, d) > 0 et repr´esenter ce coˆut comme une fonction de (θ−d)
lorsque c = 0.1, 0.5, 1, 2.
b. Donner l’expression des estimateurs de Bayes sous cette fonction de coˆut.
c. Pour x1, . . . , xn ∼N (θ, 1) et π(θ) = 1, donner l’estimateur de Bayes associ´e.
2.43 (Berger, 1985b) Soient x ∼N (θ, 1), θ ∼N (0, 1) et la fonction de coˆut
L(θ, δ) = e3θ2/2(θ −δ)2.
a. Montrer que δπ(x) = 2x.
b. Montrer que δπ est domin´e uniform´ement par δ0(x) = x et que r(π) = +∞.

2.7 Exercices
101
2.44 D´eterminer l’estimateur de Bayes associ´e avec le coˆut absolu sur Rk,
L(θ, δ) = ||θ −δ||.
2.45 Consid´erer les questions suivantes pour le coˆut entropique et le coˆut intrins`eque
de Hellinger.
a. Montrer que Le (resp. LH) est positive, qu’elle est nulle si d = θ et d´eterminer
sous quelle condition d = θ est l’unique solution de Le(θ, d) = 0 (resp. de
LH(θ, d) = 0).
b. Donner les expressions de ces deux fonctions de coˆut lorsque x ∼N (0, θ) et
x ∼Be(n, θ).
c. Montrer que, si x ∼G (α, θ) et θ ∼G (ν, x0), l’estimateur de Bayes de θ sous
le coˆut de Hellinger est de la forme k/(x0 + x).
2.46
∗(Wells, 1992) Comme cela est mentionn´e dans la Section 2.5.4, les estimateurs
de Bayes ne sont pas invariants sous une reparam´etrisation arbitraire. Dans le
cas gaussien, x ∼N (θ, 1), d´eterminer si les seules transformations de θ pour
lesquelles les estimateurs de Bayes sont invariants sous le coˆut quadratique sont
les transformations aﬃnes, η = aθ + b. [Note : La r´eponse est non.]
2.47
∗(Efron, 1992) Calculer les estimateurs de Bayes de θ lorsque θ|x ∼N (μ(x), 1)
et lorsque la fonction de coˆut est quadratique asym´etrique,
L(θ, δ) =
(
ω(θ −δ)2
si δ < θ,
(1 −ω)(θ −δ)2
sinon.
2.48 (Robert, 1996a) Montrer que les coˆuts entropiques et de Hellinger sont
´equivalents localement au coˆut quadratique associ´e `a l’information de Fisher,
I(θ) = Eθ
"
∂log f(x|θ)
∂log
„∂log f(x|θ)
∂log
«t#
,
c’est-`a-dire
Le(θ, δ) = Le(θ −δ)tI(θ)−1(θ −δ) + O(∥θ −δ∥2)
et
LH(θ, δ) = cH(θ −δ)tI(θ)−1(θ −δ) + O(∥θ −δ∥2),
o`u ce et cH sont des constantes.
2.49 Soit y = x + ϵ avec ϵ et x variables al´eatoires ind´ependantes et E[ϵ] = 0.
a. Montrer que E[y|x] = x.
b. Montrer que la r´eciproque n’est pas vraie : E[x|y] n’est pas toujours ´egal
`a y. (Indication : Consid´erer, par exemple, le cas o`u x ∼pN (θ1, 1) + (1 −
p)N (θ2, 1) et ϵ ∼N (0, 1).)
Section 2.6
2.50 Montrer que, pour les distributions universelles (Rukhin, 1978), les estimateurs
de Bayes sont eﬀectivement ind´ependants de la fonction de coˆut. Dans le cas
particulier o`u x ∼G (ν, 1/ν), identiﬁer θ, A1(x), A2(x) et l’a priori universel
π(θ).

102
2 Les bases de la Th´eorie de la D´ecision
Note 2.8.1
2.51 Montrer que l’estimateur de Bayes associ´e `a la fonction de coˆut L0 est l’esti-
mateur du maximum a posteriori (MAP).
2.52 Montrer que l’estimateur de Bayes associ´e `a la fonction de coˆut L1 est le
vecteur des estimateurs MAP pour chaque composante.
2.53 Si D est un sous-ensemble de {1, . . . , N}, notons e = {ei, i ∈D}, le vecteur
des classiﬁcations erron´ees et mD leur nombre.
a. Montrer que p(mD) peut s’´ecrire
p(mD) = 1 −
Y
i∈D
(1 −ei) .
b. Soit q(mD) la fonction qui vaut 1 si et seulement si mD = |D|. Montrer que
q(mD) =
Y
i∈D
ei .
c. Montrer que
p(mD) =
|D|
X
k=1
(−1)k+1
X
ω∈Pk(D)
q(mω) .
Note 2.8.2
2.54 Montrer que le paradoxe de Stein ne peut avoir lieu lorsque δ0 est un esti-
mateur de Bayes au sens strict, quelle que soit la dimension p. [Note : Brown
(1971) a montr´e que certains estimateurs de Bayes g´en´eralis´es jouissent de cette
propri´et´e.]
2.55 Montrer que la constante de majoration dans le Th´eor`eme 2.52 peut ˆetre
remplac´ee par
c = 2
q −2α
p −q + 4β .
(Indication : Majorer d’abord h2(t, u) par c(u/t)h(t, u).) Comparer les deux
bornes.
2.56
∗(Stein, 1973) ´Etablir le lemme de Stein : Si x ∼N (θ, 1) et f est continue
et presque partout d´erivable, alors
Eθ[(x −θ)f(x)] = Eθ[f ′(x)].
En d´eduire que, si x ∼Np(θ, Σ), δ(x) = x+Σγ(x), et L(θ, δ) = (δ−θ)tQ(δ−θ),
avec γ d´erivable, alors
R(θ, δ) = Eθ
ˆ
tr(QΣ) + 2 tr(Jγ(x)Q∗) + γ(x)tQ∗γ(x)
˜
,
o`u tr(A) est la trace de A, Q∗= ΣQΣ et Jγ(x) est la matrice form´ee des
´el´ements
∂
∂xi γj(x). [Note : Cette repr´esentation de la fonction de risque est
li´ee `a la technique d’estimation sans biais du risque, qui est centrale pour la
construction de conditions suﬃsantes de domination d’estimateurs usuels. Voir
Berger, 1985b, et Johnstone, 1998.]

2.7 Exercices
103
2.57
∗(Suite de l’Exercice 2.56)
Utiliser la repr´esentation sans biais fournie
par le lemme de Stein pour montrer que, si x ∼Np(θ, Σ), δ(x) = x + γ(x) et
L(θ, δ) = ||δ −θ||2, l’estimateur associ´e `a γ(x) = 2(2 −p)/||x||2 a un risque
constant ´egal `a p.
Note 2.8.3
Les exercices suivants (2.58–2.63) traitent du crit`ere de proximit´e de Pitman.
Un estimateur δ1 de θ domine au sens de Pitman un estimateur δ2, ce qui est
not´e δ1
P≻δ2, si, pour tout θ ∈Θ,
Pθ(|δ1(X) −θ| < |δ2(X) −θ|) > 0.5.
La notion d’admissibilit´e de Pitman en d´ecoule directement.
2.58
∗Soit un estimateur sans biais m´edian δM, qui donc satisfait
∀θ,
Pθ(δM(x) ≤θ) = 0.5.
a. Montrer que δM est le meilleur estimateur (sous le crit`ere de Pitman) au sein
des estimateurs lin´eaires δM(x) + K, K ∈R.
b. Si θ > 0 et δM > 0, montrer que δM est aussi le meilleur estimateur (pour
le crit`ere de Pitman) au sein des estimateurs KδM, K > 0.
2.59
∗Soient X = θU, θ > 0, U ∼U (−0.9, 1.1). Montrer que
X
P≻0.9|X|
P≻3.2|X|
P≻X .
2.60
∗(Robert et al., 1993b) Soit X ∼f(x −θ), avec
Z 0
−∞
f(u) du = 1/2
et f(0) > 0. Si F est la fonction de r´epartition de X pour θ = 0, la fonction ϵ(θ)
est d´eﬁnie par
F(−θ) =
(
P0(0 < X < ϵ(θ))
si θ > 0,
1 −P0(0 > X > −ϵ(θ))
si θ < 0,
et ϵ(0) = 0. Soit
θ1 = Arg{min
θ>0 |θ + ϵ(θ)|},
θ2 = Arg{min
θ<0 |θ −ϵ(θ)|}.
La version tronqu´ee de ϵ est d´eﬁnie par
ϵ∗(θ) =
8
>
<
>
:
ϵ(θ)
si θ > θ1 ou θ < θ2
θ1 + ϵ(θ1) −θ
si 0 < θ < θ1
θ + ϵ(θ2) −θ2
si 0 > θ > θ2.
L’ensemble A v´eriﬁe
(x, θ) ∈A
si et seulement si
θ < x ≤θ + ϵ∗(θ)
pour θ > 0, et
(x, θ) ∈A
si et seulement si
θ −ϵ∗(θ) ≤x < θ.
pour θ < 0.

104
2 Les bases de la Th´eorie de la D´ecision
a. Justiﬁer la troncature de ϵ et repr´esenter A dans un cas particulier o`u le
calcul de ϵ∗est faisable.
b. Montrer que, si δ(x) est une fonction croissante telle que (x, δ(x)) ∈A, alors
δ
P≻δ0(x) = x.
c. Montrer que, si F(c) −F(−c) = 1/2, tout estimateur δ tel que
δ(x) = 0
quand
|x| < c ,
(2.12)
est admissible au sens de Pitman.
d. Lorsque δ est monotone, v´eriﬁe (2.12) et est dans A, montrer que δ est
admissible au sens de Pitman et domine δ0 au sens de Pitman. Montrer que
c < θ1 + ϵ(θ1)
et
−c > θ2 −ϵ(θ2)
et conclure `a propos de l’existence de tels estimateurs.
2.61 Soit un couple de variables al´eatoires (x, y) de fonction de r´epartition jointe
Fα(x, y) =
xy
1 + α(1 −x)(1 −y)I[0,1]2(x, y).
a. Montrer que Fα est eﬀectivement une fonction de r´epartition et en d´eduire
la densit´e fα(x, y).
b. Donner la distribution marginale de x et y.
c. Supposons que deux estimateurs δ1 et δ2 soient distribu´es selon θ−2fα(δ1/θ,
δ2/θ). Que peut-on dire `a propos de la proximit´e de Pitman `a θ ? (Indication :
Calculer P(|δ1 −θ| < |δ2 −θ|).)
2.62
∗Montrer que, si X1, X2 ∼f(x|θ), alors
X
P≻X1 .
Appliquer ce r´esultat `a la loi de Cauchy. Montrer que, pour tout r´eel η, X est
plus proche au sens de Pitman de η que X1, mˆeme si η est quelconque. [Note :
Cette propri´et´e n’est pas sp´eciﬁque `a la proximit´e de Pitman, puisqu’elle est
aussi satisfaite par le coˆut quadratique.]
2.63
∗(Robert et al., 1993b) Montrer que (ou utiliser directement le r´esultat), si
χ2
α(p, λ) est l’α-quantile d’une distribution du khi deux d´ecentr´e, χ2
p(λ), il v´eriﬁe
p −1 + λ ≤χ2
0.5(p, λ) ≤χ2
0.5(p, 0) + λ.
a. D´eduire de cette in´egalit´e que les estimateurs de James-Stein
δh(x) =
„
1 −h(x)
||x||2
«
x
dominent au sens de Pitman δ0 lorsque x ∼N (θ, Ip) et
0 < h(x) ≤2(p −1).
b. Montrer que cette condition est aussi n´ecessaire lorsque h est constante.

2.8 Notes
105
2.8 Notes
2.8.1 Fonctions de coˆut pour l’analyse d’image
Une image, repr´esent´ee sur l’´ecran d’un ordinateur, est un tableau `a deux dimen-
sions x contenant des pixels de couleurs diﬀ´erentes (ou niveaux de gris, pour
les images en noir et blanc). Une image est souvent observ´ee avec du bruit,
provenant ´eventuellement des imperfections du dispositif d’acquisition, comme
pour un appareil de photo qui n’est pas mis au point, des perturbations dans
la transmission, ou de d´efauts de l’image elle-mˆeme, comme par exemple des
nuages dans une image satellite. L’analyse d’image bay´esienne cherche, entre
autres choses, `a reconstruire l’image initiale.
L’image observ´ee, x, peut aussi s’´ecrire sous la forme d’un vecteur (x1 . . . , xN),
chaque xi prenant ses valeurs dans {0, 1, . . . , C −1}, l’ensemble des couleurs. La
vraie image est not´ee θ et x suit la loi x ∼f(x|θ).
La fonction de coˆut la plus rudimentaire dans ce cadre est la fonction dichoto-
mique “0–1” L0(θ, δ) = 0 si θ = δ et L0(θ, δ) = 1 sinon. Pour un a priori π(θ),
l’estimateur de Bayes δπ associ´e au coˆut 0–1 est l’image qui maximise la densit´e
a posteriori π(θ|x), dite aussi estimateur MAP. Comme il a ´et´e not´e par Rue
(1995), cette fonction de coˆut est extrˆemement sensible aux erreurs de classiﬁ-
cation, et entraˆıne un surlissage de l’image, gommant de petites structures qui
sont importantes dans des applications comme la reconnaissance de forme.
La seconde fonction de coˆut standard est le taux d’erreur de classiﬁcation, c’est-
`a-dire le nombre de classiﬁcations erron´ees, obtenu `a partir du vecteur e, qui
est d´eﬁni, pour un estimateur δ et une vraie image θ, comme ei = Iδi̸=θi (i =
1, . . . , N). Le nombre de classiﬁcations erron´ees est alors
L1(θ, δ) =
N
X
i=1
ei .
´Etant donn´e la structure additive de cette fonction de coˆut, le coˆut a posteriori
est la somme des coˆuts pour chaque site E[ei|x] et l’estimateur de Bayes est
donc le vecteur des estimateurs MAP marginaux. Le d´efaut de cette fonction de
coˆut est donc l’inverse de celui du coˆut pr´ec´edent : elle entraˆıne une estimation
trop locale et ne prend pas en compte les interactions entre des sites voisins.
Rue (1995) introduit une nouvelle famille de fonctions de coˆuts pour la construc-
tion d’estimateurs d’images bay´esiens, qui prennent en compte les diﬀ´erents
traits caract´eristiques de l’image. Si D est un sous-ensemble de {1, . . . , N}, et
mD le nombre de classiﬁcations erron´ees dans D,
mD =
X
i∈D
ei ,
p(mD) vaut 0 si mD = 0, 1 sinon, RφD est l’ensemble D tourn´e d’un angle
φ ∈{0, ±π/2, π} et TsD est D translat´e de s (dans sa repr´esentation `a deux
dimensions). Si on note Pj(D) l’ensemble des sous-ensembles D de taille j, les
fonctions de coˆut sont construites `a partir (i) d’un ensemble de sous-ensembles
de base de {1, . . . , N}, et (ii) de coeﬃcients de p´enalit´e tij, tels que la p´enalit´e
associ´ee `a une r´egion Bi soit

106
2 Les bases de la Th´eorie de la D´ecision
Pi(mBi) =
|Bi|
X
j=1
ti,j
X
ω∈Pj(Bi)
p(mω) .
La fonction de coˆut est alors
L(θ, δ) =
n
X
i=1
X
s,φ
Pi(mTsRφBi) ,
(2.13)
o`u la seconde somme est restreinte aux couples (s, φ) tels que TsRφBi soit un
sous-ensemble de {1, . . . , N}, c’est-`a-dire est `a l’int´erieur de l’image initiale.
La motivation pour recourir `a une telle combinaison devient plus claire lorsque,
`a l’instar de Rue (1995), on prend n = 1 et B1 est la r´egion 2 × 2 constitu´ee
par les quatre voisins d’un point arbitraire. Dans ce cas particulier, Rue (1995)
propose de prendre t1,1 = 1 aﬁn de p´enaliser une classiﬁcation erron´ee en un
site et de choisir une p´enalit´e suppl´ementaire t1,2 > 0 pour le cas o`u deux sites
voisins sont simultan´ement mal class´es, tandis que t1,3 = t1,4 = 0. La fonction
de coˆut r´esultante est alors le nombre de sites mal class´es, plus t1,2 fois le nombre
de couples de voisins simultan´ement mal class´es.
Comme le d´etaille Rue (1995), les probl`emes de r´esolution minimales, de recon-
naissance de forme et les mod`eles d’Ising sont d’autres exemples de ce cadre
g´en´eral. Par exemple, les sous-ensembles de base Bi peuvent inclure des formes
particuli`eres, comme des voitures pour le contrˆole du traﬃc, ou des tumeurs
pour le traitement d’images radiologiques. Bien entendu, le calcul de l’estima-
teur de Bayes associ´e `a (2.13) n’est pas aussi simple que pour L0 et L1, et Rue
(1995) propose une m´ethode it´erative fond´ee sur une chaˆıne de Markov (voir le
Chapitre 6).
2.8.2 Le ph´enom`ene de Stein
S’il existe un unique estimateur minimax, celui-ci est admissible, selon la Pro-
position 2.32. R´eciproquement, si un estimateur minimax δ0 est inadmissible, il
existe des estimateurs minimax qui dominent δ0 (sous certaines conditions de
r´egularit´e faible, voir Brown, 1976). En particulier, si l’estimateur minimax `a
risque constant est inadmissible, il s’agit du pire estimateur minimax au sens o`u
tout autre estimateur minimax a un risque uniform´ement plus petit. Jusqu’en
1955, on supposait que l’estimateur des moindres carr´es, δ0(x) = x, lorsque
x ∼Np(θ, Ip), ´etait admissible et, puisque sa fonction de risque ´etait constante,
qu’il s’agissait de l’unique estimateur minimax. Stein (1955a) a montr´e que ceci
n’est vrai que pour p = 1, 2 et mis ainsi en lumi`ere “le ph´enom`ene de Stein”,
c’est-`a-dire le suppos´e paradoxe de l’inadmissibilit´e d’estimateurs standards.
Formellement, le paradoxe de Stein peut ˆetre exprim´e de la fa¸con suivante.
Si un estimateur standard δ∗(x) = (δ0(x1), . . . , δ0(xp)) est ´evalu´e sous le coˆut
quadratique pond´er´e
p
X
i=1
ωi(δi −θi)2,
(2.14)
o`u ωi > 0 (i = 1, . . . , p), il existe p0 tel que δ∗ne soit pas admissible pour
p ≥p0, bien que les composantes δ0(xi) soient, priss s´epar´ement, admissibles
pour l’estimation des θi. Le ph´enom`ene de Stein est dˆu `a l’utilisation de la

2.8 Notes
107
fonction de coˆut jointe (2.14), qui permet `a l’estimateur dominant de tirer proﬁt
des autres composantes, mˆeme si celles-ci sont ind´ependantes et correspondent
`a des probl`emes d’estimation sans rapport entre eux.
La litt´erature sur le ph´enom`ene de Stein et les ph´enom`enes qui lui sont associ´es
est d´esormais trop vaste pour que nous puissions en pr´esenter tous les r´esultats
ici. Nous renvoyons les lecteurs `a Judge et Bock (1978), Lehmann (1983) et
Berger (1985b) pour une bibliographie plus d´etaill´ee. Nous d´evelopperons dans le
Chapitre 10 une analyse bay´esienne du ph´enom`ene de Stein. Cette note pr´esente
bri`evement les r´esultats principaux sur le ph´enom`ene de Stein, d’un point de
vue fr´equentiste.
Initialement, bien que la d´emonstration d’inadmissibilit´e de Stein (1955a) soit
non constructive, James et Stein (1961) exhib`erent un estimateur qui domine
uniform´ement δ0(x) = x sous le coˆut quadratique pour p ≥3 dans le cas gaus-
sien, donc tel que, pour tout θ,
p = Eθ[||δ0(x) −θ||2] > Eθ[||δJS(x) −θ||2].
Cet estimateur,
δJS(x) =
„
1 −p −2
||x||2
«
x,
(2.15)
est d´esormais appel´e l’estimateur de James-Stein. Notons le comportement cu-
rieux de δJS lorsque x tend vers 0 : Le facteur
1 −p −2
||x||2
devient n´egatif et tend mˆeme vers −∞lorsque ||x|| tend vers 0. Cependant,
δJS domine δ0 pour tout θ. (Ceci est une cons´equence du Th´eor`eme 2.52 ci-
dessous.) Baranchick (1970) corrigea ce comportement paradoxal en montrant
que les estimateurs tronqu´es
δ+
c (x) =
„
1 −
c
||x||2
«+
x
=
(
(1 −
c
||x||2 )x
si ||x||2 > c,
0
sinon,
(2.16)
dominent uniform´ement leurs ´equivalents non tronqu´es pour p−2 ≤c ≤2(p−2).
En particulier, δ+
p−2 domine δJS. Ces estimateurs sont de plus non comparables
(pour diﬀ´erentes valeurs de c). Cette classe d’estimateurs est importante parce
que, bien qu’elle soit constitu´ee d’estimateurs non admissibles (voir le Chapitre
8), il est diﬃcile de construire des estimateurs qui les dominent et ces der-
niers ne r´eduisent pas de mani`ere signiﬁcative la fonction de risque (Shao et
Strawderman, 1996). En revanche, les estimateurs de James-Stein tronqu´es (ou
positive-part) permettent une r´eduction signiﬁcative du risque par rapport aux
estimateurs des moindres carr´es, comme l’illustre la Figure 2.2 pour p = 10 et
c = 2p −1.
`A la suite de James et Stein (1961), des classes plus g´en´erales d’estimateurs
dominant δ0 ont ´et´e propos´ees par Alam (1973), Berger et Bock (1976), Judge
et Bock (1978), Stein (1981), George (1986a,b), et Brandwein et al. (1992).

108
2 Les bases de la Th´eorie de la D´ecision
Ces estimateurs sont appel´es estimateurs `a r´etr´ecisseur parce que, `a l’instar de
(2.15) et (2.16), ils r´etr´ecissent x vers 0. Des ph´enom`enes de Stein ont ´et´e aussi
mis en ´evidence pour des distributions non normales et d’autres coˆuts que la
fonction quadratique, voir Berger (1975b), Brandwein et Strawderman (1980),
Hwang (1982a), Ghosh et al. (1983), Bock (1985), Haﬀet Johnstone (1986),
Srivastava et Bilodeau (1988), Brandwein et Strawderman (1990). Certaines
restrictions sur les classes d’estimateurs `a r´etr´ecisseur ont ´et´e propos´ees, qui
permettent d’int´egrer les contraintes d’admissiblit´e (Brown, 1971, Alam, 1973,
Strawderman, 1974, Brown, 1975, Berger et Srinivasan, 1978, Brown et Hwang,
1982, Das Gupta et Sinha, 1986, Brown, 1988, et Fraisse et al., 1998). Bondar
(1987) montre que l’am´elioration (en termes de risque) apport´ee par les esti-
mateurs `a r´etr´ecisseur n’est signiﬁcative que sur une petite partie de l’espace
des param`etres, mais George (1986a,b) montre qu’il est possible d’´etendre cette
r´egion grˆace au concept d’estimateur `a r´etr´ecisseur multiple (voir l’Exercice
10.38).
Le ph´enom`ene de Stein peut aussi ˆetre consid´er´e comme robuste au sens o`u
il d´epend principalement de la fonction de coˆut, plutˆot que de la distribution
exacte des observations, comme cela a ´et´e montr´e par Brown (1975), Shino-
zaki (1980, 1984), Berger (1980b,a), Das Gupta (1958), Bilodeau (1988), Cellier
et al. (1989), Brandwein et Strawderman (1990) ou Kubokawa et al. (1991, 1992,
1993b). Il ne se restreint pas `a l’estimation ponctuelle, et apparaˆıt aussi dans le
cadre des r´egions de conﬁance (Stein, 1962a, Hwang et Casella, 1982, Hwang et
Casella, 1984, Casella et Hwang, 1983, Casella et Hwang, 1987, Robert et Ca-
sella, 1990, Hwang et Ullah, 1994), et dans celui de l’estimation de la pr´ecision
(ou du coˆut) (Johnstone, 1998, Rukhin, 1988a,b, Lu et Berger, 1989a,b, Robert
et Casella, 1993, Fourdrinier et Wells, 1993, George et Casella, 1994). En re-
vanche, Gutmann (1982) a ´etabli que le ph´enom`ene de Stein ne peut avoir lieu
pour des espaces de param`etres ﬁnis. Brown (1971) (voir aussi Srinivasan, 1981,
Johnstone, 1984, et Eaton, 1992) a prouv´e que l’admissibilit´e est reli´ee `a un
processus stochastique associ´e `a l’estimateur et Brown (1980) prouve le r´esultat
surprenant suivant, appel´e ph´enom`ene de Berger, d’apr`es Berger (1980a) : il
existe toujours une fonction de coˆut telle que la fronti`ere entre admissiblit´e
et inadmissibilit´e pour l’estimateur standard soit une dimension p0 arbitraire
donn´ee.
Ce survol rapide ne fait pas justice `a la richesse des travaux sur le ph´enom`ene
de Stein. Les avanc´ees dans ce domaine sur les trente derni`eres ann´ees ont beau-
coup apport´e `a la Th´eorie de la D´ecision, notamment `a sa branche bay´esienne.
En eﬀet, une des cons´equences importantes du paradoxe de Stein a ´et´e de mar-
quer la ﬁn de l’ˆage d’or de la Statistique classique, puisqu’il montre que la
quˆete du meilleur estimateur, c’est-`a-dire d’un estimateur minimax admissible
unique, est sans espoir, `a moins qu’on ne restreigne la classe des estimateurs `a
consid´erer, ou qu’on ne prenne en compte une information a priori. Les travaux
sur le ph´enom`ene de Stein ont donc men´e `a l’abandon progressif de l’estimation
sans biais, `a une compr´ehension plus profonde de la minimaxit´e et de l’admis-
sibilit´e, et `a une am´elioration des techniques fr´equentistes de calcul de risque
(poursuivant l’id´ee de Stein, 1973, d’une estimation sans biais du risque). Ce-
pendant, son apport principal a ´et´e de renforcer l’interface entre les approches

2.8 Notes
109
fr´equentiste et bay´esienne23, en incitant les fr´equentistes `a recourir aux tech-
niques bay´esiennes (voir, par exemple, les estimateurs pseudo-bay´esiens de Bock,
1988) et les bay´esiens `a rendre les estimateurs plus robustes `a l’´egard de leurs
performances fr´equentistes, et de l’incertitude portant sur le choix de l’a priori
(Berger, 1980a, 1982b, 1984, George, 1986a,b, Lu et Berger, 1989a,b, Berger et
Robert, 1990). Nous renvoyons les lecteurs aux livres mentionn´es ci-dessus ainsi
qu’`a Brandwein et Strawderman (1990) et Lehmann et Casella (1998) pour des
r´ef´erences additionnelles.
Nous concluons cette note par la d´emonstration de l’inadmissibilit´e de δ0(x) = x
pour l’estimation du param`etre θ d’une distribution `a sym´etrie sph´erique, de
densit´e f(||x −θ||) sur Rp (p ≥3). Kelker (1970), Eaton (1986) et Fan et
Anderson (1990) (voir aussi l’Exercice 1.1) fournissent des r´ef´erences sur ces
distributions g´en´eralisant la loi normale dans les mod`eles de r´egression lin´eaire.
Ce r´esultat a ´et´e ´etabli pour la premi`ere fois par Cellier et al. (1989).
Th´eor`eme 2.52. Soit z = (xt, yt)t ∈Rp, de loi
z ∼f(||x −θ||2 + ||y||2),
(2.17)
avec x ∈Rq et y ∈Rp−q. Un estimateur
δh(z) = (1 −h(||x||2, ||y||2))x
domine δ0 sous le coˆut quadratique usuel s’il existe α, β > 0 tels que :
(1) tαh(t, u) est une fonction croissante de t pour tout u ;
(2) u−βh(t, u) est une fonction croissante de u pour tout t ; et
(3) 0 ≤(t/u)h(t, u) ≤
2(q −2)α
p −q −2 + 4β .
Les conditions sur h donn´ees ci-dessus ne font donc pas intervenir f dans (2.17),
qui n’a pas besoin d’ˆetre connue ; de plus, elles sont identiques `a celles obtenues
dans le cas normal (voir Brown, 1975). La pr´esence d’un ph´enom`ene de Stein
est donc robuste dans la classe des distributions `a sym´etrie sph´erique admettant
un coˆut quadratique ﬁni.
Preuve.
Les conditions (1) et (2) impliquent que
(
t ∂
∂th(t, u) ≥−αh(t, u),
u ∂
∂uh(t, u) ≤βh(t, u).
La fonction de coˆut δh peut s’´ecrire :
R(θ, δh) = Eθ
"
q
X
i=1
˘
xi −θi −h(||x||2, ||y||2)xi
¯2
#
= Eθ
"
q
X
i=1
(xi −θi)2
#
−2Eθ
"
q
X
i=1
h(||x||2, ||y||2)xi(xi −θi)
#
+Eθ
ˆ
h2(||x||2, ||y||2)||x||2˜
.
23Le d´eveloppement des techniques bay´esiennes empiriques en est un exemple
typique, voir le Chapitre 10.

110
2 Les bases de la Th´eorie de la D´ecision
On montre par une int´egration par parties que
Z +∞
−∞
h(||x||2, ||y||2)xi(xi −θi)f(||x −θ||2 + ||y||2) dxi
=
Z +∞
−∞
∂
∂xi
ˆ
h(||x||2, ||y||2)xi
˜ ¯F(||x −θ||2 + ||y||2) dxi,
o`u
¯F(t) =
Z +∞
t
f(u)du.
Donc
Eθ
"
q
X
i=1
h(||x||2, ||y||2)xi(xi −θi)
#
=
Z
Rp
ˆ
qh(||x||2, ||y||2) + 2h′
1(||x||2, ||y||2)||x||2˜ ¯F(||x −θ||2 + ||y||2) dz ,
o`u h′
1(t, u) =
∂
∂th(t, u). De mˆeme,
Eθ[h2(||x||2, ||y||2)||x||2] = Eθ
»||x||2
||y||2 h2(||x||2, ||y||2)||y||2
–
=
Z
Rp ||x||2
p−q
X
j=1
∂
∂yj
„
h2(||x||2, ||y||2) yj
||y||2
«
¯F(||x −θ||2 + ||y||2) dz
=
Z
Rp ||x||2
»
4h(||x||2, ||y||2)h′
2(||x||2, ||y||2)||x||2
+ (p −q −2)h2(||x||2, ||y||2)
1
||y||2
–
¯F(||x −θ||2 + ||y||2) dz,
o`u h′
2(t, u) =
∂
∂uh(t, u). La diﬀ´erence des risques vaut alors
R(θ, δ0) −R(θ, δh) =
Z
Rp
j
2
»
qh(||x||2, ||y||2) + 2h′
1(||x||2, ||y||2)||x||2
–
||x||2h(||x||2, ||y||2)
»
4h′
2(||x||2, ||y||2) −(p −q −2)h(||x||2, ||y||2)
1
||y||2
–ﬀ
× ¯F(||x −θ||2 + ||y||2) dz
≥
Z
Rp h(||x||2, ||y||2)
»
−h(||x||2, ||y||2)||x||2
||y||2 (p −q −2 + 4β)
+2(q −2α)
–
¯F(||x −θ||2 + ||y||2) dz > 0,
ce qui conclut la d´emonstration.
⊓⊔
Notez que ce r´esultat de domination inclut comme cas particulier l’estimation
d’un vecteur normal moyen lorsque la variance est connue `a une constante multi-
plicative pr`es, soit le probl`eme consid´er´e initialement par James et Stein (1961).
Lorsque h(t, u) = au/t, a est born´e par 2(q−2)/(p−q+2), comme l’ont d´emontr´e
James et Stein (1961).

2.8 Notes
111
2.8.3 Proximit´e de Pitman
Une approche alternative `a la Th´eorie de la D´ecision standard a ´et´e d´evelopp´ee
par Pitman (1937). Aﬁn de comparer deux estimateurs δ1 et δ2 de θ, il a propos´e
de comparer les distributions de leurs distances (ou proximit´e) `a θ, soit,
Pθ (||δ1(x) −θ|| ≤||δ2(x) −θ||) .
Si cette probabilit´e est uniform´ement plus grande que 0.5, δ1 domine δ2 au
sens de Pitman, avec le message implicite que δ1 devrait alors ˆetre pr´ef´er´e `a
δ2. Quoique formellement semblable `a la domination stochastique, ce crit`ere,
dit proximit´e de Pitman, pr´esente des d´efauts majeurs, et nous d´econseillons
son utilisation comme crit`ere de comparaison. N´eanmoins, la litt´erature sur ce
sujet est assez vaste (voir, par exemple, Blyth, 1972b, Rao, 1980, 1981, Blyth
et Pathak, 1985, Rao et al., 1986, Keating et Mason, 1988, Peddada et Khat-
tree, 1986, Sen et al., 1989, Ghosh et Sen, 1989). Ces articles ´etudient les pro-
pri´et´es de la proximit´e de Pitman et mettent en avant son caract`ere intrins`eque,
puisqu’elle fait intervenir la distribution compl`ete de ||δ1(x) −θ|| (par opposi-
tion `a l’´evaluation r´eductrice `a travers une fonction de coˆut, quadratique par
exemple). `A l’oppos´e, Robert et al. (1993b) exposent les d´efauts fondamentaux
de ce crit`ere. Nous pr´esentons ici deux points caract´eristiques (voir les Exercices
2.58-2.63 pour d’autres exemples).
Une premi`ere critique importante de la proximit´e de Pitman concerne sa non-
transitivit´e. De fait, ce crit`ere ne fournit pas de moyen de d´eterminer un estima-
teur optimal ou mˆeme de comparer des estimateurs entre eux. Pitman (1937)
avait d´ej`a remarqu´e cette diﬃcult´e, mais certains partisans de ce crit`ere (voir no-
tamment Blyth, 1972a) aﬃrment de mani`ere paradoxale que cette propri´et´e est
un avantage suppl´ementaire, puisqu’elle reﬂ`ete la complexit´e du monde. Comme
nous l’avons d´ej`a vu, il peut eﬀectivement arriver qu’un ordre de pr´ef´erence
raisonnable ne soit pas toujours transitif. Mais le besoin aigu de r´eduire une
telle complexit´e mis `a part, notons que la proximit´e de Pitman est mise en
avant comme un crit`ere de comparaison, une alternative aux fonctions de coˆuts
usuelles : lorsqu’il y a non-transitivit´e, l’ordre d´eduit de ce crit`ere n’est pas ab-
solu puisque, comme le montre l’exemple suivant, il y a toujours une possibilit´e
d’obtenir un cycle de pr´ef´erence. Dans de tels cas, ce crit`ere ne peut pas fournir
d’estimateur optimal.
Exemple 2.53. Soient U ∼U[−0.9,1.1] et x = θU. On peut alors prouver que,
au sens de Pitman, δ0(x) = x domine δ1(x) = 0.9|x|, δ1 domine δ2(x) = 3.2|x|, et
δ2 domine δ0. Si on doit choisir l’un de ces trois estimateurs, ce crit`ere n’apporte
aucune aide.
∥
Bien entendu, la non-transitivit´e du crit`ere de Pitman l’empˆeche d’ˆetre ´equivalent
`a une fonction de coˆut ; `a ce titre, il ne peut pas relever de la Th´eorie de la
D´ecision. Pour la mˆeme raison, il ne peut pas ˆetre ´equivalent `a la domination
stochastique. En fait, Blyth et Pathak (1985) fournissent un exemple o`u ces deux
crit`eres produisent des ordres oppos´es. Il est de mˆeme impossible de d´eﬁnir un
estimateur de Bayes (d´ecisionnel) pour le crit`ere de Pitman (bien qu’un esti-
mateur a posteriori de Pitman puisse exister. Voir Bose, 1992 et Ghosh et al.,
1993).

112
2 Les bases de la Th´eorie de la D´ecision
Un second d´efaut majeur de la proximit´e de Pitman est qu’elle peut exclure
certains estimateurs classiques, mˆeme si ces derniers sont admissibles sous coˆut
quadratique. Par exemple, Efron (1975) remarque qu’il est possible de dominer
δ0(x) = x au sens de Pitman dans le cas gaussien, x ∼N (θ, 1). Robert et al.
(1993b) montrent qu’un ph´enom`ene de Stein aﬀecte Np(θ, Ip) pour p ≥2 et que
la condition de domination ne fait intervenir qu’une majoration pour la fonction
de r´etr´ecissement h (voir aussi Sen et al., 1989 et l’Exercice 2.63). Le r´esultat
suivant ´etend celui d’Efron (1975) au cas g´en´eral o`u x ∼f(x −θ) et θ est la
m´ediane de la distribution (voir l’Exercice 2.60 pour une d´emonstration).
Proposition 2.54. Sous les conditions ci-dessus, l’estimateur δ0(x) = x n’est
pas admissible au sens de Pitman.
De plus, les estimateurs dominants peuvent avoir des comportements ind´esira-
bles, par exemple ˆetre nuls sur de grandes parties de l’espace des observations
(voir l’Exercice 2.60).
Ces multiples d´efauts semblent indiquer clairement que la proximit´e de Pitman
n’est pas une alternative viable `a la Th´eorie de la D´ecision. Cet ´echec renforce
notre conviction que la Th´eorie de la D´ecision est la formalisation ad´equate
d’une prise de d´ecision dans un cadre incertain.
Comme nous l’avons soulign´e dans l’introduction, la d´etermination de la fonc-
tion de coˆut est une ´etape importante de la mod´elisation. Cette ´etape est trop
souvent ignor´ee, au proﬁt des fonctions de coˆut classiques, et il serait int´eressant
d’´etudier la robustesse de ce choix, `a l’instar de celle de la distribution a priori
(voir la Section 3.5). Cependant, cette diﬃcult´e pratique ne justiﬁe pas `a elle
seule de recourir `a des crit`eres exotiques, comme la proximit´e de Pitman, in-
trins`equement incoh´erents.

3
Des informations a priori aux lois a priori
“In the meantime, there was so much information to gather, so
many puzzles to solve. Their house was the perfect place for Moraine
to ﬁnd the information she needed. Except that it was not there.”
Robert Jordan, The Great Hunt.
3.1 La diﬃcult´e du choix d’une loi a priori
Sans conteste, le point le plus criticable et le plus critiqu´e de l’analyse
bay´esienne est le choix de la loi a priori. Car, une fois que cette loi a priori est
connue, l’inf´erence peut ˆetre conduite d’une fa¸con quasi m´ecanique en mini-
misant le coˆut a posteriori, en calculant les r´egions de plus forte densit´e a pos-
teriori ou en int´egrant les param`etres pour obtenir la distribution pr´edictive.
La loi a priori est la cl´e de voute de l’inf´erence bay´esienne et sa d´etermination
est donc l’´etape la plus importante dans la mise en œuvre de cette inf´erence.
Dans une certaine mesure, c’est aussi la plus diﬃcile. ´Evidemment, dans la
pratique, il est rare que l’information a priori soit suﬃsamment pr´ecise pour
conduire `a une d´etermination exacte de la loi a priori, au sens o`u plusieurs lois
de probabilit´e peuvent ˆetre compatibles avec cette information. Il y a plusieurs
raisons pour cela : le d´ecideur, le client ou le statisticien n’a pas forc´ement le
temps ou les ressources (ni souvent la volont´e) de chercher `a construire un a
priori exact (qui, de toute fa¸con, peut tout simplement ne pas exister, au vu
de l’information disponible) et doit compl´eter l’information partielle qu’il a
rassembl´ee `a l’aide de donn´ees subjectives aﬁn d’obtenir une loi a priori.

114
3 Des informations a priori aux lois a priori
Il est donc n´ecessaire le plus souvent de faire un choix (partiellement) ar-
bitraire de loi a priori, ce qui peut avoir un impact consid´erable sur l’inf´erence
qui en d´ecoule. En particulier, l’utilisation syst´ematique de lois usuelles (nor-
male, gamma, bˆeta, etc.) et la restriction plus forte encore aux lois conjugu´ees
(d´eﬁnies plus loin, dans la Section 3.3) ne sont pas toujours justiﬁ´ees, car
la d´etermination subjective de la loi a priori qui en r´esulte se fait au prix
d’un traitement analytique plus fruste du probl`eme, puisque ignorant une
partie de l’information a priori. Certaines situations requi`erent cependant
une d´etermination partiellement automatis´ee de la loi a priori comme dans
le cas extrˆeme o`u l’information a priori est compl`etement absente. Nous
consid´ererons deux techniques usuelles : l’approche a priori conjugu´ee (Section
3.3), qui n´ecessite une quantit´e limit´ee d’information, et l’approche non infor-
mative (Section 3.5), qui est obtenue `a partir de la distribution de l’´echantillon.
Historiquement, les d´etracteurs du paradigme bay´esien ont concentr´e leurs
critiques sur le choix de la loi a priori, en commen¸cant par celui eﬀectu´e par
Laplace. Tandis que Bayes pouvait justiﬁer sa mod´elisation a priori des boules
de billard par un raisonnement physique (voir la Section 1.2), la mod´elisation
abstraite par Laplace de la distribution des boules blanches dans une urne
(Exemple 1.9), ou de la proportion de gar¸cons (Exemple 1.11), les deux ´etant
fond´ees sur le principe de la raison insuﬃsante. se prˆetaient plus facilement
`a des critiques, qui d’ailleurs n’ont pas tard´e `a apparaˆıtre (voir Boole, 1854,
Bertrand, 1889, et Chrystal, 1891).
Ces critiques contre l’approche bay´esienne ont une certaine validit´e au
sens o`u elles attirent l’attention sur le fait qu’il n’y a pas une fa¸con unique de
choisir une loi a priori, et que le choix de cette loi a un impact sur l’inf´erence
r´esultante. Cet impact peut ˆetre n´egligeable, mod´er´e ou ´enorme, puisqu’il
est toujours possible de choisir une loi a priori qui donnera la r´eponse qu’on
souhaite obtenir. Mais le point essentiel est ici que, premi`erement, les lois
a priori non fond´ees fournissent des inf´erences a posteriori non justiﬁ´ees et,
deuxi`emement, le concept d’une loi a priori unique n’a pas de sens, sauf dans
des cas tr`es particuliers. Apr`es des ann´ees de critiques (voir la Note 1.8.1),
le travail de Jeﬀreys (1946) sur les a priori non informatifs apparut comme
un don du ciel pour la communaut´e bay´esienne, car il propose une m´ethode
de construction de la loi a priori directement d´eduite de la distribution des
observations. Certains bay´esiens sont cependant en d´esaccord avec l’utilisa-
tion de m´ethodes automatis´ees (voir, par exemple, Lindley, 1971, 1990). Plus
r´ecemment, les avanc´ees th´eoriques en robustesse et analyse de sensibilit´e ont
aussi fourni une base solide `a l’analyse bay´esienne dans les cas d’information
a priori incompl`ete, tandis que l’introduction de la mod´elisation hi´erarchique
(Chapitre 10) permet de placer la s´election d’un a priori `a un niveau plus
´eloign´e, avec une diminution notable de l’impact sur l’inf´erence r´esultante.

3.2 D´etermination subjective et approximations
115
3.2 D´etermination subjective et approximations
3.2.1 Existence
`A moins que le d´ecideur (ou le statisticien) ne soit inform´e sur le m´ecanisme
(physique, ´economique, biologique, etc.) sous-jacent de g´en´eration du pa-
ram`etre θ, il est g´en´eralement tr`es diﬃcile de proposer une forme exacte
ou mˆeme param´etr´ee pour la distribution a priori sur θ. En fait, dans la
plupart des cas, θ n’a pas de r´ealit´e propre (intrins`eque), mais correspond
plutˆot `a une param´etrisation de la loi d´ecrivant le ph´enom`ene al´eatoire ob-
serv´e. La loi π est alors un moyen de r´esumer l’information disponible sur ce
ph´enom`ene, ainsi que l’incertitude li´ee `a cette information. Ces situations im-
pliquent ´evidemment des approximations de la vraie distribution a priori—si
une vraie loi existe ! Eﬀectivement, et comme cela est discut´e dans le Chapitre
1, les mod`eles statistiques sont le plus souvent des repr´esentations simpliﬁ´ees
de ces ph´enom`enes al´eatoires et, puisqu’il n’existe pas de vrai mod`ele—mais
seulement un mod`ele le plus proche du ph´enom`ene pour une distance appro-
pri´ee— il est conceptuellement diﬃcile de parler de la vraie valeur de θ et, a
fortiori, d’une vraie loi a priori.
Exemple 3.1. (Dupuis, 1995b)
Dans une exp´erience de capture-recapture
(les d´etails de ces exp´eriences seront abord´es `a la Section 4.3.3) de l´ezards,
des biologistes s’int´eressent aux migrations de ces l´ezards entre des zones de
leur territoire (autour du mont Loz`ere). L’information disponible aupr`es des
biologistes sur les probabilit´es de capture et de survie, respectivement pt et
qit, o`u t et i sont les indices correspondant au temps et `a la r´egion consid´er´es,
est repr´esent´ee dans le Tableau 3.1 par une moyenne a priori et un intervalle
de conﬁance a priori de 95% pour ces probabilit´es. Plusieurs distributions a
priori sont compatibles avec cette information a priori. Par exemple, puisque
la distribution bˆeta Be(α, β) peut ˆetre caract´eris´ee par sa moyenne et un in-
tervalle de conﬁance (voir l’Exercice 3.1), le statisticien choisit la distribution
a priori bˆeta pr´esent´ee dans le Tableau 3.2.
∥
Tab. 3.1.
Information a priori sur les param`etres de capture et de survie pour
diﬀ´erents temps et sites de capture. (Source : Dupuis, 1995a.)
´Episode
2
3
4
5
6
Moyenne
0.3
0.4
0.5
0.2
0.2
int. 95% [0.1,0.5] [0.2,0.6] [0.3,0.7] [0.05,0.4] [0.05,0.4]
Site
A
B
´Episode
t = 1, 3, 5
t = 2, 4 t = 1, 3, 5
t = 2, 4
Moyenne
0.7
0.65
0.7
0.7
int. 95% [0.4,0.95]
[0.35,0.9] [0.4,0.95]
[0.4,0.95]

116
3 Des informations a priori aux lois a priori
Tab. 3.2.
Mod`ele a priori de capture et de survie correspondant `a l’information
du Tableau 3.1. (Source : Dupuis, 1995a.)
´Episode
2
3
4
5
6
Dist.
Be(6, 14)
Be(8, 12)
Be(12, 12)
Be(3.5, 14)
Be(3.5, 14)
Site
A
B
´Episode
t=1,3,5
t=2,4
t=1,3,5
t=2,4
Dist.
Be(6.0, 2.5)
Be(6.5, 3.5) Be(6.0, 2.5)
Be(6.0, 2.5)
Exemple 3.2. Un d´ecideur veut mod´eliser les distributions des observations
et du param`etre comme des lois normales : x1, . . . , xn ∼N (θ, 1) et θ ∼
N (μ, τ). Puisque la moyenne a posteriori de θ est
δπ(x1, . . . , xn) = ¯xτ + μ/n
τ + 1/n ,
l’hyperparam`etre τ −1 se comporte comme n, la taille de l’´echantillon, et μ
comme ¯x, la moyenne de l’´echantillon. Ces hyperparam`etres peuvent donc
ˆetre approch´es en comparant la quantit´e d’information apport´ee par (μ, τ) `a
celle apport´ee par un ´echantillon; par exemple, en consid´erant que la moyenne
(connue) μ est la moyenne d’un ´echantillon virtuel de taille 1/τ.
∥
D’un point de vue formel, il est possible de construire une distribution
a priori de la mˆeme fa¸con que pour les fonctions d’utilit´e dans le chapitre
pr´ec´edent, c’est-`a-dire en d´eterminant une ´echelle des vraisemblances respec-
tives des valeurs du param`etre θ. Quand cette ´echelle est coh´erente, c’est-`a-dire
respecte les axiomes donn´es ci-dessous, l’existence d’une distribution a priori
peut ˆetre d´eduite. L’existence d’une distribution a priori subjective comme
r´esultat d’un ordre des vraisemblances relatives est tr`es important, car il nous
permet d’´echapper au cadre restrictif des justiﬁcations fr´equentistes qui n’est
pas toujours applicable `a ce type de situations. Nous donnons dans la Note
3.8.1 les axiomes sur lesquels se fonde la preuve de l’existence d’une distribu-
tion a priori `a partir d’un ordre des vraisemblances et renvoyons les lecteurs
`a DeGroot (1970, Chapitre 6) pour un traitement plus approfondi (voir aussi
Jeﬀreys, 1961 et Bernardo et Smith, 1994).
Il arrive souvent que la d´etermination subjective d’une distribution a priori
conduise `a des incoh´erences dans l’ordre des vraisemblances, pour des raisons
psychologiques, mais aussi parce que la capacit´e des individus `a identiﬁer des
petites probabilit´es est assez limit´ee. `A ce sujet, ainsi que sur la construction
pratique d’une distribution de probabilit´e et l’´evaluation de pr´evisionnistes,
nous renvoyons les lecteurs `a DeGroot et Fienberg (1983), Dawid (1984),
Lindley (1985) et Smith (1988).

3.2 D´etermination subjective et approximations
117
3.2.2 Approximations de la loi a priori
Quand l’espace des param`etres Θ est ﬁni, il est souvent possible d’obtenir
une ´evaluation subjective des probabilit´es des diﬀ´erentes valeurs de θ. Parfois,
on peut utiliser des exp´eriences pr´ec´edentes du mˆeme type, mais ce n’est pas
toujours le cas. Pensons, par exemple, `a l’obtention de la loi d’un incident
nucl´eaire majeur ! Plus fondamentalement, cette approche fr´equentiste m`ene
`a se poser la question conceptuelle de la r´ep´etabilit´e des exp´eriences (Les
cadres exp´erimentaux sont-ilstoujours les mˆemes ? Une exp´erience peut-elle
n’avoir aucun eﬀet sur l’exp´erience suivante ?). Jeﬀreys (1961) fournit une
critique d´etaill´ee de cette hypoth`ese.
Quand l’espace des param`etres Θ n’est pas d´enombrable, par exemple,
lorsqu’il s’agit d’un intervalle, la d´etermination subjective de la loi a priori π
est ´evidemment beaucoup plus compliqu´ee. En g´en´eral, une premi`ere approxi-
mation de π est obtenue par le partitionnement de Θ en diﬀ´erents ensembles
(par exemple des intervalles) et la d´etermination de la probabilit´e de chaque
ensemble ; π(θ) est alors approch´ee par un histogramme. Une autre d´emarche
consiste `a s´electionner des ´el´ements signiﬁcatifs de Θ, `a ´evaluer leurs vrai-
semblances respectives et `a en d´eduire une courbe de vraisemblance propor-
tionnelle `a π. Dans les deux cas, une diﬃcult´e majeure se pr´esente lorsque Θ
n’est pas born´e. En eﬀet, il est alors n´ecessaire de construire les queues de
la distribution et il est assez diﬃcile d’´evaluer subjectivement les probabilit´es
des r´egions extrˆemes de l’espace des param`etres; c’est d’autant plus gˆenant
que la forme et les propri´et´es des estimateurs r´esultants d´ependent fortement
de ces queues (voir l’Exemple 3.5).
Quand aucune information directe n’est disponible sur θ, une alternative
est de recourir `a la distribution marginale de x,
m(x) =

Θ
f(x|θ)π(θ) dθ
aﬁn d’obtenir de l’information sur π. Plusieurs techniques ont ´et´e propos´ees
dans la litt´erature (voir Berger, 1985b, Section 3.5) ; en plus de la m´ethode
des moments, nous pouvons citer l’entropie maximale et les m´ethodes ML-
II (Good, 1983). Le principe de cette construction est que le ph´enom`ene
al´eatoire observ´e peut dans certains cas ˆetre incorpor´e dans une classe plus
large (ou m´eta mod`ele) pour laquelle une information est disponible. Par
exemple, si θ est la moyenne journali`ere de production de lait pour une vache
laiti`ere donn´ee, une information sur θ peut ˆetre obtenue `a partir de la pro-
duction du troupeau auquel appartient la vache, bien que ces observations
proviennent de la distribution marginale. Cette perspective est au cœur des
mod`eles hi´erarchiques (Chapitre 10) et elle permet de r´esoudre la diﬃcult´e de
la r´ep´etabilit´e des exp´eriences mentionn´ee ci-dessus.

118
3 Des informations a priori aux lois a priori
3.2.3 Lois a priori d’entropie maximale
Si certaines caract´eristiques de la loi a priori sont connues (moments, quan-
tiles, etc.), en supposant qu’elles peuvent s’´ecrire comme des esp´erances a
priori (k = 1, . . . , K),
Eπ[gk(θ)] = ωk ,
(3.1)
une fa¸con de choisir un a priori qui satisfait ces contraintes est la m´ethode de
l’entropie maximale, d´evelopp´ee par Jaynes (1980, 1983).
Dans un cadre ﬁni, l’entropie est d´eﬁnie comme
E(π) = −

i
π(θi) log{π(θi)} .
Cette quantit´e a ´et´e introduite par Shannon (1948) comme une mesure de
l’incertitude en th´eorie de l’information et en traitement du signal. L’a priori
π qui maximise l’entropie minimise, dans ce sens th´eorico-informatif, l’infor-
mation a priori apport´ee par π sur θ. La distribution d’entropie maximale,
sous les contraintes de moments (3.1), est la distribution associ´ee `a la densit´e
π∗(θi) =
exp
%K
1 λkgk(θi)
&

j exp
%K
1 λkgk(θj)
&,
les nombres λk ´etant obtenus `a partir de (3.1) comme des multiplicateurs de
Lagrange. Par exemple, sans contrainte sur π, la distribution d’entropie maxi-
male est la distribution uniforme sur Θ. (Cette propri´et´e r´ev`ele un probl`eme
de fond de la m´ethode, car les lois a priori d’entropie maximale ne sont pas
invariantes par reparam´etrisation; voir la Section 3.5.1.)
L’extension au cas continu est plus d´elicate, car elle implique le choix
d’une mesure de r´ef´erence π0, qui peut ˆetre caract´eris´ee comme la distribu-
tion compl`etement non informative. Il s’agit en eﬀet de l’a priori d’entropie
maximale en l’absence de contrainte. Cette mesure de r´ef´erence peut ˆetre ob-
tenue de plusieurs fa¸cons (voir la Section 3.5) et la distribution d’entropie
maximale d´epend de ce choix. Quand une structure de groupe est disponible
pour le probl`eme d’int´erˆet (et accept´ee comme une partie de l’information a
priori), on convient g´en´eralement que la mesure de Haar invariante `a droite
associ´ee `a ce groupe est un choix acceptable pour π0. (Les justiﬁcations pour
un tel choix sont donn´ees dans le Chapitre 9.) Une fois la mesure de r´ef´erence
π0 choisie, l’entropie de π est d´eﬁnie par
E(π) = Eπ0

log
 π(θ)
π0(θ)

=

log
 π(θ)
π0(θ)

π0(dθ),
qui est aussi la distance de Kullback-Leibler entre π et π0. Dans ce cas, la
distribution d’entropie maximale sous (3.1) est donn´ee par la densit´e

3.2 D´etermination subjective et approximations
119
π∗(θ) =
exp
%K
1 λkgk(θ)
&
π0(θ)
 exp
%K
1 λkgk(η)
&
π0(dη)
,
(3.2)
ce qui prouve l’importance de π0. Notons que les distributions π∗ci-dessus
appartiennent formellement `a une famille exponentielle (voir la Section 3.3.3).
En plus de la d´ependance `a π0 exhib´ee par (3.2) et du manque d’inva-
riance par reparam´etrisation, un autre inconv´enient de la m´ethode d’entropie
maximale est que les contraintes (3.1) ne sont pas toujours suﬃsantes pour
obtenir une distribution sur θ. Signalons que c’est souvent le cas quand les
caract´eristiques (3.1) sont li´ees aux quantiles, car les fonctions gk(θ) sont alors
de la forme I(−∞,ak](θ) ou I(bk,∞](θ).
Exemple 3.3. Soit θ, un param`etre r´eel tel que Eπ[θ] = μ. Si la mesure de
r´ef´erence π0 est la mesure de Lebesgue sur R, l’a priori d’entropie maximale
satisfait π∗(θ) ∝eλθ et ne peut pas ˆetre normalis´e comme une distribution
de probabilit´e. En revanche, si on sait de plus que var(θ) = σ2, la loi a priori
d’entropie maximale correspondante est
π∗(θ) ∝exp{θλ1 + θ2λ2},
soit donc la distribution normale N (μ, σ2).
∥
Seidenfeld (1987) et Kass et Wasserman (1996) avancent des critiques
suppl´ementaires sur l’approche par entropie maximale (Exercice 3.2).
3.2.4 Approximations param´etriques
Une alternative fr´equemment utilis´ee pour construire un a priori continu
consiste `a restreindre arbitrairement le choix de π `a une famille de densit´es
param´etr´ees et `a d´eterminer les param`etres correspondants via les moments
ou via les quantiles, cette seconde option ´etant plus robuste. Par exemple, des
´evaluations subjectives de la m´ediane et du quantile `a 75% sont suﬃsantes
pour identiﬁer les deux param`etres d’une distribution normale. (Voir aussi
l’Exemple 3.1.)
Exemple 3.4. Soit Xi ∼B(ni, pi) le nombre d’´etudiants r´eussissant l’exa-
men d’introduction `a l’analyse, dans une classe de ni ´etudiants. Les ann´ees
pr´ec´edentes, la moyenne des pi a ´et´e de 0.70, avec une variance de 0.1. Si
nous supposons que les pi sont tous g´en´er´es selon la mˆeme distribution bˆeta,
Be(α, β), les param`etres α et β sont estim´es par
α
α + β = 0.7,
αβ
(α + β)2(α + β + 1) = 0.1,
soit α = 0.77 et β = 0.33, ce qui conduit `a la distribution a priori

120
3 Des informations a priori aux lois a priori
p ∼Be(0.77, 0.33).
Dans ce cas, le choix de la distribution bˆeta est motiv´e par son caract`ere
conjugu´e (voir la Section 3.3).
∥
La m´ethode des moments est souvent diﬃcilement applicable et engendre
parfois des valeurs impossibles des param`etres, comme par exemple des va-
riances n´egatives. Cependant, un inconv´enient plus grave de la plupart des
approches param´etriques est que la s´election de la famille param´etr´ee est
fond´ee sur la simplicit´e du traitement math´ematique et non sur des bases
subjectives comme un histogramme pr´eliminaire approchant π. Cette ap-
proche peut mˆeme provoquer un rejet partiel de l’information disponible,
parce qu’elle n’est pas compatible avec la distribution param´etr´ee. Ainsi, dans
les Exemples 3.1 et 3.4, la connaissance a priori suppl´ementaire de la m´ediane
peut empˆecher l’utilisation d’une distribution bˆeta. En r´ealit´e, la construc-
tion d’une distribution `a partir d’un histogramme peut aussi ˆetre trompeuse,
car diﬀ´erentes familles peuvent correspondre au mˆeme histogramme et mener
malgr´e tout `a des inf´erences assez diﬀ´erentes. (N´eanmoins, nous ´etudierons
dans la prochaine section une m´ethode particuli`ere de d´etermination de loi a
priori param´etr´ee, car les cas o`u l’information est limit´ee n´ecessitent une telle
approche.)
Exemple 3.5. (Berger, 1985b) Soit x ∼N (θ, 1). Supposons que la m´ediane
a priori de θ soit 0, que le premier quartile a priori soit −1, et que le troisi`eme
quartile a priori soit +1. Alors, si la distribution a priori sur θ est de la forme
N (μ, τ), nous devons avoir θ ∼N (0, 2.19). En revanche, le choix d’une
distribution de Cauchy m`ene `a θ ∼C (0, 1). Sous une perte quadratique,
l’estimateur de Bayes devrait ˆetre, dans le premier cas,
δπ
1 (x) = x −
x
3.19
et
δπ
2 (x) ≈x −
x
1 + x2
dans le deuxi`eme cas pour |x| ≥4 (voir Berger et Srinivasan, 1978). Par
cons´equent, pour x = 4, qui est une observation assez compatible avec l’in-
formation a priori dans les deux cas, les deux estimations devraient ˆetre
δπ
1 (4) = 2.75 et δπ
2 (4) = 3.76 ! La Figure 3.1 compare les deux estimateurs
pour une s´erie de valeurs de x, le calcul de δπ
2 ´etant fait par la m´ethode de
Monte Carlo (voir le Chapitre 6).
∥
Ces diﬀ´erences de r´esultats d´emontrent la n´ecessit´e de conduire des tests
sur la validit´e (ou robustesse) des lois a priori choisies, tests d´ependants des
observations, aﬁn d’´evaluer `a quel point un l´eger changement dans la distri-
bution a priori inﬂue sur l’inf´erence sur les param`etres d’int´erˆet. (La Section

3.2 D´etermination subjective et approximations
121
−1
0
1
2
3
4
5
0
1
2
3
4
x
Fig. 3.1. Comparaison des estimateurs δπ
1 (x) (pointill´es) et δπ
2 (x) (traits pleins).
3.5 traite de cette ´evaluation.) L’exemple ci-dessous illustre `a nouveau le fait
qu’une information trop vague peut mener `a des conclusions tr`es diﬀ´erentes,
selon la fa¸con dont elle est interpr´et´ee.
Tab. 3.3. ´Etendue des valeurs des moments a posteriori pour des moments a priori
μ1 = 0 et μ2 ﬁx´es. (Source : Goutis, 1990.)
Moyenne
Moyenne
Variance
μ2
x
minimale maximale maximale
3
0
-1.05
1.05
3.00
3
1
-0.70
1.69
3.63
3
2
-0.50
2.85
5.78
1.5
0
-0.59
0.59
1.50
1.5
1
-0.37
1.05
1.97
1.5
2
-0.27
2.08
3.80
Exemple 3.6. (Goutis, 1990, 1994) Soit x ∼f(x|θ), avec θ ∈R, et supposons
que la moyenne a priori de θ, μ1, soit connue. Trop de distributions a priori
s’accordent avec cette information, car
inf
π Eπ[θ|x] = −∞
et
sup
π Eπ[θ|x] = +∞
et aucune inf´erence utile ne peut ˆetre men´ee `a partir de cette seule informa-
tion ; notons que dans ce cas il est aussi impossible de construire une distribu-
tion d’entropie maximale (voir l’Exemple 3.3). Si, de plus, la variance a priori
μ2 est ﬁx´ee, la variabilit´e des r´eponses a posteriori est plus restreinte, car
−∞< inf
π Eπ[θ|x] ≤sup
π Eπ[θ|x] < +∞,
(3.3)

122
3 Des informations a priori aux lois a priori
tant que f(x|θ) est positive dans un voisinage de μ1 et born´ee quand |θ −μ1|
est grand. Sous les mˆemes hypoth`eses, nous avons de plus
0 = inf
π Varπ[θ|x] ≤sup
π Varπ[θ|x] < +∞.
(3.4)
Le Tableau 3.3 donne l’´etendue exacte des bornes (3.3) et (3.4) pour une
distribution normale N (θ, 1) et μ1 = 0.
∥
3.2.5 Autres techniques
Les techniques de Bayes dites empiriques et hi´erarchiques sont deux ap-
proches relativement oppos´ees qui int`egrent l’incertitude sur la distribution a
priori d’une fa¸con naturelle et qui seront trait´ees en d´etail dans le Chapitre 10
(voir aussi Carlin et Louis, 2000a). L’approche bay´esienne empirique se fonde
sur les observations (et la distribution marginale) pour estimer les param`etres
de la distribution a priori ; elle est utilis´ee plus souvent par les fr´equentistes
que par les bay´esiens, car elle n’ob´eit pas au paradigme bay´esien. Formelle-
ment, il semble paradoxal de choisir a posteriori une distribution a priori !
Plus fondamentalement, le choix de π d´ependant de x, les estimateurs ob-
tenus ne b´en´eﬁcient pas des propri´et´es d’optimalit´e des vrais estimateurs de
Bayes. Une derni`ere critique est qu’il existe de trop nombreuses possibilit´es
pour les techniques d’estimations utilis´ees dans la construction des distribu-
tions a priori, ce qui donne par cons´equent un caract`ere fortement arbitraire
`a la s´election d’un a priori.
L’approche hi´erarchique bay´esienne mod´elise le manque d’information sur
les param`etres d’une distribution a priori en recourant au paradigme de Bayes,
c’est-`a-dire en sp´eciﬁant une autre distribution sur ces param`etres (les pa-
ram`etres de cette distribution sont appel´es hyperparam`etres et ces nouveaux
a priori, des lois hyper a priori). Bien que ce choix puisse paraˆıtre conceptuel-
lement trop abstrait, les bay´esiens pr´ef`erent g´en´eralement cette approche `a
l’alternative empirique, car, dans un sens pratique et th´eorique, celle-ci four-
nit de meilleurs estimateurs. (Le Chapitre 10 pr´esente et compare ces deux
techniques.)
3.3 Lois a priori conjugu´ees
3.3.1 Introduction
Quand l’information a priori sur le mod`ele est trop vague ou peu ﬁable, une
construction subjective compl`ete de la distribution a priori est ´evidemment
impossible. D’autres raisons (retards, coˆuts `a respecter, manque de commu-
nication entre statisticiens et d´ecideurs, etc.) peuvent expliquer l’absence

3.3 Lois a priori conjugu´ees
123
de distributions correctement d´eﬁnies. De plus, des exigences d’objectivit´e
peuvent forcer le statisticien `a fournir une r´eponse aussi neutre que possible,
aﬁn de fonder l’inf´erence sur le mod`ele d’´echantillonnage uniquement. De
tels cas semblent justiﬁer le recours `a des solutions non bay´esiennes (estima-
teurs du maximum de vraisemblance, estimateurs sans biais optimaux, etc.).
Cependant, tout en gardant `a l’esprit les fondements bay´esiens des crit`eres
fr´equentistes d’optimalit´e (voir les Chapitres 2, 8 et 9), il paraˆıt pr´ef´erable de
suivre l’approche bay´esienne, en utilisant un a priori dit objectif, c’est-`a-dire
construit `a partir du mod`ele d’´echantillonnage, comme un outil technique.
Lorsque aucune information a priori n’est disponible, ces a priori sont dits
non informatifs et sont trait´es dans la Section 3.5.
D’abord, nous ´etudierons dans cette section une approche param´etrique
classique qui implique un apport d’information subjective le plus limit´e pos-
sible et qui est `a la base des deux techniques bay´esiennes, hi´erarchique et
empirique, du Chapitre 10. En dehors de l’exigence d’une contribution sub-
jective minimale, les lois a priori conjugu´ees peuvent ˆetre consid´er´ees comme
un point de d´epart pour l’´elaboration de distributions a priori fond´ees sur une
information a priori limit´ee, dont l’impr´ecision peut ˆetre d´etermin´ee grˆace `a
des distributions a priori suppl´ementaires. Cependant, il faut garder `a l’esprit
le fait que l’impression commune que les lois conjugu´ees sont non informatives
est fausse : le choix d’un a priori conjugu´e, bien qu’il soit d´efendable comme
on le verra ci-dessous, est toujours un choix particulier et inﬂuence donc, dans
une certaine mesure, l’inf´erence r´esultante. De plus, il peut obliger `a ignorer
une partie de l’information a priori si cette derni`ere n’est pas compl`etement
compatible avec la structure de la loi a priori conjugu´ee. Enﬁn il existe d’autres
lois a priori fond´ees sur la mˆeme information subjective limit´ee, mais avec une
inﬂuence plus limit´ee sur l’inf´erence r´esultante (voir la Section 3.6).
D´eﬁnition 3.7. Une famille F de distributions de probabilit´e sur Θ est dite
conjugu´ee (ou ferm´ee par ´echantillonnage) par une fonction de vraisemblance
f(x|θ) si, pour tout π ∈F, la distribution a posteriori π(·|x) appartient
´egalement `a F.
Un exemple trivial d’une famille conjugu´ee est l’ensemble F0 de toutes les
lois de probabilit´e sur Θ, qui est bien entendu inutile pour le choix d’une loi a
priori. L’int´erˆet principal du caract`ere conjugu´e devient plus ´evident quand F
est param´etr´ee. Eﬀectivement, le passage de distribution a priori `a distribution
a posteriori se r´eduit dans ce cas `a une mise `a jour des param`etres correspon-
dants. Cette seule propri´et´e peut expliquer pourquoi les lois a priori conjugu´ees
sont si populaires, car les distributions a posteriori sont toujours calculables
(au moins jusqu’`a un certain degr´e). En revanche, une telle justiﬁcation est
plutˆot faible d’un point de vue subjectif et d’autres familles pourraient aussi
bien convenir. Notons que l’objectif d’obtenir la famille conjugu´ee minimale
comme l’intersection de toutes les familles conjugu´ees est malheureusement
vou´e `a l’´echec, car cette intersection est vide (Exercice 3.13).

124
3 Des informations a priori aux lois a priori
3.3.2 Justiﬁcations
L’approche a priori conjugu´ee, introduite par Raiﬀa et Schlaifer (1961),
peut ˆetre justiﬁ´ee partiellement par un raisonnement d’invariance. En fait,
quand l’observation de x ∼f(x|θ) modiﬁe π(θ) en π(θ|x), l’information trans-
mise par x sur θ est ´evidemment limit´ee ; par cons´equent, elle ne devrait pas
entraˆıner une modiﬁcation de toute la structure de π(θ), mais simplement
de ses param`etres. En d’autres termes, la modiﬁcation r´esultant de l’obser-
vation de x devrait ˆetre de dimension ﬁnie. Un changement plus radical de
π est alors inacceptable et le choix des lois a priori devrait toujours ˆetre fait
parmi les lois conjugu´ees, quelle que soit l’information a priori. D’une certaine
fa¸con, de Finetti (1974) avait un avis similaire parce qu’il consid´erait que l’in-
formation a priori pouvait ˆetre interpr´et´ee comme des observations pass´ees
virtuelles, comme dans l’Exemple 3.2, ce qui m`ene forc´ement `a des lois a
priori conjugu´ees pour des familles exponentielles (voir ci-dessous). Malheu-
reusement, cette condition devient paradoxale dans les cas extrˆemes o`u toute
la distribution a priori est d´ej`a disponible ! Mais les lois a priori conjugu´ees
sont surtout utilis´ees dans des environnements o`u l’information est limit´ee,
car elles ne n´ecessitent la d´etermination que de quelques param`etres. Une
autre justiﬁcation pour utiliser les lois a priori conjugu´ees est que certains
estimateurs de Bayes sont alors lin´eaires, comme l’ont montr´e Diaconis et
Ylvisaker (1979) (voir la Proposition 3.19 ci-dessous). N´eanmoins, nous de-
vons reconnaˆıtre que la principale motivation pour utiliser les lois a priori
conjugu´ees reste la commodit´e de traitement.
Cette mod´elisation particuli`ere par une famille param´etr´ee de lois a priori
est eﬀectivement tr`es tentante, car elle autorise des manipulations explicites
des lois a posteriori. Ces lois a priori conjugu´ees sont parfois appel´ees objectives
parce que le mod`ele d’´echantillonnage, f(x|θ), d´etermine enti`erement la classe
des lois a priori, mais toute m´ethode qui produit de fa¸con automatique des lois
a priori `a partir de la distribution d’´echantillonnage serait tout aussi objective.
A contrario, leur utilisation est fortement critiqu´ee par certains bay´esiens, car
elle ob´eit `a des contraintes techniques plutˆot qu’`a des imp´eratifs d’ad´equation
`a l’information a priori disponible. Le rˆole des lois a priori conjugu´ees est alors
de fournir une premi`ere approximation de la distribution a priori ad´equate,
qui devrait ˆetre suivie d’une analyse de robustesse (voir la Section 3.5). Nous
verrons dans la Section 3.4 qu’elles sont plus justiﬁ´ees si on les traite comme
une base (dans un sens fonctionnel) pour la mod´elisation de l’information a
priori.
3.3.3 Familles exponentielles
Les lois a priori conjugu´ees sont g´en´eralement associ´ees `a un type par-
ticulier de lois d’´echantillonnage qui permet toujours leur obtention ; il est
mˆeme caract´eristique des lois a priori conjugu´ees comme nous le verrons ci-

3.3 Lois a priori conjugu´ees
125
dessous. Ces lois constituent ce qu’on appelle des familles exponentielles et
sont ´etudi´ees en d´etail dans Brown (1986b).
D´eﬁnition 3.8.
Soient μ une mesure σ-ﬁnie sur X , Θ l’espace des pa-
ram`etres, C et h des fonctions respectivement de X et Θ dans R+, et R
et T des fonctions de Θ et X dans Rk. La famille des distributions de densit´e
(par rapport `a μ)
f(x|θ) = C(θ)h(x) exp{R(θ) · T (x)}
(3.5)
est dite famille exponentielle de dimension k. Dans le cas particulier o`u Θ ⊂
Rk, X ⊂Rk et
f(x|θ) = C(θ)h(x) exp{θ · x},
(3.6)
la famille est dite naturelle.
Notons qu’un changement de variable de x en z = T (x) et une repa-
ram´etrisation de θ en η = R(θ) nous permettent de consid´erer principalement
la forme naturelle (3.6), bien que les espaces T (X ) et R(Θ) puissent ˆetre
diﬃciles `a d´ecrire et `a utiliser.
D’un point de vue analytique, les familles exponentielles ont certaines
caract´eristiques int´eressantes (voir Brown, 1986b). En particulier, elles sont
telles que, pour tout ´echantillon de (3.5), il existe une statistique exhaustive
de dimension constante. En eﬀet, si x1, . . . , xn ∼f(x|θ), avec f satisfaisant
(3.6),
¯x = 1
n
n

i=1
xi ∈Rk
est exhaustive pour tout n. La r´eciproque de ce r´esultat a ´et´e aussi ´etablie
par Koopman (1936) et Pitman (1936) (voir aussi Jeﬀreys, 1961, Section 3.7.1
pour une preuve).
Th´eor`eme 3.9. (Lemme de Pitman-Koopman)
Si une famille de lois
f(·|θ) `a support constant est telle que, `a partir d’une taille d’´echantillon suf-
ﬁsamment grande, il existe une statistique exhaustive de taille ﬁxe, la famille
est exponentielle.
La restriction sur le support de f(·|θ) est une condition n´ecessaire pour le
lemme parce que les distributions uniforme U ([−θ, θ]) et de Pareto P(α, θ)
satisfont aussi cette propri´et´e (voir l’Exemple 3.16). En r´ealit´e, ces dis-
tributions pourraient ˆetre appel´ees familles quasi exponentielles, car elles
h´eritent de plusieurs des propri´et´es int´eressantes des familles exponentielles,
incluant l’existence de statistiques suﬃsantes de dimension constante et de
lois conjugu´ees (Exercice 3.15).
De nombreuses distributions usuelles continues et discr`etes appartiennent
`a des familles exponentielles.

126
3 Des informations a priori aux lois a priori
Exemple 3.10. Si Sk est le simplexe de Rk,
Sk =

ω = (ω1, . . . , ωk);
k

i=1
ωi = 1, ωi > 0

,
la loi de Dirichlet sur Sk, Dk(α1, . . . , αk), est une extension de la distribution
bˆeta, d´eﬁnie comme
f(p|α) = Γ(α1 + · · · + αk)
Γ(α1) · · · Γ(αk)
k

i=1
pαi−1
i
ISk(p),
o`u p = (p1, . . . , pk). Puisque
f(p|α) = C(α)h(p) exp
	
k

i=1
αi log(pi)

,
la loi de Dirichlet constitue une famille naturelle exponentielle pour T (p) =
(log(p1), . . . , log(pk)).
∥
Exemple 3.11. Soit x ∼Np(θ, σ2Ip). Alors
f(x|θ) = 1
σp
1
(2π)p/2 exp

−
p

i=1
(xi −θi)2/2σ2

= C(θ, σ)h(x) exp{x.(θ/σ2) + ||x||2(−1/2σ2)}
et la distribution normale appartient `a une famille exponentielle de param`etres
naturels θ/σ2 et −1/2σ2. De la mˆeme fa¸con, si x1, . . . , xn ∼Np(θ, σ2Ip), la
distribution jointe satisfait
f(x1, . . . , xn) = C′(θ, σ)h′(x1, . . . , xn)
× exp

n¯x · (θ/σ2) +
n

i=1
||xi −¯x||2(−1/2σ2)

et la statistique (¯x, 
i ||xi −¯x||2) est exhaustive pour tout n ≥2.
∥
Dans l’exemple pr´ec´edent, notons que l’espace des param`etres est de di-
mension p + 1, tandis que la dimension des observables, x, est p. Bien que la
dimension d’une famille exponentielle ne soit pas ﬁx´ee, car il est toujours pos-
sible d’ajouter des combinaisons convexes des param`etres originaux comme
des param`etres suppl´ementaires (et ´evidemment inutiles), une dimension mi-
nimale intrins`eque est associ´ee `a cette famille.

3.3 Lois a priori conjugu´ees
127
D´eﬁnition 3.12. Soit f(x|θ) = C(θ)h(x) exp(θ.x), une famille exponentielle
naturelle. L’espace naturel des param`etres est
N =

θ;

X
eθ·xh(x) dμ(x) < +∞

.
La famille est dite r´eguli`ere si N est un ensemble ouvert et minimale si
dim(N) = dim(K) = k, o`u K est la clˆoture de l’enveloppe convexe du support
de μ.
Il est toujours possible de r´eduire une famille exponentielle `a une forme
standard et minimale de dimension m, et cette dimension m ne d´epend aucu-
nement de la param´etrisation choisie (Brown, 1986b, p. 13-16). (Voir l’Exercice
3.23 pour l’exemple d’une famille exponentielle non r´eguli`ere.)
Les familles exponentielles naturelles peuvent aussi ˆetre r´e´ecrites sous la
forme
f(x|θ) = h(x) eθ.x−ψ(θ)
(3.7)
et ψ(θ) est dite fonction cumulante des moments pour la raison suivante, dont
la d´emonstration est laiss´ee aux lecteurs.
Lemme 3.13. Si θ ∈˚
N, int´erieur de N, la fonction cumulante des moments
ψ est C ∞et
Eθ[x] = ∇ψ(θ),
cov(xi, xj) =
∂2ψ
∂θi∂θj
(θ),
o`u ∇d´esigne l’op´erateur gradient.
Exemple 3.14. Soit x ∼P(λ). Alors
f(x|λ) = e−λ λx
x! = 1
x! eθ.x−eθ
et ψ(θ) = exp(θ) pour le param`etre naturel θ = log λ. Par cons´equent, Eλ[x] =
eθ = λ et var(x) = λ.
∥
La structure r´eguli`ere des familles exponentielles permet de nombreuses
applications statistiques, comme en t´emoigne la vaste litt´erature sur ce sujet.
(Voir, par exemple, la classiﬁcation des familles exponentielles selon le type de
fonction de variance : Morris, 1982, Letac et Mora, 1990, et Exercices 3.24 et
10.33.) Nous verrons dans la Section 3.3.4 qu’elles autorisent ´egalement une
construction simple des lois a priori conjugu´ees.
Exemple 3.15. Si x ∼N (θ, θ2) dans un mod`ele multiplicatif, la loi a priori
conjugu´ee n’est pas la loi normale. La vraisemblance est proportionnelle `a

128
3 Des informations a priori aux lois a priori
1
| θ | exp
x
θ −x2
2θ2

et la distribution induit une famille exponentielle de dimension 2. Par cons´equent,
les lois normales inverses g´en´eralis´ees I N (α, μ, τ), de densit´e
π(θ) ∝|θ|−α exp

−
1
θ −μ
2 '
2τ 2

constituent pour ce mod`ele une famille conjugu´ee. Cette famille de lois, qui
forme une famille exponentielle, g´en´eralise la loi de l’inverse d’une observation
normale (qui correspond au cas α = 2). (Voir l’Exercice 3.33 pour plus de
d´etails.)
∥
-2
-1
0
1
2
0.0
0.5
1.0
1.5
2.0
 0
1
2
Fig. 3.2. Densit´es I N (α, μ, τ) pour α = 2, τ = 1 et μ = 0, 1, 2.
´Evidemment, la plupart des lois n’appartiennent pas `a une famille expo-
nentielle ! Par exemple, la loi de Student, Tp(ν, θ, σ2), ne peut pas s’exprimer
sous la forme (3.5). La D´eﬁnition 3.8 exclut aussi toutes les lois avec un
support non constant, alors que certaines d’entre elles admettent des lois a
priori conjugu´ees avec un nombre ﬁni de param`etres (ou plus exactement,
d’hyperparam`etres).
Exemple 3.16. Les lois de Pareto, P(α, θ), de densit´e
f(x|α, θ) = α θα
xα+1 I[θ,+∞[(x)
(θ > 0),
sont de telles lois puisque, bien qu’en dehors du cadre des familles exponen-
tielles, elles admettent des lois conjugu´ees simples sur θ, qui sont des lois de
Pareto pour 1/θ.
∥

3.3 Lois a priori conjugu´ees
129
D’autres exemples de familles pour lesquelles des lois conjugu´ees sont dis-
ponibles sont les distributions U[−θ,θ] et U[0,θ] ; ces lois sont aussi quasi ex-
ponentielles, car elles admettent des statistiques exhaustives de dimension
constante. Par exemple, si x1, . . . , xn ∼U[−θ,θ], une statistique exhaustive
est la statistique d’ordre (x(1), x(n)), o`u x(1) est la valeur la plus petite de
l’´echantillon et x(n) la plus grande.
Notons que, dans l’Exemple 3.15, la loi a priori conjugu´ee sur θ d´epend
de trois hyperparam`etres, α, μ, et τ2 ; par cons´equent, leur utilisation intro-
duit une plus grande complexit´e dans la loi du mod`ele. Ce type de ph´enom`ene,
c’est-`a-dire le fait que la structure du mod`ele exige un nombre plus grand d’hy-
perparam`etres, est souvent rencontr´e dans les familles exponentielles courbes,
par exemple quand une reparam´etrisation naturelle par η = R(θ) n’est pas
utile `a cause des contraintes portant sur les param`etres naturels. Il s’agit
´evidemment d’un inconv´enient, car les valeurs de ces hyperparam`etres doivent
ˆetre d´etermin´ees pour obtenir une inf´erence sur θ utilisant des lois conjugu´ees.
Quand une distribution n’admet pas de famille conjugu´ee, sauf le cas trivial
F0, il est parfois possible d’exprimer cette distribution comme un m´elange de
distributions de familles exponentielles ; f est appel´ee m´elange cach´e, car cette
repr´esentation est sans pertinence pour le probl`eme inf´erentiel, mais est utile
pour le calcul pratique de la loi a posteriori et des estimateurs de Bayes,
comme nous le verrons dans le Chapitre 6.
Exemple 3.17. (Dickey, 1968)
Pour la loi de Student, une repr´esentation
de m´elange cach´e existe, fond´ee sur la distribution normale, car f(x|θ) est le
m´elange d’une distribution normale par l’inverse d’une distribution gamma :
si x ∼T1(p, θ, σ2),
x|z ∼N (θ, zσ2),
z−1 ∼G (p/2, p/2) .
Une loi a priori techniquement int´eressante sur θ est alors N (μ, τ2) et la plu-
part des calculs peuvent ˆetre faits conditionnellement `a z. Cette d´ecomposition
est plus utile quand x est multidimensionnel, car certaines int´egrales de-
viennent alors unidimensionnelles.
∥
Exemple 3.18. Plusieurs lois non centr´ees peuvent s’´ecrire comme un m´e-
lange (cach´e) des lois centr´ees correspondantes par la loi de Poisson, de par
une propri´et´e d’inﬁnie divisibilit´e (voir Feller, 1971, Chapitre 9). Par exemple,
tel est le cas de la loi du khi deux d´ecentr´e, χ2
p(λ) : Lorsque x ∼χ2
p(λ), la
g´en´eration de x peut ˆetre aussi d´ecompos´ee comme
x|z ∼χ2
p+2z,
z ∼P(λ/2).
Cette d´ecomposition est utilis´ee par James et Stein (1961) pour exprimer le
risque de leur estimateur et obtenir une condition suﬃsante de domination de
l’estimateur de maximum de vraisemblance (voir la Note 2.8.2).
∥

130
3 Des informations a priori aux lois a priori
Cette extension du champ d’application des lois conjugu´ees est cependant
discutable, car la repr´esentation par m´elange cach´e n’est pas unique et le choix
du m´elange d´etermine celui de la loi a priori.
3.3.4 Lois conjugu´ees des familles exponentielles
Soit f(x|θ) = h(x)eθ.x−ψ(θ), loi g´en´erique d’une famille exponentielle.
Cette loi admet alors une famille conjugu´ee, comme le d´emontre le r´esultat
suivant (dont la d´emonstration est directe).
Proposition 3.19. Une famille conjugu´ee pour f(x|θ) est donn´ee par
π(θ|μ, λ) = K(μ, λ) eθ.μ−λψ(θ),
(3.8)
o`u K(μ, λ) est la constante de normalisation de la densit´e. La loi a posteriori
correspondante est π(θ|μ + x, λ + 1).
La mesure d´eﬁnie par (3.8) est σ-ﬁnie ; elle g´en`ere une loi de probabilit´e
sur Θ si et seulement si
λ > 0
et
μ
λ ∈˚
N
(3.9)
(Exercice 3.35) : c’est uniquement quand (3.9) est v´eriﬁ´e que K(μ, λ) est bien
d´eﬁni. Par cons´equent, une loi conjugu´ee pour f(x|θ) peut ˆetre obtenue de
fa¸con automatique ; c’est pourquoi (3.8) est souvent appel´ee loi conjugu´ee na-
turelle de f. Le Tableau 3.4 pr´esente les lois conjugu´ees pour certaines lois
usuelles appartenant `a une famille exponentielle24. ´Evidemment, l’inf´erence
bay´esienne ne peut ˆetre men´ee que si les hyperparam`etres μ et λ sont connus.
L’aspect automatique des lois conjugu´ees a priori est ainsi trompeur, car un
apport subjectif via la d´etermination de ces valeurs demeure n´ecessaire. No-
tons aussi que (3.8) requiert un param`etre additionnel, relativement `a f(x|θ).
Pour des familles exponentielles naturelles, les lois a priori conjugu´ees ont
un attrait suppl´ementaire, comme le montrent Diaconis et Ylvisaker (1979) : si
ξ(θ) est l’esp´erance de x ∼f(x|θ), l’esp´erance a posteriori de ξ(θ) est lin´eaire
en x pour une loi a priori conjugu´ee.
Proposition 3.20. Si Θ est un ensemble ouvert dans Rk et θ a pour loi a
priori
πλ,x0(θ) ∝eθ·x0−λψ(θ)
avec x0 ∈X , alors
Eπ[ξ(θ)] = Eπ[∇ψ(θ)] = x0
λ .
24Puisque les lois conjugu´ees viennent aussi d’une famille exponentielle, Bar-Lev
et al. (1994) ont ´etudi´e le probl`eme r´eciproque, `a savoir la d´etermination des distribu-
tions π(θ) pour lesquelles une famille exponentielle admet π(θ) comme loi conjugu´ee.

3.3 Lois a priori conjugu´ees
131
Tab. 3.4. Lois a priori conjugu´ees naturelles pour quelques familles exponentielles
usuelles.
f(x|θ)
π(θ)
π(θ|x)
Normale
Normale
N (θ, σ2)
N (μ, τ 2)
N (ϱ(σ2μ + τ 2x), ϱσ2τ 2)
ϱ−1 = σ2 + τ 2
Poisson
Gamma
P(θ)
G (α, β)
G (α + x, β + 1)
Gamma
Gamma
G (ν, θ)
G (α, β)
G (α + ν, β + x)
Binomiale
Bˆeta
B(n, θ)
Be(α, β)
Be(α + x, β + n −x)
Binomiale N´egative
Bˆeta
N eg(m, θ)
Be(α, β)
Be(α + m, β + x)
Multinomiale
Dirichlet
Mk(θ1, . . . , θk)
D(α1, . . . , αk)
D(α1 + x1, . . . , αk + xk)
Normale
Gamma
N (μ, 1/θ)
G a(α, β) G (α + 0.5, β + (μ −x)2/2)
Par cons´equent, si x1, . . . , xn sont i.i.d. f(x|θ),
Eπ[ξ(θ)|x1, . . . , xn] = x0 + n¯x
λ + n .
(3.10)
Ce r´esultat est bien connu pour les distributions normales (Exemple 3.2)
et peut ainsi ˆetre g´en´eralis´e `a toutes les familles exponentielles. L’´equation
(3.10) montre de nouveau que le param`etre λ est comparable `a la taille
de l’´echantillon n. Par cons´equent, sa d´etermination peut ˆetre r´ealis´ee, si
n´ecessaire, en consid´erant que l’information a priori sur x0 provient d’un
´echantillon virtuel de taille λ. Brown (1986b) ´etablit que la Proposition 3.20
peut s’´etendre au cas o`u πλ,x0 est impropre, par exemple quand λ = 0 et
x0 = 0. Dans ce cas, l’esp´erance a posteriori est ¯x, qui est aussi l’estimateur
du maximum de vraisemblance de ξ(θ).
Diaconis et Ylvisaker (1979) ont montr´e, de surcroˆıt, une r´eciproque de
cette proposition, `a savoir que, si la mesure de r´ef´erence est continue par
rapport `a la mesure de Lebesgue, la lin´earit´e de Eπ[ξ(θ)|x] comme dans (3.10)
entraˆıne que la loi a priori est de la forme (3.6). Les extensions aux cas discrets
sont plus d´elicates.
Bien que les familles exponentielles permettent g´en´eralement un traitement
plus ais´e et, particuli`erement, l’utilisation commode de lois a priori conjugu´ees
et le calcul analytique des esp´erances a posteriori, comme dans la Proposition
3.20, ce n’est pas toujours le cas. Par exemple, quand x ∼Be(α, θ) avec α
connu, la distribution appartient `a une famille exponentielle, car
f(x|θ) ∝Γ(α + θ)(1 −x)θ
Γ(θ)
,

132
3 Des informations a priori aux lois a priori
mais les lois conjugu´ees ne sont pas faciles `a utiliser, car
π(θ|x0, λ) ∝
Γ(α + θ)
Γ(θ)
λ
(1 −x0)θ
d´epend de la fonction gamma Γ(θ), qui n’a pas d’expression explicite.
Exemple 3.21. La r´egression logistique est utilis´ee pour d´ecrire des mod`eles
qualitatifs comme dans l’Exemple 1.1. Soit une variable indicatrice y, prenant
ses valeurs dans {0, 1}, et des variables explicatives x ∈Rk, telles que la
distribution de y conditionnelle `a x soit
Pα(y = 1) = 1 −Pα(y = 0) =
exp(αtx)
1 + exp(αtx) .
(3.11)
Ce mod`ele permet l’extension du tr`es utile mod`ele de r´egression lin´eaire `a des
cadres plus qualitatifs. Pour un ´echantillon (y1, x1), . . . , (yn, xn) de (3.11), le
mod`ele est bien sˆur exponentiel conditionnellement aux xi, puisque
f(y1, . . . , yn|x1, . . . , xn, α) = exp

αt
n

i=1
yixi
 
n

i=1
(1 + eαtxi)−1,
qui d´epend uniquement de la statistique exhaustive n
i=1 yixi. Dans la pra-
tique, les lois a priori conjugu´ees pour ce mod`ele sont plutˆot diﬃciles `a utiliser,
car elles sont de la forme
π(α|y0, λ) ∝eαty0
n

i=1
(1 + eαtxi)−λ.
La constante de normalisation pour π(α|y0, λ) est inconnue et les approxima-
tions des quantit´es a posteriori comme l’esp´erance et la m´ediane a posteriori
ne peuvent ˆetre obtenues qu’`a travers des techniques de simulation pr´esent´ees
dans le Chapitre 6.
∥
3.4 Critiques et extensions
Comme nous l’avons d´ej`a vu ci-dessus, le caract`ere automatique des lois
conjugu´ees est `a la fois un avantage et un inconv´enient. En sus des argu-
ments d’invariance et de lin´earit´e, on peut argumenter qu’il s’agit d’une
approche objective, o`u l’apport subjectif est r´eduit `a la d´etermination des
hyperparam`etres. Mis `a part le fait que l’objectivit´e est un concept diﬃ-
cile `a d´eﬁnir, on peut r´epliquer que toute autre loi a priori avec le mˆeme
nombre d’hyperparam`etres pourrait paraˆıtre tout aussi objective. De plus, les

3.4 Critiques et extensions
133
lois a priori conjugu´ees ne sont pas forc´ement les lois a priori les plus ro-
bustes (voir la Section 3.5) et, de ce point de vue, d’autres lois peuvent ˆetre
pr´ef´er´ees, si l’imp´eratif est de minimiser l’inﬂuence de l’a priori sur le r´esultat
de l’inf´erence. L’exemple suivant montre comment le choix d’une loi a priori
peut modiﬁer la distribution a posteriori pour des ´echantillons de petite taille.
Exemple 3.22. (Diaconis et Ylvisaker, 1985)
Lorsqu’on fait tourner une
pi`ece sur la tranche, plutˆot que de la lancer dans l’air, la proportion de piles
est rarement proche de 1/2, mais se stabilise plutˆot autour de 1/3 ou 2/3, du
fait d’irr´egularit´es de fabrication qui biaisent le r´esultat en faveur d’un cˆot´e
ou de l’autre. On observe le nombre de piles, x ∼B(n, p) pour une pi`ece
donn´ee qu’on fait tourner n fois sur sa tranche. La loi a priori sur p semble
ˆetre bimodale, ce que ne peut reﬂ´eter une loi a priori conjugu´ee π1 comme
Be(1, 1). Un m´elange de lois a priori π2 tel que
1
2 [Be(10, 20) + Be(20, 10)]
est donc plus appropri´e. Il peut arriver aussi que des exp´eriences pr´ec´edentes
avec la mˆeme pi`ece indiquent un biais vers pile et m`enent `a l’a priori alternatif
suivant, π3 :
0.5 Be(10, 20) + 0.2 Be(15, 15) + 0.3 Be(20, 10).
La Figure 3.3 fournit le graphe des deux densit´es a priori ci-dessus et de
l’a priori neutre Be(1, 1), les diﬀ´erences entre les trois mod`eles a priori ´etant
eﬀectivement assez importantes. Si, pour n = 10, nous observons x = 3, les
lois a posteriori correspondantes sont :
(i) Be(1 + x, 1 + n −x), soit Be(4, 8) ;
(ii) 0.84 Be(13, 27) + 0.16 Be(23, 17); et
(iii) 0.77 Be(13, 27) + 0.16 Be(18, 22) + 0.07 Be(23, 17).
En (ii), les pond´erations de probabilit´es a posteriori sont obtenues comme
´etant proportionnelles `a
1
2
B(13, 27)
B(10, 20)
et
1
2
B(23, 17)
B(20, 10)
et, pour (iii),
0.5 B(13, 27)
B(10, 20),
0.2 B(18, 22)
B(15, 15),
et
0.3 B(23, 17)
B(20, 10),
o`u
B(a, b) = Γ(a)Γ(b)
Γ(a + b)
est l’inverse du terme de normalisation de la densit´e bˆeta (d´eﬁnie dans l’Ap-
pendice A), qui peut ˆetre approch´ee num´eriquement (ou calcul´ee exactement
dans le cas de coeﬃcients entiers).

134
3 Des informations a priori aux lois a priori
p
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.5
1.0
1.5
2.0
2.5
3.0
1 comp.
2 comp.
3 comp.
Fig. 3.3. Trois lois a priori pour une exp´erience de pile ou face.
Par cons´equent, pour cet ´echantillon, les trois moyennes a posteriori, 1/3,
0.365 et 0.362 respectivement, sont assez proches mais les formes des lois a
posteriori diﬀ´erent malgr´e tout (voir la Figure 3.4). Consid´erons maintenant
un ´echantillon de taille n = 50 avec x = 36. Les lois a posteriori sont :
(i) Be(15, 37) ;
(ii) 0.997 Be(24, 56) + 0.003 Be(34, 46); et
(iii) 0.95 Be(24, 56) + 0.047 Be(29, 51) + 0.003 Be(34, 46).
Elles sont alors plus proches les unes des autres que pour n = 10, comme le
montre la Figure 3.5.
∥
p
0.0
0.2
0.4
0.6
0.8
1.0
0
1
2
3
4
1 comp.
2 comp.
3 comp.
Fig. 3.4. Lois a posteriori pour un mod`ele de pile ou face pour dix observations.
Deux remarques d´ecoulent logiquement de cet exemple. D’abord, il montre
qu’un mod`ele a priori est certainement important pour de petits ´echantillons,
mais aussi qu’il l’est de moins en moins `a mesure que la taille de l’´echantillon

3.4 Critiques et extensions
135
p
0.0
0.2
0.4
0.6
0.8
1.0
0
2
4
6
8
1 comp.
2 comp.
3 comp.
Fig. 3.5. Lois a posteriori pour cinquante observations.
augmente. Quand la taille de l’´echantillon tend vers l’inﬁni, la plupart des lois
a priori m`eneront `a la mˆeme inf´erence, qui sera ´equivalente `a celle fond´ee seule-
ment sur la fonction de vraisemblance, comme remarqu´e dans la Note 1.8.4.
De plus, cet exemple montre que les m´elanges de lois a priori conjugu´ees sont
aussi faciles `a manipuler que les lois a priori habituelles, tout en permettant
une plus grande libert´e dans la mod´elisation de l’information a priori. En eﬀet,
les m´elanges de lois conjugu´ees forment aussi des familles conjugu´ees.
Lemme 3.23. Soit F la famille conjugu´ee naturelle d’une famille exponen-
tielle (3.6). Alors l’ensemble des m´elanges de N lois conjugu´ees,
˜
FN =
 N

i=1
ωiπ(θ|λi, μi);
N

i=1
ωi = 1, ωi > 0

,
est aussi une famille conjugu´ee. De plus, si
π(θ) =
N

i=1
ωiπ(θ|λi, μi),
la loi a posteriori est un m´elange
π(θ|x) =
N

i=1
ω′
i(x)π(θ|λi + 1, μi + x),
avec
ω′
i(x) =
ωiK(μi, λi)/K(μi + x, λi + 1)
N
j=1 ωjK(μj, λj)/K(μj + x, λj + 1)
.
Les m´elanges peuvent alors ˆetre utilis´es comme base pour approcher une
loi a priori quelconque, au sens o`u la distance de Prohorov entre une loi

136
3 Des informations a priori aux lois a priori
et sa repr´esentation par un m´elange peut ˆetre rendue arbitrairement petite.
Rappelons que la distance de Prohorov entre deux mesures π et ˜π, dP (π, ˜π)
est d´eﬁnie comme
dP (π, ˜π) = inf
A {ϵ ; π(A) ≤˜π(Aϵ) + ϵ} ,
o`u l’inﬁmum est pris sur les ensembles bor´eliens et o`u Aϵ indique l’ensemble
des points distants de A d’au plus ϵ (Le Cam, 1986).
Th´eor`eme 3.24. Si Θ est l’espace naturel des param`etres pour la famille
exponentielle f(x|θ) et π est une loi a priori sur Θ, alors, pour tout ϵ > 0, on
peut trouver N et ˜π ∈˜
FN tels que dP (π, ˜π) < ϵ.
La d´emonstration de ce th´eor`eme peut ˆetre reli´ee au fait que les m´elanges
ﬁnis de mesures de Dirac sont denses dans la topologie de Prohorov et que
les masses de Dirac peuvent s’approcher par des m´elanges de lois a priori
conjugu´ees. (Pour plus de d´etails, voir Brown, 1986b, p. 254-267.) Ce r´esultat
justiﬁe beaucoup plus fortement l’utilisation de lois conjugu´ees que l’inva-
riance, la lin´earit´e ou les arguments de simplicit´e de la section pr´ec´edente.
Quelle que soit l’information a priori disponible, celle-ci peut toujours ˆetre
mod´elis´ee par un m´elange de ˜
FN avec N aussi petit que possible. Cependant,
ce r´esultat d’approximation est aussi incomplet, car il ne montre pas com-
ment l’approximation s’´etend aux quantit´es a posteriori, alors que l’inf´erence
bay´esienne ne s’int´eresse qu’`a celles-ci. Berger (1985b) illustre cette diﬀ´erence
`a travers l’exemple suivant.
Exemple 3.25. Soit x ∼N (θ, 1) et prenons pour a priori associ´e π0 une
loi de Cauchy, C (0, 1). Les lois conjugu´ees naturelles ´etant N (μ, A), π0 peut
s’approcher par
˜π =
N

i=1
λiπi,
o`u πi est N (μi, Ai), selon le Th´eor`eme 3.24. Lorsque x tend vers +∞, π0(θ|x)
tend vers N (x, 1) tandis que ˜π(θ|x) est approximativement N (μ(x), ϱ), avec
ϱ =
A∗
1 + A∗,
μ(x) = ϱx + (1 −ϱ)μ∗,
A∗= max
i {Ai},
μ∗= max
Ai=A∗μi.
Par cons´equent, π0(θ|x) et ˜π(θ|x) vont nettement diﬀ´erer pour de grandes
valeurs de x. On peut remarquer que ces valeurs ne sont pas compatibles
avec l’information a priori et devraient conduire `a une modiﬁcation de la
mod´elisation a priori. Mais ces diﬀ´erences d´emontrent malgr´e tout que l’ap-
proximation a priori n’est pas uniform´ement valide a posteriori.
∥
L’Exemple 3.25 illustre avec force le point suivant : les lois `a queues lourdes
seront mal approch´ees par des distributions `a queue moins lourde. Cette dif-
ﬁcult´e et, plus g´en´eralement, le probl`eme d’approximation de lois a poste-
riori disparaissent d’une certaine fa¸con dans la g´en´eralisation de Dalal et Hall

3.5 Lois a priori non informatives
137
(1983), qui consid`erent des m´elanges continus (dans un cas continu). Nous
d´ecrirons bri`evement leur approche dans la Note 3.8.3, mais nous tenons `a
remarquer que leur approximation via des m´elanges continus n’a pas l’at-
trait des approximations pr´ec´edentes, car elle requiert souvent une r´esolution
num´erique ou de Monte Carlo.
3.5 Lois a priori non informatives
La section pr´ec´edente a montr´e que les lois conjugu´ees peuvent ˆetre utiles
en tant qu’approximations des v´eritables lois a priori. En revanche, lorsque
aucune information a priori n’est disponible, leur unique justiﬁcation est ana-
lytique, puisqu’elles donnent des expressions exactes pour quelques quantit´es a
posteriori. Dans de telles situations, il est impossible de justiﬁer le choix d’une
loi a priori sur des bases subjectives et les hyperparam`etres des lois conjugu´ees
ne peuvent ˆetre d´etermin´es qu’arbitrairement. Plutˆot que de revenir aux al-
ternatives classiques, comme l’estimation par maximum de vraisemblance,
ou d’utiliser les donn´ees pour approcher ces hyperparam`etres, comme dans
une analyse bay´esienne empirique, il est pr´ef´erable de faire appel `a des tech-
niques bay´esiennes, ne serait-ce que parce qu’elles sont `a la base des crit`eres
classiques d’optimalit´e (voir les Chapitres 2, 8 et 9). Dans un tel cas, ces
lois a priori particuli`eres doivent ˆetre construites `a partir de la distribution
d’´echantillonnage, puisque c’est la seule information disponible. Pour des rai-
sons ´evidentes, de telles lois sont dites non informatives. Nous d´ecrivons plus
loin quelques-unes des techniques les plus importantes de construction de lois
non informatives, en demandant aux lecteurs de se r´ef´erer `a Kass et Was-
serman (1996)
pour un traitement plus approfondi de ces notions et une
bibliographie comment´ee. Le point principal m´erite d’ˆetre reproduit ici, avant
que nous entamions cette description : on ne peut attendre des lois non infor-
matives qu’elles repr´esentent exactement une ignorance totale sur le probl`eme
consid´er´e. Celles-ci doivent plutˆot ˆetre comprises comme des lois de r´ef´erence
ou des lois choisies par d´efaut, auxquelles chacun pourrait avoir recours quand
toute information a priori est absente. `A cet ´egard, certaines lois non infor-
matives sont plus utiles ou plus eﬃcaces que d’autres, mais ne peuvent ˆetre
pour autant per¸cues comme moins informatives que d’autres.
3.5.1 Les lois a priori de Laplace
Historiquement, Laplace fut le premier `a utiliser des techniques non in-
formatives puisque, bien que ne disposant pas d’information sur le nombre
de boules blanches dans l’urne ou sur la proportion de naissances mˆales
(Exemples 1.9 et 1.11), il munit ces param`etres d’une loi a priori qui prend en
compte son ignorance en donnant la mˆeme vraisemblance `a chaque valeur du
param`etre, soit donc en utilisant une loi uniforme. Son raisonnement, appel´e

138
3 Des informations a priori aux lois a priori
plus tard principe de la raison insuﬃsante, se fondait sur l’´equiprobabilit´e des
´ev´enements ´el´ementaires.
Trois critiques ont ´et´e plus tard avanc´ees sur ce choix. Premi`erement,
les lois r´esultantes sont impropres quand l’espace des param`etres n’est pas
compact et certains statisticiens se refusent `a utiliser de telles lois, car elles
m`enent `a des diﬃcult´es comme le paradoxe de marginalisation (voir les Exer-
cices 3.45-3.51). De telles inqui´etudes ne sont pas justiﬁ´ees, puisqu’en r´ealit´e il
est possible de travailler avec des lois impropres, comme nous l’avons vu dans
la Section 1.5, du moment que nous n’essayons pas de les interpr´eter comme
des lois de probabilit´e (voir aussi Stone, 1976). Comme cela est mentionn´e
dans la Section 3.2, il peut ˆetre avanc´e que, au contraire, une d´etermination
subjective d’une loi a priori devrait conduire `a une loi impropre.
Deuxi`emement, le principe des ´ev´enements ´equiprobables de Laplace n’est
pas coh´erent en termes de partitionnement : si Θ = {θ1, θ2}, la r`egle de Laplace
donne π(θ1) = π(θ2) = 1/2 mais, si la d´eﬁnition de Θ est plus d´etaill´ee, avec
Θ = {θ1, ω1, ω2}, la r`egle de Laplace m`ene `a π(θ1) = 1/3, ce qui ´evidemment
n’est pas coh´erent avec la premi`ere formulation. Comme cela est discut´e dans
Kass et Wasserman (1996), cette coh´erence n’est pas un probl`eme important :
il peut ˆetre ´evacu´e en argumentant que le niveau de partitionnement doit ˆetre
ﬁx´e `a un certain stade de l’analyse et que l’introduction d’un degr´e plus ﬁn
dans le partitionnement modiﬁe le probl`eme d’inf´erence.
La troisi`eme critique est plus fondamentale, car elle concerne le probl`eme
de l’invariance par reparam´etrisation. Si on passe de θ ∈Θ `a η = g(θ) par une
transformation bijective g, l’information a priori reste totalement inexistante
et ne devrait pas ˆetre modiﬁ´ee. Cependant, si π(θ) = 1, la loi a priori sur η
est
π∗(η) =

d
dη g−1(η)

par la formule du changement de variable. Donc π(η) est le plus souvent non
constante.
Exemple 3.26. Si p, la proportion de naissances mˆales, suit une loi uniforme
sur [0,1], le param`etre de rapport des chances ϱ =
p
1−p suit une loi a priori de
densit´e 1/(1 + ϱ)2, qui est donc non constante.
∥
Bien entendu, on peut parfois soutenir qu’il existe un param`etre naturel
d’int´erˆet et par cons´equent que le choix d’une loi uniforme pour ce param`etre
d’int´erˆet n’a pas besoin d’ˆetre invariant par reparam´etrisation. Mais cet argu-
ment ne tient pas si plus d’une inf´erence sur θ doit ˆetre men´ee ; par exemple,
nous pourrions avoir besoin de calculer les deux premiers moments de θ, mais
ce dernier est aussi l’esp´erance de θ2. Ou, dans l’Exemple 3.26, la probabilit´e
θ et le rapport des risques ϱ peuvent ˆetre d’int´erˆet. Par cons´equent, il semble
qu’une notion plus intrins`eque et plus acceptable de la loi non informative
devrait satisfaire l’invariance par reparam´etrisation.

3.5 Lois a priori non informatives
139
3.5.2 Lois invariantes
Une premi`ere solution est de tirer proﬁt des caract´eristiques d’invariance
du probl`eme, c’est-`a-dire d’utiliser les groupes G agissant sur X qui induisent
des groupes G ∗agissant sur Θ (au sens o`u seuls les param`etres de la dis-
tribution de x changent dans une transformation de x par des ´el´ements de
G ). Le Chapitre 9 d´etaille les liens entre structures d’invariance et approche
bay´esienne, ces structures permettant d’obtenir une certaine loi non informa-
tive compatible avec les exigences d’invariance, `a savoir, la mesure de Haar `a
droite sur G ∗; voir Kass et Wasserman (1996) pour plusieurs arguments en
faveur de la mesure de Haar `a droite.
Deux exemples introductifs sont pr´esent´es ci-dessous.
Exemple 3.27. La famille de lois f(x−θ) est invariante par translation, car
y = x −x0 a une loi de la mˆeme famille pour tout x0, f(y −(θ −x0)) ; θ est
alors dit param`etre de position et une exigence d’invariance est que la loi a
priori soit invariante par translation, donc satisfasse
π(θ) = π(θ −θ0)
pour tout θ0. La solution est π(θ) = c, la loi uniforme sur Θ.
∥
Exemple 3.28. Si la famille de lois est param´etr´ee par un param`etre d’´echelle,
c’est-`a-dire est de la forme 1/σf(x/σ) (σ > 0), elle est invariante par chan-
gement d’´echelle, y = x/σ ∼f(y). La loi a priori invariante par changement
d’´echelle π satisfait π(A) = π(A/c) pour tout ensemble mesurable A dans
(0, +∞) et c > 0, soit
π(σ) = 1
cπ(σ
c ).
Ceci implique π(σ) = α/σ, o`u α est une constante. Donc la mesure invariante
n’est plus constante.
∥
L’approche invariante n’est que partiellement satisfaisante, car elle im-
plique la r´ef´erence `a une structure d’invariance, qui peut ˆetre parfois choisie
de plusieurs mani`eres, ne pas exister (voir le Chapitre 9), ou ˆetre sans int´erˆet
pour le d´ecideur.
3.5.3 La loi a priori de Jeﬀreys
Jeﬀreys (1946, 1961) propose une approche intrins`eque qui ´evite eﬀective-
ment le besoin de prendre en compte une structure d’invariance potentielle,
tout en ´etant souvent compatible lorsque cette structure existe. Les lois a
priori non informatives de Jeﬀreys sont fond´ees sur l’information de Fisher,
donn´ee par

140
3 Des informations a priori aux lois a priori
I(θ) = Eθ
∂log f(X | θ)
∂θ
2
dans le cas unidimensionnel. Sous certaines conditions de r´egularit´e, cette
information est aussi ´egale `a
I(θ) = −Eθ
∂2 log f(X | θ)
∂θ2

.
(3.12)
La loi a priori de Jeﬀreys est
π∗(θ) ∝I1/2(θ),
d´eﬁnie `a un coeﬃcient de normalisation pr`es quand π∗est propre. Elle v´eriﬁe
eﬀectivement l’exigence d’invariance par reparam´etrisation, puisque, pour une
transformation bijective h donn´ee, nous avons la transformation (jacobienne)
I(θ) = I(h(θ))(h′(θ))2
(qui explique l’exposant 1/2). De plus, elle correspond aux lois invariantes
obtenues dans les Exemples 3.27 et 3.28. Plus fondamentalement, le choix
d’une loi a priori d´ependant de l’information de Fisher se justiﬁe par le fait que
I(θ) est largement accept´e comme un indicateur de la quantit´e d’information
apport´ee par le mod`ele (ou l’observation) sur θ (Fisher, 1956). Par cons´equent,
au moins `a un niveau qualitatif, il paraˆıt intuitivement justiﬁ´e que les valeurs
de θ pour lesquelles I(θ) est plus grande doivent ˆetre plus probables a priori.
En d’autres termes, I(θ) mesure la capacit´e du mod`ele `a discriminer entre θ
et θ ± dθ via la pente moyenne de log f(x|θ). Favoriser les valeurs de θ pour
lesquelles I(θ) est plus grande ´equivaut `a minimiser l’inﬂuence de la loi a priori
et est donc aussi non informatif que possible. En fait, la loi de Jeﬀreys est
fr´equemment impropre mais les d´eveloppements de la Section 1.5 montrent
comment conduire une analyse bay´esienne dans ce cas.
Exemple 3.29. (Suite de l’Exemple 3.26) Si x ∼B(n, p),
f(x|p) =
n
x

px(1 −p)n−x,
∂2 log f(x|p)
∂p2
= x
p2 +
n −x
(1 −p)2 ,
et
I(p) = n
1
p +
1
1 −p

=
n
p(1 −p).
Donc la loi de Jeﬀreys pour ce mod`ele est
π∗(p) ∝[p(1 −p)]−1/2
et est alors propre, car il s’agit de la distribution Be(1/2, 1/2).
∥

3.5 Lois a priori non informatives
141
Dans le cas o`u θ est un param`etre multidimensionnel, on d´eﬁnit la matrice
d’information de Fisher par g´en´eralisation de (3.12). Pour θ ∈Rk, I(θ) a les
´el´ements suivants :
Iij(θ) = −Eθ

∂2
∂θi∂θj
log f(x|θ)

(i, j = 1, . . . , k),
et la loi non informative de Jeﬀreys est alors d´eﬁnie par
π∗(θ) ∝[det(I(θ))]1/2.
Elle est encore invariante par reparam´etrisation. Notons que, si f(x|θ) appar-
tient `a une famille exponentielle,
f(x|θ) = h(x) exp(θ · x −ψ(θ)),
la matrice d’information de Fisher est donn´ee par I(θ) = ∇∇tψ(θ) et
π∗(θ) ∝
 k

i=1
ψ′′
ii(θ)
 1/2
,
(3.13)
o`u ψ′′
ii(θ) =
∂2
∂θ2
i ψ(θ).
Dans un cas multidimensionnel, l’approche non informative de Jeﬀreys
peut conduire `a des incoh´erences ou mˆeme `a des paradoxes (voir les Exemples
3.31 et 3.34) et nous notons que Jeﬀreys (1961) a surtout insist´e sur l’utili-
sation de cette loi dans des cas unidimensionnels (voir Berger et Bernardo,
1992a). Cependant, sa m´ethode fournit une des meilleures techniques automa-
tiques pour obtenir les lois non informatives. De plus, elle permet bien souvent
de retrouver les estimateurs classiques.
Exemple 3.30. Soit x ∼N (θ, Ip). Comme il s’agit d’une famille de position,
la loi de Jeﬀreys est constante. L’estimateur de Bayes g´en´eralis´e est donn´e par
δπ∗(x) =

Rp θ exp(−||x −θ||2/2) dθ

Rp exp(−||x −θ||2/2) dθ = x.
Il est minimax pour tout p et admissible pour p ≤2. Notons que cet estimateur
est aussi le meilleur estimateur ´equivariant pour des param`etres de position
(voir le Chapitre 9).
∥
Exemple 3.31. Soit x ∼N (μ, σ2) avec θ = (μ, σ) inconnu. Dans ce cas,
I(θ) = Eθ

1/σ2
2(x −μ)/σ3
2(x −μ)/σ3 3(μ −x)2/σ4 −1/σ2

=
1/σ2
0
0
2/σ2


142
3 Des informations a priori aux lois a priori
et la loi non informative associ´ee est π(θ) ∝1/σ2. Si, en revanche, on suppose
μ et σ ind´ependants, la loi non informative correspondante est π(μ, σ) = σ−1,
qui est aussi la mesure invariante de Haar pour ce mod`ele de position-´echelle
(voir l’Exemple 3.28 et le Chapitre 9).
∥
Cette approche est critiqu´ee par certains bay´esiens comme ´etant un outil
sans justiﬁcation subjective en termes d’information a priori. Cependant, la
seule alternative `a une approche automatique est d’exiger que l’information a
priori soit toujours disponible, ce qui n’est pas possible dans tous les cadres.
Une autre critique de la m´ethode de Jeﬀreys est que, bien qu’elle r´eponde aux
exigences d’invariance par reparam´etrisation, elle ne satisfait pas au principe
de vraisemblance. En eﬀet, l’information de Fisher peut diﬀ´erer pour deux
exp´eriences fournissant des vraisemblances proportionnelles, comme le montre
l’exemple ci-dessous.
Exemple 3.32. Nous avons vu dans l’Exemple 1.16 que les mod`eles binomial
et binomial n´egatif conduisent `a la mˆeme vraisemblance. Cependant, si x ∼
B(n, θ), la loi non informative π1(θ) est Be(1/2, 1/2) (Exemple 3.26) et, si
n ∼N eg(x, θ), la loi de Jeﬀreys est
π2(θ) = −Eθ
 ∂2
∂θ2 log f(x|θ)

= Eθ
 x
θ2 +
n −x
(1 −θ)2

=
x
θ2(1 −θ),
soit donc π2(θ) ∝θ−1(1 −θ)−1/2, qui est impropre et, fait plus important,
diﬀ`ere de π1.
∥
Comme le montre l’exemple suivant, il arrive souvent que la loi non infor-
mative de Jeﬀreys soit limite de lois conjugu´ees.
Exemple 3.33. Si x ∼U ([0, θ]), une loi conjugu´ee est la loi de Pareto,
Pa(θ0, α),
π(θ) = α θα
0 θ−α−1I[θ0,+∞[(θ),
qui donne la loi a posteriori Pa(max(θ0, x), α + 1). Sous le coˆut invariant
L(θ, δ) = (θ −δ)2
θ2
,
l’estimateur de Bayes est, si θ0 ∨x = max(θ0, x),
δπ(x) =
 +∞
θ0∨x θ−1(α + 1) θα+1
0
θ−α−2dθ
 +∞
θ0∨x θ−2(α + 1) θα+1
0
θ−α−2dθ
= α + 3
α + 2 (θ ∨x),
qui tend vers l’estimateur minimax, δ0(x) = (3/2)x, quand α et θ0 tendent vers
0. Comme θ est un param`etre d’´echelle, la loi non informative est π(θ) = 1/θ,

3.5 Lois a priori non informatives
143
qui est aussi une loi de Jeﬀreys pour ce mod`ele. Cette loi correspond `a θ0 = 0
et α = 0 pour une loi de Pareto non normalis´ee (c’est-`a-dire sans le facteur
d’´echelle αθα
0 ). Cette repr´esentation permet par ailleurs de prouver que δ0 est
admissible, en utilisant la condition d’admissibilit´e suﬃsante de Stein (voir le
Chapitre 8).
∥
Un inconv´enient plus important de la loi non informative de Jeﬀreys est
qu’elle ne donne pas des r´esultats satisfaisants pour tous les buts inf´erentiels,
en particulier lorsqu’on consid`ere des sous-vecteurs d’int´erˆet. Le probl`eme ci-
dessous a ´et´e mis en ´evidence par Stein (1959) (voir aussi Tibshirani, 1989).
Exemple 3.34. Si x ∼Np(θ, Ip), la loi non informative est π(θ) = 1. L’es-
timateur r´esultant de θ, x, est assez raisonnable, comme le montre l’Exemple
3.30. Cependant, comme θ|x ∼Np(x, Ip), la loi a posteriori de η = ||θ||2 est
χ2
p(||x||2), la loi du khi deux d´ecentr´e. Quand η est le param`etre d’int´erˆet,
l’esp´erance a posteriori de η est
δπ(x) = Eπ[η|x] = ||x||2 + p .
Cependant, le meilleur estimateur parmi les estimateurs de la forme ||x||2 + c
(pour le coˆut quadratique) est ||x||2−p, qui domine uniform´ement l’estimateur
g´en´eralis´e de Bayes, δπ (voir l’Exercice 2.35). Par cons´equent, la loi marginale
sur η d´eduite de la loi non informative de Jeﬀreys sur θ est v´eritablement
sous-optimale. De plus, la loi non informative de Jeﬀreys obtenue `a partir
de l’observation r´eduite z = ||x||2 est totalement diﬀ´erente de χ2
p(||x||2) et
conduit `a un estimateur de η aux performances beaucoup plus acceptables
(voir l’Exercice 3.53).
∥
L’Exercice 4.48 montre aussi que la loi de Jeﬀreys a priori peut ˆetre in-
consistante dans le cadre d’une calibration lin´eaire et que ce probl`eme peut
ˆetre r´esolu par la m´ethode des lois a priori de r´ef´erence.
3.5.4 Lois de r´ef´erence
Le type de probl`eme ´evoqu´e `a la ﬁn de la section pr´ec´edente a ´et´e pris en
compte par Bernardo (1979), qui propose une modiﬁcation de l’approche de
Jeﬀreys appel´ee approche de la loi de r´ef´erence. Une diﬀ´erence majeure est que
cette m´ethode fait la distinction entre param`etres d’int´erˆet et param`etres de
nuisance (par exemple, ||θ||2 et θ/||θ|| dans l’Exemple 3.34). Par cons´equent,
la loi a priori r´esultante ne d´epend pas seulement de la loi d’´echantillonnage,
mais aussi du probl`eme inf´erentiel consid´er´e. Le reste de cette section pr´esente
bri`evement la construction des lois de r´ef´erence. Pour une ´etude d´etaill´ee, voir
Berger et Bernardo (1989, 1992b,a) et Kass et Wasserman (1996).
Quand x ∼f(x|θ) et θ = (θ1, θ2), o`u θ1 est le param`etre d’int´erˆet, la loi de
r´ef´erence est obtenue en d´eﬁnissant d’abord π(θ2|θ1) comme la loi de Jeﬀreys
associ´ee `a f(x|θ) pour θ1 ﬁx´e, puis en calculant la loi marginale

144
3 Des informations a priori aux lois a priori
˜f(x|θ1) =

f(x|θ1, θ2)π(θ2|θ1)dθ2
(3.14)
et la loi de Jeﬀreys π(θ1) associ´ee `a ˜f(x|θ1). Le principe sous-jacent `a la loi
de r´ef´erence est donc d’´eliminer le param`etre de nuisance en utilisant la loi
de Jeﬀreys correspondant au cas o`u le param`etre d’int´erˆet reste ﬁx´e. (Notons
que l’int´egrale dans (3.14) n’est pas forc´ement d´eﬁnie et il peut ˆetre n´ecessaire
d’int´egrer d’abord sur une suite d’ensembles compacts et de prendre la limite.)
Exemple 3.35. Le probl`eme de Neyman-Scott (1948) est reli´e `a l’observation
de xij distribu´es selon N (μi, σ2), i = 1, . . . , n, j = 1, 2. La loi de Jeﬀreys
usuelle pour ce mod`ele est π(μ1, . . . , μn, σ) = σ−n−1 et une inconsistance
apparaˆıt, car E[σ2|x11, . . . , xn2] = s2/(2n −2), avec
s2 =
n

i=1
(xi1 −xi2)2
2
,
cette esp´erance a posteriori convergeant en n vers σ2/2. (Notons qu’il s’agit
d’un cas o`u le nombre de param`etres augmente avec le nombre d’observations.)
La loi de r´ef´erence associ´ee `a θ1 = σ et θ2 = (μ1, . . . , μn) donne une loi plate
pour π(θ2|θ1), car θ2 est un param`etre de position. Alors
˜f(x|θ1) =
n

i=1
e−(xi1−xi2)2/4σ2
1
√
2π2σ
est une famille d’´echelle et π(σ) = 1/σ. Par cons´equent, E[σ2|x11, . . . , xn2] =
s2/(n −2), qui est convergent.
∥
La construction g´en´erale d’une loi de r´ef´erence est la suivante : Soit x ∼
f(x|θ), avec θ ∈Θ ⊂Rk. Supposons que la matrice d’information de Fisher
I(θ) existe et soit de plein rang. Notons S = I−1(θ). Les param`etres sont
d´esormais s´epar´es en m groupes correspondant `a leur importance respective,
θ(1) = (θ1, . . . , θn1),
. . .
θ(m) = (θNm−1+1, . . . , θk),
(3.15)
avec Ni = i
j=1 nj (apr`es un possible changement d’indices des compo-
sants de θ). La m´ethode de la loi de r´ef´erence construit une loi a priori sur
(θ(1), . . . , θ(m)) qui prend en compte cette d´ecomposition, c’est-`a-dire qui fait
vraiment la s´eparation entre param`etres de nuisance et param`etres d’int´erˆet.
Elle permet mˆeme un niveau plus ﬁn de s´eparation entre les niveaux d’impor-
tance respectifs de ces param`etres. Nous introduisons la notation suivante :
pour j = 1, . . . , m,
θ[j] = (θ(1), . . . , θ(j))
et
θ[∼j] = (θ(j+1), . . . , θ(m)).
La matrice S est d´ecompos´ee selon la partition (3.15),

3.5 Lois a priori non informatives
145
S =
⎛
⎜
⎜
⎝
A11 At
21 . . . At
m1
A21 A22
At
m2
. . .
Am1
Amm
⎞
⎟
⎟
⎠
et Sj est le coin sup´erieur gauche (Nj, Nj) de S ; par exemple, S1 = A11. Nous
notons Hj = S−1
j
et hj le coin en bas `a droite (nj, nj) de Hj ; en particulier,
h1 = A−1
11 . La construction de la loi de r´ef´erence continue comme suit :
Algorithme 3.1. Loi de r´ef´erence
– Initialisation :
πm(θ(m)|θ[m−1]) =
|hm(θ)|1/2

|hm(θ)|1/2 dθ(m)
.
– It´eration :
For j = m −1, . . . , 1,
πj(θ[∼j−1]|θ[j−1]) = πj+1(θ[∼j]|θ[j]) exp{ 1
2Ej[log(|hj(θ)|)|θ[j]]}

exp{ 1
2Ej[log(|hj(θ)|)|θ[j]]} dθ(j)
,
o`u
Ej[g(θ)|θ[j]] =

g(θ)πj+1(θ[∼j]|θ[j]) dθ[∼j].
– Conclusion :
La loi de r´ef´erence est π(θ) = π1(θ[∼0]|θ[0]).
Souvent, quelques-unes des int´egrales apparaissant dans cet algorithme ne
sont pas d´eﬁnies. Berger et Bernardo (1989) ont alors propos´e de calculer la
loi de r´ef´erence pour des sous-ensembles compacts Θn de Θ et de consid´erer
la limite de la suite de lois de r´ef´erence correspondante (πn) quand n tend
vers l’inﬁni et Θn tend vers Θ. En g´en´eral, le r´esultat limite ne d´epend pas
du choix de la suite de compacts.
Exemple 3.36. (Suite de l’Exemple 3.34) Puisque η = ||θ||2 est le pa-
ram`etre d’int´erˆet, θ peut s’´ecrire en coordonn´ees polaires (η, ϕ1, . . . , ϕp−1),
avec
θ1 = √η cos(ϕ1),
θ2 = √η sin(ϕ1) cos(ϕ2),
. . .
θp−1 = √η sin(ϕ1) · · · cos(ϕp−1),
θp = √η sin(ϕ1) · · · sin(ϕp−1).
La matrice d’information de Fisher pour (η, ϕ1, . . . , ϕp−1) est alors H = JJt,
o`u J est la matrice jacobienne
D(θ1,...,θp)
D(η,ϕ1,...,ϕp−1). On peut montrer que J est de
la forme

146
3 Des informations a priori aux lois a priori
J =
At/√η
√ηB

,
avec des matrices A ∈Rp et B (p −1) × p. Alors, pour la partition de θ en
θ(1) = η, θ(2) = (ϕ1, . . . , ϕp−1), nous avons
π2(ϕ1, . . . , ϕp−1|η) ∝|H22|1/2,
qui ne d´epend pas de η. La loi marginale de η est
π1(η) ∝exp

E

log
1
2
|H|
|H22|
 η

et
|H|
|H22| ∝(1/η). Par cons´equent,
π1(η) = 1/√η,
qui m`ene `a un estimateur de ||θ||2 plus int´eressant que ||x||2+p (voir l’Exercice
3.53).
En r´ealit´e, le mˆeme probl`eme de marginalisation apparaˆıt pour l’estimation
du maximum de vraisemblance. En eﬀet, l’estimateur du maximum de vrai-
semblance fond´e sur l’´echantillon est ||x||2, qui est aussi domin´e par ||x||2 −p.
En revanche, l’estimateur du maximum de vraisemblance obtenu `a partir de
z = ||x||2 ∼χ2
p(||θ||2)
se conduit de la mˆeme fa¸con que (||x||2 −p)+ (voir Saxena et Alam, 1982,
Chow, 1987, et Chow et Hwang, 1990, et l’Exercice 3.53).
∥
Cet algorithme se justiﬁe comme fournissant la loi a priori qui maximise
l’information a posteriori (Bernardo, 1979, et Berger et Bernardo, 1992a).
Plus pr´ecis´ement, si l’´echantillon (x1, . . . , xn) est not´e x1:n et si Kn(π) est
la divergence de Kullback-Leibler entre la loi a priori π et la loi a posteriori
correspondante,
Kn(π) =

π(θ|x1:n) log (π(θ|x1:n)/π(θ)) dθ,
l’id´ee de Bernardo (1979) est d’utiliser E[Kn(π)], o`u l’esp´erance est prise sur la
loi marginale de x1:n, comme mesure d’information manquante, et de d´eﬁnir
la loi de r´ef´erence comme la loi π maximisant
K∗(π) = lim
n→∞E[Kn(π)] .
Les diﬃcult´es techniques associ´ees aux ´eventuelles int´egrales inﬁnies mises `a
part, la loi a priori r´esultante est la loi de Jeﬀreys pour des espaces continus des
param`etres et la loi uniforme pour des espaces ﬁnis ; voir Ghosh et Mukerjee

3.5 Lois a priori non informatives
147
(1992a), Clarke et Wasserman (1993) et Kass et Wasserman (1996) pour des
motivations suppl´ementaires en termes d’optimalit´e asymptotique.
La loi de r´ef´erence d´epend aussi de la fa¸con dont les param`etres ont ´et´e
ordonn´es (voir l’Exercice 3.60), un avantage compar´e `a la m´ethode de Jeﬀreys,
car les param`etres de nuisance sont consid´er´es diﬀ´eremment. Des paradoxes
comme ceux de l’Exemple 3.34 sont alors ´evit´es. Il peut paraˆıtre excessif de
modiﬁer la loi a priori selon le probl`eme d’int´erˆet, mais on doit se rendre
compte que, mis `a part la distribution de l’´echantillon f(x|θ), ces probl`emes
inf´erentiels sont la seule information disponible25. Notons que l’invariance par
reparam´etrisation n’est maintenue que si les changements sont bijectifs et in-
ternes `a chaque groupe dans (3.15). Cependant, l’exigence d’invariance est
moins importante dans ce cadre parce que l’ordre (3.15) interdit d’une cer-
taine mani`ere une reparam´etrisation entre les cat´egories, puisque les diﬀ´erents
groupes ne sont pas du mˆeme type. Quand un tel ordre ne peut pas ˆetre
propos´e, Berger et Bernardo (1992b) sugg`erent de consid´erer comme loi non
informative la loi de r´ef´erence correspondant au cas o`u chaque composante de
θ est trait´ee s´epar´ement. (Par comparaison, la loi de Jeﬀreys traite θ comme
un seul groupe.)
Exemple 3.37. (Berger et Bernardo, 1992b) Soit un mod`ele d’analyse de la
variance
xij = μ + αi + ϵij,
i = 1, . . . , p,
j = 1, . . . , n,
avec αi ∼N (0, τ2), ϵij ∼N (0, σ2). Pour diﬀ´erents ordres des param`etres,
μ, τ2, σ2, nous obtenons les lois de r´ef´erence suivantes :
π1((μ, σ2, τ2)) ∝σ−2(nτ 2 + σ2)−3/2
π2(μ, σ2, τ2) ∝τ−Cnσ2 #
(n −1) + (1 + nτ 2/σ2)−2$1/2
π3(μ, (σ2, τ2)) ∝σ−2(nτ 2 + σ2)−1
π4((μ, σ2), τ2) ∝σ−5/2(nτ 2 + σ2)−1
avec Cn = {1 −√n −1(√n + √n −1)−3}.
∥
3.5.5 Lois a priori co¨ıncidantes
Une approche particuli`ere, pour ne pas dire paradoxale, de la mod´elisa-
tion non informative est de s’int´eresser aux propri´et´es fr´equentistes de la loi a
priori, c’est-`a-dire en moyenne sur x plutˆot que conditionnellement `a x. Notons
tout d’abord, comme cela est discut´e dans les Chapitres 2 et 8, qu’il existe des
25Si une fonction de coˆut L est disponible, elle contient aussi quelque information
sur θ et la dualit´e entre fonction de coˆut et loi a priori peut ˆetre utilis´ee pour obtenir
une loi a priori adapt´ee `a ce coˆut (voir Rubin, 1987). Mais tr`es peu a ´et´e fait sur la
construction de la loi a priori `a partir d’une fonction de coˆut.

148
3 Des informations a priori aux lois a priori
lois a priori donnant des estimateurs optimaux selon des crit`eres fr´equentistes
comme la minimaxit´e ou l’admissibilit´e, et on peut souhaiter restreindre le
choix de la loi a priori `a ces distributions optimales. Cependant, une telle
restriction r´eduit rarement le choix de la loi a priori `a une distribution unique.
Soit aucune loi ne v´eriﬁe cette condition, notamment en petite dimension pour
l’estimation sous le coˆut quadratique (Note 2.8.2), soit une inﬁnit´e de lois
sont, par exemple, associ´ees aux estimateurs minimax admissibles (Fourdrinier
et al., 1998). (Une exception se produit lorsque des structures d’invariance
existent, auquel cas la mesure de Haar `a droite est le choix appropri´e, comme
cela est expliqu´e dans la Section 3.5.2.)
Une approche plus standard est d’imposer que certaines probabilit´es
a posteriori co¨ıncident, jusqu’`a un certain degr´e d’approximation, avec la
couverture fr´equentiste correspondante; d’o`u l’appellation de lois a priori
co¨ıncidantes (traduction de matching priors), qu’on restreint souvent dans
la litt´erature aux intervalles de conﬁance unilat´eraux. Soit un ensemble de
conﬁance a posteriori Cx donn´e sur g(θ),
π(g(θ) ∈Cx|x) = 1 −α ,
unilat´eral ou bilat´eral. Cet ensemble d´eﬁnit alors un ensemble de conﬁance au
sens fr´equentiste, de couverture
Pθ(Cx ∋g(θ)) =

ICx(g(θ)) f(x|θ) dx ,
qui diﬀ`ere g´en´eralement de 1 −α. Lorsque des quantit´es pivotales existent,
comme dans le cas normal N (θ, 1/n), la r´egion de plus forte densit´e a poste-
riori (HPD) au niveau 1 −α (Chapitre 5) est donn´ee par
Cx = [¯xn −n−1/2qα/2, ¯xn + n−1/2qα/2] ,
o`u qα/2 est le quantile au niveau 1 −α/2 d’une loi normale, et la couverture
fr´equentiste de Cx vaut aussi 1 −α. Lindley (1957) g´en´eralise ce r´esultat `a
d’autres familles de position et d´emontre qu’il ne se v´eriﬁe que pour de telles
familles. Dans un cadre g´en´eral (unidimensionnel), Welch et Peers (1963) et
Welch (1965) ont d´emontr´e que, lorsque Cx = (−∞, kα(x)],
Pθ(θ ≤kα(x)) = 1 −α + O(n−1/2) ,
et que, pour la loi a priori de Jeﬀreys,
Pθ(θ ≤kα(x)) = 1 −α + O(n−1) ,
ce qui am´eliore l’approximation d’un facteur 1/2.
Les choses se compliquent en pr´esence de param`etres de nuisance, c’est-
`a-dire lorsque l’inf´erence porte sur une composante unidimensionnelle θ1 du
param`etre. Des r´ef´erences sur des travaux dans ce domaine incluent Swee-
ting (1985), Severini (1991), Ghosh et Mukerjee (1992a,b, 1993), Mukerjee et

3.5 Lois a priori non informatives
149
Dey (1993), DiCiccio et Stern (1993, 1994), Liseo (1993), et Datta et Ghosh
(1995a,b). Nous nous concentrons ici sur certains des r´esultats obtenus par
Rousseau (1997, 2000, 2001).
Le d´eveloppement d’Edgeworth (voir Bhattacharya et Rao, 1986, Bickel
et Ghosh, 1990, et DiCiccio et Stern, 1994) de la probabilit´e de couverture
fr´equentiste est donn´ee par
Pθ(θ1 < kn(α)) = 1 −α +
ϕ(Φ−1(1 −α))
√n
I′(θ)∇log π(θ)
I′′(θ)1/2
−∇t
I′(θ)
I′′(θ)1/2

+ O(n−1) ,
dans le cas unilat´eral, o`u ϕ et Φ sont respectivement la densit´e et la fonc-
tion de r´epartition d’une loi normale, et I(θ), I′(θ), et I′′(θ) sont respecti-
vement l’information de Fisher et ses d´eriv´ees premi`ere et seconde. Dans le
cas d’une r´egion HPD bilat´erale de niveau 1 −α, CHP D
x
(α), pour θ ∈R, le
d´eveloppement correspondant est
Pθ(θ ∈CHP D
x
) = 1 −α + n−1q(α)b(π, θ) + O(n−3/2) ,
o`u q correspond `a une densit´e du χ2 et
b(π, θ) = μ′
3 −μ′′
2
I(θ)2
+ 2μ′
2(μ3 −μ′
2)
I(θ)3
+ π′(θ)
π(θ)
μ3 −μ′
2
I(θ)2
−
π′′(θ)
π(θ)I(θ) −μ′
2π′(θ)
π(θ)I(θ)2 ,
les μj ´etant d´eﬁnis par (j = 2, 3)
μj = Eθ
∂j log f(x|θ)
∂θj

.
La loi a priori co¨ıncidante est alors obtenue par annulation du terme d’ordre
un de ce d´eveloppement, comme dans l’´equation diﬀ´erentielle de Welch et
Peers (1963) :
[I′′(θ)]−1/2I′(θ)∇log π(θ) + ∇t{I′(θ)[I′′(θ)]−1/2} = 0 .
Cette ´equation diﬀ´erentielle peut ne pas avoir de solution. De plus, comme le
montre la g´en´eralisation de Rousseau (2000) aux r´egions HPD, cette solution,
lorsqu’elle existe, d´epend du param`etre d’int´erˆet correspondant `a ces r´egions
HPD et diﬀ`ere le plus souvent de la loi a priori de Jeﬀreys, mˆeme s’il existe
toujours une param´etrisation permettant de retomber sur cette derni`ere.
Exemple 3.38. (Rousseau, 2000) Soit la loi G (k, θ). Si θ est le param`etre
d’int´erˆet, les lois a priori permettant d’annuler le terme de second ordre pour
des r´egions HPD sont de la forme
π(θ) = c1 + c2θ
θ
,
c1, c2 > 0,

150
3 Des informations a priori aux lois a priori
et incluent donc la loi a priori de Jeﬀreys comme cas particulier. Si η =
c1θ5/3 +c2 log(θ) est la quantit´e d’int´erˆet, correspondant `a la param´etrisation
du χ2, la loi a priori de co¨ıncidence maximale est
π(η) = I(η)−1 ,
et diﬀ`ere de la loi de Jeﬀreys, I(η)1/2. Enﬁn, consid´erons la param´etrisation
de la moyenne, μ = k/θ. Les lois a priori co¨ıncidantes sont alors de la forme
π(μ) = c1μ2 + c2/μ ,
c1, c2 > 0,
et, de nouveau, n’incluent pas la loi de Jeﬀreys.
∥
On peut aussi consulter Rousseau (1997) pour une extension au cadre
discret o`u une co¨ıncidence ne peut pas ˆetre obtenue pour des ordres sup´erieurs
`a n1/2 et o`u une randomisation est n´ecessaire pour atteindre de tels ordres.
Exemple 3.39. (Ghosh et al., 1995) Une version simple du mod`ele de cali-
bration lin´eaire est (i = 1, . . . , n, j = 1, . . . , k),
yi = α + βxi + εi,
y0j = α + βx0 + ε0j ,
(3.16)
o`u x0, inconnue, est la quantit´e d’int´erˆet (voir l’Exercice 4.48 pour plus de
d´etails sur ce mod`ele). Pour des intervalles de conﬁance unilat´eraux, l’´equation
diﬀ´erentielle associ´ee `a (3.16) est alors
|β|−1s−1/2 ∂
∂x0
{e(x0)π(θ)} −e−1/2(x0)sgn(β)n−1s1/2 ∂π(θ)
∂x0
−e−1/2(x0)(x0 −¯x)s−1/2 ∂
∂β {sgn(β)π(θ)} = 0
o`u θ = (x0, α, β, σ2) et
s = Σ(xi −¯x)2, e(x0) = [(n + k)s + nk(x0 −¯x)2]/nk .
Les solutions de cette ´equation diﬀ´erentielle sont alors de la forme
π(x0, α, β, σ2) ∝e(x0)(d−1)/2|β|dg(σ2) ,
(3.17)
o`u g est arbitraire. Par exemple, si g(σ2) = (σ2)−a/2, la loi a posteriori cor-
respondante est propre si (n + k + a −2d −5) > 0. Dans ce cas, les lois a
priori de r´ef´erence sont aussi co¨ıncidantes, c’est-`a-dire satisfont (3.17), comme
l’illustre le Tableau 3.5 pour quatre ordres diﬀ´erents sur les param`etres.
∥
En g´en´eral, des lois a priori de r´ef´erence (inverses) sont co¨ıncidantes lorsque
le param`etre d’int´erˆet, λ, et le param`etre de nuisance, ω, sont orthogonaux
au sens de l’information de Fisher

3.5 Lois a priori non informatives
151
Tab. 3.5. Lois a priori de r´ef´erence co¨ıncidantes associ´ees `a diﬀ´erents ordres pour
le mod`ele de calibration lin´eaire (3.16).
Partition
a priori
(x0, α, β, σ2)
|β|(σ2)−5/2
x0, α, β, σ2
e(x0)−1/2(σ2)−1
x0, α, (σ2, β)
e(x0)−1/2(σ2)−3/2
x0, (α, β), σ2
e(x0)−1/2(σ2)−1
x0, (α, β, σ2)
e(x0)−1/2(σ2)−2
I(λ, η) =

I11 0
0
I22

,
comme d´etaill´e dans Tibshirani (1989), et aussi lorsqu’on utilise l’ordre inverse
(ω, λ) pour construire l’a priori de r´ef´erence, comme cela est expliqu´e dans
Berger et al. (1998).
Au-del`a de la diﬃcult´e technique de cette approche, il est conceptuelle-
ment peu ´el´egant d’imposer `a une loi a priori des propri´et´es fr´equentistes,
alors mˆeme que cette loi permet de conditionner en x plutˆot que de recourir
`a des propri´et´es sur le long terme. Tenter de r´econcilier les deux approches
(bay´esienne et fr´equentiste) ne doit pas ˆetre rejet´e syst´ematiquement, comme
cela est expliqu´e dans le Chapitre 5, mais ce changement de paradigme est
plutˆot gˆenant, comme l’illustre Rousseau (1997) qui doit recourir `a la randomi-
sation, en violation du principe de vraisemblance. Nous ne le recommandons
donc pas.
3.5.6 D’autres approches
Des alternatives `a une analyse bay´esienne non informative sont d´ecrites
dans Berger (1985b, Chapitre 3) et Kass et Wasserman (1996). Nous men-
tionnons par exemple Rissanen (1983, 1990), qui recourt `a la th´eorie de la
transmission d’information de Shannon (1948). Consid´erant la transmission
d’un message binaire par un appareil physique, la loi a priori non informa-
tive pour un mod`ele f(x|θ) est la longueur minimale d’un message d´ecrivant
ce mod`ele. Dans le cas le plus simple, ces lois sont similaires `a celle de Jef-
freys. Cette similarit´e devrait se v´eriﬁer en g´en´eral, de part les connexions qui
existent entre information statistique et th´eorie de l’information. Une revue
r´ecente de cette th´eorie de la complexit´e stochastique est donn´ee par Dawid
(1992); voir aussi Hansen et Yu (2000).
Notons aussi que la mise en œuvre des tests requiert des lois a priori
particuli`eres, comme le signalent Hansen et Yu (2000) et Kass et Wasserman
(1996). Nous traiterons ce point particulier dans le Chapitre 5.

152
3 Des informations a priori aux lois a priori
3.6 Validation a posteriori et robustesse
Mˆeme dans les situations o`u l’information a priori est disponible, il est rare
de pouvoir proposer une d´etermination exacte de la loi a priori π(θ) `a partir de
cette information, ne serait-ce que parce que le pouvoir de discrimination des
individus est ﬁni et la d´etermination des queues de distribution est impossible
en pratique. Dans la plupart des cas, une certaine impr´ecision sur la loi a
priori employ´ee dans une inf´erence bay´esienne demeure donc.
Si l’information a priori est riche, la loi a priori sera bien entendu mieux
d´eﬁnie que dans un cadre non informatif. Cependant, il est important dans
tous les cas de s’assurer que l’impact de cette ind´etermination de la loi a priori
sur les quantit´es a posteriori soit bien ´evalu´e et que la partie arbitraire de l’a
priori ne soit pas pr´edominante. L’´etude de ces aspects est dite analyse de sen-
sibilit´e (ou de robustesse). La notion de robustesse et la construction d’outils
appropri´es pour traiter ce probl`eme particulier apparaissent dans les travaux
de Good (1983) et Berger (1982a, 1984, 1985b, 1990). D’autres r´ef´erences
sont Berger et Berliner (1986), Berger et Sellke (1987), Berger et Delampady
(1987), O’Hagan (1988), Sivaganesan et Berger (1989),Walley (1991), Wasser-
man (1992) et Abraham et Daur´es (2000).
Suivant la classiﬁcation de Berger (1990), nous consid´erons que l’incer-
titude portant sur la loi a priori π peut se repr´esenter par une classe Γ de
lois a priori, `a laquelle π est suppos´ee appartenir. Ces classes peuvent ˆetre
d´etermin´ees selon des crit`eres pratiques ou subjectifs. Les types de classes de
robustesse les plus couramment rencontr´es dans la litt´erature sont :
(i) Classes de lois conjugu´ees. Ces classes sont typiquement choisies pour
des raisons pratiques, parce qu’elles fournissent en g´en´eral des bornes
explicites pour les quantit´es d’int´erˆet. Par exemple, Das Gupta et Stud-
den (1988) consid`erent le cas o`u x ∼Np(θ, Ip) et θ ∼Np(0, Σ), avec
Σ1 ⪯Σ ⪯Σ2, la relation d’ordre ⪯´etant v´eriﬁ´ee lorsque la diﬀ´erence
des deux matrices est semi-d´eﬁnie positive. Les critiques d´ej`a ´evoqu´ees
sur les lois conjugu´ees s’appliquent bien entendu dans ce cadre et ce
d’autant plus que la classe r´esultante ne contient que des lois “de conve-
nance”, dont assez peu sont compatibles avec l’information a priori.
(ii) Classes `a moments d´etermin´es. L’hypoth`ese que l’information a priori
(limit´ee) ne peut se traduire que par des bornes sur certains moments
de π correspond `a la classe
ΓM = {π; ai ≤Eπ[θi] ≤bi, i = 1, . . . , k}.
Cependant, ΓM n’est pas tellement plus satisfaisante que la classe
pr´ec´edente, car elle impose des conditions fortes sur les queues de la
loi a priori. De plus, elle contient des lois peu raisonnables, notamment
des lois `a support ﬁni26.
26Plus pr´ecis´ement, les bornes portant sur les quantit´es a posteriori sont atteintes
dans la plupart des cas par des lois `a support ﬁni, pour des raisons de convexit´e.

3.6 Validation a posteriori et robustesse
153
(iii) Classes de voisinages. Introduites par Huber (1964b) pour la d´etection
de points aberrants, les classes d’ϵ-contamination d’une loi π0,
Γϵ,Q = {π = (1 −ϵ)π0 + ϵq; q ∈Q},
sont souvent utilis´ees dans les ´etudes de robustesse. Dans l’expression
ci-dessus Q est une classe de distributions choisie en fonction de la
pr´ecision de l’information a priori. Berger et Berliner (1986) et Berger
(1990) donnent des exemples o`u de telles classes peuvent ˆetre utilis´ees.
Le probl`eme majeur li´e `a l’utilisation de Γϵ,Q est la d´etermination dif-
ﬁcile de ϵ et de Q, notamment `a partir du degr´e d’incertitude sur π0.
Mais des techniques d’estimation de m´elanges peuvent ˆetre utiles dans
un tel cadre, lorsque l’information a priori est construite `a partir d’un
´echantillon d’observations pass´ees (´eventuellement ﬁctives) (voir la Sec-
tion 6.4). Une autre relation est de consid´erer un v´eritable voisinage
associ´e `a une distance comme celles de Hellinger ou de Kullback-Leibler
(voir la Section 2.5.4 et Zucchini, 1999). La diﬃcult´e est alors de choisir
l’´echelle de tels voisinages.
(iv) Classes sous-sp´eciﬁ´ees. De telles classes r´esultent d’une construction
de la loi a priori sur une sous-σ-alg`ebre, c’est-`a-dire pour un ensemble
plus fruste d’´ev´enements que celui d’int´erˆet. Cette approche est directe-
ment reli´ee aux d´eveloppements axiomatiques de la Note 3.8.1, puisque
l’ordre sur les vraisemblances relatives n’engendre pas forc´ement une loi
a priori sur l’ensemble des bor´eliens. Par exemple, il se peut que certains
des quantiles de la loi a priori soient d´etermin´es,
ΓQ = {π; ℓi ≤

Ii
π(θ) dθ ≤ui, i = 1, . . . , m}
o`u I1, . . . , Im est une partition de Θ. Ces classes sont pr´ef´erables `a
(ii), mais il peut malgr´e tout ˆetre n´ecessaire de retirer de ΓQ certaines
lois a priori peu raisonnables, comme dans O’Hagan (1988). Cepen-
dant, cette approche semble ˆetre la plus r´ealiste, car, par exemple, il est
g´en´eralement plus facile de d´eterminer des fractiles que des moments.
Cette approche semble aussi la plus facile `a mettre en œuvre parmi celles
pr´esent´ees ici.
(v) Classes de rapport de densit´es. Partant d’une construction subjective
de la loi a priori comme dans le cas pr´ec´edent, une autre solution est
de consid´erer une repr´esentation sous forme d’histogramme. D`es lors,
l’incertitude sur l’information a priori peut se repr´esenter par des bornes
sup´erieure et inf´erieure pour la densit´e π, ce qui donne la classe
ΓR = {π; L(θ) ≤π(θ) ≤U(θ)},
o`u L et U sont donn´ees. Le choix de ces fonctions est d´elicat et a des
cons´equences importantes, car, si elles sont similaires, toutes les lois dans
ΓR auront le mˆeme type de queues ; voir DeRobertis et Hartigan (1981)
et Abraham et Daur´es (2000) pour des classes similaires.

154
3 Des informations a priori aux lois a priori
Berger (1990) et Wasserman (1992) d´eveloppent des outils num´eriques
pour le calcul de bornes sur les quantit´es a posteriori, pour les classes ci-
dessus. De fait, l’approche par robustesse remplace l’estimateur standard ϱ(π)
par l’ensemble des valeurs possibles pour cet estimateur lorsque la loi a priori
π varie dans la classe Γ,
ϱL = inf
π∈Γ ϱ(π),
ϱU = sup
π∈Γ
ϱ(π).
Goutis (1990, 1994) (voir l’Exemple 3.6) donne une illustration de cette ap-
proche pour la classe (ii). Le Chapitre 5 en donne une autre pour l’obtention
de bornes conservatrices sur la probabilit´e a posteriori d’une hypoth`ese nulle.
Une approche plus conservatrice de la notion de robustesse est de construire
des lois a priori robustes, qui sont des lois param´etr´ees aussi peu d´ependantes
que possible de petites variations de l’information a priori. Par exemple, on
peut montrer que les lois de Student sont pr´ef´erables aux lois normales pour
un mod`ele normal, mˆeme si ces derni`eres sont conjugu´ees pour ce mod`ele et
qu’elles sont en fait d’entropie maximale dans certains cas (voir Zellner, 1971,
Angers, 1987, et Angers et MacGibbon, 1990).
De mˆeme, les lois poly-t obtenues comme un produit de densit´es de Student
sont utilis´ees dans l’analyse ´econom´etrique des ´equations simultan´ees pour la
mˆeme raison (voir Dr`eze, 1976a, Richard et Tompa, 1980, et Bauwens, 1984).
Le plus souvent, ces lois a priori robustes auront des queues ´epaisses, au
contraire des lois conjugu´ees.
Une autre fa¸con d’accroˆıtre la robustesse des lois conjugu´ees
est d’in-
troduire une mod´elisation hi´erarchique. L’approche bay´esienne hi´erarchique
est pr´esent´ee dans le Chapitre 10, mais il semble d’ores et d´ej`a tout `a fait
intuitif que l’ajout d’un niveau suppl´ementaire dans la mod´elisation a priori
puisse am´eliorer la robustesse de la loi a priori. Consid´erons une loi conjugu´ee
π1(θ|λ) pour f(x|θ). Comme il est expliqu´e ci-dessus, des classes comme (i)
ne sont pas tr`es robustes et, de plus, n´ecessitent la sp´eciﬁcation de bornes
pour les hyperparam`etres λ. Puisque ces hyperparam`etres sont (partiellement
ou totalement) inconnus, une extension naturelle (dans un cadre bay´esien)
est d’introduire une loi a priori non informative π2 sur λ (ou une loi hyper a
priori compatible avec l’information disponible). Cette mod´elisation donne la
structure hi´erarchique suivante :
λ ∼π2(λ),
θ|λ ∼π1(θ|λ),
x|θ ∼f(x|θ).
La loi a priori sur θ est alors la marginale de π1(θ|λ)π2(λ), apr`es int´egration
par rapport `a λ,
π(θ) =

π1(θ|λ)π2(λ)dλ.
(3.18)

3.6 Validation a posteriori et robustesse
155
Cette loi a priori n’est g´en´eralement pas conjugu´ee, mais le but principal de
cette extension hi´erarchique est bien d’´eviter le cadre trop restrictif des lois
conjugu´ees. En int´egrant sur les hyperparam`etres λ, on obtient une distri-
bution (3.18) qui se caract´erise g´en´eralement par des queues plus ´epaisses
que les lois conjugu´ees. Par exemple, la loi de Student peut s’´ecrire comme
(3.18), o`u π2 est une loi gamma inverse (voir l’Exemple 3.17). Les formu-
lations hi´erarchiques sont aussi int´eressantes d’un point de vue num´erique,
comme expliqu´e dans le Chapitre 6.
D’autres approches prennent en compte la fonction de coˆut dans l’analyse
de robustesse, aﬁn d’obtenir un estimateur qui soit conservateur `a l’´egard de
toutes les lois a priori possibles π ∈Γ. Par exemple, δ∗peut ˆetre la solution
de
inf
δ
sup
π∈Γ
r(π, δ)
ou
inf
δ
sup
π∈Γ
[r(π, δ) −r(π, δπ)],
la premi`ere quantit´e ´etant le risque Γ-minimax et la seconde le regret Γ-
minimax , comme l’ont d´evelopp´e Robbins (1951) et Good (1952) ; voir Berger
et Berliner (1986), Berger (1985b), et Kempthorne (1988) pour de plus amples
r´ef´erences.
La litt´erature sur la robustesse bay´esienne s’est consid´erablement accrue
ces derni`eres ann´ees et nous renvoyons les lecteurs aux articles cit´es ci-dessus
pour de plus amples r´ef´erences. Pour conclure ce chapitre, remarquons que le
choix de la loi a priori d´etermine l’inf´erence bay´esienne qui en r´esulte, que ce
choix est parfois trivial et parfois tr`es d´elicat, mais qu’il doit se justiﬁer dans
tous les cas `a partir de l’information a priori et, de plus, qu’une analyse de
robustesse doit ˆetre mise en œuvre, aﬁn d’´etablir l’impact sur l’a posteriori
qu’un changement dans la loi a priori implique. Bien entendu, cette analyse
d´ependra de la fa¸con dont on ´evalue l’impact sur les quantit´es d’int´erˆet, comme
par exemple sur les coˆuts utilis´es dans le processus d’estimation. Ceci permet
d’utiliser la connaissance de la fonction de coˆut pour d´eterminer une loi a priori
non informative, mais cette approche a ´et´e peu explor´ee, mˆeme si de nombreux
bay´esiens ont remarqu´e que fonction de coˆut et loi a priori ne peuvent ˆetre
distingu´ees (voir notamment Lindley, 1985, et l’Exercice 3.58.) Un dernier
avertissement aux lecteurs pour noter que l’inﬂuence de l’a priori est souvent
sous-estim´ee par les utilisateurs, alors qu’elle peut avoir des cons´equences
inattendues sur l’inf´erence r´esultante. D`es lors, il est n´ecessaire de recourir
d`es que possible `a d’autres valeurs pour les hyperparam`etres, mais aussi `a
d’autres types de lois, aﬁn d’´etablir l’impact r´eel du choix de la loi a priori
sur l’inf´erence qui en r´esulte27.
27Insistons de nouveau sur l’erreur commune qui consiste `a croire que prendre des
lois propres de grandes variances est un substitut acceptable aux lois non informa-
tives.

156
3 Des informations a priori aux lois a priori
3.7 Exercices
Section 3.1
3.1 (Dupuis, 1995b) Rappelons que la distribution bˆeta Be(α, β) a pour densit´e
π(θ) = Γ(α + β)
Γ(α)Γ(β)θα−1(1 −θ)β,
0 ≤θ ≤1 .
a. Donner l’esp´erance de la distribution Be(α, β).
b. Montrer qu’il existe une bijection entre (α, β) et le triplet (μ, θ0, θ1), o`u
π(θ ∈[θ0, θ1]) = p et μ est l’esp´erance de la distribution.
c. Quelles sont les conditions sur (μ, θ0, θ1) pour l’existence de (α, β) ?
Section 3.2.3
3.2 (Seidenfeld, 1987) Soit θ la variable al´eatoire correspondant au r´esultat d’un
lancer de d´e `a six faces.
a. Si π est la distribution de θ, donner l’a priori d’entropie maximale associ´e
`a l’information E[θ] = 3.5.
b. Montrer que, si A est l’´ev´enement “θ est impair”, la distribution actualis´ee
π(·|A) est (1/3, 0, 1/3, 0, 1/3, 0).
c. Montrer que la loi a priori d’entropie maximale associ´ee aux contraintes
E[θ] = 3.5 et E[IA] = 1 est (.22, 0, .32, 0, .47).
[Note : Seidenfeld (1987) et Kass et Wasserman (1996) utilisent cet exemple pour
montrer que l’approche de l’entropie maximale n’est pas toujours compatible
avec le principe bay´esien d’actualisation donn´e par (1.13).]
3.3 Montrer que, si les contraintes (3.1) sont toutes associ´ees `a des fonctions gk
de la forme gk(θ) = I(−∞,ak](θ), il n’existe pas d’a priori d’entropie maximale
lorsque Θ = R et π0 est la mesure de Lebesgue sur R.
3.4 Soit θ ∈R et une loi a priori π telle que varπ(θ) = 1, π(θ < −1) = 0.1, et
π(θ > 1) = 0.1. Calculer l’a priori d’entropie maximale associ´e `a la mesure de
Lebesgue sur R, si ce calcul est possible.
3.5 Soit π0 une mesure de r´ef´erence pour la m´ethode de l’entropie maximale et π′
0
une mesure absolument continue par rapport `a π0.
a. Donner des exemples o`u les lois a priori d’entropie maximale associ´ees `a π0
et π′
0 co¨ıncident.
b. Appliquer ce r´esultat au cas o`u π0 est la mesure de Lebesgue sur R, π′
0 est
la distribution N (0, 1), et les contraintes (3.1) sont Eπ[θ] = 0, varπ(θ) = σ2,
en fonction de la valeur de σ.
3.6 Soit θ ∈R+. D´eterminer s’il existe une loi a priori d’entropie maximale sous la
contrainte Eπ[θ] = μ pour π0(θ) = 1 et π0(θ) = 1/θ.
3.7 Soit x ∼P(θ).
a. D´eterminer la loi a priori d’entropie maximale associ´ee `a π0(θ) = 1/
√
θ et
Eπ[θ] = 2.
b. D´eterminer les hyperparam`etres de la loi a priori π lorsque π est de la forme
(i) E xp(μ);
(ii) G (2, ϱ).

3.7 Exercices
157
c. Calculer les trois lois a posteriori correspondantes lorsque x = 3 et comparer
les estimateurs de Bayes de θ sous le coˆut L(θ, δ) = θ(θ −δ)2.
Section 3.2.4
3.8 D´eterminer les lois a priori dans l’Exemple 3.5, lorsque les premier et troisi`eme
quartiles sont 2 et −2, et la m´ediane est 0.
3.9 Soient x ∼B(n, θ) et θ ∼Be(α, β). D´eterminer s’il existe des valeurs de α, β
telles que π(θ|x) soit la loi a priori uniforme sur [0, 1], mˆeme pour une unique
valeur de x.
3.10 Soient x ∼Pa(α, θ), distribu´e selon une loi de Pareto, et θ ∼Be(μ, ν).
Montrer que, si α < 1 et x > 1, un certain choix de μ et ν fait de π(θ|x) la loi
a priori uniforme sur [0, 1].
Section 3.3.1
3.11 Donner l’expression de π(θ|x) lorsque π est un m´elange ﬁni de distributions
continues. En particulier, calculer les poids a posteriori. En d´eduire les r´esultats
de l’Exemple 3.22.
3.12 D´eterminer les distributions sym´etriques, c’est-`a-dire telles que distributions
d’´echantillonnage et distributions conjugu´ees appartiennent `a la mˆeme famille
param´etr´ee.
3.13 Cet exercice montre que la notion de famille minimale conjugu´ee est en g´en´eral
sans int´erˆet.
a. En utilisant les notations de la Proposition 3.19, montrer que l’ensemble des
λ dans l’expression π(θ|μ, λ) peut se restreindre `a ceux variant dans λ0 +N,
pour n’importe quel λ0 > 0.
b. En d´eduire que, si λ0 −λ′
0 ̸∈Z, les familles conjugu´ees associ´ees `a λ0 + N
et λ′
0 + N sont disjointes.
c. En conclure que l’intersection de toutes les familles conjugu´ees est vide.
3.14 Soit une population divis´ee en k cat´egories (ou cellules), se caract´erisant par
une probabilit´e pi d’appartenir `a la cellule i pour chaque individu (1 ≤i ≤n).
Une suite (πk) de lois a priori sur pk = (p1, . . . , pk), k ∈N, est dite coh´erente si
tout regroupement de cellules en m cat´egories donne la loi a priori πm pour les
probabilit´es transform´ees.
a. D´eterminer les conditions de coh´erence sur la suite (πk).
b. Dans le cas particulier o`u πk est une loi de Dirichlet Dk(α1, . . . , αk), exprimer
ces conditions en fonction des αk.
c. Est-ce que l’a priori de Jeﬀreys engendre une suite coh´erente ?
d. Mˆeme question pour πk(pk) ∝Q
i p−1/k
i
, comme propos´e par Perk (1947).
Section 3.3.3
3.15 Montrer que toute distribution tir´ee d’une famille exponentielle peut se
g´en´eraliser en une pseudo-famille exponentielle, par l’ajout de contraintes pa-
ram´etriques sur le support de x. Commenter la modiﬁcation de la statistique
exhaustive.
3.16 Montrer que, si le support de f(x|θ) ne d´epend pas de θ et s’il existe une famille
a priori conjugu´ee param´etr´ee F = {π(θ|λ), λ ∈Λ} avec dim(Λ) < +∞, f(x|λ)
appartient n´ecessairement `a une famille exponentielle. (Indication : C’est une
cons´equence du lemme de Pitman-Koopman.)

158
3 Des informations a priori aux lois a priori
3.17 Donner une statistique exhaustive associ´ee `a l’´echantillon x1, . . . , xn d’une loi
de Pareto Pa(α, θ).
3.18 Donner une statistique exhaustive associ´ee `a l’´echantillon x1, . . . , xn d’une loi
normale tronqu´ee
f(x|θ) ∝e−(x−θ)2/2I[θ−c,θ+c](x),
o`u c est connu.
3.19 *(Brown, 1986b) Montrer que toute famille exponentielle peut se repara-
m´etriser en une famille exponentielle naturelle. Montrer aussi que la dimen-
sion de cette reparam´etrisation naturelle ne d´epend pas du choix de la repa-
ram´etrisation.
3.20 *(Dynkin, 1951) Montrer que les lois normales et les lois de la forme c log(y), o`u
y ∼G (α, β), sont les seules lois appartenant `a la fois `a une famille exponentielle
et `a une famille de position. En d´eduire que les lois normales sont les seules lois
appartenant `a une famille exponentielle et `a sym´etrie sph´erique (voir l’Exercice
1.1).
3.21 *(Lauritzen, 1996) Soient X = (xij) et Σ = (σij) des matrices m × m
sym´etriques d´eﬁnies positives. La loi de Wishart, Wm(α, Σ), est d´eﬁnie par la
densit´e
pα,Σ(X) = |X|
α−(m+1)
2
exp(−tr(Σ−1X)/2)
Γm(α)|Σ|α/2
,
o`u tr(A) est la trace de A et
Γm(α) = 2αm/2πm(m−1)/4
m
Y
i=1
Γ
„α −i + 1
2
«
.
a. Montrer que cette loi appartient `a une famille exponentielle. Donner sa
repr´esentation naturelle et calculer l’esp´erance de Wm(α, Σ).
b. Montrer que, si z1, . . . , zn ∼Nm(0, Σ),
n
X
i=1
ziz′
i ∼Wm(n, Σ) .
c. Montrer que les moments de cette loi sont donn´es par
E[X|α, Σ] = αΣ,
Cov(X) = 2αΣ ⊗Σ .
d. Montrer que l’esp´erance de l’inverse X−1 est
E[X−1|α, Σ] =
1
α −p −1Σ,
α > p + 1 .
3.22 *(Pitman, 1936) D´emontrer le lemme de Pitman-Koopman : Si, pour n ≥n0,
il existe Tn de Rn dans Rk tel que Tn(x1, . . . , xn) est exhaustive pour x1, . . . , xn
observations i.i.d. de f(x|θ), la distribution f appartient n´ecessairement `a une
famille exponentielle lorsque le support de f ne d´epend pas de θ. ´Etudier le cas
o`u le support de f d´epend de θ.
3.23 Montrer que la loi gaussienne inverse, de densit´e
(π)−1/2z−3/2 exp{θ1z + θ2(1/z) −(2θ1θ2)1/2 + (1/2) log(−2θ2)}
o`u z ∈R+ et θ1, θ2 ∈R−, est exponentielle mais non r´eguli`ere.

3.7 Exercices
159
3.24 *(Morris, 1982) Une famille exponentielle restreinte sur R est d´eﬁnie par
Pθ(x ∈A) =
Z
A
exp{θx −ψ(θ)} dF(x),
θ ∈Θ.
(3.19)
a. Montrer que, si 0 ∈Θ, F est n´ecessairement une fonction de r´epartition. Si
cette condition n’est pas v´eriﬁ´ee, montrer que la transformation de F en
dF0(x) = exp{θ0x −ψ(θ)} dF(x),
pour une valeur arbitraire θ0 ∈Θ et le remplacement de θ par θ −θ0 redonne
le mˆeme r´esultat.
b. Montrer que, au sens restreint, Be(mμ, m(1 −μ)) et la loi log-normale
L N (α, σ2) n’appartiennent pas `a une famille exponentielle.
c. Si μ = ψ′(θ) est l’esp´erance de la distribution (3.19), la fonction de variance
de cette distribution est d´eﬁnie par V (μ) = ψ′′(θ) = varθ(x). Montrer que V
est eﬀectivement une fonction de μ et que, de plus, si l’espace de variation de
μ, Ω, est connu, le couple (V, Ω) caract´erise compl`etement la famille (3.19)
par
ψ
„Z μ
μ0
dm
V (m)
«
=
Z μ
μ0
m dm
V (m).
(Noter que θ =
R μ
μ0 dm/V (m).) Montrer que V (μ) = μ2 d´eﬁnit deux familles,
selon que Ω = R−ou Ω = R+.
d. Montrer que V (μ) = μ(1 −μ)/(m + 1) correspond `a la fois `a la loi binomiale
B(m, μ) et `a Be(mμ, m(1−μ)). En d´eduire que la caract´erisation par V n’est
valide que pour les familles exponentielles naturelles.
e. Montrer que les familles exponentielles de fonction de variance quadratique,
donn´ees par
V (μ) = v0 + v1μ + v2μ2,
(3.20)
incluent les distributions suivantes : normale, N (μ, σ2), Poisson, P(μ),
gamma, G (r, μ/r), binomiale, B(m, mμ) et n´egative binomiale, N eg(r, p),
qu’on peut d´eﬁnir comme le nombre de succ`es avant le r-i`eme ´echec, avec
μ = rp/(1 −p).
f. Montrer que les lois normales (respectivement, de Poisson) sont les seules
distributions exponentielles naturelles de fonction de variance constante (res-
pectivement, de degr´e un).
g. Supposons v2 ̸= 0 dans (3.20) et d´eﬁnissons d = v2
1 −4v0v2, le discriminant
de (3.20), et a = 1 si d = 0, a =
√
dv2 sinon. Montrer que x∗= aV ′(x) est
une transformation lin´eaire de x, de fonction de variance
V ∗(μ∗) = s + v2(μ∗)2,
(3.21)
o`u μ∗= aV ′(μ) et s = −sign(dv2). Montrer qu’il est suﬃsant de consid´erer V ∗
pour caract´eriser les familles exponentielles naturelles de fonction de variance
quadratique, au sens o`u les autres familles s’obtiennent par inversion de la
transformation lin´eaire.
h. Montrer que (3.21) correspond `a six cas possibles selon le signe de v2 et
la valeur de s (−1, 0, 1). ´Eliminer les deux cas impossibles et identiﬁer les
familles donn´ees `a la question e. ci-dessus. Montrer que le cas restant est

160
3 Des informations a priori aux lois a priori
v2 > 0, s = 1. Pour v2 = 1, montrer que ce cas correspond `a la distribution
de x = log{y/(1 −y)}/π, o`u
y ∼Be
„1
2 + θ
π , 1
2 −θ
π
«
,
|θ| < π
2 ,
et
f(x|θ) = exp[θx + log(cos(θ))]
2 cosh(πx/2)
.
(3.22)
[Note : La formule de r´eﬂexion B(0.5 + t, 0.5 −t) = π/ cos(πt) peut ˆetre
utile.] Les distributions g´en´er´ees par les transformations lin´eaires de (3.22)
sont not´ees GHS(r, λ) (pour generalized hyperbolic secant), avec λ = tan(θ),
r = 1/v2, et μ = rλ. Montrer que la densit´e de GHS(r, λ) peut s’´ecrire
fr,λ(x) =
`
1 + λ2´−r/2 exp{x arctan(λ)}fr,0(x)
(ne pas chercher `a obtenir une expression explicite de fr,0).
[Note : L’Exercice 10.33 exhibe d’autres propri´et´es des familles exponentielles
`a variance quadratique en termes de familles conjugu´ees et d’estimateurs de
Bayes. L’Exercice 6.11 montre comment des polynˆomes orthogonaux peuvent
ˆetre associ´es `a chaque distribution d’une famille exponentielle `a variance qua-
dratique.]
3.25 Comparer les familles exponentielles usuelles avec les distributions (2.9) obte-
nues dans le Chapitre 2 et v´eriﬁer si elles g´en`erent des estimateurs universels.
3.26 Montrer que, pour toute famille exponentielle, l’espace naturel N est convexe.
3.27 Prouver la d´ecomposition de l’Exemple 3.17
(i) directement ; et
(ii) via la repr´esentation usuelle d’une distribution de Student.
3.28 Une alternative `a la r´egression logistique introduite dans l’Exemple 3.21 est le
mod`ele probit, tel que
Pα(yi = 1) = 1 −Pα(yi = 0) = Φ(αtxi),
i = 1, . . . , n,
o`u Φ est la fonction de r´epartition d’une loi normale centr´ee r´eduite.
a. Montrer que ce second mod`ele n’appartient pas `a une famille exponentielle,
mˆeme conditionnellement aux xi.
b. Les observations yi peuvent ˆetre consid´er´ees comme les fonctions indicatrices
Izi≤αtxi o`u zi est une variable al´eatoire non observ´ee N (0, 1). Montrer que, si
les zi sont connus, la mesure de Lebesgue donne une loi a posteriori explicite.
[Note : Le caract`ere int´eressant de cette remarque apparaˆıtra plus clairement
au Chapitre 6, car les donn´ees manquantes z1, . . . , zn peuvent ˆetre simul´ees.]
Section 3.3.4
3.29 Pour une distribution quelconque d’une famille exponentielle, d´eterminer des
contraintes pour que la loi a priori d’entropie maximale soit aussi une loi
conjugu´ee.
3.30 Un mod`ele de r´egression lin´eaire classique peut s’´ecrire y ∼Np(Xβ, σ2Ip)
o`u X est une matrice p × q et β ∈Rq. Lorsque X est connu, donner la pa-
ram´etrisation naturelle de cette famille exponentielle et obtenir les lois a priori
conjugu´ees sur (β, σ2). G´en´eraliser au cas Np(Xβ, Σ), avec Σ connu.

3.7 Exercices
161
3.31 Soit x ∼N (θ, θ) avec θ > 0.
a. D´eterminer l’a priori de Jeﬀreys πJ(θ).
b. ´Etablir si la loi de x appartient `a une famille exponentielle et construire les
lois a priori conjugu´ees sur θ.
c. Utiliser la Proposition 3.20 pour relier les hyperparam`etres des lois conjugu´ees
`a l’esp´erance de θ.
3.32 Montrer que, si x ∼Be(θ1, θ2), il existe des lois conjugu´ees pour θ = (θ1, θ2),
mais que celles-ci ne permettent pas un calcul analytique des quantit´es a pos-
teriori, `a l’exception de Eπ[θ1/(θ1 + θ2)|x], suivant la Proposition 3.20.
3.33 *(Robert, 1991) La distribution normale inverse g´en´eralis´ee I N (α, μ, τ) a
pour densit´e
K(α, μ, τ)|θ|−α exp
j
−(1
θ −μ)2/2τ 2
ﬀ
,
avec α > 0, μ ∈R, et τ > 0.
a. Montrer que cette densit´e est bien d´eﬁnie et que la constante de normalisation
est
K(α, μ, τ)−1 = τ α−1e−μ2/2τ22(α−1)/2 Γ(α −1
2
) 1F1
„α −1
2
; 1/2; μ2
2τ 2
«
,
o`u 1F1 est la fonction conﬂuente hyperg´eom´etrique (voir Abramowitz et Ste-
gun, 1964).
b. Montrer que cette distribution g´en´eralise celle de y = 1/x pour x ∼
N (μ, τ 2). V´eriﬁer que la constante de normalisation ci-dessus est correcte
dans ce cas particulier.
c. En d´eduire que l’esp´erance de I N (α, μ, τ) existe pour α > 2 et vaut
Eα,μ,τ[θ] = μ
τ 2
1F1( α−1
2 ; 3/2; μ2/2τ 2)
1F1( α−1
2 ; 1/2; μ2/2τ 2).
d. Montrer que ces distributions I N(α, μ, τ) constituent une famille conjugu´ee
pour le mod`ele multiplicatif N (θ, θ2).
3.34 Montrer que la distribution de Student Tp(ν, θ, τ 2) n’admet pas de famille
conjugu´ee autre que la famille triviale F0.
3.35 La Proposition 3.19 ´etablit l’existence d’une famille conjugu´ee pour toute fa-
mille exponentielle, de la forme (3.8),
π(θ|λ, μ) = exp{θ · μ −λψ(θ)}K(μ, λ).
a. Montrer que la distribution (3.8) est en fait bien d´eﬁnie pour λ > 0 et
(μ/λ) ∈˚
N, int´erieur de N.
b. Calculer cette constante K pour des distributions normale, gamma et n´egative
binomiale.
c. En d´eduire (en recourant `a une certaine reparam´etrisation) que la fonction de
vraisemblance ℓ(θ|x) est une distribution a priori particuli`ere pour les familles
exponentielles et donner l’a priori correspondant pour les familles ci-dessus.
d. Cette propri´et´e caract´erise-t-elle les familles exponentielles ? Donner un
contre-exemple.
3.36 * D´emontrer la Proposition 3.20 et sa r´eciproque dans le cas continu. Appliquer
aux distributions du Tableau 3.4.

162
3 Des informations a priori aux lois a priori
3.37 Montrer que les distributions du Tableau 3.4 sont en fait conjugu´ees
(i) directement ; et
(ii) en utilisant la Proposition 3.20.
3.38 Soit x ∼G (θ, β), c’est-`a-dire fβ(x|θ) =
βθ
Γ (θ)xθ−1e−βx.
a. Peut-on construire une famille conjugu´ee pour cette distribution ?
b. Traiter le cas θ ∈N.
c. Mˆeme question pour x ∼Be(1, θ).
3.39 Montrer que, pour des familles exponentielles, un accroissement du nombre de
niveaux hi´erarchiques ne modiﬁe pas la nature conjugu´ee de l’a priori r´esultant
si des lois conjugu´ees avec des param`etres d’´echelle constants sont utilis´ees `a
tous les niveaux de la hi´erarchie. (Consid´erer par exemple le cas normal.)
3.40 *(Robert, 1993b) Soit f(x|θ) prise dans une famille exponentielle,
f(x|θ) = eθ·x−ψ(θ)h(x),
x ∈Rk,
et π0(θ|x0, λ) une loi a priori conjugu´ee,
π0(θ|x0, λ) = eθ·x0−λψ(θ).
Nous cherchons `a obtenir une estimation dite objective de ∇ψ(θ), `a partir d’une
loi a priori arbitraire π0(θ|x0, λ). Dans ce but, nous rempla¸cons π0 par la dis-
tribution π1(θ|x1, λ) d´eﬁnie par la relation
Eπ1[∇ψ(θ)] = Eπ0[∇ψ(θ)|x],
(3.23)
aﬁn de r´eduire l’inﬂuence de x0.
a. En d´eduire la relation entre x1 et x0.
b. Nous it´erons le processus d’actualisation (3.23) aﬁn d’´eliminer, autant que
possible, l’inﬂuence de x0 et nous construisons de cette fa¸con une suite
πn(θ|xn, λ) de lois a priori conjugu´ees. Donner la relation entre xn et xn−1 et
en d´eduire la limite de la suite (xn).
c. Donner la limite correspondante des estimateurs de Bayes de ∇ψ(θ). Com-
ment caract´erisez-vous l’estimateur r´esultant ? S’agit-il toujours d’un estima-
teur de Bayes ?
d. Dans le cas particulier o`u x ∼N (θ, 1), le param`etre d’int´erˆet est h(θ) =
e−θ. Donner l’estimateur h(θ) obtenu de cette fa¸con, en utilisant la formule
d’actualisation it´erative
Eπn[h(θ)] = Eπn−1[h(θ)|x].
e. Consid´erer le cas x ∼G (α, θ) et h(θ) = θk aﬁn de montrer que cette m´ethode
it´erative, appel´ee r´etroaction d’a priori, ne converge pas toujours vers l’esti-
mateur du maximum de vraisemblance.
f. Montrer que la limite de cet estimateur obtenu par r´etroaction d’a priori
lorsque λ tend vers +∞est l’estimateur du maximum de vraisemblance de
h(θ), pour une fonction arbitraire h et toute famille exponentielle.
Section 3.4

3.7 Exercices
163
3.41 Dans le cadre de l’Exemple 3.22, construire une loi a priori en observant
quelques pi`eces et en imposant un m´elange de lois bˆeta, comme dans Diaco-
nis et Ylvisaker (1985). Choisir l’une de ces pi`eces et calculer la distribution
a posteriori de θ, la probabilit´e d’obtenir pile, apr`es dix lancers et cinquante
lancers.
3.42 D´eduire les lois a posteriori de l’Exemple 3.22 de la relation de r´ecurrence
Γ(a + 1) = aΓ(a) sur la fonction gamma.
3.43 Soient x ∼N (0, 1) et θ ∼T1(5, 0, 1).
a. ´Etablir une m´ethode d’approximation de la loi a priori par un m´elange de :
(i) deux lois normales ; et
(ii) cinq lois normales.
b. Dans chaque cas, donner l’approximation de l’esp´erance a posteriori de θ
correspondante pour x = 1, et comparer avec la valeur exacte.
Section 3.5.1
3.44 Soit x1, . . . , xn ∼N (μ + ν, σ2), avec π(μ, ν, σ) ∝1/σ.
a. Montrer que la distribution a posteriori n’est pas d´eﬁnie pour tout n.
b. ´Etendre ce r´esultat aux mod`eles surparam´etris´es avec des lois a priori im-
propres.
Les exercices suivants (3.45-3.51) traitent du paradoxe de marginalisation `a tra-
vers plusieurs exemples et d´emontrent que celui-ci ne peut avoir lieu qu’avec
des lois a priori impropres. Dawid et al. (1973), Stone (1976) et Jaynes (1980)
proposent des solutions partielles `a ce paradoxe. Notons qu’une explication fon-
damentale est que la loi a priori impropre π(dη, dθ) = π(η) dη dθ ne correspond
pas `a la loi pseudo-marginale π(dη) = π(η) dη.
3.45 *(Dawid et al., 1973) Soient n variables al´eatoires x1, . . . , xn, telles que les
ξ premi`eres d’entre elles suivent la loi E xp(η) et les n −ξ restantes suivent
E xp(cη), o`u c est une constante connue et ξ prend ses valeurs dans {1, 2, . . . ,
n −1}.
a. Donner la forme de la distribution a posteriori de ξ lorsque π(ξ, η) = π(ξ) et
montrer qu’elle ne d´epend que de z = (z2, . . . , zn), avec zi = xi/x1.
b. Montrer que la distribution de z, f(z|ξ), ne d´epend que de ξ.
c. Montrer que la loi a posteriori π(ξ|x) ne peut pas s’´ecrire comme une loi a
posteriori pour z ∼f(z|ξ), quelle que soit π(ξ), bien qu’elle ne d´epende que
de z. Comment expliquez-vous ceci ?
d. Montrer que ce paradoxe n’a pas lieu lorsque π(ξ, η) = π(ξ)η−1.
3.46 *(Dawid et al., 1973) Soient u1, u2, s2 tels que
u1 ∼N (μ1, σ2),
u2 ∼N (μ2, σ2),
s2 ∼σ2χ2
ν/ν,
et ζ = (μ1 −μ2)/(σ
√
2) est le param`etre d’int´erˆet. La loi a priori est
π(μ1, μ2, σ) = 1
σ .
a. Montrer que la loi a posteriori π(ζ|x) ne d´epend que de
z = u1 −u2
s
√
2
.

164
3 Des informations a priori aux lois a priori
b. Montrer que la distribution de z ne d´epend que de ζ, mais que pourtant
un paradoxe apparaˆıt ; il est impossible de calculer π(ζ|x) `a partir de f(z|ζ),
mˆeme si π(ζ|x) ne d´epend que de z.
c. Montrer que ce paradoxe disparaˆıt lorsque
π(μ1, μ2, σ) = 1
σ2 .
3.47 *(Dawid et al., 1973) Soient
x11, . . . , x1n ∼N (μ1, σ2),
x21, . . . , x2n ∼N (μ2, σ2),
2n variables al´eatoires ind´ependantes.
a. Le param`etre d’int´erˆet est ξ = (ξ1, ξ2) = (μ1/σ, μ2/σ) et la loi a priori est
π(μ1, μ2, σ) = σ−p.
Montrer que π(ξ|x) ne d´epend que de z = (z1, z2) = (¯x1/s, ¯x2/s) et que la loi
de z ne d´epend que de ξ. Calculer la valeur de p qui ´evite ce paradoxe.
b. Le param`etre d’int´erˆet est d´esormais ζ = ξ1. Montrer que π(ζ|x) ne d´epend
que de z1 et que f(z1|ξ) ne d´epend que de ζ. Donner la valeur de p qui ´evite
ce paradoxe.
c. Mˆemes questions pour σ ∼Pa(α, σ0).
3.48 *(Dawid et al., 1973) Soient (x1, x2) distribu´es selon :
f(x1, x2|θ) ∝
Z +∞
0
t2n−1 exp
»
−1
2
˘
t2 + n(x1t −ζ)2 + n(x2t −ξ)2¯–
dt,
avec θ = (ζ, ξ). Justiﬁer cette distribution en recourant au cadre de l’Exercice
3.47. La loi a priori sur θ est π(θ) = 1.
a. Montrer que π(ζ|x) ne d´epend que de x1 et que f(x1|θ) ne d´epend que de ζ,
mais que π(ζ|x) ne peut pas ˆetre d´eduite de x1 ∼f(x1|ζ).
b. Montrer que, pour toute loi π(θ) telle que π(ζ|x) ne d´epend que de x1, π(ζ|x)
n’est pas proportionnelle `a π(ζ)f(x1|ζ).
3.49 *(Jaynes, 1980) Dans le cadre de l’Exercice 3.45, prendre π(ξ, η) = π(ξ)π(η).
a. Montrer que
π(ξ|x) ∝π(ξ)c−ξ
Z +∞
0
η−n exp(−ηx1Q)π(η)dη,
o`u
Q =
ξ
X
i=1
zi + c
n
X
ξ+1
zi.
b. D´eterminer si le paradoxe a lieu pour π(η) = η−k (k > −n −1).
c. Mˆeme question pour η ∼Pa(α, η0).
3.50 *(Jaynes, 1980) Soit
f(y, z|η, ζ) ∝ζzηy(1 −η)z−y
y!(z −y)!
(0 ≤y ≤z),
avec 0 < η < 1.

3.7 Exercices
165
a. Montrer que f(z|η, ζ) ne d´epend que de ζ et calculer la distribution f(y,
z|η, ζ) `a partir de f(y|z, η, ζ).
b. Montrer que le paradoxe n’a lieu pour aucun π(η).
3.51 *(Dawid et al., 1973) Soient x = (y, z) de loi f(x|θ) et θ = (η, ξ). Supposons
que π(ξ|x) ne d´epende que de z et f(z|θ) que de ξ.
a. Montrer que le paradoxe est ´evit´e lorsque π(θ) est une loi propre.
b. G´en´eraliser au cas o`u
R
π(η, ξ) dη = π(ξ) et d´eterminer si le paradoxe est
ainsi ´evit´e.
Section 3.5.3
3.52 Reprenant l’Exemple 3.32 et pour x ∼B(n, p), trouver une loi a priori sur n
telle que π(n|x) soit N eg(x,p).
3.53 * Reprenant l’Exemple 3.34,
a. Montrer que l’estimateur de Bayes de η = ||θ||2 sous un coˆut quadratique
pour π(η) = 1/√η et x ∼N (θ, Ip) peut s’´ecrire
δπ(x) =
1F1(3/2; p/2; ||x||2/2)
1F1(1/2; p/2; ||x||2/2),
o`u
1F1 est la fonction conﬂuente hyperg´eom´etrique.
b. D´eduire du d´eveloppement limit´e de 1F1 le d´eveloppement asymptotique de
δπ (pour ||x||2 →+∞).
c. Comparer δπ avec δ0 tel que δ0(x) = ||x||2 −p.
d. ´Etudier le comportement de ces estimateurs sous un coˆut quadratique
pond´er´e
L(δ, θ) = (||θ||2 −δ)2
2||θ||2 + p
et conclure.
3.54 Trouver une transformation de θ, η = g(θ), telle que l’information de Fisher
I(η) soit constante pour :
(i) une loi de Poisson, P(θ) ;
(ii) une loi gamma, G (α, θ), avec α = 1, 2, 3 ; et
(iii) une loi binomiale, B(n, θ).
3.55 En supposant que π(θ) = 1 soit une loi a priori acceptable pour des param`etres
r´eels, montrer que cette loi g´en´erale correspond `a π(σ) = 1/σ si σ ∈R+ et `a
π(ϱ) = 1/ϱ(1 −ϱ) si ϱ ∈[0, 1], pour les transformations naturelles θ = log(σ) et
θ = log(ϱ/(1 −ϱ)).
3.56 *(Saxena et Alam, 1982) Dans un cadre identique `a celui de l’Exercice 3.53 :
a. Donner l’estimateur du maximum de vraisemblance de ||θ||2 lorsque x ∼
N (θ, Ip).
b. Montrer que l’estimateur du maximum de vraisemblance obtenu `a partir de
z = ||x||2 v´eriﬁe l’´equation implicite
1 =
z
√
λz
Ip/2(
√
λz)
I(p−1)/2(
√
λz)
(z > p),
o`u Iν est la fonction modiﬁ´ee de Bessel (voir Abramowitz et Stegun, 1964
, ou l’Exercice 4.36).

166
3 Des informations a priori aux lois a priori
c. Utiliser un d´eveloppement limit´e de Iν pour montrer que l’estimateur du
maximum de vraisemblance ˆλ v´eriﬁe
ˆλ(z) = z −p + 0.5 + O(1/z).
d. Montrer que ˆλ est domin´e par (z −p)+ sous un coˆut quadratique.
3.57 L’information de Fisher n’est pas d´eﬁnie lorsque le support de f(x|θ) d´epend
de θ. Consid´erer les cas suivants :
(i) x ∼U[−θ,θ];
(ii) x ∼Pa(α, θ);
(iii) f(x|θ) ∝e−(x−θ)2/2I[0,θ](x).
3.58 Montrer qu’une approximation du second ordre des coˆuts d’entropie et de
Hellinger introduits dans la Section 2.5.4 est (θ −δ)2I(θ). Ce r´esultat est-il une
justiﬁcation suppl´ementaire pour utiliser la loi a priori de Jeﬀreys ?
3.59 Soit x ∼P(θ).
a. D´eterminer l’a priori de Jeﬀreys πJ et ´evaluer si l’a priori invariant par trans-
formation d’´echelle π0(θ) = 1/θ est pr´ef´erable.
b. Donner la loi a priori d’entropie maximale pour la mesure de r´ef´erence πJ
0 et
les contraintes Eπ[θ] = 1, varπ(θ) = 1. Que se passe-t-il si on remplace π par
π0 ?
c. En fait, x est le nombre de voitures traversant une voie ferr´ee pendant une
dur´ee T. Montrer que x est distribu´e selon une loi de Poisson P(θ) si la dur´ee
entre deux arriv´ees est distribu´ee selon E xp(λ); noter que θ = λT.
d. Justiﬁer l’utilisation de π0 `a l’aide de la construction de la loi Poisson ´etablie
ci-dessus.
Section 3.5.4
3.60 Pour x ∼N (θ, σ2), donner la loi a priori de r´ef´erence pour les ordres {θ, σ}
et {σ, θ}.
3.61 Soient θ ∈[a, b] et π(θ) ∝1/θ.
a. D´eterminer la constante de normalisation de π.
b. Calculer pi = π(i ≤θ < i + 1) pour a ≤i ≤b −1.
c. En d´eduire la limite de pi lorsque a tend vers 0 ou b tend vers ∞. [Note :
Cet exercice est reli´e au probl`eme des entr´ees de tableau, c’est-`a-dire au fait
que dans beaucoup de tableaux num´eriques la fr´equence du premier chiﬀre
signiﬁcatif est log10(1 + i−1) (1 ≤i ≤9). Voir Berger 1985b, p. 86, pour une
pr´esentation d´etaill´ee.]
3.62 *(Kass et Wasserman, 1996)
Montrer que l’a priori de r´ef´erence obtenu `a
partir de l’a priori de Jeﬀreys pour θ1 ﬁx´e, π(θ2|θ1), et de l’a priori de Jeﬀreys
pour la loi marginale (3.14) peut aussi s’´ecrire
π(θ1, θ2) ∝π(θ2|θ1) exp
jZ
π(θ2|θ1) log
p
|I|/|I22|dθ2
ﬀ
,
o`u I est l’information de Fisher et I22 est la composante de I associ´ee `a θ2.
Section 3.6
3.63 *(Berger, 1990) Soit Γϵ,Q la classe de lois d´eﬁnie en Section 3.6 (iii), avec
Q = { distributions unimodales sym´etriques en θ0}.

3.7 Exercices
167
Lorsque π varie dans Q, la loi marginale
m(π) =
Z
f(x|θ)π(θ) dθ
varie entre des bornes sup´erieure et inf´erieure mU et mL.
a. Montrer que toute distribution unimodale sym´etrique en θ0 peut s’´ecrire
comme un m´elange de distributions uniformes sym´etrique en θ0, U[θ0−a,θ0+a].
b. En d´eduire que
mU =
sup
π∈Γϵ,Q
m(π) = (1 −ϵ)m(π0) + ϵ sup
z>0
Z θ0+z
θ0−z
f(x|θ)
2z
dθ.
c. Si la quantit´e d’int´erˆet est le facteur de Bayes,
B(π) =
f(x|θ0)
R
θ̸=θ0 f(x|θ)π1(θ) dθ ,
o`u π1 est la loi π conditionn´ee par θ ̸= θ0 et π0 est la masse de Dirac en θ0,
montrer que
BL =
inf
π∈Γϵ,Q B(π) =
f(x|θ)
ϵ supz
R θ0+z
θ0−z (f(x|θ)/2z) dθ
.
3.64 Soit la classe des lois a priori
Γ = {N (μ, τ 2), 0 ≤μ ≤2, 2 ≤τ 2 ≤4}
avec x ∼N (θ, 1).
a. ´Etudier les variations de Eπ[θ|x] et varπ(θ|x) pour π ∈Γ.
b. ´Etudier ϱ(π, δπ′) pour π, π′ ∈Γ et δπ(x) = Eπ[θ|x], L(θ, δ) = (θ −δ)2 aﬁn
de d´eterminer l’estimateur minimax pour la classe Γ.
3.65 *(Walley, 1991) Supposons que, au lieu de d´eﬁnir une loi a priori π sur la
σ-alg`ebre de Θ, on d´eﬁnisse des bornes sup´erieure et inf´erieure pour π, not´ees
π et π. Pour tout ´ev´enement A, π(A) repr´esente la somme maximale qu’on est
prˆet `a parier pour obtenir une unit´e mon´etaire si A a lieu. De mˆeme, 1 −π(A)
est la somme minimale qu’on est prˆet `a parier que A n’ait pas lieu.
a. Montrer que, si la loi a priori π est connue, π = π = π.
b. Montrer qu’on doit imposer π(A) + π(Ac) ≤1 ≤π(A) + π(Ac) pour tout A
pour ´eviter une perte certaine.
c. Si π(A∪B) est la somme maximale qu’on est prˆet `a parier sur A∪B, montrer
que π(A ∪B) ≥π(A) + π(B) et, de mˆeme, que π(A ∪B) ≤π(A) + π(B).
3.66 *(Suite de l’Exercice 3.65) Si on consid`ere plutˆot des paris, c’est-`a-dire des
fonctions X `a valeurs r´eelles d´eﬁnies sur un espace mesurable Ω correspondant
`a des r´ecompenses variables, d´ependant de l’´etat d’incertitude ω ∈Ω, il est
alors aussi possible de d´eﬁnir des pr´evisions sup´erieure et inf´erieure, P et P, o`u
P(X) est le prix maximal acceptable pour la r´ecompense X et P(X) le prix de
vente minimal.
a. Un pari est d´esirable s’il est possible que quelqu’un le contracte. Justiﬁer les
axiomes suivants :
(A) Si supω X(ω) < 0, alors X n’est pas d´esirable ;
(B) Si infω X(ω) > 0, alors X est d´esirable ;
(C) Si X est d´esirable et λ > 0, alors λX est d´esirable ; et
(D) Si X et Y sont tous les deux d´esirables, alors X + Y est d´esirable.

168
3 Des informations a priori aux lois a priori
b. Justiﬁer les axiomes de coh´erence suivants sur P et montrer qu’ils corres-
pondent aux axiomes (B), (C) et (D) ci-dessus :
(P1) P(X) ≥infω X(ω) ;
(P2) P(λX) = λP(X) ; et
(P3) P(X + Y ) ≥P(X) + P(Y ).
c. Pour une pr´evision inf´erieure P donn´ee, la pr´evision sup´erieure conjugu´ee est
d´eﬁnie par P(X) = −P(−X). Montrer que, si P est coh´erente et P est la
conjugu´ee de P, celles-ci satisfont
inf
ω X(ω) ≤P(X) ≤P(X) ≤sup
ω X(ω) ,
et en d´eduire que P est une fonction convexe.
d. Montrer que, lorsque P est autoconjugu´ee, alors P(X) = P(X) et v´eriﬁe les
contraintes de lin´earit´e suivantes :
P(X + Y ) = P(X) + P)Y )
et
P(λX) = λP(X),
λ ∈R.
3.67 *(Suite de l’Exercice 3.66) On dit qu’une pr´evision inf´erieure P ´evite une
perte certaine si, pour tout n ≥1 et tout ensemble de paris X1, . . . , Xn,
sup
ω
n
X
i=1
Xi −P(Xi) ≥0.
a. Montrer que P ´evite une perte certaine si et seulement si
sup
ω
n
X
i=1
λi(Xi −P(Xi)) ≥0
pour tout n ≥1, tout ensemble de paris X1, . . . , Xn et tout λi ≥0.
b. Sous l’hypoth`ese que P ´evite une perte certaine, montrer que, pour tout
λ ≥0,
P(λX) ≤λP(X),
P(λX) ≥λP(X),
P(λX + (1 −λ)Y ) ≤λP(X) + (1 −λ)P(Y ).
o`u P est la pr´evision sup´erieure conjugu´ee.
c. Une pr´evision inf´erieure est coh´erente si
sup
ω
" n
X
i=1
(Xi −P(Xi)) −m(X0 −P(X0))
#
≥0
pour tout m, n et tout ensemble de paris X0, . . . , Xn. Montrer que P est
coh´erente si et seulement si elle satisfait les axiomes (P1), (P2), et (P3).
d. Montrer que la lin´earit´e est ´equivalente `a la coh´erence plus l’autoconjugaison,
si on d´eﬁnit la lin´earit´e comme
sup
ω
( n
X
i=1
Xi(ω) −
m
X
j=1
Yi(ω)
)
≥
n
X
i=1
P(Xi) −
m
X
j=1
P(Yi)
pour tout m, n et tout ensemble de paris X1, . . . , Xn, Y1, . . . , Ym.

3.8 Notes
169
e. Montrer que P est une pr´evision lin´eaire si et seulement si P(X + Y ) =
P(X) + P(Y ) et P(X) ≥infω X(ω). En d´eduire que P est une pr´evision
lin´eaire si et seulement si elle satisfait la condition de lin´earit´e, (P2), et
(P4) si X ≥0, alors P(X) ≥0 ; et
(P5) P(1) = 1.
Note 3.8.3
3.68 Appliquer la d´ecomposition de Dalal et Hall (1983) aux cas suivants :
(i) x ∼N (θ, Ip), θ ∼Tp(m, 0, τ 2) ; et
(ii) x ∼N eg(N, p), p/(1 −p) ∼G (1/2, 1/2).
3.69 *Trouver les mesures naturelles νm de Dalal et Hall (1983) pour les lois du
Tableau 3.6.
3.8 Notes
3.8.1 Construction axiomatique de lois a priori
Pour d´emontrer l’existence d’une loi a priori, nous avons besoin, `a l’instar
de la fonction d’utilit´e (voir la Section 2.2), de nous fonder sur un ordre des
´ev´enements (plutˆot que des r´ecompenses). Supposons donc que le d´ecideur, le
client ou le statisticien soient `a mˆeme de d´eterminer une relation d’ordre sur
une σ-alg`ebre B(Θ). Cette relation, not´ee ⪯, est telle que B ≺A signiﬁe que A
est plus vraisemblable que B, B ⪯A, que A est au moins aussi vraisemblable
que B, et B ∼A, que A et B sont aussi vraisemblables l’un que l’autre. Bien
entendu, s’il existe une distribution P de probabilit´e sur (Θ, B(Θ)), P induit
directement une relation d’ordre sur B(Θ). Nous consid´erons ci-dessous des hy-
poth`eses sous lesquelles la r´eciproque peut ˆetre ´etablie. Une premi`ere hypoth`ese
est que la relation d’ordre est totale :
(A1) Pour tout ensemble mesurable A et B, une et seulement une des relations
suivantes est satisfaite :
A ≺B,
B ≺A
ou
A ∼B.
Une autre hypoth`ese est :
(A2) Si A1, A2, B1, B2 sont quatre ensembles mesurables v´eriﬁant A1 ∩A2 =
B1 ∩B2 = ∅et Ai ⪯Bi (i = 1, 2), alors A1 ∪A2 ⪯B1 ∪B2. De plus, si
A1 ≺B1, A1 ∪A2 ≺B1 ∪B2.
Cette hypoth`ese naturelle entraˆıne la transitivit´e de la relation d’ordre. L’hy-
poth`ese suivante empˆeche l’existence d’ensembles mesurables de vraisemblance
n´egative (donc moins vraisemblables que l’ensemble vide) :
(A3) Pour tout ´ev´enement A, ∅⪯A et ∅≺Θ.
La condition suppl´ementaire ∅≺Θ ´evite le cas trivial o`u tous les ´ev´enements
sont ´equivalents. Il est aussi n´ecessaire de permettre la comparaison d’une suite
inﬁnie d’´ev´enements.
(A4) Si A1 ⊃A2 ⊃· · · est une suite d´ecroissante d’ensembles mesurables et B
est un ´ev´enement donn´e tel que B ⪯Ai pour tout i, alors
B ⪯
+∞
\
i=1
Ai.

170
3 Des informations a priori aux lois a priori
Cette hypoth`ese assure en quelque sorte la continuit´e de l’ordre des pr´ef´erences
et est reli´ee `a la propri´et´e de σ-additivit´e des mesures de probabilit´e. Cependant,
les axiomes (A1)–(A4) sont insuﬃsants pour obtenir l’existence d’une distribu-
tion de probabilit´e `a partir de l’ordre des vraisemblances. En fait, passer d’une
´echelle de comparaison qualitative `a une comparaison quantitative requiert une
derni`ere hypoth`ese.
(A5) Il existe une variable al´eatoire X sur (Θ, B(Θ)) de distribution uniforme
sur [0, 1], c’est-`a-dire telle que, pour tout I1, I2, intervalles de [0, 1],
{X ∈I1} ⪯{X ∈I2}
si et seulement si
λ(I1) ≤λ(I2),
o`u λ est la mesure de Lebesgue.
Cette hypoth`ese suppl´ementaire permet alors d’´etablir le r´esultat d’existence
suivant (voir DeGroot, 1970, pour une d´emonstration).
Th´eor`eme 3.40. Sous les axiomes (A1)–(A5), il existe une distribution P telle
que P(A) ≤P(B) si et seulement si A ⪯B.
Compar´es `a l’obtention d’une fonction d’utilit´e dans le Chapitre 2, les d´eve-
loppements pr´ec´edents sur les fondations axiomatiques de la loi a priori sont
plus limit´es. Une premi`ere raison est que les hypoth`eses ci-dessus et le cadre
formel correspondant sont plus diﬃciles `a justiﬁer. En fait, le fait qu’un sta-
tisticien soit `a mˆeme d’exprimer la vraisemblance d’un ´ev´enement signiﬁe qu’il
a, consciemment ou pas, construit un mod`ele probabiliste sous-jacent et, donc,
que la construction pr´ec´edente est en quelque sorte tautologique. L’hypoth`ese
(A5) est particuli`erement forte et peut rarement ˆetre v´eriﬁ´ee en pratique. No-
tez cependant que, jusqu’`a un certain point, la mˆeme critique peut ˆetre faite `a
l’´egard de la construction de la fonction d’utilit´e.
Une seconde raison de cette limitation est plus terre `a terre. Selon le Th´eor`eme
3.40, le d´ecideur peut construire une loi a priori `a partir de son ordre des vrai-
semblances. Cependant, il est tr`es vraisemblable, surtout si Θ n’est pas ﬁni, que
cet ordre sera grossier, c’est-`a-dire que la σ-alg`ebre B(Θ) correspondante ne
sera pas la σ-alg`ebre bor´elienne usuelle sur Θ, empˆechant par l`a mˆeme l’utili-
sation des distributions classiques sur θ. Cependant, il est rassurant de pouvoir
justiﬁer l’utilisation d’une loi a priori par d’autres raisonnements que ceux de
l’approche fr´equentiste, supposant la r´ep´etabilit´e des exp´eriences, mˆeme si cela
est d’un int´erˆet limit´e en pratique.
3.8.2 ´Echangeabilit´e et lois a priori conjugu´ees
Bernardo et Smith (1994, Section 4.3) justiﬁent partiellement l’existence de lois
a priori par la notion d’´echangeabilit´e :
D´eﬁnition 3.41. Une suite (x1, . . . , xn) de variables al´eatoires est ﬁniment
´echangeable si la distribution jointe p(x1, . . . , xn) est invariante par toute per-
mutation d’indices des variables al´eatoires, c’est-`a-dire
p(x1, . . . , xn) = p(x(1), . . . , x(n)) ,

3.8 Notes
171
Une suite inﬁnie (xn)n est inﬁniment ´echangeable si toute suite extraite ﬁnie
est ﬁniment ´echangeable.
Bien que l’hypoth`ese d’´echangeabilit´e ne soit pas toujours raisonnable (voir
Bernardo et Smith, 1994, Section 4.2.2, pour des exemples), il existe beaucoup
de situations pour lesquelles l’ordre dans lequel les donn´ees ont ´et´e obtenues n’a
eﬀectivement pas d’importance. Les cons´equences de cette hypoth`ese d’inﬁnie
´echangeabilit´e sur l’existence de lois a priori sont de plus tout `a fait int´eressantes.
Par exemple, si (xn)n est une suite inﬁnie de variables al´eatoires prenant valeurs
dans {0, 1}, de Finetti (1972) a d´emontr´e qu’il existe une mesure de probabilit´e
π(θ) telle que, pour tout n, la loi jointe de (x1, . . . , xn) puisse s’´ecrire
p(x1, . . . , xn) =
Z 1
0
n
Y
i=1
θxi(1 −θ)1−xidπ(θ),
c’est-`a-dire que, conditionnellement `a θ, les xi sont des variables al´eatoires
i.i.d. de Bernoulli B(θ). Comme l’ont montr´e Bernardo et Smith (1994, Sec-
tion 4.3.2), cette propri´et´e s’´etend aux variables al´eatoires prenant leurs valeurs
dans un ensemble ﬁni, disons {1, 2, . . . , k}, celles-ci ´etant alors multinomiales,
conditionnellement au vecteur θ = (θ1, . . . , θk).
Dans le cas g´en´eral o`u les xi sont `a valeurs r´eelles et inﬁniment ´echangeables,
une repr´esentation int´eressante est aussi disponible, de la forme
p(x1, . . . , xn) =
Z
n
Y
i=1
F(xi)dπ(F),
o`u F est une fonction de r´epartition et π est une mesure de probabilit´e sur
l’espace des fonctions de distribution (voir Chow et Teicher, 1988, pour une for-
mulation plus pr´ecise de ce r´esultat, dont les aspects les plus subtils touchant `a
la th´eorie de la mesure d´epassent le cadre de ce livre). Cette repr´esentation est
intrins`equement non param´etrique (voir la Note 1.8.2), mais Bernardo et Smith
(1994, Section 4.6) traitent d’autres notions d’´echangeabilit´e qui permettent de
revenir `a un cadre param´etrique.
3.8.3 Approximation par des m´elanges continus de lois a priori conjugu´ees
Soit une densit´e prise dans une famille exponentielle et ´ecrite sous la forme
f(x|θ) = exp{x · τ(θ) −γ(θ)},
avec E[x] = θ. (Cette param´etrisation est dite param´etrisation en moyenne ; voir
Brown (1986b, Chapitre 3.) Une suite de lois conjugu´ees naturelles est donn´ee
par (m ∈N)
hm(θ|s) = exp{s · τ(θ) −mγ(θ)}cm(s),
(3.24)
o`u cm(s) est la constante de normalisation. Rappelons que la loi a priori (3.24)
correspond `a l’actualisation d’une loi a priori plate sur θ pour m observations
ﬁctives (ou virtuelles) ˜x1, . . . , ˜xm de f(x|θ), telles que s = Pm
i=1 ˜xi.
En fait, la fonction (3.24) peut aussi ˆetre consid´er´ee comme la densit´e de s pour
une mesure dνm appel´ee mesure naturelle. Si Sm est l’espace dans lequel s varie,
et dQm est une mesure de probabilit´e sur Sm,

172
3 Des informations a priori aux lois a priori
vm(θ) =
Z
Sm
hm(θ|s) dQm(s)
(3.25)
est un m´elange (continu) de lois a priori conjugu´ees. Pour une loi a priori π sur
Θ, on d´eﬁnit
dQm(s) =
π(s/m) dνm(s)
R
Sm π(t/m) dνm(t),
ce qui donne une approximation de π, comme le montre le lemme suivant.
Th´eor`eme 3.42. Si νm est absolument continue par rapport `a la mesure de
Lebesgue ou par rapport `a la mesure de comptage sur Sm, et admet pour densit´e
fm(s), et si fm(s) converge uniform´ement sur Sm vers 1 lorsque m tend vers
+∞, alors
vm(θ) −→π(θ)
point par point, et globalement pour la norme L1.
Tab. 3.6. Approximation d’une loi a priori par m´elange de lois conjugu´ees. (Source :
Dalal et Hall, 1983.)
Distrib.
τ(θ), γ(θ)
cm(s)
hm(θ|s)
f(x, θ)
Normal
N (θ, 1)
θ, θ2/2
√mϕ(s/√m)
θ ∼N
` s
m, 1
m
´
Gamma
G
` β
θ , θ
´
−β
θ , −β log
` β
θ
´
smβ−1
β Γ (mβ−1)
1
θ ∼G (sβ, mβ −1)
Poisson
P(θ)
log θ, θ
ms+1/Γ(s + 1) θ ∼G (m, s + 1)
Bernoulli
B(1, θ)
log
θ
1−θ , log
1
1−θ
(m+1)!
s!(m−s)!
θ ∼Be(s + 1, m −s + 1)
Neg. bin.
N eg (r,
log
θ
r+θ,
rmr(mr+s−1)!
rs!(mr−2)!
r
r+θ ∼Be(mr −1, s + 1)
r
‹
r + θ
´
r log(r + θ)
De plus, cette approximation reste valide a posteriori, au sens de la distance de
la variation totale, d´eﬁnie comme
||π −˜π||T V = sup
A
|π(A) −˜π(A)| ,
et donc toujours inf´erieure `a 1. Il s’agit donc en quelque sorte d’un r´esultat
d’approximation plus faible, relativement `a la norme L1 du Th´eor`eme 3.42.
Th´eor`eme 3.43. Si pm, la loi marginale de x sous hm, est ﬁnie et si π(θ) et
π(θ|x) sont r´eguli`eres, vm(θ|x) converge vers π(θ|x), point par point et au sens
de la variation totale.

3.8 Notes
173
La loi a posteriori approch´ee est, pour n observations et t = Pn
i=1 xi,
vm(θ|n, t) =
R
Sm hm+n(θ|s + t)
cm(s)
cm+n(s + t)π(s/m) dνm(s)
R
Sm
cm(s′)
cm+n(s′ + t)π(s′/m) dνm(s′)
et le Tableau 3.6 donne les valeurs de τ, γ et cm pour quelques lois usuelles.
Compar´es aux r´esultats de Diaconis et Ylvisaker (1985), les Th´eor`emes 3.42 et
3.43 sont eﬀectivement plus g´en´eraux et assurent, de plus, la convergence des
lois a posteriori. L’inconv´enient cependant est que cette approche ne conserve
pas l’avantage principal des lois a priori conjugu´ees, `a savoir leur simplicit´e.
Les m´ethodes de simulation pr´esent´ees dans le Chapitre 6 sont donc n´ecessaires
pour le calcul de ces estimateurs de Bayes.
3.8.4 Correction de Bartlett
Dans la th´eorie asymptotique standard, la statistique du rapport de vraisem-
blance
ϖn = 2
( n
X
i=1
f(xi|ˆθ) −
n
X
i=1
f(xi|ˆθ0)
)
,
est distribu´ee approximativement selon une loi du χ2
k, o`u ˆθ0 et ˆθ sont les estima-
teurs du maximum de vraisemblance contraint et non contraint, et o`u k est le
nombre de contraintes (Gouri´eroux et Monfort, 1996). Bartlett (1937) remarque
qu’un meilleur ajustement `a une loi du χ2
k est obtenu lorsque ϖn est remplac´e
par kϖn/Eθ[ϖn], au sens o`u (Lawley, 1956)
Pθ
„kϖn
ˆE
≤t
«
= χ2
k(t) + O
`
n−2´
,
o`u ˆE est un estimateur appropri´e de Eθ[ϖn] et χ2
k(t) est la fonction de r´epartition
d’un χ2
k. La correction de Bartlett permet ainsi de r´eduire l’erreur d’approxima-
tion (par un χ2
k) de O
`
n−1´
`a O
`
n−2´
.
Comme l’ont not´e DiCiccio et Stern (1994), si θ = (ψ, ϕ) et si la contrainte sur
θ est que ψ soit ﬁx´e, le rapport de vraisemblance d´epend de ψ, ϖn = ϖn(ψ).
Bickel et Ghosh (1990) ont ´etabli que la correction de Bartlett s’´etend `a la loi a
posteriori de ϖn(ψ), c’est-`a-dire qu’il existe une correction de ϖn(ψ) telle que
P
„
ϖn(ψ) ×
„
1 −AB
k
«
≤t
˛˛˛˛ x, . . . , xn
«
= χ2
k(t) + O
`
n−2´
,
o`u AB se d´eduit d’un d´eveloppement de l’esp´erance a posteriori
E[ϖn(ψ)|x1, . . . , xn] = k + AB + O
“
n−3/2”
et est d’ordre O
`
n−1´
. DiCiccio et Stern (1994) ont aussi montr´e que cette
approximation du second ordre par un χ2
k reste valide pour une statistique
du rapport de vraisemblance ajust´ee, ϖn(ψ) + ωn(ψ), o`u ωn(ψ) est O(1). Par
exemple, Kass et Steﬀey (1989) utilisent

174
3 Des informations a priori aux lois a priori
ωn(ψ) = −1
2 log
 
det ℓϕϕ(ˆθ(ψ))
det ℓϕϕ(ˆθ)
!
+ log
 
π(ˆθ(ψ))
π(ˆθ)
!
,
o`u ˆθ(ψ) et ˆθ sont les estimateurs du maximum de vraisemblance contraint et non
contraint, et ℓϕϕ est la matrice des d´eriv´ees secondes de la log-vraisemblance
pour le param`etre de nuisance ϕ. DiCiccio et Stern (1994) ´etablissent la correc-
tion correspondante AB, tandis que DiCiccio et Stern (1993) donnent le facteur
de correction de la statistique du rapport a posteriori
κπ = 2
n
log π( ˆψ|x) −log π(ψ|x)
o
.
o`u ˆψ est l’estimateur MAP marginal de ψ.
Exemple 3.44. (DiCiccio et Stern, 1993) Soit le mod`ele de r´egression normale
yi ∼N
 k
X
j=1
uijβj, σ2
!
,
i = 1, . . . , n,
associ´e `a une loi a priori impropre plate sur (β, η), pour η = log σ. Si le param`etre
d’int´erˆet est η (ou σ2), alors
κπ = (n −k + 2)
»
nϱ
n −k + 2 −log
nϱ
n −k + 2 −1
–
,
o`u ϱ = ˆσ2/σ2 et le terme de correction ℵπ, tel que (1 + ℵπ)−1κπ soit χ2
p `a
un terme O(n−2) pr`es, est ℵπ(η) = n−1/3. Lorsque ξ = (β1, . . . , βp) est le
param`etre d’int´erˆet, ℵπ(ξ) = (1 + p/2)n−1.
∥

4
Estimation bay´esienne ponctuelle
“There is always something new from you,’ Perrin growled. ‘Can’t
you tell us what to expect once in a while, instead of explaining after
it happens ?”
Robert Jordan, The Dragon Reborn.
4.1 Inf´erence bay´esienne
4.1.1 Introduction
Quand la loi a priori π(θ) est disponible, la loi a posteriori π(θ|x) peut
ˆetre construite formellement `a partir de l’observation x, de distribution f(x|θ).
Cette loi de mise `a jour est alors un r´esum´e complet de l’information disponible
sur le param`etre θ, r´esum´e qui int`egre simultan´ement l’information a priori et
l’information apport´ee par l’observation x. (´Evidemment, ceci reste vrai pour
un ´echantillon x1, . . . , xn, mais on peut revenir g´en´eralement `a la situation
pr´ec´edente grˆace `a une statistique exhaustive.) La version bay´esienne du prin-
cipe de vraisemblance implique par cons´equent que l’inf´erence sur θ d´epend
enti`erement de la loi a posteriori π(θ|x). Mˆeme si θ n’est pas n´ecessairement
con¸cue comme variable al´eatoire, la loi π(θ|x) peut ˆetre utilis´ee comme une
distribution de probabilit´e habituelle pour d´ecrire les propri´et´es de θ. Les
indicateurs r´esumant π(θ|x) tels que moyenne, mode, variance, m´ediane a
posteriori, sont par exemple des estimateurs potentiels. Notamment, lorsque
la quantit´e d’int´erˆet est h(θ), un estimateur possible de h(θ) est la moyenne
a posteriori Eπ[h(θ)|x]. (Comme il a ´et´e dit dans la Section 3.5, quand la loi

176
4 Estimation bay´esienne ponctuelle
π est une loi non informative, quelques diﬃcult´es de marginalisation peuvent
se produire et il est parfois n´ecessaire de construire une nouvelle loi a priori
de r´ef´erence pour le param`etre d’int´erˆet h(θ).)
4.1.2 Estimateur MAP
S’il faut faire un choix entre les quantit´es a posteriori donn´ees ci-dessus,
ce choix est impossible sans crit`ere de coˆut, de sorte `a d´eﬁnir correctement
la notion de “meilleur estimateur”. N´eanmoins, un estimateur de r´ef´erence de
θ fond´e sur π(θ|x) est l’estimateur du maximum a posteriori (MAP), d´eﬁni
comme le mode a posteriori. Notons que l’estimateur MAP maximise aussi
ℓ(θ|x)π(θ) et, par cons´equent, ne requiert pas le calcul de la loi marginale.
Cet estimateur est associ´e au coˆut 0 −1, comme on l’a vu dans la Section
2.5.3, dans le cas particulier θ ∈{0, 1}. Dans le cas continu, puisque, pour
tout δ ∈Θ,

Θ
Iδ̸=θπ(θ|x)dθ = 1 ,
la fonction de coˆut 0−1 peut ˆetre remplac´ee par une suite de coˆuts, Lε(d, θ) =
I||θ−d||>ε, et l’estimateur MAP est alors la limite des estimateurs de Bayes
associ´es `a Lε, quand ε tend vers 0. Il peut aussi ˆetre associ´e `a la suite de
fonctions de coˆut Lp, Lp(d, θ) = ||θ −d||p, quand p tend vers l’inﬁni.
Cet estimateur naturel peut s’exprimer comme un estimateur du maximum
de vraisemblance p´enalis´ee au sens classique (Akaike, 1978, 1983). Notons que
les propri´et´es d’optimalit´e asymptotique pour un estimateur de maximum de
vraisemblance habituel (coh´erence, eﬃcacit´e) sont maintenues pour ces exten-
sions bay´esiennes, sous certaines conditions de r´egularit´e sur f et π (voir la
Note 1.8.4, et Ibragimov et Has’minskii, 1981). Cette extension des propri´et´es
asymptotiques de l’estimateur du maximum de vraisemblance est raisonnable
intuitivement, car, lorsque la taille de l’´echantillon tend vers l’inﬁni, l’infor-
mation contenue dans cet ´echantillon devient pr´edominante par rapport `a
l’information ﬁxe apport´ee par la loi a priori π. Cependant, les estimateurs
MAP sont asymptotiquement ´equivalents aux estimateurs du maximum de
vraisemblance classiques28, et, de plus, ont l’avantage d’ˆetre disponibles pour
des tailles ﬁnies d’´echantillons.
Exemple 4.1. Soient x ∼B(n, p). Nous avons vu dans le chapitre pr´ec´edent
que la loi de Jeﬀreys est dans ce cas la loi bˆeta Be(1/2, 1/2), soit
π∗(p) =
1
B(1/2, 1/2)p−1/2(1 −p)−1/2 ,
28Cette ´equivalence avec le maximum de vraisemblance n’est, bien sˆur, plus va-
lide lorsque le nombre de param`etres croˆıt avec le nombre d’observations, o`u des
incoh´erences peuvent apparaˆıtre (Diaconis et Freedman, 1986).

4.1 Inf´erence bay´esienne
177
en omettant la fonction indicatrice I[0,1](p) pour simpliﬁer les notations. Deux
autres lois non informatives ont ´et´e propos´ees, respectivement par Laplace
(1786) et Haldane (1931) (voir aussi l’Exercice 4.4),
π1(p) = 1
et
π2(p) = p−1(1 −p)−1 .
Les estimateurs MAP correspondant sont alors, pour n > 2,
δ∗(x) = max
x −1/2
n −1 , 0

,
δ1(x) = x
n,
δ2(x) = max
x −1
n −2, 0

.
Quand n = 1, δ∗et δ2 sont ´egaux `a δ1. Pour n = 2 et x = 1, l’estimateur δ2 est
aussi ´egal `a δ1, qui est un estimateur du maximum de vraisemblance habituel.
On voit bien que, quand n est grand, les trois estimateurs sont eﬀectivement
´equivalents.
∥
Exemple 4.2. Soit x ∼C (θ, 1), c’est-`a-dire
f(x|θ) = 1
π
#
1 + (x −θ)2$−1 ,
et π(θ) =
1
2e−|θ|. L’estimateur MAP de θ est alors δ∗(x) = 0, puisque le
maximum de exp(−|θ|)[1 + (x −θ)2]−1 est atteint en θ = 0, quelle que soit la
valeur de x ! Ce comportement surprenant d’un estimateur qui ne d´epend pas
de x peut s’expliquer par le caract`ere plat de la fonction de vraisemblance, qui
n’est pas suﬃsamment informative relativement `a une loi a priori tr`es pr´ecise.
Bien entendu, d’un point de vue pratique, cet estimateur est sans int´erˆet, mais
ce paradoxe disparaˆıt lorsque le nombre d’observations augmente (Exercices
4.6 et 4.7).
∥
4.1.3 Principe de vraisemblance
L’inf´erence bay´esienne apparaˆıt comme une fa¸con eﬃcace de mettre en
œuvre le principe de vraisemblance, puisqu’elle fournit un estimateur, en
s´electionnant, comme dans l’Exemple 4.3 ci-dessous, l’un des maxima de la
fonction de vraisemblance. Comme l’ont soulign´e Savage (1954) et Berger
et Wolpert (1988), de nombreuses consid´erations philosophiques et pratiques
relient le principe de vraisemblance `a une approche bay´esienne robuste. En
particulier, ceci permet l’´elimination de quelques paradoxes classiques, comme
ceux de Stein (1962b), Stone (1976), Fraser et al. (1984) et Le Cam (1990).
L’exemple suivant illustre la r´esolution du paradoxe de Fraser et al. (1984).
(Voir aussi Joshi, 1967b, pour une analyse plus g´en´erale de ce ph´enom`ene.)

178
4 Estimation bay´esienne ponctuelle
Exemple 4.3. (Berger et Wolpert, 1988) Soit X = Θ = N∗et
f(x|θ) = 1
3 pour x =
⎧
⎪
⎨
⎪
⎩
θ/2, 2θ, 2θ + 1
si θ est pair,
(θ −1)/2, 2θ, 2θ + 1
si θ ̸= 1 est impair,
1, 2, 3
si θ = 1.
La fonction de vraisemblance est alors
ℓ(θ|x) = 1
3 pour θ =
⎧
⎪
⎨
⎪
⎩
x/2, 2x, 2x + 1
si x est pair,
(x −1)/2, 2x, 2x + 1
si x ̸= 1 est impair,
1, 2, 3
si x = 1,
(4.1)
et les trois valeurs de θ pour lesquelles ℓ(θ|x) ̸= 0 sont pond´er´ees de la mˆeme
mani`ere par la fonction de vraisemblance. Consid´erons les trois estimateurs
suivants :
δ1(x) =
⎧
⎪
⎨
⎪
⎩
x/2
si x est pair,
(x −1)/2
si x ̸= 1 est impair,
1
si x = 1,
et
δ2(x) = 2x,
δ3(x) = 2x + 1.
Ils sont ´equivalents du point de vue du principe de vraisemblance, car la
fonction de vraisemblance est constante sur son support, mais δ2 et δ3 sont
des estimateurs relativement sous-optimaux puisque
P(δ2(x) = θ) = P(x = θ/2) =

1/3
si θ est pair,
0
sinon,
P(δ3(x) = θ) = P(x = (θ −1)/2) =

1/3
si θ ̸= 1 est impair,
0
sinon,
tandis que
P(δ1(x) = θ) =

1
si θ = 1,
2/3
sinon.
L’estimateur δ1 est donc pr´ef´erable pour des coˆuts comme le coˆut 0−1. Quand
l’information disponible sur le mod`ele se r´eduit `a la fonction de vraisemblance
(4.1), une loi non informative possible sur θ est π(θ) = 1/θ, car θ peut ˆetre
consid´er´e approximativement comme un param`etre d’´echelle. Dans ce cas,
π(θ|x) ∝1
3θ
#
Iδ1(x)(θ) + Iδ2(x)(θ) + Iδ3(x)(θ)
$
et cette loi a posteriori donne δ1(x) comme ´etant quatre fois plus probable
que δ2(x) ou δ3(x). On peut aussi montrer que P π(θ = δ1(x)|x) ≃2/3 pour

4.1 Inf´erence bay´esienne
179
x grand. Cela permet de justiﬁer le choix de δ1. Une mod´elisation a priori
plus informative conduirait `a une conclusion similaire (car une distribution
convenable π(θ) doit d´ecroˆıtre pour θ suﬃsamment grand).
∥
Berger et Wolpert (1988) fournissent des r´esolutions similaires aux para-
doxes exhib´es par Stein (1962b) et Stone (1976). Un avantage imm´ediat de
l’approche bay´esienne, comparativement `a d’autres mises en œuvre du prin-
cipe de vraisemblance est qu’elle traite les param`etres de nuisance intervenant
dans la fonction de vraisemblance en les marginalisant. En fait, si ℓ(θ, τ|x)
d´epend aussi du param`etre de nuisance τ, une construction naturelle d’une
estimation ˆθ de θ est de consid´erer le maximum de vraisemblance int´egr´e

ℓ(θ, τ|x)π(θ, τ) dτ
au lieu d’une vraisemblance “proﬁl´ee” plus classique,
max
τ
ℓ(θ, τ|x)π(θ, τ).
Voir aussi Basu (1988) pour une analyse ´etendue du traitement des param`etres
de nuisance.
4.1.4 Espace des param`etres restreint
Berger (1985b) remarque l’int´erˆet d’une approche bay´esienne non informa-
tive pour des espaces des param`etres restreints, la loi a priori ´etant simplement
la troncation d’une loi non informative sans contrainte.
D’un point de vue classique, le calcul d’estimateurs du maximum de vrai-
semblance restreints est souvent compliqu´e, notamment quand les contraintes
sont non lin´eaires (voir Robertson et al., 1988). En revanche, la mise en œuvre
d’une approche bay´esienne via des m´ethodes de simulation de Monte Carlo
(voir le Chapitre 6) permet un calcul ais´e des estimateurs de Bayes. (Cet
avantage peut mˆeme ˆetre utilis´e pour calculer des estimateurs du maximum
de vraisemblance restreints `a travers des techniques bay´esiennes. Voir Geyer
et Thompson, 1992, Robert et Hwang, 1996 et Robert et Casella, 2004, Cha-
pitre 5.)
Exemple 4.4. Soit l’estimation du mod`ele de r´egression lin´eaire
y = b1X1 + b2X2 + ϵ,
(4.2)
qui relie les revenus directs (X1), les revenus de l’´epargne (X2) et l’´epargne
(y). Une estimation pr´ecise des taux d’´epargne b1 et b2 peut aider le gou-
vernement `a d´eterminer les taux d’int´erˆet ou la politique ﬁscale. Les taux
d’int´erˆet sont ´evidemment contraints par 0 ≤b1, b2 ≤1. Soit un ´echantillon

180
4 Estimation bay´esienne ponctuelle
(y1, X11, X21), . . . , (yn, X1n, X2n) de (4.2) et supposons que les erreurs ϵi
soient ind´ependantes et distribu´ees selon N (0, 1), c’est-`a-dire que yi ∼
N (b1X1i + b2X2i, 1). La loi non informative correspondante est alors la loi
propre
π(b1, b2) = I[0,1](b1)I[0,1](b2)
et la moyenne a posteriori est donn´ee par (i = 1, 2)
Eπ[bi|y1, . . . , yn] =
 1
0
 1
0 bi
/n
j=1 ϕ(yj −b1X1j −b2X2j) db1 db2
 1
0
 1
0
/n
j=1 ϕ(yj −b1X1j −b2X2j) db1 db2
,
o`u ϕ est la densit´e de la loi normale centr´ee. Si on note par (ˆb1,ˆb2) l’estima-
teur des moindres carr´es non contraints de (b1, b2), qui est aussi l’estimateur
du maximum de vraisemblance r´egulier de (b1, b2), la loi a posteriori non
contrainte sur (b1, b2) est

b1
b2

∼N2
ˆb1
ˆb2

,
	
XtX

−1

,
(4.3)
avec
X =
⎛
⎜
⎝
X11 X21
...
...
X1n X2n
⎞
⎟
⎠.
Par cons´equent, l’estimateur de Bayes restreint est donn´e par (i = 1, 2)
δπ
i (y1, . . . , yn) = Eπ #
biI[0,1]2(b1, b2)|y1, . . . , yn
$
P π ((b1, b2) ∈[0, 1]2|y1, . . . , yn),
o`u le terme de droite est calcul´e sous la loi (4.3). Si on indique
Σ = (XtX)−1 =
σ2
11 σ12
σ12 σ2
22

,
la loi conditionnelle de b1 est
b1|b2 ∼N

ˆb1 + σ12(b2 −ˆb2)/σ2
22, σ2
11 −σ2
12σ−2
22

.
Alors
P π ((b1, b2) ∈[0, 1]2|y1, . . . , yn

=
 1
0
⎧
⎨
⎩Φ
⎛
⎝1 −ˆb1 −σ12(b2 −ˆb2)/σ2
22
0
σ2
11 −σ2
12σ−2
22
⎞
⎠
−Φ
⎛
⎝−ˆb1 −σ12(b2 −ˆb2)/σ2
22
0
σ2
11 −σ2
12σ−2
22
⎞
⎠
⎫
⎬
⎭σ−1
22 ϕ

b2 −ˆb2
σ22
 
db2

4.1 Inf´erence bay´esienne
181
et
Eπ[biI[0,1]2(b1, b2)|y1, . . . , yn] =
 1
0

ˆb1 + σ12
σ2
22
(b2 −ˆb2)
+(σ2
11 −σ2
12σ−2
22 )1/2
⎧
⎨
⎩ϕ
⎛
⎝1 −ˆb1 −σ12(b2 −ˆb2)/σ2
22
0
σ2
11 −σ2
12σ−2
22
⎞
⎠
−ϕ
⎛
⎝−ˆb1 −σ12(b2 −ˆb2)/σ2
22
0
σ2
11 −σ2
12σ−2
22
⎞
⎠
⎫
⎬
⎭
⎤
⎦σ−1
22 ϕ

b2 −ˆb2
σ22
 
db2.
Notons qu’on peut obtenir la seconde int´egrale sous forme explicite en uti-
lisant la fonction de r´epartition Φ d’une Gaussienne centr´ee r´eduite, mais le
d´enominateur ne peut pas ˆetre calcul´e de fa¸con analytique. Il est donc plus
eﬃcace de calculer les deux int´egrales par une (seule) simulation de Monte
Carlo (voir le Chapitre 6).
Si b1 et b2 sont ind´ependants a posteriori, c’est-`a-dire si σ12 = 0, l’estima-
teur de Bayes est explicite et donn´e par (i = 1, 2)
Eπ[bi|y1, . . . , yn] = ˆbi −σii
exp{−(1 −ˆbi)2/2σ2
ii} −exp{−ˆb2
i /2σ2
ii}
√
2π{Φ((1 −ˆbi)/σii) −Φ(−ˆb1/σii)}
.
∥
Notons que la mod´elisation bay´esienne est encore plus appropri´ee lorsqu’il
s’agit d’incorporer une information vague, c’est-`a-dire dans des cas o`u une
restriction sur l’espace des param`etres est probable mais pas certaine. Le
Chapitre 10 d´emontre qu’une mani`ere typique de traiter ces cas est d’utiliser
une mod´elisation empirique ou hi´erarchique.
4.1.5 Pr´ecision des estimateurs de Bayes
Puisque la loi a posteriori π(θ|x) est compl`etement disponible, il est pos-
sible d’associer `a un estimateur δπ(x) de h(θ) une ´evaluation de la pr´ecision
de l’estimation via, par exemple, l’erreur quadratique a posteriori,
Eπ[(δπ(x) −h(θ))2|x],
´egale `a varπ(h(θ)|x) lorsque δπ(x) = Eπ[h(θ)|x]. De la mˆeme fa¸con, dans
un cadre multidimensionnel, la matrice de covariance caract´erise la perfor-
mance des estimateurs. Ces indications additionnelles fournies par la loi a
posteriori illustrent l’avantage op´erationnel de l’approche bay´esienne, car l’ap-
proche classique a souvent des diﬃcult´es `a motiver le choix de ces ´evaluations.

182
4 Estimation bay´esienne ponctuelle
De plus, les mesures d’´evaluation bay´esiennes sont toujours conditionnelles29,
tandis que l’approche fr´equentiste doit recourir `a des bornes sup´erieures au
moyen du principe minimax, car le param`etre θ est inconnu (voir Berger et
Robert, 1990, pour une comparaison des deux approches).
Exemple 4.5. (Suite de l’Exemple 4.1) Soit l’estimateur du maximum
de vraisemblance de p, δ1(x) = x/n. Alors
Eπ[(δ1(x) −p)2|x] = Eπ[(p −x/n)2|x]
=
x + 1/2
n + 1
−x
n
2
+ (x + 1/2)(n −x + 1/2)
(n + 1)2(n + 2)
= (x −n/2)2
(n + 1)2n2 + (x + 1/2)(n −x + 1/2)
(n + 1)2(n + 2)
,
(4.4)
car π(p|x) est la loi bˆeta Be(x + 1/2, n −x + 1/2). D’un point de vue
fr´equentiste, le risque de l’estimateur du maximum de vraisemblance est
Ep[(δ1(x) −p)2] = var(x/n) = p(1 −p)
n
et
sup
p p(1 −p)/n = 1/4n.
En d´eveloppant (4.4), il est facile de v´eriﬁer que le maximum de (4.4) est
1/[4(n + 2)],
quantit´e toujours plus petite que 1/4n. Le principal avantage de (4.4) est de
fournir malgr´e tout une r´eponse modulable pour l’´evaluation de δ1, car (4.4)
varie entre 1/[4(n + 2)] et 3/[4(n + 1)(n + 2)]. Bien ´evidemment, une ap-
proximation fr´equentiste de p(1 −p)/n peut aussi ˆetre propos´ee, `a savoir
(x/n)(1−x/n)/n. Cette ´evaluation souﬀre alors de l’inconv´enient oppos´e, car
il varie trop largement, comme le montre la Figure 4.1. Il peut mˆeme prendre
la valeur 0 quand x vaut 0 ou n. Un comportement similaire est discut´e par
Berger (1990) dans un cadre g´en´eral.
∥
4.1.6 Pr´evision
L’inf´erence bay´esienne peut ˆetre aussi mise en œuvre dans des probl`emes
de pr´evision. Si x ∼f(x|θ) et z ∼g(z|x, θ), o`u z ne d´epend pas n´ecessairement
de x, la distribution pr´edictive de z apr`es observation de x est donn´ee par
29En fait, il existe des contreparties bay´esiennes aux in´egalit´es de Cram´er-Rao uti-
lis´ees dans l’´evaluation des estimateurs non biais´es. Il s’agit des bornes de Van Trees
(Gill et Levit, 1995), utilis´ees en traitement de signal et dans d’autres domaines,
comme l’ont illustr´e Bergman et al. (2001)

4.1 Inf´erence bay´esienne
183
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.01
0.02
0.03
0.04
0.05
0.06
p
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.01
0.02
0.03
0.04
0.05
0.06
Bayes
frequentist
Fig. 4.1. Comparaison des ´evaluations bay´esienne et fr´equentiste de l’erreur d’es-
timation dans le cas binomial (n = 3).
gπ(z|x) =

Θ
g(z|x, θ)π(θ|x) dθ.
(4.5)
La distribution de z est alors assez logiquement moyenn´ee sur les valeurs de θ
relativement `a la loi a posteriori, qui est aussi la distribution actualis´ee de θ. Il
est possible d’utiliser (4.5) pour calculer la moyenne et la variance pr´edictive
de la variable al´eatoire z. Dans la Section 4.3.1, nous consid´erons un exemple
particulier de d´etermination d’une distribution pr´edictive discr`ete (voir aussi
l’Exercice 4.41).
Exemple 4.6. Le mod`ele AR (1), o`u AR signiﬁe autor´egressif, est un mod`ele
dynamique qui d´eﬁnit la distribution d’une variable au temps t (1 ≤t ≤T ),
xt, conditionnellement `a l’observation pr´ec´edente xt−1, comme
xt = ϱxt−1 + ϵt ,
o`u les ϵt sont i.i.d. N (0, σ2). (Ce mod`ele sera consid´er´e en d´etail dans la
Section 4.5.) Pour une suite d’observations donn´ee jusqu’au temps T −1,
x1:(T −1) = (x1, . . . , x(T −1)), la distribution pr´edictive de xT est alors
xT |x1:(T −1) ∼

1
√
2πσ−1 exp{−(xT −ϱxT −1)2/2σ2}π(ϱ, σ|x1:(T −1))dϱdσ ,
o`u π(ϱ, σ|x1:(T −1)) peut ˆetre formul´ee explicitement (Exercice 4.14).
∥
Notons que l’approche de la Th´eorie de la D´ecision d´evelopp´ee dans les
sections suivantes s’applique aussi `a la pr´ediction, mˆeme si nous ne mention-
nerons plus ce point par la suite. En fait, si un coˆut de pr´ediction L(z, δ)

184
4 Estimation bay´esienne ponctuelle
est disponible, un pr´edicteur δ(x) peut ˆetre choisi qui minimise l’erreur de
pr´ediction moyenne (l’esp´erance ´etant calcul´ee par rapport `a la distribution
pr´edictive (4.5)) ; voir l’Exercice 4.46.
4.1.7 Retour `a la d´ecision
´Etant donn´e l’´etendue des utilisations possibles de la loi a posteriori, cer-
tains consid`erent qu’on devrait fournir aux clients la loi a posteriori aﬁn qu’ils
puissent l’utiliser `a leur guise. Bien que la communication de π(θ|x) soit en
eﬀet envisageable pour de petites dimensions, sa complexit´e rend en g´en´eral
diﬃcile l’extraction de l’information qu’elle contient. La loi a posteriori est
´evidemment essentielle dans le processus de d´ecision, mais il revient au sta-
tisticien d’assister plus avant le d´ecideur, aﬁn d’extraire les caract´eristiques
d’int´erˆet de π(θ|x). Par cons´equent, nous sommes de nouveau confront´es au
probl`eme important de s´election d’un estimateur et nous avons vu dans le
Chapitre 2 que cette s´election n’est eﬃcace et coh´erente que lorsqu’elle est
fond´ee sur un crit`ere de coˆut. Les sections qui suivent mettent en avant la
th´eorie bay´esienne de la d´ecision, avec une attention particuli`ere aux cas nor-
maux et d’´echantillonnage. Bien que formellement rattach´es `a la Th´eorie de la
D´ecision, tests et r´egions de conﬁance sont trait´es s´epar´ement dans le chapitre
suivant (Chapitre 5).
4.2 Th´eorie bay´esienne de la d´ecision
4.2.1 Estimateurs de Bayes
Rappelons que, pour une fonction de coˆut L(θ, δ) et une loi a priori (ou
une mesure) π, la r`egle de Bayes δπ(x) est solution de
min
δ
Eπ[L(θ, δ)|x].
Selon la complexit´e du coˆut L et de la loi a posteriori π(θ|x), l’estimateur δπ
sera d´etermin´e analytiquement ou num´eriquement.
Comme nous l’avons montr´e dans le Chapitre 2, les solutions associ´ees
`a des coˆuts classiques sont formellement connues et correspondent aux ca-
ract´eristiques usuelles d’une distribution (moyenne, m´ediane, fractiles, etc.).
Par exemple, l’estimateur de Bayes associ´e au coˆut quadratique est la moyenne
a posteriori (Proposition 2.41 et Corollaire 2.42). Bien sˆur, cette construction
formelle des estimateurs de Bayes classiques n’´evite pas toujours le recours `a
une approximation num´erique, particuli`erement dans des cas multidimension-
nels.

4.2 Th´eorie bay´esienne de la d´ecision
185
Exemple 4.7. Soit x ∼Np(θ, Ip). Comme nous l’avons indiqu´e dans la Sec-
tion 3.6, la loi de Student fournit une alternative robuste `a la loi normale
conjugu´ee pour l’estimation de θ. Soit donc θ ∼Tp(α, 0, τ2Ip), c’est-`a-dire
π(θ|α, τ) =
Γ((α + p)/2)
(ατπ)p/2Γ(α/2)

1 + ||θ||2
ατ2
−(α+p)/2
.
Par cons´equent,
π(θ|x) ∝

1 + ||θ||2
ατ2
−(α+p)/2
e−||x−θ||2/2,
qui ne conduit pas `a une expression explicite de la loi a posteriori. Cependant,
il est malgr´e tout possible de r´eduire le probl`eme de calcul `a celui d’une
int´egrale simple, pour toute valeur de p, comme l’a montr´e Dickey (1968). En
eﬀet, si θ ∼Tp(α, 0, τ2Ip), la loi a posteriori de θ peut s’´ecrire comme un
m´elange cach´e (voir l’Exemple 3.17),
θ|z ∼Np(0, τ2zIp),
z−1 ∼G (α/2, α/2),
o`u z est une variable al´eatoire auxiliaire. Conditionnellement `a z, la loi a
posteriori de θ est
θ|x, z ∼Np

x
1 + τ2z ,
τ 2z
1 + τ2z Ip

et, comme
π(z|x) ∝(1 + τ 2z)−p/2e−||x||2/2(1+τ 2z)π(z),
on calcule l’estimateur de Bayes comme ´etant
δπ(x) =
 +∞
0
Eπ[θ|x, z]π(z|x) dz
= x
 +∞
0
(1 + τ 2z)−(p+2)/2e−||x||2/2(1+τ 2z)z−(α+2)/2e−α/2z dz
 +∞
0
(1 + τ 2z)−p/2e−||x||2/2(1+τ 2z)z−(α+2)/2e−α/2z dz
.
Cet estimateur peut donc s’exprimer comme une int´egrale simple pour toute
valeur de p.
∥
Cependant, des d´ecompositions subtiles comme celle de l’exemple ci-dessus
ne sont pas toujours possibles et le calcul d’un estimateur de Bayes n´ecessite
alors une m´ethode d’approximation g´en´erale comme celles d´ecrites dans le
Chapitre 6.
En revanche, un r´esultat int´eressant est que, quand la loi marginale m(x)
est disponible, l’esp´erance a posteriori du param`etre naturel d’une famille
exponentielle se calcule ais´ement.

186
4 Estimation bay´esienne ponctuelle
Lemme 4.8. Soit f(x|θ) = h(x)eθ·x−ψ(θ), une distribution d’une famille ex-
ponentielle. Pour toute loi a priori π, la moyenne a posteriori de θ est donn´ee
par
δπ(x) = ∇log mπ(x) −∇log h(x),
(4.6)
o`u ∇est l’op´erateur gradient et mπ est la loi marginale associ´ee `a π.
Preuve.
L’esp´erance a posteriori est donn´ee par
Eπ[θi|x] =

Θ θih(x)eθ·x−ψ(θ)π(θ) dθ
mπ(x)
=
 ∂
∂xi

Θ
h(x)eθ·x−ψ(θ)π(θ) dθ

1
mπ(x) −
 ∂
∂xi
h(x)

1
h(x)
=
∂
∂xi
[log mπ(x) −log h(x)] .
⊓⊔
Notons que ce lemme est satisfait pour tout π ; il apparaˆıt comme le
r´esultat dual du calcul des moments de f(x|θ) `a partir de la d´eriv´ee de ψ
dans une famille exponentielle (voir le Lemme 3.13). Son int´erˆet pratique est
h´elas plutˆot limit´e, car le calcul de la loi marginale est g´en´eralement assez
d´elicat et connaˆıtre mπ(x) explicitement ´equivaut `a connaˆıtre π(θ|x) explici-
tement30.
Exemple 4.9.
Nous avons introduit dans la Note 2.5.4 l’estimateur de
James-Stein tronqu´e,
δJS(x) =

1 −p −2
||x||2
+
x
quand x ∼Np(θ, Ip). Dans le cas normal, (4.6) s’´ecrit
δπ(x) = x + ∇log mπ(x).
Bien qu’il existe une fonction m telle que δJS peut s’´ecrire comme ci-dessus
(voir Bock, 1988), m n’est pas une loi marginale et cet estimateur ne peut
pas ˆetre de Bayes : il vaut 0 sur l’ouvert {||x||2 < p −2} et devrait ˆetre nul
partout du fait de la contrainte d’analycit´e.
∥
L’expression (4.6) des estimateurs de Bayes est aussi utile pour l’´etablisse-
ment de r´esultats li´es `a l’eﬀet de Stein, soit pour ´etablir les conditions de do-
mination comme dans Stein (1981), George (1986a), Berger et Robert (1990)
30Une cons´equence th´eorique de ce lemme est que les estimateurs de Bayes sont
des fonctions analytiques (ou holomorphes) si la famille exponentielle consid´er´ee est
telle que la fonction h qui l’engendre est holomorphe, puisque mπ/h est alors la
transform´ee de Laplace de e−ψ(θ)π(θ). Le Chapitre 8 ´etablit un crit`ere d’inadmissi-
bilit´e `a partir de cette propri´et´e.

4.2 Th´eorie bay´esienne de la d´ecision
187
et Brandwein et Strawderman (1990), soit pour caract´eriser l’admissibilit´e de
certains estimateurs comme dans Bock (1988) et Brown (1988) ; voir l’Exercice
4.44.
Tab. 4.1.
Estimateurs de Bayes du param`etre θ sous coˆut quadratique pour les
lois a priori conjugu´ees des familles exponentielles usuelles.
Loi
Loi
Moyenne
de x
conjugu´ee
a posteriori
Normale
Normale
N (θ, σ2)
N (μ, τ 2)
μσ2 + τ 2x
σ2 + τ 2
Poisson
Gamma
P(θ)
G (α, β)
α + x
β + 1
Gamma
Gamma
G (ν, θ)
G (α, β)
α + ν
β + x
Binomiale
Bˆeta
B(n, θ)
Be(α, β)
α + x
α + β + n
Binomiale
n´egative
Bˆeta
N eg(n, θ)
Be(α, β)
α + n
α + β + x + n
Multinomiale
Dirichlet
Mk(n; θ1, . . . , θk) D(α1, . . . , αk)
αi + xi
“P
j αj
”
+ n
Normale
Gamma
N (μ, 1/θ)
G (α/2, β/2)
α + 1
β + (μ −x)2
4.2.2 Les lois a priori conjugu´ees
Dans le cas particulier des lois a priori conjugu´ees, les esp´erances a pos-
teriori des param`etres naturels admettent ´evidemment des expressions expli-
cites ; c’est d’ailleurs pratiquement le seul cas o`u des expressions analytiques
sont disponibles dans une telle g´en´eralit´e. Le Tableau 4.1 pr´esente les esti-
mateurs de Bayes associ´es aux distributions usuelles et `a leurs lois a priori
conjugu´ees. Notons que, quand plusieurs observations de f(x|θ) sont dispo-
nibles, on retrouve les mˆemes lois a priori conjugu´ees et que seuls les pa-
ram`etres dans l’estimateur sont modiﬁ´es, ceci en raison des propri´et´es d’ex-
haustivit´e des familles exponentielles (Section 3.3.3).
Exemple 4.10. Si x1, ..., xn sont des observations ind´ependantes de N eg(m,
θ) et si θ ∼Be(α, β), la loi a posteriori de θ est la distribution bˆeta

188
4 Estimation bay´esienne ponctuelle
Be

α + mn,
n

i=1
xi + β
 
et
δπ(x1, ..., xn) =
α + mn
α + β + mn + n
i=1 xi
.
Ce r´esultat est une cons´equence directe du fait que n
i=1 xi ∼N eg(mn, θ).
∥
Exemple 4.11. Soient n observations x1, ..., xn de U ([0, θ]) et prenons
θ ∼Pa(θ0, α). Alors
θ|x1, ..., xn ∼Pa(max (θ0, x1, ..., xn), α + n)
et
δπ(x1, ..., xn) =
α + n
α + n −1 max (θ0, x1, ..., xn).
Ainsi, par comparaison avec l’estimateur du maximum de vraisemblance,
δ0(x1, ..., xn) = max(x1, ..., xn),
l’estimateur de Bayes donne une estimation plus ”optimiste” de θ, car
α + n
α + n −1 > 1 .
Dans le cas limite o`u α = 0 et θ0 = 0, on retrouve le meilleur estimateur
´equivariant de θ sous coˆut quadratique
n
n−1δ0(x1, . . . , xn) (voir le Chapitre 9),
qui est plus grand que δπ quand θ0 = 0. Ce comportement de r´etr´ecissement
de δπ pour α ̸= 1 s’explique par le choix de π, qui d´ecroˆıt avec θ, et favorise
donc les valeurs de θ proches de θ0.
∥
De mˆeme, rappelons que l’estimation d’une fonction de θ, g(θ), sous coˆut
quadratique, donne comme estimateur de Bayes δπ(x) = Eπ[g(θ)|x].
Exemple 4.12. Soit x ∼G (ν, θ), o`u le param`etre de forme ν est connu, et
θ ∼G (α, β). Le param`etre d’int´erˆet est 1/θ, l’esp´erance de x. Sous le coˆut
quadratique
L(θ, δ) =

δ −1
θ
2
,
l’estimateur de Bayes est alors
δπ
1 (X) = (β + x)α+ν
Γ(α + ν)
 +∞
0
1
θ θα+ν−1e−(β+x)θdθ
=
β + x
α + ν −1.
∥

4.2 Th´eorie bay´esienne de la d´ecision
189
Sous un coˆut quadratique renormalis´e (ou pond´er´e),
L(θ, δ) = w(θ) ∥δ −θ ∥2
Q,
o`u Q est une matrice p × p sym´etrique semi-d´eﬁnie positive, l’estimateur de
Bayes associ´e est
δπ(x) = Eπ[θw(θ)|x]
Eπ[w(θ)|x] .
Exemple 4.13. (Suite de l’Exemple 4.12) Un coˆut invariant par change-
ment d’´echelle ne d´epend pas de l’unit´e de mesure et peut ˆetre plus pertinent
pour une estimation de 1/θ. Par exemple, le coˆut
L(θ, δ) = θ2

δ −1
θ
2
donne l’estimateur de Bayes
δπ
2 (x) = Eπ #
θ2/θ | x
$
Eπ [θ2 | x]
=
 +∞
0
θθα+ν−1e−(β+x)θdθ
 +∞
0
θα+ν+1e−(β+x)θdθ
=
β + x
α + ν + 1 = α + ν −1
α + ν + 1 δπ
1 (x).
∥
Insistons de nouveau sur le fait que, mˆeme pour les lois a priori conjugu´ees,
le fait que l’estimateur de Bayes de toute fonction de θ s’exprime comme une
esp´erance a posteriori n’´evite pas n´ecessairement le calcul num´erique, car une
int´egration analytique peut ˆetre impossible, en particulier dans les probl`emes
multidimensionnels.
Exemple 4.14. Soient x ∼Np(θ, Ip) et h(θ) = ||θ||2. Le coˆut consid´er´e dans
Saxena et Alam (1982) est
L(θ, δ) = (δ −||θ||2)2
2||θ||2 + p
car, si δ0(x) = ||x||2 −p,
R(δ0, θ) =
1
2||θ||2 + p E(||x||2 −||θ||2 −p)2 = 2
et δ0 a un risque constant. Sans cette renormalisation, tous les estimateurs ont
un risque maximal ´egal `a +∞, tandis que sous L, l’estimateur δ0 est minimax.
Alors, mˆeme pour une loi a priori conjugu´ee, Np(0, τ2Ip), le calcul de

190
4 Estimation bay´esienne ponctuelle
δπ(x) = Eπ[||θ||2/(2||θ||2 + p)|x]
Eπ[1/(2||θ||2 + p)|x]
ne peut pas ˆetre eﬀectu´e analytiquement.
∥
Dans les exemples pr´ec´edents, nous avons eu largement recours au coˆut
quadratique, car il constitue un coˆut standard et permet, autant que possible,
des calculs explicites. Nous renvoyons les lecteurs au Chapitre 2 pour des cri-
tiques sur le caract`ere arbitraire des coˆuts standard et l’opposition entre coˆuts
concaves born´es et coˆuts convexes non born´es, les premiers conduisant `a un
paradoxe d’amateurs du risque et les seconds `a une plus grande instabilit´e
des proc´edures en r´esultant (voir Kadane et Chuang, 1978, Smith, 1988, et les
Exercices 4.1 et 4.15). Malgr´e tout, il faut remarquer que, lorsque la fonction
de coˆut est vraiment d´etermin´ee par le d´ecideur, celle-ci est g´en´eralement com-
plexe et n´ecessite le plus souvent une minimisation num´erique pour aboutir `a
l’estimateur de Bayes.
4.2.3 Estimation du coˆut
Pour un coˆut donn´e, L(θ, δ), on peut aussi chercher `a ´evaluer les perfor-
mances de l’estimateur de Bayes δπ(x). Cette ´evaluation peut s’interpr´eter
d’un point de vue d´ecisionnel comme l’estimation du coˆut L(θ, δπ(x)) par
γ(x), sous une seconde fonction de coˆut, comme
˜L(θ, δπ, γ) = [γ(x) −L(θ, δπ(x))]2 .
(4.7)
De nouveau, le coˆut quadratique (4.7) n’est pas plus justiﬁ´e comme choix
automatique dans ce contexte que dans d’autres cas d’estimation. Mais, en
dehors de son cˆot´e pratique, le choix du coˆut quadratique peut se d´efendre par
l’absence de justiﬁcation en termes d’utilit´e et, par cons´equent, une perception
plus proche de l’erreur comme une variance. Sous (4.7), l’´evaluation bay´esienne
des performances de δπ est donn´ee par le r´esultat suivant.
Proposition 4.15.
L’estimateur de Bayes du coˆut L(θ, δπ(x)) sous (4.7)
pour la loi a priori π est
γπ(x) = Eπ[L(θ, δπ(x))|x].
Ce r´esultat d´ecoule directement de la Proposition 2.41, puisque, condi-
tionnellement `a x, le but est d’estimer une fonction particuli`ere de θ sous un
coˆut quadratique. Notons que la d´ependance de cette fonction `a x n’a pas
d’importance d’un point de vue bay´esien, car, une fois x observ´e, x est ﬁx´e.
De mˆeme, pour un coˆut d’erreur absolue, l’estimateur de Bayes du coˆut est la
m´ediane de la distribution a posteriori de L(θ, δπ(x)), moins facile `a obtenir.
Quand L est le coˆut quadratique, la variance a posteriori, varπ(x), est par
cons´equent l’estimateur de Bayes du coˆut associ´e avec δπ.

4.3 Mod`eles d’´echantillonnage
191
L’estimation du coˆut dans une perspective fr´equentiste a ´et´e ´etudi´ee par
Johnstone (1998) et Rukhin (1988a,b), le premier montrant que, pour un
estimateur minimax avec un risque constant p, l’´evaluation γ(x) = p n’est pas
n´ecessairement admissible sous (4.7). Berger (1984, 1985a) (voir aussi Lu et
Berger, 1989a,b) d´eveloppe un concept additionnel pour l’estimation du coˆut
appel´e validit´e fr´equentiste : un estimateur γ du coˆut L(θ, δ(x)) est valide en
fr´equence si
Eθ[γ(x)] ≥R(θ, δ(x)),
θ ∈Θ,
c’est-`a-dire si cet estimateur ne sous-estime jamais sur le long terme l’erreur
r´esultant de l’utilisation de δ. Une telle restriction peut sembler intuitivement
satisfaisante, mais elle est fond´ee sur la justiﬁcation `a la base de la notion
d’estimation sans biais, et cette restriction contredit le principe de vraisem-
blance.
Robert et Casella (1994) proposent une approche purement d´ecisionnelle
de l’estimation du coˆut pour des r´egions de conﬁance (voir le Chapitre 5). Si
C(x) est une r´egion de conﬁance pour θ, le coˆut usuel pour son estimation est
le coˆut 0 −1,
L(C(x), θ) = 1 −IC(x)(θ) .
Un estimateur du coˆut γ(x) ´evalue donc le taux de couverture de C(x) et ap-
proche en quelque sorte la probabilit´e de couverture de la r´egion de conﬁance.
Hwang et Brown (1991) ont ainsi montr´e que, pour les r´egions de conﬁance
usuelles C0, dans un cadre normal, l’estimateur constant
α = P(θ ̸∈C0(x))
est admissible parmi les estimateurs valides en fr´equence, mais est inadmissible
pour p > 5 en l’absence de cette restriction (voir la Section 5.5).
Exemple 4.16. Soient x ∼Np(θ, σ2Ip) et θ ∼Np(0, τ2Ip). Sous un coˆut
quadratique,
δπ(x) =
σ2
σ2 + τ 2 x
et
V π(x) =
σ2τ 2
σ2 + τ 2 p.
En revanche, l’approche fr´equentiste donne +∞comme risque maximal pour
δπ et est donc mal adapt´ee `a ce probl`eme.
∥
4.3 Mod`eles d’´echantillonnage
Dans cette section, nous consid´erons trois probl`emes d’´echantillonnage
pour lesquels une approche bay´esienne est facile `a mettre en œuvre. Notons
tout d’abord que, en g´en´eral, les mod`eles discrets n´ecessitent moins d’infor-
mation a priori pour construire une loi a priori. Le premier probl`eme que nous

192
4 Estimation bay´esienne ponctuelle
consid´erons est li´e `a la r`egle de succession de Laplace, introduite en 1774 par
Laplace. Le deuxi`eme probl`eme a ´et´e ´etudi´e sous le nom de “probl`eme du
tramway” par Neyman dans les ann´ees 1930. La derni`ere section ´etudie les
mod`eles de capture-recapture, qui sont tr`es int´eressants pour la biologie ani-
male et pour d’autres mod`eles d’estimation de population. Ces trois probl`emes
ont comme point commun le fait qu’ils proposent une inf´erence sur une popu-
lation ﬁnie ou sur une sous-population. Il s’agit de cas o`u une certaine partie
de l’information a priori est habituellement disponible, ou bien de cas o`u on
peut faire le choix d’une loi a priori non informative sans (grande) ambigu¨ıt´e.
4.3.1 R`egle de succession de Laplace
Consid´erons le mod`ele hyperg´eom´etrique H (N, N1, x) standard : Soit une
population de taille N divis´ee en deux sous-populations de tailles inconnues
respectives N1 et N2 = N −N1. Lors d’un tirage sans remise de x indivi-
dus dans cette population, x1 individus appartiennent `a la premi`ere sous-
population et x2 = x −x1 `a la seconde. Lorsque aucune information n’est
disponible sur N1, la loi non informative est
π(N1) =
1
N + 1I{0,1,...,N}(N1)
et la loi a posteriori correspondante de N1 est (x1 ≤N1 ≤N −(x −x1))
π(N1|x1) =
	N1
x1

	N−N1
x−x1

N
i=0
	 i
x1

	 N−i
x−x1

 =
	N1
x1

	N−N1
x−x1

	N+1
x+1

.
Soit E l’´ev´enement que le tirage suivant donnera un individu de la premi`ere
sous-population, p ´etant la probabilit´e de E. Alors
P(E|N1, x1) = N1 −x1
N −x .
Donc
P(E, N1|x1) = N1 −x1
N −x
	N1
x1

	N−N1
x−x1

	N+1
x+1

= x1 + 1
N −x
	 N1
x1+1

	N−N1
x−x1

	N+1
x+1

,
et
p = P(E|x1) = x1 + 1
N −x
	N+1
x+2

	N+1
x+1

 = x1 + 1
x + 2 ,
qui est ind´ependant de N. Par cons´equent, la loi pr´evisionnelle de l’apparte-
nance du (x + 1)-i`eme tirage est une loi de Bernoulli, B(1, (x1 + 1)/(x + 2)).

4.3 Mod`eles d’´echantillonnage
193
Laplace, consid´erant le cas particulier x = x1, d´eduit sa r`egle de suc-
cession : Si n premiers tirages donnent tous un ´el´ement de la mˆeme sous-
population, la probabilit´e que le tirage suivant donne `a nouveau un ´el´ement de
cette population est n+1
n+2. Une cons´equence de la r`egle de succession de Laplace
est que la probabilit´e que toute la population soit du mˆeme type que les n
premi`eres observations est
n+1
N+1. Certains critiquent31 cette r`egle de succes-
sion comme ´etant biais´ee en faveur de la sous-population la plus importante,
car les populations rares ne seront pas d´etect´ees (voir aussi Popper, 1983).
Au contraire, Jeﬀreys (1961, Section 3.2.2) soutient que, au moins dans le
domaine de la physique, cette r`egle conduit assez souvent `a rejeter les lois
consid´er´ees.
4.3.2 Le probl`eme du tramway
Jeﬀreys (1961) pose le probl`eme suivant, qu’il attribue `a Neyman :
“Une personne voyageant dans un pays ´etranger doit changer de
train `a un embranchement et aller dans une ville qui lui est totalement
inconnue. Elle n’en connaˆıt pas la taille. La premi`ere chose qu’elle y
voit est un tramway num´erot´e 100. Que peut-elle en d´eduire sur le
nombre de tramways dans la ville ? On peut supposer que les tramways
sont num´erot´es en ordre croissant `a partir de 1.”
Clairement, ce probl`eme a des applications moins anecdotiques. Par exemple,
on peut lui rattacher une partie des probl`emes de co¨ıncidence d´ecrits dans
Diaconis et Mosteller (1989).
Exemple 4.17.
Soit un ph´enom`ene cyclique de p´eriode inconnue T et
`a K ´etats possibles (crises boursi`eres, occurrences de com`etes, mutations
g´en´etiques, feux de signalisation, etc.) ; on observe qu’aux temps t1 et t2,
le ph´enom`ene est dans le mˆeme ´etat. Le probl`eme inf´erentiel est de d´eduire T
de l’observation de la diﬀ´erence t2 −t1.
∥
Dans le cas du probl`eme du tramway, le nombre N de lignes peut prendre
les valeurs 1, 2, . . . Il est pr´ef´erable de consid´erer une loi non informative de
la forme
π(N) = 1
N ,
plutˆot qu’une loi uniforme sur N∗, car N peut s’interpr´eter comme un pa-
ram`etre d’´echelle. (De plus, la loi a priori uniforme ne donne pas une loi a
posteriori proprement d´eﬁnie.) Si T est le num´ero relev´e, il est suppos´e dis-
tribu´e selon la loi uniforme
f(t|N) = P(T = t|N) = 1
N
(t = 1, 2, . . . , N).
31Il peut sembler curieux de critiquer un r´esultat math´ematique ! La critique porte
en fait sur le choix de la loi a priori, voire de l’axiomatique bay´esienne.

194
4 Estimation bay´esienne ponctuelle
Ainsi,
π(N|T ) ∝
1
N 2 I(N≥T )
et
P π(N ≥n0|T ) =
+∞
n=n0 1/n2
+∞
n=T 1/n2 ≈
 +∞
n0
(1/x2)dx
 +∞
T
(1/x2)dx
= T
n0
.
Dans ce cas, la m´ediane a posteriori est approximativement N π(T ) ≈2T , es-
timateur commun´ement retenu pour le probl`eme du tramway. En fait, notons
que la moyenne de T conditionnellement `a N est N−1
2
≈N
2 .
4.3.3 Mod`eles de capture-recapture
Lorsqu’on travaille avec une loi hyperg´eom´etrique H (N, n, p), le param`etre
d’int´erˆet est le plus souvent p comme dans le cas de la r`egle de succession de
Laplace, mais il peut aussi arriver que la taille de la population, N, soit
inconnue et qu’on cherche `a l’estimer. Plus g´en´eralement, dans les cas o`u le
recensement d’une population est impossible (ou trop coˆuteux), il faut trouver
une m´ethode d’estimation de la taille de cette population.
Exemple 4.18. Sur une ˆıle de Terre-Neuve vit une harde de cerfs isol´ee de
tout pr´edateur. Pour ´eviter que les cerfs ne rompent l’´equilibre ´ecologique de
l’ˆıle, il est n´ecessaire de r´eguler cette population en maintenant un nombre de
cerfs inf´erieur `a quarante. Un recensement annuel de tous les cerfs prendrait
cependant trop de temps.
∥
On pourrait mentionner plusieurs exemples en biologie, sociologie, psycho-
logie, m´et´eorologie, ´ecologie, etc., o`u une ´evaluation statistique de la taille de
la population est n´ecessaire. Par exemple, les m´ethodes de capture-recapture
expos´ees ici sont utilis´ees dans des recensements en France comme aux ´Etats-
Unis pour d´enombrer certaines populations sous-comptabilis´ees, car mal es-
tim´ees par les techniques habituelles de recensement, comme les populations
nomades, les sans-abri ou les immigrants ill´egaux32. L’approche habituelle
est appel´ee capture-recapture, car elle consiste `a observer au moins deux
´echantillons successifs de la population d’int´erˆet et a ´et´e d’abord utilis´ee
en biologie animale, o`u les individus sont eﬀectivement captur´es; voir Seber
(1983, 1986) et Pollock (1991) pour une pr´esentation g´en´erale.
Dans cette section, nous utilisons le cadre g´en´eral de Wolter (1986), qui
montre que la plupart des mod`eles de capture-recapture peuvent ˆetre d´ecrits
par une distribution multinomiale pour chaque individu i (1 ≤i ≤N) dans la
population. Le Tableau 4.2 donne les probabilit´es de capture, avec pi
11 +pi
12 +
pi
21 + pi
22 = 1. Par exemple, pi
12 repr´esente la probabilit´e d’ˆetre captur´e dans
32Un exemple frappant de l’eﬃcacit´e de cette m´ethode est donn´e dans McKeganey
et al. (1992) pour l’estimation du nombre de prostitu´ees dans la ville de Glasgow.

4.3 Mod`eles d’´echantillonnage
195
Tab. 4.2. Param`etres de probabilit´e pour une exp´erience de capture-recapture.
´Echantillon 2
captur´e
manqu´e
´Echantillon 1 captur´e
pi
11
pi
12
manqu´e
pi
21
pi
22
Tab. 4.3. Partition de la population selon le mod`ele du Tableau 4.2.
´Echantillon 2
captur´e
manqu´e
´Echantillon 1 captur´e
n11
n12
manqu´e
n21
n22
le premier ´echantillon seulement. Apr`es les deux exp´eriences de capture, la
population est divis´ee en quatre sous-populations comme le montre le Tableau
4.3, avec n11 +n12 +n21+n22 = N (la quatri`eme taille d’´echantillon n22 ´etant
inconnue). Pour le mod`ele le plus simple, dit uniforme, chaque individu a la
mˆeme probabilit´e p d’ˆetre captur´e dans les deux exp´eriences. Par cons´equence,
p11 = p2, p12 = p21 = p(1−p) et p22 = (1−p)2. La vraisemblance peut s’´ecrire
L(N, p|n11, n12, n21) =

N
n11 n21 n21

pn·(1 −p)2N−n·,
o`u n· = 2n11 + n12 + n21 est le nombre total d’individus captur´es et

N
n11 n12 n21

=
N!
n11! n21! n12! n22!
est le coeﬃcient multinomial. Pour π(N, p) = π(N)π(p) avec π(p) une distri-
bution Be(α, β), la loi a posteriori conditionnelle sur p est
π(p|N, n11, n12, n21) ∝pα+n·−1(1 −p)β+2N−n·−1,
c’est-`a-dire
p|N, n· ∼Be(α + n·, β + 2N −n·).
Malheureusement, la loi a posteriori marginale de N est assez compliqu´ee. Par
exemple, si π(N) = 1, elle satisfait
π(N|n·) ∝
 N
n+
 B(α + n·, β + 2N −n·)
B(α, β)
,
(4.8)
o`u n+ = n11 +n12 +n21 est le nombre d’individus captur´es qui sont diﬀ´erents.
Cette distribution est appel´ee parfois loi bˆeta-Pascal (voir Raiﬀa et Schlaifer,
1961), mais elle n’admet pas d’expression explicite. La mˆeme diﬃcult´e a lieu
lorsque π(N) = 1/N comme dans Castledine (1981) ou si π(N) est une loi
de Poisson P(λ) comme dans Raftery (1988), George et Robert (1992) et

196
4 Estimation bay´esienne ponctuelle
Dupuis (1995a,b). Bien entendu, N prenant des valeurs enti`eres, il est toujours
possible de calculer le facteur de normalisation dans (4.8) en sommant sur N.
Mais, outre le temps requis pour le calcul, les erreurs d’approximation peuvent
devenir importantes quand N et n+ prennent des valeurs ´elev´ees. Notons que,
pour la loi a priori de Poisson sur N, on a
N −n+|n+, p ∼P((1 −p)2λ),
donc les distributions a posteriori conditionnelles sont “accessibles” (le Cha-
pitre 6 utilise cette propri´et´e). Les extensions du mod`ele uniforme sont d´ecrites
dans Wolter (1986), George et Robert (1992) et Dupuis (1995a,b).
Un mod`ele plus simple utilis´e dans un cadre de capture-recapture est le
mod`ele hyperg´eom´etrique, dit aussi mod`ele de Darroch (Darroch, 1958), dans
lequel les tailles des deux ´echantillons n1 = n11 + n12 et n2 = n11 + n21 sont
ﬁx´ees. Dans ce cas, la description ci-dessus ne s’applique plus et la seule
variable al´eatoire qui reste est n11, de loi H (N, n2, n1
N ). En eﬀet, les valeurs
n1 et n2 ne sont pas d´etermin´ees `a l’avance, mais sont plutˆot d´etermin´ees par
un crit`ere d’arrˆet g´en´eralement inconnu. Cependant, si la loi a priori sur N est
non informative et de support discret, le calcul des estimateurs de Bayes est
du mˆeme ordre de complexit´e. N´eanmoins, le mod`ele de Darroch peut s’´ecrire
comme un cas particulier du mod`ele de Wolter (voir l’Exercice 4.35), ce qui
permet d’utiliser les mˆemes techniques d’approximation d´evelopp´ees pour le
mod`ele de Wolter dans ce cadre (voir le Chapitre 6).
Pour le mod`ele de Darroch, l’estimateur classique de N est l’estimateur
du maximum de vraisemblance
ˆN =
n1
(n11/n2),
qui ´egalise la proportion dans la population (n1/N) et la proportion dans
l’´echantillon (n11/n2). Cet estimateur pr´esente un inconv´enient majeur : il
ne peut pas ˆetre utilis´e lorsque n11 = 0. Il faut alors de nouveau tirer n3
individus et observer n22 individus d´ej`a pr´esents dans le premier ou le se-
cond ´echantillon. Puisque le nombre d’individus marqu´es augmente avec le
nombre d’´echantillons, la probabilit´e de n’observer que des nouveaux indivi-
dus `a chaque tirage diminue. Il est cependant peu raisonnable de r´eclamer un
´echantillon suppl´ementaire alors que l’objectif initial du mod`ele statistique
´etait de r´eduire les coˆuts d’´echantillonnage.
Une analyse bay´esienne ne souﬀre pas de ce d´efaut, car elle arrive `a une
conclusion mˆeme lorsque n11 = 0. `A partir d’une distribution a priori33 π sur
N, il est facile de calculer la loi a posteriori π(N = n|n11) et de mener une
inf´erence sur N.
33Cette loi a priori aura une inﬂuence importante sur l’inf´erence r´esultante si n11
est petit. Voir l’Exemple 3.1 pour une illustration de d´etermination de loi a priori
dans un contexte r´ealiste.

4.3 Mod`eles d’´echantillonnage
197
Exemple 4.19. (Suite de l’Exemple 4.18) Les r`egles de natalit´e et de
mortalit´e des cerfs impliquent que le nombre de cerfs varie entre trente-six
et cinquante. Une ´etude biologique plus approfondie sur l’esp´erance de vie
des cerfs peut certainement aider `a construire un mod`ele de loi a priori sur
N, mais nous utiliserons ici une distribution uniforme sur {36, . . ., 50}. Si on
observe n1 = n2 = 5, la formule de Bayes,
π(N = n|n11) =
 n1
n11

n2
n2 −n11

/
 n
n2

π(N = n)
50

k=36
 n1
n11

n2
n2 −n11

/
 k
n2

π(N = k)
,
permet d’obtenir le Tableau 4.4, qui fournit la loi a posteriori de N.
Puisque la loi a posteriori compl`ete de N est disponible, nous pouvons
calculer la moyenne, la m´ediane et le mode a posteriori de N (ou tout autre
estimateur de Bayes). Le Tableau 4.5 donne les esp´erances a posteriori pour
les diﬀ´erentes valeurs de n11 (on les comparera avec l’estimateur classique
25/n11 pour n11 ̸= 0, qui varie beaucoup plus avec n11).
Tab. 4.4. Loi a posteriori de la taille de la population de cerfs, π(N|n11).
n11
N
0
1
2
3
4
5
36 0.058 0.072 0.089 0.106 0.125 0.144
37 0.059
0.072 0.085 0.098 0.111 0.124
38 0.061
0.071 0.081 0.090 0.100 0.108
39 0.062
0.070 0.077 0.084 0.089 0.094
40 0.063
0.069 0.074 0.078 0.081 0.082
41 0.065
0.068 0.071 0.072 0.073 0.072
42 0.066
0.068 0.067 0.067 0.066 0.064
43 0.067
0.067 0.065 0.063 0.060 0.056
44 0.068
0.066 0.062 0.059 0.054 0.050
45 0.069
0.065 0.060 0.055 0.050 0.044
46 0.070
0.064 0.058 0.051 0.045 0.040
47 0.071
0.063 0.056 0.048 0.041 0.035
48 0.072
0.063 0.054 0.045 0.038 0.032
49 0.073
0.062 0.052 0.043 0.035 0.028
50 0.074
0.061 0.050 0.040 0.032 0.026
Tab. 4.5. Esp´erance a posteriori de la taille de la population de cerfs, E[N|n11].
n11
0
1
2
3
4
5
E(N|n11)
43.32 42.77 42.23 41.71 41.23 40.78

198
4 Estimation bay´esienne ponctuelle
Si, au lieu d’une erreur quadratique, nous utilisons le coˆut
L(N, δ) =

10(δ −N)
si δ > N,
N −δ
sinon,
(4.9)
aﬁn d’´eviter une surestimation du nombre de cerfs (ce qui aurait des cons´e-
quences plus dramatiques pour l’avenir de la harde qu’une sous-estimation),
l’estimateur de Bayes est le fractile (1/11) de π(N|n11), donn´e dans le Tableau
4.6 pour diﬀ´erentes valeurs de n11. Notons que, dans ce cas, les estimateurs
prennent n´ecessairement des valeurs enti`eres.
∥
Tab. 4.6.
Estimateur de la taille de la population de cerfs sous une perte
asym´etrique (4.9).
n11
0
1
2
3
4
5
δπ(n11)
37 37 37 36 36 36
Une application bay´esienne tr`es int´eressante de l’inf´erence du mod`ele de
capture-recapture est donn´ee par Mosteller et Wallace (1984). Elle concerne
l’authentiﬁcation d’œuvres par la linguistique statistique lorsque l’origine de
certaines de ces œuvres est incertaine. Par exemple, Mosteller et Wallace
(1984) ´etudient les Federalist Papers, une collection d’articles ´ecrits en 1787
aﬁn de soutenir la nouvelle Constitution des ´Etats-Unis. Douze de ces articles
sont attribu´es soit `a Hamilton, soit `a Madison. `A partir d’´ecrits authentiﬁ´es
de ces deux auteurs, Mosteller et Wallace (1984) calculent la fr´equence des
trente mots les plus courants et, en utilisant l’approche du mod`ele de capture-
recapture, d´eduisent que les douze articles auraient ´et´e ´ecrits par Madison.
Efron et Thisted (1976) ont aussi utilis´e cette m´ethode dans l’´etude du vo-
cabulaire de Shakespeare pour authentiﬁer plus tard dans Thisted et Efron
(1987) un po`eme r´ecemment d´ecouvert comme ayant ´et´e eﬀectivement ´ecrit
par Shakespeare.
4.4 Le cas particulier du mod`ele normal
4.4.1 Introduction
Lorsque Gauss introduisit la distribution normale aux alentours de 1810,
Laplace estima qu’il s’agissait en fait de la loi d’erreur id´eale (voir l’Exemple
1.12). Par la suite, s’appuyant sur le Th´eor`eme Central Limit, les statisticiens
de la premi`ere moiti´e du XIXi`eme si`ecle se r´ef´eraient presque toujours `a la
distribution normale (Stigler, 1986). Il y a, bien sˆur, de nombreux ph´enom`enes
pour lesquels un mod`ele normal n’est pas applicable, mais ce dernier reste

4.4 Le cas particulier du mod`ele normal
199
consid´erablement utilis´e, en particulier en ´econom´etrie et dans des domaines
o`u on peut justiﬁer l’approximation du Th´eor`eme Central Limit (physique
particulaire, etc.). En r´ealit´e, l’approximation normale est souvent justiﬁ´ee
par des raisons asymptotiques (voir aussi Cox et Reid, 1987). Il est donc
int´eressant d’´etudier en d´etail cette distribution particuli`ere d’un point de
vue bay´esien.
Pour l’observation d’une distribution normale multivari´ee, Np(θ, Σ), de
matrice de covariance connue Σ, la loi conjugu´ee est aussi normale, Np(μ, A),
et la loi a posteriori π(θ|x) est
Np
	
x −Σ(Σ + A)−1(x −μ), (A−1 + Σ−1)−1
.
Sous un coˆut quadratique, l’estimateur de Bayes est alors la moyenne a pos-
teriori
δπ(x) = x −Σ(Σ + A)−1(x −μ)
=
	
Σ−1 + A−1
−1 	
Σ−1x + A−1μ

;
notons que δπ(x) peut s’´ecrire comme une combinaison convexe de l’observa-
tion, x, et de la moyenne a priori, μ, les poids ´etant proportionnels `a l’inverse
de la matrice de covariance.
Plus l’information a priori sur θ est pr´ecise, plus proche de μ est l’esti-
mateur de Bayes. Notons aussi que l’information a priori (resp., l’observation
de x) apporte une r´eduction de la variance de Σ (respectivement, de A) `a
	
Σ−1 + A−1
−1. Pour des observations r´ep´et´ees du mod`ele normal ci-dessus,
x1, ..., xn, la statistique exhaustive
¯x = 1
n
n

i=1
xi ∼Np

θ, 1
nΣ

´etend directement l’analyse pr´ec´edente.
Une critique d´ej`a ´evoqu´ee dans le Chapitre 3 est que les lois a priori
conjugu´ees normales ne sont pas assez robustes et qu’il serait pr´ef´erable d’uti-
liser une loi de Student pour π(θ). La loi de Cauchy, cas limite d’une loi de
Student, peut alors ˆetre utilis´ee en raison de ses queues plus lourdes, mais
elle empˆeche encore un calcul exact (voir l’Exemple 4.7), mˆeme si Angers
(1992) propose une solution analytique reposant sur des fonctions conﬂuentes
hyperg´eom´etriques.
4.4.2 Estimation de la variance
Dans la plupart des cas, la variance du mod`ele est partiellement ou tota-
lement inconnue. Il est alors n´ecessaire de consid´erer des lois a priori pour le
param`etre (θ, Σ). Si la variance est connue `a une constante multiplicative pr`es,

200
4 Estimation bay´esienne ponctuelle
σ2, il est g´en´eralement possible de revenir `a un cadre unidimensionnel, c’est-
`a-dire lorsque x1, . . . , xn sont i.i.d. N (θ, σ2), pour des raisons d’exhaustivit´e.
(Le cas particulier o`u seul σ2 est inconnu est trait´e dans les Tableaux 3.4 et
4.4.) Si nous d´eﬁnissons les statistiques ¯x = 1
n
n
i=1 xi et s2 = n
i=1(xi −¯x)2,
la vraisemblance peut s’´ecrire
ℓ(θ, σ | ¯x, s2) ∝σ−n exp

−1
2σ2
%
s2 + n (¯x −θ)2&
et l’estimateur de Bayes ne d´epend que de ¯x et s2. Nous indiquons dans
l’Exemple 3.30 que la loi de Jeﬀreys pour ce mod`ele est π∗(θ, σ) = 1/σ2 et
mentionnons qu’il est pr´ef´erable de consid´erer la loi alternative ˜π(θ, σ) = 1/σ
pour des raisons d’invariance. Dans ce cas,
ℓ(θ, σ | ¯x, s2)˜π(θ, σ) ∝σ−n−1 exp

−1
2σ2
%
s2 + n (¯x −θ)2&
.
(4.10)
Donc,
Proposition 4.20. Si x1, . . . , xn sont i.i.d. N (θ, σ2), la loi a posteriori de
(θ, σ) associ´ee `a ˜π est
θ|σ, ¯x, s2 ∼N

¯x, σ2
n

,
σ2|¯x, s2 ∼I G
n −1
2
, s2
2

.
(4.11)
L’´equation (4.11) d´eﬁnit vraiment la loi a posteriori de (θ, σ2), car elle
fournit la loi marginale de σ2 et la loi de θ conditionnellement `a σ2. La
d´emonstration de cette proposition est une cons´equence directe de (4.10),
puisque
˜π(θ, σ2|¯x, s2) ∝σ−1e−n(¯x−θ)2/2σ2σ−ne−s2/2σ2σ−1,
et la loi gamma inverse I G(α, β) a pour densit´e
π(x|α, β) =
βα
Γ(α)xα+1 e−β/xI(0,+∞)(x).
(4.12)
Par cons´equent, la loi a posteriori marginale de σ2 est du mˆeme type que
lorsque θ est connu. En revanche, la loi marginale a posteriori de θ diﬀ`ere, car
il vient de (4.11) que
˜π(θ|¯x, s2) ∝

s2 + n(¯x −θ)2−n/2 ,
c’est-`a-dire
θ|¯x, s2 ∼T1

n −1, ¯x,
s2
n(n −1)

.
(4.13)

4.4 Le cas particulier du mod`ele normal
201
Pour la loi de Jeﬀreys, π∗, l’´equivalent de (4.13) est une loi de Student `a n
degr´es de libert´e, qui est toujours d´eﬁnie, tandis que (4.13) n’est d´eﬁnie que
pour n ≥2. (Notons que l’exclusion de n = 1 pourrait s’interpr´eter comme un
argument suppl´ementaire en faveur de ˜π, car, dans un cadre non informatif,
il paraˆıt diﬃcile de proposer une inf´erence sur le param`etre (θ, σ) tout entier
avec une seule observation.)
Les lois a posteriori conjugu´ees ont naturellement la mˆeme forme que
(4.11). Ces lois pr´esentent cependant une curieuse particularit´e, `a savoir que
θ et σ2 ne sont pas ind´ependants a priori. Par cons´equent, la loi a priori de
la moyenne θ d´epend de la pr´ecision associ´ee `a la mesure de la moyenne. Cer-
tains cadres d’application peuvent justiﬁer cette d´ependance34, mais ceci n’est
pas vrai pour tous les probl`emes d’estimation et cette loi peut encore moins
ˆetre consid´er´ee comme une loi a priori repr´esentative standard (voir Berger,
2000). Cependant, ces critiques subjectives ne se doublent pas de propri´et´es
particuli`erement n´egatives des estimateurs r´esultants.
Soit alors
π(θ, σ2) = π1(θ|σ2)π2(σ2),
o`u π1 est une distribution normale N (μ, σ2/n0) et π2 est une loi gamma
inverse I G(ν/2, s2
0/2). La loi a posteriori satisfait
π(θ, σ2|x) ∝σ−n−ν−3 exp

−1
2
#
s2 + s2
0 + n0(θ −μ)2 + n(¯x −θ)2$
/σ2

= σ−n−ν−3 exp

−1
2
#
s2
1 + n1(θ −θ1)2$
/σ2

,
o`u
n1 = n + n0,
θ1 = 1
n1
(n0θ0 + n¯x) ,
s2
1 = s2 + s2
0 +
	
n−1
0
+ n−1
−1 (θ0 −¯x)2 .
Ces lois sont en r´ealit´e conjugu´ees car
π
	
θ|¯x, s2, σ

∝1
σ exp

−n1(θ −θ1)2
2σ2

,
π
	
σ2|¯x, s2
∝σ−n−ν−2 exp

−s2
1/2σ2
.
Comme dans le cas non informatif, la loi a posteriori marginale de θ est une
loi de Student. Notons que, sauf lorsque π est construit `a partir d’observa-
tions pr´ec´edentes (ou virtuelles), n0 n’est pas une taille d’´echantillon ; n0/n
caract´erise plutˆot la pr´ecision de la d´etermination de la loi a priori, relati-
vement `a la pr´ecision des observations. En g´en´eral, n0 est plus petit que la
34Lorsque la loi a priori est construite `a partir d’observations pass´ees, il est logique
que la variance a priori de θ d´epende de σ2 (conditionnellement).

202
4 Estimation bay´esienne ponctuelle
taille d’´echantillon n. Notons aussi que, si n0/n tend vers 0, nous obtenons le
cas limite θ|¯x, σ2 ∼N (¯x, σ2/n), correspondant `a la loi a posteriori associ´ee
`a la loi a priori de Jeﬀreys. Voici donc un exemple suppl´ementaire du fait
que les lois non informatives se pr´esentent souvent comme des limites de lois
conjugu´ees.
L’inf´erence statistique fond´ee sur la loi conjugu´ee ci-dessus n´ecessite une
d´etermination pr´ecise des hyperparam`etres (θ0, s2
0, n0, ν), aﬁn d’obtenir l’ex-
pression des estimateurs de Bayes. Si la d´etermination de θ0 et n0 est plutˆot
classique, il est g´en´eralement plus diﬃcile d’avoir une information a priori sur
σ2. Rappelons que, si σ2 ∼I G(ν/2, s2
0/2), les deux premiers moments sont
donn´es par (ν > 4)
Eπ #
σ2$
=
s2
0
ν −2,
varπ(σ2) =
2s4
0
(ν −2)2(ν −4).
Ces formules peuvent alors s’utiliser pour mod´eliser une information a priori
sous une forme conjugu´ee, c’est-`a-dire pour d´eterminer s2
0 et ν.
Lorsque le param`etre (θ, Σ) est totalement inconnu, il reste possible de
construire des lois a priori conjugu´ees. Pour n observations x1, . . . , xn de
Np(θ, Σ), une statistique exhaustive est
¯x = 1
n
n

i=1
xi,
S =
n

i=1
(xi −¯x)(xi −¯x)t,
et
ℓ(θ, Σ|¯x, S) ∝|Σ|−n/2 exp −1
2

n(¯x −θ)tΣ−1(¯x −θ) + tr(Σ−1S

}.
La forme de la fonction de vraisemblance sugg`ere alors les lois conjugu´ees
suivantes :
θ|Σ ∼Np

μ, Σ
n0

,
Σ−1 ∼Wp(α, W),
(4.14)
o`u Wp indique la loi de Wishart, d´eﬁnie dans l’Exercice 3.21. Les lois a pos-
teriori sont alors
θ|Σ, ¯x, S ∼Np
n0μ + n¯x
n0 + n ,
Σ
n0 + n

,
Σ−1|¯x, S ∼Wp (α + n, W1(¯x, S)) ,
avec
W1(¯x, S)−1 = W −1 + S +
nn0
n + n0
(¯x −μ)(¯x −μ)t.
Notons que ce cas multidimensionnel est la g´en´eralisation du cas unidimen-
sionnel consid´er´e au-dessus, car la loi de Wishart Wp est la g´en´eralisation

4.4 Le cas particulier du mod`ele normal
203
en dimension p d’une loi du khi deux. Rappelons ici que les deux premiers
moments de Ξ = (ξij) ∼Wp(α, W) sont
E[Ξ] = αW,
var(ξij) = 2αw2
ij,
et que les hyperparam`etres de la loi a priori de Σ peuvent se calculer `a partir
de
E[Σ] =
W −1
α −p −1,
var(σij) =
2(wij)2
(α −p −3)(α −p −1)2 ,
pour Σ−1 ∼Wp(α, W) et W −1 = (wij) (Eaton, 1982, Anderson, 1984).
Dans ce cadre, la loi de Jeﬀreys est aussi un cas limite des lois conjugu´ees,
car Geisser et Cornﬁeld (1963) ont montr´e qu’elle vaut
πJ(θ, Σ) =
1
|Σ|(p+1)/2 ,
et donc qu’elle correspond `a la limite de lois de Wishart Wp(α, W) pour Σ−1
lorsque W −1 tend vers O et α vers 0. En eﬀet, la densit´e de Σ lorsque Σ−1 ∼
Wp(α, W) est
f(Σ|α, W) ∝|Σ|−(α+p+1)/2 exp

−1
2tr(W −1Σ−1)

(Anderson, 1984).
4.4.3 Mod`eles lin´eaires et G-priors
Le mod`ele standard de r´egression,
y = Xβ + ϵ,
(4.15)
avec ϵ ∼Nk(0, Σ), β ∈Rp, peut s’analyser de la mˆeme fa¸con que dans la
partie pr´ec´edente lorsque la matrice de covariance Σ est connue, si on travaille
conditionnellement `a X. En eﬀet, une statistique exhaustive est alors
ˆβ = (XtΣ−1X)−1XtΣ−1y ,
estimateur du maximum de vraisemblance et des moindres carr´es de β. Celui-
ci est distribu´e selon une loi Np(β, (XtΣ−1X)−1).
Lindley et Smith (1972) ont ´etudi´e des lois conjugu´ees du type
β ∼Np(Aθ, C),
o`u θ ∈Rq (q ≤p). Dans ce mod`ele, la matrice de r´egression X est consid´er´ee
comme constante. En d’autres termes, l’inf´erence est faite conditionnellement
`a X. (Habituellement, X est aussi partiellement al´eatoire, mais ce condition-
nement est justiﬁ´e par le principe de vraisemblance du moment que la loi de

204
4 Estimation bay´esienne ponctuelle
X ne d´epend pas des param`etres du mod`ele de r´egression.) Par cons´equent,
A, C, ou θ peuvent d´ependre de X (voir ci-dessous pour l’exemple des lois
a priori simpliﬁ´ees de Zellner, 1971). Lorsque la nature stochastique de X
doit ˆetre consid´er´ee, l’approche habituelle est d’´etudier un mod`ele `a eﬀets
al´eatoires,
y = X1β1 + X1X2β2 + ϵ,
qui peut se d´ecomposer en
y|θ1 ∼Nk(X1θ1, Σ1),
θ1|θ2 ∼Np(X2θ2, Σ2),
avec pour loi a priori
θ2|θ3 ∼Nq(X3θ3, Σ3).
Smith (1973) analyse ce mod`ele et montre que
θ1|y, θ3 ∼Np(θ∗
1, D1),
avec
θ∗
1 = D1
4
ˆD−1
1 ˆθ1 + (Σ2 + X2Σ3Xt
2)−1X2X3θ3
5
,
D−1
1
= ˆD−1
1
+ (Σ2 + X2Σ3Xt
2)−1,
fonction des estimateurs des moindres carr´es classiques
ˆD−1
1
= Xt
2Σ−1
1 X2,
ˆθ1 = ˆD1Xt
2Σ−1
1 y.
Par cons´equent, l’estimateur de Bayes θ∗
1 est une combinaison convexe de
l’estimateur des moindres carr´es, ˆθ1 et de la moyenne a priori, X2X3θ3.
Nous introduisons ci-dessous un exemple o`u une structure de variance
inconnue permet toujours un calcul analytique des estimateurs de Bayes. Ce-
pendant, si la variance Σ est totalement inconnue, il n’est pas possible de
construire des lois a priori conjugu´ees, comme l’avaient remarqu´e Lindley et
Smith (1972). Press (1989) propose une solution dans un cas particulier o`u
des observations ind´ependantes sont disponibles. Dans un cas g´en´eral, la loi a
priori de Jeﬀreys est de nouveau (Geisser et Cornﬁeld, 1963)
πJ(β, Σ) =
1
|Σ|(k+1)/2 .
La vraisemblance
ℓ(β, Σ|y) ∝|Σ|−n/2 exp

−1
2tr

Σ−1
n

i=1
(yi −Xiβ)(yi −Xiβ)t

sugg`ere alors d’utiliser les lois de Wishart, mais les lois a posteriori marginales
sur β ne sont d´eﬁnies que pour des ´echantillons de taille suﬃsamment grande

4.4 Le cas particulier du mod`ele normal
205
et, de plus, elles ne sont pas explicites, quelle que soit la taille de l’´echantillon
(voir l’Exercice 4.45).
Dans le cas particulier o`u la variance du mod`ele (4.15) est connue `a un
facteur multiplicatif σ2 pr`es, il est possible de r´e´ecrire le mod`ele comme ϵ ∼
Nk(0, σ2Ik) et l’estimateur des moindres carr´es ˆβ a une distribution normale
Np(β, σ2(XtX)−1). Une famille de lois conjugu´ees pour (β, σ2) est alors
β|σ2 ∼Np

μ, σ2
n0
(XtX)−1

,
σ2 ∼I G(ν/2, s2
0/2),
(4.16)
car, si s2 = ||y −X ˆβ||2, les lois a posteriori sont
β|ˆβ, s2, σ2 ∼Np

n0μ + ˆβ
n0 + 1 ,
σ2
n0 + 1(XtX)−1
 
,
σ2|ˆβ, s2 ∼I G

k −p + ν
2
,
s2 + s2
0 +
n0
n0+1(μ −ˆβ)tXtX(μ −ˆβ)
2
 
.
En eﬀet,
π(β, σ2|ˆβ, s2) ∝(σ2)−k/2 exp

−1
2σ2
%
(β −ˆβ)tXtX(β −ˆβ) + s2&
× exp

−n0
2σ2 (β −μ)tXtX(β −μ)

σ2)−ν/2−1 exp

−s2
0
2σ2

∝(σ2)−p/2 exp
⎧
⎨
⎩−n0 + 1
2σ2

β −n0μ + ˆβ
n0 + 1
 t
XtX

β −n0μ + ˆβ
n0 + 1
 ⎫
⎬
⎭
×σ−(k−p+ν+2) exp

−1
2σ2

s2
0 + s2 +
n0
n0 + 1(μ −ˆβ)tXtX(μ −ˆβ)

.
Bien que (4.16) ne soit qu’un cas particulier de loi conjugu´ee, plusieurs cri-
tiques se sont ´elev´ees contre ce choix, d´evelopp´e par Zellner (1971, 1986b) sous
le nom de G-priors ou a priori simpliﬁ´es35. Ces critiques ne s’adressent pas
pour la plupart au probl`eme de l’aspect r´educteur d’un mod`ele conjugu´e,
un argument assez l´egitime d´ej`a ´evoqu´e au Chapitre 3, mais plutˆot `a la
d´ependance de la loi a priori `a X. On peut soutenir que X est aussi une
variable al´eatoire et par cons´equent qu’un mod`ele a priori ne devrait pas
d´ependre de X. En fait, les lois a priori alternatives
β|σ ∼Np(β0, σ2A)
constituent aussi une famille conjugu´ee qui est moins critiquable lorsque A est
ﬁx´e. Cependant, nous consid´erons que le d´ebat est plutˆot vide de sens car :
35Le nom de G-priors provient de l’utilisation dans l’article originel du symbole
g comme facteur de σ2(XtX)−1 dans (4.16).

206
4 Estimation bay´esienne ponctuelle
(1) Le mod`ele de r´egression est enti`erement conditionnel aux variables
explicatives. La loi a priori (4.16) peut se voir comme une loi a poste-
riori par rapport `a ces variables (ou, pour ´elargir l’hypoth`ese habituelle
d’ind´ependance entre les variables explicatives et les erreurs, comme
l’hypoth`ese de l’ind´ependance bay´esienne avec les param`etres). Cette
approche est alors justiﬁ´ee par les points de vue conditionnel et bay´esien,
le conditionnement ´etant alors ´etabli en deux ´etapes.
(2) Un G-prior sugg`ere une distribution constante pour la moyenne de
y, θ = Eθ[y|X], plutˆot que pour β. La loi a priori est alors d´etermin´ee
par rapport au sous-espace g´en´er´e par les colonnes de X et non pas par
rapport `a une base sp´eciale de ce sous-espace.
(3) Ce mod`ele est ad´equat pour la prise en compte des probl`emes de mul-
ticolin´earit´e, car il permet d’assigner une grande variance a priori aux
composantes aﬀect´ees par la multicolin´earit´e (donc plus diﬃciles `a es-
timer). (Voir Zellner, 1971, Casella, 1985a, ou Steward, 1987, pour des
r´ef´erences sur la multicolin´earit´e.)
(4) Des points de vue pratique et subjectif, la d´etermination a priori
d’une matrice A plutˆot que d’un scalaire n0 n´ecessite une plus grande
quantit´e d’information a priori. Puisque le recours aux lois conjugu´ees
est caract´eristique des cas o`u l’information a priori est rare et o`u la
d´etermination des hyperparam`etres est assez diﬃcile, l’utilisation de la
matrice de covariance σ2(XtX)−1/n0 ´evite une d´etermination probable-
ment irr´ealiste de A.
Notons de nouveau que ces attaques contre les G-priors mentionnent `a peine
leur d´esavantage majeur, `a savoir que leur choix n’est pas totalement fond´e sur
l’information a priori. Pour des applications des G-priors dans des probl`emes
de r´egression, voir Ghosh et Sen (1989) ou Blattberg et George (1991). Voir
Bauwens et al. (1999, Chapitre 4) pour des alternatives aux lois a priori
conjugu´ees pour les mod`eles lin´eaires, comme les lois a priori poly-t (voir la
Note 4.7.5 ci-dessous).
4.5 Mod`eles dynamiques
4.5.1 Introduction
Les mod`eles dynamiques (ou de s´eries temporelles) apparaissent comme
un mod`ele param´etrique o`u la distribution des variables observ´ees x1, . . . , xT
varie dans le temps, c’est-`a-dire
f(x1, . . . , xT |θ) =
T

t=1
ft(xt|x1:(t−1), θ) ,
(4.17)
o`u x1:(t−1) indique le vecteur des variables pr´ec´edentes x1, . . . , xt−1, avec la
convention que x1:0 est soit vide, soit repr´esente la valeur initiale x0 d’une suite

4.5 Mod`eles dynamiques
207
d’observations (il est alors implicite dans le terme de gauche de (4.17)). Bien
que la repr´esentation (4.17) semble ˆetre inutilement restrictive, l’inclusion de
composants non observ´es dans xt fournit une perspective assez large pour ce
mod`ele, comme cela sera expliqu´e dans le paragraphe sur les repr´esentations
par espace d’´etat.
Ces mod`eles sont ´evidemment des cas sp´eciaux de mod`eles param´etriques
et, en tant que tels, peuvent donc ˆetre trait´es comme d’autres mod`eles pa-
ram´etriques par les outils bay´esiens, une fois la loi a priori choisie, suivant
les indications fournies dans les sections pr´ec´edentes. Ils sont isol´es dans cette
section pour plusieurs raisons : premi`erement, il s’agit des mod`eles les plus
couramment utilis´es dans des applications allant de la Finance et l’´Economie
jusqu’aux exp´eriences m´edicales et l’´ecologie. La plupart des mod`eles ren-
contr´es dans la pratique pr´esentent une dimension temporelle qui peut parfois
ˆetre dissimul´ee, mais qui le plus souvent doit ˆetre prise en compte. C’est claire-
ment le cas pour des donn´ees de pollution, comme les niveaux de concentration
d’ozone, ou les cours d’action, pour lesquelles la valeur au temps t d´epend de
la valeur pr´ec´edente et aussi des valeurs ant´erieures, par exemple `a travers
leur tendance.
Exemple 4.21. (Suite de l’Exemple 4.6) Le mod`ele autor´egressif AR(1)
est plus g´en´eralement d´eﬁni par la loi de xt conditionnellement `a x1:(t−1)
(1 ≤t ≤T ),
xt = μ + ϱ(xt−1 −μ) + ϵt ,
(4.18)
o`u ϵt est ind´ependant de x1:(t−1) et suit, par exemple, une loi N (0, σ2). La
distribution de xt sachant x1:(t−1) ne d´epend que de xt−1, ce qui prouve que
(xt) est une chaˆıne de Markov (Meyn et Tweedie, 1993).
La fonction de vraisemblance du mod`ele AR(1) est alors
σ−T exp

−1
2σ2
T

i=1
(xt −μ + ϱ(xt−1 −μ))2

et d´epend donc de la condition initiale x0. Soit x0 est connu et le mod`ele
est alors conditionnel `a x0, soit x0 a ´et´e int´egr´e en prenant pour loi a priori
π(x0|θ) et x0 est alors un param`etre additionnel du mod`ele. Par exemple, si
x0 = 0, il est simple de voir que Eθ[xt] = 0 et que var(xt) = ϱ2var(xt−1) + σ2,
donc, si ϱ2 ̸= 1,
var(xt) = 1 −ϱ2t
1 −ϱ2 σ2 ,
(4.19)
ce qui implique que var(xt) converge vers σ2/(1 −ϱ2) si ϱ2 < 1 et tend vers
+∞sinon.
∥
La seconde motivation pour ´etudier les mod`eles dynamiques est que
ceux-ci repr´esentent un plus grand d´eﬁque les mod`eles statiques ´etudi´es

208
4 Estimation bay´esienne ponctuelle
pr´ec´edemment, de par les contraintes de stationnarit´e. Bien que nous ne puis-
sions pas pr´esenter une introduction rigoureuse de la notion de stationnarit´e
pour les processus stochastiques (nous renvoyons les lecteurs `a Meyn et Twee-
die, 1993, pour une pr´esentation g´en´erale des processus de Markov et `a Box
et Jenkins, 1976 ou Brockwell et Davis, 1998, pour le cas sp´ecial des s´eries
temporelles), rappelons ici qu’un processus (xt) est stationnaire (ou stricte-
ment stationnaire) si la distribution de (xt+1, . . . , xt+d) est la mˆeme que la
distribution de (x1, . . . , xd) pour tout (t, d). Le probl`eme de la stationnarit´e
peut s’illustrer dans le cadre de l’Exemple 4.6 : lorsque ϱ2 ≥1, non seulement
la variance var(xt) tend vers l’inﬁni avec t, mais de plus le comportement
limite de la chaˆıne (xt) ne peut pas ˆetre caract´eris´e. Le processus (xt) n’a pas
de distribution limite, car la chaˆıne de Markov n’admet pas de distribution
stationnaire, c’est-`a-dire qu’il n’existe pas de densit´e f telle que, si xt ∼f,
xt+1 ∼f (Exercice 4.51). Par exemple, si ϱ = 1, (xt) est la marche al´eatoire
dans R et, en moyenne, elle prend un temps inﬁni pour revenir `a l’ensemble
d’o`u elle est partie (Meyn et Tweedie, 1993).
Imposer la stationnarit´e d’un mod`ele est critiquable du fait que les donn´ees
elles-mˆemes devraient indiquer si le mod`ele sous-jacent est stationnaire. Ce-
pendant, pour des raisons allant de l’asymptotique `a la causalit´e, en passant
par l’identiﬁabilit´e (voir ci-dessous) et la pratique g´en´erale, il est courant
d’imposer cette condition, mˆeme si l’inf´erence bay´esienne d’un processus non
stationnaire peut ˆetre conduite en principe (voir la Note 4.7.2). De telles
contraintes se traduisent dans la distribution a priori par une restriction sur
les valeurs de θ. Par exemple, pour le mod`ele AR(1) de l’Exemple 4.6, la
contrainte est |ϱ| < 1. La diﬃcult´e pratique est que, pour des mod`eles plus
complexes, les contraintes de stationnarit´e peuvent devenir beaucoup plus exi-
geantes et sont mˆeme inconnues dans certains cas, comme dans les mod`eles `a
seuil g´en´eraux (Tong, 1991).
Exemple 4.22. Le mod`ele AR(p) g´en´eralise le mod`ele AR(1) en augmentant
la d´ependance sur les valeurs pass´ees, c’est-`a-dire (1 ≤t ≤T ),
xt −μ =
p

i=1
ϱi(xt−i −μ) + ϵt ,
ϵt ∼N (0, σ2) .
(4.20)
Le processus stochastique d´eﬁni par (4.20) est alors stationnaire si et seule-
ment si les racines du polynˆome
P(x) = 1 −
p

i=1
ϱixi
sont toutes `a l’ext´erieur du cercle unit´e dans le plan complexe (voir Brockwell
et Davis, 1998, Section 3.1). Bien que cette condition soit clairement d´eﬁnie,
elle est aussi implicite par rapport au vecteur (ϱ1, . . . , ϱp) : pour v´eriﬁer qu’un
vecteur donn´e satisfait cette condition, il est n´ecessaire de trouver les racines

4.5 Mod`eles dynamiques
209
du polynˆome P et de s’assurer qu’elles sont toutes de module plus grand
que 1, ou de calculer les autocorr´elations partielles (voir la Section 4.5.2) et
d’appliquer le lemme de Schur pour v´eriﬁer qu’elles sont toutes entre −1 et
1.
∥
Exemple 4.23. Un mod`ele AR(p) `a sauts (traduction de switching AR) est
d´eﬁni comme un mod`ele AR(p) dont les param`etres changent dans le temps
selon un processus de Markov cach´e (ou non observ´e) `a espace d’´etat ﬁni,
c’est-`a-dire
xt =
p

i=1
ϱi(zt)xt−i + σ(zt)ϵt ,
ϵt ∼N (0, 1) ,
(4.21)
o`u (zt) est la chaˆıne de Markov non observ´ee,
P(zt = i|zt−1 = j, zt−2, . . .) = πj,i ,
i, j = 1, . . . , K .
Ce mod`ele a ´et´e introduit par Hamilton (1989) comme une fa¸con de repr´esenter
des s´eries avec des dynamiques variant dans le temps, comme la s´erie de la
Figure 4.2 qui est une transformation des cours de l’action IBM entre 1992
et 1997. Une diﬃcult´e avec le mod`ele (4.21) est qu’il n’existait pas de condi-
tion n´ecessaire et suﬃsante de stationnarit´e lorsque le nombre d’´etats K de la
chaˆıne de Markov cach´ee (zt) est plus grand que 2, jusqu’aux d´eveloppements
r´ecents de Francq et Zako¨ıan (2001) et Yao et Attali (2000).
∥
0
100
200
300
400
500
−10
−9
−8
−7
−6
jours
Fig. 4.2. Trac´e du logarithme des cours de l’action IBM sur la p´eriode 1992-1997.
Nous d´eveloppons dans les Sections 4.5.2-4.5.4 quelques caract´eristiques
des mod`eles dynamiques standard, `a savoir, les mod`eles AR, MA et ARMA,

210
4 Estimation bay´esienne ponctuelle
en nous concentrant sur les probl`emes de repr´esentation et de mod´elisation a
priori sous condition de stationnarit´e. Les Notes 4.7.3 et 4.7.4 pr´esentent deux
autres mod`eles dynamiques souvent rencontr´es dans la pratique. On pourra
consulter West et Harrison (1998) pour une approche g´en´erale du traitement
bay´esien des s´eries temporelles et Bauwens et al. (1999) pour une monographie
´econom´etrique sur ce sujet.
4.5.2 Le mod`ele AR
Comme pr´esent´e dans l’Exemple 4.22, le mod`ele AR(p) exprime la dis-
tribution de xt conditionnellement au pass´e x1:(t−1) comme une r´egression
lin´eaire normale sur les p variables les plus r´ecentes, c’est-`a-dire (t = 1, 2, . . .),
xt ∼N

μ −
p

i=1
ϱi(xt−i −μ), σ2
 
,
(4.22)
o`u le param`etre de position μ est introduit pour plus de g´en´eralit´e. Notons que
ce mod`ele est markovien, car la distribution de xt ne d´epend que d’un nombre
ﬁxe de valeurs pass´ees, x(t−p):(t−1), et qu’il peut s’exprimer comme une chaˆıne
de Markov r´eguli`ere en consid´erant le vecteur zt = xt:(t−p+1), c’est-`a-dire
zt = (xt, xt−1, . . . , xt−p+1) ,
car
zt = μ1 + B(zt−1 −μ1) + εt ,
(4.23)
o`u
1 = (1, . . . , 1)t ,
B =
⎛
⎜
⎜
⎜
⎝
ϱ1 ϱ2 . . . ϱp
1 0 . . . 0
...
0 0
0
⎞
⎟
⎟
⎟
⎠
et
εt = (ϵt, 0, . . . , 0)t .
Puisque la vraisemblance conditionnelle aux valeurs n´egatives du temps
x0, . . . , x−p+1 peut s’´ecrire
L(μ, ϱ1, . . . , ϱp, σ|x1:T , x0:(−p+1)) =
(4.24)
σ−T
T

t=1
exp
⎧
⎨
⎩−

xt −μ +
p

i=1
ϱi(xt−i −μ)
 2 6
2σ2
⎫
⎬
⎭,
il est possible de trouver une loi a priori conjugu´ee naturelle pour le param`etre
θ = (μ, ϱ1, . . . , ϱp, σ2), c’est-`a-dire une distribution normale sur (μ, ϱ1, . . . , ϱp)
et une loi inverse gamma sur σ2. `A la place de la loi a priori de Jeﬀreys, qui est
controvers´ee dans ce cadre (voir la Note 4.7.2), nous pouvons aussi proposer
une loi a priori non informative plus courante comme π(μ, σ, ϱ) = 1/σ.

4.5 Mod`eles dynamiques
211
Si nous imposons la contrainte de stationnarit´e que toutes les racines de
P soient en dehors du cercle unit´e, l’espace des param`etres est trop complexe
pour des valeurs de p plus grandes que 3 pour proposer comme loi a priori
la loi conjugu´ee normale restreinte `a cet espace : par exemple, simuler cette
loi est trop coˆuteux. Une solution, appel´ee r´ecurrence de Durbin-Levinson
(voir Monahan, 1984), est de proposer une reparam´etrisation des param`etres
ϱi en les autocorr´elations partielles ψi (Exercice 4.54) qui satisfont, sous la
contrainte de stationnarit´e,
ψi ∈(−1, 1) , i = 1, · · · , p ,
et permettent alors une loi a priori uniforme36. Le r´esultat suivant fournit une
connexion constructive entre (ϱ1, . . . , ϱp) et (ψ1, . . . , ψp).
Lemme 4.24. Sous la stationnarit´e du mod`ele (4.22), les coeﬃcients ϱi se
d´eduisent des coeﬃcients ψi par l’algorithme suivant :
Algorithme 4.1. R´ecurrence de Durbin-Levinson
0. D´eﬁnir ϕii = ψi et ϕij = ϕ(i−1)j−ψiϕ(i−1)(i−j), pour i > 1 et j = 1, · · · , i−1.
1. Prendre ϱi = ϕpi pour i = 1, · · · , p.
Bien que les lois a priori et a posteriori de (ϱ1, . . . , ϱp) r´esultantes ne soient
pas explicites, au sens o`u le calcul de la loi a priori (ou a posteriori) pour une
valeur donn´ee du param`etre est assez coˆuteuse en temps, cette repr´esentation
peut s’exploiter en simulation, comme dans le Chapitre 6 (voir aussi Barnett
et al., 1996), `a cause de la lin´earit´e de la relation entre les ϱj et un ψi donn´e,
conditionnellement aux autres ψℓ. Huerta et West (1999) proposent une ap-
proche diﬀ´erente reposant sur les racines r´eelles et complexes du polynˆome
P, qui, invers´ees, sont aussi `a l’int´erieur de l’unit´e du cercle.
4.5.3 Le mod`ele MA
Un r´esultat fondamental en th´eorie des processus stochastiques est la
d´ecomposition de Wold, qui ´enonce que la plupart des processus stationnaires
(xt) peuvent se repr´esenter sous la forme (t = 1, 2, . . .)
xt = μ +
∞

i=0
ψiϵt−i ,
(4.25)
o`u ψ0 = 1 et (ϵt) est un bruit blanc, c’est-`a-dire une s´equence de variables
al´eatoires de moyenne nulle, de variance ﬁxe et de covariance nulle ; voir Box
et Jenkins (1976) pour des d´etails th´eoriques.
36Les autocorr´elations partielles, dites aussi coeﬃcients de r´eﬂexion dans la
litt´erature de traitement du signal, peuvent s’utiliser pour tester la stationnarit´e,
car, selon le lemme de Schur, elles doivent toutes ˆetre entre −1 et 1 pour que la
chaˆıne (xt) soit stationnaire.

212
4 Estimation bay´esienne ponctuelle
Exemple 4.25. (Suite de l’Exemple 4.6)
Si xt = ϱxt−1 + ϵt, xt peut
s’´ecrire aussi
xt = ϵt + ϱϵt−1 + ϱ2ϵt−2 + . . .
si |ϱ| < 1.
∥
Le mod`ele MA(q), MA signiﬁant moving average (moyenne mobile), est
un cas sp´ecial de (4.25) lorsque les ψi sont ´egaux `a 0 pour i > q, c’est-`a-dire
xt = μ + ϵt −
q

j=1
ϑjϵt−j ,
ϵt ∼N (0, σ2)
(4.26)
En contraste avec le mod`ele AR(1), o`u la covariance entre les termes de la s´erie
d´ecroissent exponentiellement vers 0 mais sont toujours non nuls, le processus
MA(q) est tel que les autocovariances
γs = cov(xt, xt+s)
sont ´egales `a 0 pour |s| > q. Selon la d´ecomposition de Wold, le processus
MA(q) est stationnaire, quel que soit le vecteur (ϑ1, . . . , ϑq). Cependant, des
consid´erations d’inversibilit´e et d’identiﬁabilit´e (voir l’Exercice 4.59) m`enent
`a la condition que le polynˆome
Q(x) = 1 −
q

j=1
ϑjxj
doit avoir toutes ses racines en dehors du cercle unit´e.
Exemple 4.26. Dans le cas particulier du mod`ele MA(1), xt = μ+ϵt−ϑ1ϵt−1
et var(xt) = (1 + ϑ2
1)σ2, avec γ1 = ϑ1σ2. Alors xt peut aussi s’´ecrire comme
xt = μ + ˜ϵt−1 −1
ϑ1
˜ϵt,
˜ϵ ∼N (0, ϑ2
1σ2) ,
ce qui montre que les couples (ϑ1, σ) et (1/ϑ1, ϑ1σ) m`enent `a deux repr´esenta-
tions alternatives du mˆeme mod`ele. Ceci justiﬁe en quelque sorte la restriction
`a |ϑ1| < 1.
∥
Contrairement au mod`ele AR(p), ce mod`ele n’est pas markovien per se
(mˆeme s’il peut se repr´esenter comme un processus de Markov, en utilisant
la repr´esentation `a espace d’´etat introduite ci-dessous). Bien que le vecteur
entier x1:T soit une variable al´eatoire normale de moyenne constante μ et de
matrice de covariance
Σ =
⎛
⎜
⎜
⎜
⎝
σ2 γ1 γ2 . . .
γq
0 . . . 0
0
γ1 σ2 γ1 . . . γq−1 γq . . . 0
0
...
0
0
0 . . .
0
0 . . . γ1 σ2
⎞
⎟
⎟
⎟
⎠,

4.5 Mod`eles dynamiques
213
avec (|s| ≤q)
γs = σ2
q−|s|

i=0
ϑiϑi+|s| ,
(4.27)
et fournit donc une fonction de vraisemblance explicite, le calcul et ´evidemment
l’int´egration (ou la maximisation) de cette vraisemblance pour une valeur
donn´ee du param`etre sont assez coˆuteux, car ils n´ecessitent d’inverser la ma-
trice n×n Σ. Une repr´esentation plus pratique est d’utiliser la vraisemblance
de x1:T conditionnelle `a (ϵ0, . . . , ϵ−q+1),
L(μ, ϑ1, . . . , ϑq, σ|x1:T , ϵ0, . . . , ϵ−q+1) =
(4.28)
σ−T
T

t=1
exp
⎧
⎪
⎨
⎪
⎩
−
⎛
⎝xt −μ +
q

j=1
ϑjˆϵt−j
⎞
⎠
2
6
2σ2
⎫
⎪
⎬
⎪
⎭
,
o`u (t > 0)
ˆϵt = xt −μ +
q

j=1
ϑjˆϵt−j
(4.29)
et ˆϵ0 = ϵ0, . . ., ˆϵ1−q = ϵ1−q. Cette d´eﬁnition r´ecursive de la vraisemblance
reste coˆuteuse, car elle implique T calculs de q termes. N´eanmoins, mˆeme
si le probl`eme des valeurs de conditionnement (ϵ0, . . . , ϵ−q+1) doit se traiter
s´epar´ement, par exemple `a travers une mise en œuvre de m´ethodes de Monte
Carlo par chaˆınes de Markov (MCMC) (voir le Chapitre 6), la complexit´e de
cette repr´esentation est plus maniable que celle de la repr´esentation donn´ee
ci-dessus.
Une autre approche int´eressante est d’utiliser la repr´esentation dite `a es-
pace d’´etat, inspir´ee du ﬁltre de Kalman, qui donne des formules lin´eaires
r´ecursives pour la pr´ediction, le lissage et le ﬁltrage. Brockwell et Davis (1998,
Chapitre 8) donnent une pr´esentation g´en´erale de cette technique (voir aussi
Capp´e et al., 2005), tandis que West et Harrison (1998) d´ecrivent leur version
bay´esienne, mais l’id´ee g´en´erale est de repr´esenter une s´erie temporelle (xt)
comme un syst`eme de deux ´equations,
xt = Gyyt + εt ,
(4.30)
yt+1 = Ftyt + ξt ,
(4.31)
o`u les vecteurs εt et ξt sont des vecteurs multivari´es normaux de matrices
de covariance g´en´erales qui d´ependent de t et E[εuξ′
v] = 0 pour tout (u, v).
L’´equation (4.30) est appel´ee ´equation d’observation et (4.31) est appel´ee
´equation d’´etat. Cette repr´esentation projette le processus d’int´erˆet (xt) dans
un espace plus grand, l’espace d’´etat, o`u le processus (yt) est markovien et
lin´eaire. Par exemple, (4.23) est une repr´esentation `a espace d’´etat du mod`ele
AR(p).

214
4 Estimation bay´esienne ponctuelle
Le mod`ele MA(q) peut s’´ecrire de cette fa¸con en d´eﬁnissant yt = (ϵt−q,
. . . , ϵt−1, ϵt)′. L’´equation d’´etat est alors
yt+1 =
⎛
⎜
⎜
⎜
⎜
⎝
0 1 0 . . . 0
0 0 1 . . . 0
. . .
0 0 0 . . . 1
0 0 0 . . . 0
⎞
⎟
⎟
⎟
⎟
⎠
yt + ϵt+1
⎛
⎜
⎜
⎜
⎜
⎜
⎝
0
0
...
0
1
⎞
⎟
⎟
⎟
⎟
⎟
⎠
(4.32)
et l’´equation d’observation est
xt = μ −
	ϑq ϑq−1 . . . ϑ1 −1
yt .
Par cons´equent, cette d´ecomposition ne met pas en jeu un vecteur εt dans
l’´equation d’observation, tandis que ξt est d´eg´en´er´e dans l’´equation d’´etat. Ce
ph´enom`ene de d´eg´en´erescence est assez commun dans les repr´esentations `a
espace d’´etat, mais ceci n’est pas un obstacle `a l’utilisation conditionnelle du
mod`ele, comme dans les algorithmes MCMC du Chapitre 6. Notons aussi que
la repr´esentation `a espace d’´etat d’un mod`ele n’est pas unique.
Exemple 4.27. (Suite de l’Exemple 4.26) Pour le mod`ele MA(1), l’´equa-
tion d’observation peut aussi ˆetre xt = (1 0)yt avec yt = (y1t y2t)′ associ´ee `a
l’´equation d’´etat
yt+1 =

0 1
0 0

yt + ϵt+1

1
ϑ1

.
∥
Quelle que soit la repr´esentation choisie pour le mod`ele MA(q), la condition
d’identiﬁabilit´e sur Q(x) impose que les ϑj varient dans un espace complexe,
qui ne peut pas ˆetre d´ecrit directement pour des valeurs de q plus grandes que
3. La reparam´etrisation d´ecrite dans le Lemme 4.24 s’applique aussi formelle-
ment dans ce cas, mais avec une interpr´etation diﬀ´erente pour les ψi, qui sont
alors les autocorr´elations partielles inverses (Jones, 1987). Une loi a priori
uniforme pour les ψi peut s’utiliser pour l’estimation des ϑi, ce qui implique
le recours `a une m´ethode MCMC (voir Chapitre 6, Chib et Greenberg, 1994,
Barnett et al., 1996 et Billio et al., 1999).
4.5.4 Le mod`ele ARMA
Une extension simple du mod`ele pr´ec´edent est le mod`ele ARMA(p, q), o`u
(t = 1, 2, . . .)
xt = μ −
p

i=1
ϱi(xt−i −μ) + ϵt −
q

j=1
ϑjϵt−j ,
(4.33)

4.6 Exercices
215
o`u les ϵt’s sont i.i.d. N (0, σ2). Le but de tels mod`eles, relativement aux deux
mod`eles AR et MA, est de permettre une plus forte parcimonie, c’est-`a-dire
d’utiliser des valeurs beaucoup plus petites de p et q que dans un mod`ele
uniquement AR ou uniquement MA (voir la Note 6.6.6 pour des d´etails sur
la notion de parcimonie).
Comme l’ont d´etaill´e Box et Jenkins (1976), les conditions de station-
narit´e et d’identiﬁabilit´e correspondent de nouveau au fait que les racines
des polynˆomes P et Q sont en dehors du cercle unit´e, avec comme condi-
tion suppl´ementaire que les deux polynˆomes n’aient pas de racine commune.
(Mais ceci n’arrive presque sˆurement pas sous une loi a priori continue pour
les param`etres.) La reparam´etrisation du Lemme 4.24 peut par cons´equent
s’appliquer `a la fois aux ϑi et aux ϱj, n´ecessitant de nouveau un recours aux
techniques MCMC, en raison de la complexit´e de la loi a posteriori.
Naturellement, des repr´esentations `a espace d’´etat existent ´egalement pour
les mod`eles ARMA(p, q), une possibilit´e ´etant (Brockwell et Davis, 1998,
Exemple 8.3.2)
xt = μ −
	
ϑr−1 ϑr−2 . . . ϑ1 −1

yt
pour l’´equation d’observation et
yt+1 =
⎛
⎜
⎜
⎜
⎜
⎝
0
1
0
. . . 0
0
0
1
. . . 0
. . .
0
0
0
. . . 1
ϱr ϱr−1 ϱr−2 . . . ϱ1
⎞
⎟
⎟
⎟
⎟
⎠
yt + ϵt+1
⎛
⎜
⎜
⎜
⎜
⎜
⎝
0
0
...
0
1
⎞
⎟
⎟
⎟
⎟
⎟
⎠
,
(4.34)
pour l’´equation d’´etat, avec r = max(p, q + 1) et la convention que ϱt = 0 si
t > p et ϑt = 0 si t > q. Comme pour les mod`eles MA(q), cette repr´esentation
est pratique pour concevoir des algorithmes MCMC (voir le Chapitre 6) qui
simulent la loi a posteriori des param`etres du mod`ele ARMA(p, q).
4.6 Exercices
Section 4.1
4.1 (Smith, 1984)
Soit x, une variable al´eatoire de moyenne μ, fonction de
r´epartition F, et densit´e f. Les fonctions f et f ′ sont suppos´ees born´ees. D´eﬁnir
une suite de variables al´eatoires yn de fonction de r´epartition
Gn(y) =
„
1 −1
n
«
F(y) + 1
nHn(y),
satisfaisant
(i) EHn[y] = n2 ; et
(ii) H′
n = hn et h′
n sont born´es.

216
4 Estimation bay´esienne ponctuelle
Montrer que Gn →F, G′
n = gn →f, et g′
n →f ′, mais que |μ −E[yn]| →∞.
4.2 Si ψ(θ|x) est une loi a posteriori associ´ee `a f(x|θ) et `a la loi a priori π,
´eventuellement impropre, montrer que
ψ(θ|x)
f(x|θ) = k(x)π(θ).
a. En d´eduire que, si f appartient `a une famille exponentielle, la distribution a
posteriori appartient elle aussi `a une famille exponentielle, quelle que soit π.
b. Montrer que si ψ appartient `a une famille exponentielle, f y appartient aussi.
4.3 *(Berger et Wolpert, 1988)
Dans le cas suivant, Stein (1962b) met en avant
certaines des limitations du principe de vraisemblance. Supposons qu’une valeur
θ > 0 puisse ˆetre ´evalu´ee soit par x ∼N (θ, σ2) (avec σ2 connu), soit par
y ∼f(y|θ) = cy−1 exp
(
−d2
2
„
1 −θ
y
«2)
I[0,bθ](y),
o`u b est tr`es grand et d grand (disons 50).
a. Montrer que les deux estimateurs du maximum de vraisemblance de θ sont
δ1(x) = x et δ2(y) = y.
b. Consid´erer le cas particulier x = y = σd. Expliquer pourquoi l’inf´erence sur
θ devrait ˆetre la mˆeme dans les deux cas.
c. Expliquer pourquoi
[x −1.96 σ, x + 1.96 σ]
pourrait ˆetre propos´e comme intervalle de conﬁance `a 95% pour θ.
d. En d´eduire que
[y −(1.96)(y/d), y + (1.96)(y/d)]
peut ˆetre utilis´e comme intervalle de conﬁance si y est observ´e.
e. Montrer que
P(y −(1.96)(y/d) < θ < y + (1.96)(y/d))
peut ˆetre rendu aussi petit que possible pour un choix idoine de b.
f. Conclure que l’intervalle de conﬁance ci-dessus n’est pas appropri´e pour de
grandes valeurs de x = y et de σ, et discuter de la pertinence des intervalles
de conﬁance eu ´egard au principe de vraisemblance.
g. ´Etudier le mˆeme probl`eme avec la loi a priori π(θ) = 1/θ.
4.4 Montrer que, si p ∈[0, 1], θ = p/(1 −p) et si π(θ) = 1/θ, la loi a priori π(p) est
la distribution de Haldane.
4.5 Montrer que le ph´enom`ene oppos´e `a celui de l’Exemple 4.2 peut avoir lieu, c’est-
`a-dire qu’il peut ˆetre tel que l’information a priori est n´egligeable. (Indication :
Prendre π(θ) ´egal `a C (μ, 1) et f(x|θ) ∝exp −|x −θ|, et montrer alors que
l’estimateur MAP ne d´epend pas de μ.)
4.6 Dans le cadre de l’Exemple 4.2, consid´erer π(θ) ∝exp −a|θ| et montrer que,
pour a suﬃsamment petit, l’estimateur MAP n’est pas syst´ematiquement ´egal
`a 0.
4.7 Montrer que le paradoxe d’un estimateur MAP constant exhib´e dans l’Exemple
4.2 disparaˆıt lorsque le nombre d’observations de la loi C (θ, 1) augmente.

4.6 Exercices
217
4.8 Un tableau de contingence est une matrice k × ℓtelle que l’´el´ement (i, j) est
nij, le nombre d’occurrences simultan´ees de la i-i`eme modalit´e d’une premi`ere
caract´eristique et de la j-i`eme modalit´e d’une seconde caract´eristique dans une
population de n individus (1 ≤i ≤k, 1 ≤j ≤ℓ). La probabilit´e de cette
occurrence est not´ee pij.
a. Montrer que de telles lois appartiennent `a une famille exponentielle.
b. D´eterminer la loi des marges du tableau, c’est-`a-dire de
ni· = ni1 + . . . + niℓ
et
n·j = n1j + . . . + nkj .
En d´eduire la loi de (n1·, . . . , nk·) et de (n·1, . . . , n·ℓ).
c. Donner les lois a priori conjugu´ees sur p = (pij) et la loi a priori de Jeﬀreys.
d. Dans le cas particulier o`u les deux variables sont ind´ependantes, les pa-
ram`etres sont suppos´es satisfaire les relations pij = pi·p·j o`u (p1·, . . . , pk·)
et (p·1, . . . , p·ℓ) sont deux vecteurs de probabilit´es. Relier ces vecteurs aux
lois obtenues en b. et construire les lois a priori conjugu´ees correspondantes.
e. Comparer les esp´erances a posteriori de pij pour les lois a priori conjugu´ees
des questions c. et d. [Note : Voir Santner et Duﬀy, 1989, pour une pr´esentation
d´etaill´ee du traitement bay´esien de ces mod`eles.]
4.9 D´eterminer si les lois suivantes peuvent ˆetre des lois a posteriori :
(i) T1(k, μ(x), τ 2(x)) avec x ∼N (θ, σ2) et σ2 connu ;
(ii) une distribution normale tronqu´ee N (μ(x), τ 2(x)) avec x ∼P(θ) ; et
(iii) Pa(α(x), μ(x)) avec x ∼B(n, 1/θ).
4.10 *(Suite de l’Exercice 4.9) Pour une distribution d’´echantillonnage f(x|θ)
et une distribution conditionnelle g(θ|x), donner une condition n´ecessaire et
suﬃsante pour que g(θ|x) soit une loi a posteriori associ´ee `a f(x|θ) et `a une loi
a priori arbitraire π(θ).
4.11 Soit (xn)n une chaˆıne de Markov `a espace d’´etat ﬁni {1, . . . , p} et de matrice
de transition P.
a. Si l’´echantillon est x1, . . . , xn, exprimer la fonction de vraisemblance et cal-
culer les lois a priori conjugu´ees des composantes de P.
b. La chaˆıne de Markov est d´esormais observ´ee `a des temps al´eatoires t1 < · · · <
tn. Donner la fonction de vraisemblance ℓ(P|xt1, . . . , xtn), en supposant que
la distribution des ti ne d´epend pas de P et d´eterminer si les lois a priori
ci-dessus permettent toujours des calculs analytiques.
c. Une variable al´eatoire yt de distribution conditionnelle f(y|θxt) est observ´ee
pour t = 1, . . . , n. On suppose que les yt sont ind´ependants, conditionnelle-
ment aux xt. Montrer que la distribution marginale des yt est un m´elange des
distributions f(y|θk).
d. Si seulement les yt sont observ´es, le mod`ele est une chaˆıne de Markov cach´ee.
Lorsque f(y|θ) appartient `a une famille exponentielle, donner la fonction de
vraisemblance et les lois a priori conjugu´ees sur (P, θ1, . . . , θp).
e. Consid´erer le cas particulier p = 2 et f(y|θ) = θ exp(−θy)IR+(y) aﬁn d’´etablir
si les lois a priori ci-dessus admettent une expression simple.
4.12 Soient x ∼B(m, p) et p ∼Be(1/2, 1/2).
a. Montrer que cette loi a priori est ´equivalente `a la loi uniforme sur θ =
arcsin(√p). Comment justiﬁer cette transformation ? [Note : Voir Feller, 1970,
pour plus de d´etails sur la loi de l’arcsinus.]

218
4 Estimation bay´esienne ponctuelle
b. Soit y ∼B(n, q) une observation ind´ependante, avec q ∼Be(1/2, 1/2). Utili-
ser l’approximation arcsin x ∼N (θ, 1/4m) aﬁn d’obtenir une loi a posteriori
approch´ee de arcsin(√p) −arcsin(√q).
c. En d´eduire une approximation de
π(| arcsin(√p) −arcsin(√q)| < 0.1|x, y).
4.13 La distribution logistique est d´eﬁnie par la densit´e
e−(x−θ)/(1 + e−(x−θ))2
sur R.
a. Montrer que la fonction ci-dessus est bien une densit´e de probabilit´e et cal-
culer l’estimateur du maximum de vraisemblance de θ.
b. Montrer que cette loi n’appartient pas `a une famille exponentielle (i) direc-
tement ; et (ii) en utilisant l’Exercice 3.20. En d´eduire qu’il n’existe pas de loi
a priori conjugu´ee et proposer une loi a priori non informative.
c. ´Etablir l’expression de l’estimateur du maximum de vraisemblance de θ pour
un ´echantillon x1, . . . , xn. Montrer par un exemple que la vraisemblance peut
avoir plusieurs modes.
d. Relier la r´egression logistique et la loi logistique en exhibant des variables
al´eatoires logistiques latentes dans le mod`ele de r´egression logistique. Y a-t-il
une contradiction entre la question b. et le fait que le mod`ele de r´egression
logistique appartienne `a une famille exponentielle, comme le montre l’Exemple
3.21 ?
4.14 Pour le mod`ele AR(1) de l’Exemple 4.6, montrer que la distribution a poste-
riori jointe π(ϱ, σ2|x1:(T −1)) admet une expression explicite pour la loi a priori
conjugu´ee
ϱ ∼N (0, κσ2),
σ2 ∼I G (α, β) .
En d´eduire la densit´e pr´edictive π(xT |x1:(T −1)).
Section 4.2
4.15 (Smith, 1988) Une justiﬁcation usuelle des coˆuts quadratiques est qu’ils four-
nissent une approximation du second ordre des coˆuts sym´etriques. Soit la fonc-
tion de coˆut
L(θ, δ) = 1 −e−(δ−θ)2/2
et π(θ|x) = (1/2){ϕ(θ; 8, 1) + ϕ(θ; −8, 1)}, un m´elange de deux distributions
normales de moyennes respectives 8 et −8, et de variance 1.
a. Montrer que π(θ|x) peut en fait s’´ecrire comme une loi a posteriori.
b. Montrer que Eπ[θ|x] est un maximum local du coˆut a posteriori.
c. Relier le coˆut L(θ, δ) aux coˆuts intrins`eques de la Section 2.5.4.
4.16 Soient x ∼P(λ) et π(λ) = e−λ. Le but de l’exercice est de comparer les
estimateurs δc(x) = cx sous les coˆuts quadratiques L(λ, δ) = (δ −λ)2.
a. Calculer R(δc, λ) et montrer que δc n’est pas admissible pour c > 1.
b. Calculer r(π, δc) et en d´eduire le cπ optimal.
c. Montrer qu’il n’existe pas d’estimateur optimal δc au sens minimax.
d. Reprendre les questions pr´ec´edentes pour la fonction de coˆut
L′(λ, θ) =
„ δ
λ −1
«2
.

4.6 Exercices
219
4.17 Montrer que l’estimateur de Bayes associ´e `a un coˆut quadratique et une loi
a priori propre ne peut pas ˆetre sans biais. Est-ce que ce r´esultat s’´etend aux
estimateurs de Bayes g´en´eralis´es ? `A d’autres coˆuts ?
4.18 Soient x ∼B(n, p) et p ∼Be(α, β).
a. Calculer les distributions a posteriori et marginale. En d´eduire l’estimateur
de Bayes sous le coˆut quadratique.
b. Si la loi a priori est π(p) = [p(1−p)]−1I(0,1)(p), donner l’estimateur de Bayes
g´en´eralis´e de p (lorsqu’il est d´eﬁni).
c. Sous quelle condition sur (α, β), δπ est-il sans biais ? S’agit-il d’une contra-
diction avec l’Exercice 4.17 ?
d. Donner l’estimateur de Bayes de p sous le coˆut
L(p, δ) = (δ −p)2
p(1 −p).
4.19 En utilisant les estimateurs du Tableau 4.1, montrer que les estimateurs cor-
respondant `a des lois a priori non informatives peuvent s’´ecrire comme des li-
mites d’estimateurs conjugu´ees. Est-ce que cette convergence s’´etend `a d’autres
quantit´es d’int´erˆet pour la mˆeme suite d’hyperparam`etres conjugu´es ? Essayer
d’´etablir un r´esultat g´en´eral.
4.20 Soient x ∼N (θ, 1), θ ∼N (0, 1) et L(θ, δ) = I{δ<θ}. Montrer qu’il n’existe
pas d’estimateur de Bayes dans ce cas.
4.21 Soit x ∼P(θ), avec Θ = {θ1, θ2} et D = {d1, d2, d3}. La fonction de coˆut est
d´eﬁnie par la matrice
L =
„
0 20 10
50 0 20
«
(o`u Lij = L(θi, dj), i = 1, 2, j = 1, 2, 3). Montrer que les estimateurs de Bayes
sont de la forme
δπ(x) =
8
>
<
>
:
d1
si x < k −log2 3,
d2
si x > k −1,
d3
sinon,
et d´eﬁnir k `a partir de la loi a priori π.
4.22 (Ferguson, 1967) Soit x suivant la distribution n´egative binomiale renorma-
lis´ee,
f(x|θ) =
 
r + x −1
x
!
θx(1 + θ)−(r+x),
x = 0, 1, . . . ,
θ ∈R∗
+ .
Montrer que Eθ[x] = rθ (d’o`u θ = p/(1 −p)). La fonction de coˆut est l’erreur
quadratique pond´er´ee
L(θ, δ) = (θ −δ)2
θ(1 + θ).
a. Donner l’estimateur du maximum de vraisemblance de θ.
b. Montrer que δ0(x) = x/r admet une fonction de risque constante et est
l’estimateur de Bayes g´en´eralis´e pour π(θ) = 1 si r > 1. Que se passe-t-il
lorsque r = 1 ?

220
4 Estimation bay´esienne ponctuelle
c. Montrer que
δα,β(x) = α + x −1
β + r + 1
est un estimateur de Bayes pour
π(θ|α, β) ∝θα−1(1 + θ)−(α+β)
et que cette loi est conjugu´ee pour f(x|θ).
d. En d´eduire que δ1(x) = x/(r + 1) est un estimateur minimax.
4.23 (Ferguson, 1967) Soient Θ = [0, 1] et L(θ, δ) = (θ−δ)2
1−θ , pour la loi g´eom´etrique
f(x|θ) = θx(1 −θ)
(x ∈N).
a. Donner un d´eveloppement en s´erie enti`ere de R(θ, δ) comme fonction de θ.
b. Montrer que l’unique estimateur non randomis´e de risque constant est δ0 tel
que
δ0(0) = 1/2,
δ0(x) = 1 si x ≥1.
c. Montrer que, si δπ est l’estimateur de Bayes associ´e `a π, δπ(n) = μn−1/μn,
o`u μi est le i-i`eme moment de π.
d. Montrer que δ0 est minimax.
4.24 *(Casella et Strawderman, 1981) Soit x ∼N (θ, 1) avec |θ| ≤m (m < 1).
a. Montrer que δm(x) = m tanh(mx) est l’estimateur de Bayes associ´e `a
πm(θ) = 1
2I{−m,m}(θ).
b. Montrer que, pour le coˆut quadratique, r(πm, δm) = R(δm, ±m) et en d´eduire
que δm est minimax. [Note : Il s’agit en fait de l’unique estimateur minimax
dans ce cas.]
c. Comparer `a l’estimateur δU associ´e `a la loi a priori uniforme
π(θ) =
1
2mI[−m,m](θ),
en fonction de m. [Note : Gatsonis et al., 1987, donnent une ´etude d´etaill´ee
de la performance de δU en termes de minimaxit´e.]
4.25 (Casella et Berger, 2001) Soient x ∼U{1,2,...,θ} et θ ∈Θ = N∗.
a. Si D = Θ, montrer que, sous le coˆut quadratique, Eπ[θ|x] n’est pas forc´ement
l’estimateur de Bayes.
b. Si D = [1, +∞), montrer que Eπ[θ|x] est l’estimateur de Bayes (lorsqu’il
existe).
c. Montrer que δ0(x) = x est admissible pour tout choix de D. (Indication :
Commencer par R(1, δ0).)
d. Montrer que δ0 est un estimateur de Bayes et qu’il existe d’autres estimateurs
de Bayes pour cette loi a priori, de fonctions de risque diﬀ´erentes.
4.26 Soient x1, x2 i.i.d. de distribution f(x|θ) = (1/2) exp(−|x −θ|) et π(θ) = 1.
D´eterminer les estimateurs de Bayes associ´es aux coˆuts absolus et quadratiques.
Mˆeme question pour une observation additionnelle. [Note : Voir l’Exemple 1.12
pour une motivation historique.]

4.6 Exercices
221
Section 4.3.1
4.27 Chrystal (1891) ´ecrit : “Personne ne dira que, si vous mettez simplement deux
boules blanches dans un sac contenant une boule de couleur inconnue, avec une
mˆeme chance qu’elle soit noire ou blanche, cette action accroˆıt le rapport des
chances que la boule inconnue soit blanche de un contre un `a trois contre un”,
comme un argument contre la r`egle de succession de Laplace. Consid´erez-vous
que cette critique est valable ? (Voir Zabell, 1989.)
4.28 (Jeﬀreys, 1961)
a. Montrer que
N
X
i=1
 
i
x1
! 
N −i
x −x1
!
=
 
N + 1
x + 1
!
(i) par des calculs alg´ebriques ; et
(ii) en utilisant le calcul combinatoire.
b. Si l’´echantillon contient x = x1 + x2 individus, montrer que la probabilit´e
que les y = y1 + y2 tirages suivants contiendront y1 individus de la premi`ere
population et y2 de la seconde, est
P(y1, y2|x1, x2) =
y!
y1! y2!
(x1 + 1) . . . (x1 + y1)(x2 + 1) . . . (x2 + y2)
(x + 2) . . . (x + y + 1)
.
c. Pour x = x1, en d´eduire que la probabilit´e que les y tirages suivants sont du
mˆeme type est
x + 1
x + y + 1.
4.29 G´en´eraliser la r`egle de succession de Laplace au mod`ele multinomial.
Certains probl`emes similaires `a la r`egle de succession de Laplace ont ´et´e
consid´er´es par Lewis Carroll dans son livre Pillow Problems. Seneta (1993)
donne un commentaire d´etaill´e sur ces probl`emes, dont deux sont donn´es ci-
dessous.
4.30 Soient deux sacs, H et K, contenant deux boules chacun. Chaque boule est
soit blanche, soit noire. Une boule blanche est ajout´ee au sac H et une boule est
choisie au hasard dans le sac H et transf´er´ee dans le sac K, sans qu’on regarde
sa couleur.
a. Quelle est la probabilit´e de tirer une boule blanche du sac K ?
b. Une boule blanche est ensuite ajout´ee au sac K et on transf`ere de nouveau
du sac K au sac H une boule prise au hasard sans la regarder. Quelle est
d´esormais la probabilit´e de tirer une boule blanche du sac H ?
4.31 “Pour une inﬁnit´e de baguettes cass´ees, ´etablir la probabilit´e qu’une d’entre
elles au moins soit cass´ee au milieu.” Bien que cette question soit mal formul´ee,
puisque le milieu est de mesure z´ero, une solution discr`ete est propos´ee ici.
a. Supposons que chaque baguette a 2m + 1 points de rupture et qu’il y a
exactement 2m + 1 baguettes. Donner la probabilit´e qu’aucune baguette ne
casse au milieu et calculer la valeur limite de cette probabilit´e lorsque m tend
vers l’inﬁni.
b. ´Etudier la d´ependance de cette limite `a l’hypoth`ese que le nombre m de
points de rupture est ´egal au nombre de baguettes.

222
4 Estimation bay´esienne ponctuelle
Section 4.3.2
4.32 Dans le cadre de l’Exemple 4.17, d´evelopper un mod`ele bay´esien pour la dis-
tribution de (t2 −t1). ´Etendre au probl`eme suivant : ´Etant donn´e qu’un feu
est au rouge depuis une minute, quelle est la probabilit´e qu’il passe au vert la
minute suivante ?
4.33 Montrer que, pour le probl`eme du tramway, l’estimateur du maximum de
vraisemblance ˆ
N = T est admissible pour toute fonction de coˆut de la forme
L(| ˆ
N −N|), avec L fonction strictement croissante. (Indication : Consid´erer
d’abord le cas N = 1.)
Section 4.3.3
4.34 Pendant le lancement d’un nouveau journal ´etudiant, n1 = 220 et n2 = 570
personnes ont achet´e les num´eros tests −1 et 0. Le nombre de personnes qui ont
achet´e les deux num´eros est n11 = 180. Donner un estimateur de Bayes de N,
le nombre total de lecteurs, en supposant qu’un mod`ele de capture-recapture
s’applique et que π(N) est P(1000).
4.35 (Castledine, 1981) Pour le mod`ele de Wolter introduit en Section 4.3.3, c’est-`a-
dire lorsque n1 et n2 sont des variables al´eatoires, le mod`ele temporel consid`ere le
cas o`u tous les individus ont la mˆeme probabilit´e de capture pour une exp´erience
donn´ee, mais o`u cette probabilit´e varie entre la premi`ere et la seconde capture.
Ces deux probabilit´es sont not´ees p1 et p2 .
a. Donner la vraisemblance et l’estimateur du maximum de vraisemblance as-
soci´es `a ce mod`ele lorsque p1 et p2 sont connus.
b. Montrer que la loi a posteriori de N sachant p1 et p2 ne d´epend que de
n+ = n1 + n2 −n11 et μ = 1 −(1 −p1)(1 −p2). Lorsque la loi a priori de N
est π(N) = 1, montrer que π(N|n+, μ) est la loi N eg(n+, μ).
c. Donner la distribution marginale a posteriori de N lorsque p1 ∼B(α, β) et
p2 ∼B(α, β).
d. Montrer que, si α = 0, β = 1, nous retrouvons le mod`ele de Darroch comme
distribution marginale de N. Cette d´ecomposition facilite-t-elle le calcul de
l’estimateur de Bayes ?
Section 4.4.1
4.36 *(Robert, 1990) La fonction de Bessel modiﬁ´ee Iν (ν ≥0) est une solution de
l’´equation diﬀ´erentielle z2f ′′ + zf ′ −(z2 + ν2)f(z) = 0 et peut ˆetre repr´esent´ee
par un d´eveloppement en s´eries limit´ees
Iν(z) =
“z
2
”ν
∞
X
k=0
(z/2)2k
k! Γ(ν + k + 1).
a. Montrer que les s´eries ci-dessus convergent dans R quel que soit ν ≥0.
b. En d´eveloppant
Z π
0
ez cos(θ) sin2ν(θ) dθ
en s´erie enti`ere, montrer que Iν peut s’´ecrire
Iν(z) =
(z/2)ν
π1/2Γ(ν + 1
2)
Z π
0
ez cos(θ) sin2ν(θ) dθ.
(4.35)

4.6 Exercices
223
c. ´Etablir les formules de r´ecurrence suivantes :
(
Iν+1(z) = Iν−1(z) −(2ν/z)Iν(z),
I′
ν(z) = Iν−1(z) −(ν/z)Iν(z).
d. ´Etablir `a partir de la repr´esentation (4.35) et par une int´egration par parties
que, pour z > 0,
Iν+1(z) ≤Iν(z).
e. D´eduire du d´eveloppement en s´erie enti`ere de Iν que t−νIν(t) croˆıt en t. Si
on d´eﬁnit rν comme
rν(t) = Iν+1(t)
Iν(t) ,
montrer que rν est une fonction croissante et concave, et que rν(t)/t d´ecroˆıt.
f. Montrer que
lim
t→0 rν(t) = 1,
lim
t→∞
rν(t)
t
=
1
2(ν + 1),
et que
r′
ν(t) = 1 −2ν + 1
t
rν(t) −r2
ν(t).
g. Montrer que la densit´e d’une loi du khi deux d´ecentr´e de param`etre de
d´ecentrage λ et `a ν degr´es de libert´e peut s’exprimer comme une fonction
de Bessel modiﬁ´ee, soit,
pλ,ν(x) = 1
2
“x
λ
” ν−2
4
I ν−2
2 (
√
λx)e−x+λ
2 .
4.37 *(Bock et Robert, 1985) Sur Rp, la sph`ere de rayon c est d´eﬁnie par
Sc =
˘
z ∈Rp; ||z||2 = c
¯
.
a. Si x ∼Np(θ, Ip), avec p ≥3, et si θ a pour loi a priori πc, la loi uniforme sur
Sc, montrer que la densit´e marginale de x est proportionnelle `a
mc(x) = e−||x||2/2e−c2/2 I p−2
2 (||x||c)
(c||x||)
p−2
2
.
b. Montrer que le coeﬃcient de proportionnalit´e est ind´ependant de c et rap-
peler pourquoi il n’apparaˆıt pas dans la loi a posteriori.
c. D´eduire de la question a. l’esp´erance a posteriori δc par une d´erivation. (In-
dication : Voir le Lemme 4.8.)
d. Montrer que, si c ≥√p, δc est un estimateur `a r´etr´ecisseur en dehors de la
boule {x; ||x|| ≤ϱ} et `a “agrandisseur” `a l’int´erieur. D´eterminer la valeur
seuil ϱ.
e. Montrer que δc ne peut pas ˆetre minimax. Cet estimateur est-il admissible ?
f. Expliquer pourquoi δc n’est jamais `a l’int´erieur de Sc alors que πc se concentre
sur Sc. Est-ce que δc est le “vrai” estimateur de Bayes ?
g. En utilisant les relations de r´ecurrence de l’Exercice 4.36, montrer que
δc(x) =
„
1 −p −2
||x||2
«
x + hc(||x||2)x,
o`u hc(t) > 0 lorsque t ≤max(c2, p −2). Proposer un estimateur plus
int´eressant.

224
4 Estimation bay´esienne ponctuelle
4.38 Soit x1, . . . , x10 i.i.d. N (θ, θ2), avec θ > 0, repr´esentant dix observations de
la vitesse d’une ´etoile. Justiﬁer le choix π(θ) = 1/θ et d´eterminer l’estimateur
de Bayes g´en´eralis´e associ´e `a un coˆut invariant
L(θ, δ) =
„δ
θ −1
«2
.
(Indication : Utiliser l’Exercice 3.33.)
4.39 *(Lindley, 1965) Soit x1, . . . , xn un ´echantillon de N (θ, σ2), avec σ2 connu.
La densit´e a priori π(θ) est telle qu’il existe ϵ, M et c tels que c(1 −ϵ) ≤π(θ) ≤
c(1 + ϵ) pour θ ∈I = [¯x −1.96 σ/√n, ¯x + 1.96 σ/√n] et π(θ) ≤Mc sinon.
a. Montrer que ces contraintes sont compatibles, c’est-`a-dire qu’une telle loi a
priori existe.
b. Montrer que
(1 −ϵ)[0.95(1 + ϵ) + 0.05M]−1 e−(x−θ)2n/2σ2
p
2πσ2/n
≤π(θ|x)
≤(1 + ϵ)[(1 −ϵ)0.95]−1 e−(x−θ)2n/2σ2
p
2πσ2/n
si θ ∈I et
π(θ|x) ≤
M
0.95(1 −ϵ)
e−1.962/2
p
2πσ2/n
sinon.
c. Discuter de l’int´erˆet de ces approximations pour θ ∈I et θ ̸∈I. Pouvez-vous
obtenir une r´egion de conﬁance conservatrice ?
4.40 Soient une variable al´eatoire normale, x ∼N (θ, 1) et une transformation
bijective η = sinh(θ).
a. Lorsque π(η) = 1, montrer que la distribution a posteriori r´esultante sur θ
est
π(θ|x) ∝exN (x + 1, 1) + e−xN (x −1, 1).
b. Comparer le comportement de cette loi a posteriori avec celui de la loi a
posteriori de Jeﬀreys N (x, 1) en calculant les variance, quantiles et modes a
posteriori. En particulier, d´eterminer les valeurs de x pour lesquelles la loi a
posteriori est bimodale et celles pour lesquelles il y a deux maxima globaux.
c. Consid´erer le comportement de π(θ|x) pour de grandes valeurs de x et
conclure que la loi a priori π(η) = 1 n’est pas un choix raisonnable.
Section 4.4.2
4.41 (Jeﬀreys, 1961)
Soient x1, . . . , xn1 i.i.d. de loi N (θ, σ2) et ¯x1, s2
1 les statis-
tiques associ´ees. Pour un second ´echantillon d’observations de mˆeme taille, don-
ner la distribution pr´edictive de (¯x2, s2
2) sous la loi non informative π(θ, σ) = 1
σ .
Si s2
2 = s2
1/y et y = ez, en d´eduire que z suit la loi de Fischer.
4.42 Montrer que, si x ∼G (α, β), 1/x ∼J G (α, β) comme d´eﬁni dans (4.12).
4.43 *(Ghosh et Yang, 1996) Comme dans l’Exercice 3.47, consid´erer x11, . . . , x1n1
et x21, . . . , x2n2, deux ´echantillons ind´ependants avec xij ∼N (μi, σ2).

4.6 Exercices
225
a. Montrer que la matrice d’information de Fisher est
I(μ1, μ2, σ) = σ−2
0
@
n1 0
0
0 n2
0
0
0 2(n1 + n2)
1
A .
b. La loi a priori co¨ıncidente de Welch et Peers (1963) (voir la Section 3.5.5)
pour la quantit´e d’int´erˆet θ = (μ1 −μ2)/σ est solution de l’´equation
diﬀ´erentielle
∂
∂μ1 (η1π) +
∂
∂μ2 (η2π) + ∂
∂σ (η3π) = 0 ,
(4.36)
o`u
(η1, η2, η3) = I−1∇θ/(∇θtI−1∇θ)1/2 .
Montrer qu’une classe de solutions `a (4.36) est de la forme
»
n−1
1
+ n−1
2
+ 1
2(μ1 −μ2)2/{(n1 + n2)σ2}
–1/2
g(μ1, μ2, σ)
(4.37)
o`u
g(μ1, μ2, σ) ∝
ˆ
d1(μ1 −μ2)2 + d2(n1μ2
1 + n2μ2
2) + d3σ2˜c ,
c est une constante arbitraire et (d1, d2, d3) satisfont
d1(n−1
1
+ n−1
2 ) + d2 = 1
2d3(n1 + n2)−1 .
c. En d´eduire que la loi a priori co¨ıncidente pour (θ, μ2, σ) est
π(θ, μ2, σ) ∝σ2c+1
»
n−1
1
+ n−1
2
+ 1
2θ2(n1 + n2)−1
–c+1/2
.
d. Montrer que
π(θ|¯x1, ¯x2, s) ∝
»
n−1
1
+ n−1
2
+ 1
2θ2(n1 + n2)−1
–c+1/2
×
Z ∞
0
vn1+n2−2c−4 exp
j−1
2
„
v2 +
n1n2
n1 + n2 (vz −θ)2
«ﬀ
dv
o`u z = (¯x1 −¯x2)/s.
e. Montrer que la distribution de z ne d´epend que de θ.
f. Montrer que le choix unique de c qui ´evite le paradoxe de marginalisation
des Exercices 3.45-3.51 est c = −1.
Section 4.4.3
4.44
a. Si x ∼Np(θ, Σ), montrer que, pour toute loi a priori π,
δπ(x) = x + Σ∇log mπ(x).
b. (Bock, 1988) Les pseudo-estimateurs de Bayes sont d´eﬁnis comme les esti-
mateurs de la forme
δ(x) = x + ∇log m(x)
o`u x ∼Np(θ, Ip). Montrer que l’estimateur de James-Stein tronqu´e donn´e
dans l’Exemple 4.9 est un pseudo-estimateur de Bayes (c’est-`a-dire donner la
valeur correspondante de m). Peut-il s’agir d’un estimateur de Bayes ?

226
4 Estimation bay´esienne ponctuelle
4.45 *Pour un mod`ele normal Nk(Xβ, Σ) o`u la matrice de covariance Σ est
compl`etement inconnue, donner la loi a priori non informative de Jeﬀreys.
a. Montrer que la loi a posteriori de Σ, conditionnelle `a β, est une distribution
de Wishart et en d´eduire qu’il n’existe pas de loi marginale a posteriori propre
sur β lorsque le nombre d’observations est inf´erieur `a k.
b. Expliquer alors pourquoi il n’est pas possible de construire une loi conjugu´ee.
Consid´erer le cas particulier o`u Σ suit une loi de Wishart.
c. Quelle est la raison fondamentale pour laquelle ce qui ´etait possible dans la
Section 4.4.2 ne l’est plus pour ce mod`ele ?
4.46 *Soit le probl`eme de la pr´ediction pour un mod`ele de r´egression lin´eaire, avec
y = Xβ + ϵ observ´e, β ∈Rk, ϵ ∼Np(0, Σ). On cherche `a pr´edire z = T β + ϵ′,
avec T connu et ϵ′ ∼Np(0, Σ) ind´ependant de ϵ.
a. Si δ est le pr´edicteur consid´er´e et si l’erreur de pr´ediction est ´evalu´ee par la
fonction de coˆut L(z, δ) = ||z −δ||2, montrer que l’erreur moyenne est
Ez,x[L(z, δ(x))] = tr(Σ) + Ex[||δ(x) −T β||2].
b. Montrer que ce probl`eme est ´equivalent `a celui de l’estimation de β sous le
coˆut quadratique associ´e `a Q = T tT. (Indication : Montrer auparavant que
δ(x) est forc´ement de la forme T γ(x), avec γ(x) ∈Rk, ou qu’il est domin´e
par un tel estimateur.)
c. D´eduire du fait que Q est d´eg´en´er´ee et admet une seule valeur propre non
nulle qu’un eﬀet Stein ne peut pas avoir lieu dans un tel cas.
d. Consid´erer maintenant que T est une matrice al´eatoire, de moyenne 0 et telle
que E[T tT] = M. Montrer que, lorsque δ(x) = T γ(x), le risque fr´equentiste
est
Ez,x,T [L(z, δ(x))] = tr(Σ) + Ex[(γ(x) −β)tM(γ(x) −β)] ,
et donc qu’un eﬀet Stein est possible lorsque M a trois valeurs propres non
nulles ou plus. [Note : Ce ph´enom`ene est reli´e aux paradoxes de statistiques
libres d´evelopp´es par Brown, 1986a ; voir aussi Foster et George, 1998.]
e. Soit β ∼Nk(0, σ2Ik). Calculer le pr´edicteur de Bayes de z lorsque T est ﬁx´e
et lorsque T est al´eatoire. Conclure.
4.47 Les mod`eles tobit sont utilis´es en ´Econom´etrie (voir Gouri´eroux et Monfort,
1996) pour repr´esenter des ph´enom`enes tronqu´es. Soit y|x ∼N (βtx, σ2), qui
n’est observ´e que s’il est strictement positif, x ´etant une variable explicative
dans Rp.
a. Montrer que les mod`eles tobit sont des m´elanges de mod`eles probit (pour
y < 0) et de mod`eles de r´egression standard (pour y ≥0).
b. Donner la fonction de vraisemblance ℓ(β, σ2|y1, . . . , yn) associ´ee `a l’´echantillon
y1, . . . , yn, x1, . . . , xn et calculer une statistique exhaustive pour ce mod`ele.
c. Conditionnellement `a (x1, . . . , xn), montrer que ce mod`ele appartient `a une
famille exponentielle et proposer une loi a priori conjugu´ee pour (β, σ). Est-ce
que cette loi permet des calculs analytiques ?
4.48 *Le mod`ele de r´egression inverse (ou calibration) est donn´e par
y ∼Np(β, σ2Ip),
z ∼Np(λ0β, σ2Ip),
s2 ∼σ2χ2
q,
avec β ∈Rp, λ0 ∈R.

4.6 Exercices
227
a. Donner l’estimateur du maximum de vraisemblance de λ et montrer que son
risque quadratique peut ˆetre inﬁni.
b. Calculer la loi a priori de Jeﬀreys pour (β, σ2, λ0) et montrer que l’esp´erance
a posteriori correspondante de λ0 est l’estimateur de r´egression inverse,
δI(y, z, s) = ytz/(s + ||y||2).
c. En recourant `a la technique des lois a priori de r´ef´erence introduite dans
la Section 3.5, proposer une loi a priori alternative π({λ0, (β, σ2)}) lorsque
(β, σ2) est consid´er´ee comme un param`etre de nuisance. Calculer l’esp´erance
a posteriori correspondante de λ0, δR(y, z, s).
d. Montrer que, lorsque q tend vers l’inﬁni, δI converge presque sˆurement vers
0, mais que δR ne souﬀre pas de cette incoh´erence. [Note : Voir Osborne,
1991, pour une revue des mod`eles de calibration, et Kubokawa et Robert,
1994, pour des consid´erations d´ecisionnelles sur ces estimateurs.]
Section 4.5.1
4.49 Pour le mod`ele AR(1) donn´e par (4.18), donner la matrice de covariance de
(x1, . . . , xT ).
4.50 (Suite de l’Exercice 4.49)
a. Montrer que la variance de xt est donn´ee par (4.19).
b. Que se passe-t-il dans le cas o`u ϱ = 1, o`u (4.19) n’a pas de sens ?
c. ´Etendre au cas o`u x0 est une valeur arbitraire.
4.51
∗(Suite de l’Exercice 4.50) On souhaite ´etablir qu’il n’existe pas de loi
stationnaire pour le mod`ele AR(1) lorsque |ϱ| ≥1, c’est-`a-dire pas de densit´e f
telle que, si xt ∼f, alors xt+1 ∼f.
a. Montrer que, lorsque |ϱ| < 1, la loi stationnaire est la distribution normale
N (0, σ2/(1 −ϱ2)).
b. Dans le cas o`u |ϱ| = 1, montrer que la mesure de Lebesgue est la mesure
stationnaire de la chaˆıne (xt), c’est-`a-dire pour tout ensemble mesurable A,
Z
A
dx =
Z
A
Z
f(y|x)dxdy ,
o`u f(y|x) est la loi conditionnelle de xt sachant xt−1, soit N (xt−1, σ2) dans
ce cas. D´eduire de l’unicit´e de la mesure stationnaire la non-existence d’une
loi de probabilit´e stationnaire.
c. ´Etendre au cas |ϱ| ≥1, en ´ecrivant xt comme
xt =
t−1
X
i=0
ϱiϵt−i + ϱtx0
et en d´eduisant que xt est inﬁni presque sˆurement lorsque t tend vers l’in-
ﬁni. (Indication : Pour x0 = 0, remplacer la d´ecomposition ci-dessus avec la
d´ecomposition correspondante conditionnellement `a x1.)
Section 4.5.2
4.52 (Bernardo et Smith, 1994) Montrer que, pour un vecteur bidimensionnel,
(x1 x2)t ∼N2
„
(μ1 μ2)t,
» σ2
1
ϱσ1σ2
ϱσ1σ2
σ2
2
–«
,
la loi a priori de Jeﬀreys est π(θ) ∝(1 −ϱ2)−1/σ1σ2.

228
4 Estimation bay´esienne ponctuelle
4.53 (Bauwens et al., 1999) Pour le mod`ele AR(1) donn´e par (4.18),
a. Montrer que μ est un param`etre de position et, donc, qu’il n’apparaˆıt pas
dans la loi a priori de Jeﬀreys.
b. Montrer que
E
»∂2 log L(θ|x1:T )
∂σ2
–
= −T
2σ4 ,
E
»∂2 log L(θ|x1:T )
∂ϱ2
–
= −1
σ2 E
"T −1
X
t=0
x2
t
#
.
c. En utilisant la loi stationnaire des yt, d´eduire de E[y2
t ] = σ2/(1 −ϱ2) la loi a
priori de Jeﬀreys πJ
1 (σ2, ϱ) = 1/σ2p
1 −ϱ2.
4.54 *(Brockwell et Davis, 1998) L’algorithme de Durbin-Levinson calcule les au-
tocorr´elations partielles comme suit : soit φn1, . . . , φnn d´eﬁni r´ecursivement `a
partir des autocovariances γ(s) par
φnn =
 
γ(n) −
n−1
X
j=1
φ(n−1)jγ(nj)
!
v−1
n−1
et
0
B
@
φn1
...
φn(n−1)
1
C
A =
0
B
@
φ(n−1)1
...
φ(n−1)(n−1)
1
C
A −φnn
0
B
@
φ(n−1)(n−1)
...
φ(n−1)1
1
C
A ,
o`u vn = vn−1(1 −φnn)2, φ11 = γ(1)/γ(0) et v0 = γ(0).
a. Montrer que, si ψn = φnn, l’inverse de l’algorithme de Durbin-Levinson
s’obtient `a partir du Lemme 4.24.
b. Montrer que les autocorr´elations partielles ψn d’un processus MA(q) sont
nulles pour n > q.
c. Montrer que les autocorr´elations partielles ψn d’un processus AR(1) sont
donn´ees par ψn = (−1)n+1ϑn
1 /(1 + ϑ2
1 + . . . + ϑ2n
1 ).
4.55 (Bauwens et al., 1999) Pour le mod`ele AR(1) repr´esent´e dans (4.18),
a. En utilisant la d´ecomposition de Wold (4.25) obtenue dans l’Exemple 4.25,
montrer que
E
ˆ
x2
t
˜
= E
2
4
 
ϱtx0 +
t−1
X
i=0
ϱiϵt−i
!23
5 = 1 −ϱ2t
1 −ϱ2 σ2
avec x0 = 0.
b. En d´eduire la loi a priori de Jeﬀreys πJ
2 .
Section 4.5.3
4.56 *Donner la d´ecomposition de Wold pour le mod`ele stationnaire AR(p). (Indi-
cation : Utiliser la repr´esentation par polynˆome retard du mod`ele AR(p), soit,
P(B)xt = ϵt, o`u Bdxt = xt−d.)
4.57 Montrer que les autocorr´elations γs du mod`ele MA(q) sont donn´ees par (4.27).
4.58 ´Etablir la repr´esentation (4.32). G´en´eraliser la repr´esentation de l’Exemple
4.27 au mod`ele g´en´eral MA(q).

4.6 Exercices
229
Section 4.5.4
4.59 *Un mod`ele ARMA(p, q)
xt −μ =
p
X
i=1
ϱi(xt−i −μ) +
q
X
j=1
ϑjϵt−j + ϵt ,
est inversible (Brockwell et Davis, 1998, Section 3.1) s’il existe une suite (ϖj)j
telle que
X
i
|ϖj| < ∞
et
ϵt =
∞
X
j=0
ϖjxt−j .
Montrer que l’inversibilit´e est ´equivalente `a la condition que Q(x) ait ses racines
hors du cercle unit´e. (Indication : Utiliser la repr´esentation polynˆome retard du
mod`ele ARMA(p,q), c’est-`a-dire P(B)xt = Q(B)ϵt, avec Bdxt = xt−d.)
4.60 *Un mod`ele ARMA(p, q) est dit causal (Brockwell et Davis, 1998, Section 3.1)
s’il existe une suite (ϕj)j telle que
X
i
|ϕj| < ∞
et
xt =
∞
X
j=0
ϕjϵt−j .
Montrer que la causalit´e est ´equivalente `a la condition que P(x) ait ses racines
hors du cercle unit´e. (Indication : Utiliser la repr´esentation polynˆome retard de
l’Exercice 4.59.)
4.61 Montrer que la repr´esentation (4.34) est v´eriﬁ´ee. Proposer une repr´esentation
alternative.
4.62 Proposer une repr´esentation `a espace d’´etats similaire `a (4.34) pour le mod`ele
ARIMA
zt −μ =
p
X
i=1
ϱi(zt−i −μ) +
q
X
j=1
ϑjϵt−j + ϵt ,
(4.38)
o`u zt est la s´erie diﬀ´erenci´ee, zt = xt −xt−d, d ∈N∗. [Note : Comme Brockwell
et Davis, 1998, Section 6.5 le d´etaille, le mod`ele g´en´eral ARIMA(p,d, q) est
donn´e par un mod`ele ARMA(p, q) sur les s´eries diﬀ´erenci´ees xt −Ψ1xt−d −. . .−
ΨP xt−P d.]
Note 4.7.1
4.63 (Deely et Gupta, 1968)
Soient x1 ∼N (θ1, σ2
1), . . . , xk ∼N (θk, σ2
k) o`u la
quantit´e d’int´erˆet est θ[k], la plus grande des moyennes θ1, . . . , θk. La fonction
de coˆut est L(θ, ϕ) = θ[k] −ϕ.
a. Montrer que, si σ1 = . . . = σk sont connues et π(θ1) = . . . = π(θk) = 1,
l’estimateur de Bayes s´electionne la population comportant la plus grande
observation.
b. G´en´eraliser au cas o`u les θi ont une loi a priori ´echangeable N (0, τ 2).
4.64 *(Goel et Rubin, 1977) Montrer que les ensembles s∗
j constituent v´eritablement
une classe compl`ete lorsque la loi a priori sur θ = (θ1, . . . , θk) est sym´etrique.
(Indication : Montrer que les s∗
j sont optimaux parmi les sous-ensembles de taille
|s∗
j|.)
4.65 (Suite de l’Exercice 4.64) ´Etendre ce r´esultat aux lois f(x|θ) `a rapport de
vraisemblance monotone en θ.

230
4 Estimation bay´esienne ponctuelle
4.66 (Chernoﬀet Yahav, 1977) ´Etendre le r´esultat de classe compl`ete de l’Exercice
4.64 `a la fonction de coˆut
L(θ, s) = c(θ[k] −θs) −1
s
X
j∈s
θj.
(Indication : Montrer que, si θi1 ≤. . . ≤θij , s = {i1, . . . , ij} est domin´e par
l’ensemble {ij}.)
Note 4.7.2
4.67 *Pour le mod`ele AR(1) donn´e par (4.18), supposons que la quantit´e d’int´erˆet
soit x0, la valeur de d´epart de la chaˆıne. Calculer la loi a priori de r´ef´erence pour
l’ordre {x0, (ϱ, σ2)} et calculer un estimateur de x0 sous le coˆut quadratique.
Note 4.7.3
4.68 Soit le mod`ele `a facteurs (t = 1, . . . , T ),
(
y∗
t = [α + β(y∗
t−1)2]1/2ϵ∗
t
yt = y∗
t μ + σϵt,
(4.39)
avec ϵ∗
t ∼N (0, 1), et o`u seuls les yt ∈Rp sont observ´es.
a. ´Ecrire la vraisemblance (compl`ete) associ´ee aux couples (yt, y∗
t ).
b. Montrer que les y∗
t ne peuvent pas ˆetre marginalis´es analytiquement.
c. En d´eduire que le mod`ele `a facteurs ne peut pas s’exprimer comme un cas
particulier de mod`ele ARCH donn´e par (4.40).
4.69 (Bauwens et al., 1999)
Montrer que le mod`ele ARCH(p)
est sans int´erˆet
lorsque α = 0. (Indication : Montrer que var(yt) = 0.)
4.7 Notes
4.7.1 Classement et s´election
Beaucoup d’eﬀorts ont ´et´e consacr´es au probl`eme d’estimation et de comparai-
son de plusieurs moyennes normales. Nous mentionnons bri`evement ici quelques
approches propos´ees, aﬁn d’illustrer l’int´erˆet d’un traitement bay´esien, et ren-
voyons les lecteurs `a la litt´erature pour une discussion plus d´etaill´ee ; voir, par
exemple, Gibbons et al. (1977) Gupta et Panchapakesan (1979) et Dudewicz
et Koo (1982), `a la suite des articles introductifs de Bechofer (1954) et Gupta
(1965). Comme le d´ecrivent Berger et Deely (1988), les techniques de classe-
ment et de s´election apparaissent aussi comme des substituts de l’analyse de la
variance (Chapitre 10).
Pour x1 ∼N (θ1, σ2
1), . . ., xk ∼N (θk, σ2
k) donn´es, on cherche `a s´electionner la
population d’esp´erance la plus ´elev´ee, θ[k]. Les variances σ2
1, . . . , σ2
k sont ici sup-
pos´ees connues, mais le cadre plus g´en´eral o`u elles sont estim´ees par ˆσ2
1, . . . , ˆσ2
k
peut aussi ˆetre trait´e par le paradigme bay´esien. Berger et Deely (1988) refor-
mulent ce probl`eme pour r´epondre aux questions suivantes : (a) Peut-on accepter
l’hypoth`ese H0 : θ1 = · · · = θk ? (b) Dans le cas d’une r´eponse n´egative, quelle
est la moyenne la plus ´elev´ee ? Ils r´esolvent ce probl`eme en calculant d’abord
le facteur de Bayes contre H0, puis les probabilit´es a posteriori pj que θj soit

4.7 Notes
231
la moyenne la plus ´elev´ee (1 ≤j ≤k). (Le Chapitre 5 traite de la d´eﬁnition
et du calcul de ces quantit´es.) Pour ce faire, ils recourent `a des lois a priori
hi´erarchiques (Chapitre 10)
θi|β, σ2
π ∼N (β, σ2
π),
β ∼N (β0, A)
et
σ2
π ∼γI0(σ2
π) + (1 −γ)π∗
22(σ2
π).
La structure particuli`ere de la loi a priori sur σ2
π est due `a la n´ecessit´e de tester
le fait que les θi sont identiques. Pour π∗
22, Berger et Deely (1988) proposent la
loi informative
π∗
22(σ2
π) = (m −1)C(1 + Cσ2
π)−m,
o`u C et m peuvent s’obtenir `a partir de quantiles a priori. Pour une loi a priori
non informative, des choix possibles sont π∗
22(σ2
π) = 1 et
π∗
22(σ2
π) =
k
Y
i=1
(σ2
i + σ2
π)−1/k,
bien que ces lois a priori puissent rendre diﬃcile le calcul de la probabilit´e a
posteriori de H0 (voir le Chapitre 5).
Goel et Rubin (1977) adoptent une perspective plus d´ecisionnelle, consid´erant
comme un espace de d´ecision D l’ensemble de toutes les sous-parties non vides
de {1, . . . , k}, not´e {s1, s2, . . . , sK} avec K = 2k −1. Ils introduisent la fonction
de coˆut
L(θ, s) = c|s| + θ[k] −θs,
o`u |s| est le cardinal de s et θs = maxj∈s θj. Ce coˆut comprend une p´enalit´e
c pour toute population comprise dans l’ensemble de d´ecision s. Ce qui est
plutˆot logique, puisque, par souci de parcimonie, l’ensemble de d´ecision s doit
ˆetre choisi aussi petit que possible, le cas id´eal ´etant |s| = 1. Goel et Rubin
(1977) ont montr´e d’abord qu’une r`egle bay´esienne associ´ee `a cette fonction
de coˆut et `a une loi a priori sym´etrique doit ˆetre choisie parmi les ensembles
s∗
j = {ωk, . . . , ωk−j+1} (1 ≤j ≤k), o`u ωj est la population des x(j). La r`egle
bay´esienne sπ est alors solution de
ϱ(π, sπ|x) =
min
j=1,...,k ϱ(π, s∗
j|x),
o`u ϱ(π, s|x) = c|s| + Eπ[θ[k] −θs|x]. Introduisant
Δm = ϱ(π, s∗
m+1|x) −ϱ(π, s∗
m|x)
(1 ≤m ≤k −1),
la r`egle bay´esienne vaut s∗
k si A = {j; Δj ≥0} est vide, s∗
m sinon, avec m =
min(A). Un point d´elicat dans l’obtention de sπ est bien entendu le calcul des
esp´erances a posteriori Eπ[θ[k] −θs|x]. Ces auteurs d´etaillent le cas particulier
d’une loi a priori normale ´echangeable pour les θj, qui reste d´ependante de la
fonction
tm(z) =
Z +∞
−∞
Φm(z + x)Φ(−x) dx.
Cependant, ils montrent que, dans le cas non informatif, pour σ1 = · · · = σk, la
r`egle bay´esienne est s∗
1 lorsque c/σ1 ≥1/π2.

232
4 Estimation bay´esienne ponctuelle
4.7.2 Loi de Jeﬀreys pour un mod`ele AR(1)
La loi a priori de Jeﬀreys porte `a controverse dans ce cas, `a cause du d´ebat sur
la prise en compte ou non de la condition de stationnarit´e et des diﬀ´erences qui
en r´esulte. Si nous supposons xt = μ + ϱ(xt−1 −μ) + ϵt avec x0 = 0, l’a priori
de Jeﬀreys associ´e `a cette repr´esentation stationnaire est (Exercice 4.53)
πJ
1 (μ, σ2, ϱ) ∝1
σ2
1
p
1 −ϱ2 .
Lorsque la r´egion de non stationnarit´e |ϱ| > 1 est incluse, Phillips (1991) montre
que l’a priori de Jeﬀreys est alors (Exercice 4.55)
πJ
2 (μ, σ2, ϱ) ∝1
σ2
1
p
|1 −ϱ2|
s˛˛˛˛1 −
1 −ϱ2T
T(1 −ϱ2)
˛˛˛˛ .
Bien que πJ
2 (μ, σ2, ϱ) soit ´equivalent `a πJ
1 (μ, σ2, ϱ) pour des valeurs ´elev´ees de
T et |ϱ| < 1, la partie dominante de la loi a priori correspond `a la r´egion de non
stationnarit´e, puisqu’elle est ´equivalente `a ϱ2T (Bauwens et al., 1999). Berger
et Yang (1994) ont aussi montr´e que la loi a priori de r´ef´erence est πJ
1 et qu’elle
n’est d´eﬁnie que lorsque la contrainte de stationnarit´e est v´eriﬁ´ee. Ils sugg`erent
alors de sym´etriser cette loi a priori sur la r´egion |ϱ| > 1, posant
πB(μ, σ2, ϱ) ∝1
σ2
(
1/
p
1 −ϱ2
si |ϱ| < 1,
1/|ϱ|
p
ϱ2 −1
si |ϱ| > 1,
qui a une forme plus raisonnable que πJ
2 , comme le montre la Figure 4.3.
−3
−2
−1
0
1
2
3
0
1
2
3
4
5
6
7
x
pi
Fig. 4.3. Graphes des lois a priori πJ
1 (ϱ) et πB(ϱ) pour T = 10.
Comme le d´etaillent Bauwens et al. (1999, Section 6.8), il est aussi possible de
construire des lois a priori de Jeﬀreys dans les cas stationnaire et non station-
naire lorsqu’on prend en compte la loi de la valeur initiale x0, ce qui donne des
lois similaires `a πJ
1 et πJ
2 .

4.7 Notes
233
4.7.3 Mod`eles ARCH
Les mod`eles ARCH, introduits par Engle (1982), sont utilis´es, notamment en Fi-
nance, pour repr´esenter des processus dont les termes d’erreur sont ind´ependants
et de variance non constante dans le temps ; un processus ARCH(p) par exemple
se d´eﬁnit comme
xt = σtϵt ,
σ2
t = α +
p
X
i=1
βix2
t−i ,
(4.40)
o`u les ϵt sont i.i.d. N (0, 1). L’acronyme ARCH signiﬁe autoregressive conditional
heterocedasticity, le dernier terme ´etant utilis´e par les ´econom`etres pour qualiﬁer
les mod`eles `a variance non constante. Gouri´eroux (1997) d´ecrit ces mod`eles
en d´etail, ainsi que les m´ethodes inf´erentielles classiques correspondantes ; voir
Bauwens et al. (1999, Section 7.4) pour des extensions bay´esiennes aux processus
GARCH (pour generalised ARCH).
Comme le montrent Nelson (1990) et Kleibergen et Van Dijk (1993), une condi-
tion de stationnarit´e pour un mod`ele ARCH(1) est que E[log(β1ϵ2
t)] < 0, ce qui
est ´equivalent `a β1 < 3.4.
Au contraire des mod`eles `a volatilit´e stochastique de la Note 4.7.4, les mod`eles
ARCH(p) b´en´eﬁcient de fonctions de vraisemblance exprimables analytique-
ment, conditionnellement aux valeurs initiales x1, . . . , xp. Les non-lin´earit´es dans
les termes de variance requi`erent cependant l’utilisation de m´ethodes d’approxi-
mation comme celles du Chapitre 6.
4.7.4 Mod`eles `a volatilit´e stochastique
Les mod`eles `a volatilit´e stochastique s’appliquent `a d´ecrire la volatilit´e, log(σ2
t ),
d’une s´erie xt d’une variable al´eatoire. Bien que de tels mod`eles soient plus
complexes `a ´etudier que leurs contreparties ARCH, ils sont souvent utilis´es en
Finance pour mod´eliser des s´eries pr´esentant des variations d’´echelle brusques
(voir, par exemple, Jacquier et al., 1994).
Une illustration simple de ces mod`eles est le cas SV(1), o`u (t = 1, . . . , T )
(
y∗
t = α + ϱy∗
t−1 + σϵ∗
t−1 ,
yt = ey∗
t /2ϵt ,
(4.41)
et o`u les ϵt et ϵ∗
t ’s sont i.i.d. N (0, 1). La quantit´e non observ´ee (y∗
t ) repr´esente
donc la volatilit´e. (Une hypoth`ese courante sur la condition initiale est que y∗
0 ∼
N (α, σ2).) La Figure 4.4 repr´esente une s´erie simul´ee de volatilit´es stochastiques
pour σ = 1 et ϱ = .9.
La diﬃcult´e avec ce mod`ele est que l’information relative aux param`etres
(α, ϱ, σ) est contenue dans les volatilit´es non observ´ees. En eﬀet, condition-
nellement `a y∗
t , ces volatilit´es sont ind´ependantes de yt. (Bien entendu, les
param`etres d´ependent bien des donn´ees, au moins marginalement.) De plus,
la vraisemblance observ´ee L(α, ϱ, σ|y0, . . . , yT ) n’admet pas d’expression ana-
lytique, puisque les y∗
t ne peuvent pas ˆetre marginalis´es explicitement. En re-
vanche, la vraisemblance compl`ete est explicite, soit

234
4 Estimation bay´esienne ponctuelle
 
 
0
100
200
300
400
500
-10
-5
0
5
10
15
20
Fig. 4.4. ´Echantillon simul´e du mod`ele de volatilit´e stochastique (4.41) avec σ = 1
et ϱ = .9. (Source : Robert et Casella, 1999.)
Lc(α, ϱ, σ|y0, y∗
0 . . . , yT , y∗
T ) ∝
(4.42)
σ−T +1 exp −
(
(y∗
0 −α)2 +
T
X
t=1
(y∗
t −α −ϱy∗
t−1)2
) ﬃ
2σ2
exp −
T
X
t=0
n
y2
t e−y∗
t + y∗
t
o
/2 .
Ceci peut alors ˆetre utilis´e dans des m´ethodes simul´ees (Chapitre 6), en alter-
nance avec la simulation des volatilit´es non observ´ees y∗
t . La Figure 4.5 illustre
une telle simulation pour le jeu de donn´ees simul´e de la Figure 4.4, tel que
les valeurs des y∗
t sont connues. (L’image ﬂoue au-dessus du graphe est appel´ee
carte d’allocation et repr´esente les valeurs successives des y∗
t comme des niveaux
de gris correspondants aux it´erations de la m´ethode simul´ee utilis´ee.)
4.7.5 Lois a priori poly-t
Les lois a priori poly-t ont ´et´e propos´ees par Dr`eze (1976b) et Richard et
Tompa (1980) comme une alternative robuste aux lois conjugu´ees pour les
mod`eles de r´egression lin´eaire. Leur motivation est donn´ee par l’exemple suivant,
d´evelopp´e par Bauwens et al. (1999, Section 4.5). Consid´erons deux r´egressions
ind´ependantes,
y1 = X1β + σ1ε1, y2 = X2β + σ2ε2, ε1 ∼NT1(0, IT1), ε2 ∼NT2(0, IT2).
Si π(β, σ1, σ2) = 1/σ1σ2, l’int´egration des variances σi donne la loi a posteriori
marginale dite 2 −0 poly-t
π(β|y1, y2) ∝[S1 + (β −ˆβ1)tM1(β −ˆβ1)]−T1/2
×[S2 + (β −ˆβ2)tM2(β −ˆβ2)]−T2/2 ,
o`u ˆβi est l’estimateur des moindres carr´es ordinaires (Xt
i Xi)−1Xiyi, Mi =
(Xt
i X) et Si = ||yi −Xi −ˆβi||2 (i = 1, 2).
En g´en´eral, une loi m −n poly-t est d´eﬁnie comme le produit de m densit´es de
Student, divis´e par n densit´es du mˆeme type,

4.7 Notes
235
 
Fig. 4.5.
Carte d’allocation (haut) et allocations moyennes par vraies volatilit´es
(bas) pour le mod`ele (4.41). Les vraies volatilit´es sont repr´esent´ees par des tirets.
(Source : Mengersen et al., 1999˙)
ϕm,n(x) ∝
n
Y
j=1
ˆ
1 + (x −μ0
j)tP 0
j (x −μ0
j)
˜ν0
j /2
ﬃm
Y
j=1
ˆ
1 + (x −μ1
j)tP 1
j (x −μ1
j)
˜ν1
j /2 .
Comme le montrent Bauwens et al. (1999, Th´eor`eme A.21), les densit´es ϕm,0
peuvent s’exprimer comme un m´elange (continu) de densit´es r´eguli`eres de
Student par (m −1) variables auxiliaires, une propri´et´e qui peut s’utiliser soit
pour une simulation directe, comme dans Bauwens (1984), soit pour une mise en
œuvre MCMC (Chapitre 6), puisque le calcul direct de la constante de normali-
sation de ϕm,n, ou de l’esp´erance a posteriori correspondante, n’est pas possible.
Une diﬃcult´e suppl´ementaire avec les lois a priori poly-t est que, relativement
aux lois conjugu´ees, elles n´ecessitent la d´etermination d’un nombre beaucoup
plus grand d’hyperparam`etres.

5
Tests et r´egions de conﬁance
“Twenty-six more tests were going to take the rest of daylight,
maybe more. Heat or no heat, the days still grew shorter as if winter
really was coming on, and a failed test would take a few minutes longer
that one passed, just to make certain.”
Robert Jordan, Lord of Chaos.
5.1 Introduction
Bien que la th´eorie des tests puisse ˆetre envisag´ee comme cas particu-
lier de la Th´eorie de la D´ecision pour un espace de d´ecision restreint (et
mˆeme comme un probl`eme d’estimation), nous consid´erons l’inf´erence sur les
tests dans un chapitre s´epar´e, car il y a beaucoup plus d’ambigu¨ıt´e dans la
d´eﬁnition des buts inf´erentiels pour les tests que pour l’estimation d’une fonc-
tion r´eguli`ere du param`etre. En eﬀet, cette partie de l’inf´erence statistique
bay´esienne est encore incompl`ete, dans le sens o`u plusieurs autres r´eponses
ont ´et´e avanc´ees, mais aucune n’est enti`erement satisfaisante. En particulier,
il existe des diﬀ´erences notoires entre la th´eorie des tests fr´equentistes et celle
des tests bay´esiens. De ce point de vue, le cadre des tests rend l’approche
bay´esienne plutˆot attrayante, car la notion de probabilit´e d’une hypoth`ese,
π(θ ∈Θ0|x), ne peut ˆetre d´eﬁnie qu’`a travers cette approche.
En r´ealit´e, certains bay´esiens pensent que les tests ne devraient pas exister,
ou, du moins, les tests d’une hypoth`ese nulle ponctuelle (voir, par exemple,
Gelfand et al., 1992); nous verrons dans ce chapitre plusieurs raisons philo-
sophiques qui d’une mani`ere ou d’une autre, plaident pour cette perspective

238
5 Tests et r´egions de conﬁance
radicale. Ces raisons vont de l’aspect r´educteur de la notion de mod`ele (aucun
mod`ele n’est correct, mais certains mod`eles sont moins faux [ou plus utiles]
que d’autres), aux modiﬁcations artiﬁcielles de la loi a priori impos´ee par l’hy-
poth`ese nulle ponctuelle, au manque de structure d´ecisionnelle du probl`eme
donn´e, `a l’utilisation subs´equente de fonctions de coˆut rudimentaires 0 −1
et de niveaux d’acceptation conventionnels, `a l’impossibilit´e d’utiliser des lois
a priori impropres dans les cas d’hypoth`eses ponctuelles et dans le cadre du
choix de mod`ele (Chapitre 7). Mais les consid´erations pragmatiques sont telles
que la boˆıte `a outils bay´esienne se doit d’inclure aussi des techniques de tests,
ne serait-ce que parce que les utilisateurs de la Statistique ont ´et´e form´es et
habitu´es `a traduire leurs probl`emes en termes de tests, ´etant donn´e leur forte
inclination `a prendre cette formulation au pied de la lettre.
Nous consid´ererons d’abord dans la Section 5.2 l’approche bay´esienne stan-
dard des tests, qui repose sur une ´evaluation des d´ecisions par des coˆuts 0−1 et
comparerons les proc´edures bay´esiennes avec leurs homologues fr´equentistes
dans la Section 5.3. Nous proposerons ensuite dans la Section 5.4 une alterna-
tive `a l’approche d´ecisionnelle fond´ee sur des coˆuts plus adapt´es qui mettent
en avant l’´evaluation ex post pour des proc´edures de tests (par opposition aux
proc´edures de Neyman-Pearson pour lesquelles l’´evaluation fonctionne dans
un esprit ex ante).
Ce chapitre exhibe un fort contraste entre les approches bay´esienne et
fr´equentiste, et ce de diverses perspectives. Cette opposition est r´ev´elatrice du
caract`ere incomplet de la mod´elisation classique, qui n´ecessite des concepts
artiﬁciels pour construire ses proc´edures optimales. Contrairement au cadre
de l’estimation ponctuelle, ces proc´edures fr´equentistes optimales ne sont plus
des limites de proc´edures bay´esiennes et elles en diﬀ`erent num´eriquement.
Cependant, nous mod´erons ce rejet dans la Section 5.3 en montrant que les
proc´edures classiques et bay´esiennes non informatives peuvent parfois mener
`a des conclusions similaires. Le Chapitre 7 traite du choix de mod`ele, qui peut
ˆetre vu comme un cas particulier de tests d’hypoth`eses nulles ponctuelles,
mais il pr´esente assez de sp´eciﬁcit´es et de diﬃcult´es propres pour m´eriter
un chapitre `a lui seul (sans mˆeme prendre en compte le fait qu’il requi`ere
l’utilisation quasi syst´ematique des m´ethodes num´eriques pr´esent´ees dans le
Chapitre 6).
5.2 Une premi`ere approche de la th´eorie des tests
5.2.1 Tests d´ecisionnels
Soit un mod`ele statistique f(x|θ) avec θ ∈Θ. ´Etant donn´e un sous-
ensemble d’int´erˆet de Θ, Θ0, qui se r´eduit parfois `a un singleton {θ0}, la
question pos´ee est : la vraie valeur du param`etre θ appartient-elle `a Θ0, ce

5.2 Une premi`ere approche de la th´eorie des tests
239
qu’on appelle tester l’hypoth`ese37
H0 : θ ∈Θ0,
souvent appel´ee hypoth`ese nulle. Pour les mod`eles lin´eaires, Θ0 peut ˆetre un
sous-espace de l’espace du vecteur Θ et le probl`eme de test est alors un cas
particulier du probl`eme g´en´erique du choix de mod`ele, probl`eme auquel le
Chapitre 7 est consacr´e.
Exemple 5.1. Soit un mod`ele de r´egression logistique,
Pα(y = 1) = 1 −Pα(y = 0) = exp(αtx)/(1 + exp(αtx)),
α, x ∈Rp,
qui mod´elise la probabilit´e de d´evelopper un cancer de la prostate dans sa
vie en fonction de variables explicatives x = (x1, . . . , xp). On s’int´eresse parti-
culi`erement aux variables li´ees `a l’environnement de travail comme la concen-
tration d’amiante xi0 ; un syndicat peut par exemple vouloir tester si le coef-
ﬁcient αi0 correspondant `a xi0 est nul ou pas.
∥
Dans la perspective de Neyman-Pearson (Section 5.3), le probl`eme de test
est formalis´e `a l’aide d’un espace de d´ecision D restreint `a {oui, non} ou,
d’une mani`ere ´equivalente, `a {1, 0}. En eﬀet, il est logique de comprendre un
probl`eme de test comme une inf´erence sur la fonction indicatrice IΘ0(θ) et,
par cons´equent, de proposer des r´eponses dans IΘ0(Θ) = {0, 1}. Bien entendu,
la pertinence d’une telle restriction est moins ´evidente lorsque l’on consid`ere
que les tests apparaissent souvent comme composantes (ou comme ´etapes
pr´eliminaires) de structures inf´erentielles plus complexes et, en particulier,
que la r´eponse `a la question test´ee a aussi des cons´equences en terme d’er-
reurs d’estimation (standard). Il serait alors plus int´eressant de proposer des
proc´edures prenant des valeurs dans [0, 1]. (Nous examinerons cette approche
dans la Section 5.4.)
Dans certains cas, on dispose d’une information additionnelle sur le sup-
port de θ, `a savoir que θ ∈Θ0 ∪Θ1 ̸= Θ. Dans ce cas, on d´eﬁnit l’hypoth`ese
alternative contre laquelle nous testons H0 comme
H1 : θ ∈Θ1.
Dans cette formalisation, toute proc´edure de test ϕ apparaˆıt comme un esti-
mateur de IΘ0(θ) et nous n’avons besoin que d’une fonction de coˆut L(θ, ϕ)
pour construire des estimateurs de Bayes. Par exemple, la fonction de coˆut
propos´ee par Neyman et Pearson est le coˆut 0 −1
L(θ, ϕ) =

1
si ϕ ̸= IΘ0(θ),
0
sinon,
37Il y a une certaine ambigu¨ıt´e dans la terminologie : le mot test couvre simul-
tan´ement la question et la proc´edure utilis´ee pour r´epondre `a la question.

240
5 Tests et r´egions de conﬁance
pr´esent´ee dans le Chapitre 2. Pour ce coˆut, la solution bay´esienne est
ϕπ(x) =

1
si P π(θ ∈Θ0|x) > P π(θ ∈Θc
0|x),
0
sinon.
Cet estimateur se justiﬁe ais´ement en termes intuitifs, car il choisit l’hypoth`ese
avec la probabilit´e a posteriori la plus grande. Une g´en´eralisation du coˆut ci-
dessus est de p´enaliser diﬀ´eremment les erreurs suivant que l’hypoth`ese nulle
est vraie ou fausse. Les coˆuts pond´er´es 0 −1
L(θ, ϕ) =
⎧
⎪
⎨
⎪
⎩
0
si ϕ = IΘ0(θ),
a0
si θ ∈Θ0 et ϕ = 0,
a1
si θ ̸∈Θ0 et ϕ = 1,
(5.1)
sont appel´es “a0 −a1” pour des raisons ´evidentes. L’estimateur de Bayes
associ´e est alors donn´e par le r´esultat suivant.
Proposition 5.2. Sous le coˆut (5.1), l’estimateur de Bayes associ´e `a la loi
a priori π est
ϕπ(x) =
⎧
⎨
⎩
1
si P π(θ ∈Θ0|x) >
a1
a0 + a1
,
0
sinon.
Preuve.
Puisque le coˆut a posteriori est
L(π, ϕ|x) =

Θ
L(θ, ϕ)π(θ|x)dθ
= a0P π(θ ∈Θ0|x)I{0}(ϕ) + a1P π(θ ̸∈Θ0|x)I{1}(ϕ),
l’estimateur de Bayes peut ˆetre calcul´e directement.
⊓⊔
Pour ce type de coˆut, l’hypoth`ese nulle H0 est rejet´ee quand la probabilit´e
a posteriori de H0 est trop petite, le niveau d’acceptation a1/(a0 + a1) ´etant
d´etermin´e par le choix de la fonction de perte. Notons que ϕπ ne d´epend que
de a0/a1 et que, plus a0/a1 est grand, c’est-`a-dire plus une r´eponse incorrecte
est p´enalis´ee sous H0 relativement `a H1, plus la probabilit´e a posteriori de H0
doit ˆetre petite pour ˆetre rejet´ee.
Exemple 5.3. Soient x ∼B(n, p) et Θ0 = [0, 1/2]. Pour la loi a priori
uniforme π(p) = 1, la probabilit´e a posteriori de H0 est
P π(p ≤1/2|x) =
 1/2
0
px(1 −p)n−xdp
B(x + 1, n −x + 1)
=
(1/2)n+1
B(x + 1, n −x + 1)

1
x + 1 +
n −x
(x + 1)(x + 2) + . . . + (n −x)!x!
(n + 1)!

qui peut se calculer facilement et ˆetre compar´ee au niveau d’acceptation.
∥

5.2 Une premi`ere approche de la th´eorie des tests
241
Exemple 5.4. Soient x ∼N (θ, σ2) et θ ∼N (μ, τ2). Alors π(θ|x) est la loi
normale N (μ(x), ω2) avec
μ(x) = σ2μ + τ 2x
σ2 + τ 2
et
ω2 =
σ2τ 2
σ2 + τ 2 .
Pour tester H0 : θ < 0, nous calculons
P π(θ < 0|x) = P π
θ −μ(x)
ω
< −μ(x)
ω

= Φ (−μ(x)/ω) .
Si za0,a1 est le quantile a1/(a0+a1), donc s’il satisfait Φ(za0,a1) = a1/(a0+a1),
H0 est accept´ee lorsque
−μ(x) > za0,a1ω,
la borne sup´erieure d’acceptation ´etant alors
−σ2
τ 2 μ −(1 + σ2
τ 2 )ωza0,a1.
∥
Notons de nouveau que, d’un point de vue bay´esien, il semble naturel de
fonder la d´ecision sur la probabilit´e a posteriori que l’hypoth`ese soit vraie.
Dans la Section 5.4, nous montrons qu’une approche d´ecisionnelle alternative
m`ene `a cette probabilit´e a posteriori en tant qu’estimateur de Bayes et ´evite
ainsi la comparaison `a un niveau d’acceptation pr´ed´etermin´e. En fait, une
diﬃcult´e li´ee aux coˆuts (5.1) est le choix des poids a0 et a1, car ils sont
choisis le plus souvent de mani`ere automatique plutˆot que d´etermin´es par des
consid´erations d’utilit´e.
5.2.2 Le facteur de Bayes
Bien que, d’un point de vue d´ecisionnel, le facteur de Bayes ne soit
qu’une transformation bijective de la probabilit´e a posteriori, il a ﬁni par
ˆetre consid´er´e comme r´eponse en soi en th´eorie des tests bay´esiens, sous l’im-
pulsion de Jeﬀreys (1939).
D´eﬁnition 5.5. Le facteur de Bayes est le rapport des probabilit´es a poste-
riori des hypoth`eses nulle et alternative sur le rapport des probabilit´es a priori
de ces mˆemes hypoth`eses, soit
Bπ
01(x) = P(θ ∈Θ0 | x)
P(θ ∈Θ1 | x)
'π(θ ∈Θ0)
π(θ ∈Θ1).

242
5 Tests et r´egions de conﬁance
Ce rapport ´evalue la modiﬁcation de la vraisemblance de l’ensemble Θ0
par rapport `a celle de l’ensemble Θ1 due `a l’observation et peut se comparer
naturellement `a 1, bien qu’une ´echelle de comparaison exacte doive ˆetre fond´ee
sur une fonction de coˆut. Dans le cas particulier o`u Θ0 = {θ0} et Θ1 = {θ1},
le facteur de Bayes se simpliﬁe et devient le rapport de vraisemblance classique
Bπ
01(x) = f(x|θ0)
f(x|θ1).
En g´en´eral, le facteur de Bayes d´epend de l’information a priori, mais il est
souvent propos´e comme r´eponse bay´esienne “objective”, car il ´elimine partiel-
lement l’inﬂuence du mod`ele a priori et souligne le rˆole des observations. De
fait, il peut ˆetre per¸cu comme un rapport de vraisemblance bay´esien, car, si
π0 est la loi a priori sous H0 et π1, la loi a priori sous H1, Bπ
01(x) peut s’´ecrire
Bπ
01(x) =

Θ0 f(x|θ0)π0(θ) dθ

Θ1 f(x|θ1)π1(θ) dθ = m0(x)
m1(x) ,
(5.2)
ce qui revient donc `a remplacer les vraisemblances par des marginales sous les
deux hypoth`eses.
Comme nous l’avons indiqu´e ci-dessus, le facteur de Bayes est, d’un point
de vue d´ecisionnel, compl`etement ´equivalent `a la probabilit´e a posteriori de
l’hypoth`ese nulle puisque, sous (5.1), H0 est accept´e lorsque
Bπ
01(x) > a1
a0
6ϱ0
ϱ1
= a1ϱ1
a0ϱ0
,
(5.3)
o`u
ϱ0 = π(θ ∈Θ0)
et
ϱ1 = π(θ ∈Θ1) = 1 −ϱ0.
(5.4)
Cette version alternative de la Proposition 5.2 fournit ainsi une illustration
de la dualit´e qui existe entre coˆuts et lois a priori, dualit´e d´ej`a mentionn´ee
au Chapitre 2. En eﬀet, (5.3) montre qu’il est ´equivalent de pond´erer de la
mˆeme fa¸con les deux hypoth`eses, ϱ0 = ϱ1 = 1/2, et de modiﬁer les p´enalit´es
d’erreur dans a′
i = aiϱi (i = 0, 1) ou de p´enaliser de la mˆeme fa¸con les deux
types d’erreurs (a1 = a0 = 1), lorsque la loi a priori int`egre les poids r´eels
dans les probabilit´es a priori pond´er´ees,
ϱ′
0 =
a0ϱ0
a0ϱ0 + a1ϱ1
,
ϱ′
1 =
a1ϱ1
a0ϱ0 + a1ϱ1
.
`A la suite de Jeﬀreys (1939) et de Good (1952), le facteur de Bayes est
d´esormais un outil `a part enti`ere (voir, par exemple, Kass et Raftery, 1995,
pour une revue d´etaill´ee). En particulier, Jeﬀreys (1939) a d´evelopp´e une
´echelle “absolue” pour ´evaluer le degr´e de certitude en faveur ou au d´etriment
de H0 apport´e par les donn´ees, en l’absence d’un cadre d´ecisionnel v´eritable.
L’´echelle de Jeﬀreys est la suivante :

5.2 Une premi`ere approche de la th´eorie des tests
243
(i) si log10(Bπ
10) varie entre 0 et 0.5, la certitude que H0 est fausse est faible,
(ii) si elle est entre 0.5 et 1, cette certitude est substantielle,
(iii) si elle est entre 1 et 2, elle est forte et
(iv) si elle est au-dessus de 2, elle est d´ecisive,
avec la mˆeme ´echelle en faveur de H0 pour les valeurs n´egatives. Bien entendu,
cette graduation du facteur de Bayes donne quelques indications sur le degr´e
de certitude, mais les limites pr´ecises s´eparant une cat´egorie d’une autre sont
conventionnelles et peuvent ˆetre chang´ees de fa¸con arbitraire, comme l’ont
illustr´e Kass et Raftery (1995). C’est une cons´equence du manque de justiﬁ-
cation d´ecisionnelle de cette m´ethode et de l’absence de fonction de coˆut. (La
critique s’applique ´egalement aux niveaux α conventionnels de 0.05 ou 0.01
utilis´es pour a0/(a0 + a1) dans (5.1).)
Le Chapitre 6 donnera des pr´ecisions sur les m´ethodes utilis´ees pour ap-
procher les facteurs de Bayes lorsque l’int´egrale dans (5.2) ne peut pas se
calculer analytiquement, ce qui est souvent le cas.
Exemple 5.6. (Kass et Raftery, 1995)
La “hot hand” en basket ball est
une croyance r´epandue que les joueurs ont des bons et des mauvais jours,
plutˆot qu’une probabilit´e constante de r´eussir un tir. Pour un joueur donn´e,
le mod`ele sous l’hypoth`ese nulle (pas de hot hand) est alors H0 : yi ∼B(ni, p)
(i = 1, . . . , G), o`u G est le nombre de parties et ni (resp. yi) le nombre de
tirs (resp. de bons tirs) pendant la i-i`eme partie. Le mod`ele sous l’alterna-
tive g´en´erale est H1 : yi ∼B(ni, pi), la probabilit´e pi variant de partie en
partie. Sous une loi a priori conjugu´ee pi ∼Be(ξ/ω, (1 −ξ)/ω), la moyenne
E[pi|ξ, ω] = ξ est distribu´ee selon une loi a priori uniforme U ([0, 1]), comme
l’est p sous H0, et ω est ﬁx´e. Le facteur de Bayes est alors
B10 =
 1
0
G

i=1
 1
0
pyi
i (1 −pi)ni−yipα−1
i
(1 −pi)β−1d pi
×{Γ(1/ω)/[Γ(ξ/ω)Γ((1 −ξ)/ω)]}G
 1
0 p
P
i yi(1 −p)
P
i(ni−yi)d p
dξ
=
 1
0
G

i=1
[Γ(yi + ξ/ω)Γ(ni −yi + (1 −ξ)/ω)/Γ(ni + 1/ω)]
×
{Γ(1/ω)/[Γ(ξ/ω)Γ((1 −ξ)/ω)]}G
Γ(
i yi + 1)Γ(
i(ni −yi) + 1)/Γ(
i ni + 2) dξ ,
o`u α = ξ/ω et β = (1 −ξ)/ω. Formellement, le num´erateur peut se calculer
exactement, malgr´e les fonctions gamma, grˆace `a la simpliﬁcation

244
5 Tests et r´egions de conﬁance
Γ(yi + ξ/ω)/Γ(ξ/ω) =
yi

j=1
(j −1 + ξ/ω),
Γ(ni −yi + (1 −ξ)/ω)/Γ((1 −ξ)/ω)] =
n−i−yi

j=1
(j −1 + (1 −ξ)/ω) ,
mais la fonction de ξ `a int´egrer est alors un polynˆome de degr´e ´elev´e. La
r´esolution de l’int´egrale n´ecessite par cons´equent un logiciel de calcul formel
comme Maple ou Mathematica. Pour un joueur donn´e, la valeur de B10 est
0.16 pour ω = 0.005 et G = 138, ce qui n’indique aucune preuve d´ecisive en
faveur de l’hypoth`ese de la hot hand.
∥
5.2.3 Modiﬁcation de la loi a priori
La notion de facteur de Bayes permet aussi de mettre en ´evidence un
aspect important des tests bay´esiens. En fait, ce facteur n’est d´eﬁni que lorsque
ϱ0 ̸= 0 et ϱ1 ̸= 0. Cela implique que, si H0 ou H1 sont a priori impossibles, les
observations ne vont pas modiﬁer cette information absolue : des probabilit´es
nulles a priori le restent a posteriori ! Par cons´equent, une hypoth`ese nulle
ponctuelle H0 : θ = θ0 ne peut pas ˆetre test´ee sous une loi a priori continue.
Plus g´en´eralement, la s´election de variables (Chapitre 7) est incompatible avec
des lois a priori absolument continues par rapport `a la mesure de Lebesgue
d´eﬁnies sur l’espace le plus grand.
Le test d’une hypoth`ese nulle ponctuelle (ou `a probabilit´e nulle par rapport
`a la mesure dominante) impose par cons´equent une modiﬁcation radicale de
la loi a priori, car il exige de construire une loi a priori pour les deux sous-
ensembles Θ0 et Θ1, par exemple, des lois π0 et π1 de densit´es
g0(θ) ∝π(θ)IΘ0(θ),
g1(θ) ∝π(θ)IΘ1(θ),
(relativement aux mesures naturelles sur Θ0 et Θ1) bien que cette d´eﬁnition
ne soit pas toujours d´enu´ee d’ambigu¨ıt´e (voir l’Exercice 5.5). Combin´ees aux
probabilit´es a priori ϱ0 et ϱ1 de Θ0 et Θ1 donn´ees par (5.4), π0 et π1 d´eﬁnissent
la loi a priori π. En d’autres termes,
π(θ) = ϱ0π0(θ) + ϱ1π1(θ).
(Lorsque Θ0 = {θ0}, la loi a priori sur Θ0 est juste la masse de Dirac en θ0.)
D’un point de vue d´ecisionnel, cette modiﬁcation de la loi a priori est
surprenante, puisqu’elle revient `a mettre un poids a priori sur un ensemble de
mesure 0. Elle souligne aussi la dichotomie impos´ee par l’approche habituelle
des tests pour laquelle l’hypoth`ese nulle est soit vraie, soit fausse. Cependant,
`a moins que le d´ecideur ne soit inﬂexible sur le choix de la loi a priori π et,
dans ce cas, H0 devrait vraiment ˆetre refus´e si π ne donne aucun poids `a Θ0,

5.2 Une premi`ere approche de la th´eorie des tests
245
on peut consid´erer le probl`eme de test comme fournissant une information
suppl´ementaire sur θ (mˆeme si celle-ci est vague). Eﬀectivement, tester θ ∈
Θ0 signiﬁe qu’il y a une certaine chance que θ appartienne vraiment `a Θ0
(sinon, on ne se poserait pas la question !) et par cons´equent qu’une certaine
information, peut-ˆetre mal d´eﬁnie, a ´et´e fournie sur ce fait.
Consid´erer les cadres de test comme sources d’information est plus convain-
cant encore si la d´ecision ﬁnale n’est pas la r´eponse au test mais l’estimation
d’une fonction de θ, c’est-`a-dire lorsque le test signiﬁe le choix d’un sous-
mod`ele. Un test pr´eliminaire sur l’information vague peut alors am´eliorer
l’´etape d’estimation. De plus, en gardant cette perspective du choix de mod`ele
comme objectif r´eel de l’analyse, il est aussi logique de d´evelopper une loi a
priori s´epar´ee pour chaque sous-espace, puisqu’un seul des deux Θi sera pris
en compte apr`es l’´etape de test. Par exemple, pour une hypoth`ese nulle ponc-
tuelle donn´ee, H0 : θ = θ0, la loi non informative π(θ) = 1 ne peut pas ˆetre
consid´er´ee comme une loi a priori sur Θ acceptable, car la valeur particuli`ere
θ0 a ´et´e choisie comme une valeur possible pour θ. (Dans le Chapitre 7, nous
d´efendrons davantage la perspective que des param`etres similaires apparais-
sant dans deux mod`eles diﬀ´erents doivent ˆetre consid´er´es comme des entit´es
s´epar´ees.) En g´en´eral, consid´erer que les probl`emes de test se produisent `a
cause d’observations additionnelles (indisponibles) peut aider `a la construc-
tion de la loi a priori non informative, mˆeme s’il n’y a pas de consensus sur
une mod´elisation a priori non informative des tests (voir la Section 5.3.5).
5.2.4 Hypoth`eses nulles ponctuelles
Une critique usuelle des hypoth`eses nulles ponctuelles est qu’elles ne sont
pas r´ealistes (voir, pour illustration, Casella et Berger, 1987)38. Par exemple,
comme l’a soulign´e Good (1980), il n’y a pas de sens `a tester que la probabilit´e
qu’il pleuve demain est de39 0.7163891256 . . . Cependant, certains probl`emes
statistiques n´ecessitent vraiment un test d’hypoth`ese nulle ponctuelle. Par
exemple, pour l’estimation de m´elanges (voir la Section 1.1 et la Section 6.4),
il peut ˆetre important de savoir si une loi de m´elange poss`ede deux ou trois
composantes et il est donc n´ecessaire de tester si le poids d’une de ces com-
posantes est nul. De la mˆeme fa¸con, dans le domaine de la r´egression lin´eaire,
des tests de nullit´e des coeﬃcients de la r´egression permettent l’´elimination
des variables exog`enes inutiles, comme dans l’Exemple 5.1. D’une fa¸con plus
pertinente encore, tester si l’univers est en expansion, s’il se contracte ou s’il
est stable revient `a tester si la constante de Hubble est plus grande, plus petite
ou ´egale `a une valeur sp´eciﬁque h0.
38Roger Berger et non pas James Berger !
39En revanche, il y a un sens `a tester si la pr´evision de 75% donn´ee par le
m´et´eorologiste local est exacte, c’est-`a-dire si la probabilit´e de pluie pour un jour
donn´e est 0.75 ou une autre des probabilit´es annonc´ees par le m´et´eorologiste (voir
l’Exemple 2.12).

246
5 Tests et r´egions de conﬁance
Plus g´en´eralement, des hypoth`eses bilat´erales telles que H0 : θ ∈Θ0 =
[θ0 −ϵ, θ0 + ϵ] peuvent ˆetre approch´ees par H0 : θ = θ0, ce qui entraˆıne une
modiﬁcation des probabilit´es a posteriori, qui sont presque nulles lorsque ϵ
est suﬃsamment petit. C’est le cas notamment lorsque la vraisemblance est
constante autour de θ0 (voir Berger, 1985b, et Berger et Delampady, 1987).
Les hypoth`eses nulles ponctuelles ont aussi une grande importance pratique ;
par exemple, bien qu’il y ait un sens `a d´eterminer si un traitement m´edical
a un eﬀet positif ou n´egatif, la premi`ere question est de d´ecider s’il a un
quelconque eﬀet.
Soit l’hypoth`ese nulle ponctuelle H0 : θ = θ0 ; notons ϱ0 la probabilit´e a
priori que θ = θ0 et g1 la densit´e a priori sous l’alternative. La loi a priori est
alors π0(θ) = ϱ0IΘ0(θ) + (1 −ϱ0)g1(θ) et la probabilit´e a posteriori de H0 est
donn´ee par
π(Θ0|x) =
f(x|θ0)ϱ0

f(x|θ)π(θ) dθ =
f(x|θ0)ϱ0
f(x|θ0)ϱ0 + (1 −ϱ0)m1(x),
la loi marginale sous H1 ´etant
m1(x) =

Θ1
f(x|θ)g1(θ) dθ.
Cette probabilit´e a posteriori peut aussi s’´ecrire
π(Θ0|x) =

1 + 1 −ϱ0
ϱ0
m1(x)
f(x|θ0)
−1
.
De la mˆeme fa¸con, le facteur de Bayes est
Bπ
01(x) =
f(x|θ0)ϱ0
m1(x)(1 −ϱ0)
'
ϱ0
1 −ϱ0
= f(x|θ0)
m1(x)
et nous obtenons la relation g´en´erale suivante entre les deux quantit´es :
π(Θ0|x) =

1 + 1 −ϱ0
ϱ0
1
Bπ
01(x)
−1
.
Exemple 5.7. (Suite de l’Exemple 5.3)
Soit le test de H0 : p = 1/2
contre p ̸= 1/2. Pour g1(p) = 1, la probabilit´e a posteriori est alors donn´ee
par
π(Θ0|x) =

1 + 1 −ϱ0
ϱ0
2nB(x + 1, n −x + 1)
−1
=

1 + 1 −ϱ0
ϱ0
x!(n −x)!
(n −1)! 2n
−1
,
puisque m(x) =
	n
x

B(x + 1, n −x + 1). Par exemple, si n = 5, x = 3 et
ϱ0 = 1/2, la probabilit´e a posteriori est

5.2 Une premi`ere approche de la th´eorie des tests
247

1 +
2
12025
−1
= 15
23
et le facteur de Bayes correspondant est 15/8, proche de 2. Donc, dans la plu-
part des cas les plus favorables, les probabilit´es a posteriori tendent `a favoriser
H0. Lorsque la taille d’´echantillon augmente, les variations des r´eponses pos-
sibles s’´elargissent aussi. Par exemple, si π(p) est Be(1/2, 1/2) et n = 10, les
probabilit´es a posteriori sont donn´ees dans le Tableau 5.1 et soutiennent H0
pour x proche de 5, mˆeme si la loi a priori est plutˆot biais´ee contre l’hypoth`ese
nulle (car les valeurs extrˆemes, 0 et 1, ont un poids important).
∥
Tab. 5.1. Probabilit´es a posteriori de p = 1/2 lorsque x ∼B(10, p).
x
0
1
2
3
4
5
P (p = 1/2|x) 0.0055 0.0953 0.3737 0.6416 0.7688 0.8025
Exemple 5.8. (Suite de l’Exemple 5.4 )
Soit le test de H0 : θ = 0.
Il semble raisonnable de prendre π1 ´egal `a N (μ, τ2) et μ = 0, si aucune
information additionnelle n’est disponible. Alors
m1(x)
f(x|0) =
σ
√
σ2 + τ 2
e−x2/2(σ2+τ 2)
e−x2/2σ2
=

σ2
σ2 + τ 2 exp

τ 2x2
2σ2(σ2 + τ 2)

,
et la probabilit´e a posteriori se calcule comme suit :
π(θ = 0|x) =

1 + 1 −ϱ0
ϱ0

σ2
σ2 + τ 2 exp

τ 2x2
2σ2(σ2 + τ 2)
−1
.
Dans le cas particulier o`u ϱ0 = 1/2 et τ = σ, le Tableau 5.2 donne les proba-
bilit´es a posteriori en fonction de z = x/σ.
∥
Tab. 5.2. Probabilit´es a posteriori de θ = 0 lorsque x ∼N (θ, σ2) pour diﬀ´erentes
valeurs de z = x/σ et pour τ = σ.
z
0
0.68
1.28
1.96
π(θ = 0|z) 0.586 0.557 0.484 0.351
Consid´erons maintenant l’alternative τ2 = 10σ2, suppos´ee indiquer une
information a priori plus diﬀuse sur θ. Les probabilit´es a posteriori de H0
sont alors modiﬁ´ees comme le montre le Tableau 5.3. De mani`ere surprenante,
elles sont toutes plus favorables `a H0 : ce ph´enom`ene est li´e au paradoxe de
Jeﬀreys-Lindley, d´ecrit dans la section suivante.

248
5 Tests et r´egions de conﬁance
Tab. 5.3. Probabilit´es a posteriori de θ = 0 lorsque x ∼N (θ, σ2) pour τ 2 = 10σ2
et z = x/σ.
z
0
0.68
1.28
1.96
π(θ = 0|x) 0.768 0.729 0.612 0.366
5.2.5 Lois a priori impropres
Le recours `a des lois a priori non informatives pour tester des hypoth`eses
est plutˆot d´elicat, et DeGroot (1973) aﬃrme que les lois a priori impropres
ne devraient pas du tout ˆetre utilis´ees pour les tests. En eﬀet, comme nous
l’avons remarqu´e auparavant, le cadre formel des tests n’est pas coh´erent avec
un manque absolu d’information, car eﬀectuer un test implique au moins
une division de l’espace des param`etres en deux sous-ensembles, dont l’un
peut ˆetre de mesure nulle sous une loi impropre comme la loi de Jeﬀreys.
Cependant, l’inconv´enient d’utiliser des lois a priori impropres va plus loin,
car ces derni`eres sont incompatibles avec la plupart des tests d’hypoth`eses
nulles ponctuelles.
Nous illustrons cette diﬃcult´e dans un cadre gaussien, x ∼N (θ, 1), sous
l’hypoth`ese nulle ponctuelle H0 :
θ = 0 test´ee contre H1 : θ ̸= 0. Si nous
utilisons la loi a priori impropre π(θ) = 1 pour θ ̸= 0, donc si π est la loi de
densit´e
π(θ) = 1
2I0(θ) + 1
2 · 1,
la probabilit´e a posteriori de H0 est
π(θ = 0|x) =
e−x2/2
e−x2/2 +
 +∞
−∞e−(x−θ)2/2 dθ
=
1
1 +
√
2πex2/2 .
(Le choix particulier de la constante 1 dans la loi a priori est crucial pour la
discussion suivante, bien qu’il soit arbitraire.) Cette probabilit´e a posteriori
de H0 est donc born´ee sup´erieurement par 1/(1+
√
2π) = 0.285. Ceci implique
que la loi a posteriori est plutˆot biais´ee contre H0, mˆeme dans le cas le plus
favorable. `A moins que l’´echelle de comparaison, c’est-`a-dire le coˆut, ne soit
modiﬁ´ee pour estimer ces valeurs faibles, l’hypoth`ese nulle ponctuelle sera
donc assez souvent rejet´ee. Un ph´enom`ene similaire se produit lorsque Θ0 est
compact. Par exemple, le test de H0 : |θ| ≤1 contre H1 : |θ| > 1 m`ene `a la
probabilit´e a posteriori suivante :
π(|θ| ≤1|x) =
 1
−1 e−(x−θ)2/2 dθ
 +∞
−∞e−(x−θ)2/2 dθ
= Φ(1 −x) −Φ(−1 −x)
= Φ(x + 1) −Φ(x −1),

5.2 Une premi`ere approche de la th´eorie des tests
249
Tab. 5.4. Probabilit´es a posteriori de |θ| < 1 pour x ∼N (θ, 1).
x
0.0
0.5
1.0
1.5
2.0
π(|θ| ≤1|x)
0.683 0.625 0.477 0.302 0.157
Tab. 5.5. Probabilit´es a posteriori de θ = 0 pour la loi a priori de Jeﬀreys π(θ) = 1
et x ∼N (θ, 1).
x
0.0
1.0
1.65
1.96
2.58
π(θ = 0|x) 0.285 0.195 0.089 0.055 0.014
dont les valeurs num´eriques sont donn´ees dans le Tableau 5.4. Par cons´equent,
le support maximal de l’hypoth`ese H0, ´egal `a 0.683, reste mod´er´e.
Une caract´eristique int´eressante de la loi a priori de Lebesgue peut ˆetre ex-
hib´ee par l’hypoth`ese nulle ponctuelle H0 : θ = 0. La proc´edure r´esultante est
en accord avec la r´eponse classique correspondante, comme le montre le Ta-
bleau 5.5. La probabilit´e a posteriori π(θ = 0|x) est eﬀectivement assez proche
des niveaux d’importance classiques 0.10, 0.05 et 0.01 lorsque x est 1.65, 1.96,
ou 2.58 (on d´emontrera dans la Note 5.7.1 que cette comparaison a un sens).
Cette co¨ıncidence n’est pas v´eriﬁ´ee par toutes les valeurs de x mais montre
que, pour les niveaux de signiﬁcation habituels (et pour des objectifs de test),
la r´eponse classique peut ˆetre consid´er´ee comme une r´eponse bay´esienne non
informative, mˆeme si elle correspond `a une loi a priori diﬃcilement justiﬁable.
Une autre illustration de la d´elicate question des lois a priori impropres
dans des cadres de test est fournie par le paradoxe de Jeﬀreys-Lindley. En ef-
fet, les arguments limites ne sont pas valables pour les tests et empˆechent
une construction alternative des r´eponses non informatives. Par exemple,
consid´erant la loi a priori conjugu´ee pr´esent´ee dans l’Exemple 5.4, la pro-
babilit´e a posteriori est
π(θ = 0|x) =

1 + 1 −ϱ0
ϱ0

σ2
σ2 + τ 2 exp

τ 2x2
2σ2(σ2 + τ 2)
−1
,
qui converge vers 1 lorsque la variance a priori τ tend vers +∞, pour
tout x ̸= 0. Cette limite diﬀ`ere de la r´eponse “non informative” construite
pr´ec´edemment [1 +
√
2π exp(x2/2)]−1 et est ´evidemment compl`etement in-
utile. Ce ph´enom`ene peut aussi s’observer en comparant les Tableaux 5.2 et
5.3, car la probabilit´e est plus grande lorsque τ2 = 10σ2 que lorsque τ = σ
pour toutes les valeurs de z consid´er´ees dans les tableaux. Voir Aitkin (1991)
et Robert (1993a) pour des discussions sur ce paradoxe.
Les paradoxes associ´es aux lois a priori impropres comme l’exemple de
Jeﬀreys-Lindley sont en r´ealit´e dus `a une ind´etermination des poids a priori
qui n’apparaˆıt pas dans les probl`emes d’estimation ponctuelle, ni dans les
tests unilat´eraux.

250
5 Tests et r´egions de conﬁance
Exemple 5.9. Soient x ∼N (θ, 1) et H0 : θ ≤0 `a tester contre H1 : θ > 0.
Pour l’a priori diﬀus π(θ) = 1,
π(θ ≤0|x) =
1
√
2π
 0
−∞
e−(x−θ)2/2 dθ = Φ(−x) .
Dans ce cas, la r´eponse bay´esienne g´en´eralis´ee est aussi une proc´edure clas-
sique, appel´ee p-value (voir la Section 5.3.4).
∥
Pour des probl`emes bilat´eraux, si g0 et g1 sont des mesures σ-ﬁnies cor-
respondant `a des lois a priori non informatives tronqu´ees aux sous-espaces Θ0
et Θ1, le choix des constantes de normalisation inﬂuera sur l’estimateur de
Bayes. En eﬀet, si gi est remplac´e par cigi (i = 0, 1), le facteur de Bayes est
multipli´e par c0/c1. Par exemple, si la loi a priori de Jeﬀreys est uniforme et
si g0 = c0, g1 = c1, la probabilit´e a posteriori est
π(θ ∈Θ0|x) =
ϱ0c0

Θ0 f(x|θ) dθ
ϱ0c0

Θ0 f(x|θ) dθ + (1 −ϱ0)c1

Θ1 f(x|θ) dθ
=
ϱ0

Θ0 f(x|θ) dθ
ϱ0

Θ0 f(x|θ) dθ + (1 −ϱ0)[c1/c0]

Θ1 f(x|θ) dθ ,
qui d´epend du rapport c1/c0. Par exemple, l’´equivalent du Tableau 5.5 pour
π(θ) = 10 est donn´e dans le Tableau 5.6, avec des diﬀ´erences importantes
pour la plupart des valeurs de x, car elles diﬀ`erent d’une magnitude.
Tab. 5.6. Probabilit´es a posteriori de θ = 0 pour la loi a priori de Jeﬀreys π(θ) = 10.
x
0.0
1.0
1.65
1.96
2.58
π(θ = 0|x) 0.0384 0.0236 0.0101 0.00581 0.00143
Il est donc n´ecessaire d’´elargir la perspective non informative de ces cadres
de test en d´eveloppant une technique capable de construire les poids ci d’une
fa¸con non informative et acceptable. Bernardo (1980), Spiegelhalter et Smith
(1980), Smith et Spiegelhalter (1982), Aitkin (1991), Pettit (1992), Robert
(1993a) et Berger et Pericchi (1996b,a) ont fait des propositions dans ce
sens, comme le d´etaille la Section 5.2.6. Notons que Jeﬀreys (1961) propo-
sait au contraire d’utiliser des lois a priori propres dans ces cas, comme les
lois C (0, σ2) ou N (0, 10σ2) quand x ∼N (θ, σ2) et H0 : θ = 0. Le probl`eme
est alors que le choix d’une loi a priori propre inﬂuera sur la r´eponse du test.
Avant d’introduire dans la Section 5.2.6 certains des d´eveloppements
r´ecents li´es `a l’utilisation des lois a priori impropres, faisons la remarque sui-
vante : utiliser des lois a priori impropres, comme celle de Jeﬀreys, pour des
tests bilat´eraux reste non satisfaisant, car elles semblent conduire `a trop d’ar-
bitraire au sens o`u de nombreuses solutions contradictoires abondent, reposant

5.2 Une premi`ere approche de la th´eorie des tests
251
sur des principes th´eoriques similaires mais produisant des valeurs num´eriques
diﬀ´erentes, ce qui contredit le principe de vraisemblance. En d’autres termes,
bien que les solutions propos´ees dans la section suivante soient int´eressantes et
convaincantes, en tant que principes constructifs, les diﬃcult´es relatives `a l’uti-
lisation de lois a priori impropres dans les tests font que celles-ci ne rel`event
pas `a proprement parler du paradigme bay´esien. Nous consid´erons dans la
Section 5.3 une approche alternative qui d´eﬁnit une r´eponse bay´esienne la
moins favorable comme une limite inf´erieure d’estimateurs (propres) de Bayes
(mais qui pr´esente ´egalement d’importants d´efauts).
Les diﬃcult´es rencontr´ees avec les lois a priori non informatives montrent
aussi que le probl`eme des tests ne peut pas ˆetre trait´e de fa¸con coh´erente
s’il n’y a pas d’information a priori disponible ; en d’autres termes, l’infor-
mation apport´ee par les observations seules n’est souvent pas suﬃsante pour
d´eterminer cat´egoriquement si l’hypoth`ese est vraie ou fausse. ´Evidemment,
cela renforce la motivation d’un traitement bay´esien de tels probl`emes, car
c’est la seule approche coh´erente qui proﬁte de l’information r´esiduelle.
5.2.6 Pseudo-facteurs de Bayes
La plupart40 des solutions propos´ees pour surmonter les diﬃcult´es li´ees `a
l’emploi de lois a priori impropres reposent sur l’utilisation d’une partie des
donn´ees, aﬁn de transformer les lois impropres en lois propres, ou le recours
`a des observations imaginaires pour obtenir le mˆeme r´esultat.
D´eﬁnition 5.10. Pour une loi a priori impropre π donn´ee, un ´echantillon
(x1, . . . , xn) est un ´echantillon d’apprentissage si la loi a posteriori correspon-
dante π(·|x1, . . . , xn) est propre ; c’est un ´echantillon d’apprentissage minimal
si aucun de ses sous-´echantillons n’est un ´echantillon d’apprentissage.
Exemple 5.11. Pour le mod`ele N (μ, σ2), la taille de l’´echantillon d’appren-
tissage minimal associ´e `a la loi a priori impropre π0(μ, σ2) = 1/σ2 est 2,
car

e−{(x1−μ)2+(x2−μ)2}/2σ2σ−4dμ dσ2
=
 ∞
0
σ−3e−s2/2σ2dσ2 =
 ∞
0
ω3/2−2e−s2ω/2dω ,
tandis que
40Cette section, qui peut ˆetre omise dans une premi`ere lecture, traite de notions
plus avanc´ees, `a savoir les lois a priori intrins`eques d´evelopp´ees par Berger et Pericchi
(1996b,a). Ces notions ne seront pas utilis´ees dans le reste du livre, sauf dans le
Chapitre 7 ; voir Berger et Pericchi (2001), sur qui cette section est fond´ee, pour une
revue beaucoup plus d´etaill´ee.

252
5 Tests et r´egions de conﬁance

e−(x1−μ)2/2σ2σ−3dμ dσ2 = ∞.
Si nous consid´erons maintenant la loi a priori π1(μ, σ2) = 1/σ, la taille de
l’´echantillon d’apprentissage est 3, car

e−{(x1−μ)2+(x2−μ)2}/2σ2σ−3dμ dσ2
=
 ∞
0
σ−2e−s2/2σ2dσ2
=
 ∞
0
ω−1e−s2ω/2dω = ∞,
ce qui est un bon argument en faveur de l’utilisation de la loi π0 plutˆot que
la loi π1.
∥
L’id´ee est alors d’utiliser un ´echantillon d’apprentissage minimal, x(ℓ), pour
transformer la loi a priori impropre π en une loi propre π(·|x(ℓ)) et de traiter
cette loi a posteriori comme si c’´etait une loi a priori propre pour le reste de
l’´echantillon, x(−ℓ), aﬁn d’´eviter une double utilisation des donn´ees, comme
dans Aitkin (1991). Lorsqu’on est confront´e `a une hypoth`ese H0 associ´ee `a
une loi a priori π0 et une hypoth`ese alternative H1 plus g´en´erale de loi a priori
π1, si l’´echantillon d’apprentissage minimal sous H1 est tel que π0(·|x(ℓ)) soit
aussi propre, le pseudo-facteur de Bayes
B(ℓ)
10 =

Θ1 f1(x(−ℓ)|θ1)π1(θ1|x(ℓ))dθ1

Θ0 f0(x(−ℓ)|θ0)π0(θ0|x(ℓ))dθ0
(5.5)
ne d´epend alors pas des constantes de normalisation utilis´ees dans π0 et π1.
Une d´ecomposition utile de ce pseudo-facteur de Bayes est propos´ee dans
Berger et Pericchi (2001).
Lemme 5.12. Dans le cas de lois a priori ind´ependantes, le pseudo-facteur
de Bayes peut s’´ecrire
B(ℓ)
10 = B10(x) × B01(x(ℓ)) ,
(5.6)
avec
B10(x) =

Θ1 f1(x|θ1)π1(θ1)dθ1

Θ0 f0(x|θ0)π0(θ0)dθ0
et
B01(x(ℓ)) =

Θ0 f0(x(ℓ)|θ0)π0(θ0)dθ0

Θ1 f1(x(ℓ)|θ1)π1(θ1)dθ1
.

5.2 Une premi`ere approche de la th´eorie des tests
253
Dans cette d´ecomposition, B10(x) et B01(x(ℓ)) sont les facteurs de Bayes
calcul´es pour des lois a priori non normalis´ees π1 et π0, respectivement pour
tout l’´echantillon x et l’´echantillon d’apprentissage x(ℓ), comme s’il s’agissait
de lois a priori r´eguli`eres. Il est alors simple de voir que multiplier π0 par
c0 et π1 par c1 n’a pas d’inﬂuence sur B(ℓ)
10 , car ces constantes s’annulent.
Notons l’int´eressante inversion de B10(x) en B01(x(ℓ)) : l’eﬀet de l’´echantillon
d’apprentissage est retir´e du facteur de Bayes B10(x).
Bien que le probl`eme de la constante de normalisation disparaisse, une
diﬃcult´e majeure est que la solution B(ℓ)
10 n’est que formellement bay´esienne.
De plus, en dehors des mod`eles s´equentiels, le choix de x(ℓ) n’est pas ´evident,
alors qu’il inﬂue pourtant sur la valeur r´esultante de B(ℓ)
10 (ce qui viole par
cons´equent le principe de vraisemblance).
Exemple 5.13. (Suite de l’Exemple 5.11) Si H0 : μ = 0, avec π0(σ2) =
1/σ2 et H1 : μ ̸= 0, avec π1(μ, σ2) = 1/σ2, la taille de l’´echantillon d’appren-
tissage minimal est 2 sous H1. D’o`u
π1(μ, σ2|x1, x2) = 1
σ exp{−2(μ −¯x1)2/2σ2}s5
1σ−3e−s2
1/2σ2
et
π0(σ2|x1, x2) = s6
0
σ4 e−s2
0/2σ2 ,
avec les notations suivantes :
¯x1 = x1 + x2
2
,
s2
1 = (x1 −x2)2
2
,
s2
0 = x2
1 + x2
2 .
Alors
B(2)
10 = s5
1

e−{(n−2)(¯x2−μ)2−2(μ−¯x1)2−s2
2−s2
1}/2σ2σ−n−2dμdσ2
s6
0
 ∞
0
e−{−s2
3−s2
0}/2σ2σ−n−2dσ2
d´epend du choix de (x1, x2) via (¯x1 −¯x2)2, s2
1 et s2
0 (voir l’Exercice 5.15).
∥
Une fa¸con de supprimer cette d´ependance `a l’´echantillon d’apprentissage
est de calculer la moyenne des diﬀ´erents pseudo-facteurs de Bayes (5.6) sur
tous les ´echantillons d’apprentissage possibles x(ℓ). La diﬃcult´e suivante est
de d´ecider quel type de moyenne devrait ˆetre utilis´ee. Par exemple, Berger et
Pericchi (1996b, 1998, 2001) ont r´epertori´e
– le facteur de Bayes arithm´etique intrins`eque,
BA
10 = 1
L

x(ℓ)
B(ℓ)
10 = B10(x) 1
L

x(ℓ)
B01(x(ℓ)) ,
(5.7)
o`u L est le nombre des diﬀ´erents ´echantillons d’apprentissage;

254
5 Tests et r´egions de conﬁance
– le facteur de Bayes g´eom´etrique intrins`eque,
BG
10 = exp 1
L

x(ℓ)
log B(ℓ)
10 = B10(x) exp 1
L

x(ℓ)
log B01(x(ℓ)) ;
(5.8)
et
– le facteur de Bayes m´edian intrins`eque,
BM
10 = med B(ℓ)
10 = B10(x)med B01(x(ℓ)) ,
(5.9)
o`u med B(ℓ)
10 indique la m´ediane des B(ℓ)
10 sur les diﬀ´erents ´echantillons
d’apprentissage.
Bien que toutes ces solutions soient proches d’une r´eponse bay´esienne, en
particulier parce qu’elles utilisent les donn´ees une seule fois (Exercice 5.16),
s´eparant la partie utilis´ee pour rendre propre la loi a priori impropre de
la partie utilis´ee pour le test lui-mˆeme, aucune d’entre elles n’est vraiment
bay´esienne. Nous discuterons plus loin des inconv´enients plus s´erieux de ces
diﬀ´erents facteurs de Bayes intrins`eques. Il apparaˆıt cependant que ces der-
niers correspondent souvent `a d’authentiques facteurs de Bayes sous des lois
a priori propres, appel´ees lois a priori intrins`eques dans Berger et Pericchi
(1996b, 1998)41. (On retrouvera ce ph´enom`ene dans la Section 5.3.5 avec les
bornes inf´erieures de Berger et Sellke, 1987.)
Exemple 5.14. (Berger et Pericchi, 1998) Dans le cas x ∼N (θ, 1), lorsque
H0 : θ = 0 et π1(θ) = 1, pour un ´echantillon (x1, . . . , xn), le facteur de Bayes
arithm´etique intrins`eque,
BA
10 = B10(x)
1
√
2π
1
n
n

i=1
e−x2
i /2,
est presque identique au facteur de Bayes habituel associ´e `a la loi a priori
normale N (0, 2) sous H1.
∥
Exemple 5.15. (Berger et Pericchi, 1998) Pour x1, . . . , xn, observations i.i.d.
d’une loi exponentielle translat´ee, de densit´e exp(θ −x)Ix≥θ, si H0 : θ = θ0 et
H1 : θ > θ0, avec π1(θ) = 1,
BA
10 = B10(x) 1
n
n

i=1
#
exi−θ0 −1
$−1
41Le terme d’intrins`eque associ´e au facteur de Bayes et la loi a priori corres-
pondante tente d’´evoquer l’id´ee de quantit´es calcul´ees uniquement `a partir de la
distribution des observations, mais la diversit´e des r´eponses possibles montre que ce
terme est plutˆot inappropri´e !

5.2 Une premi`ere approche de la th´eorie des tests
255
correspond au facteur de Bayes standard associ´e `a la loi a priori propre
π2(θ) = eθ0−θ 
1 −log
	
1 −eθ0−θ

,
qui se comporte comme l’indique la Figure 5.1.
∥
0
2
4
6
8
10
0
1
2
3
4
5
Fig. 5.1.
Graphe d’une loi a priori intrins`eque associ´ee au test exponentiel H0 :
θ = θ0, lorsque θ0 = 1.
O’Hagan (1995) pr´esente une alternative ´el´egante aux facteurs de Bayes
intrins`eques, alternative qui ´evite `a la fois la s´election d’´echantillons d’ap-
prentissage et le calcul de moyenne qui en d´ecoule. Son id´ee est d’utiliser une
fraction b de la vraisemblance pour rendre propre la loi a priori, c’est-`a-dire
prendre 0 < b < 1 tel que

Θ0
f0(x|θ0)bπ0(θ0)dθ0 < ∞
et

Θ1
f1(x|θ1)bπ1(θ1)dθ1 < ∞.
La fraction restante (1−b) de la vraisemblance est alors utilis´ee pour eﬀectuer
le test, comme dans le cas d’un facteur de Bayes intrins`eque. Le facteur de
Bayes fractionnaire est par cons´equent d´eﬁni comme

256
5 Tests et r´egions de conﬁance
BF
10 =

Θ1 f1(x|θ1)1−bπb
1(θ1|x)dθ1

Θ0 f0(x|θ0)1−bπb
0(θ0|x)dθ0
= B10(x)

Θ0 f0(x|θ0)bπ0(θ0)dθ0

Θ1 f1(x|θ1)bπ1(θ1)dθ1
,
(5.10)
o`u πb
0(θ0|x) et πb
1(θ1|x) indiquent les pseudo-lois a posteriori associ´ees `a, res-
pectivement, f0(x|θ0)b et f1(x|θ1)b. Pour les familles exponentielles, la quan-
tit´e b correspond clairement `a une fraction de taille d’´echantillon, car pour n
observations d’une famille exponentielle de statistique exhaustive T , on a
(exp{θ · n T (x) −nΨ(θ)})b = exp {θ · [bn] T (x) −[bn]Ψ(θ)} .
Pour les autres lois, la fraction b doit ˆetre d´etermin´ee par une approche plus
empirique (voir O’Hagan, 1995, 1997).
Comme dans le cas du facteur de Bayes intrins`eque, cette solution est dans
certains cas ´egale `a un facteur de Bayes r´egulier, pour une certaine loi a priori
“intrins`eque”.
Exemple 5.16. (Suite de l’Exemple 5.14) Pour tout 0 < b < 1,
BF
10 =

e−n(1−b)(¯x−θ)2/2√
be−nb((¯x−θ)2/2dθ
√
2πe−n(1−b)¯x2/2
=
√
ben(1−b)¯x2/2 ,
(5.11)
qui est ´egal au facteur de Bayes associ´e `a la loi propre θ ∼N (0, (1 −b)/nb)
sous H1.
∥
Ces pseudo-facteurs de Bayes pr´esentent cependant suﬃsamment de diﬃ-
cult´es pour que nous remettions en cause leur utilisation dans les probl`emes
de test et de choix de mod`ele :
(i) Lorsque les facteurs de Bayes sont associ´es `a des lois a priori, ils satisfont
certaines propri´et´es de coh´erence telles que
B12 = B10B02
et
B01 = 1/B10 .
La plupart des pseudo-facteurs de Bayes n’y satisfont pas, mˆeme si le
facteur de Bayes fractionnaire satisfait BF
01 = 1/BF
10.
(ii) Lorsque les pseudo-facteurs de Bayes peuvent s’exprimer comme de vrais
facteurs de Bayes, les lois a priori intrins`eques correspondantes ne sont
pas n´ecessairement satisfaisantes, comme le montrent l’Exemple 5.15 pour
le facteur de Bayes arithm´etique et l’Exemple 5.16 pour le facteur de
Bayes fractionnaire. Ces lois a priori d´ependent du choix des lois a priori
de r´ef´erence impropres π0 et π1, donc elles ne sont pas v´eritablement
intrins`eques.

5.2 Une premi`ere approche de la th´eorie des tests
257
(iii) En relation avec le point pr´ec´edent, les pseudo-facteurs de Bayes peuvent
aussi ˆetre biais´es vers l’une des hypoth`eses, au sens o`u ils peuvent s’ex-
primer comme un vrai facteur de Bayes multipli´e par un certain facteur.
Exemple 5.17. (Suite de l’Exemple 5.15) Pour le facteur de Bayes
intrins`eque m´edian,
BM
10 = B10(x)
4
emed(xi) −θ0
5−1
= 0.69 ˜B10(x)
(5.12)
o`u ˜B10(x) est le facteur de Bayes associ´e `a la loi a priori π3(θ) ∝(2 exp{θ−
θ0} −1)−1, qui, bien qu’elle soit similaire `a π2, ne fournit pas exactement
la mˆeme couverture des r´egions proches de 1.
∥
Dans de tels cas, les pseudo-facteurs de Bayes peuvent ˆetre per¸cus comme
attribuant aux deux hypoth`eses des probabilit´es diﬀ´erentes de la valeur
de r´ef´erence 1/2, une caract´eristique que nous rencontrerons aussi pour
les bornes les moins favorables dans la Section 5.3.5.
(iv) Le plus souvent cependant, les pseudo-facteurs de Bayes ne correspondent
pas du tout `a un vrai facteur de Bayes et donnent des solutions fortement
biais´ees. Par exemple, Berger et Pericchi (2001) conﬁrment que les facteurs
de Bayes arithm´etiques intrins`eques ne sont pas associ´es `a des lois a priori
intrins`eques pour la plupart des probl`emes de test unilat´eraux.
Exemple 5.18. (Suite de l’Exemple 5.15) Le facteur de Bayes frac-
tionnaire
BF
10 = B10(x)bn
%
e−bn(x(1)−θ0) −1
&−1
,
(5.13)
est toujours plus grand que 1, par cons´equent, il favorise toujours l’hy-
poth`ese alternative, selon l’´echelle de Jeﬀreys. Ce comportement para-
doxal peut ˆetre attribu´e au fait que la fraction b ne modiﬁe pas la fonction
indicatrice.
∥
(v) Les pseudo-facteurs de Bayes peuvent simplement ne pas exister pour
toute une cat´egorie de mod`eles.
Exemple 5.19. Les m´elanges de lois normales
pN (μ1, σ2
1) + (1 −p)N (μ2, σ2
2)
ont ´et´e pr´esent´es dans l’Exemple 1.6. Comme on le voit dans l’Exer-
cice 1.56, les lois a priori impropres de la forme π1(μ1, σ1)π2(μ2, σ2)π3(p)
ne peuvent pas ˆetre utilis´ees dans ce cadre, quelle que soit la taille de
l’´echantillon n. (La raison fondamentale de cette interdiction est qu’il

258
5 Tests et r´egions de conﬁance
existe une probabilit´e (1 −p)n > 0 qu’aucune observation soit associ´ee
`a la premi`ere composante N (μ1, σ2
1).) Par cons´equent, il n’existe jamais
d’´echantillon d’apprentissage pour les lois a priori non informatives stan-
dard et on ne peut pas calculer de facteur de Bayes. La mˆeme r`egle s’ap-
plique aux facteurs de Bayes fractionnaires (voir l’Exercice 5.22).
∥
(vi) Comme le montre cette section, il existe plusieurs approches pour d´eﬁnir
les pseudo-facteurs de Bayes et, bien que la plupart soient sans doute
logiques, il n’y a pas de m´ethode coh´erente de les classer par ordre de
pr´ef´erence. Les pseudo-facteurs de Bayes, tels qu’ils sont d´eﬁnis ici, sont
en accord avec le principe de vraisemblance, mais la multiplication des
r´eponses possibles, mˆeme si celles-ci sont proches, n’est pas un bon signal
pour les utilisateurs42. De la mˆeme fa¸con, il n’existe pas une proc´edure
pr´ecise pour le choix de b dans les facteurs de Bayes fractionnaires, car la
taille minimale de l’´echantillon d’apprentissage n’est pas toujours claire-
ment d´eﬁnie.
(vii) Jusqu’ici, le probl`eme du calcul des pseudo-facteurs de Bayes n’a pas
´et´e ´evoqu´e, faute d’outils appropri´es, qui seront introduits dans les Cha-
pitres 6 et 7. Mais notons que chaque facteur de Bayes B(ℓ)
10 peut ˆetre
une int´egrale complexe et le calcul d’une moyenne de facteurs de Bayes
intrins`eques peut impliquer
	m
n

int´egrales de ce type, si m est la taille
minimale de l’´echantillon d’apprentissage. Les facteurs de Bayes fraction-
naires sont plus faciles `a calculer dans des cadres exponentiels, mais les
autres lois sont plus diﬃciles `a manipuler (Exercice 5.23).
5.3 Comparaisons avec l’approche classique
5.3.1 Tests UPP et UPPS
L’approche classique de la th´eorie des tests est la th´eorie de Neyman-
Pearson, pr´esent´ee, par exemple, dans Lehmann (1986). Sous le coˆut 0−1, not´e
L ci-dessous, la notion fr´equentiste d’optimalit´e est fond´ee sur la puissance
d’un test, d´eﬁnie comme suit :
D´eﬁnition 5.20. La puissance d’une proc´edure de test ϕ est la probabilit´e
de rejeter H0 sous l’hypoth`ese alternative, c’est-`a-dire β(θ) = 1 −Eθ[ϕ(x)]
lorsque θ ∈Θ1. La quantit´e 1 −β(θ) est appel´ee erreur de deuxi`eme esp`ece,
tandis que l’erreur de premi`ere esp`ece est Eθ[ϕ(x)] lorsque θ ∈Θ0.
42Berger et Pericchi (2001) soutiennent que la multiplicit´e des facteurs de Bayes
intrins`eques possibles n’est pas plus inqui´etante que la multiplicit´e des lois a priori
possibles par d´efaut. La comparaison est cependant l´eg`erement d´eﬁciente, puisque
chaque loi a priori choisie induit de multiples facteurs de Bayes intrins`eques !

5.3 Comparaisons avec l’approche classique
259
Les tests fr´equentistes optimaux sont alors ceux qui minimisent le risque
Eθ[L(θ, ϕ(x))] sous H1 seulement :
D´eﬁnition 5.21. Si α ∈]0, 1[ et Cα est la classe des proc´edures ϕ satisfaisant
la contrainte suivante sur l’erreur de premi`ere esp`ece :
sup
θ∈Θ0
Eθ[L(θ, ϕ(x))] = sup
θ∈Θ0
Pθ(ϕ(x) = 0) ≤α,
(5.14)
une proc´edure de test ϕ est dite uniform´ement plus puissante au niveau α ou
UPP si elle minimise dans Cα le risque Eθ[L(θ, ϕ(x))] uniform´ement sur Θ1.
Cette optimalit´e est beaucoup plus faible que la notion d’admissibilit´e
d´evelopp´ee dans la Section 2.4. En eﬀet, le coˆut est bidimensionnel, du fait
de la restriction sur l’erreur de premi`ere esp`ece (5.14). Cette restriction est
g´en´eralement n´ecessaire pour obtenir une proc´edure de test optimale, car les
fonctions de risque des proc´edures admissibiles se croisent, mais :
(i) Elle entraˆıne une asym´etrie entre les hypoth`eses nulle et alternative, ce
qui implique un comportement anormal des proc´edures de test. En eﬀet,
puisque l’erreur de premi`ere esp`ece est ﬁx´ee, un ´equilibre entre les deux
erreurs (acceptation sous H1 et rejet sous H0) est impossible, d’o`u une
erreur de seconde esp`ece beaucoup plus grande. Cette asym´etrie explique
aussi le fait que la th´eorie ne fasse pas intervenir de consid´erations de
minimaxit´e. C’est ce qui se passe notamment lorsque deux hypoth`eses
H0 et H1 sont contigu¨es, c’est-`a-dire lorsqu’il est possible de passer de
Θ0 `a Θ1 par une transformation connexe.
(ii) Elle implique la s´election d’un niveau de conﬁance α par le d´ecideur,
en plus du choix de la fonction de coˆut L, ce qui entraˆıne g´en´eralement
le recours `a des niveaux “standard”, comme 0.05 ou 0.01, et les in-
conv´enients qui sont li´es `a de tels niveaux “universels” (voir ci-dessous).
(iii) Elle ne sugg`ere pas n´ecessairement une r´eduction suﬃsante de la
classe des proc´edures de test et ne permet pas toujours la s´election d’une
proc´edure unique optimale. Il est parfois n´ecessaire d’imposer plus de
contraintes sur ces classes.
Dans le cas le plus simple, c’est-`a-dire si les hypoth`eses nulle et alternative
sont ponctuelles, H0 :
θ = θ0 contre H1 :
θ = θ1, le lemme de Neyman-
Pearson ´etablit l’existence de proc´edures de test UPP, de la forme43
ϕ(x) =

1
si f(x|θ1) < kf(x|θ0),
0
sinon,
43Conservant l’interpr´etation d’une proc´edure de test comme estimateur de
IΘ0(θ), les proc´edures de test sont dans ce livre les compl´ements `a 1 des proc´edures
de Neyman-Pearson classiques, pour lesquelles la valeur de 1 correspond au rejet de
H0.

260
5 Tests et r´egions de conﬁance
k ´etant donn´e par le niveau de conﬁance choisi α. ´Evidemment, le fait que
Θ1 se r´eduise `a {θ1} est assez utile, car ceci permet un ordre total sur les
proc´edures de Cα. Pour les familles `a rapport de vraisemblance monotone,
c’est-`a-dire les familles param´etriques pour lesquelles il existe une statistique
T (x) telle que
f(x|θ′)
f(x|θ)
soit croissant en T (x) pour θ′ > θ, Karlin et Rubin (1956) ont ´etabli l’exten-
sion suivante du lemme de Neyman-Pearson (voir Lehmann, 1986, p. 79, pour
une d´emonstration).
Proposition 5.22. Soit f(x|θ) `a rapport de vraisemblance monotone dans
T (x). Pour H0 : θ ≤θ0 et H1 : θ > θ0 il existe un test UPP tel que
ϕ(x) =
⎧
⎪
⎨
⎪
⎩
1
si T (x) < c,
γ
si T (x) = c,
0
sinon,
γ et c ´etant d´etermin´es par la contrainte
Eθ0[ϕ(x)] = α.
Karlin et Rubin (1956) ont aussi montr´e que, pour les fonctions de coˆut
de type (5.1), les proc´edures de test fournies dans le Th´eor`eme 5.22 forment
une classe essentiellement compl`ete, c’est-`a-dire une classe de proc´edures suf-
ﬁsamment grande pour ˆetre au moins aussi bonne que n’importe quelle autre
proc´edure (voir le Chapitre 8). De plus, si le support de la loi f(x|θ) ne
d´epend pas de θ, la classe obtenue dans la Proposition 5.22 est essentiellement
compl`ete minimale : elle ne peut ˆetre r´eduite plus avant (voir Lehmann, 1986,
p. 82-83) et, par cons´equent elle ne contient que les proc´edures optimales.
Notons qu’une classe importante de familles `a rapport de vraisemblance
monotone est celle des familles exponentielles, car
f(x|θ′)
f(x|θ) = eθ′x−ψ(θ′)
eθx−ψ(θ) =
e(θ′−θ)x
eψ(θ′)−ψ(θ)
est croissant en x. Pfangzagl (1968) a aussi ´etabli la r´eciproque de la Pro-
position 5.22 dans l’esprit du lemme de Pitman-Koopman (Section 3.3.3),
`a savoir que l’existence d’un test UPP pour toute taille d’´echantillon et un
niveau donn´e α implique que la loi appartienne `a une famille exponentielle.
Exemple 5.23. Soient x ∼P(λ) et H0 : λ ≤λ0, H1 : λ > λ0. Pour m
observations ind´ependantes de cette loi, une statistique exhaustive est s =

i xi ∼P(mλ) et, selon la Proposition 5.22, un test UPP est donn´e par

5.3 Comparaisons avec l’approche classique
261
ϕ(x) =
⎧
⎪
⎨
⎪
⎩
1
si s < k,
γ
si s = k,
0
sinon,
pour Eλ0[ϕ(x)] = Pmλ0(s > k) + γPmλ0(s = k) = α.
∥
La Proposition 5.22 et l’exemple ci-dessus mettent en avant une diﬃ-
cult´e majeure de l’approche de Neyman-Pearson, `a savoir que des niveaux
de conﬁance arbitraires ne sont pas n´ecessairement accessibles, `a moins de
faire appel `a une randomisation. En eﬀet, comme l’espace de d´ecision est
D = {0, 1}, ϕ(x) = γ signiﬁe que ϕ(x) = 1 avec probabilit´e γ (et 0 autre-
ment). De telles proc´edures sont ´evidemment incompatibles avec le principe
de vraisemblance, mˆeme si elles n’apparaissent que pour des cas discrets. Leh-
mann (1986) indique que le niveau de conﬁance α devrait ˆetre modiﬁ´e jusqu’`a
ce que la randomisation soit ´evit´ee, mais cette modiﬁcation provoque un autre
inconv´enient : le choix du niveau de conﬁance d´epend des observations et non
pas d’une fonction d’utilit´e.
De plus, la Proposition 5.22 s’applique uniquement aux hypoth`eses uni-
lat´erales. Dans un cas particulier d’hypoth`eses bilat´erales, nous pouvons ex-
poser un r´esultat d’optimalit´e (voir Lehmann, 1986, p. 101-103).
Proposition 5.24. Soient une famille exponentielle
f(x|θ) = eθT (x)−ψ(θ)h(x)
et H0 : θ ≤θ1 ou θ ≥θ2, H1 : θ1 < θ < θ2. Il existe un test UPP de la forme
ϕ(x) =
⎧
⎪
⎨
⎪
⎩
0
si c1 < T (x) < c2,
γi
si T (x) = ci
(i = 1, 2),
1
sinon,
avec (i = 1, 2)
Eθi[ϕ(x)] = α.
Cependant, il n’existe pas de test UPP correspondant au cas oppos´e, `a sa-
voir H0 : θ1 ≤θ ≤θ2. Ce paradoxe montre avec force l’absence de sym´etrie–et
donc de coh´erence–du crit`ere UPP et jette un doute sur la validit´e de l’ana-
lyse de Neyman-Pearson ou sur la pertinence d’un coˆut asym´etrique comme le
coˆut 0 −1. Dans ces cas, la solution de Neyman-Pearson est de proposer une
r´eduction additionnelle de la classe des proc´edures en consid´erant des tests
sans biais, c’est-`a-dire satisfaisant de plus
sup
Θ0
Pθ(ϕ(x) = 0) ≤inf
Θ1 Pθ(ϕ(x) = 0).
En d’autres termes, ϕ doit aussi satisfaire

262
5 Tests et r´egions de conﬁance
inf
Θ0 Eθ[ϕ(x)] ≥sup
Θ1
Eθ[ϕ(x)].
La notion de tests uniform´ement plus puissants sans biais (UPPS) en d´ecoule.
N´eanmoins, cette restriction provoque encore plus d’asym´etrie entre H0 et
H1. Bien qu’intuitivement acceptable, cette notion de test sans biais est un
autre exemple des restrictions impos´ees `a la notion d’optimalit´e par l’approche
fr´equentiste, qui d´enaturent le vrai objectif de la Th´eorie de la D´ecision.
Exemple 5.25. Si, pour x ∼N (θ, 1), on teste H0 : θ = 0 contre H1 : θ ̸= 0,
il n’existe pas de test UPP. Un test UPPS au niveau α = 0.05 est
ϕ(x) =

1
si |x| ≤1.96,
0
sinon.
∥
5.3.2 Lois a priori les moins favorables
Lorsque aucun test UPPS n’existe, il devient assez diﬃcile de d´efendre,
ou mˆeme de construire, une proc´edure de test sp´eciﬁque dans un cadre
fr´equentiste. `A moins de restreindre plus encore la classe des proc´edures accep-
tables, une approche habituelle est de consid´erer le rapport de vraisemblance
supθ∈Θ0 f(x|θ)
supθ∈Θ1 f(x|θ)
(5.15)
et sa distribution, ou de fonder le test sur la loi asymptotique de (5.15). Le
rapport ci-dessus illustre un lien avec l’approche bay´esienne, car, comme on l’a
d´ej`a dit pr´ec´edemment, il s’agit formellement d’un facteur de Bayes pour une
loi a priori π de support r´eduit aux points ˆθ0 et ˆθ1, estimateurs du maximum
de vraisemblance de θ sur Θ0 et Θ1. Cette analogie est en eﬀet formelle,
puisque les masses de Dirac sont des lois a priori artiﬁcielles et, de plus, les ˆθi
d´ependent des observations. Cependant, elle indique aussi que le rapport de
vraisemblance a une motivation bay´esienne.
Des relations entre proc´edures de test bay´esiennes et proc´edures optimales
de Neyman-Pearson sont pr´esent´ees dans Lehmann (1986), via la notion de
lois les moins favorables, d´ecrite ci-dessous44. Soient H0 : θ ∈Θ0, H1 : θ = θ1
avec π une loi a priori sur Θ0. D’un point de vue bay´esien, ce probl`eme de test
44Le reste de cette section n’est pas utilis´e dans la suite. La passerelle signal´ee ici
est d’importance moindre que la relation correspondante obtenue dans la th´eorie de
la minimaxit´e (voir la Section 2.4.3). De plus, elle ne peut s’appliquer qu’`a des cas
sp´eciﬁques et ne valide pas plus avant les r´eponses classiques, qui ne peuvent pas
ˆetre obtenues comme limites de proc´edures bay´esiennes (voir la Section 5.4).

5.3 Comparaisons avec l’approche classique
263
peut ˆetre repr´esent´e comme le test de Hπ : x ∼mπ contre H1 : x ∼f(x|θ1),
o`u m est la loi marginale sous H0
mπ(x) =

Θ0
f(x|θ)π(θ) dθ.
Puisque les deux hypoth`eses (Hπ et H1) sont des hypoth`eses ponctuelles, le
lemme de Neyman-Pearson assure l’existence d’un test UPP ϕπ, `a un niveau
de signiﬁcation α et de puissance βπ = Pθ1(ϕπ(x) = 0). Ce test est de la forme
ϕπ(x) =

1
si mπ(x) > kf(x|θ1),
0
sinon.
D´eﬁnition 5.26. Une loi la moins favorable est une loi a priori π qui maxi-
mise la puissance βπ.
Cette d´eﬁnition est utilis´ee dans le r´esultat suivant (Lehmann, 1986, p. 105).
Th´eor`eme 5.27. Soit H0 : θ ∈Θ0 `a tester contre l’alternative H1 : θ = θ1.
Si le test UPP ϕπ au niveau α pour Hπ contre H1 satisfait
sup
θ∈Θ0
Eθ[L(θ, ϕπ)] ≤α,
alors
(i) ϕπ est UPP au niveau α ;
(ii) si ϕπ est le seul test de niveau α de Hπ contre H1, ϕπ est le seul test
UPP au niveau α pour tester H0 contre H1 ; et
(iii) π est une loi la moins favorable.
La condition dans le th´eor`eme ci-dessus peut sembler superﬂue, mais no-
tons que ϕπ est d´eﬁni par

{mπ(x)>kf(x|θ1)}
mπ(x) dx = α.
Ce rapport ne garantit pas que Eθ[L(θ, ϕπ)] ≤α pour tout θ ∈Θ0.
5.3.3 Critiques
Le Th´eor`eme 5.27 exhibe une connexion entre les tests bay´esien et UPP,
de la mˆeme fa¸con que les lois les moins favorables m`enent aux estimateurs
minimax dans les probl`emes d’estimation ponctuelle avec une valeur (voir la
Section 2.4), bien qu’une proc´edure de Bayes corresponde `a un test modiﬁ´e im-
pliquant π. Nous ne poursuivrons pas l’analogie au-del`a de cette connexion,
car, comme d’autres, nous nous opposons `a l’approche de Neyman-Pearson

264
5 Tests et r´egions de conﬁance
dans son ensemble. En eﬀet, en plus des probl`emes de randomisation ´evoqu´es
ci-dessus, un inconv´enient majeur de cette perspective est de restreindre l’es-
pace de d´ecision au couple {0, 1}, ce qui oblige par cons´equent `a prendre
une d´ecision cat´egorique. Il nous semble qu’une r´eponse plus adaptative est
pr´ef´erable. De plus, les tests UPP (et UPPS), lorsqu’ils existent, d´ependent
d’une mesure d’´evaluation (le niveau de signiﬁcation α) non r´evis´ee apr`es ob-
servation. Dans l’Exemple 5.25 notamment, si le niveau est ﬁx´e `a 0.05, la
r´eponse classique est identique pour x = 1.96 et x = 100. D’un point de vue
purement d´ecisionnel, il semble aussi paradoxal de restreindre les proc´edures
inf´erentielles `a un cadre limit´e, puisque ce dernier peut (et doit) mener `a des
proc´edures sous-optimales. En particulier, la notion de “sans biais”, qui a
´et´e d´econsid´er´ee en estimation ponctuelle grˆace `a l’eﬀet Stein (Note 2.8.2),
devrait aussi disparaˆıtre des proc´edures de test.
Une critique plus fondamentale de l’approche de Neyman-Pearson (et, au
fond, de toute approche fr´equentiste) est qu’elle fonde le rejet de H0 sur des
´ev´enements improbables qui ne se sont pas produits, pour reprendre les termes
de Jeﬀreys (1939, 1961). En eﬀet, une r´egion de rejet UPP est de la forme
R = {T (X) ≥T (x)}
si la loi a un rapport de vraisemblance monotone en T , car, sous l’hypoth`ese
nulle,
P(T (X) ≥T (x)) < α.
(5.16)
Cependant, l’´ev´enement qui se produit en r´ealit´e est {T (X) = T (x)}. Il
y a donc perte d’information dans le processus (classique) de d´ecision, qui
se trouve en g´en´eral ˆetre biais´e contre l’hypoth`ese nulle. En eﬀet, la r´egion
{T (X) ≥T (x)} est relativement plus improbable qu’un voisinage de T (x), ce
qui explique le fait que les r´eponses bay´esiennes soient plus optimistes (voir
la Section 5.3.5). Bien entendu, la seule approche coh´erente qui permette de
conditionner sur {T (X) = T (x)}, c’est-`a-dire sur les observations elles-mˆemes,
est l’approche bay´esienne. En revanche, choisir une proc´edure sur la base de
(5.16) fait intervenir la loi compl`ete de x et, par cons´equent, contredit po-
tentiellement le principe de vraisemblance, comme le montrent les Exemples
1.16 et 1.18. En eﬀet, le principe des r`egles d’arrˆet n’est pas compatible avec
une th´eorie des tests fr´equentiste, car la loi de la taille de l’´echantillon ne
devrait pas avoir d’impact sur la s´election de la proc´edure de test. Le prin-
cipe de vraisemblance pr´esente eﬀectivement la propri´et´e paradoxale qu’une
proc´edure fond´ee sur un rapport de vraisemblance reste acceptable tant qu’elle
ne d´epend pas de la loi de ce rapport.
Exemple 5.28. Le test du khi deux est une proc´edure simple (mais approxi-
mative) pour tester l’ad´equation d’un ´echantillon `a une loi (ou une famille de
lois). Si l’´echantillon de taille n est divis´e en k classes, de tailles th´eoriques
Ni = npi et de tailles observ´ees ni, on d´eduit du Th´eor`eme Central Limit que

5.3 Comparaisons avec l’approche classique
265
D2 =
k

i=1
(ni −Ni)2
Ni
est approximativement distribu´e comme une loi du χ2
ℓ, de degr´es de libert´e
ℓd´ependant du probl`eme (et valant g´en´eralement k −1 moins le nombre de
param`etres estim´es). Comme l’a soulign´e Jeﬀreys (1961), l’approche classique
rejette l’hypoth`ese nulle (ad´equation `a la famille des lois propos´ees) si D2 est
trop grand, par exemple, si
P(z > D2) < 0.05
pour z ∼χ2
ℓ. Cependant, il n’y a pas de raison d’accepter l’hypoth`ese nulle
(qui est que D2 est approximativement distribu´e comme χ2
ℓ) si
P(z < D2) ≤0.05,
puisque de telles valeurs de D2 ne sont pas plus compatibles avec la loi que
lorsque P(z > D2) ≤0.05. De ce point de vue, il serait aussi justiﬁ´e de rejeter
l’hypoth`ese nulle, ce que ne fait pas l’approche classique.
∥
Exemple 5.29. Une critique bay´esienne bien connue de la th´eorie de Ney-
man-Pearson est le contre-exemple suivant pr´esent´e par Lindley (1957, 1961).
Soient ¯xn ∼N (0, 1/n) la moyenne d’un ´echantillon normal et θ ∼N (0, 1).
Pour tester H0 : θ = 0 contre H1 : θ ̸= 0, les tests UPPS correspondants
ne d´ependent que de zn = |xn|√n. Supposons zn = 1.97. Au niveau de signi-
ﬁcativit´e 5%, la proc´edure de test rejette H0 pour tout n. Au contraire, la
probabilit´e a posteriori de H0 est (voir l’Exemple 5.4)
π(θ = 0|zn) =

1 + 1 −ϱ0
ϱ0
1
√n + 1 exp{z2
nn/2(n + 1)}
−1
,
et par cons´equent tend vers 1 quand n tend vers l’inﬁni. En fait, ce r´esultat
se v´eriﬁe pour la plupart des lois a priori, de par la normalit´e asymptotique
des lois a posteriori (voir Hartigan, 1983). Ce paradoxe peut ˆetre reli´e au
probl`eme de Kepler (voir Jeﬀreys, 1961 ou Berger, 1985b), qui est que, en
astronomie, une hypoth`ese nulle–par exemple, la nature elliptique de la tra-
jectoire des plan`etes–est toujours rejet´ee d’un point de vue fr´equentiste pour
une taille d’´echantillon suﬃsamment grande, c’est-`a-dire lorsque suﬃsamment
d’observations ont ´et´e accumul´ees.
∥
Une autre diﬃcult´e majeure de l’approche de Neyman-Pearson est que la
s´election du niveau α devrait ˆetre ´equivalente `a la s´election des poids a0 et a1
dans la fonction de coˆut et que, par cons´equent, elle devrait ˆetre fond´ee sur
des consid´erations d’utilit´e. Au lieu de cela, la pratique courante d’omettre

266
5 Tests et r´egions de conﬁance
compl`etement cette ´etape de s´election et, suivant une suggestion faite par Fi-
sher (1956), de choisir un niveau α classique de 5% ou 1%, est `a pr´esent deve-
nue une r`egle formelle, quels que soient le probl`eme, la taille de l’´echantillon,
ou l’erreur de seconde esp`ece. Puisque l’approche de Neyman-Pearson est
plutˆot pr´edominante de nos jours, cette attitude dogmatique a entraˆın´e un
biais de publication. En eﬀet, les r´esultats des exp´eriences qui ne sont pas
“signiﬁcatifs au niveau 5%” sont le plus souvent rejet´es par les ´editeurs ou
mˆeme censur´es par les auteurs eux-mˆemes dans plusieurs domaines, incluant
la biologie, la m´edecine et les sciences sociales.
5.3.4 Les p-values
Les fr´equentistes (et praticiens) ont tent´e de compenser les inconv´enients
de l’approche de Neyman-Pearson en supprimant le niveau de signiﬁcation α
et en proposant une r´eponse prenant ses valeurs dans [0, 1] et, de fa¸con plus
importante, d´ependant des observations de mani`ere plus adaptative qu’une
acceptation ou un rejet ´etablis en comparant T (x) `a un seuil donn´e. La notion
suivante a ´et´e introduite pour la premi`ere fois par Fisher (1956).
D´eﬁnition 5.30. La p-value associ´ee `a un test est le niveau de signiﬁcation
α le plus petit pour lequel l’hypoth`ese nulle est rejet´ee.
Une d´eﬁnition g´en´erale pour les hypoth`eses nulles ponctuelles (voir Thomp-
son, 1989) est qu’une p-value est une statistique admettant une loi uniforme
sous l’hypoth`ese nulle ; se pose alors le diﬃcile probl`eme du choix de l’une
de ces statistiques, comme d’ailleurs pour le test introduit dans la d´eﬁnition
ci-dessus. En r´ealit´e, si un test de r´egion critique Rα est disponible pour tout
niveau de signiﬁcation α et si ces r´egions sont imbriqu´ees (c’est `a dire si
Rα ⊂Rβ pour β > α), la proc´edure
p(x) = inf{α; x ∈Rα}
est distribu´ee selon une loi uniforme si Eθ0[IRα(x)] = α (voir Goutis et al.,
1996). Dans l’´eventualit´e de plusieurs tests donnant des r´eponses oppos´ees,
nous sugg´erons d’utiliser la loi du rapport de vraisemblance sous l’hypoth`ese
nulle, si cette derni`ere est ponctuelle.
Exemple 5.31. (Suite de l’Exemple 5.25) Puisque la r´egion critique (qui
est la r´egion de rejet pour H0) du test UPPS est {|x| > k}, une p-value usuelle
est
p(x) = inf{α; |x| > kα}
= P X(|X| > |x|),
X ∼N (0, 1)
= 1 −Φ(|x|) + Φ(|x|) = 2[1 −Φ(|x|)].
Par cons´equent, si x = 1.68, p(x) = 0.10 et, si x = 1.96, p(x) = 0.05.
∥

5.3 Comparaisons avec l’approche classique
267
Exemple 5.32. Soit x ∼B(n, p), lorsque l’hypoth`ese `a tester est H0 : p =
1/2 contre H1 : p ̸= 1/2. La p-value associ´ee au rapport de vraisemblance
f(x|1/2)
supp f(x|p) =
(1/2)n
	 x
n

x 	
1 −x
n

n−x ∝x−x(n −x)−(n−x)
est la fonction
˜p(x) = P1/2

XX(n −X)(n−X) ≤xx(n −x)(n−x)
,
o`u X ∼B(n, 1/2).
∥
Les p-values sont donc des proc´edures adaptatives qui peuvent ˆetre accep-
tables d’un point de vue fr´equentiste et qui, en outre, r´epondent aux exigences
de Kiefer (1977) et Robinson (1979) d’une approche fr´equentiste condition-
nelle. Cependant, elles restent critiqu´ees, car
(i) Les p-values ´evaluent aussi la mauvaise quantit´e, `a savoir, la probabilit´e
de d´epasser la valeur observ´ee de la statistique de test. Elles contredisent
donc le principe de vraisemblance, car elles d´ependent de toute la loi des
observations.
(ii) Mˆeme si elles sont calcul´ees `a partir de proc´edures de test optimales,
les p-values ne sont pas intrins`equement optimales, car elles ne sont pas
´evalu´ees sous une fonction de coˆut. En eﬀet, comme le montre la Section
5.4, elles peuvent ˆetre sous-optimales.
(iii) Le nouvel espace de d´ecision, D
= [0, 1], n’est pas motiv´e par
des consid´erations de Th´eorie de la D´ecision et donc l’utilisation des
p-values n’est pas rendue explicite. En particulier, les p-values sont
souvent per¸cues comme fournissant une approximation fr´equentiste de
P(θ ∈Θ0|x), mˆeme si cette expression n’a pas de sens dans un cadre
non bay´esien.
(iv) Dans une perspective classique, les p-values ne r´esument pas toute
l’information disponible pour un probl`eme de test ; elles devraient ˆetre
compar´ees aux erreurs de seconde esp`ece, qui sont habituellement omises
dans l’analyse. Berger et Wolpert (1988) illustrent le danger de n’utiliser
que des p-values dans l’exemple suivant. Si x ∼N (θ, 1/2), tester θ = −1
contre θ = 1 lorsque x = 0 m`ene `a une p-value de 0.072 (pour un test
UPP), indiquant apparemment un fort rejet de l’hypoth`ese nulle, alors
que la p-value correspondante pour le test inverse de H1 contre H0 prend
exactement la mˆeme valeur. En fait, un rejet de H0 ne devrait pas tou-
jours impliquer l’acceptation de H1, cependant les praticiens consid`erent
souvent la p-value comme ´etant la proc´edure de test et supposent qu’elle
englobe toute l’information sur le probl`eme de test en jeu et concluent
n´eanmoins `a l’acceptation. (Voir la Note 5.7.4.)

268
5 Tests et r´egions de conﬁance
5.3.5 R´eponses bay´esiennes moins favorables
Le probl`eme d’´evaluation des p-values sous un coˆut adapt´e est consid´er´e
dans la Section 5.4. Nous terminons cette section par une comparaison entre
les p-values et leurs contreparties bay´esiennes, les probabilit´es a posteriori.
Consid´erer la probabilit´e a posteriori la plus petite pour une classe de lois
a priori fournit la r´eponse bay´esienne la moins favorable par rapport `a l’hy-
poth`ese nulle. Cette limite inf´erieure ne peut pas ˆetre utilis´ee comme une
proc´edure non informative, car elle s´electionne la loi a priori la plus oppos´ee `a
l’hypoth`ese nulle et elle est `a la fois biais´ee contre H0 et d´ependante des obser-
vations. Elle devrait ˆetre interpr´et´ee comme un indicateur des variations des
probabilit´es a posteriori, la r´eponse la plus favorable ´etant 1. Une litt´erature
´etendue est d´esormais disponible sur cette approche et les lecteurs pourront
consulter Berger et Sellke (1987), Berger et Delampady (1987) et Berger et
Mortera (1991) pour des r´ef´erences suppl´ementaires. La Note 5.7.4 pr´esente
une perspective diﬀ´erente due `a Berger et al. (1997) qui r´econcilient les tests
fr´equentistes et bay´esiens en modiﬁant le cadre d´ecisionnel.
Berger et Sellke (1987) et Berger et Delampady (1987) consid`erent le cas
d’une hypoth`ese nulle ponctuelle, H0 : θ = θ0, contre l’hypoth`ese alternative
H1 : θ ̸= θ0. Pour une famille G de lois a priori sous l’hypoth`ese alternative,
les mesures d’´evaluation de la vraisemblance de H0 sont donn´ees par les limites
inf´erieures
B(x, G) = inf
g∈G
f(x|θ0)

Θ f(x|θ)g(θ) dθ ,
P(x, G) = inf
g∈G
f(x|θ0)
f(x|θ0) +

Θ f(x|θ)g(θ) dθ
sur les facteurs de Bayes et les probabilit´es a posteriori (pour ϱ0 = 1/2, de
fa¸con `a donner des poids ´egaux aux deux hypoth`eses). Ces limites peuvent
aussi s’´ecrire
B(x, G) =
f(x|θ0)
supg∈G

Θ f(x|θ)g(θ)dθ ,
P(x, G) =

1 +
1
B(x, G)
−1
.
Elles varient bien ´evidemment en fonction de la classe G consid´er´ee. Dans un
cas plus g´en´eral, lorsque G est ´egal `a GA, l’ensemble de toutes les lois a priori,
le r´esultat suivant se d´emontre ais´ement.
Lemme 5.33. S’il existe un estimateur du maximum de vraisemblance de θ,
ˆθ(x), les limites inf´erieures des facteurs de Bayes et des probabilit´es a poste-
riori de H0 sont, respectivement,
B(x, GA) =
f(x|θ0)
f(x|ˆθ(x))
,
P(x, GA) =

1 + f(x|ˆθ(x))
f(x|θ0)
−1
.

5.3 Comparaisons avec l’approche classique
269
Une cons´equence du Lemme 5.33 est que la r´eponse bay´esienne ne sera
jamais fortement en faveur de l’hypoth`ese nulle, car
B(x, GA) ≤1,
P(x, GA) ≤1
2.
Ce comportement n’est pas particuli`erement surprenant, car les limites in-
f´erieures correspondent au pire choix possible de g par rapport `a H0. Un
ph´enom`ene plus inattendu est que la d´ecroissance de ces limites lorsque |x|
augmente est plus lente que pour les p-values, comme le montre l’exemple
suivant.
Exemple 5.34. (Suite de l’Exemple 5.31) Dans le cas gaussien, les limites
inf´erieures associ´ees `a H0 : θ0 = 0 sont
B(x, GA) = e−x2/2
et
P(x, GA) =

1 + ex2/2−1
,
ce qui donne le Tableau 5.7, qui compare les p-values aux r´eponses bay´esiennes
les moins favorables.
La diﬀ´erence avec les r´eponses fr´equentistes est donc assez importante. Les
p-values sont plus petites pour des niveaux de signiﬁcation usuels et rejettent
donc l’hypoth`ese nulle H0 “trop souvent”. Bien entendu, pour des valeurs plus
petites de x, les p-values sont plus grandes que les limites inf´erieures, mais
le point le plus important est que, pour les valeurs de x o`u la d´ecision est
le plus diﬃcile `a prendre, soit donc pour des niveaux de signiﬁcation entre
0.01 et 0.1, une telle divergence apparaisse entre les r´eponses fr´equentistes et
bay´esiennes.
∥
Tab. 5.7. Comparaison entre les p-values et les r´eponses bay´esiennes dans un cas
gaussien. (Source : Berger et Sellke, 1987.)
p-value 0.10
0.05
0.01 0.001
P
0.205 0.128 0.035 0.004
B
0.256 0.146 0.036 0.004
Des r´esultats de ce type sont assez surprenants, car les proc´edures clas-
siques appartiennent habituellement `a la gamme des r´eponses bay´esiennes.
De plus, la classe GA est plutˆot d´eraisonnable, car elle inclut des masses de
Dirac menant `a la limite inf´erieure. La seule justiﬁcation pour ce type de lois
a priori se rapporte au principe minimax et `a la notion correspondante de loi
la moins favorable. L’exemple ci-dessus montre que les p-values ne sont pas
minimax en ce sens. Bien entendu, la divergence est plus importante pour des
classes de lois plus petites. Par exemple, si G est ´egal `a GS, l’ensemble des
lois qui sont sym´etriques en θ0, l’´equivalent du Lemme 5.33 est :

270
5 Tests et r´egions de conﬁance
Lemme 5.35. Le facteur de Bayes le plus petit lorsque g ∈GS est
B(x, GS) =
f(x|θ0)
supξ
1
2[f(x|θ0 −ξ) + f(x|θ0 + ξ)],
qui m`ene `a la limite inf´erieure correspondante pour les probabilit´es a poste-
riori.
Ce r´esultat se d´eduit du fait que toute loi sym´etrique est un m´elange de
lois dont le support se r´eduit `a deux points, de la forme {θ0 −ξ, θ0 + ξ}.
Pour des extensions multidimensionnelles, le supr´emum doit ˆetre pris sur les
lois uniformes pour des sph`eres centr´ees sur θ0 (voir Berger et Delampady,
1987). Les probl`emes discrets n´ecessitent quelques raﬃnements, notamment la
d´eﬁnition d’une notion de loi sym´etrique. Par exemple, dans le cas binomial,
la classe correspondante est GS, l’ensemble des lois qui sont sym´etriques en
p −p0
7
p(1 −p)
.
Exemple 5.36. (Suite de l’Exemple 5.32) Pour H0 : p = 1/2, le Tableau
5.8 fournit les p-values et les limites inf´erieures bay´esiennes associ´ees `a GS
(p0 = 1/2).
∥
Tab. 5.8. Comparaison entre p-values et r´eponses bay´esiennes dans un cas binomial.
(Source : Berger et Delampady, 1987.)
p-value 0.0093 0.0507 0.1011
P
0.0794 0.2210 0.2969
Notons que dans ce cas les p-values ne sont pas des niveaux standard, de
par la nature discr`ete de la loi binomiale.
Une autre classe int´eressante de lois a priori est celle des lois unimodales
sym´etriques en θ0, GSU. Ces lois peuvent s’´ecrire comme des m´elanges de lois
sym´etriques uniformes en dimension 1 (Berger et Sellke, 1987). Cependant, le
calcul des limites inf´erieures reste faisable. De telles classes sont n´ecessaires
dans des cadres multidimensionnels, car les limites inf´erieures associ´ees `a des
classes plus g´en´erales comme GA sont proches de 0 pour la plupart des valeurs
des observations.
Exemple 5.37. (Suite de l’Exemple 5.25) Dans le cas gaussien, si |x| ≤1,
B(x, GSU) = 1 et P(x, GSU) = 1/2. Cependant, si |x| > 1 et si on d´eﬁnit
g(θ) = (1/2K)I{|θ| < K}, on a

f(x|θ)g(θ) dθ =
1
2K [Φ(K −x) −Φ(−K −x)]

5.3 Comparaisons avec l’approche classique
271
et la limite inf´erieure est associ´ee au K maximisant cette expression. Le Ta-
bleau 5.9 donne les valeurs de B et P correspondant aux p-values de 0.1 et
0.01, qui diﬀ`erent signiﬁcativement de la r´eponse fr´equentiste.
∥
Tab. 5.9. R´eponses bay´esiennes pour les p-values de 0.01 (haut) et 0.1 (bas) dans
le cas normal. (Source : Berger et Delampady, 1987.)
dim.
1
3
5
P
0.109 0.083 0.076
0.392 0.350 0.339
B
0.123 0.090 0.082
0.644 0.540 0.531
Une premi`ere cons´equence de cette comparaison est que, d’un point de
vue bay´esien, les p-values ne sont pas un outil valable pour mettre en œuvre
des exp´eriences de test d’hypoth`eses nulles. Contrairement aux probl`emes
r´eguliers d’estimation ponctuelle comme ceux d´evelopp´es dans le Chapitre
4, les r´eponses fr´equentistes ne semblent pas s’exprimer comme limites de
r´eponses bay´esiennes; nous donnons dans la Section 5.4 une preuve formelle
de ce fait. Puisque les p-values sont strictement plus petites que les r´eponses
bay´esiennes (pour des niveaux qui comptent vraiment dans un processus de
test d´ecisionnel), l’hypoth`ese nulle H0 est rejet´ee plus souvent sous une ap-
proche fr´equentiste, tandis que l’approche bay´esienne montre que le rapport
des vraisemblances a posteriori de H0 et H1 est assez mod´er´e pour des ni-
veaux de signiﬁcation usuels (0.05 ou 0.01). Cette diﬀ´erence importante entre
les deux approches justiﬁe clairement une mod´elisation bay´esienne, car cette
approche inclut plus naturellement la notion de probabilit´e d’une hypoth`ese.
Elle montre aussi que l’argument de validit´e fr´equentiste, c’est-`a-dire la jus-
tiﬁcation de long terme fournie par un niveau de signiﬁcation de 5% ou de
1%, est plutˆot illusoire et que la division introduite par la th´eorie de Neyman-
Pearson dans le traitement de H0 et H1 (entre les erreurs de premi`ere et de
seconde esp`eces) m`ene `a un biais en faveur de l’hypoth`ese alternative pour
des valeurs plus grandes de x ou T (x).
5.3.6 Le cas unilat´eral
Les hypoth`eses unilat´erales (c’est-`a-dire H0 : θ ≤θ0 contre H1 : θ > θ0)
n’exhibent pas de tels contrastes entre solutions fr´equentistes et solutions
bay´esiennes. En eﬀet, comme le montre l’Exemple 5.9, la p-value peut alors
s’´ecrire comme un estimateur de Bayes g´en´eralis´e et donc comme une limite
de solutions bay´esiennes (puisque la renormalisation n’a pas d’impact). Par
cons´equent, il n’est pas possible d’exhiber une dichotomie entre les deux ap-
proches comme dans le cas bilat´eral. Casella et Berger (1987) consid`erent ce
cadre et g´en´eralisent le ph´enom`ene de “r´econciliation” d´ecrit plus haut.

272
5 Tests et r´egions de conﬁance
Th´eor`eme 5.38. Soit x ∼f(x −θ), avec f sym´etrique en 0. L’hypoth`ese
nulle `a tester est H0 :
θ ≤0. Si f est une loi `a rapport de vraisemblance
monotone, la p-value p(x) est ´egale `a la limite inf´erieure des probabilit´es a
posteriori, P(x, GSU), lorsque cette limite est calcul´ee sur la classe GSU des
lois a priori sym´etriques unimodales et lorsque x > 0.
Preuve.
Dans ce cas la p-value est
p(x) = Pθ=0(X > x) =
 +∞
x
f(t) dt
et
B(x, GSU) =
inf
π∈GSU P π(θ ≤0|x)
=
inf
π∈GSU
 0
−∞f(x −θ)π(θ) dθ
 +∞
−∞f(x −θ)π(θ) dθ
= inf
K
 0
−K f(x −θ) dθ
 K
−K f(x −θ) dθ
,
(5.17)
de par la repr´esentation des lois a priori unimodales sym´etriques comme
m´elanges de lois uniformes sur [−K, K]. La propri´et´e de rapport de vrai-
semblance monotone implique que (5.17) est atteint en K = +∞.
⊓⊔
Une cons´equence du Th´eor`eme 5.18 est que la limite inf´erieure des r´eponses
bay´esiennes sur toutes les lois a priori est plus petite que la p-value.
Exemple 5.39. Soit X ∼C (θ, 1), la loi de Cauchy, et l’hypoth`ese `a tester
est H0 :
θ ≤0 contre H1 :
θ > 0. Si la loi a priori de θ est suppos´ee
appartenir `a la classe des lois sym´etriques par rapport `a 0, la limite inf´erieure
des r´eponses bay´esiennes et les p-values correspondantes sont donn´ees dans le
Tableau 5.10. Les diﬀ´erences entre les valeurs num´eriques ne sont pas aussi
frappantes que dans les exemples pr´ec´edents.
∥
Tab. 5.10.
Comparaison entre les p-values et les probabilit´es a posteriori
bay´esiennes dans le cas d’une loi de Cauchy. (Source : Casella et Berger, 1987.)
p-value
0.437 0.102 0.063 0.013 0.004
P
0.429 0.077 0.044 0.007 0.002
Cette diﬀ´erence entre les cas unilat´eral et bilat´eral appelle les commen-
taires suivants :

5.4 Une deuxi`eme approche d´ecisionnelle
273
(i) Comme il a d´ej`a ´et´e dit plusieurs fois, une mod´elisation bay´esienne est
g´en´eralement assez d´elicate dans les cas bilat´eraux, en particulier pour
des hypoth`eses nulles ponctuelles, car cela implique une modiﬁcation
de la loi a priori impos´ee par le probl`eme inf´erentiel. Ceci ne contredit
pas les principes bay´esiens si nous consid´erons que cette modiﬁcation
est le r´esultat d’une information (vague) additionnelle ; mais la fa¸con
d’utiliser cette information reste incertaine. Une illustration de cette
diﬃcult´e est donn´ee par le cas des lois non informatives, o`u plusieurs
approches bay´esiennes (et pas enti`erement compatibles) donnent des
r´esultats contradictoires, comme le d´etaille la Section 5.2.6.
(ii) Que la p-value soit proche de la limite inf´erieure dans le cas unilat´eral
montre le comportement conservateur (ou minimax) de la proc´edure.
Puisque cette derni`ere peut s’´ecrire comme une r´eponse bay´esienne
g´en´eralis´ee, cela nous incite `a penser que la p-value devrait aussi s’expri-
mer comme une r´eponse non informative dans les cas bilat´eraux. Bien
entendu, cela n’implique pas forc´ement que cette r´eponse devrait ˆetre
utilis´ee, car une utilisation eﬃcace de l’information contenue dans le
probl`eme de test lui-mˆeme est g´en´eralement possible.
(iii) Les p-values sont construites `a partir de tests UPP ou UPPS par
une construction empirique sur mesure. Les comparaisons dans Berger
et Sellke (1987) et Casella et Berger (1987) montrent qu’elles diﬀ`erent
(ou non) de leurs contreparties bay´esiennes. Bien que ces ´etudes si-
gnalent l’existence d’un probl`eme th´eorique, elles ne sont pas suﬃsantes
d’un point de vue fr´equentiste pour rejeter l’utilisation des p-values.
Il est donc n´ecessaire d’utiliser une perspective d´ecisionnelle adapt´ee
`a l’´evaluation des p-values. La section suivante traite de cette compa-
raison. Elle fournit aussi des explications th´eoriques `a la dichotomie
bilat´erale/unilat´erale pr´esent´ee ci-dessus.
(iv) Une perspective diﬀ´erente, qui permet d’agrandir l’espace de d´ecision
en incluant l’option “pas de d´ecision”, donne des r´eponses fr´equentistes
et bay´esiennes beaucoup plus proches, conceptuellement et num´erique-
ment. Elle est d´etaill´ee dans la Note 5.7.4.
5.4 Une deuxi`eme approche d´ecisionnelle
Comme on vient de le souligner45, les p-values n’ont pas de justiﬁcation
intrins`eque, car leur pr´etendue “optimalit´e” d´ecoule de celle des proc´edures de
test, dont elles sont d´eriv´ees. En un sens, la mˆeme remarque s’applique aux
probabilit´es a posteriori, car, bien qu’elles soient intuitivement justiﬁables,
celles-ci ne sont pas valid´ees par un processus de d´ecision. Dans cette sec-
tion, nous construisons une alternative `a l’approche de Neyman-Pearson pour
justiﬁer les probabilit´es a posteriori et ´evaluer les p-values.
45Cette section, de niveau plus avanc´e, peut ˆetre omise lors d’une premi`ere lecture.

274
5 Tests et r´egions de conﬁance
Comme le montre la Section 5.2, le probl`eme de test formalis´e par Ney-
man et Pearson peut s’exprimer comme l’estimation de la fonction indicatrice
IΘ0(θ) sous le coˆut 0 −1 ou, de fa¸con ´equivalente, le coˆut en erreur absolue
L1(θ, ϕ) = |ϕ −IΘ0(θ)| .
(5.18)
En eﬀet, si les estimateurs ϕ ne prennent que les valeurs 0 et 1, il existe de
nombreuses mani`eres d’´ecrire le coˆut 0 −1, (5.18) ´etant l’une d’elles. Mais,
comme il est indiqu´e ci-dessus, la th´eorie de Neyman-Pearson est essentielle-
ment une th´eorie “pr´e-donn´ees” que ne fournit pas de solution “post-donn´ees”
(ou plus adaptative). Nous nous tournons alors vers une th´eorie moins restric-
tive, pour laquelle les estimateurs prennent leurs valeurs dans D = [0, 1] et
peuvent ˆetre consid´er´es comme des indicateurs du degr´e de certitude contre
ou en faveur de H0.
Parall`element `a Schaafsma et al. (1989), Hwang et al. (1992) examinent
cette approche des probl`emes de test, pour laquelle les estimateurs de IΘ0(θ)
appartiennent `a [0, 1]. Lorsque la restriction `a {0, 1} est lev´ee, le choix du coˆut
devient plus important. Par exemple, (5.18) est trop semblable `a la fonction
de coˆut 0 −1, car elle fournit les mˆemes proc´edures de Bayes
ϕπ(x) =

1
si P π(θ ∈Θ0|x) > P π(θ ̸∈Θ0|x),
0
sinon.
En revanche, les coˆuts strictement convexes, comme les coˆuts quadratiques
L2(θ, ϕ) = (ϕ −IΘ0(θ))2 ,
(5.19)
m`enent `a des estimateurs plus adaptatifs.
Proposition 5.40. Sous le coˆut (5.19), l’estimateur de Bayes associ´e `a π est
la probabilit´e a posteriori
ϕπ(x) = P π(θ ∈Θ0|x).
En eﬀet, l’esp´erance a posteriori de IΘ0(θ) n’est autre que la probabi-
lit´e a posteriori de Θ0. Le coˆut quadratique (5.19) fournit alors une base
d´ecisionnelle pour l’utilisation de probabilit´es a posteriori comme r´eponses
bay´esiennes. De tels coˆuts sont dits r´eguliers (voir Lindley, 1985 et Schervish,
1989 ; l’Exercice 2.15 caract´erise ces coˆuts). Il existe d’autres coˆuts r´eguliers
que les coˆuts quadratiques, mais Hwang et Pemantle (1994) ont montr´e qu’il
suﬃt de consid´erer le coˆut quadratique en termes d’admissibilit´e et de classes
compl`etes (voir aussi le Chapitre 8).
Nous examinons dans cette section le cas particulier des familles exponen-
tielles naturelles,
f(x|θ) = eθx−ψ(θ),
θ ∈Θ ⊂R,

5.4 Une deuxi`eme approche d´ecisionnelle
275
et nous introduisons la d´eﬁnition suivante, due `a Farrell (1968b), qui nous
permet d’´evaluer les proc´edures dans un intervalle lorsqu’elles sont constantes
en dehors de cet intervalle.
D´eﬁnition 5.41. Pour un test unilat´eral, c’est-`a-dire pour une hypoth`ese de
la forme H0 :
θ ≤θ0 contre H1 :
θ > θ0, un intervalle [t1, t2] est appel´e
ensemble de troncature pour l’estimateur ϕ si ϕ(t) = 1 lorsque t < t1 et
ϕ(t) = 0 lorsque t > t2. Pour un test bilat´eral de H0 : θ ∈[θ1, θ2], l’intervalle
[t1, t2] est appel´e ensemble de troncature pour l’estimateur ϕ si ϕ(t) = 0
lorsque t ̸∈[t1, t2].
Les r´esultats suivants ont ´et´e obtenus par Hwang et al. (1992), `a partir des
travaux de Brown (1986b) ; celui-ci montre que tout estimateur admissible est
une limite ponctuelle d’estimateurs de Bayes pour une suite de mesures de
support ﬁni (voir la Section 8.3.4).
Th´eor`eme 5.42. Pour le probl`eme bilat´eral
H0 : θ ∈[θ1, θ2]
contre
H1 : θ ̸∈[θ1, θ2],
(5.20)
un estimateur ϕ d’ensemble de troncature [t1, t2] est admissible s’il existe une
mesure de probabilit´e π0 sur [θ1, θ2] et une mesure σ-ﬁnie π1 sur [θ1, θ2]c telles
que
ϕ(x) =

f(x|θ)π0(θ) dθ

f(x|θ)π0(θ)dθ +

f(x|θ)π1(θ) dθ ,
(5.21)
pour x ∈[t1, t2]. R´eciproquement, si ϕ est admissible, il existe [t1, t2], π0 et
π1 tels que (5.21) soit satisfait.
Dans le cas unilat´eral, nous ne pouvons proposer qu’une condition n´e-
cessaire d’admissibilit´e, mais celle-ci implique que les estimateurs de Bayes
g´en´eralis´es forment une classe compl`ete.
Th´eor`eme 5.43. Pour le probl`eme unilat´eral
H0 : θ ≤θ0
contre
H1 : θ > θ0,
(5.22)
si ϕ est admissible, il existe une proc´edure croissante ϕ′ telle que ϕ′ est
´equivalente `a ϕ (en termes de risque). Si ϕ est une proc´edure admissible crois-
sante et [t1, t2] est un ensemble de troncature tel que 0 < ϕ(x) < 1 sur [t1, t2],
il existe deux mesures σ-ﬁnies sur (−∞, θ0] et [θ0, +∞), π0 et π1, telles que
1 =

et0θ−ψ(θ)(π0(θ) + π1(θ)) dθ
pour t1 < t0 < t2 et ϕ est donn´e par (5.21) sur [t1, t2].

276
5 Tests et r´egions de conﬁance
Ces deux th´eor`emes de classes compl`etes montrent qu’il suﬃt de consid´erer
des estimateurs de Bayes g´en´eralis´es pour obtenir des estimateurs admissibles
sous un coˆut quadratique. Le Th´eor`eme 5.43 montre de plus que les estima-
teurs monotones forment une classe essentiellement compl`ete. Ces r´esultats
peuvent ˆetre utilis´es pour ´evaluer les p-values. Rappelons de nouveau que les
estimateurs de Bayes sous-tendent les estimateurs optimaux (classiques). ( Le
Chapitre 8 expose plus en d´etail les bases bay´esiennes de l’admissibilit´e.)
Rappelons aussi que Casella et Berger (1987) ont montr´e que les p-values
prenaient des valeurs sensiblement similaires `a celles des probabilit´es a poste-
riori bay´esiennes dans des cadres unilat´eraux. Il est donc naturel d’examiner
l’admissibilit´e des p-values. Les exemples ci-dessous montrent qu’elles sont
admissibles pour la plupart des tests unilat´eraux.
Exemple 5.44. Soient de nouveau x ∼N (θ, 1) et H0 de la forme (5.22).
Nous avons montr´e dans l’Exemple 5.9 que
p(x) = Pθ0(X > x) = 1 −Φ(x −θ0)
est un estimateur de Bayes g´en´eralis´e par rapport `a la mesure de Lebesgue.
De plus, le risque de la p-value est
r(π, p) =
 +∞
−∞
R(p, θ) dθ
=
 +∞
−∞
 +∞
−∞
(p(x) −IΘ0(θ))2f(x|θ) dx dθ
=
 θ0
−∞
 +∞
−∞
(1 −Φ(x −θ0))2f(x|θ) dx dθ
+
 +∞
θ0
 +∞
−∞
Φ(x −θ0)2f(x|θ) dx dθ
= 2
 +∞
−∞
(1 −Φ(x −θ0))2Φ(x −θ0) dx
par le th´eor`eme de Fubini. Cette int´egrale est ﬁnie. Par cons´equent, r(π) <
+∞et p est admissible sous (5.19) (voir Section 2.4).
∥
Exemple 5.45. Soit x ∼B(n, θ). La p-value pour le test de (5.21) est alors
p(x) = Pθ0(X ≥x) =
n

k=x
n
k

θk
0(1 −θ0)n−x,
qui est aussi un estimateur de Bayes g´en´eralis´e sous la loi a priori π(θ) = 1/θ.
Il est de nouveau possible de montrer que p a un risque de Bayes ﬁni et est
par cons´equent admissible. Un r´esultat similaire peut ˆetre ´etabli pour une loi
de Poisson, P(θ) (voir Hwang et al., 1992).
∥

5.5 R´egions de conﬁance
277
En revanche, les p-values ne sont pas admissibles dans les cas bilat´eraux,
comme le sugg`erent les comparaisons de la Section 5.3.5.
Th´eor`eme 5.46. Pour le test de (5.20), lorsque la distribution d’´echantillon-
nage est absolument continue par rapport `a la mesure de Lebesgue, la p-value
est inadmissible pour le coˆut (5.19).
Preuve.
Ce r´esultat repose sur le fait que la p-value vaut 1 avec une probabi-
lit´e strictement positive (voir Hwang et al., 1992, Section 4.1.2). En eﬀet, si p
est admissible, elle peut s’´ecrire sous la forme (5.21). Puisqu’elle est positive,

f(x|θ)π1(θ) dθ < +∞.
Par cons´equent, l’´egalit´e (5.21) est par continuit´e vraie partout et p(x0) = 1
implique π = π0, soit p(x) = 1 pour tout x, ce qui ne peut pas ˆetre vrai.
⊓⊔
Ce r´esultat s’accorde avec les observations de Berger et Sellke (1987), qui
ont montr´e que les p-values n’appartiennent pas `a la cat´egorie des r´eponses
bay´esiennes. Cela justiﬁe donc le rejet des p-values pour les hypoth`eses bi-
lat´erales. En outre, Hwang et Pemantle (1994) ont montr´e que l’inadmissibi-
lit´e des p-values peut s’´etendre `a la plupart des coˆuts r´eguliers born´es. Comme
remarque ﬁnale, notons qu’il semble d´esormais n´ecessaire de construire des es-
timateurs qui dominent les p-values. Dans le cas normal, Hwang et al. (1992)
montrent que cela ne peut pas ˆetre fait avec un estimateur de Bayes r´egulier,
tandis que Hwang et Pemantle (1994) donnent des arguments num´eriques en
faveur d’un estimateur dominant explicite.
5.5 R´egions de conﬁance
En plus de fournir au d´ecideur des approximations de la “vraie” valeur du
param`etre θ, `a savoir des estimateurs ponctuels et des r´eponses aux questions
sur l’inclusion de θ dans un domaine sp´eciﬁque, c’est-`a-dire des proc´edures de
test, il est souvent n´ecessaire de construire ´egalement des r´egions de conﬁance
pour θ, sous-ensembles Cx de l’espace des param`etres Θ o`u θ devrait se trouver
avec une forte probabilit´e (dans un sens fr´equentiste ou bay´esien). Cette notion
s’´etend aussi aux transformations non bijectives de θ. Elle est par ailleurs d’un
int´erˆet consid´erable dans les probl`emes de pr´evision.
Exemple 5.47. Reprenons le prix des actions IBM de l’Exemple 4.23, repr´e-
sent´e dans la Figure 4.2. Si les s´eries (xt) ont ´et´e observ´ees jusqu’au temps T ,
la valeur au temps T +1, xT +1, est ´evidemment cruciale et il est important de
ne pas communiquer `a l’investisseur uniquement la valeur la plus probable de
xT +1, sachant les observations pr´ec´edentes, mais aussi l’´eventail des valeurs
vraisemblables de xT +1, aﬁn qu’il puisse prendre une d´ecision par rapport aux
proﬁts possibles correspondants.
∥

278
5 Tests et r´egions de conﬁance
Une fois de plus, le fait que, dans la formulation bay´esienne, θ ait une
probabilit´e donn´ee d’appartenir `a une r´egion ﬁx´ee Cx est plus attrayant que
l’interpr´etation fr´equentiste d’une r´egion al´eatoire Cx ayant une probabilit´e
donn´ee de contenir le param`etre inconnu θ.
5.5.1 Intervalles de cr´edibilit´e
Comme dans le cadre des tests, le paradigme bay´esien propose une notion
de r´egion de conﬁance qui est plus naturelle que son ´equivalent fr´equentiste,
car la notation P(θ ∈Cx) a un sens mˆeme conditionnellement `a x.
D´eﬁnition 5.48. Pour une loi a priori π, un ensemble Cx est un ensemble
α-cr´edible si
P π(θ ∈Cx|x) ≥1 −α.
Cet ensemble est appel´e r´egion α-cr´edible HPD (HPD pour Highest Posterior
Density, soit densit´e a posteriori la plus forte) s’il peut s’´ecrire sous la forme46
{θ; π(θ|x) > kα} ⊂Cπ
x ⊂{θ; π(θ|x) ≥kα},
o`u kα est la plus grande borne telle que
P π(θ ∈Cα
x |x) ≥1 −α.
Consid´erer uniquement les r´egions HPD est motiv´e par le fait qu’elles sont
de volume minimal parmi les r´egions α-cr´edibles et, par cons´equent, peuvent
ˆetre per¸cues comme des solutions optimales dans un cadre de d´ecision.
Exemple 5.49. Si θ ∼N (0, τ2), la loi a posteriori de θ est N (μ(x), ω−2)
avec ω2 = τ−2 + σ−2 et μ(x) = τ 2x/(τ 2 + σ2). Alors
Cπ
α =
#
μ(x) −kαω−1, μ(x) + kαω−1$
,
o`u kα est le quantile α/2 de N (0, 1). En particulier, si τ tend vers +∞, π(θ)
converge vers la mesure de Lebesgue sur R et donne
Cα = [x −kασ, x + kασ] ,
c’est-`a-dire l’intervalle de conﬁance habituel, en tant qu’estimateur de Bayes
g´en´eralis´e.
∥
Exemple 5.50. Soient x ∼B(n, p) et la loi non informative p ∼Be(1/2,
1/2). Alors p|x ∼Be(x + 1/2, n −x + 1/2) et les intervalles de conﬁance pour
p peuvent ˆetre calcul´es `a partir de la fonction de r´epartition de la loi bˆeta. Le
Tableau 5.11 donne ces intervalles pour n = 5 et α = 5%, 10%.
∥

5.5 R´egions de conﬁance
279
Tab. 5.11. Intervalles α-cr´edibles pour la loi binomiale B(n, p).
x
0
1
2
α = 5%
[0.000, 0.38] [0.022, 0.621] [0.094, 0.791]
α = 10% [0.000, 0.308] [0.036, 0.523] [0.128, 0.74]
Notons l’avantage signiﬁcatif de l’approche bay´esienne par rapport `a l’ap-
proche classique pour traiter des lois discr`etes. En eﬀet, les intervalles de
conﬁance classiques requi`erent une ´etape de randomisation pour atteindre
les niveaux de conﬁance standard (voir Blyth, 1961, pour une illustration
dans un cas binomial). Une mod´elisation a priori ´evite cette adjonction d’un
bruit al´eatoire et, au contraire, tire proﬁt de l’information a priori disponible.
Notons aussi que les lois a priori impropres peuvent ˆetre utilis´ees dans ce
cadre, sans pr´esenter les mˆemes diﬃcult´es que pour des hypoth`eses nulles
ponctuelles. En eﬀet, les r´egions cr´edibles a posteriori peuvent ˆetre obtenues
d`es que la loi a posteriori est d´eﬁnie. Certaines r´egions de conﬁance peuvent
s’exprimer comme des r´egions cr´edibles associ´ees `a des lois g´en´eralis´ees.
Exemple 5.51. Soient x1, . . . , xn i.i.d. N (θ, σ2) et la loi a priori non infor-
mative
π(θ, σ2) = 1
σ2 .
Nous avons montr´e dans la Section 4.4.2 que la loi a posteriori marginale
pour 1/σ2 est une loi gamma G
	
(n −1)/2, s2/2

avec s2 = (xi −¯x)2. Par
cons´equent,
s2
σ2 |¯x, s2 ∼χ2
n−1
et nous obtenons le mˆeme intervalle de conﬁance que dans l’approche classique,
mais sa justiﬁcation est ici conditionnelle `a s2.
∥
Exemple 5.52. Soient x ∼B(n, p) et p ∼Be(α, β). Dans ce cas, π(p|x) est
la loi Be(α + x, β + n −x). Selon les valeurs de α, β, n et x, les r´egions de
conﬁance sont de quatre types :
(i) 0 ≤p ≤K(x) ;
(ii) K(x) ≤p ≤1 ;
(iii) K1(x) ≤p ≤K2(x) ; et
(iv) 0 ≤p ≤K1(x) ou K2(x) ≤p ≤1.
La derni`ere r´egion est assez artiﬁcielle et plutˆot inutile. Notons qu’elle corres-
pond au cas
α + x < 1
et
β + n −x < 1,
46Cette formulation permet de couvrir le cas particulier o`u {θ; π(θ|x) = kα} n’est
pas vide.

280
5 Tests et r´egions de conﬁance
ce qui implique par cons´equent que α et β doivent ˆetre suﬃsamment n´egatifs,
car α+β < 2−n. Cette possibilit´e disparaˆıt donc pour n assez grand, `a moins
que α et β ne d´ependent de n, ce qui n’est pas d´esirable d’un point de vue
bay´esien. De plus, le cas limite α = β = 0, qui correspond `a la loi de Haldane
(1931)
π(p) = [p(1 −p)]−1,
conduit d´ej`a aux r´egions de types (i)-(iii), bien que la loi a posteriori ne soit
pas d´eﬁnie pour tous les x (Exemple 1.27).
∥
Lorsque des ph´enom`enes comme ceux du cas (iv) de l’Exemple 5.52 se pro-
duisent, c’est-`a-dire lorsque la r´egion de conﬁance n’est pas connexe (voir aussi
l’Exemple 5.5), la solution habituelle est de remplacer la r´egion α-cr´edible
HPD par un intervalle `a queues ´egales, soit [C1(x), C2(x)] tel que
P π(θ < C1(x)|x) = P π(θ > C2(x)|x) = α/2.
Berger (1985b) fait remarquer que l’occurrence de r´egions HPD non connexes
met aussi en lumi`ere une divergence entre la loi a priori et les observations,
et que ce ph´enom`ene devrait conduire `a une remise en question du choix de
la loi a priori ou de la distribution de l’´echantillon. Il peut aussi permettre
d’exhiber une structure de non-identiﬁabilit´e responsable de la multimodalit´e
de la loi a posteriori.
Si la construction d’ensembles cr´edibles est plutˆot simple conceptuelle-
ment, la d´etermination pratique de ces r´egions peut ˆetre assez complexe, en
particulier lorsque la dimension de Θ est grande ou lorsque la loi a poste-
riori n’est pas disponible explicitement. Une premi`ere solution est d’utiliser
des m´ethodes num´eriques similaires `a celles d´evelopp´ees dans le Chapitre 6, le
probl`eme ´etant d’´evaluer l’erreur correspondante (qui peut ˆetre beaucoup plus
grande que les erreurs d’approximation dans les probl`emes d’estimation ponc-
tuelle). (Notons que les r´egions cr´edibles `a queues ´egales sont g´en´eralement
plus faciles `a approcher que les r´egions HPD ; voir Eberly et Casella, 1999.)
Une deuxi`eme solution, sugg´er´ee par Berger (1980b, 1985b), est d’utiliser
une approximation normale, donc de consid´erer que la loi a posteriori de θ
est approximativement Np(Eπ(θ|x), Varπ(θ|x)) et de construire les r´egions de
conﬁance `a partir de cette approximation
Cα =

θ; (θ −Eπ(θ | x))t Varπ(θ|x)−1(θ −Eπ(θ|x)) ≤k2
α

,
o`u k2
α est le quantile de niveau α de χ2
p. Cette approximation n’est justiﬁ´ee que
pour une grande taille d’´echantillon (voir Hartigan, 1983), mais elle permet
des calculs rapides et plutˆot eﬃcaces.
5.5.2 Intervalles de conﬁance classiques
Dans la th´eorie de Neyman-Pearson, les r´egions de conﬁance peuvent se
d´eduire des tests UPPS par un argument de dualit´e : Si

5.5 R´egions de conﬁance
281
Cθ = {x; ϕθ(x) = 1}
est la r´egion d’acceptation de l’hypoth`ese nulle H0 : θ = θ0, ϕθ0 ´etant un test
UPPS au niveau α, la r´egion de conﬁance correspondante est
Cx = {θ; x ∈Cθ}
= {θ; ϕθ(x) = 1}
et P(θ ∈Cx) = 1 −α. De fa¸con plus g´en´erale, une r´egion Cx est dite r´egion
de conﬁance au niveau α (dans un sens fr´equentiste) si, pour tout θ ∈Θ,
P(θ ∈Cx) ≥1 −α.
Exemple 5.53. (Suite de l’Exemple 5.49) Si x ∼N (θ, σ2), le test UPPS
`a 95% est ϕθ(x) = I[0,1.96] (|x −θ|/σ) et la r´egion de conﬁance correspondante,
lorsque σ est connu, est
Cx = [x −1.96σ, x + 1.96σ].
∥
Exemple 5.54. Soit x ∼Tp(N, θ, Ip), loi de Student `a N degr´es de libert´e
de densit´e
f(x | θ) ∝

1 + 1
N ∥x −θ ∥2
−(N+p)/2
.
Puisque ||x −θ||2/p ∼F(p, N), nous pouvons construire une boule de
conﬁance au niveau 1 −α%
Cx =

θ; ∥x −θ ∥2≤pfα(p, N)

,
o`u fα(p, N) est le quantile de niveau α de F(p, N).
∥
Ces r´egions de conﬁance, bien qu’elles soient utilis´ees de fa¸con assez ex-
tensive dans la pratique (par exemple, dans le cas des r´egressions lin´eaires),
ont ´et´e critiqu´ees en termes fr´equentistes, conditionnels et bay´esiens. Tout
d’abord, comme on l’a vu dans les sections pr´ec´edentes, l’approche de Neyman-
Pearson elle-mˆeme n’est pas sans inconv´enient et l’optimalit´e des tests UPPS
peut ˆetre contest´ee. Par cons´equent, les r´egions de conﬁance construites `a par-
tir de ces tests (appel´ees r´egions uniform´ement plus pr´ecises par Lehmann,
1986) n’ont pas n´ecessairement un comportement ad´equat. De plus, mˆeme
dans une perspective fr´equentiste, la transformation de proc´edures de test op-
timales en r´egions de conﬁance n’accorde pas automatiquement `a ces r´egions
une forme d’optimalit´e, malgr´e la d´enomination ci-dessus.
En plus des critiques conditionnelles des r´egions de conﬁance (voir la Note
5.7.3), il existe aussi des critiques fr´equentistes. `A la suite de Stein (1962a)
et Lindley (1962), Brown (1966) et Joshi (1967a) ont en eﬀet ´etabli que ces

282
5 Tests et r´egions de conﬁance
r´egions C0
x ne sont pas toujours optimales, car il peut exister un autre ensemble
C′
x tel que
Pθ(θ ∈C′
x) ≥Pθ(θ ∈C0
x)
et
vol(C′
x) ≤vol(C0
x).
Par cons´equent, l’ensemble C′
x est pr´ef´erable `a C0
x, car, pour un volume plus
petit, il a une probabilit´e plus grande de contenir la vraie valeur du param`etre.
Par exemple, dans le cas normal, Joshi (1967a) a ´etabli que, si x ∼Np(θ, Ip),
la r´egion de conﬁance
C0
x =

θ; ||θ −x||2 ≤cα

est admissible (au sens ci-dessus) si et seulement si p ≤2 (voir aussi Co-
hen et Strawderman, 1973). Pour des dimensions plus grandes, il est possible
d’exhiber des r´egions de conﬁance plus eﬃcaces.
Ce ph´enom`ene se rapporte `a l’eﬀet Stein, qui ´etablit la non-admissibilit´e
de l’estimateur du maximum de vraisemblance pour p ≥3 (voir la Note 2.8.2).
Hwang et Casella (1982) ont tir´e proﬁt de cette analogie pour montrer que, si
δJS(x) =

1 −
a
||x||2
+
x
est un estimateur de James-Stein tronqu´e, la r´egion de conﬁance recentr´ee
CJS
x =

θ; ||θ −δJS(x)||2 ≤cα

,
a le mˆeme volume que la boule usuelle C0
x et satisfait
Pθ(θ ∈CJS
x ) > Pθ(θ ∈C0
x) = 1 −α
(5.23)
pour a suﬃsamment petit. Par cons´equent, CJS
x
domine C0
x dans le sens ci-
dessus.
Une part importante de la litt´erature sur les r´egions de conﬁance recentr´ees
a ´et´e initi´ee par Hwang et Casella (1982, 1984), `a l’instar des d´eveloppements
sur l’estimation ponctuelle associ´ee `a l’eﬀet Stein (voir la Section 2.8.2). De
nouvelles r´egions recentr´ees ont ´et´e propos´ees par Hwang et Casella (1984) et
Casella et Hwang (1983, 1987). Hwang et Chen (1986) et Robert et Casella
(1990) ont ´elargi les r´esultats de domination aux lois `a sym´etrie sph´erique,
bien que le cas gaussien avec variance inconnue soit toujours sans solution
(voir Hwang et Ullah, 1994). Shinozaki (1990) a aussi imagin´e une r´egion de
conﬁance avec exactement la mˆeme probabilit´e de couverture, mais avec un
volume plus petit, tirant proﬁt de la non-admissibilit´e de la r´egion usuelle
d’une fa¸con oppos´ee `a (5.23). Lu et Berger (1989a), Robert et Casella (1993)
et George et Casella (1994) se sont aussi inspir´es de (5.23) pour proposer
des estimateurs de conﬁance am´elior´es pour les ensembles standard et re-
centr´es. Pour le probl`eme d’estimation de la variance d’une loi normale, des
am´eliorations similaires sont donn´ees par Cohen (1972), Shorrock (1990) et
Goutis et Casella (1991).

5.5 R´egions de conﬁance
283
5.5.3 ´Evaluation d´ecisionnelle des ensembles de conﬁance
Comme les lecteurs ont pu le constater, la construction des r´egions de
conﬁance ci-dessus a ´et´e conduite de mani`ere plutˆot empirique, pour des jus-
tiﬁcations d´ecisionnelles limit´ees. Le choix des r´egions HPD est g´en´eralement
li´e `a la n´ecessit´e de minimiser le volume de cette r´egion, sous une contrainte
de couverture
P(θ ∈Cα|x) ≥1 −α.
Plusieurs auteurs ont propos´e des constructions diﬀ´erentes des r´egions de
conﬁance selon des crit`eres purement d´ecisionnels. Ces auteurs consid`erent
des fonctions de coˆut int´egrant simultan´ement les exigences de volume et de
couverture. (Dans un sens, l’approche ci-dessus correspond `a un coˆut bidi-
mensionnel, dont les composantes sont vol(C) et 1 −IC(θ).) Par exemple,
une version simple de cette perspective d´ecisionnelle est de consid´erer une
combinaison lin´eaire
L(C, θ) = vol(C) + cIθ /∈C,
(5.24)
ce qui donne le risque
R(C, θ) = E[vol(Cx)] + cP(θ /∈Cx).
(La constante c peut ˆetre reli´ee `a un niveau de conﬁance particulier.) De
plus, Cohen et Sackrowitz (1984) ont montr´e que le coˆut bidimensionnel ci-
dessus est li´e au coˆut lin´eaire (5.24) lorsque c est trait´e comme un param`etre
suppl´ementaire du mod`ele.
Un d´efaut important des coˆuts (5.24) a ´et´e soulign´e par James Berger (voir
Casella et al., 1993b,a) : Le probl`eme provient d’une p´enalisation in´egale entre
volume et couverture. En eﬀet, la fonction indicatrice varie entre 0 et 1 tandis
que le volume peut augmenter jusqu’`a l’inﬁni ; cette asym´etrie m`ene `a un biais
en faveur des ensembles de conﬁance petits.
Exemple 5.55. Soient x1, . . . , xn i.i.d. N (θ, σ2). L’intervalle classique de
Student en θ,
Ck(¯x, s) =

¯x −k s
√n, ¯x + k s
√n

,
est une r´egion HPD lorsque
¯x =
n

i=1
xi/n,
s2 =
n

i=1
(xi −¯x)2/(n −1),
et
π(θ, σ2) = 1
σ2 ,
loi non informative de Jeﬀreys. Dans ce cas, en eﬀet,
√n θ −¯x
s
| ¯x, s ∼Tn−1 .
Sous (5.24), le coˆut a posteriori est

284
5 Tests et r´egions de conﬁance
ϱ(π, Ck(¯x, s)|¯x, s) = 2k s
√n −cP π(θ ∈Ck(¯x, s)|¯x, s)
= 2k s
√n −cP(|Tn−1| ≤k).
Il est alors facile de voir que la r´egion HPD est domin´ee par une r´egion
tronqu´ee
C′
t(¯x, s) =

Ct(¯x, s)
si s < √nc/(2k),
{¯x}
sinon.
Cette domination est contraire `a l’intuition : C′
t ne contient que le point {¯x},
ce qui semble indiquer une forte certitude, alors que la variance empirique
augmente, ce qui signiﬁe que l’incertitude grandit. Un ph´enom`ene similaire se
produit lorsque k d´epend de s : la taille de la r´egion de cr´edibilit´e d´ecroˆıt vers
0 quand s augmente (voir Casella et al., 1993b,a).
∥
Le paradoxe ci-dessus montre les limitations du coˆut lin´eaire (5.24). Casella
et al. (1993a) proposent une classe alternative de fonctions de coˆut qui ´evite
ce paradoxe. Le plus simple de ces coˆuts est le coˆut dit rationnel
L(C, θ) =
vol(C)
vol(C) + k + Iθ /∈C
(k > 0),
o`u les deux termes sont inf´erieurs `a un. Les estimateurs de Bayes associ´es `a
ces coˆuts restent des r´egions HPD mais sont non vides pour toutes les lois a
priori conjugu´ees dans le cas normal. Le param`etre k peut s’obtenir par des
techniques similaires `a celles d´evelopp´ees pour des coˆuts r´eguliers, `a savoir en
comparant les p´enalisations associ´ees au volume pour des r´egions diﬀ´erentes
et en approchant la fonction d’utilit´e.
Nous n’irons pas plus loin dans l’´etude d´ecisionnelle des r´egions de con-
ﬁance bay´esiennes. En eﬀet, un aspect important souvent n´eglig´e dans la
construction de r´egions de conﬁance est la fa¸con dont elles seront utilis´ees,
bien que cette fa¸con soit essentielle dans la construction de la fonction de
coˆut. En eﬀet, l’objectif du d´ecideur peut ˆetre de
(1) consid´erer l’estimation d’ensemble comme une ´etape pr´eliminaire `a
une phase d’estimation ponctuelle (et, par exemple, construire une loi a
priori empirique de support ´egal `a la r´egion de conﬁance estim´ee) ;
(2) se fonder sur la r´egion de conﬁance obtenue pour r´esoudre un probl`eme
de test (et rejeter l’hypoth`ese nulle si la r´egion de conﬁance ne contient
pas une certaine valeur) ;
(3) d´eduire de la taille (volume) de la r´egion de conﬁance un indicateur de
performance d’un estimateur associ´e, par exemple, le centre de la r´egion.
Une courbe de performance pour cet estimateur peut ˆetre obtenue en
faisant correspondre la taille et les niveaux de conﬁance.
Ces trois perspectives de l’estimation par r´egions de conﬁance m`enent `a des
fonctions de coˆut fondamentalement diﬀ´erentes et il peut paraˆıtre irr´ealiste

5.6 Exercices
285
d’essayer de construire une fonction de coˆut globale uniﬁant des objectifs si op-
pos´es. En eﬀet, des fonctions de coˆut distinctes sont pr´ef´erables, car, en accord
avec les bases de la Th´eorie de la D´ecision, le d´ecideur devrait choisir une fonc-
tion de coˆut selon ses besoins. Notons aussi que les trois objectifs consid´er´es
ci-dessus correspondent `a des probl`emes inf´erentiels d´ej`a ´etudi´es auparavant
et donc qu’une approche sp´eciﬁque aux r´egions de conﬁance peut ˆetre par-
tiellement inutile. Par cons´equent, il nous semble que, pour le moins, une
approche conditionnelle devrait ˆetre utilis´ee pour la construction de r´egions
de conﬁance (voir la Note 5.7.3). `A la suite de Kiefer (1977), nous sugg´erons
d’associer `a l’ensemble donn´e Cx un indicateur de conﬁance γ(x), ´evalu´e sous
le coˆut
L(C, γ, θ) = (IC(θ) −γ)2.
(5.25)
La r´egion de conﬁance est alors remplac´ee par une proc´edure de conﬁance,
li´ee `a la perspective conditionnelle de Robinson (1979). De ce point de vue, la
proc´edure {Θ, 1} est malheureusement parfaite, un inconv´enient qui indique
qu’une ´evaluation additionnelle de Cx devrait ˆetre incluse dans la fonction
de coˆut, comme dans Rukhin (1988a,b). De la mˆeme fa¸con, la proc´edure
bay´esienne associ´ee `a une r´egion HPD Cα est [Cα, 1 −α], comme on peut
le v´eriﬁer en minimisant le coˆut a posteriori. Pour une r´egion arbitraire, Cx,
la proc´edure correspondante est [Cx, γπ(x)], o`u
γπ(x) = P π(θ ∈Cx|x).
L’introduction d’une fonction de coˆut globale combinant volume, couverture et
rapport de conﬁance comme dans (5.25) donnerait pour proc´edures optimales
les proc´edures minimisant l’erreur a posteriori (ou fr´equentiste) maximale.
Cette approche n’a cependant pas encore ´et´e trait´ee dans la litt´erature.
5.6 Exercices
Section 5.2.1
5.1 Dans le cadre de l’Exemple 5.4, ´etudier la modiﬁcation de la probabilit´e a
posteriori de H0 lorsque x = 0 et τ/σ tend vers +∞. Comparer `a la r´eponse
non informative associ´ee `a π(θ) = 1.
Section 5.2.2
5.2 Soit x ∼N (θ, 1). L’hypoth`ese `a tester est H0 : |θ| ≤c contre H1 : |θ| > c,
avec π(θ) = 1.
a. Tracer la courbe de la probabilit´e maximale de H0 en fonction de c.
b. D´eterminer les valeurs de c pour lesquelles ce maximum est 0.95 et le facteur
de Bayes est 1. Ces valeurs sont-elles satisfaisantes ?
5.3 Un professeur doit donner un examen sur deux jours diﬀ´erents. Puisque les
´etudiants s’assoient les uns `a cˆot´e des autres, il distribue deux sujets diﬀ´erents,

286
5 Tests et r´egions de conﬁance
en alternance, aﬁn de r´eduire les possibilit´es de tricherie. Il utilise la mˆeme
technique et les mˆemes sujets avec une autre classe le jour suivant. Les r´esultats
sont : n1A = 17 ´etudiants ont planch´e sur l’examen A le premier jour, n2A = 19
le second jour, n1B = 15 sur le sujet B le premier jour et n2B = 19 le second
jour. Les notes moyennes (sur 20) sont ˆμ1A = 10.3, ˆμ2A = 10.9, ˆμ1B = 7.9
et ˆμ2B = 8.7 et les ´ecarts types sont ˆσ1A = 2.67, ˆσ2A = 2.09, ˆσ1B = 2.98 et
ˆσ2B = 2.91.
a. Tester la pr´esence d’un eﬀet de classe, de sujet, ou d’un eﬀet crois´e classe-
sujet en mod´elisant les r´esultats par une approche d’analyse de la variance,
c’est-`a-dire en supposant que chaque note d’´etudiant x est distribu´ee selon
une loi normale de moyenne μ0+μe+μc et de variance σ2
ec (e = A, B, c = 1, 2)
avec μA + μB = 0, μ1 + μ2 = 0.
b. Un ´etudiant planchant sur le sujet A a oubli´e de rendre sa copie le premier
jour. Est-il possible de d´etecter une tricherie le second jour ?
Section 5.2.3
5.4 (Pearl, 1988) Apr`es que vous ayez fait part d’une rumeur `a un voisin, celui-ci
vous la r´ep`ete quelques jours plus tard. Construire un mod`ele pour tester la
possibilit´e que ce voisin ait entendu cette rumeur d’une autre personne.
5.5
*Soient deux observations ind´ependantes normales standard x et y. Les coor-
donn´ees polaires de (x, y) sont (r, θ), avec x = r cos θ et y = r sin θ.
a. Pour 2r2 = (x −y)2 + (x + y)2 et ´etant donn´e que les variables x −y et
x + y sont ind´ependantes, montrer que la distribution de r2 sachant x = y est
G (1/2, 1).
b. Montrer que les variables r et θ sont ind´ependantes et en d´eduire que la
distribution de r2 sachant θ = π/4, 5π/4 est G (1/2, 1/2).
c. Puisque {x = y} = {θ = π/4, 5π/4}, expliquer ce paradoxe apparent, dit
paradoxe de Borel, de deux distributions conditionnelles diﬀ´erentes pour un
mˆeme ´ev´enement. (Indication : Replacer le conditionnement dans une pers-
pective de σ-alg`ebres et comparer les σ-alg`ebres engendr´ees par x −y et par
θ.)
Section 5.2.4
5.6 Pour x ∼N (θ, 1) et θ ∼N (0, σ2), comparer les r´eponses bay´esiennes pour les
deux probl`emes de test
H1
0 : θ = 0 contre H1
1 : θ ̸= 0,
H2
0 : |θ| ≤ϵ contre H2
1 : |θ| > ϵ,
lorsque ϵ et σ varient.
5.7 Dans le cadre de l’Exemple 5.3, pour x ∼B(n, p) et le test de H0 : p = 1/2,
´etudier comment varient les r´eponses bay´esiennes en fonction de n pour x = 0,
x = n/2 et la loi a priori de Jeﬀreys.
5.8 * (Berger et Delampady, 1987) Soit x ∼N (θ, 1). Le but de cet exercice est de
comparer H0 : |θ −θ0| ≤ϵ avec l’approximation H∗
0 : θ = θ0. On note g0 et g1
les densit´es a priori sur {|θ −θ0| ≤ϵ} et {|θ −θ0| > ϵ}. Soit g une densit´e sur
R telle que
g(θ) ∝g1(θ)
si
|θ −θ0| > ϵ,
et telle que

5.6 Exercices
287
λ =
Z
|θ−θ0|≤ϵ
g(θ)dθ,
soit suﬃsamment petit. On note
B =
R
|θ−θ0|≤ϵ f(x|θ)g0(θ) dθ
R
|θ−θ0|>ϵ f(x|θ)g1(θ) dθ
et
ˆB = f(x|θ0)
mg(x) =
f(x|θ)
R
f(x|θ)g(θ) dθ,
t = (x −θ0) et
γ =
1
2ϵϕ(t)[Φ(t + ϵ) −Φ(t −ϵ)] −1.
Montrer que, si |t| ≥1, ϵ < |t| −1 et ˆB ≤(1 + γ)−1, alors
B = ˆB(1 + ϱ)
avec
−λ ≤λ( ˆB −1)
1 −λ ˆB
≤ϱ ≤γ + λ(1 + γ)( ˆB −1)
1 −λ ˆB(1 + γ)
≤γ.
Section 5.2.5
5.9 Soit x ∼P(λ). L’hypoth`ese `a tester est H0 : λ ≤1 contre H1 : λ > 1. Donner
la probabilit´e a posteriori de H0 pour x = 1 et λ ∼G (α, β).
a. Comment varie cette probabilit´e lorsque α et β tendent vers 0 ? Est-ce que
la r´eponse `a cette question d´epend des taux de convergence de α et β vers 0 ?
b. Comparer aux probabilit´es associ´ees `a la loi non informative π(λ) = 1/λ.
Est-il toujours possible d’utiliser cet a priori impropre ?
5.10 Soient x ∼B(n, p), H0 : p = 1/2 et H1 : p ̸= 1/2. L’a priori π(p) est une
loi Be(α, α). D´eterminer la limite de la probabilit´e a posteriori de H0 lorsque
n = 10, x = 5 et n = 15, x = 7 pour α tendant vers +∞. Ces valeurs sont-
elles intuitives ? Donner les probabilit´es a posteriori pour les lois a priori non
informatives de Laplace, Jeﬀreys et Haldane.
5.11 R´esoudre les Exercices 5.9 et 5.10 pour les facteurs de Bayes plutˆot que les
probabilit´es a posteriori.
5.12 Dans un cadre gaussien, d´eterminer s’il existe un probl`eme de normalisation
associ´e `a des lois a priori non informatives pour des tests d’hypoth`eses uni-
lat´erales telles que
H0 : θ ∈[0, 1]
contre
H1 : θ > 1.
Remplacer [0, 1] par [0, ϵ] et ´etudier les variations de la solution optimale lorsque
ϵ tend vers 0.
5.13 Dans le test de
H0 : |θ| < ϵ
contre
H1 : |θ| > ϵ,
montrer que le facteur de Bayes tend vers le facteur de Bayes associ´e au test de
H0 : θ = 0
contre
H1 : θ ̸= 0 ,
quand ϵ tend vers 0. (Indication : On supposera que la r`egle de L’Hospital
s’applique.)

288
5 Tests et r´egions de conﬁance
Section 5.2.6
5.14 ´Etablir la d´ecomposition (5.6) `a partir de la d´eﬁnition originale (5.5) de B(ℓ)
10 .
(Indication : Utiliser la formule de Bayes pour obtenir π1(θ1|x(ℓ)) et π0(θ1|x(ℓ)).)
5.15 Dans le cadre de l’Exemple 5.13, montrer comment B(2)
10 d´epend du choix de
(x1, x2) en calculant les constantes de normalisation de π0(σ2|x1, x2) et π1(μ,
σ2|x1, x2) et en concluant le calcul d’int´egrales dans B(2)
10 .
5.16 Aitkin (1991) sugg`ere de contourner la diﬃcult´e li´ee aux lois a priori impropres
en utilisant les donn´ees deux fois : pour x ∼f(x|θ), un a priori impropre π et
une hypoth`ese `a tester H0 : θ = θ0, prendre ˜π(θ) = π(θ|x) et utiliser ˜π comme
a priori dans le facteur de Bayes.
a. Si f(·|θ) est la densit´e de la loi N (θ, 1) et π(θ) = 1, calculer les pseudo-
facteurs de Bayes correspondants.
b. Mˆeme question que a. lorsque f(·|θ) est la fonction de probabilit´e de la loi
P(λ) et π(λ) = 1/λ.
c. Analyser le comportement limite de ce pseudo-facteur de Bayes lorsque cette
proc´edure est r´ep´et´ee, c’est-`a-dire lorsque π est remplac´e it´erativement par
˜π. [Note : D’un point de vue num´erique, cette technique peut ˆetre utile
pour le calcul d’estimateurs du maximum de vraisemblance et d’estimateurs
MAP ; voir Robert et Casella, 1999, Section 5.2.4.]
5.17 Dans le cadre de l’Exemple 5.14, calculer le facteur de Bayes lorsque π1(θ)
est la densit´e de la loi N (0, 2) et comparer avec le facteur de Bayes intrins`eque
arithm´etique. (Indication : Calculer E[exp(−x2/2)].)
5.18 (Suite de l’Exercice 5.17) Pour le facteur de Bayes fractionnaire (5.11),
a. Montrer que la valeur minimale de b est 1/n.
b. Montrer que (5.11) correspond `a la loi a priori intrins`eque N (0, (1−b)/nb).
c. Montrer qu’une valeur ﬁx´ee de b m`ene `a une r´eduction de la variance vers
0 dans l’a priori intrins`eque.
d. Comparer les valeurs num´eriques des facteurs de Bayes intrins`eques arith-
m´etique et fractionnaire.
e. D´eterminer s’il existe une valeur de b telle que ces pseudo-facteurs de Bayes
soient ´equivalents.
5.19 Dans le cadre de l’Exemple 5.15,
a. Montrer que π2 s’int`egre bien `a 1.
b. Montrer que BA
10 correspond bien `a un facteur de Bayes sous π2.
5.20 Les conditions de coh´erence pour les facteurs de Bayes sont donn´ees par
B12 = B10B02
et
B01 = 1/B10 ,
lorsque trois hypoth`eses, H0, H1 et H2, sont consid´er´ees avec, pour lois a priori
respectives, π0, π1 et π2.
a. Montrer que ces conditions sont satisfaites lorsque les πi sont des lois a
priori propres.
b. Montrer que les facteurs de Bayes fractionnaires satisfont B01 = 1/B10 mais
pas B12 = B10B02.

5.6 Exercices
289
c. Montrer que ni les facteurs de Bayes arithm´etiques ni les facteurs de Bayes
g´eom´etriques intrins`eques ne satisfont ces conditions.
5.21 Pour la loi a priori intrins`eque consid´er´ee dans l’Exemple 5.17,
a. Montrer que
Z ∞
θ0
“
2eθ−θ0 −1
”−1
dθ = log(2).
(Indication : Utiliser un changement de variable de θ `a ω = exp(θ −θ0) et
une d´ecomposition fractionnelle de 1/ω(2ω −1).)
b. En d´eduire l’expression (5.12).
5.22 Dans le cadre de l’Exemple 5.19,
a. Montrer que
Z  n
Y
t=1
j p
σ1 e−(xt−μ1)2/2σ2
1 + 1 −p
σ2 e−(xt−μ2)2/2σ2
2
ﬀ!b
dπ(μ, σ)
≥
Z  n
Y
t=1
p
σ1 e−(xt−μ1)2/2σ2
1
!b
dπ(μ, σ) .
b. En d´eduire que le facteur de Bayes fractionnaire n’existe pas pour ce mod`ele.
5.23 Soient n observations x1, . . . , xn d’une loi de Student T (ν, μ, σ) et l’hypoth`ese
nulle H0 : μ = 0.
a. D´eterminer la taille d’´echantillon d’apprentissage minimale pour les lois a
priori π0(σ) = 1/σ et π1(μ, σ) = 1/σ.
b. Montrer que les facteurs de Bayes fractionnnaires ne peuvent pas ˆetre ob-
tenus explicitement dans ce cas.
Section 5.3.1
5.24 Soient f et g deux fonctions r´eelles croissantes.
a. Montrer que
Eθ[f(X)g(X)] ≥Eθ[f(X)]Eθ[g(X)]
pour toute loi Pθ de x.
b. Utiliser a. pour montrer que, si f(x|θ) est une densit´e de rapport de vrai-
semblance monotone en T(x), l’esp´erance Eθ[g(T(x))] est une fonction crois-
sante de θ. (Indication : Utiliser g(x) = 1 −f(x|θ′)/f(x|θ) et montrer que
Eθ[g(X)] = 0.)
5.25 Montrer que les lois de Student et du χ2 d´ecentr´e sont `a rapport de vraisem-
blance monotone.
Section 5.3.4
5.26 Pour la p-value ˜p d´eﬁnie dans l’Exemple 5.32, d´eterminer les valeurs de ˜p(x)
pour n = 15 et comparer avec
p(x) = P1/2 [f(X|1/2) > f(x|1/2)] .
5.27 (Johnson et Lindley, 1995) Soit une hypoth`ese nulle ponctuelle H0 : θ = θ0
telle que la p-value ϕ soit bien d´eﬁnie. La seule information disponible est que
les donn´ees sont signiﬁcatives au niveau α, donc que ϕ(x) < α.

290
5 Tests et r´egions de conﬁance
a. Donner le facteur de Bayes Rα de H0 contre H1 : θ ̸= θ0 lorsque les donn´ees
sont signiﬁcatives au niveau α, pour une loi a priori π arbitraire.
b. ´Etant donn´e un second niveau de signiﬁcativit´e β tel que β < α, on suppose
Rα < Rβ. ´Etablir une condition suﬃsante sur π pour que cette condition soit
v´eriﬁ´ee.
c. Si Rα|β est le facteur de Bayes fond´e sur l’information β < ϕ(x) < α, montrer
que Rα = ωRβ + (1 −ω)Rα|β et en d´eduire que Rβ > Rα > Rα|β.
d. Dans le cas particulier o`u π(θ) est ϱ0Iθ0(θ) + (1 −ϱ0)N (θ0, τ 2) et x1, . . . , xn
∼N (θ, σ2), montrer que Rα converge vers (1 −ϱ0)/ϱ0α lorsque n tend vers
l’inﬁni et Rα|β vers 0.
Section 5.3.5
5.28 Pour x ∼N (θ, 1) et H0 :
θ = 0, d´eterminer si les p-values prennent des
valeurs inf´erieures `a P(x, GA) et P(x, GS).
5.29 (Berger et Delampady, 1987)
Soient x ∼B(n, p) et H0 : p = 1/2. Pour la
classe de lois a priori GC form´ee des lois conjugu´ees de moyenne 1/2, montrer
que
P(x, GC) =
inf
g∈GC P(H0|x)
=
»
1 + 1 −π0
π0
sup
c>0
Γ(c)Γ(x + c/2)Γ(n −x + c/2)
Γ(c/2)2Γ(n + c)
–−1
et ´etablir la table de ces bornes inf´erieures et les p-values correspondantes pour
n = 10, 20, 30 et x variant de 0 `a n/2.
5.30
*(Casella et Berger, 1987)
´Etablir le lemme suivant, utilis´e dans le Lemme
5.35 et le Th´eor`eme 5.38 : dans le cas o`u G est la famille des lois de m´elange
g(θ) =
Z
Ξ
gξ(θ)h(ξ) dξ,
pour toute densit´e h sur Ξ, avec gξ ∈G0 et
G0 = {gξ; ξ ∈Ξ},
alors, pour tout f,
sup
g∈G
Z
f(x|θ)g(θ) dθ = sup
ξ∈Ξ
Z
f(x|θ)gξ(θ) dθ.
5.31 Dans le cas o`u x ∼N (θ, 1) et H0 : θ ≤0, d´eterminer la borne inf´erieure
P(x, GSU) =
inf
g∈GSU P g(θ ≤0|x)
=
inf
g∈GSU
R 0
−∞f(x −θ)g(θ) dθ
R +∞
−∞f(x −θ)g(θ)dθ
pour x < 0. Est-ce que la conclusion de Casella et Berger (1987) tient toujours ?
Pouvez-vous expliquer pourquoi ?

5.6 Exercices
291
5.32
*(Casella et Berger, 1987)
Soit une fonction sym´etrique unimodale born´ee
g. La famille des m´elanges d’´echelle de g est d´eﬁnie par
Gg = {πσ; πσ(θ) = (1/σ)g(θ/σ), σ > 0}.
Si la densit´e des observations est f(x −θ), avec f sym´etrique en 0, et si elle
v´eriﬁe la propri´et´e de rapport de vraisemblance monotone, montrer que, pour
x > 0,
P(x, Gg) = p(x)
pour le test de H0 : θ ≤0.
5.33
*(Casella et Berger, 1987) Soit le test de H0 : θ ≤0 contre H1 : θ > 0 avec
x ∼f(x −θ). Soient h et g des densit´es sur ] −∞, 0] et ]0, +∞[.
a. Montrer que, si π(θ) = ϱ0h(θ) + (1 −ϱ0)g(θ),
sup
h
P π(θ ≤0|x) =
ϱ0f(x)
ϱ0f(x) + (1 −ϱ0)
R +∞
0
f(x −θ)g(θ) dθ
et en d´eduire que le supr´emum favorise en fait H0 en concentrant toute la
masse `a la fronti`ere θ = 0.
b. Si
π(θ) = ϱ0h(θ/σ1) 1
σ1 + (1 −ϱ0)g(θ/σ2) 1
σ2 ,
montrer que, lorsque σ1 est ﬁx´e,
lim
σ2→∞P π(θ ≤0|x) = 1
et que, lorsque σ2 est ﬁx´e,
lim
σ1→∞P π(θ ≤0|x) = 0.
5.34
*(Caron, 1994) Aﬁn de r´epondre aux critiques `a l’´egard des hypoth`eses nulles
ponctuelles, H0 : θ = θ0, la formulation de l’hypoth`ese nulle peut ˆetre modiﬁ´ee
pour tenir compte de la loi a priori. Par exemple, pour une loi a priori donn´ee
π sur Θ admettant un mode en θ0 mais n’attribuant pas de poids a priori `a
θ0, on peut proposer l’hypoth`ese transform´ee Hπ
0 : π(θ) > kπ, de fa¸con telle
que la taille de la r´egion HPD soit d´etermin´ee par la condition “objective”
π(π(θ) > kπ) = 0.5. Consid´erons le cas x ∼N (θ, 1) et θ0 = 0.
a. Lorsque π appartient `a la famille des lois N (0, σ2), d´eterminer kπ et calculer
la borne inf´erieure des r´eponses bay´esiennes pour cette famille. Comparer
avec les probabilit´es a posteriori de Berger et Sellke (1987) pour les valeurs
d’int´erˆet.
b. D´eterminer si le paradoxe de Jeﬀreys-Lindley a lieu dans ce cas.
c. Pour les familles alternatives U[−c,c] (c > 0) et π(θ|λ) ∝exp(−λ|θ|) (λ > 0),
calculer les bornes inf´erieures correspondantes.
5.35 *(Suite de l’Exercice 5.34) Consid´erons le cas x ∼C (θ, 1) pour H0 : θ = 0.
a. Pour l’approche de Berger et Sellke (1987), montrer que la probabilit´e a
posteriori de H0 lorsque πc est U[−c,c] vaut
πc(H0|x) =
ˆ
1 + (1 + x2)(arctan(c −x) + arctan(c + x))/2c
˜−1 .

292
5 Tests et r´egions de conﬁance
b. Pour l’approche d´evelopp´ee dans l’exercice pr´ec´edent, montrer que la proba-
bilit´e correspondante est
πc(Hπ
0 |x) = arctan(c/2 −x) + arctan(c/2 + x))
arctan(c −x) + arctan(c + x))
.
c. Calculer et comparer les bornes inf´erieures pour les deux approches.
d. Montrer que
lim
x→∞
infc πc(Hπ
0 |x)
infc πc(H0|x) = 2
3.
Section 5.4
5.36 (Hwang et al., 1992)
Montrer que, pour la fonction de coˆut (5.19), les p-
values d´eﬁnies dans l’Exemple 5.45 sont eﬀectivement admissibles. (Indication :
Montrer que les risques de Bayes sont ﬁnis.)
5.37 (Hwang et al., 1992)
Le but de cet exercice est de montrer que, pour le
test bilat´eral (5.20), la p-value p(x) peut prendre la valeur 1. (Indication : On
rappelle que le test UPPS est de la forme
ϕ(x) =
(
0
si T(x) < c0 ou T(x) > c1,
1
sinon,
dans ce cadre, avec c0 = c0(α) et c1 = c1(α).)
a. Soient θ1 ̸= θ2 et
c∗= inf{T(x); f(x|θ2) > f(x|θ1)}.
Montrer que c∗∈[c0(α), c1(α)] pour tout 0 < α < 1.
b. On suppose θ1 = θ2. Appliquer le r´esultat pr´ec´edent `a
f(x|θ∗) = Eθ1[T(x)]f(x|θ1),
f(x|θ∗∗) = T(x)f(x|θ1),
et conclure.
5.38 (Hwang et al., 1992)
Dans un cadre gaussien, consid´erer l’hypoth`ese nulle
ponctuelle H0 : θ = 0. Montrer que, sous la fonction de coˆut (5.19), la p-value
ne peut pas ˆetre domin´ee par une probabilit´e a posteriori propre. (Indication :
D´emontrer d’abord que, pour tout a et ϵ,
Pθ(a < |x| < a + ϵ)
Pθ(|x| < a)
→+∞
lorsque θ tend vers l’inﬁni.)
5.39 (Hwang et al., 1992) Pour la fonction de coˆut (5.19), montrer que ϕ(x) = 1/2
est l’unique estimateur minimax. ´Etendre ce r´esultat `a toutes les fonctions de
coˆut convexes. Dans ce cadre, existe-t-il des lois les moins favorables ?
5.40 (Robert et Casella, 1994)
Une modiﬁcation possible de la fonction de coˆut
(5.18) est d’introduire une pond´eration fond´ee sur une distance, aﬁn de p´enaliser
d’une fa¸con diﬀ´erente les erreurs proches de la fronti`ere entre H0 et H1 de celles
qui en sont loin.

5.6 Exercices
293
a. Si l’hypoth`ese nulle est H0 : θ ≤θ0 pour x ∼N (θ, 1) et la fonction de coˆut
est
L(θ, ϕ) = (θ −θ0)2(IH0(θ) −ϕ)2,
donner l’expression g´en´erale des estimateurs de Bayes.
b. Si π(θ) = 1, montrer que l’estimateur de Bayes est plus petit que la p-value
si x > θ0 et plus grand si x < θ0.
5.41 (Robert et Casella, 1994) D’un point de vue de choix de mod`ele, la fonction de
perte incorpore les cons´equences d’une acceptation ou d’un rejet de l’hypoth`ese
nulle H0 : θ = θ0 en termes d’estimation.
a. Pour la fonction de coˆut
L1(θ, (ϕ, δ)) = d(θ −δ)|1 −ϕ| + d(θ0 −θ)|ϕ|,
montrer que les estimateurs de Bayes sont (0, δπ(x)) o`u δπ(x) est l’estimateur
de Bayes r´egulier de θ sous d(θ −δ) pour tout d et π.
b. Pour la fonction de coˆut
L2(θ, (ϕ, δ)) = d(θ −δ)|1 −ϕ| + d(θ0 −δ)|ϕ|,
montrer que la r`egle de Bayes est (1, θ0) pour tout π et d.
c. Pour la fonction de coˆut
L3(θ, (ϕ, δ)) = (δ −θ)2(IH0(θ) −ϕ)2,
montrer que la r`egle de Bayes associ´ee est (0, θ0), c’est-`a-dire que cette r`egle
rejette syst´ematiquement l’hypoth`ese nulle H0 : θ = θ0, mais utilise toujours
θ0 comme estimateur de θ.
d. ´Etudier les proc´edures bay´esiennes sous le coˆut modiﬁ´e
L4(θ, (ϕ, δ)) =
ˆ
1 + (δ −θ)2˜ ˆ
1 + (IH0(θ) −ϕ)2˜
,
aﬁn d’´etablir si elles sont moins paradoxales.
e. Montrer que la fonction de perte
L5(θ, (ϕ, δ)) = ξ(δ −θ)2|1 −ϕ| + {(δ −θ0)2 + (θ −θ0)2}|ϕ|,
fournit une proc´edure de pr´e-test bay´esien raisonnable qui ´evite les paradoxes
de L1, L2 et L3 si et seulement si ξ > 1.
Section 5.5.1
5.42 Soient deux observations ind´ependantes x1, x2 tir´ees d’une loi de Cauchy
C (θ, 1). Pour π(θ) = 1, donner la forme de la r´egion HPD α-cr´edible. Quelle
autre r´egion de niveau α plus convaincante pourriez-vous proposer ?
5.43 Donner la r´egion α-cr´edible pour x ∼P(λ) et λ ∼G (δ, β). Etudier l’´evolution
de cette r´egion en fonction de δ et β. Examiner le cas particulier de la loi non
informative.
5.44
*Cet exercice traite d’une alternative aux r´egions α-cr´edibles. Le meilleur
centre bay´esien au niveau α est l’estimateur δπ
α(x), qui est le centre de la boule
de plus petit rayon et de couverture 1 −α, c’est-`a-dire
P π(||θ −δπ
α(x)|| < k|x) = sup
δ
P π(||θ −δ(x)|| < k|x) = 1 −α.

294
5 Tests et r´egions de conﬁance
a. Montrer que, si la loi a posteriori est `a sym´etrie sph´erique et unimodale, la
r´egion correspondante est HPD.
b. Soient x ∼N (θ, 1), θ ∼N (0, τ 2) et π(τ 2) = 1/τ 3/2. D´eterminer la loi
a posteriori. Montrer que la densit´e correspondante est unimodale lorsque
0 < x2 < 2 et bimodale sinon, de second mode
δ(x) =
 
1 −1 −
p
1 −(2/x2)
2
!
x.
Calculer le meilleur centre de Bayes et montrer que, si α est suﬃsamment
grand, δπ
α n’est pas continu et proche de
φ(x) =
„
1 −
1
2x2
«+
x,
c’est-`a-dire que cet estimateur de Bayes reproduit l’estimateur de James-
Stein.
c. G´en´eraliser b. pour π(τ 2) = τ −v.
d. Montrer que le meilleur centre de Bayes associ´e `a un a priori propre π est
admissible sous le coˆut
L(θ, δ) = I(k,+∞)(||θ −δ||2).
5.45
*(Thatcher, 1964) Soit x ∼B(n, θ). Pour 0 < α < 1 et l’a priori π sur θ, on
d´eﬁnit θπ
x par P π(θ ≤θπ
x|x) = α.
a. Si π(θ) = (1 −θ)−1, montrer que Pθ(θ ≤θπ
x) ≤α pour θ > 0.
b. Si π(θ) = θ−1, montrer que Pθ(θ ≤θπ
x) ≥α pour θ < 1.
c. D´eﬁnir θλ
x associ´e `a π(θ) = θλ−1(1 −θ)−λ, 0 ≤λ ≤1. Montrer que θλ
x croˆıt
en λ et en d´eduire que
lim
θ↑θλ
x
Pθ(θ ≤θλ
x) ≥α ≥lim
θ↓θλ
x
Pθ(θ ≤θλ
x).
5.46
*(Hartigan, 1983) Soit x ∼P(λ). Pour 0 < α < 1 et l’a priori π sur λ, on
d´eﬁnit λπ
x par
P π(0 ≤λ ≤λπ
x|x) = α.
a. Montrer que, si π(λ) = 1/λ, Pλ(λ ≤λπ
x) ≤α pour tout λ.
b. Montrer que, si π(λ) = 1, Pλ(λ ≤λπ
x) ≥α pour tout λ. (Indication : Utiliser
la relation suivante :
∞
X
x=x0
e−λ λx
x! =
Z ∞
0
ux0−1
(x0 −1)!e−udu.
«
5.47 Un probl`eme c´el`ebre en Statistique classique est celui de Behrens-Fisher. Il
d´ecoule de la simple situation de deux populations normales de moyennes et
variances inconnues ; il n’existe pas en eﬀet de test UPP ou UPPS pour comparer
les moyennes dans ce cas. Soient x1, . . . , xn un ´echantillon tir´e de N (θ, σ2) et
y1, . . . , ym un ´echantillon de N (μ, τ 2), o`u θ, μ, τ, σ sont inconnus.
a. *Montrer qu’il n’existe pas de test UPPS pour l’hypoth`ese H0 : θ = μ.
(Indication : Conditionner en s2
x et s2
y, d´eﬁnis ci-dessous, aﬁn de montrer que
les proc´edures UPPS varient avec s2
x et s2
y.)

5.6 Exercices
295
b. Expliquer pourquoi un test raisonnable devrait d´ependre de la quantit´e pi-
votale
T = (θ −μ) −(¯x −¯y)
p
s2x/n + s2y/m
avec ¯x = P
i xi/n, ¯y = P
j yj/m, s2
x = P
i(xi −¯x)2/n −1 et s2
y = P
j(yj −
¯y)2/m −1.
c. Montrer que la distribution de T d´epend de σ/τ mˆeme quand θ = μ et qu’il
ne s’agit pas d’une loi de Student.
d. Donner la loi a posteriori de T pour π(θ, μ, σ, τ) = 1/σ2τ 2 et montrer qu’elle
ne d´epend que de (sx/√n)(sy/√m). [Note : Voir Robinson, 1982, pour une
revue d´etaill´ee des diﬀ´erents points reli´es `a ce probl`eme.]
Section 5.5.2
5.48 (Casella et Berger, 2001) Soient x ∼N (μ, 1) et
Ca(x) = {μ; min(0, x −a) ≤μ ≤max(0, x + a)}.
a. On pose a = 1.645. Montrer que Ca est un intervalle de conﬁance `a 95% tel
que
P0(0 ∈Ca(x)) = 1.
b. Pour π(μ) = 1 et a = 1.645, montrer que Ca est aussi une r´egion 0.1-cr´edible
et que
P π(μ ∈Ca(x)|x) = 0.90
si |x| ≤1.645 et
lim
|x|→+∞P π(μ ∈Ca(x)|x) = 1.
5.49 Soient x ∼f(x|θ) avec θ ∈R et π loi a priori sur θ. Si on d´eﬁnit l’ensemble
α-cr´edible (−∞, θx) par P π(θ ≥θx|x) = α, montrer que cet intervalle unilat´eral
ne peut pas ˆetre de niveau α au sens fr´equentiste. (Indication : Montrer que
P(θ ≥θx|θ ≤θ0) > α pour une certaine valeur θ0.)
5.50
*(Fieller, 1954)
Dans un cadre de calibration (voir l’Exercice 4.48), les in-
tervalles de conﬁance doivent avoir une longueur inﬁnie pour maintenir un
niveau de conﬁance ﬁx´e, comme le montrent Gleser et Hwang (1987). Soit
(x1, y1), . . . , (xn, yn) un ´echantillon tir´e de N2(μ, Σ). Le param`etre d’int´erˆet
est θ, le rapport des esp´erances μx/μy.
a. D´eﬁnir ¯zθ = ¯y −θ¯x. Montrer que
¯zθ ∼N
„
0, 1
n(σ2
y −2θσxy + θ2σ2
x)
«
et que
ˆvθ =
1
n −1(s2
y −2θsxy + θ2sx)
est un estimateur sans biais de vθ, la variance de ¯zθ, o`u ¯x, ¯y, s2
x, sxy et s2
y
sont les moments empiriques usuels et
Σ =
„ σ2
x σxy
σxy σ2
y
«
.

296
5 Tests et r´egions de conﬁance
b. Montrer que ¯zθ et ˆvθ sont ind´ependants et que (n −1)ˆvθ/vθ ∼χ2
n−1. En
d´eduire que {θ; ¯zθ/ˆvθ ≤t2
n−1,α/2} d´eﬁnit un ensemble de conﬁance `a (1 −α).
c. Montrer que cet ensemble de conﬁance d´epend d’une parabole en θ et peut
ˆetre un intervalle, le compl´ement d’un intervalle ou l’ensemble des nombres
r´eels.
Section 5.5.3
5.51
*La domination de l’estimateur usuel en tant que centre d’une r´egion de
conﬁance ne d´ecoule pas forc´ement de la domination correspondante pour le
coˆut quadratique. Montrer que, dans le cas gaussien, si
δJS
a (x) =
„
1 −
a
||x||2
«
x,
la r´egion de conﬁance recentr´ee
CJS
a (x) = {θ; ||θ −δJS
a (x)||2 ≤cα},
ne domine pas la r´egion de conﬁance usuelle, mˆeme si δJS
a
domine δ0 lorsque
a ≤2(p −2). (Indication : Consid´erer θ = 0.)
5.52 (Casella et al., 1993a)
Montrer que la fonction de coˆut rationnel donn´ee en
Section 5.5,
L(θ, C) =
vol(C)
k + vol(C) −IC(θ),
ne m`ene pas au paradoxe de Berger dans le cas gaussien.
5.53
*(Casella et al., 1993a) Soit une fonction de coˆut g´en´erale de la forme
L(θ, C) = S(vol(C)) −IC(θ),
o`u S est croissante et 0 ≤S(t) ≤1.
a. Montrer que les estimateurs de Bayes sont des r´egions HPD.
b. Montrer que, si x ∼Np(θ, Ip) et θ ∼Np(μ, τ 2Ip), les ensembles cr´edibles
bay´esiens Cπ ne sont pas vides si S(t) = t/(a + t).
c. D´eterminer le rayon minimal de Cπ lorsque τ varie.
d. Soient ¯x ∼N (θ, σ2/n) et s2 ∼σ2χ2
q. Sous le coˆut rationnel, montrer que
Cπ(¯x, s2) =
j
θ; |θ −¯x| ≤t∗s
√n
ﬀ
,
o`u t∗est la solution de
min
t
„
2ts/√n
a + 2ts/√n −P(|Tn−1| < t)
«
.
En d´eduire que P(|Tn−1| < t∗(s)|s) ≥1/2.
5.54 (Walley, 1991) Soit la loi double-exponentielle, f(x|θ) = (1/2) exp(−|x −θ|).
a. Montrer que Cx =] −∞, x] est un intervalle de conﬁance `a 50%.
b. Montrer que Pθ(θ ∈Cx|x < 0) < 0.5 pour tout θ.
c. Soit ϕ(x) = (e2x/2)Ix<0. Montrer que
Eθ[Ix<0(ICx(θ) −1/2) + ϕ(x)] ≥0
et en d´eduire que γ(x) = 1/2 n’est pas un estimateur de conﬁance admissible
sous le coˆut quadratique pour Cx.

5.6 Exercices
297
Note 5.7.3
5.55
*(Brown, 1967) Dans le cadre de l’Exemple 5.55, montrer que
P
`√n|¯x −θ| ≤ks|s ≤1
´
≤α > P
`√n|¯x −θ| ≤ks|s > 1
´
et calculer un sous-ensemble positivement pertinent. (Indication : Montrer que
P
`√n|¯x −θ| ≤ks|s
´
est croissant en s.)
5.56 (Walley, 1991) Soit un ´echantillon x1, . . . , xn tir´e de U[θ,θ+1].
a. Montrer que les intervalles de conﬁance unilat´eraux uniform´ement plus pr´ecis
sont de la forme Cx = [(x(1) + 1 −K) ∧(x(n) −1), x(1) + 1] et v´eriﬁer que le
niveau de conﬁance est γ = 1 −(1 −K/2)n.
b. Pour n = 1 et γ = 1/2, montrer que Cx = [x, x + 1]. Consid´erer une fonction
born´ee strictement d´ecroissante f et poser ϕ(x) = (f(x) −f(x + 1)) ∧(f(x −
1) −f(x)). V´eriﬁer que
Eθ[f(ICx(θ) −0.5)] = 0.25
Z θ+1
θ
(f(x −1) −f(x)) dx
et
Eθ[ϕ(x)] ≤1
8
Z θ+1
θ
(f(x −1) −f(x)) dx.
c. En d´eduire que
Eθ[f(ICx(θ) −0.5) −ϕ(x)] ≥0
pour tout θ et que γ = 1/2 n’est pas un estimateur admissible.
d. On d´eﬁnit, pour n ≥2,
B = {(x1, . . . , xn); x(n) −x(1) ≥2 −K}.
Montrer que
Pθ(θ ∈C(x1, . . . , xn)|(x1, . . . , xn) ∈B) = 1
et conclure que B est un sous-ensemble pertinent.
Note 5.7.4
5.57 (Berger et al., 1998)
Pour l’estimateur de conﬁance γ(x) donn´e en (5.26),
montrer que
γ(x) =
s
1 + s
si
s < r,
γ(x) =
1
1 + s
si
s > a .
5.58 Montrer que, dans le cadre de l’Exemple 5.59, Ψ(1) > 1 et donner le facteur
de Bayes en faveur de H0.
5.59 (Lindley, 1990) Consid´erant une troisi`eme d´ecision −1 dans un probl`eme de
test, soit l’extension suivante de la fonction de coˆut 0 −1 :
L(θ, ϕ) =
(
ℓi
si ϕ = 1 −i et Hi est vraie,
mi
si ϕ = −1 et Hi est vraie.

298
5 Tests et r´egions de conﬁance
Calculer les coˆuts a posteriori et montrer que ϕ = −1 si
m1ϱ
ℓ0 −m0 < B10(x) < (ℓ1 −m1)ϱ
m0
,
o`u ϱ est le rapport des chances a priori, soit π1/π0.
5.60 (Lindley, 1990)
Montrer que la statistique S(x) donn´ee en (5.27) n’est pas
libre, sauf lorsque
τ(t) + ϱ = 1 + ϱ
t ,
t > c ,
o`u c est d´eﬁni par F0(c) = 1−ϱF1(c) et τ(t) est donn´e par F0(t) = 1−ϱF1(τ(t)).
Montrer que cette propri´et´e est v´eriﬁ´ee lorsque B10(x) a la mˆeme loi sous m1
que B01(x) sous m0. [Note : Voir Berger et al., 1994, p. 1798.]
5.7 Notes
5.7.1 P-values et d´ecisions bay´esiennes
Une critique radicale de la comparaison de la Section 5.3.5 est qu’elle n’a en
fait aucun sens : ces deux types de r´eponses sont diﬀ´erentes conceptuellement
et des p-values ne sont pas des probabilit´es. La r´eponse `a cette critique est que,
au-del`a du fait qu’elles sont utilis´ees comme des probabilit´es en pratique, les
p-values, d’un point de vue d´ecisionnel, tentent de r´epondre au mˆeme probl`eme
inf´erentiel que les probabilit´es a posteriori. Il est donc sens´e de les comparer.
Consid´erons la fonction de coˆut a0 −a1, comme dans (5.1). Le test minimax
UPPS est alors
ϕ(x) =
(
1
si p(x) >
a1
a0+a1 ,
0
sinon.
En fait, lorsque les fonctions de puissance sont continues et les hypoth`eses sont
contigu¨es (voir Lehmann, 1986, Chapitre 4), un test UPPS v´eriﬁe
sup
Θ0
Pθ(ϕ(x) = 0) = α = inf
Θ1 Pθ(ϕ(x) = 0) = 1 −sup
Θ1
Pθ(ϕ(x) = 1).
De plus, lorsque ϕ est minimax sous cette fonction de coˆut, il satisfait
sup
Θ0
R(θ, ϕ) = a0 sup
Θ0
Pθ(ϕ(x) = 0)
= sup
Θ1
R(θ, ϕ) = a1 sup
Θ1
Pθ(ϕ(x) = 1).
Donc, sous certaines conditions de r´egularit´e, satisfaites, par exemple, par des
familles exponentielles, ϕ est tel que
sup
Θ0
Pθ(ϕ = 0) =
a1
a1 + a0 .
Il d´ecoule alors de la Proposition 5.2 qu’il est l´egitime de comparer la p-value
p(x) `a des probabilit´es a posteriori, puisque la proc´edure de d´ecision bay´esienne
est donn´ee par
γπ(x) =
(
1
si P π(θ ∈Θ0|x) >
a0
a0+a1 ,
0
sinon

5.7 Notes
299
et les deux approches comparent une ´evaluation continue (p-value ou probabilit´e
a posteriori) `a la mˆeme borne.
5.7.2 Probabilit´es a priori in´egales
Une autre critique `a l’´egard de l’´evaluation des bornes de la Section 5.3.5,
avanc´ee, par exemple, par Casella et Berger (1987), est que cette borne inf´erieure
n’est pas calcul´ee sur l’ensemble de toutes les lois a priori, puisque n’est
consid´er´ee que la probabilit´e a priori ϱ0 = 1/2. Bien entendu, si ϱ0 peut aussi
ˆetre modiﬁ´e, il est toujours possible de trouver une r´eponse bay´esienne plus pe-
tite que la p-value, puisque la borne inf´erieure sur toutes les r´eponses bay´esiennes
est alors 0 pour tout x (ce qui correspond au cas ϱ0 = 0). `A l’inverse, pour une
valeur ﬁx´ee de ϱ0 ̸= 0, il y a toujours des valeurs de x pour lesquelles la borne
inf´erieure sur les probabilit´es a posteriori est plus grande que la p-value.
Une version plus sophistiqu´ee de cette critique est de consid´erer que le poids
ϱ0 = 1/2 n’est pas n´ecessairement la probabilit´e la plus objective et qu’elle
devrait ˆetre d´etermin´ee en fonction de l’a priori π choisi. En fait, comme nous
l’avons mentionn´e ci-dessus, les lois a priori de la forme π(θ) = ϱ0Iθ0(θ) + (1 −
ϱ0)π1(θ) sont assez artiﬁcielles. Mˆeme si de telles lois a priori sont n´ecessaires
`a la r´esolution du probl`eme de test, il est plus naturel de penser π comme une
modiﬁcation de l’a priori original π1, `a la lumi`ere de ce probl`eme. Le probl`eme
inf´erentiel, c’est-`a-dire le fait qu’on s’int´eresse particuli`erement `a θ0, contient
une certaine information r´esiduelle suﬃsante pour justiﬁer une modiﬁcation de
la loi a priori (sinon, la question du test devrait elle-mˆeme ˆetre modiﬁ´ee pour
devenir compatible avec l’information a priori). Il est donc sens´e d’imposer que
le poids ϱ0 d´epende de π1. (Ce point sera repris dans le Chapitre 7 sur le choix
de mod`eles, pour le cas des mod`eles imbriqu´es
: le mod`ele le plus g´en´eral,
c’est-`a-dire celui qui contient tous les autres, devrait ˆetre plus probable que les
autres.)
Exemple 5.56. (Suite de l’Exemple 5.34)
Puisqu’il s’agit de tester H0 :
θ = 0, la probabilit´e a priori de H0 est nulle pour toute densit´e a priori continue
π1. Cependant, il est raisonnable d’imposer que H0 ait une probabilit´e a priori
plus ´elev´ee si π1 est N (0, 1) que si π1 est N (0, 10), puisque tout voisinage de
0 est moins probable sous la deuxi`eme loi a priori. Voil`a pourquoi le paradoxe
de Jeﬀreys-Lindley est bien un “paradoxe” : l’accroissement des probabilit´es du
Tableau 5.2 au Tableau 5.3 semble contre-intuitive.
∥
Malheureusement, une d´etermination du poids ϱ0 comme fonction de π1 prˆete
`a controverse et nous nous contentons de mentionner bri`evement une solution
propos´ee dans Robert et Caron (1996) (voir Spiegelhalter et Smith, 1980, pour
une autre approche fond´ee sur des observations virtuelles les plus favorables).
L’id´ee sous-jacente est que le poids ϱ0 devrait satisfaire
(1 −ϱ0)π1(θ0) = ϱ0,
aﬁn que θ0 soit pond´er´e de la mˆeme fa¸con sous les deux hypoth`eses. Bien en-
tendu, cela revient `a comparer un poids sous une masse de Dirac en 0, ϱ0, `a
un poids instantan´e relativement `a la mesure de Lebesgue, (1 −ϱ0)π1(θ0), et

300
5 Tests et r´egions de conﬁance
la comparaison n’est pas justiﬁ´ee math´ematiquement parlant (puisque la valeur
que prend la densit´e π1 en un point tel que θ0 est arbitraire). De plus, l’´equation
ci-dessus n’admet pas toujours de solution.
Exemple 5.57. (Suite de l’Exemple 5.25) Lorsque π1(θ) est une loi a priori
gaussienne N (0, n), l’´egalit´e ci-dessus donne comme expression du poids
ϱ0 =
π1(0)
1 + π1(0) =
1
1 +
√
2πn
,
et la probabilit´e a posteriori de H0 est alors
„
1 + 1 −ϱ0
ϱ0
m1(x)
ϕ(x)
«−1
=
„
1 +
r
2π
n
n + 1ex2/2−x2/2(n+1)
«−1
=
 
1 +
r
2πn
n + 1e
n
2(n+1) x2
!−1
.
Notons que cette approche ´evite le paradoxe de Jeﬀreys-Lindley, puisque la
probabilit´e limite (pour n tendant vers +∞) est
“
1 +
√
2πex2/2”−1
.
Cette valeur se trouve aussi ˆetre la probabilit´e a posteriori associ´ee `a la densit´e
a priori de Lebesgue, π(θ) = 1.
∥
5.7.3 ´Evaluation conditionnelle des r´egions de conﬁance
Une ´evaluation critique des r´egions de conﬁance de Neyman-Pearson (et plus
g´en´eralement des proc´edures fr´equentistes) d´erive de l’analyse conditionnelle
de Kiefer (1977) et Robinson (1979). Lehmann (1986, Chapitre 10) donne une
description de cette approche (voir aussi Buehler, 1959, Pierce, 1973, Casella,
1987, 1992, Maatta et Casella, 1990, et Goutis et Casella, 1991, 1992). Ces
travaux d´emontrent que des proc´edures classiques de construction de r´egions de
conﬁance sont souvent sous-optimales lorsqu’elles sont consid´er´ees d’un point
de vue conditionnel.
D´eﬁnition 5.58. Soit Cx, une r´egion de conﬁance de niveau α. Un ensemble
A ⊂X est dit sous-ensemble pertinent biais´e n´egativement pour la r´egion de
conﬁance Cx s’il existe ϵ > 0 tel que
Pθ(θ ∈Cx|x ∈A) ≤1 −α −ϵ
pour tout θ ∈Θ.
On peut d´eﬁnir de mˆeme des sous-ensembles pertinents biais´es positivement.
Cette notion est g´en´eralis´ee par Robinson (1979) `a celle de proc´edures de paris
pertinentes. L’existence de tels ensembles remet en cause le concept mˆeme de
niveau de conﬁance α, puisque, selon l’ensemble de conditionnement, la pro-
babilit´e de couverture varie et peut mˆeme tomber sous le niveau de conﬁance

5.7 Notes
301
nominal minimal. Bien entendu, cette critique peut s’´etendre aux proc´edures de
test par un argument de dualit´e.
Dans le cadre de l’Exemple 5.54 et pour des tests de Student, Brown (1967)
´etablit l’existence d’ensembles pertinents biais´es positivement de la forme {|x| <
k} ; ce qui implique
Pθ(θ ∈Cx||x| > k) ≤1 −α
(voir aussi l’Exercice 5.55). De tels ph´enom`enes ont men´e Kiefer (1977) `a
sugg´erer de partitionner l’espace d’´echantillonnage X et d’allouer `a chaque
sous-ensemble de la partition un niveau de conﬁance diﬀ´erent (voir aussi Brown,
1978). Suivant l’analyse de Fisher, il a propos´e que ces sous-ensembles soient
index´es par une statistique libre. Par exemple, la statistique libre ad´equate pour
l’Exemple 2.9 est x1 −x2.
Malheureusement, le choix d’une statistique libre modiﬁe dans la plupart des cas
la r´egion de conﬁance obtenue ; Berger et Wolpert (1988) donnent un exemple
o`u des statistiques libres diﬀ´erentes produisent des r´esultats diﬀ´erents, ce qui
est incompatible avec le principe de vraisemblance. Nous consid´erons que, fon-
damentalement, le probl`eme de l’existence d’ensembles biais´es pertinents n’est
pas li´e `a la r´egion de conﬁance Cx mˆeme, mais plutˆot au niveau de conﬁance
α, qu’il faudrait remplacer par un niveau plus adaptatif (ou plus conditionnel)
α(x) (voir la Section 4.2). En fait, l’existence de proc´edures de paris pertinentes
est ´equivalente `a la domination de l’estimateur de conﬁance constant sous le
coˆut quadratique (Robinson, 1979).
5.7.4 Perspective de r´econciliation
Alors que la Section 5.3 a montr´e que les r´eponses fr´equentistes, c’est-`a-dire les
p-values, sont intrins´equement et num´eriquement diﬀ´erentes de leurs ´equivalents
bay´esiens (voir aussi la Note 5.7.1), une modiﬁcation du cadre d´ecisionnel, pro-
pos´ee par Berger et al. (1994), permet une r´econciliation partielle des deux
approches. Bien qu’une telle r´econciliation ne soit pas une caract´eristique im-
portante d’un point de vue bay´esien–une proc´edure se doit avant tout d’ˆetre
optimale pour le probl`eme d´ecisionnel consid´er´e, plutˆot que d’ˆetre stable sur
le long terme–, elle a diﬀ´erents avantages en pratique : premi`erement, les sta-
tisticiens sont plus enclins `a utiliser une proc´edure bay´esienne lorsque celle-ci
jouit aussi de propri´et´es fr´equentistes. Deuxi`emement, ceci ´elimine le probl`eme
de l’interpr´etation d’une p-value comme une probabilit´e a posteriori.
Cette modiﬁcation revient `a ajouter l’option “pas de d´ecision” aux r´eponses
“acceptation” et “rejet” utilis´ees dans les tests classiques. Mˆeme si cette possi-
bilit´e peut sembler absurde d’un point de vue d´ecisionnel, elle est certainement
d´efendable d’un point de vue statistique : il existe bien des cas o`u les donn´ees ne
permettent pas une r´eponse concluante `a l’´egard de H0 et nous font demander
au client plus d’observations ou une information a priori plus pr´ecise. En fait,
une telle approche existait d´ej`a pour les tests s´equentiels, comme les tests du
rapport de vraisemblance s´equentiels de Wald (voir Lehmann, 1986). (Notons
cependant que cette proc´edure de Berger et al., 1994, ne prend pas en compte
les tests r´ep´et´es, ce qui a un impact sur les niveaux de conﬁance ; voir aussi
l’Exemple 1.18.)
Dans le cas de deux hypoth`eses simples,
H0 : x ∼m0(x)
contre
H1 : x ∼m1(x) ,

302
5 Tests et r´egions de conﬁance
o`u m0 et m1 sont des densit´es connues, le facteur de Bayes B10 est ´egal
au rapport de vraisemblance m1(x)/m0(x). Si l’option “pas de d´ecision” est
repr´esent´ee par −1 , le test bay´esien modiﬁ´e de Berger et al. (1994) s’´ecrit
ϕ(x) =
8
>
<
>
:
1
si B10(x) ≤r,
0
si B10(x) ≥a,
−1
si r < B10(x) < a,
(5.26)
avec pour estimateur associ´e
γ(x) =
(
1/(1 + B10(x))
si B10(x) ≥a,
B10(x)/(1 + B10(x))
si B10(x) ≤r.
Notons que γ(x) est la probabilit´e a posteriori de l’hypoth`ese rejet´ee et est donc
optimale sous le coˆut quadratique. (Mais ϕ ne semble pas ˆetre une proc´edure
d´ecisionnelle ; voir l’Exercice 5.59.)
Si on note F0 et F1 les fonctions de r´epartition de B10(x) associ´ees respecti-
vement `a m0 et m1 et si on d´eﬁnit Ψ(b) = F −1
0
(1 −F1(b)), alors Ψ −1(b) =
F −1
1
(1 −F0(b)) et Berger et al. (1994) prennent
(r, a) =
(
(1, Ψ(1))
si Ψ(1) > 1 ,
(Ψ −1(1), 1)
si Ψ(1) < 1 .
Ces auteurs d´emontrent que l’estimateur γ(x) est valide dans une perspective
fr´equentiste conditionnelle : conditionnellement en
S(x) = min{B10(x), Ψ −1(B10(x))} ,
(5.27)
la proc´edure (ϕ, γ) v´eriﬁe
P0(B10(x) ≥a|S(x) = s) = γ(s) ,
P1(B10(x) ≤r|S(x) = s) = γ(s) ,
o`u γ(x) ne d´epend que de s (Exercice 5.57). Notons cependant que S(x) n’est
une statistique libre que dans quelques cas particuliers (Exercice 5.60).
La g´en´eralisation de ce r´esultat aux hypoth`eses composites,
H0 : θ = θ0
contre
H1 : θ ∈Θ1
s’obtient en r´e´ecrivant H1 comme dans la Section 5.3.5, soit,
H1 : x ∼m1(x) =
Z
Θ1
f(x|θ)π1(θ)dθ .
Berger et al. (1997) montrent alors que l’´evaluation fr´equentiste conditionnelle
sous H0 co¨ıncide de nouveau avec l’estimateur bay´esien, mais dans un sens
plus faible, car, si la proc´edure obtenue a de bonnes propri´et´es bay´esiennes, sa
validit´e fr´equentiste est plus contestable (Hinkley, 1997, Louis, 1997).
Exemple 5.59. (Berger et al., 1997)
Pour x1, . . . , xn i.i.d. N (θ, σ2), avec σ
connu, consid´erons le test de H0 : θ = θ0 sous l’a priori conjugu´e θ ∼N (μ, kσ2).
Si z = √n(¯xn −θ0)/σ, on obtient

5.7 Notes
303
m0(z) =
1
√
2π
exp{−z2/2}
et
m1(z) =
1
√
2π
√
1 + kn
exp
(
−(z +
√
knΔ)2
2(1 + kn)
)
,
avec Δ = (θ0 −μ)/
√
kσ. Le facteur de Bayes est alors
B10(x) =
√
1 + kn exp
(
−
kn
2(1 + kn)
»
z −
Δ
√
kn
–2
+ Δ2
2
)
,
Ψ(1) > 1, r = 1 et a = F −1
0
(1 −F1(1)).
∥

6
M´ethodes de calcul bay´esien
“The contraption began to quiver, steam hissing out from two or
three places. The hiss grew to a shriek, and the thing began trem-
bling.”
Robert Jordan, Lord of Chaos.
6.1 Diﬃcult´es de mise en œuvre
`A ce stade du livre, nous devons discuter de l’aspect pratique du paradigme
bay´esien, `a savoir le calcul des estimateurs de Bayes. La simplicit´e ultime de
l’approche bay´esienne est que, pour une fonction de coˆut L et une loi a priori
π donn´ees, l’estimation bay´esienne associ´ee `a une observation x est la d´ecision
(habituellement unique) d minimisant le coˆut a posteriori
L(π, d|x) =

Θ
L(θ, d)π(θ|x) dθ.
(6.1)
Dans la pratique cependant, minimiser (6.1) peut ˆetre rendu diﬃcile pour
deux raisons :
(i) le calcul explicite de la loi a posteriori, π(θ|x), peut ˆetre impossible ; et
(ii) mˆeme si π(θ|x) est connu, cela n’implique pas n´ecessairement que mini-
miser (6.1) soit facile ; en eﬀet, lorsque l’int´egration analytique est im-
possible, la minimisation num´erique n´ecessite parfois un temps de calcul
consid´erable, en particulier lorsque Θ et D sont de grandes dimensions.

306
6 M´ethodes de calcul bay´esien
Le point (i) peut sembler ˆetre une diﬃcult´e mineure et formelle, puisque mi-
nimiser (6.1) revient en r´ealit´e `a minimiser

Θ
L(θ, d)π(θ)f(x|θ) dθ,
qui ne requiert pas une ´evaluation de π(θ|x). Cependant, nous avons vu dans
les Chapitres 2 et 4 que les coˆuts classiques, comme le coˆut quadratique,
m`enent directement `a des estimateurs s’exprimant en fonction de la loi a
posteriori, notamment la moyenne a posteriori
δπ(x) =

Θ
θ π(θ|x) dθ
=

Θ θ π(θ)f(x|θ) dθ

Θ π(θ)f(x|θ) dθ ,
pour le coˆut quadratique ; ils n´ecessitent donc un calcul direct des moments.
Une remarque similaire s’applique `a l’obtention d’autres quantit´es a posteriori
d’int´erˆet, comme les quantiles a posteriori, les facteurs de Bayes ou les r´egions
de conﬁance.
Une r´eponse simpliste `a ces diﬃcult´es de calcul est de n’utiliser que des
mod`eles d’´echantillonnage, des lois a priori et des coˆuts qui m`enent `a des
solutions explicites pour la minimisation de (6.1). Cette approche restrictive
est techniquement justiﬁ´ee lorsque les outils de calcul d´ecrits ci-dessous ne sont
pas applicables, mais elle est inacceptable en termes subjectifs, car la fonction
de coˆut et la loi a priori devraient ˆetre construites en fonction du probl`eme de
d´ecision et non pas parce qu’elles fournissent des r´eponses analytiques, comme
nous l’avons soulign´e dans le Chapitre 347.
Ce chapitre a donc pour but d’´eviter le recours syst´ematique `a des lois
a priori et `a des coˆuts simples, en fournissant aux lecteurs une s´election
repr´esentative des m´ethodes d’approximation les plus r´ecentes et les plus so-
phistiqu´ees pouvant ˆetre utilis´ees lorsque la loi a posteriori ou un estimateur
donn´e n’admettent pas d’expression analytique. Ce chapitre n’est qu’une in-
troduction `a ces m´ethodes ; les lecteurs sont renvoy´es `a Robert et Casella
(2004) pour un traitement plus approfondi.
Bien que les probl`emes d’estimation comme la minimisation du coˆut ou
le calcul d’un estimateur MAP puissent aussi ˆetre r´esolus par des techniques
de simulation (voir Geyer et Thompson, 1992, Geyer, 1996, Robert et Ca-
sella, 1999, Chapitre 5, ou Doucet et al., 2002), nous nous concentrons dans
ce chapitre sur les approximations de π(θ|x) et des int´egrales correspon-
dantes, parce qu’il s’agit de la pierre angulaire des diﬃcult´es de calcul en
47Les illustrations classiques ont recours `a de tels cas simples, pour permettre une
pr´esentation plus claire et concise des points trait´es, et ce livre a beaucoup fait appel
aux familles exponentielles, aux lois a priori conjugu´ees et aux coˆuts quadratiques.
N´eanmoins, une approche plus adaptative, reposant par exemple sur des m´elanges
des lois a priori conjugu´ees, devrait ˆetre adopt´ee en pratique.

6.1 Diﬃcult´es de mise en œuvre
307
inf´erence bay´esienne. De plus, si π(θ|x) peut ˆetre approch´ee correctement, il
est g´en´eralement possible de construire une approximation de L(π, d|x) pour
une d´ecision arbitraire d et d’utiliser alors une m´ethode de minimisation clas-
sique.
Nous pr´esentons maintenant une s´erie d’exemples utilis´es tout au long de
ce chapitre pour illustrer les diﬀ´erentes m´ethodes de calcul.
Exemple 6.1. Soit x1, . . . , xn un ´echantillon de C (θ, 1), une loi de Cauchy
de param`etre de position θ, avec θ ∼N (μ, σ2), o`u μ et σ2 sont des hyperpa-
ram`etres connus. La loi a posteriori de θ est alors
π(θ|x1, . . . , xn) ∝e−(θ−μ)2/2σ2
n

i=1
[1 + (xi −θ)2]−1,
qui ne peut pas ˆetre int´egr´ee de fa¸con analytique. Lorsque δπ est la moyenne
a posteriori,
δπ(x1, . . . , xn) =
 +∞
−∞θe−(θ−μ)2/2σ2 /n
i=1[1 + (xi −θ)2]−1dθ
 +∞
−∞e−(θ−μ)2/2σ2 /n
i=1[1 + (xi −θ)2]−1dθ
,
son calcul n´ecessite deux int´egrations num´eriques, une pour le num´erateur
et une autre pour le d´enominateur. Le calcul de la variance requiert une
int´egration suppl´ementaire. De plus, la structure typiquement multimodale de
cette loi (voir Exercice 1.27) fait que l’application de techniques d’int´egration
num´erique standard peut n´ecessiter certains r´eglages d´elicats.
∥
Comme on l’a d´ej`a vu auparavant, la diﬃcult´e de calcul peut provenir de
la fonction de coˆut choisie, mˆeme lorsque la loi a priori est conjugu´ee.
Exemple 6.2. Soient x|θ ∼Np(θ, σ2Ip) et θ|μ, τ ∼Np(μ, τ2Ip), d’hyperpa-
ram`etres connus μ et τ. La loi a posteriori de θ admet alors une expression
simple, puisque
θ|x ∼Np
σ2μ + τ 2x
σ2 + τ 2 ,
σ2τ 2
σ2 + τ 2 Ip

.
Lorsque ||θ||2 est le param`etre d’int´erˆet, le coˆut quadratique ramen´e `a l’´echelle
de l’estimateur usuel est
L(θ, δ) = (δ −||θ||2)2
2||θ||2 + p ,
comme dans Saxena et Alam (1982). Il conduit `a l’estimateur de Bayes sui-
vant :
δπ(x) = Eπ[||θ||2/(2||θ||2 + p)|x]
Eπ[1/(2||θ||2 + p)|x]
.

308
6 M´ethodes de calcul bay´esien
Bien que (σ−2 + τ −2)||θ||2 soit distribu´e a posteriori comme une variable
al´eatoire χ2
p(λ) , avec
λ = ||σ2μ + τ 2x||2
σ2τ 2(σ2 + τ 2),
δπ n’admet pas d’expression analytique et une approximation num´erique
est de nouveau n´ecessaire. Notons que, dans ce cas, l’int´egration num´erique
est plus compliqu´ee que pour l’Exemple 6.1, car la densit´e de χ2
p(λ) (voir
l’Appendice A) fait intervenir une fonction de Bessel modiﬁ´ee, I(p−2)/2(t), qui
doit ˆetre approch´ee par une suite de densit´es du khi deux (centr´ees) pond´er´ees
ou par une approximation en fractions continues (voir l’Exercice 4.36). Une
approche alternative est d’int´egrer plutˆot en θ, mais cela n’est possible que
pour de petites valeurs de p.
∥
Les Chapitres 7 et 10 fourniront ´egalement des exemples o`u l’approxima-
tion d’estimateurs de Bayes est n´ecessaire. En eﬀet, la plupart des estimateurs
de Bayes hi´erarchiques ne peuvent pas ˆetre calcul´es de fa¸con analytique ; c’est
le cas notamment pour des observations normales (voir le Lemme 10.17) et
les mod`eles graphiques (voir la Note 10.7.1). De plus, une approximation
num´erique de ces estimateurs peut donner lieu `a des complications, en parti-
culier pour des dimensions plus grandes.
Exemple 6.3. Le recours `a une variable auxiliaire dans un mod`ele de Student
multivari´e r´eduit le nombre d’int´egrations `a un, comme l’a remarqu´e Dickey
(1968). Rappelons que, si
x ∼Np(θ, σ2Ip),
θ ∼Tp(ν, μ, τ2Ip),
on peut ´ecrire
θ|ξ, x ∼Np

ξ(x),
τ 2σ2
σ2ξ + τ 2 Ip

,
π(ξ|x) ∝
ξ(p+ν)/2−1
(ξσ2 + τ 2)p/2 exp
−1
2
||x −μ||2ξ
τ 2 + ξσ2 + ξ2ν

,
avec
ξ(x) = ξσ2μ + τ 2x
ξσ2 + τ 2
(voir l’Exemple 10.3). Soit la g´en´eralisation suivante :
x|θ, Λ ∼Np(θ, Λ),
lorsque θ et Λ = diag(σ2
1, . . . , σ2
p) sont inconnus et de lois a priori (1 ≤i ≤p)
θi|σi ∼N

μi, σ2
i
ni

,
σ2
i ∼I G (νi/2, s2
i /2) ,

6.1 Diﬃcult´es de mise en œuvre
309
o`u les ni, si et νi sont des hyperparam`etres connus. Dans ce cas (1 ≤i ≤p),
θi|xi ∼T

νi + 1, xi + niμi
ni + 1 ,
(νi + 1)−1(ni + 1)−1

s2
i +
ni
n1 + 1(xi −μi)2

,
et le recours `a une variable auxiliaire ξi pour chaque composante θi ne modiﬁe
pas la complexit´e du probl`eme d’estimation, puisque le nombre d’int´egrales `a
calculer reste constant.
∥
Les deux exemples ci-dessous sont paradoxaux, au sens o`u une expression
explicite de l’estimateur de Bayes est disponible, mais ne peut pas ˆetre utilis´ee
de fa¸con simple dans la pratique, soit parce qu’elle entraˆıne une instabilit´e
num´erique et donc un manque de ﬁabilit´e du r´esultat (Exemple 6.4), soit
parce que le calcul de l’estimateur de Bayes r´esultant est impossible, car il ne
peut pas ˆetre eﬀectu´e en un temps raisonnable pour des tailles d’´echantillon
r´ealistes (Exemple 6.5).
Exemple 6.4. Dans le cadre des mod`eles de capture-recapture, nous consi-
d´erons le mod`ele temporel (voir la Section 4.3.3) et les lois conjugu´ees
xi|N, pi ∼B(N, pi),
π(N) = 1/N,
pi ∼Be(α, β)
(1 ≤i ≤n).
Si x+ est le nombre d’individus diﬀ´erents captur´es au moins une fois parmi
n captures, la loi a posteriori de N et p = (p1, . . . , pn) est, pour x =
(x1, . . . , xn, x+),
π(N, p|x) ∝(N −1)!
(N −x+)!
n

i=1
pα+xi−1
i
(1 −pi)β+N−xi−1
et la loi marginale de N se calcule comme
π(N|x) ∝(N −1)!
(N −x+)!
n

i=1
B(α + xi, β + N −xi)
∝(N −1)!
(N −x+)!
n

i=1
Γ(β + N −xi)
Γ(α + β + N) .
Par cons´equent, la loi a posteriori π(N|x) peut s’´ecrire de fa¸con “explicite”,
(N−1)!
(N−x+)!
/n
i=1 Γ(β + N −xi)/Γ(α + β + N)
+∞
M=x+
(M−1)!
(M−x+)!
/n
i=1 Γ(β + M −xi)/Γ(α + β + M)
.
(6.2)

310
6 M´ethodes de calcul bay´esien
En r´ealit´e, de par les rapports pr´esents au num´erateur et au d´enominateur,
la formule (6.2) ne n´ecessite aucune ´evaluation de la fonction gamma : le re-
cours `a la formule r´ecursive Γ(x + 1) = xΓ(x) suﬃt. N´eanmoins, si n est
grand, c’est-`a-dire si plusieurs captures ont ´et´e entreprises, et si, de plus, les
tailles de capture r´esultantes xi sont tr`es diﬀ´erentes, le calcul de la loi a pos-
teriori (6.2) sera assez diﬃcile. Les quantit´es (6.2) peuvent beaucoup ﬂuctuer
et la r`egle d’arrˆet pour le calcul de la s´erie inﬁnie en (6.2) doit ˆetre con¸cue
en cons´equence, de crainte qu’on ignore les termes signiﬁcatifs correspondant
aux grandes valeurs de M. De plus, le calcul de la suite (6.2) par la formule
de r´ecurrence
π(N + 1|x)
π(N|x)
=
N
N + 1 −x+
n

i=1
β + N −xi
α + β + N ,
bien que possible, peut ˆetre impr´ecis, car l’erreur d’approximation augmente
`a chaque ´etape, en particulier lorsque les xi sont tr`es diﬀ´erents.
La mˆeme critique s’applique au calcul de la moyenne a posteriori
δπ(x) =
+∞
N=x+
N!
(N−x+)!
/n
i=1 Γ(β + N −xi)/Γ(α + β + N)
+∞
M=x+
(M−1)!
(M−x+)!
/n
i=1 Γ(β + M −xi)/Γ(α + β + M)
.
(6.3)
Par cons´equent, mˆeme si ces mod`eles discrets paraissent simples d’un point
de vue analytique, les formules explicites ci-dessus ne peuvent ˆetre utilis´ees
que pour les exemples les plus triviaux. Lorsque les nombres d’observations et
de captures sont importants, il devient n´ecessaire de recourir `a des m´ethodes
num´eriques alternatives. En outre, l’attrait de telles formules disparaˆıt dans
un cadre hi´erarchique, car elles ne peuvent pas ˆetre utilis´ees lorsque le couple
(α, β) suit une loi a priori (voir George et Robert, 1992).
∥
Exemple 6.5. Soit un ´echantillon x1, . . . , xn de
f(x|θ) = pϕ(x; μ1, σ1) + (1 −p)ϕ(x; μ2, σ2),
(6.4)
c’est-`a-dire un m´elange de deux lois normales de moyennes μi, variances σ2
i
(i = 1, 2) et poids p (0 < p < 1). Une motivation radiologique de ce mod`ele
a ´et´e donn´ee dans l’Exemple 1.6. Une ´etude sur un premier ensemble de ra-
diographies des poumons a montr´e que les images ´etaient distribu´ees avec des
param`etres qui varient selon la Table 6.1.
Comme premi`ere approximation et ´etant donn´e l’information fournie par
la Table 6.1, une mod´elisation a priori possible consiste `a utiliser des lois a
priori “conjugu´ees” pour θ = (μ1, σ2
1, p, μ2, σ2
2),
μi|σi ∼N (ξi, σ2
i /ni),
σ2
i ∼I G (νi/2, s2
i /2),
p ∼Be(α, β),

6.1 Diﬃcult´es de mise en œuvre
311
Tab. 6.1.
Param`etres statistiques pour un mod`ele de radiographie des poumons.
(Source : Plessis, 1989.)
μ1
μ2
σ1
σ2
p
Moyenne 105.33 188.9 32.3 18.2 0.5
´Ecart type 11.18
7.38 5.62 4.5 0.08
et `a calculer la valeur des hyperparam`etres ξi, ni, νi, si et (α, β) `a partir
de la Table 6.1 par la m´ethode des moments48. En eﬀet, ces lois ne sont pas
conjugu´ees au sens de la D´eﬁnition 3.7, mais la loi a posteriori correspondante
est
π(θ|x1, . . . , xn) ∝
n

j=1
{pϕ(xj; μ1, σ1) + (1 −p)ϕ(xj; μ2, σ2)} π(θ) .
(6.5)
On peut r´e´ecrire (6.5) simplement en repr´esentant cette distribution comme
une somme pond´er´ee (c’est-`a-dire un m´elange) de lois conjugu´ees,
π(θ|x1, . . . , xn) =
n

ℓ=0

(kt)
ω(kt)π(θ|(kt)),
(6.6)
o`u ℓrepr´esente le nombre d’observations attribu´ees `a la premi`ere compo-
sante et o`u la seconde somme prend en compte toutes les permutations (kt)
de {1, 2, . . ., n} correspondant `a une partition diﬀ´erente de {x1, . . . , xn} en
{xk1, . . . , xkℓ} et {xkℓ+1, . . . , xkn}, caract´erisant ainsi les ℓobservations at-
tribu´ees `a la premi`ere composante. Le poids a posteriori d’une partition (kt)
est (voir ci-dessous pour la notation)
ω(kt) ∝
Γ(α + ℓ) Γ(β + n −ℓ) Γ([ν1 + ℓ]/2)

s2
1 + ˆs1(kt) +
n1ℓ
n1+ℓ(ξ1 −¯x1(kt))2
(ν1+ℓ)/2
×
Γ([ν2 + n −ℓ]/2)
67
(n1 + ℓ)(n2 + n −ℓ)

s2
2 + ˆs2(kt) + n2(n−ℓ)
n2+n−ℓ(ξ2 −¯x2(kt))2
(ν2+n−ℓ)/2 ,
normalis´e de telle mani`ere que
n

ℓ=0

(kt)
ω(kt) = 1.
48Notons que cet a priori diﬀ`ere d’une mod´elisation bay´esienne empirique (Cha-
pitre 10). En eﬀet, bien que l’a priori r´esultant ne soit qu’une approximation et que
l’hyperparam`etre soit estim´e par des moyennes classiques, cette loi est fond´ee sur
des observations pr´ec´edentes, ce qui peut ˆetre consid´er´e comme une information a
priori, et non sur l’´echantillon observ´e pour lequel le param`etre θ est inconnu.

312
6 M´ethodes de calcul bay´esien
Pour une permutation donn´ee (kt), la loi a posteriori conditionnelle est
π(θ|(kt)) = N

ξ1(kt),
σ2
1
n1 + ℓ

× I G ((ν1 + ℓ)/2, s1(kt)/2)
×N

ξ2(kt),
σ2
2
n2 + n −ℓ

× I G ((ν2 + n −ℓ)/2, s2(kt)/2)
×Be(α + ℓ, β + n −ℓ) ,
o`u
¯x1(kt) = 1
ℓ
ℓ
t=1 xkt,
ˆs1(kt) = ℓ
t=1(xkt −¯x1(kt))2,
¯x2(kt) =
1
n−ℓ
n
t=ℓ+1 xkt,
ˆs2(kt) = n
t=ℓ+1(xkt −¯x2(kt))2
sont les statistiques habituelles pour les deux sous-´echantillons induits par la
permutation et
ξ1(kt) = n1ξ1 + ℓ¯x1(kt)
n1 + ℓ
,
ξ2(kt) = n2ξ2 + (n −ℓ)¯x2(kt)
n2 + n −ℓ
,
s1(kt) = s2
1 + ˆs2
1(kt) +
n1ℓ
n1 + ℓ(ξ1 −¯x1(kt))2,
s2(kt) = s2
2 + ˆs2
2(kt) + n2(n −ℓ)
n2 + n −ℓ(ξ2 −¯x2(kt))2,
sont les mises `a jour a posteriori des hyperparam`etres, conditionnellement `a
la partition (kt).
Cette d´ecomposition est int´eressante, car elle montre que, malgr´e une for-
mule apparemment inextricable, l’analyse bay´esienne de la loi de m´elange
(6.4) est assez logique. En eﬀet, la loi a posteriori prend en compte toute
partition possible de l’´echantillon, en sp´eciﬁant de quelle composante chaque
observation est originaire via la permutation correspondante (kt). Il attribue
alors un poids ω(kt) `a la partition, qui peut ˆetre interpr´et´e comme la probabi-
lit´e a posteriori de la partition choisie, et op`ere comme si chaque observation
provenait en r´ealit´e de la composante choisie, les lois a posteriori (condition-
nelles) π(θ|(kt)) ´etant identiques aux lois a posteriori habituelles pour (μ1, σ1)
et (μ2, σ2) r´esultant de l’observation s´epar´ee de xk1, . . . , xkℓet xkℓ+1, . . . , xkn.
Des remarques similaires s’appliquent `a la loi a posteriori de p, car, condition-
nellement `a la partition (kt), cette loi correspond `a la loi a posteriori associ´ee
`a l’observation d’une variable al´eatoire binomiale B(n, p), qui est le nombre
d’observations attribu´ees `a la premi`ere composante.
La d´ecomposition (6.6) fournit l’estimateur de Bayes suivant de θ :
δπ(x1, . . . , xn) =
n

ℓ=0

(kt)
ω(kt)Eπ[θ|x, (kt)],
la somme pond´er´ee des estimateurs de Bayes pour chaque partition. Par
exemple, l’estimateur de Bayes de μ1 est

6.2 M´ethodes classiques d’approximation
313
μπ
1(x1, . . . , xn) =
n

ℓ=0

(kt)
ω(kt)ξ1(kt).
(6.7)
Ces d´eveloppements sont satisfaisants d’un point de vue th´eorique, car
les estimateurs r´esultants sont faciles `a interpr´eter et intuitivement convain-
cants. De fa¸con naturelle, la loi a posteriori prend en compte la possibilit´e
que cette observation ait ´et´e g´en´er´ee par la premi`ere ou la deuxi`eme compo-
sante, puisque l’origine de chaque observation dans l’´echantillon est inconnue.
Cependant, le calcul pratique de (6.7) implique deux sommes de 2n termes
chacune, ce qui correspond exactement `a l’ensemble des partitions diﬀ´erentes
de l’´echantillon. Il est donc impossible de calculer un estimateur de Bayes de
cette fa¸con, pour la plupart des tailles d’´echantillon49.
∥
L’Exemple 6.5 est repr´esentatif d’un type de mod`eles statistiques aﬀect´es
par des probl`emes similaires, incluant la plupart des mod`eles `a donn´ees man-
quantes (ou variables latentes) comme les m´elanges, les mod`eles censur´es et
la classiﬁcation (voir Robert et Casella, 1999, Chapitre 9). Ces mod`eles sont
paradoxaux au sens o`u des constructions explicites des estimateurs de Bayes
peuvent ˆetre formellement disponibles, mais sont inutiles en pratique de par
le temps de calcul qu’elles impliquent. De plus, la diﬃcult´e de calcul aug-
mente avec la taille de l’´echantillon, conduisant `a ce qui peut ˆetre appel´e un
paradoxe de l’information, car plus on a d’information, plus il devient diﬃcile
de mener une inf´erence50 sur θ. Dans de tels cadres, les m´ethodes d’approxi-
mation num´erique sont rarement appropri´ees et des solutions adapt´ees sont
n´ecessaires, comme celles d´evelopp´ees dans les Sections 6.3 et 6.4.
6.2 M´ethodes classiques d’approximation
Cette section couvre bri`evement quelques techniques classiques qui peuvent
faciliter les calculs bay´esiens; la section suivante en revanche traite des
m´ethodes de simulations r´ecentes qui semblent particuli`erement adapt´ees aux
exigences de l’approche bay´esienne. Une pr´esentation plus d´etaill´ee est fournie
par Robert et Casella (2004, Chapitres 2-5); voir aussi Berger (2000) et Carlin
et Louis (2000a) pour une pr´esentation des logiciels bay´esiens disponibles.
49Par exemple, s’il faut une seconde de temps processeur pour ´evaluer (6.7) pour
un ´echantillon de taille 20, le calcul de l’estimateur correspondant `a un ´echantillon
de taille 40 devrait prendre douze jours.
50 `A strictement parler, la diﬃcult´e de calcul grandit toujours avec la taille de
l’´echantillon, mˆeme dans les cas o`u une statistique exhaustive existe. Cependant,
dans le cas de l’Exemple 6.5, cette croissance est tellement rapide (taux exponentiel)
qu’elle empˆeche compl`etement le calcul mˆeme. (De tels probl`emes sont appel´es NP-
complets en Recherche op´erationnelle.)

314
6 M´ethodes de calcul bay´esien
6.2.1 Int´egration num´erique
`A partir de la simple m´ethode de Simpson51, plusieurs approches ont
´et´e con¸cues en Math´ematiques appliqu´ees pour l’approximation num´erique
d’int´egrales. Par exemple, la quadrature polynomiale est cens´ee approcher les
int´egrales li´ees `a des distributions proches de la loi normale (voir Naylor et
Smith, 1982, Smith et al., 1985, ou Verdinelli et Wasserman, 1998, pour une
introduction d´etaill´ee). L’approximation de base est donn´ee par
 +∞
−∞
e−t2/2f(t) dt ≈
n

i=1
ωif(ti),
o`u
ωi =
2n−1n! √n
n2[Hn−1(ti)]2
et ti est le i-i`eme z´ero du n-i`eme polynˆome d’Hermite, Hn(t).
D’autres approximations d’int´egrales reli´ees `a la m´ethode pr´ec´edente sont
disponibles, qui reposent sur diﬀ´erentes bases orthogonales classiques (voir
Abramowitz et Stegun, 1964), ou les ondelettes (voir la Note 1.8.2 et M¨uller et
Vidakovic, 1999, Chapitre 1), mais ces m´ethodes requi`erent g´en´eralement des
hypoth`eses de r´egularit´e sur la fonction f, ainsi que des ´etudes pr´eliminaires
pour d´eterminer quelle base est la plus ad´equate et `a quel point cette approxi-
mation est pr´ecise. Par exemple, des transformations du mod`ele peuvent ˆetre
n´ecessaires pour mettre en pratique l’approximation d’Hermite (voir Naylor
et Smith, 1982, et Hills et Smith, 1992); Morris (1982) (voir aussi Diaconis
et Zabell, 1991) montre comment les lois des familles exponentielles `a va-
riance quadratique (Exercices 3.24 et 10.33) peuvent ˆetre associ´ees `a une base
orthogonale particuli`ere (Exercice 6.18).
Cependant, quelle que soit la m´ethode d’int´egration num´erique utilis´ee, sa
pr´ecision diminue dramatiquement lorsque la dimension de Θ augmente. De
fa¸con plus sp´eciﬁque, l’erreur associ´ee aux m´ethodes num´eriques se comporte
comme une puissance de la dimension de Θ. En pratique, une r`egle empirique
est que la plupart des m´ethodes standard ne devraient pas ˆetre utilis´ees pour
l’int´egration en dimension sup´erieure `a 4, mˆeme si ces m´ethodes continuent `a
s’am´eliorer ann´ee apr`es ann´ee. En eﬀet, la taille de la partie de l’espace non
pertinente pour le calcul d’une int´egrale donn´ee augmente consid´erablement
avec la dimension de l’espace. Ce probl`eme est appel´e ﬂ´eau de la dimension,
voir Robert et Casella (1999, Chapitre 3) pour des d´etails.
6.2.2 Les m´ethodes de Monte Carlo
Dans un probl`eme statistique, l’approximation de l’int´egrale
51Voir Stigler (1986) pour une plus forte connexion entre Simpson (1710-1761) et
la Statistique bay´esienne.

6.2 M´ethodes classiques d’approximation
315

Θ
g(θ)f(x|θ)π(θ) dθ,
(6.8)
doit tirer avantage de la nature particuli`ere de (6.8), `a savoir le fait que π soit
une densit´e de probabilit´e (en supposant qu’il s’agisse d’une loi a priori propre)
ou plutˆot, que f(x|θ)π(θ) soit proportionnel `a une densit´e. Une cons´equence
naturelle de cette perspective est d’utiliser la m´ethode de Monte Carlo, intro-
duite par Metropolis et Ulam (1949) et von Neumann (1951). Par exemple,
s’il est possible de produire des variables al´eatoires θ1, . . . , θm de loi π(θ), la
moyenne
1
m
m

i=1
g(θi)f(x|θi)
(6.9)
converge (presque sˆurement) vers (6.8) lorsque m tend vers +∞, selon la Loi
des Grands Nombres. De la mˆeme fa¸con, si un ´echantillon iid de θi de π(θ|x)
peut ˆetre simul´e, la moyenne
1
m
m

i=1
g(θi)
(6.10)
converge vers

Θ g(θ)f(x|θ)π(θ) dθ

Θ f(x|θ)π(θ) dθ
.
De plus, si la variance a posteriori var(g(θ)|x) est ﬁnie, le Th´eor`eme Central
Limit s’applique `a la moyenne (6.10), qui est alors asymptotiquement nor-
male, de variance var(g(θ)|x)/m. Des r´egions de conﬁance peuvent alors se
construire `a partir de cette approximation normale et, de mani`ere d´ecisive, il
d´ecoule aussi du Th´eor`eme Central Limit que l’ordre de grandeur de l’erreur
est 1/√m quelle que soit la dimension du probl`eme, au contraire des m´ethodes
num´eriques.
La mise en œuvre de cette m´ethode n´ecessite la production d’une suite iid
θi par ordinateur, reposant sur un g´en´erateur pseudo-al´eatoire d´eterministe
imitant la g´en´eration de π(θ) ou de π(θ|x) comme suit : un ´echantillon iid
d’une loi uniforme U ([0, 1]) est g´en´er´e (voir la Note 6.6.1), puis transform´e
en variables de la loi d’int´erˆet (voir Robert et Casella, 2004, Chapitre 2).52 Les
techniques statistiques standard peuvent aussi ˆetre utilis´ees pour d´eterminer
l’erreur d’approximation de (6.8) par la moyenne (6.9).
En r´ealit´e, la m´ethode de Monte Carlo s’applique dans un cadre beaucoup
plus g´en´eral que pour la simulation de π, comme dans le cas ci-dessus. Par
exemple, puisque (6.8) peut se repr´esenter de plusieurs mani`eres, il n’est pas
n´ecessaire de simuler les lois π(·|x) ou π pour obtenir une bonne approximation
52Il n’est pas surprenant que les m´ethodes de Monte Carlo apparaissent au mˆeme
moment que les premiers ordinateurs. Ces m´ethodes ne pouvaient tout simplement
pas exister sans ordinateurs et ont en fait contribu´e aux premiers programmes d’or-
dinateurs jamais ´ecrits.

316
6 M´ethodes de calcul bay´esien
de (6.8). En eﬀet, si h est une densit´e de probabilit´e telle que supp(h) inclut le
support de g(θ)f(x|θ)π(θ), l’int´egrale (6.8) peut aussi ˆetre repr´esent´ee comme
une esp´erance en h, `a savoir
 g(θ)f(x|θ)π(θ)
h(θ)
h(θ) dθ.
Cette repr´esentation conduit `a la m´ethode de Monte Carlo avec fonction d’im-
portance h : g´en´erer θ1, . . . , θm selon h et approcher (6.8) par
1
m
m

i=1
g(θi)ωi(θi),
avec les poids ω(θi) = f(x|θi)π(θi)/h(θi). De nouveau, par la Loi des Grands
Nombres, cette approximation converge presque certainement vers (6.8). Et
une approximation de Eπ[g(θ)|x] est donn´ee par
m
i=1 g(θi)ω(θi)
m
i=1 ω(θi)
,
(6.11)
car le num´erateur et le d´enominateur convergent respectivement vers

Θ
g(θ)f(x|θ)π(θ) dθ
et

Θ
f(x|θ)π(θ) dθ,
si supp(h) inclut supp(f(x|·)π). Notons que le rapport (6.11) ne d´epend d’au-
cune des constantes de normalisation apparaissant dans h(θ), f(x|θ) ou π(θ).
L’approximation (6.11) peut par cons´equent ˆetre utilis´ee lorsque certaines de
ces constantes de normalisation sont inconnues.
Bien que (6.11) converge th´eoriquement vers Eπ[g(θ)|x] pour toutes les
fonctions h v´eriﬁant la condition des supports (Exercice 6.8), le choix de la
fonction d’importance est primordial. Tout d’abord, il doit ˆetre ais´e de simu-
ler selon h, `a l’aide d’un g´en´erateur pseudo-al´eatoire rapide et ﬁable. (Voir les
Exercices 6.9-6.12 pour quelques algorithmes de simulation de lois usuelles.
Devroye, 1985, Fishman, 1996, Gentle, 1998, et Robert et Casella, 1999, Cha-
pitre 2, pr´esentent ces m´ethodes en d´etail.) De plus, la fonction h(θ) doit ˆetre
suﬃsamment proche de g(θ)π(θ|x), pour r´eduire autant que possible la varia-
bilit´e de (6.11) (Exercice 6.14); sinon, la plupart des poids ω(θi) prendront
des valeurs tr`es faibles, et un petit nombre d’entre eux auront une trop forte
inﬂuence. En eﬀet, si
Eh[g2(θ)ω2(θ)]
n’est pas ﬁnie, la variance de l’estimateur (6.11) est inﬁnie. Bien entendu, la
d´ependance `a g de la fonction d’importance h peut ˆetre ´evit´ee en proposant
des choix g´en´eriques comme celui de la loi a posteriori π(θ|x) (qui n’est pas
n´ecessairement le meilleur choix, voir les Exercices 6.13 et 6.14).

6.2 M´ethodes classiques d’approximation
317
Exemple 6.6. (Suite de l’Exemple 6.2) La loi a posteriori de η = ||θ||2
est bien connue, car π(η|x) est une loi du khi deux d´ecentr´e
χ2
p(λ) avec
coeﬃcient d’´echelle σ2τ 2/(σ2+τ 2). Simuler un ´echantillon η1, . . . , ηm de π(η|x)
est trivial : g´en´erer
ξ1, . . . , ξn ∼N (
√
λ, 1),
ζ1, . . . , ζn ∼G
p −1
2
, 1
2

et prendre ηi = σ2τ 2(ξ2
i + ζi)/(σ2 + τ 2) (i = 1, . . . , n). Nous pouvons alors
approcher (6.3) par
ˆδπ(x) =
m
i=1 ηi/(2ηi + p)
m
i=1 1/(2ηi + p) .
(6.12)
De plus, la variance de (6.12) contrˆole la pr´ecision de l’approximation (et le
choix de m).
∥
Lorsque la loi a posteriori n’est pas disponible, un autre choix simple de
fonction d’importance est la loi a priori π. Bien entendu, ceci est int´eressant,
non pas lorsque π est forc´ement explicite, mais au moins facile `a simuler, par
exemple, dans des mod`eles hi´erarchiques o`u les deux niveaux correspondent `a
des lois propres. Le mˆeme appel `a la prudence s’applique de nouveau cepen-
dant, puisque π doit ˆetre suﬃsamment proche de π(θ|x) et la variance de l’es-
timateur (6.11) ﬁnie. (Notez que cette condition de ﬁnitude est g´en´eralement
satisfaite puisque π(θ) a souvent des queues plus ´epaisses que π(θ|x).) Bien
´evidemment, ce choix est impossible lorsque π est impropre.
Exemple 6.7. (Suite de l’Exemple 6.1) Puisque π(θ) est la loi normale
N (μ, σ2), il est possible de simuler un ´echantillon normal θ1, . . . , θM et d’ap-
procher l’estimateur de Bayes par
ˆδπ(x1, . . . , xn) =
M
t=1 θt
/n
i=1[1 + (xi −θt)2]−1
M
t=1
/n
i=1[1 + (xi −θt)2]−1 .
(6.13)
Dans le cas o`u les xi sont tous loin de μ, ce choix peut ˆetre nuisible puisqu’`a
la fois le d´enominateur et les poids des θt dans le num´erateur sont petits pour
la plupart des θt, et l’approximation ˆδπ est par cons´equent assez instable ; la
Figure 6.1 repr´esente le r´esultat de cinq cents estimations parall`eles suivant
(6.13), fond´ees sur M = 1 000 simulations chacune, via l’´ecart interquartiles
central `a 90% des ˆδπ moins la moyenne totale. La variation de δπ augmente
rapidement entre μ = 3 et μ = 4. Cela montre que, lorsque μ > 3, de pe-
tits changements dans la simulation des θt peuvent produire des variations
drastiques de ˆδπ.
∥

318
6 M´ethodes de calcul bay´esien
mu
variation
0
2
4
6
8
10
-0.5
0.0
0.5
Fig. 6.1. Intervalle de variation `a 90% de l’approximation (6.13) lorsque μ varie,
pour n = 10 observations d’une loi de Cauchy C (0, 1) et M = 1, 000 simulations de
Monte Carlo de θ tir´ees d’une loi N (μ, 1).
Exemple 6.8. Soit le mod`ele
x ∼Np(θ, Ip) ,
θ|c ∼U{||θ||2=c}
et c ∼G (α, β) .
(La justiﬁcation de ce mod`ele sera donn´ee dans l’Exemple 10.26.) Bien que
π(θ|x) =
 +∞
0
π1(θ|x, c)π2(c|x) dc
conduise `a une loi a posteriori et `a un estimateur de Bayes tous les deux expli-
cites (voir l’Exemple 10.26), il peut ˆetre plus int´eressant de g´en´erer c1, . . . , cm
selon G (α, β), puis les θi selon U{||θ||2=ci} (1 ≤i ≤m) et d’approcher la
moyenne a posteriori par
ˆδπ(x) =
m
i=1 θi exp{−||x −θi||2/2}
m
i=1 exp{−||x −θi||2/2} ,
car cela ´evite le calcul de fonctions hyperg´eom´etriques conﬂuentes.
∥
Lorsque la vraisemblance ℓ(θ|x) peut ˆetre normalis´ee comme une densit´e,
un choix possible de fonction d’importance est h(θ) ∝ℓ(θ|x). Ce choix a du
sens lorsque π(θ|x) est quasi proportionnel `a la vraisemblance–comme c’est
le cas pour de grandes tailles d’´echantillon ou pour des lois a priori presque
constantes. Cela peut arriver notamment pour des mod`eles exponentiels, car,
si
f(x|θ) ∝eθ.x−ψ(θ),
un ´echantillon θ1, . . . , θm de
h(θ) ∝eθ.x−ψ(θ)

6.2 M´ethodes classiques d’approximation
319
peut en g´en´eral ˆetre obtenu facilement (voir l’Exercice 6.23 pour une limitation
de cette approche).
Une remarque ﬁnale sur le choix de la fonction d’importance est qu’il
existe g´en´eralement un compromis entre des ´etudes pr´eliminaires conduisant
`a une “bonne” fonction h et des algorithmes rapides. Par exemple, lorsque
h est choisie parce qu’elle facilite la simulation des θi, il faut faire attention
`a ses queues et s’assurer qu’elles sont plus lourdes que celles de π(θ|x), pour
´eviter une convergence lente et des variances inﬁnies. D’un autre cˆot´e, si h est
sp´ecialement r´egl´ee pour le calcul d’une int´egrale sp´eciﬁque (Exercice 6.14),
elle peut ne pas donner de si bons r´esultats pour une autre int´egrale, mˆeme
si, en principe, le mˆeme ´echantillon des θi peut ˆetre utilis´e pour le calcul de
toute int´egrale arbitraire. Cependant, ces diﬃcult´es potentielles mises `a part,
les m´ethodes d’´echantillonnage d’importance constituent un outil tr`es g´en´eral
et ﬁnissent souvent par devenir comp´etitives `a l’´egard des techniques de Monte
Carlo par chaˆınes de Markov (Section 6.3), comme le montrent par exemple
les m´ethodes de ﬁltrage particulaire (voir Doucet et al., 2001 et Capp´e et al.,
2005) et de Monte Carlo populationnel (Capp´e et al., 2004, Douc et al., 2005)
Par comparaison avec les m´ethodes d’int´egration num´erique, les m´ethodes
de Monte Carlo pr´esentent en eﬀet l’avantage que, une fois l’´echantillon
θ1, . . . , θn produit, celui-ci peut ˆetre utilis´e `a plusieurs reprises pour tous les
objectifs inf´erentiels, incluant l’obtention des r`egles de Bayes `a partir du coˆut
a posteriori approch´e
ˆL(π, d|x) = 1
m
m

i=1
L(θi, d|x).
Cependant, si la dimension du probl`eme est petite et si les fonctions `a int´egrer
sont assez r´eguli`eres, les m´ethodes d’int´egration num´erique ont tendance `a
donner de plus petites erreurs et de meilleurs contrˆoles de convergence. Des
r´ef´erences suppl´ementaires et une discussion plus d´etaill´ee sur les m´ethodes
de Monte Carlo, incluant les techniques am´elior´ees de variables antith´etiques
et de contrˆole, et leurs applications `a la statistique bay´esienne, peuvent ˆetre
trouv´ees dans Robert et Casella (2004) et Chen et al. (2000).
6.2.3 L’approximation analytique de Laplace
Lorsque la fonction `a int´egrer dans (6.8) est assez r´eguli`ere, il existe une
solution alternative analytique–mais asymptotique–aux simulations de Monte
Carlo. Cette m´ethode a ´et´e introduite par Laplace et est par cons´equent ap-
pel´ee approximation de Laplace. Soit une esp´erance a posteriori
Eπ[g(θ)|x] =

Θ g(θ)f(x|θ)π(θ) dθ

Θ f(x|θ)π(θ) dθ
.
Ce rapport d’int´egrales peut s’´ecrire

320
6 M´ethodes de calcul bay´esien
Eπ[g(θ)|x] =

Θ bN(θ) exp{−nhN(θ)} dθ

Θ bD(θ) exp{−nhD(θ)} dθ ,
(6.14)
o`u la d´ependance en x est supprim´ee par souci de simplicit´e et o`u n est nor-
malement la taille de l’´echantillon (bien qu’il puisse parfois correspondre `a
la variance a priori inverse, comme dans Robert (1993b) ou dans l’Exemple
6.11). Lorsque hN(θ) = hD(θ), Eπ[g(θ)|x] s’´ecrit sous une forme standard ;
lorsque bN(θ) = bD(θ), l’esp´erance a posteriori (6.14) est ´ecrite sous forme ex-
ponentielle compl`ete, pour reprendre la terminologie de Tierney et Kadane
(1986). Pour une fonction donn´ee h admettant un minimum unique ˆθ, le
d´eveloppement de Laplace d’une int´egrale g´en´erale est donn´e par

b(θ)e−nh(θ)dθ =
√
2πσe−nˆh

ˆb + 1
2n

σ2ˆb′′ −σ4ˆb′ˆh′′′
+ 5
12
ˆb(ˆh′′′)2σ6 −1
4
ˆbˆh(4)σ4

+ O(n−2),
o`u ˆb, ˆh, etc., sont les valeurs prises par b, h et leurs d´eriv´ees pour θ = ˆθ, et
σ2 = [h′′(ˆθ)]−1 (voir Olver, 1974, et Schervish, 1995). Cette approximation du
deuxi`eme ordre ne n´ecessite le calcul que des deux premi`eres d´eriv´ees de g, par
opposition `a une approche similaire propos´ee par Lindley (1980). En plus, si on
suppose que hN et hD satisfont ˆhN −ˆhD = O(n−1), . . . , ˆh(4)
N −ˆh(4)
D = O(n−1)
(comme c’est bien entendu le cas pour la forme standard), le d´eveloppement de
Laplace conduit `a l’approximation suivante de Eπ[g(θ)|x] (avec ˆbD = bD(ˆθD),
ˆbN = bN(ˆθN), et ainsi de suite) :
Lemme 6.9. Si ˆbD ̸= 0,

Θ bN(θ) exp{−nhN(θ)} dθ

Θ bD(θ) exp{−nhD(θ)} dθ = σN
σD
e−n(ˆhN−ˆhD)
ˆbN
ˆbD
+
σ2
D
2nˆb2
D

ˆbDˆb′′
N
−ˆbNˆb′′
D −σ2
Dˆh′′′
D(ˆbDˆb′
N −ˆbNˆb′
D)
&5
+ O(n−2).
Une d´emonstration de ce r´esultat est donn´ee dans Tierney et al. (1989)
(voir aussi l’Exercice 6.17). Le Lemme 6.9 implique alors le d´eveloppement
suivant pour les deux formes du rapport (6.14) :
Corollaire 6.10. Lorsque Eπ[g(θ)|x] s’´ecrit de fa¸con standard,
Eπ[g(θ)|x] = ˆg + σ2
Dˆb′
Dˆg′
nˆbD
+ σ2
Dˆg′′
2n
−σ4
Dˆh′′′ˆg′
2n
+ O(n−2).
(6.15)
Pour la forme exponentielle compl`ete, si g est positive et g(ˆθD) est uni-
form´ement born´ee (en n) par des constantes strictement positives,
Eπ[g(θ)|x] =
ˆbN
ˆbD
σ2
N
σ2
D
e−n(ˆhn−ˆhD) + O(n−2).
(6.16)

6.2 M´ethodes classiques d’approximation
321
Preuve.
Pour la forme standard, hN = hD ; donc, bN = gbD, ˆθD = ˆθN. Par
cons´equent,
ˆbDˆb′
N −ˆbNˆb′
D
ˆb2
D
=
bN
bD
′
θ=ˆθD
= ˆg′
et
ˆbDˆb′′
N −ˆbNˆb′′
D
ˆb2
D
= ˆg′′ + 2
ˆb′
D
ˆbD
ˆg′.
Le r´esultat d´ecoule alors du Lemme 6.9.
Dans le cas exponentiel complet, posons hN = hD −(1/n) log(g). Puisque
nous supposons que g(ˆθD) ≥c > 0 pour tout n, ˆθN −ˆθD = O(n−1). Et
puisque bD = bN, cela implique ˆb(i)
N −ˆb(i)
D = O(n−1) (i = 0, 1, 2). Les termes
additionnels dans le Lemme 6.9 peuvent donc ˆetre ignor´es.
⊓⊔
Le Corollaire 6.10 montre clairement l’avantage de l’interpr´etation ex-
ponentielle compl`ete de (6.14), qui ´evite le calcul des d´eriv´ees premi`ere et
deuxi`eme, ˆg′ et ˆg′′, apparaissant dans (6.15). Notons que (6.16) peut aussi
s’´ecrire
Eπ[g(θ)|x] = σ2
N
σ2
D
g(ˆθN)f(x|ˆθN)π(ˆθN)
f(x|ˆθD)π(ˆθD)
+ O(n−2).
L’hypoth`ese sur g, `a savoir que g est positive et born´ee, en ˆθD, par des
constantes strictement positives, est cependant assez restrictive. En eﬀet, la
d´ecomposition habituelle g = g+ −g−ne marche pas dans ce cadre. Tier-
ney et al. (1989) surmontent cet inconv´enient en ´evaluant d’abord la fonction
g´en´eratrice des moments de g(θ),
M(s) = Eπ[exp{sg(θ)}|x],
bien entendu positive, par ˆ
M(s) via (6.16). Ils calculent Eπ[g(θ)|x] comme
Eπ[g(θ)|x] = d
ds(log ˆ
M(s))

s=0 + O(n−2).
Ces auteurs ont aussi ´etabli le r´esultat plutˆot surprenant que cette approche
fournit le d´eveloppement standard (6.15) sans n´ecessiter une ´evaluation des
premi`ere et deuxi`eme d´eriv´ees de g (voir l’Exercice 6.18).
Exemple 6.11. (Tierney et al., 1989) Soit π(θ|x) une loi Be(α, β) ; l’esp´e-
rance a posteriori de θ est alors
δπ(x) =
α
α + β .
Ce calcul exact peut ˆetre compar´e aux approximations (6.15),
δπ(x) = α2 + αβ + 2 −4α
(α + β −2)2
+ O((α + β)−2),

322
6 M´ethodes de calcul bay´esien
et (6.16),
δπ(x) =
α
α + β −1

α
α −1
α−0.5 α + β −2
α + β −1
α+β−0.5
+ O((α + β)−2).
Notant p = α/(α + β) et n = α + β, l’erreur d’approximation est
ΔS = 21 −2p
n2
+ O(n−3)
dans le cas standard, et
ΔE = 21 −13p2
12pn2
+ O(n−3)
dans le cas exponentiel complet. Le deuxi`eme d´eveloppement est alors meilleur
pour les valeurs moyennes de p.
∥
Nous renvoyons les lecteurs `a Leonard (1982), Tierney et Kadane (1986),
Tierney et al. (1989) et Kass et Steﬀey (1989) pour des r´esultats additionnels
et des commentaires. Une r´eserve faite dans Smith et al. (1985) sur les approxi-
mations de Laplace est qu’elles ne sont justiﬁ´ees que de fa¸con asymptotique ;
les v´eriﬁcations sp´eciﬁques men´ees dans diﬀ´erentes publications ne peuvent
fournir une justiﬁcation globale de la m´ethode, mˆeme si elles semblent donner
des r´esultats assez satisfaisants dans la plupart des cas. D’autres critiques de
cette approche sont que
(1) les m´ethodes analytiques impliquent toujours des ´etudes pr´eliminaires
d´elicates sur la r´egularit´e de la fonction int´egr´ee, ce qui n’est pas forc´ement
faisable ;
(2) la loi a posteriori doit ˆetre assez semblable `a la loi normale (pour laquelle
l’approximation de Laplace est exacte) ; et
(3) de telles m´ethodes ne peuvent pas ˆetre utilis´ees dans des cas comme ceux
de l’Exemple 6.5, o`u le calcul de l’estimateur du maximum de vraisem-
blance est assez diﬃcile.
Des extensions de la m´ethode de Laplace `a des approximations de point-
selle sont pass´ees en revue dans Kass (1989) (voir aussi Rousseau, 1997, 2000).
6.3 M´ethodes de Monte Carlo par chaˆınes de Markov
Nous consid´erons dans cette section une m´ethode de Monte Carlo plus
g´en´erale, permettant d’approcher la g´en´eration de variables al´eatoires d’une
loi a posteriori π(θ|x) lorsque cette loi ne peut pas ˆetre simul´ee directement.
L’avantage de cette m´ethode sur les m´ethodes de Monte Carlo classiques
d´ecrites dans la Section 6.2.2 est qu’elle ne n´ecessite pas la construction pr´ecise

6.3 M´ethodes de Monte Carlo par chaˆınes de Markov
323
d’une fonction d’importance, puisqu’elle prend en compte les caract´eristiques
de π(θ|x). Cette extension, appel´ee Monte Carlo par chaˆınes de Markov (et
abr´eg´ee en MCMC), a des applications presque illimit´ees, mˆeme si ses per-
formances varient largement, selon la complexit´e du probl`eme. Elle tire son
nom de l’id´ee que, pour produire des approximations acceptables d’int´egrales
et d’autres fonctions d´ependant d’une loi d’int´erˆet, il suﬃt de g´en´erer une
chaˆıne de Markov (θ(m))m de loi limite la loi d’int´erˆet53. Cette id´ee d’utiliser
le comportement limite d’une chaˆıne de Markov apparaˆıt `a la mˆeme ´epoque
que la technique de Monte Carlo originelle, au moins dans la litt´erature de
Physique particulaire (Metropolis et al., 1953), mais elle n´ecessite une puis-
sance de calcul qui n’´etait alors pas suﬃsament grande pour ˆetre appr´eci´ee
dans sa globalit´e.
Apr`es une br`eve discussion sur l’int´erˆet de l’utilisation d’une chaˆıne de
Markov en simulation (Section 6.3.1), nous pr´esenterons les deux types de
techniques les plus importantes con¸cues pour cr´eer des chaˆınes de Markov
de loi stationnaire donn´ee, `a savoir les algorithmes de Metropolis-Hastings
(Section 6.3.2) et l’´echantillonnage de Gibbs (Sections 6.3.3-6.3.6). Nous ren-
voyons les lecteurs `a Gilks et al. (1996) et Robert et Casella (2004) pour des
perspectives plus larges sur ce sujet.
6.3.1 Les MCMC en pratique
Le paradoxe apparent d’une simulation par chaˆınes de Markov est qu’il
semble que nous devions recourir deux fois `a un argument asymptotique :
premi`erement, la chaˆıne doit converger vers sa loi stationnaire ; deuxi`emement,
des moyennes empiriques comme (6.9) doivent converger vers l’esp´erance
correspondante Eπ[g(θ)|x]. Nous expliquons maintenant pourquoi, grˆace au
Th´eor`eme Ergodique, ceci n’est pas le cas.
Si les chaˆınes de Markov (θ(m))m produites par des algorithmes MCMC
sont irr´eductibles, c’est-`a-dire si elles peuvent visiter (avec probabilit´e non
nulle) tout ensemble A tel que π(A|x) > 0, alors, de par leur nature mˆeme,
ces chaˆınes sont r´ecurrentes positives, de loi stationnaire π(θ|x), c’est-`a-dire
que le nombre moyen de visites d’un ensemble arbitraire A de mesure positive
est inﬁni. Ces chaˆınes de Markov sont aussi ergodiques, ce qui signiﬁe que
la loi de θ(m) converge vers π(·|x) pour presque toute valeur initiale θ(0) ; en
d’autres termes, l’inﬂuence de la valeur initiale disparaˆıt. (Sous des conditions
assez g´en´erales, les chaˆınes MCMC sont mˆeme r´ecurrentes au sens de Harris,
ce qui implique que le “presque” ci-dessus disparaˆıt.)
53Cette section minimise le recours `a la th´eorie des chaˆınes de Markov, bien que
certaines notions comme l’ergodicit´e ne puissent pas ˆetre omises. Nous renvoyons les
lecteurs `a Meyn et Tweedie (1993) pour une introduction profonde et p´edagogique
sur ce sujet. Voir aussi Robert et Casella (1999, Chapitre 4) pour un traitement plus
exp´editif de ces notions, n´ecessaires pour la compr´ehension des m´ethodes MCMC.

324
6 M´ethodes de calcul bay´esien
Par cons´equent, pour k suﬃsamment grand, le θ(k) r´esultant est distribu´e
approximativement selon π(θ|x), quelle que soit la valeur initiale θ(0). Dans
la pratique, le probl`eme est alors de d´eterminer ce que signiﬁe un “grand” k,
car il d´etermine le nombre de simulations `a eﬀectuer : s’agit-il de 200 ou 1010
simulations ? La vitesse de convergence, c’est-`a-dire le taux de d´ecroissance de
la diﬀ´erence (distance) entre la loi de θ(k) et sa limite, apporte une r´eponse `a ce
probl`eme, mais jusqu’ici elle a ´et´e surtout ´etudi´ee d’un point de vue th´eorique
(voir Roberts et Tweedie, 2005). De plus, ce taux de convergence d´epend
souvent du point de d´epart (sauf si la chaˆıne est uniform´ement ergodique) et un
nombre k d’it´erations donn´e ne fournit pas la mˆeme qualit´e d’approximation
pour diﬀ´erentes valeurs de θ(0). Il existe donc des obstacles pratiques `a la
simulation par chaˆınes de Markov, puisqu’on ignore le plus souvent si la chaˆıne
a it´er´e suﬃsamment longtemps. Mais, comme l’ont d´etaill´e Robert et Casella
(2004, Chapitre 12), il existe d´esormais des tests de diagnostic et un logiciel
correspondant, CODA (voir la Note 6.6.2), qui fournissent diﬀ´erents indicateurs
de stationnarit´e de la chaˆıne et limitent en partie cette diﬃcult´e.
Une fois θ1 = θ(k) g´en´er´e, une fa¸con na¨ıve de construire un ´echantillon
iid θ1, . . . , θm suivant π(θ|x) est d’utiliser le mˆeme algorithme avec une autre
valeur initiale θ(0)
2
et une autre s´equence de k transitions de Markov aﬁn d’ob-
tenir θ2, et ainsi de suite jusqu’`a θm. Comme nous l’avons montr´e ci-dessous,
la vitesse de convergence d´epend souvent de la valeur initiale, et il est donc
pr´ef´erable (en termes de convergence) de prendre la valeur actuelle θ(k) comme
nouvelle valeur initiale, mˆeme si cela introduit de la d´ependance entre les θi.
Cependant, l’ind´ependance n’est pas fondamentale lorsqu’on s’int´eresse prin-
cipalement `a des fonctionnelles de π(θ|x), car le Th´eor`eme Ergodique implique
que la moyenne
1
K
K

k=1
g(θ(k))
converge vers Eπ[g(θ)|x] (du moment que Eπ[|g(θ)||x] est ﬁni) lorsque K tend
vers l’inﬁni (voir Meyn et Tweedie, 1993). L’inﬂuence de la valeur de d´epart
disparaˆıt donc aussi dans la moyenne (d’o`u l’ergodicit´e). De plus, cette pro-
pri´et´e est aussi satisfaite par toute sous-suite de (θ(k)).
Le Th´eor`eme Ergodique r´esout donc le paradoxe des deux asymptotiques
mentionn´e au d´ebut de cette section, car il ´etend la Loi des Grands Nombres
`a des suites d´ependant de variables al´eatoires et supprime le besoin de pro-
duire un ´echantillon iid, qui serait, de toute mani`ere, seulement approximatif
si nous utilisions la m´ethode propos´ee ci-dessus. En eﬀet, comme l’a not´e
Geyer (1992), la th´eorie des chaˆınes de Markov ne donne pas d’indication
g´en´erale sur le fait que la stationnarit´e soit atteinte, car, d’un point de vue
math´ematique, ceci n’est qu’une propri´et´e asymptotique de la chaˆıne54. Par
cons´equent, il vaut mieux consid´erer une seule suite (θ(k)), puisque chaque
54Une exception est fournie par les cas du renouvellement et de l’´echantillonnage
exact (voir Robert et Casella, 2004, Chapitre 13), o`u il est possible d’exhiber des k

6.3 M´ethodes de Monte Carlo par chaˆınes de Markov
325
´etape de simulation nous rapproche (en probabilit´e) d’une r´ealisation de la loi
stationnaire, π(θ|x). De plus, une simulation reposant sur de multiples points
de d´epart entraˆıne un gaspillage consid´erable, puisque la plupart des valeurs
simul´ees sont rejet´ees. Cependant, le recours `a des chaˆınes multiples est as-
sez utile pour l’´etude de la convergence d’une chaˆıne de Markov et apparaˆıt
donc fr´equemment dans des techniques de contrˆole, comme dans la m´ethode
within-between de Gelman et Rubin (1992) (voir Robert et Casella, 2004, Sec-
tion 12.3.4).
Lorsque cela est n´ecessaire, une quasi-ind´ependance peut ˆetre obtenue par
´echantillonnage par paquets, c’est-`a-dire en ne retenant qu’un point de la
chaˆıne toutes les t it´erations, pour un ´echantillon simul´e eﬃcacement, avec,
par exemple, t = 5 ou t = 10. Raftery et Lewis (1992a,b) proposent une
d´etermination plus complexe de la taille du paquet t, qui est induite par
la chaˆıne et fond´ee sur une “binarisation” de cette chaˆıne. (Voir Robert et
Casella, 2004, Section 12.3.4, pour une ´evaluation critique de cette m´ethode,
impl´ement´ee dans le logiciel CODA.)
6.3.2 Algorithmes de Metropolis-Hastings
Une fois acquis le principe d’utilisation d’une chaˆıne de Markov de loi
stationnaire π–plutˆot que des variables iid distribu´ees exactement selon π–
pour approcher des quantit´es comme (6.8), la mise en œuvre de ce principe
n´ecessite la construction d’un m´ecanisme de g´en´eration pour produire de telles
chaˆınes de Markov. De fa¸con ´etonnante, un algorithme quasi universel satis-
faisant cette contrainte existe : il a ´et´e d´evelopp´e par Metropolis et al. (1953),
au d´epart pour la Physique particulaire (et la bombe H...), et g´en´eralis´e par
Hastings (1970) dans un cadre plus statistique (et plus paciﬁque). En r´ealit´e,
il s’applique `a une grande vari´et´e de probl`emes, car sa principale restriction
est que la loi d’int´erˆet soit connue `a une constante pr`es, mais nous verrons
plus tard que cette contrainte peut ˆetre lev´ee de plusieurs fa¸cons.
Dans sa version moderne, l’algorithme de Metropolis-Hastings peut ˆetre
d´ecrit de la fa¸con suivante. Pour une densit´e donn´ee π(θ), connue `a un fac-
teur de normalisation pr`es, et une densit´e conditionnelle q(θ′|θ), l’algorithme
g´en`ere la chaˆıne (θ(m))m comme suit :
Algorithme 6.1. –Algorithme de Metropolis-Hastings–
It´eration 0 : Initialiser avec une valeur arbitraire θ(0)
It´eration m : Mettre `a jour θ(m) par θ(m+1) (m = 1, 2, . . .), de la fa¸con
suivante :
a) G´en´erer ξ ∼q(ξ|θ(m))
tels que θ(k) soit exactement distribu´e suivant la loi stationnaire. Voir aussi Hobert
et Robert (2004).

326
6 M´ethodes de calcul bay´esien
b) Poser
ϱ(θ(m), ξ) =
π(ξ) q(θ(m)|ξ)
π(θ(m)) q(ξ|θ(m)) ∧1
c) Prendre
θ(m+1) =

ξ
avec probabilit´e ϱ(θ(m), ξ),
θ(m)
sinon.
La loi de densit´e π(θ) est souvent appel´ee loi cible ou loi objet, tandis que la
loi de densit´e q(·|θ) est dite loi de proposition. Une propri´et´e stup´eﬁante de cet
algorithme est d’autoriser un nombre inﬁni de lois de proposition produisant
toutes une chaˆıne de Markov convergeant vers la loi d’int´erˆet.
Th´eor`eme 6.12. Si la chaˆıne (θ(m))m est irr´eductible, c’est-`a-dire si, pour
tout sous-ensemble A tel que π(A) > 0, il existe M tel que Pθ(0)(θ(M) ∈
A) > 0, alors π est la loi stationnaire de la chaˆıne. Si de plus la chaˆıne est
ap´eriodique, elle est aussi ergodique de loi limite π, pour presque toute valeur
initiale θ(0), au sens o`u
lim
m→∞sup
A
Pθ(0)(θ(m) ∈A) −π(A)
 = 0
(π p.s.)
La propri´et´e au cœur de ce r´esultat est la condition d’´equilibre ponctuel,
c’est-`a-dire le fait que le noyau de transition de la chaˆıne de Markov associ´ee
`a l’algorithme ci-dessus, not´e K(θ′|θ), satisfasse
π(θ)K(θ′|θ) = π(θ′)K(θ|θ′) ,
(6.17)
ce qui se v´eriﬁe ais´ement en ´ecrivant le noyau de l’algorithme de Metropolis-
Hastings
K(θ′|θ) = ϱ(θ, θ′)q(θ′|θ) +

[1 −ϱ(θ, ξ)]q(ξ|θ)dξ δθ(θ′) ,
o`u δ est la masse de Dirac.
Lorsqu’on int`egre les deux cˆot´es de (6.17) en θ, le terme de droite donne
π(θ′), car K(θ|θ′) est une densit´e (conditionnelle) en θ ; le terme de gauche
donne la densit´e de la chaˆıne de Markov apr`es une ´etape, lorsque θ(0) ∼π. Par
cons´equent, la loi π est bien stationnaire pour le noyau de transition K(θ′|θ).
(Voir l’Exercice 6.20 et Robert et Casella, 2004, Section 6.2, pour plus de
d´etails.)
La condition d’irr´eductibilit´e du Th´eor`eme 6.12 est bien entendu une
condition n´ecessaire pour que la chaˆıne explore le support de π. Des condi-
tions suﬃsantes pour l’irr´eductibilit´e sont, par exemple, que le support de
q(·|θ) contienne le support de π pour tout θ ou, plus g´en´eralement, que le

6.3 M´ethodes de Monte Carlo par chaˆınes de Markov
327
support de q(·|θ) contienne un voisinage de θ de rayon constant (voir Robert
et Casella, 1999, Lemme 6.2.7).
Tandis que le Th´eor`eme 6.12 donne une condition formelle pour que la
chaˆıne converge, ce qui couvre une immense cat´egorie de lois propos´ees, la
s´election pratique de cette loi est beaucoup plus d´elicate, car un faible che-
vauchement entre les supports de π et q(·|θ) peut consid´erablement ralentir
la convergence.
Exemple 6.13. Les lois de Weibull sont utilis´ees abondamment en ﬁabilit´e
et dans d’autres applications en ing´enierie, en partie `a cause de leur capacit´e
`a d´ecrire diﬀ´erents comportements de taux de risque et en partie pour des rai-
sons historiques. Puisqu’elles n’appartiennent `a aucune famille exponentielle,
´etant de la forme
f(x) ∝αηxα−1e−xαη,
(6.18)
elles ne peuvent pas conduire `a des lois a posteriori explicites pour les pa-
ram`etres α et η. Pour θ = (α, η), consid´erons la loi a priori (propre)
π(θ) ∝e−αηβ−1e−ξη
et des observations x1, . . . , xn de (6.18). Un algorithme de Metropolis-Hastings
pour la simulation de π(θ|x1, . . . , xn) peut se fonder sur la loi conditionnelle
q(θ′|θ) = 1
αη exp

−α′
α −η′
η

,
c’est-`a-dire sur deux lois exponentielles ind´ependantes de moyennes α et η,
versions exponentielles des marches al´eatoires (voir ci-dessous). La probabilit´e
d’acceptation r´esultante est alors
ϱ = 1 ∧
η′
η
β α′
α
 n

i=1
xi
 α′−α
n

i=1
exα
i −xα′
i e−α/α′−η/η′+α′/α+η′/η ,
si (α′, η′) = θ′ est la valeur simul´ee et (α, η) = θ est la valeur courante des
param`etres.
∥
D`es Hastings (1970), le choix le plus courant pour q est une marche
al´eatoire, o`u q(θ′|θ) est de la forme f(||θ′ −θ||). La valeur propos´ee ξ dans
l’algorithme de Metropolis-Hastings est alors de la forme
ξ = θ(m) + ε ,
o`u ε est une variable al´eatoire de loi sym´etrique f. L’id´ee naturelle sur laquelle
repose ce choix est de perturber al´eatoirement la valeur courante de la chaˆıne,
tout en restant aux alentours de ce point, et de voir si la nouvelle valeur ξ
est vraisemblable pour la loi d’int´erˆet. Pour ce m´ecanisme de proposition en
marche al´eatoire, le rapport d’acceptation de Metropolis-Hastings est

328
6 M´ethodes de calcul bay´esien
ϱ =
π(ξ)
π(θ(m)) ∧1.
La chaˆıne (θ(m))m restera donc plus longtemps en un point donn´e ξ si la valeur
a posteriori correspondante π(ξ) est sup´erieure et, inversement, des points ξ
tels que π(ξ) = 0 ne seront jamais visit´es. Des choix standard pour q sont les
lois uniformes, normales ou de Cauchy. (Notons que l’Exemple 6.13 est bien
un cas particulier de l’algorithme de Metropolis-Hastings `a marche al´eatoire,
car la proposition est une marche al´eatoire en (log α, log η).)
Exemple 6.14. Pour θ, x ∈R2, soit la loi normale modiﬁ´ee
π(θ|x) ∝exp{−||θ −x||2/2}
p

i=1
exp

−1
||θ −μi||2

,
o`u les μi agissent comme des points r´epulsifs, c’est-`a-dire des valeurs impro-
bables (ou interdites) de θ. Un algorithme de Metropolis-Hastings `a marche
al´eatoire fond´e sur une proposition N2(0, 0.2 I2) conduit au r´esultat repr´esent´e
par la Figure 6.2 pour x = 0 et p = 15. Les μj, qui sont repr´esent´es par des
croix, sont correctement ´evit´es par la chaˆıne de Markov, qui retrouve aussi la
forme de la densit´e normale.
∥
Fig. 6.2.
Trajet de la chaˆıne de Markov (θ(m))m sur la surface a posteriori de
π(θ|x) dans l’Exemple 6.14 et les points r´epulsifs μj indiqu´es par des croix, pour
x = 0 et p = 15 (5 000 it´erations).
Clairement, cet algorithme est applicable dans une grande g´en´eralit´e et, de
plus, a des contraintes de calibration limit´ees, car la loi des perturbations peut

6.3 M´ethodes de Monte Carlo par chaˆınes de Markov
329
ˆetre choisie de fa¸con quasi ind´ependante de la vraie densit´e π. (En eﬀet, cette
loi d´epend d’un facteur d’´echelle qui devrait seulement ˆetre r´egl´e en fonction
du taux d’acceptation moyen de l’algorithme55 ; voir Robert et Casella, 2004,
Section 7.5 et Note 7.8.4.) Bien qu’il ne puisse pas v´eriﬁer des propri´et´es de
convergence plus fortes que la convergence g´eom´etrique `a cause des propri´et´es
de queues longues du m´ecanisme de proposition (voir Mengersen et Tweedie,
1996), l’algorithme de Metropolis-Hastings `a marche al´eatoire apparaˆıt encore
comme ´etant le “passe-partout” des techniques MCMC.
Un autre type de m´ecanisme de proposition, ressemblant plus aux tech-
niques de Monte Carlo standard, est le m´ecanisme ind´ependant, o`u la densit´e
q(·|θ) ne d´epend pas de θ,
q(θ′|θ) = h(θ′) .
(Puisque la valeur propos´ee peut ˆetre rejet´ee avec une probabilit´e positive, l’al-
gorithme produit n´eanmoins une chaˆıne de Markov.) Bien que leurs propri´et´es
th´eoriques soient souvent meilleures que celles de l’algorithme de Metropolis-
Hastings `a marche al´eatoire (voir Mengersen et Tweedie, 1996), ces m´ethodes
ont des applications plus limit´ees, car le m´ecanisme de proposition h doit res-
sembler dans un certain sens `a la loi cible π. La loi propos´ee est parfois la
loi a priori ou est fond´ee sur un d´eveloppement asymptotique de la loi π, par
exemple, une approximation par point-selle (Robert et Casella, 1999, Exemple
6.3.4) ou sur un algorithme d’acceptation-rejet approximatif comme dans l’al-
gorithme ARMS de Gilks et al. (1995) (voir aussi l’Exercice 6.12). (Notons
la similitude avec la m´ethode d’´echantillonnage d’importance de la Section
6.2.2 : le choix du m´ecanisme de proposition de la loi h est fondamental pour
la mise en œuvre pratique de la m´ethode.)
6.3.3 L’´echantillonnage de Gibbs
La technique de Metropolis-Hastings pr´esent´ee dans la section pr´ec´edente
est attrayante de par son universalit´e, mais, d’un autre cˆot´e, le manque de
connexion entre le m´ecanisme de proposition q et la loi cible π peut ˆetre n´efaste
pour les propri´et´es de convergence de la m´ethode et, dans la pratique, peut
facilement empˆecher la convergence si la probabilit´e d’atteindre des parties
´eloign´ees du support de la loi π est trop petite. L’approche de l’´echantillonnage
de Gibbs, qui repose sur une perspective diﬀ´erente, est pour sa part fond´ee
sur la loi π. Cette m´ethode tire son nom des champs al´eatoires de Gibbs, o`u
elle a ´et´e utilis´ee pour la premi`ere fois par Geman et Geman (1984) ; voir
Robert et Casella (2004, Note 10.6.1) pour un bref compte-rendu des d´ebuts
de l’´echantillonnage de Gibbs.
55Le facteur d’´echelle 0.02 dans l’Exemple 6.14 a d´elib´er´ement ´et´e choisi trop petit,
pour mieux illustrer la fa¸con dont la chaˆıne de Markov ´evite les points r´epulsifs μi. En
pratique, un facteur d’´echelle petit peut conduire `a des probl`emes d’irr´eductibilit´e
si la chaˆıne de Markov n’arrive pas `a franchir des zones de tr`es faible probabilit´e
pour joindre deux r´egions (modales) de forte probabilit´e.

330
6 M´ethodes de calcul bay´esien
D’un point de vue g´en´eral, l’´echantillonnage de Gibbs tire proﬁt des struc-
tures hi´erarchiques d’un mod`ele, par exemple lorsque celui-ci peut s’´ecrire sous
la forme
π(θ|x) =

π1(θ|x, λ)π2(λ|x) dλ.
(6.19)
L’id´ee est alors de simuler la loi jointe π1(θ|x, λ)π2(λ|x), aﬁn d’obtenir π(θ|x)
comme la loi marginale. Bien entendu, lorsque les deux lois π1(θ|x, λ) et
π2(λ|x) sont connues et peuvent ˆetre simul´ees, la g´en´eration de θ de π(θ|x)
est ´equivalente `a la g´en´eration de λ de π2(λ|x), puis de θ de π1(θ|x, λ).
Exemple 6.15. (Casella et George, 1992) Soit (θ, λ) ∈N × [0, 1] et
π(θ, λ|x) ∝
n
θ

λθ+α−1(1 −λ)n−θ+β−1,
o`u les param`etres α et β d´ependent en r´ealit´e de x. Ce mod`ele peut s’´ecrire
de fa¸con hi´erarchique (6.19), avec π1(θ|x, λ) une loi binomiale, B(n, λ), et
π2(λ|x) une loi bˆeta, Be(α, β). La loi marginale de θ est alors
π(θ|x) =
n
θ
B(α + θ, β + n −θ)
B(α, β)
,
c’est-`a-dire une loi bˆeta-binomiale. Cette loi marginale n’est pas particuli`erement
facile `a utiliser. Par exemple, le calcul de E[θ/(θ + 1)|x], ou de la loi a poste-
riori de η = exp(−θ2), ne peut pas ˆetre fait explicitement et peut n´ecessiter
des approximations num´eriques complexes lorsque α, β et n sont grands.
Par cons´equent, en fonction du probl`eme inf´erentiel, il peut ˆetre plus avanta-
geux de tirer proﬁt de la d´ecomposition hi´erarchique ci-dessus et de simuler
(λ(1), θ(1)), . . . , (λ(m), θ(m)) avec λ(i) ∼Be(α, β) et θ(i) ∼B(n, λ(i)) ; par
exemple, E[θ/(θ + 1)|x] peut alors ˆetre approch´ee par
1
m
m

i=1
θ(i)
θ(i) + 1.
(On remarquera que, dans ce cas, l’utilisation d’un algorithme MCMC n’est
pas utile.)
∥
Cependant, et par contraste avec l’Exemple 6.15, la loi marginale π2(λ|x)
n’est pas toujours disponible (sous forme analytique ou algorithmique) et la
m´ethode classique de Monte Carlo par simulation directe ne peut pas ˆetre
mise en œuvre. Il est en fait plus fr´equent que les deux lois a posteriori
conditionnelles, π1(θ|x, λ) et π2(λ|x, θ), puissent ˆetre simul´ees. Puisqu’elles
sont suﬃsamment informatives sur la loi jointe, π(θ, λ|x), et puisque π(θ, λ|x)
peut ˆetre obtenu `a partir de ces densit´es conditionnelles (voir les Exercices
6.26 et 6.27), il semble conceptuellement possible de fonder un algorithme de
simulation de π(θ|x) sur ces lois conditionnelles uniquement.

6.3 M´ethodes de Monte Carlo par chaˆınes de Markov
331
Exemple 6.16. (Suite de l’Exemple 6.4)
Pour le mod`ele de capture-
recapture temporel, les deux lois a posteriori conditionnelles sont (1 ≤i ≤n)
pi|x, N ∼Be(α + xi, β + N −xi)
N −x+|x, p ∼N eg(x+, ϱ),
avec
ϱ = 1 −
n

i=1
(1 −pi).
En revanche, la loi marginale a posteriori π2(p|x) ne peut pas ˆetre obtenue
explicitement ou simul´ee directement.
∥
Une premi`ere technique d’´echantillonnage de Gibbs, d’abord appel´ee aug-
mentation des donn´ees parce que utilis´ee dans ce contexte, a ´et´e introduite
par Tanner et Wong (1987) aﬁn de tirer proﬁt des lois conditionnelles selon
l’algorithme it´er´e suivant :
Algorithme 6.2. –´Echantillonnage de Gibbs bivari´e–
Initialisation : Commencer par une valeur arbitraire λ(0).
It´eration t : pour λ(t−1) donn´e, g´en´erer
a. θ(t) selon π1(θ|x, λ(t−1))
b. λ(t) selon π2(λ|x, θ(t)).
Il est alors simple de montrer que π(θ, λ|x) est la loi stationnaire de la
transition ci-dessus : si (θ(i−1), λ(i−1)) est distribu´e selon la loi jointe, λ(i−1)
est distribu´e selon la loi marginale π2(λ|x) et, par cons´equent, (θ(i), λ(i−1))
est toujours distribu´e selon la loi jointe. (En r´ealit´e, il faut s’assurer que le
support de la loi jointe soit ´egal au produit cart´esien des supports de π1 et
π2 ; voir Robert et Casella, 2004, Exemple 10.7, pour un contre-exemple.)
Le mˆeme raisonnement s’applique `a la deuxi`eme ´etape de l’algorithme et la
chaˆıne (θ(t), λ(t)) est ergodique de loi limite π. De plus, la structure duale de
l’algorithme ci-dessus conduit `a de bonnes propri´et´es de convergence, comme
l’ont montr´e Diebolt et Robert (1994) :
Lemme 6.17. Si π1(θ|x, λ) > 0 sur Θ (π2(λ|x, θ) > 0 sur Λ, respectivement),
les deux suites (θ(m)) et (λ(m)) sont des chaˆınes de Markov ergodiques de lois
invariantes π(θ|x) et π(λ|x), respectivement.
De plus, on peut montrer que, si la convergence est uniform´ement g´eom´e-
trique pour une des deux chaˆınes, par exemple si elle prend ses valeurs dans
un espace ﬁni, la convergence vers la loi stationnaire est aussi uniform´ement
g´eom´etrique pour l’autre chaˆıne. Cette propri´et´e est connue sous le nom de
principe de dualit´e (voir l’Exercice 6.28).

332
6 M´ethodes de calcul bay´esien
Exemple 6.18. (Suite de l’Exemple 6.15) Les lois conditionnelles sont
θ|x, λ ∼B(n, λ),
λ|x, θ ∼Be(α + θ, β + n −θ)
et rendent possible la mise en œuvre de l’´echantillonnage de Gibbs, mˆeme
s’il n’est pas n´ecessaire dans ce contexte. La Figure 6.3 donne une compa-
raison de l’histogramme d’un ´echantillon de cinq mille observations obte-
nues par ´echantillonnage par paquets (avec t = 10), et l’histogramme d’un
´echantillon de cinq mille observations θ simul´ees directement de la loi bˆeta-
binomiale. La forte ressemblance entre les deux montre que l’approximation
par l’´echantillonnage de Gibbs est tout `a fait acceptable.
∥
0
10
20
30
40
50
0.0
0.01
0.02
0.03
0.04
0.05
0
10
20
30
40
50
0.0
0.01
0.02
0.03
0.04
0.05
0
10
20
30
40
50
0.0
0.01
0.02
0.03
0.04
0.05
Fig. 6.3.
Histogrammes d’´echantillons de taille 5 000 de la loi bˆeta-binomiale de
param`etres n = 54, α = 3.4, et β = 5.2 : (gris fonc´e) simul´e directement ; (gris
clair) obtenu par ´echantillonnage de Gibbs.
6.3.4 Rao-Blackwellisation
Comme nous avons discut´e dans la Section 6.3.1, l’´echantillon θ(1), . . . , θ(m)
produit par ´echantillonnage de Gibbs peut ˆetre utilis´e de la mˆeme fa¸con
que celui obtenu par la m´ethode classique de Monte Carlo, mais Gelfand
et Smith (1990) remarquent que la structure conditionnelle de l’algorithme
d’´echantillonnage et l’´echantillon dual, λ(1), . . . , λ(m), devraient ˆetre exploit´es.
En eﬀet, si la quantit´e d’int´erˆet est Eπ[g(θ)|x], on peut utiliser la moyenne
des esp´erances conditionnelles
δ2 = 1
m
m

i=1
Eπ[g(θ)|x, λ(m)],

6.3 M´ethodes de Monte Carlo par chaˆınes de Markov
333
lorsque celles-ci peuvent ˆetre calcul´ees facilement, plutˆot que d’utiliser la
moyenne directe
δ1 = 1
m
m

i=1
g(θ(i)).
Cette modiﬁcation est fond´ee sur le th´eor`eme de Rao-Blackwell (voir le
Th´eor`eme 2.20). Si les λ(i) et les θ(i) ´etaient ind´ependants,
Eπ #
(δ1 −Eπ[g(θ)|x])2|x
$
= 1
mvarπ(g(θ)|x)
≥1
mvarπ (Eπ[g(θ)|x, λ]|x)
= Eπ #
(δ2 −Eπ[g(θ)|x, λ])2x
$
.
Liu et al. (1994) montrent que cette in´egalit´e est aussi toujours v´eriﬁ´ee pour
l’Algorithme 6.2 de Gibbs bivari´e, car cov(θ(0), θ(m)) est alors positive et
d´ecroˆıt en m (Exercice 6.30). L’estimateur δ2, baptis´e Rao-Blackwellisation,
domine donc δ1. (Mais cette domination ne s’´etend pas n´ecessairement `a
d’autres techniques MCMC, voir Liu et al., 1995, et Geyer, 1995.)
Exemple 6.19. (Casella et George, 1992) Soient les lois conditionnelles sui-
vantes (x est omis des notations) :
π(θ|λ) ∝λe−θλ,
0 < θ < B,
π(λ|θ) ∝θe−λθ,
0 < λ < B.
La loi marginale de θ (ou de λ) ne peut pas ˆetre calcul´ee, mais les lois condi-
tionnelles sont faciles `a simuler, car ce sont des exponentielles tronqu´ees.
Puisque Eπ[θ|λ] ≃1/λ pour B grand, Eπ[θ|x] peut ˆetre approch´e par
1
m
m

i=1
θi
ou
1
m
m

i=1
1
λi
.
Pour cet exemple particulier, la sym´etrie compl`ete entre les deux lois condi-
tionnelles implique que les deux estimateurs ont exactement les mˆemes pro-
pri´et´es probabilistes, en plus de converger vers la mˆeme valeur.
∥
Le mˆeme argument nous conduit `a proposer l’approximation de la densit´e
a posteriori π(θ|x) par la moyenne des densit´es conditionnelles
1
m
m

i=1
π(θ|x, λi),
plutˆot que par les m´ethodes d’estimation non param´etrique par noyau stan-
dard (voir Tanner et Wong, 1987, et Gelfand et Smith, 1990).

334
6 M´ethodes de calcul bay´esien
6.3.5 L’´echantillonnage de Gibbs g´en´eral
Une g´en´eralisation de l’Algorithme 6.2 de Gibbs bivari´e consiste `a consid´erer
plusieurs groupes de param`etres, θ, λ1, . . . , λp, tels que
π(θ|x) =

. . .

π(θ, λ1, . . . , λp|x) dλ1 · · · dλp .
(6.20)
Cette g´en´eralisation correspond par exemple `a l’introduction de niveaux addi-
tionnels dans le mod`ele hi´erarchique (6.19), pour des raisons de mod´elisation
ou de simulation, ou de d´ecomposition de l’hyperparam`etre λ ou du param`etre
θ en des composantes de plus petites dimensions.
Comme expliqu´e dans la Section 6.3.3 `a propos du proc´ed´e de Gibbs bi-
vari´e, l’´echantillonnage de Gibbs fournit des simulations de la loi jointe π(θ, λ1,
. . . , λp|x), lorsque certaines des lois conditionnelles associ´ees `a π sont dispo-
nibles. Bien entendu, lorsque π(θ|x) se d´ecompose elle-mˆeme en lois condi-
tionnelles, il n’y a pas besoin d’introduire des param`etres additionnels λi
(1 ≤i ≤p).
Exemple 6.20. (Suite de l’Exemple 6.15) Si la taille de la population n
suit une loi a priori de Poisson, P(ξ), la loi a posteriori jointe est
π(θ, λ, n|x) ∝
n
θ

λθ+α−1(1 −λ)n−θ+β−1e−ξ ξn
n!
et la loi marginale de θ ne peut pas ˆetre calcul´ee. En revanche, les lois condi-
tionnelles compl`etes ont des expressions explicites, car
θ|x, λ, ξ ∼B(n, λ),
λ|x, θ, ξ ∼Be(θ + α, n −θ + β),
n −θ|x, θ, λ ∼P(ξ(1 −λ)).
La simulation de ces trois lois conditionnelles est donc possible.
∥
Exemple 6.21. (Tanner et Wong, 1987) Soit un mod`ele multinomial
y ∼M5 (n; a1μ + b1, a2μ + b2, a3η + b3, a4η + b4, c(1 −μ −η)) ,
param´etr´e par μ et η, o`u
0 ≤a1 + a2 = a3 + a4 = 1 −
4

i=1
bi = c ≤1
et c, ai, bi ≥0 sont connus. Ce mod`ele correspond `a un ´echantillonnage selon
x ∼M9(n; a1μ, b1, a2μ, b2, a3η, b3, a4η, b4, c(1 −μ −η)),

6.3 M´ethodes de Monte Carlo par chaˆınes de Markov
335
et `a un regroupement de certaines composantes :
y1 = x1 + x2,
y2 = x3 + x4,
y3 = x5 + x6,
y4 = x7 + x8, y5 = x9.
Une loi a priori conjugu´ee pour (μ, η) et le mod`ele en x est la loi de Dirichlet
D(α1, α2, α3),
π(μ, η) ∝μα1−1ηα2−1(1 −η −μ)α3−1,
o`u α1 = α2 = α3 = 1/2 correspond `a un mod`ele non informatif. Dans ce cadre,
la loi a posteriori de (μ, η) ne peut ˆetre obtenue de fa¸con explicite. Cependant,
si nous introduisons les donn´ees manquantes z = (x1, x3, x5, x7), qui ne sont
pas observ´ees (et donc bien manquantes), x est en relation bijective avec (y, z)
et
π(η, μ|y, z) = π(η, μ|x)
∝μz1μz2ηz3ηz4(1 −η −μ)y5+α3−1μα1−1ηα2−1 ,
o`u nous d´esignons les coordonn´ees de z par (z1, z2, z3, z4). Par cons´equent,
μ, η|y, z ∼D(z1 + z2 + α1, z3 + z4 + α2, y5 + α3).
De plus,
zi|y, μ, η ∼B

yi,
aiμ
aiμ + bi

(i = 1, 2),
zi|y, μ, η ∼B

yi,
aiη
aiη + bi

(i = 3, 4).
En d´eﬁnissant θ = (μ, η) et λ = z, il apparaˆıt donc que certaines lois condi-
tionnelles peuvent ˆetre simul´ees dans ce cadre. Notons que les donn´ees man-
quantes z n’apparaissent pas dans la formulation originelle du probl`eme et
sont peut-ˆetre artiﬁcielles, au sens o`u le mod`ele consid´er´e ne correspond pas
n´ecessairement `a un mod`ele multinomial global. Cependant, ces donn´ees man-
quantes facilitent consid´erablement la simulation des θ tout en pr´eservant leur
loi marginale. D’autres mod`eles `a donn´ees manquantes pr´esentent le mˆeme
avantage.
∥
Dans ce cadre hi´erarchique g´en´eral, la mise en œuvre de l’´echantillonnage
de Gibbs peut ˆetre faite de plusieurs fa¸cons. Si la d´ecomposition de (θ, λ) en
(θ, λ1, . . . , λp) correspond `a une d´ecomposition du mod`ele selon ses niveaux
hi´erarchiques, c’est-`a-dire
π(θ|x) =

..

π1(θ|λ1, x)π2(λ1|λ2)..πp+1(λp) dλ1 · · dλp,
(6.21)
il semble logique de simuler selon les lois conditionnelles

336
6 M´ethodes de calcul bay´esien
π(θ|x, λ1, . . . , λp) = π1(θ|λ1, x),
π(λi|x, θ, (λj)j̸=i) = π(λi|λi−1, λi+1)
(1 < i < p),
π(λ1|x, θ, (λj)j̸=1) = π(λ1|θ, λ2),
(6.22)
π(λp|x, θ, (λj)j̸=p) = π(λp|λp−1),
quelles que soient les dimensions de θ et λj (Exercice 6.32). Dans l’Exemple
6.21 notamment, (μ, η) pourrait ˆetre g´en´er´e conditionnellement `a (y, z) selon
une loi de Dirichlet et z conditionnellement `a (μ, η).
Un algorithme alternatif ´egalement propos´e par Gelfand et Smith (1990)
est l’´echantillonneur de Gibbs direction par direction, qui ne prend pas en
compte les divisions hi´erarchiques et ne consid`ere que les param`etres unidi-
mensionnels, aﬁn de les g´en´erer conditionnellement aux autres param`etres.
Exemple 6.22. (Suite de l’Exemple 6.21) Puisque
μ
1 −η |y, z, η ∼Be(z1 + z2 + α1, y5 + α3),
η
1 −μ|y, z, μ ∼Be(z3 + z4 + α2, y5 + α3),
cette version de l’´echantillonnage de Gibbs conduit `a une simulation it´erative
de
μ(t) ∼(1 −η(t−1))Be

z(t−1)
1
+ z(t−1)
2
+ α1, y5 + α3

,
η(t) ∼(1 −μ(t))Be

z(t−1)
3
+ z(t−1)
4
+ α2, y5 + α3

,
z(t)
j
∼B

yj,
ajμ(t)
ajμ(t) + bj

(j = 1, 2),
(6.23)
z(t)
j
∼B

yj,
ajη(t)
ajη(t) + bj

(j = 3, 4).
La diﬀ´erence avec la simulation de (μ, η, z) dans l’Exemple 6.21 est donc
mineure.
∥
La formulation g´en´erale de l’algorithme d’´echantillonnage de Gibbs pour
une loi jointe π(θ1, . . . , θp), de lois conditionnelles compl`etes π1, . . . , πp est
expos´ee ci-dessous.
Algorithme 6.3. –´Echantillonnage de Gibbs–
Pour (θ(t)
1 , . . . , θ(t)
p ) donn´es, simuler
1. θ(t+1)
1
∼π1(θ1|θ(t)
2 , . . . , θ(t)
p ),
2. θ(t+1)
2
∼π2(θ2|θ(t+1)
1
, θ(t)
3 , . . . , θ(t)
p ),

6.3 M´ethodes de Monte Carlo par chaˆınes de Markov
337
...
p. θ(t+1)
p
∼πp(θp|θ(t+1)
1
, . . . , θ(t+1)
p−1 ).
La validation de l’algorithme de Gibbs bivari´e ci-dessus s’´etend `a ce cas :
la loi jointe π est stationnaire `a chaque ´etape de cet algorithme, car les πj sont
des lois conditionnelles compl`etes de π. Sous la contrainte de positivit´e que le
support de π est le produit cart´esien des supports des πi, la chaˆıne r´esultante
est ergodique.
Compar´e `a l’algorithme de Metropolis-Hastings, le nombre de versions de
l’´echantillonnage de Gibbs est faible et, de plus, les diﬀ´erences entre les pro-
pri´et´es de convergence sont souvent mineures. L’approche de (6.22) (aussi
appel´ee ´echantillonnage de substitution dans Gelfand et Smith, 1990) de-
vrait malgr´e tout ˆetre pr´ef´erable `a une approche direction par direction, car
elle respecte la structure hi´erarchique initiale du mod`ele et converge sou-
vent plus rapidement vers la loi stationnaire (voir Liu et al., 1994, 1995, et
Roberts et Sahu, 1997). L’´echantillonnage de Gibbs bivari´e est le seul cas
d’´echantillonnage de Gibbs produisant une chaˆıne de Markov pour `a la fois
(θ(t)) et (λ(t)) ; dans tout autre proc´ed´e, les sous-chaˆınes ne sont pas des
chaˆınes de Markov (Exercice 6.33).
Cependant, pour ˆetre capable d’utiliser l’´echantillonnage de Gibbs bivari´e
ou mˆeme l’´echantillonnage de substitution, on a besoin des lois condition-
nelles pour tout niveau hi´erarchique (comme π(η, μ|y, z) dans l’Exemple 6.21)
et celles-ci peuvent ˆetre plus diﬃciles `a calculer que les lois conditionnelles
compl`etes (voir l’Exercice 6.50). De plus, l’´echantillonnage de Gibbs ne re-
quiert pas en r´ealit´e que les θi soient unidimensionnels et le choix de la
d´ecomposition peut alors ˆetre enti`erement fond´e sur des raisons de simula-
tion. Notons aussi que, lorsque des lois conditionnelles, comme π(θ|x, λi0),
peuvent ˆetre simul´ees, il est bien entendu pr´ef´erable d’utiliser ces lois, car
elles augmentent la vitesse de convergence en r´eduisant la d´ependance en
les autres param`etres. (Cette technique est appel´ee regroupement ; voir par
exemple Roberts et Sahu, 1997.) Une derni`ere remarque importante en pra-
tique est que, chaque fois que la simulation d’une loi conditionnelle donn´ee
πi(θi|θj, j ̸= i) est diﬃcile, cette ´etape de simulation peut ˆetre remplac´ee par
une seule ´etape de Metropolis-Hastings de loi cible πi(θi|θj, j ̸= i). Ceci peut
sembler constituer un m´ecanisme d’approximation rudimentaire, mais ce n’est
pas le cas : le remplacement d’une simulation de πi(θi|θj, j ̸= i) par une ´etape
de Metropolis-Hastings ne modiﬁe pas la loi stationnaire de la chaˆıne, et est
donc enti`erement valable d’un point de vue MCMC.
Exemple 6.23. (Suite de l’Exemple 6.16)
Lorsque N, la taille de la
population, est le param`etre d’int´erˆet, l’´echantillonnage de Gibbs fournit un
´echantillon N1, . . . , Nm, partant de la valeur initiale de p = (p(0)
1 , . . . , p(0)
n ), en

338
6 M´ethodes de calcul bay´esien
simulant it´erativement
N (j) −x+|x, p(j−1) ∼N eg(x+, ϱ(j−1)),
p(j)
i |x, N (j) ∼Be(α + xi, β + N (j) −xi)
(1 ≤i ≤n).
(Il s’agit en fait d’un cas d’´echantillonnage de Gibbs bivari´e.) L’´echantillon
N1, . . . , Nm est alors obtenu en prenant N1 = N (k0+T ), N2 = N (k0+2T ),
. . ., Nm = N (k0+mT ), o`u k0 repr´esente le temps de “chauﬀe”, c’est-`a-dire
le nombre de r´ep´etitions pour devenir raisonnablement proche de la station-
narit´e, et T est la taille du paquet, c’est-`a-dire le nombre de r´ep´etitions
pour accomplir l’ind´ependance approximative entre les points de l’´echantillon.
L’´echantillonnage de Gibbs fournit simultan´ement un ´echantillon p1, . . . , pm.
L’esp´erance Eπ[N|x] peut alors ˆetre approch´ee par
ˆδπ(x) = 1
m
m

t=1
Eπ[N|x, pt]
= 1
m
m

t=1

1 −
n

i=1
(1 −pt
i)
 −1
x+,
selon l’argument de “Rao-Blackwellisation” mentionn´e ci-dessus. George et
Robert (1992) fournissent des extensions hi´erarchiques dans ce cadre en
consid´erant diﬀ´erentes familles de lois a priori pour les hyperparam`etres (α, β)
qui deviennent eux-mˆemes al´eatoires.
∥
Une comparaison g´en´erale entre algorithmes de Metropolis-Hastings et
´echantillonnage de Gibbs n’a pas de sens : suivant le probl`eme consid´er´e
et le choix de lois propos´ees ou de d´ecompositions hi´erarchiques, un algo-
rithme peut converger plus rapidement qu’un autre. Le seul avertissement
que nous pouvons fournir ici est que, contrairement `a une croyance r´epandue,
l’´echantillonnage de Gibbs n’est pas n´ecessairement une solution optimale. En
eﬀet, mˆeme si cet algorithme se construit directement `a partir de la loi cible π
et ne fait donc pas intervenir un apport subjectif de l’exp´erimentateur, le fait
qu’il mette `a jour une composante de la chaˆıne (ou un bloc) `a la fois peut aﬀai-
blir de beaucoup ses propri´et´es de convergence si la loi a un support tr`es ´etroit
ou multimodal. Au contraire, un algorithme de Metropolis-Hastings utilisant
un m´ecanisme de proposition `a marche al´eatoire peut ˆetre ineﬃcace si la forme
ou l’´echelle de la loi propos´ee ne sont pas ajust´ees au support de π ; en re-
vanche, cette approche peut aussi permettre de grands sauts pouvant atteindre
des modes plus ´eloign´es de π. Nous pourrions qualiﬁer les ´echantillonneurs de
Gibbs d’algorithmes locaux et les techniques de Metropolis-Hastings `a marche
al´eatoire d’algorithmes globaux au sens o`u, grossi`erement, les premiers four-
nissent souvent une meilleure image des alentours du point de d´epart, tan-
dis que les seconds explorent le support de π sur une plus large ´echelle
(voir Besag, 2000, pour une discussion plus d´etaill´ee). La meilleure solu-
tion `a ce dilemme est alors de proﬁter des caract´eristiques positives de ces

6.3 M´ethodes de Monte Carlo par chaˆınes de Markov
339
diﬀ´erents ´echantillonneurs en les combinant en un algorithme hybride incor-
porant diﬀ´erentes ´etapes MCMC, de fa¸con d´eterministe ou al´eatoire.
6.3.6 L’´echantillonnage par tranche
L’´echantillonnage de Gibbs peut apparaˆıtre `a ce stade comme une m´ethode
MCMC particuli`ere qui ne peut ˆetre utilis´ee que dans un cadre relativement
restrictif : il fait intervenir des structures hi´erarchiques, comme dans (6.19)
et ne s’applique donc pas `a des probl`emes unidimensionnels ; il n´ecessite la
connaissance des lois conditionnelles compl`etes et ne peut donc s’appliquer `a
des mod`eles complexes.
Cette perception de l’´echantillonnage de Gibbs est erron´ee : comme
nous allons le voir tout de suite, cette m´ethode s’applique aussi `a des
probl`emes unidimensionnels, elle ne requiert pas une simulation des lois condi-
tionnelles compl`etes, et elle s’applique aux mˆemes mod`eles que les autres
m´ethodes MCMC. En fait, la d´ecomposition hi´erarchique (6.19) n’est pas par-
ticuli`erement restrictive. En eﬀet, de nombreuses lois (des observations ou des
param`etres) peuvent s’´ecrire comme des m´elanges cach´es, pour un param`etre
λ totalement artiﬁciel (voir la Note 6.6.3). Par cons´equent, mˆeme lorsqu’une
structure hi´erarchique n’apparaˆıt pas dans le probl`eme original, elle peut sou-
vent ˆetre r´eintroduite pour am´eliorer le calcul des estimateurs de Bayes ou
mˆeme le choix de la loi a priori.
La g´en´eralit´e de l’´echantillonnage de Gibbs est mise en ´evidence dans la
version particuli`ere dite de l’´echantillonnage par tranche (Wakeﬁeld et al.,
1991, Besag et Green, 1993, et Damien et al., 1999). Consid´erons une loi π(θ)
sur un ensemble g´en´eral Θ, uni- ou multidimensionnel, et r´e´ecrivons π comme
le produit
π(θ) =
k

i=1
ϖi(θ),
(6.24)
o`u les ϖi sont des fonctions positives, mais non n´ecessairement des densit´es.
Alors π(θ) peut s’´ecrire comme la loi marginale
π(θ) =

k

i=1
I0≤ωi≤ϖi(θ) d ω1 · · · d ωk .
L’´echantillonnage par tranche correspondant s’obtient directement :
Algorithme 6.4. –´Echantillonnage par tranche–
`A l’it´eration t, simuler
1. ω(t+1)
1
∼U[0,ϖ1(θ(t))]
...

340
6 M´ethodes de calcul bay´esien
k. ω(t+1)
k
∼U[0,ϖk(θ(t))]
k+1. θ(t+1) ∼UA(t+1), avec
A(t+1) = {ξ; ϖi(ξ) ≥ω(t+1)
i
, i = 1, . . . , k}.
Les ωj sont un type particulier de variables auxiliaires, sans signiﬁcation
pour le probl`eme statistique consid´er´e. Notons qu’il existe de nombreuses
repr´esentations possibles (6.24) pour la mˆeme loi π, notamment le cas simple
π(θ) =
 1
0
I0≤ω≤π(θ)dω ,
et que le choix d’une repr´esentation est purement dict´e par son caract`ere
pratique. En fait, la derni`ere ´etape (k+1) dans l’algorithme ci-dessus peut
ˆetre d´elicate `a mettre en œuvre, puisque l’ensemble A(t) est souvent diﬃcile
`a construire, mais cette d´ecomposition montre que l’´echantillonnage de Gibbs
peut fournir, au moins formellement, une repr´esentation de toutes les lois (voir
Roberts et Rosenthal, 1998, Tierney et Mira, 1998 et Mira et al., 2001, pour
des propri´et´es th´eoriques de l’´echantillonnage par tranche.)
Exemple 6.24. (Suite de l’Exemple 6.13) La loi jointe de (α, η) ´etant
π(α, η|x1, . . . , xn) ∝αnηn+β−1
 n

i=1
xi
 α
exp

−η
n

i=1
xα
i −α −ξη

,
la loi conditionnelle π1(η|α, x1, . . . , xn) est tout simplement la loi
G (β + n, ξ +

i
xα
i )
qui est facile `a simuler. La loi conditionnelle π2(α|η, x1, . . . , xn) est beaucoup
plus complexe `a cause de la partie exponentielle faisant intervenir les xα
i . Si
nous ´ecrivons cette loi comme αnχα exp(−η n
i=1 xα
i ), nous pouvons l’expri-
mer comme la loi marginale (en α) de
αnI0≤ω0≤χα
n

i=1
I0≤ωi≤exp(−ηxα
i ) .
La loi conditionnelle de α sachant η et les ωi est alors proportionnelle `a
αnIα log(χ)≤log(ω0)
n

i=1
Iα log(xi)≤log{−log(ωi)/η} ,
c’est-`a-dire une simple loi puissance αn sur un intervalle (α, α). L’´echantillon-
nage de Gibbs de la loi a posteriori de Weibull s’obtient alors par simulation
it´erative des η, des ωi et des α.
∥

6.3 M´ethodes de Monte Carlo par chaˆınes de Markov
341
Exemple 6.25. (Suite de l’Exemple 6.5) Puisque la loi a posteriori de
θ = (μ1, σ2
1, p, μ2, σ2
2) admet une expression analytique,
π(θ|x) ∝˜π(θ|x) = π(θ)
n

i=1
{pϕ(xi; μ1, σ1) + (1 −p)ϕ(xi; μ2, σ2)} ,
un ´echantillonneur par tranche formel admettant une variable auxiliaire
unique ω peut ˆetre propos´e, avec θ ∼U˜π(θ|x)≥ω. Mais il est impossible de
simuler cette loi uniforme, puisque la contrainte ˜π(θ|x) ≥ω ne peut pas ˆetre
transform´ee en une contrainte sur θ. Une version utilisable de l’´echantillonnage
par tranche dans ce cadre peut se construire en introduisant plutˆot n variables
auxiliaires ωi de telle mani`ere que ˜π(θ|x) s’´ecrive comme la loi marginale de
π(θ)
n

i=1
Ipϕ(xi;μ1,σ1)+(1−p)ϕ(xi;μ2,σ2)≥ωi≥0 .
Bien que la loi jointe de θ conditionnelle aux ωi ne soit pas toujours disponible,
les lois conditionnelles compl`etes des param`etres μ1, σ2
1, p, μ2 et σ2
2 sont
simples `a simuler. (Comme nous le verrons dans la Section 6.4, qui traite
des m´elanges, l’´echantillonneur de Gibbs initialement propos´e pour ce mod`ele
repose aussi sur la simulation de n variables auxiliaires.)
∥
6.3.7 L’impact des m´ethodes MCMC sur la statistique bay´esienne
Cette section a pr´esent´e tr`es bri`evement les bases des m´ethodes MCMC,
et donn´e quelques illustrations tir´ees des probl`emes de calcul bay´esien. Il est
important de souligner `a ce stade que l’apparition de ces outils MCMC en sta-
tistique bay´esienne a eu un eﬀet “d´evastateur”! En eﬀet, elle a radicalement
modiﬁ´e la fa¸con dont les gens travaillent avec des mod`eles et des hypoth`eses
a priori, permettant de prendre en compte des structures beaucoup plus com-
plexes, comme par exemple dans le cas des mod`eles graphiques o`u les relations
entre variables ne sont d´eﬁnies qu’`a un niveau local, la loi jointe ´etant im-
possible `a concevoir (voir Cowell et al., 1999, et Note 10.7.1). De mˆeme, les
mod`eles `a variables latentes comme les mod`eles de chaˆınes de Markov cach´ees
ou `a volatilit´e stochastique, peuvent d´esormais ˆetre correctement analys´es
(voir la Note 6.6.5 et Robert et Casella, 1999, Chapitre 9) alors que seules des
approximations grossi`eres ´etaient disponibles par le pass´e, un changement qui
a eu un impact immense en traitement du signal bay´esien, en ´econom´etrie et
en ﬁnance math´ematique.
La “d´evastation” mentionn´ee ci-dessus concerne aussi les structures rigides
autrefois impos´ees par la contrainte d’un traitement analytique ; par exemple,
le recours `a des lois conjugu´ees n’est plus indispensable, mˆeme si celles-ci
restent tr`es utiles comme lois a priori de base pour les diﬀ´erents niveaux d’une

342
6 M´ethodes de calcul bay´esien
mod´elisation hi´erarchique (voir le Chapitre 10). De mˆeme, des repr´esentations
beaucoup plus ﬂexibles peuvent ˆetre propos´ees dans le domaine du choix de
mod`ele, comme nous le verrons au Chapitre 7, o`u la possibilit´e de prendre en
compte de nombreux mod`eles simultan´ement incite le statisticien `a passer des
tests au sens strict au moyennage de mod`eles, les mod`eles les plus probables
obtenant les poids les plus ´elev´es mais sans ´ecarter aucun mod`ele a priori ;
voir aussi Berger (2000), Capp´e et Robert (2000) et Gelfand (2000) pour des
revues sur l’impact des m´ethodes MCMC.
Comme toujours, un accroissement signiﬁcatif de la facilit´e `a utiliser une
technique donn´ee s’accompagne d’un accroissement proportionnel des possibi-
lit´es de d´etournements de cette technique. Dans le cas de l’analyse bay´esienne,
cela signiﬁe que l’impact d’une mod´elisation a priori est plus diﬃcile `a ´evaluer
`a partir des lois conditionnelles utilis´ees en ´echantillonnage de Gibbs. Pis, la
loi a posteriori peut ˆetre impropre (Section 1.5) sans que son utilisateur en soit
conscient (voir la Note 6.6.4). Mais ces d´efauts ne peuvent pas se comparer
avec les cons´equences sur la port´ee et le nombre d’applications bay´esiennes
rencontr´ees depuis dans la litt´erature, incluant la r´esolution de probl`emes
inf´erentiels jamais consid´er´es auparavant.
6.4 Estimation bay´esienne de m´elanges
Nous concluons ce chapitre en montrant comment les m´ethodes MCMC
permettent le calcul d’estimateurs de Bayes des param`etres d’un m´elange de
lois normales consid´er´e dans l’Exemple 6.5. L’extension `a d’autres m´elanges
de lois appartenant `a une famille exponentielle ou `a des mod`eles `a chaˆınes de
Markov cach´ees est triviale (voir Gruet et al., 1999, et Robert et Casella, 2004,
Notes 9.7.1 et 14.6.3). Comme nous l’avons d´etaill´e dans la Section 6.1, une
analyse bay´esienne d’un mod`ele de m´elange m`ene au paradoxe de l’informa-
tion suivant : un estimateur explicite est disponible et est justiﬁable intuitive-
ment, mais il ne peut pas ˆetre calcul´e lorsque le nombre d’observations devient
trop grand. De plus, les estimateurs du maximum de vraisemblance des pa-
ram`etres de (6.4) ne sont pas clairement d´eﬁnis, la r´esolution des ´equations de
vraisemblance est diﬃcile et les approximations analytiques des estimateurs
de Bayes posent probl`eme (voir Crawford et al., 1992 , pour une approche re-
posant sur l’approximation de Laplace). De mˆeme, un traitement Monte Carlo
standard des mod`eles de m´elanges est ardu mˆeme si Casella et al. (2000) ont
propos´e une m´ethode fond´ee sur l’´echantillonnage d’importance dans un cadre
conjugu´e (Exercice 6.42) ; voir la Note 6.6.6 pour de plus amples r´ef´erences et
des d´etails sur les d´ebuts de l’estimation de m´elanges.
L’´echantillonnage de Gibbs pour les m´elanges repose sur une repr´esentation
par donn´ees manquantes, comme dans Dempster et al. (1977), aﬁn de cons-
truire une structure hi´erarchique similaire `a (6.19). Soit

6.4 Estimation bay´esienne de m´elanges
343
x ∼f(x|θ) =
k

i=1
piϕ(x; μi, σi),
(6.25)
un m´elange de k lois normales de moyennes μi et variances σ2
i (1 ≤i ≤k), avec

i pi = 1 (pi > 0). Pour un ´echantillon x1, . . . , xn donn´e de (6.25), on d´eﬁnit
les valeurs manquantes zj (1 ≤j ≤n) comme les vecteurs d’indicatrices de
composantes des xj, c’est-`a-dire
zij =

1
si xj ∼ϕ(x; μi, σi),
0
sinon,
et 
i zij = 1. Ce vecteur peut aussi ˆetre consid´er´e comme un param`etre
suppl´ementaire; il correspond `a la loi jointe suivante (1 ≤j ≤n) :
zj|θ ∼Mp(1; p1, . . . , pk) ,
xj|zj, θ ∼N
 k

i=1
μzij
i ,
k

i=1
σ2zij
i
 
.
Une loi a priori commode pour θ = (μ1, σ1, p1, . . . , μk, σk, pk) est le produit
des lois conjugu´ees πi(μi, σi), o`u πi(μi|σi) est une loi normale N (ξi, σ2
i /ni),
πi(σ2
i ) une loi gamma inverse I G (νi/2, s2
i /2), et π(p) une loi de Dirichlet,
D(α1, . . . , αk), comme dans l’Exemple 6.5.
Notons que, une fois connus les vecteurs d’allocation zj (1 ≤j ≤n),
la structure de m´elange disparaˆıt, puisque cette information suppl´ementaire
d´ecompose l’´echantillon en sous-´echantillons selon les valeurs de zij. Bien que
la loi a posteriori de θ ne puisse pas ˆetre utilis´ee directement, comme le montre
l’Exemple 6.5, le conditionnement en z = (z1, . . . , zn) supprime cette diﬃcult´e.
En eﬀet, on obtient les lois a posteriori suivantes (1 ≤j ≤n) :
zj|xj, θ ∼Mk(1; p1(xj, θ), . . . , pk(xj, θ)),
(6.26)
avec (1 ≤i ≤k)
pi(xj, θ) =
piϕ(xj; μi, σi)
k
t=1 ptϕ(xj; μt, σt)
,
et
μi|x, z, σi ∼N (ξi(x, z), σ2
i /(n + σ2
i )),
(6.27)
σ2
i |x, z ∼I G
νi + ni
2
, 1
2

s2
i + ˆs2
i (x, z) +
nimi(z)
ni + mi(z)(¯xi(z) −ξi)2

,
p|x, z ∼Dk(α1 + m1(z), . . . , αk + mk(z)),
o`u
mi(z) =
n

j=1
zij,
¯xi(j) =
1
mi(z)
n

j=1
zijxj,

344
6 M´ethodes de calcul bay´esien
et
ξi(x, z) = niξi + mi(z)¯xi(z)
ni + mi(z)
,
ˆs2
i (x, z) =
n

j=1
zij(xj −¯xi(z))2.
Conditionnellement `a z, les lois a posteriori ne prennent en compte que
les sous-´echantillons correspondant `a chaque composante, `a l’instar de la
d´ecomposition (6.6) de la vraie loi a posteriori. De plus, simuler selon (6.26)
et (6.27) est particuli`erement simple. Il est donc beaucoup plus facile de pro-
duire un ´echantillon θ1, . . . , θm de π(θ|x) par ´echantillonnage de Gibbs que
d’utiliser la vraie loi a posteriori directement.
La remarque qui suit le Lemme 6.17 implique que l’´echantillonnage de
Gibbs entraˆıne une convergence g´eom´etrique uniforme de la chaˆıne (θ(m)),
puisque z a un support ﬁni.
Comme derni`ere remarque, nous soulignons que l’´echantillonnage de Gibbs
n’est pas la seule solution pour la simulation de la loi a posteriori π(θ|x).
En eﬀet, comme le montre l’Exemple 6.25, une expression analytique de
cette loi est disponible : elle peut donc ˆetre utilis´ee dans un algorithme de
Metropolis-Hastings (en plus de l’´echantillonnage par tranche produit dans
l’Exemple 6.25). Par exemple, Celeux et al. (2000) d´emontrent que la strat´egie
de Metropolis-Hastings par marche al´eatoire peut ˆetre utilis´ee de fa¸con eﬃ-
cace dans ce cadre et admet de meilleures propri´et´es de m´elangeance que
l’´echantillonnage de Gibbs. Dans le cas des mod`eles de chaˆınes de Markov
cach´ees, qui g´en´eralisent les mod`eles de m´elange comme (6.25) en introdui-
sant une d´ependance markovienne entre les zj, il existe aussi dans certains
cas des repr´esentations analytiques de la vraisemblance par int´egration sur
les variables latentes ; voir les Exercices 6.50 et 6.51, et Robert et al. (1999a)
.
6.5 Exercices
Section 6.1
6.1 Pour un m´elange de deux lois normales, comme celui de l’Exemple 6.5 et les
donn´ees de la Table 6.1, identiﬁer les hyperparam`etres des lois conditionnelles
par la m´ethode des moments.
6.2 Dans le cadre de l’Exemple 6.5, montrer que la loi a posteriori peut en fait
s’´ecrire sous la forme (6.6), et d´evelopper ω(kt) et π(θ|(kt)). Donner les expres-
sions des estimateurs de Bayes de μ1, σ1 et p pour les hyperparam`etres obtenus
dans l’Exemple 6.21.
6.3 Mˆemes questions que l’Exercice 6.2 pour
(i) un m´elange de deux lois exponentielles ; et
(ii) un m´elange de trois lois uniformes.

6.5 Exercices
345
6.4 Dans l’Exercice 6.2, comment ´evolue le temps de calcul en fonction de la taille
d’´echantillon lorsque
(i) seul le poids p est inconnu ? et
(ii) tous les param`etres sont inconnus ?
6.5 *(Smith et Makov, 1978) Soit
x ∼f(x|p) =
k
X
i=1
pifi(x),
avec pi > 0, P
i pi = 1, les densit´es fi ´etant connues. L’a priori π(p) est une loi
de Dirichlet D(α1, . . . , αk).
a. Montrer que le temps de calcul reste prohibitif malgr´e la simplicit´e du
mod`ele lorsque la taille d’´echantillon augmente.
Une solution alternative s´equentielle, permettant une approximation de l’esti-
mateur de Bayes, est de remplacer π(p|x1, . . . , xn) par D(α(n)
1 , . . . , α(n)
k ), o`u
α(n)
1
= α(n−1)
1
+ P(zn1 = 1|xn), . . . , α(n)
k
= α(n−1)
k
+ P(znk = 1|xn),
et zni (1 ≤i ≤k) est le vecteur d’indicatrices des composantes de xn, d´eﬁni en
Section 6.4.
b. Justiﬁer cette approximation et la comparer avec la mise `a jour π(p|x1, . . . ,
xn−1) pour xn observ´e.
c. ´Etudier les performances de cette approximation pour un m´elange de deux
lois normales N (0, 1) et N (2, 1) pour p = 0.1, 0.25, 0.5.
d. Si πn
i = P(zni = 1|xn), montrer que
ˆp(n)
i
(xn) = ˆp(n−1)
i
(xn−1) −an−1{ˆp(n−1)
i
−πn
i },
o`u ˆp(n)
i
est l’approximation quasi bay´esienne de Eπ(pi|x1, . . . , xn).
6.6 Dans le cadre de l’Exemple 6.4, d´eterminer la loi a posteriori de π(N|x) : (a)
pour n = 10 et des xi prenant des valeurs similaires ; et (b) pour n = 30 et
des xi prenant des valeurs tr`es diﬀ´erentes. Traiter le mˆeme probl`eme lorsque
π(N) est une loi de Poisson P(λ) et λ varie. Faire particuli`erement attention
aux probl`emes potentiels li´es `a une ´evaluation directe.
Section 6.2.1
6.7 *(Morris, 1982) Pour les familles exponentielles naturelles `a variance quadra-
tique ´etudi´ees dans les Exercices 3.24 et 10.33, on pose
Pm(x, μ) = V m(μ)
j dm
dμm f(x|μ)
ﬀﬃ
f(x|μ).
a. Montrer que Pm est un polynˆome de degr´e m en x et μ.
b. Montrer que (m > 1)
Pm+1(x, μ) = [P1(x, μ) −mV ′(μ)]
Pm(x, μ)
−m[1 + (m −1)v2]V (μ)Pm−1(x, μ),
o`u V (μ) = v0 + v1μ + v2μ2.

346
6 M´ethodes de calcul bay´esien
c. Montrer que les polynˆomes Pm sont orthogonaux et que Eμ[P 2
m(x, μ)] =
amV m(μ).
d. Donner les polynˆomes associ´es aux lois normale, de Poisson, gamma, bino-
miale et binomiale n´egative. [Note : Il s’agit respectivement des polynˆomes
d’Hermite, de Poisson-Charlier, g´en´eralis´es de Laguerre, de Krawtchouk et
de Meixner.]
Section 6.2.2
6.8 Montrer que, si le support de h ne contient pas celui de f(x|θ)π(θ), l’approxi-
mation par ´echantillonnage d’importance (6.11) ne converge pas.
6.9 La m´ethode standard de simulation d’acceptation-rejet
est d´eﬁnie `a partir de
densit´es f et g telles que f(x) ≤Mg(x) pour un certain M par l’algorithme :
Algorithme 6.5. –Acceptation-Rejet–
1. Tirer y ∼g(y) et u ∼U[0,1] ;
2. Si u > f(y)/Mg(y), revenir en 1.
3. Prendre x = y.
Montrer que cet algorithme fournit bien une observation x de loi f(x).
6.10 Montrer que, si U1, U2 sont iid U[0,1],
1. Les transformations
X1 =
p
−2 log(U1) cos(2πU2) ,
X2 =
p
−2 log(U1) sin(2πU2) ,
sont iid N (0, 1).
2. Les coordonn´ees polaires sont de lois
r2 = X2
1 + X2
2 ∼χ2
2 ,
θ = arctan X1
X2 ∼U [0, 2π].
3. En d´eduire l’algorithme de Box-Muller (Box et Muller, 1958) de g´en´eration
de lois normales :
Algorithme 6.6. –Box-Muller (1)–
1. G´en´erer
U1, U2 ∼U ([0, 1])
2. Prendre
X1 =
p
−2 log(U1) cos(2πU2) ,
X2 =
p
−2 log(U1) sin(2πU2) ,
6.11 (Suite de l’Exercice 6.9)
1. Montrer qu’une version plus rapide de l’Algorithme 6.6 de Box–Muller est :
Algorithme 6.7. –Box-Muller (2)–

6.5 Exercices
347
1. G´en´erer
U1, U2 ∼U ([−1, 1])
jusqu’`a ce que S = U 2
1 + U 2
2 ≤1.
2. Poser Z =
p
−2 log(S)/S et d´eduire
X1 = Z U1,
X2 = Z U2.
en montrant que (U1, U2) est uniforme sur la boule unit´e et que X1 et X2
sont ind´ependants.
2. Donner le nombre moyen de g´en´erations dans l’´etape 1. et comparer avec
l’Algorithme 6.6 via une exp´erience informatique.
3. Que se passe-t-il si l’on ne restreint pas (U1, U2) `a la boule unit´e ?
6.12 *(Gilks et Wild, 1992) On consid`ere une m´ethode g´en´erale d’acceptation-rejet
pour des densit´es log-concaves sur R. Cette m´ethode est fond´ee sur des bornes
sup´erieures et inf´erieures adaptatives de la densit´e, qui sont mises `a jour apr`es
chaque simulation.
a. Pour f(x) donn´e, proportionnel `a la densit´e `a simuler, on suppose qu’il
existe u(x) et ℓ(x), bornes sup´erieure et inf´erieure de f(x) telles que u soit
une densit´e. L’algorithme d’acceptationrejet avec enveloppe s’´ecrit :
Algorithme 6.8. –Simulation par enveloppe–
R´ep´eter
a) G´en´erer x ∼u(x) et U ∼U[0,1]
b) Accepter x si U ≤ℓ(x)/u(x)
c) Sinon, accepter x si U ≤f(x)/u(x)
jusqu’`a ce que x soit accept´e.
Montrer que cette m´ethode produit bien une variable al´eatoire de loi f.
b. Les deux fonctions encadrantes peuvent ˆetre construites automatiquement
comme suit, pour f log-concave. Pour la premi`ere simulation, prendre trois
valeurs arbitraires x1, x2 > x1 et x3 > x2 telles qu’au moins une d’entre
elles soit de chaque cˆot´e du mode de f. (Expliquer comment cela peut ˆetre
fait sans calcul explicite du mode.) Montrer que la borne inf´erieure log ℓ(x)
de log f(x) peut ˆetre obtenue en joignant les trois points (xi, log f(xi)) et
en posant ℓ(x) = 0 en dehors de l’intervalle [x1, x3]. La borne sup´erieure
log u(x) est obtenue en prenant les compl´ements des segments utilis´es pour
log ℓ(x) jusqu’`a ce qu’ils se croisent : les queues consistent alors en des
extensions des arcs (x1, x2) et (x2, x3) ; log u(x) est compl´et´e par l’ajout
de segments verticaux passant par x1 et x3 et continuant jusqu’`a ce qu’ils
rencontrent les deux arcs.
c. Proposer une m´ethode de mise `a jour des bornes sup´erieure et inf´erieure
apr`es chaque simulation n´ecessitant le calcul de f(x).
d. Montrer que les deux fonctions u(x) et ℓ(x) sont exponentielles par mor-
ceaux et indiquer comment simuler des lois de densit´e proportionnelle `a ces
fonctions.

348
6 M´ethodes de calcul bay´esien
e. Illustrer l’algorithme ci-dessus pour la simulation de la loi N (0, 1). `A par-
tir de quand devient-il plus coˆuteux d’´evaluer et de simuler une borne
sup´erieure am´elior´ee, plutˆot que de conserver la borne courante ?
6.13 *(Rubinstein, 1981) On consid`ere l’int´egrale
I =
Z b
a
f(x) dx,
approch´ee par une m´ethode de Monte Carlo avec fonction d’importance h :
ˆI = 1
m
m
X
i=1
f(xi)/h(xi).
a. Montrer que la variance de ˆI est
var(ˆI) = 1
n
Z b
a
„f(x)
h(x) −I
«2
h(x) dx
et en d´eduire qu’elle est minimis´ee par h ∝|f|.
b. En d´ecomposant h en h+ −h−, d´eduire qu’une variance nulle est toujours
atteignable formellement.
c. Soient 0 ≤f(x) ≤c, v1, . . . , vm ∼U[0,c] et u1, . . . , um ∼U[a,b]. On d´eﬁnit
ˆI = (b −a) 1
m
m
X
i=1
f(ui)
et
˜I = c(b −a) 1
m
m
X
i=1
Ivi≤f(ui).
Montrer que
I = c(b −a)P(V ≤f(U))
pour U ∼U[a,b] et V ∼U[0,c].
d. En d´eduire que E[˜I] = I et var(˜I) ≤var(ˆI).
e. Discuter la pertinence de la notion d’une fonction d’importance “optimale”.
(Indication : Consid´erer une suite de lois normales centr´ees en la valeur
d’int´erˆet, c’est-`a-dire en x∗tel que f(x∗) = I, et de variances d´ecroissant
vers 0.)
6.14 Montrer que, pour une fonction g(θ) donn´ee et une distribution d’int´erˆet π(θ),
le choix optimal de la densit´e d’importance h, en termes de variance de l’esti-
mateur
n
X
i=1
g(θi)ωi ,
est
h(θ) ∝|g(θ)|π(θ) .
Donner l’expression de l’estimateur correspondant et en d´eduire que, si g est de
signe constant, la variance r´esultante est 0. (Indication : voir Robert et Casella,
2004, Th´eor`eme 3.12, pour une d´emonstration.)

6.5 Exercices
349
6.15 (Suite de l’Exercice 6.14) Dans le cas de constantes inconnues, c’est-`a-dire
quand l’estimateur (6.11) est utilis´e, montrer que la solution optimale au sens
de la variance est telle que
h(θ) ∝|g(θ) −E[g]|π(θ) .
Section 6.2.3
6.16 Justiﬁer l’approximation de Laplace pour h(θ) = (θ −μ)2 et b(θ) polynˆome
de degr´e 2. Que se passe-t-il si le degr´e de b est plus grand ? Obtenir le
d´eveloppement g´en´eral de Laplace `a partir de d´eveloppements de Taylor de
b et h.
6.17 *(Tierney et al., 1989) D´eduire de l’approximation de Laplace que
R
bN(θ)e−nhN (θ)dθ
R
bD(θ)e−nhD(θ)dθ = A(N)
A(D) + O(σ−2),
o`u
A(K) = σK exp{−nˆhk}
»
ˆbK + 1
2n
n
σ2
Kˆb′′
K
−ˆh′′′
Kˆb′
Kσ2
K + 5
12
ˆbK(ˆh′′′
K)2σ6
K −1
4
ˆbKσ2
Kh(4)
K
ﬀ–
et K = N, D, si ˆhK = h(ˆθK), etc., et ˆθK minimise hK. En d´eduire le Lemme
6.9 sous l’hypoth`ese que ˆh(i)
N −ˆh(i)
D = O(n−1) pour i = 0, . . . , 4 et ˆbD ̸= 0. Que
se passe-t-il si ˆbD = 0 ?
6.18 *(Tierney et al., 1989) Pour M(s) fonction g´en´eratrice des moments de g(θ)
et ˆ
M l’approximation de Laplace de M pour (6.16), avec bN = bD = b > 0 et
hD(θ) = {log[fx|θ)] + log[π(θ)] −log[b(θ)]}/n,
hN(θ) = hD(θ) −sg(θ)/n, on d´eﬁnit
ˆE(g) = ˆ
M ′(0).
a. Montrer que Eπ[g(θ)|x] = ˆE(g) + O(n−2).
b. Soit ˆθ le minimum de hD, ˆθs celui de hN et σ2
s = h(2)
N (θs). Montrer que
ˆE(g) = g(ˆθ) + d
ds log σs
˛˛˛˛
s=0
+ d
ds log b(ˆθs)
˛˛˛˛
s=0
.
c. En d´eduire que
ˆE(g) = ˆg + σ2
Dˆg′′
2n
−σ4
Dˆh′′′
D ˆg′
2n
+ σ2
Dˆb′
Dˆg′
nˆbD
,
et donc que cette m´ethode donne bien l’approximation (6.15) pour la forme
standard.

350
6 M´ethodes de calcul bay´esien
6.19 Dans le cadre de l’Exemple 6.11, choisir les repr´esentations standard et expo-
nentielle compl`ete menant aux approximations propos´ees.
Section 6.3.2
6.20 *Consid´erons l’algorithme de Metropolis-Hastings de la Section 6.3.2, qui si-
mule une densit´e π(θ) `a partir d’une densit´e propos´ee q(θ′|θ).
a. Montrer que cet algorithme se simpliﬁe en une simulation standard de π
lorsque q(θ′|θ) = π(θ′).
b. Donner la forme simpliﬁ´ee de l’algorithme de Metropolis-Hastings lorsque
q(θ|θ′) est sym´etrique en ses arguments, c’est-`a-dire lorsque q(θ|θ′) =
q(θ′|θ).
c. Montrer directement, c’est-`a-dire sans utiliser la condition d’´equilibre (6.17),
que π(θ) est une loi stationnaire pour cet algorithme lorsque le support de
q contient celui de π. (Indication : Calculer la fonction de densit´e de θ(m+1)
lorsque θ(m) ∼π(θ) en d´ecomposant l’int´egrale en quatre parties et en
´echangeant les variables muettes θ et ξ dans deux des quatre int´egrales.)
d. Dans le cas particulier o`u π est la loi N (0, 1) et q(θ|θ′) est N (θ′, σ2),
´etudier la probabilit´e d’acceptation de ξ dans le m-i`eme pas de simulation,
en fonction de σ. Quelle est la loi exacte de θ(m) ? En d´eduire la valeur
optimale de σ.
6.21 Prouver la condition d’´equilibre ponctuel (6.17) pour l’algorithme de Metro-
polis-Hastings.
6.22 D´eterminer si l’algorithme de Metropolis-Hastings produit une chaˆıne de Mar-
kov r´eversible, c’est-`a-dire telle que la loi de (x(t), x(t+1)) soit la mˆeme que celle
de (x(t+1), x(t)) en situation de stationnarit´e.
6.23 (Robert, 1993b) Soient n observations y1, . . . , yn issues d’un mod`ele de r´egres-
sion logistique, o`u
P(yi = 1) = 1 −P(yi = 0) =
exp(θtxi)
1 + exp(θtxi),
et xi, θ ∈Rp.
a. Montrer que, conditionnellement aux xi, cette loi appartient `a une famille
exponentielle et que P
i yixi est une statistique exhaustive.
b. Donner la forme g´en´erale de la loi conjugu´ee pour ce mod`ele et montrer que
le facteur de normalisation ne peut pas ˆetre calcul´e explicitement. Donner
une interpr´etation des hyperparam`etres (ξ, λ) de la loi conjugu´ee en termes
d’observations pr´ec´edentes.
c. Montrer que l’estimateur du maximum de vraisemblance de θ, ˆθ, ne peut pas
ˆetre calcul´e explicitement, et qu’il satisfait les ´equations implicites suivantes
(j = 1, . . . , p) :
n
X
i=1
exp(ˆθtxi)
1 + exp(ˆθtxi)
xij =
n
X
i=1
yixij.
(6.28)
d. Approcher une loi conjugu´ee par l’algorithme de Metropolis-Hastings. [Note :
Si une loi conditionnelle gaussienne est utilis´ee, faire attention au facteur
de variance.]

6.5 Exercices
351
e. Expliquer pourquoi (6.28) peut ˆetre utilis´e pour contrˆoler la convergence
de l’algorithme pour certaines valeurs particuli`eres du vecteur d’hyperpa-
ram`etres, (ξ, λ), celles pour lesquelles
Eπ
ξ,λ
" n
X
i=1
exp(θtxi)
1 + exp(θtxi)xi
#
= Eπ
ξ,λ
" n
X
i=1
exp(θtxi)
1 + exp(θtxi)xi
˛˛˛˛ y1, . . . , yn
#
=
n
X
i=1
yixi.
6.24 *Pour une densit´e d’int´erˆet donn´ee, π, et une densit´e connue f telle que
π/f ≤M, des tirages de π peuvent ˆetre produits par acceptation-rejet (Exercice
6.9), θ(1)
1 , . . . , θ(1)
p , ou par Metropolis-Hastings, avec f pour densit´e propos´ee,
θ(2)
1 , . . . , θ(2)
n ; alternativement, un ´echantillon d’importance, θ(3)
1 , . . . , θ(3)
n , peut
ˆetre g´en´er´e selon f. Comparer par simulation les variances de
1
p
p
X
i=1
θ(1)
i
,
1
n
n
X
i=1
θ(2)
i
,
1
n
n
X
i=1
π(θ(3)
i
)
f(θ(3)
i
)
θ(3)
i
.
[Note : p est le nombre al´eatoire d’observations produites apr`es n valeurs pro-
pos´ees dans l’algorithme d’acceptation-rejet.]
6.25 Soient une loi de probabilit´e P et une fonction ϱ telle que 0 ≤ϱ(x) ≤1
et EP [1/ϱ(x)] < ∞. Une chaˆıne de Markov (x(n)) est construite de la fa¸con
suivante : x(n) est remplac´e par x(n+1) en g´en´erant y ∼P et en prenant
x(n+1) =
(
y
avec probabilit´e ϱ(x(n)),
x(n)
avec probabilit´e 1 −ϱ(x(n)).
a. Montrer que cette variation de l’algorithme de Metropolis-Hastings converge
vers la loi stationnaire de densit´e
ϱ(x)−1/EP [ϱ(x)−1]
par rapport `a P.
b. Appliquer au cas o`u P est la loi Be(α + 1, 1) et ϱ(x) = x.
c. ´Etudier les performances de cette m´ethode lorsque α = 0.2. [Note : Voir
Robert et Casella, 1999, Exemple 8.2.8, pour une illustration des mauvaises
performances de ce g´en´erateur.]
Section 6.3.3
6.26 L’Algorithme 6.2 d’´echantillonnage de Gibbs bivari´e est fond´e sur les lois
conditionnelles π(θ|λ) et π(λ|θ). Comme le d´ecrit la Section 6.3, il consiste
`a simuler successivement π(θ|λ) et π(λ|θ). Cet exercice d´emontre qu’une telle
simulation de π(θ, λ) se justiﬁe d’un point de vue probabiliste.
a. Exprimer la loi jointe π(θ, λ) en fonction de ces lois conditionnelles.
b. Pour deux fonctions q(θ|λ) et s(λ|θ) donn´ees, fournir une condition n´eces-
saire et suﬃsante pour que q et s soient proportionnelles `a des lois condi-
tionnelles.

352
6 M´ethodes de calcul bay´esien
c. Traiter les questions ci-dessus dans le cas de n niveaux pour les mod`eles
compl´et´es, c’est-`a-dire lorsque des lois conditionnelles sont disponibles pour
θ, λ1, . . . , λn−1.
6.27 (Suite de l’Exercice 6.26)
Le th´eor`eme de Hammersley-Cliﬀord
´etablit
que la loi jointe π(ϑ) d’un vecteur ϑ = (θ1, . . . , θp) peut ˆetre obtenue `a partir
des lois conditionnelles compl`etes, πj(θj| . . . , θj−1, θj+1, . . . , θp). Montrer que
π(ϑ) ∝
p
Y
j=1
πℓj(θℓj|θℓ1, . . . , θℓj−1, θ′
ℓj+1, . . . , θ′
ℓp)
πℓj(θ′
ℓj|θℓ1, . . . , θℓj−1, θ′
ℓj+1, . . . , θ′
ℓp)
pour toute permutation ℓde {1, 2, . . . , p} et tout θ′ ∈Θ. [Note : Cliﬀord et
Hammersley n’ont jamais publi´e ce r´esultat ; voir Hammersley, 1974, et Robert
et Casella, 2004, Section 9.1.4, pour plus de d´etails.]
6.28 *(Diebolt et Robert, 1994) Soient deux chaˆınes de Markov (θ(m)) et (λ(m)) uti-
lis´ees en ´echantillonnage de Gibbs bivari´e, pour les lois conditionnelles π1(θ|x, λ)
et π2(λ|x, θ).
a. Montrer que les noyaux de transition de ces chaˆınes sont respectivement
K(θ′|θ) =
Z
Λ
π1(θ′|x, λ)π2(λ|x, θ) dλ,
et H(λ′|λ) =
Z
Θ
π2(λ′|x, θ)π1(θ|x, λ) dθ.
b. Montrer que π1(θ|x) et π2(λ|x) sont bien stationnaires pour ces noyaux.
c. ´Etablir que, si θ(m) ∼πm
1 (θ|x, λ(0)) et λ(m) ∼πm
2 (λ|x, λ(0)),
||πm
1 (·|x, λ(0)) −π1(·|x)||1 ≤||πm
2 (·|x, λ(0)) −π2(·|x)||1.
d. D´eduire le Lemme 6.17 `a partir de la question c. et du fait qu’une chaˆıne de
Markov irr´eductible admettant une distribution stationnaire est ergodique.
Montrer que, si (λ(m)) est g´eom´etriquement ergodique de taux ϱ, (θ(m))
converge aussi au taux ϱ, soit
||πm
1 (·|x, λ(0)) −π1(·|x)||1 ≤Cϱm.
e. La chaˆıne (λ(m)) est ϕ-m´elangeante s’il existe ϕ, d´ecroissant g´eom´etriquement,
et une mesure ﬁnie μ telle que
˛˛˛πm
2 (λ|x, λ(0)) −π2(λ|x)
˛˛˛ ≤ϕ(m)μ(λ).
Montrer que, lorsque (λ(m)) est ϕ-m´elangeante,
|πm
1 (θ|x, λ(0)) −π1(θ|x)| ≤ϕ(m)
Z
Λ
π1(θ|x, λ)μ(dλ)
et en d´eduire que, si Λ est compact, (θ(m)) est aussi ϕ-m´elangeante.

6.5 Exercices
353
f. De mˆeme, montrer que la convergence g´eom´etrique de (λ(m)) et le fait que
Λ soit compact sont des conditions suﬃsantes pour que, pour toute fonction
h satisfaisant
Eπ[||h(θ)||2|x, λ] < ∞,
il existe Ch tel que
|| Eπm
1 [h(θ)|x, λ(0)] −Eπ1[h(θ)|x] ||2 ≤Chϱm.
g. Tirer proﬁt du fait que, lorsque Λ est ﬁni, la chaˆıne (λ(m)) est n´ecessai-
rement g´eom´etriquement convergente et ϕ-m´elangeante (Billingsley, 1985).
D´eterminer l’importance des r´esultats ci-dessus dans le cadre de l’estimation
d’un m´elange.
h. ´Etendre le principe de dualit´e au cas d’un mod`ele hi´erarchique `a niveaux
multiples, en utilisant le fait que les lois conditionnelles ne d´ependent que
des niveaux voisins.
6.29 Deux machines sont utilis´ees en parall`ele ; les temps jusqu’`a la premi`ere panne
sont respectivement x ∼f(x|θ) et y ∼g(y|η). On sait quelle machine est en
panne lorsqu’une panne a lieu.
a. Donner la loi de z, temps jusqu’`a la premi`ere panne du syst`eme, et construire
un algorithme d’´echantillonnage de Gibbs aﬁn d’obtenir des estimateurs de
Bayes de θ et η lorsqu’un ´echantillon z1, . . . , zn est disponible et lorsque des
lois a priori conjugu´ees sont utilis´ees `a la fois pour θ et pour η.
b. Mettre en œuvre cet algorithme dans les cas particuliers (a) f et g sont des
densit´es normales de moyennes θ et η, et de variance 1 ; (b) f et g sont des
lois exponentielles de param`etres θ et η.
Section 6.3.4
6.30 Pour une chaˆıne (θ(t), λ(t)) produite par ´echantillonnage de Gibbs bivari´e
a. Montrer que, pour toute fonction h,
cov(h(θ(1)), h(θ(2))) = var {E[h(θ)|λ]} .
b. Donner une repr´esentation correspondante pour cov(h(θ(1)), h(θ(t))).
c. En d´eduire que la covariance cov(h(θ(1)), h(θ(t))) est toujours positive et
d´ecroissante en t.
d. Conclure sur la domination de la moyenne usuelle par sa version Rao-
Blackwellis´ee.
6.31 Montrer que, dans le cadre de l’Exemple 6.15, les lois marginales de θ et λ ne
peuvent pas ˆetre calcul´ees explicitement et que, de plus, il faut que B < +∞
pour que les lois marginales soient d´eﬁnies.
Section 6.3.5
6.32 Pour un mod`ele hi´erarchique comme (6.21), montrer que la loi d’un λi donn´e,
conditionnellement `a tous les autres param`etres du mod`ele π(λi|x, θ, (λj)j̸=i)
(1 ≤i ≤p) ne d´epend que de ses deux voisins les plus proches dans le vecteur
(x, θ, λ1, . . . , λp). (Indication : Faire une repr´esentation graphique du mod`ele.)

354
6 M´ethodes de calcul bay´esien
6.33 Montrer que, si l’´echantillonneur de Gibbs est mis en œuvre avec plus de
deux niveaux conditionnels, comme pour, par exemple, (6.23), les sous-chaˆınes
r´esultantes correspondant aux diﬀ´erents niveaux ne sont pas des chaˆınes de
Markov.
6.34 Pour le mod`ele multinomial de l’Exemple 6.21, expliquer pourquoi simuler
π((μ, η)|x) plutˆot que π(μ|x, η) et π(η|x, ν) devrait acc´el´erer la convergence.
(Indication : ´Etudier la corr´elation entre μ(t) et μ(t+1) dans les deux cas.)
6.35 Montrer que, pour un algorithme d’´echantillonnage de Gibbs, si une ´etape de
simulation arbitraire, telle que, disons, la simulation de π(θ1|θ2, . . . , θk), est rem-
plac´ee par une ´etape unique de Metropolis-Hastings, la validit´e de l’algorithme
est pr´eserv´ee. Commenter l’int´erˆet capital de cette propri´et´e dans la pratique.
6.36 Soit une loi π(θ1, θ2) non disponible analytiquement, mais telle que les deux
lois conditionnelles π(θ1|θ2) et π(θ2|θ1) soient connues et puissent ˆetre simul´ees.
a. Montrer qu’il est possible de mettre en œuvre l’algorithme de Metropolis-
Hastings. (Indication : Montrer que la seule diﬃcult´e est de simuler π(θ1)
ou π(θ2), et utiliser l’Exercice 6.26.)
b. En d´eduire que l’´echantillonnage de Gibbs peut s’appliquer dans tous les
cas, tout comme la forme g´en´erale de l’algorithme de Metropolis-Hastings.
6.37 Montrer qu’une ´etape d’´echantillonnage de Gibbs est un cas particulier de
l’algorithme de Metropolis tel que la probabilit´e d’acceptation soit toujours
´egale `a 1.
Section 6.3.6
6.38 On cherche `a simuler une loi normale tronqu´ee Np(0, Ip) restreinte au poly-
gone θt
ixi ≤zi (1 ≤i ≤n).
a. Donner la loi de θj conditionnelle `a θk (k ̸= j) et construire un ´echantillon-
neur de Gibbs pour la simulation de cette loi normale tronqu´ee. (Indication :
Voir Geweke, 1991, ou Robert, 1995, pour des algorithmes d’acceptation-
rejet de simulation d’une loi normale tronqu´ee unidimensionnelle.)
b. Proposer un algorithme alternatif de Metropolis-Hastings fond´e sur la si-
mulation d’une loi Np(μ, Σ), o`u μ et Σ sont calcul´es `a partir des fronti`eres
du polygone.
c. Proposer un ´echantillonneur par tranche faisant intervenir une seule variable
auxiliaire et un autre en faisant intervenir p.
d. Comparer ces diﬀ´erents algorithmes.
Section 6.3.7
6.39 (Rubin et al., 1992)
Une ´etude a ´et´e men´ee sur le campus de l’Universit´e
Cornell aﬁn de mod´eliser le comportement sexuel des ´etudiants de premier et
second cycles. Sur une population de Rm (Rf) ´etudiants masculins (f´eminins),
rm (rf) ont r´epondu `a l’enquˆete et tm (tf) ont d´eclar´e ˆetre actifs sexuellement
(durant les deux derniers mois).
a. Les premi`eres quantit´es d’int´erˆet sont Tf et Tm, nombres d’´etudiants
f´eminins et masculins sexuellement actifs. En utilisant un mod`ele hyperg´eo-
m´etrique sur tm, et en supposant tf, rm et rf ﬁx´es, calculer un estimateur
de Bayes de Tf et Tm pour

6.5 Exercices
355
Ti ∼B(Ri, pi),
pi ∼Be(α, β),
π(α, β) = 1/αβ
(i = f, m).
(Application num´erique : Rf = 5 211, rf = 253, tf = 111, Rm = 6 539,
rm = 249 et tm = 22.)
b. Durant cette enquˆete, les r´epondants sexuellement actifs ´etaient interrog´es
sur le nombre de partenaires qu’ils ont eu pendant les deux derniers mois,
yf et ym, ainsi que le nombre de partenaires ´etudiants de Cornell, xm et
xf.
Consid´erant une loi de Poisson P(λi) pour le nombre de partenaires suppl´e-
mentaires yi −1 et une loi binomiale B(yi, ϱi) pour le nombre de partenaires
´etudiants de Cornell (i = f, m), avec ϱf = Tm/Nm et ϱm = Tf/Nf, calculer
l’estimateur de Bayes de la population en contact sexuel avec les ´etudiants de
Cornell, Nm et Nf, pour les lois a priori
λi ∼E xp(λ0),
ϱi ∼Be(γ, δ),
π(γ, δ) = 1/γδ.
(Application num´erique : ym = 54, xm = 31, yf = 135, xf = 67.)
c. Comparer vos r´esultats avec l’estimateur du maximum de vraisemblance
obtenu dans cette ´etude : ˆ
Nf = 4 186, ˆ
Nm = 1 473, ˆTf = 2 323 et ˆTm = 615.
d. Reprendre l’estimation pour les lois a priori sur les hyperparam`etres
π(α, β) = e−(α+β),
π(γ, δ) = e−(γ+δ),
et
π(α, β) = 1/(α + β)2,
π(γ, δ) = 1/(γ + δ)2.
6.40 Dans le cas de la r´egression logistique (voir l’Exercice 6.23), une structure de
donn´ees manquantes peut ˆetre mise en ´evidence et utilis´ee dans un algorithme
de Gibbs.
a. Calculer la loi de zi telle que l’observation yi est Izi≤xt
iθ.
b. Donner la vraisemblance du mod`ele compl´et´e et d´eterminer si un algorithme
de Gibbs similaire `a ceux de la Section 6.4 peut ˆetre construit dans le cas
particulier θ ∼Np(μ, Σ).
c. Comparer la performance de cet algorithme avec celle d’un algorithme de
Metropolis-Hastings plus simple de votre choix.
6.41 Un mod`ele probit est un mod`ele de r´egression qualitative o`u la d´ependance
sur les variables auxiliaires est donn´ee par
Pθ(yi = 1) = 1 −Pθ(yi = 0) = Φ(θtxi).
a. Montrer que, comme dans l’Exercice 6.40, il est possible de compl´eter le
mod`ele en exhibant une variable latente continue zi.
b. Proposer un algorithme d’´echantillonnage de Gibbs fond´e sur les donn´ees
compl´et´ees lorsque θ ∼Np(μ, Σ).

356
6 M´ethodes de calcul bay´esien
Section 6.4
6.42 (Casella et al., 2000) L’´echantillonnage de Gibbs et les autres m´ethodes
MCMC ont r´esolu les diﬃcult´es de l’inf´erence bay´esienne sur des mod`eles de
m´elange. Il est cependant possible de produire des estimateurs d’importance
dans ce cadre. Nous supposons qu’un ´echantillon (x1, . . . , xn) de
k
X
j=1
pjf(x|θj)
est disponible.
a. Consid´erant les variables d’allocation z1, . . . , zn, o`u xi|zi ∼f(x|θzi), mon-
trer que la loi a posteriori de z = (z1, . . . , zn) est donn´ee par
P(z|x) =
k
Y
j=1
Z
Θ
Y
{i:zi=j}
f(xi|θj)πj(θj)dθj
X
z∈Z
k
Y
j=1
Z
Θ
Y
{i:zi=j}
f(xi|θj)πj(θj)dθj ,
(6.29)
o`u Z est l’ensemble des kn vecteurs d’allocation z.
b. Montrer que
P(Zi = j|xi) =
pjmj(xi)
Pk
j=1 pjmj(xi)
,
(6.30)
o`u mj(x) =
R
f(x|θj)π(θj)dθj, (j = 1, . . . , m) est la loi marginale univari´ee
de xi.
c. En d´eduire que, si les expressions de (6.29) et (6.30) sont toutes les deux
disponibles, `a une constante de normalisation pr`es, l’estimateur de Bayes
E[h(θ)|x] peut ˆetre approch´e par ´echantillonnage d’importance, les zi (i =
1, . . . , n) ´etant g´en´er´es `a partir des lois marginales de b., si l’expression de
E[h(θ)|(x1, z1), . . . , (xn, zn)] est elle aussi connue.
d. Appliquer au cas d’un m´elange de lois exponentielles,
k
X
j=1
pjλj exp(−λjx),
x > 0,
pour la loi a priori
λj ∼G (αj, βj),
j = 1, . . . , k ,
lorsque les poids pj et les hyperparam`etres αj, βj sont connus. En particu-
lier, d´eterminer des transformations h(λ1, . . . , λk) telles que les esp´erances
conditionnelles E[h(θ)|(x1, z1), . . . , (xn, zn)] soient connues.
6.43 Pour un m´elange gaussien, d´etailler le raisonnement menant aux lois condi-
tionnelles (6.26) et (6.27) et donner une expression explicite de Eπ[μi|x, z].
6.44 (Suite de l’Exercice 6.5)
Une approche simpliﬁ´ee des m´elanges est de
consid´erer qu’un m´elange `a k composantes n’est qu’une perturbation d’un
m´elange `a (k −1) composantes (Mengersen et Robert, 1996, Robert et Menger-
sen, 1999) et d’estimer un m´elange `a k composantes s´equentiellement en k.

6.5 Exercices
357
a. ´Ecrire un programme MCMC `a cet eﬀet, qui estime uniquement la nouvelle
composante dans le m´elange `a k composantes.
b. Comparer par des simulations les performances de cette version approch´ee
avec une estimation directe du m´elange `a k composantes.
6.45 Pour une petite taille d’´echantillon, eﬀectuer plusieurs simulations pour com-
parer l’´echantillonnage de Gibbs avec un calcul direct de l’estimateur de Bayes
pour un m´elange de deux lois normales.
6.46 Montrer que les lois a priori conjugu´ees ne peuvent pas donner une r´eponse
non informative dans le cas d’un m´elange gaussien `a deux composantes lorsque
les variances des lois a priori tendent vers +∞.
6.47 (Robert et Soubiran, 1993) Obtenir les formules ´equivalentes `a (6.26) et (6.27)
pour un m´elange de lois normales multidimensionnelles. (Indication : Utiliser la
Section 4.4.1 pour le choix d’une loi a priori conjugu´ee et d´etailler la simulation
de la loi de Wishart.)
6.48 (Binder, 1978) Soit un ´echantillon x1, . . . , xn tir´e d’un m´elange
x ∼f(x|θ) =
k
X
i=1
pifi(x),
tel que les densit´es fi et les poids pi soient connus. Le probl`eme est d’identiﬁer
l’origine des observations, g = (g1, . . . , gn), avec
gj =
k
X
i=1
iIzij =1
(1 ≤j ≤n).
a. Montrer que des diﬃcult´es de calcul ont aussi lieu dans ce cadre, pour
l’obtention des estimateurs de Bayes.
b. Donner l’estimateur de Bayes de g lorsque p ∼D(1/2, . . . , 1/2) et fi(x) =
ϕ(x; μi, 1) avec μi ∼N (ξi, 1).
c. Comment mettre en œuvre l’´echantillonnage de Gibbs pour ce probl`eme ?
6.49 Adapter les m´ethodes d’´echantillonnage de Gibbs d´evelopp´ees dans la Section
6.4 pour un m´elange de lois au cas d’un mod`ele censur´e, c’est-`a-dire pour des
observations y∗
i telles que
y∗
i =
(
yi
si yi ≤c,
c
sinon,
si yi ∼f(y|θ), o`u f(·|θ) appartient `a une famille exponentielle.
6.50 (Robert et al., 1993a)
Un mod`ele de chaˆıne de Markov cach´ee g´en´eralise le
mod`ele de m´elange ´etudi´e dans l’Exemple 6.5 et dans la Section 6.4 en introdui-
sant une certaine d´ependance entre les observations x1, . . . , xt. Si on compl`ete
ces observations par les variables indicatrices (inconnues) des ´etats zi, le mod`ele
devient hi´erarchique (1 ≤i ≤t) :
xi|zi, θ ∼f(x|θzi)
et (zi) constitue une chaˆıne de Markov sur {1, . . . , K} de matrice de transition
P = (pjk), o`u

358
6 M´ethodes de calcul bay´esien
pjk = P(zi = k|zi−1 = j)
(2 ≤i ≤t)
(on pose z1 = 1 pour des raisons d’identiﬁabilit´e). On suppose de plus que f(·|θ)
appartient `a une famille exponentielle.
a. Donner la vraisemblance de ce mod`ele et en d´eduire que ni le maximum de
vraisemblance ni l’estimation bay´esienne sous des lois conjugu´ees sur θ et
P ne donnent des expressions explicites dans ce cas.
b. Consid´erant le cas particulier o`u f(·|θ) est N (ξ, σ2) avec θ = (ξ, σ2), mon-
trer qu’un ´echantillonneur de Gibbs comprenant des simulations it´eratives
de π(θ|x, z) et π(z|x, θ) est relativement coˆuteux en temps de calcul, `a cause
de π(z|x, θ).
c. Montrer que les lois conditionnelles compl`etes π(zi|x, θ, zj̸=i) ne d´ependent
que de zi−1 et zi+1 et sont beaucoup plus faciles `a simuler.
d. Proposer un algorithme d’´echantillonnage de Gibbs pour ce mod`ele. Montrer
que la condition pkj > 0 pour tout 1 ≤j, k ≤K est suﬃsante pour assurer
la convergence g´eom´etrique des chaˆınes (θ(m)) et (P(m)) vers les vraies lois
a posteriori. (Indication : Des arguments similaires `a ceux de l’Exercice 6.28
peuvent ˆetre utilis´es.)
6.51 (Robert et al., 1999a ) Dans le cadre de l’Exercice 6.50, il existe une fa¸con de
simuler la chaˆıne compl`ete z = (z2, . . . , zn) conditionnellement aux param`etres
θ, et donc de mettre en œuvre une technique d’augmentation de donn´ees. La
repr´esentation de la loi conditionnelle de z est appel´ee r´ecurrences avant-arri`ere
(ou forward-backward) et est connue depuis longtemps en traitement du signal
(Baum et Petrie, 1966).
a. ´Etablir la relation dite de r´ecurrence arri`ere (1 ≤i ≤n −1)
f(xi, . . . , xn|θ, zi = j) =
K
X
k=1
pjkf(xi|θj)f(xi+1, . . . , xn|θ, zi+1 = k) ,
(6.31)
avec f(xn|zn = j) = f(xn|θj).
b. Calculer `a partir de la formule de r´ecurrence arri`ere la probabilit´e P(z1 =
j|x1, . . . , xn, θ) sous l’hypoth`ese que z1 est distribu´ee marginalement selon
la loi stationnaire associ´ee `a la matrice de transition P.
c. Calculer les probabilit´es P(zi = j|x1, . . . , xn, θ, z1, . . . , zi−1) (i = 2, . . . , n).
d. En conclure que le vecteur (z1, . . . , zn) peut ˆetre simul´e conditionnellement
aux observations et θ en un temps O(nK2) et donc que la technique d’aug-
mentation de donn´ees peut ˆetre mise en œuvre dans certains mod`eles de
chaˆınes de Markov cach´ees.
6.52 Dans un cadre de m´elange, comparer les performances (en termes de temps de
calcul) de l’´echantillonnage de Gibbs avec celui d’un algorithme de Metropolis-
Hastings par marche al´eatoire.
Note 6.6.3
6.53 La d´ecomposition d’une loi du khi deux d´ecentr´e propos´ee dans l’Exemple
6.26 permet-elle une mise en œuvre de l’´echantillonnage de Gibbs ? Donner une
approximation par l’algorithme de Metropolis-Hastings.

6.5 Exercices
359
6.54 (Heitjan et Rubin, 1991)
Des donn´ees grossi`eres sont d´eﬁnies comme une
agr´egation d’observations en classes. Pour une variable al´eatoire “compl`ete”
yi ∼f(y|θ), prenant ses valeurs dans Y , et une partition Aj (j ∈I) de Y , les
observations sont xi = j si yi ∈Aj.
a. Donner une illustration concr`ete de ce mod`ele.
b. Proposer un algorithme d’´echantillonnage de Gibbs dans le cas o`u f(·|θ) est
une loi normale N (ξ, σ2) avec θ = (ξ, σ2) et Aj = [j, j + 1) (j ∈Z).
Le nombre de passages de voitures durant une p´eriode d’une minute a ´et´e observ´e
pendant trois cent soixante minutes cons´ecutives ; les observations r´esultantes
sont donn´ees dans la Table 6.2.
c. En posant une loi de Poisson P(θ) sur le nombre de passages, appliquer
l’´echantillonnage de Gibbs aﬁn d’estimer le param`etre θ pour ce jeu de
donn´ees et la loi a priori π(θ) = 1/θ.
Tab. 6.2. Nombre de passages de voitures pour une suite d’intervalles d’une minute.
Nombre de
voitures
0
1
2
3 4 ou
plus
Nombre de
passages
139 128 55 25 13
Note 6.6.4
6.55 Dans le cadre de l’Exemple 6.19,
a. Montrer que la loi marginale associ´ee aux lois conditionnelles compl`etes
π(θ|λ) et π(λ|θ) satisfait
π(θ)
π(λ) = θ
λ,
θ, λ < B .
b. En d´eduire que la loi jointe correspondant `a ces deux lois conditionnelles
n’est pas d´eﬁnie lorsque B tend vers l’inﬁni.
Note 6.6.6
6.56 Pour la suite (ˆθ(j))j produite par l’algorithme EM,
a. Montrer que
Q(ˆθ(j+1)|ˆθ(j), x) ≥Q(ˆθ(j)|ˆθ(j), x).
b. On note k(z|θ, x) la loi conditionnelle de z sachant x. Montrer que
Eˆθ(j)
"
log
 
k(z|ˆθ(j+1), x)
k(z|ˆθj, x)
!
˛˛ˆθ(j), x
#
≤0 .
(Indication : Utiliser l’in´egalit´e de Jensen.)
c. Conclure que
L(ˆθ(j+1)|x) ≥L(ˆθ(j)|x),
l’´egalit´e ´etant v´eriﬁ´ee si et seulement si Q(ˆθ(j+1)|ˆθ(j), x) = Q(ˆθ(j)|ˆθ(j), x).

360
6 M´ethodes de calcul bay´esien
6.6 Notes
6.6.1 G´en´erateurs uniformes pseudo-al´eatoires.
Tout algorithme de g´en´eration d’une variable al´eatoire de loi quelconque repose
sur la g´en´eration de variables al´eatoires uniformes sur [0, 1]. Puisque la pro-
duction exacte d’une suite iid de variables uniformes U ([0, 1]) est impossible, il
existe des m´ethodes reposant sur un m´ecanisme purement d´eterministe produi-
sant des suites imitant le comportement d’une suite de variables iid U ([0, 1]),
au sens o`u cette suite d´eterministe est accept´ee comme une suite iid U ([0, 1])
par tout test statistique. Par exemple, le g´en´erateur propos´e par Ripley (1987)
est de type congruentiel, et est d´eﬁni comme suit.
Algorithme 6.9. –G´en´erateur congruentiel–
1. Initialiser avec une racine initiale arbitraire x0
2. It´erer
xi = (69069xi−1 + 1) mod 232,
ui = 2−32xi.
La suite correspondante des ui peut ˆetre consid´er´ee comme une suite iid U[0,1],
bien que son support soit en r´ealit´e ﬁni.
Des g´en´erateurs uniformes pseudo-al´eatoires sont disponibles sur la plupart des
ordinateurs et dans la plupart des langages informatiques, et peuvent ˆetre uti-
lis´es en tant que tels, mˆeme si certains de ces g´en´erateurs ne sont pas test´es
exhaustivement et peuvent avoir des propri´et´es ind´esirables (voir Robert et Ca-
sella, 1999, Exercice 2.5).
Marsaglia et Zaman (1993) ont d´evelopp´e un g´en´erateur uniforme simple `a ra-
cines multiples dont la p´eriode est sup´erieure `a 295 ; voir Robert et Casella (2004,
Note 2.6.1) pour plus de d´etails.
6.6.2 Les logiciels BUGS et CODA
Spiegelhalter et al. (1995a,b,c) de la MRC Biostatistics Unit de Cambridge, en
Angleterre, ont d´evelopp´e un logiciel MCMC. Ce logiciel oﬀre diﬀ´erentes possi-
bilit´es pour programmer un ´echantillonneur de Gibbs partiellement automatique
(BUGS signiﬁe Bayesian inference Using Gibbs Sampling). Il s’agit d’un langage
informatique, ressemblant au C ou `a R, et fond´e sur des d´eclarations sur le
mod`ele, les donn´ees et les sp´eciﬁcations a priori, ´eventuellement hi´erarchiques ;
ce langage autorise une grande vari´et´e de transformations de la plupart des
distributions standard. BUGS produit un ´echantillon de Gibbs, fait de valeurs si-
mul´ees des param`etres, apr`es un nombre arbitraire d’it´erations d’´echauﬀement,
et pour un intervalle entre valeurs retenues lui aussi arbitraire.
Une restriction importante sur la mod´elisation a priori est que des lois a priori
conjugu´ees ou des densit´es log-concaves doivent ˆetre utilis´ees pour permettre
soit une simulation standard, soit l’utilisation de l’algorithme ARMS de Gilks
et al. (1995), mais des lois plus complexes peuvent ˆetre prises en compte par

6.6 Notes
361
discr´etisation de leur support. L’autre restriction est que des lois a priori im-
propres ne peuvent pas ˆetre utilis´ees et doivent ˆetre remplac´ees par des lois a
priori vagues, c’est-`a-dire de grande variance a priori.
Le logiciel BUGS se compl`ete d’un logiciel de diagnostic de convergence56, CODA,
qui comporte les m´ethodes d’´evaluation de convergence MCMC les plus cou-
rantes. Ce “package” S-Plus a ´et´e d´evelopp´e par Best et al. (1995) et peut ˆetre
utilis´e ind´ependamment de BUGS. Les m´ethodes mises en œuvre dans CODA sont
d´ecrites dans Robert et Casella (2004, Chapitre 12) : elles incluent les diagnos-
tics de convergence de Gelman et Rubin (1992), Geweke (1992), Heidelberger et
Welch (1983), Raftery et Lewis (1992a), ainsi que les trac´es d’autocorr´elation
pour chaque variable et les corr´elations crois´ees entre variables.
6.6.3 M´elanges cach´es
La d´ecomposition hi´erarchique (6.19) sur laquelle repose l’´echantillonnage de
Gibbs est aussi utile pour la s´election de la loi a priori, lorsque la distribution
d’´echantillonnage n’appartient pas `a une famille exponentielle et qu’il n’existe
pas de loi a priori conjugu´ee. C’est le cas par exemple pour les lois de Student
et du khi deux d´ecentr´e. Une d´ecomposition de f(x|θ) de la forme
f(x|θ) =
Z
f(x|θ, z)g(z|θ) dz
peut alors permettre une mod´elisation a priori de θ via des lois a priori
conjugu´ees (pour f(x|θ, z) ou g(z|θ)). Comme dans la Section 3.3.3, nous ap-
pelons cette repr´esentation m´elange cach´e, pour marquer la diﬀ´erence avec les
probl`emes de m´elanges standard pour lesquels la structure de m´elange elle-mˆeme
est d’int´erˆet ; voir aussi la Note 3.8.3.
Exemple 6.26. Soit x ∼χ2
p(θ), une observation tir´ee d’une loi du khi deux
d´ecentr´e.Cette loi peut s’´ecrire comme le m´elange
x|θ, z ∼χ2
p+2z,
z|θ ∼P(θ/2).
Donc seul g(z|θ) d´epend de θ et une loi a priori possible pour θ est G (α, β),
puisqu’il s’agit de la loi conjugu´ee pour la loi de Poisson.
∥
Exemple 6.27.
Soit x|μ, σ ∼T (m, μ, σ2), avec θ = (μ, σ) inconnu. En se
fondant sur la repr´esentation de Dickey (1968),
x|θ, z ∼N (μ, z),
z|σ2 ∼I G (m/2, mσ2/2),
on peut proposer
μ ∼N (ξ, τ 2),
σ2 ∼G (α, β),
comme loi a priori et on obtient
56Ces deux logiciels sont actuellement disponibles sur le site de la MRC Biosta-
tistics Unit, `a l’adresse www.mrc-bsu.cam.ac.uk.

362
6 M´ethodes de calcul bay´esien
z|x, θ ∼I G
„m + 1
2
, mσ2 + (x −μ)2
2
«
,
σ2|x, z ∼G (α + (m/2), β + (m/2z)),
(6.32)
μ|x, z ∼N
„zμ + τ 2x
z + τ 2 ,
zτ 2
z + τ 2
«
.
Les lois conditionnelles (6.32) permettent directement une simulation par ´echan-
tillonnage de Gibbs. Notons la diﬀ´erence avec l’exemple normal classique (voir la
Section 4.4). Dans ce cas, σ2 suit une loi a priori gamma plutˆot qu’inverse gamma
et, fait plus important, μ et σ sont a priori ind´ependants. La d´ecomposition
conditionnelle m`ene donc `a une mod´elisation plus satisfaisante que dans le cas
normal.
∥
Recourir `a une structure de m´elange cach´e pour f(x|θ) ou pour π(θ) simpliﬁe
bien entendu la simulation de π(θ|x) par ´echantillonnage de Gibbs lorsque la loi
a posteriori n’est pas disponible.
Exemple 6.28. (Suite de l’Exemple 6.27) Si, dans un but de robustesse,
la loi a priori est en fait
μ ∼T (ν, ξ, τ 2),
σ2 ∼G (α, β),
la repr´esentation en m´elange cach´e correspondante est
μ|δ ∼N (ξ, δ),
δ ∼I G (ν/2, ντ 2/2),
et la simulation de π(μ, σ|x) peut ˆetre obtenue par ´echantillonnage de Gibbs,
via les lois conditionnelles suivantes :
z|x, θ ∼I G
„m + ν
2
, mσ2 + (x −μ)2
2
«
,
σ2|x, z ∼G (α + (m/2), β + (m/2z)),
μ|x, z, δ ∼N
„δμ + τ 2x
δ + τ 2 ,
δτ 2
δ + τ 2
«
,
δ|θ ∼I G
„ν + 1
2
, ντ 2 + (x −μ)2
2
«
.
∥
6.6.4 Lois a posteriori impropres
Comme l’a soulign´e la Note 1.8.3, des lois a priori π qui satisfont
Z
Θ
π(θ)f(x|θ)dθ = ∞
ne peuvent pas ˆetre utilis´ees. Cette condition est diﬃcile `a v´eriﬁer pour des
mod`eles complexes et il existe de nombreuses situations o`u (a) une v´eriﬁcation
analytique est impossible ; et (b) les lois conditionnelles obtenues `a partir de
π(θ)f(x|θ) sont propres. Consid´erons, par exemple, le cas de l’Exemple 6.19 :

6.6 Notes
363
lorsque B tend vers l’inﬁni, la loi jointe sur (θ, λ) n’est pas d´eﬁnie ; les lois condi-
tionnelles sont cependant des lois exponentielles standard E xp(λ) et E xp(θ)
(Exercice 6.55). Une diﬃcult´e suppl´ementaire est qu’un ´echantillonneur de
Gibbs fond´e sur ces lois conditionnelles peut tr`es bien ne pas mettre en ´evidence
le caract`ere impropre de la loi a posteriori (voir Hobert et Casella, 1996).
Exemple 6.29. Soit le mod`ele `a eﬀets al´eatoires usuel (1 ≤i ≤I, 1 ≤j ≤J)
yij = θ + ui + ϵij,
ui ∼N (0, σ2), ϵij ∼N (0, τ 2) .
La loi a priori de Jeﬀreys correspondante est π(θ, τ 2, σ2) = 1/σ2τ 2. Alors (voir
Robert et Casella, 2004, Exemple 10.31 et Probl`eme 10.25), la loi a posteriori
jointe de (θ, τ 2, σ2) n’est pas d´eﬁnie, tandis que les lois conditionnelles le sont
et peuvent (h´elas !) ˆetre utilis´ees dans un ´echantillonneur de Gibbs.
∥
Malgr´e l’impossibilit´e fondamentale d’utiliser pour une inf´erence bay´esienne des
loi a posteriori impropres, qui sont eﬀectivement des mesures f(x|θ)π(θ) de
masse inﬁnie, il existe des cas o`u de telles mesures peuvent ˆetre utiles. En
particulier, il est possible d’augmenter artiﬁciellement le param`etre θ par un
param`etre auxiliaire α et d’introduire une loi a priori impropre π(α) telle que
la loi a posteriori jointe π(α, θ|x) = π(α)π(θ)f(x|θ) soit aussi impropre, tout
en pr´eservant le caract`ere propre de la densit´e correctement d´eﬁnie π(θ|x) `a
l’int´erieur de la chaˆıne de Markov.
Exemple 6.30. (Meng et Van Dyk, 1999) Une loi de Student t de param`etre
θ = (μ, σ), T (ν, μ, σ2), peut s’´ecrire
x = μ + σy1/(νy2)1/2,
avec
y1 ∼N (0, 1), y2 ∼χ2
ν .
(voir l’Exercice 1.1 et l’Exemple 3.17). Si on introduit α > 0 tel que
x|y2 ∼N (μ, ασ2/(νy2)),
y2 ∼αχ2
ν ,
cela ne change pas le mod`ele ´etudi´e puisque la quantit´e α/y2 ne d´epend pas
de α. Le param`etre α n’est donc pas identiﬁable et, pour une loi a priori sur α
impropre, disons π(α) = α−1 exp(−β/α), la loi a posteriori marginale de α est
´egale `a sa loi a priori : la loi a posteriori jointe de (θ, α) n’est pas d´eﬁnie.
Il est cependant possible de cr´eer une chaˆıne de Markov (y(t)
2 , θ(t), α(t)) par une
m´ethode simple d’augmentation de donn´ees, appliqu´ee aux lois conditionnelles
compl`etes obtenues `a partir de
π(α)π(μ, σ)f(x|μ, α, σ, y2)f(y2|α)
et telles que (a) cette mesure σ-ﬁnie soit stationnaire pour cette chaˆıne ; et (b)
la sous-chaˆıne (θ(t)) converge vers la loi a posteriori bien d´eﬁnie π(θ|x).
∥
Les lois a posteriori impropres apparaissent alors comme des outils permettant
d’acc´el´erer l’exploration de l’espace des param`etres Θ par des chaˆınes de Mar-
kov nulles r´ecurrentes ou mˆeme transientes, dans des espaces plus grands ; voir
Casella (1996), Meng et Van Dyk (1999), Hobert (2000a,b), et Liu et Wu (1999)
pour plus de d´etails.

364
6 M´ethodes de calcul bay´esien
6.6.5 Algorithmes MCMC dans des mod`eles dynamiques
Nous avons introduit dans la Section 4.5 divers mod`eles dynamiques et soulign´e
le fait que la complexit´e de l’espace des param`etres induite par les contraintes
de stationnarit´e ainsi que l’absence d’expression explicite pour la vraisemblance
imposent le recours `a des algorithmes MCMC. Les repr´esentations `a espace
d’´etat des Sections 4.5.3 et 4.5.4 et la reparam´etrisation du Lemme 4.24 jouent
un rˆole cl´e dans l’obtention d’´echantillonneurs de Gibbs pour ces mod`eles.
Par exemple, dans le mod`ele AR(p), les ϱj (1 ≤j ≤p) sont des fonctions
lin´eaires des autocorr´elations partielles ψk (1 ≤k ≤p), lorsque les ψℓ(ℓ̸= k)
sont ﬁx´es :
ϱj = akj + bkjψk ,
avec (1 ≤ℓ≤i −1)
aii = ψi, bii = 0, aiℓ= a(i−1)ℓ−ψia(i−1)(i−ℓ), biℓ= 0,
si
i < k
aii = 0, bii = 1, aiℓ= a(i−1)ℓ, biℓ= −a(i−1)(i−ℓ)
si
i = k
aii = ψi, bii = 0, aiℓ= a(i−1)ℓ−ψia(i−1)(i−ℓ), biℓ= b(i−1)ℓ−ψib(i−1)(i−ℓ)
si
i > k
et
aik = api , bik = bpi (1 ≤i ≤p) .
Donc, si les ψi sont simul´es un par un, la vraisemblance (4.24) a une structure
normale
T
Y
t=1
exp
(
−1
2σ2
 
xt −μ −
p
X
j=1
(aij + bijψi)(xt−j −μ)
!2)
.
Une d´ecomposition conditionnelle similaire peut ˆetre utilis´ee pour les mod`eles
MA(q) et ARMA(p, q) des Sections 4.5.3 et 4.5.4, en tirant proﬁt de la structure
lin´eaire de la repr´esentation `a espace d’´etat qui pr´eserve la structure normale.
Des solutions alternatives fond´ees sur la repr´esentation r´ecursive (4.28) et sur
des ´etapes de Metropolis-Hastings ont ´et´e ´etudi´ees dans Billio et al. (1998).
6.6.6 Retour `a l’estimation de m´elange
L’importance des m´elanges de distributions standard comme outils de mod´e-
lisation ne peut pas ˆetre minimis´ee : ces mod`eles se situent `a la fronti`ere des
mod´elisations param´etrique et non param´etrique et permettent la description
de ph´enom`enes plus complexes (relativement aux lois standard), tout en respec-
tant le principe de parcimonie (c’est-`a-dire permettant le recours `a un nombre
raisonnable de param`etres pour d´ecrire un ph´enom`ene). Ce point est illustr´e
par la construction de lois a priori dans les Notes 3.8.3 et 6.6.3. Les mod`eles
de m´elange apparaissent en analyse bay´esienne non param´etrique, comme, par
exemple, avec les processus de Dirichlet (voir les Notes 1.8.2 et 6.6.7). Ils jouent
´egalement un rˆole important dans les probl`emes de classiﬁcation (voir Bensmail
et al., 1997) et en d´etection de valeurs aberrantes (Verdinelli et Wasserman,
1992).
Le traitement classique de l’estimation de m´elanges ﬁnis de lois est pr´esent´e
dans Titterington et al. (1985) et MacLachlan et Basford (1987). Il remonte `a

6.6 Notes
365
Pearson (1894), qui proposa une m´ethode d’estimation fond´ee sur les moments
et sur la r´esolution d’une ´equation polynomiale de degr´e 9.
Pour une estimation par maximum de vraisemblance, Dempster et al. (1977) et
Redner et Walker (1984) ont d´evelopp´e un algorithme dit algorithme EM (pour
Expectation-Maximisation) qui est extraordinairement populaire (voir Meng et
Van Dyk, 1997 et MacLachlan et Krishnan, 1997). Cet algorithme est fond´e
sur la mˆeme augmentation de donn´ees que l’´echantillonnage de Gibbs. Pour une
vraisemblance compl´et´ee donn´ee Lc(θ|x, z), l’algorithme EM fonctionne comme
suit.
Algorithme 6.10. –´Esp´erance-Maximisation (EM)–
`A l’it´eration m,
1. Calculer
Q(θ|ˆθ(m), x) = Eˆθ(m)[log Lc(θ|x, z)|x] ,
o`u l’esp´erance est par rapport `a k(z|ˆθm, x) (´etape E) .
2. Maximiser Q(θ|ˆθ(m), x) en θ et prendre (´etape M)
θ(m+1) = arg max
θ
Q(θ|ˆθ(m), x).
La validit´e de cet algorithme tient au fait que la vraisemblance observ´ee aug-
mente `a chaque it´eration (Exercice 6.56). La suite (ˆθ(m))m converge donc vers
un point stationnaire de la vraisemblance observ´ee (qui peut ˆetre un maximum
local ou un point-selle) ; voir Robert et Casella (1999, Section 5.3.3) pour plus
de d´etails.
Puisque la convergence de l’algorithme EM d´epend du point initial ˆθ(0) et que
cet algorithme requiert le calcul de l’esp´erance dans l’´etape E, certains auteurs,
notamment Broniatowski et al. (1983), Celeux et Diebolt (1990), Qian et Tit-
terington (1991) et Lavielle et Moulines (1997), ont propos´e des extensions sto-
chastiques de l’algorithme EM.
D’un point de vue bay´esien, une ´etude plus d´etaill´ee des m´ethodes MCMC pour
les m´elanges est propos´ee dans Robert (1996a), Roeder et Wasserman (1997),
Robert et Mengersen (1999), Celeux et al. (2000), Stephens (2000) et Marin et al.
(2004). En particulier, Celeux et al. (2000) montrent que l’ordre des param`etres
utilis´e pour assurer l’identiﬁabilit´e peut avoir des eﬀets d´esastreux sur l’inf´erence
r´esultante ; ces auteurs construisent des fonctions sp´eciﬁques de coˆut pour venir
`a bout du probl`eme de non-identiﬁabilit´e.
L’´echantillonnage de Gibbs et d’autres m´ethodes MCMC ont donc permis des
am´eliorations consid´erables de l’approche bay´esienne des mod`eles de m´elange,
non seulement pour leur estimation, comme nous l’avons expliqu´e ci-dessus,
mais aussi pour les proc´edures de tests et la mod´elisation, puisque des tests
bay´esiens sur le nombre de composantes d’un m´elange ont ´et´e propos´es (Men-
gersen et Robert, 1996, Richardson et Green, 1997). De plus, ces ´etudes ont
aussi mis en lumi`ere des extensions non informatives int´eressantes. Comme il
est mentionn´e dans l’Exercice 1.56, les propri´et´es particuli`eres des mod`eles de
m´elange empˆechent l’utilisation de lois a priori impropres de la forme

366
6 M´ethodes de calcul bay´esien
k
Y
i=1
π1(μi, σi) .
En fait, dans la d´ecomposition (6.6) de la loi a posteriori comme une somme sur
toutes les partitions possibles, certaines de ces partitions n’attribuent aucune
observation `a une composante donn´ee i∗du m´elange. La loi a priori sur les
param`etres correspondants (μi∗, σi∗) doit donc ˆetre propre.
Cependant, comme Mengersen et Robert (1996) l’ont montr´e, une loi a priori
impropre peut malgr´e tout ˆetre utilis´ee si les param`etres de composante sont a
priori d´ependants. Par exemple, le mod`ele de m´elange peut ˆetre reparam´etris´e en
termes d’un param`etre global de position-´echelle (μ, τ), de loi a priori π(μ, τ) =
1/τ. Dans ce cas, l’information a priori `a fournir peut se r´eduire au choix d’un
hyperparam`etre unique ξ > 0. En eﬀet, si (6.25) s’´ecrit
p1N (μ, τ 2) + (1 −p1)
˘
p2N (μ + τθ1, τ 2σ2
1)
+(1 −p2)
˘
p3N (μ + τθ1 + τσ1θ2, τ 2σ2
1σ2
2) + . . .
¯¯
,
une loi a priori acceptable est pi ∼Be(1/2, 1/2), θi ∼N (0, ξ2) et σi ∼
(1/2)U[0,1] + (1/2)Pa(2, 1), cette derni`ere loi ´etant justiﬁ´ee en tant que loi
uniforme soit pour σi, soit pour 1/σi ; voir Roeder et Wasserman (1997) et Ro-
bert et Titterington (1998) pour des propositions similaires.
6.6.7 ´Echantillonnage de Gibbs pour les processus de Dirichlet
Nous avons mentionn´e dans la Note 1.8.2 l’int´erˆet de l’utilisation de processus
de Dirichlet pour l’estimation bay´esienne non param´etrique. Nous indiquons ici
comment l’´echantillonnage de Gibbs peut ˆetre mis en œuvre dans le cas gaussien.
Soient xi ∼N (θi, σ2
i ) (1 ≤i ≤n) avec (θi, σ2
i ) ∼π et π distribu´e comme un
processus de Dirichlet D(α, π0). Comme nous l’avons d´ej`a mentionn´e dans la
Note 1.8.2, π0 est l’esp´erance a priori de π et α est un degr´e de concentration
autour de π0. La loi marginale correspondante est un m´elange de lois normales,
dont le nombre de composantes est al´eatoire et compris entre 1 et n. Le fait
que le nombre de composantes puisse ˆetre aussi ´elev´e que la taille d’´echantillon
reﬂ`ete le caract`ere non contraignant de cette mod´elisation et peut ˆetre reli´e
au fait que l’estimateur usuel `a noyau recourt toujours `a n composantes. Une
autre cons´equence importante de cette mod´elisation est que les lois a priori
conditionnelles des (θi, σ2
i ) peuvent s’´ecrire
π[(θi, σ2
i )|(θj, σ2
j )j̸=i] = α(α + n −1)−1π0(θi, σ2
i )
(6.33)
+(α + n −1)−1 X
j̸=i
I((θi, σ2
i ) = (θj, σ2
j )).
La d´ecomposition (6.33) met en ´evidence l’eﬀet mod´erateur de l’a priori de
Dirichlet : de nouvelles valeurs de (θ, σ2) n’apparaissent qu’avec une probabilit´e
α/(α + n −1).
Une loi conditionnelle similaire peut ˆetre obtenue a posteriori, `a savoir pour les
observations x1, . . . , xn,
π[(θi, σ2
i )|(θj, σ2
j )j̸=i, xi] = qi0π0(θi, σ2
i |xi)
+
X
j̸=i
qijI((θi, σ2
i ) = (θj, σ2
j )),
(6.34)

6.6 Notes
367
o`u qi0 + P
j̸=i qij = 1 et (i ̸= j)
qi0 ∝α
Z
e−(xi−θi)2/2σ2
i σ−1
i
π0(θi, σ2
i )dθidσ2
i ,
qij ∝e−(xi−θj)2/2σ2
j σ−1
j
.
Pour les lois conditionnelles (6.34), (θi, σ2
i ) est un nouveau param`etre avec pro-
babilit´e qi0 et est ´egal `a un autre param`etre avec probabilit´e 1 −qi0. Donc,
l’´echantillonnage de Gibbs peut ˆetre mis en œuvre en simulant successivement
ces lois conditionnelles pour chaque i et en proposant comme loi marginale
pour (x1, . . . , xn) un m´elange de k lois normales, o`u k est le nombre de valeurs
diﬀ´erentes parmi les simulations (θi, σ2
i ). Notons que ce nombre k varie `a chaque
it´eration.
Une autre cons´equence de cette repr´esentation est que, si on s’int´eresse `a la
densit´e pr´edictive f, il est possible de simuler un ´echantillon de taille T de la
loi π(θ, σ2|x1, . . . , xn), (θ(t), σ(t)2) (t = 1, . . . , T ), en simulant successivement
(θi, σ2
i ) (1 ≤i ≤n) selon (6.34) et (θn+1, σ2
n+1) selon
π(θn+1, σ2
n+1) = π[(θn+1, σ2
n+1)|(θi̸=n+1, σ2
i̸=n+1)]
= α(α + n)−1π0(θn+1, σ2
n+1)
+(α + n)−1
n
X
j=1
I((θn+1, σ2
n+1) = (θj, σ2
j )).
La densit´e pr´edictive peut ˆetre alors estim´ee par
1
T
T
X
t=1
f(x|θ(t), σ(t)2) ,
(6.35)
et est donc du mˆeme ordre de complexit´e qu’un estimateur de la densit´e `a
noyau, puisqu’elle fait formellement intervenir T termes. En fait, l’´echantillon
des (θ(t), σ(t)2) comporte un petit nombre de valeurs simul´ees selon π0(θn+1,
σ2
n+1) et principalement des valeurs (θi, σ2
i ) (1 ≤i ≤n) elles aussi simul´ees
selon π0, mais avec des r´epliques. Des am´eliorations de cette m´ethode directe
de simulation de processus de Dirichlet a priori sont propos´ees dans Escobar
et West (1995), comme le calcul du nombre de composantes dans la loi des
(θi, σ2
i ) (1 ≤i ≤n). Cependant, le choix des hyperparam`etres est relativement
important pour de bonnes performances de l’estimateur r´esultant.

7
Choix et comparaison de mod`eles
“Right this minute, wherever he is, Galad is puzzling over some-
thing he may never have faced before. Two things that are right, but
opposite.”
Robert Jordan, The Fires of Heaven.
7.1 Motivations
Nous l’avons vu dans le Chapitre 5 : le choix de mod`ele peut ˆetre consid´er´e
comme un cas particulier de la th´eorie des tests. Les raisons pour lesquelles
nous avons trait´e ce probl`eme `a part sont pr´esent´ees ci-dessous. Ce chapitre
devrait ˆetre accessible sans autre pr´e-requis sur le choix de mod`ele que l’id´ee
simple que c’est un outil pour comparer des mod`eles et ´eventuellement en
choisir un parmi ceux-ci.
Du point de vue conceptuel, la proc´edure inf´erentielle d´epasse le cadre du
Chapitre 5 : nous travaillons maintenant sur des mod`eles et non plus sur des
param`etres. Ainsi, pour un probl`eme donn´e, le choix entre un mod`ele exponen-
tiel et un mod`ele de Weibull sera certainement plus lourd de cons´equences que
de d´ecider si un param`etre θ vaut 1 ou 1.2, par exemple. En d’autres termes,
l’incertitude sur la distribution d’´echantillonnage f(x) est ici tr`es grande et
d´epasse largement le cadre des chapitres pr´ec´edents, o`u elle portait seulement
sur la valeur d’un param`etre inconnu (de dimension ﬁnie).
Du point de vue de la mod´elisation, le choix de mod`ele rel`eve plus de l’es-
timation que des tests classiques. Par rapport au Chapitre 5, o`u nous avons

370
7 Choix et comparaison de mod`eles
vu que tester l’hypoth`ese H0 : θ ∈Θ0 est ´equivalent `a estimer la fonction
indicatrice IΘ0, le choix de mod`ele peut consister `a choisir entre plusieurs pos-
sibilit´es, disons les mod`eles M1, . . . , Mp, et la d´ecision sur “le” mod`ele revient
`a estimer l’indice μ ∈{1, . . . , p} associ´e `a ce mod`ele (ou, plus exactement, `a
trouver la distribution a posteriori de cet indice). Naturellement, il existe de
nombreux cas o`u il faut choisir de fa¸con ferme et d´eﬁnitive le meilleur mod`ele
(c’est-`a-dire le mod`ele le plus appropri´e compte tenu des donn´ees), mais cela
semble moins cat´egorique que de d´ecider si l’hypoth`ese H0 est vraie.
Du point de vue num´erique, le choix de mod`ele met en jeu des structures
plus complexes qui n´ecessitent presque syst´ematiquement le recours `a des tech-
niques num´eriques avanc´ees comme celles du Chapitre 6. D’o`u la s´eparation
entre le Chapitre 5 et le pr´esent chapitre, qui nous permet ´egalement de re-
venir au calcul des facteurs de Bayes et pseudo-facteurs de Bayes `a l’aide de
m´ethodes de Monte Carlo et MCMC (Section 7.3). En r´ealit´e, la comparaison
de mod`eles implique l’emploi d’outils encore plus ´evolu´es que ceux du Chapitre
6. C’est pourquoi nous pr´esenterons dans la Section 7.3.4 des m´ethodes de si-
mulation permettant de manipuler des collections d’espaces de param`etres
(aussi appel´es espaces de dimension variable) et con¸cues sp´ecialement pour le
choix de mod`ele.
Enﬁn, comme nous le sous-entendions ci-dessus en parlant d’´elargissement
du cadre d’inf´erence, nous allons laisser un moment le domaine bien balis´e
des mod`eles param´etriques : `a plusieurs reprises dans ce chapitre, nous nous
retrouverons dans des cas pour lesquels la “vraie” distribution f est inconnue
et o`u nous essayons de d´eterminer la distance entre f et une (ou plusieurs)
familles de distributions {fθ; θ ∈Θ}. Pour les tests de validit´e d’ajustement
de la Section 7.6 par exemple, nous avons besoin d’un estimateur non pa-
ram´etrique de f. Nous rencontrerons des probl`emes analogues pour la s´election
de variables (Section 7.5), o`u une solution est d’introduire un mod`ele imbri-
quant, diﬀ´erent du vrai mod`ele.
Il reste que beaucoup des id´ees expos´ees dans ce chapitre le sont aussi dans
le Chapitre 5, ´etant donn´e que les techniques employ´ees sont similaires, prin-
cipalement les probabilit´es a posteriori et les facteurs de Bayes. De nombreux
auteurs utilisent cet argument pour minimiser les diﬀ´erences entre les tests
classiques et le choix de mod`ele. Voir par exemple Berger et Pericchi (2001),
dont l’´etude sur le choix de mod`ele comprend surtout des exemples de tests
d’hypoth`eses nulles comme H0 : θ = 0.
Le choix de mod`ele, ainsi que les sujets connexes de s´election de variables
et de tests de validit´e d’ajustement ont ´et´e l’objet d’une attention consid´erable
ces derni`eres ann´ees, en partie grˆace au d´eveloppement de nouvelles m´ethodes
num´eriques, et nous n’en pr´esentons ici qu’une vision tr`es partielle. Les lec-
teurs d´esireux d’approfondir le sujet pourront consulter par exemple le recueil
d’articles ´edit´e par Racugno (1999).

7.1 Motivations
371
7.1.1 Choix entre plusieurs mod`eles
Le choix de mod`ele semble s’aﬀranchir du paradigme bay´esien dans le sens
o`u la distribution d’´echantillonnage f elle-mˆeme n’est pas connue pr´ecis´ement.
Cette incertitude rend diﬃcile le conditionnement par rapport `a l’observation
x. Ce changement de paradigme apparaˆıtra encore plus nettement dans la
Section 7.6 o`u nous chercherons `a r´epondre `a la question : f appartient-elle `a
la famille {fθ; θ ∈Θ} ?, l’hypoth`ese alternative ´etant compl`etement ouverte.
Consid´erons d’abord le cadre plus restrictif dans lequel plusieurs mod`eles (pa-
ram´etriques) sont en concurrence,
Mi : x ∼fi(x|θi),
θi ∈Θi,
i ∈I ,
l’ensemble I des indices pouvant ˆetre ´eventuellement inﬁni. Dans ce cas,
le point de vue bay´esien est plus facile `a appliquer : on peut envisager de
construire une distribution a priori pour chaque mod`ele Mi comme s’il s’agis-
sait du seul vrai mod`ele consid´er´e.
Le cadre minimal consiste `a choisir parmi un nombre r´eduit de mod`eles.
Ces mod`eles ont pu ˆetre s´electionn´es pour des raisons tr`es vari´ees, des plus
simples, comme l’historique de la discipline ou la commodit´e de calcul, aux
plus compliqu´ees et mieux justiﬁ´ees.
Exemple 7.1. Dans l’Exemple 1.5, nous avons vu un jeu de donn´ees analys´e
par Lenk (1999) et ´etudiant la corr´elation entre le taux de chˆomage et le
nombre mensuel d’accidents dans le Michigan entre 1978 et 1987. En fait,
avant de s’int´eresser au lien entre les deux variables, on pourrait proposer
deux mod`eles diﬀ´erents pour le nombre d’accidents N dans un mois :
M1 : N ∼Poi(λ),
λ > 0
et
M2 : N ∼N eg(m, p),
m ∈N∗, p ∈[0, 1] .
∥
Dans des cas plus compliqu´es, il y a trop peu d’information disponible pour
´eliminer un nombre substantiel de mod`eles et, par cons´equent, l’ensemble de
ceux qui restent `a consid´erer est grand. Nous sommes alors plus proches d’une
perspective non param´etrique.
Exemple 7.2. Un exemple cit´e dans la plupart des ouvrages portant sur l’es-
timation de m´elanges est celui des donn´ees galactiques. D’abord abord´e par
Roeder (1992), il a ensuite ´et´e analys´e par, entre autres, Chib (1995), Escobar
et West (1995), Phillips et Smith (1996), Richardson et Green (1997) Roeder
et Wasserman (1997) et Robert et Mengersen (1999). Il consiste en l’obser-
vation de quatre-vingt-deux vitesses de galaxies, repr´esent´ees sur la Figure

372
7 Choix et comparaison de mod`eles
7.1. Pour des raisons li´ees `a l’Astrophysique, cet ensemble peut ˆetre mod´elis´e
par un m´elange de distributions normales dont le nombre de composantes k
est inconnu. (Une composante du m´elange est associ´ee `a un groupement de
galaxies.) Les mod`eles en concurrence sont donc
Mi : nj ∼
i

ℓ=1
pℓi N (μℓi, σ2
ℓi) ,
(7.1)
pour i allant de 1 `a une borne sup´erieure arbitraire.
∥
1.0
1.5
2.0
2.5
3.0
3.5
0.0
0.5
1.0
1.5
2.0
vitesses
Fig. 7.1. Histogramme des donn´ees galactiques de Roeder (1992).
Dans d’autres contextes, comme celui de la s´election de covariables (ou va-
riables explicatives) (Section 7.5), le nombre de mod`eles `a consid´erer augmente
de fa¸con tr`es importante avec l’inclusion de diverses combinaisons possibles
de covariables.
Exemple 7.3. (Gelfand, 1996) Pour ´evaluer la vitesse de croissance de cinq
orangers, on mesure leurs circonf´erences (yit pour l’arbre i) `a diﬀ´erents ˆages
Tt. Les r´esultats sont pr´esent´es en Table 7.1. Les mod`eles ´etudi´es sont (i =
1, · · · , 5, t = 1, . . . , 7)
M1 : yit ∼N (β10 + b1i, σ2
1)
M2 : yit ∼N (β20 + β21Tt + b2i, σ2
2)
M3 : yit ∼N

β30
1 + β31 exp(β32Tt), σ2
3

M4 : yit ∼N

β40 + b4i
1 + β41 exp(β42Tt), σ2
4

,
o`u les bji sont des eﬀets al´eatoires, distribu´es selon une loi N (0, τ2). Ces
mod`eles sont construits selon la graduation suivante : M1 est un mod`ele `a eﬀet
individuel simple–sans eﬀet temporel ; dans M2, l’eﬀet temporel est lin´eaire;
la d´ependance temporelle devient non lin´eaire dans M3 et on ajoute en sus
des eﬀets individuels pour obtenir le mod`ele M4.
∥

7.1 Motivations
373
L’Exemple 7.3 montre bien qu’il y a souvent beaucoup d’arbitraire lors de
la cr´eation de familles de mod`eles pour la s´election. De mˆeme, dans l’Exemple
7.2, l’hypoth`ese de normalit´e a ´et´e retenue pour son cˆot´e pratique et non pour
des motivations concr`etes issues de l’Astrophysique.
Tab. 7.1. Circonf´erences de cinq orangers (en millim`etres) pour diﬀ´erents ˆages (en
jours). (Source : Gelfand, 1996.)
arbre
jours
1
2
3
4
5
118
30
33
30
32
30
484
58
69
51
62
49
664
87 111
75
112 81
1004 115 156 108 167 125
1231 120 172 115 179 142
1372 142 203 139 209 174
1582 145 203 140 214 177
On per¸coit bien dans les Exemples 7.1 `a 7.3 une diﬃcult´e fondamentale
li´ee au choix de mod`ele : alors qu’aucun mod`ele n’est rigoureusement exact,
plusieurs mod`eles peuvent convenir dans une situation donn´ee. Se forcer `a
choisir un et un seul mod`ele reproduit donc le probl`eme rencontr´e dans le
Chapitre 5, o`u les proc´edures de test dont les valeurs sont restreintes `a {0, 1}
semblaient inadapt´ees. En particulier, l’incertitude quant au mod`ele retenu
n’est pas prise en compte. (Ce probl`eme trouvera une solution radicale dans
la Section 7.4 o`u on ´evite compl`etement le choix d’un mod`ele particulier.)
Dans l’Exemple 7.2 comme dans l’Exemple 7.3, certains mod`eles sont des
sous-mod`eles d’autres mod`eles. Cela cr´ee un probl`eme imbriqu´e suppl´emen-
taire. Ainsi, dans l’Exemple 7.2, un m´elange `a k composantes est un sous-
mod`ele d’un m´elange `a (k+p) composantes, avec p composantes de poids nuls.
Alors que, du point de vue de la mod´elisation, on a toujours int´erˆet `a prendre
le mod`ele le plus complet, la d´ecision est moins ´evidente d’un point de vue
statistique, puisque ce choix n´ecessitera d’estimer un plus grand nombre de
param`etres `a partir du mˆeme ´echantillon ! Un crit`ere de choix de mod`ele doit
donc non seulement mesurer l’ajustement57 aux donn´ees, mais aussi prendre
en compte les erreurs d’estimation.
57On parle de surajustement lorsqu’on bˆatit un mod`ele qui s’accorde exception-
nellement bien aux donn´ees courantes mais dont les performances de pr´evision sont
tr`es m´ediocres. Cette opposition entre ajustement et erreur d’estimation ´etend l’op-
position entre biais et variance rencontr´ee en Statistique classique et, en particulier,
dans l’approche bay´esienne empirique (Chapitre 10).

374
7 Choix et comparaison de mod`eles
7.1.2 Champs d’application
Les exemples pr´ec´edents le montrent bien, le choix de mod`ele n’est pas
une proc´edure (d’estimation) monolithique, mais peut ˆetre employ´e pour de
nombreuses raisons qui ne sont pas toujours ´evidentes pour (ou qui ne sont pas
toujours ´enonc´ees explicitement par) l’exp´erimentateur (ou le “client”). Par
cons´equent, il semble impossible de se placer dans un cadre strict de Th´eorie
de la D´ecision (ou tout du moins de pr´eserver le mˆeme cadre pour toutes les
utilisations envisag´ees). Parmi ces applications possibles, le choix de mod`ele
peut ˆetre utile comme
(i) une premi`ere ´etape dans la construction d’un mod`ele, comme dans l’Ex-
emple 7.1, lorsque l’intuition sugg`ere quelques mod`eles et que l’exp´erimen-
tateur veut d´eterminer lequel r´ealise le “meilleur” ajustement des donn´ees
disponibles. Il ne s’agit l`a que d’un premier pas vers la Statistique non
param´etrique, dans la mesure o`u il n’y a aucune raison de penser que l’un
des mod`eles consid´er´es est correct.
(ii) inversement, une derni`ere ´etape de la v´eriﬁcation de mod`eles, comme dans
l’Exemple 7.3. Un mod`ele ou une famille de mod`eles ont ´et´e choisis pour
diverses raisons th´eoriques ou pratiques et on cherche `a savoir s’ils corres-
pondent aux donn´ees. De mˆeme, dans le domaine des tests d’ad´equation, le
mod`ele n’est pas clairement d´eﬁni en dehors de l’hypoth`ese nulle (comme
nous l’expliquerons dans la Section 7.6).
(iii) une aide `a l’am´elioration de mod`eles, comme pour passer de M1 `a M2 ou
de M3 `a M4 dans l’Exemple 7.3. ´Etant donn´e un mod`ele, ´eventuellement
valid´e par un test d’ad´equation, le but est d’´etudier des modiﬁcations
pour am´eliorer l’ajustement, ou, en d’autres termes, d’imbriquer le mod`ele
existant dans une classe de mod`eles pour v´eriﬁer que le choix initial est
suﬃsamment bon.
(iv) au contraire, un outil pour l’´elagage de mod`eles58, lorsque le mod`ele
consid´er´e est jug´e trop compliqu´e pour ˆetre d’une quelconque utilit´e pra-
tique, comme dans l’Exemple 7.2 avec k = 50, ou lorsque, en vertu du prin-
cipe de parcimonie (Note 6.6.6), on souhaite examiner des sous-mod`eles
plus simples pour voir s’ils s’ajustent assez bien aux donn´ees. C’est le cas
en particulier dans le cadre de la s´election de variables, o`u on a `a sa dis-
position un grand ensemble de covariables et on souhaite ne conserver que
les plus importantes.
(v) plus simplement, une comparaison entre mod`eles, lorsqu’on h´esite entre
quelques mod`eles qui convenaient bien lorsqu’ils ´etaient utilis´es sur d’aut-
res ´echantillons et qu’on cherche un moyen de trouver celui qui a le meilleur
ajustement sur l’´echantillon courant, comme dans l’Exemple 7.1.
58Cette expression prend son sens litt´eral lorsqu’il s’agit d’´elaguer de la plupart
de ses branches un arbre de mod`eles possibles en s´election de variables.

7.2 Comparaison bay´esienne de mod`eles
375
(vi) de fa¸con plus ambitieuse, une mani`ere de faire du test d’hypoth`eses, sui-
vant un protocole scientiﬁque classique selon lequel on ´echafaude plusieurs
hypoth`eses `a l’aide de consid´erations th´eoriques et o`u on les v´eriﬁe par
des exp´eriences d´edi´ees. (On pense notamment `a la naissance de la th´eorie
de la gravitation, puis au passage `a la th´eorie de la gravitation d’Einstein
oppos´ee `a celle de Newton, ou encore aux th´eories cosmologiques d’expan-
sion ou de contraction de l’Univers, voir par exemple Feyerabend, 1975.)
(vii) dans un cadre plus limit´e, une fa¸con de tester l’eﬃcacit´e de pr´evision,
comme, par exemple, dans le domaine de la ﬁnance. Contrairement `a
l’application (vi), les mod`eles en eux-mˆemes n’int´eressent pas l’exp´eri-
mentateur qui se pose simplement la question de les ´evaluer en termes
de leurs performances de pr´evision. Dans le cadre de l’Exemple 7.2, on
pourrait ainsi chercher `a ´evaluer la capacit´e pour chaque mod`ele d’allouer
une nouvelle galaxie au groupe de galaxies le plus ad´equat.
Les applications du choix de mod`ele sont manifestement aussi vari´ees que
celles de la Statistique puisqu’il existe bien peu de cas o`u un mod`ele ou une fa-
mille param´etrique donn´es sont unanimement accept´es! Citons tout de mˆeme
quelques domaines o`u le choix de mod`ele s’est r´ev´el´e particuli`erement utile :
en analyse d’images, lorsqu’on compare diﬀ´erentes structures de voisinage
(Cressie, 1993); pour les mod`eles graphiques et syst`emes experts lorsqu’on
cherche `a supprimer des liens entre variables (Cowell et al., 1999); dans les
mod`eles `a dimensions variables, comme les mod`eles ARMA(p, q) avec p et q
inconnus ; pour l’inf´erence causale, o`u il s’agit de d´ecider si A a un eﬀet sur
B, connaissant un ensemble de variables C1, . . . , Cp (Shafer, 1996, Robins et
Wasserman, 2000).
7.2 Comparaison bay´esienne de mod`eles
7.2.1 Mod´elisation sp´eciﬁque de l’a priori
Comme pour d’autres probl`emes, la r´eponse bay´esienne standard consiste
`a placer une distribution a priori sur les ´el´ements inconnus, ce qui, dans le cas
pr´esent, revient `a proposer une mod´elisation a priori non plus seulement sur les
param`etres, mais aussi sur les mod`eles eux-mˆemes. L’espace des param`etres
associ´e `a l’ensemble des mod`eles (7.1) peut s’´ecrire
Θ =
8
i∈I
{i} × Θi ,
(7.2)
l’indice de mod`ele μ ∈I ´etant maintenant int´egr´e `a l’espace des param`etres.
Par cons´equent, il suﬃt de savoir attribuer des probabilit´es pi aux diﬀ´erentes
valeurs d’indice, c’est-`a-dire en fait aux diﬀ´erents mod`eles Mi (i ∈I), puis
de d´eﬁnir des lois a priori πi(θi) sur les sous-espaces des param`etres Θi pour
appliquer, comme d’habitude, le th´eor`eme de Bayes :

376
7 Choix et comparaison de mod`eles
p(Mi|x) = P(μ = i|x) =
pi

Θi
fi(x|θi)πi(θi)dθi

j
pj

Θj
fj(x|θj)πj(θj)dθj
.
(7.3)
Une premi`ere solution simple est d’utiliser la mod´elisation a priori pour
obtenir un estimateur MAP (marginal) de μ, ce qui est ´equivalent `a d´eterminer
le mod`ele de plus grande probabilit´e a posteriori p(Mi|x). On peut ´egalement
calculer directement une densit´e pr´edictive en y avec la moyenne :

j
pj

Θj
fj(y|θj)πj(θj|x)dθj =

j
p(Mj|x) mj(y)
(7.4)
N´eanmoins, il est souvent n´ecessaire de faire appel de fa¸con plus marqu´ee `a
la Th´eorie de la D´ecision.
Le formalisme bay´esien usuel ou tout du moins la mod´elisation a priori
se heurte ici `a des diﬃcult´es nouvelles : la solution consistant `a repr´esenter
la collection de mod`eles par (7.2) suppose la construction d’une distribution
a priori (πi, pi) pour chaque i ∈I, ce qui est d´elicat lorsque I est inﬁni. De
plus, toutes les lois a priori πi doivent ˆetre des lois propres puisqu’il n’y a pas
unicit´e des facteurs d’´echelles pour les lois a priori impropres, comme nous
l’avons vu dans le Chapitre 5. En outre, si certains mod`eles sont imbriqu´es
dans d’autres, c’est-`a-dire si
Mi0 ⊂Mi1 ,
le choix de πi0 devrait ˆetre li´e `a celui de πi1 et peut-ˆetre aussi celui de pi0 `a
celui de pi1. Par exemple, si M1 = M2 ∪M3, il n’est pas absurde d’exiger que
p(M1) = p(M2) + p(M3) ,
ou au moins que p(M1) ≥p(M2)+p(M3). De fa¸con analogue, si deux mod`eles
Mi0 et Mi1 ne sont pas imbriqu´es l’un dans l’autre, la mod´elisation a priori
devrait pouvoir s’adapter `a un troisi`eme mod`ele Mi2 imbriquant Mi0 et Mi1.
(En ´Econom´etrie, on appelle imbrication (traduction libre d’encompassing)
cette technique de cr´eation d’un supermod`ele.)
Formulons une derni`ere remarque importante et sp´eciﬁque au probl`eme du
choix de mod`ele : les param`etres communs `a plusieurs mod`eles doivent ˆetre
consid´er´es comme des entit´es diﬀ´erentes. Ce probl`eme est souvent n´eglig´e
dans la litt´erature, y compris dans Jeﬀreys (1961), parce que les param`etres
communs peuvent ˆetre formellement int´egr´es en utilisant la mˆeme loi de distri-
bution a priori, mˆeme (surtout !) quand celle-ci est impropre. Une autre fa¸con,
moins extrˆeme, de contourner le principe ci-dessus est de sugg´erer, comme
dans Berger et Pericchi (1998), que l’utilisation du mˆeme a priori impropre
pour les param`etres communs permet de r´egler le probl`eme de la constante
de normalisation (Exercice 7.4), mais nous ne saurions recommander de fa¸con
syst´ematique cette solution sp´eciﬁque.

7.2 Comparaison bay´esienne de mod`eles
377
Exemple 7.4. (Suite de l’Exemple 7.3)
Regardons de plus pr`es les
mod`eles M1 et M2 : bien que β10 et β20 aient en commun le fait d’ˆetre des
intercepts, comme σ2
1 et σ2
2 celui d’ˆetre des variances, ils sont bel et bien des
quantit´es diﬀ´erentes, `a cause de la pr´esence du terme β21Tt dans le mod`ele
M2. En particulier, dans le cas o`u M2 est le vrai mod`ele, β10 correspond `a
β20 d´ecal´e de la moyenne des β21Tt et σ2
1 est plus grand que σ2
2 `a cause d’une
ad´equation moins ﬁd`ele (voir l’Exercice 7.5).
∥
Le probl`eme d’inf´erence n’est pas plus facile `a formaliser dans le cadre de la
Th´eorie de la D´ecision, `a cause de toutes les applications potentielles du choix
de mod`ele, d´ecrites dans la Section 7.1.2, et qui ne sont pas n´ecessairement
compatibles entre elles. Le choix de mod`ele est en g´en´eral une partie d’un
processus de d´ecision global : le mod`ele est d’abord construit, puis am´elior´e
par extension ou r´eduction (comme nous l’avons expliqu´e dans les points
(iii) et (iv) ci-dessus). Ce n’est qu’ensuite qu’on d´ecide de s´electionner ce
mod`ele comme le “vrai” mod`ele en vue d’applications futures. Trouver une
fonction de coˆut tenant compte de toutes ces ´etapes est clairement impos-
sible, mais c’est envisageable si on s’int´eresse plus sp´eciﬁquement `a l’´etape
de s´election. Par exemple, les moyennes de mod`eles comme celle d´ecrite en
(7.4) ne sont pas acceptables de ce point de vue parce que la proc´edure d’esti-
mation, en incluant tous les mod`eles compatibles avec les donn´ees, p`eche par
exc`es d’ind´ecision ! Si on ne dispose d’aucune (ou de trop peu) d’information
sur les cons´equences d’un mauvais choix de mod`ele et qu’on est par cons´equent
incapable de construire une fonction de coˆut, L(μ, d) ou L((μ, θμ), (d, ϑ)),
d’aide `a la d´ecision, une solution, d´efendue `a la ﬁn de la Section 7.1.1, est
de pr´evenir le surapprentissage en introduisant dans la fonction de coˆut des
termes de p´enalisation portant sur le nombre de param`etres du mod`ele (c’est-
`a-dire sa taille). Ce point est d´etaill´e dans la Section 7.2.3. Voir aussi Carota
et al. (1996) pour une fa¸con de juger les mod`eles `a l’aide de la Th´eorie de la
D´ecision, relevant plus du point (iii) ci-dessus et faisant usage des divergences
de Kullback-Leibler comme dans la Section 7.5.
Une autre diﬃcult´e r´eside dans le calcul de densit´es pr´edictives et margi-
nales et d’autres quantit´es `a ´evaluer dans le cadre du choix de mod`ele. Il ne
s’agit bien sˆur pas d’un probl`eme sp´eciﬁque au choix de mod`ele (voir le Cha-
pitre 6), mais un certain nombre de particularit´es plaident pour la recherche
de solutions sur mesure :
(i) Les espaces de param`etres sont souvent de dimension inﬁnie, comme dans
(7.1), ce qui oblige `a faire appel `a des notions plus compliqu´ees de th´eorie
de la mesure.
(ii) Le fait de devoir int´egrer sur plusieurs espaces de param`etres pour ´evaluer
des quantit´es a posteriori ou pr´edictives augmente d’autant le temps de
calcul n´ecessaire, sans possibilit´e, en g´en´eral, d’exporter les r´esultats des
calculs d’un sous-espace `a un autre.

378
7 Choix et comparaison de mod`eles
(iii) L’impl´ementation d’algorithmes MCMC (Chapitre 6) dans un espace de
param`etres vu comme somme directe de diﬀ´erents sous-espaces n´ecessite
des techniques markoviennes plus ´elabor´ees.
(iv) Dans certains contextes, comme celui de la s´election de variables, la col-
lection de mod`eles est ﬁnie mais exponentiellement grande et elle ne peut
donc pas ˆetre explor´ee int´egralement.
Dans tous les cas, sauf peut-ˆetre pour les mod`eles les plus simples, on a donc
recours `a des techniques num´eriques (approximatives) avanc´ees, car il est im-
possible d’obtenir une repr´esentation analytique et exacte de la loi a posteriori.
Nous d´etaillons ces techniques en Section 7.3.
7.2.2 Facteurs de Bayes
Une fois d´eﬁnies la mod´elisation (7.1) et les distributions a priori cor-
respondantes, la proc´edure inf´erentielle est assimilable `a un probl`eme de
test g´en´erique. La solution propos´ee par Kass et Raftery (1995) et soute-
nue ´egalement par Berger et Pericchi (2001) est de faire appel aux facteurs de
Bayes. Par exemple, dans le cas de la comparaison des mod`eles M1 et M2 :
B12 = P(M1|x)
P(M2|x)
9P(M1)
P(M2) =

Θ1
f1(x|θ1)π1(θ1)dθ1

Θ2
f2(x|θ2)π2(θ2)dθ2
.
Le cadre est donc analogue `a celui de la Section 5.2 et, par cons´equent, les diﬃ-
cult´es sont ´egalement similaires, bien qu’accrues par un plus grand nombre de
mod`eles `a consid´erer (peut-ˆetre mˆeme une inﬁnit´e !) et par la n´ecessit´e d’utili-
ser beaucoup plus fr´equemment des lois a priori non informatives. Remarquons
ici qu’on peut comparer les mod`eles sur la base des facteurs de Bayes, couple
(Mi, Mj) par couple, grˆace `a la coh´erence des facteurs de Bayes, qui v´eriﬁent
Bπ
ij = Bπ
ikBπ
kj, ce qui assure la transitivit´e de l’ordonnancement de mod`eles.
(Mais rappelons que cette propri´et´e n’est pas v´eriﬁ´ee par les pseudo-facteurs
de Bayes d´eﬁnis dans la Section 5.2.6.)
Pour exactement les mˆemes raisons que dans la Section 5.2.5, les lois a
priori impropres sont `a proscrire (`a moins qu’elles ne portent sur des pa-
ram`etres communs `a tous les mod`eles, comme nous l’avons d´ecrit pr´ec´edemment).
En outre, les lois a priori vagues, c’est-`a-dire les lois a priori propres ayant
une tr`es grande variance–utilis´ees notamment dans BUGS, voir Note 6.6.2–ne
r´esolvent pas le probl`eme, comme le montre le paradoxe de Jeﬀreys-Lindley
(Section 5.2.5).
Exemple 7.5. (Suite de l’Exemple 7.1) Soient les distributions a priori
π1(λ) = G a(α, β) ,
π2(m, p) = 1
M I{1,··· ,M}(m)I[0,1](p) .

7.2 Comparaison bay´esienne de mod`eles
379
La seconde loi a priori est uniforme sur l’espace des param`etres Θ2. Le facteur
de Bayes est alors :
Bπ
12 =
βα
Γ(α)
 ∞
0
λα+x−1
x!
e−λβdλ
1
M
M

m=1
 1
0
 m
x −1

px(1 −p)m−xdp
= Γ(α + x)
x! Γ(α) β−x9 1
M
M

m=1
x
(m −x + 1)(m + 1)
= M(m + 1)(x + α −1) · · · α
x(x −1) · · · 1
β−x9
M

m=1
x
m −x + 1
Les choix de α et β ont une grande inﬂuence sur la valeur de Bπ
12, en particulier
lorsque tous deux tendent vers 0 (Exercice 7.10).
∥
Cette diﬃcult´e fondamentale avec les lois a priori impropres peut se
r´esoudre par des solutions pseudo-bay´esiennes, en ayant recours `a un ´echan-
tillon minimal d’apprentissage ou `a des observations virtuelles, comme dans
la Section 5.2.6. (C’est d’ailleurs dans le contexte du choix de mod`ele lin´eaire
ou log-lin´eaire que Spiegelhalter et Smith, 1980, furent parmi les premiers `a
sugg´erer l’utilisation de pseudo-facteurs bay´esiens.) L’´evaluation de mod`eles
sous des lois a priori impropres peut ensuite ˆetre conduite avec des facteurs de
Bayes intrins`eque ou fractionnel (avec les mˆemes r´eserves que dans la Section
5.2.6).
Exemple 7.6. (Suite de l’Exemple 7.2)
Comme nous l’avons dit dans
l’Exemple 5.19, il n’existe pas d’´echantillon minimal d’apprentissage pour les
mod`eles de m´elange, quel que soit le nombre d’observations. Par cons´equent,
les facteurs de Bayes intrins`eques et fractionnels ne sont pas applicables ici.
Une premi`ere solution, sugg´er´ee dans Diebolt et Robert (1994) `a des ﬁns
de simulation et valid´ee ensuite par Wasserman (1999), est d’imposer que
l’´echantillon (x1, . . . , xn) contienne suﬃsamment d’observations (au sens des
´echantillons d’apprentissage) issues de chaque composante (voir ´egalement
Richardson et Green, 1997). Bien que raisonnable lorsque toutes les compo-
santes sont clairement identiﬁ´ees, cette m´ethode a le d´esavantage de cr´eer une
d´ependance entre les observations (qui restent tout de mˆeme ´echangeables) et
le calcul des pseudo-facteurs de Bayes devient dans ce cas tr`es lourd.
Une alternative, adopt´ee dans Mengersen et Robert (1996) pour tester
k = 1 contre k = 2, est d’aﬀecter une distribution a priori non informative
π(μ, τ) au param`etre global de position-´echelle du mod`ele (ou de l’´echantillon)
et d’exprimer les param`etres de chaque composante en tant que perturbations
de ce param`etre de position-´echelle, avec des lois a priori propres. ´Etant donn´e

380
7 Choix et comparaison de mod`eles
que (μ, τ) est commun `a toutes les composantes, le probl`eme de normalisation
li´e `a l’a priori impropre est moins p´enalisant59.
∥
7.2.3 Le crit`ere de Schwarz
Avant d’aborder les questions li´ees aux termes de p´enalisation et aux so-
lutions bay´esiennes approch´ees (grossi`erement), nous devons pr´esenter bri`e-
vement quelques notions d’approximations asymptotiques des facteurs de
Bayes60.
Pour les mod`eles r´eguliers, lorsque M1 ⊂M2, le rapport de vraisemblance
entre M2 et M1 est approximativement distribu´e selon une loi du χ2
p2−p1,
−2 log λn ≈χ2
p2−p1
en supposant que M1 est le vrai mod`ele (Gouri´eroux et Monfort, 1996, et
Lehmann et Casella, 1998). On a
P(M2 choisi|M1) = P(λn < c|M1)
≃P(χ2
p2−p1 > −2 log(c)) > 0 .
Donc, d’un point de vue fr´equentiste, un crit`ere d´ependant seulement du rap-
port de vraisemblance ne converge pas vers une r´eponse certaine sous M1
(mais il converge sous M2). C’est la raison pour laquelle on ajoute des fac-
teurs de p´enalisation au rapport de vraisemblance pour compenser ce biais,
comme dans le cas du crit`ere d’Akaike (1983),
−2 log λn −α(p2 −p1) .
(7.5)
Pour α = log 2, on retrouve l’approximation obtenue par une proc´edure d’Ait-
kin (1991) dans laquelle l’auteur utilise les donn´ees deux fois, une premi`ere
fois pour construire un (pseudo-) a priori propre en utilisant la distribution a
posteriori, puis une seconde fois pour calculer le facteur de Bayes comme si la
distribution a priori ´etait exacte (Exercice 5.16).
Le d´eveloppement de Laplace, explicit´e dans la Section 6.2.3, donne une
approximation d’int´egrale,

Θ
exp{n h(θ)}dθ = exp{n h(ˆθ)}(2π)p/2n−p/2|H−1(ˆθ)| + O(n−1) ,
59 ´Evidemment, cet appel `a un param`etre commun `a tous les mod`eles contredit
notre recommandation ci-dessus sur les param`etres diﬀ´erents dans chaque mod`ele.
60Cette section a pour but d’illustrer le lien entre approximation bay´esienne et
crit`eres de p´enalisation usuels, pas de pr´esenter ces crit`eres. Elle peut donc ˆetre
laiss´ee de cˆot´e en premi`ere lecture, surtout si les lecteurs ne sont pas familiers avec
ces crit`eres.

7.2 Comparaison bay´esienne de mod`eles
381
o`u p est la dimension de Θ, ˆθ le point o`u h atteint son maximum et H la ma-
trice hessienne de h. En d´eveloppant `a la fois le num´erateur et le d´enominateur
du facteur de Bayes grˆace `a cette approximation, on obtient :
Bπ
12 ≃L1,n(ˆθ1,n)
L2,n(ˆθ2,n)

H−1
1 (ˆθ1,n)
H−1
2 (ˆθ2,n)

1/2  n
2π
(p2−p1)/2
,
avec p1 et p2 dimensions de Θ1 et Θ2, L1,n et L2,n fonctions de vraisemblance
calcul´ees sur n observations, et ˆθ1,n et ˆθ2,n maximums respectifs de L1 et L2.
D’o`u :
log(Bπ
12) ≃log λn + p2 −p1
2
log(n) + K(ˆθ1,n, ˆθ2,n) ,
(7.6)
en notant λn le rapport de vraisemblance usuel pour la comparaison de M1
et M2,
λn = L1,n(ˆθ1,n)/L2,n(ˆθ2,n),
et K(ˆθ1,n, ˆθ2,n) le terme restant.
Cette approximation est `a l’origine du crit`ere de Schwarz (Schwarz, 1978) :
pour M1 ⊂M2, le facteur de Bayes est approch´e par
S = −log λn −p2 −p1
2
log(n)
si le terme de reste K(ˆθ1,n, ˆθ2,n) dans (7.6) est n´egligeable devant les deux
autres, c’est-`a-dire est en O(1). (Voir Gelfand et Dey, 1994, Section 8, pour
un exemple o`u ce terme n’est pas n´egligeable.)
Le crit`ere de Schwarz, ´egalement appel´e BIC (pour Bayes Information
Criterion), est donc une premi`ere approximation `a l’ordre 1 du facteur de
Bayes, comme le d´ecrivent Kass et Raftery (1995). N´eanmoins, la pertinence
de ce crit`ere dans un contexte bay´esien est contestable pour deux raisons : (i)
l’inﬂuence de l’hypoth`ese a priori disparaˆıt; (ii) cette approximation n’est ac-
ceptable que pour les mod`eles r´eguliers. Ainsi, dans l’Exemple 7.2, le compor-
tement asymptotique (du logarithme) du rapport de vraisemblance −2 log λn
est beaucoup plus complexe que celui de l’approximation χ2
p2−p1 (voir, par
exemple, Dacunha-Castelle et Gassiat, 1999) et le crit`ere de Schwarz est ineﬃ-
cace. Berger et Pericchi (2001) recensent d’autres exemples de vraisemblances
irr´eguli`eres. En outre, dans des situations non iid, les d´eﬁnitions de n et p
peuvent ˆetre ambigu¨es, comme le soulignent Spiegelhalter et al. (1998). Du
point de vue de la complexit´e de calcul, remarquons que pour d´eterminer le
crit`ere de Schwarz, il faut disposer des estimateurs du maximum de vraisem-
blance pour tous les mod`eles.
Exemple 7.7. (Suite de l’Exemple 7.2)
On d´ecompose le crit`ere de
Schwarz en
S = log
%
L2,n(ˆθ2,n)/L1,n(ˆθ1,n)
&
−p2 −p1
2
log(n)
= log L2,n(ˆθ2,n) −p2
2 log(n) −log L1,n(ˆθ1,n) + p1
2 log(n) .

382
7 Choix et comparaison de mod`eles
La partie relative au mod`ele Mi est donc
Si = log Li,n(ˆθi,n) −pi
2 log(n) .
Si Mk est associ´e `a la composante k du mod`ele, pk = 3k −1. Pour les donn´ees
de vitesses de galaxies, Raftery (1996) obtient
S1 = −271.8 ,
S2 = −249.7 ,
S3 = −256.7 ,
S4 = −263.6 ,
en utilisant l’algorithme EM (voir Note 6.6.6) pour obtenir des approxima-
tions des estimateurs du maximum de vraisemblance ˆθi,n pour k > 1. On
en d´eduit que, selon le crit`ere de Schwarz, il faut pr´ef´erer le mod`ele `a deux
composantes aux autres. (Mais insistons de nouveau sur l’absence de vali-
dit´e asymptotique de l’approximation par une loi du χ2 de la distribution du
rapport de vraisemblance dans ce cas.)
∥
7.2.4 D´eviance bay´esienne
Spiegelhalter et al. (1998) et Spiegelhalter et al. (2002) proposent une
alternative bay´esienne aux crit`eres AIC (crit`ere d’information d’Akaike) et
BIC, utilisant la d´eviance et donc appel´e DIC (pour Deviance Information
Criterion). Ce crit`ere est plus satisfaisant que les pr´ec´edents parce qu’il prend
en compte l’information a priori et int`egre un facteur de p´enalisation naturel `a
la log-vraisemblance. De plus, il permet d’utiliser des lois a priori impropres,
puisque chaque mod`ele est consid´er´e s´epar´ement. En revanche, il ne rentre
pas naturellement dans un sch´ema d´ecisionnel bay´esien et certains, comme
Dawid (2002), critiquent sa pertinence dans une perspective bay´esienne. Sans
vouloir entamer une discussion de cet ordre, on peut eﬀectivement remarquer
que la d´eﬁnition mˆeme du crit`ere DIC est entach´ee d’impr´ecision et que sa
g´en´eralisation en dehors des familles exponentielles et des mod`eles lin´eaires
g´en´eralis´es n’est pas naturelle (voir Celeux et al., 2005).
Comme nous l’avons soulign´e en Section 7.2.3, ´etant donn´e un mod`ele
f(x|θ) avec une distribution a priori associ´ee π(θ), la d´eviance61 D(θ) =
−2 log(f(x|θ)) n’est pas une bonne mesure discriminante, puisqu’elle est
biais´ee en faveur des mod`eles `a plus grande dimension. Bien sˆur, cela reste
vrai pour sa distribution a posteriori. Spiegelhalter et al. (2002) introduisent
une d´eviance p´enalis´ee,
61Dans les mod`eles lin´eaires g´en´eralis´es (McCullagh et Nelder, 1989), la d´eviance
est en g´en´eral ajust´ee avec un terme suppl´ementaire en y comme f(y|ˆθ(y)) avec ˆθ(y)
un estimateur arbitraire de θ. Lorsque ce terme ne d´epend pas du mod`ele ou est
choisi une fois pour toutes pour un mod`ele particulier comme le mod`ele complet ou
imbriquant, il n’y a ´evidemment aucune diﬀ´erence entre le choix de mod`ele fond´e
sur D(θ) et celui fond´e sur D(θ) + 2 log f(y|ˆθ(y)).

7.2 Comparaison bay´esienne de mod`eles
383
DIC = E[D(θ)|x] + pD
(7.7)
= E[D(θ)|x] + {E[D(θ)|x] −D(E[θ|x])} ,
associ´ee `a une pseudo-dimension pD. L’´evaluation de mod`eles selon ce crit`ere
suit alors le principe que plus le crit`ere DIC est faible, meilleur est le mod`ele.
Le facteur E[D(θ)|x] dans (7.7) peut ˆetre vu comme une mesure d’ajus-
tement aux donn´ees, alors que pD est un terme ´evaluant la complexit´e, ap-
pel´e nombre eﬀectif de param`etres. L’analogie avec le crit`ere d’information
d’Akaike (7.5) d´ecoule naturellement de DIC = D(E[θ|x]) + 2pD. (Spiegelhal-
ter et al., 2002) montrent que, dans un contexte non hi´erarchique o`u la dis-
tribution a posteriori de θ est approximativement normale, DIC et AIC sont
en fait ´equivalents. Remarquons ´egalement que DIC suit la d´ecomposition
classique de l’erreur quadratique en carr´e du biais et variance,
Eθ[(δ −θ)2] = (Eθ[δ] −θ)2 + Eθ[(δ −Eθ[δ])2] ,
mais dans un cadre non param´etrique (`a l’exception de E[θ|x], qui d´epend de
la param´etrisation).
Exemple 7.8. (Spiegelhalter et al., 1998)
Pour une analyse de variance
simple (i = 1, . . . , p)
yi = θi + σiϵi ,
ϵi ∼N (0, 1) ,
la divergence s’´ecrit D(θ) = 
i σ−1
i
(θi −yi)2. Par cons´equent, si θi = θ
(i = 1, . . . , p) et π(θ) = 1,
E[D(θ)|y1, . . . , yp] =
k

i=1
σ−1
i
(yi −E[θ|y1, . . . , yp])2 + 1
(7.8)
avec E[θ|y1, . . . , yp] = 
i σ−1
i
yi/ 
i σ−1
i
. Dans ce cas, on a pD = 1.
En revanche, si on consid`ere le mod`ele θi ∼N (μ, τ2) en supposant les
hyperparam`etres μ et τ connus, il vient
E[D(θ)|y1, . . . , yp] =
k

i=1
σ−1
i
(1 −ϱi)2(yi −μ)2 +
k

i=1
ϱi ,
(7.9)
avec ϱi = σ2
i τ 2/(σ2
i + τ 2).
∥
Le calcul pratique de la d´eviance bay´esienne n´ecessite le plus souvent le
recours `a des algorithmes MCMC, les cas comme celui de l’Exemple 7.8 ou
ceux pr´esent´es dans Spiegelhalter et al. (2002) ´etant particuli`erement rares.
L’impl´ementation de ces algorithmes est toutefois relativement ais´ee, une fois
programm´ee la simulation d’un ´echantillon MCMC (θ(1), . . . , θ(T )), puisque
E[D(θ)|y1, . . . , yp] est une simple esp´erance a posteriori d’une fonction expli-
cite de θ.

384
7 Choix et comparaison de mod`eles
Exemple 7.9. (Spiegelhalter et al., 1998) Une ´etude sur le cancer de la l`evre
dans cinquante-six r´egions d’´Ecosse met en relation le nombre de cas recens´es
yi et les nombres attendus au niveau national Ei de la fa¸con suivante :
yi ∼P(λiEi) ,
λi = exp(θi) ´etant le risque de cancer des l`evres sp´eciﬁque `a la zone. Des
covariables possibles sont xi, le pourcentage de la population travaillant en
ext´erieur, et la localisation g´eographique de la r´egion, repr´esent´ee par une liste
Ai de r´egions adjacentes. On peut envisager les mod`eles suivants :
M1 : θi = α + βxi ,
M2 : θi = ϕi ,
M3 : θi = ϕi + βxi ,
les ϕi ´etant spatialement corr´el´es, c’est-`a-dire
ϕi|ϕj, j̸=i ∼N
⎛
⎝
j∈Ai
ϕj/ni, τ2/ni
⎞
⎠,
avec ni nombre de r´egions adjacentes. (Ce mod`ele spatial, appel´e mod`ele spa-
tial autor´egressif, est souvent utilis´e en Statistique spatiale. Voir Besag, 1974,
ou Cressie, 1993, et l’Exercice 7.18.)
Avec des lois a priori non informatives pour les hyperparam`etres (sauf
pour τ2 qui suit une loi I G (1, 1)), l’algorithme MCMC donne des valeurs
approch´ees de DIC de 242.8, 88.5 et 89.0 pour les trois mod`eles, avec des
nombres de param`etres pD correspondants de 2.1, 31.6 et 29.4, respectivement.
Les mod`eles M2 et M3 ont donc des performances ´equivalentes, nettement
meilleures que celles du mod`ele M1. Soulignons toutefois que, alors que le
nombre r´eel de param`etres dans le mod`ele M1 est de 2, il est respectivement
de 57 et 58 pour M2 et M3.
∥
Spiegelhalter et al. (2002) sugg`erent d’autres applications de la d´eviance
bay´esienne comme par exemple le calcul des r´esidus de d´eviance. Ils mettent
´egalement en garde contre l’absence d’invariance par reparam´etrisation de
D(E[θ|x]) et conseillent d’utiliser la param´etrisation canonique pour les mo-
d`eles lin´eaires g´en´eralis´es62.
7.3 Aspects num´eriques
Comme dans d’autres contextes, l’approche bay´esienne du choix de mod`ele
se heurte souvent `a la diﬃcult´e num´erique d’´evaluer des int´egrales du type
62Une solution est de remplacer E[θ|x] par son estimateur MAP. On obtient alors
un crit`ere avec une vraie invariance dans la param´etrisation, avec la contrepartie
que cet estimateur est plus diﬃcile `a ´evaluer que la moyenne a posteriori.

7.3 Aspects num´eriques
385
mi(x) =

fi(x|θi)πi(θi)dθi
(7.10)
et, corr´elativement, des rapports d’int´egrales

f1(x|θ1)π1(θ1)dθ1
'
f2(x|θ2)π2(θ2)dθ2 ,
sans compter toutes les complications suppl´ementaires li´ees `a la d´erivation des
facteurs de Bayes intrins`eques et fractionnels. On peut bien sˆur faire appel aux
techniques pr´esent´ees dans le Chapitre 6, qui sont principalement des approxi-
mations asymptotiques et des m´ethodes de simulation de Monte Carlo ou par
MCMC. D’autres id´ees, plus sp´eciﬁques, ont cependant ´et´e d´evelopp´ees pour
le calcul des facteurs de Bayes et de quantit´es associ´ees, comme le d´etaillent
Chen et al. (2000).
7.3.1 ´Echantillonnage d’importance pour facteurs de Bayes
Cette technique, introduite dans la Section 6.2.2, convient particuli`erement
au calcul de distributions pr´edictives comme (7.10). ´Etant donn´e une dis-
tribution d’importance, de densit´e proportionnelle `a g, et un ´echantillon
θ(1), . . . , θ(T ), on obtient une approximation de la densit´e marginale du mod`ele
Mi, mi(x), en ´ecrivant :
mIS
i (x) =
T

t=1
fi(x|θ(t))πi(θ(t))
g(θ(t))
: T

t=1
πi(θ(t))
g(θ(t)) ,
le d´enominateur prenant la place de la constante de normalisation man-
quante. (On remarque que, si g est une densit´e de probabilit´e, l’esp´erance
de π(θ(t))/g(θ(t)) est ´egale `a 1.)
Une bonne raison, parmi d’autres, d’employer l’´echantillonnage d’impor-
tance dans le cadre du choix de mod`ele est qu’on peut r´eutiliser l’´echantillon
(θ(1), . . . , θ(T )) pour plusieurs mod`eles Mi du moment qu’ils mettent en jeu
les mˆemes (types de) param`etres. (Alors que ce n’est en revanche pas possible
dans les Exemples 7.1 et 7.2 puisque les diﬀ´erents mod`eles correspondent `a des
espaces de dimensions diﬀ´erentes.) On pourra consulter Chen et Shao (1997)
pour un exemple utilisant des facteurs de Bayes.
La variance de mIS(x) peut cependant ˆetre inﬁnie, comme cela a ´et´e
´evoqu´e en Section 6.2.2. Raftery (1996) s’int´eresse au probl`eme du choix de la
fonction d’importance dans ce contexte des lois marginales, pour un mod`ele
donn´e de densit´e d’´echantillonnage f(x|θ) et de distribution a priori π(θ).
L’id´ee la plus imm´ediate est de prendre g(θ) = π(θ). On obtient alors l’esti-
mateur suivant de la densit´e marginale :
mIS(x) = 1
T

t
f(x|θ(t)) .

386
7 Choix et comparaison de mod`eles
Ce choix est malheureusement mauvais lorsque les donn´ees sont informatives,
car la plupart des valeurs simul´ees θ(t) tombent en dehors de la r´egion modale
de la vraisemblance et de la loi a posteriori. (Dans le cas limite o`u π est
impropre, cette option est ´evidemment impossible.) Naturellement, dans la
mesure o`u les queues de la distribution π sont en g´en´eral plus larges que celles
de π(θ|x), les probl`emes li´es `a une variance inﬁnie sont rares avec une telle
fonction d’importance.
Un autre choix possible est g(θ) = f(x|θ)π(θ), c’est-`a-dire de simuler sui-
vant la loi a posteriori sans connaˆıtre la constante de normalisation. L’esti-
mateur associ´e est alors
mIS(x) = 1
' 1
T
T

t=1
1
f(x|θ(t)) ,
(7.11)
qui est, en fait, la moyenne harmonique des vraisemblances. Par cons´equent,
mIS(x) est une approximation de la constante de normalisation de g. Bien
que cette solution soit compatible avec des lois a priori impropres, tant que les
distributions a posteriori sont d´eﬁnies, la variance correspondante est souvent
inﬁnie. Une technique pour r´egler ce probl`eme est appel´ee l’´echantillonnage
d’importance d´efensif. Elle consiste `a choisir un m´elange de g (ou plutˆot de
π(θ|x)) et d’une distribution `a queues lourdes, ϖ(θ) :
(1 −ϱ)π(θ|x) + ϱϖ(θ) ,
ϱ > 0 .
avec ϱ petit. Le rˆole du second terme n’est pas de fournir une approximation
int´eressante de la loi a posteriori mais simplement de stabiliser l’estimateur
pour assurer une variance ﬁnie. (Voir Hesterberg, 1998, et Owen et Zhou, 2000
pour plus de d´etails sur cette m´ethode.) Newton et Raftery (1994) proposent
par exemple ϖ(θ) = π(θ).
Une solution proche de la pr´ec´edente, sugg´er´ee par Gelfand et Dey (1994),
est de g´en´erer un ´echantillon de θ(t) suivant la loi a posteriori et d’utiliser
mIS(x) = 1
' 1
T
T

t=1
h(θ(t))
f(x|θ(t))π(θ(t)) ,
(7.12)
plutˆot que (7.11), o`u h est une densit´e quelconque (Exercice 7.19). L’estima-
teur (7.12) a de plus une variance ﬁnie si

h2(θ)
f(x|θ)π(θ)dθ < ∞.
h ´etant un param`etre (fonctionnel) libre, on peut (en principe) le choisir tel
que cette condition soit satisfaite. Bien ´evidemment, le choix pratique de h
n’est pas si ais´e, surtout en grande dimension.

7.3 Aspects num´eriques
387
7.3.2 ´Echantillonnage par passerelle
Les m´ethodes de Monte Carlo d´edi´ees `a l’estimation de rapports de
constantes de normalisation, ou, de fa¸con ´equivalente, de facteurs de Bayes,
se sont multipli´ees depuis 1995. Les lecteurs int´eress´es pourront trouver une
pr´esentation compl`ete de ces m´ethodes dans le livre de Chen et al. (2000).
Nous nous contentons ici de pr´esenter une solution li´ee `a l’´echantillonnage
d’importance.
L’´echantillonnage par passerelle (traduction libre de bridge sampling) a
´et´e propos´e par Meng et Wong (1996) `a partir de principes d´ej`a utilis´es en
Physique des particules : si deux mod`eles partagent le mˆeme espace des pa-
ram`etres Θ, si π1(θ|x) = c1˜π1(θ|x) et π2(θ|x) = c2˜π2(θ|x), alors l’´egalit´e
c2
c1
= Eπ2[˜π1(θ|x) h(θ)]
Eπ1[˜π2(θ|x) h(θ)]
(7.13)
est vraie pour toute fonction passerelle h(θ) telle que les deux esp´erances
soient ﬁnies (Exercice 7.21). L’estimateur par ´echantillonnage de passerelle
est alors
BS
12 =
1
n1
n1

i=1
˜π2(θ1i|x) h(θ1i)
1
n2
n2

i=1
˜π1(θ2i|x) h(θ2i)
,
(7.14)
o`u les θji sont simul´es selon les lois πj(θ|x) (j = 1, 2, i = 1, . . . , nj).
Par exemple, si
h(θ) = 1/ [˜π1(θ|x)˜π2(θ1i|x)] ,
BS
12 est un rapport de moyennes harmoniques, g´en´eralisant (7.11). Meng et
Wong (1996) calculent une fonction passerelle (asymptotiquement) optimale
h∗(θ) =
n1 + n2
n1π1(θ|x) + n2π2(θ|x) .
Cette expression n’est pas directement exploitable, puisque les constantes de
normalisation de π1(θ|x) et π2(θ|x) sont inconnues. (Il s’agit pr´ecis´ement de
la raison pour laquelle nous avons recours `a ces techniques !) N´eanmoins, elle
montre qu’une bonne fonction passerelle doit couvrir les supports des deux
distributions a posteriori, dans les mˆemes proportions si n1 = n2.
Exemple 7.10. Dans le cas des mod`eles lin´eaires g´en´eralis´es, c’est-`a-dire des
mod`eles explicatifs (ou conditionnels) li´es aux familles exponentielles,
f(y|θ) = h(y) eθ·y−ψ(θ) ,
la moyenne E[y|θ] = ∇ψ(θ) ´etant une fonction des covariables, x, de la forme
∇ψ(θ) = Ψ(xtβ), le choix de la fonction de lien Ψ n’est jamais ´evident.
Lorsque la variable expliqu´ee y est `a valeurs dans {0, 1} et

388
7 Choix et comparaison de mod`eles
E[y|x] = P(y = 1|x) ,
les choix suivants de Ψ sont par exemple courants (McCullagh et Nelder, 1989)
– la fonction de lien logit, Ψ(t) = exp(t)/(1 + exp(t)) ;
– la fonction de lien probit, Ψ(t) = Φ(t), fonction de r´epartition de la
distribution N (0, 1) ; et
– la fonction de lien log-log, Ψ(t) = 1 −exp(−exp(t)).
Bien que diverses justiﬁcations soient avanc´ees pour chacune des fonctions
(Gouri´eroux et Monfort, 1996), elles sont insuﬃsantes pour ´eliminer les deux
autres possibilit´es. Les trois mod`eles en comp´etition sont alors
M1 : y|x ∼
eyxtβ1
1 + eyxtβ1
M2 : y|x ∼Φ(xtβ2)y [1 −Φ(xtβ2)]1−y
M3 : y|x ∼exp{−(1 −y) exp(xtβ3)} [1 −exp{−exp(xtβ3)}]y .
Si la loi a priori π sur les βi est normale, β ∼Np(ξ, τ2Ip), et si la fonction
passerelle est h(β) = 1/π(β), l’estimateur d’´echantillonnage par passerelle est
alors (1 ≤i < j ≤3)
BS
ij = 1
n
n

t=1
Lj(βit|x)
:
1
n
n

t=1
Li(βjt|x) ,
o`u les βit sont simul´es63 selon πi(βi|x) ∝Li(βi|x)π(βi).
∥
Dans un cas particulier o`u les deux lois a priori sont ´egales, `a un hyperpa-
ram`etre pr`es, Gelman et Meng (1998) d´ecrivent une meilleure m´ethode que
l’´echantillonnage par passerelle, appel´ee ´echantillonnage par chemin (traduc-
tion de path sampling) et pr´esent´ee dans la Note 7.8.1.
7.3.3 M´ethodes MCMC
Bien que l’´echantillonnage d’importance semble particuli`erement indiqu´e
dans ce contexte, on peut ´egalement faire appel `a des m´ethodes MCMC pour
simuler des ´echantillons de distributions complexes. Par exemple, l’estimation
par ´echantillonnage par passerelle peut s’appuyer sur des ´echantillons MCMC
plutˆot que sur des ´echantillons i.i.d. si les lois πj(θ|x) sont trop compliqu´ees,
comme dans l’Exemple 7.10.
63Le d´etail de la simulation par algorithme MCMC de ces lois a priori est abord´e
dans Robert et Casella (1999, Note 9.7.3) et Gelman et al. (2003) par exemple. Une
solution repose sur l’utilisation de l’algorithme de Metropolis-Hastings `a marche
al´eatoire (voir Section 6.3.2).

7.3 Aspects num´eriques
389
Exemple 7.11. (Suite de l’Exemple 7.10)
Dans les mod`eles Mj (j =
1, 2, 3), la partie de la loi a posteriori li´ee `a la vraisemblance est
n

i=1
Ψ(xt
iβj)yi[1 −Ψ(xt
iβj)]1−yi .
Dans le cas de la fonction de lien probit (j = 2), on a Ψ(t) = Φ(t), fonction
de r´epartition de la loi normale N (0, 1). Une solution naturelle fond´ee sur
l’´echantillonnage de Gibbs est alors de cr´eer des variables auxiliaires zi ∼
N (0, 1) telles que Ψ(xt
iβ2) = E
4
Izi≤xt
iβ2
5
, ce qui revient `a simuler selon la
distribution jointe
π(β2, z1, . . . , zn) ∝π(β2)
n

i=1
Iyi
zi≤xt
iβ2I1−yi
zi≥xt
iβ2 .
Pour les deux autres fonctions de lien, un ´echantillonneur par tranche standard
(voir Section 6.3.6) convient : pour le mod`ele logit, l’in´egalit´e ui ≤Ψ(xt
iβ1)
permet de d´eduire le r´esultat
xt
iβ1 ≥log(ui/(1 −ui)) ,
et, pour le mod`ele log-log, ui ≤Ψ(xt
iβ3) est ´equivalent `a
xt
iβ3 ≥log(−log(1 −ui)) .
Pour les trois mod`eles, les composantes des βj sont donc simul´ees selon des
distributions normales multidimensionnelles tronqu´ees.
∥
Par cons´equent, l’approximation (7.12) de la distribution marginale peut
ˆetre calcul´ee sur un ´echantillon MCMC (θ(t)) de π(θ|x).
Exemple 7.12. (Suite de l’Exemple 7.4) Si les distributions a priori des
quatre mod`eles sont de la forme (j = 1, . . . , 4)
πj(β·j, σ2
j , τ2
j ) ∝σ2
j τ 2
j e−2(σ−2
j
+τ −2
j
) ,
en notant β·j le vecteur contenant les βij pour le mod`ele Mj, Gelman (1996)
sugg`ere d’´evaluer les quatre mod`eles en simulant un ´echantillon de θ(t)
j
selon
les lois a posteriori correspondantes, en adoptant les approximations suivantes
pour les distributions pr´edictives
ˆfj(y|y1, . . . , yn) = 1
T
T

t=1
fj(y|θ(t)
j ) ,
puis de v´eriﬁer si des ´echantillons tir´es selon ces lois pr´edictives correspondent
`a l’´echantillon y1, . . . , yn. Les r´esultats de cette exp´erience sont rapport´es dans

390
7 Choix et comparaison de mod`eles
le Tableau 7.2 : on remarque que les mod`eles M3 et M4 s’accordent de fa¸con
satisfaisante avec les intervalles pr´edictifs, contrairement aux mod`eles M1 et
M2. Il est ´evident qu’il ne s’agit l`a que d’un premier indicateur d’ajuste-
ment et qu’il faudrait ensuite calculer les facteurs de Bayes exacts, mais cette
´evaluation empirique peut ˆetre suﬃsante pour ´eliminer les mod`eles les moins
adapt´es.
∥
Tab. 7.2. Ad´equation des quatre mod`eles de pr´ediction de croissance d’orangers,
en pourcentage des observations `a l’int´erieur des intervalles pr´edictifs `a 50% et 90%.
(Source : Gelfand, 1996.)
Mod`ele 50% 95%
M1
89
100
M2
29
51
M3
46
100
M4
60
86
Chib (1995) propose d’utiliser l’´echantillonneur de Gibbs pour l’approxi-
mation de densit´es marginales, en adoptant la repr´esentation bay´esienne sui-
vante. Quelle que soit θ, valeur ﬁxe du param`etre, la formule de Bayes implique
que
log m(x) = log f(x|θ) + log π(θ) −log π(θ|x) .
Lorsque θ = (θ1, θ2) et lorsque π(θ1|θ2, x) et π(θ2|θ1, x) sont tous les deux cal-
culables analytiquement, constantes de normalisation comprises, l’argument
de Rao-Blackwellisation de la Section 6.3.4 fournit une approximation des lois
marginales a posteriori π(θ1|x)
ˆπ(θ1|x) = 1
T
T

t=1
π(θ1|θ(t)
2 , x) ,
les θ(t)
2
´etant simul´es par un ´echantillonneur de Gibbs. (Notons que le choix de
partitionner θ en (θ1, θ2) est guid´e par la possibilit´e de calculer explicitement
π(θ1|θ2, x) et π(θ2|θ1, x).) Chib (1995) ´etablit alors l’approximation suivante
de log m(x) :
log f(x|θ) + log π(ˆθ) −log π(ˆθ2|ˆθ1, x) −log ˆπ(ˆθ1|x) ,
avec ˆθ = (ˆθ1, ˆθ2) une approximation de l’estimateur MAP de θ, par exemple. Si
les densit´es conditionnelles ne sont pas toutes les deux calculables analytique-
ment ou bien si on ne dispose pas d’une des constantes de normalisation, Chib
(1995) propose d’introduire plus de partitions, mais le calcul en est d’autant
plus compliqu´e (Exercice 7.24).

7.3 Aspects num´eriques
391
L’avantage le plus notable des techniques MCMC pour le choix de mod`ele
est leur capacit´e `a prendre en compte les mod`eles `a dimensions variables,
c’est-`a-dire les mod`eles Mk reposant sur diﬀ´erents ensembles de param`etres,
sans intersection entre eux et ´eventuellement de dimensions diﬀ´erentes.
Exemple 7.13. (Suite de l’Exemple 7.2)
La dimension de l’espace des
param`etres pour un m´elange normal `a k composantes est 3k −1, en prenant
en compte la contrainte
k

ℓ=1
pkℓ= 1 .
Si la loi a priori sur k est une distribution de Poisson P(λ), l’espace des
param`etres est de dimension inﬁnie, puisque k n’est pas born´e.
∥
Si, pour le choix de mod`ele, la diﬃcult´e essentielle r´eside dans le calcul
de la probabilit´e a posteriori correspondant au mod`ele Mk, π(μ = k|x), cette
repr´esentation pose ´egalement des probl`emes plus fondamentaux, le premier
´etant la notion mˆeme de param`etres du mod`ele, qui peut ˆetre d´ecrite soit
comme une suite (θ1, . . . , θk, . . .), soit comme un couple (k, θk). Un autre point
d´elicat concerne la diﬃcult´e en th´eorie de la mesure `a repr´esenter une densit´e
a priori sur une somme directe d’espaces. La construction des ´echantillonneurs
MCMC correspondants n’en est que plus compliqu´ee.
Une premi`ere solution, propos´ee par Carlin et Chib (1995), consiste `a
saturer le mod`ele, c’est-`a-dire `a consid´erer tous les mod`eles `a la fois : pour un
ensemble ﬁni de mod`eles Mk (k = 1, · · · , K) avec des lois a priori associ´ees
πk(θk) et des poids a priori ϱk, l’espace des param`etres est
Θ = {1, . . . , K} ×
K

k=1
Θk
et, si μ repr´esente l’indicateur de mod`ele, la distribution a posteriori s’´ecrit
π(μ, θ1, . . . , θK|x) ∝ϱμfμ(x|θμ)
K

k=1
πk(θk) .
Puisque
m(x|μ = j) =

fj(x|θj)π(θ1, . . . , θK|μ = j) dθ =

fj(x|θj)πj(θj) dθj
ne d´epend pas des πk(θk) pour k ̸= j, Carlin et Chib (1995) proposent d’uti-
liser des pseudo-lois a priori ˜πk(θk|μ = j) pour simuler les param`etres θk
lorsque k ̸= j. Ils impl´ementent cette m´ethode `a l’aide d’un ´echantillonneur
de Gibbs sur (μ, (θ1, . . . , θK)), en simulant μ selon

392
7 Choix et comparaison de mod`eles
P(μ = j|x, θ1, . . . , θK) ∝ϱjfj(x|θj)πj(θ)

k̸=j
˜πk(θk|μ = j) .
Les auteurs remarquent que, assez naturellement, cette m´ethode donne de
meilleurs r´esultats lorsque les pseudo-lois a priori sont proches des vraies dis-
tributions a posteriori, mais il existe toujours un risque de n´egliger des r´egions
importantes des espaces des param`etres Θk dans la calibration des pseudo-
lois a priori. L’inconv´enient essentiel de la m´ethode de Carlin et Chib (1995)
est que r´ealiser une simulation pour chacun des mod`eles `a chaque ´etape de
l’algorithme est coˆuteux en termes de temps de calcul lorsque K est grand.
De plus, lorsque K est inﬁni, cette technique ne peut pas ˆetre utilis´ee.
Exemple 7.14. (Carlin et Chib, 1995) On consid`ere un jeu de mesures sur
quarante-deux pins. On r´ealise une r´egression sur la variable grain (force du
bois) yi en fonction soit de la densit´e du bois xi, soit d’une densit´e modiﬁ´ee
(adapt´ee `a la r´esine) zi. Les deux mod`eles en concurrence sont
M1 : yi = α + βxi + σεi
et
M2 : yi = γ + δzi + τεi ,
avec (α, β, σ2) et (γ, δ, τ 2) tous deux associ´es aux lois a priori (bay´esiennes
empiriques) conjugu´ees :
α
β

,
γ
δ

∼N
3000
185

,
106
0
0 104

,
σ2, τ2 ∼I G (a, b) ,
(a, b) ´etant choisis tels que la moyenne et l’´ecart type de σ2 et τ 2 soient 3002.
(Dans une analyse bay´esienne r´eelle, il faudrait ´evaluer les cons´equences de
cette mod´elisation a priori par une analyse de robustesse comme le d´ecrit la
Section 3.6.)
Dans ce cas, les pseudo-distributions a priori sont ﬁx´ees `a partir des lois a
priori sur σ2 et τ2 et de vagues lois a priori conjugu´ees sur (α, β) et (γ, δ) :
α|μ = 2 ∼N (3000, 522) ,
β|μ = 2 ∼N (185, 122) ,
γ|μ = 1 ∼N (3000, 432) ,
δ|μ = 1 ∼N (185, 92) .
Aﬁn de forcer la prise en compte du mod`ele M1, les auteurs utilisent des
poids d´es´equilibr´es, ϱ1 = .9995 et ϱ2 = .0005. (Cette pratique semble ˆetre
assez courante dans l’approche `a base de pseudo-lois a priori et est une fa¸con
de compenser un ´eventuel mauvais choix de pseudo-lois a priori.)
Ils obtiennent une approximation de 4 420 pour B21 (apr`es correction des
poids), avec un intervalle de conﬁance simul´e de (4 353, 4 487). (L’intervalle
de conﬁance est simplement d´eduit de la variance binomiale sur la probabilit´e
a posteriori P(μ = 1|x).) Le mod`ele M2 peut donc ˆetre privil´egi´e sans grand
risque.
∥

7.3 Aspects num´eriques
393
Exemple 7.15. (Suite de l’Exemple 7.2)
Dans le cas des mod`eles de
m´elanges de galaxies, en se posant seulement le probl`eme de choisir entre
toirs (mod`ele M1) et quatre (mod`ele M2) composantes, Carlin et Chib (1995)
appliquent un mod`ele de donn´ees compl´et´ees comme dans la Section 6.4,
en consid´erant des aﬀectations zk
i (i = 1, · · · , n, k = 1, 2). Comme dans
l’Exemple 7.14, on utilise les r´esultats de tests pr´eliminaires sur les deux dis-
tributions pour ﬁxer les valeurs des pseudo-lois a priori. Celles qui portent
sur les param`etres sont les distributions conjugu´ees correspondant aux esti-
mateurs a posteriori de chaque mod`ele, alors que les pseudo-lois a priori des
zμ
i , pour μ ̸= k, sont calcul´ees `a partir des fr´equences observ´ees. Les au-
teurs ´evaluent le facteur de Bayes `a 0.5153, avec un ´ecart type de 0.0146,
ce qui plaide (mod´er´ement) pour le mod`ele `a trois composantes. (Mais ils
indiquent aussi que ce r´esultat peut ˆetre modiﬁ´e jusqu’`a prendre la d´ecision
inverse, contre le mod`ele `a trois classes, en choisissant simplement d’autres
lois a priori sur les poids.)
∥
7.3.4 MCMC `a sauts r´eversibles
Pour les mod`eles `a dimensions variables, Green (1995) propose un autre
type de technique de saturation, plus localis´ee que celle de Carlin et Chib
(1995). ´Etant donn´e deux mod`eles M1 et M2 de dimensions ´eventuellement
distinctes, l’id´ee de base est d’´eliminer la diﬀ´erence entre les dimensions en
compl´etant les param`etres respectifs θ1 et θ2 avec des variables auxiliaires
u1→2 et u2→1 telles que
(θ1, u1→2) et (θ2, u2→1)
soient en bijection :
(θ2, u2→1) = Ψ1→2(θ1, u1→2) .
(7.15)
Si θ1 est distribu´e selon une loi π1(θ1) et u1→2 selon g1→2(u), la distribution
de (7.15) s’´ecrit
π1(θ1)g1→2(u1→2)

∂Ψ1→2(θ1, u1→2)
∂(θ1, u1→2)

−1
d’apr`es la formule du jacobien. Si nous souhaitons `a pr´esent v´eriﬁer si (7.15)
est distribu´e selon une loi π2(θ2)g2→1(u2→1), la probabilit´e d’acceptation de
Metropolis-Hastings est
min
π2(θ2)g2→1(u2→1)
π1(θ1)g1→2(u1→2)

∂Ψ1→2(θ1, u1→2)
∂(θ1, u1→2)
 , 1

.
`A l’inverse de l’approche adopt´ee par Carlin et Chib (1995), cette tech-
nique ne consid`ere que des modiﬁcations locales d’un mod`ele `a un autre :

394
7 Choix et comparaison de mod`eles
un d´eplacement de Mi vers Mj n’utilise explicitement que les θj et variables
auxiliaires ui→j associ´es.
La th´eorie sous-tendant les m´ethodes de MCMC `a sauts r´eversibles ne
se r´esume naturellement pas `a la pr´esentation succincte ci-dessus, ne serait-ce
que parce qu’elle est plus exigeante `a l’´egard de la densit´e jointe sur (θ2, u2→1)
et (θ1, u1→2), qui doit satisfaire une condition d’´equilibre ponctuel comme en
(6.17). Les lecteurs int´eress´es pourront consulter Green (1995) et Richardson
et Green (1997) pour plus de d´etails. Le point essentiel est que, ´etant donn´e la
probabilit´e ϱi→j de choisir le mod`ele Mj `a partir du mod`ele Mi, la probabilit´e
d’acceptation d’un d´eplacement s’´ecrit eﬀectivement
min
ϱjϱj→iπj(θj)gj→i(uj→i)
ϱiϱi→jπi(θi)gi→j(ui→j)

∂Ψi→j(θi, ui→j)
∂(θi, ui→j)
 , 1

,
(7.16)
avec (θj, uj→i) = Ψi→j(θi, ui→j), sous r´eserve que le d´eplacement de Mi vers
Mj v´eriﬁe aussi cette relation. L’algorithme peut alors ˆetre compl´et´e par des
´etapes suppl´ementaires li´ees `a un mod`ele particulier Mi ou `a des hyperpa-
ram`etres non d´ependants du mod`ele.
Comme l’indiquent Robert et Casella (2004, Section 6.5.1), l’algorithme `a
sauts r´eversibles oﬀre une libert´e telle qu’il a trouv´e nombre d’applications,
bien au-del`a du cadre du choix de mod`ele. Dans la situation de l’Exemple 7.2,
Richardson et Green (1997) ´elaborent un algorithme `a sauts r´eversibles pour
les composantes normales, qui conclut que le nombre de composantes pour
les donn´ees de vitesses de galaxies devrait ˆetre de quatre. Nous pr´esentons
ci-dessous l’algorithme correspondant pour un m´elange de distributions expo-
nentielles, provenant de Gruet et al. (1999). (Voir aussi Robert et al., 1999b,
pour une g´en´eralisation aux mod`eles de Markov cach´es.)
Exemple 7.16. Pour un m´elange de distributions exponentielles
k

j=1
pjkE xp(λjk) ,
l’algorithme `a sauts r´eversibles peut ˆetre limit´e `a des d´eplacements entre
mod`eles voisins, c’est-`a-dire entre le mod`ele Mk et les mod`eles Mk+1 et Mk−1.
Les mouvements sont assez libres : une composante peut ˆetre ajout´ee (ou re-
tir´ee) al´eatoirement, tant que la sym´etrie entre d´eplacements montants et des-
cendants est pr´eserv´ee. Par exemple, la naissance de la composante k + 1 sera
propos´ee en simulant (p(k+1)(k+1), λ(k+1)(k+1)) selon la loi a priori ϖk+1(p, λ),
en supposant un a priori commun `a toutes les composantes. La transformation
est alors
(p1(k+1), . . . , pk(k+1)) = ((1 −p(k+1)(k+1))p1k, . . . , (1 −p(k+1)(k+1))pkk)
(λ1(k+1), . . . , λ(k+1)(k+1)) = (λ1k, . . . , λkk, λ(k+1)(k+1)) .
Le jacobien de cette transformation est donc (1−p(k+1)(k+1))k et la probabilit´e
d’accepter la naissance est

7.4 Moyenne de mod`eles
395
min

ϱk+1(1 −p(k+1)(k+1))k πk+1(p1(k+1), . . . , p(k+1)(k+1),
ϱkπk(p1k, . . . , pkk, λ1k, . . . , λkk)
λ1(k+1), . . . , λ(k+1)(k+1))
ϖk+1(p(k+1)(k+1), λ(k+1)(k+1)) , 1

,
si les probabilit´es de choisir une naissance (saut vers Mk+1) ou une mort (saut
vers Mk−1) sont ´egales.
Le d´eplacement de Mk vers Mk+1 consid´er´e dans Gruet et al. (1999)
consiste en la s´eparation d’une composante j choisie al´eatoirement de fa¸con `a
ce que les param`etres (pj(k+1), p(j+1)(k+1), λj(k+1), λ(j+1)(k+1)) de la nouvelle
composante satisfassent la condition des moments
pjk = pj(k+1) + p(j+1)(k+1)
(7.17)
pjkλjk = pj(k+1)λj(k+1) + p(j+1)(k+1)λ(j+1)(k+1) .
Le d´eplacement inverse est la fusion de deux composantes j et j + 1 selon
l’´equation (7.17). On peut tout aussi bien repr´esenter la s´eparation en simulant
deux variables u1, u2 ∼U ([0, 1]), puis pj(k+1) = u1pjk et λj(k+1) = u2λjk.
On obtient alors le jacobien
∂Ψk→k+1(pjk, λjk, u1, u2)
∂(pjk, λjk, u1, u2)
= pjk/(1 −u1) .
La Figure 7.2 pr´esente une analyse succincte des performances de l’algorithme
`a sauts r´eversibles sur un jeu de donn´ees portant sur des s´ejours hospitaliers
avec un mode a posteriori pour k de 4. La carte d’allocation en bas `a droite
repr´esente les aﬀectations successives des observations en niveaux de gris : on
voit que les propri´et´es de m´elange de la chaˆıne sont bonnes, puisque aucune
forme particuli`ere n’´emerge. (Voir Gruet et al., 1999, pour plus de d´etails.) ∥
Notons l’absence de variable auxiliaire uk→(k−1) pour les mouvements des-
cendants dans les deux situations d´ecrites dans l’Exemple 7.16. Cela se produit
souvent lorsqu’un mod`ele inclut l’autre, mais l’addition de variables auxiliaires
est parfois tout de mˆeme conseill´ee dans un souci de gain en temps de calcul.
Des techniques analogues sont d´ecrites dans Ripley (1987), Grenander et
Miller (1994), Phillips et Smith (1996) et Stephens (2000), mettant en jeu les
naissances et morts de processus `a temps continu. (Voir la Note 7.8.2.)
7.4 Moyenne de mod`eles
Un geste bay´esien assez naturel devant l’incertitude sur le choix de mod`ele
est d’inclure tous les mod`eles Mk envisag´es dans la prise de d´ecision, faisant
ainsi l’´economie de l’´etape de choix de mod`ele. L’id´ee sous-jacente est qu’on

396
7 Choix et comparaison de mod`eles
affectations
Fig. 7.2.
Suite de valeurs k(t) simul´ees par sauts r´eversibles, avec l’histogramme
correspondant en haut, `a droite ; la convergence de la moyenne empirique en bas, `a
gauche ; et la s´equence d’aﬀectations aux composantes en bas, `a droite pour 50 000
it´erations. (Source : Gruet et al., 1999.)
sous-estime g´en´eralement l’incertitude pr´esente `a l’´etape du choix de mod`ele
en choisissant un mod`ele, disons Mk0, et en oubliant totalement le caract`ere
al´eatoire de ce choix dans les ´etapes ult´erieures. La solution de la moyen-
nisation de tous les mod`eles, propos´ee par Raftery et al. (1996), permet de
rem´edier `a ce probl`eme.
Ce principe n’est ´evidemment pas applicable dans tous les contextes : le but
de la personne qui prend les d´ecisions, ou du statisticien, est justement parfois
de choisir un mod`ele, comme c’est le cas en inf´erence scientiﬁque, ou d’´eliminer
les covariables superﬂues d’un mod`ele `a cause de coˆuts d’´echantillonnage pro-
hibitifs (Section 7.5), dans le domaine de la s´election de variables. De plus, la
moyenne de mod`eles va `a l’encontre des eﬀorts de parcimonie (Note 6.6.6) dans
la mesure o`u l’imbrication de tous les mod`eles dans un seul (super) mod`ele
fait augmenter d’autant le nombre de param`etres et n´ecessite la simulation et
le stockage d’un grande quantit´e d’´echantillons MCMC, puisqu’on fait appel
`a des algorithmes num´eriques dans la plupart des cas. C’est en particulier vrai
dans l’Exemple 7.2.
Le principe de cette approche est le suivant : pour un ´echantillon x =
(x1, . . . , xn), la distribution pr´edictive est obtenue par une moyenne sur tous
les mod`eles possibles,

7.4 Moyenne de mod`eles
397
f(y|x) =

Θ
f(y|θ)π(θ|x)dθ
=

k

Θk
fk(y|θk)π(k, θk|x)dθk
=

k
p(Mk|x)

fk(y|θk)πk(θk|x) dθk ,
en notant Θ l’espace des param`etres global, tel que d´eﬁni en (7.2).
Cette id´ee ne permet malheureusement pas d’´echapper `a la plupart des
probl`emes d´ej`a d´ecrits en Section 7.2, comme les nombreux calculs d’int´egrales
et les simulations sur un espace des param`etres, Θ, qui est une somme d’es-
paces de diﬀ´erentes dimensions. N´eanmoins, le contournement de l’´etape de
d´ecision sur le label μ du mod`ele permet d’all´eger certaines diﬃcult´es. Par
exemple, le fait que la collection de mod`eles soit ´eventuellement inﬁnie (ou
simplement trop grande, comme dans la s´election de variables) n’est pas
r´edhibitoire dans la mesure o`u un algorithme MCMC explorant Θ pourra
ignorer les mod`eles aux probabilit´es P(Mi|x) tr`es faibles.
Le probl`eme ici rel`eve davantage de la mod´elisation, comme nous l’avons
vu en Section 7.2.1 : lorsqu’on doit consid´erer un grand nombre de mod`eles, le
choix des probabilit´es a priori π(k) est fondamental, mais diﬃcile `a formaliser
et `a justiﬁer. Par exemple, dans le cadre de la s´election de variables (Section
7.5), les mod`eles en concurrence peuvent ˆetre repr´esent´es par des vecteurs
d’indicatrices
Mk : (δk1, · · · , δkd) ,
δkj ∈{0, 1} ,
avec d nombre de covariables potentielles. Madigan et Raftery (1991) pro-
posent d’utiliser
π(k) ∝
d

j=1
%
ϱδkj
j
(1 −ϱj)1−δkj
&
,
avec ϱj probabilit´e a priori que la variable j ait un eﬀet. Une limitation
pr´evisible de cette distribution est que les covariables sont incluses dans le
mod`ele ind´ependamment les unes des autres. Cette strat´egie n’est justiﬁ´ee
que si elles sont ind´ependantes, ce qui est une hypoth`ese hasardeuse dans
la plupart des cas. Une autre id´ee imm´ediate consistant `a mettre des poids
´egaux `a tous les mod`eles n’est pas moins critiquable : outre le fait que ce soit
impossible lorsque le nombre de mod`eles est inﬁni, cette strat´egie semble par-
ticuli`erement peu pertinente pour des mod`eles imbriqu´es, c’est-`a-dire lorsque
certains mod`eles sont des cas particuliers d’autres, comme c’est le cas en
s´election de variables.
Un avantage des techniques MCMC telles que les sauts r´eversibles ou les
processus de saut (Note 7.8.2), d´ej`a d´ecrit ci-dessus, est leur capacit´e `a ex-
plorer un grand nombre de mod`eles en ´evitant ceux auxquels sont aﬀect´ees
des probabilit´es faibles (en admettant que les algorithmes correspondants

398
7 Choix et comparaison de mod`eles
convergent correctement). Madigan et Raftery (1991) proposent une autre
solution appel´ee fenˆetre d’Occam64. Ils sugg`erent de ne consid´erer que les
mod`eles tels que
maxk P(Mk|x)
P(Mℓ|x)
≤C
c’est-`a-dire seulement les mod`eles dont la probabilit´e n’est pas trop ´eloign´ee
du mod`ele le plus probable. Ils conseillent en outre d’exclure les mod`eles Mℓ,
tels qu’il existe un sous-mod`ele Mh ⊂Mℓv´eriﬁant
P(Mh|x)
P(Mℓ|x) ≥1 .
Mais une telle r´eduction dans le nombre de mod`eles n’est impl´ementable que si
ce nombre est au d´epart relativement modeste et Clyde (1999) met en garde
contre l’apparition possible de biais dans les probabilit´es r´esultant de cette
simpliﬁcation.
Exemple 7.17. Dans le cadre de la s´election de variables en r´egression nor-
male, y ∼N (Xβ, σ2I), c’est-`a-dire lorsque
yt =
J

j=1
βjxjt + σεt
t = 1, · · · , T ,
avec des r´egresseurs orthogonaux
XtX = diag(x′
jxj) ,
Clyde (1999) propose des distributions a priori de la forme
βj ∼N (0, c2
jγj) ,
γj ∼B(pj) ,
les γj jouant le rˆole d’indicateurs 0-1 pour la pr´esence du j-i`eme r´egresseur
dans le mod`ele. Alors, sous l’a priori de Madigan et Raftery (1991),
64William d’Occam ou d’Ockham (circa 1285–circa 1349), th´eologien anglais (et
moine franciscain) d’Oxford, a travaill´e sur les bases de l’induction empirique et,
en particulier, pos´e le principe appel´e plus tard “rasoir” d’Occam (Occam’s razor),
qui ´ecarte l’admission de causes multiples pour un ph´enom`ene si elles ne sont pas
justiﬁ´ees exp´erimentalement (voir Adams, 1987). Ce principe, Pluralitas non est
ponenda sine necessitate (traduit g´en´eralement par les entit´es ne devraient pas ˆetre
multipli´ees sans n´ecessit´e) est souvent invoqu´e en tant que principe de parcimonie
pour privil´egier l’explication la plus simple lorsque deux explications sont ´egalement
possibles. On le retrouve tr`es fr´equemment dans la litt´erature bay´esienne (voir, par
exemple, Jeﬀreys, 1961, Section 6.12, ou Jeﬀerys et Berger, 1992). Nous sommes
n´eanmoins r´eticents sur l’emploi de cette notion, car elle ne fournit pas un principe
de travail et peut donc ˆetre utilis´ee `a tort. Il est clair que le seul argument du
rasoir d’Occam n’est pas suﬃsant pour justiﬁer pleinement une m´ethode donn´ee.
(Pour l’anecdote, le personnage de William de Baskerville dans Le Nom de la Rose
d’Umberto Eco est inspir´e d’Occam.)

7.5 Projections de mod`eles
399
π(γ1, . . . , γJ|y, σ) =
J

j=1
ϱγj
j (1 −ϱj)γj ,
(7.18)
avec
ϱj =
Oj(y, σ)
1 + Oj(y, σ)
et
Oj(y, σ) =
pj
1 −pj

x′
jxj + σ2/c2
j
σ2/c2
j
 −1/2
× exp

(ˆβjx′
j/σ2)2
2(x′
jxj/σ2 + 1/c2
j)

,
ce qui signiﬁe que les γj sont ind´ependants a posteriori et que la probabilit´e
d’un sous-mod`ele donn´e peut ˆetre d´eduite ais´ement ainsi que le sous-mod`ele
le plus probable (Exercice 7.26). Ce n’est pas le cas avec la mod´elisation
alternative de George et McCulloch (1997) :
βj ∼N
	
0, c2
jγj + [c2
j/100](1 −γj)

.
Si σ2 est inconnu, Clyde (1999) utilise le mˆeme a priori simple σ2 ∼
I G(α, β) pour tous les mod`eles
π(σ2|γ, y) ∼I G(ˆα, ˆβ)
et ´evalue les poids a posteriori des diﬀ´erents mod`eles soit avec un estimateur
intuitif, c’est-`a-dire rempla¸cant σ2 par un estim´e ˆσ2 dans l’´egalit´e (7.18), soit
avec une moyenne de Rao-Blackwell.
∥
Bien que de tels r´esultats soient int´eressants, ils sont diﬃciles `a transposer
`a d’autres cadres, comme les mod`eles lin´eaires g´en´eralis´es, sans l’ajout de
nouvelles approximations. Par ailleurs, l’hypoth`ese d’orthogonalit´e est trop
restrictive, car les r´egresseurs courants ne sont jamais orthogonaux et leur
appliquer une transformation orthogonale comme les composantes principales
empˆeche d’obtenir les valeurs des coeﬃcients βj ce qui est souvent un objectif
de l’´etude. Enﬁn, le principe que les param`etres communs doivent ˆetre trait´es
comme des entit´es distinctes dans des mod`eles diﬀ´erents n’est pas ici respect´e,
puisque les βj sont identiques dans tout mod`ele o`u ils apparaissent.
7.5 Projections de mod`eles
Nous pr´esentons dans cette section une approche diﬀ´erente65 du choix de
mod`ele, d´evelopp´ee par Goutis et Robert (1998), puis appliqu´ee `a la s´election
65Cette section contient des notions moins g´en´erales. Elle n’est pas plus diﬃcile
que le reste de ce chapitre, mais peut ˆetre laiss´ee de cˆot´e en premi`ere lecture.

400
7 Choix et comparaison de mod`eles
de variables par Dupuis et Robert (2001). L’id´ee sous-tendant cette approche
est de projeter un mod`ele complet f(y|θ) sur des sous-mod`eles, obtenus par
des restrictions sur θ, puis de calculer l’erreur d’approximation commise. Cette
approche est en particulier applicable `a la s´election de variables, c’est-`a-dire
`a la recherche d’un sous-ensemble de covariables, au sein d’un ensemble plus
grand (Exemple 7.17).
Exemple 7.18. Dans une ´etude sur l’inﬂuence de facteurs di´et´etiques sur
l’apparition de cancer du sein (CS), Raftery et Richardson (1995) consid`erent
les covariables suivantes :
ˆage
ˆage de la premi`ere grossesse
ˆage `a la m´enopause
ˆage `a la ﬁn des ´etudes
ˆage `a la m´enarche
indice de masse corporelle
nombre d’enfants
consommation de graisses (totale)
consommation d’alcool
consommation de graisses (satur´ees)
ant´ec´edents familiaux de CS
ant´ec´edents de CS b´enins
Les observations sont `a valeurs dans {0, 1}, correspondant `a une dichotomie
pr´esence/absence de cancer. On peut donc leur appliquer une mod´elisation
logistique impliquant toutes ou partie des covariables (i = 1, · · · , 212) :
Mi : P(yj = 1|xj) =
exp[αi + βt
ix(i)
j ]
1 + exp[αi + βt
ix(i)
j ]
,
en notant x(i) les coordonn´ees de x dans la d´ecomposition binaire de i.
Par exemple, le mod`ele M5 correspond `a i = 5 = 0 · · · 0101 et donc
x(5) = (x10, x12).
∥
Une des principales diﬀ´erences entre l’approche par projections et les
axiomes usuels de choix de mod`ele r´eside dans les distributions a priori re-
quises. En eﬀet, on ne demande ici la construction d’un a priori π(θ) que pour
le mod`ele complet et on tol`ere les lois a priori impropres, ce qui n’etait pas le
cas dans la Section 7.2, o`u un a priori propre par sous-mod`ele ´etait n´ecessaire.
En fait, comme nous le verrons ci-dessous, les poids et lois a priori de chaque
sous-mod`ele sont d´eduits de la distribution a priori originale π, ce qui permet
d’´eviter les paradoxes de marginalisation et de projection li´es `a la pr´esence de
sous-espaces de dimensions diﬀ´erentes.
Pour une restriction θ ∈Θ0, Goutis et Robert (1998) proposent le crit`ere
d’acceptabilit´e suivant :
d(f(· |θ), Θ0) < ϵ ,
(7.19)
o`u d est une mesure de divergence et
d(f(· |θ), Θ0) = d(f(· |θ), f(· |θ⊥))
=
inf
θ0∈Θ0 d(f(· |θ) , f(· |θ0)) .

7.5 Projections de mod`eles
401
Le param`etre θ⊥est alors la projection du param`etre θ sur le sous-mod`ele.
Le choix de mod`ele peut ainsi ˆetre vu comme une ´evaluation de la diﬀ´erence
entre le vrai mod`ele et un mod`ele plus parcimonieux. Il s’agit donc d’une
mod´elisation pragmatique tenant compte des r´ealit´es exp´erimentales, dans
lesquelles la nullit´e exacte est rarement v´eriﬁ´ee, et qui r`egle les probl`emes de
param´etrisation par l’absence de param`etres dans la repr´esentation (7.19). Par
ailleurs, cette m´ethode ne n´ecessite que la distribution a priori sur le param`etre
complet θ, puisque le param`etre de projection θ⊥s’obtient `a partir d’une
transformation de θ. La probabilit´e a posteriori dans (7.19) peut donc ˆetre
calcul´ee en utilisant seulement la distribution a priori. Remarquons que cela
n’est pas ´equivalent `a ´etablir la distribution a priori sur θ⊥en projetant π(θ)
et `a utiliser ensuite le facteur de Bayes standard, comme le font McCulloch
et Rossi (1992) (Exercice 7.33).
Il y a de nombreuses possibilit´es pour la mesure de divergence d, mais un
choix assez naturel est la pseudo-distance de Kullback-Leibler
d(f, g) =

log
f(z)
g(z)

f(z) dz ,
d´ej`a vue en (2.7). Bernardo et Smith (1994) pr´esentent de nombreux argu-
ments d´efendant l’utilisation de cette mesure. Ils sont li´es `a la th´eorie de
l’information, aux r`egles de p´enalisation, aux propri´et´es de transitivit´e et
d’additivit´e ou encore aux familles exponentielles et aux mod`eles lin´eaires
g´en´eralis´es.
De mˆeme, le facteur ϵ dans (7.19) peut ˆetre ﬁx´e de bien des fa¸cons
diﬀ´erentes. Par exemple, il peut ˆetre calibr´e sur des distributions simples
pour ´etablir un intervalle raisonnable, comme dans la Table 7.3 (Exercice
7.29). Dans le cas d’une restriction simple, ϵ peut ˆetre d´eduit de la distribu-
tion (propre) a priori π pour v´eriﬁer la condition
P π(d(f(· |θ), f(· |θ⊥)) ≤ϵ) = 1/2 .
Ce travail a ´et´e r´ealis´e dans le cadre des m´elanges par Mengersen et Robert
(1996), mais la valeur 1/2 est critiquable dans la mesure o`u elle donne une
fausse impression d’objectivit´e (alors que le r´esultat d´epend en fait de π). En-
ﬁn, dans le contexte de s´election de variables et de mod`eles imbriqu´es associ´es,
il existe un mod`ele minimal (ou mod`ele plus rudimentaire), f0, obtenu par la
r´egression d’un seul intercept et qui peut donner un ordre de grandeur de ϵ
par ϵ = ϱd(f, f0), avec 0 < ϱ < 1. (Dupuis et Robert, 2001, appellent d(f, f0)
le coˆut maximal en potentiel explicatif.)
D`es lors que d et ϵ sont ﬁx´es, la m´ethode peut ˆetre impl´ement´ee soit
en calculant la probabilit´e a posteriori P π(d(f(· |θ), f(· |θ⊥) ≤ϵ), soit en
´etablissant l’esp´erance a posteriori de d(f(· |θ), f(· |θ⊥)). Dans le cas de la
s´election de variables en r´egression, quand y est conditionnel `a un vecteur
x de p covariables, la tˆache se complique par la n´ecessit´e d’int´egrer sur la
distribution jointe de (x, y) pour obtenir la distance, soit (Exercice 7.31)

402
7 Choix et comparaison de mod`eles
Tab. 7.3. Valeurs des param`etres pour diﬀ´erentes divergences de Kullback-Leibler
de ϵ dans le cas des distributions Bernoulli, Poisson et normales. (Source : Goutis
et Robert, 1998.)
ϵ
0 0.01 0.05 0.1 0.25 0.5
1
2
∞
B(p)
0.5 0.57 0.65 0.71 0.81 0.9 0.96 0.99 1
P(λ)
1 1.15 1.35 1.52 1.88 2.36 3.15 4.5 ∞
N (μ, 1)
0 0.14 0.32 0.45 0.71
1
1.41
2
∞
Ex[d(f(·|x, θ), fA (·|xA , θ⊥))] ,
avec A ⊂{1, . . ., p} et xA le sous-ensemble de covariables correspondant.
Comme la distribution du vecteur de covariables x est souvent inconnue, on
l’estime par la moyenne empirique
1
n
n

i=1
Ey

log

f(y|xi, θ)
g(y|xiA , θ⊥)
 xi

.
Outre les diﬃcult´es num´eriques habituelles pour obtenir des approxima-
tions d’esp´erances ou de probabilit´es a posteriori, nous sommes confront´es
`a un nouveau probl`eme, plus sp´eciﬁque `a la s´election de variables. ´Etant
donn´e p covariables potentielles, il y a 2p (ou 2p −1) mod`eles en concurrence.
Lorsque p est grand, une exploration compl`ete de tous les mod`eles est impos-
sible. Heureusement, comme nous le d´ecrivons dans la Note 7.8.3, certaines
propri´et´es de transitivit´e et d’additivit´e de la distance Kullback-Leibler per-
mettent d’´elaguer plus rapidement l’arbre des sous-mod`eles : lorsqu’on cherche
parmi tous les sous-ensembles A de covariables tels que
d(Mg, MA ) = Ex[d(f(y|x, α), g(y|xA , α⊥))] < ϵ ,
le sous-mod`ele avec le cardinal le plus petit, c’est-`a-dire celui qui a le plus
faible nombre de covariables, on peut ´evaluer ce cardinal par pas descendants–
on part du mod`ele complet et on descend dans l’arbre des sous-mod`eles en
´eliminant une covariable `a la fois, celle qui est le plus loin de Mg, jusqu’`a ce que
la distance devienne trop importante–et par pas montants–on part du mod`ele
constant et on ajoute une covariable `a la fois, le plus proche de Mg, jusqu’`a
ce que la distance soit plus petite que ϵ–et v´eriﬁer a posteriori qu’aucun autre
mod`ele de mˆeme cardinal p0 ne soit plus proche du mod`ele complet. Cette
derni`ere ´etape peut toutefois ˆetre particuli`erement longue, de l’ordre de
	 p
p0

(Exercice 7.30).
Exemple 7.19. (Suite de l’Exemple 7.18)
Pour un a priori constant
sur les param`etres de r´egression (α, β), Dupuis et Robert (2001) obtiennent

7.5 Projections de mod`eles
403
les r´esultats pr´esent´es en Table 7.4 via cette proc´edure de s´election de va-
riables (avec ϱ = 0.9 lors de l’´etalonnage de ϵ). Les trois ´etapes de la
m´ethode choisissent le mˆeme sous-mod`ele 100111111001. D’apr`es la liste des
variables explicatives donn´ees dans l’Exemple 7.18, cela signiﬁe que le sous-
mod`ele s´electionn´e n’inclut pas les graisses consomm´ees dans la liste des va-
riables explicatives les plus importantes. L’accord entre l’approche fond´ee sur
l’esp´erance de la distance a posteriori (colonne 3) et celle fond´ee sur la probabi-
lit´e a posteriori que la distance soit inf´erieure `a ϵ (colonne 4) est remarquable.
∥
Bien que cette approche ait l’avantage de s’appuyer sur une fonction de
coˆut pour s´electionner les sous-mod`eles et d’´eliminer le probl`eme des lois a
priori impropres, elle n’est pas exempte de d´efauts. Le premier d’entre eux
est l’´enorme quantit´e de calcul n´ecessaire lorsque, comme c’est le cas en
s´election de variables, le nombre de sous-mod`eles `a ´etudier est grand. Ensuite,
la fa¸con de d´eterminer la borne ϵ n’est pas irr´eprochable : par exemple, pour-
quoi une proportion ﬁxe de la distance serait-elle pertinente pour la prise de
d´ecision? Comment doit-elle d´ependre du nombre d’observations ? Un autre
inconv´enient de cette m´ethode est qu’elle n´ecessite un mod`ele complet (ou
de r´ef´erence) et ne marche donc que pour des mod`eles imbriqu´es. S’inspi-
rant d’une id´ee commun´ement utilis´ee en ´Econom´etrie (voir, par exemple,
Gouri´eroux et Monfort, 1996), Goutis et Robert (1998) proposent d’´etendre
la m´ethode `a un cadre plus g´en´eral en cr´eant un mod`ele imbriquant, mais le
probl`eme est diﬃcile puisque le mod`ele imbriquant n’est pas le vrai mod`ele et
n’a donc qu’un int´erˆet limit´e pour la prise de d´ecision. En outre, il existe en-
core de nombreuses mani`eres de d´eﬁnir le mod`ele imbriquant, qui conduisent
`a des r´esultats diﬀ´erents. On peut par exemple consid´erer les moyennes
arithm´etique ou g´eom´etrique de mod`eles (Exercice 7.35).
Exemple 7.20. (Suite de l’Exemple 7.1)
´Etant donn´e que les mod`eles
de Poisson P(λ) et binomial n´egatif N B(n, p) contiennent des termes de la
forme
λy
y! ,
avec λ = p/(1−p) dans le cas de la binomiale n´egative, un mod`ele imbriquant
envisageable est
f(y|λ, m, α) ∝1
y!λy e−αλ

m!
(m −y)!
1
(1 + eλ)m
1−α
0 ≤α ≤1 .
On retrouve le mod`ele de Poisson pour α = 1 et la loi binomiale n´egative pour
α = 0. Cette densit´e est en fait la moyenne g´eom´etrique des deux densit´es
mais la constante de normalisation, qui d´epend de (λ, m, α), est inconnue.
On obtient une solution alternative plus abordable en utilisant la moyenne
arithm´etique, ce qui donne le m´elange

404
7 Choix et comparaison de mod`eles
Tab. 7.4. Sous-mod`eles ´etudi´es par la proc´edure de s´election de variables pour le jeu
de donn´ees concernant le cancer du sein. Le r´esultat de chaque ´etape est pr´esent´e en
gras, d(Mg, MA ) repr´esente l’esp´erance de la divergence de Kullback-Leibler entre
le mod`ele complet et sa projection sur le sous-ensemble de covariables A et P(MA )
est la probabilit´e a posteriori que la distance d(Mg, MA ) soit inf´erieure `a ϵ. (Source :
Dupuis et Robert, 2001.)
´etape sous-ensemble
d(Mg, MA ) P(MA )
A
(×740)
1.
101111111111
0.508
0.98
101111111011
1.146
0.96
100111111011
1.800
0.94
100111111001
2.726
0.91
2.
000000010000
21.78
0.29
000010010000
16.97
0.45
100010010000
13.81
0.55
100010011000
10.61
0.66
100010011001
7.601
0.75
100011011001
5.224
0.83
100111011001
3.736
0.88
100111111001
2.726
0.91
3.
111111110000
8.170
0.73
111111001010
13.72
0.55
111100111010
8.349
0.73
110011111010
5.988
0.81
001111111010
9.215
0.70
111110011001
4.542
0.85
111101011001
4.761
0.85
111011011001
3.91
0.87
110111011001
3.265
0.89
101111011001
3.017
0.90
011111011001
5.895
0.81
100111111001
2.726
0.91
100111011101
3.109
0.899
100011111101
3.826
0.88
111011010011
5.284
0.83
110110110011
6.04
0.80
101101110011
5.9
0.81
101011011011
3.576
0.88
100111011011
2.77
0.91
101010111011
5.08
0.84
011001111011
9.346
0.70
100110011111
4.151
0.87
100101011111
4.224
0.86
100011011111
3.787
0.88

7.6 Ad´equation `a une famille de lois
405
p P(λ) + (1 −p) N eg

m,
eλ
1 + eλ

0 ≤p ≤1 .
∥
7.6 Ad´equation `a une famille de lois
Nous refermons ce chapitre par une courte introduction `a l’approche
bay´esienne du concept d’ad´equation (traduction de goodness of ﬁt), qui est,
d’une certaine fa¸con, le probl`eme de choix de mod`ele le plus diﬃcile. En ef-
fet, dans les questions de type Le mod`ele M0 est-il compatible avec x ? ou f
appartient-elle `a la famille {fθ; θ ∈Θ} ?, il n’y a pas d’hypoth`ese alternative
`a M0. Ainsi, dans l’Exemple 7.1, si nous ne consid´erons que le mod`ele de
Poisson, juger de sa compatibilit´e avec les donn´ees est d’autant plus diﬃcile
que, s’il ne l’est pas, il n’y a pas alors de mod`ele d´eﬁni66.
Il semble que la diﬃcult´e vienne ici du fait que le paradigme bay´esien
ne puisse se prononcer sur la validit´e du mod`ele qu’en “sortant” du mod`ele,
c’est-`a-dire en travaillant dans un cadre ´elargi (un m´etamod`ele) dans lequel
le mod`ele consid´er´e n’est qu’un cas particulier. Mais, en r´ealit´e, le probl`eme
tient plus `a la formulation maladroite de la question qu’au paradigme bay´esien
lui-mˆeme. L’incapacit´e de ce dernier `a r´epondre `a un probl`eme aussi mal pos´e
ne signiﬁe en aucune mani`ere que d’autres m´ethodes apportant une r´eponse,
comme le test du χ2, soient plus l´egitimes! En fait, le paradigme bay´esien
clariﬁe le probl`eme en posant comme condition n´ecessaire la construction
pr´eliminaire d’un mod`ele alternatif et formalise la d´eﬁnition de m´etamod`ele
incluant le mod`ele d’´etude.
Une fois l’ambigu¨ıt´e lev´ee, il y a de nombreuses fa¸cons de d´eﬁnir le mod`ele
alternatif M1, `a moins qu’il ne soit contraint par la disponibilit´e d’informa-
tions a priori pr´ecises. Le mod`ele M1 peut par exemple ˆetre un mod`ele imbri-
quant M0. Mais comme nous l’avons vu en Section 7.5, il n’y a pas unicit´e de
choix pour un tel mod`ele. La notion de mod`ele imbriquant le plus petit (ou le
plus naturel) n’existe pas, en dehors de la r´eponse triviale de M0 lui-mˆeme !
Neyman (1937) d´eﬁnit une extension de la famille exponentielle
f1(x|θ, ϕ) ∝f(x|θ) exp

−ϕ log
f(x|θ)
f(x|ˆθ(x))

,
ϕ ≥0 ,
66L’approche fr´equentiste contourne cette diﬃcult´e en ne travaillant que sous
l’hypoth`ese nulle. Par exemple, le test du χ2 standard s’appuie sur l’approximation
du χ2 qui n’est valable que lorsque le mod`ele consid´er´e est le “vrai” mod`ele. Dans
le cas contraire, la statistique du χ2 tend vers l’inﬁni mais on ne sait rien de sa
distribution pour une taille d’´echantillon donn´ee.

406
7 Choix et comparaison de mod`eles
avec ˆθ(x) estimateur du maximum de vraisemblance (en le supposant d´eﬁni),
mais d’autres extensions hi´erarchiques sont envisageables. De plus, la repr´esen-
tation de l’hypoth`ese alternative par les mod`eles imbriquants est tr`es limit´ee,
puisque dans un probl`eme d’ad´equation, elle doit ˆetre “f n’est pas dans M0”.
On peut lever ces restrictions en utilisant une repr´esentation non pa-
ram´etrique de l’hypoth`ese alternative. Des techniques standard de Statistique
bay´esienne non param´etrique sont pr´esent´ees dans la Note 1.8.2, comme par
exemple les lois a priori par processus de Dirichlet et leurs g´en´eralisations,
m´elanges ou ondelettes. Nous ´etudions `a titre d’exemple la repr´esentation po-
lynomiale orthogonale de Verdinelli et Wasserman (1992). Voir Castro et al.
(1999) pour le cas discret (Exercice 7.38).
On peut exprimer le mod`ele consid´er´e M0 : x ∼f(x|θ), θ ∈Θ, de la fa¸con
suivante :
M0 : x = F −(u|θ),
θ ∈Θ,
u ∼U ([0, 1]) ,
avec F −(·|θ) inverse g´en´eralis´e de la fonction de r´epartition de f(·|θ) (Exercice
7.39). On peut donc ´ecrire M0 comme un cas particulier de
M1 : x = F −(u|θ),
θ ∈Θ,
u ∼g(u|ψ),
ψ ∈S ,
avec g(·|ψ) distribution sur [0, 1], dont un cas particulier est la distribution
uniforme g(u|ψ0) = 1, et S est un espace de dimension inﬁnie. Cette repa-
ram´etrisation du mod`ele nous permet de travailler sur les distributions sur
[0, 1], plutˆot que sur un espace g´en´eral, et ram`ene notre tˆache `a un test d’uni-
formit´e (conditionnellement `a θ).
Il y a de nombreuses possibilit´es pour le choix de la famille de distributions
g(·|ψ) de dimension inﬁnie. Un choix envisageable est la famille de m´elanges
de densit´es bˆeta,
g(u|ψ) = ϱ0 + (1 −ϱ0)
+∞

j=1
ϱj
uαj(1 −u)βj
K(αj, βj)
,
comme dans Petrone et Wasserman (2002) et l’estimation peut alors ˆetre
r´ealis´ee par des techniques `a sauts r´eversibles. Verdinelli et Wasserman (1998)
proposent ici d’utiliser les polynˆomes de Legendre sur [0, 1],
φj(x) =
1
2jj!
dj
dxj (x2 −1)j
correspondant aux densit´es
g(u|ψ) ∝exp
⎧
⎨
⎩
+∞

j=1
ψjφj(u)
⎫
⎬
⎭.
(Voir Barron, 1988, 1998, et Lenk, 1999, pour plus de d´etails.) Le mod`ele nul
M0 correspond alors `a ψ1 = . . . = ψp = . . . = 0.

7.6 Ad´equation `a une famille de lois
407
La distribution a priori sur (θ, ψ) est choisie de telle sorte que θ et ψ soient
ind´ependants, avec un a priori de r´ef´erence sur θ. Cette hypoth`ese d’ind´epen-
dance n’est pas sans cons´equence ´etant donn´e que θ a le mˆeme a priori sous
M0 et M1, mais n’est pas identiﬁable sous M1 (Exercice 7.40). Les ψj sont
alors mod´elis´es comme des variables al´eatoires ind´ependantes,
ψj ∼N (0, τ2
j ),
avec τj = τ/2j pour des raisons de coh´erence (Barron, 1988), et τ est associ´e
`a un a priori propre vague, π(τ).
La distribution a posteriori est alors donn´ee par
π(θ, ψ, τ|x1, · · · , xn) ∝
n

i=1
f(xi|θ)g(ui|ψ)π(θ) π(ψ|τ)π(τ) ,
(7.20)
avec
ui = F(xi|θ) (Exercice 7.41). Cette expression n’est manifestement
pas calculable, ne serait-ce que parce que les ui d´ependent de θ. On peut
n´eanmoins simuler π(θ, ψ, τ|x1, · · · , xn) au moyen d’un algorithme MCMC,
par exemple avec les ´etapes de Gibbs :
θ|ψ, x1, · · · , xn ∼
n

i=1
f(xi|θ)g(ui|ψ)π(θ) ,
ψ|τ, θ, x1, · · · , xn ∼
n

i=1
g(ui|ψ)π(ψ|τ) ,
τ|ψ ∼π(ψ|τ)π(τ) .
Il faut cependant des ´etapes de Metropolis-Hastings suppl´ementaires pour
simuler θ et ψ.
Une fois une approximation de la distribution a posteriori obtenue, Verdi-
nelli et Wasserman (1998) proposent d’utiliser le facteur de Bayes
B01 =

n

i=1
f(xi|θ)π(θ)dθ

n

i=1
f(xi|θ)g(F(xi|θ)|ψ)π(θ, ψ, τ)dθdψdτ
pour d´ecider si l’ad´equation `a M0 est suﬃsante. (Ils montrent de plus que la
proc´edure est convergente, que B01 tend vers 0 presque sˆurement si M0 n’est
pas le bon mod`ele et vers l’inﬁni en probabilit´e dans le cas contraire.) Une
autre proc´edure d’´evaluation consiste `a remarquer que M0 correspond `a τ = 0
et `a utiliser un test d’hypoth`ese standard sur l’´echantillon MCMC.

408
7 Choix et comparaison de mod`eles
7.7 Exercices
Section 7.1.1
7.1 La d´eviance d’un mod`ele est simplement la valeur de la log-vraisemblance pour
l’estimateur du maximum de vraisemblance (McCullagh et Nelder, 1989). Cal-
culer ˆλ et ( ˆm, ˆp) pour l’estimateur du maximum de vraisemblance de l’Exemple
7.1 et comparer les d´eviances.
7.2 Dans le cadre de l’Exemple 7.2, montrer qu’un m´elange `a k composantes peut
ˆetre repr´esent´e par un m´elange `a k + 1 composantes soit en annulant le poids
d’une des composantes, soit en ﬁxant la moyenne et la variance de la (k+1)-i`eme
composante ´egale `a celles d’une des k premi`eres composantes. Quel est le rapport
entre cette multiplicit´e et la propri´et´e de non-identiﬁabilit´e des m´elanges vue
dans la Note 6.6.6 ?
7.3 Pour l’Exemple 7.3, ´ecrire les distributions marginales des yi = (yi1, . . . , yi7) en
int´egrant les eﬀets al´eatoires. Est-il possible d’obtenir un r´esultat explicite avec
les lois a priori conjugu´ees ?
Section 7.2.1
7.4 On consid`ere deux mod`eles M1 : x ∼f1(x|θ1, γ) et M2 : x ∼f2(x|θ2, γ) avec
une distribution a priori
π(θ1, θ2, γ) = π1(θ1|γ)π2(θ2|γ)π0(γ) ,
π1 et π2 ´etant propres. Montrer que, si π0 est impropre, le facteur de Bayes Bπ
12
ne d´epend pas de la constante de normalisation de π0.
7.5 Dans le cadre de l’Exemple 7.4, on suppose que Tt est distribu´ee selon une loi
uniforme U[0, ¯
T ] et que β21 ∼N (0, τ 2).
a. En int´egrant le terme β21Tt dans M2, calculer le mod`ele marginal de yit.
b. En d´eduire la distribution a priori sur les param`etres de M1 si M2 est le
vrai mod`ele et (β20, b2i, σ2) ∼π(β20, b2i, σ2).
7.6
∗(Barbieri et al., 1999) Soit un mod`ele f(x|ϕ, ψ), (ϕ, ψ) ∈Φ×Ψ, tel qu’il existe
ψ∗∈Ψ v´eriﬁant
lim
ψ→ψ∗f(x|ϕ, ψ) = f ∗(x|ψ∗) ,
c’est-`a-dire tel que la distribution limite ne d´epende plus de ϕ.
a. Montrer que cette condition est v´eriﬁ´ee par le mod`ele de calibration lin´eaire,
z1 ∼N (ψ, 1),
z2 ∼N (φψ, 1) ,
pour ψ∗= 0.
b. Si π(ϕ, ψ) est un a priori propre avec une masse en ψ∗, montrer que
π(ϕ|x) = π(ϕ|ψ∗)π(ψ∗|x) + π(ϕ|ψ ̸= ψ∗, x)
Z
ψ̸=ψ∗π(ψ|x) dψ .
c. Si H0 : ϕ = ϕ0 doit ˆetre test´ee contre H1 : ϕ ̸= ϕ0, montrer que
B01 = π(ψ∗|x) + m(x|ψ ̸= ψ∗)
π(ϕ0)
Z
ψ̸=ψ∗π(ψ|x) dψ
en supposant que π a aussi une masse en ϕ0.

7.7 Exercices
409
d. En d´eduire que le facteur de Bayes est fortement inﬂuenc´e par la mod´elisation
a priori sur ψ∗, quel que soit ϕ0.
[Note : Gleser et Hwang (1987) ´etudient ces mod`eles d’un point de vue
fr´equentiste et montrent qu’un intervalle de conﬁance de niveau α sur une fonc-
tion non born´ee de ϕ a un volume inﬁni avec une probabilit´e positive.]
Section 7.2.2
7.7 (Berger et Pericchi, 2001) On consid`ere le mod`ele lin´eaire normal M2
y = α1 + z1β1 + z2β2 + ϵ,
ϵ ∼Nn(0, σ2In) ,
avec β1 ∈Rk, β2 ∈Rp et les zi centr´es et orthogonaux, c’est-`a-dire tels que
zt
1z2 = 0. Le sous-mod`ele M1 correspond `a β2 = 0.
a. Montrer que, sous les lois a priori
π1(α, β1, σ) = 1/σ
et
π2(α, β1, σ, β2) = h(β2|σ)/σ ,
avec h(β2|σ) suivant une loi de Cauchy Cp(0, zt
2z2/nσ2), le facteur de Bayes
B12 ne peut pas ˆetre calcul´e explicitement.
b. Pour le mod`ele M1 : y = Xβ + ϵ, ϵ ∼Nn(0, σ2In), le G-prior de Zellner
(1986b) est
π(σ) = 1/σ ,
π(β|σ) ∝exp{−βtXtXβ/2gσ2} .
Montrer que dans ce cas, la densit´e marginale est exprimable analytique-
ment.
c. Soit M0 le mod`ele associ´e `a β = 0. On note k la dimension de β dans
le mod`ele M1. Montrer que la limite du facteur de Bayes B01 est (1 +
g)(k−n)/2, quand l’estimateur du maximum de vraisemblance ˆβ tend vers
l’inﬁni. Conclure sur les avantages du G-prior pour ce probl`eme.
7.8
∗(Suite de l’Exercice 7.6) Pour le mod`ele `a calibration lin´eaire,
a. Montrer que l’a priori de Jeﬀreys est
πJ(ϕ, ψ) ∝|ψ| .
b. Montrer que, pour le test de H0 : ϕ = ϕ0, avec π0(ψ) ∝1, le facteur de
Bayes fractionnaire avec la fraction 0 < b < 1 (voir l’´equation (5.10)) est
BF
01 = b−1/2 exp
j
−1 −b
2
(z1 −z2ϕ0)2
1 + ϕ2
0
ﬀ
.
c. Montrer que le facteur de Bayes arithm´etique intrins`eque (voir l’´equation
(5.7)) est
BA
01 =
√
2 exp
j
−1 −0.5
2
(z1 −z2ϕ0)2
1 + ϕ2
0
ﬀ
.
d. ´Etudier l’extension `a n observations.
7.9
∗(Suite de l’Exercice 7.8)

410
7 Choix et comparaison de mod`eles
a. Montrer que l’a priori de r´ef´erence est
πR(ϕ, ψ) ∝
1
p
1 + ϕ2 .
b. Montrer que le facteur de Bayes est
BF
01 = b−1/2 exp
j
1 −b2 [(z2
1 −z2
2)(1 −ϕ0)2 −4z1z2ϕ0]
1 + ϕ2
0
ﬀ
I0(b(z2
1 + z2
2)/4)
I0((z2
1 + z2
2)/4) ,
avec I0 la fonction de Bessel modiﬁ´ee (Exercice 4.36).
7.10
∗Dans le contexte de l’Exemple 7.5,
a. Eﬀectuer le calcul complet de Bπ
12 pour arriver `a l’expression ﬁnale de
l’exemple.
b. Montrer que la limite de Bπ
12 est diﬀ´erente suivant que α/β tende vers 0
lorsque α et β tendent vers 0, ou que α/βN tende vers c > 0, avec x < N.
7.11 Calculer la distribution marginale de x1 si x1, . . . , xn est un ´echantillon d’un
m´elange normal `a deux composantes tel qu’il y ait au moins deux observations
dans chaque composante.
Section 7.2.3
7.12 Montrer que, pour la comparaison de deux mod`eles lin´eaires M1 et M2, avec
respectivement k1 et k2 r´egresseurs, et n observations, sous l’a priori πj(βj) =
σ
−1−qj
j
(j = 1, 2), le facteur de Bayes associ´e au crit`ere BIC s’´ecrit
B12 = (R2/R1)n/2 n(k2−k1)/2 ,
en notant Rj les sommes des carr´es r´esiduels.
7.13 (Suite de l’Exercice 7.8)
Dans le cas du mod`ele `a calibration lin´eaire,
sous l’a priori de Jeﬀreys, montrer que le crit`ere de Schwarz donne presque le
mˆeme r´esultat que le facteur de Bayes fractionnel avec la fraction b = 0 dans
l’exponentielle. Commenter.
Section 7.2.4
7.14 Si f(·|θ) appartient `a une famille exponentielle, montrer que le nombre eﬀectif
de param`etres pD est toujours positif.
7.15
∗(Spiegelhalter et al., 1998) Dans le cadre de l’Exemple 7.8,
a. Montrer que, pour le mod`ele satur´e avec les θi ind´ependants de lois a priori
constantes, pD est ´egal `a p et la d´eviance bay´esienne vaut 2p.
b. Montrer que la d´eviance bay´esienne associ´ee au mod`ele agr´eg´e, θi = θ pour
tout i, est donn´ee par (7.8).
c. Montrer que l’´equation (7.9) est vraie.
d. On suppose que θi ∼N (μ, τ 2) avec τ connu et π(μ) = 1. Montrer que
pD =
p
X
i=1
ϱi +
p
X
i=1
ϱi(1 −ϱi)
ﬃ
p
X
i=1
ϱi

7.7 Exercices
411
et que la d´eviance bay´esienne est ´egale `a
DIC = τ −2
p
X
i=1
ϱi(1 −ϱi)(yi −¯y)2 + pD ,
avec ϱi = σ2
i τ 2/(σ2
i + τ 2) et ¯y = P
i ϱiyi/ P
i ϱi.
7.16 Donner dans le d´etail l’impl´ementation MCMC des trois mod`eles de l’Exemple
7.9. (Indication : La simulation peut ˆetre trait´ee par BUGS.)
7.17
∗(Spiegelhalter et al., 1998) On consid`ere un mod`ele lin´eaire g´en´eral
y ∼N (Aθ1, Σ1) ,
θ1 ∼N (Bθ2, Σ2) .
a. Montrer que la distribution a posteriori de θ1 est de la forme N (¯θ1, Ψ) et
calculer ¯θ1 et Ψ.
b. Montrer que E[D(θ)|y] = D(¯θ1) + tr(A′Σ−1
1 AΨ) et en d´eduire pD =
tr(A′Σ−1
1 AΨ).
c. ´Elargir au cas θ2 al´eatoire et π(θ2) = 1.
7.18 Montrer que les lois conditionnelles sur les ϕi d´eﬁnies dans l’Exemple 7.9 sont
bien compatibles avec une loi jointe et expliciter cette loi jointe.
Section 7.3.1
7.19 L’esp´erance de
1
T
T
X
t=1
h(θ(t))
f(x|θ(t))π(θ(t)) ,
avec les θ(t) distribu´es selon π(θ|x), est-elle ´egale `a m(x) quelle que soit la densit´e
de probabilit´e h ?
7.20
∗(Chen et Shao, 1997)
Soient deux densit´es, π1(θ) = c1˜π1(θ) et π2(θ) =
c2˜π2(θ), sur le mˆeme espace de param`etres Θ.
a. Si π est une densit´e sur Θ, donner des conditions suﬃsantes sur le support
de π pour que
ϱ = c2
c1 = Eπ[˜π1(θ)/π(θ)]
Eπ[˜π2(θ)/π(θ)] .
b. Montrer que la variance asymptotique de l’estimateur de
ϱUS =
Pn
i=1 ˜π1(θi)/π(θi)
Pn
i=1 ˜π2(θi)/π(θi) ,
avec les θi i.i.d. de loi π, est
ϱ2Eπ
jπ1(θ)
π(θ) −π2(θ)
π(θ)
ﬀ2
.
c. En supposant que
ϱ−2Eπ[(ϱUS −ϱ)2] = 1
nEπ
»{π1(θ) −π2(θ)}2
π2(θ)
–
+ o
`
n−1´
,
montrer que la meilleure densit´e d’importance π est

412
7 Choix et comparaison de mod`eles
π0(θ) ∝|π1(θ) −π2(θ)| ,
si
Z
|π1(θ) −π2(θ)| dθ < ∞.
[Note : Torrie et Valleau (1977) appellent cette m´ethode l’´echantillonnage par
parapluie.]
Section 7.3.2
7.21 ´Etant donn´e deux densit´es π1(θ) = c1˜π1(θ) et π2(θ) = c2˜π2(θ) sur le mˆeme
espace de param`etres Θ, et h une fonction arbitraire,
a. Exprimer Eπ2[h(θ)˜π1(θ|x)] sous la forme d’une int´egrale en fonction de π1
et π2.
b. En d´eduire l’´egalit´e (7.13).
7.22
∗Chen et al. (2000) d´eﬁnissent l’erreur quadratique moyenne relative
E (r, ˆr) = E[ˆr −r]
r
pour ´evaluer les performances de l’estimateur ˆr du rapport constant r.
a. Montrer que, si n = n1 + n2 et si n1/n2 tend vers ϱ lorsque n tend vers
l’inﬁni, alors
E (r, BS
12) ≃
1
nϱ(1 −ϱ)
"R
π1(θ)π2(θ){ϱπ1(θ) + (1 −ϱ)π2(θ)}h2(θ) dθ
`R
π1(θ)π2(θ) dθ
´2
#
pour l’estimateur (7.14), en faisant abstraction de la d´ependance en x par
souci de simpliﬁcation. (Indication : Utiliser la m´ethode delta.)
b. En d´eduire que le choix optimal pour h est
h∗(θ) ∝
1
ϱπ1(θ) + (1 −ϱ)π2(θ) .
7.23 Pour les trois fonctions de lien de l’Exemple 7.10, proposer une structure `a
variables latentes z qui permette d’identiﬁer y `a l’indicatrice Iz≤xtβ.
Section 7.3.3
7.24 Soit une distribution a posteriori π(θ1, θ2, θ3|x) telle qu’on ait acc`es aux trois
distributions conditionnelles compl`etes π(θ1|θ2, θ3, x), . . . et π(θ3|θ1, θ2, x).
a. Montrer que
log m(x) = log f(x|ˆθ) + log π(ˆθ) −log π(ˆθ3|ˆθ1, ˆθ2, x)
−log π(ˆθ2|ˆθ1, x) −log π(ˆθ1|x) .
b. Montrer que π(θ1|x) peut ˆetre estim´e par
ˆπ(θ1|x) = 1
T
T
X
t=1
π(θ1, θ(t)
2 , θ(t)
3 |x) ,
avec (θ(t)
1 , θ(t)
2 , θ(t)
3 ) simul´e par ´echantillonnage de Gibbs.

7.7 Exercices
413
c. Montrer que π(θ2|ˆθ1, x) peut ˆetre estim´e par
ˆπ(θ2|ˆθ1, x) = 1
T
T
X
t=1
π(θ2|ˆθ1, θ(t)
3 , x)
avec (θ(t)
2 , θ(t)
3 ) simul´e par ´echantillonnage de Gibbs selon les distributions
conditionnelles π(θ2|ˆθ1, θ(t−1)
3
, x) et π(θ3|ˆθ1, θ(t)
2 , x), ce qui revient `a rem-
placer θ1 par ˆθ1.
d. ´Etendre au cas o`u on dispose de p densit´es conditionnelles compl`etes et
´evaluer le coˆut n´ecessaire en temps de calcul pour cette m´ethode d’approxi-
mation.
Section 7.3.4
7.25 Dans le cadre de l’Exemple 7.16, montrer que les jacobiens des d´eplacements
de naissance et de s´eparation sont respectivement donn´es par
(1 −p(k+1)(k+1))k
et
pjk/(1 −u1) .
Section 7.4
7.26 On revient sur les distributions a priori propos´ees par Clyde (1999),
a. Montrer que la distribution a posteriori de (γ1, . . . , γJ) conditionnellement
`a σ est donn´ee par (7.18).
b. En d´eduire que le sous-mod`ele le plus probable correspond aux r´egresseurs
Xj avec des poids ϱj plus grands que 1/2.
7.27
∗(George et Foster, 1999) Dans un mod`ele de r´egression normale
y = β1x1 + . . . + βpxp + σϵ ,
ϵ ∼N (0, I) ,
si γ est l’indice d’un sous-mod`ele parmi les 2p sous-mod`eles possibles, on note qγ
le nombre de covariables correspondant, Xγ la matrice des r´egresseurs associ´ee,
ˆβγ l’estimateur des moindres carr´es et s2
γ la somme des carr´es ˆβ′
γX′
γXγ ˆβγ.
a. Soient les distributions a priori
βγ|σ, γ, c ∼Nqγ
“
0, cσ2 `
X′
γXγ
´−1”
,
π(γ|ω) = ωqγ(1 −ω)p−qγ .
Identiﬁer cet a priori `a celui de Madigan et Raftery (1995).
b. Montrer que
π(γ|y, σ, c, ω) ∝exp
»
c
2(1 + c){s2
γ/σ2 −F(c, ω)qω}
–
avec
F(c, ω) = 1 + c
c
„
2 log 1 + w
w
+ log(1 + c)
«
.
c. En d´eduire que la distribution a posteriori int´egr´ee π(γ|y, σ, c, ω) est une
fonction croissante de s2
γ/σ2 −F(c, ω)qω.

414
7 Choix et comparaison de mod`eles
d. Conclure que, moyennant un choix ad´equat de (c, ω), le log-a posteriori
peut ˆetre ´equivalent `a n’importe quel crit`ere standard de choix de mod`ele,
de AIC (avec F(c, ω) = 2) `a BIC (avec F(c, ω) = log n), en passant par le
RIC de Foster et George (1998) (avec F(c, ω) = 2 log p).
Section 7.5
7.28 Montrer que la divergence de Kullback-Leibler entre deux distributions nor-
males N (0, 1) et N (μ, σ2) est
log σ + μ2 + 1
2σ2
−1
2 .
Adapter la formule `a la divergence de Kullback-Leibler entre N (μ0, σ2
0) et
N (μ, σ2) par un changement d’´echelle appropri´e.
7.29 Pour chacune des distributions suivantes, montrer l’´egalit´e correspondante sur
la divergence de Kullback-Leibler :
(i) Bernoulli B(p) :
d(f(· |p0), f(· |p)) = p0 log p0
p + (1 −p0) log 1 −p0
1 −p ;
(ii) Poisson P(λ) :
d(f(· |λ0), f(· |λ)) = λ −λ0 + λ0 log λ0
λ ;
et
(iii) Normale N (μ, 1) :
d(f(· |μ0), f(· |μ)) = (μ −μ0)2/2 .
7.30 On consid`ere un probl`eme de s´election de variables avec p covariables.
a. Montrer que le nombre de sous-mod`eles est 2p −1 si tous les mod`eles ont
un terme constant et 2p −2 sinon.
b. Montrer que le nombre de mod`eles avec exactement p0 covariables est
` p
p0
´
.
c. En utilisant l’approximation de Stirling, montrer que ce nombre est ´egalement
d’ordre 2p pour p0 = p/2.
7.31 On consid`ere un probl`eme de choix de mod`ele o`u (x, y) ∼g(x|α)f(y|x, θ).
a. Montrer que, pour la divergence de Kullback-Leibler,
d
`
g(·|α)f(·|·, θ), g(·|α′)f(·|·, θ′)
´
= d(g(·|α), g(·|α′))
+Eα
ˆ
d(f(·|x, θ), f(·|x, θ′)
˜
,
l’esp´erance ´etant prise sous x ∼g(x|α).
b. En d´eduire que, si le sous-mod`ele pose des contraintes sur θ uniquement,
par exemple ϕ(θ) = 0, la projection de (α, θ) est (α, θ⊥) si θ⊥est la solution
de
arg
min
θ′; ϕ(θ′)=0 Eα
ˆ
d(f(·|x, θ), f(·|x, θ′)
˜
.
7.32 Dans le cas d’un mod`ele de r´egression lin´eaire normal, y ∼N (x′β, σ2),

7.7 Exercices
415
a. Montrer que, si z est un sous-vecteur de x, la divergence de Kullback-Leibler
entre N (x′β, σ2) et N (z′γ, σ2) est ||x′β −z′γ||2/2σ2, conditionnellement
`a x.
b. En d´eduire que la projection β⊥s’´ecrit β⊥= (zz′)−1zx′β.
7.33 (Suite de l’Exercice 7.32) On suppose que β est distribu´e selon une loi a
priori conjugu´ee N (β0, Σ). Calculer la distribution a priori induite de β⊥. Que
se passe-t-il dans le cas d’un a priori constant sur β ?
7.34 Dans le cadre de l’Exemple 7.20, d´eterminer si la constante de normalisation
de la moyenne g´eom´etrique des distributions de Poisson et binomiale n´egative,
f(y|λ, m, α), est calculable.
7.35 On compare deux mod`eles M1 et M2, de densit´es f1(·|θ1) et f2(·|θ2) toutes
deux issues d’une famille exponentielle.
a. Montrer que la moyenne g´eom´etrique
f1(·|θ1)α f2(·|θ2)1−α
appartient encore `a une famille exponentielle.
b. Montrer que, si, pour (i = 1, 2)
fi(y|θi) = hi(y) exp{θi · ϕi(y) −ψi(θi)} ,
(ϕ1(y), ϕ2(y)) est une statistique exhaustive pour la moyenne g´eom´etrique.
c. En d´eduire que, si (ϕ1(y), ϕ2(y)) est de plein rang, la dimension de cette
famille (D´eﬁnition 3.8) est la somme des dimensions de f1 et f2.
d. Dans le cas particulier o`u M1 est exponentielle E xp(θ1) et M2 semi-normale
N +(0, 1/θ2), montrer que le mod`ele de la moyenne g´eom´etrique est la dis-
tribution normale tronqu´ee
N +
„
−
αθ1
(1 −α)θ2 ,
1
(1 −α)θ2
«
,
et calculer sa constante de normalisation.
Section 7.6
7.36 Consid´erer l’extension d’une famille exponentielle de Neyman (1937) lorsque
f(x|θ) est la densit´e d’une loi (i) de Poisson P(θ), (ii) exponentielle E xp(θ) et
(iii) normale N (θ, 1). Dans les trois cas, d´eterminer si la constante de norma-
lisation est calculable.
7.37 ´Etant donn´e une densit´e
f(y|θ) = h(y) exp{θ · ϕ(y) −ψ(θ)}
d’une famille exponentielle de dimension d (D´eﬁnition 3.8), montrer que son
extension de Neyman appartient encore `a une famille exponentielle de dimension
d + 1.
7.38
∗(Castro et al., 1999) On consid`ere un mod`ele multinomial
r = (r0, . . . , rk) ∼Mk+1(n; α0, . . . , αk) ,
avec α = (α1, . . . , αk).

416
7 Choix et comparaison de mod`eles
a. En notant (0 ≤b ≤1)
q2(r; b) =
R
f(r|α)π2(α) dα
R
f b(r|α)π2(α) dα ,
montrer que, sous l’a priori impropre π2(α) = 1/α1 . . . αk,
q2(r; b) = Γ(bn)
Γ(n)
k
Y
j=0
Γ(rj)
Γ(brj) ,
si tous les rj sont positifs. (Si l’un des rj est nul, l’a posteriori n’est pas
d´eﬁni.)
b. Si la contrainte sur les αj est
αj =
 
k
j
!
μj(1 −μ)k−j ,
0 < μ < 1 ,
c’est-`a-dire si on veut tester que le mod`ele sous-jacent est vraiment binomial,
montrer que, sous l’a priori π1(μ) = 1/μ(1 −μ),
q1(r; b) =
R
f(r|α(μ))π1(μ) dμ
R
f b(r|α(μ))π1(μ) dμ
=
B(r, kn −sr)
B(br, b(kn −sr))
" k
Y
j=0
 
k
j
!rj#1−b
,
avec sr = r1 + . . . + krk et B(a, b) constante de normalisation de la loi
Be(a, b) (voir Annexe A).
c. Montrer que le facteur de Bayes fractionnel associ´e `a la contrainte en b. est
BF
12 = q1(r; b)/q2(r; b).
d. Appliquer b. aux donn´ees du Tableau 7.5.
Tab. 7.5. Nombre de femmes dans une ﬁle d’attente de dix personnes dans le m´etro
de Londres (Source : Hoaglin et al., 1996.)
Nombre de femmes
0 1 2 3
4
5
6 7 8 9 10
Occurrences
1 3 4 23 25 19 18 5 1 1 0
e. Si la contrainte sur les αj prend la forme d’un mod`ele de Poisson, αj =
e−λλj/j! (j = 0, . . . , k), montrer que, sous l’a priori π1(λ) = λ−t,
q1(r; b) =
R
f(r|α(λ))π1(λ) dλ
R
f b(r|α(λ))π1(λ) dλ
= Γ(sr −t + 1)bbsr−t+1nsr(b−1)
Γ(bsr −t + 1)
k
Y
j=0
[j!](b−1)rj ,
en d´eﬁnissant sr comme en b.

7.7 Exercices
417
f. Montrer que, sous les mˆemes hypoth`eses que dans e., les facteurs de Bayes
intrins`eques ne sont pas constructibles, `a moins que les cellules ne soient
group´ees pour former des rj positifs.
g. Montrer que, pour un mod`ele continu, cette strat´egie est l’´equivalent
bay´esien du test du χ2 et qu’elle souﬀre par cons´equent du mˆeme probl`eme,
`a savoir le cˆot´e arbitraire du regroupement des observations en k cellules.
7.39 Soit F une fonction de r´epartition dans R. L’inverse g´en´eralis´ee de F est
d´eﬁnie par
F −(u) = inf{x; F(x) ≥u}
a. Montrer que dans le cas u ∼U ([0, 1]), F −(u) ∼F.
b. En d´eduire une technique de simulation pour les distributions de Cauchy et
exponentielle.
c. Comment g´en´eraliser ce r´esultat pour une distribution multidimension-
nelle ?
7.40 Dans le contexte de l’article de Verdinelli et Wasserman (1998), montrer que
le param`etre θ n’est pas identiﬁable sous le mod`ele alternatif M1. (Indication :
Montrer que, pour toute fonction de r´epartition F(x) et pour tout θ, il existe ψ
tel que F −
θ ◦Gψ = F −.)
7.41 (Verdinelli et Wasserman, 1998) D´emontrer l’´egalit´e (7.20) en ´etablissant que,
sous le mod`ele M1,
x ∼h(x|θ, ψ) = g(F(x|θ)|ψ)dF(x|θ)
dx
= g(F(x|θ)|ψ)f(x|θ) .
Note 7.8.1
7.42 Prouver l’´egalit´e (7.21) en montrant que
Z Z
d
dλ log ˜π(θ|λ)π(θ|λ) dλ dθ = −
Z λ2
λ1
d
dλc(λ) dλ .
7.43
∗(Suite de l’Exercice 7.42) Montrer que la g´en´eralisation de (7.21) au cas
multidimensionnel s’´ecrit
log(c(λ2)/c(λ1)) =
Z 1
0
Eλ(t)
" k
X
j=1
dλj(t)
dt
∂
∂λj log ˜π(θ|λ)
#
dt ,
avec λ(t) fonction continue de [0, 1] dans Λ telle que λ(0) = λ1 et λ(1) = λ2. En
d´eduire l’´echantillonneur par chemin correspondant. (Indication : Voir Gelman
et Meng, 1998, pour une solution d´etaill´ee.)
Note 7.8.2
7.44 Dans le cadre de l’Exemple 7.21, donner les ´etapes de sauts r´eversibles qui
correspondent aux d´eplacements de naissance et de mort.

418
7 Choix et comparaison de mod`eles
7.8 Notes
7.8.1 ´Echantillonnage par chemin
Gelman et Meng (1998) g´en´eralisent l’´echantillonnage par passerelle `a l’´echantil-
lonnage par chemin en consid´erant le cas particulier o`u les deux lois a posteriori
d´ependent de la mˆeme mani`ere d’hyperparam`etres, λ1 et λ2,
π1(θ|x) = π(θ|λ1) = ˜π(θ|λ1)/c(λ1) ,
π2(θ|x) = π(θ|λ2) = ˜π(θ|λ2)/c(λ2) .
Si les hyperparam`etres sont des r´eels tels que λ1 < λ2, on a, pour toute densit´e
π0 de support [λ1, λ2],
log(c(λ2)/c(λ1)) = E
»
1
π0(λ)
d
dλ log ˜π(θ|λ)
–
,
(7.21)
en int´egrant sur la densit´e π(θ|λ)π0(λ) (Exercice 7.42).
L’estimateur correspondant du logarithme du facteur de Bayes en ´echantillon-
nage par chemin est alors
BP S
12 = 1
n
n
X
i=1
d
dλ log ˜π(θi|λi)
π0(λi)
,
avec le choix formellement optimal pour π0,
π0(λ) ∝
v
u
u
tE
"„ d
dλ log ˜π(θ|λ)
«2 ˛˛˛˛λ
#
.
(Voir l’Exercice 7.43 pour une extension au cas multidimensionnel.)
7.8.2 Processus de saut
On consid`ere ici une technique analogue `a celle par sauts r´eversibles largement
abord´ee dans la litt´erature (voir, par exemple, Ripley, 1987, Grenander et Miller,
1994, ou Phillips et Smith, 1996). Elle est en th´eorie applicable (Capp´e et al.,
2003) dans un cadre tr`es g´en´eral mais n’a pour l’instant ´et´e utilis´ee que dans
des probl`emes de s´election de variables. C’est le cas notamment de la solution
de Stephens (2000) au probl`eme de l’Exemple 7.2.
Cette m´ethode s’appuie sur les processus de sauts : on simule un processus de
saut `a temps continu sur l’espace (7.2), c’est-`a-dire un processus stochastique
(ξt)t∈R+ qui reste dans un ´etat donn´e (i, θi) pour une dur´ee suivant une loi
exponentielle T ∼E xp(ϕi(θi)), ϕ ´etant l’intensit´e du processus, puis saute
vers un nouvel ´etat j avec une probabilit´e qi→j et simule θj selon une densit´e
hi→j(θj|θi). Ensuite, comme en temps discret (voir (6.17)), si les param`etres du
processus, ϕ, q et h, satisfont une condition d’´equilibre ponctuel
π(i, θi)ϕi(θi)qi→jhi→j(θj|θi) = π(j, θj)ϕj(θj)qj→ihj→i(θi|θj) ,
alors π(i, θi) est une distribution stationnaire de ce processus markovien. Par
exemple, si hi→j(θj|θi) = gj(θj) et qi→j = 1/k, avec k nombre d’´etats, la condi-
tion d’´equilibre est

7.8 Notes
419
π(i, θi)ϕi(θi)gj(θj) = π(j, θj)ϕj(θj)gi(θi)
et l’intensit´e est ϕi(θi) ∝gi(θi)/π(i, θi). (L’intensit´e ϕi(θi) est l’inverse de la
dur´ee moyenne en (i, θi), qui est logiquement proportionnelle `a π(i, θi).)
Dans le cas particulier o`u les d´eplacements sont limit´es aux ´etats adjacents, c’est-
`a-dire lorsque qi→i+1 + qi→i−1 = 1 (avec les modiﬁcations qui conviennent aux
extrˆemit´es), le processus est appel´e processus de saut `a naissances et `a morts.
On ´ecrit alors souvent ϕi(θi) = β(θi) + δ(θi), avec β(θi) taux de naissance et
δ(θi) taux de mort, et on s’aﬀranchit du param`etre qi→j. Le processus reste dans
l’´etat (i, θi) pendant un temps exponentiel E xp[β(θi) + δ(θi)], puis se d´eplace
soit vers l’´etat (i + 1, θi+1) avec probabilit´e β(θi)/(β(θi) + δ(θi)), θi+1 ´etant
simul´e selon K+
i (θi+1|θi), soit vers l’´etat (i −1, θi−1), θi−1 ´etant simul´e selon
K−
i (θi−1|θi).
Exemple 7.21. (Suite de l’Exemple 7.2)
Pour l’exemple du m´elange, les
´etiquettes des ´etats i correspondent aux nombres de composantes, la naissance
`a l’ajout d’une composante et la mort `a la suppression d’une composante. Alors
θi = (p1i, . . . , pii, μ1i, . . . , μii, σ1i, . . . , σii). Dans son impl´ementation de l’algo-
rithme `a sauts de naissances et de morts, Stephens (2000) simule de nouvelles
composantes selon la distribution a priori (dans laquelle toutes les composantes
sont i.i.d.) et choisit un taux de naissance ﬁxe β(θi) = b. La condition d’´equilibre
devient alors
(i + 1)β(θi+1)L[(i + 1, θi+1)|x1, . . . , xn]π(i + 1) = bL[(i, θi)|x1, . . . , xn]π(i) ,
en notant L(θ|x1, . . . , xn) la vraisemblance. (Le coeﬃcient (i + 1) tient au fait
qu’il y a (i + 1) composantes et donc (i + 1) suppressions possibles.)
En notant θi/(pℓi, μℓi, σℓi) le param`etre du mod`ele `a (i −1) composantes o`u la
composante (pℓi, μℓi, σℓi) a ´et´e supprim´ee, l’algorithme de naissance et de mort
est le suivant :
Algorithme 7.1. Sauts de naissance et de mort
Dans l’´etat (i, θi),
1. Calculer les taux de mort de chaque composante (ℓ= 1, . . . , i)
βℓ(θi) = L[(i −1, θi/(pℓi, μℓi, σℓi))|x1, . . . , xn]
L[(i, θi)|x1, . . . , xn]
et prendre β(θi) = Pi
ℓ=1 βℓ(θi)
2. Simuler le temps de saut T ∼E xp(β(θi) + b)
3. `A l’instant T, supprimer
(pℓi, μℓi, σℓi)|x1, . . . , xn
avec probabilit´e
βℓ(θi)
β(θi) + b
Sinon, cr´eer
(p(i+1)(i+1), μ(i+1)(i+1), σ(i+1)(i+1))
suivant la distribution a priori.

420
7 Choix et comparaison de mod`eles
Remarquons que, dans l’´etape 3, le nouveau poids est simul´e selon la distribution
marginale a priori de p(i+1)(i+1), qui est une distribution Be(i, 1) si l’a priori
sur (p1(i+1), . . . , p(i+1)(i+1)) est Dirichlet Di+1(1, . . . , 1).
∥
On pourra consulter Capp´e et al. (2003) pour une analyse plus approfondie des
liens entre l’algorithme par sauts r´eversibles et l’algorithme par processus de
saut, leur conclusion ´etant que les deux m´ethodes diﬀ`erent tr`es peu.
7.8.3 S´election de variables dans le cas de mod`eles lin´eaires g´en´eralis´es
Nous pr´esentons maintenant de fa¸con plus d´etaill´ee la technique de s´election de
variables introduite en Section 7.5. Soit, donc, une famille exponentielle g´en´erale
(i = 1, . . . , n)
yi|θi ∼exp [ϕi {θiyi −ψ(θi)} + c(ϕi, yi)]
avec une structure de mod`ele lin´eaire g´en´eralis´e (McCullagh et Nelder, 1989)
qui impose une relation entre la moyenne et le vecteur des covariables,
g(ψ′(θi)) = xt
iβ .
Dans ce cadre, la divergence de Kullback-Leibler est calculable analytiquement
puisque
d(f(· |θ), f(· |θ0)) =
n
X
i=1
ϕi {ψ
′(θi)(θi −θ0
i ) −ψ(θi) + ψ(θ0
i )}
et les ´equations de projection (j = 1, . . . , p)
n
X
i=1
ϕi ψ
′(θi) ∂θ0
i
∂βj =
n
X
i=1
ϕi ψ
′(θ0
i ) ∂θ0
i
∂βj ,
(7.22)
sont ´equivalentes au syst`eme des ´equations de vraisemblance, ce qui rend leur
r´esolution plus facile.
Pour un mod`ele logit,
P(yi = 1|xi, α) = 1 −P(yi = 0|xi, α) =
exp(αtxi)
1 + exp(αtxi) ,
la projection α⊥de α sur les covariables zi (vecteur inclus dans les xi) est, par
exemple, associ´e `a β solution de
n
X
i=1
exp βtzi
1 + exp βtzi zi =
n
X
i=1
exp αtxi
1 + exp αtxi zi ,
ce qui donne eﬀectivement une ´equivalence formelle avec les ´equations du maxi-
mum de vraisemblance
n
X
i=1
exp βtzi
1 + exp βtzi zi =
n
X
i=1
yizi .
Une cons´equence de (7.22) est que les projections de Kullback-Leibler sont tran-
sitives dans la mesure o`u, si ω est un vecteur inclus dans z, lui-mˆeme inclus dans
x, on a

7.8 Notes
421
n
X
i=1
exp γtωi
1 + exp γtωi ωi =
n
X
i=1
exp βtzi
1 + exp βtzi ωi
=
n
X
i=1
exp αtxi
1 + exp αtxi ωi
pour l’exemple du logit. En d’autres termes, cela signiﬁe que la projection γ de
la projection β de α est la projection de α sur un sous-espace plus petit, une
version orient´ee “choix de mod`ele” du th´eor`eme de la double projection. Une
autre propri´et´e remarquable est l’additivit´e des distances entre ces projections :
d(f(· |α), f(· |γ)) = d(f(· |α), f(· |β)) + d(f(· |β), f(· |γ)) .
Par rapport au sch´ema g´en´eral de s´election de variables pr´esent´e en Section
7.5, cela veut dire que, une fois qu’un sous-mod`ele a ´et´e rejet´e parce qu’il a
´et´e consid´er´e comme trop loin du mod`ele entier, tous ses sous-mod`eles seront
´egalement rejet´es. Voir Dupuis et Robert (2001) pour plus de d´etails.

8
Admissibilit´e et classes compl`etes
“You can turn the worse that comes to your advantage if you only
think, his father has always said, and certainly Abell Cauthon was
the best horse trader in the Two Rivers (...) All because he thought
about things from every side that there was.”
Robert Jordan, The Dragon Reborn.
8.1 Introduction
Nous avons soulign´e `a plusieurs reprises au cours des Chapitres 1 `a 3
l’int´erˆet des estimateurs de Bayes dans la recherche fr´equentiste d’optima-
lit´e et en particulier `a l’´egard de l’admissibilit´e. Nous y revenons `a pr´esent
en d´etail. Dans la Section 8.2, nous ´etudions les performances des estima-
teurs de Bayes et de Bayes g´en´eralis´es en termes d’admissibilit´e. Puis la
Section 8.3 ´etablit un lien entre l’admissibilit´e d’un estimateur et une suite
de distributions a priori grˆace `a la condition suﬃsante de Stein. La notion
de classe compl`ete d´ecrite en Section 8.4 est ´egalement fondamentale, car
elle permet d’obtenir une caract´erisation des estimateurs admissibles ou, au
moins, une r´eduction substantielle de la classe des estimateurs acceptables.
Nous pr´esentons des cas o`u l’ensemble des estimateurs de Bayes constitue
une classe compl`ete et d’autres situations dans lesquelles il est n´ecessaire de
consid´erer les estimateurs de Bayes g´en´eralis´es. Enﬁn dans la Section 8.5, nous
exposons une m´ethode introduite par Brown (1971) et d´evelopp´ee par Hwang
(1982b), qui donne des conditions n´ecessaires d’admissibilit´e dans un cadre

424
8 Admissibilit´e et classes compl`etes
plus g´en´eral, mais non bay´esien. Pour une analyse plus technique de ces sujets,
on pourra consulter la revue de Rukhin (1995).
8.2 Admissibilit´e des estimateurs de Bayes
8.2.1 Caract´erisations g´en´erales
Rappelons les deux r´esultats suivants sur l’admissibilit´e des estimateurs
(propres) de Bayes, vus dans le Chapitre 2 (Propositions 2.34 et 2.35) :
Proposition 8.1. Si un estimateur de Bayes est unique, il est admissible.
Proposition 8.2. Lorsque la fonction de risque est continue en θ pour tout
estimateur δ, si π est ´equivalente `a la mesure de Lebesgue sur Θ, c’est-`a-dire
si elle est absolument continue de densit´e positive sur Θ, un estimateur de
Bayes associ´e `a π est admissible.
En revanche, si le support de π n’est pas l’espace entier, il est possible qu’un
estimateur de Bayes associ´e soit inadmissible. De mˆeme, les estimateurs de
Bayes sont souvent inadmissibles lorsque le risque de Bayes est inﬁni.
Exemple 8.3. On consid`ere une loi normale x ∼N (θ, 1) avec un a priori
conjugu´e θ ∼N (0, σ2). La distribution a posteriori est alors N (
σ2
σ2+1x,
σ2
σ2+1)
et l’estimateur de Bayes pour la fonction de coˆut quadratique est
δπ(x) =
σ2
σ2 + 1x ,
qui est admissible, comme le montre le Corollaire 8.14 ci-dessous. `A l’inverse,
si on change le coˆut quadratique en
Lα(θ, δ) = eθ2/2α(θ −δ)2,
l’estimateur de Bayes correspondant est inadmissible pour α suﬃsamment
petit. L’estimateur de Bayes g´en´eralis´e associ´e `a Lα est en fait
δπ
α(x) =
 ∞
−∞θeθ2/2αe−(θ−δπ(x))2(σ2+1)/2σ2dθ
 ∞
−∞eθ2/2αe−(θ−δπ(x))2(σ2+1)/2σ2dθ ,
`a condition que les deux int´egrales soient ﬁnies. Dans la mesure o`u
exp
 θ2
2α −(θ −δπ(x))2 σ2 + 1
2σ2

= exp

−θ2
2 (σ2 + 1
σ2
−1
α) + δπ(x)θσ2 + 1
σ2
−δπ(x)2 σ2 + 1
2σ2

,

8.2 Admissibilit´e des estimateurs de Bayes
425
δπ
α est d´eﬁni pour α >
σ2
σ2+1 et
δπ
α(x) = σ2 + 1
σ2
σ2 + 1
σ2
−α−1
−1
δπ(x)
=
α
α −
σ2
σ2+1
δπ(x).
Le risque de Bayes correspondant est
r(π) =
 +∞
−∞
eθ2/2αe−θ2/2σ2dθ,
et est donc inﬁni pour α ≤σ2. De plus, puisque
α
α −
σ2
σ2+1
δπ(x) =
α
α −
σ2
σ2+1
σ2
σ2 + 1x
=
α
α σ2+1
σ2
−1
x,
l’estimateur de Bayes δπ
α(x) est de la forme cx avec c > 1 lorsque
α > ασ2 + 1
σ2
−1,
c’est-`a-dire quand α < σ2. Et, dans ce cas,
R(θ, δπ
α) = Eθ[(cx −θ)2]eθ2/2α
= {(c −1)2θ2 + c2}eθ2/2α > eθ2/2α
implique que δπ
α est inadmissible, puisqu’il est domin´e par δ0(x) = x, de
risque ´egal `a 1. Mais δ0 est ´egalement un estimateur de Bayes formel sous Lα
quand α < σ2, puisque le risque de Bayes est alors inﬁni. Il est int´eressant
de remarquer que le cas limite α = σ2 correspond `a l’estimateur admissible
δπ
σ2(x) = x avec un risque de Bayes inﬁni.
∥
Exemple 8.4. Soit y ∼σ2χ2
p. La distribution a priori conjugu´ee de σ2 est la
distribution gamma inverse I G (ν/2, α/2) (voir le Chapitre 3) et π(σ2|y) est
la distribution I G ((ν +p)/2, (α+y)/2), ce qui donne l’esp´erance a posteriori
suivante :
δπ
ν,α(y) = Eπ[σ2|y] =
α + y
ν + p −2.
Dans le cas particulier ν = 2, δπ(y) = (y/p) + (α/p). Puisque y/p est un
estimateur non biais´e de σ2, les estimateurs δπ
2,α ne sont pas admissibles sous
l’erreur quadratique (puisque α > 0). Ce r´esultat est ´egalement vrai pour
ν < 2. On v´eriﬁe facilement que le risque de Bayes de δπ est inﬁni dans ce cas
(voir Lehmann, 1983, p. 270).
∥

426
8 Admissibilit´e et classes compl`etes
Exemple 8.5. Les estimateurs constants δ0(x) = θ0 sont les estimateurs de
Bayes correspondant `a une masse de Dirac a priori en θ0 et sont presque
toujours admissibles sous des erreurs quadratiques. En fait,
Eθ0(δ(x) −θ0)2 = (Eθ0[δ(x)] −θ0)2 + varθ0(δ(x)) = 0
implique varθ0(δ(x)) = 0 et donc δ(x) = θ0 uniform´ement, `a moins que la
distribution ne soit d´eg´en´er´ee en θ0 (voir l’Exercice 8.4).
∥
La Proposition 8.2 se transpose au cas discret (la d´emonstration est directe
et laiss´ee `a titre d’exercice).
Proposition 8.6. Si Θ est un ensemble discret et si π(θ) > 0 pour tout
θ ∈Θ, alors un estimateur de Bayes associ´e `a π est admissible.
8.2.2 Conditions aux limites
Nous avons vu en Section 3.3 que, si la distribution de x appartient `a une
famille exponentielle
f(x|θ) = h(x)eθ.T (x)−ψ(θ),
les distributions conjugu´ees sont aussi membres de familles exponentielles et
l’esp´erance a posteriori de la moyenne de T (x) est aﬃne en T (x), ce qui signiﬁe
Eπ[∇ψ(θ)|x] = T (x) + t0
λ + 1
=
1
λ + 1T (x) + γ0λ
λ + 1,
(8.1)
avec
π(θ|t0, λ) = eθ.t0−λψ(θ)
et γ0 = t0/λ. Dans le cas o`u θ ∈R et l’espace naturel des param`etres est
N = [θ, ¯θ], Karlin (1958) donne une condition suﬃsante d’admissibilit´e pour
ces estimateurs de la moyenne (voir aussi les Exercices 8.1 et 8.2).
Th´eor`eme 8.7. Si λ > 0, une condition suﬃsante pour que l’estimateur
(8.1) soit admissible sous l’erreur quadratique est que, pour tout θ < θ0 < ¯θ,
 ¯θ
θ0
e−γ0λθ+λψ(θ) dθ =
 θ0
θ
e−γ0λθ+λψ(θ) dθ = +∞.
Ce th´eor`eme est une cons´equence de l’in´egalit´e de Cram´er-Rao (Leh-
mann et Casella, 1998). Il s’agit ´egalement d’un corollaire de la condition
n´ecessaire et suﬃsante de Stein (Section 8.3.3). Berger (1982a) consid`ere la
r´eciproque du Th´eor`eme 8.7 : il montre que, moyennant quelques hypoth`eses
suppl´ementaires, cette condition est aussi n´ecessaire (voir l’Exercice 8.12).

8.2 Admissibilit´e des estimateurs de Bayes
427
Exemple 8.8. (Suite de l’Exemple 8.4) La param´etrisation naturelle de
la distribution du khi deux est
θ = 1
σ2 ,
T (y) = −1
2y,
ψ(θ) = −p
2 log(θ),
et
 c
0
e−γ0λθθ−λp/2 dθ
est inﬁnie si λp ≥2. De mˆeme,
 +∞
c
e−γ0λθθ−λp/2 dθ = +∞
si γ0λ < 0 ou γ0λ = 0 et λp ≤2. Par cons´equent, l’estimateur de Bayes
δπ(y) = γ0λ
1 + λ −
1
1 + λ
y
2
est admissible si γ0 = 0 et λ = 2/p ou γ0 < 0 et λ ≥2/p; ces conditions
sugg`erent les estimateurs
ϕ1(y) =
p
p + 2
−y
2

et
ϕ2(y) = γ0λ
1 + λ +
1
1 + λ
−y
2

,
pour Eσ(−y/2) = −p
2σ2, et donc les estimateurs de Bayes admissibles suivants
pour σ2 :
δ1(y) =
y
p + 2
et
δ2(y) = ay + b,
b > 0, 0 ≤a ≤
1
p + 2.
∥
Exemple 8.9. Soit x ∼B(n, p). La param´etrisation naturelle est donn´ee
par θ = n log(p/q) puisque
f(x|θ) =
n
x

e(x/n)θ 
1 + eθ/n−n
.
Alors les deux int´egrales
 θ0
−∞
e−γ0λθ 
1 + eθ/nλn
dθ
et
 +∞
θ0
e−γ0λθ 
1 + eθ/nλn
dθ
ne peuvent diverger simultan´ement si λ < 0. Consid´erons le cas λ > 0. La
seconde int´egrale diverge en +∞si λ(1 −γ0) > 0, c’est-`a-dire si γ0 < 1. Et
la premi`ere int´egrale diverge en −∞si γ0λ ≥0. On obtient alors une classe
d’estimateurs de Bayes de p admissibles par le Th´eor`eme 8.7 :
δπ(x) = ax
n + b,
0 ≤a ≤1,
b ≥0,
a + b ≤1.
∥

428
8 Admissibilit´e et classes compl`etes
8.2.3 Estimateurs de Bayes g´en´eralis´es inadmissibles
Nous l’avons vu, les estimateurs de Bayes ne sont pas n´ecessairement ad-
missibles ; l’inadmissibilit´e est encore plus courante pour les estimateurs de
Bayes associ´es `a des lois impropres. Le cas particulier o`u le risque de Bayes
d’un estimateur de Bayes associ´e `a une loi impropre est ﬁni (et o`u cet estima-
teur est donc admissible–voir la Proposition 2.37) est relativement rare, sauf
pour les tests et d’autres cadres o`u le coˆut est born´e (voir l’Exemple 2.38), et
on a alors recours `a des techniques plus ´elabor´ees pour prouver l’admissibilit´e,
comme par exemple la condition de Stein (Section 8.3.3).
Exemple 8.10. On consid`ere x ∼Np(θ, Ip) et δ0(x) = x ; δ0 est un estima-
teur de Bayes g´en´eralis´e pour la distribution a priori π(θ) = 1 sous le coˆut
quadratique. L’eﬀet Stein (Note 2.8.2) implique l’admissibilit´e de δ0 si p ≤2
(voir le Corollaire 8.14) et inadmissible sinon.
∥
Exemple 8.11. La distribution a priori employ´ee dans l’Exemple 8.10 peut
g´en´erer des cas d’inadmissibilit´e encore plus extrˆemes. Par exemple, si π(θ) =
1 et si le param`etre d’int´erˆet est η = ||θ||2, l’Exemple 3.32 montre que la dis-
tribution a posteriori de η est une loi du χ2
p(||x||2), ce qui am`ene l’estimateur
de Bayes g´en´eralis´e suivant :
δπ(x) = ||x||2 + p.
Comme nous l’avons d´ej`a vu, cet estimateur est inadmissible et domin´e par
˜δ(x) = (||x||2 −p)+. L’Exemple 3.32 propose une distribution a priori alter-
native qui est plus appropri´ee dans ce contexte.
∥
Exemple 8.12. Soit x ∼G (α, θ) avec α suppos´e connu. Puisque θ est un pa-
ram`etre d’´echelle, π(θ) = 1/θ est une distribution non informative appropri´ee
(voir le Chapitre 9). La distribution a posteriori correspondante est G (α, x)
et donc
δπ(x) = α
x
est l’estimateur de Bayes g´en´eralis´e de θ sous coˆut quadratique. Pour un
estimateur de la forme δc(x) = c/x, le risque quadratique est
R(θ, δc) = Eθ
 c
x −θ
2
= c2Eθ(x−2) −2cθEθ(x−1) + θ2.
Pour α > 2, on a
Eθ(x−2) =
1
Γ(α)
 +∞
0
x−2xα−1θαe−θx dx
=
1
Γ(α)
 +∞
0
θαxα−3e−θx dx
= θ2 Γ(α −2)
Γ(α)
=
θ2
(α −1)(α −2)

8.2 Admissibilit´e des estimateurs de Bayes
429
et
Eθ(x−1) =
1
Γ(α)
 +∞
0
θαxα−2e−θx dx
= θΓ(α −1)
Γ(α)
=
θ
α −1.
On en d´eduit que le meilleur estimateur de la forme δc est associ´e `a
c∗= θEθ(x−1)
Eθ(x−2) =
θ2/(α −1)
θ2/(α −1)(α −2) = α −2,
et donc que δπ est domin´e par δc∗.
∥
Ces trois exemples montrent bien que toutes les situations sont possibles
pour les estimateurs de Bayes g´en´eralis´es, de l’admissibilit´e de x pour p = 1, 2
(Exemple 8.10) `a l’inadmissibilit´e forte des estimateurs des Exemples 8.11 et
8.12, en passant par l’inadmissibilit´e faible67 de x pour p ≥3 (Exemple 8.10).
8.2.4 Repr´esentations diﬀ´erentielles
Pour les familles exponentielles multidimensionnelles, Brown et Hwang
(1982) ont ´etendu le Th´eor`eme 8.7 `a des distributions a priori impropres
arbitraires. Soit une variable al´eatoire
x ∼f(x|θ) = h(x)eθ.x−ψ(θ),
o`u θ et x appartiennent `a Rp. Rappelons que la moyenne de cette distribution
est ∇ψ(θ). ´Etant donn´e une mesure π de densit´e g sur Θ, on suppose que
Ix(∇g) =

||∇g(θ)||eθ.x−ψ(θ) dθ < +∞.
(8.2)
Pour estimer ∇ψ(θ) sous coˆut quadratique, l’estimateur de Bayes g´en´eralis´e
associ´e `a g peut ˆetre repr´esent´e sous une forme diﬀ´erentielle
δg(x) = x + Ix(∇g)
Ix(g) .
(8.3)
Les conditions suivantes sur g permettent d’´etablir l’admissibilit´e de δg :
67En fait, δ0(x) = x reste un estimateur minimax quelle que soit la dimension et
les estimateurs qui dominent δ0 n’am´eliorent δ0 (en termes de risque) de fa¸con si-
gniﬁcative que dans une r´egion relativement restreinte de l’espace d’´echantillonnage
(voir, par exemple, Bondar, 1987). La cons´equence pratique de cette propri´et´e est
que, sans information a priori sur θ, la domination de δ0 a une importance essen-
tiellement formelle.

430
8 Admissibilit´e et classes compl`etes

{||θ||>1}
g(θ)
||θ||2 log2(||θ|| ∨2)dθ < ∞,
(8.4)
 ||∇g(θ)||2
g(θ)
dθ < ∞,
(8.5)
et
∀θ ∈Θ,
R(θ, δg) < ∞.
(8.6)
Th´eor`eme 8.13. Sous les hypoth`eses (8.4), (8.5) et (8.6), l’estimateur (8.3)
est admissible.
La d´emonstration de ce r´esultat repose sur la condition de Blyth, pr´esent´ee
en Section 8.3.2. Elle ne sera donc d´evelopp´ee que dans l’Exemple 8.25. Ce
th´eor`eme a des cons´equences importantes dans la mesure o`u il concerne le cas
de l’estimation des param`etres d’esp´erance pour toutes les familles exponen-
tielles continues sur Rp. Entre autres, un cas particulier est l’obtention de l’ad-
missibilit´e de Stein (1955b) pour toute famille exponentielle. Cela g´en´eralise
aussi Zidek (1970), qui s’int´eressait seulement au cas monodimensionnel (voir
l’Exercice 8.8).
Corollaire 8.14. Si Θ = Rp et p ≤2, l’estimateur δ0(x) = x est admissible.
Preuve. Consid´erons le cas g ≡1, alors ∇g ≡0 et δg(x) = x. Les conditions
(8.4), (8.5) et (8.6) ´etant satisfaites, δg est admissible.
⊓⊔
Exemple 8.15. (Suite de l’Exemple 8.10)
Si x ∼Np(θ, Ip), θ est le
param`etre naturel de la distribution et le r´esultat original de Stein (1955a)
est en fait le Corollaire 8.14. Remarquons que le Th´eor`eme 8.13 propose
´egalement une solution pour tester l’admissibilit´e d’autres estimateurs de
Bayes g´en´eralis´es de θ, notamment ceux qui sont ´etudi´es par Strawderman
(1971, Exercice 10.5) et Berger (1980b).
∥
Exemple 8.16.
Soient x1, x2 deux variables al´eatoires ind´ependantes de
mˆeme loi P(λi) (i = 1, 2). Si θi = log(λi), δ0(x) = (x1, x2) est un esti-
mateur admissible de (λ1, λ2) = (eθ
1, eθ
2). Ce r´esultat n’est pas vrai pour plus
de deux dimensions, comme le montrent Hwang (1982a) et Johnstone (1984).
∥
Brown et Hwang (1982) pr´esentent plusieurs g´en´eralisations du Th´eor`eme
8.13, couvrant des cas o`u Θ ̸= Rp, comme les distributions gamma et
g´eom´etrique. Ils d´emontrent ´egalement que, dans le cas particulier de p ob-
servations xi issues de distributions de Poisson ind´ependantes, P(λi), l’esti-
mateur de Bayes g´en´eralis´e

8.2 Admissibilit´e des estimateurs de Bayes
431
δCZ(x) =

1 −
β + p −1
β + p −1 + S

x,
avec S = 
i xi, propos´e par Clevenson et Zidek (1975) pour am´eliorer x =
(x1, . . . , xp), est admissible pour β > 0 et p ≥2 avec la fonction de coˆut
L(θ, δ) =
p

i=1
1
λi
(δ −λi)2.
Das Gupta et Sinha (1986) donnent aussi des conditions suﬃsantes d’admis-
sibilit´e pour l’estimation de moyennes de lois gamma ind´ependantes.
8.2.5 Conditions de r´ecurrence
Lorsqu’on se restreint au cas d’une distribution normale multidimension-
nelle Np(θ, Σ), avec Σ connu, Brown (1971) parvient `a donner une ca-
ract´erisation plus pr´ecise des estimateurs de Bayes admissibles sous coˆut
quadratique par le biais d’une condition n´ecessaire et suﬃsante, grˆace `a une
repr´esentation markovienne du probl`eme d’estimation. (Ajoutons que Shino-
zaki, 1975, ´etablit que le choix Σ = Ip se fait sans perte de g´en´eralit´e, voir la
Section 2.5.1 et Exercice 2.39.)
Th´eor`eme 8.17. Soit x ∼Np(θ, Ip). Un estimateur de Bayes g´en´eralis´e de
la forme
δ(x) = (1 −h(||x||))x
est
(i) inadmissible s’il existe ϵ > 0 et K < +∞tels que, pour ||x|| > K,
||x||2h(||x||) < p −2 −ϵ;
et
(ii) admissible s’il existe K1 et K2 tels que h(||x||)||x|| ≤K1 pour tout x
et, pour ||x|| > K2,
||x||2h(||x||) ≥p −2.
La d´emonstration de ce r´esultat est assez diﬃcile. Le raisonnement condui-
sant `a (i) et (ii) inclut la preuve de la r´ecurrence ou de la transience d’un
processus al´eatoire68 associ´e `a δ. (Voir Srinivasan, 1981, pour une descrip-
tion simpliﬁ´ee.) La partie (i) peut aussi ˆetre vue comme une cons´equence du
Lemme 8.38 ci-dessous. Remarquons la pr´esence du facteur (p −2), qui indi-
quait d´ej`a la limite entre admissibilit´e et inadmissibilit´e de l’estimateur usuel
68Les marches al´eatoires sont g´en´eralement r´ecurrentes en dimension 1 ou 2 et
transientes dans des dimensions plus grandes (voir Feller, 1971, ou Meyn et Tweedie,
1994). Le lien ´etabli par Brown (1971) prouve que le fait que p = 3 soit un cas limite
dans les deux probl`emes n’est pas une co¨ıncidence.

432
8 Admissibilit´e et classes compl`etes
δ0(x) = x. La relation entre ce r´esultat et le ph´enom`ene de Stein est d´etaill´ee
en Section 8.5.
Johnstone (1984) donne un ´equivalent du Th´eor`eme 8.17 pour le mod`ele
de Poisson. Si xi ∼P(λi) (i = 1, . . . , p), le param`etre λ = (λ1, . . . , λp) est
estim´e sous le coˆut
p

i=1
1
λi
(δi −λi)2.
Alors :
Th´eor`eme 8.18. Un estimateur de Bayes g´en´eralis´e de la forme
δ(x) = (1 −h(s))x,
avec s = 
i xi, est
(i) inadmissible s’il existe ϵ > 0 et K < +∞tels que, pour s > K,
sh(s) < (p −1 −ϵ);
et
(ii) admissible s’il existe K1 et K2 tels que √s h(s) ≤K1 pour tout s et,
pour s > K2,
sh(s) ≥(p −1).
Eaton (1992) dresse des parall`eles similaires `a ceux d´ecrits par Brown
(1971) entre l’admissibilit´e d’un estimateur et la r´ecurrence d’une chaˆıne de
Markov associ´ee. Nous citons ci-dessous les principaux r´esultats de cet ar-
ticle mais encourageons les lecteurs `a le consulter non seulement pour les
d´emonstrations compl`etes, mais aussi pour les d´eveloppements int´eressants
sur les cons´equences de ces r´esultats. Le probl`eme consid´er´e par Eaton (1992)
est de chercher si, pour une fonction born´ee g(θ), un estimateur de Bayes
g´en´eralis´e associ´e `a une mesure a priori π est admissible sous coˆut quadra-
tique. En supposant que la distribution a posteriori π(θ|x) soit bien d´eﬁnie,
nous consid´erons le noyau de transition
K(θ|η) =

X
π(θ|x)f(x|η) dx,
(8.7)
associ´e `a la chaˆıne de Markov (θ(n)) d´eﬁnie comme suit. La transition de θ(n)
`a θ(n+1) correspond d’abord `a la simulation de x ∼f(x|θ(n)), puis `a celle
de θ(n+1) ∼π(θ|x). (Concernant l’utilisation de ce noyau dans des m´ethodes
de Monte Carlo par chaˆınes de Markov et pour de plus amples d´etails sur
la th´eorie des chaˆınes de Markov, voir le Chapitre 6.) Pour tout ensemble
mesurable C tel que π(C) < +∞, on d´eﬁnit :
V (C) =

h ∈L 2(π); h(θ) ≥0 et h(θ) ≥1 lorsque θ ∈C

et

8.3 Conditions n´ecessaires et suﬃsantes d’admissibilit´e
433
Δ(h) =
 
{h(θ) −h(η)}2 K(θ|η)π(η) dθ dη.
Le r´esultat suivant permet alors de caract´eriser l’admissibilit´e pour toute fonc-
tion born´ee en fonction de Δ et V (C) et donc ind´ependamment des fonctions
estim´ees g :
Th´eor`eme 8.19. Si, pour tout C tel que π(C) < +∞,
inf
h∈V (C) Δ(h) = 0,
(8.8)
alors l’estimateur de Bayes Eπ[g(θ)|x] est admissible sous coˆut quadratique
pour toute fonction born´ee g.
Ce r´esultat est naturellement assez g´en´eral, mais n’est que mod´er´ement
utile dans la mesure o`u la v´eriﬁcation pratique de (8.8) pour tout ensemble
C peut ˆetre tr`es lourde. Il faut ´egalement noter que (8.8) est toujours vraie
lorsque π est une distribution a priori propre, puisque h ≡1 appartient `a
L 2(π) et Δ(1) = 0 dans ce cas. L’extension aux lois a priori impropres s’ap-
puie sur des approximations de 1 par des fonctions de V (C). (Voir le Chapitre
9 pour un lien analogue entre diﬃcult´es de calcul et minimaxit´e.) Eaton (1992)
donne une condition ´equivalente au Th´eor`eme 8.19 en s’appuyant sur la chaˆıne
de Markov (θ(n)). Pour un ensemble donn´e C, une condition d’arrˆet σC est
d´eﬁnie comme le premier entier n > 0 tel que (θ(n)) appartienne `a C (et +∞
sinon). On dit que la chaˆıne (θ(n)) est π-r´ecurrente si la probabilit´e que σC
soit ﬁnie vaut 1 pour π-presque tout point de d´epart θ(0).
Th´eor`eme 8.20. Pour tout ensemble C tel que π(C) < +∞,
inf
h∈V (C) Δ(h) =

C
%
1 −P(σC < +∞|θ(0) = η)
&
π(η) dη.
Par cons´equent, les estimateurs de Bayes g´en´eralis´es de fonctions born´ees de
θ sont admissibles si la chaˆıne de Markov associ´ee (θ(n)) est π-r´ecurrente.
Des extensions, exemples et commentaires sur ce r´esultat se trouvent dans
la Note 8.7.1 et dans Eaton (1992, 1999). Son int´erˆet essentiel, outre son
´el´egance math´ematique, est que la v´eriﬁcation de la r´ecurrence de la chaˆıne
de Markov (θ(n)) est beaucoup plus ais´ee que la d´etermination de la borne
inf´erieure de Δ(h). De plus, ce th´eor`eme permet d’obtenir une v´eriﬁcation
num´erique d’admissibilit´e en simulant une chaˆıne (θ(n)), ce qui rappelle la
v´eriﬁcation num´erique de minimaxit´e propos´ee par Berger et Robert (1990).
8.3 Conditions n´ecessaires et suﬃsantes d’admissibilit´e
Les r´esultats pr´esent´es dans la section pr´ec´edente ne concernent que les
estimateurs de Bayes g´en´eralis´es. En outre, certaines conditions sont tr`es dif-
ﬁciles `a v´eriﬁer–on pense notamment `a (8.4) ou (8.5). Nous introduisons dans

434
8 Admissibilit´e et classes compl`etes
cette section une condition g´en´erale n´ecessaire et suﬃsante d’admissibilit´e qui
n’exige pas que les estimateurs soient de Bayes g´en´eralis´es. Elle formalise en
quelque sorte l’aﬃrmation d´ej`a ´enonc´ee que “les estimateurs admissibles sont
des limites d’estimateurs de Bayes....”. Une premi`ere version de la condition
de Stein concerne uniquement les estimateurs `a risque continu ; dans la Section
8.3.1, nous expliquons pourquoi il est g´en´eralement suﬃsant de ne consid´erer
que ceux-ci.
8.3.1 Risques continus
Il est souvent n´ecessaire de restreindre le cadre d’´etude aux estimateurs `a
fonctions de risque continues pour obtenir une condition suﬃsante d’admissi-
bilit´e. Toutefois, dans certains cas, tous les estimateurs sont `a risque continu.
Dans d’autres situations, les estimateurs admissibles sont n´ecessairement `a
risque continu.
Lemme 8.21. Soit Θ ⊂Rm. La fonction de coˆut L(θ, δ) est suppos´ee born´ee
et continue en θ pour tout δ ∈D. Si f(x|θ) est continue en θ pour tout x, la
fonction de risque de tout estimateur est continue.
Preuve. ´Etant donn´e un estimateur δ, la diﬀ´erence des risques en θ et θ′ ∈Θ
est
|R(θ, δ) −R(θ′, δ)| =


L(θ, δ(x))f(x|θ) dx −

L(θ′, δ(x))f(x|θ′) dx

≤
 L(θ, δ(x)) −L(θ′, δ(x))
f(x|θ) dx
+


L(θ, δ(x))(f(x|θ) −f(x|θ′)) dx
.
Puisque L est continue et born´ee par C, il existe η0 > 0 et un ensemble
compact K0 tels que

Kc
0
f(x|θ) dx <
ϵ
8C
et

K0
L(θ, δ(x)) −L(θ′, δ(x))
f(x|θ) dx < ϵ
4
avec ||θ −θ′|| < η0. Ainsi,
 L(θ, δ(x)) −L(θ′, δ(x))
f(x|θ) dx < ϵ
2.
De plus, f(x|θ) ´etant une fonction continue de θ, un argument ´equivalent
permet d’´ecrire qu’il existe η1 > 0 et un ensemble compact K1 tels que


L(θ, δ(x))(f(x|θ) −f(x|θ′)) dx
 ≤C

K1
f(x|θ) −f(x|θ′)
 dx
+ C

Kc
1
[f(x|θ) + f(x|θ′)] dx < ϵ
2

8.3 Conditions n´ecessaires et suﬃsantes d’admissibilit´e
435
et

Kc
1
f(x|θ) dx <
ϵ
8C ,
avec ||θ −θ′|| < η1. Donc R(θ, δ) est continue.
⊓⊔
L’int´erˆet du Lemme 8.21 est plus ou moins limit´e puisque les probl`emes
d’admissibilit´e les plus diﬃciles concernent justement les cas o`u L n’est pas
born´ee. Dans certains contextes, on peut cependant r´eduire la classe des es-
timateurs `a consid´erer `a la classe des estimateurs `a risque continu. On parle
de caract´erisation de classe compl`ete.
D´eﬁnition 8.22. Une classe C d’estimateurs est dite compl`ete si, quel que
soit δ′ ̸∈C , il existe δ ∈C qui domine δ′. La classe est essentiellement
compl`ete si, quel que soit δ′ ̸∈C , il existe δ ∈C au moins aussi bon que δ′.
Si on excepte les cas triviaux comme celui de la classe de tous les estima-
teurs, il n’est pas toujours possible de d´eterminer des classes compl`etes utiles.
Par exemple, il existe des cas, bien que rares, o`u la classe des estimateurs
admissibles n’est pas une classe compl`ete (voir Blackwell et Girshick, 1954,
Th´eor`eme 5.7.1, ou Brown, 1976). La Section 8.4 analyse les relations entre
les estimateurs de Bayes, les estimateurs de Bayes g´en´eralis´es et les classes
compl`etes. Le r´esultat suivant est un lemme de classe compl`ete ´enon¸cant des
conditions suﬃsantes pour n’avoir `a consid´erer que les estimateurs `a risque
continu.
Lemme 8.23. Soit un mod`ele de d´ecision statistique X , Θ ⊂R avec un
espace de d´ecision ferm´e D ⊂R. On suppose que f(x|θ) v´eriﬁe la propri´et´e
de rapport de vraisemblances monotone et est continue en θ. Si
(i) L(θ, d) est une fonction continue de θ pour tout d ∈D ;
(ii) L est d´ecroissante en d pour d < θ et croissante pour d > θ ; et
(iii) il existe deux fonctions K1 et K2 born´ees sur les sous-ensembles compacts
de Θ, telles que
L(θ1, d) ≤K1(θ1, θ2)L(θ2, d) + K2(θ1, θ2),
alors les estimateurs `a risque ﬁni et continu forment une classe compl`ete.
Voir Ferguson (1967) et Brown (1976) pour d’autres r´esultats. Par exemple,
il est possible de montrer que si le probl`eme est monotone, alors les estima-
teurs monotones constituent une classe compl`ete (Exercice 8.23 et Th´eor`eme
5.43).

436
8 Admissibilit´e et classes compl`etes
8.3.2 Condition suﬃsante de Blyth
Avant que Stein (1955b) n’´etablisse sa condition n´ecessaire et suﬃsante
(Section 8.3.3), Blyth (1951) propose une condition suﬃsante d’admissibilit´e,
qui fait un lien entre l’admissibilit´e d’un estimateur et l’existence d’une suite
de distributions a priori approchant cet estimateur.
Th´eor`eme 8.24. Soit un ensemble ouvert non vide Θ ⊂Rp. On suppose
que les estimateurs `a risque continu forment une classe compl`ete. Si, pour
un estimateur `a risque continu δ0, il existe une suite (πn) de distributions a
priori g´en´eralis´ees telles que
(i) r(πn, δ0) est ﬁni quel que soit n ;
(ii) pour tout ensemble ouvert non vide C ⊂Θ, il existe K > 0 et N tels que,
pour tout n ≥N, πn(C) ≥K ; et
(iii)
lim
n→+∞r(πn, δ0) −r(πn) = 0 ;
alors l’estimateur δ0 est admissible.
Preuve. Si δ0 n’est pas admissible, il existe un estimateur δ′ dominant δ0,
c’est-`a-dire tel que R(θ, δ) −R(θ, δ′) ≥0 et
R(θ, δ) −R(θ, δ′) > ϵ
sur un ensemble ouvert C ⊂Θ (pour ϵ suﬃsamment petit). Il d´ecoule ensuite
des hypoth`eses (i) et (ii), que, pour n ≥N,
r(πn, δ0) −r(πn) ≥r(πn, δ0) −r(πn, δ′)
= Eπ[R(θ, δ0) −R(θ, δ′)]
≥

C
(R(θ, δ0) −R(θ, δ′))πn(θ) dθ
≥ϵ

C
πn(θ) dθ ≥ϵK.
⊓⊔
Ce r´esultat est utile pour ´etablir l’admissibilit´e d’estimateurs de Bayes
g´en´eralis´es, puisque les mesures π associ´ees `a ces estimateurs peuvent s’´ecrire
comme des limites de suites de distributions propres πn. Cela dit, le choix de
telles suites n’est pas toujours ´evident, comme le montrent Berger (1982a) ou
Brown et Hwang (1982). Le Th´eor`eme 8.24 s’applique ´egalement `a d’autres
estimateurs, dans des contextes o`u il existe des estimateurs admissibles qui
ne sont pas de Bayes g´en´eralis´es (voir la Section 8.4).
Exemple 8.25. La preuve du Th´eor`eme 8.13 est une premi`ere illustration
de la condition de Blyth. Soit hn `a valeurs dans [0, 1], d´erivable et telle que
hn(θ) = 0 si ||θ|| > n et hn(θ) = 1 sur un ensemble S v´eriﬁant

8.3 Conditions n´ecessaires et suﬃsantes d’admissibilit´e
437

S
g(θ) dθ > 0.
Nous d´eﬁnissons `a pr´esent une suite de mesures associ´ees de densit´es gn(θ) =
h2
n(θ)g(θ) et les estimateurs de Bayes correspondants δn. En repassant `a la
notation Ix(.) adopt´ee en (8.2), la diﬀ´erence des risques de Bayes int´egr´es est
r(πn, δg) −r(πn) =

||δg(x) −δn(x)||2Ix(gn) dx
=
 ;;;;
Ix(∇g)
Ix(g) −Ix(h2
n∇g)
Ix(gn)
−Ix(g∇hn)
Ix(gn)
;;;;
2
Ix(gn) dx,
avec la notation de (8.3). Par cons´equent,
r(πn, δg) −r(πn) ≤2
 ;;;;
Ix(∇g)
Ix(g) −Ix(h2
n∇g)
Ix(gn)
;;;;
2
Ix(gn) dx
+2
 ;;;;
Ix(g∇hn)
Ix(gn)
;;;;
2
Ix(gn) dx
= Bn + An.
Le second terme, An, admet pour borne sup´erieure
4

||∇hn(θ)||2g(θ) dθ.
Dans le cas particulier
hn(θ) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
1
pour ||θ|| < 1,
1 −log(||θ||)
log(n)
pour 1 < ||θ|| < n,
0
sinon,
on obtient en fait
||∇hn(θ)||2 ≤
1
||θ||2 log2(max(||θ||, 2))I||θ||>1(θ) ,
et la condition (8.4) implique que An converge vers 0 quand n tend vers l’inﬁni.
Le premier terme satisfait
Bn =
 ;;;;Ix

gn
Ix(∇g)
Ix(g) −h2
n∇g
;;;;
2 '
(Ix(gn)) dx
=
 ;;;;Ix

gn
Ix(∇g)
Ix(g) −∇g
g
;;;;
2 '
(Ix(gn)) dx
≤

Ix

g
;;;;
Ix(∇g)
Ix(g) −∇g
g
;;;;
2 
dx.

438
8 Admissibilit´e et classes compl`etes
En utilisant (8.5), on obtient par le th´eor`eme de convergence domin´ee que
Bn a pour limite 0, puisque gn tend vers g. Ceci ach`eve la d´emonstration du
Th´eor`eme 8.13.
∥
En pratique, une m´ethode typique d’utilisation de la condition de Blyth
pour un estimateur de Bayes g´en´eralis´e, δ0, est de construire une suite d’es-
timateurs de Bayes propres qui tend vers δ0, puis de “d´enormaliser” la suite
de distributions a priori associ´ees par un poids ad´equat.
Exemple 8.26. On consid`ere x ∼N (θ, 1) et δ0(x) = x, un estimateur de θ.
Parce que δ0 correspond `a π(θ) = 1 sous coˆut quadratique, nous choisissons
pour mesure πn avec une densit´e
gn(x) = e−θ2/2n,
c’est-`a-dire la densit´e d’une distribution normale N (0, n) sans le facteur de
normalisation 1/
√
2πn. Comme les densit´es gn sont croissantes en n, la condi-
tion (ii) du Th´eor`eme 8.24 est satisfaite, ainsi que (i) : l’estimateur de Bayes
pour πn est toujours
δn(x) =
nx
n + 1,
puisque l’absence du facteur de normalisation n’a pas de cons´equence directe
dans ce cas, et
r(πn) =

R

θ2
(n + 1)2 +
n2
(n + 1)2

gn(θ) dθ
=
√
2πn
n
n + 1,
ainsi que
r(πn, δ0) =

R
1 gn(θ) dθ =
√
2πn.
Les deux risques sont donc ﬁnis. De plus,
r(πn, δ0) −r(πn) =
√
2πn/(n + 1)
tend vers 0. La condition de Blyth fournit donc une autre preuve d’admissibi-
lit´e de δ0(x) = x dans le cas normal. En revanche, la preuve d’admissibilit´e de
δ0 en dimension deux requiert une suite plus compliqu´ee (voir Stein, 1955a).
∥
Exemple 8.27. Soit x ∼B(m, θ). Le probl`eme d’inf´erence est de tester
l’hypoth`ese nulle H0 : θ ≤θ0 sous la fonction de coˆut quadratique d´ecrite en
Section 5.4,

8.3 Conditions n´ecessaires et suﬃsantes d’admissibilit´e
439
	
I[0,θ0](θ) −γ(x)

2 .
La p-value est alors
ϕ(x) = Pθ0(X ≥x) =
m

k=x
m
k

θk
0(1 −θ0)m−k.
Les distributions conjugu´ees naturelles sont ici des distributions bˆeta. L’id´ee
est donc d’approcher ϕ(x) par une suite d’estimateurs associ´ee `a une suite de
distributions bˆeta convenablement choisies. En fait, ϕ(x) peut s’´ecrire (pour
x ̸= 0)
ϕ(x) =
1
B(x, m −x + 1)
 θ0
0
tx−1(1 −t)m−x dt = P(T ≤θ0|x)
lorsque T ∼Be(x, m −x + 1), ce qui correspond `a la distribution a priori
g´en´eralis´ee
π(θ) = θ−1
(0 < θ < 1).
On consid`ere πn de densit´e
gn(θ) = θαn−1
sur [0, 1] avec la suite (αn) qui d´ecroˆıt vers 0. Dans ce cas, la proc´edure
bay´esienne classique est
γπn(x) = P πn(θ ≤θ0|x) =
1
B(x + αn, m −x + 1)
 θ0
0
tx+αn−1(1 −t)m−x dt
et
r(πn) =
m

k=0
B(k + αn, m −k + 1)γπn(k)(1 −γπn(k)),
r(πn, ϕ) =
m

k=0
B(k + αn, m −k + 1)(γπn(k) −2γπnϕ(k) + ϕ2(k)).
On en d´eduit que
r(πn, ϕ) −r(πn) =
m

k=0
B(k + αn, m −k + 1)(γπn(k) −ϕ(k))2.
Si k ̸= 0, on v´eriﬁe sans diﬃcult´e que
lim
αn→0(ϕ(k) −γπn(k))2 = 0.
De mˆeme, on a

440
8 Admissibilit´e et classes compl`etes
lim
α→0
 θ0
0 tα−1(1 −t)m−1dt
 1
0 tα−1(1 −t)m−1dt
= 1 ,
pour le cas k = 0. En outre, la condition (ii) est ´egalement satisfaite. La p-
value ϕ est alors admissible dans ce cadre. L’Exemple 5.45 donne une preuve
plus directe de ce r´esultat tirant proﬁt du fait que le risque de Bayes est ﬁni.
∥
Les Exemples 8.25 et 8.27 illustrent un r´esultat g´en´eral : sous coˆut quadra-
tique, la condition (iii) du Th´eor`eme 8.24 implique la convergence quadratique
des estimateurs de Bayes vers δ0 au sens des mesures marginales.
Proposition 8.28. Si L est une fonction de coˆut quadratique et s’il existe
une suite (πn) v´eriﬁant les conditions (i), (ii) et (iii) du Th´eor`eme 8.24, alors
les estimateurs de Bayes δπn tendent quadratiquement vers δ0 pour les mesures
marginales
mn(x) =

Θ
f(x|θ)πn(θ) dθ.
Preuve. La diﬀ´erence des risques s’´ecrit naturellement
r(πn, δ0) −r(πn)
=

X

Θ
(||δ0(x) −θ||2 −||δπn(x) −θ||2)πn(θ|x) dθ mn(x) dx
=

X

||δ0(x) −δπn(x)||2
+ 2(δ0(x) −δπn(x)) ·

Θ
(δπn(x) −θ)πn(θ|x) dθ

mn(x) dx
=

X
||δ0(x) −δπn(x)||2mn(x) dx,
puisque

Θ
(δπn(x) −θ)πn(θ|x) dθ = 0.
⊓⊔
Malheureusement, ce r´esultat de convergence d´epend de la suite (mn),
sauf s’il est possible d’´etablir une ´equivalence uniforme avec la mesure de
Lebesgue, ou une autre mesure ﬁx´ee, auquel cas il y a convergence quadratique
au sens classique. C’est par exemple ce qui se passe lorsque la suite (mn)
est croissante, comme dans les Exemples 8.25, 8.26 et 8.27. La Section 8.3.4
d´ecrit un r´esultat plus fondamental dˆu `a Brown (1986b), qui montre que la
convergence ponctuelle des δπn vers δ0, ind´ependamment des mesures mn, est
en r´ealit´e n´ecessaire.

8.3 Conditions n´ecessaires et suﬃsantes d’admissibilit´e
441
8.3.3 Condition n´ecessaire et suﬃsante de Stein
Les compl´ements apport´es par Stein (1955b) et Farrell (1968a) `a la condi-
tion pr´ec´edente permettent de d´eduire un r´esultat encore plus important que
le Th´eor`eme 8.24, puisqu’il ´etablit que tous les estimateurs admissibles sont
des limites de suites d’estimateurs de Bayes (au sens du risque de Bayes). Les
hypoth`eses de Farrell (1968a) sont
(i) f(x|θ) est continu en θ et strictement positive sur Θ ; et
(ii) le coˆut L est strictement convexe, continu et, si E ⊂Θ est compact,
lim
∥δ∥→+∞inf
θ∈E L(θ, δ) = +∞.
Remarquons que cette seconde hypoth`ese ´elimine n´ecessairement les fonctions
de coˆut born´ees.
Th´eor`eme 8.29. Sous les hypoth`eses (i) et (ii), un estimateur δ est admis-
sible si et seulement si il existe une suite (Fn) d’ensembles compacts croissants
tels que Θ = <
n Fn, une suite (πn) de mesures ﬁnies de supports Fn et une
suite (δn) d’estimateurs de Bayes associ´es `a πn tels que
(i) il existe un ensemble compact E0 ⊂Θ tel que infn πn(E0) ≥1 ;
(ii) si E ⊂Θ est compact, supn πn(E) < +∞;
(iii) limn r(πn, δ) −r(πn) = 0 ; et
(iv) limn R(θ, δn) = R(θ, δ).
De ce th´eor`eme fondamental d´ecoulent la plupart des r´esultats d’admissi-
bilit´e et de classe compl`ete pr´esent´es en Section 8.4. Une d´emonstration du
Th´eor`eme 8.29 d´epasse le cadre de ce livre ; voir Farrell (1968a). La suﬃsance
est li´ee `a la condition de Blyth, mais la r´eciproque n´ecessaire permet d’exclure
de nombreux estimateurs inadmissibles.
8.3.4 Un autre th´eor`eme limite
Brown (1986b) donne une caract´erisation alternative, assez g´en´erale, des
estimateurs admissibles. Soit x ∼f(x|θ), avec f(x|θ) > 0. On suppose que D
est un ensemble ferm´e convexe. De plus, on suppose que la fonction de coˆut
L est semi-continue inf´erieurement et telle que
lim
||δ||→+∞L(θ, δ) = +∞.
(Cela correspond plus ou moins `a l’hypoth`ese (ii) de Farrell, 1968a.) Le
r´esultat principal de Brown (1986b) consiste `a montrer que, sous ces hy-
poth`eses, l’adh´erence (au sens de la convergence ponctuelle) de l’ensemble

442
8 Admissibilit´e et classes compl`etes
des estimateurs de Bayes est une classe compl`ete. Le r´esultat de convergence
qui suit reformule cette propri´et´e (voir Brown, 1986b, p. 254-267).
Proposition 8.30. Si L est strictement convexe, tout estimateur admissible
de θ est une limite ponctuelle d’estimateurs de Bayes pour une suite de dis-
tributions a priori `a supports ﬁnis.
Ce r´esultat est `a comparer aux r´esultats de Dalal et Hall (1983) et Diaconis
et Ylvisaker (1985), pr´esent´es en Section 3.4 et qui montrent que, pour une
famille exponentielle, toute distribution a priori est une limite de m´elanges
de distributions a priori conjugu´ees. Par cons´equent, pour les familles ex-
ponentielles, un estimateur admissible est aussi la limite d’estimateurs de
Bayes associ´es `a un m´elange de distributions a priori conjugu´ees. Lorsque le
mod`ele est invariant par transformation sph´erique, les distributions `a support
ﬁni peuvent ˆetre remplac´ees par des distributions sur des sph`eres imbriqu´ees,
puisque celles-ci pr´eservent la sym´etrie. Dans ce cas, si πc est la distribution
uniforme sur la sph`ere de rayon c,
Sc = {θ; ||θ|| = c},
et si δc est l’estimateur de Bayes associ´e sous coˆut quadratique, c’est-`a-dire la
moyenne a posteriori, Robert (1990) d´erive le th´eor`eme limite suivant.
Proposition 8.31. Si x ∼Np(θ, Ip) et si π est une distribution a priori `a
sym´etrie sph´erique de centre 0, alors il existe deux suites, (qi
n) et (ci
n), telles
que n
i=1 qi
n = 1 et
mπ(x) =

Rp f(x|θ)π(θ) dθ =
lim
n→+∞
n

i=1
qi
nmcin(x),
avec
mcin =

Rp f(x|θ)πcin(θ) dθ.
De plus, sous coˆut quadratique,
δπ(x) =
lim
n→+∞
n

i=1
qi
nmcin(x)

j qj
nmcj
n(x)
δcin(x).
(8.9)
Par cons´equent, dans le cas normal, tout estimateur de Bayes associ´e `a
une distribution a priori `a sym´etrie sph´erique est une limite ponctuelle d’es-
timateurs de Bayes associ´es `a des distributions uniformes sur des sph`eres. On
rappelle que les estimateurs δc peuvent s’´ecrire
δc(x) = c
Ip/2(||x||c)
Ip/2−1(||x||c)
x
||x||,
(8.10)
o`u Iν est la fonction de Bessel modiﬁ´ee (Exercices 4.36 et 4.37). Une cons´e-
quence ´etablie par Kempthorne (1988) est en fait que tout estimateur admis-
sible δ(x) peut ˆetre ´ecrit sous la forme (8.10) ou alors il existe un estimateur

8.4 Classes compl`etes
443
δ′ de la forme (8.10) ´equivalent `a δ (en termes de risque).
8.4 Classes compl`etes
Nous venons de voir dans un cadre g´en´eral que les estimateurs admissibles
peuvent ˆetre consid´er´es comme des limites d’estimateurs de Bayes de plu-
sieurs points de vue. Dans certains cas particuliers, il est possible de d´ecrire
plus pr´ecis´ement ces estimateurs admissibles et de montrer qu’ils sont des es-
timateurs de Bayes g´en´eralis´es. L’int´erˆet de ces r´esultats est multiple. D’une
part, ils permettent de r´eduire la classe des estimateurs `a consid´erer. D’autre
part, ils illustrent l’avantage de ne faire appel qu’`a des estimateurs de Bayes
ou de Bayes g´en´eralis´es d’un point de vue fr´equentiste. Cela concerne, par
exemple, le cas de l’´evaluation de proc´edures de test sous coˆut quadratique,
vue en Section 5.4 (Th´eor`emes 5.42 et 5.43). Cette section donne des r´esultats
analogues pour l’estimation ponctuelle. On trouvera d’autres r´ef´erences dans
Brown (1986b) et Rukhin (1995).
En guise d’introduction, consid´erons l’exemple tr`es simple o`u Θ = {θ1, θ2},
qui a l’avantage de permettre une repr´esentation graphique de l’ensemble de
risque,
R = {r = (R(θ1, δ), R(θ2, δ)), δ ∈D∗},
en notant D∗l’ensemble des estimateurs randomis´es. On suppose que l’en-
semble de risque R est born´e et ferm´e inf´erieurement, c’est-`a-dire tel que tous
les risques sur la fronti`ere inf´erieure de R appartiennent `a R et ont des com-
posantes ﬁnies. Cette hypoth`ese est v´eriﬁ´ee lorsque le coˆut est positif. Cette
fronti`ere inf´erieure, que nous noterons Γ(R), est importante dans la mesure
o`u elle contient en fait les points admissibles de R. En eﬀet, si r ∈Γ(R), il
ne peut exister r′ ∈R tel que r′
1 ≤r1 et r′
2 ≤r2 avec in´egalit´e stricte sur l’un
des deux axes. Par ailleurs, pour tout r ∈Γ(R), il existe une tangente `a R
passant par r, avec une pente positive et d’´equation
p1r1 + p2r2 = k,
c’est-`a-dire telle que tout r′ ∈R v´eriﬁe p1r′
1 + p2r′
2 ≥k, ce que montre la
Figure 8.1. (Il s’agit en r´ealit´e d’une cons´equence de la convexit´e de R.) Cette
propri´et´e implique que r est un estimateur de Bayes pour la distribution a
priori π(θi) = pi (i = 1, 2), puisqu’il minimise le risque de Bayes p1r1 + p2r2.
On en d´eduit le r´esultat g´en´eral suivant.
Proposition 8.32. Si Θ est ﬁni et si l’ensemble de risque R est born´e et
ferm´e inf´erieurement, alors l’ensemble des estimateurs de Bayes forme une
classe compl`ete.
Cette caract´erisation repose sur le th´eor`eme de l’hyperplan s´eparateur puis-
que, sous les hypoth`eses du th´eor`eme, il existe un hyperplan tangent `a l’en-
semble de risque pour tout point de la fronti`ere inf´erieure et que cet hy-
perplan d´eﬁnit une distribution a priori sur Θ par dualit´e. L’extension de

444
8 Admissibilit´e et classes compl`etes
0.10
0.15
0.20
0.25
0.30
0.35
0.40
0.45
0.2
0.3
0.4
0.5
0.6
0.7
δ1
δ2
δ3
δ4
δ5
δ6
δ7
δ8
δ9
Γ
Fig. 8.1. Ensemble de risque et estimateurs admissibles pour Θ = {θ1, θ2}.
ce r´esultat de classe compl`ete `a des espaces de param`etres Θ d´enombrables
et non d´enombrables n´ecessite une g´en´eralisation ´equivalente des th´eor`emes
d’hyperplan s´eparateur aux espaces de fonctions sur Θ. Par exemple, Brown
(1976) donne le r´esultat suivant, en notant ˚S l’int´erieur de S.
Lemme 8.33. Soit S un sous-ensemble convexe d’un espace vectoriel topo-
logique E . Si ˚S ̸= ∅et y0 ̸∈˚S, il existe f ∈E ∗telle que S soit incluse dans
{y; f(y) ≥f(y0)}.
On d´eduit de ce lemme le r´esultat de classe compl`ete suivant, dˆu `a Wald
(1950) et qui g´en´eralise la Proposition 8.32.
Th´eor`eme 8.34. On suppose que Θ est compact et que l’ensemble de risque
R est convexe. Si tous les estimateurs ont une fonction de risque continue,
les estimateurs de Bayes constituent une classe compl`ete.
Preuve.
Ce r´esultat est bien une cons´equence du Lemme 8.33 puisque, si δ0
est admissible, la fonction de risque R(θ, δ0) appartient `a la fronti`ere inf´erieure
de l’ensemble de risque. Par cons´equent, il existe une fonction lin´eaire sur R,
ψ∗, telle que, pour tout estimateur δ,
ψ∗(R(·, δ)) ≥ψ∗(R(·, δ0)).
Il vient alors du th´eor`eme de repr´esentation de Riesz qu’il existe une mesure
ﬁnie π sur Θ telle que
ψ∗(R(·, δ)) =

Θ
R(θ, δ)π(θ)dθ,

8.4 Classes compl`etes
445
et que cette mesure peut ˆetre renormalis´ee ainsi ˜π(θ) = π(θ)/π(Θ), d´eﬁnissant
par l`a-mˆeme une distribution a priori. L’in´egalit´e ci-dessus devient donc

R(θ, δ)˜π(θ) dθ ≥

R(θ, δ0)˜π(θ) dθ
et entraˆıne que δ0 est un estimateur de Bayes pour ˜π.
⊓⊔
Dans le cas o`u Θ n’est pas compact, nous avons d´ej`a vu des exemples o`u les
estimateurs de Bayes ne peuvent former une classe compl`ete. Ainsi, lorsqu’on
s’int´eresse `a la moyenne θ d’une variable al´eatoire normale x ∼N (θ, 1),
l’estimateur δ(x) = x est admissible mais n’est pas un estimateur de Bayes.
Cela dit, dans bien des cas, les classes compl`etes sont tout de mˆeme constitu´ees
d’estimateurs de Bayes g´en´eralis´es (en regroupant, bien sˆur, les estimateurs
de Bayes et de Bayes g´en´eralis´es). Par exemple, Berger et Srinivasan (1978)
d´emontrent, dans le cadre de l’estimation du param`etre naturel θ d’une famille
exponentielle
x ∼f(x|θ) = eθ·x−ψ(θ)h(x),
x, θ ∈Rk,
sous coˆut quadratique, que tout estimateur admissible est un estimateur de
Bayes g´en´eralis´e. Il s’agit donc d’une extension de Brown (1971), qui avait
trait´e le cas normal.
Exemple 8.35. Dans le cas normal, x ∼Np(θ, Ip), nous avons parl´e `a plu-
sieurs reprises de l’estimateur tronqu´e de James-Stein,
δJS(x) =

1 −p −2
||x||2
+
x.
(8.11)
Bien que satisfaisant, cet estimateur n’est pas admissible. En eﬀet, s’il l’´etait,
ce serait un estimateur de Bayes g´en´eralis´e, ce qui est impossible puisque la
fonction δJS(x) n’est pas analytique (voir l’Exercice 8.26).
∥
Chow (1987) montre un r´esultat analogue pour les familles avec param`etres
de non-centralit´e, χ2
p(λ) et Fp,q(λ), illustrant ainsi la compl´etude des r`egles de
Bayes g´en´eralis´ees en dehors du cadre des familles exponentielles. Ce th´eor`eme
de classe compl`ete a pour cons´equence particuli`ere l’inadmissibilit´e de l’esti-
mateur classique (x−p)+, pour la distribution χ2
p(λ), bien que Saxena et Alam
(1982) aient prouv´e l’eﬃcacit´e de cet estimateur, dans la mesure o`u il domine
l’estimateur du maximum de vraisemblance (voir ´egalement l’Exercice 3.25).
Fraisse et al. (1990) ´etablissent un r´esultat similaire `a Berger et Srinivasan
(1978) en pr´esence d’un param`etre de nuisance. Soit x = (u, z) avec u ∈Rk
et z ∈R. La densit´e de x par rapport `a ν est
f(x|θ, δ) = h(u, z)eθ.u+δz−ψ(θ,δ) ,
avec θ ∈Θ ⊂Rk et δ ∈Δ, intervalle compact de R∗
+. Comme dans le cas
normal, le probl`eme pos´e consiste `a estimer θ/δ sous coˆut quadratique. Pour
ce mod`ele, le th´eor`eme de la classe compl`ete est donn´e par :

446
8 Admissibilit´e et classes compl`etes
Proposition 8.36. Si ϕ est un estimateur admissible de θ/δ, il existe une
mesure π sur Θ × Δ telle que, pour ν-presque tout (u, z),
ϕ(u, z) =

Θ×Δ θeθ.u+δz−ψ(θ,δ)π(dθ, dδ)

Θ×Δ δeθ.u+δz−ψ(θ,δ)π(dθ, dδ) .
(8.12)
Par cons´equence, le th´eor`eme de classe compl`ete de Berger et Srinivasan
(1978) n’est pas invalid´e en pr´esence de param`etres de nuisance. La preuve
de la Proposition 8.36 repose en fait sur la Proposition 8.30 (voir l’Exercice
8.27).
Exemple 8.37.
Soient x ∼Np(θ, σ2Ip) et s2 ∼σ2χ2
q, ind´ependant de
x. Dans ce cadre, δ0(x, s2) = x est aussi inadmissible pour p ≥3. Nous
consid´erons des extensions de l’estimateur de James-Stein (8.11) de la forme
ϕ(x, s2) = (Ip −h(||x||2
C, s2)B)x,
o`u B et C sont des matrices (p × p), h est diﬀ´erentiable presque partout et
||x||2
C = xtCx. On appelle ces estimateurs estimateurs `a r´etr´ecisseur matri-
ciels (voir Judge et Bock, 1978). La Proposition 8.36 implique qu’une condition
n´ecessaire d’admissibilit´e sur ϕ est que h soit inﬁniment diﬀ´erentiable et que
B et C soient proportionnelles (voir l’Exercice 8.28).
∥
Brown (1988) consid`ere le probl`eme d’estimation de la moyenne d’une
famille exponentielle, ξ(θ). En dimension un, il ´etablit que les estimateurs
admissibles ont une expression int´egrale proche de (8.12). En fait, les estima-
teurs admissibles sont alors ´egaux par intervalles `a des estimateurs de Bayes
g´en´eralis´es.
Dans le cas des distributions `a support discret, la compl´etude des estima-
teurs de Bayes g´en´eralis´es n’est pas toujours vraie et les classes compl`etes font
intervenir des proc´edures bay´esiennes par morceaux (voir Berger et Sriniva-
san, 1978, Brown, 1981, et Brown et Farrell, 1985). Les r´esultats sur les classes
compl`etes obtenus en Section 5.4 pour le test sous coˆut quadratique sont de ce
type, puisque nous avons vu que les estimateurs admissibles sont identiques
aux estimateurs de Bayes g´en´eralis´es sur des intervalles de troncature.
8.5 Conditions n´ecessaires d’admissibilit´e
Lorsqu’on ne dispose pas d’un th´eor`eme de classe compl`ete limitant le
choix d’estimateurs `a l’ensemble des estimateurs de Bayes g´en´eralis´es, il faut
trouver une autre fa¸con d’exclure le plus d’estimateurs inadmissibles pos-
sibles. Bien que n´ecessaire, la condition de Stein n’est pas, en g´en´eral, un outil
tr`es utile pour une telle tˆache d’´elimination, car son int´erˆet pratique princi-
pal r´eside dans la condition suﬃsante de Blyth. Par ailleurs, les r´esultats

8.5 Conditions n´ecessaires d’admissibilit´e
447
de la Section 8.3 ne sont pas applicables dans ce contexte g´en´eral puis-
qu’ils ne concernent que les estimateurs de Bayes g´en´eralis´es. Pour les coˆuts
quadratiques, Hwang (1982b) d´eveloppe une technique propos´ee par Brown
(1971), appel´ee STUB (pour semi-tail upper bounds, bornes inf´erieures de
demi-queue), qui donne une condition n´ecessaire d’admissibilit´e utilisable en
pratique. Elle trouve sa source dans le lemme suivant.
Lemme 8.38. Soient deux estimateurs δ1 et δ2 `a risques ﬁnis, tels que
R(θ, δ1) = Eθ
#
(δ1(x) −θ)tQ(δ1(x) −θ)
$
< R(θ, δ2)
pour tout θ ∈Θ et pour une matrice d´eﬁnie positive donn´ee Q. Alors, tout
estimateur δ satisfaisant presque partout l’in´egalit´e
δ(x)tQ(δ1(x) −δ2(x)) < δ2(x)tQ(δ1(x) −δ2(x))
est inadmissible sous n’importe quel coˆut quadratique.
Preuve. On consid`ere le nouvel estimateur δ′(x) = δ(x)+δ1(x)−δ2(x). Alors
R(θ, δ′) = Eθ
#
(δ′(x) −θ)tQ(δ′(x) −θ)
$
= R(θ, δ) + 2Eθ
#
(δ1(x) −δ2(x))tQ(δ(x) −θ)
$
+Eθ
#
(δ1(x) −δ2(x))tQ(δ1(x) −δ2(x))
$
≤R(θ, δ) + 2Eθ
#
(δ1(x) −δ2(x))tQ(δ2(x) −θ)
$
+Eθ
#
(δ1(x) −δ2(x))tQ(δ1(x) −δ2(x))
$
= R(θ, δ) + R(θ, δ1) −R(θ, δ2) < R(θ, δ)
et δ′ domine δ.
⊓⊔
Ce lemme peut sembler simple `a premi`ere vue mais il est en fait relati-
vement puissant puisqu’il donne une nouvelle condition n´ecessaire d’admissi-
bilit´e pour tout couple (δ1, δ2) ordonn´e (par le risque). De plus, comme l’ad-
missibilit´e ne d´epend pas de la matrice Q, on obtient une gamme ´etendue
de crit`eres d’inadmissibilit´e. Elle couvre en particulier la condition n´ecessaire
d’admissibilit´e (i) du Th´eor`eme 8.17.
Exemple 8.39. On consid`ere x ∼Np(θ, Ip). Il d´ecoule de James et Stein
(1961) (voir la Note 2.8.2) que, parmi tous les estimateurs
δa(x) =

1 −
a
||x||2

x,
δp−2 est optimal pour les coˆuts quadratiques usuels. Par cons´equent, le Lemme
8.38 implique que tout estimateur δ v´eriﬁant

448
8 Admissibilit´e et classes compl`etes
δ(x)txa −(p −2)
||x||2
≤

1 −
a
||x||2

(a −(p −2))
(8.13)
est inadmissible. On consid`ere l’estimateur δ de la forme
δ(x) =

1 −h(x)
||x||2

x.
Alors (8.13) implique que δ est inadmissible si
h(x) ≤a < p −2
ou
h(x) ≥a > p −2.
Donc, tout estimateur tel que h soit uniform´ement plus grand ou plus petit que
(p −2) est inadmissible. La condition n´ecessaire du Th´eor`eme 8.17 s’obtient
en consid´erant ensuite les estimateurs tronqu´es (a ≤p −2),
ϕa(x) =

1 −
a
||x||2 I[K,+∞[(||x||2)

x ,
et en montrant que a∗= p −2 correspond `a l’estimateur optimal de cette
classe (voir l’Exercice 8.20). Le Lemme 8.38 implique alors que, si
h(x) ≤a < p −2
pour ||x||2 > K, alors l’estimateur δ est ´egalement inadmissible.
∥
Remarquons aussi que dans le Lemme 8.38, l’in´egalit´e stricte R(θ, δ1) <
R(θ, δ2) n’a pas `a ˆetre satisfaite pour tout θ, mais seulement pour certains θ,
du moment que R(θ, δ1) ≤R(θ, δ2) est v´eriﬁ´ee quel que soit θ ∈Θ.
Exemple 8.40. Das Gupta (1958) d´eduit du Lemme 8.38 une condition
n´ecessaire d’admissibilit´e pour les distributions exponentielles. Si x1, . . . , xp
sont des variables al´eatoires E xp(θi), tout estimateur δ de (θ−1
1 , . . . , θ−1
p ) sa-
tisfaisant
p

i=1
x−3
i δi(x) ≤
p

i=1
x−3
i
δB
c,i(x)
pour xi ≤M, x = (x1, . . . , xn), et
δB
c,i(x) = xi
2
⎡
⎢⎣1 +
cx−4
i
2
p
j=1 x−2
j
2
⎤
⎥⎦,
0 < c < 2(p −1), est inadmissible. L’estimateur δB
c,i a ´et´e sugg´er´e par Berger
(1980b) pour am´eliorer l’estimateur habituel, x/2, pour p ≥2. Constatons
que x/2 domine l’estimateur du maximum de vraisemblance, x (voir l’Exercice
8.32).
∥

8.5 Conditions n´ecessaires d’admissibilit´e
449
Il est ´egalement possible d’´etablir une condition n´ecessaire d’admissibi-
lit´e, `a partir du Lemme 8.38, pour l’estimation d’un vecteur moyen nor-
mal quand la variance est connue `a un facteur multiplicatif pr`es, σ2, comme
dans l’Exemple 8.37. Soient x ∼Np(θ, σ2Ip) et s2 ∼σ2χ2
q une observation
ind´ependante de x de σ2. Le r´esultat suivant donne une condition n´ecessaire
d’admissibilit´e (Robert, 1998).
Proposition 8.41. Si, ´etant donn´e l’estimateur
δ(x) = (1 −h(||x||2, s2))x,
il existe α, M1 et M2 tels que
(i) pour t ≥M1 et u ≤M2,
t
uh(t, u) ≤α < p −2
q + 2;
ou
(ii) pour t ≤M1 et u ≥M2,
t
uh(t, u) ≥α > p −2
q + 2;
δ est inadmissible sous coˆut quadratique.
La d´emonstration de ce r´esultat utilise l’existence d’un estimateur optimal
dans la classe
ϕc(x, s2) = x −cs2
||x||2 IA(||x||2, s2)x,
avec A = [K1, +∞) × [0, M2] ou A = [0, K1] × [M2, +∞). Pour ´etayer la
Proposition 8.41, rappelons que, dans ce cadre, les estimateurs de James-Stein
sont de la forme :
δJS
a (x, s2) =

1 −as2
||x||2

x
et que
a∗= p −2
q + 2
donne un estimateur optimal dans la classe δJS
a . Par cons´equent, δJS
a∗cor-
respond au facteur de r´etr´ecissement minimal pour ||x||2/s2 grand et le
r´etr´ecissement maximal pour ||x||2/s2 petit. L’estimateur δJS
a∗est n´eanmoins
inadmissible (Exemple 8.35). Fraisse et al. (1998) ´etendent ce r´esultat aux
familles exponentielles avec un param`etre de nuisance de la mˆeme fa¸con que
dans la Proposition 8.36.

450
8 Admissibilit´e et classes compl`etes
Exemple 8.42. (Suite de l’Exemple 8.37) Parmi les estimateurs `a r´etr´e-
cisseur matriciels, les seuls estimateurs d’int´erˆet sont de la forme
ϕ(x, s2) = (Ip −h(xtBx, s2)B)x,
(8.14)
puisque les autres sont inadmissibles. La Proposition 8.41 entraˆıne que, si,
quel que soit (t, u),
t
uh(t, u) ≤α < p −2
q + 2,
ces estimateurs sont ´egalement inadmissibles. De plus, une condition n´ecessaire
de minimaxit´e sous coˆut quadratique est
t
uh(t, u) ≤2 tr(B) −2λmax(B)
λmax(B)
1
q + 2,
o`u tr(B) d´esigne la trace et λmax(B) la plus grande valeur propre de B (voir
Brown, 1975 , et Cellier et al., 1989 ). Une condition n´ecessaire pour l’existence
d’un estimateur v´eriﬁant `a la fois les crit`eres d’admissibilit´e et de minimaxit´e
est donc
tr(B) > λmax(B) p + 2
2
,
ce qui exclut de fait les estimateurs r´etr´ecissant vers des sous-espaces de faibles
dimensions.
Ce r´esultat met aussi en ´evidence le fait que l’admissibilit´e et la mini-
maxit´e ne sont pas totalement compatibles. En fait, un estimateur admissible
sous coˆut quadratique l’est pour n’importe quel coˆut quadratique. `A l’inverse,
Brown (1975) montre que le seul estimateur de la forme (8.14), qui est mini-
max pour tous les coˆuts quadratiques, est δ0(x) = x. Cela est ´egalement li´e
`a l’admissibilit´e universelle de l’estimateur δ0 ´etablie dans Brown et Hwang
(1989) (voir la Section 2.6).
∥
8.6 Exercices
Section 8.2.1
8.1 (Lehmann, 1986) Soit une variable al´eatoire x de moyenne μ et de variance σ2.
a. Montrer que δ(x) = ax + b est un estimateur inadmissible de μ sous coˆut
quadratique si
(a) a > 1 ; ou
(b) a < 0 ; ou
(c) a = 1 et b ̸= 0.
b. G´en´eraliser au cas o`u δ(x) = (1 + h(x))x avec h(x) > 0.
8.2 (Suite de l’Exercice 8.1) En d´eduire qu’il suﬃt de consid´erer λ ≥0 pour
les estimateurs (8.1) utilis´es dans le Th´eor`eme 8.7.

8.6 Exercices
451
8.3 On consid`ere x ∼U[−θ,θ] et π(θ) est la distribution uniforme U[0,1].
a. Montrer que
δπ
1 (x) =
8
<
:
1 −|x|
log(1/|x|)
si |x| ≤1,
0
sinon,
est un estimateur de Bayes inadmissible et domin´e, sous coˆut quadratique
usuel, par
δπ
2 (x) =
(
δπ
1 (x)
si |x| ≤1,
|x|
sinon,
b. Montrer que δπ
2 est aussi un estimateur de Bayes de π.
8.4 Soit x ∼B(n, p). D´eterminer si δ0 ≡0 est un estimateur admissible de p sous
coˆut quadratique.
8.5 (Johnson, 1971) On consid`ere x ∼B(n, θ).
a. Montrer que δ0(x) = x est l’estimateur du maximum de vraisemblance de
θ et ´egalement un estimateur de Bayes sous coˆut quadratique pour π(θ) =
1/θ(1 −θ).
b. Montrer que (δ0, 1 −δ0) est admissible sous le coˆut
L(θ, δ) = (θ −δ1)2 + (1 −θ −δ2)2.
(8.15)
(Indication : Utiliser la repr´esentation bay´esienne de δ0 pour montrer que
Z
[R(θ, δ) −R(θ, (δ0, 1 −δ0))]
dθ
θ(1 −θ) ≥0
et en d´eduire que le seul cas d’´egalit´e est δ1 = δ0, δ2 = 1 −δ0.)
c. Montrer qu’une classe compl`ete pour le coˆut (8.15) est constitu´ee des esti-
mateurs tels que δ1 = 1 −δ2.
d. G´en´eraliser le r´esultat b. au cas multinomial x ∼Mk(n, p1, . . . , pk). (Indica-
tion : Proc´eder par r´ecurrence.)
Section 8.2.2
8.6 D´eterminer les lois a priori bˆeta Be(α, β) correspondant aux estimateurs ad-
missibles de l’Exemple 8.9.
Section 8.2.3
8.7 Dans le cadre de l’Exemple 8.12, montrer que le risque de Bayes de δπ est inﬁni
et d´eterminer si δc∗est un estimateur de Bayes.
8.8
∗(Zidek, 1970) Pour x ∼f(x|θ), θ ∈R, tel que {θ; f(x|θ) > 0} soit un intervalle,
on ´etudie l’estimation de g(θ) sous coˆut quadratique. On cherche une condition
suﬃsante d’admissibilit´e pour l’estimateur de Bayes g´en´eralis´e
δπ(x) =
R
g(θ)f(x|θ)π(θ)dθ
R
f(x|θ)π(θ) dθ
avec π une mesure et
Z
R(θ, δπ)π(θ) dθ = +∞.

452
8 Admissibilit´e et classes compl`etes
a. On d´eﬁnit
M(x, θ) =
Z +∞
θ
[g(t) −δπ(x)]2f(x|t)π(t)dt
et
h(θ) =
Z » M(x, θ)
f(x|θ)π(θ)
–2
f(x|θ) dx.
Montrer qu’il existe une fonction q(θ) telle que ˜π(θ) = q(θ)π(θ) soit une
densit´e de probabilit´es et que
Z
R(θ, δπ)˜π(θ) dθ < +∞.
b. Soit ˜δ l’estimateur de Bayes associ´e `a ˜π. Montrer que
r =
Z
[R(θ, δπ) −R(θ, δ)]˜π(θ) dθ =
Z [
R
q′(θ)M(x, θ) dθ]2
R
f(x|θ)π(θ) dθ
dx.
c. En d´esignant q(θ) par f 2(θ), utiliser l’in´egalit´e de Cauchy-Schwarz pour mon-
trer que
r ≤4
Z
[f ′(θ)]2h(θ)π(θ) dθ.
d. Montrer que si, pour tout (θ0, θ1) et ϵ > 0, il existe une fonction q telle
que q(t) = 1 sur (θ0, θ1) et un nombre r´eel r < ϵ, alors l’estimateur δπ est
admissible.
e. On consid`ere la condition (E) : Si
Z +∞
t
R(θ, δπ)π(θ) dθ = +∞,
alors
Z +∞
t
1
h(θ)π(θ) dθ = +∞.
Soit
y(θ) =
Z θ
θ1
1
h(t)π(t) dt
et
f(t) =
„
1 −y(t)
F
«
I0≤y(t)≤F .
Montrer que
f ′(t) = −
1
Fh(t)π(t)
(0 ≤y(t) ≤F),
et que
Z +∞
θ1
[f ′(t)]2h(t)π(t) dt = 1
F .
D´eduire de (E) qu’il est possible de choisir F tel que r < ϵ. Conclure en
donnant une condition suﬃsante d’admissibilit´e.
f. Recommencer la question e. sous l’hypoth`ese sym´etrique, c’est-`a-dire si
Z t
−∞
R(θ, δπ)π(θ) dθ = +∞,
alors
Z t
−∞
1
h(θ)π(θ) dθ = +∞.
8.9 On consid`ere le coˆut born´e
L(θ, δ) = 1 −e−a(θ−δ)2
(a > 0),
pour l’estimation de θ avec x ∼N (θ, 1).

8.6 Exercices
453
a. D´eterminer les estimateurs de Bayes associ´es `a l’a priori conjugu´e θ ∼
N (μ, τ 2).
b. D´eterminer les estimateurs de Bayes associ´es `a l’a priori π(θ) ∝exp(−λ
|θ −μ|).
c. ´Etudier l’admissibilit´e de l’estimateur de Bayes g´en´eralis´e associ´e `a l’a priori
de Jeﬀreys π(θ) = 1 quand a varie. (Indication : D´eterminer si le risque de
Bayes est ﬁni et appliquer la m´ethode de Blyth si n´ecessaire.)
Section 8.2.4
8.10 ´Etablir la formule de repr´esentation (8.3) et v´eriﬁer les ´egalit´es de l’Exemple
8.25.
8.11 Montrer que les estimateurs δCZ propos´es en Section 8.2 dans un cadre pois-
sonnien sont eﬀectivement des estimateurs de Bayes g´en´eralis´es en trouvant les
lois a priori correspondantes.
8.12
∗(Berger, 1982a) Soit x de loi
x ∼f(x|θ) = h(x)eθx−ψ(θ)
pour x ∈[a, b]. ´Etant donn´e deux fonctions positives diﬀ´erentiables, m0 et d, on
pose
δ0(x) = m′
0(x)
m0(x) −h′(x)
h(x) ,
γ(x) = 2d′(x)
d(x) ,
et
δ(x) = δ0(x) + γ(x).
a. Montrer que, sous coˆut quadratique,
R(θ, δ) −R(θ, δ0) = Eθ
„
4
d(x)
»
d′′(x) + d′(x)m′
0(x)
m0(x)
–«
,
moyennant certaines conditions de r´egularit´e comme
lim
x→a h(x)γ(x)eθx = lim
x→b h(x)γ(x)eθx = 0.
b. On suppose que l’une des fonctions
g1(x) =
Z x
a
1
m0(y)dy
ou
g2(x) =
Z b
x
1
m0(y)dy
est ﬁnie sur [a, b]. On note gi cette fonction. Montrer que si, en outre,
Eθ
˛˛˛˛
d
dx log gi
˛˛˛˛
2
< +∞
et
lim
x→a h(x)eθx g′
i(x)
gi(x) = lim
x→b h(x)eθx g′
i(x)
gi(x) = 0,
alors δ0 est inadmissible et domin´e par δ pour γ(x) = 2αg′
i(x)/gi(x) si 0 ≤
α ≤1.
c. Appliquer au cas x ∼G (ν, θ) et
π(θ) = 1
π
1
1 + θ2 .

454
8 Admissibilit´e et classes compl`etes
Section 8.2.5
8.13 Montrer que le noyau de transition (8.7) est li´e `a la mesure stationnaire π. (In-
dication : Montrer que la condition d’´equilibre ponctuel s’applique.) En d´eduire
que la chaˆıne associ´ee est soit r´ecurrente nulle, soit transiente lorsque l’a priori
π est impropre.
8.14 Soient x ∼N (θ, 1) et π(θ) ∝exp{−bθ2/2 + abθ}.
a. Donner des conditions n´ecessaires et suﬃsantes sur (a, b) pour que la distri-
bution a posteriori soit d´eﬁnie. Montrer que, dans ce cas, la distribution a
posteriori est normale de moyenne (x + ab)/(1 + b) et de variance 1/(b + 1).
b. Montrer que le noyau de transition (8.7) est alors donn´e par
η|θ ∼N
„θ + ab
1 + b ,
b + 2
(1 + b)2
«
.
c. En d´eduire que la chaˆıne de Markov est un mod`ele AR(1) (Section 4.5.2)
θ(t+1) =
1
1 + bθ(t) +
ab
1 + b +
√
b + 2
1 + b ϵt .
En conclure qu’elle est transiente lorsque b < 0 et r´ecurrente si b = 0.
Section 8.3.1
8.15 V´eriﬁer que les trois conditions du Lemme 8.23 sont bien satisfaites pour une
fonction de coˆut quadratique,
L(θ, δ) = (δ −θ)tQ(δ −θ),
pour toute matrice d´eﬁnie positive Q.
Section 8.3.2
8.16
∗(Clevenson et Zidek, 1975)
Soient (x1, . . . , xn) des variables al´eatoires
ind´ependantes de Poisson, xi ∼P(λi).
a. Utiliser une suite de lois a priori conjugu´ees et la m´ethode de Blyth pour
montrer que δ0(xi) = xi est un estimateur admissible de λi sous coˆut qua-
dratique.
b. Pour n ≥2, montrer que
Eλ
" n
X
i=1
1
λi
(
xi
„
1 +
n −1
Pn
i=1 xi
«−1
−λi
)2#
≤Eλ
" n
X
i=1
1
λi (xi −λi)2
#
et en d´eduire que δ0(x1, . . . , xn) = (x1, . . . , xn) est un estimateur inadmissible
de λ = (λ1, . . . , λn). (Indication : Minimiser (en λ) Eλ[P
i λ−1
i
(axi −λi)2] et
remplacer la solution a par P
i xi/ P
i xi + n −1.)
8.17 Transposer la d´emarche de l’Exemple 8.27 au cas Poisson : montrer que, si
H0 : λ ≤λ0 et ϕ(x) = Pλ0(X ≥x), avec X ∼P(λ0), alors ϕ est admissible
sous coˆut quadratique. (Indication : Utiliser la condition de Blyth.)
8.18 Reprendre l’Exercice 8.17 avec la distribution gamma, G (ν, θ) et H0 : θ ≤θ0.

8.6 Exercices
455
8.19 Soit x ∼N2(θ, I2). D´eterminer si la condition de Blyth pour l’admissibilit´e de
δ0(x) = x est v´eriﬁ´ee par la suite πn(θ) qui vaut
πn(θ) = exp{−||θ||2/2n}.
Si cette suite ne convient pas, en proposer une autre.
8.20
∗(Hwang et Brown, 1991) On consid`ere x ∼Np(θ, Ip). La r´egion de conﬁance
standard est
Cx = {θ; ∥θ −x∥< c},
avec Pθ(θ ∈Cx) = 1−α. Grˆace `a la m´ethode de Blyth, montrer que l’´evaluation
γ0(x) = 1 −α est admissible sous coˆut quadratique
L(θ, γ) = (γ −ICx(θ))2 ,
pour p ≤4. [Note : Robert et Casella, 1993, montrent en outre que cet estima-
teur constant est inadmissible pour p ≥5. `A l’inverse, Hwang et Brown, 1991,
´etablissent, par validit´e fr´equentiste, que γ0 est admissible quel que soit p (voir
la Section 5.5).]
8.21 Dans le cadre de l’Exemple 8.27, montrer que la loi marginale mn associ´ee `a
gn est croissante. Pour π(θ) = 1/θ, montrer que, pour x ̸= 0,
ϕ(x) =
1
B(x, m −x + 1)
Z θ0
0
tx−1(1 −t)m−x dt
puis traiter le cas x = 0.
Section 8.4
8.22 Une classe C est dite compl`ete minimale si C est compl`ete et si aucun sous-
ensemble propre de C n’est complet.
a. Montrer que toute classe compl`ete contient tous les estimateurs admissibles.
b. Montrer que, s’il existe une classe compl`ete minimale, il s’agit exactement
des estimateurs admissibles.
8.23
∗(Karlin et Rubin, 1956)
On suppose que f(x|θ) satisfait la propri´et´e des
rapports de vraisemblance monotones (en x ∈R), avec θ ∈Θ. Le probl`eme
d’estimation est dit monotone si L(θ, δ) est minimal pour δ = q(θ), avec q
croissante en θ, et si L(θ, δ) est une fonction croissante de |δ −q(θ)|.
a. Montrer que, si L est convexe, les estimateurs qui sont des fonctions crois-
santes de x constituent une classe compl`ete.
b. Montrer que, si δ0 n’est pas monotone, l’estimateur monotone δM, d´eﬁni par
Pq−1(a)(δM(X) ≤a) = Pq−1(a)(δ0(X) ≤a),
∀a
domine δ0.
c. Si δM est strictement croissante, montrer que la relation ci-dessus implique
que δM(x) est un nombre a tel que
F(x|q−1(a)) = Pq−1(a)(δ0(X) ≤a).
8.24 Appliquer l’Exercice 8.23 au cas o`u x ∼N (θ, 1), L(θ, δ) = (θ −δ)2 et δ0(x) =
−cx + b, avec c > 0.

456
8 Admissibilit´e et classes compl`etes
8.25 (Berger, 1985b) Soit Θ un ensemble ﬁni de cardinal p. On suppose que l’en-
semble de risque R est born´e et ferm´e inf´erieurement. On note Γ(R) la fronti`ere
inf´erieure de R, c’est-`a-dire
Γ(R) = {r ∈R; ̸ ∃r′ ∈R, r′ ̸= r et r′
i ≤ri, 1 ≤i ≤p} ⊂R.
Le coˆut L est suppos´e convexe.
a. Montrer que l’ensemble des estimateurs dont le vecteur de risque est dans
Γ(R) forme une classe compl`ete minimale.
b. Montrer que l’ensemble des estimateurs de Bayes forme une classe compl`ete
et que l’ensemble des estimateurs de Bayes g´en´eralis´es forme une classe
compl`ete minimale.
c. *G´en´eraliser au cas o`u L n’est pas convexe.
8.26
∗(Berger et Srinivasan, 1978 ) On consid`ere x ∼Np(θ, Σ) avec Σ connu. La
moyenne θ est estim´ee sous coˆut quadratique. Montrer qu’un estimateur δ0 est
un estimateur de Bayes g´en´eralis´e si et seulement si
(i) g(x) = Σ−1δ0(x) est continˆument diﬀ´erentiable, avec un jacobien sym´etri-
que Jg(x) = ∇∇tg(x); et
(ii) pour g(x) = ∇r(x), exp{r(x)} peut ˆetre exprim´ee comme une transform´ee
de Laplace.
8.27
∗(Fraisse et al., 1990 ) Soit x = (u, z) avec u ∈Rk et z ∈R, de densit´e
f(x|θ, δ) = exp{θ · u + δz −K(θ, δ)}
par rapport `a une mesure ν σ-ﬁnie, avec θ ∈Θ ⊂Rk et δ ∈Δ, sous-ensemble
compact de R∗
+.
a. Montrer (ou admettre) le lemme suivant : Si (μn) est une suite de mesures
`a supports ﬁnis telles que, pour presque tout (u, z),
sup
n
∥∇ψμn(z)∥< +∞,
alors il existe une mesure μ et une sous-suite (nk) telles que
lim
k→+∞ψμnk (u, z) = ψμ(u, z)
et
lim
k→+∞∇ψμnk (u, z) = ∇ψμ(u, z),
avec
ψμ(u, z) =
Z
Θ×Δ
eθ·u+δzμ(dθ, dδ).
b. D´eduire de la Proposition 8.30 que, pour tout estimateur admissible ϕ de θ/δ
sous coˆut d’erreur quadratique δ2||ϕ −θ/δ||2, il existe une suite de mesures
(ϱn) `a supports ﬁnis sur Θ × Δ telles que
ϕ(u, z) =
lim
n→+∞
R
θeθ·u+δzμn(dθ, dδ)
R
δeθ·u+δzμn(dθ, dδ),
avec μn(dθ, dδ) = e−K(θ,δ)ϱn(θ, δ).
c. Montrer que l’hypoth`ese du lemme ci-dessus est satisfaite et que, pour tout
estimateur admissible ϕ, il existe μ0 tel qu’on ait presque partout
ϕ(u, z) =
R
θeθ·u+δzμ0(dθ, dδ)
R
δeθ·u+δzμ0(dθ, dδ),
c’est-`a-dire que ϕ est un estimateur de Bayes g´en´eralis´e associ´e `a μ0.

8.6 Exercices
457
8.28 (Fraisse et al., 1990) Soient x ∼Np(θ, σ2Ip) et s2 ∼σ2χ2
q. La moyenne θ est
estim´ee sous coˆut quadratique, avec σ ∈[a, b].
a. Montrer que ce mod`ele s’ins`ere dans le cadre de l’Exercice 8.26.
b. On consid`ere l’estimateur
ϕ(x, s2) = (Ip −h(xtBx, s2)C)x.
Montrer que, si ϕ est admissible, il existe ϱ ∈R∗
+ tel que B = ϱC.
c. Comparer aux r´esultats de l’Exercice 8.26.
8.29
∗(Moors, 1981) Soit x ∼Be(p), avec 0.2 ≤p ≤0.8. On estime le param`etre
p sous coˆut quadratique.
a. Montrer que δπ(1) = 1 −δπ(0) lorsque l’a priori π(p) est sym´etrique centr´e
sur 1/2.
b. Montrer que δπ(1) ≤maxp[1 −2p(1 −p)] = 0.68.
c. En d´eduire que, si un estimateur v´eriﬁe δ(1) = 1 −δ(0) et δ(1) > 0.68, il est
inadmissible.
8.30
∗(Johnson, 1971) On consid`ere x ∼B(n, θ), avec θ `a estimer sous coˆut qua-
dratique.
a. Rappeler pourquoi tout estimateur admissible est n´ecessairement un estima-
teur de Bayes.
b. Montrer que la r´eciproque est fausse, ce qui revient `a proposer des estima-
teurs de Bayes inadmissibles.
c. Montrer que l’ensemble des estimateurs de Bayes admissibles est constitu´e
des estimateurs
δτ(x) =
8
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
:
0
si 0 ≤x ≤n,
Z 1
0
θx−n(1 −θ)n−x−n−1 dτ(θ)
Z 1
0
θx−n−1(1 −θ)n−x−n−1 dτ(θ)
si n < x < n,
1
si n ≤x ≤n .
d. Expliquer pourquoi δτ est un estimateur de Bayes pour une classe enti`ere de
distributions a priori τ.
8.31 (Hwang et al., 1992) On consid`ere H0 : θ ∈Θ0. Les proc´edures de test γ sont
compar´ees sous un coˆut strictement convexe, L(IΘ0(θ), γ).
a. Montrer que γ0(x) = 1/2 est le seul estimateur minimax.
b. En d´eduire que γ0 est admissible.
c. Peut-on ´ecrire γ0 comme un estimateur de Bayes g´en´eralis´e ? Ce ph´enom`ene
contredit-il les th´eor`emes de classe compl`ete (5.42 et 5.43) de la Section 5.4 ?
8.32 ´Etant donn´e x ∼E xp(θ) et δc(x) = cx, d´eterminer le meilleur estimateur δc
de θ−1 sous coˆut quadratique. Montrer que cet estimateur est un estimateur de
Bayes g´en´eralis´e et discuter son admissibilit´e.

458
8 Admissibilit´e et classes compl`etes
Section 8.5
8.33 (Robert et Casella, 1994) On consid`ere x ∼N (θ, 1) et l’ensemble de conﬁance
usuel Cx = [x −c, x + c]. Au lieu d’utiliser la probabilit´e ﬁxe de conﬁance
α = Pθ(θ ∈Cx), on propose une proc´edure ϕ qu’on ´evalue sous le coˆut
L(θ, ϕ) = d(θ, Cx)(ICx(θ) −ϕ)2,
le poids d(θ, Cx) ´etant une mesure de distance entre θ et la fronti`ere de Cx.
a. Expliquer la pertinence d’un choix d’intervalle de conﬁance d´ependant des
donn´ees et justiﬁer le choix du poids de distance.
b. Dans le cas particulier
d(θ, Cx) = 1 −e−ω(θ−x)2 “
1 −e−ω(θ−x)2”
,
montrer que cette distance est minimale pour |θ −x| = c si ω = log(2)/c2.
c. Donner la forme g´en´erale des estimateurs de Bayes sous cette fonction de coˆut
et montrer que le r´esultat de classe compl`ete du Th´eor`eme 5.42 s’applique
dans ce cas.
d. Pour les classes de distances sym´etriques de la forme h(|θ −x|) et π(θ) = 1,
montrer que les estimateurs de Bayes sont constants et pas forc´ement ´egaux
`a α. Ces estimateurs sont-ils admissibles ?
8.34 D´eduire la Proposition 8.41 du Lemme 8.38.
8.35 Montrer que, si x ∼Np(θ, Ip), δ0(x) = x est admissible pour la classe de coˆuts
L(θ, δ) = (θ −δ)tQ(θ −δ),
avec Q dans l’ensemble des matrices sym´etriques d´eﬁnies positives.
8.36 (Hwang, 1982b) Soit x ∼Np(θ, Ip). Une classe d’estimateurs de θ est donn´ee
par
φa(x) = x −
a
||x||2 I[K,+∞[(||x||2)x,
pour 0 ≤a ≤(p −2).
a. Montrer que ϕa∗associ´e `a a∗= p −2 est optimal parmi les estimateurs ϕa
sous coˆut quadratique classique.
b. D´emontrer le r´esultat de l’Exemple 8.39.
c. Appliquer la mˆeme technique `a
ϕb(x) = x −
b
||x||2 I[0,K](||x||2)x
et b ≥(p −2). En d´eduire une condition STUB.
Note 8.7.1
8.37
∗Montrer que K dans (8.7) et K∗dans (8.16) sont soit tous deux r´ecurrents,
soit tous deux transients. (Indication : Utiliser la variable indicatrice P∞
t=1 IB(xt)
pour un ensemble arbitraire B.)
8.38
∗Dans le cadre de l’Exemple 8.43,
a. Montrer que l’´equation (8.17) est v´eriﬁ´ee.

8.6 Exercices
459
b. Montrer que la chaˆıne de Markov associ´ee `a K∗peut s’´ecrire xt+1 = (xt +
b)zt+1, o`u les zt sont ind´ependants et de densit´e
f(z) =
Γ(2α + a)
Γ(α + a)Γ(α)
zα−1
(z + 1)2α+a .
c. Montrer que zt a une moyenne inﬁnie quand a + α ≤1 et que E[log(zt)] est
n´egative quand a < 0, nulle si a = 0, et positive quand a < 0.
d. Dans le cas b = 0, montrer que (xt) est r´ecurrente si et seulement si a = 0.
8.39
∗(Hobert et Robert, 1999) Soit x ∼P(θ) avec π(θ) ∝θa−1 exp{−bθ}.
a. ´Enoncer des conditions n´ecessaires et suﬃsantes sur (a, b) pour que la distri-
bution a posteriori soit d´eﬁnie et que la distribution a priori soit impropre.
b. Expliciter le noyau de transition (8.7) dans ce cas. Si b = −1/2 et a = k/2,
montrer que la transition est une loi du khi deux d´ecentr´e.
c. Montrer que le noyau de transition (8.16) est
K∗(x, y) = Γ(y + x + a)
y!Γ(x + a) px+a(1 −p)y ,
avec p = (b + 1)/(b + 2).
d. Montrer que cette distribution correspond `a la loi binomiale n´egative stan-
dard lorsque a est un entier naturel.
e. Dans le cas g´en´eral, la distribution de fonction de masse
P(Z = z) = Γ(z + c)
z!Γ(c) pc(1 −p)z
est appel´ee distribution binomiale n´egative g´en´eralis´ee N eg(c, p). D´eduire
de la fonction g´en´eratrice que, si z1, . . . , zn sont ind´ependants de zi ∼
N B(ci, p), z1 + . . . + zn ∼N eg(c1 + . . . + cn, p).
f. En d´eduire que (xt) associ´e au noyau K∗est un processus de branchement,
xt+1 =
xt
X
i=1
ηi,t + ωt+1
avec ηi,t ∼N eg(1, p) et ωt+1 ∼N eg(a, p).
g. En conclure que la chaˆıne (xt) est r´ecurrente si b = 0 et 0 < a < 1, et
transiente sinon.
8.40
∗(Hobert et Robert, 1999) Soit x ∼N eg(k, θ) avec π(θ) ∝θa−1(1 −θ)b−1.
a. Formuler des conditions n´ecessaires et suﬃsantes sur (a, b) pour que la dis-
tribution a posteriori soit d´eﬁnie et que la distribution a priori soit impropre.
b. Expliciter le noyau de transition (8.7) pour b = k.
c. Montrer que la chaˆıne de Markov correspondante (θ(t)) peut s’´ecrire θ(t+1) =
θ(t)/(ωt + θ(t)), les ωt ´etant i.i.d.
d. Montrer que E[log ωt] = 0 si et seulement si a = 0 et en d´eduire que la
chaˆıne (θ(t)) est r´ecurrente lorsque a = 0 et transiente sinon ;
8.41 Pour le noyau de transition (8.18),

460
8 Admissibilit´e et classes compl`etes
a. Montrer que la mesure stationnaire est π(θ)Ψ(θ), o`u π est la distribution
a priori et Ψ(θ) est la constante de normalisation en T(θ, η). (Indication :
Prouver que la condition de balance ponctuelle est v´eriﬁ´ee et utiliser l’´egalit´e
π(θ)f(x|θ)π(η|x) = π(η)f(x|η)π(θ|x).)
b. En d´eduire que la chaˆıne est r´ecurrente positive lorsque le risque de Bayes
Z Z
(ϕ(θ) −E[ϕ(θ)|x])2 f(x|θ)π(θ)dxdθ
est ﬁni.
8.7 Notes
8.7.1 Compl´ements sur la condition suﬃsante d’admissibilit´e d’Eaton
Hobert et Robert (1999) montrent que la condition suﬃsante de Eaton (1992)
s’applique ´egalement `a une chaˆıne duale, avec noyau de transition
K∗(x, y) =
Z
Θ
f(x|θ)π(θ|x) dθ,
(8.16)
puisque les deux noyaux K dans (8.7) et K∗sont de mˆeme nature, c’est-`a-dire
qu’ils sont soit tous deux r´ecurrents, soit tous deux transients. Ce r´esultat de
dualit´e est particuli`erement int´eressant lorsque l’espace d’´echantillonnage est
plus simple que l’espace des param`etres, par exemple lorsque K∗porte sur un
espace d’´etats ﬁni. (Cette propri´et´e a ´et´e utilis´ee dans un contexte compl`etement
diﬀ´erent par Diebolt et Robert, 1994, pour aﬃner les propri´et´es de convergence
d’un ´echantillonneur de Gibbs dans des mod`eles `a variables latentes. Voir Robert
et Casella, 2004, Section 9.2.3.) Hobert et Robert (1999) illustrent l’int´erˆet de
cette condition dans des cadres classiques (Exercices 8.39 et 8.40).
Exemple 8.43. Soit un mod`ele gamma, x ∼G a(α, θ), avec π(θ) ∝θα−1
exp{−bθ}. La loi a posteriori est d´eﬁnie lorsque b ≥0 et a > −α. Alors que le
noyau de transition K ne peut pas ˆetre calcul´e analytiquement, K∗s’´ecrit
K∗(x, y) = Γ(2α + a)Γ(b + x)α+a
Γ(α + a)Γ(α)
yα−1
(x + y + b)2α+a .
(8.17)
Hobert et Robert (1999) montrent ensuite que ce noyau est r´ecurrent si, et
seulement si, a = 0 (Exercice 8.38).
∥
Eaton (1999) g´en´eralise le r´esultat publi´e par Eaton (1992) `a des fonctions
arbitraires de θ, ϕ(θ), estim´ees sous coˆut quadratique, `a l’aide d’une autre
repr´esentation markovienne. Au lieu du K(θ|η) d´eﬁni par (8.7), Eaton (1999)
propose d’utiliser le noyau de transition
T(θ|η) = Ψ(η)−1(ϕ(θ) −ϕ(η))2K(θ|η) ,
(8.18)
o`u Ψ(θ) est le facteur de normalisation de cette densit´e. Un ´equivalent du
Th´eor`eme 8.19 dans ce cas est que l’estimateur de Bayes Eπ[ϕ(θ)|x] est ad-
missible lorsque la chaˆıne de Markov associ´ee `a T est r´ecurrente. Bien que la
proc´edure ne soit pas compl`etement g´en´erale, puisque une ´etude de la chaˆıne

8.7 Notes
461
de Markov est n´ecessaire pour chaque fonction ϕ remarquable, l’extension aux
fonctions ϕ non born´ees lui conf`ere un int´erˆet ind´eniable. (Comme le sugg`ere
Eaton, 1999, ce r´esultat s’´etend `a l’estimation de fonctions vectorielles ϕ(θ) sous
coˆut quadratique.)
Exemple 8.44. Dans le cas particulier d’une famille de position, si f(x|θ) =
g(x −θ) et si θ est estim´e sous la fonction de coˆut L(θ, d) = (θ −d)2, alors le
noyau de Markov K associ´e `a l’a priori plat π(θ) = c est
K(θ|η) =
Z
g(x −θ)g(x −η)dx = r(θ −η) ,
par un changement ad´equat d’int´egrande dans l’int´egrale. Le noyau de transition
est
T(θ, η) ∝(θ −η)2r(θ −η) = t(θ −η)
et le facteur de proportionnalit´e est ind´ependant de θ. Par cons´equent, la chaˆıne
de Markov associ´ee `a T est une marche al´eatoire. Elle est r´ecurrente en di-
mension un si le premier moment de t existe. Eaton (1999) montre que cette
condition est ´equivalente `a l’existence d’un troisi`eme moment de g.
∥

9
Invariance, mesures de Haar et estimateurs
´equivariants
“The ring certainly looked like stone, but it felt harder than steel
and heavier than lead. And the circle of it was twisted. If she ran a
ﬁnger along one edge, it would go around twice, inside as well as out ;
it only had one edge.”
Robert Jordan, The Dragon Reborn.
9.1 Principes d’invariance
La notion d’invariance a ´et´e introduite dans un cadre fr´equentiste essen-
tiellement pour r´eduire de fa¸con consid´erable le nombre d’estimateurs accep-
tables, de sorte qu’un estimateur optimal puisse ˆetre trouv´e. De ce point de
vue, cette notion est une alternative au concept d’estimation sans biais et
n’est donc pas pertinente pour le paradigme bay´esien. Cependant, il existe
une autre raison de faire appel `a l’invariance qui n’est pas li´ee `a la Th´eorie
de la D´ecision : on peut exiger des estimateurs recherch´es des propri´et´es de
convergence `a l’´egard d’un certain nombre de transformations et il est alors
logique de s’int´eresser `a cette notion. En outre, les estimateurs optimaux
(´equivariants) sont toujours de Bayes ou de Bayes g´en´eralis´es. Les mesures
correspondantes peuvent alors ˆetre consid´er´ees comme des lois a priori non
informatives d´ecoulant de la structure d’invariance. Au-del`a du fait que l’op-
timalit´e classique sugg`ere de nouveau des estimateurs de Bayes, c’est donc
surtout le lien entre structures d’invariance et distributions non informatives
qui nous pousse `a ´etudier l’invariance d’un point de vue bay´esien.

464
9 Invariance
Une premi`ere version du principe d’invariance est de consid´erer que les
propri´et´es d’une proc´edure statistique ne devraient pas d´ependre de l’unit´e
de mesure utilis´ee. Si x et θ sont mesur´es en une unit´e u1 et si y et η sont
les transform´es de x et θ pour une autre unit´e u2, alors un estimateur δ2(y)
de η devrait correspondre `a l’estimateur δ1(x) de θ par le mˆeme changement
d’unit´e. Insistons sur la g´en´eralit´e de cette notion d’unit´e de mesure : par
exemple, cela peut ˆetre un simple choix d’´echelle (cm contre m)–auquel cas
on exige des estimateurs qu’ils soient ´equivariants par changement d’´echelle–le
choix d’une origine particuli`ere–on parle dans ce cas d’´equivariance par chan-
gement de position–ou encore le choix de l’ordonnancement des observations
dans un ´echantillon x–on se restreint alors aux estimateurs sym´etriques69.
Exemple 9.1. On consid`ere le probl`eme d’estimation de la vitesse de la
lumi`ere, θ, `a partir d’une observation x, distribu´ee selon U ([θ −ϵ, θ + ϵ]),
et mesur´ee en m`etres par seconde. Un changement d’unit´e typique dans ce
contexte est le changement d’´echelle, y = τx, avec, par exemple, τ = 10−3
pour une conversion de m`etres en kilom`etres. Dans ce cas, y ∼U ([η−ϵ′, η+ϵ′])
avec η = τθ, ϵ′ = τϵ, mais η repr´esente toujours la mˆeme quantit´e intrins`eque,
`a savoir la vitesse de la lumi`ere. Si δ0 est un estimateur de θ dans l’unit´e ini-
tiale, il semble l´egitime d’exiger que l’estimateur dans le probl`eme transform´e
δ∗v´eriﬁe la propri´et´e d’´equivariance d’´echelle
δ∗(y) = τδ0(y/τ).
En outre, on suppose que le coˆut est le coˆut quadratique ajust´e
L(θ, d) =

1 −d
θ
2
.
Il satisfait
L(θ, d) =

1 −τd
τθ
2
=

1 −d∗
η
2
= L(η, d∗)
lorsque d∗= τ d. Par cons´equent, le coˆut est invariant par ce changement
d’unit´e et les deux probl`emes d’estimation sont formellement identiques. Il est
alors logique de choisir le mˆeme estimateur pour les deux probl`emes, δ∗(y) =
δ0(y). On obtient en regroupant les deux ´equations
δ0(τy) = τδ0(y)
quels que soient τ et y. Finalement, les r`egles de d´ecision compatibles avec
les exigences d’invariance sont n´ecessairement de la forme δ0(x) = ax, avec a
constante positive.
∥
69Comme nous avons discut´e au Chapitre 2, il est rare de pouvoir obtenir une
invariance absolue o`u l’estimateur de toute transformation est la transformation
d’un mˆeme estimateur, `a moins d’imposer des coˆuts invariants fonctionnels comme
dans la Section 2.5.4.

9.2 Le cas particulier des param`etres de position
465
Ce principe est souvent ´elargi en un principe d’invariance formelle, stipu-
lant que deux probl`emes de structure formelle identique, (X , f(x|θ), L), de-
vraient ˆetre trait´es avec la mˆeme r`egle de d´ecision, qu’ils soient physiquement
li´es, comme dans le principe d’invariance restreint, ou pas. Dans l’exemple
pr´ec´edent, la vitesse de la lumi`ere est toujours le mˆeme objet. Cette exten-
sion n’est pas forc´ement naturelle d’un point de vue bay´esien dans la mesure
o`u l’information a priori n’a aucune raison d’ˆetre identique dans les deux
probl`emes. C’est donc uniquement dans les cadres non informatifs que les
deux approches sont compatibles.
Une approche bay´esienne de l’invariance est justiﬁ´ee par les trois raisons
suivantes :
(i) Le meilleur estimateur invariant (ou ´equivariant) est un estimateur de
Bayes g´en´eralis´e pour une mesure particuli`ere, dite mesure de Haar.
(ii) Cette mesure convient d’autant mieux dans les contextes non informa-
tifs que l’invariance sugg`ere une m´ethode alternative pour construire des
distributions a priori non informatives.
(iii) La m´ethode la plus eﬃcace pour obtenir les meilleurs estimateurs
´equivariants est l’approche bay´esienne.
Par cons´equent, les consid´erations d’invariance vont dans le sens du pa-
radigme bay´esien, puisqu’il recouvre une fois de plus un crit`ere fr´equentiste
d’optimalit´e. Dans ce chapitre, nous d´etaillons le lien entre invariance et ap-
proche bay´esienne dans le cas des param`etres de position dans la Section 9.2,
avant de pr´esenter le cadre g´en´eral de l’invariance au cours de la Section 9.3,
puis la mesure de Haar en tant qu’a priori non informatif potentiel en Sec-
tion 9.4 et le th´eor`eme de Hunt-Stein, qui relie invariance et minimaxit´e, en
Section 9.5. (Pour des ´etudes plus d´etaill´ees sur l’invariance et des points de
vue g´en´eraux ou bay´esiens, les lecteurs pourront se reporter `a Berger, 1985b,
Chapitre 6, Eaton, 1989, et Wijsman, 1990.)
9.2 Le cas particulier des param`etres de position
Soit (x1, . . . , xn) de densit´e f(x1−θ, . . . , xn−θ), avec un param`etre de posi-
tion inconnu θ ∈R. Le degr´e naturel d’invariance du probl`eme est l’invariance
par translation. Si (x1, . . . , xn) subit la transformation
(y1, . . . , yn) = (x1 + a, . . . , xn + a) ,
la nouvelle variable al´eatoire (y1, . . . , yn) est distribu´ee selon f(y1 −θ −
a, . . . , yn −θ −a) et η = θ +a est le param`etre de position correspondant. Par
cons´equent, le vecteur transform´e a le mˆeme type de densit´e et le probl`eme
est invariant par translation. Il semble naturel de reproduire l’invariance en
exigeant la condition suivante sur les estimateurs δ de θ :
δ(x1 + a, . . . , xn + a) = δ(x1, . . . , xn) + a.
(9.1)

466
9 Invariance
Cette condition est satisfaite, par exemple, par δ0(x1, . . . , xn) = ¯x. En outre,
il paraˆıt ´egalement logique d’imposer la mˆeme restriction d’invariance sur la
fonction de coˆut, `a savoir que L(θ + a, d + a) = L(θ, d) pour tout a. Une
fonction de coˆut compatible avec la structure d’invariance devrait donc ˆetre
de la forme
L(θ, d) = L(0, d −θ) = ϱ(d −θ).
(9.2)
Les estimateurs v´eriﬁant (9.1) sont appel´es ´equivariants et les fonctions de
coˆut r´epondant `a (9.2) invariantes, sous l’action d’un groupe de translations.
Le but de ces contraintes est de r´eduire la classe des estimateurs “acceptables”
de fa¸con suﬃsamment signiﬁcative pour qu’il n’y ait ﬁnalement plus qu’un
seul meilleur estimateur ´equivariant sous le coˆut (9.2), puisque cela n’est pas
possible autrement (Exercice 2.36). Le lemme suivant explique pourquoi on
peut envisager l’unicit´e d’un estimateur optimal.
Lemme 9.2. Pour des fonctions de coˆut de la forme (9.2), les estimateurs
´equivariants ont un risque constant.
Preuve.
On a
R(δ, θ) = Eθ[ϱ(δ(x) −θ)]
= Eθ[ϱ(δ(x1 −θ, . . . , xn −θ))]
= E0[ϱ(δ(x1, . . . , xn))] = R(δ, 0).
⊓⊔
Par cons´equent, on retrouve dans le cas particulier des estimateurs ´equiva-
riants sous coˆut ´equivariant une situation analogue `a celle de l’ensemble des
estimateurs consid´er´es sous risque bay´esien : il existe un ordre total sur cette
classe restreinte, puisque comparer deux estimateurs est ´equivalent `a compa-
rer deux nombres r´eels. C’est la raison pour laquelle un meilleur estimateur
´equivariant peut exister.
Ce meilleur estimateur est classiquement d´eduit en conditionnant par rap-
port `a une statistique libre maximale, telle que y = (x1 −xn, . . . , xn−1 −xn).
On v´eriﬁe alors de fa¸con imm´ediate que tout estimateur ´equivariant peut
s’´ecrire δ0(x) + v(y), o`u δ0 est un estimateur ´equivariant particulier, par
exemple δ0(x) = xn.
Lemme 9.3. S’il existe une fonction v∗(y) qui minimise
E0[ϱ(δ0(x) + v(y))|y],
le meilleur estimateur ´equivariant sous le coˆut (9.2) est
δ∗(x) = δ0(x) + v∗(y).

9.2 Le cas particulier des param`etres de position
467
Preuve.
Par d´eﬁnition, le meilleur estimateur ´equivariant minimise (en v) le
risque constant
R(δ, θ) = E0[ϱ(δ(x))] = E0[ϱ(δ0(x) + v(y))].
On peut conditionner par rapport `a y, puisque c’est une statistique libre, en
d´ecomposant le risque en
E0[ϱ(δ0(x) + v(y))] = E [E0[ϱ(δ0(x) + v(y))|y]] .
Si v∗(y) minimise l’int´egrande pour tout y, δ∗minimise le risque dans la classe
des estimateurs ´equivariants.
⊓⊔
Dans le cas particulier o`u ϱ(δ −θ) = (δ −θ)2, le facteur v∗optimal est
donn´e par
v∗(y) = −E0[δ0(x)|y].
Nous avons ainsi obtenu le meilleur estimateur ´equivariant de Pitman (1939).
Corollaire 9.4. Pour le coˆut quadratique L(θ, d) = (θ −d)2, le meilleur
estimateur ´equivariant de θ est
δ∗(x1, . . . , xn) =
 +∞
−∞θf(x1 −θ, . . . , xn −θ) dθ
 +∞
−∞f(x1 −θ, . . . , xn −θ) dθ
.
Preuve.
On prend δ0(x) = xn en tant qu’estimateur ´equivariant particulier
pour le Lemme 9.3 et on note yn = xn pour compl´eter y. La densit´e de
(y1, . . . , yn) est alors (pour θ = 0)
gY (y1, . . . , yn) = f(y1 + yn, . . . , yn−1 + yn, yn),
car yi = xi −xn (i ̸= n) et le d´eterminant du jacobien est ´egal `a 1. De plus,
E0[yn|y1, . . . , yn−1] =
 +∞
−∞tf(y1 + t, . . . , yn−1 + t, t) dt
 +∞
−∞f(y1 + t, . . . , yn−1 + t, t) dt
=
 +∞
−∞tf(x1 −xn + t, . . . , xn−1 −xn + t, t) dt
 +∞
−∞f(x1 −xn + t, . . . , xn−1 −xn + t, t) dt
= xn −
 +∞
−∞θf(x1 −θ, . . . , xn−1 −θ, xn −θ) dθ
 +∞
−∞f(x1 −θ, . . . , xn −θ) dθ
,
par le changement de variable θ = xn −t. Avec
δ∗(x1, . . . , xn) = xn −E0[yn|y1, . . . , yn−1],
on d´eduit l’expression donn´ee ci-dessus pour δ∗.
⊓⊔

468
9 Invariance
L’int´erˆet principal du Corollaire 9.4 est, outre qu’il fournit le meilleur es-
timateur ´equivariant, de pr´esenter cet estimateur comme un estimateur de
Bayes, bien que le calcul ne fasse intervenir aucune technique bay´esienne.
L’estimateur de Pitman est bien un estimateur de Bayes associ´e `a la distribu-
tion a priori π(θ) = 1, c’est-`a-dire la distribution non informative habituelle
des param`etres de position (Chapitre 3). Ce r´esultat est d’ailleurs valable
pour d’autres coˆuts invariants (9.2), comme nous le verrons en Section 9.4.
Par cons´equent, le meilleur estimateur ´equivariant peut ˆetre d´etermin´e comme
l’estimateur δ qui minimise le coˆut a posteriori
Eπ[L(θ, δ)|x] =
 +∞
−∞ϱ(θ −δ)f(x1 −θ, . . . , xn −θ) dθ
 +∞
−∞f(x1 −θ, . . . , xn −θ) dθ
,
ou, de mani`ere ´equivalente,
 +∞
−∞
ϱ(θ −δ)f(x1 −θ, . . . , xn −θ) dθ,
et cette repr´esentation simpliﬁe grandement le calcul des meilleurs estimateurs
´equivariants. Nous verrons dans la Section 9.4 que le lien entre meilleurs esti-
mateurs ´equivariants et une classe particuli`ere d’estimateurs de Bayes existe
de fa¸con beaucoup plus g´en´erale que pour le probl`eme d’estimation de pa-
ram`etres de position.
9.3 Probl`emes de d´ecision invariants
Nous pr´esentons `a pr´esent une description abstraite du concept d’inva-
riance au moyen de groupes d’invariance qui nous permettra de g´en´eraliser le
lien entre probl`emes invariants et analyse bay´esienne. Soient un mod`ele sta-
tistique (X , Θ, f(x|θ)) et un probl`eme d’inf´erence sur θ repr´esent´e par un
espace de d´ecision, D. En outre, on suppose donn´e un groupe G de transfor-
mations sur X . (On peut aussi le voir comme une forme particuli`ere d’infor-
mation a priori.) Nous allons maintenant illustrer l’importance de l’existence
d’un tel groupe dans plusieurs cas.
D´eﬁnition 9.5. Le mod`ele statistique est dit invariant (ou ferm´e) sous l’ac-
tion du groupe G si, pour tout g ∈G , il existe un unique θ∗∈Θ tel que
y = g(x) soit distribu´e selon la densit´e f(y|θ∗). On note θ∗= ¯g(θ).
Exemple 9.6. On consid`ere x ∼f(x −θ) et le groupe des translations
G = {gc; gc(x) = x + c, c ∈R} .
Le mod`ele statistique est invariant sous l’action de G . Ce n’est pas le cas avec
le groupe multiplicatif

9.3 Probl`emes de d´ecision invariants
469
G ′ = {gc; gc(x) = cx, c > 0} ,
puisque
y = cx ∼1
cf
y −cθ
c

.
∥
Lorsque le groupe G a une action globalement invariante sur le mod`ele,
on peut d´eﬁnir naturellement un ensemble
¯
G de transformations sur Θ. La
preuve que
¯
G est aussi un groupe est laiss´ee aux lecteurs `a titre d’exercice.
Dans un souci de simpliﬁcation, nous adopterons les notations suivantes dans
ce qui suit : gx pour g(x) et ¯gθ pour ¯g(θ).
On suppose de plus que la fonction de coˆut associ´ee au mod`ele, L de
Θ × D dans R+, est discriminante, c’est-`a-dire que deux d´ecisions diﬀ´erentes
se verront aﬀect´ees des coˆuts diﬀ´erents. En outre, on fait l’hypoth`ese de com-
patibilit´e suivante avec la structure d’invariance.
D´eﬁnition 9.7. Si le mod`ele est invariant sous l’action de G , le coˆut L est
dit invariant sous G si, quels que soient g ∈G et d ∈D, il existe une unique
d´ecision d∗∈D telle que L(θ, d) = L(¯gθ, d∗) pour tout θ ∈Θ. On note cette
d´ecision d∗= ˜g(d) et on dit que le probl`eme de d´ecision est invariant sous G .
Dans ce cas, le groupe G induit un second groupe
˜
G , agissant sur D.
´Etant donn´e ces trois groupes G ,
¯
G , et ˜
G , et les hypoth`eses ci-dessus sur le
probl`eme de d´ecision, il semble logique de restreindre la classe des estimateurs
consid´er´es aux estimateurs ´equivariants, c’est-`a-dire `a ceux qui satisfont
δ(gx) = ˜gδ(x).
Dans des r´ef´erences plus anciennes, on qualiﬁe parfois ´egalement ces esti-
mateurs d’invariants. Un cas particulier int´eressant est l’estimation de θ, o`u
D = Θ, puisque G = ˜
G dans ce contexte.
Exemple 9.8. (Suite de l’Exemple 9.6) On cherche `a estimer θ sous coˆut
quadratique (θ −d)2. Le probl`eme d´ecisionnel est alors invariant et ¯
G = ˜
G =
G .
∥
Exemple 9.9. Soit x ∼N (0, σ2). La variance σ2 est estim´ee sous le coˆut
entropique,
L(σ, δ) = δ
σ2 −log(δ/σ2) −1,
pr´esent´e au Chapitre 2. Si on s’int´eresse au groupe des transformations
d’´echelle,
G = {gc; gc(x) = cx, c > 0} ,

470
9 Invariance
les groupes associ´es sont
¯
G = ˜
G =

¯gc(σ2) = c2σ2, c > 0

et le coˆut, donc le probl`eme de d´ecision, est ´egalement invariant sous l’action
de G .
∥
Exemple 9.10. Soient x ∼Tp(ν, θ, Ip) et ||θ||2 le param`etre d’int´erˆet. Une
structure naturelle d’invariance est l’invariance sous transformations orthogo-
nales,
G = ¯
G =

gA; gA(x) = Ax, AtA = Ip

,
et le probl`eme est invariant si le coˆut peut s’´ecrire
L(θ, δ) = ˜L(||θ||2, δ),
puisqu’il existe toujours une matrice orthogonale A telle que Aθ = ||θ||(1, 0, . . . ,
0)t et ˜
G contient juste la transformation identit´e. Dans ce cas, les estimateurs
´equivariants d´ependent uniquement de ||x||2.
∥
D´eﬁnition 9.11. Quand ¯
G est un groupe agissant sur Θ, θ1 et θ2 sont dits
´equivalents s’il existe ¯g ∈¯
G avec θ2 = ¯gθ1. Une orbite de Θ est une classe
d’´equivalence pour cette relation et le groupe ¯
G est dit transitif si Θ n’a qu’une
seule orbite.
Si le groupe G est suﬃsamment petit, il peut y avoir de nombreuses orbites.
Par exemple, quand x ∼B(n, p) et G est restreint `a g0(x) = x et g1(x) =
n −x,
¯
G = {¯g0, ¯g1} avec ¯g1(p) = 1 −p. Il y a donc une orbite associ´ee `a
chaque p ∈[0, 0.5]. Quand G est plus grand, cette notion permet souvent de
g´en´eraliser le ph´enom`ene observ´e pour les param`etres de position.
Th´eor`eme 9.12. Le risque d’un estimateur ´equivariant est constant dans
toute orbite de Θ, c’est-`a-dire que
R(δ, θ) = R(δ, ¯gθ)
quel que soit g ∈G .
Preuve.
Comme pour les estimateurs de param`etres de position, on a
R(δ, θ) = Eθ [L(θ, δ(x))] = Eθ [L(¯gθ, ˜gδ(x))]
= Eθ [L(¯gθ, δ(gx))]
= E¯gθ [L(¯gθ, δ(x))]
= R(δ, ¯gθ)
pour tout g ∈G .
⊓⊔

9.3 Probl`emes de d´ecision invariants
471
Le r´esultat suivant est une cons´equence imm´ediate du Th´eor`eme 9.12.
Corollaire 9.13. Si ¯
G est transitif, tout estimateur ´equivariant a un risque
constant.
Pour des groupes transitifs, il est donc l´egitime de chercher le meilleur esti-
mateur ´equivariant en minimisant le risque constant R(δ, θ0) dans la classe des
estimateurs ´equivariants. N´eanmoins, il n’est pas pour autant toujours facile
d’avoir recours aux statistiques libres, comme dans la Section 9.2. Une solution
classique est de consid´erer la statistique invariante maximale pour r´eduire la
dimension du probl`eme, de mˆeme qu’on utilise des statistiques exhaustives
minimales avec des coˆuts convexes.
D´eﬁnition 9.14. Pour un groupe de transformations G , une statistique T (x)
est invariante si T (gx) = T (x) quels que soient x ∈X et g ∈G . On parle
de statistique invariante maximale si T est invariante et si T (x1) = T (x2)
implique l’´equivalence de x1 et x2.
En d’autres termes, une statistique invariante maximale indexe les or-
bites de ¯
G . En particulier, si ¯
G est transitif, les seules statistiques invariantes
maximales sont constantes. De plus, il est alors clair que toute statistique in-
variante est une fonction d’une statistique invariante maximale. Remarquons
enﬁn que, si ¯
G est transitif, T (x) est n´ecessairement libre.
Exemple 9.15. Soit une distribution munie d’un param`etre d’´echelle σ,
x = (x1, . . . , xn) ∼1
σn f
x1
σ , . . . , xn
σ

,
et G d´esigne le groupe multiplicatif, constitu´e des transformations
gc(x1, . . . , xn) = (cx1, . . . , cxn)
(c > 0).
Alors, si z = ||x||,
T (x) =

0
si z = 0,
x
z
sinon,
est une statistique invariante maximale.
∥
Exemple 9.16. (Suite de l’Exemple 9.10) De fa¸con analogue, si z = ||x||,
la statistique
T (x) =

0
si z = 0,
x
z
sinon,
est ´egalement invariante maximale pour ce probl`eme.
∥

472
9 Invariance
Pour d´eterminer le meilleur estimateur ´equivariant, on peut faire appel `a
la statistique invariante maximale par conditionnement. (Il faut noter que le
choix d’une statistique invariante maximale particuli`ere n’a pas d’importance
puisque, toutes les statistiques invariantes maximales ´etant en bijection, elles
g´en`erent toutes la mˆeme σ-alg`ebre.) En fait, si ¯
G est transitif et T est une
statistique invariante maximale, tout estimateur ´equivariant δ satisfait
R(δ, θ) = R(δ, θ0)
= Eθ0[L(θ0, δ(x))]
= ET
θ0{Eθ0[L(θ0, δ(x))|T (x) = t]}
pour une valeur arbitraire de θ0 (puisque le risque est constant). Comme T est
invariante maximale, tout x tel que T (x) = t peut s’´ecrire gxt, o`u xt est un
membre ad´equat de l’orbite de x (en supposant l’axiome du choix). Alors, pour
un estimateur ´equivariant, δ(x) = ˜gδ(xt). Il est donc suﬃsant de minimiser la
quantit´e ci-dessus en δ(xt), conditionnellement `a T , pour obtenir le meilleur
estimateur ´equivariant. Bien que simple, le conditionnement ci-dessus se r´ev`ele
essentiel dans la d´etermination des meilleurs estimateurs ´equivariants et sera
r´eutilis´e dans la suite.
Exemple 9.17. (Suite de l’Exemple 9.15) Remarquons que, dans ce cas,
T est ´egalement une statistique libre. Pour le coˆut entropique, le probl`eme de
minimisation (en δ) est
E1[δ(x) −log δ(x)|T (x) = t] = E1[δ(zt) −log δ(zt)|T (x) = t]
= E1[zδ(t) −log δ(t) −log(z)|T (x) = t]
(avec z = ||x||). Par lin´earit´e de l’esp´erance, δ(t) minimise
E1[z|T = t]δ(t) −log δ(t),
et v´eriﬁe donc
δ∗(t) =
1
E1[z|T = t].
Le meilleur estimateur ´equivariant de σ est donc
δ∗(x) =
||x||
E1[z|T = x/||x||] .
Dans le cas particulier o`u xi ∼N (0, σ2), on en d´eduit que le meilleur esti-
mateur ´equivariant de σ est
δ∗(x) =
||x||
E1(||x||) =
Γ(p/2)
√
2Γ(p + 1/2) ||x||.
∥
De plus amples d´etails sur cette technique ﬁgurent dans Berger (1985b,
Section 6.5) et Eaton (1989, Section 2.3).

9.4 Distributions non informatives ´equivariantes
473
9.4 Meilleurs estimateurs ´equivariants et distributions
non informatives
Nous nous int´eressons `a pr´esent `a la g´en´eralisation du r´esultat de la Section
9.2, obtenu dans le cas particulier des param`etres de position. Nous montrons
qu’il est eﬀectivement possible d’´etablir un lien entre le meilleur estimateur
´equivariant et une mesure σ-ﬁnie sur Θ qui est en fait la mesure de Haar
invariante `a droite. Pour une ´etude plus d´etaill´ee et rigoureuse, les lecteurs
pourront consulter Eaton (1989) et Wijsman (1990).
Supposons d’abord que, pour un probl`eme statistique invariant sous l’ac-
tion de G , il existe une densit´e de probabilit´e π∗sur Θ ´egalement invariante
sous l’action de ¯
G , c’est-`a-dire telle que
π∗(¯gA) = π∗(A)
pour tout ensemble mesurable de Θ, soit pour tout A ∈B(Θ), et pour tout
g ∈G . Dans ce cas, l’estimateur de Bayes associ´e `a π∗, δ∗, minimise

Θ
R(δ∗, θ) dπ∗(θ) =

Θ
R(δ∗, ¯gθ) dπ∗(θ)
=

Θ
Eθ
#
L(θ, ˜g−1δ∗(gx))
$
dπ∗(θ)
et, si l’estimateur de Bayes est unique, il v´eriﬁe
δ∗(x) = ˜g−1δ∗(gx)
π-presque partout, l’ensemble de mesure nulle sur lequel l’´egalit´e n’est pas
satisfaite d´ependant de la fonction g. Par cons´equent, un estimateur de Bayes
associ´e `a un a priori invariant et `a un coˆut invariant strictement convexe est
presque ´equivariant. Lorsque G n’est pas d´enombrable, la r´eunion (sur tous
les g) des ensembles de mesure nulle ci-dessus n’est pas n´ecessairement de
mesure nulle mais il est possible de montrer, moyennant quelques hypoth`eses
suppl´ementaires (Lehmann, 1986, Chapitre 6, Th´eor`eme 4), qu’il existe un
estimateur ´equivariant qui est un estimateur de Bayes pour π∗(voir aussi
Strasser, 1985).
Exemple 9.18. On consid`ere δπ(x) = Eπ[θ|x] sous coˆut propre invariant. Si
π∗est une distribution de probabilit´e invariante, l’estimateur de Bayes associ´e
`a π∗v´eriﬁe
δπ(gx) =

Θ θf(gx|θ) dπ∗(θ)

Θ f(gx|θ) dπ∗(θ)
=

Θ θf(x|¯g−1θ) dπ∗(θ)

Θ f(x|¯g−1θ) dπ∗(θ)
=

Θ ¯gηf(x|η) dπ∗(η)

Θ f(x|η) dπ∗(η) .

474
9 Invariance
Donc, si

Θ
¯gηf(x|η) dπ∗(η) = ¯g

Θ
ηf(x|η) dπ∗(η),
quel que soit g ∈G , δ∗est bien ´equivariant.
∥
Les distributions de probabilit´e invariantes sont plutˆot rares en pratique,
puisqu’elles ne peuvent exister que sur des groupes compacts70 ¯
G (voir Leh-
mann, 1983, Chapitre 4, Exemple 4.2 pour un exemple sur un groupe non
d´enombrable). Dans d’autres contextes, il est n´ecessaire de consid´erer des me-
sures invariantes, pour lesquelles les r´esultats d´evelopp´es ci-dessus ne sont
pas toujours vrais (car les estimateurs de Bayes formels ne sont pas toujours
d´eﬁnis).
Exemple 9.19. (Suite de l’Exemple 9.6) Si π est invariante sous l’action
du groupe de translation, elle v´eriﬁe π(θ) = π(θ + c) quels que soient θ et c,
ce qui implique en particulier π(θ) = π(0) uniform´ement sur R et fait donc
de la mesure de Lebesgue une mesure invariante.
∥
Exemple 9.20. Soit x1, . . . , xn un ´echantillon de N (θ, σ2), avec θ et σ2 in-
connus. En utilisant un argument d’exhaustivit´e, on peut ´etudier uniquement
le couple (¯x, s), avec ¯x moyenne empirique et s2 somme des erreurs quadra-
tiques. Dans ce cadre, le groupe `a consid´erer est le groupe aﬃne
G = {ga,b; ga,b(¯x, s) = (a¯x + b, as), a > 0, b ∈R} ,
et
¯
G =
˜
G = G si le param`etre `a estimer est (θ, σ). Si π est une mesure
invariante, sa densit´e v´eriﬁe
a2π(aθ + b, aσ) = π(θ, σ),
∀a > 0, ∀b ∈R ,
ce qui implique
π(θ, σ) = π(0, 1)/σ2.
Par cons´equent, une mesure invariante est proportionnelle `a π(θ, σ) = 1/σ2
et rappelle la mesure de Jeﬀreys vue dans le Chapitre 3.
∥
D’une fa¸con g´en´erale, ´etant donn´e un groupe topologique localement com-
pact G et en notant K(G ) l’ensemble des fonctions r´eelles continues sur G `a
support compact, on d´eﬁnit, pour tout g ∈G , la transformation Lg sur K(G )
70Quand ¯
G n’est pas un sous-ensemble de Rp, la structure topologique induite par
¯
G est la topologie induite par la composition de groupe et l’inversion, c’est-`a-dire
la plus petite collection d’ensembles ouverts telle que la composition de groupe et
l’inversion soient continues (voir Rudin, 1976).

9.4 Distributions non informatives ´equivariantes
475
(Lgf)(x) = f(gx)
pour f ∈K(G ), x ∈G .
Une int´egrale J sur K(G ) est dite invariante `a gauche si
J(Lgf) = J(f)
quels que soient f ∈K(G ) et g ∈G . La mesure de Radon νℓassoci´ee `a J
est dite mesure de Haar `a gauche, et on peut montrer (Nachbin, 1965) que
cette mesure est unique `a une constante multiplicative pr`es. On d´eﬁnit Rg sur
K(G ) par
(Rgf)(x) = f(xg),
pour f ∈K(G ), x ∈G ,
et on d´erive de mani`ere analogue des int´egrales invariantes `a droite et une
mesure de Haar `a droite νr, ´egalement d´eﬁnie `a un facteur pr`es. Comme
nous l’avons ´enonc´e ci-dessus, la ﬁnitude de la mesure de Haar, c’est-`a-dire
l’existence d’une distribution de probabilit´e invariante, est en fait ´equivalente
`a la compacit´e de G . Voir Eaton (1989, Chapitre 1) pour des exemples de
mesures de Haar ; Berger (1985b) s’int´eresse au cas o`u G ⊂Rk.
La d´eﬁnition du module de G est le multiplicateur Δ–qui est une fonction
r´eelle v´eriﬁant Δ(g1g2) = Δ(g1)Δ(g2)–reliant ainsi les mesures de Haar `a
droite et `a gauche :
νr(dx) = Δ(x−1)νℓ(dx)
(Exercices 9.13 et 9.15). On suppose l’existence d’une mesure de Radon μ sur
X telle que, pour tout f,

X
f(g−1x)μ(dx) = Δ−1(g)

X
f(x)μ(dx).
Cette relation ´etablit une connexion entre le module de G et le jacobien de
la transformation de x en gx. Soient les distributions Pθ, θ ∈Θ, de densit´e
f(x|θ) par rapport `a μ. Alors, pour tout g ∈G ,
f(x|θ) = f(gx|¯gθ)Δ−1(g).
On fait ´egalement l’hypoth`ese que ¯
G agit transitivement sur Θ. En ajoutant
quelques conditions, Eaton (1989, p. 84) d´emontre alors un th´eor`eme appa-
rent´e `a celui de Fubini : Si νr est la mesure de Haar `a droite sur G , si Q est
la projection de X sur X /G et si (Tf) est d´eﬁni sur X /G par
(Tf)(Q(x)) =

G
f(gx)νr(dg),
alors il existe une int´egrale J1 d´eﬁnie sur K(X /G ) telle que
J1(Tf) =

X
f(x)μ(dx).

476
9 Invariance
Ainsi l’int´egrale de f par rapport `a μ est l’int´egrale sur toutes les orbites de
X (c’est-`a-dire sur X /G ) de la moyenne de f par rapport `a la mesure de
Haar `a droite sur chaque orbite, Tf.
Soit un estimateur δ et, pour θ ∈Θ ﬁx´e, posons
f0(x) = L(θ, δ(x))f(x|θ),
alors
R(δ, θ) =

X
f0(x)μ(dx).
Il vient du th´eor`eme ci-dessous qu’il existe une int´egrale J1 sur K(X /G ) telle
que
R(δ, θ) = J1(Tf0),
avec
(Tf0)(Q(x)) =

G
L(θ, δ(gx))f(gx|θ)νr(dg)
=

G
L(¯gθ, δ(x))f(x|¯gθ)νr(dg)
(voir Eaton, 1989, p. 85). D´eﬁnissons aussi
H(a, x) =

G
L(¯gθ, a)f(x|¯gθ)νr(dg),
qui ne d´epend pas de θ (puisque ¯
G agit transitivement sur Θ). Remarquons
que H(δ(x), x) donne le risque de δ conditionnellement `a l’orbite de x. Ce
constat est utile pour la d´etermination du meilleur estimateur ´equivariant.
Th´eor`eme 9.21. S’il existe a0(x) tel que
(i) H(a, x) ≥H(a0(x), x) pour tout a ∈D, x ∈X ; et
(ii) a0(gx) = ˜ga0(x) pour tout g ∈G , x ∈X ,
alors δ0(x) = a0(x) est un meilleur estimateur ´equivariant.
Preuve.
Soit un estimateur ´equivariant δ. Alors

G
L(¯gθ, δ(x))f(x|¯gθ)νr(dg) ≥

G
L(¯gθ, a0(x))f(x|¯gθ)νr(dg).
En int´egrant par rapport `a J1, on d´eduit que R(δ, θ) ≥R(δ0, θ). L’estimateur
δ0 domine alors δ.
⊓⊔
Ce th´eor`eme met en ´evidence la relation entre le meilleur estimateur
´equivariant et un estimateur de Bayes particulier, puisque H(a, x) peut
´egalement ˆetre interpr´et´e comme un risque de Bayes a posteriori. Si on
s´electionne arbitrairement un θ0 ∈Θ, la fonction τ(g) = ¯gθ0 d´eﬁnit en fait
une surjection de G dans Θ eu ´egard `a la transitivit´e de ¯
G . Elle induit donc

9.4 Distributions non informatives ´equivariantes
477
une mesure sur Θ, appel´ee mesure de Haar `a droite sur Θ et d´eﬁnie par
π∗(B) = νr(τ −1(B)) pour tout B ∈B(Θ). Elle est manifestement invariante
sous l’action de ¯
G . En outre,
H(a, x) =

Θ
L(θ, a)f(x|θ) dπ∗(θ).
Cette extension de la mesure de Haar `a droite `a Θ donne une expression du
meilleur estimateur ´equivariant sous la forme d’un estimateur de Bayes pour
tout groupe transitif agissant sur le mod`ele statistique.
Corollaire 9.22. Le meilleur estimateur ´equivariant de θ est l’estimateur de
Bayes associ´e `a la mesure de Haar `a droite sur Θ, π∗, et au coˆut invariant
correspondant.
Nous avons donc une m´ethode qui permet d’obtenir les meilleurs estima-
teurs ´equivariants directement `a partir de la mesure de Haar `a droite. (Voir
Stein, 1965, et Zidek, 1965, pour des r´esultats analogues.)
Dans le raisonnement ci-dessus, la mesure dominante est μ et il s’agit donc
d’une mesure relativement invariante avec pour multiplicateur le module Δ−1.
En fait, si la mesure μ ´etait relativement invariante avec un multiplicateur
arbitraire χ, c’est-`a-dire que, pour tout f ∈K(G ),

X
f(gx)μ(dx) = χ(g)

X
f(x)μ(dx),
le Corollaire 9.22 serait toujours vrai (Eaton, 1989, p. 87).
Exemple 9.23. (Suite de l’Exemple 9.20) Nous avons la mesure de Haar
`a gauche suivante sur Θ :
πℓ(θ, σ) = 1/σ2.
La mesure de Haar `a droite peut en ˆetre d´eduite par inversion : si g = (a, b) et
g0 = (a0, b0), gg0 = (aa0, ab0 + b) pour la composition de groupe. En prenant
le jacobien en compte, nous voulons que la mesure de Haar `a droite v´eriﬁe
a0πr(b0σ + θ, a0σ) = πr(θ, σ)
pour tout (θ, σ) et uniform´ement sur a0, b0 ; ceci entraˆıne
πr(θ, σ) = 1/σ,
`a un facteur multiplicatif pr`es. Par cons´equent, la mesure de Haar `a droite
est diﬀ´erente de la mesure de Haar `a gauche et donne une alternative non
informative `a l’a priori de Jeﬀreys (Section 3.6). Pour le coˆut quadratique
invariant,
L((θ, σ), δ) = (θ −δ1)2
σ2
+
δ2
σ −1
2
,
(9.3)

478
9 Invariance
le meilleur estimateur ´equivariant est l’estimateur de Bayes associ´e `a la dis-
tribution a priori πr, soit,
δ∗
1(¯x, s) = Eπr[θ/σ2|¯x, s]
Eπr[1/σ2|¯x, s],
δ∗
2(¯x, s) = Eπr[1/σ|¯x, s]
Eπr[1/σ2|¯x, s].
Puisque
πr(θ, σ|¯x, s) ∝σ−(n+1)e−n(¯x−θ)2/2σ2e−s2/2σ2,
il s’agit d’un cas particulier de distribution conjugu´ee sur (θ, σ) et
δ∗
1(¯x, s) = ¯x,
δ∗
2(¯x, s) =
Γ(n/2)
√
2Γ((n + 1)/2)s.
Remarquons que δ2 est aussi l’estimateur obtenu dans l’Exemple 9.15.
∥
Exemple 9.24. (Eaton, 1989)
Soit un mod`ele multiplicatif N (θ, θ2), `a n
observations x1, . . . , xn. Ce mod`ele apparaˆıt dans des contextes o`u la diﬃcult´e
de mesure d’un objet augmente avec sa magnitude (Physique des particules,
Astronomie, etc.). Si nous estimons θ sous le coˆut
L(θ, d) = (θ −d)2
θ2
,
le probl`eme est invariant sous l’action du groupe multiplicatif. La mesure de
Haar `a droite est alors π(θ) = 1/|θ|. (Il s’agit aussi de la mesure de Haar `a
gauche puisque le groupe est commutatif.)
Le meilleur estimateur ´equivariant de θ est donc
δ∗(x1, . . . , xn) = Eπ[1/θ|x1, . . . , xn]
Eπ[1/θ2|x1, . . . , xn]
et
π(θ|x) ∝1
θ2 exp

−
n

i=1
(xi −θ)2/2θ2

∝1
θ2 exp

−1
2
n¯x
s2 −1
θ
2
s2

,
pour s2 = n
i=1 x2
i . La distribution a posteriori est alors inverse normale
g´en´eralis´ee I N (2, n¯x/s2, 1/s2) (Robert, 1991) et
Eπ[1/θ|¯x, s2] =
√
2s
1F1(1; 1/2; n2¯x2/2s2)
Γ(1/2)1F1(1/2; 1/2; n2¯x2/2s2).
Par cons´equent,

9.5 Le th´eor`eme de Hunt-Stein
479
δ∗(x1, . . . , xn) =
√
2 Γ(3/2)
1F1(3/2; 1/2; n2¯x2/2s2)
Γ(1/2)1F1(1; 1/2; n2¯x2/2s2) s.
Dans ce cas, le meilleur estimateur ´equivariant domine l’estimateur du maxi-
mum de vraisemblance
ˆδ(¯x, s) = −¯x + (¯x2 + 4s2)1/2
2
,
qui est ´egalement ´equivariant. Pour plus de r´esultats sur les mod`eles multi-
plicatifs, voir Gleser et Healy (1976), Kariya et al. (1988) et Perron et Giri
(1990).
∥
Les lecteurs pourront se r´ef´erer `a Eaton (1989), Lehmann (1986) et Berger
(1985b) pour d’autres exemples d’utilisation des mesures de Haar concernant
la d´etermination de meilleurs estimateurs ´equivariants dans les cadres des tests
et de calculs de r´egions de conﬁance. Pour un trait´e g´en´eral de math´ematiques
sur les mesures de Haar, voir Nachbin (1965).
9.5 Le th´eor`eme de Hunt-Stein
Repla¸cons-nous dans le cas ´evoqu´e en d´ebut de la section pr´ec´edente, c’est-
`a-dire celui o`u G est compact et o`u il existe une distribution de probabilit´e
invariante sur Θ. Alors le meilleur estimateur ´equivariant est un estimateur
(propre) de Bayes et est donc admissible la plupart du temps. Comme le risque
est constant lorsque ¯
G est transitif, le meilleur estimateur ´equivariant est aussi
minimax. Si G n’est pas compact, le meilleur estimateur ´equivariant est un
estimateur de Bayes g´en´eralis´e associ´e `a la mesure de Haar `a droite et n’est
donc pas n´ecessairement admissible. L’eﬀet Stein (Note 2.8.2) illustre cette
possible sous-optimalit´e en montrant que le meilleur estimateur ´equivariant
d’un param`etre de position, x, est inadmissible pour le coˆut quadratique en
dimension 3 et plus. Par cons´equent, il est vain d’esp´erer une r´eponse g´en´erale
`a la question de l’admissibilit´e du meilleur estimateur ´equivariant pour des
groupes non compacts.
En revanche, il est possible d’´etendre la propri´et´e de minimaxit´e au-del`a
du cas compact, grˆace au th´eor`eme de Hunt-Stein71. Ce r´esultat est conforme
`a l’intuition puisque, quand un probl`eme est invariant, il existe un estimateur
´equivariant `a risque constant qui atteint la borne inf´erieure du risque maximal
inf
δ sup
θ
R(δ, θ).
71Ce th´eor`eme est ´egalement c´el`ebre pour ˆetre rest´e longtemps sans d´emonstration
publi´ee, bien que Kiefer (1957) en ait fourni une dans un cas particulier.

480
9 Invariance
En outre, il semble logique de tirer partie de la structure naturelle d’invariance
du mod`ele pour am´eliorer un estimateur δ en le “moyennant” par int´egration
sur G
δ∗(x) =

G
δ(gx)νr(dg),
si L(θ, d) est convexe en d et si le th´eor`eme inspir´e de celui de Fubini, pr´esent´e
en Section 9.4, s’applique (en supposant que δ∗est bien d´eﬁnie). De fa¸con
informelle, nous obtiendrions alors en fait
R(δ, θ) = Eθ[L(θ, δ(x))]
= ET (Eθ[L(θ, δ(x))|Q(x) = T ])
≥ET [L(θ, δ∗(t))] = R(δ∗, θ).
Cette am´elioration rappelle le r´esultat de domination du th´eor`eme de Rao-
Blackwell, dans le cas du conditionnement `a une statistique exhaustive.
Nous poussons un pas plus loin la formalisation de la d´emonstration en
introduisant la notion de groupe moyennable pr´esent´ee en d´etail par Bondar
et Milnes (1981). Pr´esentons tout d’abord un contre-exemple qui montre que
l’intuition n’a pas toujours raison, en particulier lorsque les structures d’inva-
riance sont trop fortes, c’est-`a-dire lorsque G est trop grand.
Exemple 9.25. (Stein, 1965)
Soient x ∼Np(0, Σ) et y ∼Np(0, ϱΣ) avec
p ≥2. Le param`etre ϱ est estim´e sous la fonction de coˆut
L((ϱ, Σ), d) = I[1/2,+∞)
1 −d
ϱ


.
Le probl`eme est alors invariant sous l’action du groupe lin´eaire GLp parce que,
si B est une matrice r´eguli`ere, Bx ∼Np(0, BΣBt) et By ∼Np(0, ϱBΣBt).
Puisque ¯gB(ϱ, Σ) = (ϱ, BΣBt), les estimateurs ´equivariants sont en r´ealit´e
invariants
δ(Bx, By) = δ(x, y)
quels que soient x, y et B. Si x et y sont lin´eairement ind´ependants (ce qui
est vrai avec probabilit´e 1), on peut trouver B telle que
Bx = (1, 0, . . . , 0)t
et
By = (0, 1, 0, . . ., 0)t,
ce qui implique que les estimateurs ´equivariants sont constants presque par-
tout. Comme
R(δ0, (ϱ, Σ)) = 1
si
1 −δ0
ϱ
 > 1/2
pour une constante donn´ee δ0, le risque minimax des estimateurs ´equivariants
est de 1.
En posant

9.5 Le th´eor`eme de Hunt-Stein
481
δ1(x, y) =

y2
x1
 ,
le risque de δ1 est
R(δ1, θ) = Pϱ,Σ
1 −

y2
x1ϱ

 ≥1/2

= P
1 −

z1
z2

 ≥1/2

,
o`u z1, z2 sont i.i.d. N (0, 1). Par cons´equent, le risque est ´egalement constant,
mais strictement plus petit que 1. On peut remarquer que δ1 est aussi un
estimateur ´equivariant pour le groupe multiplicatif, qui semble une structure
d’invariance mieux appropri´ee.
∥
Aﬁn d’obtenir une approche plus g´en´erale du probl`eme, on consid`ere `a
pr´esent un groupe localement compact de transformations G , avec une mesure
de Haar `a droite νr. Soit V une alg`ebre de fonctions mesurables essentiellement
born´ees `a valeurs r´eelles sur G , telle que la fonction constante 1 soit dans V .
D´eﬁnition 9.26. Une moyenne sur V est une fonctionnelle m, lin´eaire et
continue sur V , telle que
(i) m(1) = 1 ; et
(ii) m(f) ≥0 si f ∈V et f ≥0 (presque sˆurement).
L’existence d’une telle fonctionnelle m est en fait une condition n´ecessaire
et suﬃsante pour le th´eor`eme de Hunt-Stein. Si m existe, il est possible de
moyenner sur les orbites de X par rapport `a G , comme nous l’avons ´evoqu´e
en d´ebut de section.
Exemple 9.27. (Bondar et Milnes, 1981) Pour G = R et n ∈N, on consid`ere
mn(f) = 1
2n
 n
−n
f(x) dx;
alors mn d´eﬁnit une moyenne sur L∞(R). De plus, la suite (mn) a un point
d’accumulation m dans la topologie faible sur L∞: pour tout f ∈L∞, ϵ > 0
et n0 ∈N, il existe n ≥n0 tel que
|mn(f) −m(f)| < ϵ.
En particulier, ce point d’accumulation v´eriﬁe m(f) = 0 quelle que soit f
telle que f(x) tende vers 0 quand x tend vers ±∞. Notons ´egalement que m
n’est pas σ-additive et que la suite (mn) ne converge pas vers m au sens de
la topologie faible.
∥

482
9 Invariance
D´eﬁnition 9.28. La moyenne m est invariante `a droite si, pour toutes f ∈V
et g ∈G , m(fg) = m(f), avec fg(x) = f(xg). Le groupe G est dit moyen-
nable s’il existe une moyenne invariante `a droite sur L∞(G ) ou, de fa¸con
´equivalente, sur CB(G ), l’espace des fonctions continues born´ees sur G .
Comme le montrent Bondar et Milnes (1981), l’existence d’un groupe
moyennable est ´equivalente `a l’existence d’une suite de mesures de proba-
bilit´e presque invariantes `a droite : il existe alors une suite (Pn) de mesures
de probabilit´e sur G telle que, pour tous B ∈B(G ) et g ∈G ,
lim
n→+∞|Pn(Bg) −Pn(B)| = 0.
En outre, il existe une suite (Gn) d’ensembles compacts imbriqu´es tels que la
densit´e de Pn soit νr(Gn)−1IGn(g) (par rapport `a νr). La suite (Gn) conduit
donc `a une approximation de la mesure de Haar νr par une suite de distri-
butions de probabilit´e et ces distributions sont presque invariantes au sens
o`u
B ∩Gn = Bg ∩Gn,
Pn(B) = Pn(Bg)
(on peut ´egalement consulter Strasser, 1985, et Lehmann, 1986). L’Exemple
9.27 est une illustration directe de ce r´esultat.
Des exemples de groupes moyennables sont les groupes additifs et multi-
plicatifs, le groupe de transformations position-´echelle (Exemple 9.18) et le
groupe Tp des matrices triangulaires sup´erieures inversibles. `A l’inverse, le
groupe lin´eaire GLp et le groupe SLp des matrices de d´eterminant 1 ne sont
pas moyennables. Bondar et Milnes (1981) donnent de nombreux exemples de
groupes moyennables et de groupes non moyennables.
Le th´eor`eme de Hunt-Stein ´etablit la minimaxit´e du meilleur estimateur
´equivariant.
Th´eor`eme 9.29. Si le groupe G est moyennable et si le probl`eme statistique
(X , f(x|θ), D, L) est invariant sous l’action de G , l’existence d’un estima-
teur minimax implique celle d’un estimateur minimax ´equivariant. De plus,
un estimateur ´equivariant qui est minimax dans l’ensemble des estimateurs
´equivariants est minimax.
Des preuves de ce th´eor`eme ﬁgurent dans Berger (1985b, Section 6.7)
pour le cas o`u G est ﬁni, Lehmann (1983, Section 9.5) pour les tests et
Le Cam (1986, Section 8.6) dans des cadres plus g´en´eraux, en tant que
cons´equence du th´eor`eme du point ﬁxe de Markov-Kakutani. Comme pr´ecis´e
plus haut, le th´eor`eme de Hunt-Stein repose sur une version modiﬁ´ee du
th´eor`eme de Fubini. Nous nous contentons ici de donner une id´ee g´en´erale
de la d´emonstration. On suppose que L est convexe. Pour un estimateur δ `a
valeurs r´eelles, on pose
δ∗(x) = m(˜δx),

9.6 L’invariance en Statistique bay´esienne
483
o`u m est la moyenne invariante `a droite et ˜δx(g) = δ(gx). L’estimateur δ∗est
alors ´equivariant puisque, si g0 ∈G ,
δ∗(g0x) =

G
˜g−1δ(gg0x) dm(g)
=

G
˜g0˜g−1
0 ˜g−1δ(gg0x) dm(g)
= ˜g0

G
˜g−1δ(gx) dm(g)
= ˜g0δ∗(x),
par l’invariance `a droite de m. Par ailleurs,
sup
θ
R(δ∗, θ) ≤sup
θ

G

X
L
	
θ, ˜g−1δ(gx)

f(x|θ) dx dm(g)
(9.4)
par convexit´e de L. Il vient
sup
θ
R(δ∗, θ) ≤sup
θ

G

X
L (¯gθ, δ(gx)) f(x|θ) dx dm(g)
= sup
θ

G
R(¯gθ, δ) dm(g)
≤sup
θ
R(δ, θ),
ce qui entraˆıne72 la domination de δ par δ∗.
Une cons´equence du th´eor`eme de Hunt-Stein est que, dans le cas normal,
l’estimateur du maximum de vraisemblance, x ∼Np(θ, Ip), est minimax pour
tout p, bien qu’inadmissible pour p ≥3. Le mˆeme r´esultat est vrai si x ∼
Np(θ, σ2Ip) et la variance inconnue σ2 est estim´ee par s2/q, avec s2 ∼σ2χ2
q.
9.6 L’invariance en Statistique bay´esienne
Pour conclure ce chapitre, nous mentionnons ici les r´eserves ´emises par
Berger (1985b) quant aux cons´equences des exigences d’invariance dans l’ap-
proche bay´esienne. Elles concernent en particulier le processus de d´etermina-
tion de distributions non informatives, mˆeme s’il a l’avantage de pr´esenter en
le justiﬁant un choix alternatif `a l’a priori de Jeﬀreys (Exemple 9.18).
Une critique qu’on peut adresser `a la notion d’invariance est que, bien
qu’intuitivement attractive, elle n’est pas d´enu´ee d’ambigu¨ıt´e et, puisqu’il est
72Insistons sur le fait que ces indications n’ont pas valeur de preuve rigoureuse,
puisque l’application du th´eor`eme de Fubini `a (9.12) n’est pas toujours justiﬁ´ee. Il se
trouve que cette op´eration de moyenne ne peut ˆetre eﬀectu´ee que sous des conditions
pr´ecises. Sinon, on obtiendrait de mˆeme un r´esultat d’admissibilit´e pour le meilleur
estimateur ´equivariant sous coˆut convexe, r´esultat contest´e par l’eﬀet Stein.

484
9 Invariance
parfois possible de consid´erer plusieurs groupes globalement invariants, les
meilleurs estimateurs ´equivariants en r´esultant peuvent ˆetre distincts, ce qui
contredit le principe de vraisemblance.
Un inconv´enient plus direct de la m´ethode est que les structures naturelles
d’invariance d’un mod`ele statistique peuvent ˆetre trop faibles et donc sans
int´erˆet pour d´eterminer un estimateur, ou trop fortes et donc trop contrai-
gnantes. Une illustration extrˆeme du premier ´ecueil est obtenue avec la dis-
tribution de Poisson, pour laquelle il n’existe aucune structure d’invariance.
L’exemple suivant se place dans le cas oppos´e (voir aussi l’Exemple 9.25).
Exemple 9.30. Soit une famille de distributions sym´etriques par rapport `a
un param`etre de position θ, c’est-`a-dire telles que x ∼f(|x −θ|). La fonction
de coˆut est ϱ(|d −θ|). Si on prend en compte l’invariance par sym´etrie, c’est-
`a-dire le fait que la distribution de y = −x appartienne `a la mˆeme famille, les
estimateurs correspondant `a π(θ) = 1 et satisfaisant
δ(x + c) = δ(x) + c
et
δ(−x) = −δ(x)
se r´eduisent `a δ(x) = x, qui n’est pas n´ecessairement un choix judicieux.
∥
Un exc`es d’invariance peut ´evidemment ˆetre mod´er´e en ignorant certaines
structures d’invariance, c’est-`a-dire en ne consid´erant qu’un sous-groupe G0
de G qui induise une action transitive sur Θ, tout en ´etant aussi petit que
possible. Cependant, mˆeme lorsqu’il est envisageable, le choix d’un tel sous-
groupe peut se r´ev´eler crucial dans la suite du processus inf´erentiel.
Une derni`ere critique importante est que la mod´elisation de probl`emes
statistiques par des structures d’invariance peut ˆetre n´efaste d’un point de
vue subjectif, puisqu’elle impose la compatibilit´e des structures de d´ecision
avec l’invariance–et donc, en particulier, le choix d’un coˆut invariant–ce qui
peut contredire l’information a priori–la seule distribution a priori compa-
tible ´etant la mesure de Haar. La m´ethode peut ´egalement ˆetre peu eﬃ-
cace, puisque les estimateurs ´equivariants sont parfois fortement inadmissibles,
comme le montrent l’eﬀet Stein et l’Exemple 9.25 (voir aussi les Exemples 4.4-
4.9 de Lehmann, 1983, Section 4.4). Par ailleurs, l’invariance ne conduit pas
n´ecessairement `a une distribution non informative satisfaisante comme on le
voit dans l’Exemple 9.30. Enﬁn, en pratique, le calcul des mesures de Haar `a
droite peut se r´ev´eler fastidieux.
9.7 Exercices
Section 9.2
9.1 (Blackwell et Girshick, 1954)
On consid`ere la distribution f avec les poids
f(k) = 1/k(k + 1) pour k = 1, 2, . . . et x ∼f(x −θ), avec θ ∈R. Pour la
fonction de coˆut

9.7 Exercices
485
L(θ, d) =
(
d −θ
si d > θ,
0
sinon,
montrer que les estimateurs ´equivariants sont de la forme x −c et que tout
estimateur ´equivariant a un risque inﬁni. Comparer `a l’estimateur constant
δ0(x) = c.
9.2 Soit x une observation issue d’une loi de Cauchy C (θ, 1). Pour un coˆut qua-
dratique, montrer que tous les estimateurs ´equivariants sont de risque inﬁni.
Proposer un estimateur `a risque ﬁni diﬀ´erent de l’estimateur constant.
9.3 (Berger, 1985b) Soit
x = (x1, . . . , xn) ∼f(x1 −θ, . . . , xn −θ),
avec θ inconnu. On veut tester l’hypoth`ese H0 : f = f0 contre H1 : f = f1 sous
le coˆut 0 −1.
a. Montrer que T(x) = (x1 −xn, . . . , xn−1 −xn) est une statistique invariante
maximale pour le groupe de transformations
G = {gc; gc(x1, . . . , xn) = (x1 + c, . . . , xn + c), c ∈R} .
b. En d´eduire qu’un test invariant ne d´epend que de y = T(x) et que les tests
optimaux ont la r´egion de rejet suivante :
W = {f ∗
1 (y) ≥Kf ∗
0 (y)},
o`u f ∗
i est la densit´e de y sous Hi.
9.4 (Berger, 1985b) Soit x distribu´e selon
Pθ(x = θ −1) = Pθ(x = θ + 1) = 1/2.
La fonction de coˆut associ´ee est
L(θ, d) =
(
|θ −d|
si |θ −d| ≤1,
1
sinon.
D´eterminer les meilleurs estimateurs ´equivariants pour le groupe de translation
et montrer qu’ils sont domin´es par
δ∗(x) =
(
x + 1
si x ≤0,
x −1
sinon.
9.5 (Berger, 1985b)
Soit x1, . . . , xn un ´echantillon de la distribution normale
tronqu´ee `a R+ de densit´e
f(x|θ) =
„ 2
π
«1/2
e−(x−θ)2/2I[θ,+∞)(x).
Montrer que le meilleur estimateur ´equivariant de θ sous coˆut quadratique est
δ∗(x) = ¯x −exp{−n(x(1) −¯x)2/2}
√
2nπΦ(√n(x(1) −¯x))
.

486
9 Invariance
Section 9.3
9.6 Soit x ∼N (θ, aθ2), avec θ ∈R et a > 0 connu. Le param`etre θ est estim´e sous
le coˆut L(θ, d) = ( d
θ −1)2.
a. Montrer que le probl`eme est invariant sous le groupe de transformations
G = {gc; gc(x) = cx, c > 0}.
L’action du groupe est-elle transitive ?
b. Donner les meilleurs estimateurs ´equivariants et du maximum de vraisem-
blance de θ.
c. Les comparer aux estimateurs obtenus dans l’Exercice 3.33 et dans l’Exemple
9.24.
d. Montrer, `a l’aide de l’Exercice 3.33, que le meilleur estimateur ´equivariant
δ0 est un estimateur de Bayes g´en´eralis´e.
9.7 (Lehmann, 1983) On cherche `a estimer un param`etre d’´echelle σ, sous le coˆut
L(σ, δ) =
„ δ
σ −1
«2
,
(9.5)
pour n observations
x1, . . . , xn ∼1
σn f
“x1
σ , . . . , xn
σ
”
.
a. Si z = (x1/xn, . . . , xn−1/xn, xn/|xn|), montrer que tout estimateur de σ
´equivariant sous transformation d’´echelle peut s’´ecrire
δ(x) = δ0(x)/ω(z),
avec δ0 un estimateur ´equivariant particulier et que z est une statistique
invariante maximale.
b. D´eterminer la fonction ω∗qui minimise
E[L(σ, δ(x))|z]
sous (9.5) et en d´eduire le meilleur estimateur ´equivariant.
c. Transformer l’´ecriture de cet estimateur pour retrouver le r´esultat de la Sec-
tion 9.4 avec la mesure de Haar correspondante.
d. Reprendre les questions pr´ec´edentes pour le probl`eme d’estimation de σr
(r ∈R∗
+) sous le coˆut
L(σ, δ) =
„ δ
σr −1
«2
.
9.8 Appliquer les r´esultats de l’Exercice 9.7 aux cas suivants :
(i) x1, . . . , xn i.i.d. N (0, σ2) ;
(ii) x1, . . . , xn i.i.d. G (α, σ) ; et
(iii) x1, . . . , xn i.i.d. U [0, σ].
9.9 Reprendre l’Exercice 9.7 sous les coˆuts suivants :
L(σ, δ) = |δ −σ|
σ
,
L(σ, δ) = δ
σ −log(δ/σ) −1,
L(σ, δ) =
“σ
δ −1
”2
.

9.7 Exercices
487
9.10 (Lehmann, 1983) On consid`ere le probl`eme d’estimation de σ dans le cas o`u
x = (x1, . . . , xn) ∼1
σn f
„x1 −θ
σ
, . . . , xn −θ
σ
«
,
sous l’action du groupe aﬃne
Ga = {ga,b; ga,b(x) = ax + b1, a > 0, b ∈R},
avec 1 = (1, . . . , 1) ∈Rn.
a. D´eterminer le meilleur estimateur ´equivariant sous le coˆut (9.5) de mˆeme que
dans l’Exercice 9.7. (Indication : Utiliser les transformations yi = xi −xn et
poser zi = yi/yn−1 (i ̸= n −1), zn−1 = yn−1/|yn−1|.)
b. Comparer `a une formulation bay´esienne avec la mesure de Haar `a droite.
c. Reprendre les questions pr´ec´edentes pour l’estimation de θ sous le coˆut
L(θ, δ) = (θ −δ)2
σ2
.
d. Appliquer au cas o`u xi −θ ∼E xp(σ) et montrer que le meilleur estimateur
´equivariant de θ est
δ∗(x) = x(1) −1
n2
n
X
i=1
(xi −x(1)).
9.11
∗(Eaton, 1989) On consid`ere G ⊂R∗
+ × R muni de l’op´eration de groupe
(a1, b1)(a2, b2) = (a1a2, a1b2 + b1).
Si D = {x ∈Rn; x1 = · · · = xn}, on consid`ere X = Rn −D. On suppose que
G agit sur X de la fa¸con suivante
(a, b)x = ax + ben,
avec en = (1, . . . , 1)t. Montrer que la statistique invariante maximale est
f(x) = x −¯xen
s(x)
,
avec ¯x = P xi/n, s2(x) = P(xi −¯x)2.
9.12
∗(Eaton, 1989) V´eriﬁer que, s’il existe un multiplicateur ξ sur G , c’est-`a-dire
une fonction `a valeurs r´eelles telle que ξ(g1g2) = ξ(g1)ξ(g2), qui satisfasse
f(x|θ) = f(gx|¯gθ)ξ(g)
uniform´ement sur X , Θ, G , la famille
P = {f(x|θ); θ ∈Θ}
est G -invariante. En d´eduire que, dans ce cas, l’estimateur du maximum de vrai-
semblance est ´equivariant, comme tout estimateur de Bayes associ´e `a une mesure
a priori relativement invariante, c’est-`a-dire telle qu’il existe un multiplicateur
ξ1 avec π(gB) = ξ1(g)π(B) uniform´ement en B et g.

488
9 Invariance
9.13
∗(Delampady, 1989)
Soit x ∼Np(θ, Ip). On teste l’hypoth`ese H0 : θ = θ0
contre H1 : θ ̸= θ0. Ce probl`eme est invariant sous l’action du groupe orthogonal
Go et on consid`ere uniquement les distributions a priori de la classe invariante
I = {π; π(gA) = π(A), ∀A ∈B(Rp), ∀g ∈Go}.
a. Montrer que t(x) = ||x||2 est une statistique invariante maximale, distribu´ee
selon une loi du χ2
p d´ecentr´e, de param`etre de non-centralit´e η(θ) = ||θ||2
(la statistique invariante maximale correspondante sur ¯
G0), et que sa densit´e
peut s’´ecrire
q(t(x)|η(θ)) =
Z
Go
f(gx|θ) dμ(g),
avec μ mesure de Haar sur G0.
b. En d´eduire que si Bπ est le facteur de Bayes, il v´eriﬁe
inf
π∈I Bπ(x) = q(t(x)|θ0)
q(t(x)|ˆη) ,
avec ˆη estimateur du maximum de vraisemblance de η.
c. Comparer avec la p-value pour diﬀ´erentes valeurs de t(x).
9.14
Montrer que les coˆuts intrins`eques d´eﬁnis en Section 2.5.4 sont naturellement
invariants.
9.15 On consid`ere x ∼N (θ, σ2). Le param`etre d’int´erˆet est eθ et σ2 est connu.
a. Montrer que
Eθ[eax] = eaθ+a2σ2/2.
b. Parmi les estimateurs de la forme δc(x) = ex+cσ2, d´eterminer le meilleur
estimateur (en c) pour le coˆut quadratique L2, δ∗. Montrer que δ∗est un
estimateur de Bayes et d´eterminer l’a priori correspondant π∗. (Indication :
Consid´erer d’abord la mesure de Lebesgue et le coˆut quadratique pond´er´e
L0(θ, δ) = e−2θ(eθ −δ)2.
Quel est l’estimateur de Bayes pour l’a priori de Lebesgue sous L2 ?)
c. Reprendre la question pr´ec´edente pour le coˆut d’erreur absolu
L1(θ, δ) = |eθ −δ|.
Montrer que le meilleur estimateur est associ´e `a π(θ) = e−θ. Cette r´eponse
est-elle surprenante du point de vue de l’invariance ?
d. ´Etant donn´e l’estimateur δ∗, nous souhaitons ´evaluer les performances de δ∗
sous L0 et L2, c’est-`a-dire estimer L0(θ, δ∗(x)) et L2(θ, δ∗(x)) sous le coˆut
quadratique
(L0(θ, δ∗(x)) −γ)2 .
(9.6)
Montrer que, pour π(θ) = 1, le coˆut a posteriori Eπ[L0(θ, δ∗)|x] est constant
et ´egal au risque constant de δ∗.
e. Montrer que, pour π∗(θ) = exp(−2θ), la variance a posteriori de δ∗est
γπ(x) = e2x−2σ2 “
1 −e−σ2”
.
Montrer que γπ est un estimateur non biais´e du risque, Eθ[L2(θ, δ∗(x))], et
qu’il est domin´e par l’estimateur de Bayes de L2(θ, δ∗(x)) sous π(θ) = e−4θ.
Peut-on justiﬁer l’utilisation de cet a priori par des consid´erations d’inva-
riance ?

9.7 Exercices
489
Section 9.4
9.16
∗(Eaton, 1989) Montrer que, pour un groupe topologique G , deux int´egrales
invariantes `a gauche, c’est-`a-dire deux fonctionnelles telles que
Z
G
f(gx)μ(dx) =
Z
G
f(x)μ(dx)
pour tous f ∈L1(μ) et g ∈G , sont n´ecessairement proportionnelles.
9.17
∗(Eaton, 1989) On consid`ere νℓune mesure de Haar `a gauche, f ∈K(G ) et
J1(f) =
Z
G
f(xg−1)νℓ(dx).
a. Montrer que J1 est invariant `a gauche. En d´eduire qu’il existe une fonction
Δ sur G telle que
J1(f) = Δ(g)
Z
G
f(x)νℓ(dx) = Δ(g)J(f).
La fonction Δ est appel´ee le module de G .
b. Montrer que Δ ne d´epend pas du choix de J1 et que Δ(g1g2) = Δ(g1)Δ(g2)
(c’est-`a-dire que Δ est un multiplicateur).
c. Soit J2 tel que
J2(f) =
Z
G
f(x)Δ(x−1)νℓ(dx).
Montrer que J2 est invariante `a droite et satisfait
J2(f) =
Z
G
f(x−1)νℓ(dx).
En d´eduire que, si νℓest une mesure de Haar `a gauche,
νr(dx) = Δ(x−1)νℓ(dx)
est une mesure de Haar `a droite.
d. Si G est compact, montrer que Δ est identiquement ´egal `a 1. (Indication :
Utiliser la continuit´e de Δ et le fait que Δ(G ) soit compact.)
e. On note G = GLn, le groupe lin´eaire de Rn et dx la mesure de Lebesgue sur
Ln,n, l’espace vectoriel des matrices n × n. Montrer que
J(f) =
Z
G
f(x)
dx
|det(x)|n
est `a la fois invariante `a droite et `a gauche. En d´eduire que Δ = 1. G est-il
compact ?
9.18
∗(Eaton, 1989) Soient G un groupe compact agissant sur X et ν l’unique dis-
tribution de probabilit´e de Haar sur G . On d´eﬁnit U, variable al´eatoire uniforme
sur G , par
P(U ∈B) = ν(B).
a. Soit x ∈X . Montrer que μx, d´eﬁnie par
μx(B) = P(Ux ∈B)
est l’unique probabilit´e G -invariante sur l’orbite de x, Ox.

490
9 Invariance
b. Si P est une distribution G -invariante sur X , montrer que
P =
Z
X
μxP(dx).
c. Une section mesurable Y ⊂X est d´eﬁnie par
(i) Y est mesurable ;
(ii) ∀x ∈X , Y ∩Ox = {y(x)} ; et
(iii) la fonction t(x) = y(x) est mesurable pour la σ-alg`ebre induite par X
sur Y .
Montrer que, pour toute distribution de probabilit´e Q sur Y ,
P =
Z
Y
μyQ(dy)
est G -invariant sur X et que, r´eciproquement, toute probabilit´e G -invariante
peut s’´ecrire de cette fa¸con.
d. Soient U une variable al´eatoire uniforme sur G , Y une section mesurable de
X et X une variable al´eatoire sur X . D´eduire de c. l’´equivalence entre les
propri´et´es suivantes :
(i) la distribution de gX est ind´ependante de g ∈G ; et
(ii) il existe Y , variable al´eatoire sur Y , ind´ependante de U, telle que UY a
la mˆeme distribution que X.
e. Appliquer au cas X = {0, 1}n.
9.19 On consid`ere x ∼N (θ, 1) et on s’int´eresse plus particuli`erement `a la quantit´e
h(θ) = ecθ.
a. D´eterminer le risque de l’estimateur de Bayes de h(θ) associ´e `a π(θ) = 1 et
au coˆut quadratique, R(θ, δπ), et montrer que l’estimateur de Bayes de h(θ)
associ´e `a π′(θ) = R(θ, δπ)−1 domine δπ.
b. Remarquer que R(θ, δπ)−1(ecθ−δ)2 est un coˆut invariant et ´etablir le r´esultat
suivant : Pour tout coˆut invariant L(θ, δ), si δπ est l’estimateur associ´e `a L
et `a la mesure de Haar π, et si ω(θ) = Eθ[L(θ, δπ(x))], l’estimateur associ´e `a
L et π′(θ) = π(θ)/ω(θ) est le meilleur estimateur ´equivariant.
Section 9.5
9.20
∗(Berger, 1985b) On consid`ere le cas particulier o`u le groupe G est ﬁni, c’est-
`a-dire
G = {g1, . . . , gm}.
On suppose que le coˆut L(θ, a) est invariant, convexe en a, et, en outre, que
l’action induite par le groupe G sur D satisfait
˜g
 
1
m
m
X
i=1
ai
!
= 1
m
m
X
i=1
˜g(ai).
D´emontrer le th´eor`eme de Hunt-Stein avec l’hypoth`ese suppl´ementaire que D
est convexe. (Indication : Montrer que, pour tout estimateur δ, il existe un
estimateur invariant associ´e δI qui domine δ.)
9.21
Dans le cadre de l’Exemple 9.25, d´eterminer le risque exact de l’estimateur δ1.
(Indication : Remarquer que z1/z2 est distribu´ee comme une variable al´eatoire
de Cauchy.)

9.7 Exercices
491
9.22 Consid´erer l’estimation de ϱ dans l’Exemple 9.25 pour la structure d’invariance
induite par le groupe multiplicatif.
9.23 Soient (x1, . . . , xp) et (y1, . . . , yp) de distributions normales Np(0, Σ) et Np(0,
ΔΣ). On teste l’hypoth`ese H0 : Δ ≤Δ0 contre H1 : Δ > Δ0.
a. Montrer que le probl`eme est invariant sous G Lp, groupe des transformations
lin´eaires r´eguli`eres.
b. Montrer que G Lp est transitif sur l’espace d’´echantillonnage, `a un en-
semble de mesure nulle pr`es. En d´eduire que les estimateurs ´equivariants sont
constants, c’est-`a-dire que les tests invariants de niveau α sont ϕα(x, y) =
1 −α.
c. Montrer que ϕc(x, y) = Iy2
1≤cx2
1 domine ϕα sous le coˆut 0 −1 pour α =
PΔ0(y2
1 > cx2
1).
d. G Lp est-il moyennable ?
9.24 Soit l’´echantillon x1, . . . , xn ∼C (μ, σ2).
a. Montrer que la mesure de Haar est πH(μ, σ) ∝1/σ.
b. On s’int´eresse `a la reparam´etrisation yi = 1/xi. Montrer que yi ∼C (ν, τ 2)
et exprimer ν et τ en fonction de μ et σ.
c. Montrer que πH(ν, τ) ∝1/τ n’est pas la transform´ee de πH(μ, σ) et conclure
sur les limites de l’invariance pour la reparam´etrisation.
Section 9.6
9.25
∗(Villegas, 1990) On consid`ere une famille de distributions de probabilit´e Pθ
sur X , avec θ ∈Θ et T(x) `a valeurs dans un espace aﬃne euclidien E, telle que
la fonction de vraisemblance soit
ℓ(θ|x) = c1(x)c2(θ) exp{−||T(x) −θ||2/2}.
Ce mod`ele est appel´e bay´esien euclidien si π(θ) = 1.
a. En d´eduire que la distribution a priori euclidienne correspondante pour un
mod`ele de Poisson P(λ) est π(λ) = 1/λ.
b. Montrer que la p-value p(x) = Pλ0(X ≥x) du test de H0 : λ ≤λ0 contre
H1 : λ > λ0 est li´ee `a la distribution a priori, mais que cela n’est pas vrai
pour le test alternatif de H0 : λ ≥λ0 contre H1 : λ < λ0.
c. Montrer que la distribution a priori de Haldane
π(p) =
1
p(1 −p)
(9.7)
est ´egalement un mod`ele euclidien lorsque x ∼B(n, p). La loi (9.7) est-elle
encore l’a priori euclidien pour la distribution binomiale n´egative N eg(n, p) ?
d. Si 0 < x < n, montrer que, dans le cas binomial, les p-values Pp0(X ≤x)
et Pp0(X ≥x) associ´ees aux hypoth`eses H0 :
p ≥p0 et H0 :
p ≤p0 ne
correspondent pas `a la distribution euclidienne (9.7).
e. Dans le cas normal N (μ, σ2), montrer que les distributions euclidiennes a
priori sont les suivantes :
(i) π(θ) = 1 si θ = μ ;
(ii) π(θ) = 1 si θ = σ−2 ; et
(iii) π(θ) = θ2 si (θ1, θ2) = (μ, σ−2).
9.26 ´Etudier les probl`emes de compatibilit´e entre les exigences d’invariance et le
principe de vraisemblance. D´eterminer en particulier si l’estimateur du maxi-
mum de vraisemblance est toujours un estimateur invariant.

492
9 Invariance
9.27 *Pour une fonction de coˆut arbitraire L(θ, δ) et une distribution a priori donn´ee
π, on suppose que l’estimateur de Bayes δπ est tel que 0 < R(θ, δπ) < ∞quel
que soit θ.
a. Si on d´eﬁnit Lπ(θ, δ) = L(θ, δ)/R(θ, δπ), montrer que δπ a un risque constant
de 1. Cela implique-t-il que δπ soit minimax ? (Indication : δπ n’est pas
n´ecessairement l’estimateur de Bayes sous Lπ.)
b. On consid`ere le cas particulier o`u x ∼N (θ, 1) et π est N (θ0, τ 2). Calculer
R(θ, δπ) et ´etudier le comportement de l’estimateur de Bayes associ´e `a π et
Lπ, comparativement `a δπ (num´eriquement, si n´ecessaire).
c. Si δπ
1 , associ´e `a π et Lπ
1 = Lπ, est diﬀ´erent de δπ, une suite d’estimateurs δπ
n
peut ˆetre d´eﬁnie r´ecursivement avec Lπ
n = Lπ
n−1/R(θ, δπ
n−1). Que peut-on dire
de la limite de la suite (δπ
n) ?
d. ´Etudier la suite ci-dessus pour x ∼P(λ), π(λ) = 1 et L(λ, δ) = (1 −λ/δ)2.
9.8 Notes
9.8.1 Invariance et paradoxes de marginalisation
En plus d’apporter un nouveau point de vue sur l’estimation ´equivariante, Hel-
land (1999) consid`ere que l’utilisation de mesures de Haar `a droite est un moyen
d’´echapper aux paradoxes de marginalisation, comme l’ont observ´e Dawid et al.
(1973). (Voir les Exercices 3.45-3.51.)
Plus pr´ecis´ement, ´etant donn´e un mod`ele (X , Θ, f(x|θ)) muni d’un groupe G
agissant sur X et le groupe correspondant ¯
G agissant sur Θ, une fonction h(θ)
est dite estimable invariablement si h(θ1) = h(θ2) entraˆıne h(¯gθ1) = h(¯gθ2)
pour tout ¯g ∈¯
G (Hora et Buehler, 1966). Helland (1999) estime que la perspec-
tive d’invariance et l’utilisation de la mesure de Haar correspondante devraient
ˆetre limit´ees `a l’estimation de fonctions des param`etres estimables invariable-
ment. Par exemple, bien que la mesure de Lebesgue soit la mesure de Haar `a
droite pour le groupe de translation et s’applique donc `a la distribution normale
Np(θ, Ip), elle ne devrait pas ˆetre utilis´ee pour l’estimation de ||θ||2, `a cause de
l’ineﬃcacit´e mise en ´evidence `a la Section 3.5.4. Ce point de vue est d’une
certaine fa¸con li´e `a la construction de lois a priori de r´ef´erence : ´etant donn´e
un param`etre d’int´erˆet, on devrait d’abord d´eterminer la structure d’invariance
ad´equate puis en d´eduire la mesure de Haar `a droite en tant qu’a priori non in-
formatif correspondant. Deux d´efauts de cette approche sont (a) qu’il existe des
fonctions pour lesquelles il est impossible de trouver des groupes d’invariance
non triviaux et (b) qu’il y a toujours une part d’arbitraire dans le choix de ces
groupes, lorsqu’ils existent.
Exemple 9.31. (Helland, 1999)
Si x ∼Np(θ, σ2Ip) et θ est sur la sph`ere de
rayon c, le meilleur estimateur ´equivariant de θ sous le groupe de rotations
est associ´e `a la mesure uniforme sur la sph`ere et est donn´e par (8.10). (Voir
l’Exercice 4.37.) Si c = ||θ||2 est inconnu, il peut ˆetre estim´e `a partir de ||x||
plutˆot que de x (voir les Exemples 3.34 et 3.36), en utilisant par exemple l’es-
timateur du maximum de vraisemblance ou l’am´elioration de Saxena et Alam
(1982) (||x||2 −p)+. Si on ins`ere l’expression de l’estimateur κ(x) de c dans δc,
on obtient l’estimateur
˜δ = κ(x) Ip/2(κ(x)||x||)
Ip/2−1(κ(x)||x||)
x
||x||,

9.8 Notes
493
avec Iν fonction de Bessel modiﬁ´ee. Il se comporte comme un estimateur `a
r´etr´ecisseur (2.16) pour de grandes valeurs de ||x||, comme le montrent Bock et
Robert (1985) et Beran (1996). (Voir l’Exercice 10.37.)
∥
Pour une fonction estimable invariablement h(θ), Helland (1999) consid`ere le
sous-groupe de ¯
G suivant :
¯K = {¯g ∈¯
G ; h(¯gθ) = h(θ) pour tout θ ∈Θ} ,
puisque h(θ) est un invariant maximal pour ¯K. ´Etant donn´e le sous-groupe
correspondant de G ,
K = {g ∈G ; ¯g ∈¯K} ,
soit z une variable maximalement invariante pour K. Si η = h(θ), Helland
(1999) montre que le paradoxe de marginalisation ne se produit pas pour (η, z)
lorsqu’on utilise la mesure de Haar `a droite associ´ee `a
¯
G . Cela signiﬁe que,
sous cette mesure, si θ = (η, ξ) et x = (z, y), et si la distribution a posteriori
marginale de η d´epend seulement de z, elle peut ˆetre obtenue comme distribution
a posteriori sur z uniquement.

10
Extensions hi´erarchique et empirique
“Books and papers and scrolls covered nearly every ﬂat surface,
with all sorts of odd things interspeded among the piles, and some-
times on top of them. Strange shapes of glass or metal, spheres and
tubes interlinked, and circles held inside circles, stood among bones
and skulls of every shape and description.”
Robert Jordan, The Dragon Reborn.
10.1 Lois a priori incompl`etes
Dans les chapitres pr´ec´edents, nous avons mis en avant (parfois avec insis-
tance !) l’ambivalence de l’analyse bay´esienne : elle a un potentiel d’´elimination
suﬃsant pour conduire `a une prise de d´ecision pratique mais cette eﬃcacit´e
doit ˆetre maˆıtris´ee. Ainsi, les choix subjectifs de l’analyse bay´esienne peuvent
toujours ˆetre r´egl´es pour aboutir `a une conclusion ﬁx´ee `a l’avance. De tels tra-
vers sont certes ´egalement possibles dans un cadre fr´equentiste, par le choix
des fonctions de coˆut ou d’estimation, et l’approche classique ne fait mˆeme
pas de distinction entre les parties objective et subjective d’une analyse. Mais
notre message essentiel ici, d´ej`a pr´esent´e dans le Chapitre 3, est que le choix
d’une loi a priori par le statisticien devrait toujours ˆetre justiﬁable, c’est-`a-dire
´etabli `a partir d’arguments sens´es (ou “reproductibles”). Par cons´equent, le
fait que les outils bay´esiens puissent donner des inf´erences erron´ees ne saurait
ˆetre vu comme un d´efaut du paradigme bay´esien.
Une critique plus pertinente est en revanche que l’information a priori
est rarement assez riche pour en d´eduire une loi a priori exacte. Il paraˆıt

496
10 Extensions hi´erarchique et empirique
alors n´ecessaire d’incorporer cette incertitude au mod`ele bay´esien, bien que
la notion de lois a priori semble insuﬃsante pour rendre pleinement compte
de l’ignorance. La mod´elisation de cette incertitude r´esiduelle a inspir´e des
variations autour du paradigme bay´esien, comme les probabilit´es hautes et
basses de Dempster (1968) ou les probabilit´es impr´ecises de Walley (1991).
L’hypoth`ese de l’analyse bay´esienne hi´erarchique est au contraire que
ces consid´erations peuvent ˆetre incorpor´ees au paradigme bay´esien. Il s’agit
de mod´eliser l’information a priori en la d´ecomposant en plusieurs niveaux
de distributions a priori conditionnelles. On peut par l`a mˆeme distinguer
les caract`eres structurel et subjectif de l’information. Suivant le paradigme
bay´esien, l’incertitude `a tous les niveaux est prise en compte au moyen de lois
a priori additionnelles. Dans les cas les plus simples, la structure hi´erarchique
ne contient que deux niveaux, les param`etres du premier ´etant associ´es `a une
distribution a priori d´eﬁnie dans le second. La distribution de premier ni-
veau est en g´en´eral une loi a priori conjugu´ee, un choix qui se justiﬁe par
la facilit´e de calcul mais aussi parce que le niveau le plus haut peut d’une
certaine mani`ere compenser les erreurs de mod´elisation des plus bas niveaux.
(Une autre justiﬁcation pour la mod´elisation conjugu´ee se trouve dans Dalal
et Hall, 1983, et Diaconis et Ylvisaker, 1985 ; voir la Section 3.4.) Nous avons
d´ej`a ´etudi´e des exemples d’une telle mod´elisation dans le Chapitre 6, comme
dans l’Exemple 6.21.
Une caract´eristique g´en´erale de la mod´elisation hi´erarchique est qu’elle
am´eliore la robustesse des estimateurs de Bayes obtenus : tout en int´egrant
l’information a priori, ces estimateurs sont ´egalement performants d’un point
de vue fr´equentiste (minimaxit´e et admissibilit´e), mˆeme si ces deux crit`eres
sont souvent diﬃciles `a concilier.
On trouve d’autres justiﬁcations `a la mod´elisation bay´esienne hi´erarchique
dans les probl`emes r´eels, puisqu’il existe des cadres en m´edecine, biolo-
gie, ´elevage animalier, ´economie, etc., dans lesquels la population `a la-
quelle on s’int´eresse peut ˆetre vue comme sous-population d’une population,
voire comme sous-population d’une sous-population d’une population globale.
C’est, par exemple, le cas en m´eta analyse, lorsqu’on cherche `a rassembler
les r´esultats de plusieurs exp´eriences concernant le mˆeme ph´enom`ene mais
r´ealis´ees sur diﬀ´erents lieux ou populations et suivant divers protocoles (voir,
par exemple, Mosteller et Chalmers, 1992, Mengersen et Tweedie, 1995, ou
Givens et al., 1997).
Exemple 10.1. (Guihenneuc-Jouyaux et al., 1998)
Le virus de l’immu-
nod´eﬁcience humaine (VIH) est le virus responsable du SIDA. Pour un patient
donn´e, la transition de l’infection VIH vers le SIDA peut ˆetre repr´esent´ee
par sept ´etapes de gravit´e croissante, la derni`ere ´etant celle du SIDA. Les
d´eplacements entre les ´etats sont repr´esent´es par un mod`ele de Markov `a
temps continu avec g´en´erateur inﬁnit´esimal Λ. (Cela signiﬁe que la distribu-

10.1 Lois a priori incompl`etes
497
tion de l’´etat `a l’instant T , connaissant la distribution ω0 = (ω01, . . . , ω07) `a
l’instant 0, est donn´ee par le produit matriciel ω0 · exp{T Λ}73.)
Les six premi`eres ´etapes d’infection du VIH ne sont pas observables direc-
tement mais seulement par le biais de variables al´eatoires (1 ≤i ≤n , 1 ≤j ≤
ni),
xij ∼N
	
μSij, σ2
,
o`u i d´esigne l’individu et j le point d’´evolution, 1 ≤Sij ≤6 ´etant l’´etape
du VIH. Les xij repr´esentent des marqueurs sanguins (taux de T4) sujets `a
une grande variabilit´e et `a des erreurs de mesure. Il s’agit d’un cas particulier
de mod`ele de Markov cach´e (Exercice 6.50), avec la diﬃcult´e suppl´ementaire
que la chaˆıne de Markov cach´ee op`ere `a temps continu. Mais l’algorithme
forward-backward vu dans l’Exercice 6.51 s’applique aussi ici (Exercice 10.2).
Un mod`ele similaire a ´et´e propos´e par Kirby et Spiegelhalter (1994).
Les Sij constituent donc le premier niveau d’un mod`ele hi´erarchique, avec
des hyperparam`etres, comme la matrice g´en´eratrice Λ, correspondant au se-
cond niveau et commun `a tous les individus. Un autre hyperparam`etre est δ,
la distribution a priori de l’´etape du VIH `a la premi`ere observation. Il est sou-
vent pratique de repr´esenter ces mod`eles hi´erarchiques sous forme de graphes
(plus pr´ecis´ement de graphes acycliques orient´es ou DAG (pour Directed Acy-
clic Graph)). La Figure 10.1 donne cette repr´esentation pour le mod`ele VIH,
avec la convention usuelle que les rectangles correspondent `a des quantit´es
observ´ees ou connues et les cercles aux quantit´es inconnues ; les ﬂ`eches sym-
bolisent la d´ependance probabiliste. (Voir la Note 10.7.1 et Lauritzen, 1996,
pour plus de d´etails sur les mod`eles graphiques.)
∥
L’analyse bay´esienne empirique part de la mˆeme id´ee d’impr´ecision sur l’in-
formation a priori, mais la traite `a un niveau plus pragmatique. On consid`ere
dans cette optique qu’il est illusoire d’esp´erer mod´eliser cette impr´ecision sur
plusieurs niveaux de lois conditionnelles, alors mˆeme que le premier niveau est
d´ej`a tr`es faiblement connu. De fa¸con assez paradoxale, l’analyse bay´esienne
empirique repose elle aussi sur une mod´elisation a priori conjugu´ee, en esti-
mant les hyperparam`etres `a partir des observations et en utilisant ensuite cet
“a priori estim´e” comme a priori normal pour l’inf´erence. Il va sans dire que
le remplacement des hyperparam`etres par des hyperparam`etres estim´es, qui
constitue la base de l’analyse bay´esienne empirique, l’exclut de fait du para-
digme bay´esien. Mais elle permet au statisticien de tirer parti de l’information
a priori vague de mani`ere simpliﬁ´ee. En outre, il se trouve que les estimateurs
ainsi construits ont souvent de bonnes propri´et´es fr´equentistes mˆeme s’il y
a trop d’arbitraire dans la d´etermination des hyperparam`etres pour en faire
une r`egle g´en´erale. Un avantage annexe de la mod´elisation bay´esienne em-
pirique est de fournir des justiﬁcations bay´esiennes `a l’eﬀet de Stein (Note
73L’extension de la fonction exponentielle aux cas multivari´es comme celui-ci est
obtenue en utilisant le d´eveloppement en s´erie de exp(x). Voir l’Exercice 10.2.

498
10 Extensions hi´erarchique et empirique
δ
μ,
Λ
2
Sini
Xini
"vrais" etats
valeurs observees des marqueurs
parametres du processus de mesure
generateur infinitesimal du processus 
de  Markov
.......
.......
S
X
X
i1
i1
i2
Si2
σ
Fig. 10.1. Graphe acyclique orient´e du mod`ele hi´erarchique. (Source : Guihenneuc-
Jouyaux et al., 1998.)
2.8.2). L’analyse bay´esienne empirique se pr´esente enﬁn comme une alterna-
tive attrayante lorsque l’analyse bay´esienne hi´erarchique est trop compliqu´ee
`a mettre en œuvre, mˆeme si cet argument est de moins en moins justiﬁ´e avec
l’eﬃcacit´e grandissante des techniques de calcul (voir le Chapitre 6).
10.2 Analyse bay´esienne hi´erarchique
Cette section n’est qu’une courte introduction `a l’analyse bay´esienne
hi´erarchique et elle cible plus particuli`erement quelques aspects int´eressants
de cette approche. Pour un traitement plus exhaustif, voir Berger (1985b),
en lien avec la notion de robustesse, Deely et Lindley (1981), Dumouchel et
Harris (1983), George (1986b), Angers et MacGibbon (1990), Gelman et al.
(2003), Hobert (2000b) et Draper (1995). Pour les applications `a l’´elevage
animalier, voir, par exemple, Fouley et al. (1992).
10.2.1 Mod`eles hi´erarchiques
Pour des raisons li´ees `a la mod´elisation des observations ou `a la d´ecomposi-
tion de l’information a priori, il peut arriver que le mod`ele statistique bay´esien
soit hi´erarchique, c’est-`a-dire mette en jeu plusieurs niveaux de distributions
a priori conditionnelles.

10.2 Analyse bay´esienne hi´erarchique
499
D´eﬁnition 10.2. Un mod`ele bay´esien hi´erarchique est un mod`ele statistique
bay´esien (f(x|θ), π(θ)), dans lequel la loi a priori π(θ) est d´ecompos´ee en
plusieurs lois conditionnelles
π1(θ|θ1), π2(θ1|θ2), . . . , πn(θn−1|θn)
et une loi marginale πn+1(θn) telle que
π(θ) =

Θ1×...×Θn
π1(θ|θ1)π2(θ1|θ2) · · · πn+1(θn) dθ1 · · · dθn+1.
(10.1)
Les param`etres θi sont appel´es hyperparam`etres de niveau i (1 ≤i ≤n).
Avant d’insister sur l’utilit´e d’une telle d´ecomposition, remarquons qu’on
trouve ´egalement des structures hi´erarchiques dans des mod`eles statistiques
classiques.
Exemple 10.3. Un cas typique d’utilisation de mod`eles hi´erarchiques est la
prise en compte d’eﬀets al´eatoires au sein d’un mod`ele lin´eaire. Cette exten-
sion peut s’´ecrire sous la forme
y|θ ∼Np(θ, Σ1),
θ|β ∼Np(Xβ, Σ2),
sans lien avec une mod´elisation bay´esienne. La moyenne de y, θ, est d´ecompo-
s´ee en eﬀets ﬁxes, Xβ, et en eﬀets al´eatoires, Zη, avec η normale de moyenne
0 (la matrice de covariance Σ2 peut alors ˆetre singuli`ere). Ces mod`eles sont
souvent employ´es en biom´etrie, en particulier en am´elioration de races ani-
males, pour diﬀ´erencier l’inﬂuence des ´el´ements ﬁxes (par exemple, lign´ee,
race, ann´ee, etc.) de celle des facteurs al´eatoires (par exemple, femelles dans
une lign´ee).
∥
Un autre exemple classique de structure hi´erarchique non bay´esienne est
celui des mod`eles `a variables latentes, comme les m´elanges (Section 6.4) ou
les m´elanges cach´es (Note 6.6.3). Le vecteur des variables latentes z constitue
alors le premier niveau du mod`ele bay´esien hi´erarchique, la mod´elisation a
priori en tant que telle ayant lieu `a des niveaux plus ´elev´es.
Ces exemples montrent bien que la fronti`ere entre mod`eles hi´erarchiques
classiques et bay´esiens est parfois ﬂoue et d´epend essentiellement de l’in-
terpr´etation des param`etres. Par exemple, dans le mod`ele `a eﬀets al´eatoires,
la proc´edure est classique si l’inf´erence porte sur les eﬀets ﬁxes (β) mais
bay´esienne si on consid`ere l’eﬀet global (θ). De mˆeme, si on s’int´eresse aux
variables latentes zt, comme dans le mod`ele `a volatilit´e stochastique (4.41)
pour les y∗
t , il s’agit de donn´ees manquantes alors que, si elles sont utilis´ees
pour repr´esenter le mod`ele de fa¸con plus pratique, comme dans le cas des

500
10 Extensions hi´erarchique et empirique
m´elanges utilis´es pour la mod´elisation non param´etrique, les zt peuvent ˆetre
consid´er´es comme partie int´egrante de la mod´elisation a priori.
Insistons sur le fait qu’un mod`ele bay´esien hi´erarchique n’est rien d’autre
qu’un cas particulier de mod`ele bay´esien. Ainsi, si
x ∼f(x|θ), θ ∼π1(θ|θ1), . . . , θn ∼πn+1(θn),
(10.2)
on retrouve le mod`ele bay´esien usuel
x ∼f(x|θ),
θ ∼π(θ),
pour l’a priori
π(θ) =

Θ1×...×Θn
π1(θ|θ1) . . . πn(θn−1|θn)πn+1(θn) dθ1 · · · dθn.
Cela montre que les mod`eles hi´erarchiques s’int`egrent bien au paradigme
bay´esien et donc que cette approche b´en´eﬁcie des propri´et´es g´en´erales d’op-
timalit´e de la perspective bay´esienne avec quelques avantages additionnels
li´es `a la d´ecomposition de la loi a priori (voir la Section 10.3). Cela montre
´egalement pourquoi il est rarement n´ecessaire d’aller plus loin que deux ni-
veaux de d´ecomposition conditionnelle dans la hi´erarchie. Si les hyperpa-
ram`etres θ1, . . . , θn ne sont d’aucun int´erˆet pour l’inf´erence (sur θ), il est
´equivalent de consid´erer le mod`ele hi´erarchique plus simple
x|θ ∼f(x|θ),
θ|θ1 ∼π1(θ|θ1) ,
avec
θ1 ∼π2(θ1) =

Θ2×...×Θn
π1(θ1|θ2) · · · πn+1(θn) dθ2 · · · dθn ,
qui ´elimine les ´etapes interm´ediaires et les hyperparam`etres suppl´ementaires.
N´eanmoins, une d´ecomposition plus compliqu´ee peut toujours se justiﬁer pour
la construction et le calcul pratique d’estimateurs de Bayes, comme nous
l’avons vu dans le Chapitre 6.
Exemple 10.4. Robert et Reber (1998) ´etudient une exp´erience dans la-
quelle des rats sont intoxiqu´es par une substance, puis trait´es par un placebo
ou un m´edicament. Le mod`ele associ´e `a cette exp´erience est un mod`ele lin´eaire
`a eﬀets additifs : ´etant donn´e xij, yij et zij, j-i`emes r´eponses du rat i aux
´etapes respectivement de contrˆole, d’intoxication et de traitement, on suppose
que (1 ≤i ≤I)
xij ∼N (θi, σ2
c),
1 ≤j ≤Jc
i ,
yij ∼N (θi + δi, σ2
a),
1 ≤j ≤Ja
i ,
zij ∼N (θi + δi + ξi, σ2
t ),
1 ≤j ≤Jt
i ,
o`u θi est la mesure de contrˆole moyenne, δi l’eﬀet moyen d’intoxication et ξi
l’eﬀet moyen de traitement pour le rat i, les variances de ces mesures ´etant

10.2 Analyse bay´esienne hi´erarchique
501
constantes pour les eﬀets de contrˆole, d’intoxication et de traitement. Une
variable (observ´ee) suppl´ementaire est wi, qui est ´egale `a 1 si le rat est trait´e
avec le m´edicament, et 0 sinon.
Puisque le but de l’exp´erience est de d´eterminer l’eﬀet global du m´edica-
ment test´e, les diﬀ´erentes moyennes individuelles sont mises en relation par
une loi a priori commune (conjugu´ee) (1 ≤i ≤I),
θi ∼N (μθ, σ2
θ),
δi ∼N (μδ, σ2
δ),
et
ξi ∼N (μP , σ2
P )
ou
ξi ∼N (μD, σ2
D),
suivant que le rat i soit trait´e avec un placebo ou avec un m´edicament. Les
hyperparam`etres du mod`ele,
μθ, μδ, μP , μD, σc, σa, σt, σθ, σδ, σP , σD ,
sont alors associ´es aux lois a priori non informatives de Jeﬀreys. Cet a priori
permet de d´eduire une loi a posteriori bien d´eﬁnie pourvu qu’il y ait au moins
deux observations pour chaque ´etape de l’exp´erience.
∥
10.2.2 Justiﬁcations
L’analyse bay´esienne hi´erarchique s’appuie en partie sur les travaux de
Good (voir Good, 1980, 1983, pour plus de d´etails). Lindley et Smith (1972)
traitent le cas particulier des mod`eles lin´eaires, en jouant sur la dualit´e
entre l’analyse bay´esienne classique d’un mod`ele `a eﬀets al´eatoires et l’ana-
lyse bay´esienne hi´erarchique d’un mod`ele de r´egression standard. Bien qu’un
mod`ele bay´esien hi´erarchique ne soit qu’un cas particulier de mod`ele bay´esien,
comme en t´emoigne l’´equation (10.1), la d´ecomposition
π(θ) =

Θ1
π1(θ|θ1)π2(θ1) dθ1
ou sa g´en´eralisation (10.1) peuvent ˆetre privil´egi´ees pour un certain nombre
de raisons :
(i) Les deux premiers niveaux de la hi´erarchie peuvent ˆetre sugg´er´es par des
raisons objectives li´ees `a la mod´elisation du ph´enom`ene observ´e comme cas
particulier d’une m´etapopulation sur laquelle on dispose de connaissances
a priori, ce qui justiﬁe le recours `a l’approche bay´esienne. C’est le cas
des Exemples 10.3 et 10.4. Plus g´en´eralement, comme nous l’avons vu en
Section 10.1, les mod`eles bay´esiens hi´erarchiques interviennent naturelle-
ment en m´eta analyse lorsqu’on doit regrouper les r´esultats de diﬀ´erentes
´etudes.

502
10 Extensions hi´erarchique et empirique
Exemple 10.5. (Berger, 1985b) On consid`ere xi ∼N (βi, 10) (i = 1, . . . ,
7), correspondant `a des mesures annuelles ind´ependantes du quotient in-
tellectuel (QI) d’un enfant, sur sept ann´ees cons´ecutives. Dans la mesure
o`u les tests de QI int`egrent une correction tenant compte de l’ˆage, il est
raisonnable de consid´erer que les βi ont la mˆeme moyenne θ, qui est la
“vraie” valeur du QI. On peut alors poser la loi a priori de premier niveau
suivante :
βi|θ ∼N (θ, σ2
π)
(i = 1, . . . , 7).
De plus, si l’enfant fait partie d’un ensemble bien identiﬁ´e, on peut dis-
poser d’une information sur cette population comme, par exemple,
θ ∼N (ξ, τ2),
avec ξ et τ connus. Nous obtenons ainsi le deuxi`eme niveau d’analyse. Au
contraire, une alternative non informative serait de prendre π2(θ) = 1. ∥
(ii) En poussant plus loin la justiﬁcation ci-dessus, un chercheur peut vouloir
diviser la mod´elisation a priori en deux parties, la premi`ere correspondant
`a l’information structurelle concernant le mod`ele et la seconde correspon-
dant `a une information plus subjective. Par exemple, l’information peut
ˆetre li´ee `a des restrictions lin´eaires impr´ecises sur les param`etres d’un
mod`ele de r´egression et la loi des hyperparam`etres π2(θ1) peut prendre en
compte le caract`ere incertain de ces restrictions.
Exemple 10.6. Albert (1988) s’int´eresse aux incertitudes sur les mod`eles
lin´eaires g´en´eralis´es (McCullagh et Nelder, 1989) (i = 1, . . . , n)
yi|xi ∼exp{θi · yi −ψ(θi)} ,
∇ψ(θi) = E[yi|xi] = h(xt
iβ) ,
o`u h est la fonction de lien et xi ∈Rq un vecteur de covariables, en
reportant la contrainte de lin´earit´e ∇ψ(θi) = h(xt
iβ) `a un niveau plus
haut de hi´erarchie, c’est-`a-dire en introduisant l’a priori conjugu´e
θi ∼exp {λ [θi · ξi −ψ(θi)]}
tel que E[∇ψ(θi)] = h(xt
iβ). Le param`etre de r´egression β est alors
transf´er´e `a un second niveau avec, ´eventuellement, un a priori normal
β ∼Nq(0, τ2Iq), qui admet comme cas limite τ = ∞l’a priori constant.
La variance a posteriori de ψ(θi) est alors un indicateur de la pr´ecision
du mod`ele lin´eaire g´en´eralis´e et permet donc de mesurer la pertinence de
l’hypoth`ese de lin´earit´e.
∥
Exemple 10.7. (Suite de l’Exemple 10.4) Une alternative ´egalement
consid´er´ee dans Robert et Reber (1998) est de choisir comme loi a priori

10.2 Analyse bay´esienne hi´erarchique
503
δi ∼pN (μδ1, σ2
δ1) + (1 −p)N (μδ2, σ2
δ2),
(10.3)
qui introduit deux niveaux diﬀ´erents d’intoxication, c’est-`a-dire deux
r´eactions `a l’intoxication au sein de la population de rats. Comme l’ex-
pliquent Robert et Reber (1998), il existe des raisons li´ees au m´etabolisme
justiﬁant cette modiﬁcation de la loi a priori. Mˆeme si la structure de
m´elange se r´epercute sur les lois marginales des yij, elle est diﬀ´erente d’un
mod`ele de m´elange habituel puisqu’elle exige que les yij pour 1 ≤j ≤Ja
i
appartiennent `a la mˆeme composante de m´elange.
∥
(iii) `A l’inverse, dans un cadre non informatif, un mod`ele bay´esien hi´erarchique
est un compromis entre les lois non informatives de Jeﬀreys, qui sont dif-
fuses mais parfois diﬃciles `a utiliser et `a expliquer, et les lois conjugu´ees,
qui sont subjectivement peu justiﬁables mais num´eriquement pratiques.
Lorsque les hyperparam`etres ont une hyperdistribution a priori (ou hyper
a priori), on fait un pas vers le non informatif, tout en ´etant g´en´eralement
capable d’´etablir la loi a posteriori de θ. Une option est d’it´erer cet ar-
gument par l’introduction d’une loi conjugu´ee sur θ1, π2(θ1|θ2) et une
loi non informative sur θ2. N´eanmoins, l’introduction d’une loi conjugu´ee
sur θ1 ne permet plus forc´ement de garantir que l’estimateur de Bayes
soit calculable analytiquement et, pire encore, ne semble pas am´eliorer la
robustesse du mod`ele. Quel que soit le nombre de niveaux dans la dis-
tribution, int´egrer sur les param`etres inconnus ne peut que renforcer la
robustesse de la loi a priori par rapport `a une approche conjugu´ee clas-
sique. Les lecteurs pourront lire Berger (1985b) pour comprendre en quoi
la mod´elisation hi´erarchique est int´eressante du point de vue de la robus-
tesse.
Exemple 10.8. On consid`ere le mod`ele de r´egression classique, y =
Xβ + ϵ, c’est-`a-dire y ∼Nn(Xβ, σ2In), avec β ∈Rp. Pour des rai-
sons structurelles, les coeﬃcients de r´egression sont presque les mˆemes.
Par exemple, les βi peuvent d´ecrire les taux d’investissement de plusieurs
constructeurs automobiles europ´eens qui sont g´en´eralement assez proches.
On suppose alors que βi ∼N (ξ, σ2
π), ξ ´etant la valeur usuelle. Un tel
mod`ele est dit ´echangeable (voir la Note 3.8.2, Bernardo et Smith, 1994,
et Gelman et al., 2003 ). Si on dispose de plus d’informations sur la valeur
habituelle, on peut prendre ξ = ξ0 ou ξ ∼N (ξ0, τ2). Sinon, le second
niveau peut ˆetre non informatif : π2(ξ) = 1.
∥
Exemple 10.9. (Suite de l’Exemple 10.3) Dans le cadre du mod`ele
lin´eaire `a eﬀets al´eatoires,
y|θ ∼Np(θ, Σ1),
θ|β ∼Np(Xβ, Σ2),

504
10 Extensions hi´erarchique et empirique
Lindley et Smith (1972) et Smith (1973) supposent que β v´eriﬁe ´egalement
une relation lin´eaire et utilisent l’a priori suivant :
β ∼Nn(Zξ, Σ3).
Un a priori alternatif assurant plus de robustesse est
β ∼Tn(α, Zξ, Σ3),
mais cette distribution met en jeu un niveau de hi´erarchie suppl´ementaire
par rapport `a la distribution normale originale, comme le montre Dickey
(1968). En eﬀet, on a
β|z ∼Np(Zξ, Σ3/z),
z ∼G (α/2, α/2),
dans ce cas. Si on consid`ere β|z ∼Np(μ, zΣ3) (loi conjugu´ee) et π(z) =
1/z (loi non informative), la loi marginale
β ∼Tp(p/2, μ, Σ3),
est propre, contrairement au cas de la loi non informative π(β) = 1.
∥
(iv) Un autre aspect positif de l’analyse bay´esienne hi´erarchique est qu’elle
augmente ´egalement la robustesse de l’analyse bay´esienne classique d’un
point de vue fr´equentiste, puisqu’elle r´eduit l’arbitraire sur le choix de
l’hyperparam`etre (parfois report´e `a un niveau plus ´elev´e) et ´etablit une
moyenne des r´eponses bay´esiennes conjugu´ees. La Section 10.3 montre
que, dans le cas normal, de nombreuses lois a priori sur les hyperpa-
ram`etres donnent des estimateurs de Bayes g´en´eralis´es minimax.
(v) Un dernier avantage de l’approche bay´esienne hi´erarchique est sa capa-
cit´e `a souvent simpliﬁer les calculs bay´esiens. La d´ecomposition d’une
loi a priori π en plusieurs composantes π1, . . . , πn (qui peuvent ˆetre, par
exemple, des lois conjugu´ees) permet parfois d’obtenir des approximations
plus ais´ees de certaines quantit´es a posteriori par simulation, comme nous
l’avons d´ej`a mentionn´e en Section 6.3.5 au sujet de l’´echantillonnage de
Gibbs.
10.2.3 D´ecompositions conditionnelles
Une caract´eristique particuli`erement int´eressante des mod`eles hi´erarchi-
ques est que le conditionnement est possible `a tous les niveaux et cette libert´e
dans la d´ecomposition de la loi a posteriori compense l’augmentation appa-
rente de complexit´e de la structure. Par exemple, si
θ|θ1 ∼π1(θ|θ1),
θ1 ∼π2(θ1),
nous avons le r´esultat suivant.

10.2 Analyse bay´esienne hi´erarchique
505
Lemme 10.10. La loi a posteriori de θ est
π(θ|x) =

Θ1
π(θ|θ1, x)π(θ1|x) dθ1,
avec
π(θ|θ1, x) = f(x|θ)π1(θ|θ1)
m1(x|θ1)
,
m1(x|θ1) =

Θ
f(x|θ)π1(θ|θ1) dθ,
π(θ1|x) = m1(x|θ1)π2(θ1)
m(x)
,
m(x) =

Θ1
m1(x|θ1)π2(θ1) dθ1.
En outre, cette d´ecomposition est valide pour les moments a posteriori, c’est-
`a-dire pour toute fonction h, on a
Eπ[h(θ)|x] = Eπ(θ1|x) [Eπ1 [h(θ)|θ1, x]] ,
o`u
Eπ1[h(θ)|θ1, x] =

Θ
h(θ)π(θ|θ1, x) dθ.
Ce r´esultat d´ecoule naturellement du th´eor`eme de Bayes, la derni`ere ´egalit´e
provenant du th´eor`eme de Fubini. Il n’en a pas moins des cons´equences im-
portantes sur le calcul des estimateurs de Bayes puisqu’il montre qu’on peut
simuler π(θ|x) en g´en´erant d’abord θ1 selon π(θ1|x) puis θ selon π(θ|θ1, x),
dans le cas o`u ces deux lois conditionnelles sont plus accessibles.
Exemple 10.11. (Suite de l’Exemple 10.4) La loi a posteriori du vecteur
de param`etres complet s’´ecrit
π((θi, δi, ξi)i, μθ, . . . , σc, . . . |D) ∝
I
i=1

exp −{(θi −μθ)2/2σ2
θ + (δi −μδ)2/2σ2
δ}
Jc
i

j=1
exp −{(xij −θi)2/2σ2
c}
Ja
i

j=1
exp −{(yij −θi −δi)2/2σ2
a}
Jt
i

j=1
exp −{(zij −θi −δi −ξi)2/2σ2
t }


ℓi=0
exp −{(ξi −μP )2/2σ2
P }

ℓi=1
exp −{(ξi −μD)2/2σ2
D}
(10.4)
σ
−P
i Jc
i −1
c
σ
−P
i Ja
i −1
a
σ
−P
i Jt
i −1
t
(σθσδ)−I−1σ−ID−1
D
σ−IP −1
P
,

506
10 Extensions hi´erarchique et empirique
o`u D d´esigne l’´echantillon. Les lois marginales a posteriori des param`etres
d’int´erˆet ne s’int`egrent donc pas analytiquement et ne permettent pas d’obte-
nir des formules explicites pour les esp´erances a posteriori de ces param`etres.
N´eanmoins, on peut obtenir les lois conditionnelles compl`etes, comme le
montre l’Exercice 10.14.
∥
Naturellement, le Lemme 10.10 n’est valable que lorsque les diﬀ´erentes
int´egrales sont bien d´eﬁnies. Mais ce n’est pas toujours le cas puisque les lois
de second niveau sont g´en´eralement impropres. Le lemme suivant donne une
condition suﬃsante d’existence des moments a posteriori pour x|θ ∼Np(θ, Σ)
(voir Berger et Robert, 1990, pour une d´emonstration).
Lemme 10.12. Si la loi marginale
m(x) =

Θ
f(x|θ)π(θ) dθ
est ﬁnie pour tout x ∈Rk, alors la moyenne et la variance de la loi a posteriori
π(θ|x) existent toujours.
Le r´esultat suivant porte sur un autre avantage des mod`eles hi´erarchiques,
`a savoir leur inﬂuence dans le calcul des estimateurs bay´esiens hi´erarchiques :
Lemme 10.13. Pour le mod`ele hi´erarchique (10.2), la densit´e conditionnelle
compl`ete de θi sachant x et les θj (j ̸= i) v´eriﬁe
π(θi|x, θ, θ1, . . . , θn) = π(θi|θi−1, θi+1)
avec la convention θ0 = θ et θn+1 = 0.
Preuve. Puisque
π(θi|x, θ, θ1, . . . , θn) ∝f(x|θ)π1(θ|θ1) · · · πn+1(θn+1)
∝πi−1(θi−1|θi)πi(θi|θi+1) ,
la distribution a posteriori ne d´epend que des deux niveaux adjacents de la
hi´erarchie.
⊓⊔
L’importance de ce r´esultat pourtant simple r´eside dans le fait que seuls
des hyperparam`etres locaux interviennent dans les lois conditionnelles d’un
mod`ele hi´erarchique. Dans des cadres comme les mod`eles graphiques ou spa-
tiaux, o`u la densit´e jointe est d´eﬁnie localement sur un groupe d’hyperpa-
ram`etres (appel´e clique dans les mod`eles graphiques), le Lemme 10.13 montre
que les techniques num´eriques telles que l’´echantillonneur de Gibbs (Section
6.3.3) sont les seules envisageables pour traiter ces mod`eles complexes.

10.2 Analyse bay´esienne hi´erarchique
507
10.2.4 Probl`emes num´eriques
Un inconv´enient des mod`eles hi´erarchiques est qu’ils ne permettent en
g´en´eral pas un calcul explicite des estimateurs de Bayes, mˆeme lorsque les
niveaux successifs sont conjugu´es, et il faut donc avoir recours `a des techniques
num´eriques d’approximation.
Exemple 10.14. On consid`ere x ∼B(n, p) et p|m ∼Be(m, m) avec m ∈
N∗. Alors,
π1(p|m) = Γ(2m)
Γ(m)2 [p(1 −p)]m−1
= (2m −1)
2m −2
m −1

[p(1 −p)]m−1.
Si la loi a priori de second niveau est π2(m) = 1/(2m −1), la loi a priori sur
p est
π(p) =

N∗π1(p|m)π2(m) dm
=
+∞

n=0
2n
n

[p(1 −p)]n.
La loi a posteriori
π(p|x) =

π1(p|m, x)π2(m|x) dm
ne peut ˆetre obtenue analytiquement puisque mˆeme si π(p|m, x) est une loi
bˆeta Be(m + x, m + n −x), π(m|x) est la loi bˆeta-binomiale
(m + x −1) . . . m (m + n −x −1) . . . m
(2m + n −1) . . . (2m)(2m −1)
`a un facteur de normalisation pr`es. Les quantit´es a posteriori comme Eπ[p|x]
ne sont pas calculables analytiquement.
∥
La solution la plus naturelle en analyse hi´erarchique est de faire appel
`a des outils de simulation. En eﬀet, comme nous l’avons vu ci-dessus, la
d´ecomposition issue des Lemmes 10.10 et 10.13 est particuli`erement per-
tinente dans ce contexte, puisqu’elle permet de simuler naturellement par
l’´echantillonneur de Gibbs ou d’autres techniques MCMC (Sections 6.3.2 et
6.3.3). Cela ´etait d´ej`a manifeste dans les exemples de la Section 6.3.5 et ceux
qui suivent ne font que conﬁrmer l’ad´equation entre mod`eles hi´erarchiques et
m´ethodes MCMC (voir aussi Gelman et al., 2003 , et Robert et Casella, 1999,
Section 7.1.6).

508
10 Extensions hi´erarchique et empirique
Exemple 10.15. Soient
x ∼Np(θ, Σ)
et
θ|μ, ξ ∼Np(μ, B(ξ)) ,
avec B(ξ) = ξC −Σ. La matrice d´eﬁnie positive C est ﬁx´ee et ξ varie sur
la demi-droite [λmax(C−1Σ), +∞), o`u λmax(A) d´esigne la plus grande valeur
propre de A. Cette repr´esentation de la matrice de covariance a posteriori
simpliﬁe les calculs tout en garantissant la robustesse des estimateurs. Par
exemple, une mod´elisation de second niveau sur (μ, ξ) peut impliquer des lois
non informatives. Cependant, une hypoth`ese commune est de supposer que
μ = Y β pour β ∈Rk et pour un r´egresseur donn´e Y tel que Y tCY soit de
rang plein, avec une loi non informative sur β. On peut alors montrer que
m(x) < +∞si p > 2 + k (Exercice 10.12).
∥
 
 
0
2000
4000
6000
8000 10000
1.60
1.70
1.80
1.90
 
 
 
 
0
2000
4000
6000
8000 10000
-2.90 -2.80 -2.70 -2.60
 
 
 
 
0
2000
4000
6000
8000 10000
0.40
0.50
0.60
0.70
 
 
 
 
0
2000
4000
6000
8000 10000
1.7 1.8 1.9 2.0 2.1
 
 
Fig. 10.2.
Courbes de convergence pour μθ (en haut `a gauche), μδ (en haut `a
droite), μP (en bas `a gauche) et μD (en bas `a droite) dans l’exp´erience de l’Exemple
10.4. Les courbes en pointill´es qui repr´esentent les moyennes Rao–Blackwellis´ees
partielles sont presque indiscernables des moyennes standard. (Source : Robert et
Reber, 1998.)
Exemple 10.16. (Suite de l’Exemple 10.4)
Puisque les distributions
conditionnelles compl`etes correspondent aux distributions standard (Exercice
10.14), l’´echantillonneur de Gibbs est applicable. La Figure 10.2 montre la
convergence des esp´erances a posteriori des quatre moyennes, en fonction du
nombre d’it´erations k, `a la fois pour la moyenne partielle et l’estimateur de
Rao-Blackwell (voir la Section 6.3.4). ´Etant donn´e que les deux quantit´es
convergent vers le mˆeme estimateur de Bayes, la forte ressemblance des deux
courbes est un indicateur partiel de convergence, ce qui sugg`ere que dix mille
it´erations d’un ´echantillonneur de Gibbs devraient ˆetre suﬃsantes pour assu-
rer la stabilit´e.

10.2 Analyse bay´esienne hi´erarchique
509
Fig. 10.3.
Histogrammes des ´echantillons de Gibbs pour μθ, μδ, μP et μD dans
l’exp´erience de l’Exemple 10.4. (Source : Robert et Reber, 1998.)
Puisque nous souhaitons ´evaluer les eﬀets de l’intoxication et des deux
traitements, nous nous int´eressons aux comparaisons de μδ, μD, μP et de
μD −μP `a 0. Le Tableau 10.1 donne les probabilit´es a posteriori que les eﬀets
soient signiﬁcatifs, c’est-`a-dire qu’on ait 0 > μδ, μD > 0, etc., ainsi que les
intervalles de conﬁance, les uns comme les autres ´etant des approximations
obtenues par les ´echantillons de Gibbs de la Figure 10.3. Cela nous permet de
conclure que les eﬀets de l’intoxication, des m´edicaments et du placebo sont
signiﬁcatifs, bien qu’`a un degr´e moindre pour le placebo. On peut ´egalement
constater que l’eﬀet du m´edicament est signiﬁcativement diﬀ´erent de celui du
placebo.
∥
Tab. 10.1.
Probabilit´es a posteriori de ﬁabilit´e et intervalles de conﬁance `a 95%
pour les eﬀets de moyennes.
μδ
μD
μP
μD −μP
Probabilit´e 1.00
0.9998
0.94
0.985
Conﬁance
[-3.48,-2.17] [0.94,2.50] [-0.17,1.24] [0.14,2.20]
10.2.5 Extensions hi´erarchiques du mod`ele normal
Dans cette section, comme dans la Section 10.3, nous consid´erons le cas
particulier de la loi normale,
x ∼Np(θ, Σ)
parce qu’il donne des expressions partiellement exprimables analytiquement.
Comme dans Lindley et Smith (1972), Smith (1973) et Berger (1985b), nous

510
10 Extensions hi´erarchique et empirique
faisons appel `a une loi conjugu´ee de premier niveau θ ∼Np(μ, Σπ), pour une
d´ecomposition plus facile des estimateurs.
Lemme 10.17.
Dans le mod`ele normal conjugu´e, l’estimateur de Bayes
hi´erarchique est
δπ(x) = Eπ2(μ,Σπ|x)[δ(x|μ, Σπ)],
avec
δ(x|μ, Σπ) = x −ΣW(x −μ),
W = (Σ + Σπ)−1,
π2(μ, Σπ|x) ∝(det W)1/2 exp{−(x −μ)tW(x −μ)/2}π2(μ, Σπ).
La preuve est une cons´equence directe du Lemme 10.10 et du fait que la
loi marginale m1(x|μ, Σπ) est normale Np(μ, W −1).
Exemple 10.18. (Suite de l’Exemple 10.15) Le choix d’une loi a priori
constante sur β donne une expression analytique de δπ(x). Il existe alors une
fonction hk (Exercice 10.19) telle que
δπ(x) = x −hp−k−2(||x||2
∗)ΣC−1(x −Px),
avec
P = Y (Y tC−1Y )−1Y tC−1,
||x||2
∗= xC−1(Ip −P)x.
Remarquons que Px est la projection orthogonale de x sur le sous-espace
H = {μ = Y β, β ∈Rk} selon la m´etrique d´eﬁnie par C−1. L’estimateur δπ
est donc une somme pond´er´ee de x et de cette projection. Par cons´equent, δπ
prend en compte l’information a priori de fa¸con adaptative, en fonction de la
distance ||x||∗de x `a H.
∥
Exemple 10.19. On consid`ere le mod`ele hi´erarchique ´echangeable :
x|θ ∼Np(θ, σ2
1Ip),
θ|ξ ∼Np(ξ1, σ2
πIp),
ξ ∼N (ξ0, τ2),
avec 1 = (1, . . . , 1)t ∈Rp. Dans ce cas,
δ(x|ξ, σπ) = x −
σ2
1
σ2
1 + σ2π
(x −ξ1),

10.2 Analyse bay´esienne hi´erarchique
511
π2(ξ, σ2
π|x) ∝(σ2
1 + σ2
π)−p/2 exp{−∥x −ξ1∥2
2(σ2
1 + σ2π)}e−(ξ−ξ0)2/2τ 2π2(σ2
π)
∝
π2(σ2
π)
(σ2
1 + σ2π)p/2 exp

−p(¯x −ξ)2
2(σ2
1 + σ2π) −
s2
2(σ2
1 + σ2π) −(ξ −ξ0)2
2τ 2

avec s2 = 
i(xi −¯x)2. Alors, π2(ξ|σ2
π, x) suit une loi normale N (μ(x, σ2
π),
Vπ(σ2
π)), o`u
μ(x, σ2
π) = ¯x −
σ2
1 + σ2
π
σ2
1 + σ2π + pτ 2 (¯x −ξ0),
Vπ(σ2
π) =
τ 2(σ2
1 + σ2
π)
σ2
1 + σ2π + pτ 2 .
Alors
δπ(x) = Eπ2(σ2
π|x)

x −
σ2
1
σ2
1 + σ2π
(x −¯x1) −
σ2
1 + σ2
π
σ2
1 + σ2π + pτ 2 (¯x −ξ0)1

et
π2(σ2
π|x) ∝
τ exp −1
2

s2
σ2
1 + σ2π
+
p(¯x −ξ0)2
pτ 2 + σ2
1 + σ2π

(σ2
1 + σ2π)(p−1)/2(σ2
1 + σ2π + pτ 2)1/2
π2(σ2
π).
(10.5)
Berger (1985b, p. 184-185) donne une d´emonstration d´etaill´ee de ce r´esultat,
ainsi que l’expression correspondante de la variance a posteriori de θ.
Noter que l’estimateur bay´esien hi´erarchique a une forme particuli`ere
δπ(x) = x −Eπ2(σ2
π|x)

σ2
1
σ2
1 + σ2π

(x −¯x1)
−Eπ2(σ2
π|x)

σ2
1 + σ2
π
σ2
1 + σ2π + pτ 2

(¯x −ξ0)1.
(10.6)
Cela signiﬁe que les deux niveaux hi´erarchiques induisent deux types diﬀ´erents
de r´etr´ecissement pour l’estimateur de Bayes. L’hypoth`ese d’´echangeabilit´e
explique le second terme, (x −¯x1), qui r´eduit l’observation vers la moyenne
commune ¯x ; ce serait l’estimateur `a utiliser dans le cas d’une relation exacte
entre les param`etres du mod`ele. De mˆeme, le troisi`eme terme d´ecoule de l’hy-
poth`ese que la moyenne commune varie autour de ξ0.
Dans le cas o`u l’information concernant ξ0 n’est pas ﬁable, une loi non
informative peut ˆetre utilis´ee pour le deuxi`eme niveau, soit, π2(σ2
π) = 1 et
τ2 = +∞. Alors, pour p ≥4,
δπ(x) = x −Eπ2(σ2
π|x)

σ2
1
σ2
1 + σ2π

(x −¯x1)
= x −hp−2(∥x −¯x1∥2)(x −¯x1)
(10.7)
et

512
10 Extensions hi´erarchique et empirique
π2(σ2
π|x) ∝(σ2
1 + σ2
π)−(p−1)/2 exp

−
s2
2(σ2
1 + σ2π)

,
(10.8)
la fonction hk ´etant celle de l’Exemple 10.8 (voir aussi l’Exercice 10.19). On
peut v´eriﬁer que (10.7) et (10.8) viennent de (10.5) et (10.6) lorsque τ2 tend
vers +∞, et que (10.8) ne d´eﬁnit une loi propre que lorsque p ≥4. L’utilit´e
de l’hypoth`ese d’´echangeabilit´e en dimension 3 est subordonn´ee `a l’existence
d’une information suppl´ementaire, `a savoir une information a priori sur la
position de la moyenne commune ξ. Cette contrainte recoupe des r´esultats
fr´equentistes sur la minimaxit´e de (10.7), qui n’est vraie que pour p ≥4
(Brown, 1988).
Il faut noter que, si σ1 est ´egalement inconnu, avec une loi a priori
(´eventuellement non informative) π0, les ´egalit´es (10.6) et (10.7) sont tou-
jours vraies, `a condition que les esp´erances soient prises par rapport `a la loi
a posteriori π(σ2
1, σ2
π|x). De fa¸con analogue, si ξ est distribu´e selon une loi de
Student `a α degr´es de libert´e T (α, ξ0, τ2) plutˆot que selon une loi normale,
nous avons montr´e dans l’Exemple 10.3 que cette loi se d´ecompose en un
m´elange de lois gaussiennes N (ξ0, τ2/z) par une loi gamma G (α/2, α/2) sur
z. Par cons´equent, δπ peut ˆetre obtenu `a partir de (10.6) et (10.7) en int´egrant
par rapport `a z. Voir Angers (1987, 1992) pour une ´etude plus d´etaill´ee sur
la mod´elisation a priori par des lois de Student.
∥
Exemple 10.20. (Suite de l’Exemple 10.8)
Dans le cadre du mod`ele
de r´egression classique, une hypoth`ese d’´echangeabilit´e sur les param`etres βi
(1 ≤i ≤p) conduit `a des estimateurs similaires `a ceux que nous venons de
voir. Lorsque
βi ∼N (ξ, σ2
π)
et
π(ξ) = 1,
Lindley et Smith (1972), par une analyse similaire `a l’Exemple 10.19, ob-
tiennent l’estimateur
δπ(y) =

Ip + σ2
σ2π
(XtX)−1(Ip −p−1Jp)
−1
ˆβ,
avec ˆβ estimateur des moindres carr´es ˆβ = (XtX)−1Xty et Jp matrice (p×p)
ne contenant que des 1. L’analogie avec l’exemple ci-dessus est plus marquante
si on ´ecrit δπ sous la forme
δπ(y) = ¯β1 +

Ip + σ2
σ2π
(XtX)−1(Ip −p−1Jp)
−1
(ˆβ −¯β1)
(car (Ip −p−1Jp)¯β1 = 0) puisque l’estimateur de Bayes est r´etr´eci vers la
moyenne commune ¯β (au sens matriciel). Remarquons qu’il s’exprime aussi
δπ(y) =

XtX + σ2
σ2π
(Ip −p−1Jp)
−1
Xty.

10.2 Analyse bay´esienne hi´erarchique
513
On voit bien alors comment l’´echangeabilit´e att´enue les probl`emes num´eriques
et statistiques dus `a la quasi-colin´earit´e des colonnes de X. En eﬀet, la matrice
σ2
σ2π
(Ip −p−1Jp)
joue un rˆole de stabilisation pour cet estimateur. Si, dans l’a priori de se-
cond niveau, nous consid´erons plutˆot ξ = 0, l’estimateur de Bayes est alors
(Exercice 10.23)
δπ(y) =

Ip + σ2
σ2π
(XtX)−1
−1
ˆβ
=

XtX + σ2
σ2π
Ip
−1
Xty.
On appelle ces estimateurs estimateurs ridges. Ils ont ´et´e propos´es par Hoerl
et Kennard (1970) comme un rem`ede aux probl`emes de multicolin´earit´e dans
la matrice XtX, qui interviennent lorsque deux r´egresseurs (ou plus) sont
presque colin´eaires. Le facteur matriciel
#
Ip + k(XtX)−1$−1
stabilise l’estimateur des moindres carr´es lorsque certaines valeurs propres de
XtX sont proches de 0 (voir ´egalement Lindley et Smith, 1972, et Goldstein
et Smith, 1974). Ces estimateurs ont ´et´e ensuite g´en´eralis´es en consid´erant un
facteur matriciel de la forme
#
Ip + h(y)(XtX)−1$−1 ,
qui peut correspondre au cas σ2
π inconnu, avec une distribution a priori π2(σ2
π),
puisque l’estimateur de Bayes est alors
δπ(y) = Eπ2(σ2
π|y)

Ip + σ2
σ2π
(XtX)−1
−1
ˆβ.
Le point de vue classique donne l’impression que les imp´eratifs de r´eduction
de la multicolin´earit´e et de minimaxit´e sont contradictoires, puisque Casella
(1980, 1985a) montre que des conditions n´ecessaires de minimaxit´e pour les
estimateurs ridges ne sont pas compatibles avec l’inﬂuence stabilisatrice de
ces estimateurs. Robert (1998) observe le mˆeme ph´enom`ene pour d’autres
classes d’estimateurs `a r´etr´ecisseur et montre que cet antagonisme est dˆu
`a la monodimensionnalit´e du probl`eme de multicolin´earit´e, ce qui explique
pourquoi une am´elioration uniforme de ˆβ est impossible, du fait de l’eﬀet
Stein.
∥

514
10 Extensions hi´erarchique et empirique
10.3 Optimalit´e des estimateurs bay´esiens hi´erarchiques
D’une74 fa¸con g´en´erale, les estimateurs bay´esiens hi´erarchiques ´etant si-
milaires aux estimateurs de Bayes habituels, ils ne sont ni plus ni moins ad-
missibles que les estimateurs de Bayes d´ecrits dans les chapitres pr´ec´edents.
Par exemple, les conditions n´ecessaires et suﬃsantes du Chapitre 8 restent
vraies pour les estimateurs bay´esiens hi´erarchiques. De mˆeme, les propri´et´es
li´ees `a l’invariance dans le Chapitre 9 ne sont en aucun cas li´ees `a la structure,
hi´erarchique ou non, des lois `a priori.
Mais nous verrons ´egalement dans un cas particulier qu’il est eﬀectivement
possible de tirer parti de la sp´eciﬁcit´e des estimateurs bay´esiens hi´erarchiques
pour obtenir une condition g´en´erale de minimaxit´e, en utilisant les lois a priori
de second niveau. De tels r´esultats montrent ce que l’approche bay´esienne
hi´erarchique permet de gagner en robustesse, en incluant l’information a priori
la plus subjective aux niveaux les plus ´elev´es. On con¸coit alors cette d´emarche
comme un compromis entre une analyse bay´esienne directe et une r´eponse aux
exigences fr´equentistes.
Consid´erons de nouveau le mod`ele normal, x ∼Np(θ, Σ) avec Σ connu.
Comme dans la Section 10.2.5, la loi a priori de premier niveau sur θ est
conjugu´ee, θ ∼Np(μ, Σπ). La loi a priori π2 sur les hyperparam`etres μ, Σπ se
d´ecompose ainsi :
π2(μ, Σπ) = π1
2(Σπ|μ)π2
2(μ).
Dans ce cas,
m(x) =

Rp m(x|μ)π2
2(μ) dμ,
avec
m(x|μ) =

f(x|θ)π1(θ|μ, Σπ)π1
2(Σπ|μ) dθ dΣπ.
En outre, l’estimateur de Bayes
δπ(x) = x + Σ∇log m(x)
(10.9)
peut s’´ecrire
δπ(x) =

δ(x|μ)π2
2(μ|x) dμ,
o`u
δ(x|μ) = x + Σ∇log m(x|μ),
π2
2(μ|x) = m(x|μ)π2
2(μ)
m(x)
.
74Cette section peut ˆetre omise en premi`ere lecture puisqu’elle ne traite que de
la minimaxit´e d’une classe particuli`ere d’estimateurs bay´esiens hi´erarchiques dans
le cas gaussien. Son but est d’illustrer le gain en robustesse obtenu grˆace `a la
mod´elisation hi´erarchique.

10.3 Optimalit´e des estimateurs bay´esiens hi´erarchiques
515
Ces d´ecompositions conditionnelles seront utiles ci-dessous.
Soit Q matrice (p × p) sym´etrique d´eﬁnie positive associ´ee au coˆut qua-
dratique
LQ(θ, δ) = (θ −δ)tQ(θ −δ).
(10.10)
Un estimateur δ est minimax pour le coˆut (10.10) s’il satisfait
R(θ, δ) = Eθ[LQ(θ, δ(x))] ≤tr(ΣQ),
puisque tr(ΣQ) est le risque minimax de δ0(x) = x. La m´ethode de l’estimateur
sans biais du risque a ´et´e sugg´er´ee par Stein (1973, 1981) pour d´eterminer
des conditions suﬃsantes de minimaxit´e. (Voir Brown, 1988, et Rukhin, 1995,
pour des analyses d´etaill´ees de cette m´ethode.) Il s’agit d’obtenir un op´erateur
diﬀ´erentiel D, ind´ependant de θ, tel que
R(θ, δ) = Eθ[Dδ(x)],
pour tout param`etre θ et tout estimateur δ. Cette technique donne eﬀective-
ment une condition suﬃsante de minimaxit´e sous la forme Dδ(x) ≤tr(QΣ)
(Exercice 2.56). Dans le cas particulier (10.9), l’op´erateur diﬀ´erentiel est ob-
tenu grˆace au r´esultat suivant (Berger et Robert, 1990).
Lemme 10.21. Si m(x) v´eriﬁe les trois conditions
(1) Eθ∥∇log m(x)∥2 < +∞;
(2) Eθ

∂2m(x)
∂xi∂xj
'
m(x)
 < +∞;
et (1 ≤i ≤p)
(3)
lim
|xi|→+∞
∇log m(x)
 exp{−(1/2)(x −θ)tΣ−1(x −θ)} = 0,
l’estimateur sans biais du risque de δπ s’´ecrit
Dδπ(x) = tr(QΣ)
+
2
m(x)tr(Hm(x) ˜Q) −(∇log m(x))t ˜Q(∇log m(x)),
avec
˜Q = ΣQΣ,
Hm(x) =
∂2m(x)
∂xi∂xj

.
Cet estimateur sans biais du risque conduit alors `a une condition suﬃsante
de minimaxit´e :
2
m(x)tr(Hm(x) ˜Q) −(∇log m(x))t ˜Q(∇log m(x)) ≤0.
On note div l’op´erateur divergence, c’est-`a-dire
divf(x) =
n

i=1
∂fi
∂xi
(x),
pour toute fonction diﬀ´erentiable f de Rn dans Rn.

516
10 Extensions hi´erarchique et empirique
Corollaire 10.22. Si m satisfait les conditions du Lemme 10.21 et si
div

˜Q∇
7
m(x)

≤0,
(10.11)
δπ est minimax.
Preuve.
Il suﬃt de consid´erer le d´eveloppement de div( ˜Q∇
7
m(x)) pour
obtenir
div( ˜Q∇
7
m(x)) = 1
2div

˜Q ∇m(x)
7
m(x)
 
=
1
2
7
m(x)
div( ˜Q∇m(x)) −1
4

∇m(x)
m(x)
7
m(x)
 t
˜Q∇m(x)
=
7
m(x)
4

2
m(x)tr(Hm(x) ˜Q) −∇log m(x)t ˜Q∇log m(x)

et calculer le terme additionnel en Dδπ(x).
⊓⊔
Dans le cas particulier o`u Σ = Q = Ip, la condition du Corollaire 10.22
peut se simpliﬁer en une condition sur le laplacien de m(x)1/2 :
Δ
7
m(x) =
n

i=1
∂2
∂x2
i
(
7
m(x)) ≤0
(on dit alors que
7
m(x) est surharmonique). Comme la v´eriﬁcation pratique
de cette in´egalit´e est souvent diﬃcile, on utilise parfois une condition de mi-
nimaxit´e plus explicite, d´ecoulant du Corollaire 10.22 en conditionnant par
rapport `a μ.
Lemme 10.23. L’estimateur δπ est minimax si
div

˜Q∇m(x|μ)

≤0.
(10.12)
Preuve.
On a
div( ˜Q∇m(x)) =

div

˜Q∇m(x|μ)

π2
2(μ) dμ
et (10.12) entraˆıne (10.11).
⊓⊔
Par cons´equent, si ˜Q = Ip et si m(x|μ) est surharmonique, l’estimateur
bay´esien hi´erarchique correspondant est minimax. Ce r´esultat peut sembler
´evident dans sa formulation et sa d´emonstration mais il est en r´ealit´e assez
g´en´eral. Il donne en eﬀet une condition n´ecessaire et suﬃsante de minimaxit´e
qui ne d´epend pas de π2
2(μ) et autorise donc une mod´elisation quelconque

10.3 Optimalit´e des estimateurs bay´esiens hi´erarchiques
517
sur l’hyperparam`etre μ. D’un point de vue subjectif, il semble beaucoup plus
important d’avoir une libert´e totale pour la loi a priori de μ que pour le
choix compl´ementaire sur Σπ, puisqu’il est souvent plus facile d’obtenir de
l’information sur μ que sur Σπ. L’exemple suivant montre de plus que la
condition (10.12) est v´eriﬁ´ee par un ensemble important de lois π1
2.
Exemple 10.24. (Suite de l’Exemple 10.15) On consid`ere de nouveau le
cas o`u Σπ = ξC −Σ et Q = Σ−1CΣ−1 (alors ˜Q = C). Il vient du Lemme
10.12 que
m(x|μ) ∝
 ∞
0
ξ−p/2 exp

−(x −μ)tC−1(x −μ)
2ξ

π1
2(ξ|μ) dξ.
Donc
div

˜Q∇m(x|μ)

∝
 ∞
0

−p
ξ + (x −μ)tC−1(x −μ)
ξ2

×e−(x−μ)tC−1(x−μ)/2ξξ−p/2π1
2(ξ|μ) dξ ,
et (10.12) est ´equivalent `a
ψ(a) =
 ∞
0
(2a −pξ)ξ−(p+4)/2e−a/ξπ1
2(ξ|μ) dξ ≤0,
∀a ≥0.
Si π1
2 est presque partout diﬀ´erentiable, on obtient, par une int´egration par
parties,
ψ(a) = −2e−a/ξ0ξ−p/2
0
π′
2(ξ0|μ) −
 +∞
ξ0
ξ−p/2e−a/ξπ1
2(ξ|μ) dξ,
avec ξ0 = inf(supp(π1
2)) et π′
2 d´eriv´ee de π1
2. Cette expression implique que :
Proposition 10.25. Si π1
2(ξ|μ) est croissante quel que soit μ ∈Rp, δπ est
minimax pour toute loi a priori π2
2.
Par cons´equent, si π1
2(ξ|μ) = 1 pour ξ0 ≤ξ avec λmax(C−1Σ) ≤ξ0,
l’estimateur de Bayes correspondant est minimax.
∥
Cet exemple peut ˆetre ´etendu au cas o`u θ ∼Np(μ, σ2
πΣ) et o`u π1
2(σ2
π|μ) est
strictement croissante (C = Σ et ξ = σ2
π−1). Cette classe n’inclut ´evidemment
pas tous les estimateurs hi´erarchiques et tous les estimateurs minimax, mais
elle contient tout de mˆeme tous les estimateurs minimax propos´es par Straw-
derman (1971) et Berger (1975a, 1980b), certains ´etant de plus admissibles
(voir ´egalement Kubokawa, 1991, et l’Exercice 10.36).
Remarquons que les lois a priori sugg´er´ees par la Proposition 10.25 sont
contre-intuitives : il semble en eﬀet diﬃcile, des points de vue subjectif et

518
10 Extensions hi´erarchique et empirique
non informatif, de trouver des avantages `a une loi croissante en terme de
variance. Les lois a priori sont au contraire souvent d´ecroissantes pour de
grandes valeurs de σ2
π. C’est par exemple le cas de la loi non informative de
Jeﬀreys π(σ2
π) = 1/σ2
π. Ce r´esultat est donc une indication implicite de l’aspect
artiﬁciel de la notion de minimaxit´e : donner le mˆeme poids a posteriori `a
toutes les valeurs possibles du param`etre revient `a favoriser a priori les plus
invraisemblables (ou les moins favorables).
L’exemple ci-dessous illustre les points forts de l’approche bay´esienne
hi´erarchique d’un point de vue minimax, mˆeme lorsque la loi de premier ni-
veau est plus rudimentaire. Il pr´esente ´egalement une propri´et´e de robustesse
de minimaxit´e, au sens o`u la minimaxit´e ne d´epend pas tant de la normalit´e de
la loi a priori que de sa sym´etrie sph´erique. Ce r´esultat est donc un ´equivalent
bay´esien aux r´esultats fr´equentistes de Cellier et al. (1989).
Exemple 10.26. Soit x ∼Np(θ, Ip). La moyenne θ est estim´ee sous coˆut
quadratique. Au lieu d’utiliser une loi de premier niveau conjugu´ee, on choisit
la loi uniforme sur la sph`ere de rayon c,
π1(θ|c) ∝I{||θ||2=c},
formulant ainsi seulement une hypoth`ese de sym´etrie sph´erique pour la loi
a priori globale. La loi a priori de second niveau π2(c) est une loi gamma
G (α, β). L’estimateur de Bayes est alors (voir Robert et al., 1990)
δπ(x) = 2α
p
1
1 + 2β
1F1(α + 1; (p + 2)/2; ||x||2/(2 + 4β))
1F1(α; p/2; ||x||2/(2 + 4β))
x,
o`u on note 1F1 la fonction conﬂuente hyperg´eom´etrique. Avec α < 1 et β = 0,
on obtient
δπ(x) = 2α
p
1F1(α + 1; (p + 2)/2; ||x||2/2)
1F1(α; p/2; ||x||2/2)
x,
qui est un estimateur minimax et admissible (voir Alam, 1973).
∥
10.4 L’alternative bay´esienne empirique
La m´ethodologie que nous ´etudions `a pr´esent jusqu’`a la ﬁn de ce chapitre
ne d´ecoule pas des principes bay´esiens75, puisqu’elle consiste `a approcher la loi
a priori par des m´ethodes fr´equentistes lorsque l’information a priori est trop
limit´ee. Nous l’incluons tout de mˆeme dans ce livre pour plusieurs raisons :
75Le nom de bay´esien empirique est doublement trompeur puisque, d’une part, la
m´ethode n’est pas bay´esienne et, d’autre part, les v´eritables m´ethodes bay´esiennes
sont tout autant empiriques puisque li´ees aux donn´ees ! `A moins, bien sˆur, de prendre
empirique dans son sens p´ejoratif...

10.4 L’alternative bay´esienne empirique
519
(i) elle peut ˆetre consid´er´ee comme une m´ethode duale de l’analyse bay´e-
sienne hi´erarchique pr´esent´ee ci-dessus ;
(ii) elle est asymptotiquement ´equivalente `a l’approche bay´esienne;
(iii) elle est souvent ´etiquet´ee “bay´esienne” par les fr´equentistes et les
praticiens ; et
(iv) elle constitue dans certains cas une approximation acceptable lorsque
la mod´elisation bay´esienne r´eelle est trop compliqu´ee ou trop ch`ere.
Nous verrons que l’analyse bay´esienne empirique se situe entre les approches
classique et bay´esienne et nous montrerons que l’alternative hi´erarchique est
souvent pr´ef´erable. Cette section n’est qu’une courte introduction `a l’approche
bay´esienne empirique. Les lecteurs int´eress´es pourront se reporter `a Mor-
ris (1983b), Berger (1985b), Maritz et Lwin (1989) ou bien Carlin et Louis
(2000a,b) pour des ´etudes plus compl`etes sur le sujet.
10.4.1 Le principe bay´esien empirique non param´etrique
Robbins (1951, 1955, 1964, 1983) d´ecrit le point de vue bay´esien empirique
de la fa¸con suivante. Soient (n+1) observations ind´ependantes x1, . . . , xn+1 de
densit´es f(xi|θi) ; le probl`eme porte sur l’inf´erence sur θn+1, avec l’hypoth`ese
suppl´ementaire que les θi ont tous ´et´e tir´es selon le mˆeme a priori inconnu g.
D’un point de vue bay´esien, cela revient `a dire que la loi d’´echantillonnage est
connue, mais que la loi a priori ne l’est pas. La loi marginale,
fg(x) =

f(x|θ)g(θ) dθ,
(10.13)
peut alors ˆetre utilis´ee pour retrouver la distribution g `a partir des observa-
tions, puisque x1, . . . , xn peut ˆetre vu comme un ´echantillon i.i.d. de loi fg. En
r´esolvant ce probl`eme inverse, on obtient ainsi une approximation ˆgn qu’on
peut substituer `a la vraie loi a priori pour obtenir l’expression suivante de la
loi a posteriori
˜π(θn+1|xn+1) ∝f(xn+1|θn+1)ˆgn(θn+1).
(10.14)
Naturellement, cette technique n’est pas bay´esienne, bien qu’elle repose sur
la formule de Bayes (10.14) et rejoigne parfois la mod´elisation classique, puis-
qu’elle utilise les donn´ees deux fois. Confront´e `a la m´econnaissance de g,
le r´eﬂexe bay´esien serait d’indexer cette loi par un hyperparam`etre λ et de
mod´eliser cette ignorance par une loi a priori de second niveau π2(λ)76. Deely
et Lindley (1981) comparent les deux approches dans le cas d’une loi de Pois-
son.
Le cadre initial de Robbins (1955) est principalement non param´etrique et
fait usage des observations x1, . . . , xn+1 pour estimer fg. (Dans le cas g´en´eral,
76L’indexation par λ n’est formellement pas restrictive, comme le montre l’Exer-
cice 1.2.

520
10 Extensions hi´erarchique et empirique
la densit´e marginale fg peut ˆetre estim´ee par une m´ethode `a noyau; voir par
exemple Devroye et Gy¨orﬁ, 1985.)
Exemple 10.27. On consid`ere les xi distribu´es selon une loi P(θi) (i =
1, . . . , n). Si pk(x1, . . . , xn) est le nombre d’observations ´egales `a k, k ∈N,
pk(x1, . . . , xn) donne une estimation de la loi marginale,
fg(k) =
 +∞
0
e−θ θk
k! g(θ) dθ.
Si xn+1 ∼P(θn+1) et si θn+1 est estim´e sous coˆut quadratique, l’estimateur
de Bayes est
δg(xn+1) = Eg[θ|xn+1] =
 +∞
0
e−θθxn+1+1g(θ) dθ
 +∞
0
e−θθxn+1g(θ) dθ
= fg(xn+1 + 1)
fg(xn+1)
(xn+1 + 1).
Donc l’approximation bay´esienne empirique de δg est
δEB(xn+1) = pxn+1+1(x1, . . . , xn)
pxn+1(x1, . . . , xn) + 1(xn+1 + 1),
(10.15)
o`u on a remplac´e fg par son approximation.
∥
Cette m´ethode souﬀre de plusieurs inconv´enients :
(a) L’utilisation d’estimations non param´etriques, par exemple pour la densit´e
a priori, comme pr´eliminaire `a une proc´edure d’estimation param´etrique
semble sous-optimale, car il est toujours plus diﬃcile d’´evaluer les erreurs
commises dans une ´etape non param´etrique. Ainsi, dans l’exemple ci-
dessus, si le num´erateur de (10.15) est nul, l’estimateur est nul.
(b) Plus g´en´eralement, les estimations non param´etriques de la densit´e de
m´elange g dans (10.13) par des techniques de maximum de vraisemblance
sont souvent basiques, puisqu’elles correspondent `a des lois `a support ﬁni.
(Voir Bohning, 1999, ou Carlin et Louis, 2000a77). De telles lois a priori
sont rarement acceptables du point de vue bay´esien.
(c) Il est assez rare d’avoir des relations fonctionnelles entre la moyenne (ou
toute autre fonction d’int´erˆet) et la loi marginale, comme dans l’Exemple
10.27. Lorsqu’une telle relation n’existe pas, le calcul de l’estimateur de
g est g´en´eralement trop compliqu´e pour garantir que les estimateurs en
r´esultant soient de bonnes approximations des vrais estimateurs de Bayes.
77Cela est ´egalement vrai pour des approches a priori utilisant des noyaux ou des
processus de Dirichlet.

10.4 L’alternative bay´esienne empirique
521
(d) L’approximation n’est eﬀectivement justiﬁ´ee que pour des ´echantillons de
taille importante, c’est-`a-dire lorsque l’estimateur de la loi marginale ˆf n
g
est acceptable. Dans le cas contraire, comme le montre l’Exemple 10.27,
ˆf n
g subit des variations trop importantes et doit ˆetre liss´e pour ˆetre d’une
quelconque utilit´e (voir Maritz et Lwin, 1989).
(e) L’hypoth`ese selon laquelle on dispose de nombreux probl`emes identiques
et ind´ependants concernant la mˆeme loi a priori est forte et peut ne pas
ˆetre v´eriﬁ´ee en pratique. Ainsi, un ´echantillon unique, mˆeme tr`es grand,
ne permet pas d’estimer fg, car il ne correspond qu’`a une seule observa-
tion de θ. Cette critique reste valable avec l’approche param´etrique (voir,
notamment, la Proposition 10.31).
Pour toutes ces raisons, nous ne pousserons pas plus loin l’´etude de l’ana-
lyse bay´esienne empirique non param´etrique; nous allons `a pr´esent nous res-
treindre au principe bay´esien empirique param´etrique de Morris (1983b).
10.4.2 Principe bay´esien empirique param´etrique
Un int´erˆet pratique des techniques bay´esiennes empiriques est de d´eter-
miner des approximations dans des contextes non informatifs. Nous avons
montr´e dans les chapitres pr´ec´edents que l’approche bay´esienne ´etait un outil
eﬃcace pour obtenir des proc´edures optimales d’un point de vue fr´equentiste,
sous la forme d’un cadre uniﬁ´e d’inf´erence statistique. L’analyse bay´esienne
empirique peut alors ˆetre vue comme une approximation pratique de cet outil.
Pour les familles exponentielles, lorsque la loi a priori n’est pas disponible,
le plus simple est de consid´erer l’a priori conjugu´e associ´e `a f(x|θ), π(θ|λ).
Tandis que l’approche hi´erarchique introduit une loi suppl´ementaire sur les
hyperparam`etres λ, l’analyse bay´esienne empirique propose d’estimer ces hy-
perparam`etres `a partir de la loi marginale
m(x|λ) =

Θ
f(x|θ)π(θ|λ) dθ
pour obtenir ˆλ(x) et d’utiliser π(θ|ˆλ(x), x) en tant que pseudo-a posteriori.
Cette m´ethode est donc une version param´etrique de l’id´ee originale de Rob-
bins (1955).
Un inconv´enient de l’analyse bay´esienne empirique est qu’elle repose sur
des m´ethodes fr´equentistes pour l’estimation des hyperparam`etres de m(x|λ),
alors qu’on pourrait tout aussi bien employer des techniques bay´esiennes,
comme le montre la Note 10.7.2. Une cons´equence de ce choix est qu’un
grand nombre de m´ethodes est utilisable : par exemple, l’estimateur de λ
peut ˆetre choisi par la m´ethode des moments ou par la m´ethode du maximum
de vraisemblance. Il en r´esulte un aspect arbitraire de l’analyse bay´esienne
empirique, qui est le d´efaut principal de la d´emarche, puisqu’il exclut l’emploi
de la Th´eorie de la D´ecision. L’analyse bay´esienne empirique est alors souvent

522
10 Extensions hi´erarchique et empirique
employ´ee comme un outil pour justiﬁer a posteriori des estimateurs d´ej`a exis-
tants, comme nous le verrons `a la Section 10.5. L’approche la plus r´epandue
est d’utiliser des estimateurs du maximum de vraisemblance pour des raisons
`a la fois pratiques et th´eoriques, en particulier `a cause de la ressemblance
entre l’estimation par maximum de vraisemblance et le paradigme bay´esien.
Une justiﬁcation suppl´ementaire de ce choix est donn´ee ci-dessous dans le cas
particulier de l’estimation d’un param`etre naturel d’une famille exponentielle
sous coˆut quadratique.
Lemme 10.28. On consid`ere
x ∼f(x|θ) = eθ·x−ψ(θ)h(x),
x ∈Rk.
Si θ est distribu´e selon π(θ|λ), λ ∈Rp, et ˆλ(x) est la solution des ´equations
de vraisemblance associ´ees `a m(x|λ), l’estimateur de Bayes empirique de θ
v´eriﬁe
δEB(x) = (∇log m(x|λ))

λ=ˆλ(x) −∇log h(x)
= ∇[log m(x|ˆλ(x))] −∇log h(x).
Preuve.
On a
∇log m(x|ˆλ(x)) = (∇log m(x|λ))

λ=ˆλ(x) + ∇xˆλ(x)∇λm(x|λ)

λ=ˆλ(x),
o`u ∇λm(x|λ) est le vecteur de composantes
∂m(x|λ)
∂λi
(1 ≤i ≤p) ,
et ∇xˆλ(x) est la matrice (k × p) de composantes
∂ˆλi(x)
∂xj
(1 ≤i ≤p, 1 ≤j ≤k) .
Par d´eﬁnition de ˆλ(x), le second terme est nul.
⊓⊔
Par cons´equent, un calcul bay´esien habituel `a partir de la loi a posteriori
approch´ee π(θ|ˆλ(x)) conduit au mˆeme r´esultat que l’approche bay´esienne em-
pirique, o`u on remplace λ par ˆλ(x). Mais cette justiﬁcation n’est manifeste-
ment pas d’une grande g´en´eralit´e puisqu’elle n’est vraie que pour la moyenne
a posteriori du param`etre naturel d’une famille exponentielle.
Exemple 10.29. (Suite de l’Exemple 10.27) On suppose que π(θ|λ) est
une loi exponentielle E xp(λ). Alors
m(xi|λ) =
 +∞
0
e−θ θxi
xi! λe−θλdθ
=
λ
(λ + 1)xi+1 =

1
λ + 1
xi
λ
λ + 1,

10.4 L’alternative bay´esienne empirique
523
et xi|λ ∼G eo(λ/λ + 1). L’estimateur du maximum de vraisemblance de λ est
ˆλ(x) = 1/¯x et l’estimateur de Bayes empirique de θn+1 est
δEB(xn+1) = xn+1 + 1
ˆλ + 1
=
¯x
¯x + 1(xn+1 + 1),
la moyenne ¯x ´etant ´etablie sur les n premi`eres observations.
∥
Exemple 10.30. Soient x1, . . . , xn, n observations ind´ependantes de B(m,
pi). Casella (1985b) (voir aussi Morisson, 1979) utilise ce mod`ele pour re-
pr´esenter la d´ecision d’acheter une nouvelle voiture dans l’ann´ee `a venir. On
suppose que les param`etres pi (1 ≤i ≤n) sont distribu´es selon la mˆeme loi a
priori conjugu´ee
pi ∼B(α, β).
L’estimateur de Bayes correspondant de pi est
δπ
i (xi) =
α + β
α + β + 1
α
α + β +

1 −
α + β
α + β + 1
 xi
m
et la loi marginale de xi est appel´ee bˆeta-binomiale,
P(xi = k|α, β) = B(k + α, m −k + β)
B(α, β)
.
comme dans l’Exemple 10.14. Kendall et Stuart (1979) montrent que, pour
cette loi marginale,
E(xi|m) =
α
α + β ,
var(xi|m) = 1
m
αβ
(α + β)2
α + β + m
α + β + 1 .
Lorsque α et β sont estim´es par la m´ethode des moments, l’estimateur
bay´esien empirique de pi est
γEB
i
(x1, . . . , xn) = ˆα + (xi/m)
ˆα + ˆβ + 1
.
(L’Exercice 10.29 porte sur les donn´ees utilis´ees par Morisson, 1979.)
∥
La Section 10.5 pr´esente les parall`eles remarquables existant entre les ma-
nifestations de l’eﬀet de Stein et l’approche bay´esienne empirique et d´eduit
grˆace `a cette derni`ere de bons estimateurs pour l’estimation ponctuelle, ainsi
que pour les tests et r´egions de conﬁance. Le r´esultat qui suit explique, au
contraire, pourquoi les tests de Bayes empiriques sont d’une utilit´e limit´ee
pour un unique ´echantillon.

524
10 Extensions hi´erarchique et empirique
Proposition 10.31. On consid`ere le test de H0 : θ = θ0 contre H1 : θ = θ1
`a partir d’un ´echantillon x1, . . . , xn, i.i.d. f(x|θ). Une approche bay´esienne
empirique donne la proc´edure de test de rapport de vraisemblances
ϕ(x) =

1
si /n
i=1 f(xi|θ0) > /n
i=1 f(xi|θ1) ,
0
sinon,
(10.16)
quel que soit le niveau de conﬁance.
Preuve.
Dans ce cadre, l’ensemble des param`etres inconnus est r´eduit `a π0,
la probabilit´e a priori de H0. La loi marginale de x est alors
m(x|π0) = π0
n

i=1
f(xi|θ0) + (1 −π0)
n

i=1
f(xi|θ1)
et correspond `a l’estimateur du maximum de vraisemblance de π0 suivant :
ˆπ0(x1, . . . , xn) =

1
si /n
i=1 f(xi|θ0) > /n
i=1 f(xi|θ1) ,
0
sinon.
La r´eponse bay´esienne ´etant
ϕπ(x1, . . . , xn) =

1
si P(θ = θ0|x1, . . . , xn, π0) > α ,
0
sinon,
la probabilit´e a posteriori de H0 est
P(θ = θ0|x1, . . . , xn, ˆπ0) =
ˆπ0
/n
i=1 f(xi|θ0)
ˆπ0
/n
i=1 f(xi|θ0) + (1 −ˆπ0) /n
i=1 f(xi|θ1)
d’o`u (10.16).
⊓⊔
Lorsque l’on consid`ere plusieurs probl`emes de test simultan´ement, ce com-
portement extrˆeme des tests de Bayes empiriques disparaˆıt (Maritz et Lwin,
1989). Cependant, il est plutˆot rare d’avoir `a tester simultan´ement plusieurs
hypoth`eses sur des param`etres de la mˆeme loi et l’int´erˆet pratique de l’ap-
proche bay´esienne empirique pour les tests s’en trouve d’autant limit´e. On
consid`ere l’estimation des r´egions de conﬁance dans la Section 10.5, en rela-
tion avec l’eﬀet Stein. Pour des ´etudes alternatives, voir Laird et Louis (1987)
ou Carlin et Gelfand (1991).
Pr´esentons en guise de conclusion une l´eg`ere modiﬁcation de l’approche
bay´esienne empirique consistant `a utiliser des m´elanges de lois conjugu´ees,
puisqu’ils constituent ´egalement une famille conjugu´ee (voir le Lemme 3.23).
Si xi ∼f(xi|θi) et
θi ∼
n

j=1
pjπ(θi|λj),

10.5 Justiﬁcations bay´esiennes empiriques de l’eﬀet Stein
525
la loi marginale de xi est
xi|p, λ ∼
n

j=1
pj

Θ
f(xi|θ)π(θ|λj) dθ.
(Voir la Section 6.4 et la Note 6.6.6 pour de plus amples d´etails sur l’ana-
lyse bay´esienne de ce probl`eme.) Maritz et Lwin (1989) ´etudient plus parti-
culi`erement l’application `a l’analyse bay´esienne empirique. Un inconv´enient
de cette extension est bien sˆur qu’elle n´ecessite un plus grand nombre d’hyper-
param`etres et donc un plus grand nombre d’´echantillons ind´ependants, tout
en pr´esentant toujours certains des d´efauts ´enum´er´es ci-dessus.
Insistons de nouveau sur le fait que la l´egitimit´e des m´ethodes bay´esiennes
empiriques n’est qu’asymptotique (Deely et Lindley, 1981). Leur popula-
rit´e est li´ee aux bonnes propri´et´es fr´equentistes de certains estimateurs
ainsi obtenus et aux simpliﬁcations importantes qu’elles apportent dans la
r´esolution de probl`emes complexes, en comparaison de l’analyse bay´esienne
hi´erarchique. (Consulter, par exemple, Carter et Rolph, 1974, ou Hui et Ber-
ger, 1983.) Pour des probl`emes portant sur des ´echantillons de tailles ﬁnies,
les m´ethodes bay´esiennes empiriques ne sont que des approximations des
m´ethodes bay´esiennes exactes et ne peuvent donc se pr´evaloir de la mˆeme
coh´erence. En particulier, il est impossible de mener une inf´erence bay´esienne
compl`ete en utilisant π(θ|x, λ(x)), car ce n’est pas une loi a posteriori. Enﬁn,
l’accroissement permanent de la puissance et des m´ethodes de calcul dispo-
nibles (Chapitre 6) r´eduit le besoin en approximations empiriques d’analyses
hi´erarchiques plus complexes. (Voir Berger, 1985b, Berger et Berliner, 1986,
et Berger et Robert, 1990.)
10.5 Justiﬁcations bay´esiennes empiriques de l’eﬀet Stein
L’analyse bay´esienne empirique de l’eﬀet Stein, d´ecrit en Note 2.8.2, four-
nit un cadre d’uniﬁcation des diﬀ´erentes apparitions de ce paradoxe, selon
lequel l’estimation jointe de param`etres ind´ependants peut ˆetre am´eliorable
globalement en termes de qualit´e de l’estimation, sans qu’aucune composante
ne puisse ˆetre am´elior´ee uniform´ement. En outre, cette analyse explique la
forme originelle des estimateurs de James-Stein et montre qu’ils correspondent
`a l’information a priori vague que θ est proche de 0.
10.5.1 Estimation ponctuelle
Nous commen¸cons par un exemple qui illustre naturellement le fondement
bay´esien empirique de l’eﬀet Stein.

526
10 Extensions hi´erarchique et empirique
Exemple 10.32. Soient x ∼Np(θ, Ip) et θi ∼N (0, τ2). La loi marginale de
x est alors
x|τ2 ∼Np(0, (1 + τ 2)Ip)
et conduit `a l’estimateur du maximum de vraisemblance de τ2 suivant,
ˆτ2 =

(||x||2/p) −1
si ||x||2 > p ,
0
sinon.
L’estimateur bay´esien empirique correspondant de θi sous coˆut quadratique
est obtenu en rempla¸cant τ2 par ˆτ 2 dans l’estimateur de Bayes,
δEB(x) =
ˆτ 2x
1 + ˆτ2
=

1 −
p
||x||2
+
x.
(10.17)
L’estimateur (10.17) est en fait un estimateur tronqu´e de James-Stein. Par
cons´equent, ces estimateurs peuvent ˆetre interpr´et´es en tant qu’estimateurs
bay´esiens empiriques li´es `a l’information que les esp´erances des observations
sont proches de 0. L’estimateur originel de James-Stein peut ´egalement s’´ecrire
comme un estimateur bay´esien empirique, avec une m´ethode d’estimation
fr´equentiste alternative. En r´ealit´e, ´etant donn´e la loi marginale de x, le
meilleur estimateur sans biais de 1/(1 +τ2) est (p−2)/||x||2, ce qui conduit `a
δEB(x) =

1 −p −2
||x||2

x.
(10.18)
∥
Cet exemple illustre aussi les lacunes dans les justiﬁcations de l’approche
bay´esienne empirique, qui ne sait pas comparer les diﬀ´erentes m´ethodes d’esti-
mation des hyperparam`etres. Ce probl`eme de d´efaut de classement est plus lar-
gement caract´eristique de l’approche fr´equentiste dans son ensemble. La com-
paraison entre les estimateurs (10.17) et (10.18) doit ˆetre fond´ee sur d’autres
consid´erations.
Exemple 10.33. Soient deux vecteurs ind´ependants, x ∼Np(θ, σ2Ip) et
y ∼Nq(0, σ2Iq), comme dans la r´egression lin´eaire. Le param`etre d’int´erˆet
est le facteur de variance σ2, ´evalu´e sous coˆut entropique,
L(σ2, d) = d
σ2 −log(d/σ2) −1.
Outre les consid´erations intrins`eques (Section 2.5.4), une raison pour laquelle
on peut pr´ef´erer ce coˆut au coˆut quadratique est qu’il induit l’estimateur

10.5 Justiﬁcations bay´esiennes empiriques de l’eﬀet Stein
527
du maximum de vraisemblance ||y||2/p + q en tant que meilleur estimateur
´equivariant78 de σ2. Sous ce coˆut, l’estimateur de Bayes de σ2 est
δπ(x) =
	
Eπ[σ−2|x]

−1 .
(10.19)
Pour la loi conjugu´ee gamma-normale sur (θ, σ2),
θ|σ2 ∼Np(0, τσ2Ip),
σ−2 ∼G (ν/2, β/2) ,
l’estimateur (10.19) est alors
δπ(x, y) =
1
p + q + ν
 ||x||2
1 + τ + ||y||2 + β

et la maximisation de la vraisemblance marginale (en (τ, ν, β)) conduit `a l’es-
timateur bay´esien empirique suivant (voir Kubokawa et al., 1993b) :
δEB(x, y) = min
||y||2
q
, ||x||2 + ||y||2
p + q

.
(10.20)
Mettons en ´evidence l’aspect intuitif de cet estimateur : il n’utilise l’infor-
mation additionnelle dans x concernant σ2 que si ||x||2 n’est pas trop grand,
c’est-`a-dire si θ est proche de 0, puisque
||x||2 + ||y||2
p + q
est le meilleur estimateur ´equivariant d’´echelle de σ2 lorsque θ = 0.
L’int´erˆet r´eel de ce r´esultat est montr´e par Brewster et Zidek (1974) :
l’estimateur (10.20) am´eliore uniform´ement le meilleur estimateur ´equivariant
δ⋆(x, y) = ||y||2/q sous coˆut entropique. (Voir Maatta et Casella, 1990, pour
une ´etude d´etaill´ee des diﬀ´erents aspects de l’estimation de variance.)
∥
Morris (1983a) consid`ere l’eﬀet Stein en plus grande g´en´eralit´e que dans
le cadre de l’Exemple 10.32. Il ´etudie en fait le mod`ele bay´esien de r´egression
x|θ ∼Np(θ, Λ),
θ|β, σ2
π ∼Np(Zβ, σ2
πIp),
avec Λ = diag(λ1, . . . , λp) et Z matrice (p × q) de rang plein. La loi marginale
de x est alors
xi|β, σ2
π ∼N (z′
iβ, σ2
π + λi)
et la loi a posteriori de θ est
78Cet argument ne saurait justiﬁer l’utilisation du coˆut entropique, puisqu’il
l´egitime a posteriori un estimateur donn´e, au lieu d’utiliser des consid´erations utili-
taires conduisant `a une d´etermination pratique de l’estimateur.

528
10 Extensions hi´erarchique et empirique
θi|xi, β, σ2
π ∼N ((1 −bi)xi + biz′
iβ, λi(1 −bi)) ,
avec bi = λi/(λi + σ2
π). Si toutes les variances λi sont identiques et ´egales `a
σ2, les meilleurs estimateurs ´equivariants de β et b sont donn´es par
ˆβ = (ZtZ)−1Ztx
et
ˆb = (p −q −2)σ2
s2
,
avec s2 = p
i=1(xi −z′
i ˆβ)2. On d´eduit de ces estimateurs des hyperparam`etres
l’estimateur bay´esien empirique de θ suivant :
δEB(x) = Z ˆβ +

1 −(p −q −2)σ2
||x −Z ˆβ||2
 
(x −Z ˆβ),
(10.21)
qui est de la forme des estimateurs de Stein g´en´eraux.
Dans le cas particulier o`u on suppose que les moyennes sont identiques
(hypoth`ese d’´echangeabilit´e), la matrice Z est r´eduite au vecteur 1 et β est
un nombre r´eel; l’estimateur bay´esien empirique est alors
δEB(x) = ¯x1 +

1 −(p −3)σ2
||x −¯x1||2

(x −¯x1).
Il s’agit donc de l’estimateur de Stein qui r´etr´ecit vers la moyenne commune,
pr´esent´e dans Efron et Morris (1975). Voir Morris (1983b) pour le cas o`u les
variances λi ne sont pas identiques.
10.5.2 ´Evaluation de la variance
Comme nous l’avons d´ecrit ci-dessus, l’estimation des hyperparam`etres β
et σ2
π modiﬁe consid´erablement le comportement des proc´edures r´esultantes.
Bien que nous venions de voir que les estimateurs ponctuels obtenus sont
en g´en´eral eﬃcaces, cette approche sous-estime la variance a posteriori de
π(θ|x, β, b) en utilisant la variance empirique var(θi|x, ˆβ,ˆb). Il est donc trom-
peur d’utiliser l’analyse bay´esienne empirique pour ´etudier les performances
de δEB en estimant son coˆut quadratique (θi −δEB
π )2 par var(θi|x, ˆβ,ˆb), car
on obtient une sous-estimation de l’erreur r´esultant de l’utilisation de δEB.
Morris (1982) consid`ere la variabilit´e suppl´ementaire issue de l’estimation
des hyperparam`etres en modiﬁant les estimateurs. Dans le cas ´echangeable,
les proc´edures obtenues sont
δEB(x) = x −˜B(x −¯x1),
V EB
i
(x) =

σ2 −p −1
p
˜B

+
2
p −3
ˆb(xi −¯x)2,
avec

10.5 Justiﬁcations bay´esiennes empiriques de l’eﬀet Stein
529
ˆb = p −3
p −1
σ2
σ2 + ˆσ2π
,
ˆσ2
π = max

0, ||x −¯x1||2
p −1
−σ2
π

et
˜B = p −3
p −1 min

1, σ2(p −1)
||x −¯x1||2

.
Cette derni`ere quantit´e estime le rapport σ2/(σ2 + σ2
π). Cependant, cette
modiﬁcation, bien que plus satisfaisante, souﬀre toujours du d´efaut g´en´eral
de l’inf´erence bay´esienne empirique, `a savoir que les proc´edures sont souvent
justiﬁ´ees par des raisons sur mesure (ou empiriques !) qui ne peuvent ˆetre
g´en´eralis´ees en un principe (mˆeme si Kass et Steﬀey, 1989, pr´esentent une
g´en´eralisation partielle).
Remarquons l’analogie entre la variance empirique modiﬁ´ee V EB
i
et la
variance hi´erarchique pour le mˆeme mod`ele,
V HB
i
(x) = σ2

1 −p −1
p
Eπ

σ2
σ2 + σ2π
x

+ var

σ2
σ2 + σ2π
x

(xi −¯x)2
(Berger, 1985b). Cette ressemblance n’est pas une co¨ıncidence, puisque cette
modiﬁcation am´eliore l’approche bay´esienne empirique originelle en emprun-
tant un peu plus `a l’analyse bay´esienne r´eelle. Ghosh et Saleh (1989) et
Blattberg et George (1991) pr´esentent des exemples d’utilisation de l’analyse
bay´esienne empirique en ´Econom´etrie et ´etablissent un lien avec les estima-
teurs de Stein dans les mod`eles de r´egression.
10.5.3 R´egions de conﬁance
Il existe une autre caract´eristique de l’eﬀet Stein interpr´etable dans un
contexte bay´esien empirique. Dans le cas des r´egions de conﬁance recentr´ees
(Section 5.5), Hwang et Casella (1982) montrent que, `a volume ´egal, certaines
r´egions ont une probabilit´e de couverture plus grande que la moyenne. Ces
ensembles correspondent alors `a des r´egions HPD empiriques.
Exemple 10.34. Hwang et Casella (1982) comparent la r´egion de conﬁance
habituelle
C0(x) = {θ; ∥θ −x∥2 ≤cα},
o`u x ∼Np(θ, Ip) `a
Ca(x) = {θ; ∥θ −δa(x)∥2 ≤cα},
avec δa(x) = [1 −(a/||x||2)]+x. Ils montrent que, pour a suﬃsamment petit
et p ≥4, l’ensemble Ca v´eriﬁe, quel que soit θ,
Pθ(θ ∈Ca(x)) > Pθ(θ ∈C0(x)) = 1 −α.
Casella et Hwang (1983) consid`erent ´egalement les r´egions recentr´ees de vo-
lume variable

530
10 Extensions hi´erarchique et empirique
Cv
δ (x) = {θ; ∥θ −δ(x)∥2 ≤v(x)}
et ils d´eterminent δ et v par une analyse bay´esienne empirique `a partir d’une
r´egion HPD α-cr´edible. Le centre de la r´egion est l’estimateur de James-Stein
δ(x) =

1 −p −2
||x||2
+
x
et le rayon est donn´e par
v(x) =
⎧
⎨
⎩

1 −p−2
cα
 4
cα −p log

1 −p−2
cα
5
si ||x||2 < cα ,

1 −p−2
||x||2
 4
cα −p log

1 −p−2
||x||2
5
sinon.
La forme du rayon variable est justiﬁ´ee par un coˆut lin´eaire
L(θ, C) = k vol(C) −IC(θ),
d´ej`a vu `a la Section 5.5 (Exercice 10.29). Cette r´egion de conﬁance bay´esienne
empirique a alors un niveau de conﬁance d’au moins 1 −α (au sens fr´equen-
tiste), sauf pour les plus petites valeurs de p.
∥
Exemple 10.35. Une objection classique `a l’encontre des r´egions de conﬁan-
ce recentr´ees repose sur leur inutilit´e pratique dans la mesure o`u le niveau de
conﬁance rapport´e est toujours
inf
θ Pθ(θ ∈Ca(x)) = 1 −α = Pθ(θ ∈C0(x)).
En ce sens, on peut dire que les r´egions standard sont plus pr´ecises puisqu’elles
co¨ıncident exactement avec le niveau de conﬁance rapport´e. Nous avons d´ej`a
parl´e de la valeur intrins`eque de ces niveaux de conﬁance `a la Section 5.5
et les lecteurs pourront se r´ef´erer au Chapitre 5 pour des commentaires sur
le cˆot´e artiﬁciel de la notion de niveau de conﬁance. On propose aussi une
voie alternative `a la ﬁn du Chapitre 5 : il s’agit d’un niveau de conﬁance
conditionnel, γ(x), plus adapt´e `a la r´egion recentr´ee Ca(x), qu’on ´evalue sous
coˆut quadratique
(γ(x) −ICa(x))2.
(10.22)
Pour le mod`ele pr´esent´e dans l’Exemple 10.33, George et Casella (1994) pro-
posent une solution bay´esienne empirique `a ce probl`eme d’´evaluation avec une
r´egion recentr´ee de la forme
CEB(x) = {θ; ∥θ −(1 −ˆb)x∥2 ≤c}
et un rapport de conﬁance
γEB(x) = P(χ2
p ≤c/(1 −ˆb)).

10.5 Justiﬁcations bay´esiennes empiriques de l’eﬀet Stein
531
Si θ ∼Np(0, τ2Ip), la r´eponse bay´esienne serait
γπ(x) = P π(θ ∈CB(x)|x)
= P π(||θ −(1 −b)x||2 ≤c|x)
= P(χ2
p ≤c/(1 −b)),
puisque θ|x ∼Np((1 −b)x, (1 −b)) avec 1 −b = τ 2/(σ2 + τ 2). Les estimateurs
bay´esiens empiriques ´etablis par George et Casella (1994) dans γEB sont
1 −ˆb(x) = max

d, 1 −
a
||x||2

= ua,d(||x||2),
et CEB est centr´e sur l’estimateur de Stein tronqu´e associ´e `a a et d ≤1. George
et Casella (1994) montrent de plus que l’estimateur bay´esien empirique ainsi
obtenu
γEB(x) = P

χ2
p ≤
c
max{d, (||x||2 −a)/||x||2}

,
domine le rapport constant 1 −α sous coˆut quadratique (10.22), pour d ≤1
et a suﬃsamment petit. Une valeur possible pour d est
d =
2c
c + 2a +
7
c(c + 4a)
.
Voir Lu et Berger (1989b) pour une autre solution.
∥
10.5.4 Commentaires
Pour conclure cette ´etude des m´ethodes bay´esiennes empiriques, reve-
nons sur leur nature duale : ces proc´edures inf´erentielles s’inspirent `a la
fois de m´ethodes fr´equentistes et bay´esiennes et on peut penser que les
am´eliorations qu’elles apportent aux estimateurs fr´equentistes classiques pro-
viennent de l’approche bay´esienne. Mais leur sous-optimalit´e (notamment en
termes d’admissibilit´e) peut ˆetre attribu´ee au refus d’adopter un point de
vue compl`etement bay´esien et `a l’arbitraire en r´esultant dans les choix de
m´ethodes. Il est ﬁnalement assez logique qu’une m´ethode qui repose sur des
estimateurs classiques mais sous-optimaux (tels que l’estimateur du maxi-
mum de vraisemblance de la moyenne dans le cas normal multidimension-
nel) et sur des techniques de circonstance non l´egitim´ees par la Th´eorie de
la D´ecision (comme l’estimation sans biais ou la m´ethode des moments) ne
puisse d´eboucher sur des proc´edures optimales. Le fait que ces estimateurs
soient domin´es par de vrais estimateurs de Bayes (Brown, 1988) est un argu-
ment suppl´ementaire pour l’adoption sans restriction du paradigme bay´esien,
mˆeme s’il n´ecessite une mod´elisation hi´erarchique. Le d´eveloppement de nou-
velles techniques num´eriques (Chapitre 6), permettant aujourd’hui de trai-
ter des mod`eles bien plus complexes qu’avant, apparaˆıt comme un coup de
grˆace port´e `a ces m´ethodes empiriques qui pr´esentaient auparavant l’avantage
d’all´eger la lourdeur des calculs des analyses bay´esiennes compl`etes.

532
10 Extensions hi´erarchique et empirique
10.6 Exercices
Section 10.1
10.1 Dans le cas d’un mod`ele repr´esent´e par un graphe acyclique orient´e, comme
celui de la Figure 10.1, montrer que la densit´e conditionnelle compl`ete d’une
variable (ou nœud) sachant les autres variables du mod`ele est la mˆeme que la
loi de ce nœud sachant uniquement les nœuds auxquels il est connect´e.
10.2 Dans le cadre de l’Exemple 10.1,
a. Montrer que, si le g´en´erateur Λ peut se d´ecomposer en P ˜ΛP t, o`u P est la
matrice orthogonale des vecteurs propres de Λ et ˜Λ est la matrice diagonale
des valeurs propres de Λ, λi (i = 1, . . . , 7), alors
exp{Λ} = P
0
B
B
B
@
eλ1
0
. . .
0
0 eλ2 . . .
0
...
0
0
. . . eλ7
1
C
C
C
A P t ,
et exp{T Λ} = exp{Λ}T .
b. En d´eduire que les formules de r´ecurrence forward-backward (6.31) de
l’Exercice 6.51 s’appliquent ici en rempla¸cant pij par p(T )
ij , ´el´ement (i, j)
de la matrice exp{Λ}T .
c. D´eterminer la complexit´e num´erique de ces formules et comparer avec la
repr´esentation alternative suivante : introduire des valeurs manquantes x∗
ij
telles que les individus soient observ´es `a intervalles r´eguliers avec un temps
interobservations de η, ajouter ces valeurs manquantes `a l’´echantillon et
calculer les formules de forward-backward sur l’´echantillon complet. (Re-
marquer que cette op´eration fait que exp{Λ}η n’est calcul´ee qu’une fois.)
Section 10.2.1
10.3 Montrer que l’hyper a priori choisi dans l’Exemple 10.4 donne une loi a pos-
teriori bien d´eﬁnie s’il y a au moins deux observations pour chaque ´etape de
l’exp´erience.
10.4 Repr´esenter le mod`ele hi´erarchique de l’Exemple 10.4 sous la forme d’un
graphe acyclique orient´e, comme celui de la Figure 10.1.
10.5 Soit J ∼Mk(N; p1, . . . , pk) une variable al´eatoire multinomiale. On suppose
que N est simul´e selon une loi de Poisson de param`etre λ. D´eterminer la loi
marginale de J. Donner, en particulier, la matrice de covariance. G´en´eraliser au
cas p = (p1, . . . , pk) ∼D(α1, . . . , αk), loi de Dirichlet.
10.6 Une mouche pond N œufs selon une loi de Poisson P(λ) et chaque œuf survit
avec probabilit´e p.
a. Montrer que la loi du nombre d’œufs survivants x est alors hi´erarchique
x|N ∼B(N, p),
N ∼P(λ).
b. Calculer la distribution marginale de x et la distribution a posteriori de N.

10.6 Exercices
533
10.7 Dans le cadre de l’Exemple 10.6, avec p connu, donner la loi a posteriori de N
si π2(λ) = 1/λ. ´Etudier la g´en´eralisation au cas o`u p est inconnu et π1(p) = 1.
Section 10.2.2
10.8 Si y|θ ∼Np(θ, Σ1), θ|β ∼Np(Xβ, Σ2) et β ∼Nq(μ, Σ3), ´etablir les lois a
priori et a posteriori de θ.
10.9 On se place dans un cadre de r´egression logistique, c’est-`a-dire qu’on consid`ere
des observations (x1, y1), . . . , (xn, yn) telles que xi ∈Rk et yi ∈{0, 1} avec
P(yi = 1|xi) = exp(xt
iβ)/(1 + exp(xt
iβ)) .
D´eterminer une condition suﬃsante sur π(τ) pour que la distribution a posteriori
de β soit d´eﬁnie lorsque β|τ ∼Nq(0, τ 2Ip). (Les xi sont suppos´es ﬁx´es.)
10.10 Reprendre l’Exercice 10.9 avec un mod`ele probit, c’est-`a-dire avec
P(yi = 1|xi) = Φ(xt
iβ)
et Φ fonction de r´epartition de la loi normale standard.
Section 10.2.3
10.11 ´Etablir les Lemmes 10.10 et 10.12.
10.12
∗(Berger et Robert, 1990) Dans le cadre de l’Exemple 10.15, on suppose que
μ ∈H = {μ = Y β; β ∈Rℓ} et π2(β, σ2
π) = 1. Montrer que m(x) < +∞si
p > 2 + ℓ.
10.13 Spiegelhalter et Lauritzen (1990) pr´esentent le mod`ele suivant : les poids yij
de soixante rats sont relev´es chaque semaine, les trente premi`eres observations
constituant le groupe de contrˆole (1 ≤i ≤60, 1 ≤j ≤5). Le mod`ele associ´e est
yij ∼N (αi + βij, σi) ,
avec σi = σc pour i ≤30, σi = σt pour 31 ≤i ≤60 et
(αi, βi) ∼N2 ((αc, βc), Σc)
(i = 1, . . . , 30) ,
(αi, βi) ∼N2 ((αt, βt), Σt)
(i = 31, . . . , 60) .
Compl´eter le mod`ele avec des lois a priori non informatives sur les hyperpa-
ram`etres et ´etudier si la distribution a posteriori est bien d´eﬁnie.
10.14 Dans le cadre de l’Exemple 10.11, on d´eﬁnit les moyennes
xi = 1
Jc
i
Jc
i
X
i=1
xij,
yi = 1
Ja
i
Ja
i
X
i=1
yij,
zi = 1
Jt
i
Jt
i
X
i=1
zij
et
θ = 1
I
I
X
i=1
θi,
δ = 1
I
I
X
i=1
δi.
Montrer que les densit´es conditionnelles compl`etes s’´ecrivent (1 ≤i ≤I)
μθ ∼N (θ, σ2
θ/I),
μδ ∼N (δ, σ2
δ/I),
μP ∼N
0
@X
ℓi=0
ξi/IP , σ2
P /IP
1
A ,
μD ∼N
0
@X
ℓi=1
ξi/ID, σ2
D/ID
1
A ,

534
10 Extensions hi´erarchique et empirique
θi ∼N
„
σ−2
θ μθ + Jc
i σ−2
c xi + Ja
i σ−2
a (yi −δi) + Jt
i σ−2
t
(zi −δi −ξi)
σ−2
θ
+ Jc
i σ−2
c
+ Ja
i σ−2
a
+ Jt
i σ−2
t
,
(σ−2
θ
+ Jc
i σ−2
c
+ Ja
i σ−2
a
+ Jt
i σ−2
t
)−1
«
δi ∼N
„
σ−2
δ μδ + Ja
i σ−2
a (yi −θi) + Jt
i σ−2
t
(zi −θi −ξi)
σ−2
δ
+ Ja
i σ−2
a
+ Jt
i σ−2
t
,
(σ−2
δ
+ Ja
i σ−2
a
+ Jt
i σ−2
t
)−1
«
ξi ∼N
 
σ−2ℓi
D
σ−2(1−ℓi)
P
μℓi
Dμ1−ℓi
P
+ Jt
i σ−2
t
(zi −θi −δi)
σ−2ℓi
D
σ−2(1−ℓi)
P
+ Jt
i σ−2
t
,
(σ−2ℓi
D
σ−2(1−ℓi)
P
+ Jt
i σ−2
t
)−1
«
σ−2
c
∼G a
 X
i
Jc
i
2 ,
X
i,j
(xij −θi)2
2
!
,
σ−2
a
∼G a
 X
i
Ja
i
2 ,
X
i,j
(yij −θi −δi)2
2
!
,
σ−2
t
∼G a
 X
i
Jt
i
2 ,
X
i,j
(zij −θi −δi −ξi)2
2
!
,
σ−2
θ
∼G a
 
I
2,
X
i
(θi −μθ)2
2
!
,
σ−2
δ
∼G a
 
I
2,
X
i
(δi −μδ)2
2
!
,
σ−2
P
∼G a
0
@ IP
2 ,
X
ℓi=0
(ξi −μP )2
2
1
A , σ−2
D ∼G a
0
@ ID
2 ,
X
ℓi=1
(ξi −μD)2
2
1
A .
10.15 (Suite de l’Exercice 10.14)
Lorsque les δi sont distribu´es selon (10.3),
donner les densit´es conditionnelles compl`etes correspondantes.
Section 10.2.4
10.16
∗(Berger et Robert, 1990) Soient x ∼Np(θ, Σ), θ ∼Np(yβ, σ2
πIp), et β ∼
Nℓ(β0, A), avec rang(A) = m.
a. Montrer que si, pour K > 0, les deux int´egrales
Z K
0
π2(σ2
π)dσ2
π
et
Z +∞
K
1
(σ2π)(p−ℓ+m)/2 π2(σ2
π)dσ2
π
sont ﬁnies, alors m(x) < +∞pour tout x ∈Rp.
b. Montrer que la condition a. est satisfaite si, pour ϵ > 0, K1 > 0, K2 > 0,
π2(σ2
π) <
K1
K2 + (σ2π)(2+ϵ−p+ℓ−m)/2 ,
c’est-`a-dire si π2(σ2
π) = 1 et p −l + m > 2.
10.17
∗(Berger, 1985b)
Dans le cadre de l’Exemple 10.19, calculer la variance a
posteriori. ´Etudier ´egalement le cas non informatif.
10.18 (Lindley et Smith, 1972)
´Elargir l’Exemple 10.19 au mod`ele g´en´eral
x|θ ∼Np(A1θ, Σ1),
θ|β ∼Nℓ(A2β, Σ2),
β|ξ ∼Nq(A3ξ, Σ3),
et v´eriﬁer les r´esultats de l’Exemple 10.8.

10.6 Exercices
535
10.19 (Berger, 1985b)
Montrer que, pour le mod`ele de l’Exemple 10.19 avec des
lois non informatives sur ξ et σ2
π, l’estimateur bay´esien hi´erarchique est
δπ(x) = x −hp−2(||x −¯x1||2)(x −¯x1)
avec
hp(t) = p
2t(1 −Hp(t)),
Hp(t) =
8
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
:
tp/2
(p/2)!
n
et −P(p−2)/2
i=1
ti/i!
o
si p est pair,
tp/2
Γ(p/2)
n
et[2Φ(
√
2t) −1] −P(p−3)/2
i=1
t(i+3)/2
Γ (i+3/2)
o
si p est impair.
10.20 Dans le cadre de l’Exemple 10.14, calculer la moyenne a posteriori de p quand
x = 3, n = 5.
Section 10.2.5
10.21 Comparer les mod`eles
x ∼Np(θ, Ip),
θ|μ ∼Np(μ, τ 2Ip),
π2(μ, τ 2) = 1/τ 2,
et
x ∼Np(θ, Ip),
θ|μ ∼Np(μ, Ip),
μ|ξ ∼Np(ξ, τ 2Ip),
π2(ξ, τ 2) = 1/τ 2,
selon les estimateurs de θ.
10.22 Soient xi ∼N (μi, σ2) et μi|μ, τ ∼N (μ, τ 2) (i = 1, . . . , n).
a. Montrer que π(μ, τ) = 1/τ conduit `a une loi a posteriori ind´eﬁnie.
b. Montrer que π(μ, τ) = 1 permet de contourner le probl`eme ci-dessus.
10.23 Dans le cadre de l’Exemple 10.8, montrer que l’estimateur de Bayes
δπ(y) = Eπ2(σ2
π|y)
»
Ip + σ2
σ2π
(XtX)−1
–−1
ˆβ
peut s’´ecrire sous la forme
ˆ
Ip + h(y)(XtX)−1˜−1 ˆβ.
(Indication : Utiliser une diagonalisation conjointe de Ip et XtX.) Expliquer
comment cet estimateur peut aider `a r´eduire la multicolin´earit´e.
Section 10.3
10.24
∗(Stein, 1981)
D´emontrer le Lemme 10.21 `a l’aide d’une int´egration par
parties et mettre ce r´esultat en relation avec l’Exercice 2.56.

536
10 Extensions hi´erarchique et empirique
10.25
∗Si H est la matrice hessienne d´eﬁnie au Lemme 10.21, montrer que l’´equivalent
de (10.10) pour la matrice de covariance est
V EB(x) = Σ + Σ H(x)
m(x)Σ −Σ(∇log m(x))(∇log m(x))tΣ.
En utilisant une technique analogue `a l’Exercice 10.24, montrer qu’un estimateur
sans biais de l’erreur matricielle moyenne
Eθ[(θ −δ(x))(θ −δ(x))t]
peut s’´ecrire sous la forme diﬀ´erentielle
ˆVδHB(x) = Σ + 2Σ H(x)
m(x)Σ −Σ(∇log m(x))(∇log m(x))tΣ.
D´eduire de cette expression l’estimateur sans biais du risque quadratique.
10.26
∗En utilisant l’approximation suivante de 1F1(a; b; z) :
1F1(a; b; z) ≃Γ(b)
Γ(a)ez/2(z/2)a−b
„
1 + (1 −a)(b −a)
(z/2)
«
,
donner une approximation de l’estimateur δπ de l’Exemple 10.26 et la comparer
`a l’estimateur de James-Stein.
10.27 On consid`ere x ∼Np(θ, Ip), θ ∼Np(0, τ 2Ip) et, si η = 1/(1 + τ 2), on
suppose que π2(η) = η2−(p/2). Montrer que l’estimateur bay´esien hi´erarchique
correspondant peut s’´ecrire explicitement
δHB(x) =
„
1
1 −e−||x||2/2 −
2
||y||2
«
x ,
et d´eterminer s’il est minimax et admissible.
10.28
∗(Hartigan, 1983) Soit une observation x ∼Np(θ, Ip).
a. Si f est une fonction positive croissante major´ee par 2(p −2), montrer que
δf(x) =
„
1 −f(||x||2)
||x||2
«
x
domine δ0(x) = x pour le coˆut quadratique usuel. (Indication : Utiliser l’esti-
mateur sans biais du risque obtenu dans l’Exercice 2.56.)
b. Soit π un a priori sur θ tel que, conditionnellement `a τ 2, θ ∼Np(0, τ 2) et
τ 2 ∼π1. On suppose que l’hyper a priori π1 est une fonction log-concave
de log(τ 2 + 1) et que (τ 2 + 1)1−απ1(τ 2) est strictement croissante en τ 2. `A
l’aide du r´esultat g´en´eral de a., montrer que l’estimateur bay´esien hi´erarchique
associ´e `a π domine δ0 si 4 −2α ≤p. (Indication : Montrer que δπ(x) =
(1 −E[(τ 2 + 1)−1|x])x et que E[(τ 2 + 1)−1|x]) est strictement croissante en
||x||2 tout en ´etant clairement major´ee par 2(p −2).)
c. Montrer que de telles lois a priori ne peuvent ˆetre propres que pour α < 0
et donc qu’on ne peut garantir l’admissibilit´e de ces estimateurs de Bayes
minimax que pour p ≥5.

10.6 Exercices
537
d. Montrer que le risque de Bayes est en fait ﬁni pour α < 2 et en d´eduire que les
estimateurs bay´esiens hi´erarchiques sont admissibles quel que soit p. [Note :
Strawderman, 1971, a montr´e dans le cas particulier π1(τ 2) = (1+τ 2)α−1 que
la dimension limite pour l’existence d’estimateurs de Bayes minimax propres
est pr´ecis´ement p = 5.]
Section 10.4.2
Tab. 10.2. Intentions d’achat de voiture par foyer.
Intentions 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
R´eponses
293 26
21 21 10
9
12 13 11 10 21
10.29 (Casella, 1985b)
Dans un sondage sur les intentions d’achat de voiture,
quatre cent quarante-sept foyers ´evaluent leur probabilit´e de se procurer un
nouveau v´ehicule au cours de l’ann´ee `a venir. Les r´esultats de ce sondage sont
donn´es dans le Tableau 10.2.
Les r´eponses xi (1 ≤i ≤447) sont mod´elis´ees par une loi binomiale renormalis´ee
B(10, pi), c’est-`a-dire que 10xi ∼B(10, pi), et les pi sont distribu´es suivant une
loi Be(α, β).
a. Utiliser la distribution marginale pour donner des estimateurs de α et β par
la m´ethode des moments.
b. Calculer un estimateur bay´esien empirique des pi sous coˆut quadratique.
c. Les vraies intentions pi ´etant connues `a la ﬁn de l’ann´ee, on peut rapporter
dans le Tableau 10.3 les diﬀ´erences avec les d´eclarations initiales. Comparer
les coˆuts quadratiques de l’estimateur classique (c’est-`a-dire ˆpi = xi), de
l’estimateur bay´esien empirique et d’un estimateur de Bayes de votre choix.
Tab. 10.3.
Proportions d’achats de voitures en fonction des probabilit´es d’inten-
tion.
Intentions
0
0.1—0.3
0.4—0.6
0.7—0.9
1
D´eclarations
0
0.19
0.51
0.79
1
R´ealisations
0.07
0.19
0.41
0.48 0.583
10.30 D´eterminer l’´equivalent de la Proposition 10.31 pour le test H0 :
θ =
θ0 contre H1 :
θ = θ1 pour deux probl`emes ind´ependants d’´echantillons
x1, . . . , xn ∼f(x|θ), y1, . . . , ym ∼f(y|θ′) et P(θ = θ0) = P(θ′ = θ0) = π0.
G´en´eraliser `a p ´echantillons et appliquer au cas du test de θi = 0 contre θi = 1
pour xi ∼N (θi, 1) (1 ≤i ≤p).
10.31
∗(Hartigan, 1983) On consid`ere x ∼Np(θ, σ2Ip) et θ ∼Np(0, τ 2Ip), avec σ2
inconnu et s2 ∼σ2χ2
k.
a. Donner un estimateur bay´esien empirique de θ `a partir des estimateurs de
maximum de vraisemblance de τ 2 et σ2 et d´eterminer si l’estimateur obtenu
est minimax. (Indication : Utiliser l’Exercice 10.28.)

538
10 Extensions hi´erarchique et empirique
b. Comparer aux estimateurs bay´esiens empiriques utilisant les estimateurs des
moments de σ2 et τ 2.
c. Si π(σ2, τ 2) ∝(σ2 + σ2
0)α−1(σ2)β−1, montrer que la distribution a posteriori
de (σ−2, (σ2 + τ 2)−1) est
χ2
k−2β/s × χ2
p−2α/||x||2Iσ2≤σ2+τ2.
Montrer que l’estimateur obtenu est minimax si
p −α
k −β −2 ≤2(p −2)
k + 1 .
(Indication : Utiliser le Th´eor`eme 2.52.)
10.32 (Hartigan, 1983)
Soient un mod`ele multinomial Mk(n; p1, . . . , pk) et une
observation (n1, . . . , nk). Une loi conjugu´ee a priori possible est la loi de Dirichlet
D(α1, . . . , αk).
a. Montrer que
E
" k
X
i=1
n2
i
#
= n + (n −1) α + 1
kα + 1,
et d´eterminer quand l’´equation des moments obtenue `a partir de cette
´egalit´e a une solution positive. Donner un estimateur bay´esien empirique de
(p1, . . . , pk) dans ce cas.
b. Calculer un estimateur bay´esien empirique en utilisant les estimateurs du
maximum de vraisemblance des αi. [Note : Consulter Good, 1975, pour plus
de d´etails sur ce mod`ele.]
10.33
∗(Morris, 1983a) Une famille exponentielle de densit´e
f(x|θ) = h(x)eθx−ψ(θ)
a une variance quadratique si la variance peut s’´ecrire
V (μ) = ψ′′(θ) = v0 + v1μ + v2μ2,
o`u μ = ψ′(θ) est l’esp´erance de f(x|θ). Morris (1982) donne une caract´erisation
des six familles de variance quadratique (Exercice 3.9). Ces lois sont not´ees
NEF(μ, V (μ)).
a. Montrer que la loi conjugu´ee de μ peut s’´ecrire
g(μ) = K(m, μ0)emμ0θ(μ)−mψ(θ(μ))V −1(μ)
(10.23)
et que
Eπ[μ] = μ0,
V π(μ) = τ 2
0 = V (μ0)
m −v2 ,
Par cons´equent, la loi conjugu´ee est aussi une famille exponentielle de variance
quadratique. ´Etablir une table de correspondances entre loi de l’´echantillon
et loi a priori conjugu´ee pour les six familles obtenues dans l’Exercice 3.24.
b. Montrer que l’estimateur de Bayes associ´e `a (10.23) pour n observations
ind´ependantes x1, . . . , xn et le coˆut quadratique est
δπ(x1, . . . , xn) = (1 −B)¯x + Bμ0,
o`u
B =
V (μ0) + v2τ 2
0
V (μ0) + (n + v2)τ 2
0
.

10.6 Exercices
539
c. Montrer que, pour la loi conjugu´ee (10.23), les moments marginaux de ¯x sont
E[¯x] = μ0,
var(¯x) = V (μ0)
n
m + n
m −v2 .
d. Soient k observations ind´ependantes
xi|μi ∼NEF(μi, V (μi)/n)
(1 ≤i ≤k),
de param`etres ind´ependants μi selon la loi conjugu´ee (10.23). Si ¯x = P
i xi/k
et s = P
i(xi −¯x)2 et si
E[V (¯x)(k −1)]
E[s]
= E
»V (¯x)(k −3)
s
–
(les esp´erances ´etant prises sous la loi marginale), montrer qu’un estimateur
bay´esien empirique pour μi est
δEB
i
(x1, . . . , xk) = (1 −ˆB)xi + ˆB¯x,
avec
ˆB = min
„
v2
n + v2
k −1
k
+
n
n + v2
(k −3)V (¯x)
ns
, 1
«
.
Section 10.5.1
10.34 Montrer que, pour la loi marginale de l’Exemple 10.32, (p −2)/||x||2 est
eﬀectivement un estimateur sans biais de 1/(1 + τ 2).
10.35 D´emontrer la formule (10.20) de l’Exemple 10.33.
10.36
∗(Kubokawa, 1991)
Soient δJS(x) = [1 −(p −2)/||x||2]x, l’estimateur de
James-Stein, et x ∼Np(θ, Ip). On pose λ = ||θ||2/2 ; fp(t; λ) est la densit´e du
khi deux d´ecentr´ee avec param`etre de non-centralit´e λ.
a. Pour la troncature de δJS
δ1(x; c, r) =
8
<
:
„
1 −
c
||x||2
«
x
si ||x||2 < r,
δJS(x)
sinon,
montrer que le risque quadratique de δ1(x; c, r) est minimal pour
c1(r, λ) = p −2 −
2fp(r; λ)
R r
0 (1/t)fp(t; λ) dt.
b. On pose
c1(r) = p −2 −
2
R 1
0 tp/2−2e(1−t)r/2dt
.
Montrer que δ1(x; c1(r), r) domine δJS pour tout r.
c. En utilisant un argument de limite, montrer que
δ∗
1(x) =
„
1 −c1(||x||2)
||x||2
«
x
domine δJS. [Note : Cet estimateur vient de Strawderman, 1971, et Berger,
1975a. Voir l’Exercice 10.28.]

540
10 Extensions hi´erarchique et empirique
d. Montrer que δ∗
1 est admissible. (Indication : On pourra utiliser la condition
suﬃsante du Th´eor`eme 8.13.)
10.37
∗(Bock et Robert, 1985) On consid`ere x ∼Np(θ, Ip) et θ ∼U{∥θ∥2=c}, loi
uniforme sur la sph`ere de rayon c. Proposer un estimateur bay´esien empirique de
θ en fonction de ||x||2 et montrer que, si cet estimateur d´ecoule de l’estimateur
du maximum de vraisemblance de c, alors δEB(x) = h(x)x avec
„
1 −
p
||x||2
«+
≤h(x) ≤
„
1 −p −1
||x||2
«+
.
Discuter la robustesse de l’eﬀet Stein en termes de sym´etrie sph´erique.
10.38
∗(George, 1986a) Soit y ∼Np(θ, Ip). Cet exercice ´etablit un estimateur qui
choisit entre plusieurs partitions de y en vecteurs plus petits avant de r´etr´ecir
l’observation vers chacun de ces vecteurs. Pour k = 1, . . . , K, notons
y = (yk1, . . . , ykJk)Ck
et
θ = (θk1, . . . , θkJk)Ck
les partitions de y et θ en vecteurs ykj et θkj de dimensions pkj (1 ≤j ≤Jk),
avec Ck matrice de permutation contenant des 0 et des 1 avec un seul 1 pour
chaque ligne et chaque colonne. Pour k = 1, . . . , K, soit δk = (δk1, . . . , δkJk)Ck
un estimateur de composantes
δkj(ykj) = ykj + ∇log mkj(ykj),
o`u les fonctions mkj de Rpkj dans R sont deux fois diﬀ´erentiables. On pose
´egalement
mk(y) =
Jk
Y
j=1
mkj(ykj)
et
m∗(y) =
K
X
k=1
ωkmk(y),
pour ωk ≥0 (1 ≤k ≤K) et P
k ωk = 1.
a. Si πkj est une loi a priori sur θkj et si mkj est la loi marginale correspondante
sur ykj (1 ≤k ≤K, 1 ≤j ≤Jk), montrer que mk est la loi marginale de y
pour la loi a priori
πk(θ) =
Jk
Y
j=1
πkj(θkj) ,
et que δk est la moyenne a posteriori de cette loi.
b. En d´eduire que
δ∗(y) = y + ∇log m∗(y)
est l’estimateur de Bayes pour la loi a priori
π∗(θ) =
K
X
k=1
ωkπk(θ).
c. Montrer que δ∗peut ´egalement s’´ecrire sous la forme
δ∗(y) =
K
X
k=1
ϱk(y)δk(y),
avec ϱk(y) = ωkmk(y)/m∗(y), et interpr´eter ce r´esultat.

10.6 Exercices
541
d. Montrer que si, pour k = 1, . . . , K,
Eθ
˛˛˛˛
∂2mk(y)
∂y2
i
ﬃ
mk(y)
˛˛˛˛ < +∞,
Eθ||∇log mk(y)||2 < +∞,
alors l’estimateur sans biais du risque de δ∗peut s’´ecrire
Dδ∗(y) = p −
K
X
k=1
ϱk(y)
"
Dδk(y) −(1/2)
K
X
ℓ=1
ϱℓ(y)||δk(y) −δℓ(y)||2
#
,
avec
Dδk(y) = ||∇log mk(y)||2 −2Δmk(y)/mk(y).
(Indication : Utiliser le Lemme 10.21 avec Q = Σ = Ip.)
e. En d´eduire que, si mkj est surharmonique, c’est-`a-dire tel que Δmkj(ykj) ≤0
pour 1 ≤k ≤K, 1 ≤j ≤Jk, δ∗est minimax. [Note : Ce r´esultat peut
ˆetre d´ecrit par l’assertion qu’une combinaison convexe “propre” d’estimateurs
minimax est minimax.]
f. Pour 1 ≤k ≤K, 1 ≤j ≤Jk, on note Vkj un sous-espace de Rpkj , avec
dim Vkj = pkj −qkj et qkj ≥3 ; Pkj est le projecteur orthogonal associ´e de
Rpjk sur Vkj et skj = ||ykj −Pkjykj||2. Donner les estimateurs `a r´etr´ecisseur
multiple δ∗associ´es `a
mkj(ykj) =
8
>
<
>
:
„qkj −2
eskj
«(qkj −2)/2
si skj ≥qkj −2,
exp(−skj/2)
sinon.
(Indication : La solution est l’estimateur tronqu´e de James-Stein.)
Section 10.5.2
10.39
∗(Kubokawa et al., 1993a)
Soient x ∼Np(θ, σ2Ip), y ∼Nq(ξ, σ2Iq), et
s ∼σ2χ2
n, avec θ, ξ et σ inconnus. Un estimateur bay´esien empirique de θ est
l’estimateur de James-Stein
δJS(x, s) =
„
1 −
(p −2)s
(n + 2)||x||2
«
x.
Le but de cet exercice est de montrer que le remplacement de s par un estimateur
plus eﬃcace de σ2 peut conduire `a une am´elioration de l’estimation de θ.
a. Montrer que, si γh(y, s) = sh(||y||2/s) domine γ0(s) = s/(n + 2) sous coˆut
quadratique invariant
L(σ2, γ) =
“ γ
σ2 −1
”2
,
δJS est domin´e par
ˆδ(x, y, s) =
„
1 −(p −2)γ(y, s)
||x||2
«
x
sous coˆut quadratique. (Indication : On rappelle que γ0 est le meilleur esti-
mateur ´equivariant de σ2.)

542
10 Extensions hi´erarchique et empirique
b. Soit
δg(x, y, s) =
„
1 −(p −2)s
||x||2
g(||y||2/s, ||x||2/s)
«
x.
On d´eﬁnit
g∗(u, v) = min
„
g(u, v), 1 + u + v
p + q + n
«
,
et supposons que g et g∗sont des fonctions absolument continues de v. Mon-
trer que, si
E
»∂g∗(U, V )
∂v
−∂g(U, V )
∂v
–
≥0,
lorsque U = ||y||2/s et V = ||x||2/s, δg∗domine δg.
c. En d´eduire que
δ2(x, y, s) = x −p −2
||x||2 min
j
s
n + 2, s + ||y||2
n + q + 2, s + ||x||2 + ||y||2
n + p + q + 2
ﬀ
x
domine δJS.
Section 10.5.3
10.40
∗(Casella et Hwang, 1983) Soit x ∼Np(θ, Ip). Sous le coˆut lin´eaire
L(θ, C) = k vol(C) −IC(θ),
on rappelle que les estimateurs de Bayes sont des r´egions HPD de la forme
{θ; π(θ|x) ≥k} quand π({θ; π(θ|x) = k}) = 0. De plus, si
k = k0 = e−c2/2/(2π)p/2,
Joshi (1967a) montre que la r´egion usuelle
C0
x = {θ; ||θ −x|| ≤c},
est minimax.
a. Montrer que, si θ ∼Np(0, τ 2Ip), l’ensemble de Bayes est
Cπ
x =
(
θ; ||θ −δπ(x)||2 ≤−2τ 2
τ 2 + 1 log
"
k
„ 2πτ 2
τ 2 + 1
«p/2#)
,
o`u δπ(x) = (τ 2/τ 2 +1)x est l’estimateur de Bayes de θ. Pour k = k0, montrer
que cet ensemble peut s’´ecrire
Cπ
x =
j
θ; ||θ −δπ(x)||2 ≤
τ 2
τ 2 + 1
»
c2 −p log
„
τ 2
τ 2 + 1
«–ﬀ
.
b. En d´eduire qu’un ensemble de Bayes empirique simple est
CEB
x
=
n
θ; ∥θ −δEB(x)∥2 ≤vEB(x)
o
,
avec δEB(x) = (1 −[(p −2)/||x||2])x et
vEB(x) =
„
1 −p −2
||x||2
« „
c2 −p log
˛˛˛˛1 −p −2
||x||2
˛˛˛˛
«
.

10.6 Exercices
543
c. Expliquer pourquoi il est pr´ef´erable de consid´erer
δ+(x) =
„
1 −p −2
||x||2
«+
x
et
ve(x) =
8
>
>
<
>
>
:
`
1 −p−2
c2
´ `
c2 −p log
ˆ
1 −p−2
c2
˜´
si ||x||2 < c,
“
1 −
p−2
||x||2
” “
c2 −p log
h
1 −
p−2
||x||2
i”
sinon.
d. G´en´eraliser au cas o`u x ∼Np(θ, σ2Ip) et s2 ∼σ2χ2
q.
Note 10.7.2
10.41 Dans le cadre de l’Exemple 10.38,
a. Montrer que
L(η, ˆη) = p
2 log
„η
ˆη
«
+ 1
2
„ 1
ˆη −1
η
«
p η ,
et en d´eduire (10.26).
b. Montrer que la loi a posteriori associ´ee `a πd est bien d´eﬁnie pour d >
(4 −p)/2.
c. Prouver (10.27) et (10.28).
d. D´eduire de l’approximation
1F1(a, b, z) = Γ(b) z−a
j
1 −a(1 + a −b)
z
+ O(z2)
ﬀ
l’´equivalence (10.29).
10.42
∗(Suite de l’Exercice 10.41) En utilisant les conditions STUB (Section
8.5) et l’approximation (10.29), montrer que le choix d = 1 est optimal.
10.43
∗(Suite de l’Exercice 10.41)
D´eduire d’Alam (1973) la minimaxit´e de
δEB
1 . (Indication : Voir l’Exemple 10.26.)
10.44 Dans le cadre de l’Exemple 10.39,
a. Montrer que le coˆut entropique est donn´e par (10.30) et en d´eduire la forme
g´en´erale des estimateurs de Bayes sous ce coˆut.
b. Montrer que, lorsque π(λ) = λ−d, la distribution a posteriori s’´ecrit
πd(λ|x) ∝λn−d(λ + 1)−P
i xi−n
et en d´eduire que l’estimateur de Bayes de λ est donn´e par (10.31).
c. Montrer que la distribution conditionnelle π(θ|x, λ) ∝θxe−(λ+1)θ et en
d´eduire que l’estimateur de Bayes de θi conditionnellement `a λ est
E[θ|xi, λ] = xi + 1
λ + 1 .
10.45 (Suite de l’Exercice 10.44)
Montrer que l’estimateur classique de θ,
γ0(x) = x, a un risque inﬁni sous coˆut entropique.

544
10 Extensions hi´erarchique et empirique
10.46 (Suite de l’Exercice 10.44) Montrer que l’estimateur de Bayes associ´e `a
l’a priori int´egr´e
π(θ) =
Z
π(θ, λ)dλ
est donn´e par
δπ(x) =
„
1 −
n −d + 1
Pn
i=1 xi + n
«
(x + 1) .
D´eduire des diﬀ´erences sur les risques que l’estimateur de Bayes domine son
´equivalent empirique sous coˆut entropique.
10.7 Notes
10.7.1 Mod`eles graphiques79
Les mod`eles graphiques sont des mod`eles statistiques o`u interviennent des struc-
tures de graphes (au sens de la th´eorie math´ematique des graphes). Ils ont
´et´e d´evelopp´es essentiellement pour repr´esenter les relations d’ind´ependance
conditionnelle, d’abord dans le domaine des syst`emes experts (Whittaker, 1990,
Spiegelhalter et Lauritzen, 1990, Spiegelhalter et Cowell, 1992, Spiegelhalter
et al., 1993). L’application de l’approche bay´esienne `a ces mod`eles, qui a per-
mis d’int´egrer l’incertitude de mod´elisation, a ´et´e grandement facilit´ee par les
progr`es des techniques MCMC, comme le montrent Madigan et York (1995)
dans un article introductif `a partir duquel la pr´esente note a ´et´e ´ecrite.
La construction d’un mod`ele graphique est ´etablie `a partir d’une collection
d’hypoth`eses d’ind´ependance repr´esent´ees par un graphe. Nous rappelons ici
quelques points essentiels de th´eorie des graphes et renvoyons `a Lauritzen (1996)
pour plus de d´etails. Un graphe est d´eﬁni par un ensemble de sommets ou nœuds,
α ∈V , qui repr´esente les variables al´eatoires ou facteurs d’´etude, et par un
ensemble d’arˆetes, (α, β) ∈V2, qui peuvent ˆetre associ´ees `a une direction (le
graphe est alors dit orient´e) ou non (le graphe est non orient´e) et repr´esentent
les liens de d´ependance entre les variables. Dans un graphe non orient´e, les
variables α et β sont reli´ees par une arˆete si, conditionnellement `a toutes les
autres variables, elles ne sont pas ind´ependantes. Dans un graphe orient´e, α est
un parent de β si (α, β) est une arˆete (et β est alors un ﬁls de α)80. Une hypoth`ese
usuelle sur les graphes est de les supposer acycliques, c’est-`a-dire sans chemin
orient´e reliant un nœud α `a lui-mˆeme. On obtient alors la notion de graphes
acycliques orient´es d´eﬁnie par Kiiveri et Speed (1982) et souvent repr´esent´ee
par l’acronyme DAG.
Dans l’optique de construction de mod`eles probabilistes sur les graphes, une
notion importante est celle de clique. Une clique C est un sous-ensemble maximal
de nœuds tous connect´es deux `a deux (maximal au sens o`u il n’existe pas de
sous-ensemble contenant C et v´eriﬁant cette condition). Un ordre des cliques
d’un graphe non orient´e (C1, . . . , Cn) est dit parfait si les nœuds de chaque
79Cette note est fortement inspir´ee de la Note 7.6.6 de Robert et Casella, 1990.
80Les graphes orient´es peuvent ˆetre transform´es en graphes non orient´es en ajou-
tant des liens entre les nœuds qui ont un ﬁls commun et en ignorant les directions.

10.7 Notes
545
clique Ci qui apparaissaient dans une clique ant´erieure sont tous membres de la
mˆeme clique pr´ec´edente (ces nœuds sont appel´es les s´eparateurs, α ∈Si). Dans
ce cas, la densit´e jointe de la variable al´eatoire V `a valeurs dans V est
p(V ) =
Y
v∈V
p(v|P(v)) ,
o`u P(v) d´esigne les parents de v. Ceci peut ´egalement s’´ecrire
p(V ) =
n
Y
i=1
p(Ci)
n
Y
i=1
p(Si)
,
(10.24)
et le mod`ele est alors dit d´ecomposable ; voir Spiegelhalter et Lauritzen (1990),
Dawid et Lauritzen (1993) ou Lauritzen (1996). Comme le soulignent Spiegelhal-
ter et al. (1993), la repr´esentation (10.24) induit un principe de traitement local,
qui permet de construire une loi a priori ou de simuler selon une loi condition-
nelle `a partir d’une seule clique. (Autrement dit, la loi est de Markov par rapport
au graphe non orient´e, ce que montrent Dawid et Lauritzen, 1993.) L’int´erˆet de
cette propri´et´e apparaˆıt alors clairement dans le cadre d’une impl´ementation de
l’´echantillonnage de Gibbs.
Lorsque les densit´es ou probabilit´es sont param´etr´ees, les param`etres sont not´es
θA pour la loi marginale de V ∈A, A ⊂V . (Dans le cas des mod`eles discrets,
θ = θV peut co¨ıncider avec p lui-mˆeme ; voir l’Exemple 10.36.) La loi a priori
π(θ) doit alors ˆetre compatible avec la structure du graphe : Dawid et Lauritzen
(1993) montrent qu’il existe une solution de la forme
π(θ) =
n
Y
i=1
πi(θCi)
n
Y
i=1
˜πi(θSi)
,
(10.25)
reproduisant ainsi la d´ecomposition en cliques (10.24).
Exemple 10.36. On consid`ere un graphe d´ecomposable tel que les variables
al´eatoires correspondant `a tous les nœuds de V soient discr`etes. Soient w ∈W
une valeur possible pour le vecteur de ces variables al´eatoires et θ(w) la proba-
bilit´e associ´ee. Pour la d´ecomposition parfaite en cliques (C1, . . . , Cn), on note
θ(wi) la probabilit´e marginale que le vecteur inclus (v, v ∈Ci) prenne la valeur
wi (∈Wi) et, de fa¸con similaire, θ(ws
i ) est la probabilit´e que le vecteur inclus
(v, v ∈Si) prenne la valeur ws
i en notant (S1, . . . , Sn) la suite de s´eparateurs
correspondante. Dans ce cas,
θ(w) =
n
Y
i=1
θ(wi)
n
Y
i=1
θ(ws
i )
.

546
10 Extensions hi´erarchique et empirique
Comme le montrent Madigan et York (1995), une loi a priori de Dirichlet peut
ˆetre construite sur θW = (θ(w), w ∈W ). Il induit de vraies lois a priori de
Dirichlet sur les θWi = (θ(wi), wi ∈Wi), sous la contrainte que les poids de
Dirichlet soient identiques `a l’intersection de deux cliques. Dawid et Laurit-
zen (1993) prouvent que cette loi a priori est unique, si les deux lois a priori
marginales sur les cliques sont donn´ees.
∥
Exemple 10.37. Giudici et Green (1999) donnent un autre exemple de sp´eciﬁ-
cation a priori dans le cas d’un mod`ele graphique gaussien, X ∼Np(0, Σ),
la matrice de pr´ecision K = {kij} = Σ−1 devant ˆetre compatible avec les
relations d’ind´ependance conditionnelles du graphe. Par exemple, si Xv et Xw
sont ind´ependants sachant le reste du graphe, alors kvw = 0. La vraisemblance
peut alors ˆetre factoris´ee en
f(x|Σ) =
n
Y
i=1
f(xCi|ΣCi)
n
Y
i=1
f(xSi|ΣSi)
,
avec les mˆemes notations pour les cliques et les s´eparateurs que ci-dessus et avec
f(xC|ΣC) densit´e normale NpC (0, ΣC), d’apr`es (10.24). L’a priori sur Σ peut
ˆetre d´eﬁni comme les lois a priori inverses conjugu´ees de Wishart sur les ΣCi,
sous certaines conditions de compatibilit´e.
∥
Madigan et York (1995) utilisent ce cadre pour proposer une approche MCMC
`a la s´election de mod`eles et `a la moyennisation de mod`eles. Dellaportas et Fors-
ter (1996) et Giudici et Green (1999) impl´ementent des algorithmes `a sauts
r´eversibles pour d´eterminer la structure de graphe la plus probable associ´ee `a
un ensemble de donn´ees, les seconds le faisant sous une hypoth`ese gaussienne.
10.7.2 Approche bay´esienne empirique
Comme nous l’avons ´evoqu´e dans la Section 10.4, la diﬃcult´e de l’approche
bay´esienne empirique est qu’elle eﬀectue l’estimation en deux ´etapes, la premi`ere
consistant `a estimer l’hyperparam`etre `a partir de lois marginales et la seconde
`a estimer le param`etre `a partir du pseudo-a priori o`u l’hyperparam`etre est rem-
plac´e par son estimation. Bien que l’ineﬃcacit´e de cette proc´edure–compar´ee `a
une m´ethode vraiment bay´esienne–ne puisse ˆetre compl`etement lev´ee, il semble
logique d’utiliser la technique d’estimation la plus eﬃcace possible `a la premi`ere
´etape, `a savoir une approche bay´esienne non informative. Puisque le premier
niveau d’estimation n’est pas induit par un probl`eme de d´ecision, il est tr`es
probable qu’aucune fonction de coˆut ne soit disponible. Les coˆuts intrins`eques
pr´esent´es en Section 2.5.4 font alors ﬁgure d’option par d´efaut naturelle dans ce
cas. De mani`ere surprenante, cette solution, qui permet pourtant de s’aﬀranchir
de l’arbitraire li´e `a l’estimation des hyperparam`etres du bay´esien empirique,
n’est pas utilis´ee dans la litt´erature. Les deux exemples ci-dessous viennent de
Fourdrinier et Robert (1995).

10.7 Notes
547
Exemple 10.38. (Suite de l’Exemple 10.32) La distribution marginale de
x, m(x|η), est Np(0, η Ip), avec η = 1 + τ 2, et le coˆut entropique correspondant
pour l’estimation de η est
L(η, ˆη) =
Z
log
„m(x|η)
m(x|ˆη)
«
m(x|η)dx
= p
2
„η
ˆη −log
„η
ˆη
«
−1
«
.
(10.26)
Puisque η est un param`etre d’´echelle pour la distribution marginale, une fa-
mille de lois a priori non informatives naturelle est πd(η) = η−d sur [1, ∞) et
l’estimateur correspondant de η est
ˆηd =
R 1
0 ν(p/2)+d−3e−||x||2ν/2dν
R 1
0 ν(p/2)+d−2e−||x||2ν/2dν
.
(10.27)
L’estimateur bay´esien empirique est alors
δEB
d (x) = (1 −ˆη−1)x
=
R 1
0 ν(p/2)+d−3(1 −ν)e−||x||2ν/2dν
R 1
0 ν(p/2)+d−2e−||x||2ν/2dν
x
=
2
p + 2d −2
1F1(2, d + p/2, ||x||2/2)
1F1(2, d + p/2 −1, ||x||2/2) x ,
(10.28)
o`u 1F1 est la fonction conﬂuente hyperg´eom´etrique (Abramowitz et Stegun,
1964, Chapitre 13). Puisque δEB
d (x) est asymptotiquement ´equivalent `a
„
1 −p + 2(d −2)
||x||2
«
x ,
(10.29)
le choix d = 1, c’est-`a-dire π(η) = 1/η, est le choix optimal de d (Exercice
10.42).
∥
Exemple 10.39. (Suite de l’Exemple 10.29) Le coˆut entropique associ´e `a
m(x|λ) est
L(λ, ˆλ) = log
„λ
ˆλ
«
+
„
1 + 1
λ
«
log
 ˆλ + 1
λ + 1
!
(10.30)
et, pour π(λ) = λ−d, l’estimateur de Bayes correspondant de λ est
ˆλ =
n −d
Pn
i=1 xi + n −1 .
(10.31)
En utilisant ´egalement un coˆut entropique pour l’estimation de λ, L(θ, ˆθ) =
ˆθ −θ −log(ˆθ/θ), l’estimateur bay´esien empirique de θ = (θ1, . . . , θn) est
θEB(x) =
„
1 −
n −d
Pn
i=1 xi + n −1
«
(x + 1) ,
(10.32)
avec 1 = (1, . . . , 1) ∈Rn. Fourdrinier et Robert (1995) montrent en outre qu’il
existe un choix optimal d∗de d pour le coˆut entropique, avec d∗≤2 et que, sur
un intervalle de valeurs donn´e de d, θEB domine ˆθ0 = x + 1.
∥

11
Une d´efense du choix bay´esien
“A series of steps, each taken for good cause or pure necessity, each
seeming so reasonable at the time, and each leading to things he had
never imagined. He always seemed to ﬁnd himself caught in that sort
of dance.”
Robert Jordan, Lord of Chaos.
Ce livre a introduit les aspects les plus importants de l’approche bay´es-
ienne, principalement sous l’angle de la Th´eorie de la D´ecision. Il ne s’agit
´evidemment pas d’une couverture exhaustive : d’une part, un traitement ap-
profondi de la plupart des notions abord´ees ici est possible et d’une certaine
mani`ere souhaitable. D’autre part, il existe un nombre consid´erable d’applica-
tions de l’analyse bay´esienne, et qui va croissant en particulier du fait des nou-
velles possibilit´es oﬀertes par les m´ethodes de calcul pr´esent´ees au Chapitre 6.
Nous pouvons ainsi mentionner les Biostatistiques (voir, par exemple, Berry
et Stangl, 1996); l’´Econom´etrie (Zellner, 1971, 1984, Box et Tiao, 1973, Poi-
rier, 1995, Bauwens et al., 1999, ou Geweke, 1999); l’Environnem´etrie (Parent
et al., 1998); les syst`emes experts (Gilks et al., 1993, Cowell et al., 1999); la Fi-
nance (Jacquier et al., 1994, Pitt et Shephard, 1999); le traitement d’image et
la reconnaissance d’objets (Geman et Geman, 1984, Besag, 1986 ou Fitzgerald
et al., 1999); les r´eseaux de neurones (Ripley, 1992, Neal, 1999), le traitement
du signal (Andrieu et Doucet, 1999, Andrieu et al., 2000); les r´eseaux bay´esiens
(Chickering et Heckerman, 2000, Kontkanen et al., 2000). (On pourra aussi

550
11 Une d´efense du choix bay´esien
consulter la revue par Berger, 2000, ainsi que Gatsonis et al., 1993, 1995,
1997, 1999, Gilks et al., 1996 et Carlin et Louis, 2000a pour des r´ef´erences ad-
ditionnelles.) Des ouvrages consacr´es aux applications de l’analyse bay´esienne
sont aussi disponibles, comme par exemple Pole et al. (1994), Congdon (2001,
2003), Gill (2002) ou Holmes et al. (2002).
Par cons´equent, il nous semble utile, `a ce stade du livre, de replacer l’ana-
lyse bay´esienne dans cette approche th´eorique et d´ecisionnelle plutˆot que de
commencer `a l’illustrer dans quelques applications choisies. Premi`erement, ce
positionnement permet d’appr´ehender la coh´erence de l’analyse bay´esienne, en
soi et par rapport `a d’autres th´eories statistiques. Deuxi`emement, il n’est cer-
tainement pas inutile de bien poss´eder les bases th´eoriques d’une m´ethodologie
pour pouvoir l’appliquer eﬃcacement dans toutes les situations r´eelles. C’est
pourquoi ce dernier chapitre contient une justiﬁcation globale de l’approche
bay´esienne qui r´esume et parfois ´etend les arguments d´evelopp´es jusqu’`a
pr´esent81. Le ton de ce chapitre est donc vaguement philosophique, plutˆot
que m´ethodologique (ou math´ematique), et les lecteurs pourront juger si le
sentiment qu’ils retirent de la lecture de cet ouvrage co¨ıncide avec la perspec-
tive d´efendue ci-apr`es.
(1) Le choix d’une repr´esentation probabiliste
Le fait de proposer une loi sur les param`etres inconnus d’un mod`ele statis-
tique est en quelque sorte une probabilisation de l’incertain. Nous voulons
traduire par ce n´eologisme une r´eduction axiomatique de la notion d’in-
connu `a la notion d’al´eatoire. Cette r´eduction ´etant acceptable–et elle
l’est en g´en´eral pour la quasi-totalit´e des statisticiens–pour les mod`eles
d’´echantillonnage, elle devrait l’ˆetre tout autant pour les param`etres qui
dirigent ces mod`eles. En particulier, la distinction entre ´echantillon et pa-
ram`etres n’est jamais absolue. Il suﬃt par exemple de consid´erer le cas des
mod`eles `a eﬀets al´eatoires (Chapitre 10) ou celui des vecteurs d’allocation
dans un mod`ele de m´elange (Chapitre 6).
Plus fondamentalement, un mod`ele probabiliste n’est souvent qu’une in-
terpr´etation d’un certain ph´enom`ene–et non pas une explication. Si on
prend, par exemple, le cas des mod`eles ´econom´etriques, o`u les diﬀ´erences
entre les r´ealisations des variables endog`enes et leur pr´evision lin´eaire
par rapport aux variables exog`enes sont expliqu´ees par une perturbation
al´eatoire, il est ´evident que la nature al´eatoire de cette diﬀ´erence est de
peu d’importance, ne serait-ce que parce que l’exp´erience ne peut ˆetre
81La pr´esentation de ce chapitre est tr`es diﬀ´erente de celle des chapitres
pr´ec´edents, en ce qu’il ne contient ni th´eor`eme ni exemple, mais simplement une
suite de points (de (1) `a (10)) qui sont des argumentations en faveur de l’approche
bay´esienne. Ces points sont suivis de courtes r´efutations des critiques les plus usuelles
avanc´ees contre l’analyse bay´esienne en Statistique.

11 Une d´efense du choix bay´esien
551
reproduite82. Par cons´equent, la repr´esentation de ph´enom`enes inconnus
par un mod`ele probabiliste, au niveau des observations aussi bien qu’au
niveau des param`etres, n’a pas besoin de correspondre eﬀectivement–ou
physiquement–`a une g´en´eration issue d’une loi de probabilit´e, ni mˆeme de
nous obliger `a accepter un sch´ema superd´eterministe pour les ph´enom`enes
analys´es. Fondamentalement, l’absence de r´ep´etabilit´e de la plupart des
exp´eriences ou collectes de donn´ees vient eﬀacer en grande partie la
fronti`ere entre al´eatoire et non al´eatoire.
En fait, les repr´esentations probabilistes de ph´enom`enes partiellement ex-
pliqu´es devraient surtout ˆetre comprises comme un outil simpliﬁcateur
mais eﬃcace permettant l’analyse de ces ph´enom`enes (voir le point (4)
ci-dessous). Cette perspective est similaire `a la mani`ere dont la Physique
peut aussi ˆetre vue comme une interpr´etation du monde, donc comme un
outil, suﬃsamment eﬃcace pour permettre une meilleur compr´ehension
de l’univers (et, incidemment, la perp´etuation du progr`es technique), sans
qu’on ait `a d´efendre l’existence d’une “v´erit´e” de toute mani`ere inattei-
gnable83.
(2) Conditionner par rapport aux donn´ees
La base de l’inf´erence statistique est fondamentalement un processus
d’inversion, puisqu’elle cherche `a d´eduire les causes des eﬀets, en pre-
nant en compte la nature probabiliste du mod`ele et l’inﬂuence de facteurs
compl`etement al´eatoires (c’est-`a-dire non int´egr´es dans l’analyse). Dans
ses versions discr`etes comme dans ses versions continues, le th´eor`eme de
Bayes formalise cette inversion, comme le fait aussi la notion de vraisem-
blance ℓ(θ|x), qui remplace la densit´e f(x|θ). L’´echec de la Statistique
ﬁduciaire `a fournir un syst`eme inf´erenciel satisfaisant (voir la Note 1.8.1)
peut en fait ˆetre associ´e `a un refus (par cette th´eorie) de poursuivre cette
inversion jusqu’au bout de ses cons´equences logiques et, corr´elativement, `a
une perp´etuation de la confusion entre observations et variables al´eatoires.
D’un point de vue probabiliste, si une analyse quantitative sur les pa-
ram`etres θ est op´er´ee conditionnellement `a x, elle demande n´ecessairement
une distribution sur les param`etres θ, π(θ), pour pouvoir inverser les lois.
Si on int`egre cette contrainte, l’approche bay´esienne est la seule axioma-
tique coh´erente qui respecte la perspective d’inversion des probabilit´es. La
diﬃcult´e pratique de la d´etermination de la loi a priori π n’apparaˆıt pas
au mˆeme niveau conceptuel (voir le point (ii) ci-dessous).
(3) Construire une v´eritable vraisemblance
Continuant l’argumentation des points (1) et (2) ci-dessus, nous pouvons
´egalement faire remarquer qu’une mod´elisation a priori sur les param`etres
82En d’autres termes, un nombre arbitraire peut toujours ˆetre per¸cu comme une
unique r´ealisation d’une inﬁnit´e de distributions !
83Voir aussi Popper (1983) pour sa justiﬁcation alternative de la mod´elisation
scientiﬁque via le r´ealisme m´etaphysique qu’il oppose en fait `a cette approche ins-
trumentale.

552
11 Une d´efense du choix bay´esien
du mod`ele autorise une approche inf´erentielle compl`ete sur ces param`etres,
donc la d´etermination d’une v´eritable vraisemblance de θ conditionnelle-
ment aux observations x. Par comparaison, les approches classiques en
Statistique n’aboutissent pas `a cette compl´etude. En particulier, tant que
θ est pris comme inconnu mais ﬁxe, on ne peut pas donner un sens pro-
babiliste pr´ecis `a la fonction de vraisemblance.
Cette impossibilit´e qu’a l’analyse classique `a conduire `a des conclusions
quantitatives justiﬁ´ees est par exemple illustr´ee par le cas des r´egions de
conﬁance et des tests, puisque cette analyse propose une probl´ematique
inappropri´ee (et donc une r´eponse inappropri´ee). Comme le d´ecrit le Cha-
pitre 5, les proc´edures classiques, que ce soient un intervalle de conﬁance
`a 95% ou une p-value, tirent leur nature probabiliste d’une analyse
fr´equentiste du probl`eme. De leur point de vue, ce n’est plus le param`etre
θ qui appartient `a un intervalle donn´e avec probabilit´e 95% condition-
nellement `a x, mais plutˆot l’intervalle d´eduit de x qui contient la valeur
(ﬁxe mais inconnue) de θ avec probabilit´e 0.95. De nouveau, le manque
de r´ep´etabilit´e de la plupart des exp´eriences invalide fortement ce point
de vue fr´equentiste (voir aussi le point (9) ci-dessous).
(4) Voir les lois a priori comme outils ou r´esum´es
Le choix d’une loi a priori π ne n´ecessite pas un quelconque degr´e de
croyance en cette distribution. Il est en fait plutˆot rare de disposer d’une
loi a priori compl`etement sp´eciﬁ´ee, le cas de la boule de billard de Tho-
mas Bayes ´etant, paradoxalement, un contre-exemple exceptionnel o`u la
construction de l’exp´erience d´etermine la loi a priori. D’un point de vue
plus g´en´eral, π doit ˆetre consid´er´e soit comme un outil qui fournit une
proc´edure inf´erentielle uniﬁcatrice qui poss`ede des propri´et´es fr´equentistes
acceptables (voir les points (6) et (8)), soit comme une mani`ere de r´esumer
l’information a priori disponible ainsi que l’incertitude qui l’entoure. Que
l’analyse bay´esienne puisse s’´etendre `a des contextes non informatifs–avec
quelques diﬃcult´es parfois, comme dans le cas des tests–est en fait la
preuve de cette polyvalence. De plus, que de nombreux estimateurs stan-
dard puissent se repr´esenter via une mod´elisation non informative montre
bien que l’utilisation d’une loi a priori n’implique pas toujours un biais
dans le processus statistique mais, au contraire, qu’elle autorise en sus le
traitement quantitatif mentionn´e au point (3). En fait, ces co¨ıncidences
sont des arguments suppl´ementaires en faveur de la validit´e de l’approche
bay´esienne, puisqu’elle fournit un champ inf´erentiel incluant aussi les es-
timateurs classiques.
(5) Int´egrer les bases subjectives de la connaissance
D’un point de vue plus philosophique, il est globalement accept´e que
la connaissance proc`ede de la confrontation entre ses a priori et des
exp´eriences, voulues ou subies. Par exemple, selon Kant, bien que la
connaissance d´ebute avec l’exp´erimentation, il ne s’ensuit pas que la
connaissance soit enti`erement d´eduite de l’exp´erimentation. En eﬀet, sans

11 Une d´efense du choix bay´esien
553
a priori, ce qui signiﬁe ici, sans une structure pr´e´etablie du monde, l’ob-
servation n’a pas de sens, car elle ne proc`ede plus d’une conﬁrmation ou
d’une confrontation `a un mod`ele de r´ef´erence. Par cons´equent, la construc-
tion de la connaissance par l’exp´erimentation n’est possible que par l’exis-
tence d’un syst`eme de repr´esentation a priori, ´evidemment primitif `a l’ori-
gine, qui se trouve progressivement enrichi et actualis´e au travers de ces
exp´eriences successives. Dans cette perspective, l’apprentissage est per¸cu
comme le r´eexamen critique de syst`emes de r´ef´erence pr´eexistants `a la
lumi`ere d’exp´eriences successives.
Ce point de vue est aussi partag´e par Poincar´e (1902) :
On dit souvent qu’il faut exp´erimenter sans id´ee pr´econ¸cue.
Cela n’est pas possible ; non seulement ce serait rendre toute
exp´erience st´erile, mais on le voudrait qu’on ne le pourrait pas.
Chacun porte en soi sa conception du monde dont il ne peut se
d´efaire si ais´ement.
L’approche bay´esienne est, bien entendu, en concordance avec cette pers-
pective, puisque les distributions a priori sont le plus souvent fond´ees sur
les r´esultats d’exp´eriences ant´erieures. En fait, mˆeme l’aspect subjectif du
choix de la loi a priori peut ˆetre assimil´e par cette th´eorie de la connais-
sance, puisqu’elle implique que chaque acquisition de connaissance est es-
sentiellement subjective, r´esultant d’une interaction entre les perceptions
individuelles et la r´ealit´e ext´erieure84.
Dans sa th´eorie (radicale) de l’´Epist´emologie, Feyerabend (1975) soutient
que l’individualisme (qu’on peut aussi traduire par subjectivit´e) est un
facteur important, mais totalement pass´e sous silence, des d´ecouvertes
scientiﬁques. Bien qu’il s’oppose fortement `a cette vision subjective de la
connaissance, Popper (1983) reconnaˆıt ´egalement le rˆole des intuitions a
priori (qu’il appelle syst`emes), mˆeme si elles ne sont pas toujours fond´ees
sur l’exp´erience, dans l’histoire des Sciences–l’exemple le plus frappant
´etant, de son point de vue, l’atomisme, c’est-`a-dire la repr´esentation de
la mati`ere comme ´etant form´ee d’atomes, th´eorie qui mit plus de vingt
si`ecles avant d’ˆetre v´eriﬁ´ee exp´erimentalement.
(6) Choisir un syst`eme inf´erentiel unique et coh´erent
Le but ultime de la Statistique est, sans conteste, de conduire `a une
inf´erence sur un param`etre θ `a partir d’observations x reli´ees `a θ via
une loi de probabilit´e f(x|θ). De plus, il semble raisonnable de rechercher
l’eﬃcacit´e (voire l’optimalit´e) dans cette d´emarche inf´erentielle, cette no-
tion d’optimalit´e pouvant ˆetre d´eﬁnie explicitement par le statisticien (ou
le d´ecideur). Forcer l’inf´erence `a se couler dans un moule d´ecisionnel par le
84En exag´erant un peu, on pourrait soutenir que la Statistique bay´esienne r´epond
`a ce souhait de Kant, exprim´e dans l’introduction `a sa Critique de la raison pure :
“La Philosophie a besoin d’une science qui d´etermine la possibilit´e, les principes et
l’´etendue de toutes nos connaissances a priori.”

554
11 Une d´efense du choix bay´esien
choix d’une fonction de coˆut conduit `a une clariﬁcation (n´ecessaire) de la
mani`ere dont les outils inf´erentiels sont ´evalu´es, donc force le statisticien
ou le client `a r´ev´eler ses pr´ef´erences. En sus, quand le cadre d´ecisionnel
se trouve compl´et´e par le choix de la loi a priori, les buts et desiderata
inf´erentiels mentionn´es ci-dessus sont automatiquement remplis, puisque
l’approche bay´esienne oﬀre tr`es g´en´eralement une unique proc´edure, qui
d´epend bien sˆur des propri´et´es du coˆut et de la connaissance a priori. Bien
entendu, l’unicit´e d’une proc´edure d´ecisionnelle n’est pas un argument en
soi, puisque de nombreuses m´ethodologies, si insigniﬁantes soient-elles,
peuvent ´egalement poss´eder cette propri´et´e.
Par cons´equent, la plus importante caract´eristique d’une d´emarche bay´e-
sienne est que les estimateurs de Bayes sont construits par un processus
logique : d´emarrant de propri´et´es impos´ees aux proc´edures inf´erentielles,
traduites par la fonction de coˆut et la loi a priori, l’approche bay´esienne
d´eduit la meilleure solution sous ces contraintes. `A l’inverse, les proc´edures
classiques sont construites sans principe g´en´eral, au sens o`u elles partent
d’un estimateur “arbitraire” (estimateur du maximum de vraisemblance,
moindres carr´es, etc.) et ensuite seulement elles examinent ses propri´et´es
fr´equentistes, d’ailleurs pas toujours dans un contexte d´ecisionnel et sans
pr´etendre `a une optimalit´e globale, comme le montre l’eﬀet Stein. Dans
certaines situations, les approches classiques partent aussi d’un crit´ere
pour le choix d’un estimateur (meilleur estimateur sans biais, meilleur es-
timateur ´equivariant, test uniform´ement plus puissant, etc.), mais elles ne
peuvent pas produire une m´ethodologie universellement constructive, c’est
`a dire un algorithme, mˆeme formel, pour l’obtention des estimateurs op-
timaux (voir aussi le point (10)), et il est parfois n´ecessaire de restreindre
plus avant la classe des estimateurs consid´er´es comme, par exemple, dans
le cas des tests uniform´ement plus puissants sans biais.
Cette opposition fondamentale dans les bases logiques des deux th´eories
renforce notre argument de coh´erence de l’approche bay´esienne, puisque
c’est la seule–en consid´erant les meilleurs estimateurs ´equivariants dans un
cadre d’estimation bay´esienne sous la mesure de Haar appropri´ee–`a four-
nir une m´ethodologie universelle et impl´ementable issue des contraintes
inf´erentielles.
(7) Mettre en œuvre le principe de vraisemblance
Le principe de vraisemblance, comme l’a montr´e le Chapitre 1, est fond´e
sur les principes (logiques) de conditionnement et d’exhaustivit´e. Par
cons´equent, il devrait toujours r´egir le choix des proc´edures d’estima-
tion, cr´eant ainsi une propri´et´e d´esirable de plus par rapport `a celles
d´ej`a mentionn´ees au point (6). La th´eorie bay´esienne oﬀre une technique
d’impl´ementation de ce principe, puisqu’elle permet la construction de
d´ecisions compatibles avec ces diverses contraintes.
De plus, bien qu’elle incorpore la th´eorie (partielle) du maximum de vrai-
semblance comme cas particulier (pour π(θ) = 1), l’approche bay´esienne

11 Une d´efense du choix bay´esien
555
peut aussi ´eviter certains paradoxes de vraisemblance comme ceux pr´e-
sent´es dans la Section 4.1, grˆace `a l’utilisation des lois non informatives
de Jeﬀreys, mˆeme s’il faut garder `a l’esprit l’incompatibilit´e de ces lois
avec le principe de vraisemblance. Un avantage suppl´ementaire et non
n´egligeable, par rapport `a la th´eorie du maximum de vraisemblance, est
que l’approche bay´esienne incorpore aussi naturellement les contraintes
impos´ees par une fonction de coˆut et donc agr`eg le principe de vraisem-
blance et la Th´eorie de la D´ecision.
(8) Chercher des proc´edures fr´equentistes optimales
Du point de vue de l’approche fr´equentiste, l’argument majeur en fa-
veur de l’approche bay´esienne est qu’elle s’accorde tr`es fortement avec
les trois notions d’optimalit´e classique que sont la minimaxit´e, l’admis-
sibilit´e et l’´equivariance. Nous avons en eﬀet pu constater dans les Cha-
pitres 2, 8 et 9 que la plupart des estimateurs optimaux suivant l’un de
ces crit`eres sont des estimateurs de Bayes ou des limites d’estimateurs
de Bayes (la notion de limite d´ependant du contexte). Par cons´equent,
non seulement il est possible de produire des estimateurs de Bayes qui
satisfont `a un, `a deux ou `a trois de ces crit`eres d’optimalit´e mais, plus
fondamentalement, les estimateurs de Bayes sont essentiellement les seuls
`a atteindre ce but. Ainsi, un statisticien bay´esien peut ˆetre oppos´e `a toute
intervention subjective dans son traitement inf´erentiel sans pour autant
devoir s’interdire l’utilisation syst´ematique d’estimateurs de Bayes ou de
Bayes g´en´eralis´es, puisque la plupart d’entre eux satisfont ces crit`eres85.
On peut aussi insister sur la d´erivation ais´ee des estimateurs de Bayes,
qui fournit une m´ethode quasi universelle de construction d’estimateurs
optimaux. Dans cette perspective utilitaire, les lois a priori sont bien sˆur
`a consid´erer comme des instruments d’estimation et non plus comme des
r´esum´es exhaustifs de l’information a priori, mais leur forme et leur uti-
lisation a posteriori demeurent bien ´evidemment les mˆemes. L’optimalit´e
des proc´edures bay´esiennes est aussi satisfaite sous l’angle des principaux
crit`eres asymptotiques, puisque, sous les conditions assurant l’eﬃcacit´e de
l’estimateur du maximum de vraisemblance, la plupart des estimateurs de
Bayes sont asymptotiquement eﬃcaces et deviennent ´equivalents `a l’esti-
mateur du maximum de vraisemblance quand la taille de l’´echantillon croˆıt
(voir Lehmann, 1983, et Ibragimov et Has’minskii, 1981), mˆeme si cette
optimalit´e n’a pas ´et´e abord´ee dans cet ouvrage, car elle ne correspond
pas particuli`erement `a notre vision de la Statistique.
(9) R´esoudre le v´eritable probl`eme
Il est aussi n´ecessaire de pouvoir fournir une alternative `a l’approche
fr´equentiste d’un point de vue pratique. En eﬀet, les m´ethodes fr´equentistes
85De ce point de vue, on peut faire remarquer que les pr´etentions fr´equentistes
`a l’objectivit´e (souvent oppos´ee `a la subjectivit´e inh´erente `a l’approche bay´esienne)
sont quelque peu amoindries quand on prend en compte la n´ecessit´e qu’a cette
approche de s´electionner ses estimateurs avant de les comparer !

556
11 Une d´efense du choix bay´esien
sont justiﬁ´ees par un argument de long terme. Par exemple, un intervalle
de conﬁance au niveau 0.95 utilis´e pour des probl`emes ind´ependants aura
un taux de succ`es global proche de 95%, ce qui fournit une ´evaluation
du statisticien. Au contraire, pour un d´ecideur (le “client”), ces pro-
pri´et´es de long terme n’ont pas vraiment d’int´erˆet puisqu’il ou elle est peu
int´eress´e(e) par les performances de long terme de la proc´edure propos´ee
par le statisticien. Ce qui compte est la garantie d’une performance accep-
table pour le probl`eme qui l’occupe ! Par exemple, le fait qu’un m´edicament
soit eﬃcace dans 99% des cas n’est pas un ´el´ement important pour un pa-
tient : il d´esire connaˆıtre ses chances de gu´erison. Une telle demande sur la
validation des proc´edures statistiques implique ´evidemment une structure
qui raisonne conditionnellement `a x, ce qui nous ram`ene n´ecessairement
`a l’approche bay´esienne (voir le point (2)).
Cet argument ne semble pas s’appliquer `a des cadres statistiques impli-
quant des exp´eriences r´ep´et´ees, o`u la d´ecision est prise par le mˆeme in-
dividu `a chaque fois, comme en contrˆole de qualit´e. Il n’empˆeche que ces
situations justiﬁent tout autant une r´esolution bay´esienne, puisqu’elles
sont propices `a une exploitation des informations fournies par les r´esultats
ant´erieurs.
(10) Calculer des estimateurs via un programme d’optimisation
Un dernier point argumentant en faveur du choix bay´esien est que les
proc´edures bay´esiennes sont plus faciles `a calculer que les proc´edures
d’autres th´eories. Une telle assertion peut sembler pour le moins para-
doxale quand on se r´ef`ere aux d´evelopements des Chapitres 6 et 10 et,
par exemple, aux diﬃcult´es rencontr´ees dans le traitement des m´elanges
de distributions ; plus g´en´eralement, nous avons bien vu dans les cha-
pitres pr´ec´edents que les estimateurs de Bayes apparaissent tr`es rare-
ment sous une forme explicite, sauf dans le cas tr`es particulier des lois
conjugu´ees. Cependant, on peut facilement argumenter que l’approche
bay´esienne fournit un programme universel de calcul de ses proc´edures,
quels que soient le coˆut, la loi des observations et la loi a priori, puisque la
solution consiste toujours en la minimisation du coˆut a posteriori, mˆeme
si la r´esolution pratique de cette minimisation demande l’utilisation de
techniques num´eriques ou de Monte Carlo.
Au contraire, l’approche fr´equentiste ne dispose pas d’un algorithme uni-
versel de construction des estimateurs minimax ou admissibles, `a l’excep-
tion peut-ˆetre d’´emuler l’approche bay´esienne par l’utilisation, respecti-
vement, de lois a priori les moins favorables (mais sans indiquer comment
obtenir ces lois les moins favorables!) ou de lois propres86. De mˆeme,
86Bien que les deux approches minimisent un coˆut, la diﬀ´erence majeure entre
elles est que, pour l’approche fr´equentiste, la minimisation s’op`ere sur un espace
fonctionnel–l’espace des estimateurs–tandis que, pour l’approche bay´esienne, elle
est eﬀectu´ee sur l’espace de d´ecision–l’espace des estimations. Les complexit´es res-
pectives de ces deux espaces sont, g´en´eralement, consid´erablement diﬀ´erentes.

11 Une d´efense du choix bay´esien
557
la seule technique g´en´erique de construction des meilleurs estimateurs
´equivariants repose sur la connexion avec les mesures de Haar et leur
repr´esentation bay´esienne, comme nous l’avons d´emontr´e au Chapitre 9.
On peut argumenter que les estimateurs du maximum de vraisemblance
reposent ´egalement sur un programme g´en´eral d’optimisation. Mais il
faut prendre en compte la nature intrins`equement limit´ee de l’approche
vraisembliste, qui ne propose pas une couverture compl`ete du champ
inf´erentiel. De plus, les estimateurs de Bayes autorisent des repr´esentations
int´egrales sous les coˆuts usuels, tandis que les estimateurs du maximum de
vraisemblance n’existent pas toujours. C’est par exemple le cas pour les
m´elanges normaux, o`u la fonction de vraisemblance n’est pas born´ee, ou
pour les distributions o`u il existe plusieurs maxima globaux de la fonction
de vraisemblance.
Par ailleurs, d’un pur point de vue pratique, il est certain que le calcul
eﬀectif des estimateurs de Bayes est souvent plus d´elicat, car il implique
`a la fois la r´esolution d’un programme de minimisation et des int´egrations
multiples. Bien que ce soit certainement un probl`eme v´eritable pour le
praticien, il faut cependant relativiser en prenant en compte l’existence de
techniques (et de logiciels) g´en´eriques, comme par exemple les m´ethodes
MCMC et winBUGS. En fait, la “r´evolution bay´esienne” des ann´ees 1990
que repr´esente le d´eveloppement simultan´e et symbiotique de nouvelles
techniques de calcul et de nouveaux champs d’application de l’analyse
bay´esienne en est la preuve.
Pour d’autres perspectives sur les avantages d’une approche bay´esienne,
on pourra se reporter aux ouvrages indiqu´es dans les chapitres pr´ec´edents,
en particulier Jeﬀreys (1961), Lindley (1971), Berger (1985b, Section 4.1 et
Section 4.12), Berger et Wolpert (1988), Bernardo et Smith (1994), Carlin et
Louis (2000a), O’Hagan et Forster (2002) et Gelman et al. (2003).
Les critiques de l’approche bay´esienne sont nombreuses et nous ne voulons
pas en dresser une liste exhaustive, d’autant qu’elles ´echouent `a exhiber des
incoh´erences fondamentales dans cette approche (les estimateurs de Bayes
non convergents mentionn´es dans la Note 1.8.4 rel`event plus d’un ph´enom`ene
exotique que d’une diﬃcult´e intrins`eque). Par cons´equent, nous consid´erons
seulement trois questions usuelles sur les lois a priori, puisqu’elles constituent
g´en´eralement l’aspect le plus critiqu´e de l’approche bay´esienne.
(i) Le passage de l’information a priori, qui peut ˆetre vague ou mal sp´eciﬁ´ee,
`a la loi a priori n’est pas expliqu´e par les axiomes bay´esiens.
Une r´eponse partielle, bien que superﬁcielle, est que la mˆeme critique s’ap-
plique aux distributions d’´echantillonnage, qui sont presque toujours sup-
pos´ees connues. Dans de nombreux cas, et pour la plupart des approches,
la mod´elisation a toujours une inﬂuence d´ecisive sur l’analyse r´esultante,
mais elle ne peut pas ˆetre formalis´ee au mˆeme degr´e que la m´ethodologie

558
11 Une d´efense du choix bay´esien
qui en r´esulte. La diversit´e des sources d’information, les diﬀ´erents degr´es
de pr´ecision de cette information et l’´evaluation des cons´equences de la
s´election de la loi a priori font que la mod´elisation demeure plus un art
qu’une science. De plus, comme nous l’avons vu dans la Note 3.8.1, des
axiomes de coh´erence sur l’ordonnancement des probabilit´es (ou des vrai-
semblances) a priori justiﬁent en partie l’existence d’une loi a priori, mˆeme
si c’est g´en´eralement sur une σ-alg`ebre moins ﬁne que d´esir´e.
D’un point de vue pragmatique, la construction d’une loi a priori d´epend
de la capacit´e des individus `a pouvoir repr´esenter leurs connaissances et
leurs incertitudes au travers d’une distribution de probabilit´e. Que les
d´ecideurs ne soient pas en mesure de le faire `a pr´esent ne signiﬁe pas
qu’ils ou elles ne peuvent pas acqu´erir cette capacit´e, `a condition qu’ils
ou elles puissent ˆetre form´e(e)s dans ce but. L’´education a permis `a la
quasi-totalit´e des individus des pays d´evelopp´es de traiter et de manipu-
ler des quantit´es num´eriques. Elle peut de mˆeme les former `a manipuler
l’incertain. (Voir aussi Smith, 1988.)
Un autre argument qui m´erite d’ˆetre mentionn´e est que l’analyse bay´esien-
ne fournit ´egalement des outils permettant de faire face aux impr´ecisions
sur la loi a priori, via les approches hi´erarchique et robuste. La ca-
ract´eristique importante de la composante arbitraire dans le choix d’une
loi a priori est l’inﬂuence de l’information a priori sur l’inf´erence a pos-
teriori. Si diﬀ´erentes mod´elisations conduisent `a des inf´erences similaires,
l’arbitraire n’a que peu d’importance. Si, au contraire, des divergences
apparaissent, elles signalent que la construction de la loi a priori doit ˆetre
mieux fond´ee et que ses aspects les plus fragiles doivent ˆetre ´evalu´es via
une analyse de sensibilit´e, sans pour autant rejeter l’information a priori
disponible. Cette d´ecomposition des facteurs inﬂuant sur l’inf´erence nous
semble en fait constituer un avantage de l’analyse bay´esienne (voir aussi
ci-dessous).
(ii) La subjectivit´e n’est qu’un pr´etexte `a d´eviances et manipulations de toutes
sortes, comme par exemple le choix de la r´eponse d´esir´ee a priori.
De nouveau, il est possible d’adresser exactement la mˆeme critique `a la
plupart des m´ethodologies alternatives, par exemple `a propos du choix de
la fonction de coˆut ou de la classe d’estimateurs ´etudi´es. Une illustration
due `a Brown (1980) est que, pour toute dimension p0, il existe une fonction
de coˆut telle que l’eﬀet Stein ne se produit que lorsque la dimension du
probl`eme est sup´erieure `a p0 (voir la Note 2.8.2).
Cette mise au point ´etant faite, la critique est aussi justiﬁ´ee envers l’ana-
lyse bay´esienne, au sens o`u l’introduction d’un facteur additionnel dans le
processus inf´erentiel peut toujours ˆetre d´etourn´ee de son but originel. Une
illustration imm´ediate est l’emploi de masses de Dirac comme lois a priori !
Mais il existe ´evidemment des strat´egies beaucoup plus discr`etes pour
produire une inf´erence “`a la commande”... C’est h´elas une cons´equence
in´evitable des capacit´es d’inclusion (de l’information a priori) et d’adapta-

11 Une d´efense du choix bay´esien
559
tion qu’oﬀre l’approche bay´esienne. Bien entendu, dans les fondements de
cette approche existe un pr´esuppos´e implicite d’honnˆetet´e du statisticien
ou de l’exp´erimentateur qui est que le choix de la loi a priori doit pou-
voir se justiﬁer (ou se falsiﬁer en langage popp´erien), au sens o`u le ou la
statisticien(ne) ou l’exp´erimentateur(trice) est responsable du passage de
l’information dont il ou elle dispose vers la loi a priori–mˆeme si cette jus-
tiﬁcation accepte les arguments de recherche de simplicit´e ou d’intuition
personnelle, jusqu’`a un certain niveau.
Insister sur la possibilit´e d’une v´eriﬁcation des sources de la mod´elisation
n’est pas sans rappeler l’imp´eratif de r´ep´etabilit´e des exp´eriences dans
les disciplines exp´erimentales, mais cette contrainte est curieusement ab-
sente dans d’autres m´ethodologies statistiques, ce qui signale l’ambigu¨ıt´e
inh´erente au choix d’une proc´edure d’estimation, comme par exemple l’op-
position entre estimateur du maximum de vraisemblance et estimateur
des moindres carr´es. On peut ici d´efendre la th`ese oppos´ee que l’approche
bay´esienne est `a un certain point plus objective que les autres m´ethodes
inf´erentielles parce que, d’une part, elle identiﬁe et s´epare clairement les
diﬀ´erentes sources d’apport subjectif dans le processus inf´erentiel (distri-
bution d’´echantillonnage, loi a priori, fonction de coˆut), ce qui permet par
la suite de faire d’´eventuelles modiﬁcations sur ces facteurs. D’autre part,
elle d´eveloppe des outils objectifs d’analyse d’inﬂuence (lois non informa-
tives, analyse de sensibilit´e, etc.). De ce point de vue, Poincar´e (1902)
fournit un argument suppl´ementaire dans la suite de la citation du point
(5) :
Chacun porte en soi sa conception du monde dont il ne peut
se d´efaire si ais´ement. Il faut bien, par exemple, que nous nous
servions du langage, et notre langage n’est p´etri que d’id´ees pr´e-
con¸cues et ne peut l’ˆetre d’autre chose. Seulement ce sont des
id´ees pr´econ¸cues inconscientes, mille fois plus dangereuses que
les autres. Dirons-nous que si nous en faisons intervenir d’autres,
dont nous aurions pleine conscience, nous ne ferons qu’aggraver
le mal ! Je ne le crois pas ; j’estime plutˆot qu’elles se serviront mu-
tuellement de contrepoids, j’allais dire d’antidote. [...] C’est assez
pour nous aﬀranchir ; on n’est plus esclave quand on peut choisir
son maˆıtre.
mˆeme si le tout dernier argument de cette citation est plus que discu-
table ! Le principe des r`egles d’arrˆet illustre cette objectivit´e, au sens o`u
la d´ecision bay´esienne est ind´ependante du crit`ere d’arrˆet, donc n’est pas
inﬂuenc´ee par les motivations subjectives qui ont conduit `a cet ´echantillon.
Encore une fois, si on se place dans une perspective fr´equentiste, les choix
des distributions d’´echantillonnage et des fonctions de coˆut sont aussi des
facteurs d´eterminants qu’on passe souvent sous silence (Good, 1973).

560
11 Une d´efense du choix bay´esien
(iii) Dans un contexte int´egralement non informatif, l’utilisation de lois pr´e-
tendues non informatives n’a aucune justiﬁcation et ne sert que comme
argument `a une extension factice du champ bay´esien.
Bien entendu, nous ne voyons pas de contradiction intrins`eque `a vou-
loir ´etendre le champ bay´esien mais, plus fondamentalement, il nous
semble que les contextes totalement non informatifs ne sont pas l´egions et
qu’il existe toujours des indications a priori `a exploiter, `a moins que les
conditions de l’exp´erience n’exigent un traitement non informatif ou de
r´ef´erence. On peut noter que les points (2), (3), (4) et (6) ci-dessus four-
nissent des r´eponses partielles `a cette critique. En eﬀet, dans un contexte
non informatif, la loi a priori ne peut pas correspondre `a une traduction
de l’information a priori mais elle peut cependant ˆetre comprise comme
outil d’inf´erence eﬃcace87. Vu sous cet angle, les m´ethodes bay´esiennes
non informatives ne sont ni plus ni moins arbitraires que les m´ethodes par
maximum de vraisemblance, puisque toutes sont issues de la loi des ob-
servations, qui repr´esente la seule information a priori disponible. Si une
fonction de coˆut est aussi fournie par le d´ecideur ou le contexte, elle donne
une information suppl´ementaire dont l’approche bay´esienne peut faire bon
usage, au contraire de la m´ethode du maximum de vraisemblance. Enﬁn,
comme ces approches non informatives fournissent la plupart des estima-
teurs usuels, elles ne peuvent ˆetre rejet´ees uniquement parce qu’elles sont
bay´esiennes! Au contraire, d’un point de vue strictement bay´esien, on ar-
gumenterait que les bonnes performances de ces estimateurs d´ecoulent de
leur caract`ere bay´esien (Jaynes, 1980).
Dans les points pr´ec´edents, nous avons ´egalement insist´e sur la n´ecessit´e
de conditionner en l’observation x. Ce conditionnement implique stricto
sensu l’existence d’une mod´elisation probabiliste sur θ, donc une loi a
priori, puisque l’approche par maximum de vraisemblance ne peut pas
fournir une inf´erence statistique compl`ete et ne fonctionne que tr`es rare-
ment comme distribution “objective” sur θ.
La technique de d´etermination de lois non informatives due `a Jeﬀreys
n’est donc qu’une technique qui prend en compte l’information pr´esente
dans le mod`ele (ce qui signiﬁe dans ce cas l’information apport´ee par
les x sur θ), tout en conservant le riche ´eventail des outils bay´esiens, en
restant compatible avec les contraintes intuitives comme l’invariance et
en incluant la plupart des proc´edures usuelles. La n´ecessit´e d’une telle
approche apparaˆıt clairement en th´eorie des tests, o`u la perspective de
Neyman-Pearson est d´eﬁciente `a de nombreux points de vue88.
87Cette critique sur les lois non informatives proc`ede d’un argument qui rejette
l’utilisation de l’information a priori, sauf lorsque celle-ci n’est pas disponible !
88La diﬃcult´e de traiter des hypoth`eses ponctuelles par des lois impropres,
abord´ee dans les Chapitres 5 et 7, est r´eelle et ne doit pas ˆetre sous-estim´ee. La
diversit´e de r´eponses possibles pr´esent´ee par exemple au Chapitre 7 est cependant
rassurante.

11 Une d´efense du choix bay´esien
561
Bien que le traitement des param`etres de nuisance conduise `a des diﬃ-
cult´es techniques (comme par exemple les paradoxes de marginalisation
de la Section 3.5), la g´en´eralisation par les lois de r´ef´erence propos´ee par
Bernardo (1979) fournit une solution partielle `a cette diﬃcult´e. Un autre
probl`eme mentionn´e dans ce livre est celui de l’estimation des mod`eles
de m´elange, vue au Chapitre 6, qui est fondamentalement li´e au manque
d’identiﬁabilit´e de ces mod`eles. Il admet n´eanmoins une r´esolution non
informative via un changement de param`etres (Robert et Titterington,
1998).
Un point positif de ces critiques est qu’elles soulignent l’importance de
construire rigoureusement la loi a priori dans l’analyse bay´esienne. Elles
poussent ´egalement `a des ´etudes plus avanc´ees sur les techniques non infor-
matives, comme par exemple l’exploitation de l’information contenue dans la
fonction de coˆut ou la coh´erence des suites de lois utilis´ees dans la comparaison
de mod`eles imbriqu´es. Elles signalent en sus le besoin de voir se d´evelopper
des techniques “automatiques” (ou semi-automatiques) de d´etermination des
lois a priori aﬁn de permettre une utilisation plus universelle des m´ethodes
bay´esiennes en Statistique appliqu´ee. Des logiciels bay´esiens sont d`es `a pr´esent
disponibles (voir la Note 6.6.2, et Berger, 2000). En symbiose avec les
m´ethodes num´eriques d’approximation pr´esent´ees au Chapitre 6, ces tech-
niques devraient favoriser la diﬀusion de la m´ethodologie bay´esienne dans de
nombreuses communaut´es. La croissance exponentielle des applications bay-
´esiennes dans les dix derni`eres ann´ees est un signal fort que cette diﬀusion est
en cours (voir Berger, 2000).
Pour achever cette conclusion, notons enﬁn que le caract`ere antagoniste
des approches bay´esiennes et non bay´esiennes est parfois d´emesur´ement am-
pliﬁ´e. Pour un observateur ext´erieur non statisticien, et en particulier pour les
´etudiant(e)s, la querelle entre classiques et bay´esiens n’est pas compr´ehensible
et donne l’image d’une discipline peu ﬁable puisque les experts n’arrivent
pas `a y d´eﬁnir un standard unique ! Par ailleurs, l’utilisation toujours crois-
sante de techniques de traitement de donn´ees par des non statisticiens a ten-
dance `a eﬀacer les motivations philosophiques et les fronti`eres th´eoriques
entre m´ethodes pour se consacrer `a leur applicabilit´e. (On peut regret-
ter cette prise de pouvoir mais elle a d´ej`a eu lieu !) D’un point de vue
th´eorique, les r´ecents d´eveloppements de la Th´eorie de la D´ecision (pa-
ram´etrique et non param´etrique) ont renforc´e les fondations bay´esiennes des
notions classiques d’optimalit´e (voir (6)), tandis que l’´etat de l’art en robus-
tesse bay´esienne cherche `a r´eduire les probl`emes de mauvais choix de la loi a
priori en prenant en compte des crit`eres fr´equentistes (comme la minimaxit´e
ou la minimaxit´e bay´esienne ´etudi´ee dans Kempthorne, 1988). Par ailleurs,
des chercheurs ´eminents des deux communaut´es sont engag´es dans la produc-
tion d’un contexte d´ecisionnel qui donnerait des proc´edures acceptables par
les deux ´ecoles, comme nous le d´ecrivons dans la Note 5.7.4. En pratique,
les approximations fr´equentistes sont aussi bien souvent n´ecessaires lorsque la

562
11 Une d´efense du choix bay´esien
construction de la loi a priori est d´elicate, par exemple lorsque l’information
de Fisher n’existe pas sous forme explicite ou quand la dimension de l’espace
des param`etres est trop grande.
Le choix de l’approche bay´esienne peut donc ˆetre fond´e sur la r´econciliation
de la plupart des proc´edures classiques avec une analyse bay´esienne ou
bay´esienne g´en´eralis´ee, sur l’attrait ind´eniable de sa compl´etude et de sa
coh´erence globale, et aussi sur sa capacit´e `a ´elargir le champ des inf´erences
possibles, sans avoir besoin de rejeter toutes les proc´edures classiques. L’ap-
proche bay´esienne nous semble tout simplement plus en harmonie avec ce que
doit ˆetre l’inf´erence statistique, tout en ´etant plus attrayante intellectuelle-
ment.

A
Distributions de probabilit´e
Nous donnons dans cet appendice quelques rappels sur les distributions
les plus couramment utilis´ees dans ce livre, au travers de leur densit´e et des
deux premiers moments. Une revue quasi exhaustive des distributions usuelles
est fournie par les livres de Johnson et Kotz (1972), Johnson et al. (1994),
Johnson et al. (1995) et Johnson et Hoeting (2003). `A chaque fois, les densit´es
sont donn´ees par rapport `a la mesure de Lebesgue ou `a la mesure de comptage,
suivant le contexte (variable r´eelle ou enti`ere).
A.1. Loi normale, Np(θ, Σ)
(θ ∈Rp et Σ est une matrice sym´etrique (p × p) d´eﬁnie positive)
f(x|θ, Σ) = (det Σ)−1/2(2π)−p/2e−(x−θ)tΣ−1(x−θ)/2
Eθ,Σ[X] = θ et Eθ,Σ[(X −θ)(X −θ)t] = Σ. Quand Σ n’est pas d´eﬁnie
positive, la loi Np(θ, Σ) n’a pas de densit´e par rapport `a la mesure de
Lebesgue sur Rp. Pour p = 1, la loi log-normale est d´eﬁnie comme la loi
de exp X quand X ∼N (θ, σ2).
A.2. Loi gamma, G a(α, β)
(α, β > 0)
f(x|α, β) =
βα
Γ(α)xα−1e−βxI[0,+∞)(x)
Eα,β[X] = α/β et varα,β(X) = α/β2. Des cas particuliers de la loi gamma
sont les lois d’Erlang, G a(α, 1), exponentielle G a(1, β) (not´ee E xp(β)) et
la loi du khi deux, G a(ν/2, 1/2) (not´ee χ2
ν). (Remarquons que la conven-
tion inverse est parfois adopt´ee pour le second param`etre, donc que la loi
G a(α, β) peut parfois ˆetre donn´ee comme G a(α, 1/β). Voir, par exemple,
Berger, 1985b, qui la d´eﬁnit ainsi pour pouvoir utiliser une loi gamma
comme loi conjugu´ee.)

564
A Distributions de probabilit´e
A.3. Loi bˆeta, Be(α, β)
(α, β > 0)
f(x|α, β) = xα−1(1 −x)β−1
B(α, β)
I[0,1](x)
o`u
B(α, β) = Γ(α)Γ(β)
Γ(α + β) .
Eα,β[X] = α/(α + β) et varα,β(X) = αβ/[(α + β)2(α + β + 1)]. La loi
bˆeta s’obtient comme la loi de Y1/(Y1 + Y2) quand Y1 ∼G a(α, 1) et
Y2 ∼G a(β, 1).
A.4. Loi de Student, Tp(ν, θ, Σ)
(ν > 0, θ ∈Rp, et Σ est une matrice sym´etrique a (p×p) d´eﬁnie positive.)
f(x|ν, θ, Σ) = Γ((ν + p)/2)/Γ(ν/2)
(det Σ)1/2(νπ)p/2

1 + (x −θ)tΣ−1(x −θ)
ν
−(ν+p)/2
Eν,θ,Σ[X] = θ (ν > 1) et Eθ,Σ[(X −θ)(X −θ)t] = νΣ/(ν −2) (ν > 2).
Quand p = 1, un cas particulier de la loi de Student est la loi de Cauchy,
C (θ, σ2), qui correspond `a ν = 1. La loi de Student Tp(ν, 0, I) s’obtient
comme loi de X/Z lorsque X ∼Np(0, I) et νZ2 ∼χ2
ν. (On l’appelle aussi,
pour des raisons historiques, la loi du t de Student.)
A.5. Loi de Fisher, F(ν, ϱ)
(ν, ϱ > 0)
f(x|ν, ϱ) = Γ((ν + ϱ)/2)νϱ/2ϱν/2
Γ(ν/2)Γ(ϱ/2)
x(ν−2)/2
(ν + ϱx)(ν+ϱ)/2 I[0,+∞)(x)
Eν,ϱ[X] = ϱ/(ϱ−2) (ϱ > 2) et varν,ϱ(X) = 2ϱ2(ν+ϱ−2)/[ν(ϱ−4)(ϱ−2)2]
(ϱ > 4).
La loi F(p, q) est aussi la loi de (X −θ)tΣ−1(X −θ)/p lorsque X ∼
Tp(q, θ, Σ). De plus, si X ∼F(ν, ϱ), νX/(ϱ + νX) ∼Be(ν/2, ϱ/2). (On
l’appelle aussi, toujours pour des raisons historiques, la loi du F de Fisher.)
A.6. Loi gamma inverse, I G (α, β)
(α, β > 0)
f(x|α, β) =
βα
Γ(α)
e−β/x
xα+1 I[0,+∞[(x)
Eα,β[X] = β/(α−1) (α > 1) et varα,β(X) = β2/((α−1)2(α−2)) (α > 2).
Cette loi est celle de X−1 lorsque X ∼G a(α, β). Elle apparaˆıt naturelle-
ment dans l’analyse bay´esienne des lois gamma et normale.

A Distributions de probabilit´e
565
A.7. Loi du khi deux d´ecentr´e, χ2
ν(λ)
(λ ≥0)
f(x|λ) = 1
2(x/λ)(p−2)/4I(p−2)/2(
√
λx)e−(λ+x)/2
Eλ[X] = p + λ et varλ(X) = 3p + 4λ. Cette loi est celle de X2
1 + · · · + X2
p
lorsque Xi ∼N (θi, 1) et θ2
1 + . . . + θ2
p = λ.
A.8. Loi de Dirichlet, Dk(α1, . . . , αk)
(α1, . . . , αk > 0 et α0 = α1 + · · · + αk)
f(x|α1, . . . , αk) =
Γ(α0)
Γ(α1) . . . Γ(αk)xα1−1
1
. . . xαk−1
k
I{P xi=1}
Eα[Xi] = αi/α0, var(Xi) = (α0 −αi)αi/[α2
0(α0 + 1)] et cov(Xi, Xj) =
−αiαj/[α2
0(α0 + 1)] (i ̸= j). Comme cas particulier, notons que (X, 1 −
X) ∼D2(α1, α2) est ´equivalent `a X ∼Be(α1, α2).
A.9. Loi de Pareto, Pa(α, x0)
(α > 0 et x0 > 0)
f(x|α, x0) = α xα
0
xα+1 I[x0,+∞[(x)
Eα,x0[X] = αx0/(α −1) (α > 1) et varα,x0(X) = αx2
0/[(α −1)2(α −2)]
(α > 2).
A.10. Loi binomiale, B(n, p)
(0 ≤p ≤1)
f(x|p) =
n
x

px(1 −p)n−xI{0,...,n}(x)
Ep(X) = np et var(X) = np(1 −p).
A.11. Loi multinomiale, Mk(n; p1, . . . , pk)
(pi ≥0 (1 ≤i ≤k) et 
i pi = 1)
f(x1, . . . , xk|p1, . . . , pk) =

n
x1 . . . xk

k

i=1
pxi
i IP xi=n
Ep(Xi) = npi, var(Xi) = npi(1 −pi), et cov(Xi, Xj) = −npipj (i ̸= j).
Notons que, si, X ∼Mk(n; p1, . . . , pk), alors Xi ∼B(n, pi), et aussi que
la loi X ∼B(n, p) correspond `a (X, n −X) ∼M2(n; p, 1 −p). Cette loi
est celle du tirage ind´ependant avec remise.
A.12. Loi de Poisson, P(λ)
(λ > 0)
f(x|λ) = e−λ λx
x! IN(x)
Eλ[X] = λ et varλ(X) = λ.

566
A Distributions de probabilit´e
A.13. Loi binomiale n´egative, N eg(n, p)
(0 ≤p ≤1)
f(x|p) =
n + x + 1
x

pn(1 −p)xIN(x)
Ep[X] = n(1 −p)/p et varp(X) = n(1 −p)/p2.
A.14. Loi hyperg´eom´etrique, H yp(N; n; p)
(0 ≤p ≤1, n < N et pN ∈N)
f(x|p) =
	pn
x

	(1−p)N
n−x

	N
n

I{n−(1−p)N,...,pN}(x)I{0,1,...,n}(x)
EN,n,p[X] = np et varN,n,p(X) = (N −n)np(1 −p)/(N −1). Cette loi est
celle du tirage sans remise.

B
Notations
math´ematiques
A ≺B
(B −A) est une matrice d´eﬁnie positive
|A|, det(A)
d´eterminant de la matrice A
a+
max (a, 0)
Cp
n,
	n
p

coeﬃcient binomial
Dα
fonction logistique
Δf(z)
laplacien de f(z)
1F1(a; b; z)
fonction conﬂuente hyperg´eom´etrique
F −
inverse g´en´eralis´ee de F
f(t) ∝g(t)
les fonctions f et g sont proportionnelles
Γ(a)
fonction gamma (a > 0)
h = (h1, . . . , hn) = {hi} un caract`ere gras repr´esente un vecteur
H = {hij} = ||hij||
une majuscule repr´esente une matrice
I, 1, J = 11′
matrice identit´e, vecteur identit´e, matrice unitaire
IA(t)
fonction indicatrice (1 si t ∈A, 0 sinon)
Iν(z)
fonction de Bessel modiﬁ´ee (z > 0)
λmax(A)
plus grande valeur propre de la matrice A
	
n
n1...nk

coeﬃcient multinomial
∇f(z)
gradient de f(z), soit le vecteur de terme
g´en´erique (∂/∂zi)f(z) (f(z) ∈R et z ∈Rp)
∇tf(z)
divergence de f(z), (∂/∂zi)f(z)
(f(z) ∈Rp et z ∈R)
|| · ||T V
norme de la variation totale
Ψ(x)
fonction digamma (x > 0)
Σ ⊗Ψ
produit tensoriel des matrices Σ et Ψ
supp(f)
support de f
tr(A)
trace de la matrice A
|x| = (Σx2
i )1/2
norme euclidienne
⌊x⌋
partie enti`ere de x, le plus grand entier inf´erieur `a x

568
B Notations
⌈x⌉
plus petit entier plus grand que x
x ∨y
maximum de x et y
x ∧y
minimum de x et y
< x, y >
produit scalaire de x et y dans Rp
probabilistes
X, Y
variable al´eatoire (majuscule)
(X, P, B)
triplet probabiliste : espace des variables, loi, et σ-alg`ebre
βn
coeﬃcient de β-m´elangeance
δθ0(θ)
masse de Dirac en θ0
E (θ)
fonction ´energie d’une distribution de Gibbs
E(π)
entropie de la loi π
Eθ[g(X)]
esp´erance de g(x) pour la loi f(x|θ) sur X
EV [h(V )]
esp´erance de h(v) pour la loi de V
Eπ[h(θ)|x]
esp´erance de h(θ) pour la loi de θ conditionnellement `a x, π(θ|x)
F(x|θ)
fonction de r´epartition de X, conditionnellement au param`etre θ
f(x|θ)
densit´e de x indic´ee par le param`etre θ par rapport
`a la mesure de Lebesgue ou `a la mesure de comptage
iid
ind´ependant et identiquement distribu´e (pour un ´echantillon)
λ(dx)
mesure de Lebesgue (encore not´ee dλ(x))
Pθ
distribution de probabilit´e index´ee par le param`etre θ
ϕ(t)
densit´e de la loi normale N (0, 1)
Φ(t)
fonction de r´epartition de la loi normale N (0, 1)
f(x|θ)
Pθ
loi de probabilit´e, index´ee par le param`etre θ
p ⋆q
produit de convolution des lois p et q,
soit loi de la somme de X ∼p et de Y ∼q
pn⋆
n-i`eme produit de convolution,
soit, loi de la somme de n variables iid de loi p
ϕ(t)
densit´e de la loi normale N (0, 1)
Φ(t)
fonction de r´epartition de la loi normale N (0, 1)
O(n), o(n)
grand “O”, petit “o”. Quand n →∞, O(n)
n
→constante,
ou Op(n), op(n)
o(n)
n
→0, et l’indice p signiﬁe en probabilit´e
Xt, X(t)
´el´ement g´en´erique d’une chaˆıne de Markov
x ∼f(x|θ)
x est distribu´ee suivant la loi de densit´e
de distributions
B(n, p)
loi binomiale
Be(α, β)
loi bˆeta
C (θ, σ2)
loi de Cauchy
Dk(α1, . . . , αk)
loi de Dirichlet

B Notations
569
E xp(λ)
loi exponentielle
F(p, q)
loi de Fisher
G a(α, β)
loi gamma
I G (α, β)
loi inverse gamma
I N (α, μ)
loi normale inverse
χ2
p
loi du khi deux centr´ee
χ2
p(λ)
loi du khi deux non centr´ee
Mk(n; p1, .., pk)
loi multinomiale
N (θ, σ2)
loi normale unidimensionnelle
Np(θ, Σ)
loi normale multidimensionnelle
N eg(n, p)
loi binomiale n´egative
P(λ)
loi de Poisson
P(x0, α)
loi de Pareto
Tp(ν, θ, Σ)
loi de Student multidimensionnelle
U[a,b], U ([a, b])
loi uniforme (continue)
W e(α, c)
loi de Weibull
Wk(p, Σ)
loi de Wishart
d´ecisionnelles
D
espace des d´ecisions
G
groupe agissant sur X
¯g
´el´ement de ¯
G associ´e `a g ∈G
¯
G
groupe induit par G agissant sur Θ
˜g
´el´ement de ˜
G associ´e `a g ∈G
˜
G
groupe induit par G agissant sur D
L(θ, δ)
fonction de coˆut de δ en θ
M0, Mk
mod`eles consid´er´es
R(θ, δ)
risque fr´equentiste de δ en θ
r(π, δ)
risque de Bayes de δ pour la loi a priori π
ϱ(π, δ|x)
risque a posteriori de δ pour la loi a priori π
Θ
espace des param`etres
X
espace des observations
statistiques
AR(p)
processus autor´egressif d’ordre p
ARMA(p, q)
processus autor´egressif `a moyenne mobile d’ordre (p, q)
Bπ(x)
facteur de Bayes
BA
12(x), BG
12, BM
12
pseudo-facteur de Bayes
B
borne inf´erieure sur un facteur de Bayes
Cα
r´egion de conﬁance (ou cr´edible)
δJS(x)
estimateur de James-Stein

570
B Notations
δπ(x)
estimateur de Bayes
δ+(x)
estimateur de James-Stein tronqu´e
δ⋆(x)
estimateur randomis´e
H0
hypoth`ese nulle
H1, Ha
hypoth`ese alternative
I(θ)
information de Fisher
L(θ, δ)
fonction de coˆut de δ en θ
ℓ(θ|x)
vraisemblance, en tant que fonction de θ,
identique `a f(x|θ)
ℓP (θ|x)
vraisemblance proﬁl´ee
m(x)
loi marginale
MA(q)
processus `a moyenne mobile d’ordre q
P≻
domination au sens de Pitman
π(θ)
loi a priori g´en´erique sur θ
πJ(θ)
loi a priori de Jeﬀreys sur θ
π(θ|x)
loi a posteriori g´en´erique sur θ
s2
somme des carr´es des ´ecarts `a la moyenne empirique
θ, λ
param`etres (lettres grecques minuscules)
Θ
espace des param`etres (lettres grecques majuscules)
¯x
moyenne empirique
x∗, y∗
donn´ees latentes ou manquantes

R´ef´erences
Abraham, C. (2001). Asymptotic limit of the Bayes actions set derived from
a class of loss functions. J. Multiv. Analysis, 79(2), 251–274.
Abraham, C. et Daur´es, J. (2000). Global robustness with respect to the loss
function and the prior. Theory and Decision, 48(4), 359–381.
Abramovich, F., Spatinas, T., et Silverman, B. (1998). Wavelet thresholding
via a Bayesian approach. J. Royal Statist. Soc. Series B, 60, 725–749.
Abramowitz, M. et Stegun, I. (1964). Handbook of Mathematical Functions.
Dover, New York.
Adams, M. (1987). William Ockham. University of Notre Dame Press, Notre
Dame, Indiana.
Aitkin, M. (1991). Posterior Bayes factors (with discussion). J. Royal Sta-
tist. Soc. Series B, 53, 111–142.
Akaike, H. (1978). A new look at the Bayes procedure. Biometrika, 65, 53–59.
Akaike, H. (1983). Information measure and model selection. Bull. Int. Statist.
Inst., 50, 277–290.
Alam, K. (1973). A family of admissible minimax estimators of the mean of
a multivariate normal distribution. Ann. Statist., 1, 517–525.
Albert, J. (1988). Computational methods using a Bayesian hierarchical ge-
neralized linear model. J. American Statist. Assoc., 83, 1037–1044.
Anderson, T. (1984).
An Introduction to Multivariate Statistical Analysis.
John Wiley, New York, seconde ´edition.
Andrieu, C. et Doucet, A. (1999). Joint Bayesian detection and estimation
of noisy sinusoids via reversible jump MCMC. IEEE Trans. Signal Proc.,
47(10), 2667–2676.
Andrieu, C., Doucet, A., et Fitzgerald, W. (2000). On Monte Carlo methods
for Bayesian data analysis. In Mees, A. et R.L., S., ´editeurs, Nonlinear
Dynamics and Statistics. Birkhauser, Boston.
Angers, J. (1987). Development of robust Bayes estimators for a multivariate
normal mean. PhD thesis, Purdue University, West Lafayette, Indiana.

572
R´ef´erences
Angers, J. (1992). Use of the Student’s t-prior for the estimation of normal
means : A computational approach. In Bernardo, J., Berger, J., Dawid,
A., et Smith, A., ´editeurs, In Bayesian Statistics, volume 4, pages 567–575.
Oxford University Press, Oxford.
Angers, J. et MacGibbon, K. (1990). Hierarchical Bayes estimation in linear
models with robustness against partial prior misspeciﬁcation.
Technical
Report 69, D´ept. de Math´ematiques et d’Informatique, Universit´e de Sher-
brooke.
Arrow, K. (1956). Social Choice and Individual Values. John Wiley, New
York.
Bar-Lev, S., Enis, P., et Letac, G. (1994). Models which admit a given expo-
nential family as an a priori conjugate model. Ann. Statist., 22(3), 1555–
1586.
Baranchick, A. (1970).
A family of minimax estimators of the mean of a
multivariate normal distribution. Ann. Mathemat. Statist., 41, 642–645.
Barbieri, M., Liseo, B., et Petrella, L. (1999). Bayes factor at work in a chal-
lenging class of problems. In Racugno, W., ´editeur, Model Choice Collana
Atti di Congressi, pages 109–132. Pitagora Editrice, Bologna.
Barnard, G. (1949).
Statistical inference (with discussion).
J. Royal Sta-
tist. Soc. Series B, 11, 115–159.
Barnett, G., Kohn, R., et Sheather, S. (1996).
Bayesian estimation of an
autoregressive model using Markov chain Monte Carlo. J. Econometrics,
74, 237–254.
Barron, A. (1988).
The exponential convergence of posterior probabilities
with implication for Bayes estimators of density functions. Technical report,
Dept. of Statistics, University of Illinois.
Barron, A. (1998).
Information-theoretic characterization of Bayes perfor-
mances and the choice of priors in parametric and nonparametric problems
(with discussion). In Bernardo, J., Berger, J., Dawid, A., et Smith, A.,
´editeurs, Bayesian Statistics, volume 6, pages 27–52. Oxford University
Press, Oxford.
Barron, A., Schervish, M., et Wasserman, L. (1999). The consistency of poste-
rior distributions in nonparametric problems. Ann. Statist., 27(2), 536–561.
Bartlett, M. (1937). Properties of suﬃciency and statistical tests. Proc. Roy.
Soc. London, 130, 268–282.
Basu, D. (1988). Statistical Information and Likelihood. Springer-Verlag, New
York.
Baum, L. et Petrie, T. (1966). Statistical inference for probabilistic functions
of ﬁnite state Markov chains. Ann. Mathemat. Statist., 37, 1554–1563.
Bauwens, L. (1984). Bayesian Full Information of Simultaneous Equations
Models Using Integration by Monte Carlo, volume 232 dans Lecture Notes
in Economics and Mathematical Systems. Springer-Verlag, New York.
Bauwens, L. (1991). The “pathology” of the natural conjugate prior density
in the regression model. Ann. Econom. Statist., 23, 49–64.

R´ef´erences
573
Bauwens, L., Lubrano, M., et Richard, J. (1999). Bayesian inference in dyna-
mic econometric models. In Granger, C. et Mizon, G., ´editeurs, Advanced
Texts in Econometrics. Oxford University Press, Oxford.
Bayarri, M. et DeGroot, M. (1988). Gaining weight : a Bayesian approach.
In Bernardo, J., DeGroot, M., D., L., et A.F.M., S., ´editeurs, Bayesian
Statistics, volume 3, pages 25–44. Oxford University Press, Oxford.
Bayes, T. (1763).
An essay towards solving a problem in the doctrine of
chances. Phil. Trans. Roy. Soc., 53, 370–418.
Bechofer, R. (1954). A single-sample multiple decision procedure for ranking
means of normal populations with known variance. Ann. Mathemat. Sta-
tist., 25, 16–39.
Bensmail, H., Celeux, G., Raftery, A., et Robert, C. (1997).
Inference in
model-based cluster analysis. Statist. Comp., 7(1), 1–10.
Beran, R. (1996). Stein estimation in high dimension : A retrospective. In
Research Developments in Probability and Statistics : Madan L. Puri Fest-
schrift, pages 91–110. Universiteit Utrecht.
Berg´e, P., Pommeau, Y., et Vidal, C. (1984). Order Within Chaos.
John
Wiley, New York.
Berger, J. (1975a). Admissibility results for generalized Bayes estimators of a
location vector. Ann. Statist., 4, 334–356.
Berger, J. (1975b). Minimax estimation of location vectors for a wide class of
densities. Ann. Statist., 3, 1318–1328.
Berger, J. (1980a). Improving on inadmissible estimators in continuous ex-
ponential families with applications to simultaneous estimation of gamma
scale parameters. Ann. Statist., 8, 545–571.
Berger, J. (1980b).
A robust generalized Bayes estimator and conﬁdence
region for a multivariate normal mean. Ann. Statist., 8, 716–761.
Berger, J. (1982a). Estimation in continuous exponential families : Bayesian
estimation subject to risk restrictions and inadmissibility results. In Gupta,
S. et Berger, J., ´editeurs, Statistical Decision Theory and Related Topics,
volume 3, pages 109–142. Academic Press, New York.
Berger, J. (1982b). Selecting a minimax estimator of a multivariate normal
mean. Ann. Statist., 10, 81–92.
Berger, J. (1984). The robust Bayesian viewpoint (with discussion). In Ka-
dane, J., ´editeur, Robustness of Bayesian Analysis. North-Holland, Amster-
dam.
Berger, J. (1985a). Discussion of ‘quantifying prior opinion’ by Diaconis and
Ylvisaker. In Bernardo, J., DeGroot, M., Lindley, D., et Smith, A., ´editeurs,
Bayesian Statistics, volume 3, Amsterdam. North-Holland.
Berger, J. (1985b).
Statistical Decision Theory and Bayesian Analysis.
Springer-Verlag, New York, second ´edition.
Berger, J. (1990). Robust Bayesian analysis : sensitivity to the prior. J. Sta-
tist. Plann. Inference, 25, 303–328.
Berger, J. (2000). Bayesian analysis : A look at today and thoughts of tomor-
row. J. American Statist. Assoc., 95, 1269–1277.

574
R´ef´erences
Berger, J. et Berliner, L. (1986). Robust Bayes and empirical Bayes analysis
with ε-contamined priors. Ann. Statist., 14, 461–486.
Berger, J. et Bernardo, J. (1989). Estimating a product of means : Bayesian
analysis with reference priors. J. American Statist. Assoc., 84, 200–207.
Berger, J. et Bernardo, J. (1992a). On the development of the reference prior
method.
In Bernardo, J., Berger, J., Dawid, A., Lindley, D., et Smith,
A., ´editeurs, Bayesian Statistics 4, pages 35–60, London. Oxford University
Press.
Berger, J. et Bernardo, J. (1992b). Ordered group reference priors with ap-
plication to the multinomial problem. Biometrika, 79, 25–37.
Berger, J. et Bock, M. (1976). Eliminating singularities of Stein-type estima-
tors of location vectors. J. Royal Statist. Soc. Series B, 39, 166–170.
Berger, J., Boukai, B., et Wang, Y. (1997). Uniﬁed frequentist and Bayesian
testing of a precise hypothesis (with discussion). Statistical Science, 12,
133–160.
Berger, J., Brown, L., et Wolpert, R. (1994). A uniﬁed conditional frequentist
and Bayesian test for ﬁxed and sequential hypothesis testing. Ann. Statist.,
22, 1787–1807.
Berger, J. et Deely, J. (1988). A Bayesian approach to ranking and selection
of related means with alternatives to ANOVA methodology. J. American
Statist. Assoc., 83, 364–373.
Berger, J. et Delampady, M. (1987). Testing precise hypotheses (with discus-
sion). Statist. Science, 2, 317–352.
Berger, J. et Mortera, J. (1991). Interpreting the stars in precise hypothesis
testing. International Statistical Review, 59, 337–353.
Berger, J. et Pericchi, L. (1996a). The intrinsic Bayes factor for linear model.
In Bernardo, J., Berger, J., Dawid, A., Lindley, D., et Smith, A., ´editeurs,
Bayesian Statistics 5, pages 23–42, Oxford. Oxford University Press.
Berger, J. et Pericchi, L. (1996b). The intrinsic Bayes factor for model selec-
tion and prediction. J. American Statist. Assoc., 91, 109–122.
Berger, J. et Pericchi, L. (1998). Accurate and stable Bayesian model selec-
tion : the median intrinsic Bayes factor. Sankhya B, 60, 1–18.
Berger, J. et Pericchi, L. (2001). Objective Bayesian methods for model selec-
tion : introduction and comparison. In Lahiri, P., ´editeur, Model Selection,
volume 38 dans Lecture Notes – Monograph Series, pages 135–207, Beach-
wood Ohio. Institute of Mathematical Statistics.
Berger, J., Philippe, A., et Robert, C. (1998). Estimation of quadratic func-
tions : reference priors for non-centrality parameters. Statistica Sinica, 8(2),
359–375.
Berger, J. et Robert, C. (1990). Subjective hierarchical Bayes estimation of a
multivariate normal mean : on the frequentist interface. Ann. Statist., 18,
617–651.
Berger, J. et Sellke, T. (1987). Testing a point-null hypothesis : the irrecon-
cilability of signiﬁcance levels and evidence (with discussion). J. American
Statist. Assoc., 82, 112–122.

R´ef´erences
575
Berger, J. et Srinivasan, C. (1978). Generalized Bayes estimators in multiva-
riate problems. Ann. Statist., 6, 783–801.
Berger, J. et Wolpert, R. (1988). The Likelihood Principle, volume 9 dans
IMS Lecture Notes–Monograph Series. IMS, Hayward California, second
´edition.
Berger, J. et Yang, R. (1994). Noninformative priors and Bayesian testing for
the AR(1) model. Econometric Theory, 10, 461–482.
Bergman, N., Doucet, A., et Gordon, N. (2001).
Optimal estimation
and Cram´er-Rao bounds for partial non-Gaussian state-space models.
Ann. Inst. Statist. Math., 52(1), 97–112.
Bernardo, J. (1979). Reference posterior distributions for Bayesian inference
(with discussion). J. Royal Statist. Soc. Series B, 41, 113–147.
Bernardo, J. (1980). A Bayesian analysis of classical hypothesis testing. In
Bernardo, J., DeGroot, M. H., Lindley, D. V., et Smith, A., ´editeurs, Baye-
sian Statistics. Oxford University Press.
Bernardo, J. et Smith, A. (1994). Bayesian Theory. John Wiley, New York.
Berry, D. et Stangl, D. (1996). Bayesian Biostatistics. Marcel Dekker, New
York.
Bertrand, J. (1889). Calcul des Probabilit´es. Gauthier-Villars, Paris.
Besag, J. (1974).
Spatial interaction and the statistical analysis of lattice
systems (with discussion). J. Royal Statist. Soc. Series B, 36, 192–326.
Besag, J. (1986). On the statistical analysis of dirty pictures. J. Royal Sta-
tist. Soc. Series B, 48, 259–302.
Besag, J. (2000). Markov chain Monte Carlo for statistical inference. Technical
Report 9, University of Washington, Center for Statistics and the Social
Sciences.
Besag, J. et Green, P. (1993). Spatial statistics and Bayesian computation
(with discussion). J. Royal Statist. Soc. Series B, 55, 25–38.
Best, N., Cowles, M., et Vines, K. (1995). CODA : Convergence diagnosis and
output analysis software for Gibbs sampling output, version 0.30. Technical
report, MRC Biostatistics Unit, University of Cambridge.
Bhattacharya, R. et Rao, R. (1986). Normal approximations and asymptotic
expansions. John Wiley, New York, seconde ´edition.
Bickel, P. (1981). Minimax estimation of the mean of a normal distribution
when the parameter space is restricted. Ann. Statist., 9, 1301–1309.
Bickel, P. et Ghosh, J. (1990). A decomposition for the likelihood ratio statistic
and the Bartlett correction : a Bayesian argument. Ann. Statist., 18, 1070–
1090.
Billingsley, P. (1985). Probability and Measure. John Wiley, New York, seconde
´edition.
Billingsley, P. (1995). Probability and Measure. John Wiley, New York, third
´edition.
Billio, M., Monfort, A., et Robert, C. (1998). The simulated likelihood ratio
method. Technical Report 9821, CREST, INSEE, Paris.

576
R´ef´erences
Billio, M., Monfort, A., et Robert, C. (1999). Bayesian estimation of switching
ARMA models. J. Econometrics, 93, 229–255.
Bilodeau, M. (1988). On the simultaneous estimation of scale parameters.
Canad. J. Statist., 14, 169–174.
Binder, D. (1978). Bayesian cluster analysis (with discussion). Biometrika,
65, 31–38.
Birnbaum, A. (1962). On the foundations of statistical inference (with dis-
cussion). J. American Statist. Assoc., 57, 269–326.
Bjørnstad, J. (1990). Predictive likelihood : a review.
Statist. Science, 5,
242–265.
Blackwell, D. et Girshick, M. (1954). Theory of Games and Statistical Deci-
sions. John Wiley, New York.
Blattberg, R. et George, E. (1991). Shrinkage estimation of price and promo-
tion elasticities : seemingly unrelated equations. J. American Statist. As-
soc., 86, 304–315.
Blyth, C. (1951). On minimax statistical decisions procedures and their ad-
missibility. Ann. Mathemat. Statist., 22, 22–42.
Blyth, C. (1972a). Discussion of Robert, Hwang and Strawderman. J. Ame-
rican Statist. Assoc., 88, 72–74.
Blyth, C. (1972b). Some probability paradoxes in choice from among random
alternatives (with discussion). J. American Statist. Assoc., 67, 366–387.
Blyth, C. et Pathak, P. (1985). Does an estimator distribution suﬃce ? In
Cam, L. L. et Olshen, A., ´editeurs, Proc. Berkeley Conf. in Honor of J.
Neyman and J. Kiefer, volume 1. Wadsworth, Belmont, California.
Blyth, C.R.and Hutchinson, D. (1961). Tables of Neyman-shortest conﬁdence
interval for the binomial parameter. Biometrika, 47, 381–391.
Bock, M. (1985). Minimax estimators that shift towards a hypersphere for
location of spherically symmetric distributions. J. Multiv. Analysis, 9, 579–
588.
Bock, M. (1988). Shrinkage estimators : pseudo-Bayes rules for normal vectors.
In Gupta, S. et Berger, J., ´editeurs, Statistical Decision Theory and Related
Topics, volume 4, pages 281–297. Springer-Verlag, New York.
Bock, M. et Robert, C. (1985). Bayes estimators with respect to uniform
distributions on spheres (i) : the empirical Bayes approach. Unpublished
notes.
Bohning, D. (1999). Computer-Assisted Analysis of Mixtures and Applica-
tions. Chapman and Hall, New York.
Bondar, J. (1987). How much improvement can a shrinkage estimator give. In
McNeill, I. et Umphreys, G., ´editeurs, Foundations of Statistical Inference.
Reidel, Dordrecht.
Bondar, J. et Milnes, P. (1981). Amenability : a survey for statistical appli-
cations of Hunt-Stein and related conditions on groups. Z. Wahrsch. verw.
Gebiete, 57, 103–128.
Boole, G. (1854). A Investigation of the Laws of Thought. Walton and Ma-
berly, London.

R´ef´erences
577
Bose, S. (1992). Some properties of posterior Pitman closeness. Comm. Sta-
tist., 20, 3697–3412.
Box, G. et Jenkins, G. (1976). Time Series Analysis : Forecasting and Control.
Holden-Bay, San Francisco.
Box, G. et Muller, M. (1958). A note on the generation of random normal
variates. Ann. Mathemat. Statist., 29, 610–611.
Box, G. et Tiao, G. (1973).
Bayesian Inference in Statistical Analysis.
Addison-Wesley, Reading, Massachusetts.
Brandwein, A. et Strawderman, W. (1980).
Minimax estimators of loca-
tion parameters for spherically symmetric distributions with concave loss.
Ann. Statist., 8, 279–284.
Brandwein, A. et Strawderman, W. (1990). Stein estimation : the spherically
symmetric case. Statist. Science, 5, 356–569.
Brandwein, A., Strawderman, W., et Ralescu, S. (1992).
Stein estimation
for non-normal spherically symmetric location families in three dimensions.
J. Multiv. Analysis, 42, 35–50.
Brewster, J. et Zidek, J. (1974).
Improving on equivariant estimators.
Ann. Statist., 2, 21–38.
Brockwell, P. et Davis, P. (1998). Introduction to Time Series and Forecasting.
Springer Texts in Statistics. Springer-Verlag, New York.
Broniatowski, M., Celeux, G., et Diebolt, J. (1983).
Reconnaissance de
m´elanges de densit´es par un algorithme d’apprentissage probabiliste. In
Diday, E., ´editeur, Data Analysis and Informatics. North-Holland, Amster-
dam.
Brown, L. (1966). On the admissibility of invariant estimators of one or more
location parameters. Ann. Mathemat. Statist., 37, 1087–1136.
Brown, L. (1967). The conditional level of Student’s t-test.
Ann. Mathe-
mat. Statist., 38, 1068–1071.
Brown, L. (1971). Admissible estimators, recurrent diﬀusions, and insoluble
boundary-value problems. Ann. Mathemat. Statist., 42, 855–903.
Brown, L. (1975).
Estimation with incompletely speciﬁed loss functions.
J. American Statist. Assoc., 70, 417–426.
Brown, L. (1976).
Notes on statistical decision theory.
Technical report,
Ithaca, New York.
Brown, L. (1978). A contribution to Kiefer’s theory of conditional conﬁdence
procedures. Ann. Statist., 6, 59–71.
Brown, L. (1980). Examples of Berger’s phenomenon in the estimation of
independent normal means. Ann. Statist., 9, 1289–1300.
Brown, L. (1981).
A complete class theorem for statistical problems with
ﬁnite sample spaces. Ann. Statist., 9, 1289–1300.
Brown, L. (1986a). An ancilarity paradox which appears in multiple linear
regression (with discussion). Ann. Statist., 18, 471–538.
Brown, L. (1986b). Foundations of Exponential Families, volume 6 dans IMS
lecture notes Monograph Series. Hayward California.

578
R´ef´erences
Brown, L. (1988). The diﬀerential inequality of a statistical estimation pro-
blem. In Gupta, S. et Berger, J., ´editeurs, Statistical Decision Theory and
Related Topics, volume 4. Springer-Verlag, New York.
Brown, L. (1993).
Minimaxity, more or less.
In Gupta, S. et Berger, J.,
´editeurs, Statistical Decision Theory and Related Topics, volume 5, pages
1–18. Springer-Verlag, New York.
Brown, L. (2000). An essay on statistical decision theory. J. American Sta-
tist. Assoc., 95, 1277–1282.
Brown, L. et Farrell, R. (1985). Complete class theorems for estimation of
multivariate Poisson means and related problems. Ann. Statist., 8, 377–398.
Brown, L. et Hwang, J. (1982).
A uniﬁed admissibility proof.
In Gupta,
S. et Berger, J., ´editeurs, Statistical Decision Theory and Related Topics,
volume 3, pages 205–230. Academic Press, New York.
Brown, L. et Hwang, J. (1989). Universal domination and stochastic domina-
tion : U-admissibility and u-inadmissibility of the least-squares estimator.
Ann. Mathemat. Statist., 17, 252–267.
Buehler, R. (1959). Some validity criteria for statistical inference. Ann. Sta-
tist., 30, 845–863.
Capp´e, O., Guillin, A., Marin, J., et Robert, C. (2004). Population Monte
Carlo. J. Comput. Graph. Statist., 13(4), 907–929.
Capp´e, O., Moulines, E., et Ryd´en, T. (2005). Inference in Hidden Markov
Models. Springer-Verlag, New York.
Capp´e, O. et Robert, C. (2000). MCMC : Ten years and still running ! J. Ame-
rican Statist. Assoc., 95(4), 1282–1286.
Capp´e, O., Robert, C., et Ryd´en, T. (2003).
Reversible jump, birth-and-
death, and more general continuous time MCMC samplers. J. Royal Sta-
tist. Soc. Series B, 65(3), 679–700.
Carlin, B. et Chib, S. (1995). Bayesian model choice through Markov chain
Monte Carlo. J. Roy. Statist. Soc. (Ser. B), 57(3), 473–484.
Carlin, B. et Gelfand, A. (1991). A sample reuse method for accurate para-
metric empirical Bayes conﬁdence intervals. J. Royal Statist. Soc. Series B,
53, 189–200.
Carlin, B. et Louis, T. (2000a). Bayes and Empirical Bayes Methods for Data
Analysis. Chapman and Hall, New York.
Carlin, B. et Louis, T. (2000b). Empirical Bayes : Past, present and future.
J. American Statist. Assoc., 95, 1286–1290.
Carlin, B. et Louis, T. (2001). Bayes and Empirical Bayes Methods for Data
Analysis. Chapman and Hall, New York, seconde ´edition.
Caron, N. (1994).
Approches alternatives d’une th´eorie non-informative
des tests bay´esiens.
Th`ese de doctorat, Universit´e de Rouen, D´ept. de
Math´ematique.
Carota, C., Parmigiani, G., et Polson, N. (1996). Diagnostic measures for
model criticism. J. American Statist. Assoc., 91, 753–762.
Carter, G. et Rolph, J. (1974). Empirical Bayes methods applied to estimating
ﬁre alarm probabilities. J. American Statist. Assoc., 69, 882–885.

R´ef´erences
579
Casella, G. (1980). Minimax ridge regression estimation. Ann. Statist., 8,
1036–1056.
Casella, G. (1985a). Condition number and minimax ridge regression estima-
tion. J. American Statist. Assoc., 80, 753–758.
Casella, G. (1985b). An introduction to empirical Bayes data analysis. The
American Statistician, 39, 83–87.
Casella, G. (1987).
Conditionally acceptable recentered set estimators.
Ann. Statist., 15, 1364–1371.
Casella, G. (1990). Estimators with nondecreasing risks : application of a
chi-squared identity. Statist. Prob. Lett., 10, 107–109.
Casella, G. (1992). Conditional inference for conﬁdence sets. In Ghosh, M.
et Pathak, P., ´editeurs, Current Issues in Statistical Inference : Essays in
Honor of D. Basu, volume 17 dans IMS lectures notes Monograph Series,
pages 1–12. Hayward, California.
Casella, G. (1996). Statistical theory and Monte Carlo algorithms (with dis-
cussion). TEST, 5, 249–344.
Casella, G. et Berger, R. (1987). Reconciling Bayesian and frequentist evidence
in the one-sided testing problem. J. American Statist. Assoc., 82, 106–111.
Casella, G. et Berger, R. (2001). Statistical Inference. Wadsworth, Belmont,
CA, seconde ´edition.
Casella, G. et George, E. (1992).
An introduction to Gibbs sampling.
Ann. Mathemat. Statist., 46, 167–174.
Casella, G. et Hwang, J. (1983).
Empirical Bayes conﬁdence sets for the
mean of a multivariate normal distribution. J. American Statist. Assoc.,
78, 688–698.
Casella, G. et Hwang, J. (1987). Employing vague prior information in the
construction of conﬁdence sets. J. Multiv. Analysis, 21, 79–104.
Casella, G., Hwang, J., et Robert, C. (1993a). Loss function for set estimation,
pages 237–252. Springer-Verlag, New York.
Casella, G., Hwang, J., et Robert, C. (1993b). A paradox in decision-theoretic
set estimation. Statist. Sinica, 3, 141–155.
Casella, G., Robert, C., et Wells, M. (2000). Mixture models, latent variables
and partitioned importance sampling. Technical Report 2000-03, CREST,
INSEE, Paris.
Casella, G. et Strawderman, W. (1981). Estimating a bounded normal mean.
Ann. Statist., 4, 283–300.
Casella, G. et Wells, M. (1993). Discussion of Robert, Hwang and Strawder-
man. J. American Statist. Assoc., 88, 70–71.
Castledine, B. (1981). A Bayesian analysis of multiple-recapture sampling for
a closed population. Biometrika, 67, 197–210.
Castro, I., Conigliani, C., et O’Hagan, A. (1999).
Bayesian assessment of
goodness of ﬁt against nonparametric alternatives (with discussion).
In
Racugno, W., ´editeur, Model Selection, Collana Atti di Congressi. Pitagora
Editrice, Bologna.

580
R´ef´erences
Celeux, G. et Diebolt, J. (1990). Une version de type recuit simul´e de l’algo-
rithme EM. Comptes Rendus Acad. Sciences Paris, 310, 119–124.
Celeux, G., Forbes, F., Robert, C., et Titterington, D. (2005). Deviance cri-
teria in missing data models. Bayesian Analysis. (To appear.).
Celeux, G., Hurn, M., et Robert, C. (2000). Computational and inferential
diﬃculties with mixture posterior distribution. J. American Statist. Assoc.,
95(3), 957–979.
Cellier, D., Fourdrinier, D., et Robert, C. (1989). Robust shrinkage estimators
of the location parameter for elliptically symmetric distributions. J. Multiv.
Analysis, 29, 39–52.
Chamberlain, G. (2000). Econometrics. Springer-Verlag, New York.
Chen, M. et Shao, Q. (1997). On Monte Carlo methods for estimating ratios
of normalizing constants. Ann. Statist., 25, 1563–1594.
Chen, M., Shao, Q., et Ibrahim, J. (2000). Monte Carlo Methods in Bayesian
Computation. Springer-Verlag, New York.
Chernoﬀ, H. et Yahav, J. (1977). A subset selection employing a new criterion.
In Gupta, S. et Moore, D., ´editeurs, Statistical Decision Theory and Related
Topics. Academic Press, New York, New York.
Chib, S. (1995). Marginal likelihood from the Gibbs output. J. American
Statist. Assoc., 90, 1313–1321.
Chib, S. et Greenberg, E. (1994). Bayes inference in regression models with
ARMAi (p, q) errors. J. Econometrics, 64, 183–206.
Chickering, D. et Heckerman, D. (2000). A comparison of scientiﬁc and engi-
neering criteria forBayesian model selection. Statist. Comp., 10, 55–62.
Chow, M. (1987). A complete class theorem for estimating a non-centrality
parameter. Ann. Statist., 15, 869–876.
Chow, M. et Hwang, J. (1990). The comparison of estimators for the non-
centrality of a chi-square distribution. Technical report, Cornell University,
Dept. of Mathematics, New York.
Chow, Y. et Teicher, H. (1988). Probability Theory. Springer-Verlag, New
York.
Chrystal, G. (1891). On some fundamental principles in the theory of proba-
bility. Trans. Actuarial Soc. Edinburgh, 2, 421–439.
Clarke, B. et Wasserman, L. (1993).
Noninformative priors and nuisance
parameters. J. American Statist. Assoc., 88, 1427–1432.
Clevenson, M. et Zidek, J. (1975). Simultaneous estimation of the mean of
independant Poisson laws. J. American Statist. Assoc., 70, 698–705.
Clyde, M. (1999).
Bayesian model averaging and model search strategies.
In Bernardo, J., Dawid, A., Berger, J., et Smith, A., ´editeurs, Bayesian
Statistics, volume 6, pages 157–185. Oxford University Press, Oxford.
Cohen, A. (1972). Improved conﬁdence intervals for the variance of a normal
distribution. J. American Statist. Assoc., 67, 382–387.
Cohen, A. et Sackrowitz, H. (1984). Decision theoretic results for vector risks
with applications. Statist. Decisions, Supplement Issue, 1, 159–176.

R´ef´erences
581
Cohen, A. et Strawderman, W. (1973). Admissible conﬁdence intervals and
point estimators for translation or scale parameters. Ann. Statist., 1, 545–
550.
Congdon, P. (2001). Bayesian Statistical Modelling. John Wiley, New York.
Congdon, P. (2003). Applied Bayesian Modelling. John Wiley, New York.
Cowell, R., Dawid, A., Lauritzen, S., et Spiegelhalter, D. (1999). Probabilistic
Networks and Expert Systems. Springer-Verlag, New York.
Cox, D. R. (1958).
Some problems connected with statistical inference.
Ann. Statist., 29, 357–425.
Cox, D. R. (1990). Role of models in statistical analysis. Statist. Science, 5,
169–174.
Cox, D. R. et Hinkley, D. (1987). Theoretical Statistics. Chapman and Hall,
New York.
Cox, D. R. et Reid, N. (1987). Orthogonal parameters and approximate condi-
tional inference (with discussion). J. Royal Statist. Soc. Series B, 49, 1–18.
Crawford, S., DeGroot, M., Kadane, J., et Small, M. (1992). Modelling lake-
chemistry distributions : Approximate Bayesian methods for estimating a
ﬁnite-mixture model. Technometrics, 34, 441–453.
Cressie, N. (1993). Spatial Statistics. John Wiley, New York.
Dacunha-Castelle, D. et Gassiat, E. (1999). Testing the order of a model using
locally conic parametrization : population mixtures and stationary ARMA
processes. Ann. Statist., 27, 1178–1209.
Dalal, S. et Hall (1983). Approximating priors by mixtures of natural conju-
gate priors. J. Royal Statist. Soc. Series B, 45, 278–286.
Dale, A. (1991). A History of Inverse Probability. Springer-Verlag, New York.
Damien, P., Wakeﬁeld, J., et Walker, S. (1999). Gibbs sampling for Bayesian
non-conjugate and hierarchical models by using auxiliary variables. J. Royal
Statist. Soc. Series B, 61(2), 331–344.
Darroch, J. (1958). The multiple-recapture census. I : Estimation of a closed
population. Biometrika, 45, 343–359.
Das Gupta, A. (1958).
Admissibility in the Gamma distribution : two
examples. Sankhya, Ser. A, 46, 395–407.
Das Gupta, A. et Sinha, B. (1986). Estimation in the multiparameter expo-
nential family : admissibility and inadmissibility results. Statist. Decisions,
4, 101–130.
Das Gupta, A. et Studden, W. (1988). Frequentist behavior of smallest volume
robust Bayes conﬁdence sets. Technical Report Technical Report 94-20,
Purdue University, West Lafayette, Indiana.
Datta, G. et Ghosh, M. (1995a). On priors providing frequentist validity for
Bayesian inference. Biometrika, 82, 37–45.
Datta, G. et Ghosh, M. (1995b). Some remarks on noninformative priors.
J. American Statist. Assoc., 90, 1357–1363.
Dawid, A. (1984). Probability forecasts. Technical report, University College,
London.

582
R´ef´erences
Dawid, A. (1992). Frequential analysis, stochastic complexity and Bayesian
inference. In Berger, J., Bernardo, J., Dawid, A., et Smith, A., ´editeurs,
Bayesian Statistics 4, volume 4. Oxford University Press, Oxford.
Dawid, A. (2002). Discussion of “Bayesian measures of model complexity and
ﬁt” by Spiegelhalter et al. J. Royal Statist. Soc. Series B, 64, 583–640.
Dawid, A. et Lauritzen, S. (1993). Hyper Markov laws in the statistical ana-
lysis of decomposable graphical models. Ann. Statist., 21, 1272–1317.
Dawid, A., Stone, N., et Zidek, J. (1973). Marginalization paradoxes in Baye-
sian and structural inference (with discussion). J. Royal Statist. Soc. Series
B, 35, 189–233.
de Finetti, B. (1972). Probability, Induction and Statistics. John Wiley, New
York.
de Finetti, B. (1974). Theory of Probability, volume 1. John Wiley, New York.
Deely, J. et Gupta, S. (1968). On the property of subset selection per order.
Sankhya, Ser. A, 30, 37–50.
Deely, J. et Lindley, D. (1981). Bayes empirical Bayes. J. American Sta-
tist. Assoc., 76, 833–841.
DeGroot, M. (1970). Optimal Statistical Decisions. McGraw-Hill, New York.
DeGroot, M. (1973). Doing what comes naturally : Interpreting a tail area as
a posterior probability or as a likelihood ratio. J. American Statist. Assoc.,
68, 966–969.
DeGroot, M. et Fienberg, S. (1983). The comparison and evaluation of fore-
casters. The Statistician, 32, 12–22.
Delampady, M. (1989). Lower bounds on Bayes factors for invariant testing
situations. J. Multiv. Analysis, 28, 227–246.
Dellaportas, P. et Forster, J. (1996). Markov chain Monte Carlo model deter-
mination for hierarchical and graphical log-linear models. Technical report,
Univ. of Southampton.
Dempster, A. (1968). A generalization of Bayesian inference (with discussion).
J. Royal Statist. Soc. Series B, 30, 205–248.
Dempster, A., Laird, N., et Rubin, D. (1977).
Maximum likelihood from
incomplete data via the EM algorithm (with discussion).
J. Royal Sta-
tist. Soc. Series B, 39, 1–38.
der Meulen B., V. (1992). Assessing weights of evidence for discussing classical
statistical hypotheses. PhD thesis, University of Groningen.
DeRobertis, L. et Hartigan, J. (1981). Bayesian inference using intervals of
measures. Ann. Statist., 9, 235–244.
Dette, H. et Studden, W. (1997). The Theory of Canonical Moments with
Applications in Statistics, Probability and Analysis. John Wiley, New York.
Devroye, L. (1985).
Non-Uniform Random Variate Generation.
Springer-
Verlag, New York.
Devroye, L. et Gy¨orﬁ, L. (1985). Nonparametric Density Estimation : the L1
View. John Wiley, New York.

R´ef´erences
583
Dey, D., M¨uller, P., et Sinha, D. (1998). Practical Nonparametrics and Se-
miparametrics in Bayesian Statistical Inference, volume 133 dans Lecture
Notes in Statistics. Springer-Verlag, New York.
Diaconis, P. et Freedman, D. (1986). On the consistency of Bayes estimates.
Ann. Statist., 14, 1–26.
Diaconis, P. et Kemperman, J. (1996). Some new tools for Dirichlet priors
(with discussion). In Bernardo, J., Berger, J., Dawid, A., Lindley, D., et
Smith, A., ´editeurs, Bayesian Statistics 5, pages 97–106. Oxford University
Press, Oxford.
Diaconis, P. et Mosteller, F. (1989).
Methods for studying coincidences.
J. American Statist. Assoc., 84, 853–861.
Diaconis, P. et Ylvisaker, D. (1979). Conjugate priors for exponential families.
Ann. Statist., 7, 269–281.
Diaconis, P. et Ylvisaker, D. (1985). Quantifying prior opinion. In Bernardo,
J., DeGroot, M., Lindley, D., et Smith, A., ´editeurs, Bayesian Statistics 2,
pages 163–175. North-Holland, Amsterdam.
Diaconis, P. et Zabell, S. (1991). Closed form summation for classical distri-
bution variations on a theme of De Moivre. Statist. Science, 6, 284–302.
DiCiccio, T. J. et Stern, S. (1993). On Bartlett adjustments for approximate
Bayesian inference. Biometrika, 80, 731–740.
DiCiccio, T. J. et Stern, S. (1994). Frequentist and Bayesian Bartlett cor-
rection of test statistics based on adjusted proﬁle likelihoods.
J. Royal
Statist. Soc. Series B, 56, 397–408.
Dickey, J. (1968). Three multidimensional integral identities with Bayesian
applications. Ann. Statist., 39, 1615–1627.
Diebolt, J. et Robert, C. (1994). Estimation of ﬁnite mixture distributions by
Bayesian sampling. J. Royal Statist. Soc. Series B, 56, 363–375.
Douc, R., Guillin, A., Marin, J.-M., et Robert, C. (2005). Convergence of
adaptive sampling schemes. Technical Report 2005-6, University Paris Dau-
phine.
Doucet, A., de Freitas, N., et Gordon, N. (2001). Sequential Monte Carlo
Methods in Practice. Springer-Verlag, New York.
Doucet, A., Godsill, S., et Robert, C. (2002). Marginal maximum a posteriori
estimation using Markov chain Monte Carlo. Statistics and Computing, 12,
77–84.
Draper, D. (1995). Assessment and propagation of model uncertainty. J. Royal
Statist. Soc. Series B, 57, 45–98.
Dr`eze, J.H.and Morales, J. (1976a). Bayesian full information analysis of the
simultaneous equations. J. American Statist. Assoc., 71, 919–923.
Dr`eze, J.H.and Morales, J. (1976b). Bayesian regression analysis using poly-t
densities. J. American Statist. Assoc., 71, 919–923.
Dudewicz, E. et Koo, J. (1982). The Complete Categorized Guide to Statisti-
cal Selection and Ranking Procedures. American Science Press, Columbus,
Ohio.

584
R´ef´erences
Dumouchel, W. et Harris, J. (1983). Bayes methods for combining the results
of cancer studies in human and other species (with discussion). J. American
Statist. Assoc., 78, 293–315.
Dupuis, J. (1995a). Analyse stochastique bay´esienne de mod`eles de capture-
recapture. Th`ese de doctorat, Universit´e Paris VI.
Dupuis, J. (1995b). Bayesian estimation of movement probabilities in open
populations using hidden Markov chains. Biometrika, 82(4), 761–772.
Dupuis, J. et Robert, C. (2001). Bayesian variable selection in qualitative
models by Kullback-Leibler projections. J. Statist. Plann. Inference, 111,
77–94.
Dynkin, E. (1951). Necessary and suﬃcient statistics for a family of probabi-
lity distributions. Selected Transl. Math. Statist. Prob., 1, 23–41.
Eaton, M. (1982). Multivariate Statistics. John Wiley, New York.
Eaton, M. (1986). A characterization of spherical distributions. J. Multivariate
Anal., 20, 272–276.
Eaton, M. (1989). Group Invariance Applications in Statistics, volume 1 dans
Regional Conference Series in Probability and Statistics. Institute of Ma-
thematical Statistics, Hayward, California.
Eaton, M. (1992). A statistical dyptich : Admissible inferences - recurrence
of symmetric Markov chains. Ann. Statist., 20, 1147–1179.
Eaton, M. (1999). Markov chain conditions for admissibility in estimation pro-
blems with quadratic loss. Technical Report Report PN1 R9904, Centrum
voor Wiskunde en Informatica, Amsterdam.
Eberly, L. E. et Casella, G. (1999). Comparison of Bayesian credible intervals
in hierarchical models. Technical report, Division of Biostatistics University
of Minnesota.
Efron, B. (1975).
Biased versus unbiased estimation.
Adv. in Math., 16,
259–277.
Efron, B. (1982). The Jacknife, the Bootstrap and other resampling plans. In
Regional Conference in Applied Mathematics, volume 38. SIAM, Philadel-
phia.
Efron, B. (1992). Regression percentile using asymmetric squared error loss.
Statist. Sinica, 1, 93–125.
Efron, B. et Morris, C. (1975). Data analysis using Stein’s estimator and its
generalizations. J. American Statist. Assoc., 70, 311–319.
Efron, B. et Thisted, R. (1976). Estimating the number of species : How many
words did Shakespeare know ? Biometrika, 63, 435–447.
Eichenauer, J. et Lehn, J. (1989). Gamma-minimax estimators for a bounded
normal mean under squared error-loss. Statist. Decisions, 7, 37–62.
Engle, R. (1982). Autoregressive conditional heteroscedasticity with estimates
of the variance of United Kingdom inﬂation. Econometrica, 50, 987–1008.
Escobar, M. (1989). Estimating the means of several normal populations by
estimating the distribution of the means. PhD thesis, Yale University.
Escobar, M. et West, M. (1995). Bayesian prediction and density estimation.
J. American Statist. Assoc., 90, 577–588.

R´ef´erences
585
Evans, M., Fraser, D., et Monette, G. (1986). On principles and arguments
to likelihood (with discussion). Canadian J. Statist., 14, 181–199.
Fabius, J. (1964).
Asymptotic behavior of Bayes estimates.
Ann. Mathe-
mat. Statist., 34, 846–856.
Fan, K. et Anderson, T. (1990). Statistical Inference in Elliptically Contoured
and Related Distributions. Allerton Press, New York.
Farrell, R. (1968a). On a necessary and suﬃcient condition for admissibility
of estimators when strictly convex loss is used. Ann. Mathemat. Statist.,
38, 23–28.
Farrell, R. (1968b). Towards a theory of generalized Bayes tests. Ann. Ma-
themat. Statist., 38, 1–22.
Feller, W. (1970). An Introduction to Probability Theory and its Applications,
volume 1. John Wiley, New York.
Feller, W. (1971). An Introduction to Probability Theory and its Applications,
volume 2. John Wiley, New York.
Ferguson, T. (1967). Mathematical Statistics : a Decision-Theoretic Approach.
Academic Press, New York.
Ferguson, T. (1973). A Bayesian analysis of some nonparametric problems.
Ann. Statist., 1, 209–230.
Ferguson, T. (1974). Prior distributions in spaces of probability measures.
Ann. Statist., 2, 615–629.
Fernandez, C. et Steel, M. (1999). On the dangers of modelling through conti-
nuous distributions : a Bayesian perspective (with discussion). In Bernardo,
J., Berger, J., Dawid, A., et Smith, A., ´editeurs, Bayesian Statistics 6, pages
213–238. Oxford University Press, Oxford.
Feyerabend, P. (1975). Against Method. New Left Books, London.
Field, C. et Ronchetti, E. (1990). Small Sample Asymptotics. IMS Lecture
Notes - Monograph Series, Hayward, CA.
Fieller, E. (1954).
Some problems in interval estimation.
J. Royal Sta-
tist. Soc. Series B, 16, 175–185.
Fienberg, S. (2005). When did Bayesian statistics become Bayesian? Bayesian
Analysis. (To appear.).
Fishburn, P. (1988). Non-Linear Preferences and Utility Theory. Harvester
Wheatsheaf, Brighton, Sussex.
Fisher, R. (1912). On an absolute criterion for ﬁtting frequency curves. Mes-
senger of Mathematics, 41, 155–160.
Fisher, R. (1922). On the mathematical foundations of theoretical Statistics.
Philos. Trans. Roy. Soc. London, 222, 309–368.
Fisher, R. (1930). Inverse probability. Proc. Cambridge Philos. Soc, 26, 528–
535.
Fisher, R. (1956). Statistical Methods and Scientiﬁc Inference. Oliver and
Boyd, Edinburgh.
Fisher, R. (1959). Mathematical probability in the natural sciences. Techno-
metrics, 1, 21–29.
Fishman, G. (1996). Monte Carlo. Springer-Verlag, New York.

586
R´ef´erences
Fitzgerald, W., Godsill, S., Kokaram, A., et Stark, J. (1999). Bayesian me-
thods in signal and image processing. In Bernardo, J., Berger, J., Dawid,
A., et Smith, A., ´editeurs, Bayesian Statistics 6, pages 239–254, Oxford.
Oxford University Press.
Foster, D. et George, E. (1998). A simple ancillarity paradox. Scand. J. Sta-
tist., 23, 233–242.
Fouley, J., San Cristobal, M., Gianola, D., et Im, S. (1992). Marginal like-
lehood and Bayesian approaches to the analysis of heterogeneous residual
variances in mixed linear Gaussian models. Comput. Statist. Data Anal.,
13, 291–305.
Fourdrinier, D. et Robert, C. (1995). A note on empirical Bayes via entropy.
Statist. Prob. Letters, 23(1), 35–44.
Fourdrinier, D., Strawderman, W., et Wells, M. (1998). On the construction
of Bayes minimax estimators. Ann. Statist., 26(2), 660–671.
Fourdrinier, D. et Wells, M. (1993). Risk comparison of variable selection
rules. Technical report, Universit´e de Rouen.
Fraisse, A., Raoult, J., Robert, C., et Roy, M. (1990). Une condition n´ecessaire
d’admissibilit´e et ses cons´equences sur les estimateurs `a r´etr´ecisseur de la
moyenne d’une loi normale. Canadian J. Statist., 18, 213–220.
Fraisse, A., Robert, C., et Roy, M. (1998). Semi-tail upper bounds for admis-
sible estimators in exponential families with nuisance parameters. Statistics
& Decisions, 16(2), 147–162.
Francq, C. et Zako¨ıan, J. (2001).
Stationarity of multivariate Markov-
switching ARMA models. J. Econometrics, 102(2), 339–364.
Fraser, D., Monette, G., et Ng, K. (1984).
Marginalization,likelihood and
structural models. In Krishnaiah, P., ´editeur, Multivariate Analysis, vo-
lume 6. North-Holland, Amsterdam.
Gatsonis, C., Hodges, J., Kass, R., et McCulloch, R. (1997). Case Studies
in Bayesian Statistics II, volume 121 dans Lecture Notes in Statistics.
Springer-Verlag, New York.
Gatsonis, C., Hodges, J., Kass, R., et Singpurwalla, N. (1993). Case Studies in
Bayesian Statistics, volume 83 dans Lecture Notes in Statistics. Springer-
Verlag, New York.
Gatsonis, C., Hodges, J., Kass, R., et Singpurwalla, N. (1995). Case Stu-
dies in Bayesian Statistics II, volume 105 dans Lecture Notes in Statistics.
Springer-Verlag, New York.
Gatsonis, C., Kass, R., Carlin, B., Carriquiry, A., Gelman, A., et Verdinelli,
I. (1999). Case Studies in Bayesian Statistics IV, volume 140. Springer-
Verlag, New York.
Gatsonis, C., MacGibbon, K., et Strawderman, W. (1987). On the estimation
of a truncated normal mean. Statist. Prob. Letters, 6, 21–30.
Gauss, C. (1810). M´ethode des Moindres Carr´es. M´emoire sur la Combination
des Observations. Mallet-Bachelier, Paris. Transl. J. Bertrand.
Geisser, S. et Cornﬁeld, J. (1963). Posterior distributions for multivariate
normal parameters. J. Royal Statist. Soc. Series B, 25, 368–376.

R´ef´erences
587
Gelfand, A. (1996). Model determination using sampling-based methods. In
W.R. Gilks, S. R. et Spiegelhalter, D., ´editeurs, Markov Chain Monte Carlo
in Practice, pages 145–162. Chapman and Hall, New York.
Gelfand, A. (2000). Gibbs sampling. J. American Statist. Assoc., 95, 1300–
1304.
Gelfand, A. et Dey, D. (1994). Bayesian model choice : asymptotics and exact
calculations. J. Roy. Statist. Soc. (Ser. B), 56, 501–514.
Gelfand, A. et Smith, A. (1990). Sampling based approaches to calculating
marginal densities. J. American Statist. Assoc., 85, 398–409.
Gelfand, A., Smith, A., et Lee, T. (1992). Bayesian analysis of constrained pa-
rameters and truncated data problems using Gibbs sampling. J. American
Statist. Assoc., 87, 523–532.
Gelman, A. (1996).
Inference and monitoring convergence.
In Gilks, W.,
Richardson, S., et Spiegelhalter, D., ´editeurs, Markov chain Monte Carlo
in Practice, pages 131–143. Chapman and Hall, New York.
Gelman, A., Carlin, J., Stern, H., et Rubin, D. (2003). Bayesian Data Ana-
lysis. Chapman and Hall, New York, second ´edition.
Gelman, A. et Meng, X. (1998). Simulating normalizing constants : From
importance sampling to bridge sampling to path sampling. Statist. Science,
13, 163–185.
Gelman, A. et Rubin, D. (1992). Inference from iterative simulation using
multiple sequences (with discussion). Statist. Science, 7, 457–511.
Geman, S. et Geman, D. (1984). Stochastic relaxation, Gibbs distributions
and the Bayesian restoration of images. IEEE Trans. Pattern Anal. Mach.
Intell., 6, 721–741.
Genest, C. et Zidek, J. (1986). Combining probability distributions : A critique
and an annotated bibliography. Statist. Science, 1, 114–135.
Gentle, J. E. (1998). Random Number Generation and Monte Carlo Methods.
Springer-Verlag, New York.
George, E. (1986a). Combining minimax shrinkage estimators. J. American
Statist. Assoc., 81, 437–445.
George, E. (1986b). Minimax multiple shrinkage estimators. Ann. Statist.,
14, 188–205.
George, E. et Casella, G. (1994).
Empirical Bayes conﬁdence estimation.
Statist. Sinica, 4(2), 617–638.
George, E. et Foster, D. (1999). Empirical Bayes variable selection. In Racu-
gno, W., ´editeur, Model Choice. Pitagora Editrice, Bologna.
George, E. et McCulloch, R. (1997). Approaches for Bayesian variable selec-
tion. Statistica Sinica, 7, 339–374.
George, E. et Robert, C. (1992). Calculating Bayes estimates for capture-
recapture models. Biometrika, 79(4), 677–683.
Geweke, J. (1991).
Eﬃcient simulation from the multivariate normal and
student t-distributions subject to linear constraints.
Computer Sciences
and Statistics : Proc. 23d Symp. Interface.

588
R´ef´erences
Geweke, J. (1992). Evaluating the accuracy of sampling-based approaches to
the calculation of posterior moments (with discussion). In Bernardo, J.,
Berger, J., Dawid, A., et Smith, A., ´editeurs, Bayesian Statistics 4, pages
169–193. Oxford University Press, Oxford.
Geweke, J. (1999). Using simulation methods for Bayesian econometric mo-
dels : inference, development and communication (with discussion). Econo-
metric Reviews.
Geyer, C. (1992).
Practical Monte Carlo Markov chain (with discussion).
Statist. Science, 7, 473–511.
Geyer, C. (1995). Conditioning in Markov chain Monte Carlo. J. Comput.
Graph. Statis., 4, 148–154.
Geyer, C. (1996). Estimation and optimization of functions. In Gilks, W.,
Richardson, S., et Spiegelhalter, D., ´editeurs, Markov chain Monte Carlo
in Practice, pages 241–258. Chapman and Hall, New York.
Geyer, C. et Thompson, E. (1992). Constrained Monte Carlo maximum like-
lihood for dependent data (with discussion). J. Royal Statist. Soc. Series
B, 54, 657–699.
Ghosh, M., Carlin, B. P., et Srivastiva, M. S. (1995). Probability matching
priors for linear calibration. TEST, 4, 333–357.
Ghosh, M., Hwang, J., et Tsui, K. (1983). Construction of improved estima-
tors in multiparameter estimation for discrete exponential families (with
discussion). Ann. Mathemat. Statist., 11, 351–376.
Ghosh, M., Keating, J., et Sen, P. (1993). Discussion of Robert, Hwang and
Strawderman. J. American Statist. Assoc., 88, 63–66.
Ghosh, M. et Mukerjee, R. (1992a). Bayesian and frequentist Bartlett correc-
tions for likelihood ratio tests. J. Royal Statist. Soc. Series B, 56, 396–408.
Ghosh, M. et Mukerjee, R. (1992b). Noninformative priors (with discussion).
In Bernardo, J., Berger, J., Dawid, A., et Smith, A., ´editeurs, Bayesian
Statistics. Oxford University Press, Oxford.
Ghosh, M. et Mukerjee, R. (1993). Frequentist validity of highest posterior
density regions in the multiparameter case. Ann. Inst. Statist. Math., 45,
293–302.
Ghosh, M. et Saleh, A. (1989). Empirical Bayes subset estimation in regression
models. Statist. Decisions, 7, 15–35.
Ghosh, M. et Sen, P. (1989). Median unbiasedness and Pitman closeness.
J. American Statist. Assoc., 84, 1089–1091.
Ghosh, M. et Yang, M. (1996). Noninformative priors for the two sample
normal problem. Test, 5, 145–157.
Gibbons, J., Olkin, I., et Sobel, M. (1977). Selecting and Ordering Populations.
John Wiley, New York.
Gilks, W., Best, N., et Tan, K. (1995). Adaptive rejection Metropolis sampling
within Gibbs sampling. Applied Statist. (Ser. C), 44, 455–472.
Gilks, W., Clayton, D., Spiegelhalter, D., Best, N., McNeil, A., Sharples, L.,
et Kirby, A. (1993). Modelling complexity : applications of Gibbs sampling
in medicine. J. Royal Statist. Soc. Series B, 55, 39–52.

R´ef´erences
589
Gilks, W., Richardson, S., et Spiegelhalter, D., ´editeurs (1996). Markov Chain
Monte Carlo in Practice. Chapman and Hall, New York, London.
Gilks, W. et Wild, P. (1992). Adaptive rejection sampling for Gibbs sampling.
Appl. Statist., 41, 337–348.
Gill, J. (2002). Bayesian Methods : A Social and Behavioral Sciences Ap-
proach. CRC Press.
Gill, W. et Levit, B. (1995). Applications of the Van Trees inequality : a
Bayesian Cram´er-Rao bound. Bernouilli, 1, 59–79.
Giudici, P. et Green, P. (1999).
Decomposable graphical Gaussian model
determination. Biometrika, 86(4), 785–801.
Givens, G., Smith, D., et Tweedie, R. (1997).
Publication bias in meta-
analysis : a Bayesian data-augmentation approach to account for issues
exempliﬁed in the passive smoking debate. StatSci, 12, 221–250.
Gleick, J. (1987). Chaos. Penguin, New York.
Gleser, L. et Healy, J. (1976). Estimating the mean of a normal distribution
with known coeﬃcient of variation. J. American Statist. Assoc., 71, 977–
981.
Gleser, L. et Hwang, J. (1987). The non-existence of 100(1 −α)% conﬁdence
sets of ﬁnite expected diameters in errors-in-variable and related models.
Ann. Statist., 15, 1351–1362.
Goel, P. et Rubin, H. (1977).
On selecting a subset containing the best
population-a Bayesian approach. Ann. Statist., 5, 969–983.
Goldstein, M. et Smith, A. (1974). Ridge-type estimators for regression ana-
lysis. J. Royal Statist. Soc. Series B, 36, 284–219.
Good, I. (1952). Rational decisions. J. Royal Statist. Soc. Series B, 14, 107–
114.
Good, I. (1973). The probabilistic explication of evidence, causality, expla-
nation and utility. In Godambe, V. et Sprott, D., ´editeurs, Foundations of
Statistical Inference. Rinehart and Winston, Toronto.
Good, I. (1975). Estimation methods for two-way contingency tables. J. Royal
Statist. Soc. Series B, 37, 23–37.
Good, I. (1980). Some history of the hierarchical Bayesian methodology. In
Bernardo, J., DeGroot, M., Lindley, D., et Smith, A., ´editeurs, Bayesian
Statistics 2. North-Holland, Amsterdam.
Good, I. (1983).
Good Thinking : The Foundations of Probability and Its
Applications. University of Minnesota Press, Minneapolis.
Gouri´eroux, C. (1997). ARCH Model. Springer-Verlag, New York.
Gouri´eroux, C. et Monfort, A. (1996). Statistics and Econometric Models.
Cambridge University Press, Cambridge.
Goutis, C. (1990). Ranges of posterior measures for some classes of priors
with speciﬁed moments. Technical Report 70, University College London,
London.
Goutis, C. (1994). Ranges of posterior measures for some classes of priors
with speciﬁed moments. International Statistical Review, 62(2), 245–256.

590
R´ef´erences
Goutis, C. et Casella, G. (1991). Improved invariant conﬁdence intervals for
a normal variance. Ann. Statist., 19, 2015–2031.
Goutis, C. et Casella, G. (1992). Increasing the conﬁdence in student’s t-
interval. Ann. Statist., 20(3), 1501–1513.
Goutis, C., Casella, G., et Wells, M. (1996). Assessing evidence in multiple
hypotheses. J. American Statist. Assoc., 91, 1268–1277.
Goutis, C. et Robert, C. (1998). Model choice in generalized linear models : a
Bayesian approach via Kullback–Leibler projections. Biometrika, 85, 29–37.
Green, P. (1995). Reversible jump MCMC computation and Bayesian model
determination. Biometrika, 82(4), 711–732.
Grenander, U. et Miller, M. (1994). Representations of knowledge in complex
systems (with discussion). J. Royal Statist. Soc. Series B, 56, 549–603.
Gruet, M., Philippe, A., et Robert, C. (1999). MCMC control spreadsheets
for exponential mixture estimation. J. Comput. Graph. Statist., 8, 298–317.
Guihenneuc-Jouyaux, C., Richardson, S., et Lasserre, V. (1998). Convergence
assessment in latent variable models : application to longitudinal model-
ling of a marker of HIV progression. In Robert, C., ´editeur, Discretization
and MCMC Convergence Assessment, volume 135 dans Lecture Notes in
Statistics, chapter 7, pages 147–160. Springer-Verlag, New York.
Gupta, S. (1965). On multiple decision (selection and ranking) rules. Tech,
7, 222–245.
Gupta, S. et Panchapakesan, S. (1979). Multiple Decision Procedures. John
Wiley, New York.
Gutmann, S. (1982). Stein’s paradox is impossible in problems with ﬁnite
sample space. Ann. Statist., 10, 1017–1020.
Hadjicostas, P. et Berry, S. (1999).
Improper and proper posteriors with
improper priors in a Poisson-gamma hierarchical model. Test, 8, 147–166.
Haﬀ, L. et Johnstone, R. (1986). The superharmonic condition for simulta-
neous estimation of means in exponential families. Canadian J. Statist., 14,
43–54.
H`ajek, B. et Sid`ak, Z. (1968). Theory of Rank Test. Academic Press, New
York.
Hald, A. (1998). An History of Mathematical Statistics. John Wiley, New
York.
Haldane, J. (1931). A note on inverse probability. Proc. Cambridge Philos.
Soc., 28, 55–61.
Hall, P. (1992). The Bootstrap and Edgeworth Expansion. Springer-Verlag,
New York.
Hamilton, J. (1989). A new approach to the economic analysis of nonstatio-
nary time series and the business cycle. Econometrica, 57(2), 357–384.
Hammersley, J. (1974). Discussion of Besag’s paper. J. Royal Statist. Soc. Se-
ries B, 36, 230–231.
Hansen, M. et Yu, B. (2000). Model selection and minimum description length
principle. J. American Statist. Assoc. (To appear.).
Hartigan, J. A. (1983). Bayes Theory. Springer-Verlag, New York.

R´ef´erences
591
Hastings, W. (1970). Monte Carlo sampling methods using Markov chains
and their application. Biometrika, 57, 97–109.
Heath, D. et Sudderth, W. (1989). Coherent inference from improper priors
and from ﬁnitely additive priors. Ann. Statist., 17, 907–919.
Heidelberger, P. et Welch, P. (1983). A spectral method for conﬁdence interval
generation and run length control in simulations. Comm. Assoc. Comput.
Machinery, 24, 233–245.
Heitjan, D. et Rubin, D. (1991). Ignorability and coarse data. Ann. Statist.,
19, 2244–2253.
Helland, I. (1999). Statistical inference under a ﬁxed symmetry group. Tech-
nical report, Dept. of Mathematics and Statistics, University of Oslo.
Hesterberg, T. (1998). Weighted average importance sampling and defensive
mixture distributions. Technometrics, 37, 185–194.
Hills, S. et Smith, A. (1992). Parametrization issues in Bayesian inference.
In Bernardo, J., Berger, J., Dawid, A., et Smith, A., ´editeurs, Bayesian
Statistics 4, pages 641–649. Oxford University Press, Oxford.
Hinkley, D. (1997). Discussion of ”uniﬁed frequentist and Bayesian testing of
a precise hypothesis”. Statist. Science, 12, 155–156.
Hjort, N. (1996). Bayesian approaches to non- and semiparametric density
estimation (with discussion). In Bernardo, J., Berger, J., Dawid, A., Lindley,
D., et Smith, A., ´editeurs, Bayesian Statistics 5, pages 223–253. Oxford
University Press, Oxford.
Hoaglin, D., Mosteller, F., et Tukey, J. (1996). Exploring Data Tables, Trends,
and Shapes. John Wiley, New York.
Hobert, J. (2000a). Stability relationships among the Gibbs sampler and its
subchains. Technical report, University of Florida.
Hobert, J. et Casella, G. (1996).
The eﬀect of improper priors on Gibbs
sampling in hierarchical linear models.
J. American Statist. Assoc., 91,
1461–1473.
Hobert, J. et Casella, G. (1998). Functional compatibility, Markov chains,
and Gibbs sampling with improper posteriors. J. Comput. Graph. Statist.,
7, 42–60.
Hobert, J. et Robert, C. (1999). Eaton’s Markov chain, its conjugate partner
and p-admissibility. Ann. Statist., 27, 361–373.
Hobert, J. et Robert, C. (2004). Moralizing perfect sampling. Ann. Applied
Prob., 14(3), 1295–1305.
Hobert, J. P. (2000b). Hierarchical models : a current computational perspec-
tive. J. American Statist. Assoc., 95, 1312–1316.
Hoerl, A. et Kennard, R. (1970).
Ridge regression : biased estimators for
non-orthogonal problems. Technometrics, 12, 55–67.
Holmes, C., Denison, D., Mallick, B., et Smith, A. (2002). Bayesian Methods
for Nonlinear Classiﬁcation and Regression. John Wiley, New York.
Hora, R. et Buehler, R. (1966).
Fiducial theory and invariant estimation.
Ann. Statist., 37, 361–379.

592
R´ef´erences
Huber, P. (1964a). Robust estimation of a location parameter. Ann. Statist.,
35, 73–101.
Huber, P. (1964b). Robust statistics : a review. Ann. Statist., 67, 1041–1067.
Huerta, G. et West, M. (1999). Priors and component structures in autore-
gressive time series models. J. Royal Statist. Soc. Series B, 61(4), 881–899.
Hui, S. et Berger, J. (1983). Empirical Bayes estimation of rates in longitudinal
studies. J. American Statist. Assoc., 78, 753–760.
Hwang, J. (1982a). Improving upon standard estimators in discrete expo-
nential families with applications to Poisson and negative binomial cases.
Ann. Statist., 10, 857–867.
Hwang, J. (1982b). Semi-tail upper bounds on the class of admissible esti-
mators in discrete exponential families, with applications to Poisson and
negative binomial distributions. Ann. Statist., 10, 1137–1147.
Hwang, J. (1985). Universal domination and stochastic domination : decision
theory simultaneously under a broad class of loss functions. Ann. Statist.,
13, 295–314.
Hwang, J. et Brown, L. (1991).
Estimated conﬁdence under the validity
constraint. Ann. Statist., 19, 1964–1977.
Hwang, J. et Casella, G. (1982). Minimax conﬁdence sets for the mean of a
multivariate normal distribution. Ann. Statist., 10, 868–881.
Hwang, J. et Casella, G. (1984). Improved set estimators for a multivariate
normal mean. Statist. Decisions, 1, 3–16. Supplement Issue.
Hwang, J., Casella, G., Wells, M., et Farrel, R. (1992). Estimation of accuracy
in testing. Ann. Statist., 20, 490–509.
Hwang, J. et Chen, J. (1986). Improved conﬁdence sets for the coeﬃcients of a
linear model with spherically symmetric errors. Ann. Statist., 14, 444–460.
Hwang, J. et Pemantle, R. (1994).
Evaluation of estimators of statistical
signiﬁcance under a class of proper loss functions. Statist. Decisions, 15,
103–128.
Hwang, J. et Ullah, A. (1994).
Conﬁdence sets recentered at James-Stein
estimators-a surprise concerning the unknown variance case. Econometrics,
60(1-2), 145–156.
Ibragimov, I. et Has’minskii, R. (1981). Statistical Estimation. Asymptotic
Theory. Springer-Verlag.
Jacquier, E., Polson, N., et Rossi, P. (1994). Bayesian analysis of stochastic
volatility models (with discussion). J. Business Economic Stat., 12, 371–
417.
James, W. et Stein, C. (1961). Estimation with quadratic loss. In Proc. Fourth
Berkeley Symp. Math. Statist. Probab., volume 1, pages 361–380. University
of California Press.
Jaynes, E. (1980). Marginalization and prior probabilities. In Zellner, A.,
´editeur, Bayesian Analysis in Econometrics and Statistics. North-Holland,
Amsterdam.
Jaynes, E. (1983). Papers on Probability, Statistics and Statistical Physics.
R.D. Rosencrantz, Reidel, Dordrecht.

R´ef´erences
593
Jeﬀerys, W. et Berger, J. (1992).
Ockham’s razor and Bayesian analysis.
American Scientist, 80, 64–72.
Jeﬀreys, H. (1939). Theory of Probability. Oxford University Press, Oxford.
Jeﬀreys, H. (1946). An invariant form for the prior probability in estimation
problems. Proceedings of the Royal Society of London(Ser. A), 186, 453–
461.
Jeﬀreys, H. (1961). Theory of Probability (3rd edition). Oxford University
Press, Oxford.
Johnson, B. (1971). On the admissible estimators for certain ﬁxed sample
binomial problems. Ann. Statist., 41, 1579–1587.
Johnson, D. et Hoeting, J. (2003).
Autoregressive models for capture-
recapture data : A Bayesian approach. Biometrics, 59(2), 341–350.
Johnson, D. et Lindley, D. (1995). Bayesian inference given data “signiﬁcant
at α” : tests of point-null hypotheses. Theory and Decision, 38(1), 51–60.
Johnson, N. et Kotz, S. (1969-1972). Distributions in Statistics (4 vols.). John
Wiley, New York.
Johnson, N., Kotz, S., et Balakrishnan, N. (1994). Continuous Univariate
Distributions, volume 1. John Wiley, New York, seconde ´edition.
Johnson, N., Kotz, S., et Balakrishnan, N. (1995). Continuous Univariate
Distributions, volume 2. John Wiley, New York, seconde ´edition.
Johnstone, I. (1984). Admissibility, diﬀerence equations, and recurrence in
estimating a Poisson mean. Ann. Statist., 12, 1173–1198.
Johnstone, I. (1998). On the inadmissibility of Stein’s unbiased estimate of
loss. In Gupta, S. et Berger, J., ´editeurs, Statistical Decision Theory and
Related Topics. Springer-Verlag, New York.
Johnstone, I. et MacGibbon, B. (1992). Minimax estimation of a constrained
Poisson vector. Ann. Statist., 20, 807–831.
Jones, M. (1987). Randomly choosing parameters from the stationarity and
invertibility region of autoregressive-moving average models. Applied Sta-
tistics (Series C), 38, 134–138.
Joshi, V. (1967a). Admissibility of the usual conﬁdence set for the mean of a
multivariate normal population. Ann. Statist., 38, 1868–1875.
Joshi, V. (1967b). The censoring concept and the likelihood principle. J. Sta-
tist. Plann. Inference, 26, 109–111.
Judge, G. et Bock, M. (1978). Implications of Pre-Test and Stein Rule Esti-
mators in Econometrics. North-Holland, Amsterdam.
Kadane, J. et Chuang, D. (1978). Stable decision problems. Ann. Statist., 6,
1095–1111.
Kariya, T., Giri, N., et Perron, F. (1988). Invariant estimation of mean vector
μ of N(μ, Σ) with μ′Σ−1μ = 1 or Σ−1/2μ = C or Σ = δ2μμ′I. J. Multiv.
Analysis, 27, 270–283.
Karlin, S. (1958). Admissibility for estimation with quadratic loss. Ann. Sta-
tist., 29, 406–436.
Karlin, S. et Rubin, H. (1956). The theory of decision procedures for distri-
butions with monotone likelihood ratio. Ann. Statist., 27, 272–299.

594
R´ef´erences
Kass, R. (1989). The geometry of asymptotic inference. Statist. Science, 4,
188–234.
Kass, R. et Raftery, A. (1995). Bayes factor and model uncertainty. J. Ame-
rican Statist. Assoc., 90, 773–795.
Kass, R. et Steﬀey, D. (1989). Approximate Bayesian inference in conditio-
nally independent hierarchical models (parametric empirical Bayes models).
J. American Statist. Assoc., 87, 717–726.
Kass, R. et Wasserman, L. (1996). Formal rules of selecting prior distribu-
tions : a review and annotated bibliography. J. American Statist. Assoc.,
91, 343–1370.
Keating, J. et Mason, R. (1988). James-Stein estimation from an alternative
perspective. Amer. Statist., 42, 160–164.
Keeney, R. et Raiﬀa, H. (1976). Decisions with Multiple Objectives, volume 42.
J. Wiley, New York.
Kelker, D. (1970).
Distribution theory of spherical distributions and a
location-scale parameter generalization. Sankhya (Ser. A), 32, 419–430.
Kempthorne, P. (1988). Controlling risks under diﬀerent loss functions : the
compromise decision problem. Ann. Statist., 16, 1594–1608.
Kendall, M. et Stuart, A. (1979). Inference and Relationships. The Advanced
Theory of Statistics. Macmillan, New York, 4th edition ´edition.
Keynes, J. (1921). A Treatise on Probability. Macmillan, London.
Kiefer, J. (1957). Invariance, minimax sequential estimation and continuous
time-processes. Ann. Mathemat. Statist., 28, 573–601.
Kiefer, J. (1977). Conditional conﬁdence statements and conﬁdence estimators
(theory and methods). J. American Statist. Assoc., 72, 789–827.
Kiiveri, H. et Speed, T. (1982). Structural analysis of multivariate data : A
review. In Leinhardt, S., ´editeur, Sociological Methodology, pages 209–289.
Jossey Bass, San Francisco.
Kirby, A. J. et Spiegelhalter, D. J. (1994). Statistical modelling for the pre-
cursors of cervical cancer. In Lange, N., ´editeur, Case Studies in Biometry.
John Wiley, New York.
Kleibergen, F. et Van Dijk, H. (1993). Non-stationarity in GARCH models :
a Bayesian analysis. J. of Appl. Econometrics, 8, 41–61.
Kontkanen, P., Myllym¨aki, P., Silander, T., Tirri, H., et Gr¨unwald, P. (2000).
On predictive distributions and Bayesian networks. Statist. Comp., 10, 39–
54.
Koopman, B. (1936). On distributions admitting a suﬃcient statistic. Trans.
Amer. Math. Soc., 39, 399–409.
Kubokawa, T. (1991).
An approach to improving James-Stein estimator.
J. Multiv. Analysis, 36, 121–126.
Kubokawa, T., Morita, S., Makita, S., et Nagakura, K. (1993a). Estimation of
the variance and its applications. J. Statist. Plann. Inference, 35, 319–333.
Kubokawa, T. et Robert, C. (1994). New perspectives on linear calibration.
J. Multiv. Analysis, 51, 178–200.

R´ef´erences
595
Kubokawa, T., Robert, C., et Saleh, A. (1991). Robust estimation of common
regression coeﬃcients under spherical symmetry. Ann. Inst. Statist. Math.,
43, 677–688.
Kubokawa, T., Robert, C., et Saleh, A. (1992). Empirical Bayes estimation of
the covariance matrix of a normal distribution with unknown mean under
an entropy loss. Sankhya, 54, 402–410. Ser. A.
Kubokawa, T., Robert, C., et Saleh, A. (1993b). Estimation of noncentrality
parameters. Canadian J. Statist., 21, 54–58.
Lad, F. (1996). Operational Subjective Statistical Methods : a Mathematical,
Philosophical and Historical Introduction. John Wiley, New York.
Laird, N. et Louis, T. (1987). Conﬁdence intervals based on bootstrap samples.
J. American Statist. Assoc., 82, 739–750.
Laplace, P. (1773). M´emoire sur la probabilit´e des causes par les ´ev´enements.
M´emoires de l’Acad´emie Royale des Sciences pr´esent´es par divers savants,
6, 621–656. Reprinted in Laplace (1878).
Laplace, P. (1786). Sur les naissances, les mariages et les morts `a Paris depuis
1771 jusqu’`a 1784 et dans toute l’´etendue de la France, pendant les ann´ees
1781 et 1782. M´emoires de l’Acad´emie Royale des Sciences pr´esent´es par
divers savants, 11, 35–46. Reprinted in Laplace (1878).
Laplace, P. (1795). Essai Philosophique sur les Probabilit´es. Epist´em´e. Chris-
tian Bourgeois, Paris. Reprinted in 1986.
Lauritzen, S. (1996). Graphical Models. Oxford University Press, Oxford.
Lavielle, M. et Moulines, E. (1997). On a stochastic approximation version of
the em algorithm. Statist. Comput., 7, 229–236.
Lavine, M. (1992). Some aspects of P´olya tree distributions for statistical
modeling. Ann. Statist., 22, 1222–1235.
Lawley, D. (1956). A general method for approximating to the distribution of
the likelihood ratio criteria. Biometrika, 43, 295–303.
Le Cam, L. (1986).
Asymptotic Methods in Statistical Decision Theory.
Springer-Verlag, New York.
Le Cam, L. (1990). Maximum likelihood : an introduction. Statist. Science,
58, 153–172.
Legendre, A. (1805). Nouvelles M´ethodes pour la D´etermination des Orbites
des Com`etes. Courcier, Paris.
Lehmann, E. (1983). Theory of Point Estimation. John Wiley, New York.
Lehmann, E. (1986). Testing Statistical Hypotheses. John Wiley, New York.
Lehmann, E. (1990). Model speciﬁcation. Statist. Science, 5, 160–168.
Lehmann, E. et Casella, G. (1998). Theory of Point Estimation. Springer-
Verlag, New York, revised ´edition.
Lenk, P. (1999).
Bayesian inference for semiparametric regression using a
Fourier representation. J. Royal Statist. Soc. Series B, 61, 863–879.
Leonard, T. (1982). Comments on Lejeune and Faulkenberry. J. American
Statist. Assoc., 77, 657–658.
Letac, G. et Mora, M. (1990). Natural real exponential families with cubic
variance functions. Ann. Statist., 18, 1–37.

596
R´ef´erences
Lindley, D. (1957). A statistical paradox. Biometrika, 44, 187–192.
Lindley, D. (1961). The use of prior probability distributions in statistical in-
ference and decision. In Proc. Fourth Berkeley Symp. Math. Statist. Probab,
volume 1, pages 453–468. University of California Press.
Lindley, D. (1962). Discussion of professor Stein’s paper ‘conﬁdence sets for
the mean of a multivariate normal distribution’. J. Royal Statist. Soc. Series
B, 24, 265–296.
Lindley, D. (1965). Introduction to Probability and Statistics from a Bayesian
Viewpoint, volume Parts 1 and 2. Cambridge University Press, Cambridge.
Lindley, D. (1971). Bayesian Statistics : A Review. SIAM, Philadelphia.
Lindley, D. (1980). Approximate Bayesian methods. In Bernardo, J., De-
Groot, M., Lindley, D., et Smith, A., ´editeurs, Bayesian Statistics 2. North-
Holland, Amsterdam.
Lindley, D. (1985). Making Decisions. John Wiley, New York.
Lindley, D. (1990). The present position in Bayesian statistics (with discus-
sion). Statist. Science, 5(1), 44–89.
Lindley, D. et Smith, A. (1972). Bayes stimates for the linear model. J. Royal
Statist. Soc. Series B, 34, 1–41.
Liseo, B. (1993). Elimination of nuisance parameters with reference priors.
Biometrika, 80(2), 295–304.
Liu, J., Wong, W., et Kong, A. (1994). Covariance structure of the Gibbs
sampler with applications to the comparisons of estimators and sampling
schemes. Biometrika, 81, 27–40.
Liu, J., Wong, W., et Kong, A. (1995). Correlation structure and convergence
rate of the Gibbs sampler with various scans. J. Royal Statist. Soc. Series
B, 57, 157–169.
Liu, J. et Wu, Y. (1999). Parameter expansion scheme for data augmentation.
J. American Statist. Assoc., 94, 1264–1274.
Louis, T. (1997). Discussion of “uniﬁed frequentist and Bayesian testing of a
precise hypothesis”. Statist. Science, 12, 152–155.
Lu, K. et Berger, J. (1989a). Estimated conﬁdence procedures for multivariate
normal means. J. Statist. Plann. Inference, 23, 1–19.
Lu, K. et Berger, J. (1989b). Estimation of normal means : frequentist esti-
mators of loss. Ann. Statist., 17, 890–907.
Maatta, J. et Casella, G. (1990). Developments in decision theoretic variance
estimation (with discussion). Statist. Science, 5, 90–120.
Machina, G. (1982).
Expected utility analysis without the independence
axiom. Econometrica, 50, 277–323.
Machina, G. (1987). Choice under uncertainty : problems solved and unsolved.
Econom. Perspectives, 1, 121–154.
MacLachlan, G. et Basford, K. (1987). Mixture Models. Marcel Dekker, New
York.
MacLachlan, G. et Krishnan, T. (1997). The EM Algorithm and Extensions.
John Wiley, New York.

R´ef´erences
597
Madigan, D. et Raftery, A. (1991). Model selection and accounting for model
uncertainty in graphical models using Occam’s window. Technical report
213, University of Washington.
Madigan, D. et Raftery, A. (1995). Bayesian graphical models for discrete
data. Int. Statist. Rev., 63, 215–232.
Madigan, D. et York, J. (1995). Bayesian graphical models for discrete data.
International Statistical Review, 63, 215–232.
Marin, J., Mengersen, K., et Robert, C. (2004).
Bayesian modelling and
inference on mixtures of distributions.
In Rao, C. et Dey, D., ´editeurs,
Handbook of Statistics, volume 25 (To appear.). Springer-Verlag, New York.
Maritz, J. et Lwin, T. (1989). Empirical Bayes Methods. Chapman and Hall,
New York, seconde ´edition.
Marsaglia, G. et Zaman, A. (1993). The KISS generator. Technical report,
Dept. of Statistics, Univ. of Florida.
McCullagh, P. et Nelder, J. (1989). Generalized Linear Models. Chapman and
Hall, New York.
McCulloch, C. et Rossi, P. (1992). Bayes factors for nonlinear hypotheses and
likelihood distributions. Biometrika, 79, 663–676.
McKeganey, N., Barnard, M., Leyland, A., Coote, I., et Follet, E. (1992).
Female streetworking prostitutes and HIV infection in Glasgow. British
Medical Journal, 305, 801–804.
Meng, X. et Van Dyk, D. (1997). The EM algorithm–an old folk-song sung to
a new tune (with discussion). J. Royal Statist. Soc. Series B, 59, 511–568.
Meng, X. et Van Dyk, D. (1999). Seeking eﬃcient data augmentation schemes
via conditional and marginal augmentation. Biometrika, 86, 301–320.
Meng, X. et Wong, W. (1996). Simulating ratios of normalizing constants via
a simple identity : a theoretical exploration. Statist. Sinica, 6, 831–860.
Mengersen, K. et Robert, C. (1996). Testing for mixtures : A Bayesian entropic
approach (with discussion). In Berger, J., Bernardo, J., Dawid, A., Lindley,
D., et Smith, A., ´editeurs, Bayesian Statistics 5, pages 255–276. Oxford
University Press, Oxford.
Mengersen, K., Robert, C., et Guihenneuc-Jouyaux, C. (1999).
MCMC
convergence diagnostics : a “reviewww”. In Berger, J., Bernardo, J., Dawid,
A., Lindley, D., et Smith, A., ´editeurs, Bayesian Statistics 6, pages 415–440.
Oxford University Press, Oxford.
Mengersen, K. et Tweedie, R. (1995).
Meta-analysis approaches to dose-
response relationships with application in studies of lung cancer and passive
smoking. Statist. Medicine, 14, 545–69.
Mengersen, K. et Tweedie, R. (1996). Rates of convergence of the Hastings
and Metropolis algorithms. Ann. Statist., 24, 101–121.
Metropolis, N., Rosenbluth, A., Rosenbluth, M., Teller, A., et Teller, E. (1953).
Equations of state calculations by fast computing machines. J. Chem. Phys.,
21, 1087–1092.
Metropolis, N. et Ulam, S. (1949). The Monte Carlo method. J. American
Statist. Assoc., 44, 335–341.

598
R´ef´erences
Meyn, S. et Tweedie, R. (1993).
Markov Chains and Stochastic Stability.
Springer-Verlag, New York.
Meyn, S. et Tweedie, R. (1994). Computable bounds for convergence rates of
Markov chains. Ann. Appl. Prob., 4, 981–1011.
Mira, A., Møller, J., et Roberts, G. (2001). Perfect slice samplers. J. Royal
Statist. Soc. Series B, 63, 583–606.
Monahan, J. (1984). A note on enforcing stationarity in autoregressive-moving
average models. Biometrika, 71, 403–404.
Moors, J. (1981). Inadmissibilit´e of linearly invariant estimators in truncated
parameter spaces. J. American Statist. Assoc., 76, 910–915.
Morisson, D. (1979). Purchase intentions and purchase behavior. J. Marke-
ting, 43, 65–74.
Morris, C. (1982). Natural exponential families with quadratic variance func-
tions. Ann. Statist., 10, 65–80.
Morris, C. (1983a). Natural exponential families with quadratic variance func-
tions : statistical theory. Ann. Statist., 11, 515–529.
Morris, C. (1983b). Parametric empirical Bayes inference : theory and appli-
cations. J. American Statist. Assoc., 78, 47–65.
Mosteller, F. et Chalmers, T. (1992). Some progress and problems in meta-
analysis of clinical trials. Statist. Science, 7, 227–236.
Mosteller, F. et Wallace, D. (1984). Applied Bayesian and Classical Inference.
Springer-Verlag, New York.
Mukerjee, R. et Dey, D. (1993). Frequentist validity of posterior quantiles in
the presence of a nuisance parameter : higher order asymptotics. Biome-
trika, 80, 499–505.
M¨uller, P. et Vidakovic, B. (1999).
Bayesian Inference in Wavelet-Based
Models, volume 141 dans Lecture Notes in Statistics. Springer-Verlag, New
York.
Murphy, A.H.and Winkler, R. (1984). Probability forecasting in meteorology.
J. American Statist. Assoc., 79, 489–500.
Musio, M. et Racugno, W. (1999). Discussion of Fernandez and Steel’s paper.
In Bernardo, J., Berger, J., Dawid, A., et Smith, A., ´editeurs, Bayesian
Statistics 6, pages 231–233. Oxford University Press.
Nachbin, L. (1965). The Haar Integral. Van Nostrand, New York.
Naylor, J. et Smith, A. (1982).
Application of a method for the eﬃcient
computation of posterior distributions. Applied Statistics, 31, 214–225.
Neal, R. (1999). Bayesian Learning for Neural Networks, volume 118 dans
Lecture Notes. Springer-Verlag, New York.
Nelson, D. (1990). Stationarity and persistence in the GARCH(1,1) model.
Econometric Theory, 6, 318–334.
Newton, M. et Raftery, A. (1994). Approximate Bayesian inference by the
weighted likelihood boostrap (with discussion). J. Royal Statist. Soc. Series
B, 56, 1–48.

R´ef´erences
599
Neyman, J. (1934). On the two diﬀerent aspects of the representative method :
The method of stratiﬁed sampling and the method of purposive selection.
J. Royal Statist. Soc. Series B, 97, 558–625.
Neyman, J. (1937). ”Smooth” test for goodness of ﬁt. Skand. Aktvariebidokr,
20, 150–199.
Neyman, J. et Pearson, E. (1933a). On the problem of the most eﬃcient tests
of statistical hypotheses. Phil. Trans. Royal Soc. Ser. A, 231, 289–337.
Neyman, J. et Pearson, E. (1933b). The testing of statistical hypotheses in
relation to probabilities a priori. Proc. Cambridge Philos. Soc., 24, 492–510.
Neyman, J. et Scott, E. (1948).
Consistent estimates based on partially
consistent observations. Econometrica, 16, 1–32.
Novick, M. et Hall, W. (1965). A Bayesian indiﬀerence procedure. J. American
Statist. Assoc., 60, 1104–1117.
O’Hagan, A. (1994). Bayesian Inference. Numero 2B dans Kendall’s Advanced
Theory of Statistics. Chapman and Hall, New York.
O’Hagan, A. (1995). Fractional Bayes factors for model comparisons. J. Royal
Statist. Soc. Series B, 57, 99–138.
O’Hagan, A. (1997). Properties of intrinsic and fractional Bayes factors. Test,
6, 101–118.
O’Hagan, A. et Forster, J. (2002).
Bayesian Inference.
Numero 2B dans
Kendall’s Advanced Theory of Statistics. Chapman and Hall, New York,
seconde ´edition.
O’Hagan, A.and Berger, J. (1988). Ranges of posterior probabilities for quasi-
unimodal priors with speciﬁed quantiles. J. American Statist. Assoc., 83,
503–508.
Olkin, I., Petkau, A., et Zidek, J. (1981). A comparison of n estimators for
the binomial distribution. J. American Statist. Assoc., 76, 637–642.
Olver, F. (1974). Asymptotics and Special Functions. Academic Press, New
York.
Osborne, C. (1991). Statistical calibration : a review. International Statistical
Review, 59, 309–336.
Owen, A. et Zhou, Y. (2000). Safe and eﬀective importance sampling. J. Ame-
rican Statist. Assoc., 95, 135–143.
Parent, E., Bob´ee, B., Hubert, P., et Miquel, J. (1998). Statistical and Baye-
sian methods in hydrological sciences.
In Selected Proceedings from the
UNESCO conference in honnor of Pr. Bernier. Unesco. IHP-V Technical
Documents in Hydrology N 20.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems : Networks of
Plausible Inference. Morgan Kaufmann, San Mateo, CA.
Pearson, K. (1894). Contribution to the mathematical theory of evolution.
Proc. Trans. Roy. Soc. A, 185, 71–110.
Peddada, S. et Khattree, R. (1986). On Pitman nearness and variance of
estimators. Comm. Stat., 15, 3005–3018.
Perk, W. (1947). Some observations on inverse probabilities including a new
indiﬀerence rule. J. Inst. Actuaries, 73, 285–312.

600
R´ef´erences
Perron, F. et Giri, N. (1990). On the best equivariant estimator of mean of a
multivariate normal population. Multivariate Anal., 32(4), 1–16.
Petrone, S. et Wasserman, L. (2002). Consistency of Bernstein polynomial
posteriors. J. Royal Statist. Soc. Series B, 64, 79100.
Pettit, L. (1992). Bayes factors for outlier models using the device of imaginary
observations. J. American Statist. Assoc., 87, 541–545.
Pfangzagl, J. (1968). A characterization of the one parameter exponential
family by existence of uniformly most powerful tests. Sankhya, Ser. A, 30,
147–156.
Phillips, D. et Smith, A. (1996). Bayesian model comparison via jump diﬀu-
sions. In Gilks, W., Richardson, S., et Spiegelhalter, D., ´editeurs, Markov
chain Monte Carlo in Practice, pages 215–240. Chapman and Hall, New
York.
Phillips, P. (1991). Bayesian routes and unit roots : de rebus prioribus semper
est disputandum. J. Appl. Econometrics, 6, 435–474.
Pierce, D. (1973). On some diﬃculties in a frequency theory of inference.
Ann. Statist., 1, 241–250.
Pitman, E. (1936). Suﬃcient statistics and intrinsic accuracy. Proc. Cam-
bridge Philos. Soc., 32, 567–579.
Pitman, E. (1937).
The closest estimates of statistical parameters.
Proc.
Cambridge Philos. Soc., 33, 212–222.
Pitman, E. (1939).
The estimation of location and scale parameters of a
continuous population of any given form. Biometrika, 30, 391–421.
Pitt, M. et Shephard, N. (1999). Filtering via simulation : Auxiliary particle
ﬁlters. J. American Statist. Assoc., 94(446), 590–599.
Plessis, B. (1989). Context dependent enhancements for digitized radiographs.
Master’s thesis, Dept. of Electrical Engineering, University of Ottawa.
Poincar´e, H. (1902).
La Science et l’Hypoth`ese.
Flammarion, Paris.
R´eimpression par Champs, 1989.
Poirier, D. (1995). Intermediate Statistics and Econometrics : a Comparative
Approach. Cambridge, Mass.
Pole, A., West, M., et Harrison, J. (1994). Applied Bayesian Forecasting and
Time Series Analysis. Chapman and Hall, New York, New York.
Pollock, K. (1991). Modelling capture, recapture and removal statistics for
estimation of demographic parameters for ﬁsh and wildlife populations :
past, present and future. J. American Statist. Assoc., 86, 225–238.
Popper, K. (1983). Postface to the Logic of Scientiﬁc Discovery, Realism and
Science. Hutchinson, London.
Press, J. (1989). Bayesian Statistics. John Wiley, New York.
Qian, W. et Titterington, D. (1991).
Estimation of parameters in hidden
Markov models. Phil. Trans. Roy. Soc. London A, 337, 407–428.
Racugno, W. (1999). Model Selection. Collana Atti di Congressi. Pitagora
Editrice, Bologna.
Raftery, A. (1988). Inference for the binomial n parameter hierarchical Bayes
approach. Biometrika, 75, 355–363.

R´ef´erences
601
Raftery, A. (1996). Hypothesis testing and model selection. In W.R. Gilks,
S. R. et Spiegelhalter, D., ´editeurs, Markov chain Monte Carlo in Practice,
pages 163–188. Chapman and Hall, New York.
Raftery, A. et Lewis, S. (1992a). How many iterations in the Gibbs sampler ?
In Bernardo, J., Berger, J., Dawid, A., et Smith, A., ´editeurs, Bayesian
Statistics 4, pages 763–773. Oxford University Press, Oxford.
Raftery, A. et Lewis, S. (1992b). The number of iterations, convergence diag-
nostics and generic Metropolis algorithms. Technical report, Department
of Statistics, Univ. of Washington, Seattle.
Raftery, A., Madigan, D., et Volinsky, C. (1996). Accounting for model un-
certainty in survival analysis improves predictive performance (with dis-
cussion).
In Berger, J., Bernardo, J., Dawid, A., Lindley, D., et Smith,
A., ´editeurs, Bayesian Statistics 5, pages 323–349. Oxford University Press,
Oxford.
Raftery, A. et Richardson, S. (1995). Model selection for generalized linear
models via GLIB, with application to epidemiology). In Berry, D. et Stangl,
D., ´editeurs, Bayesian Biostatistics. Marcel Dekker, New York.
Raiﬀa, H. (1968). Decision Analysis : Introductory Lectures on Choices under
Uncertainty. Addison-Wesley, Reading, Mass.
Raiﬀa, H. et Schlaifer, R. (1961). Applied Statistical decision theory. Technical
report, Division of Research, Graduate School of Business Administration,
Harvard Univ.
Rao, C. (1980). Discussion of J. Berkson’s paper ‘Minimum chi-square, not
maximum likelihood’. Ann. Statist., 8, 482–485.
Rao, C. (1981). Some comments on the minimum mean square error as crite-
rion of estimation. In Cs¨orgo, M., Dawson, D., Rao, J., et Saleh, A., ´editeurs,
Statistics and Related Topics, pages 123–143. North Holland, Amsterdam.
Rao, C., Keating, J., et Mason, R. (1986). The Pitman nearness criterion and
its determination. Comm. Statist.-Theory Methods, 15, 3173–3191.
Redner, R. et Walker, H. (1984). Mixture densities, maximum likelihood and
the EM algorithm. SIAM Rev., 26, 195–239.
Richard, J. (1973). Posterior and Predictive Densities for Simultaneous Equa-
tion Models. Springer-Verlag, Berlin.
Richard, J. et Tompa, H. (1980). On the evaluation of poly-t density functions.
Econometrics, 12, 335–351.
Richardson, S. et Green, P. (1997). On Bayesian analysis of mixtures with an
unknown number of components (with discussion). J. Royal Statist. Soc. Se-
ries B, 59, 731–792.
Ripley, B. (1987). Stochastic Simulation. John Wiley, New York.
Ripley, B. (1992). Neural networks. In Barnorﬀ-Nielsen, O., ´editeur, Networks
and Chaos-Statistical and Probabilistic Aspects. Chapman and Hall, New
York.
Rissanen, J. (1983). A universal prior for integers and estimation by minimum
description length. Ann. Statist., 11, 416–431.

602
R´ef´erences
Rissanen, J. (1990). Complexity of models. In Zurek, W., ´editeur, Complexity,
Entropy, and the Physics of Information, volume 8. Addison-Wesley, Rea-
ding.
Robbins, H. (1951). Asymptotically subminimax solutions to compound sta-
tistical decision problems. In Proc. Second Berkeley Symp. Math. Statist.
Probab., volume 1. University of California Press.
Robbins, H. (1955). An empirical Bayes approach to statistics. In Proc. Third
Berkeley Symp. Math. Statist. Probab., volume 1. University of California
Press.
Robbins, H. (1964).
The empirical Bayes approach to statistical decision
problems. Ann. Mathemat. Statist., 35, 1–20.
Robbins, H. (1983). Some thoughts on empirical Bayes estimation. Ann. Sta-
tist., 11, 713–723.
Robert, C. (1990). Modiﬁed Bessel functions and their applications in proba-
bility and statistics. Statist. Prob. Letters, 9, 155–161.
Robert, C. (1991). Generalized inverse normal distributions. Statist. Prob.
Lett., 11, 37–41.
Robert, C. (1993a). A note on the Jeﬀreys-Lindley paradox. Statist. Sinica,
3, 601–608.
Robert, C. (1993b).
Prior Feedback : A Bayesian approach to maximum
likelihood estimation. Comput. Statist., 8, 279–294.
Robert, C. (1995). Simulation of truncated Normal variables. Statistics and
Computing, 5, 121–125.
Robert, C. (1996a). Inference in mixture models. In Gilks, W., Richardson,
S., et Spiegelhalter, D., ´editeurs, Markov Chain Monte Carlo in Practice,
pages 441–464. Chapman and Hall, New York.
Robert, C. (1996b).
Intrinsic loss functions.
Theory and Decision, 40(2),
191–214.
Robert, C. (1998). Performances d’estimateurs `a r´etr´ecisseur en situation de
multicolin´earit´e. Ann. Eco. Stat., 10, 97–119.
Robert, C., Bock, M., et Casella, G. (1990).
Bayes estimators associated
with uniform distributions on spheres (ii) : the hierarchical Bayes approach.
Technical Report Tech. Report BU-1002-M, Cornell University.
Robert, C. et Caron, N. (1996). Noninformative Bayesian testing and neutral
Bayes factors. TEST, 5, 411–437.
Robert, C. et Casella, G. (1990). Improved conﬁdence sets for spherically
symmetric distributions. J. Multivariate Anal., 32, 84–94.
Robert, C. et Casella, G. (1993). Improved conﬁdence statements for the usual
multivariate normal conﬁdence set. In Stat. Decision Theo. Rel. Topics V,
pages 351–368. Springer-Verlag, New York.
Robert, C. et Casella, G. (1994). Distance penalized losses for testing and
conﬁdence set evaluation. Test, 3(1), 163–182.
Robert, C. et Casella, G. (1999). Monte Carlo Statistical Methods. Springer-
Verlag, New York, premi`ere ´edition.

R´ef´erences
603
Robert, C. et Casella, G. (2004). Monte Carlo Statistical Methods. Springer-
Verlag, New York, seconde ´edition.
Robert, C., Celeux, G., et Diebolt, J. (1993a). Bayesian estimation of hidden
Markov models : A stochastic implementation. Statist. Prob. Letters, 16,
77–83.
Robert, C. et Hwang, J. (1996). Maximum likelihood estimation under order
constraints. J. American Statist. Assoc., 91, 167–173.
Robert, C., Hwang, J., et Strawderman, W. (1993b). Is Pitman closeness a
reasonable criterion? (with discussion). J. American Statist. Assoc., 88,
57–76.
Robert, C. et Mengersen, K. (1999).
Reparametrization issues in mixture
estimation and their bearings on the Gibbs sampler. Comput. Statis. Data
Ana., 29, 325–343.
Robert, C. et Reber, A. (1998). Bayesian modelling of a biopharmaceutical
experiment with heterogeneous responses. Sankhya B, 60(1), 145–160.
Robert, C., Ryd´en, T., et Titterington, D. (1999a). Convergence controls for
MCMC algorithms, with applications to hidden Markov chains. J. Statist.
Computat. Simulat., 64, 327–355.
Robert, C., Ryd´en, T., et Titterington, D. (1999b). Jump Markov chain Monte
Carlo algorithms for Bayesian inference in hidden Markov models. J. Royal
Statist. Soc. Series B, 62(1), 57–75.
Robert, C. et Soubiran, C. (1993). Estimation of a mixture model through
Bayesian sampling and prior feedback. TEST, 2, 125–146.
Robert, C. et Titterington, M. (1998). Reparameterisation strategies for hid-
den Markov models and Bayesian approaches to maximum likelihood esti-
mation. Statistics and Computing, 8(2), 145–158.
Roberts, G. et Rosenthal, J. (1998). Markov chain Monte Carlo : Some prac-
tical implications of theoretical results (with discussion). Canadian J. Sta-
tist., 26, 5–32.
Roberts, G. et Sahu, S. (1997). Updating schemes, covariance structure, blo-
cking and parametrisation for the Gibbs sampler. J. Royal Statist. Soc. Se-
ries B, 59, 291–318.
Roberts, G. et Tweedie, R. (2005). Understanding MCMC. Springer-Verlag,
New York.
Robertson, T., Wright, F., et Dykstra, R. (1988). Order Restricted Statistical
Inference. John Wiley, New York.
Robins, J. et Ritov, Y. (1997). A curse of dimensionality appropriate (coda)
asymptotic for semiparametric models. Statist. Medicine, 16, 285–319.
Robins, J. et Wasserman, L. (2000). Conditioning, likelihood and concepts :
A review of some foundational concepts. J. American Statist. Assoc., 95,
1340–1346.
Robinson, G. (1979).
Conditional properties of statistical procedures.
Ann. Statist., 7, 742–755.

604
R´ef´erences
Robinson, G. (1982). Behrens-Fisher problem. In Kotz, S. et Johnson, N.,
´editeurs, Encyclopedia of Statistical Sciences, volume 1, pages 205–209. wi-
ley, New York.
Roeder, K. (1992). Density estimation with conﬁdence sets exempliﬁed by
superclusters and voids in galaxies. J. American Statist. Assoc., 85, 617–
624.
Roeder, K. et Wasserman, L. (1997). Practical Bayesian density estimation
using mixtures of normals. J. American Statist. Assoc., 92, 894–902.
Romano, J. et Siegel, A. (1986). Counterexamples in Probability and Statistics.
Wadsworth, Belmont, CA.
Rousseau, J. (1997). Performances fr´equentistes des lois de r´ef´erence et pro-
pri´et´es asymptotiques des proc´edures bay´esiennes. Th`ese de doctorat, Uni-
versit´e Paris VI.
Rousseau, J. (2000). Coverage properties of one-sided intervals in the discrete
case and application to matching priors. Ann. Inst. Statist. Math., 52(1),
28–42.
Rousseau, J. (2001). Asymptotic coverage of joint two-sided conﬁdence inter-
vals. Scan. J. Statist. (To appear.).
Rubin, D. (1984). Bayesianly justiﬁable and relevant frequency calculations
for the applied statistician. Ann. Statist., 12, 1151–1172.
Rubin, D. (1987). Multiple Imputation for Nonresponse in Surveys.
John
Wiley, New York.
Rubin, D., Umbach, D., Shyu, S., et Castillo-Chavez, C. (1992). Using mark-
recapture methodology to estimate the size of a population at risk for
sexually transmitted diseases. Statist. Medicine, 11, 1533–1549.
Rubinstein, R. (1981). Simulation and the Monte Carlo Method. John Wiley,
New York.
Rudin, W. (1976). Principles of Real Analysis. McGraw-Hill, New York.
Rue, H. (1995). New loss functions in Bayesian imaging. J. American Sta-
tist. Assoc., 90, 900–908.
Rukhin, A. (1978). Universal Bayes estimators. Ann. Statist., 6, 345–351.
Rukhin, A. (1988a). Estimated loss and admissible loss estimators. In Gupta,
S. et Berger, J., ´editeurs, Statistical Decision Theory and Related Topics
IV, pages 409–420. Springer-Verlag, New York.
Rukhin, A. (1988b). Loss functions for loss estimations. Ann. Statist., 16,
1262–1269.
Rukhin, A. (1995). Admissibility : Survey of a concept in progress. Interna-
tional Statistical Review, 63, 95–115.
Santner, T. et Duﬀy, D. (1989). The Statistical Analysis of Discrete Data.
Springer-Verlag, New York.
Savage, L. (1954). The Foundations of Statistical Inference. John Wiley, New
York.
Saxena, K. et Alam, K. (1982). Estimation of the non-centrality parameter
of a chi-squared distribution. Ann. Statist., 10, 1012–1016.

R´ef´erences
605
Schaafsma, W., Tolboom, J., et Van der Meulen, B. (1989). Discussing truth
or falsity by computing a q-value. In Dodge, Y., ´editeur, Statistics, Data
Analysis and Informatics. North-Holland, Amsterdam.
Schervish, M. (1989). A general method for comparing probability assessors.
Ann. Statist., 17, 1856–1879.
Schervish, M. (1995). Theory of Statistics. Springer-Verlag, New York.
Schwarz, G. (1978). Estimating the dimension of a model. Ann. Statist., 6,
461–464.
Seber, G. (1983). Capture-recapture methods. In Kotz, S. et Johnson, N.,
´editeurs, Encyclopedia of Statistical Science. John Wiley, New York.
Seber, G. (1986). A review of estimation of animal abundance. Biometrika,
42, 267–292.
Seidenfeld, T. (1987). Entropy and uncertainty. In MacNeill, I. et Umphrey,
G., ´editeurs, Foundations of Statistical Inference, pages 259–287. Reidel,
Boston.
Seidenfeld, T. (1992). R.A. Fisher’s ﬁducial argument and Bayes’ theorem.
Statist. Science, 7(3), 358–368.
Sen, P., Kubokawa, T., et Saleh, A. (1989). The Stein paradox in the sense
of Pitman measure of closeness. Ann. Statist., 17, 1375–1384.
Seneta, E. (1993). Lewis Carroll’s pillow problems. Statist. Science, 8, 180–
186.
Severini, T. (1991). On the relationship between Bayesian and non-Bayesian
interval estimates. J. Royal Statist. Soc. Series B, 53, 611–618.
Shafer, G. (1996). Art of Causal Conjecture. MIT, Press, MIT, Cambridge.
Shannon, C. (1948). A mathematical theory of communication. Bell System
Tech. J., 27, 379–423 et 623–656.
Shao, J. et Strawderman, W. (1996). Improving on the James-Stein positive-
part estimator. Statistica Sinica, 6(1), 259–274.
Shinozaki, N. (1975). Admissibility. PhD thesis, Keio University.
Shinozaki, N. (1980). Estimation of a multivariate normal mean with a class
of quadratic loss. J. American Statist. Assoc., 75, 973–976.
Shinozaki, N. (1984). Simultaneous estimation of location parameters under
quadratic loss. Ann. Statist., 12, 322–335.
Shinozaki, N. (1990). Improved conﬁdence sets for the mean of a multivariate
normal distribution. Ann. Inst. Statist. Math., 41, 331–346.
Shorrock, G. (1990). Improved conﬁdence intervals for a normal variance.
Ann. Statist., 18, 972–980.
Sivaganesan, S. et Berger, J. (1989). Ranges of posterior measures for priors
with unimodal contaminations. Ann. Statist., 17, 868–889.
Smith, A. (1973). A general Bayesian linear model. J. Royal Statist. Soc. Se-
ries B, 35, 67–75.
Smith, A. (1984). Present position and potential developments : some personal
view on Bayesian statistics. J. Royal Statist. Soc. Series B, 147, 245–259.
Smith, A. et Makov, U. (1978). A quasi-Bayes sequential procedure for mix-
tures. J. Royal Statist. Soc. Series B, 40, 106–112.

606
R´ef´erences
Smith, A., Sken, A., Shaw, J., Naylor, J., et Dransﬁeld, M. (1985). The im-
plementations of the Bayesian paradigm. Comm. Statist.-Theory Methods,
14, 1079–1102.
Smith, A. et Spiegelhalter, D. (1982). Bayes factors for linear and log-linear
models with vague prior information. J. Royal Statist. Soc. Series B, 44,
377–387.
Smith, J. (1988). Decision Analysis : A Bayesian Approach. Chapman and
Hall, New York.
Spiegelhalter, D., Best, N., et Carlin, B. (1998). Bayesian deviance, the ef-
fective number of parameters and the comparison of arbitrarily complex
models. Technical report, MRC Biostatistics Unit.
Spiegelhalter, D. et Cowell, R. (1992). Learning in probabilistic expert sys-
tems. In Bernardo, J., Berger, J., Dawid, A., Lindley, D., et Smith, A.,
´editeurs, Bayesian Statistics 4, pages 447–460. Oxford University Press,
Oxford.
Spiegelhalter, D., Dawid, A., Lauritzen, S., et Cowell, R. (1993). Bayesian
analysis in expert systems (with discussion). Statist. Science, 8, 219–283.
Spiegelhalter, D. et Lauritzen, S. (1990). Sequential updating of conditional
probabilities on directed graphical structures. Networks, 20, 579–605.
Spiegelhalter, D. et Smith, A. (1980). Bayes factors and choice criteria for
linear models. J. Royal Statist. Soc. Series B, 42, 215–220.
Spiegelhalter, D., Thomas, A., Best, N., et Gilks, W. (1995a). BUGS : Baye-
sian inference using Gibbs sampling. Technical report, Medical Research
Council Biostatistics Unit, Institute of Public Health, Cambridge Univ.
Spiegelhalter, D., Thomas, A., Best, N., et Gilks, W. (1995b).
BUGS
examples. Technical report, MRC Biostatistics Unit, Cambridge Univ.
Spiegelhalter, D., Thomas, A., Best, N., et Gilks, W. (1995c). BUGS examples.
Technical report, MRC Biostatistics Unit, Cambridge Univ.
Spiegelhalter, D. J., Best, N., B.P., C., et Van der Linde, A. (2002). Bayesian
measures of model complexity and ﬁt.
Journal of the Royal Statistical
Society, Series B, 64, 583–640.
Srinivasan, C. (1981). Admissible generalized Bayes estimators and exterior
boundary value problems. Sankhya, 43(Ser. A), 1–25.
Srivastava, M. et Bilodeau, M. (1988). Estimation of the MSE matrix of the
Stein estimator. Canadian J. Statist., 16, 153–159.
Stein, C. (1955a). Inadmissibility of the usual estimator for the mean of a
multivariate normal distribution.
In Proc. Third Berkeley Symp. Math.
Statist. Probab., volume 29, pages 197–206. University of California Press.
Stein, C. (1955b).
A necessary and suﬃcient condition for admissibility.
Ann. Statist., 26, 518–522.
Stein, C. (1959). An examination of wide discrepancy between ﬁducial and
conﬁdence intervals. Ann. Statist., 30, 877–880.
Stein, C. (1962a).
Conﬁdence sets for the mean of a multivariate normal
distribution (with discussion). J. Royal Statist. Soc. Series B, 24, 573–610.

R´ef´erences
607
Stein, C. (1962b).
A remark on the likelihood principle.
J. Royal Sta-
tist. Soc. Series B, 125, 565–568.
Stein, C. (1965). Approximation of improper prior measures by prior probabi-
lity measures. In Bernoulli, Bayes, Laplace Anniversary Volume. Springer-
Verlag, New York.
Stein, C. (1973). Estimation of the mean of a multivariate distribution. In
H`ajek, J., ´editeur, Proceedings of the Prague Symposium on Asymptotic
Statistics, pages 345–81. Charles University.
Stein, C. (1981).
Estimation of the mean of a multivariate distribution.
Ann. Statist., 9, 1135–1151.
Stephens, M. (1997). Bayesian methods for mixtures of normal distributions.
PhD thesis, Oxford University.
Stephens, M. (2000). Bayesian analysis of mixture models with an unknown
number of components-an alternative to reversible jump methods. Ann. Sta-
tist., 28, 40–74.
Steward, G. (1987). Collinearity and least-squares regression. Statist. Science,
2, 68–100.
Stigler, S. (1986). The History of Statistics. Belknap, Cambridge.
Stone, M. (1976). Strong inconsistency from uniform priors (with discussion).
J. American Statist. Assoc., 71, 114–125.
Strasser, H. (1985). Mathematical Theory of Statistics. W. de Gruyter, Berlin.
Strawderman, W. (1971). Proper Bayes minimax estimators of the multiva-
riate normal mean. Ann. Mathemat. Statist., 42, 385–388.
Strawderman, W. (1974).
Minimax estimation of location parameters for
certain spherically symmetric distributions. Multivariate Anal., 42, 255–
264.
Strawderman, W. (2000). Minimaxity. J. American Statist. Assoc., 95, 1364–
1368.
Sweeting, T. (1985). Consistent prior distributions for transformed models.
In Bernardo, J., DeGroot, M., Lindley, D., et Smith, A., ´editeurs, Bayesian
Statistics 2, pages 755–762. Elsevier Science Publishers, Amsterdam.
Tanner, M. et Wong, W. (1987). The calculation of posterior distributions by
data augmentation. J. American Statist. Assoc., 82, 528–550.
Thatcher, A. (1964). Relationships between Bayesian and conﬁdence limits
in prediction. J. Royal Statist. Soc. Series B, 26, 176–210.
Thisted, R. et Efron, B. (1987). Did Shakespeare write a newly-discovered
poem ? Biometrika, 74, 445–468.
Thompson, P. (1989). Admissibility of p-value rules. PhD thesis, Dept. Sta-
tistics.
Tibshirani, R. (1989).
Noninformative priors for one parameter of many.
Biometrika, 76, 604–608.
Tierney, L. et Kadane, J. (1986). Accurate approximations for posterior mo-
ments and marginal densities. J. American Statist. Assoc., 81, 82–86.

608
R´ef´erences
Tierney, L., Kass, R., et Kadane, J. (1989). Fully exponential Laplace approxi-
mations to expectations and variances of non-positive functions. J. Ameri-
can Statist. Assoc., 84, 710–716.
Tierney, L. et Mira, A. (1998).
Some adaptive Monte Carlo methods for
Bayesian inference. Statistics in Medicine, 18, 2507–2515.
Titterington, D., Smith, A., et Makov, U. (1985). Statistical Analysis of Finite
Mixture Distributions. John Wiley, New York.
Tong (1991). Non-linear Time Series : a Dynamical Systems Approach. Ox-
ford Press University, Oxford.
Torrie, G. et Valleau, J. (1977). Nonphysical sampling distributions in Monte
Carlo free-energy estimation : Umbrella sampling.
J. Comp. Phys., 23,
187–199.
Van Eeden, C. et Zidek, J. (1993).
Group Bayes estimation of the expo-
nential mean : a retrospective view of the Wald theory. In Stat. Decision
Theo. Rel. Topics V, pages 35–50. Springer-Verlag, New York.
Venn, J. (1886). The Logic of Chance. Macmillan, London.
Verdinelli, I. et Wasserman, L. (1992). Bayesian analysis of outliers problems
using the Gibbs sampler. Statist. Comput., 1, 105–117.
Verdinelli, I. et Wasserman, L. (1998). Bayesian goodness-of-ﬁt testing using
inﬁnite-dimensional exponential families. Ann. Statist., 26, 1215–1241.
Villegas, C. (1977). On the representation of ignorance. J. American Sta-
tist. Assoc., 72, 651–654.
Villegas, C. (1990). Bayesian inference in models with Euclidian structure.
J. American Statist. Assoc., 85, 1159–1164.
von Neumann, J. (1951). Various techniques used in connection with random
digits. J. Resources of the National Bureau of Standards–Applied Mathe-
matics Series, 12, 36–38.
von Neumann, J. et Morgenstern, O. (1947). Theory of Games and Economic
Behavior. Princeton University Press, Princeton, seconde ´edition.
Wakeﬁeld, J., Gelfand, A., et Smith, A. (1991). Eﬃcient generation of random
variates via the ratio-of-uniforms method. Statistics and Computing, 1, 129–
133.
Wald, A. (1950). Statistical Decision Functions. John Wiley, New York.
Wallace, C. et Boulton, D. (1975).
An invariant Bayes method for point
estimation. Classiﬁcation Society Bulletin, 3, 11–34.
Walley, P. (1991). Statistical Reasoning with Imprecise Probability. Chapman
and Hall, New York.
Wasserman, L. (1992). Recent methodological advances in robust Bayesian
inference. In Bernardo, J., Berger, J., Dawid, A., Lindley, D., et Smith,
A., ´editeurs, Bayesian Statistics 4, pages 483–490. Oxford University Press,
Oxford.
Wasserman, L. (1999).
Asymptotic inference for mixture models by using
data-dependent priors. J. Royal Statist. Soc. Series B, 61(1), 159–180.
Welch, B. (1965). On comparisons between conﬁdence point procedures in
the case of a single parameter. J. Royal Statist. Soc. Series B, 27, 1–8.

R´ef´erences
609
Welch, B. et Peers, H. (1963). On formulae for conﬁdence points based on
integrals of weighted likelihoods. J. Royal Statist. Soc. Series B, 25, 318–
329.
Wells, M. (1992). Private communication.
West, M. et Harrison, J. (1998). Bayesian Forecasting and Dynamic Models.
Springer-Verlag, New York, seconde ´edition.
Whittaker, J. (1990).
Graphical Models in Applied Multivariate Statistics.
John Wiley, Chichester.
Wijsman, R. (1990). Invariant measures on groups and their use in statistics.
In IMS lecture notes-Monographs Series. Hayward, California.
Wilkinson, G. (1977). On resolving the controversy in statistical inference.
J. Royal Statist. Soc. Series B, 39, 119–171.
Wolter, W. (1986). Some coverage error models for census data. J. American
Statist. Assoc., 81, 338–346.
Yao, J. et Attali, J. (2000).
On stability of nonlinear AR processes with
Markov switching. Applied Probability, 32, 394–407.
Zabell, S. (1989). Fisher on the history of inverse probability. Statist. Science,
4, 247–263.
Zabell, S. (1992). Fisher and the ﬁducial argument. Statist. Science, 7, 369–
387.
Zellner, A. (1971). An Introduction to Bayesian Inference in Econometrics.
John Wiley, New York.
Zellner, A. (1984). Basic Issues in Econometrics. University of Chicago Press,
Chicago.
Zellner, A. (1986a). Bayesian estimation and prediction using asymmetric loss
functions. J. American Statist. Assoc., 81, 446–451.
Zellner, A. (1986b).
On assessing prior distributions and Bayesian regres-
sion analysis with G–priors distributions.
In Goel, P. et Zellner, A.,
´editeurs, Bayesian Inference and Decision Techniques, pages 233–243. El-
sevier North-Holland, Amsterdam.
Zidek, J. (1965). A representation of Bayes invariant procedures in terms of
Haar measure. Ann. Inst. Statist. Math., 21, 291–308.
Zidek, J. (1970). Suﬃcient conditions for the admissibility under squared error
loss of formal Bayes estimators. Ann. Mathemat. Statist., 41, 1444–1447.
Zucchini, W. (1999). Frequentist model choice. Technical report, Cagliari,
Sardinia. Summer school on Model Choice.

Index des noms
Abraham, C., 92, 152, 153
Abramovich, F., 52
Abramowitz, M., 161, 165, 314, 547
Adams, M., 398
Aitkin, M., 249, 250, 252, 288, 380
Akaike, H., 22, 176, 380
Alam, K., 24, 107, 108, 146, 165, 189,
307, 445, 492, 518, 543
Albert, J.H., 502
Anderson, T.W., 109, 203
Andrieu, C., 549
Angers, J.F., 154, 199, 498, 512
Arrow, K.S., 63, 91
Attali, J.G., 209
Balakrishnan, N., 563
Bar-Lev, S., 130
Baranchick, A.J., 107
Barbieri, M., 408
Barnard, G.A., 17
Barnett, G., 211, 214
Barron, A., 54, 406, 407
Bartlett, M.S., 149, 173
Basford, K., 364
Basu, D., 40, 179
Baum, L.E., 358
Bauwens, L., 33, 44, 154, 206, 210, 228,
230, 232, 234, 235, 549
Bayarri, M.J., 70
Bayes, T., 10–14, 50
Bechofer, R.E., 230
Bensmail, H., 364
Beran, R., 493
Berg´e, P., 2
Berger, J.O., 8, 17, 20, 22, 31, 37,
38, 51, 63, 71, 76, 79, 86,
87, 100, 102, 107–109, 117,
120, 136, 141, 143, 145–147,
151–155, 166, 177–179, 182,
186, 191, 201, 216, 230, 232,
246, 250–254, 257, 258, 265,
267–271, 273, 277, 280, 282,
283, 286, 290, 291, 297, 298,
301, 302, 313, 342, 370, 376,
378, 381, 398, 409, 426, 430,
433, 436, 445, 446, 448, 453,
456, 465, 472, 475, 479, 482,
483, 485, 490, 498, 502, 503,
506, 509, 511, 515, 517, 519,
525, 529, 531, 533–535, 539,
550, 557, 561, 563
Berger, R., 84, 220, 245, 271–273, 276,
290, 291, 295, 299
Bergman, N., 182
Berliner, L.M., 152, 153, 155, 525
Bernardo, J.M., 50, 65, 91, 116, 141,
143, 145–147, 170, 171, 227,
250, 401, 503, 557, 561
Berry, D.A., 549
Berry, S.M., 48
Bertrand, J., 50, 114
Besag, J., 338, 339, 384, 549
Best, N.G., 329, 360, 361, 381–384, 410,
411, 549
Bhattacharya, R.N., 149
Bickel, P.J., 80, 149, 173

612
Index des noms
Billingsley, P., 38, 353
Billio, M., 214, 364
Bilodeau, M., 108
Binder, D., 357
Birnbaum, A., 17, 20
Bjørnstad, J., 22
Blackwell, D., 76, 435, 484
Blattberg, R.C., 206, 529
Blyth, C.R., 63, 111, 279, 436
Bob´ee, B., 549
Bock, M.E., 80, 107–109, 186, 187, 223,
225, 446, 493, 518, 540
B¨ohning, D., 520
Bondar, J.V., 108, 429, 480–482
Boole, G., 114
Bose, S., 111
Boukai, B., 268, 302
Boulton, D.M., 90
Box, G.E.P., 22, 208, 211, 215, 346, 549
Brandwein, A.C., 107–109, 187
Brewster, J.F., 527
Brockwell, P.J., 208, 213, 215, 228, 229
Broniatowski, M., 365
Brown, L.D., 71, 73, 76, 79, 92, 93,
102, 106, 108, 109, 125, 127,
131, 136, 158, 171, 187, 191,
226, 275, 281, 297, 298, 301,
302, 423, 429–432, 435, 436,
440–447, 450, 455, 512, 515,
531, 558
Buehler, R.J., 300, 492
Capp´e, O., 213, 319, 342, 418, 420
Carlin, B.P., 122, 150, 313, 381–384,
391–393, 410, 411, 519, 520,
524, 550, 557
Carlin, J.B., 388, 498, 503, 507, 557
Caron, N., 291, 299
Carota, C., 377
Carriquiry, A., 550
Carter, G., 525
Casella, G., 2, 8, 15, 16, 23, 34, 41, 45,
47, 53, 63, 76, 80, 84, 86, 95,
108, 109, 179, 191, 206, 220,
234, 245, 266, 271–277, 280,
282–284, 288, 290–293, 295,
296, 299, 300, 306, 313–316,
319, 322–366, 380, 388, 394,
426, 455, 457, 458, 460, 507,
513, 518, 523, 527, 529–531,
537, 542, 544
Castillo-Chavez, C., 354
Castledine, B., 195, 222
Castro, I., 406, 415
Celeux, G., 45, 344, 357, 364, 365, 382
Cellier, D., 108, 109, 450, 518
Chalmers, T.C., 28, 496
Chamberlain, G., 58
Chen, J., 282, 319
Chen, M.H., 385, 387, 411, 412
Chernoﬀ, H., 230
Chib, S., 214, 371, 390–393
Chickering, D.M., 549
Chow, M.S., 146, 171, 445
Chrystal, G., 114, 221
Chuang, D., 190
Clarke, B., 147
Clayton, D.G., 549
Clevenson, M., 431, 454
Cliﬀord, M.S., 352
Clyde, M., 398, 399, 413
Cohen, A., 282, 283
Congdon, P., 550
Conigliani, C., 406, 415
Cornﬁeld, J., 203, 204
Cowell, R.G., 341, 375, 544, 545, 549
Cowles, M.K., 361
Cox, D.R., 6, 20, 49, 199
Crawford, S.L., 342
Cressie, N., 375, 384
Dacunha-Castelle, D., 381
Dalal, S.R., 137, 169, 172, 442, 496
Dale, A.I., 50
Damien, P., 339
Darroch, J., 196
Das Gupta, A., 108, 152, 431, 448
Datta, G.S., 149
Daur´es, J.P., 92, 152, 153
Davis, P.A., 208, 213, 215, 228, 229
Dawid, A.P., 116, 151, 163–165, 341,
375, 382, 492, 544–546, 549
Deely, J.J., 229, 230, 498, 519, 525
DeGroot, M.H., 58, 60, 63, 70, 94, 116,
170, 248, 342
Delampady, M., 152, 246, 268, 270, 271,
286, 290, 488
Dellaportas, P., 546

Index des noms
613
Dempster, A.P., 23, 342, 365, 496
Denison, D.G.T., 550
DeRobertis, L., 153
Dette, H., 27, 42
Devroye, L., 2, 316, 520
Dey, D., 9, 149, 381, 386
Diaconis, P., 47, 48, 54, 124, 130, 131,
133, 163, 173, 176, 193, 314,
442, 496
DiCiccio, T.J., 149, 173, 174
Dickey, J.M., 129, 185, 308, 361, 504
Diebolt, J., 331, 352, 357, 365, 379, 460
Doucet, A., 182, 306, 319, 549
Dransﬁeld, M., 314, 322
Draper, D., 498
Dr`eze, J.H., 154, 234
Dudewicz, E.J., 230
Duﬀy, D., 217
Dumouchel, W.M., 498
Dupuis, J.A., 115, 116, 156, 196,
400–402, 404, 421
Dykstra, R.L., 23, 39, 179
Dynkin, E.B., 158
Eaton, M.L., 108, 109, 203, 432, 433,
460, 461, 465, 472, 473,
475–479, 487, 489
Eberly, L., 280
Eco, U., 398
Efron, B., 15, 101, 112, 198, 528
Eichenauer, J., 81
Engle, R.F., 233
Enis, P., 130
Escobar, M.D., 9, 367, 371
Evans, M., 21
Fabius, J., 52
Fang, K.T., 109
Farrel, R., 277
Farrell, R.H., 86, 274–277, 292, 441,
446, 457
Feller, W., 129, 217, 431
Ferguson, T.S., 9, 52, 58, 76, 220, 435
Fernandez, C., 44
Feyerabend, P., 553
Field, A., 6
Fieller, E.C., 47, 295
Fienberg, S., 70, 116
Finetti, B., de, 51, 124, 171
Fishburn, P.C., 58, 62
Fisher, R.A., 9, 16, 17, 22, 36, 50, 51,
140, 266
Fishman, G.S., 316
Fitzgerald, W.J., 549
Forbes, F., 382
Forster, J.J., 546, 557
Foster, D.P., 226, 413, 414
Fouley, J.L., 498
Fourdrinier, D., 82, 86, 108, 109, 148,
450, 518, 546, 547
Fraisse, A.M., 108, 445, 449, 456, 457
Francq, C., 209
Fraser, D.A.S., 21, 177
Freedman, D.A., 54, 176
Freitas, N., de, 319
Gassiat, E., 381
Gatsonis, C., 80, 220, 550
Gauss, C.F., 14, 57, 85, 198
Geisser, S., 203, 204
Gelfand, A.E., 237, 332, 333, 336, 337,
339, 342, 372, 373, 381, 386,
389, 390, 524
Gelman, A., 325, 361, 388, 417, 418,
498, 503, 507, 550, 557
Geman, D., 329, 549
Geman, S., 329, 549
Genest, C., 91
Gentle, J.E., 2, 316
George, E.I., 107–109, 186, 195, 196,
206, 226, 282, 310, 330,
333, 338, 399, 413, 414, 498,
529–531, 540
Geweke, J., 354, 361, 549
Geyer, C.J., 179, 306, 324, 333
Ghosh, J.K., 149
Ghosh, M., 108, 111, 147–150, 173, 206,
224, 529
Gianola, D., 498
Gibbons, J.D., 230
Gilks, W.R., 323, 329, 347, 360, 549,
550
Gill, J., 550
Gill, R.D., 182
Gini, C., 51
Giri, N., 479
Girshick, M.A., 76, 435, 484
Giudici, P., 546

614
Index des noms
Givens, G.H., 28, 496
Gleick, J., 2
Gleser, L.J., 295, 409, 479
Godsill, S.J., 306
Godwill, S., 549
Goel, P.K., 229, 231
Goldstein, M., 513
Good, I.J., 117, 152, 155, 242, 245, 501,
538, 559
Gordon, N.J., 182, 319
Gouri´eroux, C., 36, 173, 226, 233, 380,
388, 403
Goutis, C., 121, 154, 266, 282, 300, 399,
400, 402, 403
Green, P.J., 53, 339, 365, 371, 379, 393,
394, 546
Greenberg, E., 214
Grenander, U., 53, 395, 418
Gruet, M.A., 342, 394–396
Gr¨unwald, P., 549
Guihenneuc-Jouyaux, C., 235, 496, 498
Guillin, A., 319
Gupta, S.S., 229, 230
Gutmann, S., 108
Gy¨orﬁ, L., 520
Hadjicostas, P., 48
Haﬀ, L., 108
H`ajek, J., 6
Hald, A., 50
Haldane, J., 32, 177, 280
Hall, P., 15
Hall, W.J., 32, 137, 169, 172, 442, 496
Hamilton, J.D., 209
Hammersley, J.M., 352
Hansen, M., 151
Harris, J.E., 498
Harrison, J., 210, 213, 550
Hartigan, J.A., 31, 153, 265, 280, 294,
536–538
Has’minskii, R., 51, 54, 176, 555
Hastings, W.K., 325, 327
Healy, J.D., 479
Heath, D., 8
Heckerman, D., 549
Heidelberger, P., 361
Heitjan, D.F., 359
Helland, I.S., 492, 493
Hesterberg, T., 386
Hills, S., 314
Hinkley, D., 49, 302
Hjort, N.L., 52
Hoaglin, D., 416
Hobert, J.P., 34, 45, 53, 325, 363, 459,
460, 498
Hodges, J.S., 550
Hoerl, A., 513
Holmes, C.C., 550
Hora, R.B., 492
Huber, P.J., 88, 153
Hubert, P., 549
Huerta, G., 211
Hui, S., 525
Hurn, M.A., 45, 344, 365
Hutchinson, D., 279
Hwang, J.T.G., 23, 85, 86, 92, 93, 103,
104, 108, 111, 112, 146, 179,
191, 274–277, 282–284, 292,
295, 296, 409, 423, 429, 430,
436, 447, 450, 455, 457, 458,
529, 542
Ibragimov, I., 51, 54, 176, 555
Ibrahim, J., 319, 385, 387, 412
Im, S., 498
Jacquier, E., 233, 549
James, W., 107, 110, 129, 447
Jaynes, E.T., 118, 163, 164, 560
Jeﬀerys, W., 398
Jeﬀreys, H., 50, 51, 67, 114, 116, 117,
125, 139, 141, 193, 221, 224,
241, 242, 250, 264, 265, 376,
398, 557
Jenkins, G.M., 208, 211, 215
Johnson, B.M., 451, 457
Johnson, N.L., 563
Johnstone, D.J., 289
Johnstone, I.M., 80, 102, 108, 191, 430,
432
Johnstone, R.W., 108
Jones, M.C., 214
Jordan, R., 1, 55, 113, 175, 237, 305,
369, 423, 463, 495, 549
Joshi, V.M., 177, 281, 282, 542
Judge, G., 107, 446
Kadane, J.B., 190, 320–322, 342, 349

Index des noms
615
Kariya, T., 479
Karlin, S., 260, 426, 455
Kass, R.E., 119, 137–139, 143, 147,
151, 156, 166, 173, 242, 243,
320–322, 349, 378, 381, 529,
550
Keating, J.P., 111
Keeney, R.L., 64
Kelker, D., 35, 109
Kemp, A.W., 563
Kemperman, J., 47, 48
Kempthorne, P.J., 80, 81, 155, 442, 561
Kendall, M., 523
Kennard, R., 513
Keynes, J.M., 50
Khattree, R., 111
Kiefer, J., 84, 267, 285, 300, 301, 479
Kiiveri, H., 544
King, A., 333
Kirby, A.J., 497, 549
Kleibergen, F., 233
Kohn, R., 211, 214
Kokaram, A.C., 549
Kolmogorov, A., 50
Kong, A., 337
Kontkanen, P., 549
Koo, J.O., 230
Koopman, B., 125
Kotz, S., 563
Krishnan, T., 23, 365
Kubokawa, T., 47, 108, 111, 112, 227,
517, 527, 539, 541
Lad, F., 50
Laird, N.M., 23, 342, 365, 524
Laplace, P.S., 10–14, 22, 32, 50, 57, 64,
87, 137, 177, 192, 193, 198,
319
Lasserre, V., 496, 498
Lauritzen, S.L., 158, 341, 375, 497, 533,
544–546, 549
Lavielle, M., 365
Lavine, M., 52
Lawley, D.N., 173
Le Cam, L., 76, 136, 177, 482
Lee, T.M., 237
Legendre, A., 14, 85
Lehmann, E.L., 6, 8, 15, 16, 23, 34, 47,
76, 107, 109, 258, 260–263,
281, 298, 300, 301, 380, 425,
426, 450, 473, 474, 479, 482,
484, 486, 487, 555
Lehn, J., 81
Lenk, P., 4, 5, 371, 406
Leonard, T., 322
Letac, G., 127, 130
Levit, B.Y., 182
Lewis, S., 325, 361
Lindley, D.V., 11, 15, 31, 32, 51, 57, 85,
114, 116, 148, 155, 203, 204,
224, 265, 274, 281, 289, 297,
298, 320, 498, 501, 504, 509,
512, 513, 519, 525, 534, 557
Liseo, B., 149, 408
Liu, J.S., 333, 337, 363
Louis, T.A., 122, 302, 313, 519, 520,
524, 550, 557
Lu, K., 86, 108, 109, 191, 282, 531
Lubrano, M., 206, 210, 228, 230, 232,
234, 235, 549
Lwin, T., 519, 521, 524, 525
Maatta, J., 300, 527
MacGibbon, B.K., 80, 154, 220, 498
Machina, G., 58
MacLachlan, G., 23, 364, 365
Madigan, D., 396–398, 413, 544, 546
Makita, S., 541
Makov, U.E., 345, 364
Mallick, B.K., 550
Marin, J.M., 53, 319, 365
Maritz, J.S., 519, 521, 524, 525
Marsaglia, G., 360
Mason, R., 111
McCullagh, P., 382, 388, 408, 420, 502
McCulloch, R.E., 399, 401, 550
McNeil, A.J., 549
Meng, X.L., 363, 365, 387, 388, 417, 418
Mengersen, K.L., 28, 45, 53, 235, 329,
356, 365, 366, 371, 379, 401,
496
Metropolis, N., 315, 323, 325
Meyn, S.P., 207, 208, 323, 324, 431
Miller, M.I., 53, 395, 418
Milnes, P., 480–482
Miquel, J., 549
Mira, A., 340
Møller, J., 340

616
Index des noms
Monahan, J.F., 211
Monette, G., 21, 177
Monfort, A., 36, 173, 214, 226, 364, 380,
388, 403
Moors, J.J.A., 457
Mora, M., 127
Morales, J.A., 154
Morgenstern, O., 58
Morisson, D., 523
Morita, S., 541
Morris, C., 127, 159, 314, 345, 519, 521,
527, 528, 538
Mortera, J., 268
Mosteller, F., 28, 193, 198, 416, 496
Moulines, E., 213, 319, 365
Mukerjee, R., 147–149
M¨uller, P., 9, 52, 314
Muller, M., 346
Murphy, A.H., 70
Musio, M., 44
Myllym¨aki, T., 549
Nachbin, L., 475, 479
Nagakura, K., 541
Naylor, J.C., 314, 322
Neal, R.M., 549
Nelder, J., 382, 388, 408, 420, 502
Nelson, D.B., 233
Neumann, J., von, 58, 315
Newton, M.A., 386
Neyman, J., 18, 51, 71, 89, 192, 405, 415
Ng, K.W., 177
Novick, M.R., 32
O’Hagan, A., 152, 153, 255, 256, 406,
415, 557
Occam, W., d’, 398
Olkin, I., 40, 230
Olver, F.W.J., 320
Osborne, C., 47, 227
Owen, A., 386
Panchapakesan, S., 230
Parent, E., 549
Parmigiani, G., 377
Pathak, P.K., 111
Pearl, J., 286
Pearson, E.S., 18, 36, 71, 89
Pearson, K., 50, 365
Peddada, S., 111
Peers, H.W., 148, 149, 225
Pemantle, R., 85, 274, 277
Pericchi, L.R., 250–254, 257, 258, 370,
376, 378, 381, 409
Perk, W., 157
Perron, F., 479
Petkau, A.J., 40
Petrella, L., 408
Petrie, T., 358
Petrone, S., 406
Pettit, L.I., 250
Pfangzagl, J., 260
Philippe, A., 151, 297, 342, 394–396
Phillips, D.B., 52, 53, 232, 371, 395, 418
Pierce, D., 79, 300
Pitman, E.J.G., 111, 125, 158, 467
Pitt, M.K., 549
Plessis, B., 5, 6, 311
Poincar´e, H., 553, 559
Poirier, D.J., 549
Pollock, K., 194
Polson, N.G., 233, 377, 549
Pommeau, Y., 2
Popper, K., 193, 551, 553
Press, J.S., 204
Price, R., 50
Qian, W., 365
Racugno, W., 44, 370
Raftery, A.E., 195, 242, 243, 325, 361,
364, 378, 381, 382, 385, 386,
396–398, 400, 413
Raiﬀa, H., 20, 38, 44, 63, 64, 95, 97,
124, 195
Ralescu, S., 107
Rao, C.R., 111
Rao, R., 149
Raoult, J.P., 445, 456, 457
Reber, A., 500, 502, 503, 508, 509
Redner, R., 365
Reid, N., 199
Richard, J.F., 33, 154, 206, 210, 228,
230, 232, 234, 235, 549
Richardson, S., 53, 323, 365, 371, 379,
394, 400, 496, 498, 550
Ripley, B.D., 360, 395, 418, 549
Rissanen, J., 22, 151

Index des noms
617
Ritov, Y., 49, 54
Robbins, H., 155, 519, 521
Robert, C.P., 2, 23, 41, 45, 47, 53, 71,
80, 86, 91, 101, 103, 104, 108,
109, 111, 112, 151, 161, 162,
179, 182, 186, 191, 195, 196,
214, 222, 223, 227, 234, 235,
249, 250, 274–277, 282–284,
288, 292, 293, 296, 297, 299,
306, 310, 313–316, 319, 320,
322–366, 371, 379, 382, 388,
394–396, 399–404, 418, 420,
421, 433, 442, 445, 449, 450,
455–460, 478, 493, 500, 502,
503, 506–509, 513, 515, 518,
525, 527, 533, 534, 540, 544,
546, 547, 561
Roberts, G.O., 324, 337, 340
Robertson, T., 23, 39, 179
Robins, J., 8, 49, 54, 375
Robinson, G.K., 267, 285, 295, 300, 301
Roeder, K., 365, 366, 371, 372
Rolph, J., 525
Romano, J.P., 36, 40, 41
Ronchetti, E., 6
Rosenbluth, A.W., 323, 325
Rosenbluth, M.N., 323, 325
Rosenthal, J.S., 340
Rossi, P.E., 233, 401, 549
Rousseau, J., 149, 151, 322
Roy, M., 108, 445, 449, 456, 457
Rubin, D.B., 23, 62, 325, 342, 359, 361,
365, 388, 498, 503, 507, 557
Rubin, G., 354
Rubin, H., 63, 91, 147, 229, 231, 260,
455
Rubinstein, R.Y., 348
Rudin, W., 474
Rue, H., 105, 106
Rukhin, A.L., 86, 93, 101, 108, 191, 285,
424, 443, 515
Ryd´en, T., 213, 319, 344, 358, 394, 418,
420
Sackrowitz, H., 283
Sahu, S.K., 337
Saleh, A.K.Md.E., 108, 111, 112, 206,
527, 529
San Cristobal, M., 498
Santner, T.J., 217
Savage, L.J., 8, 51, 177
Saxena, K., 24, 146, 165, 189, 307, 445,
492
Schaafsma, W., 274
Schervish, M.J., 54, 70, 85, 96, 274, 320
Schlaifer, R., 20, 38, 44, 63, 97, 124, 195
Schwarz, G., 381
Seber, G.A.F., 194
Seidenfeld, T., 50, 119, 156
Sellke, T., 152, 254, 268–270, 273, 277,
291
Sen, P.K., 111, 112, 206
Seneta, E., 221
Severini, T.A., 148
Shafer, G., 375
Shannon, C., 118, 151
Shao, J., 107, 319, 385, 387, 411, 412
Sharples, L.D., 549
Shaw, J., 314, 322
Sheather, S., 211, 214
Shephard, N., 549
Shinozaki, N., 86, 100, 108, 282, 431
Shorrock, G., 282
Shyu, S.F., 354
Sid`ak, Z., 6
Siegel, A.F., 36, 40, 41
Silander, T., 549
Silverman, B.W., 52
Singpurwalla, N., 550
Sinha, B.K., 431
Sinha, D., 9, 108
Sivaganesan, S., 152, 153
Sken, A., 314, 322
Small, M.J., 342
Smith, A.F.M., 52, 53, 63, 65, 91, 116,
170, 171, 203, 204, 227, 237,
250, 299, 314, 322, 332, 333,
336, 337, 339, 345, 364, 371,
379, 395, 401, 418, 501, 503,
504, 509, 512, 513, 534, 550,
557
Smith, D.D., 28, 496
Smith, J.Q., 64, 65, 70, 95, 116, 190,
215, 218, 558
Sobel, M., 230
Soubiran, C., 357
Spatinas, T., 52
Speed, T.P., 544

618
Index des noms
Spiegelhalter, D.J., 250, 299, 323, 341,
360, 375, 379, 381–384, 410,
411, 497, 533, 544, 545, 549,
550
Srinivasan, C., 108, 120, 431, 445, 446,
456
Srivastava, M.S., 108, 150
Stangl, D.K., 549
Stark, J.A., 549
Steel, M., 44
Steﬀey, D., 173, 322, 529
Stegun, I., 161, 165, 314, 547
Stein, C., 51, 102, 106–108, 110, 129,
143, 177, 179, 186, 216, 281,
430, 436, 438, 441, 447, 477,
480, 515, 535
Stephens, D., 418, 419
Stephens, M., 53, 365, 395
Stern, H.S., 388, 498, 503, 507, 557
Stern, S.E., 149, 173, 174
Steward, G., 206
Stigler, S., 9, 12–14, 37, 50, 198, 314
Stone, M., 138, 163, 177, 179, 492
Stone, N., 163–165
Strasser, H., 76, 473, 482
Strawderman, W.E., 71, 73, 79, 80, 82,
103, 104, 107–109, 111, 112,
148, 187, 220, 282, 430, 517,
537, 539
Stuart, A., 523
Studden, W.J., 27, 42, 152
Sudderth, W.J., 8
Sweeting, T.J., 148
Tan, K.K.C., 329, 360
Tanner, M., 331, 333, 334
Teicher, H., 171
Teller, A.H., 323, 325
Teller, E., 323, 325
Thatcher, A.R., 294
Thisted, R.A., 198
Thomas, A., 360
Thompson, E.A., 179, 306
Thompson, P.M., 266
Tiao, G.C., 22, 549
Tibshirani, R., 143, 151
Tierney, L., 320–322, 340, 349
Tirri, H., 549
Titterington, D.M., 344, 358, 364–366,
382, 394, 561
Tolboom, J., 274
Tompa, H., 154, 234
Tong, H., 208
Torrie, G.M., 412
Tsui, K., 108
Tukey, J.W., 416
Tweedie, R.L., 28, 207, 208, 323, 324,
329, 431, 496
Ulam, S., 315
Ullah, A., 108, 282
Umbach, D., 354
Valleau, J.P., 412
Van der Linde, A., 382–384
Van der Meulen, B., 85, 274
Van Dijk, H.K., 233
Van Dyk, D.A., 363, 365
Van Eeden, C., 91
Venn, J., 50, 114
Verdinelli, I., 314, 364, 406, 407, 417,
550
Vidakovic, B., 9, 52, 314
Vidal, C., 2
Villegas, C., 32, 491
Vines, K., 361
Volinsky, C., 396
Wakeﬁeld, J.C., 339
Wald, A., 18, 51, 58, 71, 301, 444
Walker, H., 365
Walker, S., 339
Wallace, C.S., 90
Wallace, D.L., 198
Walley, P., 152, 167, 296, 297, 496
Wang, Y., 268, 302
Wasserman, L., 8, 49, 54, 119, 137–139,
143, 147, 151, 152, 154, 156,
166, 314, 364–366, 371, 375,
379, 406, 407, 417
Welch, B.L., 148, 149, 225
Welch, P.D., 361
Wells, M.T., 63, 82, 86, 101, 108, 148,
266, 274–277, 292, 342, 356,
457
West, M., 9, 210, 211, 213, 367, 371, 550
Whittaker, J., 544

Index des noms
619
Wijsman, R.A., 465, 473
Wild, P., 347
Wilkinson, G., 51
Winkler, R.L., 70
Wolpert, R., 17, 20, 22, 37, 38, 87,
177–179, 216, 267, 298, 301,
302, 557
Wolter, W., 196
Wong, W.H., 331, 333, 334, 337, 387
Wright, F.T., 23, 39, 179
Wu, Y.N., 363
Yahav, J.A., 230
Yang, M.C., 224
Yang, R., 232
Yao, Y.C., 209
Ylvisaker, D., 124, 130, 131, 133, 163,
173, 442, 496
York, J., 544, 546
Yu, B., 151
Zabell, S.L., 50, 51, 221, 314
Zako¨ıan, J.M., 209
Zaman, A., 360
Zellner, A., 100, 154, 204–206, 409, 549
Zhou, Y., 386
Zidek, J.V., 40, 91, 163–165, 430, 431,
451, 454, 477, 492, 527
Zucchini, W., 153

Index des mati`eres
a posteriori, 10, 18, 25
construction, 175
coˆut
approch´e, 319
moyen, 68
erreur quadratique, 181
impropre, 362, 363
information, 146
marginal, 234
m´ediane, 14, 88, 190
moyenne, 85
probabilit´e, 148, 241
p-value comme, 301
variation de la, 268
propre, 31, 342
pseudo-, 256, 521
r´egion cr´edible, 148
a priori, 10
arbitraire, 114, 122
`a sym´etrie sph´erique, 442
biais, 80
choix d’un, 15, 113, 155, 361, 397,
558
automatique, 114
exact, 152
param´etr´e, 120
subjectif, 114, 116, 117
classe
`a moments d´etermin´es, 152
de voisinages, 153
ϵ-contamin´ee, 153
rapport de densit´es, 153
sous-sp´eciﬁ´ee, 153
cognitif, 553
comme outil, 552, 555
conjugu´ee, voir conjugu´ee
construction de l’, 116
d’entropie maximale, 154, 156
de co¨ıncidence, 148, 149, 225
de Dirichlet, 366, 406, 546
de Haldane, 491
de Jeﬀreys, voir non informatif, a
priori de Jeﬀreys
controvers´e, 210
de r´ef´erence, 137, 143, 144, 146,
147, 176, 227, 230
construction, 145
du maximum d’entropie, 121
dualit´e entre coˆut et, 147, 242
existence d’un, 169, 170
ferm´e par ´echantillonnage, 123
fondements axiomatiques d’un, 170
G, 204–206, 409
hi´erarchique, voir Bayes
hi´erarchique
impropre, voir impropre a priori
et hypoth`ese ponctuelle, 248
et test, 403
incertitude sur l’, 152
inconnu, 519
inﬂuence de l’, 114
information, 113, 137, 152, 155,
206, 311
diﬀuse, 247
intrins`eque, 254, 256, 289
intuition, 553

622
Index des mati`eres
invariante par changement
d’´echelle, 139
Jeﬀreys
alternative `a l’, 483
m´elange de, 133
mod´elisation, 134
eﬀet de la, 342
modiﬁcation de l’, 244, 273
non informatif, voir non informatif
objectif, 123
par arbres de P´olya, 52
par d´efaut, 137
param´etr´e, 114, 115, 119
poly-t, 206, 234, 235
pour les tests, 151
probabilit´e d’un mod`ele, 397
pseudo, 391
relativement invariant, 487
robuste, 154
s´election d’un, 71
uniforme, 137, 138, 146
vague et propre, 31
absence de d´ecision
alternative par, 301
r´eponse, 302
acceptation
niveau d’, 240, 241, 259
conventionnel, 243, 249, 266
rapport d’, 326, 327
acceptation-rejet, 346
accidents dans le Michigan, 4, 371
ad´equation, 374, 405
probl`eme d’, 406
admissibilit´e, 81, 82, 86, 91, 148
condition n´ecessaire d’, 275
d’un unique estimateur, 81
de l’estimateur de Bayes, 82
de l’estimateur des moindres
carr´es, 106
et r´ecurrence, 432
AIC, voir crit`ere d’information d’Akaike
ajustement
contre erreurs d’estimation, 373
meilleur, 374
al´eatoire
g´en´erateur, voir g´en´erateur
pseudo-al´eatoire
algorithme, 146
ARMS, 329, 360
d’acceptation-rejet, 346
avec enveloppe, 347
de Box-Muller, 346
de Durbin-Levinson, voir
r´ecurrence de Durbin-
Levinson
de Gibbs, voir ´echantillonnage, de
Gibbs
de Metropolis-Hastings, 325, 327,
350
`a marche al´eatoire, 328, 329
EM, voir EM
MCMC, 323
α
niveau, 266
amiante, 239
analyse
conditionnelle, 300
de la variance, 147, 230, 286
de robustesse, 152, 155
de sensibilit´e, 152, 558
animal
biologie, 192, 194
´elevage, 498
approche
bay´esienne empirique, 27
conditionnelle, 285
ﬁduciaire, 22
fr´equentiste, 18, 66
non param´etrique, 6, 364, 370
param´etrique, 6, 8
approximation, 136
de Bartlett, 149
de la densit´e marginale, 385, 390
de Laplace, 54, 319–322, 342, 349,
380
du second ordre par χ2
k, 173
num´erique, 313
par point-selle, 329
AR(1), voir mod`ele, AR(1)
arbre
classement par, 40
de d´ecision, 65
de mod`eles possibles, 374
´elagage, 402
orangers, 372
pins, 392
ARCH, 233
argument limite, 33

Index des mati`eres
623
aucun mod`ele n’est vrai, 238
augmentation de donn´ees, 331
auteur
identiﬁcation d’, 198
autocorr´elation
partielle, voir partiel
autocovariance, 212
autor´egressive, voir mod`ele, AR
axiomes, 116
bay´esiens, 11, 30, 35, 169, 550–561
choix des, 472
de coh´erence, 168
de pari, 167
des probabilit´es, 50
statistiques, 15, 35
base fonctionnelle, 124
bay´esien
calcul, 313, 341
contre fr´equentiste, 238
crit`ere d’information (BIC), 381,
382, 414
logiciel, 561
meilleur centre, 293
mod`ele statistique, 10
non param´etrique, 9, 406
paradigme, 9–15, 22, 25, 50, 114,
251, 371, 405, 495, 500, 531
principe d’actualisation, 156
software, 313
test, 237, 241
UPP, 263
bay´esienne
approche
coh´erence de l’, 550, 554
critique de l’, 557
non informative, 560
approximation, 345
imagerie, 70
inf´erence, 136
minimaxit´e, 561
r´eponse la moins favorable, 268
robustesse, 155
Bayes
empirique, 122, 518
de Bayes, 546
et eﬀet Stein, 525–531
inconv´enient du, 529, 531
mod´elisation, 311
non param´etrique, 519
param´etrique, 521
test, 524
estimateur de, 69
admissible, 424
analytique, 186
calcul d’un, 305, 556, 557
du coˆut, 190
et admissibilit´e, 82
g´en´eralis´e, 69, 79, 141, 275, 428,
429, 443, 446
hi´erarchique, 308
inadmissible, 424
inconsistant, 54
limite d’, 442
lin´eaire, 124
meilleur ´equivariant, 476
minimax, 77, 80, 537
pour une mesure invariante, 473
propre, 438
pseudo-, 109
randomis´e, 78
repr´esentation diﬀ´erentielle, 429
universel, 93
hi´erarchique, 122, 154
d´ecomposition, 504–506
estimateur, 514
et robustesse, 496
inconv´enient du mod`ele, 507
mod`ele, 499
motivations, 501–504
probl`emes num´eriques, 507–509
r`egle de, 184
risque de, 69
inﬁni, 73
int´egr´e, 68
th´eor`eme de, 9–10, 375, 551
Behrens-Fisher, probl`eme de, 294
Berger
paradoxe de, 296
ph´enom`ene de, 108
r´econciliation au sens de, 301–303
biais, 373
BIC, voir bay´esien, crit`ere d’information
Biostatistiques, 549
bootstrap, 15
born´e
coˆut, 62, 190, 277, 428, 434, 441,
452

624
Index des mati`eres
ensemble de risque, 443, 456
espace des param`etres, 179
param`etre, 86
bornes inf´erieures de demi-queue
(STUB), 447
bruit blanc, 211
BUGS, 360, 378
bus, 3
C, 360
calcul
de l’incertain, 3
diﬃcult´es de, 306
calibration, 226, 295, 328
d’expert, 70
lin´eaire, 47, 143, 150, 408, 409
intervalle de conﬁance, 409
cancer de la l`evre, 384
capture-recapture, 3, 115, 309
calcul de l’a posteriori en, 310
mod`ele, 194–198
de Darroch, 196
temporel, 331
carte d’allocation, 234, 395
censure, 38
cercle unit´e, 208, 211
cerf, 194
chaos, 2
choix de mod`ele, 342, 369
espace des param`etres, 375
et estimation, 370
et test, 369
termes de p´enalisation, 377
classe compl`ete, 260, 274, 276, 435,
443–446
essentiellement, 276
minimale, 455
classement, 230
classiﬁcation, 364
taux d’erreur, 105
clique, 506, 544
ordre parfait pour une, 544
co¨ıncidences, 193
CODA, 324, 325, 360, 361
coeﬃcient
de normalisation, 28, 140, 223
de r´eﬂexion, 211
multinomial, 195
coh´erence, 8, 26, 34, 97, 98, 138, 157,
168, 551
des facteurs de Bayes, 256
coin, 133
colin´earit´e, 513
comit´e, 91
complet
chaˆıne, 358
classe, 34
distribution, 111
espace, 72
forme exponentielle, 320
ignorance, 32
statistique, 37
variable al´eatoire, 359
condition
d’´equilibre ponctuel, 326, 350, 394,
418
de positivit´e, 331
n´ecessaire et suﬃsante
de Stein, 426, 441
STUB, 543
suﬃsante d’admissibilit´e, 426
d’Eaton, 460–461
de Blyth, 436, 441
conditionnement, 504
conﬁance
index de, 285
intervalle de, 216
niveau de, 29, 238
rapport´e, 530
r´egion, 19, 24, 28, 108, 191, 277
comme r´egion cr´edible, 279
de niveau α, 281
eﬃcace, 282
non connexe, 280
recentr´ee, 282, 296, 529, 530
conjugu´e, 341
a priori, 123–125, 127, 128, 131,
133, 154, 187
classe de, 152
et a priori d’entropie maximale,
160
et loi de Jeﬀreys, 142
et BUGS, 360
hyperparam`etre, 137
m´elange de, 135, 157, 172, 442,
524
naturel, 171

Index des mati`eres
625
normal, 199
famille, 123
minimale, 123, 157
contrˆole, 325
contrainte
de positivit´e, 337
convergence, 23, 144, 176, 407, 463
diagnostic de, voir diagnostic
g´eom´etrique, 329, 331, 344, 353,
358
indicateur de, 508
quadratique, 440
vitesse de, 324
convexit´e, 152
coordonn´ees polaires, 145
Cornell University, 354
correction de Bartlett, 149, 173
pour un a posteriori, 173
coˆut, 56, 66, 554
absolu, 274
al´eatoire, 91
asym´etrique en erreur quadratique,
101
bidimensionnel, 259
born´e, 62
classique, 85, 184
construction d’un a priori `a partir
du, 147
contrainte de, 555
convexe, 70, 76, 81, 85, 88, 99
strictement, 274
d’information, 264
d’opportunit´e, 97
de classiﬁcation, 105
de Hellinger, 90, 101, 166
de pr´evision, 183
d’une p-value, 268
en erreur absolue, 54, 87, 100
entropique, 90, 91, 101, 469, 526,
527, 543, 547
estimation de, 86, 190, 191
global, 285
intrins`eque, 23, 89, 101
invariant, 224, 469
par changement d’´echelle, 189
par reparam´etrisation, 90
lin´eaire, 283, 284
LINEX, 100
maximal en potentiel explicatif,
401
multiple, 93
pour images, 105–106
pour l’estimation
de m´elanges, 365
ensembliste, 283, 284
propre, 274, 277
quadratique, 85, 86, 106, 109, 190
rationnel, 284, 296
robustesse sous, 108
0 −1, 89, 105, 239, 258, 261, 274
covariables, 372
covariance
matrice de, 206
crit`ere
d’information
bay´esien, voir bay´esien, crit`ere
d’information
d’Akaike (AIC), 380, 382, 414
de d´eviance (DIC), 382
de proximit´e de Pitman, 103
de Schwarz, 380, 381
ineﬃcace, 381
minimax, 73
croyance, 552
DAG, voir graphe acyclique orient´e
d´ecision
arbre de, 65
dans l’incertain, 63
erreur, 57
espace de, 66, 267
compact, 76
optimale, 97
unique, 259, 554
pour le choix de mod`ele, 377
d´ecomposition de Wold, 211, 228
densit´e pr´edictive, 367, 376, 377, 389,
396
d´eplacement
fusion, 395
naissance et mort, 395, 417
s´eparation, 395
d´eveloppement d’Edgeworth, 149
d´eviance, 382, 408
bay´esienne, 383
associ´ee, 410
p´enalis´ee, 382

626
Index des mati`eres
diagnostic
d’autocorr´elation, 361
de convergence, 324
software, 361
DIC, voir crit`ere d’information de
d´eviance
dichotomie unilat´erale/bilat´erale, 273
distance
de Hellinger, 54, 90
de Kullback-Leibler, voir diver-
gence, Kullback-Leibler
de Prohorov, 135
en variation totale, 172
entre distributions, 370
entropique, 90
distribution de probabilit´e, voir loi
divergence, 400
de Kullback-Leibler, 90, 118, 146,
153, 377, 401, 402, 414
domination
stochastique, 92, 111
universelle, 92
donn´ee
collecte de, 1
grossi`ere, 359
manquante, 160, 313, 335
repr´esentation par, 342
dualit´e, 86
principe de, 331
´echangeabilit´e, 170, 528
´echantillon d’apprentissage, 251
minimal, 251
pour un m´elange, 379
´echantillonnage
d’importance, 317, 329, 342, 385,
388, 411
choix de la fonction, 318
d´efensif, 386
et variance inﬁnie, 319
pour le choix de mod`ele, 385
de Gibbs, 329–341
bivari´e, 331, 333, 337, 338,
351–353
pour les m´elanges, 344
processus de Dirichlet pour, 366
de substitution, 337
exact, 324
hybride, 339
par chemin, 388, 417, 418
par paquets, 325
par parapluie, 412
par passerelle, 387–388
par tranche, 339–341, 344, 354, 389
s´equentiel, 253
´echelle, 153
de coh´erence, 116
´Econom´etrie, 226, 376, 549
´Ecosse, 384
Edgeworth, voir d´eveloppement
eﬀet Stein, voir Stein, 479, 483, 484
eﬀets al´eatoires, 499, 503, 550
a priori de Jeﬀreys pour, 363
mod`ele `a, 204
propri´et´e a posteriori pour, 45, 363
eﬃcacit´e, 23
dans l’inf´erence, 553
´elevage, 499
EM, 365, 382
´etapes, 365
encompassing, voir imbrication
ensemble
de troncature, 275
entropie
coˆut, voir coˆut
d´eﬁnition, 118
maximale, 117, 118
Environnem´etrie, 549
´equation
d’´etat, 213
d’observation, 213
diﬀ´erentielle, 150
´equations simultan´ees, 154
´equiprobabilit´e des ´ev´enements
´el´ementaires, 13, 138
ergodicit´e, 323, 324
uniforme, 324
erreur
de mesure, 497
de type I, 89, 258
de type II, 89, 258, 267
esp´erance morale, 64
espace
d’´etat, 213
repr´esentation, voir
repr´esentation, espace
d’´etat
d´enombrable, 117

Index des mati`eres
627
de dimension
inﬁnie, 52
variable, 370
des param`etres, 7, 30, 125
compact, 138
naturel, 127
restreint, 179
fonctionnel, 9
estimateur, 66
admissible
avec risque de Bayes inﬁni, 425
comme limite d’estimateurs de
Bayes, 275
et minimax, 148
`a r´etr´ecisseur, 92, 108, 493, 511
matriciel, 446
multiple, 108, 541
`a risque continu, 434
construction optimale d’, 71
de Bayes, voir Bayes, estimateur
de
de James–Stein, 129
de James-Stein, 104, 107, 282, 294,
525, 530
`a partie positive, 74, 107
tronqu´e, 186, 225, 445, 526
de la r´egression inverse, 227
de Pitman, 468
de Rao-Blackwell, 508
des moindres carr´es, 36, 106, 203
du maximum a posteriori (MAP),
102, 105, 174, 176, 376
du maximum de vraisemblance,
22, 131, 521
p´enalis´e, 176
´equivariant, 469
inadmissible, 81
inconsistant, 54
meilleur ´equivariant, 141, 465
minimax, 73, 76
´equivariant, 482
monotone, 435
performances d’un, 284
pseudo-Bayes, 225
randomis´e, 71, 72, 81, 85, 88
ridge, 513
sans biais, 36
unique, minimax, 83, 292
estimation, 67
ensembliste, 283, 284
comme forme d’estimation, 284
comme forme de test, 284
comme indicateur de perfor-
mance, 284
et test, 7
et ´evaluation, 8
m´elange, 153, 245
non param´etrique, 520
sans biais, 191
´evaluation
ex post, 238
´evidence, 20
exp´erience mixte, 20
expert
calibration d’, 70
ordre d’, 95
syst`eme, 375, 544, 549
explicative
variable, 206
facteur de Bayes, 241, 243, 244, 246,
250, 378
approximatif, 243
arithm´etique intrins`eque, 253, 254,
256, 289, 409
fractionnaire, 255, 256, 289, 409
g´eom´etrique intrins`eque, 254, 289
m´edian intrins`eque, 254
pour un a priori impropre, 378
pseudo-, 252, 256, 257, 370, 379,
392
calcul de, 258
choix de, 258
coh´erence de, 378
facteur de p´enalisation, 382
famille
conjugu´ee, voir conjugu´ee, famille
de position, 148
exponentielle, voir famille
exponentielle
famille exponentielle, 16, 91, 125, 130,
131, 157, 160, 185, 521
courbe, 129
de variance quadratique, 160, 314,
538
naturelle, 345
estimateur admissible pour, 445

628
Index des mati`eres
et rapport de vraisemblance
monotone, 260
extension, 405
minimale, 127
naturelle, 158, 274
forme de, 125
param`etre naturel d’une, 522
restreinte, 159
position et, 158
pseudo-, 157
quasi, 125
r´eguli`ere, 127, 158
variance d’une, 159
Federalist Papers, 198
fermeture, 30
ﬁle d’attente, 74
ﬁltrage, 213
ﬁltre de Kalman, 213
Finance, 549
Fisher
loi de, 36
ﬂ´eau de la dimension, 314
fonction
analytique, 80, 322
coˆut, voir coˆut
conﬂuente hyperg´eom´etrique, 161,
165, 199, 318, 518, 547
cumulante des moments, 127
d’importance, 348, 385, 386
choix de la, 316, 318, 385
optimale, 411
d’utilit´e, 61, 64
convexe, 64
de Bessel modiﬁ´ee, 165, 222, 223,
308, 410, 442, 493
de lien, 387, 502
de vraisemblance, voir vraisem-
blance
estimable invariablement, 492
gamma, 132
g´en´eratrice des moments, 321, 349
r´eguli`ere, 322
surharmonique, 516
variance quadratique, 159
forage p´etrolier, 74
forme
compl`etement exponentielle, 320
standard, 320
formule de r´eﬂexion, 160
fractile, 153
fr´equentiste
approche, 66
cadre d´ecisionnel, 67, 71
conditionnel, 267
couverture, 148
m´ethode, 555
notion d’optimalit´e, 423
paradigme, 67
propri´et´e, 147
de long terme, 151
risque, 66
test, 72, 259
validit´e, 191, 271, 455
Γ-minimax
regret, 155
risque, 155
g´en´erateur
inﬁnit´esimal, 496
pseudo-al´eatoire, 315, 316, 360
Gibbs
champ de, 329
´echantillonnage, voir
´echantillonnage, de Gibbs
Glasgow, 194
graphe, 544
non orient´e, 544
orient´e, 544
acyclique, 497, 532, 544, 545
Green
compl´etion de, 393
groupe
action d’un, 139
moyennable, 480, 482
structure de, 118
transitif, 470
Haar
mesure de, voir mesure, de Haar
ondelette de, 52
Harris
r´ecurrence au sens de, 323
h´et´eroc´edasticit´e, 233
hi´erarchique
a priori, voir Bayes hi´erarchique
mod´elisation, 154
histogramme, 117, 120, 153
hot hand, 243, 244

Index des mati`eres
629
Hubble
constante de, 245
hyper a priori, 122, 154, 503
hyperbolic secant, 160
hyperparam`etre, 122, 128, 155, 202,
206, 499
conjugu´e, 219
estim´e, 521
poly-t, 235
hypoth`ese
alternative, 239
contigu¨e, 259
nulle, 239, 240
ponctuelle, 237, 238, 245, 289
unilat´erale, 271
identiﬁabilit´e, 26, 212, 215, 561
image, 70, 105
noir et blanc, 105
radiologique, 4
traitement, 549
imbrication, 376, 403
impropre
a priori, 30–34, 138, 140, 365
comme a priori usuel, 32
et ´echantillon d’apprentissage,
252
et hypoth`ese nulle ponctuelle,
238
et r´egions cr´edibles, 279
et test, 248, 249, 254
in´egalit´e
de Jensen, 76
de Van Trees, 182
inadmissibilit´e, 107
de la p-value, 277
du maximum de vraisemblance,
106
incoh´erence, 116, 141
inconsistance
d’estimateurs de Bayes, 54, 144
de la loi de Jeﬀreys, 143
in´egalit´e
de Cauchy-Schwarz, 452
de Cram´er-Rao, 426
inf´erence, 1, 3, 7
causale, 375
quantitative, 552
inﬁnie divisibilit´e, 129
information, 17, 27
a priori, 30, 35, 113
d´ecomposition de l’, 498
et loi a priori, 557
insuﬃsante, 496
justiﬁcations subjectives, 142
r´esum´e de, 175
de Fisher, 139, 141, 144, 149, 150,
165
´equivalent ´echantillon, 116
limit´ee, 114, 120, 124
manquante, 146
pour un probl`eme de test, 267
structurelle, 502
suppl´ementaire, 245
vague, 121, 181
int´egrabilit´e, 34
int´egrale
approximation, 314
d´eveloppement de Laplace d’une,
voir approximation, de
Laplace
invariante `a gauche, 475
invariante `a droite, 475
rapport d’, 319
int´egration
analytique, 305
num´erique, 307
interface
bay´esien-fr´equentiste, 109, 268, 301
interpr´etation contre explication, 2, 550
invariance, 24, 57, 90, 124, 463
et mesure de Haar, 142
groupe, 468
par reparam´etrisation, 118, 138,
140, 147
par translation, 139
structure d’, 139
translation, 465
inverse g´en´eralis´ee, 417
inversibilit´e, 212, 229
inversion, 551
causale, 50
de la Statistique, 22
des probabilit´es, 9, 10, 25
entre causes et eﬀets, 9
irr´eductibilit´e, 323, 326
Jeﬀreys

630
Index des mati`eres
a priori, voir non informatif, a
priori de Jeﬀreys
´echelle de, 242
Jensen
in´egalit´e de, 76, 359
Kalman
ﬁltre de, 213
Kepler
probl`eme de, 265
χ2, voir loi, du khi deux
Lagrange, voir multiplicateur
Laplace
approximation, voir approxima-
tion, de Laplace
d´eveloppement de, voir approxima-
tion, de Laplace
r`egle d’´equiprobabilit´e de, 138
r`egle de succession de, 192
transform´ee de, 186
lemme
de Jensen, 76
de Neyman-Pearson, 259
de Pitman-Koopman, 125, 157,
158, 260
de Schur, 209, 211
de Stein, 102
le probl`eme a une valeur, 77
l´ezard, 115
lin´earisation, 61
lin´earit´e, 131
lissage, 213
loi
a posteriori, voir a posteriori
a priori, voir a priori, 11
`a support ﬁni, 152
`a sym´etrie sph´erique, 35, 109, 158,
282
bˆeta, 35, 115, 120, 156, 564
bˆeta-binomiale, 330, 332, 507, 523
bˆeta-Pascal, 195
binomiale, 565
binomiale n´egative, 219, 566
g´en´eralis´ee, 459
cible, 326, 329
classe de, 152
conjugu´ee, 154
d’Erlang, 563
de Bernoulli, 171, 192
de Cauchy, 23, 104, 120, 136, 199,
307, 564
de Dirichlet, 52, 126, 565
de Fisher, 564
de Haldane, 216
de Jeﬀreys, voir non informatif, a
priori de Jeﬀreys
de l’arcsinus, 217
de Laplace, 14, 44
de Pareto, 125, 128, 142, 157, 565
de Poisson, 129, 484, 519, 565
de probabilit´e invariante, 474
de Student, 93, 128, 154, 155, 199,
201, 512, 564
d´ecomposition de Dickey pour
la, 129, 308
m´elange de, 235
de Weibull, 23, 39, 327, 340
de Wishart, 158, 202, 204, 357
double exponentielle, 14
du khi deux (χ2), 173, 427, 563
d´ecentr´e, 24, 104, 143, 223, 308,
317, 358, 361, 459, 488, 565
du logarithme it´er´e, 38
du maximum d’entropie, 118
du rapport de vraisemblance
monotone, 272
exponentielle, 563
F, voir Fisher, loi de
g´eom´etrique, 220
gamma, 33, 129, 563
inverse, 155, 200, 210, 564
gaussienne inverse, 158
g´en´eralis´ee, 14
hyperg´eom´etrique, 3, 194, 566
impropre, 31
jointe, 24
la moins favorable, 31, 77, 79, 80,
263
pour les tests, 262
log-normale, 563
logistique, 218
m´elange, voir m´elange
marginale, 24, 117, 154, 521
estimation de la, 520
multimodale, 307
multinomiale, 194, 565
naturelle conjugu´ee, 130

Index des mati`eres
631
non centr´ee, 129
non informative, voir non
informatif
approximation, 54
normale, 116, 119, 126, 198, 210,
563
inverse g´en´eralis´ee, 128, 161, 478
tronqu´ee, 354, 415
pr´edictive, 25
stationnaire, 208, 227, 323, 325,
326, 331
sym´etrique, 157
t, voir Student
unimodale, 167, 270
Loi des Grands Nombres, 67, 315, 324
Maple, 244
marche al´eatoire, 208, 431
march´e boursier, 207
marginalisation, 176
paradoxe de, 138, 163
Markov
chaˆıne de, 207, 209, 210, 217, 323,
354
ap´eriodique, 326
`a temps continu, 496
cach´ee, 52, 209, 217, 341, 344,
357
ergodique, 331
g´en´eration d’une, 325
irr´eductible, 323, 352
Monte Carlo par, voir MCMC
ϕ-m´elangeance, 352
r´ecurrente, 432
r´eversible, 350
transiente, 363, 431
Kakutani, 482
mod`ele de
cach´e, 341, 358, 394
Mathematica, 244
mauvaise sp´eciﬁcation, 31
maximum de vraisemblance, voir
estimateur du maximum de
vraisemblance
estimation, 22
et estimation non param´etrique,
520
m´ethode du, 555
MCMC, 323, 339
`a sauts r´eversibles, 394
et DIC, 383
et loi impropre, 34
impact des m´ethodes, 342
pour les mod`eles
`a dimensions variables, 377, 391
de m´elange, 342–344
dynamiques, 364
hi´erarchiques, 507
non param´etriques, 407
simulation et stockage, 396
m´edicament, 509
meilleur estimateur ´equivariant, 465,
471, 472, 527, 557
comme estimateur de Bayes, 468
de Pitman, 467
existence d’un, 466
sous coˆut entropique, 527
m´elange, 34, 44, 52, 129, 157, 163, 218,
270, 290, 312, 364, 401, 503,
550
bˆeta, 163, 406
cach´e, 129, 185, 339, 361
continu, 137
d’´echelle, 291
de masses de Dirac, 136
de Student, 235
´echantillonnage de Gibbs pour, 344
estimation de, 561
exponentiel, 356, 394
g´eom´etrique, 27
non-identiﬁabilit´e, 408
normal, 4, 23, 45, 257, 310, 342,
372, 410
uniforme, 167
mesure
de Haar, 31, 465, 479, 482
`a droite, 118, 148, 473, 475, 477,
481
`a gauche, 475
droite contre gauche, 477
ﬁnitude, 475
de Lebesgue, 14, 30
de Radon, 475
de r´ef´erence, 118
invariante, 474
m´eta analyse, 28, 496, 501
m´eta mod`ele, 117, 405
m´et´eorologiste, 70, 96, 245

632
Index des mati`eres
m´ethode
de ﬁltrage particulaire, 319
de Monte Carlo, voir Monte Carlo
de Simpson, 314
des moments, 117, 120
ML-II, 117
m´etro de Londres, 416
minimax
analyse, 75
estimateur, 73, 76
randomis´e, 76
r`egle de Bayes, 80
strat´egie, 76
minimaxit´e, 73, 91, 148
et admissibilit´e, 81, 450
minimaxit´e, 518
condition n´ecessaire et suﬃsante
de, 516
d’estimateurs bay´esiens
hi´erarchiques, 512, 514
mod`ele
`a variables latentes, 499
`a facteurs, 230
AR(1), 207, 208, 232, 454
AR(p), 208, 210, 212, 213, 364
`a sauts, 209
ARCH(p), 230, 233
ARIMA, 229
ARMA(p, q), 214
`a variables latentes, 341, 460
`a volatilit´e stochastique, voir
volatilit´e
causal, 229
censur´e, 357
choix de, 17, 239, 245
complet, 400, 403
projection du, 400
construction d’un, 6
de calibration lin´eaire, voir
calibration
de capture-recapture, voir
capture-recapture
de Darroch, 196, 222
de dimension
variable, 391
de Markov, voir Markov, chaˆıne
de, cach´ee
de Wolter, 196, 222
d´ecomposable, 545
de m´elange, voir m´elange
discret, 191
dynamique, 206, 207
´echangeable, 503
exploration de, 402
GARCH, 233
graphique, 341, 506, 544
hi´erarchique, 48, 117, 334, 337,
353, 360, 497
´echangeable, 510
et densit´e conditionnelle
compl`ete, 506
et robustesse, 504
imbrication, 370, 376, 403, 405
imbriqu´e, 299
lin´eaire, 501
additif, 500
`a eﬀets al´eatoires, voir eﬀets
al´eatoires
g´en´eralis´e, 387, 399, 420, 502
logistique, 2
logit dichotomique, 46
MA(q), 212, 214
moyennage de, 342
moyenne de, 377, 395
multinomial, 415
normal, 198–206
avec a priori hi´erarchique, 509
probit, 160, 355, 533
dichotomique, 46
qualitatif, 132
saturation de, 391, 410
spatial autor´egressif, 384
statistique, 7, 115
invariant, 468
temporel, 222
tobit, 226
volatilit´e stochastique, 499
vrai, 115
module, 475, 489
moment
canonique, 42
m´ethode de, 365
Monte Carlo
approximation par, 179, 322
d´eﬁnition, 315
par fonction d’importance, 316
populationnel, 319
r´esolution par, 137

Index des mati`eres
633
moving average, voir MA
moyenne
a posteriori, 85
et th´eor`eme de Hunt-Stein, 481
fonctionnelle, 481
g´eom´etrique, 403, 415
harmonique, 386, 387
invariante `a droite, 482
la plus ´elev´ee, 230
mobile, 212
multicolin´earit´e, 206, 513, 535
minimaxit´e, 513
multiplicateur, 475, 487
de Lagrange, 118
naissance et mort, 394
processus `a temps continu, 395
processus de saut, 418, 419
naissances mˆales, 138
Neyman-Scott, probl`eme de, 54
nœud, 544
Le Nom de la Rose, 398
nombre de composantes, 366, 367, 373
inconnu, 372
non informatif, 137
a priori, 50, 51, 123, 137–151
comme limite de conjugu´es, 202
de Haldane, 287
de Jeﬀreys, 114, 139, 141–143,
147, 150, 151, 166, 200, 232,
248, 250, 560
et loi conjugu´ee, 123
et reparam´etrisation, 138
et structure d’invariance, 463
mesure de Lebesgue comme, 84,
139, 249, 300, 474, 492
hi´erarchique, 503
loi, 22
mod´elisation, 30, 552
r´eponse
p-value comme, 273
non-centralit´e, 488
non-identiﬁabilit´e, 26
non-transitivit´e, 111
normalisation
constante de, 132, 133, 235, 376,
385, 390
rapports de, 387
notation, 7, 567–570
nul mod`ele n’est parfait, 373, 374
num´erique
approximation, 313
calcul, 189
int´egration, 307, 308, 314, 319
et m´ethodes de Monte Carlo,
319
m´ethode, 238
minimisation, 190, 305
outil, 51
technique, 29
objectivit´e, 132
observation, 6, 7
espace d’, 66
imaginaire, 251
virtuelle, voir virtuelle, observation
Occam
fenˆetre d’, 398
rasoir d’, 398
ondelette, 314, 406
base d’, 52
de Haar, 52
optimale
d´ecision, voir d´ecision, optimale
optimalit´e
asymptotique, 147
classique, 555
orbite, 470
ordre, 94, 95, 111, 147
dans P, 59
des pr´ef´erences, 170
grossier, 170
partiel, 81, 92
relation d’, 169
social, 63
total, 67, 73
orthogonal
base, 314
polynˆome, 160
r´egresseur, 398
paradigme, 9
paradoxe, 147
de Borel, 286
de Condorcet, 63
de Jeﬀreys-Lindley, 34, 247, 249,
291, 299, 300, 378
de l’information, 313, 342

634
Index des mati`eres
de marginalisation, 32, 138, 146,
163, 225, 400, 492, 493
de projection, 400
de Saint-P´etersbourg, 56, 64
de Simpson, 36, 63
de Stein, 102, 177
de vraisemblance, 555
des statistiques libres, 226
param´etrisation, 149, 401
choix de la, 57, 90
en moyenne, 171
inﬂuence, 57, 90
lin´eaire, 61
naturelle, 89
param`etre
al´eatoire, 11
born´e, voir born´e
d’´echelle, 139
d’interˆet, 143
de non-centralit´e, 223, 445, 488,
539
de nuisance, 143, 144, 147, 148,
174, 179, 445, 561
de position, 30, 139, 465
espace de, 66
naturel, 91, 138
sous contrainte d’ordre, 23
parcimonie, 215, 231, 374, 396
pari, 167
d´esirable, 167
proc´edure de, 300
partiel
autocorr´elation, 209, 211, 228, 364
inverse, 214
partition de l’´echantillon, 312, 313
partitionnement, 138
performance, 67, 81
fr´equentiste, 109
perspective conditionnelle fr´equentiste,
302
pertinent
sous-ensemble
biais´e n´egativement, 300
biais´e positivement, 300
ph´enom`ene de d´eg´en´erescence, 214
Pillow Problems, 221
Pitman
admissibilit´e, 104
domination au sens de, 103
proximit´e de, 104, 111
pixel, 4, 105
placebo, 509
Pluralitas non est ponenda sine
necessitate, 398
point-selle, 365
polynˆome
d’Hermite, 314, 346
Legendre, 406
orthogonal, 160
quadrature par, 314
population
estimation de la taille d’une, 194
ﬁnie, 192
rare, 193
pr´ecision, 181
´evaluation, 86
pr´evision, 8, 182, 213, 277
coh´erente, 168
conjugu´ee sup´erieure, 168
densit´e de, 367
pour la r´egression lin´eaire, 226
sup´erieure et inf´erieure, 167
pr´evisionniste, 70
principe
d’exhaustivit´e, 16, 17, 20
d’invariance, 464
formelle, 465
de conditionnement, 20, 21
de dualit´e, 331, 353
de la raison insuﬃsante, 114, 138
de parcimonie, 215, 231, 364, 396,
398
de vraisemblance, 17, 21, 71, 151,
203, 216, 251, 267, 301, 484,
554
et a priori de Jeﬀreys, 142
et Th´eorie de la D´ecision, 88
impl´ementation, 23, 35
justiﬁcation, 20
mise en œuvre, 177, 179
version bay´esienne du, 175
des r`egles d’arrˆet, 19, 264
des z´eros s´epar´es, 80
minimax, 74
probabilisation, 550
probabiliste
interpr´etation, 3
mod´elisation, 3, 9, 11, 12

Index des mati`eres
635
probabilit´es
axiomes des, 50
impr´ecises, 496
inverses, 9
th´eorie des, 13
probl`eme
de Fieller, 47
de Neyman-Scott, 144
inverse, 519
mal pos´e, 405
NP-complet, 313
processus
bˆeta, 52
de Dirichlet, 364
de saut, voir naissance et mort,
processus de saut
de L´evy, 52
inf´erentiel
apport subjectif dans un, 559
non stationnaire, 208
stationnaire, 211
programme
d’optimisation, 557
informatique, 315
universel, 556
projection, 475, 510, 541
de Kullback-Leibler, 420
proposition, 326
choix d’une, 326, 327, 329
ind´ependante, 329
par marche al´eatoire, 327, 329, 344
pseudo-a priori, 391
puissance
d’un test, 258
de calcul, 323
du continu, 36
loi, 340
p-value, 266, 267, 273, 439
admissible, 440
comportement conservateur de la,
273
quadrature, 314
quantile, 153
quantit´e pivotale, 148
queue, 117
´epaisse, 136
radiographie, 4
randomisation, 150, 261, 264
et distributions discr`etes, 279
Rao-Blackwellisation, 332, 333, 338,
353, 390
rapport des risques, 138
rasoir d’Occam, 398
rationalit´e, 63
des d´ecideurs, 63
r´ealisation, 7
r´ecompense mon´etaire, 62
r´econciliation, 271, 301, 561
r´ecurrence, 432
au sens de Harris, 323
d’une chaˆıne, 431, 433
de Durbin-Levinson, 211, 228
r´eduction, 68, 115
des principes, 17
et mod´elisation, 238
par la mod´elisation, 2–4, 8
r´ef´erence
a priori
comme loi co¨ıncidente, 150
d’ordre inverse, 151
pour la calibration lin´eaire, 47
r´egion
`a queues ´egales, 280
HPD, 28, 148, 149, 283, 284, 542
α-cr´edible, 278
non connexe, 280
uniform´ement plus pr´ecise, 281
r`egle
d’arrˆet, 19
de score, 96
propre, 96
r´egression
et calibration, 47
inverse, 226
isotonique, 39
lin´eaire, 132, 179
logistique, 132, 160, 218, 239, 350,
355, 400, 533
mod`ele de, 203, 206
non param´etrique, 6
normale, 413
poissonienne, 4
regroupement, 337
rejet d’une hypoth`ese nulle, 264
renouvellement, 324

636
Index des mati`eres
reparam´etrisation, 129, 138, 211, 214,
215
invariance par, 101, 142
naturelle, 158
non param´etrique, 406
r´ep´etabilit´e des exp´eriences, 67, 117,
170, 551, 552, 559
r´eponse la moins favorable, 268, 269
r´eponse non informative
pour des tests, 245
repr´esentation
a priori, 553
de la mati`ere, 553
espace d’´etat, 213, 214, 364
pour ARMA(p,q), 215
forward-backward, 358, 532
int´egrale, 557
markovienne, 431
non param´etrique, 171
par m´elange cach´e, 362
par polynˆome retard, 228, 229
polynomiale orthogonale, 406
probabiliste, 551
stationnaire, 232
r´eseaux
bay´esiens, 549
de neurones, 52, 549
restaurant chinois, 48
r´etr´ecisseur
estimateur `a, voir estimateur
r´etroaction a priori, 162
RIC, 414
risque
amateurs de, 64, 85
aversion au, 64, 65
constant, 79, 82
continu, 434
ensemble de, 443
estimateur sans biais du, 102, 108,
515
fr´equentiste, 66
int´egr´e, 68
maximin, 77
minimax, 73
vecteurs de, 77
robustesse, 31, 91, 120, 124, 514, 518
dans la fonction de coˆut, 155
et analyse hi´erarchique, 558
rumeur, 286
R, 360
sans biais, 15, 108
sauts r´eversibles, 397
Schwarz
crit`ere de, 381
score de Brier, 95
s´election de variables, 372, 396, 400
descendante, 402
montante, 402
s´election, 230
s´eparateur, 545
s´eries temporelles, 206
Shakespeare
vocabulaire de, 198
SIDA, 496
signal
traitement du, 549
signiﬁcativit´e
niveau de, 259, 261, 264, 266
usuel, 271
simulation, 306
acceptation-rejet, 346, 347
alternative `a la, 319
bases, 315–319
d’une loi conditionnelle, 330, 339
it´erative, 340
r´esultats, 53
software, 313
sommet, 544
S-Plus, 361
stationnarit´e, 208, 209, 215, 324
contrainte de, 208
Statistique
bay´esienne
d´eﬁnition de la, 10
non param´etrique, 51
ﬁduciaire, 50, 551
linguistique, 198
math´ematique, 51
perspective conditionnelle dans la,
14
statistique
compl`ete, 37, 38
d’ordre, 37, 129
d´eﬁnition, 15
du rapport de vraisemblance, 173
exhaustive, 15, 125, 199
minimale, 16
invariante maximale, 471

Index des mati`eres
637
libre, 37, 38, 298, 301, 302, 471
Stein, 15, 106, 108, 479
condition d’admissibilit´e, 143
de eﬀet, 497
eﬀet, 92, 102, 186, 264, 282, 428,
513, 523, 525, 527, 558
analyse fr´equentiste de l’, 107
et espace des param`etres ﬁni,
108
robuste, 108
stochastique
complexit´e, 151
domination, 92, 111
STUB, voir bornes inf´erieures de
demi-queue
subjectivit´e, 123
suite
´echangeable, 171
inﬁniment ´echangeable, 171
surajustement, 373
surharmonicit´e, 516, 541
table de contingence, 217
technique de saturation, 393
test, 34, 239
bilat`eral, 250
comme probl`eme d’estimation, 237
de Neyman-Pearson, 18
de Student, 301
du khi deux, 264, 405
du rapport de vraisemblance
s´equentiel, 301
r´ep´et´e, 301
sans biais, 261
uniform´ement plus puissant
(UPP), 259
uniform´ement plus puissant sans
biais (UPPS), 262
minimax, 298
th´eor`eme
Central Limit, 4, 198, 199, 264
de Basu, 37
de Bayes, voir Bayes, th´eor`eme
de factorisation, 16, 21
de Fubini, 43, 69
de Hammersley-Cliﬀord, 41, 352
de Hunt-Stein, 81, 479, 482, 483,
490
de la double projection, 421
de Markov-Kakutani, 482
de Rao-Blackwell, 16, 17, 76, 81,
98, 333, 480
de repr´esentation de Riesz, 444
ergodique, 323, 324
hyperplan s´eparateur, 443
th´eorie
de l’information, 151
de la connaissance, 553
de la D´ecision, 8, 63, 112, 237
bay´esienne, 184
fondements de la, 285
fr´equentiste, 71
de Neyman-Pearson, 89, 239, 258,
274, 280
des jeux, 58, 69, 73, 75
des tests, 237
total
ignorance, 137
ordre, 63, 67, 68
traitement
analytique, 341
commodit´e du, 124
du signal, 118, 211, 358
tramway, 193
transformation d’´echelle, 469
transience, voir Markov
transition
noyau de, 326
transitivit´e, 63, 169
utilit´e
construction de l’, 170
existence de la fonction d’, 63
vache laiti`ere, 117
valeur, 80
aberrante, d´etection, 364
validation asymptotique
des estimateurs de Bayes, 54
des m´ethodes non param´etriques,
6
des m´ethodes bay´esiennes
empiriques, 525
du maximum de vraisemblance, 23
variable
auxiliaire, 308, 340, 341, 354
explicative, 372
latente, 313

638
Index des mati`eres
variance
sous-estimation de la, 373
estimation d’une, normale, 282
fonction, 159
h´et´erog`ene, 233
inconnue, 204
sous-estimation de la, 528
VIH, 497
virtuel
´echantillon, 116
observation, 124, 153, 171, 201,
299
vitesses de galaxies, 371, 419
volatilit´e, 233, 235, 341
vraisemblance, 9, 17, 21, 170
d´eﬁnition r´ecursive de la, 213
explicite, 213
observ´ee, 233
principe, voir principe de
vraisemblance
proﬁl´ee, 179
rapport de, 242, 262, 380
Wheel of Time, The, 1, 55, 113, 175,
237, 305, 369, 423, 463, 495,
549
within-between, 325

Achevé d’imprimer sur les presses de l’Imprimerie BARNÉOUD
B.P. 44 - 53960 BONCHAMP-LÈS-LAVAL
Dépôt légal : novembre 2005 - N° d’imprimeur : 511.076
Imprimé en France

