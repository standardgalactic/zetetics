A B AY E S I A N N E T W O R K M O D E L F O R P R E D I C T I N G D ATA
B R E A C H E S
lisa de wilde
s1091514
Caused by Insiders of a Health Care Organization
Services, Cybersecurity and Security Research Group
EEMCS
University of Twente in cooperation with Delft University of Technology
December 9, 2016

supervisors:
Dr. ir. Wolter Pieters
Prof. dr. ir. Raymond Veldhuis 
Ir. Ali Ougajou (KPMG)
Lisa de Wilde: A Bayesian Network Model for Predicting Data Breaches,
Caused by Insiders of a Health Care Organization, © December 9,
2016

A B S T R A C T
In the Netherlands organizations are required by law to protect per-
sonal data with technical and organizational measures. Since January
2016 they are also required to report breaches of security leading to (a
considerable likelihood of) serious adverse effects on the protection
of personal data to the Dutch data protection authority (in Dutch:
autoriteit persoonsgegevens). In the health care sector medical data,
which is extra sensitive, is processed and therefore security is even
more important.
Data breaches are, in this sector, mostly caused by insiders who
have malicious intentions or make mistakes. Because insiders already
have access to the data and have capabilities not known to other (ex-
ternal) attackers it is easier for them than for outsiders to misuse the
data. A malicious insider attack can be characterized by the motiva-
tion and capability of the attacker and the opportunity to perform
the attack. In general insiders do not have a reason to make mistakes
and therefore the accidental insider threat can be characterized by the
(lack of) capability and the opportunity to perform the attack. These
elements can be observed before a data breach occurs and therefore
are called “prior indicators” of a data breach. Each element can be
divided into speciﬁc prior indicators related to the insider threat.
For organizations it is hard to protect themselves effectively against
insider threats and make sure that data breaches do not occur. To
help organizations determine whether a data breach is likely to occur
Bayesian Networks (BNs) can be used. With this modeling technique it
is possible to show (probabilistic) relationships among many causally
related variables. Since a conditional probability table is related to
each variable in this model predictions about variables given speciﬁc
information can be made. An example of such a prediction is the
probability a data breach occurs when the employees are stressed.
In the context of security and privacy, however, there is limited in-
formation available on how BNs can be created and used in practice.
This research contributes to this by developing a model that combines
observed prior indicators of a data breach and measures taken by an
organization to predict the probability of a data breach in a health
care organization as a kind of risk assessment. The model combines
both malicious and accidental insider threats posed by a group of
insiders. When changing the observations the probabilities for differ-
ent scenarios can be determined. In this way the best combination of
measures to minimize the probability of a data breach given certain
prior indicators can be identiﬁed.
iii

To investigate how BNs must be built in the context of security and
privacy we created a BN based on a malicious and accidental insider
threat to mobile devices owned by the employer or (when allowed) by
the employees themselves. Employees can lose both devices and the
employer-owned devices can be misused by copying data to private
devices. The BN can be used to predict the probability that a data
breach caused by a group of employees of a health care organization
who lose or misuse mobile devices occurs within a year.
The initial model was created using literature and common sense.
To keep the model simple we grouped multiple measures together in
variables and created an assessment tool. This tool calculates which
observations must be entered into the BN after the organization en-
tered which measures are taken and which are not. Because freely
available data breach databases do not contain speciﬁc causes of data
breaches, we updated the model using experts knowledge. We inter-
viewed two legal advisers and a security ofﬁcer, conducted a survey
with cyber security master students and cyber security consultants
and arranged a focus group session with security and privacy experts.
The updated assessment tool also contains prior indicators.
To investigate the usefulness of the model in practice the assess-
ment has been performed in three Dutch hospitals and interviews
with employees responsible for information security in the hospitals
took place. Based on the results of the assessments the model was
updated again, which resulted in a ﬁnal BN model structure for the
mobile device case. Since we are also interested in the applicability of
such a model to other threats, we created a general BN structure that
can be extended with multiple prior indicators and measures (see
ﬁgure 1).
Figure 1: General Bayesian network model.
iv
Motivation
Capability
Malicious 
opportunity
Accidental 
action
Data breach
Technical 
measures
Procedural 
measures
Physical 
measures
- False
- True
- Low
- Medium
- High
- False
- True
- False
- True
- False
- True
- False
- True
Malicious 
action
- False
- True
Protection level
- Low
- Medium
- High
- Low
- Medium
- High
Awareness 
measures
- False
- True
Accident 
opportunity
- Low
- Medium
- High
- Low
- Medium
- High
Legend
Basis variables
Prior indicator 
variables
Measure 
variables

According to the interviewees in the hospital a BN does have po-
tential to predict the probability of data breaches caused by insiders
based on prior indicators and measures, but should be used in combi-
nation with the assessment tool. Together, the BN and tool, provide a
clear oversight of the current measures implemented in the organiza-
tion and the improvements that could be done. This allows the user
to control the situation and consciously decide what actions should
be taken. Users of the tool would probably the management board
of the hospital, but also the legal advisers and security ofﬁcers and
other employees responsible for information security.
Creating a BN, however, does results in multiple challenges. First,
prior indicators and measures related to a speciﬁc threat or case
should be searched for. They should also be tailored to the health
care sector and their effect on data breaches must be known. Fur-
thermore, organizations are not by default allowed to monitor their
employees and therefore the law including the right to privacy and
ethical problems with monitoring must be taken into account while
selecting prior indicators. Filling the conditional probability tables of
the nodes is also quite hard, since limited data is available for this. At
this moment the best way to ﬁll the tables is by using expert knowl-
edge. Because the model cannot contain detailed variable descriptions
it is hard to make clear in the variable names what is exactly meant
with them. So, to be able to properly use a BN additional guidance,
such as our assessment tool, would be useful. Finally, to avoid model
complexity the number of parents of a node and the number of states
must be limited to three and ﬁve respectively. However, the smaller
the number of states, the lower the accuracy of the model.
v


Friendship is the hardest thing in the world to explain. It is not something
you learn in school. But if you have not learned the meaning of friendship,
you really have not learned anything.
— Muhammad Ali
A C K N O W L E D G E M E N T S
This thesis marks the end of my student life which started on Wednes-
day August 18, 2010. On this day I joined the Kick-In of the University
of Twente and was ready to start my bachelor Technical Computer
Science. I joined the do-group TEGEL 11 and the foundation for close
friendships was created. TEGEL 11, thank you all for the fun we had
and will have in the future.
Soon after the introduction period I joined my ﬁrst committee at the
study association Inter-Actief. This resulted in a total of seven com-
mittees with a lot of fun, instructive moments and awesome activities.
The highlights were deﬁnitely the SurroundIT congress I organized
together with my enthusiastic committee members and the year as
board member of Inter-Actief. Thanks to all my committee members,
board 35 “Met TOM op de kofﬁe” and active members of Inter-Actief.
After ﬁnishing my bachelor, I started with my master Computer Sci-
ence - 4TU Cyber Security in February 2015. The past six months I
have been working on my thesis at KPMG. This was a period of hard
work with a lot of traveling and train delays. But, it was a rewarding
experience to discover what the world of business and research en-
tails and it helped me to determine my desires for a future job. So,
thanks to all my colleagues of the ITA North and Cyber department.
Special thanks go to my supervisors, Ali, Raymond and Wolter for be-
ing very helpful, motivating me and pushing me to keep challenging
myself. Saba, thank you for all the feedback and good discussions
we had. I also want to thank Anne-Greeth, Joris, Martijn, Roeland,
Sebastiaan and Tim with whom I could discuss my challenges and
progress and who provided me with a lot of feedback. Thank you for
all advise and fun! Finally, I want to thank my parents, brother, sister
and grandmother for all their support, advise and love.
Now, 6 years and about 4 months later it is time to ﬁnish my student
life and starting my “burger” (civilian) life. I hope you all enjoy read-
ing my thesis and be aware of personal data of yours and others.
— Lisa
vii


C O N T E N T S
1
introduction
1
1.1
Background
. . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Problem Statements . . . . . . . . . . . . . . . . . . . . .
2
1.3
Research Questions . . . . . . . . . . . . . . . . . . . . .
4
1.4
Research Method . . . . . . . . . . . . . . . . . . . . . .
5
1.5
Conceptual Framework . . . . . . . . . . . . . . . . . . .
7
1.6
Contribution of this Research . . . . . . . . . . . . . . .
10
1.7
Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
2
state-of-art
11
2.1
Bayesian Networks . . . . . . . . . . . . . . . . . . . . .
11
2.1.1
Nodes and Values
. . . . . . . . . . . . . . . . .
12
2.1.2
Structure . . . . . . . . . . . . . . . . . . . . . . .
13
2.1.3
Conditional Probabilities
. . . . . . . . . . . . .
14
2.1.4
Reasoning with BNs . . . . . . . . . . . . . . . .
15
2.1.5
Intercausal Reasoning . . . . . . . . . . . . . . .
18
2.1.6
Combined Reasoning
. . . . . . . . . . . . . . .
19
2.2
Applications and Extensions of Bayesian Networks . .
20
2.2.1
A Bayesian Network Model for Predicting In-
sider Threats
. . . . . . . . . . . . . . . . . . . .
20
2.2.2
Bayesian Network Modeling for Analysis of Data
Breach in a Bank . . . . . . . . . . . . . . . . . .
21
2.2.3
Detecting Threatening Behaviour Using Bayesian
Networks
. . . . . . . . . . . . . . . . . . . . . .
23
2.2.4
Privacy Intrusion Detection Using Dynamic Bayesian
Networks
. . . . . . . . . . . . . . . . . . . . . .
25
2.2.5
Risk Management Using Behavior Based Bayesian
Networks
. . . . . . . . . . . . . . . . . . . . . .
28
2.3
Comparison . . . . . . . . . . . . . . . . . . . . . . . . .
30
2.4
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . .
30
3
insider threats
33
3.1
Insiders . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
3.2
Insider Threat . . . . . . . . . . . . . . . . . . . . . . . .
34
3.3
Behavioral Theories . . . . . . . . . . . . . . . . . . . . .
34
3.3.1
Overview of Behavioral Theories . . . . . . . . .
37
3.4
Characterizing the Insider Threat . . . . . . . . . . . . .
38
3.4.1
Frameworks Related to Motivation, Capability
and Opportunity . . . . . . . . . . . . . . . . . .
38
3.4.2
Behavioral Indicators . . . . . . . . . . . . . . . .
41
3.4.3
Organizational Indicators . . . . . . . . . . . . .
42
3.4.4
Technical Indicators
. . . . . . . . . . . . . . . .
42
3.5
Selecting Indicators . . . . . . . . . . . . . . . . . . . . .
43
3.6
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . .
45
ix

x
contents
4
data breach prevention
47
4.1
Information Security . . . . . . . . . . . . . . . . . . . .
47
4.2
Law in the Health Care Sector . . . . . . . . . . . . . . .
48
4.2.1
Data Protection Act . . . . . . . . . . . . . . . . .
48
4.2.2
Other Laws
. . . . . . . . . . . . . . . . . . . . .
49
4.3
Norms and Guidelines in the Health Care Sector
. . .
49
4.3.1
Code of Conduct . . . . . . . . . . . . . . . . . .
49
4.3.2
Dutch Norms . . . . . . . . . . . . . . . . . . . .
50
4.3.3
International Standards . . . . . . . . . . . . . .
50
4.3.4
Guidelines . . . . . . . . . . . . . . . . . . . . . .
51
4.4
General Standards and Frameworks . . . . . . . . . . .
51
4.4.1
Cyber Security Framework for Critical Infras-
tructures . . . . . . . . . . . . . . . . . . . . . . .
52
4.4.2
Privacy Control Catalog . . . . . . . . . . . . . .
52
4.4.3
Standard of Good Practice for Information Se-
curity . . . . . . . . . . . . . . . . . . . . . . . . .
52
4.4.4
Generally Accepted Privacy Principles
. . . . .
53
4.5
Selecting Measures . . . . . . . . . . . . . . . . . . . . .
53
4.6
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . .
55
5
conceptual models
57
5.1
Scenario
. . . . . . . . . . . . . . . . . . . . . . . . . . .
57
5.2
Bayesian Network Type Selection . . . . . . . . . . . . .
58
5.3
Basic Model Structure
. . . . . . . . . . . . . . . . . . .
58
5.4
First Conceptual Model
. . . . . . . . . . . . . . . . . .
63
5.4.1
Nodes and Values
. . . . . . . . . . . . . . . . .
63
5.4.2
Structure . . . . . . . . . . . . . . . . . . . . . . .
65
5.5
Second Conceptual Model . . . . . . . . . . . . . . . . .
67
5.5.1
Nodes and Values
. . . . . . . . . . . . . . . . .
67
5.5.2
Structure . . . . . . . . . . . . . . . . . . . . . . .
70
5.6
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . .
71
6
alpha model
73
6.1
Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
6.2
Model Background . . . . . . . . . . . . . . . . . . . . .
74
6.3
Alpha Model . . . . . . . . . . . . . . . . . . . . . . . . .
75
6.3.1
Nodes and Values
. . . . . . . . . . . . . . . . .
75
6.3.2
Structure . . . . . . . . . . . . . . . . . . . . . . .
79
6.3.3
Probabilities . . . . . . . . . . . . . . . . . . . . .
80
6.3.4
Sensitivity Analysis
. . . . . . . . . . . . . . . .
84
6.3.5
Final Alpha Bayesian Network Model . . . . . .
86
6.4
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . .
87
7
beta model
89
7.1
Interviews with Legal Advisers . . . . . . . . . . . . . .
89
7.2
Interview with a Information Security Ofﬁcer
. . . . .
90
7.2.1
Mobile Device Case
. . . . . . . . . . . . . . . .
91
7.3
Survey
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
7.3.1
Results . . . . . . . . . . . . . . . . . . . . . . . .
93

contents
xi
7.4
Focus group . . . . . . . . . . . . . . . . . . . . . . . . .
95
7.4.1
Individual Assignment
. . . . . . . . . . . . . .
96
7.4.2
Group Assignment . . . . . . . . . . . . . . . . .
96
7.4.3
Suggestions . . . . . . . . . . . . . . . . . . . . .
97
7.5
Beta Model . . . . . . . . . . . . . . . . . . . . . . . . . .
99
7.5.1
Nodes and Values
. . . . . . . . . . . . . . . . .
99
7.5.2
Structure . . . . . . . . . . . . . . . . . . . . . . .
101
7.5.3
Probabilities . . . . . . . . . . . . . . . . . . . . .
101
7.5.4
Sensitivity Analysis
. . . . . . . . . . . . . . . .
101
7.5.5
Final Beta Bayesian Network Model . . . . . . .
104
7.6
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . .
104
8
gamma model
107
8.1
Hospital Validation . . . . . . . . . . . . . . . . . . . . .
107
8.1.1
Hospital A . . . . . . . . . . . . . . . . . . . . . .
108
8.1.2
Hospital B . . . . . . . . . . . . . . . . . . . . . .
110
8.1.3
Hospital C . . . . . . . . . . . . . . . . . . . . . .
112
8.2
Gamma Model . . . . . . . . . . . . . . . . . . . . . . . .
115
8.2.1
Nodes and Values
. . . . . . . . . . . . . . . . .
115
8.2.2
Structure . . . . . . . . . . . . . . . . . . . . . . .
116
8.2.3
Probabilities . . . . . . . . . . . . . . . . . . . . .
118
8.3
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . .
118
9
general model
119
9.1
Basic Bayesian Network Model . . . . . . . . . . . . . .
119
9.1.1
Nodes and Values
. . . . . . . . . . . . . . . . .
119
9.1.2
Structure . . . . . . . . . . . . . . . . . . . . . . .
121
9.2
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . .
121
10 discussion
123
10.1 Challenges . . . . . . . . . . . . . . . . . . . . . . . . . .
123
10.1.1 Variables . . . . . . . . . . . . . . . . . . . . . . .
123
10.1.2 Conditional Probability Tables . . . . . . . . . .
123
10.1.3 Model Representation . . . . . . . . . . . . . . .
124
10.1.4 Ethics . . . . . . . . . . . . . . . . . . . . . . . . .
124
10.2 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . .
125
10.2.1 Prior Indicators . . . . . . . . . . . . . . . . . . .
125
10.2.2 Measures . . . . . . . . . . . . . . . . . . . . . . .
126
10.2.3 Causal Relationships . . . . . . . . . . . . . . . .
126
10.2.4 Impacts . . . . . . . . . . . . . . . . . . . . . . . .
127
10.2.5 Conclusion . . . . . . . . . . . . . . . . . . . . . .
127
10.3 Future Work . . . . . . . . . . . . . . . . . . . . . . . . .
128
a
preliminaries
129
a.1
Directed Acyclic Graphs . . . . . . . . . . . . . . . . . .
129
a.2
Probability Theory
. . . . . . . . . . . . . . . . . . . . .
130
a.2.1
Basics . . . . . . . . . . . . . . . . . . . . . . . . .
130
a.2.2
Random Variables
. . . . . . . . . . . . . . . . .
135
b
information gathering for beta model
139
b.1
Survey
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
139

xii
contents
b.1.1
Introduction . . . . . . . . . . . . . . . . . . . . .
139
b.1.2
Case
. . . . . . . . . . . . . . . . . . . . . . . . .
140
b.2
Focus Group Results . . . . . . . . . . . . . . . . . . . .
141
b.2.1
Results Individual Assignment . . . . . . . . . .
141
b.2.2
Reasoning . . . . . . . . . . . . . . . . . . . . . .
141
c
information gathering for gamma model
147
c.1
Interview Questions
. . . . . . . . . . . . . . . . . . . .
147
c.2
Observations Hospital Assessments
. . . . . . . . . . .
149
d
materials
151
d.1
Focus Group Session . . . . . . . . . . . . . . . . . . . .
151
d.2
Data Breach Prediction Models . . . . . . . . . . . . . .
151
d.3
Data Breach Assessment Tools
. . . . . . . . . . . . . .
151
d.4
Sensitivity Analyses
. . . . . . . . . . . . . . . . . . . .
152
d.5
Hospital Assessments
. . . . . . . . . . . . . . . . . . .
152
bibliography
153

L I S T O F F I G U R E S
Figure 1
Final Bayesian network model . . . . . . . . . .
iv
Figure 2
Research method overview
. . . . . . . . . . .
5
Figure 3
Conceptual model . . . . . . . . . . . . . . . . .
8
Figure 4
Detailed conceptual model . . . . . . . . . . . .
9
Figure 5
Directed acyclic graph to explain the Markov
condition . . . . . . . . . . . . . . . . . . . . . .
11
Figure 6
Nodes and states for the lung cancer problem
13
Figure 7
Bayesian network for the lung cancer problem
14
Figure 8
Bayesian network for the lung cancer problem
with conditional probability tables . . . . . . .
15
Figure 9
Bayesian network for the lung cancer problem
without observations . . . . . . . . . . . . . . .
16
Figure 10
Diagnostic reasoning . . . . . . . . . . . . . . .
17
Figure 11
Predictive reasoning
. . . . . . . . . . . . . . .
18
Figure 12
Intercausal reasoning - part 1 . . . . . . . . . .
19
Figure 13
Intercausal reasoning - part 2 . . . . . . . . . .
19
Figure 14
Combined reasoning . . . . . . . . . . . . . . .
20
Figure 15
Bayesian network versus multi-entity Bayesian
network [39] . . . . . . . . . . . . . . . . . . . .
24
Figure 16
Dynamic Bayesian network example [5] . . . .
26
Figure 17
Threat components and their relationships [12]
38
Figure 18
Motivation of the actor [56]
. . . . . . . . . . .
40
Figure 19
Skill set of the actor [56] . . . . . . . . . . . . .
40
Figure 20
Opportunity of the actor [56]
. . . . . . . . . .
41
Figure 21
General insider threat indicators
. . . . . . . .
43
Figure 22
Motivation indicators for our model . . . . . .
44
Figure 23
Capability indicators for our model
. . . . . .
44
Figure 24
Opportunity indicators for our model . . . . .
45
Figure 25
General protection measures . . . . . . . . . . .
53
Figure 26
Measure areas for our model [35] . . . . . . . .
55
Figure 27
Example extension of a measure category [35]
55
Figure 28
Typical Bayesian network structure [37] . . . .
60
Figure 29
Typical Bayesian network structure applied to
our variables . . . . . . . . . . . . . . . . . . . .
60
Figure 30
Extended Bayesian network structure with our
variables
. . . . . . . . . . . . . . . . . . . . . .
61
Figure 31
USB stick found example 1 . . . . . . . . . . . .
61
Figure 32
USB stick found example 2 . . . . . . . . . . . .
62
Figure 33
Basic BN structure for our research . . . . . . .
63
Figure 34
First conceptual model . . . . . . . . . . . . . .
65
Figure 35
Second conceptual model
. . . . . . . . . . . .
72
xiii

xiv
List of Figures
Figure 36
Alpha model structure . . . . . . . . . . . . . .
82
Figure 37
Snapshot alpha Bayesian network model
. . .
85
Figure 38
Sensitivity analysis of the data breach node -
table . . . . . . . . . . . . . . . . . . . . . . . . .
86
Figure 39
Sensitivity analysis of the data breach node -
graph . . . . . . . . . . . . . . . . . . . . . . . .
87
Figure 40
Alpha Bayesian network model . . . . . . . . .
88
Figure 41
Beta model structure . . . . . . . . . . . . . . .
102
Figure 42
Beta Bayesian network model . . . . . . . . . .
105
Figure 43
Gamma model structure . . . . . . . . . . . . .
117
Figure 44
General Bayesian network model . . . . . . . .
121
Figure 45
Directed graphs . . . . . . . . . . . . . . . . . .
129
Figure 46
Graph to explain the deﬁnition of parent, de-
scendant, ancestor and non-descendant . . . .
130
Figure 47
Venn diagrams for conditional probability . . .
133
Figure 48
Experiment with 13 objects [52] . . . . . . . . .
134

L I S T O F TA B L E S
Table 1
Research methods per research question . . . .
7
Table 2
Markov condition based on ﬁgure 5
. . . . . .
12
Table 3
Bayesian network variables by [6] . . . . . . . .
22
Table 4
Prior belief about the weather condition [5] . .
27
Table 5
Prior belief about the relationship between the
weather condition and Bob’s activities and the
evolution of the weather condition [5] . . . . .
27
Table 6
Comparison of four types of Bayesian networks
31
Table 7
Overview of behavioral theories . . . . . . . . .
37
Table 8
First conceptual model: nodes and values . . .
64
Table 9
Second conceptual model: prior indicators and
values . . . . . . . . . . . . . . . . . . . . . . . .
69
Table 10
Second conceptual model: measures and values
70
Table 11
Alpha model: basis nodes and values
. . . . .
76
Table 12
Alpha model: prior indicators and values . . .
77
Table 13
Alpha model: measures and values . . . . . . .
79
Table 14
Conditional probability table of data breach . .
85
Table 15
Interview with an information security ofﬁcer:
measures for mobile device misuse and loss
.
92
Table 16
Survey: motivations and measures for mobile
device misuse
. . . . . . . . . . . . . . . . . . .
93
Table 17
Survey: capability and measures for mobile de-
vice misuse and loss
. . . . . . . . . . . . . . .
94
Table 18
Survey: opportunities and measures for mobile
device misuse and loss . . . . . . . . . . . . . .
95
Table 19
Focus group: characteristics of the participants
96
Table 20
Focus group: results conditional probability ta-
ble Skills
. . . . . . . . . . . . . . . . . . . . . .
97
Table 21
Focus group: results group assignment
. . . .
98
Table 22
Beta model: changes in the conditional proba-
bility tables . . . . . . . . . . . . . . . . . . . . .
103
Table 23
General model: nodes and values . . . . . . . .
120
Table 24
Focus group: results individual assignment -
prior indicators
. . . . . . . . . . . . . . . . . .
142
Table 25
Focus group: results individual assignment -
measures . . . . . . . . . . . . . . . . . . . . . .
142
Table 26
Observations for hospital A, B and C . . . . . .
150
xv

A C R O N Y M S
AICPA American Institute for Certiﬁed Public Accountants
BN
Bayesian Network
BYOD Bring Your Own Device
CICA Canadian Institute of Chartered Accountants
CPT
Conditional Probability Table
DAG Directed Acyclic Graph
DBN Dynamic Bayesian Network
DPA Data Protection Act
EMM Enterprise Mobility Management
EU
European Union
GAPP Generally Accepted Privacy Principles
GDPR General Data Protection Regulation
GDT General Deterrence Theory
IRAM2 Information Risk Assessment Methodology 2
ISF
Information Security Forum
ISO
International Organization for Standardization
MEBN Multi-Entity Bayesian Network
MFrag MEBN Fragment
NIST National Institute of Standards and Technology
SBT
Social Bond Theory
SCP
Situational Crime Prevention
SLT
Social Learning Theory
TPB
Theory of Planned Behavior
VPN Virtual Private Network
xvi

1
I N T R O D U C T I O N
This chapter introduces our research and provides background infor-
mation on data breaches and establishes two problem statements in
sections 1.1 and 1.2. The research questions and proposed research
method are discussed in sections 1.3 and 1.4 and the conceptual
framework of this research is provided in section 1.5. Finally, the con-
tribution of this research is stated in section 1.6 and an outline for the
rest of this thesis is given in section 1.7.
1.1
background
Background on
personal data
protection
In the European Union (EU) “everyone has the right to the protection
of personal data concerning him or her” (article 8 of charter of fun-
damental rights of the European Union [22]). This right is regulated
separately in each Member State of the EU by the data protection
directive (Directive 95/46/EC). This directive provides a regulatory
framework that sets limits on the collection and use of personal data.
The goal of this framework is to strike a balance between the pro-
tection for the privacy of individuals on a high level and the free
movement of personal data within the EU. Furthermore, it requires
that each Member State has an independent national body responsi-
ble for the supervision of any activity related to personal data pro-
cessing [21]. In the Netherlands this directive is implemented in the
Data Protection Act (DPA) [18]. This directive (and thus the DPA) will
be replaced by the General Data Protection Regulation (GDPR) [23] in
May 2018. One of the differences between the directive and regulation
is that the latter requires organizations to report data breaches to the
national data protection authority.
Background on data
breaches
Since January 2016 the Dutch DPA contains a comparable data
breach reporting requirement. This act deﬁnes personal data as “any
information relating to an identiﬁed or identiﬁable natural person”
and data processing as “any operation or any set of operations con-
cerning personal data, including in any case the collection, record-
ing, organization, storage, updating or modiﬁcation, retrieval, consul-
tation, use, dissemination by means of transmission, distribution or
making available in any other form, merging, linking, as well as block-
ing, erasure or destruction of data”. To protect the data against loss
or unlawful processing and thus avoid data breaches organizations
must take technical and organizational measures. When the security
is breached and this leads to (a considerable likelihood of) serious
adverse effects or to serious adverse effects on the protection of per-
1

2
introduction
sonal data organizations are required to report this to the Dutch data
protection authority within 72 hours [8] [18].
Data concerning
health
For speciﬁc categories of data, such as data concerning health, pro-
tection is even more important and stricter rules apply before these
types of data can be processed (article 13 of the Dutch DPA [18]).
Despite the importance of health data protection, data breaches in
the health sector still occur. To emphasize this, the report of Verizon
[73] will be used. In this report the distinction between security in-
cidents and data breaches is made: a security incident is “a security
event that compromises the integrity, conﬁdentiality or availability of
an information asset” and a data breach is “an incident that results
in the conﬁrmed disclosure (not just potential exposure) of data to
an unauthorized party”. According to the report 69,3% of the secu-
rity incidents in the health care sector result in a data breach. The
top 3 causes of security incidents resulting in (conﬁrmed) data losses
in this sector are insider and privilege misuse (32%), miscellaneous
errors (22%) and physical theft and loss (19%) [73].
Breaches by insiders
All three causes are (partly) related to malicious or ignorant insid-
ers and will be discussed on the basis of two recent news articles. The
ﬁrst article is about a doctor of a Dutch hospital who discussed dis-
ease details and medications of at least ten patients in the train via
phone [49]. This might be an example of a miscellaneous error due
to an employee who is not aware of the organizations’ policies. The
other example is of a Dutch hospital employee who stored names, pa-
tient numbers, dates of birth and other medical data of 504 patients in
a spreadsheet on her private laptop. This password protected laptop
was stolen from her house which resulted in a data breach. Storing
data on private devices is not allowed by the hospital and therefore
this news item is not only an example of physical (outsider) theft, but
also of insider misuse or a miscellaneous error [36].
1.2
problem statements
Identifying insider
threats
Malicious insider threats are described as the most serious security
problem for organizations in many researches. These threats are hard
to mitigate since insiders have information and capabilities not known
to other (external) attackers. Insiders, however, can also make errors
which might result in a data loss as well [6].
Insider attacks can be characterized by the reason and the skills
needed to perform the attack within the organization and the chance
to initiate the attack. These elements are also known as motivation, ca-
pability or skills set and opportunity. Each of the terms can be divided
into multiple speciﬁc prior indicators related to the insider threat [56].
Measures to protect
personal data
Knowing the insider threats the organization faces can be used to
determine the related risks [60]. In the context of personal data it
could be used to determine which measures should be taken to pro-

1.2 problem statements
3
tect personal data and decrease the data breach probability. However,
organizations do have limited resources and cannot implement more
and more measures. Therefore, they have to choose the measures
which have the highest impact on the probability of a data breach.
The measures can be divided into three categories: preventive, de-
tective and corrective [26]. A preventive measure tries to prevent a
data breach from occurring. An example of such a measure related to
the health care sector would be to use a ﬁngerprint scanner to get ac-
cess to the computers. In this way it is not possible for doctors to share
their passwords and it will be way harder for unauthorized users to
get access to the computer. The detective and corrective measures, on
the other hand, attempt to detect the data breach and reverse its ef-
fects. So, if an unauthorized insider did get access to the computer,
an automatic logging and network monitoring system could be used
to detect abnormal activity on the computer. Once it turns out that a
nurse used the computer when the doctor was still logged on addi-
tional measures should be taken.
Another categorization given by Gibson [26] is that of procedural,
technical and physical measures. Procedural measures are in place to
deﬁne and guide the actions of employees within the organization.
These measures are mainly procedures and policies, but a training is
also a procedural measure. Technical measures automate protection
and enforce security using a technical method such as prompting the
user to change their password before they can perform any other
task on the computer. Finally, physical measures control the physical
environment and an example of such a measure might be a lock on
the door to the archive with patient information.
Practical problem
statement
Based on the previous paragraphs we identiﬁed a practical problem
for health care organizations in the context of insider threats:
The insider threat is a serious problem in the health care sector and for
organizations it is difﬁcult to characterize this threat and to effectively
protect themselves against data breaches caused by insiders.
Bayesian networks
One solution for this problem is to create a model that combines
indicators of a data breach and measures taken by an organization to
predict the probability of a data breach as a kind of risk assessment.
The type of model that could be used is a Bayesian Network (BN). Us-
ing this modeling technique (probabilistic) relationships among many
causally related variables, such as the level of happiness in the orga-
nization, a data breach and the procedures for performance reviews,
can be shown. Each variable has a probability table related to it which
shows the probability of the variable happening, being successful et
cetera. Based on these probabilities the probability of a data breach
when certain measures are taken and prior indicators of data breaches
are observed can be determined. When changing the observations the
probabilities for different scenarios can be determined. In this way the

4
introduction
best combination of measures to minimize the probability of a data
breach given certain prior indicators can be identiﬁed.
Theoretical problem
statement
However, there are only a limited number of researches performed
on Bayesian networks in the context of security and privacy and to
the best of our knowledge it is not known how models in this context
can be used effectively in practice. Thus, using BNs for our research
results in a theoretical problem as well:
Bayesian networks are a modeling technique to make predictions about
variables given speciﬁc information, however in the context of security and
privacy there is limited information available on how Bayesian networks
can be created and used in practice.
1.3
research questions
Research goal
Since most data breaches in the health care sector are caused by in-
siders and there is limited information available about the use of
Bayesian networks in the context of security and privacy the goal of
this research is to create a Bayesian network to predict the probability of a
data breach caused by a group of insiders of a health care organization given
certain prior indicators and preventive measures and test its usefulness in
practice. The indicators will be related to malicious and accidental insider
threats and focus on the motivation, capability and opportunity of a group
of insiders. This model can also be used to determine which measures should
be taken to minimize the probability of a data breach.
Research questions
To reach this goal the following two main research questions with
four subquestions will be answered:
1. How can Bayesian networks be used to determine the probabil-
ity of a data breach in a health care organization caused by an
insider?
a) Which indicators related to insider motivation, capability
and opportunity can be used to predict a data breach in a
health care organization?
b) Which preventive measures decrease the probability of a
data breach in a health care organization?
c) What are the causal relationships between an indicator,
measure and data breach?
d) How are indicators and measures related to the probability
of a data breach?
2. How useful are Bayesian networks to predict data breaches in
real world health care organizations?
The subquestions are based on how BNs can be built and what in-
formation is needed for this. The third subquestion is extra important
since the whole model will be based on the discovered basic structure
of an indicator, measure and data breach.

1.4 research method
5
1.4
research method
This research is divided into four phases: preparation, model, vali-
dation and ﬁnalization and each of those phases consist of multiple
steps. These steps are based on the guidelines of Marcot et al. [41]
and Chen and Pollino [14] and the lung cancer example of Korb and
Nicholson [38]. An overview of the research steps can be found in
ﬁgure 2 and each phase will be described in more detail below.
7. Gather 
information for alpha 
model
10. Validate alpha 
model
11. Create beta 
model
9. Select experts
8. Create alpha 
model
12. Select health care 
organizations
13. Validate beta 
model
14. Create gamma 
model
15. Create general 
model
16. Discuss 
challenges and 
conclusions
17. Discuss future 
work
1. Gather 
information about 
prior indicators
2. Gather 
information about 
measures
4. Create first 
conceptual model
6. Determine case 
scenario
3. Determine basic 
Bayesian network 
structure
5. Create second 
conceptual model
Figure 2: Research method overview.
Tool
To answer the research questions we will create multiple BNs. For
this several tools exists, but only the tools GeNIe [10], Netica [55]
and AgenaRisk [2] have been explored. The functionally of the tools
is quite similar, but we prefer the user interface of AgenaRisk and
therefore this tool will be used to create the models. This tool allows
us to model, analyze and predict risk and supports both diagnostic
and predictive reasoning about uncertainty using BNs.

6
introduction
Preparation phase
This research starts with the preparation phase in which we will
gather information that will be used to determine the prior indicators
and measures for the Bayesian network. The prior indicators will be
gathered by performing a literature study using terms such as: “char-
acterization”, “insider threats”, “indicators”, “insider behavior” and
“prediction”. We are especially interested in frameworks with charac-
terizations of the insider threat, since we can reuse them. In order to
ﬁnd measures to protect organizations against data breaches we will
start with searching for law that applies in the Dutch health care sec-
tor. After that, we will search for norms, standards, frameworks and
guidelines that are related to information protection and contain spe-
ciﬁc measures that organizations can take to protect themselves. With
the collected information subquestions 1 and 2 will be answered.
Model phase
In the model phase subquestions 3 and 4 will be answered by cre-
ating a BN model for a speciﬁc case. Before this can be done the
basic structure of the model will be determined by identifying the
relations between a prior indicator, measure and data breach. Once
the basic structure is known, two conceptual models will be created
using the information of the preparation phase. Both models will be
supplemented with states to more precisely show the purpose of the
variables. The second model will be more comprehensive than the
ﬁrst one. After both models are ﬁnished the alpha model will be cre-
ated. This model will be based on a speciﬁc insider threat case and
will be described by the problem situation, model purpose and scope.
Information from the preparation phase and the conceptual models
will be used to create the alpha model. However, to add probabilities
to the nodes additional information about the relationships between
the variables will be searched for as well. A sensitivity analysis will be
performed to ﬁnd the absolute degree and the rank order of inﬂuence
of parent variables on each outcome variable. The model will be ad-
justed until it behaves as desired and will be reviewed by interviews
with two legal advisers and a information security ofﬁcer. Addition-
ally, six security and privacy experts from a large organization will
be selected for two focus group sessions. This selection will be based
on their expertise with privacy and security and whether they have
experience in the health care sector. These experts would have a more
general view on data security and breaches and could therefore be
very helpful to review the alpha model and suggest changes. Based
on the suggestions of the experts the model will be updated to the
beta model and the ﬁrst main research question will be answered.
Validation phase
The validation phase is about the usefulness of the beta model in
health care organizations and answering main research question 2.
First, security or privacy ofﬁcers in three hospitals will be selected.
This selection will be based on the size of the organization. With each
of the ofﬁcers an interview will be performed to validate the correct-
ness of the beta model and to discuss its use in practice. Additionally,

1.5 conceptual framework
7
we will perform an assessment to determine the data breach probabil-
ity within each organization. Using the interviews and assessments
we will update the beta model to the gamma model and determine
its usefulness in practice.
Finalization phase
During the ﬁnalization phase we will use the two conceptual and
three case model to create a general model that can be adjusted to
multiple threats. Finally, we will discuss the experienced challenges,
conclude this research and provide suggestions for future research.
Overview
An overview of the research methods per research question is given
in table 1. This table also shows the type of question and the chapter
in which the question is answered.
research question
type
chapter
1a. Which indicators related to in-
sider motivation, capability and op-
portunity can be used to predict a
data breach in the health care sector?
Knowledge
Chapter 3
1b. Which preventive measures de-
crease the probability of a data breach
in the health care sector?
Knowledge
Chapter 4
1c. What are the causal relationships
between an indicator, measure and
data breach?
Design
Chapter 5
1d. How are indicators and measures
related to the probability of a data
breach?
Design
Chapter 6
Chapter 7
2. How useful are Bayesian networks
to predict data breaches in real world
health care organizations?
Knowledge
Chapter 8
Table 1: Research methods per research question.
1.5
conceptual framework
In ﬁgure 3 the conceptual framework of this research is shown. This
research focuses on data breaches in the health care sector and takes
both malicious and accidental insider threats into account. In every
organization insiders pose a threat to one or multiple assets. For this
research threats related to personal data processed in health care or-
ganizations are in our interest. When this data falls into wrong hands
it can have enormous consequences for the patient, but also for other
parties. A combination of standard and special categories of personal

8
introduction
data can, for example, lead to medical identity theft. With the identity
of the patient the criminal can, among others, receive medical services
and prescription medication, but can also try to commit fraudulent
billing. This can have a negative impact on the reputation of the pa-
tient and is costly, complicated and time consuming to resolve [62].
Since not every threat results in a data breach, the explicit distinc-
tion between security incident and data breach is made. A threat has
one or more prior indicators that can be used to predict the likelihood
of a security incident or data breach. Additionally, measures can be
taken to limit the insider threat and to limit the probability of a secu-
rity incident or data breach. Once a security incident or data breach
has occurred posterior indicators, such as a found USB-stick or lap-
top, are visible and can be used to detect a breach. Note that the prior
and posterior indicators of a security incident may differ from the
prior and posterior indicators of a data breach. A posterior indicator
of a security incident might, for example, be a deviating amount of
internet trafﬁc, whilst this is not a direct posterior indicator of a data
breach. However, since this research is exploratory and only focuses
on predicting data breaches, the security incident and posterior indi-
cators will be left out and only measures and prior indicators related
to data breaches will be taken into account.
Measures
Data breach
Prior indicators
Security incident
Insider threat to 
personal data
Posterior indicators
Figure 3: Conceptual model (scope presented by the blue areas).
Figure 4 shows the detailed conceptual model for this research. The
prior indicators will be related to the motivation, capability and op-
portunity of a group of employees. This categorization is made be-
cause research of, among others, Nurse et al. [56] and Blyth and
Kovacich [12] shows that these three elements are related to an at-
tack. Furthermore, the indicators will be related to a group of em-
ployees, since this improves the ethical and legal acceptability of the
model. The organization wants to ensure a certain level of security,
but should affect the privacy of their employees as little as possible.

1.5 conceptual framework
9
To achieve a high level of security each individual should be assessed
separately, however this is time-consuming, costs money and affects
the privacy of the individuals. Because of personal data protection
laws organizations are not allowed to monitor employees individu-
ally unless there is a legitimate purpose whereby the measures may
only serve that purpose. This law does not apply when the monitor-
ing process is anonymous or automated intervention on the basis of
measurements is performed [20]. So, when our model can be applied
without referring to one individual it would be more acceptable to
use it in practice.
In order to build the model prior indicators discovered in litera-
ture will be taken into account. When determining the states for the
variables in the model only indicators visible at that moment will be
taken into account, e. g. the current happiness level of the employees.
As mentioned before measures can be divided in preventive, detec-
tive and corrective measures. This research only focuses on the pre-
ventive measures, since we are interested in predicting a data breach
and not in the actions taken after the occurrence of a data breach. Fur-
thermore, to protect an organization against threats a combination of
procedural, technical and physical measures should be in place [67]
and thus will be part of this research.
Preventive
Measures
Procedural
Detective
Corrective
Technical
Physical
Data breach
Prior indicators
Motivation
Opportunity
Capability
Figure 4: Detailed conceptual model (scope presented by the blue areas).
With this research we are aiming to predict the probability of a
data breach within twelve months. This time span has been chosen
because it is not possible for organizations to perform an assessment
every day or week and it takes time to apply measures in the or-
ganization. However, technology changes fast and behaviors might
change as well, therefore the time span is not longer than one year.

10
introduction
1.6
contribution of this research
Limited research has been performed on Bayesian networks in the
context of security and privacy, but this research contributes. Not only
does this research describe how BNs can be created and how they
can be used in the context of security and privacy, the research also
focuses on how BNs can be used effectively in practice. Additionally,
this research describes how insider threats can be characterized and
what preventive measures can be taken to lower the probability of a
data breach.
The speciﬁc and general BN models that we created allows (infor-
mation) security ofﬁcers and others responsible for information secu-
rity in health care organizations to get a clear overview of the proba-
bility of a data breach and the factors inﬂuencing this probability. A
general model has been created to show how BNs can be used for
different threats a health care organization faces. This model is based
on the speciﬁc model which is focused on data breaches caused by
employees of a health care organization who lose or misuse mobile
devices. Not only the health care sector can beneﬁt from such model,
but when it results in a lower probability of a data breaches the data
subjects beneﬁts from this as well.
1.7
outline
The next chapters address the research questions and background
needed to answer these questions and achieve the research goal. In
chapter 2 Bayesian networks and their applications in the context of
security and privacy are discussed. The ﬁrst subquestion related to
prior indicators will be answered in chapter 3 in which insider threats
and their characteristics are discussed. In chapter 4 preventive mea-
sures are explained on the basis of law, standards, frameworks and
other guidelines. The second subquestion is also answered in this
chapter. Then, the basic model structure will be identiﬁed in chapter
5 which answers our third sub-research question. The alpha model
based on a case will be created in chapter 6 and updated to the beta
model using expert knowledge (see chapter 7). Those two chapters
answer the fourth subquestion. The second main research question
is answered in chapter 8 in which the beta model will be tested in
practice by information security experts of three hospitals. This also
results in the gamma model. In chapter 9 a general applicable model
will be shown which helps to answer the ﬁrst main research question.
Finally, the challenges, conclusions and future research are provided
in chapter 10.

2
S TAT E - O F - A RT
In this research Bayesian Networks (BNs) will be used to predict the
probability of data breaches caused by a group of insiders of a health
care organization. This chapter discusses this technique which is based
on Directed Acyclic Graphs (DAGs) and probability theory. Background
knowledge for both topics is provided in appendix A. The elements,
structure and Conditional Probability Tables (CPTs) of a BN and how
a BN can be used for reasoning is described in section 2.1. Then, in
section 2.2, we show four different types of BNs in ﬁve applications.
The advantages and challenges of each type are discussed in section
2.3. This chapter ends with a discussion about the provided informa-
tion and remarks for this research (see section 2.4).
2.1
bayesian networks
Deﬁnition of
Bayesian network
A Bayesian network is a probabilistic graphical model that represents
a set of random variables and their conditional dependencies via a
Directed Acyclic Graph (DAG). Using this model it is for example pos-
sible to represent the probabilistic relationships between diseases and
their symptoms. More formally, a BN (G, P) is a DAG G and joint
probability distribution P which together satisfy the Markov condi-
tion. This condition is satisﬁed if for each variable X ∈V, X is con-
ditionally independent of the set of all its non-descendants (NDX)
given the set of all its parents (PAX), i. e. IP(X, NDX|PAX) [52].
example
Figure 5 shows a DAG with ﬁve nodes. Each node has
a probability distribution, but the values are not relevant at the mo-
ment. Table 2 shows the parents and non-descendants of each node
together with the necessary conditional independencies. These condi-
tional independencies should hold for the probability distributions to
ensure that the relationships in the DAG match with the distributions.
V
W
X
Y
Z
Figure 5: Directed acyclic graph to explain the Markov condition.
11

12
state-of-art
node
parents
non-descendants
conditional
independency
V
∅
∅
None
W
V
X, Z
IP(W, {X, Z}|V)
X
V
W
IP(X, W|V)
Y
X, W
V, Z
IP(Y, {V, Z}|{X, W})
Z
X
V, W, Y
IP(Z, {V, W, Y}|Z)
Table 2: Markov condition based on ﬁgure 5.
Lung cancer
problem
To explain the elements of a BN the lung cancer problem as de-
scribed by Korb and Nicholson [38] will be used. This problem is
about one patient who has been suffering from dyspnoea (shortness
of breath). Because he is worried that he has cancer he visits his doc-
tor. The doctor knows that one of the causes of dyspnoea is lung can-
cer. However, other important information is necessary to determine
whether cancer is the cause, namely: whether the patient is a smoker
or not and to what level of air pollution he has been exposed. Finally,
a positive X-ray could, among others, indicate lung cancer. Based on
this problem and additional information of Korb and Nicholson [38],
we will now explain the elements of a BN step-by-step.
2.1.1
Nodes and Values
A BN consists of multiple nodes representing variables of interest. For
the lung cancer problem there are ﬁve variables of interest, namely:
Pollution, Smoker, Cancer, XRay and Dyspnoea. Each node can take
State
a discrete or continuous value out of a set of values which are known
as the states of the node. The state that is selected for a node is the
current state of that node and can be used for entering observations
in the model. This will be explained in more detail in section 2.1.4.
Discrete values
The discrete values must be mutually exclusive and exhaustive, i. e.
the variable can take exactly one of these values at a time. For the
nodes the following types of discrete values can be chosen when cre-
ating a BN with AgenaRisk:
• Boolean: for nodes with two states: one represents a positive out-
come and the other a negative outcome, e. g. “True” and “False”;
• Labeled: for nodes with any number of states, e. g. “Round”,
“Square” and “Triangle”;
• Ranked: for nodes with any number of ranked states, e. g. “Low”,
“Medium” and “High”;

2.1 bayesian networks
13
• Discrete real: for nodes with any number of unordered states
with each state a positive or negative real number, e. g. -2, -1.4,
0, 7, 5.1;
• Continuous interval: nodes with any number of states, with the
states being consecutive and containing a range of real numbers,
e. g. [0, 10], [10, 20] and [20, inﬁnity];
• Integer interval: nodes with any number of states, with the states
being consecutive and containing a range of integers, e. g. [4, 8]
and [9, inﬁnity].
Continuous values
The last two categories are ﬁxed discretized approximations, but
can also be represented by a set of continuous numbers. For now
lets assume that the values of the nodes are all discrete. The nodes
Smoker, Cancer and Dyspnoea can only take the Boolean values “True”
and “False”, whereas Pollution can take the ranked values “Low” and
“High” and the node XRay the Boolean values “Positive” and “Nega-
tive”. An overview of the nodes with their states can be found in ﬁg-
ure 6. Furthermore, all states have a probability assigned to it, which
will be explained in section 2.1.3.
Pollution
{Low, High}
Smoker
{True, False}
Cancer
{True, False}
XRay
{Positive, Negative}
Dyspnoea
{True, False}
Figure 6: Nodes and states for the lung cancer problem.
2.1.2
Structure
The BN should consist of qualitative relationships between the vari-
ables. If one node affects or causes the other nodes they should be
directly connected with an arc that shows the direction of the effect.
This implicitly means that if there is no arc between two nodes, these
nodes do not (directly) affect or cause each other. For the lung cancer
problem the basic structure with the relationships between the ﬁve
nodes is shown in ﬁgure 7.
As can be seen in the ﬁgure this structure is a directed graph with-
out cycles and thus meets the condition for a DAG. Now, lets explain
the nodes in relation to the other nodes with more detail.
Relations between
nodes
In each BN a node is a parent if there is an arrow from that node
to another node, which is the child node. The nodes that do not have
any parents are called root nodes and the set of parent nodes of a
node X is given by Parents(X). Leaf nodes are the nodes that do not
have children and any other node is an intermediate node. From a

14
state-of-art
Pollution
{Low, High}
Smoker
{True, False}
Cancer
{True, False}
XRay
{Positive, Negative}
Dyspnoea
{True, False}
Figure 7: Bayesian network for the lung cancer problem.
causal perspective, the root nodes represent the causes and the leaf
nodes the end effect. So, the root nodes Pollution and Smoker are the
parents of Cancer and thus cause cancer. On the other hand, the leaf
nodes XRay and Dyspnoea are the children of Cancer and affect the
diagnosis of cancer.
The relations between nodes can be extended with the terms ances-
tor and descendant. If there is a directed chain of nodes, the node is
an ancestor of another node if it appears earlier in the chain. If the
node appears later in the chain the node is the descendant of the other
node. In our example Smoker is an ancestor of the two nodes XRay
and Dyspnoea, and XRay is a descendant of Pollution and Smoker.
2.1.3
Conditional Probabilities
Conditional
probability table
When the model structure is complete the relationships between the
connected nodes can be speciﬁed by deﬁning a conditional probabil-
ity distribution for all nodes. The discrete variables will be placed in
the form of a Conditional Probability Table (CPT). These tables can
become enormous if a parent takes a large number of values or if the
node has many parents, since the total size of a CPT is exponential in
the number of parents. So, a node with Boolean variables, thus having
two states and with n parents requires a CPT with 2n+1 probabilities.
Figure 8 shows the probabilities for the nodes in the the lung cancer
BN. This example is not created using AgenaRisk since this tool has
no view to explicitly show the CPTs of all nodes.
The root nodes in this model only have one row in their CPT. This
row indicates the prior probability instead of the conditional proba-
bility. So, the prior probability for a patient being a smoker is pre-
sented as 0.3 meaning that 30% of the persons that visits the doctor
are smokers and 70% are non-smokers. Additionally, the probability
for the patient being exposed to a low level of air pollution is 90%.
Instantation
For the other nodes all possible combinations of states of their par-
ents should be determined, which is called an instantiation of the par-
ent set. For each of those instantiations, the conditional probability of
the child being in a certain state must be speciﬁed, i. e. the probabil-

2.1 bayesian networks
15
P(P=Low)
0.90
P(X=Pos|C)
0.90
0.20
C
True
False
P(D=True|C)
0.65
0.30
C
True
False
P(S=True)
0.30
P(C=True|P,S)
0.05
0.02
0.03
0.001
P
S
High
High
Low
Low
True
False
True
False
Pollution
{Low, High}
Smoker
{True, False}
Cancer
{True, False}
XRay
{Positive, Negative}
Dyspnoea
{True, False}
Figure 8: Bayesian network for the lung cancer problem with conditional
probability tables.
ity of a child node being in a certain state given an instantiation of its
parents. For the lung cancer problem the parents of the Cancer node,
Pollution and Smoking, can take the following possible joint values:
{(High, True), (High, False), (Low, True), (Low, False)}
In the CPT of the Cancer node the following probabilities are as-
signed to the joint values for the node Cancer being “True”:
(0.05, 0.02, 0.03, 0.001)
Now, the probability of the node Cancer being “False” can be easily
calculated for each of the cases by 1 −P(Cancer = True). This holds
because the probabilities must sum to one over all possible states.
This, thus, results in the following probabilities:
(0.95, 0.98, 0.97, 0.999)
This can also be done for the nodes XRay and Dyspnoea which
both have the node Cancer as parent.
2.1.4
Reasoning with BNs
To explain the different types of reasoning BNs can be used for, we
created the BN for the lung cancer problem of ﬁgure 8 with the tool
AgenaRisk (see ﬁgure 9). The BN in ﬁgure 9 represents the actual
probabilities for each node independent of the state of each node.
Thus, the probability that a person has cancer is 1,163% when not
knowing the level of pollution, whether he is a smoker or not, the
result of the x-ray and whether he has dyspnoea or not.

16
state-of-art
Figure 9: Bayesian network for the lung cancer problem without observa-
tions.
Scenarios and
evidence
At the moment that evidence is found for a speciﬁc node being in
a certain state the probabilities of the nodes will change. When using
AgenaRisk scenarios can be entered which contain the current state
of each node. The default option is no evidence, meaning that no in-
formation is available about the current state of the node. When there
is evidence that the node should be in a speciﬁc state, the choice can
be made between entering hard evidence or soft evidence. Hard evi-
dence means that the node is in an exact state, e. g. the patient smokes,
so the node Smoker is (100%) true. When one is not certain that the
node is in an exact state soft evidence can be entered. In this way a
percentage can be assigned to two or more states being true, e. g. the
result of an X-ray may be 90% positive, then 90% can be assigned to
the node being positive and 10% to the state negative. After the ev-
idence is entered the tool automatically updates the probabilities in
the BN based on the current states of all nodes. How updating works
in relation with reasoning will be explained in the next sections. All
scenarios described in these sections are based on hard evidence.
2.1.4.1
Diagnostic Reasoning
The ﬁrst type of reasoning is diagnostic reasoning, i. e. reasoning from
symptoms to cause. This type of reasoning is reasoning in the oppo-
site direction to the network arcs. In the lung cancer example diag-
nostic reasoning is, for example, performed when a doctor observes
dyspnoea and then updates his belief about cancer and whether the

2.1 bayesian networks
17
patient is a smoker and/or has been exposed to a low or high level of
pollution.
To show how the probabilities change when an observation is done,
ﬁgure 9 will be discussed in relation to ﬁgure 10. As said before the
doctor observes Dyspnoea, this means that the states of all nodes are
unknown except for the node Dyspnoea which is True. Now, the prob-
ability of the node Dyspnoea being True changes to 100% and there-
fore the probability of Dyspnoea being False changes to 0%. This ob-
servation also has a (small) effect on the nodes Cancer, Pollution and
Smoker. The probability of the person having cancer has increased
from 1,163% to 2,486%, the probability that the person has been ex-
posed to a low level of pollution has decreased a bit from 90% to
89,8% and the probability that the person is a smoker increased from
30% to 30,703%.
Figure 10: Diagnostic reasoning about the lung cancer problem.
2.1.4.2
Predictive Reasoning
When the patient informs his doctor that he is a smoker, before any
symptoms have been determined, the doctor knows this will increase
the chances of the patient having cancer. Additionally, it will change
the doctor’s expectations that the patient will exhibit other symptoms,
such as shortness of breath or having a positive x-ray result. This is
an example of predictive reasoning: reasoning from new information
about causes to new beliefs about effects, following the directions of
the network arcs. This example is visualized in ﬁgure 11.
Now, the node Smoker is (100%) “True” which implies that the
probability of the person being a non-smoker is 0%. Based on this ob-
servation the probability of the person having cancer increased from

18
state-of-art
1,163% to 3,2%. The nodes XRay and Dyspnoea changed as well from
20,814% to 22,24% for being Positive and 30,407% to 31,12% for being
True respectively. Because the number of nodes is limited the proba-
bility of cancer is predicted with higher uncertainty, however when
more symptoms and causes are included in the model the prediction
of cancer becomes more accurate.
Figure 11: Predictive reasoning about the lung cancer problem.
2.1.5
Intercausal Reasoning
Intercausal reasoning is reasoning about the mutual causes of a com-
mon effect, represented by a v-structure in a BN. A speciﬁc type of
intercausal reasoning is explaining away in which the conﬁrmation
of one cause of an observation reduces the need to invoke alternative
causes. In the described model the causes pollution and smoker have
the common effect cancer. Within this model both causes are indepen-
dent of each other, that is, an observation of the one does not change
the probability of the other. But, now assume that we learn that per-
son X has cancer (see ﬁgure 12). This will increase the probabilities
for possible causes of cancer i. e. increasing the chances that he is a
smoker and that he has been exposed to a high level of pollution. Fur-
thermore, when assuming that this person is a smoker, this explains
something about the observed cancer, resulting in a lower probability
that the person has been exposed to high levels of pollution (see ﬁg-
ure 13). So, even though both causes are initially independent, with
knowledge of the effect the presence of one explanatory cause makes
an alternative cause less likely. In other words, the alternative cause
has been explained away.

2.1 bayesian networks
19
Figure 12: Intercausal for the lung cancer problem - part 1.
Figure 13: Intercausal for the lung cancer problem - part 2.
2.1.6
Combined Reasoning
Finally, the last type of reasoning is combined reasoning. This type
of reasoning combines the methods mentioned above to ensure that
there can be reasoned about the nodes. Figure 14 shows an example
of combined reasoning. For this model it is assumed that the x-ray is
negative and that the person is a smoker. This decreases the proba-
bility of the patient having cancer and thus increases the probability
of the person not having cancer from 98,837% to 99,588%. The proba-
bility that the person is exposed to a low level of pollution increases

20
state-of-art
as well, from 90% to 90,162%. Finally, the probability of the patient
having dyspnoea decreases from 30,407% to 30,144%.
Figure 14: Combined reasoning for the lung cancer problem.
2.2
applications and extensions of bayesian networks
In this section ﬁve BN applications related to security and/or privacy
will be discussed. The ﬁrst two researches use standard BNs whereby
the ﬁrst model is a general model related to insider threats and the
second model is speciﬁed to data breaches. The other researches are
based on extensions of the standard BN. For each application we will
discuss the input and output variables, purpose and data sources.
2.2.1
A Bayesian Network Model for Predicting Insider Threats
The threat of malicious insiders is growing and malicious acts mostly
happen without any warning potentially resulting in enormous dam-
age. Once the malicious act has been performed it is often possible
to identify a pattern or trail that could have lead to the malicious
insider. This trail mostly consists of a combination of suspicious ac-
tivities and a motivational or psychological proﬁle that represents the
desire to perform the malicious act.
Axelrad et al. [9] based their BN on this to indicate the degree of
interest of an organization in a potential malicious insider i. e. the
relative risk of an insider attack based on one individual.
Their research started with a literature study which resulted in a
list of 83 variables potentially associated with insider threats. Those
variables were ranked based on an estimation of the power of each

2.2 applications and extensions of bayesian networks
21
variable to predict degree of interest in a potential malicious insider.
Using this list with ranked variables the BN was created. The vari-
ables for the BN were selected based on the correlation between the
variables, i. e. two variables that are highly correlated should not be
both added to the network. This resulted in a network of 15 variables
related to an individual divided over ﬁve categories and two variables
that are used to create a weighted subtotal:
1. Dynamic environmental stressors: personal stressors, job stressors,
environmental stressors.
2. Static personal characteristics: capability, agreeableness, neuroti-
cism, excitement seeking, conscientiousness.
3. Dynamic personal characteristics: perceived life stress, perceived
job stress, job satisfaction, hostility.
4. Insider actions: interpersonal and organizational counterproduc-
tive workplace behaviors.
5. Degree of interest: the relative risk of an insider attack (output).
After the network was created, a survey was made to measure the
predictive variables of the model in a common sample of normal par-
ticipants. This resulted in a total of 486 observations. During the next
step a structural equation model was created based on the original
BN and updated with half of the data set gathered by the survey.
The other part of the data set was used to validate the model and
the suggestions derived from this step were used to update the BN.
This resulted in an additional node personality factor 1 in the cate-
gory of the static personal characteristics. Finally, the predictions of
counterproductive behavior of the BN were tested: simulated cases
created by the BN itself were used as a baseline against which the
quality of the predictions of empirical cases based on the responses
to the survey was assessed. Based on the tests it turned out that the
updated model predicted the simulated data less well than the orig-
inal model, most likely because in the updated model some of the
associations between variables were lower. On the other hand, the
updated model predicted the empirical data better than the original
model. Still there were some limitations on the predictiveness of the
model: the associations between variables in the environment were
low, proxy measures were used for counterproductive behaviors and
the fact that counterproductive behaviors are rare events.
2.2.2
Bayesian Network Modeling for Analysis of Data Breach in a Bank
A speciﬁc threat that can result in enormous damage for organiza-
tions is the threat of data breaches. Examples of damages are reputa-
tion damage, loss of customers and/or loss of their market position.

22
state-of-art
In his work Apukhtin [6] provided an overview with threat agents
and actions, such as malware and hacking, of which organizations
should be aware. Furthermore, his analysis of data breach investi-
gations and theoretical sources conﬁrmed that insiders are a large
threat to organizations and that their accidental or malicious activity
can result in negative consequences. This kind of threat is an opera-
tional issue that organizations should take into account while man-
aging operational risks. As Apukhtin [6] discovered in literature BNs
are potentially powerful tools for managing of operational risks and
therefore he used them for his research. The model focuses on data
breaches caused by malicious insiders and consists of the most com-
mon and critical factors based on multiple reports and theoretical
sources. An overview of the variables can be found in table 3. The
states of all variables are “True” and “False”, except for “The degree
of minor policy violations” and “Insiders motivation to steal data” for
which the states are “Many” and “Few” and “High” and “Low”.
variables
Data breach (output)
Presence of vulnerabilities
Insiders motivation to steal data
External pressure
Attempt of data theft will occur
Sensitive data is at risk
Use of shared passwords
Security software is installed
Access control is OK
Controls are OK
Security software is OK
Software based control is OK
Degree of minor policy viola-
tions
Access control to sensitive infor-
mation is implemented
Internal whistleblowing is en-
couraged
Measures to thwart stolen cre-
dentials are implemented
Insiders activity is logged and
analyzed on a timely basis
Policy violations and inappro-
priate behavior occur
Security is robust and up-to-
date
Precondition for data theft at-
tempt
Table 3: Bayesian network variables by [6].
After the creation phase the model was validated using multiple
sensitivity analyses. For this analysis a target node and one or more
sensitivity nodes should be selected to determine, for example, the
impact of Insiders motivation, External pressure and Presence of vul-
nerabilities on the target node Data breach. This type of analysis is
useful to identify and visualize variables with the highest impact
and is particular helpful when the historical data is limited. Since
the nodes should match the beliefs of the expert, it was analyzed
whether the input nodes had signiﬁcant inﬂuence on the probabil-

2.2 applications and extensions of bayesian networks
23
ities of target nodes. Because the results of the sensitivity analyses
did not fully match the expectations the model was adjusted several
times. In addition, the results can be helpful for management to prior-
itize monitoring activities and to indicate which management options
will have the greatest impact on the target nodes.
2.2.3
Detecting Threatening Behaviour Using Bayesian Networks
Where Axelrad et al. [9] and Apukhtin [6] use standard Bayesian
networks in their approach, Laskey et al. [39] use a more advanced
version of Bayesian networks, called Multi-Entity Bayesian Network
(MEBN). They use this BN to detect insider threats to information sys-
tems. Whilst BNs are limited to the same set of random variables for
all problem instances with evidence being different from problem to
problem, MEBNs do not have this limitation. Therefore they are use-
ful to reason about complex problems in which multiple numbers of
entities interact in various ways.
A MEBN consists of one or multiple modular components called
MEBN Fragments (MFrags). Such a fragment represents a fairly small,
separable and conceptually meaningful part of the total argument
structure supporting or denying a given hypothesis. When combin-
ing multiple MFrags models with complex conﬁgurations of many
features, such as models with multiple computer systems, actors and
documents, can be built.
In ﬁgure 15 a basic BN is shown together with its representation as
a set of MFrags. The basic BN in ﬁgure 15a will not be explained any
further since this type of BN has already been discussed extensively.
The MEBN fragments in ﬁgure 15b do need additional explanation.
There are three types of variables in these fragments:
1. Resident random variables with local distributions deﬁned in the
MFrag (shown in white);
2. Input random variables whose values condition the local distribu-
tions of the resident random variables (shown in light gray);
3. Context random variables must have value “True” for the local dis-
tribution deﬁned in the MFrag to apply (shown in dark gray).
The random variables take arguments called entities, which specify
the relationship between the user’s assigned task, the user’s intention
and the query task of ﬁgure 15a. So, the query task MFrag applies
when the entity u (user) is equal to the value of PerformingUser(q)
for the entity q (query) i. e. when user u is performing query q.
Wright et al. [76] explain the relationship and difference between
BNs and MEBNs as follows: “If all we have is BNs, and there are
M months of data with N variables per month, we must build a BN

24
state-of-art
(a) Task relevant document model.
(b) MEBN Fragments for document retrieval.
Figure 15: Bayesian network versus multi-entity Bayesian network [39].
with MxN nodes, and ﬁll in identical arcs and local probability distri-
butions at each time step. With MEBNs, we can write a single BNFrag
relating the variables at time t with the variables at time t+1 and say
repeat for all t’s. Similarly, we can relate a vehicle’s type to the type
of the unit it is a member of and say repeat for all vehicles in a unit,
and then repeat for all units”.
In the research of Laskey et al. [39] a user behavior model was
created to get document retrieval patterns. Since, the patterns can
be compared they can be used to discover unusual access patterns
related to illegal activities, such as disclosure of classiﬁed information,
and thus result in the detection of insider threats. Seven MFrags were
created to model queries and document accesses performed by users:

2.2 applications and extensions of bayesian networks
25
1. User: represents an individual user’s proﬁle by motive, inten-
tion, assignment and other activity;
2. User Background: indicators that a user is likely to be a threat: po-
litical activities, personal background and ﬁnancial background;
3. User Assignment: the geographic region and tasks that are as-
signed to the user;
4. User Intention: users are classiﬁed as “normal” or “threat”;
5. User Other Intention: indicates the nature of the potential threat
by information sources, regions and tasks the user shows inter-
est in;
6. Document: relevance of each document (with source) and how it
matches with each region and task;
7. Query: results in a document access whereby the user is search-
ing for information about a source, a task and a region. Whereas
insider actions in the previous discussed paper are counterpro-
ductive, this is not directly the case in the query actions.
The probabilities used in this research are based on 5-point scales
from very low to very high, 3-point scales from no to serious concerns
and categories with two and four options. The text does not provide
any information on how the actual values are chosen. However, to
conﬁrm the usefulness of the model it was investigated whether it
was possible to distinguish the type of user through a set of actions
by the users over a period of time. For this experiment two identical
BNs were created: a ground truth network that simulated a user’s
intention and behavior and an inference network which was used to
detect threatening user behavior. Both models were operated simulta-
neously and could be used to test the detection model with different
input values. With this approach the model has not been tested us-
ing actual user behavior. However, the experiments did show that the
model was able to perform reasonable inferences using data gener-
ated from the model itself and that using MEBNs for detecting insider
threat in information systems is a promising approach.
2.2.4
Privacy Intrusion Detection Using Dynamic Bayesian Networks
Another approach to detect speciﬁc privacy intrusions is proposed by
An, Jutla, and Cercone [5]. In their approach they use a dynamic BN
instead of a standard BN. A Dynamic Bayesian Network (DBN) is a
graphical model for probabilistic inference in dynamic domains i. e.
domains that are stochastic (unpredictable due to the inﬂuence of a
random variable) and change from time to time.

26
state-of-art
This type of BN is an extension of a normal BN that is used in static
domains. A DBN consists of a ﬁnite number of BNs (called slices)
related to a particular time instant. The way a state of the domain
evolves over time is represented by arcs between BNs corresponding
to successive instants. Additionally, a DBN satisﬁes the Markovian
property: “the state of the domain at time t + 1 is independent of the
states of the domain prior to time t, given the state of the domain at
time t”. The nodes of a DBN, their dependencies and the strength of
the dependencies do not change over time.
An, Jutla, and Cercone [5] presented the following example to ex-
plain the use of a DBN: assume two men, Bob and Peter, living in
different cities far away from each other. Every evening they talk with
each other by phone. We also know that Bob usually walks around
when the weather in his city is good and stays home otherwise. Peter
does not know the weather condition of Bob’s city, but can judge it
from Bob’s activities on that day.
This situation can be translated into a DBN as shown in ﬁgure 16.
To illustrate this example a very simple DBN has been chosen which
cannot be used for complex domains, however it does introduce the
basics of a DBN. Just like a normal BN each node represents a random
variable and each arrowed arc represents the causal dependencies be-
tween two nodes. Additionally, the subscript of a variable represents
the corresponding time instant, i. e. Wi represents the weather on day
i (good/bad) and Ai represents the activities of Bob on day i (out/in).
The evolution of the weather condition is shown by the arrowed arc
between two successive slices.
A0
A1
A2
W0
W1
W2
.
.
.
.
.
.
Figure 16: Dynamic Bayesian network example [5].
Since each slice will be repeated the DBN can be described by the
ﬁrst two slices with the parameters as given in table 4 and 5. This
model can be used to determine the probabilities of the weather being
good on some days given Bob’s activities for a few days and to predict
whether the weather on the next day will be good.
Because privacy intrusions occur in dynamic environments and
could be time-series of data, An, Jutla, and Cercone [5] propose to
use DBNs since they capture richer and more realistic domain depen-
dencies. For their model they assume two hypothesis variables:

2.2 applications and extensions of bayesian networks
27
W0
p(W0)
good
0.75
bad
0.25
Table 4: Prior belief about the weather condition [5].
Wi
Ai
P(Ai|Wi)
Wi
Wi+1
P(Wi+1|Wi)
good
in
0.10
good
good
0.75
good
out
0.90
good
bad
0.25
bad
in
0.80
bad
good
0.65
bad
out
0.20
bad
bad
0.35
Table 5: Prior belief about the relationship between the weather condition
and Bob’s activities and the evolution of the weather condition [5].
• a privacy intrusion is occurring (has occurred);
• the task an employee is (was) working on.
They created a DBN model based on a government’s revenue ser-
vice whereby a representative is granted access to some information
in the revenue database. This representative is not allowed to disclose
personal information to third parties, however this rule can still be vi-
olated. The model consists of features with a threshold which can be
used to recognize anomaly activities:
1. Working hours: during 8:00 - 17:00 or outside working hours;
2. Duration in database: less or more than 10 minutes;
3. Duration on records: less or more than 3 minutes;
4. Amount of records: less or more than 100 records;
5. Modiﬁcation: zero or more modiﬁcations in the database;
6. Frequency on database: less or more than 10 times;
7. Frequency on records: less or more than 3 times;
8. Task: audit or collection/delivery;
9. Intrusion of privacy: true or false (output).
These features are not complete and may not be the most effective.
To collect features for the model manual and statistical approaches
can be applied. Nevertheless, both approaches might be very hard
to apply since for manual approaches a good knowledge about the
domain is necessary and for statistical approaches DBN learning from

28
state-of-art
live data is necessary but this is not investigated yet. It is not known
for sure how the probabilities of the variables are determined, but it
seems like information of their previous research is used.
The purpose of this model is not to detect privacy breaches of one
or a few individuals, however when changing the model this might
be possible as well. Because this model is dynamic the histories of ac-
tions can also be taken into account which helps determining current
activities, but also predicting activities in the future. Furthermore,
this method is useful for both online real-time privacy intrusion de-
tection and ofﬂine privacy intrusion auditing.
2.2.5
Risk Management Using Behavior Based Bayesian Networks
The four researches discussed above focus on insider threats and the
behavior related to those threats whilst the research of Dantu and
Kolan [17] focus on attacker behavior and a set of vulnerabilities that
can be exploited by an attacker. Using this information the risk of a
critical resource can be estimated. Attacker proﬁles are created and
used as basis for attack graphs. These attack graphs then are used
to calculate the vulnerability level and risk of a critical resource in a
given network for different attacker proﬁles.
With their approach Dantu and Kolan [17] try to conﬁrm their hy-
pothesis: “There is a relation between network actions and social be-
havior attributes”. This hypothesis is tested using a ﬁve-step proce-
dure that is repeated until the most optimal security is achieved:
1. Creation of an attacker proﬁle
When creating an attacker proﬁle the expendable resources re-
lated to the attacker become visible. Examples are the skills of
the attacker and their motives to exploit a vulnerability. Dif-
ferent behavioral attribute values can be assigned to attacker
resources, resulting in multiple different attacker proﬁles.
2. Creation of attack graphs
To create an attack graph information such as network topol-
ogy, interconnection between hosts and various vulnerabilities
can be used. The attack graph of Dantu and Kolan [17] repre-
sents series of exploits and can be used to learn how intruders
reach their ultimate goal using different state transitions. Fur-
thermore, the attack graph can be visualized as a causal graph
whereby each parent node represents a cause and its child node
an effect. A successful attack is shown by a path from the root
to the leaf node whereby each node represents an event.
3. Assigning behavior attributes to attack graph nodes
The nodes of the attack graph can be labeled using a set of be-
havior attributes of a given attacker proﬁle. The attack graph

2.2 applications and extensions of bayesian networks
29
based on a proﬁle can be used as a source of analysis for infer-
ring proﬁle based attacks.
4. Risk computation
The risk for all the critical resources is calculated using the set
of paths, attributes and attacker type. Furthermore, BN based
estimation can be used for calculating the aggregated risk value
of the resource and a resource is marked as attack prone if this
value is higher than a threshold.
a) Deriving risk of an attack path
The eventual attack path of an attacker would be his opti-
mized use of the quantifying variables and might differ per
type of attacker. The ﬁnal attack path (Θ) is given by Θ =
(f1, f2, . . . , fn) whereby each fi is the attack path an attacker
would take for an identiﬁer variable i. The behavioral at-
tributes for each attack path can be used to derive the re-
lationship between a sequence of network actions and the
social motives of the attacker.
b) Bayesian networks for risk inference
Attack graphs can be modeled by reducing them to causal
graphs and add probabilities to the nodes. The probabili-
ties can be determined by, for example, monitoring or in-
trusion detection systems. Using Bayesian inference tech-
niques the posterior probabilities can be calculated based
on any deviation from normal behavior. Bayesian statistics
can help to quantify the available prior probabilities. This
information updates the subjective belief of all the other
random variable probability distributions. The posterior
probability calculations are performed before and after the
exploits are patched to estimate the new risk level of the
critical resources. In this way the overall goal of exploiting
the vulnerabilities existing in the network and its compo-
nents are achieved.
c) Inference based on attacker proﬁles
During this step the attack graph for a speciﬁc proﬁle is ini-
tialized based on expert knowledge and past observations.
This information can be used to compute the inferred prob-
ability on speciﬁc nodes. In other words, all probable attack
paths that can lead to the exploitation of it can be inferred
for a given resource.
d) Relating risk, behavior and penetration
The goal of this step is to derive the relation between the
vulnerability of a given resource and the penetration an
attacker can achieve in exploiting the network. This can be
achieved by deﬁning the probability of each event in the
attack path and inferring the posterior probability given

30
state-of-art
evidence at a node, usually the leaf nodes represent the
ﬁnal event of a successful attack.
5. Optimizing the risk level
The previous steps should be repeated until an optimum risk
value is reached. This value might be useful in processes such
as patch management and penetration testing.
This procedure conﬁrmed the hypothesis that “there is a relation
between sequence of network actions and attacker behavior and that
the behavior can be used for network risk analysis”. Furthermore, the
described steps can be used to create security policies to reduce the
vulnerability of a network and its hosts to external attacks. This work
could be extended by applying the methodology in the real world
and using data collected during past attacks.
2.3
comparison
Above we described ﬁve applications of Bayesian networks in which
four types of models have been used. The advantages and challenges
of using these types of models are summarized in table 6.
2.4
discussion
For this research we will use BNs because these models allows us
to make predictions about the data breach probability even when
limited data about the conditional probabilities is available. Because
this kind of model shows the causal relations between variables we
are able to provide a structured model that helps to better understand
the problem domain. When this domain changes it is easy to adjust
the BN and make new predictions.
Even tough there are multiple BN examples, they are often not re-
lated to security and privacy. Nevertheless, we found ﬁve applications
of BNs in which different types of BNs are used. These applications
were based on individuals and insiders threats except for the last ap-
plication in which the behavior of the attacker was the focus point.
As our research will focus on a group of employees it is to our best
knowledge a new point of view.
All types of BNs have their own advantages and challenges. The
type that is most suitable for our research will be chosen in chapter 5.
In this chapter we will describe our model scenario and purpose.
The fact that a pattern could be identiﬁed after a malicious act
has been performed will be very useful for our model indicates that
it should be possible to ﬁnd indicators of a data breach based on
suspicious activities and a motivational or psychological proﬁle that
represents the desire to perform a malicious act.

2.4 discussion
31
type
characteristics
advantages
disadvantages
BN [71] [5]
A network of causal relation-
All available data can be taken into account
Model for static domains
ships with their probabilities
No minimum sample size
No support for feedback loops
represented by nodes with
CPTs attached to it
Knowledge of a subject can be reﬂected before
research is conducted
Expert knowledge must be converted into
probability distributions
Learning the structure from data
No standard solution for continuous values
Consequences of decisions can be studied from
the perspective of expected values and the
risks of highly undesirable outcomes
Fast responses to queries
MEBN [39]
Modular components called
Consists of modular components
Too tedious for simpler models and domains
MEBN Fragments (MFrags)
Random variables can be changed for different
problem instances
MFrags can be combined to build complex
models with many features
MFrags can be re-used in multiple scenarios
Table 6: Comparison of four types of Bayesian networks.
DBN [5]
Finite number of BNs called
Model for dynamic domains
slices
Provide an easy and compact way to specify
First research on DBNs related to privacy
Obtaining features using DBN learning is not
investigated yet
Too tedious for non-dynamic domains
the conditional independencies
Past events can be taken into account
Useful to determine the relevance of a feature
Attack graph
Based on attack graphs
BN [17]
Attack graphs help to identify possible attacks
Must be based on attackers and their actions
Different graph for each type of attacker
Attacker actions might be unknown
Better prediction due to risk computation at
each node in the graph


3
I N S I D E R T H R E AT S
This chapter is about the insider as cause of a data breach and ex-
plains how insider threats can be characterized. This characterization
can afterwards be used to select nodes for our model. In sections 3.1
and 3.2 we start with deﬁning and explaining the terms insider and
insider threat in the context of our research. Once the deﬁnitions are
provided ﬁve theories that can be used to predict the behavior of in-
siders will be described (see section 3.3). After that, literature will be
used to characterize the insider threat by discussing prior indicators
related to the behavior of the insider, the organization and technol-
ogy (see section 3.4). Using the gathered information we will select
general indicators that can be used for our model (see section 3.5).
Finally, we will discuss this chapter in section 3.6 and mention some
points to take care of when building the models.
3.1
insiders
When the term insider is used it is by far from all uses explicit deﬁned
and even when deﬁnitions are given they are contradictory or related
to a speciﬁc context [11]. An insider is, for example, “simply a system
user who is granted and can use certain privileges” [53], “someone
who is authorized to use computers and networks” [66] and “an in-
dividual who is an employee (past or present), contractor or other
trusted third party, who has privileged access to the networks, sys-
tems or data of an organization” [56]. These three deﬁnitions all have
their own context, but according to Bishop et al. [11] there is a simi-
larity between most of the deﬁnitions of the term insider, namely that
they are based on three key properties:
• Access: “the insider needs some degree of access to resources”;
• Knowledge: “the insider needs to know about the resources avail-
able to it”;
• Trust: “the insider must be trusted to honor the restrictions im-
posed on it”.
We will deﬁne our own deﬁnition to make sure that it is narrowed
to the scope of our research and is only related to access to personal
data and no other information. Our deﬁnition of insider is an employee
who is authorized to process physical and/or digital personal data. The term
process is used in this deﬁnition because the Data Protection Act (DPA)
and General Data Protection Regulation (GDPR) use this term in rela-
tion to personal data [18] [23]. This deﬁnition furthermore includes
33

34
insider threats
both patient-related and non-patient-related employees and is based
on the three key properties. Without access to personal data some of
the employees in the health care sector cannot perform their job and
thus should be authorized to process personal data. However, when
having access to the data one must also know how to use it and ﬁnally
the organization must trust the employees with that data. Examples
of employees and departments that have access to personal informa-
tion are doctors, surgeons, nurses, secretaries and Human Resources,
but IT departments may also be able to access personal data.
3.2
insider threat
Insiders are a threat to organizations and pose a great risk since they
already have access to the information within the systems and there-
fore it is easier misuse the information [42]. In the context of risks a
Threat
threat is “anything (e. g. object, substance, human, etc.) that is capable
of acting against an asset in a manner that can result in harm” [24].
When a threat is posed by an insider we call it an insider threat. Two
types of insider threats can be distinguished: malicious and acciden-
tal insider threats.
Malicious insider
threat
The malicious insider threat relates to “insiders who use their priv-
ileged access to intentionally cause a negative impact to the conﬁden-
tiality, integrity or availability of the organizations’ information, sys-
tems or infrastructure”. By accidental insider threats the malicious
Accidental insider
threat
intent is missing and the negative impact can be caused both by ac-
tion and inaction [56]. The accidental threats related to information
security breaches can be divided into the following ﬁve types: acts of
omission in which people forget to perform a necessary action (also
known as inaction), acts of omission in which people perform an in-
correct procedure or action, extraneous acts in which people do some-
thing unnecessary, sequential acts in which people do something in
the wrong order and time errors in which people do not perform a
task within the required time [61].
In the context of data breaches an insider threat is posed by an
insider who uses his privileged access to intentionally or accidentally perform
an act directly or indirectly leading to unlawful processing of personal data.
3.3
behavioral theories
In the ﬁeld of criminology multiple studies have been performed to
understand the behavior of insiders in relation to criminology the-
ories. These theories can be used to predict the (criminal) behavior
of individuals within an organization. In this section we will discuss
ﬁve of the most inﬂuential criminology theories [70].
General Deterrence
Theory
The ﬁrst one, General Deterrence Theory (GDT), is based on the
assumption that people base their decisions on the maximization of

3.3 behavioral theories
35
their beneﬁts and the minimization of the costs [70]. So, an individual
commits a crime if the expected beneﬁt outweighs the expected costs
of action [50]. This theory focuses on the “disincentives” or sanctions
against performing a malicious act and how effective they are to deter
the criminal by the certainty and severity of a sanction. So, criminals
will be deterred from performing malicious acts when the possibility
of punishment is high and the sanction is severe. This also holds for
insiders who usually do not have strong criminal motives [70].
Social Bond Theory
The second theory is the Social Bond Theory (SBT) which focuses
on the role of social bonds on the behavior of individuals within an
organization [70]. The main assumption of this theory is that a person
commits a crime if there are no or weak social bonds. Additionally,
the theory states that everybody has the tendency to commit a crime,
even when there are strong security tools to deter them. As a result,
the probability of an individual committing a crime is higher when
there are weak or no social bonds. So, when organizations put enough
effort in the social bonds it is less likely that the insiders perform an
attack. In literature four factors are used to measure the effects of
social bonds [4]:
1. Attachment: individuals who are more attached to their social
circle are less likely to commit any misbehavior;
2. Commitment: when individuals commit themselves to achieve
their goals and build a good status they are less likely to per-
form any misbehavior;
3. Involvement: there is not enough time to commit a crime or mis-
behavior if the individual is involved in many activities at work,
home and with family and friends;
4. Belief: individuals who do not believe in social values are more
likely to commit crimes or misbehavior.
When relating this theory to insider threats it turns out that organi-
zations should focus on these factors. Even though trusted employees
are already more involved in and attached to their organization and
are quite concerned about their achieved trust level it helps organiza-
tions to avoid the tendency of employees to commit crime [4].
Social Learning
Theory
The Social Learning Theory (SLT) is the third theory and describes
that people commit crimes because they have relations with others
who already committed a crime or have intentions to do so. Accord-
ing to this theory there is a high correlation between delinquency and
the kind of relationships of the individual [4]. More speciﬁcally, this
theory is based on the following four concepts [70]:
1. Differential associations: a person is exposed to normative deﬁni-
tions that promote or retain criminal behavior;

36
insider threats
2. Differential reinforcement: the balance of anticipated or actual re-
wards or punishments that are consequences of the behavior of
an individual;
3. Deﬁnition of behavior: whether an individual deﬁnes an act as
right or wrong, desirable or undesirable, justiﬁed or unjustiﬁed,
et cetera depends on his attitude and/or the meaning he assigns
to the behavior;
4. Imitation: performing certain behavior after observing similar
behavior by others.
Theory of Planned
Behavior
The Theory of Planned Behavior (TPB) focuses on the role of the
intention of the individual in order to predict his behavior [4]. Inten-
tions capture motivational factors that inﬂuence behavior and indi-
cate how hard people are willing to try and how much effort they
are planning to put into the behavior. However, to succeed in per-
forming the behavior one should be able to decide by themselves to
perform the behaviors or not and have the required opportunities and
resources. This results in three independent concepts of intention: at-
titude towards behavior, subjective norms and perceived behavioral controls.
The ﬁrst concept is about the degree to which a individual has a favor-
able evaluation or appraisal of the concerned behavior. The subjective
norms relate to the perceived social pressure to perform or not to per-
form the behavior. Finally, the perceived behavioral controls refer to
the perceived ease or difﬁculty of performing the behavior. This con-
cept also focuses on past experiences and anticipated impediments
and obstacles. Concluding, the intention of the individual to perform
a behavior is stronger when the attitude and subjective norm with re-
spect to that behavior is more favorable and the perceived behavioral
control is greater [3].
Situational Crime
Prevention
Finally, Situational Crime Prevention (SCP), states that a crime oc-
curs when both motive and opportunity exist. In contrast to the the-
ories discussed above, this theory tries to explain the possibility of a
criminal act and not the criminal. Because it is not possible to perform
a crime without an opportunity this theory focus on the opportunity
and thus the act and not on the motive the perform an attack [70].
The goal of this theory is to make the criminal act less appealing
to offenders. This is done by modifying situational factors that inﬂu-
ence the decision of an individual to commit a crime. To reduce the
opportunity of a criminal multiple techniques of one of the following
categories can be used [64]:
1. Increase perceived effort: when using techniques of this category
the commission of a crime is discouraged by increasing a po-
tential criminal’s perception that the crime would involve more
effort than he is willing to spend.

3.3 behavioral theories
37
2. Increase perceived risk: the countermeasures in this category dis-
courage committing a crime by increasing the potential crimi-
nal’s perception that a crime involves more risk than he is will-
ing to tolerate.
3. Decrease anticipated rewards: countermeasures to reduce the ben-
eﬁt that a criminal believes he will receive as a result of a crime.
4. Remove excuses: techniques in this category reduce a potential
criminal’s ability to justify his actions.
3.3.1
Overview of Behavioral Theories
In table 7 we provide a simple overview of the ﬁve discussed theo-
ries. For each theory we will show whether they are focused on the
criminal or on the act, what the basic concepts of the security are and
what the specializations are.
focus
concept
specialization
GDT
Criminal
Beneﬁts
Fear for detection
Costs
and prosecution
SBT
Criminal
Social bonds
Attachment
Commitment
Involvement
Belief
SLT
Criminal
Relations with
Differential associations
(to be) criminals
Differential reinforcement
Deﬁnition of behavior
Imitation
TPB
Criminal
Intention
Attitude towards behavior
Subjective norms
Perceived behavioral controls
SCP
Act
Motive
Increase perceived effort
Opportunity
Increase perceived risk
Decrease anticipated rewards
Remove excuses
Table 7: Overview of behavioral theories.

38
insider threats
3.4
characterizing the insider threat
The SCP theory states that both motive and opportunity should exist
before a crime occurs. Sarkar [65] adds another element and states
that in order to successfully exploit a vulnerability or compromise
a system motivation, capability and opportunity should be present.
Therefore, a threat can be divided into these three elements. The in-
sider’s motivation is “the extent to which the insider is prepared to exe-
cute a threat” and consists of factors that drive the insider to consider
an attack. Examples of such factors are the desire to address issues re-
lated to for example employment, personal relationships, ﬁnance and
revenge, peer pressure and religious or political issues. The second el-
ement, capability, is “the extent to which an insider threat agent is able
to execute a threat” which depends on the access to tools, techniques,
training, manuals and resources and the ability to use them correctly
and acquire more over time. Finally, opportunity refers to the perfect
conditions needed to perform an attack and therefore the target must
be vulnerable.
3.4.1
Frameworks Related to Motivation, Capability and Opportunity
The three elements of Sarkar [65] also recur in the work of Blyth and
Kovacich [12] who provided an overview of threat components and
their relationships based on a malicious attacker (see ﬁgure 17). They
deﬁne a threat as “a potential cause of an incident that may result in
harm to a system or organization”.
Threat agent
Capability
Catalyst
Motivation
Access
Inhibitors
Amplifiers
Threat
Figure 17: Threat components and their relationships [12].
According to the research of Blyth and Kovacich [12] the motivation
of a threat agent can be among others political, secular, personal gain,
religion, power, terrorism and curiosity. The capability of a malicious
threat agent can be divided into the following categories: software,
technology, facilities, education and training, methods and books and
manuals. Instead of using the term opportunity the term access is

3.4 characterizing the insider threat
39
used in this model which refers to the ability of the attacker to gain
physical or electronic access to the information infrastructure.
Additionally, the model shows four others factors: threat agent, cat-
alyst, inhibitors and ampliﬁers. The threat agent is the individual (or
group) who would knowingly try to manifest a threat. A malicious
threat agent can be divided into the following categories: criminals,
terrorists, subversive or secret groups, state sponsored, disaffected
employees, hackers, pressure groups and commercial groups. The cat-
alyst is an action or event that initiates a threat agent to perform an
attack. The ﬁrst type of catalyst is an event which might be a personal
experience or exposure to news that triggers predetermined actions
and may be directly or indirectly related to the attacker or target. Sec-
ondly, the indicator technology changes, is about that when technology
changes new uses become available, but shortcomings also become
known. The last type of catalyst is personal circumstances which indi-
cates that the values and beliefs of a threat agent may be affected by
a change in the personal circumstances.
Inhibitors and ampliﬁers are, respectively, factors that decrease and
increase the likelihood of an attack happening or being successful.
An example of a threat inhibitor is the level of technical difﬁculty, i. e.
when the defenses of the target are strong and difﬁcult to bypass the
attacker may search for a target that is easier to reach. On the other
hand, if the attacker, for example, feels that the attack will increase
his status within his peer group it is more likely that he will perform
the attack which is thus an ampliﬁer.
Nurse et al. [56] also created a framework to characterize insider
attacks and uses the three main elements as well. The framework con-
sists of multiple components divided over four areas: catalyst, actor
characteristics, attack characteristics and organization characteristics.
The catalyst consists of a precipitating event that is an event that
initiates the insider to become a threat to their employer. The charac-
teristics of an attack are the attack itself, the objective of the attack, attack
steps and attack step goal. Assets and vulnerabilities are characteristics
of the organization i. e. the valuable items of the organization and the
items of interest to the threat agent (e. g. personal data) and the weak-
nesses in the assets and measures to protect them. The characteristics
of the actor are divided into three mains components: motivation to
attack, skill set and opportunity. The reason for an insider to attack
the organization, the motivation, can be ﬁnancial, political, revenge,
curiosity, fun, power, competitive advantage or peer recognition. This
element can be expanded as shown in ﬁgure 18 and described here:
• Psychological state: the psychological and emotional state of the
actor, e. g. happy, depressed, stressed and anxious;
• Attitude towards work: the attitude of the employee regarding his
job, e. g. committed;

40
insider threats
• Personality characteristics: captures the static and dynamic fea-
tures of an actor’s personality which are their innate self and
life experiences, such as social skill problems, their openness
and agreeableness;
• Historical behavior: activities the actor was engaged in during the
past, e. g. previous violations;
• Observed physical behavior: the physical behavior of the actor,
such as assaulting co-workers;
• Observed cyber behavior: technology-related behavior of the actor,
for example Internet and e-mail usage.
Attitude 
towards work
Psychological 
state
Observed 
cyber behavior
Observed 
physical 
behavior
Personality 
characteristics
Historical 
behavior
Motivation
Figure 18: Motivation of the actor [56].
The skill set refers to the capability of the actor or the skills needed
to perform an attack and relates to the enterprise role (see ﬁgure 19):
• Enterprise role: the actor role within the organization may be
useful because certain roles tend towards speciﬁc attacks, with
a set attack objectives in mind. Engineers and programmers are,
for example, typical persons that steal intellectual property.
Skill set
Enterprise 
role
Figure 19: Skill set of the actor [56].
Lastly, the actor needs an opportunity to initiate the attack, which is
also known as the chance to initiate an attack within the organization.
The opportunity of an actor has a relationship with the two elements
as shown in ﬁgure 20 and explained here:

3.4 characterizing the insider threat
41
• Type of actor: depending on the type of actor opportunities arise,
this is because actors have different trust levels within and ac-
cess to the organization. Within an organization the following
types of actors can be identiﬁed employee, contractor or con-
sultant, client or customer, joint venture partner, vendor and
external attacker. The only party that is not trusted personnel
of the organization is an external attacker and is included be-
cause they may recruit and collaborate with trusted personnel
to assist them in performing an attack;
• State of relationship: this variable represents the current state of
the relationship between the organization and actor. Four differ-
ent relationships can be distinguished: current, former, serving
notice and temporary.
Opportunity
Type of 
actor
State of 
relationship
Figure 20: Opportunity of the actor [56].
3.4.2
Behavioral Indicators
In literature multiple lists of indicators of insider threats are given.
These indicators are mostly based on the behavior of a potential at-
tacker. Since we are no behavior experts we will only show some
examples of indicators can potentially be used for our model.
First of all, the National Cybersecurity and Communications Inte-
gration Center [50] provides an overview of characteristics of insiders
at risk of becoming a threat. Examples of these characteristics are: in-
tolerance of criticism, introversion and reduced loyalty. Besides the
characteristics, they mention indicators of malicious threat activity
that organizations should be aware of. These activities are working
odd hours without authorization, accessing the network remotely at
odd times or while the employee is on vacation or sick and copy-
ing unnecessary material and drugs or alcohol abuse are some of the
examples they mention.
Another overview is given by Schultz [66] who proposes a frame-
work for understanding and predicting insider attacks. He mentions
six indicators of a potential attack. The ﬁrst indicator, deliberate mark-
ers are behavioral markers left by attackers to make a “statement”,
meaningful errors are errors made in preparing and/or performing an
attack and preparatory behavior is behavior related to the preparatory
phase of an attack. Furthermore, behavior of an insider on a speciﬁc

42
insider threats
system or network might not show a suspicious pattern, but when
taking multiple systems or networks together they might show a pat-
tern which is known as correlated usage pattern. The indicator verbal
behavior includes both spoken and written behavior and the ﬁnal in-
dicator is personality traits and is correlated with the likelihood of an
insider being a threat. This correlation is highest for introversion.
Separately these indicators do not reﬂect an insider threat, however
a combination of these indicators can be used to determine the like-
lihood of a potential insider attack. To calculate the likelihood of an
insider attack indicators of past insider attacks can be analyzed [66].
On a more speciﬁc level Greitzer and Frincke [28] provided an
overview of psychosocial indicators of insider threats obtained by
judgments from Human Resources experts. Because of legal and ethi-
cal reasons they decided to leave out indicators such as arrest records,
use of employee assistance program or employee complaint mecha-
nism and life and health events such as marriage and medical records.
They did, however, include factors such as stress and disgruntlement.
3.4.3
Organizational Indicators
Besides behavioral indicators there are also indicators related to tasks,
processes or other elements of the organization that can lead to a
higher probability of a data breach. Examples are violations of poli-
cies and controls, negative work place issues and violations of phys-
ical security measures [65]. Other indicators are related to a speciﬁc
system or processes such as deviating working hours, duration in
database, duration on records, amount of records, number of modiﬁ-
cations, frequency on database, frequency on records and task which
are based on database usage [5]. In some organizations the employ-
ees are allowed to take certain devices home, however this is a great
cause of data breaches and thus could be an organizational indicator
of a data breach [65].
3.4.4
Technical Indicators
There might also be technical indicators of an insider threat, for ex-
ample employees downloading and using hacker tools, unauthorized
access to systems of colleagues and inappropriate access of internet.
Related to networks within the organizations indicators might be em-
ployees installing modems and unauthorized wireless access. These
were just a few examples of technical indicators mentioned Sarkar
[65]. In his work he mentions many others which could also be used
for our model.

3.5 selecting indicators
43
3.5
selecting indicators
Based on the ﬁve discussed crime theories and the provided litera-
ture, we will now select indicators for our model. The ﬁrst discussed
theory, GDT, states that a crime occurs when the expected beneﬁts
outweighs the expected costs. This statement, however, is especially
useful when organizations want to deter insiders from performing a
criminal act. Therefore, this theory could be very useful for our next
chapter about protecting the organization against data breaches. The
SBT, SLT and TPB all focus on behavioral characteristics of persons,
namely: the social bonds, the relations they have and the intention
to perform a malicious act. These three factors will all be very use-
ful for our model as we will discuss beyond. The ﬁnal theory, SCP,
provides two factors that need to be present for a crime to occur:
motivation and opportunity. These two elements also recur in the re-
searches of Sarkar [65], Blyth and Kovacich [12] and Nurse et al. [56]
as discussed before. But in addition to motivation and opportunity
they based their models also on the capability/skill set of the insider
to indicate how capable the insider is to perform an attack.
The division of (insider) threat into motivation, capability and op-
portunity therefore seems a good basis for our model. However, when
an accidents occurs the insider does not have a motivation to perform
an attack and most of the time these errors occur when the capability
of the insider is low. By determining the right model structure and
variable states for these indicators it can be ensured that both mali-
cious and accidental insider threats can be represented in our model
(see chapter 5). Based on this information ﬁgure 21 shows our ﬁrst
breakdown of insider threat indicators.
Capability
Motivation
Threat
Opportunity
Figure 21: General insider threat indicators.
Since, the framework of Nurse et al. [56] contains not only an expan-
sion of motivation, but also the relationships between the elements it
will be used as basis for our model. We merged the variables Ob-
served physical behavior and Observed cyber behavior to the indica-
tor Observed behavior. In an extension this and other elements can
be expanded further to add more detail to the model. We will not
do this for the conceptual models that will be created in chapter 5,
however in chapter 6 the indicators will be related to a speciﬁc case
and more detail will be added to the model. Then, for example, the
behavioral indicators mentioned in section 3.4.2 can be used to spec-
ify the model. Our ﬁrst extension of the motivation of an insider can

44
insider threats
be found in ﬁgure 22. The social bonds of the SBT are captured in
the indicator Attitude towards work, relations of the SLT match with
Historical behavior and the intention of the TPB is captured in the
Motivation itself.
Attitude 
towards work
Psychological 
state
Observed 
behavior
Personality 
characteristics
Historical 
behavior
Motivation
Figure 22: Motivation indicators for our model.
According to Nurse et al. [56] the capability of an insider can be ex-
panded with the Enterprise role. As we believe that different types of
employees are working in the health care sector with different tech-
nical capabilities, we will add this variable to our list of indicators
as well. We will call this indicator Job type. This variable, however,
focuses only on the capability of the insider related to their job. To
also reﬂect the capabilities of the insiders that are not related to their
job we will add the indicators Skills and Resources. The skills of the
insiders can eventually be extended to, for example, their knowledge
about certain topics and education and training they followed. The
resources capture the access the insiders have to for example tools,
techniques, methods, books and manuals. Figure 23 shows the basic
extension of the capability of an insider.
Job type
Skills
Capability
Resources
Figure 23: Capability indicators for our model.
When there is a vulnerability in the organization it is more likely
that an error occurs or an attack will be successful. Therefore, the
indicator opportunity will be extended with technical and organiza-
tional indicators. Nurse et al. [56] mentions assets and vulnerabilities
as characteristics of the organization. We translate the assets to Data

3.6 discussion
45
type which represents the type of personal data the insiders have priv-
ileges for. The vulnerabilities are the weaknesses in the protection of
personal data and this will be captured by the measures as will be
described in chapter 4. Nevertheless, there are still indicators that
represent a higher likelihood of an opportunity. Since some types of
personnel are more likely to come in contact with personal data, they
will also have a higher opportunity to perform an attack or make an
error with the data. Therefore, the indicator Personnel type will be
added as well. We did not found any signs that the size and type
(hospital, rehabilitation center, et cetera) of the organization and their
culture are indicators of a data breach. However, the type of devices
the organizations use might be an indicator, for example, whether the
employees may take work devices home. This results in the extension
of the insider opportunity as shown in ﬁgure 24.
Portable 
devices
Data type
Opportunity
Personnel 
type
Figure 24: Opportunity indicators for our model.
In order to use the indicators to predict a data breach the model
should be as detailed as possible. This is a quite quite a difﬁcult task
since different insider threats might have different (technical) indica-
tors. To show how this works we will select speciﬁc indicators for
a case in chapter 6. Because not all indicators are directly related to
data breaches in the health care sector the difference will be made
when states are selected for all variables in the BN.
3.6
discussion
In this chapter we have explained the terms insider and threat and
mentioned the differences between a malicious and accidental insider
threat. For the malicious insider threat we used criminal theories to
determine why people commit crimes and in what situations crimes
occurs. The GDT stated that if persons fear detection and prosecution
they can be deterred from committing the crime. This information
will be useful for the next chapter in which we select measures to
prevent data breaches. After discussing the criminal theories we iden-
tiﬁed three elements that are related to the malicious insider threat,
namely: motivation, capability and opportunity. For the accidental in-
sider threat the ﬁrst element is not relevant, because persons do not
have a reason to make mistakes. Using literature examples of exten-
sions of these three elements have been provided. These extensional
indicators are related to the behavior of insiders, the organization and

46
insider threats
the technique. Based on this information we selected indicators that
are useful for our conceptual models and alpha model.
Even though we found a lot of literature related to insider threats
we did not found any characterization of insiders that cause data
breaches. Since data breaches are a speciﬁc kind of insider threats the
behavioral indicators can be used in our models, but it might be less
speciﬁed as when we would have found behavioral indicators of data
breaches.

4
D ATA B R E A C H P R E V E N T I O N
The data breach prediction model we develop in this research will
consist of indicators that are visible before a data breach occurs and
of measures organizations can take to protect themselves. In the pre-
vious chapter we already discussed indicators of malicious and acci-
dental insider threats. To limit these threats and avoid data breaches
organizations should protect themselves. Therefore, in this chapter,
we will discuss how personal data can be protected. We start with
explaining the terms security and information security and deﬁning
the term measure (see section 4.1). Once the deﬁnitions are provided
an overview of laws that apply in the health care sector will be given
in section 4.2. Then, in section 4.3, standards, guidelines and codes of
conducts applicable in the health care sector will be described. Since
data security is not only an issue in this sector, multiple general infor-
mation security standards and frameworks will be discussed in sec-
tion 4.4. Based on this information a selection of measures that will
be useful for our model will be made (see section 4.5). This chapter
ends with a discussion of the provided information in section 4.6.
4.1
information security
Security
To avoid data breaches organizations should be protected against any-
one who would do harm, intentionally or otherwise. The state of be-
ing secure and free from danger is called security. To create an opti-
mal level of security the focus should be on different security layers,
otherwise someone can harm to organization via another layer of the
organization. The ﬁrst layer is physical security which is important to
protect physical items and areas from unauthorized access and mis-
use. Personnel security is necessary to protect anyone who is autho-
rized to access the organization and its operations. Those operations
or activities should also be protected which is part of operations se-
curity. To protect communications media, technology and content or-
ganizations should focus on communications security and to protect
networking components, connections and contents the focus should
be on network security. Finally, organizations should protect their in-
formation assets which includes the access to them [75].
Information security
The objective of information security is to protect the conﬁdential-
ity, integrity and availability of information assets during storage,
processing or transmission. Conﬁdentiality means that information
should be protected against disclosure or exposure to unauthorized
persons or systems. Information should also have integrity which is
47

48
data breach prevention
the case when it is whole, complete and not corrupted. Finally, the in-
formation should be available in the required format without interfer-
ence or obstruction to authorized persons and system [75]. Since our
research focuses on personal data, information security is the most
relevant security layer. Conﬁdentiality is the most important aspect,
because when unauthorized individuals can view personal data conﬁ-
dentiality is breached and a data breach occurs. However, availability
and integrity can be concerned in a data breach when, for example, a
laptop with sensitive data is stolen and there is no data backup [7].
Measure
To protect personal data measures (also known as controls, safe-
guards or countermeasures) should be taken. Measures are “security
mechanisms, policies, or procedures that can successfully counter at-
tacks, reduce risk, resolve vulnerabilities, and otherwise improve the
security within an organization” [75]. For this research we are inter-
ested in measures that can successfully counter insider accidents or mali-
cious insider attacks, reduce risk, resolve vulnerabilities and otherwise im-
prove the protection of personal data within an organization. In the context
of the insider threats these measures try to deter malicious employ-
ees from performing an attack and to protect the organization against
errors of the employees, therefore measures can be seen as inhibitors.
4.2
law in the health care sector
In the Netherlands multiple laws and regulations apply in or are es-
pecially created for the health care sector. The book of Ekker et al. [19]
provides an overview of these laws and regulations. Since the book is
published in 2013 we will only discuss the ones that still apply and
are related to privacy and data protection.
4.2.1
Data Protection Act
The Dutch Data Protection Act (DPA) [18] is an implementation of
the data protection directive of the European Union (EU) [21] and
applies to all organizations in the Netherlands. According to this act
appropriate technical and organizational measures to secure personal
data against loss or any form of unlawful processing should be imple-
mented. This act does not provide concrete measures that organiza-
tions should take to protect the personal data they process. However,
in the Dutch guidelines on personal data security [15] by precursor of
the Dutch data protection authority more concrete information about
data security is given. Even though this document originates from
2013 and is not updated after the legislative change in the Dutch data
protection act in January 2016 it is still useful for data protection. For
more speciﬁc measures this document refers to the Dutch norms for
data protection which will be discussed in section 4.3.2.

4.3 norms and guidelines in the health care sector
49
4.2.2
Other Laws
Social security
numbers
Using social security numbers in the care sector is only allowed when
required by law. According to the use of social security numbers in
the care sector arrangement [58] personal data processing should
comply with the Dutch standard NEN 7510 and the elaborations
thereof in NEN 7511 (does not exist anymore) and NEN 7512. These
information security standards will be discussed in section 4.3.2.
Data provision
In the Dutch health insurance act [59] the data provision between
the health insurance provider, care provider and other agencies is reg-
ulated in a separate chapter. This chapter, however, does not provide
concrete measures to protect personal data and refers to the DPA and
the social security number usage act instead.
Medical treatment
The Dutch medical treatment agreement [57] is created to protect
the position of the patient and requires, among others, that health
care providers arrange a ﬁle related to the treatment of the patient.
Data concerning the health of the patient and the performed actions
should be recorded in this ﬁle. This data may not be provided to
others unless the patient gives consent or the provision is regulation
by law, this is called the obligation of secrecy.
4.3
norms and guidelines in the health care sector
None of the mentioned laws provide speciﬁc information on what
security measures should be implemented and in which way. Health
care providers are free to give a concrete interpretation on the law
from their own expertise and practice. To do so health care providers
and other agencies create their own standards and guidelines [19].
We will mention the ones that apply for a large group of health care
organizations and are related to privacy and data protection.
4.3.1
Code of Conduct
A code of conduct regarding electronic transmission of personal data
in the care sector [54] has been created because the combination of
ﬁling duty, obligation of secrecy and the Dutch data protection act
is quite confusing and unclear in the perspective of information tech-
nology [19]. This code applies to the care sector and personal data
processing via an electronic exchange system. Personal data process-
ing within (health) care institutions is excluded from this code.
Article 9 of this code comes into effect in 2017 and addresses iden-
tiﬁcation and authentication. The responsible party must ensure that
sufﬁcient technical measures are taken to determine and verify the
identity of the care providers, employees and others involved. This
should be done by multi-factor authentication and at least two of the
following three parts should be used:

50
data breach prevention
• Knowledge: something that the user knows, such as a password
or pin code;
• Possession: something that the user has, for example a token or
smart card;
• Inherence: something that the user is, e. g. a ﬁngerprint or iris.
4.3.2
Dutch Norms
As mentioned before some of the laws and regulations refer to the
Dutch standards called NEN. The organization NEN administers over
31.000 international and European norms accepted in the Nether-
lands and national norms (NEN) [45].
NEN7510
The ﬁrst norm that applies to all health care organizations in the
Netherlands is called NEN 7510 - Health Informatics - Information
security management in healthcare [43]. This norm provides a com-
mon framework for arranging information security in the health care
sector and takes the cooperation within and between different orga-
nizations in this sector into account. This norm is based on the inter-
national standards which will be explained in the next section. The
NEN is revised every ﬁve year and since in the meanwhile the ISO
standards have been changed, a new version of this norm is being
created [46].
Because every organization is different this standard indicates what
an organization should do to protect information, but it does not con-
tain speciﬁc technical measures that should be taken. The measures
are described in 11 chapters and divided into 39 main categories.
Each chapter consists of a management objective and one or multi-
ple measures to realize the objective. Additionally, focus points and
recommendations for implementation and other relevant information
for each measure is provided.
NEN7512
NEN 7512 is a complement to the measures of NEN 7510 and is
about requirements for trusted exchange of health information. The
norm describes necessary requirements and measures and focuses on
the agreements that communicating parties should make [44].
4.3.3
International Standards
The independent and non-governmental International Organization
for Standardization (ISO) has 163 members whose purpose is to “share
knowledge and develop voluntary, consensus-based, market relevant
international standards that support innovation and provide solu-
tions to global challenges”. ISO has published over 21.000 interna-
tional standards and related documents of which we will discuss the
standards on which NEN 7510 is based [32].

4.4 general standards and frameworks
51
ISO 27001
The ﬁrst standard is ISO 27001, which is about information tech-
nology and more speciﬁcally focuses on information security man-
agement systems. The goal of this standard is to “provide require-
ments for establishing, implementing, maintaining and continually
improving an information security management system”. Such a sys-
tem helps organizations to manage the risks of data protection in
IT systems, but also of physical documents and (digital) communica-
tions with other parties and systems [29].
ISO 27002
Within the process of implementing an information security man-
agement system controls must be selected. This can be done by using
ISO 27002 as a reference. Additionally, this standard can be used as
a guidance for implementing commonly accepted information secu-
rity controls. The described controls cover topics such as asset man-
agement, human resource security, information security policies and
physical and environmental security [30].
ISO 27799
Both ISO standards are not tailored to a speciﬁc industry, but there
are standards created for certain industries. An example of such a
standard is ISO 27799 on information security management in health
and is based on ISO 27001 and ISO 27002 [31].
4.3.4
Guidelines
The Dutch college of general practitioners created guidelines for infor-
mation exchange between general practitioners and other providers
of care in a structured way. In this way all involved care providers
should have the correct information about patients. Guidelines are
created to arrange the exchange between, at least, the general prac-
titioner and redirected specialists, physiotherapist, second-line men-
tal health care, general practice center, ambulance services and emer-
gency care. Additionally, guidelines on patient ﬁles, online care pro-
vision and transfer of medication data in the supply chain exist [19].
4.4
general standards and frameworks
Worldwide multiple standards and frameworks on information pro-
tection exist to help organizations improve their information security.
Four of them will be discussed because they are widely used in the
ﬁeld of information security. For all four we will point out impor-
tant elements for the protection of personal data and our model. This
section only focuses on security and therefore the rules for data col-
lection, processing, et cetera are excluded.

52
data breach prevention
4.4.1
Cyber Security Framework for Critical Infrastructures
The National Institute of Standards and Technology (NIST) is a non-
regulatory federal agency and part of part of the United States Depart-
ment of Commerce. Their mission is to “promote U.S. innovation and
industrial competitiveness by advancing measurement science, stan-
dards, and technology in ways that enhance economic security and
improve our quality of life” [48]. To do so NIST created a framework
to improve critical infrastructures in the area of cyber security [51].
The framework consists of controls divided over the functions iden-
tify, protect, detect, respond and recover. Since this research focuses
on protection we are only interested in protective measures. The pur-
pose of this function is to develop and implement appropriate mea-
sures to ensure the delivery of critical infrastructure services and to
limit the impact of a security incident. The function protection can
be divided into six categories of controls which could all be relevant
for our model: access control, awareness and training, data security,
information protection processes and procedures, maintenance and
protective technology.
4.4.2
Privacy Control Catalog
Besides the cyber security framework, NIST also created a privacy
control catalog consisting of a set of privacy protection controls [47].
This catalog helps organizations to identify and implement privacy
protection controls related to the entire life cycle of non-electronic
and electronic personal data. The controls are divided over eight
main topics. For each of the topics controls are described, supple-
mental guidance is given and control enhancements and references
are mentioned. The controls are focused on administrative, technical
and physical safeguards to protect personal data and can be matched
to articles of the Dutch DPA. The topic “Security” is relevant for our
research to select appropriate safeguards and can be matched with
article 13 which is about security of personal data [18].
4.4.3
Standard of Good Practice for Information Security
The independent and non-proﬁt organization Information Security
Forum (ISF) with members of many world leading organizations is
committed to investigate, clarify and resolve main issues in informa-
tion security and risk management. To meet the business needs of
their members they develop best practice methodologies, processes
and solutions [34]. One of their developments is the Standard of
Good Practice for Information Security. This standard provides com-
prehensive controls and guidance on 17 information security cate-
gories. Each of these categories can be divided into 2 areas which

4.5 selecting measures
53
results in a total of 34 lower level areas. Those areas can be divided
into 132 topics (also known as business activities) that consist of good
practice controls related to that topic and relevant in the perspective
of information security [35].
Organizations can implement this standard in order to identify how
regulatory and compliance requirements can be met, respond fast to
evolving threats and to be agile and exploit new opportunities.
4.4.4
Generally Accepted Privacy Principles
To address privacy issues within organizations and the risks related
to those issues, the American Institute for Certiﬁed Public Accoun-
tants (AICPA) and the Canadian Institute of Chartered Accountants
(CICA) together developed a privacy framework. This framework is
called Generally Accepted Privacy Principles (GAPP) and consists of
ten widely available principles [1]. These principles are created from
complex privacy requirements and supported by objective, measur-
able criteria to manage privacy risks and compliance in an effective
manner. To clarify those criteria policy requirements, communica-
tions and controls are described.
Just like with the privacy control catalog of NIST these principles
can be linked to articles of the Dutch DPA. The principle security
for privacy is relevant for our model, because it captures physical
and logical protection of personal information against unauthorized
access.
4.5
selecting measures
In the different standards and guidelines multiple security topics and
measures ranging from general to more speciﬁc are mentioned. Fig-
ure 25 shows the ﬁrst breakdown of measures into three main cat-
egories. These are based on the categorization of Gibson [26] and
the statement of Silowash et al. [67] that organizations should have a
combination of procedural, technical and physical measures in place
to themselves against threats.
Technical 
measures
Physical 
measures
Measures
Procedural 
measures
Figure 25: General protection measures.
Because the categories of measures and security topics as discussed
in section 4.4 do not solely consist of one type of measures it is not di-

54
data breach prevention
rectly possible to divide those topics or categories over the three main
categories. Therefore, we will independently provide an overview of
topics and categories that should be considered when protecting an
organization against data breaches.
Since the NEN and ISO standards are not very speciﬁc and are
not freely available, we selected the most relevant topics related to
personal data protection from the four standards and guidelines de-
scribed in section 4.4. This means that we only looked at topics that
are related to the protection against data breaches caused by insiders
and not at topics related to the purpose of collecting personal data,
the data quality, the protection against outsider threat, et cetera. This
results in the following topics for the four standards and guidelines:
• Cyber security framework:
Access control, awareness and training, data security, informa-
tion protection processes and procedures, maintenance and pro-
tective technology.
• Privacy control catalog:
Security.
• Standard of good practice for information security:
Security management, people management, information man-
agement, physical asset management, business application man-
agement, system access, system management, networks and com-
munications, supply chain management, technical security man-
agement and local environment management.
• Generally accepted privacy principles:
Security for privacy.
The standard of good practice for information security is the most
comprehensive standard and has overlap with the other three stan-
dards, therefore it will be used as basis for our research. The eleven
categories we have identiﬁed above can be can be extended to 22 spe-
ciﬁc areas. Since we are searching for protective measures the 19 areas
as shown in ﬁgure 26 are relevant for our research.
The areas can be divided further into topics topics, but this does
not directly result in measures that an organization should take. More
concrete information is needed to make sure the organization is pro-
tected at a sufﬁcient level. Therefore, the topics can be extended fur-
ther to eventually come up with detailed measures to organization
should take. Since it will be too tedious to show this for all categories,
we will only do this for one (see ﬁgure 27). The category “Local envi-
ronment management” captures all security measures that are related
to the two areas “Local environments” and “Local security coordina-
tion”. These areas can be divided into speciﬁc topics: two for the ﬁrst
and three for the second area. One of those speciﬁc topics is “Physical

4.6 discussion
55
Information 
security 
management
Security 
awareness / 
education
Information 
protection
Mobile 
computing
Security policy 
management
Human resource 
security
Information 
classification 
and privacy
Equipment 
management
Access 
management
System 
configuration
Network 
management
Security 
solutions
System 
maintenance
Electronic 
communications
Cryptography
Physical and 
environmental 
security
Corporate 
business 
applications
External 
supplier 
management
Cloud 
computing
Figure 26: Measure and areas for our model [35].
protection” and can be expanded to multiple measures of which we
have shown three in the ﬁgure [35].
Local 
environment 
management
Local 
environments
Physical and 
environmental 
security
Local 
environment 
profile
Local security 
coordination
Hazard 
protection
Physical 
protection
Power supplies
Locating intruder 
detection 
systems
Installing closed-
circuit television
Standards for 
physical 
protection
Figure 27: Example extension of a measure category [35]
The measures to protect the organization depend on a lot of factors:
the type of applications and devices that are used, the skills of the
employees, the size of the organization, the physical environment,
the type of personal data that is being processed, et cetera. Therefore
we will leave the measure explanation as it is and come up with more
concrete measures in chapter 6.
4.6
discussion
In this chapter we provided an overview of law that applies in the
Dutch health care sector. Additionally, we gave an overview of guide-
lines, frameworks and standards that are related to information pro-

56
data breach prevention
tection. As mentioned in the previous chapter a person can be de-
terred from committing a crime if he fears detection and prosecution.
This, however, we did not recognize in the discussed frameworks,
standards, et cetera. Nevertheless, the point of protection organiza-
tions against data breaches is to make it harder for unauthorized per-
sons to access personal data which is an inhibitor as we discussed
before as well.
To determine the probability of a data breach measures will be
added to the Bayesian network model. Since multiple measures can
be taken to protect an organization against insider threats, we did
not select speciﬁc measures yet. This process might be too tedious
and the measures too generic. Therefore we provide a more compre-
hensive overview of measures in chapter 6. These measures will be
related to a speciﬁc insider threat case and capture physical, technical
and procedural measures. How the measures can be converted into
variables with the two or multiple states will be explained in the next
chapter.

5
C O N C E P T U A L M O D E L S
In the previous two chapters we identiﬁed indicators of malicious
and accidental insiders threats and measures to protect organizations
against data breaches. This information will be used to create two con-
ceptual models for data breach prediction. First, a description of the
model scenario will be given (see section 5.1). Based on this scenario
the type of Bayesian Network (BN) for this research will be selected
(see section 5.2). Then, in section 5.3, our ﬁrst sub-research question
will be answered by determining the basic structure of the model.
Once the basic structure is known it will be extended to a ﬁrst and
second conceptual model using the prior indicators and measures
identiﬁed in the previous chapters (see section 5.4 and 5.5). This chap-
ter ends with a discussion and lessons learned in section 5.6.
5.1
scenario
A data breach in the health care sector can have far reaching con-
sequences for the affected organization and doctor-patient relation-
ships, but also for the involved individual and his family. Further-
more, health care costs of governments, organizations and individu-
als might increase due to a data breach [72].
In this sector most of the data breaches are caused by insiders [73]
and insider threats are a cited as a serious problem [6]. To limit or
avoid these insider threats organizations should protect themselves
by taking a combination of procedural, technical and physical mea-
sures [67]. However, instead of preventing the attack, the focus is cur-
rently on detecting the insider after the malicious act has occurred
[28]. During the detection process a combination of suspicious activ-
ities and a motivational or psychological proﬁle becomes visible and
can lead to the malicious insider [9].
Model purpose and
context
It is a challenge to develop a prediction method to prevent insider
threats [28]. However, by using a Bayesian Network (BN) one should
be able to determine the probability of a data breach given prior in-
dicators related to a group of insiders and the measures taken by the
organization. It should be possible to use the model in a health care
organization for malicious and accidental insider threats related to
personal data including health care data. The exact outcome of the
model will be discussed in the next chapter after we explained the
speciﬁc case on which the model will be based.
57

58
conceptual models
5.2
bayesian network type selection
Based on the described scenario and the advantages and disadvan-
tages of the four types of BNs as discussed in chapter 2, we will select
the type of BN for our research. These four types are: Bayesian Net-
work (BN), Multi-Entity Bayesian Network (MEBN), Dynamic Bayesian
Network (DBN) and a BN based on an attack graph.
Since the organization wants to know the same information about
every group of employees, but the states of the nodes might differ for
each group, a MEBN can be very useful. Furthermore, the MEBN
consists of modular elements which can, for example, be used to
represent different threats. In this way new threats, prior indicators
or measures can be easily added to an existing model. Additionally,
the insider threat is a very dynamic problem since the environment
within organizations, the technique and the behavior of employees
changes fast. Therefore, the DBN could also be very suitable for this
research. Using this model history can be taken into account and the
effect of changes in prior indicators and measures can be seen easily.
Whilst the MEBN and DBN both have potential, there is limited in-
formation available about building these types of BNs and the tools
to do so are also limited.
The combination between a BN and attack graph is useful when
the focus is on attackers and the steps they might perform. Since this
research does not focus on the speciﬁc steps the insider performs this
type of BN will not be very useful. Furthermore, the accidental in-
sider threat is not directly an attack on the organization and therefore
might be hard to apply in an attack graph.
A lot of information is available about the standard BN. The MEBN
and DBN are based on this type of BN and therefore can be seen as
extensions of the BN. Because of this, it takes less time to build a
standard BN than building the extensional models. Since this research
is an exploratory research and limited time is available the standard
BN will be used to create a model to predict data breaches caused
by a group of insiders. Because only static domains can be modeled
using this BN (see chapter 2), the model can solely be used to predict
a data breach given a situation at a speciﬁc moment, but this will be
sufﬁcient for this research. In a later stage the standard BN can be
extended to a MEBN or DBN.
5.3
basic model structure
To determine what the basic structure of the model should like, we
searched for typical BN structures in literature. During this research
we found the work of Kjærulff and Madsen [37] which contains a
method to decide what variables should be used in the model. As
our third sub-research question states we are looking for the basic

5.3 basic model structure
59
structure with only three variables: Indicators, Measures and Data
breach. For each of the variables we have to select the right type:
• Problem variables: these variables are mostly not observable and
by computing their posterior probability given observations of
information variables diagnoses, predictions, decisions, et cetera
can be made. In the lung cancer problem of chapter 2 the node
Cancer is the problem variable since we are interested in whether
a patient has cancer. With our model we want to predict the
probability of a data breach. This cannot be observed directly,
therefore the variable Data breach is a problem variable.
• Information variables: this type of variable may be observed and
can provide important information to solve the problem. The
information variables can be divided into:
– Background information: these variables capture information
that is available before the occurrence of the problem such
as the patient being a smoker or not for the lung cancer
problem. Measures taken by the organization can be ob-
served and are known before a data breach occurs and
therefore are background variables. Additionally, indica-
tors can be background variables when they are known
before a data breach occurs. These indicators will be called
prior indicators and an example of such an indicator is the
stress level of a group of employees.
– Symptom information: information that is visible after the
problem occurred and thus is a consequence of the prob-
lem is captured in these variables. An example related to
the lung cancer problem is the result of an x-ray. For our
research indicators are symptom information if they are
visible after a data breach has occurred, i. e. posterior indi-
cators. An example of such an indicator is that the organi-
zation receives an alert that their USB stick is found.
• Mediating variables: these variables are important for the correct-
ness of the model and are most often children of background
and problem variables and are parents of symptom variables.
Furthermore, they are not observable and their posterior proba-
bilities are not of immediate interest. In the lung cancer problem
and our basic model structure there are no variables of this type,
however in our conceptual models we might include them. An
example of this variable is “Protection level” which combines
all measures in the model.
These categories of variables are generally linked in the same way,
which results in the typical BN structure as shown in ﬁgure 28. How-
ever, not all types of and relationships between nodes exist in every
model. In the lung cancer BN, for example, there are no mediating

60
conceptual models
variables and there is no direct relation between the background and
symptom variables.
Background 
variables
Problem variables
Symptom variables
Mediating variables
Figure 28: Typical Bayesian network structure [37].
When we apply this structure to our three variables the model will
consists of two background variables namely Measures and Prior in-
dicators and a problem variable being Data breach. Even though we
are only interested in the prediction of a data breach, we will also
add the symptom variable Posterior indicators to explain how the
model can be extended to a detection model. The relationships be-
tween these variables are shown in ﬁgure 29 whereby the two back-
ground variables are merged into one variable. Just like with the lung
cancer example there is no relationship between the background vari-
able and symptom variable, because all of the effect goes via whether
a data breach occurs or not.
Measures and prior 
indicators
Posterior indicators
Data breach
Figure 29: Typical Bayesian network structure applied to our variables.
Now, the fundamental structure is known we are going to split
the variables and replace them by speciﬁc indicators and measures to
eventually come up with a complete model. First, we split the back-
ground variable into two separate variables: “Measures” and “Prior
indicators”. This results in the model shown in ﬁgure 30. Measures
either inﬂuence data breaches via prior indicators (which are observ-
able) or through an unobservable route which could be modeled with
mediating variables if needed. The dotted line shows that we do not
know yet whether that speciﬁc relation exist between the two nodes.
To explain this and why the arrow goes from measures to prior indi-
cators we use two examples.
For both examples assume that the employees in the organization
are very chaotic. Because of their behavior it is likely that they will

5.3 basic model structure
61
Measures
Prior indicators
Posterior indicators
Data breach
Figure 30: Extended Bayesian network structure with our variables.
lose their USB stick. When personal data is stored on the stick a
data breach occurs. One of the posterior indicators that shows a data
breach could have occurred is when someone ﬁnds the stick and re-
turns or report it to the organization. To prevent a data breach the
organization can take multiple measures, for example, encrypting the
USB sticks. When a USB stick is encrypted using a strong encryption
method it is very hard or maybe even impossible to access the data
on the stick. This situation is shown for a group of employees in ﬁg-
ure 31. As can be seen there is no relation between the nodes USB
stick encryption and Chaotic employees. This is because 1) encrypt-
ing the stick has no impact on the behavior of the employees and 2)
the chaotic behavior of the employees is not related to whether a USB
stick is encrypted or not.
USB stick 
encryption
Chaotic employees
USB stick found
Data breach
Figure 31: USB stick found example 1.
Instead of encrypting the USB sticks the organization can also orga-
nize a time management training for their employees (see ﬁgure 32).
When the training is effective it is likely that the employees are less
chaotic. Therefore, there is a relation from Time management train-
ing to Chaotic employees. The other way around, chaotic employees
do not have an impact on the time management training. Even if this
relationship did exist another solution must be found, since it is not
allowed to have two relationships between two nodes.
Based on the ﬁrst example it is clear that not every combination of
measure and prior indicator has a relationship. So, lets now explain
that if a relationship exist the arrow goes from the measure to the
prior indicator. As the second example shows it is possible to have a
relation from the measure to the prior indicator. The reversed relation
could exist if a measure is selected because a speciﬁc prior indicator is

62
conceptual models
Time management 
training
Chaotic employees
USB stick found
Data breach
Figure 32: USB stick found example 2.
visible. However, then the measure mitigates the prior indicator and
thus should the arrow go from measure to indicator and not the other
way around. This is part of a risk management exercise and outside
the scope of our model.
Using models with this structure one is able to predict the proba-
bility of a data breach when certain measures are taken and/or prior
indicators are observed. When predicting data breaches the following
question can be answered: what is the probability of a data breach if
the organization takes measures m1 to mn and prior indicators p1
to pn are visible? With this model including posterior indicators it is
also possible to detect a data breach. When detecting data breaches
the following question can be answered: what is the probability a
data breach already has occurred when posterior indicators i1 to in
are observed? Finally, it is also possible to use the model for a combi-
nation of prediction and detection. Then, the following question can
be answered: what is the probability a data breach occurs or has oc-
curred when the organization takes measures m1 to mn and prior
indicators p1 to pn and posterior indicators i1 to in are observed?
Using these models it is not only possible to determine the probabil-
ity of a data breach, but the most effective measures and likely causes
and effects of a data breach can be identiﬁed as well. The most effec-
tive measures can be found by entering observed prior indicators and
different combinations of measures.
The measure combination which results in the lowest probability
of a data breach is the most effective. In order to determine the most
likely cause or effect the observation whether a data breach has oc-
curred or not can be entered in the model and the prior and/or poste-
rior indicator with the highest probability of being visible is the most
likely cause or effect. Since this research does not focus on detection
the posterior indicators will be left out. This results in the model in
ﬁgure 33 which can only be used to predict the probability of a data
breach and determine the most effective measures and most likely
prior indicators of a data breach.

5.4 first conceptual model
63
Measures
Prior indicators
Data breach
Figure 33: Basic BN structure for our research.
5.4
first conceptual model
The identiﬁed basic structure will be used to create the ﬁrst concep-
tual model. This model will be based on the prior indicators and mea-
sures identiﬁed in chapters 3 and 4. Each variable can be extended
step-by-step and the more variables are added to more detailed and
accurate the ﬁnal model will be.
5.4.1
Nodes and Values
We start with selecting nodes for a simple extension of the basic
model. The model should focus on data breaches caused by both ma-
Basic nodes
licious and accidental insiders. To represent this the basic nodes Data
breach, Malicious insider threat and Accidental insider threat should
be present in the model. Both types of threats are a risk for health
care organizations and should be limited.
Prior indicators
In the context of risk management a risk is calculated by risk =
threat × vulnerability × consequence [16]. The consequence is not
relevant for this research since we are not interested in the impact of a
data breach. But, threat and vulnerability are both important to deter-
mine the probability that a data breach occurs. As mentioned before,
the malicious insider threat exists when the prior indicators Motiva-
tion, Capability and Opportunity are available. The ﬁrst two variables
are about the offenders and thus represent the threat. For the acciden-
tal threat the element motivation is not relevant, but this will be made
explicitly in section 5.3 when we determine the relationships between
the nodes. When vulnerabilities exist in the organization, the Oppor-
tunity for attack increases. This thus is about the protection of the
target and the characteristics of the defender.
Measures
The model will also focus on the measures an organization can
take to prevent a data breach. We distinguish two purposes for these
measures, namely measures that limit the insider threat and measures
that increase the protection level of the organization. The latter will
be captured in the mediating node Protection level.
As explained in chapter 4 measures can be divided into physical,
technical and procedural measures, these variables will be included
in our model as well. The procedural measures are focused on de-
creasing the motivation and capability of the group of insiders. How-
ever, there are also procedural measures that could be used to de-

64
conceptual models
crease the opportunity to perform an attack. This kind of measures
will be called Awareness measures. Awareness training and clean
desk policies are examples of such measures, since they does not in-
crease the motivation or capability of insiders to perform an attack.
States
In total we have identiﬁed eleven nodes for which states must be
determined. As explained before the nodes can be either discrete or
continuous. In our research we will only use discrete nodes, since
it is not clear how continuous nodes can be used effectively in BNs
and the tool AgenaRisk is mostly designed for discrete values. So, for
each of the variables it must be determined whether they are labeled,
Boolean, ranked, a continuous or integer interval or a discrete real.
In our ﬁrst conceptual model we will only use ranked and Boolean
variables with two to ﬁve states as can be seen in table 8.
node
type
values
Basis
Data Breach
Boolean
{False, True}
Malicious insider threat
Ranked
{Very
low,
Low,
Medium,
High, Very high}
Accidental insider threat
Ranked
{Very
low,
Low,
Medium,
High, Very high}
Prior indicators
Motivation
Ranked
{Very
low,
Low,
Medium,
High, Very high}
Capability
Ranked
{Very
low,
Low,
Medium,
High, Very high}
Opportunity
Ranked
{Very
low,
Low,
Medium,
High, Very high}
Measures
Protection level
Ranked
{Very
low,
Low,
Medium,
High, Very high}
Physical measures
Boolean
{False, True}
Technical measures
Boolean
{False, True}
Procedural measures
Boolean
{False, True}
Awareness measures
Boolean
{False, True}
Table 8: First conceptual model: nodes and values.
The Data breach node and all measures are Boolean variables, be-
cause a data breach occurs or not and measures are taken or not.
Protection level is a mediating node and represents the level of pro-
tection in organization and thus is a ranked variable with states from
very low to very high. So, the more effective measures are taken, the

5.4 first conceptual model
65
higher the protection level. The Malicious insider threat and Acci-
dental insider threat are ranked variables as well, since the group of
employees can pose them in different levels. The loss of a USB stick
with personal data is, for example, less critical than when the stick
also contains ﬁnancial and medical data. The ﬁnal variables Motiva-
tion, Capability and Opportunity are all ranked variables, since they
represent how motivated the group of insiders is to perform an at-
tack, how capable they are and how likely it is that an opportunity
exists.
Complexity
To limit the complexity of the model the number of states per node
should be not higher than ﬁve [41]. If this is still too complex and
costs too much calculation time the states of the ranked nodes can
be merged. As an example, the states of the node protection level
represent how well the organization is protected on a ﬁve point scale,
but it can also be changed to a three point scale: “Low”, “Medium”
and “High”. This, however, reduces the accuracy of the model.
5.4.2
Structure
The next step is to determine the relations between the identiﬁed
nodes and to create the ﬁrst conceptual model. Figure 34 shows all
nodes, their states and how they are linked together.
Motivation
Capability
Opportunity
Accidental 
insider threat
Data breach
Technical 
measures
Procedural 
measures
Physical 
measures
- Very low
- Low
- Medium
- High
- Very high
- Very low
- Low
- Medium
- High
- Very high
- False
- True
- False
- True
- False
- True
- False
- True
Malicious 
insider threat
- Very low
- Low
- Medium
- High
- Very high
Protection level
- Very low
- Low
- Medium
- High
- Very high
- Very low
- Low
- Medium
- High
- Very high
- Very low
- Low
- Medium
- High
- Very high
Awareness 
measures
- False
- True
Legend
Basis variables
Prior indicator 
variables
Measure 
variables
Figure 34: First conceptual model.

66
conceptual models
As explained before the node Data breach is a problem variable,
since we want to determine the probability of a data breach occurring
or not. This variable is therefore placed at the bottom of the model
and all other variables are background variables and thus placed
above the problem variable.
The identiﬁed basic structure (in ﬁgure 33) suggested that the mea-
sures and prior indicators should be linked directly to Data breach
and that if needed the measures should be connected with the prior
indicators. However, multiple new nodes have been added to the
model and therefore the effects of the measures do not go directly
to the probability of a data breach. Now, the effect goes via the indi-
cators of a Malicious and/or Accidental insider threat to Data breach.
Prior indicators
First of all, a data breach can be caused by malicious or acciden-
tal insiders, therefore there must be a relation from both threats to
the Data breach node. The malicious insider threat exists when the
group has a motivation, the capability and an opportunity to per-
form an attack in the organization. So, there are relations from these
three elements to Malicious insider threat. For the Accidental insider
threat there is no relation with Motivation, since there is no moti-
vation when an accident occurs. The other two elements, Capability
and Opportunity, are connected with Accidental insider threat in the
same way as with Malicious insider threat.
Measures
Furthermore, when organizations want to lower the malicious in-
sider threat they face they can try to lower the motivation of the
insider to perform an attack by procedural measures. This can for
example be done by high punishments if policies are breached. Addi-
tionally, these type of measures can be used to change the capability
of the employees. This is a bit difﬁcult, since a higher capability helps
to avoid mistakes of the employees and thus lowers the accidental in-
sider threat. However, when the employees have more capabilities it
is also easier for them to perform a malicious attack. An attack could
be deterred by other measures such as creating policies. Finally, they
can try to decrease the chance of an opportunity to perform an attack
by physical, technical and awareness measures. These measures are
linked to the node Protection level to limit the number of parents to
a node and make the model easier to read. The protection level then
inﬂuences how likely it is that there is an opportunity for the insiders.
So, there are three ways how measures can inﬂuence the prior indica-
tors: the measures 1) decrease the motivation of the group of insiders,
2) increase the capability of the insiders and 3) decrease the likelihood
of an opportunity via the protection level of the organization.

5.5 second conceptual model
67
5.5
second conceptual model
The ﬁrst conceptual model will now be extended with more speciﬁc
prior indicators and measures which will also be based on chapter 3
and 4. This model will be used as a basis for the alpha BN.
5.5.1
Nodes and Values
Just like with creating the ﬁrst model, we start with selecting nodes
and their states. Since it is recommended to limit the number of par-
ents of a node to three, we will select no more than three nodes per
variable expansion [41]. However, when we add measures to the prior
indicators more than four parents might be connected to a node. Nev-
ertheless, we will keep in mind that the model should not be too
complex, but also show enough detail.
Prior indicators
In section 3.5 we provided an overview of prior indicators that
could be useful for our model. For our second conceptual model will
we use most of these indicators as nodes, however since we are fo-
cusing on a group of employees and not on individuals we renamed
some of the variables.
Motivation
For the node Motivation only the nodes with a direct relation with
motivation will be added to our model to avoid complexity. Those
nodes are Psychological state and Attitude towards work. The ﬁrst
node will be renamed to Group state, since this name matches better
with the purpose of our model. Nurse et al. [56] mentioned stress,
happy, anxious and depressed as examples of psychological states.
For our conceptual model we will not use these states directly since
it is not possible that a measure directly changes the state from stress
to happy. Instead we will use the states “Negative”, “Neutral” and
“Positive” to show whether the state of the group is good or not. For
example, when the employees are happy the state of the node will be
“Positive”.
Furthermore, the Social Bond Theory (SBT) states that a person com-
mits a crime if there are no or weak social bonds and Nurse et al. [56]
described this by attitude towards work. We will capture this informa-
tion in the variable Attitude towards work with three ranked states.
The ﬁrst state “Actively uncommitted” capture employees who are
uncommitted and thus have a negative inﬂuence and could be hos-
tile to the organization. Employees who are not committed and do
not have a positive or negative inﬂuence on the organization are rep-
resented by the state “Not committed”. The third state captures em-
ployees who are committed and emotionally invested in and focused
on creating value for the organization [25].
Finally, Nurse et al. [56], Sarkar [65] and Blyth and Kovacich [12]
mention examples of attacker motivations. For now we will use the
nodes Financial, Competitive advantage and Revenge to represent

68
conceptual models
the motivation of the insiders. Because a measure cannot change the
type of motivation to another motivation, it is not possible to use the
motivation types as states of a speciﬁc node. Of course additional mo-
tivational nodes can be added to the model as well. In order to avoid
too many parents to the node Motivation an mediating node Reason
strength will be added to merge the reasons to attack, thus ﬁnancial,
competitive advantage and revenge and represent the strength of the
reasons.
Capability
The node Capability can be split into three nodes being Job type,
Resources and Skills. We divided the job type within a health care
organization in three states, namely “Care workers” such as doctors,
nurses and surgeons, “Support staff”, for example, secretaries and
HR departments, and “Technical support” which can be, among oth-
ers, employees of the IT department. The resources and skills rep-
resent the level of resources and skills the group of employees has,
therefore the states are ranked from very low to very high.
Opportunity
Opportunity, the ﬁnal prior indicator, will be divided into Person-
nel type, Data type and Portable devices. Certain types of person-
nel are more likely to cause a data breach than others. Therefore we
divide the types of personnel into “Employees”, “Contractors” and
“Third parties”. Furthermore, some data types are more sensitive and
valuable than other types, thus the division between different types
of personal data is made. For this we assume that if a group of em-
ployees has access to ﬁnancial or medical personal data they also have
access to standard personal data. Finally, the node Portable devices
represents whether the employees use portable devices such as busi-
ness smart phones, laptops and storage devices like USB sticks.
Overview
Table 9 provides a compact overview of the 12 additional nodes
and their types and states. The nodes in this list are all related to a
group of insiders. Even though this list of variables is not complete,
we will not add more nodes, because that will make the model too
complex.
Measures
As mentioned before the distinction between measures to increase
the protection level of the organization and thus decrease the oppor-
tunity for the insiders and measures to decrease the motivation and
capability of the insiders can be made. Because we will only show
limited example measures the mediating nodes Procedural measures,
Technical measures, Physical measures and Awareness measures can
be left out. When more measures will be added it can be useful to
put the mediating nodes back into the model. The node Protection
level will still be visible in the model as a mediating variable that
captures measures related to the protection of the organization itself.
As a supplement to this, we will add the node Device protection level
which captures all nodes related to the protection of devices in the
organization. Both nodes have ranked states ranging from very low
to very high.

5.5 second conceptual model
69
node
type
values
Motivation
Group state
Ranked
{Negative, Neutral, Positive}
Reason strength
Ranked
{Very
low,
Low,
Medium,
High, Very high}
Attitude towards work
Ranked
{Actively uncommitted, Not
committed, Committed}
Financial
Boolean
{False, True}
Competitive advantage
Boolean
{False, True}
Revenge
Boolean
{False, True}
Capability
Job type
Labeled
{Care workers, Support, Tech-
nical support}
Resources
Ranked
{Very
low,
Low,
Medium,
High, Very high}
Skills
Ranked
{Very
low,
Low,
Medium,
High, Very high}
Opportunity
Personnel type
Labeled
{Employees,
Contractors,
Third parties}
Data type
Labeled
{Personal data (P), Personal
and ﬁnancial data (P+F), Per-
sonal and medical data (P+M),
Personal, ﬁnancial and medi-
cal data (P+F+M)}
Portable devices
Boolean
{False, True}
Table 9: Second conceptual model: prior indicators and values.
Table 10 shows the measures that we selected for the second con-
ceptual model. These measures are just like in the ﬁrst conceptual
model Boolean variables because the organization has taken them or
not. Since the purpose of this conceptual model is to show how a data
breach prediction model could look like, it does not contain all mea-
sures that are necessary for good protection against data breaches.
We selected seven measures for the conceptual model such that dif-
ferent type of relationships with prior indicators could be discussed.
Because these measures are just examples they will not be explained.

70
conceptual models
node
type
values
Mediating
Protection level
Ranked
{Very low, Low, Medi-
um, High, Very high}
Device protection level
Ranked
{Very low, Low, Medi-
um, High, Very high}
Measures
Security policies
Boolean
{False, True}
Performance management
Boolean
{False, True}
Security training
Boolean
{False, True}
Device encryption
Boolean
{False, True}
Environment protection
Boolean
{False, True}
Up-to-date malware software
Boolean
{False, True}
Awareness training
Boolean
{False, True}
Table 10: Second conceptual model: measures and values.
5.5.2
Structure
Together with the nodes that we reuse from the ﬁrst conceptual model
the second conceptual model will consist of 27 nodes which should
be linked together. Figure 35 shows how the nodes are connected
with each other. The lower part of the model which is shown by the
gray area did not change and will not be explained again.
Motivation
As mentioned before the node Motivation can be expanded with
the nodes Reason to attack, Group state and Attitude towards work.
This means that the arrows go from these variables towards Motiva-
tion. The Reason to attack variable then can be extended with Finan-
cial, Competitive advantage and Revenge, this node thus has three
incoming arrows. Two out of the seven measures can be used to lower
the motivation of the group of insiders. The ﬁrst one is Security poli-
cies which lowers the attack motivation of the insiders because there
are punishments when policies are breached. Additionally, to ensure
that the state of the group is positive, Performance management can
be helpful and this measure therefore inﬂuences the Group state.
Capability
The node Capability can also be expanded with three nodes: Job
type, Resources and Skills. This results in three incoming arrows for
the Capability node. Organizations can try to increase the skills of the
employees via a Security training and therefore there is a relationship
between this node and Skills.
Opportunity
Finally, the node Opportunity captures all security measures that
can be used to lower the opportunity to perform an attack or make
an accident. Since the number of measures that can be related to this

5.6 discussion
71
node is high, the intermediate node Protection level is added with
three example measures. There are three speciﬁc indicators related
to the opportunity for the insiders, being: Personnel type, Data type
and Portable devices. To ensure that the data that is put on the device
cannot be downloaded easily it must by encrypted and therefore the
measure device encryption inﬂuences whether their is an opportunity
via portable devices.
5.6
discussion
This chapter started with the identiﬁcation of the basic structure for
our data breach prediction model using literature and examples. We
started with the three variables Data breach, Indicators and Measures.
However, it turned out that the indicators should be divided into
prior indicators that are visible before a data breach occurs and pos-
terior indicators that are visible after the occurrence of a data breach.
With these four variables we determined the basic structure for our
model and showed how the model can be used as a detection model
when the posterior indicators are included. Since our research only
focuses on the prediction of data breaches a structure with the nodes
Data breach, Prior indicators and Measures is sufﬁcient. This struc-
ture is used as basic for two conceptual models.
Both models provide a good overview of how a data breach predic-
tion model could look like. The division of measures over the differ-
ent types of indicators seems like a good approach, because when the
measures are linked to a low level of prior indicators the model will
be more detailed. Nevertheless, the nodes are too general to use in
practice, do not capture all measures and indicators of insider threats
related to data breaches and do not have Conditional Probability Ta-
bles (CPTs). So, we need to create a more speciﬁc model for a detailed
insider threat. For this model the probabilities can be determined and
its usefulness can be validated it in practice.

72
conceptual models
Motivation
Capability
Opportunity
Malicious 
insider threat
Data breach
- Very low
- Low
- Medium
- High
- Very high
- Very low
- Low
- Medium
- High
- Very high
- False
- True
- Very low
- Low
- Medium
- High
- Very high
- Very low
- Low
- Medium
- High
- Very high
Personnel type
Data type
Portable 
devices
- N
- P
- P+F
- P+M
- P+F+M
- Employees
- Contractors
- Third parties
Job type
Resources
Skills
- Very low
- Low
- Medium
- High
- Very high
Group state
Attitude 
towards work
- Negative
- Neutral
- Positive
Security 
training
- False
- True
Awareness 
training
Device 
encryption
Environment 
protection
- False
- True
- False
- True
- False
- True
- Care workers
- Support
- Technical  
  support
- Actively 
  uncommitted
- Not
  committed
- Committed
- Very low
- Low
- Medium
- High
- Very high
- False
- True
Security 
policies
- False
- True
Up-to-date 
malware 
software
- False
- True
Protection 
level
- Very low
- Low
- Medium
- High
- Very high
Performance 
management
- False
- True
Accidental 
insider threat
- Very low
- Low
- Medium
- High
- Very high
Financial
- False
- True
Revenge
- False
- True
Competitive 
advantage
- False
- True
Reason 
strength
- Very low
- Low
- Medium
- High
- Very high
Device pro-
tection level
- Very low
- Low
- Medium
- High
- Very high
Legend
Basis variables
Prior indicator 
variables
Measure 
variables
Figure 35: Second conceptual model.

6
A L P H A M O D E L
In the previous chapter the basic structure for our data breach pre-
diction model has been identiﬁed. This structure has been extended
to two conceptual models. One with the basic elements to predict
data breaches caused by a group of insiders and a more extended
model with detailed variables. Both models are very generic, do not
capture prior indicators of all insider threats and do not contain Con-
ditional Probability Tables (CPTs). In this chapter we will create the
alpha model which is a complete Bayesian Network (BN) based on the
case that will be described in section 6.1. The model purpose, context
and outcome will be given in section 6.2 and how the actual model
will be created will be explained in section 6.3. Once the model is com-
plete it will be analyzed by performing multiple sensitivity analyses
which results in the impact the variables have on each other. Finally,
the challenges and implications of creating the alpha model will be
described in section 6.4.
6.1
case
Because we would like to investigate the usefulness of the model in
practice, the model will be based on a case and not on a hypothetical
hospital. The selected case contains both malicious and accidental
insider threat elements and focuses on mobile devices.
Case description
80% of Dutch care professionals use a smart phone and/or tablet
for job related tasks [74]. The principle that employees of an organi-
zation are allowed to use their own mobile devices (e. g. smart phone,
laptop and tablet) for work purposes is also known as Bring Your
Own Device (BYOD). Even tough BYOD does have advantages, such
as easier communication with colleagues, cost and work ﬂow time
savings and greater access to patient information, it also brings chal-
lenges regarding security [68]. 40% of the employees, for example,
do not protect their smart phone with a password and only 3 out 5
applies the most basic security protocols. Furthermore, 52% of them
access unsecured wiﬁnetworks with their smart phone [77].
In the context of privacy the access to patient information is a cause
for concern. Not only can outsiders steal the devices, employees can
lose it as well. In the health care sector 32% of the security incidents
occur because of physical theft or loss and in 19% of the cases this
results in a data loss [73]. BYOD also results in concerns for data
security, difﬁculties with IT support and higher costs for additional
security measures [68]. To mitigate or avoid these issues organizations
73

74
alpha model
can provide the mobile devices themselves. In this way they can buy
the same devices for all employees and protect them in the same way.
Nevertheless, employees can lose these devices as well, not return
them to the organization when they have to or copy the personal
data to their own devices.
6.2
model background
For the purpose of the alpha model mobile devices are all devices,
either owned by the employee or the employer, that are portable and
can be used to process personal data. Using the alpha model one
should be able to assess the probability of a data breach caused by a
group of employees of a hospital. This model focuses on two threats:
the loss of mobile devices which is an accidental insider threat and
the misuse of employer-owned devices which is a malicious insider
threat. Misuse in the context of this case occurs when employees do
not return the employer-owned mobile devices when they have to or
when they copy personal data to their own mobile devices.
Model purpose
So, this model has actually two purposes. The ﬁrst purpose is to
determine the probability of a data breach caused by a group of insiders
who lose employee- and/or employer-owned mobile devices or misuse the
employer-owned mobile devices and the second purpose is to help health
care organizations determine which additional measures they should take to
protect themselves against data breaches caused by insiders.
Model outcome
The model will be based on prior indicators that are observed
within the hospital. However, when employers decide to monitor
their employees they have to follow rules laid down in, among others,
the Dutch Data Protection Act (DPA). To monitor their employees they
not only should have a legitimate reason to do so, but this must also
be the only way to reach the organizations’ goal. This reason must be
more important than the privacy of the employees. When the organi-
zation decides to monitor the employees they have to report it to the
Dutch data protection authority and the employees must be informed
about what they are allowed to do and what is prohibited. Finally, the
employer must receive an agreement of its counsel and take into ac-
count the privacy of the employees and the conﬁdential communica-
tion they have. When organizations are planning to secretly monitor
their employers even stricter rules apply [78].
Because of these strict rules, the privacy of the employees and or-
ganizations not being able to monitor everything they want to, we
will select variables that are not directly privacy sensitive and thus
ensure that the model does not focus on one speciﬁc person. Instead
the model can be used to determine the probability of a data breach
caused by one random person in a group. To determine the data
breach probability a group of employees must be selected for which
observations will be entered in the model. The prior indicators, there-

6.3 alpha model
75
fore, represent characteristics of a group of employees. Since we are
interested in the data breach probability of the whole group the out-
come of the model should be converted. This can be done by using
the following formula: 1 −(1 −p)n, whereby p is the probability of a
data breach according to the BN model and n is the group size [40].
The resulting number is the probability that a data breach is caused
by at least one person in the group within twelve months. This time
span has been chosen because it is not possible for organizations to
perform an assessment every day or week and it takes some time
to implement measures. However, technology changes fast and be-
haviors might change as well, therefore the time span should not be
longer than one year. When the prior indicators and/or measures
change the assessment should be performed again.
Finally, we are not aiming to create a model which calculates the
precise probability of a data breach because there is limited infor-
mation available about probabilities and conditional probabilities of
the prior indicators and measures. Instead the model will show the
relationships and the impacts without providing absolute numbers.
Using the model it must be possible to determine which additional
measures organizations should take and to investigate the relative
difference in the outcome of multiple situations.
6.3
alpha model
The alpha model will be based on the conceptual models of the pre-
vious chapter and on the described mobile device case. In addition to
the previous chapter we will now also ﬁll the Conditional Probability
Table (CPT) of the nodes to ﬁnalize the Bayesian network.
6.3.1
Nodes and Values
For this model most of the nodes of the second conceptual model
will be reused. But, this model is not tailored to the mobile device
case and therefore some nodes will be changed. Because it will be
quite difﬁcult to assign probabilities to nodes when they have ﬁve
states and it costs more calculation time, we simpliﬁed the ranked
states to “Low”, “Medium” and “High”.
Basis nodes
Both conceptual models consist of three basic nodes of which the
Data breach node will be used directly in the alpha model. The Ma-
licious insider threat and Accidental insider threat nodes will be re-
named to Mobile device misuse and Mobile device loss since these
are the threats in the mobile device case (see table 11).
Prior indicators
Just like in the second conceptual model the basic elements are re-
lated to prior indicators. Most of them have been identiﬁed before
and therefore we will only discuss the changes compared to the sec-

76
alpha model
node
type
values
Data Breach
Boolean
{False, True}
Mobile device misuse
Ranked
{Low, Medium, High}
Mobile device loss
Ranked
{Low, Medium, High}
Table 11: Alpha model: basis nodes and values.
ond conceptual model. An overview of all prior indicators and states
can be found in table 12.
The only change in the expansion of the Motivation node is the ad-
dition of the mediating variable Motivation level between this node
and the speciﬁc prior indicators. For the Capability variable, the Job
type and Skills variables will both be used. The Resources node, how-
ever, will be removed, because in our opinion insiders do not need re-
sources to lose mobile devices and the employees already have access
to the devices and (temporally) own them they do not need resources
to misuse them. Finally, the group of insiders needs an opportunity to
misuse or lose mobile devices. To represent this in the model we cre-
ated two separate variables: Attack opportunity and Accident oppor-
tunity. In this way it is possible to relate different prior indicators and
measures to them. As mentioned in the case description the model fo-
cuses only on the employees of a health care organization. Therefore,
we do not need the node Personnel type in our model. The variable
Portable devices will be replaced by the variables Employee-owned
mobile devices and Employer-owned mobile devices since these two
types of devices are mentioned in the case. These variables represent
the type of data that can be accessed using the mobile devices. For
simplicity reasons there are only three states without the distinction
between ﬁnancial and medical data. The ﬁrst state is “None” and rep-
resents that no personal data can be accessed or that the type of mo-
bile device is not used within the organization. The other two states
are “Personal data” and “Personal and sensitive data”. The last vari-
able, Data type, will be removed, as its states are already used for the
two device type nodes.
Because the current prior indicators are mostly related to mobile de-
vice misuse we added one additional prior indicator related to device
loss as example to show how this increases the probability of mobile
device loss. Whilst it is totally normal that people forget or lose stuff,
there are factors which can make it worse. One of these factors is
stress, not only because it impacts the overall health of people, but
also because it makes people more distracted with the consequence
of a lower ability to obtain information that should be remembered
[27]. So, when people are stressed, it is harder for them to remember
information which includes where they left their mobile device.

6.3 alpha model
77
node
type
values
Motivation
Ranked
{Low, Medium, High}
Motivation level
Ranked
{Low, Medium, High}
Gender
Boolean
{Male, Female}
Group state
Ranked
{Negative, Neutral, Positive}
Reason strength
Ranked
{Low, Medium, High}
Attitude towards work
Ranked
{Actively uncommitted, Not
committed, Committed}
Financial
Boolean
{False, True}
Competitive advantage
Boolean
{False, True}
Revenge
Boolean
{False, True}
Capability
Ranked
{Low, Medium, High}
Job type
Labeled
{Care workers, Support, Tech-
nical support}
Skills
Ranked
{Low, Medium, High}
Attack opportunity
Ranked
{Low, Medium, High}
Accident opportunity
Ranked
{Low, Medium, High}
Employee-owned
mobile devices
Ranked
{None,
Personal
data,
Per-
sonal and sensitive data}
Employer-owned
mobile devices
Ranked
{None,
Personal
data,
Per-
sonal and sensitive data}
Stress level
Ranked
{Low, Medium, High}
Table 12: Alpha model: prior indicators and values.
Measures
As we described in chapter 4 organizations can take dozens of mea-
sures to protect themselves against malicious and accidental insider
threats. The measures that we selected for the conceptual models are
far from specialized and not related to the mobile device case. How-
ever, when we add more measures to the model it becomes way too
complex. Instead of adding each measure separately we decided to
add multiple measures together in groups. To determine the groups
of measures we consulted the Standard of Good Practice for Infor-
mation Security [35] of the Information Security Forum (ISF) again.
In the appendix of this standard a comprehensive list of informa-
tion security-related terms is given and for each of those terms rel-
evant topics in which those terms are covered are mentioned. From
this list we selected eleven topics that are related to our case, be-
ing: Bring Your Own Device (BYOD), data loss protection/information
leakage protection, data protection, General Data Protection Regula-

78
alpha model
tion (GDPR), mobile application management, mobile computing, mo-
bile devices, mobile device management, portable storage (devices),
smart phones and tablets. Together all these terms refer to 35 top-
ics, however not all of them are related to misuse and loss of mobile
devices.
The related measures are categorized into nine groups and con-
verted into protection level variables with ranked states as can be
seen in table 13. These protection level variables represent how well
the organizations protect themselves and more speciﬁc the data and
mobile devices. The description of each group with an example is
given below:
• Policy protection level: all measures related to policies that de-
scribe how employees should behave and what is and is not
allowed with the mobile devices. One example of such a mea-
sure is: “Policies are kept up-to-date”.
• Pre-employment screening level: measures to avoid hiring people
with a serious criminal past or serious addictions. An example
screening measure is: “Career history is checked”.
• Performance management level: the measures to evaluate how the
employees perform as a group related to their security responsi-
bilities. An example is: “The performance of employees is eval-
uated on a regularly basis”.
• Security training level: measures to educate the employees about
security and speciﬁcally about the protection of personal data.
One of these measures is: “Trainings are related to the job of the
employees”.
• Organization protection level: all security awareness program mea-
sures to promote expected security behavior within the organi-
zation and ensure a higher awareness regarding mobile device
loss and misuse. This group also measures for security incident
reporting. “The security awareness program is kept up-to-date”
and “Actual and suspected security incidents are reported to a
help desk or specialist IT team/department” are examples of
these measures.
• Employer-owned protection level: measures to protect mobile de-
vices against loss and misuse. One of those measures is “Em-
ployees return devices when they do not longer need it”.
• Employee-owned protection level: all measures to protect employee-
owned mobile devices against loss, for example “Employees de-
stroy data copies when they do not longer need it”.
• Data attack protection level: the measures to protect personal data
when the insiders try to misuse the mobile devices. An example
is: “There are data storage restrictions”.

6.3 alpha model
79
• Data accident protection level: measures to protect personal data
in the case that mobile devices are lost. “Default passwords are
changed” is an example of such a measure.
node
type
values
Policy protection level
Ranked
{Low, Medium, High}
Pre-employment screening level
Ranked
{Low, Medium, High}
Performance management level
Ranked
{Low, Medium, High}
Security training level
Ranked
{Low, Medium, High}
Organization protection level
Ranked
{Low, Medium, High}
Employee-owned protection
Ranked
{Low, Medium, High}
level
Employer-owned protection
Ranked
{Low, Medium, High}
level
Data attack protection level
Ranked
{Low, Medium, High}
Data accident protection level
Ranked
{Low, Medium, High}
Attack protection level
Ranked
{Low, Medium, High}
Accident protection level
Ranked
{Low, Medium, High}
Table 13: Alpha model: measures and values.
Since the model will not contain speciﬁc measures but groups of
measures, we created an assessment tool in Microsoft Excel (see ap-
pendix D.3). Using this tool organizations can determine the states for
the protection level groups. The organization has to ﬁll in which mea-
sures they have taken and the tool then calculates the protection level
for each group. This is done by dividing the number of measures
taken by three and selecting the corresponding state. The resulting
levels then can be entered as observations into the BN.
In order to make a distinction between measures related to mobile
device loss and misuse two new variables have been added: Accident
protection level and Attack protection level. These variables are me-
diating variables and do not contain speciﬁc measures and therefore
are not captured in the assessment tool.
6.3.2
Structure
The identiﬁed nodes and states are used to determine the model
structure which is shown in ﬁgure 36. The idea behind the relations
between the three basic nodes and Motivation, Capability and Op-
portunity are the same as in the conceptual models. However, now
the distinction between an opportunity for an accident and for an at-
tack is made. The remaining relations will be discussed on the basis

80
alpha model
of their relation to Motivation, Capability, Accident opportunity and
Attack opportunity.
Motivation
The Motivation node can be expanded with prior indicators in the
same way as in the second conceptual model. However, since the
model becomes too complex if we connect four prior indicators and
multiple measures to the Motivation variable, we decided to add a
mediating variable called Motivation level. Then, two of the three pro-
tection level variables, Policy protection level and Pre-employment
screening level, have an impact on the motivation of the insiders.
The policies can be used to deter employees from performing an at-
tack and pre-employment screening helps to lower the possibility that
the group has a motivation to misuse mobile devices. Finally, perfor-
mance management can improve the group state and therewith lower
the motivation of a group to perform an attack. Therefore, there is a
relation from Performance management level to Group state.
Capability
To ensure that employees have a higher understanding of security,
organizations can provide training. This increases the skills of the
employees and therefore there is a relation between Security training
level and Skills.
Opportunity
We have split Opportunity into Attack opportunity and Accident
opportunity to ensure that different prior indicators and measures
can be related to the different situations. In the mobile device case
misuse is only possible when the employees use employer-owned mo-
bile devices, so there is a relation with the variable Employer-owed
devices. To avoid an opportunity for misuse organizations can take
multiple measures therefore there is a relation between Attack protec-
tion level and Attack opportunity. This ﬁrst variable can be expended
to different groups of measures being: Organization protection level,
Employer-owned protection level and Data attack protection level.
The opportunity for an accident is also inﬂuenced by employer-
owned devices, but employees can also lose their own mobile devices
and therefore this node also has a relation with employee-owned
devices. Additionally, this opportunity can be extended with stress
level to indicate that it is more likely that employees lose mobile de-
vices when they are more stressed. To protect against mobile device
loss organization can take measures from four measure groups, be-
ing: Organization protection level, Employer-owned protection level,
Employee-owned protection level and Data accident protection level.
Those groups are all combined in the mediating node Accident pro-
tection level.
6.3.3
Probabilities
Now the model structure is complete we can determine the impact
the variables have on each other and add probabilities to them. Since
our model is based on the data breach probability for an employee

6.3 alpha model
81
group in one organization we are not interested in the probability that
prior indicators are visible or measures are taken within the whole
sector. This information will be entered for one organization as obser-
vations. Therefore, the probabilities of the root nodes are not relevant
and will be default values, i. e. if a variables has two states both have
probability 0,5 and if there are three states both have probability 1/3,
et cetera. This means that we only have to ﬁll thirteen conditional
probability tables. We start at the top of the model and work towards
the bottom until we eventually reach the data breach node.
On the internet we found multiple freely available data breach
databases. Examples of these sources are the data breach database of
Breach Level Index [13], a chronology of data breaches from 2005 to
present of Privacy Rights Clearinghouse [63] and an overview of data
breaches of the Identity Theft Resource Center [33]. These databases
contain among others information about the industry in which the
breach occurred, the organization, number of records breached, data
of the breach, type of breach and the source of breach. However, these
databases are not detailed enough for our research and therefore
could not be used to ﬁll the CPTs. They neither contain information
about health care data breaches in the Netherlands.
Because literature, reports and cases neither provide very speciﬁc
information about conditional probabilities related to the case, we
will enter the values to our best knowledge and check them in the
next chapter with security and privacy experts.
In order to determine the probabilities for the CPTs we created
thirteen statements. Each of the statements is related to the parents of
the variables with a CPT and mentions which parent variable should
have the highest impact on the CPT variable. We will not show the
ﬁlled CPTs over here, but we will explain the statements and how we
determine the correctness of the tables. The statements related to the
impact of the nodes including an explanation are as follows:
1. Mobile device misuse results more often in a data breach than
mobile device loss, because when someone loses a device it is
possible that they ﬁnd it back without data being breached.
2. Employees do not need speciﬁc skills to misuse a device they
already borrow from the organization, therefore capability has
the lowest impact on mobile device misuse. Furthermore, mo-
tivation has a higher impact than attack opportunity because
when the employees have a motivation to misuse the mobile
devices they will ﬁnd an opportunity.
3. Accident opportunity has an higher impact on mobile device
loss than capability since everyone is likely to lose devices no
matter what their capabilities are.

82
alpha model
Accident 
opportunity
- Low
- Medium
- High
Employer-
owned devices
- N
- P
- P + S
Employee-
owned devices
- N
- P
- P + S
Capability
- Low
- Medium
- High
Job type
- Care workers
- Support
- Technical
  support
Skills
- Low
- Medium
- High
Motivation
- Low
- Medium
- High
Reason 
strength
- Low
- Medium
- High
Attitude 
towards work
- Actively un-
  committed
- Not com-
  mitted
- Committed
Group state
- Negative
- Neutral
- Positive
Revenge
- False
- True
Competitive 
advantage
- False
- True
Financial
- False
- True
Mobile device 
misuse
- Low
- Medium
- High
Mobile device 
loss
- Low
- Medium
- High
Data breach
- False
- True
Attack 
opportunity
- Low
- Medium
- High
Employer-
owned pro-
tection level
- Low
- Medium
- High
Organization 
protection 
level
- Low
- Medium
- High
Employee-
owned pro-
tection level
- Low
- Medium
- High
Data accident 
protection 
level
- Low
- Medium
- High
Attack 
protection 
level
- Low
- Medium
- High
Accident 
protection 
level
- Low
- Medium
- High
Data attack 
protection 
level
- Low
- Medium
- High
Security 
training level
- Low
- Medium
- High
Policy 
protection 
level
- Low
- Medium
- High
Performance 
management 
level
- Low
- Medium
- High
Pre-
employment 
screening level
- Low
- Medium
- High
Gender 
(soft evidence)
- Male
- Female
Stress level
- Low
- Medium
- High
Motivation 
level
- Low
- Medium
- High
Legend
Basis variables
Prior indicator 
variables
Measure 
variables
Figure 36: Alpha model structure.

6.3 alpha model
83
4. Pre-employment screening is the best protection against mali-
cious employees and thus has the highest impact on motivation.
When the organization has policies the employees can still de-
cide not to follow them, therefore policy protection has a lower
impact than motivation level.
5. Motivation level is inﬂuenced by four nodes which makes it
quite hard to ﬁll its table. The node with the highest impact is
Group state because when the group is positive it is not likely
that mobile devices will be misused. Reason strength comes sec-
ond since strong reasons will have a large impact on whether
the misuse will actually be performed. Since a positive group is
likely to have a good Attitude towards work this node does not
have much impact anymore and becomes third. The node with
the lowest impact is Gender whereby males are more likely to
have a motivation than females.
6. In general there is a small probability that the group state is neg-
ative, however the higher the performance management level
the smaller the negativity and the higher the positivity.
7. Because Revenge is an emotional state of a group we assume
that this variable has a low impact on Reason strength. Further-
more, we assume that people are more likely to commit crime if
it results in money and therefore a ﬁnancial motive is stronger
than competitive advantage.
8. Skills have a larger impact on capability than job type because
we think that crimes and losses occur within every job no matter
how technical their job is.
9. When organizations provide security training to their employ-
ees they are more informed about how to protect their devices
against loss, but on the other hand they are more aware of the
protection level of the organization, so the higher the security
training level, the higher the skills of the employees will be.
10. Employer-owned devices have a higher impact on attack op-
portunity than attack protection level because employees are
already able to use the mobile devices and access the data.
11. To avoid that employees misuse mobile devices organizations
should have a high employer-owned device level of protection
since these measures, among others, have to make sure that
mobile devices can be tracked and have to be returned when
no longer needed. This variable thus has the highest impact
on the Attack protection level node. The data attack protection
level has the second highest impact because organizations have
to protect the data. Finally, employees can misuse the devices

84
alpha model
when there are no co-workers near them the organization pro-
tection level has the lowest impact of the three protection levels.
12. Employer-owned devices have a higher impact on accident op-
portunity than employee-owned devices because employees take
more care of devices they do not own. Since everyone is likely
to lose mobile device stress level only has a small impact on the
opportunity for an accident. Even though organizations cannot
avoid device loss, they can take multiple measures to protect
the data when mobile devices are lost. Therefore, the node with
the highest impact is Accident protection level.
13. To avoid that employees cause a data breach by losing their mo-
bile devices, organizations should have a high employer-owned
device level of protection because employees are most likely
to use these devices. This variable thus has the highest impact
on the accident protection level node. Thereafter, the employee-
owned device level has the highest impact and the data at-
tack protection level comes third impact, because organizations
should protect the data. Finally, employees can lose the devices
everywhere, so organization protection level has the lowest im-
pact of the three protection levels.
Additionally, the model must ensure that when there are no mobile
devices used in the organization data breaches cannot occur. So, when
the states for both Employer-owned devices and Employee-owned
devices are “None” the probability of a Data breach should be 0%.
This also includes that the probability for Mobile device misuse and
Mobile device loss should be 100% “Low”.
6.3.4
Sensitivity Analysis
To check whether the model suits our impact statements, we per-
formed multiple sensitivity analyses using AgenaRisk. This analysis
can be used to determine which variables have the highest impact in
the model by selecting one target node and one or multiple sensitiv-
ity nodes. When the target node is A and the sensitivity nodes are B
and C we can determine whether B or C has a higher impact on A.
For each node with a CPT we performed an analysis using its par-
ents nodes as sensitivity nodes. This resulted in a total of thirteen
analyses and for each of the analyses we checked whether the impacts
matched with the statements. We are not aiming for perfect numbers
in the model as it is hard to retrieve them, so we only looked at the
order of impact. If the order did not match we changed the values in
tables of the target variable until the correct order has been achieved.
More precisely, we checked for which state the impact was not cor-
rect and focused on the probabilities of these states by changing them
until this resulted in a correct analysis.

6.3 alpha model
85
In appendix D.4 it is explained were the results of the analyses
can be found. We will only show for the data breach analysis how
the results should be interpreted. Figure 37 shows the data breach
variable and its parents as part of the alpha Bayesian network.
Figure 37: Snapshot alpha Bayesian network model.
Table 14 shows the CPT for the Data breach variable whereby “L”
means “Low”, “M” stands for “Medium” and “H” for “High”.
loss
L
M
H
misuse
L
M
H
L
M
H
L
M
H
False
1.000
0.998
0.996
0.999
0.99
0.96
0.998
0.99
0.9
True
0.000
0.002
0.004
0.001
0.01
0.04
0.002
0.01
0.1
Table 14: Conditional probability table of data breach.
The information in this CPT is used for the automatic sensitivity
analysis of AgenaRisk. Figure 38 shows the outcome of the sensitiv-
ity analysis in the form of a table whereby the Data breach node is
selected as the target node and Mobile device misuse and Mobile de-
vice loss are the selected sensitivity nodes. The ﬁrst table, shown in
ﬁgure 38a, provides the outcome of P(Data breach | Mobile device
misuse) given all combinations of states. So, P(Data breach = True |
Mobile device misuse = Low), for example, results in a probability of
0.001. This probability is calculated as follows:
P(Data breach = True | Misuse = Low) =
P(Data breach = True | Misuse = Low, Loss = Low)
∗P(Loss = Low) +
P(Data breach = True | Misuse = Low, Loss = Medium)
∗P(Loss = Medium) +
P(Data breach = True | Misuse = Low, Loss = High)
∗P(Loss = High)

86
alpha model
The conditional probabilities, i. e. the parts before the ∗, can be re-
trieved directly from the Data breach CPT and the parts after the ∗
can be retrieved from the variable Mobile device loss in the BN of
ﬁgure 37. These values are derived from the parents of Mobile device
loss and those values are derived from their parents and so on until
the root nodes are reached. The formula given above thus results in:
P(Data breach = True | Misuse = Low) =
0.001 ∗0.3597 +
0.002 ∗0.14331 +
0.002 ∗0.49699 =
0.0016403 = 0.001
To verify the correctness of the values we checked whether the prob-
ability for the state “High” is higher than for the state “Medium” and
whether the probability for the state “Medium” is higher than for the
state “Low”. The same has been done for the table in ﬁgure 38b which
represents P(Data breach | Mobile device loss).
Mobile de-
vice misuse
Low
Medium
High
False
True
Data breach
0.999
0.992
0.936
0.001
0.008
0.064
(a) P(Data breach | Device misuse).
Mobile 
device loss
Low
Medium
High
False
True
Data breach
0.999
0.986
0.972
0.001
0.014
0.028
(b) P(Data breach | Device loss).
Figure 38: Sensitivity analysis of the data breach node - table.
The described method, however, cannot be easily used to check
which variable has the highest impact on the Data breach variable.
Therefore, it is also possible to show the sensitivity analysis in the
form of a tornado graph (see ﬁgure 39). As can be seen in both ﬁg-
ures Mobile device misuse is at the highest position and has thus the
largest impact on the Data breach variable. This is as desired and
therefore no changes need to be made to the CPT of Data breach.
6.3.5
Final Alpha Bayesian Network Model
In ﬁgure 40 the ﬁnal Alpha BN is shown. The probability of a data
breach for one random person according to this model is 1,639%. This,
however, is not the probability for one speciﬁc organization or the
whole sector since no observations have been been entered and there-
fore the probabilities of the root variables are not correct. So, this
model only provides the correct outcome for one speciﬁc organiza-
tion if observations are entered for all root variables or its children.

6.4 discussion
87
0.93      0.94       0.95      0.96       0.97      0.98       0.99      1.00       1.01
P(Mobile device 
misuse = High)
P(Mobile device 
loss = High)
P(Mobile device 
misuse = Low)
P(Mobile device 
loss = Low)
0.936
0.999
0.972
0.999
P(Data breach = False)
Current value P(Data breach = False) = 0.984
(a) P(Data breach = False).
P(Mobile device 
misuse = Low)
P(Mobile device 
loss = Low)
P(Mobile device 
misuse = High)
P(Mobile device 
loss = High)
-0.01      0.00       0.01      0.02       0.03      0.04       0.05      0.06       0.07
0.001
0.064
0.001
0.028
P(Data breach = True)
Current value P(Data breach = True) = 0.016
(b) P(Data breach = True).
Figure 39: Sensitivity analysis of the data breach node - graph.
6.4
discussion
The Bayesian network we created in this chapter can be viewed with
AgenaRisk (see appendix D.2). This model contains relative probabil-
ities and does not show precise numbers. This model is based on the
mobile device case and can be used to determine the probability of
a data breach caused by a group of insiders who lose or misuse mo-
bile devices. Additionally, the model can be used to determine which
measures the organization should take to lower this probability.
Since the model contains measure group it does not show details
for the measures. Using the model one is able to determine in which
group of measures additionally measures must be taken. But, for spe-
ciﬁc measures the assessment tool should be consulted. The assess-
ment tool, however, does not distinguish between different types of
measures and assigns the same value to all measures. Because of this
and since the measure variables in the model only have three states,
the model is less accurate model than when different values were
attached to the measures and ﬁve states were used.
Because the model is initial we did not provide all sensitivity anal-
yses, but only have shown an example of such an analysis. In the next
chapter we will use the knowledge of experts to check the correctness
of the nodes and the CPTs and perform additional analyses.

88
alpha model
Figure 40: Alpha Bayesian network model.

7
B E TA M O D E L
In this chapter we will create the beta Bayesian Network (BN) which
is an updated and validated version of the alpha BN of the previous
chapter. This model will also be based on the mobile device case and
thus takes employees who misuse employer-owned mobile devices
and employees who lose employee- and/or employer-owned mobile
devices into account. Misuse exists, in this context, of not returning
the devices when needed and copying personal data to private mo-
bile devices. The beta model can, just as the alpha model, be used
to determine the data breach probability for one speciﬁc organiza-
tion. To validate this model we will ﬁrst interview two legal advisers
about law and data breaches (see section 7.1). Thereafter, in section
7.2, we interview an information security ofﬁcer about the threats his
organization faces and how they protect themselves against mobile
device misuse and loss. To gather additional information about the
variables in the model we will create a survey for privacy and infor-
mation security experts (see section 7.3). Finally, in section 7.4, we
determine the impact of the variables in the model by a focus group
session. How the information is used to create the beta model and
how the model will be created will be explained in section 7.5 and
we end this chapter with a discussion in section 7.6.
7.1
interviews with legal advisers
To make sure our model captures a practical deﬁnition of the term
data breach, we interviewed two legal advisers of the same organiza-
tion. Both have experience with data breaches since the data breach
requirement came into practice in January 2016. The advisers have
over thirty years and over nine years of experience with privacy. They
both advise about whether a data breach should be reported or not,
but also ensure that data processing is conducted following the law.
During the interview we were curious about the answer to the fol-
lowing question: does a data breach occur if an encrypted mobile
device is lost? The answer to this question is not as straightforward
as we might think. The term data breach is not deﬁned in Dutch
Data Protection Act (DPA). But, in the corresponding guidelines [8]
this term is discussed and additional guidance on how data breaches
can be identiﬁed and when they should be reported to the authority
is provided. A data breach can only occur when there is a breach of
security. But, when there is a security breach this does not imply that
a data breach occurs as well. To determine the occurrence of a data
89

90
beta model
breach it must be investigated whether personal data has been lost or
not. When there is no complete and up-to-date backup a data breach
has occurred. When no data has been lost it should be reasonably
excluded that the personal data has been processed unlawfully and
when this is not possible there is a data breach and otherwise there is
not. This, however, does not imply that the data breach should be re-
ported to the Dutch data protection authority. Organizations should
investigate the situation further, but it is unclear whether the organi-
zation should report the loss of an encrypted device to the authority.
On the one hand, there is a group of people who state that there
are no negative consequences for the data subjects, as mentioned in
article 34a of the Dutch DPA [18], if the device has been protected
well. So, organizations do have not to report the incident. The other
group states that the data breach should be reported to the author-
ity, because the legislators’ intention was that data breaches should
be reported to the authority even when the devices are encrypted.
Amendment 14 on article 34a of the Dutch DPA [69] emphasizes on
this and states that organizations have to report data breaches to the
authority even if the data is encrypted.
The Dutch law is deﬁnitely unclear about this topic and therefore it
is likely that not all data breaches are reported to the authority even
though they should be. Since the law is quite new it is still a mat-
ter of interpretation, but lawsuits can provide a clear answer to this
situation. However, because the Dutch DPA will be replaced by the
General Data Protection Regulation (GDPR) in 2018, it might take a
while before clariﬁcation is given and it is known how the reporting
requirement should be interpreted. The GDPR does not have guide-
lines and it is not known whether they will be created.
Because the Dutch DPA applies since 2001 (without the reporting
requirement), it should be clear to organizations what technical and
organizational measures are and how they can be used to protect
personal data. To see how the organization of the legal advisers deals
with data breaches we interviewed the information security ofﬁcer.
7.2
interview with a information security officer
The ofﬁcer has over twenty years of experience with information secu-
rity and started with his current function in 2003. Until 2007 privacy
was a part of security within the organization, but thereafter two sep-
arate functions were created. Nowadays he is responsible for all risks
that arise from the use and management of computer systems.
Data breaches
For the security ofﬁcer the difference between a security breach and
a data breach is clear, however, he also mentioned the uncertainties
we discussed in section 7.1. To determine whether a security breach
resulted in a data breach the security ofﬁcer performs a risk analysis.
The loss of an encrypted laptop, for example, is a security breach.

7.2 interview with a information security officer
91
But, since the disk of the laptop is encrypted no one, except for the
owner, is able to access the data. Furthermore, the security ofﬁcer has
never heard of data access from lost encrypted laptops and therefore
assumes there is no risk of data loss. So, from his perspective the loss
of an encrypted laptop is not a data breach whilst the legal advisers
would probably call this a data breach in terms of the law.
Threats
We also asked the security ofﬁcer which threats to personal data are
the largest in his organization. This is hard to say as different kinds
of data breaches with a variety of consequences can occur. The secu-
rity ofﬁcer does believe that when taking all data breaches together
the threat posed by employees is the largest. The organization does
therefore focus on employees who consciously perform malicious ac-
tions, unconsciously make mistakes and consciously make mistakes
and assume that a small mistake is no problem at all.
Measures
To determine the threats and risks the organization faces, risk anal-
yses using Information Risk Assessment Methodology 2 (IRAM2) are
performed. These analyses are conducted per system and focus on
internal and external parties. Once a year an analysis is performed
for the whole organization. These analyses allow the organization to
identify the security gaps and get a clear view on which measures
should be taken. The measures are based on ISO 27001 and are con-
cretized using the knowledge and expertise of the employees within
the organization. Determining the speciﬁc measures is a challenge for
the organization, however they can make it as difﬁcult as they would
like. Since it is not possible to guarantee a protection level of hun-
dred percent, the focus should be on whether the current measures
are sufﬁcient enough and the remaining risks are acceptable.
Awareness
Security awareness has the highest priority within the organiza-
tion. The process of creating security awareness helps to determine
to what extent employees can be trusted with data i. e. the higher the
awareness, the more capable the employees will be with protecting
data. Other factors that can inﬂuence the trust in the employees are
their professionalism, skills and background. The organization does
not use speciﬁc methods to search for risk factors that can lead to a
data breach. However, they perform, on a regular basis, a threat/im-
pact analysis in which employees are an actor. When it is more likely
that more employees are, for example, disgruntled additional mea-
sures are taken. Finally, the organization is planning to obtain more
information about the awareness level of the employees.
7.2.1
Mobile Device Case
Laptops and tablets
All employees receive a laptop which may be used for private pur-
poses in a limited way whereby the organization is not responsible
for private data loss. Some employees also receive tablets for which

92
beta model
additional password requirements apply. Both devices must be re-
turned when the employment of the employees ends.
Smart phones
For smart phones the organization has a bring and select your own
device policy. If the device of the employee meets the organizations’
requirements and the employee agrees with the policies and allows
the organization to manage the device like it is theirs, the employee
is allowed to use his own device for business purposes. At the end of
employment or when the employee is going to use the smart phone
only for private purposes again the device will be wiped.
Employees who select a smart phone can spend a certain budget
and additional costs have to be paid by themselves. These devices
come with a contract of three years and if the employment ends be-
fore the contract ends they have to return the device. They can also
pay the remaining costs to the organization and then they are allowed
to keep the devices after they are wiped by the organization.
Measures
To avoid mobile device misuse and loss the organization has taken
multiple measures as shown in table 15. Because people are likely
to lose devices disk encryption is probably the most effective way to
avoid data breaches. But, increasing the awareness of the employees
is also a good way to decrease the probability of data loss.
Information security policies
Acceptable use policy
Device owner in policies
Private use allowed in policies
Mobile device usage in policies
Fining policy
Password requirements
Laptop lock
Laptop bag
Lockers
Introduction training
Security courses
Performance review
Access right checking
Awareness activities
Revoke access end employment
Remote wiping
Location services
No permanent data storage
Disk encryption
Automatic device locking
Report security incidents
Pre-employment screening with
criminal records check
Device disposing (third party)
Table 15: Interview with an information security ofﬁcer: measures for mo-
bile device misuse and loss.
7.3
survey
To gather more information about the prior indicators and measures
for the beta model we planned to arrange two focus group sessions
with three privacy and security experts in each session. But, the ex-
perts canceled the ﬁrst session, so instead we created a survey with

7.3 survey
93
ten open questions (see appendix B.1) and shared it with ten cyber
security master students and three cyber security and privacy consul-
tants. Even though this method has disadvantages, such as not being
able to discuss the answers and participants not spending much time
on the survey, we chose this option because it provides the answers
we need within a short time span.
7.3.1
Results
Six students and one consultant, all between 21 and 30 years, an-
swered the questions of the survey. Two of them are female and ﬁve
are male. In the survey we separated the questions based on the three
main elements of the alpha model: Motivation, Capability and Op-
portunity. Nevertheless, the answers to the questions were not clearly
divided among the topics and therefore we sorted them ourselves.
Motivation
The ﬁrst three questions of the survey provided insider motivations
to not return mobile devices and to copy data to private devices and
measures that can be taken to avoid these misuses (see table 16).
not returning devices
Monetary gain
Malicious intentions
Disgruntlement
Anger
Use for private purposes
Addition to their own devices
Forgetfulness
No data transfer to new device
Laziness
Device is lost
Device is stolen
Device is damaged
Feeling of being the owner
Not knowing the return rules
Employees see no problem in
keeping the device
Understanding a new device is
time consuming
copying data
Avoid restrictions
Dislike the device
Creating backups
Easy data access
To sell it
Blackmailing
Espionage
Curiosity
measures
(Punishment) policies
Regular policy awareness check
High quality devices
Provide multiple device options
Dismissal procedure
Table 16: Survey: motivations and measures for mobile device misuse.

94
beta model
Capability
Questions four to six focused on the capability of the employees
and measures to improve their capability. According to the partici-
pants employees in general do not need speciﬁc skills to misuse or
loss mobile devices. However, for misuse some basic skills might
be helpful or even necessary when good protection mechanisms are
used to protect the mobile devices. It might also be possible that the
employees do need resources when they let someone else copy the
data for them. To avoid device loss, which is seen as an accident, the
participants did also provide speciﬁc skills. An overview of all men-
tioned skills and measures is given in table 17.
skills for misuse
Knowledge of mobile devices
Data copy techniques
Knowledge of online sale
Circumventing remote locking
Circumventing remote wiping
How to use Google
Become “friends” with someone
from IT to ask for help
Understanding of policies
skills for loss
Understand sensitivity of data
Sense of responsibility
Knowledge of remote wiping
Knowledge of device tracking
Knowledge of encryption
Carefulness with devices
Understand difference between
business and private devices
measures
(Introduction) training
Device usage explanation
Explain protection of devices
Explain risks of copying data
Explain dangers of devices
Awareness campaign
Explain consequences of loss
Explain consequences of misuse
Discuss rules with employees
Table 17: Survey: capability and measures for mobile device misuse and
loss.
Opportunity
In questions seven to nine we asked for factors that indicate that
employees are likely to lose mobile devices and about measures that
can be taken to lower the probability of mobile device misuse and
loss. We did not ask for opportunity indicators of device misuse be-
cause this was captured in the motivation question. The answers to
the questions can be found in table 18.
Final comments
Based on question ten we received two ﬁnal comments. First, to
avoid the impact of a data breach organizations should use cryptog-

7.4 focus group
95
raphy and ensure regular cleanups of unnecessary data. The other
suggestion is that we could also take adversaries who are trying to
gain access to mobile devices without the explicit fault of the employ-
ees into account. For example when the employees leave the devices
somewhere for a few minutes, but have an intention of coming back
and recovering the device (e. g. when they are going to the toilet).
prior indicators of loss
Lack of security interest
Carelessness
Sloppiness
Chaotic employees
Negligence
Device loss history
Complaints about devices
Unmotivated employees
measures for misuse
Remote device locking
Remote device wiping
Device monitoring
Data encryption
Device tracking
Collect employees’ wishes
Anti-theft solutions
Owner indication on the device
Employee behavior monitoring
Remote administration
Only
authorized
devices
can
pull data from mobile devices
Device owner list
measures for loss
Awareness campaign
User-friendly devices
Limit number of devices to one
Kensington locks for laptops
Device tracking
Owner indication on the device
Device owner list
Sanctions/ﬁnes for device loss
Table 18: Survey: opportunities and measures for mobile device misuse and
loss.
7.4
focus group
After the survey was shared the focus group session with three cyber
security and privacy consultants took place. The goal of this session
was to determine the impact the variables in the model have on each
other. We ﬁrst asked the experts about themselves using a form (see
appendix D.1) which resulted in the characteristics of table 19. After
they ﬁlled in the form, a presentation with an explanation of our
research and the two assignments was given (see appendix D.1).

96
beta model
#1
#2
#3
Gender
Male
Male
Male
Age
31
27
27
Years experience privacy
4
2
3
Years experience health care sector privacy
2
1
1,5
Years experience security
6
2
4,5
Years experience health care sector security
2
1
4
Table 19: Focus group: characteristics of the participants.
7.4.1
Individual Assignment
The ﬁrst assignment was an individual assignment whereby the par-
ticipants ﬁlled in whether they agreed or disagreed with ﬁfteen state-
ments. Eight of these statements were related to prior indicators of
data breaches due to mobile device misuse and loss and the other
seven statements were related to preventive measures an organiza-
tion can take to prevent these data breaches. These statements were
used to trigger the experts to establish a ﬁrst opinion about the prior
indicators and measures related to data breaches. Because their opin-
ion changed during the second assignment these results will not be
used to create the beta model, but can be found in appendix B.2.1.
7.4.2
Group Assignment
The second assignment, a group assignment, was about the actual
impact of the relationships. Nodes with a Conditional Probability Ta-
ble (CPT) were mentioned and ten points must be divided over their
parent nodes. We chose this number because our model does not re-
sult in absolute probabilities and more precision makes it harder to
determine the values. The more points were assigned to a parent, the
higher the impact on the CPT variable. To make sure that the impacts
are solely based on expert knowledge, the participants could only ask
questions about unclear terms or interpretations of the model.
In total there are thirteen CPT variables. The Group state variable
was not part of this assignment because the parent Performance man-
agement was captured in the impact on Motivation. We did this be-
cause we were interested in which measure has the highest possibility
of decrease the misuse motivation of employees. Additionally, Attack
opportunity was not added to the assignment either since it has only
one prior indicator and measure as parents.
For the Skills variable we asked the participants to determine the
inﬂuence of training and to ﬁll in the CPT whereby each column
must sum up to ten (see table 20). Their reasoning was actually quite

7.4 focus group
97
simple: there are always people who have more or less skills than can
be learned via a training.
training level →
low
medium
high
Low
7
3
1
Medium
2
5
6
High
1
2
3
Table 20: Focus group: results conditional probability table Skills.
For the other ten variables table 21 shows the division of the ten
points over their parents. The reasoning for these divisions can be
found in appendix B.2.2. Additionally, three reasonings are not cap-
tured in the divisions in this table, but are relevant for the beta model:
• Training employees is not enough to avoid mistakes, so addi-
tional measures must be taken, however training is at least as
important as these additional measures;
• Creating policies is less important than training the employees
because creating policies is a passive way of protection and em-
ployers must make sure they are clear to and read by the em-
ployees. Training, on the other hand, is more active and can be
used to make the employees aware of security, teach them about
device protection and answering their questions;
• Protection against mobile device loss and misuse is very im-
portant, but loss protection might be more important since it is
more likely that employees lose devices than misuse them.
7.4.3
Suggestions
It turned out to be quite hard for the participants to determine the im-
pact of the variables. Not only because they have no experience with
behavioral prior indicators, but also because they have no detailed
knowledge on which measures are more effective and there was lim-
ited time available (1.5 hours). Nevertheless, the participants came up
with four additional suggestions to improve the model:
1. The opportunity for mobile device loss might also depend on
the location of the employees or their surroundings;
2. A relation could be added between Group state and Attitude
towards work because when there is a positive group state the
group might also be more committed to their job;

98
beta model
cpt variable
parents
points
Data breach
Mobile device misuse
2
Mobile device loss
8
Mobile device misuse
Motivation
8
Capability
1
Attack opportunity
1
Mobile device loss
Capability
6
Accident opportunity
4
Motivation
Policy protection level
1
Performance management level
5
Pre-employment screening level
4
Motivation level
Group state
2
Gender
1
Reason strength
4
Attitude towards work
3
Reason strength
Financial
8
Competitive advantage
0
Revenge
2
Capability
Skills
7
Job type
3
Accident opportunity
Employer-owned devices
3
Employee-owned devices
2
Stress level
5
Accident protection level
Employer-owned protection level
2
Employee-owned protection level
1
Organization protection level
4
Data accident protection level
3
Attack protection level
Employer-owned protection level
4
Organization protection level
2
Data attack protection level
4
Table 21: Focus group: results group assignment.
3. The competitive advantage variable can be removed because
this is not applicable for the health care sector, i. e. the employ-

7.5 beta model
99
ees are not going to leave and start their own hospital or sell the
data to their new employer;
4. Take a look at ethical reasons to misuse mobile devices such as
someone who wants to blow a whistle.
After the session we have showed our assessment tool and alpha
Bayesian network model to the participants. This resulted in three
comments and questions:
1. How does the model deal with devices that can be used for
private and business purposes at the same time?
2. The names of the variables could be clariﬁed, i. e. attack and
accident is not speciﬁc;
3. To complete the assessment tool it might be useful to add the
prior indicators as well.
7.5
beta model
The gathered information will be used to update the alpha model
to the beta model. Based on the discussions with the legal advisers
and security ofﬁcer we will concretize the deﬁnition of the term data
breach. The law and complementary guidelines determine the occur-
rence of a data breach independently of which measures are taken
by the organization. So, if an encrypted laptop is lost and backups
are available this might still be a data breach. However, the security
ofﬁcer takes a risk point of view and states that with a high protec-
tion level it is unlikely that the data has been breached. The focus for
our model will be the latter since this is more practical and organiza-
tions want to avoid actual data leakage. Furthermore, the model does
not take the impact of the data breach, the number of records that
are unlawfully processed and the reporting requirement into account.
Because we take this focus measures such as encryption and remote
wiping are still relevant for our model and can inﬂuence whether a
data breach is likely to occur. So, using this model organizations can
determine the probability of a breach from a risk point of view, which
is not directly related to the deﬁnition of the guidelines of the law.
7.5.1
Nodes and Values
Prior indicators
Because the motivation part in our model only focuses on malicious
actions only the suggestions ﬁnancial gain, blackmailing, curiosity, es-
pionage and anger are relevant. However, since we want to avoid com-
plexity we decided to keep Revenge as example and did not add any
other variables. The experts of the focus group suggested to remove
C advantage, we agreed with this as this is not likely to happen and

100
beta model
makes the model simpler. They also suggested to consider variables
related to whistle blowing. However, since this is an ethical question
and every organization deals with this in a different manner and to
avoid complexity we did not add such variables.
For Capability we agree with the participants of the survey that
employees in general do not need speciﬁc skills to lose a device, not
return a device or copy data to their own devices. The suggested skills
are very speciﬁc and as mentioned by the participants of the survey
Google can be useful to learn about misuse and loss, therefore we did
not change the prior indicators related to capability.
The Accident opportunity could be extended with prior indicators
such as location, history of lost devices, device complaints and slop-
piness. However, to avoid complexity we will not add them.
Furthermore, for both Accident opportunity and Attack opportu-
nity we did not take into account whether employer-owned devices
may be used for private purposes. This could, however, make a dif-
ference in the probability of mobile device loss and misuse. When
the devices can be used for both private and business purposes, the
employees will use the devices more often which increases the prob-
ability of loss. The probability that they will not return the devices
might also increase because they have a higher emotional bond with
the device. Finally, we assume that the probability of employees copy-
ing data to their own devices will be lower when they are allowed
to use the devices for private purposes. So, based on the comment of
the focus group we were planning to add a Boolean prior indicator
called Private use. However, it was not possible to add only one vari-
able for both employer- and employee-owned devices because they
have a different inﬂuence on the data breach probability. This would
be too complex, so we decided to leave this variable out.
For the data breach assessment tool we agreed with the suggestion
of the focus group to extend it with the prior indicators. The tool
shows questions whereby one of the states can be selected as answer
and afterwards can be entered in the BN (see appendix D.3).
Measures
For the measure variables changes have been made as well. Be-
cause the terms accident and loss and attack and misuse are used
interchangeable in the alpha model it is confusing for the readers.
Therefore, we changed the names of six nodes as follows:
• Data attack protection level
→Data misuse protection level
• Data accident protection level →Data loss protection level
• Attack protection level
→Device misuse protection level
• Accident protection level
→Device loss protection level
• Attack opportunity
→Device misuse opportunity
• Accident opportunity
→Device loss opportunity

7.5 beta model
101
Most of the measures mentioned by the security ofﬁcer and survey
participants were already (indirectly) captured in the assessment tool.
However, based on the discussion with the security ofﬁcer we added
two measures to the Policy protection level variable: “Policies should
cover who owns the devices” and “Policies should cover whether pri-
vate use of mobile devices is allowed”. The survey results led to one
additional measure in the same category, namely: “Policies cover the
employee dismissal process”. Furthermore, we merged the sugges-
tions “User-friendly devices”, “Providing high quality devices” and
“Providing multiple device options” to “There are requirements for
which devices the employee can use” as part of the Employer-owned
protection level. Finally, we did not add the suggestions “Digital right
management system” and “The mechanism that only authorized de-
vice can pull data from and push to the mobile devices” because this
is too complex and already (partly) captured in the existing measures.
So, we did not change the measures in the model itself.
7.5.2
Structure
In ﬁgure 41 the structure for the beta BN can be found. There are only
two changes compared to the alpha model: the Competitive advan-
tage variable has been removed and the six variables, as mentioned
above, have been renamed. The focus group suggested to add a rela-
tion between attitude towards work and group state, but we decided
not to do this for two reasons. Firstly because in the research of Nurse
et al. [56], on which we based our model, this relation was not added
and secondly we want to avoid additional model complexity.
7.5.3
Probabilities
Now, we will use the results of the focus group session to reestab-
lish the values in the CPTs. We used the CPTs of the alpha Bayesian
network model as basis and changed them when needed. Table 22
provides comments on why the changes have been made.
7.5.4
Sensitivity Analysis
To check whether we achieved the correct impacts we performed mul-
tiple sensitivity analyses (see appendix D.4). This was done in the
same way as in section 6.3.4. However, now we also checked which
measure has the highest impact on the probability of misuse and loss.
We did this by selecting the measures as sensitivity nodes and the
mobile device misuse variable as target node and later with mobile
device loss as target node. For these analyses we tried to make sure
that the following statements about impacts of the focus group are
met:

102
beta model
Device loss 
opportunity
- Low
- Medium
- High
Employer-
owned devices
- N
- P
- P + S
Employee-
owned devices
- N
- P
- P + S
Capability
- Low
- Medium
- High
Job type
- Care workers
- Support
- Technical
  support
Skills
- Low
- Medium
- High
Motivation
- Low
- Medium
- High
Reason 
strength
- Low
- Medium
- High
Attitude 
towards work
- Actively un-
  committed
- Not com-
  mitted
- Committed
Group state
- Negative
- Neutral
- Positive
Revenge
- False
- True
Financial
- False
- True
Mobile device 
misuse
- Low
- Medium
- High
Mobile device 
loss
- Low
- Medium
- High
Data breach
- False
- True
Device misuse 
opportunity
- Low
- Medium
- High
Employer-
owned pro-
tection level
- Low
- Medium
- High
Organization 
protection 
level
- Low
- Medium
- High
Employee-
owned pro-
tection level
- Low
- Medium
- High
Data loss 
protection 
level
- Low
- Medium
- High
Device misuse 
protection 
level
- Low
- Medium
- High
Device loss 
protection 
level
- Low
- Medium
- High
Data misuse 
protection 
level
- Low
- Medium
- High
Security 
training level
- Low
- Medium
- High
Policy 
protection 
level
- Low
- Medium
- High
Performance 
management 
level
- Low
- Medium
- High
Pre-
employment 
screening level
- Low
- Medium
- High
Gender 
(soft evidence)
- Male
- Female
Stress level
- Low
- Medium
- High
Motivation 
level
- Low
- Medium
- High
Legend
Basis variables
Prior indicator 
variables
Measure 
variables
Figure 41: Beta model structure.

7.5 beta model
103
cpt variable
changed
comment
Data breach
No
The focus group reasoned that mobile device loss occurs more often than misuse and therefore results
in a data breach more often. However, a loss does not always result in a data breach and we therefore
stick with the reasoning of the alpha model.
Mobile device misuse
Yes
We followed the focus group and made the impact of opportunity smaller.
Mobile device loss
Yes
We agreed with the focus group that the impacts should be closer to each other. However, we believe
that opportunity has a higher impact because loss is mostly an accident.
Motivation
No
The values already matched with the opinion of the focus group.
Motivation level
Yes
We followed the reasoning of the experts, so the impact, from high to low, is: reason strength, group
state, attitude towards work and gender.
Group state
Yes
The focus group stated that performance management has a high impact and we followed this.
Reason strength
Yes
Competitive advantage was removed and we followed the reasoning of the focus group, so ﬁnancial
has a larger impact than revenge.
Capability
Yes
The table was changed to make the impacts closer to each other.
Skills
Yes
The completed CPT of the focus group was used.
Device misuse opportunity
Yes
In the alpha model the inﬂuence of the protection level was too small, so we changed the table.
Device misuse protection level
Yes
We agreed with the focus group that protection of mobile devices is equally important as protecting
the data on the devices and that the organization protection level is less important.
Device loss opportunity
Yes
The reasoning of the focus group has been followed, i. e. the stress level has the highest impact and
thereafter employer-owned devices and ﬁnally employee-owned devices. We also made sure that not
all devices losses can be protected with device loss protection level.
Device loss protection level
Yes
We agree with the focus group on the following order, from high to low: organization protection level,
data accident protection level, employer-owned protection level, employee-owned protection level.
Table 22: Beta model: changes in the conditional probability tables.

104
beta model
• Training is at least as important as taking other measures;
• Creating policies is less important than training the employees;
• Mobile device loss protection is at least as important as mobile
device misuse protection.
7.5.5
Final Beta Bayesian Network Model
In ﬁgure 42 the ﬁnal beta Bayesian network is shown (for ﬁle see
appendix D.2). Due to the changes in the model the probability of a
data breach for one random person is now 2,467% instead of 1,639%
in the alpha model. This, however, is still not a the probability for
one organization or the whole sector since no observations have been
been entered and therefore the probabilities of the root variables are
not correct. So, this model only provides the correct outcome for one
speciﬁc organization if observations are entered for all root variables
or its children which we will do in the next chapter for three hospitals.
7.6
discussion
For the beta Bayesian network we used the alpha model of the previ-
ous chapter as basis, but changed the variables and values using the
knowledge of two legal advisers, an information security ofﬁcer, cy-
ber security and privacy consultants/experts and cyber security mas-
ter students. Since we wanted to avoid additional model complexity
we did not apply all suggested changes. Furthermore, it turned out
to be really hard to ﬁll the CPTs of the variables. Not only because the
experts did not have sufﬁcient knowledge to be sure about their divi-
sions, but also because some CPT variables have four parents which
is too many. Due to time constraints we were not able to ask more
security and privacy experts about their opinion on the model, but
for future research it might be valuable to do so. It might also be an
option to include behavioral and crime experts in the focus group
session or use methods to automatically collect data.
The focus of this model is on data breaches in which data is actu-
ally breached, so a well protected mobile device does not result in a
data breach. The survey participants suggested to also take measures
to decrease the impact of the data breach into account and look at
situations in which adversaries are trying to gain access to mobile
devices without the explicit fault of the employees. This, however, is
outside the scope of our research, but could be an option for future
research.
In the next chapter we will use the beta model and assessment tool
to determine how they can be used effectively in hospitals.

7.6 discussion
105
Figure 42: Beta Bayesian network model.


8
G A M M A M O D E L
The alpha and beta model of the previous chapters are both based
on a mobile device case. This case describes that employees can use
their own mobile devices for business purposes or use mobile devices
from the organization. Both devices can be lost by employees and they
can try to misuse the employee-owned devices by not returning them
when needed or by copying personal data from the devices to their
private devices. This chapter focuses on the usefulness and effective-
ness of the beta model in practice. Therefore, we will interview three
employees responsible for data protection in different Dutch hospitals
and perform the data breach assessment with them (see section 8.1).
Based on the outcome of these sessions we will investigate whether
further updates of the model are necessary. This, then, will result in
the gamma model (see section 8.2). Finally, in section 8.3, we will
discuss the overall effectiveness of the model in practice.
8.1
hospital validation
To investigate the usefulness of the beta model and the designed tool
in practice, we visited three top-clinical hospitals in the Netherlands.
The ﬁrst hospital has over 6.000 employees, the second hospital has
less than 3.000 employees and the last hospital has between 3.000 and
6.000 employees. During each visit we discussed the topics informa-
tion security and threats related to personal data with an employee
responsible for the security of personal data in the hospital. Since all
three interviewees of the hospitals agreed to participate anonymously
in this research we will not provide any further details about the hos-
pitals and when we say “he” it can also mean “she”.
Interview process
During the interviews we ﬁrst discussed personal data threats the
hospital faces and which differences they experience between threats
of authorized and unauthorized persons and malicious and acciden-
tal insider threats. We also asked for methods to investigate non-
technical risk factors of data breaches and whether they look at chang-
ing behavior of the employees to lower the probability of a data
breach. Thereafter, we asked which methods are used to determine
what measures should be taken, what difﬁculties they face while se-
lecting measures and how they determine to what extent employees
can be trusted with personal data. After the general questions, we
asked questions related to the mobile device case and performed the
assessment using the designed assessment tool. Initially, we discussed
which mobile devices are provided by the organization and which
107

108
gamma model
employee-owned devices may be used. Since it takes quite some time
to enter the data from the assessment tool as observations into the
Bayesian Network (BN) we e-mailed the results to the hospitals after-
wards and asked for a short reaction. We still demonstrated how the
BN can be used in combination with the assessment tool and asked
the interviewees the give their opinion about this. The interview ques-
tions can be found in appendix C.1.
8.1.1
Hospital A
In the largest hospital we spoke with the information security ofﬁcer
who also is a privacy ofﬁcer and data protection ofﬁcer. He has over
twenty years of experience with privacy in the health care sector and
he became responsible for information security in 2010.
Threats
The ofﬁcer mentioned three threats related to personal data of
which the employees of the hospital are the largest. Not only because
they already have access to the data, they are also likely to make mis-
takes and are unaware of the importance of personal data and the
consequences of their behavior. The second threat are suppliers, such
as cloud or medical equipment suppliers. These parties have a lot of
power since the hospital depends on them and need their supplies.
The ﬁnal threat is related to the exchange of personal data between,
for example, hospitals. In these situations additional measures must
be taken and the data is not in control of the hospital anymore.
Measures
To determine general security measures to protect the organization
ISO 27001 and NEN 7510 are being used. The speciﬁc measures are
determined with knowledge of the IT department, IT specialists from
other hospitals and consultancy organizations. For privacy the Dutch
Data Protection Act (DPA) and the General Data Protection Regula-
tion (GDPR) are taken into account. Additionally, risk analyses are
performed to determine the priorities. These analyses provide guid-
ance on which measures should be taken, but do not take behavioral
changes of the employees into account. For the organization it is difﬁ-
cult to determine what should be done with new developments, but
they do have a center for improvement and innovation in which em-
ployees try to improve processes of the organization.
Awareness
The hospital expects a certain level of security awareness and ca-
pability to perform tasks from the employees. It is, however, hard
to determine to what extent they can be trusted with personal data
and at this moment most of the employees of the hospital are un-
consciously incompetent. But, the hospital is aiming to achieve that
their employees are consciously competent. Therefore, the awareness
of the employees is their most important point of focus. To increase
the awareness the organization leaves nothing to chance and explains
to the employees how they should deal with personal data and why
speciﬁc methods should be used. However, consciously competent

8.1 hospital validation
109
employees can also have negative consequences such as malicious
employees knowing the security level of the organization.
8.1.1.1
Mobile device case
To perform the assessment we introduced the mobile device case to
the interviewee and asked which mobile devices can be used by the
employees. If the employees need mobile devices to perform their job
and have permission of their supervisor they receive a laptop, tablet
and/or smart phone. For these devices the IT department deﬁnes the
requirements. Employees can also use their own mobile devices for
business purposes. The kind or brand does not matter, but the device
must be protected with a log in code. With these devices employees
can log in to the secured network of the hospital and access the data
via a Virtual Private Network (VPN) connection.
Assessment
The assessment has been performed for a group of hundred doctors
of the hospital. According to the interviewee a data breach because of
loss probably occurs on a yearly basis within this group, but it might
be even more since not all doctors know what a data breach is and
when incidents should be reported. The questions of the assessment
tool have been answered while keeping this group of employees in
mind. In appendix C.2 the observations are shown and it is explained
where the completed assessment can be found.
Results
The results of the assessment have been added to the BN as obser-
vations (see appendix D.5). This resulted in a data breach probability
of 2,612%. Since we performed the assessment for a group of hundred
employees, the probability that at least one person within the group
causes a data breach within a year is 92,12%. The probability that
this data breach is caused due to mobile device loss is the highest.
Given the prior indicators of the assessment the probability ranges
from 84,48% to 99,42% depending on which measures are taken. To
decrease this probability it is most effective for the hospital to take
measures related to pre-employment screening, employer-owned de-
vices and security awareness.
Evaluation
The security ofﬁcer has not seen a tool like this before and believes
that this tool could be a valuable measurement instrument. Not only
does it provide the option to analyze speciﬁc groups of employees,
such as doctors, but it also has a strong link between implemented
measures and measures that could be taken. This allows the users
to obtain an insight in the current situation and link this to possible
improvements. Because the tool provides insights in what should be
improved within the organization, it is possible to consciously decide
what action should be taken and control the situation. Even though
this model is very speciﬁc it would be practical if it can also be created
for other threats or organization parts. For a security ofﬁcer it is hard
to gain insight in the states of the prior indicators. Maybe it might
be an idea to link these indicators to the outcome of the yearly em-

110
gamma model
ployee satisfaction survey. Another option is to have a conversation
with the group of employees and then using this tool to check what
should and could be done to improve the current situation. Finally, it
is hard to focus on speciﬁc individuals and therefore it is sufﬁcient
that different group sizes can be taken into account.
8.1.2
Hospital B
The interviewee of the second hospital has seven years of experience
with privacy and information security and is besides security ofﬁcer
also privacy ofﬁcer and data protection ofﬁcer.
Threats
For the ofﬁcer it is hard to say whether authorized or unautho-
rized persons are a larger threat to the hospital. Authorized persons
can make mistakes with the data and misuse their privileges to harm
the organization, whereby the latter is a smaller threat for the hos-
pital. Unauthorized persons, on the other hand, have to take addi-
tional steps to access the data but they can harm the organization as
well. Because of the open structure of the hospital it might be easier
for them to attack the hospital than other organizations. The largest
threat the hospital faces is data sharing with external parties such as
general practitioners, suppliers and other hospitals. The organization
then has to trust the security of these parties and is not always able to
control the security of the data. More speciﬁc, external e-mail trafﬁc
has the main priority within the organization at this moment.
Measures
To determine which measures should be taken discussions with the
IT/security team take place. However, the hospital also has a formal-
ized way of determining the measures which is based NEN 7510, ISO
27001 and risk analyses on information resources. The hospital does
not use speciﬁc methods to identify risk factors of a data breach, but
tries to inﬂuence the behavior of the employees by measures that both
facilitate the user and increase the security.
Awareness
The organization fundamentally trusts all its employees, but does
take measures to make sure they work safely. They, for example, ar-
range information meetings, write blogs about information security
and visits departments to share security knowledge. To increase the
awareness within the organization the ofﬁcer uses methods to make
sure that the employees remember the information better and to make
the information more recognizable and realistic. Finally, checks on
system actions of the employees are performed.
8.1.2.1
Mobile device case
The hospital provides laptops, tablets and smart phones to employ-
ees who need them to perform their job and have approval of their
supervisor. For these devices the hospital determines their own re-
quirements. They decided to avoid corporate applications and mobile
device management because of the high level of security that already

8.1 hospital validation
111
is in place by using virtual sessions with no data stored local on the
device. Employees can also use their own mobile devices for which
there are no requirements. With the mobile devices the employees
only can access their e-mail and calendar when they agree with the
security policy. This policy forces the user to use a code to protect
their phone and allows the organization to perform a remote wipe.
In the case of mobile device loss all data will be wiped including
private data, therefore a back-up of private data is suggested. Fur-
thermore, there is no difference in the management of both types of
devices and only e-mail and the calendar data is stored on the de-
vices. All other information can be accessed via the online workplace
using Citrix which requires a password. Accessing the business wire-
less network, however, is only possible after the employees received
permission from their supervisor. When connected to this network
e-mail and calendar can be synchronized and other hospital applica-
tions can be accessed after entering a password. Outside the hospitals
business network two factor authorization is required.
Assessment
For the assessment a group of 160 specialized doctors has been se-
lected. The security ofﬁcer cannot imagine that it is possible to steal
the devices when the employees have to return it to the organization
and cause a data breach. Since the device is owned by the organiza-
tion the organization is able to wipe the device and avoid data loss.
Losing devices, on the other hand, will maybe occur once or twice
per year. How many employees are copying the data to their own de-
vices is difﬁcult to say, because employees are already allowed to use
all kind of devices and if they want to download personal data from
the new digital workplace they have to put a lot of effort in it. Since
this is a conscious action they want to harm the organization which
is likely, but with a small probability.
Results
The assessment results for this group of employees can be found
appendix C.2 and D.5 and have been added as observations to the
BN. This resulted in a data breach probability of 2,548%. Since we
performed the assessment for a group of 160 employees, the proba-
bility that at least one person within the group causes a data breach
within a year is 98,39%. Given the prior indicators of the assessment
the probability ranges from 95,79% to 99,98% depending on which
measures are taken. To decrease the probability the hospital could
best take measures related to pre-employment screening. However,
since the ofﬁcer did not know whether the measures related to pre-
employment screening were taken we assumed a medium protection
level. The organization is not planning to take additional measures
against mobile device misuse and loss. The basis principle of the
organization regarding mobile device loss is that even though mo-
bility is one of the characteristics of a mobile device and it is likely
that these devices will be lost, the ﬁnder cannot do anything with
the device. The organization does not want to use measures such as

112
gamma model
RFID tags because of the privacy of the employees. Taking measures
against data copying costs a lot of effort while these are easy to by-
pass. Employees can, for example, take a photo of the screen. Finally,
the devices are owned by the hospital and will be claimed back at the
end of employment and are in case of theft or loss easy to wipe.
Evaluation
The security ofﬁcer does not like systems to improve the secu-
rity within the organization, instead it should be a process that can
be followed which eventually results in a more secure environment.
However, he does think this kind of model might be useful to de-
termine where the organization should focus on. Nevertheless, the
ofﬁcer would only take a short look and perform the assessment to
see what the effect is. Thereafter he will not use the program anymore
and uses his own common sense to determine what measures should
be taken by the organization. Determining prior indicators is hard for
the security ofﬁcer, but he does understand the importance of it and
states that the focus should be on persons because the organization
always depend on their employees. During the continuous process
of information security he keeps in mind that it should be easier for
employees to perform their job and not harder. Finally, he states that
as a security ofﬁcer you should look around and keep on asking and
use your own intellect.
8.1.3
Hospital C
In the third hospital we visited the data protection ofﬁcer who is an
internal supervisory authority for the organization and monitors the
application of and compliance with the Dutch data protection act. The
interviewee has about one and a half years of experience with privacy
and has limited knowledge about information security.
Threats
Within this hospital employees are seen as the largest threat to per-
sonal data. Employees are able to access personal data and make
mistakes of which they are (sometimes) unaware. Malicious insider
threats are not likely to occur in the hospital since the ﬁrst intention
of employees in the health care sector is to take care of patients and
cure them. Suppliers are also a threat for the hospital since they might
have access to the data. A third threat the hospital faces is the possibil-
ity that data access is made impossible due to ransomware installed
by employees. The consequences of this can be huge regardless of
whether the employees installed it on purpose or it was an accident.
Even though these three threats are substantial, the main priority
within the hospital, at this moment, are system authorizations to pa-
tient ﬁles in which medical data is stored. Since it might occur that,
besides the doctor of the patient, other experts need to access the data
a practical solution that takes both patient safety and health and data
protection into account is needed.

8.1 hospital validation
113
Measures
The hospital has no speciﬁc method to identify the prior indicators
of a data breach. They neither use methods to identify behavioral
changes of their employees. But, to determine which measures should
be taken to limit the probability of data breaches the organization
performs risk analyses and a privacy impact assessment. The speciﬁc
measures are determined in discussions with the IT team. Ensuring
that these measures are implemented is hard since the ofﬁcer can
only advice on what should be done and others take factors such as
money, time and usability into account. The policies and agreements
of the organization are based on ISO 27001 and NEN 7510, but the
organization is not yet certiﬁed for these standards.
Awareness
In general all employees are trusted, but awareness is an important
aspect and when an accident or data breach occurs the organization
intervenes and takes additional measures. Additionally, the organi-
zation has an authorization matrix that describes the authorizations
per job role which is checked on a regularly basis. Finally, logging
is performed to monitor the data actions the employees perform. It
is, however, difﬁcult to determine what should be checked and mon-
itored. The organization does, however, promote their information
security policy and suggests supervisors to discuss this in team meet-
ings. New employees are required to follow an introduction day of
which privacy and data breaches is an important part. Additionally,
the hospital participates in the national campaign Alert Online and
data protection information is provided via the hospitals’ magazine,
leaﬂets and intranet. To make sure employees read and remember the
information cartoons are designed for the hospital.
8.1.3.1
Mobile device case
The hospital provides tablets, smart phones and laptops to their em-
ployees. Since the supervisors have to pay the devices from their bud-
get they decide whether an employee receives a mobile device or not.
Employees are allowed to use the devices for private use in a limited
way when it does not disturb their job. Accessing their private e-mail,
however, is not allowed. The employees can access their business e-
mail and calendar via Outlook. For access to other information they
have to sign in to the hospitals online environment using Microsoft
Works. When the employees are accessing the environment outside
the hospitals’ private network two factor authentication with a pass-
word and token is required. The employees are also able to access the
environment via their private computer, then however certain func-
tionalities such as printing are disabled. The data protection ofﬁcer
believes that no data is stored on the devices, but does not know
whether the e-mails and calendar information are stored on the de-
vices. All devices can be wiped by the organization.

114
gamma model
Employees are not allowed to bring their own devices, because this
results in a lot of extra costs, is difﬁcult to manage, a license results
in technical difﬁculties and information security is also an issue.
Assessment
Initially, the assessment has been performed for the ofﬁce functions,
however there where to many differences within this group and there-
fore a smaller group was selected. This new group consisted of ﬁfty
employees of the ﬁnancial administration. It is assumed that the em-
ployees can lose the devices because they are allowed to take them
outside the hospital. The probability of misuse is assumed to be lower,
since care workers are in general not malicious intended.
Results
The questions of the assessment tool have been answered while
keeping the ﬁnancial administration in mind. In appendix C.2 the ob-
servations can be found and have been added to the beta BN (see
appendix D.5). This resulted in a data breach probability of 1,651%.
Since we performed the assessment for a group of ﬁfty employees,
the probability that at least one person within the group causes a
data breach within a year is 56,50%. Given the prior indicators of the
assessment the probability ranges from 49,80% to 85,40% depending
on which measures are taken. To decrease the probability the hospi-
tal could best take measures related to the protection of the mobile
devices themselves. Nevertheless, the ofﬁcer has only one wish to im-
prove the security of mobile devices: make it technically impossible
to download data. This, however, is very difﬁcult in practice.
Evaluation
According to the interviewee, the upper part of the organization,
i. e. the management board, is in need of insights in the current pro-
tection level of the organization. This tool could be helpful to provide
insights to them and show what measures should be taken to improve
the current situation. The data protection ofﬁcer is trying his best and
hopes he is doing the right thing, but there is not a lot of information
available to hold on to. Of course standards like NEN 7510 can be
followed, but these are not tailored to the organization or speciﬁc
situations. Additionally, all kinds of employees have a different opin-
ion about data protection. Legal advisers, for example, are especially
focusing on meeting the requirements of the law, whereas security
ofﬁcers are working towards a situation with low risks and high pro-
tection and the board wants to limit the costs. This tool can provide
additional guidance on this and provide a clear overview of what can
be done to improve the protection. It would, however, be better to
perform the assessment on a higher level and thus for bigger groups
of employees. So, instead of selecting the ﬁnancial administration as
group, selecting all administration staff. Another addition might be to
add an explanatory table to the assessment tool which describes the
risk and how much it can be reduced by taken additional measures.

8.2 gamma model
115
8.2
gamma model
The discussions with the ofﬁcers of the three hospitals and the results
of the performed assessments will be used to determine the effective-
ness of the tool and to update the beta model to the gamma model.
For this model the perspective will be the same as for the beta
model i. e. encrypted mobile device loss is not a data breach. But, we
did change the case for this model. We removed the threat of not
returning mobile devices because the device itself is not valuable to
the organization and when the device is not returned the employees
would probably misuse the data and not the device. So, the gamma
model can be used to determine the probability of a data breach
caused by employees who lose their employer- or employee-owned
mobile devices by accident or malicious employees who copy data
from employer-owned mobile devices to their own mobile devices.
8.2.1
Nodes and Values
Prior indicators
Based on the interviews it came forward that not all personal data
was stored on the devices themselves, but could be accessed via the
online hospitals environment. Since employees can access this data
using an authentication method it does not inﬂuence the probability
of mobile device misuse. However, the probability of mobile device
loss will increase when more data is stored on the devices themselves.
Therefore, we added the mediating variable Device loss level with the
states “Low”, “Medium” and “High” and the Boolean variable Sensi-
tive data stored on devices representing whether the data is actually
stored on the devices or not. The latter is also added to the data
breach assessment tool as prior indicator.
We also changed the types of the variables Mobile device misuse
and Mobile device loss. These variables are now Boolean variables
instead of ranked variables. This not only results in a simpler model
with smaller probability tables, but also makes the model more real-
istic: employees lose or misuse their devices or not.
Measures
In the model we also renamed the following variables since the
mobile device case has changed:
• Device misuse opportunity
→Data copy opportunity
• Device misuse protection level →Device copy protection level
• Data misuse protection level
→Data copy protection level
Furthermore, we removed the measure related to the reporting of
security incidents from the assessment tool because this must always
be done in health care organization. Therefore, we also changed the
node Organization protection level in the model to Awareness level.
Assessment tool

116
gamma model
While performing the assessment in the three hospitals we ﬁgured
out that the ofﬁcers do not always know for sure which (detailed)
measures are taken. To deal with this we added the option to answer
the question with unknown. Now, the protection levels are calculated
by summing up the taken measures and adding the “do not know”
option times a half. This score is divided by three and the correct level
will be selected using this score. In addition to this, it is also possible
to perform the assessment twice: once for this measure is taken and
once for this measure is not taken. This, however, might result in a
lot of assessments as all combinations of answers must be assessed.
Whereas it was even harder for the interviewees to answer the ques-
tions about the prior indicators we considered a “do not know” op-
tion here as well. However, we did not add this to the model because
the model needs a basic situation to determine the probability of a
data breach.
In the tool the measures for misuse did not change because they
can also be used to protect against data copying. Finally, we added
comment ﬁelds which might be useful when the assessment are per-
formed on a regular basis and the results must be compared with
each other. Appendix D.3 explains where the updated data breach
assessment tool can be found.
8.2.2
Structure
In ﬁgure 43 the gamma BN structure is shown. This model captures
the name changes as mentioned above and the addition of the vari-
ables Device loss level and Sensitive data stored on devices.
While we performed the assessments for the three hospitals we dis-
covered that the variables policy protection level and pre-employment
screening level have a larger impact on the data breach variable than
all other measure variables. This is because they are placed on a lower
layer of the model and therefore always have a larger impact. To
change this impact the variables are placed higher in the model. Pol-
icy protection level now impacts the Reason strength. Pre-employment
screening would affect the Attitude towards work, however this change
has a side effect which can be solved by adding a mediating vari-
able. When Pre-employment management level inﬂuences Attitude
towards work it is does not have an effect if for both types of nodes
observations are added to the model. Since both variables can be ob-
served a ranked mediating variable called Attitude level has been
added. The same has been be done for Group state for which the
ranked variable Group state level has been added. Therefore, we also
added Group state to the assessment tool. Since the number of par-
ents to Motivation level became one after the structure change, we
removed that variable.

8.2 gamma model
117
Device loss 
opportunity
- Low
- Medium
- High
Employer-
owned devices
- N
- P
- P + S
Employee-
owned devices
- N
- P
- P + S
Capability
- Low
- Medium
- High
Job type
- Care workers
- Support
- Technical
  support
Skills
- Low
- Medium
- High
Motivation
- Low
- Medium
- High
Reason 
strength
- Low
- Medium
- High
Attitude level
- Low
- Medium
- High
Group state 
level
- Low
- Medium
- High
Revenge
- False
- True
Financial
- False
- True
Mobile device 
misuse
- Low
- Medium
- High
Mobile device 
loss
- Low
- Medium
- High
Data breach
- False
- True
Data copy 
opportunity
- Low
- Medium
- High
Employer-
owned pro-
tection level
- Low
- Medium
- High
Awareness 
level
- Low
- Medium
- High
Employee-
owned pro-
tection level
- Low
- Medium
- High
Data loss 
protection 
level
- Low
- Medium
- High
Copy 
protection 
level
- Low
- Medium
- High
Device loss 
protection 
level
- Low
- Medium
- High
Data copy 
protection 
level
- Low
- Medium
- High
Security 
training level
- Low
- Medium
- High
Policy 
protection 
level
- Low
- Medium
- High
Performance 
management 
level
- Low
- Medium
- High
Pre-
employment 
screening level
- Low
- Medium
- High
Gender 
(soft evidence)
- Male
- Female
Stress level
- Low
- Medium
- High
Legend
Basis variables
Prior indicator 
variables
Measure 
variables
Sensitive data 
stored on 
devices
- False
- True
Device loss 
level
- Low
- Medium
- High
Group state
- Negative
- Neutral
- Positive
Attitude 
towards work
- Actively un-
  committed
- Not com-
  mitted
- Committed
Figure 43: Gamma model structure.

118
gamma model
8.2.3
Probabilities
We already discussed that it is really hard to ﬁll the CPTs of the BN
and that most of the values are based on common sense, therefore
we will not ﬁll them for the gamma model. Therefore, we will neither
perform sensitivity analyses for this model.
8.3
discussion
In this chapter we updated to beta Bayesian network to the gamma
BN. Since ﬁlling the CPTs is really hard and limited information is
available. We decided not to change the tables of the variables again.
Before the model can be used in practice the exact probabilities of the
tables should be determined and its correctness should be validated
i. e. is it realistic that the data breach probability is about 90% for
hospital A.
But more importantly, we investigated, in this chapter, the useful-
ness of our Bayesian network model in practice. Based on the inter-
views with the persons responsible for information security in hospi-
tals, it can be concluded that hospitals face multiple threats related
to personal data. Those threats are not only caused by malicious in-
siders or insider who make mistakes, but also by malicious outsiders
who want to harm the organization. Our Bayesian network model and
the data breach assessment tool provide guidance in what measures
should be taken against a speciﬁc threat and calculates the current
data breach probability for a group of employees. The combination
of those two tools have a good potential, but can be improved by
making it easier for participants to identify the states of the prior in-
dicators. Another addition might be to add an explanatory table to
the assessment tool which describes the data breach probability and
how much it can be reduced by implementing additional measures.
Finally, the tool can be extended to also take other threats, parts of
the organization into account.

9
G E N E R A L M O D E L
In the previous chapters we created a Bayesian network to predict
the probability of a data breach caused by a group of insiders who
misuse or lose mobile devices. Since health care organizations face
multiple threats we will, in this chapter, create a model structure that
can be adjusted to these threats (see section 9.1). The points to take
into account while extending and applying this model structure will
be discussed in section 9.2.
9.1
basic bayesian network model
The previous chapter showed that our Bayesian network model has a
good potential in combination with the designed assessment tool. We
did, however, only show this for one case: the mobile device case. But,
the hospitals face other threats, such as suppliers and personal data
exchange with external parties, as well. To represent these threats in
the model we created a basic Bayesian network structure that can be
tailored to the speciﬁc threat. This basic, not case-speciﬁc Bayesian
network is based on the ﬁrst conceptual model of chapter 5 and the
Bayesian network structure we identiﬁed for the mobile device case.
9.1.1
Nodes and Values
Basis
The variables we have identiﬁed before can also be used for this gen-
eral model. First of all, we are interested in the data breach proba-
bility and therefore the Boolean Data breach variable is the problem
variable. A data breach can be caused by insiders who have malicious
intentions or make mistakes. Their actions are represented by the vari-
ables Malicious action and a Accidental action. For our mobile device
case model we chose a case with two types of malicious actions, how-
ever it turned out that the model would be more useful with only one
malicious and one accidental action. Therefore, those actions must be
as simple as possible to avoid model complexity. Since an action takes
place or not we changed the states of both variables to “False” and
“True”.
Prior indicators
For both actions an opportunity is needed. But, since the prior indi-
cators and measures might differ for both types, we suggest to create
two separate nodes: Malicious opportunity and Accident opportunity.
Additionally, a malicious insider has a motivation to perform an at-
tack and needs certain skills to perform the attack. Those elements
are captured in the variables Motivation and Capability. Since an ac-
119

120
general model
cidental insider does not have an intention to perform an attack, the
node Motivation is not relevant for the accidental threat. Capability,
however, is relevant since an accident is more likely to occur when
the insider has is a lack of capability.
Measures
The measures in the model are not changed compared to the ﬁrst
conceptual model as designed in chapter 5. We, therefore, will only
shorty describe their purpose again. The procedural measures are
focused on decreasing the motivation and capability of the group
of insiders and consist mostly of policies, procedures and training.
However, there are also procedural measures that could be used to
decrease the opportunity to perform an attack. This kind of mea-
sures will be called Awareness measures. Awareness training and
clean desk policies are examples of such measures, since they does
not increase the motivation or capability of insiders to perform an
attack. Additionally, the technical measures automate protection and
enforce security using a technical method such as encryption. Finally,
physical measures control the physical environment and an example
of such a measure is a laptop lock.
node
type
values
Basis
Data Breach
Boolean
{False, True}
Malicious action
Boolean
{False, True}
Accidental action
Boolean
{False, True}
Prior indicators
Motivation
Ranked
{Low, Medium, High}
Capability
Ranked
{Low, Medium, High}
Attack opportunity
Ranked
{Low, Medium, High}
Accident opportunity
Ranked
{Low, Medium, High}
Measures
Protection level
Ranked
{Low, Medium, High}
Physical measures
Boolean
{False, True}
Technical measures
Boolean
{False, True}
Procedural measures
Boolean
{False, True}
Awareness measures
Boolean
{False, True}
Table 23: General model: nodes and values.

9.2 discussion
121
9.1.2
Structure
Figure 44 shows the model structure in which the nodes described
above are linked together. The only change in the structure compared
to the ﬁrst conceptual model is the addition of a second opportunity
variables which results in additional relationships.
Figure 44: General Bayesian network model.
9.2
discussion
In this chapter we showed a general applicable Bayesian network
structure. This model can be expanded with multiple speciﬁc prior
indicators and measures to capture different threats. Therefore, the
names of the action variables have to be changed to speciﬁc threat
actions and the prior indicators and measures should be extended.
While expanding the variables it should be known what information
is available to ﬁll the Conditional Probability Tables (CPTs) and what
information can be gathered from the health care organization as ob-
servations.
The designer should take the number of states per variable into
account while extending the structure. It is recommended to limit this
to ﬁve, but when there is limited data to ﬁll the CPTs three might be
even better. Furthermore, the number of parents per variable should
be limited to three, otherwise it will be too hard to ﬁll the CPTs.
We already explained, in chapter 8, that it is known that the nodes
in the top of the network have a smaller effect on the data breach prob-
ability than the ones on the bottom. Therefore, the location of the vari-
ables should be identiﬁed carefully while creating the model struc-
Motivation
Capability
Malicious 
opportunity
Accidental 
action
Data breach
Technical 
measures
Procedural 
measures
Physical 
measures
- False
- True
- Low
- Medium
- High
- False
- True
- False
- True
- False
- True
- False
- True
Malicious 
action
- False
- True
Protection level
- Low
- Medium
- High
- Low
- Medium
- High
Awareness 
measures
- False
- True
Accident 
opportunity
- Low
- Medium
- High
- Low
- Medium
- High
Legend
Basis variables
Prior indicator 
variables
Measure 
variables

122
general model
ture. Sensitivity analyses, which we explained in chapter 6, might be
a good method to support this.
Because this model is very generic, we believe it can be used for or-
ganizations in other sectors as well. To specify this model to a speciﬁc
sector, characteristics of the sector, e. g. type of employees working in
this sector, can be used. Finally, this general model might also have
potential to predict data breaches caused by outsiders. In this case the
Accidental action and Accident opportunity variable can be removed
from the model since outsiders have malicious intentions to perform
an attack. Nevertheless, further research is needed to conﬁrm these
two options.

10
D I S C U S S I O N
The goal of this research is to create a Bayesian network to predict the
probability of a data breach caused by a group of insiders of a health care
organization given certain prior indicators and preventive measures and test
its usefulness in practice. The indicators will be related to malicious and
accidental insider threats and focus on the motivation, capability and oppor-
tunity of a group of insiders. This model can also be used to determine which
measures should be taken to minimize the probability of a data breach.
To reach this research goal we developed two research questions
with four subquestions. The challenges we faced while we were try-
ing to answer these questions are discussed in section 10.1. The ques-
tions themselves will all be answered in section 10.2, where we will
conclude our research. Finally, we will discuss our suggestions for
future work (see section 10.3).
10.1
challenges
In this section we will discuss the four main challenges we faced
while gathering information for the Bayesian network models and
creating them.
10.1.1
Variables
During this research we were interested in two types of variables:
prior indicators and measures. For the latter is was easier to gather
information, however the measures we did ﬁnd were not tailored to
the health care sector and not speciﬁcally designed for our mobile
device case. Nevertheless, we could select relevant measures from
the found information security frameworks using our own knowl-
edge. Determining the prior indicators for our model was way harder.
The indicators we did ﬁnd are related to general (malicious) insider
threats and it is not known what their effect on data breaches is. The
found indicators were not tailored to the health care sector either. In-
stead we selected general applicable indicators and made a difference
in the type of employees i. e. in the health care sector there are care
workers, support staff and technical support staff.
10.1.2
Conditional Probability Tables
Since our model can be used to determine the probability of a data
breach for one speciﬁc organization and observations will be entered,
123

124
discussion
the Conditional Probability Tables (CPTs) of the root nodes of model
were not in our interest. So, we used the default values for these vari-
ables, i. e. when there are two states both have a probability of 50%,
when there are three states they have a probability of 33%. Filling
the CPTs for the other nodes turned out to be quite hard. Not only
was limited information available about what measures organizations
take. Even if we did ﬁnd the percentage in literature or reports it was,
in most cases, not tailored to the health care sector or to the mobile de-
vice case. On the internet we also found multiple freely available data
breach databases. However, these databases are not detailed enough
for our research and therefore could not be used for our model. They
neither contain information about health care data breaches in the
Netherlands.
So, to ﬁll the CPTs of the alpha model we used our own knowledge
and the best way to improve these CPTs for the beta model was by us-
ing expert knowledge. The experts had difﬁculties with determining
the values as well and tried their best.
10.1.3
Model Representation
During our research we were continuously trying to limit the com-
plexity of the models. Because the model can capture only short vari-
able names it is hard to make clear in the name what is exactly meant
with the name. So, to be able to properly use a BN additional guid-
ance would be useful. We therefore created the data breach assess-
ment tool which provides additional information about the variables.
Furthermore, it is recommended to limit the number of parents of a
node to three. Our three models do, however, contain variables with
four parents. It directly turned out that it was way harder to ﬁll the
probability tables of these nodes. Another suggestion we followed
was to limit the number of states to a maximum of ﬁve. For our mod-
els we actually limited the number to three. The smaller the number
of states the easier to ﬁll the CPT, but also the lower the accuracy of
the model. Therefore, the model builder should weigh the pros and
cons to determine the maximum for their model. To limit the number
of variables in the model we did not add each measure separately,
but combined them in groups of variables. In the models each group
of measures is represented by protection level variables and the states
of these variables can be determined by performing the data breach
assessment using the created tool.
10.1.4
Ethics
Employee monitoring is a challenges for organizations and an in-
formed decision should be made on this. Organizations are not al-
lowed to monitor their employees without a legitimate purpose, be-

10.2 conclusion
125
cause the requirements of the Dutch data protection act must be met.
Security risks, however, can be a legitimate purpose and only mea-
sures can be taken that serve this purpose. Employers may create
rules regarding the use of mobile devices and check whether the em-
ployees follow those rules. But, they should also take the right to
privacy of the employees into account. The employer may limit the
use of mobile devices, but those limits may not result in an abso-
lute competence on individual monitoring. To avoid the difﬁculties
of individual monitoring we decided to determine the probability of
a data breach for a group of employees and select prior indicators
that are focused on groups as well. This does not conﬂict with the
Dutch data protection act since this law is only applicable when data
of individual users is recorded and made available to the employer.
Nevertheless, it wisely to inform the employees about unusual meth-
ods of monitoring.
10.2
conclusion
To be able to reach the research goal, the two main research question
How can Bayesian networks be used to determine the probability of a data
breach in a health care organization caused by an insider? and How useful
are Bayesian networks to predict data breaches in real world health care
organizations? needed to be answered. Before the ﬁrst question could
be answered, four subquestions needed to be answered. The answers
to each of the questions will be discussed below.
10.2.1
Prior Indicators
The ﬁrst knowledge question, which indicators related to insider motiva-
tion, capability and opportunity can be used to predict a data breach in a
health care organization?, was answered using a literature study. An in-
sider in the context of this research is an employee who is authorized
to process physical and/or digital personal data and is a threat when
he is likely to use his privileged access to intentionally or accidentally
perform an act directly or indirectly leading to unlawful processing
of personal data.
We discussed ﬁve crime theories that can be used to characterize
the insider threat. These threats are a risk for organizations and can
be calculated by risk = threat × vulnerability × consequence. In
our model we use Motivation and Capability of an insider to repre-
sent the threat and Opportunity to represent the vulnerability. The
latter therewith focus on the defender and the ﬁrst two variables on
the offender. Note that our model does not capture the consequences
of a data breach since we are not interested in the impact. These three
elements can be extended with behavioral (e. g. stress), technical (e. g.

126
discussion
installing hacker tools) and organizational (e. g. policy violations) in-
dicators of insider threats.
10.2.2
Measures
To answer our second knowledge question, which preventive measures
decrease the probability of a data breach in a health care sector?, we per-
formed a study as well. During this study we searched for measures
that can successfully counter insider accidents or malicious insider at-
tacks, reduce risk, resolve vulnerabilities and otherwise improve the
protection of personal data within an organization. The Dutch law
does not provide speciﬁc information on what measures should be
taken by organization to protect against data breaches. The guide-
lines of the Dutch data protection act refer to the national standards
which are based on the international ISO standards. These standards
provide general measures that could be taken to improve the informa-
tion security within (health care) organizations. However, since every
organization is different organizations must determine by themselves
how the measures must be implemented and tailored to their environ-
ment. We also discussed four frameworks that can be used to deter-
mine measures to protection information, but these are not tailored
to the health care sector.
In general to increase the protection level of the organization a com-
bination of technical, procedural and physical measures should be
taken. These types of measures have also been included in the model
for the mobile device case.
10.2.3
Causal Relationships
The third question, what are the causal relationships between an indica-
tor, measure and data breach, the identiﬁed the basic structure of the
model. Bayesian networks can be used to predict the probability of
a data breach, but also to detect a data breach. Our research focuses
on prediction, but also showed how the BN can be extended to in-
clude the possibility for detection. A BN in general consists of back-
ground, problem, mediating and symptom variables. In our case the
measures and prior indicators are background variables and can be
used to determine whether a data breach is likely to occur or not.
The data breach variable is the problem variable and its probability is
predicted used the model. Symptom variables can be used for detec-
tion and are not included in our model. An example related to data
breaches is an indicator such as “USB stick found” that shows a data
breach has possibly occurred. Finally, it is important to keep in mind
that the shorter the path from a variable to the problem variable, the
higher the impact on the problem will be.

10.2 conclusion
127
10.2.4
Impacts
Answering the fourth question, how are indicators and measures related
to the probability of a data breach?, turned out to be quite hard as we
already discussed in section 10.1.2. The model consists of variables
which are inﬂuencing each other. All variables except for the root
variables have one to four parents with all two or three states. For
each of those combinations the impacts was determined using our
own and expert knowledge. In general the indicators increase the
probability of a data breach and by taking measures this probability
will decrease. Too improve the CPTs it might be better for the future
research to include more security and privacy experts and possibly
also crime and behavior experts. Another option might be to collect
data to ﬁll the CPTs as discussed in 10.3.
10.2.5
Conclusion
Using the previous four research questions our ﬁrst main question,
how can Bayesian networks be used to determine the probability of a data
breach in a health care organization caused by an insider? can be answered.
Even though we faced multiple challenges while performing this re-
search and creating the BNs as discussed in section 10.1. We did show
that it is possible to use Bayesian networks to visualize the causal re-
lations between prior indicators of a malicious and accident insider
threat and the measures to avoid data breaches.
Whether it is possible to predict the data breach probability for
speciﬁc threats is not that clear. We used our own common sense
and that of experts to ﬁll the CPTs since there was limited informa-
tion available. The experts experienced difﬁculties when ﬁlling the
tables and were not sure about the correctness either. Even though
we cannot guarantee that the data breach probability of the model is
realistic, it is possible to determine which measures should be taken
to lower the data breach probability. This can be done by investigat-
ing the relative difference between multiple situations, whereby the
prior indicators do not change, and the most optimal combination of
measures is determined. When more data becomes available about
the impact of the relations between a data breach, prior indicator and
measure, the model could also be used to predict a more exact data
breach probability for a speciﬁc situation.
The second research question, how useful are Bayesian networks to
predict data breaches in real world health care organization?, was created
to determine the usefulness of BNs in practice. It turned out that
the BN does have potential, but should be used in combination with
the assessment tool. The tool does provide a clear oversight of the
current measures implemented in the organization and the improve-
ments that could be done and allows the user to control the situation

128
discussion
and consciously decide what actions should be taken. Since it is dif-
ﬁcult to focus on speciﬁc individuals, the possibility to use the tool
for different group sizes is a good addition. The only requirements
for the group is that they all should have access to the same type of
data and that they have access to the same personal data with the
mobile devices. Users of the tool would probable the management
board of the hospital, but also legal advisers and security ofﬁcers
and other employees responsible for information security. Possible
improvements of the tool are linking the prior indicators to the sur-
vey satisfaction survey or have discussions with the employees do
determine the states of the prior indicators. Another addition might
be to add an explanatory table to the assessment tool which describes
the risk and how much it can be reduced by taking additional mea-
sures. Finally, the tool can be extended to also take other threats, parts
of the organization into account.
10.3
future work
Even though we stated at the beginning of our research that the
standard BN could be extended to a Multi-Entity Bayesian Network
(MEBN) or Dynamic Bayesian Network (DBN), we do not suggest this
as future work. At this stage it is more important to identify methods
that can be used to gather data to ﬁll the conditional probability tables
of the variables. For this, the effects of the measures on prior indica-
tors and data breaches must be investigated. It might, for example, be
an option to monitor hospitals and investigate the security incidents
and data breaches they face. This might be a challenge, since permis-
sion of hospitals is needed for this, secrecy of information must be
taken into account and because of law and ethical reasons it is not
always possible to monitor the behavior of the employees.
Another improvement would be the calculation of the data breach
assessment tool. The tool now calculates the protection level scores by
dividing the number of taken measures by three and selecting the cor-
responding protection level, i. e. “Low”, “Medium” or “High”. This
calculation can be improved by weighing the measures and increas-
ing the number of ranked states to ﬁve. Since increasing the number
of states increases the complexity of the CPTs, it will be helpful if the
gathered data could be automatically entered in the tables.

A
P R E L I M I N A R I E S
In order to understand Bayesian Networks (BNs) it is important to
have a basic knowledge on Directed Acyclic Graphs (DAGs) since
these are the basis of a Bayesian networks (see section A.1). Because
probabilities will be added to the graph, probability theory is dis-
cussed in section A.2. Both subjects are explained using deﬁnitions,
examples and other information from Neapolitan [52].
a.1
directed acyclic graphs
Directed graph
A directed graph is a set of vertices (V) connected by edges (E),
whereby the edges have a direction associated with them. More for-
mally, a directed graph is a pair (V,E) where V is a ﬁnite, nonempty
set and E is a set of ordered pairs of distinct elements of V and if
(A,B) ∈E, there is an edge from A to B.
Figure 45a shows an example of a directed graph, whereby the set
of vertices and edges is as follows:
• V = {A, B, C, D}
• E = {(A,B), (A,C), (B,D), (C,B), (D,C)}
(a) Directed graph with cycle.
(b) Directed acyclic graph.
Figure 45: Directed graphs.
Directed acyclic
graph
Within a directed graph paths, chains and cycles can be distin-
guished. A path in a directed graph is a sequence of nodes [X1, X2,
. . . , Xk] such that (Xi−1, Xi) ∈E for 2 ⩽i ⩽k. An example of a path
in ﬁgure 45a is: [A, B, D, C]. A chain in a directed graph is a sequence
of nodes [X1, X2, . . . , Xk] such that (Xi−1, Xi) ∈E or (Xi, Xi−1) ∈
E for 2 ⩽i ⩽k. For example, [B, D, C, A] is a chain in the directed
graph in ﬁgure 45b, but it is not a path. In a directed graph a path
from a node to itself is called a cycle. Figure 45a contains a cycle from
129
A
B
C
D
A
B
C
D

130
preliminaries
B to B: [B, D, C, B]. This order, however, is not a cycle in ﬁgure 45b,
because it is not a path. Such a directed graph without cycles is called
a Directed Acyclic Graph (DAG).
Parent, descendant
and non-descendant
When assuming a DAG with two vertices X and Y i. e. DAG G =
(V,E) and V = {X,Y}, the following deﬁnitions can be established:
• Y is the parent of X if there is an edge from Y to X.
• Y is a descendant of X and X is an ancestor of Y if there is a
path from X to Y.
• Y is a non-descendant of X if Y is not a descendant of X and Y
is not a parent of X.
example
To explain those deﬁnitions with additional clarity the
graph shown in ﬁgure 46 will be used. In this ﬁgure Y is the par-
ent of X and Z since there is an edge from Y to X and from Y to Z.
Furthermore, X and Z are descendants of Y, because there is a path
from Y to X and Y to Z. The other way around: Y is an ancestor of
X and Z, because there is a path from Y to X and Y to Z. Finally, Z
is a non-descendant of X and X is a non-descendant of Z. This can
be explained as follows: X does not have descendants, because it is
not a parent of another node and the parent of X is Y, so the remain-
ing nodes are the non-descendants of X. In this case the remaining
node is Z and thus a non-descendant of X. For node X being a non-
descendant of Z the same reasoning can be applied.
Y
X
Z
Figure 46: Graph to explain the deﬁnition of parent, descendant, ancestor
and non-descendant.
a.2
probability theory
This section starts with the explanation of basic probability theory
terms (see section A.2.1). Each of those terms is explained and clari-
ﬁed by examples. In section A.2.2 the terms related to random vari-
ables are described and explained together with examples.
a.2.1
Basics
Basic probability
theory terms
Probability theory is about experiments (e. g. drawing the top card
from a deck of playing cards or tossing a coin) that have a set of
distinct outcomes. The set of all outcomes is deﬁned as the sample

A.2 probability theory
131
space and any subset of the sample space is an event meaning that one
of the elements of the subset is the outcome of the experiment. When
there is only one element in the subset it is called an elementary event.
The certainty that an event contains the outcome of the experiment
is called the probability of the event and is denoted with a real number
between 0 and 1, e. g. P(E) = 0.5 means the probability of event E is
0.5.
example
Assume the following experiment for all examples un-
less mentioned otherwise: draw the top card from a deck of playing
cards. Based on this, examples for the deﬁnitions as described above
are:
• Sample space: all 52 cards in the set.
• Event: E = {JackofHearts, QueenofHearts, KingofHearts}.
• Elementary event: F = {JackofHearts}.
• Probability: the probability of drawing the card jack of hearts:
P(JackofHearts) = 1/52.
Probability function
When assuming a sample space Ωcontaining n distinct elements:
Ω= {e1, e2, . . . , en}, then a function that assigns a real number P(E)
to each event E ⊆Ωis called a probability function on the set of
subsets of Ωif it satisﬁes the following conditions:
1. 0 ⩽P(ei) ⩽1
for 1 ⩽i ⩽n;
2. P(e1) + P(e2) + · · · + P(en) = 1;
3. For each event that is not an elementary event P(E) is the sum
of the probabilities of the elementary events whose outcomes
are in E.
Probability space
Additionally, the pair (Ω, P) is called the probability space and for
this pair the following holds:
1. P(Ω) = 1;
2. 0 ⩽P(E) ⩽1;
3. For every two subsets E and F of Ωsuch that E ∩F = ∅,
P(E ∪F) = P(E) + P(F), where ∅denotes the empty set.
example
When drawing the top card from a deck of playing cards
the sample space Ωcontains all 52 cards, whereby P(Ω) = 1. Since
each card has the same probability of being drawn the probability
of a speciﬁc card being drawn is 1/52, i. e. P(card) = 1/52 for each
card ∈Ω. Using this information the probability of a certain event E
can be calculated as follows:

132
preliminaries
• E = {JackofHearts, QueenofHearts, KingofHearts}
• P(E) = P(JackofHearts) + P(QueenofHearts) +
P(KingofHearts) = 1
52 + 1
52 + 1
52 = 3
52
This calculation is performed using only one subset of Ω, i. e. one
event. Additionally, the probability of two subsets of Ωcan be calcu-
lated as well as described above. An example of the calculation with
the two events Ace (A) and Jack (J) is:
• A = {AceofHearts, AceofSpades, AceofDiamonds,
AceofClubs}
• J = {JackofHearts, JackofSpades, JackofDiamonds,
JackofClubs}
• A and J are subsets of Ωand A ∩J = ∅, thus:
• P(A ∪J) = P(A) + P(J) = 1
13 + 1
13 = 2
13
Conditional
probability
Until now, only unconditional probabilities have been explained,
however the probability of an event E can also be determined given
another event F. This is called the conditional probability and denoted
as P(E|F). More formally, it can be deﬁned as follows: let E and F be
events such that P(F) ̸= 0, then the conditional probability of E given
F is given by:
P(E|F) = P(E ∩F)
P(F)
Now, let n be the number of items in the sample space, nF the
number of items in F and nE∩F the number of items in E ∩F, then the
formula can be circumscribed to:
P(E ∩F)
P(F)
=
nE∩F
n
nF
n
= nE∩F
nF
To explain the function more intuitive, assume the situation as de-
scribed in ﬁgure 47a. The sample space Ωcontains all possible out-
comes and E and F are two events in this sample space. As we know
that event F has occurred, every outcome outside F should be dis-
carded. This results in a new sample space of set F. Because we want
that event E happens as well, the outcome should belong to the set
E ∩F. To ensure that the new sample space becomes 1, P(E ∩F) will
be divided by P(F). Furthermore, since there is no conditional proba-
bility of P(E|F) if P(F) = 0, i. e. event F never occurs, it makes no sense
to calculate the probability of E given F and therefore the following
must hold: P(F) > 0.

A.2 probability theory
133
E
F
E   F
(a) Abstract diagram for the calculation
of P(E|F).
A
3
H
12
A   H
1
(b) Example for the card game, P(A|H).
Figure 47: Venn diagrams for conditional probability.
example
Now, lets explain the calculation of the probability of
drawing an ace given that the suit will be hearts. To visualize this
situation a Venn diagram is given in ﬁgure 47b. This diagram is based
on the sample space Ωwith all 52 cards and two events Ace (A) and
Hearts (H) with 4 and 13 elements respectively:
• A = {AceofHearts, AceofSpades, AceofDiamonds,
AceofClubs}
• H = {2, 3, 4, 5, 6, 7, 8, 9, 10, Jack, Queen, King, Ace}
Since we know that event H has occurred the denominator P(H)
is 13 or more speciﬁc the number of cards in H divided by the total
number of cards (Ω): 13/52. Because we are only interested in the
cases in which a card is drawn from set A as well, i. e. the card with
an ace and a heart, we would like to know P(A ∩H). In this example
the only card that fulﬁlls this requirement is the ace of hearts card
and therefore the nominator P(A|H) is 1 or more comprehensive: 1/52.
This results in the following calculation of drawing an ace given that
the suit will be hearts:
P(A|H) = P(A ∩H)
P(H)
= 1
13, which is the same as:
1
52
13
52
Independence
Furthermore, two events E and F are independent of each other if
one of the following holds:
1. P(E|F) = P(E) and P(E) ̸= 0, P(F) ̸= 0;
2. P(E) = 0 or P(F) = 0.
Conditional
independence
Next to independence between two events, two events E and F are
conditionally independent given G if P(G) ̸= 0 and one of the follow-
ing holds:

134
preliminaries
1. P(E|F∩G) = P(E|G) and P(E|G) ̸= 0, P(F|G) ̸= 0, whereby P(E|F∩
G) is the probability of E given both F and G;
2. P(E|G) = 0 or P(F|G) = 0.
A
A
A
A
B
B
B
B
B
B
A
B
B
Figure 48: Experiment with 13 objects [52].
example
A new experiment will be introduced to explain inde-
pendence and conditional independence. Assume there are 13 objects
in two colors and with two letters: blue and white and A and B (see
ﬁgure 48). The set A contains all objects with an A on it, the set Blue
contains all blue objects and the set Square consists of all square ob-
jects. The calculations below show that the set A and Square are not
independent, since the outcome of both calculations is not the same:
• P(A) = 5
13
• P(A|Square) = 3
8
However, the sets A and Square are conditionally independent
given the set Blue, since both calculations result in the same answers:
• P(A|Blue) = 3
9 = 1
3
• P(A|Square ∩Blue) = 2
6 = 1
3
Bayes’ theorem
Finally, to calculate conditional probabilities of events of interest
from known probabilities, the Bayes’ theorem can be used as follows:
given two events E and F such that P(E) ̸= 0 and P(F) ̸= 0, the follow-
ing equation holds:
P(E|F) = P(F|E)P(E)
P(F)
This theorem can be extended to multiple events as follows: given
n mutually exclusive and exhaustive events E1, E2, . . . , En such that
P(Ei) ̸= 0 for 1 ⩽i ⩽n, then the following equation holds:
P(Ei|F) =
P(F|Ei)P(Ei)
P(F|E1)P(E1) + P(F|E2)P(E2) + · · · + P(F|En)P(En)

A.2 probability theory
135
example
The probability of drawing a card with a number lower
than 4 (so the cards with number 2 and 3) given that it will be a card
with a heart can be calculated as follows:
P(< 4|Hearts) = P(Hearts| < 4) ∗P(< 4)
P(Hearts)
=
2
8 ∗8
52
13
52
= 2
13
a.2.2
Random Variables
Random variable
and space
Given a probability space (Ω, P), a random variable X is a function
whose domain is Ω. The range of random variable X is called the
space which represents the values that X can have. For a random
variable X, X = x is used to denote the subset containing all elements
e ∈Ωthat X maps to the value of x, i. e. :
X = x represents the event{e such that X(e) = x}
Probability
distribution
Furthermore, the sum of all probabilities of the variables x in the
space of X is equal to 1. The values of P(X = x) for all values x of X
together is called the probability distribution of X, referred to as P(X).
example
Assume an experiment whereby two dices will be thrown.
Let Ωcontain all outcomes of throwing both dices and let P assign
1/36 to each outcome. This results in the following set of ordered
pairs with all a probability of 1/36:
Ω= {(1, 1), (1, 2), (1, 3), . . . , (6, 4), (6, 5), (6, 6)}
Now assume that the random variable X assigns the sum of each
ordered pair to that pair. This results in the numbers 2 to 12 (1 + 1
and 6 + 6):
the space of X is {2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}
When assigning a value to X it represents a speciﬁc event. In this
case X = 11 represents the event {(1, 5), (5, 1)} with the following prob-
ability:
(X = 11) = 2
36 = 1
18
Joint probability
distribution
Until now only the use of one random variable has been explained
in the example, but it is also possible to use two random variables.
When having two random variables X and Y deﬁned on the same
sample space Ω, X = x and Y = y are used to denote the subset
containing all elements e ∈Ωthat are mapped both by X to x and by
Y to y:
X = x, Y = y represents the event {e such that X(e) = x} ∩

136
preliminaries
{e such that Y(e) = y}
Then, the joint probability distribution of random variables X and
Y is given by: P(X = x, Y = y).
example
The dice example will now be extended with the random
variable Y. This variable assigns “odd” to each pair of odd numbers
and “even” to all pairs with at least one even number. This results in
the following space of Y: {odd,even}. We will now calculate the prob-
ability that the sum of the pair is 11 and the variables are both odd,
i. e. P(X = 11|Y = odd) whereby X = 11 given Y = odd represents the
event {(1, 5), (5, 1)}:
P(X = 11, Y = odd) = 2
36 = 1
18
Independence of
random variables
Assume a probability space (Ω, P) and two random variables X and
Y deﬁned on Ω. Then, X and Y are independent if, for all values x of
X and y of Y, the events X = x and Y = y are independent, denoted
as: Ip(X, Y).
example
Let Ωbe the set of all cards, let P assign 1/52 to each
card and assume the following two variables:
• Variable R with value r1 being all royal cards and r2 being all
non-royal cards.
• Variable S with value s1 being all hearts and s2 being all non-
hearts.
Then, R and S are independent, i. e. Ip(R,S) since P(r) = P(r|s):
• P(r1) = 12
52 = 3
13
and
P(r1|s1) = 3
13
• P(r2) = 40
52 = 10
13
and
P(r2|s1) = 10
13
• P(r1) = 12
52 = 3
13
and
P(r1|s2) = 9
39 = 3
13
• P(r2) = 40
52 = 10
13
and
P(r2|s2) = 30
39 = 10
13
Conditional
independence of
random variables
Now assume, as addition to random variables X and Y, the random
variable Z deﬁned on Ω. Then, X and Y are conditionally independent
given Z if, for all values x of X, y of Y, and z of Z, whenever P(z) ̸= 0,
the events X = x and Y = y are conditionally independent given the
event Z = z, denoted as: Ip(X, Y|Z).

A.2 probability theory
137
example
Let Ωbe the set of all 13 objects in ﬁgure 48 (as used
before), let P assign 1/13 to each object and assume the following
random variables:
• Variable L for letter with value l1 being all objects containing an
A and l2 being all objects containing a B.
• Variable S for shape with value s1 being all square objects and
s2 being all circular objects.
• Variable C for color with value c1 being all blue objects and c2
being all white objects.
Then, L and S are conditionally independent given C, i. e. Ip(L, S|C),
since P(l|s, c) = P(l|c) for all values of l, s and c. This will be shown
for l1, s1 and c1, for the other values the calculation should be per-
formed the same way:
• P(l1|c1) = 3
9 = 1
3
and
P(l1|s1, c1) = 2
6 = 1
3


B
I N F O R M AT I O N G AT H E R I N G F O R B E TA M O D E L
This appendix contains information related to the information gath-
ering process for the beta model. In section B.1 the questions of the
survey can be found and in section B.2 the results of the focus group
session are provided.
b.1
survey
In this section the survey that was shared with privacy and security
consultants and cyber security master students can be found. The
survey consists of two parts: general questions and mobile device
case related questions.
b.1.1
Introduction
The last three months I have been working on a model to predict the
probability of a data breach caused by insiders of a health care orga-
nization. Since a lot of sensitive data is processed in the health care
sector I selected this sector as focus for my model. The focus on insid-
ers was chosen because malicious insider threats are described as the
most serious security problem for organizations in many researches.
These threats are hard to mitigate since insiders have information and
capabilities not known to other (external) attackers. Nevertheless, er-
rors by insiders occur as well which also might result in data loss.
With this form I would like to receive your opinion about factors
that inﬂuence the probability of a data breach caused by insiders. To
keep my model compact it is based on a speciﬁc case which will be
described in the next section.
Filling in the form costs at least ﬁve minutes, but spending more
time on answering the questions will be appreciated. Your participa-
tion in this research is anonymous.
Thank you for your participation!
general questions
1. What is your gender?
2. What is your age?
3. What is your job title/study?
4. Is your work/study related to cyber security?
139

140
information gathering for beta model
5. Is your work/study related to privacy?
b.1.2
Case
I will ask you some questions about the case described below. Please
read it carefully and answer the questions afterwards. There are no
correct or incorrect answers, so it would be really helpful if you write
down as many answers as possible.
case description
We would like to determine the probability
of a data breach caused by a group of employees of a health care
organization. This data breach can be caused in only two ways:
1. Employees lose mobile devices they use for work purposes, i.e.
owned by their employer, by themselves or both;
2. Employees misuse employer-owned mobile devices by not re-
turning them when needed (e.g. if their employment ends) or
by copying personal data to their own devices.
Examples of mobile devices are:
• Laptops
• Smart phones
• PDAs
• Tablets
You will be asked for factors that can be used to predict the prob-
ability of a data breach and to describe multiple measures organi-
zations can take to avoid data breaches. Please be precise and think
about different types of measures:
• Physical measures (e.g. lock on the door)
• Technical measures (e.g. encryption)
• Procedural measures (e.g. bring your own device policies)
case questions
1. Why would employees of a health care organization not return
the mobile devices their employer owns when they are required
to do so?
2. Why would employees of a health care organization copy per-
sonal data from the mobile devices owned by their employer to
their own device?

B.2 focus group results
141
3. What can health care organizations do to change or lower the
motivation of an insider to misuse mobile devices? (not return-
ing them when needed or copying personal data to their own
devices)
4. Which skills or resources do employees of a health care orga-
nization need to misuse mobile devices? (not returning them
when needed or copying personal data to their own devices)
5. Which skills or resources are lacking when employees of a health
care organization lose mobile devices?
6. Which measures can health care organizations take to improve
the skills of their employees?
7. Which factors are indicators that employees are likely to lose
mobile devices?
8. Which measures can health care organizations take to lower the
probability that employees misuse employer-owned devices? (not
returning them when needed or copying personal data to their
own devices)
9. Which measures can health care organizations take to lower the
probability that employees lose mobile devices?
10. Do you have any other comments or suggestions?
b.2
focus group results
In this section we will provide the results of the individual assign-
ment that has been performed during this session (see section B.2.1)
and the reasoning to answer the group assignment can be found in
section B.2.2.
b.2.1
Results Individual Assignment
The results of the individual assignment of the focus group session
can be found in tables 24 and 25. Please note that the opinions of the
experts on these statements might have changed during the discus-
sions of the second assignment.
b.2.2
Reasoning
The focus group performed a group assignment after ﬁnishing the
individual assignment. During this assignment they reasoned about
the impact the variables in the alpha model have on each other. The
reasoning to achieve the answers to the questions are summarized
per Conditional Probability Table (CPT) variable.

142
information gathering for beta model
#
statement
t
f
1.
Mobile device misuse results in a data breach more of-
ten than mobile device loss
0
3
2.
Employees have a motivation to lose a mobile device
1
2
3.
The capability of the employees depend on their job
3
0
4.
Stress increases the probability of mobile device loss
1
2
5.
Females misuse mobile devices more often than males
0
3
6.
Most of the malicious employees have a strong reason
to misuse a mobile device
2
1
7.
Employees who are not committed to their job are less
likely to misuse mobile devices
0
3
8.
Care workers are more likely to lose mobile devices
than support and technical support staff
2
1
Table 24: Focus group: results individual assignment - prior indicators.
#
statement
t
f
1.
Protection against mobile device misuse is just as im-
portant as protection against mobile device loss
2
1
2.
Training the employees is less important than protect-
ing the mobile devices
1
2
3.
Pre-employment screening is more important than per-
formance management*
1
1
4.
Protecting mobile devices is less important than pro-
tecting the data on the devices
3
0
5.
Creating policies is more important than training the
employees
0
3
6.
Protection against mobile device loss is less important
than protection against mobile device misuse
0
3
7.
An awareness program is more important than protec-
tion of data on the devices
1
2
Table 25: Focus group: results individual assignment - measures.
* One participant did not know the answer
data breach
The participants stated that mobile device loss oc-
curs more often than mobile device misuse, because people make
mistakes and this happens unconsciously. This matches with their
answer that the statement “Mobile device misuse” results in a data
breach more often than Mobile device loss” is false.

B.2 focus group results
143
mobile device misuse
If employees are planning to perform a
malicious act they will have a reason to do so and with a reason they
will be able ﬁnd an opportunity to perform the act. This opportunity
is not hard to ﬁnd because employees (temporally) own the mobile
devices with personal data on it. A high capability is especially useful
if the employees want to lower the probability of detection. It is not
that hard to copy data since the employees can, for example, send an
e-mail with the data to their private account.
mobile device loss
Only one participant agreed with the fol-
lowing statement “employees have a motivation to lose a mobile de-
vice”. But, after the discussion they all agreed to the fact that people
make mistakes and are unconscious, which implies they have no mo-
tivation to lose a device.
To avoid device losses employees should be aware and keep their
mobile devices close to them. However, the probability might, for
example, also depend on the location of the employees or their sur-
roundings. The probability of mobile device loss might be, for exam-
ple, higher in New York than in Amsterdam.
motivation
We also asked the participants about the impact of
measures on the motivation of employees to misuse mobile devices.
Even tough “Performance management” does not have a direct im-
pact on the “Motivation” variable we included this variable in the list
because we were interested in which measure has the highest impact.
“Policies” have the lowest impact, because guidelines and punish-
ments do not directly make sure employees behave correctly. How-
ever, when the policies are communicated to the employees very well
they might lower the motivation to misuse mobile devices. Still, this
might depend from person to person since not everybody attaches
the same value to possible punishments.
Before the discussion there was quite some disagreement to the
answer of the related statement: “pre-employment screening is more
important than performance management”. One participant agreed,
one disagreed and the third did not know the correct answer. During
the discussion they identiﬁed that pre-employment screening is not
about behavioral changes during employment and is performed once.
Nevertheless, it does provide information to the employer about the
past that may be hidden otherwise. Since employee performance re-
views are performed on a regular basis within the organizations this
variable is a bit more important than the screening.
motivation level
Determining the impact on the “Motivation
level” variable turned out to be quite hard for the experts since they
have limited knowledge about behavioral factors. Two participants
agreed with the statement “most of the malicious employees have a

144
information gathering for beta model
strong reason to misuse a mobile device”. After the discussion they
determined that “Reason strength” has the highest impact on “Mo-
tivation level” because this is the only factor that can be inﬂuenced
consciously.
According to the participants it is harder for employees to change
the “Attitude towards work” and “Group state”. Additionally, the
participants disagreed with the following statement: “ employees who
are not committed to their job are less likely to misuse mobile devices”
and do believe that the level of commitment impacts the motivation
to misuse mobile devices. The participants suggested that it might
be a good idea to add a relation between “Group state” and “Atti-
tude towards work” because when there is a positive group state, the
group might also be more committed to their job and the organiza-
tion. Based on this the “Attitude towards work” variable will have
a higher impact than “Group state” and therefore this factor comes
second and “Group state” comes third.
Finally, all participants disagreed with the statement “ females mis-
use mobile devices more often than males”. They came up with two
reasons for this: 1) there is no difference in gender and 2) males are
more likely to commit crimes. However, after a discussion they as-
sumed that literature will show that males are more likely to com-
mit crimes than females and therefore the “Gender” does have an
inﬂuence on the motivation, but this inﬂuence is assumed to be the
smallest.
reason strength
The participants suggested to remove the “Com-
petitive advantage” variable because this is not applicable for the
health care sector, i. e. the employees are not going to leave and start
their own hospital or sell the data to their new employer. Instead they
suggested to take a look at ethical reasons to misuse mobile devices
such as someone who wants to blow a whistle.
Additionally, ﬁnancial reasons are way more likely to result in mis-
use than revenge, because money is a good driver and can be more
useful for the employees than a feeling of revenge.
capability
All participants agreed with the statement “the capa-
bility of the employees depend on their job” and two of them agreed
with the statement “care workers are more likely to lose mobile de-
vices than support and technical support staff”. After a short discus-
sion they agreed all agreed that crime and loss occurs within all layers
of the organization and thus due to all types of employees. The capa-
bility of the group should be determined on an individual level or
based on the skills the employees have.

B.2 focus group results
145
skills
For the inﬂuence of training on the skills of the employees
the reasoning was actually quite simple: there are always people who
have more or less skills than can be learned via a training.
accident opportunity
Employees do not have an emotional
connection with employer-owned devices because they did not have
to buy it themselves and there is probably no private information
stored on these devices. Based on this, it is more likely that employees
lose employer-owned mobile devices. Related to the “Stress level” we
stated that “stress increases the probability of mobile device loss”.
Only one of the participants agreed with this statement, but after
a discussion they all realized that stress does inﬂuence how often
people lose or forget their devices.
accident protection level
To avoid mobile device loss all
employees should be aware of their devices and surroundings. There-
fore, the “Organization protection level” has the highest impact on
the “Accident protection level”. This, however is not reﬂected in the
fact that only one participant agreed with the statement: “an aware-
ness program is more important than protection of data on the de-
vices”. This might be due to the idea that for loss awareness is impor-
tant, but for misuse it is not.
All participants agreed that “protecting mobile devices is less im-
portant than protecting the data on the devices” and based on this
the participants decided that “Data accident protection level” has the
second highest impact. Furthermore, the assumption is made that
employee-owned mobile devices are protected in the same way as
employer-owned and therefore the protection of the latter is more
important.
attack protection level
All participants all agreed that “pro-
tecting mobile devices is less important than protecting the data on
the devices”. They see both elements as equally important. Further-
more, the awareness within the organization does not change the mo-
tivation of a malicious employee, therefore the organization has to
make sure that it is difﬁcult or technical impossible to misuse mobile
devices.


C
I N F O R M AT I O N G AT H E R I N G F O R G A M M A M O D E L
In this chapter we provide the interview questions we used to gather
information for the gamma model (see section C.1). During the ses-
sion in the three hospitals we also performed data breach assessments
of which the results can be found in section C.2.
c.1
interview questions
The questions below were asked during the interview sessions in the
three hospitals. Before we performed the assessment and asked the
questions related to this we explained the mobile device case.
general
• What is your function within the hospital?
• How many years of experience do you have with privacy?
• How many years of experience do you have with privacy in the
health care sector?
• How many years of experience do you have with information
security?
• How many years of experience do you have with information
security in the health care sector?
threats
• What are the three largest personal data threats the hospital
faces?
• What is a larger personal data breach for the hospital: autho-
rized or unauthorized persons? Why?
• what is a larger personal data breach for the hospital: employees
who make mistakes or employees who maliciously misuse their
privilege? Why?
• Which personal data threat has at this moment the highest pri-
ority within the hospital?
147

148
information gathering for gamma model
prior indicators
• Which speciﬁc methods are used within the organization to
identify risk factors of a data breach before it occurs?
• Do you watch/monitor behavioral changes among employees
to lower the probability on a data breach?
measures
• What methods are being used to determine which measures
should be taken to protect the hospital against employees who
cause data breaches by making mistakes or who have malicious
intentions?
• What difﬁculties do you experience while determining which
measures should be taken to protect the organization against
data breaches?
• How do you determine to what extent employees can be trusted
with personal data?
case
• Are mobile devices used by employees within the hospital?
• Which mobile devices are owned by the hospital?
• Does the hospital have a bring your own device policy? Why?
• Which mobile devices can the employees bring themselves?
• How do you determine which mobile devices are allowed for
business purposes?
assessment
• For which group of employees do you want to perform the as-
sessment?
• How many employees are in this group?
• How often per year does a data breach caused by this group
occur when taking mobile device loss into account?
• How often per year does a data breach caused by this group
occur when taking mobile device misuse into account?
• What measures do you still want to take to limit the probability
of a data breach caused by mobile device misuse and loss?

C.2 observations hospital assessments
149
evaluation
• Would you use this tool to determine which measures should
be taken to limit the probability of a data breach? Why?
• What are the strong points of this tool? Why?
• What suggestions do you have to improve this tool?
c.2
observations hospital assessments
After the interview we performed the data breach assessment to-
gether with the interviewees. The ﬁnal observations for each hospital
are also shown in table 26.

150
information gathering for gamma model
node
hospital a
hospital b
hospital c
Motivation
Financial
False
False
False
Revenge
False
False
False
Gender
-
Male
0,5
0,6
0,5
-
Female
0,5
0,4
0,5
Attitude towards work
Committed
Committed
Committed
Policy protection level
High
High
High
Pre-employment screening level
Medium
Medium
High
Performance management level
Medium
Medium
Medium
Capability
Job type
Care workers
Care workers
Support
Security training level
Low
High
Medium
Opportunity
Stress level
Low
Medium
Low
Employer-owned devices
P+S
P+S
P+S
Employee-owned devices
P+S
P+S
N
Organization protection level
Medium
High
High
Employer-owned protection level
Medium
Medium
Medium
Employee-owned protection level
Low
Low
High
Data attack protection level
High
High
Medium
Data accident protection level
High
High
High
Table 26: Observations for hospital A, B and C.

D
M AT E R I A L S
The materials of this research are stored online such that they can be
accessed any time. Below we explain how each document is called
and how they can be opened. The link to the materials is:
http://doi.org/10.4121/uuid:
c637245d-93fb-4cee-8f4a-9b5fa14d5513
d.1
focus group session
The presentation we showed to the security and privacy experts con-
sists of a research description and an explanation of the assignments.
This document is called:
• Focus Group - Presentation.pdf
In addition to this, we used a form to gather the demographics of
the security and privacy experts, which is called:
• Focus Group - Demographics.pdf
d.2
data breach prediction models
The alpha and beta Bayesian network were created using the tool Age-
narisk (paid version). To open the models the tool should be installed.
The ﬁles are called:
• Alpha Bayesian Network.cmp
• Beta Bayesian Network.cmp
d.3
data breach assessment tools
The data breach assessment tools for the alpha, beta and gamma mod-
els can be opened with Microsoft Excel and are called:
• Data breach assessment - Alpha.xlsx
• Data breach assessment - Beta.xlsx
• Data breach assessment - Gamma.xlsx
151

152
materials
d.4
sensitivity analyses
In chapter 6 we already described how the results of the sensitivity
analyses must be interpreted. The results for the alpha and beta anal-
yses are called:
• Sensitivity Analyses - Alpha.zip
• Sensitivity Analyses - Beta.zip
d.5
hospital assessments
The results of the hospital assessments are also stored online. For each
hospital we shared the completed data breach assessment and the re-
sulting Bayesian network. To open the ﬁles AgenaRisk and Microsoft
excel should be used. The ﬁles are called:
• Bayesian Network - Hospital A.cmp
• Data breach assessment - Hospital A.xlsx
• Bayesian Network - Hospital B.cmp
• Data breach assessment - Hospital B.xlsx
• Bayesian Network - Hospital C.cmp
• Data breach assessment - Hospital C.xlsx

B I B L I O G R A P H Y
[1]
AICPA and CICA. Generally Accepted Privacy Principles. 2009.
[2]
Agena. AgenaRisk version 7.0. Accessed: 2016-08-01. 2016. url:
http://www.agenarisk.com/.
[3]
Icek Ajzen. “The theory of planned behavior.” In: Organizational
behavior and human decision processes 50.2 (1991), pp. 179–211.
[4]
Qutaibah Althebyan. Design and analysis of knowledge-base centric
insider threat models. ProQuest, 2008.
[5]
Xiangdong An, Dawn Jutla, and Nick Cercone. “Privacy intru-
sion detection using dynamic Bayesian networks.” In: ACM In-
ternational Conference Proceeding Series. Vol. 156. 2006, pp. 208–
215.
[6]
Vasily Apukhtin. Bayesian network modeling for analysis of data
breach in a bank. 2011.
[7]
Article 29 Working Party. Opinion 03/2014 on Personal Data Breach
Notiﬁcation. 2014.
[8]
Autoriteit Persoonsgegevens. De meldplicht datalekken in de Wet
bescherming persoonsgegevens (Wbp) - Beleidsregels voor toepassing
van artikel 34a van de Wbp. 2015.
[9]
Elise T. Axelrad, Paul J. Sticha, Oliver Brdiczka, and Jianqiang
Shen. “A Bayesian network model for predicting insider threats.”
In: Security and Privacy Workshops (SPW), 2013 IEEE. IEEE. 2013,
pp. 82–89.
[10]
BayesFusion. GeNIe Modeler: Complete Modeling Freedom. Accessed:
2016-08-01. 2015. url: http://www.bayesfusion.com/\#!genie-
modeler/.
[11]
Matt Bishop, Sophie Engle, Deborah A. Frincke, Carrie Gates,
Frank L. Greitzer, Sean Peisert, and Sean Whalen. “A risk man-
agement approach to the “insider threat”.” In: Insider threats in
cyber security. Springer, 2010, pp. 115–137.
[12]
A. Blyth and G.L. Kovacich. Information Assurance: Security in the
Information Environment. Computer Communications and Net-
works. Springer London, 2006. doi: 10.1007/1-84628-489-9.
[13]
Breach Level Index. Data Breach Database. Accessed: 2016-08-
20. 2016. url: http://breachlevelindex.com/data- breach-
database.
153

154
Bibliography
[14]
Serena H. Chen and Carmel A. Pollino. “Guidelines for good
practice in Bayesian network modelling.” In: International Congress
on Environmental Modelling and Software Modelling for Environ-
ment’s Sake, Fifth Biennial Meeting. International Environmental
Modelling and Software Society (iEMSs). 2010, pp. 170–178.
[15]
College Bescherming Persoonsgegevens. CBP Richtsnoeren - Bevei-
liging van persoonsgegevens. 2013.
[16]
Louis Anthony Tony Cox Jr. “Some limitations of “Risk= Threat×
Vulnerability× Consequence” for risk analysis of terrorist at-
tacks.” In: Risk Analysis 28.6 (2008), pp. 1749–1761.
[17]
Ram Dantu and Prakash Kolan. “Risk management using be-
havior based bayesian networks.” In: International Conference on
Intelligence and Security Informatics. Springer. 2005, pp. 115–126.
[18]
De Raad van State. Wet Bescherming Persoonsgegevens. 2016.
[19]
Anton Ekker, Arina Burghouts, Henk Hutink, Peter Uitendaal,
Shirin Golyardi, and Sylvia Veereschild. Wet-en regelgeving in de
zorg: een overzicht voor ICT en eHealth. Nictiz, 2013.
[20]
Arnoud Engelfriet. Security: deskundig en praktisch juridisch ad-
vies. Ius Mentis, 2011.
[21]
European Parliament. Directive 95/46/EC. 1995.
[22]
European Parliament. Charter of Fundamental Rights of the Euro-
pean Union. 2012.
[23]
European Parliament. REGULATION (EU) 2016/679. 2016.
[24]
J. Freund and J. Jones. Measuring and Managing Information Risk:
A FAIR Approach. Elsevier Science, 2014. isbn: 9780127999326.
[25]
Gallup. State of the Global Workplace - Employee Engagement In-
sights for Business Leaders Worldwide. 2013.
[26]
D. Gibson. Managing Risk in Information Systems. Jones & Bartlett
Learning, LLC, 2014. isbn: 9781284055962.
[27]
C.R. Green. Total Memory Workout: 8 Easy Steps to Maximum
Memory Fitness. Random House Publishing Group, 2012. isbn:
9780307574091.
[28]
Frank L. Greitzer and Deborah A. Frincke. “Combining Tradi-
tional Cyber Security Audit Data with Psychosocial Data: To-
wards Predictive Modeling for Insider Threat Mitigation.” In:
Insider Threats in Cyber Security. Ed. by W. Christian Probst, Jef-
frey Hunker, Dieter Gollmann, and Matt Bishop. Springer US,
2010, pp. 85–113. isbn: 978-1-4419-7133-3. doi: 10.1007/978-1-
4419-7133-3_5.
[29]
ISO 27001:2013. Information technology — Security techniques —
Information security management systems — Requirements. Stan-
dard. 2013.

Bibliography
155
[30]
ISO 27002:2013. Information technology — Security techniques —
Code of practice for information security controls. Standard. 2013.
[31]
ISO 27799:2016. Health informatics — Information security manage-
ment in health using ISO/IEC 27002. Standard. 2016.
[32]
ISO. About ISO. Accessed: 2016-08-15. 2016. url: http://www.
iso.org/iso/home/about.htm.
[33]
Identity Theft Resource Center. Data Breaches. Accessed: 2016-
08-20. 2016. url: http://www.idtheftcenter.org/Data-Breaches/
data-breaches.html.
[34]
Information Security Forum. About. Accessed: 2016-08-15. 2015.
url: https://www.securityforum.org/about/.
[35]
Information Security Forum. The Standard of Good Practice for
Information Security 2016. 2016.
[36]
Isala. “Isala meldt datalek in verband met gestolen laptop.” In:
(2016). Accessed: 2016-10-06. url: http://www.isala.nl/over-
isala/nieuws/isala-meldt-datalek-gestolen-laptop.
[37]
Uffe B. Kjærulff and Anders L. Madsen. “Probabilistic networks
for practitioners–A guide to construction and analysis of Bayesian
networks and inﬂuence diagrams.” In: Department of Computer
Science, Aalborg University, HUGIN Expert A/S (2006).
[38]
K.B. Korb and A.E. Nicholson. Bayesian Artiﬁcial Intelligence, Sec-
ond Edition. Chapman & Hall/CRC Computer Science & Data
Analysis. CRC Press, 2010. isbn: 9781439815922.
[39]
Kathryn Laskey, Ghazi Alghamdi, Xun Wang, Daniel Barbara,
Tom Shackelford, Edward Wright, and Julie Fitzgerald. “Detect-
ing threatening behavior using Bayesian networks.” In: Proceed-
ings of the Conference on Behavioral Representation in Modeling and
Simulation. 2004.
[40]
Prem S Mann. Introductory statistics. John Wiley & Sons, 2007.
[41]
Bruce G Marcot, J Douglas Steventon, Glenn D Sutherland, and
Robert K McCann. “Guidelines for developing and updating
Bayesian belief networks applied to ecological modeling and
conservation.” In: Canadian Journal of Forest Research 36.12 (2006),
pp. 3063–3074.
[42]
Agata McCormac, Kathryn Parsons, and Marcus Butavicius. Pre-
venting and Proﬁling Malicious Insider Attacks. 2013.
[43]
NEN 7510:2011. Medische informatica – Informatiebeveiliging in de
zorg. Standard. 2011.
[44]
NEN 7512:2015. Medische informatica - Informatiebeveiliging in de
zorg - Vertrouwensbasis voor gegevensuitwisseling. Standard. 2015.
[45]
NEN. NEN, normalisatie en normen. Accessed: 2016-08-15. 2016.
url: https://www.nen.nl/Over-NEN.htm.

156
Bibliography
[46]
NEN. Start revisie NEN 7510 en NEN 7513 voor informatiebeveilig-
ing in de zorg. Accessed: 2016-08-15. 2016. url: https://www.
nen . nl / NEN - Shop / Nieuwsberichten - Zorg - Welzijn / Start -
revisie-NEN-7510-en-NEN-7513-voor-informatiebeveiliging-
in-de-zorg.htm.
[47]
NIST. Security and Privacy Controls for Federal Information Systems
and Organizations. 2013.
[48]
NIST. NIST General Information. Accessed: 2016-08-15. 2016. url:
http://www.nist.gov/public_affairs/general_information.
cfm.
[49]
NOS. “Arts UMCG bespreekt patiëntgegevens in volle trein.”
In: (2016). Accessed: 2016-08-01. url: http://nos.nl/artikel/
2122653-arts-umcg-bespreekt-patientgegevens-in-volle-
trein.html.
[50]
National Cybersecurity and Communications Integration Cen-
ter. Combating the Insider Threat. 2014.
[51]
National Institute of Standards and Technology. Framework for
Improving Critical Infrastructure Cybersecurity. 2014.
[52]
R.E. Neapolitan. Probabilistic Methods for Bioinformatics: with an
Introduction to Bayesian Networks. Elsevier Science, 2009. isbn:
9780080919362.
[53]
Peter G Neumann. “Combatting insider threats.” In: Insider Threats
in Cyber Security. Springer, 2010, pp. 17–44.
[54]
Nictiz. Gedragscode Elektronische Gegevensuitwisseling in de Zorg.
Accessed: 2016-08-15. 2014. url: https : / / www . nictiz . nl /
SiteCollectionDocuments/Overig/Gedragscode_EGiZ_november_
2014.pdf.
[55]
Norsys. Netica Application. Accessed: 2016-08-01. 2016. url: https:
//www.norsys.com/netica.html.
[56]
Jason RC Nurse, Oliver Buckley, Philip A Legg, Michael Gold-
smith, Sadie Creese, Gordon RT Wright, and Monica Whitty.
“Understanding insider threat: A framework for characterising
attacks.” In: Security and Privacy Workshops (SPW), 2014 IEEE.
IEEE. 2014, pp. 214–228.
[57]
Overheid.nl. De overeenkomst inzake geneeskundige behandeling. Ac-
cessed: 2016-08-15. 2016. url: http://wetten.overheid.nl/
BWBR0005290/2016-08-01\#Boek7_Titeldeel7_Afdeling5.
[58]
Overheid.nl. Regeling gebruik burgerservicenummer in de zorg. Ac-
cessed: 2016-08-15. 2016. url: http://wetten.overheid.nl/
BWBR0023923/.
[59]
Overheid.nl. Zorgverzekeringswet. Accessed: 2016-08-15. 2016. url:
http://wetten.overheid.nl/BWBR0018450/.

Bibliography
157
[60]
PWC. Managing insider threats. 2013. url: http://www.pwc.com/
us/en/increasing-it-effectiveness/publications/assets/
managing-insider-threats.pdf.
[61]
Kathryn Parsons, Agata McCormac, Marcus Butavicius, and
Lael Ferguson. Human factors and information security: individual,
culture and security environment. 2010.
[62]
Ponemon Institute. Fifth Annual Study on Medical Identity Theft.
2015.
[63]
Privacy Rights Clearinghouse. Chronology of Data Breaches: Se-
curity Breaches 2005 - Present. Accessed: 2016-08-20. 2016. url:
http://www.privacyrights.org/data-breach/.
[64]
M Juliane Santiago. The relationship between situational crime pre-
vention theory and campus employee computer misuse. 2010.
[65]
Kuheli Roy Sarkar. “Assessing insider threats to information
security using technical, behavioural and organisational mea-
sures.” In: information security technical report 15.3 (2010), pp. 112–
133.
[66]
E Eugene Schultz. “A framework for understanding and pre-
dicting insider attacks.” In: Computers & Security 21.6 (2002),
pp. 526–531.
[67]
George J Silowash, Dawn M Cappelli, Andrew P Moore, Ran-
dall F Trzeciak, Timothy Shimeall, and Lori Flynn. Common
sense guide to mitigating insider threats. 2012.
[68]
Spok. BYOD Trends in Healthcare: an Industry Snapshot. 2015.
[69]
Tweede Kamer der Staten-Generaal. Nr. 14 Amendement van het
lid van Wijngaarden C.S. 2015.
[70]
Marianthi Theoharidou, Spyros Kokolakis, Maria Karyda, and
Evangelos Kiountouzis. “The insider threat to information sys-
tems and the effectiveness of ISO17799.” In: Computers & Secu-
rity 24.6 (2005), pp. 472–484.
[71]
Laura Uusitalo. “Advantages and challenges of Bayesian net-
works in environmental modelling.” In: Ecological modelling 203.3
(2007), pp. 312–318.
[72]
Verizon. 2015 Protected Health Information Data Breach Report. 2015.
[73]
Verizon. 2016 Data Breach Investigation Reports. 2016.
[74]
VvAA. Wat geld(t) in de zorg? VvAA trendonderzoek onder zorgaan-
bieders. 2013.
[75]
M.E. Whitman and H.J. Mattord. Principles of Information Secu-
rity. Cengage Learning, 2011. isbn: 9781111138219.

158
Bibliography
[76]
Edward Wright, Suzanne Mahoney, K Laskey, Masami Takikawa,
and Tod Levitt. “Multi-entity Bayesian networks for situation
assessment.” In: Information Fusion, 2002. Proceedings of the Fifth
International Conference on. Vol. 2. IEEE. 2002, pp. 804–811.
[77]
Cisco mConcierge. BYOD Insight 2013: A Cisco Partner Network
Study. 2013.
[78]
Autoriteit persoonsgegevens. Controle van personeel. Accessed:
2016-07-25. 2016. url: https://autoriteitpersoonsgegevens.
nl/nl/onderwerpen/werk-uitkering/controle-van-personeel.

