Sparse & Redundant Representations  
and Their Applications in  
Signal and Image Processing 
 
Image Denoising – The Sparseland Way  
Michael Elad 
The Computer Science Department 
The Technion – Israel Institute of technology 
Haifa 32000, Israel 
 

The Denoising Problem  
 
and Its Importance 
Michael Elad  |  The Computer-Science Department  |  The Technion 

  Lets Take a Photo, Shall we ?  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Here is a photo I took with my cellphone 
(Samsung Galaxy S) in my office 
The image looks great, don’t you think? 
 
 
 
 
 
 
 
Well, think again …. and lets zoom in 
True, I turned off the lights in the 
room to get a more extreme effect 

  Images Are Noisy  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Almost all the images we take 
suffer from noise effects, due to  
the sensors’ imperfections, the 
surrounding electronics, and 
even the digital treatment 
(compression, demosaicing, …) 
&  
When the illumination is poor, all 
mentioned above gets worse  

  Denoising: Classic Problem Formulation 
Michael Elad  |  The Computer-Science Department  |  The Technion 
x 


2
v ~
0,I
+ 
z 
We assume that x is contaminated by an 
additive zero-mean iid Gaussian noise 
 
 
 
  
Denoising: Starting from z, our goal is to  
recover an image  
as close as  
possible to x 
Denoising 
Algorithm 
ˆx

  Poisson vs. Gaussian Noise  
Michael Elad  |  The Computer-Science Department  |  The Technion 
We have just defined the denoising 
problem, in which we assumed that the 
noise is additive, being iid and Gaussian 
An alternative noise model of great 
importance: Poisson distribution 
 
 
 
The Poisson model becomes relevant in 
low-light scenarios, in which the z value is 
viewed as a low count of photons  


2
2
z
x
y
x
1
exp
Gaussian
2
2
p(z| x)
x e
, z
0
Poisson
z!


























  Poisson vs. Gaussian Noise  
Michael Elad  |  The Computer-Science Department  |  The Technion 
In this course we focus on the Gaussian 
case only, because of several reasons:   
o The Gaussian case is more common and 
much more important 
o When the Poisson noise is weak (high 
count of photons), the distribution gets 
closer and closer to the Gaussian case 
o A low-count Poisson-distributed image can 
be converted to a Gaussian-noisy one by 
the Anscomb variance stabilizing transform 
o Many of the ideas we present can be 
converted to the Poisson with little effort   

  So, Why Study the Denoising Problem ?  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Reason 1: Because images are noisy  
and we need algorithms to improve their 
quality. This problem becomes more  
acute when the illumination conditions 
are unfavorable 
Reason 2: Because denoising is the 
simplest inverse problem, and as such,  
it is a terrific platform for introducing  
new ideas to image processing 

  Inverse Problems ? 
Michael Elad  |  The Computer-Science Department  |  The Technion 
In image processing, we often refer to the 
degradation as a linear operator H, thus 
z=Hx+v 
This covers problems such as denoising 
(H=I), deblurring, inpainting, super-
resolution, tomographic reconstruction, … 
Denoising is indeed  
       the simplest inverse problem 


2
v ~
0,I
+ 
x 
z 
 
degradation 

  So, Why Study the Denoising Problem ?  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Reason 1: Because images are noisy  
and we need algorithms to improve their 
quality. This problem becomes more  
acute when the illumination conditions 
are unfavorable 
Reason 2: Because denoising is the 
simplest inverse problem, and as such,  
it is a terrific platform for introducing  
new ideas to image processing 
Reason 3: If you know how to denoise 
an image, you are in fact equipped to do 
so much more 

  Using Denoisers for Other Tasks 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Given a well-performing denoising 
algorithm 
 
 
one can do great many things with it: 
 
o
Use it for artistic effects (e.g., cartooning) 
o
Decompose the image into multi-scale 
o
Expand the image dynamic range 
o
Dehaze an image, and … 
o
Solve ANY inverse problem 
 

We do not touch on all of the above  
in this course, as our focus is a denoising 
algorithm derived from Sparseland  

ˆx
f z


  Papers on Denoising  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Searching Web-of-Science   with the topic 
image and noise and (denoising or removal 
or filtering) 
leads to ~14,500 papers 
*  This search was 
performed on 
August 22nd, 2017 
* 
Years 
Number of Papers 

  Existing Denoising Algorithms 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Year 
L2-based 
Regularization 
PDE-Methods 
Robust statistics  
Heuristic 
Spatially 
adaptive 
filtering  
Wavelet 
Sparsity Methods  
Neural-Networks 
1970       1975       1980       1985       1990       1995       2000       2005       2010       2015 
K-SVD 
BM3D 
NCSR 
Heuristic: 
Bilateral 
Thresholding 
Cycle-Spinning 
TNRD 
Frames 
Anisotropic Diffusion 
Hubber-Markov 
GSM 
SURE 
Patch-Methods  
Kernel-Regr. 
               EPLL 
DenoiseNet 
Self-Similarity Methods 
NLM 
NL-Bayes NLM-PCA 
Wiener 
TV 
Beltrami 

First Steps in  
Image Denoising 
Michael Elad  |  The Computer-Science Department  |  The Technion 

  Making Some Decisions 
Michael Elad  |  The Computer-Science Department  |  The Technion 
If we are to denoise an image, then P0
 
seems like the right thing to do, i.e.,  
 
 
 
 
 
 
Issues to consider:  
o Who is D ?  
o Who is  ? And  
o How shall we approximate the solution? 
0
2
min
s.t.
z
ˆ






D
and then  
ˆx
ˆ


D

  OK then, Lets Start 
Michael Elad  |  The Computer-Science Department  |  The Technion 
We answer these questions in the spirit of 
the image deblurring experiment we just 
presented:  
o Who is D ? We choose the undecimated Haar 
o Who is  ? This is easy – it is the noise level  
o How shall we approximate the solution ?  
We could move to L1 and apply ISTA, but we 
will try something even simpler – stay with L0 
and apply the Thresholding algorithm: 
 
BTW: This resembles the first iteration of the ISTA algorithm, 
when initialized with zeros, and using a hard-thresholding 


T
T
ˆx
S
z


D
D

  A (Slight) Difficulty With Haar 
Michael Elad  |  The Computer-Science Department  |  The Technion 
The atoms in D, as used in the deblurring 
experiment, are not L2-normalized 
However, in order to apply a fixed 
threshold T to all the elements of DTz,  
we must take the atoms’ norm into 
consideration. How ?  
We construct the vector w of length m, 
containing the atom norms. The threshold 
we shall use is wT: a smaller threshold is 
used to a low-norm atom 
As we do not know which T to use, we 
sweep over values in the range [0,200] 

  Experimenting with Global Thresholding   
Michael Elad  |  The Computer-Science Department  |  The Technion 
We are about to run a very simple denoising 
algorithm, based on Thresholding 
This and later tests refer to the image 
Barbara with a noise level of =20 
The quality of the output will be evaluated 
by the Peak-SNR, given by 
 
 
 
where z0 is the ideal (clean) image, and N 
stands for the number of pixels in it  


2
2
10
10
2
2
T
0
2
0
wT
2
N 255
N 255
PSNR
10log
10log
ˆ
z
z
z
S
z







D
D

  Denoising Results: Global Thresholding   
Michael Elad  |  The Computer-Science Department  |  The Technion 
The output quality as a function of T  
Best T  
value (=53)  
How can we find it?  
27.97dB 

  Denoising Results: Global Thresholding   
Michael Elad  |  The Computer-Science Department  |  The Technion 


T
wT
2
1
z
S
z
n


D
D
The residual might help in choosing T 
T=64 in the 
cross-over point 

  Denoising Results: Global Thresholding   
Michael Elad  |  The Computer-Science Department  |  The Technion 
The Original  
Image  
The Noisy Image 
PSNR=22.12dB  
The Best-Restored Image 
PSNR=27.97dB  
Very nice result but not a perfect one, as we do see some 
washed-out content – Could we do better ? 

  Global Thresholding : Summary 
Michael Elad  |  The Computer-Science Department  |  The Technion 
First of all, It Works  !! 
 
However: 

We need to choose T – using the residual is 
not bad, as it leads to PSNR=27.11dB  

We will propose a better alternative shortly 

Another “complication”: Just like in the 
deblurring case, the representation for the 
best T is not sparse at all (NNZ550000, 
n=5122=260000) 


T
wT
S
z
ˆ
D

Variations on the 
Global Thresholding  
Algorithm 
Michael Elad  |  The Computer-Science Department  |  The Technion 

  Improvements ?  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Could we improve the above-described method?  
The answer is Positive ! Various techniques 
appeared in the early 2000’s, aiming to do this 
Basic ideas:  
o Adapt the thresholds 

  Improvements ?  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Could we improve the above-described method?  
The answer is Positive ! Various techniques 
appeared in the early 2000’s, aiming to do this 
Basic ideas:  
o Improve the choice of the dictionary 

  Improvements ?  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Could we improve the above-described method?  
The answer is Positive ! Various techniques 
appeared in the early 2000’s, aiming to do this 
Basic ideas:  
o impose a more sophisticated statistical model   

  Improvements ?  
Michael Elad  |  The Computer-Science Department  |  The Technion 
The list of improvements over the global 
Thresholding went on and on, and with it, the 
quality of the denoising got better and better 
However, at some point these algorithms  
became quite complicated, heavily heuristic,  
and touching a ceiling in terms of performance 
Is there an alternative, still under Sparseland  
that will break this barrier? The answer is  
 
                            Yes 
This will bring us to patch-based processing  

  Wait  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Just before moving to patch-based methods, 
we want to come back to the need to tune T 
in the Thresholding algorithm 
 
Can we suggest an automatic  
way to do this? 
 
The answer is YES, based on the  
Stein Unbiased Risk Estimation 
which we present next   

SURE for  
Parameter Tuning:  
The Theory 
Michael Elad  |  The Computer-Science Department  |  The Technion 

  The Objective 
Michael Elad  |  The Computer-Science Department  |  The Technion 
We have a denoising algorithm of some sort 
We want to set its parameters so as to 
extract the best out of it 
x
+ 


2
v ~
0,I
z
Algorithm 


ˆz
h z,








2
2
2
2
ˆ
minE
z
x
minE
h z,
x






  Charles M. Stein’s Paper 
Michael Elad  |  The Computer-Science Department  |  The Technion 
SURE: Stein’s Unbiased 
Risk estimation 

  SURE Derivation – 1  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Lets open the error norm into its 
ingredients: 
 
 
 
 
 
 
Therefore, we will proceed with the 
second term and show that in fact it  
can be computed 














2
2
2
2
T
2
2
E
h z,
x
E
h z,
2 E x h z,
E
x






Easy 
Impossible? 
Not important 

  SURE Derivation – 2  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Using the fact that              we get 
 
 
 
 
 
Again, the first term is fine for us to 
compute, while the second seems hard 
(we do not know the noise vector!) 
 
We proceed with the second term … 












T
T
T
E x h z,
E z h z,
E v h z,





Easy 
Impossible? 
x
z
v



  SURE Derivation – 3  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Using the definition of expectation 
 
 
 
 
This may look ugly BUT this expression can 
be written differently as  
 
 
 
This reminds us of “integration by parts” 










T
k
k
k
2
k
k
k
k
2
k
E v h z,
E v h
z,
v
1
v h
z,
exp
dv
2
2




















2
k
k
k
2
k
k
v
d
h
z,
exp
dv
dv
2
2























The derivative w.r.t. 
vk can be replaced by 
a derivative w.r.t. zk 






k
k
k
k
k
k
k
k
k
k
k
k
k
dz
d(x
v ) 1
dv
dv
dh
z,
dh
z,
dh
z,
dz
dv
dz
dv
dz









Assuming that the 
function h is finite for all 
z, this term is zero 
  SURE Derivation – 4  
Michael Elad  |  The Computer-Science Department  |  The Technion 
            Using integration by parts  
 
 
 





d
d
f x
g x
dx
f x g x
f x
g x dx
dx
dx
































2
2
k
k
k
k
2
2
k
2
k
k
k
2
k
v
v
d
h z,
exp
dv
h
z,
exp
dv
2
2
v
d
exp
h
z,
dv
dv
2


























































  SURE Derivation – 5  
Michael Elad  |  The Computer-Science Department  |  The Technion 
One last step – the expression we got (the 
derivative of the denoiser w.r.t. its input)  
is in fact an expectation over the noise … 
 
 
 






2
k
k
k
2
k
2
k
k
k
2
k
k
k
v
d
h
z,
exp
dv
dv
2
v
d
exp
h
z,
dv
dz
2
d
E
h
z,
dz























































  Wrap-Up – 1  
Michael Elad  |  The Computer-Science Department  |  The Technion 
















2
2
2
2
T
2
z
E
h z,
x
E
h z,
2E z h z,
2
E
h z,
const.









We got the following expression after 
all of the steps above 
The squared norm of 
the estimated image  
An inner product between 
the noisy and the denoised 
images 
Sum over the “sensitivity”  
of our algorithm to 
perturbations in the input  
Our estimator is true up 
to an unknown constant 

  Wrap-Up – 2  
Michael Elad  |  The Computer-Science Department  |  The Technion 










2
2
T
2
2
2
z
E
h z,
x
h z,
2z h z,
2
h z,







Since we cannot compute the expectation, 
we simply drop it with the hope that the 
summation over all the image pixels is 
sufficient to provide the desired accuracy 
 
 
If you want to set the parameters, , do  
this while minimizing the above expression 
This implies that the denoising algorithm 
should be differentiable w.r.t. the input 

  Bottom Line 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Well, say hello to the  
 
 
 
 
SURE: Stein’s Unbiased 
Risk estimation 










2
2
T
2
2
2
z
E
h z,
x
h z,
2z h z,
2
h z,








SURE for  
Parameter Tuning:  
The Practice 
Michael Elad  |  The Computer-Science Department  |  The Technion 

  Using SURE for the Global Thresholding  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Lets come back to the global image denoising 
scheme by Thresholding 
 
 
 
 
 
 
Our goal: Finding the optimal T  
 
Note: SURE is effective for evaluating small number of 
parameters. Thus, finding the best threshold per 
element is out of the question 
Algorithm 
x
+ 


2
v ~
0,I




T
wT
ˆz
h z,
S
z




D
D
z

  h(z,) Should be Differentiable 
Michael Elad  |  The Computer-Science Department  |  The Technion 

k
k
T
k
k
k
z
z
T
S
z
z
z
z
T
z
1
T

















Let’s make sure that our estimator is 
differentiable by smoothing it (even k) 


2k
k
T
'
T
2
k
z
z
(k
1)
dS
z
T
T
S
z
dz
z
1
T































  Derivation of SURE for Our Case – 1  
Michael Elad  |  The Computer-Science Department  |  The Technion 


















2
2
2
T
2
z
2
2
T
1
T
T
1
T
T
'
1
T
1
2
T
T
2
S
z
tr
S
E
h z,
x
h z,
2z h z,
2
h z,
S
z
z
2z
2














DW
W D
DW
W D
W
W
W
D
D
D




T
1
T
wT
T
S
z
S
z


D
D
DW
W
D
We start by reformulating our algorithm: 
Using the new 
formulation 

diag w

W

  Derivation of SURE for Our Case – 2  
Michael Elad  |  The Computer-Science Department  |  The Technion 


















'
1
T
1
T
T
'
1
T
1
T
T
'
1
T
1
T
T
A Diagonal Matrix
'
1
T
T
T
'
1
T
2
T
tr
S
z
tr
S
z
tr
S
z
tr S
z
tr S
z






















DW
W D
W D
W
W D
W D D
W
W D
W
D D
W D
D D
W D
W
We can simplify the last term  












1
1
2
1
2
tr
tr
tr
tr
tr
tr
diag( )





AB
BA
W W W
W
WR
W
R
Some Properties: 

  Derivation of SURE for Our Case – 3  
Michael Elad  |  The Computer-Science Department  |  The Technion 










2
2
1
T
T
2
2
T
1
T
T
2
'
1
T
2
T
ˆ
E
z
x
S
z
2z
S
z
2
tr S
z







DW
W D
DW
W D
W D
W
Bottom Line: 
 
 
 
 
 
 
 
We are to use this expression and check for 
which T it gets its maximal value – and this 
is what SURE recommends to use 
 
Will this work ?   

  SURE: An Experiment 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Works Amazingly Well !! There is a perfect 
agreement between the true PSNR and the 
SURE predicted one (up to a constant) 

Patch-Based Denoising  
– Basics 
Michael Elad  |  The Computer-Science Department  |  The Technion 

  The Core Idea 
Michael Elad  |  The Computer-Science Department  |  The Technion 
0
2
1
min
s.t.
z
ˆ
2






D
In bringing Sparseland to denoising,  
we necessarily pass though the 
approximation of P0
 
 
 
A key ingredient here is … 
A global treatment must compromise  
in choosing D, and cannot benefit  
from the learning option 
The solution: Operate on small image 
patches, imposing Sparseland on them  
D 
Operating on small image  
patches has various benefits: 
o Leveraging dictionary learning  
o Enabling simple (e.g. Greedy) pursuit 
methods 
o Parallelizing the treatment 
o Overcoming the paradox of  
getting dense representations, and  
o Enabling treatment of any size images 

However,  
o Isn’t this strategy necessarily sub-
optimal ? 
o Can it be theoretically justified ? 

  Moving to Patches: The Simplest Method 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Here is a recipe [Guleryuz 2003 & 2005]:  
Divide the image into non-overlapping patches  
Solve per each its corresponding P0
 &  
Merge these patches back to their locations 
0
2
1
min
s.t.
z
ˆ
2






D
Issues to consider:  
o Who is D ?  
o Who is  ? &  
o How shall we 
approximate P0
 ? 
Approximation 
of P0
 
ˆ
Multiply 
by D 

  Moving to Patches: The Simplest Method 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Approximation 
of P0
 


T
T
S
z
ˆ
D
ˆ
Multiply 
by D 
Answers (for now):  
o Who is D ? Use the unitary 2D-DCT 
o Who is  ? The expected noise level in the patch 
o How shall we approximate P0
 ? Since D is unitary, Thresholding is in-
fact optimal 
The threshold should be set per 
each patch based on the noise level 

The Original  
Image  
The Noisy Image 
PSNR=22.12dB  
The Restored Image 
PSNR=26.50dB  
  The Simplest Method: An Experiment 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Parameters: Patch-size n=16, Noise level =20 
Strong 
blockiness 
artifacts 

  Improving this Simple Patch-Method 
Michael Elad  |  The Computer-Science Department  |  The Technion 
The core engine remains the pursuit 
that is applied on each patch 
However, we may perform better by:  
o Overlapping the patches and averaging  
o We can replace the unitary dictionary by  
a redundant one and maybe even … and 
even a learned one 
Approximation 
of P0
 
0
2
1
min
s.t.
z
ˆ
2






D
ˆ
Multiply 
by D 
Comments:  
The overlap and add idea is closely 
related to the concept of Cycle-
Spinning [Coifman & Donoho 1995]  
A weighted (and better) averaging  
was proposed [Guleryuz 2007] 

  Experimenting with (full) Overlapping  
Michael Elad  |  The Computer-Science Department  |  The Technion 
When working with patches of size n×n, 
every pixel (disregard boundaries) is 
covered n2 times - We propose to simply 
average these values 
This has a strong denoising effect, and thus 
we have an incentive to use large patches 
On the other hand, the bigger the patch, 
the less accurate the model becomes 
Thus, there is a critical optimal size to use  
Let’s see how the patch-size influences the 
overall denoising performance  
The best performance is 
obtained for n=21, leading to  
PSNR=30.55dB  

The Original  
Image  
The Noisy Image 
PSNR=22.12dB  
The Restored Image 
PSNR=30.55dB  
  Full-Overlap: The Result 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Parameters: Patch-size n=21 (fully overlapped), Noise level =20 
A much 
better 
result 

Patch-Based Denoising:  
Theoretical Foundations 
Michael Elad  |  The Computer-Science Department  |  The Technion 

  Theoretical Foundations 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Could we propose a clear mathematical 
formulation that provides an origin to the 
above algorithm ? The answer is positive  
[Elad & Aharon 2006] 
Recall the discussion on Priors and the MAP 
estimation: Given z, denoising is done by 
 
 
G(x) should reflect our belief about the 
unknown image we are trying to recover. 
Well, what is our belief about x ?  



2
2
x
G x
log
ˆx
ArgMin
x
P
z
G x
2
x










  The Patch-Based Sparseland Prior 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Our belief: Every patch in x is expected to 
have a sparse representation w.r.t. D 
Thus, our prior should be  

k
k
k
0
2
k
G x
s.t.
x










R
D
Rk 
Rk extract a patch 
from location k 
Individual P0
 per each patch 

  Overall Algorithm 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Here is the MAP in a more pleasant form: 
 
 
 
We optimize w.r.t. both the representations 
of all the patches and the overall image x: 
o Given x, update k (k=1,2, …) – This is a 
simple pursuit per patch. If D is unitary, THR is 
a perfect pursuit  
o Given k, update x – This is an easy to solve 
Quadratic problem 
2
k
k
k
0
2
k
1
x
2












R
D


k k
2
2
x,
ˆx
ArgMin
x
z
2





  Overall Algorithm: The Pursuit Stage 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Given x, we shall update k by solving  
 
 
If x is initialized x=z, the level of the noise 
in each patch (and thus, ) is known 
The above is a low-dimensional pursuit 
problem, so we can (and shall) use OMP or 
THR (if D is unitary) 
2
k
k
k
0
2
k
1
x
2












R
D


k k
2
2
x,
ˆx
ArgMin
x
z
2




k
k
k
k
0
2
k
Min
s.t.
x















R
D

  Overall Algorithm: The Image Update Stage 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Given {k}, we shall update x by solving 
 
The gradient of this expression is  
 
Thus: 
2
k
k
k
0
2
k
1
x
2












R
D


k k
2
2
x,
ˆx
ArgMin
x
z
2




2
2
k
k
2
2
x
k
1
ˆx
ArgMin
x
z
x
2
2






R
D
1
T
T
k
k
k
k
k
k
ˆx
z






















R R
I
R D




T
k
k
k
k
x
z
x
0






R
R
D

  Overall Algorithm: The Image Update Stage 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Observation 1: When Dk is multiplied by 
Rk
T, this puts the cleaned patch Dk back to 
location k in the image. Thus this 
summation sums the overlapped patches 
Observation 2: The matrix to be inverted is 
diagonal, simply normalizing the averaging  
Observation 3: This is patch-averaging with 
a small twist ( adds an averaging with the 
noisy image as well) 
1
T
T
k
k
k
k
k
k
ˆx
z






















R R
I
R D

? 
  The Overall Algorithm 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Initialize  x=z 
Apply pursuit for each patch 
k
k
k
k
k
0
2
ArgMin
s.t.
x
ˆ







R
D
Update x by “Patch-Averaging” 
1
T
T
k
k
k
k
k
k
ˆx
z






















R R
I
R D
What about iterating? 
 
This will complicate the 
algorithm because once x 
has been updated, the noise 
strength in each patch is no 
longer as simple to obtain 
 
We will come back to this 
when we discuss the EPLL 

The K-SVD Image  
Denoising Algorithm 
Michael Elad  |  The Computer-Science Department  |  The Technion 

  The K-SVD Image Denoising Algorithm 
Michael Elad  |  The Computer-Science Department  |  The Technion 
2
k
k
k
0
2
k
1
x
2












R
D


k k
2
2
x,
ˆx
ArgMin
x
z
2




Recall the above formulation, which led to the patch-averaging algorithm 
What if we decide that the  
dictionary D is also an  
unknown to be optimized?  
Once k are set, D could be  
updated using the K-SVD  
rationale. This brings us to 
      K-SVD Denoising 

  The Overall Algorithm 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Initialize  x=z 
Apply pursuit for each patch 
k
k
k
k
k
0
2
ArgMin
s.t.
x
ˆ







R
D
Update x: “Patch-Averaging” 
1
T
T
k
k
k
k
k
k
ˆx
z






















R R
I
R D
Update D: K-SVD Approach 
This highlighted part (in blue) performs  
K-SVD dictionary learning on the noisy 
patches extracted from z  
The overall algorithm is quite heavy in 
computations, mostly due to the need 
to apply pursuit for each patch 
However, this effort can be easily 
parallelized, as this stage is 
independently applied on the patches 
Other shortcuts exist, such as training 
on a portion of the patches, … 

  Does It Work ?  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Here are a few key details about the experiment: 
The initial D: Redundant and separable 2D-DCT 
The parameter : =0.5 (found empirically to  
perform well) 
The pursuit used: OMP with an error  
stopping condition  
 
 
The Applied K-SVD algorithm: All the usual tricks  
of replacing unused atoms or too similar ones 
Dictionary=zeros(n,sqrt(K)); 
for k=0:1:sqrt(K)-1 
  V=cos([0:1:n-1]*k*pi/sqrt(K)); 
  if k>0, V=V-mean(V); end 
  Dictionary(:,k+1)=V/norm(V); 
end 
Dictionary=kron(Dictionary,Dictionary); 
k
k
k
k
k
0
2
ArgMin
s.t.
x
ˆ
1.15 n









R
D

  Output Quality   
Michael Elad  |  The Computer-Science Department  |  The Technion 
For n=10, K=256:  

After 0 iterations:    
30.30dB 

After 10 iterations:  
31.00 dB  

After 50 iterations:  
31.24 dB 

The output quality stabilizes on 
~31.25dB after 75 iterations  
 
For n=15, K=625:   

After 0 iterations:    
30.53dB 

After 10 iterations:  
31.06 dB  

After 50 iterations:  
31.33 dB 

  The Resulting Image  
Michael Elad  |  The Computer-Science Department  |  The Technion 
The Original  
Image  
The Noisy Image 
PSNR=22.12dB  
The Restored Image 
PSNR=31.24dB  
Parameters: Patch-size n=10, 50 Iterations, Noise level =20 
A much 
better 
result 

  Sparsity ?  
Michael Elad  |  The Computer-Science Department  |  The Technion 
We update iteratively {k} and D, in 
order to get a sparse description of the 
patches we train on 
The resulting {k} are sparse and 
getting sparser as we iterate 
Recall: the number of patches  number 
of pixels in the image 
Thus, the overall number of non-zero in 
all {k} is ~3.2 times the number of 
pixels in the image. Thus, we get a 
            Locally Sparse  Globally Dense 
                   representation 

  The Resulting Dictionary   
Michael Elad  |  The Computer-Science Department  |  The Technion 
The resulting dictionary is specifically tailored to handle the image Barbara  

  Improvements: EPLL   
Michael Elad  |  The Computer-Science Department  |  The Technion 
Update 
the 
Output 
image 
Update the 
sparse repr. 
Update the 
Dictionary 
The algorithm we proposed  
updates x only once at the end  
Why not repeat the whole  
process several times?   
The rationale: Our model should  
be imposed on the patches of  
the FINAL image. After averaging,  
this is ruined 
Expected Patch Log Likelihood (EPLL)  
[Zoran and Weiss, 2011] offers such a mechanism. It has been applied to the  
K-SVD denoising, leading to a 0.5-1dB improvement [Sulam and Elad, 2015]  

  Improvements: EPLL   
Michael Elad  |  The Computer-Science Department  |  The Technion 
Noisy image   
has σ=25 
 
KSVD  
PSNR 31.42 dB 
 
EPLL  
PSNR 31.83 dB 
Original  
K-SVD  
EPLL  

  Improvements: Joint-Sparsity   
Michael Elad  |  The Computer-Science Department  |  The Technion 
Take a closer look at what we do: We exploit the  
structure that exists within each of the patches  
A critical force that has not be exploited is the  
self-similarity that exists between different patches  
Modified K-SVD Denoising: for each patch, seek  
similar ones to it, apply pursuit on them  
together (forcing the same support), and proceed as usual 
Variations on this idea were proposed in [Mairal, Back, Ponce, Spario, & Zisserman, 2009]  
& [Dong, Zhang, Shi & Li, 2013] leading to ~1dB improvement 
2
k
k
k
0
2
k
1
x
2












R
D


k k
2
2
x,
ˆx
ArgMin
x
z
2





Patch-Based Denoising  
– Other Methods  
Michael Elad  |  The Computer-Science Department  |  The Technion 

  Other Algorithms ? 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Over the past decade, many papers  
offered novel patch-based image  
denoising algorithms 
Common ideas:  
o Improvements over the above methods 
o Other techniques still relying on sparsity 
o Low-rank assumption 
o Gaussian Mixture Models 
o Example-Based (e.g. NLM), … 

We will briefly mention few of these, with 
emphasis on the sparsity-oriented ones 

  The BM3D [Dabov, Foi, Katkovnik & Egiazarian, 2007] 
Michael Elad  |  The Computer-Science Department  |  The Technion 
The Block-Matching 3D Transform (BM3D) 
algorithm was published in 2007 
This is one of the leading known denoising 
algorithms due to its superb performance 

  The BM3D: Core Idea 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Rely on both self-similarity in the image 
and on the local sparsity of patches 

  The BM3D: More Details 
Michael Elad  |  The Computer-Science Department  |  The Technion 
The Algorithm Steps: 
1. For each patch, find similar ones 
2. Pile the set into a 3D cube 
3. Apply a 3D transform (Haar or DCT) 
4. Threshold small values 
5. Apply inverse-transform  
6. Put the patches back to their location 
7. Average patches based on their sparsity 
0 
Second round with MMSE shrinkage 
Denoising the image Barbara (=20)  
with BM3D leads to PSNR=31.76dB 

  Learning the Shrinkage Curves 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Guleryuz’ scheme: Operate on each patch 
separately (THR) and merge by averaging  
K-SVD Denoising: Question D & the pursuit 
How about keeping D and questioning the 
shrinkage curve?  
This brings us to the work in  
[Hel-Or & Shaked, 2008]  
Multiply 
by D 
Multiply 
by DT 
? 

  Learning the Shrinkage Curves: Basic Idea 
Michael Elad  |  The Computer-Science Department  |  The Technion 


2
T
2
k
0
k
k
p
n
p
mi
S



D
D
Clean patches 
Noisy patches 
Consider the following objective function 
 
 
: the shrinkage curve  
If the curve is  
represented as a linear combination of basis 
functions (polynomials), the above becomes LS  
Once solved on a training image, one should use 
the found parameters on other images 
Basic idea: We should train a different curve for 
each transform coefficient 

  Learning the Shrinkage Curves: Results 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Here is a demonstration of the result for 
patches of size n=5 and the 2D-DCT: we have 
25 curves 
Of these, the  
high-frequency  
ones tend to  
suppress the  
value  
For n=12, we  
get a PSNR of  
29.23dB (train  
on Lena) 

  Learning the Shrinkage Curves: Results 
Michael Elad  |  The Computer-Science Department  |  The Technion 
A flaw in the above is that we disregard the 
averaging over the overlaps that takes place  
When this is  
taken into  
account, the  
curves are  
different, and  
the results  
can improve  
(29.85dB) 
 Observe:  
Some curves  
flip the value  

  Handling Video 
Michael Elad  |  The Computer-Science Department  |  The Technion 
Many of the existing algorithms for single 
image denoising can be turned into video 
denoisers 
Key-idea: while one could denoise each  
image separately, we could benefit greatly 
(computationally and in output quality) if we 
fuse information between frames 
Extended algorithms for video: 
o NLM-based [Boades, Coll & Morel, 2005]  
o BM3D-based [Rusanovskyy, Dabov, & Egiazarian 2006]  
o K-SVD-based [Protter & Elad 2009] 

  Handling Video: The K-SVD Approach 
Michael Elad  |  The Computer-Science Department  |  The Technion 
When turning to handle video using the  
K-SVD denoising, one could improve over the 
single-image scheme in three important 
ways: 
Propagate the dictionary from one frame to 
another, and thus reduce the number of 
iterations 
Use 3D patches that handle the motion 
implicitly, and 
Motion estimation and compensation can 
and should be avoided 

  Handling Video: K-SVD Results 
Michael Elad  |  The Computer-Science Department  |  The Technion 
      Original                 Noisy (σ=25)       Denoised (PSNR=27.62) 
      Original                 Noisy (σ=15)       Denoised (PSNR=29.98) 

Image Denoising  
– Summary 
Michael Elad  |  The Computer-Science Department  |  The Technion 

  Results We Saw in this Chapter  
Michael Elad  |  The Computer-Science Department  |  The Technion 
BM3D  
31.76dB  
Noisy image 
22.11dB 
Global Thresholding + 
Redundant Haar 27.97dB  
Patch-based + Learned 
Shrinkage 29.85dB 
Non-Local-
Means 29.60dB 
Simple  
Patch-Averaging 
30.55dB 
K-SVD Denoising 
31.33dB 

  Who is the Best ?  
Michael Elad  |  The Computer-Science Department  |  The Technion 
Over the past 15 years, we see a series  
of papers offering better and better 
performing denoising algorithms 
How to compare? Use an agreed test  
set (Barbara, Lena, House, …) and a 
series of experiments with varying   
Performance evaluation: PSNR and SSIM  
The current lead: Trainable Nonlinear 
Reaction Diffusion (TNRD) [Chen & Pock, 2016] 
Main TNRD theme: connection to CNN 
and to the co-sparse analysis model 

  Are we Touching the Ceiling ? 
Michael Elad  |  The Computer-Science Department  |  The Technion 
The best performing methods lead to very close 
PSNR values, and this raises the suspicion that 
we are touching the ceiling 
 
Verdict: There is still room for improvement  
[Chatterjee & Milanfar, 2010] 

  Are we Touching the Ceiling ? 
Michael Elad  |  The Computer-Science Department  |  The Technion 
The best performing methods lead to very close 
PSNR values, and this raises the suspicion that 
we are touching the ceiling 
 
Verdict: Touching the ceiling  
(for small windows) [Levin & Nadler, 2011] 

  Final Words  
Michael Elad  |  The Computer-Science Department  |  The Technion 
The image 
denoising problem 
was and still is the 
most studied 
problem in image 
processing  
Thousands  
algorithms were 
proposed over the 
years for its solution 
Sparseland  
related methods are 
among the best-
performing methods  
Most recent comers 
to the game: Deep-
Learning, which are 
also related to  
sparse modeling  

