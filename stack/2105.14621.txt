Thermodynamic stability implies causality
L. Gavassino, M. Antonelli & B. Haskell
Nicolaus Copernicus Astronomical Center, Polish Academy of Sciences, ul. Bartycka 18, 00-716 Warsaw, Poland
The stability conditions of a relativistic hydrodynamic theory can be derived directly from the
requirement that the entropy should be maximised in equilibrium. Here we use a simple geometrical
argument to prove that, if the hydrodynamic theory is stable according to this entropic criterion,
then localised perturbations cannot propagate outside their future light-cone. In other words, within
relativistic hydrodynamics, acausal theories must be thermodynamically unstable. We show that
the physical origin of this deep connection between stability and causality lies in the relationship
between entropy and information.
Introduction - A hydrodynamic theory is said to be
stable if small deviations from the state of global ther-
modynamic equilibrium do not have the tendency to grow
indeﬁnitely, but remain bounded over time. It is said to
be causal if signals do not propagate faster than light.
Every hydrodynamic theory should guarantee the valid-
ity of these two principles, the former arising from the
deﬁnition of equilibrium as the state towards which dis-
sipative systems evolve (as t →+∞), the latter arising
from the principle of relativity (if signals were superlumi-
nal, there would be a reference frame in which the eﬀect
precedes the cause). Whenever a new theory is proposed,
it needs to pass these two tests, to be considered reliable.
To date, these properties have been mostly studied as two
distinct, disconnected features of the equations of the the-
ory, to be discussed separately. Intuitively, this approach
seems natural, as stability and causality are two prin-
ciples which pertain to two complementary branches of
physics: thermodynamics [1] and ﬁeld theory [2].
However, in reality these two features appear to be
strongly correlated. Divergence-type theories are causal
if and only if they are stable [3] while Israel-Stewart the-
ories are causal if they are stable [4, 5]. Geroch and Lind-
blom [6] analysed a wide class of causal theories for dis-
sipation and found that many causality conditions have
an important stabilising eﬀect. Finally, Bemﬁca et al. [7]
have recently proven a theorem, according to which, if a
theory is stable in the ﬂuid rest-frame, and it is causal,
then it is stable in every reference frame, formalising a
widespread intuition [8, 9]. All these results suggest the
existence of an underlying physical mechanism connect-
ing causality and stability. Discovering it would lead to
a complete change of paradigm. In fact, it would pro-
vide a new insight into the physical meaning of the (usu-
ally complicated) mathematical structure which ensures
causality.
Furthermore, it would importantly simplify
the (usually tedious) job of testing both causality and
stability, maybe reducing one to the other.
To date, a “fully explanatory” mechanism connecting
causality and stability has never been proposed. In fact,
such a connection is usually found a posteriori, by direct
comparison between the two distinct sets of conditions
(as in [4]), or through complicated mathematical proofs,
as in [7].
The goal of this letter is to ﬁnally explain
simply the relationship between causality and stability.
We prove, with a geometrical argument, that if a the-
ory is thermodynamically stable, namely if the entropy is
maximised at equilibrium (see Gavassino [10]), it is also
causal. We show that the key to understand this result
from a physical perspective is the underlying relationship
between entropy and information. Furthermore, we ex-
plain why causality alone does not imply stability (see
e.g. [11]), but one needs at least to prove stability in a
particular reference frame (in agreement with [7]).
We adopt the signature (−, +, +, +) and we work in
natural units c = kB = 1.
Thermodynamic stability - Consider a relativistic ﬂuid
located in a stationary (ﬁxed) background spacetime [12].
Given a selection of the macroscopic ﬁelds (ϕi) which
carry information about the local state of the ﬂuid (e.g.
the ﬂuid four-velocity or the temperature ﬁeld) we con-
sider two solutions of the hydrodynamic equations, ϕi
and ϕi + δϕi. The ﬁrst is the state of global thermo-
dynamic equilibrium, while δϕi is a small perturbation
which conserves the total energy and any other conserved
quantity (such as the total baryon number).
Assume that the ﬂuid is thermodynamically stable.
Then, following [10], we know that, for an arbitrary
space-like Cauchy 3D-surface Σ, the quantity
E[Σ] := S[Σ, ϕi] −S[Σ, ϕi + δϕi],
(1)
quantifying the entropy diﬀerence between the equilib-
rium and the perturbed state, can be written as the ﬂux
E[Σ] =
Z
Σ
Eana
p
|γ| d3y
(2)
of a four-current Ea = Ea[ϕi, δϕi], which has the follow-
ing properties:
(i) - For any unit vector na, time-like and past-directed
(nana = −1, n0 < 0), we have
Eana ≥0.
(3)
(ii) - Ea = 0 on any point where the perturbation of ev-
ery measurable quantity is zero, and only on these
points.
arXiv:2105.14621v1  [gr-qc]  30 May 2021

2
(iii) - The four-divergence of Ea is non-positive:
∇aEa ≤0.
(4)
The ﬁrst condition is simply the Gibbs stability criterion,
according to which E ≥0 (namely, the entropy is max-
imised in equilibrium) for any possible choice of Σ and
δϕi. In fact, the vector na = na[Σ] appearing in (2) is the
unit normal to Σ; it is time-like past-directed. The sec-
ond condition is a consequence of how the current Ea is
explicitly constructed, as minus the second-order pertur-
bation to the entropy current [10]. The third condition
is the second law of thermodynamics.
The criterion for thermodynamic stability described
above is a suﬃcient condition for hydrodynamic stability
[10], but contains more information than a direct hydro-
dynamic stability analysis. In fact, while the latter is a
dynamical property of the ﬁeld equations (an on-shell cri-
terion [13]), the former is a property of the constitutive
relations (it must be respected also oﬀ-shell). Thermo-
dynamic stability implies stability of any ﬁeld equation,
realistic or not, which obeys the global conservation laws
and the second law of thermodynamics. It also implies
stability to virtual processes and thermal ﬂuctuations,
even if these are not explicitly modelled in the hydrody-
namic theory. To better understand this point, consider
the case of a perfect ﬂuid, whose current Ea is [4, 10]
TEa = ua
2 (ρ + p)δubδub + δuaδp +
ua
2
 1
c2s
(δp)2
ρ + p + nT
cp
(δσ)2

,
(5)
where ua, n, T, ρ, p, σ, cs and cp are ﬂuid velocity,
particle density, temperature, energy density, pressure,
entropy per particle, speed of sound and speciﬁc heat at
constant pressure. The condition (i) produces the ther-
modynamic inequalities (assuming n, T > 0)
0 < c2
s ≤1
ρ + p > 0
cp > 0.
(6)
The third inequality is a condition of stability to heat
transfer, a process that is, however, not allowed in a per-
fect ﬂuid. Hence, cp > 0 is not a condition of hydrody-
namic stability (as long as the ﬂuid is perfect) because
the mechanism driving the instability is a virtual pro-
cess, i.e. a process that is forbidden on-shell. However,
thermodynamic stability implies stability also to virtual
processes [14], which become real when thermal ﬂuctua-
tions are included in the description [15, 16].
The argument for causality - Our goal is to show that
the conditions (i,ii,iii) also imply causality. We work, for
clarity, in 1+1 dimensions, on a scale that is assumed
suﬃciently small that we can neglect the gravitational
ﬁeld, but the argument can be straightforwardly gener-
alised. Working in an inertial coordinate system (t, x),
FIG. 1. Visualization of the geometric argument. The ini-
tial perturbation (in red) is located to the left of the origin.
Causality requires it to stay conﬁned in the t ≥x half-plane.
We build the triangle ABC in such a way that all its edges are
space-like. B and C intersect at the origin. We can regulate B
to be arbitrarily close to the line t = x. The green arrows are
a Euclidean representation of the unit normals to the edges
and are taken inward-pointing, consistently with our choice
of metric signature [17].
we consider a perturbation that is initially conﬁned in
the semi-axis x ≤0, namely
δϕi(0, x) = 0
∀x > 0.
(7)
We apply the Gauss theorem to the triangle ABC shown
in ﬁgure 1 and use condition (iii):
E[A] + E[B] + E[C] =
Z
(triangle)
∇aEa dt dx ≤0.
(8)
The 1D surfaces A, B and C are all space-like, so that
their unit normal vector must be taken inward-pointing
[17]. Combining (7) with condition (ii) we immediately
obtain E[C] = 0. Furthermore, since the unit normals
to A and B are time-like past-directed, we can use (i) to
show that both E[A] and E[B] are non-negative, so that
(8) implies
E[A] = E[B] = 0.
(9)
But this implies, recalling (ii), that δϕi must be zero
on all the sides of the triangle. Since we can make the
triangle arbitrarily long (A and C may extend to x =
+∞) and the side B may be arbitrarily close to the line
t = x (without crossing it, because B must be space-like),
we ﬁnally obtain
δϕi(t, x) = 0
for
x > t.
(10)
This shows that no perturbation can propagate outside
the light-cone, hence causality.

3
Physical interpretation - To be able to understand the
physical meanig of the argument above, we need ﬁrst to
have an intuitive interpretation of Ea.
Within the usual interpretation of entropy as uncer-
tainty, in the sense that S reﬂects our ignorance, inter-
preted as lack of information [18], about the exact sys-
tem’s microstate (recall Boltzmann’s formula S = ln Γ,
where Γ is the number of microscopic realizations of a
given macrostate), the deﬁnition (1) can be rewritten as
E =
 Ignorance at
equilibrium

−
 Ignorance in the
perturbed state

.
(11)
Hence, E is the net information carried by the pertur-
bation. The Gibbs stability criterion (E ≥0), then, is
the statement that any perturbation increases our knowl-
edge about the microstate. Now, if we look at equation
(2) and invoke the condition (ii), it follows that we can
identify Ea with the current of information transported
by the perturbation [19]. In fact, if Ea = 0 in a given
region of space R, then the average value of any observ-
able on R coincides with the microcanonical average (i.e.
the equilibrium value). Since the microcanonical ensem-
ble assigns equal a priori probability to every microstate,
there is no information in R. The reader can see Sup-
plementary Material for a more rigorous proof that Ea is
the current of information.
Now that we have an interpretation of Ea, let us ex-
amine the conditions (i) and (iii). The latter is just the
second law of thermodynamics, as seen from the point of
view of information theory: our initial information about
the microstate of the system can only be lost (or trans-
ported from one place to another) in time, but never cre-
ated, because all the initial conditions tend, as t →+∞,
to the same ﬁnal macrostate (the equilibrium). However,
the most interesting condition for us is (i): it is easy to
show that imposing (i), namely that the density of in-
formation is non-negative, is equivalent to requiring that
Ea is time/light-like future-directed, namely
EaEa ≤0
E0 ≥0.
(12)
This is where the contact with causality is established.
In fact, if information is transported by a non-space-like
four-current, it propagates along causal trajectories and
cannot exit the light-cone. This is the most fundamental
deﬁnition of causality.
The inverse argument - At this point it is natural to
ask whether we can reverse the argument and show that
causality implies stability. This is in general not true (see
e.g. [11]). In fact, let us assume that we still have an in-
formation current Ea, deﬁned by equation (2), and that
conditions (ii) and (iii) are valid (they are typically en-
sured by construction when there is an entropy current).
The causality requirement reduces to imposing that Ea is
time/light-like, but this does not specify its orientation.
It might be the case that Ea, for some conﬁgurations, is
FIG. 2. Visualization of the geometric argument for the the-
orem of Bemﬁca et al. [7]. All the edges of the triangle ABC
are space-like. We create an arbitrary initial perturbation (in
red) on the side C. Since A is outside the causal future of C,
we are free to set the initial perturbation to zero on A. The in-
verse temperature four-vector βa (dark green) is aligned with
the t-axis. The light green arrows are a Euclidean represen-
tation of the unit normals to the edges.
past-directed, generating instability. Thus, in general
(Causality)
=⇒
/
(i).
However, to ﬁx the orientation we only need to assume
that there is a preferred reference frame in which E0 ≥0
∀δϕi. It is natural, and it usually simpliﬁes the calcula-
tions, to take this reference frame to be aligned with the
equilibrium inverse-temperature four-vector βa, which al-
ways exists, is unique and is time-like future-directed [20–
22]. Hence, we can conclude that
(Causality)
+
(Eaβa ≤0)
=⇒
(i),
which leads to the theorem of Bemﬁca et al. [7].
We can also give a more rigorous geometrical proof of
this result, considering the triangle in ﬁgure 2, assum-
ing causality and that Eaβa ≤0. The setting is simi-
lar to that of the previous geometric argument, however,
note that now (t, x) is not an arbitrary inertial frame,
but it has been chosen is such a way that βa ∝δa
t. Fur-
thermore, the arbitrary initial perturbation has now been
freely imposed on the side C of the triangle and not on
the x-axis. Again we can apply the Gauss theorem, to
obtain
E[A] + E[B] + E[C] ≤0.
(13)
Since there is no perturbation on A, we know that E[A] =
0. Furthermore, given that the normal to B is
na[B] = −
βa
p
−βbβb
,
(14)
we can use the condition Eaβa ≤0 to show that E[B] ≥
0. Hence, we have
−E[C] ≥E[B] ≥0 .
(15)

4
However, noting that E[C] is computed taking the nor-
mal to C future-directed, as in ﬁgure 2, we conclude that
−E[C] quantiﬁes the information contained in C. Its pos-
itiveness, for any possible choice of initial perturbation
on C and for any possible triangle (having the properties
described in ﬁgure 2), leads to (i) and hence to stability.
Example 1: perfect ﬂuids - We conclude the letter with
some examples. Consider the information current of a
perfect ﬂuid (5), assuming that δσ = 0 to the ﬁrst order.
Then, the condition of stability in the ﬂuid rest frame
reduces to (note that ua = Tβa)
−Eaua = (ρ + p)δubδub
2
+
(δp)2
2(ρ + p)c2s
≥0.
(16)
This produces the conditions ρ + p > 0 (positive inertial
mass [23]) and c2
s ≥0 (stability of the ﬂuid against com-
pression), which exist also in the Newtonian theory. The
causality requirement EaEa ≤0 reads explicitly
(ρ + p)δubδub +
(δp)2
(ρ + p)c2s
± 2δp
p
δubδub ≥0,
(17)
which produces the well-known condition c2
s ≤1 (sublu-
minal speed of sound). The reader might be surprised
that this condition turns out to be also a stability con-
dition.
After all, a sound-wave that propagates faster
than light is still governed by a wave equation, hence its
amplitude should remain bounded over time. However,
again we need to remember that a system is thermody-
namically stable if it is stable also to virtual processes.
One can verify that a virtual process in which the am-
plitude of a sound-wave grows with time increases the
entropy of the ﬂuid in all those reference frames in which
the sound-wave moves backwards in time, generating an
instability. Indeed, it is well-known that if a causal mi-
croscopic Lagrangian produces an eﬀective macroscopic
ﬂuid theory with c2
s > 1, then the equilibrium state is un-
stable and the perfect ﬂuid description is not applicable,
because high frequency modes must grow [24–26].
Example 2: Cattaneo equation - As a second example
we consider a rigid inﬁnite solid bar (1+1 dimensions in
ﬂat spacetime), with uniform density, and we model the
heat propagation within extended irreversible thermody-
namics [27]. We take the ﬁelds (ϕi) = (T, q), representing
temperature and heat ﬂux, as degrees of freedom and im-
pose, in the rest-frame of the solid, the conservation law
ncp∂tT + ∂xq = 0.
(18)
The (t, x) components of the entropy current are postu-
lated to be
sa =

s −1
2χq2 , q
T

,
(19)
where s = s(T) is the equilibrium entropy density. Com-
bining the conservation law (18) and the constitutive re-
lation (19), one can show (just apply the technique of
[10]) that the information current is
Ea =
 ncp(δT)2
2T 2
+ 1
2χ(δq)2 , δq δT
T 2

.
(20)
Now, the requirement Et > 0 for δϕi ̸= 0 immediately
produces the stability conditions
cp > 0
χ > 0,
(21)
the ﬁrst ensuring stability to heat diﬀusion [1], the second
to ﬂuctuations of q. The requirement that Ea should not
be space-like (EaEa ≤0) produces
1
χncpT 2 ≤1.
(22)
This is, indeed, the causality condition of the model (but
it is also an important stability condition, see [28], Ap-
pendices 3-4).
In fact, if we postulate an information
annihilation rate ∇aEa = −(δq)2/(κT 2) ≤0 (κ is the
positive heat conductivity coeﬃcient), the resulting lin-
earised ﬁeld equation is the Cattaneo equation
χncpT 2 ∂2
t δT −∂2
xδT + ncp
κ ∂tδT = 0,
(23)
whose characteristic maximum signal propagation speed
is (χncpT 2)−1/2. Again, we see that the causality condi-
tion is merely thermodynamic (it involves only thermo-
dynamic coeﬃcients) and is unaﬀected by the value of the
kinetic coeﬃcient κ. In fact, while causality is a geomet-
ric constraint on the direction of the information current,
κ only quantiﬁes the rate at which the information is de-
stroyed. In the limit in which κ →+∞, heat does not
propagate inﬁnitely fast. Instead, information becomes a
conserved quantity, and (23) becomes a non-dissipative
causal wave equation.
Example 3: kinetic theory - All our results remain valid
also in ideal-gas kinetic theory: one only needs to replace
the ﬁelds ϕi = ϕi(x) with the invariant distribution func-
tion f = f(x, p), counting the number of particles in a
small phase-space volume centered on (x, p). The entopy
current, particle current and stress-energy tensor of the
gas are (working in local inertial coordinates)
{ sa , N a , T ab } =
Z
{ σ , f , fpb } pa gs d3p
p0
,
(24)
where gs is the spin degeneracy and σ = σ(f) is a func-
tion that the depends on the type of particle (distinguish-
able, bosons or fermions).
The equilibrium states are
given by
dσ
df = −α −βbpb
α = const, βb Killing.
(25)
The information current can be computed using the for-
mula Ea = −δsa −α δN a −βb δT ab (see Supplementary
Material for the proof) and is given by
Ea = −
Z d2σ
df 2
δf 2
2
pa gs d3p
p0
.
(26)

5
Imposing that Ea is time/light-like future directed for
any δf produces the conditions
papa ≤0
d2σ
df 2 < 0 .
(27)
The ﬁrst condition (subluminal motion of particles) is
a well-known causality requirement.
However, it also
constitutes a stability condition, because hypothetical
tachyons would be able to bounce (as a result of colli-
sions) backwards and forward in time an unlimited num-
ber of times, arbitrarily increasing their apparent num-
ber with no energy cost. This would generate a tachyon
condensation instability, analogous to the one observed in
ﬁeld theories [25]. The second condition is the ubiquitous
concavity requirement for the entropy function [29, 30],
which is obeyed by every classical and quantum statistics
(including anyons [31], in 2+1 dimensions).
Conclusions - The implications of this work are
twofold. On the practical side, it shows that the entropy-
based stability criterion developed in [10] is enough also
to ensure causality, simplifying considerably the job of
testing the reliability of a theory. On the more theoreti-
cal side, it reveals the central importance of the informa-
tion current Ea in relativistic hydrodynamics, shedding a
new light on the role of information theory in a relativis-
tic context. The reason why it took so long to achieve
this understanding is that the focus has been up to now
on trying to connect causality with hydrodynamic sta-
bility, while the real connection is with thermodynamic
stability, which is a much more complete reliability cri-
terion.
This work was supported by the Polish National Sci-
ence Centre grants SONATA BIS 2015/18/E/ST9/00577
and OPUS 2019/33/B/ST9/00942.
Partial support
comes from PHAROS, COST Action CA16214.
LG
thanks Masoud Shokri and Giorgio Torrieri for stimu-
lating discussions.
[1] D. Kondepudi and I. Prigogine, Modern Thermodynamics
(John Wiley and Sons, Ltd, 2014).
[2] M. E. Peskin and D. V. Schroeder, An introduction to
quantum ﬁeld theory (Addison-Wesley, Reading, USA,
1995).
[3] R. Geroch and L. Lindblom, Phys. Rev. D 41, 1855
(1990).
[4] W. A. Hiscock and L. Lindblom, Annals of Physics 151,
466 (1983).
[5] T. S. Olson, Annals of Physics 199, 18 (1990).
[6] R. Geroch and L. Lindblom, Annals of Physics 207, 394
(1991).
[7] F. S. Bemﬁca, M. M. Disconzi,
and J. Noronha, arXiv
e-prints , arXiv:2009.11388 (2020), arXiv:2009.11388 [gr-
qc].
[8] G. S. Denicol, T. Kodama, T. Koide,
and P. Mota,
Journal of Physics G Nuclear Physics 35, 115102 (2008),
arXiv:0807.3120 [hep-ph].
[9] S. Pu, T. Koide,
and D. H. Rischke, Phys. Rev. D 81,
114039 (2010).
[10] L. Gavassino, arXiv e-prints , arXiv:2104.09142 (2021),
arXiv:2104.09142 [gr-qc].
[11] M.
Kiamari,
M.
Rahbardar,
M.
Shokri,
and
N. Sadooghi, arXiv e-prints , arXiv:2102.11695 (2021),
arXiv:2102.11695 [hep-th].
[12] The stationarity of the spacetime guarantees the conser-
vation of the total energy of the ﬂuid associated with the
Killing ﬁeld.
[13] By on-shell we mean “along solutions of the ﬁeld equa-
tions”, by oﬀ-shell we mean“independently from the ﬁeld
equations”.
[14] H. B. Callen, Thermodynamics and an introduction to
thermostatistics; 2nd ed. (Wiley, New York, NY, 1985).
[15] P.
Kovtun,
G.
D.
Moore,
and
P.
Romatschke,
Phys. Rev. D 84, 025006 (2011), arXiv:1104.1586 [hep-
ph].
[16] G. Torrieri, Journal of High Energy Physics 2021, 175
(2021), arXiv:2007.09224 [hep-th].
[17] S. W. Hawking and G. F. R. Ellis, The Large Scale Struc-
ture of Space-Time, Cambridge Monographs on Mathe-
matical Physics (Cambridge University Press, 2011).
[18] E. T. Jaynes, Phys. Rev. 106, 620 (1957).
[19] To avoid confusion, we remark that, chosen a ﬂuid ele-
ment X, Ea[X] does not describe the ﬂow of information
relative to the microstate of X (this would be given by
sa[X, ϕi] −sa[X, ϕi + δϕi], where sa is the entropy cur-
rent). Instead, Ea[X] quantiﬁes the ﬂow of information
relative to the microstate of the whole ﬂuid that we can
extract by performing measurements on X.
[20] F. Becattini, Phys. Rev. Lett. 108, 244502 (2012).
[21] F. Becattini, Acta Physica Polonica B 47, 1819 (2016),
arXiv:1606.06605 [gr-qc].
[22] L.
Gavassino,
Found.
Phys.
50,
1554
(2020),
arXiv:2005.06396 [gr-qc].
[23] C. W. Misner, K. S. Thorne,
and J. A. Wheeler, San
Francisco: W.H. Freeman and Co., 1973 (1973).
[24] M. Ruderman, Phys. Rev. 172, 1286 (1968).
[25] Y. Aharonov, A. Komar,
and L. Susskind, Phys. Rev.
182, 1400 (1969).
[26] S. A. Bludman and M. A. Ruderman, Phys. Rev. D 1,
3243 (1970).
[27] D. Jou, J. Casas-V´azquez,
and G. Lebon, Reports on
Progress in Physics 51, 1105 (1999).
[28] L. Gavassino, M. Antonelli,
and B. Haskell, Physical
Review D 102 (2020), 10.1103/physrevd.102.043018.
[29] H. S. Leﬀ, The Physics Teacher 50, 170 (2012).
[30] J. Amig´o, S. Balogh, and S. Hern´andez, Entropy 20, 813
(2018).
[31] Y.-S. Wu, Phys. Rev. Lett. 73, 922 (1994).
[32] W. Israel and J. Stewart, Annals of Physics 118, 341
(1979).
[33] K. Huang, Statistical Mechanics, 2nd ed. (John Wiley &
Sons, 1987).

6
Supplementary Material
Here we prove some properties of the current Ea presented in the main text. In particular we show that:
• Ea is unique;
• For simple ﬂuids, Ea is given by Ea = −δsa −αδN a −βbδT ab;
• If the theory is causal and stable, Ea is the current of information carried by the perturbation.
Assumptions and notation
We work in the physical setting described in [10], adopting also the same notation, according to which ϕi are the
(macroscopic) ﬁelds in equilibrium and ϕi + δϕi are the ﬁelds in a perturbed state. For a generic observable A, its
perturbation is deﬁned as
δA = A[ϕi + δϕi] −A[ϕi].
(28)
The background spacetime is ﬁxed (hence δgab = 0) and has one and only one independent symmetry generator Ka,
which is assumed time-like future-directed. In equilibrium it is possible to deﬁne the inverse temperature four-vector
ﬁeld βa = ua/T (uaua = −1) and the chemical potential scalar ﬁeld µ, such that [21]
µ
T = α
βa = βKa
α, β = const
β > 0.
(29)
The complete set of possibly independent conserved (i.e. divergence-free) currents of the system is
{ f(T)βa , sa , N a , T abKb , δN a , δT abKb } ,
(30)
where sa, N a and T ab are entropy current, particle current and symmetric stress-energy tensor. The scalar f(T) is
an arbitrary function of the temperature. The conservation of f(T)βa, for any f, follows from the fact that βa is a
Killing vector ﬁeld.
Uniqueness
Let us prove that the vector ﬁeld Ea = Ea[ϕi, δϕi], deﬁned through equations (1) and (2) of the main text and
satisfying the conditions (i,ii,iii), is unique. To show it, we will assume that there are two vector ﬁelds Ea and ˜Ea
which satisfy all the requirements and we will verify that they must be identical.
First of all, we note that, for equations (1) and (2) of the main text to be valid for any space-like Cauchy 3D-surface
Σ, we must require (using the Gauss theorem)
∇aEa = ∇a ˜Ea = −∇a δsa.
(31)
It follows that the diﬀerence za := Ea −˜Ea is a conserved current (∇aza = 0). But since (30) is a basis for all
the independent conserved currents that we can can build out of ϕi and δϕi, it follows that za must be a linear
combination of them (with constant coeﬃcients hj):
za = h0f(T)βa + h1sa + h2N a + h3T abKb + h4δN a + h5δT abKb.
(32)
Condition (ii) implies that wherever the perturbation is absent we must have Ea = ˜Ea = za = 0, hence h0 = h1 =
h2 = h3 = 0 and we can write
za = h4δN a + h5δT abKb.
(33)
Finally, we note from condition (i) that, under the transformation δϕi →−δϕi, the sign of Ea and ˜Ea cannot change.
Hence za (like Ea and ˜Ea) is a second-order quantity in the perturbations δϕi. However, both δN a and δT ab contain
non-zero ﬁrst-order contributions, so that the only way for za to be of second order is that h4 = h5 = 0. This implies
that za = Ea −˜Ea = 0, completing our proof.

7
Thermodynamic interpretation
If the current Ea is unique, there must be a general thermodynamic formula for it. Here we compute it. From (31)
it immediately follows that wa := Ea + δsa is a conserved current (∇awa = 0), which again implies
wa = m0f(T)βa + m1sa + m2N a + m3T abKb + m4δN a + m5δT abKb
yj = const.
(34)
Since both Ea and δsa are zero wherever the perturbation is absent, we must impose m0 = m1 = m2 = m3 = 0 and
we can write
Ea = −δsa + m4δN a + m5δT abKb.
(35)
This relation is indeed consistent with the identity δsa = (zfc) −Ea invoked in [10]. We are left with the problem of
determining the value of the constant coeﬃcients m4 and m5. In order to compute them, we consider a small region
of space R (i.e. a small space-like 3D-surface element) which is locally orthogonal to Ka. The particles, energy and
entropy contained in R are
{N , U , S } =
Z
R
{ N a , −δT abKb , δsa } na
p
|γ| d3y
na past-directed,
(36)
so that equation (35), truncated to the ﬁrst order in the perturbation (namely neglecting Ea), implies
δS = m4δN −m5δU.
(37)
If we work in local inertial coordinates aligned with Ka (and R is suﬃciently small) then,
U = −
Z
R
T abKbna
p
|γ| d3y = K
Z
R
T 00 d3x
K =
p
−KbKb.
(38)
This implies that U/K is the internal energy (diving by the red-shift factor K we eﬀectively remove the gravita-
tional potential energy) as measured by a local inertial observer moving with four-velocity ua, so that from standard
thermodynamics we know that (to the ﬁrst order)
δS = −µ
T δN + δU
KT .
(39)
Comparing (37) with (39) we ﬁnally obtain
m4 = −µ
T
m5 = −1
KT .
(40)
Inserting them into (35) we have our formula for the information current:
Ea = −δsa −αδN a −βbδT ab.
(41)
This formula is, indeed, not unexpected. In fact, since Ea must be a pure second-order quantity, the ﬁrst-order
truncation of (41) produces the identity
δsa = −αδN a −βbδT ab ,
(42)
which is Israel’s condition of equilibrium [32].
We ﬁnally note that, if we multiply (41) by T, we are able to deﬁne a new current
δΩa = TEa = −ubδT ab −Tδsa −µδN a ,
(43)
whose ﬂux across R is
δΩ= δU
K −TδS −µδN.
(44)
But this is nothing but the perturbation to the grand potential of the region R at ﬁxed T and µ. So, the condition
(i), which implies δΩ≥0, in the end reduces to the statement that the grand potential of small ﬂuid elements is
minimised in equilibrium. Also this result is not surprising, as we may regard the volume element R as a small system
which can exchange both energy and particles with a large environment (the rest of the ﬂuid) at temperature T with
chemical potential µ.

8
Current of information
The ﬁnal result that we want to prove is that Ea is the current of information carried by the perturbation δϕi.
First of all we need to state precisely how we quantify the information. We deﬁne our ignorance about the state
of a system as the natural logarithm of the number of microstates in which the system can be, compatibly with our
knowledge. We assume that the energy and the number of particles of the system are known to be in the intervals
[U, U + ∆U] and [N, N + ∆N], with ∆E ≪E and ∆N ≪N, so that the maximum amount of ignorance possible is
the microcanonical entropy. If we make a measurement of a property of the system, our ignorance is reduced by an
amount that we call information.
Following this line of thoughts, we can deﬁne the amount of information I[R, ϕi, δϕi] carried by a perturbation
δϕi, contained in a region of space R, as the information that we would gain about the system (about the system as a
whole, not just about the region R) measuring all the macroscopic ﬁelds ϕi +δϕi on R, assuming to have no previous
knowledge (apart from that of U and N and hence of the equilibrium ﬁelds ϕi, which are microcanonical averages, so
they do not constitute additional knowledge). Thus, it follows from the deﬁnition that
I[R, ϕi, δϕi] = −ln
Γ[U, ∆U, N, ∆N, ϕi + δϕi on R]
Γ[U, ∆U, N, ∆N]

with
Γ = (number of microstates).
(45)
Now we only need to rewrite the right-hand side as a hydrodynamic integral. We call Rc (namely, the complementary
of R) an arbitrary portion of space such that
R ∪Rc = Σ
R ∩Rc = ∅,
(46)
where Σ is a smooth space-like Cauchy 3D-surface. Then we can use Boltzmann’s formula for the entropy and make
the identiﬁcations
ln Γ[U, ∆U, N, ∆N, ϕi + δϕi on R] = S[R, ϕi + δϕi] +
max
δϕi on Rc S[Rc, ϕi + δϕi]
ln Γ[U, ∆U, N, ∆N] = S[Σ, ϕi] .
(47)
The maximum in the ﬁrst formula appears because Γ[U, ∆U, N, ∆N, ϕi + δϕi on R] constrains only the value of δϕi
on R, while it sums over all the admissible choices of δϕi outside R (in the thermodynamic limit the conﬁguration δϕi
that maximizes the entropy dominates the sum [33]). In addition, note that, in the computation of the maximum, we
are not completely free to choose δϕi on Rc because the perturbation needs to conserve the total energy and particle
number (which are known). Thus we must impose the constraint
δU[Rc, ϕi, δϕi] = −δU[R, ϕi, δϕi] =: −δUR
δN[Rc, ϕi, δϕi] = −δN[R, ϕi, δϕi] =: −δNR .
(48)
Combining (45), (47) and (48), recalling the formula (41), we obtain
I[R, ϕi, δϕi] = E[R, ϕi, δϕi] +
min
δϕi on Rc E[Rc, ϕi, δϕi].
(49)
Finally, let us study the second term on the right-hand side. To derive a qualitative upper bound on its typical value
we can restrict our attention to conﬁgurations δϕi on Rc which are approximately homogeneous across the domain
occupied by the ﬂuid, namely
(δϕi)on Rc ∼const .
(50)
This is possible only if the theory is causal: in acausal theories the initial data imposed on R might propagate on Rc,
producing unphysical constraints on δϕi. To estimate the order of magnitude of (δϕi)on Rc, assuming (50), we can
use equation (48), recalling that ϕi are intensive variables, to derive the estimates
V (δϕi)on R ∼{δNR , δUR } ∼Vc (δϕi)on Rc ,
(51)
with
V =
 Volume
of R

V + Vc =

Total volume
occupied by the ﬂuid

.
(52)

9
These estimates, in turn, can be used to show that (recall that Ea is quadratic in the perturbation)
V E[R, ϕi, δϕi] ∼V 2 (δϕi)2
on R ∼V 2
c (δϕi)2
on Rc ∼Vc E[Rc, ϕi, δϕi] .
(53)
Hence, we have obtained the qualitative bound
0 ≤
min
δϕi on Rc E[Rc, ϕi, δϕi] ≲V
Vc
E[R, ϕi, δϕi] ,
(54)
where the ﬁrst inequality is a consequence of stability. In the limit in which the region R is inﬁnitely small compared
to the size of the whole ﬂuid (namely V ≪Vc), equation (49) reduces to
I[R, ϕi, δϕi] = E[R, ϕi, δϕi] =
Z
R
Ea[ϕi, δϕi] na
p
|γ| d3y ,
(55)
proving that Ea can be interpreted as the current of information.

