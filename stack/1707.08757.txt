J. Lang (Ed.): TARK 2017
EPTCS 251, 2017, pp. 415–425, doi:10.4204/EPTCS.251.30
c⃝Philippe Mongin
This work is licensed under the
Creative Commons Attribution License.
Bayesian Decision Theory and Stochastic Independence
Philippe Mongin
CNRS & HEC Paris
mongin@greg-hec.com
Stochastic independence has a complex status in probability theory. It is not part of the deﬁnition of
a probability measure, but it is nonetheless an essential property for the mathematical development
of this theory. Bayesian decision theorists such as Savage can be criticized for being silent about
stochastic independence. From their current preference axioms, they can derive no more than the
deﬁnitional properties of a probability measure. In a new framework of twofold uncertainty, we
introduce preference axioms that entail not only these deﬁnitional properties, but also the stochastic
independence of the two sources of uncertainty. This goes some way towards ﬁlling a curious lacuna
in Bayesian decision theory.
1
Introduction and preview
The property of stochastic (or statistical) independence occupies a rather special place in the mathemat-
ical theory of probability. It does not belong to the properties that this theory singles out to deﬁne a
probability measure axiomatically. It is indeed a property of given events for a given probability mea-
sure, and its adoption can only result from a modelling choice to ﬁt the particular situation. At the same
time, probability theory obviously uses independence assumptions extensively; they are needed for such
major results as the Laws of Large Numbers, various theorems on stochastic processes, and some central
results of statistical theory. For Kolmogorov [14] himself, the inventor of the axiomatic deﬁnition, this
property occupies a ”central position in the theory of probability” (1933-1950, p. 8). One would thus
expect all theories of the foundations of probability to pay careful attention to stochastic independence,
but curiously, this is not the case with Bayesian decision theory, one of the most inﬂuential among these
theories.
Bayesian decision theorists claim that an agent’s uncertain beliefs should be represented be a prob-
ability measure and ground this claim on a pragmatic argument. They formally show that if the agents’
preferences over uncertain prospects - typically, but not exclusively over monetary bets - obey certain
requirements of practical rationality, these agents’ beliefs should conform to the axiomatic deﬁnition of a
probability measure. Bayesian decision theorists hardly go beyond this demonstration, and in particular
have nothing to add on stochastic independence. Thus, they can be criticized for falling short of justifying
the probability calculus as it actually works and stopping too early in their foundational work.
More technically, Bayesian decision theorists prove a representation theorem for preferences over
uncertain prospects that involves two sets of quantities, utilities (over the consequences of prospects)
and probabilities (over the uncertain events), these two items being combined by the familiar rule of
expected utility (EU). After Ramsey’s and de Finetti’s sketches, this strategy was implemented in full
detail by Savage (1954) [19]. In a subsequent simpliﬁcation of Savage’s system, Anscombe and Aumann
(1963) [1] took some probability values for granted in order to obtain the remaining ones more easily. All
these authors derive a prior probability measure to represent initially uncertain beliefs. Savage (1954-
1972, p. 44) extends this argument to obtain a posterior probability measure, i.e., one that represents
beliefs after a partial resolution of uncertainty, and he shows that this posterior obeys Bayes’s rule of

416
Bayesian Decision Theory and Stochastic Independence
revision; literally, the ”Bayesian” label becomes fully justiﬁed only at this stage. This is also where
Savage stops. He however acknowledges that a treatment of stochastic independence should have come
next.
Two comments in Savage make this point clearly. Having axiomatized a qualitative probability rela-
tion, he complains that ”the notions of independence and irrelevance have ... no analogues in qualitative
probability; this is surprising and unfortunate, for these notions seem to evoke a strong intuitive response”
(1954-1972, p. 44). Later, he reiterates the complaint differently: ”it would be desirable, if possible, to
ﬁnd a simple qualitative personal description of independence between events” (p. 91). (Savage prefers
the expression of ”personal probability” to the more received one of ”subjective probability”.) In today’s
Bayesian theory, the ﬁrst comment is not justiﬁed anymore. There now exist richer systems of qualita-
tive probability than Savage’s, in which a special relation serves to express the stochastic independence
of two events or two random variables (see Domotor, 1969 [5], Fine, 1971 [6], Kaplan and Fine, 1977
[12], Luce and Nahrens, 1978 [15], to cite but the early papers). However, the second comment is still
topical. We understand it as referring to preferences over uncertain prospects, i.e., the ultimate primitive
in Savage’s construction. To the best of our knowledge, Bayesian decision theory has not yet explicated
stochastic independence in terms of this overarching concept.
The present paper is an attempt to do so. We assume that there are two distinctive sources of un-
certainty, and accordingly that states of nature have the form of two-component vectors. As in Savage
and in Anscombe and Aumann, we deﬁne uncertain prospects to be mappings from states of the world
to consequences, and take the agent’s preferences over these prospects to be the only axiomatic prim-
itive. Our construction leans towards Anscombe and Aumann by considering a ﬁnite number of states
and by making a structural assumption on consequences (they are real numbers). However, it also leans
towards Savage because we eschew any numerical data, hence Anscombe and Aumann’s questionable
trick of taking some probability values for granted. The twofold uncertainty framework has recently been
introduced by Mongin and Pivato (2016) [17] with a theoretical purpose different from the present one.1
Our axioms entail that there exists an EU representation for the agent’s preferences, and that the
probability measure in this representation decomposes multiplicatively on the two sources of uncertainty,
which establishes their stochastic independence. The same uniqueness conditions hold as in standard
EU representation theorems. A heuristic argument indicates where to locate the stochastic independence
property in our preference axioms. They state that, for either source of uncertainty, there exist preferences
conditional on each value this source can take, and moreover that these conditional preferences are
invariant across possible values. This heuristically means that the realization of one of the two uncertainty
components does not affect the agent’s preferences over those prospects which only depend on the other,
still unknown component. In a betting interpretation, if the initial bets relate, say, to tomorrow’s weather
and tomorrow’s economic conditions, and the agent somehow comes to know what tomorrow’s weather
will be, this does not affect the agent’s preferences amongst bets on tomorrow’s economic conditions,
and vice-versa.
We offer two representation theorems along the lines just explained. The ﬁrst adapts a result al-
ready obtained in Mongin and Pivato (2015) [16]. We develop it here because it neatly exempliﬁes how
Bayesian decision theory can approach stochastic independence. Although this theorem implements the
heuristics of last paragraph, it is, in a subtle sense to be explained, not yet entirely satisfactory. Hence
we propose a second representation theorem, which is the technical novelty of this paper. Section 2 adds
further motivations. Sections 3 and 4 state the two representation theorems respectively. Section 5 returns
1That paper aims at offering a solution to the classic problem of deﬁning a normatively compelling notion of social prefer-
ence under uncertainty.

Philippe Mongin
417
to conceptual comments and comparisons, while also sketching directions for future work.
2
Further motivating the approach
A corn producer must decide how much land to cultivate while not knowing what the climatic conditions
and the state of demand for corn will be at the time of the harvest. Each cultivation policy can be
analyzed as an uncertain prospect, i.e., a mapping from the unknown states to the possible consequences,
here monetary proceeds. We will develop this example along a Bayesian theorist’s line, and heuristically
reason backwards, taking for granted what the Bayesian theorist would conclude, plus the target property
of stochastic independence. Recall the textbook deﬁnition since Kolmogorov: given a probability space
(Ω,A ,P), two events A,B in A are said to be stochastically (or statistically) independent if P(A∩B) =
P(A).P(B). From this deﬁnition, others, which are equally standard, follow concerning collections of
events or random variables.
Assuming for simplicity that climate and demand take two values, we ﬁx two sets S = {s1,s2} and
T = {t1,t2} and deﬁne a state of nature to be any element of the product set S × T. We now apply
stochastic independence to each possible pair of events (subsets) {s}×T and S ×{t}, or by an obvious
identiﬁcation, to each possible pair (s,t). The producer’s probabilities are thus given by the matrix:
t1
t2
s1
ps1qt1
ps1qt2
s2
ps2qt1
ps2qt2
where (ps1, ps2) and (qt1,qt2) are probability vectors on S and T, respectively. Now, a policy X for the
producer can be represented by its monetary proceeds in the various states:
X
t1
t2
s1
x11
x12
s2
x21
x22
Denote by ≿the producer’s preferences over policies X. The EU representation for ≿is
V(X) = ps1qt1u(x11)+ ps1qt2u(x12)+ ps2qt1u(x21)+ ps2qt2u(x22).
This can be restated either as:
(∗) V(X) = ps1 [qt1u(x11)+qt2u(x12)]+ ps2 [qt1u(x21)+qt2u(x22)],
or as:
(∗∗) V(X) = qt1 [ps1u(x11)+ ps2u(x21)]+qt2 [ps1u(x12)+ ps2u(x22)].
The bracketed sums in (∗) contain utility representations for conditional preferences on the possible
values of s, and those in (∗∗) contain utility representations for conditional preferences on the possible
values of t. Thus, the overall conclusions entail that (i) conditional preferences are orderings. Since the
same functional form qt1u(.)+qt2u(.) appears in the two bracketed sums of (∗), and similarly, the same
functional form ps1u(.)+ ps2u(.) appears in the two bracketed sums of (∗∗), these conclusions also entail
that (ii) conditional preferences are the same for different s, and the same for different t. Lastly, from
the same equations, if the conditional orderings for both s1 and s2, or the conditional orderings for both
t1 and t2, agree to rank prospect X above prospect Y, then the overall preference ≿ranks X above Y.
Thus, the conclusions also entail that (iii) preferences over prospects are increasing with respect to either
family of conditional preferences.

418
Bayesian Decision Theory and Stochastic Independence
Importantly, we have stated (i), (ii) and (iii) by abstracting from the EU representation. Each of
these properties can indeed be satisﬁed by more general theories than Bayesian decision theory, and in
particular, the dominance property (iii) is well-known to apply to most existing alternatives (like rank-
dependent theory, see, e.g., Wakker, 2010 [21]).
In the ﬁrst result, we assume (i), (ii) and (iii), plus some background conditions. Given the formal
deﬁnition of a conditional, which is restated below, it is actually possible to fuse (i) with (iii) and obtain
an even more condensed system. One may wonder how apparently weak necessary conditions for the
representation turn out also to be sufﬁcient for it. The key point is that the conditions apply to s and t
at the same time, and this creates the possibility of representing the preference ≿both in terms of s-
conditionals and t-conditionals; comparing these representations leads to the results. Their equivalence
shows in the fact that either the ps or the qt can be factored out from the same sum - see (∗) and (∗∗).
3
A ﬁrst representation theorem for stochastic independence
Formally, there are two variables of interest, s ∈S and t ∈T, and a state of the world is any pair (s,t) ∈
S ×T; we thus permit the two variables to vary together in any possible way. For technical reasons, we
take S and T to be ﬁnite with cardinalities |S|, |T| ≥2. Prospects X are mappings from states (s,t) to
real numbers x, and we deﬁne the set of prospects to be RS×T, thus putting no constraint on what counts
as a prospect. The sets of all probability functions on S, T and S × T are denoted by ∆S, ∆T and ∆S×T,
respectively.
It is convenient to represent prospects X as |S| × |T| matrices, with each s standing for a row and
each t standing for a column. We will thus write X = [xt
s]t∈T
s∈S , but sometimes also X = (x1,...,x|S|), where
each component is a row vector xs ∈RT, or X = (x1,...,x|T|), where each component is a column vector
xt ∈RS.
By assumption, the agent compares prospects in terms of an ex ante preference relation ≿. As a
maintained assumption, we take this relation to be a continuous weak ordering, hence representable by
a continuous utility function. The other preference relations are obtained from ≿as conditionals. There
are three families of conditionals to consider, i.e., {≿s}s∈S, {≿t}t∈T and {≿st}s∈S,t∈T. The last family
represents ex post preferences, and the ﬁrst two represent interim preferences, since each relation in these
families depends on ﬁxing one variable and letting the other vary, and this amounts to resolving only part
of the uncertainty.
We now formally deﬁne the various conditionals in terms of the master relation ≿. The conditional
of ⪰on s ∈S is the relation ⪰s on RT deﬁned by the property that for all xs,ys ∈RT,
xs
⪰
s ys iff X ≿Y
for some X,Y
∈
RS×T s.t. xs is the s-row of X, ys is the s-row of Y,
and X and Y are equal outside their s-row.
Similarly, the conditional of ⪰on t ∈T is the relation ≿t on RS deﬁned by the property that for all
xt,yt ∈RS ,
xt
≿
t yt iff X ≿Y
for some X,Y
∈
RS×T s.t. xt is the t-column of X, yt is the t-column of Y,
and X and Y are equal outside their t-column.

Philippe Mongin
419
By themselves, these deﬁnitions do not make conditionals weak orderings. By a well-known fact of de-
cision theory, ⪰s is a weak ordering if and only if the choice of X,Y in the deﬁnition of ⪰s is immaterial,
or more precisely, if and only if X ≿Y ⇐⇒X′≿Y′ when X′,Y′ also satisfy the condition stated for X,Y
in this deﬁnition. When this holds, ⪰is said to be weakly separable in s. By another well-known fact,
weak separability in a factor (or set of factors) is equivalent to the property that ≿is increasing with the
conditional on this factor (or the conditionals of the set of factors). That is to say, for all X,Y ∈RS×T,
if xs ⪰s ys for all s, then X ≿Y; and if moreover xs ≻s ys for some s, then X ≻Y.2 Everything said for
s of course applies to t. Combining the two well-known facts, we see that conditions (i) and (iii) of the
previous section can be fused into the single requirement that all ⪰s and all ⪰t are weak orderings.3
The conditional of ⪰on (s,t) ∈S × T is deﬁned similarly. Since this conditional ≿st compares
real numbers, it makes sense to identify it with the natural order of these numbers. This amounts to
saying that numbers represent desirable quantities, be they money values, as in the producer example,
or something else. Thus, as another maintained assumption, we require that for all (s,t) ∈S ×T and all
xt
s,yt
s ∈R,
xt
s ≿st yt
s iff xt
s ≥yt
s.
Since this turns the ≿st into an ordering, ≿is increasing with each of these conditionals, hence also with
each entry xt
s of X.
Let us say that the family {≿s}s∈S ( {≿t}t∈T) is invariant if ≿s= ≿s′ for all s,s′ ∈S (resp. ≿t= ≿t′
for all t,t′ ∈T). Such requirements capture condition (ii) of previous section. Notice they are not needed
for the ≿st since these are identical relations by construction.
We are now ready for a representation theorem.
Theorem 1 The following conditions are equivalent:
• The conditionals ≿s and ≿t are weak orderings for all s ∈S and all t ∈T, and each family of
conditionals is invariant.
• There are an increasing, continuous function u : R −→R, and strictly positive probability functions
p ∈∆S and q ∈∆T, such that ⪰is represented by the function V : RS×T−→R that computes the
p⊗q-expected value of u, i.e., by the function deﬁned as follows: for all X = [xt
s]t∈T
s∈S ,
V(X) := ∑
s∈S∑
t∈T
ps qtu(xt
s).
In this format of EU representation, p and q are unique, and u is unique up to positive afﬁne transforma-
tions.
As was foreshadowed, the representation theorem combines the conclusions of Bayesian decision
theory with the desired property that the probability measure (here a vector) is multiplicative in the two
sources. This theorem is Corollary 1(c) in Mongin and Pivato (2015) [16], but recast autonomously and
in a different formal language, so as to facilitate the discussion of stochastic independence.
2By ≻, we mean the strict preference associated with the weak preference ⪰, and similarly for for ≻s, ≻t and ≻st.
3For these deﬁnitions and basic facts, see Fishburn (1970) [7], Keeney and Raiffa (1976) [13], and Wakker (1989) [22].

420
Bayesian Decision Theory and Stochastic Independence
4
A second representation theorem for stochastic independence
In Theorem 1, strong results follow from a compact list of assumptions, undoubtedly a feature of mathe-
matical elegance, but also a cause for conceptual dissatisfaction. Would it not be better to expand on the
assumptions and separate those which are responsible for the existence of the EU representation and those
which account for the stochastic independence property occurring in this representation? This disentan-
gling would make sense on two counts: stochastic independence is an optional property of probability
measures (a logical point) and Bayesian decision theory invests only the existence, not the properties, of
such measures with universal rationality signiﬁcance (a normative point). However, the assumptions of
Theorem 1 cannot be divided in the appropriate way. This can be seen as follows. By taking the ≿s and
≿t to be merely orderings, not invariant orderings, one would get an additively separable representation
that does not separate the utility and probability components of the added terms. By taking only one of
the two families to satisfy the ordering and invariance assumptions, one would only get a representation
that is only separable in that family and says nothing on probabilities either.4
Fortunately, we can obtain a relevant partitioning of assumptions if we enrich the decision-theoretic
framework beyond the present, two-dimensional stage. Let us suppose that the agent pays attention not
only to the uncertainty dimensions s and t of the ﬁnal consequences, but also to a third, heuristically
unrelated dimension i, so that these consequences are now represented by real numbers xi
st. The added
dimension can be interpreted as being the time at which these consequences occur, and the corn producer
decision problem can easily be reformulated accordingly. For technical reasons, we require i to take its
values in a ﬁnite set I with cardinality |I| ≥2.
Given this added dimension, alternatives become mappings from triples (s,t,i) to the reals, that is
three-dimensional arrays,
X =

xt
s
i∈I
s∈S,t∈T ∈RS×T×I,
which may be rewritten as
X = (X1,...,X|S|), X =(X1,...,X|T|) or X = (X1,...,X|I|),
where the components are matrix-valued, i.e., Xs = (xi
st)i∈I
t∈T ∈RT×I, Xt = (xi
st)i∈I
s∈S ∈RS ×I and Xi =
(xi
st)s∈S ,t∈T ∈RS ×T respectively.
With i representing time, alternatives should be viewed as contingent plans, i.e., plans whose con-
sequences in a given period depend on the way the uncertainty - still represented by (s,t) - is resolved
in that period. The matrix-valued objects just listed are interpreted in terms of partly contingent plans
(when one dimension of uncertainty is ﬁxed) or dated prospects (when the time dimension is ﬁxed).
Vector-valued objects can also be interpreted - e.g., the xst = (xi
st)i∈I ∈RI as non-contingent plans.5
4The additively separable representation of the ﬁrst case reads as
∑
s∈S,t∈T
vst(xt
s),
with increasing and continuous vst : R →R, s ∈S,t ∈T. In the second case, if the assumptions only hold for the ≿s, the
separable representation reads as
W(V1(x1),...,V|S|(x|S|)),
with increasing and continuous W : RS →R and Vs : RT →R, s ∈S. These partial results follow from standard results in
separability theory.
5It is essential for these interpretations that each period is uncertain in the same way as any other, i.e., no interaction exists
between the resolution of uncertainty and the passing of time.

Philippe Mongin
421
We assume the agent compares contingent plans in terms of a preference relation ≿, which is a
continuous weak ordering, and this relation gives rise to conditional relations that are deﬁned as in the
previous section, mutatis mutandis. Among the seven families of conditionals, we pay special attention
to {≿s}s∈S, {≿t}t∈T,

≿i	i∈I, {≿st}s∈S,t∈T and

≿i
st
	i∈I
s∈S,t∈T. The ≿s and ≿t compare plans Xs and Xt,
respectively; the ≿i compare dated prospects Xi, the ≿st non-contingent plans xst and the ≿i
streal-valued
consequences. As before, we assume that each ≿i
st coincides with the natural order of real numbers, and
that all other relations may or may not be weak orderings, and may or may not form an invariant family.
Theorem 2 The following conditions are equivalent:
• The conditionals ≿i and ≿st are weak orderings, and the ≿st family is invariant.
• There are increasing, continuous functions ui : R −→R, for all i ∈I, and a strictly positive proba-
bility function π ∈∆S×T, such that ⪰is represented by the functionW : RS×T×I−→R that computes
the π-expected value of ∑i∈I ui, i.e., the function thus deﬁned: for all X = [xt
s]i∈I
s∈S,t∈T ,
(∗) W(X) :=
∑
s∈S,t∈T∑
i∈I
πst ui(xi
st).
In this format of representation, π is unique, and the ui are unique up to positive afﬁne transformations
with a common multiplier.
Moreover, the following are equivalent:
• The assumptions made above on the ≿i and ≿st hold, and furthermore the ≿s are weak orderings
and an invariant family.
• The same conclusions hold, and moreover there are strictly positive probability functions p ∈∆S
and q ∈∆T with π = p⊗q, so that (∗) becomes: for all X = [xt
s]i∈I
s∈S,t∈T ,
(∗∗) W(X) = ∑
s∈S∑
t∈T∑
i∈I
ps qtui(xi
st).
In this alternative format, p and q are unique, while the ui have the same uniqueness properties as before.
Proof.
(Sketch). The ﬁrst part follows from Theorem 1 in Mongin and Pivato (2015) [16]; we leave
it for the reader to check that the assumptions of this theorem apply here. For the second part, we ﬁrst
observe that, for every given s ∈S, the W(X) representation delivers a function RT×I →R
∑
t∈T∑
i∈I
πstui(xi
st)
that represents the weak ordering ≿s. If we deﬁne π′
st := πst/∑t∈T πst for all t ∈T, the function
∑
t∈T∑
i∈I
π′
stui(xi
st)
is also a representation of ≿s. Now ﬁx s0 ∈S. By the invariance of the ≿s family, for every s ∈S, there
is a strictly increasing transformation Φs s.t.
∑
t∈T∑
i∈I
π′
s0t ui(xi
st) = Φs
 
∑
t∈T∑
i∈I
π′
stui(xi
st)
!
.

422
Bayesian Decision Theory and Stochastic Independence
As the ui are strictly increasing and continuous, Φs is R →R, and we can apply a functional equation
argument (Rado and Baker, 1987 [18]) and conclude that the Φs are positive afﬁne transformations. I.e.,
for all s ∈S, there exist numbers αs > 0 and βs s.t.
∑
t∈T∑
i∈I
π′
s0t ui(xi
st) = αs
 
∑
t∈T∑
i∈I
π′
stui(xi
st)
!
+βs.
After redeﬁning the functions so as to dispense with the constant terms, we see that, for all s ∈S and
t ∈T, π′
s0t = αsπ′
st, and in fact (since proportional probability vectors are equal) π′
s0t = π′
st. We thus
rewrite (∗) as
∑
s∈S ,t∈T∑
i∈I
π′
s0t (∑
t∈T
πst)(ui(xi
st),
which is (**) if one takes p = (∑t∈T πst)s∈S and q = (π′
sot)t∈T. The uniqueness of p and q in this format
of representation is easily established.
The two steps of Theorem 2 correspond to the EU representation theorem and the addition made by
stochastic independence, respectively. Interestingly, the same assumption - that of invariant conditional
orderings - underlies both conclusions, but in the richer framework adopted here, it is possible to apply
it twice over, thus separating each step. Note also that it is enough to apply the assumption to the ≿st
and one of the two ≿s and ≿t families; then, as the representation shows, the other family automatically
satisﬁes this assumption (the ≿t can of course be interchanged with the ≿s in the theorem statement).
5
Interpretations, comparisons and future directions
The following heuristic argument will help locate the preference ancestor of stochastic independence
more precisely. Considering only four states for simplicity, we suppose that the agent considers (s1,t1)
more likely that (s1,t2), and (s2,t1) less likely than (s2,t2). That is, from knowing how the uncertainty
on s is resolved, the agent draws an inference on how the uncertainty on t would be resolved. If the
agent reasoned probabilistically, the joint probabilities would of course not decompose multiplicatively.
We now check that the s-conditional preferences cannot be invariant. Take ξ,ξ ′ representing desirable
quantities, with ξ > ξ ′, and the following prospects in matrix form:
X
t1
t2
s1
ξ
ξ ′
s2
ξ ′
ξ
and
Y
t1
t2
s1
ξ ′
ξ
s2
ξ
ξ ′
.
The ﬁrst line of X, which puts the best consequence on the more likely state, should be preferred to the
ﬁrst line of Y, which puts it on the less likely state. By a similar comparison, the second line of X should
be preferred to the second line of Y. Thus, the two s-conditional preferences differ. Contraposing the
argument, we see that invariant s-preferences express a one-way form of informational independence,
i.e., that observing s does not bring any information on t. The opposite one-way form, i.e., that observing
t does not bring any information on s, would be expressed by invariant t-preferences. The two invariance
conditions together convey a sense of mutual informational independence.
This concept of independence actually underlies one of the two main informal explications of stochas-
tic independence, the other relying on the very different concept of mutual causal independence6. Today’s
6The causal explication of stochastic independence is actually the older and more established of the two. On the problematic
linkage of stochastic independence with causality, see Spohn (1980) [20].

Philippe Mongin
423
probability texts sometimes entangle the two independence concepts, and it is perhaps one virtue of the
above axiomatization to bring out the informational concept in a way that precludes any confounding
with its causal competitor. Our betting agents may or may not be inﬂuenced by what they perceive of
causal relations, but this is irrelevant, given that only their decisions matter to the analysis. However,
the informational concept and associated informal explication can be pursued in various ways, and our
axiomatization more speciﬁcally contributes to giving both a pragmatic slant. Generally, when it comes
to the epistemic aspects of probability, a divide appears between theorists who would like to explore
these aspects per se, and Bayesian decision theorists, who absorb them into their practical rationality
concerns.7
The introduction sketched a comparison with two such theorists that can now be made precise. We
share with Anscombe and Aumann (1963) [1] not only the two assumptions of a ﬁnite set of states
and a structured set of consequences, but also that of two distinctive sources of uncertainty. However,
unlike them, we do not suppose that one of these sources already has a probabilistic representation, a
question-begging assumption from the perspective of Bayesian decision theory, since this would require
a preference derivation for every kind of probability. Our completely preference-based approach likens
it to Savage’s (1954) [19] despite the technical dissimilarities concerning the set of states and set of
consequences, as well as an axiomatic difference we now clarify. The assumptions in Theorems 1 and
2 that certain conditionals are orderings amount to replacing his postulate P2, i.e., the notorious ”sure-
thing principle”, by a dominance principle, which is weaker and more generally accepted. However, to
make good for this loss, we had to revise his other postulates, and this was done by the way in which
we state the invariance of the orderings in question. Savage’s P3 requires that conditional preferences
be invariant across all possible conditioning events, but only when these preferences compare constant
prospects. We require invariance only for some events, but - crucially - for any comparison of prospects,
whether these are constant or not. The other event-invariance condition of Savage, P4, has no role to play
here, because it serves to order an unstructured consequence set, while ours inherits the order structure
of real numbers.8
The results of this paper may be extended in several directions. One of them is conditional probabil-
ity, and the corresponding deﬁnition of stochastic independence in terms of this concept rather than that
of joint probability. Conditional prospects can be introduced into the preference apparatus with relevant
preference axioms. Such a variation is unlikely to make much difference to the conclusions, but it would
be judged preferable by those probability theorists and philosophers who, unlike Kolmogorov, regard
conditional probability as the genuine primitive of the probability calculus.9 Another, conceptually more
problematic direction is one-sided stochastic independence. Such a concept appears rarely, if ever, in
probability theory. In our preference framework, it is possible to express the idea that s does not bring any
information on t whereas t may bring information on s; it is enough to assume that the s-conditionals are
invariant, while not assuming that the t-conditionals are. However, Theorem 2 teaches us in effect that,
if the preference assumptions endow (s,t) with a probabilistic representation, one-sided informational
independence automatically entails mutual informational independence. This suggests that the issue of
one-sided stochastic independence may be impossible to pursue in the present framework; which other
preference framework would facilitate its investigation is unclear. Last but not least, stochastic indepen-
7Joyce (1998) [11] has made this divide very clear, while adopting the former position.
8The difference with earlier results in Bayesian decision theory is also one of mathematical techniques. The proofs of
Theorems 1 and 2 depend on additive separability arguments; see Mongin and Pivato (2015 [16], 2016 [17]), and for the source
papers, Debreu (1960) [4] and Gorman (1968) [10].
9This is a common line to take, especially among philosophers of probability; in connection with stochastic independence,
see Fitelson and Hajek (2014) [8].

424
Bayesian Decision Theory and Stochastic Independence
dence has been reconsidered in the currently active work on multiple (or ”imprecise”) probabilities, and
it would be an interesting project to connect one or more of the deﬁnitions given to it in this work with a
decision-theoretic apparatus; the latter would of course not be Bayesian in the usual sense. Some steps
have been taken in this direction, but much work still remains to be done.10
Acknowledgements. Many thanks for conceptual and technical comments to Lorraine Daston, Mar-
cus Pivato, the audience of a seminar at the Munich Center for Mathematical Philosophy, and three
TARK referees. The author also gratefully acknowledges the hospitality of the Max Planck Institut f¨ur
Wissenschaftsgeschichte zu Berlin when he developed this project.
References
[1] F. J. Anscombe & R. J. Aumann (1963): A deﬁnition of subjective probability. The Annals of Mathematical
Statistics 34(1), pp. 199–205, doi:10.1214/aoms/1177704255.
[2] S. Bade (2008): Stochastic independence with maxmin expected utilities. Penn State University, Mimeo.
[3] F. G. Cozman (2012): Sets of probability distributions, independence, and convexity. Synthese 186(2), pp.
577–600, doi:10.1007/s11229-011-9999-0.
[4] G. Debreu (1959): Topological methods in cardinal utility theory. In K. J. Arrow, S. Karlin & P. Suppes,
editors: Mathematical Methods in the Social Sciences, Stanford University Press, pp. 16–26.
[5] Z. Domotor (1969): Probabilistic relational structures and their applications. Technical Report 144, Stanford
University, Institute for Mathematical Studies in the Social Sciences.
[6] T. L. Fine (1973): Theories of Probability. Academic Press.
[7] P. C. Fishburn (1970): Utility Theory for Decision Making. Wiley.
[8] B. Fitelson & A. H´ajek (2014): Declarations of independence. Synthese, doi:10.1007/s11229-014-0559-2.
[9] P. Ghirardato (1997): On independence for non-additive measures, with a Fubini theorem. Journal of Eco-
nomic Theory 73(2), pp. 261–291, doi:10.1006/jeth.1996.2241.
[10] T. W. Gorman (1968): The structure of utility functions. The Review of Economic Studies 35(4), pp. 367–390,
doi:10.2307/2296766.
[11] J. M. Joyce (1998): A Non-Pragmatic Vindication of Probabilism. Philosophy of Science 65, pp. 575–603,
doi:10.1086/392661.
[12] M. Kaplan & T. L. Fine (1977): Joint orders in comparative probability. The Annals of Probability, pp.
161–179, doi:10.1214/aop/1176995843.
[13] R. L. Keeney & H. Raiffa (1993): Decisions with multiple objectives: preferences and value trade-offs.
Cambridge University Press, doi:10.1017/CBO9781139174084.
[14] A. N. Kolmogorov (1950): Foundations of the Theory of Probability. Chelsea Publishing Co. Original as
Grundbegriffe der Wahrscheinlichkeitsrechnung, in Ergebnisse der Mathematik und ihrer Grenzgebiete, 3,
1933.
[15] R. D. Luce & L. Narens (1978): Qualitative independence in probability theory. Theory and Decision 9(3),
pp. 225–239, doi:10.1007/BF00133452.
[16] P. Mongin & M. Pivato (2015): Ranking multidimensional alternatives and uncertain prospects. Journal of
Economic Theory 157, pp. 146–171, doi:10.1016/j.jet.2014.12.013.
[17] P. Mongin & M. Pivato (2016): Social preference under twofold uncertainty. Technical Report Research
Paper No. ECO/SCD-2016-1154, HEC Paris.
10See in particular Ghirardato (1997) [9] and Bade (2008) [2]. Cozman (2012) [3] surveys different ways in which stochastic
independence can be redeﬁned when beliefs are represented by sets of probabilities.

Philippe Mongin
425
[18] F. Rad´o & J. A. Baker (1987): Pexider’s equation and aggregation of allocations. Aequationes Mathematicae
32(1), pp. 227–239, doi:10.1007/BF02311311.
[19] L. J. Savage (1954): The Foundations of Statistics. John Wiley. Revised edition, 1972.
[20] W. Spohn (1980): Stochastic independence, causal independence, and shieldability. Journal of Philosophical
logic 9(1), pp. 73–99, doi:10.1007/BF00258078.
[21] P. Wakker (2010): Prospect Theory. Cambridge University Press, doi:10.1017/CBO9780511779329.
[22] P. Wakker (2013): Additive Representations of Preferences: A New Foundation of Decision Analysis. 4,
Springer Science & Business Media, doi:10.1007/978-94-015-7815-8.

