Swarm Intell (2018) 12:283–305
https://doi.org/10.1007/s11721-018-0157-x
Informative and misinformative interactions in a school
of ﬁsh
Emanuele Crosato1,5
· Li Jiang2,3 · Valentin Lecheval3,4 · Joseph T. Lizier1 ·
X. Rosalind Wang5 · Pierre Tichit3 · Guy Theraulaz3 · Mikhail Prokopenko1
Received: 25 November 2017 / Accepted: 1 March 2018 / Published online: 8 March 2018
© Springer Science+Business Media, LLC, part of Springer Nature 2018
Abstract Quantifying distributed information processing is crucial to understanding collec-
tive motion in animal groups. Recent studies have begun to apply rigorous methods based on
information theory to quantify such distributed computation. Following this perspective, we
use transfer entropy to quantify dynamic information ﬂows locally in space and time across
a school of ﬁsh during directional changes around a circular tank, i.e., U-turns. This analy-
sis reveals peaks in information ﬂows during collective U-turns and identiﬁes two different
ﬂows: an informative ﬂow (positive transfer entropy) from ﬁsh that have already turned to
ﬁsh that are turning, and a misinformative ﬂow (negative transfer entropy) from ﬁsh that have
not turned yet to ﬁsh that are turning. We also reveal that the information ﬂows are related
to relative position and alignment between ﬁsh and identify spatial patterns of information
and misinformation cascades. This study offers several methodological contributions and we
expect further application of these methodologies to reveal intricacies of self-organisation in
other animal groups and active matter in general.
Keywords Collective animal behaviour · Collective motion · Fish interactions ·
Information dynamics
Electronic supplementary material The online version of this article (https://doi.org/10.1007/s11721-
018-0157-x) contains supplementary material, which is available to authorized users.
B Emanuele Crosato
emanuele.crosato@sydney.edu.au
1
Complex Systems Research Group and Centre for Complex Systems, Faculty of Engineering & IT,
The University of Sydney, Sydney, NSW 2006, Australia
2
School of Systems Science, Beijing Normal University, Beijing 100875, People’s Republic of China
3
Centre de Recherches sur la Cognition Animale, Centre de Biologie Intégrative (CBI), Centre
National de la Recherche Scientiﬁque (CNRS), Université Paul Sabatier (UPS), 31062 Toulouse
Cedex 9, France
4
Groningen Institute for Evolutionary Life Sciences, Centre for Life Sciences, University of
Groningen, Nijenborgh 7, 9747AG Groningen, The Netherlands
5
CSIRO Data61, PO Box 76, Epping, NSW 1710, Australia
123

284
Swarm Intell (2018) 12:283–305
1 Introduction
Collective motion is one of the most striking examples of aggregated coherent behaviour in
animal groups, dynamically self-organising out of local interactions between individuals. It
is observed in different animal species, such as schools of ﬁsh (Parrish et al. 2002; Sumpter
et al. 2008), ﬂocks of birds (Lissaman and Shollenberger 1970; May 1979; Ballerini et al.
2008; Bialek et al. 2012), colonies of insects (Buhl et al. 2006; Fourcassié et al. 2010; Buhl
et al. 2010; Attanasi et al. 2014b; Buhl and Rogers 2016) and herds of ungulates (Ginelli et al.
2015). There is an emerging understanding that information plays a dynamic role in such a
coordination (Sumpter et al. 2008), and that distributed information processing is a speciﬁc
mechanism that endows the group with collective computational capabilities (Bonabeau et al.
1999; Couzin 2009; Albantakis et al. 2014).
Information transfer is of particular relevance for collective behaviour, where it has been
observed that small perturbations cascade through an entire group in a wave-like man-
ner (Potts 1984; Procaccini et al. 2011; Herbert-Read et al. 2015; Attanasi et al. 2015),
with these cascades conjectured to embody information transfer (Sumpter et al. 2008). This
phenomenon is related to underlying causal interactions, and a common goal is to infer phys-
ical interaction rules directly from experimental data (Katz et al. 2011; Gautrais et al. 2012;
Herbert-Read et al. 2011) and measure correlations within a collective.
Nagy et al. (2010) used a variety of correlation functions to measure directional depen-
dencies between the velocities of pairs of pigeons ﬂying in ﬂocks of up to 10 individuals,
extended to 30 in Nagy et al. (2013), reconstructing the leadership network of the ﬂock.
As has been shown, this network does not correspond to the dominance hierarchy between
birds (Nagy et al. 2013). Information transfer has been extensively studied in ﬂocks of star-
lings, by observing the propagation of direction changes across the ﬂocks (Cavagna et al.
2013b,a; Attanasi et al. 2014a). More recently, Rosenthal et al. (2015) attempted to deter-
mine a communication structure of a school of ﬁsh during its collective evasion manoeuvres
manifested through cascades of behavioural change. A functional mapping between sensory
inputs and motor responses was inferred by tracking ﬁsh position and body posture, and
calculating visual ﬁelds.
The main scientiﬁc question we address is how to identify and quantify information pro-
cessing during decision-making in groups (Giardina 2008; Attanasi et al. 2014a), exacerbated
by misinformative and noisy data. In trying to obtain such understanding, it is impor-
tant to develop predictive models of information propagation among individuals, including
behavioural cascades. Speciﬁcally, we aim to reveal how information propagates within
a group and affects collective decisions (e.g., choosing a common travelling direction).
This would provide an objective way to use such information for predictive modelling of
behavioural reactions in response to various inputs.
Rather than consider semantic or pragmatic information, many contemporary studies
employ rigorous information-theoretic measures that quantify information as uncertainty
reduction, following Shannon (Cover and Thomas 2006), in order to deal with the stochastic,
continuous and noisy nature of intrinsic information processing in natural systems (Feldman
et al. 2008). Distributed information processing is typically dissected into three primitive
functions: the transmission, storage and modiﬁcation of information (Langton 1990). Infor-
mation dynamics is a recent framework characterising and measuring each of the primitives
information-theoretically (Lizier et al. 2014; Lizier 2013). In viewing the state update dynam-
ics of a random process as an information processing event, this framework performs an
information regression in accounting for where the information to predict that state update
123

Swarm Intell (2018) 12:283–305
285
can be found by an observer, ﬁrst identifying predictive information from the past of the pro-
cess as information storage, then predictive information from other sources as information
transfer (including both pairwise transfer from single sources, and higher-order transfers due
to multivariate effects). The framework has been applied to modelling collective behaviour
in several complex systems, such as Cellular Automata (Lizier et al. 2008, 2010, 2012),
Ising spin models (Barnett et al. 2013), Genetic Regulatory Networks and other biological
networks (Lizier et al. 2011b; Prokopenko et al. 2011; Faes and Porta 2014), and neural
information processing (Gómez et al. 2014; Wibral et al. 2015).
This study proposes a domain-independent, information-theoretic approach to detecting
and quantifying individual-level dynamics of information transfer in animal groups using
this framework. This approach is based on transfer entropy (Schreiber 2000), an information-
theoretic measure that quantiﬁes the directed and time-asymmetric predictive effect of one
random process on another. We aim to characterise the dynamics of how information transfer
is conducted in space and time within a biological school of ﬁsh (Hemigrammus rhodostomus
or rummy-nose tetras, Fig. 1a). Using transfer entropy allows us to consider speciﬁcally the
information dynamics during collective decision-making, identifying predictive information
ﬂows and their spatial patterns, complementing our parallel study which used correlation
analysis to identify inﬂuential neighbours (Jiang et al. 2017).
We stress that the predictive information transfer should be considered from the observer
perspective, that is, it is the observer that gains (or loses) predictability about a ﬁsh motion,
having observed another ﬁsh. In other words, notwithstanding possible inﬂuences among
the ﬁsh that could potentially be reﬂected in their information dynamics, our quantitative
analysis focuses on the information ﬂow within the school which is detectable by an external
observer, captured by the transfer entropy. This means that, whenever we quantify a predictive
information ﬂow based on a source ﬁsh about a destination ﬁsh, we attribute the change
of predictability (uncertainty) to a third party, be it another ﬁsh in the school, a predator
approaching the school or an independent experimentalist. To improve readability, we refer to
ﬂow or transfer from a source ﬁsh to a destination ﬁsh. Importantly, this predictive information
ﬂow may or may not account for the causal information ﬂow affecting the source and the
destination (Ay and Polani 2008; Lizier and Prokopenko 2010)—however it does typically
indicate presence of causality, either within the considered pair or from some common cause.
We focus on collective direction changes, i.e., collective U-turns, during which the direc-
tional changes of individuals progress in a rapid cascade, at the end of which a coherent
motion is re-established within the school. Sets of different U-turns are comparable across
experiments under the same conditions, permitting a statistically signiﬁcant analysis involv-
ing an entire set of U-turns.
By looking at the pointwise or local values of transfer entropy over time, rather than at
its average values, we are not only able to detect information transfer, but also to observe
its dynamics over time and across the school. We demonstrate that information is indeed
constantly ﬂowing within the school, and identify the source-destination lag where predic-
tive information ﬂow is maximised (which has an interpretation as an observer-detectable
reaction time to other ﬁsh). The information ﬂow is observed to peak during collective direc-
tional changes, where there is a typical “cascade” of predictive gains and losses to be made
by observers of these pairwise information interactions. Speciﬁcally, we identify two distinct
predictive information ﬂows: (i) an “informative” ﬂow, characterised by positive local values
of transfer entropy, from ﬁsh that have already changed direction to ﬁsh that are turning, and
(ii) a “misinformative” ﬂow, characterised by negative local values of transfer entropy, from
ﬁsh that have not changed direction yet to the ﬁsh that are turning. Finally, we identify spa-
tial patterns coupled with the temporal transfer entropy, which we call spatio-informational
123

286
Swarm Intell (2018) 12:283–305
motifs. These motifs reveal spatial dependencies between the source of information and its
destination, which shape the directed pairwise interactions underlying the informative and
misinformative ﬂows. The strong distinction revealed by our quantitative analysis between
informative and misinformative ﬂows is expected to have an impact on modelling and under-
standing the dynamics of collective animal motion.
2 Information-theoretic measures for collective motion
The study of Wang et al. (2012) introduced the use of transfer entropy to investigations
of collective motion. This work quantitatively veriﬁed the hypothesis that information cas-
cades within an (artiﬁcial) swarm can be spatiotemporally revealed by conditional transfer
entropy (Lizier et al. 2008, 2010) and thus correspond to communications, while the collec-
tive memory can be captured by active information storage (Lizier et al. 2012).
Richardson et al. (2013) applied related variants of conditional mutual information, a
measure of non-linear dependence between two random variables, to identify dynamical
coupling between the trajectories of foraging meerkats. Transfer entropy has also been used
to study the response of schools of zebraﬁsh to a robotic replica of the animal (Butail et al.
2014; Ladu et al. 2015), and to infer leadership in pairs of bats (Orange and Abaid 2015) and
simulated zebraﬁsh (Butail et al. 2016). Lord et al. (2016) also posed the question of identi-
fying individual animals which are directly interacting with other individuals, in a swarm of
insects (Chironomus riparius). Their approach used conditional mutual information (called
“causation entropy” although it does not directly measure causality (Lizier and Prokopenko
2010)), inferring “information ﬂows” within the swarm over moving windows of time.
Unlike the study of Wang et al. (2012), the above studies quantiﬁed average dependencies
over time rather than local dependencies at speciﬁc time points; for example, leadership
relationships in general rather than their (local) dynamics over time. Local versions of transfer
entropy and active information storage have been used to measure pairwise correlations in a
“swarm” of soldier crabs, ﬁnding that decision-making is affected by the group size (Tomaru
et al. 2016). Statistical signiﬁcance was not reported, presumably due to a small sample size.
Similar techniques were used to construct interaction networks within teams of simulated
RoboCup agents (Cliff et al. 2017).
In this study, we focus on local (or pointwise) transfer entropy (Schreiber 2000; Lizier et al.
2008; Lizier 2014b) for speciﬁc samples of time series processes of ﬁsh motion, which allows
us to reconstruct the dynamics of information ﬂows over time. Local transfer entropy (Lizier
et al. 2008), captures information ﬂow from the realisation of a source variable Y to a
destination variable X at time n. As described in Sect. 5, local transfer entropy is deﬁned as
the information provided by the source yn−v = {yn−v, yn−v−1, . . . , yn−v−l+1}, where v is a
time delay and l is the history length, about the destination xn in the context of the past of
the destination xn−1 = {xn−1, xn−2, . . . , xn−k}, with a history length k:
ty→x(n, v) = log2
p(xn|xn−1, yn−v)
p(xn|xn−1)
.
(1)
Importantly, local values of transfer entropy can be negative, while the average transfer
entropy is non-negative. Negative values of the local transfer entropies indicate that the
source is misinformative about the next state of the destination (i.e., it increases uncertainty).
Previous studies that used average measures over sliding time windows in order to investigate
how information transfer varies over time (Richardson et al. 2013; Lord et al. 2016) cannot
detect misinformation because they measure average but not local values.
123

Swarm Intell (2018) 12:283–305
287
As an observational measure, transfer entropy does not measure causal effect of the source
on the target; this can only be established using interventional measures (Ay and Polani 2008;
Lizier and Prokopenko 2010; Chicharro and Ledberg 2012; Smirnov 2013). Rather, transfer
entropy measures the predictive information gained from a source variable about the state
transition in a target, which may be viewed as information transfer when measured on an
underlying causal interaction (Lizier and Prokopenko 2010). It should be noted that while
some researchers may be initially more interested in causality, the concept of information
transfer reveals much about the dynamics that causal effect does not (Lizier and Prokopenko
2010), in particular being associated with emergent local structure in dynamics in complex
systems (Lizier et al. 2008; Wang et al. 2012) and with changes in behaviour, state or regime
(Boedecker et al. 2012; Barnett et al. 2013), as well as revealing the misinformative inter-
actions described above. As a particular example, local transfer entropy spatiotemporally
highlights emergent glider entities in cellular automata (Lizier et al. 2008), which are ana-
logues of cascading turning waves in swarms (also highlighted by transfer entropy (Wang
et al. 2012)), while local measures of causality do not differentiate these from the background
dynamics (Lizier and Prokopenko 2010).
In general, to understand the processes that govern collective behaviour in animal groups, it
is important to disentangle the interactions between ﬁsh, how these interactions are combined
and how interrelated are the individual behaviours. This can be achieved much more easily by
investigatingcollectivebehaviourinsmallgroupsofindividuals.Suchmethodology(Gautrais
et al. 2012; Weitz et al. 2012) has been successfully applied to studies of the individual-level
interactions involved in several examples of collective animal behaviour: aggregation in
cockroaches (Jeanson et al. 2004, 2005), division of labour, corpse aggregation and nest
building in ant colonies (Theraulaz et al. 2002a,b; Khuong et al. 2016), collective motion
in groups of pelagic ﬁsh (Gautrais et al. 2012; Weitz et al. 2012) and collective motion in
human groups (Moussaïd et al. 2009, 2011). Although for schools of minnows (Phoxinus
phoxinus), two ﬁsh schools are qualitatively different from schools containing three or more,
the effects seem to level off by the time the school reaches a size of six individuals (Partridge
1980). Collective behaviour, as well as a stereotypical “phase transition”, when an increase
in density leads to the onset of directional collective motion, have also been detected in small
groups of six glass prawns (Paratya australiensis) (Mann et al. 2012). Furthermore, at such
intermediate group sizes, it has been observed that multiple ﬁsh interactions could often be
faithfully factorised into pair interactions in one particular species of ﬁsh (Gautrais et al.
2012). The rationale for choosing a limited number of ﬁsh is also strengthened by the fact
that it allowed us to quantify both the dynamics of collective decisions at the group level
and the predictive information ﬂow, while preserving the coordination of swimming in this
species that exhibits strong schooling behaviour.
In our study, we investigated information transfer within a school of ﬁsh during speciﬁc
collective direction changes, i.e., U-turns, in which the school collectively reverses its direc-
tion. Groups of ﬁve ﬁsh were placed in a ring-shaped tank (Fig. 1b), a design conceived to
constrain ﬁsh swimming circularly, with the possibility of undergoing U-turns spontaneously,
without any obstacles or external factors. A similar well-controlled environment has been
previously successfully used in studies of groups of locusts (Buhl et al. 2006), enabling a large
number of replicates which for obvious reasons cannot be done in a natural environment. The
choice of a small and cohesive group allows us to focus on pairwise interactions in the context
of collective motion, while studies of larger and less cohesive groups could reveal dominance
hierarchies and leader-follower relationships, as well as social inﬂuence in groups.
In many species of ﬁsh, sudden collective changes of the state of a school may happen
without external cause as a consequence of stochastic effects (Tunstrøm et al. 2013). In these
123

288
Swarm Intell (2018) 12:283–305
cases, local behavioural changes of a single individual can lead to large transitions between
collective states of the school, such as between the schooling and milling states (Calovi et al.
2015). Determining how ﬂuctuations in individual behaviour, for instance in heading direc-
tion, propagate within a group is a key to understanding transitions between collective states
in ﬁsh schools and in animal groups in general. In our setup, ﬁsh swim in a highly synchro-
nised and polarised manner, and can only head in two directions, clockwise or anticlockwise,
regularly switching from one to the other. Our work thus also allows us to analyse in groups
how individual U-turns occur, propagate through the group, and ultimately lead to collective
U-turns. A total of 455 U-turns have been observed during 10 trials of 1h duration each.
We computed local transfer entropy between each (directed) pair of ﬁsh from time series
obtained from ﬁsh heading. Speciﬁcally, the destination process X was deﬁned as the direc-
tional change of the destination ﬁsh, while the source process Y was deﬁned as the relative
heading of the destination ﬁsh with respect to the source ﬁsh (see Sect. 5). This allowed us
to capture the inﬂuence of the source-destination ﬁsh alignment on the directional changes
of the destination. Such inﬂuence is usually delayed in time and we estimated the optimal
delay [maximising ⟨ty→x(n, v)⟩n (Wibral et al. 2013), see Sect. 5] at v = 6, corresponding
to 0.12 s. The relative heading is not the only aspect of ﬁsh motion and other components
can be considered, such as speed and acceleration. Moreover, a heading change in the desti-
nation ﬁsh could be related to many aspects of the source ﬁsh motion other than the heading
difference between the two ﬁsh. However, in this study, we focus on the relative heading,
which we believe is one of the most relevant features to explore in our controlled setup. In
order to simplify our terminology, in the remainder of the text, we shall refer to this partial
information ﬂow, based on relative heading, as the information ﬂow. It is important to clarify
that large direction changes do not imply high values of transfer entropy, even while such
measure is based on the heading. Large direction changes (where they are rare events) may
have more capacity for information ﬂow; however, there is not necessarily large information
ﬂow at these events unless the source ﬁsh are predictive of their occurrence.
3 Results
3.1 Information ﬂows during U-turns
In order to represent the school’s orientation around the tank, we deﬁne its polarisation as
its circumferential velocity component, so that it is positive when the school is swimming
clockwise and negative when it is swimming anticlockwise (see Sect. 5). The better the
school’s average heading is aligned with an ideal circular trajectory around the tank, the
higher is the intensity of the polarisation. When the school is facing one of the tank’s walls,
for example in the middle of a U-turn, the polarisation is zero, and the polarisation ﬂips
sign during U-turns. Polarisation allows us to map local values of transfer entropy onto the
progression of the collective U-turns.
The analyses of transfer entropy over time reveal that the measure clearly diverges from
its baseline in the vicinity of U-turns, as shown in the representative U-turn in Fig. 1c (Sup-
plementary Figure S1 shows a longer time interval during which several U-turns can be
observed). The ﬁgure shows that during regular circular motion, when the school’s polari-
sation is highly pronounced, transfer entropy is low. As the polarisation approaches zero the
intensity of transfer entropy grows, peaking near the middle of a U-turn, when polarisation
switches its sign.
123

Swarm Intell (2018) 12:283–305
289
(a)
(b)
(c)
Fig. 1 Transfer entropy within the school during a U-turn. a Is a photo of a spontaneous U-turn initiated
by a single ﬁsh in a group of ﬁve Hemigrammus rhodostomus ﬁsh. b Shows the experimental ring-shaped
tank. c Plots the school’s polarisation during a U-turn and the detected transfer entropy over a time interval
of approximately 6 s. The purple line represents the school’s polarisation, while dots represent local values of
transfer entropy between all directed pairs of ﬁsh: red dots represent positive transfer entropy and blue dots
represent negative transfer entropy. Time is discretised in steps of length 0.02 s and for each time step 20
points of these local measures are plotted, for the 20 directed pairs formed out of 5 ﬁsh. The yellow lines in the
inset are the thresholds for considering a value of transfer entropy statistically different from zero (p < 0.05
before false discovery rate correction, see Sect. 5). Grey dots between these lines represent values that are not
statistically different from zero. Credits to David Villa ScienceImage/CBI/CNRS, Toulouse, 2015, for a, b
(Color ﬁgure online)
We clarify that the aim here is not to establish transfer entropy as an alternative to polarisa-
tion for detecting turn; rather, our aim is to use polarisation to describe the overall progression
of the collective U-turns and then to use transfer entropy to investigate the underlying infor-
mation ﬂows in the dynamics of such turns. Indeed, transfer entropy is found to be statistically
different from zero at many points outside of the U-turns (see Supplementary Figure S1),
although the largest values and most concentrated regions of these are during the U-turns.
This indicates that information transfer, based on the heading direction’s change, occurs
even when ﬁsh school together without changing direction; we know that the ﬁsh are not
executing precisely uniform motion during these in-between periods, and so interpret these
small amounts of information transfer as sufﬁciently underpinning the dynamics of the group
maintaining its collective heading. We would like to also point out that information process-
ing during the aligned motion mostly corresponds to the information storage, which can be
detected using other information-theoretic measures (Lizier et al. 2012), while only a low
information transfer is needed to maintain the alignment.
We also see in Fig. 1c thatboth positive and negative values of transfer entropy are detected.
In order to understand the role of the positive and negative information ﬂows during collective
motion, in the next section, we show the dynamics of transfer entropy for individual pairwise
interactions.
3.2 Informative and misinformative ﬂows
Our analysis revealed a clear relationship between positive and negative values of transfer
entropy and the sequence of individual ﬁsh turning, which is illustrated in Fig. 2. Figure 2a
123

290
Swarm Intell (2018) 12:283–305
(a)
(b)
(c)
(d)
(e)
(f)
Fig. 2 Positive and negative information ﬂows during a U-turn. a Shows the trajectories of the ﬁve ﬁsh during
the U-turn shown in c. The two black lines are the inner and the outer walls of the tank, and each of the ﬁve
trajectories coloured in different shades of purple correspond to a different ﬁsh: from darkest purple for the
ﬁrst ﬁsh turning (Fish 1), to the lightest purple for the last (Fish 5). The total time interval is approximately
2 s, during which all ﬁsh turn from swimming anticlockwise to clockwise. d Depicts the polarisations of
the ﬁve ﬁsh, showing the temporal sequence of ﬁsh turns. b Shows the ﬁsh trajectories again, but this time
indicates the value of the incoming local transfer entropy to each ﬁsh as a destination, averaged over the
other four ﬁsh as sources. The colour of each trajectory changes as the ﬁsh turn: strong red indicates intense
positive transfer entropy; strong blue indicates intense negative transfer entropy; intermediate grey indicates
that transfer entropy is close to zero. e Is obtained analogously to b, but the polarisations of the individual ﬁsh
are shown rather than their trajectories. c, f mirror b, e, but where the direction of the transfer entropy has been
inverted: the colour of each trajectory or polarisation now indicates the value of the outgoing local transfer
entropy from each ﬁsh as a source, averaged over the other four ﬁsh as destinations (Color ﬁgure online)
shows the trajectories of individual ﬁsh during the same U-turn depicted in Fig. 1c. These
trajectories are retraced in Fig. 2d in terms of polarisation of each ﬁsh. It is quite clear that
there is a well-deﬁned sequence of individual U-turns during the collective U-turn. Moreover,
Fig. 2 shows how the transfer entropy maps onto the ﬁsh trajectories, both from the ﬁsh whose
trajectory is traced as a source to the other four ﬁsh—i.e., outgoing transfer entropy—and,
vice versa, from the other four ﬁsh to the traced one as a destination—i.e., incoming transfer
entropy.
The incoming transfer entropy clearly peaks during the destination ﬁsh’s individual turns
and its local values averaged over all sources go from negative, for the ﬁrst (destination)
ﬁsh that turns, to positive for the last ﬁsh turning (Fig. 2b, e). In the opposite direction, the
outgoing transfer entropy (averaged over all destinations) displays negative peaks only before
the source ﬁsh has turned, and positive peaks only afterwards (Fig. 2c, f). Figure 2 suggests
that predictive information transfer intensiﬁes only when a destination ﬁsh is turning, with
this transfer being informative from source ﬁsh that have already turned and misinformative
from source ﬁsh that have not turned yet.
This phenomenon can be observed very clearly in Fig. 3a, b, which show the transfer
entropy in both directions for a single ﬁsh (the second ﬁsh turning in Figs. 1 and 2). One
positive peak of incoming transfer entropy (indicating informative ﬂow) and three negative
ones (misinformative ﬂows) are detected when this ﬁsh, as a destination, is undergoing the
U-turn (Fig. 3a). No other peaks are detected for this ﬁsh as a destination. On the other hand,
one negative peak of outgoing transfer entropy is detected before the ﬁsh, this time as a
123

Swarm Intell (2018) 12:283–305
291
(a)
(b)
(c)
(d)
Fig. 3 a Shows the polarisation of the second ﬁsh turning, together with the incoming transfer entropy to that
ﬁsh as the destination, with the other four ﬁsh as the sources: red dots represent positive values and blue dots
represent negative values. b Mirrors a, but with the outgoing transfer entropy from that ﬁsh as the source, and
the other four ﬁsh as destinations. In c, each purple line corresponds to a ﬁsh, with the shade again reﬂecting
the order in which the ﬁsh turn (darkest for ﬁrst ﬁsh to turn, and lightest for the last). Now however (in c), rather
than corresponding to a single U-turn event, the incoming local transfer entropy (to each ﬁsh as a destination,
averaged over the other four ﬁsh as sources) is averaged over all 455 observed U-turns and is shown as a
function of time. The horizontal axis is the relative time of the U-turns, with zero being the time when the
average polarisation of the school changes sign. d Mirrors c, but where the direction of the transfer entropy
has been inverted (showing outgoing transfer from each ﬁsh in turning order) (Color ﬁgure online)
source, has turned, and three positive peaks are detected after the ﬁsh has turned (Fig. 3b).
These four peaks occur respectively when the ﬁrst, the third, the fourth and the ﬁfth ﬁsh
undergo the U-turn, as is evident by comparing Figs. 2d, 3b. A movie of the ﬁsh undergoing
this speciﬁc U-turn is provided in Supplementary Video S1, while a detailed reconstruction
of the U-turn, showing the dynamics of transfer entropy over time for each directed pair of
ﬁsh, is provided in Supplementary Video S2.
In order to demonstrate that the phenomenon described here holds for U-turns in general,
and not only for the representative one shown in Fig. 2, we performed an aggregated analysis
of all 455 U-turns observed during the experiment. Since the order in which ﬁsh turn is not
the same in every U-turn, in this analysis, we refer not to single ﬁsh as individuals, but rather
to ﬁsh in the order in which they turn. Thus, when we refer, for instance, to “the ﬁrst ﬁsh
that turns”, we may be pointing to a different ﬁsh at each U-turn. It is worth noting that, in
general, multiple ﬁsh can turn at the same time during a U-turn, but averaging over all U-turn
events allows us to statistically order turning events, as shown in Fig. 3c, d.
The aggregated results are presented in Fig. 3c, d. Figure 3c shows that incoming transfer
entropy peaks for each ﬁsh in turning order and gradually grows, from a minimum negative
peak corresponding to the ﬁrst ﬁsh turning, to a maximum positive peak corresponding to
the last ﬁsh turning. Vice versa, Fig. 3d shows that outgoing transfer entropy peaks only
positively for the ﬁrst ﬁsh turning, which is an informative source about all other ﬁsh turning
afterwards. For the last ﬁsh that turns the peak is negative, since this ﬁsh is misinformative
about all other ﬁsh that have already turned. The second, third and fourth ﬁsh present both a
123

292
Swarm Intell (2018) 12:283–305
negative and a positive peak. The intensity of the negative peaks increases from the second
ﬁsh to the fourth, while the intensity of the positive peak decreases.
In general, the source ﬁsh is informative about all destination ﬁsh turning after it and
misinformative about any destination ﬁsh turning before it. This is because the prior turn of
a source helps the observer to predict the later turn of the destination, whereas examining
a source which has not turned yet itself is actively unhelpful (misinformative) in predicting
the occurrence of such a turn. This also explains why, for a source, the negative peaks come
before positives.
The sequential cascade-like dynamics of information ﬂow suggests that the strongest
sources of predictive information transfer are ﬁsh that have already turned. Moreover, our
analyses reveal that once a ﬁsh has performed a U-turn, its behaviour in general ceases to be
predictable based on the behaviour of other ﬁsh that swim in opposite direction (in fact such
ﬁsh would provide misinformative predictions). This suggests an asymmetry of predictive
information ﬂows from and to an individual ﬁsh during U-turns.
3.3 Spatial motifs of information transfer
It is reasonable to assume that predictive information transfer in a school of ﬁsh results
from spatial interactions among individuals. We investigated the role of pairwise spatial
interactions in carrying the positive and negative information ﬂows that we detected in the
previous section, looking for spatial patterns of information and misinformation transfer.
In particular, we established the statistics of the relative position and heading of the
destination ﬁsh relative to the source ﬁsh, at times when the transfer entropy from the source
to the destination is more intense. For this purpose, we used radial diagrams (see Fig. 4)
representing the relative data in terms of transfer entropy, focusing separately on their positive
(informative) and negative (misinformative) values. In each diagram, we aggregate data from
all 455 U-turns and all pairs. The diagrams show clear spatial patterns coupled with the
transfer entropy, which we call spatio-informational motifs.
We see that positive information transfer is on average more intense from source ﬁsh to:
(a) other ﬁsh positioned behind them (Fig. 4a, left), and (b) to ﬁsh with headings closer to
perpendicular rather than parallel to them (Fig. 4a, right). We know from Figs. 2 and 3 that
positive transfer entropy is detected from source ﬁsh that have already turned to destination
ﬁsh that are turning. Thus, Fig. 4a suggests that a source is more informative about destination
ﬁsh that are left behind it after a turn, most intensely when the destination ﬁsh are executing
their own turning manoeuvre to follow the source. Directional relationships from individuals
in front towards others that follow were observed in previous works on birds (Nagy et al.
2010), bats (Orange and Abaid 2015) and ﬁsh (Katz et al. 2011; Herbert-Read et al. 2011;
Rosenthal et al. 2015).
For negative information transfer (Fig. 4b), we see a different spatio-informational motif.
Negative information transfer is on average more intense to ﬁsh generally positioned at the
side and with opposite heading. This aligns with Figs. 2 and 3 in that negative transfer entropy
typically ﬂows from ﬁsh that have not turned yet to those which are turning.
In summary, transfer entropy has a clear spatial signature, showing that the spatio-
informational dependencies in the studied school of ﬁsh are not random but reﬂect speciﬁc
interactions.
123

Swarm Intell (2018) 12:283–305
293
Fig. 4 Spatio-informational motifs. Each diagram is a circle centred on a source ﬁsh with zero heading,
providing a reference. In each diagram, space is divided into 60 angular sectors measuring 6◦. Within each
circle, we group all pairwise samples from all 455 U-turns such that the source ﬁsh is placed in the centre and
the destination ﬁsh is placed within the circle in one of the sectors. The left circles in a, b aggregate the relative
positions of destination ﬁsh, while the right circles aggregate the relative headings of destination ﬁsh. The
value of each radial sector (for both position and heading) represents the average of the corresponding values
of either positive (a) of negative (b) transfer entropy. For example, the value in each sector of the left diagram
of a represents the average positive transfer entropy for a destination ﬁsh, given it has relative position in that
sector with respect to the source ﬁsh: all positive values of transfer entropy corresponding to each sector are
summed and divided by the total number of values corresponding to that sector. The value in each sector of the
right diagram of a represents the average positive transfer entropy for a destination ﬁsh, given that its heading
diverges from the one of the source by an angle in that sector. b Mirrors a this negative transfer entropy. The
source ﬁsh data are taken from the time points corresponding to the time delay v with respect to the source
4 Discussion
Informationtransferwithinanimalgroupsduringcollectivemotionishardtoquantifybecause
of implicit and distributed communication channels with delayed and long-ranged effects,
selective attention (Riley and Leith 1976) and other species-speciﬁc cognitive processes.
Here, we presented a rigorous framework for detecting and measuring predictive informa-
tion ﬂows during collective motion, by attending to the dynamic statistical dependence of
directional changes in destination ﬁsh on relative heading of sources. This predictive infor-
mation ﬂow should be interpreted as a change (gain or loss) in predictability obtained by an
observer. Importantly, the information-theoretic nature of the measure means that it is appli-
cable to other stochastic interactions; more stochastic dynamics would require more data and
suitable video capture resolution to identify the salient ﬂows. Furthermore, one may consider
methods of statistical mechanics and information thermodynamics in studies of collective
motion distributed over large systems (Bialek et al. 2012; Crosato et al. 2018).
We studied Hemigrammus rhodostomus ﬁsh placed in a ring-shaped tank which effectively
only allowed the ﬁsh to move straight ahead or turn back to perform a U-turn. The individual
trajectories of the ﬁsh were recorded for hundreds of collective U-turns, enabling us to
perform a statistically signiﬁcant information-theoretical analysis for multiple pairs of source
and destination ﬁsh. The experimental setup used in this study has been chosen to focus on
collective U-turns, but the information ﬂow analysis has been applied in other situations
with more complex collective behaviour, e.g., general swarming behaviour with different
constraints (Wang et al. 2012; Miller et al. 2014; Tomaru et al. 2016), and swarming behaviour
with leaders (Sun et al. 2014; Orange and Abaid 2015).
Transfer entropy was used in detecting pairwise time delayed dependencies within the
school. By observing the local dynamics of this measure, we demonstrated that predictive
information ﬂows intensify during collective direction changes—i.e., the U-turns—a hypoth-
esis that until now was not veriﬁed in a real biological system. Furthermore, we identiﬁed
123

294
Swarm Intell (2018) 12:283–305
two distinct predictive information ﬂows within the school: an informative ﬂow from ﬁsh
that have already preformed the U-turn to ﬁsh that are turning, and a misinformative ﬂow
from ﬁsh that have not preformed the U-turn yet to the ﬁsh that are turning.
We also explored the role of spatial dynamics in generating the inﬂuential interactions
that carry the information ﬂows, another well-known problem. In doing so, we mapped the
detected values of transfer entropy against each ﬁsh’s relative position and heading, iden-
tifying clear spatio-informational motifs. Importantly, the positive and negative predictive
information ﬂows were shown to be associated with speciﬁc spatial signatures of source
and destination ﬁsh. For example, positive information ﬂow is detected when the source ﬁsh
is in front of the destination, similarly to what was already observed in previous works on
animals (Nagy et al. 2010; Katz et al. 2011; Herbert-Read et al. 2011; Rosenthal et al. 2015;
Orange and Abaid 2015). The identiﬁed sequential cascade-like dynamics of information
ﬂow is well-pronounced, suggesting that this pattern will be retained in larger schools—this
however remains a subject of future research.
In a previous work, the analysis of short-term directional correlations between ﬁsh on the
same experimental data has shown that, when the group changes direction, individual ﬁsh
respond to a limited number of inﬂuential neighbours, typically one or two which are not
necessarily the closest ones (Jiang et al. 2017). Moreover, ﬁsh continuously change who they
are interacting with. In this study, using a complementary approach, we show that a ﬁsh that
has just made a U-turn may also decide to ignore the input of other ﬁsh moving in opposite
direction (which is shown by the misinformation ﬂow). A ﬁsh can thus choose to move in
the opposite direction of the majority. This suggests that the behavioural tendency of a ﬁsh
to align in the direction of the majority of its neighbours, which is a manifestation of social
conformity and implemented in most models of collective motion, can be “shut down” for
some time. When these events occur, a ﬁsh can temporary take the lead of a group thanks
to the behavioural contagion. Our analysis provides a way to create a quantitative model
for predictive information ﬂow between ﬁsh and thus brings a better understanding of the
processes underlying collective decisions in ﬁsh groups and animal groups in general.
Local transfer entropy as it was applied in this study reveals the dynamics of pairwise
information transfer. It is well known that multivariate extensions to the transfer entropy,
e.g., conditioning on other information sources, can be useful in terms of eliminating redun-
dant pairwise relationships while also capturing higher-order relationships beyond pairwise
(i.e. synergies) (Lizier et al. 2008, 2010; Lizier and Prokopenko 2010; Vakorin et al. 2009;
Williams and Beer 2011; James et al. 2016), and as such the identiﬁcation of effective neigh-
bourhoods cannot be accurately inferred using pairwise relationships alone. Transfer entropy
comprises both (i) a unique component from the source, and (ii) a synergistic component
from the source in the context of the target, as has been clariﬁed by Williams and Beer
(2011), among others. While we can learn more by measuring these components separately
(for which well accepted measures have not yet been developed), both capture important
aspects of the concept of information transfer. Thus, we argue that focussing on the unique
component alone would not align with the popularly understood concept of information
transfer. Improvements are possible by adapting algorithms for deciding when to include
higher-order multivariate transfer entropies (and which variables to condition on), developed
to study effective networks in brain imaging data sets (Lizier and Rubinov 2012; Faes et al.
2011; Marinazzo et al. 2012; Stramaglia et al. 2012), to collective animal behaviour, as such
methods can eliminate redundant connections and detect synergistic effects. Whether or not
such algorithms will prove useful for swarm dynamics is an open research question, with
conﬂicting ﬁndings that ﬁrst suggest that multiple ﬁsh interactions could be faithfully fac-
123

Swarm Intell (2018) 12:283–305
295
torised into simply pair interactions in one species (Gautrais et al. 2012) but conversely that
this may not necessarily generalise (Katz et al. 2011).
In any case, such adaptations to capture multivariate effects will be non-trivial, as it
must handle the short-term and dynamic structure of interactions across the collective. Early
attempts have been made using (a similar measure to) conditional TE—on average over time
windows—in collectives under such algorithms (Lord et al. 2016); however, it remains to be
seen what such measures reveal about the collective dynamics on a local scale.
In summary, we have proposed a novel information-theoretic framework for studying
the dynamics of information transfer in collective motion and applied it to a school of ﬁsh,
without making any speciﬁc assumptions on ﬁsh behavioural traits and/or rules of interaction.
This framework can be applied to studies of other biological collective phenomena, such as
swarming and ﬂocking, artiﬁcial multi-agent systems and active matter in general.
5 Methods
A general scheme of the methodology from the animal experimentation to the analysis of the
information ﬂows is provided in Fig. 5.
5.1 Experimental procedures
A group of 70 Hemigrammus rhodostomus (rummy-nose tetras) were purchased from Ama-
zonie Labège (http://www.amazonie.com) in Toulouse, France. Fish were kept in 150 L
aquariums on a 12:12 h, dark/light photoperiod, at 27.7 ◦C(± 0.5 ◦C) and were fed ad libi-
tum with ﬁsh ﬂakes. Body lengths of the ﬁsh used in these experiments were on average 31
mm (± 2.5 mm). This species was chosen because it exhibits a strong schooling behaviour
and it is very easy to handle in controlled conditions (Jiang et al. 2017; Lecheval et al. 2017).
Moreover, individuals perform a burst-and-coast type of swimming that involves sharp direc-
tional changes, which implies a series of separate behavioural decisions in time and space.
It is likely that an information-theoretic analysis would be able to better temporally resolve
information ﬂows associated with these transitions, as compared to more continuous dynam-
ics [such as exhibited by Khulia mugil (Gautrais et al. 2012)].1 Further, when swimming in
a ring-shaped tank, schools of rummy-nose tetra hardly ever split despite collective U-turns,
because of their social interactions relying on attraction and alignment (Calovi et al. 2018).
The experimental tank measured 120 × 120 cm was made of glass and set on top of a box
to isolate ﬁsh from vibrations. The setup, placed in a chamber made by four opaque white
curtains, was surrounded by four LED light panels giving an isotropic lighting. A ring-shaped
tank made from two tanks (an outer wall of radius 35 cm and an inner wall, a cone of radius
25 cm at the bottom; both shaping a corridor of 10 cm) was set inside the experimental tank
ﬁlled with 7 cm of water of controlled quality (50% of water puriﬁed by reverse osmosis and
50% of water treated by activated carbon) heated at 28.1 ◦C(± 0.7 ◦C). The conic shape of
the inner wall has been chosen to avoid the occlusion on videos of ﬁsh swimming too close
to the inner wall that would occur with straight walls.
Five ﬁsh were randomly sampled from their breeding tank for each trial. Fish were ensured
to be used only in one experiment per day at most. Fish were left for 10 min to habituate
1 With that said, we have also shown that techniques employed in this study are also successful in identifying
information ﬂows in groups with smoother motion dynamics (Wang et al. 2012; Miller et al. 2014).
123

296
Swarm Intell (2018) 12:283–305
before the start of the trial. A trial consisted of 1 h of ﬁsh swimming freely (i.e. without any
external perturbation).
5.2 Data extraction and pre-processing
Fish trajectories were recorded by a Sony HandyCam HD camera ﬁlming from above the
setup at 50Hz (50 frames per second) in HDTV resolution (1920 × 1080p). Videos were
converted from MTS to AVI ﬁles with the command-line tool FFmpeg 2.4.3. Positions of
ﬁsh on each frame were tracked with the tracking software idTracker 2.1 (Pérez-Escudero
et al. 2014).
When possible, missing positions of ﬁsh have been manually corrected, only during the
collective U-turn events detected by the sign changes of polarisation of the ﬁsh groups.
The corrections have involved manual tracking of ﬁsh misidentiﬁed by idTracker as well as
interpolation or merging of positions in the cases where only one ﬁsh was detected instead of
several because they were swimming too close from each other for a long time. All sequences
less or equal than 50 consecutive missing positions were interpolated. Larger sequence of
missing values have been checked by eye to check whether interpolating was reasonable or
not—if not, merging positions with closest neighbours was considered. All tracked positions
have been monitored by eye during all U-turn events to make sure that any manual corrections
improved the quality of the data set of positions. The entire process of manual changes and
eye checking required three weeks. No U-turns were omitted from the analysis.
Time series of positions has been converted from pixels to metres, and the origin of the
coordinate system O(0, 0) has been set to the centre of the ring-shaped tank. The resulting
data set contains 9273720 data points (1854744 for each ﬁsh) from all the ten trials. Velocity
was numerically derived from position using the symmetric difference quotient two-point
estimation (Larson 1983). Heading was then computed as the four-quadrant inverse tangent
of velocity and used to compute transfer entropy.
5.3 Polarisation
The polarisation is used to represent the orientation of a ﬁsh or of the whole school around the
tank, which can be clockwise or anticlockwise, and is deﬁned as the circumferential velocity
component of the velocity a ﬁsh or of the whole school. Let Z and ˙Z be the two-dimensional
position and normalised velocity of a ﬁsh, deﬁned as Cartesian vectors with the centre of
the tank being the origin—in case of the whole school, Z and ˙Z are averaged over all ﬁsh.
The ﬁsh direction along an ideal circular clockwise rotation is described by a unit vector
z =
ω×Z
|ω×Z|, where ω is a vector orthogonal to plane of the rotation, chosen using the left-hand
rule. In other words, z is the azimuthal unit vector of the ﬁsh heading θ.
The polarisation is deﬁned as ˙Z·z, so thatitis positive when the ﬁsh is swimming clockwise
and negative when it is swimming anticlockwise. Also, the better ˙Z is aligned with z or −z,
the higher is the intensity of the polarisation. On the contrary, as ˙Z deviates from z or −z,
the polarisation decreases and eventually reaches zero when ˙Z and z are orthogonal. As a
consequence, during a U-turn, the intensity of the polarisation decreases and becomes zero
at least once, before it increases again with the opposite sign.
5.4 Local transfer entropy
Transfer entropy (Schreiber 2000) is deﬁned in terms of Shannon entropy, a fundamental mea-
sure in information theory (Cover and Thomas 2006) that quantiﬁes the uncertainty of random
123

Swarm Intell (2018) 12:283–305
297
7
Fig. 5
General scheme of the methodology. For each of the 10 trials of the experiment, 5 ﬁsh were randomly
chosen and placed in the ring-shaped tank, where they were let swimming free for 1 h while being recorded.
The position of the ﬁsh over time was tracked from the produced videos, and the heading extracted from the
position. Once all time series of ﬁsh heading were created, for each ﬁsh and during all trials, they were used in
order to optimise the embedding parameters and the lag between source and destination ﬁsh. The conditional
probability distributions involved in the computation of transfer entropy were then estimated using the heading
time series of all trials. Subsequently, the local values of transfer entropy at each time step were calculated for
each trial, as well as their statistical signiﬁcance. Finally, local values of transfer entropy around every U-turns
were aggregated in order to perform the analyses presented in Sects. 3.2 and 3.3
variables. Shannon entropy of a random variable X is H(X) = −
x∈X p(x) log2 p(x),
where p(x) is the probability of a speciﬁc instance x of X. H(X) can be interpreted
as the minimal expected number of bits required to encode a value of X without los-
ing information. The joint Shannon entropy between two random variables X and Y is
H(X, Y) = −
x∈X

y∈Y p(x, y) log2 p(x, y), where p(x, y) is the joint probability of
instances x of X and y of Y. This quantity allows the deﬁnition of conditional Shannon
entropy as H(X|Y) = H(X, Y) −H(X), which represents the uncertainty of X knowing Y.
In this study, we are interested in local (or pointwise) transfer entropy (Fano 1961; Lizier
2014b) for speciﬁc instances of time series processes of ﬁsh motion, which allows us to
reconstruct the dynamics of information ﬂows over time. Shannon information content of an
instance xn of process X at time n is deﬁned as h(xn) = −log2 p(xn). The quantity h(xn) is
the information content attributed to the speciﬁc instance xn, or the information required to
encode or predict that speciﬁc value. Conditional Shannon information content of an instance
xn of process X given an instance yn of process Y is deﬁned as h(xn|yn) = h(xn, yn)−h(xn).
Local transfer entropy is deﬁned as the information provided by the source yn−v =
{yn−v, yn−v−1, . . . , yn−v−l+1}, where v is a time delay and l is the history length, about the
destination xn in the context of the past of the destination xn−1 = {xn−1, xn−2, . . . , xn−k},
with a history length k:
123

298
Swarm Intell (2018) 12:283–305
ty→x(n, v) = h(xn|xn−1) −h(xn|xn−1, yn−v)
= log2
p(xn|xn−1, yn−v)
p(xn|xn−1)
.
(2)
Transfer entropy TY→X(v) is the average of the local transfer entropies ty→x(n, v) over
samples (or over n under a stationary assumption). The transfer entropy is asymmetric in Y
and X and is also a dynamic measure (rather than a static measure of correlations) since it
measures information in state transitions of the destination.
In order to compute transfer entropy here, the source variable Y and destination variable
X are deﬁned in terms of the ﬁsh heading. Speciﬁcally, X is the ﬁrst-order divided difference
(Newton’s difference quotient) of the destination ﬁsh heading, while Y is the difference
between the two ﬁsh headings at the same time. Let θS and θD be, respectively, the heading
time series of the source and the destination ﬁsh. We then construct variables X and Y as
follows, for all time points n (cf. Fig. 6 for an illustration of the headings involved):
xn = θ D
n −θ D
n−1,
(3)
yn = θ D
n −θ S
n .
(4)
Thus, yn represents the relative heading of the destination ﬁsh with respect to the source
ﬁsh, while xn represents the directional change of the destination ﬁsh. The variables were
so deﬁned in order to capture directional changes of the destination ﬁsh in relation to its
alignment with the source ﬁsh, which is considered an important component of movement
updates in swarm models (Reynolds 1987).
Given the deﬁnition of the variables (3) and (4), we computed local transfer entropy
ty→x(n, v) using Eq. (2), where v was determined as described in Sect. 5.5 that follows. The
past state xn−1 of the destination in transfer entropy was deﬁned as a vector of an embedding
space of dimensionality k and delay τ, with xn−1 = {xn−1−jτ}, for j = {0, 1, . . . , k −1}.
Finding optimal values for k and τ is also described in Sect. 5.5. The state of the source
process yn−v was also deﬁned as a vector of an embedding space whose dimensionality
l and delay τ ′ were similarly optimised. The local transfer entropy ty→x(n, v) computed
on these variables therefore tells us how much information (l time steps of) the heading
of the destination relative to the source adds to our knowledge of the directional change in
the destination (some v time steps later), in the context of k past directional changes of the
destination. We note that while turning dynamics of the destination may contain more entropy
(as rare events), there will only be higher transfer entropy at these events if the source ﬁsh is
able to add to the prediction of such dynamics.
Computing transfer entropy requires knowledge of the probabilities of xn and yn deﬁned
in (3) and (4). These are not known a priori, but the measures can be estimated from the data
samples using existing techniques. In this study, this was accomplished by modelling the
probability distribution function as a multivariate Gaussian distribution (making the transfer
entropy proportional to the Granger causality (Barnett et al. 2009)). This technique is the
simplest ﬁrst-order estimation available and well applied for transfer entropy (Marinazzo
et al. 2012). We used the JIDT software implementation (Lizier 2014a).
Also, we assume stationarity of behaviour and homogeneity across the ﬁsh, such that
we can pool together all pairwise samples from all time steps, for all trials, maximising the
number of samples available for the calculation of each measure. For performance efﬁciency,
we make calculations of the local measures using 10 separate sub-sampled sets (sub-sampled
evenly across the trials), then recombine into a single resultant information-theoretic data
set.
123

Swarm Intell (2018) 12:283–305
299
Fig. 6 Illustration of the
headings from which the source
and destination variables are
constructed
5.5 Parameter optimisation
The embedding dimensionality and delay for the source and the past state of the destination
need to be appropriately chosen in order to optimise the quality of transfer entropy. The
combination (k, τ) for the past state of the destination, as well as the combination (l, τ ′) for
the source, have been optimised separately by minimising the global self-prediction error,
as described in Ragwitz and Kantz (2002) and Wibral et al. (2014). In the case of Markov
processes, the optimal dimensionality of the embedding is the order of the process. Lower
dimensions do not provide the same amount of predictive information, while higher dimen-
sions add redundancy that weaken the prediction. For non-Markov processes, the algorithm
selects the highest dimensionality found to contribute to self-prediction of the destination
while still being supported by the ﬁnite amount of data that we have. Values of the dimension-
ality between 1 and 10 have been explored in combination with values of the delay between
1 and 5. The optimal combinations were found to be the same for both the source and the
past of the destination: k = l = 3, τ = τ ′ = 1.
The lag v was also optimised. This was done by maximising the average transfer entropy
(after the optimisation of k, τ, l and τ ′) as per the technique of Wibral et al. (2013), Faes
et al. (2014) used in, e.g., Razak and Jensen (2014), Materassi et al. (2014), Dimitriadis et al.
(2016) and Khadem et al. (2016), over lags between 0.02 and 1 s, at time steps of 0.02 s.
The average transfer entropy was observed to grow and reach a local maximum at v = 6
(0.12 s), and then decrease for higher values (see Fig. 7). This result might have a biological
interpretation: it is plausible that the response to behaviour of the other ﬁsh is delayed by
both a communication and a reaction times, which would both be included in this lag.
5.6 Statistical signiﬁcance of estimates of local transfer entropy
Theoretically, transfer entropy between two independent variables is zero. However, a
non-zero bias (and a variance of estimates around that bias) is likely to be observed when,
as in this study, transfer entropy is numerically estimated from a ﬁnite number of samples.
This leads to the problem of determining whether a non-zero estimated value represents a
real relationship between two variables, or is otherwise not statistically signiﬁcant (Wibral
et al. 2014).
There are known statistical signiﬁcance tests for the average transfer entropy (Vicente
et al. 2011; Lizier et al. 2011a; Lizier 2014a), involving comparing the measured value to
a null hypothesis that there was no (directed) relationship between the variables. For an
average transfer entropy estimated from N samples, one surrogate measurement is con-
structed by resampling the corresponding yn−v for each of the N samples of {xn, xn−1} and
then computing the average transfer entropy over these new surrogate samples. This process
123

300
Swarm Intell (2018) 12:283–305
Fig. 7 Time lag optimisation. The red line represents the average transfer entropy (with k = l = 3, τ = τ′ =
1) over all samples, as a function of the time delay between the source variable and the destination variable,
for time delays between 0.02 and 1 s (1–50 time cycles) (Color ﬁgure online)
retains p(xn|xn−1) and p(yn−v), but not p(xn|yn−v, xn−1). Many surrogate measurements
are repeated so as to construct a surrogate distribution under this null hypothesis of no directed
relationship, and the transfer entropy estimate can then be compared in a statistical test against
this distribution. For the average transfer entropy measured via the linear-Gaussian estimator,
it is known that analytically the surrogates (in nats, and multiplied by 2 × N) asymptotically
follow a χ2 distribution with l degrees of freedom (Geweke 1982; Barnett and Bossomaier
2012). We use this distribution to conﬁrm that the transfer entropy at the selected lag of 0.12 s
(and indeed all lags tested) is statistically signiﬁcant compared to the null distribution (at
p < 0.05 plus a Bonferroni correction for the multiple comparisons across the 50 candidate
lags).
Next, we introduce an extension of these methods in order to assess the statistical sig-
niﬁcance of the local values. This simply involves constructing surrogate transfer entropy
measurements as before, however this time retaining the local values within those surrogate
measurements and building a distribution of those surrogates. Measured local values are then
statistically tested against this null distribution of local surrogates to assess their statistical
signiﬁcance.
We generated ten times as many surrogate local values as the number of actual local esti-
mates, with a total of approximately 371 million local surrogates. This large set of surrogate
local values was used to estimate p values of actual local values of the transfer entropy. If p
value is sufﬁciently small, then the test fails and the value of the transfer entropy is considered
signiﬁcant (the value represents an actual relationship). The Benjamini and Hochberg (1995)
procedure was used to select the p value cutoff while controlling for the false discovery rate
under (N) multiple comparisons.
Data accessibility
The datasets generated and analysed during the current study are available from the corre-
sponding author on request.
123

Swarm Intell (2018) 12:283–305
301
Author contributions GT designed research; VL, PT and GT performed research; VL, LJ, PT, RW and
GT analysed data. EC, JL, RW and MP developed information dynamics methods, performed information-
theoretic analysis, and identiﬁed information ﬂows and motifs. EC designed, developed and run software for
the information-theoretic analysis. GT, JL, EC and MP conceived and analysed information cascade. EC, JL
and MP wrote the paper. GT and VL edited the manuscript and contributed to the writing.
Funding E.C. was supported by the University of Sydney’s “Postgraduate Scholarship in the ﬁeld of Complex
Systems” from Faculty of Engineering & IT and by a CSIRO top-up scholarship. L.J. was supported by
a grant from the China Scholarship Council (CSC NO.201506040167). V.L. was supported by a doctoral
fellowship from the scientiﬁc council of the University Paul Sabatier. This study was supported by grants from
the Centre National de la Recherche Scientiﬁque and University Paul Sabatier (project Dynabanc). J.L. was
supported through the Australian Research Council DECRA grant DE160100630. M.P. was supported by The
University of Sydney’s DVC Research Strategic Research Excellence Initiative (SREI-2020) project, “CRISIS:
Crisis Response in Interdependent Social-Infrastructure Systems” (IRMA 194163). Sydney Informatics Hub
at the University of Sydney provided access to HPC computational resources that have contributed to the
research results reported within the paper.
Compliance with ethical standards
Conﬂict of interest The authors declare no conﬂict of interest.
Ethical standard All experiments have been approved by the Ethics Committee for Animal Experimentation
of the Toulouse Research Federation in Biology N1 and comply with the European legislation for animal
welfare.
References
Albantakis, L., Hintze, A., Koch, C., Adami, C., & Tononi, G. (2014). Evolution of integrated causal structures
in animats exposed to environments of increasing complexity. PLOS Computational Biology, 10(12), 1–
19.
Attanasi, A., Cavagna, A., Del Castello, L., Giardina, I., Grigera, T. S., Jeli´c, A., et al. (2014a). Information
transfer and behavioural inertia in starling ﬂocks. Nature Physics, 10(9), 691–696.
Attanasi, A., Cavagna, A., Del Castello, L., Giardina, I., Jelic, A., Melillo, S., et al. (2015). Emergence of
collective changes in travel direction of starling ﬂocks from individual birds’ ﬂuctuations. Journal of The
Royal Society Interface, 12(108), 20150319.
Attanasi, A., Cavagna, A., Del Castello, L., Giardina, I., Melillo, S., Parisi, L., et al. (2014b). Collective
behaviour without collective order in wild swarms of midges. PLOS Computational Biology, 10(7),
1–10.
Ay, N., & Polani, D. (2008). Information ﬂows in causal networks. Advances in Complex Systems, 11(01),
17–41.
Ballerini, M., Cabibbo, N., Candelier, R., Cavagna, A., Cisbani, E., Giardina, I., et al. (2008). Interaction
ruling animal collective behavior depends on topological rather than metric distance: evidence from a
ﬁeld study. Proceedings of the National Academy of Sciences, 105(4), 1232–1237.
Barnett, L., Barrett, A. B., & Seth, A. K. (2009). Granger causality and transfer entropy are equivalent for
gaussian variables. Physical Review Letters, 103, 238701.
Barnett, L., & Bossomaier, T. (2012). Transfer entropy as a Log-Likelihood ratio. Physical Review Letters,
109, 138105.
Barnett, L., Lizier, J. T., Harré, M., Seth, A. K., & Bossomaier, T. (2013). Information ﬂow in a kinetic ising
model peaks in the disordered phase. Physical Review Letters, 111(17), 177203.
Benjamini, Y., & Hochberg, Y. (1995). Controlling the false discovery rate: A practical and powerful approach
to multiple testing. Journal of the Royal Statistical Society Series B (Methodological), 57(1), 289–300.
Bialek, W., Cavagna, A., Giardina, I., Mora, T., Silvestri, E., Viale, M., et al. (2012). Statistical mechanics for
natural ﬂocks of birds. Proceedings of the National Academy of Sciences, 109(13), 4786–4791.
Boedecker, J., Obst, O., Lizier, J. T., Mayer, N. M., & Asada, M. (2012). Information processing in echo state
networks at the edge of chaos. Theory in Biosciences, 131(3), 205–213.
Bonabeau, E., Dorigo, M., & Theraulaz, G. (1999). Swarm intelligence: From natural to artiﬁcial systems.
Oxford: Oxford University Press.
123

302
Swarm Intell (2018) 12:283–305
Buhl, J., & Rogers, S. (2016). Mechanisms underpinning aggregation and collective movement by insect
groups. Current Opinion in Insect Science, 15, 125–130.
Buhl, J., Sumpter, D. J. T., Couzin, I. D., Hale, J. J., Despland, E., Miller, E. R., et al. (2006). From disorder
to order in marching locusts. Science, 312(5778), 1402–1406.
Buhl, J., Sword, G. A., Clissold, F. J., & Simpson, S. J. (2010). Group structure in locust migratory bands.
Behavioral Ecology and Sociobiology, 65(2), 265–273.
Butail, S., Ladu, F., Spinello, D., & Porﬁri, M. (2014). Information ﬂow in animal-robot interactions. Entropy,
16(3), 1315–1330.
Butail, S., Mwaffo, V., & Porﬁri, M. (2016). Model-free information-theoretic approach to infer leadership in
pairs of zebraﬁsh. Physical Review E, 93(4), 042411.
Calovi, D. S., Litchinko, A., Lecheval, V., Lopez, U., Pérez Escudero, A., Chaté, H., et al. (2018). Disentangling
and modeling interactions in ﬁsh with burst-and-coast swimming reveal distinct alignment and attraction
behaviors. PLOS Computational Biology, 14(1), 1–28.
Calovi, D. S., Lopez, U., Schuhmacher, P., Chaté, H., Sire, C., & Theraulaz, G. (2015). Collective response
to perturbations in a data-driven ﬁsh school model. Journal of The Royal Society Interface, 12(104),
20141362.
Cavagna, A., Giardina, I., & Ginelli, F. (2013a). Boundary information inﬂow enhances correlation in ﬂocking.
Physical Review Letters, 110(16), 168107.
Cavagna, A., Queirós, S. M. D., Giardina, I., Stefanini, F., & Viale, M. (2013b). Diffusion of individual birds in
starling ﬂocks. Proceedings of the Royal Society of London B: Biological Sciences, 280(1756), 20122484.
Chicharro, D., & Ledberg, A. (2012). When two become one: The limits of causality analysis of brain dynamics.
PLOS ONE, 7(3), 1–16.
Cliff, O. M., Lizier, J. T., Wang, X. R., Wang, P., Obst, O., & Prokopenko, M. (2017). Quantifying long-range
interactions and coherent structure in multi-agent dynamics. Artiﬁcial Life, 23(1), 34–57.
Couzin, I. D. (2009). Collective cognition in animal groups. Trends in Cognitive Sciences, 13(1), 36–43.
Cover, T. M., & Thomas, J. A. (2006). Elements of Information Theory. New York: Wiley-Interscience.
Crosato, E., Spinney, R. E., Nigmatullin, R., Lizier, J. T., & Prokopenko, M. (2018). Thermodynamics and
computation during collective motion near criticality. Physical Review E, 97, 012120.
Dimitriadis, S., Sun, Y., Laskaris, N., Thakor, N., & Bezerianos, A. (2016). Revealing cross-frequency
causal interactions during a mental arithmetic task through symbolic transfer entropy: A novel vector-
quantization approach. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 24(10),
1017–1028.
Faes, L., Marinazzo, D., Montalto, A., & Nollo, G. (2014). Lag-speciﬁc transfer entropy as a tool to assess car-
diovascular and cardiorespiratory information transfer. IEEE Transactions on Biomedical Engineering,
61(10), 2556–2568.
Faes, L., Nollo, G., & Porta, A. (2011). Information-based detection of nonlinear granger causality in multi-
variate processes via a nonuniform embedding technique. Physical Review E, 83(5), 051112.
Faes, L., & Porta, A. (2014). Conditional Entropy-Based evaluation of information dynamics in physiological
systems. In M. Wibral, R. Vicente, & J. T. Lizier (Eds.), Directed information measures in neuroscience,
understanding complex systems (pp. 61–86). Berlin: Springer.
Fano, R. M. (1961). Transmission of information: A statistical theory of communications. Cambridge, MA:
M.I.T Press.
Feldman, D. P., McTague, C. S., & Crutchﬁeld, J. P. (2008). The organization of intrinsic computation:
Complexity-entropy diagrams and the diversity of natural information processing. Chaos, 18(4), 043106.
Fourcassié, V., Dussutour, A., & Deneubourg, J. L. (2010). Ant trafﬁc rules. The Journal of Experimental
Biology, 213(14), 2357–2363.
Gautrais, J., Ginelli, F., Fournier, R., Blanco, S., Soria, M., Chaté, H., et al. (2012). Deciphering interactions
in moving animal groups. PLOS Computational Biology, 8(9), 1–11.
Geweke, J. (1982). Measurement of linear dependence and feedback between multiple time series. Journal of
the American Statistical Association, 77(378), 304–313.
Giardina, I. (2008). Collective behavior in animal groups: Theoretical models and empirical studies. Human
Frontier Science Program Journal, 2(4), 205–219.
Ginelli, F., Peruani, F., Pillot, M. H., Chaté, H., Theraulaz, G., & Bon, R. (2015). Intermittent collective
dynamics emerge from conﬂicting imperatives in sheep herds. Proceedings of the National Academy of
Sciences, 112(41), 12729–12734.
Gómez, C., Lizier, J. T., Schaum, M., Wollstadt, P., Grützner, C., Uhlhaas, P., et al. (2014). Reduced predictable
information in brain signals in autism spectrum disorder. Frontiers in Neuroinformatics, 8, 9.
Herbert-Read, J. E., Buhl, J., Hu, F., Ward, A. J., & Sumpter, D. J. (2015). Initiation and spread of escape
waves within animal groups. Royal Society open science, 2(4), 140355.
123

Swarm Intell (2018) 12:283–305
303
Herbert-Read, J. E., Perna, A., Mann, R. P., Schaerf, T. M., Sumpter, D. J. T., & Ward, A. J. W. (2011).
Inferring the rules of interaction of shoaling ﬁsh. Proceedings of the National Academy of Sciences,
108(46), 18726–18731.
James, R. G., Barnett, N., & Crutchﬁeld, J. P. (2016). Information ﬂows? A critique of transfer entropies.
Physical Review Letters, 116(23), 238701.
Jeanson, R., Deneubourg, J. L., & Theraulaz, G. (2004). Discrete dragline attachment induces aggregation in
spiderlings of a solitary species. Animal Behaviour, 67(3), 531–537.
Jeanson, R., Rivault, C., Deneubourg, J. L., Blanco, S., Fournier, R., Jost, C., et al. (2005). Self-organized
aggregation in cockroaches. Animal Behaviour, 69(1), 169–180.
Jiang, L., Giuggioli, L., Perna, A., Escobedo, R., Lecheval, V., Sire, C., et al. (2017). Identifying inﬂuential
neighbors in animal ﬂocking. PLOS Computational Biology, 13(11), 1–32.
Katz, Y., Tunstrøm, K., Ioannou, C. C., Huepe, C., & Couzin, I. D. (2011). Inferring the structure and dynamics
of interactions in schooling ﬁsh. Proceedings of the National Academy of Sciences, 108(46), 18720–
18725.
Khadem, A., Hossein-Zadeh, G. A., & Khorrami, A. (2016). Long-range reduced predictive information
transfers of autistic youths in EEG sensor-space during face processing. Brain topography, 29(2), 283–
295.
Khuong, A., Gautrais, J., Perna, A., Sbaï, C., Combe, M., Kuntz, P., et al. (2016). Stigmergic construction and
topochemical information shape ant nest architecture. Proceedings of the National Academy of Sciences,
113(5), 1303–1308.
Ladu, F., Mwaffo, V., Li, J., Macrì, S., & Porﬁri, M. (2015). Acute caffeine administration affects zebraﬁsh
response to a robotic stimulus. Behavioural Brain Research, 289, 48–54.
Langton, C. G. (1990). Computation at the edge of chaos: Phase transitions and emergent computation. Physica
D, 42(1–3), 12–37.
Larson, L. (1983). The symmetric derivative. Transactions of the American Mathematical Society, 277(2),
589–599.
Lecheval, V., Jiang, L., Tichit, P., Sire, C., Hemelrijk, C. K., & Theraulaz, G. (2017). Domino-like propagation
of collective u-turns in ﬁsh schools. submitted to bioRxiv.
Lissaman, P. B. S., & Shollenberger, C. A. (1970). Formation ﬂight of birds. Science, 168(3934), 1003–1005.
Lizier, J. T. (2013). The local information dynamics of distributed computation in complex systems, Springer
Theses. Berlin: Springer.
Lizier, J. T. (2014a). JIDT: An information-theoretic toolkit for studying the dynamics of complex systems.
Frontiers in Robotics and AI, 1, 11.
Lizier, J. T. (2014b). Measuring the dynamics of information processing on a local scale in time and space. In M.
Wibral, R. Vicente, & J. T. Lizier (Eds.), Directed information measures in neuroscience, understanding
complex systems (pp. 161–193). Berlin: Springer.
Lizier, J. T., Heinzle, J., Horstmann, A., Haynes, J. D., & Prokopenko, M. (2011a). Multivariate information-
theoretic measures reveal directed information structure and task relevant changes in fMRI connectivity.
Journal of Computational Neuroscience, 30(1), 85–107.
Lizier, J. T., Pritam, S., & Prokopenko, M. (2011b). Information dynamics in small-world boolean networks.
Artiﬁcial Life, 17(4), 293–314.
Lizier, J. T., & Prokopenko, M. (2010). Differentiating information transfer and causal effect. The European
Physical Journal B, 73(4), 605–615.
Lizier, J. T., Prokopenko, M., & Zomaya, A. Y. (2008). Local information transfer as a spatiotemporal ﬁlter
for complex systems. Physical Review E, 77(2), 026110.
Lizier, J. T., Prokopenko, M., & Zomaya, A. Y. (2010). Information modiﬁcation and particle collisions in
distributed computation. Chaos, 20(3), 037109.
Lizier, J. T., Prokopenko, M., & Zomaya, A. Y. (2012). Local measures of information storage in complex
distributed computation. Information Sciences, 208, 39–54.
Lizier, J. T., Prokopenko, M., & Zomaya, A. Y. (2014). A framework for the local information dynamics
of distributed computation in complex systems. In M. Prokopenko (Ed.), Guided self-organization:
Inception, emergence, complexity and computation (Vol. 9, pp. 115–158). Berlin: Springer.
Lizier, J. T., & Rubinov, M. (2012). Multivariate construction of effective computational networks from
observational data. Technical Report Preprint 25/2012, Max Planck Institute for Mathematics in the
Sciences.
Lord, W. M., Sun, J., Ouellette, N. T., & Bollt, E. M. (2016). Inference of causal information ﬂow in collective
animal behavior. IEEE Transactions on Molecular, Biological and Multi-Scale Communications, 2(1),
107–116.
123

304
Swarm Intell (2018) 12:283–305
Mann, R. P., Perna, A., Strömbom, D., Garnett, R., Herbert-Read, J. E., Sumpter, D. J. T., et al. (2012). Multi-
scaleinferenceofinteractionrulesinanimalgroupsusingbayesianmodelselection.PLOSComputational
Biology, 8(1), 1–12.
Marinazzo, D., Pellicoro, M., & Stramaglia, S. (2012). Causal information approach to partial condition-
ing in multivariate data sets. Computational and Mathematical Methods in Medicine, 2012, 303601.
https://doi.org:1155/2012/303601.
Materassi, M., Consolini, G., Smith, N., & De Marco, R. (2014). Information theory analysis of cascading
process in a synthetic model of ﬂuid turbulence. Entropy, 16(3), 1272–1286.
May, R. M. (1979). Flight formations in geese and other birds. Nature, 282, 778–780.
Miller,J.M.,Wang,X.R.,Lizier,J.T.,Prokopenko,M.,&Rossi,L.F.(2014).Measuringinformationdynamics
in swarms. In M. Prokopenko (Ed.), Guided self-organization: Inception, emergence, complexity and
computation (Vol. 9, pp. 343–364). Berlin: Springer.
Moussaïd, M., Helbing, D., Garnier, S., Johansson, A., Combe, M., & Theraulaz, G. (2009). Experimental
study of the behavioural mechanisms underlying self-organization in human crowds. Proceedings of the
Royal Society of London B: Biological Sciences, 276(1668), 2755–2762.
Moussaïd, M., Helbing, D., & Theraulaz, G. (2011). How simple rules determine pedestrian behavior and
crowd disasters. Proceedings of the National Academy of Sciences, 108(17), 6884–6888.
Nagy, M., Ákos, Z., Biro, D., & Vicsek, T. (2010). Hierarchical group dynamics in pigeon ﬂocks. Nature,
464(7290), 890–893.
Nagy, M., Vásárhelyi, G., Pettit, B., Roberts-Mariani, I., Vicsek, T., & Biro, D. (2013). Context-dependent
hierarchies in pigeons. Proceedings of the National Academy of Sciences, 110(32), 13049–13054.
Orange, N., & Abaid, N. (2015). A transfer entropy analysis of leader-follower interactions in ﬂying bats. The
European Physical Journal Special Topics, 224(17), 3279–3293.
Parrish, J. K., Viscido, S. V., & Grünbaum, D. (2002). Self-organized ﬁsh schools: an examination of emergent
properties. Biological Bulletin, 202(3), 296–305.
Partridge, B. (1980). The effect of school size on the structure and dynamics of minnow schools. Animal
Behaviour, 28(1), 68-IN3.
Pérez-Escudero, A., Vicente-Page, J., Hinz, R. C., Arganda, S., & de Polavieja, G. G. (2014). idTracker:
Tracking individuals in a group by automatic identiﬁcation of unmarked animals. Nature Methods, 11(7),
743–748.
Potts, W. K. (1984). The chorus-line hypothesis of manoeuvre coordination in avian ﬂocks. Nature, 309(5966),
344–345.
Procaccini, A., Orlandi, A., Cavagna, A., Giardina, I., Zoratto, F., Santucci, D., et al. (2011). Propagating
waves in starling, sturnus vulgaris, ﬂocks under predation. Animal Behaviour, 82(4), 759–765.
Prokopenko, M., Lizier, J. T., Obst, O., & Wang, X. R. (2011). Relating Fisher information to order parameters.
Physical Review E, 84(4), 041116.
Ragwitz, M., & Kantz, H. (2002). Markov models from data by simple nonlinear time series predictors in
delay embedding spaces. Physical Review E, 65, 056201.
Razak, F. A., & Jensen, H. J. (2014). Quantifying ‘causality’ in complex systems: Understanding transfer
entropy. PLOS ONE, 9(6), e99462.
Reynolds, C. W. (1987). Flocks, herds and schools: A distributed behavioral model. In SIGGRAPH ’87
Proceedings of the 14th annual conference on computer graphics and interactive techniques. ACM, New
York, NY, USA (Vol. 21, pp. 25–34).
Richardson, T. O., Perony, N., Tessone, C. J., Bousquet, C. A., Manser, M. B., & Schweitzer, F. (2013).
Dynamical coupling during collective animal motion. arXiv:1311.1417.
Riley, D. A., & Leith, C. R. (1976). Multidimensional psychophysics and selective attention in animals.
Psychological Bulletin, 83(1), 138.
Rosenthal, S. B., Twomey, C. R., Hartnett, A. T., Wu, H. S., & Couzin, I. D. (2015). Revealing the hidden
networks of interaction in mobile animal groups allows prediction of complex behavioral contagion.
Proceedings of the National Academy of Sciences, 112(15), 4690–4695.
Schreiber, T. (2000). Measuring information transfer. Physical Review Letters, 85(2), 461–464.
Smirnov, D. A. (2013). Spurious causalities with transfer entropy. Physical Review E, 87, 042917.
Stramaglia, S., Wu, G. R., Pellicoro, M., & Marinazzo, D. (2012). Expanding the transfer entropy to identify
information circuits in complex systems. Physical Review E, 86, 066211.
Sumpter, D., Buhl, J., Biro, D., & Couzin, I. (2008). Information transfer in moving animal groups. Theory in
Biosciences, 127(2), 177–186.
Sun, Y., Rossi, L. F., Shen, C. C., Miller, J., Wang, X. R., Lizier, J. T., et al. (2014). Information transfer in
swarms with leaders. arXiv:1407.0007.
Theraulaz, G., Bonabeau, E., Nicolis, S. C., Solé, R. V., Fourcassié, V., Blanco, S., et al. (2002a). Spatial
patterns in ant colonies. Proceedings of the National Academy of Sciences, 99(15), 9645–9649.
123

Swarm Intell (2018) 12:283–305
305
Theraulaz, G., Bonabeau, E., Sole, R. V., Schatz, B., & Deneubourg, J. L. (2002b). Task partitioning in a
ponerine ant. Journal of Theoretical Biology, 215(4), 481–489.
Tomaru, T., Murakami, H., Niizato, T., Nishiyama, Y., Sonoda, K., Moriyama, T., et al. (2016). Information
transfer in a swarm of soldier crabs. Artiﬁcial Life and Robotics, 21 (2), 177–180.
Tunstrøm, K., Katz, Y., Ioannou, C. C., Huepe, C., Lutz, M. J., & Couzin, I. D. (2013). Collective states,
multistability and transitional behavior in schooling ﬁsh. PLOS Computational Biology, 9(2), 1–11.
Vakorin, V. A., Krakovska, O. A., & McIntosh, A. R. (2009). Confounding effects of indirect connections on
causality estimation. Journal of Neuroscience Methods, 184(1), 152–160.
Vicente, R., Wibral, M., Lindner, M., & Pipa, G. (2011). Transfer entropy—A model-free measure of effective
connectivity for the neurosciences. Journal of Computational Neuroscience, 30(1), 45–67.
Wang, X. R., Miller, J. M., Lizier, J. T., Prokopenko, M., & Rossi, L. F. (2012). Quantifying and tracing
information cascades in swarms. PLOS ONE, 7(7), 1–7.
Weitz, S., Blanco, S., Fournier, R., Gautrais, J., Jost, C., & Theraulaz, G. (2012). Modeling collective animal
behavior with a cognitive perspective: A methodological framework. PLOS ONE, 7(6), 1–16.
Wibral, M., Lizier, J. T., & Priesemann, V. (2015). Bits from brains for biologically-inspired computing.
Frontiers in Robotics and AI, 2, 5.
Wibral, M., Pampu, N., Priesemann, V., Siebenhühner, F., Seiwert, H., Lindner, M., et al. (2013). Measuring
information-transfer delays. PLOS ONE, 8(2), 1–19.
Wibral, M., Vicente, R., & Lindner, M. (2014). Transfer entropy in neuroscience. In M. Wibral, R. Vicente, &
J. T. Lizier (Eds.), Directed information measures in neuroscience, understanding complex systems (pp.
3–36). Berlin: Springer.
Williams, P. L., & Beer, R. D. (2011). Generalized measures of information transfer. arXiv:1102.1507.
123

