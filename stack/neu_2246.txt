 
A Bayesian Model for Controlling Cost Overrun 
in a Portfolio of Construction Projects 
 
 
 
A Dissertation Presented 
 
by 
 
 
Payam Bakhshi Khayani 
 
 
to 
 
The Department of Civil and Environmental Engineering 
 
 
 
in partial fulfillment of the requirements 
for the degree of 
 
 
Doctor of Philosophy 
 
 
in the field of 
 
 
Civil Engineering 
 
 
 
Northeastern University 
Boston, Massachusetts 
 
 
(March 2011) 

i 
 
ABSTRACT 
Planning and executing a successful capital project is one of the main objectives of every 
public agency. A successful capital project is defined as a project completed in accordance 
with a given scope, within budget, and on time. Due to risks associated with complex 
projects, an owner agency usually adds an amount known as contingency to the estimated 
project cost to absorb the monetary impact of the risks and to prevent cost overrun. 
However, studies show that large capital infrastructure projects, especially transit projects all 
around the globe have been mostly experiencing cost and schedule overruns. Despite all 
efforts and evolving new probabilistic methods to establish sufficient and optimum 
contingency budget, many agencies have not been able to provide adequate contingency for 
their large capital projects. For instance, nearly 50% of the large active transportation 
projects in the United States overran their initial budgets. Some agencies have reacted to this 
issue by employing approaches that result in too large a contingency budget. Having too 
much contingency can be just as undesirable as insufficient contingency, especially where the 
agency is dealing with a portfolio of projects rather than a single project. Assigning large 
contingencies will use up the agency’s budget and will reduce the number of projects that 
may receive funding. 
In this research, a new probabilistic model is proposed for calculation of contingency in a 
portfolio of construction projects. A Bayesian approach is used to update historical 
contingency values based on new project data that becomes available as construction 
projects are completed. Most agencies dealing with a portfolio of infrastructure projects 
should define the level of confidence  for the portfolio budget based on available funding 
and the agency’s policy goals. An important question is what level of confidence  is needed 

ii 
 
at the individual project level to insure that the portfolio budget will not overrun with a 
probability of more than 


1
. This information is indispensable for the conduct of 
probabilistic risk assessment for individual projects.  
The mathematical model developed in this research provides an analytical tool for calculating 
contingency levels in such a way to meet agency goals with respect to individual projects and 
the project portfolio. The model assumes a hybrid normal distribution for the cost of 
individual projects and uses the historical data to calculate the primary parameters of the 
model. The model defines the required confidence level for the risk assessment of individual 
project with respect to the desired confidence level for sufficiency of the portfolio budget. 
The required increase in the portfolio budget is calculated based on the desired confidence 
level. The correlation between costs of projects is recognized and a structured guideline 
along with a mathematical method is suggested for estimating correlation coefficients 
between costs of projects in the portfolio. To consider the recent performance of projects 
and to update model characteristics based on new project data that becomes available, a 
Bayesian approach is employed to update the model on regular intervals, such as once every 
two years. As more information becomes available, the required adjustment in portfolio 
budget will be reduced, because the accuracy of estimating the contingency is improved. The 
proposed model is an effective tool for the agencies to develop contingency budgets based 
on all the performance data historically available and the new data that becomes available in 
the future. Even though the proposed model is a generic model that can be used on any type 
of infrastructure projects, our emphasis in this research is mostly on transit projects. Because 
of this, the funding process for the Federal Transit Administration (FTA) is analyzed and the 
practical application of the model is based on transit projects’ characteristics and costs.  

iii 
 
ACKNOWLEDGEMENTS 
Words cannot convey my gratitude to those who helped and supported me during my PhD 
studies. I would like to take this opportunity to express my individualized thanks to all of those, 
even though the list is long and the space allocation for this purpose is short.  
My special thanks and heartfelt gratitude go to my academic advisor Prof. Ali Touran for his 
invaluable advice, patience, guidance, and consistent support throughout my studies. The 
accomplishment of this work would have been impossible without his help and the lessons 
learned from him will be a precious asset in my career.  
I would like to extend my sincere appreciation to the committee members: Prof. Sara Wadia-
Fascetti, Prof. Douglas D. Gransberg, and Prof. Roberto Pietroforte for their valuable time and 
thoughtful comments. I am also grateful to Prof. Masoud Salehi for his kind advice in a section 
of this dissertation. I would like to thank the Department of Civil and Environmental 
Engineering of Northeastern University for its financial support and for providing a friendly and 
progressive work atmosphere, particularly the department chair Prof. Jerome F. Hajjar, the 
former acting chair Prof. Thomas Sheahan, Prof. Peter Furth, Dr. Daniel Dulaski, and the 
department staff Dr. David Whelpley, Patricia Michaud, Ed Stevens and Mike McNeil. I also 
appreciate the help and cooperation of Graduate School of Engineering staff specially Lisa 
O’Neill and College of Engineering IT staff David Moore, Tom Papadopoulos, and James Jones. 
Furthermore, I would like to thank my officemates and friends specially Kamran Ghavamifar, 
Arash Nasseri, Babak Jalalzadeh Fard, and Ye Zhang for their encouragement and support. 
Finally, my deepest gratitude goes to my wife, Raheleh Khosh Tinat, my parents, Mohammad 
and Monir Karim Bakhsh, and my sisters, Nasim and Saba for their endless love, support, and 
help. 

iv 
 
TABLE OF CONTENTS 
ABSTRACT ................................................................................................................................ i 
ACKNOWLEDGEMENTS ..................................................................................................... iii 
TABLE OF CONTENTS ........................................................................................................ iv 
LIST OF FIGURES ................................................................................................................ viii 
LIST OF TABLES ..................................................................................................................... x 
CHAPTER 1: INTRODUCTION ............................................................................................ 1 
1.1  OVERVIEW .............................................................................................................................. 1 
1.2  PROBLEM IDENTIFICATION ................................................................................................. 2 
1.3  RESEARCH OBJECTIVES ........................................................................................................ 4 
1.4  ORGANIZATION OF THE DISSERTATION ........................................................................... 4 
CHAPTER 2: CONTINGENCY CALCULATION METHODS............................................ 9 
2.1  INTRODUCTION ..................................................................................................................... 9 
2.2  CONTINGENCY DEFINITIONS ............................................................................................. 9 
2.3  CONTINGENCY CALCULATION METHODS ...................................................................... 12 
2.3.1  Deterministic Methods ............................................................................................................. 16 
2.3.2  Probabilistic Methods ............................................................................................................... 21 
2.3.3  Modern Mathematical Methods .............................................................................................. 38 
2.4  CONCLUSION ....................................................................................................................... 41 
CHAPTER 3: NEW STARTS PROJECTS DEVELOPMENT ............................................. 43 
3.1 
INTRODUCTION ................................................................................................................... 43 
3.2 
NEW STARTS PROJECTS PROGRAM ................................................................................... 44 
3.3 
NEW STARTS PROJECTS DEVELOPMENT ......................................................................... 45 
3.4 
FULL FUNDING GRANT AGREEMENT (FFGA) .............................................................. 47 
3.5 
COST ESTIMATION METHODOLOGY ................................................................................ 49 
3.6 
RISK MANAGEMENT AND CONTINGENCY ALLOCATION ............................................. 51 
3.7 
ESTIMATING ESCALATION COSTS ..................................................................................... 53 
3.8 
PREVIOUS STUDIES AND LESSONS LEARNED .................................................................. 57 
3.9 
CONCLUSION ....................................................................................................................... 59 

v 
 
CHAPTER 4: COMPARISON OF BUDGET ESTIMATING FOR TRANSIT 
PROJECTS IN THE U.S. AND THE U.K. ........................................................................... 61 
4.1 
INTRODUCTION ................................................................................................................... 61 
4.2 
FEDERAL TRANSIT ADMINISTRATION (TOP-DOWN) MODEL ....................................... 62 
4.2.1 
Top-down Model Background ................................................................................................ 62 
4.2.2 
Top-down Model Methodology .............................................................................................. 63 
4.2.3 
How to Assign  Values to Different SCCs at the Various Project Delivery Stages ... 65 
4.2.4 
Applying the Top-down Model to U.S. Data ....................................................................... 66 
4.3 
THE BRITISH DEPARTMENT FOR TRANSPORT (OPTIMISM BIAS UPLIFTS) MODEL ... 71 
4.3.1 
Optimism Bias Uplifts Model Background ........................................................................... 71 
4.3.2 
The Optimism Bias Uplifts Model Methodology ................................................................ 72 
4.3.3 
Applying Optimism Bias Uplifts Model to U.S. Data ......................................................... 73 
4.5 
COMPARISON OF TOP-DOWN AND OPTIMISM BIAS UPLIFTS MODELS ....................... 75 
4.6 
CONCLUSION ....................................................................................................................... 77 
CHAPTER 
5: 
A 
HYBRID 
NORMAL 
MODEL 
FOR 
CALCULATING 
CONTINGENCY IN A PORTFOLIO OF PROJECTS ........................................................ 78 
5.1 
INTRODUCTION ................................................................................................................... 78 
5.2 
BASIS OF THE PROPOSED MODEL ..................................................................................... 80 
5.3 
BAYESIAN APPROACH FOR UPDATING THE MODEL ..................................................... 88 
5.3.1 
Fundamental of Bayesian Approach ...................................................................................... 90 
5.3.2 
Bayesian Approach for k Independent Projects ................................................................... 92 
5.3.3 
Bayesian Approach for k Correlated Projects ....................................................................... 95 
5.4 
UPDATING THE PRIMARY PARAMETERS OF THE PROPOSED MODEL ......................... 99 
5.5 
SUMMARY ............................................................................................................................ 100 
CHAPTER 
6: 
SUGGESTED 
METHOD 
TO 
ESTIMATE 
CORRELATION 
BETWEEN PROJECTS’ COSTS .......................................................................................... 101 
6.1 
INTRODUCTION ................................................................................................................. 101 
6.2 
MEASURE OF DEPENDENCE ............................................................................................ 102 
6.2.1 
Pearson Coefficient ................................................................................................................. 102 
6.2.2 
Spearman’s Rank Correlation Coefficient ........................................................................... 103 
6.3 
SUBJECTIVE ESTIMATE OF CORRELATION .................................................................... 104 
6.4 
PROPOSED STRUCTURED GUIDELINE (PSG) TO ELICIT CORRELATION .................. 107 

vi 
 
6.4.1 
Identifying Common Risk Factors ....................................................................................... 108 
6.4.2 
Subjectively Estimating the Correlation............................................................................... 115 
6.4.3 
Delphi Method for Improving the Subjectively Estimated Correlation ......................... 117 
6.5 
IMPLEMENTATION OF CORRELATION ............................................................................ 119 
6.5.1 
Characteristics of Correlation Matrices ................................................................................ 119 
6.5.2 
Controlling Consistency of Correlation Matrices ............................................................... 121 
6.6 
SUMMARY ............................................................................................................................ 124 
CHAPTER 7: APPLYING THE PROPOSED MODEL ...................................................... 126 
7.1 
INTRODUCTION ................................................................................................................. 126 
7.2 
APPLICATION OF THE MODEL BY AN OWNER AGENCY ............................................. 127 
7.3 
SELECTING DATA TO FIND THE INITIAL VALUES OF AND  ............................... 128 
7.4 
SELECTING DATA (FIRST  DATASET) TO APPLY THE MODEL FOR THE FIRST 
TIME .................................................................................................................................... 132 
7.4.1 
Case Study Projects in the First Dataset .............................................................................. 133 
7.4.2 
Estimating Correlation between Projects in the First Dataset Using the PSG ............. 137 
7.4.3 
Positive Semidefinite Check for the Correlation Matrix in the First Dataset ................ 139 
7.5 
SELECTING DATA (SECOND DATASET) TO APPLY THE MODEL FOR THE 
SECOND TIME .................................................................................................................... 140 
7.5.1 
Case Study Projects in the Second Dataset ......................................................................... 141 
7.5.2 
Estimating Correlation between Projects in the Second Dataset Using the PSG ........ 144 
7.5.3 
Positive Semidefinite Check for the Correlation Matrix of the Second Dataset .......... 146 
7.6 
METHODOLOGY ASSUMED FOR APPLYING THE PROPOSED MODEL ....................... 147 
7.7 
APPLYING THE MODEL ASSUMING INDEPENDENCE COST DATA ............................ 148 
7.7.1 
Applying the Model on the First Dataset (Independent Case) ........................................ 148 
7.7.2 
Updating the Model Using the First Dataset Projects (Independent Case) ................... 152 
7.7.3 
Applying the Model on the Second Dataset (Independent Case) ................................... 154 
7.7.4 
Updating the Model Using the Second Dataset (Independent Case) ............................. 157 
7.8 
APPLYING THE MODEL ASSUMING CORRELATED COST DATA ................................. 160 
7.8.1 
Applying the Model on the First Dataset (Correlated Case) ............................................ 160 
7.8.2 
Updating the Model Using the First Dataset (Correlated Case) ...................................... 163 
7.8.3 
Applying the Model on the Second Dataset (Correlated Case) ....................................... 166 
7.8.4 
Updating the Model Using the Second Dataset (Correlated Case) ................................. 170 

vii 
 
7.9 
SENSITIVITY ANALYSIS FOR COST CORRELATION IMPACT ON REQUIRED 
PERCENT INCREASE IN BUDGET .................................................................................... 172 
7.10  ANALYSIS OF RESULTS ...................................................................................................... 175 
7.11  SUMMARY ............................................................................................................................ 177 
CHAPTER 8: CONCLUSION .............................................................................................. 179 
8.1  SUMMARY OF THE COMPLETED WORK .......................................................................... 179 
8.2  LIMITATIONS OF THE PROPOSED MODEL ..................................................................... 181 
8.3  RECOMMENDED WORKS FOR FUTURE .......................................................................... 183 
APPENDIX A: REFERENCES ............................................................................................ 185 
APPENDIX B: A PROPOSED MATHEMATICAL METHOD FOR CALCULATING 
COST CORRELATION ........................................................................................................ 199 
B.1  INTRODUCTION ................................................................................................................. 199 
B.2  BASIS OF THE METHOD .................................................................................................... 199 
B.3  NUMERICAL EXAMPLE ..................................................................................................... 203 
 

viii 
 
LIST OF FIGURES 
Figure 2.1: Estimating Total Project Cost (TPC) .......................................................................... 11 
Figure 3.1: Planning and Project Development Process for New Starts Projects (FTA 
2010c) ................................................................................................................................................... 46 
Figure 3.2: Standard Cost Category (SCC) Workbook Using by the FTA ................................ 50 
Figure 3.3: YOE and Mid-point of Construction Methods to Estimate Escalation 
(AACE 2010b) .................................................................................................................................... 55 
Figure 4.1: Standard Cost Categories (SCC) .................................................................................. 63 
Figure 4.2: Percentage of Each SCC to the Total Cost ................................................................ 67 
Figure 4.3: Final Top-down Model Curves (Total Required Budget) at Three Different 
Phases of a Transit Project ............................................................................................................... 69 
Figure 4.4: Converted Curves of the Top-down Model to Show the Required Uplift ............ 70 
Figure 4.5: Probability Distribution of Cost Overrun at Three Different Stage of a 
Project .................................................................................................................................................. 74 
Figure 4.6: Required Uplifts at Three Different Stages of a Project .......................................... 74 
Figure 5.1: Hybrid Normal Distribution ........................................................................................ 80 
Figure 5.2: Procedure for Applying the Proposed Model ............................................................ 88 
Figure 5.3: Prior Distribution of Parameter  (Ang and Tang 2007) ........................................ 91 
Figure 6.1: Relationships of Correlation Coefficient and Concordance Probability (Cho 
2006) ................................................................................................................................................... 106 
Figure 7.1: Fitting the Normal Distribution on 22 Transit Projects (Historical Dataset) ..... 131 
Figure 7.2: Probability of Budget Sufficiency in the Portfolio of Independent Projects 
)
( vs. in Individual Projects () .................................................................................................. 149 
Figure 7.3: Required Percent Increase in Budget 
)
(
* B
B
 vs. Probability of Budget 
Sufficiency in the Portfolio of Independent Projects () .......................................................... 150 
Figure 7.4: The prior, likelihood, and posterior distributions of cost overrun/ underrun 
Using Projects in the First Dataset (Independent Assumption) ............................................... 153 
Figure 7.5: Probability of Budget Sufficiency in the Portfolio of Independent Projects 
)
( vs. in Individual Projects () .................................................................................................. 155 

ix 
 
Figure 7.6: Required Percent Increase in Budget 
)
(
* B
B
 vs. Probability of Budget 
Sufficiency in the Portfolio of Independent Projects () .......................................................... 156 
Figure 7.7: The prior, likelihood, and posterior distributions of cost overrun/ underrun 
Using Projects in the Second Dataset (Independent Assumption) .......................................... 159 
Figure 7.8: Probability of Budget Sufficiency in a Portfolio of Correlated Projects () vs. 
in Individual Projects () ............................................................................................................... 161 
Figure 7.9: Required Percent Increase in Budget 
)
(
* B
B
 vs. Probability of Budget 
Sufficiency in the Portfolio of Correlated Projects ().............................................................. 162 
Figure 7.10: The prior, likelihood, and posterior distributions of cost overrun/ underrun 
Using Projects in the First Dataset (Correlated Assumption) ................................................... 165 
Figure 7.11: Probability of Budget Sufficiency in the Portfolio of Correlated Projects () 
vs. in Individual Projects () .......................................................................................................... 167 
Figure 7.12: Required Percent Increase in Budget 
)
(
* B
B
 vs. Probability of Budget 
Sufficiency in the Portfolio of Correlated Projects ().............................................................. 168 
Figure 7.13: The prior, likelihood, and posterior distributions of cost overrun/ underrun 
Using Projects in the Second Dataset (Correlated Assumption) .............................................. 171 
Figure 7.14: Required Percent Increase in Budget for the First Dataset Considering Four 
Different Correlation Matrices ....................................................................................................... 173 
Figure 7.15:  Required Percent Increase in Budget for the Second Dataset Considering 
Four Different Correlation Matrices ............................................................................................. 174 

x 
 
LIST OF TABLES 
Table 2.1: Contingency Estimating Methods (Adopted from Baccarini 2006) ......................... 14 
Table 2.2: Percentage of SHAs that Using Range (Probabilistic) Estimating (Olumide 
2009) ..................................................................................................................................................... 17 
Table 2.3: An Example of Agencies that use Deterministic Contingency ................................. 18 
Table 2.4: Required Contingency in Different Phases of a Normal Construction Project 
(Davis and Peng 2010) ...................................................................................................................... 19 
Table 2.5: A set of Arbitrary Classes of Risk (Yeo 1990) ............................................................. 26 
Table 3.1: Costs of Two New Starts Projects Reported in Two Different Reports 
Sponsored by the FTA ...................................................................................................................... 57 
Table 3.2: Average Cost Overrun percentages of Three Different New Starts Projects 
Samples Compiled by the FTA at three Phases of Project Development ................................. 59 
Table 4.1:  Values Assigned to Each Cost Category at Three Key Phases of a Transit 
Project .................................................................................................................................................. 68 
Table 4.2: 10th Percentile, 90th Percentile, Mean and Standard Deviation of Each Cost 
Category ............................................................................................................................................... 68 
Table 4.3: Required uplift with 50% Acceptable Chance of Cost Overrun with Two 
Approaches ......................................................................................................................................... 75 
Table 4.4: Comparison of the  Values in Two Approaches .................................................... 76 
Table 6.1: Identified Common Cost Factors for All Construction Projects (Adapted 
from Touran 2006b with Some Modifications) ........................................................................... 109 
Table 6.2: Identified Common Cost Factors for All Construction Projects (Adopted 
from Shane et al 2009) ..................................................................................................................... 110 
Table 6.3: Recommended Common Cost Factors in Correlation Estimation for a Pair of 
Projects .............................................................................................................................................. 111 
Table 7.1: List of 28 Transit Projects Adopted from Booz Allen Hamilton (2005) .............. 129 
Table 7.2: Cost Overrun/underrun of 28 Transit Projects Adopted from Booz Allen 
Hamilton (2005) ............................................................................................................................... 130 
Table 7.3: Dataset of Five Transit Projects for Applying the Model for the First Time 
(First Dataset) ................................................................................................................................... 132 
Table 7.4: Finding the Correlation Coefficients among Projects in the First Dataset ........... 139 

xi 
 
Table 7.5: Dataset of Four Transit Projects for Applying the Model for the Second Time 
(Second Dataset) .............................................................................................................................. 140 
Table 7.6: Finding the Correlation Coefficients among Projects in the Second Dataset ...... 146 
Table 7.7: Comparison of Cost Overrun/Underrun of Projects in the First Dataset 
Using the Proposed Model (Independent Assumption) ............................................................ 151 
Table 7.8: Comparison of Cost Overrun/Underrun of Projects in the Second Dataset 
Using the Proposed Model ............................................................................................................. 157 
Table 7.9: Comparison of Cost Overrun/Underrun of Projects in the First Dataset 
Using the Proposed Model (Correlated Projects) ....................................................................... 163 
Table 7.10: Comparison of Cost Overrun/Underrun of Projects in the Second Dataset 
Using the Proposed Model (Correlated Projects) ....................................................................... 169 
Table 7.11: Summary of the Results from Applying the Proposed Model on Transit 
Projects .............................................................................................................................................. 176 

 
1 
 
CHAPTER 1: INTRODUCTION 
1.1 
Overview 
Risks and uncertainties associated with a project are impediments to reach an accurate cost 
estimate. Nearly 50% of the large active transportation projects in the United States overran 
their initial budgets (Sinnette 2004). To overcome the cost overrun issue, identifying project 
risk factors and cost escalation factors have been the subject of much research (Shane et al 
2009; Flyvbjerg et al 2003; Pickrell 1990). For instance, Shane et al (2009) identified 14 risk 
factors classified in two categories: (1) Internal Sources such as bias, poor estimating, and 
contract document conflicts; (2) External Sources such as effects of inflation, market 
conditions, and unforeseen events/ conditions. To absorb the cost impact of these risk 
factors, a contingency budget is added to the total project budget. Contingency is defined as 
a reserve budget for coping with risks and uncertainties and to help keep the projects on 
budget. Contingency is traditionally estimated as a predetermined percentage of project base 
cost depending on the project phase. In recent years, some agencies have started conducting 
formal probabilistic risk assessment to estimate contingency budget rather than deterministic 
approach (Touran 2010; Molenaar 2005). However, to establish the contingency budget, an 
agency must make all efforts to set aside a budget which is optimized. This becomes more 
important when an agency is dealing with a portfolio of projects. Allocation of an excess 
budget for a project will use up the money that can be spent on other projects. For instance 

 
2 
 
the current approach used by the U.S. Federal Transit Administration (FTA) to estimate the 
contingency budget in transit projects called Top-down Model is based upon a probabilistic 
method using lognormal distributions for different cost categories in the project. Our 
research shows the way that cost categories are ranged is very conservative resulting in a 
contingency budget far larger than what might be indeed needed (Bakhshi and Touran 2009). 
1.2 
Problem Identification 
Planning and executing a successful capital project is one of the main objectives of every 
public agency. A successful capital project is defined as a project completed in accordance 
with a given scope, within budget, and on time. Cost overrun in capital projects can 
jeopardize project success and viability. It also redefines those projects that initially were 
promoted as effective vehicles to economic growth as possible impediments to such growth 
(Flyvbjerg et al 2003). Therefore, it is essential for agencies to keep their projects within 
budget if they want to ensure the successful completion of projects. Despite all claims 
regarding improved models, budget estimating for most capital projects especially transit 
projects have been constantly inaccurate for several decades (Touran 2010; Flyvbjerg 2006). 
To demonstrate this, we can refer to some research in which the transit projects have been 
studied: 
1. Pickrell (1990): 9 out of 10 reviewed transit projects sponsored by the Federal 
Transit Administration (FTA) of the U.S. Department of Transportation (DOT) 
experienced cost overrun with the average of 50.06% from their cost estimate at the 
Alternative Analysis/Draft Environmental Impact Study (AA/DEIS); 

 
3 
 
2. Flyvbjerg (2002): Flyvbjerg considered a sample of 258 transportation projects such 
as rail, fixed-link (tunnel and bridge), and road all around the world. On average, cost 
overrun occurred in 9 out of 10 projects. The average of cost overrun was 27.6% 
from the time that the project was approved for execution to the completion. 
Among them, 58 rail projects experienced the highest average of cost overrun of 
44.7%; 
3. FTA (2003c): 21 transit projects completed between 1990 and 2002 in the U.S. were 
reviewed in which 16 projects had cost overrun. On average, the sample of 21 
projects showed 20.9% cost overrun compared with inflation-adjusted cost estimate 
at the AA/DEIS; 
4. Booz.Allen.Hamilton (2005): They reviewed 28 transit projects in the U.S. They 
found that 26 out of 28 projects experienced cost overrun from the cost estimate at 
the AA/DEIS with the average of 36.3%;  
5. FTA (2008): Another 21 transit projects completed between 2003 and 2007 in the 
U.S. were reviewed. For 17 of them, the inflation-adjusted costs at the AA/DEIS 
were reported. All 17 projects experienced cost overrun with the average of 40.2% 
higher cost compared to their inflation-adjusted costs at the AA/DEIS. 
It should be mentioned that the Pickrell (1990), FTA (2003c), and FTA (2008) are three 
consecutive studies in which there is no repetitive project. Numerous observed cost 
overruns in capital projects suggest a need for developing an effective method for cost 
estimating and contingency allocation to control and prevent over budgeting issue. As it was 
mentioned earlier, this issue becomes even more important when an agency is dealing with a 
portfolio of projects where the cost overrun of one project can jeopardize the successful 
completion of other projects in the portfolio. In the context of this research, a portfolio of 

 
4 
 
projects is a capital program consisting of several projects where the contingency is being 
established at the program level.  
1.3 
Research Objectives 
In this research, the objective is to develop a new probabilistic model to effectively plan for 
projects’ cost overruns in a portfolio with allocation of sufficient and optimized contingency 
budget while it has the potential to be updated. To this end, there have been three main 
objectives: 
1. Calculating the required cost increase in the portfolio based on historical 
performance data; 
2. Estimating the pairwise correlation coefficient between costs of projects in the 
portfolio using a proposed structured guideline and/or a mathematical method; 
3. Updating the model using a Bayesian approach considering the performance of 
recently completed projects.  
The proposed model is a significant improvement over the state of art in research at this 
point. Also, it is expected that after each time that the model is updated, the required 
increase (or decrease) in portfolio budget will be reduced, because the accuracy of estimating 
the contingency is improved. 
1.4 
Organization of the Dissertation 
This dissertation is comprised of eight chapters and two appendices as follows.   

 
5 
 
Chapter 1 introduces the scope of work and the objectives of this research. The synopses of 
all chapters are presented here. 
Chapter 2 focuses on contingency definition and calculation. An extensive literature search 
was conducted and relevant information and data were collected. Contingency definition by 
different agencies is presented and discussed. An exhaustive list of common methods for 
calculating contingency budget is prepared and the methods are explained in detail. The 
methods are categorized in three main categories of: (1) Deterministic, (2) probabilistic, and 
(3) modern mathematical methods. At the end, the methods are compared and advantages 
and disadvantages of these methods are enumerated. 
In Chapter 3, the regulatory characteristics of New Starts transit projects and their planning 
and budget development process are concisely discussed. The problem and issues in their 
cost estimating process such as escalation and contingency allocation are explained in more 
detail. This will help in setting the stage for developing a probabilistic approach for 
determining the required contingency for future projects. 
In Chapter 4, the current budget estimating process to allocate contingency for transit 
projects in the U.S. and the U.K. are explained. Methods of contingency calculation and 
allocation in the U.S. and the U.K., known respectively as Top-down and the Optimism Bias 
Uplifts, are critically compared. Both methods are applied to the U.S. transit projects data and 
the results are discussed. The advantages and disadvantages of the two methods are 
highlighted. It is concluded that these methods do not provide an effective and optimum 
model for calculating the required contingency budget. The results also highlight the fact that 
developing a new method for calculating and allocating contingency budget is necessary and 
long overdue. 

 
6 
 
Chapter 5 describes the new probabilistic model proposed in this dissertation for contingency 
calculation in a portfolio of projects. This analytical method is developed using available 
historical data and assumes a hybrid normal distribution for cost of each project in the 
portfolio. This model can be applied to any set of projects that an agency desires to fund. It 
calculates the required increase in the budget in order to have a certain confidence for 
budget sufficiency. The model also can help the agency define the required level of 
confidence needed for risk assessment of individual projects with respect to the level of 
confidence associated with the portfolio budget. Then, a Bayesian approach for both 
independent and correlated cases is introduced to update the model in a specified time 
interval (for example, every two years) depending on the number of newly completed 
projects.  
In Chapter 6, we first explain the common correlation coefficients used in construction 
industry such as Pearson and Spearman’s Rank coefficients. Since in the proposed model we 
recognize the correlation between costs of projects, estimation of the pairwise correlation 
between costs of projects is required. Despite an intensive literature search, no previous 
work for estimating correlation between costs of projects where there is no historical data 
available was found; however, there were suggestions for subjectively estimating correlation 
coefficient between cost components in a project or activity durations (Cho 2006; Wang 
2000; Touran 1993). We propose a systematic guideline for eliciting the correlation 
coefficient between costs of projects. To this end, a list of common risk factors that can 
affect any pair of projects are identified among cost risk factors presented in the literature. 
This list works as a baseline to qualitatively estimate the correlation using a set of suggested 
guidelines and thresholds. The proposed method is called proposed structured guideline. 

 
7 
 
Furthermore, in Appendix B, a mathematical method is proposed for calculation of 
correlation coefficient where risk registers are available for projects. 
Chapter 7 is dedicated to the application of the proposed model and verification of its 
effectiveness. To accomplish this, 31 transit projects constructed in the U.S. and sponsored 
by the Federal Transit Administration (FTA) are selected. These projects are divided into 
three different datasets: (1) Historical Dataset consisting of 22 projects completed prior to 
2004, (2) First Dataset consisting of 5 projects completed in 2004, and (3) Second Dataset 
consisting of 4 projects completed in 2005 and 2006. Historical Dataset is used for initiating 
the model and calculating the primary parameters. To apply the model and realize the 
importance of accommodating the correlation, we consider two approaches. We first assume 
that projects in each dataset are statistically independent. In the second approach, the 
correlation among project costs is explicitly considered. Therefore, we recognize the 
correlation among projects in each dataset. Correlation coefficients between costs of projects 
in the datasets are estimated using the proposed structured guideline described in Chapter 6.  
Chapter 8 is the conclusion chapter. It summarizes the findings of the research and makes 
specific recommendation for future research. 
Appendix A lists the references used in this dissertation.  
Appendix B proposes a mathematical method for calculating the pairwise correlation 
coefficient between costs of projects. This method is developed on the premise of breaking 
down the total project cost to a deterministic base cost plus a probabilistic contingency (sum 
of monetary impacts of risk factors). It uses the common risk factors between any pair of 
projects to calculate a pairwise correlation coefficient between costs of projects. A numerical 

 
8 
 
example using two hypothetical transit projects along with their risk registers is provided to 
illustrate the use of the proposed method.   
 

 
9 
 
CHAPTER 2: CONTINGENCY CALCULATION 
METHODS 
2.1 
Introduction 
Owners usually need to have an accurate early cost estimate for their projects in order to 
provide sufficient budget for projects. A total cost of project is broken down to: (1) base 
cost, and (2) contingency cost. Base cost is the cost of project which is not including 
contingency (Touran 2006b). These are certain cost items of a project with a given scope 
necessary to physically deliver the project. Contingency is budget or time set aside to cope 
with uncertainties and risks during a project design and construction. 
In this chapter, we first present several contingency definitions given by different agencies. 
Then an exhaustive list of available methods for estimating contingency budget is compiled 
and explained. At the end, these methods are compared.  
2.2 
Contingency Definitions 
Project Management Institute (PMI 2004) delineates contingency as: “The amount of funds, 
budget or time needed above the estimate to reduce the risk of overruns of project 
objectives to a level acceptable to the organization.” The Association for the Advancement 
of Cost Engineering (AACE 2010a) defines contingency as: “An amount added to an 

 
10 
 
estimate to allow for items, conditions, or events for which the state, occurrence, or effect is 
uncertain and that experience shows will likely result, in aggregate, in additional costs. 
Typically estimated using statistical analysis or judgment based on past asset or project 
experience.” Moreover, it declares that contingency does not include costs caused by: 
1. Major scope changes; 
2. Extraordinary events such as major strikes and catastrophes; 
3. Management reserves which is an amount added to an estimate to allow for 
discretionary management purposes outside of the defined scope of the project; 
4. Escalation and currency effects. 
Construction Industry Research & Information Association (CIRIA 1996) describes 
contingency as three basic types in construction projects: 1. Tolerance in the specification; 2. 
Float in the schedule; 3. Money in the budget. Also Schneck et al (2009) categorizes 
contingency in construction projects in: 1. Schedule contingency; and 2. Cost contingency. 
As is revealed by aforementioned contingency definitions, there is unanimity that 
contingency is considered in project management for managing risks and uncertainty 
associated with cost and schedule of a project. It should be noted that our focus in this 
research is on cost contingency. Therefore, hereafter contingency refers to cost contingency 
unless otherwise stated.  
Since contingency is part of a project budget, this reveals the importance of estimating it as 
accurately as possible in the early stage of a project life. As the project progresses and the 
design details are decided, uncertainty associated with the project diminishes which means 
less contingency is required. Contingency is meant to keep the total project budget constant 
(Olumide et al 2010). In other words, by increasing the level of design and the clarity of 

 
11 
 
scope, base cost should go up and contingency becomes less. When a project experiences 
cost overrun, one of the reasons could be insufficient established contingency budget to 
absorb cost growth (Baccarini 2006). This shows the importance of accurate contingency 
estimation in the early stages of project development. To establish a total project’s budget, 
first the base cost is estimated. Then using a formal or informal risk assessment, the 
necessary contingency budget in accordance with the owner’s (or in case of public projects, 
agency’s) policy is added. Also, to consider the effect of inflation, market conditions, and 
variation in interest rate, the budget must be escalated. Escalation is usually not included in 
contingency (AACE 2010a; Moselhi 1997), because it is important to separate the cost of 
uncertainties resulting from inflation from uncertainties caused by technical difficulties, 
environmental issues, and administrative delays. The procedure to calculate total project cost 
(TPC) is depicted in the following diagram (Figure 2.1). 
 
Figure 2.1: Estimating Total Project Cost (TPC)
 
It should be noted that contingency can be seen from contractor’s stand point and owner’s 
stand point. Also, a close attention should be paid that project allowances are different from 
contingencies. Project allowances are estimates or plug numbers that estimator uses to 
account for project components that are hard to estimate either because the design is not 
complete or because based on available information an accurate estimate is not feasible 
(Touran 2006b). These allowances are undoubtedly part of project scope and must be 
incorporated in the base cost. 

 
12 
 
2.3 
Contingency Calculation Methods 
As it was stated earlier, contingency is a budget for prevailing cost growth due to risks and 
uncertainties associated with a project. In other words, contingency is meant to offset the 
cost impact of uncertainties and risks that influence a project. This magnifies the importance 
of conducting a formal risk assessment to estimate as accurate as possible the contingency 
budget. Mak and Picken (2000) show the effectiveness of risk analysis to estimate 
contingency. They collected data on 332 building projects; among them 45 had used risk 
analysis. Defining a new variable DEVI, the ratio between the amount of contingency and 
the amount of variation at final cost, the hypothesis test that the mean of both groups were 
equal was rejected and they concluded that a significant improvement of resulted in 
contingency calculation by the use of risk analysis.  
The Association for the Advancement of Cost Engineering (AACE 2008a) categorizes the 
methods to estimate risk cost and establish contingency in four major groups: 
1. Expert judgment: An expert or a group of experts with strong experience in risk 
management and risk analysis define(s) the percentage of contingency for the project 
under consideration ; 
2. Predetermined guidelines: A set of predetermined contingency values is provided for 
different key phases of certain project types; 
3. Simulation analysis including range estimating and expected value: This method 
usually integrates expert judgment with an analytical model. Then a simulation 
process such as Monte Carlo simulation is employed to obtain probabilistic output; 

 
13 
 
4. Parametric modeling: This method usually quantifies the amount of cost growth 
using risk drivers by the means of multi variable regression or artificial neural 
network; 
Aforementioned methods will be explained in more detail in the following sections of the 
current chapter.  
Schneck et al (2009) groups the methods of contingency calculation into:  
1. Deterministic methods: 
1.1:  An across-the-board percentage addition on the base cost estimate derived on 
the basis of intuition, experience, and historical data; 
1.2: Combination of line item specific contingencies with an overall unallocated 
contingency. The line item contingencies are based upon a combination of historical 
cost variance, project features, and identified risk of the project; 
2. Probabilistic methods based on the statistical and probability analysis of project risk 
factors and estimation of project cost variance such as linear and nonlinear 
regression, the probability based Monte Carlo, and artificial neural network 
simulation.   
Baccarini (2006) describes the traditional percentage as the most commonly used method in 
practice. He also mentions Monte Carlo simulation, regression analysis, and artificial neural 
networks as the methods that have gained prominence in recent times. Table 2.1 depicts 
several methods that Baccarini referred to in his review of the contingency concept.   
 

 
14 
 
Table 2.1: Contingency Estimating Methods (Adopted from Baccarini 2006) 
Contingency Estimating 
Methods 
Reference (Example) 
Traditional percentage 
Ahmad 1992, Moselhi 1997
Method of Moments 
Diekmann 1983; Moselhi, 1997, Yeo 1990 
Monte Carlo Simulation 
Lorance & Wendling 1999, Clark 2001 
Factor Rating 
Hackney 1985, Oberlander & Trost 2001 
Individual risks – expected value
Mak, Wong & Picken 1998; 2000 
Range Estimating
Curran 1989
Regression Analysis 
Merrow & Yarossi 1990; Aibinu & Jagboro 2002
Artificial Neural Networks 
Chen & Hartman 2000; Williams 2003 
Fuzzy Sets 
Paek, Lee, & Ock, 1993
Influence Diagrams 
Diekmann & Featherman 1998
Theory of Constraints 
Leach 2003
Analytical Hierarchy Process 
Dey, Tabucanon & Ogunlana 1994 
 
One should realize that the methods given by Baccarini in Table 2.1 are not completely 
different categories of models. For instance, range estimating can be categorized under 
Monte Carlo Simulation as it always needs random number generating for analysis. Also, 
artificial neural network and regression analysis are two subcategory of parametric modeling 
(AACE 2008a). The Methods mentioned by Baccarani (2006) will be covered in our 
exhaustive list of contingency estimation in the next sections.   
 In this research, we divide the common methods for establishing contingency budget into 
three main groups: 1. Deterministic methods; 2. Probabilistic methods, and 3. Modern 
mathematical methods. All other common methods will be explained as the subcategories of 
these three. Figure 2.2 depicts all common methods. These methods are described in detail 
in the following sections. 

 
15 
 
 
Figure 2.2: Contingency Calculation Methods
Contingency 
Calculation 
Methods
 
Deterministic 
Methods 
Probabilistic 
Methods 
Modern 
Mathematical 
Methods
Predefined 
Percentages 
(Fixed/ Line 
Items) 
Expert  
Judgment 
Simulation 
Methods  
(Monte Carlo) 
 
Non-Simulation 
Methods 
Fuzzy 
Techniques 
Range 
Estimating 
Integrated 
Models for 
Cost & 
Schedule 
Parametric 
Estimating 
 
PERT 
Analytic 
Hierarchy 
Process 
 
Regression 
Expected 
Value* 
First-Order 
Second-
Moment  
Probability 
Tree 
Artificial 
Neural 
Network 
Optimism 
Bias Uplifts 
*If there are variable risks in the risk register, the use of simulation is required. Please see Section 2.3.2.1.3. 

 
16 
 
2.3.1 Deterministic Methods 
Deterministic methods are considered to be the simplest and most common methods used 
to establish contingency budget (AACE 2008a; Baccarini 2006; Touran 2003). These are 
used by owners when they do not want to apply a formal risk assessment on a project due to 
lack of time, size of project, or insufficient budget. The term deterministic implies that these 
methods offer a point estimate for contingency budget. In these methods usually a 
predetermined (guideline) or project oriented (expert judgment) percent of base cost 
depending on the project phase and development level is assigned as contingency budget. 
The percentages become smaller by the project development when more details are added in 
design and less uncertainties associate with project.    
Even though deterministic approaches are simple and easy to apply, they have a main 
drawback. They cannot effectively address the risks specific to a project and consider the 
unique effects of project complexity, market condition, and location (Olumide et al 2010; 
AACE 2008a). Even in project oriented percentage where an expert or panel (estimator, 
engineer, or project manager) defines a unique percentage of base cost to allocate as 
contingency, this approach cannot be very effective since they do not implement a formal 
risk assessment to identify all risks and uncertainties associated to that certain project. 
Furthermore, the use of a fixed percentage does not provide information on the level of 
protection that this contingency is providing for the budget or schedule. 
Even though in the recent years some agencies have started the use of probabilistic methods, 
deterministic methods are still employed by a most agencies. Olumide (2009) reports on a 
research led by Molenaar (NCHRP Project 08-60) in which 48 State Highway Agencies 
(SHA) were interviewed; it was revealed that the majority of these states are using 

 
17 
 
deterministic contingency in their projects and a few of them uses formal risk assessment. 16 
out of 48 SHAs were using predetermined contingency method in their projects. The result 
of these interviews is summarized in Table 2.2. Term range has been defined for those cost 
estimates that are delivered probabilistically which may be shown graphically with a 
probability curve.   
Table 2.2: Percentage of SHAs that Using Range (Probabilistic) Estimating (Olumide 2009) 
Project  
Development Phase 
Never Use 
Ranges 
Sometimes 
Use Ranges 
Always Use 
Ranges 
Planning 
36%
55%
9%
Programming and Preliminary Design
53%
38%
9%
Final Design 
70% 
19% 
11% 
 
Table 2.2 shows that the number of agencies that always use probabilistic methods for cost 
estimating is relatively small. Table 2.3 summarizes various agencies practices in calculation 
of deterministic contingency. Parsons Jr. (1999) recommended a set of contingency values 
based on design completion stage for Waste Management (WM) projects of Department of 
Energy (DOE). Schneck et al (2009), Olumide et al (2010) and Olumide (2009) list a number 
of agencies such as AACE and States Department of Transportation (DOT) that employ 
deterministic methods for contingency allocation. These examples are summarized in Table 
2.3.  

 
18 
 
Table 2.3: An Example of Agencies that use Deterministic Contingency 
Agency 
Contingency Required at Different Phases 
Phase 1 
Phase 2 
Phase 3 
Phase 4 
Phase 5 
Name 
Design 
Compl 
Cont. 
Val. 
Name 
Design 
Compl
Cont. 
Val. 
Name 
Design 
Compl
Cont. 
Val. 
Name 
Design 
Compl
Cont. 
Val. 
Name 
Design 
Compl
Cont. 
Val. 
DOE, 
WM 
Projects 
Planning 
0-2% 
50% 
Conceptual 
1-5% 
40% 
Title I 
5-20% 
30% 
Title II 
20-
50% 
15% 
Construction
50-
100% 
5% 
AACE 
Exploration: 
Class V 
0-2% 
50% 
Concept 
Definition: 
Class IV 
1-5% 
30% 
Basic 
Engineering: 
Class III 
5-20% 
20% 
Detailed 
Engineering: 
Class II 
20-
50% 
15% 
Construction
: Class I 
50-
100% 
5% 
Louisiana 
DOT 
Planning/ 
Environmenta
l 
 
30% 
Preliminary 
Design 
 
15% 
Final Design
 
10% 
Construction
 
5% 
 
 
 
Electric 
Power 
Research 
Institute 
Class I: 
Simplified 
Planning 
0-5% 
30-
50% 
Class II: 
Preliminary 
Engineering 
10-
15% 
15-
30% 
Class III: 
Detailed 
Engineering 
25-
35% 
10-
20% 
Class IV: 
Finalized 
Engineering 
60-
100% 
5-
10% 
 
 
 
California 
DOT 
Planning 
Estimates 
 
25% 
General 
Plan 
Estimates 
 
20% 
Marginal 
Estimate, 
Final Plans 
 
5% 
 
 
 
 
 
 
Maryland 
DOT 
Planning 
 
35-
40% 
Programmin
g and 
Preliminary 
 
25-
35% 
Final Design
 
0-
25% 
 
 
 
 
 
 
Florida 
DOT 
Initial Cost 
Estimate 
 
25% 
Design 
Scope of 
Work 
 
20% 
Design 
Phase I 
30% 
15% 
Design 
Phase II 
60% 
10% 
Design 
Phase III 
90% 
5% 
 

 
19 
 
Olumide (2009) also mentions that Nevada, and Washington State DOTs are using 
contingency percentages similar to Caltrans (California DOT) given in Table 2.3.  
Davis and Peng (2010) concluded that contingency percentages used by agencies are 
influenced by factors such as project stage, type, location, complexity and design quality. 
They summarize the percentages used for a normal (not complex) construction project in 
different phases in Table 2.4.  
Table 2.4: Required Contingency in Different Phases of a Normal Construction Project 
(Davis and Peng 2010) 
Required Contingency at Phase 
Planning 
Preliminary
Budget 
Definitive 
25 to 35% 
20 to 25% 
10 to 20% 
5 to 15% 
 
Baccarini (2005) presented the results of a survey of 78 project practitioners participating in a 
project management conference regarding issues relating to project cost contingency. A key 
finding was that most practitioners were not aware that contingency is a risk management 
notion even though they knew it is a reserve budget. It is also found that 77% of 
practitioners were still using a deterministic percentage approach for estimating project cost 
contingency.  
In summary deterministic methods can be summarized in two main categories which will be 
explained in the following sections. 

 
20 
 
2.3.1.1 Predefined Percentages (Fixed/Line Items) 
This approach is the simplest method of contingency allocation. In this method, either an 
across-the-board predetermined (fixed) percentage of total project base cost or various 
percentages of line items will be added to the project budget as contingency. When 
contingency is added separately for each line item (allocated contingency), it can be an 
overall contingency as unallocated contingency added to the project budget on top of the 
allocated contingency. Each agency has its own set of guideline for contingency percentages. 
For instance, one can refer to Table 2.3 for a few examples of suggested percentages by 
different agencies. The suggested percentages are given for different key phases of a certain 
type of project and may be a single value or a range of values. Even though this method is 
simple and easy to apply, it does not consider the unique situation of each project and 
specific risk factors and uncertainties associated with every project. Moreover, it does not 
quantify the degree of confidence (confidence level) that the estimated contingency will 
provide against cost overruns. 
2.3.1.2 Expert Judgment 
The only difference of this method and predetermined percentage is that in this method 
there is not a set of predetermined percentages, but an expert or a group of experts with 
strong experience in risk management and risk analysis define(s) the percentage of 
contingency for the project under consideration. Even though this method can relatively 
considers the specific situation of each project by adding unique percentage for each project 
but it does not go through a formal and comprehensive risk assessment. Therefore, the 
contingency budget cannot be estimated adequately. Furthermore, similar to predefined 

 
21 
 
percentage method, it does not provide the confidence level for the sufficiency of the 
estimated contingency.  
2.3.2 Probabilistic Methods 
The main difference between probabilistic methods and deterministic methods is that in 
probabilistic methods, uncertainties are explicitly modeled using appropriate statistical 
distributions (Touran 2006b). In deterministic methods the degree of confidence that the 
contingency will provide cannot be quantified against cost overruns (Davis and Peng 2010; 
Touran 2003). Also, it does not bring under consideration all risks and uncertainties that 
effect a project.  
A cost estimate is considered as the prediction of the expected final cost of a project with a 
given scope and constructed during a certain time window (Dysert 2006). This definition 
discloses the probabilistic nature of cost estimate. Due to all uncertainties and risks 
associated with construction projects from errors in calculation to catastrophes affecting the 
project, finding the exact cost of a project is near to impossible. That is why a distribution or 
range can be more a realistic representation of project cost item. Using a cost distribution, 
one can define the level of confidence against different values of project cost. According to 
Moselhi (1997), contingency is an inverse function of risk that management accepts at an 
associated probability of cost overrun occurrence. The lower the taken risk of cost overrun 
occurrence is, the higher contingency budget will be required.   
In probabilistic models the uncertainties and risks are incorporated within the cost estimate. 
The necessary contingency budget is estimated based on a desired confidence level 
determined by sponsor agency. A probabilistic method of contingency calculation uses 

 
22 
 
formal risk analysis with probability concepts to model uncertainties affecting project cost 
and schedule (Touran 2006b). These types of models calculate a range of estimate rather 
than a point estimate. All mathematical operations such as addition, subtraction, 
multiplication, and other have to be performed on data ranges, and require the use of 
probability theory. Probabilistic models output which are distributions help the client 
understand the possible consequences of their decision where point estimate does not have 
this flexibility (AACE 2008b). Probabilistic risk assessment may employ a set of tools such as 
fault tree, probability tree, decision analysis, and Monte Carlo simulation (Touran 2006b). 
Probabilistic methods usually need more time and budget to conduct, and some agencies and 
most contractors are not willing to employ it on their normal projects. According to Smith 
and Bohn (1999) only contractors engaged in procurement of highly complex projects invest 
in formal risk analysis. In their study, they interviewed 12 contractors. The interviews 
revealed that none of them had the mathematical knowledge to calculate contingency.  
Following sections explain the common practices of probabilistic contingency calculation in 
the construction industry. 
2.3.2.1 
Non-simulation Methods 
This category includes the analytical methods in which risk assessment and contingency 
calculation are conducted without the use of simulation software packages. This is an 
advantage when an agency is not willing to invest on such software packages. However, 
these approaches are not suitable for large infrastructure projects where complex models are 
required. These models can be effective tools for the risk assessment of early phases of 
project developments such as conceptual or planning when project definition is not 

 
23 
 
complete. With the advent of the low-cost, personal computer-based, and powerful 
simulation software, the justification for the use of non-simulation approaches is reduced. 
However, the main weaknesses of simulation approaches, such as lack of a closed-form 
solution and the possibility of non-convergence of results remain. 
Following are some examples of non-simulation methods. 
2.3.2.1.1 
Probability Tree 
Probability trees provide a systematic method to transform individual risks each with a 
conditional expected value impact and probability of occurrence into an overall probability 
and expected value. This method is a diagrammatic representation of possible outcomes of 
consequence events. This model is not practical when the number of risks become large as 
the number of outcomes increases exponentially with the number of risks (Parsons et al 
2004).  
2.3.2.1.2 
First-Order Second-Moment (FOSM) 
FOSM methods are approximate methods to calculate the mean and standard deviation of 
complex functions. They usually linearize the function first using methods such as Taylor 
series about an appropriate point (usually mean) and then its first and second moments are 
obtained.  
Let us assume that we have the different cost components of a project as a random vector 
X  with mean vector 
X
μ  and covariance matrix V . If we consider total project cost Y as a 
nonlinear function of X , we have: 

 
24 
 
)
X
(
g
Y 
 
 
 
 
 
 
 
 
 
 
(2.1) 
The 
Y
μ and 
2
Y
σ depend on the entire joint distribution of vector X . Now, using the FOSM 
we can approximately estimate the mean and standard deviation of vector Y . The 
linearization of Y  is conducted around  
X
μ using Taylor series: 
)
(
)
X
(
)
μ
(
)
X
(
X
μ
X
1
X
i
X
i
n
i
i
X
X
g
g
g
Y









 
 
 
 
 
(2.2) 
Therefore with some approximation: 
)
μ
(
X
g
μY 
 
 
 
 
 
 
 
 
 
 
(2.3) 
)
,
(
)
X
(
)
X
(
X
X
μ
X
1
1
μ
X
2
j
i
j
n
i
n
j
i
Y
X
X
Cov
X
g
X
g
σ









 
 
 
 
 
(2.4) 
In Eq. (2.4), the values of 
)
,
(
j
i X
X
Cov
come from covariance matrix V .  
2.3.2.1.3 
Expected Value  
In this method first all significant risks in the risk register are identified. Risk register is a list 
of all risks/opportunities along with their impacts on cost/schedule of the project which is 
the important product of risk identification process (Touran 2006b). Then the risks need to 
be quantified by estimating the probability (likelihood) of risks’ occurrence and impact of 
risks. The expected value of each risk is calculated by multiplying the probability of 
occurrence and its impact. If the all impacts are deterministic, the analysis can be done 
without simulation. However, most of the times it is not the case and the impact is uncertain 

 
25 
 
and has a distribution. AACE (2009a) groups the risks that have deterministic impact as 
fixed (or deterministic) and those with uncertain impact as variable (or continuous). When 
the risks are variable or at least there is one, the use of Monte Carlo is required and this 
method should be considered as a simulation method. The correlation among the risks can 
be addressed while using Monte Carlo simulation. The contingency is considered to be the 
sum of all expected values and has a distribution (CDF) when the impacts are uncertain.  
AACE (2209a) recommends that those risks that are being accepted by agency should be 
input to expected value analysis. Accepted risks are those that will remain part of the project 
scope and plan after mitigation and not being transferred or avoided. It also classifies the 
risk as significant when the expected value of risk affects the cost bottom line by more than 
±0.5% (called critical variance) at the conceptual estimate or ±0.2% at the detailed estimate. 
If the risk is not significant it is dropped from further consideration in the analysis. The risk 
quantification is usually done in a workshop setting. The probability of risks’ occurrence are 
estimated either using a percent point (or decimal point) or in preset qualification terms such 
as low, moderate, high, and very high. The advantage of preset qualification terms is that 
getting consensus on these terms among the participants is easier than specific probability 
percentages (AACE 2009a). 
2.3.2.1.4 
Program Evaluation and Review Technique (PERT) 
Program Evaluation and Review Technique (PERT) is a project management method 
developed in 1957 which works for both schedule and cost of projects using central limit 
theorem (CLM). This method assumes a Beta distribution for the cost of each item which is 
approximated with a three point estimate: optimistic cost (lowest), most likely (target), and 

 
26 
 
pessimistic (highest). These three points can be either estimated quantitatively using data 
from previous projects or qualitatively using expert knowledge and experience (Moselhi 
1997). Yeo (1990) suggested a set of arbitrarily defined classes of risk given in Table 2.5 that 
can help estimator find the optimistic and pessimistic points based on an estimated cost item 
(target or most likely).  
Table 2.5: A set of Arbitrary Classes of Risk (Yeo 1990) 
Class of 
Risk 
Definition of 
Parameters 
Probable Error Range 
Lowest Bound
Upper Bound
A 
Reasonably Well Defined
-5%
+20% 
B 
Fairly Defined
-10%
+30% 
C 
Poorly Defined
-15%
+40% 
D 
Undefined
-20%
+50% 
 
Having the three-point estimate of each cost item, mean and variance of cost item 
distribution can be calculated based on some assumptions in the PERT method as follows:  
6
4
b
m
a
x
x
x
x



 
 
 
 
 
 
 
 
 
(2.5) 
2
6








a
b
x
x
v
 
 
 
 
 
 
 
 
 
(2.6) 
Where 
ax is the optimistic estimate, 
bx is the pessimistic estimate, 
m
x is the most likely 
estimate, x  is the mean of distribution of cost item and v is its variance. Also, Yeo (1990) 
modifies the original variance equation according to a 5-95th percentile as follows: 
2
2.3








a
b
x
x
v
 
 
 
 
 
 
 
 
 
(2.7) 

 
27 
 
PERT assumes that the cost items are independent of each other which is a drawback of this 
method. Therefore, when there are sufficiently large numbers of independent cost items 
(more than say five), the sum, based on central limit theorem (CLT) follows a normal 
distribution whose mean is the sum of all cost items’ means and its variance is the sum of all 
cost items’ variances. This distribution is used to define the required contingency budget for 
different probabilities that budget will not fall short.  
Moselhi and Dimitrov (1993) suggested a probabilistic method similar to PERT which can 
accommodate the correlation among the project cost items. The mean in this method is 
similar to PERT but the variance is proved to be as follows regardless of the type of the 
marginal distributions of cost items: 








n
i
n
i
n
i
j
j
i
ij
i
tot
C
V
C
V
C
V
C
V
1
1
1
)
(
.)
(
2
)
(
)
(

 
 
 
 
 
(2.8) 
Where 
tot
C
is the total cost of project comprised of n cost items (random variables) with 
known variances 
)
(
i
C
V
 and correlation matrix
n
j
i
R
ij
...,
,2
,1
,
,


. 
Even though the modified PERT model proposed by Moselhi and Dimitrov accommodates 
the correlation among cost items and have preference over traditional PERT model, this is 
still cannot be considered theoretically accurate since it assumes that total cost has a normal 
distribution. This assumption is not true when cost items are not independent and 
correlation among them is observed.  

 
28 
 
2.3.2.1.5 
Parametric Estimating 
This method creates a relationship between an output which can be the cost overrun and 
inputs which can be a set of risk factors. This relationship is developed using historical data 
and methods such as multivariate regression analysis, artificial neural network, or even trial 
and error. Even though this method is simple and quick to apply, precaution is needed to 
select the risk factors that have predictable relationship with the outcome. First, parameters 
of the model which are risk factors such as scope definition, level of complexity, and size of 
project must be identified (AACE 2009b). It is recommended by AACE (2009b) that 
outcome is set as cost growth percentage relative to the base estimate excluding contingency. 
Data must be controlled to be free of any obvious and significant errors. After establishing 
all input and output parameters and collecting the necessary data, the relationship model can 
be constructed using either traditional multivariate regression analysis or more recent neural 
network methods.  
The neural network methods are classified as Modern Mathematical Methods and will be 
explained in Section 2.3.3.2. 
2.3.2.1.5.1 
Regression 
This type of parametric estimating has been used since 1970s. A review by Skitmore and 
Patchell in 1990 on cost modeling systems showed that use of regression analysis have been 
focused on finding the best predictors of bid price (Baccarini 2006). This model is more 
effective for the early cost estimate when there is not enough detail about the project. Using 
a sophisticated model at the early stages of project requires adding assumptions that add 
more uncertainty to the analysis and runs against the parsimony principle of regression 

 
29 
 
analysis. Ideally, the regression model must be sophisticatedly simple and without using 
unnecessary parameters should provide the best fit for the data at hand (Baccarini 2006). 
Regression method is recommended where there is a linear relationship between dependent 
(e.g. cost growth) and independent variables (risk factors). While the assumption of linearity 
is not necessarily true, it is commonly made. 
Most of the time analysts need to have a distribution of possible outcomes in order to 
determine required contingency for acceptable levels of risk. AACE (2009b) suggests a 
simple method which is consistent with observed industry data to convert the calculated 
contingency value from regression analysis to a probability distribution. This method is 
based on two assumptions: cost outcomes (base cost plus contingency) are more or less 
normally distributed, and contingency is equal to standard deviation of the distribution. The 
mathematical explanation for these assumptions can be found in Rothwell (2005). This 
simple model helps the analyst form a normal distribution of cost where the mean of the 
distribution is the estimated base cost plus the contingency calculated from the regression 
model and its standard deviation is the contingency calculated from the regression model.  
As an instance of the regression method, Kim and Ellis (2006) formed a model to estimate 
and predict cost contingency of transportation projects based on two factors: original 
contract amount, and estimated contingency amounts set by maximum funding limits. 
Florida Department of Transportation (FDOT) defines the maximum funding limit based 
on a percentage of original contract amount. For example, if the original contract amount is 
$5 million or less, the maximum funding limit is the minimum of 5% of the contract amount 
and $50, 000. Kim and Ellis (2006) used data from 79 Florida DOT projects to develop the 

 
30 
 
model and 53 projects to validate it. Estimated contingency amounts were calculated using 
maximum fund limits of FDOT. The proposed model is: 
2
1
ˆ
00141
.0
ˆ
88
.0
5017
ˆ
X
X
Yi



 
 
 
 
 
 
 
(2.9) 
Where 
iYˆ is the required contingency, 
1ˆX  is the estimated contingency amount set by 
maximum funding limit, and 
2
ˆX is the original contract amount. Their model has a 
coefficient of determination R2=0.84 and the validation confirmed that it has the capability 
to estimate the contingency with good accuracy.   
Creedy et al (2010) employed regression to check if there is any Pearson’s correlation 
between cost overrun and risk factors for highway projects. They collected 231 highway 
projects data executed by Queensland Department of Main Road (QDMR) and completed 
between 1995 and 2003. Their study was comprised of two parts. First, they identified the 
risk factors contributing significantly to cost overrun from owners’ view. For this purpose, 
they employed factor analysis (i.e. principal components analysis) and expert elicitation (i.e. 
nominal group technique). As a result of this part, they identified 11 factors such as design 
change, quality change, insufficient investigations and latent conditions contributed 
significantly in cost overrun. Then, they used multivariate regression analysis to identify 
direct correlations between cost overrun and factors such as geographical project type 
(urban/rural projects), project construction type, project delivery type, indexed project 
programmed cost (size of project), and identified risk factors in the previous part. They used 
forward and stepwise multivariate regression analyses and generated three identical models. 
They also employed backward analyses and generated 13 models. The coefficient of 
determination R2 of models ranged from 0.019 to 0.061 and the models have not fitted the 

 
31 
 
data very well. Using developed mode, they concluded that there are no strong correlations 
between project type, work type, and project risk factors in producing cost overrun.  
2.3.2.1.6 
Analytical Hierarchy Process (AHP) 
To assess the effect of risks on the projects, different methods have been proposed that 
utilize probability analysis and Monte Carlo simulation. However, there is not always 
quantitative detailed information available to us for developing such models. Therefore, the 
use of a subjective approach for project risk assessment sometimes becomes indispensable. 
The analytical Hierarchy Process (AHP) developed by Saaty (1980) presents a flexible and 
simple way of project risks analysis. The linguistic terms used in AHP allows risk analyst to 
include subjectivity, experience, and knowledge in an intuitive and natural way. This was first 
applied in the risk analysis by Mustafa and Al-Bahar in 1991 for the risk assessment of a 
construction project (Dey et al 1994).  
In a method suggested by Dey et al (1994), first the whole project is classified according to 
the work breakdown structure (WBS). Risk analysis is performed separately for various work 
packages (WP). In each WP, risk factors and subfactors are identified and the overall risk of 
WP is calculated using the AHP. To allocate contingency budget they use two tiers. First, 
they implement the PERT approach suggested by Yeo (1990) for each WP to estimate the 
total cost distribution. Then using the overall risk of WP estimated from AHP, they find the 
appropriate targeted cost from the total cost distribution. The required contingency is the 
difference of the targeted cost and base cost.  

 
32 
 
2.3.2.1.7 
Optimism Bias Uplifts  
Optimism Bias Uplifts method (also known as Reference Class Forecasting) is a non-
simulation probabilistic method developed by Flyvbjerg and COWI (2004) for the British 
Department for Transport (DfT) in effort to deal with optimism bias in capital project cost 
estimates. According to Flyvbjerg et al (2002; 2005) and Flyvbjerg (2006), psychological 
(optimism bias) and political explanations (strategic misrepresentation of costs due to 
political and organizational pressure) are responsible for much of the inaccuracy in 
transportation cost forecasting. Optimism bias and strategic misrepresentation are among 
the most difficult systematic risks to deal with (AACE 2009b).  
In this method, transportation projects have been divided into a number of distinct groups. 
These groups include road, rail, fixed links (such as tunnel or bridge), buildings, and IT 
projects and have been selected in order to have statistically similar risk of cost overrun 
based on the study of an international database of 260 transportation projects. For each 
category, the probability distribution for cost overrun as the share of projects with a given 
maximum cost overrun was created. Having established the empirical cumulative probability 
distribution, uplifts are set up as a function of the level of risk that the DfT is willing to 
accept regarding cost overrun. “Uplift” is the term used to show the amount that the original 
estimate needs to be increased to arrive at the project budget for a given level of certainty 
with respect to cost adequacy. If the DfT wants to accept a higher risk, then a lower uplift is 
required. In this approach, it is assumed that the projects in future will behave similar to the 
past projects from a budgeting point of view. In other words, the improvement in cost 
containment in future projects is completely disregarded. Also, because the uplift values are 

 
33 
 
based on a relatively small number of projects (for example, the database is comprised of 
only 46 rail projects), serious error can potentially occur in the calculated uplifts.  
In Chapter 4, the Optimism Bias Uplifts method using by the DfT in the U.K. is compared 
with a method practiced by the United States FTA for transit projects in the U.S.  
2.3.2.2 
Simulation Methods (Monte Carlo) 
In this method usually expert judgment and an analytical method come together to reach a 
probabilistic output using a simulation routine (AACE 2008a).  In many cases where the 
closed form equations are not available or due to several mathematical operations of 
distributions, analytical models become more complicated, simulation can help analyst find 
the probabilistic output. Touran (1993) declares that the use of simulation in most cases is 
indispensable because direct analytical approaches tend to be difficult and are sometimes 
infeasible. Monte Carlo is one of the most common simulation methods in the construction 
industry which is widely applied in risk analysis and contingency calculation. Monte Carlo 
methods rely on repeated random sampling of various cost distributions and basically need a 
computer to be applied. Monte Carlo refers to the famous Casino in Monte Carlo, Monaco, 
famed for gambling casinos and luxurious hotels (Clark 2001). The name connotes the 
uncertainty associated with gambling with modeling uncertainty. This method first was 
introduced by Stanislaw Ulam, a Polish mathematician.    
The outcome of simulation should be evaluated to ensure it is reasonable (Clark 2001; 
Touran 2006b). When even an unrealistic model is developed, simulation can be conducted 
to reach some results which may be misleading. As simulation always “works” (garbage in, 

 
34 
 
garbage out!) some people may distrust the results (Touran 2006b).  Clark (2001) summarizes 
the steps needed to conduct a Monte Carlo simulation: 
1. Prepare estimate and review it by a group meeting to get a precise estimate; 
2. Conduct group Monte Carlo meeting to develop the data to conduct simulation; 
3. Prepare and run Monte Carlo analysis; 
4. Write report to management including recommended contingency.  
One of the most common methods that employ Monte Carlo simulation is Range 
Estimating. 
2.3.2.2.1 
Range Estimating 
This term was first coined by Curran (1976, 1989) and he even obtained a patent for the use 
of the term! In this method, first critical cost items are identified. The deterministic estimate 
of each critical cost item is considered as the most likely value. Next, the minimum and 
maximum values of the critical items are defined by a project group. At the end, with the 
help of Monte Carlo simulation the total cost cumulative distribution function (CDF) is 
calculated. This CDF is used to estimate the required contingency to reach the desired 
confidence level that budget will not fall short.  
To identify the critical items, the Pareto’s Law, the law of the significant few and the 
insignificant many, or what is known as 80/20 rule is employed (Moselhi 1997, AACE 
2008b). It means 80% of the risks costs will be associated with 20% of cost items. In other 
words, 20% or fewer of the cost items are critical. AACE (2008b) explains the critical item as 
an item that its deviation from target can cause ±0.5% change (called critical variance) in the 

 
35 
 
bottom line cost at the conceptual estimate or ±0.2% at the detailed estimate. Just those cost 
items identified as critical are ranged by a project team based on their knowledge and 
experience. AACE (2008b) recommends the probability range of 98% (1 to 99 percentile) 
for considering the extreme events. It also mentions that the minimum and maximum values 
are not comprised of events that would be considered way out of scope such as Acts of God 
or funding cuts which are outside of 1 to 99 percentile. Considering very rare events can lead 
to overstatement of the risks and consequently tie unnecessary contingency budget. After 
determining the range of critical cost items, all the required information is available to run a 
Monte Carlo simulation. The non-critical items are input in the analysis as the fixed 
(deterministic) values. Each critical item can have different probability density function 
(PDF) such as triangular, normal, lognormal, or Beta.1 The selection of appropriate PDF for 
each cost item depends on how it fits the available data or meets the project group’s belief. 
There are numerous commercial software packages such as @Risk and Cristal Ball that can 
help analysts apply Monte Carlo simulation. By adding all cost items (ranged and fix) and 
running the model for sufficient iterations (say 500 to 5000), the total project cost which is 
now a distribution (CDF) rather than a deterministic value, is calculated. This CDF describes 
the probability that total project cost as a random variable will be found at a value less than 
or equal to a certain number. Based upon the level of risk that agency desires to accept (80% 
is a common confidence level), the total project cost is selected from the estimated CDF. 
Defining 80% as the confidence level means that there is only 20% chance that the total 
project cost will go over the selected total project cost. The required contingency is the 
difference between the newly estimated cost and initially estimated cost before applying 
range estimating. The range estimating can be applied at any key phase of the project and 
                                                 
1 In Curran’s approach, the CDF is confidential and the same CDF is apparently used for all critical cost 
items. Here, we are describing the concept of range estimating rather than the specific method used by Curran.  

 
36 
 
even during the construction phase at any certain period of time to release unnecessary 
contingency budget. Recently all software packages are capable to accommodate correlation 
among cost items by the means of Spearman Rank correlation method which will be 
explained in Chapter 5.  
An example of this method is the technique used by the Federal Transit Administration 
(FTA 2007b) published in Project Guidance (PG)# 40 called Top-down model. In this 
guideline, the FTA requires a formal risk assessment for all new transit projects. In this 
method, various project cost components are treated as random variables and are ranged 
according to predetermined values to explicitly model the variability of each major cost 
component. Lognormal distribution is assumed for each cost category. The sum of these 
cost components will be a distribution that represents the total cost. This method will be 
explained in more detail and compared with the method used by British Department for 
Transport in Chapter 4.  
2.3.2.2.2 
Integrated Models for Cost and Schedule 
The final costs and schedules for large infrastructure projects have been underestimated for 
the past decades (Flyvbjerg 2002). Even though it is obvious that cost estimate and schedule 
of construction projects are somehow related, cost estimating and probabilistic scheduling 
are often separately and independently applied (Isidore and Edward Back 2002). When there 
is no such a direct link between schedule and cost estimate of a project, the developed model 
cannot completely capture uncertainty and risk impacts associated with the project. 
Therefore, the calculated contingency budget may not be sufficient.  

 
37 
 
A model called ABC-Sim (Activity Based Costing Simulation) was developed by Isidore and 
Edward Back (2002) in which range estimating and probabilistic scheduling are applied 
simultaneously on an appropriately modeled construction project at the work breakdown 
structure (WBS) level. This model is based on discrete event simulation. Its main advantage 
over the traditional range estimating and probabilistic scheduling is that the model is capable 
of performing both range estimating and probabilistic scheduling simultaneously on a 
properly modeled construction project. Also, the model enables the analyst to find the 
project schedule value and its corresponding cost estimate value in each iteration of running 
model. After simulation, they use an analytical method to explain the relationship between 
the cost estimate and schedule data.  
Roberds and McGrath (2006) suggested an integrated cost and schedule risk assessment 
approach for infrastructure projects. They discussed that most commercial software 
packages developed for conducting risk analysis using Monte Carlo simulation are not 
capable of conducting true probabilistic, risk based, integrated cost and schedule modeling. 
They suggested the use of general-purpose Monte Carlo simulation software such as @Risk 
for developing tailor-made spreadsheet-based models with following capabilities: 
 Calculate the base project duration by considering activities relationships and critical 
path; 
 Calculate base project cost by adding up all activities costs; 
 Calculate cost escalation of each activity from current dollar to the year-of-
expenditure (YOE) which is usually the mid-point of activity duration. The midpoint 
for a certain activity is calculated from the simulated start point and the total activity 
duration considering the uncertainty associated with the duration; 

 
38 
 
 Incorporate uncertainties including risks and opportunities; 
 Calculate total activity cost which is the sum of all escalated base activity costs plus 
all risks effects, and project duration. 
Touran and Bakhshi (2010) introduced an integrated cost and schedule model for multi-year 
programs which considers uncertainties in cost, schedule, and escalation. This model uses 
Monte Carlo Simulation and considers Martingale series for modeling of escalation 
uncertainties. This Model is developed in an Excel spreadsheet; @Risk 5.0 (Palisade Corp 
2008) is used for Monte Carlo simulation.  
2.3.3 Modern Mathematical Methods 
2.3.3.1 
Fuzzy Techniques  
Fuzzy set theory is a branch of modern mathematics that was first introduced by Zadeh in 
1965 for modeling vagueness intrinsic in human cognitive process (Chan et al 2009). This is a 
method for capturing vagueness, uncertainty, imprecision, embedded human knowledge, 
human behavior, and intuition, and fuzzy logic enables computing with words where words 
are used instead of numbers (Sachs and Tiong 2009). In the risk assessment process when 
there is no statistical data available, opinions of experts with years of experience become very 
important. Experts can provide qualitative assessment of the risks. The conversion of these 
qualitative statements to numbers for estimating the uncertainty is not always easy. Fuzzy set 
theory is a mathematical tool that can help analyst quantify these linguistic terms (Choi et al 
2004). Due to conceptual differences between fuzzy logic and probabilistic logic, Fuzzy 
technique has not been categorized into probabilistic methods.  Even though both have 

 
39 
 
values ranging between 0 and 1, fuzzy logic corresponds to degree of truth and probabilistic 
logic corresponds to probability (likelihood) (Buckley and Eslami 2002).  
Sachs and Tiong (2009) develop a method for quantifying qualitative information on risk 
called Quantitative Qualitative Information on Risks (QQIR). In this method, fuzzy sets are 
used for capturing expert opinions and fuzzy weighted average method is employed for 
aggregating that information. The outcome of their model is a probability density function. 
Moreover Chan et al (2009) gives a review of fuzzy techniques in the field of construction 
management. It seems that the use of fuzzy sets and logics in the risk assessment and 
contingency calculation is becoming more widespread. As an example, Choi et al (2004) 
developed a risk assessment method for underground construction projects. The proposed 
model is comprised of four steps of identifying, analyzing, evaluating, and managing the risks 
inherent in construction projects and a risk analysis software is developed using uncertainty 
modeling based on fuzzy sets concept. In the analyzing step mentioned above, a fuzzy-based 
uncertainty model considers the uncertainty range involved in both probabilistic parameter 
estimates and subjective judgment. The final outcome of this model is a point estimate of 
total risk as the mean.  
Also, Paek et al (1993) presented a model for pricing construction risks using fuzzy sets as a 
tool for contractors to assist them in deciding the bidding price of a construction project.  
2.3.3.2 
Artificial Neural Network 
Artificial Neural Network (ANN) is an information processing technique that simulates 
human brain and its biological process (Chen and Hartman 2000). ANN uses a mechanism 
to learn from training examples and detect hidden relationships among data for generalizing 

 
40 
 
solutions to future problems (Baccarini 2006). ANN is a better solution for modeling 
complex nonlinear relationships than conventional method such as nonlinear regression 
analysis (Chen and Hartman 2000). ANN uses a set of observations (input and output) to 
find the pattern called training example. After training, a network has the capability to 
estimate outputs quickly for new cases when fed only with their associated inputs (Moselhi et 
al 1993). Two drawbacks of ANNs are: analyzing and explaining the relationship between 
inputs and outputs is hard to accomplish because ANNs are essentially black-box methods 
(Chen and Hartman 2000); also selection of the consistence and unbiased inputs as the 
training data is really important because existence of bias in the training data is the major 
factor that limits the performance of an ANN (Touran and Lopez 2006; Chen and Hartman 
2000).      
As an example of this method, Chen and Hartman (2000) used ANN on the oil and gas 
projects. They selected projects performed by one organization in order to have as much 
consistency in practices as possible. They identified 19 risk factors for achieving successful 
budget and schedule performance. They nominated a group of 80 projects randomly divided 
for training, test, and production subsets with splits of 60/20/20 percent (48/16/16 
projects). A commercial neural network development software package called NeuroShell 2 
was used to implement training and develop the model. For cost performance model 
development, they used back propagation (BP) and general regression neural network 
(GRNN) algorithms. In the model trained with the BP, cost variance percentage (underrun/ 
overrun) of 75% (12 out of 16) production projects were predicted correctly. However, in 
four projects the model performed contrarily in which the difference between the actual cost 
overruns/ underruns and predicted ones were not over 23%. They also implemented a 
comparison on ANN and multiple linear regression analysis (MLR) by conducting MLR on 

 
41 
 
the same data. The comparison revealed that ANN outperformed MLR and can be used as a 
method of cost performance prediction with an acceptable accuracy.   
2.4 
Conclusion 
Several contingency definitions were presented in this chapter. According to these 
definitions, there is consensus that cost contingency is a reserve budget for coping with 
monetary impacts of risks and uncertainties associated with a project. Therefore, if the 
impact of risks associated with a project can be estimated as accurate as possible, then the 
necessary contingency budget will be allocated accordingly. It should be noted that 
contingency budget is not intended to absorb the impacts of escalation, major scope 
changes, and extraordinary. 
The most important and common methods to calculate contingency budget were 
introduced. The whole methods were classified into three main categories of: 1. 
deterministic, 2. probabilistic, and 3. modern mathematical methods. Deterministic methods 
are simple and easy to apply and consider to be still the most commonly used method. 
However, they are not capable of effectively addressing the risks specific to a project and 
reflect the unique characteristics of project such as complexity, market condition, and 
location. Also, the use of a fixed percentage does not provide information on the level of 
protection that this contingency is providing for the budget.  
Probabilistic methods recognize the probabilistic nature of cost estimate by incorporating 
the uncertainties and risks within the cost estimate. Some agencies and most contractors are 
not willing to employ probabilistic methods on their normal projects because they usually 
need more time and budget to conduct. Unlike deterministic methods, the necessary 

 
42 
 
contingency budget is estimated based on a desired confidence level determined by sponsor 
agency. Probabilistic methods are divided into two main categories: 1. Non-simulation 
methods, and 2. Simulation methods. Non-simulation methods are based on analytical 
methods and can employed with no need to software packages. This is an advantage when 
one is not willing to invest on such software packages. As it was mentioned, these models 
can be effective tools for the risk assessment of early phases of project developments such as 
conceptual or planning when project definition is not complete. However, these approaches 
are not suitable for large infrastructure projects where complex models are required. With 
the advent of the low-cost, personal computer-based, and powerful simulation software, the 
justification for the use of non-simulation approaches is reduced. Nevertheless, the main 
weaknesses of simulation approaches, such as lack of a closed-form solution and the 
possibility of non-convergence of results remain. 
Two relatively new approaches in risk assessment: 1. fuzzy technique, and 2. artificial neural 
network (ANN) were classified as the third category of modern mathematical method. In 
risk assessment, fuzzy technique is used to quantify the qualitative assessment of risks 
provided by experts. Fuzzy technique mathematically helps analyst convert linguistic terms 
into numbers. ANN is a type of parametric estimate and uses a mechanism to learn from 
training examples and detect hidden relationships among data for generalizing solutions to 
future problems. ANN has proved better prediction for complex and nonlinear models.   

 
43 
 
CHAPTER 3: NEW STARTS PROJECTS 
DEVELOPMENT 
3.1 
Introduction 
The Federal government has provided a large portion of the Nation’s capital investment in 
urban mass transportation especially in new starts projects since early 1970s (FTA 2002). New 
starts projects are new fixed guideway systems or extension to existing fixed guideway 
systems that might be eligible for the Federal financial support under 49 U.S.C. 5309 (United 
States Code: Title 49, Transportation, Subtitle III, General and Intermodal, Chapter 53, 
Public Transportation, Section 5309, Capital Investment Grants) if they meet certain criteria. 
Due to the fact that the demand for federal funds exceeded the supply, Urban Mass 
Transportation Administration (UMTA) (the predecessor to the Federal Transit 
Administration (FTA)) in the late 1970s established new policies to ensure that the available 
Federal funds would be used in the most prudent and effective manner. As part of this 
effort, UMTA developed Full Funding Grant Agreement (FFGA) as a contract between the 
Federal government and a transit agency. As time passed, UMTA/FTA gained more 
experience and the FFGAs became more sophisticated to protect the Federal government’s 
interest. The FTA has prepared various manuals regarding project development and 
management to assure completion of high quality projects on time and within budget 
according to the scope.    

 
44 
 
Despite all these precautions, we still see that the new starts projects suffer from cost 
overrun. In the current chapter, we briefly discuss the regulatory characteristics of new starts 
projects and their planning and development process. This will help in setting the stage for 
developing a probabilistic approach for determining the required contingency for future 
projects.    
3.2 
New Starts Projects Program 
The Federal Transit Administration (FTA) has helped several local transit agencies get the 
Federal technical and financial support for locally planned, implemented, and operated fixed 
guideway transit projects such as heavy rail, light rail, commuter rail, and bus rapid transit 
systems. 49 C.F.R. §611 defines the New Starts Project as a new fixed guideway system, or 
an extension to an existing fixed guideway system. This part prescribes the process that local 
agencies (applicants/ grantees/ sponsors) must follow to be considered eligible for capital 
investment grants and loans through new starts program. Also, this part prescribes the 
procedures used by the FTA to evaluate proposed new starts projects as required by 49 
U.S.C. 5309(e), and the scheduling of project reviews required by 49 U.S.C. 5328(a).  
On August 10, 2005, President George W. Bush signed the Safe, Accountable, Flexible, 
Efficient Transportation Equity Act: A Legacy for Users (SAFETEA-LU) as an amendment 
to Title 49. SAFETEA-LU authorized the Federal surface transportation programs for 
highways, highway safety, and transit for the 5-year period 2005-2009. SAFETEA-LU 
authorized $6.6 billion in new starts funding through fiscal year 2009 and has been extended 
to fiscal year 2010 in which Congress appropriated $2 billion for new starts funding (FTA 
2010d).  

 
45 
 
Prior to SAFETEA-LU, federal transit amendments were Intermodal Surface 
Transportation Efficiency Act (ISTEA) in 1991 which authorized $5 billion over the 6 years 
in new starts funding and the Transportation Equity Act for the 21st Century (TEA-21) in 
1998 which authorized nearly $218 billion in Federal funding for highway, highway safety 
and transit programs over six years.  
3.3 
New Starts Projects Development 
SAFETEA-LU requires the FTA to evaluate and rate the projects requesting federal support 
and entering to the new starts program at specific key points of the project’s planning and 
development. There are specific criteria that the FTA must consider before inputting a fixed 
guideway transit project into new starts program and entering into a long term commitment 
to a local agency. These criteria include project cost effectiveness, the transit supportiveness 
of existing and future land use, and local financial commitment. Evaluation of a candidate 
project’s performance against the new starts criteria eventually results in an overall project 
rating of "Highly Recommended," "Recommended," or "Not Recommended."  
Figure 3.1 depicts the procedure that the FTA must follow during the planning and project 
development of a new starts project. For entering into all key phases with the exception of 
alternative analysis (AA), the FTA must evaluate, rate and approve projects. AA and much 
of the preliminary engineering (PE) is conducted within the metropolitan planning process 
specified by SAFETEA-LU and the environmental review process as required by the 
National Environmental Policy Act of 1969 (NEPA). AA is a corridor-level analysis to 
address local requirement and is considered complete with the selection of a locally preferred 
alternative (LPA) to advance into PE. In the PE phase, the LPA is further developed and 

 
 
enviro
estim
comm
which
financ
agree
Figur
 
Proje
Over
onmental im
mate is reaso
mitment is a
h the sponso
cial commit
ment (FFGA
re 3.1: Planni
ect review a
sight Contra
mpacts and m
nably firm. 
allocated. Th
or gets ready
ment to fun
A).  
ing and Proje
and oversigh
actors (PMO
mitigations are
Also, the fi
he last phase
y for constr
nd the new
ect Developm
ht by the F
OCs) require
46 
e identified. T
inancial plan
e of project 
uction and t
w start proje
ment Process
FTA is cond
ed by 49 C.
The project 
n with the m
developmen
the FTA ma
ect known a
s for New St
ducted throu
.F.R. § 633
scope is fina
majority of 
nt is final de
ay enter into
as the full f
tarts Projects
ugh Project 
. PMOC ro
alized and co
local fundin
esign (FD) i
o a multi-yea
funding gran
 
s (FTA 2010c
Managemen
ole in a fixe
st 
ng 
in 
ar 
nt 
c)
nt 
ed 

 
47 
 
guideway transit project is to monitor and oversee the project’s process to determine 
whether it is on time, within budget, in conformance with design criteria, constructed to 
approved plans and specifications, and is efficiently and effectively implemented. The FTA 
has documented procedures that the PMOCs must follow in each phase of project life in a 
set of Project Guidance (PG) manuals. 
3.4 
Full Funding Grant Agreement (FFGA) 
Full Funding Grant Agreement (FFGA) is a contract between the FTA and a local transit 
authority (grantee) that establishes the FTA commitments to provide the Federal support for 
a new start project. According to Circular C5200.1A (Full Funding Grant Agreements 
guidance) by the FTA, FFGA defines the terms and conditions for Federal financial 
participation, describes the project, sets the maximum amount of Federal new starts funding 
for a project, stipulates project completion, and facilitates efficient management of the 
project in accordance with applicable Federal statutes, regulations, and policy. This is the 
point that the FTA contractually commits to a new start project.  
The whole life cycle of a transit project development is divided into several phases as 
follows: 
1. Alternative Analysis (AA) / Draft Environmental Impact Study (DEIS); 
2. Preliminary Engineering (PE)/ Final Environmental Impact Study (FEIS); 
3. Final Design (FD); 
4. Full-Funding Grant Agreement (FFGA); 
5. Construction; 
6. Revenue Operation (RO). 

 
48 
 
The FTA mostly enters into FFGA commitment after FD regardless of project delivery 
method such as design-bid-build (DBB), design-build (DB), or design-build-operate-
maintain (DBOM) (FTA 2010e, and 2002). Before establishing the FFGA, the project 
management oversight contractor (PMOC) must go over a procedure to examine the 
Grantee’s readiness to enter into a FFGA which protects the FTA’s interests. The PG-52, 
Readiness to Execute FFGA (FTA 2010c), describes necessary review, analysis, and 
recommended procedures and reporting requirements that PMOC must follow. The final 
product of the PMOC is part of the package that is submitted to Congress. The FFGA 
readiness review is basically an update of earlier reviews and risk assessments performed at 
entry to both PE and FD.  
Circular C5200.1A enumerates the reasons that may affect the length of time required for 
reaching the point to establish FFGA as follows: 
1. Nature of the corridor;  
2. Complexity of the project alternatives;  
3. Magnitude and nature of potential environmental impacts;  
4. Status of local planning data bases, e.g., socioeconomic, transportation 
systems data;  
5. Quality of local analysis tools, e.g., travel demand forecasting, cost 
estimation;  
6. Competence and motivation of local agency staff; and  
7. Absence or presence of local consensus on how to proceed.  
Aforementioned reasons will vary the time required to establish FFGA from the application 
submission.  

 
49 
 
3.5 
Cost Estimation Methodology 
Cost estimation is a progressive process that as a project develops from conceptual toward 
final design and project scope is better defined, it becomes more accurate. Grantees initially 
conduct cost estimation and the FTA controls the accuracy of cost estimates at entry to each 
key phase of project.  
In transit projects, project costs are estimated from the bottom up using work breakdown 
structure (WBS). The WBS helps define all hard costs (what is to be built) and soft costs 
(management and administrative costs including fees, testing, etc.). Soft costs are typically 
20% of a project cost (FTA 2003b), although it varies depending on project characteristics 
(TCRP 2010). 
In 2005, the FTA started implementing a new format for cost estimates called the Standard 
Cost Categories (SCCs) for new starts projects. The FTA classifies all costs of a new start 
transit project into ten SCCs, SCC-10 to SCC-100. Figure 3.2 illustrates a typical SCC 
workbook. The SCC workbook is a project management tool and constructs a consistent 
format for the reporting, estimating, and managing of capital costs for new starts projects. 

 
50 
 
 
Figure 3.2: Standard Cost Category (SCC) Workbook Using by the FTA
 
In the FFGA, there is a cost term called Baseline Cost Estimate (BCE). The BCE includes 
all costs necessary to complete the project with a given scope in the FFGA and is eligible for 
Federal assistance (FTA 2002). The BCE reflects escalation, contingencies, and schedule 
dates pertaining to the individual cost elements or contract units. Cost escalation can be 
calculated either based on year of expenditure or mid-point of construction. Contingency 
can be added to each line item, or added as a whole to the project cost estimate, or both. In 
the FFGA, the BCE is the Estimated Total Project Cost unless a grantee choose to pursue 
activities or pay for items within the project scope of work that are not eligible for Federal 
assistance; in this case, the Estimated Total Project Cost will be greater than the BCE. The 
estimated total project cost shows the total projected costs of the project at the time of the 
FFGA award (FTA 2002).   
10 GUIDEWAY & TRACK ELEMENTS (route miles)
40.06 Pedestrian / bike access and accommodation, landscaping
10.01
Guideway: At-grade exclusive right-of-way
40.07 Automobile, bus, van accessways including roads, parking lots
10.02
Guideway: At-grade semi-exclusive (allows cross-traffic)
40.08 Temporary Facilities and other indirect costs during construction
10.03
Guideway: At-grade in mixed traffic
50  SYSTEMS
10.04
Guideway: Aerial structure
50.01 Train control and signals
10.05
Guideway: Built-up fill
50.02 Traffic signals and crossing protection
10.06
Guideway: Underground cut & cover
50.03 Traction power supply:  substations 
10.07
Guideway: Underground tunnel
50.04 Traction power distribution:  catenary and third rail
10.08
Guideway: Retained cut or fill
50.05 Communications
10.09
Track:  Direct fixation
50.06 Fare collection system and equipment
10.10
Track:  Embedded
50.07 Central Control
10.11
Track:  Ballasted
10.12
Track:  Special (switches, turnouts)
60.01 Purchase or lease of real estate  
10.13
Track:  Vibration and noise dampening
60.02 Relocation of existing households and businesses
20 STATIONS, STOPS, TERMINALS, INTERMODAL (number)
70 VEHICLES (number)
20.01 At-grade station, stop, shelter, mall, terminal, platform
70.01 Light Rail
20.02 Aerial station, stop, shelter, mall, terminal, platform
70.02 Heavy Rail
20.03 Underground station, stop, shelter, mall, terminal, platform 
70.03 Commuter Rail
20.04 Other stations, landings, terminals:  Intermodal, ferry, trolley, etc. 
70.04 Bus
20.05 Joint development 
70.05 Other
20.06 Automobile parking multi-story structure
70.06 Non-revenue vehicles
20.07 Elevators, escalators
70.07 Spare parts
30 SUPPORT FACILITIES: YARDS, SHOPS, ADMIN. BLDGS
30.01 Administration Building:  Office, sales, storage, revenue counting
80.01 Preliminary Engineering
30.02 Light Maintenance Facility 
80.02 Final Design
30.03 Heavy Maintenance Facility
80.03 Project Management for Design and Construction
30.04 Storage or Maintenance of Way Building
80.04 Construction Administration & Management 
30.05 Yard and Yard Track
80.05 Professional Liability and other Non-Construction Insurance 
40 SITEWORK & SPECIAL CONDITIONS
80.06 Legal; Permits; Review Fees by other agencies, cities, etc.
40.01 Demolition, Clearing, Earthwork
80.07 Surveys, Testing, Investigation, Inspection
40.02 Site Utilities, Utility Relocation
80.08 Start up
40.03 Haz. mat'l, contam'd soil removal/mitigation, ground water treatments
90 UNALLOCATED CONTINGENCY
40.04 Environmental mitigation, e.g. wetlands, historic/archeologic, parks
40.05 Site structures including retaining walls, sound walls
100  FINANCE CHARGES
Standard Cost Categories for Capital Projects
(Rev.11a, June 4, 2008)
60 ROW, LAND, EXISTING IMPROVEMENTS
80 PROFESSIONAL SERVICES (applies to Cats. 10-50)

 
51 
 
The Maximum Federal New Starts Financial Contribution is stipulated in the FGGA and 
signifies the limit on the amount of Section 5309 new starts funds that will be allocated to 
the Project. The Federal government has no obligation to provide further financial assistance 
for the project beyond the Maximum Federal New Starts Financial Contribution. If this 
budget is insufficient to complete the project, the grantee agrees to expeditiously finish the 
project and accepts sole responsibility for the payment of any cost overruns.  
Even though the FTA accepts no responsibility for cost overruns, they closely review the 
cost estimates at entry to each key phase and right before the FFGA execution. There are 
also Project Guidance (PG) manuals to conduct risk assessment and estimate necessary 
contingency budget that the grantee is supposed to employ over the course of project 
development before and even after execution of the FFGA. This is done to prevent cost 
overrun that can jeopardize the on-time completion of project and tax payers’ interests.  
3.6 
Risk Management and Contingency Allocation 
As it was mentioned, contingency is a component added to the BCE which is intended to 
absorb the impacts of uncertainties and risk factors on projects. The FTA had established a 
set of predefined contingency amounts as percentage of total estimated cost for different 
phases of project development as follows (FTA 2003b): 
1. Conceptual Design: 20% or higher 
2. Preliminary Design: 10-20% 
3. Definitive (75-100% Design): 5-15% 
4. Detailed (Complete Plans, Specifications, and Estimate): 0-10% 

 
52 
 
However, in late 2003, the FTA established a new guidance using an event-based analysis 
process entitled “Risk Assessment and Mitigation Procedures” as PG-22 (FTA 2003a). In 
this method, a risk register prepared during a risk workshop is used to estimate the required 
contingency. These are the items in the grantee’s estimate that seem to vary significantly with 
anticipated ranges. Using a Monte Carlo simulation, the sum of all these risk factors is 
calculated. Since this method considers details and elemental events is called a bottom-up 
analysis.  
Sillars and O’Connor (2008) described bottom-up analysis and showed that the costs were 
underestimated using this risk assessment approach. They analyzed the budget established 
using this procedure for three projects in detail. The result showed some variation between 
actual and predicted costs. However the study demonstrated the improvement on previous 
method where contingency was a set of subjective percentages mentioned above.  
The observed variation in the actual and estimated cost of projects using the PG-22 
motivated the FTA for developing a more conservative procedure in which projects were 
allocated larger contingencies to overcome uncertainties and risk events. To this end, in 2007 
the PG-22 was superseded with the PG-40 (Risk Management Products and Procedures 
2007) which is a holistic method and called the top-down model. The FTA found out that 
considering the individual risk events and not project risk as a whole may ignore some risk 
events that are individually insignificant but collectively have large impact on the total cost 
(Sillars and O’Connor 2008).  
The top-down model considers the SCCs and ranges cost components using a set of 
predetermined coefficient. It assumes a lognormal distribution for each cost components 
and the sum of these cost components will be a distribution that represents the total cost. 

 
53 
 
However, in this method the way that cost categories are ranged is somewhat conservative 
resulting in a contingency budget far larger than previous approaches (Bakhshi and 
Touran 2009). It can be argued that using conservative contingencies is not prudent 
especially for an organization that is dealing with a portfolio of projects every year. This 
overestimation of contingency will use up the budget that can be spent on other projects 
waiting to enter into new starts program.     
In the next chapter the top-down model is explained in more detail and is employed on a set 
of data as the current contingency estimation in the U.S. Also, the current technique used in 
the U.K. is explained and applied on a set of data. These two models are then analyzed and 
compared. 
3.7 
Estimating Escalation Costs 
FTA requires that for each project, the cost escalation should be calculated and added to the 
budget. Association for Advancement of Cost Engineering (AACE) defines escalation as: 
“The provision in actual or estimated costs for an increase in the cost of equipment, 
material, labor, etc., over that specified in the purchase order or contract due to continuing 
price level changes over time. Inflation may be a component of escalation, but non-
monetary policy influences, such as supply-and-demand, are often components.” (ACCE 
2010a)  
Escalation is a risk factor and can have large impact on the cost estimate. The FTA study 
(2003c) in the review of 19 new starts projects found the inflation as the largest component 
of the difference in absolute dollars between the estimated cost and the final costs. As it was 

 
54 
 
mentioned earlier, the FTA requires local transit agencies to escalate construction costs to 
reflect predicted inflation (FTA 2003b). The escalation cost is reported as a separate budget 
line item. This requirement takes into consideration the fact that over time, materials and 
labor costs may rise due to general inflation. The FTA (2003b) mentions two methods to 
calculate the escalation costs. One is to estimate it by applying an assumed fixed annual 
percentage to probable construction costs through the mid-point of construction. This 
method does not need any knowledge regarding the distribution of project costs over time. 
It sets a single date which is the mid-point between the start and finish date of the 
construction phase. This method is not suitable when the cash flow or indices are not 
uniform over the course of construction phase (AACE 2010b). Another method which is a 
more sophisticated approach is to apply escalation by either individual construction contract 
or by trade item, e.g. bridge, track, signal, etc., and adjust to the predicted year of expenditure 
(YOE). This method breaks the whole expenditures over the course of construction phase in 
spending at a certain period of time such as monthly or yearly depending on the project’s 
duration. Then each spending is escalated separately using proper cost indices and mid-point 
of that period. This method requires the knowledge of project cost distribution over time 
and is more accurate than mid-point construction phase (AACE 2010b).  
In the studies where estimated costs are compared with actual costs, it is a common practice 
to adjust the estimated cost to mid-point of construction (i.e. constant) or year of 
expenditure dollars. Even though for each phase of New Starts project development, 
planning documents include capital cost estimates in escalated dollars, they may need to be 
adjusted when the projects’ YOE or mid-point of construction has been changed from the 
plan. To do this, the actual inflation rates will be usually used for the adjustment.   

 
 
Howe
under
This 
illustr
Figu
When
result
signif
Using
differ
an act
the w
prese
the U
ceme
nation
ever, this ad
rrun of a pro
can be due 
rates the effe
ure 3.3: YOE
n the projec
ts of cost es
ficantly differ
g inconsisten
rent compon
tivity/ trade 
widely used 
nted quarter
U.S. The late
nt 1%. ENR
n’s economy
djustment m
oject in vario
to using di
ect of applyin
E and Mid-po
t cost distrib
scalation fro
rent.  
nt indices is a
nents and wei
using an ind
indexes in t
rly by Engine
est CCI comp
R chose steel,
y as well as 
may cause so
ous reports w
ifferent indic
ng different m
oint of Cons
bution over 
om YOE an
another issue
ightings. The
ex which ind
the construc
eering News
ponents are 
, lumber and
playing a m
55 
ome discrep
when there i
ces or meth
methods to e
truction Met
2010b)
time is not 
nd mid-point
e in estimatin
erefore it is r
deed represen
ction industr
-Record (EN
common lab
d cement bec
major role in 
pancy in the
is no absolut
hods to escal
scalate proje
thods to Esti
symmetric 
t of constru
ng cost escala
really import
nts that type 
ry is Constr
NR) for the a
bor 80%, ste
cause of their
construction
e reported c
te methodolo
late the cos
ct cost.  
imate Escala
and/or non
uction metho
ation. Each c
tant to escala
of activity/ t
ruction Cost
average price
eel 13%, lum
r stable relati
n (ENR 200
cost overrun
ogy to follow
ts. Figure 3
tion (AACE 
n-uniform, th
ods would b
cost index ha
ate the cost o
trade.  One o
t Index (CC
e of 20-city i
mber 6%, an
ionship to th
09). ENR als
n/ 
w. 
.3 
 
he 
be 
as 
of 
of 
I) 
in 
nd 
he 
so 

 
56 
 
provides price data on 75 different building materials, in 20 major U.S. cities, plus Montreal 
and Toronto, on a monthly basis for over 50 years. Other than ENR, there are other sources 
such as R.S. Means, Marshall and Swift/Boeckh, and BNI Books that collect and report 
construction cost data. Also, there are agencies such as Office of Federal Housing Enterprise 
Oversight, and Bureau of Labor Statistics (BLS) that report cost index for various products. 
It is obvious choosing different cost indexes will result in different escalated costs.  
As an example of discrepancy in selecting cost indexes, we can point out to two reports 
prepared for the FTA. The FTA (2008) suggested the following indices to estimate the 
escalation for different cost components: The CCI of ENR (20-city average) for 
construction costs, the Producer Price Index by BLS for metals and metals products, the 
national House Price Index by the Office of Federal Housing Enterprise Oversight for right-
of-way costs, Employment Cost Index by BLS for all costs associated with Design, 
administration, project management and contingency. On the other hand, FTA (2003c) only 
used CCI of ENR for all cost components.  
Thus, it is crucial for an agency to set forth a set of guidelines for using the escalation 
method and selecting the proper cost indexes. This will help an agency obtain a unique 
escalated cost estimate if it is prepared by different entities or at different times. Choosing 
optional cost index and/or escalation method will result in dissimilar escalated costs. This 
will also be a source of confusion for the researchers who want to study the project under 
consideration.  
The following illustrates the discrepancy in the adjusted cost estimate of two transit projects 
presented in two different reports sponsored by the FTA. Atlanta North Line Extension and 
Portland Westside-Hillsboro MAX costs are reported differently in two relevant reports: 

 
57 
 
Booz.Allen.Hamilton 2005, and FTA 2008. Costs in million dollars at the DEIS, FEIS, 
FFGA, and final cost are shown in the Table 3.1.  
   Table 3.1: Costs of Two New Starts Projects Reported in Two Different Reports 
Sponsored by the FTA 
Project 
Report 
DEIS 
(Millions $)
FEIS 
(Millions $)
FFGA 
(Millions $) 
Final Cost 
(Millions $) 
Atlanta North 
Line Extension 
Booz.Allen.Hamilton 
2005 
$422.4 
$438.9 
$381.3 
$472.7 
FTA 2008 
$439.5 
$389.7 
$352.0 
$472.7 
Portland 
Westside-
Hillsboro MAX 
Booz.Allen.Hamilton 
2005 
$531.9 
$913.0 
$910.2 
$963.5 
FTA 2008 
$559.3 
$804.0 
$886.5 
$964.0 
 
Table 3.1 depicts the impact of differently adjustment costs on the calculated cost overrun in 
various phases of projects. This can be a serious source of confusion and drawing wrong 
conclusion which leads to inefficient remedy. Therefore a close attention is required to 
establish a certain policy to escalate the costs which leads anyone estimating cost escalation 
to a unique cost at each stage of project development. 
3.8 
Previous Studies and Lessons Learned 
Capital projects have been suffering from cost overrun and schedule delay over the past 
decades (Touran 2010; Flyvbjerg 2006). Researchers have shown that these are due to many 
different reasons including optimistic original estimates, lack of scope definition at the start 
of the project, scope creep during the project development phase caused by pressure from 
project stakeholders, errors in estimation, and lack of appropriate contingency budget 

 
58 
 
(Bakhshi & Touran 2009; Booz.Allen 2005; Flyvbjerg et al 2004). Transit projects are not an 
exception and have been mostly experiencing cost overrun. To identify the problems and 
control this issue, the FTA has conducted three exhaustive studies entitled Predicted and 
Actual Impacts of New Starts Projects in 1990 (Pickrell 1990), 2003 (FTA 2003c), and 2008 
(FTA 2008). In these three reports, the FTA has analyzed the predicted costs (inflation-
adjusted costs)/ridership and actual costs (as-built costs)/ ridership impacts of nearly 52 new 
starts projects. The predicted costs were adjusted to the mid-point of construction year 
dollars using industry accepted published inflation rates. The main purpose to conduct these 
studies was to evaluate the effectiveness of the procedures and technical methods used to 
develop the new starts projects.  
Pickrell (1990) considered the cost of 10 new start projects and reviewed their actual costs 
with the predicted costs at AA/ DEIS. The total cost of these projects was $15.5 billion in 
1988 dollars. It was found out that 9 out of 10 projects experienced overrun ranging from 13 
to 106% with the average of 50.06% cost overrun. He concluded that main reasons for this 
overrun were optimistic original cost estimates, insufficient contingency, and delay in project 
startup, and delays in different points of projects’ development.      
The FTA (2003c) reviewed 21 additional projects completed between 1990 and 2002. The 
analysis showed that the projects on average suffered 20.9% cost overrun compared with 
inflation-adjusted estimated cost at the DEIS, 13.5% compared at the FEIS, and 7.3% at the 
FFGA.  
In the latest study of predicted and actual impacts by the FTA (2008), 21 new starts projects 
completed between 2003 and 2007 were reviewed. On average, these projects had 40.2% 
higher cost compared to their inflation-adjusted cost at the DEIS, 11.8% higher at the FEIS, 

 
59 
 
and 6.2% at the FFGA. The average length of time to open the projects for revenue service 
after selection of locally preferred alternative was about 7.9 years which didn’t show 
significant change since 1990. Table 3.2 summarizes the results obtained from 
aforementioned studies by the FTA.  
Table 3.2: Average Cost Overrun percentages of Three Different New Starts Projects 
Samples Compiled by the FTA at three Phases of Project Development 
Study 
No. of 
Projects  
DEIS 
FEIS 
FFGA 
Pickrell (1990) 
10 
50.1 
N/A 
N/A 
FTA 2003 
19 
20.9 
13.5 
7.3 
FTA 2008 
21 
40.2 
11.8 
6.2 
 
Even though the results in Table 3.1 suggests some improvement in cost estimating over 
time, cost overrun still is an issue in capital projects specially in the early stage of project’s 
planning and development (i.e. AA/DEIS).  
3.9 
Conclusion 
In this chapter some regulatory specifications of new starts project, new fixed guideway 
systems or extension to existing fixed guideway systems, was explained. The planning and 
development of these projects and how they can get the Federal financial support under 49 
U.S.C. 5309 was described.  
The evolutionary practices of the FTA to assign contingency budget was discussed. The 
methods to escalate the capital cost estimate and the issues in this regard were explained. It 

 
60 
 
was concluded that a consistent policy is required for escalating project costs which leads 
anyone estimating cost escalation to a unique cost at each stage of project development.   
 Three exhaustive studies by the FTA covering 50 new starts projects to evaluate the 
predicted and actual cost/ridership impacts were reviewed. It was found that despite all 
progress in the FTA’s project development and management, projects are suffering from 
cost overrun. This suggests the need for a new solution to control/prevent cost overrun. In 
the following chapters a new method is proposed that can help agencies similar to the FTA 
to effectively decrease cost overrun in their portfolio of projects.  

 
61 
 
CHAPTER 4: COMPARISON OF BUDGET 
ESTIMATING FOR TRANSIT PROJECTS IN THE 
U.S. AND THE U.K. 
4.1 
Introduction 
In this cahpter, the probabilistic approaches for cost estimating currently used in 
transportation industry are illustrated. We examine two probabilistic approaches to allocate 
contingency budget developed and used in the United States and United Kingdom. In the 
first approach, we review the method used by the Federal Transit Administration (FTA) of 
the U.S. Department of Transportation. The FTA requires a formal risk assessment for all 
new transit projects. In this method, various project cost components are treated as random 
variables and are ranged according to predetermined values to explicitly model the variability 
of each major cost component. The sum of these cost components will be a distribution that 
represents the total cost. In the second approach, the British Department for Transport 
suggests increasing project contingency in order to cope with the optimism bias in 
infrastructure transportation projects. This is done by considering a cumulative distribution 
function of the amounts of overruns in previous projects and specifying a confidence limit 
for the project at hand for establishing a revised budget.  

 
62 
 
The two methods discussed above have similarities; they both consider the probabilistic 
nature of the project costs and establish budget levels by explicitly considering this 
variability. These two methods are evaluated and a quantitative comparison of the results 
obtained by these methods is made. This is accomplished by analyzing the cost performance 
data of a group of major transit projects in the United States, applying the two 
methodologies, comparing and analyzing the results. The problem areas of these approaches 
are discussed and recommendations are made to optimize the use of these techniques. 
4.2 
Federal Transit Administration (Top-down) Model  
4.2.1 
Top-down Model Background 
As it was stated in the previous chapter, the Federal Transit Administration (FTA) of the 
U.S. Department of Transportation (DOT) sponsors and provides technical support 
assistance to local transit authorities to carry out their transit projects.  FTA, through a set of 
documented Project Guidance (PG) manuals and procuring the services of Project 
Management Oversight Contractors (PMOCs), provides oversight assistance to transit 
authorities. Among the PGs, PG-40 “Risk Management Products and Procedures” (March 
2007) is used currently for conducting risk analysis of all new transit projects. This 
probabilistic risk assessment, referred to as top-down model, is a “holistic view of all risks 
associated with the projects” rather listing all risks in a risk register.  FTA approach asserted 
that assessment of project risks considering discrete risk events could not capture the 
variability that is witnessed in current transit projects (Sillars and O’Connor 2008). The PG’s 
stance was that to focus on significant but few risk items instead of project risk as a whole 

 
63 
 
may be masking risks that are unconsidered or individually small, but in total have a 
significant impact on the final cost.  
4.2.2 Top-down Model Methodology 
FTA classifies all costs of a new start transit project into ten Standard Cost Categories 
(SCC), SCC-10 to SCC-100 (Figure 4.1).  
 
Figure 4.1: Standard Cost Categories (SCC)
 
Costs in SCC 90, Unallocated Contingency, and SCC 100, Financial Charges, are not 
considered in the top-down procedure. The remained categories should be carefully 
reviewed to identify all allocated contingencies and escalation. These contingencies and 
10 GUIDEWAY & TRACK ELEMENTS (route miles)
40.06 Pedestrian / bike access and accommodation, landscaping
10.01
Guideway: At-grade exclusive right-of-way
40.07 Automobile, bus, van accessways including roads, parking lots
10.02
Guideway: At-grade semi-exclusive (allows cross-traffic)
40.08 Temporary Facilities and other indirect costs during construction
10.03
Guideway: At-grade in mixed traffic
50  SYSTEMS
10.04
Guideway: Aerial structure
50.01 Train control and signals
10.05
Guideway: Built-up fill
50.02 Traffic signals and crossing protection
10.06
Guideway: Underground cut & cover
50.03 Traction power supply:  substations 
10.07
Guideway: Underground tunnel
50.04 Traction power distribution:  catenary and third rail
10.08
Guideway: Retained cut or fill
50.05 Communications
10.09
Track:  Direct fixation
50.06 Fare collection system and equipment
10.10
Track:  Embedded
50.07 Central Control
10.11
Track:  Ballasted
10.12
Track:  Special (switches, turnouts)
60.01 Purchase or lease of real estate  
10.13
Track:  Vibration and noise dampening
60.02 Relocation of existing households and businesses
20 STATIONS, STOPS, TERMINALS, INTERMODAL (number)
70 VEHICLES (number)
20.01 At-grade station, stop, shelter, mall, terminal, platform
70.01 Light Rail
20.02 Aerial station, stop, shelter, mall, terminal, platform
70.02 Heavy Rail
20.03 Underground station, stop, shelter, mall, terminal, platform 
70.03 Commuter Rail
20.04 Other stations, landings, terminals:  Intermodal, ferry, trolley, etc. 
70.04 Bus
20.05 Joint development 
70.05 Other
20.06 Automobile parking multi-story structure
70.06 Non-revenue vehicles
20.07 Elevators, escalators
70.07 Spare parts
30 SUPPORT FACILITIES: YARDS, SHOPS, ADMIN. BLDGS
30.01 Administration Building:  Office, sales, storage, revenue counting
80.01 Preliminary Engineering
30.02 Light Maintenance Facility 
80.02 Final Design
30.03 Heavy Maintenance Facility
80.03 Project Management for Design and Construction
30.04 Storage or Maintenance of Way Building
80.04 Construction Administration & Management 
30.05 Yard and Yard Track
80.05 Professional Liability and other Non-Construction Insurance 
40 SITEWORK & SPECIAL CONDITIONS
80.06 Legal; Permits; Review Fees by other agencies, cities, etc.
40.01 Demolition, Clearing, Earthwork
80.07 Surveys, Testing, Investigation, Inspection
40.02 Site Utilities, Utility Relocation
80.08 Start up
40.03 Haz. mat'l, contam'd soil removal/mitigation, ground water treatments
90 UNALLOCATED CONTINGENCY
40.04 Environmental mitigation, e.g. wetlands, historic/archeologic, parks
40.05 Site structures including retaining walls, sound walls
100  FINANCE CHARGES
Standard Cost Categories for Capital Projects
(Rev.11a, June 4, 2008)
60 ROW, LAND, EXISTING IMPROVEMENTS
80 PROFESSIONAL SERVICES (applies to Cats. 10-50)

 
64 
 
escalation are removed from the estimate to arrive at the Base Cost Estimate (BCE) in each 
category which is not including contingency and escalation. The approach assumes that each 
cost category follows a lognormal distribution that can be identified by estimating the 10th 
and 90th percentile values of each cost component. The BCE is usually considered to be the 
10th percentile of the lognormal distribution. The 90th percentile of the distribution is 
estimated from Eq. (4.1): 
on
Distributi
the
of
Percentile
on
Distributi
the
of
Percentile
th
th
10
*
90


 
 
(4.1) 
 is dependent on the level of risk in project delivery stages and ranges from 1.0 to 2.5 and 
above. A  value of 1.0 means that there is no risk associated with the BCE. The more the 
project progresses, the smaller the value of . Having the 10th and 90th percentile of each 
cost components and using Lognormal Distribution equations, the mean and standard 
deviation of each cost component are calculated (Eqs. (4.2)-(4.7)). In these equations,  and 
 are parameters of the underlying normal distribution; mean and variance of the lognormal 
distribution are given in Eqs. (4.6) and (4.7). 
SCC
Each
in
Percentile
of
Cost
Estimate
Optimistic
x
th
a
10
% 

  
 
(4.2) 
SCC
Each
in
Percentile
of
Cost
Estimate
Pesimistic
x
th
b
90
% 

  
 
(4.3) 




2
)]
(
)
(
[
)
(
2
1
1
1
b
a
x
x
Ln
b
a





  
 
 
 
 
 
(4.4) 
)]
(
)
(
/[
)
(
1
1
a
b
x
x
Ln
b
a







 
 
 
 
 
 
 
(4.5) 
2
/
2


e
Mean
 
 
 
 
 
 
 
 
 
(4.6) 

 
65 
 
)1
(
2
2
2






e
e
Variance
 
 
 
 
 
 
 
 
(4.7) 
The sum of these cost components that represents the total cost is calculated using the 
Central Limit Theorem and assuming normality for the sum of lognormal components. The 
cumulative distribution is formed once with the assumption that all cost categories are 
completely correlated, 
0.1

r
, and once with the assumption that there is no correlation, 
0

r
. Note that the assumption of normality is not correct when components are fully 
correlated. Indeed, it can be proven that the total will follow a lognormal distribution. A 
“First Order Approximation” distribution which is the final product of the proposed top-
down approach is created by finding the one-third point of the total difference in variance 
between two aforementioned distributions. This process is applied at project cost 
components and several scenarios are run at the beginning of various project phases. 
4.2.3 How to Assign  Values to Different SCCs at the Various Project Delivery 
Stages 
Based on the historical data and lesson learned from previous transit projects, a set of 
recommended  values is suggested by PG-40. It is risk analyst’s responsibility to find the 
most appropriate  factors to assign to each SCC considering the unique and specific 
characteristics of every project.  
4.1 Requirement risks: those associated with definition of basic project needs and transit 
system requirements to meet those needs (
5.2


); 
4.2 Design risks: those involved with engineering design of the transit system 
)
0.2
5.2
(


; 

 
66 
 
4.3 Market risks: those associated with procurement of construction services and other 
system components (
75
.1
0.2


); 
4.4 Construction risks: those associated with the actual construction of the systems
)
05
.1
75
.1(


. 
 
The guidelines provide specific  values to be applied to various Standard Cost Categories 
(SCC) of the transit project. The values of  may vary through project implementation at 
each key stage of project development. These recommendations would be used in the next 
section to assign the ’s at three different stages of the project completion. 
4.2.4 Applying the Top-down Model to U.S. Data 
The value of  will vary from project to project and depending on the level of project 
development. As the project design progresses, the values of  tend to decrease. However, 
one can estimate an average  for the average transit project in the United States. The 
objective here is to calculate the average range for U.S. transit projects costs using the 
guidelines provided in PG-40. We have identified 51 transit projects in the U.S. (30 heavy 
rail and 21 light rail) for which actual costs were reported (Booz.Allen & Hamilton 2003 and 
2004) according to SCC format. Using these cost data, the breakdown of costs for the 
average of these 51 transit projects are calculated for various cost categories. The result is 
illustrated in Figure 4.2. 

 
 
The 
of a 
Prelim
transi
Prelim
are gi
stage,
as larg
 factors us
project. Th
minary Engin
it project de
minary Engin
iven in Table
, the average
ge as the 10th
Figure 4.2
 
sing the FTA
hese three p
neering (PE),
velopment i
neering, and 
e 4.1. It can 
  value is 2
h percentile c
: Percentage 
A recommend
phases are: D
, and Final D
n the U.S. a
Final Desig
be seen tha
2.2. This me
cost. 
67 
of Each SCC
dations are a
Draft Enviro
Design (FD).
and are roug
gn phases of 
t following t
eans that the 
 
 
 
C to the Tota
assigned for 
onmental Im
 These phas
ghly equivale
f a project de
this procedu
90th percenti
 
al Cost
three differe
mpact Statem
es are comm
ent to Conce
evelopment. 
ure, for exam
ile cost is mo
ent key phase
ment (DEIS
monly used fo
eptual Design
These value
mple at the P
ore than twic
es 
S), 
or 
n, 
es 
E 
ce 

 
 
Ta
For th
90th p
catego
Then
correl
cost i
T
able 4.1:  V
he average tr
percentile is 
ory are calcu
n, all SCCs a
lation among
is assumed to
Table 4.2: 10th
Values Assign
ransit project
calculated us
ulated using E
are summed 
g cost BCEs.
o be a Norma
h Percentile, 
ned to Each 
t, the 10th per
sing Eq. (4.1
Eqs. (4.2)-(4.7
to generate
. In both cas
al distributio
90th Percenti
C
68 
Cost Catego
Project 
rcentile is ass
1). Values of 
7). 
e Total Cost
ses, following
n. The result
ile, Mean and
Category 
ory at Three K
sumed to be 
f mean and s
t assuming i
g the FTA gu
t is given in T
d Standard D
Key Phases o
the value of
standard dev
independenc
uide, the mea
Table 4.2.    
Deviation of E
of a Transit 
f BCE and th
viation in eac
e and perfec
an of the tot
Each Cost 
 
he 
ch 
ct 
tal 
 

 
 
Follo
assum
appro
Fi
Using
of a p
a bud
transi
contin
budge
at the
Uplif
Since
huge 
wing the to
ming compl
oximation cu
igure 4.3: Fin
g Figure 4.3, 
project, in or
dget equal to 
it project, a 
ngency varie
eted estimate
e Final Desig
fts approach,
 transit proje
amount of m
p-down mo
etely correl
urves are gene
nal Top-down
if an agency
rder to have 
1.69 of initia
contingency
es according 
e should be 
gn phase is 
, this estimat
ects usually a
money to ens
del process, 
lated and i
erated (Figur
n Model Cur
Phases of
 
y wants to es
85% confide
al cost estima
y budget is a
to the proje
smaller. For 
about 10%. 
ted budget s
are costly, it 
sure the suff
69 
cumulative 
independent 
re 4.3). 
rves (Total R
f a Transit Pr
tablish proje
ence that the
ate (Total BC
added to the
ect phase, th
example, a t
This means 
should be inc
means that 
ficiency of bu
normal dist
are forme
Required Bud
roject
ect budget at 
e budget is su
CEs). It shou
e Base Cost 
he amount o
typical contin
that accordi
creased by 1
the agency m
udget. Figure
tributions fo
ed and the
dget) at Three
t the “Final D
ufficient, it sh
uld be noted 
Estimate (B
of uplift com
ngency adde
ing to the O
1.69/1.1 = 1
must provid
e 4.4 is a mo
or each phas
e first orde
 
e Different 
Design” phas
hould allocat
that since in 
CE), and th
mpared to th
ed to the BC
Optimism Bia
.54 (or 54%
de and block 
odified versio
se 
er 
se 
te 
a 
his 
he 
E 
as 
%). 
a 
on 

 
 
of Fig
Perce
to be
Figur
Uplif
later i
phase
there 
F
 
 
gure 4.3. The
ent of Assura
e added to t
re 4.4 similar
fts) Model. W
in this chapt
e), will mean
will be a cos
Figure 4.4: C
e X axis is co
ance (Confid
he base cos
r to the final 
We will be com
ter. As an exa
n that there i
st overrun. 
Converted Cu
onverted to t
dence), and Y
t), Total Co
product of B
mparing the 
ample, increa
is a 15% cha
urves of the T
70 
the “Accepta
Y axis to “Re
st - 100%. T
British Depa
outcome of 
asing the bas
ance that th
Top-down M
able Chance o
equired Uplif
This modific
artment for T
this analysis 
se budget by
e budget wo
Model to Show
of Cost Ove
ft” (or the am
cation was d
Transport (O
 with the Bri
y 69% (at the
ould not be 
w the Requir
rrun”, 100%
mount neede
done to mak
Optimism Bia
itish approac
e Final Desig
sufficient, i.e
 
red Uplift
% - 
ed 
ke 
as 
ch 
gn 
e., 

 
71 
 
4.3 
The British Department for Transport (Optimism Bias Uplifts) Model  
4.3.1 
Optimism Bias Uplifts Model Background 
The second approach examined for this research is the British Department for Transport 
approach in dealing with optimism bias in capital project cost estimates. This approach is 
based on work done by Flyvbjerg and COWI (2004) and reported by Flyvbjerg (2006). 
According to Flyvbjerg et al (2002; 2005) and Flyvbjerg (2006), psychological (optimism bias) 
and political explanations (strategic misrepresenting due to political and organizational 
pressure) are responsible for much of the inaccuracy in transportation cost forecasting. 
Reference class forecasting method is based on theories of decision-making under 
uncertainty. “Reference class forecasting does not try to forecast the specific uncertain 
events that will affect the particular project, but instead places the project in statistical 
distribution of outcomes from the class of reference projects.” (Flyvbjerg 2006). 
According to Supplementary Green Book (HM Treasury 2003): “There is a demonstrated, 
systematic tendency for project appraisers to be overly optimistic. To redress this tendency, 
appraisers should make explicit, empirically based adjustments to the estimates of a project’s 
costs, benefits, and duration… It is recommended that these adjustments be based on data 
from past projects or similar projects elsewhere”.  To this end, the British Department for 
Transport (DfT) and HM Treasury published a guide: “Procedures for dealing with 
Optimism Bias in Transport Planning” based on the work conducted by Flyvbjerg and 
COWI to establish a guide for selected reference classes of transport infrastructure projects 
to prevent cost overrun. This approach is hereafter called “Optimism Bias Uplifts Model” 
method in this research. 

 
72 
 
4.3.2 The Optimism Bias Uplifts Model Methodology 
In the DfT guide, transportation projects have been divided into a number of distinct 
groups. These groups include road, rail, fixed links, buildings, and IT projects and have been 
selected in order to have statistically similar risk of cost overrun based on the study of an 
international database of 260 transportation projects. In this chapter, we are interested in rail 
projects because the transit projects that we analyzed for the U.S. case were almost 
exclusively rail projects.  
In the DfT guide, cost overrun is defined as the difference between actual cost (final cost) 
and estimated costs which is the forecasted costs at the time of approval of/decision to build 
a project in percentage of estimated costs. Where the approval point is not clear in the 
project planning process, the closest available estimate is used. For each category, the 
probability distribution for cost overrun as the share of projects with a given maximum cost 
overrun was created. Having established the empirical cumulative probability distribution, 
uplifts are set up as a function of the level of risk that the DfT is willing to accept regarding 
cost overrun. “Uplift” is the term used to show the amount that the original estimate needs 
to be increased to arrive at the project budget for a given level of certainty with respect to 
cost adequacy. If the DfT wants to accept a higher risk, then a lower uplift is required. The 
readers are referred to the British DfT (2004) and Flyvbjerg (2006) for a thorough 
description of the Optimism Bias Uplifts methodology. 

 
73 
 
4.3.3 Applying Optimism Bias Uplifts Model to U.S. Data 
To generate a reference class, 22 transit projects across the U.S. were selected. The objective 
here is to apply the Optimism Bias Uplifts Model approach to these projects and then 
compare the results with the results of applying the USDOT approach to the same data. 
These projects were part of a study conducted under a research project where the co-author 
was a team member of the research group (Booz.Allen 2005). As part of this research effort, 
cost overruns for 22 major transit projects were calculated considering estimated budgets at 
various stages of these projects. For each project, the cost overrun/underrun was calculated 
at the DEIS, PE, and FD stages by comparing these estimates with actual cost of projects. 
Although, DfT calculates the cost overrun relative to the estimate at the point of approval 
of/decision to build, in order to compare FTA and DfT models, here cost overrun has been 
calculated at: DEIS, PE, and FD stages. PE can be considered equivalent to the time that 
British agencies prepare their initial budgets. In this way, we can compare these two models. 
It should be noted that the main criteria in selecting these 22 projects for inclusion in the 
original study was the availability of data. In other word, the research team was not trying to 
identify and select projects that were notorious for cost overrun or delay. Following the 
abovementioned process, the cumulative probability distribution for cost overrun as the 
percentage of projects with a given maximum cost overrun is formed (Figure 4.5); then the 
required uplift curve is calculated (Figure 4.6).  

 
 
Figu
 
Figur
apply
proje
ure 4.5: Prob
Figu
 
re 4.6 illustra
y the method
ct, the requi
bability Distri
ure 4.6: Requ
ates that base
d suggested b
ired uplift is
ibution of Co
uired Uplifts a
ed on the se
by the DfT a
s 91.61% at 
74 
ost Overrun 
at Three Dif
elected U.S. p
and to accept
the DEIS p
at Three Dif
fferent Stages
projects, if a
t a 10% chan
phase, 67.36%
fferent Stage
s of a Project
a transit agen
nce of cost o
% at the PE
 
 of a Project
 
t
ncy decides t
overrun for i
E phase,  an
t
to 
ts 
nd 

 
75 
 
44.01% at the FD phase. It demonstrates that the more project progresses, due to the 
decreasing level of uncertainty, the less uplift is required. 
4.5 
Comparison of Top-down and Optimism Bias Uplifts Models  
In previous sections, we applied two different probabilistic approaches to a group of transit 
projects in the U.S. Although, the Optimism Bias Uplifts approach used in the U.K. only 
considers the cost estimate at the approval of/decision to built stage of a project to calculate 
cost overrun, in order to evaluate  values of top-down model used in the U.S., we have 
calculated cost overrun at three phases of DEIS, PE, and FD. Comparing Figure 4.4 and 
Figure 4.6 shows that required uplift for 50% confidence at PE stage is 55.12% with top-
down model and 7.70% with the Optimism Bias Uplifts approach. Table 4.3 lists the 
required uplift with 50% confidence at three stages of the project with two approaches.  
Table 4.3: Required uplift with 50% Acceptable Chance of Cost Overrun with Two 
Approaches 
Model 
Required Uplift with 50% Confidence 
DEIS 
PE 
FD 
Top-Down approach 
65.73% 
55.12% 
44.43% 
Optimism Bias Uplifts approach 
25.96% 
7.70% 
2.37% 
 
Comparing these results show that the top-down approach established a much larger budget 
for the project. It should be realized that establishing too conservative a budget is not 
necessarily desirable because by tying excessive funds for projects, other candidate projects 

 
76 
 
will be deprived of the necessary funds. From top-down Methodology, we remember that  
is defined as the ratio between 90th percentile and 10th percentile of the cumulative cost 
distribution. So using data in Figure 4.5, we can construct equivalent  values for the 
Optimistic Bias approach by calculating the ratio between the 10th and 90th percentile points. 
In Table 4.4, the calculated β values are compared with weighted average of  values 
recommended by the top-down model (computed in Table 4.1).  
Table 4.4: Comparison of the  Values in Two Approaches 
Key Stages  
Optimism Bias Uplifts 
Top-down 
10th 
Percentile
90th 
Percentile
 
Weighted  
Average  
DEIS 
1.001 
1.916 
1.91 
2.44 
PE 
0.847 
1.674 
1.97 
2.20 
FD 
0.872 
1.440 
1.65 
1.96 
 
As stated before, reviewing Table 4.4 shows that  values from Optimism Bias Uplifts 
approach where the data come from historical data are significantly smaller than the  
recommended by the top-down approach. Looking at s for Optimism Bias Uplifts 
approach illustrates that the values of  at PE stage is greater than DEIS where it should be 
normally smaller. This anomaly might be due to the nature of the projects in the sample and 
the relative small sample size. This is due to the greater number of projects that have had 
cost underrun at the PE stage possibly due to scope reduction.  

 
77 
 
4.6 
Conclusion 
Optimism Bias Uplifts and top-down approaches are suggested (and used) for transit project 
development in the U.S. and the U.K. Both these approaches have positive and negative 
aspects. First, the top-down model selects large values of  in order to prevent cost overrun 
which results in establishing a budget far larger than historical actual costs. Optimism Bias 
Uplifts approach is based on historical data but does not consider unique features and 
characteristic of individual projects. It gives an estimate of the actual cost based on a set of 
peer projects without considering the location and special condition of each projects. The 
positive aspect of both approaches is the explicit consideration of uncertainty in cost 
estimating and budgeting.  
Our suggestion is to refine these approaches and come up with a probabilistic method that 
considers the unique characteristics of each project without tying up huge capital in order to 
prevent potential cost overruns. In this response, in the next chapter, we will develop a 
probabilistic model that calculates the required contingency budget for a portfolio of 
projects on top of the allocated contingency for individual projects.  

 
78 
 
CHAPTER 5: A HYBRID NORMAL MODEL FOR 
CALCULATING CONTINGENCY IN A PORTFOLIO OF 
PROJECTS 
5.1 
Introduction 
As we discussed in the previous chapters, notwithstanding of all efforts and evolving new 
probabilistic methods to allocate sufficient and optimum contingency budget for capital 
projects, the research shows that cost overrun is still plaguing these projects. For instance in 
Chapter 4, it was shown that the FTA currently employs an approach that results in too large 
a contingency budget. Having too much contingency can be just as undesirable as 
insufficient contingency, especially where the agency is dealing with a portfolio of projects 
rather than a single project. Allocation of large contingencies will use up the agency’s budget 
that can be spent on funding other projects and will reduce the number of projects that may 
receive funding. 
In dealing with a portfolio of infrastructure projects, an agency should usually define the 
level of confidence γ for the portfolio budget based on available funding and the agency’s 
policy goals (Touran 2006a). However, defining the required level of confidence  for 
conducting risk assessment at the individual project level is an important task in order to 
insure that the portfolio budget will not fall short with a probability of more than 


1
. 
Touran (2006a) suggested a mathematical model for establishing a minimum portfolio 
budget assuming a shifted exponential distribution for each project cost in the portfolio. It 

 
79 
 
did not include project cost correlations and this could underestimate the level of 
contingency calculated. 
In response to imperfections associated with current contingency allocation methods, in this 
chapter, a new probabilistic model for contingency allocation in a portfolio of construction 
projects is proposed. The proposed model assumes a hybrid normal distribution for the cost 
of individual projects and uses the available historical data for initializing and calculating the 
primary parameters of the model. It estimates the required increase in the budget of 
portfolio in such a way to meet the agency goals with respect individual projects and the 
project portfolio. This is a dynamic models meaning that it is updated when the information 
of newly completed project becomes available. To this end, a Bayesian approach is employed 
to update the model based on the recently completed projects’ performances on regular 
intervals, such as once every two years. It is expected that the required increase (or decrease) 
in portfolio budget will be diminished over the course of time by doing updating process. It 
is because the accuracy of estimating the contingency is improved. As an advantage of the 
model to be more accurate, correlation among the projects in the portfolio is recognized and 
accommodated in the proposed analytical model and Bayesian updating process. The basis 
of the model and updating procedure is developed in the current chapter. The suggested 
method to estimate the correlation between costs of projects will take up in the next chapter. 
Then in Chapter 7, the application and verification of the model is presented using a 
numerical example.  

 
 
5.2 
Even
mode
To fo
proba
an arb
the 
~
X
We p
proje
%

c
mode
Basis of t
n though the 
el that can be
orm truncate
ability of exp
bitrary numb
historical c
)
,
(




N
, w
presume that
cts with the 
chance to ha
el is construc

ib
 Initia

ix
Actu
the Propose
emphasis of
e applied on a
ed normal d
periencing un
ber based up
cost overrun
where the nor
Fig
 
t there is a 
initial budge
ave m  perce
cted using the
al budget allo
al cost of pro
d Model 
f this model i
any type of c
distribution 
nderrun m  i
on agency’s 
ns/underrun
rmal compon
ure 5.1: Hyb
database of
et of 
ib . It 
ent underrun 
e following p
ocated for pr
oject i ; 
80 
is on transit 
construction 
of cost for 
is  as the 
objectives an
ns. Figure 
nent of the d
rid Normal D
f constructio
is found thr
and get the 
parameters: 
roject i ; 
projects, it is
project.  
each projec
discrete por
nd  can be
5.1 illustra
distribution is
Distribution
on projects c
rough this h
project don
s a mathema
ct, it is assu
rtion of distr
e determined
ates the hy
s 
)
,
(


N
. 
comprising 
historical data
ne with 
ic
(

atically flexib
umed that th
ribution. m
d by reviewin
ybrid norm
 
of 
n
i
...,
,1

a that there 
ib
m).
1( 
. Th
le 
he 
is 
ng 
al
n  
is 
he 

 
81 
 

m
 The maximum expected underrun; 

ic
 Minimum expected project i cost which is 
ib
m).
1( 
; 


 Percent of projects in the historical data having underrun more than or equal to 
m ; 


 Cost overrun/underrun; 


 Average of cost overruns/underruns in the historical data; 


 Standard deviation of cost overruns/underruns in the historical data; 


 Average rate of cost overrun/underrun relative to b which is 


1
; 


 Average rate of cost overrun/underrun relative to c  which is 
)
1
/(
m


; 

i
 Mean of underlying normal distribution in project i ; 

i

 Standard deviation of underlying normal distribution in project i ; 

i
 Mean of hybrid normal distribution in project i ; 

i

 Standard deviation of hybrid normal distribution in project i ; 


 A constant coefficient which is equal to
i
i c
/

; 

*
ib
Revised budget of project i ; 

B
 Sum of all individual initial budgets, 
ib ; 


Percent of confidence that individual projects’ cost will not be more than 
*
b ;  

*
B
Sum of all revised individual budgets based on , 
*
ib
; 


Probability that portfolio of projects’ cost will not be more than 
*
B ; 
Project cost 
i
X  is defined as follows: 

 
82 
 












1
)
(
)
(
0
)
(
i
i
i
i
i
i
c
X
P
c
X
P
c
X
P
  
 
 
 
 
 
 
 
(5.1) 
The Probability Distribution Function (PDF) which is a hybrid normal distribution is: 











i
i
x
i
i
i
c
x
for
e
x
f
c
x
for
x
f
i
i
i
2
2
2
)
(
.
2
1
)
(
)
(





   
 
 
 
 (5.2) 
The mean  and standard deviation  of hybrid normal can be calculated using the 
following equations (Walpole et al 2007): 
2
)]
(
[
2
)
(
2
1
2
2
.
2
).
1(
.
.
2
1
.
)
(




























e
c
dx
e
x
c
X
E
i
i
i
c
i
x
i
i
i
i
i
i
i
i
i
 (5.3) 
)
).(
1(
].
2
)
(
.
.[
2
.
.
2
1
.
)
(
2
2
2
)]
(
[
1
2
2
2
2
)
(
2
2
2
2
2
2
1
2
2
i
i
i
i
i
i
i
b
i
x
i
i
i
i
i
i
e
c
dx
e
x
c
X
E
i
i
i
i
i













































  
(5.4) 
Where: 
 
i
i
ic






)
(
1
 
 
 
 
 
 
 
 
 
(5.5) 
is the inverse of cumulative function for standard normal distribution.  is the average rate 
of cost overruns/underruns and can be calculated from the historical data as: 







n
i
i
i
i
b
b
x
n
1
.
1
1
1


  
 
 
 
 
 
 
(5.6) 
 

 
83 
 
In other words: 
i
i
b.



 
 
 
 
 
 
 
 
 
 
(5.7) 
Also, we can define:  
i
i
c.



 
 
 
 
 
 
 
 
 
 
(5.8) 
and knowing that 
i
i
b
m
c
).
1( 

, we have: 
m
c
b
c
b
i
i
i
i
i








1
.
.
.







 
 
 
 
 
(5.9) 
By rearranging Eq. (5.5), mean of the underlying distribution is: 
)
(
.
1 






i
i
i
c
  
 
 
 
 
 
 
 
(5.10) 
By substituting Eq. (5.10) and (5.8) in Eq. (5.3) and rearranging, the standard deviation of 
underlying distribution is found: 






2
)
(
).
1(
).
1
).(
1(
2
)]
(
[
1
2
1










e
b
m
i
i
   
 
 
 
 
 
 
(5.11) 
Reviewing Eq. (5.4) shows that all terms of 
2
i
are comprised of a constant coefficient times
2
ic .  Therefore, 
2
i
can be written in the form of: 
i
i
or
i
i
c
c
.
.
2
2
2










  
 
 
 
 
 
 
(5.12) 

 
84 
 
Where  is a constant coefficient for all values of 
i
and 
ic  and using Eq. (5.4) and (5.12), 
it can be computed. Referring to Figure 5.1, if a budget 
i
i
b
b

*
 for each project is selected, 
the chance of shortfall of budget would be limited to . So: 
 

























)
*
(
)
(
)
*
(
*)
(
*)
(
i
i
i
i
i
i
i
i
i
i
i
i
b
c
b
b
F
b
X
P
 (5.13) 
If we rearrange Eq. (5.13), we obtain: 
)
(
.
*
1 






i
i
ib
  
 
 
 
 
 
 
 
(5.14) 
We know that the original portfolio budget is: 
 
B
m
c
c
m
m
c
b
B
i
Then
i
i
i
).
1(
)
1(
1
)
1(














  
 
 
(5.15) 
Using Eq. (5.14), (5.15) and substituting 
i by Eq. (5.10), the new portfolio budget can be 
computed as follows: 

























i
i
i
i
i
i
i
B
m
c
b
B










)].
(
)
(
[
).
1(
]
).
(
[
)]
(
.
[
)]
(
.
[
*
*
1
1
1
1
1
  
(5.16) 
Substituting Eq. (5.11) in Eq. (5.16), the ratio of 
B
B /
*
 is found as follows: 







































2
)
(
).
1(
)]
(
)
(
).[
1(
1
).
1(
*
2
)]
(
[
1
1
1
2
1
e
m
B
B
 
 
 
 
 
(5.17) 

 
85 
 
Now, we assume that the total cost of all projects in the portfolio is T . If we consider that 
all projects in the portfolio are independent, then T  based upon Central Limit Theorem will 
follow an approximate normal distribution with the mean 
T
and the variance 
2
T
 as 
follows: 
)
,
(
~
2
T
T
CLT
i
N
T
X
T







  
 
 
 
 
 
(5.18) 







B
m
ci
i
T
).
1
.(
)
.
(




  
 
 
 
 
 
(5.19) 












2
2
2
2
2
2
.
.
)
.
(
i
T
Then
i
i
i
T
c
c
c






 
 
 
(5.20) 
However, sometime projects in the portfolio are highly correlated and by ignoring the 
correlation, we will underestimate the results. The correlation becomes more important here 
since we are dealing with a portfolio of projects funding with the same agency and somewhat 
similar characteristics (such as being contemporaneous and all being transit projects). This 
magnifies the importance of correlation.  
When there is correlation among the projects 
T
 will not change and can be calculated using 
Eq. (5.19), but 
2
T
 will be different. The distribution of total cost is no longer a normal 
distribution. If all projects are perfectly correlated (
0.1


) then the total cost has the 
distribution of each single projects which is a hybrid normal here. However, assumption of 
normality is a good approximation for the total cost especially for small correlation values. 
To calculate the variance of total cost of projects where they are correlated, we have:  

 
86 
 




















j
i
j
j
i
ij
i
T
i
j
Then
j
i
ij
i
j
i
j
j
i
ij
i
T
c
c
c
c
c
c












2
.
)
.
).(
.
(
2
)
.
(
2
2
2
2
2
 
(5.21) 
Defining  as the percent of confidence that portfolio of projects cost will not be more than
*
B , we have: 








)
*
(
*)
(
T
T
B
B
T
P
 
 
 
 
 
 
 
(5.22) 
Rearranging Eq. (5.21) and using Eq. (5.19) and (5.21), we have: 

















n
i
n
j
i
n
j
j
i
ij
i
Then
T
T
c
c
c
B
m
B
B
B
1
2
1
1
2
.)
(
.
)
1
.(
*
*
)
(







 (5.23) 
By equating Eqs. (5.17) and (5.23), one can find the  values for different  values as 
follows: 
































































2
)
(
).
1(
)]
(
)
(
[
1
2
.
).
1
).(
1(
2
)]
(
[
1
1
1
1
2
2
1
e
c
c
c
B
m
n
i
n
j
i
n
j
j
i
ij
i
 
 
(5.24) 
Rearranging Eq. (5.24) gives: 

 
87 
 




























































1
).
1
).(
1(
)
(
.
2
.
.
2
)
(
).
1(
)
(
1
1
2
2
)]
(
[
1
1
2
1
B
m
c
c
c
e
n
i
n
j
i
n
j
j
i
ij
i










 
 
 
 
 
 
 
 
 
 
 
 
(5.25) 
If we assume that we have n  identical projects, Eq. (5.24) and (5.25) can be rewritten as 
follows: 




























































2
)
(
).
1(
)]
(
)
(
[
1
2
.
).
1(
2
)]
(
[
1
1
1
2
1
e
n
n
n
j
i
n
j
ij
 
 
 
(5.26) 

























































1
).
1(
2
).
(
.
.
2
)
(
).
1(
)
(
1
2
)]
(
[
1
1
2
1
n
n
e
n
j
i
n
j
ij










 
(5.27) 
Flowchart shown in Figure 5.2 illustrates the procedure of how to employ the proposed 
model. 

 
 
5.3 
An ag
newly
 
Bayesian
gency emplo
y funded pro
Figure 5.2: P
n Approach f
ying the prop
ojects. Since 
Procedure fo
for Updatin
posed model
the model 
88 
or Applying t
g the Mode
l is expected
has been co
the Proposed
el 
d to experienc
onstructed b
d Model
ce less cost o
based on lim
overrun in th
mited observe
 
he 
ed 

 
89 
 
data, it can help decrease the level of overrun/underrun and is not expected to eradicate the 
overruns in the first attempt. Therefore the model needs to be updated in a yearly or biyearly 
basis depending on the number of completed projects. To this end, a Bayesian updating 
approach is proposed to update the model as the information regarding the costs of new 
projects becomes available. The Bayesian approach helps by using the new data to augment 
historical data to arrive at revised, more accurate predictions.  
The Bayesian approach systematically combines the prior knowledge as to a fact and recent 
observations and helps the analyst make decision using all source of available information. 
Using Bayesian, even subjective judgments based on intuition, experience, or indirect 
information can be integrated formally with observations to make interference. This is 
something which is not possible in classical statistical approach which uses sample statistics 
as the estimator of parameters. The Bayesian probability of an event A, signifies the degree 
of belief or confidence in that event’s occurrence based on prior information and observed 
data whereas classical probability refers to the actual probability of the event and is not 
concerned with observed behavior.  
Ang and Tang (2007) identifies two broad source of uncertainties: 1. Aleatory and 2. 
Epistemic. The aleatory uncertainty is associated with the inherent variability of information 
(being intrinsically unpredictable) and the epistemic uncertainty is associated with 
imperfections in our knowledge or capability to make prediction. Only aleatory uncertainty is 
acknowledged in classical statistics, whereas the Bayesian approach encompasses both kinds 
of uncertainty equally well. The Bayesian approach systematically updates existing aleatory 
and epistemic uncertainties as new data for each type becomes available.  

 
90 
 
All in all, the Bayesian approach for updating the proposed model will benefit the agency by 
using all available information in a systematic way. It brings into consideration new 
observations that become available one by one whereas the other methods just consider the 
overall mean and standard deviation of sample.   
5.3.1 
Fundamental of Bayesian Approach  
Let us suppose that the possible values of a parameter  are a set of discrete values
k
i
...,
,2
,1


 with prior relative likelihoods
)
(
i
i
P
p





. Also,  denotes the observed 
outcome of the experiment. Now, the prior assumptions on parameter  may be modified 
formally through the Bayes’ theorem. The Bayesian approach in discrete cases is defined as 
(Ang and Tang 2007): 
















k
i
i
i
i
i
i
P
P
P
P
P
1
)
(
)
(
)
(
)
(
)
(







 
 
 
 
 
 
(5.28)
 
Where:  
)
(
i
P




 is the likelihood of the experimental outcome if 
i


, that is the 
conditional probability of obtaining a particular experimental outcome assuming that the 
parameter is 
i. 
)
(
i
P




is the prior probability of 
i


, that is prior to the availability of the 
experimental information. 

 
 
(
P 

has b
Exten
param
will b
Again
can b
proba
and T
f (
Wher

f (
(
)
i
P 



een revised i
nding Eq. (5
meter of a dis
be between 
n assume tha
be modified 
ability of hav
Tang 2007):  




k
i
i
P
P
1
(
). 

Figur
 
re 
)
( 


i
P










P
P
i
(
(
)
)

i


is t
in light of the
5.28) to con
stribution wh
i and 
i
at  is an ob
with this ext
ving 
ibetwe


i
i
i
i
f
P
f
(
).
(
).
(
).
(






re 5.3: Prior D
(





i
P







d
f
f
)
(
).
)
(
).
 
the posterior
e experiment
ntinuous case
hose prior di



 is

(
i
f
served exper
tra informati
een 
iand 


).
.


 
Distribution 
).





i
 In
 
91 
r probability 
tal outcome
es, assume t
stribution (P


).
i
. Figur
rimental outc
ion employin




i
in lig
 
of Paramete
n the limit, E
 
of 
i


, t
. 
thatis the 
PDF) is
)
(
f 
re 5.3 illustra
come and th
ng the Bayes
ght of the ne
er  (Ang an
Eq. (5.29) bec
that is the pr
random va
).  The prob
ates the dist
e prior distri
s’ theorem. T
ew observati
 
 
 
nd Tang 2007
comes: 
 
 
robability tha
riable for th
ability that 
tribution of
ibution 
(
f 
Therefore th
ion  is (An
(5.29)
7)
(5.30)
at 
he 
 
. 
)

he 
ng 

 
92 
 
In Eq. (5.30) 
)
( 

P
is the likelihood of observing the outcome  where the value of 
distribution parameter is . Hence
)
( 

P
is a function of and is known as the likelihood 
function. The denominator is independent of and is just a constant to normalize the 
equation in order to make the
)
(
f 
a proper PDF. So, Eq. (5.30) can be rewritten as: 
)
(
).
(
.
)
(



f
L
k
f



  
 
 
 
 
 
 
 
 
(5.31)
 
Where:  
1
]
)
(
).
(
[










d
f
P
k
 
is the normalizing constant; 
 
 
 
(5.32) 

)
(
L
the likelihood of observing the experimental outcome  assuming a given , the 
parameter of the distribution.  
Eq. (5.31) can be used to update the proposed model in the light of new information 
acquired through newly completed projects in a certain period of time. Here  is considered 
to be the average of cost overruns/underruns () required to calculate the parameters  
and  of the model. Eq. (5.31) can be rewritten as follows: 
)
(
).
(
.
)
(



f
L
k
f



  
 
 
 
 
 
 
 
(5.33) 
5.3.2 Bayesian Approach for k Independent Projects 
Let’s presume that k  new projects are completed. Assuming these k  new projects with the 
cost overrun/underrun of 
j
 are completely independent of each other, the probability of 

 
93 
 
observing 
k


...,
,
1
coming from a population  having an underlying normal distribution 
)
,
(



N
with the mean of  and the known standard deviation of is:  
)
(
.)
,
(
)
...,
,
(
1
1








d
N
P
j
k
j
k
j





   
 
 
 
 
(5.34) 
Since we do not know the standard deviation of the population,  is assumed to be the 
standard deviation of cost overruns/underruns of k  observed projects . Therefore, the 
likelihood function can be written as: 

























k
j
j
k
j
j
N
L
1
2
1
.
2
1
exp
.
2
1
)
,
(
)
(









   
 
 
(5.35) 
It should be noted that Eq. (5.35) is the product of k  PDFs of normal distributions which is 
the function of . It is known that the product of k  normal PDFs with means
iand 
standard deviations 
i
 is also a normal PDF with the mean 
L
and standard deviation 
L
as 
follows (Bolstad 2007): 


















k
i
i
L
k
i
i
k
i
i
i
L
1
2
1
2
1
2
/
1
1
/
1
)
/
(






                            
 
 
 
 
 
(5.36) 
Hence, the likelihood function can be written as: 

 
94 
 







































k
k
N
N
N
L
k
k
j
k
j
k
j
i
L
L










,
...
/
1
1
,
/
1
/
,
)
(
1
1
2
1
2
1
2
  
(5.37) 
To find the likelihood function, we can take either analytical approach using Eq. (5.37) or a 
numerical approach. The posterior distribution is now the product of likelihood 
)
(
L
and 
prior
)
(
f 
. If the prior is a normal PDF such as: 























2
.
2
1
exp
.
2
1
)
,
(
~
)
(








N
f
 
 
 
 
 
(5.38) 
Then the posterior has also a normal PDF. In this case the posterior has a mean and 
standard deviation as follows (Ang and Tang 2006): 
)
,
(
~
)
(
).
(
.
)
(










N
f
L
k
f
  
 
 
 
 
 
(5.39) 

















































































2
2
2
2
2
2
2
2
1
2
2
2
2
.
.
.
)
.(
...
.
.
k
k
k
k
k
L
L
k
L
L
L























 
 
 
(5.40) 
Eq. (5.40) in conjunction with Eq. (5.37) shows that the posterior mean  approaches the 
mean of observations (sample mean) for relatively large number of observations k . Also, it 
is found that the standard deviation of posterior distribution  is always smaller than 
standard deviation of prior distribution .  

 
95 
 
In this research, both likelihood and posterior distributions of  are calculated using Eqs. 
(5.37) and (5.40). These same values can be calculated using a numerical approach as well.  
5.3.3 Bayesian Approach for k Correlated Projects 
So far we were assuming that the k newly completed projects were independent and there is 
no correlation among the cost overruns/underruns of these projects. Now, we consider the 
case where there are dependencies among the collected projects for updating. We know that 
to conduct analysis with correlated cost overruns/underruns, joint density function is 
required. The probability distribution of each cost overrun/underrun is the marginal 
distribution. When the cost overruns/underruns are independent, the product of their 
marginal distributions gives their joint density function. In the previous section where we 
assumed independence among projects, we saw that the probability of observing cost 
overruns/underruns
k


...,
,
1
coming from a population  having an underlying normal 
distribution 
)
(
f
 with the mean of  and the known standard deviation of  is the 
product of probability of observing each 
k
 individually given the population information. 
If the projects are not independent, knowing the marginal distributions of cost 
overruns/underruns is not sufficient to obtain their joint density function. Multivariate 
normal distribution is the special case in which the only information is required other than 
marginal distribution of each random variable is the values of covariance among the 
variables (Rowe 2003). When there is a multivariate normal distribution, each of its marginal 
variables by itself is normally distributed. The converse however is not generally true 
(Kurtner et al 2005). Despite this, we have made a simplifying assumption that the joint 

 
96 
 
density function of the cost overruns/underruns to be a multivariate normal distribution. 
The multivariate normal PDF is (Springer 1979): 














δ
δ
.
V
.
δ
δ
.
2
1
exp
.
)
2
(
V
)
...,
,
(
1
2
/
2
/
1
1
1
n
k
f



  
 
 
 
(5.41) 
Where all bold letters represent a matrix/vector and:  


T
k


...,
,
1

δ
are the cost overruns/underruns of k newly completed projects (T denotes 
the transpose of matrix). 


T
k


...,
,
δ
1

are the means of each cost underruns/overruns distribution. Since it was 
assumed that all these k projects are coming from a normal population with the mean, δ
can be written as


T

...,
,

δ
. 
V  is the variance-covariance matrix which is a symmetrical (
k
k 
) matrix as follows: 

























2
3
3
2
2
1
1
2
2
3
2
23
2
2
1
2
21
1
1
3
1
13
2
1
12
2
1
...
...
...
...
...
k
k
k
k
k
k
k
k
k
k
k






























V
  
 
 
 
(5.42) 
mk

is the correlation coefficient between project m and k .
j
 is the standard deviation of 
cost overrun/underrun of project j . Again, since it was assumed that all k projects are 
coming from a unique normal population with the standard deviation of , all 
)
...,
,1
(
k
i
j


in the matrix V are equal to . Since we do not know the standard deviation 

 
97 
 
of the population,  is assumed to be the standard deviation of cost overruns/underruns of 
k  observed projects . 
1
V is the determinant of matrix 
1
V  which is the inverse of matrix V . 
One should note that Eq. (5.41) is the joint probability function of project cost overruns. In 
other words, assuming that δ  and V are known, the probability of observing 


T
k


...,
,
1

δ
 is found.  However in Bayesian updating we need to find the likelihood of 
having 


T

...,
,

δ
as the parameter of distribution when we have observed


T
k


...,
,
1

δ
. Therefore Eq. (5.41) can be used to obtain the likelihood function of δ  
which is the function of just  as follows (Rowe 2003): 















δ
δ
.
V
.
δ
δ
.
2
1
exp
.
)
2
(
V
)
...,
,
(
)
...,
,
(
1
2
/
2
/
1
1
1
n
k
L
L





 
 
 
(5.43) 
Having the likelihood function and assuming a prior distribution
)
(
f 
like Eq. (5.38), the 
posterior distribution 
)
(
f 
is a normal shape as follows: 
)
,
(
~
)
(
).
...,
,
(
.
)
(
1











N
f
L
k
f
k
  
 
 
 
 
(5.44) 
In the correlated case, to calculate mean and standard deviation
)
,
(




 of 
)
(
f 
, only 
numerical approach is available to us and there is no close form formula. To this end, a 
range of possible  is selected. It is obvious that  cannot be less than -100% as it is 
practically impossible that a project have underrun of its whole budget. To be conservative, 
the range is assumed to be from -99.99% to 200% with the pace of 0.001. These values are 
input in Eqs. (5.38) and (5.43) to respectively calculate the correspondence prior PDF value, 

 
98 
 
)
(
f 
and likelihood value, 
)
...,
,
(
1
k
L


 of each possible . It should be noted that for 
the values of  outside the range of [-99.99%, 200%], the 
)
(
L
and accordingly 
)
(
f 
 
become too small so that they can be ignored from the analysis without any significant 
impact. 
Reviewing Eq. (5.43), it is found that the term in the exponential function is the product of 
three (
k

1
) and (
k
k 
) and (
1

k
) matrices which results in a polynomial function of . It 
means that Eq. (5.43), for any , gives a scalar likelihood value. Having variance-covariance 
matrix, 
)
...,
,
(
1
k
L


can be easily calculated by any available mathematical package such as 
MATLAB. 
Multiplying of the prior PDF and likelihood values of each  gives 
)
(
f 
 which is the 
posterior PDF value of  before normalization (the area under the curve is not equal one). 
Both curves 
)
...,
,
(
1
k
L


vs.  and 
)
(
f 
 vs.  are needed to be normalized.  
To calculate and , the area under the curve of 
)
(
f 
 vs.  after normalizing is 
assumed to be divided to t  narrow rectangles. The area of each rectangle is the probability 
of having the 
j
mid )
(

(midpoint of the rectangle j ).  Then: 
)
)
(
:
(
)
(
Maximum
is
f
E
δ
δ






  
 
 
 
 
 
(5.45) 







2
)
(
1
1
)
(
)
(
)
(
2
1
)
(
)
(
1
2
)
(
)
(
2
2
2
2
.
.
.
.
1
)
(
.
))
(
(
)
(






































j
mid
t
j
j
mid
j
mid
j
mid
t
j
j
mid
j
mid
t
j
j
mid
j
mid
f
f
P
E
E
 
 
(5.46) 

 
99 
 
The term 







t
j
j
mid
j
mid
f
1
)
(
)
(
.


 in Eq. (5.46) is to normalize the posterior distribution and 
plays the role of k  in Eq. (5.44).  
5.4 
Updating the Primary Parameters of the Proposed Model 
In Section 5.3.2 (for independent projects) and Section 5.3.3 (for correlated projects), using 
Bayesian approach and having the information of newly completed projects the distribution 
of , the average of cost overruns/underruns, was updated  and posterior distribution
)
,
(
~
)
(






N
f
 was calculated.  
The mean and standard deviation of the posterior distribution is now used to update 
the primary parameters of the proposed model, , and as follows: 
 
)
(
)
(
)
(




















m
m
Z
P
m
x
P
new
 
 
 
 
(5.47) 
m
new
new
new






1
1




 
 
 
 
 
 
 
(5.48) 
where is the cumulative function for standard normal distribution. The proposed model is 
updated by 
new

,
new

, and 
new

 values and becomes ready to be applied to any prospective 
set of projects which are in budget allocation process.  

 
100 
 
5.5 
Summary 
In this chapter, a new probabilistic model was proposed for budget allocation in a portfolio 
of projects. The model assumes hybrid normal distribution for cost of projects and utilizes 
available historical data. Then, a Bayesian approach is employed to update the model as 
more projects are completed and new information becomes available. The proposed model 
first helps an agency to find the required portfolio’s budget increase in order to have a 
certain confidence  that the budget will be sufficient. Also, the model gives the required 
confidence level η to conduct risk assessment at individual project level to insure that the 
portfolio budget will not overrun with a probability of more than


1
. The model can be 
updated with the information of newly completed projects on a regular basis. Bayesian 
updating is applied considering two different approaches: 1. independent projects; and 2. 
correlated projects.  
In Chapter 7, application of the proposed model with a numerical example is explained in 
detail.  

 
101 
 
CHAPTER 6: SUGGESTED METHOD TO 
ESTIMATE CORRELATION BETWEEN 
PROJECTS’ COSTS 
6.1 
Introduction 
One of the important steps in a probabilistic risk assessment is the recognition of the 
statistical correlation among cost components. Ignoring the correlation results in an 
underestimation of total cost variance.  This may lead to underestimation of contingency 
budget for the desired confidence level. The effect of correlation on the total construction 
cost variance has been the emphasis of numerous papers in the past 20 years (Ince and 
Buongiorno 1991; Touran and Wiser 1992; Wall 1997; Touran and Suphot 1997; Ranasinghe 
2000). To consider correlation among cost components, two major issues are noteworthy:  
1. Measure of dependence between components where there is not sufficient 
historical cost data; and  
2. Implementation of correlation where correlation matrix is not mathematically true. 
In this chapter, a structured guideline is proposed for more accurate or at least more 
consistent subjectively estimating of correlation coefficients between costs of two 
construction projects where there is no historical data available. Furthermore, the 

 
102 
 
mathematical characteristics of a correlation matrix are explained and the methods to make it 
a mathematically true matrix are discussed.  
6.2 
Measure of Dependence  
When two or more random variables do not vary independent of each other, the measure of 
their dependence is measured by correlation coefficients. There are several correlation 
coefficients to measure this relationship among which Pearson Coefficient and Spearman’s 
Rank Correlation Coefficient are the most commonly used in construction research and 
practice. 
6.2.1 
Pearson Coefficient  
Pearson coefficient measures the degree of linear relationship between variables. It ranges 
from -1 to +1. If a variable is a linear function of another variable with both variables 
changing in the same direction, this coefficient is 1 and if they move in opposite directions 
this coefficient is -1 (perfect correlation). A coefficient of 0 means that there is no linear 
relationship between variables. It should be noted that coefficient of 0 is not an indication of 
independence. However, the inverse is correct and the coefficient of two independent 
random variables is 0. If we assume X and Y are two random variables with the mean
Y
X 
,
and standard deviation of 
Y
X 
,
 respectively, Pearson coefficient is defined as 
follows: 
 





Y
X
Y
X
Y
X
Y
X
Y
X
E
Y
X
Cov







.
.
.
)
,
(
,




 
 
 
 
 
 
(6.1) 

 
103 
 
Substituting estimates of the covariance and variance based on a given sample, Pearson 
coefficient is calculated from Eq. (6.1): 


















n
i
n
i
n
i
y
x
y
y
x
x
y
y
x
x
1
2
1
2
1
,
.
.
ˆ
 
 
 
 
 
 
 
(6.2) 
Where x and y are sample means for variables X and Y. 
6.2.2 Spearman’s Rank Correlation Coefficient  
Spearman’s rank correlation coefficient ranges between -1 to +1. This is a non-parametric 
measure of statistical dependence between two variables and is an indication of correlation 
between ranks of the values of random numbers instead of correlation between values. It 
evaluates how well the relationship between two variables can be described using a 
monotonic function. To find the rank correlation between a set of sample 
)
,
(
y
x
 observed 
from random variables X and Y, one first needs to sort the x  values in descending or 
ascending order and assign a rank 
iR to each row, and then corresponding y  values are 
ranked 
iS among all y . The Spearman’s rank correlation can be calculated using Eq. (6.3) 
(Kurowicka and Cooke 2006): 


















n
i
i
n
i
i
i
n
i
i
y
x
S
S
R
R
S
S
R
R
1
2
1
2
1
,
.
ˆ
 
 
 
 
 
 
 
(6.3) 

 
104 
 
Where n is the number of observed values, and R and S are the rank means in the sample of 
n  observations. In summary, Pearson correlation is a measure of linear relationship between 
variables while Spearman rank correlation is a measure of monotonosity (Iman and Conover 
1982). 
6.3 
 Subjective Estimate of Correlation 
Several researchers have shown that the effect of excluding correlation in cost or schedule 
estimation is significant (Ince and Buongiorno 1991; Touran and Wiser 1992; Wall 1997; 
Touran and Suphot 1997; Ranasinghe 2000; Yang 2006). The problem is that usually there is 
no sufficient historical data to help estimate the correlation coefficients. Most of the time in 
construction we do not have access to the detailed data about cost items or activity durations 
to find their relationships. In such a case, subjective estimates of correlation elicited from the 
experts are used (Touran 1993; Wang and Demsetz 2000; Cho 2006). To this end, building a 
system to gather the qualitative information and convert them to quantitative values is 
required. When there is not enough data to calculate the correlation coefficient, the 
estimator can provide some qualitative values using his or her judgment or by asking the 
experts. It is neither accurate nor reasonable to ask non-experts to provide a number 
between -1 to +1 as an estimate of the correlation coefficient for two variables under 
question. Most people even experts do not know how to interpret the numerical magnitude 
of correlation while they may be more familiar with terms such as very low, low, moderate, high, 
and very high as correlation terms. The challenge is to start from a qualitative estimate of the 
correlation coefficient and turn it into a numerical value for conducting the statistical 
analysis.  

 
105 
 
Touran (1993) suggested a convenient system to quantify the subjective correlations. He 
recommended that experts can estimate the correlation in three levels of weak, moderate, or 
strong based on previous experience which could vary from project to project depending on 
the circumstances. The proposed correlation coefficients for different levels are as follows: 
Weak: 0.15 which is the midpoint of 0 to 0.3; 
Moderate: 0.45 which is the midpoint of 0.3 to 0.6; 
Strong: 0.80 which is the midpoint of 0.6 to 1.0. 
Touran (1993) applied both calculated correlation coefficients and suggested subjective 
coefficients in numerous construction cost examples to compare the resulting total cost 
CDFs (Cumulative Distribution Functions). It was shown that the actual CDFs were very 
close to the CDFs using suggested subjective correlation. It should be noted however that in 
order to have a mathematically correct and applicable correlation matrix, the matrix must be 
positive semidefinite. The use of qualitative or subjective correlation coefficients (or even 
calculated correlation coefficients from relatively small samples) may lead to a correlation 
matrix that may not be positive semidefinite. This issue and available methods to resolve it 
are discussed in detail in the following section. 
Another suggested method for finding the correlation between durations of activities in a 
CPM network is to use the concordance probability. Cho (2006) employed concordance 
probability, the idea proposed by Gokhale and Press (1982), in conjunction with a three-step 
questionnaire to estimate correlation coefficients between activity durations. In this method, 
for two dependent random variables, a bivariate normal density is assumed and a conditional 
probability called concordant is required. For variables X and Y having two independently 
observed pairs 

1
1, Y
X
and

2
2,Y
X
, the concordance probability is:  

 
 
P
_
C
The c
Figur
coeffi
Fig
Havin
any p
coeffi
Pr(
Pr
2
Y
Y 

concordance 
re 6.1 explica
ficient.    
gure 6.1: Rel
ng concordan
pair of variab
ficient of the 
1. Asking 
each activ
is used; 
2. Asking
environme
)
1
2
1
X
X
Y

 
probability i
tes the relatio
lationships of
nce probabili
les. Cho sugg
duration of t
the experts t
vity. In case o
g the experts
ental risks 
  
is a monoton
onship betwe
f Correlation
ity and using
gested a thre
two activities
to determine
of multiple e
s whether th
or shares h
106 
 
ne increasing 
een concorda
n Coefficient 
2006)
 
g Figure 6.1, 
ee-step meth
s A and B, as
e the mean d
experts, eithe
he pair of ac
human reso
function of 
ance probabi
and Concor
the correlatio
od to succes
s follows: 
duration and 
er simple ave
ctivities is in
urces. If th
 
 
correlation c
ility and corr
rdance Proba
on coefficien
ssfully elicit t
the standard
erage or weig
nfluenced by 
he answer i
(6.4) 
coefficient. 
relation 
 
ability (Cho 
nt is found fo
the correlatio
d deviation fo
ghting averag
the commo
is “No”, th
or 
on 
or 
ge 
on 
he 

 
107 
 
correlation is 0; otherwise, if there is a dependency feeling between two activities, it 
should be proceeded to step 3; 
3. Asking the experts in what fraction of the cases he/she would expect that the 
duration of activity B will be longer than its expected duration, given that the 
duration of activity A is longer than its expected duration. Having this fraction as the 
concordance probability and using Figure 6.1, the correlation coefficient is found.  
6.4 
Proposed Structured Guideline (PSG) to Elicit Correlation 
 Even though the correlation among cost items has a significant impact on the total cost 
distribution as it was stated earlier, few studies exist that have focused on precisely 
measuring the correlation between costs. In this research as we are dealing with the portfolio 
of projects rather than individual projects, the correlation among projects becomes an 
important issue which needs to be studied. There is a need for some guidelines for 
estimating the correlation coefficient as accurately as possible among each pair of projects in 
the portfolio (or construction program). A simple approach is to apply a subjective 
coefficient by the judgment of the estimator or a panel of experts using terms such as low, 
moderate, and high and then convert them to pre-specified numerical values. Example of this 
subjective correlation is what Touran (1993) suggested and was explained earlier. Chau 
(1995) used a similar qualitative assessment method for estimating degree of dependence.    
In case of more than one estimator or expert, the average of values can be used. However, 
this method cannot be very precise since the experts may ignore some important 
characteristics that cause strong correlation among the cost of two projects. Having a 

 
108 
 
systematic and consistent approach can improve the precision of correlation estimate. Here a 
structured guideline is proposed for more accurate or at least more consistent estimating of 
correlation coefficients between costs of two construction projects.   
6.4.1 
Identifying Common Risk Factors 
As it was mentioned earlier, correlation between two variables is the degree to which there is 
a linear relationship between them and coefficient measures the strength of that linear 
relationship. Based on this definition, what is needed to find the correlation among the cost 
of two projects in the lack of historical data, is to consider all the common factors that can 
influence the cost of the projects under consideration. Reviewing all the effective factors and 
analyzing those that are in common can help find an approximate estimate for the 
correlation coefficient with a good degree of accuracy. In this way, the expert estimating the 
correlation coefficient can be ensured that he/she is not missing any significant factor that 
can establish correlation among two projects. To this end, first two relatively comprehensive 
sources of cost risk factors: 1. Touran (2006b), and 2. Shane et al (2009), were identified. In 
these two sources, authors have compiled all the risk factors that can affect the cost of a 
project. Both of these sources emphasize transportation projects that make them especially 
relevant to this dissertation. These sources are reviewed in depth to identify the risk factors 
that can affect a group of projects and increase or decrease their costs.  
Touran (2006b) provides a risk catalog based on several sources that its main purpose is to 
help the CM agency dealing with project owners. However this risk checklist provides a 
listing of the typical factors affecting the risks associated with a project. Similar or related 
risks are grouped according to their general theme or source and are arranged in a roughly 

 
109 
 
chronological order. The project life cycle is divided into the following phases based on 
Construction Management Association of America (CMAA) life-cycle breakdown: 
1. Pre-design phase; 2. Design phase; 3. Bid and award phase; 4. Construction phase;  
5. Post-construction phase. 
This risk catalog is reviewed precisely to select those factors that potentially can have 
common influence on all projects in a portfolio rather than to be specific to a project. These 
factors with some modifications are classified based on their types and given in Table 6.1.  
Table 6.1: Identified Common Cost Factors for All Construction Projects (Adapted from 
Touran 2006b with Some Modifications) 
No Classification 
Risk Factor 
1 
Regulatory 
Conditions 
Statutory/regulatory constraints (federal, state, or local) 
2 
Delay in federal approvals
3 
Environmental and ADA regulations/requirements 
4 
Taxes and duties
5 
Financial 
Conditions 
Federal political climate
6 
Bond market and rates
7 
Exchange rate
8 
Inflation rate
9 
Interest rate
10 
Market 
Conditions 
Number of bidders
11 
General economic climate that can affect bidding behavior 
12 
Availability of suppliers and subcontractors
13 
Unemployment rate in construction trades
14 
Material and energy prices
15 
Material shortages and large price increases
16 
Adequacy of marketplace supply (special items)
17 
Sole source equipment and service providers
18 
Opportunity for equipment discounts (concurrent projects/clients)
 

 
110 
 
In another extensive research conducted by Shane et al (2009), an anthology of individual 
cost increase factors were identified through an in-depth literature review. The authors list 
18 primary factors in two internal and external classifications which impact the cost of all 
types of construction projects. These factors were verified by interviews with 20 state 
highway agencies. In this classification those factors that contribute to cost escalation and 
are controlled by the agency/owner are internal, while factors existing outside the direct 
control of the agency/owner are classified as external. For our purpose, to find the 
correlation among two projects, both internal and external factors should be reviewed. Table 
6.2 shows the identified cost factors by Shane et al.  
Table 6.2: Identified Common Cost Factors for All Construction Projects (Adopted from 
Shane et al 2009) 
No Classification 
Risk Factor 
1 
Internal 
Bias 
2 
Delivery/procurement approach
3 
Project schedule changes
4 
Engineering and construction complexities
5 
Scope changes
6 
Scope creep
7 
Poor estimating
8 
Inconsistent application of contingencies
9 
Faulty execution
10 
Ambiguous contract provisions
11 
Contract document conflicts
12 
External 
Local concerns and requirements
13 
Effects of inflation
14 
Scope changes
15 
Scope creep
16 
Market conditions
17 
Unforeseen events
18 
Unforeseen conditions
 

 
111 
 
Table 6.1 and 6.2 together give a reasonably exhaustive source of all cost escalation factors 
for each individual project. As we are interested in those factors that can impact a pair of 
projects, these two sources are reviewed to eliminate repetitive factors and those factors 
which cannot concurrently affect a pair of projects. In this proposed approach, factors with 
negligible common effect are removed because of the approximate nature of the approach. 
Table 6.3 illustrates 12 factors that this author believes should be considered during 
correlation estimation for a pair of projects. These are the factors that if they occur in 
project A, they can potentially impact project B.   
Table 6.3: Recommended Common Cost Factors in Correlation Estimation for a Pair of 
Projects 
No 
Common Risk Factor 
Project 
A
B 
1 
Optimistic estimating (Bias)
 
2 
Lack of experience with delivery/ procurement 
method 
 
 
3 
Statutory/ regulatory constraints (federal, state, or 
local) 
 
 
4 
Environmental regulations and requirements
 
5 
Political climate 
 
6 
Bond market and rates
 
7 
Exchange rate 
 
8 
Inflation/interest rate
 
9 
Number of bidders
 
10 
Unemployment rate in construction trades
 
11 
Material and energy prices
 
12 
Sole source equipment and service providers
 
 

 
112 
 
We now have a list of the common risk factors. We have tried to consider risk factors that 
are more or less independent of each other, otherwise the effect of some factors will be 
counted more than once. Below a brief explanation of each factor is given: 
1. Optimistic estimating (Bias): Large projects tend to be underestimated due to 
optimistic estimation (Flyvbjerg 2006). Most people, especially those championing projects, 
have a tendency to see the future events in a more favorable light than the actual experience. 
Thus, when an estimator is preparing a project budget, he may underestimate costs due to 
this optimism and not considering all the important factors that may go wrong in the 
project. Also, this bias can have political reason to increase the likelihood of approving the 
project for being funded.  
2. Lack of experience with delivery/ procurement method: Project delivery methods, 
DBB (design-bid-build), DB (design-build), and CMR (construction manager at risk) along 
with procurement methods LB (low bid), BV (best value) and QBS (qualifications based 
selection) distribute the risk among the contract parties. The risks are supposed to be 
transferred to the party who can handle and manage the risks most effectively. If the party is 
unable to manage the risks properly this will increase the project costs. So, when an agency is 
using a delivery system other than the traditional DBB, depending on previous experience 
with the alternative delivery method, the project cost may increase. 
3. Statutory/ regulatory constraints (federal, state, or local): New statutes/regulations 
may be imposed by federal, state, or local governments which may require even major 
changes in project design. This will affect project costs or duration that has indirect impact 
on project cost. For instance, the Aviation and Transportation Security Act (ATSA) passed 
by congress in November 19, 2001 after terrorist attack in September 11, 2001 made several 

 
113 
 
changes in airports’ design to increase the measure of security. For analyzing this risk factor, 
the geographical locations of the two projects under consideration are really important 
meaning both projects must be under similar constraints.  
4. Environmental regulations and requirements: This risk factor is similar to the risk 
factor No. 3, but is only limited to the constraints imposed by environmental regulations and 
requirements. These are the constraints to mitigate the impact of projects on the local 
societal environment as well as the natural environment. This factor is again important when 
it can affect both projects under consideration.  
5. Political climate: Changing the political climate may cause some alterations that impact a 
project and result in cost increase. For instance political climate in state level or federal level 
may lead to expedite the finishing of transit projects which may cause cost growth.  
6. Bond market and rates: Any changes in the bond market will have a direct impact on 
project cost. If bond rates go up nationwide, so we can expect to see cost growth in any pair 
of projects under consideration. Many of the local bonds would have rates that are affected 
by the financial health of the issuing agency. In such cases, of course the bond rates are 
independent from each other for projects in different states. 
7. Exchange rate: This factor is important when projects have items imported from 
another country. For example, if we are analyzing correlation among two projects that have 
vehicles manufactured in Canada, if dollar becomes weaker against the Canadian currency, 
the exchange rate becomes a common cost growth factor on both projects. 
8. Inflation/interest rate:  When inflation/interest rate is higher than what is anticipated 
during project cost estimate, this becomes a major factor. This factor is more important 

 
114 
 
when we are dealing with multi-year projects (Touran and Bakhshi 2010). For the 
applications considered in this dissertation, this risk factor may be the most important cause 
of cost correlation because the portfolio consists of contemporaneous projects. 
9. Number of bidders: When the number of bids that an agency receives for a project is 
low, it means there is little competition and that project cost goes up. This happens when the 
project is complex, too large and/or the risks associated with the project are much greater 
than usual. Economic conditions can have an effect on the number of bidders as well. 
Usually tough economic times will result in an increase in the number of bidders as was 
evidenced in the current economic recession. Even obtaining payment/performance bonds 
for this type of projects is not easy for every contractor.  
10. Unemployment rate in construction trades: Low unemployment rate and wage have 
inverse relationship. When the unemployment rate increases up to a certain point, the wages 
go down. This is another effective escalation factor that should be considered.  
Blanchflower and Oswald (1990) used Britain and the U.S. data to form a wage curve. They 
found out that in both Britain and the U.S. there is a wage curve that has a negative gradient 
over low levels of unemployment. However they concluded these curves become flat once 
sufficiently large unemployment rate reached. The British wage curve was minimized at 13% 
while the U.S. curve was minimized at 10%.  
11. Material and energy prices: When the price of key materials and/or energy items 
change, it has a direct impact on the project cost. For instance if the price of cement 
increases significantly and both projects under consideration have considerable amount of 
cement, this factor must be considered as a common risk factor in both projects. Also, most 
of the time scarcity of materials is followed by large price increases. For example if for some 

 
115 
 
reason steel shortage happens in the market, its price would dramatically increase. Therefore 
two projects under consideration in which huge amounts of steel are consumed, will 
experience cost growth and this factor is a common risk factor in both projects. 
12. Sole source equipment and service providers: When the agency requires supplies or 
services which are available from only one source, and no other suppliers or services will 
satisfy its requirements due to unique features or functions, this will be considered as sole 
source equipment or service providers. If similar conditions affect both projects under 
consideration, this factor must be considered in the analysis of correlation coefficient.  
6.4.2  Subjectively Estimating the Correlation 
It should be noted that factors given in Table 6.3 are the common escalation factors in each 
project; but, it does not mean if a factor impacts project A it would necessarily impact 
project B as well. For instance, Material and Energy Prices is a risk factor that can potentially 
impact any project. Two projects are considered for correlation analysis. Both projects may 
need a certain type of material that has increased in price. However, project A is a design-
build contract where the design-builder has already submitted his firm bid. So while project 
B may receive higher bids because of material price, project A would be unaffected as far as 
the owner is concerned. In this case this factor will not change the degree of dependency 
between cost of project A and B. Also, it is important to find out to what degree these 
common risk factors that are influencing both projects. In other words, the share of each 
risk factor can be different from project to project. For example, project A is affected by 
sharp increase in price of copper, however, project B is not affected because the amount of 
copper used in that project is much less compared to project A. It can be plausible that only 

 
116 
 
two or three common factors can cause a large correlation for more than one project 
depending on the magnitude of their effect.   
In the proposed approach, an expert needs to go over the factors given in Table 6.3 for each 
pair of projects and check if it will impact both projects for the same reasons. The estimate 
of correlation coefficient should be an expert decision considering these common risk 
factors. These factors help expert consider the causes of dependency. So what is suggested 
here is that the analyst uses the common risk factors as the causes of creating correlation and 
his/her expert judgment to estimate a subjective degree of correlation between pairs of 
projects. These subjective degrees are suggested to be: none or independent, small, moderate, and 
large correlation. Previous research has suggested numerical values for these qualitative 
correlations. As an example, for quantification of these statements, Cohen (1988) suggests a 
threshold as follows: 
1. Large: 0.5;  
2. Moderate: 0.3; 
3. Small: 0.1. 
These values tend to underestimate the effect of correlations. Touran and Wiser (1992) 
showed that correlation among various cost categories in building projects can be as high as 
0.80. Further Touran (1993) suggested using three correlation values of 0.15, 0.45 and 0.8 
and reproduced results close to actual correlations between project costs. The author of this 
dissertation suggests the following thresholds based on other relevant studies, the subject 
matter and the ability of experts to feel the difference between various magnitudes when they 
are quantifying the correlation:   

 
117 
 
1. Large or strong correlation: Ranges from 0.7 to 1.0 and should be assigned as 0.85;  
2. Moderate correlation: Ranges from 0.4 to 0.7 and should be assigned as 0.55; 
3. Small or weak correlation: Ranges from 0.1 to 0.4 and should be assigned as 0.25; 
4. None or independent: Ranges from 0 to 0.1 and should be assigned as 0.  
These values are slightly larger than those suggested by Touran (1993) and hence more 
conservative, but are justified given the lack of data regarding large transit projects which are 
the subject of this dissertation. It should be noted that the correlation coefficient of 0.85 
among costs of two projects is very high and can rarely happen. 
In Appendix B, a mathematical method is suggested to calculate the pairwise correlation 
coefficient between costs of projects in which the risk registers (a list of probable risk factors 
along with their monetary impacts) are available.  
6.4.3  Delphi Method for Improving the Subjectively Estimated Correlation 
The accuracy of estimate can be improved by considering the opinion of a panel of experts 
instead of a single expert. There are three major methods to elicit experts’ judgments:  
interactive group, Delphi, and individual interview (Meyer and Booker 2001). We suggest the 
use of Delhi method because of its well-known characteristic to avoid biases arising from 
group interactions. 
The Delphi method is a structured communication technique to elicit a panel of experts’ 
judgment on an issue. This method is comprised of repeated solicitations of questions 

 
118 
 
through mail or email from the panel. The experts’ opinion on an issue is collected by a 
moderator (facilitator) in two or more rounds until reaching a consensus. After the first 
round of collecting opinions, the moderator prepares an anonymous summary of the 
collected opinions from the experts in the panel along with the given reasons they provided 
for their judgments. In the next round of collecting data, this summary is distributed among 
the same experts and they are encouraged to revise their previous opinion in light of other 
experts’ judgments. After a few rounds, a consensus should be achieved or at least the 
dispersion of opinions becomes less. This method was first developed by Rand Corporation 
for Air Force in the early 1950s (Chan et al 2001).   
The panel usually consists of a number of experts selected based on their experience and 
knowledge on the issue under consideration. Panel members are anonymous to each other in 
the whole process and only moderator communicates with them. The moderator creates the 
questionnaire, distributes and collects them, and answers the questions of the panel 
members.  
In the context of estimating correlation between costs of projects using our suggested 
method, we can use the Delphi method to increase the accuracy of the estimate. Hallowell 
and Gambatese (2009) suggested the use of Delphi method for interpretive reasoning which 
involves the recognition of pattern, spatial relationships, correlations and casual 
relationships.  
The moderator can select a panel of experts who have enough knowledge about the projects 
under consideration and are also familiar with the correlation concept. The moderator must 
develop a questionnaire including the brief explanation of the suggested method, the list of 
projects, and a matrix for inputting pairwise correlation along with a section to provide the 

 
119 
 
reason to select that correlation value. After the first round, the moderator should average all 
answers on pairwise correlations and round them up to the closest number in the four 
suggested correlation coefficient in the previous section (i.e., 0, 0.25, 0.55, or 0.85). The 
reason for that is we ask the experts to select the correlation coefficient from among these 
four predetermined values. Therefore, for the next round, the correlation coefficient must be 
in the predetermined format to enable the expert to possibly revise its previous opinion by 
comparing it with the outcome of all panel members.  This process can go on until it reaches 
a steady point and a consensus is arrived on the estimated correlation coefficients.  
6.5 
Implementation of Correlation 
6.5.1 
Characteristics of Correlation Matrices 
The process described in the previous section is based on expert judgment considering the 
common risks impacting the cost of each pair of projects. After correlation coefficients are 
estimated in this way, the correlation matrix should be tested to ensure that the matrix is 
mathematically a correct correlation matrix. The correlation among each pair of projects may 
appear to be rational; however, the whole system represented by correlation matrix might be 
inconsistent. Covariance matrix and correlation matrix as the normalized covariance matrix 
must be either a positive definite or positive semidefinite matrix (Koch 1999; Pearson 2002). 
Before taking up this concept, some matrix definitions will be explained that are required for 
better understanding of the following sections. 
 

 
120 
 
Eigenvector and Eigenvalue 
If A is an 
n
nmatrix and if x is a non-zero vector such that 
x
Ax
λ

, where λ is a scalar, 
then x  is an eigenvector of matrix A with corresponding eigenvalue λ . Any eigenvalue λ  
satisfies the 
th
n degree polynomial equation 
0
)I
A
(
det

λ
. This equation is called the 
characteristic equation of matrix A . We thus have n eigenvalues which may not be all 
distinct and n  corresponding eigenvectors (Bell 1975).  
Also, it is known that if A is symmetric, then 



n
i
n
1
)
A
(
det
. 
Positive Semidefinite Matrix 
A symmetric matrix 
n
n


A
is positive semidefinite if 
0
Ax
x T

 for every 
n


x
 and is 
denoted by 
0
A 
. When A is positive semidefinite, we can say (Berman et al 2003): 
1. All the eigenvalues of A are nonnegative; 
2. An 
n
n lower triangular real matrix L  exists such that 
T
LL
A 
. This is called 
Choleski decomposition; 
3. 
0
)
(

A
det
. 
Determinant of a lower or upper triangular or diagonal matrix is equal to the product of the 
diagonal elements of the matrix (Bell 1975). 
Positive Definite Matrix 
This is a special case of positive semidefinite matrix. An 
n
n positive semidefinite matrix 
A is completely positive if and only if it is a nonsingular matrix and matrix A is nonsingular 

 
121 
 
if and only if the determinant of the matrix is not equal to zero. This means 
0
Ax
x T

 for 
every 
n


x
0
. When A is positive definite, we can say (Berman et al 2003): 
1. All the eigenvalues of A are positive; 
2. 
T
LL
A 
where L  is a nonsingular lower triangular matrix (Choleski decomposition); 
3. 
0
)
(

A
det
. 
6.5.2 Controlling Consistency of Correlation Matrices 
A correlation matrix needs to be consistent which means the possible simultaneous 
correlation relationships between three or more variables must exist. Inconsistency happens 
when a matrix cannot meet the positive semidefinite or definite criteria. This issue is 
magnified when most of the correlations among the variables are relatively large (Touran 
1993). The requirement for being positive semidefinite or definite first needs to be tested 
and once it is satisfied, one can be confident that the correlation matrix used in the analysis 
indeed represents a relationship that would be possible among random variables. To this 
end, a couple of methods based on the characteristics of semidefinite matrices have been 
suggested to test if the correlation matrix is a positive semidefinite matrix. There are also 
suggested algorithms to make the correlation matrix or covariance matrix a positive 
semidefinite matrix when it cannot satisfy the requirements with the lowest impact on the 
original values.  
 
 

 
122 
 
Suggested Methods: 
Fishman (1978) suggested an algorithm based on Choleski decomposition to test if the 
covariance matrix is positive definite or not. If Choleski decomposition exists for a matrix it 
means that the matrix is either positive definite or semidefinite. Fishman algorithm to 
decompose 
T
BB


is as follows where is the covariance matrix of n  variables, 
ij

denotes entries in matrix and 
ij
b denotes entries in matrixB : 
n
i
b
i
i
...,
,1
for
11
1
1




  
  
 
 
 
 
 
 
(6.5) 
2

i
: 





1
1
2
i
j
ij
ii
ii
b
b

 
 
 
 
 
 
 
 
 
 (6.6)  
If 
n
i 
, then computation of matrix B is complete. If not, increment i  by 1: 
1
...,
,2
for
.
,1
1
1










i
j
b
b
b
b
i
i
jj
j
m
jm
im
ij
ij

  
 
 
 
 (6.7)  
Matrix cannot be decomposed if the term under the root in Eq. (6.6) is negative; in other 
words 
iib  becomes imaginary. If covariance matrix is tested for being positive definite, then 
this term must be positive and for positive semidefinite it must be non-negative.  
To remedy this problem, Touran (1993) suggested that all correlation coefficients (not 
covariances) should be reduced by about 1% and then matrix  B  recalculated to see if all 
iib
entries become real. If some entries still remain imaginary, the process of reducing 

 
123 
 
correlation coefficients should be repeated until there is no imaginary entry anymore. 
However, the final adjusted correlation matrix would be different from the original matrix. 
Ince and Buongiono (1991) suggested Scheuer and Stoller algorithm which is completely 
similar to Fishman algorithm for testing for positive definiteness and deriving the elements 
ij
b  in Choleski decomposition. They also recommended that whenever the term under the 
square root is not positive the corresponding variance factor 
ii
 must be increased by: 
i
ii
i
j
ijb







1
1
2
 
 
 
 
 
 
 
 
 
(6.8) 
where 
iis an arbitrarily small number that can restore positive definiteness to the 
covariance matrix. This can be interpreted as a situation where the originally specified 
variances of one or more variables are too small in relation to the larger variances of other 
variables (Ince and Buongiono 1991).  
Most of mathematical software packages such as MATLAB can do Choleski decomposition 
and when the matrix is not a positive definite or semidefinite it alerts the user that 
decomposition is not possible. Also simulation software packages check the consistency of 
input correlation matrix using different algorithms. In case of inconsistency, they usually 
offer to resolve the issue by creating a new matrix that is as close as possible to the original 
one and meets the requirements. For instance, @Risk developed by Palisade Corporation 
uses the eigenvalue characteristic of a positive semidefinite matrix to check the consistency 
of the entered correlation matrix. As it was mentioned earlier, the eigenvalues of a positive 
semidefinite matrix are greater than or equal to zero. If @Risk determines the entered matrix 
is invalid, it implements a three-step process to make it consistent: 

 
124 
 
1. It first finds the smallest eigenvalue 
1
 of the correlation matrix C ; 
2. Using the transformation: 
I.
C
C
1




  
 
 
 
 
 
 
 
(6.9) 
 Where C is the entered correlation matrix,Cis the transformed correlation matrix, 
and I is the identity matrix, it shifts the eigenvalues so that the smallest eigenvalue 
becomes 0; 
3. Using another transformation: 
C
).
1
1(
C
1




λ
 
 
 
 
 
 
 
 
(6.10) 
It divides all the diagonal terms of Cby 
)
1(
1λ

to make the diagonal values equal to 
1. This matrix has the smallest eigenvalue equal to zero.  
Therefore, using one of the abovementioned methods the correlation matrix can be tested 
and adjusted to ensure a consistent correlation matrix.  
6.6 
Summary 
In this chapter, the effect of correlation on total portfolio’s budget variance was described. 
Correlation coefficients in construction costs for measuring the degree of dependence 
between two variables were explained. Lack of historical data to mathematically calculate 
correlation was considered to be a major issue in construction projects. Subjective estimate 
and qualitatively assessment of correlation were described as a solution when there is no 
sufficient data available to calculate correlation.  

 
125 
 
A new method called proposed structured guideline (PSG) was introduced to help estimators 
or experts to estimate the correlation coefficient between costs of pair of projects in a 
reasonable and systematic fashion. In order to do that two exhaustive sources of risk factors 
were identified and a short list of 12 common risk factors that can affect the cost of any two 
projects under consideration were determined. A set of guidelines was developed that can 
help the estimator or the expert first qualitatively estimates the correlation and then by the 
means of predetermined coefficient figures converts the qualitative term into a correlation 
coefficient. 
Moreover, the characteristics of correlation matrix were described and the methods to 
convert a matrix to a positive semidefinite matrix were discussed.       

 
126 
 
CHAPTER 7: APPLYING THE PROPOSED MODEL 
7.1 Introduction 
The proposed model is a mathematically flexible model that can be applied to any portfolio 
of projects. Different agencies may have different policies for cost estimating process and 
budget development that may require a certain point in time to use the model. The model 
may be used to improve the budget of each project in a portfolio at any key stage of project 
development such as conceptual design, preliminary engineering, or final design. However, 
the use of the model is contingent upon availability of historical data. An agency needs to 
have historical cost estimates at the point that they are seeking to employ the model along 
with actual final costs. For instance, if an agency intends to use the proposed model after 
finishing the final design, they need to have access to a set of projects whose estimated costs 
at the final design and their actual final costs are available. This data forms the first step of 
the model where the mean and standard deviation of cost overruns/underruns are defined.  
After collecting historical data and calculating the mean and standard deviation of cost 
overruns/underruns, the model will be ready to be applied on any set of projects in a 
portfolio. The model will calculate the required budget increase/decrease based on the past 
projects’ performances. Then by finishing new projects and receiving more information, the 
model is updated and becomes ready to be applied on another prospective portfolio of 
projects.  

 
127 
 
7.2 Application of the Model by an Owner Agency 
We will now demonstrate the application of the model by an owner agency. We will use the 
Federal Transit Administration (FTA) as a case in point. As it was stated earlier in Chapter 3, 
the FTA financially and technically supports local transit agencies for major capital 
investment in new fixed guideway system such as rapid rail, light rail, commuter rail, 
exclusive bus/high occupancy vehicle lanes, or ferry service or an extension to an existing 
fixed guideway system. The FTA financial assistance to local transit agencies happens 
through an agreement called Full Funding Grant Agreement (FFGA). This is the point that 
the FTA commits contractually to provide the agency with Federal funds. Each year based 
on the amount of available funds for new starts projects under the 49 U.S.C. 5309 Major Capital 
Investment Program, a number of transit projects are selected and reported to the Congress 
through Annual Report on Funding Recommendations for approval. These annual reports 
are prepared for each fiscal year. Therefore, it is of high importance to have accurate cost 
estimates for all projects in the portfolio of projects in a certain fiscal year. Cost overrun of 
projects and providing more funds will jeopardize the on time completion of projects, and 
incur more expenses to the tax payers. Thus it is important for the FTA to have a precise 
estimate of project’s cost before tying themselves to the FFGA contracts.  
The proposed model can greatly help the FTA adjust the projects’ cost estimates based on 
past projects’ performances. In the proposed approach, first the preparation of a set of 
historical projects’ data including cost estimate at the FFGA and actual final cost (as-built 
cost) is required. Using this data, mean and standard deviation of cost overruns/underruns 
in the historical data set is determined. Based on this, the parameters of the model are 
calculated and the model can be applied on the first set of projects recommended in the 

 
128 
 
upcoming annual report to the Congress. The model may advise to increase or decrease the 
total portfolio budget. Then all projects’ cost estimates are modified using the calculated 
increase/ decrease factor. The new adjusted cost estimates must be considered by the FTA 
to establish the FGGAs. Henceforth, every single year or two, when the new projects are 
completed and new data becomes available, the model will be updated using the suggested 
Bayesian approach. The updating incorporates the performance of recently completed 
projects in the model. However, it will take a few years until the actual costs of projects used 
in the proposed model become available and their cost overruns/underruns input to the 
model. The model is updated in the regular intervals and performances of the projects 
completed are input in the model. The hope is to see the cost overrun and/or underrun 
close to zero after a few iterations.  
In the following sections, the application of the model through a numerical example using 
transit capital cost data is illustrated and the ability and effectiveness of the model to control 
cost overrun in a portfolio of projects is verified.    
7.3 Selecting Data to Find the Initial values of and  
To show the application and effectiveness of the model, in this chapter the model is applied 
to a set of transit capital cost data. For this purpose, a set of 28 transit projects (Booz Allen 
Hamilton 2005) is selected. These projects have been funded by the Federal Transit 
Administration (FTA) of the U.S. Department of Transportation in the past twenty years 
(Table 7.1).  
 

 
 
Revie
proje
the pr
proje
next 
dynam
identi
new 
Bayes
Table 7.1: L
ewing Table 7
cts in 2004 a
rimary values
cts complete
step, the mo
mic character
ified three tr
observed pr
sian updating
List of 28 Tra
7.1 discloses 
and 1 project
s for and 
ed in 2004 to
odel is updat
ristic of the m
ransit project
rojects are c
g.  
ansit Projects
that 22 out o
t in 2005. We
 used in th
o see the eff
ted with the 
model by the
ts that were 
created to b
129 
s Adopted fro
of 28 project
e set aside th
he model. Th
fect of mode
actual costs
e means of B
completed in
be used for 
om Booz All
ts have been 
he 22 project
hen the mode
el on cost ov
s of these 5 
Bayesian upda
n 2005 and 2
applying th
len Hamilton
completed b
ts as historica
el is applied 
verruns/und
projects. To
ating over tim
2006. Theref
he model an
n (2005) 
before 2004, 
al data to fin
to the set of 
erruns. In th
o perceive th
me, we furthe
fore a set of 
nd conductin
5 
nd 
f 5 
he 
he 
er 
4 
ng 

 
 
From
“Hist
proje
Cost 
actual
transi
proce
overr
Table
T
m this point o
torical Datas
cts “Second 
overrun/und
l final cost (
it projects Fu
ess of transit 
run/underrun
e 7.2. 
Table 7.2: Co
on, for cons
set”, the set 
Dataset”.  
derrun of ea
(as-built cost)
ull Funding 
project appr
n data for 28
ost Overrun/
istency and 
of 5 projec
ach project is
t) and estima
Grant Agree
roval and fun
8 projects in B
underrun of 
Ham
130 
ease of refer
ts “First Da
s defined to 
ated cost at t
ement (FFGA
nding by the
Booz Allen H
f 28 Transit P
milton (2005)
rencing, we 
ataset”, and 
be the perce
the end of fi
A) is establis
e FTA, pleas
Hamilton (20
Projects Adop
) 
call the set o
the set of 4
ent of differ
final design (
shed by the 
e refer to Ch
005) report i
pted from B
of 22 projec
4 more recen
rence betwee
(FD), when i
FTA. For th
hapter 3. Co
s illustrated i
ooz Allen 
ts 
nt 
en 
in 
he 
st 
in 
 

 
131 
 
To verify the assumption of normality, a test of goodness of fit using @Risk (Palisade Corp. 
2008) software is conducted on 22 cost overruns/ underruns of Historical Dataset. The test 
using the Chi-squared statistic passed at 1% level of significance (P-value= 0.0219). Figure 
7.1 depicts the superposition of the normal distribution on the original data histogram.  
 
Figure 7.1: Fitting the Normal Distribution on 22 Transit Projects (Historical Dataset)
 
Figure 7.1 demonstrates the limitation in the cost underrun values. It means that in the real 
world we are dealing with projects that their costs would not be less than a certain value. 
This certain value can be approximated using historical data. Reviewing the historical data, 
we assume that the FTA defines 
%
15

m
 as the maximum expected underrun. Using 
Figure 7.1, it is found that the value of  corresponding with 
%
15

m
 is 
%
1.9


 and 
the 
average 
of 
cost 
underruns/overruns 
is 
%
79
.8


; 
thus
0879
.1


and 
2799
.1
)
15
.0
1(
0879
.1




.  
9.1%
85.9%
12.3%
86.4%
-0.150
0.546
-0.4
-0.3
-0.2
-0.1
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
Fitted Normal Distribution on Cost Overruns/Underruns of 22 Transit Projects
RiskNormal(0.087940,0.20527)
Input
Minimum
-0.1561
Maximum
0.5517
Mean
0.0879
Std Dev
0.2053
V alues
22
Normal
Minimum
- 8
Maximum
+8
Mean
0.0879
Std Dev
0.2053

 
132 
 
In the following sections, we first introduce the First and Second Dataset in more detail and 
estimate the correlation between projects of each dataset. Then the model will be applied to 
the datasets. To highlight the impact of correlation, we first apply the model presuming that 
all projects are statistically independent of each other. Later, we will recognize estimated 
correlation between projects. Correlation coefficients are estimated using the Proposed 
Structured Guideline (PSG) described in Chapter 5.  
7.4 Selecting Data (First  Dataset) to Apply the Model for the First Time 
After estimating values of and from the historical data, the model is ready to be applied 
on any prospective set of projects. As it was mentioned earlier, a set of 5 transit projects 
completed in 2004 from Booz Allen Hamilton (2005) called First Dataset is selected to apply 
the model for the first time. These projects with estimated cost at the FFGA and actual final 
cost and percent of cost overrun/ underrun are summarized in Table 7.3.  
Table 7.3: Dataset of Five Transit Projects for Applying the Model for the First Time (First 
Dataset) 
Proj. 
ID 
Project Name 
State 
Completed 
Year 
Mode 
Delivery 
Method
Cost at 
FFGA 
in M$ 
Actual 
Cost in 
M$ 
Cost 
Overrun/
Underrun
1 
Boston Silver Line 
(Phase 1) 
MA 
2004 
Busway 
DBB 
$413.4 
$604.4 
46.2% 
2 
Minneapolis 
Hiawatha Line 
MD 
2004 
Light Rail 
DB 
$675.4 
$715.3 
5.91% 
3 
Portland Interstate 
MAX 
OR 
2004 
Light Rail 
CMR 
$314.9 
$349.4 
10.96% 
4 
Santa Clara Vasona 
Line 
CA 
2004 
Light Rail 
DBB 
$313.6 
$316.8 
1.02% 
5 
Washington Largo 
Extension 
DC 
2004 
Heavy Rail
DB 
$433.9 
$456.0 
5.09% 

 
133 
 
7.4.1 
Case Study Projects in the First Dataset 
The projects in the First Dataset have been selected from Booz Allen Hamilton (2005) and 
the following information is gathered from that report. This information forms the basis for 
estimating the correlation coefficients among project costs. These projects were built at 
about the same time and all of them were completed and went into revenue in 2004. This is 
important because it can show that they have been under similar economical conditions in 
terms of inflation and escalation.  
Below, each project is briefly described. This information will later be used to estimate the 
pairwise correlation coefficients. 
 
Project 1- Boston Silver Line (Phase 1):  
This is a 1.5 mile underground Bus way. Boston Silver line Phase 1 was developed by 
Massachusetts Bay Transportation Authority (MBTA) and is comprised of a 1 mile, 3 station 
tunnel between South Station and the World Trade Center. The project included the 
procurement of 32 vehicles and the construction of a new vehicle maintenance facility. The 
project delivery method used for this project was design-bid-build (DBB). 
The total cost for the Silver Line project was estimated to be $413.4 million at the Full 
Funding Grant Agreement (FFGA) phase, but grew to $604.4 million upon completion. The 
cost increase was due to schedule delays and changes in unit cost and scope. The midpoint 
of construction from 1995 was shifted to 2002 resulting in an increase in project costs of 
about $99.1million. The remaining increase was due to changes in unit cost and scope. 
Factors contributing to delays were identified to be coordination problems on the joint 
construction contracts with the Central Artery/Tunnel project, complication with the design 

 
134 
 
for relocating utilities, and differing site conditions. Land acquisition costs were also higher 
than what was originally estimated.  
Project 2- Minneapolis Hiawatha Line: 
Metro Transit of Minneapolis-St. Paul Metropolitan Council, Minnesota Department of 
Transportation (MnDOT), Metropolitan Airports Commission (MAC), and Hennepin 
County constructed an 11.9 mile light rail transit line connecting downtown Minneapolis, 
Minneapolis/St. Paul International Airport, and the Mall of America. This is the first LRT 
line built in Minnesota and the project experienced political pressures during its planning. 
Hiawatha Line project included a 1.5 mile tunnel, 26 light rail vehicles, and 17 stations. The 
project delivery method used for this project was design-build (DB). 
After the feasibility study and the Final Environmental Impact Statement (FEIS) in 1985, the 
project was halted when the “Legislature prohibited any expenditure of public funds on light 
rail transit”. However this constraint was removed before entering into the FFGA and did 
not affect the cost estimate at that point.  
The Hiawatha Line project was estimated as $675.4 million total cost at the FFGA stage, but 
was completed for $715.3 million. An FFGA was signed for the project for $675.4 million in 
January 2001 with revenues service scheduled for December 2004. Construction started on 
the Hiawatha Corridor LRT in January 2001. The project faced a challenge in acquiring land 
from five federal agencies because each agency had a different structure and rule for land 
transfer. Eventually all the right-of-way (ROW) was acquired and deals were made with the 
agencies without any cost increase. The major cost increase happened due to re-alignment at 
the Mall of America. The re-alignment provided better access (and more ridership) at the 
Mall of America and increased ridership. The cost increase included $18.8 million for design 

 
135 
 
and construction, $11.8 million for additional right-of-way costs, additional local 
contribution of $3.6 million, additional $2.8 for management and administration, additional 
insurance of $2.8 million, and additional contingency of $1.5 million. This project 
experienced one year of delay after final design during the construction phase.  
Project 3- Portland Interstate MAX: 
This is a 5.8 mile interstate Metropolitan Area Express (MAX) light rail line. It tied into the 
existing MAX Blue Line at Rose Quarter. Interstate MAX used innovative, green 
construction practices not previously widely applied to light rail construction. The project 
delivery method used for this project was Construction Manager at Risk (CMR).  
The Interstate MAX project total cost was estimated at $314.9 million at the FFGA stage, 
but was completed for $349.4 million. The project schedule remained constant throughout 
project development, and the project was completed on time. Despite an increase in the fleet 
size during final design, cost containment during construction was made possible by value 
engineering, utilizing the CMR delivery method, bringing the construction contractor early 
into the design phase, and using innovative construction practices and materials. Alignment 
costs went down during final design, but up again during construction. Construction costs 
were also impacted by the need to close the MAX Blue Line for a brief period while existing 
tracks were raised and realigned. During the closure, buses shuttled MAX riders around the 
area. 
Project 4- Santa Clara Vasona Line: 
This is a 5.2 mile light rail extension constructed by Santa Clara Valley Transportation 
Authority (VTA). Santa Clara Vasona Line includes 0.18 miles of subway alignment, 0.1 
miles elevated and the rest at-grade. There are eight stations, seven at-grade and one 

 
136 
 
elevated. The project objectives were to provide service between downtown San Jose and 
town of Campbell and to ease traffic on adjacent freeways and surface streets. The project 
delivery method used for this project was design-bid-build (DBB). 
The total cost estimate for Vasona project was $313.6 million at the FFGA stage, and was 
completed for $316.8 million. The project schedule remained constant throughout project 
development, and the project was completed on time. From planning to operations, project 
scope quantities remained constant, while cost increases totaled about $47.8 million. Only 
$3.2 million cost increase happened after final design/FFGA. The growth is attributed in 
part to several requirements imposed by third parties, such as additional requirements by 
Union Pacific Railroad (UPRR) as part of the right-of-way (ROW) purchase for existing 
freight track relocation and reconstruction. ROW purchase cost from UPRR was also higher 
than the original budget. Similarly, 496 feet of guideway required elevation after the 
California Public Utilities Commission (CPUC) disapproved of at-grade crossing at 
Hamilton Avenue. In addition, the Hamilton station had to be elevated as a result of the 
guideway being elevated. Utility relocation was more significant than envisioned in the 
original budget and required additional construction management resources to limit schedule 
slippage. 
Project 5- Washington Largo Extension: 
This was a 3.1 mile heavy rail extension led jointly by the Maryland Transit Administration 
(MTA) and the Washington Metropolitan Area Transit Authority (WMATA). The 3.1 mile 
path included tunnel and surface segments, 2 new stations, and the purchase of 14 heavy rail 
vehicles. The stations provide 2,700 park-and-ride spaces. The MTA developed the project 

 
137 
 
through preliminary engineering and WMATA accepted responsibility for managing the final 
design and construction activities, using a design-build (DB) construction method.  
The cost estimate of this project at the FFGA stage was $433.9 million and the actual cost at 
completion was $456.0 million. The planned opening of the project shifted multiple times, 
from 2003 during planning, to 2005 during preliminary engineering, and to 2004 during final 
design through actual opening in 2004. However, the project schedule was not delayed after 
final design during construction phase. Changes in scope and unit cost caused cost increase 
in the project.  
7.4.2 Estimating Correlation between Projects in the First Dataset Using the PSG 
To calculate the correlation coefficient among each pair of projects in the First Dataset using 
the proposed structured guideline (PSG), precise knowledge of every project is required. 
What has been compiled in the previous section is not covering all aspects of the projects’ 
information necessary to complete the PSG table. Since we lack detailed information on 
each project, we may not be able to go over all twelve common risk factors in the PSG 
method. An agency’s expert who has access to all contract documents of the projects in 
hand can review all twelve common risk factors and estimate the correlation with a better 
accuracy. 
It should be noted that the estimation of the correlation should happen at the time of the 
FFGA. Many of the risk factors described in the projects descriptions were not known at the 
time of the FFGA. The correlation evaluation is performed by going through the 12 factors 
given in Table 6.3. The relevant factors are discussed in the following.  

 
138 
 
It is presumed that all five projects had optimistic estimating and that they were 
underestimated. Flyvbjerg (2006) declares that there is a demonstrated, systematic tendency 
for project appraisers in large public projects to be overly optimistic. Projects 2, 3 and 5 were 
using alternative delivery method. Hiawatha Line was the first LRT project in Minneapolis in 
which they did not have much experience. For Washington Largo Extension, MTA had 
experience with design-build in Central LRT Project Phase II constructed in 1997. Given the 
variety of the delivery methods used and the experience of transit agencies, it seems that the 
assumption of independence is not unrealistic.  
Due to September 11, 2001 terrorist attack, the risk of security enhancement and changing 
the alignment to protect Federal lands may arise. Despite this, due to geographic dispersity 
of these projects, we could not identify any one regulation or incidence that would affect 
more than any one of these projects concurrently. Also, there is no evidence that any 
environmental regulation has affected the projects after completing the final design.   
The bond rating in each state is established based on that state’s creditor situation. However, 
as all five projects are contemporary, bond rate would incur some correlation between costs 
of the five projects. Rail cars of projects 2, 3, 4, and 5 could have been imported from 
overseas or Canada. Inflation also can create some degree of correlation between the 
projects as they are contemporary.  
Now, Table 7.4 is completed on the basis of the gathered information in accordance with 
the criteria explained in the PSG method (Sections 6.4.1 and 6.4.2). The correlation 
magnitudes are first identified, and then they are converted to the correlation coefficients 
using the proposed conversion threshold.  

 
139 
 
Table 7.4: Finding the Correlation Coefficients among Projects in the First Dataset 
Correlation 
Projects 
1, 2 
1, 3 
1, 4 
1, 5 
2, 3 
2, 4 
2, 5 
3, 4 
3, 5 
4, 5 
Correlation Magnitude 
(Qualification) 
Weak 
Weak 
Weak 
Weak 
Moderate 
Moderate 
Moderate 
Moderate 
Moderate 
Moderate 
Correlation Coefficient 
(Quantification) 
0.25 
0.25 
0.25 
0.25 
0.55 
0.55 
0.55 
0.55 
0.55 
0.55
 
The correlation matrix estimated here then need to be checked for being positive 
semidefinite. This control is conducted in the next section.  
7.4.3 Positive Semidefinite Check for the Correlation Matrix in the First Dataset 
We remember that a matrix is positive semidefinite if and only if all eigenvalues of the matrix 
are non-negative. With the help of MATLAB programming language, this condition is 
checked first and if the matrix is not positive semidefinite, it is restored using @Risk 
algorithm explained in Chapter 5.  
The correlation matrix of the projects in the First Dataset estimated in the previous section 
is labeled
1
C  where projects with ID 1 to 5 are arranged from left to right and top to down 
which is: 

















00
.1
55
.0
55
.0
55
.0
25
.0
55
.0
00
.1
55
.0
55
.0
25
.0
55
.0
55
.0
00
.1
55
.0
25
.0
55
.0
55
.0
55
.0
00
.1
25
.0
25
.0
25
.0
25
.0
25
.0
00
.1
C1
 
 
 
 
 
 
(7.1) 

 
140 
 
Using MATLAB, five eigenvalues of matrix 
1
C  are calculated: 
7897
.2
;
8603
.0
4500
0
4500
.0
4500
.0
5
4
3
2
1





λ
λ
;
.
λ
;
λ
;
λ
 
 
(7.2) 
Since all five eigenvalues of correlation matrix 
1
C  are positive, therefore the matrix can be 
considered as a mathematically true correlation matrix. 
7.5 
Selecting Data (Second Dataset) to Apply the Model for the Second Time 
To show the effectiveness and dynamic characteristic of the model over the course of time, 
we employ the model on another set of projects. For this purpose, a set of four projects 
were identified that were completed in 2005 and 2006 (Annual Report on New Starts (FTA 
2010a), Capital Cost Database (FTA 2010b), and Booz Allen Hamilton (2005)). These 
projects are summarized in Table 7.5 and called Second Dataset. 
Table 7.5: Dataset of Four Transit Projects for Applying the Model for the Second Time 
(Second Dataset) 
Proj. 
ID 
Project Name 
State 
Completed 
Year 
Mode 
Delivery 
Method
Cost at 
FFGA 
in M$ 
Actual 
Cost in 
M$ 
Cost 
Overrun/
Underrun
1 
Chicago CTA Blue 
Line (Douglas) 
Rehabilitation 
IL 
2006 
Heavy Rail
DBB 
$482.6 
$419.61 
-13.05% 
2 
Northern New 
Jersey Hudson-
Bergen MOS-II 
NJ 
2006 
Light Rail 
DBOM 
$1,215.4 
$1,218.47 
0.25% 
3 
San Diego Mission 
Valley East 
CA 
2005 
Light Rail 
DBB 
$431.0 
$504.01 
16.94% 
4 
San Juan Tren 
Urbano 
PR 
2005 
Heavy Rail
DB 
$1,250.0 
$2,250.0 
80.00% 

 
141 
 
7.5.1 
Case Study Projects in the Second Dataset 
This dataset is chosen to apply the model for the second time after updating the model by 
the actual data of completed projects in the First Dataset. This will help demonstrate the 
effectiveness and dynamic characteristics of the model.  
The projects in the Second Dataset are selected from Annual Report on New Starts (FTA 
2010a) and Booz Allen Hamilton (2005). Followings are brief explanations for each project 
of the Second Dataset. This data forms the basis for estimating the correlation coefficients 
among them. The main criteria for selecting these projects have been the availability of the 
required cost data. 
Project 1- Chicago CTA Blue Line (Douglas) Rehabilitation: 
 The Douglas Branch Line of Chicago Transit Authority (CTA) is a heavy rail originally built 
in the early 20th century. This line serves one of the most economically distressed areas in 
Chicago. The rehabilitation project reconstructed 6.6 mile length of the existing line which 
was comprised of extensive work on eight CTA rail stations (six elevated and two at-grade), 
five miles of track, signal and communications equipment, traction power system and 
infrastructure rehabilitation. The project delivery method used for this project was design-
bid-build (DBB).  
 The total capital costs for the proposed project were estimated to be $482.6 million but it 
was completed with $419.6 million. The FTA issued a Finding of No Significant Impact on 
the Environmental Assessment (EA) in April 2000. Following to Environmental Assessment 
process, the FTA approved the project into final design in June 2000. The FFGA between 
the FTA and CTA was reached in January 2001 and the FTA committed $320.1 million in 
Section 5309 New Starts funds to the project. The contractor of this project was 

 
142 
 
Kiewit/Delgado, AJV (A Joint Venture) with $317 million construction contract. The 
project started at Pulaski station on September 10, 2001 and was completed on January 8, 
2005. The project is anticipated to have 6,000 daily new riders in the year 2020. 
Project 2- Northern New Jersey Hudson-Bergen MOS-II: 
The Northern New Jersey Hudson-Bergen MOS-II (Minimum Operable Segment - II) of 
the New Jersey Transit Hudson-Bergen is a 5.1 mile light rail system with seven stations. 
This project is part of a three phase project. The whole Hudson-Bergen Light Rail Transit 
(LRT) system is a 20.1 mile, 30 station LRT project. It runs from the Vince Lombardi Park-
and-Ride lot in Bergen County to West Fifth Street in Bayonne in Hudson County. The 
MOS-I is 10.3 mile, MOS-2 is 5.1 mile, and MOS-3 is a 4.7 mile system. This line provides 
transit service for one of the highest residential densities in the region. It also serves the 
Manhattan central business district by providing connections to ferry and commuter rails. 
MOS-II was in fact negotiated as a large change order to MOS-I project. MOS-II was a DBOM 
(design- build- operate- maintain) project which is unusual for transit projects in the United 
States, however, the agency had sufficient experience with this delivery system because 
MOS-I was DBOM also.  
The total capital cost for MOS-II was estimated at $1,215.40 million. The FEIS for the full 
Hudson-Bergen LRT project was issued in August 1996. A Finding of No Significant Impact 
on the EA was issued by the FTA in June 1999. Full Funding Grant Agreement for MOS–II 
between the FTA and New Jersey Transit was reached in November 2000. The FTA 
committed $500 million of Section 5309 New Starts funds. The issuance of the FFGA at 
that time provided NJ Transit with the authority to borrow funds to begin construction 
while the MOS-I was being completed, under the same turnkey contract. This was an 

 
143 
 
advantage which allowed that the entire Hudson-Bergen project to be constructed at a lower 
cost by preventing the considerable costs associated with stopping and then restarting a 
major construction project MOS-II was completed in 2005 and is anticipated to serve 34,900 
average weekday riders in 2010.  
Project 3- San Diego Mission Valley East:  
San Diego Mission Valley East light rail transit (LRT) was an extension of existing Blue Line 
executed by The Metropolitan Transit Development Board (MTDB) with a length of 5.9 
mile. The project extended the existing system from the Mission San Diego Trolley Station 
east of Interstate 15 to the City of La Mesa in which it connects to the existing Orange Line 
near Baltimore Drive. The project was comprised of the construction of four new stations at 
Grantville, San Diego State University, Alvarado Medical Center and 70th Street, and served 
two existing stations at Mission San Diego and Grossmont Center. The project had elevated, 
at-grade, and tunnel (400 ft) portions, 11 new low-floor railcars, and provided two park-and-
ride lots and a new access road between Waring Road and the Grantville Station. The project 
delivery method used for this project was design-bid-build (DBB).  
Total capital cost was estimated at $431 million. The project is anticipated to serve 
approximately 10,800 average weekday riders in 2015. A Major Investment Study/Draft 
Environmental Impact Statement (MIS/DEIS) was completed in May 1997. The FEIS was 
completed, and a Record of Decision was issued by the FTA in August 1998. The FTA and 
MTDB reached a FFGA on June 22, 2000. The FTA committed a total of $330 million in 
Section 5309 New Starts funds to the project. In July 2005, the project was completed and 
called Green Line.  
 

 
144 
 
Project 4- San Juan Tren Urbano: 
This was the first fixed guideway mass transit system in Puerto Rico. This heavy rail system 
consisted of 10.7 miles of track and 16 stations, and 74 vehicles. The project owner was the 
Puerto Rico Highway and Transportation Authority (PRHTA). It is a rapid rail line between 
Bayamon Centro and Sagrado Corazan area in the metropolitan San Juan area. The system is 
comprised of double-track lines. This project used design-build (DB) delivery method.  
The total project cost at the FFGA was estimated to be $1,250 million but it was completed 
with $2,250 million. Due to increased cost of this project, PRHTA reduced its budget for 
other transportation projects in the area, such as a planned transportation building.   
After establishing the FFGA , three Environmental Assessments were prepared that revised 
the alignment at the Villa Nevarez station and added two new stations in Rio Piedras at the 
University of the Puerto Rico and in Hato Rey. Two new stations along the line were added 
to the plan and a previous station was realigned. Also, 10 cars were added to the original 
plan. Tren Urbano also experienced 4 years of delay in the construction phase and went to 
revenue in 2005. A multitude of issues including the use of design-build, local contractors, 
and several changes in scope caused the vast cost overrun. 
7.5.2 Estimating Correlation between Projects in the Second Dataset Using the 
PSG 
Due to lack of detailed information as to each project in the Second Dataset, similar to what 
we did for calculating correlation coefficients in the First Dataset, we take into consideration 
just those common risk factors for which the data is available. Once again it should be 

 
145 
 
noticed that an agency’s expert who has access to the all contract documents of the projects 
in hand can review all twelve common risk factors identified in the PSG method and 
estimate the correlation with a better accuracy.  
One should remember that the estimation of the correlation should happen at the time of 
the FFGA when many of the risk factors described in the projects descriptions were not 
known. The correlation evaluation is performed by going through the 12 factors given in 
Table 6.3 and the relevant factors are discussed in the following.  
According to Flyvbjerg (2006), there is a demonstrated, systematic tendency for project 
appraisers in large public projects to be overly optimistic. Therefore, it is presumed that all 
four projects had optimistic estimating and that they would be underestimated. Projects 2 
and 4 were using alternative delivery method. However, New Jersey Transit Agency had 
experience in DBOM delivery method as they had constructed Hudson-Bergen MOS-I with 
the same delivery method. Therefore because of variety of the delivery methods used and 
the experience of transit agencies, it seems that the assumption of independence is not 
unrealistic.  
Due to the September 11, 2001 terrorist attack, the risk of security enhancement and 
changing the alignment to protect Federal lands may arise. Despite this, due to geographic 
dispersity of these projects, we could not identify any one regulation or incidence that would 
affect more than any one of these projects concurrently. Also, there is no evidence that any 
environmental regulation has affected the projects after completing the final design.   
The bond rating in each state is established based on that state’s creditor situation. However, 
as all four projects are more or less contemporary, bond rate would incur some correlation 
between costs of the five projects. Rail cars of all projects could have been imported from 

 
146 
 
overseas or Canada. Inflation also can create some degree of correlation between the 
projects as they are contemporary.  
Now, Table 7.6 is completed on the basis of the gathered information in accordance with 
the criteria explained in the PSG method (Sections 6.4.1 and 6.4.2). The correlation 
magnitudes are first identified, and then they are converted to the correlation coefficients 
using the proposed conversion threshold.  
Table 7.6: Finding the Correlation Coefficients among Projects in the Second Dataset 
Correlation 
Projects 
1, 2 
1, 3 
1, 4 
2, 3 
2, 4 
3, 4 
Correlation Magnitude 
(Qualification) 
Moderate 
Moderate 
Weak 
Moderate 
Weak 
Weak 
Correlation Coefficient 
(Quantification) 
0.55 
0.55 
0.25 
0.55 
0.25 
0.25 
 
The positive semidefiniteness of the estimated correlation matrix for the projects in the 
Second Dataset is checked in the next section.   
7.5.3 Positive Semidefinite Check for the Correlation Matrix of the Second Dataset 
We first need to calculate all eigenvalues of the correlation matrix estimated in the previous 
section to see if it has any negative eigenvalues. With the help of MATLAB programming 
language, this condition is checked first and if the matrix is not positive semidefinite, it is 
restored using @Risk algorithm explained in Chapter 5.  

 
147 
 
The correlation matrix of the projects in the Second Dataset estimated in the previous 
section is labeled
2
C  where projects with ID 1 to 4 are arranged from left to right and top to 
down which is: 













00
.1
25
.0
25
.0
25
.0
25
.0
00
.1
55
.0
55
.0
25
.0
55
.0
00
.1
55
.0
25
.0
55
.0
55
.0
00
.1
C 2
 
 
 
 
 
 
 
(7.3) 
Using MATLAB, four eigenvalues of matrix 
2
C  are calculated: 
2500
.2
8500
0
4500
.0
4500
.0
4
3
2
1




λ
;
.
λ
;
λ
;
λ
 
 
 
 
(7.4) 
Since all five eigenvalues of correlation matrix 
2
C  are positive, therefore the matrix is 
mathematically a true correlation matrix. 
7.6 
Methodology Assumed for Applying the Proposed Model  
Let us assume that the FTA is going to allocate budget for the projects in the First Dataset 
and wants to know the required portfolio budget increase. Also, they are interested in 
knowing the level of confidence  which is needed at the individual project level to insure 
that the portfolio budget will not overrun with a probability of more than 


1
. The model 
is fed by 
%
1.9


,
0879
.1


and 
2799
.1


 values calculated from the Historical 
Dataset in Section 7.3 and the required portfolio budget increase is calculated. 
We will multiply the original cost estimates at the FFGA by the calculated increase factor to 
get the adjusted cost estimate at the FFGA. This means that the FTA has used the model 
and increased the required total budget for the portfolio. Then cost overruns/ underruns in 

 
148 
 
the First Dataset are computed with respect to the adjusted cost estimates at the FFGA. 
These cost overruns/ underruns are served as the new observations to update the model. 
Updating the model results in new  
1
new

 and 
1
new

values. At this point, the model has been 
updated and is ready to be applied on the next dataset which is the Second Dataset. It is 
expected that the local agencies will improve the accuracy of the cost estimate over time. To 
incorporate this fact, we increase the cost estimate at the FFGA of the projects in the 
Second Dataset using the previously calculated increase factor. This reflects the 
improvement of the cost estimates by local agencies over the course of time. Once again, the 
model is applied on the adjusted cost estimates in the Second Dataset. The new increase 
factor is estimated. Similar to the process applied on the First Dataset, the model is updated 
using the cost overruns/ underruns in the Second Dataset and 
2
new

 and 
2
new

values are 
computed. These new values can be used on any prospective set of projects in the future.   
7.7 
Applying the Model Assuming Independence Cost Data 
In order to show model application, we apply the model to the collected data assuming 
independence between project costs. Later, this assumption is relaxed and we will consider 
cost correlations. 
7.7.1 
Applying the Model on the First Dataset (Independent Case) 
From Historical Dataset (Section 7.3), 
%
1.9


,
0879
.1


, and  
2799
.1


 were 
estimated. Using Eqs. (5.4) and (5.12), 
1875
.0


 is calculated. Then by the means of Eq. 

 
149 
 
(5.25), the corresponding s for different s are calculated. This is done for between 5% 
and 95% and the result is depicted in Figure 7.2.  
 
Figure 7.2: Probability of Budget Sufficiency in the Portfolio of Independent Projects 
)
( vs. 
in Individual Projects ()
 
Then, Eq. (5.17) is employed to compute the required percent increase in portfolio budget 
based on the  values found from Eq. (5.25). The required percent increase in budget is 
graphed versus and shown in Figure 7.3. In order to make sure that the results are 
accurate, we simulated the model to find increasing factor which is superimposed on the 
analytical curve found using the analytical approach. These two curves are very similar. 
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
η
γ
Probability of Budget Sufficiency 
in the Portfolio Vs. in Projects
First Dataset (Independent)
Analytical

 
150 
 
 
Figure 7.3: Required Percent Increase in Budget 
)
(
* B
B
 vs. Probability of Budget 
Sufficiency in the Portfolio of Independent Projects ()
 
For example, one can see in Figure 7.2 that if the FTA wants to have 85% confidence that 
allocated budget for the portfolio of projects will not fall short, it needs to consider a 
minimum level of confidence of 68.78%  69% in each individual project risk assessment. 
Also, Figure 7.3 illustrates that the FTA needs to increase the portfolio budget by 16.52% in 
order to have 85% level of confidence that the budget for the portfolio is sufficient.  
This finding is significant because none of the existing approaches that are used for 
probabilistic contingency analysis provides a method for calculating the percent increase 
over existing portfolio budget levels to achieve a certain confidence level in individual 
projects.  
In Table 7.7, a comparison is made between the actual cost overrun/underrun of projects in 
the First Dataset and cost overrun/underrun if the budget had been adjusted with the 
0.95
1.00
1.05
1.10
1.15
1.20
1.25
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
B*/B
γ
Required Percent Increase in Budget
First Dataset (Independent)
Analytical
Simulation

 
151 
 
estimated increasing factors. Even though the required budget increase in the portfolio can 
be distributed differently between the projects, we assume all will be increased proportionally 
by multiplying the required increase factor (

B
B*
1.1652) by the cost at the FFGA to 
reach Adjusted Cost at the FFGA.  
Table 7.7: Comparison of Cost Overrun/Underrun of Projects in the First Dataset Using the 
Proposed Model (Independent Assumption)  
Proj. 
ID 
Cost at 
the FFGA 
(in M$) 
Adj. Cost at 
the FFGA 
(in M$) 
Actual 
Cost 
(in M$) 
Cost Overrun/Underrun 
Actual 
Adjusted 
1 
$413.40 
$481.71 
$604.40 
46.20% 
25.47% 
2 
$675.40 
$786.99 
$715.30 
5.91% 
-9.11% 
3 
$314.90 
$366.93 
$349.40 
10.96% 
-4.78% 
4 
$313.60 
$365.42 
$316.80 
1.02% 
-13.30% 
5 
$433.90 
$505.59 
$456.00 
5.09% 
-9.81% 
Total 
$2,151.20 
$2,506.64 
$2,441.90 
13.84% 
-2.31% 
 
Table 7.7 shows that if the FTA had used the proposed model to allocate budget for five 
new projects, they could prevent occurring cost overrun of 13.84% with experiencing -
2.31% cost underrun. We expect by updating the model and considering the performance of 
the recently completed projects, we reach more accurate and optimized increasing factor for 
budgeting of future projects.  

 
152 
 
7.7.2 Updating the Model Using the First Dataset Projects (Independent Case) 
In this step, we use the information collected from completed projects in the First Dataset to 
update the model. The cost overruns/ underruns of five projects are considered new 
observations and serve to form the underlying distribution. The prior distribution is the 
normal distribution fitted on the histogram of 22 cost overruns/ underruns in the Historical 
Dataset with the mean of 8.79% and standard deviation of 0.2053.  
Considering 85% confidence as a reasonable level, we found that 16.52% increase on the 
total budget was required. By means of Bayesian updating and recent performance of the 
transit projects sponsored by the FTA, theand of the model can be updated.  
The prior distribution comes from the Historical Dataset as follows:  



















2
2053
.0
0879
.0
.
2
1
exp
)
2053
.0
(
2
1
)
2053
.0
,
0879
.0
(
)
(



N
f
 
 
(7.5) 
Five new observations are the cost overruns/underruns of projects with adjusted cost at the 
FFGA using 16.52% increasing factor shown in Table 7.7. Using Eq. (5.37), the joint 
likelihood function, the product of five individual normal PDFs, is calculated: 
)
0708
.0
,
0231
.0
(
)
5
1582
.0
,
5
0981
.0
1330
.0
0478
.0
0911
.0
2542
.0
(
,
...
)
(
1
















N
N
k
k
N
L
k




 
 
 
 
 
 
 
 
 
 
 
 
(7.6) 
To find the posterior distribution, Eq. (5.40) is used:  

 
153 
 






























0669
.0
)
0708
.0
(
)
2053
.0
(
)
0708
.0
(
2053
.0
)
(
)
(
.
%
13
.1
)
0708
.0
(
)
2053
.0
(
)
0708
.0
(
0879
.0
)
2053
.0
(
02313
.0
)
(
)
(
)
.(
)
.(
2
2
2
2
2
2
2
2
2
2
2
2
L
L
L
L
L












 
 
 
 
 
 
 
 
 
 
 
 
(7.7) 
Prior, likelihood, and posterior distributions of cost overrun/ underrun are shown in Figure 
7.4. 
 
Figure 7.4: The prior, likelihood, and posterior distributions of cost overrun/ underrun 
Using Projects in the First Dataset (Independent Assumption)
 
The posterior distribution parameters can now be used to update ,  and  parameters 
considering 
%
15

m
: 
0.0
1.0
2.0
3.0
4.0
5.0
6.0
7.0
-1.0
-0.8
-0.6
-0.4
-0.2
0.0
0.2
0.4
0.6
0.8
1.0
PDF Value
Cost Overrun/Underrun
Prior, Likelihood, and Posterior Curves 
First Dataset (Independent)  
Prior
Likelihood
Posterior

 
154 
 
1632
.1
85
.0
9887
.0
1
9887
.0
)
0113
.0
(
1
1
%
90
.1
)
0669
.0
0113
.0
15
.0
(
)
(
)
(
1
1
1
1


























m
m
Z
P
m
x
P
new
new
new
new







 
(7.8) 
Replacing the new values of parameters (
1
new

, 
1
new

 and 
1
new

) in the model, it is ready 
and updated to be applied to any future dataset. The updated model is applied to the Second 
Dataset in the next section.  
7.7.3 Applying the Model on the Second Dataset (Independent Case) 
Now, we assume that the FTA is budgeting for four new projects (with data provided in the 
Second Dataset, Table 7.5) and wants to establish the required portfolio budget increase and 
level of confidence  needed at the individual project level to insure that the portfolio 
budget will not overrun with a probability of more than 


1
.  
It should be noted that the projects in the Second Dataset have been estimated with 
procedures similar to those used for estimating projects in the First Dataset. In other words 
no improvement has been made in cost estimation for the Second Dataset compared with 
the First Dataset.  Therefore to reflect the impact of the model we increase the cost estimate 
at the FFGA of all projects in the Second Dataset by the increasing factor estimated in the 
previous section 16.52% 
)
1652
.1
(
*

B
B
.  
From updating process, we have 
%
90
.1


,
9887
.0


. By selecting 
%
15

m
 as the 
maximum expected underrun, 
1632
.1


(Eq. 7.8). Using Eqs. (5.4) and (5.12), 
0771
.0


 is calculated. Then by the means of Eq. (5.25), the correspondent s for 

 
155 
 
different s are computed. For  between 5% and 95%, is calculated and the result is 
graphed in Figure 7.5.  
 
Figure 7.5: Probability of Budget Sufficiency in the Portfolio of Independent Projects 
)
( vs. 
in Individual Projects ()
 
Then, Eq. (5.17) is employed to compute the required percent increase in portfolio budget 
based on the  values found from Eq. (5.25). The required percent increase in budget is 
shown versus values in Figure 7.6. Again to ensure the correctness of calculations, we 
simulated the model to find the increasing factor. Simulation results are superimposed on the 
analytical curve found from equations as described above. These two curves are almost 
identical. 
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
η
γ
Probability of Budget Sufficiency 
in Portfolio Vs. in Projects
Second Dataset (Independent)
Analytical

 
156 
 
 
Figure 7.6: Required Percent Increase in Budget 
)
(
* B
B
 vs. Probability of Budget 
Sufficiency in the Portfolio of Independent Projects ()
 
From Figure 7.5, one can see that if the FTA wants to have 85% confidence that allocated 
budget for portfolio of projects in the Second Dataset will not fall short, it needs to consider 
71.49%  71% level of confidence in each individual project risk assessment. Also, Figure 
7.6 illustrates that the FTA needs to increase the portfolio budget by 2.61% in order to have 
85% level of confidence that the budget for portfolio is sufficient. 
In Table 7.8, to verify the effectiveness of the model, a comparison is made between the 
actual cost overrun/underrun of projects in the Second Dataset and cost overrun/underrun 
if the budget had been adjusted with the estimated increasing factors. It was found that to 
have 85% confidence that the budget will not fall short, the FTA needs to increase the 
portfolio budget by 2.61%. Thus the adjusted cost at the FFGA using the proposed model 
will be higher than the original cost estimate by: 
1956
.1
0261
.1
1652
.1
.
.



Ind
Factor
Adj
 
 
 
 
 
 
 (7.9) 
0.90
0.95
1.00
1.05
1.10
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
B*/B
γ
Required Percent Increase in Budget
Second Dataset (Independent)
Analytical
Simulation

 
157 
 
Table 7.8: Comparison of Cost Overrun/Underrun of Projects in the Second Dataset Using 
the Proposed Model 
Proj. 
ID 
Cost at 
FFGA 
(in M$) 
Adj. Cost 
at FFGA  
(in M$) 
Actual 
Cost 
(in M$) 
Cost 
Overrun/Underrun 
Actual 
Adjusted 
1 
$482.6 
$577.02 
$419.61 
-13.05% 
-27.28% 
2 
$1,215.4 
$1,453.20 
$1,218.47 
0.25% 
-16.15% 
3 
$431.0 
$515.33 
$504.01 
16.94% 
-2.20% 
4 
$1,250 
$1,494.57 
$2,250.00 
80.00% 
50.54% 
Total 
$3,379.0 
$4,040.12 
$4,392.09 
21.04% 
1.23% 
 
Table 7.8 shows that if the FTA had used the proposed model to allocate budget for the 
four new projects, they could reduce the cost overrun from 21.04% to 1.23%. This result 
verifies how effective the model can be to control the cost overrun while is not 
overallocating the budget.  
7.7.4 Updating the Model Using the Second Dataset (Independent Case)  
Once again, we use the information of completed projects in the Second Dataset to update 
the model for the second time. The cost overruns/ underruns of the four projects are 
considered new observations and serve to form the underlying distribution.  
The prior distribution is the posterior distribution calculated in Section 7.7.2 as follows:  




















2
0669
.0
0110
.0
.
2
1
exp
)
0669
.0
(
2
1
)
0669
.0
,
0110
.0
(
)
(



N
f
 
 
(7.10) 

 
158 
 
New observations are the adjusted cost overruns/underruns of four independent projects in 
the Second Dataset given in Table 7.8. Using Eq. (5.37), the joint likelihood function, the 
product of four individual normal PDFs, is calculated: 
)
1722
.0
,
0123
.0
(
)
4
3444
.0
,
4
5054
.0
0220
.0
1615
.0
2728
.0
(
,
...
)
(
1
N
N
k
k
N
L
k



















 
(7.11) 
To find the posterior distribution, Eq. (5.40) is used:  






























0624
.0
)
1722
.0
(
)
0669
.0
(
)
1722
.0
(
0699
.0
)
(
)
(
.
%
79
.0
)
1722
.0
(
)
0669
.0
(
)
1722
.0
(
0110
.0
)
0669
.0
(
0123
.0
)
(
)
(
)
.(
)
.(
2
2
2
2
2
2
2
2
2
2
2
2
L
L
L
L
L












 
 
 
 
 
 
 
 
 
 
 
 
(7.12) 
Prior, likelihood, and posterior distributions of cost overrun/ underrun are shown in Figure 
7.7. 

 
 
Fig
It can
much
imple
 pa
2
2
new
new


The v
datase
gure 7.7: The
Usin
 
n be seen tha
h more simila
emented. The
arameters con
1
1
(
2
2







m
x
P

values of 
ne

et in the futu
e prior, likelih
ng Projects i
at in this seco
ar. This proc
e posterior d
nsidering m
0079
.0
(
1
(
)





Z
P
m
2
ew , 
2
new

 an
ure, assuming
hood, and po
n the Second
ond round of
cess fine tun
distribution p
%
15

: 
9921
.0
)
)






m


nd 
2
new

 mu
g independen
159 
osterior distr
d Dataset (In
f updating, th
nes the accur
parameters c
1
06
.0
15
.0
(
2 




new


ust be used t
nce between 
ributions of c
ndependent A
he prior and 
racy of estim
an now be u
85
.0
989
.0
.1
)
624
0079
.0
2 


m
new

to apply the m
cost estimate
cost overrun/
Assumption)
posterior dis
mates as mor
used to upda
1672
.1
5
9
%
14
.

model on an
es. 
 
/ underrun 
stributions ar
re updates ar
ate ,  an
 
(7.13)
ny prospectiv
re 
re 
nd 
ve 

 
160 
 
7.8 
Applying the Model Assuming Correlated Cost Data  
In this section, the application of the model is repeated on both the First and Second 
Datasets recognizing correlation between projects. The correlation coefficients were already 
estimated in Sections 7.4.2 and 7.5.2.  
7.8.1 
Applying the Model on the First Dataset (Correlated Case) 
From Historical Dataset (Section 7.3), we have 
%
1.9


,
0879
.1


, and  
2799
.1


. 
Using Eqs. (5.4) and (5.12), 
1875
.0


 is calculated. To use Eq. (5.25), we need to have the 
correlation coefficient matrix 
1
C  which was estimated before (Sections 7.4.2). Therefore by 
means of Eq. (5.25), the correspondent s for different s from 5% to 95% are calculated. 
The result is graphed in Figure 7.8.  
 

 
161 
 
 
Figure 7.8: Probability of Budget Sufficiency in a Portfolio of Correlated Projects () vs. in 
Individual Projects ()
 
Similar to independent projects, the estimated values of for different s are used in Eq. 
(5.17) to compute the required percent increase in portfolio budget. The required percent 
increase in budget is graphed versus  and shown in Figure 7.9. Again, we used simulation 
to check the accuracy of proposed analytical method. Required 
B
B*
 factor values found 
from simulation and proposed analytical method are superimposed and shown in Figure 7.9. 
It is clear that two curves are very similar. 
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
η
γ
Probability of Budget Sufficiency 
in the Portfolio Vs. in Projects
First Dataset (Correlated)
Analytical

 
162 
 
 
Figure 7.9: Required Percent Increase in Budget 
)
(
* B
B
 vs. Probability of Budget 
Sufficiency in the Portfolio of Correlated Projects ()
 
Reviewing Figure 7.8, one can see that if the FTA wants to have an 85% confidence that 
allocated budget for the portfolio of correlated projects will not fall short, it needs to 
consider 77.48%  77% level of confidence in each individual project risk assessment. This 
is about 8% more than what was calculated when projects were independent. Also, Figure 
7.9 illustrates that the FTA needs to increase the portfolio budget by 21.11% in order to 
have an 85% level of confidence that the budget for the portfolio is sufficient. This is 4.59% 
more than what was required for the independent case.  
Therefore, it is found that the results from correlated assumption are more conservative than 
independent case. In Table 7.9, the actual cost overruns/underruns of projects in the First 
Dataset and cost overruns/underruns if the budget had been adjusted with the estimated 
0.85
0.90
0.95
1.00
1.05
1.10
1.15
1.20
1.25
1.30
1.35
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
B*/B
γ
Required Percent Increase in Budget
First Dataset (Correlated)
Analytical
Simulation

 
163 
 
increasing factor are compared. By increasing the cost estimates at the FFGA by the required 
increasing factor of 21.11% 
)
2111
.1
(
*

B
B
, we reach Adjusted Cost at the FFGA.  
Table 7.9: Comparison of Cost Overrun/Underrun of Projects in the First Dataset Using the 
Proposed Model (Correlated Projects) 
Proj. 
ID 
Cost at 
the FFGA 
(in M$) 
Adj. Cost at 
the FFGA 
(in M$) 
Actual 
Cost 
(in M$) 
Cost 
Overrun/Underrun 
Actual 
Adjusted 
1 
$413.40 
$499.83 
$604.40 
46.20% 
20.72% 
2 
$675.40 
$816.61 
$715.30 
5.91% 
-12.55% 
3 
$314.90 
$380.74 
$349.40 
10.96% 
-8.38% 
4 
$313.60 
$379.17 
$316.80 
1.02% 
-16.58% 
5 
$433.90 
$524.6 
$456.00 
5.09% 
-13.22% 
Total 
$2,151.20 
$2,605.22 
$2,441.90 
13.84% 
-6.00% 
 
Table 7.9 shows if the FTA had used the proposed model to allocate budget for five new 
projects, they could have ended up with an average 6.00% cost underrun instead of 13.84% 
cost overrun. It is expected that by updating the model and considering the performance of 
the recently completed projects, we can reach more accurate and optimal increasing factor 
for budgeting of future projects.  
7.8.2 Updating the Model Using the First Dataset (Correlated Case) 
Here the estimated correlation matrix between the projects is incorporated in the updating 
analysis. It should be noted that the Eq. (5.40) (to analytically calculate the mean and 
standard deviation of the posterior distribution) is not valid anymore because of dependency 

 
164 
 
among the projects. Therefore the only feasible approach is the numerical procedure. The 
prior distribution from the Historical Dataset is the same as given in Eq. (7.5).  Five new 
observations are the cost overruns/underruns of projects with adjusted cost at the FFGA 
using 21.11% increasing factor with the average of -6.00% and standard deviation of 0.1522.   
First, we need to find the variance-covariance matrix 
1
V  correspondent with correlation 
matrix 
1
C which is positive semidefinite. We know that: 





















































0.0232
0.0128
0.0127
0.0127
0.0058
0.0127
0.0232
0.0127
0.0127
0.0058
0.0127
0.0127
0.0232
0.0127
0.0058
0.0127
0.0127
0.0127
0.0232
0.0058
0.0058
0.0058
0.0058
0.0058
 
0.0232

00
.1
55
.0
55
.0
55
.0
25
.0
55
.0
00
.1
55
.0
55
.0
25
.0
55
.0
55
.0
00
.1
55
.0
25
.0
55
.0
55
.0
55
.0
00
.1
25
.0
25
.0
25
.0
25
.0
25
.0
00
.1
1522
.0
0
0
0
0
0
1522
.0
0
0
0
0
0
1522
.0
0
0
0
0
0
1522
.0
0
0
0
0
0
1522
.0
σ.
σ.C
V
1
1
  
 
 
 
 
 
 
 
 
 
 
 (7.14) 
Where σ  is a diagonal matrix whose entries are the standard deviation of cost overrun/ 
underrun of five observed projects.  
Using Eq. (5.41) and MATLAB, the likelihood values for the various values of  ranging 
from -99.99% to 200% with the pace of 0.001 are calculated. The posterior is computed 
using Eq. (5.44) and the numerical method explained previously, in an Excel spreadsheet. 
Using Eqs. (5.45) and (5.46), the mean and standard deviation of the posterior distribution 
are calculated: 

 
165 
 





0965
.0
%
30
.1


 
 
 
 
 
 
 
 
 
(7.15) 
Prior, likelihood, and posterior distributions of cost overrun/ underrun are shown in Figure 
7.10.  
 
Figure 7.10: The prior, likelihood, and posterior distributions of cost overrun/ underrun 
Using Projects in the First Dataset (Correlated Assumption)
 
The posterior distribution parameters can now be used to update ,  and  parameters 
assuming 
%
15

m
: 
1918
.1
85
.0
013
.1
1
0130
.1
0130
.0
1
1
%
55
.4
)
0965
.0
0130
.0
15
.0
(
)
(
)
(
1
1
1

























m
m
Z
P
m
x
P
new
new
new
new







  
(7.16) 
Replacing the new values of parameters in the model, it is ready and updated to be applied 
on any future dataset to estimate the new and 
B
B*
. 
0.0
1.0
2.0
3.0
4.0
5.0
-1.0
-0.8
-0.6
-0.4
-0.2
0.0
0.2
0.4
0.6
0.8
1.0
PDF Value
Cost Overrun/Underrun
Prior, Likelihood, and Posterior Curves 
First Dataset (Correlated)  
Prior
Likelihood
Posterior

 
166 
 
7.8.3 Applying the Model on the Second Dataset (Correlated Case) 
From updating process (Section 7.8.2), we have
%
55
.4


,
0130
.1


. By selecting 
%
15

m
 as the maximum expected underrun, 
1918
.1


.  
Like Section 7.7.3 where the projects assumed to be independent, it should be noted that the 
projects in the Second Dataset have been estimated with the similar manner in the past. 
Therefore to reflect the impact of the model and improvement in the cost estimate, we 
increase the cost estimate at the FFGA of all projects in the Second Dataset by increasing 
factor 21.11%
)
2111
.1
(
*

B
B
estimated in Section 7.8.1.  
Correlation coefficients are added to the model using correlation matrix
2
C . Using Eqs. (5.4) 
and (5.12), 
1078
.0


 is calculated. Then by the means of Eq. (5.25), the correspondent 
s for different s are computed. For  between 5% and 95%, is calculated and the result 
is graphed in Figure 7.11.  
 

 
167 
 
 
Figure 7.11: Probability of Budget Sufficiency in the Portfolio of Correlated Projects () vs. 
in Individual Projects ()
 
Like independent projects, the estimated values of for different s are used in Eq. (5.17) 
to compute the required percent increase in portfolio budget. The required percent increase 
in budget is shown versus values in Figure 7.12.  
 
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
η
γ
Probability of Budget Sufficiency 
in the Portfolio Vs. in Projects
Second Dataset (Correlated)
Analytical

 
168 
 
 
Figure 7.12: Required Percent Increase in Budget 
)
(
* B
B
 vs. Probability of Budget 
Sufficiency in the Portfolio of Correlated Projects ()
 
Again we use simulation to check the accuracy of proposed analytical method. Required 
increasing factor curves found from simulation and proposed analytical method are 
superimposed in Figure 7.12. The two curves are very close together. This comparison 
suggests that the normality assumption is not adding significant error to the analytical model. 
Reviewing Figure 7.11, one can see that if the FTA desires an 85% confidence that allocated 
budget for portfolio of the correlated projects will not fall short, it needs to consider 77.48% 
 77% level of confidence in each individual project’s risk assessment. This is about 6% 
more than when we assumed that the projects are independent. Also, Figure 7.12 illustrates 
that the FTA needs to increase the portfolio budget by 8.32% in order to have 85% level of 
confidence that the budget for portfolio is sufficient. This is 5.71% more than required 
increasing factor for independent projects in the portfolio of the Second Dataset. 
0.85
0.90
0.95
1.00
1.05
1.10
1.15
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
B*/B
γ
Required Percent Increase in Budget
Second Dataset (Correlated)
Analytical
Simulation

 
169 
 
In Table 7.10, to verify the effectiveness of the model, a comparison is made between the 
actual cost overrun/underrun of projects in the Second Dataset and cost overrun/underrun 
if the budget had been adjusted with the estimated increasing factors. It was found that to 
have 85% confidence that the budget will not fall short, the FTA needs to increase the 
portfolio budget by 8.32%. Thus the adjusted cost at the FFGA using the proposed model 
will be higher than the original cost estimate by: 
3118
.1
0832
.1
2111
.1
.
.



Cor
Factor
Adj
.  
 
 
 
 
 
(7.17) 
Table 7.10: Comparison of Cost Overrun/Underrun of Projects in the Second Dataset 
Using the Proposed Model (Correlated Projects) 
Proj. 
ID 
Cost at 
FFGA 
(in M$) 
Adj. Cost 
at FFGA 
(in M$) 
Actual 
Cost 
(in M$) 
Cost 
Overrun/Underrun 
Actual 
Adjusted  
1 
$482.6 
$633.08 
$419.61 
-13.05% 
-33.72% 
2 
$1,215.4 
$1,594.38 
$1,218.47 
0.25% 
-23.58% 
3 
$431.0 
$565.39 
$504.01 
16.94% 
-10.86% 
4 
$1,250 
$1,639.77 
$2,250.00 
80.00% 
37.21% 
Total 
$3,379.0 
$4,432.62 
$4,392.09 
21.04% 
-7.73% 
 
Table 7.10 shows if the FTA had used the proposed model to allocate budget for four new 
projects, they could have 7.73% underrun in average instead of experiencing 21.04% 
overrun. This shows the effectiveness of the model to keep the portfolio within budget. 

 
170 
 
7.8.4 Updating the Model Using the Second Dataset (Correlated Case) 
For the correlated approach, the prior distribution is the posterior distribution calculated in 
Section 7.8.2 as follows:  



















2
0965
.0
0130
.0
.
2
1
exp
)
0965
.0
(
2
1
)
0965
.0
,
0130
.0
(
)
(



N
f
 
 
(7.18) 
New observations are the adjusted cost overruns/underruns of four correlated projects in 
the Second Dataset given in Table 7.10. First, we need to find the variance-covariance matrix 
2
V  correspondent with correlation matrix 
2
C . We know that: 









































0.0985
0.0246
0.0246
0.0246
0.0246
0.0985
0.0542
0.0542
0.0246
0.0542
0.0985
0.0542
0.0246
0.0542
0.0542
0.0985
0.3139
0
0.3139
0
0.3139
0
0.3139

00
.1
25
.0
25
.0
25
.0
25
.0
00
.1
55
.0
55
.0
25
.0
55
.0
00
.1
55
.0
25
.0
55
.0
55
.0
00
.1
0
0
0
0
0
0
0
0
0
σ.
σ.C
V
2
2
   
  (7.19) 
Where σ  is a diagonal matrix whose entries are the standard deviation of cost overruns/ 
underruns of the four observed projects.  
Using Eq. (5.41) and MATLAB, the likelihood values for the various values of  ranging 
from -99.99% to 200% with the pace of 0.001 are calculated. The posterior is computed 
using Eq. (5.44) and the numerical method explained previously, in an Excel spreadsheet. 
Using Eqs. (5.45) and (5.46), the mean and standard deviation of the posterior distribution 
are calculated: 

 
171 
 





0888
.0
%
10
.1


 
 
 
 
 
 
 
 
 
(7.20) 
Prior, likelihood, and posterior distributions of cost overrun/ underrun are shown in Figure 
7.13.  
 
Figure 7.13: The prior, likelihood, and posterior distributions of cost overrun/ underrun 
Using Projects in the Second Dataset (Correlated Assumption)
 
The posterior distribution parameters can now be used to update ,  and  parameters 
considering 
%
15

m
: 
1894
.1
85
.0
0110
.1
1
0110
.1
0110
.0
1
1
%
50
.3
)
0888
.0
0110
.0
15
.0
(
)
(
)
(
2
2
2
2

























m
m
Z
P
m
x
P
new
new
new
new







 
(7.21) 
0.0
1.0
2.0
3.0
4.0
5.0
-1.0
-0.8
-0.6
-0.4
-0.2
0.0
0.2
0.4
0.6
0.8
1.0
PDF Value
Cost Overrun/Underrun
Prior, Likelihood, and Posterior Curves
Second Dataset (Correlated)  
Prior
Likelihood
Posterior

 
172 
 
The values of 
2
new

, 
2
new

 and 
2
new

 must be used to apply the model on any prospective 
dataset whose projects are correlated. 
7.9 
Sensitivity Analysis for Cost Correlation Impact on Required Percent Increase 
in Budget 
In this section, we carry out a sensitivity analysis (SA) to evaluate the contribution of cost 
correlation to the variability of required percent increase in budget (
B
B*
). To this end, we 
perform a screening method in which the cost correlation matrices are changed and the 
output of the model is monitored.  
Conducting the SA requires a set of possible cost correlation matrices. In the previous 
sections, we estimated the correlation between project costs of the First Dataset (
1
C ) and 
the Second Dataset (
2
C ). To create the sets of possible inputs, we need to develop new 
correlation matrices. Therefore, we multiply each pairwise correlation in matrix 
1
C  and 
2
C  to a 
set of multipliers. These multipliers must be selected in a manner that the new generated 
correlations are not greater than 1.0.  
Considering the correlation coefficients in matrices 
1
C  and 
2
C , we selected the set of 
multipliers as {1.5, 1.0, 0.5, 0}. It is obvious that the multiplier of zero to all pairwise 
correlations in matrices 
1
C  and 
2
C  results in an identity matrix which is the previously 
calculated independent case. Moreover, the multiplier of 1.0 makes no changes and it is again 
the original correlated case. Thus, two new scenarios are added with multiplier of 0.5 and 
1.5. The newly generated matrices are checked to be positive semidefinite matrices. The 

 
173 
 
control showed that the matrices are indeed positive semidefinite and no transformation is 
required. All steps explained in Section 7.8 is repeated once with new matrices 
1
C
5.0

 and 
2
C
5.0

 and once with 
1
C
5.1

 and 
2
C
5.1

. The required percent increase in budget 
)
(
* B
B
 for the First Dataset and the Second Dataset is estimated and depicted in Figures 
7.14 and 7.15 for all four scenarios.  
 
Figure 7.14: Required Percent Increase in Budget for the First Dataset Considering Four 
Different Correlation Matrices 
 
0.85
0.90
0.95
1.00
1.05
1.10
1.15
1.20
1.25
1.30
1.35
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
B*/B
γ
Required Percent Increase in Budget
First Dataset 
1.5 X Correlation
1.0 X Correlation
0.5 X Correlation
0 X Correlation (Independent)

 
174 
 
 
Figure 7.15:  Required Percent Increase in Budget for the Second Dataset Considering Four 
Different Correlation Matrices 
Figures 7.14 and 7.15 show the effect of various correlations on the required percent budget 
increase. For instance, for the First Dataset if the sponsor wants to have 85% budget 
sufficiency confidence and ignore the correlation among the project costs, the model shows 
16.52% required budget increase, while considering the 
1
C
5.1

 correlation matrix results in 
a 22.85% required budget increase. This is 6.33% difference which is translated into $136 
million extra budget. This reveals the importance of recognition of correlation in the model. 
Therefore, in order to allocate as accurate as possible contingency budget for a portfolio, the 
precise estimation of correlation between costs of projects is imperative.  
0.85
0.90
0.95
1.00
1.05
1.10
1.15
1.20
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
B*/B
γ
Required Percent Increase in Budget
Second Dataset 
1.5 X Correlation
1.0 X Correlation
0.5 X Correlation
0 X Correlation (Independent)

 
175 
 
7.10 
Analysis of Results 
In this chapter, a comprehensive numerical example was presented to illustrate the 
application and effectiveness of the proposed model to decrease the cost overrun in the 
portfolio of projects over time. To this end, three different datasets of transit projects were 
chosen: 1. Historical Dataset comprised of 22 projects finished before 2004 to find the initial 
and to prepare the model for applying on any prospective dataset; 2. First Dataset 
including five projects completed in 2004 to apply the model for the first time and updating 
the model; 3. Second Dataset including four projects completed in 2005 and 2006 to apply 
and update the model for the second time.  
To apply the model, two different approaches were considered: 1. we assumed independence 
among projects’ costs; 2. the correlations between projects in applying and updating were 
recognized and estimated using the Proposed Structured Guideline (PSG). The results from 
applying the proposed model on aforementioned datasets are summarized in Table 7.11. 
Column “Actual Cost Overrun/ Underrun” depicts the actual mean and standard deviation 
of cost overruns/ underruns in three datasets. Column “Adjusted Cost Overrun/ Underrun” 
shows the mean and standard deviation of cost overrun/ underrun if the model had been 
applied to the data. The last Column “Updated Cost Overrun/Underrun” presents the mean 
and standard deviation of cost overruns/underruns after using the Bayesian updating which 
will prepare the model for the next application.  
 
 
 

 
176 
 
Table 7.11: Summary of the Results from Applying the Proposed Model on Transit Projects 
Data 
Approach 
 
 
For 
%
85


 
Actual Cost 
Overrun/ 
Underrun 
Adjusted Cost 
Overrun/ 
Underrun 
Updated Cost 
Overrun/ 
Underrun 
B
B*
 
 
 
 
.
Adj

 
.
Adj

 
 
 
Historical 
Dataset 
N/A 
N/A 
N/A 
N/A 
N/A
8.79% 
0.2053 
N/A 
N/A 
N/A 
N/A 
First 
Dataset 
Ind. 
9.10% 
1.0879 
1.1652 
69%
13.84% 
0.1844 
-2.31% 
0.1582 
-1.13% 
0.0669 
Cor. 
9.10% 
1.0879 
1.2111 
77%
13.84% 
0.1844 
-6.00% 
0.1522 
1.30% 
0.0965 
Second 
Dataset 
Ind. 
1.90% 
0.9887 
1.0261 
71%
21.04% 
0.4118 
1.23% 
0.3444 
-0.79% 
0.0624 
Cor. 
4.55% 
1.0130 
1.0832 
77%
21.04% 
0.4118 
-7.73% 
0.3139 
1.10% 
0.0888 
Prospective 
Dataset 
Ind. 
1.14% 
0.9921 
 
 
 
 
 
 
 
 
Cor. 
3.50% 
1.0110 
 
 
 
 
 
 
 
 
 
One can see that the required adjustment in the value of factor 
B
B*
and cost overrun/ 
underrun are diminished after each updating. For example, with the independent approach 
B
B*
(for 85% confidence) was decreased from 1.1652 for the First Dataset to 1.0261 for 
the Second Dataset. Also, in the First Dataset the model was able to decrease the cost 
overrun from 13.84% to -2.31%. This improvement continues in the Second Dataset where 
the cost overrun goes down from 21.04% to 1.23%. Moreover, the model shows that in 
order to have 85% confidence that the portfolio budget for the First Dataset is sufficient, 
each individual project in the portfolio needs to be assessed with 
%
69


 where this is 
%
71


 for the Second Dataset.  

 
177 
 
With the correlated approach, for the First Dataset they could have ended up with a 6.00% 
cost underrun instead of the actual 13.85% cost overrun by assigning increasing factor of 
1.2111 to the budget and individual risk assessment confidence level of 77%. For the Second 
Dataset, the model could have brought down the cost overrun of 21.04% to 7.73% cost 
underrun by assigning increasing factor of 1.0832 and individual risk assessment confidence 
level of 77%. 
In summary, Table 7.11 illustrates the improvement that can be gained through applying this 
model over a period of time to control cost overrun and provide adequate budget in the 
project portfolio. One can notice that in this example, the independent approach is more 
successful in controlling cost overrun and allocating optimized contingency than the 
correlated approach. However, it may not be the case for all situations. Therefore, in order 
to be realistic and more conservative, the consideration of correlation between project costs 
is encouraged.  
7.11 
Summary 
This chapter demonstrates the application and success of the model through a numerical 
example of transit projects. First a general procedure that an owner agency such as the FTA 
should take to apply the proposed model in their budget development procedure was 
elucidated. To explain the application and verify the effectiveness of the model, three 
different datasets of transit projects were introduced called: Historical (including 22 transit 
projects), First (including five transit projects), and Second Datasets (including four transit 
projects). Historical Dataset was used to estimate the initial parameters of the model. Then 
the First and Second Datasets were employed for applying and updating the model 

 
178 
 
considering two different assumptions: 1. assuming independent projects, and 2. assuming 
correlation among the projects’ costs in each dataset were recognized. A brief description of 
projects in the First and Second Datasets was given and pairwise correlation coefficients of 
projects were estimated. The outcomes for two different approaches were summarized in 
Table 7.11 which depicts the success of the model in predicting and controlling cost overrun 
over time.  

 
179 
 
CHAPTER 8: CONCLUSION 
8.1 
Summary of the Completed Work 
Most large infrastructure projects have been suffering from cost overruns. A method has 
been established to calculate an optimum contingency budget to protect the project against 
cost overrun, while not tying an excessive budget that can be used on other projects. This 
becomes more important when an agency is dealing with a portfolio of projects. Even 
though all suggested methods in this dissertation are applicable for any agency, our emphasis 
has been mostly on transit projects since they are usually costly (several hundred million 
dollars), complex and have been plagued by cost overrun.  
In an attempt to identify the drawbacks in the current methods of contingency allocation in 
transit agencies, the current methods used in the U.S. (Top-down method) and the U.K. 
(Optimism Bias Uplifts method) were discussed and compared in Chapter 4. The analysis 
revealed that the way that projects are ranged in Top-down model is conservative, resulting 
in tying large sums of money to a project which can be used for other projects. The 
Optimism Bias Uplifts approach used in the U.K. adds a contingency budget to the base cost 
of projects by only considering the historical performance of that type of projects (i.e. transit, 
road, etc.). This means the unique features and characteristics of each project do not have 
any impact on contingency allocation. Furthermore, the historical data is used in a statistical 
sense, requiring large datasets. The U.K. method is based on only 46 transit projects 

 
180 
 
(including metro, light rail, bus lines, and conventional rail projects). In reality, due to the 
wide differences between transit projects, very few of these projects can be considered 
similar and hence following the same statistical distribution.  
The shortcomings of the abovementioned approaches was the motivation to develop a 
probabilistic method that not only considers the historical performance of typical projects 
but also brings into consideration the unique feature of the projects by individual project risk 
assessment. The proposed model uses a hybrid normal distribution and utilizes historical 
data to assist the agencies to find the optimum required increase in the portfolio budget 
based on the desired confidence level. It is a dynamic model that is updated when new 
information regarding newly completed projects becomes available. It also considers the 
correlation among costs of projects in order to estimate more precise contingencies. Another 
advantage of the model is that it enables the agency to identify the required confidence level 
for risk assessment in individual project level with respect to the desired confidence level for 
portfolio of projects. 
The advantages of the proposed model for allocation of contingency for portfolio of 
projects can be summarized as:  
1.  Considering the historical performance of typical projects; 
2. Allowing for the unique features of each project through individual risk assessment 
of projects; 
3. Defining the required confidence level for risk assessment of individual project with 
respect to the desired confidence level for sufficiency of portfolio budget; 
4. Flexibility for updating using a Bayesian approach when new projects are completed 
and new performance data becomes available; 

 
181 
 
5. Accommodating the correlation among project costs in order to obtain more 
accurate results; 
6. The approach is a completely analytical approach not based on simulation; therefore 
closed form solutions are developed that will eliminate the errors resulting from the 
use of simulation modeling; further, there is no need for investing in Monte Carlo 
simulation software packages. Furthermore, errors inherent in simulation approaches 
such as nonconvergence of results will be eliminated.   
The performance of the model was investigated using cost data from 32 transit projects 
sponsored by the Federal Transit Administration (FTA) divided into three sets. The 
Historical Dataset was used for initializing of the model and estimating the primary 
parameters of the model. Then, the model was applied to the First and Second Datasets. To 
identify the impact of correlation, the model is first applied to the datasets assuming 
statistically independent projects. Then, the correlation between projects in each dataset is 
recognized and estimated using the PSG method developed in this research and described in 
Chapter 6.    
Even though in these cases the independent approach showed better success in controlling 
cost overrun and allocating optimized contingency, it may not be the case for all situations. 
Therefore, we encourage agencies to consider the correlation between projects in order to be 
realistic and more conservative.  
8.2 
Limitations of the Proposed Model 
To develop the proposed model, we made some assumptions for developing a complete 
analytical model. These assumptions can be summarized as follows: 

 
182 
 
1. We assumed that the population of cost overruns/underruns has a normal 
distribution. While this assumption may not be very accurate as projects are not fully 
identical, this is required to develop an analytical model. Using this assumption, we 
employed a hybrid normal distribution to range the cost of projects; 
2. As part of the model development, we added up the cost of projects in the portfolio 
and calculated mean of total cost 
T
 and standard deviation 
T
. Then, we assumed 
a normal distribution for the total cost where the projects can be correlated. 
However, we explained, since in reality all projects in a portfolio may not be strongly 
correlated, this assumption will not cause significant error to the model. This was 
confirmed with the given numerical example in Chapter 7. For instance, to calculate 
the required percent increase in budget for the First Dataset, we simulated the model 
and superimposed the results on the analytical curve (Figures 7.3 and 7.9). It was 
found that both curves were very similar. Since the simulation considers the exact 
shape of the total cost distribution, the similarity of the results justifies the use of a 
normal distribution for modeling total cost of the portfolio.   
Other than aforementioned assumptions, we can identify two more limitations in the 
application of the model as follows:  
1. The model needs historical data to be trained first, and then is applied to a prospective 
portfolio of projects. To obtain the immediate and precise results from the model, 
having the historical data is indispensable. However, in the absence of that information, 
the model is still utilizable. Let us consider that there is an agency with no former 
knowledge about the cost performance of their projects. However, they have recently 
completed a few projects. These projects can be used as new observations in the 

 
183 
 
Bayesian updating section of the proposed model. The agency can use a defuse 
distribution as the prior distribution of cost overruns/underruns, calculate the posterior 
distribution and continue the procedure thereafter; 
2. Implementing the model procedure in agencies’ budget development process could be a 
challenging task. It may not be an easy task to convince an agency to add the proposed 
model in their budget development procedures.  
8.3 
Recommended Works for Future 
We suggest the current effort can be expanded in the following areas in the future: 
1. All the discussions in this research were limited to the budget contingency. Therefore 
it would be a valuable effort to develop a similar method for schedule contingency 
allocation for a portfolio of projects where the relationships between the projects are 
specified; 
2. The distribution assumed for the cost of project in the model is a hybrid normal 
distribution. It is suggested to evaluate other distributions such as lognormal. The 
challenge here is to keep the model completely analytical; in order to keep the model 
analytical, the choice of distributions become limited. Of course using simulation 
modeling other distributions can also be used; 
3. Even though an Excel spreadsheet in conjunction with MATLAB was created for 
applying the model to the numerical example presented in Chapter 7, development 
of a user friendly software program which can accommodate any number of projects 
without need of MATLAB is suggested. In this way, an agency can use the model 
easily and more conveniently; 

 
184 
 
4.  In Appendix B, a mathematical method is presented for estimating the value of 
Pearson correlation coefficient between project costs. A comparison between this 
method and the proposed suggested guideline (PSG) in Chapter 6 for the same 
projects by different experts is suggested.  
The PSG provides a list of 12 common risk factors that can potentially affect any 
pair of project. An expert or a panel of experts should first identify the common risk 
factors affecting both projects under consideration from the list. After that, using a 
set of suggested guidelines and thresholds, the correlation coefficient is estimated. 
On the other hand, the proposed mathematical method (Appendix B) is an analytical 
tool which needs the project’s risk register. For any pair of projects, the common risk 
factors in their risk registers are identified. Then, using the computational approach 
suggested in Appendix B the correlation coefficient between project costs is 
calculated. Comparison of correlation coefficients calculated with these two 
approaches can help identify estimation problems and may lead to development of 
simple practical approaches for estimating correlation coefficients accurately;  
5. In Chapter 3, we discussed using different methods for estimating cost escalation 
and employing various cost escalation indices by agencies. It was shown that the 
inconsistency in use of these methods and indices result in reporting of dissimilar 
project costs for the same project in different studies. Therefore, the importance of 
improving the current budget development guideline for agencies such as the FTA is 
recognized.  
 
   

 
185 
 
APPENDIX A: REFERENCES 
1. 
Ang, A., and Tang, W. (2007). Probability Concepts in Engineering: Emphasis on Applications in 
Civil and Environmental Engineering, 2nd Edition, John Wiley and Sons, Inc., Hoboken, NJ.  
2. 
Association for the Advancement of Cost Engineering (AACE) International. (2010a). 
“Cost Engineering Terminology.” AACE Recommended Practice No. 10S-90, TCM 
Framework: General Reference, March 5.  
3. 
Association for the Advancement of Cost Engineering (AACE) International. (2010b). 
“Escalation Estimating Principles and Methods Using Indices.” AACE Recommended 
Practice No. 58R-10, TCM Framework: 7.6-Risk Management, November 22.  
4. 
Association for the Advancement of Cost Engineering (AACE) International. (2009a). 
“Risk Analysis and Contingency Determination Using Expected Value.” AACE 
Recommended Practice No. 44R-08, TCM Framework: 7.6- Risk Management, January 
26. 
5. 
Association for the Advancement of Cost Engineering (AACE) International. (2009b). 
“Risk Analysis and Contingency Determination Using Parametric Estimating.” AACE 
Recommended Practice No. 42R-08, TCM Framework: 7.6- Risk Management, January 
26. 

 
186 
 
6. 
Association for the Advancement of Cost Engineering (AACE) International. (2008 a). 
“Contingency Estimating- General Principles.” AACE Recommended Practice No. 
40R-08, TCM Framework: 7.6, June 25. 
7. 
Association for the Advancement of Cost Engineering (AACE) International. (2008 b). 
“Risk Analysis and Contingency Determination Using Range Estimating.” AACE 
Recommended Practice No. 41R-08, TCM Framework: 7.6- Risk Management, October 
27. 
8. 
Baccarini, D. (2006). “The Maturing Concept of Estimating Project Cost Contingency- 
A Review.” 31st Australasian University Building Educators Association Conference 
(AUBEA 2006), Curtis University of Technology, Australia. 
9. 
Baccarini, D. (2005). “Understanding Project Cost Contingency – A Survey.” COBRA, 
International Construction Conference, Brisbane, Australia, July.  
10. Bakhshi, P. and Touran, A. (2009). “Comparison of Current Probabilistic Approaches 
for Budget Estimating for Transportation Projects.” Proceedings of 7th International 
Probabilistic Workshop, 25-26 November, Delft, The Netherlands.  
11. Bell, W. (1975). Matrices for Scientists and Engineers, Van Nostrand Reinhold Company, 
New York, NY.  
12. Berman, A. and Shaked-Monderer, N. (2003). Completely Positive Matrices, World 
Scientific Publishing Company, River Edge, NJ.  
13. Blanchflower, D. G., and Oswald, A. J. (1990). “The Wage Curve.” The Scandinavian 
Journal of Economics, Vol. 92, N0. 2, 215-235, Jun.  

 
187 
 
14. Bolstad, W. (2007). Introduction to Bayesian Statistics, 2nd Edition, John Wiley and Sons, 
Inc, Hoboken, NJ. 
15. Booz Allen Hamilton Inc. (2005). “Managing Capital Costs of Major Federally Funded 
Public Transportation Projects”. web-only Document 31, Transit Cooperative Research 
Program (TCRP), Washington, D.C. 
16. Buckley, J. and Eslami, E. (2002). An Introduction to Fuzzy Logic and Fuzzy Sets, Physica-
Verlag, Heidelberg, New York.   
17. Chan, A., and Chan, D., and Yeung, J. (2009). “Overview of the Application of Fuzzy 
Techniques in Construction Management Research.” Journal of Construction Engineering 
and Management, ASCE, Vol. 135, No. 11, 1241-1252, November. 
18. Chan, A., Yung, K., Lam, P., Tam, C., Cheung, S. (2001). “Application of Delphi 
Method in Selection of Procurement Systems for Construction Projects.” Journal of 
Construction Management and Economics, Vol. 19, Issue 7, 699-718. 
19. Chau, K. (1995). “Monte Carlo Simulation of Construction Costs Using Subjective 
Data.” Journal of Construction Management and Economics, Vol. 13, Issue 5, 369-383. 
20. Chen, D. and Hartman, F. T. (2000). “A Neural Network Approach to Risk Assessment 
and Contingency Allocation.” Association for the Advancement of Cost Engineering 
(AACE) International Transaction, Risk.07.  
21. Cho, S. (2006). “An Exploratory Project Expert System for Eliciting Correlation 
Coefficient and Sequential Updating of Duration Estimation.” Journal of Expert Systems 
with Applications, Vol. 30, Issue 4, 553-560, May. 

 
188 
 
22. Choi, H., Cho, H., and Seo, J. (2004.) “Risk Assessment Methodology for Underground 
Construction Projects.” Journal of Construction Engineering and Management, ASCE, Vol. 
130, No. 2, 258-272, April. 
23. Cohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences, 2nd Edition, Lawrence 
Erlbaum Associates, Hillsdale, NJ.  
24. Construction Industry Research & Information Association (CIRIA). (1996). Control of 
Risk: A Guide to the Systematic Management of Risk from Construction, Special Publication 125, 
CIRIA, London, U.K.  
25. Creedy, G., Skitmore, M., and Wong, J. (2010). “Evaluation of Risk Factors Leading to 
Cost Overrun in Delivery of Highway Construction Projects.” Journal of Construction 
Engineering and Management, ASCE, Vol. 136, No. 5, 528-537, May. 
26. Curran, M. (1989). “Range Estimating: Measuring Uncertainty and Reasoning with 
Risk.” Cost Engineering, Vol. 31, No. 3, 18-26.  
27. Davis, S. and Peng. Y. (2010). “Mathematical Models of Contingency for Errors of 
Omission.” Association for the Advancement of Cost Engineering (AACE) 
International Transaction, EST. 12.  
28. Dey, P., Tabucanon, M. T., and Ogunlana, S. O. (1994). “Planning for Project Control 
through Risk Analysis: a Petroleum Pipeline-Laying Project.” International Journal of Project 
Management, Vol. 12, Issue 1, 23-33.  

 
189 
 
29. Diekmann, J. and Featherman, D. (1998). “Assessing Cost Uncertainty: Lessons from 
Environmental Restoration Projects.” Journal of Construction Engineering and Management, 
ASCE, Vol. 124, No. 6, 445-451, November/December. 
30. Dysert, L. (2006). “Is Estimate Accuracy an Oxymoron?” Association for the 
Advancement of Cost Engineering (AACE) International Transaction, EST. 01.  
31. Engineering News-Record. (2009). “What Drives ENR’s Cost Indexes.” March 18, 
WWW 
document] 
URL 
http://enr.ecnext.com/coms2/article_bmfi090318ENRCostIndex   (Visited 2011, 
January 13).  
32. Federal Transit Administration (FTA) (2010a). “Annual Report on New Starts.” [WWW 
document] 
URL 
http://www.fta.dot.gov/planning/newstarts/planning_environment_2618.html 
(Visited 2010, September 15). 
33. Federal Transit Administration (FTA) (2010b). “Capital Cost Database.” [WWW 
document] 
URL 
http://www.fta.dot.gov/planning/newstarts/planning_environment_11951.html 
(Visited 2010, September 15). 
34. Federal Transit Administration (FTA) (2010c). “Part I- Planning and Project 
Development.” 
[WWW 
document] 
URL 
http://www.fta.dot.gov/printer_friendly/planning_environment_2599.html 
(Visited 
2010, December 15). 

 
190 
 
35. Federal Transit Administration (FTA) (2010d). “New Starts Program Overview.” 
[WWW 
document] 
URL 
http://www.fta.dot.gov/printer_friendly/planning_environment_217.html 
(Visited 
2010, December 15). 
36. Federal Transit Administration (FTA) (2010e). “Interim Guidance on Design-Build 
Project 
Delivery 
and 
the 
FFGA 
Process.” 
[WWW 
document] 
URL 
http://www.fta.dot.gov/printer_friendly/leg_reg_4191.html  (Visited 2010, December 
15). 
37. Federal Transit Administration (FTA) (2008). “The Predicted and Actual Impacts of 
New Starts Projects – 2007 (Capital Cost and Ridership).” Office of Planning and 
Environmental, April. 
38. Federal Transit Administration (FTA) (2007b). “Risk Management Products and 
Procedures.” PG# 40, March 29. 
39. Federal Transit Administration (FTA) (2003a). “Risk Assessment and Mitigation 
Procedures.” PG# 22, December 8. 
40. Federal Transit Administration (FTA) (2003b). “Project & Construction- Management 
Guidelines.” [WWW document]  
URL 
http://www.fta.dot.gov/printer_friendly/planning_environment_1344.html 
(Visited 2010, December 15). 

 
191 
 
41. Federal Transit Administration (FTA) (2003c). “Predicted and Actual Impacts of New 
Starts Projects (Capital Cost, Operating Cost and Ridership Data).” Office of Planning 
and Environmental, September. 
42. Federal Transit Administration (FTA) (2002). “Full-Funding Grant Agreements 
Guidance.” Circular C 5200.1A, December 5. 
43. Flyvbjerg, B. (2006). “From Nobel Prize to Project Management: Getting Risk Right.” 
Project Management Journal, 5-15, August. 
44. Flyvbjerg, B., Holm, M., and Buhl, S. (2005). “How (In)accurate Are Demand Forecasts 
in Public Works Projects?” Journal of the American Planning Association, Vol. 71, No. 2, 
131-146, Spring. 
45. Flyvbjerg, B., Holm, M., and Buhl, S. (2004). “What Causes Cost Overrun in 
Transportation Infrastructure Projects?” Transport Reviews, Vol. 24, No. 1, 3–18, January. 
46. Flyvbjerg, B., Bruzelius, N., and Rothengatter, W. (2003). Mega Projects and Risk: An 
Anatomy of Ambition, Cambridge University Press, Cambridge, UK. 
47. Flyvbjerg, B., Holm, M., and Buhl, S. (2002). “Underestimating Costs in Public Works 
Projects: Error or Lie?” Journal of the American Planning Association, Summer, 68(3), 279-
295. 
48. Hallowell, M., and Gambatese, J. (2009). “Qualitative research: Application of the 
Delphi method to CEM Research.” Journal of Construction Engineering and Management, 
ASCE, Vol. 136, No. 1, 99-107, January.  

 
192 
 
49. Iman, R. and Conover, W. (1982). “A Distribution-Free Approach to Inducing Rank 
Correlation Among Input Variables.” Communications in Statistics - Simulation and 
Computation, 1532-4141, Volume 11, Issue 3, 311 – 334. 
50. Ince, P. and Buongiono, J. (1991). “Multivariate Stochastic Simulation with Subjective 
Multivariate Normal Distribution.” Symposium on System Analysis in Forest 
Resources, Charleston, South Carolina, March 3-7.  
51. Isidore, L., Edward Back, W. (2002). “Multiple Simulation Analysis for Probabilistic 
Cost and Schedule Integration.” Journal of Construction Engineering and Management, ASCE, 
Vol. 128, No. 3, 211-219, June. 
52. Kim, J., Ellis, R. (2006). “Accurate Cost Contingency Model for Transportation 
Construction Projects.” Transportation Research Board (TRB) Annual Meeting, 
Washington, D.C. 
53. Koch, K. (1999). Parameter and Estimation and Hypothesis Testing in Linear Models, 2nd 
Edition, Springer, Germany. 
54. Kurowicka, D., and Cooke, R. (2006). Uncertainty Analysis with High Dimensional 
Dependency Modeling, Wiley, Hoboken, NJ.  
55. Kutner, M., Nachtsheim, C., Neter, J., and Li, W. (2005). Applied Linear Statistical Models, 
5th Edition, McGraw-Hill, New York, NY.  
56. Mak, S., and Picken, D. (2000). “Using Risk Analysis to Determine Construction 
Project Contingencies.” Journal of Construction Engineering and Management, ASCE, Vol. 
126, No. 2, 130-136, March/April. 

 
193 
 
57. Meyer, M., and Booker, J. (2001). Eliciting and Analyzing Expert Judgment, A Practical 
Guide, American Statistical Association (ASA) and Society for Industrial and Applied 
Mathematics (SIAM), Philadelphia, PA.  
58. Molenaar, K. R. (2005). “Programmatic Cost Risk Analysis for Highway Mega-
projects.” Journal Construction Engineering and Management, ASCE, Vol. 131, No. 3, 343–
353, March. 
59. Moselhi, O. (1997). “Risk Assessment and Contingency Estimating.” Association for 
the Advancement of Cost Engineering (AACE) International Transaction, 
D&RM/A.06.  
60. Moselhi, O., and Dimitrov, B. (1993). “Discussion of Monte Carlo Technique with 
Correlated Random Variables by Touran and Wiser.” Journal of Construction Engineering 
and Management, ASCE, Vol. 119, No. 3, 658-660. 
61. Moselhi, O., and Hegazy, T., and Fazio, P. (1993). “DBID: Analogy–Based DSS for 
Bidding in Construction.” Journal of Construction Engineering and Management, ASCE, Vol. 
119, No. 3, 658-660, September. 
62. Olumide, A., Anderson, S., and Molenaar, K. (2010). “Sliding Scale Contingency for the 
Project Development Process.” Journal of the Transportation Research Board (TRB), 
No. 2151, Washington, D.C., pp 21-27.  
63. Olumide, A. (2009). “Sliding Contingency for the Highway Construction Project 
Development Process.” MS Thesis, Texas A&M University, Texas. 

 
194 
 
64. Paek, J. H., Lee, Y. W., and Ock, J. H. (1993) “Pricing Construction Risk: Fuzzy Set 
Application.” Journal of Construction Engineering and Management, ASCE, Vol. 119, No. 4, 
743-756, December. 
65. Palisade Corporation. (2008). “@Risk: Risk Analysis Add-in for Microsoft Excel.” 
Version 5.0.1: Professional Edition, Ithaca, New York. 
66. Parsons Inc., Touran, A., and Golder Association. (2004). “Risk Analysis 
Methodologies and Procedures.” The Federal Transit Administration, Project No. DC-
03-5649, Washington, D.C.  
67. Parsons Jr., E. (1999). “Waste Management Project Contingency Analysis.” US 
Department of Energy, Morgantown, WV.  
68. Pearson, N. (2002). Risk Budgeting: Portfolio Problem Solving with Values-at-Risk, John Wiley 
& Sons, New York, NY.  
69. Pickrell, D. H. (1990). “Urban Rail Transit Projects: Forecast Versus Actual Ridership 
and Cost.” DOT-T-91-04, U.S. Department of Transportation, Washington, D.C.  
70. Project Management Institute (PMI) (2004). A Guide to the Project Management Body of 
Knowledge, 3rd Edition, Newton Square, PA. 
71. Ranasinghe, M. (2000). “Impact of Correlation and Induced Correlation on the 
Estimation of Project Cost of Buildings.” Journal of Construction Management and Economics, 
Vol. 18, Issue 4, 395-406, June. 

 
195 
 
72. Roberds, W. and McGrath T. (2006). “Quantitative Cost and Schedule Risk Assessment 
and Risk Management for Large Infrastructure Projects.” Golder Associate, Inc, Pre-
reviewed for PMI COS 2006 Conference Proceeding. 
73. Rothwell, G. (2005). “Cost Contingency as the Standard Deviation of the Cost 
Estimate.” Cost Engineering Journal, AACE International, Vol. 47, Issue 7, 22-25, July, 
Morgantown, WV. 
74. Rowe, D. (2003). Multivariate Bayesian Statistics: Models for Source Separation and Signal 
Unimixing, Chapman & Hall/CRC Press, Boca Raton, FL.  
75. Saaty, T.L. (1980). The Analytic Hierarchy Process: Planning, Priority Setting, Resource Allocation, 
McGraw-Hill. 
76. Sachs, T. and Tiong, R. (2009). “Quantifying Qualitative Information on Risks: 
Development of the QQIR Method.” Journal of Construction Engineering and Management, 
ASCE, 135 (1), 56-71, January. 
77. Sinnette, J. (2004). “Accounting for Megaproject Dollars.” Public Roads, Federal 
Highway Administration, Vol. 68, No. 1, July/August, [WWW document] URL 
http://www.fhwa.dot.gov/publications/publicroads/04jul/07.cfm (Visited Feb 08, 
2010). 
78. Schneck, D., Laver, R., and O’Connor, M. (2009). “Cost Contingencies, Development 
Basis, and Project Application.” Journal of the Transportation Research Board (TRB), No. 
2111, Washington, D.C., pp 109-124. 

 
196 
 
79. Shane, J., Molenaar, K., Anderson, S. and Schexnayder, C. (2009). “Construction 
Project Cost Escalation Factors.” Journal of Management in Engineering, ASCE, Vol. 25, 
No. 4, 221-229, October. 
80. Sillars, D. and O’Connor, M. (2008). “Risk-Informed Project Oversight at the FTA.” 
Transportation Research Board (TRB) Annual Meeting, Washington, D.C. 
81. Smith, G. and Bohn, C. (1999). “Small to Medium Contractor Contingency and 
Assumption of Risk.” Journal of Construction Engineering and Management, ASCE, Vol. 125, 
No. 2, 101-108, March/April. 
82. Springer, M. (1979). The Algebra of Random Variables, 1st Edition, John Wiley and Sons, 
Inc, Hoboken, NJ. 
83. Transit Cooperative Research Program (TCRP) (2010). “Guidebook for Estimating Soft 
Costs for Major Public Transportation Projects.” TCRP Report No. 138, Transportation 
Research Board of National Academies, Washington, D.C. 
84. The British Department for Transportation (DfT). (2004). “Procedure for Dealing with 
Optimism Bias in Transport Planning.” Guidance Document, June.  
85. Touran, A. (2010). “A Probabilistic Approach for Budgeting in a Portfolio of Projects.” 
Journal of Construction Engineering and Management, ASCE, Vol. 136, No. 3, 361-366, March. 
86. Touran, A. (2006a). “A Mathematical Model for Establishing Budget Levels for a 
Portfolio of Transit Projects.” Proceedings of the 11th International Conference on 
Computing in Civil and Building Engineering (ICCCBE XI), Montreal, Canada, June 
14-16. 

 
197 
 
87. Touran, A. (2006b). “Owners Risk Reduction Techniques Using a CM.” Construction 
Management Association of America (CMAA), October.  
88. Touran, A. (2003). “Probabilistic Model for Cost Contingency.” Journal of Construction 
Engineering and Management, ASCE, Vol. 129, No. 3, 280-284, May/June. 
89. Touran, A. (1993). “Probabilistic Cost Estimating with Subjective Correlations.” Journal 
of Construction Engineering and Management, ASCE, Vol. 119, No. 1, 58-71, March. 
90. Touran, A. and Bakhshi, P. (2010). “Effect of Escalation on Large Construction 
Programs.” Association for the Advancement of Cost Engineering (AACE) 
International Transactions, Risk.14.  
91. Touran, A. and Lopez, R. (2006). “Modeling Cost Escalation in Large Infrastructure 
Projects.” Journal of Construction Engineering and Management, ASCE, Vol. 132, No. 8, 853-
860, August. 
92. Touran, A. and Suphot, L. (1997). “Rank Correlation in Simulating Construction 
Costs.” Journal of Construction Engineering and Management, ASCE, Vol. 123, No. 3, 297-
301, September. 
93. Touran, A., and Wiser, E. (1992). “Monte Carlo Technique with Correlated Random 
Variables.” Journal of Construction Engineering and Management, ASCE, Vol. 118, No. 2, 58-
272, June. 
94. Wall, M. D. (1997). “Distributions and Correlations in Monte Carlo Simulation.” Journal 
of Construction Management and Economics, Vol. 15, Issue 3, 241-258, May. 

 
198 
 
95. Walpole, R., Myers, R., Myers, S., and Ye, K. (2007). Probability & Statistics for engineers & 
Scientists, 8th Edition, Pearson Prentice Hall, Upper Saddle River, NJ.  
96. Wang, W., and Demsetz, L. (2000). “Model for Evaluating Networks Under Correlated 
Uncertainty-NETCO.” Journal of Construction Engineering and Management, ASCE, Vol. 126, 
No. 6, 458-466, November/December. 
97. Yang, I. (2006). “Using Gaussian Copula to simulate Repetitive Projects.” Journal of 
Construction Management and Economics, Vol. 24, Issue 9, 901-909. 
98. Yeo, K. T. (1190). “Risks, Classification of Estimates, and Contingency Management.” 
Journal of Management in Engineering, ASCE, Vol. 6, No. 4, 458-470, October. 

 
199 
 
APPENDIX B: A PROPOSED MATHEMATICAL 
METHOD FOR CALCULATING COST 
CORRELATION 
B.1 
Introduction 
One problem facing the modeler in using the approaches described in this research is 
estimating the correlation coefficient between project costs. As was described in this 
dissertation, the most common approach is to provide subjective estimates of correlation 
coefficient. This of course while better than ignoring correlation, may be subject to 
inaccuracy and estimator’s bias. No analytical approach for calculating correlations was 
found even after an exhaustive search in civil engineering, construction, and management 
literature. In order to alleviate this problem, this appendix proposes a mathematical model 
developed by the author for the calculation of correlation coefficient between project costs.  
B.2 
Basis of the Method 
Here a mathematical method is proposed to calculate the Pearson Correlation Coefficient 
between costs of two projects. This method is based on the premise of breaking down the 
total cost of project to: (1) base cost, and (2) risks cost. Base cost is the cost of project which 
is not including contingency (Touran 2006b). These are costs for items with a high degree of 

 
200 
 
certainty and which are necessary for delivering the project. Risk costs on the other hand, are 
costs that are uncertain in nature and may or may not affect the project. The costs of risks 
are usually allowed for by budgeting a contingency set aside to cope with uncertainties and 
risks during a project design and construction. Using this definition, let us define the total 
cost of project as: 




in
j
ij
i
i
R
B
X
1
 
 
 
 
 
 
 
 
 
(B.1) 
Where 
i
X  denotes total cost, 
iB denotes the base cost of project i and 
ij
R represents the 
monetary impact of risk factors
)
...,
,2
,1
(
n
j 
 for project i  which can be random variables 
or even deterministic. The summation is the required contingency budget for projecti .  
To estimate the correlation coefficient between costs of two projects, let us assume two 
projects with the following total costs: 




1
1
1
1
1
n
j
j
R
B
X
  
 
 
 
 
 
 
 
 
(B.2) 




2
1
2
2
2
n
j
j
R
B
X
 
 
 
 
 
 
 
 
 
(B.3) 
Risk factors in both projects can be divided into two parts: (1) common risk factors (CR ) 
and (2) special risk factors ( SR ). CR  risk factors are those that if they occur in project 1, 
they will potentially happen in project 2. SR  risk factors are those that are not likely to 
happen in both projects. Therefore the costs can be rewritten as: 







1
1
1
1
1
1
1
1
p
l
l
m
k
k
SR
CR
B
X
  
 
 
 
 
 
 
(B.4) 

 
201 
 







2
2
1
2
1
2
2
2
p
l
l
m
k
k
SR
CR
B
X
  
 
 
 
 
 
 
(B.5) 
Where 
m
m
m


2
1
 and 
1
1
1
n
p
m


 and 
2
2
2
n
p
m


. To estimate the correlation 
coefficient, we need to calculate the covariance between 
1
X  and 
2
X : 
)
,
(
)
,
(
2
2
1
1
1
2
1
2
2
1
1
1
1
1
2
1













p
l
l
m
k
k
p
l
l
m
k
k
SR
CR
B
SR
CR
B
COV
X
X
COV
 
 
(B.6) 
Expanding the above, we have: 
)
,
(
)
,
(
)
,
(
)
,
(
)
,
(
)
,
(
)
,
(
)
,
(
)
,
(
)
,
(
2
1
1
1
2
2
1
2
1
1
1
2
1
1
2
1
1
1
2
1
1
1
2
1
1
2
1
1
1
2
1
1
2
1
2
1
2
1

































p
l
l
p
l
l
m
k
k
p
l
l
p
l
l
p
l
l
m
k
k
m
k
k
m
k
k
m
k
k
p
l
l
m
k
k
SR
SR
COV
CR
SR
COV
B
SR
COV
SR
CR
COV
CR
CR
COV
B
CR
COV
SR
B
COV
CR
B
COV
B
B
COV
X
X
COV
  
(B.7) 
We note that covariance between two constants or a constant and a variable is equal to zero. 
Thus: 
)
,
(
)
,
(
)
,
(
)
,
(
)
,
(
2
1
1
2
1
2
1
1
1
2
1
1
1
2
1
1
1
2
1
1
2
1




















p
l
l
p
l
l
m
k
k
p
l
l
p
l
l
m
k
k
m
k
k
m
k
k
SR
SR
COV
CR
SR
COV
SR
CR
COV
CR
CR
COV
X
X
COV
 
 
 
 
(B.8) 
To calculate the above covariances, we need to make some assumptions.  
We recognize the correlation between analogous common risk factors such as 
)
,
(
21
11 CR
CR
and 
)
,
(
22
12 CR
CR
in two projects. All other combinations of common risk factors such as 
)
,
(
22
11 CR
CR
or 
)
,
(
23
12 CR
CR
are assumed to be independent meaning the covariance is 
zero. We also consider that there is no correlation between all combinations of special risk 

 
202 
 
factors in two projects
)
,
(
2
1
l
l SR
SR
. We also assume that there is no correlation between 
common risk factors and special risk factors of the two projects. The abovementioned 
independence assumptions are justified as no relationship exists between those combinations 
of risk factors. In other words, if one occurs in Project 1, we cannot have any prediction on 
occurrence of the other one in Project 2. Therefore, the assumption of independence (or 
covariance of zero) is rational and adequate.  
Knowing the fact that: 
y
x
y
x
y
x
y
x
y
x
COV
y
x
COV






.
.
)
,
(
.
)
,
(
,
,



 
 
 
 
 
(B.9) 
Where 
y
x,

is the correlation coefficient between x  and y . Thus we have: 
















m
k
CR
CR
CR
CR
CR
CR
CR
CR
CR
CR
CR
CR
CR
CR
CR
CR
m
m
m
k
k
m
k
k
k
k
k
k
m
m
m
m
CR
CR
COV
CR
CR
COV
CR
CR
COV
CR
CR
COV
X
X
COV
1
,
,
,
,
2
1
22
12
21
11
1
2
1
1
2
1
)
.
.
(
.
.
...
.
.
.
.
)
,
(
...
)
,
(
)
,
(
)
,
(
)
,
(
2
1
2
1
2
1
2
1
22
12
22
12
21
11
21
11












 
 
(B.10) 
We know that: 






















1
1
1
1
1
1
1
1
1
1
1
2
1
2
1
2
2
1
1
1
1
2
)
,
(
p
l
SR
m
k
CR
n
j
R
X
t
independen
are
risks
all
If
n
j
n
t
t
j
X
l
k
j
R
R
Cov





 
 
 
 
 
 
 
 
 
 
 
 
(B.11) 
and: 






















2
2
2
2
2
2
2
2
2
2
1
2
1
2
1
2
2
1
1
2
2
2
)
,
(
p
l
SR
m
k
CR
n
j
R
X
t
independen
are
risks
all
If
n
j
n
t
t
j
X
l
k
j
R
R
Cov





 
 
 
 
 
 
 
 
 
 
 
 
(B.12) 

 
203 
 
Therefore: 










2
2
1
1
2
1
2
1
2
1
2
1
1
1
2
2
1
1
1
1
1
,
2
1
,
)
,
(
.)
,
(
)
.
.
(
.
)
,
(
n
j
n
t
t
j
n
j
n
t
t
j
m
k
CR
CR
CR
CR
X
X
X
X
R
R
Cov
R
R
Cov
X
X
COV
k
k
k
k






 
 
(B.13) 
Using Eq. (B.13), one can calculate the correlation coefficient among costs of any pair of 
projects with an acceptable degree of accuracy.   
Due to common characteristics of the analogous common risk factors in two projects, if we 
assume perfect correlation with correlation coefficient of 1.0 among them, Eq. (B.13) can be 
simplified to: 
 









2
2
1
1
2
1
2
1
1
1
2
2
1
1
1
1
1
,
)
,
(
.)
,
(
)
.
(
n
j
n
t
t
j
n
j
n
t
t
j
m
k
CR
CR
X
X
R
R
Cov
R
R
Cov
k
k 


 
 
 
 
(B.14) 
B.3 
Numerical Example 
Here to illustrate the application of the model, two hypothetic contemporary projects along 
with their identified risks are presented. Then using the mathematical model, the correlation 
between costs of two projects is estimated.  
Figure B.1 shows a hypothetical transit project with 26 identified risks/opportunities with 
the total monetary impact of $26,101,022 and standard deviation of $4,212,370. Figure B.2 
depicts the risks/opportunities identified for the second hypothetical transit project with the 
total impact of $31,726,409 and standard deviation of $5,033,372. Both risk assessments 

 
204 
 
have been conducted after final design in 2005, with the expected starting construction 
phase in 2005.   
The goal is to estimate the correlation between costs of these two projects using the 
proposed mathematical method. 
 
Figure B.1: The Risk Register for the First Hypothetical Transit Project 
 
Project Name: Hypothetical Transit Project 1
Construction Start Date:
3/7/2005
Location:
Las Vegas, NV
Risk Anaylisis at Phase:
Final Design
Project BC:
$432,027,078
Risk Anaylisis Date:
7/19/2004
5%
Most Likely
95%
P1.R01
Owner directed change 
$0
$2,400,000
$4,800,000
$2,400,005
$1,433,071
P1.R02
Utility relocation variation 
-$3,500,000
$0
$5,000,000
$594,238
$2,543,428
P1.R03
Remaning property acquistions 
-$250,000
$2,500,000
$4,000,000
$2,004,386
$1,276,672
P1.R04
Environmental risks
$500,000
$1,250,000
$2,500,000
$1,448,164
$599,768
P1.R05
Proximity to existing structures 
$100,000
$250,000
$500,000
$289,633
$119,956
P1.R06
City restrictions
$0
$1,093,580
$2,187,159
$1,093,579
$653,008
P1.R07
Design change for column location
$25,000
$50,000
$100,000
$59,916
$22,568
P1.R08
Daily lane closures and their 
frequency 
$0
$250,000
$500,000
$250,001
$149,277
P1.R09
Design changes/City requirements
$0
$243,201
$486,402
$243,200
$145,222
P1.R10
Estimate deviation (pessimistic 
estimate)
-$1,000,000
$1,950,000
$4,000,000
$1,593,473
$1,496,211
P1.R11
Permanent barriers 
$0
$1,500,000
$2,000,000
$1,102,344
$607,475
P1.R12
Parking space construction
$0
$250,000
$300,000
$170,134
$92,235
P1.R13
Traffic signal modifications
$0
$1,642,000
$1,970,400
$1,117,440
$605,814
P1.R14
Site conditions (geotech), 
environmental risk
$100,000
$250,000
$500,000
$289,632
$119,953
P1.R15
Locomotives uncertainty due to 
exchange rate 
$1,500,000
$2,750,000
$5,000,000
$3,146,460
$1,051,004
P1.R16
Additional surveying required
$25,000
$75,000
$200,000
$104,786
$52,920
P1.R17
Potential RTC caused project delay 
$601,865
$1,203,730
$2,407,460
$1,442,458
$543,316
P1.R18
Fire Protection - NFPA 130 
$0
$180,000
$300,000
$156,229
$89,823
P1.R19
Credit for Station Connector 
$0
$0
$2,400,000
$983,528
$754,226
P1.R20
Potential increase in insurance cost 
$0
$1,687,500
$3,375,000
$1,687,490
$1,007,617
P1.R21
Emergency walkway lighting 
$0
$1,000,000
$2,400,000
$1,158,447
$717,949
P1.R22
Additional fare collection equipment
$0
$200,000
$300,000
$160,335
$90,274
P1.R23
Escalation from Sep 30,04 to NTP 
of Mar 05 
$0
$2,375,000
$4,750,000
$2,374,999
$1,418,171
P1.R24
Effect of potential delay
$742,761
$1,485,523
$2,971,046
$1,780,141
$670,491
P1.R25
Scope change for additional 
oversight and Before & After study
$200,000
$350,000
$500,000
$350,002
$89,568
P1.R26
V/E Study 
$50,000
$100,000
$150,000
$100,000
$29,856
$26,101,022 $4,212,370
Mean
Std. 
Deviation
Total
Risk/Opportunity Event
Risk ID
Risk/Opportunity Impact

 
205 
 
 
Figure B.2: The Risk Register for the Second Hypothetical Transit Project 
First, two risk registers shown in Figure B.1 and B.2 are compared to recognize the common 
risk factors in both risk registers. The common risk factors have been highlighted in the 
figures. These are risks with IDs P1.R10, P1.R15, and P1.R23 in Project 1 corresponding 
with P2.R05, P2.R13, and P2.R18 in Project 2. The standard deviation of all risks can be 
found in the last column of risk registers. It should be noted that no correlation is appeared 
to be between the risk factors in each project. Because of this, independence is assumed 
between these risk factors. Hence, standard deviations of total costs are calculated using Eqs. 
(B.11) and (B.12) and are presented in the last row of risk registers ($4,212,370 and 
5,033,372). The analogous common risks in two projects are assumed to be fully correlated 
Project Name: Hypothetical Transit Project 2
Construction Start Date:
1/3/2005
Location:
Maryland, MD
Risk Anaylisis at Phase:
Final Design
Project BC:
$381,358,049
Risk Anaylisis Date:
2/23/2004
5%
Most Likely
95%
P2.R01
Design uncertainty 
$2,650,000
$4,650,000
$6,650,000
$4,649,995
$1,194,219
P2.R02
ADA Compliance
$297,000
$330,000
$396,000
$343,090
$29,790
P2.R03
Opportunity (only half of platform 
built)
$3,095,000
$3,439,000
$4,127,000
-$3,575,446
$310,536
P2.R04
Archaelogy finds
$125,000
$250,000
$500,000
$299,582
$112,839
P2.R05
Deviation from estimate 
(pessimistic estimate)
-$55,000
$2,650,000
$4,750,000
$2,410,396
$1,436,191
P2.R06
Fiber optics purchase and install
$480,000
$500,000
$900,000
$653,672
$131,579
P2.R07
Potential cost overrun on track 
costs
$100,000
$5,566,100
$9,276,833
$4,870,713
$2,746,972
P2.R08
Opportunity that less than 100% of 
line is born by MTA
$100,000
$1,000,000
$1,500,000
-$841,420
$420,409
P2.R09
Risk of property price needed to 
create wetlands
-$1,500,000
$0
$1,000,000
-$198,096
$748,515
P2.R10
Support and setup facility
$0
$150,000
$250,000
$130,191
$74,853
P2.R11
Appraisal services ranged
$225,000
$600,000
$900,000
$570,299
$201,705
P2.R12
Prpoperty acquistion
$5,390,000
$6,200,000
$9,440,000
$7,168,499
$1,238,819
P2.R13
Locomotives uncertainty due to 
exchange rate 
$3,500,000
$6,500,000
$8,750,000
$6,202,936
$1,569,747
P2.R14
Bid uncertainty 
-$1,440,000
$0
$2,880,000
$571,178
$1,299,918
P2.R15
Overrun on the rehab cars and 
uncertainty on car cond
$0
$2,750,000
$5,400,000
$2,710,410
$1,612,218
P2.R16
Spare parts
$961,200
$2,352,000
$5,140,800
$2,906,525
$1,257,736
P2.R17
Variability of engineering services
-$1,507,800
$0
$1,507,800
$13
$900,331
P2.R18
Escalation
$0
$3,250,000
$5,500,000
$2,853,873
$1,645,963
$31,726,409
$5,033,372
Std. 
Deviation
Total
Risk ID
Risk/Opportunity Event
Risk/Opportunity Impact
Mean

 
206 
 
).
0.
1
(


Using Eq. (B.14) the correlation coefficient between costs of two projects is 
estimated: 
289
.0
5033372
4212370
1645963
1418171
1569747
1051004
1436191
1496211
2
1,








X
X

  (B.15) 
This method is very simple to apply on large projects where the risk register for these types 
of projects is mostly available. Please note that currently, the FTA requires each New Starts 
transit project to go through a complete risk analysis and hence the risk register should be 
prepared for each new project. The analyst should be careful to select the common risk 
factors correctly. This is the most important step in the application of the method. Since the 
correlation estimation is usually required between costs of similar projects in a portfolio, the 
agency can publish a template or a risk catalogue. As a result of this practice, the recognition 
of common risk factors becomes more accurate and straight-forward.  
 

