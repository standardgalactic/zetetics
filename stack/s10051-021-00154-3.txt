Eur. Phys. J. B (2021) 94:188
https://doi.org/10.1140/epjb/s10051-021-00154-3
THE EUROPEAN
PHYSICAL JOURNAL B
Topical Review - Computational Methods
A maximum caliber approach for continuum path
ensembles
Peter G. Bolhuis1,a
, Z. Faidon Brotzakis2
, and Michele Vendruscolo2
1 van ’t HoﬀInstitute for Molecular Sciences, University of Amsterdam, PO Box 94157, 1090 GD Amsterdam,
The Netherlands
2 Department of Chemistry, University of Cambridge, Cambridge CB2 1EW, UK
Received 23 April 2021 / Accepted 5 July 2021 / Published online 23 September 2021
© The Author(s) 2021
Abstract. The maximum caliber approach implements the maximum entropy principle for trajectories by
maximizing a path entropy under external constraints. The maximum caliber approach can be applied to a
diverse set of equilibrium and non-equilibrium problems concerning the properties of trajectories connecting
diﬀerent states of a system. In this review, we recapitulate the basic concepts of the maximum entropy
principle and of its maximum caliber implementation for path ensembles, and review recent applications
of this approach. In particular, we describe how we recently used this approach to introduce a framework,
called here the continuum path ensemble maximum caliber (CoPE-MaxCal) method, to impose kinetic
constraints in molecular simulations, for instance to include experimental information about transition
rates. Such incorporation of dynamical information can ameliorate inaccuracies of empirical force ﬁelds,
and lead to improved mechanistic insights. We conclude by oﬀering an outlook for future research.
1 Introduction
The maximum entropy principle is a general varia-
tional principle to maximize the entropy of a system
under given constraints [1,2]. This principle provides
an eﬀective route to a statistical mechanical descrip-
tion of complex molecular systems. The maximum cal-
iber approach represents an implementation of the max-
imum entropy principle for path ensembles [3,4]. This
approach is becoming increasingly used to deal with the
equilibrium and non-equilibrium statistical mechanics
of trajectories [5–11].
The trajectories of a molecular system can be pro-
duced using computer simulation methods, as for
instance molecular dynamics. Such simulations have
become a standard tool for predicting equilibrium
properties of molecular systems in structural biology,
physics, chemistry, and material science, yielding sta-
ble and metastable structures and their populations,
as given by the free energy diﬀerences between states.
While the application of molecular dynamics provides
such information by sampling the Boltzmann distribu-
tion, the timescales that such simulations can access
are often insuﬃcient to observe the reactive processes
of interest [12–15]. This is known as the sampling prob-
lem, and is a well-known source of statistical and sys-
tematic errors [16]. Therefore, enhanced sampling is
often needed to overcome the high free energy barri-
ers that are underlying the long timescales [13,17,18].
A second source of error arises from the approxima-
a e-mail: p.g.bolhuis@uva.nl (corresponding author)
tions used in the deﬁnition of the force ﬁeld used in the
simulations. In the last decade, it has become there-
fore common to correct for force ﬁeld inaccuracies in a
system-dependent manner by incorporating experimen-
tal data as restraints in the simulations. To implement
this strategy, powerful tools have been developed based
on the maximum entropy principle [19–30] leading to
numerous applications for example in protein folding
and assembly [31–36] as well as in cases where force
ﬁelds are less accurate [37], such as for intrinsically dis-
ordered proteins (IDPs) and nucleic acids [28,30,38–
44].
The maximum entropy (MaxEnt) principle can also
be applied to accurately determine dynamical processes
in complex systems undergoing rare transitions, such as
biomolecular isomerization, association, self-assembly
or nucleation phenomena. In these approaches, exper-
imental rate constants or time-dependent data are
incorporated in discrete time, biased molecular dynam-
ics simulations using the maximum caliber (MaxCal)
approach [9,45] (for an explanation of the terminology
see Table 1). We recently explored a new avenue by
developing a method based on the MaxCal approach,
which utilizes unbiased atomistic classical molecular
dynamics in combination with trajectory-based rare
event methods. This framework can be used to ame-
liorate the eﬀects of force ﬁeld errors on the kinetic
properties of complex molecular systems [46].
Dill and coworkers [5,9,11] have reviewed the broad
scope of applications of the MaxCal approach in the
area of non-equilibrium dynamics, including Green–
Kubo relations, and Onsager’s reciprocal relations, as
123

188
Page 2 of 21
Eur. Phys. J. B (2021) 94:188
Table 1 Terminology used in this work
MaxEnt principle
Maximum entropy principle
Conﬁguration space
MaxEnt approach
MaxEnt principle applied to conﬁguration space
MaxEnt method
A method based on the MaxEnt approach
Trajectory space
MaxCal approach
Application of the MaxEnt principle to discrete or continuous trajectory space
CoPE-MaxCal
Application of the MaxCal approach to continuous path ensembles
CoPE-MaxCal for transition rates
Application of the CoPE-MaxCal method for imposing transition rates
well as applications in equilibrium situations, including
the optimization of Markov state models [47]. The latter
approach aims to infer the interconversion rate matrix
between metastable states from limited information on
the population of the states themselves. Using MaxCal
optimization, a classical-mechanics connection between
trajectories and Langevin/Fokker–Planck parameters
was recently derived [8], Furthermore, a way to con-
struct such Markov state models for non-equilibrium
steady state processes was also reported [48,49].
These approaches concern discrete systems [9], in the
sense that continuous molecular dynamics trajectories
are discretized into matrices of transition probabilities
between metastable states, which can then be analyzed
with MaxCal approaches. In many cases, however, one
would like to keep the microscopic atomistic informa-
tion of the pathways, and use the concept of altering the
path probabilities, also known as trajectory reweight-
ing. This concept is well known in the literature, e.g.,
in large deviation theory [50,51] and path reweight-
ing [48,52,53]. However, the application of the MaxCal
approach to continuous space trajectories has proven
diﬃcult.
We recently introduced the continuum path ensemble
maximum caliber (CoPE-MaxCal) method to reweight
existing ensembles of trajectories to match experimen-
tal rate constants [46]. Given an ensemble of path-
ways harvested by unbiased molecular dynamics or
enhanced trajectory sampling methods that do not bias
the dynamics, we introduced a consistent reweighting
scheme in which not only the reactive paths are assigned
altered weights, but also all other paths in the ensemble,
so that they match the corrected free energy landscape
obtained from a simultaneous MaxEnt-based reweight-
ing. Transition Path Sampling (TPS) [54–56] and the
related Transition Interface Sampling (TIS) [57–59]
techniques are rigorous enhanced trajectory sampling
methods that can provide the required path ensem-
bles. These methods elucidated the kinetics of a variety
of complex molecular systems, including biomolecular
conformational changes [60–75], ion dissociation [76–78]
and dissolution [79], water isomerization [80] and evap-
oration [81], polymer collapse [82,83], nucleation pro-
cesses [84–92], polymorph transitions [93–95], chemical
reactions [96,97], enzyme reaction kinetics [98–101], col-
loidal cluster assembly [85,102–104], and glassy systems
[51,105–110], leading in many cases to novel insights.
Other trajectory-based methods such as Forward Flux
Sampling [111,112] or Weighted Ensemble [113–115],
stochastic process rare event sampling [116], mileston-
ing [117,118], adaptive multilevel splitting [119], and
non-equilibrium umbrella sampling [120], can in princi-
ple also be used to collect a prior path ensembles.
An important feature of the CoPE-MaxCal method
is that it can be applied a posteriori, i.e., by post-
processing an existing prior path ensemble. Impor-
tantly, such an approach addresses simultaneously the
sampling and the force ﬁeld problems. Thus, the CoPE-
MaxCal method enables a system-dependent character-
ization when experimental data are available, without
solving the extremely challenging problem of optimizing
the force ﬁeld itself in a system-independent, transfer-
able manner, even though this might be preferred from
a fundamental point of view.
In this review, we provide a perspective of the CoPE-
MaxCal method by explaining the basic MaxEnt and
MaxCal concepts, and how they lead to the CoPE-
MaxCal reweighting scheme. Our aim is to recapit-
ulate, and partly recast, this method, put it in per-
spective, and to provide an outlook on future research
directions. The remainder of the paper is organized as
follows. In Sects. 2 and 3, we introduce the MaxEnt
principle and the MaxCal approach, and describe how
they apply to continuous time and coordinate spaces.
Section 4 reviews the speciﬁc application to the incor-
poration of rate constants. Section 5 discusses several
extensions, and connects some loose ends. We end with
a conclusion and an outlook.
2 Maximum entropy
2.1 The maximum entropy principle
According to the MaxEnt principle [1,2], the condition
of equilibrium for a system is achieved by a maximiza-
tion of the Shannon entropy
S = −

i
pi ln pi,
(1)
where pi is the probability distribution for state i. Note
that this entropy is related to the Gibbs entropy by a
factor kB. For a closed and isolated system with only
the constraint of an overall normalization, obtaining the
123

Eur. Phys. J. B (2021) 94:188
Page 3 of 21
188
probability distribution that optimizes the entropy can
eﬃciently be done by the method of Lagrange multipli-
ers. The Lagrange function is
L = −

i
pi ln pi −ν

i
pi −1

,
(2)
where ν is the Lagrange multiplier, which is used to
impose the normalization condition. The extremum of
this function follows from setting to zero the derivative
with respect to pi
δS
δpi
= −ln pi −1 −ν = 0.
(3)
Solving this for pi gives
pi = e−ν−1,
(4)
which is a constant factor. Applying the normalization
condition leads to

i
pi =

i
e−ν−1 = We−ν−1 = 1,
(5)
where W is the number of accessible states, so that the
Lagrange multiplier is given by eν+1 = W, leading to
the probability pi = 1/W. This condition corresponds
to the standard assumption in statistical mechanics
that in a closed and isolated system each microstate has
the same probability, which corresponds to the Boltz-
mann identity S = ln W, in units of the Boltzmann
constant kB.
Often the MaxEnt principle is concerned with the
relative entropy, which is
S = −

i
pi ln pi
p0
i
,
(6)
where p0 denotes the prior distribution, e.g., the con-
stant probability of the microcanonical ensemble. The
relative entropy is the negative of the Kullback–Leibler
(KL) divergence, and reaches its maximum of zero only
when the prior and posterior distribution are identi-
cal. The MaxEnt principle can be applied subject to
additional constraints, for instance that an average of
a ﬂuctuating observable si is ﬁxed to a certain value

i
pisi = s.
(7)
The MaxEnt principle states that in equilibrium, the
entropy should be maximized subject to this constraint.
Using the method of Lagrange multipliers, the opti-
mization function becomes
L=−

i
pi ln pi
p0
i
−η

i
pisi −s

−ν

i
pi−1

,
(8)
which again can be optimized by setting the derivative
to zero
δS
δpi
= −ln pi
p0
i
−1 −ηsi −ν = 0.
(9)
Rearranging leads to
pi ∝p0e−ηsi,
(10)
where we ignored the normalization constant set by ν.
Assuming a constant prior probability p0, and normal-
izing, gives the distribution
pi = e−ηsi
Z
,
(11)
where the partition function is
Z =

i
e−ηsi.
(12)
As an example, we can take the energy Ei of the system
to be the observable s, and identify η as β. This leads
to
pi =
e−βEi

i e−βEi ,
(13)
which is the Boltzmann distribution, with β = 1/kBT
being the inverse temperature of the surrounding reser-
voir that the system can exchange heat with. In addi-
tion, the derivative of Z with respect to the variable η
∂ln Z
∂η
= −⟨si⟩,
(14)
gives the average of the observable.
In summary, the above outline illustrates how apply-
ing the MaxEnt principle to systems with a large num-
ber of degrees of freedom leads to standard statistical
mechanics. For further details, we refer to Refs. [1,2,9].
2.2 MaxEnt in conﬁguration space
In this section, we discuss the application of the Max-
Ent principle in continuous space [28,29]. Consider a
continuous state space x, where x denotes the posi-
tions and velocities of all the particles in a system. The
maximum relative entropy principle states that, given a
prior probability distribution (density) ρ0(x), the opti-
mal distribution ρ(x) maximally compatible with a set
of given experimental constraints is the one that which
maximizes the entropy, or the negative of the KL diver-
gence
S[ρ||ρ0] = −

dxρ(x) ln ρ(x)
ρ0(x).
(15)
123

188
Page 4 of 21
Eur. Phys. J. B (2021) 94:188
Constrained conformational average 
Maximum Entropy
A
B
sexp
P[s(x)]
Reweighed ensemble of 
conformations compatible 
with the constraint
Prior
Reweighed ensemble of 
paths compatible with 
the constraint
Posterior
⟨s⟩0 ⟨s⟩
⟨s⟩0 ⟨s⟩
s (x)
sexp
P[(s(x)]
Prior
Posterior
s (x)
A
B
Maximum Caliber
Constrained path ensemble average 
Fig. 1
Schematic comparison of the MaxEnt and MaxCal approaches for reweighting continuous space conformational and
path ensembles, respectively. Left: The prior conformational ensemble (blue circles) changes its weights of conformations,
illustrated by the diﬀerent size of the circles in the posterior ensemble (green circles). This change of weights also alters
the distribution along a conformational observable s(x) and shifts the prior conformational ensemble average ⟨s(x)⟩0 to the
posterior average ⟨s(x)⟩= sexp (in green). Right: The same principle holds for path reweighting, where now instead of a
conformational ensemble, a prior path ensemble (blue paths) is reweighted (green paths) according to a constraint in an
experimental (dynamical) observable, such as a kinetic rate constant
The entropy should, thus, be maximized subject to
M experimental constraints
ρME(x)= argmax
P (x)
S[ρ||ρ0]
subject to:

dxρ(x)si(x)=⟨si(x)⟩=sexp
i

dxρ(x) = 1,
(16)
where the si denote the experimental observables (1 ≤
i ≤M), and sexp
i
is the value of the experimental con-
straint. The last line is the normalization condition.
Again, the relative entropy is always non-positive, and
zero only if the two distributions are identical. In Fig. 1
we illustrate the application of the MaxEnt principle
to the reweighting of the prior conformation distribu-
tion, thereby identifying a posterior distribution which
meets a given experimental constraints sexp
i
. The max-
imization can be carried out using the method of the
Lagrangian multipliers, by looking for the stationary
point of the Lagrange function
L = S[ρ||ρ0] −
M

i=1
μi
	
dxsi(x)ρ(x) −sexp
i

−ν
	
dxρ(x) −1

,
(17)
where the μi and ν are the multipliers, which are related
to each of the M experimental constraints, and the nor-
malization condition, respectively. A functional deriva-
tive with respect to ρ(x) gives
δL
δρ(x) = −ln ρ(x)
ρ0(x) −1 −
M

i=1
μisi(x) −ν.
(18)
Setting the derivative to zero and solving for ρ(x) leads
to
ρME(x) = 1
Z e−M
i=1 μisi(x)ρ0(x),
(19)
123

Eur. Phys. J. B (2021) 94:188
Page 5 of 21
188
where Z is a normalization factor akin to the partition
function,
Z =

dxρ0(x)e−M
i=1 μisi(x).
(20)
The posterior MaxEnt density is, thus, a reweighing of
the prior distribution with an exponential factor involv-
ing the experimental observable.
The unknown multipliers can be determined by not-
ing that the solution of the Lagrange function is equiv-
alent to minimizing the following function with respect
to μ, as shown by Cesari and coworkers [28]
Γ(μ) = −ln Z + μ · sexp,
(21)
where bold symbols denote a vector of the M multi-
pliers and observables. This can be seen as a Legen-
dre transformation. Minimization of Γ(μ) with respect
to each multiplier yields a set of M equations for the
ensemble averages in the posterior ensemble

dxρ0(x)e−M
i=1 μisi(x)si(x)

dxρ0(x)e−M
i=1 μisi(x)
= sexp
i
,
(22)
which can be solved to give the sought multipliers μi.
For further details on the MaxEnt approach, we refer
the interested reader to Ref. [28].
2.3 MaxEnt approach for equilibrium constants
In this review, we are concerned with the application
of the MaxEnt principle to incorporate kinetic informa-
tion, for example rate constants, in the characteriza-
tion of a system. While the phase space distributions in
the MaxEnt approach preclude the description of time
dependent properties, one can use MaxEnt to impose
the ratio of rate constants, which is related to the equi-
librium constant.
In what follows, we focus on systems that exhibit two-
state kinetics between two well-deﬁned stable states,
A and B, for which there is a separation between the
molecular timescale and the reaction time [12,13]. This
guarantees that well-deﬁned rate constants, kAB and
kBA, exist for the interconversion from A to B, and vice
versa. Using the detailed balance condition kABπA =
kBAπB, with π being the equilibrium population of the
two states, it follows that
Keq = πB
πA
= kAB
kBA
.
This equilibrium constant is related to the equilibrium
fraction K = πB/(πA + πB) = 1/(1 + Keq), which
reduces to K = πB, for normalized populations. This
is an equilibrium quantity that can be treated with the
MaxEnt procedure described above by setting M = 1
and setting the sexp
1
= πB. Next, we should ﬁnd a micro-
scopic function s1(x) that can measure the equilibrium
fraction K. In the following, we denote this microscopic
function g(x). Substituting these variables in Eq. 22
gives

dxg(x)ρ(x)

dxρ(x)
= πB,
(23)
which states that the ensemble average of ⟨g(x)⟩should
be equal to πB, the fraction of conﬁgurations in state
B. Therefore, g(x) should be a function that deter-
mines whether or not a conﬁguration is part of B or
not. A possible, quite natural, deﬁnition is the (conﬁg-
urational) committor function pB(x), which gives the
probability for ending in state B, when a trajectory is
initiated in x with random velocities [56,76,121] (see
Fig. 2). While this is not an easy function to compute,
it is well deﬁned and extensively studied [56,122,123].
Note that the committor is also sometimes denoted
Onsager’s splitting probability [124], or p-fold [125] in
the context of protein folding. Here, following the tran-
sition path theory convention [126], we denote pB(x) as
the committor function. Using the committor function
pB(x), it is possible to compute the density in the basin
of attraction of state A, and that of state B, respec-
tively, as
ρA(x) = ρ(x)pA(x)
(24)
ρB(x) = ρ(x)pB(x),
(25)
where pA(x) = 1 −pB(x). Setting g(x) = pB(x), we
now can apply the MaxEnt principle to obtain the
reweighted posterior distributions
ρA(x) = ρ0
A(x)e−μApA(x)
(26)
ρB(x) = ρ0
B(x)e−μBpB(x).
(27)
The posterior densities will alter the committor func-
tion as [127]
pB(x) = ρB(x)/(ρA(x) + ρB(x)),
(28)
with respect to the original prior committor
p0
B(x) = ρ0
B(x)/(ρ0
A(x) + ρ0
B(x)),
(29)
or, by substituting the densities
pB(x) =
ρ0
B(x)
ρ0
A(x)e−μAe(μA+μB)pB(x) + ρ0
B(x).
(30)
As we need the g(x) to be correct in the posterior
ensemble average, it is clear that g(x) ≡pB(x) is not
equal to p0
B, but instead follows from numerically solv-
ing Eq. 30.
The multipliers μA and μB derive from the ensemble
average conditions, and are related to the ratio of the
123

188
Page 6 of 21
Eur. Phys. J. B (2021) 94:188
A(x)
B(x)
x
x
pB(x)
Fig. 2
Schematic illustration of how the conﬁgurational
density in state B (red area) is related to the committor
through Eq. 28
equilibrium constants as
eμA−μB = Kexp
eq /K0
eq = πexp
B
πexp
A
π0
A
π0
B
.
(31)
Using the deﬁnitions in terms of rates, this is equal to
eμA−μB = kexp
AB
kexp
BA
/k0
AB
k0
BA
.
(32)
We can then identify the multipliers μA and μB as
eμA = kexp
AB
k0
AB
eμB = kexp
BA
k0
BA
.
(33)
We will later see that this is correct by applying the
MaxCal approach.
3 Maximum caliber
3.1 The maximum caliber approach
In 1980, Jaynes proposed an extension of the maxi-
mum entropy principle for trajectories [3]. Following
the notation of Dill and collaborators [5,9,11], the path
entropy is deﬁned as
S = −

Γ
ln pΓ
qΓ
,
(34)
where Γ = {X0, X1, ...XL} denotes a sequence of dis-
crete state variables X, at diﬀerent time indices, pΓ is
the probability of such sequence, and qΓ denotes a prior
or reference distribution. The summation is over all pos-
sible sequences of states, or trajectories.
Consider a dynamical feature s(Γ) in the system that
can be computed over the trajectory ensemble
⟨s⟩=

Γ
pΓs(Γ).
(35)
According to the MaxCal approach, imposing this aver-
age as a constraint on a system can be carried out
according to the maximum entropy principle, by opti-
mizing the distribution pΓ such that it maximizes the
path entropy in Eq. 34. To do so, we again use the
method of Lagrange multipliers. The optimization func-
tion, or caliber is
L =−

Γ
ln pΓ
qΓ
−η

Γ
pΓs(Γ)−si

−ν

Γ
pΓ −1

.
(36)
This constrained caliber can, in analogy with the Max-
Ent approach, be optimized by setting the derivative
with respect to pΓ to zero, and solving for pΓ,
pΓ = e−ηs(Γ)
Z
,
(37)
with the partition function analog
Z =

Γ
e−ηs(Γ).
(38)
The path ensemble average of s is recovered by taking
the derivative of Z with respect to η
∂ln Z
∂η
= −⟨si⟩.
(39)
Solving for η gives the value of the Lagrange multiplier.
Dill and collaborators reviewed the MaxCal approach
extensively, and illustrated how it can be invoked
to obtain general principles for non-equilibrium sys-
tems, including the Onsager’s and Green–Kubo rela-
tions, Prigogine’s entropy production, and the diﬀusion
and Fokker–Planck equations. In addition, the Max-
Cal approach can be used for optimization of transition
rate matrices in Markov state models, for equilibrium
and non-equilibrium steady states [48,49]. The Max-
Cal approach also has been used for reaction coordinate
optimization [128,129].
These studies deﬁne the state space as a discrete
space, which makes the approach suitable for Markov
state models, but less so for molecular dynamics trajec-
tories in continuous space. However, as we are interested
in atomistic microscopic trajectories, our purpose is to
recast the MaxCal approach in continuous space.
3.2 Continuum path ensemble (CoPE) MaxCal
In this section, we discuss how the MaxCal approach
can be extended to the space of continuous trajectories.
Such space can be mapped using molecular dynamics
simulations, Langevin dynamics or Brownian dynamics.
A trajectory can be denoted as a ordered sequence of
frames x = {x0, x1, ...xL}, where x is a continuous space
conﬁguration as in Sect. 2.2, and the subscripts denote
the time index. Each frame is separated from the next
by a short time interval Δt, so that the total duration of
a trajectory is T = LΔt. The probability distribution
123

Eur. Phys. J. B (2021) 94:188
Page 7 of 21
188
Table 2 Deﬁnitions of variables and functions used in this work
CV
Description
ρ(x)
A conﬁgurational probability distribution, with x denoting the conﬁguration
ρ0(x)
The prior conﬁgurational probability distribution
ρME(x)
The maximum entropy posterior conﬁgurational probability distribution, after applying the constraints
si(x)
Collective variable/observable i as a function of the microscopic conﬁgurations.
sexp
i
The experimental observation/data i
kexp
AB
Experimental observation/data of transition kAB
σi
Level of conﬁdence in the data i
σkAB
Level of conﬁdence in the rate constant data kAB
μi
Lagrange multiplier associated with experimental data i
μA,B
Lagrange multiplier associated with experimental rate constant data for A (kAB), or B (kBA)
p(xi →xi+1)
Short time Markovian probability representing the evolution of the probability density
P[x]
A full path distribution, with x denoting the trajectory
P0[x]
The prior full path distribution
PMC[x]
The maximum caliber posterior path distribution, after applying the constraints
hA,B(x)
Indicator function identifying whether a conﬁguration is in state (A,B)
PA,B[x]
A partial path distribution of trajectories starting in A, or B
P0
A,B[x]
The prior partial path distribution of trajectories starting in A, B
PMC
A
[x]
The MaxCal posterior partial path distribution of trajectories starting in
A, after applying the constraints related to state A, i.e kAB
PMC
B
[x]
The MaxCal posterior partial path distribution of trajectories starting in
B, after applying the constraints related to state B i.e kBA
λ
Collective variable used to parameterize ordered set of interfaces between state A and B
λ(x)
Value of collective variable λ evaluated at conﬁguration x
λmax[x]
Maximum value of λ along an individual path x
λmin[x]
Minimum value of λ along an individual path x
PA(λn|λi)
Probability that a trajectory originating from A and crossing interface i, reaches interface n (i.e., B)
PA(λi|λ0)
Probability that a trajectory originating from A and crossing the ﬁrst interface (λ0), reaches interface i
PA(λ|λ0)
Probability that a trajectory originating from A and crossing the ﬁrst interface, reaches a value λ.
φ0
Flux through innermost interface λ0 for trajectories starting in A
fA(λ[x])
MaxCal biasing/reweighting function for pathways starting in A
fB(λ[x])
MaxCal biasing/reweighting function for pathways starting in B
P 0
A(λ|λ0)
Probability a trajectory of the prior path ensemble originating from A and
crossing the ﬁrst interface, reaches a value λ
P MC
A
(λ|λ0)
Probability a trajectory of the MaxCal posterior path ensemble originating
from A and crossing the ﬁrst interface, reaches a value λ
g(λ)
MaxEnt biasing function of the conﬁgurational densities that reassures the
experimentally determined equilibrium constant
gexp
Experimentally determined value of the conﬁgurational density observable, i.e. the equilibrium constant
ρ(λ)
Conﬁgurational density projected onto λ
ρ0(λ)
The prior conﬁgurational density projected onto λ
ρMC(λ)
The MaxCal conﬁgurational density projected onto λ
ρA,B(λ)
A conﬁgurational density projected onto λ for trajectories originating in A, B
ρ0
A,B(λ)
The prior conﬁgurational density projected onto λ for trajectories originating in A, B
ρME
A,B(λ)
The MaxEnt conﬁgurational density projected onto λ for trajectories originating in A, B
ρMC
A,B(λ)
The MaxCal conﬁgurational density projected onto λ for pathways originating in A, B
ˆρ(λ|x)
Instantaneous density operator projecting the path x on λ
R0
A(λ|λ0)
The reaching histogram for pathways originating from state A, crossing the
innermost interface λ0 and just reach the value of λ
R0
B(λ|λn)
The reaching histogram for pathways originating from state B, crossing the
innermost interface λn and just reach the value of λ
Keq
The equilibrium constant
K
The equilibrium fraction
Kexp
eq
The experimental equilibrium constant
K0
eq
The prior equilibrium constant
pB(x)
The probability that a trajectory initiated at conﬁguration x (with random
momenta) ends up in B, a.k.a. the committor
pB(λ)
The probability to end up in B, a.k.a. the committor, projected onto the collective variable λ
S(P||P0)
Relative path entropy, or Caliber, equivalent to negative KL divergence
between path distributions P and P0
123

188
Page 8 of 21
Eur. Phys. J. B (2021) 94:188
for a trajectory x is [17,55,56]
P0[x] = ρ(x0)
L−1

i=0
p(xi →xi+1),
(40)
where ρ(x0) is the initial distribution, and p(xi →xi+1)
is the short time Markovian propagator that describes
the transition from state xi to the next xi+1 in the time
interval.
In molecular dynamics, the initial condition is often
the Boltzmann distribution ρ(x) = exp(−βH(x)), with
H(x) the Hamiltonian of the system. The short-time
Markovian probability p(xi →xi+1) depends on the
dynamics used, for example for molecular dynam-
ics in the microcanonical ensemble this probability is
a δ function given by the molecular dynamics inte-
grator or propagator φ, p(xi →xi+1) = δ(xi+1 −
φ(xi)) [56]. For stochastic dynamics p(xi →xi+1) ∝
e−δx2
R/(2σ2), where δR denotes the random displacement
in the stochastic (Wiener) process, and σ2 is the vari-
ance of that displacement [54]. One can also deﬁne
a Metropolis–Hasting Monte Carlo-based dynamics
p(xi →xi+1) = min[1, e−β(H(x+1)−H(x))], where the
min function returns the lower of its arguments [54].
Besides enabling the estimate of equilibrium properties,
molecular dynamics trajectories can also oﬀer infor-
mation on dynamical and non-equilibrium properties.
Since this type of study is aﬀected by the approxima-
tions involved in the deﬁnition of the force ﬁeld, here
we are concerned with improving such description by
incorporating in the simulations dynamical information
in the form of constraints on dynamical properties such
as the rate constants.
The path entropy is now deﬁned as
S[P||P0] = −

DxP[x] ln P[x]
P0[x],
(41)
where Dx indicates an integral over all trajectories or
paths x. Following MaxEnt for continuous space, the
MaxCal approach states that the optimal distribution
P[x] is given by the maximization
PMC[x] = argmax
P[x]
S[P||P0]
subject to:

DxP[x]si[x] = ⟨si[x]⟩= sexp
i

DxP[x] = 1.
(42)
Again, the sexp
i
are experimental constraints encoded
in the microscopic observable si[x]. The ensemble aver-
age ⟨si[x]⟩refers to either static/thermodynamic or
dynamic/kinetic observables. Note that s[x] is now a
function of the entire path, which includes autocorrela-
tion functions.
Following the same procedure as for the MaxEnt
approach, we can perform this optimization by apply-
ing the method of Lagrange multipliers, and ﬁnding the
stationary point of the Lagrange function, or caliber
L = −

DxP[x] ln P[x]
P0[x] −ν
	
DxP[x] −1

−

i
μi
	
DxP[x]si[x] −sexp
i

,
(43)
by taking the functional derivative with respect to the
path distribution. This yields
δL
δP[x] = −ln P[x]
P0[x] −1 −

i
μisi[x] −ν,
(44)
which gives in turn the posterior distribution
PMC[x] ∝e−
i μisi[x]P0[x],
(45)
as a reweighting of a given prior distribution P0[x].
In Fig. 1 we illustrate the eﬀect of the CoPE-MaxCal
procedure in reweighting the prior path distribution,
thereby identifying a posterior distribution which meets
a given experimental constraints sexp
i
, which can be for
instance a rate constant. It is important to realize that
the trajectories are not changing, but only the weights
with which they occur in the ensemble. This is analo-
gous to the fact that the conﬁgurations are not changing
in the MaxEnt procedure.
3.3 CoPE-MaxCal for dynamical constraints
In this section, we discuss the application of the CoPE-
MaxCal approach to incorporate dynamical informa-
tion as constraints in the description of a system. This
can be achieved for instance using a correlation function
c(t) deﬁned as
c(t) = ⟨si(0)sj(t)⟩=

DxP[x]si(x0)sj(xτ),
(46)
where the observable si at time t = 0 is correlated with
observable sj a later time t. As i and j can be identical,
this deﬁnition includes autocorrelation functions. In the
second equation, we have used the explicit dependence
si,j(xτ) as a function of the conﬁguration xτ, with τ =
t/Δt corresponding to the frame index for time t.
Experimental information about the dynamics of a
system in the form of correlation data cexp(t) can be
imposed as a constraint on the path ensemble distribu-
tion, giving the Lagrange function
L = −

DxP[x] ln P[x]
P0[x] −ν
	
DxP[x] −1

−

τ
μτ
	
DxP[x]si(x0)sj(xτ) −cexp(t)

.
(47)
123

Eur. Phys. J. B (2021) 94:188
Page 9 of 21
188
Following the optimization procedure gives
δL
δP[x] = −ln P[x]
P0[x] −1 −

τ
μτsi(x0)sj(xτ) −ν,
(48)
yielding the posterior distribution
PMC[x] ∝e−
τ μτ si(x0)sj(xτ )P0[x].
(49)
As an example, consider the mobility Kτ[x], measur-
ing the mean square displacement at a particular time
τ with respect to time τ = 0. As this correlation only
has to be constrained at τ, the posterior is
PMC[x] ∝e−μτ Kτ [x]P0[x].
(50)
Note that this is also the expression for the s-ensemble
(with μ = s, where s should not be confused with
the observable function s[x]). In the s-ensemble path
ensembles are biased according to a time correlation
function [51,105–110]. This s-ensemble is usually pre-
sented in the context of large deviation theory, but
clearly follows also from the MaxCal approach. The s-
ensemble biases all paths with a ﬁeld s conjugate to
the function K. In the MaxCal approach, the Lagrange
multiplier μ follows from the constraint imposed. Thus,
the s-ensemble might also be interpreted as the ﬁeld
that imposes a certain constraint.
3.4 MaxCal for thermodynamic constraints
Since equilibrium properties are not time dependent,
they can be computed as time averages over path
ensembles distributions
⟨s⟩=
1
⟨L⟩

DxP[x]

t
s(xt),
(51)
with ⟨L⟩being the average path length, and xt the coor-
dinates at each time step of the path. Constraining an
equilibrium property sexp then leads to a posterior dis-
tribution
PMC[x] ∝e−μ 
t s(xt)P0[x].
(52)
An alternative way of constraining equilibrium proper-
ties is to ﬁrst reduce the path space back to a conﬁgu-
rational density ρ(x) ≡P(x) by
ρ(x) ∝

DxP[x]

t
δ(xt −x).
(53)
The average then becomes
⟨s⟩=

dxρ(x)s(x)

dxρ(x)
.
(54)
Indeed, substitution of Eqs. 52 and 53 in Eq. 54 yields
the same result as Eq. 51.
4 Continuum path ensemble maximum
caliber for rate constants
4.1 Independence of partial path distributions
In the above sections, we did not specify the path
ensembles precisely. When considering systems that
show two-state kinetics between two stable states, A
and B, with forward and backward rate constants,
kAB and kBA respectively, we can think about partial
path ensembles PA[x] and PB[x], consisting, respec-
tively, of all paths that start in A and paths that
start in B. We can deﬁne these partial ensembles as
PA[x] ≡P[x]hA(x0) and PB[x] ≡P[x]hB(x0), where
hA,B(x) are the indicator functions, which are unity
when the conﬁguration x is in state A(B), and zero oth-
erwise. Restricting all paths to start and end in one of
the stable states, the total path distribution is simply
the sum of the non-normalized partial path distribu-
tions P[x] = PA[x] + PB[x].
We apply diﬀerent constraints sA and sB to both
partial ensembles we arrive at the Lagrange function
L = −

DxP[x] ln P[x]
P0[x] −ν
	
DxP[x] −1

−μA
	
DxP[x]hA(x0)sA[x] −sexp
A

−μB
	
DxP[x]hB(x0)sB[x] −sexp
B

,
(55)
where we used the deﬁnition of the partial ensembles.
Maximization of the caliber yields the posterior
PMC[x] ∝e−μAhA(x0)sA[x]−μBhB(x0)sB[x]P0[x], (56)
or, expressing it in partial ensembles
PMC
A
[x] + PMC
B
[x] ∝
∝e−μAhA(x0)sA[x]−μBhB(x0)sB[x](P0
A[x] + P0
B[x]).
(57)
For paths belonging to partial ensemble A, hA(x0) = 1
and thus hB(x0) = 0, leading to
PMC
A
[x] ∝e−μAsA[x]P0
A[x],
(58)
while for paths from partial ensemble B, hA(x0) = 0
and hB(x0) = 1 it holds
PMC
B
[x] ∝e−μBsB[x]P0
B[x].
(59)
Thus, both partial ensembles can be optimized and nor-
malized independently.
123

188
Page 10 of 21
Eur. Phys. J. B (2021) 94:188
4.2 CoPE-MaxCal for rate constants
One can apply a rate constant as a kinetic constraint
by setting sexp
A
≡kexp
AB, and sexp
B
≡kexp
BA. However, we
also need a microscopic dynamical correlation function
for this constraint
C(t) = ⟨hA(x0)hB(xτ)⟩/⟨hA(x0)⟩.
(60)
The observed rate constant is the time derivative of this
function, measured at the plateau value [12]
kAB = dC(t)
dt
= ⟨hA(x0)˙hB(xτ)⟩
⟨hA(x0)⟩
.
(61)
The rate is, thus, the ﬂux through the boundary of state
B, given that the trajectory started in state A.
At this point, we are switching to the language
of transition path sampling [54–56], and in particular
transition interface sampling [57], as this allows us to
write the rate constant in terms of the path probability
P[x]. In the TIS method, the conﬁguration space is foli-
ated by a set of non-intersecting interfaces parametrized
with a collective variable λ(x). This set of n + 1 inter-
faces is denoted {λ0, λ1...λn}. Taking λ0 and λn as the
boundary of A and B, respectively, the rate is expressed
as the eﬀective positive ﬂux φ through these interfaces
kAB = φn = φ0PA(λn|λ0),
(62)
where φi denotes the eﬀective positive ﬂux through
interface i. In the second equation, we have deﬁned the
crossing probability PA(λn|λ0) for a trajectory to reach
interface λn, under the condition that it has already
crossed λ0 = λA. Note that φ0 is usually large, and easy
to obtain from a molecular dynamics simulation in state
A, while PA(λn|λ0) is usually very small, and diﬃcult to
compute. While it is in principle (and sometimes even in
practice) possible to obtain this also from a brute force
molecular dynamics simulation, it is much more eﬃcient
to compute via TPS [17,54,56,130,131], TIS [57–59],
Forward Flux Sampling [111,112], or other trajectory-
based methods. In these sampling approaches, we can
construct a path ensemble by reweighting the paths,
yielding the so-called reweighted path ensemble [132],
which constitutes a collection of paths with an asso-
ciated weight, representing the probability to observe
that path in an unbiased simulation, i.e., PA[x]. This
reweighted path ensemble is related to the crossing
probability by
PA(λ|λ0) =

DxPA[x]θ(λmax[x] −λ),
(63)
where λmax[x] returns the maximum value of λ(x) along
the trajectory, and the Heaviside step function θ returns
unity for the paths that cross the λ interface, assuming
that λ monotonically increases when going from A to
B. This function can take the place of the microscopic
correlation function in the Lagrange function, giving
L = −

DxPA[x] ln PA[x]
P0
A[x] −ν
	
DxPA[x] −1

−μ′
A
	
φ0

DxPA[x]θ(λmax[x] −λB) −kexp
AB

.
(64)
Optimizing this function as before leads to the poste-
rior
PMC
A
[x] ∝e−μ′
Aφ0θ(λmax[x]−λB)P0
A[x],
(65)
We can now solve for the Lagrange multiplier by con-
structing a log partition function as in Eq. 21
ΓMC(μ′
A) = ln

DxPMC
A
[x]

+ μ′
Akexp
AB,
(66)
taking the derivative with respect to the μ′
A and setting
it to zero
−

DxPMC
A
[x]φ0θ(λmax[x] −λB)

DxPMC
A
[x]
+ kexp
AB = 0. (67)
Since only the paths that reach the ﬁnal interface are
contributing to the θ function, this changes into

DxP0
A[x]e−μ′
Aφ0φ0θ(λmax[x] −λB)

DxP0
A[x]
= kexp
AB, (68)
where we replaced the P with P0 in the normalization,
which hardly aﬀects it. The exponent on the left hand
side can be taken out of the integral, yielding

DxP0
A[x]φ0θ(λmax[X] −λB)

DxP0
A[x]
e−μ′
Aφ0 = k0
AB.e−μ′
Aφ0
= kexp
AB.
(69)
The exponential factor needs to be larger than unity
for an increase in the rate, which is then associated
with a negative Lagrange multiplier μ′
A. As we prefer
to associate a positive variable with an increase in rate,
we deﬁne μA ≡−μ′
Aφ0 yielding
k0
ABeμA = kexp
AB,
(70)
Indeed, a positive μA now increases the rate.
4.3 Imposing a rate constraint for all λ
In the above procedure, only the reactive AB paths in
the prior ensemble are reweighted to yield a given rate
constant. However, while this imposes the experimental
rate constant, it does lead to an undesirable discontinu-
ity at the boundary of λB. Moreover, the rate cannot
123

Eur. Phys. J. B (2021) 94:188
Page 11 of 21
188
be strongly dependent on where precisely this bound-
ary is located. More precisely, the rate can be expressed
as the product of two crossing probabilities [57]
kAB = φ0PA(λB|λi)PA(λi|λ0).
(71)
We can now interpret the λi as the interface that we put
the kinetic constraint on. Since this location is arbitrary
for 0 < i < n we impose constraints on all these λ values
simultaneously. This leads to the following Lagrange, or
caliber, function
L = −

DxPA[x] ln PA[x]
P0
A[x] −ν

DxPA[x] −1

−
n

i=0
μi
×

DxPA[x]θ(λmax[x] −λi)PA(λn|λi) −kexp
AB

,
(72)
where the sum runs over the n + 1 interfaces. In each of
the constraints in the summation the paths that cross λi
are counted, and PA(λn|λi) is the crossing probability
to reach B from the λi interface. Optimization leads to
the MaxCal posterior path distribution
PMC
A
[x] ∝exp

−
n

i=0
μiθ(λmax[x] −λi)PA(λn|λi)

P0
A[x].
(73)
Note that the PA(λn|λi) in this equation is dependent
on the posterior distribution itself, and hence this is
an implicit deﬁnition. The sum in the exponent is only
dependent on λmax[x] (and of course on PA(λn|λ)), but
for a given system PA(λn|λ) is a function of λ, so the
sum can be written as
−
n

i=0
μiθ(λmax[x] −λi)PA(λn|λi) ≡fA(λmax[x]),
(74)
where the PA(λn|λ) dependence is implicit in the func-
tion fA. The interpretation is that the weight of each
trajectory in the posterior path ensemble is entirely
dependent on λmax[x].
The n+1 constraints imposed are given for k = 0...n,

DxPMC
A
[x]θ(λmax[x] −λk)PA(λn|λk) = kexp
AB,
(75)
with
PMC
A
[x] ∝efA(λmax[x])P0
A[x],
(76)
In Ref. [46] it is shown that these constraints can ful-
ﬁlled for any reasonably continuous function fA(λ), as
long as fA(λB) = μA, and fA(λ0) = 0.
We can simplify the function by considering all paths
that reach a maximum at λj. Due to the θ function in
Eq. 74 only interfaces 0 < i < j contribute to the sum,
leading to
fA(λj) = −
j

i=1
μiPA(λn|λi).
(77)
The function fA(λ) will be determined in the next
section. Figure 3 shows schematically how the TIS,
reweighted
path
ensemble
and
CoPE-MaxCal
approaches are related in terms of interface ensembles
based on λ.
The prior path distributions can be projected on the
collective variable (CV) or order parameter λ. In par-
ticular, the crossing probability P 0
A(λ|λ0) and conﬁgu-
rational density ρ0
A(λ) are expressed as
P 0
A(λ|λ0) =

DxP0
A[x]θ(λmax[x] −λ),
(78)
ρ0
A(λ) ∝

DxP0
A[x]ˆρ(λ|x),
(79)
where we deﬁned the instantaneous density projection
operator
ˆρ(λ|x) =
L[x]

k=0
δ(λ(xk) −λ),
(80)
to project a single path x on the CV λ. These projec-
tions can also be done for the posterior distribution,
leading to the conﬁgurational density ρMC
A
(λ)
ρMC
A
(λ) ∝

DxP0
A[x]efA(λmax[x])ˆρ(λ|x),
(81)
and for the crossing probability
P MC
A
(λ|λ0) =
 λ
λn
R0
A(λ|λ0)efA(λ)dλ,
(82)
where we deﬁned the prior probability R0
A(λ|λ0) for a
path to just reach the interface λ
R0
A(λ|λ0) =

DxP0
A[x]δ(λmax[x] −λ).
(83)
4.4 The MaxCal bias function fA(λ) follows from
MaxEnt for the density
The function fA(λ) above is not completely speciﬁed.
However, we can make use of the density obtained by a
MaxEnt reweighting of the same system. In particular,
we can set
ρMC
A
(λ) = ρME
A
(λ).
(84)
123

188
Page 12 of 21
Eur. Phys. J. B (2021) 94:188
A
B
A
B
TIS
RPE
CoPE MaxCal
A
B
Fig. 3
Schematic illustration of the relationship between the TIS, reweighted path ensemble (RPE) and CoPE-MaxCal
approaches. (Left) TIS simulations samples paths that cross a certain interfaces. The single path shown for each interface
represents a whole ensemble. (Center) The RPE follows by reweighting the path ensembles sampled in TIS. Weights are
schematically indicated by the line thickness. (Right) After application of the CoPE-MaxCal to impose a rate constant
constraint the paths in the RPE are reweighted with the fA function, as indicated by color. Lighter colors indicate more
strongly aﬀected weights
In the MaxEnt Sect. 2.3, we imposed the equilibrium
fraction by
ρME
A
(λ) = e−μAg(λ)ρ0
A(λ),
(85)
where we projected the conﬁgurational density on the λ
parameter. Like in Sect. 2.3, we can use the committor
to impose the constraint, g(λ) = pB(λ), where pB(λ) is
now the projected committor. This committor follows
from the implicit equation Eq. 30. This procedure leads
to the following condition for the densities

DxP0
A[x]efA(λmax[x])ˆρ(λ|x) = e−μg(λ)

DxP0
A[x]ˆρ(λ|x),
(86)
which should be solved numerically.
We can also use the full (conﬁgurational) committor
pB(x), which gives

DxP0
A[x]efA(pmax
B
[x])ˆρ(x|x) = e−μpB(x)

DxP0
A[x]ˆρ(x|x),
(87)
where pmax
B
[x] returns the maximum committor value
along the trajectory x. Clearly, this might be very dif-
ﬁcult to obtain in practice.
4.5 Application of CoPE-MaxCal to protein folding
The CoPE-MaxCal approach enables the investigation
of mechanistic properties for instance the location of
the transition state, by imposing experimental transi-
tion rates. In this section we brieﬂy highlight an appli-
cation of the MaxCal approach on the folding of a
small protein, which we presented in Ref. [46]. Taking
information from a long molecular dynamics simula-
tion [133], we constructed the prior path distributions
and predicted rates [46]. Since the force ﬁeld did not
reproduce the folding rate correctly at the expected
melting temperature, we imposed the correct experi-
mental folding rate using the CoPE-MaxCal procedure
[46]. The reweighted path ensembles led to a reweighted
free energy and committor landscape. Importantly, the
imposed rate caused a shift in predicted transition state
(see Fig. 4), that provides a qualitative change in mech-
anistic insight. We refer to Ref. [46] for more details and
examples.
4.6 Interpretation of the CoPE-MaxCal method
The CoPE-MaxCal method takes as input an unbiased
ensemble of paths from molecular dynamics simula-
tions, or a reweighted path ensemble [132] from TIS [57]
or Virtual Interface Exchange TPS [134], and reweights
each trajectory in this ensemble according to how far
it progresses along a predeﬁned collective variable (see
a rendering in Fig. 5). This includes the paths that
cross the barrier and reach the ﬁnal state, so the rate
constants are automatically constrained to the correct
value via the functions fA,B(λ). The more involved part
of the framework is to ensure that the thermodynamic
properties are correct, in particular the equilibrium con-
stant. This requires a speciﬁc bias function g(λ) based
on the committor function, which produces the least
perturbed path ensemble, while still obeying the con-
straints (see Sect. 2.3). So, imposing g(λ) can be viewed
as responsible for constraining equilibrium conditions,
whereas fA,B(λ) takes care of the dynamical correc-
tions. The interpretation of the reweighting procedure
is that trajectories are artiﬁcially made more, or less,
probable in the path ensembles. This is analogous to
changing the weight of each conformation in the Boltz-
mann distribution, using the MaxEnt approach. Note
that the trajectories themselves do not change in the
reweighting procedure. Rather, the distribution of ini-
tial conditions is adjusted. This is analogous, but not
identical, to how microcanonical trajectories can be
reweighted to give a canonical distributed path ensem-
ble (see, e.g., Ref. [135]).
123

Eur. Phys. J. B (2021) 94:188
Page 13 of 21
188
Fig. 4
Illustration of the movement of the transition state
for protein folding when the folding rate constant is imposed
using the CoPE-MaxCal method
A
B
A
B
original paths
kinetically reweighted paths
high
weight
normal
Fig. 5
Cartoon of how the method reweights paths in a
complex landscape
5 Extensions
5.1 Multiple state descriptions
The MaxCal method can be extended to multiple
states. For multiple states, the kinetics is described
by a rate matrix K with entries kij for each pair of
states i and j. Incorporating multiple rate constants
in the ensembles adds additional constraints to the cal-
iber function, which ensures that the ﬂuxes through the
ﬁnal interfaces are correct, and yields the following path
reweighting
PMC
i
[x] ∝efi(λmax
i
[x])P0
i [x],
(88)
where the function fi is now deﬁned for each state, as
function of the maximum value along an order param-
eter, that is possibly diﬀerent for each state. Note that
by changing the weight of state i all rates out of i are
changed in the same way. Thus ki,j = cik0
i,j , i.e., all
the rates from state i change proportionally by the same
factor. This leads to a consistent description.
The other ingredient, the MaxEnt part, is based on
the committor. Applying a correction to the imposed
equilibrium constant Kij = πj/πi = kij/kji. means
that the densities for each basin of attraction ρi(x) are
reweighted by
ρi(x) = ρ0
i (x)e−μipi(x),
(89)
where pi is the committor to state i with 
i pi = 1
[136]. Using the deﬁnition
pi(x) =
ρi(x)

i ρi(x).
(90)
This implicit equation for pi(x) can be solved numeri-
cally for a given ρ0
i (x). This gives rise to the MaxEnt
reweighting by setting gi(x) = pi(x)
ρME
i
= ρ0
i (x)e−μipi(x),
(91)
which in turn can be related to the MaxCal condition
ρMC
i
(x) = e−μipi(x)ρ0
i (x),
(92)
or

DxP0
i [x]efi(pi,min[x])ˆρ(x|x)
= e−μipi(x)

DxP0
i [x]ˆρ(x|x),
(93)
where the minimum of the committor pi to state i is
searched for along the path. Note that we have to use
the minimum along the pathway now, since the com-
mittor starts high, being close to the initial state, and
then slowly decreases to zero as the reaction progresses.
It is also possible to project the committor to an
order parameter λi, connected to each state. A numer-
ical solution should then lead to a set of committor-
based bias functions pi(λi). We leave the speciﬁc details
for future work.
5.2 An alternative formulation of the MaxCal
approach
In this section, we discuss whether one could establish
a MaxCal approach by including the equilibrium den-
sity constraint directly in the MaxCal procedure. This
would give an additional constraint to fulﬁll
ζA
	
dx

DxPA[x]ˆρ(x|x) −πexp
A

= ζA
	
DxPA[x]L[x] −πexp
A

.
(94)
One could include this constraint in the MaxCal
approach, which would lead to an additional weighting
factor
P[x] = P0[x]efA(λmax[x])e−ζAL[x],
(95)
where the ζ multiplier would be determined by solving

Pi[x]L[x] = πi,
(96)
123

188
Page 14 of 21
Eur. Phys. J. B (2021) 94:188
and where one should use the non-normalized distri-
butions to obtain the correct relative path ensemble
weights. This could in principle be done but has a seri-
ous downside, namely that the paths are weighted with
the instantaneous path length L[x], which is sensitive
to the A and B deﬁnition, and hence seems arbitrary.
Moreover, this is not what we do in the CoPE-
MaxCal approach. Instead, we state that the MaxCal
method should reproduce the MaxEnt density ρME
A
(x)
at each conﬁguration x. This means that, in fact, we
are introducing many constraints, one for each conﬁgu-
ration point x, yielding an additional set of constraints

dxζA(x)
	
DxPA[x]ˆρ(x|x) −ρME
A
(x)

=

dxζA(x)
	
DxPA[x]ˆρ(x|x)
−e−μAg(x)

DxP0
A[x]ˆρ(x|x)

,
(97)
where g(x) is again the MaxEnt biasing function deﬁned
in Sect. 2.3. This set of constraints ensures that the
densities match at all conﬁgurations x. The path weight
is then
P[x] ∝P0[x]efA(λmax[x])e−

dxζA(x)ˆρ(x|x),
(98)
where the ζA(x) multiplier would be determined by
solving the root of the derivative of the log partition
function with respect to the ζA(x)

DxPA[x]ˆρ(x|x) = ρME
A
(x).
(99)
Indeed, imposing this equation is at the heart of the
CoPE-MaxCal method. Note that this implies that the
equilibrium constant is also correctly reproduced. Note
also that the constraint is stronger than what is needed
from MaxCal alone. However, we stress for an equilib-
rium system the MaxEnt approach should give a distri-
bution that is consistent with the MaxCal one.
5.3 Eﬀects of the errors in the measurements
The MaxEnt principle can be used to model uncertain-
ties in the experimental data [24,28–30]. This is done
by adding to the constraint average ⟨si⟩the expected
error ⟨ei⟩due to the perturbed distribution, leading to
⟨si⟩= sexp
i
+ ⟨ei⟩.
(100)
When the error is Gaussian distributed with a standard
deviation σi, this average expected error is given by
⟨ei⟩= −μiσ2
i ,
(101)
where σi can be interpreted as the level of conﬁdence
in the experimental measurements or data. One can
include this into the Langrange function and obtain
Γ(μ) = ln

dxP ME(x)

+ μ · sexp + 1
2
M

i=1
μ2
i σ2
i .
(102)
Optimizing this function, and solving for the Lagrange
multipliers μi thus takes the level of conﬁdence into
account. Setting σ = 0, the level of conﬁdence is so high
that it is actually a constraint, and leads to the original
Eq. 21. When σ is set large, the Lagrange multiplier μi
will become smaller, and the optimized distributor will
hardly diﬀer from the original distribution. Thus, this
procedure changes the constraint into a restraint, tuned
by the level of conﬁdence in the data.
The MaxCal equation can also be adjusted to incor-
porate the errors in the data, leading to the analog of
Eq. 102
k0
ABeμA = kexp
AB + μAσ2
kAB,
(103)
where σkAB represents the level of conﬁdence in the
rate constant data. Thus, one can turn the constraint
condition into a restraint condition.
5.4 CopE-MaxCal and machine learning
The MaxCal method aims at incorporating experimen-
tal data in molecular simulations by a path reweight-
ing function fA(λ). Since the computation of fA(λ)
from
Eq. 86 might be not always trivial, one might
use advanced regression procedures, such as those pro-
vided by machine learning methods. In addition, when
considering the more general form of the function,
fA(pB,max[x]), machine learning methods might be
invoked to optimize both the fA function as well as the
committor description in terms of CVs. This direction
of research is left for future exploration.
5.5 Optimization of a collective variable with
CoPE-MaxCal
By inspecting the CoPE-MaxCal approach, one realizes
that the path reweighing depends on the choice of the
collective variable λ. For a diﬀerent choice of λ, one
would get a diﬀerent weight function, and hence caliber.
So, it should be possible to optimize the caliber function
over all possible CVs.
In principle, it is possible to vary the collective vari-
able and maximize the entropy and caliber as function
of this CV. The most optimal collective variable is then
the one that leads to the least perturbed path distribu-
tion. To do so, we can substitute the optimized MaxCal
distributions PMC
A
[x] = C−1
A P0
A[x] exp[fA(λmax[x])]
and PMC
B
[x] = C−1
B P0
B[x] exp[fB(λmin[x])], with CA, CB
normalization constants for these distributions, into
the path entropy expression. Here, we can make use
123

Eur. Phys. J. B (2021) 94:188
Page 15 of 21
188
of the reaching histograms approach R0
A(λ|λ0), and
R0
B(λ|λn). It follows that
S[PA||P0
A] = −1
CA

dλR0
A(λ|λ0)efA(λ)(fA(λ) −ln CA)
S[PB||P0
B] = −1
CB

dλR0
B(λ|λn)efB(λ)(fB(λ)−ln CB),
(104)
where the normalization CA =

dλR0
A(λ|λ0)efA(λ),
is now in terms of the reaching histograms. While in
the above all sub-distributions P0
A, PA, PB, P0
B are sup-
posed to be normalized, we require the normalized total
path distributions P and P0, when computing the total
entropy In terms of S[PA||P0
A] and S[PB||P0
B], deﬁned
above, the total path entropy becomes
S[P||P0] = αS[PA||P0
A] + (1 −α)S[PB||P0
B]
+ α ln α
α0
+ (1 −α) ln 1 −α
1 −α0
,
(105)
with α = CA/(CA + CB), and α0 = C0
A/(C0
A + C0
B).
It is now possible to compare combinations of diﬀer-
ent CVs with each other and select the best combina-
tion that optimizes the caliber, i.e disturbs the original
distribution as little as possible. This gives thus an addi-
tional variational principle. Going back to the original
caliber maximization over the distribution, we can add
a second level of optimization
PMC[x] = argmax
P[x],λ
S[P||P0]
subject to:
⎧
⎪
⎨
⎪
⎩

DxPB[x]f (λi)
A
[x] = kexp
AB

DxPB[x]f (λi)
B
[x] = kexp
BA

DxP[x] = 1.
(106)
with f (λi)
A
[x] = θ((λmax[x]−λi)P(λB|λi)), and f (λi)
B
[x]
= θ((λmin[x] −λi)P(λA|λi)), the instantaneous mea-
sures for the rates. The additional maximization over
the CV space gives, thus, the best set of CVs. Such a
procedure is very similar to reaction coordinate opti-
mization [128,137–141].
5.6 CoPE-MaxCal as a variational principle?
In the previous section, we discussed how varying the
collective variables until the path entropy is maximized
yields the best set of CVs, i.e., the reaction coordinate.
It seems, therefore, natural to identify the committor
pB as the best collective variable, or reaction coordi-
nate, since it predicts for each conﬁgurations the prob-
ability to end in B. But why should the MaxCal proce-
dure give the same reaction coordinate? In other words,
why would the path entropy be optimal when the com-
mittor is chosen as a CV?
This question can be addressed by showing that when
deviating from the optimal CV, i.e., the committor
function, one always increases the KL divergence, i.e.,
lowers the path entropy. This would be the case even
for very small perturbations, i.e., in the limit μ →0.
Such a ﬁnding would amount to establishing a varia-
tional principle.
To justify such a principle, we can take a closer look
at the path entropy and its behavior for a given path
distribution. We consider ﬁrst an illustrative example
in Fig. 6.
For a path ensemble in 2D space of a 3 × 3 grid,
we consider two cases, a diagonal and a horizontal
CV. From the symmetry of the problem, the left panel
should represent the best CV, with the maximum path
entropy S or the lowest KL divergence, the negative of
S, which is always positive (or zero). To show that we
reconsider the expressions for the negative entropy, and
change from a integral expression to a discrete version
for the sake of this illustration. The KL divergence is
then written as
DKL = −S =
1
CA

i
Riefi(fi −ln CA
C0
A
),
(107)
where we used Ri as the discrete version of the reach-
ing histogram R(λ|λ0), and fi as the discrete version
of f(λ). The normalization constant C0
A = n
i Ri,
CA = n
i Riefi. Substitution of these expressions into
the above equation gives
DKL =

i=0 Riefifi

i=0 Riefi
−ln

i=0 Riefi

i=0 Ri
.
(108)
We can simplify this expression by taking a factor f0 out
of the ﬁrst and a factor ef0 out of the second fraction,
diagonal CV
horizontal CV
Fig. 6
CoPe-MaxCal as a variational principle. We show a
path ensemble in 2D space of a 3×3 grid emanating from the
bottom left cell, which is part of state A. In both panels,
the same prior path ensemble is considered. The coloring
of the paths shows the prior weight of the trajectories. Blue
indicates a higher weight, while green and red lower weights.
The CV foliation is shown as shades of yellow cells (from
dark to light is bin 0, 1 and 2). Also shown is a indication
of the location of the barrier in the projection on the CV.
This is the best estimate of the location of the barrier in
each CV
123

188
Page 16 of 21
Eur. Phys. J. B (2021) 94:188
and canceling out several factors: where the f0 terms
cancel
DKL =

i=1 Riefi(fi −f0)

i=0 Riefi
−ln
	
1 +

i=1 Ri(efi−f0 −1)

i=0 Ri

(109)
Up to now, we made no assumptions. Next, we con-
sider the small perturbation limit μ ≪1. This means
that |f| ≪1. The logarithm can then be replaced, yield-
ing
DKL =

i=1 Riefi(fi −f0)

i=0 Riefi
−

i=1 Ri(efi−f0 −1)

i=0 Ri
.
(110)
Combining the two fractions gives
DKL =

j=0

i=1 RjRiefi(fi −f0) −Rjefj Ri(efi−f0 −1)
(
i=0 Riefi)(
i=0 Ri)
=

j=0

i=1 RjRi

efi(fi −f0) −efj (efi−f0 −1)

(
i=0 Riefi)(
i=0 Ri)
.
(111)
The second assumption that we can make is that the
R0 is the largest contribution to the path ensemble.
This represents the paths that make small excursions
from the stable state. In fact, R0 can be made expo-
nentially larger than the next terms in the summation,
if the barrier is high enough. This means that we can
approximate DKL by only keeping the j = 0 term.
DKL ≈

i=1 R0Ri

efi(fi −f0) −(efi −ef0)

R0R0
.
(112)
The next step is to realize that the bias f0 →0, which
means that we obtain
DKL = 1
R0

i=1
Ri

efi(fi) −(efi −1)

.
(113)
Finally, since all biases are small, due the fact that we
choose μ ≪1, we can expand the exponential giving
DKL = 1
R0

i=1
1
2Rif 2
i .
(114)
The above reasoning shows that in the limit of small
μ, the path entropy, i.e., the KL divergence, scales with
the square of the bias f-function (thus, being always
positive as expected), and is linear in the value of the
reaching histogram, the number of paths reaching a cer-
tain bin. This derivation shows that this KL divergence
should be minimal for the optimal CV.
The f-function is changing with the choice of the CV,
but not strongly, as we assume |f| ≪1. This means
that the most important factor is the Ri. This then
establishes a variational principle. Either f goes to zero
(i.e., no perturbation), which is a trivial solution, or the
CV is chosen such that the path reaching histogram Ri
becomes minimal.
This path density is minimal for a CV that is aligned
with the committor, for the following reason. Reactive
paths have to go through a bottleneck where the path
density Ri is low. When the CV is the committor, this
Ri is the density of reaching paths that is measured.
Any deviation from this optimal CV will include paths
that are not part of the bottleneck, with a higher path
density. This will then increase the KL divergence, or
lower the path entropy. This is illustrated in the ﬁg-
ure 6, where only 3 bins are considered: R0, R1 and R2
(indicated by the yellow shades in the cells). The diag-
onal CV has only 3 paths in R1 (the green paths), but
the horizontal CV also picks up the blue paths in the
lower middle cells, which have a much higher weight (as
they do not reach the barrier). This increase in Ri is
much more inﬂuential than the marginal change in fi
due to the change in variable. In fact, for this example
the function f only changes by 1% between the CVs.
While this is just an example, it is possible that this
variational principle holds more generally. In fact, the
concept of lowest path density Ri for the best CV is
reminiscent of the variational transition state theory
[142], which states that the best CV is the one that has
the highest barrier, or lowest rate. In our treatment, the
rate constant does not change since the reactive path-
ways do not change. Still, the conﬁgurational density
for both the A and B ensembles projected on the CV,
directly gives the free energy as we have seen above.
Thus, optimizing the CV using MaxCal is consistent
with optimizing the free energy barrier in the sense of
the variational transition state theory.
6 Conclusions and outlook
6.1 Summary
In this review, we have described the MaxEnt and
MaxCal approaches and their extensions to continuum
path ensembles through the CoPE-MaxCal method.
This strategy enables the deﬁnition of the least per-
turbed path ensemble consistent with given external
information, i.e., the trajectory ensemble of maximum
relative path entropy under given constraints. We have
focused in particular on imposing kinetic rate constants
on the continuous path ensembles obtained by molecu-
lar dynamics simulations of rare events. We have shown
how this can be done by a reweighting function depend-
ing on the maximum value of a collective variable along
the trajectory. To obtain this function, we made use of
the MaxEnt approach to impose the equilibrium con-
stant.
The CoPE-MaxCal optimized trajectory ensemble
can yield new information for other observables. One
example is a shift in transition state, which we dis-
123

Eur. Phys. J. B (2021) 94:188
Page 17 of 21
188
cussed in the previous section. Other kinetic proper-
ties might include residual dipolar couplings in NMR
spectroscopy.
Besides reviewing the CoPE-MaxCal method, we
have discussed several further additional directions of
investigations of this method, including an extension to
multiple states, and the relationship of the MaxCal col-
lective variable optimization with reaction coordinate
optimization methods.
To provide an outlook, we present here some open
questions and future directions.
6.2 Incorporation of time-resolved experimental
measurements
An potential extension and application of the CoPE-
MaxCal framework involves the addition of constraints
on the evolution of time-dependent variables. In this
way, one goes beyond adding a constraint on the ﬁnal
reactive ﬂux into a certain state (the rate constant)
for trajectories starting in a diﬀerent initial state. This
extension can be obtained for example by starting from
the correlation function in Eq. 46. This would result
in a reweighting of the existing trajectories based on
constraints added at each time, as derived in Eq. 49.
Such time-dependent experimental data could be pro-
vided for example by time-dependent small angle X-ray
scattering (SAXS) [33,41,42,143] and time-dependent
solution cryo-electron microscopy [144].
6.3 Rational design of mutations and lead
compounds in drug discovery
We envision that a combination of our CoPE-MaxCal
framework (providing more accurate path ensembles)
with perturbative interaction models can result in
kinetics-mutation
landscapes
and/or
kinetics-lead-
compound-optimization landscapes. This will, thus,
constitute a relatively inexpensive way to non-random
design of biomolecular mutation and lead compound
derivatives that modify the barrier in the desired direc-
tion, as opposed to random design of mutations that
have to be tested experimentally, or in expensive addi-
tional simulations.
6.4 Biased molecular dynamics simulations
In its initial implementation, the CoPE-MaxCal method
utilizes unbiased molecular dynamics simulations, pos-
sibly with the help of enhanced path sampling such as
TPS, thereby preserving the correct kinetics up to the
accuracy of the force ﬁeld. Yet, advances in compu-
tational structural biology methods enable incorporat-
ing experimental data in the form of restraints or con-
straints [28–32,34–36,38,39,43] by biasing the Hamilto-
nian, while providing free energies that maximally meet
the experimental restraints or constraints. These obser-
vations raise the question whether the CoPE-MaxCal
approach can be combined with such biasing methods,
even if they cannot reproduce the natural kinetics.
Obtaining a free energy landscape using enhanced
sampling, and then performing unbiased molecular
dynamics, might be a viable way to reconstruct unbi-
ased kinetics. For instance, trajectories from infrequent
metadynamics or frequency adaptive metadynamics
[145–148] can subsequently be reweighted to meet given
kinetic constraints.
Finally, the Filizola and Keller groups recently
explored the use of biased molecular dynamics simula-
tions and subsequent application of constraints on con-
ﬁgurational ensemble averages that result in the alter-
ation of an transition-probability matrix to reconstruct
the unbiased kinetics [149,150].
6.5 Force ﬁeld optimization for molecular kinetics
Molecular dynamics is in principle capable to pro-
vide quantitative predictions about the thermodynam-
ics and kinetics of a system at the atomistic level.
However, the accuracy of the calculations is limited
by the quality of the force ﬁelds, which are typically
parameterized using quantum mechanical calculations
and experimental measurements of equilibrium prop-
erties [14]. There are several methods using MaxEnt,
Bayesian inference and force-matching techniques that
pursuit the development of such force ﬁelds [28,151–
155]. However, there is still a need of further method-
ological advances in this area for the accurate repro-
duction of time-dependent properties, such as the rate
constants. These advances would have a large impact
in the growing ﬁeld of integrative structural biology,
since for example they would potentially better predict
populations of conformations that lie in the transition
states [46]. Such a force ﬁeld optimization for molec-
ular kinetics is currently not possible within CoPE-
Maxcal approach, as the prior dynamical trajecto-
ries, and hence the force ﬁeld, are not aﬀected in the
reweighting procedure. Yet, it might be made possi-
ble by introducing novel forward models for the rate
as a function of the force ﬁeld parameters. By comput-
ing the derivative of the rate constant with respect to
these parameters, one could minimize an error function
to meet target kinetics. This is an avenue that are we
currently actively pursuing.
6.6 Open questions in statistical mechanics
The extension of the MaxEnt principle to path ensem-
bles that we have discussed in this review prompts a
series of questions of general nature, some of which are
listed in the following.
(1) We have presented the CoPE-MaxCal method as a
reweighting scheme. This method aﬀects only the
initial conditions (see Sect. 4.6), but not the trajec-
tories themselves. It would be interesting to inves-
tigate the analogy between this type of reweighting
and the coupling to a heat bath, such as done in
the derivation of the canonical ensemble from the
microcanonical ensemble. One can also ask whether
123

188
Page 18 of 21
Eur. Phys. J. B (2021) 94:188
the MaxCal approach can be used to modify the
trajectories themselves. This might be used in an
on-the-ﬂy optimization such as proposed in [156].
(2) In the CoPE-MaxCal application to rate constants
we have used the Transition Path Sampling and
Transition Interface Sampling framework. While
these methods are eﬃcient tools to obtain and
manipulate path ensembles, one should be able to
formulate the methodology independently.
(3) The investigation of the relationship between the
CoPE-MaxCal approach and other path reweight-
ing methodologies, such as the s-ensemble or other
path reweighting methods, could provide further
insight for establishing more general methods.
(4) The CoPE-MaxCal framework may be extended to
non-equilibrium steady states, e.g., for the driven
dynamics observed in active systems. For that sit-
uation the MaxEnt approach cannot describe the
correct steady state density, and one has to use
the MaxCal approach in order to construct the
reweighting function.
6.7 Final thoughts
We anticipate that the application of the MaxCal
approach to ensembles of continuum trajectories, as for
example provided by molecular dynamics simulations,
will oﬀer new opportunities to address equilibrium and
non-equilibrium problems that involve the trajectory
space. We undoubtedly will see more research in this
area in the coming years.
Z.F.B. would like to acknowledge the Federation of Euro-
pean Biochemical Societies (FEBS) for ﬁnancial support
(LTF).
Author contributions
ZFB and PGB designed research; ZFB and PGB per-
formed research; and ZFB, MV, and PGB wrote the
paper. All authors have read and approved the ﬁnal
manuscript.
Data Availability Statement This manuscript has no
associated data or the data will not be deposited [Authors’
comment: This review has no associated data as all data
discussed has been published elsewhere.]
Open Access This article is licensed under a Creative Com-
mons Attribution 4.0 International License, which permits
use, sharing, adaptation, distribution and reproduction in
any medium or format, as long as you give appropriate credit
to the original author(s) and the source, provide a link to
the Creative Commons licence, and indicate if changes were
made. The images or other third party material in this arti-
cle are included in the article’s Creative Commons licence,
unless indicated otherwise in a credit line to the material. If
material is not included in the article’s Creative Commons
licence and your intended use is not permitted by statu-
tory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
To view a copy of this licence, visit http://creativecomm
ons.org/licenses/by/4.0/.
References
1. E.T. Jaynes, Phys. Rev. 108, 171 (1957)
2. E. T. Jaynes, Phys. Rev. 106, 620 (1957)
3. E. T. Jaynes (1980) Ann. Rev. Phys. Chem. 31 579
4. E.T. Jaynes, H. Haken, Complex Systems- Operational
Approaches (Springer-Verlag, Berlin, 1985), pp. 254–
259
5. S. Press´e, K.Ghosh, J. Lee, K. A. Dill. Rev. Mod. Phys.
85 1115 (2013)
6. A. A. Filyukov, V. Y. Karpov (1967) J. Eng. Phys. 13
416
7. C. Monthus, J. Stat. Mech. 2011 P03008 (2011)
8. S. Davis, D. Gonzalez, J. Phys. A: Math. Theor. 48,
425003 (2015)
9. P.D. Dixit, J. Wagoner, C. Weistuch, S. Press´e, K.
Ghosh, K.A. Dill, J. Chem. Phys. 148, 010901 (2018)
10. D.M. Rogers, J. Stat. Mech.: Theory Exp. 2019,
084010 (2019)
11. K. Ghosh, P.D. Dixit, L. Agozzino, K.A. Dill, Annu.
Rev. Phys. Chem. 71, 213 (2020)
12. D.
Chandler,
Introduction
to
modern
statistical
mechanics. Oxford University Press (1987)
13. D. Chandler. Classical and quantum dynamics in con-
densed phase simulations. (World Scientiﬁc, Singapore,
1998), Chap. Barrier crossings: classical theory of rare
but important events, pgs. 3–23
14. D. Frenkel, B. Smit, Understand-ing Molecular Simula-
tion, 2nd ed (Academic Press, Inc., Orlando, FL, USA,
2001)
15. D.E. Shaw, P. Maragakis, K. Lindorﬀ-Larsen, S. Piana,
R.O. Dror, M.P. Eastwood, J.A. Bank, J.M. Jumper,
J.K. Salmon, Y. Shan, W. Wriggers Sci. 330, 341
(2010)
16. M. Bonomi, M. Vendruscolo, Current Opinion in Struc-
tural Biology. 56, 37 (2019)
17. C. Dellago, P. G. Bolhuis. Adv. Polym. Sci. 221 167
(2009)
18. M. Bonomi, G. Bussi, C. Camilloni, G. Tribello, P.
Ban´aˇs, A. Barducci, M. Bernetti et al., Nat. Methods
16, 670 (2019)
19. J. W. Pitera, J. D. Chodera, J. Chem. Theory Comput.
8 3445 (2012)
20. A. Cavalli, C. Camilloni, M. Vendruscolo, J. Chem.
Phys. 138, 094112 (2013)
21. B. Roux, J. Weare, J. Chem. Phys. 138, 084107 (2013)
22. W. Boomsma, J. Ferkinghoﬀ-Borg, K. Lindorﬀ-Larsen,
PLoS Computational Biology 10, 1 (2014)
23. G. Hummer, J. K¨oﬁnger, J. Chem. Phys. 143, 243150
(2015)
24. M. Bonomi, C.Camilloni, A.Cavalli, M.Vendruscolo.
Sci. Adv. 2 1 (2015)
25. F. Marinelli, J. D. Faraldo-G´omez. Biophys. J. 108
2779 (2015)
26. S. Olsson, H. Wu, F. Paul, C. Clementi, F. No´e, Pro-
ceedings of the National Academy of Sciences. 114,
8265 (2017)
123

Eur. Phys. J. B (2021) 94:188
Page 19 of 21
188
27. M. Bonomi, R. Pellarin, M. Vendruscolo, Biophys. J.
114, 0605018 (2018)
28. A. Cesari, S. Reißer, G. Bussi, Computation 6, 15
(2018)
29. S. Bottaro, K. Lindorﬀ-Larsen, Science 361, 355 (2018)
30. S. Bottaro, T. Bengtsen, K. Lindorﬀ-Larsen Integrat-
ing Molecular Simulation and Experimental Data: A
Bayesian/Maximum Entropy Reweighting Approach,
in Structural Bioinformatics: Methods and Protocols
edited by Z.G´asp´ari (Springer US New York, NY, 2020)
pp. 219–240
31. M. Bonomi, C. Camilloni, A. Cavalli, M. Vendruscolo,
Sci. Adv. 21 (2016)
32. S. Vahidi, Z.A. Ripstein, M. Bonomi, T. Yuwen, M.F.
Mabanglo, J.B. Juravsky, K. Rizzolo, A. Velyvis, W.A.
Houry, M. Vendruscolo, J.L. Rubinstein, L.E. Kay,
Proc. Nat. Acad. Sci. USA 115, E6447 (2018)
33. M. R. Hermann, J. S. Hub. J. Chem. Theory Comput.
15 5103 (2019)
34. L. Eshun-Wilson, R.Zhang, D.Portran, M. V. Nachury,
D. B. Toso, T.L¨ohr, M.Vendruscolo, M.Bonomi, J. S.
Fraser, E.Nogales, Proc. Nat. Acad. Sci. USA. 116
10366 (2019)
35. Z. F. Brotzakis, T. Lohr, M. Vendruscolo, Chem. Sci.
12, 9168–9175 (2021)
36. Z.F. Brotzakis, P.R. Lindstedt, R. Taylor, G.J.L.
Bernardes, M. Vendruscolo, bioRxiv https://doi.org/
10.1101/2020.11.10.376285 (2020)
37. P. Robustelli, S.Piana, D. E. Shaw, Proc. Natl. Acad.
Sci. U. S. A. 115 E4758 (2018)
38. G.T. Heller, F.A. Aprile, M. Bonomi, C. Camilloni,
A. De Simone, M. Vendruscolo, Journal of Molecular
Biology. 429, 2772 (2017)
39. A. N. Borkar, M. F. Bardaro, C.Camilloni, F. A. Aprile,
G.Varani, M.Vendruscolo, Proc. Nat. Acad. Sci. USA.
113 7171 (2016)
40. H. Lou, R.I. Cukier, J. Chem. Phys. 149, 234106 (2018)
41. T. Bengtsen, V.L. Holm, L.R. Kjølbye, S.R. Midtgaard,
N.T. Johansen, S. Bottaro, B. Schiøtt, L. Arleth, K.
Lindorﬀ-Larsen, Elife. 9, e56518 (2020)
42. C. Paissoni, A. Jussupow, C. Camilloni, J. Chem. The-
ory Comput. 16 2825 (2020)
43. G.
T.
Heller,
F.
A.
Aprile,
T.
C.
Michaels,
R.Limbocker, M.Perni, F. S. Ruggeri, B.Mannini,
T.L¨ohr, M.Bonomi, C.Camilloni, A.de Simone, I. C.
Felli, R.Pierattelli, T. P. Knowles, C. M. Dobson,
M.Vendruscolo, Science Adv. 6, 1 (2020)
44. S. Orioli, A. H. Larsen, S.Bottaro, K. Lindorﬀ-Larsen.
Prog Mol Biol Transl Sci. 170, 123 (2020)
45. R. Capelli, G. Tiana, C. Camilloni, J. Chem. Phys.
148, 184114 (2018)
46. Z.F. Brotzakis, M. Vendruscolo, P.G. Bolhuis, Proc.
Natl. Acad. Sci. U.S.A. 118, e2012423118 (2021)
47. J.-H. Prinz, H. Wu, M.Sarich, B. Keller, M. Senne, M.
Held, J. D. Chodera, C.Sch¨utte, F. No´e,J. Chem. Phys.
134, 174105 (2011)
48. M. Bause, T. Wittenstein, K. Kremer, T. Bereau, Phys.
Rev. E.100, 60103 (2019)
49. M. Bause T. Bereau, J. Chem. Phys. 154, 134105
(2021)
50. H. Touchette, Physics Reports. 478 1 (2009)
51. L. O. Hedges, R. L. Jack, J. P. Garrahan, D.Chandler,
Science. 323 1309 (2009)
52. A.B. Adib, J. Phys. Chem. B. 112, 5910 (2008)
53. S. Kieninger B. G. Keller, J. Chem. Phys. 154, 094102
(2021)
54. C. Dellago, P. G. Bolhuis, F. S. Csajka, D. Chandler,
J. Chem. Phys. 108, 1964 (1998)
55. P. G. Bolhuis, D .Chandler, C. Dellago, P. Geissler.
Ann. Rev. Phys. Chem. 53, 291 (2002)
56. C. Dellago, P.G. Bolhuis, P. L. Geissler. Adv. Chem.
Phys. 123 1 (2002)
57. T. S. van Erp, D.Moroni, P. G. Bolhuis. J. Chem. Phys.
118 7762 (2003)
58. T. S. van Erp. Adv. Chem. Phys. 151 27 (2012)
59. R. Cabriolu, K.M.S. Refsnes, P.G. Bolhuis, T.S. van
Erp, J. Chem. Phys. 147, 152722 (2017)
60. P. G. Bolhuis, Proc. Nat. Acad. Sci. USA. 100 12129
(2003)
61. J. Juraszek, P.G.. Bolhuis, Proc. Nat. Acad. Sci. USA
103, 15859 (2006)
62. J. Juraszek, P. G. Bolhuis, Biophys. J. 95 4246 (2008)
63. W. Du, P.G. Bolhuis, J. Chem. Phys. 140, 195102
(2014)
64. W. Du, P.G. Bolhuis. Biophys. J. 108 368 (2015)
65. J. Vreede, J. Juraszek, P. G. Bolhuis, Proc. Natl. Acad.
Sci. U.S.A. 107 2397 (2010)
66. R. B. Best, G.Hummer, Proc. Natl. Acad. Sci. U.S.A.
113 3263 (2016)
67. Z.F. Brotzakis, P.G. Bolhuis, J. Phys. Chem. B. 123,
1883 (2019)
68. J. Doma´nski, M.S. Sansom, P.J. Stansfeld, R.B. Best,
PLOS Comput. Bio. 16, e1007919 (2020)
69. M. Hagan, A.Dinner, D.Chandler, A.Chakraborty,
Proc. Natl. Acad. Sci. U.S.A. 100 13922 (2003)
70. R. Radhakrishnan, T.Schlick, Proc. Natl. Acad. Sci.
U.S.A. 101 5970 (2004)
71. R.J. Dimelow, N. A. Burton, I.H. Hillier, Phys. Chem.
Chem. Phys. 9 1318 (2007)
72. Y. Li, B.D. Freudenthal, W. A. Beard, S. H. Wilson,
T.Schlick, J. Am. Chem. Soc. 136 3630 (2014)
73. J. Vreede, A. P. de Alba Ort´ız, P. G. Bolhuis, D.W.H.
Swenson, Nucleic Acids Res. 47, 11069 (2019)
74. E. Riccardi, E.C. van Mastbergen, W.W. Navarre, J.
Vreede, PLOS Comput. Bio. 15, e1006845 (2019)
75. K.-i. Okazaki, D.W¨ohlert, J.Warnau, H.Jung, ¨Ozkan
Yildiz, W.K¨uhlbrandt, G.Hummer, Nat. Commun. 10,
4322 (2019)
76. P. L. Geissler, C.Dellago, D.Chandler, J. Phys. Chem.
B. 103 3706 (1999)
77. A. J. Ballard and C.Dellago, J. Phys. Chem. B. 116
13490 (2012)
78. R. G. Mullen, J.-E. Shea, B.Peters, J. Chem. Theory.
Comput. 10 659 (2014)
79. M. N. Joswiak, M. F. Doherty, B.Peters, Proc. Natl.
Acad. Sci. U.S.A. 115 656 (2018)
80. D. Laria, J. Rodriguez, C.Dellago, D.Chandler, J.
Phys. Chem. A. 105 2646 (2001)
81. P. Varilly and D.Chandler, J. Phys. Chem. B. 117 1419
(2013)
82. P.R. ten Wolde, D. Chandler, Proc. Natl. Acad. Sci.
U.S.A. 99, 6539 (2002)
83. C. Leitold, C. Dellago, J. Chem. Phys. 141, 134901
(2014)
84. D. Moroni, P.R. Ten Wolde, P.G. Bolhuis, Phys. Rev.
Lett. 94 1 (2005)
123

188
Page 20 of 21
Eur. Phys. J. B (2021) 94:188
85. W. Lechner, C. Dellago, P.G. Bolhuis, Phys. Rev. Lett.
106, 085701 (2011)
86. G. T. Beckham, B.Peters, J. Phys. Chem. Lett. 2 1133
(2011)
87. B.C. Barnes, B.C. Knott, G.T. Beckham, D.T. Wu,
A.K. Sum, J. Phys. Chem. B. 118 13236 (2014)
88. G.D. Leines, R. Drautz, J. Rogal, J. Chem. Phys. 146,
154702 (2017)
89. G.D. Leines, J. Rogal, J. Phys. Chem. B. 122 10934
(2018)
90. Arjun, T.A. Berendsen, P. G. Bolhuis, Proc. Natl.
Acad. Sci. U.S.A. 116 19305 (2019)
91. Y. Liang, G.D. Leines, R. Drautz, J. Rogal, J. Chem.
Phys. 152, 224504 (2020)
92. A. Arjun, P. G. Bolhuis, J. Phys. Chem. B. 124 8099
(2020)
93. D. Zahn, Y. Grin, S. Leoni. Phys. Rev. B.72 064110
(2005)
94. G.T. Beckham, B.Peters, C.Starbuck, N.Variankaval,
B. L. Trout, J. Am. Chem. Soc. 129 4714 (2007)
95. G.T. Beckham, B.Peters, B.L. Trout, J. Phys. Chem.
B. 112 7460 (2008)
96. P.L. Geissler, C. Dellago, D. Chandler, J. Hutter, M.
Parrinello, Science 291, 2121 (2001)
97. A. Tiwari, B.Ensing, Faraday Discuss. 195 291 (2016)
98. J.E. Basner, S. D. Schwartz, J. Am. Chem. Soc. 127
13822 (2005)
99. B. C. Knott, M. H. Momeni, M. F. Crowley, L. F.
Mackenzie, A.W. G¨otz, M.Sandgren, S. G. Withers, J.
St˚ahlberg, G. T. Beckham, J. Am. Chem. Soc. 136 321
(2013)
100. M. Dzierlenga, M. Varga, S. Schwartz in Methods in
Enzymology (Elsevier 2016) pp. 21–43
101. T.K. Paul, S. Taraphder, ChemPhysChem 21, 1455
(2020)
102. A. C. Newton, J. Groenewold, W. K. Kegel, P. G. Bol-
huis. Proc. Nat. Acad. Sci. USA. 112 15308 (2015)
103. A.C. Newton, J. Groenewold, W.K. Kegel, P.G. Bol-
huis, J. Chem. Phys. 146, 234901 (2017)
104. A.C. Newton, R. Kools, D.W. Swenson, P.G. Bolhuis,
J. Chem. Phys. 147, 155101 (2017)
105. A. S. Keys, L. O. Hedges, J. P. Garrahan, S. C. Glotzer,
D.Chandler, Phys. Rev. X, 1 021013 (2011)
106. R. L. Jack, L. O. Hedges, J. P. Garrahan, D.Chandler,
Phys. Rev. Lett. 107, 275702 (2011)
107. A.S. Mey, P.L. Geissler, J.P. Garrahan, Phys. Rev. E.
89, 032109 (2014)
108. D. Coslovich, R.L. Jack, J. Stat. Mech: Theory Exp.
2016, 074012 (2016)
109. F.Turci, C. P. Royall, T.Speck, Phys. Rev. X. 7, 031028
(2017)
110. M. Campo, T. Speck, J. Chem. Phys. 152, 014501
(2020)
111. R.J. Allen, P.B. Warren, P.R. ten Wolde, Phys. Rev.
Lett. 94, 018104 (2005)
112. R.Allen, D.Frenkel, P.R.ten Wolde,J. Chem. Phys.
124, 024102 (2006)
113. G. Huber, S.Kim, Biophys. J. 70 97 (1996)
114. B.W. Zhang, D. Jasnow, D.M. Zuckerman, J. Chem.
Phys. 132, 054107 (2010)
115. L. T. Chong, A. S. Saglam, D. M. Zuckerman, Curr.
Opin. Struct. Biol. 43 88 (2017)
116. J. T. Berryman, T. Schilling, J. Chem. Phys. 133,
244101 (2010)
117. A. K. Faradjian , R. Elber, J. Chem. Phys. 120, 10880
(2004)
118. R. Elber, Annu. Rev. Biophys. 49 69 (2020)
119. F.Cerou, A.Guyader, T.Lelievre, D.Pommier,J. Chem.
Phys. 134, 054108 (2011)
120. A. Dickson, A. Warmﬂash, A.R. Dinner, J. Chem.
Phys. 131, 154104 (2009)
121. P. G. Bolhuis, C.Dellago, D.Chandler, Proc. Natl.
Acad. Sci. U.S.A. 97, 5877 (2000)
122. W.E, W.Ren, E.Vanden-Eijnden, J. Phys. Chem. B.
109, 6688 (2005)
123. W.E., E.Vanden-Eijnden, J. Stat. Phys. 123, 503
(2006)
124. L. Onsager, Physical Review. 54 554 (1938)
125. R. Du, V. S. Pande, A. Y. Grosberg, T.Tanaka, E. S.
Shakhnovich, J. Chem. Phys. 108 334 (1998)
126. W.E , E.Vanden-Eijnden, Annu. Rev. Phys. Chem. 61,
391 (2010)
127. P.G. Bolhuis, W.Lechner, J. Stat. Phys. 145 841 (2011)
128. P. Tiwary, B. J. Berne, Proc. Nat. Acad. Sci. USA. 113
2839 (2016)
129. Y.
Mori,
K.I.
Okazaki,
T.
Mori,
K.
Kim,
N.
Matubayasi. J. Chem. Phys. 153, 054115 (2020)
130. P.G. Bolhuis, C.Dellago, Eur. Phys. J. Spec. Top. 224
2409 (2015)
131. P.G. Bolhuis, D.W.H. Swenson, Adv Theory Simul. 4,
2000237 (2021)
132. J. Rogal, W. Lechner, J. Juraszek, B. Ensing, P.G. Bol-
huis, J. Chem. Phys. 133, 174109 (2010)
133. K. Lindorﬀ-Larsen, S. Piana, R.O. Dror, D.E. Shaw,
Science 334, 517 (2011)
134. Z.F. Brotzakis, P.G. Bolhuis, J. Chem. Phys. 151,
174111 (2019)
135. P.G. Bolhuis, G. Cs´anyi, Phy. Rev. Lett. 120, 1 (2018)
136. P. Kir´aly, D.J. Kiss, G. T´oth, .J. Chem. Phys. 148,
134107 (2018)
137. A. Ma, A. R. Dinner. J. Phys. Chem. B. 109 6769
(2005)
138. B. Peters, B.L. Trout, J. Chem. Phys. 125, 054108
(2006)
139. B. Peters, Annu. Rev. Phys. Chem. 67 669 (2016)
140. F. No´e, F. N¨uske, Multiscale Model. and Simul. 11,
635 (2013)
141. J.
Marcelo,
L.Ribeiro,
P.
B.
Collado,
Y.Wang,
P.Tiwary, J. Chem. Phys. 149 1 (2018)
142. D. G. Truhlar, B. C. Garrett, Ann. Rev. Phys. Chem.
35 159 (1984)
143. L. Pollack, Biopolymers. 95 543 (2011)
144. G.Marchello,
C.De
Pace,
S.Acosta-Gutierrez,
C.Lopez-Vazquez,
N.Wilkinson,
F.
L.
Gervasio,
L.Ruiz-Perez, G.Battaglia, C. I. Building, bioRxiv ,
2021.01.21.427613 (2021)
145. P. Tiwary, M. Parrinello, Phy. Rev. Lett. 111, 230602
(2013)
146. P. Tiwary, V. Limongelli, M. Salvalaglio, M. Parrinello,
Proc. Nat. Acad. Sci. USA 112, E386 (2015)
123

Eur. Phys. J. B (2021) 94:188
Page 21 of 21
188
147. Y.Wang,
O.Valsson,
P.Tiwary,
M.Parrinello,
K.Lindorﬀ-Larsen,
J.
Chem.
Phys.
149,
072309
(2018)
148. Z. F. Brotzakis, V.Limongelli, M.Parrinello,J. Chem.
Theory Comput. 15, 743 (2019)
149. D.Meral, D.Provasi, M.Filizola. J. Chem. Phys. 149,
224101 (2018)
150. L. Donati, B.G. Keller, J. Chem. Phys. 149, 072335
(2018)
151. A. Cesari, A.Gil-Ley, G.Bussi, J. Chem. Theory Com-
put. 12 6192 (2016)
152. R.Dutta, Z. F. Brotzakis, A.Mira, J. Chem. Phys. 149,
154110 (2018)
153. J. Chen, J. Chen, G. Pinamonti, C. Clementi, J. Chem.
Theory Comput. 14, 3849 (2018)
154. J.Wang, S.Olsson, C.Wehmeyer, A.P´erez, N. E. Char-
ron, G.De Fabritiis, F.No´e, C.Clementi, ACS Central
Science 5, 755 (2019)
155. S.
Doerr,
M.Majewski,
A.P´erez,
A.Kr¨amer,
C.Clementi,
F.Noe,
T.Giorgino,
G.De
Fabritiis,
J. Chem. Theory Comput. 17 2355 (2021)
156. D.C. Rose, J.F. Mair, J.P. Garrahan, New J. Phy. 23,
013013 (2021)
123

