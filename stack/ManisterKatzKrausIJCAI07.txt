Providing a Recommended Trading Agent to a Population: a Novel Approach
Computer Science Department, Bar-Ilan University, Ramat Gan, Israel
{maniste,sarit}@cs.biu.ac.il;katz@biu.013.net.il
Abstract
This paper presents a novel approach for provid-
ing automated trading agents to a population, fo-
cusing on bilateral negotiation with unenforceable
agreements. A new type of agents, called semi-
cooperative (SC) agents is proposed for this envi-
ronment. When these agents negotiate with each
other they reach a pareto-optimal solution that is
mutually beneﬁcial.
Through extensive experi-
ments we demonstrate the superiority of provid-
ing such agents for humans over supplying equi-
librium agents or letting people design their own
agents.
These results are based on our observa-
tion that most people do not modify SC agents even
though they are not in equilibrium. Our ﬁndings in-
troduce a new factor —human response to provided
agents — that should be taken into consideration
when developing agents that are provided to a pop-
ulation.
1
Introduction
Designing automated trading agents has received increasing
attention, as trading in many markets (e.g. NASDAQ) has
now become fully electronic [Da-Jun and Liang-Xian, 2002].
In many domains, such as NASDAQ and e-bay, there is an en-
tity which provides a generic agent for a considerable number
of traders in the market. This entity might offer the agent for
a fee or even for free, as a recommended agent. The goal of
this entity is to provide an agent that maximizes the overall
traders’ utility when it is delivered to a population, for two
reasons: First, one of the entity’s goals is to provide good
service to its users. Therefore, the entity should aim to max-
imize the average payoff of all the traders’ agents in the en-
vironment. Second, web-marketplaces, such as e-bay, which
host commercial transactions for a certain percentage of the
transaction amount, are interested in increasing the total prof-
its of all the traders, since they will receive higher fees as a
result. Nevertheless, in these domains each client who obtains
an agent has his own interests.
In this paper we discuss the question of which agent should
be recommended to a population. We consider environments
in which the fulﬁllment of the agreements reached by traders
are unenforceable by the system, similar to many real-life do-
mains. The game theory approach uses equilibrium agents
[Da-Jun and Liang-Xian, 2002]. These agents’ strategies are
in equilibrium, namely no agent will be better off by deviating
from its equilibrium strategy. However, although the equilib-
rium agent guarantees stability of the environment(there is no
motivation for any trader to use any other agent), its outcome
is not always Pareto-optimal, i.e. a solution may exist where
some agents obtain higher utilities than they would have ob-
tained by using the equilibrium strategy, while others do not
attain lower utilities. Consider, for example, a seller and a
buyer who have reached a sales agreement in a market-place
which does not compel the traders to fulﬁll the agreement
(e.g., Ebay). If the traders follow the equilibrium strategy,
both sides will not fulﬁll the agreement they reached, (i.e. the
seller will not send the goods and the buyer will not send the
money). However, this solution is not Pareto-optimal, since it
would be more beneﬁcial, if the agreement would be fulﬁlled
as agreed upon.
Different from the game theory approach, we present a
new family of agents called semi-cooperative (SC). These
SC agents are designed to reach mutually beneﬁcial agree-
ments and to keep their commitments (unless the other side
has broken its agreements in prior transactions).
In addi-
tion when trading with identical SC agents, they achieve a
pareto-optimal outcome that is beneﬁcial for both sides. Con-
sider the trading environment in the previous example. If
we would provide an SC agent and traders would adopt it
without change, both sides would receive the money or the
goods, as agreed. Consequently, traders would achieve bet-
ter results than when using the equilibrium agent. However,
in this example adopting an SC agent may not be beneﬁcial,
if many traders modify their SC agents to equilibrium agents
that do not send money or goods. In such cases the traders
that adopt an SC agent without changes will send money (or
goods) without receiving goods (or money) in return.
Conversely, we claim that if a recommended agent is pro-
vided to a population, most people will not modify their
agents, even if their strategies are not compatible with the
equilibrium strategy. We restrict our argument to low-cost
environments, so that if one of the traders breaks the agree-
ment, the loss for the one that keeps it (e.g. sending the goods
without receiving consideration) is relatively small. Such sit-
uations, where the traded costs of the goods are not very high
IJCAI-07
1408
Efrat Manisterski and Ron Katz and Sarit Kraus

(such as books, ﬂowers and cinema tickets) are very common
on the internet. There are several reasons for our claim that
people do not tend to modify their agents. First, it is well
known that people do not necessarily play according to the
equilibrium [Grosz et al., 2004]. Social factors such as equal-
ity, social welfare and risk taking play very important roles in
people’s decisions [Gal et al., 2004]. Second, modifying an
agent’s code is time consuming and requires an understanding
of the given code. For most users in low-cost environments
it is simply not worth the effort, especially when the agent’s
code is complex and seems to be reasonable. Moreover, most
traders are not programmers and modifying the code would
require hiring a programmer thus incurring additional costs.
Another factor is the credibility of an agent which is recom-
mended by an authoritative and experienced entity. It is im-
portant to note that despite the above reasons, we believe that
some people will change the recommended agent. However,
we claim that the percentage of people who would change
their agent is small, and thus it is still worthwhile to supply
an SC agent which is more cooperative with others, rather
than the non-cooperative equilibrium agent.
In order to examine our assumption we conducted exten-
sive experiments which included 132 participants. In the ﬁrst
experiment, we provided three groups of human subjects with
recommended agents for a resource allocation game. This
game extends the well known Prisoner’s Dilemma to sim-
ulate a common real-life bilateral negotiation environment.
One group received an equilibrium agent, while the other two
groups received SC agents; one with a simple negotiation
method and the other with a more complex one. All subjects
from the same group received the same initial code. Sub-
jects were free to make any changes in their recommended
agent. Note that the participants could change their agents
not only to the equilibrium agent, but even to an agent which
speciﬁcally exploits the recommended agent.
The results
show that most subjects did not change their agents. More-
over, in groups which were given an SC agent as a recom-
mended agent, the overall utility of all the subjects was sig-
niﬁcantly higher than in the group that was given the equilib-
rium agent. Furthermore, even when giving subjects the op-
portunity to change their agents, after observing the results of
playing with other agents in their group, subjects did not tend
to change their agents and the superiority of the SC agents
remained.
In addition, we compared the overall utility of recommend-
ing an SC agent to the overall utility when there is no rec-
ommended agent at all. For this purpose, we asked another
group of subjects to design their own agents without prof-
fering a recommended agent. We named these agents Peer
Designed Agents (PDAs). The results show that the group
that received a recommended SC agent yielded higher over-
all payoffs compared to the group which was not provided
a recommended agent. Thus, we propose that entities wish-
ing to maximize the overall utility in the environment offer
the traders a recommended agent, rather than leave it totally
open to the users’ development.
The innovative contribution of this paper is in presenting a
new approach for designing recommended agents that takes
human behavior into consideration. To our knowledge we
are the ﬁrst to examine how human populations react to the
existence of recommended computerized agents. Moreover,
our approach saves the need of designing and implementing
a mechanism for the trading environment. Mechanism de-
sign requires many resources, and it is not always applicable.
Consider, for example, what it would take for E-bay to en-
force all the agreements reached on the site. Our approach,
on the other hand, induces cooperation and fairness without
spending any additional resources.
The rest of the paper is organized as follows. In section
2 we discuss related work. In sections 3 and 4 we describe
our negotiation environment and broadly present the semi co-
operative agents (SC). Then we discuss the experiments we
conducted in order to evaluate the SC agents’ performance.
Finally, in section 7 we conclude and suggest directions for
future research.
2
Related work
Developing automated agents for a population has received
extensive attention in recent years. In addition to equilibrium
agents there are approaches which propose designing coop-
erative agent systems, e.g., [Zhang et al., 2000]). In these
systems the agents cooperate in order to achieve a common
goal, or to maximize the overall system’s utility. However,
the agents in such systems are indifferent toward their own
utilities. Therefore, these agent systems are inapplicable in
our environment, where each agent attempts to increase its
client’s utility. Furthermore, there have been efforts to de-
sign a mechanism which induces cooperative behavior among
selﬁsh agents, e.g., [Mui et al., 2002]. However, these mech-
anisms require resources and are based on assumptions such
as repeated interactions and the ability to detect an agent’s
identity, which are not appropriate for our environment.
Some researchers have explored the behavior of evolu-
tional agents that dynamically adapt to their environment,
e.g., [Fatima et al., 2005]. These agents are designated for
environments in which learning and adaptation can be done
during long periods. These agents are also used for model-
ing human behavior. However, the evolutionary model re-
quires repeated interactions, while we consider negotiation
environments where agents may interact only once. Other
researchers have considered socially rational agents, whose
utility depends on the overall utility of the society, e.g., [Hogg
and Jennings, 2001]. In our environment, however, as in other
e-commerce applications, traders do not take into considera-
tion the overall beneﬁt of the society. Other researchers have
developed non-equilibrium agents for competing against a
population of bounded rational agents such as humans, e.g.,
[Gal et al., 2004]. In contrast, we have designed agents desig-
nated for the entire population. Moreover, none of the previ-
ous studies have considered human behavior when providing
a recommended agent.
The concept which is most similar to the recommended
agents considered here is a recommended play, in which sub-
jects are presented recommendations of how to play a game,
e.g., [Croson and Marks, 2001]). Some of the studies that
explore recommended play, present mixed results concerning
the inﬂuence of the recommended play on people’s behav-
IJCAI-07
1409

ior. However, recommended play is fundamentally different
from a recommended agent. First, most studies which exam-
ine recommended play induce playing the equilibrium strat-
egy and are explored in games with simple strategies. In con-
trast, we suggest providing non-equilibrium agents and using
more complex settings which reﬂect real-life negotiations. In
addition, in order to use the recommended play people must
actively choose it. However, in our case the recommended
agent can be passively adopted without any additional activ-
ity required. Moreover, modifying the recommended agent
does actually require effort and time.
3
Environment Description
In order to simulate a general trading framework, we have
designed a resource allocation game. The advantage of this
basic game is that it makes very few assumptions, and thus
it can represent many situations in real economical markets.
Moreover, such environments are very common and easy to
manage via the Web. In the beginning of our 2-player game,
each player i (i ∈{1, 2}) is allocated an initial pool of re-
sources Rinit
i
, which are attributed to several types. The goal
of the game for each player i is to possess a speciﬁed set of re-
sources Gi, which includes a certain quantity (zero or more)
of each resource type. There are enough resources for both
players to satisfy their goals, i.e. G1 ∪G2 ⊆Rinit
1
∪Rinit
2
.
However, some of the resources needed by one player may be
in the possession of the other. Thus, in order to obtain the goal
set of resources, a player might need to exchange resources
with the other party, according to a certain negotiation pro-
tocol. The protocol consists of a ﬁnite number of rounds n.
Each round l is comprised of two phases: a negotiation phase
and an exchange phase. In the negotiation phase one of the
players makes an offer Ol = (Ogivel
1, Ogivel
2) to exchange
resources with the other player. In his offer the proposer i
promises to send Ogivel
i resources to the other player and in
return requests that player j send Ogivel
j to him. The receiver
should inform the proposer whether he accepts or rejects the
offer. Afterwards, there is an exchange phase, in which each
player i sends a set of resources Sl
i to the other player. In this
game, agreements are not enforced by the game controller,
allowing players to break agreements. Therefore Sl
i can be
different from Ogivel
i. The exchange is executed simultane-
ously, so that no player knows how many resources, if any,
the other party has actually sent till he has already sent his re-
sources. The next round is identical to the ﬁrst one except for
the role of the proposer, which is alternated between the two
players. The performance of each player is determined by its
score at the end of the game. The score of player i (scorei)
possessing the set of resources Rend
i
at the end of the game
is Scoregoal if the player holds the whole target set. In ad-
dition, each resource the player possesses imparts him with
Scoreres points. Formally
scorei =

Scoregoal + |Rend
i
|ScoreRes
Gi ⊆Rend
i
|Rend
i
|ScoreRes
otherwise
The resource allocation game, supplies a general negotiation
platform which is more similar to real-life negotiations than
typical economic games.1 This game is a simpliﬁed version
of the Colored-Trails framework, which is a paradigm for ex-
amining negotiation environments which involve automated
agents [Grosz et al., 2004].
In our experiment the conﬁguration of the parameters is:
n = 10, Scoregoal = 200 and Scoreresources = 10. Thus,
obtaining the target set becomes the most important compo-
nent of the scoring function. We set the initial state in such a
manner that one player possesses all the resources that com-
prise a target set, which means he is not dependent on the
resources of the other. The other player, on the other hand,
is dependent on the other player’s resources. More speciﬁ-
cally, he needs two resources from the other player in order
to complete the target set. Both players have extra available
resources for which they can negotiate. Our game setting en-
ables an examination of situations in which the equilibrium
strategy is not Pareto-optimal, and cooperation between the
players yields better results for both parties: The dependent
player can obtain the resources he needs to complete the tar-
get set, and the independent player can increase the number
of resources he obtains by reaching agreements in which the
number of resources he sends is lower than the number of re-
sources he receives in return. Moreover, our game setting en-
ables the examination of two different situations: the depen-
dent player gains from the exchange of resources signiﬁcantly
more than he is required to pay, while the independent player
only slightly improves his proﬁt from the exchange. Both
situations are common in real life. Consider for instance, a
researcher who crucially needs to buy some books for an im-
portant research she is conducting. The seller will gain some
money from the transaction. The researcher, however, is go-
ing to gain much more from the deal.
4
Recommending Semi-cooperative Agents
A recommended agent for this game can be described by its
strategies, i.e. the agent’s decisions in each possible phase
of the game: the offers the agent makes, its responses to the
offers it receives and the resources it sends. To describe the
agents, when agent A plays the role of player 1 and agent
B is player 2, we denote the set of resources that player i
possesses at the end of the game and its score as Rend
i
(A, B)
and scorei(A, B), respectively. We use N l
i to denote the set
of resources that player i needs in round l in order to complete
its goal set. Finally, me signiﬁes the index of the player the
agent plays and other indicates the index of the other player.
In our resource allocation game the combination of unen-
forceable agreements and a ﬁnite horizon of the game leads
to a theoretical equilibrium result that no resources will be
exchanged. Therefore, an equilibrium agent (EA) in the con-
text of this game is any agent that never sends any resources,
i.e. ∀i, ∀l Sl
i = ∅. As a result, at the end of the game
each player will possess only its initial set of resources, ∀i,
Rend
i
(EA, EA) = Rinit
i
.
1The game is similar to the prisoner’s dilemma by having the
choice of cooperating (sending the promised resources) or not co-
operating (not sending the promised resources). However, our game
also includes negotiation processes to resemble real life situations.
IJCAI-07
1410

In contrast to the equilibrium agent, we deﬁne a semi co-
operative agent (SC) as an agent which
1. When the agent plays against an identical agent, both
agents obtain higher scores than the scores they have at
the beginning of the game.
2. When the agent negotiates with an identical agent, both
agents reach a pareto-optimal solution.
3. It fulﬁlls its agreements as long as the other side does
not deceive it.
4. In each stage of the game, it commits to activities that are
beneﬁcial for both sides (for itself and for its opponent).
In particular in our game properties 1 and 2 imply that when
an SC agent plays against an identical agent, both agents
satisfy their goals, i.e. ∀i, Gi ⊆Rend
i
(SC, SC). Accord-
ing to property 4, for each round l the SC agent proposes
and accepts agreements that are beneﬁcial to both sides. In
this game, an agreement is beneﬁcial for player i if it in-
creases the number of resources it possesses, or if it increases
the number of resources it needs in order to satisfy its goal,
i.e. |Ogivel
other| > |Ogivel
me| or Ogivel
other ∩Nme ̸= ∅.
Note that unlike a cooperative agent which agrees to send re-
sources to the other agent for free if it maximizes the joint
utility, the SC agent does not accept such an offer. When
providing an SC agent as a recommended agent, if players
adopt it without change, the dependent players will satisfy
their goals, and the independent players will obtain additional
resources. Therefore both players will beneﬁt more by us-
ing semi-cooperative agents than when both of them use the
equilibrium agents (in case we provide equilibrium agents).
Consequently, providing semi-cooperative agents is superior
over providing equilibrium agents if the users do not modify
their agents, ∀i scorei(SC, SC) > scorei(EA, EA). How-
ever, semi-cooperative agents can obtain a lower score than
equilibrium agents, if one of the users modiﬁes his recom-
mended agent. For example, consider a scenario in which
user US1 adopts the SC recommended agent without change
while user US2 modiﬁes its agent to an equilibrium agent
that does not send any resources. In this scenario, the agent
of US1 will send resources to the agent of US2 but will not
receive resources in return. As a result, US1’s score in this
game will be lower than if US1 would have used an equilib-
rium agent, which would have let him at least reserve all his
initial resources. Nevertheless, if most users do not modify
their agents, the revenue of an SC agent in games where both
sides use SC agents will compensate for the loss from games
where the SC agent plays against a modiﬁed agent.
4.1
Experiment
In order to investigate which agent should be provided to a
population, an SC or an equilibrium agent, we conducted the
following experiment. In this experiment we examined the
behavior of three groups of programmers who received rec-
ommended agents’ codes for the resources allocation game.
For this purpose, in addition to the equilibrium agent (EA)
we designed two SC agents2, distinguished by their level of
2The behavior of the recommended SC agents can be any be-
havior that satisﬁes conditions 1-4 in the SC deﬁnition. Indeed in
complexity, as described below.
Description of SC Agents
The Simple semi-Cooperative Agent (SCA)
In general, this agent is a simple agent in the sense that it
agrees to any beneﬁcial offers ( it doesn’t try to increase its
score by being greedier at the beginning of the game) or try
to learn the opponent type (see SSC’s strategy for detecting
liars). More speciﬁcally:
Sending strategy: This agent is honest and fulﬁlls its agree-
ments, unless the other agent deceives it. Once this player has
been deceived, it stops sending resources.
Negotiation strategy: This agent’s logic is quite simple. For
round l of the game; if the agent has already satisﬁed its
goal (N l
me = ∅) it accepts any offer that: (1) Gives the
other agent resources it needs to satisfy its goal, Ogivel
me ⊆
N l
other (2) Increases the number of resources it possesses
(|Ogivel
other| > |Ogivel
me|). If the agent hasn’t satisﬁed its
goal (N l
me ̸= ∅), it accepts any offer which: (1) Promotes it
to satisfy its goal, Ogivel
other ⊆N l
me, Ogivel
other ̸= ∅(2) It
needs to send only the resources not necessary for it to reach
its goal, Ogivel
me ⊆Avl
me, where Avl
i denotes the agent’s
set of available resources.
The Complex semi-Cooperative Agent (CCA)
In general, this agent has a complex logic as it tries to in-
crease its score by being greedier at the beginning of the
game. In addition, it tries to minimize the damage in case
it plays against a deceiving player. More speciﬁcally:
Sending strategy: CCA is honest and usually fulﬁlls its
agreements. However, unlike the SCA, this agent is also cau-
tious and protects itself from agents that do not fulﬁll their
agreements. CCA identiﬁes situations in which there is a high
probability that it will be deceived by the other agent which
will not send the resources agreed upon:(1) In situations in
which the other agent has already satisﬁed its goal and if it
will keep the agreement, the CCA agent will satisfy its goal,
i.e., Nme ⊆Ogivel
other. In these situations there is a higher
probability that the other agent will not send the promised re-
sources, since both agents are about to possess their target sets
and no future interactions are expected. In such cases, there
is no motivation for the other agent to maintain its credibility
and to avoid deceiving. (2) When the other agent has already
deceived in the past. (3) When there are very few rounds till
the end of the game. In all the situations mentioned above, the
CCA waits to send its resources until one round after receiv-
ing the resources from the other agent, i.e, Sl+1
me = Ogivel
me
if Ogivel
other = Sl
other.
Negotiation strategy: In round l of the game, if the agent
has already satisﬁed its goal (N l
me = ∅) it accepts offers in
which it promises to send the other agent only one resource
which the other agent needs in order to satisfy its goal, i.e
|Ogivel
me| = 1 and Ogivel
me ⊆N l
other. The logic behind
sending one resource at a time is to minimize the damage
in case the other side is a liar and does not fulﬁll its agree-
ment. The number of resources it demands for sending this
resource decreases over time. Similarly, if the agent has not
our experiment we used two variations of SC agents: a simple agent
that negotiates several resources at a time and a complex agent that
negotiates one resource at a time.
IJCAI-07
1411

satisﬁed its goal (N l
me ̸= ∅), it accepts any offer in which it
is promised one resource which it needs to satisfy its goal,
i.e. |Ogivel
other| = 1 ,(Ogivel
other ⊆Nme). The number of
resources it agrees to send in return increases over time.
Experiment Design
In our experiment 99 subjects were divided to three equal
groups. Each group was provided with a different recom-
mended agent’s code3 EA, CCA or SCA. All programmers of
the same group received the same initial code. We also pre-
sented a short description of the recommended agent’s strat-
egy. The group that received the EA agent was also explained
the meaning of their agents being equilibrium agents. We
conveyed to the subjects in all the groups that the provided
agent is recommended. Each programmer was requested to
submit an agent’s code aiming to maximize its score (as spec-
iﬁed below), which was not necessarily equal to or based
upon the recommended agent. They were required to submit
their ﬁnal agents in 10 days. We explained that each agent
would play in a tournament against all the other 32 subjects’
agents who had received the same recommended agent. Each
agent played both as the role of the dependent and the role of
the independent agent against all the other agents. It is wor-
thy to note that this experimental methodology is innovative
since no one, as far as we know, has ever examined the in-
ﬂuence of providing a recommended agent to a population of
programmers.
All subjects who participated in our experiment were
upper-class undergraduate and graduate computer science
students at Bar-Ilan University, who are experienced pro-
grammers.
The subjects were motivated to perform well
by receiving a course grade. A subject’s grade was calcu-
lated according to the score obtained by his agent accumu-
lated over all its 64 plays. We emphasized that the grade
is based only upon the subject’s own score, and not upon
other agents’ scores - similar to real negotiation environ-
ments, where traders gain money only according to their own
agents’ performance. The game was explained in class and
the participants were able to ask questions. In addition, they
received an accurate written description of the game. For de-
bugging purposes, we gave participants a server upon which
they could run their agents. We made sure that each subject
knew how to run the server and we offered any technical sup-
port needed.
Our main hypothesis was that the groups provided with SC
agents would achieve better results (as speciﬁed below) than
a group provided with the equilibrium agents. The results
were evaluated based on two aspects: (1) The average score
of the players that adopted the recommended agent without
changing it. (2) The overall score of all the agents in the
environment, including agents that were modiﬁed to deviate
from the recommended strategy. This hypothesis was based
on our assumption that people tend not to change their agents,
as explained in the introduction.
170
210
250
290
EA
SCA
CCA
170
210
250
290
EA
SCA
CCA
PDA
Figure 1: (a) Recommended agent’s average score; (b) Average
score of all the agents in the environment.
4.2
Results
The average scores achieved by the agents in the tournaments
are presented in Figure 1. The results depicted in Figure 1.a
show that the average scores achieved both by SCA and CCA
agents (which were not modiﬁed) are signiﬁcantly higher
than the EA’s average score (Mann-Whitney test, p < 0.01).
Similar results are presented in ﬁgure 1.b, which depicts the
average scores of all agents in the environments (including
agents modiﬁed to deviate from the recommended agent strat-
egy). The superiority of using the SC agents over using the
EA agents applies to both the dependent and the independent
roles.
These results support our hypothesis which claims that pro-
viding SC recommended agents to a population yields better
results than providing the equilibrium agent. We have based
our hypothesis mainly upon the assumption that people tend
not to change the recommended agents. This assumption was
supported by the experimental results. In all three groups,
most subjects did not modify their agents. In particular, only
5 subjects (of 33) modiﬁed the recommended agent in the EA
group, 10 in the SCA group and 4 in the CCA group.
The provided agents’ performance is determined not only
by the number of people that change their agents, but also
by the way they modify their agents.
Some changes do
not affect the recommended agents’ score and therefore are
not relevant.
Other changes do reduce the recommended
agents’ score.
Therefore we classify the modiﬁed agents
according to the way they affect the recommended agent’s
score, when they play against it. More speciﬁcally the mod-
iﬁed agents can be classiﬁed into three types. These types
are determined by comparing the performance of the mod-
iﬁed agent when playing against a recommended agent to
the recommended agent’s performance when playing against
another recommended agent: (1) Counter agents - agents
that achieve higher scores than the recommended agent. The
best-response agent is the agent that achieves the highest
score among all the counter agents. (2) Agents with neutral
changes- agents that achieve the same score as the recom-
mended agent. (3) Inferior agents-agents whose scores are
lower than the recommended agents. In the EA group, all the
modiﬁed agents were agents of type 2, and no resources were
sent during the EA group tournament. Unlike the EA group,
in the SCA and the CCA groups most of the modiﬁed agents
were counter agents (8 out of 10 and 3 out of 4, respectively).
Surprisingly, only one subject modiﬁed its agent to the best-
response agent.
Comparing the performance of SCA and CCA groups
3The code provided was written in C++ or in Java according to
the subject’s preference.
IJCAI-07
1412

reveals higher average scores of the latter, though non-
signiﬁcant (see Figures 1.a and 1.b).
Similarly, as men-
tioned above, there were more modiﬁed agents in the SCA
group. This can be attributed to the higher sophistication
of the CCA’s negotiation method. Indeed, no changes were
made in CCA’s negotiation method, and the only changes
were in the send method. The SCA’s negotiation method, on
the other hand, was naive, i.e. it accepted any offer that in-
creased its score, and therefore called for more modiﬁcations.
Another observation, which indicates that the recommended
agent’s strategy affects the way people modiﬁed their agents,
is that no subject modiﬁed its agent to become an inferior
agent (type 3).
5
Users’ Response to their Agents’
Performance
In the previous section we showed that most subjects did not
modify the provided SC agent. However, consider a scenario
in which people are able to observe their agents performance
after playing several games. Even though most people would
not have modiﬁed their agents before observing their agents’
results they may modify it after such observation. In order to
investigate whether people modify their agents after observ-
ing their results, we provided the subjects with feedback on
their agents’ performance, after they submitted their agents
(as described in the previous section). Each subject received a
ﬁle which detailed the ﬁnal score of each of his agent’s games
and the other agent’s scores. In order to keep the other player
anonymous we identiﬁed each player by a random number.
In addition, the subject received a log ﬁle for each game its
agent played, which included the course of the game.4 Af-
ter observing these log ﬁles, subjects had one week to revise
their agents and resubmit them.
We hypothesized that the number of subjects that would
modify their agents at this stage would still be small enough,
such that it would still be proﬁtable to provide the SC agent.
There are several reasons for our hypothesis. First, as shown
in Figure 1, the SC agents achieved high scores in the tour-
nament. Thus, we assumed that most players would be satis-
ﬁed with their score and would not modify their agents. Sec-
ond, the tasks of reading all log ﬁles and understanding the
course of the games is very exhausting and time consuming.
Third, even if subjects recognize that other players modiﬁed
the original agent, it is not trivial to derive which are the mod-
iﬁed agents codes. Fourth, even if we assume that someone
succeeded in recognizing the hidden codes of all the agents
in the environment, sometimes it is very difﬁcult to calculate
the strategy that will yield better results against all other mod-
iﬁed agents. Thus we believed that most people would not
modify their agents after observing their performance. The
experiment results support our hypothesis. Only one subject
modiﬁed his agent.
In order to examine how seriously the participants treated
the experiment (including the ﬁrst part), we asked them to
4The subjects could not observe the courses of other players’
games, nor other subject’s total score, similarly to many real negoti-
ation environments in which traders are enable to see only their own
trading results.
ﬁll out an anonymous questionnaire after the experiment. It
was revealed that the exercise was considered very seriously,
and 96% of the respondents read their agents code very care-
fully. We believe that this percentage is even higher than
the percentage of traders who would read a recommended
agent’s code in the real world, for several reasons. First, not
all traders are programmers. Therefore, in order to read the
recommended agent’s code or modify it they must make an
effort and consult a programmer. Second, in our experiment
we explicitly mentioned the possibility of changing the rec-
ommended agent’s code. In real world situations, however,
we believe that many traders would not be aware of this pos-
sibility.
6
Comparison: SC and Peer Designed Agents
In the previous sections we discussed the question of which
kind of agent a central entity should provide to a population,
given that it should provide a certain recommended agent.
However, frequently the central entity has the choice of decid-
ing whether to provide a recommended agent or to let traders
design their own agents by themselves. It is not trivial that
the ﬁrst option is preferable, for a few reasons. First, it is
well documented that people do not play and do not design
agents according to the equilibrium strategy [Grosz et al.,
2004]. Second, when each trader designs his own agent, no
trader knows the other agents’ strategies. This is in contrast
to the recommended agent approach, in which traders can ex-
ploit their knowledge about the strategy of others and modify
their agents to achieve higher scores at the expense of others.
In order to compare the recommended agents to Peer De-
signed Agents (PDAs), we asked another group of 33 sub-
jects to design agents that play the resource allocation game,
without providing any recommended agent code. In addition,
the subjects were asked to present verbal documentation ex-
plaining their strategy. In order to help subjects to focus on
strategy matters and not on coding, we provided them with an
agent skeleton which included three functions: Accept, Send
and Propose. The subjects were instructed to implement these
functions.
Following the high performance of SC agents (described in
Figure 1) we hypothesized that the group that received a rec-
ommended SC agent would yield a higher overall utility com-
pared to a group that had not received a recommended agent.
We based our hypothesis on the assumption that providing
a default SC recommended agent would cause some people
to adopt it and to play cooperatively, though they would not
have designed such a cooperative agent by themselves. As
expected, the average score of all the games played by the
PDAs (shown in Figure 1.b) is signiﬁcantly higher (Mann-
Whitney test, p < 0.01) than in the EA tournament. How-
ever, this score is signiﬁcantly lower (Mann-Whitney test,
p < 0.05) than the average score of agents in both SCA
and CCA groups. In particular, three PDAs were equilibrium
agents, and ten others never sent their opponents all the re-
sources required for satisfying their goals. The remaining
20 agents enabled their opponents to satisfy their goals in
some of the games. This explains the higher performance
of the PDAs compared to the EA group. However, there were
IJCAI-07
1413

games, where the 20 agents played against each other without
satisfying the goal of both players. This is because the PDAs
were heterogeneous and two PDAs could have different ex-
change rates. Thus, in some of games they could not reach an
agreement during negotiations. In contrast, since most sub-
jects adopted the recommended agents in the CCA and SCA
tournaments both players usually satisﬁed their goals.
7
Conclusions And Future Work
In this work we present a novel approach for providing au-
tomated trading agents to a population. We focus on bilat-
eral negotiations with unenforceable agreements. Unlike the
traditional Game Theory approach that recommends the pro-
vision of equilibrium agents which are not always pareto-
optimal, we propose to provide a new type of agents called
semi-cooperative agents that are not in equilibrium. When
these agents negotiate with each other they reach a pareto-
optimal solution that is mutually beneﬁcial. The theoreti-
cal risk in providing such agents is that people can change
their agents in order to increase their own utility at the ex-
pense of others. However, we hypothesized that if people
are provided with agents that are reasonable and beneﬁcial
for both sides, most people will not spend time and effort to
change it. Therefore, we designed semi-cooperative agents
which yield higher beneﬁts for both sides using it, compared
to the case of both sides using equilibrium agents. In order
to test our approach we designed an unenforceable resource
allocation game, which simulates real life bilateral negotia-
tions. Indeed, experimental results of this resource allocation
game fully supported our hypothesis. The experiments show
that providing SC agents to a human population yields bet-
ter results than providing equilibrium agents or letting people
design their own agents. Our results, based on 99 program-
mers who mostly did not change their agents, has led us to
assert that common clients, who are typically non program-
mers, will not invest the efforts needed to change the code in
complex real world situations. In light of these ﬁndings we
propose that users’ reactions to recommended agents should
be taken into consideration when developing agents that are
provided to a population.
Our research focuses on negotiation environments, which
are very common in commercial life. However, the SC prin-
ciple may also be successfully implemented in other environ-
ments, such as: information exchange, where the information
transferred is not necessarily reliable, or tasks distribution,
where each agent decides how much effort to invest in carry-
ing out its part in the assigned task. In the future we intend to
examine our approach in such environments. In addition we
plan to develop a formal model that will support our approach
and explore our agents in real trading problems.
8
Acknowledgment
This work was supported in part by NSF #IIS0222914 and
ISF #1211-04. Kraus is also afﬁliated with UMIACS.
References
[Croson and Marks, 2001] R. Croson and M. Marks. The ef-
fect of recommended contributions in the voluntary provi-
sion of public goods. Economic Inquiry, 39(2):238—249,
2001.
[Da-Jun and Liang-Xian, 2002] C. Da-Jun and X. Liang-
Xian. A negotiation model of incomplete information un-
der time constraints. In AAMAS02, pages 128–134, 2002.
[Fatima et al., 2005] S. Fatima, M. Wooldridge, and N. R.
Jennings.
A comparative study of game theoretic and
evolutionary models for software agents.
AI Review,
23(2):187–205, 2005.
[Gal et al., 2004] Y. Gal, A. Pfeffer, F. Marzo, and B.J.
Grosz. Learning social preferences in games. In AAAI04,
pages 226–331, 2004.
[Grosz et al., 2004] B. Grosz, S. Kraus, S. Talman, S. Boaz,
and M. Havlin. The inﬂuence of social dependencies on
decision-making: Initial investigations with a new game.
In AAMAS04, pages 782–789, 2004.
[Hogg and Jennings, 2001] L. M. J. Hogg and N. R. Jen-
nings.
Socially intelligent reasoning for autonomous
agents. IEEE Transactions on Systems, Man, and Cyber-
netics, Part A, 31(5):381–393, 2001.
[Mui et al., 2002] L. Mui, A. Halberstadt, and M. Mo-
htashemi. Notions of reputation in multi-agents systems:a
review. In AAMAS02, pages 280—287, 2002.
[Zhang et al., 2000] X.
Zhang,
R.
Podorozhny,
and
V. Lesser.
Cooperative, multistep negotiation over a
multi-dimensional utility function multi-agent systems
negotiation. In ASC00, pages 136—142, 2000.
IJCAI-07
1414

