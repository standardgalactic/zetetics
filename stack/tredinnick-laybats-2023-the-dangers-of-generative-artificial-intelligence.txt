Editorial
Business Information Review
2023, Vol. 40(2) 46–48
© The Author(s) 2023
Article reuse guidelines:
sagepub.com/journals-permissions
DOI: 10.1177/02663821231183756
journals.sagepub.com/home/bir
The dangers of generative artiﬁcial
intelligence
2023 looks set to become the year that anxieties about the
risks posed by artiﬁcial intelligence (AI) escape from their
safe conﬁnes in techno-sociological debates into the wider
public consciousness. Barely a week has gone by without a
new warning about the threat of AI and the potentially dire
consequences of emergent technology.
In the last month alone dozens of stories have appeared in
the world’s press. Tech leaders and academics issued a
statement warning that AI poses a risk of human extinction
and should be treated as “a global priority alongside other
societal-scale risks such as pandemics and nuclear war”
(Centre for AI Safety, 2023). Professor Stuart Russell was
reported as stating that “if we don’t control our own civi-
lisation, we have no say in whether we continue to exist.”
(Taylor, 2023). An article in BMJ Global Health was
published warning of the existential threat of AI (Federspiel
et al., 2023). Geoffrey Hinton – widely described as the
“godfather of AI” - warned of a “serious danger that we’ll
get things smarter than us fairly soon and that these things
might get bad motives and take control” (Allyn, 2023). A
simulated trial of AI drones was reported to have developed
“highly unexpected strategies” included “killing” its op-
erators to allow it to complete its mission (Guardian, 2023).
On top of this have been hundreds of opinion articles and
other news items addressing the risk of AI. The average
news junkie could be forgiven for thinking that the tech-
nological singularity – a longstanding fear about runaway
AI driven technological advancement - is only weeks or
months away.
This sudden panic about the future of AI is in large part a
product of the success of large language models and
emerging forms of generative AI particularly in music and
image creation. There is something uncanny about the
apparent human-level of understanding of the latest gen-
erative AI technologies, which can respond with remarkable
prescience to often quite vague requests and generate ap-
parently spontaneous and humanly meaningful outputs.
Interacting with ChatGPT can give the impression of
communication with a conscious and self-aware machine.
But this experience reveals more about what it means to be
human, that it does about the abilities of technology. We are
predisposed to perceive motivation and understanding in the
acts of others, and generative AI has reached the point
where it can trick us now and then into seeing motivations
that are not there.
Fortunately the current threat of AI is vastly overstated
and the technological singularity remains a distant theo-
retical danger. We are not really signiﬁcantly closer to the
emergence of Artiﬁcial General Intelligence, and however
uncanny the experience of interacting with large language
models, they remain resolutely dumb, lacking anything that
can be interpreted as true understanding. But while the
current generation of AI is are not about to develop au-
tonomous dangerous behaviours, nevertheless it does
present new challenges for regulation, law, and professional
practice. These challenges include:
·
Misinformation and fake content: Generative AI can be
used to create realistic but entirely fabricated content
including news articles, social media posts, or images,
raising the risk of their use in generating and spreading
misinformation, fake news, and propaganda, and the
potential automation of misinformation campaigns.
·
Privacy, data security, and intellectual propertu: In
their training Generative AI models require vast
amounts of data. There is a risk that these models may
inadvertently leak sensitive or personal information
from this training data. Generative AI could also
potentially be used to generate synthetic data that
mimics real individuals, leading to new forms of
identity theft. In addition Generative AI models can
inadvertently produce content that infringes copyright,
trademarks, or patents.
·
Ampliﬁcation of bias: Generative AI models learn
from data, often including text and images from the
Internet, which may contain inherent biases and
prejudices. These biases can be reﬂected in the
content subsequently generated, perpetuating and
amplifying societal inequalities, stereotypes, and
generating new forms of discrimination.
·
Malicious uses: Generative AI can be exploited by
individuals with malicious intent to create content
with harmful or illegal uses, such as generating re-
alistic phishing emails, producing counterfeit docu-
ments, or designing convincing scams.
·
Ethical Considerations: The deployment and use of
generative AI raise broader ethical concerns including
consent for use of personal data, transparency in the
disclusure of AI-generated content, and a potential
impact on human creativity and employment.

·
Economic disruption: AI may bring with it economic
disruption as the automation of the creation of dif-
ferent kinds of content upends industries that have
previously relied on human-generated content, and
this disruptive effect is likely to increase over time as
generative technologies become increasingly em-
bedded in automated content creation contexts.
Some of these dangers are already present. The publisher
of Charkesworld Magazine recently suspended new ﬁction
submission after being overwhelmed with AI generated
proposale (Hern, 2023); traditional ways of assessing
professional or educational attainment are threatened by
large language models (Pirrone, 2023); large language
models are already ﬁnding application in twitter farms and
phishing operations. However, these are nevertheless cur-
rently manageable risks that are within the range of current
human behaviour, and which can be mitigated by improved
general understanding of the emerging and shifting infor-
mation ecosphere. In this respect the current risks posed by
new AI technologies are an acceleration of social and
technological trends originating in the global shift to online
communications in the mid nineteen-nineties.
Nevertheless 2023 does mark an important moment in two
ways. In the ﬁrst place it marks the point at which generative
AI has become good enough to become universally useful,
and yet still ﬂawed enough in its responses to give a glimpse
of the ghost inside the machine. Large language models for
example still betray their lack of true understanding, struggle
with contextual and nuanced interpretations, and sometimes
generate overconﬁdent responses. These ﬂaws will not only
limit the use of generative AI in the near future and require
careful human curation of machine-generated content, but are
also baked-into the statistic approaches they use to generate
content, and may prove very difﬁcult or impossible to fully
resolve. In the second place 2023 is also the moment at which
the novelty of generative AI is precisely balanced against its
uncanny impression of human creativity, giving us an insight
into the social and psychological impact of artiﬁcial general
intelligence in the future. As generative AI becomes more
widely used the uncanny nature of machine-generated texts,
images, music and programming scripts will fade and such
technologies will come to be seen as tools to be used as part of
creative processes akin to spellcheckers or digital editing
suites, not driving creativity but slaves to the human mind.
Yet their current novelty gives us a glimpse at how society
might respond to future Artiﬁcal General Intelligence.
The question in the present is therefore not what we can do
to mitigate the long term existential risks of AI, but what we
can do to integrate these technologies into our current social
structures and organisations to the beneﬁt of society as a
whole, and without exacerbating existing or future in-
equalities. More important for Business Information Review
is the role that is the role that Information and Knowledge
Professionals can play in this.
1.
Data Management and Governance: Information pro-
fessionals can help ensure that the data used in AI
systems is well-managed, clean, and appropriately
governed. They can establish data management prac-
tices, develop data catalogues, and deﬁne data quality
standards to support accurate and reliable AI models.
2.
Information Retrieval and Knowledge Organization:
AI systems rely on organized and structured infor-
mation. Information professionals can contribute
their expertise in information retrieval, taxonomy
development, and knowledge organization to help
categorize and tag data, enabling effective search,
retrieval, and analysis by AI algorithms.
3.
Ethical considerations and Bias Detection: Information
professionals can help identify and address ethical
considerations
and
potential
biases
in
AI
im-
plementation. They can assess the fairness and equity
of AI systems, conduct bias audits, and contribute to the
development of responsible AI practices and policies.
4.
End user education: Information professionals can
provide training and support to employees on using AI
tools and technologies effectively. They can educate
users on the beneﬁts and limitations of AI, promote
digital literacy, and help individuals understand how to
interpret and critically assess AI-generated information.
5.
Information Privacy and Security: AI systems often rely
on sensitive and personal data. Information professionals
can contribute to ensuring data privacy and security
measures are in place. They can assist in implementing
data protection frameworks, complying with regula-
tions, and educating users on data privacy best practices.
6.
Knowledge Discovery and Insights: Information
professionals can leverage AI technologies to en-
hance knowledge discovery and insights within or-
ganizations.
They
can
apply
natural
language
processing and machine learning techniques to un-
cover patterns, trends, and relationships in data,
enabling better decision-making and innovation.
7.
Collaboration and Cross-functional Support: Information
professionals can act as facilitators, fostering collabo-
ration between different teams and departments involved
in AI implementation. They can bridge the gap between
technical and non-technical stakeholders, helping to
align business goals, data needs, and AI capabilities.
8.
Continuous Professional Learning and Development:
AI technologies are evolving rapidly, and information
professionals can stay abreast of the latest advance-
ments, research, and best practices. They can participate
in professional development activities, attend confer-
ences, and engage in knowledge sharing to ensure they
Tredinnick and Laybats
47

can contribute effectively to AI implementation in the
workplace.
Generative AI therefore raises a set of new professional
issues, and highlights emerging areas of professional
knowledge that are likely to become central to information
and knowledge work of the future. Business Information
Review has addressed some of these concerns over the past
6 years, including exploring the impact of AI on profes-
sional roles (Tredinnick, 2017; Kirkwood, 2018), the ethics
of AI (Carter, 2020), and cognitive automation (Richardson,
2020), as well as reﬂecting on industry trends through our
Annual Survey (Carter 2018). It is a topic that we are likely
to return to repeatedly into the future.
June issue of Business Information Review
This issue of BIR has a focus on professional issues and
professional training within the commercial information and
knowledge management sector. Our ﬁrst professional paper
this issue explores the role of apprenticeships as a path into
the Library and Information Profession. Written by Claire
Laybats, the paper outlines the development of apprentice-
ship pathways in the UK in collaboration with the Chartered
Institute of Library and Information Professions. Our second
professional paper also focusses on the role of CILIP in
developing professional careers. Claire Robe discusses op-
portunities for continuing professional development (CPD)
offered by CILIP, including professional registration, ac-
creditation, and the Employer Partners Scheme.
Our ﬁrst opinion paper shifts focus to professional body
support in Africa. Entitled “Investing in Employability of
Librarians: An Impetus for Enhancing the Professionalism
of Librarians in Nigeria” the paper argues for steps to en-
hance the professional status of Nigerian librarians. Our
second opinion paper was contributed by Mostafa Sayyadi
and explores “The New Patterns of Organization and In-
novation for the Future”. Finally this issue includes two
research article addressing processional issues. The ﬁrst
addresses the role of infopreneurship in information and
knowledge management careers. The second addresses the
role that social media proﬁles play in recruitment.
Luke Tredinnick and Claire Laybats
References
Allyn B. (2023), ‘The godfather of AI’ sounds alarm about po-
tential dangers of AI, Available at: https://www.npr.org/2023/
05/28/1178673070/the-godfather-of-ai-sounds-alarm-about-
potential-dangers-of-ai (accessed on 06 June 2023).
Carter D (2018) How real is the impact of artiﬁcial intelligence the
business information survey 2018. Business Information
Review 35(3): 99–115.
Carter D (2020) Regulation and ethics in artiﬁcial intelligence and
machine learning technologies: Where are we now?who is
responsible?can the information professional play a role?
Business Information Review 37(2): 60–68.
Centre for AI Safety (2023) Statement on AI risk. Available at:
https://www.safe.ai/statement-on-ai-risk (accessed: 6th June
2023).
Federspiel F, Mitchell R, Asokan A, et al. (2023) Threats by ar-
tiﬁcial intelligence to human health and human existence.
BMJ Global Health 8(5).
Guardian (2023), US air force denies running simulation in which
AI drone ‘killed’ operator, Available at: https://www.
theguardian.com/us-news/2023/jun/01/us-military-drone-ai-
killed-operator-simulated-test Accessed: 06th June 2023].
Hern Ales (2023) Sci-ﬁpublisher Clarkesworld halts pitches amid
deluge of AI-generated stories. The Guardian February(21st).
Available at: https://www.theguardian.com/technology/2023/
feb/21/sci-ﬁ-publisher-clarkesworld-halts-pitches-amid-
deluge-of-ai-generated-stories.
Kirkwood H (2018) The current state of artiﬁcial intelligence and
the information profession. Business Information Review
35(1): 9–11.
Pirrone Angelo (2023) Resist AI by rethinking assessment. LSE
Higher Education Blog March. Available at: https://blogs.lse.
ac.uk/highereducation/2023/03/23/resist-ai-by-rethinking-
assessment/.
Richardson S (2020) Cognitive automation: a new era of knowledge
work? Business Information Review 37(4): 182–189.
Taylor H (2023), Ministers not doing enough to control ai, says UK
Professor, the guardian, 13th May 2023, Available at: https://
www.theguardian.com/technology/2023/may/13/ministers-
not-doing-enough-to-control-ai-says-uk-professor (accessed:
06th June 2023).
Tredinnick L (2017) Artiﬁcial intelligence and professional roles.
Business Information Review 34(1): 37–41.
48
Business Information Review 40(2)

