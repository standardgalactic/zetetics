ORIGINAL ARTICLE
Theorizing change in artiﬁcial intelligence: inductivising
philosophy from economic cognition processes
Debasis Patnaik
Received: 30 December 2012 / Accepted: 14 October 2013 / Published online: 10 November 2013
 Springer-Verlag London 2013
Abstract
Economic value additions to knowledge and
demand
provide
practical,
embedded
and
extensible
meaning to philosophizing cognitive systems. Evaluation
of a cognitive system is an empirical matter. Thinking of
science in terms of distributed cognition (interactionism)
enlarges the domain of cognition. Anything that actually
contributes to the speciﬁc quality of output of a cognitive
system is part of the system in time and/or space. Cognitive
science studies behaviour and knowledge structures of
experts and categorized structures based on underlying
structures. Knowledge representation through understand-
ing of ‘epistemic cultures’ is an evolutionary stage. But
cognition goes beyond knowledge representation. Not-
withstanding the importance of epistemology of phenom-
ena,
the
practicability
cum
philosophical
aspects
of
machine learning needs to be seen in dynamic behaviour in
socio-economic-technical
value
additions
if
human
machine interaction processes that are context speciﬁc are
incorporated into strong artiﬁcial intelligent systems.
Cognitive Science is also studied from both computational
and biological angles. Evolution of interactive forms of
reasoning through understanding of meta-language of
computations or biological learning processes is possible.
But the limitation of historical cultures predeﬁnes the role
of interactive processes in user-networks beyond technol-
ogy networks. Despite this limitation, inclusive develop-
ment notions of a heterogeneous national society such as
India or Europe can be tested and incorporated.
Keywords
Physical symbol systems 
Connectionism  Evolutionary  Cognitive 
Human factors  Economic value addition
1 Introduction
The progress of industrialization was an outcome of
contrarian thinking to the immediate goals of traditional
religious thinking that tended to deﬁne and impute
meaning to the world, its actions and the inherent thinking
process embedded in it. It shaped man in ways of logical
thinking, provided meaning to its multiple language
structures and sought a harmony across world’s language
structures within a framework of free and diversiﬁed
thinking. It brought value addition to the issue of ideas
and matter, to paradigms that grew and enriched one
another. When machines grew to command a space of its
own, it manifested signs of efﬁciency, wear and tear with
manifold levels of human–machine interaction processes.
Artiﬁcial Intelligence (AI) brought in a concept of an
agent centric rule that based its action-decisions on
observation
programs,
belief
systems
and
adductive-
interactive processes. In multi-agent systems, the primary
language of the agent performed a secondary function of
communicating with other agents and in turn incorporat-
ing the feedbacks. Procedural and inferential processes
generated decision-making outputs thereby aiding in the
world’s language and actual economic production sys-
tems. Behavioural productions of the world resulted from
individual’s language, cognitive and economic structures
that
shaped
philosophical
thinking
to
transform
the
world’s agenda for action.
When Kirsh (1991) formulated the ﬁve foundational
issues
of
AI,
at
its
core
was
the
initiation
and
D. Patnaik (&)
Department of Economics, Birla Institute of Technology and
Science, Pilani-K.K. Birla Goa Campus, 17 B Bypass Road,
Zuari Nagar, Vasco 403726, Goa, India
e-mail: marrikesh@yahoo.com
123
AI & Soc (2015) 30:173–181
DOI 10.1007/s00146-013-0524-5

conceptualization of knowledge level theories that would
make for diversiﬁcation, expansionism and possibility of
non-homogeneous multiplicity of architectures underlying
it? His avowal of cognition as a disembodied process even
without
solving
symbol-grounding
problems
had
the
potential to provide discrete philosophical insights despite
not being Unitarian or reductionist. Learning was seen as
an accumulative process of knowledge with its unique
semantic structures and so describing cognition in propo-
sitional terms was seen as retaining the innovative physical
symbol structures (PSS) of Newell and Simon at the core of
knowledge processing structure and to that extent justify-
ing a single architecture underlying all cognition.
The approach in this paper is taking the Thinking Humane
(Cognitive Modelling) and Acting Rational (rational Agent)
aspects of Russell’s fourfold approach to Ai while discussing
the nature of the inter-relationships in economic and cogni-
tive aspects wherein mega-philosophical thinking aiming to
provide the ontogenetic cover. Computational issues of
ontological engineering is not delved into but is subsumed
within the cognitive-economic mode. This is so even when a
Noisy neural Bayesian computational model is proposed
(Shi 2009) in case of feature-binding problems encountered
in basic perceptual representation problems in visual, audi-
tory, kinaesthetic, olfactory or gustatory aspects of model-
ling generative functions for making a volumetric spatial
sense of the world1 where the weights of connection between
neurons reﬂected statistical relation between them. Each
neuron with two parts of inputs (feeding and linking) with the
neurons integrating these inputs non-linearly. Outputs of
neurons were determined by their own output and also output
of their neurons.
Philosophical thoughts originate in beliefs, words and
actions as believed by Hagerman (84:2). Similarly, any
rational system should be able to learn from its mistakes
and refutations of hypotheses. This can be akin to the
genetic epistemology of Piaget. In Piaget, the cognitive
processes
can
be
seen
as
internally
re-constructible
sequences
of
competencies.
Such adaptive
processes
expand the sphere of learning processes. This gives rise to
action, output and testability of fallibility propositions.
Chomsky (1968) would post a bio-physical featuring of the
human mind providing for the possibility of ediﬁcatory role
in universal transmission processes.
When language is used as an emergent property for
training a connectionist network (By bee), competencies
and performances therein make it unique among cognitive
capacities. Epistemologies bring categorizations making
for user-speciﬁc agent applications the corner stone for
evolutionary advancement of machines in the context of an
economic society. In artiﬁcial intelligence systems, rea-
soning, knowledge, planning, learning, communication,
perception and problem solving making for autonomy,
local views and decentralized architecture provide oppor-
tunities for sustainable machine–human interaction as
connectionist models of the future both as expert systems
and its multi-agent system (MAS).
2 The Challenges
The objective of this essay arises from the manifold
problematic faced by AI: its innate historical dreams to
provide for a new paradigm for science that would
encompass the essentiality of all sciences, basic and social,
and to carry the unifying seeds of all technology. It did
make a cardinal mistake in its progress of not making
sufﬁcient efforts to provide for a multiplicative interpre-
tation of ‘intelligence’ that would have enabled diversity of
output satisfying different sub-themes and plots. The bot-
tlenecks it faced did provide for discussion and penaliza-
tion bringing together Thomas Dean, Tom Mitchell,
Rodney Brooks, Niles Nilsson, Eric Horvitz that threw the
future spotlight on challenges that must be addressed if AI
is to live up to its past promise. This was embedded in the
meta issue of how to measure progress made in this dis-
cipline. Rodney Brooks of MIT put the issue in perspective
when he broadly categorized the problems as those of AI’s
performances when arraigned against biological systems
and when seen from a positive angle leading to a socio-
logical problem of ‘winner takes all’ situation. The basic
question that needed to be faced was whether there can be a
program that can probe an unknown architecture and
reconﬁgure it so as to be a self-optimizing exercise. Going
beyond bounded rationality assumptions so as to tackle
asymmetric ties in complex structures was thought out to
be a benchmark of success. Moderately put, it was asked as
to whether divergence in program could be measured, i.e.
error in program or data representation. Variable genotypes
embodied in some new ‘perception’ (beyond Minsk and
Paper of 1969) in evolutionary processes were another
computational challenge to achieve non-trivial goals.1
1 To implement competitive relationship among neurons (taking cue
from Crick’s view that when external stimuli come to brain-speciﬁc
neurons corresponding to features of same object form dynamic
neural assemblies by a temporal synchronous neural oscillation to
code objects in external world. So a ﬁring probability of a competitive
neuron within a Bayesian P(X/l1, l2….) = P(X) pij is wh
y P(I) where
elk is linking pre-synaptic neuron, X is neuron and wh
y = (Ply/X)/P(lid)
where P(X) is prior probe calculated from feeding information; and
P(X/l1, l2….) is post probe after getting information from linking
P(elk) is ﬁring probability of lj. Therefore, for assessing ﬁring
probability, posit X1 X2….Xn be n neurons competitive to one another;
Pbefore (Xi) is ﬁring probability of Xi before competition; and so ﬁring
probability after competition is Pafter (Xi) = Pbefore (Xi))/Summation
Pbefore (Xj).—From Shi J-Chinese Academy of Science-Institute of
Computing Technology-ky Lab of Intelligent Information processing.
174
AI & Soc (2015) 30:173–181
123

Developments in neuronal science to challenge bio-
logical learning capabilities were another visionary goal.
Despite deep blue, playing chess as a human would deﬁne
progress.
Building
a
noise-understanding
system
or
speech-understanding not based on generative grammar
and hidden Markov was marked as a goal. Thomas Dean
(ibid) sought an integration of theory and practice through
understanding of the planning problem. He posited a
progression in learning theory as providing for a possi-
bility of providing newer planning problems. He lamented
minimal interplay of theorization and experimentations as
a social, academic and attitudinal constraint though he
wondered why science should suffer due to such an
impasse in human behaviour. Asymptotic arguments on
sharp threshold functions, relevance of phase-transition
phenomenon and assessment of statistical properties of
graphs were further practical and pedantic problems fac-
ing the discipline.
Further sub-problems as part of original systems were
considered. For example how to create autonomous sys-
tems in dynamic environments, over extended time periods
entrusted with complex tasks meant processing streams of
events over lifetimes with greatest expected utility. The
key phases of automated decision-making included steps of
perceiving states of world-framing decisions, performing
inferences to compute beliefs about the world and identify
best set of actions were necessary. Autonomous systems
needed to make decisions in an evolving environment that
can change dramatically overtime partly in response to
actions emanating from systems. Thus, systems needed to
be endowed with ability to represent and reason about
time-dependent dynamics of belief factors, including
notions of persistence and world states.
All the above needed a cognitive frame as is traditional
with value-adding implications providing the economic
context. But thinking and methodological justiﬁcation via
individualism or holism provide the philosophical envelope
and mooring and insights that would necessitate AI agenda
of the future. It is for this reason that a work of this nature
is undertaken here.
The world of economics provided many sub-problems.
Modelling preference and utility is one of them. The
Axiom of Utility governs the principle of expected utility.
The philosophical questions that are asked here:
1.
Where does information about Utility of States come
from?
2.
Whose Utility is being maximized?
3.
How to derive Utilities of High levels Goals such as
longer living?
4.
What is the most reasonable Utility Model for
evaluating
ﬁnite
sequence
of
actions,
An
agent(s) take over time?
It is necessary to note that different assumptions about
speciﬁc structure of Utility Models lead to different notions
of best behaviour and different computational efﬁciency
proﬁles evaluating sequences of plans (Tsang 2007).
Planning involves knowledge representation (of belief,
actions and effects), causal reasoning (about action resur-
gence) and resource allocation (i.e. economic time as to
when to perform what action). Computation as one of the
cognitive actions provides for decision procedures encoded
in algorithms and heuristics. Bounded-lee rational utility
structures explicitly specify decision maker’s decision-
making procedures. So in Tsang, the effective rationality of
an agent being determined by its computational power does
not allow for unifying deﬁnition of all types of bounded
rationality that can be used in machine systems and so no
reductionist approach would be suitable. Being rational
meant to maximize one’s utility, given all available infor-
mation. Even when full rationality assumption is relaxed, a
computational approach allowed reasoning on economic
systems. The General Problem Solver, an early approach to
AI, planned for evolutionary development and cross cul-
tural development by separating domain-speciﬁc knowl-
edge from reasoning mechanisms.
An odd cognitive dimension such as a psychological
feature of mastery of attention and architecture do have an
economic dimension. Perceiving, reasoning, acting all
require costly resources. Therefore, controlling allocation of
computational resources can be a critical issue in maximiz-
ing value for behaviour in situated systems. Organization-
ally, it may also be asked as to what aspects of a problem and
problem-solving strategy should a system attend to and
when? Can a decision theoretic approach be enforced into
problem-solving architecture? Using an expected value of
computation (EVC) to make design time and time decision
about ideal quantities of computation and memoryto allocate
alternate phases of reasoning including control processes
shows embedded-nests of economics in cognitive systems.
Learning about self and environment with alternative
ontology’s does have idle time between active problem-
solving sessions. A holistic world-view needs constantly
opera table machines to address alternative problematic in
competitive time slots thus making for a lower transaction
costs in machine operation.
Tom Mitchell invokes researchers to think big and says
that Ai needs to go beyond incremental progress. So he
asks whether programs could be developed to make WWW
as worlds’ biggest knowledge base. The problem was that it
can take a million people to build but maintaining them is
difﬁcult. Today Web is online marked with text, image,
sound but not logic. So the challenge is how to ‘read’ it and
turn it into a frame-based symbolic representation mirror-
ing content of the web. One approach he says is to apply
AI & Soc (2015) 30:173–181
175
123

machine learning to learn to understand natural language.
Hyperlinks are already doing that to show meanings of
sentences and phrases. Thirdly, it is necessary to build
agents to show lifelong machine learning, i.e. how to build
agents exhibiting long-term learning that is cumulative in a
way-like
people
learn
(not
sub-routine
learning
of
machines via algorithmic learning that learn one thing at a
time and then reboot).
Nils Nilsson searches for ﬂexible and robust robots that
need not go back to the factory for re-programming. With
effectors, sensors and software’s for instruments, robots
will perform as and when necessary. The issue is how to
build hierarchies of useful action routine and appropriate-
associated perceptual processing routines to guide them to
action. He cites James Album 1991 twin-towers archi-
tectures
for
overall
control
and
towers
grow
with
instruction and experience. Drescher (1991) develop-
mental learning as a computational model is also high-
lighted for experiment.
AI’s cognitive framework reached a peak in Newell’s
1980 physical symbol systems (PSS) and moved past
symbol-grounding structures. When McClelland (2012)
was asked to speak on symbolic structures in a thirtieth
anniversary of Cognitive Science Society, he wondered
how newer structures emerged from older ones and how
a representational system can be built in AI so that
science keeps pace with the ongoing evolutionary, cre-
ative progress of man in human society and getting
manifested in diverse creative arts. PSS was having
difﬁculty in capturing context sensitive data and coming
to terms with human-cognitive abilities. According to
the emergent’s perspective, intelligence emerges out of
neuronal interaction. Holland 1998 said emergent prop-
erties can be seen in patterns of units and/or processes in
programming systems. Bunge (2003) states that these
units/processes may be more or less complex vis a vis
the substrate that gives rise to them. Intelligence is less
about repetition and regularities but more about real time
behaviour
such
as
perception,
comprehension
and
inductive capabilities. Hofstadter (1979) pointed out that
even intuition may be less a goal-directed process and
more out of a substratum, sub-symbolic constraint sat-
isﬁcing system. Holland’s introduction of genetic algo-
rithms could be an example of emergent property in
computational computer science. Building on Hopﬁeld’s
(1984) approach, Rummelhart et al. (1986) built a con-
nectionist network of a house with different goodness
states bringing on a schema of representation. Concom-
itant to the emergent rules in schemata, linguistic rules
arose as emergent properties as a part of putative rep-
resentationalism. When distributed connectionism arose
as response to questions posed by the earlier wave,
choice making was questioned as improbably discrete
outcomes. Yet those decision states were the attractor
states arising out of inhibitory and excitatory interplay of
processing elements. Thus, economic applications along
with predictive games added value to the project to
global AI systems. Competitive elements in between
discrete and continuous structures showed the strength of
inputs supporting those states and provided meat and
malleability to those decisions. Moreover, the mind was
seen as less biologically programmatic and more a
consequence
of
competitive
processes
of
cognition
structures.
In symbol-grounding experiments of Harnad in response
to Searle’s Chinese Room, it was thought that realism of
symbols would imbue understanding to Robots. Problems
of categorization and best criteria would help in assessing
epistemology of need and accessibility for economic sat-
isfaction. But the test of understanding so effectively
refuted by Turing (1950) was challenged by Harnad when
the latter said that a cognitive reorganization of features
provides the necessary ‘groundability’ to robots and makes
for understanding. Mayo’s (1993) new test makes symbols
intrinsic to the system (syntactic manipulations of symbols
do not apply to the grounded robot). This is rooted in the
idea that intelligence means both acquiring and learning
about its symbols.
Mind language machines, each has its own cognitive
domain. Along with Ai, linguistics, neuroscience psy-
chology, etc., these cognitive sciences search for an
interdisciplinary synthesis that is not so easily forth-
coming. The movement from machine language to a PSS
and later to connectionism seemed to provide a phe-
nomenological connection beyond super-structuralism. To
scientiﬁcally
and
perspectivally
analyse
cognitive
achievements in AI, philosophers must learn to undertake
testable hypotheses.
Rationality and reasoning provide bases of philosophical
and economic reasonings and theory/methodology building
in sciences. AI can try to model irrationality and rationality
using computational intelligence. But the challenge that
gets generated relate to degree of biasness in learning
modules. Behavioural ﬁnance is a practical science that
models irrationality, and bias emergent system behaviour is
dependent on behaviour of agents in the system. Cognitive
modelling and inclusion of bias were sought to explain
both in case of self-esteem as an explanation of ﬁnancial
risk propensity and risk preference in the system and also
momentum trading in Indian stock markets. Taking cue
from Tsang that effective rationality of an agent is deter-
mined by its computational intelligence, ceteris paribus
agents that had better algorithms and heuristics would
make more rational and optimizing decisions. Epistemol-
ogy would then aim to formulate a method for justiﬁcation
of cognitions.
176
AI & Soc (2015) 30:173–181
123

3 Interactionism’s implications for architectures
Terveen’s (1995) model whether among agents or human–
computer interface has same semantic problematic and
symbol groundedness issues versus encodingism’s problem
of correspondences. But the ‘knowing how’ feature pro-
vides for greater possibilities of interactions, and therefore,
possible greater choice sets, and therefore, freedom in
decision-making processes of economics and social sci-
ences. The basic epistemic of representation as function
(wide functionalism) is a property of the system with its
meaning as use as in Wittgenstein (Anat 2011). Internal
selection criteria though make it error prone to that extent.
Environment differentiations and implicit deﬁnitions are its
foundation stones. Its evolutionary foundations have a
sequence of knowing, learning and a certain reﬂexive
consciousness brining in a macro-evolutionary epistemol-
ogy that would suit macroeconomic paradigms.
The Interactionist alternative is akin to ‘knowing how’
and does not correspond to the encodingist notion of
‘knowing that’. It indicates that in certain circumstances a
certain course of action is possible. But what would be the
implications of such a perspective to perception and
language?
A computational architecture such as SOAR did good
representation with sub-goal structures but neither could be
a model for general intelligence nor could it reﬂect or
recurse.
Moreover, connectionist/interactionist has not gone far
probably because the radicalness of the functional rela-
tionship between a machine and external stimulus envi-
ronment could not be foreseen especially when the internal
machine state is considered on a ﬁnite state automata mode
despite great achievements in overcoming domain speci-
ﬁcity. Generic theory could do an exploratory internal
structure by developing search and proof technique for
managing symbolic knowledge bases only. The embodied
cognitive potentials could not be understood properly.
Perhaps,
some
external
permanent
existing
domain
knowledge structures could be a way out. The Arbetsliv-
scentrum group on participatory design that works on
human–machine interfaces is posited as a way out. For
example, project MEDICA-AMIGOS integrates human-
speciﬁc knowledge in a real world contribution towards
developing a Commercial Human-centred Software appli-
cation (Gill 1996a, b).
Rasmussen et al. (1988) deﬁne the human-centred par-
adigm as an individual and collective learning process that
includes four inter-related perspectives. They are the
following:
1.
Dialectical development orientation using possible
alternative perspectives arising out of human conﬂict.
2.
Shaping
perspective
that
tends
to
integrate
and
harmonize social and technical design.
3.
Dialogue perspective integrating producer and user
viewpoints
4.
Social sustainability perspective based on interconnec-
tedness of individual, society and nature3.
Apart from philosophizing on cognitive phenomenol-
ogy, value additions via creative applications in different
ﬁelds are making hypothesis testing approaches in philo-
sophical research lucrative and demanding.
The Scandinavian UTOPIA research Ehn (1988) sees
involvement of users in design to promote organization
change process. Users need to have experience of being in
a future use situation. Ehn explored language games (akin
to
Wittgensteinian
‘practice’)
for
participatory
user
involved design. In such a language game, metaphors and
prototypes for facilitating learning processes.
The syntagmatic approach in phenomenology is not
the ending phase of any perceptual synthesis. The log-
ico mathematical structures need to be adjusted through
reﬂective abstraction of Piaget and Harland (Harland:
80) The processes of syntagm give one freedom to
create meanings independent of reality too though a
human-centred approach would make it unnecessary. In
a syntagm, language can have a liberating effect rather
than being constrictive (Harland). A possible World
Semantics of Carnap (Salmi 2012) is a product of new
‘intentional’ forms of logic. By analysing the applica-
tions of a proposition into many applications, indecisive
truth values can ﬁnd a solution. Language can be seen
as describing new possible world. Language does con-
stitute a world.
The philosophical tractability of the new science/tech-
nology in its innovative modes needs to take one to the
detailed world of AI as in conventional expert systems and
for economic transactions. Expert system is a component
program designed to emulate expertise in any domain.
However, concomitant understanding of developments in
domain areas makes for high cost-delivery schedules. A
knowledge base represented by ‘‘if, then’’ rules need to be
combined with inference engine to explain reasons and
reach conclusions. Knowledge engineers need to extract an
expert’s knowledge in an organization and use it in an
expert system. Institutional structures with its conﬁdenti-
ality clauses are another institutional barrier. Understand-
ing the role of private, public and shared knowledge
dissolves the intangible feature of knowledge dependence
on humans.
An agent-based ecommerce system can react to buyer’s
feedback using a fuzzy approach. This recommends pro-
ducts to buyers as per their preferences. The agent collects
the buyers preferences in fuzzy or linguistically deﬁned
AI & Soc (2015) 30:173–181
177
123

terms and based on this presents them an ordered set of
products. After obtaining the buyers’ feedbacks when they
come across their products, the sellers’ agents interacts
with the buyer agent, revises the products’ preferential
order and recommends the same. The methodology mea-
sures the degree of customer’s focus on the products ﬁnally
recommended by ecommerce agent.
The product ranking obtained through buyers’ initial
preferences is the subjective information and the available
information from the agent’s-presented products is taken as
the objective information.
Such an approach integrates both cognitive and eco-
nomic aspects. To the extent, experimental economics do
not fulﬁl/need any special condition of consistency, and
cognitive identiﬁcations allow for philosophical rationality
in the system.
Bonakdarian (2010) uses an evolutionary algorithm in
analysing data from experimental economics. This algo-
rithm was sued in conjunction with stepwise regression
to evaluate various subsets so as to generate an optimum
subset from user-denied criteria. The evolutionary algo-
rithm is based on cross-generational elitist selection
using heterogeneous recombination with a cataclysmic
mutation algorithm. This is a population based approach,
ﬂexible and user directed. However, a particle swarm
optimization technique could have been tested herewith
to see whether difference in results is getting generated
with same data.
However, aggressive investment in new IT leads ven-
dors, investors, market analysts to support AI. Mental
activities modelled in AI led to product differentiation,
unlike employment trade-offs in early industrialization
automation of production processes. Expert systems boost
productivity when staff members do not have to ask a
question and wait for an answer. Underwriting work has
seen lowering handling costs and lower mortality expenses
through accurate risk assessment and pricing in Bank of
America, Nippon life, etc1. Further quality management,
rapid automation, professional development and competi-
tive advantage are enhanced through integrating domain
knowledge in AI expert systems as seen in ﬁnancial ser-
vices sectors.
Philosophizing knowledge entails virtue of classiﬁcation
that has been used by AI Knowledge decomposition as
discussed by Wallingford and Sticklen (1991) via struc-
tured mapping and hierarchizing knowledge groups has the
merit of system debugging and system extension of AI.
This was discussed in the context of Selecting Plans for
Capital Asset Acquisition through Classiﬁcation Problem
Solving. A Plan Selection Problem Solver can generally
look this way below.
USER
Hierarchical  Classifier
Planning Interface
Further economic and ﬁnance-related value addition
measurement and testing problems incorporated in AI
expert systems has been mentioned. To give a few exam-
ples: A multi-expert architecture for credit risk assessment
(Credex) by Suzanne Pinson from IX Dauphine, Lamsade-
Paris is sued using kEE, an improvement over Intelligent
DSS systems as the former can process qualitative infor-
mation and at varied risk interval scales. It is a combination
of multi-attribute aggregation rules derived from cognitive
psychology and decision theory of Nisbet (2005) and
Bremer (1987). The meta-expert system employed therein
reasons not on domain objects but on tasks within the meta-
domain. Extensions can be made for individual-experi-
enced experts, and sensitivity analysis can be done if
experts disagree on risk levels.
Genetic algorithm-incorporating chromosome crossover
and mutation is touted as one of the evolutionary research
areas in AI was developed by Richard Bauer and Liepins
Gunar from USA to generate trading strategies. If the
algorithm is programmed in modules/subroutines, only the
evaluation problem needs to change across problems.
However, more creative insights through experience is
needed.
In an age, when e-commerce is above $1.5 billion p.a.
and promises to increase due to advances in agent tech-
nology, i.e. application where users delegate authority to
search and ﬁlter information schedule meeting/negotiate
agreements to software agents, programs that act inde-
pendently on their behalf. So what is the research agenda
for economist versus changes in technology and lifestyle
changes due to globalization? Economic theory especially
implementation theory can be used to design and improve
efﬁciency of e-com systems. A study of impact of software
agents on the markets can be undertaken. So how can
economic theory be used to design interaction between
agents and users. So unlike ﬁrst-generation e-com agents,
the second-generation agents have feature that user dele-
gates authority to transact business to agent. These agents
can copy themselves over internet, interrogate host web-
sites, interact with other agents.
178
AI & Soc (2015) 30:173–181
123

Wider applications to telecom, marketing, entertainer
and military segments via movement to agent-based
environment supported by communication languages—
KQML
and
Tele-supply
and
standardized
electronic
transaction. So the research categories in different aspects
of e-commerce: 1—design of markets for automated
interaction of protocols for multi-agent interaction and of
negotiating agents.2
The philosophic or ideological rationale could be pos-
iting freedom and maximal gain or maximal control for
communal sharing. Implementation theory or mechanism
designs would be prescribed for partnerships with given
preference sets though human agents always outsmart
designs and impose their own preferences.
Consequently, whether a philosophy of mainstream
planning, organized education cum training system would
be accepted or human perception-linked output module
would be developed would be decided on a Rawlsian jus-
ticiable mode (Patnaik 2003). But looking only through the
glass of AI and implementation theory, market for auto-
mated agents (automated agent is a pre program algorithm
such as game theoretic concept of strategy) seem a viable
outcome in richer climes in the current context of devel-
opmental logic minus the climate change worries. Thus,
game theoretic designs would be machined into automated
markets in the very design of agents themselves. Another
category of economics propelled cognitive research would
be via the factuality of search agents enhancing consumer’s
search power and increase competitiveness in markets for
homogeneous goods. Justice notions will allow general
modelling frames based on underlying incentive schemes
that can be used for regulation and tax schemata. But will
AI psyche counter institutional constraints? Say, a user
learning to trust agents to act in his interests? Such an
outcome would be sensitive to many assumptions. A good
technology would be operating in an inﬁnitely divisible
capital-design-decision model.
Marcuse (1941)’s musings on social implications of
modern technology replaced an era of commodity fetishism
or so it seemed. This seemingly large scale investigation of
technical efﬁciency hits a roadblock: whether technology
would need to be politically neutral or there would be
progressive utilization of technique through democratic
(read education) reform. But technology can breed liberty,
scarcity/abundance, extension/abolition are questions that
human actions in society would determine. So whether
commercialism is leading to a societal harmony through
both vertical and horizontal sense of Rawlsian justice
(Patnaik 2003) or rational structures get progressively
dissolved is the action agenda of humanity is the essence of
this debate on machine philosophy through cognitive and
economic behaviours on a justiciable and norms/contract/
emergent creativity enforcement platform.
Economic Aspect: In Romer’s pioneering endogenous
growth where human capital is a key factor of economic
growth, Kaas et al. (2010) make the theoretical claim that
an inﬁnite growth is possible. However, notwithstanding
this claim, Romer’s production function allows smart
goods to have more proﬁts, prices and a sequences of
production structures in time (entire proﬁt of research
sector comes back as wages to human capital).However,
positing a Rostovian Age of High Mass Consumption,
wages would have been high enough to give diminishing
satisfaction, barring un-smart goods and production struc-
tures (deﬁned as goods having ill-health implications in a
holistic sense and high regulatory transaction costs with
increasing production with or without constraints).
So do achievements of AI contribute to economic the-
orization
through
providing
insights
into
economic
problematic?
It provides a methodology for modelling rationality. For
example, Finite Automata is used to model strategic
choice. This models choice given an artiﬁcial neural net-
work (ANN) prediction from stock market in relation to
outputs generated in a Cobb Douglas production type
equation within the framework of a real-ﬁnancial systems
model. Such an approach can be relevant to correct plan-
ning mistakes (agent mistakes) and therefore to disequi-
librium
situations.
Disequilibrium
situation
being
non-consistent is problematic for economics due to non-
exploration of ways to move into equilibrium. AI by pro-
viding decision rules provides pathways to new equilibrium
structures.
In market structure analysis, as in Cournot Duopoly,
when method inﬂuences choice, reasoning becomes a sort
of pre commitment. So the nature of assumptions can be
explored.
Rationality without reasoning took recourse to cardinal
utilitarianism but consequential problems of measurement
made the issue a mimimax problem. The problem in tra-
ditional economics eschewed the processes behind rea-
soning structures with agents costlessly choosing the
options. Economic technology demanded a continuous
objective function and a compact choice set (closed and
bounded budget set and positive price) with many restric-
tive assumptions behind it. No restrictions implied zero
possibility of seeking solutions.
The contributions of AI to economic theorizing are also
an alternative philosophical and cognitive path4. It provides
a method to model reason and rationality. It provides a
perspective to view current problems while raising new
problems. Mistake and disequilibrium modelling has
become possible due to AI.
2 Expert Systems Catalogue by Paul Harmon appearing in The Rise
of the Expert Systems (Times books-1988).
AI & Soc (2015) 30:173–181
179
123

4 Conclusions
The philosophical, cognitive and economic processes prove
unworthy if the machine breakdown gives rise to ethical
implications. If a medical diagnosis proves false, whose
responsibility is it, the physician or the programmer’s?
In Cristiano (2000) deception is incorporated in AI for
social welfare, warfare for economic reasons and issues of
freedom. Kowalski (2011) provides a computational model
by providing constraints that prevent immoral/illegal
action. Decision theories in law, management, economics
and sociology can then judge the moral status of actions in
terms of consequences and also motivations.
However, this third intelligence revolution as Shi (2009)
puts it brings neuronal analysis, AI and other evolving
knowledge structures together in a fruitful endeavour.
Lindley’s (2011) bottoms-up (using different sub-strata)
intelligent system that is self-replicating and capable of
generating cognizing systems as large scale assemblies
makes
development of engineered
systems
revealing
properties of autonomy and intelligence a possibility. Such
autonomous systems with connectionist architectures are
characterized by special competence but limited high-level
capacity at present. Wilson’s ‘consilience’ of inductions
from different classes of observation will describe a chain
of cause and effect explanations leading through natural
sciences into a vertically integrated interpretative social
science and humanities. But to what extent it would be
‘reductionist’ can be known only from the emergent
properties at the interfaces of ‘stratas’ in the system.
The philosophizing of AI and its practices is providing
some insights and justifying Rosen rock’s (1992) musings
on existence of technological convergence and uniformity
of technological practices. If science is the source of con-
sistency in scientiﬁc practices across cultures, then cau-
sality in science needs to be substituted by sets of cultural
ideations as a basis for knowledge designs to be used in
machines for harmonious social optimum in its techno-
social interfaces. However, a newer set of challenges
would have to be dealt with, such as user involvement,
degrees of cognitive performance in network of relation-
ships at local and global levels and valorisation of diversity
(Gill 1996a, b). Gill’s coherence of choice innovation has
to look at national value addition and purchasing power
parity (PPP) measures. Economic underpinnings behind
choice innovation via conventional utility maximization
model within a national sale with similar PPPs enable
development and fulﬁlment of formal production structures
of locally speciﬁc hardware software mix. Cognitive sur-
faces would be local user-speciﬁc encompassed by trans-
latable borderless language cultures and not limited by
narrow economic determinism and single-user single
technology syndrome. Translations provide the bug bear of
multiple interpretations and so cultural speciﬁc meanings
can help in cultural education for user at both ends of
production–user network. This variant of humanizing of
technological interface in human machine interaction lit-
erature is one step towards fulﬁlment of vision of artiﬁcial
intelligence.
Thus,
a human-cantered machine approach
shows
Cooley (1996: 99) approving of a Heidegger an approach
to machines as tools that would support non-existent and
newer ways of application and thinking rather than
accepting scientiﬁc utilitarianism as objectiﬁcation of
knowledge. Thus, one can forego menu-driven approach
and plan for independent understanding of implications
about the unknown with capacity to work on group goals in
a more rational and progressive rather than rigid way. This
would imbue a scientiﬁc cum technological enterprise with
Rosenbrokian purpose rather than machine causality em-
beddedness which is only a dull repetitive work syndrome.
This would also help Frissian (1987) prototyping in design
systems where she deﬁnes ‘prototyping’ as a method for
mediating knowledge/dialogue between designers and
users. She devised a PROTEV (meaning prototyping for
evolutionary systems development) that provide users with
a understandable tool for work helpful in taking feedbacks
and modifying it.
References
Anat B, Anat M (2011) Ludwig Wittgenstein. In: Zelta E (ed) The
Stanford Encyclopedia of Philosophy
Bickard M, Terveen L (1995) Foundational issues in Ai and cognitive
science—impasse and solutions. Elsevier Science Publishers,
Amsterdam
Bonakdarian E, Whittaker T, Yang Y (2010) Mixing it up: more
experiments in hybrid learning. J Comput Sci Coll 25(4):97–103
Bremer SA (1987) Essays on life, literature and method. J Exp Theor
Artif Intell 5:285–333
Bunge M (2003) Emergence of convergence. Toronto University
Press, Toronto
Chomsky N (1968) Language and the mind-pub by Harcourt Count
Jovanovich Inc
Cooley M (1996) On human machine symbiosis. In: Gill K (ed)
Human machine symbiosis. Elsevier, UK
Cristiano C (2000) Artiﬁcial liars: why computers will (necessarily)
deceive us and each other. National Research Council, Institute
of Psychology, Division of ‘‘Artiﬁcial Intelligence, Cognitive
and Interaction Modeling’’, Rome
Drescher G (1991) Make up minds—a constructivist approach to AI.
MIT Press, Cambridge
Ehn P (1988) Work oriented design of computer artifacts. Arbetsliv-
scentrum. Almsqvist & Wicksell International, Stockholm
Friis S (1987) User developed prototype systems. In: Rasmussen J,
Pranas Z (eds) Empirical foundations of information and
software sciences III. Plenum Press, New York
Gill K (ed) (1996a) ‘Human machine symbiosis’ (the foundation of
human centred systems in human centred systems). Elsevier, UK
Gill K (1996) The foundation of human centred. In: Gill K (ed)
Human machine symbiosis. Elsevier, pp 1–68
180
AI & Soc (2015) 30:173–181
123

Hofstadter DR (1979) Godel, Escher, Bach: an eternal golden braid.
New York
Hopﬁeld JJ (1984) Neuron with graded response have collective
computational processes like two state neurons. Proc Natl Acad
Sci USA 81:3088–3092
Kaas S, Rayhawk S, Salamon A et al (2010) Economic implications
of software minds
Kirsh D (1991) Foundations of AI: the big issues. Department of
Cognitive Science, Univ of California, California
Kowalski R (2011) Computational logic and human thinking: how to
be artiﬁcially intelligent. Cambridge University Press, London
Lindley C (2011) Synthetic intelligence: beyond AI and robotics;
Blekings Institute of Technology, SE-371
Marcuse H (1941) Some social Implications of modern technology.
Philos Soc Sci IX
Mayo M (1993) Symbol grounding and its implications for AI.
Oxford University Press, Oxford
McClelland (2012) Thirteenth anniversary speech in conference on
cognitive science. http://www.cse.buffalo.edu/*rapaport/index.
html-20120112
Nisbet R (2005) Impact of Programs for adolescent who sexually
offend. www.community.nsw.gov.au
Patnaik D (2003) Constitution of man: the key to world harmony
through
global
planning
of
productive
employment
and
economic freedom. Journal of Indian Council of Philosophical
Research, New Delhi
Rasmussen L, Rauner F, Corbett JM (1988) The social shaping of
technology and work; human centred computer integrated
manufacturing systems. AI Soc 2:47–61
Rummelhart DE, Hinton GE, Williams RJ (1986) Learning internal
representation by error propagation. Parallel Distrib Process
1:318–362
Salmi S (2012) Carnap and the unity of science: intellectual and moral
formation of a science-technology generalist: a case study.
Helsinki Univ
Shi Z (2009) On intelligence science. Int J Adv Intell 1:39–57
Tsang E (2007) Computational intelligence determine effective
rationality; WPO-15-07 Centre for Computational Finance and
Economic Agents
Turing A (1950) Computing machinery and intelligence. Mind
LIX(236):433–460
Wallingford E, Sticklen J (1991) The relationship between task
speciﬁc architectures for problem solving and the knowledge
level. In: Manikopoulous CN (ed) Proceedings of the 8th
international congress on cybernetics and systems. NIIT Press,
pp 169–175
AI & Soc (2015) 30:173–181
181
123

