Cybernetics  
and Ghosts1 
  
In the No-Man’s-Land  
between Science and Art 
Oswald Wiener 

Cybernetics 
 
Once I began to waver whether or not I wanted to become a musician 
or a poet, the question of how, in what way, music and language exert 
their effects gradually became more important to me than these 
effects themselves — more important than my aesthetic emotions. 
How do we understand? What is the cause of the effect that Achleit-
ner’s “constellation” baum bim had on me?2 So epistemology became 
more important to me than aesthetics. 
        What is a concept? How come that I know where I am now in this 
piece of music, and what it “means” what I hear? How do I lose the 
thread? What is meaning? Thus, I turned to philosophy and to psy-
chology, but I realized, gradually, that they wouldn’t provide satisfying 
answers to my questions. What I would need was not “conceptual 
work” but mechanisms — mechanisms that understand, and which I 
could observe and then learn to understand how they understand. It 
was the 1950s, and you could hear cybernetics coming. Finally, cyber-
netics would bring the answers ... 
        … not. Already in his famous 1950 essay Turing had written:  
“May not machines carry out something which ought to be described 
as thinking but which is very different from what a man does?  
This objection is a very strong one, but at least we can say that if, nev-
ertheless, a machine can be constructed to play the imitation game 
satisfactorily, we need not be troubled by this objection” (Turing  
1950: 435). So he had already realized that the coming development 
of “Artificial Intelligence” would not bother the exploration of 
human intelligence. Presumably, Turing wanted this development; 
but — in the Austrian backwoods fifteen years later and still unaware 
of his paper — I saw, how the use of computers indicated by him 
would block the way to a strong epistemology.3 In 1984,4 I still 
believed that Turing’s behaviorist approach would not even lead to 
machines passing his own test. So thought I could spare any argu-
ment about his “objection” (although I should have noticed that he 
had placed it at the very beginning of his paper instead of in the 
166

167
context of his discussion of the objections he considered refutable; 
Turing 1950: 442ff.). 
        For then I could not imagine that the development of hardware 
would keep its speed till the twenty-first century. Today, we do have 
computers that are able to generate “all the possible combinations, 
whose number would frighten the imagination“5 and to squeeze the 
Library of Babel into a sequence of a few letters forming one remain-
ing sentence, which a human being is able to understand as a fitting 
bon mot. In 2011, a program called Watson6 won three episodes of the 
television quiz game Jeopardy! against the two reigning champions of 
that series. Compared to the goals of today’s projects, Watson was 
quite modestly equipped — only ninety IBM Power 750 servers with 
only sixteen terabytes of RAM, each server with only a 3.5 GHz 8-core 
processor, and each core only handling a maximum of four threads 
at a time.7 
        There is a trade-off between storage space and speed (as I wrote 
in the passage in footnote 3) because “deep” structures require less 
data but more time than “shallow” ones. With the immense growth of 
storage space and the incredible acceleration of processing speed, i.e., 
with decreasing processing costs per unit, Occam’s razor itself 
becomes uneconomical, and remains, if at all, as a rule for mental 
exercise only. Today, processing speed exclusively serves the search 
of databases or generate-and-test8 of flat formalisms. The abundance 
of storage space etc. renders any accommodation of structure unnec-
essary. Now “accommodation” only consists in collecting exceptional 
cases — thus a large, perhaps even huge, set of exceptions to a shallow 
rule replaces the deep rule (which would be troubled by any excep-
tion). Of course, a minimum of structure must exist. The goal is to find 
for each case that minimum which yields a universal machine in the 
given domain, so to speak.9 This could largely be achieved by simple 
trial and error, if the development of computation is faster than the 
development of what is computed.10 
        At any rate, such programs show one thing clearly enough. As 
they are no longer dependent on the acquisition of structure, they 

achieve the goal set for them in quite different ways than human intel-
ligence.11 Watson computes words as bit strings — they do not mean 
anything. Controlled by a set of partially probabilistic12 derivation 
rules and supported by its huge and ever-growing database, the pro-
gram converts an input string interpreted by humans as a linguistic 
expression into an output string that humans understand as a sen-
tence. This amounts to a perfect execution of Watson’s (the behavior-
ist’s) intrinsically Occamian concern to keep hidden variables as shal-
low as possible — “we denied the necessity of assuming imagery (…) 
for the reason that we can substitute for what it is supposed to do a 
mechanism which is exactly in line with what we have found to exist 
everywhere else, viz., an enormously developed system of language 
habits.”13 
        For Watson and in Watson, thought is a mapping of word lists on 
word lists by a function with maximum extension and minimum 
intension. Its ideal is the lookup table.14 In Watson’s case, the opera-
tions do not hide any puzzles. If it seems puzzling that they pass 
Turing’s test, then the reason seems to be Turing’s test itself. Watson, 
on the other hand, is puzzling enough (e.g., the reader has to guess 
why an excitation pattern in the speech apparatus so frequently and 
tediously transforms into chains of other excitation patterns of the 
same muscle group before the hand or the arm moves, etc.). Yet, 
unlike Watson, he functions quite differently than he is inferring from 
his own activity. 
        “[M]eaning is but a trick [of evolution] to overcome limitations of 
formal capacity; this insight extends to the guidance of formal 
manipulations content.”15 Well, sense and meaning are the ghosts of 
cybernetics. More generally, “subjective experiences” — “mental 
images,” “figuring,” “believing,” “mind,” and “consciousness” as such 
... It seems ghostly that such words, which belong to colloquial lan-
guage use alone, have now found their way back into science, and that 
for this very reason what is meant by them has begun to rumble once 
more. And it is no less ghostly that today’s computer programs have 
been turned into explications of these words — now they “under-
168

169
stand,” “learn,” “try out,” “expect,” “represent,” and so on. In this 
respect, Turing was yet again right: Only a few will laugh (sadly) at the 
claim that today’s machines are thinking machines. 
 
 
Ghosts 
 
“Content,” “intuitions,” “ideas,” “propositions,” and the like do not only 
haunt cybernetics (if this is the right name for today’s applied com-
puter science and its philosophy), they also play their tricks in physi-
ology — How Neurons Mean16 — and, of course, even more so in psy-
chologizing philosophy. Isn’t it a little spooky that the “view from 
within” wants to gain reputation by using crutches such as phenom-
enology and Franz Brentano? Or, that the countless new efforts to 
make sense of the word “consciousness” do not result in more than 
an interchange of words?17 In any case, the devil must have his hand 
in it when someone tries to “visualize” “covert behavior” by fMRI 
scans, and at the same time excludes introspection unable to find 
such images as a diagnostic tool.18 
        For without introspection some crucial questions of psychophysi-
ology will, I believe, remain unanswered: 
—     How do energy modulations in the environment impacting on 
the organism’s sensory surface become parameters in the control 
of adaptive behavior? 
—     In what ways do people surrogate such impacts from their envi-
ronment when thinking and imagining, and how are the stimuli 
integrated with these surrogates? 
—     What role does subjective experience play in the control of adap-
tive behavior? And most importantly: 
—     What is the physiological correlate of subjective experience? 
The “cognitive revolution” of the fifties did not significantly change 
the status of these questions. As far as, for instance, the “contents of 
consciousness” are concerned (i.e., the second of my “all-important 
questions” above), Roger Sperry (1952: 295) declared: “The scope and 

diversity of opinion to be found in the current literature reflect our 
general confusion and almost complete lack of guiding principles.” 
The decades since then have only increased this confusion insofar as 
we know less and less how to define it but at the same time try to clar-
ify it with increasingly complex technical tools. Regarding the ques-
tion of “neural correlates of conscious experience” — i.e., question four 
above — it was “really the ’brain’ part of the mind-brain relation that 
most urgently needs clarification” (ibid.: 291f.). Thus, Sperry thought 
that physiology was to blame for the confusion. But should really neu-
robiology or neural engineering establish a “Theory of Representa-
tional Content”? I think that here we have two different, hitherto 
unsolved tasks: What is a mental apparatus able to grasp of its own 
workings, and how can it communicate with others about it? How are 
the introspectively established regularities realized in the CNS? Since 
Sperry did not take into account introspectively gained clues, it is not 
even clear what he actually meant by “subjective experience.” To 
everyone seeking clarity, it becomes clear that here psychology has 
been erased from the picture. 
        Sperry’s paradigm is the sensor→motor-transformation: “per-
ception is basically an implicit preparation to respond” (ibid.: 302), 
it is “motor adjustment” (ibid. passim). So it is rather understandable 
that he, in 1952, kept a low profile concerning “imagery.” But at the 
same time it is also regrettable, because in this direction, or so I 
believe, a breakthrough is possible. The internal representation of 
an object in the organism is its respective “readiness for adaptive 
response” (ibid.: 300), a specific readiness for action19 — and there are 
strong arguments for such a motor-hypothesis of mental processes. 
However, it would have to be refined into an ideo-motor hypothesis, 
because any pure motor theory has difficulties with the “figurative 
aspect”20 of thought. How can the fabric of my readinesses for 
action surrogate the behavior of an object I am prepared 
for?21 
—     What, then, would have to be explained? In the following I give 
an example from my fragmentary, selected, and edited introspec-
170

171
tion notes to pose the question of the phenomenal as well as to 
illustrate some functional aspects of imagery. 
 
 
Seeds and running structures 
 
While reflecting on an introspection report shared by T., I came across 
the following “content:” 
        A coordinate plane, first quadrant (top right); and a line segment 
t of constant length (hereafter also called “rod”); η as the end point of 
t sliding in the vertical y-axis, ξ as its other end point sliding in the 
horizontal x-axis. 
        I have already played with these ideas a few times in order to “see” 
which properties the “logic” of the object produces.22 First, I try to elab-
orate on their phenomenal aspect from some relevant introspection 
episodes (i.e., for the time being I neglect the meanings of the “phe-
nomena,” namely their embedding within my orientation). 
 
The quadrant of the coordinate plane appears as a seed, its origin 
in the lower left, its axes indeterminate — 
 
indeterminate but constructible. An irritation, which was also already 
there, expands to a seed of the rod: 
 
A front is shearing to the left [implication: across the quadrant — 
the coordinate axes have vanished], rearing clockwise. The center 
of rotation and attention is the area around ξ pushing towards 
the origin. 
 
The phenomenal aspect is underdetermined: the “front” is a move-
ment of something indeterminate but determinable, but during the 
process it is only an elongated zone wiping in the direction of its width 
in contrast to the assumed surface. The “wiper” is no proxy object, 
but a kind of change; the dynamics of the process is present. What is 

determined is the running environment: obviously, I am well 
oriented, but the running environment is neither present.23 I only 
notice that “this, again ...” happens. 
        Present in the narrowest, i.e. in the decisive sense, are thus changes 
— changes of relations, of positions, of situations. Therefore, the present 
is not a point in time but lasts as long as I need to grasp the character 
of the ongoing change. The respective situation (running environ-
ment24) is constituted within the respective orientation. It manifests 
itself only indirectly, namely as the background controlling the 
changes.25 
 
New assembly, almost immediately. Now η upwards on the y-axis. 
The η-end of t is a steeply sloping elongated shadow or fringe 
unrecognizably connected to an obstruction half-right below out-
side the pan. 
 
By the word “shadow,” I appoint a deficit (something merely implied, a 
“defined lack” in Sartre 2004) to a “vague mental image” (Müller 1924).26 
How do I recognize what I imagine? I know what it is before it appears 
and, within limits, independent of how it appears. 
        Sometimes, I indeed notice that what “appears” is something differ-
ent or has different features than what it was supposed to have. There 
is a transition from what is to be assembled to the new interpretation: 
a moment of uncertainty, of disorientation. An “association” has taken 
place, the beginning of assembly distorts, so to speak, the orientation 
and, thus, brings a new aspect into play (which is not always recognized 
as an aspect implied by the seed): 
 
My attention “slides” down at t, in the direction of that place where 
it snags. Through this “movement” t turns out to be a black rubber 
rope with a square profile, which from there is stretched against a 
pull towards that there [upper left]. 
Following the direction of the opposite pull, I reach ξ, the dark end 
of the dark rope. 
172

173
I did not notice but am able to remember the following: Mean-
while — or maybe only now, while I digress from the observing atti-
tude — t slowly swings to the left, like a pendulum. 
 
—     The names of the objects — t, ξ, ... — only serve communication; dur-
ing the observation of the episode “I knew” that this was that (the 
rod) and that there was “the other” end. 
—     Is this episode an artifact of introspection? Yes — because I experi-
enced it when I intended to pay attention to the phenomenal 
aspect of the events. No — because something emerged that would 
have been produced even without this attention. Yet, it would have 
remained unnoticed and, therefore (see below), almost ineffective. 
I had noticed the rubber rope already in an early attempt and at 
times while trying to repeat the assembly. The seed originally 
implied an “expander” (an elastic luggage strap).27 
I now turn to the functional aspects of imagery: 
        The movement of t satisfying the above instructions yields a 
curve — intuition tells this to everybody who imagines the movement 
under this aspect. Every single position of t is a tangent of this curve.28 
—     Intuition that t, when “swinging,” slides along the curve while being 
fixed to a point that slides in it like ξ slides in the x-axis (“swinging:” 
turning the rod from position “t lies in the x-axis” to the position 
“t lies in the y-axis,” or vice versa). 
—     Intuition that my right middle finger, resting in the middle of t, 
draws the curve. 
        The first intuition turns out to be correct, if I additionally allow 
the point of contact to shift in t. Notably, the second one is wrong:  
the center of t describes a quarter circle around the origin with the 
radius t/2. 
        … Various thought experiments by pursuing various intuitions. 
Attempts, for example, to determine the shape of the curve intuitively. 
Is it a quarter circle too? Or I “see” t as the base line of a triangle, as the 
fixed-length hypotenuse of a deformable but always right triangle, 
whose right angle (the angle of the coordinate axes at the origin) 

remains fixed, and whose variable legs lie in the axes. At the beginning 
of the upward movement the triangle is the line itself, namely the 
hypotenuse lying in the x-axis. Then it grows until it is half of a square 
cut diagonally by the hypotenuse. Then it shrinks back to the distance, 
now totally symmetrically in the y-axis. Seed of Thales’s circle, or rather 
of Thales’s circles, but they remain inconsequential for now. Yet, the 
intermediate results of all these variations become sub-structures of 
my “rod” running environment. 
        A “longer mind Game:” While t is swinging upwards from the x-axis 
I have the intuition of a wave. At the beginning, I was not really able to 
clarify it, i.e., to grasp the wave more clearly. Instead, intuition cum 
“logic:” a point moves from right to left on the rod swinging up. In front 
of this point the wave rises, behind this point it falls. 
        Following a vague impulse from this thought, I insert a perpendi-
cular line, parallel to the y-axis and (quite “automatically:”) at a distance 
from it, which is smaller than the length of t. How come? I assume that 
it arose from the repertoire of my geometrical routines, and that the 
then current running environment was favorable to this idea, to this 
association. 
 
 
 
 
 
 
 
I observe the movement of the point S where t intersects this fixed line 
v. At the beginning t lies in the x-axis, and S lies in the base point V of v. 
 
η starts to climb up the y-axis. The rotation of t in ξ slowly sliding 
to the left becomes clearer, seed of ξ, η now reduced to an irrita-
tion. Now S, S is given as a point on t, which, held by the merely 
implicit vertical v, slowly slides upwards on it. 
 
174

175
A shift of aspect shows: 
 
S also “runs” along t in the direction of η — I get the feeling of scis-
sors, wordless, only the movement of the scissors is present, the 
blades are merely implied by the position of v and t; an indeter-
minate object between the “blades” is pressed upward as they 
close. 
 
Feeling: “Does not quite fit.” 
—     the shear-movement had become a scissors-movement, which is 
to blame for the intuition that the distance from S to η decreases. 
An aspect grasping the relations more exactly, namely t becoming 
steeper particularly also between v and the y-axis would have 
resulted in the opposite intuition.29 Later, the idea of scissors, albeit 
applied differently, will lead to new insights.30 
t “gliding” over v is the guiding intuition for a more detailed exploration. 
My attention sticks to the movement of the intersection. Sometimes, I 
experience this movement as more or less continuous, sometimes as 
discontinuous transition from one position to the next. The “continu-
ous” movement (apparently based solely on intuition) appears some-
what vague, as the intersection itself — a point?! — is not itself present. 
What is present is the upward movement of a place determined only 
roughly in terms of its size. I’d rather say: Present is the change of a seed 
of S, driven by a feeling of rotation represented by a tendency to supi-
nate my right bent forearm. On the other hand, the single “snapshot” 
(intuition cum “logic”) is equally vague. Actually, it consists only of 
jumps of attention to places, where the construction of a proxy sub-
object could possibly ensue. 
        I rotate t from the x-axis into the y-axis: 
 
η rises swiftly from the origin, ξ inertly follows the pull trans-
mitted by t (in a sense t is this pull) moving in the (mere seed of 
the) x-axis. I attend to S; the seeds of t and v appear as line-frac-
tions, but are only attended to as “forces” acting on S. S rises; 

slower and slower; the fixation of the rotation in the axes 
decreases the pressure of the rod on S. For a moment η again 
becomes salient as pivot of the rotation, then suddenly a transi-
tion to wiping of t over v downward. It is impressive how t “is turn-
ing out of v” clockwise — S got stuck at the top (at the maximum), 
and the intersection of t and v drops down, briefly stalls in V and 
then accelerates bottomlessly.31 
 
So the swinging rod affords the intersection to reach a maximum height 
above the x-axis. I imagine another perpendicular between v and the 
y-axis. Repeating the displacement of t I have the impression that the 
rod’s highest point of intersection with the new perpendicular is higher 
than with the old one. I tend to think that these highest intersections 
are points of the envelope curve. And so forth.32 
 
 
I try to sum up: 
 
The descriptions of my introspections cannot satisfy any reasonably 
practiced and, therefore, skeptical introspector. I indicate my own 
concerns as follows: 
        Whenever I want to direct my attention to the sensory features 
of imagery, I fail due to the ephemerality of my “vague mental images.” 
Since I don’t find any “mental images” essentially comparable, e.g., to 
a sight or a sound, I conclude that we confuse the definiteness of our 
orientation with the clarity of stimuli. The reason is that for imagery 
the only analogy available is perception, because in the perceptual 
situation orientation is controlled by sensory influences of the envi-
ronment,33 and because we fail to realize that in perception orienta-
tion plays an almost equally dominant role as in imagery. 
        Then again colloquial language suggests a phenomenology of imag-
ery, although it cannot describe what it simply posits as phenomenal by 
its own terms. Therefore, everyone who wants to describe it has to side-
step to the phenomenology of perception. Under these circumstances, 
176

177
the only legitimate manner of speaking is (as James would say) the “sub-
stantive” one, which is itself legitimate only as long as one refrains from 
psychological ambition and does not describe the sensory-phenome-
nal, the quasi-sensory/quasi-phenomenal as the trigger of ideas.34 
        In any case, it is clear that, in imagery as in perception, I attend 
to the phenomenal only if exactly this is the task (and then only with 
mixed and, in the case of imagery, very doubtful success). In such 
cases, the author later reads his description — like mine sketched 
above — differently than the reader, because he is oriented to the con-
ditions of, e.g., the rod or the coordinate axes, etc. So the description 
is transparent to him or her.35 
        But neither do I pay attention to objects or to what would cor-
respond to objects in imagery. I have already said it above: I pay atten-
tion to changes of the respective quite specific relations, and these 
relations are given and determined only as actions. Obviously, it 
depends on the specifics of these changes alone. The entities subject 
to the change are crucial only insofar as their changes are again mere 
changes of relations. 
        Such entities — James (1890, I: 243) calls them the “substantive 
parts” of the “stream of thought” — are not grasped by “sensorial imag-
inations of some sort, whose peculiarity is that they can be held before 
the mind for an indefinite time, and contemplated without changing” 
(!). For they are either seeds and so stand for “objects, with which one 
will occupy oneself if necessary,” or an assembly ensues immediately 
and the seed comes to life as a structure, which the subject experi-
ences as a sequence of lawful changes and which s/he experiences only 
when operating them. “Some parts — the transitive parts — of our stream 
of thought cognize the relations rather than the things; but both the 
transitive and the substantive parts form one constant stream, with no 
discrete ’sensations’ in it” (ibid.: 258). The “substantive parts” are 
insights into “things” insofar as they are seeds of structures of proxy 
objects; the expansion of the seed to the respective structure trans-
forms the “substantive parts” into “transitive parts.” The “conclusion” 
cannot be “a word or a phrase or a particular image” but a “practical 

attitude or a resolve” (ibid.: 260). “[T]he meaning, or, as we say, the topic 
of the thought” is nothing but a collection of more or less interlaced 
readinesses for action, i.e., a (germinating or running) structure. 
        For example, it is essential for the processes suggested above lead-
ing to the discovery of a procedure for computing envelope curves, that 
very specific intermediate results of running my t-and-v-mechanism, 
i.e., the positions of S, are “marked” by other sub-structures to yield a 
movement detached from the producing structure. That 
means they yield a separate structure. The new structure arises 
mainly by accommodation, adaptation, coupling etc. of already existing 
structures. It imitates the “movement” of S produced by the t-and-v-
mechanism within my rearranged astroid heterarchy. 
        At first, the new structure almost always appears as a mere intu-
ition (“association”), which must then be developed into a structure. 
Such intuitions accompany, in varying degrees of obtrusiveness, every 
move in orientation. Often, the intuition does not contain what I am 
looking for. But realizing, during the attempted assembly following 
the intuition, that it is wrong, increases my stock of useful structures 
too. Often the intuition can be corrected (like the middle finger 
above), and its expansion then leads to new aspects or insights. 
 
 
Conclusion 
 
When introspecting, even skeptically, one can hardly avoid experienc-
ing the changes of one’s orientation by imagery as changes of real 
objects, that is, of objects with intrinsic laws, which are not readily 
experienced as manifestations of one’s own mental apparatus. One has 
few qualms about taking these workings of one part of orientation for 
the use of another part as sensory phenomena, but in doing so one 
should heed Shepard’s remarks quoted in footnote 18. 
        Gaining knowledge of the nature, functionality, and biological 
implementation of these manifestations is one of the great desiderata 
of contemporary psychology. Can the “no-man’s-land between science 
178

179
and art” shed some light on this area? In any case, the above fragments 
of introspections illuminate problems that only those will get to know 
who bother entering it. There s/he’ll find a lot of questions. The ones 
already mentioned only pertain to a part of this territory: 
—     Do the processes described have a functional core? In my descrip-
tions the word “function” works as poorly as “phenomenon.” In 
introspective explorations like those sketched above, problem-
solving thought appears as the constructing, accommodating, 
parameterizing of structures, i.e., as the task-controlled changing 
of one component of current orientation under the influence of 
stimuli and of other components of this same orientation. Such 
introspections force us to conclude that accommodation cannot 
occur without “phenomena,” that is, without stimulus configura-
tions in perceiving or without “manifestations” of orientation in 
perceiving and in imagery. I simply would not have learned that S 
reaches a maximum on v, if I had not experienced it in the way 
described or in a “functionally equivalent” way. In any case, this 
relation has to be experienced as a specific spatio-temporal regu-
larity, as an action determined by a certain background of action 
readinesses.36 And I would not have been able to generalize my 
experience, if my attempts had taken place against a background 
too different from the one described. 
That one part of orientation is beginning to have an effect on orien-
tation at large can be compared to broadcast: Depending on the cur-
rent orientation, such a broadcast updates several structures to dif-
ferent degrees and in different ways. I think that this “mechanism” 
(which is not a mechanism in the real sense, because “coincidences” 
contribute to its control) achieves what colloquial language means by 
“consciousness.”37 
—     If “mental images” do not function as images, and thought does not 
function by operating on images or on words, we have to ask our-
selves: Function of what? If running structures are operations — 
where are the operands? Therefore, I refer back to the question: If 
operations are (spatio-temporal) molds of the operand — how can 

such a “mold” of an object, its “negative,” surrogate the object’s 
intrinsic laws? 
Piaget (1951: 163) attempted an answer: “As we have seen, the image is 
interiorized imitation, i.e., the positive of accommodation, which is 
the negative of the imitated object. The image is therefore a schema 
which has already been accommodated and is now used in present 
assimilations, which are also interiorized, as ’signifier’ for these ’signi-
fied.’” 
        I believe we should understand this the following way: Sensorimo-
tor schemata differentiate by accommodations to the variable (but in 
all its variability still regular) behavior of the objects, starting with slight 
adaptations (further ahead ..., more ..., slower ...), parameterizations, then 
anticipations of the object’s behavior (reaching to where the object is 
supposed to be) etc. If the organism is able explicate regularities within 
these calibrations, i.e., render the control of its own behavior on the 
object its proxy object, then the resulting structure represents the 
intrinsic laws of the object, onto which the (preserved but now mod-
ified) sensorimotor schema fits.38 Thus, the operands of the cognitive 
operations are again structures. 
        Considerations such as these lead the introspector to the insight 
that the real problems lie behind the “phenomena.” The “phenomena” 
are our metaphors for the dynamics of thought, whose peculiarity we 
do not yet understand. Our cognitive apparatus does not store symbol 
strings, which we might conceive of as images or as descriptions. The 
structures my thinking already seems to have at its disposal are not 
available as ready-made automata. So the heterarchy of my astroid, i.e., 
my astroid structure, must be reassembled every time “I think of the 
astroid.” What is obviously stored are “seeds,” which, as construction 
parameters, control the assembly of my astroid procedures, i.e., the 
growth of suitable action readinesses within the respective orientation. 
        We do not yet know what it is that we are to take as the elements 
of our cognitive structures. Is it the sensorimotor schemata?39 What is 
certain is that the flexibility of cognitive dynamics is based on the fact 
that these elements are not hardwired to each other, but are held 
180

181
together ad hoc and fall apart post factum. In other words, we do not 
yet know how the structures are implemented, of whose work we catch 
a glimpse in introspection. Introspection indicates that what colloquial 
language means by “mental image” is a seed, namely a readiness, a ten-
dency.40 And it also indicates that the nature of mental represen-
tations is to be sought in the direction professed by MacKay 
(footnote 19). 
        So from the perspective of my “no-man’s-land,” the situation looks 
like this: 
        Either I hallucinated what I tried to describe above; then I did not 
produce literature but bullshit. Or the mental must indeed be searched 
for at said physiological level of “broadcast,” and the processes indi-
cated in my introspective descriptions are indeed functional for such 
construction, accommodation, and adaption. In the latter case, we are 
forced to admit that neither contemporary psychology nor physiology, 
and much less the modeling of thought on computers, have even come 
close to elucidating these processes. 
        On the part of psychology, there is hardly anything to report con-
cerning introspections: Philosophers deal with it, perhaps even 
demand the “view from within,” which they themselves shun to share. 
There have been very few exceptions among the pioneers, but their 
introspective reports are far from sufficient too. Many of Brentano’s 
doctrines, for example, suggest that he pursued his “self-perception” 
quite superficially.41 From the schools of phenomenologists and neo-
phenomenologists favorable to introspection, I have not yet witnessed 
one single empirical report. 
        How much today’s physiology has to say about thought can be 
reviewed in works such as that of Parker et al. (2003). Modest is the psy-
chologist who is satisfied with it. What, for instance, could today’s imag-
ing methods contribute to the elucidation of Anthony Marcel’s crucial 
results (obtained without systematic introspection)?42 
        Indeed, I am convinced that new efforts based on introspection 
will reach far beyond the level of knowledge of the pioneers — since we, 
by our modest means, have already been able to take a few small 

steps.43 More significant progress, however, can only be achieved 
through professionally organized research. Unfortunately, my experi-
ences with research policy suggest that the potential of this approach 
will have to wait for a generation yet to come. 
 
 
Appendix: Glossary, short version (details in Eder and Raab 2015) 
 
A structure of a string is a Turing machine generating or accepting this 
string. 
 
A schema is a biologically/epigenetically implemented structure.44 
From a didactic perspective the following idealization suggests itself: A 
fully developed “schema of sensorimotor intelligence” (Piaget) is (1) 
“automated,” (2) controlled exclusively by sensory stimuli, and (3) shows 
itself exclusively by motor action. 
        A “schema of conceptual intelligence” is a heterarchy45 of sen-
sorimotor and conceptual schemata. The definition of the conceptual 
schema includes the fact that, as a heterarchy, sensorimotor schemata 
are able control each other without having to take a detour via the 
organism’s environment.46 To some degree, a conceptual schema can 
also become “automated,” but in general it must be assembled on the 
fly, held together, and controlled by a “scaffold” of other schemata, i.e., 
by an adequate running environment.47 
 
Intuition is the term for the activity of a sensorimotor schema when em -
bedded in a conceptual schema, if this activity manifests itself as a seed. 
 
The change of a structure is registered, if the run of the structure, 
before and after this change, can (possibly) be repeated in a way suitable 
for “broadcast.” In general, such repetitions are surrogated with seeds. 
 
Seeds are colloquially and misleadingly called “mental images” (or the 
like). A seed is the inchoate reconstruction of a conceptual schema. As 
182

183
long as physiological explanations are missing, the best way to 
approach a definition of the term is by a physiologizing metaphor: A 
seed is a pilot excitation of varying strength providing components for 
scaffolding, which in any case already ensures Bühler’s “structural 
determinations“ (“Platzbestimmtheiten,” Bühler 1907: 357ff., 1927: 116f.), 
namely the anchoring in relevant structures of the current orientation 
by providing the basis for an assembly. 
        Introspection indicates that these pilot excitations manifest them-
selves in quite different intensities. A seed can emerge as a “tachistoscopic” 
intrusion, or persevere as a mere irritation (the “meaning” of which is 
not present and becomes “broadcastable” only by expansion). Yet, it may 
also be expanded to the very structure seeded in the first place.48 
        The transition from the expansion of a seed to the assembly of a 
structure is continuous. 
 
Action readinesses are pre-excited schemata whose excitations 
remain below the threshold necessary for a seed.49 
 
The current overall arrangement of action readinesses is the organism’s 
respective orientation. 
        Together with the findings of introspection, the fact that an 
“ordered thought process” is possible allows for the conclusion that 
heterarchies of action readinesses, as a background of implications, 
intervene in the control of thought processes (as “determining tenden-
cies,” Ach 1951). 
 
References 
 
Ach, Narziss, 1951 [1905]. Determining Tendencies, Awareness. In: Rapaport, David (ed.), Organiza-
tion and Pathology of Thought. New York, 15—38. 
Beth, Evert Willem, and Jean Piaget, 1961. Épistémologie mathématique et psychologie / Essai sur les 
relations entre la logique formelle et la pensée réelle. Paris. 
Brentano, Franz, 1874. Psychologie vom empirischen Standpunkte. 2 vols., Vom sinnlichen und noeti-
schen Bewußtsein (1928) as vol. 3, (I 1973, II 1971, III 1974). Hamburg.  
Bühler, Karl, 1907. Tatsachen und Probleme zu einer Psychologie der Denkvorgänge I. Über Gedan-
ken. Archiv für die gesamte Psychologie. 9, 297—365. 
Bühler, Karl, 1927. Die Krise der Psychologie. Jena. 

Calvino, Italo, 1986. Cybernetics and Ghosts. In: The Uses of Literature. San Diego, New York, London, 
3—27. 
Campbell, Murray, A. Joseph Hoane Jr., and Feng-hsiung Hsu, 2001. Deep Blue. http://sjeng.org/ 
ftp/deepblue.pdf (14 March 2022). 
Coltheart, Max, 2006a. What Has Functional Neuroimaging Told Us about the Mind (So Far)? Cortex, 
42, 323—331. 
Coltheart, Max, 2006b. Perhaps Functional Neuroimaging Has Not Told Us Anything about the 
Mind (So Far). Cortex, 42, 422—427. 
Eder, Thomas, and Thomas Raab (eds.), 2015. Selbstbeobachtung: Oswald Wieners Denkpsychologie. Berlin. 
Eliasmith, Chris, 2000. How Neurons Mean: A Neurocomputational Theory of Representational 
Content. Ph.D. Dissertation. St. Louis. 
Ferrucci, David, Eric Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya A. Kalyanpur, 
Adam Lally, J. William Murdock, Eric Nyberg, John Prager, Nico Schlaefer, and Chris Welty, 
2010. Building Watson: An Overview of the DeepQA Project. AI Magazine, 31/3, 59—79. 
Guillery, R.W., and S. Murray Sherman, 2011. Branched Thalamic Afferents: What Are the Messages 
That They Relay to the Cortex? Brain Research Reviews, 66/0, 205—219. 
Hadamard, Jacques, 1954 [1945]. An Essay on The Psychology of Invention in the Mathematical Field. 
New York. 
Helmholtz, Hermann von, 1995 [1878]. The Facts of Perception. In: Cahan, David (ed.), Hermann von 
Helmholtz: Science and Culture — Popular and Philosophical Essays. Chicago and London, 342—380. 
Hobson, J. Allan, 1994. The Chemistry of Conscious States. Boston. 
Horikawa, Tomoyasu, Masako Tamaki, Yoichi Miyawaki, and Yukiyasu Kamitani, 2013a. Neural 
Decoding of Visual Imagery During Sleep. Science, 340, 639—642. 
Horikawa, Tomoyasu, Masako Tamaki, Yoichi Miyawaki, and Yukiyasu Kamitani, 2013b. Supple-
mentary Materials for Neural Decoding of Visual Imagery During Sleep; especially: 
www.science.org/doi/suppl/10.1126/science.1234330/suppl_file/1234330s1.mov and www. 
science.org/doi/suppl/10.1126/science.1234330/suppl_file/1234330s2.mov (22 March 2022). 
James, William, 1890. The Principles of Psychology, Vols. I and II. New York 1950. 
Lehrer, Jonah, 2008. Can a Thinking, Remembering, Decision-Making, Biologically Accurate Brain 
Be Built from a Supercomputer? Seed Magazine 3/4, http://shinyverse.org/al4ai/ extras/Seed-
Out_of_the_Blue.pdf (11 February 2023). 
Loftus, Geoffrey, 1985. Johannes Kepler’s Computer Simulation of the Universe: Some Remarks about 
Theory in Psychology. Behavior Research Methods, Instruments, & Computers, 17/2, 149—156. 
MacKay, Donald MacCrimmon, 1984. Mind Talk and Brain Talk. In: Gazzaniga, Michael S. (ed.), Hand-
book of Cognitive Neuroscience, 293—317.  
Marcel, Anthony J., 1980. Conscious and Preconscious Recognition of Polysemous Words: Locating 
the Selective Effects of Prior Verbal Context. In: Nickerson, Raymond S. (ed.), Attention and 
Performance 8. Hillsdale, NJ, 435—457. 
Marcel, Anthony J., 1983. Conscious and Unconscious Perception: Experiments on Visual Masking 
and Word Recognition. Cognitive Psychology, 15, 197—237. 
Metzinger, Thomas (ed.), 2000. Neural Correlates of Consciousness: Empirical and Conceptual Ques-
tions. Cambridge. 
Müller, Georg Elias, 1924. Über die undeutlichen Vorstellungbilder. In: id., Zur Analyse der Gedächt-
nistätigkeit und des Vorstellungsverlaufs, III. Teil. Second edition. Leipzig, 505—567. 
Neumaier, Otto (ed.), 2015. Grenzgänge zwischen Wissenschaft und Kunst. Vienna, Münster. 
Orden, Guy C. van, and Kenneth R. Paap, 1997. Functional Neuroimages Fail to Discover Pieces of 
Mind in the Parts of the Brain. Philosophy of Science, 64, Supplement: Proceedings of the 1996 
Biennial Meeting of the Philosophy of Science Association, Part II: Symposium Papers (Dec. 
1997), S85—S94. 
184

185
Parker, Andrew, Andrew Derrington, and Colin Blakemore (eds.), 2003. The Physiology of Cognitive 
Processes. Oxford. 
Piaget, Jean, 1951 [1945]. Play, Dreams and Imitation in Childhood. London. 
Piaget, Jean, 1960 [1947]. Psychology of Intelligence. Paterson, NJ. 
Poincaré, Henri, 1921. Mathematical Creation. In: id., The Foundations of Science, trans. by George 
B. Halsted. New York, Garrison, NY, 383-394. 
Pötzl, Otto, 1928. Die Aphasielehre vom Standpunkte der klinischen Psychiatrie. Vol. 1: Die optisch-
agnostischen Störungen (Die verschiedenen Formen der Seelenblindheit). Vienna. 
Rühm, Gerhard (ed.), 1985. Die Wiener Gruppe: Achleitner, Artmann, Bayer, Rühm, Wiener. Reinbek. 
Ryle, Gilbert, 1963 [1949]. The Concept of Mind. London. 
Sartre, Jean-Paul, 2004. The Imaginary: A Phenomenological Psychology of the Imagination. Trans-
lated by Jonathan Webber, London and New York. 
Segal, Jakob, 1916. Über das Vorstellen von Objekten und Situationen: Ein Beitrag zur Psychologie der 
Phantasie. Stuttgart. 
Shepard, Roger N., 1978. The Mental Image. American Psychologist, 33/2, 125—137. 
Silberer, Herbert, 1909. Report on a Method of Eliciting and Observing Certain Symbolic Halluci-
nation-Phenomena. In: Rapaport, David (ed.), Organization and Pathology of Thought. New 
York 1951, 195—207. 
Skinner, Burrhus F., 1966. An Operant Analysis of Problem Solving. In: Kleinmuntz, Benjamin (ed.), 
Problem Solving: Research, Method and Theory. New York, 225—257. 
Sperry, Roger W., 1952. Neurology, and the Mind-Brain Problem. American Scientist, 40/2, 291—312. 
Stricker, Salomon, 1879. Studien über das Bewusstsein. In: id., 1883. Vorlesungen über allgemeine 
und experimentelle Pathologie. Vienna, 461-560. 
Turing, Alan M., 1937. On Computable Numbers, with an Application to the Entscheidungsproblem. 
Proceedings of the London Mathematical Society Second Series, 42/1, 230—265. 
Turing, Alan M., 1950. Computing Machinery and Intelligence. Mind, 59/236, 433—460. 
Watson, John B., 1914. Behavior: An Introduction to Comparative Psychology. New York. 
Wiener, Oswald, 1984. Turings Test. Kursbuch, 75, 12—37. 
Wiener, Oswald, 1988. Form and Content in Thinking Turing Machines. In: Herken, Rolf (ed.), The 
Universal Turing Machine: A Half-Century Survey. New York, 631—657. 
Wiener, Oswald, 1990. Kambrium der Künstlichen Intelligenz. In: Simon, Herbert A., Die Wissen-
schaften vom Künstlichen. Berlin, 175—228. 
Wiener, Oswald, 2000. Materialien zu meinem Buch VORSTELLUNGEN. In: Lesák, František (ed.), 
Ausschnitt 05. Vienna. 
Wiener, Oswald, 2013. die verbesserung von mitteleuropa / roman. Third edition. Salzburg. 
 
1          The title “Cybernetics and Ghosts” is not mine, but was suggested by Otto Neumaier, the edi-
tor of the volume in which the essay originally appeared (Neumaier 2015: 173—196). He chose 
it in reference to the title of a lecture given by Italo Calvino in 1967 (cf. Calvino 1986). 
2          Cf., e.g., Rühm (1985: 39). 
3         Cf., for example, Wiener (2013: CXLIX): “if (...) koppernigk would have had a computer at his 
disposal, which could have easily multiplied or shifted the ptolemaic circles having become 
conspicuous, we would probably have a modern ptolemaic worldview and would nonethe-
less be tackling space travel,” as well as further remarks passim. See also Loftus (1985). 
4         Wiener (1984, the subtitle is not mine); see also Wiener (1988: 633) and Wiener (1990). 
5         Poincaré (1921: 392). 
6         Named after the founder of IBM; it could just as well have been named after the founder of 
behaviorism, see below. 
7          See, for example, Ferrucci et al. (2010). During von Neumann’s times, a computer with as many 

tubes as the number of neurons in the human brain would have been as large as the Empire 
State Building, consumed the entire energy the Niagara River could supply, and would have 
needed the entire river for cooling. Now The Blue Gene / Q System at the Lawrence Livermore 
National Laboratory operates with 1.6 million processor cores and a memory capacity of 1.6 
petabytes (1.6 * 1015 bytes). In 2005, the Blue Gene / L System was already running at 280 tera-
FLOPS (280 * 1012 floating-point operations per second). The Brain Activity Map Project will 
engage about 300 petabytes per year. In a 2008 interview, Henry Markram claimed that his proj-
ect is designed on the basis of half an exabyte of memory (0.5 * 1018). So the supercomputers of 
five years ago would occupy the area of a few American football fields. Markram estimated his 
project’s electricity costs at three billion dollars per year (a typo? Cf. Lehrer 2008). Etc. 
8         That is, generating and testing symbol combinations under respective constraints, which 
would amount to Poincaré’s (op. cit.) calculations of the “subliminal self.” Cf. also the opera-
tion of the chess program Deep Blue (e.g., Campbell et al. 2001). 
9         The application of support vector machines (SVM) classifying all differences by the same 
method already points into this direction. 
10       Of course, sooner or later this will lead to disaster ... but the, decision-making by human intel-
ligence is unreliable too. 
11         This statement also holds true, or so I believe, for all other contemporary attempts at mock 
intelligence, which are by far less successful. 
12        Applying probability theory to psychology almost always carries the seed of sacrificing 
insight. Statistics and probability theory are the mathematical expression of behaviorism, 
the theorem of Bayes alone encapsulates its entire program: “When a response occurs and 
is reinforced {hit}, the probability that it will occur again in the presence of similar stimuli is 
increased” (Skinner 1966: 226). 
13        Watson (1914: 324); his “language habits” are mysterious, as his introspection proves: “(…) glance 
for a moment at the complexity of habit systems with which we have to deal in daily life. (…) 
before me as I write is a calendar with ’Friday, January 9’ upon its face. (…) The city bell rings 
12 P.M.. I say aloud ’another day over, it’s January 10!’ I glance at the calendar and say aloud, 
’tear off leaf.’ Immediately the movement is executed. Two stimuli are present simultaneously, 
both of which act upon the same effectors, viz., the intra-organically aroused one (exercise of 
the throat muscles) and the one extra-organically aroused (i.e., by the spoken word). 
            (…) On the other hand, I may think the words ’Saturday, January 10, tear off leaf,’ and the act will 
follow. (It is just at this point that the upholders of the image say that you can<not only think it 
by silent speech, but that you can also imagine the act and the movement will follow. Our con-
tention is that in thought the words must be uttered silently before the habitual act arises.) 
            (…) if a suitable stimulus is at hand, the act of the hand and arm follows. Now this stimulus 
can have its origin in any receptor (or in any muscle, considering them now as receptors). 
We have found such a group of receptors to be the throat muscles themselves, i.e., the move-
ment of these muscles, as the silent speaking of the word, will initiate the impulse which 
drives the muscles of the arms and hands. All such processes are at bottom really identical 
in nature” (Watson 1914: 332f., footnote). 
14        “Shallow” table lookup: the function is a set of ordered pairs (question/answer); “deep” table 
lookup: the answer is computed (recursive tables = programs). 
15        Wiener (1988: 646). 
16        Eliasmith (2000). 
17        Just as Brentano replaced the undefined term “psychic” by the undefined term “intentional,” 
newer explanations replace “conscious” by the undefined term “aware;” cf., for instance, 
Hobson’s “two theorems: (1) The mind is all the information in the brain. (2) Consciousness 
is the brain’s awareness of some of that information” (Hobson 1994: 203). 
186

187
18        Roger Shepard predicted such experiments: 
 
 
 
 
 
 
            Device used for the externalization of a purely mental image (Shepard 1978: 128) 
            But he already warned: “our hypothetical device would [.] reconstruct an external like-
ness of the object imagined, [but] this would not imply that the pattern of brain activity 
underlying the mental image had itself the shape of the external object” (ibid.), and “[n]ot 
only is it unnecessary to suppose that the brain process underlying a mental image is like 
some sort of picture, but in some situations it is unjustified to assume even that an exter-
nally reconstructed picture can fully capture what is represented in that brain process“ 
(ibid. 130). 
            The assumption that every time “I think of the same thing” a specific neural activity is more 
or less repeated seems evident today, but repeating an excitation pattern does not imply 
that the same image is activated. If a measuring instrument detects this pattern, we reach 
the strange conclusion that we now know “that I have thought something again,” but still 
don’t know what I have thought, and even less how thinking works. 
            Despite such concerns, Horikawa et al. (2013a, 2013b) did not refrain from “externalizing” 
some SVM classifications of their fMRI measurements on dreamers as image sequences — 
dream cinema in Science magazine. 
19        MacKay (1984: 298) developed this notion one step further into the “notion of the internal 
representation of the external world, not by a model or analogue in the usual sense, but by 
a structure that embodies a matching state of conditional readiness for action.” 
20       Beth and Piaget (1961: 234). 
21        Apparently, Sperry’s ideas are irrelevant for today’s neurophilosophy. In a book whose sub-
ject as well as title could well be inspired by Sperry (Metzinger 2000), his name is mentioned 
only once (by Joëlle Proust on page 309), and only in connection with his concept of “collat-
eral discharge” (which in turn, renamed efference copy by Guillery and Sherman [2011], could 
well include physiological arguments in favor of the [ideo-] motor hypothesis). 
22       In this case, the “logic of the object” is the structure described by “coordinate plane, ....” Let-
ting these structures run enables me to render the properties of the object explicit to myself. 
23       Usually, my sense of orientation “seems rather a negative than a positive thing, being the 
mere absence of a shock, or sense of discord, between the terms of thought” (James 1890: 
262f.). In my terminology it is the lack of an error signal. 
24       “Working memory.” 
25       Addendum to footnote 23: sometimes also as an attunement. 
26       “Our images are usually vague,” wrote James (1890, II: 45), and he was not the first to say so; 
more detailed Hadamard (1954: 78) noted: “I see something like a formula, but by no means 
a legible one, as I should see it (being strongly long-sighted) if I had no eye-glasses on, with 
letters seeming more apparent (though still not legible) at the place which is supposed to be 
the important one.” 
27       The fantastic addition I describe here obviously has no elementary function. However, in 
retrospect I realize that it represents a condensation and/or a symbol and, thus, the seed of 
the following insight: 
            I cannot follow the movements of η and ξ simultaneously if I want to grasp local details (as, 
for example, comparing the distances covered by η or ξ in a given time). I am able to seed 

the implied simultaneity — in the present case by an irritation, or otherwise, for example, by 
motor or quasi-motor innervations. But the seed can only be expanded to a structure, and 
this structure is able to surrogate the relevant connection of the simultaneous events only 
by a sequence of operations. 
            Now, on the one hand, the increasing tension of the rubber string points to the “ballistic” 
movement of η outside the pan. On the other hand, it symbolizes (in a way reminiscent  
of Silberer) my own irritation. At the same time, however — and this is the main point —, it 
projects a virtual process — moving η, then going back in time to study the behavior of ξ 
while moving η — onto a physically possible process. 
            When I first had this experience, I did not know yet that the implied luggage strap type is 
called “expander.” Otherwise, I might also refer to Freud’s idea of the rebus — which is obvious 
anyway regarding the expressions of “con-nection” and “re-lation“ (between η and ξ). 
28       Intuition “tells” that, but it has yet to be proven. 
29       I notice dream-like slips such as this so frequently that I believe they urgently deserve closer 
investigations (the “expander” commented above probably belongs to the same category). 
Are these normal intermediates of structural accommodation? “Splitting into partial qual-
ities,” “insufficient bundling of partial effects” (Pötzl 1928: 27). 
30       Namely in the direction of the quarter circle of the middle finger, which I do not detail here. 
31        The reader may ask him or herself how it is possible that s/he is able to understand this 
description. 
32       If I wanted to know exactly what this curve is all about, I would have to do some more work 
on it, but the direction is now marked out. A little analysis tells me that I come to an exact 
description of the curve via the exact description of the rod and its movement; a formula 
for it can soon be found with the help of Pythagoras and the intercept theorem; swapping 
the independent variables brings in the “swinging;” the derivation of this function yields the 
maximum. By these operations I derive the formula of a curve, which, as I will soon find out, 
already has a name. It is an “astroid.” And, by a series of generalizations, I further reach the 
harmonic oscillation and then the mechanics of the double slider mechanic — and who 
knows what! 
            My biggest yield is, of course, having found the general procedure for constructing an envel-
ope curve (but, following what I said on the first pages of this paper, the reader should keep 
in mind that computers are able to compute the respective curve solely on the basis of the 
maximum principle, i.e., without any “insight” caused by finding a closed formula for the 
respective envelope). After all, this excursion has, among other things, brought me to a 
deeper understanding of how to parameterize curves, etc. 
33       „Unconscious inferences,“ (Helmholtz 1995: 355) — “sense impressions change my orienta-
tion; now my orientation changes, therefore these are sense impressions ...;” “The visual 
character of my mental images seems less questionable, the less I pay attention to it” 
Wiener (2000: 79). 
34       Sentences like “it grows until it is half of a square cut diagonally by the hypotenuse,” although 
referring to experiences, leave the question of the phenomenal untouched. 
            Whoever wants to go beyond that should admit failure, as, e.g., “Subject XII [the author him-
self]: ‘It was like some blurred seeing.’ ’I would best compare it to the attempt of a 
blind man to see something, of which he knows where it is, and to look in that direction.’ 
’Seen extremely little. I was only aware of the compact environment. I did not move in 
empty space, but in the real store, although I saw very little of it. I could, however, indicate 
exactly the way I went” (Segal 1916: 433). 
            Ryle also hit the “phenomenological” ambition hard (but not fatally, since he could not show 
a viable alternative). 
188

189
35        I have often tried to formulate this strangely indirect, i.e., exactly the seed-like, character of my 
“mental images” — “as if I were looking through it,” “as if through a net,” “looking over it,” “next 
to it;” “as if I had just seen it,” “as if it were lying next to me and I could look at it at any time.” 
36       “I am vaguely conscious of the fact that in the flow of words something attaches itself to the 
word-presentations, whereby they become more than mere word-presentations,” wrote 
Stricker (1879: 41). By that he does not say much, but certainly something correct; amazing 
that he then continues: “But in active consciousness there is nevertheless only the word”! 
            “psychic overtone, suffusion, fringe” is how James (1890, I: 258) specified Stricker’s “self-con-
sciousness” (= “potential knowledge”) — “Since I have already used the metaphor of coal [for 
consciousness], I would like to add that it seems as if a large part of the coal depot is glowing 
without me hardly noticing it, but still it contributes to the general brightness, while only a 
small part of it actually shines” (Stricker 1879: 3). 
37       “Coincidences” also encompass that an unprimed structure is triggered by the situation. As 
most of them seem to fade almost without any effect, I have the impression that most of 
these manifestations are consumed as control signals for reconstructions (“realizations,” 
actualization of readinesses). 
38       According to Piaget, this meta-accommodation (my term, ad hoc) becomes possible with the 
onset of “conceptual intelligence” (1960; also “representative intelligence,” 1951: 161ff.) during 
the second year of human life. 
            The “image” is, of course, not a sign in the sense of a marking, but a seed or, if expanded, a 
structure, a schema, as Piaget himself indicated. 
39       Cf. the short glossary appended above. 
40      “Seed” is both a fortunate and an unfortunate term. At any rate, a seed is not a pointer in the 
sense of computer science, but the beginning of an assembly. 
41        Brentano (1874: 40f. and passim): “inner perception.” 
42       See, for example, Coltheart (2006a, 2006b, as well as the other papers in that same volume, 
and van Orden and Paap (1997) — thanks, Thomas Raab, for the references! 
43       Eder and Raab (2015). 
44       It does not take much introspection to understand that a structure is instantiated quite differ-
ently in an organism than, for example, in a computer. The concept of the Turing machine is 
just a “miroir” (of a specific, essential aspect) of the “pensée reélle.” — “Logic is the mirror of 
thought, and not vice versa (...) we were led to this point of view by the study of the formation 
of operations in the child” (Piaget 1960: 27). I would translate “miroir” simply as “surface.” In 
the same sense Piaget elsewhere spoke of a “decal” (décalque, Beth and Piaget 1961: 155). 
45       A heterarchy is a hierarchy that can be rearranged (following respective laws). 
            The idea that “a conceptual schema is a heterarchy of schemata” does not lead to an infinite 
regress, because the elementary building blocks are “hard-wired” sensorimotor schemata 
(which can be “mirrored” as finite automata). 
46       Conceptual schemata develop via attunements and affects. 
47       Compared to the canonical Turing machine, the need for such scaffolding is an essential fea-
ture of “living thought.” 
48       Obviously, seeds are only expanded as far as the respective task requires. I often notice, for 
instance, that a completely undeveloped seed — “This [imageless] (is also involved)” — results 
in a radical rearrangement of current tendencies. 
49       Such excitations are preconscious (“latently conscious,“ i.e., potentially expandable to a seed 
and beyond) or unconscious. A heterarchy of action readinesses can manifest itself, seed-
like, as an attunement. 
 


