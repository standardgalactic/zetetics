Nature Computational Science | Volume 3 | October 2023 | 883–893
883
nature computational science
https://doi.org/10.1038/s43588-023-00519-x
Article
Unifying pairwise interactions in complex 
dynamics
Oliver M. Cliff1,2, Annie G. Bryant1,2, Joseph T. Lizier 
  2,3, Naotsugu Tsuchiya 
  4,5,6 
& Ben D. Fulcher 
  1,2 
Scientists have developed hundreds of techniques to measure the 
interactions between pairs of processes in complex systems, but these 
computational methods—from contemporaneous correlation coefficients 
to causal inference methods—define and formulate interactions differently, 
using distinct quantitative theories that remain largely disconnected. Here we 
introduce a large assembled library of 237 statistics of pairwise interactions, 
and assess their behavior on 1,053 multivariate time series from a wide 
range of real-world and model-generated systems. Our analysis highlights 
commonalities between disparate mathematical formulations of interactions, 
providing a unified picture of a rich interdisciplinary literature. Using three 
real-world case studies, we then show that simultaneously leveraging diverse 
methods can uncover those most suitable for addressing a given problem, 
facilitating interpretable understanding of the quantitative formulation 
of pairwise dependencies that drive successful performance. Our results 
and accompanying software enable comprehensive analysis of time-series 
interactions by drawing on decades of diverse methodological contributions.
A fundamental question in science is how complex dynamics can be 
characterized by measuring the interactions within a distributed sys-
tem. To address this question, many approaches have been developed 
to measure different types of pairwise interactions from dynamical 
data. For example, in neuroimaging, functional connections between 
pairs of brain regions are quantified through statistical correlations, 
which mark changes in human behaviors1 and differ in neurological 
diseases2. In Earth system science, pairwise causal models have been 
used to infer mechanistic drivers of natural processes, from the influ-
ence of sea-surface temperature on sardine and anchovy populations3, 
to the atmospheric drivers of air circulation4. Furthermore, economic 
analysts have studied the co-integration of paired non-stationary time 
series—including stock-market indices and their associated future 
contracts—to infer a statistically significant coupling for building 
econometric models5.
As illustrated schematically in Fig. 1a, the common goal of these 
studies is to extract meaningful pairwise relationships from multi-
variate time series (MTS): sets of observations taken regularly over 
time6. In the age of big data, the scientific problems that are studied in 
diverse disciplinary contexts—from genomics to astronomy7—require 
novel ways to extract information from MTS data; however, despite the 
myriad ways to quantify a statistical dependency between two time 
series, it remains common practice to manually select a single method 
with minimal comparisons against alternatives. For instance, Pearson 
correlation remains the most commonly used tool for measuring pair-
wise relationships in neuroimaging8 and Earth system science4, despite 
rather restrictive (and often unsatisfied) assumptions that the data are 
serially independent and normally distributed9. Fortunately, many 
more sophisticated and powerful algorithms have been developed, 
including those where dependencies are lagged in time (for example, 
Received: 1 July 2022
Accepted: 14 August 2023
Published online: 25 September 2023
 Check for updates
1School of Physics, The University of Sydney, Camperdown, New South Wales, Australia. 2Centre for Complex Systems, The University of Sydney, 
Camperdown, New South Wales, Australia. 3School of Computer Science, The University of Sydney, Camperdown, New South Wales, Australia. 4Turner 
Institute for Brain and Mental Health & School of Psychological Sciences, Faculty of Medicine, Nursing, and Health Sciences, Monash University, 
Melbourne, Victoria, Australia. 5Center for Information and Neural Networks (CiNet), National Institute of Information and Communications  
Technology (NICT), Suita-shi, Japan. 6Advanced Telecommunications Research Computational Neuroscience Laboratories, Seika-cho, Japan.  
 e-mail: ben.fulcher@sydney.edu.au

Nature Computational Science | Volume 3 | October 2023 | 883–893
884
Article
https://doi.org/10.1038/s43588-023-00519-x
these methods remain disconnected from one another. In this work, we 
unify this wealth of interdisciplinary scientific knowledge, empirically 
connecting previously disjoint methodological traditions to yield a 
unified set of tools for quantifying interactions in complex dynamics.
As diverse scientific methods for quantifying pairwise interactions 
have never been compared at scale, there remain many unanswered 
questions. Are all of these methods capturing unique information 
on the interactions occurring within a time-varying system? Is there 
synergy between complementary approaches that, when combined, 
tells us more about the underlying system than any single method 
can? Or, do interesting redundancies exist between techniques used 
across disciplines that hint at a common theoretical underpinning 
cross-correlation6), may be misaligned (for instance, dynamic time 
warping10), or where the knowledge of one variable improves the pre-
dictability of another (for example, Granger causality11).
In this Article, we represent algorithms that measure interactions 
between pairs of time series as real-valued summary statistics, that 
is, statistics of pairwise interactions (SPIs). Figure 1b illustrates the 
diverse theoretical tools and types of interactions covered in the sci-
entific literature on SPIs, from covariance (the foundation of statistics 
and machine learning) to convergent cross-mapping3 (developed to 
infer causal effect in complex ecosystems); however, as the theory 
underlying statistical interactions between pairs of time series has 
been developed largely independently across disciplinary contexts, 
Time
?
Miscellaneous (17 SPIs)
Linear model fits
Cointegration
Envelope correlation
...
Basic (21 SPIs)
Covariance
Kendall's τ
Cross-correlation
...
Causal indices (10 SPIs)
Additive noise models
Convergent cross-mapping
...
Distance similarity (26 SPIs)
Distance correlation
Heller–Heller–Gorfine test
Dynamic time warping
...
Information theory (37 SPIs)
Mutual information
Transfer entropy
Integrated information
...
Spectral (126 SPIs)
Coherence magnitude
Directed coherence
Spectral Granger causality
...
Library of 237 SPIs
Library of MTS (1,053 datasets)
Synthetic models (505 time series)
Wave equations
Coupled oscillators
Coupled maps
Brownian motion
Ornstein–Uhlenbeck
Simulated climate
Simulated fMRI
Uncorrelated noise
Vector autoregressive
Real-world data (548 time series)
fMRI data
Daily stock prices
Epidemic incidence
River runoﬀ
Earthquake seismograms
Articulogram
Human activity
EEG data
Heartbeat sonogram
MTS
Interacting pairs of time series
Process
Time
a
b
c
€
$
Fig. 1 | The behavior of a scientific library of 237 SPIs was evaluated using 
a collection of 1,053 MTS. a, In many disciplines, including neuroscience, 
economics and biology, scientists analyze interactions between pairs of 
processes in a MTS. For illustration, two time series are plotted, using colour to 
indicate time-series values on a scale from low (light blue), to the mean (black), 
to high (light orange). An MTS can be visualized as a heat map using the same 
coloring, in which individual processes (rows) evolve over time (columns). 
b, The 237 SPIs analyzed here derive from six broad disciplinary categories: 
‘basic’, ‘distance similarity’, ‘causal indices’, ‘information theory’, ‘spectral’ 
and ‘miscellaneous’, as described in detail in Supplementary Note 1; selected 
examples of SPIs within each category are listed here, along with a schematic 
depiction. c, Selected examples from our diverse collection of 1,053 MTS—
which are used to evaluate the empirical behavior of the SPIs—are plotted as 
process × time heat maps (using the same colors as in a). Our library includes data 
generated from synthetic models (left) and measured from real-world systems 
(right), as described in detail in Supplementary Note 2.

Nature Computational Science | Volume 3 | October 2023 | 883–893
885
Article
https://doi.org/10.1038/s43588-023-00519-x
that has not previously been identified? Following previous highly 
comparative studies of univariate time series12 and graphs13, this work 
addresses these questions by simultaneously evaluating hundreds 
of different SPIs directly from data. Our empirical approach to this 
problem involves first assembling a comprehensive annotated library 
of computational methods for quantifying pairwise interactions from 
data (summarized in Fig. 1b), and then analyzing their behavior across 
a large and diverse library of MTS (Fig. 1c).
As shown in Fig. 1b, our annotated library of SPIs was organized 
into six broad categories on the basis of their underlying theory: ‘basic’, 
‘distance similarity’, ‘causal indices’, ‘information theory’, ‘spectral’ 
and ‘miscellaneous’ (see ‘Library of 237 SPIs’ section in the Methods 
for more details, and Supplementary Note 1 for a full list of SPIs with 
descriptions and references). To understand the behavior of these SPIs 
on data, we constructed a library of 1,053 diverse MTS, curated with 
the aim of capturing the main classes of systems and dynamics that 
are studied across scientific disciplines, including synchronization, 
spatiotemporal chaos, wave propagation, criticality and phase transi-
tions. As depicted in Fig. 1c, our MTS library contains 505 synthetic MTS 
generated from a range of mathematical models, including coupled 
maps, ordinary differential equations and partial differential equations, 
and 548 diverse real-world MTS assembled from public databases such 
as geophysical, medical and financial data (see ‘Library of 1,053 MTS’ 
section in the Methods for further details, and Supplementary Note 2 
for a full list of included MTS).
Results
Organizing pairwise interactions by their empirical behavior
Having assembled diverse libraries of methods (237 SPIs) and data 
(1,053 MTS), we aimed to analyze how similarly the different SPIs behave 
on the data. To achieve this, we developed an empirical similarity index, 
R (0 ≤ R ≤ 1), that captures the relationship between any two SPIs by 
comparing their output when applied to all 195,112 pairwise interactions 
present across all 1,053 MTS. This index is derived from the average 
absolute Spearman correlation between a pair of SPIs when applied to 
all pairs of processes in all datasets (see ‘Quantifying similarity between 
SPIs using the empirical similarity index’ section of the Methods for 
details). The minimum value, R = 0, indicates a pair of maximally  
distinct SPIs (with uncorrelated behavior on all datasets), whereas the 
maximum, R = 1, indicates a pair of SPIs that are perfectly correlated on 
all datasets (that is, they behave as simple monotonic transformations 
of one another); thus, a pair of SPIs with a high R reflects broadly similar 
behavior across MTS containing very different types of structures, and 
therefore acts as a suitable candidate index of empirical similarity.
Using the dissimilarity measure, D = 1 − R, we organized all 237 
SPIs using hierarchical clustering, yielding the dendrogram shown in  
Fig. 2b. This presents a data-driven, structured representation of a 
diverse literature that allows us to probe and interpret relationships 
between scientific methods at multiple levels. We focus our analysis 
here on a 14-module resolution (with modules labeled M1–M14), which 
captures important methodological connections between groups of 
SPIs with similar behavior on data. As summarized in Fig. 2a, these four-
teen modules group common conceptual and theoretical approaches 
to measuring interactions between pairs of time series, demonstrating 
the ability of our empirical approach to meaningfully organize the 
interdisciplinary literature.
In addition to grouping similar types of methods into modules, we 
found that different high-level conceptual formulations of dynamical 
interactions were recapitulated in the relationships between modules. 
For example, modules M3–M6 contain distinct types of SPIs (including 
Granger causality11, directed information14 and integrated informa-
tion15,16), all of which capture statistical dependencies between two 
time series by considering the context of their past. This idea that 
observable interactions are predicated (or, from a statistical stand-
point, conditioned) on the history of a process was first proposed by 
the Wiener–Granger theories of causality and feedback17, specifically 
by measuring how one time series might improve the self-predictabil-
ity of another. Our results group SPIs on the basis of this underlying 
theoretical formulation, due to their characteristic behavior on data. 
Other types of SPIs (that do not predicate on the self-predictability 
of a process) also display distinctive behavior, including measures of 
contemporaneous relationships (the correlation coefficients of M14), 
dependencies that account for temporal lags (the coherence measures 
of M12), or temporal dilation and shifts (dynamic time warping and 
related methods in M10).
Ten of the fourteen modules are homogeneous, containing meth-
ods that are derived from similar underlying theories (as indicated by 
the color of the category labels in Fig. 2bii). Of these ten homogeneous 
modules, six of them (M4, M7, M8, M9, M11 and M13) comprise SPIs 
for measuring one specific type of pairwise interaction, differing in 
either their: specific algorithmic implementation (for example, M13 
contains both the Engle–Granger5 and the Johansen18 tests for meas-
uring co-integration); extracted summary statistics (for example, M8 
contains both the mean and maximum of the wavelet-based phase lag 
index19); or parameter settings (for example, M4 contains SPIs that 
use five different estimation techniques for transfer entropy20). The 
remaining four homogeneous modules (M1, M2, M6 and M12) comprise 
methods with very similar theoretical underpinnings; for example, 
M12 contains many SPIs for measuring undirected interactions via 
Fourier transformations, such as the magnitude and the imaginary part 
of the coherence21. Of particular interest are the four heterogeneous 
modules (M3, M5, M10 and M14), which mix SPIs from different litera-
ture categories, revealing interesting connections between different 
theoretical bases for quantifying pairwise dependencies between time 
series. Although M3 contains a mix of SPIs based on information theory 
(six labeled ‘information theory’ measures and one, information-
geometric conditional independence, labeled as a ‘causal index’), the 
remaining three modules establish interesting connections between 
the behavior of seemingly disparate SPIs on MTS data. Three networks 
that are derived from these modules are plotted in Fig. 2c–e and are 
investigated in detail below.
As illustrated in Fig. 2c, module M5 contains a mix of two different 
types of methods: the first includes five linear estimators for inte-
grated information (such as geometric integrated information, ΦG 
(ref. 22), phi star, Φ* (ref. 16) and stochastic interaction23), whereas the 
second includes 16 estimators for Granger causality in both the time 
and frequency domains24. Although Granger causality and integrated 
information theory were developed in very different contexts (for 
example, Granger’s investigations into causality between economic 
time series in 196911, versus Tononi’s recent integrated information 
theory (Φ) of consciousness15,16,22), our analysis reveals that all SPIs 
in this module nevertheless behave similarly on data (with an empiri-
cal similarity index, R = 0.52, which lies in the 95th percentile for all  
R values; see Supplementary Fig. 1c). Recent results have indeed shown 
that Granger causality can be formulated as the information-theoretic 
measure, transfer entropy25, and can thus be grouped under the same 
information-geometric framework as integrated information the-
ory22,26. However, it was not known whether these information-theoretic 
SPIs behave similarly in practice and, as such, their relationship was 
not widely recognized. Module M5 thus demonstrates an important 
confirmation of our empirical approach in being able to recapitulate 
emerging theory and unify scientific tools for understanding interact-
ing processes.
Module M10, shown in Fig. 2d, highlights striking connections 
between three conceptually distinct types of methods: (1) dynamic 
time warping (DTW), which was developed in the data-mining com-
munity to quantify the similarity between two (potentially shifted and 
dilated) audio signals10; (2) cross-spectral phase-based measures—the 
maximum phase coherence21, and the mean and maximum phase-
locking value27—which were developed to examine frequency-specific 

Nature Computational Science | Volume 3 | October 2023 | 883–893
886
Article
https://doi.org/10.1038/s43588-023-00519-x
synchronization in neuroimaging data21; and (3) the maximum cross-
correlation6, a classical statistical technique for correlating two time 
series at different temporal lags. All of these SPIs capture time-lagged 
interactions between two processes, but in slightly different ways: 
the maximum cross-correlation finds the highest fixed-lag match, 
DTW extends this idea by optimizing the distortion of the time axis to 
best match potentially misaligned time series, and the cross-spectral 
measures account for time lags in terms of phase differences. Module 
M10 thus reveals previously unreported connections between diverse 
approaches to capturing associations between pairs of potentially una-
ligned time series, indicating a common conceptual basis for methods 
developed and applied across disciplines—whether they are measuring 
synchronization between neuroelectric recordings or recognizing 
speech from audio signals.
Finally, we discuss module M14, which groups 66 SPIs from all  
literature categories except for ‘spectral’ (see Fig. 1b for categories). This 
module recapitulates some theoretical relationships that have already 
been established, such as the equivalence between linear-Gaussian  
mutual information and absolute correlation28 (with a maximum 
similarity of R = 1). To highlight some previously unreported rela-
tionships, we focus on a demonstrative submodule (shown in Fig. 2e)  
comprising 17 SPIs from the ‘causal indices’, ‘distance similarity’ and 
‘miscellaneous’ literature categories. We first note the tight cluster of 
SPIs, labeled ‘i’ in Fig. 2e, that were developed independently in two 
different domains: distance correlation-based methods29 from the 
statistics community, and kernel-based methods from the machine-
learning community. This cluster first highlights a recent finding that 
distance correlation and the Hilbert–Schmidt independence criteria 
M1: mean phase lag/slope
indices and group delay
M2: causal models
M3: directed information
and causal entropy measures
M4: transfer entropy
M7: max phase lag indices
M5: parametric granger causality
and integrated information
M6: parametric granger causality
and directed spectral measures
M8: phase slope indices (wavelet)
M13: co-integration
M14: a mix of contemporaneous linear-
dependence statistics, information-
theoretic measures, convergent cross-
mapping, maximum barycenters, 
distance- and kernel-based statistics
M12: undirected spectral measures
M10: dynamic time warping,
phase coherence and locking values
M11: Power envelope correlation
M9: mean of barycenters
Spectral Granger
causality
(optimized order)
Φ* and stochastic
interaction
Granger
causality
CCM
(optimized/
high order)
Spectral Granger
causality
(ﬁrst order)
DTW/LCSS
(ref. 
10)
Phase
coherence
M1
M4
M8
M13
M10
M7
M5
M14
M6
0
0.2
0.4
0.6
0.8
M3
M12
Distance- and kernel- 
based statistics
Phase coherence
Phase
locking
value
Maximum
cross-correlation
Soft DTW
and DTW
LCSS
CCM (ﬁrst order)
ΦG
R > 0.50
R > 0.25
R > 0.75
Gaussian process
ﬁt (RBF)
Distance (D)
i
ii
i
a
b
c
d
e
Fig. 2 | Statistics for measuring pairwise interactions between time series can 
be organized into 14 modules on the basis of their behavior on over 1,000 
MTS, providing an intuitive, data-driven organization of interdisciplinary 
scientific literature. a, A brief summary of the main types of methods in each  
of the modules (see Supplementary Note 1 for a full list with descriptions).  
b, The dendrogram used to infer the modules, produced by hierarchical clustering 
using a dissimilarity measure, D = 1 − R, that is based on the empirical similarity 
index, R (see Methods). SPIs are colored according to: (i) their module label 
(upper row) and (ii) their literature categorization (lower row), displayed using 
the color scheme defined in Fig. 1b. A high-resolution version of this dendrogram, 
including each of the SPIs (leaf nodes) that form the modules, is presented in 
Supplementary Fig. 2 (and the assignment of SPIs to modules is in Supplementary 
Data 1). c–e, Three selected modules that include a mixture of SPIs developed in 
different disciplinary contexts are shown as network plots in M5 (c), M10 (d) and 
a subset of M14 (e). In these plots, SPIs are represented as nodes, three different 
edge weight thresholds are displayed (corresponding to R > 0.25, R > 0.5 and 
R > 0.75), and connected components with high similarities, R > 0.75, are shaded 
yellow. DTW, dynamic time warping; LCSS, longest continuous subsequence; 
CCM, convergent cross-mapping; RBF, radial basis function.

Nature Computational Science | Volume 3 | October 2023 | 883–893
887
Article
https://doi.org/10.1038/s43588-023-00519-x
(HSIC, a kernel-based method)30 are equivalent when computed using 
certain distance kernels31; our results suggest that similar theoretical 
connections can be established between the other SPIs of the clus-
ter (including the Heller–Heller–Gorfine test32 and multiscale graph 
correlation29). Second, we find that the distance- and kernel-based 
statistics display strikingly similar behavior as common implementa-
tions of the convergent cross-mapping (CCM) algorithm, which was 
originally developed for inferring causality in complex ecosystems3. 
Convergent cross-mapping aims to measure the causal effect of one 
time series on another by the ability of the second to reconstruct the 
first using a nearest-neighbor approach. The fact that these methods 
behave so similarly on MTS data indicates that the well-studied tech-
niques of phase-space reconstruction (used in the CCM algorithm) 
have a correspondence to the nonlinear kernel-estimation techniques 
from the statistics and machine learning communities. These observed 
connections also have important practical ramifications; for example, 
our results suggest candidate proxy algorithms to substitute for the 
computationally expensive CCM, which could yield major compu-
tational efficiencies and enable new applications on larger datasets.
In summary, our empirical approach to unifying a large and dis-
joint literature of methods for characterizing pairwise interactions 
in time series has allowed us to: (1) capture the commonalities in 
0
0.05
0.10
45
75
Average accuracy (%)
Proportion
Significant SPIs
All SPIs
0
0.05
0.10
20
40
60
80
100
Average accuracy (%)
Proportion
Significant SPIs
All SPIs
xyzxyz
Accelerometer (acceleration)
Gyroscope (angular velocity)
b
c
y
z
x
z rotation
x translation
f
d
a
g
h
i
Channel
2 → 1
Control
Ventral
attention
– Cortical negativity
+ Cortical positivity
Cursor
movement
e
fMRI networks
fMRI film dataset
EEG state dataset
Smartwatch
activity dataset
Control
Default
Dorsal attention
Limbic
Salience/ventral attention
Somatomotor
Visual
Resting
fMRI
Film-
viewing
fMRI
EEG channels
1
2
3
4
5
6
1
2
1
2
3
4
5
6
0.008
0.012
0.016
0.020
0.024
Film
Rest
RECI
0
0.05
0.10
40
80
100
Average accuracy (%)
Proportion
Significant SPIs
All SPIs
Pearson correlation
0
2
4
6
Running
Walking
Causally conditioned
entropy, Kozachenko
–6
–4
–2
0
Negativity Positivity
Causally conditioned
entropy, Gaussian
Badminton
Running
Walking
Resting
Time
x
50
55
60
65
70
↓
60
↓
z
y
Fig. 3 | A comprehensive library of SPIs can be used to accurately classify and 
understand differences in human movement and neural activity datasets.  
a, In the smartwatch activity dataset, we aimed to determine which of four 
activities a participant is performing (‘resting’, ‘walking’, ‘running’ or ‘badminton’) 
from smartwatch accelerometer recordings. An example MTS from each of the 
four classes is shown as a process × time heat map (colored as in Fig. 1a).  
b, Distribution of average classification accuracy (over train–test resamples) across 
228 SPIs, where all pairwise interactions are used as the basis for classification 
for each SPI. The 213 SPIs with significant accuracy are shaded blue (one-sided 
permutation test, Bonferroni-corrected P < 0.05). Concatenating feature vectors 
from all SPIs into a single classification model yields an average accuracy of 96% 
(red). c, Violin plots showing the distribution of the top-performing SPI (causally 
conditioned entropy with a Kozachenko–Leonenko density estimator) between 
the wrist’s x-axis translation and z-axis rotation, indicating a stronger interaction 
during walking (mean ± s.d. = 4.1 ± 0.8, N = 20) than running (0.4 ± 0.7, N = 20). 
In each violin plot, the annotated box plot shows the box centre and extent as 
the median, 25th and 75th percentiles; whiskers extend for 1.5× the interquartile 
range and outliers are shown as black dots. d, In the EEG state dataset, we aimed 
to classify positive versus negative cortical activity states using data from six EEG 
channels, for which the electrode locations and example time series are depicted.  
e, Distribution of average classification accuracy across all 219 SPIs, including 
the 165 significant SPIs, and a combination of all SPIs (71% accuracy). f, The 
top-performing SPI (causally conditioned entropy with a Gaussian density 
estimator) is visualized from EEG channel 2 to 1 in cortical negativity (−2.7 ± 1.4, 
N = 282) versus positivity (−3.8 ± 1.4, N = 279). g, In the fMRI film dataset, we 
aimed to classify rest versus film-viewing using fMRI time series from seven brain 
networks. h, Distribution of classification accuracy across all 227 SPIs, including 
the 67 significant SPIs (shaded blue) and annotating the performance of Pearson 
correlation coefficient (86%, black) and the combined set of all 227 SPIs (91%, red) 
for comparison. i, The top-performing SPI (regression error-based causal inference, 
RECI) is shown from the control to ventral attention networks in film-viewing 
(0.014 ± 0.003, N = 29) and rest (0.018 ± 0.004, N = 29) conditions.

Nature Computational Science | Volume 3 | October 2023 | 883–893
888
Article
https://doi.org/10.1038/s43588-023-00519-x
the conceptualizations of dynamical interactions (such as whether  
methods predicate a statistical dependence on self-predictability) and 
(2) understand empirical and theoretical connections between diverse 
methods, with implications for shaping theory and practice.
Leveraging diverse methods to address scientific problems
Our results above illustrate the rich diversity of scientific methods 
for quantifying pairwise interactions. This diversity suggests that, 
when quantifying pairwise interactions for a given application, there 
is potential to make comparisons across the scientific literature of SPIs 
to: (1) select the best-performing SPI in an unbiased, data-driven way; 
and (2) leverage a synergistic combination of multiple complemen-
tary SPIs to better capture complex underlying interactions in MTS. 
Here we provide a simple demonstration of this strategy (referred to 
as ‘highly comparative’ due to the broad methodological comparison 
involved12,13) on three MTS classification problems using three open 
datasets: (1) the smartwatch activity dataset (Fig. 3a), where the aim 
is to classify one of four behavioral states (walking, running, resting, 
or playing badminton) from six-sensor smartwatch MTS (compris-
ing a three-axis accelerometer and three-axis gyroscope)33; (2) the 
electroencephalogram (EEG) state dataset (Fig. 3d), where the aim is 
to distinguish positive versus negative slow cortical potentials from 
single-subject EEG data (originally used to move a cursor up or down 
on a computer screen)34,35; and (3) the functional magnetic resonance 
imaging (fMRI) film dataset (Fig. 3g), where the aim is to classify rest-
ing and film-watching conditions from fMRI data36 (see ‘Classifica-
tion case studies’ section in the Methods for additional details on each 
dataset). To investigate the performance of different SPIs on these 
tasks, we represented each MTS as a set of features corresponding to 
all pairwise interactions between its constituent processes and com-
pared their classification performance using a linear support vector 
machine (SVM) with cross-validation (see ‘Classification’ section in 
the Methods for details).
We observed a wide range of SPI performances in each case study, 
ranging from null performance up to high and statistically significant 
performance: 27–92% accuracy on the smartwatch activity dataset  
(Fig. 3b), 48–69% accuracy on the EEG state dataset (Fig. 3e) and 41–95% 
accuracy on the fMRI film dataset (Fig. 3h). Many SPIs displayed sig-
nificant classification performance on each dataset (permutation test, 
Bonferroni-corrected P < 0.05): 213 SPIs for the smartwatch activity 
dataset, 165 SPIs for the EEG state dataset, and 67 SPIs for the fMRI film 
dataset. This wide range of observed SPI performance on all three data-
sets demonstrates the crucial importance of selecting an SPI that is able 
to capture the relevant types of interactions underlying a given dataset.
To understand the types of interactions that characterize the 
labeled classes of MTS, we analyzed and interpreted the highest-per-
forming SPIs on each dataset (see Supplementary Data 2 for the full 
results). To provide a simple demonstration of this process, here we 
focus on the top-performing individual SPI in each case study. In the 
smartwatch activity dataset, the top-performing SPI was causally 
conditioned entropy (CCE) using a Kozachenko–Leonenko estimator 
(92% accuracy; SPI label ‘cce_kozachenko’; see Supplementary Note 
1.4.7 for details). Its high performance is driven in part by its ability to 
capture the coupling from the wrist’s z-rotation to its x-translation, 
which differs strongly between running and walking, as shown in  
Fig. 3c. This tells us that wrist rotation in the z-direction is more inform-
ative of subsequent elbow movement in the x-direction (as the elbow 
moves side to side) in walking than in running.
The top-performing SPI for the EEG state dataset was, as above, a 
causally conditioned entropy, but using a Gaussian density estimator 
(69%, SPI label ‘cce_gaussian’; see Supplementary Note 1.4.7 for details). 
Its performance was driven in part by its ability to capture the increased 
coupling from EEG channel 2 to 1 (from near the right ear to near the left 
ear) in cortical negativity versus positivity states, as shown in Fig. 3f. 
Other statistics designed to capture directed information flow (in a way 
that includes instantaneous interactions in the presence of feedback) 
also performed well on this task, including directed information with 
a Gaussian density estimator (69% accuracy, SPI label ‘di_gaussian’; see 
Supplementary Note 1.4.8). Although past applications of SPIs derived 
from directed information theory to neuroimaging data are limited37,38, 
our highly comparative analysis suggests them as high-performing 
methods for measuring EEG coupling alongside other novel candi-
dates for further investigation, including the direct directed transfer 
function evaluated over high frequencies (67%, SPI label ‘ddtf_multi-
taper_mean_fs–1_fmin-0–25_fmax-0–5’; see Supplementary Note 1.5.9) 
and the Hilbert–Schmidt Independence Criterion (66%, SPI label ‘hsic’; 
see Supplementary Note 1.2.5). Of the classical methods for quantifying 
EEG connectivity, some are recapitulated as high performers by our 
data-driven analysis, including mean directed coherence across various 
frequency bands39 (all 67% accuracy; see Supplementary Note 1.5.10), 
whereas others exhibited surprisingly low accuracy, such as algorith-
mic variants of partial directed coherence40 (between 55% and 64%).
Finally, for the fMRI film dataset, the top-performing SPI was 
regression error-based causal inference (95% accuracy; SPI label ‘reci’; 
see Supplementary Note 1.3.4). Its high performance is driven in part 
by its ability to capture the stronger coupling from the control network 
to the ventral attention network during film-watching compared to 
rest (Fig. 3i). The dominant way of measuring coupling in whole-brain 
fMRI is to use the Pearson correlation coefficient8,41 (annotated in  
Fig. 3h), which exhibits strong and statistically significant classification 
accuracy on this problem (86%); however, our data-driven approach 
highlights 30 alternative SPIs with higher performance (88% to 95%; 
compare with Supplementary Data 2). These high-performing meth-
ods include alternative types of covariance (for example, minimum 
covariance determinant, 93% accuracy, SPI label ‘cov_MinCovDet’; 
see Supplementary Note 1.1.1) and precision estimates (for example, 
using Ledoit–Wolf shrinkage, 91%, SPI label ‘prec_LedoitWolf’; see 
Supplementary Note 1.1.2) that better deal with non-Gaussian bivariate 
distributions. Other high performers include information-theoretic 
SPIs (such as conditional entropy, joint entropy and mutual informa-
tion using Gaussian density estimators, all of which exhibited 91% 
accuracy; see Supplementary Note 1.4.1–1.4.3) and directed SPIs which 
distinguish asymmetric coupling (for example, the top-performing 
regression error-based causal inference, ‘reci’). Compared with the typi-
cally subjective process of selecting an appropriate method to analyze 
a given dataset, the highly comparative approach demonstrated here 
highlights the most useful scientific methods automatically, facilitat-
ing interpretable understanding of the conceptual formulations of 
pairwise dependencies that drive successful performance.
As different types of systems involve different types of interactions 
between measured processes, we expected different SPIs to perform 
well across the three datasets. Indeed, we found that an SPI with high 
performance on one problem does not imply its high performance 
on other problems. In particular, some SPIs performed well on only 
a single dataset; for example, dynamic time warping with an Itakura 
parallelogram (SPI label ‘dtw_constraint–itakura’; see Supplementary 
Note 1.2.7), which was a top performer on the fMRI film dataset (91%), 
but showed weaker performance on the smartwatch activity dataset 
(78%) and null performance on the EEG state dataset (53%). Yet some 
SPIs did perform strongly across all three datasets, such as the cross 
distance correlation (SPI label ‘dcorrx_maxlag–10’; see Supplementary 
Note 1.2.2), which ranked among the top 10 SPIs for all three problems 
(90%, 66% and 91%, for the smartwatch activity, EEG state and fMRI film 
datasets, respectively). Moreover, different algorithmic variants of 
causally conditioned entropy were top performers for the smartwatch 
activity (‘cce_kozachenko’, 92%), EEG state (‘cee_gaussian’, 69%) and 
fMRI film (‘cce_kernel_W–0.5’, 90%) datasets (although we note a strong 
dependence of the density estimation approach on CCE performance). 
We also found that grouping SPIs based on the fourteen data-driven 
modules (identified by their similarity of behavior on data, Fig. 2) 

Nature Computational Science | Volume 3 | October 2023 | 883–893
889
Article
https://doi.org/10.1038/s43588-023-00519-x
better captured their relative performance on these tasks than the six 
literature categories (from Fig. 1b), as shown in Supplementary Fig. 3, 
suggesting our modular representation as a useful one for understand-
ing differential SPI performance on a given task.
Relative to investigating individual SPIs one at a time, we finally 
aimed to investigate the value of drawing on multiple SPIs simulta-
neously. We developed a combined representation of the pairwise 
dependence structures captured by all SPIs, allowing us to simultane-
ously represent each MTS using a large and diverse set of pairwise 
dependency structures (through feature concatenation, as described 
in the ‘Classification’ section of the Methods). Although this approach 
represents each MTS in a much higher-dimensional space than the indi-
vidual SPI representation analyzed above (with associated challenges 
for robust classifier fitting), we expected it to outperform the individual 
best SPI on datasets involving multiple types of interactions, such that 
simultaneously leveraging multiple SPIs provides complementary 
and useful information about class differences. Relative to the top-
performing individual SPI, our combined SPI approach improved clas-
sification accuracy on the smartwatch activity dataset (to 96%) and the 
EEG state dataset (to 71%), shown as vertical red lines in Fig. 3b,e. On the 
fMRI film dataset, it yielded slightly lower performance (91%) than the 
top individual SPI, ‘reci’ (95%), suggesting that the associated interac-
tions are well-captured by a single, well-chosen SPI on this dataset (that 
is, multiple SPIs do not provide an advantage sufficient to overcome 
the challenges of fitting a classifier in a higher-dimensional space). By 
simultaneously drawing on a wide range of SPIs, the simple statistical 
approach demonstrated here can quantify multiple complementary 
types of interactions from MTS data (and is likely to yield improved 
accuracy through optimization; see ‘Discussion’ section).
Discussion
Our empirical organization of SPIs (Fig. 2b) identifies connections 
between a rich literature of diverse methods for quantifying interac-
tions between time series, and thereby highlights fruitful directions for 
future research to consolidate, extend and develop new theory. These 
results were obtained using a similarity index, R, that averages across 
a large and diverse range of 1,053 MTS but—as the behavior of an SPI 
depends on the types of interactions present in a dataset—the resulting 
relationships between SPIs depend on the MTS we chose to include. As 
a simple illustrative example, consider the case that our MTS library 
only contained data generated by lag-1 vector autoregressive models, 
VAR(1). Then the unique behavior of more sophisticated SPIs (such as 
those capturing nonlinear dependence or causal coupling on longer 
time lags) would not be observed, as data containing those types of 
interactions would be absent. Consequently, the variety of behaviors 
exhibited by our library of SPIs would be reduced, and the modular 
structure evident in the dendrogram of Fig. 2b would become far more 
homogeneous. In constructing the MTS data library used in this work, 
we thus aimed to be as even-handed and comprehensive as possible 
in sampling from diverse systems, which has been sufficient to yield a 
meaningful and useful representation of the interdisciplinary literature 
on SPIs. However, as any such finite sample is incomplete and relies on 
subjective decisions in its construction, future work may explore the 
dataset-dependent similarity of SPI pairs in detail to construct more 
nuanced organizations of the literature. This would provide new under-
standing of how different mechanisms (and hence empirical depend-
ency structures) play out in different classes of complex systems. Future 
work may also revisit the simple methodological choices made here, 
including our decisions to: (1) quantify the similarity of a pair of SPIs 
using a single number (R); (2) represent the resulting relationships in 
one dimension (as a dendrogram); and (3) analyze the resulting den-
drogram at a single selected resolution (a 14-module decomposition). 
For example, more complex unsupervised methods, such as overlap-
ping community-detection methods42,43, could reveal interesting new 
relationships between SPIs at different resolution scales.
As different time-varying systems contain different statistical 
relationships between their elements (for example, those that capture 
instantaneous or time-delayed responses, linear or nonlinear interac-
tions, are conditioned on the past, allow for non-constant delays, or 
infer directional coupling), our results demonstrate that a highly com-
parative approach can be used to detect the most informative types of 
SPIs for capturing the relevant types of interactions underlying a given 
dataset. Unlike many machine-learning approaches to MTS classifica-
tion, which can be challenging to interpret33, this approach connects 
scientists to interpretable theory that shapes understanding of the 
most important types of pairwise interactions in a dataset, following 
recent undertakings to unify interdisciplinary literatures on sum-
mary statistics (‘features’) for univariate time series12,44,45 and complex 
networks13. This broad, comprehensive methodological comparison 
stands in contrast to a more conventional approach in which the data 
analyst manually selects a method—a practice that leaves open the pos-
sibility that alternative methods may provide clearer interpretation, 
better performance, or computational efficiencies. The three classifi-
cation case studies analyzed here provide a simple demonstration of 
the procedure, automatically highlighting high-performing SPIs from 
across the literature and providing interpretable understanding of the 
relevant interactions in each dataset. We observed a wide range of per-
formance in all cases, highlighting the importance of careful selection 
of SPIs for a given application. In the EEG state dataset, for example, 
our analysis flagged high-performing SPIs consistent with common 
methodological practice in EEG analysis (thus recapitulating existing 
domain knowledge), and others with surprisingly poor performance, 
as well as flagging novel high-performing SPIs as promising candidates 
for methodological innovation in the field. Future work investigating 
which types of SPIs are best suited to which types of problems will 
yield new insights into the interactions underlying different complex 
systems, and is likely to uncover additional novel applications of SPIs 
to new problems.
Although the ability to compare across the full library of SPIs is 
powerful, it comes at a computational cost, particularly for larger 
MTS datasets in which each MTS is sampled over many time points and 
processes. The high redundancy between many groups of SPIs (Fig. 2), 
together with the preliminary indications from case studies that some 
SPIs may exhibit generally high performance, suggest the potential 
for major efficiency gains by constructing a high-performing and 
minimally redundant reduced set of SPIs. Beyond a simple approach 
of selecting a representative SPI from each of the 14 modules, a more 
systematic approach could compare SPI performance across a wide 
range of representative MTS tasks, for example, following recent work 
reducing a large pool of thousands of interdependent univariate time-
series features to just 22 representatives46. There is also much scope 
for statistical optimization in applying any given set of SPIs to real-
world problems, beyond the simple choices made here. In particular, 
performance could be optimized by tackling the challenges of high-
dimensionality and strong interdependence of SPIs using dimensional-
ity reduction, regularization or feature-selection methods to find small 
but highly explanatory combinations of complementary SPIs tailored 
to a given dataset47. Given the methodological freedoms involved in 
highly comparative time-series analysis, pre-registration should be 
considered for transparency and to avoid bias48 (for example, ref. 49).
Beyond the applications to MTS classification presented here, 
the ability to represent the coupling structure in a MTS using a large 
and diverse set of pairwise interactions could form the foundation for 
tackling myriad statistical inference problems, including regression, 
clustering, anomaly detection, and causal network inference. For exam-
ple, current methods for inferring networks of causal interactions from 
MTS data50,51 range from heuristic approaches based on thresholding 
a set of pairwise dependencies defined by a given SPI through to full 
statistical inference50,52–54. Rather than manually selecting an SPI for this 
purpose, the ability to compare diverse SPIs provides the flexibility to 

Nature Computational Science | Volume 3 | October 2023 | 883–893
890
Article
https://doi.org/10.1038/s43588-023-00519-x
capture different types of underlying interactions that could form the 
basis of improved network-inference algorithms. Such an extension 
may also go beyond point estimates of pairwise dependence strengths 
(considered here) towards assessing statistical significance through 
comparison to an appropriate null model9,51,55. Future work could also 
explore comprehensive statistical representations of MTS using more 
diverse properties than just the set of pairwise interactions, by also 
incorporating properties of univariate dynamics of individual system 
components45, system-level structure in the full set of pairwise inter-
actions represented as a network13 and higher-order interactions56.
The flexible and extendable software accompanying this work, 
pyspi57 (see ‘Code Availability’ section), facilitates the application of 
our highly comparative approach to quantifying pairwise interactions 
to myriad applications. Through careful framing of systems-level 
inference55, it has the potential to highlight unexpected and powerful 
methodological approaches to quantifying interaction patterns in 
time-varying systems. The data library of over 1,000 MTS provided 
with this work58 (see ‘Data Availability’ section) is another resource that 
will allow researchers to characterize the behavior of their computa-
tional methods on a comprehensive range of real-world and simulated 
systems, addressing issues associated with only testing new complex 
systems methods on idealized datasets55. In summary, this work demon-
strates the utility of an empirical approach to unifying diverse complex 
dynamical systems and their methods of analysis, providing insights 
and tools for scientific discovery.
Methods
Comprehensive scientific libraries of methods and data
Library of 237 SPIs. This work takes an empirical approach to under-
standing the relationships between diverse scientific methods for 
quantifying pairwise interactions between time series, formulated as 
an SPI. The first step in this approach was to construct a comprehen-
sive, annotated library of SPIs. Here we introduce a library of 237 SPIs, 
organized into six broad categories based on their underlying theory: 
‘basic’ (such as co-variance, Kendall’s τ (ref. 59) and cross-correlation); 
‘distance similarity’ (for example, distance correlations29, kernel-based 
independence tests30,32 and dynamic time warping10); ‘causal indices’ 
(including additive noise models and convergent cross-mapping3); 
‘information theory’ (such as Granger causality11,25 (note that Granger 
causality is included in the information theory category as it is equiva-
lent to transfer entropy evaluated with a Gaussian estimator25), trans-
fer entropy20 and integrated information16); ‘spectral’ (derived from 
Fourier or wavelet transformations, for example, coherence mag-
nitude, phase-locking value27 and spectral Granger causality60); and 
‘miscellaneous’ (for example, co-integration5 and model fits). A full 
list of SPIs, along with descriptions and references, is presented in 
Supplementary Note 1.
Library of 1,053 MTS. To understand how each SPI behaves on different 
types of multivariate time-series data, we constructed a library of 1,053 
diverse model-generated and real-world MTS. Our aim in assembling 
these data was to capture the main classes of systems and dynamics 
that are studied across scientific disciplines, including synchroniza-
tion, spatiotemporal chaos, wave propagation, criticality and phase 
transitions. Our library contains 505 synthetic MTS generated from 
mathematical models, including: uncorrelated and correlated noise 
(for example, Cauchy and normally distributed noise and Brownian 
motion); coupled maps (such as vector autoregression6 and coupled 
map lattices61); coupled ordinary differential equations (including 
Kuramoto oscillators62, Hodgkin–Huxley and Wilson–Cowan net-
works); and partial differential equations (namely, wave equations, 
in which processes are embedded in physical space). It also contains 
548 diverse real-world MTS from public databases across: geophys-
ics (such as earthquake seismograms and atmospheric processes); 
medicine (for example, heartbeat sonograms, fMRI data and EEGs); 
physiology (including accelerometer and gyroscope readings for 
sports and basic motions); and finance (for instance, exchange rates 
and stock prices), among others. Each MTS comprises between 5 and 40 
processes, and between 100 and 2,000 observations—characteristics 
that were designed to match many real-world datasets. Across all MTS 
in our library, we have a total of 195,112 pairwise interactions that we 
used to evaluate the SPIs. Descriptions of the full set of MTS analyzed 
here are presented in Supplementary Note 2.
Quantifying similarity between SPIs using the empirical 
similarity index
Our main aim in this work was to assess the similarity of behavior of 
any two SPIs across a diverse range of MTS. In this section we describe 
the empirical similarity index, R, used to capture the similarity between 
the behavior of all pairs of SPIs across our diverse library of 1,053 MTS. 
This index measures the monotonic relationship between a pair of SPIs 
across a large number of datasets that have different numbers of pro-
cesses (and thus a different number of pairwise interactions). For an 
M-variate time series, z = (z1, …, zM), we first consider the M × M matrix 
of pairwise interactions (MPI), constructed by evaluating a given SPI 
for all pairs of M processes within the MTS. The scalar values of the MPI, 
S = (sij) ∈ℝM×M, where the (i, j) entries of the matrix, sij = s(zi, zj), denotes 
an SPI evaluated on the ith and the jth time series, zi and zj, respectively. 
In general, undirected statistics (for which sij = sji, such as Kendall’s τ) 
yield symmetric MPIs, whereas directed statistics (such as transfer 
entropy, which have sij ≠ sji) yield asymmetric MPIs. Furthermore, some 
SPIs are signed (for example, correlation coefficients are within  
[−1, 1]), whereas others are unsigned (for example, the distance correla-
tion is within [0, 1]). To compare all methods appropriately, we con-
verted signed SPIs to their absolute value, such that all statistics increase 
with the strength of dependency between zi and zj (for example, we 
analyze the magnitude of the covariance rather than its sign). Some 
example MPIs are shown in Supplementary Fig. 1a. Having computed 
MPIs for all SPIs on all 1,053 MTS, we computed the empirical similarity 
index between each pair of SPIs via a two-step process (depicted in 
Supplementary Fig. 1b). First, we defined the similarity of a pair of SPIs, 
k and l, on a given dataset, d. We did this by computing MPIs for k and l 
(yielding Skd and Sld, respectively) and then computing the absolute 
value of the Spearman’s rank correlation coefficient between each of 
their (off-diagonal) entries, |rd|. The resulting correlation value, |rd|, thus 
captures the strength of a monotonic relationship between the output 
of the two SPIs on the dataset d. After repeating this computation for 
all MTS in our library, we calculated the empirical similarity index, R, as 
the average of |rd| across all datasets. Although R provides a useful scalar 
summary of the similarity between a pair of SPIs, it is important to note 
that some pairs of SPIs have quite a wide distribution of scores, |rd|, 
across datasets, indicating that they yield highly correlated outputs on 
some MTS (high |rd|) but not on others (low |rd|). See Supplementary 
Note 3.1 for more details, including a detailed visual breakdown of |rd| 
distributions for some selected pairs of SPIs. We found a wide range of 
similarity indices across pairs of SPIs, from R ≈ 0 to R ≈ 1, illustrated by 
the cumulative distribution function in Supplementary Fig. 1c.
Classification case studies
Datasets. Smartwatch activity dataset. The smartwatch activity dataset 
is derived from the BasicMotions problem in the University of East Anglia  
(UEA) MTS classification repository34. Each MTS includes six sensors—
a three-axis accelerometer and a three-axis gyroscope—recorded for 
10 s at 10 Hz, yielding 1,000 time points. There are 20 MTS in each of 
the four classes (resting, walking, running or playing badminton) for 
a total of 80 MTS in the dataset. This dataset was recently analyzed in a 
large MTS classification challenge33 in which the data was split 50%–50% 
into training and test subsets with 30 stratified repeats. The baseline 
classifier (based on dynamic time warping) achieved 95.25% accuracy; 
the best algorithm (HIVE–COTE) achieved 100% accuracy33.

Nature Computational Science | Volume 3 | October 2023 | 883–893
891
Article
https://doi.org/10.1038/s43588-023-00519-x
EEG state dataset. The EEG state dataset corresponds to the  
SelfRegulationSCP1 problem in the UEA MTS classification repository34  
and was originally published in work by Birbaumer and colleagues35. 
Electrical activity was measured from six EEG channels in one par-
ticipant as they were instructed to move a cursor up or down on a 
computer screen by generating negative or positive slow cortical poten-
tials, respectively. The physical placement of these EEG electrodes 
is depicted in Fig. 3d. Cortical activity (measured in microvolts) was 
recorded for 3.5 s at 256 Hz, yielding 896 time points in each channel 
per MTS, with 282 negativity trials and 279 positivity trials. This data-
set was analyzed in work by Ruiz et al.33, assessing accuracy using 30 
stratified train–test splits of 268 training and 293 test samples. In the 
original comparison, the baseline DTW algorithm achieved an accuracy 
of 81.81% and the best algorithm (TapNet) achieved 95.68% (ref. 33).
fMRI film dataset. The fMRI film dataset is derived from a functional 
connectome fingerprinting study examining individual signatures of 
cortical activity in N = 29 individuals at rest or while watching a film36. 
In this dataset, blood-oxygen-level-dependent signals were recorded 
in 114 parcellated cortical regions with a repetition time of 813 ms  
(a sampling rate of 1.23 Hz) for either 1,200 frames (resting), or between 
952 and 1,000 frames (film-watching). Each trial type (rest versus film-
watching) was repeated four times per participant. Here we analyzed 
pre-processed data obtained from work by Betzel and co-workers63. 
For consistency and simplicity, we examined the first rest and first 
film-watching session per participant; across all participants and trials, 
only the first 947 frames contain real data, and thus we restricted our 
analysis to this time range. To retain a comparable number of processes 
as the first two classification case studies, we averaged blood-oxygen-
level-dependent signals from the 114 original brain regions into the 
seven functional networks from Yeo et al.64, as depicted in Fig. 3g. We 
compared the performance of the Pearson correlation coefficient, used 
to construct functional connectivity matrices in the original publica-
tion (ref. 36) to our library of SPIs.
Classification. For all three case studies, our simple approach to SPI-
based classification involved computing the MPIs (6 × 6 for the smart-
watch activity and EEG state datasets, and 7 × 7 for the fMRI film dataset) 
for each z-scored MTS and repeating for each SPI. We then used the 
elements of these matrices as features for a linear SVM classifier. Note 
that we used the most recent version of pyspi (v.0.4.0) to compute 
SPIs for the classification case studies, which included some improved 
implementations of some SPIs. Features were extracted from each 
MPI differently for directed and undirected SPIs (see Supplementary  
Data 1): we used the upper triangular entries as features for undirected 
SPIs (for which the corresponding MPI is symmetric), whereas we used 
all non-diagonal elements as features for directed SPIs. As a preproc-
essing step, for each case study, we removed any SPI that had invalid 
entries (due to numerical issues) in any of the MPIs, or gave constant 
results across all MTS (see Supplementary Data 3 for a list of omitted 
SPIs). This yielded a set of 228 SPIs for the smartwatch activity prob-
lem, 219 SPIs for the EEG state problem and 227 SPIs for the fMRI film 
problem. For the analysis involving combining all SPIs into a single 
classifier, this yielded a total of 4,755 features for the smartwatch activ-
ity dataset, 4,659 features for the EEG state dataset and 6,743 features 
for the fMRI film dataset.
The linear SVM was implemented using default settings from 
Python’s scikit-learn65 as part of a classification pipeline that involved 
z-score feature normalization (fitted on training data and applied 
to unseen test data). The very simple methodological choices made 
here allowed us to focus on demonstrating the key conceptual types 
of analyses made possible by drawing on a diverse set of SPIs, aiding 
transparency while acknowledging that more complicated statistical 
methodologies are likely to improve the classification performance 
quoted here. We implemented 30 class-stratified train–test splits for 
cross-validation with the same proportions implemented in ref. 33 
using the StratifiedShuffleSplit function for the smartwatch activity 
and EEG state datasets. As there are N = 29 individuals in the fMRI film 
dataset, we implemented leave-one-individual-out cross-validation, 
such that each classifier was trained with the rest and film scans of 
N = 28 participants, and tested on the rest and film fMRI scans of the 
left-out participant.
We measured classification performance using total accuracy for 
all three case studies. Statistical significance was estimated using a per-
mutation testing approach whereby 100 null models were fitted (using 
randomly shuffled class labels) and evaluated using the same cross-
validation classification procedure described above. The observed clas-
sification performance for each SPI was then compared with the pooled 
null distribution of all SPIs, yielding P-values that were then adjusted for 
multiple comparisons by controlling the family-wise error at 0.05 using 
the method of Bonferroni66. The performance metric for the union of all 
SPIs was similarly compared with its corresponding null permutation 
distribution to yield a single P-value per classification problem.
Reporting summary
Further information on research design is available in the Nature  
Portfolio Reporting Summary linked to this article.
Data availability
The full database of 1,053 diverse real-world and simulated MTS 
analyzed here is available on the Zenodo repository at: https://doi.
org/10.5281/zenodo.7118947 (ref. 58). This resource could be used to 
test scientific methods on a diverse sample of MTS. Time-series data 
used in the three case studies are from open sources, as described in 
the ‘Classification case studies’ section in the Methods. Source data 
are provided with this paper.
Code availability
Accompanying this paper is an extendable Python-based package 
called pyspi57, which includes implementations of all 237 SPIs. This 
software allows users to compare the behavior of an interdisciplinary 
literature on methods for quantifying interactions between pairs of 
time series. Furthermore, code and instructions for reproducing the 
results and figures presented in this work can be found on the Zenodo 
repository at: https://doi.org/10.5281/zenodo.8027702 (ref. 67).
References
1.	
Bassett, D. S. & Sporns, O. Network neuroscience. Nat. Neurosci. 
20, 353–364 (2017).
2.	
Buckner, R. L. et al. Molecular, structural, and functional 
characterization of Alzheimer’s disease: evidence for a 
relationship between default activity, amyloid, and memory.  
J. Neurosci. 25, 7709 (2005).
3.	
Sugihara, G. et al. Detecting causality in complex ecosystems. 
Science 338, 496–500 (2012).
4.	
Runge, J. et al. Inferring causation from time series in Earth system 
sciences. Nat. Commun. 10, 2553 (2019).
5.	
Engle, R. F. & Granger, C. W. Co-integration and error correction: 
representation, estimation, and testing. Econometrica 55, 251–276 
(1987).
6.	
Reinsel, G. C. Elements of Multivariate Time Series Analysis 
(Springer, 2003).
7.	
Stephens, Z. D. PLoS Biol. 13, e1002195 (2015).
8.	
van den Heuvel, M. P. & Hulshoff Pol, H. E. Exploring the brain 
network: a review on resting-state fMRI functional connectivity. 
Eur. Neuropsychopharmacol. 20, 519 (2010).
9.	
Cliff, O. M., Novelli, L., Fulcher, B. D., Shine, J. M. & Lizier, J. T. 
Assessing the significance of directed and multivariate measures 
of linear dependence between time series. Phys. Rev. Res. 3, 
013145 (2021).

Nature Computational Science | Volume 3 | October 2023 | 883–893
892
Article
https://doi.org/10.1038/s43588-023-00519-x
10.	 Sakoe, H. & Chiba, S. Dynamic programming algorithm 
optimization for spoken word recognition. IEEE Trans. Signal 
Process 26, 43 (1978).
11.	
Granger, C. W. Investigating causal relations by econometric 
models and cross-spectral methods. Econometrica 37, 424 
(1969).
12.	 Fulcher, B. D., Little, M. A. & Jones, N. S. Highly comparative time-
series analysis: the empirical structure of time series and their 
methods. J. R. Soc. Interface 10, 20130048 (2013).
13.	 Peach, R. L. et al. HCGA: Highly comparative graph analysis for 
network phenotyping. Patterns 2, 100227 (2021).
14.	 Massey, J. Causality, feedback and directed information. 
In International Symposium on Information Theory and its 
Applications (ISITA-90) 303–305 (IEEE, 1990).
15.	 Tononi, G. An information integration theory of consciousness. 
BMC Neurosci. 5, 42 (2004).
16.	 Oizumi, M., Amari, S.-i, Yanagawa, T., Fujii, N. & Tsuchiya, N. 
Measuring integrated information from the decoding perspective. 
PLoS Comput. Biol. 12, e1004654 (2016).
17.	 Wiener, N. in Modern Mathematics for Engineers (ed. Beckenback, E.) 
(McGraw-Hill, 1956).
18.	 Pesaran, M. H. & Shin, Y. An autoregressive distributed lag 
modelling approach to cointegration analysis. In Econometrics and 
Economic Theory in the 20th Century: The Ragnar Frisch Centennial 
Symposium (ed. Strøm, S.) (Cambridge Univ. Press, 1999).
19.	 Nolte, G. et al. Robustly estimating the flow direction of 
information in complex physical systems. Phys. Rev. Lett. 100, 
234101 (2008).
20.	 Schreiber, T. Measuring information transfer. Phys. Rev. Lett. 85, 
461 (2000).
21.	 Bastos, A. M. & Schoffelen, J.-M. A tutorial review of functional 
connectivity analysis methods and their interpretational pitfalls. Front. 
Syst. Neurosci. https://doi.org/10.3389/fnsys.2015.00175 (2016).
22.	 Oizumi, M., Tsuchiya, N. & Amari, S.-I. Unified framework for 
information integration based on information geometry. Proc. Natl 
Acad. Sci. USA 113, 14817 (2016).
23.	 Ay, N. Information geometry on complexity and stochastic 
interaction. Entropy 17, 2432 (2015).
24.	 Geweke, J. Measurement of linear dependence and feedback 
between multiple time series. J. Am. Stat Assoc. 77, 304 (1982).
25.	 Barnett, L., Barrett, A. B. & Seth, A. K. Granger causality and 
transfer entropy are equivalent for Gaussian variables. Phys. Rev. 
Lett. 103, 238701 (2009).
26.	 Cliff, O. M., Prokopenko, M. & Fitch, R. Minimising the  
Kullback–Leibler divergence for model selection in distributed 
nonlinear systems. Entropy 20, 51 (2018).
27.	 Lachaux, J.-P., Rodriguez, E., Martinerie, J. & Varela, F. J. Measuring 
phase synchrony in brain signals. Hum Brain Mapp 8, 194–208 (1999).
28.	 MacKay, D. J. in Information Theory, Inference and Learning 
Algorithms (Cambridge Univ. Press, 2003).
29.	 Shen, C., Priebe, C. E. & Vogelstein, J. T. From distance correlation 
to multiscale graph correlation. J. Am. Stat Assoc. 115, 280 (2020).
30.	 Gretton, A. et al. A kernel statistical test of independence. In 
Advances in Neural Information Processing Systems (eds Roweis, 
S. et al.) Vol. 20 (Curran Associates, 2008).
31.	 Sejdinovic, D., Sriperumbudur, B., Gretton, A. & Fukumizu, K. 
Equivalence of distance-based and RKHS-based statistics in 
hypothesis testing. Annals Stat. 41, 2263–2291 (2013).
32.	 Heller, R., Heller, Y. & Gorfine, M. A consistent multivariate test of 
association based on ranks of distances. Biometrika 100, 503–510 
(2013).
33.	 Ruiz, A. P., Flynn, M., Large, J., Middlehurst, M. & Bagnall, A. The 
great multivariate time series classification bake off: a review and 
experimental evaluation of recent algorithmic advances. Data 
Min. Knowl. Discov. 35, 401–449 (2021).
34.	 Bagnall, A. et al. The UEA multivariate time series classification 
archive. Preprint at https://arxiv.org/abs/1811.00075 (2018).
35.	 Birbaumer, N. et al. A spelling device for the paralysed. Nature 
398, 297–298 (1999).
36.	 Byrge, L. & Kennedy, D. P. Accurate prediction of individual 
subject identity and task, but not autism diagnosis, from 
functional connectomes. Hum. Brain Mapp. 41, 2249 (2020).
37.	 Liu, Y. & Aviyente, S. Quantification of effective connectivity in 
the brain using a measure of directed information. Comput. Math 
Methods Med. 2012, 635103 (2012).
38.	 Mehta, K. & Kliewer, J. Directional and causal information flow in 
EEG for assessing perceived audio quality. IEEE Trans. Mol. Biol. 
Multiscale Commun. 3, 150–165 (2017).
39.	 Wang, G. & Takigawa, M. Directed coherence as a measure of 
interhemispheric correlation of EEG. Int J. Psychophysiol. 13, 
119–128 (1992).
40.	 Schelter, B. et al. Testing for directed influences among neural 
signals using partial directed coherence. J. Neurosci. Methods 
152, 210–219 (2006).
41.	 Smith, S. M. et al. Network modelling methods for FMRI. 
NeuroImage 54, 875–891 (2011).
42.	 Evans, T. & Lambiotte, R. Line graphs, link partitions, and 
overlapping communities. Phys. Rev. E 80, 016105 (2009).
43.	 Ahn, Y.-Y., Bagrow, J. P. & Lehmann, S. Link communities reveal 
multiscale complexity in networks. Nature 466, 761–764 (2010).
44.	 Fulcher, B. D. Feature-based time-series analysis. In Feature 
Engineering for Machine Learning and Data Analytics 87–116 (CRC, 
2018).
45.	 Fulcher, B. D. & Jones, N. S. hctsa: a computational framework 
for automated time-series phenotyping using massive feature 
extraction. Cell Syst. 5, 527–531.e3 (2017).
46.	 Lubba, C. H. et al. catch22: CAnonical Time-series CHaracteristics. 
Data Min. Knowl. Discov. 33, 1821–1852 (2019).
47.	 Phinyomark, A. et al. Navigating features: A topologically 
informed chart of electromyographic features space. J. R. Soc. 14, 
20170734 (2017).
48.	 Nosek, B. A., Ebersole, C. R., DeHaven, A. C. & Mellor, D. T. The 
preregistration revolution. Proc. Natl Acad. Sci. USA 115, 2600 
(2018).
49.	 Leung, A. et al. Towards blinded classification of loss of 
consciousness: distinguishing wakefulness from general anesthesia 
and sleep in flies using a massive library of univariate time series 
analyses. Preprint at https://psyarxiv.com/rmsv8/ (2023).
50.	 Peixoto, T. P. Network reconstruction and community detection 
from dynamics. Phys. Rev. Lett. 123, 128301 (2019).
51.	 Banerjee, A., Chandra, S. & Ott, E. Network inference from short, 
noisy, low time-resolution, partial measurements: application to 
C. elegans neuronal calcium dynamics. Proc Natl Acad. Sci. USA 
120, e2216030120 (2023).
52.	 Hoffmann, T., Peel, L., Lambiotte, R. & Jones, N. S. Community 
detection in networks without observing edges. Sci Adv 6, 
eaav1478 (2020).
53.	 McCabe, S. et al. Netrd: A library for network reconstruction and 
graph distances. J. Open Source Softw. 6, 2990 (2021).
54.	 Wollstadt, P. et al. IDTxl: The Information Dynamics Toolkit 
xl: a Python package for the efficient analysis of multivariate 
information dynamics in networks. J. Open Source Softw. 4, 1081 
(2019).
55.	 Peel, L., Peixoto, T. P. & De Domenico, M. Statistical inference 
links data and theory in network science. Nat. Commun. 13, 6794 
(2022).
56.	 Battiston, F. et al. The physics of higher-order interactions in 
complex systems. Nat. Phys. 17, 1093–1098 (2021).
57.	 Cliff, O. M. DynamicsAndNeuralSystems/pyspi (Zenodo, 2023); 
https://doi.org/10.5281/zenodo.8223340

Nature Computational Science | Volume 3 | October 2023 | 883–893
893
Article
https://doi.org/10.1038/s43588-023-00519-x
58.	 Cliff, O. M. Library of Multivariate Time Series (Zenodo, 2022); 
https://doi.org/10.5281/zenodo.7118947
59.	 Kendall, M. G. A new measure of rank correlation. Biometrika 30, 
81 (1938).
60.	 Dhamala, M., Rangarajan, G. & Ding, M. Estimating Granger 
causality from Fourier and wavelet transforms of time series data. 
Phys. Rev. Lett. 100, 018701 (2008).
61.	 Kaneko, K. & Tsuda, I. Complex systems: Chaos and Beyond 
(Springer, 2011).
62.	 Strogatz, S. H. From Kuramoto to Crawford: exploring the onset of 
synchronization in populations of coupled oscillators. Physica D 
143, 1–20 (2000).
63.	 Betzel, R., Kennedy, D. & Byrge, L. Resting-State and Movie-
Watching Data (Figshare, 2020); https://doi.org/10.6084/
m9.figshare.12971162.v2
64.	 Yeo, B. T. et al. The organization of the human cerebral cortex 
estimated by intrinsic functional connectivity. J. Neurophysiol. 
106, 1125–1165 (2011).
65.	 Pedregosa, F. et al. Scikit-learn: machine learning in Python.  
J. Mach. Learn. Res. 12, 2825 (2011).
66.	 Bonferroni, C. Teoria Statistica Delle Classi e Calcolo Delle 
Probabilita Vol. 8, 3 (Seeber, 1936).
67.	 Bryant, A. G. DynamicsAndNeuralSystems/pyspi_paper_
classification: Documentation ft. readme and code comments 
(Zenodo, 2023); https://doi.org/10.5281/zenodo.8027702
Acknowledgements
O.M.C., N.T. and B.D.F. were supported by NHMRC Ideas Grant 1183280. 
N.T. was supported by by Japan Society for the Promotion of Science, 
Grant-in-Aid for Transformative Research Areas (20H05710, 23H04830, 
23H04829). A.G.B. was supported by an Australian Government 
Research Training Program Scholarship, an American Australian 
Association Graduate Education Fund Scholarship, and the University 
of Sydney Physics Foundation. The funders had no role in study design, 
data collection and analysis, decision to publish or preparation of the 
paper. High-performance computing facilities provided by the School 
of Physics, the University of Sydney contributed to our results.
Author contributions
N.T. and B.D.F. conceived of the project. O.M.C. developed the software 
and large data repositories and performed the main analysis. A.G.B. 
performed the classification case study analyses. B.D.F. supervised the 
project with input from J.T.L. and N.T. O.M.C. and B.D.F. wrote the paper, 
with input from all other co-authors.
Competing interests
The authors declare no competing interests.
Additional information
Supplementary information The online version contains 
supplementary material available at  
https://doi.org/10.1038/s43588-023-00519-x.
Correspondence and requests for materials should be addressed to 
Ben D. Fulcher.
Peer review information Nature Computational Science thanks the 
anonymous reviewers for their contribution to the peer review of this 
work. Primary Handling Editor: Jie Pan, in collaboration with the Nature 
Computational Science team. Peer reviewer reports are available.
Reprints and permissions information is available at  
www.nature.com/reprints.
Publisher’s note Springer Nature remains neutral with regard to 
jurisdictional claims in published maps and institutional affiliations.
Springer Nature or its licensor (e.g. a society or other partner) holds 
exclusive rights to this article under a publishing agreement with 
the author(s) or other rightsholder(s); author self-archiving of the 
accepted manuscript version of this article is solely governed by the 
terms of such publishing agreement and applicable law.
© The Author(s), under exclusive licence to Springer Nature America, 
Inc. 2023









