GraphCast: Learning skillful medium-range
global weather forecasting
Remi Lam*,1, Alvaro Sanchez-Gonzalez*,1, Matthew Willson*,1, Peter Wirnsberger*,1, Meire Fortunato*,1,
Alexander Pritzel*,1, Suman Ravuri1, Timo Ewalds1, Ferran Alet1, Zach Eaton-Rosen1, Weihua Hu1,
Alexander Merose2, Stephan Hoyer2, George Holland1, Jacklynn Stott1, Oriol Vinyals1, Shakir Mohamed1
and Peter Battaglia1
*equal contribution, 1DeepMind, 2Google
We introduce a machine-learning (ML)-based weather simulatorâ€”called â€œGraphCastâ€â€”which outper-
forms the most accurate deterministic operational medium-range weather forecasting system in the
world, as well as all previous ML baselines. GraphCast is an autoregressive model, based on graph
neural networks and a novel high-resolution multi-scale mesh representation, which we trained on his-
torical weather data from the European Centre for Medium-Range Weather Forecasts (ECMWF)â€™s ERA5
reanalysis archive. It can make 10-day forecasts, at 6-hour time intervals, of ï¬ve surface variables and
six atmospheric variables, each at 37 vertical pressure levels, on a 0.25Â° latitude-longitude grid, which
corresponds to roughly 25Ã—25 kilometer resolution at the equator. Our results show GraphCast is more
accurate than ECMWFâ€™s deterministic operational forecasting system, HRES, on 90.0% of the 2760 vari-
able and lead time combinations we evaluated. GraphCast also outperforms the most accurate previous
ML-based weather forecasting model on 99.2% of the 252 targets it reported. GraphCast can generate
a 10-day forecast (35 gigabytes of data) in under 60 seconds on Cloud TPU v4 hardware. Unlike tradi-
tional forecasting methods, ML-based forecasting scales well with data: by training on bigger, higher
quality, and more recent data, the skill of the forecasts can improve. Together these results represent
a key step forward in complementing and improving weather modeling with ML, open new opportuni-
ties for fast, accurate forecasting, and help realize the promise of ML-based simulation in the physical
sciences.
Keywords: Weather forecasting, ECMWF, ERA5, HRES, learning simulation, graph neural networks
1. Introduction
Every day, people factor in the upcoming weather when they plan what they do, from deciding which
jacket to wear, to deciding whether to ï¬‚ee a hurricane. When these decisions involve anticipating
the weather over the next ten days, people rely on â€œmedium-rangeâ€ weather forecasts, which are
provided up to four times a day by weather bureaus, such as the European Centre for Medium-Range
Weather Forecasts (ECMWF), the USâ€™s National Oceanic and Atmospheric Administration, and the UK
Met Oï¬ƒce. Here we show that weather forecasting based on machine learning (ML) can rival the
approaches these bureaus have traditionally used.
Medium-range weather forecasts are generated by simulations run on large high-performance
computing (HPC) clusters, and involve two main components. The ï¬rst component is â€œdata assimila-
tionâ€, which is the process of inferring and tracking the weather, based on recent and past observations
from satellites, weather stations, ships, etc. The resulting output of data assimilation is an estimate
of the most recent sequence of weather states, termed â€œanalysisâ€. The second is a forecast model,
traditionally based on â€œnumerical weather predictionâ€ (NWP), which predicts the future temporal
evolution of variables that represent the state of the weather. These two components are closely
Corresponding author(s): remilam@deepmind.com, alvarosg@deepmind.com, matthjw@deepmind.com, peterbattaglia@deepmind.com
Â© 2022 DeepMind. All rights reserved
arXiv:2212.12794v1  [cs.LG]  24 Dec 2022

GraphCast: Learning skillful medium-range global weather forecasting
Figure 1 | Model schematic. (a) The input weather state(s) are deï¬ned on a high-resolution latitude-longitude-
pressure-levels grid. In the closeup pop-out window, the yellow layers represent surface variables, and the
blue layers represent atmospheric variables. Notice that the atmospheric variablesâ€™ colors repeat several times,
which signiï¬es that they are represented at multiple pressure levels extending upwards. At each grid point,
GraphCast (GC) models 5 surface variables, plus 6 atmospheric variables at each of 37 pressure levels, for 227
variables total. The 0.25Â° latitude-longitude grid has 1, 038, 240 = 721 Ã— 1440 = (180/0.25 + 1) Ã— (360/0.25)
values, so in total the state representation contains 235, 680, 480 values. (b) GraphCast predicts the next state
of the weather as the latitude-longitude-pressure-levels grid. (c) A forecast is made by iteratively applying
GraphCast to each previous predicted state, to produce a sequence of states which represent the weather
as successive lead times. (d) The Encoder component of the GraphCast architecture maps local regions of
the input (green boxes) into nodes of the multi-mesh graph representation (green, upward arrows which
terminate in the green-blue node). (e) The Processor component updates each multi-mesh node using learned
message-passing (heavy blue arrows that terminate at a node). (f) The Decoder component maps the processed
multi-mesh features (purple nodes) back onto the grid representation (red, downward arrows which terminate
at a red box). (g) The multi-mesh is a set of icosahedral meshes of increasing resolution, from the base mesh
(ğ‘€0, 12 nodes) to the ï¬nest resolution (ğ‘€6, 40, 962 nodes), which has uniform resolution across the globe.
Each node belongs to a particular mesh resolution, and is connected to all neighboring nodes at the same
resolution, as well as higher resolutions. The learned message-passing over the diï¬€erent meshesâ€™ edges happens
simultaneously, so that each node is updated by all of its incoming edges. (Earth texture credit [license:
CC BY 4.0]: https://www.solarsystemscope.com/textures/.)
2

GraphCast: Learning skillful medium-range global weather forecasting
coupled: data assimilation uses an NWP model within its inference and tracking processes, previous
forecasts are used to inform the assimilation estimates, and the most up-to-date analysis is used as
input to the forecast model. This work focuses on improving the second component: forecast models.
The governing equations of Earthâ€™s weather have no known closed-form solution, thus NWP-based
forecasting models approximate them numerically. NWP methods scale well with compute: accuracy
generally increases with increased compute resources, because additional compute can be allocated
to higher-resolution simulations, with more sophisticated parametrization schemes (Bauer et al.,
2015; Benjamin et al., 2019). For decades, there has been tremendous investment in NWP systems,
and some of the largest supercomputers in the world are used to make accurate forecasts of the
weather (Met Oï¬ƒce, 2021).
However, NWPs do not scale well with increasing amounts of available data. Today there are vast
archives of weather and climatological observations, but traditionally there have been few direct
means for these data to improve the quality of forecast models. The primary way that NWP methods
are improved is through highly trained experts manually innovating better models, algorithms, and
approximations, which is a time-consuming and costly process.
By contrast, ML methods generally do scale well with data. Across a wide range of scientiï¬c
domains, ML-based methods can increase in accuracy as greater, higher-quality data becomes available,
often at a much lower computational budget. In weather forecasting, ML systems are beginning
to improve on NWP-based forecasting models, especially in regimes where traditional methods are
relatively poor. Examples include sub-seasonal heat wave prediction (Lopez-Gomez et al., 2022) and
precipitation nowcasting, both with and without NWP information (Espeholt et al., 2022; Ravuri
et al., 2021; Shi et al., 2017; SÃ¸nderby et al., 2020).
In medium-range weather forecasting, however, ML-based methods have only recently begun to be
competitive with traditional NWP. The most accurate medium-range operational forecasting system
in the world, which is based on NWP, is ECMWFâ€™s Integrated Forecasting System (IFS), and is still
regarded as superior to ML-based approaches. The IFS is comprised of two main components: HRES,
a deterministic model that produces a single 10-day forecast, at 0.1Â° latitude-longitude resolution,
several times per day; and ENS, an ensemble model that produces a set of 50 stochastically perturbed
15-day forecasts, at 0.2Â° resolution, several times per day. Among the most widely recognized and
challenging goals in ML-based weather forecasting (Rasp and Thuerey, 2021; Weyn et al., 2019,
2020) is to outperform HRES and ENS, and in the past year there have been a number of exciting
advances on this front. Keisler (2022) introduced a graph neural network (GNN)-based model, and
reported results on 1Â° latitude-longitude resolution and 6-day forecasts, which approached the skill of
HRES on several of variables and pressure levels, even improving over a coarsened resolution HRES
on several variables. Kurth et al. (2022); Pathak et al. (2022) introduced FourCastNet(FCN), based
on Fourier Neural Operators (Guibas et al., 2021; Li et al., 2020), and reported promising results on
0.25Â° latitude-longitude resolution and 7-day forecasts, the ï¬rst to operate at that resolution globally.
Bi et al. (2022) recently introduced Pangu-Weather, based on Vision Transformers (Dosovitskiy et al.,
2020; Vaswani et al., 2017), and reported the most accurate ML-based weather forecasting on 0.25Â°
latitude-longitude resolution and 7-day forecasts, outperforming HRES on many of the nine variables
and pressure levels they presented. While these advances are encouraging, their results are generally
reported on only a select handful of variables, without comprehensive comparison to operational
forecasting systems, which begs the question: How skillful are ML-based weather models? The
purpose of this work is to provide an answer to that question, and provide a powerful framework for
competing with, and potentially rivaling operational systems.
We introduce GraphCast, which uses GNNs in an â€œencode-process-decodeâ€ (Battaglia et al., 2018)
conï¬guration, to autoregressively generate forecast trajectories. The encoder maps two consecutive
3

GraphCast: Learning skillful medium-range global weather forecasting
input frames of the latitude-longitude input grid, with hundreds of variables per grid point, into a
multi-scale internal mesh representation. The processor performs many rounds of message-passing on
this â€œmulti-meshâ€, where the edges can span short or long ranges, and allow eï¬ƒcient communication
without requiring an explicit hierarchy. The decoder maps the multi-mesh representation back to
the latitude-longitude grid as a prediction for the next time step. GraphCast was trained on a corpus
of 39 years of historical weather data, ECMWFâ€™s ERA5 reanalysis dataset (Hersbach et al., 2020),
to make 10-day forecasts at 6-hour time steps, at 0.25Â° latitude-longitude resolution, for 5 surface
variables and 6 atmospheric variables, each on 37 vertical pressure levels, that represent the state
of the weather at a given location and time. The full state at a given time is represented as 235
million numbers, which is almost 900 megabytes at ï¬‚oat32 precision, which posed unique challenges
for implementing and training our model. Our GraphCast architecture is most related to Keisler
(2022)â€™s approach, and follows a long tradition of GNN-based learned simulators (Battaglia et al.,
2016; Cranmer et al., 2020; Fortunato et al., 2022; Kipf et al., 2018; Li et al., 2018, 2019; Mrowca
et al., 2018; Pfaï¬€et al., 2021; Rubanova et al., 2021; Sanchez-Gonzalez et al., 2018, 2019, 2020;
Sun et al., 2019).
Comparing the forecast skill of diï¬€erent models is a challenging problem in its own right due to
the many variables and time horizons these models predict. The way ECMWF improves its NWP-based
HRES model is by assessing the skill of a new candidate version of HRES versus previous releases
using the HRES Scorecard1 (Haiden et al., 2018, 2021). The Scorecard compares two versions against
one another on around 27 surface and atmospheric variables and levels, daily, for 10-day forecasts.
We adopt ECMWFâ€™s approach by introducing an analogous scorecard, for comparing HRESâ€™s skill
with GraphCastâ€™s skill in a comprehensive way over many key variables. We evaluated our modelâ€™s
performance on all variables and levels in the Scorecard (except the ocean wave variables), as well as
most of the WeatherBench (Rasp et al., 2020) variables and levels, giving 69 variables and levels in
total. We used 10-day forecasts, at 6-hour time steps, on 0.25Â° latitude-longitude resolution.
Our primary ï¬ndings are that across these 2760 combinations (69 Ã— 40) of evaluation variables
and levels, and lead times, GraphCast has greater forecasting skill than HRES on 90.0% of them, for
a held out test set from 2018. A key reason GraphCast can exceed HRESâ€™s performance is because
it is trained directly from data, and thus, in principle, can capture weather phenomena, such as air
masses, fronts, storms, etc., at scales which are not represented explicitly within NWP-based systems.
We also ï¬nd that GraphCast has greater forecasting skill than Pangu-Weather on 99.2% of the 252
targets that Bi et al. (2022) reported. Key advances of this work include:
â€¢ A novel multi-mesh GNN architecture for learned weather simulation.
â€¢ An autoregressive model that can be trained to generate forecasts on 0.25Â° latitude-longitude
resolution and 37 levels of vertical resolution, for 40 or more steps.
â€¢ An evaluation protocol with comprehensive coverage of medium-range forecast variables.
â€¢ An ML-based forecasting model with greater skill than the best NWP-based deterministic model.
â€¢ The most accurate ML-based weather forecasting model.
1ECMWF Scorecards: https://sites.ecmwf.int/ifs/scorecards/.
The current operational HRES (Cycle
47r3) is compared to the previous version, Cycle 47r2, here: https://sites.ecmwf.int/ifs/scorecards/
scorecards-47r3HRES.html. The Scorecard uses both analysis and observation for veriï¬cation, i.e., the â€œanâ€ and
â€œobâ€ sections, but here we focus on verifying via analysis, which is available from ECMWF.
4

GraphCast: Learning skillful medium-range global weather forecasting
2. ERA5 dataset
For training and evaluating GraphCast, we built our datasets from a subset of ECMWFâ€™s ERA5 (Hers-
bach et al., 2020)2 reanalysis archive, for the years 1979-2018, at 6 hour time intervals (corresponding
to 00z, 06z, 12z, 18z each day), at 0.25Â° horizontal latitude-longitude resolution, and 37 vertical
atmospheric pressure levels3. â€œReanalysisâ€ means performing data assimilation on historical weather
observations, to estimate the full state of the weather globally over time, and ERA5 is regarded as the
most comprehensive and accurate reanalysis archive in the world.
Our model predicts a total of 227 target variables, which includes 5 surface variables, plus 6
atmospheric variables at each of 37 pressure levels (several other static and/or external variables
were also provided as input context for our modelâ€”see Appendix Table A.1). These variables
are uniquely identiï¬ed by their short name (and the pressure level, for atmospheric variables).
For example, the surface variable â€œ2 metre temperatureâ€ is denoted 2t; the atmospheric variable
â€œGeopotentialâ€ at pressure level 500 hPa is denoted z500. The modeled surface variables were: 2
metre temperature (2t), 10 metre u wind component (10u), 10 metre v wind component (10v),
mean sea level pressure (msl), and total precipitation (tp) (accumulated over the previous 6
hours). The atmospheric variables, which were represented at each of the 37 pressure levels, were:
geopotential (z), speciï¬c humidity (q), temperature (t), u component of wind (u), v component of
wind (v), and vertical velocity (w). The static/external variables include information such as the
geometry of the grid/mesh, orography and radiation at the top of the atmosphere. See Appendix
Table A.1 for more information about the variables, and Appendix A.1 and Appendix A.2.4 for full
details.
As shown in Figure 1a, we represent the weather state at time index, ğ‘¡, as ğ‘‹ğ‘¡. The grid encircling
the Earth corresponds to the variables at every latitude, longitude, and pressure level. The surface and
atmospheric variables are illustrated by the yellow and blue boxes in the magniï¬ed view, respectively.
We refer to the subset of variables in ğ‘‹ğ‘¡that correspond to a particular grid point ğ‘–(1,038,240 in
total) as xğ‘¡
ğ‘–, and to each variable ğ‘—of the 227 target variables as ğ‘¥ğ‘¡
ğ‘–,ğ‘—.
3. GraphCast model
3.1. Generating a forecast
GraphCast takes as input two weather states, (ğ‘‹ğ‘¡, ğ‘‹ğ‘¡âˆ’1), which correspond to the current time, ğ‘¡,
and the immediately preceding time, ğ‘¡âˆ’1, and predicts the weather state at the next time step (as
depicted in Figure 1b),
Ë†ğ‘‹ğ‘¡+1 = GraphCast(ğ‘‹ğ‘¡, ğ‘‹ğ‘¡âˆ’1)
.
(1)
To generate a ğ‘‡-step forecast, Ë†ğ‘‹ğ‘¡+1:ğ‘¡+ğ‘‡= ( Ë†ğ‘‹ğ‘¡+1, . . . , Ë†ğ‘‹ğ‘¡+ğ‘‡), GraphCast iteratively applies Equation (1)
in an autoregressive fashion, feeding its own predictions back in as input to predict later steps (i.e., to
predict step ğ‘¡+ 2, the input is ( Ë†ğ‘‹ğ‘¡+1, ğ‘‹ğ‘¡); to predict step ğ‘¡+ 3, the input is ( Ë†ğ‘‹ğ‘¡+2, Ë†ğ‘‹ğ‘¡+1)). Figure 1b,c
depicts this process, and see Appendix Equation A.5 for details.
2See ERA5 documentation: https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation.
3We follow common practice of using pressure as our vertical coordinate, instead of altitude. A â€œpressure levelâ€ is a ï¬eld
of altitudes with equal pressure. E.g., â€œpressure level 500 hPaâ€ corresponds to the ï¬eld of altitudes for which the pressure is
500 hPa. The relationship between pressure and altitude is determined by the geopotential variable.
5

GraphCast: Learning skillful medium-range global weather forecasting
3.2. Architecture
The core architecture of GraphCast uses GNNs in an â€œencode-process-decodeâ€ conï¬guration (Battaglia
et al., 2018), as depicted in Figure 1d,e,f. GNN-based learned simulators are very eï¬€ective at learning
complex physical dynamics of ï¬‚uids and other materials (Pfaï¬€et al., 2021; Sanchez-Gonzalez et al.,
2020), as the structure of their representations and computations are analogous to learned ï¬nite
element solvers (Alet et al., 2019). A key advantage of GNNs is that the input graphâ€™s structure
determines what parts of the representation interact with one another via learned message-passing,
allowing arbitrary patterns of spatial interactions over any range. By contrast, a convolutional neural
network (CNN) is restricted to computing interactions within local patches (or, in the case of dilated
convolution, over regularly strided longer ranges). And while Transformers (Vaswani et al., 2017)
can also compute arbitrarily long-range computations, they do not scale well with very large inputs
(e.g., the 1 million-plus grid points in GraphCastâ€™s global inputs) because of the quadratic memory
complexity induced by computing all-to-all interactions. Contemporary extensions of Transformers
often sparsify possible interactions to reduce the complexity, which in eï¬€ect makes them analogous
to GNNs (e.g., graph attention networks (VeliÄkoviÄ‡ et al., 2017)).
The way we capitalize on the GNNâ€™s ability to model arbitrary sparse interactions is by introducing
GraphCastâ€™s internal multi-mesh representation, which has homogeneous spatial resolution over
the globe, and allows long-range interactions within few message-passing steps. The multi-mesh
is constructed by ï¬rst dividing a regular icosahedron (12 nodes and 20 faces) iteratively 6 times
to obtain a hierarchy of icosahedral meshes with a total of 40,962 nodes and 81,920 faces on the
highest resolution (see Section 3). We leveraged the fact that the coarse-mesh nodes are subsets of
the ï¬ne-mesh nodes, which allowed us to superimpose edges from all levels of the mesh hierarchy
onto the ï¬nest-resolution mesh. This procedure yields a multi-scale set of meshes, with coarse edges
bridging long distances at multiple scales, and ï¬ne edges capturing local interactions. Figure 1g
shows each individual reï¬ned mesh, and Figure 1e shows the full multi-mesh.
GraphCastâ€™s encoder (Figure 1d) ï¬rst maps the input data, from the original latitude-longitude
grid, into learned features on the multi-mesh, using a GNN with directed edges from the grid points
to the multi-mesh. The processor (Figure 1e) then uses a 16-layer deep GNN to perform learned
message-passing on the multi-mesh, allowing eï¬ƒcient propagation of information across space due to
the long-range edges. The decoder (Figure 1f) then maps the ï¬nal multi-mesh representation back to
the latitude-longitude grid using a GNN with directed edges, and combines this grid representation,
Ë†ğ‘Œğ‘¡+ğ‘˜with the input state, Ë†ğ‘‹ğ‘¡+ğ‘˜, to form the output prediction, Ë†ğ‘‹ğ‘¡+ğ‘˜+1 = Ë†ğ‘‹ğ‘¡+ğ‘˜+ Ë†ğ‘Œğ‘¡+ğ‘˜.
The encoder and decoder do not require the raw data to be arranged in a regular rectilinear
grid, and can also be applied to arbitrary mesh-like state discretizations (Alet et al., 2019). The
general architecture builds on various GNN-based learned simulators which have been successful in
many complex ï¬‚uid systems and other physical domains (Fortunato et al., 2022; Pfaï¬€et al., 2021;
Sanchez-Gonzalez et al., 2020). Keisler (2022) used similar approaches in weather forecasting, with
promising results.
On a single Cloud TPU v4 device4, GraphCast can generate a 0.25Â° resolution, 10-day forecast
(at 6-hour steps) in under 60 seconds. For comparison, ECMWFâ€™s IFS system runs on a 11,664-core
cluster, and generates a 0.1Â° resolution, 10-day forecast (released at 1-hour steps for the ï¬rst 90
hours, 3-hour steps for hours 93-144, and 6-hour steps from 150-240 hours5) in about an hour (Rasp
et al., 2020). For full details of GraphCast, see Appendix A.2.
4Cloud TPU v4 device speciï¬cations: https://cloud.google.com/tpu/docs/system-architecture-tpu-vm.
5See the HRES release details here: https://www.ecmwf.int/en/forecasts/datasets/set-i.
6

GraphCast: Learning skillful medium-range global weather forecasting
3.3. Training procedure
GraphCast was trained to minimize an objective function over 12-step forecasts (3 days) against ERA5
targets, using gradient descent. The objective function was,
LMSE =
1
|ğ·batch|
âˆ‘ï¸
ğ‘‘0âˆˆğ·batch
|              {z              }
forecast date-time
1
ğ‘‡
âˆ‘ï¸
ğœâˆˆ1:ğ‘‡train
|     {z     }
lead time
1
|ğº0.25Â°|
âˆ‘ï¸
ğ‘–âˆˆğº0.25Â°
|           {z           }
spatial location
âˆ‘ï¸
ğ‘—âˆˆğ½
|{z}
variable-level
ğ‘ ğ‘—ğ‘¤ğ‘—ğ‘ğ‘–(Ë†ğ‘¥ğ‘‘0+ğœ
ğ‘–,ğ‘—
âˆ’ğ‘¥ğ‘‘0+ğœ
ğ‘–,ğ‘—
)2
|              {z              }
squared error
(2)
which averages the squared errors over forecast date-times, lead times, spatial locations, variables
and levels, where
â€¢ ğ‘‘0 âˆˆğ·batch represent forecast initialization date-times in a batch of forecasts in the training set,
â€¢ ğœâˆˆ1 : ğ‘‡train are the lead times that correspond to the ğ‘‡train autoregressive steps during training,
â€¢ ğ‘–âˆˆğº0.25Â° are the spatial latitude and longitude coordinates in the grid,
â€¢ ğ‘—âˆˆğ½indexes the variable and level, e.g., ğ½= {z1000, z850, . . . , 2t, msl},
â€¢ Ë†ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
and ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
are predicted and target values for some variable-level, location, and lead time,
â€¢ ğ‘ ğ‘—is the per-variable-level inverse variance of single-timestep diï¬€erences,
â€¢ ğ‘¤ğ‘—is the per-variable-level loss weight,
â€¢ ğ‘ğ‘–is the normalized area of the latitude-longitude grid cell, which varies with latitude.
The quantities ğ‘ ğ‘—= ğ•ğ‘–,ğ‘¡
h
ğ‘¥ğ‘¡+1
ğ‘–,ğ‘—âˆ’ğ‘¥ğ‘¡
ğ‘–,ğ‘—
iâˆ’1
are per-variable-level inverse variance estimates of the time
diï¬€erences. The ğ‘¤ğ‘—are per-variable-level loss weights we speciï¬ed in a simple way, to control
how heavily diï¬€erent target variables are weighed during optimization. The ğ‘ğ‘–weight depends on
latitude, and weights the errors proportionally to the area of their corresponding grid cells. See the
Appendix A.3 for full details of these symbols and indices.
We found that using an autoregressive, multi-step loss is eï¬€ective at making the model minimize
error accumulation over long forecasts, as described in Appendix A.3. The gradient of the objective
with respect to the network weights is computed by backpropagating through the entire autoregressive
prediction sequence in Appendix Equation A.5.
During model development and training, we only used ERA5 data from 1979-2017, while we
reserved the 2018 ERA5 data for testing only. We maintained a strict protocol whereby data from
2018 onward was never observed by our research team or training procedures, until after our ï¬nal
GraphCast was frozen and the evaluation phase began (see Appendix A.1.3). As part of our preliminary
experiments, we trained models up through 2015, validated them on 2016-2017 to select the best one,
re-trained that model up through 2017, and tested on 2018. We also tested the model trained through
2015 on 2018 test data, and found its performance was not as good on 2018 data as the model
re-trained on data through 2017. In other preliminary experiments, we found similar improvements
on test performance for models trained up to an earlier test period (2015), versus those whose training
data did not include years immediately preceding that test period. This may be due to the data being
non-stationary across years (i.e., due to the ENSO cycle, climate change, or other multi-year weather
patterns), or a result of having additional training data. In principle, GraphCast can be retrained (or
ï¬ne-tuned) regularly, on the most recent weather data, to potentially reap these beneï¬ts.
Training GraphCast took about 3 weeks on 32 Cloud TPU v4 devices using batch parallelism. To
reduce the memory footprint, we used sophisticated gradient-checkpoint strategies and low-precision
numerics. To reduce training time, we applied a training schedule that ramped up the number of
autoregressive steps, as detailed in Appendix A.3.
7

GraphCast: Learning skillful medium-range global weather forecasting
Figure 2 | Forecast images and errors for 10u. The plot shows the true and forecasted weather states
for 10u. The columns are 3 lead times, 2, 6, and 10 days, with the dates indicated in the column headers.
Row 1 shows ERA5, row 2 shows HRES, and row 3 shows GraphCast. Rows 4 and 5 are maps of the absolute
value of the error between HRES and HRES-fc0, and GraphCast and ERA5, respectively. The line plot on the
bottom shows the RMSE skill for HRES and GraphCast, as a function of lead time, for that speciï¬c forecast.
The dashed lines show which lead times on the line plot correspond to the forecast images. The forecast
initialization date-time (2018-01-20_00:00) was chosen by selecting the forecast which had median skill
score for GraphCast versus HRES (normalized RMSE diï¬€erence, averaged over lead times), across all forecasts
in the 2018 test set, so that it is a representative example.
8

GraphCast: Learning skillful medium-range global weather forecasting
Figure 3 | Forecast images and errors for msl. The plot shows the true and forecasted weather states for
msl, for forecast initialization date-time 2018-02-11_00:00. See the caption of Figure 2 for details.
9

GraphCast: Learning skillful medium-range global weather forecasting
4. Model evaluation
We quantify the skillfulness6 of GraphCast, other ML models, and HRES using the root mean square
error (RMSE) and the anomaly correlation coeï¬ƒcient (ACC), which are both computed against ground
truth data. The RMSE, L ğ‘—,ğœ
RMSE, measures the magnitude of the diï¬€erences between forecasts and
ground truth (see Appendix Equation A.20). The ACC, L ğ‘—,ğœ
ACC, is deï¬ned in Appendix Equation A.21 and
measures how well the model forecasts diï¬€erences from climatology, i.e., the average weather for a
location and date, correlate with the same quantity computed for the ground truth. For skill scores6 we
use the normalized RMSE diï¬€erence between model ğ´and baseline ğµas (RMSEğ´âˆ’RMSEğµ)/RMSEğµ,
and the normalized ACC diï¬€erence as (ACCğ´âˆ’ACCğµ)/(1 âˆ’ACCğµ).
GraphCast was trained to predict ERA5 data and we therefore report errors that were computed
against ERA5 as ground truth. The HRES model, however, uses HRES analysis as input. We therefore
built a separate dataset, termed â€œHRES-fc0â€, that serves as ground truth for computing HRES errors
(see Appendix A.1.2). This dataset comprises the initial time step of HRES forecasts. In other words,
HRES errors were evaluated by comparing its forecasts to the HRES inputs for future forecasts. In the
ECMWF Scorecard, the skill of HRES forecasts is also measured against HRES analysis. Our overall
aim is to use a fair comparison between models trained on ERA5, versus HRES. See also Appendix A.5.
In the Results, we highlight 10 â€œheadlineâ€ variables chosen from the ECMWF Scorecard:
â€¢ z500, z850: Geopotential, at 500 and 850 hPa, respectively.
â€¢ t500, t850: Temperature, at 500 and 850 hPa, respectively.
â€¢ q700: Speciï¬c humidity, at 700 hPa.
â€¢ u500, v850: u and v components of wind at 500 and 850 hPa, respectively. The error in the
wind components is always highly correlated (e.g., average Pearsonâ€™s ğ‘Ÿ= 0.99981 across levels
for u and v), so we only show one at each level.
â€¢ 2t: 2 metre temperature (surface temperature).
â€¢ 10u: 10 metre vector wind (surface wind). Again, we exclude 10v because it is highly
correlated with 10u (ğ‘Ÿ= 0.99995).
â€¢ msl: Mean sea level pressure.
These variables were selected because they comprise all the variables the Scorecard shows for the
comparison-with-analysis section, which GraphCast models. We chose those pressure levels which
were at or closer to the surface than the 500 hPa level, for each variable.
In our Results below, we also present a scorecard with GraphCastâ€™s performance versus HRES for all
69 variable-level combinations in our evaluation set. The pressure levels we evaluated were the 13 used
in WeatherBench (Rasp et al., 2020): 50, 100, 150, 200, 250, 300, 400, 500, 600, 700, 850, 925, 1000
hPa. The variables we evaluated were those listed above, except vertical velocity (w) and total
precipitation (tp), which are diagnostic variables in ERA5 and HRES (i.e., they are calculated from
other variables, rather than modeled explicitly). This leaves 69 total evaluation variables (4 surface
variables, plus 5 atmospheric variables at 13 pressure levels), at 40 lead times, for a total of 2760.
Figure 2 and Figure 3 show sequences of states from ERA5, an HRES forecast, and a GraphCast
forecast (top three rows). The fourth row shows the absolute value of the diï¬€erence between HRESâ€™s
forecasted state and the HRES-fc0 ground truth. The ï¬fth row shows the absolute value of the
diï¬€erence between GraphCastâ€™s forecasted state and the ERA5 ground truth. The line plot shows the
RMSE between the forecasts and their respective ground truths, with dashed lines indicating the lead
times to which the forecast images correspond. The ï¬gure demonstrates the quality of GraphCastâ€™s
forecasts, and provides intuition for how forecasts are used to compute skill metrics.
6For deï¬nitions of â€œskillâ€ and â€œskill scoreâ€: https://en.wikipedia.org/wiki/Forecast_skill.
10

GraphCast: Learning skillful medium-range global weather forecasting
1 2 3 4 5 6 7 8 9 10
0
200
400
600
800
RMSE
Lower is better
a) Skill (RMSE): z500 (m2/s2)
1 2 3 4 5 6 7 8 9 10
0
200
400
600
b) Skill (RMSE): z850 (m2/s2)
1 2 3 4 5 6 7 8 9 10
1
2
3
c) Skill (RMSE): t500 (K)
1 2 3 4 5 6 7 8 9 10
1
2
3
d) Skill (RMSE): t850 (K)
1 2 3 4 5 6 7 8 9 10
0.3
0.2
0.1
0.0
Normalized RMSE diff.
e) Skill score (RMSE): z500
1 2 3 4 5 6 7 8 9 10
0.4
0.3
0.2
0.1
0.0
f) Skill score (RMSE): z850
1 2 3 4 5 6 7 8 9 10
0.15
0.10
0.05
0.00
g) Skill score (RMSE): t500
1 2 3 4 5 6 7 8 9 10
0.20
0.15
0.10
0.05
0.00
h) Skill score (RMSE): t850
1 2 3 4 5 6 7 8 9 10
0.0000
0.0005
0.0010
0.0015
0.0020
RMSE
i) Skill (RMSE): q700 (kg/kg)
1 2 3 4 5 6 7 8 9 10
2
4
6
8
10
j) Skill (RMSE): u500 (m/s)
1 2 3 4 5 6 7 8 9 10
2
4
6
k) Skill (RMSE): u850 (m/s)
1 2 3 4 5 6 7 8 9 10
2
4
6
8
10
l) Skill (RMSE): v500 (m/s)
1 2 3 4 5 6 7 8 9 10
0.3
0.2
0.1
0.0
Normalized RMSE diff.
m) Skill score (RMSE): q700
1 2 3 4 5 6 7 8 9 10
0.20
0.15
0.10
0.05
0.00
n) Skill score (RMSE): u500
1 2 3 4 5 6 7 8 9 10
0.2
0.1
0.0
o) Skill score (RMSE): u850
1 2 3 4 5 6 7 8 9 10
0.20
0.15
0.10
0.05
0.00
p) Skill score (RMSE): v500
1 2 3 4 5 6 7 8 9 10
2
4
6
RMSE
m) Skill (RMSE): v850 (m/s)
1 2 3 4 5 6 7 8 9 10
1
2
n) Skill (RMSE): 2t (K)
1 2 3 4 5 6 7 8 9 10
1
2
3
4
5
o) Skill (RMSE): 10u (m/s)
1 2 3 4 5 6 7 8 9 10
0
200
400
600
p) Skill (RMSE): msl (Pa)
1 2 3 4 5 6 7 8 9 10
Lead time (days)
0.2
0.1
0.0
Normalized RMSE diff.
q) Skill score (RMSE): v850
1 2 3 4 5 6 7 8 9 10
Lead time (days)
0.0
0.2
0.4
r) Skill score (RMSE): 2t
1 2 3 4 5 6 7 8 9 10
Lead time (days)
0.3
0.2
0.1
0.0
s) Skill score (RMSE): 10u
1 2 3 4 5 6 7 8 9 10
Lead time (days)
0.3
0.2
0.1
0.0
t) Skill score (RMSE): msl
GraphCast - 12 AR
HRES against HRES-fc0
Figure 4 | GraphCastâ€™s RMSE skill versus HRES in 2018 (lower is better). Rows 1 and 3 show absolute RMSE
for GraphCast (blue lines) and HRES (black lines); rows 2 and 4 show normalized RMSE diï¬€erences between
GraphCastâ€™s RMSE and HRESâ€™s. GraphCastâ€™s RMSE is computed against ERA5; HRESâ€™s RMSE is computed
against HRES-fc0 (see Section 4). Each subplot represents a single variable (and pressure level), as indicated
in the subplot titles. The x-axis represents lead time, at 6-hour steps over 10 days. The y-axis represents
(absolute or normalized) RMSE. We did not include 10v because it was highly correlated with 10u. Note,
there are small oscillations visible in the skill of GraphCast, as a function of lead time, which we speculate may
result from reporting metrics only for 00z and 12z initialization times (to be comparable to HRES), and small
diï¬€erences in region-speciï¬c forecast skill that varies over the diurnal cycle (see Appendix Figures A.4 to A.5).
11

GraphCast: Learning skillful medium-range global weather forecasting
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
ACC
Higher is better
a) Skill (ACC): z500
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
b) Skill (ACC): z850
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
c) Skill (ACC): t500
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
d) Skill (ACC): t850
1 2 3 4 5 6 7 8 9 10
0.0
0.2
0.4
Normalized ACC diff.
e) Skill score (ACC): z500
1 2 3 4 5 6 7 8 9 10
0.0
0.2
0.4
0.6
f) Skill score (ACC): z850
1 2 3 4 5 6 7 8 9 10
0.0
0.1
0.2
0.3
g) Skill score (ACC): t500
1 2 3 4 5 6 7 8 9 10
0.0
0.1
0.2
0.3
0.4
h) Skill score (ACC): t850
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
ACC
i) Skill (ACC): q700
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
j) Skill (ACC): u500
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
k) Skill (ACC): u850
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
l) Skill (ACC): v500
1 2 3 4 5 6 7 8 9 10
0.0
0.2
0.4
Normalized ACC diff.
m) Skill score (ACC): q700
1 2 3 4 5 6 7 8 9 10
0.0
0.1
0.2
0.3
n) Skill score (ACC): u500
1 2 3 4 5 6 7 8 9 10
0.0
0.2
0.4
o) Skill score (ACC): u850
1 2 3 4 5 6 7 8 9 10
0.0
0.1
0.2
0.3
p) Skill score (ACC): v500
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
ACC
m) Skill (ACC): v850
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
n) Skill (ACC): 2t
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
o) Skill (ACC): 10u
1 2 3 4 5 6 7 8 9 10
0.00
0.25
0.50
0.75
1.00
p) Skill (ACC): msl
1 2 3 4 5 6 7 8 9 10
Lead time (days)
0.0
0.2
0.4
Normalized ACC diff.
q) Skill score (ACC): v850
1 2 3 4 5 6 7 8 9 10
Lead time (days)
1.0
0.5
0.0
r) Skill score (ACC): 2t
1 2 3 4 5 6 7 8 9 10
Lead time (days)
0.0
0.2
0.4
s) Skill score (ACC): 10u
1 2 3 4 5 6 7 8 9 10
Lead time (days)
0.0
0.2
0.4
0.6
t) Skill score (ACC): msl
GraphCast - 12 AR
HRES against HRES-fc0
Figure 5 | GraphCastâ€™s ACC skill versus HRES in 2018 (higher is better). This plots skill and skill scores for
ACC and normalized ACC diï¬€erences, respectively. See the caption of Figure 4 for all other details.
12

GraphCast: Learning skillful medium-range global weather forecasting
1
2
3
4
5
6
7
8
9
10
Lead time (days)
var
PL
Normalized RMSE difference
50
100
150
200
250
300
400
500
600
700
850
925
1000
50
100
150
200
250
300
400
500
600
700
850
925
1000
50
100
150
200
250
300
400
500
600
700
850
925
1000
50
100
150
200
250
300
400
500
600
700
850
925
1000
50
100
150
200
250
300
400
500
600
700
850
925
1000
 
 
 
 
z
t
u
v
q
2t
10u
10v
msl
1.6
2.0
2.1
4.5 2.6 2.4 2.1 2.0 1.8 1.7 1.6 1.5 1.4 1.4 1.3 1.2 1.2 1.1 1.1
Figure 6 | Scorecard of GraphCastâ€™s skill score versus HRES in 2018. Skill score was measured by normal-
ized RMSE diï¬€erences, where colors are proportional to the value: blue is negative (better), red is positive
(worse). Each cell represents one of the 2760 evaluation variable-level-lead-time combinations. Each row is a
single variable (â€œvarâ€) at a single pressure level (â€œPLâ€). Each column is a single lead time (â€œForecast daysâ€), at
6 hour steps, over 10 days. Normalized RMSE diï¬€erence has a lower bound of -1, but no upper bound, so we
clipped (red) colors above 1, and overlaid the numeric value on those cells which were clipped.
13

GraphCast: Learning skillful medium-range global weather forecasting
5. Results
5.1. Skill of GraphCast versus HRES
Our results show GraphCast comprehensively outperforms HRESâ€™s weather forecasting skill across
10-day forecasts, at 0.25Â° horizontal resolution.
Figure 4 shows how GraphCast (blue lines) clearly outperforms HRES (black lines) for our 10
headline surface and atmospheric variables (see Section 3 for evaluation protocol), chosen from the
ECMWF Scorecard for pressure levels closest to the surface. Each subplot corresponds to a variable
(and pressure level, for atmospheric variables) and skill (y-axis) is plotted at 6-hour steps over 10 day
horizons (x-axis). Rows 1 and 3 show absolute RMSE, and rows 2 and 4 show the corresponding
normalized diï¬€erences in RMSE. From the initial 6-hour step, through all 40 steps over 10 days,
GraphCast almost always has higher skill, and the normalized diï¬€erences are often 30% lower error
than HRES at early lead times, while typically plateauing to around 10âˆ’15% after 10 days. We found
similar results when evaluating ACC, as shown in Figure 5. We also performed a regional analysis,
which indicates that these results are consistent across the entire globe (see Appendix Figure A.3,
Appendix Figure A.4, and Appendix Figure A.5).
Figure 6 summarizes the normalized diï¬€erences (i.e., Figure 4â€™s rows 2 and 4) for all variables
and pressure levels, across the 10 day forecasts, in a format analogous to the ECMWF Scorecard. Each
row represents a single variable (left row label) at a single level (right row label), where each colored
squareâ€™s color is proportional to the normalized diï¬€erence (scaled between -1 and 1), where blue
indicates GraphCast had lower error than HRES (negative normalized diï¬€erence), with -1 (solid blue)
meaning zero error, and red indicates it had higher error (positive normalized diï¬€erences), with 1
(solid red) meaning twice the error. GraphCast outperformed HRES on 90.0% of the 2760 variables,
levels, and lead times in our evaluation set (4 surface variables, plus 5 atmospheric variables Ã— 13
levels, over 10 days with 4 steps per day). We note that HRES tended to have superior performance
than GraphCast on the upper atmospheric levels, especially pressure level 50 hPa, which is not
surprising because the total training loss weight applied to pressure levels at or below 50 hPa was
only 0.66% of the total loss weight across all variables and levels (see Section 3 for details). When
excluding the 50 hPa level, the percentage of the 2240 targets on which GraphCast outperforms
HRES is 96.6%; when excluding levels 50 and 100 hPa, the percentage of the 1720 targets is 99.2%.
Skill score (normalized RMSE diï¬€erence)
Lead time
Mean
Median
1-day
-0.092
-0.15
3-day
-0.13
-0.19
5-day
-0.12
-0.17
Table 1 | Summary of skill score between GraphCast and HRES, for key lead times. The means and
medians (columns) are computed across the normalized RMSE diï¬€erences for our 69 evaluation variable-level
combinations, for lead times of 1, 3, and 5 days (the rows).
Together these results show that GraphCast has substantially greater skill than HRES across the
variables, levels, and lead times we tested. Table 1 shows the mean and median RMSE skill scores
between GraphCast and HRES, averaged over all 69 variables and levels, for the key lead times of
1, 3, and 5 days. For context, the improvement in skill GraphCast provides over HRES appears to
be considerably greater than typical improvements between successive cycles of HRES releases, and
roughly corresponds to the improvements in skill over several years.
14

GraphCast: Learning skillful medium-range global weather forecasting
1 2 3 4 5 6 7 8 9 10
0
200
400
600
800
RMSE
Lower is better
a) Skill (RMSE): z500 (m2/s2)
1 2 3 4 5 6 7 8 9 10
1
2
3
b) Skill (RMSE): t850 (K)
1 2 3 4 5 6 7 8 9 10
0.5
1.0
1.5
2.0
2.5
3.0
c) Skill (RMSE): 2t (K)
1 2 3 4 5 6 7 8 9 10
0
200
400
600
d) Skill (RMSE): msl (Pa)
1 2 3 4 5 6 7 8 9 10
Lead time (days)
0.05
0.00
0.05
0.10
Normalized RMSE diff.
e) Skill score (RMSE): z500
1 2 3 4 5 6 7 8 9 10
Lead time (days)
0.05
0.00
0.05
0.10
0.15
f) Skill score (RMSE): t850
1 2 3 4 5 6 7 8 9 10
Lead time (days)
0.00
0.05
0.10
0.15
0.20
g) Skill score (RMSE): 2t
1 2 3 4 5 6 7 8 9 10
Lead time (days)
0.05
0.00
0.05
0.10
h) Skill score (RMSE): msl
GraphCast - 1 AR
GraphCast - 2 AR
GraphCast - 4 AR
GraphCast - 6 AR
GraphCast - 8 AR
GraphCast - 10 AR
GraphCast - 12 AR
Figure 7 | Eï¬€ects of autoregressive training. Each line in the plots represents GraphCast, ï¬ne-tuned with
diï¬€erent numbers of autoregressive steps, where increasing numbers of steps are represented with darker
shades of blue. The top row shows absolute RMSE for GraphCast. The bottom row shows normalized RMSE
diï¬€erences, with respect to our full 12 autoregressive-step GraphCast. Each column shows a diï¬€erent variable,
as indicated in the subplot titles. The x-axis represents lead time, at 6-hour steps over 10 days. The y-axis
represents (absolute or normalized) RMSE.
5.2. How autoregressive training aï¬€ects forecast skill
Figure 7 shows how the forecast performance varies with the number of autoregressive (AR) steps
used to train our model. When trained with fewer autoregressive steps, the model performs better at
short lead times, and worse over longer lead times. As the number of autoregressive steps is increased,
the performance becomes worse at short lead times, but better at longer ones7. These results suggest
potential for combining multiple models with varying numbers of AR steps, e.g., for short, medium
and long lead times, to capitalize on their respective advantages across the entire forecast period.
5.3. Performance of GraphCast compared to top ML forecasting models
Of the three most recent ML-based forecasting models in the past year, Keisler (2022)â€™s model,
FCN (Kurth et al., 2022; Pathak et al., 2022), and Pangu-Weather (Bi et al., 2022), the most recent,
Pangu-Weather reports results that are categorically stronger than the former two. Thus we focus our
evaluation of GraphCast on Pangu-Weather, as it represents the state-of-the-art of ML-based weather
forecasting. Pangu-Weather is based on a Vision Transformers (Dosovitskiy et al., 2020; Vaswani
et al., 2017), which has similar patterns of computations to GNNs (e.g., Pangu-Weatherâ€™s masking of
non-local interactions among embedded patches means it can also be viewed as a Graph Attention
Network (VeliÄkoviÄ‡ et al., 2017)).
7The way we obtained each of these models was using a curriculum where the 1 AR-step model was ï¬ne-tuned for
1000 gradient updates each, on increasing numbers of AR steps, from 2-12 (see Appendix A.3 and Appendix Figure A.2
for details). Each model shown in Figure 7 was from the end of its respective number of AR-step training. This means
the higher AR-step models had slightly more training than the others, though we do not believe that each had generally
converged, so training the lower AR-step models longer likely would not have made much diï¬€erence.
15

GraphCast: Learning skillful medium-range global weather forecasting
1
2
3
4
5
6
7
0
200
400
RMSE
Lower is better
a) Skill (RMSE): z500
1
2
3
4
5
6
7
1
2
b) Skill (RMSE): t500
1
2
3
4
5
6
7
1
2
c) Skill (RMSE): t850
1
2
3
4
5
6
7
0.0002
0.0004
0.0006
0.0008
d) Skill (RMSE): q500
1
2
3
4
5
6
7
0.0
0.2
0.4
0.6
Normalized RMSE diff.
e) Skill score (RMSE): z500
1
2
3
4
5
6
7
0.2
0.0
0.2
0.4
0.6
f) Skill score (RMSE): t500
1
2
3
4
5
6
7
0.2
0.0
0.2
0.4
0.6
g) Skill score (RMSE): t850
1
2
3
4
5
6
7
0.00
0.25
0.50
0.75
h) Skill score (RMSE): q500
1
2
3
4
5
6
7
2
4
6
RMSE
i) Skill (RMSE): u500
1
2
3
4
5
6
7
2
4
6
j) Skill (RMSE): v500
1
2
3
4
5
6
7
0.5
1.0
1.5
2.0
k) Skill (RMSE): 2t
1
2
3
4
5
6
7
1
2
3
4
l) Skill (RMSE): 10u
1
2
3
4
5
6
7
Lead time (days)
0.0
0.2
0.4
0.6
Normalized RMSE diff.
m) Skill score (RMSE): u500
1
2
3
4
5
6
7
Lead time (days)
0.0
0.2
0.4
0.6
n) Skill score (RMSE): v500
1
2
3
4
5
6
7
Lead time (days)
0.0
0.5
o) Skill score (RMSE): 2t
1
2
3
4
5
6
7
Lead time (days)
0.25
0.00
0.25
0.50
0.75
p) Skill score (RMSE): 10u
GraphCast - 12 AR
HRES against ERA5
HRES against HRES-fc0
Pangu-Weather
Figure 8 | Comparison between GraphCast and Pangu-Weather, on RMSE skill. Rows 1 and 3 show
absolute RMSE for GraphCast (blue lines), Pangu-Weather (Bi et al., 2022) (red lines), HRES evaluated against
HRES-fc0 (black lines), and HRES evaluated against ERA5; rows 2 and 4 show normalized RMSE diï¬€erences
between the models with respect to Pangu-Weather. Each subplot represents a single variable (and pressure
level, for atmospheric variables), as indicated in the subplot titles. The x-axis represents lead time, at 6-hour
steps over 10 days. The y-axis represents (absolute or normalized) RMSE. The variables and levels were chosen
to be those reported by Bi et al. (2022). The reason HRES evaluated against ERA5 is shown is because that is
what Bi et al. (2022) use as their HRES baseline, while our analyses use HRES against HRES-fc0. We did not
include 10v, because 10u is already present, and the two are highly correlated.
16

GraphCast: Learning skillful medium-range global weather forecasting
Bi et al. (2022) report Pangu-Weatherâ€™s 7-day forecast accuracy (RMSE and ACC) on: z500,
t500, t850, q500, u500, v500, 2t, 10u, 10v, and msl. They did not provide the raw values, so
we used a software tool to extract the values from their paperâ€™s plots. As shown in Figure 8, GraphCast
(blue lines) outperforms Pangu-Weather (red lines) on 99.2% of targets reported by Bi et al. (2022).
The only 2 (of the 252 total) metrics on which Pangu-Weather outperformed GraphCast was z500, at
lead times 6 and 12 hours, where GraphCast had 1.7% higher average RMSE (Figure 8a,e).
Our evaluation approach for comparison with HRES diï¬€ers from that used in Bi et al. (2022).
As described in Section 4, we measured HRESâ€™s skill by using HRES-fc0 as ground truth. In Bi et al.
(2022), HRESâ€™s skill is computed by using ERA5 as ground truth. As detailed in Appendix A.5, this
HRES-against-ERA5 approach can lead to systematically worse skill estimates. As shown in Figure 8,
we computed HRESâ€™s skill both ways: against HRES-fc0 (black lines), and against ERA5 (grey lines).
HRES-against-ERA5 is clearly worse at early lead times, and in some cases, especially for temperature,
HRES-against-HRES-fc0 has better skill than Pangu-Weather.
6. Discussion
We show that our GraphCast model outperforms the most accurate deterministic operational system,
ECMWFâ€™s HRES, on 10-day forecasts, at 6-hour steps, and 0.25Â° latitude-longitude resolution. We
evaluated GraphCastâ€™s skill on a comprehensive set of 2760 variable, pressure level, and lead time
combinations, and our results showed our model had lower RMSE than HRES on 90.0% of the metrics.
When we excluded the upper atmosphere ï¬elds from 100 hPa and above, GraphCast outperformed
HRES on 99.2% of the 1760 targets. GraphCast also outperformed the best previous ML baseline,
Pangu-Weather (Bi et al., 2022), on 99.2% of the 252 metrics which Bi et al. (2022) reported. A key
innovation of GraphCast was its novel â€œmulti-meshâ€ representation, which allows it to capture much
longer-range spatial interactions than in traditional NWP methods, and thus support much coarser
native timesteps. This is part of why GraphCast can generate an accurate 10-day weather forecast, at
6 hour steps, in under 60 seconds on a single Cloud TPU v4 device.
One important caveat to our work is that we focused on deterministic forecasts, and compared
GraphCastâ€™s skill only to HRES. While HRES is ECMWFâ€™s highest ï¬delity single forecast, the other
pillar of IFS, the ensemble forecasting system, ENS, is of comparable importance, especially for forecast
horizons in the 5-15 day range. Because weather dynamics are highly nonlinear, and the analysis
provided as input to weather models has inherent uncertainty, as a forecastâ€™s lead time increases, it
becomes increasingly diï¬ƒcult to make accurate point-wise predictions of weather trajectories, and
thus modeling the uncertainty becomes increasingly important. Over longer time horizons, we notice
GraphCastâ€™s forecasts become somewhat more blurry than HRESâ€™s. This is to be expected, because
it was trained to optimize a weighted mean squared error. Thus, the way it expresses uncertainty
over longer lead times is by producing a forecast closer to the mean. This contrasts with traditional
deterministic NWPs, which will make high-resolution, but sometimes incorrect, predictions. However
these predictions may be useful for some purposes, such as predicting temperature extremes, or the
chance of storms. It also contrasts with ensemble forecast models, which produce multiple forecasts
from a sample of initial conditions which approximate the uncertainty in the true initial conditions.
Statistical measures of the ensemble forecasts are used to quantify uncertainty. Ensemble forecasting
oï¬€ers key advantages, such as estimating the distribution more explicitly, however it comes at the
cost of requiring many expensive forecasts to be generated. Building models that model uncertainty,
and can be comprehensively evaluated against ensemble systems, is a crucial next step.
Another caveat is that we focused on 0.25Â° latitude-longitude resolution, while HRES operates on
0.1Â°. This choice was based on the fact that ERA5 is available only at 0.25Â°, and because there are
17

GraphCast: Learning skillful medium-range global weather forecasting
substantial engineering challenges in working with large 0.25Â° state representations. Nevertheless,
there is no principled or technical reason why our approach will not scale to higher resolution, given
suï¬ƒcient data and engineering advances.
We also invite the meteorological community to join us in deï¬ning new, broader skill metrics that
go beyond the ECMWF Scorecard (which was designed to evaluate IFS Cycles against one another).
For example, storm tracking, preparing for extreme weather, etc. are important applications of
weather forecasts, which would beneï¬t from concrete metrics and benchmarks on which ML-based
methods can be trained and evaluated.
Our contributions represent a signiï¬cant step forward for ML-based weather modeling, and can,
in principle, apply to a much wider range of environmental and other geo-spatiotemporal forecasting
problems. Key application areas include modeling other weather variables, seasonal and climate
forecasting, wildï¬res, deforestation, animal and human activity, etc. However, our approach should
not be regarded as a replacement for traditional weather forecasting methods, which have been
developed for decades, rigorously tested in many real-world contexts, and provide probabilistic
predictions (Palmer, 2018). Rather, our work should be interpreted as clear evidence that ML-based
simulation is able to scale eï¬€ectively to the challenges of real-world forecasting problems, and has
potential to complement and transform the current best methods. More broadly, by training on
complex, real-world data, and outperforming traditional numerical approaches, this work helps
realize the promise of ML-based simulation in the physical sciences.
Acknowledgements
In alphabetical order, we thank Kelsey Allen, Charles Blundell, Matt Botvinick,
Zied Ben Bouallegue, Michael Brenner, Rob Carver, Matt Chantry, Marc Deisenroth, Peter Deuben,
Marta Garnelo, Ryan Keisler, Dmitrii Kochkov, Chris Mattern, Piotr Mirowski, Peter Norgaard, Ilan
Price, Chongli Qin, Stephan Rasp, Yulia Rubanova, Kunal Shah, and Daniel Worrall for advice and
feedback on our work. We also thank ECMWF for providing invaluable datasets to the research
community.
References
F. Alet, A. K. Jeewajee, M. B. Villalonga, A. Rodriguez, T. Lozano-Perez, and L. Kaelbling. Graph
element networks: adaptive, structured computation and memory. In International Conference on
Machine Learning, pages 212â€“222. PMLR, 2019.
K. R. Allen, Y. Rubanova, T. Lopez-Guevara, W. Whitney, A. Sanchez-Gonzalez, P. Battaglia, and T. Pfaï¬€.
Learning rigid dynamics with face interaction graph networks. arXiv preprint arXiv:2212.03574,
2022.
J. L. Ba, J. R. Kiros, and G. E. Hinton. Layer normalization. arXiv, 2016. doi: 10.48550/ARXIV.1607.
06450.
I. Babuschkin, K. Baumli, A. Bell, S. Bhupatiraju, J. Bruce, P. Buchlovsky, D. Budden, T. Cai, A. Clark,
I. Danihelka, C. Fantacci, J. Godwin, C. Jones, R. Hemsley, T. Hennigan, M. Hessel, S. Hou,
S. Kapturowski, T. Keck, I. Kemaev, M. King, M. Kunesch, L. Martens, H. Merzic, V. Mikulik,
T. Norman, J. Quan, G. Papamakarios, R. Ring, F. Ruiz, A. Sanchez, R. Schneider, E. Sezener,
S. Spencer, S. Srinivasan, L. Wang, W. Stokowiec, and F. Viola. The DeepMind JAX Ecosystem,
2020. URL http://github.com/deepmind.
P. Battaglia, R. Pascanu, M. Lai, D. Jimenez Rezende, et al. Interaction networks for learning about
objects, relations and physics. Advances in neural information processing systems, 29, 2016.
18

GraphCast: Learning skillful medium-range global weather forecasting
P. W. Battaglia, J. B. Hamrick, V. Bapst, A. Sanchez-Gonzalez, V. Zambaldi, M. Malinowski, A. Tacchetti,
D. Raposo, A. Santoro, R. Faulkner, et al. Relational inductive biases, deep learning, and graph
networks. arXiv preprint arXiv:1806.01261, 2018.
P. Bauer, A. Thorpe, and G. Brunet. The quiet revolution of numerical weather prediction. Nature,
525, 2015. doi: https://doi.org/10.1038/nature14956.
S. G. Benjamin, J. M. Brown, G. Brunet, P. Lynch, K. Saito, and T. W. Schlatter. 100 years of progress
in forecasting and nwp applications. Meteorological Monographs, 59:13â€“1, 2019.
K. Bi, L. Xie, H. Zhang, X. Chen, X. Gu, and Q. Tian. Pangu-weather: A 3d high-resolution model for
fast and accurate global weather forecast. arXiv preprint arXiv:2211.02556, 2022.
J. Bradbury, R. Frostig, P. Hawkins, M. J. Johnson, C. Leary, D. Maclaurin, G. Necula, A. Paszke, J. Van-
derPlas, S. Wanderman-Milne, and Q. Zhang. JAX: composable transformations of Python+NumPy
programs, 2018. URL http://github.com/google/jax.
T. Chen, B. Xu, C. Zhang, and C. Guestrin. Training deep nets with sublinear memory cost. arXiv
preprint arXiv:1604.06174, 2016.
M. Cranmer, S. Greydanus, S. Hoyer, P. Battaglia, D. Spergel, and S. Ho. Lagrangian neural networks.
arXiv preprint arXiv:2003.04630, 2020.
A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Min-
derer, G. Heigold, S. Gelly, et al. An image is worth 16x16 words: Transformers for image recognition
at scale. arXiv preprint arXiv:2010.11929, 2020.
L. Espeholt, S. Agrawal, C. SÃ¸nderby, M. Kumar, J. Heek, C. Bromberg, C. Gazen, R. Carver,
M. Andrychowicz, J. Hickey, et al. Deep learning for twelve hour precipitation forecasts. Na-
ture communications, 13(1):1â€“10, 2022.
M. Fortunato, T. Pfaï¬€, P. Wirnsberger, A. Pritzel, and P. Battaglia. Multiscale meshgraphnets. arXiv
preprint arXiv:2210.00612, 2022.
J. Godwin*, T. Keck*, P. Battaglia, V. Bapst, T. Kipf, Y. Li, K. Stachenfeld, P. VeliÄkoviÄ‡, and A. Sanchez-
Gonzalez. Jraph: A library for graph neural networks in jax., 2020. URL http://github.com/
deepmind/jraph.
J. Guibas, M. Mardani, Z. Li, A. Tao, A. Anandkumar, and B. Catanzaro. Adaptive fourier neural
operators: Eï¬ƒcient token mixers for transformers. arXiv preprint arXiv:2111.13587, 2021.
T. Haiden, M. Janousek, J. Bidlot, R. Buizza, L. Ferranti, F. Prates, and F. Vitart. Evaluation of ECMWF
forecasts, including the 2018 upgrade. European Centre for Medium Range Weather Forecasts
Reading, UK, 2018.
T. Haiden, M. Janousek, F. Vitart, Z. Ben-Bouallegue, L. Ferranti, and F. Prates. Evaluation of ECMWF
forecasts, including the 2021 upgrade. ECMWF Technical Memoranda, September 2021.
T. Hennigan, T. Cai, T. Norman, and I. Babuschkin. Haiku: Sonnet for JAX, 2020. URL http:
//github.com/deepmind/dm-haiku.
H. Hersbach, B. Bell, P. Berrisford, S. Hirahara, A. HorÃ¡nyi, J. MuÃ±oz-Sabater, J. Nicolas, C. Peubey,
R. Radu, D. Schepers, et al. The era5 global reanalysis. Quarterly Journal of the Royal Meteorological
Society, 146(730):1999â€“2049, 2020.
19

GraphCast: Learning skillful medium-range global weather forecasting
S. Hoyer and J. Hamman. xarray: N-D labeled arrays and datasets in Python. Journal of Open Research
Software, 5(1), 2017. doi: 10.5334/jors.148. URL https://doi.org/10.5334/jors.148.
R. Keisler. Forecasting global weather with graph neural networks. arXiv preprint arXiv:2202.07575,
2022.
D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980,
2014.
T. Kipf, E. Fetaya, K.-C. Wang, M. Welling, and R. Zemel. Neural relational inference for interacting
systems. In International Conference on Machine Learning, pages 2688â€“2697. PMLR, 2018.
T. Kurth, S. Subramanian, P. Harrington, J. Pathak, M. Mardani, D. Hall, A. Miele, K. Kashinath,
and A. Anandkumar. Fourcastnet: Accelerating global high-resolution weather forecasting using
adaptive fourier neural operators. arXiv preprint arXiv:2208.05419, 2022.
Y. Li, J. Wu, R. Tedrake, J. B. Tenenbaum, and A. Torralba. Learning particle dynamics for manipulating
rigid bodies, deformable objects, and ï¬‚uids. arXiv preprint arXiv:1810.01566, 2018.
Y. Li, J. Wu, J.-Y. Zhu, J. B. Tenenbaum, A. Torralba, and R. Tedrake. Propagation networks for
model-based control under partial observation. In 2019 International Conference on Robotics and
Automation (ICRA), pages 1205â€“1211. IEEE, 2019.
Z. Li, N. Kovachki, K. Azizzadenesheli, B. Liu, K. Bhattacharya, A. Stuart, and A. Anandkumar. Fourier
neural operator for parametric partial diï¬€erential equations. arXiv preprint arXiv:2010.08895,
2020.
I. Lopez-Gomez, A. McGovern, S. Agrawal, and J. Hickey. Global extreme heat forecasting using
neural weather models. arXiv preprint arXiv:2205.10972, 2022.
I. Loshchilov and F. Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101,
2017.
Met Oï¬ƒce, 2021.
URL https://www.metoffice.gov.uk/about-us/what/technology/
supercomputer.
D. Mrowca, C. Zhuang, E. Wang, N. Haber, L. F. Fei-Fei, J. Tenenbaum, and D. L. Yamins. Flexible
neural representation for physics prediction. Advances in neural information processing systems, 31,
2018.
T. Palmer. The ECMWF ensemble prediction system: Looking back (more than) 25 years and projecting
forward 25 years. Quarterly Journal of the Royal Meteorological Society, 145(S1):12â€“24, Sept. 2018.
doi: 10.1002/qj.3383.
J. Pathak, S. Subramanian, P. Harrington, S. Raja, A. Chattopadhyay, M. Mardani, T. Kurth, D. Hall,
Z. Li, K. Azizzadenesheli, et al. Fourcastnet: A global data-driven high-resolution weather model
using adaptive fourier neural operators. arXiv preprint arXiv:2202.11214, 2022.
T. Pfaï¬€, M. Fortunato, A. Sanchez-Gonzalez, and P. Battaglia. Learning mesh-based simulation with
graph networks. In International Conference on Learning Representations, 2021.
P. Ramachandran, B. Zoph, and Q. V. Le.
Searching for activation functions.
arXiv preprint
arXiv:1710.05941, 2017.
20

GraphCast: Learning skillful medium-range global weather forecasting
S. Rasp and N. Thuerey. Data-driven medium-range weather prediction with a resnet pretrained on
climate simulations: A new model for weatherbench. Journal of Advances in Modeling Earth Systems,
13(2):e2020MS002405, 2021.
S. Rasp, P. D. Dueben, S. Scher, J. A. Weyn, S. Mouatadid, and N. Thuerey. Weatherbench: a benchmark
data set for data-driven weather forecasting. Journal of Advances in Modeling Earth Systems, 12
(11):e2020MS002203, 2020.
S. Ravuri, K. Lenc, M. Willson, D. Kangin, R. Lam, P. Mirowski, M. Fitzsimons, M. Athanassiadou,
S. Kashem, S. Madge, et al. Skilful precipitation nowcasting using deep generative models of radar.
Nature, 597(7878):672â€“677, 2021.
Y. Rubanova, A. Sanchez-Gonzalez, T. Pfaï¬€, and P. Battaglia. Constraint-based graph network
simulator. arXiv preprint arXiv:2112.09161, 2021.
A. Sanchez-Gonzalez, N. Heess, J. T. Springenberg, J. Merel, M. Riedmiller, R. Hadsell, and P. Battaglia.
Graph networks as learnable physics engines for inference and control. In International Conference
on Machine Learning, pages 4470â€“4479. PMLR, 2018.
A. Sanchez-Gonzalez, V. Bapst, K. Cranmer, and P. Battaglia. Hamiltonian graph networks with ode
integrators. arXiv preprint arXiv:1909.12790, 2019.
A. Sanchez-Gonzalez, J. Godwin, T. Pfaï¬€, R. Ying, J. Leskovec, and P. Battaglia. Learning to simulate
complex physics with graph networks. In International Conference on Machine Learning, pages
8459â€“8468. PMLR, 2020.
X. Shi, Z. Gao, L. Lausen, H. Wang, D.-Y. Yeung, W.-k. Wong, and W.-c. Woo. Deep learning for
precipitation nowcasting: A benchmark and a new model. Advances in neural information processing
systems, 30, 2017.
C. K. SÃ¸nderby, L. Espeholt, J. Heek, M. Dehghani, A. Oliver, T. Salimans, S. Agrawal, J. Hickey, and
N. Kalchbrenner. Metnet: A neural weather model for precipitation forecasting. arXiv preprint
arXiv:2003.12140, 2020.
C. Sun, P. Karlsson, J. Wu, J. B. Tenenbaum, and K. Murphy. Stochastic prediction of multi-agent
interactions from partial observations. arXiv preprint arXiv:1902.09641, 2019.
R. Swinbank, M. Kyouda, P. Buchanan, L. Froude, T. M. Hamill, T. D. Hewson, J. H. Keller, M. Matsueda,
J. Methven, F. Pappenberger, et al. The tigge project and its achievements. Bulletin of the American
Meteorological Society, 97(1):49â€“67, 2016.
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Å. Kaiser, and I. Polosukhin.
Attention is all you need. Advances in neural information processing systems, 30, 2017.
P. VeliÄkoviÄ‡, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio. Graph attention networks.
arXiv preprint arXiv:1710.10903, 2017.
J. A. Weyn, D. R. Durran, and R. Caruana. Can machines learn to predict weather? using deep
learning to predict gridded 500-hpa geopotential height from historical weather data. Journal of
Advances in Modeling Earth Systems, 11(8):2680â€“2693, 2019.
J. A. Weyn, D. R. Durran, and R. Caruana. Improving data-driven global weather prediction using
deep convolutional neural networks on a cubed sphere. Journal of Advances in Modeling Earth
Systems, 12(9):e2020MS002109, 2020.
21

GraphCast: Learning skillful medium-range global weather forecasting
Appendix
A.1. ECMWF data and forecasts
Here we summarize ECMWFâ€™s ERA5 data that we used to train and evaluate our learned model
(Appendix A.1.1), as well as the data we used to evaluate ECMWFâ€™s HRES forecasts, which is our
main NWP baseline (Appendix A.1.2). We constructed multiple internal datasets that all comprise
subsets of the original data provided by ECMWF. Whenever appropriate, we distinguish between
ECMWFâ€™s datasets, which we refer to as ECMWFâ€™s â€œarchiveâ€, versus the datasets we have built from
these archives, which we refer to as â€œdatasetsâ€.
Type
Variable name
Short
ECMWF
Role (accumulation
name
Parameter ID
period, if applicable)
Atmospheric
Geopotential
z
129
Input/Predicted
Atmospheric
Speciï¬c humidity
q
133
Input/Predicted
Atmospheric
Temperature
t
130
Input/Predicted
Atmospheric
U component of wind
u
131
Input/Predicted
Atmospheric
V component of wind
v
132
Input/Predicted
Atmospheric
Vertical velocity
w
135
Input/Predicted
Single
2 metre temperature
2t
167
Input/Predicted
Single
10 metre u wind component
10u
165
Input/Predicted
Single
10 metre v wind component
10v
166
Input/Predicted
Single
Mean sea level pressure
msl
151
Input/Predicted
Single
Total precipitation
tp
28
Input/Predicted (6h)
Single
TOA incident solar radiation
tisr
212
Input (1h)
Static
Geopotential at surface
z
129
Input
Static
Land-sea mask
lsm
172
Input
Static
Latitude
n/a
n/a
Input
Static
Longitude
n/a
n/a
Input
Clock
Local time of day
n/a
n/a
Input
Clock
Elapsed year progress
n/a
n/a
Input
Table A.1 | ECMWF variables used in our datasets. The â€œTypeâ€ column indicates whether the variable
represents a static property, a time-varying single-level property (e.g., surface variables are included), or a
time-varying atmospheric property. The â€œVariable nameâ€ and â€œShort nameâ€ columns are ECMWFâ€™s labels. The
â€œECMWF Parameter IDâ€ column is a ECMWFâ€™s numeric label, and can be used to construct the URL for ECMWFâ€™s
description of the variable, by appending it as suï¬ƒx to the following preï¬x, replacing â€œIDâ€ with the numeric
code: https://apps.ecmwf.int/codes/grib/param-db/?id=ID. The â€œRoleâ€ column indicates whether
the variable is something our model takes as input and predicts, or only uses as input context (the double
horizontal line separates predicted from input-only variables, to make the partitioning more visible.
A.1.1. ERA5
For training and evaluating our ML models, we built a dataset from ECMWFâ€™s ERA5 archive (Hersbach
et al., 2020)8, which is a large corpus of data that represents the global weather from 1959 to the
8See ERA5 documentation: https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation.
22

GraphCast: Learning skillful medium-range global weather forecasting
present, at 0.25Â° latitude/longitude resolution, and 1 hour increments, for hundreds of static, surface,
and atmospheric variables. The ERA5 archive is based on reanalysis, which uses ECMWFâ€™s NWP model
that was operational for most of 20169 to assimilate 12 hour windows of observations, from 21z-09z
and 09z-21z, as well as previous forecasts, into a dense representation of the weatherâ€™s state, for each
historical date and time.
Our ERA5 dataset contains a subset of available variables in ECMWFâ€™s ERA5 archive (Appendix
Table A.1), on 37 pressure levels:
1, 2, 3, 5, 7, 10, 20, 30, 50, 70, 100, 125, 150, 175, 200, 225, 250, 300, 350, 400, 450,
500, 550, 600, 650, 700, 750, 775, 800, 825, 850, 875, 900, 925, 950, 975, 1000
The range of years included was 1979-2018, and were downsampled to 6 hour time intervals
(corresponding to 00z, 06z, 12z and 18z each day). The downsampling is performed simply by
subsampling, except for the total precipitation, which is accumulated for the 6 hours leading up to
the corresponding downsampled time.
A.1.2. HRES
Evaluating the HRES model baseline requires two separate sets of data, namely the forecast data and
the ground truth data10, which are summarized in the subsequent sub-sections. The HRES versions
which were operational during our test year of 2018 were Cycle 43r3 and Cycle 45r19.
HRES operational forecasts
HRES is the most accurate deterministic NWP-based weather model in
the world, so to evaluate the HRES baseline, we built a dataset of HRESâ€™s archived historical forecasts.
HRES is regularly updated by ECMWF, so these forecasts represent the latest HRES model at the
time the forecasts were made. The forecasts were downloaded at 0.1Â°, then spatially downsampled to
0.25Â° (to match ERA5â€™s resolution) using ECMWFâ€™s Metview library, with default regrid parameters.
Each forecast consists of a 10-day prediction with 6h timesteps, initialized from HRES analysis at 00z
or 12z each day11.
HRES-fc0 analysis
For evaluating the skill of the HRES operational forecasts, we constructed a
ground truth dataset, â€œHRES-fc0â€, based on ECMWFâ€™s HRES operational forecast archive. This dataset
comprises the initial time step of each HRES forecast, at initialization times 00z, 06z, 12z, and
18z. The HRES-fc0 analysis data is similar to the ERA5 data, but it is assimilated using the latest
ECMWF NWP model at the forecast time, and assimilates observations from Â±3 hours around the
corresponding date and time, along with previous forecasts.
9HRES Cycle 41r2 was operational from 2016-03-08 to 2016-11-21.
HRES Cycle 43r3 was operational
from 2017-07-11 to 2018-06-04.
HRES Cycle 45r1 was operational from 2018-06-05 to 2019-06-10.
See
https://www.ecmwf.int/en/forecasts/documentation-and-support/changes-ecmwf-model for the full cy-
cle release schedule.
10Note, ECMWF also provides an archive of â€œHRES Analysisâ€ data, which is not to be confused with our HRES-fc0 dataset.
Our understanding is the HRES Analysis dataset includes atmospheric and land surface analyses, but is not the input which
is provided to the HRES forecasts, therefore we do not use it because it would disadvantage HRES at short lead times.
11Our HRES dataset was missing several surface variables (10u, 10v, msl, tp) on 11 dates and times:
1. 2018-10-22_12:00:00
2. 2018-10-28_12:00:00
3. 2018-11-06_12:00:00
4. 2018-11-09_12:00:00
5. 2018-11-12_12:00:00
6. 2018-11-18_12:00:00
7. 2018-11-21_12:00:00
8. 2018-11-23_12:00:00
9. 2018-11-24_12:00:00
10. 2018-11-30_12:00:00
11. 2018-12-04_12:00:00
because the download requests failed with the message, â€œRequested data is on one or more damaged tapeâ€.
For evaluation of those variables we excluded these forecasts and ground truth data from our analyses.
23

GraphCast: Learning skillful medium-range global weather forecasting
A.1.3. Training, validation, and test splits
We separated the ERA5 data used to develop the model, i.e., to train and validate it iteratively, from
the data used for evaluating test performance. This means that neither the researchers, nor the model
training software, ever had access to data from the â€œtest setâ€ until we had developed and frozen our
ï¬nal model solely based on the â€œdevelopment setâ€. We then evaluated the frozen model on the test set
to assess its performance, and compare it against baselines. We chose to split the data â€œcausallyâ€ by
which we mean that the test set only contained dates later than those in the training and validation
sets. Our test set includes all data from 2018; our â€œdevelopment setâ€ contains data from 2017 and
earlier. This prevented our model development and training protocols from being able to exploit
any information from the test set (either by directly optimizing on the training set, or by somehow
ï¬tting to the validation set)12. A further beneï¬t of this protocol, as compared to other choices in the
literature, e.g., Bi et al. (2022); Keisler (2022), is that it reï¬‚ects actual deployment conditions, in
which the forecast cannot depend on information from the future.
Within our development set, we further split the data into a â€œtraining setâ€ comprising the years
1979-201513, and a â€œvalidation setâ€ that includes 2016-2017. We used the training set as training
data for our models and the validation set for hyperparameter optimization and model selection, i.e.,
to decide on the best-performing model. We then froze that model, including the architecture and
all the training choices, and re-trained the architecture from scratch on the full development set,
combining training and validation data (1979-2017), to leverage all the available development data.
That ï¬nal, trained model marks the transition from the development phase to the evaluation phase.
A.2. Model details
A.2.1. Time notation
Forecasting involves a number of diï¬€erent time symbols, e.g., to denote the initial forecast time,
validity time, forecast horizon, etc. We therefore start by introducing the relevant terms and notation
for clarity and simplicity. We refer to a particular point in time as â€œdate-timeâ€, indicated by calendar
date and UTC time. For example, 2018-06-21_18:00:00 means June 21, 2018, at 18:00 UTC. For
shorthand, we also sometimes use the Zulu convention, i.e., 00z, 06z, 12z, 18z mean 00:00, 06:00,
12:00, 18:00 UTC, respectively. We further deï¬ne the following symbols:
â€¢ ğ‘¡: Forecast time step index, which indexes the number of steps since the forecast was initialized.
â€¢ ğ‘‡: Forecast horizon, which represents the total number of steps in a forecast.
â€¢ ğ‘‘: Validity time, which indicates the date-time of a particular weather state.
â€¢ ğ‘‘0: Forecast initialization time, indicating the validity time of a forecastâ€™s initial inputs.
â€¢ Î”ğ‘‘: Forecast step duration, indicating how much time elapses during one forecast step.
â€¢ ğœ: Forecast lead time, which represents the elapsed time in the forecast (i.e., ğœ= ğ‘¡Î”ğ‘‘).
A.2.2. General forecasting problem statement
Let ğ‘ğ‘‘denote the true state of the global weather at time ğ‘‘. The time evolution of the true weather
can be represented by an underlying discrete-time dynamics function, Î¦, which generates the state
at the next time step (Î”ğ‘‘in the future) based on the current one, i.e., ğ‘ğ‘‘+Î”ğ‘‘= Î¦(ğ‘ğ‘‘). We then obtain
12Of course, we experienced the weather in 2018, but we assume this had negligible eï¬€ect on the choices we made to
develop the model.
13In preliminary work, we also explored earlier data from 1959-1978, but found it had little impact on training
performance, so in the ï¬nal phases of our work we excluded 1959-1978 for simplicity.
24

GraphCast: Learning skillful medium-range global weather forecasting
a trajectory of ğ‘‡future weather states by applying Î¦ autoregressively ğ‘‡times,
ğ‘ğ‘‘+Î”ğ‘‘:ğ‘‘+ğ‘‡Î”ğ‘‘= (Î¦(ğ‘ğ‘‘), Î¦(ğ‘ğ‘‘+Î”ğ‘‘), . . . , Î¦(ğ‘ğ‘‘+(ğ‘‡âˆ’1)Î”ğ‘‘)
|                                           {z                                           }
1...ğ‘‡autoregressive iterations
)
.
(A.1)
Our goal is to ï¬nd an accurate and eï¬ƒcient model, ğœ™, of the true dynamics function, Î¦, that can
eï¬ƒciently forecast the state of the weather over some forecast horizon, ğ‘‡Î”ğ‘‘. We assume that we
cannot observe ğ‘ğ‘‘directly, but instead only have some partial observation ğ‘‹ğ‘‘, which is an incomplete
representation of the state information required to predict the weather perfectly. Because ğ‘‹ğ‘‘is only
an approximation of the instantaneous state ğ‘ğ‘‘, we also provide ğœ™with one or more past states,
ğ‘‹ğ‘‘âˆ’Î”ğ‘‘, ğ‘‹ğ‘‘âˆ’2Î”ğ‘‘, ..., in addition to ğ‘‹ğ‘‘. The model can then, in principle, leverage this additional context
information to approximate ğ‘ğ‘‘more accurately. Thus ğœ™predicts a future weather state as,
Ë†ğ‘‹ğ‘‘+Î”ğ‘‘= ğœ™(ğ‘‹ğ‘‘, ğ‘‹ğ‘‘âˆ’Î”ğ‘‘, ...)
.
(A.2)
Analogous to Appendix Equation A.1, the prediction Ë†ğ‘‹ğ‘‘+Î”ğ‘‘can be fed back into ğœ™to autoregressively
produce a full forecast,
Ë†ğ‘‹ğ‘‘+Î”ğ‘‘:ğ‘‘+ğ‘‡Î”ğ‘‘= (ğœ™(ğ‘‹ğ‘‘, ğ‘‹ğ‘‘âˆ’Î”ğ‘‘, ...), ğœ™( Ë†ğ‘‹ğ‘‘+Î”ğ‘‘, ğ‘‹ğ‘‘, ...), . . . , ğœ™( Ë†ğ‘‹ğ‘‘+(ğ‘‡âˆ’1)Î”ğ‘‘, Ë†ğ‘‹ğ‘‘+(ğ‘‡âˆ’2)Î”ğ‘‘, ...)
|                                                                                        {z                                                                                        }
1...ğ‘‡autoregressive iterations
)
.
(A.3)
We assess the forecast quality, or skill, of ğœ™by quantifying how well the predicted trajectory,
Ë†ğ‘‹ğ‘‘+Î”ğ‘‘:ğ‘‘+ğ‘‡Î”ğ‘‘, matches the ground-truth trajectory, ğ‘‹ğ‘‘+Î”ğ‘‘:ğ‘‘+ğ‘‡Î”ğ‘‘. However, it is important to highlight
again that ğ‘‹ğ‘‘+Î”ğ‘‘:ğ‘‘+ğ‘‡Î”ğ‘‘only comprises our observations of ğ‘ğ‘‘+Î”ğ‘‘:ğ‘‘+ğ‘‡Î”ğ‘‘, which itself is unobserved. We
then measure the consistency between forecasts and ground truth with an objective function,
L

Ë†ğ‘‹ğ‘‘+Î”ğ‘‘:ğ‘‘+ğ‘‡Î”ğ‘‘, ğ‘‹ğ‘‘+Î”ğ‘‘:ğ‘‘+ğ‘‡Î”ğ‘‘
,
which is described explicitly in section Appendix A.4.
A.2.3. Modeling ECMWF weather data
For training and evaluating models, we treat our ERA5 dataset as the ground truth representation of
the surface and atmospheric weather state. As described in Appendix A.1.2, we used the HRES-fc0
dataset as ground truth for evaluating the skill of HRES.
In our work, the temporal resolution of data and forecasts was always Î”ğ‘‘= 6 hours with a
maximum forecast horizon of 10 days, corresponding to a total of ğ‘‡= 40 steps. Because Î”ğ‘‘is a
constant throughout this paper, we can simplify the notation using (ğ‘‹ğ‘¡, ğ‘‹ğ‘¡+1, . . . , ğ‘‹ğ‘¡+ğ‘‡) instead of
(ğ‘‹ğ‘‘, ğ‘‹ğ‘‘+Î”ğ‘‘, . . . , ğ‘‹ğ‘‘+ğ‘‡Î”ğ‘‘), to index time with an integer instead of a speciï¬c date-time.
An ERA5 weather state ğ‘‹ğ‘¡comprises all variables in Appendix Table A.114, at a 0.25Â° horizontal
latitude-longitude resolution with a total of 721 Ã— 1440 = 1, 038, 240 grid points and 37 vertical
pressure levels. The set of (horizontal) grid points is given by
ğº0.25Â° = {âˆ’90.0, âˆ’89.75, . . . , 90.0} Ã— {âˆ’179.75, âˆ’179.5, . . . , 180.0}
,
(A.4)
14Note, only the â€œpredictedâ€ variables are output by our model, because the â€œinputâ€-only variables are forcings that are
known apriori, and simply appended to the state on each time-step. We ignore them in the description for simplicity, so in
total there are 5 surface variables and 6 atmospheric variables.
25

GraphCast: Learning skillful medium-range global weather forecasting
and atmospheric variables are deï¬ned at all pressure levels. We refer to the subset of variables
in ğ‘‹ğ‘¡that correspond to a particular grid point ğ‘–(1,038,240 in total) as xğ‘¡
ğ‘–, and to each variable ğ‘—
of the 227 target variables as ğ‘¥ğ‘¡
ğ‘–,ğ‘—. The full state representation ğ‘‹ğ‘¡therefore contains a total of
721 Ã— 1440 Ã— (5 + 6 Ã— 37) = 235, 680, 480 values15.
While a regular latitude-longitude grid is a straightforward way to discretize the sphere, it induces
a non-uniform distribution of grid points. This is likely sub-optimal for learning useful representations
and also ineï¬ƒcient from a computational perspective, because the unnecessarily high resolution at the
poles requires a lot of processing. It is therefore desirable to discretize the sphere more uniformly, e.g.,
by using a suitable mesh instead of a latitude-longitude grid. As detailed below, a central component
of our model is an internal representation that uses a multi-scale icosahedral mesh, which we refer to
as â€œmulti-meshâ€. We construct this mesh by reï¬ning a base icosahedral mesh consisting of 12 nodes
iteratively six times, which yields a total of 40,962 nodes. A key feature of the multi-mesh is that we
preserve the edges at all reï¬nement levels (see Figure 1g).
A.2.4. GraphCast
Our GraphCast model is deï¬ned as a one-step learned simulator that takes the role of ğœ™in Ap-
pendix Equation A.2 and predicts the next step based on two consecutive input states, as deï¬ned
in Equation (1) in the main text,
Ë†ğ‘‹ğ‘¡+1 = GraphCast(ğ‘‹ğ‘¡, ğ‘‹ğ‘¡âˆ’1)
.
As in Appendix Equation A.3, we can apply GraphCast iteratively to produce a forecast
Ë†ğ‘‹ğ‘¡+1:ğ‘¡+ğ‘‡= (GraphCast(ğ‘‹ğ‘¡, ğ‘‹ğ‘¡âˆ’1), GraphCast( Ë†ğ‘‹ğ‘¡+1, ğ‘‹ğ‘¡), . . . , GraphCast( Ë†ğ‘‹ğ‘¡+ğ‘‡âˆ’1, Ë†ğ‘‹ğ‘¡+ğ‘‡âˆ’2)
|                                                                                                  {z                                                                                                  }
1...ğ‘‡autoregressive iterations
)
(A.5)
of arbitrary length, ğ‘‡.
GraphCast is implemented using GNNs in an â€œencode-process-decodeâ€ conï¬guration (Battaglia
et al., 2018; Pfaï¬€et al., 2021; Sanchez-Gonzalez et al., 2020), where the encoder maps (surface and
atmospheric) features on the input latitude-longitude grid to a multi-mesh, the processor performs
many rounds of message-passing on the multi-mesh, and the decoder maps the multi-mesh features
back to the output latitude-longitude grid (see Figure 1).
The model operates on a graph G(VG, VM, EM, EG2M, EM2G) which is deï¬ned in detail in the
subsequent paragraphs.
Grid nodes
VG represents the set containing each of the grid nodes ğ‘£G
ğ‘–. Each grid node represents a
vertical slice of the atmosphere at a given latitude-longitude point, ğ‘–. The features associated with each
grid node ğ‘£G
ğ‘–are vG,features
ğ‘–
= [xğ‘¡âˆ’1
ğ‘–
, xğ‘¡
ğ‘–, fğ‘¡âˆ’1
ğ‘–
, fğ‘¡
ğ‘–, fğ‘¡+1
ğ‘–
, cğ‘–], where xğ‘¡
ğ‘–is the time-dependent weather state
ğ‘‹ğ‘¡corresponding to grid node ğ‘£G
ğ‘–and includes all the predicted data variables for all 37 atmospheric
levels as well as surface variables. The forcing terms fğ‘¡consist of time-dependent features that can
be computed analytically, and do not require to be predicted by GraphCast. They include the total
incident solar radiation at the top of the atmosphere, accumulated over 1 hour, the sine and cosine
of the local time of day (normalized to [0, 1)), and the sine and cosine of the of year progress
(normalized to [0, 1)). The constants cğ‘–are static features: the binary land-sea mask, the geopotential
at the surface, the cosine of the latitude, and the sine and cosine of the longitude. At 0.25Â° resolution,
there is a total of 721 Ã— 1440 = 1, 038, 240 grid nodes, each with (5 surface variables + 6 atmospheric
variables Ã— 37 levels) Ã— 2 steps + 5 forcings Ã— 3 steps + 5 constant = 474 input features.
15At the poles, the 1440 longitude points are equal, so the actual number of distinct grid points is slightly smaller.
26

GraphCast: Learning skillful medium-range global weather forecasting
Mesh nodes
VM represents the set containing each of the mesh nodes ğ‘£M
ğ‘–. Mesh nodes are placed
uniformly around the globe in a R-reï¬ned icosahedral mesh ğ‘€ğ‘…. ğ‘€0 corresponds to a unit-radius
icosahedron (12 nodes and 20 triangular faces) with faces parallel to the poles (see Figure 1g). The
mesh is iteratively reï¬ned ğ‘€ğ‘Ÿâ†’ğ‘€ğ‘Ÿ+1 by splitting each triangular face into 4 smaller equilateral faces,
resulting in an extra node in the middle of each edge, and re-projecting the new nodes back onto
the unit sphere.16 Features vM,features
ğ‘–
associated with each mesh node ğ‘£M
ğ‘–include the cosine of the
latitude, and the sine and cosine of the longitude. GraphCast works with a mesh that has been reï¬ned
ğ‘…= 6 times, ğ‘€6, resulting in 40,962 mesh nodes (see Supplementary Appendix Table A.2), each with
3 input features.
Reï¬nement
0
1
2
3
4
5
6
Num Nodes
12
42
162
642
2,562
10,242
40,962
Num Faces
20
80
320
1,280
5,120
20,480
81,920
Num Edges
60
240
960
3,840
15,360
61,440
245,760
Num Multilevel Edges
60
300
1,260
5,100
2,0460
81,900
327,660
Table A.2 | Multi-mesh statistics. Statistics of the multilevel reï¬ned icosahedral mesh as function of the
reï¬nement level ğ‘…. Edges are considered to be bi-directional and therefore we count each edge in the mesh
twice (once for each direction).
Mesh edges
EM are bidirectional edges added between mesh nodes that are connected in the mesh.
Crucially, mesh edges are added to EM for all levels of reï¬nement, i.e., for the ï¬nest mesh, ğ‘€6, as well
as for ğ‘€5, ğ‘€4, ğ‘€3, ğ‘€2, ğ‘€1 and ğ‘€0. This is straightforward because of how the reï¬nement process
works: the nodes of ğ‘€ğ‘Ÿâˆ’1 are always a subset of the nodes in ğ‘€ğ‘Ÿ. Therefore, nodes introduced at
lower reï¬nement levels serve as hubs for longer range communication, independent of the maximum
level of reï¬nement. The resulting graph that contains the joint set of edges from all of the levels of
reï¬nement is what we refer to as the â€œmulti-meshâ€. See Figure 1e,g for a depiction of all individual
meshes in the reï¬nement hierarchy, as well as the full multi-mesh.
For each edge ğ‘’M
ğ‘£M
s â†’ğ‘£M
r connecting a sender mesh node ğ‘£M
s to a receiver mesh node ğ‘£M
r , we build
edge features eM,features
ğ‘£M
s â†’ğ‘£M
r
using the position on the unit sphere of the mesh nodes. This includes the
length of the edge, and the vector diï¬€erence between the 3d positions of the sender node and the
receiver node computed in a local coordinate system of the receiver. The local coordinate system of
the receiver is computed by applying a rotation that changes the azimuthal angle until that receiver
node lies at longitude 0, followed by a rotation that changes the polar angle until the receiver also
lies at latitude 0. This results in a total of 327,660 mesh edges (See Appendix Table A.2), each with 4
input features.
Grid2Mesh edges
EG2M are unidirectional edges that connect sender grid nodes to receiver mesh
nodes. An edge ğ‘’G2M
ğ‘£Gs â†’ğ‘£M
r is added if the distance between the mesh node and the grid node is smaller
or equal than 0.6 times17 the length of the edges in mesh ğ‘€6 (see Figure 1) which ensures every grid
node is connected to at least one mesh node. Features eG2M,features
ğ‘£Gs â†’ğ‘£M
r
are built the same way as those for
the mesh edges. This results on a total of 1,618,746 Grid2Mesh edges, each with 4 input features.
16Note this split and re-project mechanism leads to a small variance in triangle edge lengths across the mesh.
17Technically it is 0.6 times the â€œlongestâ€ edge in ğ‘€6, since there is some variance in the length of the edges caused by
the split-and-reproject mechanism.
27

GraphCast: Learning skillful medium-range global weather forecasting
Mesh2Grid edges
EM2G are unidirectional edges that connect sender mesh nodes to receiver grid
nodes. For each grid point, we ï¬nd the triangular face in the mesh ğ‘€6 that contains it and add three
Mesh2Grid edges of the form ğ‘’M2G
ğ‘£M
s â†’ğ‘£Gr , to connect the grid node to the three mesh nodes adjacent
to that face (see Figure 1). Features eM2G,features
ğ‘£M
s â†’ğ‘£Gr
are built on the same way as those for the mesh
edges. This results on a total of 3,114,720 Mesh2Grid edges (3 mesh nodes connected to each of the
721 Ã— 1440 latitude-longitude grid points), each with four input features.
A.2.5. Encoder
The purpose of the encoder is to prepare data into latent representations for the processor, which will
run exclusively on the multi-mesh.
Embedding the input features
As part of the encoder we ï¬rst embed the features of each of the
grid nodes, mesh nodes, mesh edges, grid to mesh edges, and mesh to grid edges into a latent space
of ï¬xed size using ï¬ve multi-layer perceptrons (MLP),
vG
ğ‘–= MLPembedder
VG
(vG,features
ğ‘–
)
vM
ğ‘–= MLPembedder
VM
(vM,features
ğ‘–
)
eM
ğ‘£M
s â†’ğ‘£M
r = MLPembedder
EM
(eM,features
ğ‘£M
s â†’ğ‘£M
r
)
eG2M
ğ‘£Gs â†’ğ‘£M
r = MLPembedder
EG2M
(eG2M,features
ğ‘£Gs â†’ğ‘£M
r
)
eM2G
ğ‘£M
s â†’ğ‘£Gr = MLPembedder
EM2G
(eM2G,features
ğ‘£M
s â†’ğ‘£Gr
)
(A.6)
Grid2Mesh GNN
Next, in order to transfer information of the state of atmosphere from the grid
nodes to the mesh nodes, we perform a single message passing step over the Grid2Mesh bipartite
subgraph GG2M(VG, VM, EG2M) connecting grid nodes to mesh nodes. This update is performed using
an interaction network (Battaglia et al., 2016, 2018), augmented to be able to work with multiple
node types (Allen et al., 2022). First, each of the Grid2Mesh edges are updated using information
from the adjacent nodes,
eG2M
ğ‘£Gs â†’ğ‘£ğ‘€
r
â€² = MLPGrid2Mesh
EG2M
([eG2M
ğ‘£Gs â†’ğ‘£ğ‘€
r , vG
ğ‘ , vğ‘€
ğ‘Ÿ]).
(A.7)
Then each of the mesh nodes is updated by aggregating information from all of the edges arriving at
that mesh node:
vM
ğ‘–
â€² = MLPGrid2Mesh
VM
 
vM
ğ‘–,
âˆ‘ï¸
ğ‘’G2M
ğ‘£Gs â†’ğ‘£M
r
: ğ‘£M
r =ğ‘£M
ğ‘–
eG2M
ğ‘£Gs â†’ğ‘£M
r
â€²
.
(A.8)
Each of the grid nodes are also updated, but with no aggregation, because grid nodes are not
receivers of any edges in the Grid2Mesh subgraph,
vG
ğ‘–
â€² = MLPGrid2Mesh
VG
 vG
ğ‘–

.
(A.9)
After updating all three elements, the model includes a residual connection, and for simplicity of the
notation, reassigns the variables,
vG
ğ‘–â†vG
ğ‘–+ vG
ğ‘–
â€²,
vM
ğ‘–â†vM
ğ‘–+ vM
ğ‘–
â€²,
eG2M
ğ‘£Gs â†’ğ‘£ğ‘€
r â†eG2M
ğ‘£Gs â†’ğ‘£ğ‘€
r + eG2M
ğ‘£Gs â†’ğ‘£ğ‘€
r
â€².
(A.10)
28

GraphCast: Learning skillful medium-range global weather forecasting
A.2.6. Processor
The processor is a deep GNN that operates on the Mesh subgraph GM(VM, EM) which only contains
the Mesh nodes and and the Mesh edges. Note the Mesh edges contain the full multi-mesh, with not
only the edges of ğ‘€6, but all of the edges of ğ‘€5, ğ‘€4, ğ‘€3, ğ‘€2, ğ‘€1 and ğ‘€0, which will enable long
distance communication.
Multi-mesh GNN
A single layer of the Mesh GNN is standard interaction network (Battaglia et al.,
2016, 2018) which ï¬rst updates each of the mesh edges using information of the adjacent nodes:
eM
ğ‘£ğ‘€
s â†’ğ‘£ğ‘€
r
â€² = MLPMesh
EM ([eM
ğ‘£ğ‘€
s â†’ğ‘£ğ‘€
r , vğ‘€
ğ‘ , vğ‘€
ğ‘Ÿ]).
(A.11)
Then it updates each of the mesh nodes, aggregating information from all of the edges arriving at
that mesh node:
vM
ğ‘–
â€² = MLPMesh
VM
 
vM
ğ‘–,
âˆ‘ï¸
ğ‘’M
ğ‘£M
s â†’ğ‘£M
r
: ğ‘£M
r =ğ‘£M
ğ‘–
eM
ğ‘£M
s â†’ğ‘£M
r
â€²
(A.12)
And after updating both, the representations are updated with a residual connection and for simplicity
of the notation, also reassigned to the input variables:
vM
ğ‘–â†vM
ğ‘–+ vM
ğ‘–
â€²
eM
ğ‘£ğ‘€
s â†’ğ‘£ğ‘€
r â†eM
ğ‘£ğ‘s â†’ğ‘£ğ‘€
r + eM
ğ‘£ğ‘€
s â†’ğ‘£ğ‘€
r
â€²
(A.13)
The previous paragraph describes a single layer of message passing, but following a similar
approach to Pfaï¬€et al. (2021); Sanchez-Gonzalez et al. (2020) we applied this layer iteratively 16
times, using unshared neural network weights for the MLPs in each layer.
A.2.7. Decoder
The role of the decoder is to bring back information to the grid, and extract an output.
Mesh2Grid GNN
Analogous to the Grid2Mesh GNN, the Mesh2Grid GNN performs a single mes-
sage passing over the Mesh2Grid bipartite subgraph GM2G(VG, VM, EM2G). The Grid2Mesh GNN is
functionally equivalent to the Mesh2Grid GNN, but using the Mesh2Grid edges to send information
in the opposite direction. The GNN ï¬rst updates each of the Grid2Mesh edges using information of
the adjacent nodes:
eM2G
ğ‘£ğ‘€
s â†’ğ‘£Gr
â€² = MLPMesh2Grid
EM2G
([eM2G
ğ‘£ğ‘€
s â†’ğ‘£Gr , vğ‘€
ğ‘ , vG
ğ‘Ÿ])
(A.14)
Then it updates each of the grid nodes, aggregating information from all of the edges arriving at that
grid node:
vG
ğ‘–
â€² = MLPMesh2Grid
VG
 
vG
ğ‘–,
âˆ‘ï¸
ğ‘’M2G
ğ‘£M
s â†’ğ‘£Gr
: ğ‘£Gr =ğ‘£G
ğ‘–
eM2G
ğ‘£M
s â†’ğ‘£Gr
â€²
.
(A.15)
In this case we do not update the mesh nodes, as they wonâ€™t play any role from this point on.
Here again we add a residual connection, and for simplicity of the notation, reassign the variables,
this time only for the grid nodes, which are the only ones required from this point on:
vG
ğ‘–â†vG
ğ‘–+ vG
ğ‘–
â€².
(A.16)
29

GraphCast: Learning skillful medium-range global weather forecasting
100
300
500
700
900
Pressure level (hPa)
0.000
0.005
0.010
0.015
0.020
0.025
0.030
0.035
0.040
0.045
0.050
0.055
0.060
0.065
Loss weight
a)
Loss weights per level (atmospheric)
2t
10u
10v
msl
tp
Surface variable
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
b)
Loss weights (surface)
Figure A.1 | Training loss weights. (a) Loss weights per pressure level, for atmospheric variables. (b) Loss
weights for surface variables.
Output function
Finally the prediction Ë†yğ‘–for each of the grid nodes is produced using another MLP,
Ë†yG
ğ‘–= MLPOutput
VG
 vG
ğ‘–

(A.17)
which contains all 227 predicted variables for that grid node. Similar to Pfaï¬€et al. (2021); Sanchez-
Gonzalez et al. (2020), the next weather state, Ë†ğ‘‹ğ‘¡+1, is computed by adding the per-node prediction,
Ë†ğ‘Œğ‘¡, to the input state for all grid nodes,
Ë†ğ‘‹ğ‘¡+1 = GraphCast(ğ‘‹ğ‘¡, ğ‘‹ğ‘¡âˆ’1) = ğ‘‹ğ‘¡+ Ë†ğ‘Œğ‘¡.
(A.18)
A.2.8. Other model details
Input normalization
Similar to Pfaï¬€et al. (2021); Sanchez-Gonzalez et al. (2020), we normalized
all inputs. For each physical variable, we computed the per-pressure level mean and standard deviation
over 1979-2015, and used that to normalize them to zero mean and unit variance. For relative edge
distances and lengths, we normalized the features to the length of the longest edge. For simplicity,
we omit this output normalization from the notation.
Output normalization
Because our model outputs a diï¬€erence, Ë†ğ‘Œğ‘¡, which, during inference, is
added to ğ‘‹ğ‘¡to produce Ë†ğ‘‹ğ‘¡+1, we normalized the output of the model by computing per-pressure
level mean and standard deviation statistics for the time diï¬€erence ğ‘Œğ‘¡= ğ‘‹ğ‘¡+1 âˆ’ğ‘‹ğ‘¡of each variable.
When the GNN produces an output, we multiply this output by this standard deviation, and add the
mean to Ë†ğ‘Œğ‘¡before computing Ë†ğ‘‹ğ‘¡+1, as in Appendix Equation A.18. For simplicity, we omit this output
normalization from the notation.
Neural network parameterizations
The neural networks within GraphCast are all MLPs, with one
hidden layer, and hidden and output layers sizes of 512 (except the ï¬nal layer of the Decoderâ€™s MLP,
whose output size is 227, matching the number of predicted variables for each grid node). We chose
the â€œswishâ€ (Ramachandran et al., 2017) activation function for all MLPs. All MLPs are followed by a
LayerNorm (Ba et al., 2016) layer (again, except for the Decoderâ€™s MLP).
30

GraphCast: Learning skillful medium-range global weather forecasting
A.3. Training details
Training objective
The training objective (Equation (2), repeated here for ease of reading) is
deï¬ned as the mean square error (MSE) between the target output ğ‘‹and predicted output Ë†ğ‘‹,
LMSE =
1
|ğ·batch|
âˆ‘ï¸
ğ‘‘0âˆˆğ·batch
|              {z              }
forecast date-time
1
ğ‘‡
âˆ‘ï¸
ğœâˆˆ1:ğ‘‡train
|     {z     }
lead time
1
|ğº0.25Â°|
âˆ‘ï¸
ğ‘–âˆˆğº0.25Â°
|           {z           }
spatial location
âˆ‘ï¸
ğ‘—âˆˆğ½
|{z}
variable-level
ğ‘ ğ‘—ğ‘¤ğ‘—ğ‘ğ‘–(Ë†ğ‘¥ğ‘‘0+ğœ
ğ‘–,ğ‘—
âˆ’ğ‘¥ğ‘‘0+ğœ
ğ‘–,ğ‘—
)2
|              {z              }
squared error
(A.19)
where
â€¢ ğœâˆˆ1 : ğ‘‡train are the lead times that correspond to the ğ‘‡train autoregressive steps.
â€¢ ğ‘‘0 âˆˆğ·batch represent forecast initialization date-times in a batch of forecasts in the training set,
â€¢ ğ‘—âˆˆğ½indexes the variable, and for atmospheric variables the pressure level.
E.g.
ğ½=
{z1000, z850, . . . , 2t, msl},
â€¢ ğ‘–âˆˆğº0.25Â° are the location (latitude and longitude) coordinates in the grid,
â€¢ Ë†ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
and ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
are predicted and target values for some variable-level, location, and lead timeâ€
â€¢ ğ‘ ğ‘—is the per-variable-level inverse variance of time diï¬€erences,
â€¢ ğ‘¤ğ‘—is the per-variable-level loss weight,
â€¢ ğ‘ğ‘–is the area of the latitude-longitude grid cell, which varies with latitude, and is normalized to
unit mean over the grid.
In order to build a single scalar loss, we took the average across latitude-longitude, pressure levels,
variables, lead times, and batch size. We averaged across latitude-longitude axes, with a weight
proportional to the latitude-longitude cell size (normalized to mean 1). We applied uniform averages
across time and batch.
The ğ‘ ğ‘—= ğ•ğ‘–,ğ‘¡
h
ğ‘¥ğ‘¡+1
ğ‘–,ğ‘—âˆ’ğ‘¥ğ‘¡
ğ‘–,ğ‘—
iâˆ’1
are per-variable-level inverse variance estimates of the time diï¬€erences,
which aim to standardize the targets (over consecutive steps) to unit variance. These were estimated
from the training data. We then applied per-variable-level loss weights, ğ‘¤ğ‘—. For atmospheric variables,
we averaged across levels, with a weight proportional to the pressure of the level (normalized to
unit mean), as shown in Appendix Figure A.1a. We use pressure here as a proxy for the density
(Keisler, 2022). We tuned the loss weights for the surface variables during model development, so as
to produce roughly comparable validation performance across all variables: the weight on 2t was
1.0, and the weights on 10u, 10v, msl, and tp were each 0.1, as shown in Appendix Figure A.1b.
The loss weights across all variables sum to 7.4, i.e., (6 Ã— 1.0 for the atmospheric variables, plus
(1.0 + 0.1 + 0.1 + 0.1 + 0.1) for the surface variables listed above, respectively).
Training on autoregressive objective
In order to improve our modelâ€™s ability to make accurate
forecasts over more than one step, we used an autoregressive training regime, where the modelâ€™s pre-
dicted next step was fed back in as input for predicting the next step. The ï¬nal GraphCast version was
trained on 12 autoregressive steps, following a curriculum training schedule (see Appendix A.3). The
optimization procedure computed the loss on each step of the forecast, with respect to the correspond-
ing ground truth step, error gradients with respect to the model parameters were backpropagated
through the full unrolled sequence of model iterations (i.e., using backpropagation-through-time).
Optimization
The training objective function was minimized using gradient descent, with mini-
batches. We sampled ground truth trajectories from our ERA5 training dataset, with replacement, for
31

GraphCast: Learning skillful medium-range global weather forecasting
0
500
1k
Training iteration
0
2e-04
4e-04
6e-04
8e-04
1e-03
Learning rate
a)
Training phase 1
1k
50k
100k
150k
200k
250k
300k
Training iteration
0
2e-04
4e-04
6e-04
8e-04
1e-03
b)
Training phase 2
300k 302k 304k 306k 308k 310k
Training iteration
3e-07
c)
Training phase 3
1
1
1
2
3
4
5
6
7
8
9
10
11
12
Autoregressive steps
Figure A.2 | Training schedule. (a) First phase of training. (b) Second phase of training. (c) Third phase of
training.
batches of size 32. We used the AdamW optimizer (Kingma and Ba, 2014; Loshchilov and Hutter,
2017) with parameters (beta1 = 0.9, beta2 = 0.95). We used weight decay of 0.1 on the weight
matrices. We used gradient (norm) clipping with a maximum norm value of 32.
Curriculum training schedule
Training the model was conducted using a curriculum of three
phases, which varied the learning rates and number of autoregressive steps. The ï¬rst phase consisted
of 1000 gradient descent updates, with one autoregressive step, and a learning rate schedule that
increased linearly from 0 to 1eâˆ’3 (Appendix Figure A.2a). The second phase consisted of 299,000
gradient descent updates, again with one autoregressive step, and a learning rate schedule that
decreased back to 0 with half-cosine decay function (Appendix Figure A.2b). The third phase
consisted of 11,000 gradient descent updates, where the number of autoregressive steps increased
from 2 to 12, increasing by 1 every 1000 updates, and with a ï¬xed learning rate of 3eâˆ’7 (Appendix
Figure A.2c).
Software and hardware stack
We use JAX (Bradbury et al., 2018), Haiku (Hennigan et al., 2020),
Jraph (Godwin* et al., 2020), Optax, Jaxline (Babuschkin et al., 2020) and xarray (Hoyer and
Hamman, 2017) to build and train our models. We distribute the batch across 32 Cloud TPU v4
devices. We leverage bï¬‚oat16 ï¬‚oating point precision and gradient check-pointing (Chen et al., 2016)
to ï¬t training on long trajectories into the 32GB of the TPU v4 device.
A.4. Evaluation details
A.4.1. Evaluation metrics
Our goal is to assess the performance of our model in a way that allows for a consistent comparison
with the HRES 10-day forecast and other baseline ML models. We therefore focus on the initialization
times 00z and 12z, which are when HRESâ€™s 10-day forecasts are initialized, as well as what Bi et al.
(2022) use. All results are reported for the year 2018 (our test set), with the ï¬rst forecast initialization
time being 2018-01-01_00:00:00 and the last 2018-12-21_12:00:00. We excluded the last 10
days of the year so that the last day of the 10-day ground truth forecast was still within 2018.
Note, using 00z and 12z forecast times means that ERA5â€™s state is informed by observations from
+9 hours ahead (because ERA5â€™s assimilation windows are 21z-09z and 09z-21z, as described in
Appendix A.1). By contrast, HRESâ€™s assimilation window is only +3 hours ahead. Therefore, the
32

GraphCast: Learning skillful medium-range global weather forecasting
ERA5 initial state can carry information from further into the future than HRESâ€™s. However, after
2022-11-22 HRES forecasts are based on upgraded NWPs than ERA5â€™s version of HRES, which may
balance potential advantages of using a longer assimilation window.
All metrics were computed using ï¬‚oat32 precision and reported using the native scale of the
variables without normalization.
Root mean square error (RMSE)
We quantiï¬ed forecast skill for a given variable, ğ‘¥ğ‘—, and lead
time, ğœ= ğ‘¡Î”ğ‘‘using a latitude-weighted root mean square error (RMSE) given by
L ğ‘—,ğœ
RMSE =
1
|ğ·eval|
âˆ‘ï¸
ğ‘‘0âˆˆğ·eval
âˆšï¸„
1
|ğº0.25Â°|
âˆ‘ï¸
ğ‘–âˆˆğº0.25Â°
ğ‘ğ‘–

Ë†ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
âˆ’ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
2
(A.20)
where
â€¢ ğ‘‘0 âˆˆğ·eval represent forecast initialization date-times in the evaluation dataset,
â€¢ ğ‘—âˆˆğ½indexes the variable and level, e.g., ğ½= {z1000, z850, . . . , 2t, msl},
â€¢ ğ‘–âˆˆğº0.25Â° are the location (latitude and longitude) coordinates in the grid,
â€¢ Ë†ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
and ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
are predicted and target values for some variable-level, location, and lead time,
â€¢ ğ‘ğ‘–is the area of the latitude-longitude grid cell (normalized to unit mean over the grid) which
varies with latitude.
Anomaly correlation coeï¬ƒcient (ACC)
We also computed the anomaly correlation coeï¬ƒcient for
a given variable, ğ‘¥ğ‘—, and lead time, ğœ= ğ‘¡Î”ğ‘‘, according to
L ğ‘—,ğœ
ACC =
1
|ğ·eval|
âˆ‘ï¸
ğ‘‘0âˆˆğ·eval
Ã
ğ‘–âˆˆğº0.25Â° ğ‘ğ‘–

Ë†ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
âˆ’ğ¶ğ‘‘0+ğœ
ğ‘—,ğ‘–
 
ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
âˆ’ğ¶ğ‘‘0+ğœ
ğ‘—,ğ‘–

âˆšï¸„Ã
ğ‘–âˆˆğº0.25Â° ğ‘ğ‘–

Ë†ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
âˆ’ğ¶ğ‘‘0+ğœ
ğ‘—,ğ‘–
2 Ã
ğ‘–âˆˆğº0.25Â° ğ‘ğ‘–

ğ‘¥ğ‘‘0+ğœ
ğ‘—,ğ‘–
âˆ’ğ¶ğ‘‘0+ğœ
ğ‘—,ğ‘–
2
(A.21)
where ğ¶ğ‘‘0+ğœ
ğ‘—,ğ‘–
is the climatological mean for a given variable, level, latitude and longitude, and for the
day-of-year containing the validity time ğ‘‘0 + ğœ. All other variables are deï¬ned as above. Climatological
means were computed using ERA5 data between 1993 and 2016.
A.5. Details of baseline comparisons
When comparing diï¬€erent releases of HRES to one another, ECMWF measures HRESâ€™s accuracy by
computing prediction errors against HRESâ€™s own analysis. Generally, verifying a model against its
own analysis gives the best skill estimates (Swinbank et al., 2016). By contrast, evaluating HRES
against ERA5, for example, could lead to misinterpreting or underestimating HRESâ€™s skill, because
HRES is not designed to predict ERA5 values. The reason is that HRES is initialized with its own
analysis, not ERA5 values. By measuring HRES against ERA5, even if HRES were a perfect weather
model, the results would still exhibit a non-zero error, simply because it is making predictions from
diï¬€erent initial conditions. This was why we created the HRES-fc0 dataset (Appendix A.1.2), and
evaluated HRES skill against that as ground truth.
Figure 8 shows the diï¬€erent eï¬€ects of computing HRESâ€™s skill using ERA5 as ground truth (grey
lines), versus using HRES-fc0 as ground truth (black lines). Using ERA5 leads to a systematically
worse skill, relative to using HRES-fc0. The eï¬€ect is most prominent at short lead times, and as
33

GraphCast: Learning skillful medium-range global weather forecasting
the lead time increases, the two skill curves converge to similar values. Bi et al. (2022) measured
HRESâ€™s skill by using ERA5 as ground truth, and Figure 8 shows that in some cases Pangu-Weather
outperforms HRESâ€™s skill when evaluated against ERA5, but not when evaluated against HRES-fc0. It
was not speciï¬ed in Kurth et al. (2022); Pathak et al. (2022) whether ERA5 was used as ground truth
for their IFS skill computations. Keisler (2022) used NOAAâ€™s GFSâ€™s reported skill, which is likely an
appropriate skill measure.
To determine how GraphCastâ€™s performance compares to competing ML methods, we focus on
Pangu-Weather as it is the strongest baseline. Bi et al. (2022) report Pangu-Weatherâ€™s 7-day forecast
accuracy (RMSE and ACC) on: z500, t500, t850, q500, u500, v500, 2t, 10u, 10v, and msl.
As shown in Figure 8, GraphCast (blue lines) outperforms Pangu-Weather Bi et al. (2022) (red lines)
on 99.2% of targets. For the surface variables (2t, 10u, 10v, msl), GraphCastâ€™s error in the ï¬rst
several days is around 10-20% lower, and over the longer lead times plateaus to around 7-10% lower
error. The only 2 (of the 252 total) metrics on which Pangu-Weather outperformed GraphCast was
z500, at lead times 6 and 12 hours, where GraphCast had 1.7% higher average RMSE (Figure 8a,e).
Figure A.3 | Region speciï¬cation for the regional analysis. We use the same regions and naming convention
as in the ECMWF scorecards (https://sites.ecmwf.int/ifs/scorecards/scorecards-47r3HRES.
html), and add some additional regions for better coverage of the entire planet. Per-region evaluation is
provided in Appendix Figure A.4 and Appendix Figure A.5.
34

GraphCast: Learning skillful medium-range global weather forecasting
1
2
3
4
5
6
7
8
9 10
0
500
RMSE
n.hem
a) Skill (RMSE): z500 (m2/s2)
1
2
3
4
5
6
7
8
9 10
2
4
b) Skill (RMSE): t850 (K)
1
2
3
4
5
6
7
8
9 10
2
4
6
c) Skill (RMSE): v850 (m/s)
1
2
3
4
5
6
7
8
9 10
1
2
3
d) Skill (RMSE): 2t (K)
1
2
3
4
5
6
7
8
9 10
2
4
e) Skill (RMSE): 10u (m/s)
1
2
3
4
5
6
7
8
9 10
0
500
1000
RMSE
s.hem
f)
1
2
3
4
5
6
7
8
9 10
2
4
g)
1
2
3
4
5
6
7
8
9 10
2.5
5.0
7.5
h)
1
2
3
4
5
6
7
8
9 10
1
2
3 i)
1
2
3
4
5
6
7
8
9 10
2
4
j)
1
2
3
4
5
6
7
8
9 10
50
100
RMSE
tropics
k)
1
2
3
4
5
6
7
8
9 10
0.5
1.0
1.5 l)
1
2
3
4
5
6
7
8
9 10
1
2
3
m)
1
2
3
4
5
6
7
8
9 10
0.50
0.75
1.00
n)
1
2
3
4
5
6
7
8
9 10
0.5
1.0
1.5
2.0 o)
1
2
3
4
5
6
7
8
9 10
0
500
1000
RMSE
europe
p)
1
2
3
4
5
6
7
8
9 10
2
4
q)
1
2
3
4
5
6
7
8
9 10
2
4
6
8 r)
1
2
3
4
5
6
7
8
9 10
1
2
3
s)
1
2
3
4
5
6
7
8
9 10
2
4
t)
1
2
3
4
5
6
7
8
9 10
0
500
1000
RMSE
n.atl
u)
1
2
3
4
5
6
7
8
9 10
2
4
v)
1
2
3
4
5
6
7
8
9 10
2.5
5.0
7.5
w)
1
2
3
4
5
6
7
8
9 10
1
2
x)
1
2
3
4
5
6
7
8
9 10
2
4
6
y)
1
2
3
4
5
6
7
8
9 10
0
250
500
750
RMSE
n.amer
z)
1
2
3
4
5
6
7
8
9 10
2
4
A)
1
2
3
4
5
6
7
8
9 10
2
4
6
8 B)
1
2
3
4
5
6
7
8
9 10
2
4
C)
1
2
3
4
5
6
7
8
9 10
1
2
3
D)
1
2
3
4
5
6
7
8
9 10
0
500
1000
RMSE
n.pac
E)
1
2
3
4
5
6
7
8
9 10
2
4
F)
1
2
3
4
5
6
7
8
9 10
2.5
5.0
7.5
G)
1
2
3
4
5
6
7
8
9 10
0.5
1.0
1.5
H)
1
2
3
4
5
6
7
8
9 10
2
4
6
I)
1
2
3
4
5
6
7
8
9 10
0
200
400
600
RMSE
e.asia
J)
1
2
3
4
5
6
7
8
9 10
2
4
K)
1
2
3
4
5
6
7
8
9 10
2
4
6
L)
1
2
3
4
5
6
7
8
9 10
1
2
3
M)
1
2
3
4
5
6
7
8
9 10
1
2
3
N)
1
2
3
4
5
6
7
8
9 10
0
200
400
600
RMSE
austnz
O)
1
2
3
4
5
6
7
8
9 10
1
2
3
P)
1
2
3
4
5
6
7
8
9 10
2
4
6
Q)
1
2
3
4
5
6
7
8
9 10
1
2
R)
1
2
3
4
5
6
7
8
9 10
1
2
3
4
S)
1
2
3
4
5
6
7
8
9 10
Lead time (days)
0
500
1000
RMSE
arctic
T)
1
2
3
4
5
6
7
8
9 10
Lead time (days)
2
4
U)
1
2
3
4
5
6
7
8
9 10
Lead time (days)
2.5
5.0
7.5
V)
1
2
3
4
5
6
7
8
9 10
Lead time (days)
2
4
W)
1
2
3
4
5
6
7
8
9 10
Lead time (days)
2
4
X)
HRES against HRES-fc0
GraphCast - 12 AR
Figure A.4 | Skill (RMSE) of GraphCast versus HRES, per-region. Each column is a diï¬€erent variable (and
level), for a representative set of variables. Each row is a diï¬€erent region. The x-axis is lead time, in days. The
y-axis is RMSE, with units speciï¬ed in the column titles. GraphCastâ€™s RMSEs are the blue lines, and HRESâ€™s
RMSEs are the black lines. The regions are: n.hem, s.hem, tropics, europe, n.atl, n.amer, n.pac,
e.asia, austnz, and arctic. See Appendix Figure A.3 for a legend of the region names.
35

GraphCast: Learning skillful medium-range global weather forecasting
1
2
3
4
5
6
7
8
9 10
0
500
1000
RMSE
antarctic
a) Skill (RMSE): z500 (m2/s2)
1
2
3
4
5
6
7
8
9 10
2
4
b) Skill (RMSE): t850 (K)
1
2
3
4
5
6
7
8
9 10
2.5
5.0
7.5
c) Skill (RMSE): v850 (m/s)
1
2
3
4
5
6
7
8
9 10
2
4
d) Skill (RMSE): 2t (K)
1
2
3
4
5
6
7
8
9 10
2
4
6
e) Skill (RMSE): 10u (m/s)
1
2
3
4
5
6
7
8
9 10
100
200
300
RMSE
n.africa
f)
1
2
3
4
5
6
7
8
9 10
1
2
g)
1
2
3
4
5
6
7
8
9 10
2
4
h)
1
2
3
4
5
6
7
8
9 10
1
2
i)
1
2
3
4
5
6
7
8
9 10
1
2
j)
1
2
3
4
5
6
7
8
9 10
100
200
RMSE
s.africa
k)
1
2
3
4
5
6
7
8
9 10
1
2
l)
1
2
3
4
5
6
7
8
9 10
1
2
3
4
m)
1
2
3
4
5
6
7
8
9 10
1
2
n)
1
2
3
4
5
6
7
8
9 10
0.5
1.0
1.5
o)
1
2
3
4
5
6
7
8
9 10
0
250
500
750
RMSE
s.atl
p)
1
2
3
4
5
6
7
8
9 10
1
2
3
q)
1
2
3
4
5
6
7
8
9 10
2
4
6
r)
1
2
3
4
5
6
7
8
9 10
0.5
1.0
1.5 s)
1
2
3
4
5
6
7
8
9 10
2
4
t)
1
2
3
4
5
6
7
8
9 10
0
100
200
300
RMSE
s.amer
u)
1
2
3
4
5
6
7
8
9 10
1
2
v)
1
2
3
4
5
6
7
8
9 10
2
4
w)
1
2
3
4
5
6
7
8
9 10
1
2
x)
1
2
3
4
5
6
7
8
9 10
0.5
1.0
1.5
2.0
y)
1
2
3
4
5
6
7
8
9 10
50
100
RMSE
m.pac
z)
1
2
3
4
5
6
7
8
9 10
0.5
1.0
A)
1
2
3
4
5
6
7
8
9 10
1
2
3
B)
1
2
3
4
5
6
7
8
9 10
0.2
0.4
0.6
0.8
C)
1
2
3
4
5
6
7
8
9 10
1
2
D)
1
2
3
4
5
6
7
8
9 10
0
500
1000
RMSE
s.pac
E)
1
2
3
4
5
6
7
8
9 10
2
4
F)
1
2
3
4
5
6
7
8
9 10
2.5
5.0
7.5
G)
1
2
3
4
5
6
7
8
9 10
0.5
1.0
1.5
H)
1
2
3
4
5
6
7
8
9 10
2
4
6
I)
1
2
3
4
5
6
7
8
9 10
0
250
500
750
RMSE
indian
J)
1
2
3
4
5
6
7
8
9 10
1
2
3
K)
1
2
3
4
5
6
7
8
9 10
2
4
6
L)
1
2
3
4
5
6
7
8
9 10
0.5
1.0
M)
1
2
3
4
5
6
7
8
9 10
2
4
N)
1
2
3
4
5
6
7
8
9 10
0
200
400
600
RMSE
w.asia
O)
1
2
3
4
5
6
7
8
9 10
2
4
P)
1
2
3
4
5
6
7
8
9 10
2
4
Q)
1
2
3
4
5
6
7
8
9 10
1
2
3
R)
1
2
3
4
5
6
7
8
9 10
1
2
S)
1
2
3
4
5
6
7
8
9 10
Lead time (days)
50
100
RMSE
se.asia
T)
1
2
3
4
5
6
7
8
9 10
Lead time (days)
0.5
1.0
U)
1
2
3
4
5
6
7
8
9 10
Lead time (days)
1
2
3
V)
1
2
3
4
5
6
7
8
9 10
Lead time (days)
0.50
0.75
1.00
1.25
W)
1
2
3
4
5
6
7
8
9 10
Lead time (days)
0.5
1.0
1.5
X)
HRES against HRES-fc0
GraphCast - 12 AR
Figure A.5 | Skill (RMSE) of GraphCast versus HRES, per-region. This plot is the same as Appendix
Figure A.4, except for regions (in Appendix Figure A.3): antarctic, n.africa, s.africa, s.atl, s.amer,
m.pac, s.pac, indian, w.asia, and se.asia.
36

