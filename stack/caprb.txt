Chapter 1
Redes Bayesianas
Luis Enrique Sucar
INAOE
Sta. Mar´ıa Tonantzintla, Puebla, 72840, M´exico
Correo electrnico: esucar@inaoep.mx
1.1
Introducci´on
Las redes bayesianas modelan un fen´omeno mediante un conjunto de variables
y las relaciones de dependencia entre ellas. Dado este modelo, se puede hacer
inferencia bayesiana; es decir, estimar la probabilidad posterior de las variables
no conocidas, en base a las variables conocidas. Estos modelos pueden tener
diversas aplicaciones, para clasiﬁcaci´on, predicci´on, diagn´ostico, etc. Adem´as,
pueden dar informaci´on interesante en cuanto a cmo se relacionan las variables
del dominio, las cuales pueden ser interpretadas en ocasiones como relaciones
de causa–efecto.
Incialmente, estos modelos eran construidos ’a mano’ basados en un conocimiento
experto, pero en los ´ultimos a˜nos se han desarrollado diversas t´ecnicas para
aprender a partir de datos, tanto la estructura como los par´ametros asociados
al modelo. Tambi´en es posible el combinar conocimiento experto con los datos
para aprender el modelo.
A continuaci´on, veremos una introducci´on general a redes bayesianas y los
principales m´etodos de inferencia. Despu´es, introducimos una estructura partic-
ular, los clasiﬁcadores bayesianos, y veremos cmo aprenderlos de datos. Porteri-
ormente tratamos el tema de aprendizaje en general de redes bayesianas, tanto
param´etrico como estructural.
Concluimos hablando de la redes bayesianas
din´amicas y cmo se pueden aprender estas estructuras. Al ﬁnal se dan referen-
cias y lecturas adicionales para cada tema.
1

2
CHAPTER 1. REDES BAYESIANAS
1.2
Redes bayesianas
Las redes bayesianas son una representaci´on gr´aﬁca de dependencias para ra-
zonamiento probabilstico, en la cual los nodos representan variables aleatorias
y los arcos representan relaciones de dependencia directa entre las variables.
La Figura 1.1 muestra un ejemplo hipot´etico de una red bayesiana (RB) que
representa cierto conocimiento sobre medicina.
En este caso, los nodos rep-
resentan enfermedades, s´ıntomas y factores que causan algunas enfermedades.
La variable a la que apunta un arco es dependiente de la que est´a en el ori-
gen de ´este, por ejemplo fiebre depende de tifoidea y gripe en la red de la
Figura 1.1. La topolog´ıa o estructura de la red nos da informaci´on sobre las
dependencias probabil´ısticas entre las variables. La red tambi´en representa las
independencias condicionales de una variable (o conjunto de variables) dada(s)
otra(s) variable(s). Por ejemplo, en la red de la Figura 1.1, reacciones es cond.
indep. de C, G, F, D dado tifoidea. (Donde: C es comida, T es tifoidea, G es
gripe, R es reacciones, F es ﬁebre y D es Dolor). Esto es:
P(R|C, T, G, F, D) = P(R|T)
(1.1)
Esto se representa gr´aﬁcamente por el nodo T separando al nodo R del resto de
las variables.
Figure 1.1: Ejemplo de una red bayesiana. Los nodos representan variables
aleatorias y los arcos relaciones de dependencia.
En una RB todas la relaciones de independencia condicional representadas en
el grafo corresponden a relaciones de independencia en la distribuci´on de prob-
abilidad. Dichas independencias simpliﬁcan la representaci´on del conocimiento
(menos par´ametros) y el razonamiento (propagaci´on de las probabilidades). Una
red bayesiana representa en forma gr´aﬁca las dependencias e independencias en-
tre variables aleatorias, en particular las independencias condicionales. Lo an-
terior se representa con la siguiente notaci´on, para el caso de X independiente
de Y dado Z:
• Independencia en la distribuci´on: P(X|Y, Z) = P(X|Z).
• Independencia en el grafo: I < X | Z | Y >.

1.2. REDES BAYESIANAS
3
La independencia condicional se veriﬁca mediante el criterio de separaci´on-D.
Antes de deﬁnir formalmente la separaci´on-D, es necesario distinguir tres tipos
de nodos de acuerdo a las direcciones de los arcos que inciden en el nodo:
• Nodos en secuencia: X →Y →Z.
• Nodos divergentes: X ←Y →Z.
• Nodos convergentes: X →Y ←Z.
Separaci´on D
El conjunto de variables A es independiente del conjunto B dado el conjunto C,
si no existe trayectoria entre A y B en que:
1. Todos los nodos convergentes est´an o tienen descendientes en C.
2. Todos los dem´as nodos est´an fuera de C.
Por ejemplo, en la Figura 1.1, R es independiente de C dado T, pero T y G nos
son independientes dado F.
Dada una distribuci´on de probabilidad o modelo (M) y una representaci´on
gr´aﬁca de dependencias o grafo (G) debe existir una correspondencia entre las
independencias representadas en ambos. En una RB, cualquier nodo X es in-
dependiente de todos los nodos que no son sus descendientes dados sus nodos
padres, Pa(X), denominado el contorno de X. La estructura de una RB se
especiﬁca indicando el contorno (padres) de cada variable. La estructura de la
RB en la Figura 1.1 se especiﬁca de la siguiente manera:
1. Pa(C) = ∅
2. Pa(T) = C
3. Pa(G) = ∅
4. Pa(R) = T
5. Pa(F) = T,G
6. Pa(D) = T,G
La cobija de Markov (manto de Markov, Markov Blanquet) de un nodo es
el conjunto de nodos que lo hacen independiente del resto de la red. Para una
RB, la cobija de Markov est´a formada por:
• Nodos padre.
• Nodos hijo.
• Otros padres de los hijos.
Complementa la deﬁnici´on de una red bayesiana las probabilidades condi-
cionales de cada variable dados sus padres:

4
CHAPTER 1. REDES BAYESIANAS
• Nodos ra´ız: vector de probabilidades marginales.
• Otros nodos: matriz de probabilidades condicionales dados sus padres.
La Figura 1.2 ilustra un ejemplo de algunas de las matrices de probabilidad
asociadas al ejemplo de la Figura 1.1.
Figure 1.2: Par´ametros asociados a una red bayesiana. Se muestran las tablas
de probabilidad condicional de algunas de las variables de la red bayesiana de
la Figura 1.1: probabilidad a priori de Comida, P(C); probabilidad de Tifoidea
dada Comida, P(T | C); y probabilidad de Fiebre dada Tifoidea y Gripe, P(F |
T, G). En este ejemplo se asume que todas las variables son binarias.
Dado que los contornos (padres) de cada nodo especiﬁcan la estructura,
mediante las probabilidades condicionales de dichos nodos podemos especiﬁcar
tambi´en las probabilidades requeridas. Aplicando la regla de la cadena y las
independencias condicionales, se puede veriﬁcar que con dichas probabilidades
se puede calcular la probabilidad conjunta. En general, la probabilidad conjunta
se especiﬁca por el producto de las probabilidades de cada variable dados sus
padres:
P(X1, X2, ..., Xn) =
n
Y
i=1
P(Xi|Pa(Xi))
(1.2)
El tama˜no de la tabla de probabilidad condicional crece exponencialmente
con el n´umero de padres de un nodo, por lo que puede crecer demasiado. Una
forma de reducir este problema es utilizando ciertos modelos para representar
las tablas sin requerir especiﬁcar todas las probabilidades, utilizando lo que se
conoce como modelos can´onicos. Los principales tipos de modelos can´onicos
son:

1.2. REDES BAYESIANAS
5
• Modelo de interacci´on disyuntiva (Noisy OR).
• Modelo de interacci´on conjuntiva (Noisy AND).
• Compuerta Max (Noisy Max gate).
• Compuerta Min (Noisy Min gate).
El modelo can´onico m´as com´un es el Noisy-OR, que se aplica cuando varias
causas pueden ocasionar un efecto cada una por s sola, y la probabilidad del
efecto no disminuye si se presentan varias causas. Por ejemplo, este modelo se
puede aplicar cuando varias enfermedades pueden producir el mismo s´ıntoma.
En este caso s´olo se especiﬁca un par´ametro por cada nodo padre, considerando
variables binarios, en vez de 2n, donde n es el n´umero de padres.
Otras formas compactas de representar las tablas de probabilidad condicional
son mediante ´arboles de decisi´on y redes neuronales.
1.2.1
Inferencia
El razonamiento probabil´ıstico o propagaci´on de probabilidades consiste en
propagar los efectos de la evidencia a trav´es de la red para conocer la probabil-
idad a posteriori de las variables. Es decir, se le dan valores a ciertas variables
(evidencia), y se obtiene la probabilidad posterior de las dem´as variables dadas
las variables conocidas (el conjunto de variables conocidas puede ser vac´ıo, en
este caso se obtienen las probabilidades a priori). Existen diferentes tipos de
algoritmos para calcular las probabilidades posteriores, que dependen del tipo
de grafo y de si obtienen la probabilidad de una variable a la vez o de todas.
Los principales tipos de algoritmos de inferencia son:
1. Una variable, cualquier estructura: algoritmo de eliminaci´on (variable
elimination).
2. Cualquier variable, estructuras sencillamente conectadas: algoritmo de
propagaci´on de Pearl.
3. Cualquier variable, cualquier estructura: (i) agrupamiento (junction tree),
(ii) simulaci´on estoc´astica, y (iii) condicionamiento.
A continuaci´on, veremos el algoritmo de propagaci´on en ´arboles y poli´arboles,
que se ilustran en la Figura 1.3; y despu´es el de agrupamiento o ´arbol de uniones.
Propagaci´on en ´arboles
Este algoritmo se aplica a estructuras de tipo ´arbol, y se puede extender a
poli´arboles (grafos sencillamente conectados en que un nodo puede tener m´as
de un padre).
Dada cierta evidencia E, representada por la instanciaci´on de ciertas vari-
ables, la probabilidad posterior de cualquier variable B, por el teorema de Bayes
(ver Figura 1.4):
P(Bi|E) = P(Bi)P(E|Bi)/P(E)
(1.3)

6
CHAPTER 1. REDES BAYESIANAS
Figure 1.3: Estructuras sencillamente conectadas: (a) ´arbol, (b) poli´arbol.
Figure 1.4: Propagaci´on en ´arboles. En un ´arbol, cualquier nodo (B) divide la
red en dos subgrafos condicionalmente independientes, E+ y E−.
Ya que la estructura de la red es un ´arbol, el Nodo B la separa en dos sub´arboles,
por lo que podemos dividir la evidencia en dos grupos:
E-: Datos en el ´arbol que cuya ra´ız es B.
E+: Datos en el resto del ´arbol.

1.2. REDES BAYESIANAS
7
Entonces:
P(Bi|E) = P(Bi)P(E−, E + |Bi)/P(E)
(1.4)
Pero, dado que ambos son independientes y aplicando nuevamente a Bayes:
P(Bi|E) = αP(Bi|E+)P(E −|Bi)
(1.5)
Donde α es una constante de normalizaci´on Si deﬁnimos los siguientes t´erminos:
λ(Bi) = P(E −|Bi)
(1.6)
π(Bi) = P(Bi|E+)
(1.7)
Entonces:
P(Bi|E) = απ(Bi)λ(Bi)
(1.8)
En base a la ecuaci´on anterior, se puede integrar un algoritmo distribuido
para obtener la probabilidad de un nodo dada cierta evidencia. Para ello, se
descompone el c´alculo en dos partes: (i) evidencia de los hijos (λ), y (ii) evidenica
de los dem´as nodos (π). Cada nodo guarda los valores de los vectores π y λ, as´ı
como las matrices de probabilidad P. La propagaci´on se hace por un mecanismo
de paso de mensajes, en donde cada nodo env´ıa los mensajes correspondientes
a su padre e hijos. Mensaje al padre (hacia arriba), nodo B a su padre A:
λB(Ai) =
X
j
P(Bj | Ai)λ(Bj)
(1.9)
Mensaje a los hijos (hacia abajo), nodo B a su hijo Sk :
πk(Bi) = απ(Bj)
Y
l̸=k
λl(Bj)
(1.10)
Al instanciarse ciertos nodos, ´estos env´ıan mensajes a sus padres e hijos, y
se propagan hasta a llegar a la ra´ız u hojas, o hasta encontrar un nodo instan-
ciado. Al ﬁnal de la propagaci´on, cada nodo tiene un vector π y un vector λ.
Entonces se obtiene la probabilidad simplemente multiplicando ambos (t´ermino
por t´ermino) de acuerdo a la ecuaci´on 1.8. La propagaci´on se realiza una sla
vez en cada sentido (hacia la ra´ız y hacia las hojas), en un tiempo proporcional
al di´ametro (distancia de la ra´ız a la hoja m´as lejana) de la red.
Este algoritmo se puede extendar fcilmente para poli´arboles, pero no se
aplica en redes multiconectadas.
En este caso hay varios algoritmos, en la
siguiente secci´on analizaremos el de ’´arbol de uniones’.
Propagaci´on en redes multiconectadas
El algoritmo general m´as com´un en redes bayesianas es el de agrupamiento
o ’´arbol de uniones’ (junction tree). El m´etodo de agrupamiento consiste en
transformar la estructura de la red para obtener un ´arbol, mediante agrupaci´on
de nodos usando la teor´ıa de grafos. Para ello, se hace una transformaci´on de la
red a un ´arbol de uniones (grupos de nodos) mediante el siguiente procedimiento:

8
CHAPTER 1. REDES BAYESIANAS
1. Eliminar la direccionalidad de los arcos.
2. Ordenamiento de los nodos por m´axima cardinalidad.
3. Moralizar el grafo (arco entre nodos con hijos comunes).
4. Triangular el grafo.
5. Obtener los cliques y ordenar.
6. Construir ´arbol de cliques.
Un clique es un subconjunto de nodos completamente conectados m´aximo,
de forma que hay un arco entre cada par de nodos, y no existe un conjunto
completamente conectado del que ´este sea subconjunto. La Figura 1.5 ilustra
esta transformaci´on para una red sencilla. Para los detalles del algoritmo vanse
las referencias al ﬁnal del cap´ıtulo.
Un vez transformado el grafo, la propagaci´on es mediante el env´ıo de men-
sajes en el ´arbol de uniones o cliques (en forma similar a ´arboles). Inicialmente
se calcula la probabilidad conjunta (potencial) de cada clique, y la condicional
dado el padre. Dada cierta evidencia se recalculan las probabilidades de cada
clique. La probabilidad individual de cada variable se obtiene de la del clique
por marginalizaci´on.
En el peor caso, la propagaci´on en redes bayesianas es un problema NP-
duro. En la pr´actica, en muchas aplicaciones se tienen redes no muy densamente
conectadas y la propagaci´on es eﬁciente a´un para redes muy grandes (funci´on
del clique mayor). Para redes muy complejas (muchas conexiones), la mejor
alternativa son t´ecnicas de simulaci´on estoc´astica o t´ecnicas aproximadas.
Figure 1.5: Transformaci´on de una red a un ´arbol de uniones: (a) red original,
(b) red moralizada y triangulada, (c) ´arbol de uniones.
1.3
Aprendizaje de clasiﬁcadores bayesianos
Un clasiﬁcador, en general, suministra una funci´on que mapea (clasiﬁca) un dato
(instancia), especiﬁcado por una serie de caracter´ısticas o atributos, en una o

1.3. APRENDIZAJE DE CLASIFICADORES BAYESIANOS
9
diferentes clases predeﬁnidas.
Los clasiﬁcadores bayesianos son ampliamente
utilizados debido a que presentan ciertas ventajas:
1. Generalmente, son f´aciles de construir y de entender.
2. Las inducciones de estos clasiﬁcadores son extremadamente r´apidas, re-
quiriendo s´olo un paso para hacerlo.
3. Es muy robusto considerando atributos irrelevantes.
4. Toma evidencia de muchos atributos para realizar la predicci´on ﬁnal.
Un clasiﬁcador bayesiano se puede ver como un caso especial de una red bayesiana
en la cual hay una variable especial que es la clase y las dem´as variables son
los atributos. La estructura de esta red depende del tipo de clasiﬁcador, como
veremos m´as adelante.
1.3.1
Clasiﬁcador bayesiano simple
Un clasiﬁcador bayesiano obtiene la probabilidad posterior de cada clase, Ci,
usando la regla de Bayes, como el producto de la probabilidad a priori de la
clase por la probabilidad condicional de los atributos (E) dada la clase, dividido
por la probabilidad de los atributos:
P(Ci | E) = P(Ci)P(E | Ci)/P(E)
(1.11)
El clasiﬁcador bayesiano simple (naive Bayes classiﬁer, NBC) asume que los
atributos son independientes entre s´ı dada la clase, as´ı que la probabilidad se
puede obtener por el producto de las probabilidades condicionales individuales
de cada atributo dado el nodo clase:
P(Ci | E) = P(Ci)P(E1 | Ci)P(E2 | Ci)...P(En | Ci) | Ci)/P(E)
(1.12)
Donde n es el n´umero de atributos. Esto hace que el n´umero de par´ametros se
incremente linealmente con el nmero de atributos, en vez de hacerlo en forma ex-
ponencial. Gr´aﬁcamente, un NBC se puede representar como una red bayesiana
en forma de estrella, con un nodo de la ra´ız, C, que corresponde a la variable de
la clase, que est´a conectada con los atributos, E1, E2, ..., En. Los atributos son
condicionalmente independientes dada la clase, de tal manera que no existen
arcos entre ellos. Esta estructura se ilustra en el Figura 1.6.
Dado que la estructura de una clasiﬁcador bayesiano simple est´a predeter-
minada, s´olo es necesario aprender los par´ametros asociados, que son:
P(C): vector de probabilidades a priori para cada clase.
P(Ei | C): matriz de probabilidad condicional para cada atributo dada la clase.
Estos par´ametros se pueden estimar fcilmente, a partir de los datos, en base a
frecuencias. El denominador en la ecuaci´on 1.12 no se requiere, ya que es una
constante; es decir, no depende de la clase. Al ﬁnal se pueden simplemente

10
CHAPTER 1. REDES BAYESIANAS
Figure 1.6:
Clasiﬁcador bayesiano simple.
Los atributos A1, A2, ..., An son
condicionalmente independientes dada la clase C.
normalizar las probabilidades posteriores de cada clase (haciendo que sumen
uno).
Aunque el clasiﬁcador bayesiano simple funciona muy bien (tiene una alta
precisi´on en clasiﬁcaci´on) en muchos dominios, en ocaciones su rendimiento
decrece debido a que los atributos no son condicionalmente independientes como
se asume. En las secciones siguientes veremos dos enfoques para resolver esta
limitaci´on.
1.3.2
Extensiones al clasiﬁcador bayesiano
Cuando se tienen atributos dependientes, una forma de considerar estas de-
pendencias es extendiendo la estructura b´asica de NBC agregando arcos entre
dichos atributos. Existen dos alternativas b´asicas:
TAN: clasiﬁcador bayesiano simple aumentado con un ´arbol.
BAN: clasiﬁcador bayesiano simple aumentado con una red.
En ambos casos se extiende el NBC agregando una estructura de dependencias
entre los atributos. En el TAN, se agrega una estructura de ´arbol entre los atrib-
utos, de forma que se tienen en principio ’pocas’ conexiones y no aumenta de-
masiado la complejidad de la estructura. Para el BAN se agrega una estructura
general de dependencia entre atributos, sin limitaciones. Dichas estructuras,
tanto la de ´arbol como la general, se pueden aprender mediante los algoritmos
de aprendizaje estructural que veremos m´as adelante. Una vez obtenida la es-
tructura de dependencia entre atributos, se agregan arcos de la clase a cada uno
de los atributos. La Figura 1.7 muestra un ejemplo de BAN y uno de TAN.
En algunos dominios, la precisi´on de la clasiﬁcaci´on aumenta utilizando TAN
o BAN, pero no hay uno claramente mejor al otro; y en ciertos casos el NBC

1.3. APRENDIZAJE DE CLASIFICADORES BAYESIANOS
11
Figure 1.7: Extensiones al clasiﬁcador bayesiano simple: (a) TAN, (b) BAN.
da una mayor precisi´on. La desventaja de estas extensiones es que aumenta
la complejidad (y el tiempo) tanto para aprender el modelo como para clasi-
ﬁcaci´on. Otra alternativa es tratar de mantener la misma estructura sencilla
del NBC pero considerando las dependencias entre atributos, la cual veremos a
continuaci´on.
1.3.3
Mejora estructural de un clasiﬁcador bayesiano
El clasiﬁcador bayesiano simple asume que los atributos son independientes dada
la clase. Si esto no es verdad, existen dos alternativas b´asicas. Una es trans-
formar la estructura del clasiﬁcador a una red bayesiana, introduciendo arcos
dirigidos entre los atributos dependientes, como vimos en la secci´on anterior. La
desventaja es que la simplicidad del NBC se pierde, ya que aprender el modelo
y despu´es clasiﬁcar nuevos casos llega a ser m´as complejo. La otra alternativa
es transformar la estructura pero mantener una estructura de estrella o una
estructura de ´arbol. Para esto, se introducen tres operaciones b´asicas:
1. Eliminar un atributo,
2. Unir dos atributos en una nueva variable combinada,
3. Introducir un nuevo atributo que haga que dos atributos dependientes
sean independientes (nodo oculto).
La Figura 1.8 ilustra las tres operaciones.
Para aprender el modelo se hace un proceso iterativo, en que se van probando
en forma alternada las tres operaciones, de la m´as sencilla (eliminar un atributo)
hasta la m´as compleja (introducir un nuevo atributo). Esta b´usqueda puede ser
guiada midiendo la dependencia entre pares de atributos condicionada a la clase,
de forma que los pares de atributos con mayor dependencia sean analizados

12
CHAPTER 1. REDES BAYESIANAS
Figure 1.8: Mejora estructural a un clasiﬁcador bayesiano simple. Arriba: es-
tructura original. Abajo, de izq. a derecha: eliminaci’on, uni´on, inserci´on.
primero. La dependencia se puede medir mediante el c´alculo de la informaci´on
mutua entre pares de atributos X, Y dada la clase C:
I(Xi, Xj | C) =
X
Xi,Xj
P(Xi, Xj | C)log(P(Xi, Xj | C)/P(Xi | C)P(Xj | C))
(1.13)
En base a lo anterior puede integrarse el siguiente Algoritmo de Mejora Estruc-
tural:
1. Obtener la informaci´on mutua condicional (IMC) entre cada par de atrib-
utos.
2. Seleccionar el par de atributos de IMC mayor.
3. Probar las tres operaciones b´asicas (i) eliminaci´on, (ii) uni´on, (iii) in-
serci´on.
4. Evaluar las tres estructuras alternativas y la original, y quedarse con la
’mejor’ opci´on.
5. Repetir 2–4 hasta que ya no mejore el clasiﬁcador.
Para evaluar las estructuras alternativas pueden usarse dos enfoques. Uno es
evaluar el clasiﬁcador (con datos de prueba), lo cual en principio es mejor, pero
m´as costoso. El otro enfoque consiste en medir la calidad de la estructura re-
sultante, por ejemplo, basado en el principio de longitud de descripci´on m´ınima
(MDL), el cual se describe en la siguiente secci´on. El caso de inserci´on de un
nodo es m´as complejo (ver secci´on al ﬁnal del cap´ıtulo de lecturas adicionales),

1.4. APRENDIZAJE DE REDES BAYESIANAS
13
por lo que puede implementarse el algoritmo usando s´olo las opciones de elimi-
naci´on y uni´on.
Aunque el proceso de mejora estructural es costoso computacionalmente, se
tiene la ventaja de que el clasiﬁcador resultante tiene una estructura de ´arbol,
lo cual es muy eﬁciente para clasiﬁcaci´on.
1.4
Aprendizaje de redes bayesianas
El aprendizaje, en general, de redes bayesianas consiste en inducir un modelo,
estructura y par´ametros asociados, a partir de datos.
Este puede dividirse
naturalmente en dos partes:
1. Aprendizaje estructural. Obtener la estructura o topolog´ıa de la red.
2. Aprendizaje param´etrico. Dada la estructura, obtener las probabilidades
asociadas.
Veremos primero el aprendizaje param´etrico y luego el estructural.
1.4.1
Aprendizaje param´etrico
Cuando se tienen datos completos y suﬁcientes para todas las variables en el
modelo, es relativamente f´acil obtener los par´ametros, asumiendo que la es-
tructura est´a dada. El m´etodo m´as com´un es el llamado estimador de m´axima
verosimilitud, bajo el cual se estiman las probabilidades en base a las frecuencias
de los datos. Para una red bayesiana se tienen dos casos:
• Nodos ra´ız. Se estima la probabilidad marginal. Por ejemplo: P(Ai) ∼
NAi/N, donde NAi es el n´umero de ocurrencias del valor i de la variable
A, y N es el n´umero total de casos o registros.
• Nodos hoja. Se estima la probabilidad condicional de la variable dados
sus padres. Por ejemplo: P(Bi | Aj, Ck) ∼NBiAjCk/NAjCk, donde
NBiAjCk es el n´umero de casos en que B = Bi, A = Aj y C = Ck y
NAjCk es el n´umero de casos en que A = Aj y C = Ck.
Dado que normalmente no se tienen suﬁcientes datos, se tiene incertidumbre en
las probabilidades estimadas. Esta incertidumbre se puede representar mediante
una distribuci´on de probabilidad, de forma que se considere en forma expl´ıcita
la incertidumbre sobre las probabilidades. Para el caso de variables binarias
se modela con una distribuci´on Beta y para variables multivaluadas mediante
su extensi´on, que es la distrubuci´on Dirichlet. Para el caso binario, con una
distribuci´on Beta, el valor esperado (promedio) esta.do por: P(bi) = a + 1/a +
b + 2, donde a y b son los par´ametros de la distribuci´on.
Esta representaci´on puede utilizarse para modelar la incertidumbre cuando
se tienen estimaciones de expertos, cambiando los valores de a+b, con el mismo
valor estimado. Por ejemplo:

14
CHAPTER 1. REDES BAYESIANAS
• Ignorancia completa: a=b=0.
• Poco conﬁdente: a+b peque˜no (10).
• Medianamente conﬁdente: a+b mediano (100).
• Muy conﬁdente: a+b grande (1000).
Tambi´en para combinar las estimaciones de expertos con datos. Por ejemplo,
para estimar la probabilidad marginal de una variable B:
P(bi) = k + a + 1/n + a + b + 2
(1.14)
Donde a/a+b representa la estimaci´on del experto, y k/n la estimaci´on a partir
de los datos.
Datos incompletos
En la pr´actica, en muchas ocasiones los datos no est´an completos. Hay dos tipos
b´asicos de informaci´on incompleta:
Valores faltantes: Faltan algunos valores de una de las variables en algunos
casos.
Nodos ocultos: Faltan todos los valores de una variable.
Cuando existen valores faltantes, que es el caso m´as sencillo, existen varias
alternativas, entre ellas:
• Eliminar los casos (registros) donde aparecen valores faltantes.
• Considerar un nuevo valor adicional para la variable, como ’desconocido’.
• Tomar el valor m´as probable (promedio) de la variable.
• Considerar el valor m´as probable en base a las otras variables
• Considerar la probabilidad de los diferentes valores en base a las otras
variables.
Las primeras dos alternativas pueden ser adecuadas cuando se tienen muchos
datos, pero si no, se est de alguna manera desaprovechando informaci´on. La
tercera alternativa no considera las dem´as variables del modelo, por lo que
normalmente no da los mejores resultados. La cuarta y quinta alternativa son
las m´as interesantes y en general las mejores.
Para el caso del valor m´as probable se parte de una red bayesiana inicial
construida en base a los datos completos. Posteriormente, se complementa el
modelo usando los registros con datos incompletos, en base al siguiente algo-
ritmo:
1. Asignar todas las variables observadas en el registro.

1.4. APRENDIZAJE DE REDES BAYESIANAS
15
2. Propagar su efecto y obtener las probabilidades posteriores de las no ob-
servables.
3. Para las variables no observables, asumir el valor con probabilidad mayor
como observado.
4. Actualizar las probabilidades previas y condicionales en el modelo.
5. Repetir 1 a 4 para cada observaci´on.
Esto se puede mejorar si, en vez de tomar el valor m´as probable, se considera
cada caso como varios casos parciales, en base a la probabilidad posterior de
cada valor de la variable faltante.
Cuando existen nodos ocultos, se pueden tambi´en estimar las tablas de prob-
abilidad condicional faltantes. El m´etodo m´as comnmente utilizado es el de la
’maximizaci´on de la expectaci´on’ (EM, por sus siglas en ingl´es, expectation max-
imization).
El algoritmo EM es un m´etodo estad´ıstico muy utilizado para estimar prob-
abilidades cuando hay variables no observables. Consiste b´asicamente de dos
pasos que se repiten en forma iterativa:
Paso E: se estiman los datos faltantes en base a los par´ametros actuales.
Paso M: se estiman las probabilidades (par´ametros) considerando los datos
estimados.
Para el caso de nodos ocultos en redes bayesianas, el algoritmo EM es el sigu-
iente:
1. Iniciar los par´ametros desconocidos (probabilidades condicionales) con val-
ores aleatorios (o estimaciones de expertos).
2. Utilizar los datos conocidos con los par´ametros actuales para estimar los
valores de la variable(s) oculta(s).
3. Utilizar los valores estimados para completar la tabla de datos.
4. Re-estimar los par´ametros con los nuevos datos.
5. Repetir 2–4 hasta que no haya cambios signiﬁcativos en las probabilidades.
La principal limitaci´on de EM es que puede caer en ´optimos locales, por lo que
los valores ﬁnales obtenidos pueden depender de la inicializaci´on.
Discretizaci´on de variables continuas
Normalmente las redes bayesianas consideran variables discretas o nominales,
por lo que si no lo son, hay que discretizarlas antes de construir el modelo.
Aunque existen modelos de redes bayesianas con variables continuas, estos est´an
limitados a variables gaussianas y relaciones lineales.

16
CHAPTER 1. REDES BAYESIANAS
Los m´etodos de discretizaci´on se dividen en dos tipos principales: (i) no
supervisados y (ii) supervisados (Vese el captulo dedicado a discretizacin de
variables).
Los m´etodos de no supervisados no consideran la variable clase, as´ı que
los atributos continuos son discretizados independientemente. El m´etodo m´as
simple es dividir el rango de valores cada atributo, [Xmin; Xmax], en k inter-
valos, donde k es dado por el usuario u obtenido usando una cierta medida de
informaci´on sobre los valores de los atributos.
Los m´etodos supervisados consideran la variable clase, es decir los puntos de
divisi´on para formar rangos en cada atributo son seleccionados en funci´on del
valor de la clase. El problema de encontrar el n´umero ´optimo de intervalos y de
los l´ımites correspondientes se puede considerar como un problema de b´usqueda.
Es decir, podemos generar todos los puntos posibles de divisi´on para formar
intervalos sobre la gama de valores de cada atributo (donde hay un cambio
en la clase), y estimamos el error de clasiﬁcaci´on para cada partici´on posible
(usando por ejemplo, cross validation). Desafortunadamente, la generaci´on y la
prueba de todas las posibles particiones es impr´actica, por lo que normalmente
se realiza una b´usqueda heur´ıstica.
El enfoque supervisado se aplica directamente al caso de los clasiﬁcadores
bayesianos. Por ejemplo, para un atributo continuo, A, se comienza con un
n´umero inicial de particiones. Entonces hace una b´usqueda iterativa para en-
contrar una mejor partici´on, uniendo o particionando intervalos, y probando
la exactitud del clasiﬁcador despu´es de cada operaci´on. Esta es b´asicamente
una b´usqueda ’glotona’ (hill-climbing), que se detiene cuando la exactitud ya no
puede ser mejorada.
Para el caso general de una red bayesiana, existe un m´etodo para la dis-
cretizaci´on de atributos continuos, mientras se aprende la estructura de la red
bayesiana. La discretizaci´on esta basada en el principio de MDL, considerando
el n´umero de intervalos de una variable con respecto a sus vecinos en la red.
Para una estructura dada, un procedimiento de b´usqueda local encuentra la dis-
cretizaci´on de una variable que reduce al m´ınimo la longitud de la descripci´on
referente a los nodos adyacentes en la red, y ´este se repite en forma iterativa
para cada una de las variables continuas.
1.4.2
Aprendizaje estructural
El aprendizaje estructural consiste en encontrar las relaciones de dependencia
entre las variables, de forma que se pueda determinar la topolog´ıa o estructura
de la red bayesiana.
De acuerdo al tipo de estructura, podemos dividir los
m´etodos de aprendizaje estructural en:
• Aprendizaje de ´arboles.
• Aprendizaje de poli´arboles.
• Aprendizaje de redes multiconectadas.

1.4. APRENDIZAJE DE REDES BAYESIANAS
17
Para el caso m´as general, que es el de redes multiconectadas, existen dos
clases de m´etodos:
1. M´etodos basados en medidas y b´usqueda.
2. M´etodos basados en relaciones de dependencia.
A continuaci´on veremos el m´etodo para aprendizaje de ´arboles y su ex-
tensi´on a poli´arboles, para despu´es ver los dos enfoques para aprender redes
multiconectadas.
1.4.3
Aprendizaje de ´arboles
El aprendizaje de ´arboles se basa en el algoritmo desarrollado por Chow y Liu
para aproximar una distribuci´on de probabilidad por un producto de probabil-
idades de segundo orden (´arbol). La probabilidad conjunta de n variables se
puede representar como:
P(X1, X2, ..., Xn) =
n
Y
i=1
P(Xi | Xj(i))
(1.15)
donde Xj(i) es el padre de Xi.
Para obtener el ´arbol se plantea el problema como uno de optimizaci´on:
obtener la estructura de ´arbol que m´as se aproxime a la distribuci´on ’real’. Esto
se basa en una medida de la diferencia de informaci´on entre la distribuci´on real
(P) y la aproximada (P∗):
DI(P, P∗) =
X
X
P(X)log(P(X)/P ∗(X))
(1.16)
El objetivo es minimizar DI. Se puede deﬁnir dicha diferencia en funci´on de la
informaci´on mutua entre pares de variables, que se deﬁne como:
I(Xi, Xj) =
X
Xi,Xj
P(Xi, Xj)log(P(Xi, Xj)/P(Xi)P(Xj))
(1.17)
Se puede demostrar que la diferencia de informaci´on es una funci´on del negativo
de la suma de las informaciones mutuas (pesos) de todos los pares de variables
que constituyen el ´arbol. Entonces, encontrar el ´arbol m´as pr´oximo equivale a
encontrar el ´arbol con mayor peso.
Podemos entonces encontrar el ´arbol ´optimo mediante el siguiente algoritmo,
que es equivalente al conocido problema del maximum weight spanning tree:
1. Calcular la informaci´on mutua entre todos los pares de variables (que para
n variables, son n(n −1)/2).
2. Ordenar las informaciones mutuas de mayor a menor.
3. Seleccionar la rama de mayor valor como ´arbol inicial.

18
CHAPTER 1. REDES BAYESIANAS
4. Agregar la siguiente rama mientras no forme un ciclo, si es as´ı, desechar.
5. Repetir 4 hasta que se cubran todas las variables (n-1 ramas).
El algoritmo NO provee la direcci´on de los arcos, por lo que ´esta se puede asignar
en forma arbitraria o utilizando sem´antica externa (experto).
Para ilustrar el algoritmo consideremos el cl´asico ejemplo del jugador de
golf (o de tenis, segn distintas versiones), en el cual se tienen cuatro variables:
juega, ambiente, humedad y temperatura. Obtenemos entonces las informaciones
mutuas de cada par de variables (10 en total), que se muestran en la Tabla 1.1.
No.
Var 1
Var 2
Info. mutua
1
temp.
ambiente
.2856
2
juega
ambiente
.0743
3
juega
humedad
.0456
4
juega
viento
.0074
5
humedad
ambiente
.0060
6
viento
temp.
.0052
7
viento
ambiente
.0017
8
juega
temp.
.0003
9
humedad
temp.
0
10
viento
humedad
0
Table 1.1: Informaci´on mutua entre pares de variables para el ejemplo del golf.
En este caso seleccionamos las primeras 4 ramas y generamos el ´arbol que
se ilustra en la Figura 1.9. Las direcciones de las ligas han sido asignadas en
forma arbitraria.
Figure 1.9: Ejemplo de golf. ´Arbol obtenido mediante el algoritmo de apren-
dizaje de ´arboles. J es juega, A es ambiente, H es humedad y T es temperatura.

1.4. APRENDIZAJE DE REDES BAYESIANAS
19
1.4.4
Aprendizaje de poli´arboles
Una forma de darle direcciones al ’esqueleto’ aprendido con el algoritmo de
Chow y Liu, es mediante pruebas de independencias no s´olo entre dos variables,
sino entre grupos de tres variables o tripletas. Mediante este esquema se genera
un algoritmo que aprende poli´arboles, ya que al signar las direcciones puede ser
que la estructura generada sea un ´arbol o un poli´arbol (en realidad, un ´arbol es
un caso especial de poli´arbol).
El algoritmo parte del esqueleto (estructura sin direcciones) obtenido con
el algoritmo de Chow y Liu. Despu´es se determinan las direcciones de los ar-
cos utilizando pruebas de dependencia entre tripletas de variables. Dadas tres
variables, existen tres casos posibles:
1. Arcos secuenciales: X →Y →Z.
2. Arcos divergentes: X ←Y →Z.
3. Arcos convergentes: X →Y ←Z.
Los primeros dos casos son indistinguibles en base a pruebas de independencias;
es decir, son equivalentes. En ambos, X y Z son independientes dado Y . Pero
el tercero es diferente, ya que las variables X y Z son marginalmente independi-
entes. Este tercer caso lo podemos usar para determinar entonces las direcciones
de los dos arcos que unen estas tres variables, y a partir de ´estos, es posible en-
contrar las direcciones de otros arcos utilizando pruebas de independencia. De
acuerdo a lo anterior, se establece el siguiente algoritmo para aprendizaje de
poli´arboles:
1. Obtener el esqueleto utilizando el algoritmo de Chow y Liu.
2. Recorrer la red hasta encontrar una tripleta de nodos que sean conver-
gentes, donde la variable a la que apuntan los arcos la llamaremos nodo
multipadre.
3. A partir de un nodo multipadre, determinar las direcciones de otros arcos
utilizando la prueba de dependencia de tripletas, hasta donde sea posible
(base causal).
4. Repetir 2-3 hasta que ya no se puedan descubrir m´as direcciones.
5. Si quedan arcos sin direccionar, utilizar sem´antica externa para obtener
su direcci´on.
Consideremos nuevamente el ejemplo del golf, y el esqueleto obtenido (red sin
las direcciones), para ilustrar el m´etodo. Supongamos que H, J, V corresponden
al caso convergente, entonces los arcos apuntan de H a J y de V a J. Despu´es
se prueba la dependencia entre H y V respecto a A dado J. Si resulta que
H, V son independientes de A dado J, entonces hay un arco que apunta de J a
A. Finalmente, probamos la relaci´on de dependencia entre J y T dado A, y si
nuevamente fueran independientes, entonces el arco apunta de A hacia T. La
Figura 1.10 muestra la estructura resultante.

20
CHAPTER 1. REDES BAYESIANAS
Figure 1.10: Ejemplo de golf.
Poli´arbol obtenido mediante el algoritmo de
aprendizaje.
1.4.5
Aprendizaje de redes
Como comentamos previamente, existen dos clases de m´etodos para el apren-
dizaje gen´erico de redes bayesianas, que incluyen redes multiconectadas. Estos
son:
1. M´etodos basados en medidas de ajuste y b´usqueda.
2. M´etodos basados en pruebas de independencia.
A continuaci´on veremos ambos enfoques.
Aprendizaje basado en medidas globales
En esta clase de m´etodos se tiene una evaluaci´on global de la estructura respecto
a los datos. Es decir, se generan diferentes estructuras y se eval´uan respecto
a los datos utilizando alguna medida de ajuste. Existen diferentes variantes
de estos m´etodos que dependen b´asicamente de dos aspectos principales: (i)
medida de ajuste de la estructura a los datos, y (ii) m´etodo de b´usqueda de la
mejor estructura.
Hay varias posibles medidas de ajuste, las dos m´as comunes son la medida
bayesiana y la medida basada en el principio de longitud de descripci´on m´ınima
(MDL). La medida bayesiana busca maximizar la probabilidad de la estructura
dados los datos, esto es:
P(Bs | D)
(1.18)
donde Bs es la estructura y D son los datos.
La cual podemos escribir en
t´erminos relativos al comparar dos estructuras, i y j, como:
P(Bsi | D)/P(Bsj | D) = P(Bsi, D)/P(Bsj, D)
(1.19)

1.4. APRENDIZAJE DE REDES BAYESIANAS
21
Considerando variables discretas y que los datos son independientes, las estruc-
turas se pueden comparar en funci´on del n´umero de ocurrencias (frecuencia) de
los datos predichos por cada estructura.
La medida MDL hace un compromiso entre la exactitud y la complejidad
del modelo. La exactitud se estima midiendo la informaci´on mutua entre los
atributos y la clase; y la complejidad contando el n´umero de par´ametros. Una
constante, α, en [0, 1], se utiliza para balancear el peso de cada aspecto, exac-
titud contra complejidad. As´ı, la medida de calidad est´a dada por:
MC = α(W/Wmax) + (1 −α)(1 −L/Lmax)
(1.20)
donde W representa la exactitud del modelo y L la complejidad, mientras que
Wmax y Lmax representan la m´axima exactitud y complejidad, respectiva-
mente.
Para determinar estos m´aximos normalmente se considera una lim-
itaci´on en cuanto al n´umero de padres m´aximo permitido por nodo. Un valor
α = 0.5 da la misma importancia a complejidad y exactitud, mientras que un
valor cercano a 0 considera darle mayor importancia a la complejidad y cercano
a uno mayor importancia a exactitud.
La complejidad est´a dada por el n´umero de par´ametros requeridos para
representar el modelo, la cual se puede calcular con la siguiente ecuaci´on:
L = Si[kilog2n + d(Si −1)Fi]
(1.21)
Donde, n es el n´umero de nodos, k es el n´umero de padres por nodo, Si es el
n´umero de valores promedio por variable, Fi el n´umero de valores promedio de
los padres, y d el n´umero de bits por par´ametro.
La exactitud se puede estimar en base al ’peso’ de cada nodo, en forma
an´aloga a los pesos en el m´etodo de aprendizaje de ´arboles. En este caso el peso
de cada nodo, xi, se estima en base a la informaci´on mutua con sus padres, Fxi:
w(xi, Fxi) =
X
xi
P(xi, Fxi)log[P(xi, Fxi)/P(xi)P(Fxi)]
(1.22)
y el peso (exactitud) total est´a dado por la suma de los pesos de cada nodo:
W =
X
i
w(xi, Fxi)
(1.23)
Una vez establecida una forma de medir la calidad de una estructura, se
establece un m´etodo para hacer una b´usqueda de la ’mejor’ estructura entre
todas las estructuras posibles. Dado que el n´umero de posibles estructuras es
exponencial en el n´umero de variables, es imposible evaluar todas las estruc-
turas, por lo que se hace una b´usqueda heur´ıstica. Se pueden aplicar diferentes
m´etodos de b´usqueda. Una estrategia com´un es utilizar b´usqueda de ascenso de
colinas (hill climbing), en la cual se inicia con una estructura simple (´arbol) que
se va mejorando hasta llegar a la ’mejor’ estructura. El algoritmo de bsqueda
de la mejor estructura es el siguiente:
1. Generar una estructura inicial - ´arbol.

22
CHAPTER 1. REDES BAYESIANAS
2. Calcular la medida de calidad de la estructura inicial.
3. Agregar / invertir un arco en la estructura actual.
4. Calcular la medida de calidad de la nueva estructura.
5. Si se mejora la calidad, conservar el cambio; si no, dejar la estructura
anterior.
6. Repetir 3 a 5 hasta que ya no haya mejoras.
El algoritmo anterior no garantiza encontrar la estructura ´optima, ya que puede
llegar a un m´aximo local.
Se pueden utililzar otros m´etodos de b´usqueda
como algoritmos gen´eticos, recocido simulado, b´usquedas bidireccionales, etc.
La Figura 1.11 ilustra el procedimiento de b´usqueda para el ejemplo del golf,
inciando con una estructura de ´arbol que se va mejorando hasta llegar a una
estructura ﬁnal.
Figure 1.11: Ejemplo de golf. Algunos pasos en la secuencia del aprendizaje de
la estructura, partiendo de un ´arbol (izquierda) hasta llegar a la estructura ﬁnal
(derecha).
Aprendizaje basado en pruebas de independencia
A diferencia del enfoque basado en una medida global, este enfoque se basa en
medidas de dependencia local entre subconjuntos de variables. El caso m´as sen-
cillo es el del algoritmo de Chow y Liu, en el cual se mide la informaci´on mutua
entre pares de variables. A partir de estas medidas, como se vi´o previamente,
se genera una red bayesiana en forma de ´arbol. Analizando dependencias entre
tripletas de variables, el m´etodo se extiende a poli´arboles.
Este enfoque se puede generalizar para el aprendizaje de redes multiconec-
tadas, haciendo pruebas de dependencia entre subconjuntos de variables, nor-
malmente dos o tres variables. Por ejemplo, se puede continuar el m´etodo de
Chow y Liu agregando m´as arcos aunque se formen ciclos, hasta un cierto umbral
m´ınimo de informaci´on mutua. La desventaja es que pueden generarse muchos
arcos ’innecesarios’, por lo que se incorporan formas de luego eliminar arcos.

1.5. APRENDIZAJE DE REDES BAYESIANAS DIN ´AMICAS
23
Hay diferentes variantes de este enfoque que consideran diferentes medidas de
dependencia y diferentes estrategias para eliminar arcos innecesarios.
1.5
Aprendizaje de redes bayesianas din´amicas
1.5.1
Redes bayesianas din´amicas
Las redes bayesianas, en principio, representan el estado de las variables en
un cierto momento en el tiempo. Para representar procesos din´amicos existe
una extensi´on a estos modelos conocida como red bayesiana din´amica (RBD).
Consiste en una representaci´on de los estados del proceso en un tiempo (red
est´atica) y las relaciones temporales entre dichos procesos (red de transici´on).
Se pueden ver como una generalizaci´on de las cadenas (ocultas) de Markov.
Para las RBD generalmente se hacen las siguientes suposiciones:
• Proceso markoviano. El estado actual s´olo depende del estado anterior
(s´olo hay arcos entre tiempos consecutivos).
• Proceso estacionario en el tiempo. Las probabilidades condicionales en el
modelo no cambian con el tiempo.
Lo anterior implica que podemos deﬁnir una red bayesiana din´amica en base a
dos componentes: (i) una red base est´atica que se repite en cada periodo, de
acuerdo a cierto intervalo de tiempo predeﬁnido; y (ii) una red de transici´on
entre etapas consecutivas (dada la propiedad markoviana). Un ejemplo de una
RBD se muestra en la Figura 1.12.
La inferencia en RBD es en principio la misma que para RB, por lo que
aplican los mismos m´etodos.
Sin embargo, la complejidad aumenta, por lo
que son m´as comunes los m´etodos basados en simulaci´on estoc´astica, como los
m´etodos MoneCarlo y los ﬁltros de part´ıculas.
1.5.2
Aprendizaje
Dada la representaci´on de una RBD en base a dos componentes, la estructura
base y la red de transici´on, el aprendizaje de RBD puede naturalmente dividirse
en el aprendizaje de cada parte por separado:
1. Aprender la estructura base (est´atica).
2. Aprender la estructura de transici´on.
Para aprender la estructura base, se consideran los datos de todas las vari-
ables en cada tiempo, de forma que sea posible obtener las dependencias entre
´estas sin considerar las relaciones temporales. Entonces el problema es equiva-
lente al aprendizaje estructural y param´etrico de una red bayesiana, y se pueden
aplicar cualquiera de los m´etodos vistos anteriormente.
Dada la estructura base, se aprende la red de transici´on. Esto se puede re-
alizar usando ambos enfoques, tanto el basado en medidas de ajuste y b´usqueda,

24
CHAPTER 1. REDES BAYESIANAS
Figure 1.12: Ejemplo de una red bayesiana din´amica. Se muestra la estruc-
tura base que se repite en cuatro etapas temporales, as´ı como las relaciones de
dependencia entre etapas.
Figure 1.13: Aprendizaje de una red bayesiana din´amica. Primero se obtiene la
estructura base (izquierda) y despu´es las relaciones entre etapas (derecha).
como el de medidas locales; con ciertas variantes. Si se utiliza el enfoque basado
en b´usqueda, se parte de una estructura inicial con dos copias de la red base, y
se busca agregar las ligas entre variable en el tiempo T y T +1 que optimizen la
medida de evaluaci´on. Para ello se consideran los datos de cada variable en un
tiempo y el siguiente (de acuerdo al periodo predeﬁnido). Para el enfoque de
medidas locales, se aplican ´estas a las variables entre etapas para de esta forma
determinar los arcos a incluirse en la red de transici´on. La Figura 1.13 ilustra

1.6. LECTURAS ADICIONALES
25
el esquema general de aprendizaje de una RBD para un ejemplo sencillo.
1.6
Lecturas adicionales
Las redes bayesianas surgieron en los aos ochenta, y un libro que tuvo un im-
portante impacto es el libro de Judea Pearl [Pearl, 1988], que presenta una
muy buena introducci´on general a redes bayesianas, principalmente en cuanto
a representaci´on e inferencia. A partir de entonces se han publicado varios li-
bros de redes bayesianas, entre otros Neapolitan [Neapolitan, 1990] y Jensen
[Jensen, 2001]. Recientemente se han publicado algunos libros m´es enfocados
al aprendizaje de redes bayesianas [Borglet and Kruse, 2002, Neapolitan, 2004].
Otra introducci´on general a aprendizaje en redes bayesianas es el tutorial de
Heckerman y otros [Heckerman, 1995].
El algoritmo para propagaci´on en ´arboles es introducido por Pearl [Pearl, 1986,
Pearl, 1988], mientras que el que se basa en la transformaci´on a un ´arbol
de uniones por Lauritzen y Spiegelhalter [Lauritzen and Spiegelhalter, 1988].
Cooper demuestra que el problema de propagaci´on en redes bayesianas es, en
general, un problema NP-duro [Cooper, 1990].
Los diferentes enfoques para clasiﬁcadores bayesianos se presentan en [Friedman et al., 1997],
y una comparaci´on emp´ırica en [Cheng and Greiner, 1999]. La idea de la mejora
estructural de clasiﬁcadores bayesianos fue introducida originalmente en [Sucar, 1992,
Sucar et al., 1993] y posteriormente por [Pazzani, 1996].
En [Pazzani, 1995] se presnta un m´etodo para la discertizaci´on de atributos
en clasiﬁcadores bayesianos. Friedman y otros [Friedman and Goldszmidt, 1996]
introducen una t´ecnica para disctretizar atributos continuos para al aprendizaje
de redes bayesianas en general.
Una introducci´on general a los m´etodos de
discretizaci´on se presenta en [Dougherty et al., 1998].
El algoritmo para aprendizaje de ´arboles fue introducido por Chow y Liu
[Chow and Liu, 1968], y posteriormente extendido a poli´arboles por Rebane y
Pearl [Pearl, 1988]. La idea de usar el principio MDL para aprendizaje de re-
des bayesianas es originalmente de [Lam and Bacchus, 1994]. Mart´ınez lo aplica
para el aprendizaje interactivo de redes bayesianas [Mart´ınez-Arroyo, 1997]. En-
foques alternativos para el aprendizaje estructural de redes bayesianas se pre-
sentan en [Cooper and Herskovitz, 1992, Heckerman et al., 1994], entre otros.
Existen diversas herramientas p´ublicas y comerciales para edici´on, inferencia
y aprendizaje de redes bayesianas. Entre ´estas se encuentra el sistema Elvira
[Elvira Consortium, 2002].

26
CHAPTER 1. REDES BAYESIANAS

Bibliography
[Borglet and Kruse, 2002] Borglet, C. and Kruse, R. (2002). Graphical Models:
Methdos for Data Analysis and Mining. Wiley, West Sussex, England.
[Cheng and Greiner, 1999] Cheng, J. and Greiner, R. (1999).
Comparing
bayesian network classiﬁers. Proceedings of the Fifteenth Conference on Un-
certainty in Ariﬁcial intelligence, pages 101–108.
[Chow and Liu, 1968] Chow, C. and Liu, C. (1968). Approximating discrete
probability distributions with dependence trees. IEEE Trans. on Info. The-
ory, 14:462–467.
[Cooper, 1990] Cooper, G. (1990). The computational complexity of probabilis-
tic inference using bayesian networks. Artiﬁcial Intelligence, 42:393–405.
[Cooper and Herskovitz, 1992] Cooper, G. and Herskovitz, E. (1992).
A
bayesian method for the induction of probabilistic networks from data. Ma-
chine Learning, 9(4):309–348.
[Dougherty et al., 1998] Dougherty, J., Kohavi, R., and Sahami, M. (1998). Su-
pervised and unsupervised discretization of continuous features.
Machine
Learning: Proceedings of the Twelfth International Conference on Artiﬁcial
Intelligence, pages 194–2002.
[Elvira Consortium, 2002] Elvira Consortium, T. (2002). Elvira: An environ-
ment for creating and using probabilistic graphical models. In Proceedings
of the First European Workshop on Probabilistic graphical models (PGM’02),
pages 1–11, Cuenca, Spain.
[Friedman et al., 1997] Friedman, N., Geiger, D., and Goldszmidt, M. (1997).
Bayesian network classiﬁers. Machine Learning, 29:131–163.
[Friedman and Goldszmidt, 1996] Friedman, N. and Goldszmidt, M. (1996).
Discretizing continuous attributes while learning bayesian networks.
13th
International Conference on Machine Learning (ICML), pages 157–165.
[Heckerman, 1995] Heckerman, D. (1995). A tutorial on learning with bayesian
networks. Technical Report MSR-TR-95-06, Microsoft Research, U.S.A.
27

28
BIBLIOGRAPHY
[Heckerman et al., 1994] Heckerman, D., Geiger, D., and Chickering, D. (1994).
Learning Bayesian networks: The combination of knowledge and statistical
data. In Proceedings of the Tenth Annual Conference on Uncertainty in Ar-
tiﬁcial Intelligence (UAI–94), pages 293–301, Seattle, WA.
[Jensen, 2001] Jensen, F. (2001).
Bayesian Networks and Decision Graphs.
Springer-Verlag, New York, U.S.A.
[Lam and Bacchus, 1994] Lam, W. and Bacchus, F. (1994). Learning bayesian
belief netwoks: An aproach based on the mdl principle. Computational Intel-
ligence, 10:269–293.
[Lauritzen and Spiegelhalter, 1988] Lauritzen,
S. and Spiegelhalter,
D. J.
(1988). Local computations with probabilities on graphical structures and
their application to expert systems. Journal of the Royal Statistical Society
series B, 50(2):157–224.
[Mart´ınez-Arroyo, 1997] Mart´ınez-Arroyo, M. (1997). Aprendizaje Interactivo
de Redes Bayesianas Multiconectadas. MSc thesis, Instituto Tecnolgico y de
Estudios Superiores de Monterrey - Campus Cuernavaca.
[Neapolitan, 2004] Neapolitan, R. (2004). Learning Bayesian Networks. Pren-
tice Hall, New Jersey.
[Neapolitan, 1990] Neapolitan, R. E. (1990). Probabilistic resoning in expert
systems. John Wiley & Sons, New York, U.S.A.
[Pazzani, 1995] Pazzani, M. J. (1995). An iterative improvement approach for
the discretization of numeric attributes in bayesian classiﬁers. KDD95, pages
228–233.
[Pazzani, 1996] Pazzani, M. J. (1996). Searching for atribute dependencies in
bayesian classiﬁers. In preliminary Papers of the Intelligence and Statistics,
pages 424–429.
[Pearl, 1986] Pearl, J. (1986).
Fusion, propagation and structuring in belief
networks. Artiﬁcial Intelligence, 29:241–288.
[Pearl, 1988] Pearl, J. (1988).
Probabilistic reasoning in intelligent systems.
Morgan Kaufmann, Palo Alto, Calif., U.S.A.
[Sucar, 1992] Sucar, L. (1992). Probabilistic reasoning in knowledge based vi-
sion systems. PhD dissertation, Imperial College of Science, Technology, and
Medicine, London U.K.
[Sucar et al., 1993] Sucar, L., Gillies, D., and Gillies, D. (1993). Objective prob-
abilities in expert systems. Artiﬁcial Intelligence, 61:187–208.

