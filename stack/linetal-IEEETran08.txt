1
On Self-Interested Agents in Vehicular Networks
with Car-to-Car Gossiping
Sarit Kraus, Raz Lin, and Yuval Shavitt
Abstract—As more and more cars are equipped with GPS
and Wi-Fi transmitters, it becomes easier to design systems
that will allow cars to interact autonomously with each other,
e.g., regarding trafﬁc on the roads. Indeed, car manufacturers
are already equipping their cars with such devices. Though,
currently these systems are a proprietary, we envision a natural
evolution where agent applications will be developed for vehicular
systems, e.g., to improve car routing in dense urban areas.
Nonetheless, this new technology and agent applications may lead
to the emergence of self-interested car owners, who will care
more about their own welfare than the social welfare of their
peers. These car owners will try to manipulate their agents such
that they transmit false data to their peers. Using a simulation
environment, which models a real transportation network in a
large city, we demonstrate the beneﬁts achieved by self-interested
agents if no counter-measures are implemented. We then proceed
to describe mechanisms for minimizing the effect of the malicious
agents on other agents in the network.
Index Terms—agent-based deployed applications, intelligent
agents, peer to peer networks, transportation networks.
I. INTRODUCTION
A
S technology advances, more and more cars are being
equipped with devices, which enable them to act as
autonomous agents. An important advancement in this respect
is the introduction of ad-hoc communication networks (such
as Wi-Fi), which enable the exchange of information between
cars, e.g., for locating road congestions [1] and optimal routes
[2] or improving trafﬁc safety [3].
Agent technology, which allows cars to interact au-
tonomously, is becoming recognized by car manufactures as an
important aspect in deploying future intelligent cars ([4], [5]).
For example, GM [4] develops vehicles with a “sixth sense”
that, through Vehicular-to-Vehicular (V2V) communication,
allows vehicles to detect movement of other vehicles and
use this technology to provide more safety for the driver.
The U.S. Department of Transportation is also promoting
the Vehicle Infrastructure Integration initiative (VII) [6], with
the vision that every car manufactured in the U.S. will be
equipped with a communication device and a GPS unit so
that data can be exchanged via a nationwide, instrumented
roadway system. In addition, “vehicles could serve as data
collectors and anonymously transmit trafﬁc and road condition
information from every major road within the transportation
network” [6].
S. Kraus and R. Lin are with the Department of Computer Science, Bar-
Ilan University, Ramat-Gan, Israel 52900.
E-mail: {linraz,sarit}@cs.biu.ac.il
Y. Shavitt is with the School of Electrical Engineering, Tel-Aviv University,
Israel 69978.
E-mail: shavitt@eng.tau.ac.il
We build on the notion of Gossip Networks, introduced
by Shavitt and Shay [2], in which the agents can obtain
road congestion information by gossiping with peer agents
using ad-hoc communication. We ﬁrst investigate the attraction
of being a selﬁsh agent in vehicular networks. That is, we
investigate the beneﬁts achieved by car owners, who tamper
with on-board devices and incorporate their own self-interested
agents in them, which act for their beneﬁt by exchanging false
data with other agents.
We recognize two typical behaviors that the self-interested
agents could embark upon, in the context of vehicular net-
works. In the ﬁrst, described in Section IV, the objective of
the self-interested agents is to maximize their own utility,
expressed by their average journey duration. This situation
can be modeled in real life by car owners, whose aim is to
reach their destination as fast as possible, and who would
like to have their route free of other cars. To this end the
self-interested agents would let their agents cheat the other
agents, by injecting false information into the network. This
is achieved by reporting heavy trafﬁc values for the roads on
their route to other agents in the network in the hope of making
the other agents believe that the route is jammed, and causing
them to choose a different way.
The second type of behavior, described in Section V, is
modeled by the self-interested agents’ objective to cause
disorder in the network, more than they are interested in
maximizing their own utility. This kind of behavior could be
generated, for example, by vandals or terrorists, who aim to
cause as much mayhem in the network as possible.
We note that the introduction of self-interested agents into
the network, would most probably motivate other agents to
try and detect these agents in order to minimize their effect.
This is similar, though in a different context, to the problem
introduced by Lamport et al. [7] as the Byzantine Generals
Problem. However, the mechanism introduced in [7] and a long
line of consequent works that deal with self-interested agents
are costly and time consuming. In this paper we focus mainly
on the attractiveness of selﬁsh behavior by these agents,
though we also provide some insights into the possibility of
detecting self-interested agents and minimizing their effect on
other agents in the network.
Because of the complexity of mathematically analyzing
dynamic networks, to demonstrate the beneﬁts achieved by
self-interested agents, we have used a simulation environment,
which models the transportation network in a central part
of a large real city. To this end we extended the micro
simulation tool (see [8], [9], [10] for other micro simulators)
proposed in [11] which supports the use of gossiping between
individual cars to support the different behaviors of agents (see

2
Sections IV, V, and VI for the description of the different
behaviors). The simulation environment is further described
in Section III. Our simulations provide insights to the beneﬁts
of self-interested agents that cheat. Our ﬁndings can motivate
future research in this ﬁeld in order to minimize the effect of
selﬁsh-agents. Finally, in Section VI we describe mechanisms
for minimizing the effect of the malicious agents on other
agents in the network. In Section VII we show the results of
malicious agents forming coalitions to overcome the protection
mechanisms implemented by gossip agents.
We begin by reviewing related work in the ﬁeld of self-
interested agents and V2V communications.
II. RELATED WORK
In their seminal paper, Lamport et al. [7] describe the Byzan-
tine Generals problem, in which processors need to handle
malfunctioning components that give conﬂicting information
to different parts of the system. They also present a model in
which not all agents are connected, and thus an agent is not
able to send a message to all the other agents. Dolev et al. [12]
has built on this problem and has analyzed the number of
faulty agents that can be tolerated in order to eventually reach
the right conclusion about true data. Similar work is presented
by Minsky et al. [13], who discuss techniques for constructing
gossip protocols that are resilient to up to t malicious host
failures. As opposed to the above works, our work focuses
on vehicular networks, in which agents constantly roam the
network and exchange data. Also, the domain of transportation
networks introduces dynamic data, as the load of the roads is
subject to change. In addition, transportation networks systems
include a feedback mechanism, since the load of the roads
depends on the reports and the movement of the agents
themselves.
Malkhi et al. [14] present a gossip algorithm for propagating
information in a network of processes, in the presence of
malicious parties. Their algorithm prevents the spreading of
spurious gossip and diffuses genuine data. This is done in
time, which is logarithmic in the number of processes and
linear in the number of corrupt parties. Nevertheless, their
work assumes that the network is static and also that the agents
are static (they discuss a network of processes). This is not
true for transportation networks. Transportation networks, by
nature, are dynamic. The agents constantly move and the data
changes over time. For example, in our model, agents might
gossip about a heavy trafﬁc load on a speciﬁc road, which is
currently jammed. Nonetheless, this information might be false
several minutes later, leaving the agents to speculate whether
the spreading agents are indeed malicious. In addition, as the
agents are constantly moving, each agent cannot choose with
whom it interacts and exchanges data.
In the context of analyzing the data and its correctness,
researchers have focused on distributed reputation systems or
on mechanisms to decide whether to share data. Yu and Singh
[15] built a social network of agents’ reputations. In their
network every agent keeps a list of its neighbors, which can be
changed over time, and computes the trustworthiness of other
agents by updating the current values of testimonies obtained
from reliable referral chains. After a bad experience with an-
other agent every agent decreases the rating of the ‘bad’ agent
and propagates this bad experience throughout the network so
that other agents can update their ratings accordingly. This
approach could be implemented in our domain to allow the
agents, by gossiping with their peer agents, to identify self-
interested agents and thus minimize their effect. However, the
implementation of such a mechanism is an expensive addition
to the infrastructure of autonomous agents in transportation
networks, mainly due to the dynamic nature of the list of
neighbors in such networks.
Leckie et al. [16] study when to share information between
the agents in the network. Their domain involves monitoring
distributed sensors. Each agent monitors a subset of the sensors
and evaluates a hypothesis based on the local measurements
of its sensors. If the agent believes that a hypothesis is likely
he exchanges this information with the other agents. In their
domain, the goal of all the agents is to reach a global consensus
about the likelihood of the hypothesis. In our domain, however,
as the agents constantly move, they have many samples, which
they exchange with each other. Also, the data is dynamic (e.g.,
a road might be reported as jammed, but a few minutes later
it could be free), thus making it harder to decide whether to
trust the agent, who sent the data. Moreover, the agent might
lie only about a subset of its samples, thus making it even
harder to detect his cheating.
Some work has been done in the context of gossip networks
or transportation networks regarding the spreading of data
and its dissemination. Datta et al. [17] focus on informa-
tion dissemination in mobile ad-hoc networks (MANET).
They propose an autonomous gossiping algorithm for an
infrastructure-less mobile ad-hoc networking environment.
Their autonomous gossiping algorithm uses a greedy mech-
anism to spread data items in the network. The data items
are spread to immediate neighbors that are interested in
the information, and avoid ones that are not interested. The
decision which node is interested in the information is made
by the data item itself, using heuristics. However, their work
concentrates on the movement of the data itself, and not on
the agents who propagate the data. This is different from
our scenario in which each agent maintains the data it has
gathered, while it roams the road and is responsible (and has
the capabilities) for spreading the data to other agents in the
network.
Das et al. [18] propose a cooperative strategy for con-
tent delivery in vehicular networks. In their domain, peers
download a ﬁle from a mesh and exchange parts of the ﬁle
among themselves. We, on the other hand, are interested in
vehicular networks in which there is no rule forcing the agents
to cooperate.
Shibata et al. [19] propose a method for cars to coop-
eratively and autonomously collect trafﬁc jam statistics to
estimate the arrival time to destinations of each car. The
communication is based on IEEE 802.11, without having to
utilize a ﬁxed infrastructure on the ground. While we use
the same domain, we focus on a different problem. Shibata
et al. [19] mainly focus on efﬁciently broadcasting the data
between agents (e.g., avoid duplicates and communication

3
overhead), while we focus on the case where agents are not
cooperative by nature, and on how selﬁsh agents affect other
agents and the network load.
Kraus et al. [11] describe a simulation tool which supports
the use of gossiping between individual cars to support the
different behavior of each car. In their model, they assume that
drivers learn the expected congestion on the roads and some
of them have a gossiping system that help them learn about
congestion on distant roads. They study the information prop-
agation speed in an urban network and quantify its advantage
to drivers on the road. While we use the same simulation tool,
we focus on a different problem and investigate the effects of
self-interested and malicious agents on the other drivers in the
network.
Wang et al. [20] also assert that individual agents are
likely to act selﬁshly in the context of wireless networks.
They design a protocol for communication in networks in
which all agents are selﬁsh. Their protocol motivates every
agent to maximize its proﬁt only when it behaves truthfully
(an incentive compatibility mechanism). However, the domain
of wireless networks is quite different from the domain of
transportation networks. In the wireless network, a wireless
terminal is required to contribute its local resources to transmit
data. Thus, Wang et al. [20] use a payment mechanism,
which attaches costs to terminals when transmitting data, and
thus enables them to maximize their utility when transmitting
data, instead of acting selﬁshly. Disparately, in the context
of transportation networks, constructing such a mechanism
is not quite a straightforward task, as self-interested agents
and regular gossip agents might incur the same cost when
transmitting data. The difference between the two types of
agents only exists regarding the credibility of the data they
exchange.
In the next section, we will describe our transportation
network model and gossiping between the agents. We will
also describe the types of agents in our system.
III. MODEL AND SIMULATIONS
In our simulations we wanted to model a scenario in which
drivers roam the city, with the objective of traveling from
one point to another, and observe what happens when self-
interested drivers are also present. To this end, we devised
different scenarios and settings. We ﬁrst describe our trans-
portation network model, and then we depict the simulations’
designs.
A. The Transportation Network Model
Following Shavitt and Shay [2] and Parshani ([11], [21]),
the transportation network is represented by a directed graph
G(V, E), where V is the set of vertices representing junctions,
and E is the set of edges, representing roads. An edge e ∈E
is associated with a weight w > 0, which speciﬁes the time
it takes to traverse the road associated with that edge. The
roads’ weights vary in time according to the network (trafﬁc)
load. Each car, which is associated with an autonomous agent,
is given a pair of origin and destination vertices. A journey
is deﬁned as the (not necessarily simple) path taken by an
agent between the origin vertex and the destination vertex.
We assume that there is always a path between a source
and a destination. A journey length is deﬁned as the sum of
all weights of the edges constituting it. Every agent aims to
minimize its journey length.
At a given time, an agent may have inaccurate information
about the weights and no information on how the weights may
change over time. We assume that an agent, which travels
from vertex v1 ∈V to v2 ∈V , will search for the shortest
path between these two vertices, based on its current available
information, and will move accordingly. Once, its information
about the network has been updated, it will randomly decide
whether to recalculate the shortest path or to keep on moving
and follow its current route. If there is more than one path
that is associated with the shortest distance, one of them will
be chosen randomly.
Initially, agents are ignorant about the state of the roads.
Regular agents are only capable of gathering information
about the roads as they traverse them. However, we assume
that some agents have means of inter-vehicle communication
(e.g., IEEE 802.11) with a given communication range, which
enables them to communicate with other agents with the same
device. Those agents are referred to as gossip agents. Since the
communication range is limited, the exchange of information
using gossiping is done in one of two ways: (a) between
gossip agents passing one another, or (b) between gossip
agents located at the same junction. We assume that each agent
stores the most recent information it has received or gathered
around the edges in the network. Note that we assume a limited
communication range. This assumption can be extended to
allow a broader communication range. However, such an
extension would also raise other issues of complexity (e.g.,
maintaining a larger set of information), applicability (e.g.,
how much would the data gathered at time t on a given
junction be relevant for another agent that would not arrive
at the said junction within the near future) and other issues.
In addition, this could create a similar effect as the results of
increasing the percentage of gossiping agents. However, as we
discuss in the next subsection, our simulations were conducted
when the percentage of gossip agents was shown to be most
efﬁcient. Thus, in this paper we only investigate the limited
communication model.
A subset of the gossip agents are self-interested and manip-
ulate the devices for their own beneﬁt. We will refer to these
agents as self-interested agents. A detailed description of their
behavior is given in Sections IV and V.
B. Simulation Design
Building on [11] and [21], the network in our simulations1
replicates a large city center, and consists of 50 junctions and
150 main roads. Each simulation consists of 6 iterations. The
basic time unit of the iteration is a step, which is equivalent
to about 30 seconds. Each iteration simulates six hours of
movement. The average number of cars passing through the
network during the iteration is about 70,000 and the average
1See http://www.cs.biu.ac.il/∼linraz/vehicularAgents.htm for the simulation
tool.

4
number of cars in the network at a speciﬁc time unit is about
3,500 cars. In each iteration the same agents are used, such
that each agent has the same origin and destination points in
the different iterations, whereas the data collected in earlier
iterations is preserved for future iterations (referred to as the
history of the agent). This allows us to simulate a somewhat
daily routine in the transportation network (e.g., a working
week).
Each of the experiments that we describe below was run
with 5 different trafﬁc scenarios. Each of these trafﬁc scenarios
differed from one another by the initial load of the roads and
the designated routes of the agents (cars) in the network. Five
simulations were run for each scenario, thereby creating a total
of 25 simulations for each experiment.
Parshani et al. ([21], [11]) showed that the information prop-
agation in the network is very efﬁcient when the percentage
of gossiping agents is 10% or more. Yet, due to congestion
caused by too many cars rushing to what was reported as the
less congested part of the network, 20-30% of gossiping agents
led to the most efﬁcient routing results in their experiments.
Consequently, in our study, we focus only on simulations in
which the percentage of gossip agents is 20%.
The simulations were done with different percentages of
self-interested agents. Each simulation was run with changes
in the set of gossip agents, and the set of self-interested agents.
In order to attain a similar ordinal scale, the results were nor-
malized. The normalized values were calculated by comparing
each agent’s results to its results when the same scenario was
run with no self-interested agents. This was done for all of the
iterations. Using the normalized values enabled us to observe
how worse (or better) each agent would perform compared to
the basic setting. For example, if the journey length of a certain
agent in iteration 1 with no self-interested agent was 50, and
the length was 60 in the same scenario and iteration in which
self-interested agents were involved, then the normalized value
for that agent would have been 60/50 = 1.2. We refer to a
change of ±3% in the normalized value as a small effect on
the agent while higher changes are considered to have large
effects.
The simulations were all done at the system level. In
particular, we did not model the MAC performance and signal
propagation. The simulator with documentation is available at
http://www.cs.biu.ac.il/∼linraz/vehicularAgents.htm.
Further details of the simulations are presented in Sections
IV and V.
IV. SPREADING LIES, MAXIMIZING UTILITY
In the ﬁrst set of experiments we investigated the beneﬁts
achieved by self-interested agents, whose aim was to minimize
their own journey length. The self-interested agents adopted a
cheating approach, whereby they sent false data to their peers.
In this section we ﬁrst describe the simulations with the
self-interested agents. Then, we model the scenario as a game
with two types of agents, and prove that the equilibrium result
can only be achieved when there is no efﬁcient exchange of
gossiping information in the network.
A. Modeling the Self-Interested Agents’ Behavior
While the gossip agents gather data and send it to other
agents, the self-interested agents’ behavior is modeled as
follows:
1) Calculate the shortest path from origin to destination.
2) Communicate the following data to other agents:
a) If the road is not on the agent’s route - send the true
data about it (e.g., data about roads it has received
from other agents).
b) For all roads on the agent’s route, which the agent
has not yet traversed, send a random high weight.
Basically, the self-interested agent acts in the same manner
as the gossip agent. It collects data regarding the weight of
the roads (either by traversing the road or by getting the data
from other agents) and sends the data it has collected to other
agents. However, the self-interested agent acts differently when
the road is on its route. Since the agent’s goal is to reach its
destination as fast as possible, the agent will falsely report
that all the roads on its route are heavily congested. This is
in order to free the path for itself, by making other agents
recalculate their paths, this time without including roads on the
self-interested agent’s route. To this end, for all the roads in its
route, which the agent has not yet passed, the agent generates
a random weight, which is above the average weight of the
roads in the network. It then associates these new weights with
the roads on its route and sends them to the other agents.
Though an agent can also divert cars from its route by
falsely reporting congested roads parallel to its route as free,
this behavior is not very likely since other agents, attempting
to use the roads, will ﬁnd the mistake within a short time and
spread the true situation of the road. On the other hand, if an
agent manages to persuade other agents not to use a road, it
will be harder for them to detect that the said roads are not
congested.
In addition, in order to avoid being inﬂuenced by their own
lies and other lies spread throughout the network, all self-
interested agents will ignore data received about roads with
heavy trafﬁc (note that data about roads that are not congested
will not be ignored)2.
In the next subsection we describe the simulation results,
involving the self-interested agents.
B. Simulation Results
We ran several experiments in order to test the beneﬁts of
self-interested agents cheating. In the ﬁrst set of experiments,
we created a scenario, in which a small group of self-interested
agents spread lies about the same route, and tested its effect
on the journey length of all the agents in the network. In
order to try and maximize the effect of the lies on agents
traveling that route, we selected several cars, which had the
same origin and destination, to server as the self-interested
agents. In this simulation, we selected only 6 agents to be
2In other simulations we have run, in which there were several real
congestions in the network, we indeed observed that even when the roads
were jammed, the self-interested agents were less affected if they ignored all
reported heavy trafﬁc, since consequently they also discarded all disinforma-
tion roaming the network.

5
Iteration
Self-Interested
Gossip -
Gossip -
Regular
Number
Agents
Same
Others
Agents
1
1.38
1.27
1.06
1.06
2
0.95
1.56
1.18
1.14
3
1.00
1.86
1.28
1.17
4
1.06
1.93
1.35
1.17
5
1.13
2.00
1.40
1.17
6
1.08
2.02
1.43
1.18
TABLE I
NORMALIZED JOURNEY LENGTH VALUES BY ITERATION WHEN 6
SELF-INTERESTED AGENTS, WITH THE SAME ORIGIN AND DESTINATION,
SPREAD LIES ABOUT THEIR ROUTE; ONE ROAD, ON THE ROUTE OF THESE
AGENTS, WAS PARTIALLY BLOCKED.
part of the self-interested agents group, in order to investigate
the effect achieved by only a small number of agents.
In this experiment, 6 different agents were randomly chosen
in each simulation to be part of the self-interested agents
group, as described above. In addition, one road, on the route
of these agents, was randomly selected to be partially blocked,
letting only one car go through at each time step. About 8,000
agents were randomly selected as regular gossip agents, and
the other 32,000 agents were designated as regular agents.
We analyzed the average journey length of the self-
interested agents compared to the average journey length of
other regular gossip agents traveling along the same route. Ta-
ble I summarizes the normalized results for the self-interested
agents, the gossip agents (those having the same origin and
destination as the self-interested agents, denoted Gossip -
Same, and all other gossip agents, denoted Gossip - Others)
and the regular agents, as a function of the iteration number.
The results presented in Table I reveal that the ﬁrst time
(iteration 1) self-interested agents travel the route while
spreading false data about the roads does not help them (using
the paired t-test we show that the agents have signiﬁcantly
lower journey lengths in the scenario in which they do not
spread any lies, with p-value < 0.01). This is mainly due to
the fact that the lies do not advance ahead of the self-interested
agent and reach other cars that are ahead of the self-interested
car on the same route. Thus, spreading the lies in the ﬁrst
iteration does not help the self-interested agent free the route
it is about to travel during the ﬁrst iteration.
Only when the self-interested agents repeat their journey in
the next iteration (iteration 2) the disinformation signiﬁcantly
helps them (p-value = 0.04). The reason for this is that
other gossip agents have received this data and have used it to
recalculate their shortest path, thus avoiding the roads which
are the subject of the disinformation. It is also interesting to
note the large value attained by the self-interested agents in
the ﬁrst iteration. This is mainly due to several self-interested
agents that enter the jammed road. This situation occurs since
the self-interested agents ignore all heavy trafﬁc data, and thus
ignore the fact that the road is jammed. As they begin to
spread lies about this road, more cars shift from this route,
thus making the road free for future iterations.
However, we also recall that the self-interested agents ignore
Iteration
Beneﬁciary
Gossip -
Gossip -
Regular
Number
Agent
Same
Others
Agents
1
1.10
1.05
0.94
1.11
2
1.09
1.14
0.99
1.14
3
1.04
1.19
1.02
1.14
4
1.03
1.26
1.03
1.13
5
1.05
1.32
1.05
1.12
6
0.92
1.39
1.06
1.11
TABLE II
NORMALIZED JOURNEY LENGTH VALUES BY ITERATION WHEN ONE
SELF-INTERESTED AGENT HAS THE OBJECTIVE TO HELP ANOTHER
BENEFICIARY AGENT WITH THE SAME ORIGIN AS ITS.
all information about heavy trafﬁc roads. Thus, when the
network becomes congested, more self-interested cars are
affected, since they might enter jammed roads, which they
would otherwise not have entered. This can be seen, for
example, in iterations 4-6, in which the normalized value of the
self-interested agents increases above 1.00. Using the paired
t-test to compare these values with the values achieved by
these agents when no lies are used, we reveal that there is no
signiﬁcant difference between the two scenarios.
As opposed to the gossip agents, we observe how little
effect the self-interested agents have on the regular agents.
In comparison to the gossip agents on the same route that
travel as much as 93% more when self-interested agents are
introduced, the average journey length for the regular agents
only increases by about 15%. This result is even lower than
the effect on other gossip agents in the entire network.
Since we noticed that self-interested agents do not beneﬁt
by cheating in the ﬁrst iteration, we devised another set
of experiments. In the second set of experiments, the self-
interested agents have an objective to help another agent,
that is supposed to enter the network some time after the
self-interested agent has entered. We refer to the latter agent
as the beneﬁciary agent. Similar to a self-interested agent,
the beneﬁciary agent also ignores all data regarding heavy
trafﬁc. In real-life this can be modeled, for example, by a
husband, who would like to help his wife ﬁnd a faster route
to her destination. Table II summarizes the normalized values
for the different agents. As in the ﬁrst set of experiments,
5 simulations were run for each scenario, with a total of
25 simulations. In each of these simulations one agent was
randomly selected as a self-interested agent, and then another
agent, with the same origin as the self-interested agent, was
randomly selected as the beneﬁciary agent. The other 8,000
and 32,000 agents were designated as regular gossip agents
and regular agents, respectively.
We can see that the higher the number of iterations, the
lower the normalized value for the beneﬁciary agent. In this
scenario, as in the previous one, in the ﬁrst iterations not only
does the beneﬁciary agent not avoid the jammed roads, since
it ignores all heavy trafﬁc, it also does not beneﬁt from the
lies spread by the self-interested agent. This is due to the fact
that the disinformation has not yet been incorporated by other
gossip agents. Thus, if we compare the average journey length

6
in the ﬁrst iteration when lies are spread and when there
are no lies, the average is signiﬁcantly lower for the latter
case (p-value < 0.03). On the other hand, if we compare
the average journey length in all of the iterations, there is no
signiﬁcant difference between the two settings. Nonetheless,
in most of the iterations, the average journey length of the
beneﬁciary agent is longer than in the case when no lies are
spread.
We can also see the impact on the other agents in the
system. While the gossip agents, which are not on the route
of the beneﬁciary agent, are virtually not affected by the self-
interested agent, those on the route and the regular agents are
affected and have higher normalized values. That is, even with
only one self-interested car, we can see that both the gossip
agents that begin the same route (i.e. the same origin and
destination points) as the self-interested agents spreading the
lies, and other regular agents, increase their journey length
signiﬁcantly (p-value < 0.015 for the gossip agents and
p-value < 0.002 for the regular agents) by more than 17% on
average.
In our third set of experiments we examined a setting
whereby there is an increasing number of self-interested
agents, which do not necessarily have the same origin and
destination points. To model this we randomly selected self-
interested agents, whose objective was to minimize their
average journey length, assuming the cars repeat their journeys
(that is, more than one iteration was performed). As opposed
to the ﬁrst set of experiments, in this set the self-interested
agents were selected randomly, and we did not enforce the
constraint of having the same origin and destination points.
As in the previous sets of experiments we ran 5 different
simulations per scenario. In each simulation 11 runs were
made, each run with a different number of self-interested
agents: 0 (no self-interested agents), 1, 2, 4, 8, and 16. Each
agent adopted the behavior modeled in Section IV-A. Figure
1 shows the normalized value achieved by the self-interested
agents as a function of their number. The ﬁgure shows these
values for iterations 2-6. The ﬁrst iteration is not shown
intentionally, as we assume repeated journeys.
Using these simulations we examined the possible threshold
of the number of randomly selected self-interested agents
which will allow them to beneﬁt from their selﬁsh behavior.
We can see that with up to 8 self-interested agents, the average
normalized value is below 1. That is, the self-interested agents
beneﬁt from their malicious behavior. In the case of one self-
interested agent a signiﬁcant difference is revealed between
the average journey length of when misinformation is spread
by the agent and when no lies are spread (p-value < 0.001).
However, when there are 2, 4, 8 and 16 self-interested agents
there is no signiﬁcance difference. Yet, as the number of
self-interested agents increases, the normalized value also
increases. In such cases, the normalized value is larger than
1, and the self-interested agents’ journey length becomes
signiﬁcantly higher than their journey length in cases where
there are no self-interested agents in the system.
In the next subsection we analyze the scenario as a game
and show that when in equilibrium the exchange of gossiping
between the agents becomes inefﬁcient.
0.955
0.96
0.965
0.97
0.975
0.98
0.985
0.99
0.995
1
1.005
1.01
1.015
1.02
1.025
1.03
0 1 2 3 4 5 6 7 8 9 10111213141516
Self-Interested Agents Number
Normalized Value
Iteration 2
Iteration 3
Iteration 4
Iteration 5
Iteration 6
Fig. 1.
Self-interested agents normalized values as a function of the number
of self-interested agents. Self-interested agents have the objective to minimize
their average journey length.
C. When Gossiping is Inefﬁcient
We continued by modeling our scenario as a game, in order
to ﬁnd the equilibrium.
In our game there are two possible types of agents: (a)
regular gossip agents, and (b) self-interested agents. Each of
these agents is a representative of its group, and thus all agents
in the same group have similar behavior.
We note that the advantage of using gossiping in transporta-
tion networks is to allow the agents to detect anomalies in the
network (e.g., trafﬁc jams) and to quickly adapt by recalcu-
lating their routes [11]. We also assume that the objective of
the self-interested agents is to minimize their own journey
length, thus they spread lies on their routes, as described
in Section IV-A. Furthermore, we assume that sophisticated
methods for identifying the self-interested agents or managing
reputation are not used. This is mainly due to the complexity
of incorporating and maintaining such mechanisms, as well
as due to the dynamics of the network, in which interactions
between different agents are frequent; agents may leave the
network, and data about the road might change as time
progresses (e.g., a road might be reported by a regular gossip
agent as free at a given time, yet currently it may be jammed
due to heavy trafﬁc on the road). Nevertheless, we discuss
mechanisms for overcoming malicious agents in Section VI.
We should also note the fact that the Nash solution does
not necessarily mean the optimal solution, but rather a stable
solution. Also, research has shown that humans (and we
assume that the self-interested agents model human drivers)
do not necessarily follow equilibrium strategy (e.g., see [22],
[23]). Even as such, we should note the different assumptions
that were the basis of this analysis and were not part of the
simulations with which we experiment:
• We assume there are two groups of agents - self-interested
agents and regular gossip agents. We give similar weight

7
to both groups, though in our simulation there are much
less self-interested agents than gossip agents (as we
assume is the case in real-life).
• The dynamics of the network, the propagation of infor-
mation and whether the data is update or not are not taken
into consideration in the game modeling.
• We assume that self-interested agents and gossip agents
have information regarding the average time it takes to
traverse each edge (this, however, can be assumed in real-
life as well).
We proceed by analyzing the game’s equilibrium. Let Tavg
be the average time it takes to traverse an edge in the
transportation network (that is, the average load of an edge).
Let Tmax be the maximum time it can take to traverse an edge.
We will investigate the game, in which the self-interested and
the regular gossip agents can choose the following actions.
The self-interested agents can choose how much to lie, that
is, they can choose to spread the information of how long (not
necessarily the true duration) it takes to traverse certain roads.
Since the objective of the self-interested agents is to spread
messages as though some roads are jammed, the traversal
time they report is obviously larger than the average time.
We denote the time the self-interested agents spread as Ts,
such that Tavg ≤Ts ≤Tmax. Motivated by the results of
the simulations we have described above, we observed that
the agents are less affected if they discard the heavy trafﬁc
values. Thus, the regular gossip cars, attempting to mitigate
the effect of the liars, can choose a strategy to ignore abnormal
congestion values above a certain threshold, Tg. Obviously,
Tavg ≤Tg ≤Tmax. In order to prevent the gossip agents
from detecting the lies and simply discarding the values,
the self-interested agents send lies within the given range
([Tavg, Tmax]) with an inverse geometric distribution, that is,
the higher the T value, the higher its frequency.
Now we construct the utility functions for each type of
agents, which are deﬁned by the values of Ts and Tg. If
the self-interested agents spread traversal times higher than or
equal to the regular gossip cars’ threshold, they will not beneﬁt
from their lies. Thus, the utility value of the self-interested
agents in this case is 0. On the other hand, if the self-interested
agents spread misinformation stating traversal times lower than
the threshold, they will gain a positive utility value (to ensure
that the utility value will always be larger than 0 we added 1 in
the calculations). From the regular gossip agents point-of-view,
if they accept messages from the self-interested agents, then
they incorporate the lies in their calculation, thereby losing
utility points. On the other hand, if they discard the false values
the self-interested agents send, that is, they do not incorporate
the lies, they will gain utility values. Formally, we use us to
denote the utility of the self-interested agents and ug to denote
the utility of the regular gossip agents. We also denote the
strategy proﬁle in the game as {Ts, Tg}. The utility functions
are deﬁned as:
us =
(
0
if Ts ≥Tg
Ts −Tavg + 1
if Ts < Tg
(1)
ug =
(
Tg −Tavg
if Ts ≥Tg
Ts −Tg
if Ts < Tg
(2)
We are interested in ﬁnding the Nash equilibrium. Re-
call from Osborne and Rubinstein ([24], Chapter 2), that
the Nash equilibrium is a strategy proﬁle, where no player
has anything to gain by deviating from his strategy, given
that the other agent follows his strategy proﬁle. Formally,
let (S, u) denote the game, where S is the set of strategy
proﬁles and u is the set of utility functions. When each
agent i ∈{regular gossip, self-interested} chooses a strategy
Ti resulting in a strategy proﬁle T = (Ts, Tg) then agent
i obtains a utility of ui(T). A strategy proﬁle T ∗∈S is
a Nash equilibrium if no deviation in the strategy by any
single agent is proﬁtable, that is, if for all i, ui(T ∗) ≥
ui(Ti, T ∗
−i). In other words, (Ts, Tg) is a Nash equilibrium
if the self-interested agents have no other value T ′
s such that
us(T ′
s, Tg) > us(Ts, Tg), and similarly for the gossip agents.
We now present the following theorem.
Theorem 4.1: (Tavg, Tavg) is the only Nash equilibrium.
Proof. First we will show that (Tavg, Tavg) is a Nash
equilibrium. Assume, by contradiction, that the gossip agents
choose another value Tg′ > Tavg. Thus, ug(Tavg, Tg′) =
Tavg −Tg′ < 0. On the other hand, ug(Tavg, Tavg) = 0. Thus,
the regular gossip agents have no incentive to deviate from this
strategy. The self-interested agents also have no incentive to
deviate from this strategy. By contradiction, again assume that
the self-interested agents choose another value Ts′ > Tavg.
Thus, us(Ts′, Tavg) = 0, while us(Tavg, Tavg) = 0.
We will now prove that the above solution is unique. We
will demonstrate that any other pair (Ts, Tg), such that Tavg <
Tg ≤Tmax and Tavg < Ts ≤Tmax is not a Nash equilibrium.
We have three cases. In the ﬁrst case Tavg < Tg < Ts ≤
Tmax. Thus, us(Ts, Tg) = 0 and ug(Ts, Tg) = Tg −Tavg. In
this case, the regular gossip agents have an incentive to deviate
and choose another strategy Tg + 1, since by doing so they
increase their own utility: ug(Ts, Tg + 1) = Tg + 1 −Tavg.
In the second case Tavg < Ts < Tg ≤Tmax. Thus,
ug(Ts, Tg) = Ts−Tg < 0. Also, the regular gossip agents have
an incentive to deviate and choose another strategy Tg −1, in
which their utility value is higher: ug(Ts, Tg−1) = Ts−Tg+1.
In the last case Tavg
<
Ts
=
Tg
≤
Tmax. Thus,
us(Ts, Tg) = Ts −Tg = 0. In this case, the self-interested
agents have an incentive to deviate and choose another strategy
Tg −1, in which their utility value is higher: us(Tg −1, Tg) =
Tg −1 −Tavg + 1 = Tg −Tavg > 0.
The above theorem proves that the equilibrium point is
reached only when the self-interested agents send the time
to traverse certain edges equal to the average time, and on the
other hand the regular gossip agents discard all data regarding
roads that are associated with an average time or higher.
Thus, for this equilibrium point the exchange of gossiping
information between agents is inefﬁcient, as the gossip agents
are unable to detect congestions and heavy trafﬁc in the
network.
While above we prove the equilibrium states that gossiping
is inefﬁcient under the assumptions we have laid, this theoret-
ical result is relevant to these extreme cases. Moreover, this

8
Number of
Self-Interested
Gossip
Regular
Self-Interested Agents
Agents
Agents
Agents
1
0.98
1.01
1.05
2
1.09
1.02
1.05
4
1.07
1.02
1.05
8
1.06
1.04
1.05
16
1.03
1.08
1.06
32
1.07
1.17
1.08
50
1.12
1.28
1.10
64
1.14
1.39
1.13
80
1.15
1.50
1.14
100
1.17
1.63
1.16
TABLE III
NORMALIZED JOURNEY LENGTH VALUES FOR THE FIRST ITERATION.
INCREASING THE NUMBER OF SELF-INTERESTED AGENTS WITH THE
OBJECTIVE OF MINIMIZING THE AVERAGE JOURNEY LENGTH.
proof provides a guideline on how to ensure that the gossip
will remain effective, i.e., preventing the assumption of the
theoretical model from coming true.
In the next section we describe another scenario for the self-
interested agents, in which they are not concerned with their
own utility, but rather interested in maximizing the average
journey length of other gossip agents.
V. SPREADING LIES, CAUSING CHAOS
Another possible behavior that can be adopted by self-
interested agents is characterized by their goal to cause dis-
order in the network. This can be achieved, for example, by
maximizing the average journey length of all agents, even at
the cost of maximizing their own journey length.
To understand the vulnerability of the gossip based trans-
portation support system, we ran 5 different simulations for
each scenario. In each simulation different agents were ran-
domly chosen (using a uniform distribution) to act as gossip
agents, from which self-interested agents were chosen. Each
self-interested agent behaved in the same manner as described
in Section IV-A.
Every simulation consisted of 11 runs with each run com-
prising different numbers of self-interested agents: 0 (no self-
interested agents), 1, 2, 4, 8, 16, 32, 50, 64, 80 and 100.
Also, in each run the number of self-interested agents was
increased incrementally. For example: the run with 50 self-
interested agents consisted of all the self-interested agents that
were used in the run with 32 self-interested agents, but with
an additional 18 self-interested agents. Also recall that in each
run the average number of cars passing through the network
during an iteration was about 70,000.
Tables III and IV summarize the normalized journey length
for the self-interested agents, the regular gossip agents and the
regular (non-gossip) agents for the ﬁrst iteration and for the
average of all iterations, respectively. Figure 2 demonstrates
the changes in the normalized values for the regular gossip
agents and the regular agents, as a function of the iteration
number. Similar to the results in our ﬁrst set of experiments,
Number of
Self-Interested
Gossip
Regular
Self-Interested Agents
Agents
Agents
Agents
1
0.98
1.01
1.06
2
1.00
1.02
1.07
4
1.00
1.04
1.07
8
1.01
1.18
1.11
16
1.02
1.53
1.17
32
1.06
2.13
1.25
50
1.13
2.21
1.29
64
1.21
2.21
1.32
80
1.21
2.12
1.27
100
1.26
2.10
1.27
TABLE IV
NORMALIZED JOURNEY LENGTH VALUES FOR ALL ITERATIONS.
INCREASING THE NUMBER OF SELF-INTERESTED AGENTS WITH THE
OBJECTIVE OF MINIMIZING THEIR AVERAGE JOURNEY LENGTH.
described in Section IV-B, we can see that randomly selected
self-interested agents that follow different randomly selected
routes do not beneﬁt from their malicious behavior (that is,
their average journey length does not decrease). However,
when only one self-interested agent is involved, it does ben-
eﬁt from the malicious behavior, even in the ﬁrst iteration.
The results also indicate that the regular gossip agents are
more sensitive to malicious behavior than regular agents -
the average journey length for the gossip agents increases
signiﬁcantly (e.g., with 32 self-interested agents, the average
journey length for the gossip agents was 113% higher, which is
signiﬁcantly higher with p-value < 0.01, than in the setting
with no self-interested agents, as opposed to an increase of
only 25% for the regular agents). In addition, these results
also indicate the effects of the self-interested agents’ behavior
on the network load. It is also interesting to see that the highest
normalized value for the gossip agents is achieved when there
are 50 malicious agents. When the number of malicious agents
increases, the normalized value begins to decrease. This can be
explained by the fact that the malicious agents were randomly
chosen and thus they spread lies that more routes are highly
congested. This, in turn, virtually makes different routes have
the same (high and inaccurate) weights, and allows the regular
gossip agents to choose routes which eventually turn out to be
uncongested.
Since the goal of the self-interested agents in this case is to
cause disorder in the network rather than use the lies for their
own beneﬁt, the question arises as to why would the behavior
of the self-interested agents be to send lies about their routes
only. Furthermore, we hypothesize that if they all send lies
about the same major roads the damage they might inﬂict on
the entire network would be larger than had each of them
sent lies about its own route. To examine this hypothesis, we
designed another set of experiments. In this set of experiments,
all the self-interested agents spread lies about the same 13
main roads in the network. However, the results show quite
a smaller impact on other gossip and regular agents in the
network. The average normalized value for the gossip agents

9
1
1.1
1.2
1.3
1.4
1.5
1.6
1.7
1.8
1.9
2
2.1
2.2
2.3
2.4
2.5
2.6
2.7
2.8
2.9
1
2
3
4
5
6
Iteration Number
Normalized Value
32 self-interested agents, gossip agents normalized value
100 self-interested agents, gossip agents normalized value
32 self-interested agents, regular agents normalized value
100 self-interested agents, regular agents normalized value
Fig. 2.
Gossip and regular agents normalized values, as a function of the
iteration. 32 and 100 self-interested agents with the objective of minimizing
their average journey length.
in these simulations was only about 1.07, as opposed to 1.7 in
the original scenario. When analyzing the results we revealed
that although the false data was spread, it did not cause other
gossip cars to change their route. The main reason was that
the lies were spread on roads that were not on the route of the
self-interested agents. Thus, it took the data longer to reach
agents on the main roads, and when the agents reached the
relevant roads this data was “too old” to be incorporated in
the other agents’ calculations.
We also examined the impact of sending lies in order
to cause chaos when there are already congestions in the
network. To this end, we simulated a network in which 13
main roads are jammed. The behavior of the self-interested
agents is the same as described in Section IV-A, and the
self-interested agents spread lies about their own route. The
simulation results, detailed in Table V, show that there is a
greater incentive for the self-interested agents to cheat when
the network is already congested, as their cheating causes more
damage to other agents in the network. For example, whereas
the average journey length of the regular agents increased only
by about 18% in the original scenario with an uncongested
network (see Table IV), in this scenario the average journey
length of the agents signiﬁcantly increased by about 60%
(p-value < 0.03).
VI. MECHANISMS FOR OVERCOMING MALICIOUS
AGENTS IN VEHICULAR NETWORKS
In the previous section we demonstrated the effects of the
malicious agents on other agents, mostly gossip agents, in
the network. Even though the effect is relatively low, it still
increases the average journey length incurred by the other
gossip agents. Therefore we proceeded to implement two
Number of
Self-Interested
Gossip
Regular
Self-Interested Agents
Agents
Agents
Agents
1
1.07
1.02
1.22
2
1.09
1.04
1.23
4
1.06
1.06
1.23
8
1.09
1.15
1.26
16
1.11
1.55
1.39
32
1.14
2.25
1.56
50
1.30
2.25
1.60
64
1.35
2.47
1.63
80
1.51
2.41
1.64
100
1.68
2.61
1.75
TABLE V
NORMALIZED JOURNEY LENGTH VALUES FOR ALL ITERATIONS.
INCREASING THE NUMBER OF SELF-INTERESTED AGENTS WITH THE
OBJECTIVE OF MINIMIZING THEIR AVERAGE JOURNEY LENGTH. 13 MAIN
ROADS ARE JAMMED.
mechanisms to show how they can signiﬁcantly reduce the
inﬂuence of the malicious or self-interested agents in the
network. Unlike mechanisms of distributed reputation, our
proposed mechanisms are not costly nor time consuming. The
ﬁrst mechanism we propose is mainly incorporated in the
agents themselves: a history of the roads is maintained and
used to update the belief regarding each road. The second
mechanism is implemented in the network with the introduc-
tion of trusted agents in the network. For example, ambulance
or police cars (agents) are ﬂagged and their data is always
assumed to be true. Thus, each agent can use this data as a
reference to evaluate the data on each road. We elaborate on
these mechanisms below.
When implementing mechanisms to overcome the effects of
malicious agents, we should take into consideration the special
dynamics and characteristics of transportation networks. Since
the communication range is limited there is a bound on the
amount of information that two cars can exchange. A complex
mechanism would turn out to be costly, as well as, inefﬁcient,
since it would signiﬁcantly reduce the data exchanged on road
conditions. Even if we attempt to incorporate only a simple
mechanism of distributed reputation, the tradeoff between
communicating reputation and data exists.
To this end, we began by implementing two mechanisms
and using these simulations we show their efﬁcacy in sig-
niﬁcantly decreasing the effects of malicious agents on other
agents in the system. For both mechanisms we characterize the
data about a given road as having a true value (e.g., an agent
gathering data about a road as it traverses it will characterize
this data as being true for his local evaluations) or as having
an unknown value (e.g., data received from other agents, even
if it is characterized as true in their local evaluations).
A. Maintaining a History
In this mechanism a history is maintained for each road.
Each agent maintains a constant size array of values per road
(history) and uses these values to update its belief regarding the

10
road load. We continue with a description of how the history
is updated and how a belief about the road load is updated.
1) Description of the Mechanism: When receiving new
data the agent can distinguish between two cases. First, when
the history array is not yet full, the data is simply added to
the array of the given road. In the second case, when the
history array is already full, the agent needs to decide whether
the newly received data should override any existing data.
Basically, the agent gives a higher priority to data known
to be true over other data. A major difference between this
algorithm and our initial version, described in Section III, is
that the agent distinguishes between data items it collects itself
while traversing the road and data items received from other
agents. Since the data collected by the agent is characterized
as having a true value, while other data is not, its own
data receives a higher priority, even if newer data about the
same roads is received. This allows the agents to be more
selective when updating their history. Let trecv be the time
of the newly received data. Speciﬁcally, the agent needs to
distinguish between two possibilities. trecv can override data
in the history only if it is either more recent than any data in
the history or within a given time threshold from the oldest
data. If this is the case, the new data will override existing data
either if new data is characterized as having a true value or if
the data in the agent’s history is not characterized as having a
true value. In addition, the history is maintained per road and
there cannot be more than one data item per road’s history
that was generated from the same agent. This is in order to
protect against malicious agents that are aware of the fact that
the gossip agents maintain a history and try to manipulate it
to their advantage by bombarding them with misinformation
regarding the same road.
Another important decision when using the history mech-
anism is which of the data in the history should be used -
both for gossiping purposes and for local calculations. If any
of the data of the history is characterized as having a true
value, then this data is used (if there are several items in the
history of the road having a true value then the most recent
one is chosen). If all the data in the history is characterized as
having an unknown value then an average of the road’s load is
calculated. Then, the data item in the history which is closest
to the average load is chosen as the believed data about the
road.
2) When Maintaining History is Inefﬁcient: In Section IV-C
we proved that there is an equilibrium in which gossiping
is inefﬁcient when no countermeasures are implemented
against the malicious agents. We will demonstrate now that
gossiping is inefﬁcient when maintaining a history as well.
To do so, we model our scenario as a game in order to ﬁnd
the equilibrium. Two possible types of agents participate
in the game: regular gossip agents and malicious agents.
Each of these agents is a representative of its group, and
thus all agents in the same group have similar behavior. The
gossip agents can choose the size of the history which they
maintain, while the malicious agents can choose the size of
the coalition that they form in order to try to manipulate
the entire history so it will consist of only false data. If the
coalition size is larger than the history maintained by the
gossip agents, then the malicious agents can gain control
over the history. In this case, the malicious agents gain
utility, while the gossip agents lose. However, the larger the
coalition’s size, the larger the overhead and coordination
required by the malicious agent. Thus, the larger the coalition,
the lower the utility value they gain. Similar considerations
apply to the gossip agents. If the history size is larger than
the coalition’s size, then the gossip agents can use the history
to minimize the effects of malicious agents and they gain a
higher utility value. On the other hand, the larger the history
size, the more computation required by the agents and thus
they gain lower utility values. Given these considerations, we
can generate the following payoff matrix, in which the rows
represent the coalition size and the columns the history size:




1
2
...
n −1
n
1
(n −1, n −1)
(−1, n)
...
(−1, 3)
(−1, 2)
2
(n, −1)
(n −2, n −2)
...
(−2, 3)
(−2, 2)
3
(n −1, −1)
(n −1, −2)
...
(−3, 3)
(−3, 2)
...
...
...
...
...
...
n −1
(3, −1)
(3, −2)
...
(1, 1)
(−(n −1), 2)
n
(2, −1)
(2, −2)
...
(2, −(n −1))
(0, 0)




From the payoff matrix we can observe that as the coalition
size (history size) increases, the lower the utility value of
the malicious agents (gossip agents). In addition, whenever
the coalition size (history size) is larger than the history size
(coalition size), the utility value of the malicious agents (gossip
agents) is positive, while the utility value of the gossip agents
(malicious agents) is negative. Furthermore, the highest utility
of the malicious agents (gossip agents) is gained when the
coalition size (history size) is minimal, yet larger than the
history size (coalition size), that is, a coalition size (history
size) of 2 and a history size (coalition size) of 1.
It is easy to see that a Nash equilibrium exists in which both
the history size and the coalition’s size is of size n. Following
our results in Section IV-C, in this situation gossiping is
inefﬁcient.
B. Trusted Agents
In the second mechanism we implemented, we assume that
a subset of the gossip agents that roam the network can be
characterized as trusted agents. This can be modeled, for
example, by ambulances or police cars, which are known to be
trustworthy and have no incentive to spread misinformation.
Data which is received from trusted agents is always presumed
to have a true value and thus receive a higher priority when
updating the data about the road. The updating of the history
(whether there is no history, i.e., the history size is 1, or the
history size is larger than 1) and the generation of the belief
about the roads is similar to the algorithms described above.
Note that we assume that the network infrastructure supports
this mechanism. That is, it provides a way to detect messages
of trusted agents and prevents other agents from disguising
as trusted agents (for example, using private and public key
encryptions). The next subsection describes our simulation
results using both mechanisms.
C. Simulation Results
We ran two sets of experiments. In each we implemented
our mechanisms for decreasing the effect caused by the

11
Iteration
Self-Interested
Gossip -
Gossip -
Regular
Number
Agents
Same
Others
Agents
1
1.02
1.10
1.03
1.06
2
1.02
1.04
1.01
1.10
3
1.09
1.07
1.04
1.12
4
1.07
1.02
1.01
1.09
5
0.99
1.02
1.01
1.07
6
1.05
1.03
1.02
1.06
TABLE VI
NORMALIZED JOURNEY LENGTH VALUES, WHEN 6 SELF-INTERESTED
AGENTS, WITH THE SAME ORIGIN AND DESTINATION, SPREAD LIES
ABOUT THEIR ROUTE; ONE ROAD, ON THE ROUTE OF THESE AGENTS, WAS
PARTIALLY BLOCKED. GOSSIP AGENTS ARE IMPLEMENTED WITH THE
HISTORY MECHANISM ONLY (HISTORY SIZE OF 3).
malicious agents. In both experiments the history size was
set at 3. In one set no trusted agents were present, while in
the other 1% of the gossip agents (approximately 80 agents)
were trusted agents. We believe that there would not be higher
proportion of trusted agents in real settings.
In the ﬁrst set of experiments, we created a scenario, in
which a small group of self-interested agents spread lies about
the same route, and tested its effect on the journey length of all
the agents in the network, while implementing our mechanisms
in order to overcome their effect. Thus, several cars, which had
the same origin and destination points, were designated as self-
interested agents. We selected only 6 self-interested agents, in
an attempt to investigate the effect achieved by only a small
number of agents.
In each simulation in this experiment, 6 different self-
interested agents were randomly chosen. In addition, one road,
on the route of these agents, was randomly selected to be
partially blocked, allowing only one car to go through at
each time step. About 8,000 agents were randomly selected
as regular gossip agents, and the other 32,000 agents were
designated as regular agents. When implementing the trusted
agent mechanism, a random number of 80 agents of the 8,000
gossip agents were randomly selected to act as trusted agents.
We analyzed the average journey length of the self-
interested agents as opposed to the average journey length
of other regular gossip agents traveling along the same route.
Tables VI and VII summarize the normalized results for the
self-interested agents, the gossip agents and the regular agents,
as a function of the iteration number. The two tables list the
results when the history size was 3 without trusted agents
and with 1% trusted agents, respectively. These results can be
compared with Table I in which neither of the two mechanisms
to overcome the malicious agents were implemented.
The results clearly illustrate the beneﬁt of implementing the
history mechanism. For example, in the last iteration, when
neither mechanisms were implemented, the gossip agents with
the same original route as the malicious agents, doubled their
journey length (normalized value of 2.02). However, when the
history mechanism was implemented the effect on the gossip
agents decreased signiﬁcantly to a normalized value of just
1.03 in the last iteration. These results reveal that maintaining
Iteration
Self-Interested
Gossip -
Gossip -
Regular
Number
Agents
Same
Others
Agents
1
1.10
1.07
1.03
1.05
2
1.03
1.04
1.01
1.10
3
1.04
1.04
1.04
1.12
4
0.93
0.97
1.00
1.10
5
1.01
1.01
1.01
1.08
6
1.01
1.02
1.01
1.07
TABLE VII
NORMALIZED JOURNEY LENGTH VALUES, WHEN 6 SELF-INTERESTED
AGENTS, WITH THE SAME ORIGIN AND DESTINATION, SPREAD LIES
ABOUT THEIR ROUTE; ONE ROAD, ON THE ROUTE OF THESE AGENTS, WAS
PARTIALLY BLOCKED. GOSSIP AGENTS ARE IMPLEMENTED WITH BOTH A
HISTORY MECHANISM (HISTORY SIZE OF 3) AND 1% OF TRUSTED
AGENTS.
a history helps minimize the effects of the malicious agents.
This can be attributed to two main reasons. The ﬁrst is that true
data is given priority. Thus, even if several malicious agents
spread data on the same road, the false data cannot override
true data which exists about the road. The second reason is the
fact that an agent can only attribute one instance to the history
of a given road. Thus, a malicious agent cannot aggregate data
and ﬁll the history of a given road with its own misinformation.
Adding the trusted agents mechanism together with the
history mechanism does not help the gossip agents to further
decrease their journey length, which has already signiﬁcantly
decreased due to the use of the history mechanism. To clarify
this, we also ran experiments (which are not presented in this
paper) in which the history was set to 1 and no trusted agents
existed. In these experiments the results also revealed that our
new history update mechanism enables a signiﬁcant decrease
in the effects caused by the malicious agent, and thus the
beneﬁt of the trusted agents in the system is minimized.
In the second set of experiments we tested the effect of
our mechanisms when the malicious agents aim to cause
disorder in the network. This can be achieved, for example, by
malicious agents causing an increase in the average journey
length of all agents, even at the cost of increasing their own
journey length. We ran 2 sets of simulations: in the ﬁrst set
32 malicious agents were present and in the second set 100
malicious agents were present. The malicious agents spread
lies about the same 13 main roads in the network. Table VIII
is a snapshot of Table IV which summarizes the average results
of all size iterations when no mechanism is used, while Tables
IX and X summarize the average results of all six iterations
with a history of size 1 (H = 1) and a history of size 3
(H = 3), when only the history mechanism is implemented
and when both the history mechanism and the trusted agents
mechanisms are implemented, respectively.
Again, in this experiment as well, we can see the signiﬁcant
decrease in the journey length for the gossip agents due to the
incorporation of the history mechanism. We can also see that
the addition of a trusted agents mechanism when the history
mechanism is already implemented, has no signiﬁcant effect
on the results.

12
Malicious Agents
Malicious
Gossip
Regular
Number
Agents
Agents
Agents
32
1.06
2.13
1.25
100
1.26
2.10
1.27
TABLE VIII
NORMALIZED JOURNEY LENGTH VALUES FOR ALL ITERATIONS. 32 AND
100 SELF-INTERESTED AGENTS WITH THE OBJECTIVE OF MINIMIZING
THEIR AVERAGE JOURNEY LENGTH. NO OVERCOMING MECHANISM WAS
IMPLEMENTED.
History
Malicious Agents
Malicious
Gossip
Regular
Number
Agents
Agents
Agents
H = 1
32
1.01
1.03
1.05
H = 3
1.00
1.00
1.06
H = 1
100
1.01
1.04
1.05
H = 3
1.00
1.00
1.05
TABLE IX
NORMALIZED JOURNEY LENGTH VALUES FOR ALL ITERATIONS. 32 AND
100 SELF-INTERESTED AGENTS WITH THE OBJECTIVE OF MINIMIZING
THEIR AVERAGE JOURNEY LENGTH. GOSSIP AGENTS ARE IMPLEMENTED
WITH THE HISTORY MECHANISM ONLY (HISTORY OF SIZE 1 AND 3).
History
Malicious Agents
Malicious
Gossip
Regular
Number
Agents
Agents
Agents
H = 1
32
1.00
1.04
1.05
H = 3
1.00
1.00
1.05
H = 1
100
1.02
1.04
1.05
H = 3
1.00
1.01
1.06
TABLE X
NORMALIZED JOURNEY LENGTH VALUES FOR ALL ITERATIONS. 32 AND
100 SELF-INTERESTED AGENTS WITH THE OBJECTIVE OF MINIMIZING
THEIR AVERAGE JOURNEY LENGTH. GOSSIP AGENTS ARE IMPLEMENTED
WITH BOTH THE HISTORY MECHANISM (HISTORY OF SIZE 1 AND 3) AND
1% OF TRUSTED AGENTS.
VII. COALITIONS OF MALICIOUS AGENTS
In the previous section we demonstrated how the history
mechanism allows the gossip agents to minimize the effect
of the malicious agents. The question arises as to what will
happen if the malicious agents are aware of the protection
method implemented by the gossip agents. Can the malicious
agents manipulate this mechanism to their own beneﬁt?
In Section VI-A2 we have shown that the gossiping is inef-
ﬁcient under some assumptions of maintaining a history and a
coalition formation by the malicious agents. In this section we
examine whether coalition formation by the malicious agent
can also assist the malicious agents in increasing their effect
on the gossip agents in the network, while the gossip agents
maintain a history mechanism. The main goal is to check
whether the malicious agents can form coalitions that will
enable them to take control of the different roads upon which
they spread false data, and thus make the gossip agents believe
that the actual road load is the false one.
To test this we ran two sets of experiments. In each
experiment, the gossip agents used the history mechanism as
a mechanism to decrease the effect caused by the malicious
agents. In addition, two runs were made in each experiment.
The ﬁrst consisted of 32 malicious agents being present in the
network and the second consisted of 100 malicious agents.
The malicious agents were randomly selected and followed the
same strategy: spreading lies about the same 13 main roads in
the network. We deﬁned a coalition of K cars to be a set of K
agents that have the same route (same source and destination
nodes) and enter the network at approximately the same time.
For example, if the coalition size is set to 4 and the network
consists of 100 malicious agents, then they form 25 different
coalition groups.
In the ﬁrst set of experiments, the malicious agents were
grouped into coalitions of size 2 and we conducted two
simulations. In the ﬁrst, the history size of the gossip agents
was set at 1, while in the second simulation it was set at 3.
This allowed us to examine the effect of a coalition of size 2,
both when the history size is smaller than the coalition size and
when it is larger than the coalition size. In the second set of
experiments the malicious agents were grouped into coalitions
of size 4 and we had a single simulation in which the history
size was set at 3. Tables XI and XII summarize the average
results of all six iterations of the ﬁrst experiment, while Table
XIII summarizes the results of the second experiment. Note
also that in all of the results the standard deviation was lower
than 0.002. Since the goal of the malicious agents is to cause
chaos in the network and not minimize their own journey
length, we omit the results concerning the malicious agents
themselves. The results of the previous experiments in which
no coalitions were formed are presented in Table IX.
Number of Malicious Agents
Gossip Agents
Regular Agents
32
1.03
1.05
100
1.04
1.05
TABLE XI
NORMALIZED JOURNEY LENGTH VALUES FOR ALL ITERATIONS, WITH A
HISTORY OF SIZE 1, AND A COALITION OF SIZE 2.
Malicious Agents Number
Gossip Agents
Regular Agents
32
1.00
1.06
100
1.02
1.06
TABLE XII
NORMALIZED JOURNEY LENGTH VALUES FOR ALL ITERATIONS, WITH A
HISTORY OF SIZE 3, AND A COALITION OF SIZE 2.
Malicious Agents Number
Gossip Agents
Regular Agents
32
1.02
1.06
100
1.01
1.06
TABLE XIII
NORMALIZED JOURNEY LENGTH VALUES FOR ALL ITERATIONS, HISTORY
OF SIZE 3, COALITION OF SIZE 4.
When we observe the normalized journey length of the reg-
ular gossip agents and the regular agents (a maximal increase
of 2% and 6%, respectively) we can deduce that the coalition
formation did not help the malicious agents achieve disorder in
the network. One reason for this could be the way the coalition

13
was formed and the way the history is updated. The coalition
is formed by grouping malicious agents traversing the same
route at about the same time. However, the malicious agents
themselves, do not spread false data about the roads they
traverse, but rather about 13 main junctions in the network. We
hypothesized that by going the same route the coalition will
be able to take control of the history of other gossip agents on
that route. Yet, it seems that the way in which the history is
updated proffers no advantage to the coalition groups. While
the malicious agents in the coalition can gain monetary control
over the history, if the gossip agents receive new data regarding
the same roads, it will override the false data. The chances of
agents, on the route of the 13 main junctions in the network,
receiving other data about these roads is quite high, as it takes
time until the malicious data is propagated to them, and in
addition, when it is propagated only one instance of the data
is communicated, and the history list can quickly recover.
Simulating coalitions that spread false data regarding their own
route, is similar to the results presented in Section IV-B, in
which 6 self-interested agents spread lies regarding their own
route. Table I summarizes the results, which indeed reveal
how the self-interested agents can beneﬁt from the lies, while
causing harm to other gossip agents in the network, mainly the
gossip agents on the same route as the self-interested agents.
Based on the latter experiments, it seems that implementing
the history mechanism will signiﬁcantly decrease the harm
inﬂicted by the self-interested agents in that scenario.
VIII. DISCUSSION AND CONCLUSIONS
In this paper we investigated the beneﬁts achieved by self-
interested agents in vehicular networks and whether mech-
anisms can help gossip agents overcome malicious agents
in transportation networks. Using simulations we investigated
two behaviors that might be taken by self-interested agents: (a)
trying to minimize their journey length, and (b) trying to cause
chaos in the network. Our simulations indicate that in reference
to both behaviors the self-interested agents have only limited
success achieving their goal, even if no counter-measures are
taken. This is in contrast to the greater impact inﬂicted by self-
interested agents in other domains (e.g., E-Commerce). Several
reasons for this are the special characteristics of vehicular
networks and their dynamic nature. While the self-interested
agents spread lies, they cannot choose with which agents they
will interact. Also, by the time their lies reach other agents,
they might become irrelevant, as more recent data has reached
the same agents.
The importance of implementing mechanisms to overcome
malicious agents cannot be overrated as we have seen the
effect of malicious agents on other agents in the network
when no countermeasures are implemented. However, it is
also important that these mechanisms not be costly, nor time
consuming, due to the dynamic nature of the transportation
network and in light of the fact that the interaction is range
and bandwidth limited. Furthermore the fact that agents cannot
choose with which agents to interact might effect the efﬁcacy
of these mechanisms. Our simulations indicate that for both
behaviors implemented by the malicious agents in the experi-
ments, our mechanisms enabled gossip agents to signiﬁcantly
overcome the effects of malicious agents. In addition, we
show that even a short history mechanism can sufﬁce to
overcome the effects of malicious agents. We also demonstrate
that malicious agents can not take advantage of the history
mechanism simply by grouping into coalitions.
Motivated by the simulation results, future research in
this ﬁeld will focus on modeling different behaviors of self-
interested agents, which might cause more damage to net-
works. Another direction would be to focus on the beneﬁts
of distributed reputation mechanisms in this model, as well as
using this type of mechanism to penalize malicious agents.
REFERENCES
[1] A. Bejan and R. Lawrence, “Peer-to-peer cooperative driving,” in ISCIS,
Oct. 2002, pp. 259–264.
[2] Y. Shavitt and A. Shay, “Optimal routing in gossip networks,” IEEE
Transactions on Vehicular Technology, vol. 54, no. 4, pp. 1473–1487,
July 2005.
[3] I. Chisalita and N. Shahmehri, “A novel architecture for supporting
vehicular communication,” in VTC, Sept. 2002, pp. 1002–1006.
[4] GM, “V2V. http://www.gm.com/company/gmability/safety/news issues/
releases/sixthsense
102405.html,” 2005.
[5] Honda, “http://world.honda.com/news/2005/c050902.html,” 2005.
[6] U.S
Department
of
Transportation,
“VII
initiative.
http://www.its.dot.gov/vii/docs/vii factsheet.pdf,” 2006.
[7] Lamport, Shostak, and Pease, “The byzantine generals problem,” in
Advances in Ultra-Dependable Distributed Systems, N. Suri, C. J. Walter,
and M. M. Hugue (Eds.).
IEEE Computer Society Press, 1982.
[8] G. H. Bham and R. Benekohal, “A high ﬁdelity trafﬁc simulation model
based on automata cellular and car following concepts,” Transportation
Research Part C: Emerging Technologies, vol. 12, no. 1, pp. 1–32, 2004.
[9] D. Helbing, A. Hennecke, V. Shvetsov, and M. Treiber, “Micro- and
macro- simulation of freeway trafﬁc,” Mathematical and Computer
Modelling, vol. 35, no. 5–6, pp. 517–547, 2002.
[10] D. Krajzewicz, G. Hertkorn, C. R¨ossel, and P. Wagner, “SUMO (Simu-
lation of Urban MObility); an open-source trafﬁc simulation,” in the 4th
Middle East Symposium on Simulation and Modelling (MESM), Sharjah,
UAE, Sept. 2002.
[11] S. Kraus, R. Parshani, and Y. Shavitt, “A study of gossiping in transporta-
tion networks,” IEEE Transactions on Vehicular Technology, accepted,
doi:10.1109/TVT.2007.912339.
[12] D. Dolev, R. Reischuk, and H. R. Strong, “Early stopping in byzantine
agreement,” JACM, vol. 37, no. 4, pp. 720–741, 1990.
[13] Y. M. Minsky and F. B. Schneider, “Tolerating malicious gossip,”
Distributed Computing, vol. 16, no. 1, pp. 49–68, Feb. 2003.
[14] D. Malkhi, E. Pavlov, and Y. Sella, “Gossip with malicious parties,”
School of Computer Science and Engineering - The Hebrew University
of Jerusalem, Israel, Technical Report: 2003-9, Mar. 2003.
[15] B. Yu and M. P. Singh, “A social mechanism of reputation management
in electronic communities,” in CIA, 2000.
[16] C. Leckie and R. Kotagiri, “Policies for sharing distributed probabilistic
beliefs,” in ACSC, 2003, pp. 285–290.
[17] A. Datta, S. Quarteroni, and K. Aberer, “Autonomous gossiping: A self-
organizing epidemic algorithm for selective information dissemination
in mobile ad-hoc networks,” in Proceedings of IC-SNW, June 2004, pp.
126–143.
[18] S. Das, A. Nandan, and G. Pau, “Spawn: A swarming protocol for
vehicular ad-hoc wireless networks,” in Proceedings of VANET, 2004,
pp. 93–94.
[19] N. Shibata, T. Terauchi, T. Kitani, K. Yasumoto, M. Ito, and T. Hi-
gashino, “A method for sharing trafﬁc jam information using inter-
vehicle communication,” in V2VCOM, 2006.
[20] W. Wang, X.-Y. Li, and Y. Wang, “Truthful multicast routing in selﬁsh
wireless networks,” in MobiCom, 2004, pp. 245–259.
[21] R. Parshani, “Routing in gossip networks,” Master’s Thesis, Bar-Ilan
University, Ramat-Gan, Israel, 2004.
[22] D. Kahneman and A. Tversky, “Prospect theory: an analysis of decisions
under risk,” Econometrica, vol. 47, pp. 263–291, 1979.
[23] D. Kahneman, P. Slovic, and A. Tversky, Judgment under Uncertainty:
Heuristics and Biases.
Cambridge University Press, 1982.
[24] M. J. Osborne and A. Rubinstein, A Course In Game Theory.
Cam-
bridge MA: MIT Press, 1994.

