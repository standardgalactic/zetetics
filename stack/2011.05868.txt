1 
 
Cite as: Dresp-Langley, B. Seven Properties of Self-Organization in the Human Brain. Big Data 
and Cognitive Computing, 2020; 4, article10. 
 
Seven properties of self-organization in the human brain 
Birgitta Dresp-Langley 1* 
1 Centre National de la Recherche Scientifique (CNRS) France, ICube UMR 7357 CNRS-
University of Strasbourg; birgitta.dresp@unistra.fr 
 
* Correspondence: birgitta.dresp@unistra.fr; 
Received: date; Accepted: date; Published: date 
Abstract: The principle of self-organization has acquired a fundamental significance in the 
newly emerging field of computational philosophy. Self-organizing systems have been 
described in various domains in science and philosophy including physics, neuroscience, 
biology and medicine, ecology, and sociology. While system architecture and their general 
purpose may depend on domain specific concepts and definitions, there are (at least) seven key 
properties of self-organization clearly identified in brain systems: 1) modular connectivity, 2) 
unsupervised learning, 3) adaptive ability, 4) functional resiliency, 5) functional plasticity, 6) 
from-local-to-global functional organization and 7) dynamic system growth. These are defined 
here in the light of insight from neurobiology, cognitive neuroscience and Adaptive Resonance 
Theory (ART), and physics to show that self-organization achieves stability and functional 
plasticity while minimizing structural system complexity. A specific example informed by 
empirical research is discussed to illustrate how modularity, adaptive learning, and dynamic 
network growth enable stable yet plastic somatosensory representation for human grip force 
control. Implications for the design of “strong” artificial intelligence in robotics are brought 
forward. 
Keywords: self-organization; computational philosophy; brain; synaptic learning; adaptation; 
functional plasticity; activity-dependent resonance states; circular causality; somatosensory 
representation; prehensile synergies; robotics 
 
1. Introduction 
The principle of self-organization [1] governs both structure and function, which co-evolve in 
self-organizing systems. Self-organizing systems [2] differ from any computational system where 
the architecture and all its functional aspects are created and controlled by their designer. In line 
with previous attempts at a comprehensive definition of the concept [1], the author proposes that 
self-organization may be defined in terms of a general principle of functional organization that 
ensures a system’s auto-regulation, stability, adaptation to new constraints, and functional 
autonomy. A self-organizing system [2], beyond the fact that it regulates and adapts its own 
behavior [2,3], is capable of creating its own functional organization [2,3,4]. The concept of self-
organization acquires a critically important place in the newly emerging field of computational 

2 
 
philosophy, where it inspires and lends conceptual support to new approaches to complex 
problems, in particular in the field of Artificial Intelligence (AI) [5].  
Mathematical developments evoking self-organization as a general functional principle of 
learning and adaptation in biological systems hark back to Hebb’s work on synaptic plasticity [6], 
and to work by Minsky and colleagues [7] at the dawn of research on artificial intelligence in the 
context of Rosenblatt’s PERCEPTRON model [8]. Self-organization is the foundation of what is 
sometimes referred to as “strong AI” [5]. Systems with self-organizing properties [2] have been 
developed in physics [9], ecology and sociology [10,11], biology and medicine [12], and in 
neuroscience [3,13] and perceptual neuroscience [3,14] in continuity with the earlier 
PERCEPTRON approaches. Structure and functional organization of self-organizing systems 
vary depending on the field. Their properties relate to function more than to components. The 
fields of neuroscience and artificial intelligence in particular share a history of interaction in the 
theoretical development of both the concept of self-organization and self-organizing systems, and 
many of the current advances in AI were inspired by the study of neural processes in humans and 
other living species [3,5,13].  
Neuroscience provides a source of inspiration for new algorithms and architectures, 
independent of and complementary to mathematical methods. Such inspiration is well-reflected 
by many of the concepts and ideas that have largely dominated traditional approaches to AI. 
Neuroscience may also convey external validity to AI. If an algorithm turns out to prove a good 
model for a functionally identified process or mechanism in the brain, then such biological 
plausibility lends strong support to the fitness of the algorithm for the design of an intelligent 
system. Neuroscience may thus help conceive new algorithms, architectures, functions, and codes 
of representation for the design of biologically plausible AI by using a way of thinking about 
similarities and analogies between natural and artificial intelligence [15]. Such two-way 
conceptual processes acquires a particular importance in the newly emerging field of 
computational philosophy, which regroups a wide range of approaches relating to all fields of 
science. 
Computational philosophy [16] is aimed at applying computational techniques, models, and 
concepts to advance philosophical and scientific discovery, exploration, and argument. 
Computational philosophy is neither the philosophy of computation, an area that asks about the 
nature of computation itself, nor the philosophy of artificial intelligence. Computational 
philosophy represents a self-sufficient area with a widespread application across the full range of 
scientific and philosophical domains. Topics explored in computational philosophy may draw 
from standard computer programming,  software engineering, artificial intelligence, neural 
networks, systems science, complex adaptive systems, and computer modeling. As a relatively 
young and still growing domain, its field of application is broad and unrestricted within the 
traditional discipline of general philosophy. In the times of Newton, there was no epistemological 
boundary between philosophy and science. Across the history of science, there has never been a 
clear division between either computational and non-computational philosophy, or computational 
philosophy and other computational disciplines [16].  
The place of computational philosophy in science entirely depends on the viewpoint adopted, 
and goal pursued by the investigator [17,18]. If the goal pursued is to enrich computational 
philosophy based on an understanding of brain processes, then the functional characteristics of 
brain mechanisms may fuel the development of computational philosophy. If the goal is to enrich 
brain science based on computational philosophy, then empirical brain research will be fueled by 
computational philosophy for building brain models reflective of mechanisms identified in the 
human brain [17,18]. This article is a conceptual essay written from the viewpoint of 

3 
 
computational philosophy. It highlights seven general functional key properties related to the 
principle of self-organization, which are then discussed under the light of a specific example 
from sensory neuroscience, backed by empirical data. How modularity, adaptive learning, and 
dynamic network growth enable stable somato-sensory representation for human grip force 
control in a biological neural network (from hand to brain and back) with previously identified 
functional plasticity is illustrated.  
Since structure and functional organization co-evolve in self-organizing systems [1,2], one 
cannot account for such systems without providing an account for the functional properties most 
closely linked to its self-organizing capacity. The latter is generally described in terms of 
spatiotemporal synergies [1,9]. In the brain, neurons respond at time scales of milliseconds, while 
perception, which is experience and memory dependent, takes longer to form. Such timescale 
separation between long-time scale parameters and short-time scale functioning [19,20] is akin to 
that described for physical synergetic systems [9], and reflects the circular causality that is 
characteristic of self-organization in general [1]. The following sections start with an overview of 
seven key properties of systems that “self-organize”. This is followed by a discussion of 
examples of such properties in the human somato-sensory system [21,22] involved in the control 
of prehensile synergies for grip-force adaptation. The example provides a biologically plausible 
conceptual support for the design of autonomous self-organization (AI) in soft robotics, and 
illustrates why the seven key properties brought forward here in this concept paper are conducive 
to advancing the development of “strong AI” [5], as pin-pointed in the conclusions.  
2. Seven key properties of self-organization 
Seven properties linked to the principle of self-organization have been described on the basis 
of functional investigation of the human brain: 1) modular connectivity, 2) unsupervised learning, 
3) adaptive ability, 4) functional resiliency, 5) functional plasticity 6) from-local-to-global 
functional organization and 7) dynamic system growth. 
2.1.Modular functional architecture and connectivity 
Modularity refers to a computational and/or structural design principle for systems that can be 
decomposed into interacting subsystems (nodes, modules) that can be understood independently. 
Modular systems design is aimed at reducing complexity [23] by a fundamental design principle 
identified in biological neuronal systems at the scale of cells (units, neurons), local circuits 
(nodes), and interconnected brain areas (subsystems) [24]. The human brain’s neuronal network 
architecture is not based on a genetically preformatted design, although some of it may be 
prewired, but is progressively shaped during ontogenetic development by physiological and 
chemical changes that obey computational rules of activity-dependent self-organization [25]. At 
the medium level of local circuits, the brain (cortex) is organized in local clusters of tightly 
interconnected neurons that share common input. The neuronal targets that constitute a basic 
computational module share similar functional properties. Activity-dependent self-organization 
influences the system’s modularity on the one hand, and modular connectivity promotes 
spontaneous firing activity on the other [25]. Thus, the modular connectivity of a self-organizing 
system and its capacity of self-organization are interdependent, and they co-evolve in a mutually 
reinforcing process to ensure the simultaneous development of both structural and functional 
capacity. This entails that the more such a system learns, the more active connections it will 

4 
 
develop on the one hand, and the more it will be able to learn, on the other. For its structural and 
functional development, a self-organizing system exclusively uses unsupervised learning. 
2.2.Unsupervised Learning 
Unsupervised learning [6,26,27,28], one may also call it self-reinforced learning,  is essential 
to the principle of self‐organization, as illustrated by  functional dynamics of the neural network 
systems described in Adaptive Resonance Theory (ART) and Self‐Organizing Maps (SOM). 
Unsupervised learning is essential to overcome the stability–plasticity dilemma in neural 
networks, and both ART [27] and SOM [28,29] are based on unsupervised approaches that are 
fundamental in machine learning in general, and in Artificial Intelligence (AI) in particular. The 
Hebbian synapse and synaptic learning rules [6] are the fundamental conceptual basis of 
unsupervised learning in biological [30] and artificial neural networks [31]. A synapse refers to 
connection between two neurons in a biological or artificial neural network, where the neuron 
transmitting information via a synapse or synaptic connection is referred as the pre-synaptic 
neuron, and the neuron receiving the information at the other end of a synaptic connection as the 
post-synaptic neuron (Figure 1). The information propagation efficiency of biological and 
artificial synapses is strictly self-reinforcing as the more a synapse is stimulated, the more 
effectively information flows through the connection, which ultimately results in what Hebb [6], 
and subsequently others [3,31] have called Long-Term Potentiation (LTP). Synaptic connections 
that are not repeatedly stimulated and as a consequence not self-reinforced will lose their 
information propagation efficiency, which ultimately results in Long-Term Depression (LTD).  
 
 
Figure 1: Schematic illustration of Hebbian synapses within a small neural network. Self-
reinforcing synaptic learning is by definition unsupervised and involves the progressive 
increment of the synaptic weights (w) of efficiently stimulated connections, which are thereby 
long-term potentiated, while non-reinforced synapses will lose their efficiency and ultimately 
become long-term depressed. 
 
The information propagation in unsupervised synaptic learning in neural networks may be event-
driven [32], clock-driven [33], or a combination of both [31]. The Long-Term Potentiation (LTP) 
of efficient synaptic connections on the one hand, and the Long-Term Depression (LTD) of 
inefficient connections on the other promote the emergence of an increasingly effective 
functional organization in the neural network akin to that found in biological organisms, chemical 

5 
 
structures, and ecosystems. In computational thinking and philosophy, self-reinforcing Hebbian 
learning may, indeed, be seen as a ground condition for adaptive system function, a highly 
dynamic, unsupervised learning process where local connections change state towards 
potentiation or depression, depending on how efficiently they propagate information across the 
system. Synaptic long-term potentiation and long-term depression are not definitive. A depressed 
state may reverse to a potentiated one, and vice versa, as a function of a persistent change in the 
system’s external environment (stimuli), or of a specific chemical treatment or drug in the case of 
biological neural networks. LTP and LTD have acquired a potentially important role in 
contemporary neuroscience [34], and may be exploited to treat disorder and disease in the human 
brain, knowing that a variety of neurological conditions arise from either lost, or excessive 
synaptic drive due to sensory deprivation during childhood, brain lesions, or disease [35]. 
Manipulation of relative synaptic efficiency using various technologies may provide a means of 
normalizing synaptic strength and thereby ameliorating plasticity-related disorders of the brain 
[34,35]. Thus it may, indeed, be argued that the reversibility of synaptic efficiency as a function 
of changes during self-reinforcing learning drives the self-organizing system’s adaptive ability. 
 
2.3.Adaptive ability 
 
A self-organizing system will adapt its functional organization to significant changes in the 
environment by the ability to learn new "tricks" to cope with new problems of increasing 
complexity. Biological neural networks in the human central nervous system have the ability to 
adapt their functional fine-tuning to sudden changes in the environment [36], making the brain 
remarkably efficient at coping with an often unpredictable, ever-changing external world. In any 
self-organizing neural network, such adaptation relies heavily on their modular connectivity on 
the one hand, and on synaptic (Hebbian) plasticity, on the other [37,38,39]. Research on so-called 
neuromodulation [40,41,42], a biological mechanism that dynamically controls intrinsic 
properties of neurons and their response to external stimuli in a context-dependent manner, has 
produced simulations of adaptive system behavior. Adaptive Resonance Theory (ART) uses self-
organization to explain how normal and abnormal brains learn to categorize and recognize 
objects and events in a changing world, and how normal as well as abnormal learned categories 
may be consolidated in memory for a long time [42]. Thus, brain pathology may be conceived in 
terms of a self-organizing system’s adaptive ability gone wrong. This possibility was already to 
some extent taken into consideration by Darwin [43], who noted that natural selection can act 
together with other processes, including random changes in the frequencies of phenotypic 
differences that are not under strong selection, and changes in the environment, which may 
reflect evolutionary changes in the organisms themselves. At the cellular level, adaptation refers 
to changes in a cell’s or neuron’s behavior in response to adverse or varying environmental 
changes. Adaptation may be normal, or pathological (abnormal), depending on extent and type of 
environmental pressure on the cell, a system of cells, or a whole brain network [44,45,46,47]. 
Under extreme external conditions, some forms of pathological adaptation may be an effective 
means towards the general goal of survival. In human behavior, the Stockholm Syndrome is one 
such example, where hostages start taking sides with their aggressors to functionally adapt to the 
terrible fact that they are at their complete mercy. Adaptive system ability as a concept, in the 
brain sciences and in computational philosophy, helps conceive intelligent systems with a 
capacity to generate order from, or preserve order within, external chaos. Seemingly random 
perturbations will help a self-organizing system develop and perform even better, rather than 
prevent its evolution. Perturbations will promote the emergence of an increasingly effective 
functional organization, as found in biological organisms, chemical structures, or ecosystems. 
Self-organizing adaptation is to be seen as a highly dynamic process [20,46,47], where 
components are constantly changing state as a function of state changes in other components. 

6 
 
Such complex mutual dependency in self-organization was not known in the times of Darwin, 
and is therefore not included in traditional definitions of the concept “adaptation” [43,44,45]. The 
adaptive systemic changes we are talking about here in this concept paper are determined by self-
reinforcement of connections that profit the system’s functioning and ensure its dynamic 
functional growth on the one hand, and by local suppression of connections that are either 
redundant, or disserve the system, on the other. Both processes, reinforcement and inhibition, are 
critical to sustain a self-organizing system’s ability to cope with unexpected external changes or 
pressure, and thereby also ensure its functional resiliency. 
 
2.4.Functional resiliency 
 
A self-organizing system’s adaptive ability implies functional resiliency. After lesion or 
damage, a human brain will continue to function, often astonishingly well and without any 
detectable change in efficiency. The human brain can endure numerous micro-strokes with 
seemingly no detrimental impact, and is resilient against both targeted and random damage or 
lesions [48,49]. Self-organizing systems, like the human brain, are intrinsically robust and can 
withstand a variety of perturbations, even partial destruction. The strength of functional 
interaction between any two system nodes is not solely determined by the presence or absence of 
a direct connection, but mostly by the number of indirect (long-range) connections [50]. These 
long-range connections, which will be discussed in greater detail in 5) here below, are 
indispensable to ensure self-repair or self-correction of partial systemic damage, and make the 
system capable of returning to its initial functional state after local damage. By virtue of their 
modular connectivity discussed here above in 1), and self-reinforcing learning capacity discussed 
here above in 2), system components or subsystems (synapses or networks) that have initially 
learnt to fulfill a specific function can spontaneously adapt to perform a different, new function 
that was  previously ensured by the damaged component(s). This self-organizing ability is 
referred to as functional plasticity. 
 
2.5 Functional plasticity 
 
The functional resiliency of a self-organizing system implies functional plasticity [21,22,51], 
which is a necessary ground condition for system resiliency, but also achieves a purpose well 
beyond. Functional plasticity ensures system functioning under adverse conditions and/or after 
partial system damage. Posttraumatic stress disorder (PTSD), for example, is associated with 
plastic functional changes in the human medial prefrontal cortex, hippocampus, and amygdala 
that correlate with a smaller hippocampal volume, and both reversed to normal after treatment 
[52]. Like in the human brain, where a functional subsystem may take over the functions of 
another after brain damage [21,22,51], a functional subsystem may appear spontaneously and 
maintain its function autonomously by self-organization in a computer generated system. The 
control needed to achieve this has to be distributed across system levels, components or cells, 
and/or sub-systems. If system control were centralized in a subsystem or module, then the system 
as whole would lose its organization whenever the sub-system is damaged or destroyed. Use-
dependent long-term changes of neuronal response properties must be gated to prevent irrelevant 
activity from inducing inappropriate modifications. Local network dynamics contribute to such 
gating, as synaptic modifications [53] depend on temporal contiguity between pre-synaptic and 
post-synaptic activity, there are observable stimulation-dependent modifications, as shown on the 
example of orientation selectivity in adult cat visual cortex [35]. The stability-plasticity dilemma, 
a constraint for intelligent systems, is potentially resolved in self-organizing systems, such as 
those in ART [3,14,47]. Plasticity is necessary for the integration of new knowledge by self-

7 
 
reinforced learning, but too much of it compromises systemic stability and may cause 
catastrophic forgetting of previous knowledge [54]. It is assumed that too much plasticity will 
result in previously learnt data being constantly forgotten, whereas too much stability will hinder 
self-reinforce learning at the synaptic level, yet, the exact functional relationship between 
changes in synaptic efficacy and structural plasticity is not entirely understood. It has been 
proposed that a continuum exists between the two, such that changes in synaptic efficacy precede 
and instruct structural changes, however, in other cases, structural changes may occur without 
any stimulation producing an initial change in local synaptic efficiency [55], which points 
towards the critical functional role of long-range connections [56] within the from-local-to-global 
functional organization of self-organizing systems. 
 
2.6.From-local-to-global functional organization 
 
In a self-organizing neural network, changes in the system during self-reinforced synaptic 
learning are initially local, as components or neurons initially only interact with their nearest 
"neighbors". Though local connections are initially independent of connections farther away, self-
organization generates “global order” on the basis of many spontaneous, initially local, 
interactions [56], where the most efficient synaptic connections self-reinforce, are long-term 
potentiated as described here above in 2) and, ultimately, acquire propagation capacity beyond 
local connections. This leads to the formation of functionally specified long-range connections, 
or circuits which, by virtue of self-organization, self-reinforce on the basis of the same Hebbian 
principles that apply to single synapses, however, the rules by which long-range circuits of 
connections learn can no longer be accounted for in terms of a Hebbian linear model. The human 
brain is, again, the choice example of a complex biological structure where local, modular 
processing potentiates global integrative processing. Current functional brain anatomy suggests 
areas  that form domain-specific hierarchical connections [57,58] on the one hand, and 
multimodal association areas receiving projections from more widely distributed functional 
subsystems [59]. Dominance of one connectivity profile over the other can be identified for many 
areas [56], revealing the self-organizing principles of long-range cortical-cortical functional 
connectivity. Early visual cortical areas such as V1 and V2 already show a functional 
organization beyond strictly local hierarchical connections [58,60]. The prefrontal, temporal, and 
limbic areas display “functional hubs” [56], projecting long-range connections across larger 
distances to form the “neural epicenters” [56] of scale-free, distributed brain networks [61,62]. 
The “beyond the classic receptive field” functional organization of the visual brain was 
progressively unraveled in behavioral and functional neuroscience over the last 30 years [60]. 
The discovery of input effects from beyond the “classic receptive field”, as previously identified 
and functionally defined in much earlier, Nobelprize awarded work [63-66], has shown that 
neuronal activity recorded from cortical areas V1 and V2 in response to visual stimuli is 
modulated by stimuli presented outside the corresponding receptive fields on the retina [67-69]. 
This is direct evidence for contextual modulation of neural activity, and indirectly reflects 
functional properties of long-range neural connections at early processing levels in the visual 
brain [68,69]. In higher visual areas such as the temporal lobe, visual receptive fields increase in 
size and lose retinotopic organization, encoding increasingly complex features [60]. This from-
simple-to-complex, self-organizing functional hierarchy forms the core of the LAMINART 
model family [70-71] of Adaptive Resonance Theory [3,14,47]. In the LAMINART neural 
networks, self-organizing long-range cooperation and short-range competition, whereby locally 
stimulated bipolar neurons complete boundaries across gaps in oriented line or edge contrast 
stimuli by receiving strong excitatory inputs from both sides, or just one side of their receptive 
fields. The more strongly activated bipolar cells inhibit surrounding bipolar cells within a 

8 
 
spatially short-range competitive network. The short-range network communicates with long-
range resonant feedback networks connecting the interblob and blob cortical streams within V1, 
V2, and V4 of the visual cortex. The resonant feedback networks enable boundaries and surfaces 
in images to emerge as consistent representations on the basis of computationally complementary 
rules. This self-organizing property of resonant feedback networks in ART is called 
complementary consistency [72]; the computational mechanisms that ensure complementary 
consistency contribute to three-dimensional perceptual organization [72,73,74,75]. The long-
range resonant properties of the neural network architectures exploited by ART enable the self-
organizing system to grow dynamically. 
 
2.7.Dynamic functional growth 
 
A self-organizing system is dynamic and its components (cells, neurons, circuits) are 
constantly changing states relative to each other. As explained here above under 1), structure and 
function of the system are mutually dependent, which entails that the changes that occur while 
such a system is developing further, i.e. growing, are not arbitrary but activity-dependent 
[76,77,78,99]. While the system grows by changing states, there will be relative states that will be 
particularly beneficial to the system’s effectiveness and, as a consequence, these states self-
reinforce along similar principles as those described here above in 2). When consistently 
reinforced, newly emerging system states will, ultimately, become stable states, but with 
functional plasticity as explained here above in 4) to resolve the stability-plasticity dilemma 
[3,54].  Less beneficial or useless new relative states will not self-reinforce and, as a 
consequence, be inhibited and ultimately functionally depressed. Each connection within a self-
organizing system has its own, individual characteristics, like a species within  an ecosystem. A 
particular example of non-linear dynamic functional growth in fixed-size neural networks (Figure 
2) would be activity-dependent formation of dedicated resonant circuitry [3,79]. 
 
 
 

9 
 
Figure 2: Schematic illustration of self-organizing formation of dedicated resonant circuitry in a 
fixed-size neural network of ten neurons only. An exponential number of functional states are 
possible therein, allowing even a small-size network to develop new, dynamic functionalities 
without the need for adding further structural complexity. Resonant neurons (highlighted in red 
colour) are primed throughout their functional development to preferentially process input which 
carries statistically “strong” signals, as explained previously in [79]. When activated, resonant 
neurons send signals along all delay paths originating from them, and all those receiving a signal 
coinciding with the next input signal remain activated. The formation of resonant circuitry is 
activity-dependent; long-term potentiated connections between resonant neurons may become 
progressively depressed, as in the model of self-reinforcing (Hebbian) synaptic learning, when 
their function is no longer activated. 
 
The amount of different individual characteristics within the functional structure  directly 
determines the system’s functional complexity. Individual components, or cells, fit in a 
functionally specified “niche” within the system. The propagation of fits is self-reinforcing by 
nature, and the larger the niche, the quicker the propagation of additional functions in 
increasingly  larger sub-circuits, exerting increasingly stronger attraction on functionally still 
independent cells. Such propagation of fits drives a positive feedback process enabling explosive 
system growth, and the production of new functional circuitry in existing network structures. A 
system’s growth generally stops when the system resources are exhausted. A self-organizing 
system, however, never stops growing dynamically. As illustrated here above on the example of 
resonant sub-circuitry formation in structurally fixed/limited neural networks (Figure 2), self-
organized functional growth does not require adding structural component (cells, neurons, 
subsystems). The system can grow and develop new, dynamic functionalities without the need for 
adding further structural complexity. As the external environment of the system changes, 
functional components or cells directly interacting with the environment will adapt their state(s) 
in a self-reinforcing process to maintain their fitness within the system. This adaptive fit will 
propagate further inwards, until the whole functional structure is fully adapted to the new 
situation. Thus, a dynamically growing self-organizing system constantly re-organizes by 
mutually balancing internal and external pressures for change while trying to maintain its general 
functional organization, and to counteract any loss thereof. Functional self-preservation is, 
indeed, a self-organizing system’s main purpose, and each component or cell is adaptively tuned 
to perform towards this goal. A self-organized system is stable, largely scale-invariant, and robust 
against adverse conditions. At the same time, it is highly dynamic. In physics, systems achieve 
so-called “criticality” by the fine-tuning of control parameters to a specific value for which 
system variations become scale-invariant. In biological systems, criticality occurs without the 
need for such fine-tuning. The human brain is an example of such a system. This self-tuning to 
criticality, accounted for in physics by graph theory, is called self-organized criticality [80]. 
3. Seven properties of self-organization in a somatosensory neural network 
The brain structures which subserve cognitive functions require sensory experience for the 
formation of neuronal connections by self-organization during learning [81]. Neuronal activity 
and the development of functionally specific neural networks in the continuously learning brain 
are thus modulated by sensory signals. The somatosensory cortical network [82], or S1 map, in 
the primate brain is an example of such self-organization. S1 refers to a neocortical area that 
responds primarily to tactile stimulations on the skin or hair. Somatosensory neurons have the 
smallest receptive fields and receive the shortest-latency input from the receptor periphery. The 
S1 cortical area is conceptualized in current state of the art [82,83] as containing a single map of 

10 
 
the receptor periphery. The somatosensory cortical network has a modular functional 
architecture and connectivity (property 1), with highly specific connectivity patterns 
[82,83,84,85], binding functionally distinct neuronal subpopulations from other cortical areas into 
motor circuit modules at several hierarchical levels [84]. The functional modules display a 
hierarchy of interleaved circuits connecting via inter-neurons in the spinal cord, in visual sensory 
areas, and in motor cortex with feed-back loops, and bilateral communication with supraspinal 
centers [84,85]. The from-local-to-global functional organization (property 6) of motor circuits 
relates to precise connectivity patterns, and these patterns frequently correlate with specific 
behavioral functions of motor output. Current state of the art suggest that developmental 
specification, where neuronal subpopulations are specified in a process of precisely timed 
neurogenesis [85], determines the self-organizing nature of this connectivity for motor control, in 
particular limb movement control [84,85]. The functional plasticity (property 5) of the 
somatosensory cortical network is revealed by neuroscience research investigating the 
somatosensory cortical map has shown that brain representations change adaptively following 
digit amputation in adult monkeys [21]. In the human primate [86], somatosensory 
representations of the fingers left intact after amputation of others on the same hand become 
expanded in less than ten days after amputation, when compared with representations in the intact 
hand of the same patient, or to representations in either hand of controls. Such network expansion 
reflects the functional resiliency (property 4) of the self-organized somatosensory system. 
The human hand has evolved [87] as a function of active constraints [88-100], and in 
harmony with other sensory systems such as the visual and auditory brain [97,99,101]. Grip force 
profiles are a direct reflection of complex low-level, cognitive, and behavioral synergies this 
evolution has produced [87-101]. The state of the art in experimental studies on grip force control 
for lifting and manipulating objects [88,89,91,93,94] provides insight into the contributions of 
each finger to overall grip strength and fine grip force control. The middle finger, for example, 
has evolved to become the most important contributor to gross total grip force and, therefore, is 
most important for getting a good grip of heavy objects to lift or carry, while the ring finger and 
the small (pinky) finger have evolved for the fine control of subtle grip force modulations, which 
is important in precision tasks [102-106]. Human grip force is governed by self-organizing 
prehensile synergies [91,92] that involve from-local-to-global functional interactions (property 
6) between sensory (low-level) and central (high-level) representations in the somatosensory 
brain. Grip force can be stronger in the dominant hand compared with the non-dominant hand, 
and may reverse spontaneously depending on the necessity for adaptive ability (property 3) as a 
function of specific environmental constraints [95,96,100]. In recent studies, the grip force 
profiles from thousands of force sensor measurements collected from specific locations on 
anatomically relevant finger parts on the dominant and non-dominant hands revealed spontaneous 
adaptive grip force changes in response to sensory stimuli [105], and long-term functional 
plasticity (property 5) as a function of task expertise [103,104]. 
Somatosensory cortical neural networks of the S1 map [81] develop their functional 
connectivity [83-86] through a self-organizing process of activity-dependent, dynamic functional 
growth (property 7). This process is fueled by unsupervised learning (property 2) and, more 
specifically, synaptic (cf. Hebbian) learning, which drives spontaneous functional adaptation as 
well as long-term functional re-organization and plasticity [22,23,54,56,83]. An example of this 
process, fueled by recent empirical data from thousands of sensor data collected from 
anatomically relevant locations in the dominant and non-dominant hands of human adults, is 
illustrated here in Figures 3, 4 and 5. 
 

11 
 
 
 
Figure 3: Schematic illustration of self-organizing functional reorganization in a fixed-size 
neural network in the somatosensory brain before (left) and after (right) unsupervised learning of 
a visually guided manual robotic precision task [103,104]. Mechanoreceptors on the middle 
phalanxes of the small (R1) and the middle fingers (R2) are indicated. Two different network 
representations correspond to brain-behaviour states before (left) and after acquisition of grip 
force expertise (right) for performing the robotic precision task. The different levels of 
connectivity used here are arbitrarily chosen, and for illustration only; single nodes in the 
networks displayed graphically here may correspond to single neurons, or to a subpopulation of 
neurons with the same functional role. Red nodes may represent motor cortex (M) neurons, blue 
nodes may represent connecting visual neurons (V). Only one-way propagation is shown here to 
keep the graphics simple, knowing that the somatosensory brain has multiple two-way 
propagation pathways with functional feed-back loops [82-85]. 
The grip force profiles of a novice (beginner) and a skilled expert in the manipulation of the 
robotic device directly reflect such differences in somatosensory cortical representation before 
and after learning. Individual grip force profiles, corresponding to thousands of individual force 
sensor data, were recorded in real time from different sensor locations, including R1 and R2 
(Figure 3) on the middle phalanxes of the small (R1) and the middle fingers (R2) in the hands of 
a total beginner and the expert across several robotic task sessions. The grip force profiles are 
shown in Figure 4 here below. They display two radically different functional states with respect 
to gross (middle finger) and fine (small finger) grip force control, translating motor expertise and 
functionally reorganized somatosensory network states driven by self-organization. 
 
The self-organized functional reorganization due to plasticity shown here is stable, as 
reflected by stable grip force profiles in the expert across task sessions [103]. By comparison, the 
grip force profiles of the beginner do not display the same stability, as shown by the statistical 
analyses reported elsewhere [103,104]. It may be assumed that stable dynamic functional growth 
in the neural network system generating the somatosensory representations is driven by such 
long-term plasticity, which reflects a process of long-term adaptation to specific task constraints. 

12 
 
This long-term adaptation ensures system stability, but does not reflect a permanent system state. 
However, the somatosensory system also displays spontaneous functional plasticity and 
reorganization, and rapid adaptation to new constraints [21,22,81-85].  
 
 
Figure 4: Individual grip force profiles of an expert (left) and a beginner (right) in a robotic task 
[103,104] reflecting two radically different functional states with respect to gross (middle finger) 
and fine (small finger) grip force control, translating motor expertise and functionally reorganized 
somatosensory network states (cf. Figure 3), governed by self-organization. 
 
The grip force profiles of one and the same individual adapt spontaneously to new sensory input 
from other modalities, as predicted by the general functional organization of the somatosensory 
brain networks [82-86]. Such spontaneous adaptive ability is reflected by dynamic changes that 
are short-term potentiated, rather than reflective of long-term plasticity. An example of 
spontaneous grip force adaptation to new visual input in one and the same individual is shown 
here below in Figure 5. The subject was blindfolded first, then made to see again, during a 
bimanual grip task where young male adults had to move two weighted handles up and down 
[105]. The individual grip force profiles corresponding to force sensor recordings from the 
middle phalanxes of the forefinger and the middle finger in the dominant hand are shown for 
comparison (Figure 5). 
 

13 
 
Figure 5: Spontaneous adaptive reorganization of an individual’s grip force profile (dominant 
hand) during a bimanual grip task executed first blindfolded, and then with both eyes open. 
Unpublished data from a study described in [106] are shown. Gross grip force in the middle 
finger spontaneously increases with sudden visual input (left), while simultaneous grip force in 
the forefinger decreases (right).  
The example here above illustrates seven key properties of self-organization in the 
somatosensory brain, and points towards the implications of self-organized brain learning for the 
design of robust control schemes in large complex systems with unknown dynamics, which are 
difficult to model [108]. Beyond the functional stability and resilience of self-organizing systems, 
self-reinforced unsupervised learning based on differential plasticity, with feedback control 
through internal system dynamics, may enable robots [107] to learn to relate objects on the basis 
of specific sensorimotor representations, for example.  
 
 
Figure 6: Conceptual diagram illustrating a “closed-loop” link between systems neuroscience 
and robotics / AI. 
Conclusions 
Self-organization is a major functional principle that allows us to understand how the neural 
networks of the human brain continuously generate new knowledge at all hierarchical levels, 
from sensory to cognitive representation. From the philosophical standpoint, the principle of self-
organization establishes a clear functional link between the “mental” and the “physical” 
[109,110]. As a fundamental conceptual support for the design of intelligent systems, it provides 
conceptual as well as mathematical [1,2,3] tools to help achieve system stability and reliability, 
while minimizing system complexity. It enables specific fields such as robotics to conceive new, 
adaptive solutions based on self-reinforced systemic learning, where the activity of connections 
directly determines their performance and, beyond robotics, allows for the conceptual design of a 

14 
 
whole variety of adaptive systems that are able to learn and grow independently without the need 
for adding non-necessary structural complexity. There is a right balance between structural and 
functional complexity, and this balance conveys functional system plasticity; adaptive learning 
allows the system to stabilize but, at the same time, remain functionally dynamic and able to 
learn new data. Activity-dependent functional systemic growth in minimalistic sized network 
structures is probably the strongest advantage of self-organization; it reduces structural 
complexity to a minimum, and promotes dimensionality  reduction [111,112], which is a 
fundamental quality in the design of “strong” Artificial Intelligence [5]. Bigger neural networks 
akin to those currently used for deep learning [113] do not necessarily learn better or perform 
better [114]. Self-organization is the key to designing networks that will learn increasingly larger 
amounts of data increasingly faster as they learn, consolidate what has been learnt, and generate 
output that is predictive [47,68] instead of being just accurate. In this respect, the principle of 
self-organization will help design Artificial Intelligence that is not only reliable, but also meets 
the principle of scientific parsimony, where complexity is minimized, and functionality 
optimized. For example, a single session of robot controlled proprioceptive training induces 
connectivity changes in the somatosensory networks associated with residual motor and sensory 
function [115], translating into improved motor function in stroke patients. This example 
perfectly illustrates the closed-loop epistemological link (Figure 6) between systems 
neuroscience and robotics/AI. Robotic sensory learning models inspired by self-organizing 
somatosensory network dynamics (in short: AI) are currently developed [115,116,117], within 
and well beyond the context of motor rehabilitation programs. Further studies on the effects of 
repeated training sessions on neural network learning and somatosensory functional plasticity 
will 1) enable the possible generalization of motor relearning and treatment effects in the clinical 
domain, and 2) the development of reliable robot motor learning and control on the basis of 
“strong” neuro-inspired AI. 
Funding: This research received no external funding 
Acknowledgments: The support of the CNRS is gratefully acknowledged 
Conflicts of Interest: The authors declares no conflict of interest 
References 
1. Haken H. Self-Organization. Scholarpedia, 2008; 3(8):1401. Available online at:  
http://www.scholarpedia.org/article/Self-organization  
2. Self-Organizing Systems. Science Direct Topics, Elsevier, 2020; available online at: 
https://www.sciencedirect.com/topics/physics-and-astronomy/self-organizing-systems 
3. Grossberg, S. Self-organizing neural networks for stable control of autonomous behavior in a 
changing world. In J.G. Taylor (Ed.), Mathematical approaches to neural networks, 1993; 
Amsterdam : Elsevier Science Publishers,  pp.139-197. 
4. Crognier E. Biological adaptation and social behaviour. Ann Hum Biol, 2000; 27(3):221- 
37. 
5. Gershman SJ, Horvitz EJ, Tenenbaum JB. Computational rationality: A converging 
paradigm for intelligence in brains, minds, and machines. Science. 2015;349(6245):273-8. 
6. Hebb D. The Organization of Behaviour, 1949; John Wiley & Sons.  
7. Minsky M, Papert S. Perceptrons. An Introduction to Computational Geometry. 1969; MIT 
Press, Cambridge, MA.  
8. Rosenblatt F. The perceptron: a probabilistic model for information storage and organization 
in the brain. Psychological Review, 1958; 65:386–408. 

15 
 
9. Haken, H. Synergetic Computers and Cognition. 2004; 2nd ed., Springer, Berlin. 
10. Hahn T, Nykvist, B. 2017. Are adaptations self-organized, autonomous, and harmonious? 
Assessing the social–ecological resilience literature. Ecology and Society, 2017; 22(1):12. 
11. Westley FR, Tjornbo O, Schultz, L, Olsson, P, Folke, C, Crona, B, Bodin O. A theory of 
transformative agency in linked social–ecological systems. Ecology and Society, 2013; 
18:27. 
12. Deisboeck TS, Berens ME, Kansal AR, Torquato S, Stemmer-Rachamimov AO, Chiocca 
EA. Pattern of self-organization in tumour systems: complex growth dynamics in a novel 
brain tumour spheroid model. Cell Prolif, 2001; 34(2):115-34. 
13. Hassabis D, Kumaran D, Summerfield C, Botvinick M. Neuroscience-Inspired Artificial 
Intelligence. Neuron, 2017;95(2):245-258. 
14. Carpenter GA, Grossberg S. Discovering order in chaos: stable self-organization of neural 
recognition codes. Ann N Y Acad Sci. 1987;504:33-51.  
15. van Gerven M.  Computational Foundations of Natural Intelligence. Frontiers in 
Computational Neuroscience, 2017;11:112.  
16. Grim P. Computational Philosophy. The Stanford Encyclopedia of Philosophy, 2016;  
https://plato.stanford.edu/entries/computational-philosophy/ 
17. Churchland, PS, Sejnowski, T. The Computational Brain. 1992; MIT Press, Cambridge, 
Mass. 
18. Churchland PS. Brain-Wise. Studies in Neurophilosophy. 2002; MIT Press, Cambridge, 
Mass. 
19. Lehmann D, Strik WK, Henggeler B, Koenig T, Koukkou M. Brain electric microstates and 
momentary conscious mind states as building blocks of spontaneous thinking. I. Visual 
imagery and abstract thoughts. International Journal of Psychophysiology. 1998;29(1):1–11. 
20. Bassett DS, Meyer-Lindenberg A, Achard S, Duke T, Bullmore E. Adaptive reconfiguration 
of fractal small-world human brain functional networks. Proceedings of the National 
Academy of Sciences of the United States of America. 2006;103(51):19518–19523. 
21. Merzenich MM, Nelson RJ, Stryker MP, Cynader MS, Schoppmann A, Zook JM. 
Somatosensory cortical map changes following digit amputation in adult monkeys. Journal 
of Comparative Neurology. 1984;224(4):591–605. 
22. Wall JT, Xu J, Wang X. Human brain plasticity: an emerging view of the multiple substrates 
and mechanisms that cause cortical changes and related sensory dysfunctions after injuries of 
sensory inputs from the body. Brain Research Reviews. 2002;39(2-3):181–215. 
23. Newman M E J. Modularity and community structure in networks, Proc. Natl Acad. Sci.  
USA, 2006; 103:8577. 
24. Tetzlaff C, Okujeni S, Egert U, Wörgötter F, Butz M. Self-organized criticality in developing 
neuronal networks. PLoS Comput Biol, 2010;6(12):e1001013.  
25. Okujeni S, Egert U. Self-organization of modular network architecture by activity-dependent 
neuronal migration and outgrowth, 2019; eLife, 8:e47996 doi:10.7554/eLife.47996 
26. Kyan M, Muneesawang P, Jarrah K, Guan, L. Self‐Organization. In Unsupervised Learning 
(eds 
M. 
Kyan, 
P. 
Muneesawang, 
K. 
Jarrah 
and 
L. 
Guan), 
2014. 
doi:10.1002/9781118875568.ch3 
27. Grossberg, S. Adaptive Resonance Theory, Scholarpedia, 2013; 8(5):1569.  
http://www.scholarpedia.org/article/Adaptive_resonance_theory 
28. T. Kohonen. Physiological interpretation of the self-organizing map algorithm. Neural 
Networks, 1993;6: 895–905. 

16 
 
29. T. Kohonen. Self-Organizing Maps. Springer, Berlin, 1995. 
30. Berninger B, Bi GQ. Synaptic modification in neural circuits: a timely action, BioEssays, 
2002; 24: 212-222. 
31. Brette, R et al. Simulation of networks of spiking neurons: A review of tools and strategies, 
Journal of Computational Neuroscience, 2007; 23(3):349-98. 
32. Delorme A, Thorpe SJ. Spikenet: An event-driven simulation package for modelling large 
networks of spiking neurons. Network. 2003;14(4):613–627. 
33. Haider, B., Schulz, D. P. A., Häusser, M., and Carandini, M. Millisecond coupling of local 
field potentials to synaptic currents in the awake visual cortex. Neuron, 2016; 90, 35–42. doi: 
10.1016/j.neuron.2016.02.034 
34. Bliss TV, Cooke SF. Long-term potentiation and long-term depression: a clinical 
perspective. Clinics, 2011;66 Suppl 1:3-17. 
35. Cooke SF, Bear MF. How the mechanisms of long-term synaptic potentiation and depression 
serve experience-dependent plasticity in primary visual cortex. Philos Trans R Soc Lond B 
Biol Sci, 2013;369(1633):20130284.  
36. Koch H, Garcia AJ 3rd, Ramirez JM. Network reconfiguration and neuronal plasticity in 
rhythm-generating networks. Integr Comp Biol, 2011;51(6):856-68. 
37. Motanis H, Seay MJ, Buonomano, DV. Short-term synaptic plasticity as a mechanism for 
sensory timing. Trends Neurosci, 2018; 41:701–711. 
38. Frank MG, Cantera R. Sleep, clocks, and synaptic plasticity. Trends Neurosci, 2014; 
37(9):491-501. 
39. Galuske RAW, Munk MHJ, Singer W. Relation between gamma oscillations and neuronal 
plasticity in the visual cortex. Proc Natl Acad Sci U S A, 2019;116(46):23317-23325.  
40. Lizbinski KM, Dacks AM. Intrinsic and Extrinsic Neuromodulation of Olfactory Processing. 
Front Cell Neurosci, 2018;11:424. 
41. Vecoven N, Ernst D, Wehenkel A, Drion G. Introducing neuromodulation in deep neural 
networks to learn adaptive behaviours. PLoS One, 2020;15(1):e0227922. 
42. Grossberg S. Acetylcholine Neuromodulation in Normal and Abnormal Learning and 
Memory: Vigilance Control in Waking, Sleep, Autism, Amnesia and Alzheimer's Disease. 
Front Neural Circuits, 2017; 11:82.  
43. Darwin C. On the Origin of Species by Means of Natural Selection, or, the Preservation of 
Favoured Races in the Struggle for Life, 1859; London: John Murray. 
44. Liu Y. Natural Selection and Pangenesis: The Darwinian Synthesis of Evolution and 
Genetics. Adv Genet, 2018;102:121-142. 
45. Charlesworth D, Barton NH, Charlesworth B. The sources of adaptive variation.  Proc Biol 
Sci, 2017; 284:1855. 
46. Grossberg S. How hallucinations may arise from brain mechanisms of learning, attention, 
and volition. J. Int Neuropsychol Soc, 2000;6:579–588. 
47. Grossberg S. Cortical and subcortical predictive dynamics and learning during  perception, 
cognition, emotion and action. Philos Trans R Soc Lond B Biol Sci, 2009;364(1521):1223-
34. 
48. Joyce KE, Hayasaka S, Laurienti PJ. The Human Functional Brain Network Demonstrates 
Structural and Dynamical Resilience to Targeted Attack. PLoS Comput Biol, 2013; 
9(1:e1002885. 
49. Alstott J, Breakspear M, Hagmann P, Cammoun L, Sporns O. Modeling the Impact of 
Lesions in the Human Brain. PLoS Computational Biology, 2009; 5: e1000408. 

17 
 
50. Maslov S, Sneppen K. Specificity and Stability in Topology of Protein Networks. Science, 
2002; 296: 910–913. 
51. Silva PR, Farias T, Cascio F, Dos Santos L, Peixoto V, Crespo E, Ayres C, Ayres M, 
Marinho V, Bastos VH, Ribeiro P, Velasques B, Orsini M, Fiorelli R, de Freitas MRG, 
Teixeira S. Neuroplasticity in visual impairments. Neurol Int, 2018;10(4):7326.  
52. Bremner JD, Elzinga B, Schmahl C, Vermetten E. Structural and functional plasticity of the 
human brain in posttraumatic stress disorder. Prog Brain Res, 2008;167:171-86. 
53. Tanaka J, Horiike Y, Matsuzaki M, Miyazaki T, Ellis-Davies GC, Kasai H. Protein synthesis 
and neurotrophin-dependent structural plasticity of single dendritic spines. Science, 
2008;319(5870):1683-7. 
54. Mermillod M, Bugaiska A and Bonin P. The stability-plasticity dilemma: investigating the 
continuum from catastrophic forgetting to age-limited learning effects. Front Psychol, 2013; 
4:504. 
55. Bramati IE, Rodrigues C, Simões EL et al. Lower limb amputees undergo long-distance 
plasticity in sensorimotor functional connectivity. Sci Rep, 2019; 9:2518. 
56. Sepulcre J, Liu H, Talukdar T, Martincorena I, Yeo BTT, Buckner RL. The Organization of 
Local and Distant Functional Connectivity in the Human Brain. PLoS Comput Biol, 2010; 
6(6): e1000808. 
57. Gogtay N, Giedd JN, Lusk L, Hayashi KM, Greenstein D, et al. (2004) Dynamic mapping of 
human cortical development during childhood through early adulthood. Proc Natl Acad Sci 
U S A 101: 8174–8179. 
58. Fair DA, Cohen AL, Power JD, Dosenbach NU, Church JA, et al. Functional brain networks 
develop from a “local to distributed” organization. PLoS Comput Biol, 2009; 5: e1000381. 
59. Ungerleider LG, Haxby JV (1994) ‘What’ and ‘where’ in the human brain. Curr Opin 
Neurobiol 4: 157–165. 
60. Spillmann L, Dresp-Langley, B, Tseng, CH. Beyond the classic receptive field: The effect of 
contextual stimuli, Journal of Vision, 2015; 15:article7. 
61. Bullmore E, Sporns O. Complex brain networks: Graph theoretical analysis of structural and 
functional systems. Nat Rev Neurosci, 2009; 10: 186–198. 
62. Eguíluz VM, Chialvo DR, Cecchi GA, Baliki M, Apkarian AV. Scale-free brain functional 
networks. Phys Rev Lett, 2005; 94: 018102 
63. Hubel DH, Wiesel TN. Receptive fields of single neurones in the cat’s striate cortex. The 
Journal of Physiology, 1959; 148:574-591. 
64. Hubel DH, Wiesel TN. Receptive fields, binocular interaction and functional architecture in 
the cat's visual cortex. Journal of Physiology, 1962; 160:106-154. 
65. Hubel DH, Wiesel TN. Receptive fields and functional architecture in two nonstriate visual 
areas (18 and of the cat. Journal of Neurophysiology, 1965; 28:229-289. 
66. Hubel DH, Wiesel, TN. Receptive fields and functional architecture of monkey striate 
cortex. Journal of Physiology, 1968; 195, 215-243. 
67. Li HH, Chen CC. Surround modulation of global form perception. Journal of Vision, 2011; 
11(17):1-9.  
68. Muckli L, Vetter P, Smith, F. Predictive coding - contextual processing in primary visual 
cortex V1. Journal of Vision, 2011; 11:25. 
69. Muckli L, Petro LS. Network interactions: non-geniculate input to V1. Current Opinion in 
Neurobiology,2013; 23:195-201. 

18 
 
70. Grossberg S, Swaminathan, G. A laminar cortical model for 3D perception of slanted and 
curved surfaces and of 2D images: development, attention and bistability. Vision Research, 
2004; 44:1147-1187. 
71. Grossberg S, Yazdanbakhsh, A. Laminar cortical dynamics of 3D surface perception: 
stratification, transparency, and neon color spreading. Vision Research, 2005; 45: 1725-1743. 
72. Dresp-Langley B, Grossberg, S. Neural Computation of Surface Border Ownership and 
Relative Surface Depth from Ambiguous Contrast Inputs, Frontiers in Psychology, 2016; 
7:article1102 
73. Dresp-Langley  B,  Reeves A, Grossberg, S. Editorial: Perceptual Grouping—The State of 
The Art. Frontiers in Psychology, 2017; 8, article 67. 
74. Dresp-Langley B. Bilateral Symmetry Strengthens the Perceptual Salience of Figure against 
Ground. Symmetry, 2019; 11:225. 
75. Dresp-Langley B, Monfouga M. Combining Visual Contrast Information with Sound Can 
Produce Faster Decisions. Information, 2019; 10, 346. 
76. Grossberg S. The link between brain learning, attention, and consciousness, Consciousness 
and Cognition, 1999; 8(1):1–44. 
77. Grossberg S, Myers CW. The resonant dynamics of speech perception: interword integration 
and duration-dependent backward effects, Psychological Review, 2000; 107(4):735–767. 
78. Helekar, SA. On the possibility of universal neural coding of subjective experience, 
Consciousness and Cognition, 1999; 8(4):423–446. 
79. Dresp-Langley B, Durup J. A plastic temporal brain code for conscious state generation. 
Neural Plasticity, 2009;2009:482696.  
80. Hoffmann H, Payton DW. Optimization by Self-Organized Criticality. Scientific 
Reports,2018; 8(1):2358. 
81. Singer, W. The brain as a self-organizing system. Eur Arch Psychiatr Neurol Sci, 1986; 
236:4–9. 
82. Wilson S,  Moore C. S1 somatotopic maps. Scholarpedia, 2015; 10(4):8574. 
83. Braun, C et al. Dynamic organization of the somatosensory cortex induced by motor activity. 
Brain, 2001;124(11): 2259-2267. 
84. Arber S. Motor circuits in action: specification, connectivity, and function. Neuron. 
2012;74(6):975-89. 
85. Tripodi M, Arber S. Regulation of motor circuit assembly by spatial and temporal 
mechanisms. Curr Opin Neurobiol, 2012 ;22(4):615-23. 
86. Weiss T et al. Rapid functional plasticity of the somatosensory cortex after finger 
amputation. Experimental Brain Research, 2000;134(2): 199-203. 
87. Young, R.W. Evolution of the human hand: The role of throwing and clubbing. J Anat, 2003; 
202:165–174. 
88. Kinoshita H, Kawai S, Ikuta K. Contributions and co-ordination of individual fingers in 
multiple finger prehension. Ergonomics, 1995; 38(6):1212-30.  
89. Latash ML, Zatsiorsky VM. Multi-finger prehension: control of a redundant mechanical 
system. Adv Exp Med Biol, 2009; 629:597-618. 
90. Oku T, Furuya S. Skilful force control in expert pianists. Exp Brain Res, 2017; 235(5):1603-
1615. 
91. Zatsiorsky VM, Latash ML. Multifinger prehension: an overview. J Mot Behav, 2008; 
40(5):446-76. 
92. Sun, Y, Park J, Zatsiorsky VM, Latash ML. Prehension synergies during smooth changes of 
the external torque. Exp Brain Res, 2011; 213(4): 493-506.  

19 
 
93. Wu YH, Zatsiorsky VM, Latash ML. Static prehension of a horizontally oriented object in 
three dimensions. Exp Brain Res, 2002; 216( 2):249-61. 
94. Cha SM, Shin HD, Kim KC, Park JW. Comparison of grip strength among six grip methods. 
J Hand Surg Am, 2014; 39(11): 2277-84. 
95. Cai A, Pingel I, Lorz D, Beier JP, Horch RE, Arkudas A. Force distribution of a cylindrical 
grip differs between dominant and nondominant hand in healthy subjects. Arch Orthop 
Trauma Surg, 2018; 138(9):1323-1331. 
96. Bohannon RW. Grip strength: A summary of studies comparing dominant and non-dominant 
limb measurements. Percept. Mot. Skills, 2003; 96:728–730. 
97. Johansson RS, Cole KJ. Sensory-motor coordination during grasping and manipulative 
actions. Curr Opin Neurobiol, 1992; 2: 815–823. 
98. Eliasson AC, Forssberg H, Ikuta K, Apel I, Westling G, Johansson R. Development of 
human precision grip V. Anticipatory and triggered grip actions during sudden loading. Exp 
Brain Res, 1995; 106:425–433, 1995. 
99. Jenmalm P, Johansson RS. Visual and somatosensory information about object shape control 
manipulative fingertip forces. J Neurosci, 1997; 17: 4486–4499. 
100. Li KW, Yu R. Assessment of grip force and subjective hand force exertion under handedness 
and postural conditions. App Ergonomics, 2011; 42: 929-933. 
101. Aravena, P., Delevoye-Turrell, Y., Deprez, V., Cheylus, A., Paulignan, Y., Frak, V., Nazir, 
T. Grip force reveals the context sensitivity of language-induced motor activity during « 
action words » processing : evidence from sentential negation. PLOSone, 2012; 7: e50287. 
102. González, A.G.; Rodríguez, D.R.; Sanz-Calcedo, J.G. Ergonomic analysis of the dimension 
of a precision tool handle: A case study. Procedia Manuf, 2017; 13:1336–1343. 
103. de Mathelin M, Nageotte F, Zanne P, Dresp-Langley B. Sensors for Expert Grip Force 
Profiling: Towards Benchmarking Manual Control of a Robotic Device for Surgical Tool 
Movements. Sensors (Basel), 2019;19(20).  
104. Batmaz, AU, Falek, AM, Zorn, L, Nageotte, F, Zanne, P, de Mathelin, M, Dresp-Langley, B. 
Novice and expert behavior while using a robot controlled surgery system. In Proceedings of 
the 2017 13th IASTED International Conference on Biomedical Engineering (BioMed), 
Innsbruck, Austria, 20–21 February 2017; pp. 94–99. 
105. Batmaz AU, Falek, MA, de Mathelin, M, Dresp-Langley, B. Tactile sensors for measuring 
effects of sight, movement, and sound on handgrip forces during hand-tool interaction. 
Preprints, 2017; doi: 10.20944/preprints201711.0093.v1 
106. Batmaz, A.U.; de Mathelin, M.; Dresp-Langley, B. Seeing virtual while acting real: Visual 
display and strategy effects on the time and precision of eye-hand coordination. PLoS ONE, 
2017; 12:e0183789. 
107. Kawamura S, Svinin M. Advances in robot control: from everyday physics to human-like 
movements. 2006; Springer, New York. 
108. Dresp-Langley, B. Towards Expert-Based Speed–Precision Control in Early Simulator 
Training for Novice Surgeons. Information 2018, 9:316. 
109. Dresp-Langley, B. Why the brain knows more than we do: non-conscious representations 
and their role in the construction of conscious experience. Brain Sciences, 2011;2(1):1-21. 
110. Feigl H. The “Mental” and the “Physical”, in Concepts, Theories and the Mind-Body 
Problem, H. Feigl, M. Scriven, and G. Maxwell (Eds), vol. 2 of Studies in the Philosophy of 
Science, 1958; Minneapolis, USA. 

20 
 
111. Dresp-Langley, B.; Wandeto, J.M.; Nyongesa, H.K.O. Using the quantization error from 
Self-Organizing Map output for fast detection of critical variations in image time series. In 
ISTE OpenScience, Collection from Data to Decisions; Wiley & Sons: London, UK, 2018. 
112. Wandeto JM, Dresp-Langley B. The quantization error in a Self-Organizing Map as a 
contrast and color specific indicator of single-pixel change in large random patterns. Neural 
Networks, 2019; 119:273–285. 
113. Le Cun Y, Bengio Y, Hinton G. Deep Learning. Nature, 2015; 215:437. 
114. Dresp-Langley B, Ekseth OK, Fesl J, Gohshi S, Kurz M, Sehring HW. Occam’s Razor for 
Big Data? On Detecting Quality in Large Unstructured Datasets. Appl. Sci, 2019; 9:3065. 
115. Vahdat S, Darainy M, Thiel A, Ostry DJ. A Single Session of Robot-Controlled 
Proprioceptive Training Modulates Functional Connectivity of Sensory Motor Networks and 
Improves Reaching Accuracy in Chronic Stroke. Neurorehabil Neural Repair, 
2019;33(1):70-81. 
116. Miall RC, Kitchen NM, Nam SH, Lefumat H, Renault AG, Orstavik K, et al. Proprioceptive 
loss and the perception, control and learning of arm movements in humans: Evidence from 
sensory neuronopathy. Exp Brain Res. 2018;236:2137–2155. 
117. Elangovan N, Yeh IL, Holst-Wolf J, Konczak J. A robot-assisted sensorimotor training 
program can improve proprioception and motor function in stroke survivors. IEEE Int Conf 
Rehabil Robot, 2019; 2019:660-664. 
 
 

