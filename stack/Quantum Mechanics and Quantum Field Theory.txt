
This page intentionally left blank

Quantum Mechanics and Quantum Field Theory
Explaining the concepts of quantum mechanics and quantum ﬁeld theory in a precise
mathematical language, this textbook is an ideal introduction for graduate students
in mathematics, helping to prepare them for further studies in quantum physics.
The textbook covers topics that are central to quantum physics: non-relativistic
quantum mechanics, quantum statistical mechanics, relativistic quantum mechanics,
and quantum ﬁeld theory. There is also background material on analysis, classical
mechanics, relativity, and probability. Each topic is explored through a statement of
basic principles followed by simple examples. Around 100 problems throughout the
textbook help readers develop their understanding.
Jonathan Dimock is Professor of Mathematics, SUNY at Buffalo. He has carried out
research in various areas of mathematical physics, including constructive quantum
ﬁeld theory, quantum ﬁeld theory on manifolds, renormalization group methods, and
string theory.


Quantum Mechanics
and Quantum Field Theory
A Mathematical Primer
JONATHAN DIMOCK
SUNY at Buﬀalo

C A M B R I D G E U N I V E R S I T Y P R E S S
Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore,
São Paulo, Delhi, Dubai, Tokyo, Mexico City
Cambridge University Press
The Edinburgh Building, Cambridge CB2 8RU, UK
Published in the United States of America by Cambridge University Press, New York
www.cambridge.org
Information on this title: www.cambridge.org/9781107005099
c⃝J. Dimock 2011
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2011
Printed in the United Kingdom at the University Press, Cambridge
A catalog record for this publication is available from the British Library
Library of Congress Cataloging in Publication data
Dimock, Jonathan, 1945–
Quantum mechanics and quantum ﬁeld theory :
a mathematical primer / Jonathan Dimock.
p.
cm.
ISBN 978-1-107-00509-9 (hardback)
1. Quantum theory – Mathematics.
I. Title.
QC174.17.M35D56
2011
530.12–dc22
2010041723
ISBN 978-1-107-00509-9 Hardback
Cambridge University Press has no responsibility for the persistence or
accuracy of URLs for external or third-party internet websites referred to
in this publication, and does not guarantee that any content on such
websites is, or will remain, accurate or appropriate.

for Benjamin, Christina, Gregory, and Ann


Contents
Preface
page xi
Introduction
1
Part I Non-relativistic
3
1
Mathematical prelude
5
1.1
Bounded operators
5
1.2
Unbounded operators
11
1.3
Self-adjoint operators
14
1.4
Compact operators
22
2
Classical mechanics
28
2.1
Hamiltonian mechanics
28
2.2
Examples
29
2.3
Canonical transformations
31
2.4
Symmetries
34
3
Quantum mechanics
38
3.1
Principles of quantum mechanics
38
3.2
Canonical quantization
41
3.3
Symmetries
43
3.4
Perspectives and problems
45
4
Single particle
47
4.1
Free particle
47
4.2
Particle in a potential
48
4.3
Spectrum
51
4.4
The harmonic oscillator
53
vii

viii
Contents
t
4.5
Scattering
55
4.6
Spin
58
5
Many particles
63
5.1
Two particles
63
5.2
Identical particles
66
5.3
n-particles
67
5.4
Fock space
70
6
Statistical mechanics
78
6.1
Mixed states
78
6.2
Equilibrium states
79
6.3
Free boson gas
83
6.4
Free fermion gas
86
6.5
Interacting bosons
88
6.6
Further developments
90
Part II Relativistic
93
7
Relativity
95
7.1
Principles of relativity
95
7.2
Minkowski space
96
7.3
Classical free ﬁelds
103
7.4
Interacting classical ﬁelds
107
7.5
Fundamental solutions
111
8
Scalar particles and ﬁelds
114
8.1
Scalar particles
114
8.2
Scalar ﬁelds
118
8.3
Charged scalar ﬁeld
126
9
Electrons and photons
130
9.1
Spinors
130
9.2
Electrons
132
9.3
Dirac ﬁelds
139
9.4
Photons
144
9.5
Electromagnetic ﬁeld
148
10 Field theory on a manifold
152
10.1 Lorentzian manifolds
152

ix
Contents
t
10.2 Classical ﬁelds on a manifold
154
10.3 Quantum ﬁelds on a manifold
155
Part III Probabilistic methods
159
11 Path integrals
161
11.1 Probability
161
11.2 Gaussian processes
163
11.3 Brownian motion
165
11.4 The Feynman–Kac formula
168
11.5 Oscillator process
169
11.6 Application: ground states
171
12 Fields as random variables
174
12.1 More on Gaussian processes
174
12.2 The Schrödinger representation
181
12.3 Path integrals – free ﬁelds
184
12.4 Vacuum correlation functions
187
12.5 Thermal correlation functions
189
13 A nonlinear ﬁeld theory
192
13.1 The model
192
13.2 Regularization
193
13.3 Inﬁnite volume
197
13.4 Path integrals – interacting ﬁelds
201
13.5 A reformulation
204
Appendix A Normed spaces
208
Appendix B Tensor product
211
Appendix C Distributions
215
References
219
Index
222


Preface
This is a book on mathematical physics for a reader with a good background in
mathematics, but possibly a minimal knowledge of physics. The subject matter is
quantum physics and includes non-relativistic quantum mechanics, quantum statisti-
cal mechanics, relativistic quantum mechanics, and quantum ﬁeld theory. The book
only contains material which meets the twin criteria of being basic physics and being
treatable with complete mathematical rigor. For each topic there is a straightforward
statement of basic principles followed by simple examples. There is also background
material in analysis, classical mechanics, relativity, and probability.
The book does not prove deep mathematical theorems. The book does not consider
the complicated models of mathematical physics. The book does not enter into the
fascinating speculative topics on the frontiers of physics, for example string theory.
Finally the book does not consider questions concerning the foundations or philoso-
phy of quantum physics. However the book does help prepare the reader for a journey
in any of these directions.
The book assumes knowledge of elementary analysis, measure theory, linear
algebra, some group theory, and some knowledge of differential equations. Some
reference is made to manifolds, differential geometry, and Lie groups. Not much
knowledge of physics is assumed beyond an introductory course. However one
probably needs more than this to really appreciate the material.
The book is suitable for a graduate course in mathematics. In this connection there
are problems scattered throughout the text. These serve the dual function of further
developing the material and providing a study aid. The level of difﬁculty is quite
variable.
Books which cover similar ground are Gustafson and Sigal (2003) and Takhtajan
(2008). The mathematical level is about the same, but they have different points of
emphasis.
xi


Introduction
At the end of the nineteenth century most macroscopic phenomena could be
explained in terms of a few basic equations. For the behavior of matter there was
Newton’s equation which said that the location of an object, modeled by a point
x ∈R3, evolves in time according to the equation
md2x
dt2 = F
(0.1)
Here m > 0 is the mass of the object and F = F(t, x, dx/dt) is the sum of all the
forces on the object. Forces were either gravitational or electromagnetic. In the
electromagnetic case the force due to an electric ﬁeld E : R3 →R3 and a mag-
netic ﬁeld B : R3 →R3 on a particle with charge e was given by the Lorentz force
F = eE+e/c(dx/dt×B). Here c is the speed of light, approximately 3 × 1010 cm/sec.
In this case Newton’s equations were
md2x
dt2 = eE + e
c
dx
dt × B

(0.2)
The electric and magnetic force ﬁelds (E, B) themselves might depend on time,
and were determined by Maxwell’s equations
∇· E = ρ
∇· B = 0
∇× E = −1
c
∂B
∂t
∇× B = 1
c
∂E
∂t + j

(0.3)
where ρ : R3 →R and j : R3 →R3 are speciﬁed charge densities and current
densities which necessarily obey the conservation law
1
c
∂ρ
∂t + ∇· j = 0
(0.4)
If ρ, j are expressed in terms of the positions of a number of particles obeying
(0.2), the system of equations (0.2),(0.3) provide a model for an enormous range
of phenomena.
However large velocity and large-scale gravitational phenomena were not
accurately explained and it took the invention of special relativity (1905) and general
1

2
Introduction
t
relativity (1915) by Einstein to rectify matters. Furthermore microscopic phenomena
such as the structure of atoms were not accurately described and it took the invention
of quantum mechanics by deBroglie, Schrödinger, Heisenberg, and others in the
1920s to rectify the situation. For phenomena involving both large velocities and tiny
particles there is a synthesis known as quantum ﬁeld theory which is still undergoing
development.
Quantum mechanics does not itself contain physical laws. Rather it is a general
framework in which physical laws should be formulated. As such it has a certain
mysterious and ad hoc character; there is not much insight into why it is the way it
is. However it is not ambiguous or inconsistent, and it has been very successful in
describing microscopic phenomena.
In this book we explain quantum mechanics with particular mathematical care. In
the ﬁrst part of the book it is quantum mechanics without relativity. Here we take a
historical, empirical approach to the subject and develop the theory as an extension of
the classical equations (0.1), (0.2). After a discussion of general principles, the theme
here is increasing complexity as the number of particles is increased, culminating in
an introduction to quantum statistical mechanics.
In the second part of the book we add relativity to the mix studying quantum ﬁelds
obeying various linear ﬁeld equations such as (0.3) (which is already relativisitic,
although its formulation predated relativity). A theme here is to develop the comple-
mentary ﬁeld-particle aspects of the various cases. In this part we also make some
attempt at understanding why the basic equations are natural from a mathematical
point of view.
In the third part of the book we introduce some stochastic processes useful for
analyzing various quantum problems. These are in fact essential for treating quantum
ﬁelds obeying a nonlinear ﬁeld equation. This is the interesting case since the non-
linearity corresponds to particle interactions. We illustrate the key role of stochastic
processes by developing a two-dimensional model at some length.

Part I
Non-relativistic


1
Mathematical prelude
We begin with a survey of some of the mathematics we will need. The reader may
wish to read it lightly and come back for details as needed.
Vector spaces can be real or complex, usually complex. A Banach space is a
complete normed vector space. A Hilbert space is a Banach space in which the norm
comes from an inner product. We review some basic facts about Hilbert spaces and
Banach spaces in appendix A.
We are particularly interested in linear operators on a Hilbert space. Many of the
results we present also hold for linear operators on a Banach space, but we will not
need the more general result, and the proofs are sometimes easier for a Hilbert space.
1.1 Bounded operators
1.1.1 Deﬁnitions
A linear operator T from a Hilbert space H1 to a Hilbert space H2 is a mapping
T : H1 →H2 such that
T(af + bg) = aT(f) + bT(g)
f, g ∈H1,
a, b ∈C
(1.1)
The operator is injective or one-to-one (that is Tf = Tg implies f = g) iff T has
kernel {0} (that is Tf = 0 implies f = 0). The operator is surjective or onto if the
range is H2. The operator is bijective if it is injective and surjective and then there is
an inverse T−1 : H2 →H1 which is also linear. (If H1 = H2 is ﬁnite dimensional,
then T is injective iff it is surjective, but not in general.)
A linear operator is bounded if there is a constant M such that
∥Tf∥≤M∥f∥
(1.2)
for all f ∈H1. Linear operators are continuous iff they are bounded.
The set of all bounded operators T : H1 →H2 is itself a vector space with
(aT)f = a(Tf) and (T1 + T2)f = T1f + T2f. It is denoted B(H1, H2) or B(H) if
H1 = H2 = H. We deﬁne the norm of a bounded operator by
5

6
Mathematical prelude
t
∥T∥= sup
f̸=0
∥Tf∥
∥f∥= sup
∥f∥=1
∥Tf∥
(1.3)
Then we have
∥Tf∥≤∥T∥∥f∥
(1.4)
and ∥T∥is the smallest possible constant here. With this norm, B(H1, H2) is a
normed vector space. We will see that it is complete and hence is a Banach space.
If T ∈B(H1, H2), then by the Schwarz inequality |(f, Tg)| ≤∥T∥∥f∥∥g∥. Hence
for f ∈H2 the mapping g →(f, Tg) is a bounded linear functional on H1 and by
the Riesz representation theorem (theorem A.3) there is a unique vector f ∗∈H1 so
that (f, Tg) = (f ∗, g). We deﬁne T∗f = f ∗. Then T∗: H2 →H1 is a linear operator
called the adjoint of T and we have
(T∗f, g) = (f, Tg)
(1.5)
Then |(T∗f, g)| ≤∥T∥∥f∥∥g∥and hence also by Riesz
∥T∗f∥= sup
∥g∥=1
|(T∗f, g)| ≤∥T∥∥f∥
(1.6)
Thus T∗is bounded, T∗∈B(H2, H1), and ∥T∗∥≤∥T∥.
Now we look at some special classes of bounded operators.
1. Let M ⊂H be a closed linear subspace. Then any vector f ∈H can be uniquely
written f = f1+f2 where f1 ∈M and f2 ∈M⊥(theorem A.2). Deﬁne PMf = f1.
This is a bounded linear operator with norm 1 called the projection onto M. It
satisﬁes P2
M = PM and P∗
M = PM and has range M.
More generally any bounded operator satisfying P2 = P and P = P∗is called
an orthogonal projection. One can show that any orthogonal projection has closed
range M and that P = PM.
2. A linear operator T is an isometry if it is norm preserving, that is ∥Tf∥= ∥f∥.
Since the norm determines the inner product by the polarization identity (A.5),
it is equivalent to say that it is inner product preserving (Tf, Tg) = (f, g). An
isometry is bounded and injective.
The range of an isometry is always closed. To see this suppose Tfn →g. Then
∥fn −fm∥= ∥Tfn −Tfm∥→0. Hence fn is Cauchy and has a limit f. Then
Tfn →Tf by the continuity of T and hence g = Tf.
An isometry satisﬁes (f, (T∗T −I)g) = 0 for any f, g, hence it satisﬁes
(T∗T −I)g = 0 for any g, and hence
T∗T = I
(1.7)
It follows that P = TT∗is an orthogonal projection. The range is the same as the
range of T (since Tf = (TT∗)Tf) and so

7
1.1 Bounded operators
t
TT∗= PRan(T)
(1.8)
3. If an isometry is also surjective, then the operator is called unitary or a Hilbert
space isomorphism. In this case
T∗T = TT∗= I
(1.9)
and T∗= T−1.
Problem 1.1
Let (M, μ) be a measure space and suppose k(x, y) is an element of
L2(M × M, μ × μ). Show that
(Kf)(x) =

k(x, y)f(y)dμ(y)
(1.10)
deﬁnes a bounded operator on L2(M, μ).
Problem 1.2
Let T, S ∈B(H).
1. Show that TS is bounded and ∥TS∥≤∥T∥∥S∥.
2. Show that ∥T∗∥= ∥T∥.
3. Show that ∥T∗T∥= ∥T∥2.
1.1.2 Sequences
A sequence of bounded operators {Tn} converges strongly if Tnf converges for
all f ∈H. The sequence converges in norm if ∥Tn −Tm∥→0 as n, m →∞.
This is uniform convergence on the unit sphere. Norm convergence implies strong
convergence since ∥Tnf −Tmf∥≤∥Tn −Tm∥∥f∥.
Theorem 1.1
Let Tn ∈B(H1, H2).
1. If Tn converges strongly, then it has a strong limit, that is there is a bounded
operator T such that Tf = limn→∞Tnf.
2. If Tn converges in norm and T is the strong limit, then ∥Tn −T∥→0 as n →∞.
Remark
We will use the principle of uniform boundedness which says that if ∥Tnf∥
is bounded for each f, then there is a constant M such that ∥Tn∥≤M.
Proof
For the ﬁrst point deﬁne Tf = limn→∞Tnf and check that T is linear. Since
Tnf converges for each f, it is bounded for each f and so by the remark ∥Tn∥≤M.
Now by the reverse triangle inequality, we can take the limit of ∥Tnf∥≤M∥f∥and
get ∥Tf∥≤M∥f∥. Hence T is bounded.

8
Mathematical prelude
t
For the second point given ϵ choose N so that if n, m ≥N, then ∥Tn −Tm∥< ϵ.
Then ∥Tnf −Tmf∥≤ϵ for all ∥f∥≤1. Take the limit m →∞and conclude that for
n ≥N we have ∥Tnf −Tf∥≤ϵ for all ∥f∥≤1 and hence ∥Tn −T∥≤ϵ.
The second part of the theorem shows that B(H1, H2) is a Banach space. If H1 =
H2 = H, then B(H) has even more structure. Since we can multiply operators and
∥TS∥≤∥T∥∥S∥, we say that B(H) is a Banach algebra. Since also ∥T∥= ∥T∗∥, we
have a Banach ∗-algebra. Since also ∥T∗T∥= ∥T∥2, we have a so-called C∗-algebra.
Theorem 1.2
Let T ∈B(H) satisfy ∥T∥< 1. Then I −T is bijective and the inverse
is also a bounded operator.
Proof
Start by deﬁning
Sn =
n

k=0
Tk
(1.11)
Then for n > m
∥Sn −Sm∥= ∥
n

k=m+1
Tk∥≤
n

k=m+1
∥T∥k →0
(1.12)
as n, m →∞. Thus Sn is a Cauchy sequence and since B(H) is complete, it has a
limit which is a bounded operator
S = lim
n→∞Sn ≡
∞

k=0
Tk
(1.13)
We then compute
(I −T)Sn =
n

k=0
Tk −
n+1

k=1
Tk = I −Tn+1
(1.14)
Now take the limit n →∞and use ∥Tn+1∥≤∥T∥n+1 →0. Then (I −T)S = I so
I−T is surjective. Similarly S(I−T) = I so I−T is injective and S is the inverse.
1.1.3 Extensions
A subspace D ⊂H has a closure D, which is also a subspace. D is dense if D = H.
We consider the problem of extending a linear operator deﬁned on a dense subspace.
Theorem 1.3
Let D be a dense subspace of a Hilbert space H1 and let T : D →H2
be a bounded linear operator.
1. T has a unique extension to a bounded linear operator T ∈B(H1, H2) and the
extension has the same bound.

9
1.1 Bounded operators
t
2. If T is norm preserving, then so is the extension, that is it is an isometry.
3. If T is norm preserving and has dense range, the extension is unitary.
Proof
Our assumption is that ∥Tf∥≤M∥f∥for all f ∈D. For f ∈H1, choose a
sequence fj ∈D so that fj →f. Then
∥Tfj −Tfk∥≤M∥fj −fk∥→0
(1.15)
as j, k →∞. Hence there is a limit f ∗= limj→∞Tfj and we deﬁne Tf = f ∗. The
deﬁnition is independent of the sequence since if f ′
j is another sequence converging
to f, we have
∥Tfj −Tf ′
j ∥≤M∥fj −f ′
j ∥→0
(1.16)
Now linearity and boundedness for T on H follow by taking limits of the same
relations for T on D.
The second assertion follows by taking the limit of ∥Tfj∥= ∥fj∥. The third
assertion follows since the range of the extension is closed and dense and hence
it is H.
1.1.4 Fourier transform
We want to deﬁne the Fourier transform as a unitary operator on L2(Rn), but we start
with a smaller space.
Let S(Rn) be the Schwartz space of smooth rapidly decreasing functions on Rn.
These are complex valued C∞functions f on Rn with the property that for any
multi-indices α = (α1, . . . , αn) and β = (β1, . . . , βn)
∥xβDαf∥∞< ∞
(1.17)
where
xβ = xβ1
1 . . . xβn
n
Dα = Dα1
1 . . . Dαn
n
(1.18)
and Di = −i∂/∂xi. For N > n/4 we can write
f(x) = [(1 + |x|2)−N][(1 + |x|2)Nf(x)]
(1.19)
This exhibits f as a product of an L2 function and an L∞function and hence
f ∈L2(Rn). Similarly ∥xβDαf∥2 < ∞for any multi-indices. Indeed we could have
used these conditions to deﬁne the space. Examples of functions in S(Rn) are those
of the form f(x) = P(x)e−a|x|2 where P is a polynomial. Another example is the
inﬁnitely differentiable functions of compact support,1 denoted C∞
0 (Rn). We have
the inclusion of subspaces
C∞
0 (Rn) ⊂S(Rn) ⊂L2(Rn)
(1.20)
1 The support of a function f, written supp f, is the closure of {x ∈Rn : f(x) ̸= 0}.

10
Mathematical prelude
t
One can show C∞
0 (Rn) is dense in L2(Rn) and so the same is true for S(Rn).
Now for f ∈S(Rn) we deﬁne the Fourier transform ˜f : Rn →C by
˜f(p) = (Ff)(p) = (2π)−n/2

e−ipxf(x)dx
(1.21)
Since f ∈L1(Rn) by (1.19) with N > n/2, the integral converges and ˜f is bounded.
The mapping Ff = ˜f is a linear operator.
More generally we compute
pαDβ
p (Ff) = (−1)|β|F(Dαxβf)
(1.22)
This exhibits pαDβ
p Ff as the Fourier transform of a Schwartz function, hence it is
bounded as well, and hence Ff ∈S(Rn). Thus the Fourier transform maps S(Rn) to
itself.
Next deﬁne
(Ff)(p) = ˜f(−p) = (2π)−n/2

eipxf(x)dx
(1.23)
which also maps S(Rn) to itself. The basic inversion theorem says F is the inverse
of F.
Theorem 1.4
1. FF = FF = I, so F is a bijection on S(Rn).
2. F, F extend to unitary operators on L2(Rn) satisfying FF = FF = I.
(So F = F−1 = F∗.)
Proof
For f ∈S(Rn) we compute
(FFf)(x) = lim
ϵ→0(2π)−n/2

eikxe−ϵ|k|2/2(Ff)(k)dk
= lim
ϵ→0(2π)−n

f(y)eik(x−y)e−ϵ|k|2/2dk dx
= lim
ϵ→0(2πϵ)−n/2

f(y)e−|x−y|2/2ϵdx
= f(x)
(1.24)
Here in the ﬁrst step we regularize the F integral. In the second step we insert the
deﬁnition of Ff and use Fubini’s theorem to change the order of integration. In the
third step we explicitly do the integral over k. The last step is a standard estimate
using the facts that (2πϵ)−n/2e−|x−y|2/2ϵ has integral one and peaks around x = y as
ϵ →0. Details are left to the problems.
For the second point we compute that for f, g ∈S(Rn)
(f, Fg) = (Ff, g)
(1.25)

11
1.2 Unbounded operators
t
Then (Ff, Fg) = (f, g) and the same for F. Hence they are norm preserving and by
theorem 1.3 they extend to a unitary operators on L2(Rn). The identity FF = FF = I
still holds since it holds on a dense set.
Problem 1.3
Show that in Rn
(2π)−n/2

eikxe−ϵ|k|2/2dk = ϵ−n/2e−|x|2/2ϵ
(1.26)
Problem 1.4
Show that if f is bounded and continuous on Rn
lim
ϵ→0(2πϵ)−n/2

e−|x−y|2/2ϵf(y) dy = f(x)
(1.27)
Problem 1.5
If f ∈L1 ∩L2, then the Fourier transform can be deﬁned directly by
(1.21). Show that this deﬁnition coincides with our deﬁnition on L2.
Problem 1.6
For f, g ∈S(Rn) deﬁne the convolution
(f ∗g)(x) =

f(x −y)g(y)dy
(1.28)
Show that f ∗g ∈S(Rn) and that
F(f ∗g) = (2π)n/2(Ff)(Fg)
(1.29)
1.2 Unbounded operators
1.2.1 Closed operators
We consider linear operators T from H1 to H2 deﬁned on a subspace D(T) ⊂H1.
The operator is not necessarily bounded, but we would like it to be closed. An
operator is closed if for any sequence fn ∈D(T) we have that fn →f and Tfn →g
imply f ∈D(T) and Tf = g. A bounded operator T : H1 →H2 is easily seen to be
closed. Furthermore if D(T) = H1, we have:
Theorem 1.5
(Closed graph theorem) If T : H1 →H2 is closed, then it is bounded.
Thus if the operator is closed and unbounded, D(T) must be a proper subspace
of H1. Usually it will be a dense subspace. Here is an example:

12
Mathematical prelude
t
Example 1.1
Let H = L2(R) and let
D(T) = {f ∈H :

|x|2|f(x)|2dx < ∞}
(1.30)
Deﬁne T : D(T) →H by
(Tf)(x) = xf(x)
(1.31)
This is not bounded since if fn is the characteristic function of [n, n + 1], then
∥Tfn∥≥n∥fn∥. However suppose fn is a sequence such that fn ∈D(T) →f and
Tfn →g. After passing to a subsequence we have fnj(x) →f(x) and xfnj(x) →
g(x) for almost every x. Hence xf(x) = g(x) for almost every x so f ∈D(T) and
Tf = g. Thus T is closed.
The graph of an operator T : D(T) →H2 is the subset of H1 × H2 deﬁned by
(T) = {< f, g >: f ∈D(T), Tf = g}
(1.32)
This is in fact a subspace of H1 × H2. A subspace of H1 × H2 is the graph of an
operator iff it has no elements of the form < 0, g > with g ̸= 0.
An operator S is an extension of an operator T written T ⊂S if the domains satisfy
D(T) ⊂D(S) and Tf = Sf for f ∈D(T). Then T ⊂S iff (T) ⊂(S).
An operator is closed iff every sequence < fn, Tfn > in (T) converging to
< f, g >
∈H1 ⊕H2 has < f, g >∈(T). Thus an operator is closed iff
its graph is closed. It follows that an injective operator T is closed iff T−1 is
closed.
An operator T that is not closed may have a closed extension. This is true iff
the closure of the graph is the graph of an operator, that is (T) = ( ¯T). In this
case we say the operator is closable and call ¯T the closure of T. If T is a closed
operator, a subspace D ⊂D(T) is a core for T if T | D = T. This is the same as the
statement that for every ψ ∈D(T) there is a sequence ψn ∈D so that ψn →ψ and
Tψn →Tψ.
Example 1.2
In the Hilbert space H = L2[−1, 1], consider the subspace D(T) of
bounded continuous functions and the operator T : D(T) →H deﬁned by
(Tf)(x) = f(0)
(1.33)
Let fn ∈D(T) be the “tent function” which is piecewise linear and satisﬁes
fn(±1) = 0, fn(±1/n) = 0, fn(0) = 1. Then as n →∞, fn →0 and Tfn = 1 →1,
so < 0, 1 > is in the closure of the graph, which is therefore not the graph of an
operator. Thus T is not closable.

13
1.2 Unbounded operators
t
1.2.2 Spectrum of a closed operator
For D(T) ⊂H let T : D(T) →H be a closed operator. The resolvent set ρ(T) is all
complex z such that T −z : D(T) →H is a bijection and the inverse is bounded
ρ(T) = {z ∈C : (T −z)−1 ∈B(H)}
(1.34)
(This would be empty if T were not closed.) The spectrum σ(T) is the complement
of the resolvent set.
A complex number z is an eigenvalue for T if (T −z)f = 0 for some f ̸= 0. Then
T −z is not injective and so z is in the spectrum. The set of all eigenvalues is a subset
of the spectrum called the point spectrum. If z is not an eigenvalue, then T −z is
injective, but z still may not be in the resolvent set since the range of T −z may not
be all of H. In this case we make a further distinction and specify that z is in the
continuous spectrum if the range of T −z is dense and otherwise z is in the residual
spectrum.
Theorem 1.6
ρ(T) is open and σ(T) is closed.
Proof
Suppose z0 ∈ρ(T). Then on the domain of T
(T −z) = (I −(z −z0)(T −z0)−1)(T −z0)
(1.35)
By theorem 1.2 the operator I −(z −z0)(T −z0)−1 is a bijection and has a bounded
inverse if
∥(z −z0)(T −z0)−1∥< 1
(1.36)
Hence T −z has a bounded inverse under the same condition which we write
|z −z0| < ∥(T −z0)−1∥−1
(1.37)
Hence this disc is in the resolvent set which is therefore open.
Problem 1.7
Show that if T is bounded, σ(T) ⊂{z ∈C : |z| ≤∥T∥}.
Problem 1.8
Show that if U is unitary, σ(U) ⊂{z ∈C : |z| = 1}.
1.2.3 Adjoints
We generalize the notion of adjoint to unbounded operators. For D(T) ⊂H let T :
D(T) →H be densely deﬁned, but not necessarily closed. Let D(T∗) be all vectors
g ∈H such that the function f ∈D(T) →(g, Tf) is continuous. Equivalently
D(T∗) = {g ∈H : ∃C so |(g, Tf)| ≤C∥f∥for all f ∈D(T)}
(1.38)

14
Mathematical prelude
t
Then the linear functional has an extension to all of H and by the Riesz representation
theorem (theorem A.3) if g ∈D(T∗), then there is a unique g∗such that (g∗, f) =
(g, Tf). We deﬁne a new operator T∗: D(T∗) →H by T∗g = g∗. Then T∗is a linear
operator called the adjoint of T. It is deﬁned so that
(T∗g, f) = (g, Tf)
f ∈D(T), g ∈D(T∗)
(1.39)
Theorem 1.7
Deﬁne V on H × H by V < f, g >=< −g, f >. Then
(T∗) = V[(T)]⊥
(1.40)
Proof
< f, g >∈V[(T)]⊥is equivalent to (−g, h) + (f, Th) = 0 for all h ∈D(T).
But by deﬁnition this is equivalent to f ∈D(T∗) and T∗f = g, that is < f, g >∈
(T∗).
Corollary 1.1
T∗is closed.
Proof
(T)⊥is closed and V is unitary.
Corollary 1.2
If T ⊂S, then S∗⊂T∗.
Proof
(T) ⊂(S) implies (S)⊥⊂(T)⊥.
Corollary 1.3
If D(T∗) is dense so T∗∗exists, then T is closable and T∗∗= ¯T.
Proof
(T∗∗) = V[V(t)⊥]⊥= [(T)]⊥⊥= (T)
(1.41)
Since (T) is the graph of an operator, T is closable and the closure is that operator,
that is ¯T = T∗∗.
Corollary 1.4
Ker T∗= [Ran(T)]⊥
(1.42)
Proof
The kernel of T∗is all g so (g, 0) ∈(T∗). By the theorem this is the same as
(0, g) ∈(T)⊥, that is g ∈[Ran(T)]⊥.
1.3 Self-adjoint operators
1.3.1 Deﬁnitions
A densely deﬁned operator is symmetric if
(g, Tf) = (Tg, f)
(1.43)

15
1.3 Self-adjoint operators
t
for all f, g ∈D(T). Then g ∈D(T∗) and T∗g = Tg so that T ⊂T∗. If the domains are
the same, that is if T = T∗, then the operator is said to be self-adjoint . A self-adjoint
operator is necessarily closed.
Self-adjoint operators have nice properties not shared by symmetric operators as
we will see. A symmetric operator T fails to be self-adjoint because its domain is
too small. Indeed if S is a symmetric extension of T, then T ⊂S ⊂S∗⊂T∗so S is
closer to being self-adjoint. A general problem is to ﬁnd a large enough symmetric
extension of T so that it is self-adjoint.
If T is symmetric, then D(T∗) is dense so the closure T∗∗exists. Then T ⊂T∗
implies T∗∗⊂T∗and we have the situation
T ⊂T∗∗⊂T∗
(1.44)
Now T∗∗is always symmetric (T∗∗⊂T∗∗∗). The simplest possibility for a self-
adjoint extension for T is that T∗∗= ¯T is self-adjoint, that is T∗∗= T∗∗∗. We say
that T is essentially self-adjoint. Since T∗is closed T∗∗∗= T∗and an equivalent
statement is that T∗∗= T∗, that is T∗is self-adjoint.
Example 1.3
Let H = L2[0, 1] and let T = id/dx deﬁned on C1 functions with
compact support in (0,1). Then integration by parts shows that T is symmetric.
However if we let h(x) = ex, then integration by parts also gives (h, Tf) = (ih, f).
Hence h ∈D(T∗) and T∗h = ih. The imaginary eigenvalue means that T∗is not
symmetric and hence T is not essentially self-adjoint.
We quote without proof some further results.2 Consider the subspace
AC[0, 1] = {f ∈L2[0, 1] : f is absolutely continuous and f ′ ∈L2[0, 1]}. (1.45)
(Absolutely continuous implies f ′ ∈L1[0, 1]. Since L2[0, 1] ⊂L1[0, 1], we are
assuming a bit more.) Let S = id/dx now deﬁned on the larger domain
D(S) = {f ∈AC[0, 1] : f(0) = f(1) = 0}
(1.46)
One can still integrate by parts and show that this operator is symmetric. It turns
out it is also closed, but it is not self-adjoint. The adjoint has the domain D(S∗) =
AC[0, 1]. A further extension is a family of operators Sα indexed by a complex
number α with |α| = 1. We have Sα = id/dx with domain
D(Sα) = {f ∈AC[0, 1] : f(0) = αf(1)}
(1.47)
These turn out to be self-adjoint. Thus there is a family of self-adjoint extensions
and we have
T ⊂S ⊂Sα = S∗
α ⊂S∗⊂T∗
(1.48)
2 See Reed and Simon (1975: 141) for details.

16
Mathematical prelude
t
This example has a property typical of differential operators in a region with a
boundary, namely the choice of a self-adjoint extension corresponds to a choice of
boundary conditions.
Problem1.9
Show that if T is essentially self-adjoint and S is a symmetric exten-
sion, then S is essentially self-adjoint and S∗∗= T∗∗. (Thus if T is essentially
self-adjoint, then it has a unique self-adjoint extension.)
1.3.2 Properties
If T is symmetric, then for f ∈D(T) the quantity (f, Tf) is real since (f, Tf) =
(Tf, f) = (f, Tf). It follows that any eigenvalue must be real. For self-adjoint
operators we have the following stronger statement.
Theorem 1.8
The spectrum of a self-adjoint operator is a subset of the real line.
Proof
We have to show that a complex number z with Imz ̸= 0 is in the resolvent
set. First we note that for f ∈D(T)
|Imz|∥f∥2 = |Im((T −z)f, f)| ≤|((T −z)f, f)| ≤∥(T −z)f∥∥f∥
(1.49)
and so
|Imz|∥f∥≤∥(T −z)f∥
(1.50)
Hence (T −z)f = 0 implies f = 0 so T is injective.
The inequality also implies that T −z has a closed range since if (T −z)fn is a
sequence in the range converging to g, then
∥fn −fm∥≤|Imz|−1∥(T −z)(fn −fm)∥→0
(1.51)
as n, m →∞. Then fn is Cauchy and so converges to some f. Since T is closed,
T −z is closed. Then fn →f and (T −z)fn →g imply f ∈D(T −z) = D(T) and
(T −z)f = g. Hence g is in the range and so the range is closed.
Now by (1.42) we have
[Ran(T −z)]⊥= Ker(T∗−¯z) = Ker(T −¯z) = {0}
(1.52)
Hence Ran(T −z) = [Ran(T −z)]⊥⊥= H.
Thus T −z is a bijection from D(T) to H. Now in (1.50) let f = (T −z)−1g for
any g ∈H. This gives
∥(T −z)−1g∥≤|Imz|−1∥g∥
(1.53)
which shows that the inverse is bounded.
The following is a test for self-adjointness:

17
1.3 Self-adjoint operators
t
Theorem 1.9
A symmetric operator T is self-adjoint iff Ran(T ± i) = H.
Proof
If T is self-adjoint, then ±i is in the resolvent set by the previous theorem and
hence the result.
For the converse suppose T is symmetric and the range of T ± i is H. We must
show D(T∗) ⊂D(T). If g ∈D(T∗), choose f ∈D(T) so that
(T∗−i)g = (T −i)f
(1.54)
Since also f ∈D(T∗) and T∗f = Tf, this says
(T∗−i)(f −g) = 0
(1.55)
But by (1.42) we have Ker(T∗−i) = [Ran(T + i)]⊥= {0} so f = g and hence
g ∈D(T).
Problem 1.10
A self-adjoint operator is positive if (f, Tf) ≥0 for all f ∈D(T).
Show that in this case σ(T) ⊂[0, ∞).
Problem 1.11
Let T be self-adjoint. Show that z ∈σ(T) iff for every ϵ > 0 there
exists a f ∈H with ∥f∥= 1 such that ∥(T −z)f∥< ϵ.
Problem 1.12
Show that if T is symmetric and Ran(T ± i) is dense, then T is
essentially self-adjoint.
Problem 1.13
Let T be symmetric and suppose the domain contains a complete
set of eigenvectors e1, e2, . . . with eigenvalues λ1, λ2, . . . . Show that T is essen-
tially self-adjoint and that the spectrum of the closure is the closure of the set of
eigenvalues.
Problem 1.14
Let (M, μ) be a measure space and let τ : M →R be a measur-
able function. Deﬁne an operator [τ] on L2(M, μ) by ([τ]f)(x) = τ(x)f(x) with
domain
D([τ]) = {f ∈L2(M, μ) : τf ∈L2(M, μ)}
(1.56)
1. Show that [τ] is self-adjoint.
2. Show that the spectrum is the essential range of τ. (The essential range of τ is
all λ ∈R such that μ

τ −1(λ −ϵ, λ + ϵ)

is positive for all ϵ > 0.)

18
Mathematical prelude
t
1.3.3 Spectral theorem
Suppose that T is a bounded self-adjoint operator on a Hilbert space H and suppose T
has a complete set of eigenvectors e1, e2, . . . with eigenvalues λ1, λ2, . . . , which are
bounded but not necessarily distinct. (For example suppose T is a compact operator
which we study in the next section.) Then we have for any f ∈H
f =
∞

i=1
(ei, f)ei
Tf =
∞

i=1
(ei, f)λiei
(1.57)
The operator V : H →ℓ2 deﬁned by
(Vf)i = (ei, f)
(1.58)
is unitary. Deﬁne a multiplication operator [λ] : ℓ2 →ℓ2 by
([λ]f)i = λifi
(1.59)
Then VT = [λ]V or
T = V−1[λ]V
(1.60)
Thus T is unitarily equivalent to a multiplication operator.
The content of the spectral theorem is that something similar is true for any
bounded self-adjoint operator.
Theorem 1.10
(Spectral theorem – bounded operator) Let T be a bounded self-
adjoint operator on a Hilbert space H. Then there exists a measure space
(M, μ), a bounded measurable function τ
: M →R, and a unitary operator
V : H →L2(M, dμ) such that T = V−1[τ]V where [τ] is the operator multiplication
by τ.
In the example, (M, μ) is the integers with counting measure. There is also a
version for unbounded operators:
Theorem 1.11
(Spectral theorem – unbounded operators) Let T be a self-adjoint
operator on a Hilbert space H. Then there exists a measure space (M, μ), a mea-
surable function τ : M →R, and a unitary operator V : H →L2(M, dμ) such
that VD(T) = D([τ]) as deﬁned in (1.56) and T = V−1[τ]V.
For proofs see Reed and Simon (1980). The representation as a multiplication
operator is not unique.
The spectral theorem allows us to deﬁne functions of a self-adjoint operator. Sup-
pose T is self-adjoint, bounded or not, and let h : R →C be a bounded Borel

19
1.3 Self-adjoint operators
t
function.3 Then h ◦τ is measurable and we deﬁne h(T) by
h(T) = V−1[h ◦τ]V
(1.61)
Then h(T) is a bounded operator for we have
∥h(T)f∥= ∥Vh(T)f∥2 = ∥[h ◦τ]Vf∥2 ≤∥h ◦τ∥∞∥Vf∥2 ≤∥h∥∞∥f∥
(1.62)
If h is unbounded, we can still use (1.61) to deﬁne h(T) but now restrict the domain
to V−1D([h ◦τ]).
The deﬁnition h(T) has the following properties (known as the functional
calculus):
1. (h1 + h2)(T) = h1(T) + h2(T)
2. (λh)(T) = λh(T)
λ ∈C
3. (h1 · h2)(T) = h1(T)h2(T)
4. 1(T) = I
5. h(T)∗= h(T).
An important case is when h is the characteristic function of a Borel set B ⊂R.
We deﬁne
E(B) = χB(T)
(1.63)
Then we have by the functional calculus
E(B)2 = E(B)
E(B)∗= E(B)
(1.64)
Thus E(B) is an orthogonal projection. The E(B) are called the spectral projections
for T. The projections E(λ) ≡E((−∞, λ]) are increasing and satisfy E(−∞) = 0
and E(∞) = I.
For f ∈H we deﬁne Borel measures (f, E(B)f) of total mass ∥f∥2. These are called
the spectral measures for the operator. The integral of a function h with respect to
such a measure is denoted

h(λ)d(f, E(λ)f)
(1.65)
Problem 1.15
Let T be a self-adjoint operator with spectral projections E(B).
1. Show that μ(B) = (f, E(B)f) deﬁnes a Borel measure.
2. Show that for bounded h
(f, h(T)f) =

h(λ)d(f, E(λ)f)
∥h(T)f∥2 =

|h(λ)|2d(f, E(λ)f)
(1.66)
3 The Borel sets in R are the smallest σ-algebra of subsets which contains the open sets. A function
h : R →R is Borel measurable if h−1(O) is a Borel set for any open O. If f is a measurable real-valued
function on any measure space, and h is Borel, then h ◦f is also measurable.

20
Mathematical prelude
t
3. Show that f ∈D(T) iff

λ2d(f, E(λ)f) is ﬁnite in which case
(f, Tf) =

λ d(f, E(λ)f)
∥Tf∥2 =

λ2d(f, E(λ)f)
(1.67)
1.3.4 One-parameter groups
A one-parameter unitary group is deﬁned to be a representation of the additive group
R by unitary operators. More precisely a one-parameter unitary group is a function
U from R to unitary operators on a Hilbert space such that U(t)U(s) = U(t + s) and
U(0) = I. Then U(t)∗= U(t)−1 = U(−t).
A self-adjoint operator determines a one-parameter unitary group as follows:
Theorem 1.12
Let T be self-adjoint on H and deﬁne U(t) = exp(itT).
1. U(t) is a one-parameter unitary group.
2. t →U(t)f is strongly continuous from R to H for any f ∈H.
3. If f ∈D(T), then f(t) ≡U(t)f ∈D(T) and solves the differential equation
df
dt = iTf
(1.68)
Proof
U(t) is deﬁned via the spectral theorem as U(t) = V−1[eiτ]V. It is straight-
forward to check that this deﬁnes a one-parameter unitary group. For the continuity
we use the dominated convergence theorem to show that
∥U(t + h)f −U(t)f∥2 =∥(U(h) −I)f∥2
=

|eiτ(m)h −1|2|(Vf)(m)|2dμ(m)
→0 as h →0
(1.69)
For the last point U(t)f ∈D(T) by the spectral theorem and we have
∥
U(t + h) −U(t)
h

f −iTU(t)f∥2
=∥
	U(h) −I
h
−iT

f∥2
=
 
eiτ(m)h −1
h
−iτ(m)

2
|(Vf)(m)|2dμ(m)
→0 as h →0
(1.70)
Here again we use the dominated convergence theorem, using |eix −1| ≤|x| and the
fact that |τ|2|Vf|2 is integrable.

21
1.3 Self-adjoint operators
t
The operator T is called the generator of the unitary group. The last theorem has
a converse known as Stone’s theorem.
Theorem1.13
Let U(t) be a strongly continuous one-parameter unitary group. Then
there is a unique self-adjoint operator T such that U(t) = eiTt.
Proof
(sketch) For the existence part of Stone’s theorem follow the steps below:
1. Deﬁne D(T) to be all f ∈H such that t−1(U(t) −I)f converges as t →0
and for f ∈D(T) deﬁne
Tf = lim
t→0
(U(t) −I)
it
f
Show that D(T) is a subspace and that T is a linear operator.
2. For λ > 0 deﬁne
Rλf = 1
i
 ∞
0
e−λsU(s)f ds
Show that the integral exists as a Hilbert space valued Riemann integral and
deﬁnes a bounded operator.
3. Show that Rλf ∈D(T) and that
(T + iλ)Rλf = f
4. Show that for any f ∈H we have λRλf →f as λ →∞and conclude that D(T)
is dense.
5. Show that if f ∈D(T), then U(t)f ∈D(T) and
1
i
d
dtU(t)f = TU(t)f = U(t)Tf
6. Show that T is symmetric by verifying for f ∈D(T)
0 = 1
i
d
dt∥U(t)f∥2 = (Tf, f) −(f, Tf)
7. Show that T is self-adjoint by verifying Ran(T ± iλ) = H. (We already know this
with the plus sign.)
8. Show that U(t) = eiTt by deﬁning h(t) = (U(t) −eiTt)f and showing that
d
dt∥h(t)∥2 = 0
Problem 1.16
Supply the details in the above argument.
Here is a variation of the above. Let H be a positive self-adjoint operator. Then
V(t) = e−tH is bounded and self-adjoint for t ≥0 and gives a representation of
the additive semi-group R+ = [0, ∞) (“semi-group” since there are no inverses).
Conversely we have as in Stone’s theorem:

22
Mathematical prelude
t
Theorem 1.14
Let V(t) be a semi-group of bounded self-adjoint operators deﬁned
for t ≥0 satisfying:
1. ∥V(t)∥≤1
2. V(0) = I
3. V(t)V(s) = V(t + s)
4. t →V(t)f is continuous for all f ∈H.
Then there is a unique positive self-adjoint operator H such that V(t) = e−tH.
1.4 Compact operators
1.4.1 Properties
A Hilbert space is a metric space and so a subset K ⊂H is compact iff every
sequence in K has a convergent subsequence. In a ﬁnite-dimensional Hilbert space,
a subset is compact iff it is closed and bounded. But in an inﬁnite-dimensional
Hilbert space, closed and bounded is not sufﬁcient. For example an orthonormal
basis {φ1, φ2, . . . } is closed and bounded, but since ∥φi −φj∥2 = 2 for all i ̸= j, there
can be no convergent subsequence.
An bounded operator T : H1 →H2 is compact if it maps bounded sequences
in H1 into sequences in H2 with convergent subsequences. An operator is ﬁnite
rank if the range is ﬁnite dimensional. By the above remarks a ﬁnite rank opera-
tor is compact. More generally a norm limit of ﬁnite rank operators is compact. This
follows from:
Lemma 1.1
The compact operators form a closed subspace of B(H1, H2).
Proof
It is straightforward to show that sums of compacts are compact, and it is
trivial to show that multiplication by a scalar preserves compactness. Thus they form
a subspace.
To show that it is a closed subspace let Tn be a sequence of compact operators such
that ∥Tn −T∥→0 as n →∞. We must show that T is compact. Let fn be a bounded
sequence in H1. Then there is a subsequence f (1)
n
such that T1f (1)
n
is Cauchy. Then this
sequence has a subsequence f (2)
n
so that T2f (2)
n
is Cauchy (as is T1f (2)
n ). Continuing
in this fashion we get for each k a subsequence f (k)
n
such that Tkf (k)
n
is Cauchy. The
diagonal sequence gn = f (n)
n
is then a subsequence of each f (k)
n
and so Tkgn is Cauchy
for all k.
Now given ϵ > 0, choose k so that ∥T −Tk∥< ϵ, and choose N so that for
n, m ≥N we have ∥Tkgn −Tkgm∥≤ϵ. Let M = supn ∥fn∥. Then for n, m ≥N
∥Tgn −Tgm∥≤∥(T −Tk)gn∥+ ∥Tk(gn −gm)∥+ ∥(Tk −T)gm∥
≤(2M + 1)ϵ
(1.71)

23
1.4 Compact operators
t
Since ϵ is arbitrary, Tgn is Cauchy, and since gn is a subsequence of fn, this shows T
is compact.
Lemma 1.2
The compact operators on H are a (two-sided) ∗-ideal in the Banach
algebra B(H). That is:
1. The compacts are a subspace of B(H).
2. If T is compact and S is bounded, then TS and ST are compact.
3. If T is compact, then so is T∗.
We already noted the ﬁrst. The second is easy. We will not need the third, so we
omit it.
Lemma 1.3
Let T ∈B(H) be compact. If λ is not an eigenvalue and λ ̸= 0, then
Ran(T −λ) is closed.
Proof
Suppose fn ∈D(T) and (T −λ)fn →g. We show g ∈Ran(T −λ).
If fn is not bounded, then there is a subsequence going to inﬁnity, so we may as well
assume ∥fn∥→∞. Then hn = fn/∥fn∥is bounded and so there is a subsequence hnj
so that Thnj converges. We also have that (T −λ)hnj = (T −λ)fnj/∥fnj∥converges to
zero. Combining these statements and the fact that λ ̸= 0 we conclude that hnj →h
with ∥h∥= 1. But also (T −λ)h = 0, which contradicts the assumption that λ is not
an eigenvalue.
Thus we may assume fn is bounded. Then Tfn has a convergent subsequence Tfnj.
Since λ ̸= 0, it follows that fnj →f. Then g = limj(T −λ)fnj = (T −λ)f as
required.
The next result characterizes the spectrum of a compact operator:
Theorem 1.15 (Riesz–Schauder)
Let T ∈B(H) be compact.
1. Complex λ ̸= 0 is either an eigenvalue or else is in the resolvent set.
2. Eigenvalues λ ̸= 0 have ﬁnite multiplicity (that is dim Ker(T −λ) < ∞).
3. Eigenvalues have no limit point except possibly zero.
Proof
We give the proof with the simpliﬁcation that T is self-adjoint so the spectrum
is real. Suppose λ is real, is not an eigenvalue, and λ ̸= 0. Then T −λ is injective.
Ran(T −λ) is closed by the lemma, and since Ran(T −λ)⊥= Ker(T −λ) = {0}
by (1.42), it follows that Ran(T −λ) = H. The inverse (T −λ)−1 is bounded by the
closed graph theorem and hence λ is in the resolvent set. This proves the ﬁrst point.
For the second point suppose dim Ker(T −λ) = ∞. Let φn be an orthonormal
basis for this space. Then there is a subsequence so Tφnj converges and it follows
that φnj = λ−1Tφnj converges. But this is impossible for an orthonormal set.
For the third point suppose λn is a sequence of distinct eigenvalues such that
λn →λ ̸= 0. Choose eigenfunctions φn such that Tφn = λnφn. These are necessar-
ily orthogonal and we may assume they are orthonormal. Then λ−1
n φn is bounded
and hence T(λ−1
n φn) = φn has a convergent subsequence. But this is impossible.

24
Mathematical prelude
t
Problem 1.17
Let T be a bounded operator with a complete set of eigenfunctions
{φn} and eigenvalues λn so λn →0 as n →∞. Show that T is compact.
1.4.2 Hilbert–Schmidt operators
A bounded operator T ∈B(H1, H2) is said to be Hilbert–Schmidt if
∥T∥2
HS ≡
∞

i=1
∥Tφi∥2 < ∞
(1.72)
for some orthonormal basis {φi} in H1. The condition is independent of basis since
if {ψj} is an orthonormal basis for H2, then

i
∥Tφi∥2 =

i,j
|(ψj, Tφi)|2 =

i,j
|(T∗ψj, φi)|2 =

i,j
∥T∗ψj∥2
(1.73)
This also shows that if T is Hilbert–Schmidt, then so is T∗. In fact restricting to the
case H1 = H2 we have:
Lemma 1.4
The Hilbert–Schmidt operators on H are a ∗-ideal in B(H):
1. If T, S are Hilbert–Schmidt, then so is aT + bS for a, b ∈C.
2. If T is Hilbert–Schmidt and S is bounded, then TS and ST are Hilbert–Schmidt.
3. If T is Hilbert–Schmidt, then so is T∗.
The proof is straightforward.
Lemma 1.5
A Hilbert–Schmidt operator is compact.
Proof
Given a Hilbert–Schmidt operator T, let {ψj} be an orthonormal basis for H2.
Then
Tf =
∞

j=1
(ψj, Tf)ψj
(1.74)
We also deﬁne
Tnf =
n

j=1
(ψj, Tf)ψj
(1.75)
Each Tn has ﬁnite-dimensional range and hence is compact. We have
∥(T −Tn)f∥2 =
∞

j=n+1
|(ψj, Tf)|2 ≤
⎛
⎝
∞

j=n+1
∥T∗ψj∥2
⎞
⎠∥f∥2
(1.76)

25
1.4 Compact operators
t
Hence
∥T −Tn∥2 ≤
⎛
⎝
∞

j=n+1
∥T∗ψj∥2
⎞
⎠→0
(1.77)
as n →∞. Since T is a norm limit of compacts, it is compact by lemma 1.1.
Now suppose T is a bounded operator on a Hilbert space H, which has a basis of
eigenfunctions {φi} with eigenvalues λi. Taking this basis in (1.72) we see that T is
Hilbert–Schmidt iff

i
|λi|2 < ∞
(1.78)
Here is another test for Hilbert–Schmidt.
Lemma 1.6
Let (M, μ) be a measure space and suppose k(x, y) is an element of
L2(M × M, μ × μ). Then
(Kf)(x) =

k(x, y)f(y)dμ(y)
(1.79)
deﬁnes a Hilbert–Schmidt operator on L2(M, μ) and
∥K∥HS = ∥k∥2
(1.80)
Proof
We have seen in problem 1.1 that K is a bounded operator. Let {φj} be
an orthonormal basis for L2(M, μ). Then ¯φi ⊗φj is an orthonormal basis for
L2(M × M, μ × μ); see the proof of theorem B.1 in the appendix. We compute
∥K∥2
HS =

j
∥Kφj∥2 =

i,j
|(φi, Kφj)|2
=

i,j
|(k, ¯φi ⊗φj)|2 = ∥k∥2
2
(1.81)
1.4.3 Trace class
Let T be a bounded positive self-adjoint operator on a Hilbert space H. (Recall that
positive means (f, Tf) ≥0 for all f ∈H.) We say that T is trace class if
Tr(T) =

i
(φi, Tφi) < ∞
(1.82)
for some orthonormal basis {φi}. By the spectral theorem, T = V−1[τ]V for a
function τ satisfying τ ≥0 almost everywhere. Then T has a positive self-adjoint
square root T1/2 = V−1[τ 1/2]V and the condition is equivalent to the statement that
T1/2 is Hilbert–Schmidt. It follows that the sum is independent of the basis. If T

26
Mathematical prelude
t
has a complete set of eigenfunctions {φi} with nonnegative eigenvalues λi, then the
condition for trace class is equivalent to

i
λi < ∞
(1.83)
More generally if T is a bounded operator on H, then T∗T is a positive operator
and we say that T is trace class if |T| = (T∗T)1/2 is trace class. This reduces to the
previous deﬁnition if T is positive self-adjoint.
To investigate this concept we need to know more about the relation between T and
|T|. A bounded operator U is a partial isometry if it is an isometry when restricted
to (Ker U)⊥.
Lemma 1.7
(Polar decomposition) If T is a bounded operator, there are partial
isometries U, V such that T = U|T| and |T| = VT.
Proof
Deﬁne U : Ran(|T|) →Ran(T) by U(|T|f) = Tf. Since
∥|T|f∥2 = (f, |T|2f) = (f, T∗Tf) = ∥Tf∥2
(1.84)
this is well-deﬁned (that is |T|f = |T|g implies Tf = Tg) and norm preserving. It
extends to an isometry from Ran|T| to RanT. Deﬁne U to be zero on (Ran|T|)⊥=
Ker|T| = Ker T. Then U is a partial isometry and U|T| = T. For V, reverse the roles
of T and |T|.
Lemma 1.8
A bounded operator is trace class iff it is the product of two Hilbert–
Schmidt operators. In particular a trace class operator is Hilbert–Schmidt and hence
compact.
Proof
If T is trace class, then T = (U|T|1/2)(|T|1/2) exhibits the operator as a prod-
uct of Hilbert–Schmidt operators. On the other hand suppose T = A∗B with A, B
Hilbert–Schmidt. First if T is positive, then

i
(φi, Tφi) =

i
(Aφi, Bφi) ≤

i
∥Aφi∥∥Bφi∥
≤

i
∥Aφi∥2
1/2 
i
∥Bφi∥2
1/2
< ∞
(1.85)
and hence T is trace class. In the general case if T = A∗B, then |T| = (VA∗)(B)
exhibits |T| as a product of two Hilbert–Schmidts. Thus |T| is trace class and hence
T is trace class.
Lemma 1.9
The trace class operators are a ∗-ideal in B(H):
1. If T, S are trace class, then so is aT + bS for a, b ∈C.
2. If T is trace class and S is bounded, then TS and ST are trace class.
3. If T is trace class, then so is T∗.

27
1.4 Compact operators
t
Proof
The only tricky part is showing that S + T is again trace class. To see this
write S = A∗
1B1 and T = A∗
2B2 with Ai, Bi Hilbert–Schmidt. Then A = A1 ⊕A2 and
B = B1⊕B2 are Hilbert–Schmidt operators from H to H⊕H and T +S = A∗B. This
is sufﬁcient to conclude that T + S is trace class as in the proof of lemma 1.8.
If T is trace class but not positive, we again deﬁne the trace by (1.82). This makes
sense because:
Lemma 1.10
Let T be trace class.
1. Tr(T) ≡
i(φi, Tφi) is absolutely convergent and independent of the choice of
basis.
2. Tr is a linear functional on the trace class operators.
3. (cyclicity) If T = AB with A, B Hilbert–Schmidt, then
Tr(AB) = Tr(BA)
(1.86)
Proof
Write T = A∗B as a product of Hilbert–Schmidt operators. Then the absolute
convergence of the sum is demonstrated as above in (1.85). If {ψj} is another basis,
we have
Tr(A∗B) =

i
(Aφi, Bφi) =

i,j
(Aφi, ψj)(ψj, Bφi)
=

i,j
(B∗ψj, φi)(φi, A∗ψj) =

j
(B∗ψj, A∗ψj) = Tr(BA∗)
(1.87)
This shows the independence of the basis and also establishes the cyclicity.
Problem 1.18
Show that if T is trace class and S is bounded, then Tr(ST) =
Tr(TS).
Notes
on
chapter
1:
A
good
general
reference
is
the
four
volume
set Reed and Simon (1980), Reed and Simon (1975), Reed and Simon (1979),
Reed and Simon (1978). Other books that cover this material are Kato (1966), Yosida
(1966), and Taylor (1996).

2
Classical mechanics
2.1 Hamiltonian mechanics
We start by reviewing some classical physics, speciﬁcally mechanics. Classical
mechanics is the study of the motions of macroscopic bodies under the inﬂuence
of certain speciﬁed forces. Mathematically it is formulated in terms of ordinary
differential equations. These equations can be presented in one of three general
forms: Newtonian, Hamiltonian, or Lagrangian. Here we emphasize the Hamiltonian
form, which is most easily connected with quantum mechanics.
In Hamiltonian mechanics the states of the system are speciﬁed by points in a
phase space which we take to be P = O × Rn for some integer n and some open set
O in Rn. (More generally the phase space is a 2n-dimensional manifold.) Points in
the phase space have the form (x, p) where the point x ∈O describes the location or
conﬁguration of the various objects in the system and the point p ∈Rn describes the
momenta of the various objects in the system.
The evolution of the system in time is speciﬁed by a function (x(t), p(t)) from
(an interval in) R to P called a trajectory. The fundamental dynamical principle is
that the allowed trajectories obey Hamilton’s equations. These are a system of 2n
ordinary differential equations of the form
dxi
dt = ∂H
∂pi
dpi
dt = −∂H
∂xi
(2.1)
where H = H(x, p) is a function on phase space called the Hamiltonian. The choice
of the Hamiltonian depends on the system we are trying to describe, and we will see
a number of examples shortly.
An immediate advantage of formulating the dynamics in this way is that the
Hamiltonian H(t) = H(x(t), p(t)) is constant in time. Indeed we have
dH
dt =
n

i=1
∂H
∂xi
dxi
dt + ∂H
∂pi
dpi
dt
28

29
2.2 Examples
t
=
n

i=1
∂H
∂xi
∂H
∂pi
−∂H
∂pi
∂H
∂xi
(2.2)
= 0
The usual interpretation is that the Hamiltonian is the energy of the system, and this
property represents conservation of energy.
More generally let F(p, q) be an arbitrary smooth function on the phase space,
sometimes called a “classical observable.” Let (x(t), p(t)) be a solution of Hamilton’s
equations, and let F(t) = F(x(t), p(t)) be the time evolution of the quantity F. Then
we have
dF
dt =
n

i=1
∂F
∂xi
dxi
dt + ∂F
∂pi
dpi
dt
=
n

i=1
∂F
∂xi
∂H
∂pi
−∂F
∂pi
∂H
∂xi
(2.3)
We write this as
dF
dt = {F, H}
(2.4)
where the right side is evaluated at (x(t), p(t)) and where we deﬁne the Poisson
bracket of F and G to be the function on P
{F, G} =
n

i=1
∂F
∂xi
∂G
∂pi
−∂F
∂pi
∂G
∂xi
(2.5)
For future reference we note that the Poisson bracket is anti-symmetric and
satisﬁes the Jacobi identity
{F, G} + {G, F} = 0
{{F, G}, H} + {{H, F}, G} + {{G, H}, F} = 0
(2.6)
Also the coordinate functions satisfy
{xi, xj} = 0
{pi, pj} = 0
{xi, pj} = δij
(2.7)
where δij = 1 if i = j and is zero otherwise.
2.2 Examples
Example 2.1
Single particle in an external ﬁeld We consider a single particle
in an external force ﬁeld. The particle is considered small enough that its state can

30
Classical mechanics
t
be described by its position which is a point x ∈Rd. The force is modeled by a
vector ﬁeld, that is a function F : O →Rd. The particle at x feels a force F(x).
The time evolution of the system is given by Newton’s second law
md2x
dt2 = F(x)
(2.8)
Suppose further that F is a gradient, that is F = −∇V for some function
V : O →R. We say that the force is conservative and call V a potential for
the problem. For example in R3 if the particle has charge q1 and the force is
the electrostatic force due to another particle of charge q2 at the origin, then
F(x) = q1q2x/|x|3 and V(x) = q1q2/|x|. For a conservative force we can write
Newton’s law as a Hamiltonian system. We deﬁne p = m(dx/dt) and then (2.8) is
equivalent to
dx
dt = p
m
dp
dt = −∇V
(2.9)
This is a Hamiltonian system on P = O × Rd with
H(x, p) = |p|2
2m + V(x)
(2.10)
Example 2.2
Single particle in electric and magnetic ﬁelds In O ⊂R3 suppose
that the magnetic ﬁeld B is static, ∂B/∂t = 0. Then Maxwell’s third equation (0.3)
says that ∇× E = 0. If O is simply connected, it follows that there exists a
scalar function  called the electrostatic potential so that E = −∇. Furthermore
Maxwell’s second equation says that ∇·B = 0 and it follows that there is a vector
ﬁeld A called the the magnetic potential so that B = ∇× A. (These potentials are
not unique. Indeed we could replace A by A + ∇λ for any scalar function λ. This
is called a gauge transformation, about which more later.)
For a single particle of charge e in such a ﬁeld the Lorentz force equation
(0.2) becomes
md2x
dt2 = −e∇ + e
c
dx
dt × ∇× A

(2.11)
This can be written as the system of equations (r, s = 1, 2, 3)
dxr
dt =

pr −e
cAr

/m
dpr
dt = e
mc

s

ps −e
cAs
 ∂As
∂xr
−e∂
∂xr
(2.12)

31
2.3 Canonical transformations
t
This is a Hamiltonian system on P = O × R3 with
H(x, p) = 1
2m
p −e
cA(x)

2
+ e(x)
(2.13)
Note that if A = 0, then this example reduces to the previous example with
V = e.
Example 2.3
Many particles Next consider a collection of n particles in Rd
interacting with each other. The location of the particles is given by a point
(x1, ..., xn) ∈Rnd and the momenta is given by a point (p1, ..., pn) ∈Rnd. The
phase space is Rnd × Rnd.
The force of the jth particle on the ith particle is assumed to depend only on
the relative positions and have the form F(xi −xj) for some force F as in the ﬁrst
example. We assume that F(−x) = −F(x) so that the force of the ith particle on
the jth particle is minus the force of the jth particle on the ith particle (Newton’s
third law). Newton’s equations for this problem take the form
mi
d2xi
dt2 =

j̸=i
F(xi −xj)
(2.14)
where mi is the mass of the ith particle.
If we further assume that the force F is conservative with F = −∇V and
V(−x) = (x), then this equation can be written
dxi
dt = pi
mi
dpi
dt = −∇i
⎛
⎝
j̸=i
V(xi −xj)
⎞
⎠
(2.15)
This is a Hamiltonian system with
H(x1, . . . , xn, p1, . . . , pn) =

i
|pi|2
2mi
+ 1
2

j̸=i
V(xi −xj)
(2.16)
2.3 Canonical transformations
Let ξ = (x, p) be a point in a phase space P = O × Rn and let J be the 2n × 2n
matrix
J =

0
I
−I
0

(2.17)

32
Classical mechanics
t
Then Hamilton’s equations can be written in the form
dξ
dt = J∇H
(2.18)
We want to investigate transformations which preserve the form of this equation.
First deﬁne a 2n×2n matrix M to be symplectic if MTJM = J. Products of symplec-
tic matrices are symplectic. Symplectic matrices are non-singular since | det M| = 1,
and the inverse is also symplectic. Thus symplectic matrices form a group. The
inverse and the transpose are related by M−1 = −JMTJ or MT = −JM−1J. Thus MT
is symplectic as well.
A smooth mapping ξ′ = φ(ξ) is a canonical transformation if the derivative
Dφ = {dξ′
i /dξj} is symplectic, that is if
(Dφ)TJ(Dφ) = J
(2.19)
Since | det Dφ| = 1, a canonical transformation is volume preserving. By the inverse
function theorem, a canonical transformation is at least locally invertible, and can be
thought of as a change of coordinates in phase space.
Canonical transformations preserve the form of Hamilton’s equations as the
following result shows:
Theorem 2.1
Let φ be a canonical transformation and suppose ξ(t) solves Hamil-
ton’s equations (2.18). Then the transformed solution ξ′(t) = φ(ξ(t)) solves
dξ′/dt = J∇H′
(2.20)
where H′ = H ◦φ−1.
Proof
Since H = H′ ◦φ, we have
∇H = (∇H′ ◦φ)Dφ = (Dφ)T(∇H′ ◦φ)
(2.21)
Thus for ξ′(t) = φ(ξ(t)) we have
dξ′
dt = (Dφ)(ξ(t))dξ
dt
= (Dφ)(ξ(t))(J∇H)(ξ(t))
= ((Dφ)J(Dφ)T)(ξ(t))∇H′(ξ′(t))
= J∇H′(ξ′(t))
(2.22)
where we use that (Dφ)T is symplectic.
Theorem2.2
Let φ∗F = F◦φ be the pull-back of F. A smooth function φ is canonical
iff
φ∗{F, G} = {φ∗F, φ∗G}
(2.23)
for all smooth functions F, G.

33
2.3 Canonical transformations
t
Proof
We have the representation
{F, G} = −(∇F)J∇G
(2.24)
Since ∇(φ∗G) = (Dφ)T(∇G) ◦φ, the equation (2.23) can be written as
((∇F)J(∇G)) ◦φ = ((∇F) ◦φ)(Dφ)J(Dφ)T((∇G) ◦φ)
(2.25)
If φ is canonical, then (Dφ)J(Dφ)T = J and the identity holds. On the other hand
suppose (2.25) holds. Take F(ξ) = ξi, G(ξ) = ξj so that (∇F)k = δik, (∇G)k = δjk.
Then we get [(Dφ)J(Dφ)T]ij = Jij so that φ is canonical.
Before continuing we introduce some additional concepts. Let X be a vector ﬁeld
on P, that is a function from P to R2n. Let φt be the ﬂow of X. That is ξ(t) = φt(ξ)
is the solution of dξ/dt = X(ξ) starting at ξ and deﬁned for t sufﬁciently small. For
any smooth function F on P deﬁne the Lie derivative LXF to be the function
(LXF)(ξ) = d
dtF(φt(ξ))|t=0
(2.26)
Applying the chain rule in (2.26) we have the representation
LXF =

i
Xi(ξ)∂F
∂ξi
(2.27)
This is the vector ﬁeld X regarded as a differential operator. The ﬂow satisﬁes φt ◦
φs = φt+s = φs ◦φt, and from this it is straightforward to deduce that φ∗
t (LXF) =
LX(φ∗
t F) and that
d
dt(φ∗
t F) = LX(φ∗
t F)
(2.28)
Now our solution of Hamilton’s equations is the ﬂow φt of the vector ﬁeld
XH = J∇H, called a Hamiltonian vector ﬁeld. The evolution equation (2.4) can be
written
d
dt(φ∗
t F) = φ∗
t {F, H}
(2.29)
and specializing to t = 0 we have
LXHF = {F, H}
(2.30)
Then φ∗
t {F, H} = {φ∗
t F, H} and either (2.28) or (2.29) becomes
d
dt(φ∗
t F) = {φ∗
t F, H}
(2.31)
Theorem 2.3
The ﬂow φt of Hamilton’s equations is canonical for each t.

34
Classical mechanics
t
Proof
Let Ft = φ∗
t F = F ◦φt so dFt/dt = {Ft, H}. Using the Jacobi identity we
compute
d
dt{Ft, Gt} =
dFt
dt , Gt

+

Ft, dGt
dt

= {{Ft, H}, Gt} + {Ft, {Gt, H}}
= {{Ft, Gt}, H} = LXH{Ft, Gt}
(2.32)
Thus U(t, ξ) = {Ft, Gt}(ξ) satisﬁes the ﬁrst-order linear partial differential equation
with initial condition
 ∂
∂t −LXH

U = 0
U(0, ξ) = {F, G}(ξ)
(2.33)
This is also satisﬁed by U(t, ξ) = {F, G}t(ξ). Solutions are unique and thus {F, G}t =
{Ft, Gt}. Since the Poisson bracket is preserved, the ﬂow is canonical.
Remark
Suppose the phase space is the vector space R2n and suppose that the
Hamiltonian ﬂow φt is linear, that is suppose that the Hamiltonian is a quadratic
polynomial. Then Dφt = φt and the statement that Dφt is symplectic becomes
φT
t Jφt = J. Another way to formulate it is to deﬁne a skew-symmetric bilinear form
(a symplectic form) by σ(ξ1, ξ2) = ξ1 ·Jξ2. Then σ is invariant under time evolution:
σ(φtξ1, φtξ2) = σ(ξ1, ξ2). An inﬁnite-dimensional version of this will be of interest
when we study quantum ﬁeld theory.
Problem2.1
On R2 consider the Hamiltonian H(x, p) = 1
2(p2 + ω2x2) where ω is
a constant. Find an explicit expression for the ﬂow φt and verify directly that it is
canonical.
2.4 Symmetries
We continue to let φt be the ﬂow of Hamilton’s equations. For any smooth function
F on phase space P we have d(φ∗
t F)/dt = φ∗
t {F, H} and from this it follows that
φ∗
t F = F
⇐⇒
{F, H} = 0
(2.34)
In this case we say that F is a conserved quantity or a constant of the motion.
There may be other Hamiltonian ﬂows occurring naturally in the problem.
Suppose G is a smooth function on P and let ψt be the ﬂow of XG = J∇G. We
say that G is the generator of ψt. Then ψ∗
t F = F iff {F, G} = 0. Combining these
facts we have
φ∗
t G = G
⇐⇒
{G, H} = 0
⇐⇒
ψ∗
t H = H
(2.35)
We can paraphrase this by saying that a function G is a constant of motion iff the
ﬂow ψt that it generates leaves the Hamiltonian invariant. This suggests that we look

35
2.4 Symmetries
t
for constants of the motion by looking for symmetries of the Hamiltonian. We now
proceed to look at some special cases.
In our models we will generally have an action of translations on the phase space,
that is an action of the additive group R3. Translations in a particular direction are
a Hamiltonian ﬂow and the generator of this ﬂow will be called the total momentum
in that direction. If the Hamiltonian is invariant under translations in that direction,
then the associated total momentum is conserved.
Example 2.4
We continue with a single particle in an external ﬁeld (example 2.1).
The phase space is P = R3 × R3 and the Hamiltonian is H = |p|2/2m + V(x).
A translation by a ∈R3 acts on P by Ta(x, p) = (x + a, p). We consider one-
parameter subgroups of the form Ttn(x, p) = (x + tn, p) with |n| = 1. These are
the ﬂow of the vector ﬁeld (n, 0) and this is a Hamiltonian vector ﬁeld since it
can be written J∇(p · n). Thus the total momentum in direction n is the particle
momentum p · n in the direction n. The translation takes the Hamiltonian to H ◦
Ttn = |p|2/2m + V(x + tn). The Hamiltonian is invariant if V is constant in the
direction n, that is there is no force in the direction n. In this case the momentum
p · n is conserved.
Example 2.5
Now consider again n particles interacting with each other
(example 2.3). The phase space is P = R3n × R3n and the Hamiltonian is given
by (2.16). Translations by a ∈R3 act on P by
Ta(x1, ..., xn, p1, ..., pn) = (x1 + a, ..., xn + a, p1, ..., pn)
(2.36)
and we consider the one-parameter subgroups of the form Ttn for |n| = 1.
The action of Ttn is the ﬂow of the vector ﬁeld (n, . . . , n, 0, . . . , 0). This is a
Hamiltonian vector ﬁeld since it can be written J∇(P · n) where
P =
n

i=1
pi
(2.37)
is identiﬁed as the total momentum. The Hamiltonian is invariant under transla-
tions since the potentials V(xi −xj) only depend on the differences xi −xj. Hence
P · n is conserved for any n and so P conserved.
Also we will generally have an action of the rotation group on the phase
space. Rotations around a particular axis are Hamiltonian ﬂows and the genera-
tor will be called the total angular momentum for the system around that axis. If
the Hamiltonian is invariant under rotations, then the total angular momentum is
conserved.

36
Classical mechanics
t
Before getting into examples we review some facts about the rotation group on R3.
The orthogonal group O(3) is all 3×3 matrices R, preserving lengths or equivalently
so that RTR = I. It inherits a topology as a subset of R9 and is in fact a Lie group,
that is a manifold. Such R have det R = ±1 and this divides O(3) into two con-
nected components. The component with det R = 1 is a subgroup called the rotation
group or special orthogonal group and is denoted SO(3). One-parameter subgroups
are rotations about a ﬁxed axis n ∈R3, |n| = 1. For example a rotation by an angle θ
around the axis e3 = (0, 0, 1) is
R(e3, θ) =
⎛
⎜⎝
cos θ
−sin θ
0
sin θ
cos θ
0
0
0
1
⎞
⎟⎠
(2.38)
Then
X3 ≡dR(e3, θ)
dθ

θ=0 =
⎛
⎜⎝
0
−1
0
1
0
0
0
0
0
⎞
⎟⎠
(2.39)
is an element of the Lie algebra (tangent space to the group at the identity). The
matrix X3 is the generator of the subgroup in the sense that R(e3, θ) = exp(θX3).
Similarly we have generators X1, X2 for the rotations R(e1, θ), R(e2, θ) around the
other axes. They are
X1 =
⎛
⎜⎝
0
0
0
0
0
−1
0
1
0
⎞
⎟⎠
X2 =
⎛
⎜⎝
0
0
1
0
0
0
−1
0
0
⎞
⎟⎠
(2.40)
The matrices X1, X2, X3 are a basis for the Lie algebra of SO(3), the skew-symmetric
matrices. The Lie algebra has a bracket operation inherited from the group structure
and determined by the commutators1
[X1, X2] = X3
[X2, X3] = X1
[X3, X1] = X2
(2.41)
Example 2.6
We consider again a single particle in an external ﬁeld (example 2.4
continued). The phase space is P = R3 × R3 and the Hamiltonian is
H = |p|2/2m + V(x). A rotation by R ∈SO(3) acts on ξ = (x, p) ∈P by
ˆRξ = (Rx, Rp). The one-parameter subgroup R(e3, θ) acts by
ˆR(e3, θ)ξ = (R(e3, θ)x, R(e3, θ)p)
(2.42)
This is the ﬂow of the vector ﬁeld
ˆX3ξ = (X3x, X3p)
(2.43)
1 [A, B] = AB −BA.

37
2.4 Symmetries
t
This is a Hamiltonian vector ﬁeld since it has the form J∇L3 where
L3 = −1
2(ξ, J ˆX3ξ) = x1p2 −x2p1
(2.44)
The generator L3 is identiﬁed as the angular momentum around e3. Similarly
associated with R(e1, θ), R(e2, θ) we have
L1 = x2p3 −x3p2
L2 = x3p1 −x1p3
(2.45)
Thus L = (L1, L2, L3) is the cross product L = x × p. For rotations around a unit
vector n the angular momentum turns out to be L · n.
Is the Hamiltonian invariant under rotations? The term |p|2/2m is invariant.
If the potential is also invariant, V(Rx) = V(x), then the Hamiltonian is invariant,
L · n is conserved for any n, and so the vector L is conserved.
For multiparticle systems as in example 2.5 one ﬁnds that the total angular
momentum is the sum of the angular momenta for the individual particles.
Problem 2.2
On the phase space R4 consider the Hamiltonian
H(x1, x2, p1, p2) = a(p2
1 + x2
1) + b(p2
2 + x2
2) + c(p1p2 −x1x2)
(2.46)
Find a constant of motion by showing that H is invariant under the rotations
 x1(θ)
p1(θ)

=
 cos θ
−sin θ
sin θ
cos θ
  x1
p1

 x2(θ)
p2(θ)

=

cos θ
sin θ
−sin θ
cos θ
  x2
p2

(2.47)
and then ﬁnding a generator for this ﬂow.
Notes on chapter 2: For a modern treatment of classical mechanics try
Abraham and Marsden (1978), Gallavotti (1983), or Marsden and Ratiu (1994).
A good general reference for mathematical physics is the two volume set by
Choquet-Bruhat et al. (1977) and Choquet-Bruhat and DeWitt-Morette (1989). In
particular they discuss Lie groups. For a more elementary treatment of Lie groups
see Miller (1972) or Hall (2003).

3
Quantum mechanics
3.1 Principles of quantum mechanics
We now begin with the main subject of the book: quantum mechanics. Quantum
mechanics is a fundamental framework for describing physical phenomena.
Although in principle it is needed for all phenomena, its features are especially
evident in microscopic phenomena such as the structure of atoms.
The fundamental principle is that some attributes of a physical system, for
example the position, cannot be speciﬁed exactly, but only by a probability den-
sity. Furthermore it is not the probability density itself which is fundamental, but
rather a complex valued function ψ called a “probability amplitude” or a “wave
function” whose modulus squared |ψ|2 gives the probability density. These ideas are
encompassed in the following axiom:
Axiom I: The states of the system are described by vectors of norm one in a
complex Hilbert space H.
Actually we do not distinguish states which differ by a phase. Two vectors
ψ1, ψ2 ∈H are considered as equivalent if ψ1 = eiθψ2 for some real θ. It is equiva-
lence classes of unit vectors, called rays, which describe the states of the system.
As an example for a single particle, say an electron, the Hilbert space would be
H = L2(R3). A particle in the state ψ ∈H with ∥ψ∥= 1 is located with a prob-
ability distribution |ψ(x)|2. In particular the probability of ﬁnding the particle in a
measurable set B ⊂R3 is

B |ψ(x)|2dx.
As a second example suppose we have two different particles, say a proton and an
electron. In this case the Hilbert space would be H = L2(R3 × R3). If the particles
are in a state ψ with ∥ψ∥= 1, then

B1×B2 |ψ(x1, x2)|2dx1dx2 is the probability of
ﬁnding the ﬁrst particle in the set B1 and the second particle in the set B2.
The wave function contains information about all observable quantities, not just
the position. This information is extracted according to the following principle.
Axiom II: Properties of physical measurements of a system correspond to pro-
jection operators on H. Physically measurable quantities for a system correspond to
self-adjoint operators on H.
38

39
3.1 Principles of quantum mechanics
t
We elaborate on the meaning of the ﬁrst point. If the state of the system is ψ and
one experimentally tests for a property corresponding to a projection operator P, then
the probability that the result of the test is positive is
(ψ, Pψ) = ∥Pψ∥2
(3.1)
A special case is that one tests whether the the system is in some other state φ. In
this case the projection operator is the projection onto φ which is Pφ = φ(φ, ·). (Note
that this depends only on the ray.) Thus if the system is in the state ψ, the probability
of ﬁnding it in the state φ is
(ψ, Pφψ) = |(φ, ψ)|2
(3.2)
For the second point suppose that a physically measurable quantity (e.g. position,
momentum, etc. ) corresponds to a self-adjoint operator A. For short we say A is an
observable. By the functional calculus, we have an associated family of projection
operators E(B) = χB(A) indexed by Borel sets B ⊂R. The basic interpretation is
that if the system is in the state ψ, then the probability that a measurement of the
observable A yields a result in B is
(ψ, E(B)ψ) = ∥E(B)ψ∥2
(3.3)
These quantities constitute the spectral measures introduced earlier. By the spectral
theorem (see problem 1.15)
(ψ, Aψ) =

λ d(ψ, E(λ)ψ)
(3.4)
As in classical probability theory, (ψ, Aψ) is interpreted as the average value of
repeated measurements. It is called the expectation value of the observable A.
If we have several commuting self-adjoint operators A1, ..., An, then it turns out
they have a joint spectral resolution, that is there is a unitary operator which trans-
forms all of them to multiplication operators on the same L2 space. Then we deﬁne
projection operators E(B) = χB(A1, ..., An) for B ⊂Rn and (ψ, E(B)ψ) is inter-
preted as the probability that a simultaneous measurement of observables A1, . . . , An
will yield a value in B. However if self-adjoint operators do not commute, there is
no joint spectral resolution and no probability density for simultaneous measure-
ments. Indeed arbitrarily precise simultaneous measurements are not possible. This
is a complete departure from classical probability theory.
As an example, for a single particle with Hilbert space L2(R3) let [xr] be the
operator of multiplication by the coordinate xr. Then for B ⊂R the projection oper-
ators are χB([xr]) = χB(xr) and the probability of ﬁnding the rth coordinate in B is

xr∈B |ψ(x)|2dx. For B ⊂R3 the joint projection operators are χB([x1], [x2], [x3]) =
χB(x1, x2, x3) and the probability of ﬁnding the particle in B is

B |ψ(x)|2dx just as
before.

40
Quantum mechanics
t
Now there is the question of how we associate physically measurable quantities
with self-adjoint operators. This is one of the more obscure areas of the subject.
However a few general principles sufﬁce to cover most of the situations that arise
in practice. One way of systematizing these principles is as follows. We know how
to associate classical observables with actual physical attributes. Thus a correspon-
dence between classical observables (that is functions on phase space) and quantum
observables (that is self-adjoint operators) serves our purpose. This correspondence
is known as “canonical quantization” and is discussed in the next section.
Next we turn to the question of how the system evolves in time. We assume that
external inﬂuences on the system are independent of time. (Otherwise the following
needs modiﬁcation.)
Axiom III: The time evolution of a system is given by a one-parameter group of
unitary operators U(t) on H such that if ψ ∈H is the state of the system at time
zero, then ψt = U(t)ψ is the state at time t.
The fact that time evolution is given by a family of linear operators (even for sys-
tems which are classically nonlinear) is perhaps mysterious, but once this is accepted
we are more or less forced to admit that it is unitary to preserve the probabilistic
interpretation.
We have formulated dynamics so that the states evolve in time and operators cor-
responding to observables are ﬁxed in time. The expectation of an observable given
by a self-adjoint operator A in a state ψ at time t is (ψt, Aψt). This is known as
the Schrödinger picture. There is also the Heisenberg picture in which the operators
evolve in time and the states are ﬁxed. For any operator A on the H we deﬁne the
operator at time t by At = U(t)−1AU(t). Now the expectation of A in the state ψ at
time t is (ψ, Atψ). This is the same as the Schrödinger picture. The two pictures are
equivalent in the sense that they have the same expectation values.
By Stone’s theorem (Theorem 1.13) the time evolution U(t) will be generated by
a self-adjoint operator H. We write
U(t) = e−itH/h
(3.5)
Here ¯h is a small fundamental constant of nature, which sets the scale on which
quantum effects are important. In CGS units it is ¯h = 1.05 × 10−27erg · seconds.
In the Schrödinger picture we have ψt = e−itH/hψ and so if ψ ∈D(H), the state
satisﬁes the Schrödinger equation,
i¯hdψt
dt = Hψt
(3.6)
In the Heisenberg picture we have At = eitH/hAe−itH/h, which satisﬁes
−i¯hdAt
dt = [H, At]
(3.7)

41
3.2 Canonical quantization
t
on a suitable domain. Note the analogy with the time evolution of observables in
a classical Hamiltonian system as in (2.4). Poisson brackets are replaced by com-
mutators and the operator H plays the role of the Hamiltonian. Indeed H is called
the (quantum) Hamiltonian and corresponds to the energy of the system. This cor-
respondence is further developed in the framework of canonical quantization in the
next section.
In addition to this continuous unitary time evolution the system also changes in a
discontinuous way when a measurement is made upon it. Roughly the state jumps
to a state which is speciﬁed by the results of the measurement. This is known as
“reduction of the wave function.” The question of which physical processes consti-
tute measurements in this sense is rather unsettled, as well as the question of ﬁnding
a correct mathematical description. Nevertheless it turns out that one can solve most
practical problems without entering into these issues.
This completes our survey of the basic principles in the form of three axioms
which list the kind of mathematical structures we are interested in and how they
are supposed to model the physical world. They are not meant to be exhaustive or
inﬂexible, but only a general point of reference.
3.2 Canonical quantization
Canonical quantization is a recipe for passing from a classical Hamiltonian system
to a quantum mechanical system. We should say at the outset that there are lim-
its to how seriously one should take this procedure. We do not mean to say that
the classical system is fundamental and it is somehow modiﬁed for microscopic
phenomena. Rather it is the quantum system which is fundamental. The classical
system is an approximation, which however is excellent for macroscopic bodies.
Canonical quantization is just a sophisticated method for guessing the correct quan-
tum description from its classical manifestation. As such it need not be too sharply
drawn.
We begin with a classical Hamiltonian system with phase space P = Rn × Rn
with points (x, p) = (x1, . . . , xn, p1, . . . , pn) and a Hamiltonian H(x, p). The ﬁrst step
of quantization consists of associating with each of the coordinates (unbounded)
linear operators (ˆx, ˆp) = (ˆx1, . . . , ˆxn, ˆp1, . . . , ˆpn) on a Hilbert space H such that the
commutators satisfy the relations

ˆxi, ˆxj

= 0

ˆpi, ˆpj

= 0

ˆxi, ˆpj

= i¯hδij
(3.8)

42
Quantum mechanics
t
The relations (3.8) are known as the canonical commutation relations or CCR. Note
the analogy with the Poisson brackets of the classical coordinates given in (2.7). Note
also the presence of the fundamental constant ¯h.
The second step is to substitute (ˆx, ˆp) into the classical Hamiltonian H(x, p) to
form the quantum Hamiltonian ˆH = H(ˆx, ˆp). This is just a formal expression which
we must give a meaning as a self-adjoint operator. The time evolution operator is
then taken to be U(t) = e−it ˆH/h in accordance with our general principles. In the
Heisenberg picture we then deﬁne canonical operators (ˆxt, ˆpt) at time t by
ˆxt = eit ˆH/¯hˆxe−it ˆH/h
ˆpt = eit ˆH/¯hˆpe−it ˆH/h
(3.9)
These also satisfy the CCR and obey the equations
−i¯h d
dt ˆxt = [ ˆH, ˆxt]
−i¯h d
dt ˆpt = [ ˆH, ˆpt]
(3.10)
Example 3.1
As an example consider the quantization of the classical system in
example 2.1. This is a single particle in R3 with mass m and under the inﬂuence
of a potential V. The classical coordinates xr, pr with 1 ≤r ≤3 can be quantized
as the operators ˆxr, ˆpr deﬁned by
ˆxr = [xr] ≡multiplication by xr
ˆpr = −i¯h ∂
∂xr
(3.11)
When deﬁned on a suitable domain in L2(R3), say the Schwartz space S(R3),
these satisfy the canonical commutation relations (3.8). The classical Hamiltonian
H(x, p) = |p|2/2m + V(x) becomes the quantum Hamiltonian
ˆH = |ˆp|2
2m + V(ˆx)
= −¯h2 
2m + [V(x)]
(3.12)
In the next chapter we will deﬁne ˆH as a self-adjoint operator and so specify the
dynamics. In any case proceeding formally and using that [H, At] = [H, A]t we
ﬁnd that the equations (3.10) become in this case
d
dt ˆxr,t = ˆpr,t
m
d
dt ˆpr,t = −∂V
∂xr
(ˆxt)
(3.13)

43
3.3 Symmetries
t
(Here we use the formal identity [∂V/∂xr]t = ∂V/∂xr(ˆxt).) Thus the quan-
tum operators (ˆxr, ˆpr) obey the classical Hamilton’s equations. This is a general
principle known as Ehrenfest’s theorem.
Let us consider the momentum operators ˆpr in more detail. These satisfy on
S(R3)
ˆpr = F−1
h [pr]Fh
(3.14)
where Fh is the Fourier transform deﬁned with the exponent exp(−ipx/¯h) rather
than exp(−ipx). Since the multiplication operator [pr] is naturally a self-adjoint
operator, this formula can be used to deﬁne ˆpr as a self-adjoint operator on L2(R3)
with domain
D(ˆpr) = {ψ :

p2
r| ˜ψ(p)|2dp < ∞}
(3.15)
The joint spectral projections for ˆp = (ˆp1, ˆp2, ˆp3) are the operators E(B) =
F−1
¯h [χB(p1, p2, p3)]Fh and so the probability of ﬁnding the momentum in the
set B ⊂R3 in the state ψ is
(ψ, E(B)ψ) =

B
| ˜ψ(p)|2dp
(3.16)
Thus | ˜ψ(p)|2 gives probability density for momentum. We say that the Fourier
transform ˜ψ(p) is the wave function in momentum space. This interpretation
of the Fourier transform is not special to this example, but pervades quantum
physics.
Problem 3.1
In the above example let ψ ∈S(R3) with ∥ψ∥= 1 and deﬁne
the expectations ¯xr = (ψ, ˆxrψ) and ¯pr = (ψ, ˆprψ). Further deﬁne the variances
(xr)2 = (ψ, (ˆxr −¯xr)2ψ) and (pr)2 = (ψ, (ˆpr −¯pr)2ψ). Show that
xrpr ≥¯h
2
(3.17)
This result, known as the Heisenberg uncertainty principle, shows that position
and momentum cannot simultaneously be constrained arbitrarily sharply.
The value of ¯h depends on which system of units we are using. Hereafter we
choose units in which ¯h = 1 so that ¯h disappears from our equations.
3.3 Symmetries
We want to consider symmetries and conserved quantities for quantum systems.
Our discussion parallels the classical discussion of section 2.4, but with canonical

44
Quantum mechanics
t
ﬂows replaced by one-parameter unitary groups and Poisson brackets replaced by
commutators.
Suppose we have a quantum system with Hilbert space H and time evolution e−iHt.
Let
αt(A) = At = eiHtAe−iHt
(3.18)
be the time evolution of the observable A. Since −idAt/dt = [H, A]t, we deduce that
αt(A) = A
⇐⇒
[H, A] = 0
(3.19)
Thus A is constant in time iff it commutes with H. We say that A represents a
conserved quantity. To ﬁnd such quantities we consider other group actions on H.
Suppose e−iGt is another one-parameter unitary group on H with self-adjoint
generator G. The action on an observable A is
βt(A) = eiGtAe−iGt
(3.20)
and the observable is invariant iff [G, A] = 0. Combining the above we have
αt(G) = G
⇐⇒
[H, G] = 0
⇐⇒
βt(H) = H
(3.21)
Thus an observable is conserved iff it generates a symmetry of the Hamiltonian.
Now we get more speciﬁc. The translation group R3 acts on R3 by x →x + a.
We suppose that we have a continuous representation of this group by unitary
operators U(a) on H, that is U(a)U(a′) = U(a + a′). For any state ψ the state
U(a)ψ is interpreted as the state translated by a. For any basis vector er, U(ter) is a
one-parameter unitary group and by Stone’s theorem there is a self-adjoint operator
Pr such that
U(ter) = exp(−iPrt)
(3.22)
Then Pr is interpreted as the rth component of the total momentum of the system, in
analogy with the classical situation. If the Hamiltonian is invariant under translations
in the direction er, then Pr is conserved.
We also suppose that we have a continuous representation of the rotation
group, that is unitary operators U(R) on H for each R ∈SO(3) such that
U(R)U(R′) = U(RR′). For a state ψ the state U(R)ψ is the state rotated by R.
If R(er, θ) is the rotation by θ around a basis vector er, then U(R(er, θ)) is a
one-parameter unitary group and by Stone’s theorem there is a self-adjoint operator
denoted Jr such that
U(R(er, θ)) = exp(−iθJr)
(3.23)
Then Jr is interpreted as the r-component of the total angular momentum of the
system, again in analogy with the classical situation. If the Hamiltonian is invariant
under rotations around er, then Jr is conserved.

45
3.4 Perspectives and problems
t
Example 3.2
We continue the example of a single particle in an external potential,
example 3.1. The translation group on L2(R3) is represented by
(U(a)ψ)(x) = ψ(x −a)
(3.24)
The generator in the direction er is for suitable ψ
(Prψ)(x) = i d
dt(U(ter)ψ)(x)|t=0 = −i∂ψ
∂xr
(x)
(3.25)
Thus the total momentum Pr is just the momentum ˆpr of the single particle as
we might expect. The Hamiltonian H is invariant under U(ter) if the potential
satisﬁes V(x + ter) = V(x). In this case Pr is conserved.
The rotation group is represented by
(U(R)ψ)(x) = ψ(R−1x)
(3.26)
which is unitary since det R = 1. The third component of the angular momentum,
denoted L3 rather than J3 in this example, is
(L3ψ)(x) = i d
dθ ψ(R(e3, θ)−1x)|θ=0 =

x1

−i ∂
∂x2

−x2

−i ∂
∂x1

ψ(x)
(3.27)
If H is invariant under R(e3, θ), that is if V(R(e3, θ)x) = V(x), then L3 is
conserved. Rotations around other axes are treated similarly.
Note that L3 = ˆx1ˆp2−ˆx2ˆp1. Thus we can get the quantum angular momentum
by making the substitution xr →ˆxr, pr →ˆpr in the classical angular momen-
tum (2.44), just as we did with the Hamiltonian. However it has proved difﬁcult
to elevate this substitution rule into a general principle for generating quantum
observables. Canonical quantization is not a universal recipe.
Problem 3.2
It is generally true that −iJr give a representation of the Lie algebra
of SO(3) as in (2.41), that is
[J1, J2] = iJ3
[J2, J3] = iJ1
[J3, J1] = iJ2
(3.28)
Check that this is true for Jr = Lr in the above example.
3.4 Perspectives and problems
If one wants to give a quantum mechanical model for a physical system one proceeds
as follows. First one selects a Hilbert space of states H and a Hamiltonian H. Possibly
this would be by applying the method of canonical quantization to a classical model
or possibly by experience or guesswork. This is the job of the physicist.

46
Quantum mechanics
t
Then there are three mathematical problems:
1. (Self-adjointness) The Hamiltonian will typically be given as a formal operator
and the ﬁrst task, at least for a mathematician, is to give it a rigorous meaning as
a self-adjoint operator. Then one has the existence of the time evolution operator
U(t) = e−itH.
2. (Spectrum) The next task is to study the spectrum of H. In particular one looks
for eigenvalues Hψ = Eψ. These are the states of deﬁnite energy. Such a state
would evolve in time according to ψt = e−iEtψ. Since the phase factor e−iEt does
not change the ray, the state is stationary. These are the states one would look for
in nature. Differences in energy levels can often be observed directly since if the
system changes from one state to another, it usually emits light with exactly the
energy difference.
3. (Scattering) For states which are not eigenvectors or linear combinations of eigen-
vectors, we ask instead for the long time behavior of the state. Thus we ask for the
asymptotic behavior of e−iHtψ as t →±∞. This leads to the scattering problem:
given a state with speciﬁed asymptotic behavior as t →−∞, ﬁnd the asymptotic
behavior as t →∞.
In the next chapter we take up these problems for the case of a single particle in
an external potential.
Notes on chapter 3: The original mathematical treatment of quantum mechanics
was von Neumann (1955). Other books on the mathematical foundations are Jauch
(1968) and Isham (1995).

4
Single particle
4.1 Free particle
We start with the case of a single particle with no forces – a free particle. To begin
we work in Rd so the Hilbert space is L2(Rd) and the Hamiltonian from (3.12) with
V = 0 is
H0 = −
2m
(4.1)
Our ﬁrst task is to choose a domain for this operator so it is self-adjoint. On S(Rd)
we have
H0 = F−1
	|p|2
2m

F
(4.2)
The multiplication operator |p|2/2m has a natural domain of self-adjointness and we
just deﬁne D(H0) to be the transform of this domain. Thus H0 is deﬁned by (4.2)
with domain
D(H0) = {ψ :

|p|4| ˜ψ(p)|2dp < ∞}
(4.3)
As the unitary transform of a self-adjoint operator, it is self-adjoint. The operator is
deﬁned by its spectral representation.
Time evolution as deﬁned by the spectral theorem is given by
e−iH0tψ = F−1[e−i(|p|2/2m)t]F
(4.4)
or if ψ ∈S(Rd)
(e−iH0tψ)(x) = (2π)−d/2

eipxe−i(|p|2/2m)t ˜ψ(p)dp
(4.5)
Lemma 4.1
For ψ ∈S(Rd) and t ̸= 0
(e−iH0tψ)(x) =
 m
2πit
d/2 
ei|x−y|2m/2tψ(y)dy
(4.6)
and so as |t| →∞
∥e−iH0tψ∥∞≤O(|t|−(d/2))
(4.7)
47

48
Single particle
t
Remark
The estimate says that amplitude of the wave function goes to zero at
t →±∞. Since the L2 norm is conserved, this means that the region of concentration
of the wave function must increase. This loss of localization is known as spreading
of the wave function.
Proof
Suppose instead of the Schrödinger equation dψ/dt = −iH0ψ we were solv-
ing the heat equation dψ/dτ = −H0ψ. Then we would have as the solution for
τ > 0
(e−H0τψ)(x) = (2π)−d/2

eipxe−(|p|2/2m)τ ˜ψ(p)dp
=
 m
2πτ
d/2 
e−|x−y|2m/2τψ(y)dy
(4.8)
Here in the second step we insert the deﬁnition of ˜ψ(p) and do the integral over p,
see problem 1.3. This calculation holds equally well for τ complex, Re τ > 0. Now
exp(−H0(ϵ + it))ψ converges to exp(−iH0t))ψ in L2(Rd) as ϵ →0. Hence we have
pointwise convergence for a subsequence ϵn. Take τ = ϵn + it above and let ϵn →0.
Using the dominated convergence theorem on the right we obtain (4.6). (And we also
see that the right side is in L2.)
Problem 4.1
Deﬁne for ψ ∈S(Rd) and t ̸= 0
(Vtψ)(x) =
m
it
d/2
exp

im|x|2
2t

˜ψ
mx
t

(4.9)
Show that
lim
t→±∞∥e−iH0tψ −Vtψ∥2 = 0
(4.10)
This result shows that in spite of the spreading of the wave function, some locali-
zation is preserved. Suppose that | ˜ψ(p)| is peaked at some momentum p0 ∈Rd.
Then the asymptotic form of |(e−iH0tψ)(x)| is peaked at points where mx/t = p0 or
x = (p0/m)t. This special point moves with velocity p0/m just as for the classical
trajectory.
Problem 4.2
Show that the spectrum of H0 is [0, ∞) and that it is all continuous
spectrum.
4.2 Particle in a potential
Now we specialize to d = 3 and study a single particle in a potential. As explained
in the previous section this means our Hamiltonian has the form
H = H0 + V = −
2m + V
(4.11)

49
4.2 Particle in a potential
t
where V is the potential function. The ﬁrst task is to deﬁne it as a self-adjoint
operator. For this we need:
Theorem 4.1
(Kato’s theorem) Let T be a self-adjoint operator on a Hilbert space
and let S be symmetric. Suppose that D(T) ⊂D(S) and for some constants 0 ≤a < 1
and 0 ≤b and all f ∈D(T) we have
∥Sf∥≤a∥Tf∥+ b∥f∥
(4.12)
Then T + S is self-adjoint on D(T).
Proof
The operator T + S is symmetric on D(T) so it sufﬁces to show that Ran(T +
S ± iμ) = H for some μ > 0 by theorem 1.9. (Actually theorem 1.9 is stated for
μ = 1, but it holds as well for any μ.)
For any g ∈H we have that (T ± iμ)−1g ∈D(T) and by the inequality
∥S(T ± iμ)−1g∥≤a∥T(T ± iμ)−1g∥+ b∥(T ± iμ)−1g∥
(4.13)
On the right side we have certain bounded functions of T, which we estimate by the
spectral theorem using ∥h(T)∥≤∥h∥∞. In particular
∥T(T ± iμ)−1∥≤sup
λ∈R
|λ(λ ± iμ)−1| ≤1
∥(T ± iμ)−1∥≤sup
λ∈R
|(λ ± iμ)−1| ≤μ−1
(4.14)
Therefore
∥S(T ± iμ)−1g∥≤

a + b
μ

∥g∥
(4.15)
Since a + b/μ < 1 for μ sufﬁciently large, we conclude that ∥S(T ± iμ)−1∥< 1.
Hence by theorem 1.2
Ran(I + S(T ± iμ)−1) = H
(4.16)
Now for any f ∈D(T) we have
(T + S ± iμ)f = (I + S(T ± iμ)−1)(T ± iμ)f
(4.17)
On the right side we have the composition of two surjective operators, hence
T + S ± iμ is surjective as required.
Theorem4.2
H = H0 +V on L2(R3) is self-adjoint on D(H0) in any of the following
circumstances:
1. V ∈L∞(R3)
2. V ∈L2(R3)
3. V = V1 + V2 where V1 ∈L2(R3) and V2 ∈L∞(R3).
Proof
Take m = 1/2 for simplicity. If V ∈L∞, then it determines a bounded
operator and ∥Vf∥≤∥V∥∞∥f∥. The hypotheses of Kato’s theorem are satisﬁed with
a = 0, b = ∥V∥∞, hence the result.

50
Single particle
t
Now suppose V ∈L2(R3). If ψ ∈D(H0), then |p|2 ˜ψ(p) is in L2(R3). We write for
any α > 0
˜ψ(p) = (α2 + |p|2)−1
(α2 + |p|2) ˜ψ(p)

(4.18)
This exhibits ˜ψ(p) as the product of two L2 functions and hence it is in L1 as well
as L2. Hence the Fourier inversion formula ψ(x) = (2π)−3/2 
eipx ˜ψ(p)dp holds
pointwise. By a Schwarz inequality we get1
|ψ(x)| ≤(2π)−3/2

(α2 + |p|2)−2dp
1/2 
(α2 + |p|2)2| ˜ψ(p)|2dp
1/2
= cα−1/2∥(H0 + α2)ψ∥
≤cα−1/2∥H0ψ∥+ cα3/2∥ψ∥
(4.19)
for some constant c. Hence |ψ(x)| is bounded and so is in the domain of V. Thus
D(H0) ⊂D(V). Furthermore for ψ ∈D(H0) we have
∥Vψ∥≤∥V∥2∥ψ∥∞≤∥V∥2

cα−1/2∥H0ψ∥+ cα3/2∥ψ∥

(4.20)
For α sufﬁciently large Kato’s inequality holds and we conclude that H is self-adjoint
on D(H0).
For the last result treat V2 as a bounded perturbation of H0 + V1.
Example 4.1
Consider the Yukawa potential
V(x) = c
|x|e−μ|x|
(4.21)
This is supposed to provide a crude model of nuclear forces transmitted by a
particle of mass μ > 0. We have V ∈L2(R3) and hence H = H0+V is self-adjoint
on D(H0) by the theorem.
Example 4.2
Consider the Coulomb potential
V(x) = −e2
|x|
(4.22)
This is supposed to describe an electron of charge −e in the electrostatic ﬁeld of
a proton of charge e. This is a simple model of the Hydrogen atom. If B is the unit
ball, then V = V 1B + V 1Bc exhibits the potential as the sum of an L2 function
and an L∞function. Hence H = H0 + V is self-adjoint on D(H0) by the theorem.
We also consider a particle in a magnetic ﬁeld B = ∇×A. Applying our canonical
quantization procedure to the Hamiltonian (2.13) with  = 0 we ﬁnd the quantum
Hamiltonian
1 This is an example of a Sobolev inequality.

51
4.3 Spectrum
t
H = 1
2m

−i∇−e
cA
2
≡H0 +
e
2mc (2iA · ∇+ i∇· A) +
e2
2mc2 |A|2
(4.23)
Problem 4.3
Suppose A and all its ﬁrst derivatives are bounded functions. Show
that the Hamiltonian (4.23) is self-adjoint on D(H0).
4.3 Spectrum
We study the spectrum of H = H0 + V. First we need a variation of the Riesz–
Schauder theorem, theorem 1.15.
A function F(z) from an open set O ⊂C to a Banach space is said to be analytic
if the derivative F′(z) = limh→0(F(z + h) −F(z))/h exists for all z ∈O. Analytic
functions in this sense enjoy many of the same properties of complex-valued analytic
functions, e.g Cauchy’s theorem, power series representation, etc.
Theorem 4.3
(Analytic Fredholm theorem) Let F(z) be an analytic function from a
connected open set O ⊂C to B(H) such that F(z) is compact for all z ∈O. Then
one of the following holds:
1. (I + F(z))−1 does not exist for any z ∈O.
2. (I + F(z))−1 exists except for a discrete set S ⊂O with no limit points in O. For
z ∈S the operator F(z) has eigenvalue −1 with ﬁnite multiplicity.
For the proof see Reed and Simon (1980: 201).
Problem 4.4
Show that the Riesz–Schauder theorem follows from the analytic
Fredholm theorem. (Hint: (T −z) = −z(I −T/z).)
Theorem 4.4
Let V ∈L2(R3) and let H = H0 + V on H = L2(R3). Then σ(H) ∩
(−∞, 0) is a bounded countable set E1 < E2 < E3 < · · · < 0 (possibly empty) with
no limit points except possibly zero. Each Ej is an eigenvalue with ﬁnite multiplicity.
Remark
We characterize σ(H) ∩[0, ∞) in section 4.5.
Proof
H is self-adjoint by theorem 4.2. Consider E < 0. On D(H) = D(H0) we
have the identity
(H −E) = (I + V(H0 −E)−1)(H0 −E)
(4.24)
Since E is in the resolvent set for H0, we see that E is in the resolvent set for H iff
(I + V(H0 −E)−1)−1 exists as a bounded operator. Furthermore (H −E)ψ has a
nonzero solution in D(H) iff (I + V(H0 −E)−1)φ = 0 has a nonzero solution in H,
that is iff V(H0 −E)−1 has eigenvalue −1.

52
Single particle
t
First we show that the spectrum is bounded below. In Kato’s inequality ∥Vψ∥≤
a∥H0ψ∥+ b∥ψ∥insert ψ = (H0 −E)−1φ and obtain
∥V(H0 −E)−1φ∥≤

a + b
|E|

∥φ∥
(4.25)
Thus if E is sufﬁciently negative, ∥V(H0 −E)−1∥< 1 and so (I + V(H0 −E)−1)−1
exists and E is in the resolvent set for H.
We next note that V(H0 −E)−1 is an analytic function in C −[0, ∞). Indeed one
can compute directly that the derivative is V(H0 −E)−2.
We claim V(H0 −E)−1 is compact for all such E in C −[0, ∞). It sufﬁces to
show the momentum space version FV(H0 −E)−1F−1 is compact, and we show it
is Hilbert–Schmidt. Since the Fourier transform of a product is the convolution of
the transforms, we have
(FV(H0 −E)−1F−1ψ)(p) = (2π)−3/2( ˜V ∗(F(H0 −E)−1F−1)ψ)(p)
= (2π)−3/2

˜V(p −q)
|q|2
2m −E
−1
ψ(q) dq
≡

k(p, q)ψ(q) dq
(4.26)
This is Hilbert–Schmidt since
∥k∥2
2 = (2π)−3
 
˜V(p −q)
|q|2
2m −E
−1
2
dp dq
= (2π)−3∥V∥2
2
 
|q|2
2m −E

−2
dq
< ∞
(4.27)
Now we can apply the analytic Fredholm theorem for V(H0 −E)−1 in the region
C−[0, ∞). The alternative that (I+V(H0−E)−1)−1 does not exist anywhere is ruled
out for E very negative by (4.25). Thus we conclude V(H0 −E)−1 has eigenvalue −1
at a bounded discrete set of points E1, E2, . . . necessarily real and with no accumu-
lation point except possibly zero. Hence H has these eigenvalues. The multiplicity
is ﬁnite for V(H0 −Ej)−1 and hence the Ej have ﬁnite multiplicity as eigenvalues
of H.
Note that the theorem holds in particular for the Yukawa potential, example 4.1.
Problem 4.5
Prove the same result if for every ϵ > 0 there exists a split V =
V1 + V2 such that V1 ∈L2 and V2 ∈L∞with ∥V2∥∞< ϵ.
Example 4.3
Consider the Coulomb potential of example 4.2 with the Hamilto-
nian
H = −
2m −e2
|x|
(4.28)

53
4.4 The harmonic oscillator
t
The potential V(x) = −e2/|x| satisﬁes the conditions of the previous problem as
we see by letting BR be the ball of radius R and writing V = V 1BR + V 1Bc
R with
R large depending on ϵ. We conclude that the negative spectrum is purely discrete
with ﬁnite multiplicity.
Actually for this problem the spectrum can be computed exactly. Solving the
differential equation (H −E)ψ = 0 by separation of variables one ﬁnds that the
eigenvalues are
En = −me4
2n2
n = 1, 2, 3, . . .
(4.29)
and the dimension of the eigenspace for En is n2. For details see any textbook on
quantum mechanics.
These are the energy levels for hydrogen. Differences of these energies
determine the frequencies of light emitted by hydrogen, something which is
experimentally observable. The success of these predictions was one of the
original triumphs of quantum mechanics.
Problem 4.6
Let V be the rank-one operator Vψ = λχ(χ, ψ) where λ is real
and ∥χ∥= 1. Deﬁne H = H0 + V as a self-adjoint operator. Find the negative
spectrum.
4.4 The harmonic oscillator
The harmonic oscillator potential is
V(x) = k|x|2/2
(4.30)
The classical Hamiltonian |p|2/2m + k|x|2/2 describes a particle with equilibrium
position x = 0 subject to a linear restoring force −kx. The quantum Hamiltonian is
H = −
2m + k
2|x|2
(4.31)
This potential is not a small perturbation of H0 and is not covered by any of our
analysis so far. However we can analyze it directly. For simplicity take m = 1, k = 1
and dimension d = 1.
Theorem 4.5
The Hamiltonian
H = 1
2

−d2
dx2 + x2

(4.32)
is essentially self-adjoint on S(R) ⊂L2(R) and has spectrum 1
2, 1, 3
2, 2, . . . .

54
Single particle
t
Proof
Introduce the operators
a∗=
1
√
2

x −d
dx

a =
1
√
2

x + d
dx

(4.33)
and then
H = a∗a + 1
2
(4.34)
We can ﬁnd one eigenfunction by solving a0 = 0, for then H0 = 1
20. The
normalized solution is
0(x) = (π)−1/4e−x2/2
(4.35)
From this we can generate more eigenfunctions deﬁning
n = (a∗)n0
(4.36)
Since [a, a∗] = 1, we have [H, a∗] = a∗and hence can compute
Hn =

n + 1
2

n
(4.37)
Thus the spectrum of H consists of at least the positive half integers.
In fact the n are the Hermite polynomial and form a complete orthogonal set.
A proof of the completeness is sketched in the following problem. Since H has
a complete set of eigenfunctions, it is essentially self-adjoint and the spectrum is
exactly the eigenvalues 1
2, 1, 3
2, 2, . . . ; see problem 1.13.
Problem 4.7
Show that the eigenfunctions n form a complete set by the
following steps:
1. Show that the subspace spanned by ﬁnite linear combinations is the space P
of all functions of the form P(x) exp(−x2/2) where P(x) is a polynomial with
complex coefﬁcients.
2. Show that for any k ∈R the function eikxe−x2/2 is in the closure P.
3. Show that P = L2(R) by showing that the orthogonal complement is {0}.
Theorem 4.5 readily generalizes to any number of dimensions. The features of
this example will surface again in quantum ﬁeld theory. A scalar quantum ﬁeld can
be thought of as an inﬁnite collection of coupled harmonic oscillators, one for each
point in space. The displacement is not in physical space, but in ﬁeld strength.
Problem 4.8
Find the spectrum for the harmonic oscillator in d = 3.
Finally we note that there is an explicit formula for the kernel of the semi-group
e−tH known as Mehler’s formula. It is

55
4.5 Scattering
t
(e−tHf)(x) =

qt(x, y)f(y)dy
(4.38)
where
qt(x, y) = (2π sinh t)−1/2 exp

−1
2(coth t)(x2 + y2) + (sinh t)−1xy

(4.39)
Problem 4.9
Check Mehler’s formula by verifying the following:
1. For t > 0
 ∂
∂t + H

qt(x, y) = 0
(4.40)
2. For f ∈S(R)
lim
t→0

qt(x, y)f(y)dy = f(x)
(4.41)
4.5 Scattering
4.5.1 Wave operators
We continue to consider the single particle in a potential with Hamiltonian H =
H0 + V and ask for the behavior of the state e−iHtψ as t →∞. One possibility is
that ψ is an eigenvector Hψ = Eψ and in this case e−iHtψ = e−iEtψ. The state is
localized and stationary and is called a bound state.
Another possibility is that the particle escapes the potential and behaves like a free
particle. In this case there would be a free state e−iH0tφ such that
lim
t→∞∥e−iHtψ −e−iH0tφ∥= 0
(4.42)
This is equivalent to
lim
t→∞∥ψ −eiHte−iH0tφ∥= 0
(4.43)
This motivates the deﬁnition of wave operators ± as the limits
±φ =
lim
t→±∞eiHte−iH0tφ
(4.44)
when they exist for φ in H. Given φ let ψ = ±φ. Then ∥e−iHtψ −e−iH0tφ∥→0
as t →±∞. Thus we have found a state with given asymptotic behavior either in
the past or the future. Note also that
∥±φ∥=
lim
t→±∞∥eiHte−iH0tφ∥= ∥φ∥
(4.45)
Thus ± is an isometry if it exists.

56
Single particle
t
Theorem 4.6
In H = L2(R3), if V ∈L2(R3), then ± exists.
Proof
Let t = eiHte−iH0t. We must show that tφ has a limit as t →±∞. Since
∥t∥= 1, we can approximate tφ by tφ′ with φ′ ∈S(R3) uniformly in t. Thus it
sufﬁces to prove the result for φ ∈S(R3).
Such φ are in D(H) = D(H0) and so we may compute the derivative
d
dttφ = d
dt(eiHte−iH0tφ)
= eiHt(iH −iH0)e−iH0tφ
= eiHtiVe−iH0tφ
(4.46)
Here we use the fact that e−iH0t leaves D(H0) invariant.
Now we write for t′ > t > 0
(t′ −t)φ =
 t′
t
eiHsiVe−iH0sφ ds
(4.47)
Here the integral can be understood as a Hilbert space valued Riemann integral since
the integrand is a continuous Hilbert space valued function. It follows that
∥(t′ −t)φ∥≤
 t′
t
∥Ve−iH0sφ∥ds
≤
 t′
t
∥V∥2∥e−iH0sφ∥∞ds
≤2c∥V∥2(t−1/2 −t′−1/2)
(4.48)
Here we have used the bound (4.7) which says
∥e−iH0sφ∥∞≤cs−3/2
(4.49)
Thus tjφ is a Cauchy sequence for any tj →∞and hence the limits limt→∞t
exists. The limit t →−∞is similar.
Problem 4.10
Let V be a rank-one operator as in problem 4.6, now with χ ∈
L1 ∩L2. Show that ± exist.
4.5.2 Asymptotic completeness
Suppose the wave operators exist. We deﬁne
H± = Ran(±)
(4.50)
Since the range of an isometry is closed, this is a closed subspace of H. These
are states which become free as t →±∞. We also deﬁne a subspace of bound
states
Hbd = closed subspace spanned by eigenvectors of H
(4.51)

57
4.5 Scattering
t
Lemma 4.2
H± and Hbd are orthogonal subspaces.
Proof
Let ψ = +φ and let Hχ = Eχ. We show that (χ, ψ) = 0. We have
(χ, ψ) = lim
t→∞(χ, eiHte−iH0tφ) = lim
t→∞eiEt(χ, e−iH0tφ)
(4.52)
Thus it sufﬁces to show for χ, φ ∈L2(R3) that limt→∞(χ, e−iH0tφ) = 0. We can
assume that χ, φ ∈S(R3) since we can approximate the general case uniformly in t.
Then the result follows from the bound (4.49) since
|(χ, e−iH0tφ)| ≤∥χ∥1∥e−iH0tφ∥∞→0
(4.53)
It is possible that these subspaces exhaust the Hilbert space, that is
H = H± ⊕Hbd
(4.54)
If this is true, we say that the system exhibits asymptotic completeness. Note that this
entails that H+ = H−. Roughly it means that either a state is stationary or it goes
out to inﬁnity both in the distant past and in the distant future.
Asymptotic completeness is generally true. For example if V ∈L1 ∩L2, it is true,
although not especially easy to prove.
4.5.3 The scattering operator
Next we discuss actual scattering experiments, for example scattering a neutron off
a nucleus, which we model as scattering the neutron off the potential created by the
nucleus. We prepare the neutron in a certain state, which we model by the condition
that it behaves like e−iH0tφ as t →−∞. Thus the prepared state (at time zero) is
−φ. After the scattering has taken place we measure the state of the system to be
something with asymptotic behavior e−iH0tχ as t →∞. Thus the measured state (at
time zero) is +χ. By (3.2) the probability of this occurring is
|(+χ, −φ)|2 = |(χ, Sφ)|2
(4.55)
Here we have introduced the scattering operator
S ≡(+)∗−
(4.56)
One can then study the structure of the nucleus by hypothesizing a potential V,
computing the scattering operator S for the potential, and then comparing the scat-
tering probabilities |(χ, Sφ)|2 with the observed events. A more ambitious program
is the so-called inverse scattering problem which asks to ﬁnd V given S.
Lemma 4.3
If H+ = H−, then S is unitary.

58
Single particle
t
Proof
Since ± are isometries, we have
(±)∗± = I
±(±)∗= PH±
(4.57)
Then we compute
S∗S = (−)∗+(+)∗−= (−)∗−= I
(4.58)
Similarly SS∗= I. Hence S is unitary.
4.5.4 Continuous spectrum
Finally we complete our characterization of the spectrum using the wave operators.
Theorem 4.7
Suppose that ± exist.
1. eiHt± = ±eiH0t.
2. H restricted to H± has continuous spectrum [0, ∞).
Proof
1. This follows from the computation
eiHt±φ =
lim
s→±∞eiH(t+s)e−iH0sφ
=
lim
u→±∞eiHue−iH0(u−t)φ
= ±eiH0tφ
(4.59)
2. ± : H →H± is unitary. Then eiHt restricted to H± is unitarily equivalent to
eiH0t on H by
eiHt = ±eiH0t(±)−1
(4.60)
It follows that the generators H|H± and H0 are unitarily equivalent. Since H0 has
continuous spectrum [0, ∞) (problem 4.2), the same is true for H|H±.
4.6 Spin
4.6.1 Representations of the rotation group
As noted earlier the natural representation of the rotation group SO(3) on our Hilbert
space H = L2(R3) is (U(R)ψ)(x) = ψ(R−1x). There are however other possibilities
for a single particle. Suppose that R →T(R) is a representation of SO(3) by unitary
m×m matrices so that T(R1)T(R2) = T(R1R2). Then we could take the Hilbert space

59
4.6 Spin
t
to be H = L2(R3, Cm), the square integrable Cm valued functions on R3, and deﬁne
a unitary representation on H by
(U(R)ψ)(x) = T(R)ψ(R−1x)
R ∈SO(3)
(4.61)
If we want our particle to be elementary (that is not composite), we would add the
requirement that T is irreducible.
It turns out that the most common elementary particles (electrons, protons, neu-
trons) do behave nontrivially under rotations, but not exactly in the manner suggested
above. Instead there is a representation of the universal covering group of SO(3).
This is SU(2), the 2 × 2 complex matrices A satisfying A∗A = 1 and det A = 1.
As we explain below there is a two-to-one homomorphism A →R(A) from SU(2)
onto SO(3) such that R(−A) = R(A). If T(A) is an m-dimensional unitary represen-
tation of SU(2), then there is a unitary representation of SU(2) on the Hilbert space
H = L2(R3, Cm) deﬁned by
(U(A)ψ)(x) = T(A)ψ(R(A)−1x)
A ∈SU(2)
(4.62)
This also gives a representation of SO(3) if we recall that the states are really rays.
To ﬁnd the action of R ∈SO(3) choose ±A so R(±A) = R and deﬁne (U(R)ψ)(x) =
T(±A)ψ(R−1x). For an irreducible representation, T(−A) = ±T(A). Thus the choice
of ±A at worst changes the sign, and this has no effect on the ray.
It turns out there is an m-dimensional irreducible representation of SU(2) for
all positive integers m. The dimension is written m = 2s + 1 with s = 0, 1/2, 1, 3/2,
2, . . . and we say that the particle has spin s; more on this terminology later.
For spin zero we have T(A) = I. This is the case we have been discussing and
describes pions. For spin 1/2 we have T(A) = A; this is the case that describes elec-
trons, protons, neutrons, etc. For spin one we have T(A) = R(A) and we are back
to a special case of (4.61). A modiﬁcation of this describes photons; see section 9.4.
Higher spins are also possible.
4.6.2 The covering group
Now we explain the covering map. First deﬁne Pauli matrices by
σ1 =

0
1
1
0

σ2 =

0
−i
i
0

σ3 =

1
0
0
−1

(4.63)
These form a basis for the real vector space of self-adjoint traceless 2 × 2 matrices.
(The matrices −iσ1/2, −iσ2/2, −iσ3/2 form a standard basis for the skew-adjoint
traceless matrices, the Lie algebra of SU(2).) With any x ∈R3 associate the matrix
σ · x =
3

i=1
σixi =

x3
x1 −ix2
x1 + ix2
−x3

(4.64)

60
Single particle
t
Note that
det(σ · x) = −|x|2
(4.65)
Now for A ∈SU(2) we have that A(σ ·x)A−1 is again a self-adjoint traceless matrix
and thus it has the form σ · y for a unique y ∈R3. The map x →y is easily seen to
be linear and so y = R(A)x for some matrix R(A). Thus R(A) is deﬁned by2
A(σ · x)A−1 = σ · (R(A)x)
(4.66)
Lemma 4.4
The map A →R(A) is a two-to-one homomorphism from SU(2) onto
SO(3).
Proof
First R(A) is a homomorphism because
σ · (R(AB)x) = (AB)(σ · x)(AB)−1
= A(σ · R(B)x)A−1
= σ · (R(A)R(B)x)
(4.67)
which implies R(AB) = R(A)R(B). Second R(A) is orthogonal because
|R(A)x|2 = −det(σ · (R(A)x)) = −det(σ · x) = |x|2
(4.68)
To see that R(A) is a rotation we need det(R(A)) = 1. This follows from the facts that
det(R(I)) = det I = 1 and that A →det(R(A)) is continuous from SU(2) to {±1} and
that SU(2) is connected (see problem 4.11).
Next note that
exp
−iσ3θ
2

=
 e−iθ/2
0
0
eiθ/2

(4.69)
is an element of SU(2). By explicit computation we ﬁnd that
exp
−iσ3θ
2

(σ · x) exp
iσ3θ
2

= σ · (R(e3, θ)x)
(4.70)
where R(e3, θ) is the rotation by θ around the e3 axis (2.38), and so
R

exp
−iσ3θ
2

= R(e3, θ)
(4.71)
Rotations about the other axes are generated similarly. Since rotations about the three
axes generate SO(3), the homomorphism is onto.
To show that the homomorphism is two-to-one it sufﬁces to check that R(A) = I
implies A = ±I which we omit.
Problem 4.11
Show that every element of SU(2) can be written in the form
A =

α
β
−¯β
¯α

(4.72)
2 Essentially we are deﬁning R(A) as the adjoint representation of SU(2).

61
4.6 Spin
t
for complex α, β satisfying |α|2 + |β|2 = 1. Thus SU(2) can be identiﬁed with
the three-sphere S3 and hence is simply connected.
4.6.3 Spin 1/2 particles
Now we discuss quantum mechanics for a spin 1/2 particle. The Hilbert space is
H = L2(R3, C2) and the representation of SU(2) is
(U(A)ψ)(x) = Aψ(R(A)−1x)
A ∈SU(2)
(4.73)
Our deﬁnition of angular momentum should now be modiﬁed. The third component
is the generator of rotations around the third axis and is now given by
(J3ψ)(x) = i d
dθ
	
exp
−iσ3θ
2

ψ(R(e3, θ)−1x)

θ=0
(4.74)
This is computed as
J3 = L3 + σ3
2
(4.75)
Here L3 is the “orbital” angular momentum computed in (3.27). To this is added
an intrinsic angular momentum σ3/2 called spin. The spin operator has eigenvalues
±1/2 hence the term “spin 1/2.” Other components are treated similarly. Spin has no
classical analog.
A spin 1/2 particle has a modiﬁed Hamiltonian in the presence of electric and
magnetic ﬁelds with potentials (, A). This is the Pauli Hamiltonian
H = 1
2m

−i∇−e
cA
2
+ e −e
mc
σ
2 · B

(4.76)
where B = ∇× A is the magnetic ﬁeld. This arises naturally as an approximation to
a relativistic Dirac Hamiltonian.
Problem 4.12
Suppose that the magnetic ﬁeld B is constant with A = (B × x)/2.
Show that for e/c small
1
2m

−i∇−e
cA
2
= −
2m −
e
2mc(L · B) + O(e2/c2)
(4.77)
This problem shows that in the Pauli Hamiltonian the spin angular momentum
σ/2 couples to a magnetic ﬁeld in the same way as the orbital angular momentum L,
except for a factor of 2 known as the “gyromagnetic ratio.”
Notes on chapter 4: See Reed and Simon (1980), Reed and Simon (1975),
Reed and Simon (1979), Reed and Simon (1978), and Cycon et al. (1987) for much

62
Single particle
t
more about self-adjointness, spectra, and scattering. For spin and representations of
SU(2), see Miller (1972). Besides potentials that are functions one can also study
delta function potentials, see Albeverio et al. (1988).
The expression −i∇−ec−1A in (4.23) or (4.76) can be interpreted as a covariant
derivative on a complex line bundle. See section 7.4

5
Many particles
5.1 Two particles
5.1.1 A ﬁrst look
Suppose we have two (spinless) particles. As explained in example 2.3 the classical
Hamiltonian for the system might have the form
H(p1, p2, x1, x2) = p2
1
2m1
+ p2
2
2m2
+ V(x1 −x2)
(5.1)
Here pi ∈R3, xi ∈R3 are the momentum and position of the ith particle, mi is
the mass of the ith particle and V is a potential giving the interaction between them.
Following our canonical quantization procedure we replace p1, p2, x1, x2 by operators
ˆp1, ˆp2, ˆx1, ˆx2 satisfying the canonical commutation relations. We take ˆpi = −i∇xi and
ˆxi = [xi] acting in the Hilbert space H = L2(R3 × R3) = L2(R6). With this choice
the quantum Hamiltonian becomes
H = −1
2m1
+ −2
2m2
+ V(x1 −x2)
(5.2)
where i is the Laplacian in xi. If V = 0, then the Hamiltonian is
H0 = −1
2m1
+ −2
2m2
(5.3)
This can be deﬁned as a self-adjoint operator with the Fourier transform on R6 by
H0 = F−1

p2
1
2m1
+ p2
2
2m2

F
(5.4)
where the multiplication operator has the natural domain.
Problem 5.1
If V ∈L2(R3), show that H = H0 + V is self-adjoint on D(H0).
63

64
Many particles
t
5.1.2 Generalization
Now we give a more general treatment. Suppose we have two particles: the ﬁrst with
Hilbert space H1 and time evolution U1(t) = exp(−iH1t) and the second with Hilbert
space H2 and time evolution U2(t) = exp(−iH2t). The Hilbert spaces may allow spin
or other internal degrees of freedom like charge. To describe the two particle system,
the prescription is that the Hilbert space is the tensor product
H = H1 ⊗H2
(5.5)
(See appendix B for the deﬁnition of tensor product.) If the particles do not interact,
then they should evolve in time just as they would by themselves, that is
U(t) = U1(t) ⊗U2(t)
(5.6)
This is a strongly continuous unitary group and so by Stone’s theorem it has a self-
adjoint generator U(t) = exp(−iHt). We compute H = i d/dt[U(t)]t=0 when it
exists. For example if ψ ∈D(H1) and φ ∈D(H2)
H(ψ ⊗φ) = (H1ψ ⊗φ) + (ψ ⊗H2φ)
(5.7)
More generally let D(H1) ⊗D(H2) be the algebraic tensor product of D(H1) and
D(H2), that is ﬁnite linear combinations of ψ ⊗φ as above. On this dense domain
we have
H = (H1 ⊗I) + (I ⊗H2)
(5.8)
Let us see how this reproduces the earlier treatment. Suppose we have two free
spinless particles so that Hi = L3(R3) and Hi = −/2mi. In this case we have a
natural identiﬁcation
H1 ⊗H2 = L2(R3) ⊗L2(R3) ⇐⇒L2(R6)
(5.9)
The identiﬁcation is given by a unitary operator which sends the vector ψ ⊗φ ∈
L2(R3) ⊗L2(R3) to the function ψ ⊗φ ∈L2(R6) deﬁned by
(ψ ⊗φ)(x1, x2) = ψ(x1)φ(x2)
(5.10)
(See appendix B for details.) Under this identiﬁcation we have
H1 ⊗I =
 −
2m1
⊗I

⇐⇒−1
2m1
I ⊗H2 =

I ⊗−
2m2

⇐⇒−2
2m2
(5.11)

65
5.1 Two particles
t
Thus the Hamiltonian H = H1 ⊗I + I ⊗H2 is identiﬁed with the Hamiltonian
H0 = −1/2m1 −2/2m2 on L2(R6) as deﬁned earlier.
5.1.3 Center of mass coordinates
How can we incorporate potentials into this tensor product structure? We give one
answer now and another answer later in section 5.4.2. Working on L2(R6) we make
a change of coordinates
X = m1x1 + m2x2
m1 + m2
x = x1 −x2
(5.12)
Then X represents the center of mass of the system and x is the relative displacement
of the particles. If M = m1 + m2 is the total mass, then the inverse is
x1 = X + m2
M x
x2 = X −m1
M x
(5.13)
The coordinate change is implemented by the operator
(Vψ)(X, x) = ψ

X + m2
M x, X −m1
M x

(5.14)
The operator V is unitary on L2(R6) since the Jacobian determinant for the
transformation has absolute value one.
If H is the full two particle Hamiltonian (5.2), we ﬁnd in the new coordinates
H′ ≡VHV−1 = Hcm + Hrel
(5.15)
where on (X, x) ∈L2(R6)
Hcm = −X
2M
Hrel = −x
2μ + V(x)
(5.16)
and where
μ =
m1m2
m1 + m2
(5.17)
is called the reduced mass.
Now under the correspondence L2(R6) ↔L2(R3)⊗L2(R3) with the identiﬁcation
φ(X)ψ(x) ↔φ ⊗ψ we ﬁnd as before
e−iH′t = exp(−iHcmt) ⊗exp(−iHrelt)
H′ = (Hcm ⊗I) + (I ⊗Hrel)
(5.18)
Thus the center of mass and a ﬁctitious relative particle evolve in time independently
of each other. The motion of the center of mass is free. The motion of the relative
particle is the same as that of a single particle in a potential which we have studied

66
Many particles
t
at length in the previous chapter. The only change is that we have the relative mass
μ instead of the actual mass. If m2 is much larger than m1, then μ ≈m1. This is
the case for the hydrogen atom where the mass of the proton is much larger than the
mass of the electron.
Problem 5.2
Verify (5.15).
5.2 Identical particles
Until now we have been implicitly assuming that our two particles are distinguishable
in the sense that they have a different mass or spin or charge. But suppose that this is
not the case, for example suppose we have two electrons. Empirically there is no way
to tell which is which. This statement is true in the strong sense that there is no way
to label the particles and follow their individual evolution through the course of an
experiment. This seems to be a deep fact and not just a reﬂection of our limited skill
at experiments. Then describing the two particle system by a Hilbert space H ⊗H,
which effectively labels the particles, would be a substantial over-description. Indeed
nature does not choose this Hilbert space, but rather a subspace which is invariant
under permutation of the labels.
We deﬁne a permutation operator P on H ⊗H by
P(ψ1 ⊗ψ2) = ψ2 ⊗ψ1
(5.19)
This satisﬁes P2 = I and P∗= P. We restrict to the subspace which is invariant
under P. The orthogonal projection onto this subspace is
+ = 1
2(I + P)
(5.20)
since this is a projection and Pψ = ψ iff ψ ∈Ran +. Thus our Hilbert space is
H+
2 = +(H ⊗H)
(5.21)
and is called the symmetric tensor product. An example of an element of this
space is
+(f ⊗g) = 1
2(f ⊗g + g ⊗f)
(5.22)
Particles for which this is the correct Hilbert space are called bosons. Examples are
pions and photons.
Remarkably this is not the only interesting possibility. Another possibility is that
the state changes sign under the permutation operator P. A change of sign still gives

67
5.3 n-particles
t
the same ray so our description is still invariant under P. The projection onto the
subspace which changes signs under P is
−= 1
2(I −P)
(5.23)
Now the Hilbert space is
H−
2 = −(H ⊗H)
(5.24)
and is called the anti-symmetric tensor product. An example of an element of this
space is
−(f ⊗g) = 1
2(f ⊗g −g ⊗f)
(5.25)
Particles for which this is the correct Hilbert space are called fermions. Examples are
electrons, protons, and neutrons.
The choice of the symmetric or anti-symmetric tensor product is called the statis-
tics of the particle. It turns out that particles with integer spin are always bosons,
and particles with half-integer spin are always fermions. This fact has an expla-
nation in quantum ﬁeld theory, but for us it is just an empirical fact. In spite of
this spin-statistics connection we will sometimes ﬁnd it useful to consider spinless
fermions.
5.3 n-particles
Starting with a Hilbert space for a single particle we want to construct a Hilbert space
for n identical particles. Consider the n-fold tensor product
Hn = H ⊗· · · ⊗H
(5.26)
We deﬁne operators on Hn by
+(f1 ⊗· · · ⊗fn) = 1
n!

π
fπ(1) ⊗· · · ⊗fπ(n)
−(f1 ⊗· · · ⊗fn) = 1
n!

π
sgn(π)fπ(1) ⊗· · · ⊗fπ(n)
(5.27)
where the sum is over permutations π of (1, . . . , n) and sgn(π) is the sign of the
permutation.1 One can check that this deﬁnes an operator on the dense domain of
ﬁnite combinations of vectors f1 ⊗· · · ⊗fn. One also checks that (±)2 = ±
and (±)∗= ±. It follows that ∥±ψ∥≤∥ψ∥and hence ± extends to a
1 A permutation π is a bijection on (1, . . . , n). The sign sgn(π) depends on the number of elementary
exchanges to return π(1), . . . , π(n) to its original order. It is ±1 depending on whether the number is
even or odd. We have sgn(π ◦σ) = sgn(π)sgn(σ).

68
Many particles
t
bounded operator on Hn (theorem 1.3). The extensions are projection operators since
the identities hold for the extensions.
The Hilbert space for n identical particles is taken as
H±
n = ±Hn = ±(H ⊗· · · ⊗H)
(5.28)
with the plus sign for bosons and the minus sign for fermions. Exchanging two
entries in this space has no effect for bosons, and changes the sign for fermions
±(f1 ⊗· · · ⊗fi ⊗· · · ⊗fj ⊗· · · ⊗fn)
= ±±(f1 ⊗· · · ⊗fj ⊗· · · ⊗fi ⊗· · · ⊗fn)
(5.29)
For fermions this means that if fi = fj for some i ̸= j, then
−(f1 ⊗· · · ⊗fn) = 0
(5.30)
This is the Pauli exclusion principle: two identical fermions cannot be in the same
state.
Next we consider a simple dynamics on H±
n . In general if U is a unitary operator
on H, then
n(U) ≡U ⊗· · · ⊗U
(5.31)
deﬁnes a unitary operator on Hn which preserves the subspaces H±
n . In particular if
e−iHt is a time evolution on the single particle space H, and if the particles do not
interact with each other, then
n(e−iHt) ≡e−iHt ⊗· · · ⊗e−iHt
(5.32)
is the time evolution on H±
n . This is a one-parameter unitary group and so has a
self-adjoint generator Hn such that
e−iHnt = n(e−iHt)
(5.33)
On D(H) ⊗· · · ⊗D(H) we compute by taking derivatives
Hn = dn(H) ≡H ⊗· · · ⊗I + · · · + I ⊗· · · ⊗H
(5.34)
Example 5.1
Atoms An atom with atomic number N is described by N-electrons
each moving under the inﬂuence of a central potential created by an atomic
nucleus of charge N
V(x) = −e2N
|x|
(5.35)
The single particle Hamiltonian is H = (−/2m) + V on H = L2(R3) as in
example 4.3. (Or we could take the Pauli Hamiltonian (4.76) on H = L2(R3, C2).)

69
5.3 n-particles
t
Since electrons are fermions, the multiparticle Hamiltonian is then HN = dN(H)
on H−
N as above.
Now H has the spectrum of the hydrogen atom but with e2 replaced by e2N.
Thus it has eigenfunctions {φk} with eigenvalues {ek} labeled so that e1 ≤e2 ≤
e3 ≤. . . . The multiparticle Hamiltonian HN has eigenfunctions
φα1,...,αN = −(φα1 ⊗· · · ⊗φαn)
(5.36)
with eigenvalues
eα1,...,αN =
N

i=1
eαi
(5.37)
Here α1, . . . , αN is a sequence of positive integers. However because of the Pauli
exclusion principle they must be distinct integers. Thus the lowest energy states,
physically the stable states, will be states like φ1,2,...,N. The electrons ﬁll the lowest
energy levels (“shells”).
This is the starting point for chemistry. Our model of an atom still needs
reﬁnement since we have neglected a number of additional effects, starting with
the interaction between the electrons themselves.
Example 5.2
Interacting particles Consider the case of N spinless bosons or
fermions interacting only with each other. The single particle Hilbert space is
H = L2(R3) with Hamiltonian H0 = −/2m. The N-particle Hilbert space is
H±
N and the free Hamiltonian is H0,N = dN(H0). However H±
N is isomorphic
to L2
±(R3N) the symmetric or anti-symmetric subspace of L2(R3N). Under this
isomorphism we have
H0,N =
N

i=1
−i
2m
(5.38)
If v is the potential between two particles with v(x) = v(−x), then the total
potential is VN deﬁned by
VN(x1, . . . , xN) =

1≤i<j≤N
v(xi −xj)
(5.39)
This acts on L2
±(R3N) and the total Hamiltonian on this space is
HN = H0,N + VN
(5.40)
As in problem 5.1 we can show that this is self-adjoint on D(H0,N).
Problem 5.3
In the previous example deﬁne representations of the translation
and rotation groups. Find the total momentum and angular momentum. Are they
conserved? (This is an extension of example 3.2.)

70
Many particles
t
Problem 5.4
From the deﬁnition (5.27) check that ± is well-deﬁned, that
(±)2 = ± and (±)∗= ±, and deduce that ∥±ψ∥≤∥ψ∥.
5.4 Fock space
5.4.1 Deﬁnitions
In non-relativistic quantum mechanics, for a closed system, the number of particles
is ﬁxed. Nevertheless it is convenient to introduce a formalism in which there are an
indeﬁnite number of particles. There are several reasons for this:
1. The formalism for an indeﬁnite number of particles has some elegant features
which can be used even when the particle number is ﬁxed.
2. The number of particles may undergo statistical ﬂuctuations due to contact with
an external system (more about this later).
3. It makes contact with relativistic quantum systems where the number of particles
in a closed system can actually change.
Start with a single particle Hilbert space H, and deﬁne the n-particle Hilbert space
H±
n to be the symmetric or anti-symmetric n-fold tensor product as in the last section.
Then the (boson/fermion) Fock space over H is the inﬁnite direct sum of the H±
n . It is
F±(H) =
∞

n=0
H±
n
(5.41)
where H±
0
≡C corresponds to no particles. The elements are sequences ψ =
(ψ0, ψ1, ψ2, . . . ) with ψn ∈H±
n such that
∥ψ∥2 =
∞

n=0
∥ψn∥2 < ∞
(5.42)
This is a Hilbert space with inner product
(ψ, χ) =
∞

n=0
(ψn, χn)
(5.43)
The no-particle state
0 = (1, 0, 0, . . . )
(5.44)
is also called the vacuum.

71
5.4 Fock space
t
We describe some operators on this space:
(1) The number operator N is deﬁned by
N(ψ0, ψ1, ψ2, ψ3, . . . ) = (0, ψ1, 2ψ2, 3ψ3, . . . )
(5.45)
or equivalently
(Nψ)n = nψn
(5.46)
It is self-adjoint on
D(N) = {ψ :

n
n2∥ψn∥2 < ∞}
(5.47)
It describes the number of particles in the state. For ∥ψ∥= 1 the quantity ∥ψn∥2 is
the probability of ﬁnding n-particles in the state.
(2) In general if U is a unitary operator on H, then (U) is the unitary operator on
F±(H) deﬁned by
(U) =
∞

n=0
n(U)
(5.48)
where n is deﬁned in (5.31). In particular if e−iH1t is a time evolution on H, then
we deﬁne a time evolution on F±(H) as
(e−iH1t) =
∞

n=0
n(e−iH1t)
(5.49)
This is a strongly continuous one-parameter unitary group and so has a self-adjoint
generator H such that e−iHt = (e−iH1t). On a domain with a ﬁnite number of parti-
cles and with wave functions in the algebraic tensor product D(H) ⊗· · · ⊗D(H) we
ﬁnd that
H = d(H1) ≡
∞

n=0
Hn
(5.50)
where Hn = dn(H1) is deﬁned in (5.34). This turns out to be a domain of
essential self-adjointness and so determines the operator completely. Note also that
N = d(1)
(3) We introduce creation and annihilation operators, at ﬁrst without statistics on
Hn = H⊗· · ·⊗H. For h ∈H deﬁne α∗(h) : Hn →Hn+1 and α(h) : Hn →Hn−1 by
α∗(h)(f1 ⊗· · · ⊗fn) =
√
n + 1 h ⊗f1 ⊗· · · ⊗fn
α(h)(f1 ⊗· · · ⊗fn) = √n (h, f1) f2 ⊗· · · ⊗fn
(5.51)

72
Many particles
t
One checks that these formulas do indeed deﬁne operators. Furthermore the opera-
tors are bounded with
∥α∗(h)∥≤
√
n + 1∥h∥
∥α(h)∥≤√n∥h∥
(5.52)
They are adjoint to each other because for ψ ∈Hn and χ ∈Hn+1 we have
(α∗(h)ψ, χ) = (ψ, α(h)χ). Note also that α∗(h) is linear in h while α(h) is anti-linear
in h.
Next we deﬁne a∗(h) : H±
n →H±
n+1 and a(h) : H±
n →H±
n−1 by
a∗(h) = ±α∗(h)
a(h) = ±α(h)
(5.53)
These are still bounded operators with the same bound and they are still adjoint to
each other. We need a more explicit expression for these operators
Lemma 5.1
a∗(h)±
n (f1 ⊗· · · ⊗fn)
=
√
n + 1 ±
n+1(h ⊗f1 ⊗· · · ⊗fn)
a(h)±
n (f1 ⊗· · · ⊗fn)
=
1
√n
n

j=1
(±1)j+1(h, fj)±
n−1(f1 ⊗· · · ⊗ˆfj ⊗· · · ⊗fn)
(5.54)
where the “hat” on ˆfj means omit this entry.
Proof
We give the proof for fermions; bosons are easier. With h = f0 we have
α∗(f0)−
n (f1 ⊗· · · ⊗fn)
=
√
n + 1
n!

π
sgn(π)f0 ⊗fπ(1) ⊗· · · ⊗fπ(n)
=
√
n + 1
n!

π′:π′(0)=0
sgn(π′)fπ′(0) ⊗fπ′(1) ⊗· · · ⊗fπ′(n)
(5.55)
In the second expression we have replaced the sum over permutations π on (1, . . . , n)
with a sum over permutations π′ on (0, 1, . . . , n) that leave 0 ﬁxed. Now to get
a∗(f0)−
n (f1 ⊗· · · ⊗fn) we apply −
n+1. However
−
n+1(sgn(π′) fπ′(0) ⊗fπ′(1) ⊗· · · ⊗fπ′(n)) = −
n+1(f0 ⊗f1 ⊗· · · ⊗fn)
(5.56)
and
1
n!

π′:π′(0)=0
1 = 1
(5.57)
so we have the ﬁrst result.

73
5.4 Fock space
t
For the second result we compute
α(f0)−
n (f1 ⊗· · · ⊗fn)
=
√n
n!

π
sgn(π)(f0, fπ(1))fπ(2) ⊗· · · ⊗fπ(n)
=
√n
n!

j
(−1)j+1(f0, fj)

σ
sgn(σ)fσ(2) ⊗· · · ⊗fσ(n)
(5.58)
=
1
√n

j
(−1)j+1(f0, fj)−
n−1(f2 ⊗· · · ˆfj · · · ⊗fn)
Here in the second step we have replaced the sum over permutations π of
(1, . . . , n) by a sum over j = π(1) and a sum over bijections σ from (2, . . . , n) to
(1, . . . ,ˆj, . . . , n). We have also used sgn(π) = (−1)j+1sgn(σ) where sgn(σ) is the
number of elementary exchanges to return σ(2), . . . , σ(n) to its natural order. (It takes
j−1 exchanges to move π(1) = j back to the ﬁrst position, and (−1)j−1 = (−1)j+1.)
Thus α(h) already maps into the symmetrized subspace, hence a(h) = α(h), and
hence the result.
The operators a∗(h), a(h) on H±
n induce operators on the boson/fermion Fock
spaces F±(H) by letting them act on each component. We make the convention that
a(h) = 0 on H0. As a dense domain for these operators we take the ﬁnite particle
vectors
D0 = {ψ ∈F±(H) : ∃N so ψn = 0 for n ≥N}
(5.59)
The operators preserve this domain. From (5.54) we have
±
n (f1 ⊗· · · ⊗fn) =
1
√
n!
a∗(f1) · · · a∗(fn)0
(5.60)
Thus we can create a dense set of states by acting on the vacuum with creation
operators and taking the linear span.
Lemma 5.2
With [A, B]±
=
AB ± BA the following commutation or anti-
commutation relations hold on F±(H)
[a(g), a(h)]∓= 0
[a∗(g), a∗(h)]∓= 0
[a(g), a∗(h)]∓= (g, h)
(5.61)
Proof
To check the last we compute using (5.54)
a(g)a∗(h)±
n (f1 ⊗· · · ⊗fn)
= (g, h)±
n (f1 ⊗· · · ⊗fn)
+
n

j=1
(±1)j(g, fj)±
n (h ⊗f1 ⊗· · · ⊗ˆfj ⊗· · · ⊗fn)
(5.62)

74
Many particles
t
On the other hand
a∗(h)a(g)±
n (f1 ⊗· · · ⊗fn)
=
n

j=1
(±1)j+1(g, fj)±
n (h ⊗f1 ⊗· · · ⊗ˆfj ⊗· · · ⊗fn)
(5.63)
Comparing these gives the result [a(g), a∗(h)]∓= (g, h).
We still have that a∗(h) is linear in h, that a(h) is anti-linear in h, and that for
ψ, χ ∈D0
(a∗(h)ψ, χ) = (ψ, a(h)χ)
(5.64)
This says that (a(h))∗⊃a∗(h) and (a∗(h))∗⊃a(h). Since the adjoints are densely
deﬁned, the operators a(h), a∗(h) have closures which we denote by the same symbol.
To characterize the closure we have the following:
Lemma 5.3
1. For bosons D(
√
N) ⊂D(a∗(h)), also for a(h), and for ψ ∈D(
√
N)
∥a∗(h)ψ∥≤∥h∥∥
√
N + 1ψ∥
∥a(h)ψ∥≤∥h∥∥
√
Nψ∥
(5.65)
2. For fermions the closed operators are bounded and satisfy
∥a∗(h)ψ∥≤∥h∥∥ψ∥
∥a(h)ψ∥≤∥h∥∥ψ∥
(5.66)
Proof
1. (Bosons) The inequality holds for ψ ∈D0 by (5.52). But D0 is a core for
√
N,
which means that given ψ ∈D(
√
N) there are sequences ψk ∈D0 such that
ψk →ψ,
√
Nψk →
√
Nψ as k →∞. (For example let ψk be the truncation of
ψ at the kth entry.) Then we have
∥a∗(h)(ψj −ψk)∥≤∥h∥∥
√
N + 1(ψj −ψk)∥→0
(5.67)
as j, k →∞. Thus limk→∞a∗(h)ψk exists and since a∗(h) is closed it follows that
ψ ∈D(a∗(h)) and that a∗(h)ψ = limk→∞a∗(h)ψk. Hence D(
√
N) ⊂D(a∗(h)).
Taking the limit in ∥a∗(h)ψk∥≤∥h∥∥
√
N + 1ψk∥we get the inequality for ψ.
2. (Fermions) The anti-commutation relation a∗(h)a(h) + a(h)a∗(h) = ∥h∥2 implies
for ψ ∈D0
∥a(h)ψ∥2 + ∥a∗(h)ψ∥2 = ∥h∥2∥ψ∥2
(5.68)
Hence the inequalities hold for ψ ∈D0 and it follows that closures are bounded
operators satisfying the same bound.
Problem 5.5
Verify the claims made for α∗(h), α(h).

75
5.4 Fock space
t
Problem 5.6
If U is unitary on H, show that
(U)a(h)(U−1) = a(Uh)
(U)a∗(h)(U−1) = a∗(Uh)
(5.69)
Problem5.7
Let T be a contraction on H, that is ∥T∥≤1. Show that (T) deﬁnes
a contraction on F±(H). Show that (T) may not be bounded if ∥T∥> 1.
5.4.2 Fock space over L2
We now specialize to the case where the one-particle Hilbert space is H = L2(R3).
In this case H±
n is identiﬁed with the symmetric or anti-symmetric subspace L2
±(R3n)
of L2(R3n).
Lemma 5.4
If ψ ∈H±
n is identiﬁed with ψ ∈L2
±(R3n), then a(h)ψ ∈H±
n−1 is
identiﬁed with a(h)ψ ∈L2
±(R3(n−1)) given by
(a(h)ψ)(x1, . . . , xn−1) = √n

h(x)ψ(x, x1, . . . , xn−1) dx
(5.70)
Proof
We give the proof for fermions. Consider ψ = −(f1 ⊗· · · ⊗fn) which is
identiﬁed with
ψ(x1, . . . , xn) = 1
n!

π
sgn(π)fπ(1)(x1) · · · fπ(n)(xn)
(5.71)
Then a(h)ψ is identiﬁed with
(a(h)ψ)(x2, . . . , xn)
=
1
√n
n

j=1
(−1)j+1(h, fj)[−
n−1(f1 ⊗· · · ˆfj · · · ⊗fn)](x2, . . . , xn)
=
1
√n
n

j=1
(−1)j+1(h, fj)
1
(n −1)!

σ
sgn(σ)fσ(2)(x2) · · · fσ(n)(xn)
= √n

h(x1)

1
n!

π
sgn(π)fπ(1)(x1) · · · fπ(n)(xn)

dx1
= √n

h(x1)ψ(x1, . . . , xn)dx1
(5.72)
The fourth line follows as in (5.58).

76
Many particles
t
If ψ ∈L2
±(R3n) is a continuous function, then in a(h)ψ we can take h to be a
δ-function and deﬁne an operator a(x) by
(a(x)ψ)(x1, . . . , xn−1) = √nψ(x, x1, . . . , xn−1)
(5.73)
We recover the original operator by a(h)ψ =

h(x)(a(x)ψ)dx. We also get an
operator a(x) on the Fock space by (a(x)ψ)n = a(x)ψn+1. Then
(a(x)ψ)n(x1, . . . , xn) =
√
n + 1 ψn+1(x, x1, . . . , xn)dx
(5.74)
As a suitable dense domain we might take ﬁnite particle vectors with wave functions
in Schwartz space
DS = {ψ ∈D0 : ψn ∈S(R3n)}
(5.75)
The operator a(x) has no adjoint; the formal adjoint creates delta functions which
are not in L2. Nevertheless we can deﬁne a∗(x) as the bilinear form on DS × DS,
anti-linear in the ﬁrst factor, which sends ψ, φ to
(ψ, a∗(x)φ) ≡(a(x)ψ, φ)
(5.76)
With this interpretation we have an elegant representation of some of our basic
operators:
Lemma 5.5
In F±(H), H = L2(R3), as bilinear forms on DS × DS:
1. The number operator satisﬁes
N =

a∗(x)a(x)dx
(5.77)
2. The free Hamiltonian H0 = d(−/2m) satisﬁes
H0 =

a∗(x)
−
2m

a(x)dx
(5.78)
3. Let v be an interparticle potential, for n ≥2 let Vn be the associated n-particle
potential deﬁned in (5.39), and let V = ⊕nVn be the Fock space potential. Then
V = 1
2

a∗(x)a∗(y)v(x −y)a(x)a(y)dxdx
(5.79)
Proof
Let ψ, φ ∈DS. Then we have
(ψ, (

a∗(x)a(x)dx)φ) ≡

(a(x)ψ, a(x)φ)dx
=
∞

n=0

((a(x)ψ)n, (a(x)φ)n)dx
=
∞

n=0
(n + 1)

ψn+1(x, x1, . . . , xn)φn+1(x, x1, . . . , xn)dxdx1 . . . dxn
= (ψ, Nφ)
(5.80)

77
5.4 Fock space
t
This proves the identity for N, and the identity for H0 is similar. For the last
we have
 1
2 (a(x)a(y)ψ, a(x)a(y)φ) v(x −y)dxdy
=
∞

n=0
(n + 1)(n + 2)
2

ψn+2(x, y, x1, . . . , xn)φn+2(x, y, x1, . . . , xn)
v(x −y) dxdy dx1 . . . dxn
=
∞

n=2
n(n −1)
2

ψn(x1, . . . , xn)φn(x1, . . . , xn)v(x1 −x2) dx1 . . . dxn
(5.81)
=
∞

n=2

1≤i<j≤n

ψn(x1, . . . , xn)φn(x1, . . . , xn)v(xi −xj) dx1 . . . dxn
=
∞

n=2
(ψn, Vnφn)
= (ψ, Vφ)
Notes on chapter 5: For more on multiparticle quantum mechanics see
Reed and Simon (1979), Reed and Simon (1978), or Gustafson and Sigal (2003).

6
Statistical mechanics
6.1 Mixed states
Until now the states of a physical system have been described by unit vectors (actu-
ally rays) in a Hilbert space. These are states which are prepared so that we have
as much knowledge about them as possible. They are also called pure states. But
we also want to consider states whose preparation is incomplete. We only know the
probability that it is in any of various pure states. These are known as mixed states.
The mathematical deﬁnition is that a mixed state is a positive trace class operator Q
on the Hilbert space H with Tr(Q) = 1. The operator Q is called a density operator.
If {φn} is an orthonormal basis of eigenvectors for Q with eigenvalues μn ≥0, then
Qψ = ∞
n=1 μnφn(φn, ψ) which we write as
Q =
∞

n=1
μnφn(φn, ·)
(6.1)
The condition Tr(Q) = 1 means that

n
μn = 1
(6.2)
If a property of a physical measurement is described by a projection operator P,
then the probability of a positive result in state Q is taken to be
Tr(PQ) =
∞

n=1
μn(φn, Pφn)
(6.3)
Taking P = Pψ = ψ(ψ, ·), the projection onto ψ, the probability of ﬁnding the
system in the pure state ψ is
Tr(PψQ) =
∞

n=1
μn|(ψ, φn)|2
(6.4)
In particular μn is the probability of ﬁnding the system in the state φn.
Observable quantities are still described by self-adjoint operators A. If E(B) are
the spectral projections for A, then the probability that a measurement of A in the
state Q gives a value in B is
78

79
6.2 Equilibrium states
t
Tr(E(B)Q) =
∞

n=1
μn(φn, E(B)φn)
(6.5)
The expected value of repeated measurements of A in the state Q is
Tr(AQ) =
∞

n=1
μn(φn, Aφn)
(6.6)
if it exists. It exists if A is bounded, and it may or may not exist for unbounded
operators.
Note that we can identify pure states with mixed states of rank one via the map
ψ →Qψ = ψ(ψ, ·). This is deﬁned on rays: ψ and eiθψ give the same mixed state.
The probabilities Tr(PQψ) = (ψ, Pψ) are the same as before.
6.2 Equilibrium states
We describe some mixed states appropriate for describing large numbers of parti-
cles called equilibrium states. In this section we give a general discussion of both
the classical and quantum versions, but in subsequent sections we only consider the
quantum version in detail. In the classical versions the states are probability mea-
sures on phase space – the measure of a set is the probability of ﬁnding the system in
that set. In the quantum versions the states are density operators as described above –
we assign a probability to ﬁnding the system in various pure states.
For this discussion we suppose that we are in a bounded open region  ⊂R3 or
possibly the torus  = R3/L Z3 of width L. The important point is that  have ﬁnite
volume.
6.2.1 Microcanonical ensemble
The ﬁrst case is a system which is isolated from its surroundings and has a ﬁxed
energy E and a ﬁxed number of particles N. With no further knowledge of the system
an appropriate state is one which assigns equal weight to all states with this energy
and particle number. States which enter into such a description with ﬁxed E and N
are said to constitute a microcanonical ensemble. One can create such states in either
a classical or a quantum version. However we do not go into details.
6.2.2 Canonical ensemble
In the second case the system still has a ﬁxed number of particles N, but now the
energy E is not ﬁxed due to interactions with its surroundings. The surroundings

80
Statistical mechanics
t
are taken to be a heat bath at a temperature T. The temperature is a measure of the
average kinetic energy of particles in the bath. We do not attempt a mathematical
description of the heat bath or of its interaction with the system, but we do make
a hypothesis about the probabilities for states of the system in this circumstance.
The fundamental hypothesis is that the probability of ﬁnding the system in a state
with energy E is proportional to e−E/kT. Here k = 1.38×10−16 ergs/◦K is a constant
which sets the temperature scale and is known as Boltzmann’s constant. We usually
let β = 1/kT and write e−E/kT = e−βE. With probabilities assigned in this fashion
the states are called Gibbs states and are said to constitute a canonical ensemble. We
now spell out the construction in more detail.
In the classical case the phase space is P = N ×R3N and we have a Hamiltonian
HN(x, p) on this space. We deﬁne a probability measure on P by
dμβ(x, p) =
1
Z(β)e−βHN(x,p)dxdp
(6.7)
The normalizing factor is known as the partition function and it is given by
Z(β) =

e−βHN(x,p)dxdp
(6.8)
This integral is required to converge. A classical observable A is a function on phase
space, hence a random variable, and its expected value is
< A >β=

A(x, p)dμβ(x, p) =

A(x, p)e−βHN(x,p)dxdp

e−βHN(x,p)dxdp
(6.9)
In the quantum case there is a single particle space H, for example H = L2(),
and an N-particle space H±
N = ±(H ⊗· · · ⊗H). The Hamiltonian HN is required
to be a self-adjoint operator on this space. The basic hypothesis is that the state at
inverse temperature β has the density operator
Qβ = Z(β)−1e−βHN
(6.10)
where the partition function is now
Z(β) = Tr(e−βHN)
(6.11)
For this to make sense we need e−βHN to be trace class. An observable A is a self-
adjoint operator on HN and the expected value is
< A >β ≡Tr(AQβ) = Tr(Ae−βHN)
Tr(e−βHN)
(6.12)
The quantum state is invariant under time evolution in the following sense. If At =
eiHNtAe−iHNt is the time evolution of A in the Heisenberg picture, then
< At >β=< A >β
(6.13)
This follows from the cyclicity of the trace. We say that the state is a stationary state.

81
6.2 Equilibrium states
t
6.2.3 Grand canonical ensemble
In the third case neither E or N is ﬁxed. Instead the system is supposed to be in con-
tact with a heat bath and a particle bath. The basic hypothesis is that the probability
of ﬁnding the system in a state with energy E and particle number N is proportional
to exp(−β(E −μN)). Here β is again the inverse temperature, and μ is a parameter
called the chemical potential. A particle has energy −μ just by its presence in the
system. States weighted in this fashion constitute a grand canonical ensemble.
In the classical case the phase space is the disjoint union of the n-particle phase
spaces  = ∪∞
n=0n. A measure μβ,μ is deﬁned on  by stipulating that its
restriction to n is
dμβ,μ | n = Z(β, μ)−1 exp(−β(H(x, p) −μn))dxdp
(6.14)
The partition function which gives the overall normalization factor is
Z(β, μ) =
∞

n=0

n
exp(−β(H(x, p) −μn))dxdp
(6.15)
One can also deﬁne expectations of classical observables.
In the quantum case the Hilbert space is taken to be the Fock space F±(H) =
⊕nH±
n and the Hamiltonian is H = ⊕nHn where Hn is the n-particle Hamiltonian.
The density operator has the form
Qβ,μ = Z(β, μ)−1e−β(H−μN)
(6.16)
where now N is the number operator. The partition function is
Z(β, μ) = Tr(e−β(H−μN))
(6.17)
An observable is a self-adjoint operator A on the Fock space and has the expectation
< A >β,μ≡Tr(AQβ,μ) = Tr(Ae−β(H−μN))
Tr(e−β(H−μN))
(6.18)
This is also a stationary state.
6.2.4 General problems
One set of problems is concerned with motivating the above discussion. A great deal
of effort has been expended over the years attempting to derive the various ensembles
from more basic hypotheses, and to study the relation between them. There are many
interesting developments here but it would take us too far aﬁeld to explore them. We
just take the ensembles as deﬁned as our starting point.

82
Statistical mechanics
t
Another class of problems is concerned with picking speciﬁc models or classes of
models and studying detailed properties of the states. We do this for a few simple
models working in the grand canonical ensemble. This will just give a taste of what
is a very large subject.
Let us ﬁrst mention some items of interest for the quantum grand canonical
ensemble. We deﬁne a free energy in terms of the partition function by
F(β, μ) = −β−1 log Z(β, μ)
(6.19)
It turns out this can be interpreted as the amount of energy available to do work. The
pressure is deﬁned as minus the free energy per unit volume and is given by1
p(β, μ) = −||−1F(β, μ) = β−1||−1 log Z(β, μ)
(6.20)
where || is the volume of . The expected number of particles is
< N >β,μ= Z(β, μ)−1Tr(N e−β(H−μN))
(6.21)
It can be computed from the partition function by
< N >β,μ= 1
β
∂
∂μ log Z(β, μ)
(6.22)
The density is the expected number of particles divided by the volume
ρ(β, μ) = ||−1 < N >β,μ
(6.23)
Recall that the number operator can be expressed as N =

a∗(x)a(x)dx. We
could also consider the number of particles in a region B ⊂R3 deﬁned by
NB
=

B a∗(x)a(x)dx or the kinetic energy in B which would be deﬁned by

B a∗(x)(−/2m)a(x)dx. Thus if we knew the expectations < a∗(x)a(y) >β,μ, we
could compute expectations of many interesting observables. More generally we
would like to compute correlation functions deﬁned by
< a∗(x1) · · · a∗(xn)a(y1) · · · a(yn) >β,μ
(6.24)
These may or may not be well-deﬁned. The situation is improved if we replace a(x)
by the more regular a(f) =

f(x)a(x)dx, f ∈S(R3). Then the correlation functions
are
< a∗(f1) · · · a∗(fn)a(g1) · · · a(gn) >β,μ
(6.25)
If it exists, this gives (6.24) a meaning as a distribution. Indeed it is a multilinear
functional on S(R3) and hence by the kernel theorem determines a distribution in
S′(R3n). (See appendix C for the basic facts about distributions.)
1 The deﬁnition says that pressure has dimensions of energy/volume. But since energy has dimensions of
force × distance, pressure has dimensions of force/area as expected.

83
6.3 Free boson gas
t
All these quantities depend on the volume , and generally the volume must be
ﬁnite in order that they be well-deﬁned. At ﬁrst this seems to correlate well with
actual physical situations where the volume really is ﬁnite. However volumes are
typically very large on an atomic scale, and so it is a good idealization to treat the
system as inﬁnite. If it can be done mathematically, it is worthwhile because then
one avoids uninteresting boundary effects. Furthermore collective phenomena like
phase transitions generally have more dramatic manifestations at inﬁnite volume. In
short it is not enough to study the quantities p(β, μ), ρ(β, μ) and correlation func-
tions in a ﬁnite volume , one should also take the limit  →R3, known as the
thermodynamic limit.
6.3 Free boson gas
We consider the case of free bosons in detail. We take  to be the torus  =
R3/L Z3. Making this choice is the same as taking  to be the cube [−L/2, L/2]3
and imposing periodic boundary conditions. This might not seem like a good start-
ing point for an actual gas. Perhaps a better model would be the cube with some
local boundary conditions. We make the choice anyway with the idea that the inﬁnite
volume limit should be independent of the boundary conditions.
For a single particle the Hilbert space is H = L2() and specializing to m = 1/2
the Hamiltonian is − as for the R3 construction. The trigonometric polynomials
are functions in L2() of the form
φk(x) = eikx
L3/2
k ∈2π
L Z3
(6.26)
These form a complete orthonormal set in L2(). This statement is equivalent to the
L2- convergence of Fourier series. Furthermore the φk are eigenfunctions of −
−φk = |k|2φk
(6.27)
Thus − is naturally a positive self-adjoint operator by problem 1.13. As in the R3
construction, the k are called momenta.
Now consider n such particles. The Hilbert space for bosons is now H+
n
=
+(H ⊗· · · ⊗H) and the Hamiltonian is Hn = dn(−). States φk1 ⊗· · · ⊗φkn
form a basis for H ⊗· · · ⊗H and so states
k1,...,kn = +(φk1 ⊗· · · ⊗φkn)
(6.28)
span H+
n . Note that k1,...,kn depends only on the collection {k1, . . . , kn}, not on the
ordering. Different collections give orthogonal states. They are eigenfunctions of Hn
and satisfy

84
Statistical mechanics
t
Hnk1,...,kn =
 n

i=1
|ki|2

k1,...,kn
(6.29)
We reformulate as follows. First identify H+
n as a subspace of the Fock space
F+(H) and write k1,...,kn as a constant times a∗(φk1) . . . a∗(φkn)0 (see (5.60)).
Then label these basis vectors by the number of times a particular momentum occurs.
Thus let {nk} be a collection of nonnegative integers indexed by k ∈(2π/L)Z3 such
that 
k nk = n. For each such collection deﬁne
({nk}) =

k
1
√nk!
 
k
a∗(φk)nk0
(6.30)
With this choice of normalization the ({nk}) form an orthonormal basis for H+
n
(problem 6.1). We have
Hn({nk}) =

k
nk|k|2

({nk})
(6.31)
Finally consider the full Fock space. We drop the restriction 
k nk = n and
instead take inﬁnite sequences {nk} with the condition that nk = 0 except for a ﬁnite
number of k. Then the ({nk}) form an orthonormal basis for the entire Fock space.
Furthermore ({nk}) is an eigenvector for the full Hamiltonian H with eigenvalue

k nk|k|2. Note also that ({nk}) is an eigenvector for N with eigenvalue 
k nk.
Now we are ready to calculate the partition function in the grand canonical
ensemble. We have for μ < 0
Z(β, μ) = Tr(e−β(H−μN))
=

{nk}
(({nk}), e−β(H−μN)({nk}))
=

{nk}
exp

−β

k
nk(|k|2 −μ)

=

{nk}

k
e−βnk(|k|2−μ)
=

k
∞

n=0
e−βn(|k|2−μ)
=

k
1
1 −e−β(|k|2−μ)
(6.32)
The inﬁnite product converges since

k

1
1 −e−β(|k|2−μ) −1

=

k
e−β(|k|2−μ)
1 −e−β(|k|2−μ) < ∞
(6.33)

85
6.3 Free boson gas
t
From the partition function we compute the pressure (6.20) and the density (6.23)
and ﬁnd
p(β, μ) = ||−1β−1 
k
log

1
1 −e−β(|k|2−μ)

ρ(β, μ) = ||−1 
k
e−β(|k|2−μ)
1 −e−β(|k|2−μ)
(6.34)
These expressions also have a nice inﬁnite volume limit. As L →∞the sum over
k ∈(2π/L)Z3 becomes an integral over k ∈R3 and we ﬁnd
p(β, μ) = (2π)−3β−1

log

1
1 −e−β(|k|2−μ)

dk
ρ(β, μ) = (2π)−3

e−β(|k|2−μ)
1 −e−β(|k|2−μ) dk
(6.35)
Returning to ﬁnite volume, the correlation functions can also be computed. We
illustrate with the two-point function.
Lemma 6.1
Let f, g ∈C∞() and let h = −. Then for μ < 0
< a∗(f)a(g) >β,μ=

g,

e−β(h−μ)
1 −e−β(h−μ)

f

(6.36)
Remark
Explicitly
< a∗(f)a(g) >β,μ=

k
¯gk

e−β(|k|2−μ)
1 −e−β(|k|2−μ)

fk
(6.37)
where fk = (φk, f) are the Fourier coefﬁcients for f. The expression (6.36) also holds
in the inﬁnite volume limit, but now deﬁned with the Fourier transform instead of
Fourier series.
Proof
Since e−β(H−μN) = (e−β(h−μ)), we can compute (cf. problem 5.6)
e−β(H−μN)a∗(f) = a∗(e−β(h−μ)f)e−β(H−μN)
(6.38)
Using the cyclicity of the trace and then the commutation relations for a, a∗, (5.61)
yields
Tr(a∗(f)a(g)e−β(H−μN)) = Tr(a(g)e−β(H−μN)a∗(f))
= Tr(a(g)a∗(e−β(h−μ)f)e−β(H−μN))
= Tr(a∗(e−β(h−μ)f)a(g)e−β(H−μN)) + Z(β, μ)(g, e−β(h−μ)f)
(6.39)

86
Statistical mechanics
t
Dividing by Z(β, μ) this can be written
< a∗((1 −e−β(h−μ))f)a(g) >β,μ= (g, e−β(h−μ)f)
(6.40)
Now replacing f by (1 −e−β(h−μ))−1f gives the result.
Problem 6.1
Check that ∥({nk})∥= 1.
Problem 6.2
Prove that pressure and density in (6.35) really are the inﬁnite
volume limits of the ﬁnite volume expressions (6.34) as claimed.
Problem6.3
Take  = [0, L]N. On H = L2() deﬁne − as a self-adjoint opera-
tor by taking eigenfunctions with Dirichlet boundary conditions, that is vanishing
on the boundary. Compute the grand canonical partition function in this case.
Problem 6.4
Compute the n-point correlation functions (6.25) for the free boson
gas by establishing ﬁrst that
< a∗(f1) · · · a∗(fn)a(g1) · · · a(gn) >β,μ
=
n

j=1
< a∗(f1)a(gj) >β,μ< a∗(f2) · · · a∗(fn)a(g1) · · · 
a(gj) · · · a(gn) >β,μ
(6.41)
where the factor a(gj) is omitted in the last expectation. Then show that
< a∗(f1) · · · a∗(fn)a(g1) · · · a(gn) >β,μ=

π
n

i=1
< a∗(fi)a(gπ(i)) >β,μ
(6.42)
where the sum is over permutations π of (1, . . . , n).
6.4 Free fermion gas
We consider noninteracting fermions. For simplicity we neglect spin and take the
one particle space to be H = L2(). The treatment is the same as for bosons except
that the full Hilbert space is now the anti-symmetric Fock space F−(H). We still
have the basis vectors ({nk}) given by (6.30) but now the Pauli exclusion principle
means that each nk can only take the values zero and one.
The partition function in the grand canonical ensemble is now computed just as
in (6.32)

87
6.4 Free fermion gas
t
Z(β, μ) = Tr(e−β(H−μN))
=

{nk}

k
e−βnk(|k|2−μ)
=

k

n=0,1
e−βn(|k|2−μ)
=

k

1 + e−β(|k|2−μ)
(6.43)
This converges for all β > 0 and all μ ∈R since

k
e−β(|k|2−μ) < ∞
(6.44)
For the pressure and the density we compute
p(β, μ) = ||−1β−1 
k
log(1 + e−β(|k|2−μ))
ρ(β, μ) = ||−1 
k
e−β(|k|2−μ)
1 + e−β(|k|2−μ)
(6.45)
One can also compute the two-point function as for bosons and we ﬁnd with h = −
< a∗(f)a(g) >β,μ=

g,

e−β(h−μ)
1 + e−β(h−μ)

f

(6.46)
Note that the only difference from bosons is the plus sign in the denominator.
Next we investigate the zero temperature limit. Let Nk be the number of particles
with momentum k deﬁned by Nk({nk}) = nk({nk}). Then Nk = a∗(φk)a(φk) and
from (6.46) the expectation is
< Nk >β,μ=
e−β(|k|2−μ)
1 + e−β(|k|2−μ)
(6.47)
For μ > 0 we have the zero temperature limit
lim
β→∞< Nk >β,μ=
⎧
⎨
⎩
1
|k|2 < μ
0
|k|2 > μ
(6.48)
This is saying that at zero temperature all states with energy |k|2 < μ are occupied
while states with energy |k|2 > μ are empty. This corresponds to the lowest energy
state and is referred to as the Fermi sea.
The situation for bosons is quite different as there is no exclusion principle. A
more extensive analysis shows that at ﬁxed density below a certain critical temper-
ature a substantial fraction of particles occupy the lowest energy state k = 0, and
at zero temperature they all occupy it. This phenomenon is known as Bose–Einstein
condensation.

88
Statistical mechanics
t
6.5 Interacting bosons
Now we consider the statistical mechanics of interacting bosons on the three-
dimensional torus  = R3/L Z3; there is a similar treatment for fermions. The
n-particle Hilbert space is now L2
+(n), the symmetric subspace of L2(n). The
n-particle Hamiltonian is
Hn = H0,n + Vn =
n

i=1
−i
2m
+

1≤i<j≤n
v(xi −xj)
(6.49)
where the interparticle potential v is taken to be in L2(). Then one can show that
Hn is self-adjoint on the domain of H0. (See example 5.2 and problem 5.1 for the R3
result.)
We assume that the following stability condition is satisﬁed: there is a constant B
such that for all n and all points xi ∈

1≤i<j≤n
v(xi −xj) ≥−Bn
(6.50)
This is a fairly restrictive condition. It is trivially satisﬁed if v ≥0 and obviously
false if v(0) < 0 (take all {xi} coincident and n large). Physically it means that
particles have a hard core repelling other particles.
Problem 6.5
v is said to be of positive type if the Fourier series has nonnegative
coefﬁcients. Show that the stability condition is satisﬁed if v is of positive type
For a stable interaction we have2
0 ≤H0,n −(B + μ)n ≤Hn −μn
(6.51)
where the ﬁrst inequality holds if μ < −B. Under the same assumption the full
Hamiltonian on the Fock space satisﬁes
0 ≤H0 −(B + μ)N ≤H −μN
(6.52)
Our modest goal is to prove the existence of the grand canonical ensemble on the
torus, that is we want to show that exp(−β(H −μN)) is trace class. First we have:
Lemma 6.2
For μ < −B the Hamiltonian H −μN has pure point spectrum with
ﬁnite multiplicity and no accumulation points.
Proof
Let S = H−μN+1 and T = H0−(μ+B)N+1 so 1 ≤T ≤S. We have seen in
our treatment of the free boson gas that T has point spectrum with ﬁnite multiplicity
and no accumulation points. Hence T−1/2 is compact (see problem 1.17).
2 T ≤S means D(S) ⊂D(T) and (ψ, Tψ) ≤(ψ, Sψ) for ψ ∈D(S).

89
6.5 Interacting bosons
t
Now D(T) = D(S) is contained in both D(T1/2) and D(S1/2) by the spectral
theorem. The inequality T ≤S implies that for ψ ∈D(S)
∥T1/2ψ∥≤∥S1/2ψ∥
(6.53)
But D(S) is a core for D(S1/2) again by the spectral theorem. It follows that D(S1/2) ⊂
D(T1/2) and that the inequality (6.53) holds for ψ ∈D(S1/2). (We made a similar
argument in lemma 5.3.) Replacing ψ by S−1/2χ for any χ we see that T1/2S−1/2 is
a bounded operator with ∥T1/2S−1/2∥≤1.
Now write
S−1/2 = T−1/2(T1/2S−1/2)
(6.54)
This exhibits S−1/2 as the product of a compact operator and a bounded opera-
tor. Hence it is compact and has point spectrum with ﬁnite multiplicity and no
accumulation points except zero. The result for H−μN = (S−1/2)−2−1 follows.
We also need:
Theorem6.1
(min–max theorem) Let T be a self-adjoint operator on a Hilbert space
with pure point spectrum
λ0 ≤λ1 ≤λ2 ≤. . .
(6.55)
repeated by multiplicity. Then
λn =
sup
ξ1,...,ξn−1

inf
ψ∈[ξ1,...,ξn−1]⊥,∥ψ∥=1(ψ, Tψ)

(6.56)
where the inﬁmum is over ψ ∈D(T).
The theorem is useful because it gives control over the eigenvalues without know-
ing the eigenvectors. We do not give the full proof.3 But observe that for n = 0
it says
λ0 =
inf
∥ψ∥=1(ψ, Tψ)
(6.57)
This is true since if φn are a basis of eigenvectors with Tφn = λnφn, then for any
ψ ∈D(T) with ∥ψ∥= 1
(ψ, Tψ) =

n
λn|(ψ, φn)|2 ≥

n
λ0|(ψ, φn)|2 = λ0∥ψ∥2 = λ0
(6.58)
On the other hand the lower bound λ0 is actually attained at ψ = φ0.
Corollary6.1
Let T, S satisfy the hypotheses of the theorem and suppose T ≤S. Then
the eigenvalues λn(T), λn(S) satisfy λn(T) ≤λn(S).
3 For the proof see Reed and Simon (1978: 76).

90
Statistical mechanics
t
Proof
We have
inf
ψ∈[ξ1,...,ξn−1]⊥,∥ψ∥=1(ψ, Tψ) ≤
inf
ψ∈[ξ1,...,ξn−1]⊥,∥ψ∥=1(ψ, Sψ)
(6.59)
Now take the supremum over ξ1, . . . , ξn−1.
Now we have the main result:
Theorem6.2
If the two particle potential is stable with constant B and if the chemical
potential satisﬁes μ < −B, then the grand canonical partition function Z(β, μ) =
Tr(exp(−β(H −μN))) exists.
Proof
Let λn(H −μN) be the eigenvalues of H −μN repeated by multiplicity. By
(6.52) and the corollary we have
λn(H −μN) ≥λn(H0 −(μ + B)N)
(6.60)
Then
Tr

e−β(H−μN)
=

n
e−βλn(H−μN)
≤

n
e−βλn(H0−(μ+B)N)
= Tr

e−β(H0−(μ+B)N)
(6.61)
The last expression is ﬁnite by our results on the free boson gas.
6.6 Further developments
Suppose we are working in the grand canonical ensemble as deﬁned in (6.18). Let
K = H −μN be the Hamiltonian, let A, B be observables, and let
αt(B) = eiKtBe−iKt
(6.62)
be the time evolution of B. Then we have
< A αt(B) >β,μ= Tr(AeiKtBe−(β+it)K)
Tr(e−βK)
(6.63)
Assuming that K ≥0 the function eiKt is the boundary value on the real axis of an
analytic function from the upper half plane to the bounded operators on Fock space.
Then (6.63) is the boundary value on the real axis of a function analytic in the strip
0 < Im t < β. But by the cyclicity of the trace we also have
Tr(AeiKtBe−(β+it)K) = Tr(Be−(β+it)KAeiKt)
(6.64)

91
6.6 Further developments
t
Taking the boundary value at t = iβ we obtain the identity
< A αt(B) >β,μ |t=iβ =< BA >β,μ
(6.65)
This is known as the KMS condition.4 It turns out that the KMS condition completely
characterizes the expectation < · · · >β,μ, and so gives an alternate deﬁnition of
equilibrium states. An advantage is that it also makes sense in inﬁnite volume.
Let us discuss further the general problem of inﬁnite volume. We would like to
have a full quantum theory in inﬁnite volume, rather than just certain special limits
of ﬁnite volume quantities. This turns out to be possible and we sketch the idea. One
must modify the basic quantum structure founded on a Hilbert space. Instead the
basic object is taken to be a C∗algebra5 A whose self-adjoint elements correspond
to observables. For example it might be the C∗algebra generated by creation and
annihilation operators on Fock space. A state is now speciﬁed by giving the expec-
tations of all the elements of A. More precisely a state ω is a continuous positive6
linear functional on A with norm one. Finite volume Gibbs states are states in this
sense and so are inﬁnite volume limits of Gibbs states. Time evolution is given by a
family αt of automorphisms of A such that α0 = id and αtαs = αt+s. For example
αt could be generated by a Hamiltonian as in (6.62). Finally ω is deﬁned to be an
equilibrium state at inverse temperature β if the β-KMS condition is satisﬁed, that
is if for A, B ∈A the function t →ω(A αt(B)) is the boundary value of a function
analytic in 0 < Im t < β such that
ω(A αt(B))|t=iβ = ω(BA)
(6.66)
These ideas can be carried a great deal further with beneﬁcial results.
Notes on chapter 6: For the basic structure of statistical mechanics see Ruelle
(1969). For quantum statistical mechanics as we have presented it see Bratteli and
Robinson (1981); for the algebraic approach consult Bratteli and Robinson (1981)
and Haag (1992); for stability bounds with realistic potentials see Lieb and Seiringer
(2010).
For physics books on statistical mechanics, try Landau and Lifschitz (1969) or
Huang (2009).
There are important topics in statistical mechanics which have not been discussed
at all. These include phase transitions, critical phenomena, and nonequilibrium
statistical mechanics.
4 KMS stands for Kubo–Martin–Schwinger.
5 A C∗algebra is a Banach ∗-algebra with ∥A∗A∥= ∥A∥2. Think of a closed subalgebra of the algebra
of bounded operators on a Hilbert space.
6 Positive means ω(A∗A) ≥0 for all A ∈A.


Part II
Relativistic


7
Relativity
7.1 Principles of relativity
Einstein arrived at the principles of relativity by thinking about the relationship
between measurements made by observers in uniform motion relative to each other.
We depart from this historical path and instead start with Maxwell’s equations (0.3).
In the absence of charges and currents (ρ = 0, j = 0) one can deduce from
Maxwell’s equations that any component u of the electric or magnetic ﬁeld obeys
the wave equation

−1
c2
∂2
∂t2 + 

u = 0
(7.1)
Disturbances propagate with the velocity c which is the speed of light. Hence light
is explained as a wave in the electric and magnetic ﬁelds.
Suppose we think of space and time as a single entity called spacetime and mod-
eled by R4. A point is labeled x = (x0, x1, x2, x3) with x0 = ct a scaled time with
units of distance. Then the wave equation can be written

μν
ημν ∂
∂xμ
∂
∂xν u = 0
(7.2)
where ημν is the diagonal matrix with entries (−1, 1, 1, 1). We take these coefﬁcients
in the wave equation above as a clue to the structure of spacetime. The coefﬁcients
can be interpreted as coming from a metric on R4 given by
η =

μν
ημνdxμdxν = −(dx0)2 + (dx1)2 + (dx2)2 + (dx3)2
(7.3)
This is not a positive deﬁnite metric, but a Lorentzian metric, that is a metric which
has signature −+++. The basic postulate of special relativity is that spacetime is to
be modeled by the pair (R4, η). The idea is that ﬁeld equations are to be built out of
this metric as above. Furthermore free particles should respect the metric in the sense
that their trajectories should be geodesics for the metric. All the structure of special
relativity follows from these assumptions, some of which we develop as we go on.
The scope of special relativity is limited as the name suggests. It is only supposed
to be valid in situations where there is no gravitational ﬁeld, or more precisely where
95

96
Relativity
t
the effect of gravitational ﬁelds is negligible. The effect of the gravitational ﬁeld
is to distort the metric and indeed possibly even distort the topology of spacetime.
The basic postulate of general relativity is that spacetime is to be modeled by a
Lorentzian manifold (M, g) consisting of a four-dimensional manifold M and a
Lorentzian metric g which in local coordinates takes the form
g =

μν
gμνdxμdxν
(7.4)
Field equations are to be constructed out of the metric. For example the wave
equation would have the form

μν
| det g|−1/2 ∂
∂xμ

| det g|1/2gμν ∂u
∂xν

= 0
(7.5)
where {gμν} is the inverse matrix to {gμν}. Again free particles should travel on
geodesics. The metric itself is determined by the distribution of energy and matter
by an equation known as Einstein’s equation.
A manifold is anyway the best model for spacetime with or without gravity. Man-
ifolds are deﬁned to treat all coordinate systems equally and this is matched by the
phenomenon that nature has no distinguished coordinate systems. In constructing
the basic equations to describe nature one should take care that the construction is
not tied to any particular coordinate system. This naturalness condition is sometimes
known as the principle of general covariance. Einstein’s theory of gravity outlined
above respects it. Quantum mechanics has a more difﬁcult time with it, primarily
because it has a more rigid notion of time.
In the next three chapters we concentrate on combining quantum mechanics with
special relativity and ignore gravitational effects. It is appropriate in any case because
on microscopic scales gravity is much weaker than electromagnetic or nuclear forces
and thus is usually negligible for elementary particle physics.
7.2 Minkowski space
7.2.1 Deﬁnitions
We start by developing some general features of (R4, η) called Minkowksi space. The
tangent space to any point R4 can be taken to be R4 itself. The metric determines
an indeﬁnite inner product on the tangent space by deﬁning for tangent vectors
v = (v0, . . . , v3) and w = (w0, . . . , w3)
v · w =

μν
ημνvμwν = −v0w0 + v1w1 + v2w2 + v3w3
(7.6)

97
7.2 Minkowski space
t
We employ the summation convention that repeated indices are summed over, so this
is written v · w = ημνvμwν. We also write v = (v0, v) and w = (w0, w) and then
v · w = −v0w0 + v · w
(7.7)
where the second dot product v · w is the usual scalar product in R3.
There are also linear functions on tangent vectors called cotangent vectors. These
are also identiﬁed with R4 and written θ = (θ0, . . . , θ3). The cotangent vector θ
sends tangent vector v to θμvμ. The metric enables us to identify tangent vectors and
cotangent vectors by vμ = ημνvν or θμ = ημνθν. Then for tangent vectors v, w we
have v · w = ημνvμwν = vμwμ.
Tangent vectors are deﬁned to be spacelike, lightlike, or timelike according to
whether v · v = −(v0)2 + v · v is positive, zero, or negative. The timelike vec-
tors form a double cone in R4. The component with v0 > 0 is called future directed
and the component with v0 < 0 is called past directed.
We consider parametrized curves x : [a, b] →R4. If the tangent vector dx/dt
is always spacelike, then the curve is spacelike and we deﬁne the length of the
curve to be
L(x) =
 b
a
#
dx
dτ · dx
dτ dτ
(7.8)
If the tangent vector dx/dτ is always timelike, then the curve is timelike and we
deﬁne the elapsed proper time to be
T(x) =
 b
a
#
−dx
dτ · dx
dτ dτ
(7.9)
Such curves are past or future directed according to whether dx/dτ is past or
future directed. Future directed timelike curves are possible trajectories of massive
particles. The curve is called the worldline of the particle.
Finally if the tangent vector dx/dτ is always lightlike, then the curve is lightlike.
Future directed lightlike curves are possible trajectories of light rays and massless
particles.
7.2.2 Free particles
In the absence of external forces massive particles travel on the timelike geodesics
of the metric. These geodesics are the forward directed timelike curves between
two given points (x, y) in spacetime which maximize the proper time among all
such curves. To ﬁnd the geodesics note that the proper time does not depend on
the parametrization of the curve. Thus it sufﬁces to consider curves for which
−dx/dτ · dx/dτ is a positive constant. Such a curve is parametrized proportional
to proper time.

98
Relativity
t
Theorem 7.1
Let x : [a, b] →R4 be a future directed timelike geodesic that is
parametrized proportional to proper time with x(a) = x, x(b) = y. Then d2x/dτ 2 = 0
and hence x is a straight line. The elapsed proper time is
$
−(x −y) · (x −y)
(7.10)
Proof
Let η : [a, b] →R4 be any smooth function with η(a) = η(b) = 0. Then for
s sufﬁciently small
xs(τ) = x(τ) + sη(τ)
(7.11)
is also a forward timelike curve from x to y. Then we can compute the proper time
T(xs). This has a maximum at s = 0 and so d/ds[T(xs)]s=0 = 0. We compute
d
dsT(xs) = 1
2
 b
a

−dxs
dτ · dxs
dτ
−1/2 d
ds

−dxs
dτ · dxs
dτ

dτ
(7.12)
At s = 0 this becomes
0 = −
 b
a
dη
dτ · dx
dτ dτ =
 b
a
η · d2x
dτ 2 dτ
(7.13)
Since η is arbitrary, it follows that dx2/dτ 2 = 0. Then the solution is
x(τ) = x +
τ −a
b −a

(y −x)
(7.14)
For this curve, T(x) has the value (7.10).
We still have some freedom in the parametrization of our geodesics. We use this
to make a choice of the constant −dx/dτ · dx/dτ. For particles of mass m > 0 a
convenient choice is to set
−dx
dτ · dx
dτ = m2c2
(7.15)
which we now assume.
We write the dynamical equation d2x/dτ 2 = 0 as the ﬁrst-order system
dxμ
dτ = pμ
dpμ
dτ = 0
(7.16)
where pμ = ημνpν. This is a Hamiltonian system with variables xμ, pμ and Hamil-
tonian p · p/2 = ημνpμpν/2 = ημνpμpν/2, not now the energy. The constant
p = (p0, p1, p2, p3) = (p0, p) is called the four-momentum. For a forward directed
solution of mass m we have
−p · p = m2c2
p0 > 0
(7.17)
Once we restrict to solutions of mass m we can reduce the number of variables by
eliminating x0 and p0 = −p0. By (7.17) we have p0 = ω(p) where for p ∈R3
ω(p) =
%
|p|2 + m2c2
(7.18)

99
7.2 Minkowski space
t
The x0 equation is then dx0/dτ = ω(p), which we use to replace the parameter τ by
the time coordinate x0. We have then dx/dx0 = (dx/dτ)(dτ/dx0) = p/ω(p). Finally
with x0 = ct the remaining equations become
dx
dt = c p
ω(p)
dp
dt = 0
(7.19)
This is a Hamiltonian system with Hamiltonian c ω(p). It is interpreted as describing
particle of mass m, position x, momentum p, and energy
E = c ω(p) =
%
|p|2c2 + m2c4
(7.20)
Note that the four-momentum (p0, p) = (E/c, p) is an energy–momentum vector.
Next we make the connection with the corresponding non-relativistic concepts.
For |p|/mc small we have the expansion
E = mc2 + |p|2
2m + . . .
(7.21)
Thus for small momenta the energy is the same as the non-relativistic energy
|p|2/2m, but shifted by the constant amount mc2. The latter is the energy of the
particle at rest and comes only from the mass.
Also note that according to (7.19) the velocity v = dx/dt of a particle of
momentum p is
v = pc2
E
=
pc
$
|p|2 + m2c2
(7.22)
Note that |v|/c < 1, that is velocities of massive particles are always less than the
speed of light. Eliminating p in favor of v we ﬁnd instead of (7.20), (7.22)
E =
mc2
$
1 −|v|2/c2
p =
mv
$
1 −|v|2/c2
(7.23)
These also reduce to the non-relativistic deﬁnitions of energy and momentum for
|v|/c small.
Finally consider free particles of mass m
=
0 modeled by solutions of
d2x/dτ 2 = 0 satisfying −dx/dτ · dx/dτ = 0. This still can be written as the Hamil-
tonian system (7.16) but now restricted to solutions with p · p = 0. Energy and
momentum are related by E = |p|c. The velocity is still v = pc2/E, but now |v| = c
so massless particles travel at the speed of light. There is no non-relativistic approx-
imation for these particles. An example of a massless particle is a photon which is a
particle of light. These are quantum mechanical entities, but for some purposes can
be treated as classical particles as we have done here.
The value of c depends on which system of units we are using. Hereafter we
choose units so that c = 1 and the parameter c disappears from our equations.

100
Relativity
t
7.2.3 Forces
There is no fully consistent theory of interacting classical relativistic particles. Hence
in this framework we do not attempt to use symmetries of a system to identify con-
served quantities such as total momentum, as we did in the non-relativistic case
(section 2.4). Nevertheless one can assign a total four-momentum to a system of rel-
ativistic particles by adding the individual four-momenta. It is an empirical fact that
this total four-momentum is conserved in collisions of elementary particles, even
when particles are created or destroyed. This feature emerges naturally in quantum
ﬁeld theory.
What we can do now is consider relativistic particles acted on by external forces.
Suppose a massive charged particle is acted on by external electric and magnetic
ﬁelds E, B. We combine these ﬁelds into a single entity, the electromagnetic ﬁeld. It
is a matrix of functions Fμν : R4 →R given by
{Fμν} =
⎛
⎜⎜⎜⎝
0
−E1
−E2
−E3
E1
0
B3
−B2
E2
−B3
0
B1
E3
B2
−B1
0
⎞
⎟⎟⎟⎠
(7.24)
Note that this is anti-symmetric Fμν = −Fνμ.
The electromagnetic force on a particle with world line xμ(τ) and charge e is
given by the Lorentz force eFμ
ν dxν/dτ where Fμ
ν = ημρFρν. With a parametrization
satisfying −dx/dτ · dx/dτ = m2, the equation of motion of the particle is
d2xμ
dτ 2 = eFμ
ν
dxν
dτ
(7.25)
Note that the value of dx/dτ · dx/dτ is preserved by the time evolution, since if x(τ)
is a solution, then
d
dτ
 dx
dτ · dx
dτ

= 2 d2x
dτ 2 · dx
dτ = 2eFμν
dxμ
dτ
dxν
dτ = 0
(7.26)
by the anti-symmetry of Fμν. The equation (7.25) is the relativistic generalization of
the Lorentz equation (0.2).1
Now suppose that Fμν is derived from a potential Aμ by2
Fμν = ∂μAν −∂νAμ
(7.27)
1 If we reparametrize by σ = mτ, then dx/dσ · dx/dσ = −1 so the worldline is parametrized by proper
time. In this case the equation takes the form
m d2x
dσ2 = eFμ
ν dxν
dσ
which shows the mass dependence.
2 This relation is naturally expressed in terms of differential forms. If we consider the two-form F =
Fμνdxμdxν and the one-form A = Aμdxμ, then (7.27) says that F = dA, that is F is the exterior
derivative of A.

101
7.2 Minkowski space
t
where ∂μ = ∂/∂xμ. If A = (, A), then this says
E = ∂A
∂x0 −∇
B = ∇× A
(7.28)
so we can identify  as the electrostatic potential and A as the magnetic potential.
In addition a time-dependent A induces an electric ﬁeld ∂A/∂x0.
Line integrals of A over curves C are naturally deﬁned by

C
Aμdxμ =
 b
a
Aμ(x(τ))dxμ
dτ dτ
(7.29)
whenever x : [a, b] →Rd is a parametrization of C. The integral is independent of
parametrization. This makes it natural to consider integrals such as
I(x) =
 b
a

m
#
−dx
dτ · dx
dτ −eAμ(x(τ))dxμ
dτ

dτ
(7.30)
Then the next problem gives an indication of why the Lorentz equation is natural.
Problem 7.1
Let x : [a, b] →R4 be forward timelike parametrized so that
−dx/dτ · dx/dτ = m2. Show that if x maximizes the integral I(x) among all
forward timelike curves between the same endpoints, then x satisﬁes the Lorentz
equation (7.25) with Fμν given by (7.27).
7.2.4 Lorentz transformations
Now consider the isometries (symmetries) of the spacetime (R4, η). These are maps
y = κ(x) which preserve the metric or equivalently preserve proper time intervals
and distances. Thus they satisfy
(κ(x1) −κ(x2)) · (κ(x1) −κ(x2)) = (x1 −x2) · (x1 −x2)
(7.31)
for all x1, x2 ∈R4. Translations y = x + a are isometries and linear transforma-
tions y = x, also written yμ = μ
νxν, are isometries if x · x = x · x. This is
equivalent to
Tη = η
(7.32)
also written ημνμ
μ′ν
ν′ = ημ′,ν′. These are called Lorentz transformations. They
form a group known as the Lorentz group.
It turns out these are all the isometries, that is the general isometry has the form
{a, }x = x + a
(7.33)
The group of all such transformations is called the Poincaré group denoted P. The
group law is

102
Relativity
t
{a, }{a′, ′} = {a′ + a, ′}
(7.34)
It is the semi-direct product of the Lorentz group and the translation group.
The Lorentz group is denoted L or O(1, 3). It inherits a topology as a subset of R16
and is in fact a Lie group. It follows from the deﬁning relation (7.32) that elements of
the group satisfy det  = ±1 and this condition divides the group into disjoint sets
denoted L±. An example of  ∈L−is a reﬂection through a hyperplane. The set
L+ contains the identity and is a subgroup. Furthermore (7.32) implies that (0
0)2 =
1 + 3
k=1(k
0)2 so L+ is divided into disjoint sets with ±0
0 > 1 and denoted
respectively L↑
+ and L↓
+. Elements of L↓
+ involve time reversal. The set L↑
+ contains
the identity and is a subgroup known as the proper Lorentz group. Correspondingly
there is a proper Poincaré group P↑
+.
An example of a proper Lorentz transformation is a rotation of the form
R =

1
0
0
R

(7.35)
where R is a rotation on R3. Another proper Lorentz transformation is a boost along
the ﬁrst axis of the form
β =
⎛
⎜⎜⎜⎝
cosh β
sinh β
0
0
sinh β
cosh β
0
0
0
0
1
0
0
0
0
1
⎞
⎟⎟⎟⎠
(7.36)
There are also boosts in any spacelike direction. It turns out that any element of
 ∈L↑
+ can be written in the form
 = R1βR2
(7.37)
for some R1, R2, β. Since each of these special transformations can be continuously
connected to the identity, it follows that any element of L↑
+ can be continuously
connected to the identity and hence the group is connected.
Physical laws are differential equations built from the metric η and will have the
proper Poincaré transformations as a symmetry. This means that the proper Poincaré
group acts on the space of solutions. More precisely this is true when there are no
forces external to the system we are describing. For a simple example suppose x(τ) =
pτ +b is a solution of dx2/dτ 2 = 0 describing a free particle of energy–momentum p
with mass m so −p·p = m2 and p0 > 0. If {a, } is a proper Poincaré transformation,
then the transformed world line x′(τ) ≡x(τ) + a = (p)τ + b + a is also a
solution, now with energy–momentum p′ = p and still satisfying −p′ · p′ = m2
and (p′)0 > 0.
The physical interpretation of Poincaré transformations can be made in either an
active sense or a passive sense. In the active sense they carry physical conﬁgurations
to different physical conﬁgurations. In the passive sense they describe the same

103
7.3 Classical free ﬁelds
t
physical system in new coordinates. For boosts the new coordinates are associated
with an observer in relative motion with respect to the original coordinates, hence
the term “relativity.”
Problem 7.2
Show that if Tη = η, then the same holds for −1, T.
Problem 7.3
Show that if qμ = μ
νpν, then qμ = pν(−1)ν
μ.
Problem 7.4
Show that the boost β takes a particle at rest to a particle with
velocity v = (tanh β, 0, 0).
7.3 Classical free ﬁelds
We now begin a discussion of various ﬁelds on spacetime. Mathematically these
are functions on spacetime. Physically they model some sort of local disturbance,
often not directly observable. Although we introduce them in a classical context the
complete physical interpretation involves quantum mechanics.
7.3.1 Scalar ﬁelds
A scalar ﬁeld φ is a function φ : R4 →R, which is a solution of the Klein–Gordon
equation
(−□+ m2)φ = 0
(7.38)
Here □= ∂· ∂is the Laplacian for the Minkowski metric, called the d’Alembertian.
Written out with ∂μ = ∂/∂xμ it is
□= ημν∂μ∂ν = −∂2
0 + ∂2
1 + ∂2
2 + ∂2
3
(7.39)
The parameter m is called the mass. This is related to the deﬁnition of mass for
particles (think pμ ↔−i∂μ) but we do not make the connection precise until we
quantize.
There is a basic existence and uniqueness theorem which says that given smooth
functions f, g on R3 there is a unique smooth function u(x) = u(x0, x) on R4 such
that (−□+ m2)u = 0 with intial values u(0, x) = f(x) and (∂0u)(0, x) = g(x). In
addition inﬂuence propagates with unit speed. We explore some variations of these
facts in the following.

104
Relativity
t
We also note Green’s identity for the d’Alembertian, which says that for suitable
functions u, v

[a,b]×R3 u(−□+ m2)v −v(−□+ m2)u
=

x0=b
u∂0v −v∂0u −

x0=a
u∂0v −v∂0u
(7.40)
This is proved by integration by parts.
Problem 7.5
Show that if φ satisﬁes the Klein–Gordon equation, the Poincaré
transformed function φa,(x) ≡φ(−1(x −a)) is also a solution.
7.3.2 Charged scalar ﬁelds
The next simplest possibility is a charged scalar ﬁeld φ of mass m, which is a function
from R4 to R2. We write φ = (φ1, φ2) and require each component to solve the
Klein–Gordon equation: (−□+ m2)φi = 0.
By Green’s identity if φ = (φ1, φ2) is a solution, then
Q =

x0=t
φ1∂0φ2 −φ2∂0φ1
(7.41)
is independent of t and is called a charge. There is an associated charge-current
density j = (j0, j) = (j0, j1, j2, j3) deﬁned by
jμ(φ) = φ1∂μφ2 −φ2∂μφ1
(7.42)
This satisﬁes the conservation law ∂μjμ = ∂0j0 + ∇· j = 0 and the conservation of
Q =

x0=t j0 can also be understood from
dQ
dt =

x0=t
∂0j0 = −

x0=t
∇· j = 0
(7.43)
Multiples of (j0, j) will be identiﬁed with the actual electric charge density and
current density when the ﬁeld φ is coupled to the electromagnetic ﬁeld.
It will also be useful to write the ﬁeld as a single complex valued function φ =
(φ1 + iφ2)/
√
2. In this case the current is given by
jμ = −i( ¯φ∂μφ −φ∂μ ¯φ)
(7.44)
These considerations generalize to ﬁelds φ : R4 →Rn with each component
satisfying (−□+ m2)φα = 0. In this case there are n(n −1)/2 conserved charges
Qαβ =

x0=t
φα∂0φβ −φβ∂0φα
(7.45)

105
7.3 Classical free ﬁelds
t
7.3.3 Dirac ﬁelds
Next consider ﬁelds which solve the Dirac equation. The equation is based on a
ﬁrst-order linear differential operator whose square is the d’Alembertian.
The starting point is the Clifford algebra for Minkowski space. The algebra is gen-
erated by complex matrices γ μ with μ = 0, 1, 2, 3 satisfying the anti-commutation
relations3
{γ μ, γ ν} = 2ημνI
(7.46)
For a ∈R4 we deﬁne
γ · a = γ μaμ = γ 0a0 + γ 1a1 + γ 2a2 + γ 3a3
(7.47)
These satisfy
{γ · a, γ · b} = 2ημνaμbν = 2a · b
(7.48)
In particular (γ · a)2 = a · a and thus γ · a provides a linear square root of the
Minkowski inner product. Note also that (γ 0)2 = −I and (γ k)2 = I for k = 1, 2, 3.
There are various possibilities for the gamma matrices. One possible choice is the
4 × 4 matrices
γ 0 = −i

0
I
I
0

γ k = −i

0
σk
−σk
0

(7.49)
where σk are the Pauli matrices (4.63). These satisfy (γ 0)∗= −γ 0 and (γ k)∗= γ k
and we usually assume we have a representation which has this property.
If ˜γ μ is another choice of 4 × 4 gamma matrices, then there is a nonsingular matrix
M such that4
˜γ μ = Mγ μM−1
(7.50)
The operator γ · ∂= γ μ∂μ has the desired property
(γ · ∂)2 = ∂· ∂= □
(7.51)
The Dirac equation is now deﬁned by
(γ · ∂+ m)ψ = 0
(7.52)
for some function ψ : R4 →C4 called a spinor ﬁeld. Applying the operator
(−γ · ∂+ m) we see that any solution of the Dirac equation also satisﬁes the
Klein–Gordon equation (−□+ m2)ψ = 0. Hence m is again a mass.
3 The anticommutator is {A, B} = [A, B]+ = AB + BA.
4 See for example Miller (1972: 363).

106
Relativity
t
Next let β = iγ 0 and deﬁne an indeﬁnite inner product on C4 by u, v →u†βv.
Here if u is a column vector, then u† is the conjugate transpose row vector so
u†βv =

ab
¯uaβabvb
(7.53)
The γ matrices are skew-adjoint with respect to this inner product
(γ μu)†βv = −u†β(γ μv)
(7.54)
Green’s identity for the Dirac operator says

[a,b]×R3 χ†β(γ · ∂+ m)ψ −((γ · ∂+ m)χ)†βψ
=

x0=b
χ†β(γ 0ψ) −

x0=a
χ†β(γ 0ψ)
(7.55)
Then if ψ is a solution of the Dirac equation, the quantity
Q =

x0=t
ψ†β[iγ 0]ψ =

x0=t
|ψ|2
(7.56)
is positive deﬁnite and independent of t. A multiple will be interpreted as the electric
charge. The associated conserved current
jμ = ψ†β[iγ μ]ψ
(7.57)
satisﬁes Q =

x0=t j0 and ∂μjμ = 0.
Problem 7.6
1. Show that Tr(γ μγ ν) = ημνTr(I).
2. Show that the γ μ are linearly independent.
7.3.4 The electromagnetic ﬁeld
We have already noted that the electromagnetic ﬁeld can be described by a matrix
of functions Fμν. If the total charge density ρ and the total current density j are
combined into a spacetime vector ﬁeld j = (j0, j1, j2, j3) = (ρ, j), then Maxwell’s
equations can be written in the form5
∂σFμν + ∂μFνσ + ∂νFσμ = 0
∂νFμν = jμ
(7.58)
In this form the necessity of the charge conservation law ∂μjμ = 0 is transparent.
5 In terms of the two-form F = Fμνdxμdxν, the one-form j = jμdxμ, the exterior derivative d, and its
adjoint δ these say dF = 0 and δF = j.

107
7.4 Interacting classical ﬁelds
t
In a simply connected region the ﬁrst equation says that
Fμν = ∂μAν −∂νAμ
(7.59)
for some functions Aμ.6 We identify A = (A0, A) with the electric potential and
the magnetic potential as in section 7.2.3. The potential can be assumed to satisfy
∂μAμ = 0 (see problem 7.7). Then Maxwell’s equations are replaced by the pair of
equations
□Aμ = −jμ
∂μAμ = 0
(7.60)
It is just the wave equation with a source and a constraint. This is the equation we
will eventually quantize (for j = 0).
Problem 7.7
In R4 let Fμν = ∂μAν −∂νAμ.
1. Show that if A′
μ = Aμ + ∂μχ for any smooth function χ, then Fμν = ∂μA′
ν −
∂νA′
μ.
2. Show that one can choose χ so that ∂μA′
μ = 0.
Problem 7.8
Show that if Aμ solves (7.60) with j = 0, then so does A′
μ(x) =
(−1)ν
μAν(−1(x −a)).
7.4 Interacting classical ﬁelds
7.4.1 The gauge principle
The equations (7.58) or (7.60) show how the charge-current density acts as the source
of the electromagnetic ﬁeld. But the electromagnetic ﬁeld also affects charges and
in particular charged ﬁelds. This occurs in a geometrically natural way as we now
explain.
Let us start with the charged scalar ﬁeld whose conﬁguration is a function u :
R4 →Rn. Just as the vector space R4 is not the best model for spacetime, yielding
that honor to a manifold, so the vector space Rn is not the best model for charge
space. We continue to treat it as an inner product space, but now do not single out
any special oriented orthonormal basis. Instead we consider all possible oriented
orthonormal bases denoted {eα}, and instead of a ﬁxed vector in Rn we consider its
expression v = 
α vαeα in each of these bases. The bases are related to each other
by an element of the rotation group SO(n) in Rn and hence so are the components
6 Every closed form dF = 0 is exact F = dA.

108
Relativity
t
relative to each choice of basis. Thus what we want is an assignment to each oriented
orthonormal basis {eα} a vector v ∈Rn such that if
eβ =

α
Rαβe′
α
(7.61)
for some R ∈SO(n), then
v′
α =

β
Rαβvβ
(7.62)
For then we have

β
vβeβ =

α
v′
αe′
α
(7.63)
Next we want to allow the possibility of choosing a different basis at each point
in spacetime. Thus we consider functions from x ∈R4 to orthonormal bases {eα(x)}.
Two such functions are related by a function R : R4 →SO(n) such that
eβ(x) =

α
Rαβ(x)e′
α(x)
(7.64)
The function R(x) is known as a (local) gauge transformation and is assumed to be
smooth. Now if our charged scalar ﬁeld is expressed as 
β uβ(x)eβ(x) and also as

α u′
α(x)e′
α(x), then
u′
α(x) =

β
Rαβ(x)uβ(x)
(7.65)
This is the structure of a trivial SO(n) vector bundle. If we allow R4 to be a man-
ifold and allow different choices of bases in Rn in different open subsets of the
manifold, we would have the general deﬁnition of an SO(n) vector bundle. In the
terminology of vector bundles the functions u(x) are sections of the vector bundle
in a particular trivialization and the gauge transformations R(x) are the transition
functions for a change of trivialization.
Let us specialize now to the case n = 2 in which case φ : R4 →R2 is the charged
scalar ﬁeld and the gauge group is SO(2). We regard R2 as the complex numbers C.
Then SO(2) is identiﬁed with the group U(1), the complex numbers of modulus one,
under the identiﬁcation

cos θ
−sin θ
sin θ
cos θ

↔eiθ
(7.66)
Thus we consider families of functions φ : R4 →C assigned to oriented orthonor-
mal bases in C (that is choices of the real axis) such that if two bases are related by
the gauge transformation eiθ(x), then the functions are related by
φ′(x) = eiθ(x)φ(x)
(7.67)

109
7.4 Interacting classical ﬁelds
t
A family of functions with this transformation law is called a section of a complex
line bundle.
Next we want to write a differential equation for a section of a complex line bun-
dle. The equation will be expressed in terms of a particular function representing the
section, but should be natural in the sense that it should not matter which function
we take.
To build such an equation we need the notion of a connection. A connection is
given by a family of functions Aμ each associated with choice of basis. Under a
change of basis given by eiqλ(x) the connection changes (by deﬁnition) by
A′
μ(x) = Aμ(x) + ∂μλ(x)
(7.68)
Here we have inserted a constant q in the transformation eiqλ(x) to allow a different
weighting for ﬁelds and connections.
The connection determines a covariant derivative ∂μ −iqAμ. If φ′ = eiqλφ, then
(∂μ −iqA′
μ)φ′ = (∂μ −iqAμ −iq∂μλ)eiqλφ
= eiqλ(∂μ −iqAμ)φ
(7.69)
Thus the functions (∂μ −iqAμ)φ give a new section of the complex line bundle.
Now we can deﬁne a differential equation for the charged ﬁeld φ : R4 →C by
treating it as a section of a complex line bundle. Take the Klein–Gordon equation
and replace the derivatives by covariant derivatives. Then we have
(−(∂−iqA) · (∂−iqA) + m2)φ = 0
(7.70)
The interpretation is that the connection Aμ is the electromagnetic potential, that the
equation is describing the time evolution of the charged ﬁeld φ in the presence of A,
and that q is the charge measuring the strength of the coupling.
Recall that potentials A, A′ related by a gauge transformation (7.68) have the same
ﬁeld strength Fμν = ∂μAν −∂νAμ. Thus it is possible to regard the different ver-
sions of (7.70) as describing the same physical situation. The ﬁeld strength Fμν
also has a natural interpretation in the vector bundle language. Namely it is the
curvature of the connection deﬁned as the commutator of the covariant derivative.
We have
−iqFμν = [(∂μ −iqAμ), (∂ν −iqAν)]
(7.71)
This all generalizes to SO(n) and indeed any Lie group G. Suppose G is repre-
sented by n × n real or complex matrices. A section of a G-bundle is a family of
functions φ : R4 →Rn or Cn connected by gauge transformations g : R4 →G by
φ′(x) = g(x)φ(x)
(7.72)

110
Relativity
t
Let G be Lie algebra of G; for example if G = SO(n), then G is the skew-symmetric
n × n matrices. A connection or gauge potential is given by a family of functions
Aμ : R4 →G which are related by7
A′
μ(x) = g(x)Aμ(x)g−1(x) −(∂μg)(x)g−1(x)
(7.73)
The covariant derivative ∂μ + Aμ again maps sections to sections in the sense that
(∂μ + A′
μ)φ′ = g(∂μ + Aμ)φ
(7.74)
One can form a dynamical equation by
(−(∂+ A) · (∂+ A) + m2)φ = 0
(7.75)
This describes a ﬁeld with a generalized charge. The curvature is now
Fμν = [(∂μ + Aμ), (∂ν + Aν)]
∂μAν −∂νAμ + [Aμ, Aν]
(7.76)
and it is interpreted as the ﬁeld strength of the potential. Equivalent connections A, A′
do not now give the same ﬁeld strength. We have instead F′
μν = gFμνg−1.
7.4.2 Systems
Now we can put together some of our equations to form complete systems in which
each ﬁeld has a dynamics and inﬂuences the other ﬁelds.
To start, consider a system consisting of a charged Dirac ﬁeld ψ : R4 →C4 inter-
acting with an electromagnetic ﬁeld A : R4 →R. In this case the charge-current
density jμ = qψ†β[iγ μ]ψ is the source for the electromagnetic ﬁeld in Maxwell’s
equations (7.58). The inﬂuence of A on ψ is given by replacing the ordinary
derivative by the covariant derivative in the Dirac equation. Thus we have
(γ · (∂−iqA) + m)ψ = 0
∂νFμν = qψ†β[iγ μ]ψ
(7.77)
Note that the same charge q is used in both equations. Because of this the system of
equations can be derived from a simple variational principle. Deﬁne an action by
S(ψ, A) =
 t1
t0

R3

ψ†β(γ · (∂−iqA) + m)ψ + 1
4FμνFμν

dx
(7.78)
The least action principle says that dynamical ﬁelds must minimize the action and
these turn out to be exactly the ﬁelds satisfying (7.77).
7 A′ is again in the Lie algebra G. To see that vμ(∂μg)(x)g−1(x) is in G for any x, v ∈R4 let x(t) be a
curve in R4 with x(0) = x, x′(0) = v. Then γ (t) = g(x(t))g−1(x) is a curve in G with γ (0) = I, γ ′(0) =
vμ(∂μg)(x)g−1(x) and hence the latter is in G.

111
7.5 Fundamental solutions
t
Next consider a charged scalar ﬁeld φ : R4 →C interacting with an electro-
magnetic potential A. The inﬂuence of A on the φ ﬁeld is given by taking covariant
derivatives in the Klein–Gordon equation as in (7.75). We complete the system by
taking jμ = −iq( ¯φ∂μφ −φ∂μ ¯φ) as the source for the electromagnetic ﬁeld. Thus we
have the system:
(−(∂−iqA) · (∂−iqA) + m2)φ = 0
∂νFμν = −iq( ¯φ∂μφ −φ∂μ ¯φ)
(7.79)
Usually one also adds a term −2q2Aμ|φ|2 to the right side of the second equation.
Then the equations can be derived from a least action principle with action
S(φ, A) =
 t1
t0

R3
1
2(∂−iqA)φ · (∂−iqA)φ + m2|φ|2 + 1
4FμνFμν

dx (7.80)
The equations were constructed in accordance with the gauge principle for gauge
group SO(2) = U(1). For a general gauge group G we would replace φ or ψ by a
vector valued function and A by a Lie algebra valued function. The actions (7.80) or
(7.78) still hold with Fμν now given by (7.76) and 1
4FμνFμν replaced by the gauge
invariant 1
4tr(FμνFμν). Variation of the action leads to a system of equations similar
to (7.77) or (7.79), but even more nonlinear. These are known as nonabelian gauge
theories. With the gauge group SU(3)×SU(2)×U(1) a quantized version provides a
model for the strong, weak, and electromagnetic interactions of elementary particles,
known as the standard model.
These are difﬁcult systems of nonlinear equations. A simpler case is a single scalar
ﬁeld which interacts with itself according to the equation
(−□+ m2)φ + 4λφ3 = 0
(7.81)
with λ > 0. This can be derived from the action
S(φ) =
 t1
t0

R3
1
2(∂φ · ∂φ + m2φ2) + λφ4

(7.82)
Problem 7.9
Consider smooth functions φ(t, x) such that for t0 ≤t ≤t1 the
function φ(t, ·) has compact support and so φ(t0, x) = f0(x), φ(t1, x) = f1(x) Show
that if φ(t, x) minimizes the action (7.82) among all such functions, then it satisﬁes
the equation (7.81).
7.5 Fundamental solutions
In this last section we depart from general considerations to treat a speciﬁc problem.
We deﬁne and study certain fundamental solutions of the Klein–Gordon equation.

112
Relativity
t
For any x ∈R4 deﬁne
J±(x) = {y ∈R4 : (x −y) · (x −y) ≤0, ±(y0 −x0) ≥0}
(7.83)
This is the causal future or past of the point x, that is the point which can be reached
by a future or past directed timelike curve. For any subset A ⊂R4 we deﬁne
J±A = ∪x∈AJ±x
(7.84)
Theorem 7.2
Then there exist linear operators E± : C∞
0 (R4) →C∞(R4) such that
(−□+ m2)(E±f) = f
supp (E±f) ⊂J±(supp f)
(7.85)
Proof
We ﬁrst deﬁne a distribution E±
0 by
E±
0 (x) = (2π)−4

±×R3
eip·x
p · p + m2 dp
(7.86)
where ± is the contour R ± iα with α > 0, and we use the Lorentz inner product
in the exponential. The Fourier transform is in the sense of distributions so for f ∈
C∞
0 (R4)
< E±
0 , f >= (2π)−2

±×R3
ˆf(−p)
p · p + m2 dp
(7.87)
where the Fourier transform is with the Lorentz inner product
ˆf(p) = (2π)−2

R4 e−ip·xf(x)dx
(7.88)
Note that p · p + m2 = −(p0)2 + |p|2 + m2 has zeros at p0 = ±ω(p), which we avoid
by the choice of the contour ±. The function ˆf is an entire function which is rapidly
decreasing in real directions.. Thus < E±
0 , f > is well-deﬁned and independent of
the choice of α.
The operator is deﬁned by the convolution E±f
= E±
0 ∗f, which means
(E±f)(x) =< E±
0 , f(x −·) >. Replacing f by f(x −·) means replacing ˆf(p) by
e−ip·xˆf(−p) and so we obtain
(E±f)(x) = (2π)−2

±×R3
eip·xˆf(p)
p · p + m2 dp
(7.89)
It satisﬁes (−□+ m2)(E±f)(x) = f(x) since after taking the derivatives we get
(2π)−2 
±×R3 eip·xˆf(p)dp in which we can take α = 0 to identify f(x).
The statement about supports is equivalent to supp E±
0 ⊂J±(0). We consider E+
0
and ﬁrst show that supp E+
0 is contained in the set x0 ≥0. Thus we want to show
that if suppf ⊂{x0 < 0}, then < E+
0 , f >= 0. If x0 < 0, then | exp(−ip · x)| =
exp(−Im p0x0) is bounded in Im p0 < 0 and so ˆf(p) is bounded in Im p0 < 0.
Then ˆf(−p) is bounded in Im p0 > 0, and in the formula (7.87) we can complete the
contour + in the upper half plane and get zero.

113
7.5 Fundamental solutions
t
Finally we use the fact that E+
0 is Lorentz invariant, E+
0 (x) = E+
0 (x). It follows
that if E+
0 (x) vanishes on a neighborhood of a point x, then it vanishes on a neigh-
borhood of any point x in the orbit of x. Hence we can enlarge the region where it
vanishes from {x0 < 0} to {x0 < 0}. The latter is the complement of J+(0), hence
the support of E+
0 is in J+(0). The argument for E−
0 (x) is similar.
From these fundamental solutions we construct the propagator8
E = E+ −E−
(7.90)
If f ∈C∞
0 (R4), then u = Ef is a C∞solution of the Klein–Gordon equation with the
property that for any t the function u(t, ·) has compact support. Such a solution will
be called a regular solution.
It will be useful to have an alternate expression for (Ef)(x). It is given by the
expression (7.89) but now integrated over (+−−)×R3. The p0 contour (+−−)
can be shrunk down to circles around p0 = ±ω(p) and evaluated. After a change of
variables we have
(Ef)(x) =
i
2π

R3 ei(−ω(p)x0+p·x)ˆf(ω(p), p) dp
2ω(p)
−
i
2π

R3 ei(ω(p)x0−p·x)ˆf(−ω(p), −p) dp
2ω(p)
(7.91)
Problem7.10
Show that every regular solution of the Klein–Gordon equation has
the form u = Ef for some f ∈C∞
0 (R4)
Notes on chapter 7: Special relativity is best understood as general relativity with
a special metric. References are Misner et al. (1973) and Sachs and Wu (1977).
For gauge theories see Drechsler and Mayer (1977) or Frankel (2004).
It is also common to use the metric η′ = −η instead of η. Then the Klein–Gordon
equation (−□η + m2)φ = 0 becomes (□η′ + m2)φ = 0. The Dirac matrices γ μ
are replaced by (γ ′)μ = iγ μ. The Dirac equation (γ μ∂μ + m)u = 0 becomes
(−i(γ ′)μ∂μ + m)u = 0.
8 Not to be confused with the Feynman propagator.

8
Scalar particles and ﬁelds
In this chapter we develop a quantum mechanical description of both scalar particles
and scalar ﬁelds, in each case without interaction. In fact there is a deep connection
between particles and ﬁelds. Mathematically it is reﬂected in the fact that ﬁeld oper-
ators naturally act on a multiparticle Hilbert space. Physically it is the fact that ﬁelds
and particles are complementary manifestations of the same underlying reality. The
prime example is electromagnetism which exists as electric and magnetic ﬁelds or
as massless spin 1 particles called photons. This is taken up in the next chapter, after
we treat the simpler case of scalars.
As we develop this and other relativistic ﬁeld theories we will encounter states
with arbitrarily negative energies. If present, these would lead to serious instabilities
when our system is coupled to other systems. Our system could serve as an inﬁnite
energy source by dropping to lower and lower levels. This is completely unphysical
so one of our tasks is to ﬁnd a consistent way to discard or reinterpret the negative
energy states.
8.1 Scalar particles
8.1.1 Canonical quantization
We consider a single free relativistic particle of mass m in the spacetime (R4, η)
and start with a canonical quantization procedure. Recall from section 7.2.2 that in
reduced form the phase space is R3 × R3 and the Hamiltonian for a particle of mass
m is H(x, p) = ω(p) =
$
|p|2 + m2. Correspondingly we take the Hilbert space
L2(R3, dx) and the representation of the CCR
ˆxi = [xi]
ˆpi = −i∂/∂xi
(8.1)
just as in (3.11). The quantum Hamiltonian is then
H =
%
|ˆp|2 + m2 =
$
− + m2
(8.2)
114

115
8.1 Scalar particles
t
This is deﬁned in terms of the Fourier transform by H = F−1[ω(p)]F and time
evolution is
e−iHt = F−1[e−iω(p)t]F
(8.3)
Alternatively we can work directly in momentum space. Then the Hilbert space is
L2(R3, dp), the position and momentum operators are
ˆxi = i∂/∂pi
ˆpi = [pi]
(8.4)
The Hamiltonian is
H =
%
|ˆp|2 + m2 = [ω(p)]
(8.5)
and time evolution is e−iHt = [e−iω(p)t]. The two constructions are of course unitarily
equivalent via the Fourier transform.
Problem 8.1
(Non-relativistic limit) If we reinstate the speed of light c as a
parameter, then ω(p) is replaced by ωc(p) =
$
|p|2c2 + m2c4. Show that for
ψ ∈L2(R3, dp)
L2 −lim
c→∞eimc2te−iωc(p)tψ(p) = e−i|p|2t/2mψ(p)
(8.6)
Thus when adjusted by the phase factor eimc2t the relativistic dynamics converges
to the non-relativistic dynamics.
8.1.2 Quantization from Klein-Gordon
Another way to approach quantization is to start with the Klein–Gordon equation
(−□+ m2)φ = 0 and try to interpret solutions as wave functions. To ﬁnd solutions
take the partial Fourier transform
˜φ(t, p) = (2π)−3/2

e−ip·xφ(t, x)dx
(8.7)
This satisﬁes
 ∂2
∂t2 + |p|2 + m2

˜φ = 0
(8.8)
and has solutions
˜φ(t, p) = e−iω(p)tφ+(p) + eiω(p)tφ−(p)
(8.9)
for any φ±(p). Hence a general complex valued solution of the Klein–Gordon
equation is
φ(t, x) = (2π)−3/2

eip·x 
e−iω(p)tφ+(p) + eiω(p)tφ−(p)

dp
(8.10)

116
Scalar particles and ﬁelds
t
with φ±(p) determined by a pair of initial conditions. Real solutions have φ−(p) =
φ+(−p).
For the quantum interpretation we specialize to positive energy solutions which
have φ−(p) = 0. Then the solution is determined by a single complex valued
initial condition. The solution (8.9) with initial condition ψ(p) ∈L2(R3, dp) is
ψ(t, p) = e−iω(p)tψ(p) which agrees with our momentum space quantization. The
solution (8.10) with initial condition ψ(x) ∈L2(R3, dx) is given by
ψ(t, x) = (2π)−3/2

eip·xe−iω(p)t ˜ψ(p)dp
(8.11)
which agrees with our conﬁguration space quantization (8.3).
Now consider the effect of spacetime translations by a = (a0, a) ∈R4 and rota-
tions R ∈SO(3). The transformation {a, R} on R4 forms a subgroup of the proper
Poincaré group; we exclude boosts for the time being. Deﬁne a representation of this
subgroup on L2(R3, dp) by
(u0(a, R)ψ)(p) = ei(ω(p)a0−p·a)ψ(R−1p)
(8.12)
These operators are unitary since the Lebesgue measure is invariant under rotations
and one checks that u0(a, R)u0(a′, R′) = u0(a + Ra′, RR′).
On L2(R3, dx) we deﬁne a representation
ˆu0(a, R) = F−1 u0(a, R) F
(8.13)
Then ˆu0(a, R) implements the action of these transformations on our wave functions.
If ψ(t, x) is a complete wave function given by (8.11), then

ˆu0(a, R)ψ(t, ·)

(x) = ψ(t −a0, R−1(x −a))
(8.14)
Note that the representation of the rotation group corresponds to spin zero.
8.1.3 Covariant quantization
There is a third way to arrive at the quantization of a single relativistic particle.
This begins with the idea that associated with any isolated system there should be a
unitary representation of the proper Poincaré group describing the effect of Poincaré
transformations. Since time translation is included the representation contains the
complete dynamics of the system. Elementary particles are supposed to correspond
to irreducible representations. These are labeled by two parameters interpreted as
mass and spin. Here we want to ﬁnd the irreducible representation for particle of
mass m and spin zero.
Working in momentum space R4 note that the mass shell
V+
m = {p = (p0, p1, p2, p3) ∈R4 : p · p = −m2, p0 > 0}
(8.15)

117
8.1 Scalar particles
t
is invariant under the proper Lorentz group L↑
+. (In fact V+
m is the orbit of the point
(m, 0, 0, 0).) Then we can deﬁne a representation of the proper Poincaré group P↑
+ on
functions on V+
m by
(u(a, )ψ)(p) = e−ip·aψ(−1p)
(8.16)
where p · a = −p0a0 + p · a. One checks that
u(a, )u(a′, ′) = u(a + a′, ′)
(8.17)
There is an essentially unique measure on V+
m which is invariant under the Lorentz
group which we denote μm. Then u(a, ) is a unitary representation of the proper
Poincaré group on L2(V+
m , μm) and it turns out to be irreducible.
We can be more speciﬁc about the measure μm. First note that the map
φ(p) = (ω(p), p)
(8.18)
from R3 to V+
m provides a global set of coordinates for V+
m . For measurable B ⊂R3
we deﬁne
μm(φ(B)) =

B
dp
2ω(p)
(8.19)
Then ψ →ψ ◦φ is a unitary map from L2(V+
m , μm) to L2(R3, dp/2ω(p)) and the
representation (8.16) becomes the representation on L2(R3, dp/2ω(p)) given by
(u(a, )ψ)(p) = e−iφ(p)·aψ(φ−1−1φ(p))
(8.20)
Problem 8.2
Check that the measure dp/2ω(p) on R3 is invariant under Lorentz
transformations p →φ−1−1φ(p). (Hint: Use the decomposition (7.37).)
Problem 8.3
Check that u(a, ) as deﬁned in (8.16) is a unitary representation of
the proper Poincaré group on L2(V+
m , μm).
8.1.4 Comparison
We now compare the different approaches. In the ﬁrst two the Hilbert space can be
taken as H0 = L2(R3, dp) the same as for non-relativistic problems. In this case there
are position operators ˆxi = i∂/∂pi and a representation u0(a, R) of spacetime transla-
tions and rotations. In the third approach the Hilbert space is H = L2(R3, dp/2ω(p))
and there is a representation of the proper Poincaré group u(a, ).
These two possibilities are equivalent via the unitary operator V : H0 →H
deﬁned by
(Vψ)(p) =
$
2ω(p)ψ(p)
(8.21)

118
Scalar particles and ﬁelds
t
This connects the representations since
V−1u(a, R) V = u0(a, R)
(8.22)
If we want a representation of the full Poincaré group on H0, we can extend the
representation on the subgroup by deﬁning
u0(a, ) ≡V−1u(a, ) V
(8.23)
If we want a position operator on H, we can take the Newton–Wigner operator
Xi = V ˆxi V−1
(8.24)
Note that if ψ ∈H0 is strictly localized (that is if F−1ψ has compact support), it is
not true in general that u0(0, )ψ is strictly localized. Strict localization of particles
is not a Lorentz invariant concept. We will do better with ﬁelds.
Problem 8.4
Find explicit expressions for Xi and u0(a, ).
8.1.5 Many particles
Now suppose we want to describe many free bosons of mass m and spin zero. The
Hilbert space would be the Fock space F+(H0) or F+(H). The time evolution would
be given by the one-parameter unitary group
e−iHt = ([e−iω(p)t])
(8.25)
where  is deﬁned in (5.48). The Hamiltonian is the generator
H = d([ω(p)]) =

ω(p)a∗(p)a(p)dp
(8.26)
Here the second expression is a bilinear form, a(p) is deﬁned as in (5.74) (now in
momentum space), and the identity can be veriﬁed as in lemma 5.5. There is also a
representation of the Poincaré group which on the relativistic Fock space F+(H) is
U(a, ) = (u(a, ))
(8.27)
8.2 Scalar ﬁelds
8.2.1 Hamiltonian formulation
In section 7.3.1 we introduced the classical scalar ﬁeld φ(t, x) on R4 satisfying the
Klein–Gordon equation

119
8.2 Scalar ﬁelds
t
(−□+ m2)φ = 0
(8.28)
This can also be written as a pair of ﬁrst-order equations for functions φ(x), π(x)
dφ
dt = π
dπ
dt = −(− + m2)φ
(8.29)
This is an inﬁnite-dimensional Hamiltonian system with the Hamiltonian
H(φ, π) = 1
2

R3(π2(x) + (∇φ(x))2 + m2φ2(x))dx
(8.30)
That is we have the functional derivatives ∂H/∂π(x) = π(x) and ∂H/∂φ(x) =
((− + m2)φ)(x). We are computing these derivatives formally, although they could
be given a rigorous meaning without too much trouble.
In terms of the pair  = (φ, π) the Hamiltonian can be written
H() = 1
2(, ˆH)
(8.31)
where the inner product is in (real) L2(R3) ⊕L2(R3) and where
ˆH =

(− + m2)
0
0
I

(8.32)
The equations become with ∇ = (∂/∂φ, ∂/∂π)
d
dt = J∇H = J ˆH
J =

0
I
−I
0

(8.33)
Let t be the solution of this equation with 0 =  ∈S(R3) × S(R3). Time
evolution preserves this space and t is linear in  so we can write
t = T(t)
(8.34)
where T(t) is a linear operator on S(R3) × S(R3). It satisﬁes T(t)T(s) = T(t + s) and
T(0) = I. An explicit expression for T(t) is given below.
Since we have a linear Hamiltonian system there is a symplectic form invariant
under time evolution, see the remarks at the end of section 2.3. It is given by
σ(1, 2) = (1, J2) = (φ1, π2) −(π1, φ2)
(8.35)
The invariance σ(1,t, 2,t) = σ(1, 2) follows from Green’s identity (7.40).
Alternatively note that J ˆH is skew-symplectic
σ(J ˆH1, 2) = ( ˆH1, 2) = (1, ˆH2) = −σ(1, J ˆH2)
(8.36)
Hence
d
dt σ(1,t, 2,t) = σ(J ˆH1,t, 2,t) + σ(1,t, J ˆH2,t) = 0
(8.37)
which gives the invariance.

120
Scalar particles and ﬁelds
t
Problem 8.5
With ˆω =
√
− + m2 show that
T(t) =

cos( ˆωt)
ˆω−1 sin( ˆωt)
−ˆω sin( ˆωt)
cos( ˆωt)

(8.38)
Problem 8.6
Show that T(t) commutes with J ˆH.
8.2.2 Canonical quantization
To quantize this Hamiltonian system by our canonical procedure we would begin
with a representation of the CCR which we interpret as
[φ(x), φ(y)] = [π(x), π(y)] = 0
[φ(x), π(y)] = iδ(x −y)
(8.39)
Then put these operators in the classical Hamiltonian (8.30) to get a quantum
Hamiltonian H. Then deﬁne ﬁeld operators in the Heisenberg picture at time t by
φ(t, x) = eiHtφ(x)e−iHt
π(t, x) = eiHtπ(x)e−iHt
(8.40)
However H constructed in this manner is rather ill-deﬁned.
For an alternate strategy recall that the operators φ(t, x), π(t, x) should satisfy
the classical dynamical equations (Ehrenfest’s theorem). Thus we look for operator
valued solutions of (8.29) which satisfy the CCR (8.39) at time zero.
Furthermore we treat the ﬁelds as distributions and consider averaged ﬁelds
φ(h) =

φ(x)h(x)dx
π(h) =

π(x)h(x)dx
(8.41)
where the test functions h are in the (real) Schwartz space S(R3). The interpretation
of the CCR is now that φ(h), π(h) should be symmetric operators on a dense invariant
domain in some Hilbert space satisfying
[φ(h), φ(g)] = [π(h), π(g)] = 0
[φ(h), π(g)] = i(h, g)
(8.42)
The dynamical equations are also interpreted in the sense of distributions.
We also consider the pair  = (φ, π). As a test function for the pair we take a pair
F = (f, g) of elements in S(R3). Then we form the particular combination
σ(, F) = φ(g) −π(f)
(8.43)
corresponding to the symplectic form. Then the CCR (8.42) imply
[σ(, F1), σ(, F2)] = iσ(F1, F2)
(8.44)

121
8.2 Scalar ﬁelds
t
Conversely if we have a representation σ(, F) of (8.44), then the operators φ(g) =
σ(, (0, g)) and π(f) = −σ(, (f, 0)) satisfy (8.42). The problem is now to ﬁnd a
distribution solution of d/dt = J ˆH with initial conditions satisfying (8.44).
If we have a representation of the CCR, then a formal solution is t = T(t)
and we take this as the deﬁnition of t interpreted in the sense of distributions. Thus
taking into account the invariance of the symplectic form on functions we deﬁne
σ(t, F) = σ(, T(−t)F)
(8.45)
Taking into account that it is skew-symplectic, we deﬁne J ˆH as a distribution by
σ(J ˆH, F) = −σ(, J ˆHF)
(8.46)
Then we have
d
dtσ(t, F) = d
dtσ(, T(−t)F) = −σ(, J ˆHT(−t)F)
= −σ(, T(−t)J ˆHF) = σ(J ˆHt, F)
(8.47)
which is the result we want.
There are many quantizations corresponding to different representations of the
CCR. In the ﬁnite-dimensional case it does not matter which we take since (as it
turns out) they are all unitarily equivalent and so physically equivalent. In the present
inﬁnite-dimensional case this is not true and different choices correspond to different
physics. Which should we choose?
We have two criteria. The ﬁrst is that we want a representation which differs only
locally from empty space. This is the appropriate choice to describe a ﬁnite number
of free elementary particles. For statistical mechanics or for interacting ﬁelds we
would want to make a different choice. The second criterion is that the energy (that
is the spectrum of the Hamiltonian) should be positive.
Our choice is based on a Fock space for a free relativistic particle, thus realiz-
ing the ﬁeld-particle duality. As in section 8.1.5 we take the symmetric Fock space
F+(H0) where H0 = L2(R3, dp). If a∗, a are the creation and annihilation operators
on this Fock space, we deﬁne on the domain D0 of ﬁnite particle vectors (see (5.59))
σ(, F) = i(a(K0F) −a∗(K0F))
(8.48)
where with ω(p) =
$
|p|2 + m2
K0(f, g) =
1
√
2

ω1/2˜f + iω−1/2˜g

(8.49)
The operator K0 : S(R3) × S(R3) →L2(R3, dp) is selected to satisfy two criteria.
The ﬁrst is that it is symplectic from (real) S(R3) × S(R3) with symplectic form σ
to (complex) L2(R3) with symplectic form which is twice the imaginary part of the
inner product, that is
2 Im(K0F1, K0F2) = σ(F1, F2)
(8.50)

122
Scalar particles and ﬁelds
t
This will give the CCR. Second it maps a real solution Ft = T(t)F of the Klein–
Gordon equation to a complex positive energy solution (in momentum space), that is
K0Ft = e−iωtK0F
(8.51)
This will give the positive energy. Both of these are easily checked.
Let us see that this works:
Theorem 8.1
The operators σ(, F) deﬁned by (8.48) (8.49) satisfy the CCR, and
time evolution is implemented by the free particle Hamiltonian H = d(ω) ≥0 in
the sense that
σ(t, F) = eiHtσ(, F)e−iHt
(8.52)
Proof
It gives a representation of the CCR since
[σ(, F1), σ(, F2)] = (K0F1, K0F2) −(K0F2, K0F1)
= 2iIm(K0F1, K0F2)
= iσ(F1, F2)
(8.53)
The time evolution is
σ(t, F) = σ(, T(−t)F)
= i(a(K0T(−t)F) −a∗(K0T(−t)F))
= i(a(eiωtK0F) −a∗(eiωtK0F))
= eiHtσ(, F)e−iHt
(8.54)
the last step by e−iHt = (e−iωt) and (5.69).
The ﬁeld φ(t, h) = σ(t, (0, h)) and the momentum π(t, h) = σ(t, (−h, 0)) are
given by
φ(t, h) = a

eiωt˜h
√
2ω

+ a∗

eiωt˜h
√
2ω

π(t, h) = −ia
$
ω/2eiωt˜h

+ ia∗$
ω/2eiωt˜h

(8.55)
The ﬁrst can also be written as the distribution identity
φ(t, x) = (2π)−3/2
 
a(p)e−i(ω(p)t−px) + a∗(p)ei(ω(p)t−px)
dp
√2ω(p)
(8.56)
That is φ(t, h) =

φ(t, x)h(x)dx has a meaning and the meaning is (8.55). But (8.56)
can also be understood pointwise as a bilinear form on DS × DS as in section 5.4.2.
Our time evolution is generated by H = d(ω). But is this the quantization of the
classical Hamiltonian (8.30)? Indeed it is, suitably interpreted. The claim is that with
φ(x) = φ(0, x) and π(x) = (dφ/dt)(0, x) given by (8.56)
1
2

: (π2(x) + (∇φ(x))2 + m2φ2(x)) : dx =

a∗(p)ω(p)a(p)dp
(8.57)

123
8.2 Scalar ﬁelds
t
Here on the left the symbol : · · · : is Wick ordering which means move all creation
operators to the left and all annihilation operators to the right. Then both sides of the
equation are well-deﬁned as bilinear forms on DS × DS and the claim is that they
are equal. We leave the details as a problem.
Problem 8.7
Verify (8.50), (8.51). (For the latter use (8.38) or K0J ˆH = −iωK0.)
Problem 8.8
Verify (8.57).
8.2.3 Generalization
Next we digress and give a more abstract version of the construction we used in
theorem 8.1. Let (S, σ) be a real vector space with symplectic form σ, that is σ is a
bilinear form on S which is skew-symmetric and nondegenerate. Let H be a complex
Hilbert space taken as a real vector space with symplectic form which is twice the
imaginary part of the inner product. Let K : S →H be symplectic with dense range.
Then for F ∈S
σ(, F) = i(a(KF) −a∗(KF))
(8.58)
on D0 ⊂F+(H) satisﬁes the CCR (8.44).
Further suppose T(t) is a linear symplectic time evolution on S and that KT(t) =
e−ihtK for some self-adjoint operator h on H. Then the time evolution deﬁned by
σ(t, F) = σ(, T(−t)F) is unitarily implemented with U(t) = (e−iht) in the
sense that
σ(t, F) = U(t)−1σ(, F)U(t)
(8.59)
The following problems refer to this abstract construction.
Problem 8.9
Let (H, K, h) and (H′, K′, h′) be two such structures for (S, σ, T(t))
with ﬁelds σ(, F), σ(′, F). Establish the following:
1. If there is a unitary operator V : H →H′ such that VK = K′, then there is a
unitary U : F+(H) →F+(H′) so
Uσ(t, F)U−1 = σ(′
t, F)
(8.60)
2. If h, h′ are both positive, then V exists.1 (So a positive energy representation is
essentially unique.)
1 See Kay (1979).

124
Scalar particles and ﬁelds
t
Problem 8.10
Suppose we want to quantize a ﬁeld which satisﬁes the equation
(−□+ m2 + V)φ = 0 where V = V(x) in L2(R3) only depends on the spatial
variables. Construct a suitable ﬁeld operator satisfying the CCR at time zero, and
show that the time evolution is unitarily implemented.
8.2.4 Covariant quantization
Now we give a more covariant construction of the scalar quantum ﬁeld. The quanti-
zation problem is just as before but now we deﬁne the ﬁeld operator on a different
space. We start with the relativistic single particle space H = L2(V+
m , dμm) which
is identiﬁed with H = L2(R3, dp/2ω(p)). Our map K from S(R3) to H is now
taken to be
K(f, g) = ω˜f + i˜g
(8.61)
and we still have
2 Im(KF1, KF2) = σ(F1, F2)
KFt = e−iωtKF
(8.62)
The ﬁeld operator is again
σ(, F) = i(a(KF) −a∗(KF))
(8.63)
on D0 ⊂F+(H). Time evolution is deﬁned by σ(t, F) = σ(, T(−t)F) as before
and we ﬁnd that φ(t, h) = σ(t, (0, h)) is given by
φ(t, h) = a(eiωt˜h) + a∗(eiωt˜h)
(8.64)
Since the operator V = [√2ω(p)] is unitary from H0 to H and satisﬁes VK0 = K,
the ﬁeld operators are unitarily equivalent to those of the previous section by (V).
(This is a special case of problem 8.9.)
It is also useful to consider a ﬁeld smeared in space and time. Formally we
have φ(t, h) =

φ(t, x)h(x)dx, so for real f
∈S(R4) the operator φ(f) =

φ(t, x)f(t, x)dtdx would be deﬁned by
φ(f) =

φ(t, f(t, ·))dt
(8.65)
This is evaluated as
φ(f) = a(+f) + a∗(+f)
(8.66)
where
(+f)(p) =
√
2πˆf(ω(p), p)
(8.67)

125
8.2 Scalar ﬁelds
t
and where ˆf is again the Fourier transform with the Lorentz inner product (see
(7.88)). Thus +f is essentially the restriction of the Fourier transform of f to the
mass shell V+
m . Since (−□+ m2)f has a Fourier transform which vanishes on the
mass shell we have
φ((−□+ m2)f) = 0
(8.68)
This says that φ satisﬁes the Klein–Gordon equation (−□+ m2)φ = 0 in the sense
of distributions.
We can also exhibit the covariance under proper Poincaré transformations (a, ).
If fa,(x) = f(−1(x −a)) is the transformed test function, then +(fa,) =
u(a, )(+f) where u(a, ) is the unitary representation deﬁned in (8.16). Hence
with U(a, ) = (u(a, )) we have
φ(fa,) = U(a, )φ(f)U(a, )−1
(8.69)
This shows that the Poincaré transformed ﬁeld is unitarily equivalent to the original
ﬁeld.
Finally we consider the commutator of two ﬁelds. We compute taking into account
the reality condition ˆf(p) = ˆf(−p)
[φ(g), φ(f)]
= (+g, +f)H −(+f, +g)H
= 2π
 
ˆg(−ω(p), −p)ˆf(ω(p), p) −ˆf(−ω(p), −p)ˆg(ω(p), p)
 dp
2ω(p)
= 1
i < g, Ef >
(8.70)
where < g, f >=

g(x)f(x)dx and E = E+ −E−is the propagator (7.91). If f, g
have spacelike separated supports, that is if supp g ∩J±(supp f) = ∅, then supp g ∩
supp E±f = ∅; hence < g, Ef >= 0, and so [φ(g), φ(f)] = 0. This strict locality
result is a manifestation of the basic fact that inﬂuence cannot propagate faster than
the speed of light.
Let us summarize writing (8.68), (8.69), (8.70) in distribution form:
Theorem 8.2
(The free ﬁeld) Let φ be the ﬁeld operator by (8.66). Then in the sense
of distributions
1. (Field equation)
(−□+ m2)φ = 0
(8.71)
2. (Covariance) For any proper Poincaré transformation (a, ) ∈P↑
+
U(a, )φ(x)U(a, )−1 = φ(x + a)
(8.72)
3. (Locality) In the region of spacelike separation (x −y) · (x −y) > 0
[φ(x), φ(y)] = 0
(8.73)

126
Scalar particles and ﬁelds
t
8.3 Charged scalar ﬁeld
8.3.1 Hamiltonian formulation
First we write the equations for the classical charged scalar ﬁeld as a Hamiltonian
system. We have four functions (φ1, π1) and (φ2, π2) each pair of which satisﬁes
(8.29). This is a Hamiltonian system with Hamiltonian
H(φ, π) = 1
2

i=1,2

(π2
i + (∇φi)2 + m2φ2
i )dx
(8.74)
Since ∂0φi = −∂0φi = −πi, the charge (7.41) is
Q =

(φ2π1 −π2φ1)dx
(8.75)
It is essentially the symplectic form (8.35) but has a new interpretation in this context.
Here is another formal way to arrive at a conserved charge. Note that the Hamil-
tonian is invariant under rotations in R2, that is with φ = (φ1, φ2) and π = (π1, π2)
we have H(φ(θ), π(θ)) = H(φ, π) where φ(θ) = R(−θ)φ and π(θ) = R(−θ)π and
R(−θ) =

cos θ
sin θ
−sin θ
cos θ

(8.76)
This is a global (that is constant) gauge transformation. But φ(θ), π(θ) are the
solutions of the equations
dφ1
dθ = φ2
dπ1
dθ = π2
dφ2
dθ = −φ1
dπ2
dθ = −π1
(8.77)
This is a Hamiltonian system with generator Q given by (8.75), that is ∂Q/∂π1 = φ2
and −∂Q/∂φ1 = π2 and so forth. As explained in section 2.4 the invariance of H
under the ﬂow of Q implies that {H, Q} = 0, which in turn implies that Q is invariant
under the ﬂow of H, that is charge is conserved.
It will also be useful to regard the ﬁeld as complex valued and introduce
φ = φ1 + iφ2
√
2
φ∗= φ1 −iφ2
√
2
π = π1 −iπ2
√
2
π∗= π1 + iπ2
√
2
(8.78)
Then (φ, π) and (φ∗, π∗) are pairs of conjugate variables. The Hamiltonian is
H =

(π∗π + ∇φ∗· ∇φ + m2φ∗φ)dx
(8.79)

127
8.3 Charged scalar ﬁeld
t
and the charge is
Q = i

(φ∗π∗−φπ)dx
(8.80)
The gauge transformations generated by Q now take the form φ
→
e−iθφ,
π∗→e−iθπ∗, and φ∗→eiθφ∗, π →eiθπ and they are still a symmetry of the
Hamiltonian.
8.3.2 Canonical quantization
For quantization we look for symmetric operators φ1, π1 and φ2, π2, each pair satis-
fying the ﬁeld equations (8.29) and the CCR, and commuting self-adjoint operators
H, Q implementing time evolution and gauge transformations. With i = (φi, πi),
i = 1, 2 and F = (f, g) in real S(R3) × S(R3) the combination σ(i, F) =
φi(g) −πi(f) should satisfy
[σ(i, F), σ(i, F′)] = iσ(F, F′)
[σ(1, F), σ(2, F′)] = 0
eiHtσ(i, F)e−iHt = σ(i, T(−t)F)
eiQθ

σ(1, F)
σ(2, F)

e−iQθ = R(−θ)

σ(1, F)
σ(2, F)

(8.81)
We can also formulate this in terms of  = (1 + i2)/
√
2 = (φ, π∗) and its
adjoint ∗= (1 −i2)/
√
2 = (φ∗, π). It is equivalent to ask for operators σ(, F)
and σ(∗, F), which are adjoint to each other and self-adjoint H, Q which satisfy
[σ(, F), σ(∗, F′)] = iσ(F, F′)
[σ(, F), σ(, F′)] = 0
eiHtσ(, F)e−iHt = σ(, T(−t)F)
eiQθσ(, F)e−iQθ = e−iθσ(, F)
(8.82)
The ﬁrst three equations in (8.81) or (8.82) are familiar from the discussion of the
neutral scalar ﬁeld. The last is the quantum version of the classical statement that
charge generates global gauge transformations.
To realize this structure we introduce a second particle and follow the treatment of
section 8.2.2. On the Hilbert space F+(H0) ⊗F+(H0) we deﬁne
a(f) = a(f) ⊗I
b(f) = I ⊗a(f)
(8.83)
The operators a(f), a∗(f), b(f), b∗(f) satisfy
[a(f), a∗(g)] = (f, g)
[b(f), b∗(g)] = (f, g)
(8.84)

128
Scalar particles and ﬁelds
t
with all other commutators equal to zero. Then we deﬁne
σ(, F) = i(a(K0F) −b∗(K0F))
σ(∗, F) = i(b(K0F) −a∗(K0F))
(8.85)
These are adjoint to each other and the identities (8.82) are satisﬁed with e−iHt =
(e−iωt) ⊗(e−iωt) and e−iQθ = (e−iθ) ⊗(eiθ). The ﬁrst three follow as before.
For the last, note that
eiQθσ(, F)e−iQθ = i

a(eiθK0F) −b∗(e−iθK0F)

= e−iθi

a(K0F) −b∗(K0F)

= e−iθσ(, F)
(8.86)
The Hamiltonian and the charge are given by
H = d(ω) ⊗I + I ⊗d(ω)
=

ω(p)[a∗(p)a(p) + b∗(p)b(p)]dp
Q = N ⊗I −I ⊗N
=

[a∗(p)a(p) −b∗(p)b(p)]dp
(8.87)
The charge can also be written as Q = Na −Nb where Na = N ⊗I is the
number of a particles and Nb = I ⊗N is the number of b particles. Thus we see
that the a particles carry charge +1 (in natural units) while the b particles carry
charge −1. Charge takes integer values – “charge is quantized.” The b particles are
called the anti-particles of the a particles. Both are necessary to get the structure we
want.
Problem 8.11
1. Find expressions for φ(t, x), π(t, x), φ∗(t, x), π∗(t, x) as bilinear forms on
DS × DS. as in (8.56).
2. Show that the quantum charge Q in (8.87) regarded as a bilinear form on DS ×
DS has the same form as the classical charge (8.80), that is
Q = i

: (φ∗(x)π∗(x) −φ(x)π(x)) : dx
(8.88)
where φ(x) = φ(0, x), etc. (Wick ordering was deﬁned after equation (8.57).)
Notes on chapter 8: In general charge can be deﬁned as the labels for the irre-
ducible representations of the internal symmetry group, see Haag (1992). In our
case the symmetry group is U(1) and the irreducible representations eiθ →einθ
are labeled by integers n.

129
8.3 Charged scalar ﬁeld
t
Everything in this chapter could be done in a spacetime (Rd, η) with d ≥2 instead
of speciﬁcally d = 4.
There are many physics texts on quantum ﬁeld theory. Early works by
Schweber (1962) and Roman (1969) are still useful. Some more recent books are
Itzykson and Zuber (1980), Weinberg (1995) and Peskin and Schroeder (1995). Our
notation mostly agrees with Weinberg.
A mathematical treatment of free ﬁelds can be found in Baez et al. (1992).

9
Electrons and photons
In this chapter we explore the quantum mechanical description of free electrons and
photons and associated ﬁelds.
However we start with a digression developing the transformation properties of
spinors under the Lorentz group, or more precisely the covering group of the Lorentz
group. The discussion extends the discussion of spin in section 4.6 and the Dirac
equation in section 7.3.
9.1 Spinors
Given 4 × 4 gamma matrices satisfying {γ μ, γ ν} = 2ημν, let V be the real vector
space of all matrices of the form γ · a = ημνγ μaμ with a ∈R4. Consider the group
of nonsingular 4 × 4 matrices S so that S(γ · a)S−1 is again in V, called Pin(1, 3).1
Since the γ matrices are a basis (problem 7.6) this means that S(γ · a)S−1 = γ · a′
for a unique a′ ∈R4. The map a →a′ is linear and so a′ = (S)a for some matrix
(S). Thus (S) is deﬁned by
S(γ · a)S−1 = γ · (S)a
(9.1)
Lemma 9.1
The map S →(S) is a two-to-one homomorphism from Pin(1, 3) onto
the Lorentz group L = O(1, 3).
Proof
The map is a homomorphism since
γ · (ST)a = ST(γ · a)(ST)−1
= S(γ · (T)a)S−1
= γ · ((S)(T))a
(9.2)
which implies (ST) = (S)(T). The matrix (S) is a Lorentz transformation
since
(S)a · (S)a = (γ · (S)a)2 = (S(γ · a)S−1)2 = a · a
(9.3)
1 The name Pin(1, 3) is a truncation of Spin(1, 3) deﬁned below.
130

131
9.1 Spinors
t
To see that the mapping is onto note that for  ∈L we have that (γ ′)μ =
(−1)μ
νγ ν is also a set of gamma matrices. But any two such are related by
(γ ′)μ = Mγ μM−1 for some M and so we have
M(γ · a)M−1 = −1γ · a = γ · (a)
(9.4)
Hence M ∈Pin(1, 3) and (M) = .
The mapping is at least two-to-one since (−S) = (S). To see it is exactly
two-to-one it sufﬁces to show that (S) = I implies S = ±I, which we omit.
Recall that L has a subgroup L+ = SO(1, 3) deﬁned by the condition det  = 1.
This is covered by
Spin(1, 3) = {S ∈Pin(1, 3) : (S) ∈L+}
(9.5)
which is a subgroup of Pin(1, 3). Furthermore L+ has a connected subgroup L↑
+
deﬁned by 0
0 ≥1, which is covered by
Spin↑(1, 3) = {S ∈Spin(1, 3) : (S) ∈L↑
+}
(9.6)
This is a subgroup of Spin(1, 3) and is connected as well (problem 9.4).
Next consider the indeﬁnite inner product u†βv of (7.53) on the spinor space C4.
We show it is invariant under Spin↑(1, 3).
Lemma 9.2
For S ∈Spin↑(1, 3), u, v, ∈C4, and β = iγ 0
(Su)†βSv = u†βv
(9.7)
Equivalently if S∗is the adjoint with the usual inner product
S∗γ 0S = γ 0
(9.8)
Proof
Take the adjoint of S(γ · x)S−1 = γ · (S)x. Then with ˆx = (−x0, x) we ﬁnd
(S−1)∗(γ · ˆx)S∗= γ · 
((S)x)
(9.9)
However γ · ˆx = γ 0(γ · x)γ 0, so we have
[γ 0(S−1)∗γ 0](γ · x)[γ 0S∗γ 0] = γ · ((S)x)
(9.10)
This implies that
γ 0(S−1)∗γ 0 = ±S
(9.11)
and so
S∗γ 0S = ±γ 0
(9.12)
The sign is a continuous function of S on the connected set Spin↑(1, 3). Since it is
+1 at the identity, it is +1 everywhere.

132
Electrons and photons
t
Problem 9.1
If S = γ · y with y · y ̸= 0, show that S ∈Pin(1, 3) and ﬁnd (S).
Problem 9.2
Show that
e−γ 2γ 3θ/2 = cos(θ/2) −γ 2γ 3 sin(θ/2)
(9.13)
is in Spin↑(1, 3) and that
(e−γ 2γ 3θ/2) = R(e1, θ)
(9.14)
where R(e1, θ) is the rotation by θ around the ﬁrst axis.
Problem 9.3
Show that
eγ 0γ 1β/2 = cosh(β/2) + γ 0γ 1 sinh(β/2)
(9.15)
is in Spin↑(1, 3) and that
(eγ 0γ 1β/2) = β
(9.16)
where β is the boost (7.36).
Problem 9.4
Show that Spin↑(1, 3) is connected by showing that every element
can be joined to the identity by a continuous path.
Problem 9.5
Show that if ψ is a solution of (γ · ∂+ m)ψ = 0, then ψa,S(x) =
Sψ((S)−1(x −a)) is also a solution.
9.2 Electrons
9.2.1 Solutions of the Dirac equation
We consider the Dirac equation (γ · ∂+ m)ψ = 0 deﬁned in section 7.3.3 and try to
interpret it as describing the quantum time evolution for a single electron or proton
or any other massive spin 1/2 particle. We begin by rewriting it and exhibiting some
solutions.
Consider the self-adjoint 4 × 4 matrices
β = iγ 0
αk = −γ 0γ k
k = 1, 2, 3
(9.17)

133
9.2 Electrons
t
These have the anti-commutation relations
{αj, αk} = 2δjk
{αk, β} = 0
β2 = I
(9.18)
and they are traceless. Multiplying the Dirac equation by iγ 0, it takes the form
i∂ψ
∂t = (−i∇· α + βm)ψ
(9.19)
To solve it, note that the partial Fourier transform ˜ψ(t, p) satisﬁes the equation
i∂˜ψ
∂t = (p · α + βm) ˜ψ
(9.20)
The matrix p · α + βm is self-adjoint and satisﬁes
(p · α + βm)2 = |p|2 + m2 = ω(p)2
(9.21)
It follows that the eigenvalues of p · α + βm can only be ±ω(p). Furthermore since
tr(p·α+βm) = 0, both ±ω(p) must occur, each with multiplicity 2. For each p ∈R3
let Wp,± be the two-dimensional eigenspace for the positive or negative eigenvalue.
Then we have
C4 = W+
p ⊕W−
p
(9.22)
Now a general solution of (9.20) is
˜ψ(t, p) = e−iω(p)tψ+(p) + eiω(p)tψ−(p)
(9.23)
with ψ±(p) ∈W±
p . A general solution of the Dirac equation is
ψ(t, x) = (2π)−3/2

eip·x
e−iω(p)tψ+(p) + eiω(p)tψ−(p)

dp
(9.24)
9.2.2 Quantum interpretation
Now we give the quantum interpretation. First we work with the Fourier trans-
formed variable, which we interpret as momentum space. The Hilbert space is
H0 ≡L2(R3, C4, dp), the C4-valued square integrable functions on R3. Equation
(9.20) has the form of a Schrödinger equation if we take as the Hamiltonian
˜H = [p · α + βm]
(9.25)
The Hilbert space splits into positive and negative energy subspaces
H0 = H+
0 ⊕H−
0
(9.26)
where
H±
0 = {ψ ∈H0 : ψ(p) ∈W±
p }
(9.27)

134
Electrons and photons
t
With respect to this splitting the Hamiltonian is ˜H = [ω(p)] ⊕[−ω(p)], which is
self-adjoint on its natural domain. Time evolution is exp(−i ˜Ht) = exp(−iω(p)t) ⊕
exp(iω(p)t) as in (9.23). To write it another way, note that the projection onto H±
0 is
P± =
	ω(p) ± (p · α + βm)
2ω(p)

(9.28)
Then for any ψ ∈H0 we have
e−i ˜Htψ = e−iωtP+ψ + eiωtP−ψ
(9.29)
Return to conﬁguration space ˆH0 ≡L2(R3, C4, dx) with a Fourier transform
F−1 : H0 →ˆH0. The Dirac Hamiltonian is HD = F−1 ˜HF, which on S(R3) is
HD = −i∇· α + βm
(9.30)
The time evolution is exp(−iHDt) = F−1 exp(−i ˜Ht)F as in (9.24).
At this point we remember that we only want positive energy solutions. Thus
instead of H0, the Hilbert space is H+
0 , the Hamiltonian is [ω(p)], and the time
evolution is [exp(−iω(p)t)]. Taking the inverse Fourier transform gives a Hilbert
space ˆH+
0 = F−1H+
0 , a Hamiltonian HD = F−1[ω(p)]F, and a time evolution
F−1[exp(−iω(p)t)]F. The wave function with initial condition ψ ∈ˆH+
0 is
ψ(t, x) = (2π)−3/2

e−i(ω(p)−p·x) ˜ψ(p)dp
(9.31)
which still satisﬁes the Dirac equation.
But there is a problem with this restriction to positive energy. The operator [xk] can
no longer be precisely interpreted as representing the kth coordinate of the particle.
This is because it does not act on ˆH+
0 . To put it another way, F[xk]F−1 = i∂/∂pk
does not act on the positive energy subspace H+
0 . To remedy this we stay in momen-
tum space and deﬁne a new coordinate operator – the Newton–Wigner operator. It
involves the projection operator at zero momentum which is (1 + β)/2 and it is
deﬁned by
Xk = 2P+
#
ω
ω + m
1 + β
2
 
i ∂
∂pk
 #
ω
ω + m P+
(9.32)
This is a symmetric operator mapping H+
0 ∩S(R3) to itself and is supposed to
represent the kth coordinate of the particle. This interpretation is supported by the
following result:
Problem 9.6
Show that Xk, [pj] satisfy the the canonical commutation relations.

135
9.2 Electrons
t
9.2.3 Translations and rotations
Next we investigate the effect of spacetime translations and rotations on solutions,
excluding boosts for now.
Note that the positive energy condition (p · α + βm −ω(p))ψ(p) = 0 can be
multiplied by β = iγ0 and written (iγ · φ(p) + m)ψ(p) = 0 where φ(p) = (ω(p), p).
If ψ(p) satisﬁes the condition and S ∈Spin↑(1, 3) is a spinor rotation covering R ∈
SO(3), then Sψ(R−1p) also satisﬁes the condition. This follows since S−1(γ · a)S =
γ · R−1a and so

iγ · φ(p) + m

Sψ(R−1p) = S

iγ · φ(R−1p) + m

ψ(R−1p) = 0
(9.33)
Now we can deﬁne a representation of translations and rotations on H+
0 . For a =
(a0, a) and a spinor rotation S covering a rotation R, we deﬁne
(u0(a, S)ψ)(p) = ei(ω(p)a0−p·a)S ψ(R−1p)
(9.34)
One checks that u0(a, S) is unitary using the facts that the Lebesgue measure is rota-
tion invariant and that S∗S = I. (For a rotation, [S, β] = 0 so S∗S = S∗βSβ =
β2 = I.) One also checks that u0(a, S)u0(a′, S′) = u0(a + Ra′, SS′) so we have a
representation.
A unitary representation on ˆH+
0 is deﬁned by ˆu0(a, S) = F−1u0(a, S)F. If ψ(t, x)
is the complete wave function given by (9.31), then
(ˆu0(a, S)ψ(t, ·))(x) = Sψ(t −a0, R−1(x −a))
(9.35)
Furthermore the Newton–Wigner operator X = (X1, X2, X3) satisﬁes
u0((0, a), S)−1Xu0((0, a), S) = RX + a
(9.36)
This is a consistency check on the interpretation of both u0(a, S) and X.
Now specialize to the rotation Rθ = R(e1, θ) around the ﬁrst axis. By problem 9.2
this is covered by Sθ = e−γ2γ3θ/2 and so (9.34) becomes
(u0(0, Sθ)ψ)(p) = e−γ2γ3θ/2ψ(R−1
θ (p))
(9.37)
The ﬁrst component of angular momentum is i(J1ψ)(p) = id/dθ[· · · ]|θ=0 and we
ﬁnd as in (4.74)
J1 = p3

i ∂
∂p2

−p2

i ∂
∂p3

−i
2γ2γ3
(9.38)
The ﬁrst component of spin is the internal part 1 = −iγ2γ3/2. Similarly the other
components are 2 = −iγ3γ1/2 and 3 = −iγ1γ2/2. In each case we have 2
i =
1/4 so i has eigenvalues ±1/2, which conﬁrms that we are describing a particle of
spin 1/2.

136
Electrons and photons
t
Now we have operators on H+
0 for position, momentum, and angular momentum
(but not spin alone, which does not act on this space). This is all we need. It is not
required or particularly useful to try to give a meaning to the individual components
of our spinor-valued wave function.
9.2.4 A covariant formulation
Next we give an alternative more covariant construction for the free electron. Our
goal is a unitary representation of the extended proper Poincaré group deﬁned as all
pairs {a, S} with a ∈R4 and S ∈Spin↑(1, 3) with the group law
{a, S}{a′, S′} = {a + (S)a′, SS′}
(9.39)
We know that u†βv is invariant under Spin↑(1, 3). We next show that it is postive
deﬁnite on the positive energy subspace.
Lemma 9.3
For u, v ∈W+
p
ω(p) u†βv = m u†v
(9.40)
Proof
Since (α · p + βm)v = ω(p)v
ω(p) u†βv = u†β(α · p + βm)v
(9.41)
and since (α · p + βm)u = ω(p)u
ω(p) u†βv = ((α · p + βm)u)†βv
= u†(α · p + βm)βv
= u†β(−α · p + βm)v
(9.42)
Adding these equations and using β2 = I gives the result.
Now consider L2 
R3, C4, m ω(p)−1dp

as a candidate for the single particle
space. Here we have used a slightly different normalization for the Lorentz invari-
ant measure; compare the dp/(2ω(p)) that we used in the scalar case. There is again
a positive energy subspace deﬁned by the condition ψ(p) ∈W+
p . On this positive
energy subspace we introduce the relativistic inner product
(ψ, χ)β =

ψ(p)†βχ(p) m
ω(p)dp
=

ψ(p)†χ(p)
 m
ω(p)
2
dp
(9.43)
This is positive deﬁnite and we let H+ be the completion in the associated norm. We
have the identiﬁcation
H+ = {ψ ∈L2 
R3, C4, m2ω(p)−2dp

: ψ(p) ∈W+
p }
(9.44)

137
9.2 Electrons
t
An alternative is to identify R3 with the mass shell V+
m via the function φ(p) =
(ω(p), p). As in section 8.1 the measure mω(p)−1dp becomes the measure 2m μm on
V+
m . The condition u ∈W+
p says (iγ · φ(p) + m)u = 0 as noted earlier, and thus we
can deﬁne H+ as the completion of
{ψ ∈L2(V+
m , C4, 2m μm) : (iγ · p + m)ψ(p) = 0}
(9.45)
with the inner product
(ψ, χ)β =

ψ(p)†βχ(p) 2m dμm(p)
(9.46)
Theorem 9.1
On H+ there is a unitary representation of the extended proper
Poincaré group deﬁned by
(u(a, S)ψ)(p) = e−ip·aSψ((S)−1p)
(9.47)
Proof
To see that u(a, S) maps H+ to itself, we compute as in (9.33)

iγ · p + m

Sψ((S)−1p) = S

iγ · ((S)−1p) + m

ψ((S)−1p) = 0
(9.48)
To see that U(a, S) is unitary, use (Su)†β(Sv) = u†βv from (9.7) and the Lorentz
invariance of the measure to compute
∥u(a, S)ψ∥2
β =
 
Sψ((S)−1p)
†
β

Sψ((S)−1p)

2m dμm(p)
=

ψ(p)†βψ(p) 2m dμm(p)
= ∥ψ∥2
β
(9.49)
One also checks that u(a, S)u(a′, S′) = u(a + (S)a′, SS′) to ﬁnish the proof.
Remark
Identify the new Hilbert space with the old Hilbert space by the unitary
operator V : H+
0 →H+ deﬁned by
(Vψ)(p) = ω(p)
m
ψ(p)
(9.50)
With this identiﬁcation the new representation of translations and rotations in (9.47)
extends the old representation (9.34).
9.2.5 Charge conjugation
We close this section with some special results about charge conjugation, which we
need in the next section. Let us temporarily return to the classical Dirac equation
with an external electromagnetic potential A. This has the form (from (7.77))
(γ · (∂−ieA) + m)ψ = 0
(9.51)

138
Electrons and photons
t
We want to ﬁnd a charge conjugation operator which maps solutions of this equation
with charge e to solutions with the opposite charge −e. Start by taking the complex
conjugate which yields
(γ · (∂+ ieA) + m)ψ = 0
(9.52)
Now let C be a nonsingular matrix which satisﬁes Cγ μC−1 = γ μ. Such a matrix
exists since γ μ is again the possible choice of the gamma matrices. In fact we can
choose C = C = C−1 = C∗. For example in the representation (7.49) where γ 2 is
real and the other γ μ are imaginary we could take C = γ 2. Applying C we get
(γ · (∂+ ieA) + m)Cψ = 0
(9.53)
Thus the charge conjugation operator we seek is
Cψ = C ψ
(9.54)
It is anti-linear and satisﬁes Cγ μ = γ μC and C2 = 1.
Return now to the free case A = 0 and the quantum interpretation. Then C deﬁned
on L2(R3, C4, dx) by (9.54) is an anti-unitary operator which is a conjugation in the
mathematical sense that (Cψ, Cχ) = (χ, ψ). It satisﬁes CαiC = αi and CβC = −β
and hence we have
C(−i∇· α + βm)C = −(−i∇· α + βm)
(9.55)
This shows that C maps positive energy states into negative energy states and vice-
versa. Thus it does not act on our positive energy Hilbert space. However charge
conjugation will ﬁnd a place in the quantum ﬁeld theory.
We also will need the momentum space version of (9.55). Let ˜C = FCF−1 be
conjugation in L2(R3, C4, dp). Explicitly
( ˜Cψ)(p) = C ψ(−p)
(9.56)
Then we have
˜C[p · α + βm] ˜C = −[p · α + βm]
(9.57)
Problem 9.7
Let H = HD + βV = −i∇· α + β(m + V) where V is is a real
function with ∥V∥∞< m.
1. Show that H is self-adjoint on D(HD) ⊂ˆH0.
2. Show that zero is in the resolvent set for H.
3. Show that CH = −HC.
4. (hard) Let P± be the projection onto the positive and negative energy subspaces
for H. Show that CP± = P∓C.

139
9.3 Dirac ﬁelds
t
9.3 Dirac ﬁelds
9.3.1 The problem
Now we want solutions of the Dirac equation which are quantum ﬁeld operators.
We seek Dirac ﬁeld operators ψα(x) = ψα(t, x) indexed by x ∈R4, α = 1, . . . , 4
such that
i∂ψ
∂t = (−i∇· α + βm)ψ
{ψα(0, x), ψ∗
β(0, y)} = δ(x −y)δαβ
(9.58)
This is roughly analogous to what we did with the scalar ﬁeld, except that now we use
the anti-commutator instead of the commutator. This turns out to be necessary for a
consistent theory. It means that the associated particles are fermions as we shall see.
These equations should be interpreted in the sense of distributions. We formally
integrate with complex test functions h ∈S(R3, C4) in space only and deﬁne
ψ(t, h) =
 
α
ψα(t, x)hα(x)dx
ψ∗(t, h) =
 
α
ψ∗
α(t, x)hα(x)dx
(9.59)
Thus we seek operators ψ(t, h) anti-linear in h with adjoints ψ∗(t, h) linear in h such
that
i ∂
∂tψ(t, h) = ψ(t, (−i∇· α + βm)h)
{ψ(0, h), ψ∗(0, g)} = (h, g)
(9.60)
where (h, g) is the L2(R3, C4, dx) inner product.
Example 9.1
Here is a construction that accomplishes these goals. With H0 =
L2(R3, C4, dp) take the anti-symmetric Fock space F−(H0). Deﬁne the ﬁelds in
terms of the bounded creation and annihilation operators a, a∗by
ψ(h) = a(˜h)
ψ∗(h) = a∗(˜h)
(9.61)
Then {ψ(h), ψ∗(g)} = (˜h, ˜g) = (h, g) as required. Time evolved ﬁeld operators
are deﬁned by ψ(t, h) = ψ(eiHDth) where HD = −i∇· α + βm is the self-adjoint
Hamiltonian deﬁned in section 9.2.2. Then i∂/∂t ψ(t, h) = ψ(t, HDh) as required.
This construction is not satisfactory because of the presence of the negative energy
particles. If we suppress them entirely, we do not get the commutator we want.
An alternative picture is that all the negative energy states are present, but they

140
Electrons and photons
t
are already ﬁlled, thereby stabilizing the theory. (The idea invokes the exclusion
principle again.) Because this sea of negative energy fermions is homogeneous, its
presence is not manifest. It is possible however to have unoccupied states or holes
in this negative energy sea. These holes propagate as if they have positive energy
and the opposite charge. They are identiﬁed as the anti-particles. If the particles
are electrons, the anti-particles are called positrons. The observed electron-positron
annihilation into photons is then identiﬁed with an electron falling to a negative
energy state, ﬁlling the hole and emitting a photon. The theory is known as hole
theory and the negative energy background is called the Dirac sea. It is reminiscent
of the Fermi sea encountered in section 6.4, but here it is a more radical concept
since there is no lowest energy state.
We do not attempt to make direct mathematical sense of this picture. Instead take
a standard shortcut and give a construction in which the anti-particles are introduced
as elementary particles, just as for the charged scalar ﬁeld. Our goal is again ﬁeld
operators ψ(t, h) satisfying (9.60) but now such that time evolution is implemented
with positive energy.
9.3.2 The ﬁeld operator
Let H+
0 be the positive energy Hilbert space (9.27) and consider the fermion Fock
space
F0 = F−(H+
0 ) ⊗F−(H+
0 )
(9.62)
The ﬁrst factor represents particles and the second factor represents anti-particles.
We introduce annihilation operators for h ∈H+
0 by
a(h) = a(h) ⊗I
b(h) = (−1)N ⊗a(h)
(9.63)
where N is the number operator. These satisfy
{a(h), a∗(g)} = (h, g)
{b(h), b∗(g)} = (h, g)
(9.64)
with all other anti-commutators equal to zero. In particular we have
{a(h), b(g)} = 0
(9.65)
This is the reason we have introduced the factor (−1)N in the deﬁnition; otherwise the
commutator would be zero rather than the anti-commutator. This anti-commutator is
a reﬂection of the deep connection between particles and anti-particles, which is
natural in hole theory.
Now for h ∈S(R3, C4) deﬁne the time zero ﬁeld operator on F0 by
ψ(h) = a(P+˜h) + b∗( ˜CP−˜h)
(9.66)

141
9.3 Dirac ﬁelds
t
Here P± is the projection onto H±
0 as in (9.28) and ˜C is charge conjugation in
momentum space as in (9.56). Note that ˜CP−h does have positive energy since it
follows from (9.57) that ˜CP± = P∓˜C. The ﬁeld has the desired anti-commutator
since
{ψ(h), ψ∗(g)} = (P+˜h, P+˜g) + ( ˜CP−˜g, ˜CP−˜h)
= (P+˜h, P+˜g) + (P−˜h, P−˜g)
= (˜h, ˜g) = (h, g)
(9.67)
To satisfy the ﬁeld equation, time evolution is again deﬁned by
ψ(t, h) = ψ(eiHDth)
(9.68)
But F(eiHDth) = ei ˜Ht˜h and P+ei ˜Ht = eiωtP+ and ˜CP−ei ˜Ht = ˜CP−e−iωt = eiωt ˜CP−
and so we have
ψ(t, h) = a(eiωtP+˜h) + b∗(eiωt ˜CP−˜h)
(9.69)
In this form we can see that time evolution is generated by a Hamiltonian with
positive energy. We collect this and other properties of the ﬁeld in a theorem.
Theorem 9.2
1. ψ(t, h) satisﬁes the ﬁeld equation and anti-commutation relations (9.60).
2. Time evolution is unitarily implemented by
ψ(t, h) = eiHtψ(h)e−iHt
(9.70)
where e−iHt = (e−iωt) ⊗(e−iωt) and
H = d(ω) ⊗I + I ⊗d(ω) ≥0
(9.71)
3. Gauge transformations are implemented by
e−iθψ(t, h) = eiQθψ(t, h)e−iQθ
(9.72)
where e−iQθ = (e−iθ) ⊗(eiθ) and the charge is
Q = Na −Nb = N ⊗I −I ⊗N
(9.73)
The last point follows just as for the charged scalar ﬁeld, see (8.86). As in prob-
lem 8.11, Q can be identiﬁed with

x0=t : ψ∗ψ : which is the quantization of (7.56).
From (9.73) we see that each particle contributes charge +1 (in natural units), while
each anti-particle contributes charge −1. These are the conventions for a positively
charged fermion like a proton. For electrons replace Q by −Q and change signs
elsewhere.
Note the reversal from the construction of example 9.1. There Q is positive and H
is not. Now H is positive and Q is not.

142
Electrons and photons
t
Problem9.8
Consider the Dirac equation with a bounded real potential V = V(x)
satisfying ∥V∥∞< m
i∂ψ
∂t = (−iα · ∇+ β(m + V))ψ = 0
(9.74)
Using the results of problem 9.7 construct a distribution solution ψ(t, h) with the
canonical anti-commutator at t = 0 and with positive energy.
9.3.3 Locality
Let us also smear in space and time and deﬁne for f ∈S(R4, C4)
ψ(f) =

ψ(t, f(t, ·))dt = a(P++f) + b∗( ˜CP−−f)
(9.75)
where as in (8.67)
(±f)(p) =
√
2πˆf(±ω(p), p)
(9.76)
Note that ψ(f) is anti-linear in f.
Then we compute
{ψ(f), ψ∗(g)} = (P++f, P++g) + ( ˜CP−−g, ˜CP−−f)
= (P++f, P++g) + ( P−−f, P−−g)
= (P++f, +g) + ( P−−f, −g)
(9.77)
Now use the identity
(P±±f)(p) = ±
1
2ω(p)(±(i∂t + HD)f)(p)
(9.78)
where again HD = −iα · ∇+ βm. Then (9.77) becomes

+(i∂t + HD)f, 1
2ω+g

−

−(i∂t + HD)f, 1
2ω−g

(9.79)
However

+f, 1
2ω+g

−

−f, 1
2ω−g

= 1
i (f, Eg)
(9.80)
where E is the scalar propagator (7.91) and on the right side the inner product is in
L2(R4, C4). Then we have
{ψ(f), ψ∗(g)} = 1
i

(i∂t + HD)f, Eg

= 1
i

f, (i∂t + HD)Eg

(9.81)
Since (i∂t + HD) does not enlarge supports, this vanishes if f, g have spacelike
separated supports. This is our locality result.

143
9.3 Dirac ﬁelds
t
9.3.4 A covariant formulation
Now we give an alternate construction in which the Lorentz covariance is manifest.
Again let H+ be the positive energy relativistic Hilbert space deﬁned in (9.43)–(9.46)
and set
F = F−(H+) ⊗F−(H+)
(9.82)
The unitary map V : H+
0 →H+ deﬁned in (9.50) induces a unitary map 2(V) =
(V) ⊗(V) from F0 to F. Thus starting with the ﬁeld operator on F0 deﬁned in
(9.75) and now denoted ψ0(f) we deﬁne an equivalent ﬁeld operator ψ(f) on F by
ψ(f) = 2(V)ψ0(f)2(V)−1
(9.83)
Then
ψ(f) = a(VP++f) + b∗( ˜CVP−−f)
(9.84)
where now the creation and annihilation operators are on F. However by (9.78)
VP±± = ± 1
2m±(i∂t + HD) = ±±β
(9.85)
where
 = −γ · ∂+ m
2m
(9.86)
Therefore
ψ(f) = a(+βf) −b∗( ˜C−βf)
(9.87)
These have the following properties:
Theorem 9.3
The Dirac ﬁelds ψ(f) =

ψ(x)f(x)dx satisfy in the sense of distribu-
tions:
1. (Field equation) (γ · ∂+ m)ψ = 0
2. (Covariance) There is a unitary representation U(a, S) of the extended proper
Poincaré group such that
U(a, S)ψ(x)U(a, S)−1 = S−1 ψ((S)x + a)
(9.88)
3. (Locality) With ˜ψ(f) = ψ∗(βf) (the “Dirac adjoint”) and scalar propagator E
{ψ(f), ˜ψ(g)} = 1
i (f, (−γ · ∂+ m)Eg)
(9.89)
Proof
These operations translate nicely to the test function if we consider
ψ(βf) rather than ψ(f). For the ﬁeld equation ((γ · ∂+ m)ψ)(βf) = 0 says that

144
Electrons and photons
t
ψ(β(γ · ∂+ m)f) = 0. (Think of Green’s identity (7.55) at times ±∞.) We compute
using ±(−□+ m2)f = 0
ψ(β(γ · ∂+ m)f)
= a(+(γ · ∂+ m)f) −b∗( ˜C−(γ · ∂+ m)f)
=

a(+(−□+ m2)f) −b∗( ˜C−(−□+ m2)f)

/2m
= 0
(9.90)
For the second we set U(a, S) = (u(a, S)) where u(a, S) is deﬁned in (9.47). Then
with fa,S(x) = Sf((S)−1(x −a)) we have
U(a, S)ψ(βf)U(a, S)−1 = a(u(a, S)+f) −b∗(u(a, S) ˜C−f)
= a(+fa,S) −b∗( ˜C−fa,S)
= ψ(βfa,S)
(9.91)
This is the meaning of (9.88). We have also used [ ˜C, u(a, S)] = 0.
For the third point refer back to the result (9.81) for ψ0(f). Then ψ(f) must have
the same anti-commutator and so
{ψ(f), ˜ψ(g)} = 1
i (f, (i∂t + HD)βEg) = 1
i (f, (−γ · ∂+ m)Eg)
(9.92)
9.4 Photons
Recall that in the absence of charges the electromagnetic potential A satisﬁes the
wave equation □A = 0 and a constraint ∂μAμ = 0. Following the scalar case we
want to interpret positive energy solutions as wave functions for a massless spin one
particle – the photon. Again there is more than one way to accomplish this.
9.4.1 Coulomb gauge
Our ﬁrst quantization starts with the observation that potentials A, A′ which are
gauge equivalent A′
μ = Aμ + ∂μλ represent the same physical situation. Any
potential A is gauge equivalent to a potential A′ with A′
0 = 0; one has only to
take λ(t, x) = −
 t
0 A0(s, x)ds. Thus it sufﬁces to consider solutions with constraint
A0 = 0 and A = (A1, A2, A3). Making this choice we are working in the Coulomb
gauge.

145
9.4 Photons
t
In the Coulomb gauge the equations for A(t, x) become
 ∂2
∂t2 −

A = 0
∇· A = 0
(9.93)
The partial Fourier transform ˜A(t, p) satisﬁes
 ∂2
∂t2 + |p|2

˜A = 0
p · ˜A = 0
(9.94)
For quantization we consider complex square integrable positive energy solutions.
In the Fourier transform variable, identiﬁed as momentum, the Hilbert space is the
closed subspace
H0 = { ∈L2(R3, C3, dp) : p · (p) = 0}
(9.95)
The time evolution is (t, p)
=
e−i|p|t(p). It does preserve the constraint
p · (p) = 0 and is unitary on the Hilbert space. The Hamiltonian is [|p|]. In
conﬁguration space the Hilbert space is ˆH0 = F−1H0, the time evolution is
U(t) = F−1[e−i|p|t]F
(9.96)
and the Hamiltonian is
H = F−1[|p|]F = (−)1/2
(9.97)
We deﬁne a representation of spacetime translations and rotations on H0 by
(u0(a, R))(p) = ei(|p|a0−p·a)R(R−1p)
(9.98)
This preserves the constraint since if p · (p) = 0, then p · R(R−1p) = R−1p ·
(R−1p) = 0. It is unitary since RTR = I. On ˆH0 the representation is
ˆu0(a, R) = F−1 u0(a, R)F
(9.99)
The deﬁnitions implement these symmetries since if (t, x) = (U(t))(x) is a
complete time evolved wave function, then
(ˆu0(a, R)(t, ·))(x) = R (t −a0, R−1(x −a))
(9.100)
The representation of the rotation group is characteristic of a spin one particle.
However we have again lost the position operator. Multiplication by xk does
not preserve the Fourier transformed space ˆH0. In this case the difﬁculty cannot
be avoided. There is no Newton–Wigner operator and photons cannot be precisely
localized.
Problem 9.9
1. Show that H0 is a closed subspace of L2(R3, C3, dp).

146
Electrons and photons
t
2. Show that the projection onto H0 is
(P)i(p) =

j

δij −pipj
|p|2

j(p)
(9.101)
9.4.2 A covariant formulation
Next we give a more covariant construction with the zeroth component restored. Start
with the light cone
V+
0 = {p ∈R4 : p · p = 0, p0 > 0}
(9.102)
Consider the Hilbert space
H = L2(V+
0 , C4, μ0)
(9.103)
where μ0 is the invariant measure on V+
0 . Let H′ be the closed subspace
H′ = {ψ ∈H : pμψμ(p) = 0}
(9.104)
We want a representation of the Poincaré group on this space consistent with
(9.98). Our ﬁrst choice would be to take on H
(u(a, )ψ)μ(p) = e−ip·a(−1)ν
μψν(−1p)
(9.105)
which can also be written (u(a, )ψ)(p) = e−ip·a(−1)Tψ(−1p). This preserves
H′ since if pμψμ(p) = 0 for all p, then
pμ(−1)ν
μψν(−1p) = (−1p)νψν(−1p) = 0
(9.106)
If  = R is a rotation, then (R−1)T = R and the representation is unitary. However
for boosts the representation is not unitary since −1(−1)T = I fails.
To ﬁx this we introduce an indeﬁnite inner product on L2(V+
0 , C4, μ0) by
(ψ, χ)η =

V+
0
ψ(p) · χ(p) dμ0(p) =

V+
0
ψμ(p)ημνχν(p) dμ0(p)
(9.107)
This is well-deﬁned and since −1η(−1)T = η we do have the invariance
(u(a, )ψ, u(a, )χ)η = (ψ, χ)η
(9.108)
But if we adopt the indeﬁnite inner product, we no longer have a Hilbert space.
We proceed as follows. Consider the closed subspace
H′′ = {ψ ∈H′ : ψμ(p) = pμf(p)}
(9.109)
where f is some measurable function from V+
0
to C. These are null vectors:
(ψ, ψ)η = 0 for ψ ∈H′′. Then consider the factor space H′/H′′. Elements of
this space are equivalence classes [ψ] of vectors in H′ with ψ ∼ψ′ if ψ −ψ′ ∈H′′.

147
9.4 Photons
t
Theorem 9.4
1. The indeﬁnite inner product is well-deﬁned and positive deﬁnite on the factor
space H′/H′′ and with this inner product it is a Hilbert space denoted
Hphys = H′/H′′
(9.110)
2. The operators u(a, ) deﬁned by (9.105) on H′ determine unitary operators
u(a, ) on Hphys, which give an (irreducible) representation of the proper
Poincaré group.
Proof
With the usual L2 inner product let M be the orthogonal complement of H′′
in H′ so that H′ = M ⊕H′′. The projection from H′ onto M has kernel H′′ and so
gives an identiﬁcation of H′/H′′ and M as vector spaces. The inverse sends ψ ∈M
to [ψ] ∈H′/H′′.
To identify M, note that the condition that ψ = (ψ0, ) ∈H′ be orthogonal to H′′
is the condition that pμψμ(p) = 0. Since p0 = −p0 = −|p|, this says −|p|ψ0(p) +
p·(p) = 0. On the other hand because ψ ∈H′ we have pμψμ(p) = 0 or |p|ψ0(p)+
p · (p) = 0. Together these imply that ψ0(p) = 0 and p · (p) = 0. Thus we have
M = {ψ = (ψ0, ) ∈H′ : ψ0 = 0, p · (p) = 0}
(9.111)
Now consider the indeﬁnite inner product. If ψ′ is in H′ and ψ′′
μ(p) = pμf(p) is in
H′′, then
(ψ′, ψ′′)η =

V+
0
pμψ′μ(p)f(p)dμ0(p) = 0
(9.112)
It follows that the indeﬁnite inner product is well deﬁned on H′/H′′ and for ψ1, ψ2 ∈
H′ we have (ψ1, ψ2)η = ([ψ1], [ψ2])η. So the map from M to H′/H′′ preserves the
indeﬁnite inner product. But the indeﬁnite inner product on M coincides with the
L2 inner product since there is no zeroth component and hence it is positive deﬁnite.
Hence the indeﬁnite inner product is positive deﬁnite on H′/H′′. Furthermore M
is complete with the indeﬁnite inner product since M is a closed subspace of L2.
Hence the same is true for H′/H′′ and it is a Hilbert space. Thus we have the ﬁrst
result and have identiﬁed Hphys and M as Hilbert spaces.
We have already noted that u(a, ) preserves H′. It also preserves H′′ since if
ψν(p) = pνf(p) = ηνσpσf(p) is in H′, then
(−1)ν
μψν(−1p) = (−1)ν
μηνσ(−1)σ
ρpρf(−1p)
= ημρpρf(−1p) = pμf(−1p)
(9.113)
is again in H′′. It follows that we have a representation on Hphys, and since it
preserves the inner product, it is unitary.
Remarks
1. Hphys is the basic Hilbert space, called the physical Hilbert space. This procedure
of going to the factor space is known as Gupta–Bleuler quantization.

148
Electrons and photons
t
2. When we form the factor space, equivalence classes are formed with ψ ∼ψ′ if
ψμ = ψ′
μ + pμf. Returning to spacetime with an inverse Fourier transform this
says that ψ and ψ′ are related by a gauge transformation. Thus the mathemati-
cal equivalence in the construction of the Hilbert space is mirrored by physical
equivalence in the sense that equivalent vectors have the same ﬁeld strength.
3. The identiﬁcation of Hphys with M also gives the equivalence with the quantiza-
tion in the Coulomb gauge on H0. First identify R3 with V+
0 by φ(p) = (|p|, p).
Then deﬁne a unitary map V : H0 →M given by
(V)(φ(p)) =
$
2|p|

0, (p)

(9.114)
One checks that for spacetime translations and rotations
V−1u(a, R)V = u0(a, R)
(9.115)
which establishes the equivalence.
9.5 Electromagnetic ﬁeld
Now we undertake the quantization of the electromagnetic ﬁeld, again as represented
by a potential A satisfying the wave equation □A = 0 and a constraint ∂μAμ = 0. We
skip a Coulomb gauge construction and proceed with a covariant construction. The
strategy is to ﬁrst ignore the constraint, carry out the quantization, and then impose
the constraint after quantization.
The quantization of □A = 0 proceeds as in the scalar case except that now we
use the indeﬁnite inner product. Start with the single particle Hilbert space H =
L2(V+
0 , C4, μ0) and form the symmetric Fock space F = F+(H). The indeﬁnite
inner product (h, g)η = (h, ηg) on H induces an indeﬁnite inner product (ψ, χ)η =
(ψ, (η)χ) on F. If we then deﬁne creation and annihilation operators a†(h), a(h)
as in (5.54), but now with the indeﬁnite inner product, we ﬁnd that on D0
[a(h), a†(h′)] = (h, h′)η
(a†(h)ψ, χ)η = (ψ, a(h)χ)η
(9.116)
So a† is the formal adjoint with respect to the indeﬁnite inner product.
Now as in (8.66) we deﬁne ﬁeld operator A(f) =

Aμ(x)ημνfν(x) dx by
A(f) = a†(+f) + a(+f)
(9.117)
where +f ∈H is deﬁned by
(+f)μ(p) =
√
2πˆfμ(p)
(9.118)
We summarize the results for this ﬁeld.

149
9.5 Electromagnetic ﬁeld
t
Theorem 9.5
For real f ∈S(R4, R4) let A(f) be the symmetric operator valued
distribution deﬁned on (F, (·, ·)η) by (9.117). Then
1. (Field equation) (−□+ m2)A = 0.
2. (Covariance) There is a representation U(a, ) of the proper Poincaré group
preserving the indeﬁnite inner product (·, ·)η such that
U(a, )Aμ(x)U(a, )−1 = ν
μAν(x + a)
(9.119)
3. (Locality)
[A(f), A(g)] = 1
i ημν < fμ, Egν >
(9.120)
The representation of the Poincaré group is U(a, ) = (u(a, )) where u(a, )
is deﬁned in (9.105) and the covariance (9.119) is equivalent to
U(a, )A(f)U(a, )−1 = A(fa,)
(9.121)
where (fa,)μ(x) = (−1)ν
μfν(−1(x −a)). All statements can be checked as for the
scalar ﬁeld, Theorem 8.2.
Now we impose the constraint ∂μAμ = 0 not as an operator identity but on
wavefunctions by passing to the subspace
F′ ≡F+(H′)
(9.122)
where H′ deﬁned in (9.104) has pμψμ(p) = 0. The indeﬁnite inner product is
nonnegative on F′. We consider the null subspace
F′′ = {ψ ∈F′ : (ψ, ψ)η = 0}
(9.123)
By the Schwarz inequality, elements of F′′ are orthogonal to any element of F′.
Then the indeﬁnite inner product is well-deﬁned on F′/F′′ with ([ψ1], [ψ2])η =
(ψ1, ψ2)η. Furthermore it is positive deﬁnite. The physical Hilbert space is the
completion
Fphys = F′/F′′
(9.124)
We will see later that the completion is unnecessary.
Theorem 9.6
1. The representation U(a, ) on F determines a unitary representation of the
Poincaré group on Fphys.
2. If ∂μfμ = 0, then the ﬁeld operator A(f) acts on a dense domain in Fphys.
Proof
U(a, ) preserves F′ with its inner product and F′′ and hence determines an
inner product preserving operator on F′/F′′ which extends to a unitary on Fphys.
If ∂μfμ = 0, then
pμ(+fμ)(p) = (+(−i∂μfμ))(p) = 0
(9.125)

150
Electrons and photons
t
so +f ∈H′. Hence A(f) preserves ﬁnite particle vectors in F′. Furthermore it
preserves ﬁnite particle vectors in F′′ since if (ψ, ψ)η = 0, then
(A(f)ψ, A(f)ψ)η = (ψ, A(f)2ψ)η
≤(ψ, ψ)1/2
η (A(f)2ψ, A(f)2ψ)1/2
η
= 0
(9.126)
Thus A(f) gives an operator on ﬁnite particle vectors in F′/F′′.
Remark
Without the restriction ∂μfμ = 0, ﬁeld operators A(f) do not act on Fphys.
However the ﬁeld strength Fμν = ∂μAν −∂νAμ does act on Fphys. For a family of
test functions hμν we have F(h) = A(δh) where (δh)μ = ∂ν(hμν −hνμ) and this does
satisfy ∂μ(δh)μ = 0.
We also can identify our physical Hilbert space Fphys as a multi-photon Fock
space.
Theorem 9.7
There is a natural identiﬁcation
Fphys ≈F+(Hphys)
(9.127)
where Hphys = H′/H′′ is the single photon Hilbert space.
Proof
First work with the usual inner product. Since H′ = M ⊕H′′ we have the
identiﬁcation of Fock spaces (see problem 9.10)
F′ = F+(H′) ≈F+(M) ⊗F+(H′′)
(9.128)
Separate off the vacuum component and write F+(H′′) = C ⊕F+
≥1(H′′) and make
the identiﬁcation C ⊗F+(M) ≈F+(M) and we have
F′ ≈F+(M) ⊕(F+(M) ⊗F+
≥1(H′′))
(9.129)
Every element of F+(M) ⊗F+
≥1(H′′) is in F′′ since all entries have at least one
element in H′′. No element of F+(M) is in F′′. We conclude that F′′ = F+(M) ⊗
F+
≥1(H′′) and have the identiﬁcation
F′ ≈F+(M) ⊕F′′
(9.130)
It follows that F+(M) ≈F′/F′′ as vector spaces under the map ψ →[ψ]. The
identiﬁcation preserves the indeﬁnite inner product as we have seen. Thus F′/F′′
with the indeﬁnite inner product inherits completeness from F+(M), the completion
in (9.124) was unnecessary, and F+(M) ≈F′/F′′ = Fphys as Hilbert spaces. Since
also F+(M) ≈F(Hphys) we have the result.
Problem 9.10
Show that if a Hilbert space splits as H = H1 ⊕H2, then there is
a unitary operator V : F+(H) #→F+(H1) ⊗F+(H2) such that

151
9.5 Electromagnetic ﬁeld
t
1. If U = U1 ⊕U2 is unitary on H, then
V(U)V−1 = (U1) ⊗(U2)
2. If h = (h1, h2), then
Va(h)V−1 = a(h1) ⊗I + I ⊗a(h2)
Problem 9.11
Show that U(a, )Fμν(x)U(a, )−1 = σ
μρ
νFσρ(x + a).
Remarks
For both electrons and photons we have two kinds of ﬁelds. The ﬁelds
ψ, A are basic for the construction, but are not self-adjoint operators on a Hilbert
space and are not regarded as observables. From them one can construct current den-
sities jμ = i ˜ψγ μψ (we only did Q =

j0) and ﬁeld strengths Fμν = ∂μAν −∂νAμ
which are self-adjoint operators on a Hilbert space and are regarded as observables.
The natural next step would be to quantize the combined system of electrons and
photons as described by the equations (7.77). This is known as quantum electro-
dynamics. There has been very little mathematical progress on this problem. There
are expressions for scattering amplitudes given as formal expansions in the charge e.
The coefﬁcients in these expansions are given by formal integrals, some of which are
badly divergent. Nevertheless physicists have developed consistent methods for inter-
preting these integrals known as renormalization. When renormalized, the scattering
amplitudes for the interactions of electrons and photons agree with experiments with
an accuracy of up to 11 signiﬁcant ﬁgures. This spectacular agreement is one reason
that quantum ﬁeld theory continues to be a fascinating subject.
Notes on chapter 9:
For a discussion of the groups O(n, m), Spin(n, m), see
Choquet-Bruhat and DeWitt-Morette (1989).
The universal covering group of L↑
+ can be identiﬁed as SL(2, C) the complex 2×2
matrices with determinant 1. Our group Spin↑(1, 3) is the so-called ( 1
2, 0) ⊕(0, 1
2)
reducible representation of SL(2, C).
The general treatment of irreducible representations of the Poincaré group was
originally due to Wigner and can be found in many places, for example Ohnuki
(1988).
For Newton–Wigner coordinates see Newton and Wigner (1949).
There is a fairly large literature on quantum ﬁelds with external potentials, but no
deﬁnitive reference. The examples of problem 8.10 and problem 9.8 were chosen
more for simplicity than physical relevance.
For a discussion of the quantization of the electromagnetic ﬁeld in various gauges,
see Stocchi and Wightman (1974).

10
Field theory on a manifold
In this chapter we construct a scalar quantum ﬁeld operator on a general class of
manifolds.1 This is the mathematics appropriate for modeling the propagation of
quantum particles and ﬁelds in a gravitational ﬁeld. It is particularly relevant for
extreme situations like black holes and the early universe where quantum effects are
important. However we conﬁne the treatment to basic constructions.
10.1 Lorentzian manifolds
A Lorentzian manifold is a pair (M, g) consisting of a d-dimensional manifold M
and a Lorentzian metric g. The latter is a symmetric nondegenerate 2-tensor with
signature (−, +, . . . , +). This means that for each point p ∈M there is a symmetric
nondegenerate bilinear form gp(v, w) on the tangent space Mp such that the associ-
ated matrix has one negative and d −1 positive eigenvalues. Local coordinates {xμ}
give a basis {∂/∂xμ} for Mp and the matrix in this basis is
gμν(p) = gp(∂/∂xμ, ∂/∂xν)
(10.1)
A general tangent vector v ∈Mp is written v = vμ∂/∂xμ (summation convention)
and then
gp(v, v) = gμν(p)vμvν
(10.2)
In terms of the dual basis {dxμ} for the cotangent space we have
gp = gμν(p)dxμdxν
(10.3)
Minkowski space is the special case M = R4, gμν = ημν.
We classify the tangent vectors according to the sign of gp(v, v). The vector
v ∈Mp is spacelike if gp(v, v) > 0, it is lightlike if gp(v, v) = 0, and it is
timelike if gp(v, v) < 0. The timelike vectors form a cone with two components.
One component is designated as future directed and one component is designated as
1 This chapter assumes more knowledge about manifolds than elsewhere in the book. In particular we
assume the reader is familiar with the deﬁnitions and basic properties of manifolds, tensors, metrics,
etc. This chapter is not referred to elsewhere and can be skipped.
152

153
10.1 Lorentzian manifolds
t
past directed. We assume that this can be done in a continuous way over the whole
manifold, that is the manifold has a time orientation. There is an associated splitting
of lightlike vectors.
A curve x : [a, b] →M is timelike if the tangent vectors dx/dτ = x∗(d/dτ) are
timelike at all points on the curve. Similarly we deﬁne lightlike and spacelike curves.
A curve is causal if its tangent vectors are either timelike or lightlike. A causal curve
is future directed if the tangent vectors are all future directed. Future directed causal
curves are the possible world lines of particles. If x is future directed and timelike,
the elapsed proper time is deﬁned as
 b
a
#
−gx(τ)
 dx
dτ , dx
dτ

dτ
(10.4)
Timelike curves with ﬁxed endpoints minimizing proper time are geodesics. These
are the trajectories of freely falling objects.
For any point p ∈M deﬁne the future and past of the point by
J±(p) = {q ∈M : ∃a future/past causal curve from p to q}
(10.5)
We also deﬁne J±(A) = ∪p∈AJ±(p) for any A ⊂M.
A hypersurface  is a submanifold of dimension d −1. For p ∈ the tangent
space p is identiﬁed as a d −1-dimensional subspace of Mp. There is also a one-
dimensional subspace of normal vectors N deﬁned by the condition gp(N, v) = 0 for
all v ∈p. The hypersurface  is spacelike if the nonzero tangent vectors p are
spacelike for all p ∈. It is equivalent to say that the nonzero normal vectors N are
timelike.
A spacelike hypersurface is a Cauchy surface if every endless causal curve
intersects it exactly once.
Theorem 10.1
The following conditions on a Lorentzian manifold (M, g) are
equivalent.
1. There exist no closed causal curves2 and the set J+(p) ∩J−(q) is compact for all
p, q ∈M.
2. There is Cauchy surface .
3. (M, g) is diffeomorphic to a manifold (R × , g′) for which t = {t} ×  is a
Cauchy surface for all t.
If these conditions hold, we say that (M, g) is globally hyperbolic.
2 This includes a prohibition on “almost closed” causal curves; see Bär Ginoux and Pfäfﬂe (2007) for the
deﬁnition.

154
Field theory on a manifold
t
10.2 Classical ﬁelds on a manifold
We study the Klein–Gordon equation on a globally hyperbolic Lorentzian manifold
(M, g). It has the form
(−□+ m2)u = 0
(10.6)
where in local coordinates
□u = | det g|−1/2 ∂
∂xμ

| det g|1/2gμν ∂u
∂xν

(10.7)
and {gμν} is the inverse matrix to {gμν}.
Let  be a spacelike hypersurface and let n be the vector ﬁeld of forward directed
unit normal vectors on . A real solution u of (−□+ m2)u = 0 has data on
(, n) consisting of the restriction u and the normal derivative given in local
coordinates by
∂u
∂n ≡nμ ∂u
∂xμ


(10.8)
We call a solution regular if it is C∞and if the data on any Cauchy surface have
compact support.
The basic existence and uniqueness theorem is:
Theorem 10.2
Let (M, g) be globally hyperbolic and let (, n) be a Cauchy surface
with forward unit normal n. Then for any f, g ∈C∞
0 () there exists a unique regular
solution u of (−□+ m2)u = 0 such that u = f and ∂u/∂n = g.
For any smooth functions u, v on M and any Cauchy surface  deﬁne
σ(u, v) =



u ∂v
∂n −∂u
∂nv

dμ
(10.9)
where μ is the measure on  induced by the Riemannian volume form on . Let
O be an open set in M bounded by two Cauchy surfaces 1, 2 and say 2 lies to
the future of 1. Then Green’s identity says that for any smooth functions u, v

O
&
u(−□+ m2)v −v(−□+ m2)u
'
dμM = σ2(u, v) −σ1(u, v)
(10.10)
Here μM is the measure on M induced by the Lorentzian volume form, in local
coordinates dμM = | det g|1/2dx. If u, v are regular solutions, then the left side
vanishes. Hence σ(u, v) is independent of  and we can denote it just by σ(u, v).
Next we need advanced and retarded fundamental solutions. In theorem 7.2 these
have already been constructed for Minkowski space.
Theorem 10.3
Let (M, g) be globally hyperbolic. Then there exist linear operators
E± : C∞
0 (M) →C∞(M) such that

155
10.3 Quantum ﬁelds on a manifold
t
(−□+ m2)E±f = E±(−□+ m2)f = f
(10.11)
and such that
supp (E±f) ⊂J±(supp f)
(10.12)
From these fundamental solutions we construct the propagator
E = E+ −E−
(10.13)
For any f ∈C∞
0 (M) the function u = Ef is a regular solution of the Klein–Gordon
equation, and it turns out every regular solution has this form.
Let u be a regular solution regarded as a distribution. For a test function f ∈
C∞
0 (M) we have
< u, f >=

M
uf dμM
(10.14)
Then we have the following result which expresses the solution in terms of its data
on any Cauchy surface.
Lemma10.1
Let u be a regular solution of (−□+m2)u = 0 on a globally hyperbolic
manifold. Then for any f ∈C∞
0 (M)
< u, f >= σ(u, Ef)
(10.15)
Proof
We can assume that the manifold has the form R ×  with Cauchy surfaces
t = {t} × . By Green’s identity we have
σ0(u, E+f) −σ−t(u, E+f) =

(−t,0)×
uf dμM
(10.16)
But E+f vanishes on −t for t sufﬁciently large. Thus taking the limit t →∞we
have
σ0(u, E+f) =

(−∞,0)×
uf dμM
(10.17)
Similarly
σ0(u, E−f) = −

(0,∞)×
uf dμM
(10.18)
Taking the difference of the last two equations gives the result.
10.3 Quantum ﬁelds on a manifold
We want to quantize the classical ﬁeld theory just discussed. Generalizing the
Minkowski space case we seek to solve the Klein–Gordon equation with data on
some Cauchy surface  which satisfy the CCR.

156
Field theory on a manifold
t
For the Cauchy data we suppose we have a pair of operator valued distributions
φ(h), π(h). For each h ∈C∞
0 () these are symmetric operators on a dense domain in
some complex Hilbert space H. They are required to satisfy
[φ(h1), φ(h2)] = 0
[π(h1), π(h2)] = 0
[φ(h1), π(h2)] = i < h1, h2 >
(10.19)
where < h1, h2 >=

h1h2dμ. Equivalently if we deﬁne for  = (φ, π) and
H = (h1, h2)
σ(, H) = φ(h2) −π(h1)
(10.20)
and deﬁne
σ(H, H′) =< h1, h′
2 > −< h2, h′
1 >
(10.21)
then
[σ(, H), σ(, H′)] = iσ(H, H′)
(10.22)
Now we evolve in time and deﬁne φ(f) for f ∈C∞
0 (M) by analogy with (10.15) as
φ(f) = σ(, ρ(Ef))
(10.23)
where
ρ(u) =

u, ∂u
∂n

(10.24)
are the data on  for a solution u.
Theorem 10.4
For f ∈C∞
0 (M) the ﬁeld operator φ(f) satisﬁes the ﬁeld equation
(−□+ m2)φ = 0
(10.25)
and
[φ(f1), φ(f2)] = −i < f1, Ef2 >
(10.26)
In particular the commutator vanishes if f1, f2 have spacelike separated supports,
that is if suppf1 ∩J±(suppf2) = ∅(locality).
Proof
The operator □is symmetric for the inner product (10.14) so the meaning of
the ﬁeld equation is φ((−□+ m2)f) = 0. This follows from E(−□+ m2) = 0.
For the second point we compute
[φ(f1), φ(f2)] =
&
σ(, ρ(Ef1)), σ(, ρ(Ef2))
'
= iσ

ρ(Ef1), ρ(Ef2)

= iσ(Ef1, Ef2)
= −i < f1, Ef2 >
(10.27)
where the last step follows from (10.15).

157
10.3 Quantum ﬁelds on a manifold
t
Remarks
1. The construction does not depend on the choice of Cauchy surface. Indeed we
can formulate it so that there is no reference to a particular Cauchy surface as
follows. Consider the space of regular solutions u of the Klein–Gordon equation
with symplectic form σ(u, v). Let R(u) be a representation of the CCR over this
space, that is we have a family of densely deﬁned operators R(u) on a Hilbert
space H such that R(u) is linear in u and
[R(u), R(v)] = iσ(u, v)
(10.28)
Deﬁne the ﬁeld operator φ(f) by
φ(f) = R(Ef)
(10.29)
This satisﬁes the ﬁeld equation (10.25) and has the commutator (10.26) just as in
the theorem.
Now if we pick a Cauchy surface , we can deﬁne σ(, H) = R(ρ−1
 H) where
ρ−1
 H is the unique regular solution with data H on . Then
[σ(, H), σ(, H′)] = iσ(ρ
−1H, ρ
−1H′) = iσ(H, H′)
(10.30)
and φ(f) = σ(, ρ(Ef)) so we recover our earlier construction.
2. There is still the question of which representation of the CCR to take. In this
generality there is no deﬁnitive answer. Without a timelike symmetry there is no
Hamiltonian and so we cannot ask for a positive energy representation as we did
before. There is also no vacuum to use as a reference point so it is also difﬁcult to
identify particles. One has to proceed on a case by case basis.
3. The construction does respect the principle of general covariance mentioned at
the beginning of chapter 7. We made no special choice of coordinates.
Problem 10.1
Show that representations of the CCR as deﬁned by (10.19) or
(10.22) exist by making an explicit construction.
Problem10.2
In the special case of Minkowksi space (R4, η), take  = {0} × R3
and take σ(, H) given by (8.63). Show that the new deﬁnition of the ﬁeld φ(f) =
σ(, ρ(Ef)) agrees with the old deﬁnition (8.66).
Notes on chapter 10: These topics are covered by Wald (1994) and by
Bär Ginoux and Pfäfﬂe (2007).
In spite of the uncertainty in the choice of a representation of the CCR it has
been possible to identify a class of representations with desirable physical properties.
These are characterized by the requirement that correlation functions have certain
prescribed “Hadamard singularities” at coinciding points, see Wald (1994).

158
Field theory on a manifold
t
For a mathematical formulation of the principle of general covariance, see Dimock
(1980) or Brunetti Fredenhagen and Verch (2003).
By studying a scalar ﬁeld on the spacetime manifold for a collapsing black hole,
Hawking was led to his famous prediction that black holes emit thermal radiation.
See Bachelot (1999).

Part III
Probabilistic methods


11
Path integrals
As we have seen quantum mechanics is fundamentally probabilistic, but it is a special
kind of noncommutative probability. Nevertheless the techniques of standard proba-
bility theory can also be useful. In the remainder of the book we explore some of the
ways this occurs.
In this chapter we return to the consideration of a single non-relativistic parti-
cle and develop some new representations of the dynamics. These are the Feynman
path integrals which express the quantum dynamics as an integral over all possi-
ble classical paths with a special weighting. For the single particle Hamiltonian
H = −/2 + V and ψ, χ ∈L2(R3) a typical integral is
(ψ, e−iHtχ) =

ψ(ω(0)) exp

−i
 t
0
V(ω(s))ds

χ(ω(t))dω
(11.1)
Here the “integral” is over all possible paths ω : [0, t] →R3 and “dω” is supposed
to be some kind of measure on these paths. Actually it has not been possible to make
sense of this within the context of standard measure theory. But if one replaces the
time evolution e−iHt by e−Ht, that is if we go to imaginary time, then one can give a
rigorous formulation. This is what we study in this chapter. This gets us away from
the basic dynamics but still can be useful in an indirect way. For example one can
study properties of the Hamiltonian through the semi-group e−Ht as represented by
path integrals. Similar representations occur in quantum ﬁeld theory where they are
crucial for a mathematical analysis. We explore this in subsequent chapters.
11.1 Probability
We start by reviewing some deﬁnitions. A measure space is a triple (M, , μ) con-
sisting of a set M, a σ-algebra of subsets , and a measure μ :  →[0, ∞]. We
consider probability measure spaces which have μ(M) = 1. In applications M rep-
resents all possible outcomes, A ∈ represent events, and μ(A) is interpreted as the
probability that A occurs.
161

162
Path integrals
t
Random variables are measurable functions X : M →R. The probability that X
takes values in a Borel set B is
P(X ∈B) = μ(X−1[B]) ≡m(B)
(11.2)
The set function m(B) is a probability measure on R called the distribution of X.
It contains all relevant information about X. For any Borel function f the function
f(X) = f ◦X is again a random variable and we have the expectation or mean
E(f(X)) ≡

M
f(X)dμ =

R
f(x)dm(x)
(11.3)
if the integrals exist. The identity of the two integrals is a standard argument. First
verify it for simple functions, then by monotone limits for positive functions, and
ﬁnally for any integrable function. In particular there is the characteristic function of
X, which is a function on R deﬁned by
(s) = E(eisX) =

eisxdm(x)
(11.4)
As the Fourier transform of the measure m it uniquely determines m. Indeed the prob-
ability distribution m determines a tempered distribution m and the Fourier transform
is bijective on S′(R) – see appendix C.
More generally suppose we have n random variables X1, . . . , Xn on a probability
measure space (M, , μ). Equivalently we have a vector-valued random variable
X = (X1, . . . , Xn) : M →Rn. Again the probability that the random variables take
values in a Borel set B ⊂Rn is
P

(X1, . . . , Xn) ∈B

= μ(X−1[B]) ≡m(B)
(11.5)
The distribution m(B) is now a Borel measure on Rn. For any Borel function f on Rn
E(f(X)) =

M
f(X1, . . . , Xn)dμ =

Rn f(x1, . . . , xn)dm(x)
(11.6)
The characteristic function is  : Rn →R deﬁned by
(s1, . . . , sn) = E(ei 
i siXi) =

ei 
i sixidm(x)
(11.7)
and it determines the distribution.
We generalize still further and suppose we have an inﬁnite family {Xα}α∈A of
random variables on a space (M, , μ), called a stochastic process. For any ﬁnite
ordered subset I = (α1, . . . , αn) from A we have the family of random variables
XI = (Xα1, . . . , Xαn) and we consider their joint distribution
P(XI ∈B) = μ(X−1
I
(B)) ≡mI(B)
(11.8)
Then
E(f(XI)) =

M
f(XI)dμ =

Rn f(x)dmI(x)
(11.9)

163
11.2 Gaussian processes
t
The joint distributions must satisfy some consistency conditions. Let π be a per-
mutation of (1, . . . , n). This induces mappings πI = (απ(1), . . . , απ(n)) on the index
set and πx = (xπ(1), . . . , xπ(n)) on Rn. Then the event Xπ(I) ∈πB is the same as the
event XI ∈B and hence
mπ(I)(π(B)) = mI(B)
(11.10)
Also if I′ = (I, α), then the event XI′ = (XI, Xα) ∈B × R is the same as the event
XI ∈B and hence
mI′(B × R) = mI(B)
(11.11)
The family of all ﬁnite-dimensional distributions is enough to specify the full
structure for one has the following result on the existence of stochastic processes
Theorem11.1(Kolmogorov)
Let A be an index set and suppose for each ﬁnite ordered
subset I in A there is a Borel probability measure mI on R|I|. The measures are
assumed to satisfy the consistency conditions (11.10), (11.11). Then there exists a
probability measure space (M, , μ) and a family of random variables {Xα}α∈A
such that for any ﬁnite ordered subset I in A the random variables XI have the
distributions mI.
There is also a uniqueness result which says that (under some further conditions)
any two realizations are equivalent by an isomorphism of measure spaces.
11.2 Gaussian processes
Now consider a special class of random variables, the Gaussian random variables.
A random variable X is Gaussian if there are constants c, a such that for any Borel
B ⊂R the distribution is the normal distribution
P(X ∈B) = m(B) = (2πc)−1/2

B
exp

−(x −a)2
2c

dx
(11.12)
Then for any Borel function f
: R →R we have that f(X) is integrable iff
f(x) exp(−(x −a)2/2c) is integrable on R in which case
E(f(X)) =

f(x)dm(x) = (2πc)−1/2

R
f(x) exp

−(x −a)2
2c

dx
(11.13)
For the second step one again veriﬁes the identity successively for simple functions,
positive functions, and integrable functions. In particular the characteristic function
is (see problem 1.3)
(s) = E(eisX) = exp

ixa −1
2cs2

(11.14)

164
Path integrals
t
Taking derivatives at s = 0 we ﬁnd that X has mean E(X) = a and E(X2) = c + a2.
The variance is then
Var(X) ≡E(X2) −E(X)2 = c
(11.15)
More generally a family of random variables X = (X1, . . . , Xn) is jointly Gaussian
if there is an n × n positive deﬁnite symmetric matrix C = {Cij} and a ∈Rn such
that for any Borel B ⊂Rn we have the joint distribution
P(X ∈B) = m(B)
= (2π)−n/2(det C)−1/2

B
exp

−1
2(x −a) · C−1(x −a)

dx
(11.16)
(Positive deﬁnite means x · Cx ≥0 and x · Cx = 0 iff x = 0.) It is clear that such
structures exist. Indeed we can take (M, μ) = (Rn, m) and Xi(x) = xi. For any Borel
function f : Rn →R we have
E(f(X))
= (2π)−n/2(det C)−1/2

Rn f(x) exp

−1
2(x −a) · C−1(x −a)

dx
(11.17)
if the integral exists. In particular we ﬁnd for the characteristic function (s) =
(s1, . . . , sn)
(s) = E

eis·X
= (2π)−n/2(det C)−1/2

Rn eis·x exp

−1
2(x −a) · C−1(x −a)x

dx
= exp

is · a −1
2s · Cs

(11.18)
Taking derivatives at s = 0 we ﬁnd the mean and covariance are
E(Xi) = ai
E(XiXj) −E(Xi)E(Xj) = Cij
(11.19)
The mean and the covariance completely characterize the family of Gaussian random
variables.
Finally suppose we have an inﬁnite set A and functions a : A →R and symmetric
C : A × A →R such that for any α1, . . . , αn ∈A the matrix Cij = C(αi, αj) is posi-
tive deﬁnite. Then we can deﬁne a Gaussian process with mean a and covariance C
to be a collection of random variables {Xα} indexed by α ∈A such that for any ﬁnite
collection I = (α1, α2, . . . , αn) the random variables XI = (Xα1, . . . , Xαn) are jointly
Gaussian with means aI = (a(α1), . . . , a(αn)) and covariance CI = {C(αi, αj)}. In
particular then
E(Xα) = a(α)
E(XαXβ) −E(Xα)E(Xβ) = C(α, β)
(11.20)

165
11.3 Brownian motion
t
Such a Gaussian process exists as a consequence of the theorem 11.1 once we
show that the consistency conditions on the ﬁnite-dimensional measures mI are
satisﬁed. To show such measures are equal it sufﬁces to show that the character-
istic functions are equal. Thus it sufﬁces to consider the characteristic function I
for XI, which is
I(s) = exp
⎛
⎝i
n

i=1
sia(αi) −1
2
n

i,j=1
siC(αi, αj)sj
⎞
⎠
(11.21)
The permutation condition (11.10) translates as πI(πs) = I(s). The extension
condition (11.11) translates as (I,αn+1)(s, 0) = I(s). Both are easily checked and
hence the process exists.
Problem 11.1
Let C be a symmetric positive deﬁnite matrix.
1. Show that C is invertible and that C−1 is symmetric and positive deﬁnite.
2. Show that there exists M > 0 so that x · Cx ≥M|x|2, hence also for C−1.
Problem 11.2
Do the integral in (11.18). (Hint: diagonalize C.)
Problem 11.3
1. Show that a Gaussian random variable is in Lp for all 1 ≤p < ∞.
2. Justify the differentiations in computing the mean and covariance in (11.19).
11.3 Brownian motion
This is a particular example of a Gaussian process indexed by R+ = [0, ∞). A family
of random variables Xt, t ≥0 is a Brownian motion if it is Gaussian with mean and
covariance
E(Xt) = 0
E(XtXs) = min(t, s)
(11.22)
For this to be well deﬁned we need for any distinct t1, t2, . . . , tn that the matrix
{min(ti, tj)} is positive deﬁnite. To verify this it sufﬁces to assume t1 < t2 < · · · < tn.
Then we have the identity (with t0 = 0)

ij
xixj min(ti, tj) =
n

i=1
(ti −ti−1)
⎛
⎝
n

j=i
xj
⎞
⎠
2
(11.23)

166
Path integrals
t
This vanishes iff n
j=i xj = 0 for i = 1, . . . , n which occurs iff xi = 0. Hence the
matrix is positive deﬁnite.
Now Xt has mean zero and variance E(X2
t ) = t. Hence for t = 0, X0 takes the
constant value X0 = 0. If t > 0, we compute the probability that Xt is in a Borel
set B as
P(Xt ∈B) =

B
pt(x)dx
(11.24)
where pt is the even function
pt(x) = (2πt)−1/2e−x2/2t
(11.25)
This is saying that for t small Xt takes values near the origin with high probability,
while for t large that probability is widely spread around the origin. These features
allow the interpretation that Xt describes the location at time t of a diffusing particle
which starts at the origin at t = 0 and moves randomly as time evolves.
More generally a Brownian motion starting at x ∈R is a family of Gaussian
random variables Xx
t with mean x and variance t deﬁned by
Xx
t = Xt + x
(11.26)
Then we ﬁnd
P(Xx
t ∈B) = P(Xt ∈B −x)
=

B−x
pt(y)dy =

B
pt(y −x)dy
(11.27)
Similarly if pt(x −·)f is integrable, we compute
E(f(Xx
t )) = E(f(Xt + x))
=

f(y + x)pt(y)dy =

pt(x −y)f(y)dy
(11.28)
Note the following facts. The sum of two Gaussian random variables is again
Gaussian. Hence for s < t, Xx
t −Xx
s = Xt −Xs is Gaussian with mean zero and
variance
E((Xx
t −Xx
s)2) = E((Xt −Xs)2) = t −s −s + s = t −s
(11.29)
Furthermore for s1 ≤t1 ≤s2 ≤t2 we have that Xx
t1 −Xx
s1 and Xx
t2 −Xx
s2 are
uncorrelated since
E

(Xx
t1 −Xx
s1)(Xx
t2 −Xx
s2)

= t1 −t1 −s1 + s1 = 0
(11.30)
For Gaussian random variables uncorrelated means independent so Xx
t1 −Xx
s1 and
Xx
t2 −Xx
s2 are independent, which means that the joint distribution is the product of
the individual distributions. One says that the process has independent increments.
In particular for 0 < s < t the random variables Xx
t −Xx
s and Xx
s = Xx
s −Xx
0 are
independent and so

167
11.3 Brownian motion
t
E

f(Xx
s, Xx
t −Xx
s)

=

ps(x −y1) pt−s(y2) f(y1, y2) dy1dy2
(11.31)
Then we compute
E(f1(Xx
s)f2(Xx
t )) = E(f1(Xx
s)f2(Xx
s + (Xx
t −Xx
s)))
=

ps(x −y1) pt−s(y2) f1(y1)f2(y1 + y2) dy1dy2
=

ps(x −y1) f1(y1) pt−s(y1 −y2) f2(y2) dy1dy2
(11.32)
Similarly for 0 < t1 < t2 < · · · < tn
E

f1(Xx
t1) · · · fn(Xx
tn)

=

pt1(x −y1)f1(y1) · · · ptn−tn−1(yn−1 −yn)fn(yn)dy1 · · · dyn
(11.33)
Specializing to characteristic functions we have for the joint distribution
P(Xx
t1 ∈B1, . . . , Xx
tn ∈Bn)
=

B1×···×Bn
pt1(x −y1) · · · ptn−tn−1(yn−1 −yn)dy1 · · · dyn
(11.34)
This gives an idea of the character of the measure on paths.
We quote the following regularity result which shows that Brownian paths are
continuous but nowhere differentiable.
Theorem 11.2
There is a construction of Brownian motion Xt on a measure space
(M, μ) with the following properties:
1. Let α < 1/2. Then for almost every ω ∈M the path t →Xt(ω) is Holder
continuous with exponent α, that is there is a constant Cω such that
|Xt(ω) −Xs(ω)| < Cω|t −s|α
(11.35)
2. Let α > 1/2. Then for almost every ω ∈M the path t →Xt(ω) is nowhere
Holder continuous with exponent α.
The construction needs more than the Kolmogorov theorem. Just for the continuity
one way to proceed is to take as the basic probability space the continuous functions
M = {ω ∈C(R+) : ω(0) = 0} and then construct a measure so that the evaluation
maps Xt(ω) = ω(t) give a Brownian motion. This gives a strong meaning to the idea
that we are integrating over a space of paths.
All the above is easily generalized to Rd. We set
Xt = (X1
t , . . . , Xd
t )
(11.36)
where the Xi
t are independent one-dimensional Brownian motions. All the above
formulas generalize. For example we have for a function f on Rd and a point x ∈Rd
E(f(Xx
t )) = (2πt)−d/2

exp

−|x −y|2
2t

f(y)dy
(11.37)

168
Path integrals
t
Problem 11.4
Verify (11.23).
11.4 The Feynman–Kac formula
The connection with single particle quantum mechanics comes via the Laplacian.
We work in d dimensions. With mass m = 1 the free Hamiltonian is H0 = −/2
and for f ∈L2(Rd) we have from (4.8)
(e−H0tf)(x) = (2πt)−d/2

exp

−|x −y|2
2t

f(y)dy
(11.38)
This is the same as (11.37). Thus if Xx
t is Brownian motion in Rd starting at x, then
(e−H0tf)(x) = E

f(Xx
t )

(11.39)
Taking into account that Xx
0 = x another way to write this is
(g, e−H0tf) =

E

g(Xx
0)f(Xx
t )

dx
(11.40)
Now we add a bounded potential to the Hamiltonian
Theorem11.3
(Feynman–Kac formula) Let V be bounded and continuous on Rd and
let H = H0 + V. Then for f, g ∈L2(Rd)
(g, e−Htf) =

E

g(Xx
0) exp

−
 t
0
V(Xx
s)ds

f(Xx
t )

dx
(11.41)
Remark
For the proof we use the Trotter product formula1 which says that if S and
T are self-adjoint and bounded below and S+T deﬁned on D(T)∩D(S) is self-adjoint,
then as a strong limit
lim
n→∞

e−St/ne−Tt/nn
= e−(S+T)t
(11.42)
We apply this with S = H0, T = V. The sum H = H0 + V is self-adjoint on
D(H0) ∩D(V) = D(H0) by theorem 4.1.
Proof
By (11.33) for t1 < t2 < · · · < tn
E

f1(Xx
t1) · · · fn(Xx
tn)

=

e−t1H0f1e−(t2−t1)H0f2 . . . e−(tn−tn−1)H0fn

(x)
(11.43)
1 See for example Reed and Simon (1980: 295).

169
11.5 Oscillator process
t
Thus with tj = jt/n
(g, e−Htf) = lim
n→∞

g,

e−H0t/ne−Vt/nn f

= lim
n→∞

g(x)E
⎛
⎝
n

j=1
exp

−t
nV(Xx
tj)

f(Xx
t )
⎞
⎠dx
= lim
n→∞

E
⎛
⎝g(Xx
0) exp
⎛
⎝−t
n
n

j=1
V(Xx
tj)
⎞
⎠f(Xx
t )
⎞
⎠dx
=

E

g(Xx
0) exp

−
 t
0
V(Xx
s) ds

f(Xx
t )

dx
(11.44)
Here in the last step we have used that
lim
n→∞
t
n
n

j=1
V(Xx
tj) =
 t
0
V(Xx
s) ds
(11.45)
holds almost everywhere. This follows by the continuity of V and the continuity of
paths with the integral interpreted as a Riemann integral. We have also used

g(Xx
0) exp
⎛
⎝−t
n
n

j=1
V(Xx
tj)
⎞
⎠f(Xx
t )

≤|g(Xx
0)||f(Xx
t )|et∥V∥∞
(11.46)
Then since

E

|g(Xx
0)||f(Xx
t )|

dx = (|g|, e−H0t|f|) < ∞
(11.47)
we can use the dominated convergence theorem to take the limit inside the integrals
in (11.44).
Problem 11.5
For h ∈L∞(Rd) and 0 ≤u ≤t show that
(g, e−uH h e−(t−u)Hf)
=

E

g(Xx
0)h(Xx
u) exp

−
 t
0
V(Xx
s)ds

f(Xx
t )

dx
(11.48)
11.5 Oscillator process
The oscillator process (also called the Ornstein–Uhlenbeck process) is deﬁned to be
the Gaussian process Xt indexed by t ∈R with mean and covariance
E(Xt) = 0
E(XsXt) = C(s, t)
(11.49)

170
Path integrals
t
where
C(s, t) = (2π)−1
 eip(s−t)
p2 + 1dp = 1
2e−|t−s|
(11.50)
The second version follows by closing the contour in the upper or lower half plane
depending on this sign of s −t. This is positive deﬁnite since for any sequence
x1, . . . , xn and any choice of points t1, . . . , tn

ij
xixjC(ti, tj) = (2π)−1
 | 
i xieipti|2
p2 + 1
dp ≥0
(11.51)
and it vanishes iff 
i xieipti = 0 for all p which occurs iff xi = 0.
Note that Xt has mean zero and constant variance 1/2. Thus if it is describing
the motion of a particle, it is not diffusive like Brownian motion but stays localized
around the origin. This process also has continuous paths.
The oscillator process is related to the semi-group e−Ht generated by the harmonic
oscillator Hamiltonian which we considered in section 4.4 and which is given by
H = 1
2

−d2
dx2 + x2
(11.52)
Recall that the operator has discrete spectrum and that the lowest eigenvalue is 1/2
with eigenvector 0(x) = π−1/4e−x2/2.
Theorem 11.4
Let Xt be the oscillator process and let f, g be polynomially bounded
functions on R . Then for t > 0
(g0, e−(H−1
2 )tf0) = E(g(X0)f(Xt))
(11.53)
Proof
The covariance matrix for X0, Xt is
C =
 C(0, 0)
C(0, t)
C(t, 0)
C(t, t)

= 1
2

1
e−t
e−t
1

(11.54)
Thus we compute by (11.17)
E(g(X0)f(Xt))
= (2π)−1(det C)−1/2

g(x1) exp

−1
2x · C−1x

f(x2)dx
= π−1(1 −e−2t)−1/2

g(x1) exp

−(1 −e−2t)−1(x2
1 + x2
2 −2x1x2e−t)

f(x2)dx
= et/2(2π sinh t)−1/2

(g0)(x1) exp

−1
2(coth t)(x2
1 + x2
2) + (sinh t)−1x1x2

(f0)(x2)dx
= (g0, e−(H−1
2 )tf0)
(11.55)
The last step follows by Mehler’s formula (4.38).

171
11.6 Application: ground states
t
Remarks
1. There is also a Feynman–Kac formula for the oscillator process. If V is a bounded
continuous function on R and
H′ = H + V = 1
2

−d2
dx2 + x2
+ V
(11.56)
Then
(g0, e−(H′−1
2 )tf0) = E

g(X0) exp

−
 t
0
V(Xs)ds

f(Xt)

(11.57)
2. The fact that Brownian motion and the oscillator process are related to semi-
groups is not accidental. In fact both are (time homogeneous) Markov processes
which roughly means that the future depends only on the present and not on the
past. Such Markov processes always give rise to semi-groups of operators.
11.6 Application: ground states
If a quantum mechanical system has a Hamiltonian for which the bottom of the
spectrum is an eigenvalue, then states in the corresponding eigenspace are called
ground states. These are the states most likely to be occupied. In this section we give
some results about ground states for non-relativistic single particle systems using the
Feynman–Kac formula.
First some deﬁnitions. A function on a measure space (M, μ) is positive, written
f ≥0, if f(m) ≥0 for almost every m and f is not identically zero. A function is
strictly positive, written f > 0, if f(m) > 0 for almost every m. A function f ∈L2
is strictly positive iff (f, g) > 0 for every positive g ∈L2 (see problem below). A
bounded operator A on L2(M, dμ) is positivity improving Af > 0 whenever f ≥0.
This is true iff (g, Af) > 0 whenever f ≥0, g ≥0.
Problem 11.6
Let (M, μ) be a σ-ﬁnite measure space.2 Show that f ∈L2 is
strictly positive iff (f, g) > 0 for every positive g ∈L2.
For example on L2(Rd) consider e−tH0 where H0 is the free Hamiltonian. The
operator e−tH0 has a strictly positive kernel (2πt)−d/2 exp(−|x −y|2/2t) and hence it
is positivity improving.
Lemma 11.1
Let A be a bounded self-adjoint operator on L2(M, μ) which is posi-
tivity improving. If ∥A∥is an eigenvalue, then the eigenspace is spanned by a single
strictly positive function.
2 σ-ﬁnite means there is a sequence of subsets Mi with ﬁnite measure so ∪iMi = M.

172
Path integrals
t
Remark
Since σ(A) ⊂(−∥A∥, ∥A∥), ∥A∥is the largest possible eigenvalue.
Proof
Let ψ be an eigenvector for A with eigenvalue ∥A∥. Since A is reality preserv-
ing both the real and imaginary parts are eigenvectors with eigenvalues ∥A∥. Hence
we may as well assume ψ is real. Then |ψ| ± ψ ≥0 hence A(|ψ| ± ψ) > 0 and
hence
|Aψ| ≤A|ψ|
(11.58)
It follows that
∥A∥∥ψ∥2 = (Aψ, ψ) ≤(|Aψ|, |ψ|) ≤(A|ψ|, |ψ|) ≤∥A∥∥ψ∥2
(11.59)
and hence
(Aψ, ψ) = (A|ψ|, |ψ|)
(11.60)
Write ψ = ψ+ −ψ−where ψ± ≥0. Then |ψ| = ψ+ + ψ−and the last identity
implies that
(Aψ+, ψ−) + (Aψ−, ψ+) = 0
(11.61)
If ψ± are both nonzero, this contradicts the strict positivity. Thus one of them must
be zero and we may assume that ψ−= 0. Thus ψ ≥0. Since ψ = ∥A∥−1Aψ
we have ψ > 0. Finally if ψ′ is another eigenvector, then by the same argument
conclude ψ′ > 0. Then ψ′ cannot be orthogonal to ψ so the eigenspace is one
dimensional.
The next result shows that ground states are unique.
Theorem 11.5
Let H0 = −/2 and let V be a bounded continuous function on Rd
so that H = H0 + V is self-adjoint.
1. The operators e−tH are positivity improving for all t > 0.
2. If H has an eigenvalue at the bottom of the spectrum, then the eigenspace is
spanned by a single strictly positive function.
Proof
For f, g ≥0 we have by the Feynman–Kac formula for Brownian motion
(11.41)
(g, e−tHf) =

E

g(Xx
0) exp

−
 t
0
V(Xx
s)ds

f(Xx
t )

dx
≥e−t∥V∥∞

E

g(Xx
0)f(Xx
t )

dx
= e−t∥V∥∞(g, e−tH0f)
(11.62)
Hence (g, e−tHf) > 0 and e−tH is positivity improving.
If E is a lowest eigenvalue for H, then e−tE = ∥e−tH∥is a highest eigenvalue for
e−tH and the eigenspace is the same. The result now follows by lemma 11.1. This
proves the second point.

173
11.6 Application: ground states
t
Problem 11.7
Let H = H0 + V and let H′ = H0 + V′ be as in the theorem with
isolated lowest eigenvalues E, E′ < 0 and with normalized eigenvectors ψ, ψ′.
1. Show that (ψ, ψ′) > 0.
2. Show that
E′ = lim
t→∞−1
t log(ψ, e−tH′ψ)
(11.63)
3. Show that
ψ′ = lim
t→∞
e−tH′ψ
∥e−tH′ψ∥
(11.64)
Problem 11.8
(Perturbation theory) As in the previous problem suppose ψ, E are
known and V′ = V + λV1. We want to compute E′ = E′(λ) for λ small. More
precisely we want to compute the ﬁrst-order term in an expansion
E′(λ) = E +
dE′
dλ (0)

λ + · · ·
(11.65)
Assuming one can exchange limits and derivatives use the representation (11.63)
and the Feynman–Kac formula to compute the ﬁrst-order term.
(Answer: (dE′/dλ)(0) = (ψ, V1ψ).)
Notes on chapter 11: There are many books on the fundamentals of probability
and stochastic processes, for example Billingsley (1979) or Durrett (1996).
For more on path integrals and their application to physics, see Simon (1979) or
Glimm and Jaffe (1987).
It is possible to make some sense of Feynman’s original real time path integral
(11.1). See Albeverio et al. (2008).

12
Fields as random variables
Now we return to quantum ﬁeld theory. The time zero scalar ﬁelds are a family of
commuting symmetric operators on Fock space. Thinking of the spectral theorem,
this suggests that it may be possible to represent them all as functions on some mea-
sure space. In this chapter we develop this representation, known as the Schrödinger
representation. This representation also leads to a path space representation for the
imaginary time dynamics analogous to that for a single particle.
12.1 More on Gaussian processes
12.1.1 Indexing by an inner product space
We consider Gaussian processes indexed by a real vector space S. We are particularly
interested in the case when S is the Schwartz space S(Rd) but proceed generally. The
covariance is a function C : S ×S →R, which we suppose is an inner product on S.
For any collection h1, . . . , hn of linearly independent elements of S deﬁne an n × n
matrix ˆC by
ˆCij = C(hi, hj)
(12.1)
Then ˆC is positive deﬁnite since for any s1, . . . , sn

ij
sisj ˆCij = C
⎛
⎝
i
sihi,

j
sjhj
⎞
⎠≥0
(12.2)
and since it equals zero iff 
i sihi = 0 which occurs iff si = 0. We deﬁne a Gaussian
random process with covariance C (and mean zero) to be a probability measure space
(M, , μ) and a family of random variables {φ(h)}h∈S linear in h such that for any
ﬁnite collection of linearly independent elements h1, . . . , hn, the random variables
φ(h1), . . . , φ(hn) are jointly Gaussian with mean zero and covariance matrix ˆC. Thus
E

f(φ(h1), . . . , φ(hn)

= (2π)−n/2(det ˆC)−1/2

Rn f(x1, . . . , xn) exp

−1
2x · ˆC−1x

dx
(12.3)
174

175
12.1 More on Gaussian processes
t
The characteristic function is
E(eiφ(h)) = exp

−1
2C(h, h)

(12.4)
and it follows that for any h1, . . . , hn ∈H (not necessarily linearly independent)
E

exp

i
n

i=1
tiφ(hi)

= exp
⎛
⎝−1
2
n

i,j=1
titjC(hi, hj)
⎞
⎠
(12.5)
We also have E(φ(h)) = 0 and E(φ(h1)φ(h2)) = C(h1, h2).
In fact the characteristic function is enough to determine the process. Indeed
if a family of random variables {φ(h)}h∈S satisﬁes (12.4) and is linear in h,
then (12.5) with h1, . . . , hn linearly independent says that the joint distribution for
φ(h1), . . . , φ(hn) is Gaussian with covariance ˆCij = C(hi, hj) as required.
Theorem 12.1
Let S be a real vector space with inner product C. Then a Gaussian
random process {φ(h)}h∈S with covariance C exists.
Remarks
1. Because of the linearity requirement and the restriction to linearly independent
elements, the existence does not follow directly from the Kolmogorov theorem.
2. Just as before (problem 11.3) the random variables φ(h) are in Lp(M, μ) for all
1 ≤p < ∞. Hence the same is true for polynomials in the φ(h). If we assume
that  is the smallest σ-algebra with respect to which the φ(h) are measurable,
then polynomials are dense in L2(M, μ), a result we need later.1
3. In the proof we show more. Let H be the real Hilbert space which is the comple-
tion of S in the inner product C. We construct a family of random variables φ(h)
indexed by h ∈H with the stated properties.
Proof
Pick an orthonormal basis {ei} for H. For any ﬁnite collection of basis ele-
ments the matrix C(ei, ej) = δij is positive deﬁnite. Hence there exists a Gaussian
process {φ(ei)}∞
i=1 with identity covariance by the Kolmogorov theorem as explained
in section 11.2. We have
E(φ(ei)φ(ej)) = C(ei, ej) = δij
(12.6)
Any h ∈H has the expansion h = 
i C(ei, h)ei. Hence we deﬁne
φ(h) =
∞

i=1
C(ei, h)φ(ei)
(12.7)
1 For this result see Segal (1956).

176
Fields as random variables
t
The limit exists in L2(M, μ) since if hN = N
i=1 C(ei, h)ei, then for N > M
∥φ(hN) −φ(hM)∥2 = ∥
N

i=M+1
C(ei, h)φ(ei)∥2 =
N

i=M+1
C(ei, h)2
(12.8)
and this converges to zero as N, M →∞. Note that φ(h) is linear in h. Also we
compute
E(eiφ(hN)) = E

exp

i
N

i=1
C(ei, h)φ(ei)

= exp

−1
2
N

i=1
C(ei, h)2

= exp

−1
2C(hN, hN)

(12.9)
There is a subsequence φ(hNj) that converges to φ(h) almost everywhere and passing
to this subsequence and using the dominated convergence theorem we take the limit
in (12.9) and conclude that E(eiφ(h)) = exp (−C(h, h)/2). This is sufﬁcient to show
that φ(h) is the desired Gaussian process.
Theorem 12.2
E(φ(h1) . . . φ(hn)) =

0
n odd

P
(
{i,j}∈P C(hi, hj)
n even

(12.10)
where the sum is over pairings P = {{i1, j1}, . . . , {in/2, jn/2}} of (1, . . . , n).
Proof
Take the partial derivative ∂n/∂t1 · · · ∂tn[. . . ]ti=0 of (12.5). On the left we get
inE(φ(h1) . . . φ(hn)). On the right we get the coefﬁcient of t1 · · · tn in the power series
expansion of exp

−1
2
n
i,j=1 titjC(hi, hj)

. For this we can ignore terms with i = j.
Also we can drop the factor 1/2 and write it as a sum over unordered pairs {i, j} (two
element subsets) from (1, . . . , n). Then we have
exp
⎛
⎝−

{i,j}
titjC(hi, hj)
⎞
⎠=

{i,j}
exp

−titjC(hi, hj)

=

{i,j}

1 −titjC(hi, hj) + . . .

= 1 +

Q

{i,j}∈Q

−titjC(hi, hj)

+ . . .
(12.11)
where the sum over Q is over collections of pairs {i, j} from (1, . . . , n). But only
collections which give a partition of (1, . . . , n) will contribute. This is only possible
if n is even in which case we get the announced sum over pairings. There is also a
factor (−1)n/2 which matches the in on the left. Hence the result.

177
12.1 More on Gaussian processes
t
12.1.2 Wick monomials
We next introduce Wick monomials.2 These are polynomials in the random variables
φ(h) with the property that monomials of different degree are orthogonal. First deﬁne
: eiφ(h) :C= eiφ(h) exp
1
2C(h, h)

(12.12)
This is deﬁned so that
E(: eiφ(h) :C) = 1
(12.13)
Then we deﬁne Wick monomials by
: φ(h1) . . . φ(hn) :C = 1
in
∂n
∂t1 . . . ∂tn

: exp

i

i
tiφ(hi)

:C

t=0
= 1
in
∂n
∂t1 . . . ∂tn
⎡
⎣exp
⎛
⎝i

i
tiφ(hi) + 1
2

ij
titjC(hi, hj)
⎞
⎠
⎤
⎦
t=0
(12.14)
This looks like the generating function for Hermite polynomials and indeed Wick
monomials are a generalization of Hermite polynomials. We have explicitly
: φ(h) :C = φ(h)
: φ(h1)φ(h2) :C = φ(h1)φ(h2) −C(h1, h2)
: φ(h1)φ(h2)φ(h3) :C = φ(h1)φ(h2)φ(h3) −φ(h1)C(h2, h3)
−φ(h2)C(h1, h3) −φ(h3)C(h1, h2)
(12.15)
and in general
: φ(h1) . . . φ(hn) :C= φ(h1) . . . φ(hn) + lower order terms
(12.16)
It follows that Wick monomials span the dense subspace of polynomials in
L2(M, μ). Also note that : φ(h1) . . . φ(hn) :C is linear in each hi and is invariant
under permutations of the hi.
Lemma 12.1
1. For a single Wick monomial
E

: φ(h1) . . . φ(hn) :C

= 0
(12.17)
2. For a pair of Wick monomials
E

: φ(h1) . . . φ(hn) :C: φ(g1) . . . φ(gm) :C

=

0
n ̸= m

π C(h1, gπ(1)) . . . C(hn, gπ(n))
n = m

(12.18)
2 There is a connection with Wick ordering explained in the next section

178
Fields as random variables
t
where the sum is over permutations π of (1, 2, . . . , n).
Proof
The ﬁrst follows by taking derivatives of
E

: exp(i

i
tjφ(hj)) :C

= 1
(12.19)
For the second note the identity.
: eiφ(h) :C: eiφ(g) :C=: eiφ(h+g) :C e−C(h,g)
(12.20)
Let h = n
i=1 tihi and g = m
j=1 sjgj and take the expectation which gives
E
⎛
⎝: exp

i

i
tiφ(hi)

:C: exp

i

j
sjφ(gj)

:C
⎞
⎠
= exp
⎛
⎝−

ij
tisjC(hi, gj)
⎞
⎠
(12.21)
Now take a single derivative in each of ti, sj at ti = sj = 0. On the left we get in+m
times the desired expectation. On the right we get the coefﬁcient of t1 · · · tns1 · · · sm
in a power series expansion in s, t. To identify this coefﬁcient we write
exp
⎛
⎝−

(i,j)
tisjC(hi, gj)
⎞
⎠=

(i,j)
exp

−tisjC(hi, gj)

=

(i,j)

1 −tisjC(hi, gj) + . . .

= 1 +



(i,j)∈

−tisjC(hi, gj)

+ . . .
(12.22)
where the sum over  is over collections of elements (i, j) from (1, . . . , n) ×
(1, . . . , m). But only collections in which each element of (1, . . . , n) appears exactly
once in the ﬁrst position and each element of (1, . . . , m) appears exactly once in the
second position will contribute. This is only possible if n = m and then the sum over
such terms can be identiﬁed with a sum over permutations π of (1, . . . , n). Hence we
get (−1)n = i2n times the right side of (12.18).
Problem 12.1
Show that
φ(h) : φ(h1) . . . φ(hn) :C =: φ(h)φ(h1) . . . φ(hn) :C
+
n

j=1
C(h, hj) : φ(h1) . . . 
φ(hj) . . . φ(hn) :C
(12.23)
where the hat on φ(hj) means “omit this factor”.

179
12.1 More on Gaussian processes
t
Problem 12.2
Establish the identity
: φ(h1) . . . φ(hn) :C=

Q

{i,j}∈Q

−C(hi, hj)
 
k/∈Q
φ(hk)
(12.24)
where Q is a (possibly empty) collection of pairs from (1, . . . , n). Then establish
the special case
: φ(h)n :C=
[n/2]

j=0
(−1)jn!
(n −2j)! j! 2j C(h, h)jφ(h)n−2j
(12.25)
Problem 12.3
Let {hα
i } be a collection from S indexed by pairs (α, i) with 1 ≤
α ≤r and 1 ≤i ≤nα. Show that
E
 r
α=1
:
nα

i=1
φ(hα
i ) :

=

G

{(α,i),(β,j)}∈G
C(hα
i , hβ
j )
(12.26)
where the sum is over all graphs G on r vertices with legs (α, i) at the αth vertex
and lines {(α, i); (β, j)}. Each leg must belong to exactly one line and the lines
must have α ̸= β, that is lines cannot join legs at the same vertex.
12.1.3 Realization on S′
Depending on the real vector space S and the covariance C there may be more con-
crete representations of the Gaussian process. In particular suppose that S is the
Schwartz space S(Rd). It turns out that in this case we can take our basic measure
space to be (Q, , μC) where Q = S′(Rd) is the space of real tempered distributions,
 is the σ-algebra generated by the functions q →< q, f >, f ∈S(Rd), and μC is a
Gaussian measure. The random variables φ(f) are given by the evaluation map

φ(f)

(q) =< q, f >
q ∈Q,
(12.27)
so the distributions q are the ﬁelds. With this choice, expectations will be written out
explicitly as
E(F) =

Q
F dμC
(12.28)
An advantage of this representation is that there is a natural deﬁnition of deriva-
tives with respect to the ﬁeld. For any function F on Q = S′(Rd) we deﬁne the
derivative along h ∈Q by
(∇hF)(q) = d
dt[F(q + th)]t=0
(12.29)

180
Fields as random variables
t
if it exists. We consider in particular functions on Q of the form
F = ˆF(φ(f1), . . . , φ(fn))
(12.30)
where ˆF is a complex Borel function on Rn and fi ∈S(Rd). Equivalently we can
write
F(q) = ˆF(< q, f1 >, . . . , < q, fn >)
(12.31)
Such functions are called cylinder functions. If ˆF is differentiable, then ∇hF does
exist and by the chain rule we have
∇hF =
n

i=1
∂ˆF
∂xi
(φ(f1), . . . , φ(fn)) < h, fi >
(12.32)
Note that this is linear in h.
As a special case we can take h = δx, the delta function at x. Then ∇δxF is denoted
∂F/∂φ(x). If F has the form (12.30), then
∂F
∂φ(x) =
n

i=1
∂ˆF
∂xi
(φ(f1), . . . , φ(fn))fi(x)
(12.33)
Hence ∂F/∂φ(x) is in S(Rd) and for h ∈S′(Rd)
∇hF =< h, ∂F
∂φ >=

h(x) ∂F
∂φ(x)dx
(12.34)
Problem 12.4
Establish the identities
∇h

φ(f1) . . . φ(fn)

=
n

j=1
< h, fj > φ(f1) . . . 
φ(fj) . . . φ(fn)
∇h

: φ(f1) . . . φ(fn) :C

=
n

j=1
< h, fj >: φ(f1) . . . 
φ(fj) . . . φ(fn) :C
(12.35)
Next we develop an integration by parts formula for ∇h.
Lemma 12.2
Let C(f, g) =< f, Cg > where C is a bijection on S(Rd). Let F =
ˆF(φ(f1), . . . , φ(fn)) be a cylinder function on Q = S′(Rd) with ˆF and its partial
derivatives continuous and exponentially bounded. Then for h ∈S(Rd)

Q
∇hF dμC =

Q
F φ(C−1h) dμC
(12.36)
Proof
Let e1, . . . , em be a basis for the subspace spanned by f1, . . . , fn and C−1h
such that C(ei, ej) = δij. Such a basis can be constructed by the Gram-Schmidt pro-
cess. We can write F = ˜F(φ(e1), . . . , φ(em)) and evaluate the derivative by (12.32).
Then write the integral in Rm by (12.3), and integrate by parts to obtain

181
12.2 The Schrödinger representation
t

Q
∇hF dμC
=

i
< h, ei >

Q
∂˜F
∂xi
(φ(e1), . . . , φ(em)) dμC
=

i
< h, ei > (2π)−m/2

Rm
∂˜F
∂xi
(x1, . . . , xm)e−|x|2/2dx
=

i
< h, ei > (2π)−m/2

Rm
˜F(x1, . . . , xm) xi e−|x|2/2dx
=

i
< h, ei >

Q
˜F(φ(e1), . . . , φ(em))φ(ei) dμC
=

Q
F φ(C−1h)dμC
(12.37)
The last step follows by C−1h = 
i < h, ei > ei.
Corollary 12.1
(Integration by parts) With F, G as in the lemma

Q
F(∇hG) dμC = −

Q
(∇hF) G dμC +

Q
F G φ(C−1h)dμC
(12.38)
Proof
In the lemma replace F by FG and use
∇h(FG) = (∇hF)G + F(∇hG)
(12.39)
12.2 The Schrödinger representation
12.2.1 Deﬁnitions and equivalence
As an application of the previous section we give another representation of the
time zero free scalar ﬁeld. This is known as the Schrödinger representation and is
characterized by the feature that the ﬁeld operators are all multiplication operators.
For the free scalar ﬁeld in space dimension d we generalize the results of sec-
tion 8.2.2 for d = 3. The symmetric Fock space is F+(H0) where H0 = L2(Rd, dp).
On ﬁnite particle vectors D0 ⊂F+(H0) the ﬁeld operator is deﬁned as in (8.55) and
is now denoted φ0(t, h). Thus
φ0(t, h) = a

eiωt˜h
√
2ω

+ a∗

eiωt˜h
√
2ω

(12.40)
where h ∈S(Rd) is real and ω(p) =
$
|p|2 + m2. The ﬁeld and its time derivative at
t = 0 are

182
Fields as random variables
t
φ0(h) = a

(2ω)−1/2˜h

+ a∗
(2ω)−1/2˜h

π0(h) = −ia

(ω/2)1/2 ˜h

+ ia∗
(ω/2)1/2 ˜h

(12.41)
and these satisfy the canonical commutation relations. We will also want to consider
Wick ordered products : φ0(h1) · · · φ0(hn) : on the vacuum 0. These satisfy the
identity
: φ0(h1) · · · φ0(hn) : 0 = a∗
(2ω)−1/2˜h1

· · · a∗
(2ω)−1/2˜hn

0
(12.42)
This follows since Wick ordering means move annihilation operators to the right,
and annihilation operators on 0 give zero.
To represent the φ0(h) as multiplication operators we consider
ˆω =
$
− + m2 = F−1[ω(p)]F
(12.43)
and introduce the Gaussian process φ(h) indexed by real h ∈S(Rd) with mean zero
and covariance (2 ˆω)−1. Thus3
E(φ(g)φ(h)) =< g, (2 ˆω)−1h >= (˜g, (2ω)−1˜h)
(12.44)
Theorem12.3
Let φ(h) be a Gaussian process with covariance (2 ˆω)−1 on a measure
space (M, , μ). There is a unitary operator V : F+(H0) →L2(M, μ) such that
V0 = 1 and
V

: φ0(h1) · · · φ0(hn) : 0

=: φ(h1) · · · φ(hn) :(2 ˆω)−1
(12.45)
Proof
First deﬁne V on complex linear combinations of the vectors (12.42). These
can be written in the form 
α cα : φ0(hα1) · · · φ0(hαn) : 0 with α = (α1, . . . , αn) in
some index set and complex cα. We want to deﬁne
V

α
cα : φ0(hα1) · · · φ0(hαn) : 0

=

α
cα : φ(hα1) · · · φ(hαn) :(2 ˆω)−1 (12.46)
To see this is well-deﬁned we ﬁrst claim that both vectors have the same norm. For
this it sufﬁces to show that
(: φ0(g1) · · · φ0(gm) : 0, : φ0(h1) · · · φ0(hn) : 0)
= E

: φ(g1) · · · φ(gm) :(2 ˆω)−1 : φ(h1) · · · φ(hn) :(2 ˆω)−1

(12.47)
In fact each side is zero if n ̸= m. If n = m the left side of (12.47) is computed as

π
(˜g1, (2ω)−1˜hπ(1)) · · · (˜gn, (2ω)−1˜hπ(n))
(12.48)
3 Here and elsewhere we write < g, h >=

g(x)h(x)dx as a reminder that it is the real inner product. But
since g, h are real it is the same as (g, h) =

g(x)h(x)dx.

183
12.2 The Schrödinger representation
t
where the sum is over permutations π of (1, . . . , n). This follows from (12.42) and
the commutation relations for a, a∗, or more directly from (5.60). This is the same as
the right side of (12.47) by (12.18) and (12.44).
Since both sides have the same norm, it follows that if a sum is the zero vector,
then it is sent to the zero vector. Hence if a vector has two different representations
they are sent to the same place. Thus the mapping is well-deﬁned.
The mapping has a dense domain since vectors a∗(f1) · · · a∗(fn)0 with fi ∈S(Rd)
span a dense subspace of Fock space. Also the range is the subspace of all polynomi-
als in the φ(h) which is dense in L2(M, μ). Since V is norm preserving with dense
domain and dense range it extends to a unitary operator (theorem 1.3).
Remark
Let H0 = d(ω) be the free Hamiltonian on Fock space so imaginary time
evolution is e−H0t = (e−ωt). Then by (12.42) and e−H0ta∗(f) = a∗(e−ωtf)e−H0t or
directly from (5.60)
e−H0t : φ0(h1) · · · φ0(hn) : 0 =: φ0(e−ˆωth1) · · · φ0(e−ˆωthn) : 0
(12.49)
Note that e−ˆωthj is still real. Then Ve−H0tV−1 deﬁnes a contraction on L2(M, μ),
also denoted e−H0t, and we have
e−H0t : φ(h1) · · · φ(hn) :(2 ˆω)−1=: φ(e−ˆωth1) · · · φ(e−ˆωthn) :(2 ˆω)−1
(12.50)
Problem 12.5
1. Show that
φ0(h) : φ0(h1) · · · φ0(hn) : 0 =: φ0(h)φ0(h1) · · · φ0(hn) : 0
+
n

j=1
< h, (2 ˆω)−1hj >: φ0(h1) · · · 
φ0(hj) · · · φ0(hn) : 0
(12.51)
2. Show that φ(h) = Vφ0(h)V−1 on polynomials.
Problem 12.6
Show that
: φ(h1) · · · φ(hn) :(2 ˆω)−1= V : φ0(h1) · · · φ0(hn) : V−1
(12.52)
12.2.2 The CCR
If the Gaussian process φ(h) is realized on the space (Q, , μ(2 ˆω)−1) with Q =
S′(Rd), then we can construct a representation of the CCR. This is a representation
on L2(Q, μ(2 ˆω)−1) in which φ(h) is multiplication by (φ(h))(q) =< q, h > and π(h) is
a derivative operator. However we cannot take π(h) = −i∇h since this would not be
symmetric with respect to the Gaussian measure. Instead we take for real h ∈S(Rd)

184
Fields as random variables
t
φ(h) = [φ(h)]
π(h) = −i∇h + i[φ( ˆωh)]
(12.53)
with the polynomials as the domain.
Lemma 12.3
φ(h), π(h) are densely deﬁned symmetric operators on the Hilbert
space L2(Q, μ(2 ˆω)−1) which satisfy the canonical commutation relations.
Proof
φ(h) is symmetric. To see that π(h) is symmetric use the integration by parts
formula (12.38) with C = (2 ˆω)−1 to obtain
(F, π(h)G) = (F, (−i∇h)G) + i(F, φ( ˆωh)G)
= ((−i∇h)F, G) −i(F, φ( ˆωh)G)
= (π(h)F, G)
(12.54)
For the commutators we compute that [φ(g), −i∇h] = i < g, h >. It follows that
[φ(g), π(h)] = i < g, h > and [π(g), π(h)] = 0. Since [φ(g), φ(h)] = 0 is trivial, the
proof is complete.
The next problem combined with problem 12.5 shows that the representation
φ(h), π(h) of the CCR on L2(Q, μ(2 ˆω)−1) is unitarily equivalent to the representation
φ0(h), π0(h) on Fock space.
Problem 12.7
Show that π(h) = Vπ0(h)V−1 on polynomials.
12.3 Path integrals – free ﬁelds
We continue to consider the free scalar ﬁeld. The Schrödinger representation opens
the door for the representation of the imaginary time dynamics e−H0t in terms of ran-
dom paths as in the Feynman–Kac formula. Recall from section 11.5 that the imagi-
nary time dynamics for the harmonic oscillator with Hamiltonian 1/2(p2 +x2) could
be represented by a Gaussian process Xt with covariance E(Xt1Xt2) = e−|t2−t1|/2/2.
Our Hamiltonian H0 = 1/2

(π2 + φ ˆω2φ) is an inﬁnite-dimensional analog of the
harmonic oscillator. This suggests a similar representation which we now explain.
For t ∈R and real h ∈S(Rd) let φ(t, h) be the Gaussian process with mean zero
and covariance E(φ(t1, h1)φ(t2, h2)) given by
C(t1, h1; t2, h2) =
-
h1,

e−|t2−t1| ˆω
2 ˆω

h2
.
=

˜h1(p) e−|t2−t1|ω(p)
2ω(p)
˜h2(p) dp
(12.55)

185
12.3 Path integrals – free ﬁelds
t
This is positive deﬁnite since it can also be written in the form
C(t1, h1; t2, h2) = 1
2π

˜h1(p)
eip0(t1−t2)
p2
0 + |p|2 + m2 ˜h2(p) dp0 dp
(12.56)
To see that this is the same, evaluate the p0 integral by closing the contour in the
upper or lower half plane depending on the sign of t1 −t2. The Gaussian process
φ(t, h) exists by the Kolmogorov theorem as in our previous discussions. We also
give an alternate construction shortly.
Note that for ﬁxed t the random variables φ(t, h) are Gaussian with covariance
(2 ˆω)−1 and so are a realization of our basic scalar ﬁeld on Rd. Thus t →φ(t, h) is
a random path through random scalar ﬁelds. Furthermore our basic Hilbert space is
square-integrable functions of these ﬁxed time ﬁelds and so this structure is imbed-
ded at various times in a larger Hilbert space of time dependent ﬁelds. This leads to
a Feynman–Kac formula. The details are as follows:
Theorem 12.4
Let φ(h) be a Gaussian process indexed by h ∈S(Rd) with covari-
ance < h1, (2 ˆω)−1h2 > on a measure space (M, , μ). Furthermore let φ(t, h) be a
Gaussian process indexed by (t, h) ∈R × S(Rd) with covariance C(t1, h1; t2, h2) on
a measure space (M′, ′, μ′). Then
1. For each t there is an isometry Jt : L2(M, μ) →L2(M′, μ′) such that Jt(1) = 1
and
Jt

: φ(h1) · · · φ(hn) :(2 ˆω)−1

=: φ(t, h1) · · · φ(t, hn) :C
(12.57)
2. Let F, G ∈L2(M, μ) be states of the scalar ﬁeld. Then for t ≥0
(G, e−H0tF) = E(J0G JtF)
(12.58)
Proof
For the ﬁrst part we follow the strategy of theorem 12.3. We want to deﬁne
the map by
Jt

α
cα : φ(hα1) . . . φ(hαn) :(2 ˆω)−1

=

α
cα : φ(t, hα1) . . . φ(t, hαn) :C (12.59)
This is well-deﬁned if both vectors have the same norm and this follows from
E

: φ(g1) . . . φ(gm) :(2 ˆω)−1 : φ(h1) . . . φ(hn) :(2 ˆω)−1

= E

: φ(t, g1) . . . φ(t, gm) :C : φ(t, h1) . . . φ(t, hn) :C

(12.60)
Each side is evaluated by (12.18) and the result follows from the equal time identity
< g, (2 ˆω)−1h >= C(t, g; t, h)
(12.61)
Hence Jt is well deﬁned. Since the domain is dense and it is norm preserving it
extends to an isometry.
For the second point ﬁrst take
G =: φ(g1) . . . φ(gn) :(2 ˆω)−1
F =: φ(h1) . . . φ(hn) :(2 ˆω)−1
(12.62)

186
Fields as random variables
t
Then we have using (12.50) and (12.18)
(G, e−H0tF)
= E

: φ(g1) . . . φ(gn) :(2 ˆω)−1 : φ(e−t ˆωh1) . . . φ(e−t ˆωhn) :(2 ˆω)−1

=

π
-
g1,
e−t ˆω
2 ˆω

hπ(1)
.
· · ·
-
gn,
e−t ˆω
2 ˆω

hπ(n)
.
= E

: φ(0, g1) . . . φ(0, gn) :C : φ(t, h1) . . . φ(t, hn) :C

= E(J0G JtF)
(12.63)
The same holds for complex linear combinations of such vectors since monomials of
different degree are orthogonal. This is a dense domain and since both sides of the
equation are continuous bilinears on L2(M, μ), the result follows.
Problem 12.8
Show that Jt[φ(h)] = [φ(t, h)]Jt and hence
Jt

φ(h1) · · · φ(hn)

= φ(t1, h1) · · · φ(tn, hn)
(12.64)
Remarks
Starting with our Gaussian process φ(t, h) with mean zero and covariance
C(t1, h1, t2, h2) we can consider real test functions f ∈S(Rd+1) and deﬁne4
φ(f) =

φ(t, f(t, ·))dt
(12.65)
Then the φ(f) are Gaussian with covariance from (12.56)
E(φ(f1)φ(f2)) =

C(t1, f(t1, ·), t2, f(t2, ·)) dt1dt2
=

Rd+1
˜f1(p)
1
p2 + m2 ˜f2(p) dp
=< f1, (− + m2)−1f2 >
(12.66)
In fact we could have started with a Gaussian process φ(f) indexed by S(Rd+1)
with covariance (−+m2)−1. The sharp time ﬁelds can then be recovered as follows.
As in the proof of theorem 12.1 the φ(f) are naturally deﬁned for f in the completion
of S(Rd+1) in the norm (f, (− + m2)−1f)1/2. This space can be identiﬁed as the
Sobolev space
H−1(Rd+1) = {f ∈S′(Rd+1) :

|˜f(p)|2(p2 + m2)−1dp < ∞}
(12.67)
For h ∈S(Rd) the Fourier transform of the distribution δt ⊗h is the function
(2π)−1/2e−ip0t˜h(p). Since

|˜h(p)|2(p2
0 + |p|2 + m2)−1dp is ﬁnite, δt ⊗h is in the
Sobolev space and so φ(δt ⊗h) is deﬁned. If we set φ(t, h) = φ(δt ⊗h), we get
Gaussian ﬁelds with covariance C(t1, h1, t2, h2).
4 Formally φ(t, h) =

φ(t, x)h(x) and so formally φ(f) =

φ(t, x)f(t, x).

187
12.4 Vacuum correlation functions
t
Thus the basic free dynamics are encoded in a Gaussian process with covariance
(− + m2)−1. Expectations for this process can be thought of as integrals with
respect to the formal measure5, which is a constant times
e−S(φ)dφ
≡exp

−1
2
 
∂φ(x) · ∂φ(x) + m2φ(x)2
dx
 
x∈Rd+1
dφ(x)
(12.68)
Note that S(φ) is just the classical action (7.82) (at λ = 0 and imaginary time). One
expects that integrals are dominated by the minima of S(φ) which come at solutions
of (− + m2)φ = 0. This is just the Klein–Gordon equation we started with (now
at imaginary time). Thus the integral has a leading contribution from the classical
solutions, but there are also quantum corrections. This picture manifests itself in
other models as well.
12.4 Vacuum correlation functions
We now study correlation functions which are expectation values of products of
ﬁeld operators in some distinguished state. They are of interest because all infor-
mation about a model can be recovered from them. They are particularly important
for nonlinear ﬁeld theories because they are easier to control than states, ﬁelds, or
Hamiltonians directly. We explain these points in more detail in the next chapter.
Here we continue with the free scalar ﬁeld φ0(t, h) deﬁned by (12.40). Vacuum
correlation functions are deﬁned for ti ∈R, hi ∈S(Rd) by

0, φ0(t1, h1) · · · φ0(tn, hn)0

(12.69)
Since φ0(t, h) = eiH0tφ0(h)e−iH0t and e−iH0t0 = 0, this can also be written

0, φ0(h1)e−iH0(t1−t2)φ0(h2) . . . φ0(hn−1)e−iH0(tn−1−tn)φ0(hn)0

(12.70)
Now suppose we go to imaginary time replacing each t by it. Then we have
S(t1, h1, . . . , tn, hn)
=

0, φ0(h1)e−(t2−t1)H0φ0(h2) . . . φ0(hn−1)e−(tn−tn−1)H0φ0(hn)0

(12.71)
Now we impose the restriction that ti+1 −ti ≥0 so we can deal with bounded
operators e−tH0 for t ≥0 rather than unbounded operators for t < 0. In fact for
complex t with Re t > 0 the operators e−tH0 are bounded and analytic (by the spec-
tral theorem and the positivity of H0). The expression (12.71) is also analytic in
5 This can be made precise if we approximate Rd+1 by a ﬁnite lattice, say ϵZd+1/LZd+1 with ϵ small
and L large.

188
Fields as random variables
t
Re(ti+1 −ti) > 0, and the real time correlation functions (12.70) are boundary values
as Re(ti+1 −ti) →0. The S(t1, h1, . . . , tn, hn) are called the Schwinger functions.
The result we are after is that the Schwinger functions are the moments for the
Gaussian process φ(t, h), which we have been discussing.
Theorem12.5
Let φ(t, h) be the Gaussian process indexed by R×S(Rd) with covari-
ance C(t1, h1; t2, h2) deﬁned in (12.55), (12.56). Then for times t1 ≤t2 · · · ≤tn the
Schwinger functions for the free scalar ﬁeld satisfy
S(t1, h1, . . . , tn, hn) =E

φ(t1, h1) . . . φ(tn, hn)

(12.72)
Proof
Insert φ0(h1) = a((2ω)−1/2˜h1) + a∗((2ω)−1/2˜h1) in the expression (12.71).
Move the creation operator to the left where it becomes an annihilation operator and
gives zero on 0. Move the annihilation operator to the right using a(f)e−H0s =
e−H0sa(e−ωsf) and the commutation relations for a, a∗until it reaches the 0 where
it gives zero. This yields the identity
S(t1, h1, . . . , tn, hn)
=
n

j=2

˜h1, e−(tj−t1)ω
2ω
˜hj

S(t2, h2, . . . , 
tj, hj, . . . , tn, hn)
(12.73)
The inner product here is identiﬁed as C(t1, h1, tj, hj). Iterating this relation we ﬁnd
that S(t1, h1, . . . , tn, hn) is zero if n is odd and if n is even is given as a sum over
pairings P of (1, . . . , n)
S(t1, h1, . . . , tn, hn) =

P

{i,j}∈P
C(ti, hi; tj, hj)
(12.74)
But this is the same as E(φ(t1, h1) . . . φ(tn, hn)) by (12.10).
Remark
These results can be generalized. Working in the Schrödinger represen-
tation on a measure space (M, , μ), let R1, . . . , Rn belong to some subspace of
L2(M, μ). We want to assert that for t1 ≤t2 · · · ≤tn
E(R1e−(t2−t1)H0R2 · · · Rn−1e−H0(tn−tn−1)Rn)
=E

(Jt1R1) · · · (JtnRn)

(12.75)
If n = 2, this is (12.58). If Rj = φ(hj), this is the result (12.72) just established.
(Recall that φ0(h) = φ(h) and 0 = 1 under the identiﬁcation of Fock space with
L2(M, μ).) Since we allow coinciding times, the result also holds for monomials
R = φ(h1) · · · φ(hn). Since both sides are linear, it then holds for R = polynomial.
By approximating with polynomials the result can be extended to R ∈L∞(M, μ) or
R ∈∩p<∞Lp(M, μ), but we do not go into details.

189
12.5 Thermal correlation functions
t
12.5 Thermal correlation functions
We continue with the free scalar ﬁeld. Suppose now we want to represent not the
vacuum correlation functions, but thermal correlation functions in the grand canoni-
cal ensemble at chemical potential μ = 0 and inverse temperature β > 0. These are
expectations < · · · >β of products of ﬁeld operators of the form
< · · · >β= Tr([· · · ]e−βH0)
Tr(e−βH0)
(12.76)
Working on Rd, the operator e−βH0 is not trace class, so this must be interpreted as a
limit from a sequence of tori Rd/L Zd as L →∞just as in the non-relativistic case;
see section 6.3.
The KMS condition (6.65) for commuting observables can be interpreted as a
statement of periodicity in imaginary time. This suggests that we try to represent
the imaginary time correlation functions on the cylinder Sβ × Rd rather than Rd+1.
Here Sβ = R/βZ is a circle of circumference β. Indeed let Cβ = (− + m2)−1
on L2(Sβ × Rd). The periodicity in t means we replace the Fourier transform with a
Fourier series and so instead of (12.56) we have for real hi ∈S(Rd)
Cβ(t1, h1; t2, h2) = β−1

p0∈(2π/β)Z

˜h1(p)
e−ip0(t1−t2)
p2
0 + |p|2 + m2 ˜h2(p)dp
(12.77)
The path space representation is the following:
Theorem12.6
Let φ(t, h) be the Gaussian process indexed by Sβ×S(Rd) with covari-
ance Cβ(t1, h2, t2, h2). The thermal correlation functions for the free scalar ﬁeld
< φ0(t1, h1) · · · φ0(tn, hn) >β have an analytic continuation to 0 < Im t1 < · · · <
Im tn < β and at points tj = isj with 0 < s1 < · · · < sn < β

< φ0(t1, h1) · · · φ0(tn, hn) >β
'
tj=isj
= E

φ(s1, h1) · · · φ(sn, hn)

(12.78)
Proof
We ﬁrst check it for n = 2. To compute the left side we note that for f, g ∈
S(Rd)
< a∗(f)a(g) >β =

g,
e−βω
(1 −e−βω) f

< a(g)a∗(f) >β =

g,
1
(1 −e−βω) f

(12.79)
and that < a∗(f)a∗(g) >β=< a(f)a(g) >β= 0. This computation is the same as in
the non-relativistic case lemma 6.1, except that we have ω(p) =
$
|p|2 + m2 instead
of |p|2/2m and μ = 0 is now allowed.

190
Fields as random variables
t
The ﬁeld operator from (12.40) then satisﬁes
< φ0(t1, h1)φ0(t2, h2) >β
=
-
a∗

eiωt1 ˜h1
2ω

a

eiωt2 ˜h2
2ω

+ a

eiωt1 ˜h1
2ω

a∗

eiωt2 ˜h2
2ω
 .
β
=

˜h2,
e(−β−i(t2−t1))ω
2ω(1 −e−βω)

˜h1

+

˜h1,

ei(t2−t1)ω
2ω(1 −e−βω)

˜h2

(12.80)
Since ω ≥0, this has the analytic continuation and
&
< φ0(t1, h1)φ0(t2, h2) >β
'
t1=is1,t2=is2
=

˜h2,
 e(−β+s2−s1)ω
2ω(1 −e−βω)

˜h1

+

˜h1,

e−(s2−s1)ω
2ω(1 −e−βω)

˜h2

(12.81)
On the other hand the right side of (12.78) is E(φ(s1, h1)φ(s2, h2)) = Cβ(s1, h1;
s2, h2). But we can relate the covariance Cβ on Sβ × Rd to the covariance C on Rd+1
deﬁned in (12.55), (12.56) by
Cβ(s1, h1; s2, h2) =

n∈Z
C(s1, h1; s2 + nβ, h2)
(12.82)
To see this is true we ﬁrst establish the identity for ω ̸= 0
β−1

p0∈(2π/β)Z
eip0t
p2
0 + ω2 = (2π)−1 
n∈Z
 eip0(t+nβ)
p2
0 + ω2 dp0
(12.83)
The second expression can be written 
n e−ω|t+nβ|/2ω, which shows that the sum
over n converges. To establish the identity note that both sides are periodic functions
with period β and hence deﬁne functions on Sβ. Both sides satisfy the equation

−d2
dt2 + ω2

u =

n∈Z
δ(t + nβ)
(12.84)
in the sense of distributions. Such solutions are unique, hence the identity. (This is
the method of images.) Now in (12.83) let t = s1 −s2, let ω = ω(p), multiply by
˜h1(p)˜h2(p), and integrate over p to get (12.82).
Now we have
Cβ(s1, h1; s2, h2)
=

n∈Z
(˜h1,
e−|s2−s1+βn|ω
2ω

˜h2)
=
−1

n=−∞

˜h1,
e(s2−s1)ω
2ω

enβω˜h2

+
∞

n=0

˜h1,
e−(s2−s1)ω
2ω

e−nβω ˜h2

=

˜h1,
 e(−β+s2−s1)ω
2ω(1 −e−βω)

˜h2

+

˜h1,

e−(s2−s1)ω
2ω(1 −e−βω)

˜h2

(12.85)

191
12.5 Thermal correlation functions
t
Taking into account that h real implies ˜hi(p) = ˜hi(−p) this is the same as (12.81).
For general n the correlation function < φ0(t1, h1) · · · φ0(tn, hn) >β can be
expressed as a sum over pairings 
P
(
{i,j}∈P < φ0(ti, hi)φ0(tj, hj) >β by a vari-
ation of problem 6.4. Thus it continues to 
P
(
{i,j}∈P Cβ(si, hi; sj, hj), which is
E

φ(s1, h1) · · · φ(sn, hn)

by (12.10).
Problem 12.9
1. Check that both sides of (12.83) satisfy (12.84).
2. (uniqueness) Show that if u ∈S′(R) and (−d2/dt2 + ω2)u = 0, then u = 0.
Notes on chapter 12: A general reference is Glimm and Jaffe (1987). For Gaussian
measures on S′(Rd), see Gelfand and Vilenkin (1964). There is an analogue of path
integrals for fermions, see for example Salmhofer (1999).

13
A nonlinear ﬁeld theory
13.1 The model
In this chapter we give an example of a ﬁeld theory governed by a nonlinear ﬁeld
equation. In its particle aspect the nonlinearity means that particles can interact with
each other and can also be created and destroyed.
We take the simplest nontrivial case which is a scalar ﬁeld on the spacetime (R2, η)
obeying the ﬁeld equation (7.81)
(−□+ m2)φ + 4λφ3 = 0
(13.1)
Here λ is a positive coupling constant. As a ﬁrst-order system it has the form
dφ
dt = π
dπ
dt = −(− + m2)φ −4λφ3
(13.2)
This is an inﬁnite-dimensional Hamiltonian system with the Hamiltonian
H = H0 + V
H0(φ, π) = 1
2
 ∞
−∞

π(x)2 + (∇φ(x))2 + m2φ(x)2
dx
V(φ) = λ
 ∞
−∞
φ(x)4dx
(13.3)
This is formally positive, which is why we took φ3 in the ﬁeld equation rather than
say φ2. The model is known as the φ4
2 model, the two for dimension d = 2. More
generally if we replace φ4 by a lower semi-bounded polynomial P(φ), it is called the
P(φ)2 model.
The problem is to construct operator valued solutions to this equation with
initial values π0(x), φ0(x), which satisfy the canonical commutation relations
[φ0(x), π0(y)] = iδ(x −y). From chapter 8 we already know the solution for
λ = 0. Start with the Fock space F+(H0) with H0 = L2(R3, dp). Deﬁne time
zero ﬁelds φ0, π0 as in (8.56). If the terms in H0 = H0(φ0, π0) are Wick-ordered,
then the operator H0 is well-deﬁned as H0
= d(ω) (problem 8.8) and the
192

193
13.2 Regularization
t
dynamical equations (13.2) are solved by φ(t, x) = eiH0tφ0(x)e−iH0t and π(t, x) =
eiH0tπ0(x)e−iH0t interpreted as distributions.
If we try to incorporate V into this picture, we would try to add a term
λ
 ∞
−∞φ0(x)4dx to the Hamiltonian. But this is very poorly deﬁned. In the ﬁrst place
we are raising a (operator-valued) distribution to the fourth power, something with
no natural meaning. In the second place we are integrating something with no decay
over all of R. Our task is to explain how to deal with these problems.
First some comments about the physics. On states with low momentum
ω(p) =
$
p2 + m2 ≈m. Hence in (8.56) for d = 1 the ﬁeld is approximately
φ0(x) ≈(2m)−1/2(a(x) + a∗(x))
(13.4)
where a(x) = (2π)−1/2 
eipxa(p) labels a particle at position x. Hence with Wick
ordering
λ

: φ0(x)4 : dx ≈3λ
2m2

a∗(x) a∗(x) a(x) a(x) dx + . . .
(13.5)
This leading term preserves particle number and comparing it with (5.79) we see
that it describes pairs of particles interacting with a repulsive delta function potential
v(x−y) = 3λ/m2 δ(x−y). There are also other terms such as

a∗(x)4dx which create
or annihilate particles, but these turn out to be less important at low momentum.
13.2 Regularization
We regularize the problem as follows. As mentioned, the ﬁrst step is to replace
λ
 ∞
−∞φ0(x)4dx with a Wick-ordered version
V = λ
 ∞
−∞
: φ0(x)4 : dx
(13.6)
The second step is to restrict the integral to a ﬁnite interval by
VL = λ
 L
−L
: φ0(x)4 : dx
(13.7)
The third step is to regularize the ﬁeld. Let χ be an arbitrary positive function in
C∞
0 (R) with

χ(x)dx = 1. Then let
δκ(x) = κχ(κx)
(13.8)
This is an approximate delta-function in the sense that any continuous function

f(y)δκ(x −y)dx →f(x) as κ →∞(problem 13.1). We deﬁne a regularized
ﬁeld by
φ0,κ(x) = φ0(δk(· −x))
(13.9)

194
A nonlinear ﬁeld theory
t
and a regularized potential by
VL,κ = λ
 L
−L
: φ0,κ(x)4 : dx
(13.10)
This is a well-deﬁned operator on a dense domain on Fock space.
We now change to the Schrödinger representation as in section 12.2. The ﬁeld
operators φ0(h) become a family of Gaussian random variables φ(h) with covari-
ance (2 ˆω)−1 on a measure space (M, , μ). The equivalence is provided by the
unitary map V from the Fock space to L2(M, μ) deﬁned in theorem 12.3. The free
Hamiltonian is now VH0V−1 also denoted H0, and (problem 12.6) the interaction
becomes VVL,κV−1, which is multiplication by
VL,κ(φ) = λ
 L
−L
: φκ(x)4 :(2 ˆω)−1 dx
(13.11)
where φκ(x) is the random variable φκ(x) = φ(δκ(·−x)). Then VL,κ(φ) is well-deﬁned
as a function in Lp(M, μ) for all 1 ≤p < ∞.
Our goal is to remove the regularizations by ﬁnding a meaning for the limits
κ →∞and L →∞. The limit κ →∞is facilitated by the Wick monomials as
we now explain. Note that the random variables φκ(x) have a covariance
cκ(x −y) ≡E(φκ(x)φκ(y))
=
/
δκ(· −x), (2 ˆω)−1δκ(· −y)
0
=

eip(x−y)| ˜χ(p/κ)|2(2ω(p))−1dp
(13.12)
Thus we have
: φκ(x)4 :(2 ˆω)−1= φκ(x)4 −6cκ(0)φκ(x)2 + 3

cκ(0)
2
(13.13)
As κ →∞we have ˜χ(p/κ) →˜χ(0) = (2π)−1/2 and cκ(0) →∞, in fact cκ(0)
grows like log κ. Thus in
 L
−L : φκ(x)4 :(2 ˆω)−1 dx the constant and quadratic terms
develop inﬁnite coefﬁcients as κ →∞. The idea is that these should cancel the natu-
ral inﬁnities in the quartic term
 L
−L φκ(x)4dx. This is an example of renormalization.
Theorem 13.1
The following limit exists in L2(M, μ)
VL = lim
κ→∞VL,κ
(13.14)
Proof
We ﬁrst compute the L2 norm of VL,κ. We have by (12.18)
∥VL,κ∥2
2 = λ2
 L
−L
dx
 L
−L
dy E

: φκ(x)4 :(2 ˆω)−1 : φκ(y)4 :(2 ˆω)−1

= 4! λ2
 L
−L
dx
 L
−L
dy (cκ(x −y))4
= 4! λ2 /
χ[−L,L], c4
κ ∗χ[−L,L]
0
(13.15)

195
13.2 Regularization
t
Using the Schwarz inequality and the bound ∥f ∗g∥2 ≤∥f∥1∥g∥2 we have
∥VL,κ∥2
2 ≤4! λ2∥χ[−L,L]∥2
2∥c4
κ∥1 = 48λ2L∥cκ∥4
4
(13.16)
By the Hausdorff–Young inequality1 ∥cκ∥4 ≤∥˜cκ∥4/3. Furthermore
˜cκ(p) = (2π)1/2| ˜χ(p/κ)|2(2ω(p))−1 ≤(2ω(p))−1
(13.17)
and so
∥˜cκ∥4/3 ≤

(2ω(p))−4/3dp
3/4
< ∞
(13.18)
Hence ∥cκ∥4 is bounded in κ and hence so is ∥VL,κ∥2
2. This result fails in higher
dimensions (the integral (13.18) is inﬁnite), which is why we have taken one space
dimension.
Similarly we have with cκ,κ′(x −y) =< δκ(· −x), (2 ˆω)−1δκ′(· −y) >
∥VL,κ −VL,κ′∥2
2
= 4! λ2
 L
−L
dx
 L
−L
dy

(cκ(x −y))4 −2(cκ,κ′(x −y))4 + (cκ′(x −y))4
(13.19)
Since ˜χ(p) has a bounded derivative, | ˜χ(p) −˜χ(p′)| is bounded by a constant times
|p −p′|. Since also | ˜χ(p)| is bounded, we have that | ˜χ(p) −˜χ(p′)| is bounded by a
constant times |p −p′|ϵ for any 0 ≤ϵ ≤1. Hence with κ ∧κ′ = min{κ, κ′} we have
| ˜χ(p/κ) −˜χ(p/κ′)| ≤O((κ ∧κ′)−ϵ)|p|ϵ and therefore
|˜cκ(p) −˜cκ,κ′(p)| ≤O((κ ∧κ′)−ϵ)|p|ϵω(p)−1
(13.20)
For ϵ small the extra |p|ϵ does not spoil the convergence of our integrals and so
∥cκ −cκ,κ′∥4 ≤∥˜cκ −˜cκ,κ′∥4/3 ≤O((κ ∧κ′)−ϵ)
(13.21)
Using estimates like this in (13.19) gives that
∥VL,κ −VL,κ′∥2
2 = O((κ ∧κ′)−ϵ)
(13.22)
Hence ∥VL,κ −VL,κ′∥2
2 →0 as κ, κ′ →∞and by the completeness of L2 there is a
limit VL in L2.
Convergence in Lp can also be established. Indeed one can show that for ϵ > 0
and small and any even integer p there is a constant c (depending on ϵ, λ, L) so that
∥VL,κ −VL,κ′∥p
p ≤cp(2p)! (κ ∧κ′)−ϵp
(13.23)
The dependence on p can be understood as follows. One can evaluate the Gaussian
integrals in this norm as a sum over graphs on p vertices with four legs at each vertex
with the restriction that no lines join legs of the same vertex, see (12.26). The number
1 The Hausdorff–Young inequality says that if a function f is in Lp(Rd) for 1 ≤p ≤2, then the Fourier
transform ˜f is in Lq(Rd) for p−1 + q−1 = 1 and ∥˜f∥q ≤(2π)d/2−d/p∥f∥p. We use it for the inverse
transform.

196
A nonlinear ﬁeld theory
t
of such graphs is dominated by the number of graphs without the restriction which
is (4p −1)(4p −3) · · · 3 · 1 ≤22p(2p)!.
Completing the square in (13.13) gives : φκ(x)4 :≥−6cκ(0)2 and hence
VL,κ ≥−12λLcκ(0)2 ≥−b(log κ)2 + 1
(13.24)
for some constant b. This is a sharp bound and so exp(−VL,κ) becomes unbounded
as κ →∞. Nevertheless e−VL is integrable for we have:
Theorem 13.2
(Nelson)
E

e−VL
< ∞
(13.25)
Proof
The idea is to show that although VL is not bounded below it only becomes
very negative on a set with small measure. Using (13.24) have for any κ and any
even p
P

e−VL ≥eb(log κ)2
= P

VL ≤−b(log κ)2
≤P

|VL −VL,κ| ≥1

≤∥VL −VL,κ∥p
p
≤cp(2p)! κ−pϵ
(13.26)
In the last step we have used (13.23) at κ′ = ∞. Choosing p close to κϵ/4 and using
Stirling’s formula for the asymptotics of (2p)! yields for κ sufﬁciently large
P

e−VL ≥eb(log κ)2
≤exp(−κϵ/4)
(13.27)
or with t = eb(log κ)2
P

e−VL ≥t

≤exp

−exp
ϵ
4
#
log t
b

(13.28)
Since
E

e−VL
=
 ∞
0
P

e−VL ≥t

dt
(13.29)
this is sufﬁcient to establish the integrability.
The Hamiltonian for the model is now HL = H0 + VL on a dense domain in
L2(M, μ). The potential VL is not a Kato perturbation of H0. Nevertheless by a more
difﬁcult proof2 which uses the result (13.25):
Theorem 13.3
HL is essentially self-adjoint on D(H0) ∩D(VL) and HL is bounded
below.
This theorem and the next can actually be circumvented as we explain later.
2 See Glimm and Jaffe (1970), or Reed and Simon (1975: 267).

197
13.3 Inﬁnite volume
t
Theorem13.4
Let EL = inf σ(HL) be the bottom of the spectrum for HL. Then EL < 0
is a simple eigenvalue with eigenvector L which is a strictly positive function.
This is a generalization of theorem 11.5 to an inﬁnite-dimensional measure space.3
The state L is the vacuum for the model and can be thought of as the distortion
of the free vacuum 0. Well outside of the interval [−L, L] we have HL ≈H0 and so
we expect L to be close to 0, which has no particles. However inside the interval
[−L, L] the vacuum L is ﬁlled with particles. The vacuum is not empty. (These
remarks are best visualized in the Fock representation.)
Problem13.1
Let χ ∈C∞
0 (Rd) with

χ = 1 and let δκ(x) = κdχ(κx). Show that
δκ is a family of approximate delta functions in the sense that for any function f
continuous on a neighborhood of the origin in Rd
lim
κ→∞
1
δκ, f
2
=< δ, f >≡f(0)
(13.30)
Problem 13.2
Fill in the details in the proof of theorem 13.2.
13.3 Inﬁnite volume
13.3.1 Wightman functions
Now we would like to take the limit L →∞. The operators HL and vacuum vectors
L actually have no limit in Fock space. But we use them to deﬁne some correlation
functions which do have limits. Then from these inﬁnite volume correlation functions
we will give an abstract construction of a new Hilbert space, new ﬁeld operators, and
a new vacuum vector, which reproduce the correlation functions.
The correlation functions are vacuum expectation values of products of ﬁeld oper-
ators. The ﬁeld operator is φL(t, x) = exp(iHLt)φ(x) exp(−iHLt) or smeared with
f ∈S(R2)
φL(f) =

φL(t, x)f(t, x)dxdt =

eiHLtφ(f(t, ·))e−iHLtdt
(13.31)
One can show that φL(f) is a well-deﬁned operator mapping the dense domain
C∞(HL) = 3∞
n=1 D(Hn
L) to itself. If f is real, it is symmetric, but we can extend the
deﬁnition to complex f by linearity and then φL(¯f) ⊂φL(f)∗. Since L is a vector in
C∞(HL), we can deﬁne vacuum correlation functions or Wightman functions by
3 See Glimm and Jaffe (1970) or Reed and Simon (1978: p.208).

198
A nonlinear ﬁeld theory
t
Wn,L(f1, . . . , fn) = (L, φL(f1) . . . φL(fn)L)
(13.32)
These Wightman functions are bounded multilinear functionals on S(R2) uniformly
in L. All these results follow from the “φ-bound”4, which says that there is a constant
C so for real h ∈S(R1) and all L
± φ(h) ≤C∥h∥1(HL + 1)
(13.33)
We note some properties of these ﬁnite volume Wightman functions. By the kernel
theorem (see appendix C) there exist distributions Wn,L ∈S′(R2n) such that
Wn,L(f1 ⊗· · · ⊗fn) = Wn,L(f1, . . . , fn)
(13.34)
Lemma13.1
The ﬁnite volume Wightman functions Wn,L(F) for F in complex S(R2n)
satisfy the following properties:
1. Let F∗(x1, . . . , xn) = F(xn, . . . , x1), then
Wn,L(F) = Wn,L(F∗)
(13.35)
2. Let F0, F1, F2, . . . be a ﬁnite sequence with F0 ∈C and Fn ∈S(R2n). Then with
W0,L = 1

i,j
Wi+j,L(F∗
i ⊗Fj) ≥0
(13.36)
3. Let Ft(x0
1, x1
1, . . . , x0
n, x1
n) = F(x0
1 −t, x1
1, . . . , x0
n −t, x1
n) be the time translate of F.
Then for any t ∈R
Wn,L(Ft) = Wn,L(F)
(13.37)
Proof
For an identity like (13.35) it sufﬁces to prove the result for F = f1 ⊗· · · ⊗fn
in which case it follows from φL(¯f) ⊂φL(f)∗.
For the second point deﬁne
n,L(f1, . . . , fn) = φL(f1) · · · φL(fn)L
(13.38)
This is a continuous (vector-valued) multilinear functional on S(R2) and so by a
(vector-valued) kernel theorem there is a unique extension to a (vector-valued) linear
function n,L(F) on S(R2n) such that
n,L(f1 ⊗· · · ⊗fn) = n,L(f1, . . . , fn)
(13.39)
Then for F ∈S(R2i) and G ∈S(R2j) we have
Wi+j,L(F∗⊗G) = (i,L(F), j,L(G))
(13.40)
again by φL(¯f) ⊂φL(f)∗. Then for sequences F0, F1, F2, . . .

i,j
Wi+j,L(F∗
i ⊗Fj) =
⎛
⎝
i
i,L(Fi),

j
j,L(Fj)
⎞
⎠≥0
(13.41)
The third point follows by φL(ft) = eiHLtφL(f)e−iHLt and e−iHLtL = L.
4 Glimm and Jaffe (1972).

199
13.3 Inﬁnite volume
t
We would like to show that Wn = limL→∞Wn,L exists in S′(R2n). This is possible,
but difﬁcult. We will have more to say about it. For the moment suppose that the limit
does exist. The properties (13.35), (13.36), (13.37) established in the previous lemma
then carry over to the limit. These are sufﬁcient to reconstruct a ﬁeld theory as we
now explain.
13.3.2 Reconstruction
The reconstruction theorem is quite general and we state the result for a scalar ﬁeld
in a d-dimensional spacetime. There are also versions for other spins.
Theorem 13.5
(Wightman reconstruction theorem) Let Wn ∈S′(Rnd) be a family of
distributions with W0 = 1. Suppose they satisfy
Wn(F) = Wn(F∗)
(13.42)
and for any ﬁnite sequence F0, F1, F2, . . . with Fn ∈S(Rnd)

i,j
Wi+j(F∗
i ⊗Fj) ≥0
(13.43)
Then there exists a Hilbert space H, a dense domain D ⊂H, a family of ﬁeld
operators φ(f) : D →D for f ∈S(Rd), and a vector  ∈D such that
Wn(f1 ⊗· · · ⊗fn) = (, φ(f1) . . . φ(fn))
(13.44)
Furthermore φ(¯f) ⊂φ(f)∗. In addition if the Wn are time translation invariant in the
sense that
Wn(Ft) = Wn(F)
(13.45)
then there is a self-adjoint operator H such that e−iHt preserves D and satisﬁes
e−iHt = 
eiHtφ(f)e−iHt = φ(ft)
(13.46)
Proof
Let E be the space of sequences F = (F0, F1, F2, . . . ) with F0 ∈C and
Fn ∈S(Rnd). On E deﬁne
(F, G) =

i, j
Wi+j(F∗
i ⊗Gj)
(13.47)
By (13.42)
(F, G) =

i, j
Wi+j(F∗
i ⊗Gj) =

i, j
Wi+j(G∗
j ⊗Fi) = (G, F)
(13.48)
and by (13.43) (F, F) ≥0. Thus (F, G) is an inner product except that it is not positive
deﬁnite. Let N be the subspace of all F with ∥F∥2 = (F, F) = 0 and form the factor
space E/N consisting of equivalence classes [F]. Using the Schwarz inequality one
shows that the inner product is well-deﬁned on E/N by ([E], [F]) = (E, F). On this

200
A nonlinear ﬁeld theory
t
space it is positive deﬁnite. Thus D ≡E/N is a pre-Hilbert space and we let H be
the completion.  is the equivalence class of (1, 0, 0, . . . ).
The ﬁeld operator is deﬁned on E by
φ(f)F = (0, f ⊗F0, f ⊗F1, f ⊗F2, . . . )
(13.49)
Then
(F, φ(f)G) =

i,j
Wi+j+1(F∗
i ⊗f ⊗Gj)
=

i,j
Wi+j+1((¯f ⊗Fi)∗⊗Gj) = (φ(¯f)F, G)
(13.50)
By the Schwarz inequality
∥φ(f)F∥2 = (φ(f)F, φ(f)F) = (F, φ(¯f)φ(f)F) ≤∥F∥∥φ(¯f)φ(f)F∥
(13.51)
Hence if F ∈N, then φ(f)F ∈N and so φ(f) is deﬁned on E/N and φ(f)[F] =
[f ⊗F]. The identity (13.44) holds since φ(f1) . . . φ(fn) is the equivalence class of
(0, 0, . . . , f1 ⊗· · · ⊗fn, 0, . . . ) and so
Wn(f1 ⊗· · · ⊗fn)
=

(1, 0, 0, · · · ) , (0, 0, . . . , f1 ⊗· · · ⊗fn, 0, . . . )

= (, φ(f1) . . . φ(fn))
(13.52)
For the second point deﬁne Ft = (F0, F1,t, F2,t, . . . ). Then t →Ft is a represen-
tation of the group R on E and it preserves the inner product by (13.45). Hence it
preserves N and deﬁnes a representation of R on E/N by U(t)[F] = [Ft], which
also preserves the inner product. This extends to a one-parameter unitary group U(t)
on H, which is continuous since translations are continuous on the Schwartz space.
The Hamiltonian H is deﬁned to be the generator U(t) = eiHt and the identities
(13.46) are easily checked.
We have given a bare bones version of the reconstruction theorem. The full
theorem5 has more features some of which we develop in the following problems.
Problem 13.3
(Poincaré invariance) The proper Poincaré group on (Rd, η) acts
on S(Rd) by fa,(x) = f(−1(x −a)). Show that if the Wightman functions in
theorem 13.5 are invariant in the sense that
Wn((f1)a, ⊗· · · ⊗(fn)a,) = Wn(f1 ⊗· · · ⊗fn)
(13.53)
then there is a unitary representation U(a, ) of the Poincaré group on H such
that
U(a, ) = 
U(a, )φ(f)U(a, )−1 = φ(fa,)
(13.54)
5 See Streater and Wightman (1964).

201
13.4 Path integrals – interacting ﬁelds
t
Problem 13.4
(locality) Show that if the Wightman functions in theorem 13.5
satisfy
Wn(f1 ⊗· · · ⊗fj ⊗fj+1 ⊗· · · ⊗fn) = Wn(f1 ⊗· · · ⊗fj+1 ⊗fj ⊗· · · ⊗fn) (13.55)
whenever fj and fj+1 have spacelike separated supports, then
[φ(f), φ(g)] = 0
(13.56)
whenever f and g have spacelike separated supports.
13.3.3 Interpretation
Following these general considerations we return to the φ4
2 model. Assuming that the
inﬁnite volume Wightman functions exist, the triple (H, , φ(f)) of the reconstruc-
tion theorem forms the basic model. The physical picture is that the Hilbert space H
has a distinguished vacuum vector  which is invariant under time evolution. Since
it is in some sense the limit as L →∞of the Fock vacua L localized in [−L, L], we
can think of it as a sea of Fock particles (also called bare particles) ﬁlling all space.
States φ(f1) . . . φ(fn) represent local disturbances in the vacuum. These states span
a dense set so the entire Hilbert space can be thought of as local distortions of the
vacuum.
Furthermore suppose that we could establish the Poincaré invariance. This would
not be straightforward since the ﬁnite volume Wightman functions are not invariant.
Nevertheless once it is known, we would have a representation of the Poincaré
group. Physical particles could be identiﬁed by ﬁnding irreducible subspaces for this
representation. A physical particle can be thought of as a cloud of bare particles.
13.4 Path integrals – interacting ﬁelds
Continuing with the φ4
2 model we seek to represent the imaginary time dynamics as
an integral over paths just as for the free ﬁeld. That is we seek another version of the
Feynman–Kac formula as in theorem 12.4.
Again let φ(h) be a Gaussian process indexed by h ∈S(R) with covariance
< h1, (2 ˆω)−1h2 > on a measure space (M, , μ) and let φ(t, h) be a Gaussian pro-
cess indexed by (t, h) ∈R × S(R) with covariance C(t1, h1; t2, h2) (deﬁned in
(12.55), (12.56)) on a measure space (M′, ′, μ′). We now deﬁne a potential on
ﬁelds φ(t, h) by
V[0,T]×[−L,L] = λ
 T
0
 L
−L
: φ(t, x)4 :C dtdx
(13.57)

202
A nonlinear ﬁeld theory
t
This can be deﬁned as a limit in L2(M′, μ′) of regularized potentials with : φ(t, x)4 :C
replaced by :φ(t, δκ(·−x))4:C. This is entirely similar to the treatment in theorem 13.1
of the potential VL in L2(M, μ) . In fact we have the identity
V[0,T]×[−L,L] =
 T
0
JtVLdt
(13.58)
where Jt : L2(M, μ) →L2(M′, μ′) is deﬁned in theorem 12.4. This holds with the
regularizations on both sides since
: φ(t, δκ(· −x))4 :C= Jt : φ(δκ(· −x))4 :(2 ˆω)−1
(13.59)
and hence in the limit κ →∞.
Theorem 13.6
1. exp

−V[0,T]×[−L,L]

is in Lp(M′, μ′) for all p < ∞.
2. Let ψ, χ ∈L2(M, μ) be polynomials and let HL = H0 + VL. Then
(ψ, e−THLχ) = E

J0ψ exp

−V[0,T]×[−L,L]

JTχ

(13.60)
Remark
The proof of the ﬁrst part is entirely similar to the proof of theorem 13.2
and is omitted. The second part is a Feynman–Kac formula. The proof given below is
analogous to the proof of theorem 11.3, but here it is just heuristic. It could be made
rigorous but this would probably not be the most efﬁcient way to obtain the result.6
Proof
We compute with tj = jT/n
(ψ, e−THLχ) = lim
n→∞

ψ,

e−TH0/ne−TVL/nn χ

= lim
n→∞E
⎛
⎝J0ψ
⎛
⎝
n

j=1
Jtje−TVL/n
⎞
⎠JTχ
⎞
⎠
= lim
n→∞E
⎛
⎝J0ψ exp
⎛
⎝−T
n
n

j=1
JtjVL
⎞
⎠JTχ
⎞
⎠
= E

J0ψ exp

−
 T
0
JtVL dt

JTχ

(13.61)
Here the ﬁrst step is the Trotter product formula. The second step is the free ﬁeld
result (12.75). The third step uses Jt exp(−VL) = exp(−JtVL). In the last step we
take the limit inside the integral and identify a Riemann sum. Finally use (13.58) to
complete the proof.
A variation of this result for the imaginary time correlation functions is the
following. For
−T < t1 < · · · < tn < T
(13.62)
6 See for example Simon (1975: 163).

203
13.4 Path integrals – interacting ﬁelds
t
the bare vacuum correlation functions are (with 0
= 1 in our Schrödinger
representation)

0, e−(T+t1)HLφ(h1)e−(t2−t1)HLφ(h2) . . . φ(hn)e−(T−tn)HL0

= E

φ(t1, h1) . . . φ(tn, hn) exp

−V[−T,T]×[−L,L]
 
(13.63)
Formally this follows as in (13.61). In any case the expression on the left is well-
deﬁned since the φ bound (13.33) implies (HL +1)−1/2φ(h)(HL + 1)−1/2 is bounded
and since (HL + 1)1/2e−tHL(HL + 1)1/2 is bounded for t > 0. Next divide by
∥e−THL0∥2 = E

exp

−V[−T,T]×[−L,L]

(13.64)
By theorem 13.4 the lowest eigenvalue of HL is simple with eigenvector L and so
(cf. problem 11.7)
lim
T→∞
e−THL0
∥e−THL0∥= L
(13.65)
Then we have for correlation functions with the physical vacuum

L, φ(h1)e−(t2−t1)HLφ(h2) . . . φ(hn−1)e−(tn−tn−1)HLφ(hn)L

= lim
T→∞
E

φ(t1, h1) . . . φ(tn, hn) exp

−V[−T,T]×[−L,L]

E

exp

−V[−T,T]×[−L,L]

(13.66)
An advantage of this representation is that the L dependence is in a place where
we can get our hands on it. It is indeed possible to take the limit L →∞in this
form, see the notes for references. If the ﬁelds φ(t, x) were independent random vari-
ables, this would be easy since one could cancel the large distance contributions
from V[−T,T]×[−L,L] in the numerator and denominator. They are not independent
but they are approximately independent as points separate since the covariance C is
exponentially decaying. This is the basic mechanism behind the result.
Now we can give an indication of why the Wightman functions have an inﬁnite
volume limit as well.7 By the φ-bound the functions
(L, φ(h1)e−(τ2−τ1)HLφ(h2) . . . φ(hn−1)e−(τn−τn−1)HLφ(hn)L)
(13.67)
are analytic and bounded uniformly in L on compact subsets of the complex region
Re(τi −τi−1) > 0. Since the functions converge as L →∞when the τi are real, it
follows by the Vitali convergence theorem8 that these functions have a limit for τi in
the entire region. Then for ϵ > 0 and fi ∈S(R2)

dt1 . . . dtn (L, φ(f1(t1, ·))e−i(t2−t1−iϵ)HLφ(f2(t2, ·)) · · · φ(fn(tn, ·))L)
(13.68)
7 Glimm Jaffe and Spencer (1974).
8 See for example Titchmarsh (1939).

204
A nonlinear ﬁeld theory
t
also converges as L →∞. However as ϵ →0 this expression converges to the
Wightman function Wn,L(f1, . . . , fn) and by the φ-bound again one can show that the
limit is uniform in L. Hence the Wightman functions converge as L →∞.
13.5 A reformulation
The approach we have sketched for the φ4
2 model is the most intuitive, but it is not the
most efﬁcient. We now explain a variation which involves constructing the Hilbert
space directly at imaginary time.
Start with the equivalent Gaussian random process φ(f) indexed by real f ∈S(R2)
with mean zero and covariance C = (− + m2)−1. Deﬁne the unnormalized ﬁnite
volume Schwinger functions
S0
n,T,L(f1, . . . , fn) = E

φ(f1) . . . φ(fn) exp

−V[−T,T]×[−L,L]
 
(13.69)
and extend to complex test functions by linearity. By the kernel theorem this deﬁnes
a linear functional S0
n,T,L on S(R2n) such that
S0
n,T,L(f1 ⊗· · · ⊗fn) = S0
n,T,L(f1, . . . , fn)
(13.70)
It will be convenient to restrict attention to the algebraic tensor product ⊗nS(R2) =
S(R2) ⊗· · · ⊗S(R2) which is the subspace of S(R2n) consisting of ﬁnite combina-
tions of the f1 ⊗· · · ⊗fn.
If f1 ⊗· · · ⊗fn has support in the region (13.62), then we have the identity
S0
n,T,L(f1 ⊗· · · ⊗fn)
=
 
0, e−(T+t1)HLφ(f1(t1, ·))e−(t2−t1)HL
φ(f2(t2, ·)) · · · φ(fn(tn, ·))e−(T−tn)HL0

dt1 · · · dtn
(13.71)
Indeed the ﬁeld φ(f) can be written in terms of the sharp time ﬁeld φ(t, h) as φ(f) =

φ(t, f(t, ·))dt and the result follows from (13.63).
Lemma 13.2
The ﬁnite volume Schwinger functions have the following properties:
1. Let F ∈⊗nS(R2) have support in −T < t1 < · · · < tn < T and deﬁne
(F)(t1, x1, . . . , tnxn) = F(−tn, xn, . . . , −t1, x1)
(13.72)
Then
S0
n,T,L(F) = S0
n,T,L(F)
(13.73)

205
13.5 A reformulation
t
2. (reﬂection positivity) Let F0, F1, F2, . . . be a ﬁnite sequence with F0 ∈C and
Fn ∈⊗nS(R2) with support in 0 < t1 < · · · < tn < T. Then with S0
0,T,L = 1

i,j
S0
i+j,T,L(Fi ⊗Fj) ≥0
(13.74)
Proof
It sufﬁces to check the ﬁrst identity for F = f1⊗· · ·⊗fn. Then it follows from
the representation (13.71) and the facts that e−Ht is self-adjoint and φ(¯h) ⊂φ(h)∗.
For the second point let f1, . . . , fn have supports in 0 < t1 < · · · < tn < T and
deﬁne
n,T,L(f1, . . . , fn) =

dt1 · · · dtn
e−t1HLφ(f(t1, ·))e−(t2−t1)HLφ(f(t2, ·)) . . . φ(f(tn, ·))e−(T−tn)HL0
(13.75)
As a multilinear functional this deﬁnes a linear function n,T,L(F) on the subspace
of ⊗nS(R2) of restricted supports satisfying
n,T,L(f1 ⊗· · · ⊗fn) = n,T,L(f1, . . . , fn)
(13.76)
Now for F ∈⊗iS(R2) and G ∈⊗jS(R2) with restricted supports we have
S0
i+j,T,L(F ⊗G) =

i,T,L(F), j,T,L(G)

(13.77)
Again this follows from the representation (13.71) and adjoint relations. Then for
sequences F0, F1, F2, . . .

i,j
S0
i+j,T,L(Fi ⊗Fj) =
 
i
i,T,L(Fi),

j
j,T,L(Fj)

≥0
(13.78)
Now consider the normalized Schwinger functions:
Sn,T,L(f1, . . . , fn) =
E

φ(f1) . . . φ(fn) exp

−V[−T,T]×[−L,L]
 
E

exp

−V[−T,T]×[−L,L]
 
(13.79)
As noted earlier for these one can establish an inﬁnite volume limit
Sn(f1, . . . , fn) =
lim
T,L→∞Sn,T,L(f1, . . . , fn)
(13.80)
These inﬁnite volume Schwinger functions again satisfy Sn(F) = Sn(F) as well as
the reﬂection positivity condition

i,j
Si+j(Fi ⊗Fj) ≥0
(13.81)
Now we can sketch a reconstruction theorem; the details are a bit too much to
go into here. One uses (13.81) to deﬁne an inner product on sequences. Factoring
out the null space and completing in the resulting norm gives a Hilbert space. On

206
A nonlinear ﬁeld theory
t
the Hilbert space we can reconstruct ﬁeld operators which reproduce the Schwinger
functions Sn. The inﬁnite volume Schwinger functions Sn will be time translation
invariant (although the ﬁnite volume were not) and one can use this to construct
a semi-group e−tH which generates the time translations. All this is analogous to
the Wightman reconstruction theorem. Then using the semi-group one can make an
analytic continuation to real time and get a family of distributions Wn satisfying the
Wightman axioms and hence a full ﬁeld theory. This reconstruction theorem exists
in various forms and was originally due to Osterwalder and Schrader.
This approach generalizes to other models and has a number of advantages:
1. It turns out to be relatively easy to prove the reﬂection positivity (13.81) directly
in path space without establishing the connection with Fock space as in (13.71).
Thus the whole Fock space construction can be dispensed with.
2. Properties of the Wightman functions can be deduced from simpler properties
of the Schwinger functions. In particular Poincaré invariance of the Wightman
functions can be deduced from the invariance of the Schwinger functions under
the Euclidean group (translations, rotations). Also locality for the Wightman
functions can be deduced from the symmetry of the Schwinger functions.
3. Expressions such as (13.79) for the ﬁnite volume Schwinger functions can be
thought of as the correlation functions for a problem in classical statistical
mechanics. The phase space is all ﬁeld conﬁgurations on a Euclidean space.
Hence in studying the Schwinger functions one can sometimes use techniques
developed for classical statistical mechanics, for example in proving the existence
of the inﬁnite volume limit. (This works the other way also: ﬁeld theory tech-
niques have proved to be useful in statistical mechanics problems, both classical
and quantum.)
The φ4
2 model and more generally the P(φ)2 models have been completely con-
structed along the lines we have been discussing. Other nonlinear models have also
been treated with varying degrees of success. In higher dimensions the renormaliza-
tion problems become much more severe (for us Wick ordering was sufﬁcient). The
model φ4
3 has been constructed, but φ4
4 probably does not exist. There is as yet no
model completely constructed in d = 4.
Once a model is constructed the next task is to ﬁnd what particles are present.
Then one looks for states whose long time behavior consists of a ﬁnite number of
particles moving in separate trajectories. This is analogous to the construction of
wave operators in section 4.5 and is the content of the Haag–Ruelle scattering theory.
From these asymptotic states, one forms scattering amplitudes which can in principle
be compared with the results of scattering experiments (in d = 4).
Notes on chapter 13: For the P(φ)2 model see Glimm and Jaffe (1970), Nelson
(1973), Simon (1975), Glimm and Jaffe (1987).

207
13.5 A reformulation
t
For an axiomatic treatment of quantum ﬁeld theory see Streater and Wightman
(1964) or Bogolubov Logunov and Todorov (1975).
There is also a treatment of relativistic quantum physics in which ﬁelds are
displaced as the primary objects and replaced by C∗algebras with a local struc-
ture. This has certain advantages and some believe is a more fundamental approach.
For this algebraic version of quantum ﬁeld theory see Haag (1992).
There are also books which attempt to explain quantum ﬁeld theory as practiced
by theoretical physicists to a mathematical audience, for example Folland (2008).

A
Appendix A Normed spaces
A.1 Banach spaces
We review some basic facts. A Banach space X is a complete normed vector space.
The vector space can be real or complex, but is complex unless speciﬁed otherwise.
The norm is a real-valued function on X sending x ∈X to ∥x∥which satisﬁes:
1. ∥cx∥= |c|∥x∥for c ∈C
2. ∥x + y∥≤∥x∥+ ∥y∥
3. ∥x∥≥0 and ∥x∥= 0 iff x = 0.
The norm makes X into a metric space with distance function
d(x, y) = ∥x −y∥
(A.1)
As such it is a topological space and we have all the usual notions of open sets,
closed sets, dense sets, connected sets, compact sets, etc. To say X is complete
means that every Cauchy sequence in X has a limit in X. That is if ∥xn −xm∥→0
as n, m →∞, then there exists a (unique) x ∈X such that ∥xn −x∥→0 as
n →∞.
Examples:
1. For 1 ≤p < ∞let ℓp be the space of inﬁnite sequences of complex numbers
x = (x1, x2, . . . ) such that
∥x∥p =
 ∞

i=1
|xi|p
1/p
(A.2)
is ﬁnite. Then ℓp is a Banach space with this norm.
2. For 1 ≤p < ∞let Lp(Rn) be the space of all complex measurable functions u on
Rn such that the integral with respect to Lebesgue measure
∥u∥p =

|u(x)|pdx
1/p
(A.3)
is ﬁnite. If we identify functions which are equal almost everywhere, then Lp(Rn)
is a Banach space with this norm.
208

209
A.2 Hilbert spaces
t
3. Let L∞(Rn) be the space of all complex measurable functions u on Rn which
are bounded almost everywhere. Identifying functions which are equal almost
everywhere, this is a Banach space with the essential supremum norm
∥u∥∞= ess supx|u(x)|
(A.4)
4. Any closed subspace of a Banach space is a Banach space
Theorem A.1
Any normed vector space X0 can be identiﬁed as dense subspace of a
Banach space X = X0 called the completion of X0.
We sketch the construction. The space X is equivalence classes of Cauchy
sequences in X0 with {xi} ∼{x′
i} if ∥xi −x′
i∥→0 as i →∞. Then X is
naturally a vector space. One shows that limi→∞∥xi∥exists and depends only
on the equivalence class. This gives a norm on X and one shows that X is
complete. X0 is identiﬁed as the subspace of (equivalence classes of) constant
sequences.
A.2 Hilbert spaces
A Hilbert space H is a complete inner product space. An inner product on a vector
space H is a map from pairs u, v ∈H to (u, v) ∈C such that
1. (u, v) is linear in v and anti-linear in u.
2. (u, v) = (v, u)
3. (u, u) ≥0 and (u, u) = 0 iff u = 0
The inner product deﬁnes a norm by ∥u∥= √(u, u). Thus an inner product space is
a normed space. Complete means complete as a normed space. Thus a Hilbert space
is a Banach space.
The inner product can be recovered from the norm by the polarization identity
(u, v) = 1
4

∥u + v∥2 −∥u −v∥2 −i∥u + iv∥2 + i∥u −iv∥2
(A.5)
We also have the Schwarz inequality
|(u, v)| ≤∥u∥∥v∥
(A.6)
Examples:
1. ℓ2 is a Hilbert space with (x, y) = ∞
i=1 ¯xiyi.
2. L2(Rn) is a Hilbert space with (u, v) =

u(x)v(x)dx.
3. Any closed subspace of a Hilbert space is a Hilbert space.
4. Let H1, H2 be Hilbert spaces then H1 ×H2 ( = all pairs < u1, u2 > with u1 ∈H1
and u2 ∈H2 ) is a Hilbert space when supplied with the inner product

210
Normed spaces
t
(< u1, u2 >, < v1, v2 >) = (u1, v1) + (u2, v2)
(A.7)
This Hilbert space is denoted H1 ⊕H2.
If S is any subspace of a Hilbert space H, not necessarily closed, then
S⊥= {u ∈H : (u, v) = 0 for all v ∈S}
(A.8)
is the orthogonal subspace. Then S⊥is closed and (S⊥)⊥= ¯S, the closure of S.
Theorem A.2 (Projection theorem)
Given a closed subspace M of H, any u ∈H can
be uniquely written as a sum u = u1 + u2 where u1 ∈M and u2 ∈M⊥.
Then the map u →< u1, u2 > gives a natural isomorphism between H and M ⊕
M⊥and we write
H = M ⊕M⊥
(A.9)
A linear functional L on H is a linear function from H to C. We say L is bounded
if |L(u)| ≤C∥u∥for some constant C. A bounded linear functional is a continu-
ous linear functional, and the converse is also true. The space of all bounded linear
functionals denoted H′ is a normed space with
∥L∥= sup
u̸=0
|L(u)|
∥u∥= sup
∥u∥=1
|L(u)|
(A.10)
Then ∥L(u)∥≤∥L∥∥u∥. The space H′ is also a Hilbert space called the dual space
of H. The dual space can be identiﬁed with H because:
Theorem A.3 (Riesz representation theorem)
Let L be a bounded linear functional on a
Hilbert space H. Then there is a unique v ∈H such that L(u) = (v, u). Furthermore
∥L∥= ∥v∥.
An orthonormal set in H is a sequence of vectors {φi} with i = 1, 2, · · · such that
(φi, φj) = δij =
4
1
if i = j
0
if i ̸= j
(A.11)
Theorem A.4
The following conditions on an orthonormal set {φi} are equivalent
1. (φi, f) = 0 for all i implies f = 0.
2. The subspace of ﬁnite linear combinations of the {φi} is dense.
3. f = ∞
i=1(φi, f)φi for f ∈H.
4. ∥f∥2 = ∞
i=1 |(φi, f)|2 for f ∈H.
5. (f, g) = ∞
i=1(f, φi)(φi, g) for f, g ∈H.
If one and hence all of these conditions hold, the {φi} are said to be complete and
constitute an orthonormal basis.

B
Appendix B Tensor product
We give a deﬁnition of the tensor product of two Hilbert spaces H1, H2. Given
u ∈H1 and v ∈H2 we deﬁne an anti-linear functional u ⊗v on H1 × H2 by
(u ⊗v) < w1, w2 >= (w1, u)(w2, v)
(B.1)
We have
u1 ⊗v + u2 ⊗v = (u1 + u2) ⊗v
(αu ⊗v) = α(u ⊗v) = (u ⊗αv)
(B.2)
for α ∈C. The algebraic tensor product H1 ˇ⊗H2 is deﬁned to be the space of
functionals which are ﬁnite combinations of the u ⊗v, that is all functionals of the
form 
j uj ⊗vj. A particular functional may have more than one representation of
this form.
We want to deﬁne an inner product on the algebraic tensor product so that
⎛
⎝
j
uj ⊗vj,

k
u′
k ⊗v′
k
⎞
⎠=

j,k
(uj, u′
k)(vj, v′
k)
(B.3)
Note that this entails
∥u ⊗v∥= ∥u∥∥v∥
(B.4)
Lemma B.1
Equation (B.3) deﬁnes an inner product on H1 ˇ⊗H2.
Proof
First we must check that it is well-deﬁned, that is independent of the repre-
sentation. It sufﬁces to show that if 
j uj ⊗vj = 0, then the inner product with any
other element is zero. But this follows since
⎛
⎝
k
u′
k ⊗v′
k,

j
uj ⊗vj
⎞
⎠=

k
 
j
uj ⊗vj

< u′
k, v′
k >= 0
(B.5)
It is straightforward to check that the inner product is bilinear. We must check that
it is positive deﬁnite. Given  ∈H1 ˇ⊗H2 we can pick orthonormal bases {φa} for
H1 and {ψb} for H2 such that
 =

ab
cab φa ⊗ψb
(B.6)
211

212
Tensor product
t
with only a ﬁnite number of the cab not equal to zero. Then
(, ) =

aba′b′
¯cabca′b′(φa ⊗ψb, φa′ ⊗ψb′) =

ab
|cab|2 ≥0
(B.7)
If the inner product is zero, then all cab = 0 and hence  = 0.
Now we deﬁne the tensor product H1 ⊗H2 to be the Hilbert space which is the
completion of H1 ˇ⊗H2 in the inner product (B.3).
Lemma B.2
1. If D1 is a dense subspace of H1 and D2 is a dense subspace of H2, then the
algebraic tensor product D1 ˇ⊗D2 is a dense subspace of H1 ⊗H2.
2. If {φa} is an orthonormal basis for H1 and {ψb} is an orthonormal basis for H2,
then φa ⊗ψb is an orthonormal basis for H1 ⊗H2.
Proof
Given  ∈H1 ⊗H2 and ϵ > 0 choose N
k=1 uk ⊗vk so that
∥ −
N

k=1
uk ⊗vk∥< ϵ
3
(B.8)
Now let M = supk{∥uk∥, ∥vk∥} and choose u′
k ∈D1 and v′
k ∈D2 so that ∥uk −u′
k∥≤
ϵ/3MN and ∥vk −v′
k∥≤ϵ/3MN. Then we have
∥
N

k=1
uk ⊗vk −
N

k=1
u′
k ⊗v′
k∥
≤
N

k=1
∥(uk −u′
k) ⊗vk∥+
N

k=1
∥u′
k ⊗(vk −v′
k)∥
≤ϵ
3 + ϵ
3
(B.9)
Combining the above gives
∥ −
N

k=1
u′
k ⊗v′
k∥< ϵ
(B.10)
and proves the ﬁrst point.
For the second point let D1 be the ﬁnite span of the ﬁrst basis which is dense in H1
and let D2 be the ﬁnite span of the second basis which is dense in H2. Then D1 ⊗D2
is the ﬁnite span of {φa ⊗ψb} which is therefore dense.
If the Hilbert spaces are L2 spaces, then we can also identify the tensor product as
an L2 space:
Theorem B.1
There is a unitary operator U from L2(R) ⊗L2(Rm) to L2(Rn+m) such
that

U(u ⊗v)

(x, y) = u(x)v(y)
(B.11)

213
Tensor product
t
Proof
Let {φa(x)} be an orthonormal basis for L2(Rn) and let {ψb(y)} be an orthonor-
mal basis for L2(Rm). Then {φa(x)ψb(y)} is an orthonormal set in L2(Rn+m). We
deﬁne U on the ﬁnite span of the φa ⊗ψb by

U
 
ab
cab φa ⊗ψb

(x, y) =

ab
cab φa(x)ψb(y)
(B.12)
This is densely deﬁned and norm preserving and so extends to an isometry. To show
U is unitary we have to show that the range is dense, that is that {φa(x)ψb(y)} are
complete in L2(Rn+m).
Suppose that f(x, y) ∈L2(Rn+m) is orthogonal to all {φa(x)ψb(y)}. By Fubini’s
theorem
 
f(x, y)φa(x)dx

ψb(y)dy = 0
(B.13)
Since the ψb are dense, this implies

f(x, y)φa(x)dx = 0 for almost every y. Since
the φa are dense, this implies f(x, y) = 0 for almost every (x, y), hence f = 0 in
L2(Rn+m) as required.
It is now straightforward to check (B.11) to complete the proof.
If S is a bounded operator on H1 and T is a bounded operator on H2, then we
deﬁne an operator S ⊗T on H1 ˇ⊗H2 by
(S ⊗T)

k
uk ⊗vk

=

k
Suk ⊗Tvk
(B.14)
This is well-deﬁned since if 
k uk ⊗vk = 0, then

k
Suk ⊗Tvk

< w1, w2 >=

k
uk ⊗vk

< S∗w1, T∗w2 >= 0
(B.15)
Lemma B.3
S ⊗T is bounded and extends to a bounded operator on H1 ⊗H2
satisfying
∥S ⊗T∥= ∥S∥∥T∥
(B.16)
Proof
First consider the operator S⊗I. Let {φa} be an orthonormal basis for H1 and
let {ψb} be an orthonormal basis for H2. Consider vectors which are ﬁnite sums of
basis vectors of the form
 =

ab
cab φa ⊗ψb
(B.17)

214
Tensor product
t
Then we have
∥(S ⊗I)∥2 = ∥

ab
cab Sφa ⊗ψb∥2 = ∥

b

a
cab Sφa

⊗ψb∥2
=

b
∥

a
cab Sφa∥2 ≤∥S∥2 
b
∥

a
cab φa∥2
= ∥S∥2 
ab
|cab|2 = ∥S∥2∥∥2
(B.18)
Thus S ⊗I is bounded. Similarly I ⊗T is bounded. It follows that S ⊗T is bounded
since S ⊗T = (S ⊗I)(I ⊗T). Hence it extends to a bounded operator on H1 ⊗H2
and it is straightforward to check that the extension satisﬁes (B.14). We have also
∥S ⊗T∥≤∥S∥∥T∥
(B.19)
We omit the proof that this is actually an equality.
Reference: Reed and Simon (1980).

C
Appendix C Distributions
Distributions are a generalization of functions. In this appendix we consider a special
class of distributions called tempered distributions.
Recall from chapter 1 that the Schwartz space S(Rd) is the space of all complex-
valued inﬁnitely differentiable functions on Rd such that for any choice of multi-
indices α, β we have ∥xβDαf∥∞< ∞. A tempered distribution T is an element of
the dual space S′(Rd), that is it is a continuous linear functional from S(Rd) to C.
To each f ∈S(Rd) it assigns a complex number denoted T(f) or < T, f >.
To complete the deﬁnition we have to specify what “continuous” means in this sit-
uation and this means specifying a topology for S(Rd). Since S(Rd) is not a Banach
space, we do not have a norm to help us. Instead the topology is speciﬁed by the
family of semi-norms ∥xβDαf∥∞. (A semi-norm ρ(f) has the properties of a norm
except that ρ(f) = 0 need not imply f = 0.) Skipping the exact deﬁnition of the
topology we say that a linear functional T on S(Rd) is continuous if there exists a
semi-norm
∥f∥nm =
sup
|α|≤n,|β|≤m
∥xβDαf∥∞
(C.1)
and a constant C such that
|T(f)| ≤C∥f∥nm
(C.2)
for all f ∈S(Rd).
Examples:
1. Let g be a polynomially bounded measurable function on Rd. Then there is an
associated distribution Tg deﬁned by
< Tg, f >=

g(x)f(x)dx
(C.3)
Polynomially bounded means that h(x) = (1 + |x|2)−Ng(x) is in L1(Rd) for N
sufﬁciently large and so we have
|Tg(f)| ≤∥h∥1 sup
x
|(1 + |x|2)Nf(x)|
(C.4)
This can be dominated by a constant times a norm ∥f∥nm and hence Tg is a
tempered distribution. Usually we would write < g, f > instead of < Tg, f >.
215

216
Distributions
t
2. Let μ be a measure on Rd such that for some N

(1 + |x|2)−Ndμ(x) < ∞
(C.5)
Then we can deﬁne a tempered distribution by
Tμ(f) =

f(x)dμ(x)
(C.6)
The proof is similar to the previous example.
3. The delta function δx0 at x0 ∈Rd is the tempered distribution deﬁned by
δx0(f) =< δx0, f >= f(x0)
(C.7)
This is a special case of the previous example. The measure is the point
measure at x.
4. Given complex numbers c1, . . . , cn, multi-indices α1, . . . , αn, and points
x1, . . . , xn in Rd there is a tempered distribution deﬁned by
T(f) =

i
ci(Dαif)(xi)
(C.8)
These are generally not given as functions or measures.
In the ﬁrst example we have seen that polynomially bounded functions determine
distributions. In fact it turns out that the map g →Tg is injective in the sense
that if Tg = Th, then g = h almost everywhere.1 Thus we can identify such func-
tions as a subspace of S′(Rd). Accordingly it is appropriate to refer to the tempered
distributions as generalized functions.
Even for distributions which are not functions it is sometimes convenient to write
< T, f > as if it were a function by < T, f >=

T(x)f(x)dx with some suggestive
symbol T(x). In particular we write:
< δx0, f >=

δ(x −x0)f(x)dx
(C.9)
Let O ⊂Rd be open and let C∞
0 (O) be the inﬁnitely differentiable functions with
compact support in O. A distribution T is said to vanish on O if < T, f >= 0 for all
f ∈C∞
0 (O). The support of T is the smallest closed set such that T vanishes on the
complement. For example the support of δx0 is the single point x0.
Next we deﬁne some operations on tempered distributions.
1. (Multiplication by a smooth function) Suppose that h is a smooth polynomially
bounded function and T ∈S′(Rd). Then we can deﬁne hT ∈S′(Rd) by
< hT, f >=< T, hf >
(C.10)
1 If g, h are in L2(Rd) this is immediate since Tg = Th implies that (¯g −¯h, f) = 0 for all f in the dense
set S(Rd), hence for all f ∈L2, hence g −h = 0 in L2.

217
Distributions
t
This makes sense since if f ∈S(Rd), then hf ∈S(Rd). The deﬁnition satisﬁes
hTg = Thg.
2. (Derivatives) Any tempered distribution T has a partial derivative ∂μT = ∂T/∂xμ,
which is the tempered distribution deﬁned by
< ∂μT, f >= −< T, ∂μf >
(C.11)
If the distribution is a differentiable function, say Tg with g ∈S(Rd), then
integrating by parts this is computed as
−< Tg, ∂μf >= −

g(x)∂μf(x)dx =

∂μg(x)f(x)dx =< T∂μg, f >
(C.12)
Hence ∂μTg = T∂μg and the deﬁnition extends the deﬁnition on smooth functions.
It follows that any linear differential operator can be applied to a distribution,
even operators with smooth variable coefﬁcients.
Examples:
In d = 1 consider the distribution deﬁned by the Heaviside function
θ which is the characteristic function of [0, ∞). Then
< dθ
dx , f >= −< θ, df
dx >= −
 ∞
0
df
dx = f(0)
(C.13)
and thus
dθ
dx = δ0
(C.14)
3. (Fourier transform) Since the Fourier transform maps S(Rd) to itself (see
chapter 1), we can deﬁne the Fourier transform on a distribution T by
< FT, f >=< T, Ff >
(C.15)
This agrees with the deﬁnition on functions, that is if g ∈L2(Rd), then FTg =
TFg. To see this use the fact the F is unitary on L2(Rd) to compute for f ∈S(Rd)
< FTg, f >=< Tg, Ff >= (¯g, Ff)
= (F−1¯g, f) = (Fg, f) =< TFg, f >
(C.16)
Also F is a bijection on S′(Rd); this follows from the fact that F is a bijection on
S(Rd).
Examples:
We have (Fδx)(p) = (2π)−d/2e−ipx since
< Fδx, f >=< δx, Ff >= Ff(x) = (2π)−d/2

e−ipxf(p)dp
(C.17)
Other examples are
F(1) = (2π)d/2δ0
F(∂μδ0) = ipμ(2π)−d/2
(C.18)
Next we quote the kernel theorem which says that a multilinear functional on S
has a kernel in S′.

218
Distributions
t
Theorem C.1
Let T(f1, . . . , fn) be a multilinear functional continuous in each fi ∈
S(Rd). Then there is a unique T ∈S′(Rnd) such that
T(f1, . . . , fn) = T(f1 ⊗· · · ⊗fn)
(C.19)
where f1 ⊗· · · ⊗fn ∈S(Rnd) is deﬁned by
(f1 ⊗· · · ⊗fn)(x1, . . . , xn) = f1(x1) · · · fn(xn)
(C.20)
Examples:
Let T be a bounded operator on L2(Rd). Then (¯f1, Tf2) is a continuous
bilinear function on S(Rd) × S(Rd) and so by the theorem there is a T ∈S′(R2d)
such that (¯f1, Tf2) = T(f1 ⊗f2). Replacing f1 by ¯f1 and denoting the distribution T by
T(x, y) this can also be written
(f1, Tf2) =

¯f1(x)T(x, y)f2(y)dxdy
(C.21)
Then T(x, y) is called the kernel of the operator. (Not to be confused with the null
space, which is also called the kernel.) For example the kernel of the identity is
δ(x −y).
For completeness we quote the general deﬁnition of distributions. These are
deﬁned in open sets O ⊂Rd. Let D(O) = C∞
0 (O), the inﬁnitely differentiable
functions on O with compact support. A distribution T is an element of the dual
space D′(O), that is it is a linear functional f →T(f) on D(O) which is continuous
in the sense that for every compact subset K ⊂O there are constants k, C such that
|T(f)| ≤C
sup
|α|≤k,x∈K
|(Dαf)(x)|
(C.22)
for all f ∈D(O) with supp f ⊂K.
Tempered distributions are distributions in this sense: S′(Rd) ⊂D′(Rd).
References: Yosida (1966), Reed and Simon (1980), or Taylor (1996).

References
Abraham, R. and Marsden, J. 1978. Foundations of Mechanics. Benjamin.
Albeverio, S., Gesztesy, G., Hoegh-Krohn, R., and Holden, H. 1988. Solvable Models in
Quantum Mechanics. Springer.
Albeverio, S., Hoegh-Krohn, R., and Mazzucchi, S. 2008. Mathematical Theory of Feynman
Path Integrals: An Introduction. Springer.
Bachelot, A. 1999. The Hawking effect. Ann. Inst. Henri Poincaré, 70, 41–99.
Baez, J., Segal, I., and Zhou, Z. 1992. Introduction to Algebraic and Constructive Quantum
Field Theory. Princeton University Press.
Bär, C., Ginoux, N., and Pfäfﬂe, F. 2007. Wave Equations on Lorentzian Manifolds and
Quantization. European Mathematical Society Publishing House.
Billingsley, P. 1979. Probability and Measure. Wiley.
Bogolubov, N.N., Logunov, A.A., and Todorov, I.T. 1975. Introduction to Axiomatic Quantum
Field Theory. Benjamin.
Bratteli, O. and Robinson, D. 1981. Operator Algebras and Quantum Statistical Mechanics II.
Springer.
Brunetti, R., Fredenhagen, K., and Verch, R. 2003. The generally covariant locality
principle - a new paradigm for local quantum ﬁeld theory. Commun. Math. Phys., 237,
31–68.
Choquet-Bruhat, Y., DeWitt-Morette, C., and Dillard-Bleick, M. 1977. Analysis, Manifolds,
and Physics I. North Holland.
Choquet-Bruhat, Y. and DeWitt-Morette, C. 1989. Analysis, Manifolds, and Physics II. North
Holland.
Cycon, H., Froese, R., Kirsch, W., and Simon, B. 1987. Schrödinger Operators. Springer.
Dimock, J. 1980. Algebras of local observables on a manifold. Commun. Math. Phys., 77,
219–228.
Drechsler, W. and Mayer, M. 1977. Fiber Bundle Techniques in Gauge Theory. Springer.
Durrett, R. 1996. Stochastic Calculus. CRC press.
Folland, G. 2008. Quantum Field Theory: A Tourist Guide for Mathematicians. American
Mathematical Society.
Frankel, T. 2004. The Geometry of Physics. Cambridge University Press.
Gallavotti, G. 1983. The Elements of Mechanics. Springer.
Gelfand, I.M. and Vilenkin, N. 1964. Generalized Functions IV. Academic Press.
Glimm, J. and Jaffe, A. 1970. Quantum ﬁeld theory models, pages 1–108 of: DeWitt, C. and
Stora, R. (eds), Statistical Mechanics and Quantum Field Theory. Gordon & Breach.
Glimm, J. and Jaffe, A. 1972. The (λφ4)2 quantum ﬁeld theory without cutoffs IV. Perturba-
tions of the Hamiltonian. J. Math. Phys., 13, 1568–1584.
Glimm, J. and Jaffe, A. 1987. Quantum Physics: A Functional Integral Point of View.
Springer.
219

220
References
t
Glimm, J., Jaffe, A., and Spencer, T. 1974. The Wightman axioms and particle structure in the
P(φ)2 quantum ﬁeld model. Ann. Math., 100, 585–632.
Gustafson, S. and Sigal, I.M. 2003. Mathematical Concepts of Quantum Mechanics. Springer.
Haag, R. 1992. Local Quantum Physics. Springer.
Hall, B. 2003. Lie Groups, Lie Algebras, and Representations. Springer.
Huang, K. 2009. Introduction to Statistical Physics. CRC Press.
Isham, C.J. 1995. Lectures on Quantum Theory: Mathematical and Structural Foundations.
Imperial College Press.
Itzykson, C. and Zuber, J. 1980. Quantum Field Theory. McGraw-Hill.
Jauch, J. 1968. Foundations of Quantum Mechanics. Addison-Wesley.
Kato, T. 1966. Perturbation Theory for Linear Operators. Springer.
Kay, B. 1979. A uniqueness result in the Segal–Weinless approach to linear Bose ﬁelds.
J. Math. Phys., 20, 1712–1713.
Landau, L. and Lifschitz, E. 1969. Statistical Physics. Addison-Wesley.
Lieb, E. and Seiringer, R. 2010. The Stability of Matter in Quantum Mechanics. Cambridge
University Press.
Marsden, J. and Ratiu, T. 1994. Introduction to Mechanics and Symmetry. Springer.
Miller, W. 1972. Symmetry Groups and Their Applications. Academic Press.
Misner, C., Thorne, K., and Wheeler, J. 1973. Gravitation. W.H. Freeman.
Nelson, E. 1973. Probability theory and Euclidean ﬁeld theory, pages 94–124 of: Velo, G. and
Wightman, A. (eds), Constructive Quantum Field Theory. Springer.
von Neumann, J. 1955. Mathematical Foundations of Quantum Mechanics. Princeton
University Press.
Newton, T. and Wigner, E. 1949. Localized states for elementary systems. Rev. Mod. Phys.,
21, 400–406.
Ohnuki, Y. 1988. Unitary Representations of the Poincaré Group and Relativistic Wave
Equations. World Scientiﬁc.
Peskin, M. and Schroeder, D. 1995. An Introduction to Quantum Field Theory. Perseus.
Reed, M. and Simon, B. 1980. Methods of Modern Mathematical Physics, Vol. I: Functional
Analysis. Academic Press.
Reed, M. and Simon, B. 1975. Methods of Modern Mathematical Physics, Vol. II: Fourier
Analysis, Self-adjointness. Academic Press.
Reed, M. and Simon, B. 1979. Methods of Modern Mathematical Physics, Vol. III: Scattering
Theory. Academic Press.
Reed, M. and Simon, B. 1978. Methods of Modern Mathematical Physics, Vol. IV: Analysis of
Operators. Academic Press.
Roman, P. 1969. Introduction to Quantum Field Theory. Wiley.
Ruelle, D. 1969. Statistical Mechanics. Benjamin.
Sachs, R. and Wu, H.-H. 1977. General Relativity for Mathematicians. Springer.
Salmhofer, M. 1999. Renormalization: An Introduction. Springer.
Schweber, S. 1962. An Introduction to Relativistic Quantum Field Theory. Harper & Row.
Segal, I.E. 1956. Tensor algebras over Hilbert spaces. Trans. Am. Math. Soc., 81, 106–134.
Simon, B. 1975. The P(φ)2 Euclidean Field Theory. Princeton University Press.
Simon, B. 1979. Functional Integration and Quantum Physics. Academic Press.
Streater, R. and Wightman, A. 1964. PCT, Spin-Statistics, and All That. Benjamin.
Strocchi, F. and Wightman, A. 1974. Proof of the charge superselection rule in local relativistic
quantum ﬁeld theory. J. Math. Phys., 15, 2198–2224.

221
References
t
Takhtajan, L. 2008. Quantum Mechanics for Mathematicians. American Mathematical
Society.
Taylor, M. 1996. Partial Differential Equations I: Basic Theory. Springer.
Titchmarsh, E. 1939. The Theory of Functions. Oxford University Press.
Wald, R. 1994. Quantum Field Theory in Curved Spacetime and Black Hole Thermodynamics.
University of Chicago Press.
Weinberg, S. 1995. The Quantum Theory of Fields. Cambridge University Press.
Yosida, K. 1966. Functional Analysis. Springer.

Index
action, 111, 187
algebra
C∗, 8, 91, 207
Clifford, 105
Lie, 36, 110
algebraic quantum ﬁeld theory, 207
algebraic statistical mechanics, 91
analytic Fredholm theorem, 51, 52
angular momentum, 35, 44
annihilation operator, 71, 75, 148
anti-commutator, 73, 139
anti-particles, 128, 140
asymptotic completeness, 57
atoms, 68
axioms, 38
Banach space, 208
boost, 102
Borel
function, 19
set, 19
Bose–Einstein condensation, 87
bosons, 66, 83
bound state, 55
boundary conditions, 16, 83
Brownian motion, 165
in Rd, 167
regularity, 167
canonical commutation relations, 42, 114, 120,
157, 184, 192
canonical quantization, 41
canonical transformation, 32
Cauchy surface, 153
causal curve, 153
CCR, see canonical commutation relations
center of mass, 65
characteristic function, 162, 175
charge
from an internal symmetry group, 128
in classical ﬁeld theories, 104, 106, 109, 110
in classical mechanics, 30
in quantum ﬁeld theories, 128, 141
charge conjugation, 138
chemical potential, 81
conservation
angular momentum, 35, 44, 69
charge, 104, 126
energy, 29, 100
momentum, 35, 44, 69, 100
core, 12
correlation functions
Schwinger, 188, 204
thermal, 82, 189
vacuum, 187
Wightman, 197
covariance of random variables,
164, 174
creation operator, 71, 76, 148
current, 1, 104, 106
cylinder function, 180
d’Alembertian, 103
delta function, 197, 216
density, 82, 85
density operator, 78
Dirac equation, 105, 132
covariance, 132
Green’s identity, 106
positive energy solutions, 134
Dirac ﬁelds
classical, 105
covariance, 143
locality, 143
quantized, 139
Dirac sea, 140
distribution, 218
S′(Rd), 215
as generalized function, 216
kernel theorem, 217
of a random variable, 162
tempered, 179, 215
222

223
Index
t
domains
D0, 73
DS, 76
Ehrenfest’s theorem, 43, 120
eigenvalue, 13
Einstein, 2, 96
electric ﬁeld, 1, 30
electromagnetic ﬁeld
classical, 100, 106, 109
covariance, 107, 149
locality, 149
quantized, 148
electromagnetic potential, see electromagnetic
ﬁeld
electrons, 67, 132
energy, 29, 99
ensemble
canonical, 79
grand canonical, 81
microcanonical, 79
expectation
quantum, 39
random variable, 162
Fermi sea, 87
fermions, 67, 86
Feynman path integrals, 161, 173
Feynman–Kac formula, 168, 171, 185, 202
Fock space, 70
four-momentum, 98
Fourier series, 83
Fourier transform
on distributions, 217
on functions, 10
free energy, 82
free particle
quantum, 47
quantum and relativistic, 114
relativistic, 97
function spaces
Lp(Rn), 208
C∞
0 (Rn), 9
H−1(Rn), 186
S(Rn), 9
fundamental constant
¯h, 40, 43
c, 1, 99
k, 80
gamma matrices, 105
gauge
Coulomb, 145
covariant, 146
potential, 110
transformation, 30, 108, 126, 141
Gaussian
measure, 179
process, 164, 174
random variable, 163
general relativity, 2, 96
generalized functions, 216
generator
of a semi-group, 21
of a unitary group, 21
of Hamiltonian ﬂow, 34
geodesics, 97, 153
globally hyberbolic manifold, 153
graph of operator, 12
graphs, 179
Green’s identity, 104, 106, 154
ground states, 171
group
O(1, 3), 102
O(3), 36
Pin(1, 3), 130
SO(3), 36, 60
SO(n), 107
SU(2), 59
Spin(1, 3), 131
U(1), 108
L,L+, L↑
+, 102
P, P↑
+, 102
SL(2, C), 151
Lie, 36, 37
one-parameter unitary, 20
symplectic, 32
Gupta–Bleuler quantization, 147
Hadamard singularity, 157
Hamiltonian
classical, 28
Dirac, 134
Pauli, 61
quantum, 41
vector ﬁeld, 33
harmonic oscillator, 53, 170
Hausdorff–Young inequality, 195
Hawking, 158
Heisenberg picture, 40
Heisenberg uncertainty principle, 43
Hermite polynomials, 54, 177

224
Index
t
Hilbert space, 209
hydrogen atom, 50, 53, 66
indeﬁnite inner product, 106, 131, 146
inﬁnite volume limit, 83, 91, 197, 203
integration by parts, 180
Jacobi identity, 29
Kato’s theorem, 49
kernel theorem, 217
Klein–Gordon equation, 103
positive energy solutions, 116
covariance, 104
existence and uniqueness, 103, 154
fundamental solutions, 111, 154
Green’s identity, 104, 154
on a manifold, 154
propagator, 113, 155
with gauge potential, 109
KMS condition, 91, 189
Kolmogorov theorem, 163
Lie derivative, 33
locality, 125, 142, 143, 149, 156, 201
Lorentz force, 1, 30, 100
Lorentz group, 101
Lorentzian metric, 96, 152
magnetic ﬁeld, 1, 30, 50, 61
many particles
classical, 31, 35
quantum, 67, 69
relativistic, 100, 118
Markov process, 171
mass shell, 116
Maxwell’s equations, 1, 106
measure space, 161
measurement, 41, 78
Mehler’s formula, 55, 170
min-max theorem, 89
Minkowski space, 96
models
P(φ)2, 192
φ4
2, 192
φ4
3, φ4
4, 206
momentum, 28, 35, 44, 83, 99
momentum space, 43
Newton’s equation, 1
Newton–Wigner coordinates, 118, 134
nonabelian gauge theory, 111
non-relativistic limit, 115
number operator, 71
observable
classical, 29
quantum, 39
operator
adjoint, 14
bounded, 5
closed, 11
compact, 22
essentially self-adjoint, 15
ﬁnite rank, 22
graph, 12
Hilbert–Schmidt, 24
isometry, 6
kernel, 5, 218
linear, 5
partial isometry, 26
positive, 17
projection, 6
self-adjoint, 15
spectral projections, 19
spectrum, 13
symmetric, 14
trace class, 25
unitary, 7
Ornstein–Uhlenbeck process, see oscillator
process
orthonormal
basis, 210
set, 210
oscillator process, 169, 184
partition function, 80, 84, 86
Pauli
exclusion principle, 68
Hamiltonian, 61
matrices, 59
perturbation theory, 173
phase space, 28
phi-bound, 198
photon, 99, 144
Poincaré group, 101
extended, 136
representation, 117, 125, 137, 143, 200
Poisson bracket, 29
positive deﬁnite, 164
positive type, 88
positivity improving, 171

225
Index
t
positrons, 140
potential
Coulomb, 50, 52
delta function, 62, 193
harmonic oscillator, 53
rank one, 53, 56
Yukawa, 50
pressure, 82, 85
principle of general covariance, 96, 157
principle of least action, 110
propagator, 113, 155
proper time, 97
protons, 67, 141
quantum electrodynamics, 151
random variable, 162
ray, 38
reconstruction theorem
Osterwalder–Schrader, 206
Wightman, 199
reﬂection positivity, 205
renormalization, 151, 194, 206
resolvent set, 13
Riesz representation theorem, 210
Riesz–Schauder theorem, 23
rotation group, 36
scalar ﬁeld
locality, 125
charged, 104
charged quantized, 126
classical, 103
covariance, 125
external potential, 124
nonlinear, 111, 192
on a manifold, 154
quantized, 118
Schrödinger representation, 182
scattering
Haag–Ruelle, 206
operator, 57
single particle, 55
Schrödinger
equation, 40
picture, 40
representation, 181
Schwartz space, 9
Schwinger functions, 188, 204
self-adjoint operator, 15
semi-group, 21
Sobolev
inequality, 50
space, 186
spacetime, 95
spectral theorem, 18
spectrum, 13
continuous, 13
of compact operator, 23
of self-adjoint operator, 16
of unitary operator, 13
point, 13
residual, 13
spin, 58, 135, 145
spin-statistics, 67
spinor, 105, 131
stability condition, 88
standard model, 111
states
on C∗algebra, 91
equilibrium, 79
Gibbs, 80
ground, 171
mixed, 78
pure, 78
stationary, 80
statistics, 67
stochastic process, 162
Stone’s theorem, 21
strictly positive, 171
summation convention, 97
support
distribution, 216
function, 9
symmetries
in classical mechanics, 34
in quantum mechanics, 43
of spacetime, 101
symplectic
form, 34, 119, 123
group, 32
matrix, 32
tangent vector, 96, 152
temperature, 80
tensor product, 211
algebraic, 211
anti-symmetric, 67
symmetric, 66
thermodynamic limit, 83
time orientation, 153
trace, 25

226
Index
t
Trotter product formula, 168
vacuum, 70, 197, 201
vector bundle, 108
connection, 109
covariant derivative, 62, 109
line bundle, 62, 109
wave equation, 95, 107
wave operators, 55
wave function, 38
reduction, 41
spreading, 48
Wick
monomial, 177, 194
order, 123, 193
Wightman
functions, 197
reconstruction theorem, 199
worldline, 97

