Enjoy the Ride Consciously with CAWA: Context-Aware
Advisory Warnings for Automated Driving
Erfan Pakdamanian
School of Engineering
University of Virginia
Charlottesville, VA, USA
ep2ca@virginia.edu
Erzhen Hu
School of Engineering
University of Virginia
Charlottesville, VA, USA
eh2qs@virginia.edu
Shili Sheng
School of Engineering
University of Virginia
Charlottesville, VA, USA
ss7dr@virginia.edu
Sarit Kraus
Department of Computer Science
Bar-Ilan University
Tel Aviv, Isreal
sarit@cs.biu.ac.il
Seongkook Heo
School of Engineering
University of Virginia
Charlottesville, VA, USA
seongkook@virginia.edu
Lu Feng
School of Engineering
University of Virginia
Charlottesville, VA, USA
lu.feng@virginia.edu
Figure 1: The study‚Äôs proposed context-aware advisory warning method, CAWA. a) Detection of the NDRT in which the driver is
engaged, b) Selecting the type of modality according to detected activity.
ABSTRACT
In conditionally automated driving, drivers decoupled from driv-
ing while immersed in non-driving-related tasks (NDRTs) could
potentially either miss the system-initiated takeover request (TOR)
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
AutomotiveUI ‚Äô22, September 17‚Äì20, 2022, Seoul, Republic of Korea
¬© 2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9415-4/22/09.
https://doi.org/10.1145/3543174.3546835
or a sudden TOR may startle them. To better prepare drivers for a
safer takeover in an emergency, we propose novel context-aware
advisory warnings (CAWA) for automated driving to gently inform
drivers. This will help them stay vigilant while engaging in NDRTs.
The key innovation is that CAWA adapts warning modalities ac-
cording to the context of NDRTs. We conducted a user study to
investigate the effectiveness of CAWA. The study results show that
CAWA has statistically significant effects on safer takeover behavior,
improved driver situational awareness, less attention demand, and
more positive user feedback, compared with uniformly distributed
speech-based warnings across all NDRTs.

AutomotiveUI ‚Äô22, September 17‚Äì20, 2022, Seoul, Republic of Korea
Pakdamanian et al.
CCS CONCEPTS
‚Ä¢ Human-centered computing ‚ÜíEmpirical studies in HCI.
KEYWORDS
advisory warning; automated driving; takeover behavior; context-
aware warning; multimodal adaptive warning; haptic warning; visual
warning; auditory warning
ACM Reference Format:
Erfan Pakdamanian, Erzhen Hu, Shili Sheng, Sarit Kraus, Seongkook Heo,
and Lu Feng. 2022. Enjoy the Ride Consciously with CAWA: Context-Aware
Advisory Warnings for Automated Driving. In 14th International Conference
on Automotive User Interfaces and Interactive Vehicular Applications (Au-
tomotiveUI ‚Äô22), September 17‚Äì20, 2022, Seoul, Republic of Korea. ACM,
New York, NY, USA, 11 pages. https://doi.org/10.1145/3543174.3546835
1
INTRODUCTION
The rapid development of autonomous driving technologies promises
a future where drivers can take their hands off the steering wheels,
foot off the pedals, and instead engage in non-driving related tasks
(NDRTs) such as reading or using mobile devices. While full self-
driving vehicles are not yet commercially available, we are at the
stage that conditionally automated driving (level 3 of autonomy,
defined by the Society of Automotive Engineers (SAE) [9]) provides
various forms of driver assistance, advanced monitoring systems,
and control of the longitudinal and lateral vehicle kinematics on a
sustained basis. Although in conditionally automated driving, drivers
do not need to continuously monitor the driving environment, due to
current technology limitations and legal restrictions, the automated
system still needs to relinquish the control back and ask the human
driver to resume the control in case of system failures, anticipated
dangerous situation, or exceeding its operational limit via a so-called
take-over request (TOR) [4, 17].
A growing body of research shows that being immersed in NDRTs
for an extended period of time causes the level of situation awareness
to fall below a comfortable point to safely recover manual control,
mainly in urgent situations [33, 40, 57]. Importantly, the control tran-
sition process and taking control back cause longer reconfiguration
of cognitive and motoric states for drivers to react properly [22, 33].
Thus, human factors researchers argue while most vehicles are not
completely self-driving, safety hurdles arise in automated vehicles.
Recent fatal crashes indicate drivers‚Äô failures to promptly and prop-
erly respond to a TOR due to the loss of situation awareness [6].
Hence, a key challenge is how to maintain driver readiness for a safe
takeover while enabling an enjoyable user experience of engaging
in NDRTs. Most existing works focus on the design of TORs, such
as its timing [14, 62] and modalities [39, 49, 61]. On the one hand,
limitations on current vehicle sensing technologies pose constraints
on how early hazardous road incidents can be detected for initiating
TORs. The takeover time-budget between the TOR initiation and the
incident occurrence is typically 5-7 seconds [63], which may not be
long enough for drivers immersed in NDRTs to regain situational
awareness and resume manual driving in a timely and safe fashion.
On the other hand, current incorporated unimodal or multimodal
TOR may suddenly inform drivers about an upcoming hazard [63],
which may in fact startle and stress the driver and leaving the driver
in a less capable state to execute a life-saving maneuver.
To address the aforementioned limitations, we propose context-
aware advisory warnings (CAWA) for automated driving to gently
and adaptively inform drivers (see Figure 1), helping them stay
vigilant while engaging in NDRTs. Previous studies on advisory
warnings mainly regard manual driving system settings that alert
drivers prior an upcoming hazard [31, 52]. In contrast, we consider
advisory warnings for automated driving system to let drivers know
that they are entering the incipient phase of error creation. Then,
the key contributions of CAWA are two-fold: (1) CAWA adapts
warning modalities according to the NDRT context in which a driver
is immersed, for reducing the likelihood that a warning will go
unnoticed. (2) CAWA provides gentle warnings in contrast with
sudden and startling TORs. For example, if a driver is playing a
game on her mobile phone and is wearing headphones, CAWA sends
a text message warning to the phone to grab the driver‚Äôs attention,
while auditory or visual warnings may be missed.
In this study each participant experienced two driving scenarios,
CAWA and baseline. In the CAWA trial, advisory warnings were is-
sued depending on the context of NDRTs (e.g., text message warning
when the driver is playing a game on her mobile phone, visual warn-
ing when the driver is having a conversation) (see Figure 1). In the
baseline, however, auditory warnings were given uniformly for all
NDRTs. We compared CAWA with auditory warning as these are om-
nidirectional and have already widely applied by auto-manufacturers.
The user study demonstrated promising results. Compared with the
baseline, CAWA has statistically significant effects on safer takeover
behavior, improved driver situational awareness, less attention de-
mand for workload, and more positive driver perceptions.
To the best of our knowledge, this is the first study on context-
aware advisory warnings for automated driving. We believe that our
work has the potential to provoke future HCI research on integrating
advisory warnings into the design of automated vehicles, taking a
step toward improving the safety and user experience of automated
driving.
2
RELATED WORK
Takeover performance can be explained by both reaction time and
post takeover control [34, 40]. Despite many factors have been
identified contributing to better reaction time and takeover control
such as traffic density [19] and driver cognitive state [48, 56] or
emotion [51], the impact of time budget (‚Äúlead time‚Äù) [15] and TOR
modality [7] have been widely studied by researchers. For example,
studies show that additional second of time budget lead to increase
of reaction time by on average 0.27second [34, 63]. If drivers are
given more time to gain sufficient situation awareness, they could
prepare for the upcoming transition of control. Gold et al. [17] has
shown that shorter takeover times lead to faster responses but worse
maneuvers. On the other hand, a study by Merat et al. [35] suggests
20-40second of time budget for a safe takeover to fully stabilised
the vehicle after reclaiming control. As supplying such time budget
may not be technologically feasible at the moment, researchers are
required to study alternative approaches to enable drivers gaining
enough situation awareness as a function of available time [30].
To improve takeover time and quality, many warning modalities
have been studied such as audio [46], visual [23], vibrotactile [4]

Enjoy the Ride Consciously with CAWA
AutomotiveUI ‚Äô22, September 17‚Äì20, 2022, Seoul, Republic of Korea
and combination of these warning modalities [3]. Prior studies ex-
plored priming drivers before asking them to resume vehicle control.
In the study by van der Heiden [55], participants received audio
warnings 20 seconds prior to TORs, which caused them to disen-
gage from the NDRT earlier and look at the road more closely. In
another study [20], participants received visual warnings indicat-
ing the remaining driving time or distance until a TOR would be
issued. Compared with these existing works, our study employed a
richer set of warning modalities including speech-based cues, visual
head-up-displays, text messages, and vibrotactile cues.
Previous research has extensively studied different modalities
for in-vehicle alerts, in particular TORs. One of the most prevalent
modalities is auditory cues, which can be divided into two categories:
nonspeech- and speech-based. Compared with nonspeech-based au-
ditory tones, speech-based messages offer more information and
are more favorable to drivers [59]. Various representations of visual
cues have been designed and utilized, such as a head-up-display [16],
augment reality [28], and LED lights [8]. Studies also found that
vibrotactile and haptic cues can effectively alert drivers [10, 36, 53].
Recent efforts have been increasingly focusing on multi-modal alerts
where multiple modalities are triggered simultaneously [4, 44, 50].
While multi-modal alerts were found to be more effective (e.g., lead-
ing to shorter takeover reaction time), they were perceived as more
urgent and annoying [45]. Our study takes a different approach from
these existing works by incorporating advisory warnings instead of
TORs. Moreover, in order to avoid prevalence alert fatigue, CAWA
chooses a proper advisory warning from multiple modalities accord-
ing to the context of NDRTs, rather than triggering all modalities
simultaneously.
3
METHOD
In this section, we describe the experimental setup, design and pro-
cedure. The study protocol was approved by the Institutional Review
Board at University of Virginia (#IRB-SBS 4701).
3.1
Participants
We recruited a total of 20 participants (14 males; 6 females) with the
age range of 18-32 years old (mean= 22.65years; SD= 4.01years).
All eligible participants had normal or corrected-to-normal vision,
as well as a valid driver‚Äôs license (mean= 2.8 years, SD = 3.1 years).
None of the participants had previous experience with automated
driving or prior knowledge about the user study. We used 19 partici-
pants‚Äô data for the result analysis, excluding one participant due to
largely missing biometric data.
3.2
Experimental Apparatus
Driving simulator. The study was conducted in a fixed-based driving
simulator from SimXperience (Stage 5 Full Motion Racing simu-
lator, Figure 2). The setup consists of a 55-inch display (1280 √ó
720 pixel resolution) placed within a horizontal field-of-view and
approximately 63-inch away from the driving seat, a racing car seat,
a Logitech G29 steering wheel, and sport pedals. No gearshift was re-
quired and participants could switch between automated and manual
driving modes by pressing a designated button on steering wheel (see
Figure 2 for details). An Apple iPad Pro with a 9.7-inch display was
mounted on the right side of the driving seat for watching movies.
Figure 2: The driving simulator setup for the user study.
Tablet was mounted in common height of the infotainment systems
in a landscape format. A 2.0 channel sound bar speaker was placed
behind the driver seat for the auditory warnings. The virtual driving
environment was created using CARLA [13], an open-source driv-
ing simulation environment built on top of the Unreal Engine. The
vehicle was programmed to simulate an SAE Level 3 automation,
which handled the longitudinal and lateral vehicle kinematics, and
responded to traffic elements.
Biometrics. In this study, we collected drivers‚Äô psychophysiolog-
ical, vehicle-related metrics, workload, and perceived safety. We
used a Shimmer3+ wearable device to measure the driver‚Äôs heart rate
(PPG) and galvanic skin response (GSR) signals with a sampling
rate of 256 Hz. Heart rate variability (the time elapsed between two
successive R-waves) from PPG and maximum and mean phasic com-
ponents were calculated as the objective metrics reflecting cognitive
load variation and stress, respectively.
Face and activity cameras. We installed one high resolution cam-
era (NexiGo N930E 1080p webcam with ring light) above the steer-
ing wheel to monitor the driver‚Äôs eye and head movements. Since
CAWA required real-time detection of gaze behavior, we employed
state-of-the art pupil and iris localization models [42, 60] and mod-
ified it to fit our needs by integrating deep pictorial gaze estima-
tion [1, 41]. Thus, we were able to reliably estimate position and
direction of gaze in real-time. Figure 3 shows an example of the
face video examined to capture drivers‚Äô eye movements and gaze
directions. These videos helped to monitor and to identify when a
driver detected a threat or when took her eyes off the driving scene.
Furthermore, a high resolution camera (Logitech Ultra HD 1080p)
was used to extract participant‚Äôs driving and engagement activities.
Finally, we developed multiple APIs to forward all stream of data
to iMotions biometric platform for the real-time aggregation and
synchronization.
3.3
Experimental Design
We used a within-subject design with driver‚Äôs cognitive load, and the
modality of advisory warnings as independent variables (see Section
3.4). The cognitive load was manipulated via the difficulty of the
NDRTs (low: watching movie; mid: reading and having an informal
conversation; high: playing 2048 game) (see Table1). These four

AutomotiveUI ‚Äô22, September 17‚Äì20, 2022, Seoul, Republic of Korea
Pakdamanian et al.
Figure 3: Examples of estimated eye region landmarks around the iris and eyelid edges along with gaze direction while performing
NDRTs and after a takeover control. a) four main landmarks of eyes and pupil detection, b) gaze direction while looking at the phone,
c) gaze direction while reading a book, d) looking at the road after takeover control resumption.
activities were selected as the common activities drivers will most
likely engage with in L3 [29, 38]. Based on prior literature [24, 44],
four takeover events were designed in urban areas with typical road-
way features (see Figure 4). The difficulty of the scenarios was
designed to be approximately the same. Each participant executed
two sessions (CAWA and baseline) and the order of sessions was
counterbalanced across participants. Per session, the participant ex-
perienced 16 possible takeover events (4 TORs per NDRT). In order
to avoid predictably and over-trusting of the automated system, we
randomly assigned 4 more TORs in each trial to be false alarms,
where no hazardous incident was actually detected but a TOR was
issued. Although participants interacted with all NDRTs, the given
advisory warnings were different in each session. In the CAWA
session, the modality of advisory warnings adapted to the context
of NDRTs, whereas in baseline, all advisory warnings across differ-
ent NDRTs use the same auditory modality. In both experimental
sessions, the simulated vehicle was equipped with SAE Level 3 au-
tomation which could issue TORs (350 Hz acoustic tone with 75 ms
duration) to ask the driver to resume the control once it detected
an unfamiliar situation out of its capabilities. In the manual driving
mode, participants could control the vehicle via the steering wheel
and pedals (see details in Sec. 3.5).
Figure 4: Examples of the TOR four takeover situations, adapted
from [24, 44]. a) Fallen trees. b) Working zone. c) Police set up
roadblocks. d) Breakdown cars.
Table 1: CAWA adapts advisory warning modalities based on
the context of NDRTs
Non-Driving Related Tasks
Warning Modalities
Playing 2048 game on the cellphone
Text message
Watching a movie on the tablet
Vibrotactile
Reading a book
Speech-based
Conversation with the passenger
Visual
3.4
Independent Variables
3.4.1
Modalities. Text message. We developed a Python API
that can automatically send a text message containing an advisory
warning of ‚ÄúPlease pay ATTENTION!‚Äù to the driver‚Äôs mobile phone
(see Figure 5(b)). The developed attention warning message was
displayed at the top of the screen. While drivers are immersed with
playing a game on phone, they may potentially miss the auditory
and visual cues. In such situation, a notification that grabs users‚Äô
attention with a quick-to-the-point warning could abruptly direct
their attention to the driving scene.
Vibrotactile. We attached 10 vibrotactile actuators (Tatoko 10mm
√ó 3mm vibration motor, 3V, 12000rpm) to the driver‚Äôs seat as shown
in Figure 5(c), and used an Arduino Uno microcontroller and L9910
motor drivers to drive the vibrotacile actuators. The generated vi-
brotactile feedback pattern involves two 200 ms long vibrations at
maximum amplitude, separated by a 200 ms delay between them.
Speech-based. Previous research has shown that semantics and
emotional tone leads to higher perceived urgency [2, 27, 45]. So, it
is important to consider whether the message is comprehensible and
pleasant for a driver to react upon in a timely manner. We created a
gentle warning message ‚ÄúPlease pay attention‚Äù with a female voice
and an American accent.
Visual. Head-up-displays are increasingly used for effective visual
communication with drivers [12]. We designed the visual advisory
warning as a windshield projected head-up-display shown in Fig-
ure 5(a), which includes a warning sign icon accompanying the text
‚ÄúPlease pay ATTENTION‚Äù.
Please note that we implemented a unimodal advisory warning in
CAWA to be effective for each NDRT and to avoid resource sharing
conflicts defined by Wickens‚Äô multiple resource theory [58].

Enjoy the Ride Consciously with CAWA
AutomotiveUI ‚Äô22, September 17‚Äì20, 2022, Seoul, Republic of Korea
Figure 5: Advisory warning modalities: (a) visual warning from the ego‚Äôs vehicle view , (b) text message, (c) vibrotactile.
3.4.2
Non-driving activities. Participants were asked to perform
four NDRTs with three cognitive difficulty levels (i.e. Low: watching
movies; Mid: reading and informal conversation; High: playing a
mentally demanding game) while setting the vehicle in an automated
driving mode. They were also informed that they needed to take
control of the vehicle in case a TOR is issued. Studies have shown
that engaging with a NDRT for more than three minutes could lead
significant decline in situation awareness [11]. Thus, in this study,
each NDRT lasted about 219 seconds (SD=15s) before the system
initiated a TOR. Participants interacted with each NDRT for about
657 seconds in each block of experiment. Both blocks of experiment
consisted of the following NDRTs:
Watching. We selected two movies in the same Action/Thriller
genre to prevent potential effects from one specific genre. Partici-
pants were given two Netflix movies to choose from, "Extraction"
by Sam Hargrave or "Ava" by Tate Taylor.
Reading. "No One Is Too Small to Make a Difference" by Greta
Thunberg was selected for the users to read. Participants were also
instructed to read out loud to make sure they are surely reading the
book.
Conversing. The subjects were asked to have a conversation with
the experimenter sitting behind them to simulate conversation with
another passenger regarding everyday topics (e.g., plans for summer
vacation).
Gaming. The participant played a 2048 smartphone game, a
single-player sliding block puzzle game, whose objective is to slide
and combine numbers on a grid with the purpose of achieving a
sum of 2048. This game challenge physical and visual demands for
receiving an emergency alert.
3.5
Procedure
Upon arrival, the participants were briefed about the study. Par-
ticipants then signed an informed consent form and completed a
demographics questionnaire, followed by a 5-minute practice drive
to get familiar with the driving simulator and NDRTs. We fitted the
participant with the Shimmer3+ wearable device and calibrated the
eye-tracker algorithm (which was re-calibrated at the beginning of
each trial). Participants were informed that there was no need to
actively monitor the driving environments or resume the control of
the vehicle unless a TOR was issued. However, they were instructed
to resume the vehicle control as soon as a TOR was issued, then
switch back to the automated driving once the incident had passed
and continue the engagement with a NDRT.
At the beginning of the drive, the participants were asked to
activate the automated mode and perform a NDRT based on the
experimenter‚Äôs instructions, followed by three more NDRTs (see
Table 1). Previous research finds that participants engaging with a
NDRT for more than 180 seconds could lead to a significant decline
in situation awareness [11]. In this study, immersion to a NDRT
lasted 200 seconds on average (SD=15s) before being interrupted
by a TOR, which was programmed to be triggered automatically
about 111 meters (‚âà5s) before detection of a dangerous incident.
The advisory warnings were also triggered 38-45 seconds (M=40.3s,
SD=1.6s) prior TOR to make drivers vigilant of vehicle‚Äôs state.
Overall, participants engaged with each NDRT per trial for 12-15min.
The chosen time window is twice as long as in previous studies [8,
55] in order to evaluate CAWA‚Äôs impact on driver takeover readiness.
At the end of each trial, the questionnaire on workload (DALI) and
perceived safety and urgency were administered.
After the participant completed all of the driving trials, the ex-
perimenter conducted a semi-structured interview to seek the partic-
ipant‚Äôs general feedback about the study. The interview guideline
was prepared following a prior study [54]. The entire study took
about 100-130 minutes, and the participant received a $30 gift card
for completing the study.
3.6
Dependent Variables
To investigate the proposed research questions, we used the follow-
ing objective measurements and subjective feedback as dependent
variables.
RQ1 questions driver takeover behavior. We measured the driver‚Äôs
reaction time (i.e., the time difference between the TOR initiation
and the exact moment of the driver pressing the button on the steering
wheel to resume manual control), and the lateral vehicle control (i.e.,
deviation from the lane during the takeover).

AutomotiveUI ‚Äô22, September 17‚Äì20, 2022, Seoul, Republic of Korea
Pakdamanian et al.
RQ2 asks about driver situational awareness. As gaze behavior
shown to be a reliable indicator of situation awareness [5, 26, 47],
we applied the state-of-the-art computer vision techniques [41, 42]
to estimate the gaze behavior of drivers in real-time. We calculated
two metrics: (i) percentage of drivers looking at the road; and (ii)
fixation duration of when a driver‚Äôs eyes are on/off the road.
RQ3 evaluates driver stress and cognitive workload. We used the
biometric data to calculate metrics including heart rate variability
and the number of GSR signal peaks, showing mental workload
and stress respectively.pNN50 was calculated as the number of two
consecutive intervals (called NN) in which the change in consecu-
tive normal sinus intervals exceeds 50 milliseconds divided by the
total number of NN intervals measured. Furthermore, we report the
number GSR peaks from the time of advisory warning receipt to
moment of takeover control. We also asked participants to complete
the Driving Activity Load Index (DALI) [43], which customizes
NASA-TLX for the automotive domain.
RQ4 inquires about driver perceptions. We asked participants
to rate their perceived safety, disruptiveness, and the urgency of
advisory warnings on a 5-point Likert-type scale ranging from 1
(strongly disagree) to 5 (strongly agree), which was adapted from
the rating questionnaire used in the prior study by Iqbal et al. [21].
At the end of the study, we interviewed the participants about their
preferences for the different advisory warnings and solicited their
rationales for the order of preference and usefulness.
4
RESULTS
We analyzed the data collected from the user study for the proposed
research questions. We set the statistical significance level as ùõº=
0.05.
4.1
Quantitative Measurements
4.1.1
Effects on Driver Takeover Behavior (RQ1). We ob-
served in the study that participants were able to take over the ve-
hicle control following TORs with a high success rate. Out of the
456 TORs (19 participants √ó 2 trials √ó 12 true TORs per trial), only
4 takeovers were failed (e.g., the driver was playing a game on the
mobile phone and failed to take over in a timely manner, causing
the vehicle to collide with an obstacle). We conducted statistical
analysis using the data of 452 successful takeovers to investigate
drivers‚Äô takeover behavior.
Takeover Quality. We plotted the vehicle trajectories in Fig-
ure 7. It shows substantial variation in control strategies and higher
takeover control after receiving CAWA, as opposed to the baseline,
indicating better takeover quality.
A two-way repeated-measures ANOVA also found statistically
significant effects on the lateral vehicle control (ùêπ(1, 443) = 13.46,
ùëù< 0.01, ùúÇ2 = 0.15) by comparing CAWA and the baseline. Post-hoc
showed that the visual warning resulted in lower lateral deviation
compared to all other modalities (ùëù< 0.01). This means that the
drivers who were looking at the road while holding a conversation
had better control of the car as opposed to other modalities.
Reaction Time. A two-way repeated-measures analysis of vari-
ance (ANOVA) analysis found a significant main effect of type
of NDRTs (ùêπ(3, 443) = 2.39, ùëù< 0.05, ùúÇ2 = 0.049) and type of
advisory warnings (ùêπ(1, 443) = 185.53, ùëù< 0.001, ùúÇ2 = 0.47) on
reaction time, showing CAWA can lead to a faster reaction time than
the baseline. For types of NDRTs, post-hoc analyses with Bonferroni
revealed that there was a significant difference between gaming on
the phone an conversation with the experimenter (ùëù< 0.01) and be-
tween gaming and watching a movie on tablet (ùëù< 0.01), indicating
that conversing with passengers and watching movie leads to quicker
reaction time than gaming (see Figure 6 (ii)).
4.1.2
Effects on Driver Situational Awareness (RQ2). Fig-
ure 8 displays the percentage of drivers looking at the road from
the time they received the advisory warning to 20 seconds after
resuming vehicle control (i.e., the number of drivers looking at the
road at a given time divides the total number of participants). On
average, 87.6% of the drivers look at the road from the time of
receiving an advisory warning, to the time of actual takeover of
control, showing an enhancement on driver‚Äôs situation awareness.
Shortly after the TOR, more than 95% of drivers shifted their visual
attention to the screen. However, more participants stayed vigilant in
baseline after taking the vehicle control. Furthermore, analyzing the
eye-gaze vector for investigating the fixation time on/off the road,
shows the standard deviations across the mean of participants. We
ran ANOVA and found significant main effect of type of advisory
warnings (ùêπ(1, 443) = 39.47, ùëù< 0.05, ùúÇ2 = 0.23) on the fixation
time. Although conversing resulted in higher time fixation on the
road, there was no significant difference was observed between the
type of NDRTs.
4.1.3
Effects on Driver Stress and Cognitive Workload (RQ3).
We investigated the effect of CAWA and baseline on stress (i.e. GSR)
and cognitive load(i.e. heart rate variability(HRV)). The results show
no significant effect of NDRT type (ùêπ(3, 443) = 0.95, ùëù= 0.42,
ùúÇ2 = 0.007) and type of advisory warnings (ùêπ(1, 443) = 2.23, ùëù=
0.14, ùúÇ2 = 0.006) on HRV (i.e., pNN50). Besides, the statistical
analysis showed that the number of GSR peaks from the time of
receiving advisory warnings to moment of takeover was signifi-
cantly impacted by type of NDRT (ùêπ(3, 443) = 0.95, ùëù= 0.42,
ùúÇ2 = 0.007), no significant effect of the type of advisory warnings
was found (ùêπ(1, 443) = 2.23, ùëù= 0.14, ùúÇ2 = 0.006). Post-hoc test
with Bonferroni on the number of GSR peaks indicated a statisti-
cally significant difference between watching a movie with convers-
ing (ùëù< 0.05) and reading (ùëù< 0.05).
We also analyzed the participants‚Äô subjective ratings on DALI,
which includes six dimensions of workload as shown in Figure 9a.
ANOVA analysis found significant effects on attention demand
(F(2,54)= 3.70, ùëù< 0.05, ùúÇ2 = 0.12). Post-hoc testing with Bon-
ferroni on attention demand also indicated a significant difference
between CAWA and the baseline (ùëù= 0.029), which means that the
attention required by the baseline was much more demanding than
CAWA. However, no statistically significant effects were found in
other workload dimensions.
4.1.4
Driver Perceptions (RQ4). Figure 9b shows the survey
results on drivers‚Äô perceived safety, disruptiveness and urgency of
advisory warnings. The results of safety (ùêπ(2, 54) = 0.799, ùëù= 0.377,
ùúÇ2 = 0.021), disruptiveness (ùêπ(2, 54) = 0.0.498, ùëù= 0.485ùëÖ, ùúÇ2 =
0.014) and urgency (ùêπ(2, 54) = 2.866, ùëù= 0.099, ùúÇ2 = 0.074), did
not show a significant main effect on type of advisory warnings.

Enjoy the Ride Consciously with CAWA
AutomotiveUI ‚Äô22, September 17‚Äì20, 2022, Seoul, Republic of Korea
Figure 6: Comparisons between the participants‚Äô takeover reaction time in relation to the type of advisory warning and the imposed
modality. **: ùëù< 0.01, ****:ùëù< 0.0001
Figure 7: Lateral trajectories of vehicle after TORs.
Even though more participants rated CAWA to be safer with higher
urgency than the baseline, yet they found it more disruptive.
4.2
Qualitative Measurements
4.2.1
Preferences and Challenges. For the qualitative evalu-
ation, the details of the interviews for each subject were recorded
verbatim. We transcribed the audio recordings from the post-session
semi-structured interviews into text and arranged the texts according
to the condition. Then, based on the participants‚Äô statements on each
condition describing their observation, we compared the similarities
and differences. Overall, seventeen participants rated the CAWA
as more gentle than baseline warnings. Two participants perceived
baseline as more gentle mainly due to the ‚Äúshocking‚Äù of the Vibro-
tactile modality. CAWA was referred to as ‚Äúsafer‚Äù alternative by
fifteen participants.
They described a feeling of a need for learning why they received
the warnings in order to adapt to the situation. However, four par-
ticipants found CAWA ‚Äúdisruptive‚Äù, ‚Äútoo pressuring‚Äù, and ‚Äúurgent‚Äù.
Although they stated that only a beep is ‚Äúnot enough‚Äù or there is
‚Äúnot enough information‚Äù, they still preferred being less disturbed
and let continuing engagement in NDRTs.
4.2.2
Types of Modalities. Participants were asked to express
their perception about pros and cons of each implemented type of
warning modalities, and their preferences were varied. Participants‚Äô
preferences of the most suitable types of warning modality for in-
creasing situation awareness and takeover readiness were ranked as
Text messages (N = 7), speech-based (N = 6) and Vibrotactile (N = 4),
Visual (N = 1). Only one participant mentioned that he doesn‚Äôt need
any warnings at all. Four participants expressed the main reasons
for preferring the vibrotactile modality over the others was as ‚Äúit

AutomotiveUI ‚Äô22, September 17‚Äì20, 2022, Seoul, Republic of Korea
Pakdamanian et al.
Figure 8: Results on the percentage of drivers looking at the
road.TOR: issue of TOR; Takeover: the longest time of takeover
directly connected to my body and waked me up‚Äù and they preferred
feeling the cues rather than being interrupted via visual or auditory
alarms (P15). For example, a participant stated ‚Äú... I guess if you are
in the car and your have your music up really loud and watching
TV really loud then vibrotactile warnings would be really helpful‚Äù.
However, five participants did not favor the vibrotactile modality
found it difficult to know where their attention should be directed to,
for example, P2 stated - ‚Äúit did not vibrate anywhere I need to pay
attention or I was close to accident. I don‚Äôt know in which condition
did it vibrate or what I should do‚Äù.
Seven subject found the text messages notification ‚Äúvery useful‚Äù,
‚Äúcreative‚Äù, ‚Äúattention-grabbing‚Äù while engaging with the games on
the cellphone. For example, P5 stated - ‚ÄúThe game was the hardest.
With the game I was using my hands and my eyes, and then when
the computer says takeover, I need to redirect my eyes to the screen,
and put down the phone and then hit the button, with the book I
can quickly put it down, and then put it back‚Äù. However, five of
participants who opposing the text messages mentioned two main
reasons. They found it ‚Äúdisruptive‚Äù as it could block the other urgent
text notifications during everyday life. In addition, it was expressed
by one that the workload that they need to not only pay attention but
also read the text message.
Participants had mixed feelings over the Speech-based modality,
as they perceived it as most interruptive and ‚Äújarring‚Äù of the four, yet
effective; Six participants valued it as ‚Äúit stands out from everything
else, and immediately brought me back. Contrarily, over half of
participants perceived the speech-based modality as ‚Äúrobotic‚Äù.
Three participants favored the Visual modality, as the most ‚Äúprac-
tical‚Äù type of warning. These participants backed their choice as
it required "less attention" and it was found "less annoying". For
instance, P15 stated that Visuals is "easy to understand compared to
the text messages that I still need to read the words." Three partici-
pants opposed visual warnings as it potentially ‚Äúoccluded the vision
of the situation‚Äù (P1, P5, P7) and could be ‚Äúdistracting‚Äù (P7). For
example, P5 commented - ‚Äúit can blend into the background‚Äù.
5
DISCUSSION
This study aimed to investigate the effects of context-aware advi-
sory warnings on takeover readiness and performance. In order to
do so, we proposed a novel context-aware advisory warning sys-
tem (CAWA). CAWA adapts its warning modalities based on the
context a driver is immersed in. In contrast to pre-alert systems [55]
that startle and stress the driver to take an immediate action, advi-
sory warnings are non-assertive. Although a large body of litera-
ture has investigated the influence of various warnings on takeover
time [15, 30, 44] and quality [14, 57], to the best of our knowledge, it
is the first study to employ multiple modalities for ‚Äúadvising‚Äù drivers
of automated vehicles to pay attention to the driving scene and to be
more conscious of the automated driving status, specifically via text
messages.
5.1
Takeover Behavior
Takeover reaction times and quality were measured and analyzed to
compare differences due to perceived CAWA and auditory warning.
In line with previous studies that found auditory warning leads to
significantly higher reaction time [15, 45], we observed significantly
higher reaction times with baseline as opposed to CAWA. Further,
the results showed that conversing yielded the lowest reaction time,
but the results may reflect the fact that the conversation with the
experimenter did not need shifting visual attention. The most cog-
nitively and visually demanding task, playing 2048 game, showed
higher reaction time. Although the react times were varied, CAWA
helped drivers to resume the control faster. The range of reaction time
obtained in our study slightly differ from previous studies [15, 63],
showing that participants were somewhat prepared to take the control
or anticipated a takeover after receiving an advisory warning. De-
spite the research of [18] indicating that the complexity of NDRTs is
not a significant variable for reaction time, our experiment‚Äôs findings
indicated that takeover time was significantly impacted by physical
and cognitive loads needed for performing NDRTs.
We also observed that CAWA assisted drivers to departure earlier
and helped less deviation from the center of the lane(see Figure 7).
This finding of vehicle control after receiving TOR is in line with
our expectations based on previous studies [32, 45] showing non-
auditory warnings provides relatively better control of the vehicle.
Our findings also suggest that a safer takeover is a composite of
multiple factors (e.g. type of NDRT and its level of complexity, type
of modalities, etc.) and they may have a greater effect on readiness
and takeover.
5.2
Situation Awareness
We observed higher rates of monitoring of the road after receiving
CAWA compared to the baseline. More specifically, after the vehicle
approached to advisory warning time, 14% more of driver looked
back at the road and stayed more visually attentive. In general,
our results shows that receiving advisory warnings increases 26%
likelihood of looking at the road as opposed to the results reported
in [55].
5.3
User Experience
Concerning the usability aspect of proposed method, the users per-
ceptions towards advisory warnings‚Äô safety and disturbance were

Enjoy the Ride Consciously with CAWA
AutomotiveUI ‚Äô22, September 17‚Äì20, 2022, Seoul, Republic of Korea
Baseline
Strongly
Disagree
2
3
4
Strongly
Agree
Disruptiveness
CAWA
Baseline
Strongly 
Disagree
2
3
4
Strongly 
Agree
Urgency
CAWA
Baseline
Strongly 
Disagree
2
3
4
Strongly 
Agree
Safety
CAWA
(a) Results on DALI ratings
(b) Results on driver perceived safety, disruptiveness, and urgency
Figure 9: The results of the (a) driving activity load index (DALI) questionnaire along with (b) perceived disruptiveness, safety, and
urgency under two CAWA and Baseline conditions.
analyzed along with their subjective workload using DALI survey.
Participants‚Äô ratings of their perceived safety, disruptiveness and
urgency, favored CAWA, but did not differ significantly between the
two conditions. Post-study interviews revealed that users believed
that CAWA could avoid being missed, but it leads to higher an-
noyance. Even though we extended the timing of advisory warning
suggested by literature to 200s on average, we acknowledge that
a better experimental design with less frequent interruption could
have increased CAWA‚Äôs usability. In addition to driver‚Äôs perceptions,
only the significant difference in the attention demand subscale of
the DALI supported the hypotheses. Despite slightly better score
in visual and auditory demand of CAWA, participants‚Äô subjective
workload rating did not differ significantly between the conditions.
It is possible that the similar time budget to takeover between the
two conditions was perceived as alike workload. Another possibility
for the absence of significance in the subscales of DALI could be
due to the within-subject design where we only collected one data
point to compare the conditions.
6
LIMITATIONS AND FUTURE WORK
We applied unimodal advisory warning rather than multimodal
modalities. While multimodal modalities were found to improve
reaction time [44] and quality of takeover [37], prior studies re-
ported them as urgent [25] and annoying [45]. We utilized unimodal
modalities (1) to avoid resource sharing conflicts according to Wick-
ens‚Äô multiple resource theory [58], (2)to investigate the impact of
non-assertive advisory warnings on takeover behavior. However,
we acknowledge that a more exhaustive picture would have been
available if we combined multiple modalities to urge drivers to pay
attention to the driving scene.
Another limitation is using a driving simulator. While driving
simulator studies are very common due to advantages in creating
standardized situations for experimental control, they come with
limited external validity. Participants may react differently in the lab
than they do naturally while driving in the wild. Despite randomizing
the time interval for advisory warnings, participant could still expect
to encounter a TOR.
Despite these limitations, this study takes the first steps toward
enabling CAWA for automated driving, which can provoke many
exciting future research directions. In this study warnings were trig-
gered for a fixed period (about 40 seconds) before TORs in the study.
Future work could leverage recent advances in predicting driver
takeover behavior and readiness [40, 62], and develop agent-based
systems to intelligently decide when and how to trigger warnings
based on driver state predictions.
7
CONCLUSION
In this work, we proposed CAWA, a novel method that provides
gentle advisory warnings to improve driver readiness. Furthermore,
CAWA tends to select appropriate modality according to the context
of NDRTs, seeking the balance between (i) avoiding a warning to
go unnoticed like generic warnings and (ii) frequent interruptions
unless situation awareness falls bellow dangerous level for proper
takeover in the case of emergency. Our user study found encouraging
results proving the applicability of potentially incorporating CAWA
into the design of automated driving vehicles for safer and smoother
transition of control.
8
ACKNOWLEDGMENT
This work was supported in part by National Science Foundation
(NSF) grants CCF-1942836 and CNS-1755784. Any opinions, find-
ings, and conclusions or recommendations expressed in this material
are those of the author(s) and do not necessarily reflect the views of
the grant sponsors.
REFERENCES
[1] Sonia Baee, Erfan Pakdamanian, Inki Kim, Lu Feng, Vicente Ordonez, and Laura
Barnes. 2021. Medirl: Predicting the visual attention of drivers via maximum
entropy deep inverse reinforcement learning. In Proceedings of the IEEE/CVF
international conference on computer vision. 13178‚Äì13188.
[2] Carryl L Baldwin. 2011. Verbal collision avoidance messages during simulated
driving: perceived urgency, alerting effectiveness and annoyance. Ergonomics 54,
4 (2011), 328‚Äì337.
[3] Carryl L Baldwin, Jesse L Eisert, Andre Garcia, Bridget Lewis, Stephanie M Pratt,
and Christian Gonzalez. 2012. Multimodal urgency coding: auditory, visual, and
tactile parameters and their impact on perceived urgency. Work 41, Supplement 1
(2012), 3586‚Äì3591.
[4] Pavlo Bazilinskyy, Sebastiaan M Petermeijer, Veronika Petrovych, Dimitra Dodou,
and Joost CF de Winter. 2018. Take-over requests in highly automated driving: A
crowdsourcing survey on auditory, vibrotactile, and visual displays. Transportation
research part F: traffic psychology and behaviour 56 (2018), 82‚Äì98.
[5] Punitkumar Bhavsar, Babji Srinivasan, and Rajagopalan Srinivasan. 2017. Quan-
tifying situation awareness of control room operators using eye-gaze behavior.
Computers & chemical engineering 106 (2017), 191‚Äì201.
[6] NTS Board. 2020. Collision between a sport utility vehicle operating with partial
driving automation and a crash attenuator mountain view, california. accessed
October 30 (2020).

AutomotiveUI ‚Äô22, September 17‚Äì20, 2022, Seoul, Republic of Korea
Pakdamanian et al.
[7] Shadan Sadeghian Borojeni, Torben Wallbaum, Wilko Heuten, and Susanne Boll.
2017. Comparing shape-changing and vibro-tactile steering wheels for take-over
requests in highly automated driving. In Proceedings of the 9th international
conference on automotive user interfaces and interactive vehicular applications.
221‚Äì225.
[8] Shadan Sadeghian Borojeni, Lars Weber, Wilko Heuten, and Susanne Boll. 2018.
From reading to driving: priming mobile users for take-over situations in highly
automated driving. In Proceedings of the 20th international conference on human-
computer interaction with mobile devices and services. 1‚Äì12.
[9] SAE On-Road Automated Vehicle Standards Committee et al. 2018. Taxonomy
and definitions for terms related to driving automation systems for on-road motor
vehicles. SAE International: Warrendale, PA, USA (2018).
[10] David E Dass Jr, Alex Uyttendaele, and Jacques Terken. 2013. Haptic in-seat
feedback for lane departure warning. In Proceedings of the 5th International
Conference on Automotive User Interfaces and Interactive Vehicular Applications.
258‚Äì261.
[11] Joost CF De Winter, Riender Happee, Marieke H Martens, and Neville A Stanton.
2014. Effects of adaptive cruise control and highly automated driving on workload
and situation awareness: A review of the empirical evidence. Transportation
research part F: traffic psychology and behaviour 27 (2014), 196‚Äì217.
[12] Anup Doshi, Shinko Yuanhsien Cheng, and Mohan Manubhai Trivedi. 2008. A
novel active heads-up display for driver assistance. IEEE Transactions on Systems,
Man, and Cybernetics, Part B (Cybernetics) 39, 1 (2008), 85‚Äì93.
[13] Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen
Koltun. 2017. CARLA: An open urban driving simulator. In Conference on robot
learning. PMLR, 1‚Äì16.
[14] Na Du, Jinyong Kim, Feng Zhou, Elizabeth Pulver, Dawn M Tilbury, Lionel P
Robert, Anuj K Pradhan, and X Jessie Yang. 2020. Evaluating effects of cognitive
load, takeover request lead time, and traffic density on drivers‚Äô takeover perfor-
mance in conditionally automated driving. In 12th International Conference on
Automotive User Interfaces and Interactive Vehicular Applications. 66‚Äì73.
[15] Alexander Eriksson and Neville A Stanton. 2017. Takeover time in highly auto-
mated vehicles: noncritical transitions to and from manual control. Human factors
59, 4 (2017), 689‚Äì705.
[16] Michael A Gerber, Ronald Schroeter, Li Xiaomeng, and Mohammed Elhenawy.
2020. Self-Interruptions of Non-Driving Related Tasks in Automated Vehicles:
Mobile vs Head-Up Display. In Proceedings of the 2020 CHI Conference on
Human Factors in Computing Systems. 1‚Äì9.
[17] Christian Gold, Daniel Damb√∂ck, Lutz Lorenz, and Klaus Bengler. 2013. ‚ÄúTake
over!‚Äù How long does it take to get the driver back into the loop?. In Proceedings
of the human factors and ergonomics society annual meeting, Vol. 57. Sage
Publications Sage CA: Los Angeles, CA, 1938‚Äì1942.
[18] Christian Gold, Riender Happee, and Klaus Bengler. 2018. Modeling take-over
performance in level 3 conditionally automated vehicles. Accident Analysis &
Prevention 116 (2018), 3‚Äì13.
[19] Christian Gold, Moritz K√∂rber, David Lechner, and Klaus Bengler. 2016. Taking
over control from highly automated vehicles in complex traffic situations: the role
of traffic density. Human factors 58, 4 (2016), 642‚Äì652.
[20] Kai Holl√§nder and Bastian Pfleging. 2018. Preparing drivers for planned control
transitions in automated cars. In Proceedings of the 17th International Conference
on Mobile and Ubiquitous Multimedia. 83‚Äì92.
[21] Shamsi T Iqbal, Eric Horvitz, Yun-Cheng Ju, and Ella Mathews. 2011. Hang on
a sec! Effects of proactive mediation of phone conversations while driving. In
Proceedings of the SIGCHI conference on human factors in computing systems.
463‚Äì472.
[22] Philipp Kerschbaum, Lutz Lorenz, and Klaus Bengler. 2015. A transforming steer-
ing wheel for highly automated cars. In 2015 ieee intelligent vehicles symposium
(iv). IEEE, 1287‚Äì1292.
[23] Naeun Kim, Kwangmin Jeong, Minyoung Yang, Yejeon Oh, and Jinwoo Kim.
2017. " Are You Ready to Take-over?" An Exploratory Study on Visual Assistance
to Enhance Driver Vigilance. In Proceedings of the 2017 CHI Conference Extended
Abstracts on Human Factors in Computing Systems. 1771‚Äì1778.
[24] Moritz K√∂rber, Lorenz Prasch, and Klaus Bengler. 2018. Why do I have to drive
now? Post hoc explanations of takeover requests. Human factors 60, 3 (2018),
305‚Äì323.
[25] Kyle Kutchek and Myounghoon Jeon. 2019. Takeover and handover requests using
non-speech auditory displays in semi-automated vehicles. In Extended Abstracts
of the 2019 CHI Conference on Human Factors in Computing Systems. 1‚Äì6.
[26] Wen-Chin Li, Fa-Chung Chiu, and Ka-Jay Wu. 2012. The evaluation of pilots
performance and mental workload by eye movement. (2012).
[27] Jessica K Ljungberg, Fabrice BR Parmentier, Robert W Hughes, William J Macken,
and Dylan M Jones. 2012. Listen out! Behavioural and subjective responses to
verbal warnings. Applied Cognitive Psychology 26, 3 (2012), 451‚Äì461.
[28] Lutz Lorenz, Philipp Kerschbaum, and Josef Schumann. 2014. Designing take
over scenarios for automated driving: How does augmented reality support the
driver to get back into the loop?. In Proceedings of the Human Factors and
Ergonomics Society Annual Meeting, Vol. 58. SAGE Publications Sage CA: Los
Angeles, CA, 1681‚Äì1685.
[29] Tyron Louw, Jonny Kuo, Richard Romano, Vishnu Radhakrishnan, Michael G
Lenn√©, and Natasha Merat. 2019. Engaging in NDRTs affects drivers‚Äô responses
and glance patterns after silent automation failures. Transportation research part
F: traffic psychology and behaviour 62 (2019), 870‚Äì882.
[30] Zhenji Lu, Xander Coster, and Joost De Winter. 2017. How much time do drivers
need to obtain situation awareness? A laboratory-based study of automated driving.
Applied ergonomics 60 (2017), 293‚Äì304.
[31] Christian Maag, Norbert Schneider, Thomas L√ºbbeke, Thomas H Weisswange,
and Christian Goerick. 2015. Car Gestures‚ÄìAdvisory warning using additional
steering wheel angles. Accident Analysis & Prevention 83 (2015), 143‚Äì153.
[32] Udara E Manawadu, Hiroaki Hayashi, Takaaki Ema, Takahiro Kawano, Mitsuhiro
Kamezaki, and Shigeki Sugano. 2018. Tactical-Level Input with Multimodal
Feedback for Unscheduled Takeover Situations in Human-Centered Automated
Vehicles. In 2018 IEEE/ASME International Conference on Advanced Intelligent
Mechatronics (AIM). IEEE, 634‚Äì639.
[33] Claus Marberger, Holger Mielenz, Frederik Naujoks, Jonas Radlmayr, Klaus
Bengler, and Bernhard Wandtner. 2017. Understanding and applying the concept of
‚Äúdriver availability‚Äù in automated driving. In international conference on applied
human factors and ergonomics. Springer, 595‚Äì605.
[34] Anthony D McDonald, Hananeh Alambeigi, Johan Engstr√∂m, Gustav Markkula,
Tobias Vogelpohl, Jarrett Dunne, and Norbert Yuma. 2019. Toward computational
simulations of behavior during automated driving takeovers: a review of the
empirical and modeling literatures. Human factors 61, 4 (2019), 642‚Äì688.
[35] Natasha Merat, A Hamish Jamson, Frank CH Lai, Michael Daly, and Oliver MJ
Carsten. 2014. Transition to manual: Driver behaviour when resuming control from
a highly automated vehicle. Transportation research part F: traffic psychology
and behaviour 27 (2014), 274‚Äì282.
[36] John Morrell and Kamil Wasilewski. 2010. Design and evaluation of a vibrotactile
seat to improve spatial awareness while driving. In 2010 IEEE Haptics Symposium.
IEEE, 281‚Äì288.
[37] Frederik Naujoks, Christoph Mai, and Alexandra Neukum. 2014. The effect of
urgency of take-over requests during highly automated driving under distraction
conditions. Advances in human aspects of transportation 7, Part I (2014), 431.
[38] Frederik Naujoks, Christian Purucker, and Alexandra Neukum. 2016. Secondary
task engagement and vehicle automation‚ÄìComparing the effects of different au-
tomation levels in an on-road experiment. Transportation research part F: traffic
psychology and behaviour 38 (2016), 67‚Äì82.
[39] Erfan Pakdamanian, Nauder Namaky, Shili Sheng, Inki Kim, James Arthur Coan,
and Lu Feng. 2020. Toward minimum startle after take-over request: A preliminary
study of physiological data. In 12th International Conference on Automotive User
Interfaces and Interactive Vehicular Applications. 27‚Äì29.
[40] Erfan Pakdamanian, Shili Sheng, Sonia Baee, Seongkook Heo, Sarit Kraus, and
Lu Feng. 2021. Deeptake: Prediction of driver takeover behavior using multimodal
data. In Proceedings of the 2021 CHI Conference on Human Factors in Computing
Systems. 1‚Äì14.
[41] Seonwook Park, Adrian Spurr, and Otmar Hilliges. 2018. Deep pictorial gaze
estimation. In Proceedings of the European Conference on Computer Vision
(ECCV). 721‚Äì738.
[42] Seonwook Park, Xucong Zhang, Andreas Bulling, and Otmar Hilliges. 2018.
Learning to find eye region landmarks for remote gaze estimation in unconstrained
settings. In Proceedings of the 2018 ACM Symposium on Eye Tracking Research
& Applications. 1‚Äì10.
[43] Annie Pauzi√©. 2008. A method to assess the driver mental workload: The driving
activity load index (DALI). IET Intelligent Transport Systems 2, 4 (2008), 315‚Äì
322.
[44] Sebastiaan Petermeijer, Fabian Doubek, and Joost de Winter. 2017. Driver re-
sponse times to auditory, visual, and tactile take-over requests: A simulator study
with 101 participants. In 2017 IEEE International Conference on Systems, Man,
and Cybernetics (SMC). IEEE, 1505‚Äì1510.
[45] Ioannis Politis, Stephen Brewster, and Frank Pollick. 2015. Language-based mul-
timodal displays for the handover of control in autonomous cars. In Proceedings
of the 7th international conference on automotive user interfaces and interactive
vehicular applications. 3‚Äì10.
[46] Ioannis Politis, Stephen Brewster, and Frank Pollick. 2015. To beep or not to
beep? Comparing abstract versus language-based multimodal driver displays. In
Proceedings of the 33rd annual ACM conference on human factors in computing
systems. 3971‚Äì3980.
[47] Miguel A Recarte and Luis M Nunes. 2000. Effects of verbal and spatial-imagery
tasks on eye fixations while driving. Journal of experimental psychology: Applied
6, 1 (2000), 31.
[48] Shadan Sadeghian Borojeni, Susanne CJ Boll, Wilko Heuten, Heinrich H B√ºlthoff,
and Lewis Chuang. 2018. Feel the movement: Real motion influences responses
to take-over requests in highly automated vehicles. In Proceedings of the 2018
CHI Conference on Human Factors in Computing Systems. 1‚Äì13.
[49] Katri Salminen, Ahmed Farooq, Jussi Rantala, Veikko Surakka, and Roope
Raisamo. 2019. Unimodal and multimodal signals to support control transitions
in semiautonomous vehicles. In Proceedings of the 11th International Conference
on Automotive User Interfaces and Interactive Vehicular Applications. 308‚Äì318.

Enjoy the Ride Consciously with CAWA
AutomotiveUI ‚Äô22, September 17‚Äì20, 2022, Seoul, Republic of Korea
[50] Harsh Sanghavi, Myounghoon Jeon, Chihab Nadri, Sangjin Ko, Jaka Sodnik,
and Kristina Stojmenova. 2021. Multimodal takeover request displays for semi-
automated vehicles: Focused on spatiality and lead time. In International Confer-
ence on Human-Computer Interaction. Springer, 315‚Äì334.
[51] Harsh Sanghavi, Yiqi Zhang, and Myounghoon Jeon. 2020. Effects of anger and
display urgency on takeover performance in semi-automated vehicles. In 12th
International Conference on Automotive User Interfaces and Interactive Vehicular
Applications. 48‚Äì56.
[52] Florian Seeliger, Galia Weidl, Dominik Petrich, Frederik Naujoks, Gabi Breuel,
Alexandra Neukum, and Klaus Dietmayer. 2014. Advisory warnings based on
cooperative perception. In 2014 IEEE Intelligent Vehicles Symposium Proceedings.
IEEE, 246‚Äì252.
[53] Ariel Telpaz, Brian Rhindress, Ido Zelman, and Omer Tsimhoni. 2015. Haptic
seat for automated driving: preparing the driver to take control effectively. In
Proceedings of the 7th international conference on automotive user interfaces and
interactive vehicular applications. 23‚Äì30.
[54] Sandra Tr√∂sterer, Alexander Meschtscherjakov, Alexander G Mirnig, Artur Lupp,
Magdalena G√§rtner, Fintan McGee, Rod McCall, Manfred Tscheligi, and Thomas
Engel. 2017. What we can learn from pilots for handovers and (de) skilling in semi-
autonomous driving: An interview study. In Proceedings of the 9th international
conference on automotive user interfaces and interactive vehicular applications.
173‚Äì182.
[55] Remo MA van der Heiden, Shamsi T Iqbal, and Christian P Janssen. 2017. Priming
drivers before handover in semi-autonomous cars. In Proceedings of the 2017 CHI
conference on human factors in computing systems. 392‚Äì404.
[56] Remo MA Van der Heiden, J Leon Kenemans, Stella F Donker, and Christian P
Janssen. 2021. The effect of cognitive load on auditory susceptibility during
automated driving. Human factors (2021), 0018720821998850.
[57] Bradley W Weaver and Patricia R DeLucia. 2020. A systematic review and meta-
analysis of takeover performance during conditionally automated driving. Human
factors (2020), 0018720820976476.
[58] Christopher D Wickens. 2002. Multiple resources and performance prediction.
Theoretical issues in ergonomics science 3, 2 (2002), 159‚Äì177.
[59] Xingwei Wu and Linda Ng Boyle. 2021. Auditory messages for intersection
movement assist (IMA) systems: effects of speech-and nonspeech-based cues.
Human factors 63, 2 (2021), 336‚Äì347.
[60] Yunyang Xiong, Hyunwoo J. Kim, and Vikas Singh. 2019. Mixed Effects Neural
Networks (MeNets) With Applications to Gaze Estimation. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).
[61] Sol Hee Yoon, Young Woo Kim, and Yong Gu Ji. 2019. The effects of takeover
request modalities on highly automated car control transitions. Accident Analysis
& Prevention 123 (2019), 150‚Äì158.
[62] Sol Hee Yoon, Seul Chan Lee, and Yong Gu Ji. 2021. Modeling takeover time
based on non-driving-related task attributes in highly automated driving. Applied
ergonomics 92 (2021), 103343.
[63] Bo Zhang, Joost de Winter, Silvia Varotto, Riender Happee, and Marieke Martens.
2019. Determinants of take-over time from automated driving: A meta-analysis of
129 studies. Transportation research part F: traffic psychology and behaviour 64
(2019), 285‚Äì307.

