Daniel J. Madden and Jason A. Aubrey
The University of Arizona
Tucson, Arizona, USA
An Introduction to Proof
through Real Analysis

This edition ï¬rst published 2017
Â© 2017 John Wiley & Sons, Inc.
Library of Congress Cataloging-in-Publication Data
Names: Madden, Daniel J., 1948- | Aubrey, Jason A., 1975-
Title: An introduction to proof through real analysis / by Daniel J. Madden,
Jason A. Aubrey, The University of Arizona, Tucson, Arizona, USA.
Description: 1st edition. | Hoboken, NJ : Wiley, 2017. | Includes
bibliographical references and index. |
Identiï¬ers: LCCN 2017015345 (print) | LCCN 2017023296 (ebook) | ISBN
9781119314738 (pdf) | ISBN 9781119314745 (epub) | ISBN 9781119314721
(cloth)
Subjects: LCSH: Proof theoryâ€“Textbooks. | Functions of real
variablesâ€“Textbooks. | Numbers, Realâ€“Textbooks. | Mathematical
analysisâ€“Textbooks.
Classiï¬cation: LCC QA9.54 (ebook) | LCC QA9.54 .M335 2017 (print) | DDC
511.3/6â€“dc23
LC record available at https://lccn.loc.gov/2017015345
Cover design: Wiley
Cover image: Â© monsitj/Gettyimages
Set in 10/12pt WarnockPro by SPi Global, Chennai, India
Printed in the United States of America

Contents
List of Figures
xiii
Preface
xv
Introduction
xvii
Part I
A First Pass at Deï¬ning â„
1
1
Beginnings
3
1.1
A naive approach to the natural numbers
3
1.1.1
Preschool: foundations of the natural numbers
3
1.1.2
Kindergarten: addition and subtraction
5
1.1.3
Grade school: multiplication and division
8
1.1.4
Natural numbers: basic properties and theorems
11
1.2
First steps in proof
12
1.2.1
A direct proof
12
1.2.2
Mathematical induction
14
1.3
Problems
17
2
The Algebra of the Natural Numbers
19
2.1
A more sophisticated look at the basics
19
2.1.1
An algebraic approach
21
2.2
Mathematical induction
22
2.2.1
The theorem of induction
24
2.3
Division
27
2.3.1
The division algorithm
27
2.3.2
Odds and evens
30
2.4
Problems
34

3
Integers
37
3.1
The algebraic properties of â„•
37
3.1.1
The algebraic deï¬nition of the integers
40
3.1.2
Simple results about integers
42
3.1.3
The relationship between â„•and â„¤
45
3.2
Problems
47
4
Rational Numbers
49
4.1
The algebra
49
4.1.1
Surveying the algebraic properties of â„¤
49
4.1.2
Deï¬ning an ordered ï¬eld
50
4.1.3
Properties of ordered ï¬elds
51
4.2
Fractions versus rational numbers
53
4.2.1
In some ways they are diï¬€erent
53
4.2.2
In some ways they are the same
56
4.3
The rational numbers
58
4.3.1
Operations are well deï¬ned
58
4.3.2
â„šis an ordered ï¬eld
63
4.4
The rational numbers are not enough
67
4.4.1
âˆš
2 is irrational
67
4.5
Problems
70
5
Ordered Fields
73
5.1
Other ordered ï¬elds
73
5.2
Properties of ordered ï¬elds
74
5.2.1
The average theorem
74
5.2.2
Absolute values
75
5.2.3
Picturing number systems
78
5.3
Problems
79
6
The Real Numbers
81
6.1
Completeness
81
6.1.1
Greatest lower bounds
81
6.1.2
So what is complete?
82
6.1.3
An alternate version of completeness
84
6.2
Gaps and caps
86
6.2.1
The Archimedean principle
86
6.2.2
The density theorem
87
6.3
Problems
90
6.4
Appendix
93

Part II
Logic, Sets, and Other Basics
97
7
Logic
99
7.1
Propositional logic
99
7.1.1
Logical statements
99
7.1.2
Logical connectives
100
7.1.3
Logical equivalence
104
7.2
Implication
105
7.3
Quantiï¬ers
107
7.3.1
Speciï¬cation
108
7.3.2
Existence
108
7.3.3
Universal
109
7.3.4
Multiple quantiï¬ers
110
7.4
An application to mathematical deï¬nitions
111
7.5
Logic versus English
114
7.6
Problems
116
7.7
Epilogue
118
8
Advice for Constructing Proofs
121
8.1
The structure of a proof
121
8.1.1
Syllogisms
121
8.1.2
The outline of a proof
123
8.2
Methods of proof
127
8.2.1
Direct methods
127
8.2.1.1
Understand how to start
127
8.2.1.2
Parsing logical statements
129
8.2.1.3
Mathematical statements to be proved
131
8.2.1.4
Mathematical statements that are assumed to be true
135
8.2.1.5
What do we know and what do we want?
138
8.2.1.6
Construction of a direct proof
138
8.2.1.7
Compound hypothesis and conclusions
139
8.2.2
Alternate methods of proof
139
8.2.2.1
Contrapositive
139
8.2.2.2
Contradiction
142
8.3
An example of a complicated proof
145
8.4
Problems
149
9
Sets
151
9.1
Deï¬ning sets
151
9.2
Starting deï¬nitions
153
9.3
Set operations
154

9.3.1
Families of sets
157
9.4
Special sets
160
9.4.1
The empty set
160
9.4.2
Intervals
162
9.5
Problems
168
9.6
Epilogue
171
10
Relations
175
10.1
Ordered pairs
175
10.1.1
Relations between and on sets
176
10.2
A total order on a set
179
10.2.1
Deï¬nition
179
10.2.2
Deï¬nitions that use a total order
179
10.3
Equivalence relations
182
10.3.1
Deï¬nitions
182
10.3.2
Equivalence classes
184
10.3.3
Equivalence partitions
185
10.3.3.1 Well deï¬ned
187
10.4
Problems
188
11
Functions
193
11.1
Deï¬nitions
193
11.1.1
Preliminary ideas
193
11.1.2
The technical deï¬nition
194
11.1.2.1 A word about notation
197
11.2
Visualizing functions
202
11.2.1
Graphs in â„2
202
11.2.2
Tables and arrow graphs
202
11.2.3
Generic functions
203
11.3
Composition
204
11.3.1
Deï¬nitions and basic results
204
11.4
Inverses
206
11.5
Problems
210
12
Images and preimages
215
12.1
Functions acting on sets
215
12.1.1
Deï¬nition of image
215
12.1.2
Examples
217
12.1.3
Deï¬nition of preimage
218
12.1.4
Examples
220
12.2
Theorems about images and preimages
222
12.2.1
Basics
222

12.2.2
Unions and intersections
228
12.3
Problems
231
13
Final Basic Notions
235
13.1
Binary operations
235
13.2
Finite and inï¬nite sets
236
13.2.1
Objectives of this discussion
236
13.2.2
Why the fuss?
237
13.2.3
Finite sets
239
13.2.4
Intuitive properties of inï¬nite sets
240
13.2.5
Counting ï¬nite sets
241
13.2.6
Finite sets in a set with a total order
243
13.3
Summary
246
13.4
Problems
246
13.5
Appendix
248
13.6
Epilogue
257
Part III
A Second Pass at Deï¬ning â„
261
14
â„•, â„¤, and â„š
263
14.0.1
Basic properties of the natural numbers
263
14.0.2
Theorems about the natural numbers
266
14.1
The integers
267
14.1.1
An algebraic deï¬nition
267
14.1.2
Results about the integers
268
14.1.3
The relationship between natural numbers
and integers
270
14.2
The rational numbers
272
14.3
Problems
279
15
Ordered Fields and the Real Numbers
281
15.1
Ordered ï¬elds
281
15.2
The real numbers
284
15.3
Problems
289
15.4
Epilogue
290
15.4.1
Constructing the real numbers
290
16
Topology
293
16.1
Introduction
293
16.1.1
Preliminaries
293
16.1.2
Neighborhoods
295
16.1.3
Interior, exterior, and boundary
298

16.1.4
Isolated points and accumulation points
300
16.1.5
The closure
303
16.2
Examples
305
16.3
Open and closed sets
311
16.3.1
Deï¬nitions
311
16.3.2
Examples
315
16.4
Problems
316
17
Theorems in Topology
319
17.1
Summary of basic topology
319
17.2
New results
321
17.2.1
Unions and intersections
321
17.2.2
Open intervals are open
325
17.2.3
Open subsets are in the interior
327
17.2.4
Topology and completeness
328
17.3
Accumulation points
329
17.3.1
Accumulation points are aptly named
329
17.3.2
For all A âŠ†â„, Aâ€² is closed
333
17.4
Problems
341
18
Compact Sets
345
18.1
Closed and bounded sets
345
18.1.1
Maximums and minimums
345
18.2
Closed intervals are special
354
18.3
Problems
356
19
Continuous Functions
359
19.1
First semester calculus
359
19.1.1
An intuitive idea of a continuous function
359
19.1.2
The calculus deï¬nition of continuity
360
19.1.3
The oï¬ƒcial mathematical deï¬nition of continuity
363
19.1.4
Examples
364
19.2
Theorems about continuity
374
19.2.1
Three speciï¬c functions
374
19.2.2
Multiplying a continuous function by a constant
377
19.2.3
Adding continuous functions
378
19.2.4
Multiplying continuous functions
379
19.2.5
Polynomial functions
382
19.2.6
Composition of continuous functions
382
19.2.7
Dividing continuous functions
384
19.2.8
Gluing functions together
385
19.3
Problems
386

20
Continuity and Topology
389
20.1
Preliminaries
389
20.1.1
Continuous images mess up topology
389
20.2
The topological deï¬nitions of continuity
391
20.3
Compact images
397
20.3.1
The main theorem
397
20.3.2
The extreme value theorem
400
20.3.3
The intermediate value theorem
401
20.4
Problems
404
21
A Few Final Observations
407
21.1
Inverses of continuous functions
407
21.1.1
A strange example
408
21.1.2
The theorem about inverses of continuous functions
409
21.2
The intermediate value theorem and continuity
412
21.3
Continuity at discrete points
413
21.4
Conclusion
413
Index
415

List of Figures
Figure 11.1 y = 1
x
199
Figure 11.2 y = 1
x for x > 0
201
Figure 11.3 An arrow graph
203
Figure 11.4 A generic function
203
Figure 12.1 The image of S is f (S)
216
Figure 12.2 f (x) = x2
218
Figure 12.3 f âˆ’1(T) is the preimage of T
219
Figure 12.4 f (x) = x2
221
Figure 13.1 j(x) =
x
âˆš
x2+1
240
Figure 16.1 x = 1
n
295
Figure 16.2 x = 1
n
307
Figure 17.1 An open interval
326
Figure 17.2 x = 1
n
334
Figure 19.1 A discontinuity
360
Figure 19.2 A second type of discontinuity
361
Figure 19.3 A third type of discontinuity
361
Figure 19.4 A fourth type of discontinuity
361
Figure 19.5 Composition of continuous functions
383
Figure 20.1 f (x) = x3 âˆ’x
390
Figure 20.2 f (x) = 1
x
390
Figure 20.3 f maps S to f (S)
398
Figure 20.4 The sets îˆ»i for i âˆˆîˆµcover f (S)
398
Figure 20.5 We claim the sets f âˆ’1(îˆ»i) for i âˆˆîˆµcover S
399
Figure 21.1 f (x) = Sin(xâˆ’1)
412

Preface
Many mathematics departments in universities in the United States now oï¬€er
courses intended to introduce students to mathematical proof and transition
students to the study of advanced Mathematics. Such courses typically focus on
proof techniques, mathematical content foundational to the study of advanced
Mathematics, and some explicit attention to the conventions and best practices
of mathematical writing.
Across such courses, there seems to be general agreement about the
important proof techniques students should learn, and similarly, there is
little substantial disagreement regarding the principles of good mathematical
writing. However, these transition courses do vary widely in regard to the
mathematical content taught. Some courses focus almost entirely on proof
techniques and introduce almost no new mathematical content. Some focus
ï¬rst on elementary logic and set theory and then move on to other content,
such as discrete mathematics, geometry, or analysis.
As hinted by the title, this book is intended to be an introduction to proof
through analysis. It is a development of notes Daniel Madden has created over
many years of teaching the proofs course at the University of Arizona, and the
approach taken in this text is diï¬€erent in a number of ways.
First, although this is not an analysis book, the content is heavily focused
on analysis. And second, foundational material such as logic, sets, relations,
functions are not explicitly studied until the middle of the book, after we have
had a go at developing the real numbers. We have found that this approach,
while challenging, rewards the eï¬€ort. Students come away with a solid under-
standing of mathematical proof techniques and ample experience using those
techniques in a robust mathematical context. In addition, students leave the
course very well prepared for their advanced mathematics courses and with
particularly strong readiness for analysis.
This study has three parts. First, there is a careful review of the basic ideas of
numbers, not entirely rigorous, but distinctly careful. This ï¬rst part will cover
select results about natural numbers, integers, rational numbers. We will look
at the things we learned in grade school very carefully. Our goal is to reset the

stage so that we can examine all our basic notions about numbers. This will end
in a deï¬nition of the real numbers based on â€œthe completeness axiom.â€ This is
the key to truly understanding the real numbers as most people know them,
decimals. As we learn more mathematical analysis in this study and any that
follow, we will learn how to correctly understand and apply all sorts of inï¬nite
processes that describe real numbers.
In the second part, we will shore up our intuitive understanding of logic and
set theory by formalizing both subjects. We will go over basic logic and simple
set theory. Here we begin the mathematical practice of giving precise deï¬ni-
tions for even the simplest of mathematical terms. This is not surprising at all,
but it is abstract. We will talk about true and false statements without regard
to what those statements are. We will see how to interpret (parse) a compli-
cated sentence to extract its logical meaning. We will use logic to redeï¬ne our
terminology for numbers so that it can be used in more general mathematical
context. We will take the ideas about the various systems of numbers in part
1 to set up a mathematical language that can be used for other mathematical
systems. None of this is diï¬ƒcult, but it will be a challenge to keep up with a
large number of abstract (but very familiar) deï¬nitions.
The third part begins with a repeat of most of part 1. With the terminol-
ogy and logic of part 2, many things that seemed diï¬ƒcult or unnecessarily long
in the ï¬rst pass at numbers will be much clearer. The second pass will go by
quicker, but it should go much easier. A lot of results and proofs will be repeated
almost as new. By this time, the basic structure of all proofs will be much more
familiar and setup time greatly reduced. The ideas behind a proof will be much
more apparent now that the logic and structure of the exposition are more
familiar. Finally, in this third part, the new Mathematics begins with the intro-
duction of topology on the real line. The mathematical goal of the course is to
prove that the real numbers are all that is needed to measure all distances. This
goal is achieved with a proof of â€œthe intermediate value theorem.â€ The educa-
tional goal of the course, however, is to learn how to use logic to understand,
explain, and prove Mathematics in a careful and rigorous manner.

xvii
Introduction
Why proof?
For most people, Mathematics is about using mathematical facts to solve
practical problems. Users of Mathematics are rarely concerned about why the
methods work and care only that they do work. To too many people, Math-
ematics is a collection of arcane techniques known only to a select few with
â€œmath brains.â€ It is troublesome when those arcane techniques that confuse
people are diï¬€erentiation, integration, or matrix manipulation. It is downright
frightening when the confusing problems are adding fractions or computing
a restaurant tip. The worst way to view Mathematics is as a long collection of
hard-to-remember techniques for solving speciï¬c problems. A much better
way is to think of Mathematics as an organization of basic ideas that can solve all
sorts of problems as needed. When you understand what Mathematics actually
means, you can use that understanding to produce your own problem-solving
techniques. The key to understanding any piece of Mathematics (or anything
else for that matter) is to understand why it works the way it does.
Since the ancient Greeks ï¬rst studied Mathematics in a careful way, the
subject has been built on deductive proof. Mathematical results are accepted
as facts only after they have been logically proved from a few basic facts. Once
mathematical facts are established, they can be used to solve practical and
theoretical mathematical problems. Mathematicians have two reasons for
proving a mathematical statement rigorously: ï¬rst, to be sure that the result is
true, and second, to understand when and how it works.
Following the ancient Greek process, mathematicians want a proof for
everything - whether it is on the cutting edge of mathematics and science or
it is an apparently obvious fact about grade school arithmetic. The idea is to
understand why a mathematical result is true and to move on to what you
know because it is true. Most of the Mathematics we see in school is about
the â€œmoving onâ€ variety. Once school children understand the connection

xviii
Introduction
between combining small groups of objects and adding numbers, they can
move on to the arithmetic algorithm of adding larger numbers. Thus,
278
+
394
672
is just the theoretical way to combining 278 objects and 394 objects and
counting the combination. Once school children understand the connection
between groups of groups and multiplication, they can learn the algorithm for
multiplication. Then
2
5
7
Ã—
3
5
1
2
8
5
7
7
1
8
9
9
5
is just the theoretical way of counting 35 rows of 257 objects.
At the very beginning, every child is given some simple justiï¬cations for
the validity of these algorithms. The strong belief among math educators and
education researchers is that students who understand those justiï¬cations best
are the students that will learn the algorithms best. Granted in the long run,
it is a childâ€™s ability with the algorithm that is considered most important. In
time, greater facility with the algorithms supplants a personâ€™s need for the logic
behind those algorithms. But the complete understanding of the operation
behind the algorithm is always essential for its proper use in odd situations.
There is a popular notion that the logic behind the techniques of Mathemat-
ics can be ignored once the procedures of Mathematics are learned. This notion
seems to work well for the basic arithmetic of whole numbers. There is a lot
of evidence, however, that this is why so many people stumble over problems
involving fractions. Too many people â€œmove onâ€ to memorizing the algorithms
of fractional arithmetic before they understand the meaning of that arithmetic
or why the things they are memorizing work. It is hard to memorize anything
and harder still to hold that memory without knowing the context of what you
are learning. â€œTo add fractions, ï¬nd a common denominator.â€ â€œTo divide frac-
tions, invert and multiply.â€ Everyone knows this, but how many can correctly
add 3 3
4 to 5 7
8 or divide 21 by 2
3?
As perplexing as fractions are to the general population, decimal numbers are
even worse. Thanks to calculators, everyone knows ðœ‹= 3.14159 â€¦ where the
dots tell us a better calculator would give more digits. Everyone also seems to
know that 1
3 = 0.33333 â€¦where here the dots mean that the 3s go on forever, or
at least they would if it were actually possible for written digits to go on forever.
Most people understand decimal numbers well enough that they can move on

Introduction
xix
to using them very well and very eï¬€ectively without error. But even the most
highly trained person can be tripped up by an unexpected decimal question
that involves inï¬nitely many decimals. In the next section, we consider some
surprisingly confusing questions about simple numbers.
Before we get to these confusing examples, let us set up a plan for curing any
resulting mathematical confusion. Early school mathematical training generally
concentrates on the problem-solving problems using Mathematics. Some the-
oretical or intuitive explanations of the ideas and techniques are given, but the
level of logical rigor in these justiï¬cations varies greatly depending on the topic
under discussion. If we are interested in a more advanced education in Math-
ematics, we must revisit these past justiï¬cations of the mathematical ideas we
now hold so dear. The time must come when we understand and appreciate a
rigorous justiï¬cation of every mathematical result we will use. This turns out
to be a rather diï¬ƒcult step to make. We will work on it in stages.
Why analysis?
Our main objective in this study is to develop a precise description of the real
numbers for use as a foundation for the ideas and methods of calculus. There are
two ingredients in this development: algebra and analysis. â€œAlgebraâ€ generally
refers to the arithmetic of the numbers: addition, subtraction, multiplication,
and division. The ways in which these operations interact form the â€œalgebraic
structureâ€ of the number systems that we will consider. â€œAnalysisâ€ refers to the
study of the distinctions between exact numbers and their approximations. It is
simply a fact that certain real numbers cannot be expressed exactly using only
ï¬nitely many whole numbers. Analysis allows us to say precise things about real
numbers that cannot be precisely described with a ï¬nite expression.
Problems in analysis typically occur when we use numbers to measure things.
Given an isosceles right triangle, two squares drawn with sides the length of
the short sides of the triangle will have a combined area equal to a square
with a side whose length is the same as the hypotenuse. If we measure the
sides as n units, the hypotenuse will measure n
âˆš
2 units. Thus, to measure the
hypotenuse, there must be a number we write as
âˆš
2, which when multiplied by
itself is 2. A good calculator will approximate
âˆš
2 as 1.41421. A better calculator
will approximate it as 1.41421356237, and a sensational one as
1.4142135623730950488016887242096980785696718753769.
But, as the Greeks discovered, the only way to write an exact representation of
the number is by saying that it is a number that when squared is 2 and then to
make up a symbol for it, such as
âˆš
2.
Since our goal is to develop a rigorous description of the real numbers, we
must be able to use it to work with numbers we can describe exactly but cannot

xx
Introduction
calculate exactly. We will use algebra and analysis to allow us to do arithmetic
with numbers such as this. Suppose, for example, that we need a number x so
that x3 + x = 7. Once we are sure that it exists, we can assign it a symbol. For
now, let us say â™®. As it turns out, â™®is like
âˆš
2. We can approximate it as accurately
as we like, but it may be that the only way to write it exactly is â™®. We can use
algebra to do some exact calculations with â™®. For example, â™®4 = 7â™®âˆ’â™®2, but it
is a matter of opinion whether 7â™®âˆ’â™®2 is a better name for â™®4 or if it is the other
way around.
For a more famous example, suppose that we need a number that is the ratio
between the circumference of a circle and the diameter of the circle. First, we
need to know that it exists, but we can thank the ancient Greeks for that. We
can assign it a symbol ðœ‹. We can approximate it as accurately as we like, but
the only way to write it exactly is ðœ‹. The situation is even worse than
âˆš
2 or
â™®; mathematicians have proved that there is no polynomial P(x) of any degree
with rational coeï¬ƒcients so that P(ðœ‹) = 0. This means that the only possible
way to write ðœ‹4 exactly is ðœ‹4.
The way most people know ðœ‹is â€œ3.14159 . . . . where the digits continue
forever without a pattern.â€ So the question is, â€œDoes anyone know ðœ‹exactly?â€
If there is no pattern to the digits and they go on forever, then no one can know
them all. These digits may look random after a while, but because we believe ðœ‹
is a real number, we believe that all the digits are exactly described even if they
may never be all known. Most educated people have a working knowledge of
the real numbers, but mostly because they have a reasonable understanding of
decimal approximation. Thus, they are not bothered by questions about exact
values of ðœ‹.
On the other hand, consider 2ðœ‹. With a calculator, almost anyone can ï¬nd
that 2ðœ‹= 8.8249778, and many will guess that this is simply an approximation
of the exact value. But scratch the surface of this general understanding of real
numbers and you discover a problem: what have we approximated? That is,
â€œWhat is the meaning of 2ðœ‹?â€ Now 2
22
7 =
7âˆš
222, but ðœ‹is not a rational fraction.
So this is of little help describing what the number 2ðœ‹means. The only reason
most people have to believe that it has a meaning at all is that their calculator
will calculate it.
Next consider a problem with inï¬nite decimal arithmetic that most
people
avoid
by
using
approximations.
Consider
the
numbers:
ð›¼=
0.91260 91260 91260 â€¦ and 0.142857 142857 142857 â€¦, where the ellip-
sis (â€¦) means that the pattern of digits repeats forever. Now if we believe
that we can make ðœ‹a number by saying â€œðœ‹is 3.14159 . . . . where the digits
continue forever without a pattern,â€ then knowing all the digits of ð›¼and ð›½
should make them even better known numbers. The question is, can we ï¬nd

Introduction
xxi
an exact decimal expression for ð›¼âˆ’ð›½? Does it even have one? If we line them
up to subtract using the familiar algorithm, it is hard to know where to start
working on the digits. If we know enough about real and rational numbers,
we may know a better approach that tells us that the answer will have its
own repeating decimal form. But ï¬nding that exact answer means having the
patience to calculate and recognize the 30 digit repeating pattern it turns out
to have.
The ï¬nal example has been known to be good bait used by trolls on math-
ematical discussion boards since the invention of the internet. Consider two
other numbers ð›¼= 0.5 and ð›½= 0.499999 â€¦. The question is, â€œIs one of these
numbers greater than the other, and if so which?â€ Now as we know, the number
ð›¼has a better name. The decimal point in 0.5 is mathematical notation where
the next digits give the number of parts where the previous unit is divided into
10 equal parts. Thus, ð›¼=
5
10 = 1
2. Comparing the ï¬rst decimal digits, we know
that, ð›¼is deï¬nitely greater than or equal to ð›½. Its ï¬rst digit is larger than the
ï¬rst digit of ð›½, and some might say that that makes it greater. But it really only
tells us that ð›¼â‰¥ð›½. We might try to subtract to see if the diï¬€erence is 0. If we
line them up
0.50000000000000 â€¦
0.49999999999999 â€¦
we run into the same problem we just saw; where to start? The fact that most
of the digits in ð›½are greater than the ones in ð›¼above them forces us to guess
how that arithmetic will go. Still, we can certainly see that the result will start:
0.00000. We can guess that it will never give a digit other than 0 until it ends
and that it will, in fact, never end. The result of the subtraction will be a decimal
with inï¬nitely many 0 digits. That must be 0, right? In the end, we can only use
the ï¬nite versions of subtraction to approximate the inï¬nite arithmetic. If we
are lucky, we can identify a pattern and guess an answer. But can we be sure? It
does look like ð›½âˆ’ð›¼= 0 and so ð›¼= ð›½, but can one real number really have two
decimal expansions?
In Mathematics, we often describe a precise number that we can only approx-
imate using decimal numbers. We then give the number a name or symbol and
work with the number by working with the name. We did this earlier by setting
ð›¼= 0.5 and ð›½= 0.499999 â€¦. We then interpreted ð›¼= 0.5 to mean 5 divided by
10. We then argued that there was reason to suspect ð›¼= ð›½. The most famous
case of naming numbers we do not know exactly is ðœ‹, but the base of the natural
logarithms e is basically the same. From this point of view, for any positive real
number a, we use the symbol
nâˆš
a as a name for the real solution to xn = a. In
addition, for any real number ðœƒ, we use geometry to precisely describe a number

xxii
Introduction
between 0 and 1 that we call sin(ðœƒ). A lot of Mathematics is about ï¬nding precise
relations between the diï¬€erent numbers we have named. If the real numbers
work as we expect, it should come as no surprise that 0.5 = 0.499999 â€¦. We
should be able to prove this from basic undeniable principles. We also should
know that sin
(
ðœ‹
4
)
=
1
âˆš
2, and we expect someone is able to prove it. A bit more
surprising is that â™®, the real solution of x3 + x = 7 can also be given as
â™®= âˆ’3
âˆš
2
189 +
âˆš
35829
+
3
âˆš
63 +
âˆš
3981
18
.
However, mathematicians were mostly shocked when Niels Abel proved that
the real solution â™­to x5 + 10x2 = 40 cannot be given precisely in terms of nat-
ural numbers and radical signs alone.
Numbers such as ðœ‹and e have no pattern in their decimal expansions. We
can, however, describe ðœ‹and e using inï¬nite representations where all the terms
are known:
ðœ‹= 4
1 âˆ’4
3 + 4
5 âˆ’4
7 + 4
9 + â€¦
e = 1 + 1
1! + 1
2! + 1
3! + 1
4! + â€¦
ðœ‹= 2
1 â‹…2
3 â‹…4
3 â‹…4
5 â‹…6
5 â‹…6
7 â‹…Â· Â· Â·
These are at least a bit better than the decimal approximations because the pat-
terns they follow do give all the terms. If we prove that these inï¬nite expressions
actually give numbers, we can claim to know them exactly. We still cannot write
them down exactly without alluding to inï¬nitely many terms. We can use our
names for them to do calculations with them using algebra. We can do approx-
imate calculations with them by keeping just the ï¬rst terms in their inï¬nite
expressions. However, knowing why the ï¬rst and last inï¬nite expressions can be
given the same name is an issue for analysis. If we can ï¬nd some argument that
the diï¬€erence between ð›¾= 4
1 âˆ’4
3 + 4
5 âˆ’4
7 + 4
9 + â€¦ and ð›¿= 2
1 â‹…2
3 â‹…4
3 â‹…4
5 â‹…6
5 â‹…
6
7 â‹…Â· Â· Â· is zero, we can at least say ð›¾= ð›¿. But why either of these make
sin
(
ðœ‹
4
)
=
1
âˆš
2 true requires analysis.
Our goal is to develop a precise description of the real numbers that allows us
to deal with real numbers we can describe precisely but not write out precisely
with ï¬nite terms. We will generally use analysis to determine when we have
actually described one and only one real number, that is, to determine when a
number exists and is unique. This will allow us to give it a name. We will then
typically use algebra to use the name to study that number or other numbers
we might be interested in.

Introduction
xxiii
We start by reviewing the most basic aspects of numbers. These are things
that we may not have looked at closely since we learned about then in preschool,
kindergarten, or elementary school. The object is to practice being very careful
and precise with the most familiar of all Mathematics. But this time, we have
algebra to help. As we have seen, some things about numbers can be confusing.
We can learn to work past any confusion by starting with an extra careful look
at things we know very well.

1
Part I
A First Pass at Deï¬ning â„

3
1
Beginnings
1.1
A naive approach to the natural numbers
1.1.1
Preschool: foundations of the natural numbers
One of the ï¬rst things we learn in mathematics is the counting chant: one,
two, three, four, ï¬ve . . . . We quickly learn how to count to higher and higher
numbers, and ï¬nally, the day comes when we realize that we can continue on
counting forever. At that point, believe it or not, we have all the necessary
assumptions we need to discover all of mathematics. The counting numbers
are often called whole numbers, but mathematicians call them natural numbers.
We can express our childhood discovery in four adult principles:
â€¢ There is a unique ï¬rst natural number.
â€¢ Every natural number has a unique immediate successor.
â€¢ Every natural number except the ï¬rst has a unique immediate predecessor.
â€¢ Every natural number is an eventual successor of the ï¬rst.
Algebra begins when we introduce symbols to express these principles. Now
there is a unique ï¬rst natural number; we will write it as 1. Every natural num-
ber has a unique immediate successor. There are many choices for denoting the
successor of a natural number. In a more rigorous course on the foundations of
mathematics, we might write the successor of a natural number n as s(n). We
will choose a notation that anticipates later deï¬nitions. The successor of a natu-
ral number n will be written as n + 1. Notice that this is not addition (yet); n + 1
means â€œthe successor of n,â€ no more and no less. Every natural number except
the ï¬rst has a unique immediate predecessor. Again, we choose a notation with
an eye on what is coming later. If n â‰ 1, the predecessor of a natural number
n will be written as n âˆ’1. This is not subtraction; it is simply the symbol for
the predecessor. The relationship between successors and predecessors can be
described using this notation. Notice that 1 âˆ’1 is not deï¬ned because the ï¬rst
number does not have a predecessor.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

4
1 Beginnings
Remark. If n is a natural number, then (n + 1) âˆ’1 = n.
Remark. If n is a natural number and n â‰ 1, then (n âˆ’1) + 1 = n.
These are our ï¬rst algebraic results. Note that they are nothing more than
symbolic representations of the meanings of the words â€œsuccessorâ€ and â€œpre-
decessor.â€ Thus, (n + 1) âˆ’1 = n is just a symbolic statement that means â€œthe
predecessor of the successor of a natural number n is just the number n.â€ Thus,
(n âˆ’1) + 1 = n means â€œthe successor of the predecessor of a natural number
n other than the ï¬rst number 1 is just the number n.â€ That is all algebra really
is: the encoding of ideas expressed in words into symbolic representations of
those ideas.
The fourth principle is the hardest to precisely express in symbols. However,
in this ï¬rst chapter, we are just setting some groundwork to make later logi-
cally rigorous mathematics easier. We are willing to forgo some rigor to lay this
groundwork. To say this more clearly, we are not going to restrict ourselves to
completely logical proofs and deï¬nitions until the end of this chapter.
The fourth principle states: Every natural number is an eventual successor of
the ï¬rst. That is, every natural number is the successor of the successor of the
successor of â€¦ the successor of 1. The loose notation for this is: if n is a natural
number, then n can be written as
n = (((â€¦ ((1 + 1) + 1) + â€¦ + 1) + 1) + 1.
(1.1)
The use of the ellipsis in this bit of algebra kills any hope of making an unam-
biguous statement. It should be clear what this means: n is made up of a series
of (+1)s, each of which signals the successor of a previous number. This is not
the best way to begin a course in rigorous mathematics, and soon we will need
to replace it with something else.
There is one more bit of notation we set for dealing with these basic princi-
ples. We say m is an eventual successor of n if
m = (((â€¦ ((n + 1) + 1) + â€¦ + 1) + 1) + 1.
(1.2)
Again, the use of ellipsis kills any rigor this idea might have. When m is an even-
tual successor of n, we say â€œm is greater than nâ€; and we write m > n. Actually,
we might prefer to move smaller to larger and write n < m and say â€œn is less than
m.â€ This leads to some algebra, and a careful name for an important algebraic
property:
Remark. Let k, m and n be natural numbers. If n < m and m < k, then n < k.
We can refer to this remark by saying, â€œThe order of the natural numbers is
transitive.â€

1.1 A Naive Approach to the Natural Numbers
5
This remark is true because n < m means
m = (((â€¦ ((n + 1) + 1) + â€¦ + 1) + 1) + 1,
(1.3)
and m < k means
k = (((â€¦ ((m + 1) + 1) + â€¦ + 1) + 1) + 1.
(1.4)
Equality means that m is exactly the same as the expression that follows
the equal sign. So we can â€œsubstituteâ€ that expression for the m in the later
equation.
k = (((â€¦ ((â€¦ (n + 1) â€¦ + 1) + â€¦ + 1) + 1) + 1.
(1.5)
So, indeed, k is an eventual successor of n.
Finally, suppose that we have natural numbers n and m. Since we have not said
otherwise, they could be the same. Thus, it might be that n = m. Both numbers
are eventual successors of 1. If n â‰ m, one of the two must be an eventual suc-
cessor of 1 that appears before the ï¬rst. Thus, either n < m or m < n. This leads
to our ï¬nal observation about the order of the natural numbers and another
mathematical term.
Remark. If n and m are natural numbers, then exactly one of the following must
be true: n < m; m < n; or n = m.
We refer to this remark by saying, â€œThe order on the natural numbers has
trichotomy.â€
Thus, if n < m is not true, then either m < n or n = m. We have notation that
allows us to abbreviate this further. We write n â‰¤m to mean either n < m or
n = m. Similarly, we write n â‰¥m to mean either n > m or n = m. There is no
notational shortcut for saying either n > m or n < m other than n â‰ m.
1.1.2
Kindergarten: addition and subtraction
The ï¬rst use we learn for numbers is for counting things. We learn names and
symbols for all the eventual successors of 1.
1 + 1 = 2.
(1.6)
(1 + 1) + 1 = 3.
((1 + 1) + 1) + 1 = 4.
(((1 + 1) + 1) + 1) + 1 = 5.
Â· Â· Â· Â· Â· Â· = Â· Â· Â·
In the early grades, we add the two numbers 2 and 5 by creating two sets (say,
of marbles), one with 2 marbles and another set with 5 marbles. We combine

6
1 Beginnings
the two sets into one and count to ï¬nd a total of 7 marbles. We learn that the
notation for this is 2 + 5 = 7.
2 = 1 + 1;
(1.7)
5 = (((1 + 1) + 1) + 1) + 1;
2 + 5 = (1 + 1) + ((((1 + 1) + 1) + 1) + 1)
= ((((((1 + 1) + 1) + 1) + 1) + 1) + 1)
= 7.
While a main goal in elementary school arithmetic is learning the algorithm for
adding natural numbers, this would be pointless without a few years of counting
and combining so that we know what the addition algorithm does for us. This
algorithm is a theoretical method that allows us to avoid long counts. We even-
tually learn how to ï¬nd that 27 + 35 = 62 without knowing what objects we
are trying to count. The concrete problem of counting combined sets becomes
the abstract problem of adding numbers. We learn what addition is mostly by
repeated counting. Later, we learn a shortcut that uses an arithmetic procedure.
But addition has never been taught by someone deï¬ning it for us, until now.
As adults we need to invent (or deï¬ne) an operation on natural numbers
where two natural numbers n and m are combined to produce a new natural
number. We denote this new number as n + m. We deï¬ne this new number by
writing n and m as eventual successors of 1:
n = (((â€¦ ((1 + 1) + 1) + â€¦ + 1) + 1) + 1;
(1.8)
m = (((â€¦ ((ðŸ+ ðŸ) + ðŸ) + â€¦ + ðŸ) + ðŸ.
Then
n + m = [(((â€¦ ((1 + 1) + 1) + â€¦ + 1) + 1) + 1]
(1.9)
+ [(((â€¦ ((ðŸ+ ðŸ) + ðŸ) + â€¦ + ðŸ) + ðŸ]
= (((â€¦ ((1 + 1) + 1) + â€¦ + 1) + 1) + 1)
+ Â· Â· Â· + ðŸ) + ðŸ) + ðŸ) + â€¦ ðŸ) + ðŸ.
The imprecision of the ellipsis almost renders this deï¬nition useless, but the
bold 1s help a bit. In a course on the rigorous foundations of mathematics,
we would need to do much better than this. Luckily, years of combining sets
of marbles allows us to realize what we are trying to say in this study with
the aforementioned deï¬nition. This almost unintelligible deï¬nition does lead
to one very important algebraic fact. It is clear that the deï¬nition of addition
is just the rearrangement of the parenthesis around 1s and +s. Thus, we have
an algebraic fact about the addition of counting numbers: parentheses do not
matter.
Remark. If k, m, and n are natural numbers, then (k + n) + m = k + (n + m).

1.1 A Naive Approach to the Natural Numbers
7
We refer to this by saying, â€œAddition of natural numbers is associative.â€
A few other algebraic facts follow just as quickly.
Remark. If m and n are natural numbers, then n < n + m.
We refer to this by paraphrasing Euclid, â€œThe whole is greater than the part.â€
Remark. If k, m, and n are natural numbers and n < m, then n + k < m + k.
We refer to this by saying, â€œAddition of natural numbers respects the order.â€
If we remember our lessons from counting blocks, we realize that it doesnâ€™t
make a diï¬€erence which set of blocks we start with when we combine the two
sets â€“ the total always comes out the same. We can turn this observation into
another useful algebraic fact.
Remark. If m and n are natural numbers, then m + n = n + m.
We refer to this by saying, â€œAddition of natural numbers is commutative.â€
The ï¬rst step after learning the arithmetic operation of addition is the intro-
duction of a new operation, subtraction. At ï¬rst we learned it as the solution
to an addition puzzle, such as â€œWhat number added to 5 gives 7?â€ We all recall
the problem: Fill in the box
5 + [ ] = 7.
(1.10)
Only later, after we understood this type of question better, did we learn a
procedure for subtracting. Soon we learned that there were two arithmetic
operations: addition and subtraction. As mathematicians, we will not talk about
subtraction as its own operation, but rather look at it in terms of addition. It is
not that there is anything wrong with thinking of subtraction as its own oper-
ation, but just that it will help later algebraic ideas to try to keep the language
focused on addition. Subtraction will still be a possibility, but we will not fully
admit it, but rather refer to the following property of the natural numbers:
Remark. If n and m are natural numbers with n < m, then there exists a unique
natural number k so that m = n + k.
We refer to this by saying, â€œThere is a conditional subtraction on the natural
numbers.â€
We say that this subtraction is conditional because we cannot subtract the
natural number n from m unless n < m (and get a natural number as a result).
Of course, one of our ï¬rst orders of business will be to create the integers as
a larger collection of numbers that removes this condition on subtraction. As
for notation, it is no surprise that we will eventually write k as m âˆ’n. Thus,

8
1 Beginnings
the sign â€œâˆ’â€ for subtraction is still there. For at least a while, we will not take
advantage of this notation because we are trying to avoid treating subtraction
as an operation. The reason for this should be clearer when we start to discuss
the integers where things work better algebraically.
There are two other â€œsubtractionâ€ properties that we will use frequently.
Remark. If k, n, and m are natural numbers with n + k = m + k, then n = m.
Remark. If k, n, and m are natural numbers with n + k < m + k, then n < m.
Rather than talking about these in terms of subtraction, we will refer to these
as â€œcancellation properties of addition.â€
1.1.3
Grade school: multiplication and division
Once we know that we can add any two natural numbers, we can use that
to invent a new operation, multiplication. Two natural numbers n and m are
combined to produce a new natural number. We denote this new number as
n â‹…m or nm. We deï¬ne this new number by writing n as eventual successor
of 1:
n = (((â€¦ ((1 + 1) + 1) + â€¦ + 1) + 1) + 1.
(1.11)
Then
n â‹…m = (((â€¦ ((m + m) + m) + â€¦ + m) + m) + m.
(1.12)
Again, because of the ellipsis, the only reason this might be considered a deï¬-
nition is because we already know what it means: to ï¬nd n â‹…m add m to itself n
times. For example,
3 Ã— 7 = (7 + 7) + 7.
(1.13)
As we move on to a discussion of the properties of multiplication, we lose any
pretense of rigor. We need to refer to geometric intuition to justify our obser-
vations. Luckily, we spent endless hours playing with various objects in the
elementary grades, developing this intuition just to understand the multipli-
cation properties. A geometric representation of nâ‹…m is the number of objects
arranged in a rectangle n blocks wide and m blocks long. A geometric repre-
sentation of (n â‹…m) â‹…k is the number of objects arranged in k rectangles each
n blocks wide and m blocks long and stacked into a 3-D box. If we turn an n
by m rectangle on its side, it turns into a rectangle that is m objects wide and n
objects long. So we have our ï¬rst algebraic property of multiplication.
Remark. If m and n are natural numbers, then m â‹…n = n â‹…m.
We refer to this by saying, â€œMultiplication of natural numbers is
commutative.â€

1.1 A Naive Approach to the Natural Numbers
9
If we pile k of these rectangles one on top of each other, we get a box n blocks
wide, m blocks long, and k blocks high. The number of blocks in the box is
k â‹…(n â‹…m). But if we stack m walls of rectangles that are m blocks long and k
blocks high, we get the same box. The number of blocks in the box is m â‹…(n â‹…k).
But by commutativity of multiplication, we can say
Remark. If k, m and n are natural numbers, then (k â‹…n) â‹…m = k â‹…(n â‹…m).
We refer to this by saying, â€œMultiplication of natural numbers is associative.â€
The next observation follows directly from the deï¬nition of multiplication.
Remark. If n is a natural number, then n â‹…1 = 1 â‹…n = n.
We refer to this by saying, â€œ1 is a multiplicative identity.â€
If n < m, then m is an eventual successor of n, and we can write
m = (((â€¦ ((n + 1) + 1) + â€¦ + 1) + 1) + 1
(1.14)
= (â€¦ (.(ðŸ+ ðŸ) + ...ðŸ) + â€¦ + 1) + 1) + 1.
So
m â‹…k = (â€¦ (.(k + k) + ...k) + â€¦ + k) + k) + k
(1.15)
= (â€¦ (kn + k) â€¦ + k) + k) + k.
So we know k â‹…n < k â‹…m. Thus,
Remark. If k, m, and n are natural numbers and n < m, then n â‹…k < m â‹…k.
We refer to this by saying, â€œMultiplication of natural numbers respects the
order.â€
Notice that we have deï¬ned three things for the natural numbers: an order
<, and two operations: addition + and multiplication â‹…. We know how addition
interacts with the order. Addition respects the order. We know how multipli-
cation interacts with the order; multiplication respects the order. Next, we see
how multiplication interacts with addition. We leave a geometric justiï¬cation
of this as an exercise.
Remark. If k, m, and n are natural numbers, then k â‹…(n + m) = k â‹…n + k â‹…m.
We refer to this by saying, â€œMultiplication of natural numbers distributes over
addition.â€
If we were reluctant to talk about subtraction of natural numbers simply
because to subtract n from m we must know n < m, we are deï¬nitely going to
wait before we discuss division of natural numbers. Division of natural numbers

10
1 Beginnings
is a much more complicated procedure involving remainders as well as quo-
tients. We will get to it, but not just now.
Still we would like some division-like algebraic results to make things easier.
We have two painfully obvious observations:
Remark. If k, n, and m are natural numbers with n â‹…k = m â‹…k, then n = m.
Remark. If k, n, and m are natural numbers with n â‹…k < m â‹…k, then n < m.
We refer to either of these as â€œcancellation properties of multiplication.â€ Be
warned, however, these are very dangerous. We are basically going to ï¬nd safer
replacements for them as soon as we can.
These are â€œpainfullyâ€ obvious because while they are quite obvious after
years of practicing arithmetic, the justiï¬cations that they are correct are rather
painful to follow. There are a few ingredients in this justiï¬cation: trichotomy,
the results of multiplication are unique, multiplication respects order, and
logical reasoning. Let us give a justiï¬cation a try.
We know that the results of multiplication are unique; however we multiply
two numbers m and k, the result will always be the same. Thus, we can state this
algebraically as: if n = m, then for all natural numbers k, we have n â‹…k = m â‹…k.
We really want to be clear about what this says.
If it is true that n = m, then it absolutely must be true that n â‹…k = m â‹…k.
(We are just being resolute about our earlier statement.) But then, if we ever see
that n â‹…k = m â‹…k is false, then there is no way that n = m could be true. This is
to say:
If n â‹…k â‰ m â‹…k, then n â‰ m.
Let us remember this for now.
Because multiplication respects order, we know that if k, m, and n are natural
numbers and n < m, then n â‹…k < m â‹…k. So assuming that k, m, and n are natural
numbers, if it is true that n < m, then it absolutely must be the case that n â‹…k
< m â‹…k. So as before, if we ever see that n â‹…k < m â‹…k is false, then there is no
way that n < m could be true. So
If n â‹…k < m â‹…k is not true, then n < m is not true either.
But by trichotomy, saying that n â‹…k < m â‹…k is false is the same as saying n â‹…k
â‰¥m â‹…k. By basically the same argument, we can also say:
If m â‹…k < n â‹…k is not true, then m < n is not true either.
Now we can justify our ï¬rst statement that, if nâ‹…k = mâ‹…k, then n = m. Sup-
pose it is true that n â‹…k = m â‹…k. Then by trichotomy, both (n â‹…k < m â‹…k) and
(m â‹…k < n â‹…k) are not true. (Trichotomy says exactly one must be true.) By our

1.1 A Naive Approach to the Natural Numbers
11
two observations, we know (n < m) is not true, and (m < n) is not true. But
trichotomy leaves only one possibility. It must be that n = m. Thus, as we said
in our second remark: if k, n, and m are natural numbers with n â‹…k < m â‹…k, then
n < m.
Next, we justify our second statement that, if n â‹…k < m â‹…k, then n < m. Sup-
pose nâ‹…k < mâ‹…k. Then by trichotomy, both (nâ‹…k = mâ‹…k) and (mâ‹…k < nâ‹…k) are
not true. By the ï¬rst observation, we know that (nâ‹…k â‰ mâ‹…k) implies n â‰ m. The
last observation says that (m â‹…k < n â‹…k) is not true implies that (m < n) is not
true. But again, trichotomy leaves only one possibility. It must be that n < m.
It was a bit painful to follow these justiï¬cations of those simple remarks, but
we do now see that they are simply consequences of trichotomy and a unique
result from multiplication. One of our goals is to create an algebraic and logical
language that makes arguments such as this easier to understand.
There is only one last remark we need to make about the natural numbers.
Remark. Let n and m be natural numbers with n â‰¤m â‰¤n + 1, then either
n = m or m = n + 1.
We refer to this by saying, â€œThe natural numbers are discrete.â€
Again, the justiï¬cation for this depends on the statements in the earlier
remarks. Suppose n < m < n + 1. Then by subtraction (whoops), we know
that there is a natural number k so that m = n + k. But then n + k = m and
m < n + 1. So by transitivity, n + k < n + 1. But we have a cancellation rule for
addition; so k < 1. But since every natural number is an eventual successor of
1 and trichotomy holds, this cannot happen.
The purpose of algebra is to help make all these justiï¬cations easier to
manage.
1.1.4
Natural numbers: basic properties and theorems
We have just reviewed several years of elementary school arithmetic so that we
can identify and name various basic algebraic properties of the natural num-
bers. They are as follows:
â€¢ There is a ï¬rst natural number, which we call 1.
â€¢ There is an order on the natural numbers.
â€¢ The order is transitive.
â€¢ The order has trichotomy.
â€¢ For any two natural numbers n and m, there is a unique natural number
n + m.
â€¢ This addition is associative.
â€¢ This addition is commutative.
â€¢ If m and n are natural numbers, then n < n + m.
â€¢ If k, m, and n are natural numbers and n < m, then n + k < m + k.

12
1 Beginnings
â€¢ If n and m are natural numbers with n < m, then there exists a unique natural
number k so that m = n + k.
â€¢ If k, n, and m are natural numbers with n + k = m + k, then n = m.
â€¢ If k, n, and m are natural numbers with n + k < m + k, then n < m.
â€¢ For any two natural numbers n and m, there is a unique natural number n â‹…m.
â€¢ This multiplication is associative.
â€¢ This multiplication is commutative.
â€¢ The natural number 1 is a multiplicative identity.
â€¢ If k, m, and n are natural numbers and n < m, then n â‹…k < m â‹…k.
â€¢ If k, n, and m are natural numbers with n â‹…k = m â‹…k, then n = m.
â€¢ If k, n, and m are natural numbers with n â‹…k < m â‹…k, then n < m.
â€¢ If m and n are natural numbers and n â‰¤m â‰¤n + 1, then either m = n or
m = n + 1.
â€¢ Multiplication distributes over addition.
1.2
First steps in proof
There are, of course, many more true facts about the natural numbers, but they
all should follow from these basic properties. We will state many further facts
about these numbers as theorems. We will prove these theorems by using the
aforementioned basic properties. If our justiï¬cations for these properties are
accepted and are correct, then the theorems we prove by using them must be
perfectly true. Granted our justiï¬cations of these properties are a bit dicey, but
we are going to have to start being rigorous somewhere, and it will be easier
starting by assuming a list of basic properties such as those aforementioned.
Let us now use these properties to prove something.
1.2.1
A direct proof
The ï¬rst proof we will give is called a direct proof . Suppose that we wish to
prove a statement of the form â€œIf P, then Q.â€ In a direct proof of this statement,
we begin by assuming P. Then we deduce Q using P and any other assumptions
we have available. Let us now prove the statement
If n is a natural number, then (n + 1)2 = n2 + 2n + 1
using a direct proof. This is of the form â€œIf P, then Qâ€ where P is the statement
â€œn is a natural numberâ€ and Q is the statement â€œ(n + 1)2 = n2 + 2n + 1.â€ We will
begin the proof by assuming that n is a natural number. Knowing that, we can
use all of the basic properties of the natural numbers listed earlier. So we will
use those assumptions to deduce that (n + 1)2 = n2 + 2n + 1.
Theorem 1.2.1.
If n is a natural number, then (n + 1)2 = n2 + 2n + 1.

1.2 First Steps in Proof
13
Proof. Assume that n is a natural number. Then n + 1 is a natural number
because addition is always deï¬ned. Then
(n + 1)2 = (n + 1)(n + 1),
(1.16)
because that is what the exponent means.
(n + 1)(n + 1) = (n + 1)n + (n + 1) â‹…1,
(1.17)
by the distributive property.
(n + 1)n + (n + 1) â‹…1 = (n + 1)n + (n + 1),
(1.18)
because 1 is a â‹…identity.
(n + 1)n + (n + 1) = n(n + 1) + (n + 1),
(1.19)
because â‹…is commutative.
n(n + 1) + (n + 1) = (n â‹…n + n â‹…1) + (n + 1),
(1.20)
by the distributive property.
(n â‹…n + n â‹…1) + (n + 1) = (n â‹…n + n) + (n + 1),
(1.21)
because 1 is a â‹…identity.
(n â‹…n + n) + (n + 1) = (n2 + n) + (n + 1),
(1.22)
because that is what the exponent means.
(n2 + n) + (n + 1) = n2 + (n + (n + 1)),
(1.23)
because + is associative.
n2 + (n + (n + 1)) = n2 + ((n + n) + 1),
(1.24)
because + is associative.
n2 + ((n + n) + 1) = n2 + ((n â‹…1 + n â‹…1) + 1),
(1.25)
because 1 is a â‹…identity.
n2 + ((n â‹…1 + n â‹…1) + 1) = n2 + (n(1 + 1) + 1),
(1.26)
by the distributive property.
n2 + (n(1 + 1) + 1) = n2 + (n â‹…2 + 1),
(1.27)
because that is what 2 means.
n2 + (n â‹…2 + 1) = n2 + (2n + 1),
(1.28)
because â‹…is commutative.
n2 + (2n + 1) = n2 + 2n + 1,
(1.29)
because + is associative, this is unambiguous.

14
1 Beginnings
Thus, we have
(n + 1)2 = n2 + 2n + 1.
(1.30)
â—½
This is a completely algebraic proof; it is also a completely boring proof to
anyone who knows algebra. This is the stuï¬€of middle school algebra and is not
the kind of proof that should give us any problems. While we should be able to
justify any step in any algebraic part of any proof we give, there is rarely a reason
to do so. In addition, we can take advantage of algebraâ€™s disregard for the rules
of proper language composition. Notice that each step in the aforementioned
proof is a full English sentence with a subject, a verb (always â€œequalsâ€), and an
object followed by a prepositional phrase. This is how a paragraph should be in
any English composition.
But in an algebraic proof, we can violate one the major rules of good writing:
no run-on sentences. The aforementioned proof is completely over the top for
mathematical adults. In any work past a high school text, it would be written
more like:
(n + 1)2 = (n + 1)(n + 1)
(1.31)
= (n + 1)n + (n + 1)
= n2 + n + n + 1
= n2 + 2n + 1.
Even this might be longer that necessary. Notice that this is a run-on English
sentence. It has one subject, (n + 1)2, several objects, and one word â€œequalsâ€
used as a verb four times. This is unacceptable in an English composition, but
perfectly acceptable in an algebraic proof. We need to remember that this proof
is an abbreviation of the full proof written earlier as a composition. Each equal
sign has two subjects: the object of the previous line, and by deduction, the orig-
inal subject of the sentence. The conclusion drawn from the four intermediate
sentences is that the original subject is equal to the ï¬nal object.
In this study, we will not bother to do much more than outline an algebraic
proof such as this. This does not, however, reduce at all our need for detailed
algebraic proofs. As humans we will make algebra mistakes, and we need to
be ready to ï¬nd them before someone else does. Finding an algebraic mistake
is often nothing more than giving a complete and thorough line-by-line step
through the use of our basic properties until the error reveals itself.
1.2.2
Mathematical induction
Unfortunately, not all theorems about the natural numbers are easily proved by
a direct proof or simple algebra. Consider
For all natural numbers n, 2 â‹…(1 + 2 + 3 + â€¦ (n âˆ’1) + n) = n(n + 1).

1.2 First Steps in Proof
15
The dreaded rigor killer, ellipsis, appears again. Mathematics has notation
that allows us to write such a summation in a more precise mathematical way.
However, in this case, it is pretty clear what this claim is: if we add all the num-
bers starting at 1 and stop when we get to n and then double the result, the
answer would be the same as if we multiplied n by its successor. Unfortunately,
the only direct proof of this involves using geometric intuition. This is a per-
fectly ï¬ne proof, but there is an alternate proof that uses a much more general
method with many more applications.
We will prove this claim using a â€œproof by mathematical induction.â€ Such a
proof is a two-step process. Both steps must be completed successfully for the
proof to be valid. The ï¬rst step is to prove that the result is true for the ï¬rst nat-
ural number. The second step takes advantage of a logical loophole. To prove a
statement of the form â€œIf something, then something else,â€ one may assume that
something is true. Once something is assumed true for a valid logical reason,
we can use that assumption to draw additional conclusions. The second step
in induction is to prove the following: â€œIf the statement is true for a particular
natural number, then it will be true for its successor.â€
If we can accomplish both these steps, we will know
â€¢ that the statement is true for 1;
â€¢ that anytime the statement is true for a particular number, it will be true for
its successor.
So we know that the statement is true for 1, and 1 is certainly a particular
number. Since the statement is true for 1, it is true for the successor of 1. But
2 is a particular number, and the statement is true for it; so because we have
proved the second step of induction, the statement is true for the successor of
2. Because every natural number is an eventual successor of 1, we will eventually
know that the statement is true for any number.
Here is the claim written as a theorem, and this is followed by its (mostly
rigorous) proof. Notice that, as we write out exactly what we are proving, our
statement about n reappears three times. It may look like we are proving or
assuming the same thing over and over. But a more careful look reveals that in
each statement, the meaning of the variable n changes. Thus, the statements
are actually about diï¬€erent numbers.
Theorem 1.2.2.
For all natural numbers n, 2 â‹…(1 + 2 + 3 + â€¦ (n âˆ’1) + n) =
n(n + 1).
Proof. The proof is by induction on n. Thus, we will actually prove two other
mini theorems:
1. If n = 1, then 2 â‹…(1 + 2 + 3 + â€¦ (n âˆ’1) + n) = n(n + 1).

16
1 Beginnings
2. If for a particular n = n0,
2 â‹…(1 + 2 + 3 + â€¦ (n âˆ’1) + n) = (n + 1)n,
(1.32)
then for n = n0 + 1,
2 â‹…(1 + 2 + 3 + â€¦ (n âˆ’1) + n) = n(n + 1).
(1.33)
Proof of Step 1. Assume that n = 1. To prove that two expressions are the same,
consider them one at a time. First, (1 + 2 + 3 + â€¦ (n âˆ’1) + n) means start at 1
and stop when you get to n. But we are working under the assumption that
n = 1. So
(1 + 2 + 3 + â€¦ (n âˆ’1) + n) = 1.
(1.34)
So
2 â‹…(1 + 2 + 3 + â€¦ (n âˆ’1) + n) = 2 â‹…1 = 2.
(1.35)
Now consider the other expression, n(n + 1). We are still assuming n = 1.
(n + 1)n = (1 + 1) â‹…1 = 2.
(1.36)
Since 2 = 2, we have shown that if n = 1, then 2 â‹…(1 + â€¦ (n âˆ’1) + n) =
n(n + 1).
â—¾
Proof of Step 2. Assume for a particular n = n0, 2 â‹…(1 + â€¦ (n âˆ’1) + n) =
n(n + 1). Thus, we can say
2 â‹…(1 + â€¦ (n0 âˆ’1) + n0) = n0.(n0 + 1).
(1.37)
Under this assumption, we want to prove, for n = n0 + 1, that we also have
2 â‹…(1 + 2 + 3 + â€¦ (n âˆ’1) + n) = n(n + 1). That is to say, we want to show
2 â‹…(1 + 2 + â€¦ ((n0 + 1) âˆ’1) + (n0 + 1)) = (n0 + 1)((n0 + 1) + 1). (1.38)
To prove that two expressions are equal, we consider each side. Consider
2 â‹…(1 + â€¦ ((n0 + 1) âˆ’1) + (n0 + 1)). We have
2 â‹…(1 + â€¦ ((n0 + 1) âˆ’1) + (n0 + 1))
(1.39)
= 2 â‹…[(1 + 2 + 3 + â€¦ n0) + (n0 + 1)]
= 2 â‹…[1 + 2 + 3 + â€¦ n0] + 2[n0 + 1]
= n0(n0 + 1) + 2(n0 + 1)
because that is the assumption we are working under in this step. Then
2 â‹…(1 + â€¦ ((n0 + 1) âˆ’1) + (n0 + 1))
(1.40)
= n0(n0 + 1) + 2(n0 + 1)
= (n0 + 2)(n0 + 1).

1.3 Problems
17
Next, consider the other side, (n0 + 1)((n0 + 1) + 1).
(n0 + 1)((n0 + 1) + 1) = (n0 + 1)(n0 + 2).
(1.41)
The two expressions are equal. So we have proved: if for a particular n = n0,
we have 2 â‹…(1 + 2 + 3 + â€¦ (n âˆ’1) + n) = (n + 1)n, then for n = n0 + 1, we have
2 â‹…(1 + 2 + 3 + â€¦ (n âˆ’1) + n) = n(n + 1).
â—¾
These two steps complete the proof by induction. So we have proved: for all
natural numbers n, 2 â‹…(1 + 2 + 3 + â€¦ (n âˆ’1) + n) = n(n + 1).
â—½
There are a few ï¬nal comments on this write-up. Much of the exposition is a
matter of taste, but no matter what, the proof must be an English essay. It may
contain some headings, but everything in the content should be a full sentence.
This includes the algebraic calculations. The logic is easier if all statements to
be proved are written in the â€œIf P, then Qâ€ form. The proof of one of these state-
ments should begin with â€œAssume P.â€ After that assumption, the goal becomes
to prove Q. The use of n0 to stand for a particular value of n in the induction
step is completely optional. With more experience in writing induction proofs,
it becomes a distraction. However, even with experience, the second step of
an induction step can get rather confusing when the statement being proved is
long. Using the n0 can be a valuable tool in ï¬ghting through that kind of confu-
sion. For beginners, it is not a bad idea to take the time to use that extra notation
so that it will always be available when needed.
1.3
Problems
1.1
(a) Use n = 2, m = 3, and k = 4 to provide an example of the distribu-
tive property n(m + k) = nm + nk using either ellipsis arguments or
a geometric construction.
(b) Provide a justiï¬cation of the general distributive property n(m + k) =
nm + nk using either ellipsis arguments or a geometric construction.
1.2
Provide justiï¬cations for the cancellation properties of addition. (Hint:
look at the justiï¬cations for multiplication.)
1.3
Prove that for all natural numbers n,
nâˆ‘
k=1
k2 = n(n+1)(2n+1)
6
.
1.4
Be careful while reading these formulas.
(a) Prove that for all natural numbers n,
nâˆ‘
k=1
(2k âˆ’1) = n2.

18
1 Beginnings
(b) Prove that for all natural numbers n,
nâˆ‘
k=1
2k âˆ’1 = n2 + n âˆ’1.
1.5
Prove that for all natural numbers n, n2 â‰¥n.
1.6
Prove that for all natural numbers n â‰¥2, n2 â‰¥n + 2. (Hint: when trying to
prove an inequality a â‰¤b, it can help to write the objective as a â‰¤? â‰¤b.
Then the idea is to ï¬nd a value we can use in place of the question mark.
If we can prove the two inequalities a â‰¤? and ? â‰¤b, the result we want
follows from transitivity. If we are lucky, one of these two inequalities is
already known to be true.)
1.7
Prove that for all natural numbers n,
nâˆ
k=1
(
1 + 1
k
)
= n + 1. (Hint: the
symbol âˆis similar to the symbol âˆ‘except it means multiply instead of
add.)
1.8
Let n be any natural number greater than or equal to 7.
(a) Prove that if there is a natural number q so that n = 7 â‹…q, then
n + 1 = 7 â‹…q + 1.
(b) Prove that if there are natural numbers q and r so that n = 7 â‹…q + r
and r < 6, then there is a natural number râ€² so that n + 1 = 7 â‹…k + râ€²
with râ€² < 7.
(c) Prove that if there are natural numbers q and r so that n = 7 â‹…q + r
and r = 6, then there is a natural number qâ€² so that n + 1 = 7 â‹…qâ€².
(d) Prove the following statement using induction.
For all natural numbers n â‰¥7, either there exists a natural
number q so that n = 7q or there exists a pair of natural
numbers q and r so that n = 7q + r with r < 7.

19
2
The Algebra of the Natural Numbers
2.1
A more sophisticated look at the basics
In the previous chapter, we expressed a few basic discoveries about counting as
four principles:
â€¢ There is a unique ï¬rst natural number.
â€¢ Every natural number has a unique immediate successor.
â€¢ Every natural number except the ï¬rst has a unique immediate predecessor.
â€¢ Every natural number is an eventual successor of the ï¬rst.
We used these principles to deï¬ne an order, an addition, and a multiplication
on the natural numbers. We gave a list of basic properties that followed from
these ideas. Our justiï¬cations for these properties might not have all that a logi-
cian would want, but they were all familiar enough that we are not going to let
that bother us. We can sleep soundly knowing that someone, somewhere, can
turn them into rigorous proofs. As it turns out, the process of doing this goes
much better if we add one, rather more sophisticated, principle to the list. That
is, â€œthe well-ordering principle of the natural numbers.â€
Before we state this principle, we need some notation and our ï¬rst really for-
mal mathematical deï¬nition. Any collection of objects is a mathematical set.
Things in the collection are elements of the set. In mathematical notation, we
might say S is a set, and s is an element of S. We write s âˆˆS. Thus, â€œâˆˆâ€ is a sym-
bol for the phrase â€œis an element of.â€ It is the mathematical equivalent to the
verb in the sentence relating the subject s to the object S.
Of course, in mathematics, we often deal with sets of numbers. When we
have a set of numbers, it may have one that is less than all the rest, a minimum.
We want a very precise deï¬nition of this familiar term.
Deï¬nition 2.1.1
Let S be a set of numbers. When we say m is a minimum of
the set S, we mean
1. m âˆˆS, and
2. If s âˆˆS, then m â‰¤s.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

20
2 The Algebra of the Natural Numbers
To be a minimum of the set S, the number m must make both statements true.
This may seem like a rather long-winded way of describing a simple term. It is,
however, a mathematical deï¬nition speciï¬cally designed to be useful in a logical
proof. It is not meant to describe a minimum, although it does. That is the way of
all mathematical deï¬nitions. They are meant to give a precise logical statement
of what a word or phrase means, and â€“ sometimes â€“ not even a clue about
what the word is meant to describe. For a while, we will be giving mathematical
deï¬nitions to terms that we already understand. Later, however, we will give
mathematical meanings to terms we do not know and then we will use those
deï¬nitions to investigate what the terms mean. Therefore, we use the deï¬nition
to understand what the deï¬nition is really all about.
In anticipation of this future, we should take the time to memorize the oï¬ƒcial
mathematical deï¬nitions of even the most well-known terms. As we do this,
we will become more familiar with the structure of mathematical deï¬nitions,
and the process of memorizing speciï¬c deï¬nitions will get easier. There are
more mathematical deï¬nitions ahead than one might imagine; so the faster we
get at memorizing precise mathematical deï¬nitions, the better oï¬€we will be.
Hence, from now on, the answer to the question â€œWhat is the deï¬nition of the
minimum of the set A?â€ is â€œIt is a number s so that s âˆˆA and if x âˆˆA, then
s â‰¤x.â€ Of course, the letters we use to name the parts have nothing to do with
the deï¬nition. This rephrasing is exactly the same as the aforementioned oï¬ƒcial
version. Variables are called variables for a good reason.
Example 2.1.2.
Let S = {4, 8, 12}. Notice that (1) 4 âˆˆS, and (2) if x âˆˆS, then
4 â‰¤x. Thus, 4 is the minimum of S. Notice that, for example, 3 is not a minimum
of S because 3 âˆ‰S. In addition, 8 is not a minimum of S because it is not true
that 8 â‰¤x for all x âˆˆS. In particular, 8 â‰°4.
Now we are ready for an oï¬ƒcial statement of the well-ordering principle for
natural numbers.
If S is a set of natural numbers with at least one element, then S has a
minimum.
So a complete set of the basic principles that characterize the natural
numbers is
â€¢ There is a unique ï¬rst natural number.
â€¢ Every natural number has a unique immediate successor.
â€¢ Every natural number except the ï¬rst has a unique immediate predecessor.
â€¢ Every natural number is an eventual successor of the ï¬rst.
â€¢ If S is a set of natural numbers with at least one element, then S has a
minimum.

2.1 A More Sophisticated Look at the Basics
21
2.1.1
An algebraic approach
Five basic principles are enough to lead us to all sorts of additional properties
of the natural numbers. It is those algebraic properties that allow us to study
and investigate the numbers themselves. We can make it very clear that these
algebraic properties are the starting point in our studies by deï¬ning the nat-
ural numbers by these properties. We write most of these properties in full
sentences with the logical form â€œIf P, then Q.â€ Thus,
Deï¬nition 2.1.3.
The natural numbers form a set â„•with the following
properties:
1. There is an element of â„•.
2. There is an order on the natural numbers such that
(a) If k < m and m < n, then k < n.
(b) If n, m âˆˆâ„•, then exactly one of the following is true: n < m, m < n, or
n = m.
3. If S is a set of natural numbers with at least one element, then S has a
minimum.
4. If n and m are two natural numbers, then there is a unique natural number
n + m.
5. If k, n, m âˆˆâ„•, then k + (n + m) = (k + n) + m.
6. If n, m âˆˆâ„•, then n + m = m + n.
7. If n, m âˆˆâ„•, then n < n + m.
8. If k, n, m âˆˆâ„•and n < m, then n + k < m + k.
9. If n, m âˆˆâ„•with n < m, then there is a unique natural number k so that
m = n + k.
10. If k, n, m âˆˆâ„•with n + k = m + k, then n = m.
11. If k, n, m âˆˆâ„•with n + k < m + k, then n < m.
12. If n and m are two natural numbers, then there is a unique natural number
n â‹…m.
13. If k, n, m âˆˆâ„•, then k â‹…(n â‹…m) = (k â‹…n) â‹…m.
14. If n, m âˆˆâ„•, then n â‹…m = m â‹…n.
15. If we write 1 for the minimum natural number, then if n âˆˆâ„•, then 1 â‹…n =
n â‹…1 = n.
16. If k, n, m âˆˆâ„•with n < m, then n â‹…k < m â‹…k.
17. If k, n, m âˆˆâ„•with n â‹…k = m â‹…k, then n = m.
18. If k, n, m âˆˆâ„•with n â‹…k < m â‹…k, then n < m.
19. If we write 1 for the minimum natural number, then if n, m âˆˆâ„•and n â‰¤
m â‰¤n + 1, then either m = n or m = n + 1.
20. If k, n, m âˆˆâ„•, then k â‹…(n + m) = k â‹…n + k â‹…m.
Now the fact is that some of these can be proved to be true using others on
the list. (We saw that the cancellation properties of multiplication follow from

22
2 The Algebra of the Natural Numbers
the uniqueness of multiplication and trichotomy.) So this is not the most con-
cise of deï¬nitions. However, this is a convenient list of algebraic properties of
â„•; so that is where we will start. Next, the set â„•itself is a set of natural numbers,
and property 1 says that it has at least one element. By property 3, â„•itself has
a minimum. We will call it 1. Thus, 1 âˆˆâ„•and if n âˆˆâ„•, then 1 â‰¤n. Thus, the
notation set in properties 15 and 19 is permanent.
We can use these properties to give direct proofs of many algebraic results.
As before,
Proposition 2.1.4.
If n âˆˆâ„•, then (n + 1)2 = n2 + 2n + 1.
Proof. Assume n âˆˆâ„•. Then
(n + 1)2 = (n + 1)(n + 1)
(2.1)
= n2 + n + n + 1
= n2 + 2n + 1.
â—½
This is called a direct proof because we started by assuming only that we
have a natural number and then performed a calculation that used the the basic
algebra that â„•has. As we have seen, not all proofs are direct. We have already
seen a proof that uses mathematical induction.
2.2
Mathematical induction
Mathematical induction is an important proof technique, and it is important
to clearly understand the logic of an induction proof.
In Chapter 1, we looked at a proof that for all natural numbers, 2
nâˆ‘
k=1
k =
n(n + 1). We proved this by induction. Let us revisit that proof.
Proposition 2.2.1.
For all natural numbers n, 2
nâˆ‘
k=1
k = n(n + 1)
Proof. We begin this proof with a base case.
Step 1, The base case. We claim that if n = 1, then 2
nâˆ‘
k=1
k = n(n + 1).
Proof of claim. Assume n = 1. Then
2
n
âˆ‘
k=1
k = 2(1) = 2.
(2.2)

2.2 Mathematical Induction
23
In addition,
n(n + 1) = 1(2) = 2.
(2.3)
So 2
nâˆ‘
k=1
k = n(n + 1). This completes step 1.
â—¾
Step 2, The induction step. We claim that
If for n = n0, 2
nâˆ‘
k=1
k = n(n + 1), then for n = n0 + 1, 2
nâˆ‘
k=1
k = n(n + 1).
Proof of claim. Assume that for n = n0, 2
nâˆ‘
k=1
k = n(n + 1). Then 2
n0âˆ‘
k=1
k
= n0(n0 + 1).
Consider 2
n0+1
âˆ‘
k=1
k.
2
n0+1
âˆ‘
k=1
k = 2
(( n0
âˆ‘
k=1
k
)
+ (n0 + 1)
)
(2.4)
= 2
( n0
âˆ‘
k=1
k
)
+ 2(n0 + 1)
= n0(n0 + 1) + 2(n0 + 1)
= (n0 + 2)(n0 + 1).
Next, consider n(n + 1) for n = n0 + 1. We get
n(n + 1) = (n0 + 1)(n0 + 1 + 1).
(2.5)
So 2
n0+1
âˆ‘
k=1
k = (n0 + 1)((n0 + 1) + 1). This completes step 2.
â—¾
By induction, we have proved that, for all n âˆˆâ„•, 2
nâˆ‘
k=1
k = n(n + 1). This
completes the proof.
â—½
We did not prove that the equation 2
nâˆ‘
k=1
k = n(n + 1) is true all by itself. We
could not; we do not even know what this equation means until we know what
n means.
In the aforementioned proof, the variable n took on four diï¬€erent meanings
before it was over: n = 1; n = n0, n = n0 + 1, and at the end, n stands for any
natural number.
We cannot prove a theorem until we know exactly what it says. Theorems
must, therefore, be in the form of an â€œifâ€¦thenâ€ sentence. Thus, we could prove
something like:
If n = 5, then 2
n
âˆ‘
k=1
k = n(n + 1).

24
2 The Algebra of the Natural Numbers
To do so, we assume n = 5. The left-hand side is 2
nâˆ‘
k=1
k = 2(1 + 2 + 3 +
4 + 5) = 30. The right-hand side is 5(5 + 1) = 30. They are the same. Notice
that we do not need to assume anything about k because it does not play a
role in the result. It is a â€œdummy variableâ€ that simply gives meaning to the
notation. Computer science calls this a â€œlocal variableâ€ to the notation. It only
has meaning within the calculation called for by the notation.
Then we can, and did, prove
For all n âˆˆâ„•, 2
n
âˆ‘
k=1
k = n(n + 1)
because the statement tells us what n stands for.
By the same token, we did not prove
2
n0
âˆ‘
k=1
k = n0(n0 + 1) or 2
n0+1
âˆ‘
k=1
k = (n0 + 1)(n0 + 2)
(2.6)
by themselves either. We did, however, prove
If 2
n0
âˆ‘
k=1
k = n0(n0 + 1),
then 2
n0+1
âˆ‘
k=1
k = (n0 + 1)((n0 + 1) + 1).
To do so, we assume that we have an n0 so that
2
n0
âˆ‘
k=1
k = n0(n0 + 1).
(2.7)
We have a valid reason for making this assumption. Because we are proving an
â€œifâ€¦thenâ€ statement, we are allowed to assume the â€œifâ€ part of the statement.
Once we begin to work under this assumption, we turn our attention to proving
the â€œthenâ€ part of the statement. At this point, we can prove
2
n0+1
âˆ‘
k=1
k = (n0 + 1)((n0 + 1) + 1)
(2.8)
by itself. Since we have assumed we know something about n0, this does have
meaning under that assumption. After this, it is just algebra: using what we
assume we know, to prove what we want.
2.2.1
The theorem of induction
The problem is that none of our basic properties say that a proof by induction
works. For that, we need to prove a theorem using those basic properties.

2.2 Mathematical Induction
25
Theorem 2.2.2
(The Theorem of Induction). Let P(n) be a statement that
is either true or false (but not both) for each n âˆˆâ„•. If the following statements
are true:
1. if n = 1, then P(n) is true, and
2. if for n = n0, P(n) is true, then for n = n0 + 1, P(n) is true,
then for all n âˆˆâ„•, P(n) is true.
Proof. Notice that the hypothesis of our â€œifâ€¦thenâ€ statement has two parts. So
we begin by the proof by making two assumptions: assume that
1. if n = 1, then P(n) is true;
and
2. if for n = n0, P(n) is true, then for n = n0 + 1, P(n) is true.
Comment: Our second assumption tells us that, if we ever ï¬nd a number n0 (no
matter its actual name) where P(n0) is true, then we will know that P(n0 + 1) is
true. This assumption does not give us an n0 where P(n0) is true; it just tells us
that we know something else if we ï¬nd one. We should be on the lookout for a
number that makes P(n) true.
Let A be the set of all counterexamples to the theorem. That is, A is a set of
all natural numbers k where P(k) is not true. In mathematical notation, we can
write this as follows:
A = {k âˆˆâ„•âˆ£P(k) is false}.
(2.9)
Comment: There is a name for the argument we use in this proof: a minimum
counterexample argument. As the name suggests, we construct a minimum
counterexample and then show that it cannot exist.
There are two possibilities for this set A: either it has an element or it does
not. We will see what each possibility means by considering cases.
Case 1: Assume by way of contradiction that A has an element.
Comment: Because we promise to consider the other case, this is a logically
valid assumption for this case. It will hold until the case is complete. It is a
valid assumption, but it is also an assumption we hope is a false statement. An
assumption is valid if there is a logical reason to make it. In a proof such as
this, we can make a valid assumption that we fully expect is a false statement.
We hope that making this assumption leads us to a logical contradiction. Once
that happens, we will be sure our assumption (in case 1) is false and that our
alternative assumption (in case 2) must be true.

26
2 The Algebra of the Natural Numbers
Since â„•is well ordered, this assumption tells us that A has a minimum. We
should name it; we call it m. Let us write down what this means:
â€¢ m âˆˆA.
â€¢ If x âˆˆA, then m â‰¤x.
Comment: This second fact about m says that, if we ever ï¬nd x âˆˆA, then we
will know m â‰¤x. But it also says that, if we ever ï¬nd an x where x < m, then
we will know x âˆ‰A. We now write this down.
â€¢ If x < m, then x âˆ‰A.
Comment: We should be on the lookout for a number that is less than m, so
we can use this.
We have accumulated a number of facts denoted by bullets. We now use these
facts to draw conclusions.
Our ï¬rst bullet point asserts that
m âˆˆA = {k âˆˆâ„•âˆ£P(k) is false}.
(2.10)
This tells us that m âˆˆâ„•and P(m) is false. Next, we recall that we have assumed
that P(1) is true. These two together tell us that m â‰ 1. But 1 is the minimum
natural number, so 1 â‰¤m, and we just discovered that m â‰ 1. By trichotomy,
we have 1 < m.
The subtraction property of â„•tells us that there is a s âˆˆâ„•so that m = s + 1.
(We call it s because we are already using k for something else.) Since the part
is less than the whole, s < m.
But wait â€“ our last bullet point tells us about this situation. Because s < m,
we know that
s âˆ‰A = {k âˆˆâ„•âˆ£P(k) is false}.
(2.11)
Since we know that s âˆˆâ„•, the reason s âˆ‰A must be that P(s) is not false. That
is to say, P(s) is true.
Recall now that we started this proof by making two assumptions. By our
second assumption, since P(s) is true, we must have that P(s + 1) is true.
However, s + 1 = m. So that means P(m) is true. But m âˆˆA, so we also
have P(m) is false. These two conclusions are logically incompatible; there is a
contradiction.
So, somewhere earlier we made an assumption that cannot be true. The last
assumption we made was the one that began this case: â€œAssume A has an ele-
ment.â€ So this case cannot actually occur. As hoped for, the valid assumption
we made to begin case 1 has turned out to be false. So it is not true that â€œA has
an element.â€

2.3 Division
27
Case 2: The only logical possibility is case 2: A has no elements. Because
we have eliminated the other possibility, this is a valid assumption, and we
now know that it must be true. It is time to recall what we are proving at this
moment. After our initial two assumptions, we need to prove
If n âˆˆâ„•, then P(n) is true.
We begin a proof of this particular â€œifâ€¦thenâ€ with another assumption:
Assume n âˆˆâ„•.
Then n âˆ‰A because nothing is. But n âˆˆâ„•and n âˆ‰{k âˆˆâ„•âˆ£P(k) is false}. So
P(n) is not false. Thus, P(n) is true.
We have proved that under assumptions 1 and 2 in the statement of the
theorem, P(n) must be true for all n âˆˆâ„•.
â—½
It is worth examining the logical outline of this proof. We start by assuming
the â€œifâ€ parts of our theorem. We create, for the purposes of the proof, a set of
counterexamples â€“ places where the ï¬nal conclusion is false. We identify two
possibilities, of which at least one must be true. At this point in the strict rules
of logic, either or both might be true. In this proof, though, we strongly suspect
that one is not. Since we cannot be logically sure which is true, we must consider
each possibility in its own case. In considering the ï¬rst possibility, it is valid to
assume that it is true even if we suspect that it is not. It is customary to warn
a reader of this by using the phrase â€œAssume by way of contradiction.â€ When
we reach a logical contradiction under this assumption, it tells us that this case
cannot actually occur. The assumption is not actually true. That leaves us with
the second possibility as the only one that could be true. Assuming that it is
true, we begin its case and ï¬nd that it leads to the ï¬nal conclusion we wanted.
Since that is the only logically consistent possibility, our theorem is proved.
2.3
Division
2.3.1
The division algorithm
Division in â„•is messy. If we try to divide a natural number by, say 7, several
things can happen. We might be lucky and get one natural number as an answer,
the quotient. For example, 7 goes into 28 exactly 4 times because 28 = 7 â‹…4. But
this might not work out exactly, and even though we can ï¬nd a quotient, it may
be that a remainder will be left over. Thus, 7 goes into 25 about 3 times with a
remainder of 4 because 25 = 7 â‹…3 + 4. But 7 goes into 64 exactly 9 times with
a remainder of 1 because 64 = 7 â‹…9 + 1. Remainders must be smaller than the
number we divide by to be a true remainder. Many a school child has gotten
tripped up by saying that 7 divides into 79 with a quotient of 10 and a remainder
of 9. If we are not careful, we will fall for our own version of this trap.

28
2 The Algebra of the Natural Numbers
We can describe this precisely:
Theorem 2.3.1
(The Division Algorithm for Natural Numbers). If n,
m âˆˆâ„•and n â‰¤m, then either
1. there is a q âˆˆâ„•so that m = n â‹…q, or
2. there are q, r âˆˆâ„•so that m = n â‹…q + r where r < n.
We will prove this using the tried and true method used by school children
everywhere; we will count with our ï¬ngers. To divide 7 into 39, we count by
7s keeping track of how many times we jump on our ï¬ngers. We start: 7, 14,
21, 28, 35, 42. We stop here because this is the ï¬rst time our number is greater
than 39. This was the 6-th number we hit; so the quotient we are looking for
is at count 5. That tells us that the quotient is 5; the remainder is easy to ï¬nd,
4. Thus, we check that 39 = 7 â‹…5 + 4 and be sure that 4 < 7. We know that the
remainder is correct because we had the patience to wait until our count by 7
passed out goal of 39 before we stopped. This is the idea of the proof, all we
need do is convert it to algebra. This is not hard once we realize that 6 was the
minimum number where 7 â‹…6 > 39.
Proof. Always start a proof of an â€œifâ€¦thenâ€ statement the same way, by
assuming all the statements between the â€œifâ€ and the â€œthen.â€
Assume n, m âˆˆâ„•. Assume n â‰¤m. Let
S = {k âˆˆâ„•âˆ£n â‹…k â‰¥m}.
(2.12)
Comment: We want S to have a minimum; so we need to ï¬nd a natural number
that is deï¬nitely in S. This requires a bit of thought, but an example or two might
lead us to a guess. Basically though, it must be a number we already have in the
proof.
Claim. m âˆˆS
Proof of claim. Since n âˆˆâ„•, we know that n â‰¥1. Because multiplication
respects order, m â‹…n â‰¥m â‹…1. So, indeed, m âˆˆâ„•and n â‹…m â‰¥m. So m âˆˆS. That
proves the claim.
â—¾
So by the claim, S is a set of natural numbers with at least one element. By
well ordering, S has a minimum.
Comment: Now we need to name the minimum. However, it would be a real mis-
take to call it m because we have already used that letter to mean something else.
Let p denote the minimum of S. Thus,
â€¢ p âˆˆS.
â€¢ If x âˆˆS, then p â‰¤x.

2.3 Division
29
As before, we can phrase this second fact as
â€¢ If x < p, then x âˆ‰S.
Now
p âˆˆS = {k âˆˆâ„•âˆ£n â‹…k â‰¥m}.
(2.13)
So we know that p âˆˆâ„•and n â‹…p â‰¥m. In a startlingly obvious, but easily over-
looked, observation, this means either n â‹…p > m or n â‹…p = m. This gives us two
cases to consider.
Case 1: Assume n â‹…p = m. Let q = p. Then m = n â‹…p = n â‹…q. Since q âˆˆâ„•and
m = n â‹…q, we have found a q that the ï¬rst possibility allowed in the theorem
does occur. So we have proved that the ï¬rst conclusion in our theorem can
occur. We have shown that under the assumption of case 1, there is a q âˆˆâ„•so
that m = n â‹…q. This ï¬nishes case 1.
Case 2: Assume n â‹…p > m.
Now p is still an element of S because we made this observation before we
began case 1. We assumed in the beginning that n â‹…1 = n â‰¤m, and we just
assumed that n â‹…p > m. So 1 â‰ p. This means 1 < p, and by our subtraction
rule, there is q âˆˆâ„•so that p = q + 1.
Since p = q + 1, we know that q < p, the minimum element of S. So
q âˆ‰S = {k âˆˆâ„•âˆ£n â‹…k â‰¥m}.
(2.14)
We now know that n â‹…q â‰¥m cannot be true. By trichotomy, we must have n â‹…
q < m. By the subtraction rule, there is an r âˆˆâ„•so that m = n â‹…q + r.
Comment: It may look like we are done, but we are not. We cannot forget that
the remainder must be the right size. That is, we still need to prove r < n.
We still have our assumption that n â‹…p > m. Thus,
m < n â‹…p = n â‹…(q + 1) = n â‹…q + n.
(2.15)
But we have carefully selected q and r so that m = n â‹…q + r. Since m < n â‹…q + n,
we must have
n â‹…q + r = m < n â‹…q + n.
(2.16)
But one of our basic assumptions is a cancellation rule; so, indeed, we have
r < n. Under the assumption of case 2, we have proved that there are q, r âˆˆâ„•
so that m = n â‹…q + r where r < n.
So assuming that n, m âˆˆâ„•and n â‰¤m, we have shown that one of two things
must happen: either there is a q âˆˆâ„•so that m = n â‹…q, or there are q, r âˆˆâ„•so
that m = n â‹…q + r where r < n. This completes the proof.
â—½
It is worth examining the logical outline of this proof as well. We are dividing
a smaller number into a larger number and looking for a quotient or a quotient

30
2 The Algebra of the Natural Numbers
and a remainder, theoretically. We start by assuming the â€œifâ€ parts of our
theorem. We create, for the purposes of the proof, a set of numbers too big
to be the quotient. This time we expect the set to have elements, but we must
actually demonstrate that it does. We cannot just assume that it does since we
have no valid reason to do so. Once we have an element, we know that the set
has a minimum. We identify two possibilities from the fact that n â‹…p â‰¥m, of
which at least one must be true. At this point, logically, either or both might
be true. Depending on the actual numbers n and m, either might indeed occur.
Since we cannot be sure which is true, we must consider each possibility in its
own case. It is valid to assume that one is true to begin case 1 because we have
made an implicit promise to consider the other case later. This assumption
leads to one of the two possibilities the theorem claims must hold. That
completes the proof in this case. That brings us to the second possibility. We
begin by assuming the alternative possibility to case 1 identiï¬ed earlier. This
leads to another possibility the theorem claimed might occur. Since the two
cases considered cover every possible way that n â‹…p â‰¥m and all those cases
led to a version of the conclusion we wanted, our theorem is proved.
2.3.2
Odds and evens
One of the ï¬rst things we learn to do with natural numbers is to distinguish the
odd ones from the even ones. The even numbers are those that can be divided
by 2 without a remainder, the odd ones are those that cannot. Every natural
number is either even or odd, and no number is both. We need to formalize
this with oï¬ƒcial mathematical deï¬nitions.
Deï¬nition 2.3.2.
A natural number n is even if there is k âˆˆâ„•such that
n = 2 â‹…k.
Because we said that this is the deï¬nition of an even number, we have actually
said that n is even if and only if there is a k âˆˆâ„•such that n = 2 â‹…k.
Deï¬nition 2.3.3.
A natural number n is odd if there is a k âˆˆâ„•such that
n = 2 â‹…k âˆ’1.
Anyone familiar with mathematics might ask, why 2 â‹…k âˆ’1 and not 2 â‹…k + 1?
But the reason is that we are temporarily conï¬ned to the natural numbers. Since
1 is a natural number that we want to be considered to be odd, we cannot
require that there be a natural number k where n = 2 â‹…k + 1. The number 1
would fail this requirement. This is a minor problem, but a deï¬nite irritation.
Still we must make it a point to memorize and use this oï¬ƒcial (and perfectly
correct deï¬nition) just in case it ever really matters.
A corollary is a theorem that follows directly from a theorem or the proof of
a theorem. We have one now. The following result is a corollary of the division
algorithm for the natural numbers.

2.3 Division
31
Corollary 2.3.4.
If n is a natural number, then n is either even or odd, but
never both.
Proof. The proof will have two steps. In step 1, we will prove that every natural
number is even or odd. In step 2, we will prove that no natural number is both
even and odd.
Step 1. We claim that if n is a natural number, then n is either even or odd.
Proof of claim. As always, assume n âˆˆâ„•. Then we have 1 â‰¤n; so either 1 = n
or 1 < n. We have two cases:
Case 1: Assume n = 1. Then let k = 1. Since n = 2 â‹…k âˆ’1, we know that n is
odd. This completes case 1.
Case 2: Assume 1 < n. Since â„•is discrete (remember this?), we have 2 â‰¤n.
By the division algorithm, either there is a q âˆˆâ„•so that m = 2 â‹…q or there are
q, r âˆˆâ„•so that m = 2 â‹…q + r where r < 2. Thus, we have two subcases.
Subcase 1: Assume that there is a q âˆˆâ„•so that m = 2 â‹…q. Then n is even, and
this subcase is complete.
Subcase 2: Assume that there are q, r âˆˆâ„•so that m = 2 â‹…q + r where r < 2.
Now r < 2 and â„•is discrete, so r â‰¤1. But 1 is still the minimum natural number.
So r = 1. Thus,
m = 2 â‹…q + r
(2.17)
= 2 â‹…q + 1
= 2 â‹…(q + 1) âˆ’1.
Thus, n is odd. This completes the subcase 2 and so the entire case.
So we have proved that n is either even or odd.
â—¾
Step 2. We claim that n cannot be both even and odd.
Comment: We should rephrase this as an â€œifâ€¦thenâ€¦â€ The typical way to
rephrase a claim that something cannot happen is as: â€œIf it does happen, then
thatâ€™s ridiculous.â€ So here we try to prove: If n is even and n is odd, then we can
ï¬nd a logical contradiction.
Proof draft. Assume that n is even. Assume that n is also odd.
Because n is even, there is a k âˆˆâ„•such that n = 2 â‹…k.
In addition, because n is odd, there is a k âˆˆâ„•such that n = 2 â‹…k âˆ’1.
Comment: Leaving this last statement as is would be a horrible mistake! We
have just used the same name for two things that we do not know are the same.
Naming new mathematical objects is a major responsibility, similar to naming
children. In a proof, the words â€œSo there is a numberâ€¦â€ should cause a momentâ€™s

32
2 The Algebra of the Natural Numbers
reï¬‚ection before assigning it a name. We should never use the same name twice
in a proof unless we ï¬rst prove that the two things are the same.
Here we used the assumption that n is even to say there is a k âˆˆâ„•such that
n = 2 â‹…k. This means that, in this proof, k stands for the one natural number
for which n = 2 â‹…k. This is word for word the deï¬nition of even. We could have
stated that deï¬nition just as well as â€œA natural number n is even if there is r âˆˆâ„•
such that n = 2 â‹…r.â€ The symbolic letter k is not an ï¬xed part of the deï¬nition.
After this, we move to n is odd. The deï¬nition of that is there is a k âˆˆâ„•such
that n = 2 â‹…k. However, we cannot simply copy this deï¬nition without taking
into account the context of our proof. The letter k is already been assigned to
stand for a ï¬xed natural number. So we need to adjust our application of the
deï¬nition to the context of our proof where the letter k is not available.
Let us start this step over.
Î”
Step 2. We claim that n cannot be both even and odd.
Proof of claim. Assume that n is even. Assume that n is also odd.
So there is a k âˆˆâ„•such that n = 2 â‹…k. In addition, there is a kâ€² âˆˆâ„•such that
n = 2 â‹…kâ€² âˆ’1.
Then 2k = 2kâ€² âˆ’1. Then 2kâ€² > 2k. And so kâ€² > k. By subtraction, there is
s âˆˆâ„•such that kâ€² = k + s. But recall that 2k = 2kâ€² âˆ’1; so 2kâ€² = 2k + 1. And
now we are in trouble. We also have
2kâ€² = 2(k + s)
(2.18)
= 2k + 2s
But s â‰¥1, so 2s â‰¥2 > 1. Thus,
2kâ€² = 2k + 2s > 2k + 1.
(2.19)
But this contradicts trichotomy, since we also have 2kâ€² = 2k + 1.
â—¾
To summarize, in Step 1, we proved that every natural number n is either
even or odd. In Step 2, we proved that no natural number n is both even and
odd. This completes the proof of our corollary.
â—½
There are few more theorems about odd and even natural numbers that we
need to state.
Theorem 2.3.5.
If n and m are even natural numbers, then n + m is even.
Theorem 2.3.6.
If n and m are odd natural numbers, then n + m is even.
Theorem 2.3.7.
If n and m are natural numbers with one odd and the other
even, then n + m is odd.

2.3 Division
33
Theorem 2.3.8.
If n and m natural numbers and one of them is even, then
n â‹…m is even.
Theorem 2.3.9.
If n and m are odd natural numbers, then n â‹…m is odd.
Theorem 2.3.10.
If n is a natural number and n2 is even, then n is even.
We will leave the proofs of the ï¬rst ï¬ve of these as exercises. We will prove the
last one though. Before we do, let us plan out our proof. As always, we will begin
making the allowed assumptions. Assume that n is a natural number. Assume
that n2 is even. Then there is a k âˆˆâ„•such that n2 = 2k. At this point, we are
a bit stymied. None of our basic properties say anything at all about taking a
square root or even any sort of â€œun-multiplying.â€ We can try to use the other
assumption, n âˆˆâ„•. After a bit of thought, we might use the aforementioned
corollary to divide the proof into cases. Since n âˆˆâ„•, we know either n is even
or n is odd. We can assume that n is odd and hope that it leads to a contradiction,
leaving only the possibility that n is even.
Proof. Assume that n is a natural number.
Assume that n2 is even. Then there is a k âˆˆâ„•such that n2 = 2k. Since n âˆˆâ„•,
the aforementioned corollary gives us two possibilities: n is even or n is odd.
Case 1: Assume that n is odd. Thus, there is r âˆˆâ„•so that n = 2r âˆ’1.
Then n2 = (2r âˆ’1)2 = 4r2 âˆ’4r + 1. But then 2k = 4r2 âˆ’4r + 1. So 2k + 4r =
4r2 + 1. Since 2k + 4r = 2(k + 2r) is even, 4r2 + 1 = 2(r2 + 1) âˆ’1 is odd. This
gives one number that is both odd and even, and that contradicts the corollary.
Case 1 cannot occur.
Case 2: It must be true that n is even. This completes the proof.
â—½
This proof works perfectly well, but we will give another version that might
be considered better. We will rewrite the statement we are proving in a rather
silly, but useful way. We want to prove that whenever n2 is even, it absolutely
must happen that n is also even. So this says, if we happened to know that n is
not even, then n2 cannot be even.
Proof. Assume that n is a natural number.
We will prove if n2 is even, then n is even, by proving
if n is odd, then n2 is odd.
Assume that n is odd. Then there is a k âˆˆâ„•so that n = 2k âˆ’1. Now
consider n2.
n2 = (2k âˆ’1)2
(2.20)
= 4k2 âˆ’4k + 1
= (4k2 âˆ’4k + 2) âˆ’1
= 2(2k2 + 1 âˆ’2k) âˆ’1.

34
2 The Algebra of the Natural Numbers
Now we make sure that (2k2 + 1 âˆ’2k) âˆˆâ„•by showing that the subtraction is
legal. We know that k â‰¥1. So 2k2 â‰¥2k. So 2k2 + 1 > 2k. So by the subtrac-
tion property of â„•, there is a natural number that is 2k2 + 1 âˆ’2k. So we have a
complete proof that n2 is odd.
â—½
In general, if we wish to prove a statement of the form â€œif P, then Q,â€ then
it suï¬ƒces to prove the contrapositive statement â€œif not Q, then not P.â€ Accord-
ingly, a successful proof using this technique is called a proof by contrapositive.
Notice how this worked in the previous proof. We wanted to prove â€œif n2 is
even, then n is even.â€ We did this by proving the contrapositive of that state-
ment, which is â€œif n is not even, then n2 is not even.â€ Or, more naturally, â€œif n is
odd, then n2 is odd.â€
2.4
Problems
2.1
Prove that for all n âˆˆâ„•,
nâˆ‘
k=1
2k + 3 = n2 + n + 3.
2.2
Prove that for all n âˆˆâ„•,
nâˆ‘
k=1
k3 =
( nâˆ‘
k=1
k
)2
.
2.3
Prove that for all n âˆˆâ„•,
nâˆ‘
k=2
1
k2âˆ’1 = 3n2âˆ’nâˆ’2
4n2+4n .
2.4
Prove that for all n, m âˆˆâ„•, with n < m,
mâˆ‘
k=n
k = (n+m)(mâˆ’n+1)
2
.
(a) Use the previously proved theorems.
(b) Use induction on m.
2.5
Prove the following statements.
(a) ( 1
9 + 1
10 + 1
11 + 1
12 + 1
13 + 1
14 + 1
15 + 1
16
) >
8
16. (Do this without actu-
ally adding the fractions.)
(b) For all n âˆˆâ„•,
(
1
2n+1 +
1
2n+2 +
1
2n+3 +
1
2n+4 + â€¦
1
2n+1
)
> 1
2.
(c) For all n âˆˆâ„•,
2n+1
âˆ‘
k=1
1
k > n
2.
2.6
Prove that for all natural numbers n large enough, n2 > n + 200. (Hint:
when trying to prove an inequality a < b, it can help to write the objec-
tive as a <? < b. Then the idea is to ï¬nd a value we can use in place of
the question mark. If we can prove the two inequalities a <? and ? < b,

2.4 Problems
35
the result we want follows from transitivity. If we are lucky, one of these
two inequalities is already known to be true.)
2.7
Look up an oï¬ƒcial mathematical deï¬nition of â€œfactorial.â€
(a) Prove that for all natural numbers n large enough, n! â‰¥n + 200.
(b) Prove that for all natural numbers n large enough, n! â‰¥2n.
2.8
Prove that the sum of two even natural numbers is even.
2.9
Prove that the product of two even natural numbers is even.
2.10
Prove that the sum of two odd natural numbers is even.
2.11
Prove that the product of two odd natural numbers is odd.
2.12
Prove that the product of any two consecutive natural numbers is even.
2.13
Prove that if n, m âˆˆâ„•and nm is even, then either n is even or m is even.
2.14
Prove the following: Let P(n) be a statement that is either true or false
(but not both) for each n âˆˆâ„•. Let m âˆˆâ„•. If the following two statements
hold: if n = m, then P(n) is true; and if for n = n0, P(n) is true, then for
n = n0 + 1, P(n) is true, then for all n âˆˆâ„•where n â‰¥m, P(n) is true.
2.15
Let n be any natural number greater than 7.
(a) Prove that if there is a natural number k so that n = 7 â‹…k, then there
is a number r so that n + 1 = 7 â‹…k + r with r < 7.
(b) Prove that if there is a natural number k so that n = 7 â‹…k + r with
r < 6, then there is a number râ€² so that n + 1 = 7 â‹…k + râ€² with râ€² < 7.
(c) Prove that if there is a natural number k so that n = 7 â‹…k + r with
r = 6, then there is a number kâ€² so that n + 1 = 7 â‹…kâ€².
(d) What happens to part (a) if instead of 7 we use 1?
2.16
Assume n, m âˆˆâ„•and n â‰¤m. Assume that n is a ï¬xed number. (Hint: it
could be ï¬xed at n = 1.)
(a) Prove that if m = n, then either there is a q âˆˆâ„•so that m = n â‹…q or
there are q, r âˆˆâ„•so that m = n â‹…q + r where r < n.
(b) Prove that if for m = m0, there is a q âˆˆâ„•so that m = n â‹…q, then for
m = m0 + 1, either there is a qâ€² âˆˆâ„•so that m = n â‹…qâ€² or there are
qâ€², râ€² âˆˆâ„•so that m = n â‹…qâ€² + râ€² where râ€² < n.
(c) Prove that if for m = m0, there are q, r âˆˆâ„•so that m = n â‹…q + r
with r < n, then for m = m0 + 1, either there is a qâ€² âˆˆâ„•so that
m = n â‹…qâ€² or there are qâ€², râ€² âˆˆâ„•so that m = n â‹…qâ€² + râ€² where râ€² < n.

36
2 The Algebra of the Natural Numbers
(Hint: you will need to use the fact that the natural numbers are
discrete to create two cases.)
(d) Use induction to prove the following statement.
If n, m âˆˆâ„•and n â‰¤m, then either there is a q âˆˆâ„•so that
m = n â‹…q or there are q, r âˆˆâ„•so that m = n â‹…q + r where
r < n.

37
3
Integers
3.1
The algebraic properties of â„•
One lesson we might take from the previous chapter is that not having 0 in the
natural numbers is a real inconvenience. There are those who support the idea
of simply declaring that 0 (an additive identity) belongs to the natural num-
bers. There is nothing wrong with that, but we will not follow that course. So
for now at least, the smallest natural number is 1. In some ways, this idea of
keeping 0 out of â„•makes sense. If you are going to add a zero for convenience,
why not move all in and include negative numbers as well. Now that would be
convenient.
That is exactly what we will do next when we deï¬ne integers. We will not
begin constructing the integers as we did in school. Now that we have algebra
and are looking at numbers through their algebraic properties, we will stick
with this approach. We will look at this from an algebraic point of view. We will
list out the algebraic properties we want, look at their implications, and then
construct a number system according to the results we ï¬nd.
We begin by looking at the basic properties of â„•. Our goal is to include an
additive identity and to include numbers that reverse addition. We will see what
we want to keep and what we want to replace as we add more numbers to the
mix. The properties of â„•are
1. There is an element of â„•.
This is a deï¬nite keeper, but because 0 is as useful a number as 1, we will
insist that the Integers have at least two elements.
2. There is an order on the natural numbers such that
(a) if k < m and m < n, then k < n;
(b) if n, m âˆˆâ„•, then exactly one of the following is true: n < m, m < n, or
n = m.
We should keep these as well. Together these tell us that our numbers will
line up, and we certainly want that.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

38
3 Integers
3. If S is a set of natural numbers with at least one element, then S has a min-
imum.
We would like to keep the well-ordering principle, but we cannot. We know
enough about the integers to know that there are sets of integers (such as
the negative ones) that have even smaller elements and no possibility of a
minimum. We can, however, salvage the idea by adding a condition that the
set has a lower bound. That will prevent the set in question from having too
many small numbers. This will, of course, require a careful deï¬nition of the
term â€œlower bound.â€
4. For any two natural numbers n and m, there is a unique natural number
n + m.
We deï¬nitely want an addition.
5. If k, n, m âˆˆâ„•, then k + (n + m) = (k + n) + m.
6. If n, m âˆˆâ„•, then n + m = m + n.
We should keep both of these so our addition in integers acts as addition
in the natural numbers.
7. If n, m âˆˆâ„•, then n < n + m.
We actually hope to lose this property if for no other reason than it will not
be true if m is an additive identity.
8. If k, n, m âˆˆâ„•and n < m, then n + k < m + k.
Yes, we want addition to continue to respect the order.
We consider the three cancellation properties as a package:
9. If n, m âˆˆâ„•with n < m, then there exists a unique natural number k so that
m = n + k.
10. If k, n, m âˆˆâ„•with n + k = m + k, then n = m.
11. If k, n, m âˆˆâ„•with n + k < m + k, then n < m.
These three are about subtraction, and we want to keep all three. But we
hope to replace them by inventing numbers that reverse addition. We will
add in one new property and use that property to prove these three as
theorems. We will introduce the notion of additive inverses. Whenever we
need to cancel, we will instead add an inverse. This way we can also continue
our pathological avoidance of subtracting.
12. For any two natural numbers n and m, there is a unique natural number
n â‹…m.
We want a multiplication.
13. If k, n, m âˆˆâ„•, then k â‹…(n â‹…m) = (k â‹…n) â‹…m.
14. If n, m âˆˆâ„•, then n â‹…m = m â‹…n.
We should keep both of these so our multiplication in integers acts as mul-
tiplication in natural numbers.
15. If 1 is the minimum natural number, then if n âˆˆâ„•, then 1 â‹…n = n â‹…1 = n.
We want to keep an identity, but we donâ€™t so much care if the identity is the
minimum of any particular set. If it turns out to be one, then good for it.
Otherwise, all we will ask for is that a multiplicative identity exists.

3.1 The Algebraic Properties of â„•
39
16. If k, n, m âˆˆâ„•with n < m, then n â‹…k < m â‹…k.
This looks like something to keep, but we know we need to be careful. We
cannot keep the general statement in integers, but we can keep the condi-
tion that k âˆˆâ„•and still have the conclusion.
17. If k, n, m âˆˆâ„•with n â‹…k = m â‹…k, then n = m.
18. If k, n, m âˆˆâ„•with n â‹…k < m â‹…k, then n < m.
We want to keep these, but the introduction of 0 gives us the opportunity
to replace both requirements with a simpler one. That is what we will do.
Slowly but surely, we are eliminating cancellation as an assumed property.
19. If n, m âˆˆâ„•, then n < m + 1 if and only if n â‰¤m.
20. If n, m âˆˆâ„•and n â‰¤m â‰¤n + 1, then either m = n or m = n + 1.
We want to keep both these. We will, but with the extra basic properties,
they will appear as theorems.
21. If k, n, m âˆˆâ„•, then k â‹…(n + m) + k â‹…n + k â‹…m.
Deï¬nitely something to keep.
We need a few deï¬nitions just to make the changes we need easier. First,
Deï¬nition 3.1.1.
The number z is an additive identity for a number system, if
for every number n in the system, n + z = z + n = n.
Deï¬nition 3.1.2.
The number u is an multiplicative identity for a number sys-
tem, if for every number n in the system, n â‹…u = u â‹…n = n.
Deï¬nition 3.1.3.
In a number system, we say b is an additive inverse of the
number a, if a + b = b + a is an additive identity.
Deï¬nition 3.1.4.
In an ordered number system, the number l is said to be a
lower bound on a set S when: if s âˆˆS, then l â‰¤s.
These may seem a bit strange, but the reason for the peculiar wording of
the ï¬rst three will become clear soon enough. A lower bound on a set is just
that, a number that is less or equal to every number in the set. It is a bound on
how small the numbers in the set actually are. The lower bound deï¬nition is
crafted to be in the most useful form possible. It would be perfectly reasonable
to require a lower bound to be deï¬nitely smaller than every element of the set,
but that would eventually make most mathematical arguments a bit longer than
necessary. Yet again, the best thing to do is memorize this deï¬nition as is, with
the promise that it will be an advantage later.
Some hint as to why a lower bound is the way it is comes from comparing it to
the deï¬nition of minimum. If m is the minimum of a set S, it is automatically a
lower bound. However, a lower bound is most probably not a minimum. To be
a minimum, the lower bound must be in the set. Once a set has a lower bound,

40
3 Integers
every number smaller than it is also a lower bound. Thus, most lower bounds
are not minimums. The upside of this is that if we need to prove that a set has
a lower bound (and we often will), there should be plenty to ï¬nd, and we need
not fear accidentally bumping into an actual minimum when we do identify
one.
In other words, a minimum of a set is always a lower bound for the set. A
lower bound on a set may or may not be a minimum of the set. A lower bound
is a minimum only when it is in the set. An element of the set is a minimum
exactly when it is also a lower bound of the set.
3.1.1
The algebraic deï¬nition of the integers
Deï¬nition 3.1.5.
The integers form a set â„¤with the following properties:
1. There is an order on â„¤that is transitive and has trichotomy.
2. If S is a set of integers with at least one element and at least one lower bound,
then S has a minimum.
3. If n, m âˆˆâ„¤, there is a unique integer n + m.
4. Addition is associative.
5. Addition is commutative.
6. There is an additive identity in â„¤.
7. If n âˆˆâ„¤, then n has an additive inverse.
8. If k, n, m âˆˆâ„¤and n < m, then n + k < m + k.
9. If n, m âˆˆâ„¤, there is a unique integer n â‹…m.
10. Multiplication is associative.
11. Multiplication is commutative.
12. There is an multiplicative identity in â„¤.
13. If k, n, m âˆˆâ„¤, n < m, and k is greater than an additive identity, then n â‹…k <
m â‹…k.
14. If k, n, m âˆˆâ„¤, then k â‹…(n + m) = k â‹…n + k â‹…m.
15. If n, m âˆˆâ„¤with nm equal to an additive identity, then one of n or m is equal
to an additive identity.
(We refer to this by saying â„¤has no divisors of 0.)
16. The additive identity and the multiplicative identity are not equal.
Notice that we require that the integers have an additive identity but not
require it be unique. That is because we can prove it is using the deï¬nition.
Theorem 3.1.6.
The additive identity of â„¤is unique.
Proof. We will prove: If 0 is an additive identity, and z is an additive identity,
then 0 = z.

3.1 The Algebraic Properties of â„•
41
Comment: The idea here is that to prove any statement, we rephrase it as an
â€œifâ€¦then.â€ There is a trick to this when the statement is that something is unique.
To prove that something is unique, prove â€œif we think we have two of them, then
they are actually equal.â€
So the proof begins:
Assume that 0 is an additive identity.
Assume that z is an additive identity.
Consider 0 + z.
Because 0 is an additive identity, 0 + z = z.
Because z is an additive identity, 0 + z = 0.
Because the sum of two integers is unique, 0 = z.
â—½
Proof technique. To prove that something is unique, we rephrase it into the
form: â€œIf we think we have two of them, then they are actually equal.â€
Now that we know that the additive identity is unique, we can assign it one
symbol and stick with it. We will write it as 0 because that is what everyone
else does.
Theorem 3.1.7.
The multiplicative identity of â„¤is unique.
The proof of this should be pretty clear; so we will not write it out. We will
write this multiplicative identity as 1.
Theorem 3.1.8.
If a âˆˆâ„¤, its additive inverse is unique to it.
Proof. We will prove: If b is an additive inverse of a, and c is an additive inverse
of a, then b = c.
Assume that b is an additive inverse of a.
Assume that c is an additive inverse of a.
Consider b + a + c.
b + a + c = (b + a) + c = 0 + c = c;
(3.1)
b + a + c = b + (a + c) = b + 0 = b.
So b = c.
â—½
The notation for the inverse is the minus sign. Thus, the additive inverse of a
is written as âˆ’a. A few words about this are in order. The symbol â€œâˆ’â€ is called
a minus sign. Unfortunately, it is used for three diï¬€erent (but closely related)
ideas in mathematics. As we have just seen, it is used as a symbol that means
â€œthe additive inverse of.â€ It is also a symbol for the term â€œnegative,â€ meaning a

42
3 Integers
number less than 0. Thus, consider the statement: â€œThe additive inverse 5 is âˆ’5.â€
There are two ways to read this: ï¬rst â€œThe additive inverse of ï¬ve is the additive
inverse of ï¬ve.â€ This reading is basically content-free. The other way is to read it
as â€œThe additive inverse of ï¬ve is the integer less than 0 named â€˜negative ï¬veâ€™.â€
At least that says something, if not something that is interesting.
It might seem from this example that the two interpretations â€œthe additive
inverse ofâ€ and â€œnegativeâ€ are completely interchangeable. They are not, and a
lot of mathematical confusion occurs when they are mixed. For example, âˆ’n
should be read as â€œthe additive inverse of n.â€ Since we do not know what n is,
we do not know if âˆ’n is positive or negative.
So, we need to be careful when mixing the words â€œnegativeâ€ and â€œminusâ€ as
if they always mean the same thing. It is a deï¬nite mistake to assume that the
additive inverse of an x is a negative number.
This mess is compounded by the fact that we also use the minus sign to denote
the arithmetic operation of subtraction. Thus, 7 âˆ’5 = 2 means â€œ7 minus 5 is
2.â€ Now 7 âˆ’(âˆ’5) = 12. This says that 7 minus the inverse of 5 is positive 12.
While 7 + (âˆ’5) = 2 says that 7 plus the inverse of 5 is 2. This is all bad enough
when it involves numbers; it can get very confusing when it involves variables.
So one trick when performing algebra is to avoid subtraction all together and
always read the minus sign as â€œthe additive inverse.â€ This is a good rule, but it is
overkill, and no one should follow it exclusively. But it is a good way to get out of
trouble. If we get confused about what some expression means, we should read
any minus sign as â€œthe additive inverse.â€ If we are looking for an algebraic error
in a calculation, we try the same trick. It would be silly to always write a âˆ’b
as a + (âˆ’b), but it can help catch a calculation error. If we ï¬nd it convenient
to write a + (âˆ’b), we should deï¬nitely take the time to include the parenthesis.
We never write this as â€œa + âˆ’b.â€ That is bad mathematical grammar.
3.1.2
Simple results about integers
Theorem 3.1.9.
If n âˆˆâ„¤, then n â‹…0 = 0 â‹…n = 0.
Proof. Assume n âˆˆâ„¤. There is not much we can do with this assumption. It
helps to know what to consider. Consider n + n â‹…0.
n + n â‹…0 = n â‹…1 + n â‹…0
(3.2)
= n â‹…(1 + 0)
= n â‹…1
= n.
Now
n + n â‹…0 = n.
(3.3)

3.1 The Algebraic Properties of â„•
43
We can add the additive inverse of n to both sides. (Heaven forbid we ever would
subtract.) Then
(âˆ’n) + n + n â‹…0 = (âˆ’n) + n.
(3.4)
0 + n â‹…0 = 0.
n â‹…0 = 0.
â—½
Theorem 3.1.10.
If a, b âˆˆâ„¤, then
1. âˆ’(âˆ’a) = a;
2. âˆ’a = (âˆ’1) â‹…a;
3. âˆ’(a + b) = (âˆ’a) + (âˆ’b);
4. âˆ’(a â‹…b) = (âˆ’a) â‹…b = a â‹…(âˆ’b).
Proof. This is really four theorems written as one. Each deserves its own proof.
However, each one makes the later ones easier. The trick is to read what they say.
Number 1 says, â€œThe additive inverse of the additive inverse of a is a.â€ To
prove that the additive inverse of something is something else, we add them and
see if the result is zero. If it is, since additive inverses are unique, that clinches it.
Consider a + (âˆ’a). Clearly, a + (âˆ’a) = 0. So a acts as the inverse of the inte-
ger âˆ’a. It is the inverse of âˆ’a. Thus, in notation, âˆ’(âˆ’a) = a.
Number 2 says, â€œThe additive inverse of a is given by the formula (âˆ’1) â‹…a.â€
Of course, âˆ’1 is the additive inverse of 1. We need to see if the formula works.
Consider a + (âˆ’1) â‹…a.
a + (âˆ’1) â‹…a = 1 â‹…a + (âˆ’1) â‹…a
(3.5)
= (1 + (âˆ’1)) â‹…a
= 0 â‹…a
= 0.
Thus, (âˆ’1) â‹…a acts as the inverse of a. Notice that we needed the previous
theorem about multiplication by 0.
Number 3 is just the distributive property now that number 2 is proved.
Number 4 also follows from number 2 and the associative and commutative
properties of multiplication.
â—½
Theorem 3.1.11.
If k, n, m âˆˆâ„¤with n < m and k < 0, then k â‹…n > k â‹…m.
Proof. This is the classical observation that multiplying an inequality by a nega-
tive number reverses the direction of the inequality. As we have seen, in algebra,
it is often diï¬ƒcult to tell if something is positive or negative. This theorem has
caused many an algebra studentâ€™s heart to break.

44
3 Integers
Assume k, n, m âˆˆâ„¤.
Assume n < m.
Assume k < 0.
We will add the additive inverse of k to both sides of this last inequality. Thus,
0 < âˆ’k. Now âˆ’k is an integer, and no matter what it looks like, it is positive.
Multiplication by positive numbers in â„¤preserves the order. Thus, we can mul-
tiply n < m by (âˆ’k) and get (âˆ’k) â‹…n < (âˆ’k) â‹…m. From the last theorem, we have
âˆ’(k â‹…n) < âˆ’(k â‹…m). Finally, we add (k â‹…n + k â‹…m) to both sides of this.
(k â‹…n + k â‹…m) âˆ’(k â‹…n) < (k â‹…n + k â‹…m) âˆ’(k â‹…m).
(3.6)
(k â‹…n âˆ’k â‹…n) + (k â‹…m) < k â‹…n + (k â‹…m âˆ’k â‹…m).
0 + k â‹…m < k â‹…n + 0.
k â‹…m < k â‹…n.
Sure enough, the direction has reversed.
â—½
Corollary 3.1.12.
If n âˆˆâ„¤and n â‰ 0, then n2 > 0.
Proof. Assume n âˆˆâ„¤and n â‰ 0. By trichotomy, either n > 0 or n < 0. That
gives us two cases:
Case 1: Assume n > 0. Since n > 0, we can multiply both sides of any
inequality by n. So n â‹…n > n â‹…0. So n2 > 0.
Case 2: Assume n < 0. Since n < 0, we can multiply both sides of any
inequality by n as long as we reverse the direction of the inequality. So
n â‹…n > n â‹…0. So n2 > 0.
In all possible cases, n2 > 0.
â—½
Corollary 3.1.13.
In â„¤, 1 > 0.
Proof. Since 12 = 1 and 1 â‰ 0, this follows immediately from the last
result.
â—½
Now we promised that several of the properties of â„•that we wanted to keep
but dropped from the list of properties of â„¤would not be gone for long. Here
are four of them stated as theorems.
Theorem 3.1.14.
If k, n, m âˆˆâ„¤with n + k = m + k, then n = m.
Theorem 3.1.15.
If k, n, m âˆˆâ„¤with n + k < m + k, then n < m.
Both of these can be proved by assuming the â€œifâ€ and adding the additive
inverse of k to both sides of that assumption.

3.1 The Algebraic Properties of â„•
45
Theorem 3.1.16.
If k, n, m âˆˆâ„¤with n â‹…k = m â‹…k, then if k â‰ 0, then n = m.
Proof. Assume k, n, m âˆˆâ„¤.
Assume n â‹…k = m â‹…k.
Assume k â‰ 0.
Now n â‹…k = m â‹…k implies n â‹…k âˆ’m â‹…k = 0. So (n âˆ’m) â‹…k = 0. But there are
no 0-divisors in â„¤. So either (n âˆ’m) = 0 or k = 0. But our assumption says that
it is not k. So n âˆ’m = 0, and thus, n = m.
â—½
Theorem 3.1.17.
If k, n, m âˆˆâ„¤with n â‹…k < m â‹…k, then if k > 0, then n < m.
Proof. Assume k, n, m âˆˆâ„¤.
Assume nk < mk.
Assume k > 0.
By trichotomy, there are three possibilities: n < m, m < n, or n = m.
Case 1: Assume m < n. Since k > 0 and multiplication by positive integers
preserves order, this would mean that mk < nk. But we assumed that nk < mk.
So we have ruled out this possibility.
Case 2: Assume m = n. This would mean that mk = nk. But we assumed that
nk < mk. So we have ruled out this possibility as well.
One of the three cases must occur; so case 3 must be true: n < m.
â—½
3.1.3
The relationship between â„•and â„¤
The only property of â„¤left to prove is that it is discrete. We will prove: n <
m + 1 if and only if n â‰¤m. But before we do this, we need to discuss property
2 in terms of the deï¬nition of the integers. It says
If S is a set of integers with at least one element and at least one lower
bound, then S has a minimum.
To be oï¬ƒcially called a well-ordered set, every nonempty set should have a
minimum. The extra condition requiring the set have at least one lower bound
means we cannot say â„¤is well ordered. The set of even integers has at least
one element, but it has no minimum element. Even if we cannot say that â„¤is
well-ordering, property 2 tells us that it is close. This is just a matter of seman-
tics. Mathematicians say â„•is well ordered and â„¤is not well ordered. In math-
ematics, deï¬nitions are precise; so once a deï¬nition is made oï¬ƒcial, we must
use the term exactly as the deï¬nition says.
Now â„¤is not well ordered; still property 2 is almost as useful as the
well-ordering principle of â„•. It has most of the same power as that of well
ordering, and all it is missing is an oï¬ƒcial name. We will use it in the proof
of a lemma. (A lemma is a theorem that makes the proof of a larger theorem
easier.)

46
3 Integers
Lemma 3.1.18.
If A = {k âˆˆâ„¤âˆ£k > 0}, then 1 is the minimum of A.
Proof. Assume
A = {k âˆˆâ„¤âˆ£k > 0}.
(3.7)
By a previous result, 1 âˆˆA. So A has at least one element.
By its deï¬nition, if k âˆˆA, then we know that k â‰¥0. So 0 is a lower bound
of A.
In â„¤this is enough to guarantee that A has a minimum. Call it m. It is a good
idea to spell out what this means using the oï¬ƒcial deï¬nition of minimum. Then
â€¢ m âˆˆA;
â€¢ if x âˆˆA, then m â‰¤x.
Now m âˆˆA = {k âˆˆâ„¤âˆ£k > 0}. So m > 0.
Since 1 âˆˆA, we know that m â‰¤1. Combining these using transitivity, we can
write 0 < m â‰¤1.
Because m > 0, we can multiply all sides of any inequalities by it. Thus,
m â‹…0 < m â‹…m â‰¤m â‹…1. So we have 0 < m2 â‰¤m. Since m2 > 0, we know that
m2 âˆˆA. But m is the minimum of A; so this tells us m â‰¤m2. By transitivity,
m â‰¤m2 â‰¤m. By trichotomy, this can only happen if m = m2.
Now m = m2 implies that 0 = m2 âˆ’m = m(m âˆ’1). Since there are no
0-divisors and m > 0, we must have m âˆ’1 = 0. So we have shown that 1 = m,
the minimum of A.
â—½
Theorem 3.1.19.
Let n, m âˆˆâ„¤. Then n < m + 1 if and only if n â‰¤m.
Proof. This is actually two theorems stated as one.
1. If n < m + 1, then n â‰¤m.
2. If n â‰¤m, then n < m + 1.
Part 1. Claim: If n < m + 1, then n â‰¤m.
Comment: Another way of saying â€œIf n < m + 1, then n â‰¤mâ€ is as â€œIf n â‰¤m is
not true, then n < m + 1 is not true.â€ So we will prove that if m < n is true, then
m + 1 â‰¤n. We begin the proof by assuming the â€œif.â€
Proof of claim. Assume m < n. Then 0 < n âˆ’m. Let A = {k âˆˆâ„¤âˆ£k > 0}.
Thus, n âˆ’m âˆˆA. By the previous lemma, 1 is the minimum of the set A. So
1 â‰¤n âˆ’m. So m + 1 â‰¤n.
â—¾
Part 2. Claim: If n â‰¤m, then n < m + 1.

3.2 Problems
47
Proof of claim. Assume n â‰¤m. We know that 0 < 1. So m + 0 < m + 1. Thus,
n â‰¤m < m + 1. By transitivity, n < m + 1.
â—¾
We have now proved both parts and therefore completed the proof of the
theorem.
â—½
Theorem 3.1.20.
Let A = {k âˆˆâ„¤âˆ£k > 0}. Then A has all the properties of the
natural numbers.
We leave the proof of this as an exercise. It is quite long, since it requires
proving that A has 20 diï¬€erent properties, and each requires a proof. It is not
actually that diï¬ƒcult to go through the list, though. Many of the properties that
need to be proved are part of the deï¬nition of â„¤, and the others have just been
proved as theorems. There are a few technical matters concerning where the
numbers actually come from, but with a little care, they go away.
3.2
Problems
3.1
Give an example of a set of integers with at least one element but no
minimum.
3.2
Prove that 5 is a lower bound of the set A = {m âˆˆâ„¤âˆ£there is
n âˆˆâ„¤with m = 2n2 âˆ’8n + 6}. (No Calculus allowed.)
3.3
Consider A = {m âˆˆâ„¤âˆ£m > 17}.
(a) Is 17 a lower bound of A?
(b) Is 12 a lower bound of A?
(c) Is 20 a lower bound of A?
(d) Is 17 a minimum of A?
(e) Is 12 a minimum of A?
(f) Is 20 a minimum of A?
(g) Is 18 a lower bound of A?
(h) Is 18 a minimum of A?
3.4
Prove that if n âˆˆâ„¤, then n â‹…0 = 0 â‹…n = 0.
3.5
Prove that if S is a set of integers and m is a lower bound of S, then if
n < m, then n is also a lower bound of S.
3.6
Prove that if n âˆˆâ„¤, then âˆ’n = (âˆ’1) â‹…n.
3.7
Prove that every set of natural numbers has a lower bound in â„¤.

48
3 Integers
3.8
Prove that if n, m âˆˆâ„¤with m â‰¤n â‰¤m + 1 then either m = n or
n = m + 1.
3.9
Prove that if k, n, m âˆˆâ„¤with n + k < m + k, then n < m.
3.10
Let a, b âˆˆâ„¤. Prove that if a â‰ b, then ab â‰ 1.
3.11
Let A and B be sets of integers so that every element of A is also an ele-
ment of B. Let r, s âˆˆâ„¤with r < s. Are the following true or false?
(a) If r is a lower bound on A, then s is a lower bound on A.
(b) If s is a lower bound on A, then r is a lower bound on A.
(c) If r is a lower bound on A, then s is a lower bound on B.
(d) If s is a lower bound on A, then r is a lower bound on B.
(e) If r is a lower bound on B, then s is a lower bound on A.
(f) If s is a lower bound on B, then r is a lower bound on A.
3.12
Let A be a set of integers and m âˆˆâ„¤. Deï¬ne the terms:
(a) m is a maximum of A.
(b) m is an upper bound on A.
3.13
Carefully state the division algorithm for integers. (Remember, you can-
not divide by zero, but you can divide by anything else. In addition, there
is only one case now that zero is a number. Finally, remainders should be
positive no matter what you divide by.)
3.14
Prove that for all n, m âˆˆâ„¤with n < m,
mâˆ‘
k=n
k = (n+m)(mâˆ’n+1)
2
.
3.15
Deï¬ne the terms â€œoddâ€ and â€œevenâ€ for integers and prove that your def-
initions give the same results as the oï¬ƒcial deï¬nitions of odd and even
natural numbers when applied to the positive integers. (The amount of
work this proof takes depends on the deï¬nition you choose.)
3.16
Let a âˆˆâ„¤. Prove that if a > 1, then for all n âˆˆâ„•with n > 1, a < an.
3.17
Explain why the last property of â„¤(that the additive identity and the
multiplicative identity are not equal) is necessary.

49
4
Rational Numbers
4.1
The algebra
Neither of the number systems â„•nor â„¤have good division properties. The
natural numbers have a theorem about division that in retrospect is rather com-
plicated. We can also state a division algorithm for the integers that is just a bit
simpler. We will not bother to prove it though.
Theorem 4.1.1.
If n, m âˆˆâ„¤and n â‰ 0, then there exists q, r âˆˆâ„¤such that
m = n â‹…q + r, where 0 â‰¤r < |n|.
Technically, to be an arithmetic operation, two numbers should go in, but
only one number should come out. Thus, division in â„¤is not an arithmetic
operation. We need to solve this problem by adding more numbers to the mix.
However, just as we did with subtraction, we are not going to introduce divi-
sion as an arithmetic operation. Rather we are going to introduce multiplicative
inverses.
4.1.1
Surveying the algebraic properties of â„¤
We start oï¬€by examining the algebraic properties we want to keep as we expand
our number system. We identify the ones we want to keep, and look for ways
to use one property about multiplicative inverses to replace as many other as
possible. Recall the properties of the integers:
â€¢ There is an order that is transitive and has trichotomy.
We like this, so letâ€™s keep it.
â€¢ If S is a set of integers with at least one element and at least one lower bound,
then S has a minimum.
We like this, and we want to keep it or some weaker version of it. The eventual
replacement will not be very natural at ï¬rst. For right now, we have to leave
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

50
4 Rational Numbers
this property out of our algebra. As we go forward we will look at this issue
very closely.
â€¢ If n, m âˆˆâ„¤, there is a unique integer n + m.
â€¢ Addition is associative.
â€¢ Addition is commutative.
â€¢ There is an additive identity in â„¤.
â€¢ If n âˆˆâ„¤, then n has an additive inverse.
â€¢ If k, n, m âˆˆâ„¤and n < m, then n + k < m + k.
All of these need to stay. We know that by keeping them, we will automati-
cally have a unique identity that we will call 0 and unique additive inverses
that we denote with minus signs.
â€¢ If n, m âˆˆâ„¤, there is a unique integer n â‹…m.
â€¢ Multiplication is associative.
â€¢ Multiplication is commutative.
â€¢ There is a multiplicative identity in â„¤.
â€¢ If k, n, m âˆˆâ„¤and n < m and 0 < k, then n â‹…k < m â‹…k.
All of these need to stay, but we know that by keeping them, we will
automatically have a unique multiplicative identity we will call 1.
â€¢ If k, n, m âˆˆâ„¤, then k â‹…(n + m) = k â‹…n + k â‹…m.
Deï¬nitely keep this. Distribution is the property that produces the most
useful consequences.
â€¢ If n, m âˆˆâ„¤with nm = 0, then either n = 0 or m = 0.
We can drop this, because we will not need it once we have division.
â€¢ 0 â‰ 1.
We keep this to make sure that we have an interesting collection of numbers.
4.1.2
Deï¬ning an ordered ï¬eld
To get to division, we need to only add one property that gives us multiplicative
inverses. Of course, ï¬rst, we make this oï¬ƒcial with
Deï¬nition 4.1.2.
We say b is a multiplicative inverse of a when a â‹…b =
b â‹…a = 1.
We want to have at least two numbers, so we assume 0 â‰ 1. We have seen
how the aforementioned properties lead us to conclude that for all numbers
x, x â‹…0 = 0 â‹…x = 0. Thus, the additive identity cannot have a multiplicative
inverse. We need to leave this number out of any property requiring inverses.
This is all we need to state our next deï¬nition.
Deï¬nition 4.1.3.
An ordered ï¬eld is a set F that has the following properties:
1. There is an order on F that is transitive and has trichotomy.
2. If a, b âˆˆF, then there is a unique a + b âˆˆF.

4.1 The Algebra
51
3. Addition is associative.
4. Addition is commutative.
5. There is an additive identity in F. (We know that we can prove it to be unique,
and we will call it 0.)
6. If a âˆˆF, then a has an additive inverse. (We know that we can prove it to be
unique to a, and we will call it âˆ’a.)
7. If a, b, c âˆˆF and a < b, then a + c < b + c.
8. If a, b âˆˆF, there is a unique a â‹…b âˆˆF.
9. Multiplication is associative.
10. Multiplication is commutative.
11. There is a multiplicative identity in F. (We know that we can prove it to be
unique, and we will call it 1.)
12. If a âˆˆF and a â‰ 0, then a has a multiplicative inverse. (We can prove it to
be unique to a, and we will call it aâˆ’1.)
13. If a, b, c âˆˆF and a < b and 0 < c, then a â‹…c < b â‹…c.
14. If a, b, c âˆˆF, then a â‹…(b + c) = a â‹…b + a â‹…c.
15. 0 â‰ 1.
This is the same process we used in the previous chapter, and it led us to
one new system of numbers: the integers. We might have been expecting that
our next set of numbers would be the rational numbers, and we might expect
that this list of algebraic properties would give us exactly those. Unfortunately,
without any substitute for well ordering, this does not happen. As we will see,
there are plenty of number systems that have all these algebraic properties. The
rational numbers form just one example of an ordered ï¬eld. The real numbers
will be another example. The impact of the loss of an adequate replacement
for well ordering has been greater than expected. Adding algebraic properties
alone does not nail down the next number system as uniquely as we might want.
This is where the mathematical subject called â€œAnalysisâ€ will play an important
role. We will need to deal with this missing â€œminimum propertyâ€ before we have
a single ï¬nal system of numbers, the real numbers. For now we will investigate
the algebraic properties of ordered ï¬elds and only later add an extra property
to get us to our ï¬nal goal of real numbers.
4.1.3
Properties of ordered ï¬elds
There are a lot of housekeeping theorems that we can prove using these prop-
erties. The results are as follows: identities are unique, additive inverses are
unique, and the algebra of minus signs. But since the proofs are the same as
those for the integers, we will not bother to even state them. Still we will do
some of this housekeeping:
Theorem 4.1.4.
If a âˆˆF is an ordered ï¬eld, and a â‰ 0, then the multiplicative
inverse of a is unique.

52
4 Rational Numbers
Proof. To prove that something is unique, we prove that if we assume that there
are two, then they are actually the same. So we will prove: if b and c are multi-
plicative inverses of a, then b = c. Consider b â‹…a â‹…c.
b â‹…a â‹…c = (b â‹…a) â‹…c = 1 â‹…c = c;
(4.1)
b â‹…a â‹…c = b â‹…(a â‹…c) = b â‹…1 = b.
So c = b.
â—½
Now we can deï¬ne some notation. We will write the multiplicative inverse of
a as aâˆ’1. (We can also write it as 1
a, but let us not for now.)
Theorem 4.1.5.
Let F be an ordered ï¬eld. If a, b âˆˆF, a â‰ 0, and b â‰ 0, then
1. (aâˆ’1)âˆ’1 = a;
2. (a â‹…b)âˆ’1 = (bâˆ’1) â‹…(aâˆ’1);
3. (âˆ’a)âˆ’1 = âˆ’(aâˆ’1).
All three proofs are left as exercises.
If n is a natural number and F is an ordered ï¬eld, none of these properties
tell us that n âˆˆF. However, if n is a natural number, we can use it to count the
elements of F. Let us use the notation
nâˆ‘
k=1
1 to mean the sum of the multiplicative
identity in F added to itself n times. Then consider the set
N =
{ n
âˆ‘
k=1
1 | n âˆˆâ„•
}
.
(4.2)
This is a set made up of elements from the ordered ï¬eld F.
Theorem 4.1.6.
Let F be an ordered ï¬eld. If
N =
{ n
âˆ‘
k=1
1 | n âˆˆâ„•
}
,
(4.3)
then N has all the properties of the natural numbers.
We will not go through the entire proof of this. That proof would look a lot
like what we saw in Chapter 1. The main diï¬€erence is that the ellipses can all be
replaced by âˆ‘. The question as to whether this makes this proof even slightly
more rigorous is a matter of opinion. But let us just accept the theorem as
deï¬nitely proved.
Since any set that has all the properties of â„•is basically a copy of â„•, we see
that every ordered ï¬eld F contains a copy of the natural numbers. We will say
that any ordered ï¬eld actually contains the natural numbers. (A mathemati-
cian would say we identify the subset N â€“ which is a copy of â„•â€“ with the

4.2 Fractions Versus Rational Numbers
53
actual set â„•.) Next in the ordered ï¬eld F, there is an additive identity, and every
element has an additive inverse. So every element of N = â„•has an additive
inverse. Let
Nâˆ’= {a âˆˆF | âˆ’a âˆˆN}.
(4.4)
So N âˆª{0} âˆªNâˆ’is a set of numbers in F. This is a copy of â„¤, and so we can
identify this set in F as â„¤itself. Every ordered ï¬eld F contains the integers.
(Again, this is because we identify the actual subset N âˆª{0} âˆªNâˆ’with the
integers â„¤.)
Now is the time to use our other notation for the multiplicative inverse. If
n âˆˆâ„•is considered as an element of the ordered ï¬eld F, then nâˆ’1 âˆˆF. If n âˆˆâ„•
and m âˆˆâ„¤are considered as elements of the ordered ï¬eld F, then m â‹…nâˆ’1 âˆˆF.
So we can deï¬ne a set
Q = {m â‹…nâˆ’1 âˆˆF | m âˆˆâ„¤and n âˆˆâ„•}.
(4.5)
We might recognize Q as a set of rational numbers. But we donâ€™t actually have
the rational numbers just yet, nor do we have an ordered ï¬eld. At this point,
we only know what properties we want an ordered ï¬eld to have, but we donâ€™t
actually have an example of one yet. We have found a subset of any ordered ï¬eld
that gives us a clue to ï¬nding an example of one for certain. Just as we did with
the integers, we will use the properties of Q to help us construct the rational
numbers we need.
4.2
Fractions versus rational numbers
4.2.1
In some ways they are diï¬€erent
We want to create the rational numbers independently. To do this, we need to
look at the rational numbers very carefully. Before we do, one of the authors of
this book would like to relay the story of a tragic incident he experienced as a
child. The experience was so traumatic that it set him oï¬€on a lifetime quest.
When I was in about the 4th grade, I was taught the ï¬rst basic ideas about
fractions. The fraction 3
5 meant that I should take a whole and divide it
into 5 equal pieces. To get 3
5, I should set aside 3 of those pieces. This
made perfect sense, and I enjoyed ï¬nding the meaning of many other
fractions.
Now this was the olden days when parents were involved in their
childrenâ€™s education. One of the students had a birthday on one of the
class days, and the studentâ€™s parents baked birthday cookies for the
class. These were naÃ¯ve times, and instead of declaring an emergency
and calling in a hazmat team to dispose of the cookies, the teacher just
gave them out. There were not enough cookies to be given to every

54
4 Rational Numbers
child, but the cookies were large and each child could have 1
2 of a cookie.
I was happy, because I knew exactly what that meant.
But that happiness turned to horror when I realized that my cookie
had been given to Bruce Moyer, the class bully. Bruce had been through
this grade twice before and considered himself very knowledgeable
about all things fractional. So Bruce immediately mashed up our cookie
into 2000 tiny crumbs and dumped â€“ what he said was â€“ 1000 of them
onto my desk. After all, as he defended himself later, everyone knows
that 1000
2000 = 1
2.
That was not how I understood fractions. My share of the cookie was
most deï¬nitely not 1
2: one of two equal-sized pieces. Sure I would later
learn that, as rational numbers, 1000
2000 and 1
2 were the same. That did not
make my crumbled cookie any more palatable. I never have and never
will accept that 1000
2000 and 1
2 are the same fraction. I will admit that they
are the same rational number, but not at all the same fraction. I vowed
from that moment on that I would forever insist that â€œFractions are not
numbers.â€ Unfortunately, I have yet to convince many other people to go
along with this.
In the next few pages, we need to heed the warning that fractions should not
automatically be considered numbers. Unfortunately, in standard mathemat-
ical notation, they are written exactly the same way. In the next few pages, we
will ignore this standard and use diï¬€erent notation for fractions and rational
numbers. When we write
m
n , the double bar will tell us that we mean it is a
fraction. If we write the usual m
n , the single bar will tell us that it is meant as
a rational number. Thus,
1000
2000 â‰ 
1
2, because the only way fractions are equal
is if they have the same numerator and the same denominator. On the other
hand, 1000
2000 = 1
2 because as rational numbers these are the same. In either case
though, m must be an integer and n must be a natural number.
Now if fractions are to be numbers, they should have all the properties that we
want numbers to have. We should be able to compare them in order, we should
be able to add them, and we should be able to multiply them. Since these are not
oï¬ƒcial mathematical deï¬nitions yet, we will not identify them as deï¬nitions at
all. We look to the order, addition, and multiplication on the set
Q = {m â‹…nâˆ’1 âˆˆF | m âˆˆâ„¤and n âˆˆâ„•}.
(4.6)
in an ordered ï¬eld F to guide us to the following deï¬nitions.
â€¢ The inequality of fractions
m
n <
p
q means
mq < np as integers,
(4.7)

4.2 Fractions Versus Rational Numbers
55
or
mq = np and n < q.
(4.8)
â€¢ If
m
n and
p
q are fractions, then the sum is given by the formula
m
n +
p
q =
mq + np
nq
.
(4.9)
â€¢ If
m
n and
p
q are fractions, then the product is given by the formula
m
n â‹…
p
q =
mp
nq .
(4.10)
We should now go through all 16 of the properties of an ordered ï¬eld to see
if those properties hold using these deï¬nitions. We will just hit a few highlights
since we are interested in studying numbers more than studying mere fractions.
â€¢ The order is transitive, and that is not diï¬ƒcult to check. It also has
trichotomy because of the extra â€œorâ€ condition in the deï¬nition of â€œless
than.â€ That condition also makes the fractions as almost well ordered as the
integers.
â€¢ Addition is associative.
m
n +
(p
q +
s
t
)
=
m
n +
(pt + qs
qt
)
(4.11)
=
mqt + n(pt + qs)
nqt
=
mqt + npt + nqs
nqt
.
We get this by using the formula as written and using the distributive
property of â„¤. On the other hand,
(m
n +
p
q
)
+
s
t =
mq + np
nq
+
s
t
(4.12)
=
(mq + np)t + nqs
nq
=
mqt + npt + nqs
nqt
.
Since the numerators and denominators are exactly the same, the fractions
are equal.
m
n +
(p
q +
s
t
)
=
(m
n +
p
q
)
+
s
t .
(4.13)

56
4 Rational Numbers
â€¢ The fraction
0
1 is an additive identity.
0
1 +
m
n =
0 â‹…n + 1 â‹…m
1 â‹…n
=
m
n .
(4.14)
â€¢ The fraction
1
1 is a multiplicative identity.
These high points, however, are just postponing the inevitable. The arithmetic
of fractions is simply not distributive. Consider the following calculations:
m
n â‹…
(p
q +
s
t
)
=
m
n â‹…
(pt + qs
qt
)
(4.15)
=
m(pt + qs)
nqt
=
mpt + mqs
nqt
.
On the other hand,
m
n â‹…
p
q +
m
n â‹…
s
t =
mp
nq +
ms
nt
(4.16)
=
mpnt + nqms
nqnt
=
mpnt + nqms
n2qt
.
These are not exactly the same fractions, and so the fractions are not equal
(unless it so happens that n = 1). Thus, in general,
m
n â‹…
(p
q +
s
t
)
â‰ 
m
n â‹…
p
q +
m
n â‹…
s
t .
(4.17)
Now the distributive property has been with us from the beginning. We
just cannot consider an arithmetic without it being part of any arithmetic of
numbers. So fractions are not numbers (one might say.)
4.2.2
In some ways they are the same
We certainly expect that rational numbers are numbers. So what is going on?
Until now, we have neglected an important deï¬nition from grade school. It is
an oï¬ƒcial mathematical deï¬nition and an important one.
Deï¬nition 4.2.1.
Let
m
n and
p
q be fractions. (That is to say, let m, p âˆˆâ„¤and
n, q âˆˆâ„•.) We say
m
n is equivalent to
p
q if mq = np.

4.2 Fractions Versus Rational Numbers
57
The notation for this is
m
n â‰¡
p
q. This reminds us that two fractions
m
n and
p
q
represent equal rational numbers if and only if they are equivalent. So what
exactly is a rational number? To mathematicians, a rational number is, quite
literally, a set of equivalent fractions. For example,
1
2 =
{1
2,
2
4,
3
6,
4
8,
5
10 Â· Â· Â·
}
;
(4.18)
3
5 =
{3
5,
6
10,
9
15,
12
20,
15
25 Â· Â· Â·
}
;
âˆ’11
12 =
{âˆ’11
12 ,
âˆ’22
24 ,
âˆ’33
36 ,
âˆ’44
48 ,
âˆ’55
60 Â· Â· Â·
}
;
0
1 =
{0
1,
0
2,
0
3,
0
3,
0
5,
0
6 Â· Â· Â·
}
;
30
50 =
{3
5,
6
10,
9
15,
12
20,
15
25, â€¦
30
50 Â· Â· Â·
}
.
The single bar means rational number, and the double bar means fraction. If we
compare the second and the last example, we see that
3
5 â‰ 
30
50. However the sets
that they represent have exactly the same elements. This is true even though we
explicitly listed more elements when we wrote down the last one. Still:
{3
5,
6
10,
9
15,
12
20,
15
25 Â· Â· Â·
}
=
{3
5,
6
10,
9
15,
12
20,
15
25, â€¦ 30
50 Â· Â· Â·
}
.
(4.19)
This means that the rational numbers are equal: 3
5 = 30
50.
We can now write down an oï¬ƒcial deï¬nition of rational numbers.
Deï¬nition 4.2.2.
Let m âˆˆâ„¤and n âˆˆâ„•, then
m
n =
{p
q
||
m
n â‰¡
p
q
}
.
(4.20)
Then,
â„š=
{m
n
|| m âˆˆâ„¤and n âˆˆâ„•
}
.
(4.21)
Using these deï¬nitions, we can say
m
n = s
t if and only if ns = mt.
Once we have done this, we can drop our double bar notation for fractions
forever. All we need to take from this is that every rational number has many
diï¬€erent fractions that could be its name.

58
4 Rational Numbers
4.3
The rational numbers
The set â„šis called the set of rational numbers. While the set of fractions is not
an ordered ï¬eld, the set of rational numbers is. All we need to prove this is to
deï¬ne an order, an addition, and a multiplication on â„šand check that all 16
properties hold.
Deï¬nition 4.3.1.
Let f1, f2 âˆˆâ„š. The inequality of rational numbers f1 < f2
means, if we write f1 = m
n and f2 = p
q, then
mq < np as integers.
(4.22)
Deï¬nition 4.3.2.
Let f1, f2 âˆˆâ„š. If we write f1 = m
n and f2 = p
q, the sum is given
by the formula
f1 + f2 = mq + np
nq
.
(4.23)
Deï¬nition 4.3.3.
Let f1, f2 âˆˆâ„š. If we write f1 = m
n and f2 = p
q, the product is
given by the formula
f1 â‹…f2 = mp
nq .
(4.24)
4.3.1
Operations are well deï¬ned
The aforementioned three deï¬nitions are written as they are to clearly illustrate
a problem with deï¬ning terms involving rational numbers using the fractions
that represent them. Each of these deï¬nitions say, â€œif we write f1 = m
n and
f2 = p
qâ€¦â€. The trouble is that there are many diï¬€erent ways to do this. Every
rational number has inï¬nitely many diï¬€erent fractional names. What if we
apply one of these deï¬nitions using one choice of fractions for f1 and f2 and
someone else applies the deï¬nition using a diï¬€erent choice of equivalent
fractions? One very clear requirement for addition in an ordered ï¬eld is that
the sum f1 + f2 be a unique rational number. So adding two equivalent pairs of
fractions must end with equivalent fractions as results.
To illustrate the problem, suppose we tried to deï¬ne addition of rational
numbers mâˆ•n and pâˆ•q as
m
n + p
q = m + p
n + q .
(4.25)
This seems to be a very natural deï¬nition. However, notice that although
1âˆ•2 = 4âˆ•8 and 1âˆ•3 = 3âˆ•9 with this deï¬nition of addition, we have
1
2 + 1
3 = 2
5
but
4
8 + 3
9 = 7
17.
(4.26)

4.3 The Rational Numbers
59
But 2âˆ•5 â‰ 7âˆ•17. Here, adding two equivalent pairs of fractions does not give
equivalent fractions as results. As a result, we say that the operation is not well
deï¬ned, and as a result, we must reject that deï¬nition for addition.
The three formal deï¬nitions given earlier do give us well-deï¬ned notions. But,
before we begin using them, we must prove that they are well deï¬ned. That is,
we must prove that diï¬€erent choices for the names of the numbers involved will
give the same results when the deï¬nition is applied.
Theorem 4.3.4.
Let f1, f2 âˆˆâ„š. The inequality f1 < f2 is well-deï¬ned.
Proof draft. We will prove
If m1
n1
= m2
n2
, and p1
q1
= p2
q2
,
then if m1
n1
< p1
q1
, then m2
n2
< p2
q2
.
Comment: The idea here is that to prove any statement, we need to rephrase it
as an â€œifâ€¦then.â€ When asked to prove that something is â€œwell deï¬ned,â€ that is
usually a hint that there is some choice involved in the deï¬nition. The deï¬nition
is logically sound if in the end that choice does not matter. So when asked to prove
that something is â€œwell deï¬ned,â€ we should try to phrase it as â€œIf I use diï¬€erent
names for the ingredients, then the results are the same.â€ That is what we did
earlier.
We begin as always, assuming the â€œif.â€
Assume m1
n1 = m2
n2 .
Assume p1
q1 = p2
q2 .
Then, we know m1n2 = m2n1.
And, we know p1q2 = p2q1.
Under these assumptions, we want to prove if m1
n1 < p1
q1 , then m2
n2 < p2
q2 . How do
we prove this â€œifâ€¦thenâ€ statement? We still assume the â€œif.â€
Assume m1
n1 < p1
q1 .
Then, we know m1q1 < n1p1.
Under these assumptions, we want to prove
m2
n2 < p2
q2 . If we consider the
left-hand side alone, it is not clear what to do with this as either a rational
number or as a fraction. Instead, we ask ourselves, what must we prove to
show that m2
n2 < p2
q2 ? We must show that m2q2 < n2p2. After a bit of thought, we
guess that we need to turn the inequality m1q1 < n1p1 into m2q2 < n2p2 using
our ï¬rst two conclusions m1n2 = m2n1 and p1q2 = p2q1. We come up with the
following argument.

60
4 Rational Numbers
All these are statements about integers; so we have access to all the algebraic
properties of â„¤. We start with the (assumed) fact that m1q1 < n1p:
m1q1 < n1p1.
(4.27)
Multiplying by n2 > 0, we have
n2m1q1 < n2n1p1.
(4.28)
Since m1n2 = m2n1, we have
n1m2q1 < n2n1p1.
(4.29)
Since n1 > 0, we have
m2q1 < n2p1.
(4.30)
Multiplying by q2 > 0, we have
m2q1q2 < n2p1q2.
(4.31)
Since p1q2 = p2q1, we have
m2q1q2 < n2p2q1.
(4.32)
Since q1 > 0, we have
m2q2 < n2p2.
(4.33)
Now that we have m2q2 < n2p2, we can say m2
n2 < p2
q2 .
Î”
This proof is kind of wordy because we explained our reasoning along the
way. We do not need to explain how we discover a proof; all we need to do is
explain the logic of the argument and not its construction. We can, and should,
rewrite the proof to make the argument pithier.
Proof. We will prove
If m1
n1
= m2
n2
, and p1
q1
= p2
q2
,
then if m1
n1
< p1
q1
, then m2
n2
< p2
q2
.
Assume m1
n1 = m2
n2 .
Assume p1
q1 = p2
q2 .
Assume m1
n1 < p1
q1 .
Thus, n1 > 0; n2 > 0; q1 > 0 and q2 > 0.
In addition, we know that m1n2 = m2n1, and p1q2 = p2q1, and m1q1 < n1p1
are true statements about integers.

4.3 The Rational Numbers
61
So
m1q1 < n1p1.
n2m1q1 < n2n1p1.
n1m2q1 < n2n1p1.
m2q1 < n2p1.
(4.34)
m2q1q2 < n2p1q2.
m2q1q2 < n2p2q1.
m2q2 < n2p2.
Now that we have m2q2 < n2p2, we can say m2
n2 < p2
q2 .
â—½
Mostly we cleaned up the proof by erasing the nonessential comments about
why we were taking each step and just leaving the step. We did, however, make
it a point to leave the algebraic justiï¬cations for some of the steps by pointing
out that the numbers that we would use later to multiply the inequalities are
positive.
Theorem 4.3.5.
Let f1, f2 âˆˆâ„š. The sum f1 + f2 is well deï¬ned.
Proof draft. We will prove that
If m1
n1 = m2
n2 and p1
q1 = p2
q2 , then m1q1+n1p1
n1q1
= m2q2+n2p2
n2q2
.
Comment: Again, to prove any statement, we need to rephrase it as an ifâ€¦then.
When asked to prove that something is â€œwell deï¬ned,â€ that is usually a hint that
there is some choice involved in the deï¬nition. The deï¬nition is logically sound
if in the end that choice does not matter. So when asked to prove that something
is â€œwell deï¬ned,â€ we should try to phrase it as â€œIf I use diï¬€erent names for the
ingredients, then the results the same.â€ That is what we did earlier.
Assume m1
n1 = m2
n2 .
Assume p1
q1 = p2
q2 .
Then, we know m1n2 = m2n1.
And, we know p1q2 = p2q1.
Under these assumptions, we want to prove
m1q1 + n1p1
n1q1
= m2q2 + n2p2
n2q2
.
(4.35)
If we consider the left-hand side alone, it is not clear what to do with this as
either a rational number or as a fraction. Instead, we ask ourselves, what must
we prove to show that m1q1+n1p1
n1q1
= m2q2+n2p2
n2q2
?

62
4 Rational Numbers
Comment: Notice that the deï¬nition of â€œequalsâ€ has changed. For natural num-
bers and integers, it means â€œexactly the same.â€ For rational numbers written as
fractions, it means â€œare equivalent.â€
We must show that
n2q2(m1q1 + n1p1) = n1q1(m2q2 + n2p2).
(4.36)
Comment: This is a statement about integers and not rational numbers. This
gives us access to all the algebraic properties of â„¤.
Consider n2q2(m1q1 + n1p1).
n2q2(m1q1 + n1p1) = n2q2m1q1 + n2q2n1p1
(4.37)
= (n2m1)(q2q1) + (n2n1)(p1q2)
= (n1m2)(q2q1) + (n2n1)(p2q1).
Here we used our two assumptions. Next, consider the right-hand side of our
equation.
n1q1(m2q2 + n2p2) = n1q1m2q2 + n1q1n2p2
(4.38)
= (n1m2)(q2q1) + (n2n1)(p2q1).
Since the results are the same
n2q2(m1q1 + n1p1) = n1q1(m2q2 + n2p2).
(4.39)
And, so we have
m1q1 + n1p1
n1q1
= m2q2 + n2p2
n2q2
.
(4.40)
Î”
Again, it is a good idea to rewrite this proof more concisely, leaving only the
parts that are directly relevant to the mathematics.
Proof. We will prove
If m1
n1
= m2
n2
, and p1
q1
= p2
q2
,
then m1q1 + n1p1
n1q1
= m2q2 + n2p2
n2q2
.
Assume m1
n1 = m2
n2 .
Assume p1
q1 = p2
q2 .

4.3 The Rational Numbers
63
Then, m1n2 = m2n1, and p1q2 = p2q1.
Consider n2q2(m1q1 + n1p1).
n2q2(m1q1 + n1p1) = n2q2m1q1 + n2q2n1p1
(4.41)
= (n2m1)(q2q1) + (n2n1)(p1q2)
= (n1m2)(q2q1) + (n2n1)(p2q1)
= n1q1(m2q2 + n2p2).
And, so we have
m1q1 + n1p1
n1q1
= m2q2 + n2p2
n2q2
.
(4.42)
â—½
Theorem 4.3.6.
Let f1, f2 âˆˆâ„š. The product f1â‹…f2 is well deï¬ned.
We will leave the proof of this as an exercise.
4.3.2
â„šis an ordered ï¬eld
Once all the arithmetic is shown to be well deï¬ned, we can perform arithmetic
and algebra on rational numbers without explicitly writing them as fractions.
But ï¬rst, we must show that these algebraic properties really work for these
fractional deï¬nitions.
Theorem 4.3.7.
The rational numbers â„šform an ordered ï¬eld.
This actually comprises 17 separate claims
Claim 1. There is a well-deï¬ned order on â„š.
Proof. This was just proved.
â—½
Claim 2. That order is transitive.
Proof. We will prove: if a, b, c âˆˆâ„š, then if a < b and b < c, then a < c.
Assume a, b, c âˆˆâ„š.
Assume a < b.
Assume b < c.
We can write a = n
m, b = p
q, and c = s
t. Then, m, q, and t are positive.
Then, a < b means nq < mp, while b < c means pt < qs.
Then, nq < mp implies that nqt < mpt. In addition, pt < qs implies that
mpt < mqs. So nqt < mpt < mqs, and nqt < mqs. Then, we have nt < ms.
Thus, n
m < s
t. So a < c.
â—½

64
4 Rational Numbers
Claim 3. That order has trichotomy.
Proof. We will prove: if a, b âˆˆâ„š, then exactly one of the following holds: a < b,
b < a, or a = b.
Assume a, b âˆˆâ„š.
Then, we can write a = n
m and b = p
q.
Now mp and nq are integers, and the integers have trichotomy. So exactly one
of the following is true:
mp < nq, in which case a = n
m < p
q = b;
nq < mp, in which case b = p
q < n
m = a;
or mp = nq, in which case a = n
m = p
q = b.
â—½
Claim 4. If a, b âˆˆâ„š, there is a unique a + b âˆˆâ„š.
Proof. This was what we proved when we proved that addition is well
deï¬ned.
â—½
Claim 5. Addition is associative.
Proof. We leave this as an exercise, but it is the same calculation we performed
when we proved that addition of fractions was associative.
â—½
Claim 6. Addition is commutative.
Proof. We leave this as an exercise.
â—½
Claim 7. There is an additive identity in â„š.
Proof. Consider 0
1 âˆˆâ„š. Assume a âˆˆâ„š. We can write a = n
m. Then
0
1 + a = 0
1 + n
m = 0 â‹…m + 1 â‹…n
1 â‹…m
= n
m = a.
(4.43)
Since we know that addition is commutative, we also have a + 0
1 = a.
â—½
Claim 8. If a âˆˆâ„š, then a has an additive inverse.
Proof. We leave this as an exercise.
â—½
Claim 9. If a, b, c âˆˆâ„šand a < b, then a + c < b + c.
Proof. Assume a, b, c âˆˆâ„š.
Assume a < b.

4.3 The Rational Numbers
65
We can write a = n
m, b = p
q, and c = s
t.
Since a < b, we know that nq < mp.
Consider tq(nt + ms).
tq(nt + ms) = (qn)t2 + tqms
(4.44)
< (mp)t2 + tqms
< tm(pt + qs).
So
(nt + ms)
mt
< (pt + qs)
qt
.
(4.45)
So
n
m + s
t < p
q + s
t .
(4.46)
So a + c < b + c.
â—½
Claim 10. If a, b âˆˆâ„š, there is a unique a â‹…b âˆˆâ„š.
Proof. This is what â€œmultiplication is well deï¬nedâ€ means; so it was proved
already.
â—½
Claim 11. Multiplication is associative.
Proof. We leave this as an exercise.
â—½
Claim 12. Multiplication is commutative.
Proof. We leave this as an exercise.
â—½
Claim 13. There is a multiplicative identity in â„š.
Proof. Consider 1
1 âˆˆâ„š. Assume n
m âˆˆâ„š. Then 1
1 â‹…n
m = n
m = n
m â‹…1
1.
â—½
Claim 14. If a âˆˆâ„šand a â‰ 0, then a has a multiplicative inverse.
Proof. Assume a âˆˆâ„š. Assume a â‰ 0. This means that a is not the additive
identity of â„š, which we proved is 0
1. We can write a = n
m, where n âˆˆâ„¤and
m âˆˆâ„•. Since a â‰ 0, we know that n
m â‰ 0
1. By the deï¬nition of equality of ratio-
nal numbers, n â‹…1 â‰ m â‹…0. So n = n â‹…1 â‰ m â‹…0 = 0. (Notice that we cannot use
m
n as a legitimate rational number unless we know that n âˆˆâ„•. We can avoid

66
4 Rational Numbers
such cases by using the fact that multiplication is well deï¬ned.) Since n â‰ 0 âˆˆâ„¤,
n2 > 0, and so n2 âˆˆâ„•. Then, mn
n2 âˆˆâ„š. Then
a â‹…mn
n2 = n
m â‹…mn
n2 = mn2
mn2 = 1
1.
(4.47)
So mn
n2 is a multiplicative inverse of n
m = a.
Comment: We can all pretend that, instead of canceling, we checked the last
equality using the deï¬nition of equality by observing that mn2 â‹…1 = mn2 â‹…1.
â—½
Claim 15. If a, b, c âˆˆâ„šand a < b and 0 < c, then a â‹…c < b â‹…c.
Proof. We leave this as an exercise.
â—½
Claim 16. If a, b, c âˆˆâ„š, then a â‹…(b + c) = a â‹…b + a â‹…c.
Proof. Assume a, b, c âˆˆâ„š.
Assume a < b.
Assume b < c.
We can write a = n
m, b = p
q, and c = s
t.
Then
a â‹…(b + c) = n
m â‹…
(p
q + s
t
)
(4.48)
= n
m â‹…
(pt + qs
qt
)
= n(pt + qs)
mqt
= npt + nqs
mqt
.
On the other hand,
n
m â‹…p
q + n
m â‹…s
t = np
mq + ns
mt
(4.49)
= npmt + mqns
mqmt
= mpnt + nqms
m2qt
.
But since
m2qt(npt + nqs) = mqt(mpnt + nqms),
(4.50)

4.4 The Rational Numbers are Not Enough
67
we have
npt + nqs
mqt
= mpnt + nqms
m2qt
(4.51)
as rational numbers. So we have shown that a â‹…(b + c) = a â‹…b + a â‹…c.
â—½
Claim 17. The additive identity and the multiplicative identity are not equal.
Proof. Since in â„¤we have 0 â‰ 1, we know that in â„š, 0
1 â‰ 1
1.
â—½
Now â„šis an ordered ï¬eld, and earlier we said that every ordered ï¬eld has a
subset that is a copy of â„¤. In â„šthat set is
Z =
{n
1 âˆˆâ„š| n âˆˆâ„¤
}
.
(4.52)
We said that we would identify this subset of the ordered ï¬eld with â„¤. In this
case, this means that we can write the rational number represented by the
fraction n
1 as simply n. Since technically integers are not sets of equivalent frac-
tions, this identiï¬cation lets us say that, yes, they sort of are. This is deï¬nitely a
convenient trick.
Now suppose that F is an ordered ï¬eld. Through identiï¬cation, we say that
both â„•and â„¤are contained in F. In addition, all the elements of â„•have
multiplicative inverses. Thus,
Q = {mnâˆ’1 âˆˆF | m âˆˆâ„¤and n âˆˆâ„•}
(4.53)
=
{m
n âˆˆF | m âˆˆâ„¤andn âˆˆâ„•
}
.
is also contained in the ordered ï¬eld. Because of our identiï¬cations, this is a
set of rational numbers. So we can also say that every ordered ï¬eld contains
rational numbers by identiï¬cation.
4.4
The rational numbers are not enough
We have been hinting that the rational numbers are not the only example of
an ordered ï¬eld. That is a good thing because not all the numbers we need are
rational. Suppose that we have a square where the sides all have a length of one
unit. Geometry tells that the exact length of the diagonal will be a number that
when multiplied by itself is 2. To measure the length of this diagonal, we need
a number that has this property.
4.4.1
âˆš
2 is irrational
Theorem 4.4.1.
There is no number r âˆˆâ„šso that r2 = 2.
Proof draft. Assume, by way of contradiction (BWOC), that there is a number
r âˆˆâ„šso that r2 = 2.

68
4 Rational Numbers
Comment: We typically use a proof by contradiction to prove that something is
not true. This allows us a logically valid reason to assume that something is true,
even though we expect that it is not. It is only polite to warn the reader of what
we are doing, so we announced it at the beginning of the proof.
Since r âˆˆâ„š, we may write r = i
j with i âˆˆâ„¤and j âˆˆâ„•.
Comment: All our elementary school training tells us that we should pick the
best possible choice for the fraction r = i
j, one that is reduced. However, we do
not want to spend the time talking about common factors, nonreduced fractions,
and reduced fractions. Luckily, another way to describe a reduced fraction is as
a fraction in the lowest terms. We have already deï¬ned other things that allow
us to talk about the â€œlowestâ€ terms.
Let
D =
{
q âˆˆâ„•| there is a p âˆˆâ„¤so that p
q = r
}
.
(4.54)
Comment: This is a set of all possible denominators of fractions equivalent to our
rational number.
The set D is a set of natural numbers, and by assumption, j is an element
of D.
By well ordering in â„•, the set D has a minimum. Call it m. We have m âˆˆD.
In addition, if k âˆˆD, then m â‰¤k. (We should be on the lookout for something
in D so we can use this.)
Now
m âˆˆD =
{
q âˆˆâ„•| there is a p âˆˆâ„¤so that p
q = r
}
.
(4.55)
So there is an n âˆˆâ„¤so that n
m = r.
Comment: We can name it anything we want as long as we have not used the
name already. Of course, we now have written r as a fraction in the lowest terms
without using the common factors.
Now r2 = 2; so
(
n
m
)2
= 2
1. Therefore, n2 = 2m2.
By deï¬nition, this means that n2 is even. We proved a theorem a while ago
that said:
If n2 is even, then n is even.
Luckily, we memorized it so that we would remember it at a critical moment
such as this. So n is even.

4.4 The Rational Numbers are Not Enough
69
By deï¬nition, there is k âˆˆâ„¤so that n = 2k. But we still have the equation
n2 = 2m2. So
4k2 = (2k)2 = n2 = 2m2.
(4.56)
So m2 = 2k2. This means that m2 is even as well. By our old theorem, m is even.
So by deï¬nition, there is g âˆˆâ„¤so that m = 2g.
But then, r = n
m = 2k
2g = k
g . By the deï¬nition of the set D, we have g âˆˆD. But
we have been waiting for something in D to appear so we could use â€œif k âˆˆD,
then m â‰¤k.â€ Therefore, we know that m â‰¤g.
Of course, this is a problem because it says 2g = m â‰¤g. This would mean
2 â‰¤1. This logical contradiction means that we made an assumption that can-
not be true. We only made one; so there is no number r âˆˆâ„šso that r2 = 2. Î”
We should clean up this proof by removing the commentary.
Proof. Assume BWOC that there is a number r âˆˆâ„šso that r2 = 2.
Since r âˆˆâ„šwe may write r = i
j with i âˆˆâ„¤and j âˆˆâ„•.
Let
D =
{
q âˆˆâ„•| there is a p âˆˆâ„¤so that p
q = r
}
.
(4.57)
This is a set of natural numbers, and by assumption, j is an element of D.
By well ordering, the set D has a minimum. Call it m. Then m âˆˆD, and if
k âˆˆD, then m â‰¤k.
Now
m âˆˆD =
{
q âˆˆâ„•| there is a p âˆˆâ„¤so that p
q = r
}
.
(4.58)
So there is an n âˆˆâ„¤so that n
m = r.
Now r2 = 2; so
(
n
m
)2
= 2
1. Therefore n2 = 2m2.
By deï¬nition, this means that n2 is even. We proved a theorem that said:
If n2 is even, then n is even.
By deï¬nition, there is k âˆˆâ„¤so that n = 2k. But we still have the equation
n2 = 2m2. So
4k2 = (2k)2 = n2 = 2m2.
(4.59)
So m2 = 2k2. This means that m2is even as well. By our old theorem, m is even.
So by deï¬nition, there is g âˆˆâ„¤so that m = 2g.
But then
r = n
m = 2k
2g = k
g .
(4.60)

70
4 Rational Numbers
By the deï¬nition of the set D, we have g âˆˆD. This means 2g = m â‰¤g. So 2 â‰¤1.
This logical contradiction. We have proved that there is no number r âˆˆâ„šso
that r2 = 2.
â—½
4.5
Problems
4.1
Let F be an ordered ï¬eld and a, b âˆˆF, with a â‰ 0 and b â‰ 0. Prove the
following.
(a) (aâˆ’1)âˆ’1 = a.
(b) (a â‹…b)âˆ’1 = (bâˆ’1) â‹…(aâˆ’1).
(c) (âˆ’a)âˆ’1 = âˆ’(aâˆ’1).
4.2
Let F be an ordered ï¬eld and a âˆˆF, where a â‰ 0. Prove the following.
(a) If a > 0, then aâˆ’1 > 0.
(b) If a < 0, then aâˆ’1 < 0.
4.3
Let F be an ordered ï¬eld and a, b, c, d âˆˆF. Prove that if a < b and
c < d, then a + c < b + d. (Remember the trick for proving inequalities:
we want a + c <? < b + d.)
4.4
Let F be an ordered ï¬eld. Suppose that a âˆˆF and a â‰ 0. Prove that for
all n âˆˆâ„•, (an)âˆ’1 = (aâˆ’1)n.
4.5
We gave an odd deï¬nition for the order of fractions:
m
n <
p
q means that mq < np as integers or mq = np and n < q.
(a) Prove that this order is transitive. (It requires several cases.)
(b) Prove that this order has trichotomy.
(c) Explain why this order makes the fractions well ordered, and if you
are brave, write out a proof.
4.6
Prove that addition in â„šis well deï¬ned.
4.7
Prove that multiplication in â„šis well deï¬ned.
4.8
Prove that addition in â„šis commutative.
4.9
Prove that the order in â„šis well deï¬ned.
4.10
Prove that if a âˆˆâ„š, then a has an additive inverse.

4.5 Problems
71
4.11
Prove that multiplication in â„šis associative.
4.12
Prove that multiplication in â„šis commutative.
4.13
Prove that if a, b, c âˆˆâ„šand a < b and 0 < c, then a â‹…c < b â‹…c.
4.14
Prove that if a âˆˆâ„šand a â‰ 0, then a has a multiplicative inverse.
4.15
Let n
m and p
m be elements of â„š.
(a) Use the deï¬nition of addition in â„što prove that n
m+ p
m = n+p
m .
(b) Use the algebraic properties of an ordered ï¬eld to prove that
n
m+ p
m = n+p
m .
4.16
Prove that there is no r âˆˆâ„šso that r2 = 6.
4.17
Write a deï¬nition of â€œthe fraction n
m is in lowest termsâ€ that does not
use the idea of common factors but uses the fact that the terms are the
lowest possible.

73
5
Ordered Fields
5.1
Other ordered ï¬elds
So far, we have one example of an ordered ï¬eld, â„š. We also know that there is
no element r âˆˆâ„šso that r2 = 2. We really want a number such as this though.
We can create an ordered ï¬eld just to have such a thing. We deï¬ne
â„š(
âˆš
2) = {a + bðœ™| a, b âˆˆâ„š}.
(5.1)
Here ðœ™is just a symbol. Thus, the only way a + bðœ™= c + dðœ™is if a = c and b = d.
To make this an ordered ï¬eld, we need to deï¬ne an order, an addition, and a
multiplication. The deï¬nition of the order is rather long and strange, but that is
what makes it work. This is only an example, so the deï¬nitions are not of lasting
importance.
Deï¬nition: we say s + tðœ™â‹–u + ð‘£ðœ™when |s âˆ’uâˆ£(s âˆ’u) < 2 âˆ£ð‘£âˆ’tâˆ£(ð‘£âˆ’t).
Deï¬nition: we say (s + tðœ™) âŠ•(u + ð‘£ðœ™) = (s + u) + (t + ð‘£)ðœ™.
Deï¬nition: we say (s + tðœ™) âŠ™(u + ð‘£ðœ™) = (su + 2tð‘£) + (sð‘£+ tu)ðœ™.
Notice that in each of these, we deï¬ne things for â„š(
âˆš
2) by using the order,
addition, and multiplication in â„š. In the order deï¬nition, the ï¬rst â€œâ‹–â€ refers to
the newly required order for â„š(
âˆš
2), while the second â€œ<â€ refers to the already
understood order in â„š. In addition, notice that because each element in â„š(
âˆš
2)
has only one name and arithmetic in â„šis completely safe, there is no need to
worry that these are not well deï¬ned.
While it is not a pleasant task, we could check that â„š(
âˆš
2) is indeed an
ordered ï¬eld. We might also note that
ðœ™2 = (0 + 1ðœ™)2 = (0 + 1ðœ™) âŠ™(0 + 1ðœ™) = 2 + 0 â‹…ðœ™= 2.
(5.2)
So we could have written ðœ™=
âˆš
2. So even though â„šdoes not have an r âˆˆâ„šso
that r2 = 2, there is at least one ordered ï¬eld that does.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

74
5 Ordered Fields
But this does not help us if we also want a number s so that s2 = 6. Neither â„š
nor â„š(
âˆš
2) will have such a number. We could invent
â„š(
âˆš
2,
âˆš
6) = {a + bðœ™+ cðœ“+ dðœ™ðœ“âˆ£a, b, c, d âˆˆâ„š}.
(5.3)
But suppose that we need the number ðœ‹?
Eventually, we would like to ï¬nd the deï¬nition of a special ordered ï¬eld that
will give us all the numbers we could possibly need at once. We will do this by
adding an adequate replacement for the well ordering that has served us so well
for â„•. We compromised a bit and found a replacement that worked for â„¤. We
will need to do even more compromising to make the next step.
For now we will concentrate on proving some useful results for any ordered
ï¬eld. That way we will have properties we can apply to â„šor to the ï¬nal ï¬eld we
are hoping for.
5.2
Properties of ordered ï¬elds
5.2.1
The average theorem
Anytime a theorem has a name, that is a signal that it is worth remembering.
The main reason to name a theorem is to make it easier to refer to it later. Some-
times, a theorem has a name because it is complicated, and it takes a while to
state. A theorem with a long or complicated proof is often worth naming, so
we can use the name and avoid having to reproduce the proof. Other theorems
have names even though they are rather simple to understand and prove. That
generally means that they are used in lots of other places. Our ï¬rst theorem is
an example of the latter.
Theorem 5.2.1
(The Average Theorem). If a, b âˆˆF an ordered ï¬eld with
a < b, then there is an element r âˆˆF such that a < r < b. In fact, r = a+b
2 is one
example.
Proof. Assume a, b âˆˆF. Assume a < b. Adding a to both sides gives us
2a < a + b. Adding b to both sides gives us a + b < 2b. We can put these
together using transitivity and say 2a < a + b < 2b. Multiplying by the positive
number 2âˆ’1, we get a < a+b
2
< b. (Heaven forbid, we divide by 2.)
â—½
Notice that the average theorem tells us that no ordered ï¬eld is discrete. There
is no element o in an ordered ï¬eld so that a â‰¤b â‰¤a + o implies that either a = b
or a = b + o. There is never a way to ever say that we have two consecutive
numbers in an ordered ï¬eld. Graphically, the line representing an ordered ï¬eld
has no measurable gaps. It has points, but it may also have one-point holes.
Because of the average theorem, there is no number â€œin front of a pointâ€ or any
number â€œafter a pointâ€ on this line. There is no number â€œin front of a holeâ€ or
any number â€œafter a holeâ€ on the line either.

5.2 Properties of Ordered Fields
75
5.2.2
Absolute values
As we have seen, mathematicians insist that mathematical terms, ideas, and
symbols be well deï¬ned. There is, however, one example where this is not the
case. Mathematicians ï¬nd the symbol â€œÂ±â€ very useful for dealing with cases in a
proof. But by its very meaning, Â± is not well deï¬ned. The expression Â±x means:
â€œEither +x or âˆ’x; we do not know which or we do not care which.â€
We have already used the idea of the absolute value of a number several times.
It is a familiar idea. But what does it mean?
Now
|x| = Â±x
(5.4)
is a true statement. It says, â€œthe absolute value of x is either +x or âˆ’x.â€ Someone
who is not careful about logic might try to deï¬ne the absolute value of a number
as
|x| = Â±x.
(5.5)
This is wrong because it does not make the symbol |x| well deï¬ned. We know
that â€œwell deï¬nedâ€ means that there should be only one possible value for âˆ£xâˆ£,
while the symbol Â± signiï¬es that there is a choice determining what |x| might
be. The correct deï¬nition of the absolute value is
Deï¬nition 5.2.2.
Let x âˆˆF an ordered ï¬eld. Then
|x| =
âŽ§
âŽª
âŽ¨
âŽªâŽ©
x
if x > 0
0
if x = 0
âˆ’x
if x < 0
.
(5.6)
There is no ambiguity in this deï¬nition. By trichotomy, exactly one of the
following is true about x: x > 0, x < 0, or x = 0. This deï¬nition tells us which
calculation to make in each of these cases. There may be three formula, but each
one only applies in any one circumstance. The absolute value is well deï¬ned on
any ordered ï¬eld. (Here, â€œwell deï¬nedâ€ is not about the name of the variable,
but it is about the ï¬rst impression that there is a choice to be made. Once we see
that there is no actual choice, the absolute value is deï¬ned without ambiguity.)
The Â± sign is used in mathematics because it can condense several cases
involving absolute values into one line. This is because
|x| = Â±x
(5.7)
and
x = Â± âˆ£xâˆ£
(5.8)
are true mathematical statements. We will see this in the following proof.

76
5 Ordered Fields
Theorem 5.2.3.
Let F be an ordered ï¬eld.
1. If a âˆˆF, then |a| â‰¥0.
2. If a âˆˆF, then âˆ’|a| â‰¤a â‰¤|a|.
3. Let r âˆˆF with r â‰¥0. Consider x as a variable in F. Then |x âˆ’a| â‰¤r if and
only if a âˆ’r â‰¤x â‰¤a + r.
4. Let r âˆˆF with r > 0. Consider x as a variable in F. Then, |x âˆ’a| < r if and
only if a âˆ’r < x < a + r.
5. If a, b âˆˆF, then |ab| = |a||b|.
Proof. There are ï¬ve parts to prove.
Part 1. We claim that if a âˆˆF, then |a| â‰¥0.
Proof of claim. Assume a âˆˆF. By trichotomy, there are three possibilities:
a > 0; a < 0; or a = 0.
Case 1: Assume a > 0. Then |a| = a > 0.
Case 2: Assume a < 0. Then |a| = âˆ’a > 0.
Case 3: Assume a = 0. Then |a| = 0.
â—¾
Part 2. We claim that if a âˆˆF, then âˆ’|a| â‰¤a â‰¤|a|.
Proof of claim. Assume a âˆˆF. By the previous part, |a| â‰¥0. But then âˆ’|a| â‰¤
0 â‰¤|a|. So âˆ’|a| â‰¤|a|. However, a = Â±|a|, and that is all âˆ’|a| â‰¤a â‰¤|a| is
saying.
â—¾
Part 3. Let r âˆˆF with r â‰¥0. Consider x as a variable in F. Then |x âˆ’a| â‰¤r if
and only if a âˆ’r â‰¤x â‰¤a + r.
Proof of claim. This is an â€œif and only ifâ€ statement, so we have two directions
to prove. First, we will prove that
If |x âˆ’a| â‰¤r, then a âˆ’r â‰¤x â‰¤a + r.
To begin the proof of this, let r âˆˆF with r â‰¥0. Assume |x âˆ’a| â‰¤r. Then
âˆ’r â‰¤âˆ’|x âˆ’a|. By the previous part
âˆ’r â‰¤âˆ’|x âˆ’a| â‰¤x âˆ’a â‰¤|x âˆ’a| â‰¤r.
(5.9)
So
âˆ’r â‰¤x âˆ’a â‰¤r;
(5.10)
a âˆ’r â‰¤x â‰¤a + r.
This completes the proof of the ï¬rst direction.
Now we will prove that
If a âˆ’r â‰¤x â‰¤a + r, then |x âˆ’a| â‰¤r.

5.2 Properties of Ordered Fields
77
To begin the proof, let r âˆˆF with r â‰¥0. Assume a âˆ’r â‰¤x â‰¤a + r. Then
âˆ’r â‰¤x âˆ’a â‰¤r.
(5.11)
If we multiply both the inequalities by âˆ’1, the signs reverse
âˆ’r â‰¤âˆ’(x âˆ’a) â‰¤r.
(5.12)
But |x âˆ’a| = Â±(x âˆ’a). So |x âˆ’a| â‰¤r. This completes the proof of the other
direction and ï¬nishes the proof of Step 3.
â—¾
Part 4. Let r âˆˆF with r > 0. Consider x as a variable in F. Then, |x âˆ’a| < r if
and only if a âˆ’r < x < a + r.
Proof of claim. This claim follows from the previous result.
â—¾
Part 5. If a, b âˆˆF, then |ab| = |a||b|.
Proof of claim. Assume a, b âˆˆF. Then |a| = Â±a and |b| = Â±b. So by multiply-
ing, we ï¬nd the product up to the sign: |a| â‹…|b| = Â±ab. Also, ab = Â±|ab|. These
statements imply that |a| â‹…|b| = Â±|ab|. Now âˆ£a||bâˆ£â‰¥0 and âˆ£abâˆ£â‰¥0. Including
the possibility that these might be zero, the only sign that works in the equation
|a| â‹…|b| = Â±|ab| is +.
â—¾
We have now proved all ï¬ve claims in the theorem.
â—½
Notice how we avoided writing down a bunch of cases in the later proofs by
lumping them all together and hiding them in the Â± signs.
Theorem 5.2.4
(The Triangle Inequality). Let a, b âˆˆF an ordered ï¬eld.
Then
|a + b| â‰¤|a| + |b|.
(5.13)
Proof. Assume a, b âˆˆF. From the last theorem,
âˆ’|a| â‰¤a â‰¤|a|;
(5.14)
âˆ’|b| â‰¤b â‰¤|b|.
Adding these inequalities we get
âˆ’(|a| + |b|) â‰¤a + b â‰¤|a| + |b|.
(5.15)
But since r = |a| + |b| â‰¥0, we can use part 3 of Theorem 5.2.3 to say
|a + b| â‰¤|a| + |b|.
(5.16)
â—½

78
5 Ordered Fields
5.2.3
Picturing number systems
All our number systems have an order that is transitive and satisï¬es tri-
chotomy. Transitivity means that the numbers proceed from smaller to larger.
Trichotomy means that any two numbers can be compared in size; and that
means that when arranged by size, they appear in a line.
The natural numbers and the integers are discrete. This is because they both
satisfy the condition that
if n < m â‰¤n + 1, then n = m + 1.
In other words, there are no integers between two consecutive integers. We
might also say that there are gaps between the integers. If we try to draw a
representation of either of these systems, we need to draw the numbers in a
line with gaps between consecutive numbers.
The natural numbers might resemble
â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…
The integers might resemble
â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…â‹…
An ordered ï¬eld is not discrete. The average theorem says that, between any two
numbers in a ï¬eld, there is another number. So basically, no drawing depicting
an ordered ï¬eld should show gaps between the points representing the numbers
in the ï¬eld. The drawing should resemble a solid line.
If the ordered ï¬eld is the rational numbers â„š, or any ordered ï¬eld, the aver-
age theorem says that there is an element between any two. Thus, any line that
represents an ordered ï¬eld should be solid (no gaps), but we cannot think of â„š
as a complete line. There are distances on the line that indicate distances such
as
âˆš
2 that are not part of â„š. There may be no gaps in the line, but there are
plenty of one-point holes. None of the â€œholesâ€ are large enough to create a visi-
ble â€œgapâ€ at any magniï¬cation. So it is probably not possible to accurately draw
such a thing. One way to try is to depict the line as light gray. It is a solid line, but
we can pretend that the one-point holes let the white background slip through
enough to make it appear gray.
Keeping this analogy, we might say that a drawing of the ordered ï¬eld â„š(
âˆš
2)
would also be a solid line; it would still be gray because there are still distances
not measurable with numbers from â„š(
âˆš
2). However, it should be a darker gray
than the line for â„š, because it has numbers that ï¬ll a good many holes in â„š. In
this graphic analogy, it is easy to describe a picture of the best possible ordered
ï¬eld. It should be a solid line with no gaps, but a complete line without any
holes either. Its picture is a totally dark solid line that remains totally dark.

5.3 Problems
79
Our next step is to add another property to the requirements for an ordered
ï¬eld to produce a complete ordered ï¬eld. The aforementioned geometric anal-
ogy is so compelling that we want to be sure that it survives the added require-
ment. We will add this property and with it include a complete collection of
new, irrational, numbers. However, we want to be sure that we do not add more
than we need. According to the given graphic description, the average theorem
says that any holes that might appear in the lines representing â„š, â„š(
âˆš
2) or any
other ordered ï¬eld will not be large enough to create a gap. When we ï¬ll in
those holes, we do not want to create a â€œsmudgeâ€ of new numbers that creates
a gap between rational numbers. That is, we want one new number in each old
hole; we do not want to jam a whole segment of new numbers into one hole
between old numbers. In addition, the integers and all ordered ï¬elds extend
forever in each direction. We want to be sure that our new property does not
cap oï¬€either end of the line by adding an irrational number larger than all the
numbers we already have.
One of the ï¬rst things we will do when we add an extra property to the num-
bers to complete our ordered ï¬elds once and for all is to check that we have not
created â€œend capsâ€ or â€œsmudgesâ€ in the process. By that time, however, these
will be real mathematical statements we can prove rigorously.
5.3
Problems
5.1
The average theorem states: if a, b âˆˆF an ordered ï¬eld with a < b, then
there is an element r âˆˆF such that a < r < b. In fact, r = a+b
2
is one
example. Why would it be wrong to call the average a+b
2 a fraction?
5.2
Let F be an ordered ï¬eld.
(a) Prove that for all â„•, if a1 âˆˆF, a2 âˆˆF, Â· Â· Â· an âˆˆF, then
nâˆ‘
k=1
a2
k â‰¥0.
(b) Prove that for all â„•, if a1 âˆˆF, a2 âˆˆF, Â· Â· Â· an âˆˆF, and
nâˆ‘
k=1
a2
k = 0, then
a1 = a2 = Â· Â· Â· an = 0.
5.3
Explain why the average theorem means that no ordered ï¬eld is
discrete.
5.4
Prove that there is no r âˆˆâ„šso that r2 = 8.
5.5
Let n âˆˆâ„•be odd. Prove that there is no r âˆˆâ„šso that r2 = 2n.
5.6
Let F be any ordered ï¬eld and a âˆˆF with a < 0. Prove that there is no
r âˆˆF so that r2 = a.

80
5 Ordered Fields
5.7
Let F be any ordered ï¬eld with a, b, c âˆˆF, prove that âˆ£a âˆ’câˆ£â‰¤âˆ£a âˆ’bâˆ£
+ âˆ£c âˆ’bâˆ£.
5.8
Let F be any ordered ï¬eld.
(a) Prove that if a, b âˆˆF so that a < b, then for all n âˆˆâ„•, there are
numbers xi âˆˆF so that a < x1 < x2 < â€¦ xnâˆ’1 < xn < b.
(b) Explain why you have just proved that if a, b âˆˆF so that a < b, then
for all n âˆˆâ„•, there are numbers xi âˆˆF all diï¬€erent so that for all
i = 1, 2, â€¦ n, a < xi < b.
(c) Remember this problem.
5.9
Consider the ï¬eld â„š(
âˆš
2) = {a + bðœ™âˆ£a, b âˆˆâ„š}. Prove that if a + bðœ™â‰ 
0 + 0ðœ™, then a + bðœ™has a multiplicative inverse in â„š(
âˆš
2).
5.10
Consider the ï¬eld â„š(
âˆš
2) = {a + bðœ™âˆ£a, b âˆˆâ„š} and the order on it given
by
s + tðœ™â‹–u + ð‘£ðœ™if and only if âˆ£s âˆ’uâˆ£(s âˆ’u) < 2 âˆ£ð‘£âˆ’tâˆ£(ð‘£âˆ’t)
(a) Prove that if a, b, c, d âˆˆâ„š, then exactly one of the following holds
âˆ£a âˆ’câˆ£(a âˆ’c) < 2 âˆ£d âˆ’bâˆ£(ð‘£âˆ’t); âˆ£a âˆ’câˆ£(a âˆ’c) > 2 âˆ£d âˆ’bâˆ£(ð‘£âˆ’t);
or âˆ£a âˆ’câˆ£(a âˆ’c) = 2 âˆ£d âˆ’bâˆ£(d âˆ’b).
(b) Prove that if a, b, c, d âˆˆâ„š, so that âˆ£a âˆ’câˆ£(a âˆ’c) > 2 âˆ£d âˆ’bâˆ£(ð‘£âˆ’t),
then âˆ£c âˆ’aâˆ£(c âˆ’a) < 2 âˆ£b âˆ’dâˆ£(b âˆ’d).
(c) Prove that if a, b, c, d âˆˆâ„š, so that âˆ£a âˆ’câˆ£(a âˆ’c) = 2 âˆ£d âˆ’bâˆ£(ð‘£âˆ’t),
then (c âˆ’a)2 = 2(b âˆ’d)2.
(d) Prove that if a, b, c, d âˆˆâ„š, so that âˆ£a âˆ’câˆ£(a âˆ’c) = 2 âˆ£d âˆ’bâˆ£(ð‘£âˆ’t),
then b âˆ’d = 0.
(e) Prove that the order â‹–on â„š(
âˆš
2) = {a + bðœ™âˆ£a, b âˆˆâ„š} satisï¬es
trichotomy.
5.11
Assuming that it is possible to deï¬ne an order, an addition, and a
multiplication that make
â„š(
âˆš
2,
âˆš
6) = {a + bðœ™+ cðœ“+ dðœ™ðœ“âˆ£a, b, c, d âˆˆâ„š}
an ordered ï¬eld and that the same is true for
â„š(
âˆš
2,
âˆš
3) = {a + bðœ™+ cðœ“+ dðœ™ðœ“âˆ£a, b, c, d âˆˆâ„š},
explain why one would expect that in some way â„š(
âˆš
2,
âˆš
6) =
â„š(
âˆš
2,
âˆš
3).

81
6
The Real Numbers
6.1
Completeness
6.1.1
Greatest lower bounds
If we compare our deï¬nition of an ordered ï¬eld with the deï¬nitions of â„•and
â„¤, there is something missing. The natural numbers have the property of well
ordering, and the integers have a conditional version of it. However, there is no
property that guarantees that a set of elements from an ordered ï¬eld will have a
minimum. One reason for this is that the average theorem guarantees the exact
opposite: there will be plenty of sets that cannot possibly have minimums. And
unlike â„¤there is no one uniform condition that causes this problem.
Consider
A = {r âˆˆâ„šâˆ£2 < r}.
(6.1)
This set deï¬nitely has elements; and it has the lower bound of 2 built right into
the deï¬nition. The number 2 is not in the set, so it cannot be the minimum.
Suppose we thought we found a minimum m. Then m âˆˆA; so 2 < m. But by
the average theorem, there is and r âˆˆâ„šso that 2 < r < m. So r âˆˆA, and m
cannot really be the minimum. This is true in every ordered ï¬eld, not just â„š!
Except for the insistence in Mathematics that a minimum must exactly ï¬t the
deï¬nition for that term, we might say that 2 is enough of a minimum to be called
one. In Mathematics, close enough is not good enough. The number 2 is at best
a â€œmoralâ€ minimum of A. Here is where our insistence on careful deï¬nitions
pays oï¬€. We can completely describe 2â€™s relation to the set A using terms we
have already deï¬ned. First, 2 is a lower bound of the set A. In addition, by the
average theorem, every number greater than 2 is not a lower bound of A. Thus,
2 is the greatest lower bound of the set A.
Consider the related but diï¬€erent set
B = {r âˆˆâ„šâˆ£2 â‰¤r}.
(6.2)
This set has a minimum, 2. By deï¬nition, this means that 2 is a lower bound of
the set B. In addition, 2 âˆˆB, so every other lower bound of B is smaller than 2.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

82
6 The Real Numbers
This makes 2 the greatest lower bound of B. In general, the minimum of a set will
always also be the greatest lower bound of the set. The greatest lower bound,
however, must be in the set to be a minimum. So a greatest lower bound is
close to being a minimum, but not enough to be one in Mathematics. It might,
however, prove to be an adequate alternative for a minimum when a minimum
is not available. If a minimum is available, well it will automatically be a greatest
lower bound.
Because the natural numbers and the integers are discrete, for sets of those
numbers, greatest lower bounds and minima are the same. For example, for the
set
C = {r âˆˆâ„¤âˆ£2 â‰¤r},
(6.3)
the number 2 is both the minimum and the greatest lower bound. If we consider
the set
D = {r âˆˆâ„¤âˆ£2 < r},
(6.4)
we see that 2 is a lower bound, but not the greatest lower bound. That honor
goes to 3, the minimum of D. Remember that the integers are discrete, so the
strict inequality simply shifts the lower bound 2 up to the next integer and that
is in the set.
The average theorem means that no ordered ï¬eld is discrete, and so the strict
inequality deï¬ning the set
A = {r âˆˆâ„šâˆ£2 < r}.
(6.5)
basically kills the possibility of a minimum. The set A has a greatest lower bound
(2), but it is not a minimum of the set. In the aforementioned example, the set
B has the inequality changed to â€œless than or equal to.â€ Thus, the set
B = {r âˆˆâ„šâˆ£2 â‰¤r}.
(6.6)
has a greatest lower bound (2) that is in the set; so it has a minimum.
6.1.2
So what is complete?
Certainly, a set in an ordered ï¬eld cannot have a greatest lower bound unless
it has at least one lower bound somewhere. It cannot have a minimum without
a lower bound either. In â„¤, we know that if a set has at least one element and
at least one lower bound, then it has a minimum (and thus a greatest lower
bound.) Unfortunately, not all sets of rational numbers that are bounded below
have greatest lower bounds that are rational numbers. Consider the sets
A = {r âˆˆâ„šâˆ£0 < r and 2 < r2}
(6.7)
and
B = {r âˆˆâ„šâˆ£0 < r and 2 â‰¤r2}.
(6.8)

6.1 Completeness
83
Neither of the sets has a rational number as its greatest lower bound.
Consequently, neither has a rational number that is a minimum either. Both
of these sets have elements and have 0 as a lower bound, but neither has a
rational minimum because there is no rational number that when squared
gives 2.
The rational numbers do not give us all the numbers we need to measure
things. They are not a complete collection of numbers. As the aforementioned
two examples show, the rational numbers do not give us all the numbers we
need to give sets greatest lower bounds. A set such as B should have a mini-
mum, but it has no minimum in â„š. We do not expect that the set A will have a
minimum at all, but we would like it to have a greatest lower bound. There is no
number in â„šthat works. If we want such thing, we need more numbers than â„š
can provide.
So what if we consider
C = {r âˆˆâ„š(
âˆš
2) âˆ£0 < r and 2 < r2}.
(6.9)
We know that both â„šand â„š(
âˆš
2) are ordered ï¬elds, but C has more elements
than A, because â„š(
âˆš
2) has more numbers than â„š. All three of the sets A, B,
and C have 0 as a lower bound, but not one has a minimum. Neither A nor
B has rational greatest lower bounds. But because we rigged the ordered ï¬eld
â„š(
âˆš
2) to have a number ðœ™so that ðœ™2 = 2, the set C has a greatest lower bound
in â„š(
âˆš
2), namely ðœ™=
âˆš
2. There is no such number in â„š. The sets A and B do
not have a rational number that serves as a greatest lower bound. Even though
A and C are not equal sets, the addition of a
âˆš
2 has given them both greatest
lower bounds, but only in the larger ï¬eld â„š(
âˆš
2). But neither â„šnor â„š(
âˆš
2) is
a complete set of required numbers. The lines that represent these ï¬elds have
too many holes. The set
D = {r âˆˆâ„šâˆ£0 < r and 6 < r2}
(6.10)
needs a
âˆš
6 to have a greatest lower bound, and neither ï¬eld has one.
So what would a complete line without holes do for us? It would ï¬ll in any
hole, and then it could include any potential greatest lower bound for any set.
To complete our number line, we need enough numbers to ï¬ll in all the holes
in the â„š-line. Maybe adding an axiom that guarantees greatest lower bounds
will do the trick.
Draft 6.1.1
(The Completeness Axiom).
An ordered ï¬eld F is complete
when: if S is a set of numbers from F, and S has at least one element, and S has
at least one lower bound, then there is an s âˆˆF that is a greatest lower bound
of the set S.
(The reason why we label this as a draft is that we will state it slightly diï¬€er-
ently later simply using a diï¬€erent word for â€œgreatest lower bound.â€)
Deï¬nition 6.1.2.
Any complete ordered ï¬eld is called the real numbers â„.

84
6 The Real Numbers
6.1.3
An alternate version of completeness
All this number business began with the natural numbers, and the ï¬rst and
smallest natural number is 1. Since then, we have introduced smaller num-
bers in â„¤, in â„šand in any ordered ï¬eld. However, the momentum established
in â„•has limited us to considering the small side of numbers and sets: mini-
mums, lower bounds, and now greatest lower bounds. It is now time to deal
with neglected large side of things.
Deï¬nition 6.1.3.
We say that m is an upper bound of a set S when it satisï¬es
1. if s âˆˆS, then s â‰¤m.
Deï¬nition 6.1.4.
We say that m is the maximum of the set S when it satisï¬es
1. m âˆˆS, and
2. if s âˆˆS, then s â‰¤m.
With these deï¬nitions, the notion of a least upper bound makes sense. This
allows us to oï¬€er a theorem about complete ordered ï¬elds that could just as
well have been used as the Completeness Axiom. In that case, our stated axiom
would have been a theorem that was proved from the alternate. For us, it is the
alternate that needs proof.
Theorem 6.1.5
(The Alternate Completeness Axiom). For a complete
ordered ï¬eld â„: if S is a set of numbers from â„, and S has at least one element,
and S has at least one upper bound, then there is an s âˆˆF that is a least upper
bound of the set S.
We prove this using a lemma and some temporary notation. For the pur-
pose of proving this theorem and stating the following lemma, we deï¬ne the
following:
For S a set of real numbers,
UB(S) = {u âˆˆâ„âˆ£u is an upper bound on the set S}.
(6.11)
Notice that this deï¬nition means: u âˆˆUB(S) if and only if u is an upper bound
on the set S.
Lemma 6.1.6.
If s âˆˆS, then s is a lower bound of UB(S).
Proof. Assume s âˆˆS. Under this assumption, we want to prove that s is a lower
bound of UB(S). To prove anything, we restate it as an â€œifâ€¦then.â€ To do this,
we ask ourselves, what does â€œs is a lower bound of UB(S) mean?â€ It means: if
u âˆˆUB(S), then s â‰¤u. So we can assume
u âˆˆUB(S) = {u âˆˆâ„âˆ£u is an upper bound on the set S}.
(6.12)

6.1 Completeness
85
Since u is an upper bound on the set S, if x âˆˆS, then x â‰¤u. But we have s âˆˆS;
so s â‰¤u. So indeed, if u âˆˆUB(S), then s â‰¤u. That says that s is a lower bound
of UB(S).
â—½
That is kind of wordy; so let us trim it down to the essentials.
Proof. Assume s âˆˆS. Assume u âˆˆUB(S). Thus, u is an upper bound on S; so
s â‰¤u. So s is a lower bound on UB(S).
â—½
Now we are ready to prove the theorem.
Proof. Assume that S is a set of numbers from â„.
Assume that S has at least one element.
Assume that S has at least one upper bound.
Consider UB(S).
UB(S) is a set of numbers from â„.
Because S has at least one upper bound, UB(S) has at least one element.
Because elements in S are lower bounds of UB(S), we know that UB(S) has at
least one lower bound.
But by the completeness axiom, UB(S) has a greatest lower bound in â„. Call
it t.
Thus, t is a lower bound of UB(S). (Note that it is not enough to tell us that it
is in S since S might have gaps. That is OK, since we expect t to be a least upper
bound on S and not necessarily a maximum.)
In addition, because t is a greatest lower bound of UB(S), if ð‘£is a lower bound
of UB(S), then ð‘£â‰¤t.
Claim. t is a least upper bound on S.
Proof of claim. To prove this, we need to prove both parts of the deï¬nition: (i)
if x âˆˆS, then s â‰¤t, and (ii) if u is an upper bound of S, then t â‰¤u.
To prove the ï¬rst â€œif â€¦ then,â€ assume x âˆˆS. Then, as the lemma said,
x is a lower bound on UB(S). But then, we know that x â‰¤t, the greatest
lower bound of UB(S). Since x âˆˆS implies x â‰¤t, we know that t is an upper
bound of S.
To prove the second â€œif â€¦ then,â€ assume that u is any upper bound of S. Then
u âˆˆUB(S). So t â‰¤u since t is a lower bound of UB(S).
Thus, t is an upper bound of S, and if u is an upper bound of S, then t â‰¤u.
This makes t the least of all upper bounds of S.
â—¾
This completes the proof of the theorem.
â—½

86
6 The Real Numbers
6.2
Gaps and caps
If our intuition is correct, adding the completeness axiom to the properties of
an ordered ï¬eld should provide us with all the numbers we need to measure the
distances on a line. The resulting real numbers â„should have all the algebraic
and analytic properties we need. We would still like to be sure that this axiom
does not cap oï¬€the numbers we already have by creating an irrational number
larger than all the rational ones. We also hope that we have ï¬lled each hole with
a single irrational number and not smudged the line up by placing a solid string
of irrational numbers in one hole. These may be rather ï¬‚ippant descriptions
of the reasons why we need the next two theorems, but the theorems them-
selves are interesting and valuable mathematical facts. Both these theorems are
important in our understanding of the real numbers.
6.2.1
The Archimedean principle
First recall that, as in any ordered ï¬eld, the real numbers contain (a copy of) â„•,
â„¤, and â„š.
Theorem 6.2.1
(The Archimedean Principle). If r âˆˆâ„, then there is an n âˆˆ
â„•so that r < n.
Notice this says that the real numbers have no cap on the high end. The appli-
cations of this seemingly obvious result appear frequently in even the most
advanced studies of the real numbers.
Proof draft. We will prove this by contradiction.
Assume BWOC that there is an r âˆˆâ„so that if n âˆˆâ„•, then n â‰¤r.
Comment: This should remind us of a deï¬nition we have already seen. This
means that r is an upper bound on the set of real numbers â„•. Clearly â„•has at
least one element. Our assumption means that â„•has at least one upper bound.
By the alternate completeness axiom, there is a real number s so that s is a
least upper bound of â„•.
This means if n âˆˆâ„•, then n â‰¤s.
Comment: We should be on the lookout for an interesting natural number to use
this on. In addition, if we ever ï¬nd a real number less than s, there is no way
it can be an upper bound on â„•. Here is a real number less than s: s âˆ’1. Let us
use that.
Since s âˆ’1 < s, the real number s âˆ’1 is not an upper bound of â„•.

6.2 Gaps and Caps
87
Comment: What does that mean? It means that there is at least one natural
number that prevents s âˆ’1 from being an upper bound of the natural numbers.
Thus, there exists m âˆˆâ„•such that s âˆ’1 < m.
But then, s < m + 1. And since both m and 1 are natural numbers, so is
m + 1 âˆˆâ„•.
However, we have been looking for an interesting natural number in â„•.
Because s is an upper bound of â„•, this means that m + 1 â‰¤s. We have reached
the conclusion that m + 1 â‰¤s < m + 1. This contradicts the properties of an
order in an ordered ï¬eld. We have a contradiction, so our initial assumption
cannot be true.
So indeed, if r âˆˆâ„, then there is an n âˆˆâ„•so that r < n.
Î”
This deserves to be cleaned up.
Proof. Assume BWOC that there is an r âˆˆâ„so that if n âˆˆâ„•, then n â‰¤r.
This means that r is an upper bound on the set of natural numbers â„•.
Now â„•has at least one element, and it has an upper bound. By the alter-
nate completeness axiom, there is a real number s so that s is a least upper
bound of â„•.
This means if n âˆˆâ„•, then n â‰¤s.
In addition, if we ever ï¬nd a real number less than s, there is no way it can be
an upper bound on â„•.
But s âˆ’1 < s, so the real number s âˆ’1 is not an upper bound of â„•. There is
at least one natural number, call it m, so that s âˆ’1 < m.
But then, s < m + 1. And since both m and 1 are natural numbers, so is
m + 1 âˆˆâ„•.
However, because s is an upper bound of â„•, this means m + 1 â‰¤s. So m + 1 â‰¤
s < m + 1. This is a contradiction, so our initial assumption cannot be true.
So indeed, If r âˆˆâ„, then there is an n âˆˆâ„•so that r < n.
â—½
What about a cap on the lower side?
Corollary 6.2.2.
If r âˆˆâ„, then there is an n âˆˆâ„¤so that n < r.
Proof. Assume r âˆˆâ„. Then âˆ’r âˆˆâ„. By the Archimedean principle, there is
n âˆˆâ„•so that âˆ’r < n. So âˆ’n < r. Of course, âˆ’n âˆˆâ„¤, and that is what we were
looking for.
â—½
6.2.2
The density theorem
Next, we deal with the possibility of smudges.

88
6 The Real Numbers
Theorem 6.2.3
(The Density Theorem). Let a, b âˆˆâ„with a < b. Then, there
exists r âˆˆâ„šso that a < r < b.
This closely resembles the average theorem that holds in any ordered ï¬eld,
but on closer inspection it says much more. The average of two real numbers is
rather unlikely to be a rational number. If the two numbers a and b are ratio-
nal, well, the average will also be. But this is a theorem about any pair of real
numbers. The average theorem says that there is a real number between any
diï¬€erent a and b. The density theorem says that there is always a rational num-
ber between them. For example, we expect that
âˆš
2 âˆ’1 and
âˆš
2 + 1 are real
numbers. Their average is
âˆš
2. Their average is a real number, but it is not a
rational number. The density theorem says that there is some other real num-
ber between them that is actually a rational number. In addition, for any positive
number ðœ€> 0, no matter how small, the density theorem tells us that there is a
rational number between
âˆš
2 âˆ’ðœ€and
âˆš
2 + ðœ€. If the completeness axiom had
smudged one of the irrational holes in â„š, there would be a whole string of new
numbers with no rationals between them. The density theorem tells us that this
does not happen.
To prove it, we prove a lemma that says that with enough room between a
and b, we can actually ï¬nd an integer between them.
Lemma 6.2.4.
Let a, b âˆˆâ„with a + 1 < b. Then, there exists m âˆˆâ„¤so that
a < m < b.
Proof. Assume a, b âˆˆâ„. Assume a + 1 < b.
Comment: We are looking for the integer that is closest to a from above. The word
â€œclosestâ€ reminds us of â€œsmallest,â€ and that reminds us of â€œminimum.â€
Let
A = {k âˆˆâ„¤âˆ£a < k}.
(6.13)
Comment: We want the minimum of A, but we need to be sure that one exists.
By the Archimedean principle, A has at least one element.
By the corollary to the Archimedean principle, there is a p âˆˆâ„¤with p < a.
Thus, p is an integer lower bound on A. By the well-ordering like property of â„¤,
we know that A has a minimum. Call it m. Then
m âˆˆA = {k âˆˆâ„¤âˆ£a < k}.
(6.14)
In addition, if x âˆˆA, then m â‰¤x.

6.2 Gaps and Caps
89
Comment: This means that if we ever ï¬nd an x so that x < m, then x âˆ‰A. We
should be on the lookout for something less than m to use this on.
Now a < m.
In addition, m âˆ’1 < m. So we know m âˆ’1 âˆ‰A = {k âˆˆâ„¤âˆ£a < k}. By tri-
chotomy, since a < m âˆ’1 is not true, it must be that m âˆ’1 â‰¤a. So, m â‰¤a + 1.
But now we are done, by transitivity:
a < m â‰¤a + 1 < b.
(6.15)
â—½
Now let us try to prove the theorem.
Proof draft. Assume a, b âˆˆâ„. Assume a < b.
Comment: We need to open up some space between the numbers we are given.
If the space is large enough, we can ï¬t an integer in there. We do not want to
ruin any rationality, so we will open the space by multiplying by a large natural
number. (Oh yeah, we will need old Archimedes for this.) The question is how
large an n do we need? If we set up this question as a word problem, perhaps all
our training in algebra will be of help.
Scratch work:
So, the problem we must solve is: Find n âˆˆâ„•so that na + 1 < nb. Now â€œFind
nâ€ means â€œWrite a sentence that has n as the subject and says what n is.â€ So, we
want n âˆˆâ„•large enough that na + 1 < nb. How large is that?
na + 1 < nb.
(6.16)
1 < nb âˆ’nb.
1 < n(b âˆ’a).
1
b âˆ’a < n.
Comment: Since
1
bâˆ’a is a real number, Archimedes tells us that this natural num-
ber will exist. Now we have two real numbers na and nb where na + 1 < nb. We
can apply the lemma to any two numbers no matter what they are called. So
there is m âˆˆâ„¤so that na < m < nb. But n âˆˆâ„•; so we can divide the inequali-
ties by it to get a < m
n < b. We have the rational number we need. We have solved
our problem and can get back to the proof. The problem and solution it contains
are just scratch work we needed to get to a proof. It does not belong in the write-up
of the proof it ï¬nds. Besides, the calculation we used in the solution reappears
backward in the presentation of the result, so it seems to be a waste to write it
twice.
Î”

90
6 The Real Numbers
We start the proof over from scratch.
Proof. Assume a, b âˆˆâ„. Assume a < b.
Then b âˆ’a > 0. So it has a multiplicative inverse, and
1
bâˆ’a âˆˆâ„.
By the Archimedean principle, there is n âˆˆâ„•so that n >
1
bâˆ’a. Then since
b âˆ’a > 0, we can multiply to get
n(b âˆ’a) > 1;
(6.17)
nb âˆ’nb > 1;
nb > na + 1.
Now we have two real numbers na and nb where na + 1 < nb. We can apply
the lemma to any two real numbers no matter what they are called. So there
is m âˆˆâ„¤so that na < m < nb. But n âˆˆâ„•, so we can divide the inequali-
ties by it to get a < m
n < b. Since m âˆˆâ„¤and n âˆˆâ„•, we have the rational
number we need.
â—½
6.3
Problems
6.1
Let S = {x âˆˆâ„âˆ£xâˆ’1 âˆˆâ„•}. Prove that 0 is the greatest lower bound of
S. (Hint: you need to prove that â€œif s is a lower bound of S, then s â‰¤0.â€
Rewrite it in reverse to have the same meaning - the contrapositive.)
6.2
Using the notation
UB(S) = {u âˆˆâ„âˆ£u is an upper bound on the set S}
set in the proof of the alternate completeness axiom, ï¬nd
(a) UB(A) for A = {x âˆˆâ„âˆ£x < 5}.
(b) UB(B) for B = {x âˆˆâ„âˆ£x â‰¤5}.
(c) UB(C) for C = {5}.
(d) UB(D) for D = {4, 5, 6}.
(e) UB(E) for E = {x âˆˆâ„¤âˆ£x < 5}.
(f) UB(F) for F = {x âˆˆâ„¤âˆ£x â‰¤5}.
6.3
For any subset S âŠ†â„, let
LB(S) = {l âˆˆâ„âˆ£l is a lower bound on the set S}.
Prove that if s âˆˆS, then s is an upper bound of LB(S).
6.4
Let A be a set of real numbers.
(a) Prove that if A has an upper bound, then A has an upper bound that
is a natural number.

6.3 Problems
91
(b) Prove that if A has a lower bound, then A has a lower bound that is
an integer.
(c) Prove that if A has a lower bound and an upper bound, then there
is a natural number n so that n is an upper bound and âˆ’n is a lower
bound of A.
(d) Prove that A is bounded (above and below) if and only if there is
n âˆˆâ„•so that for all x âˆˆA, âˆ’n â‰¤x â‰¤n.
(e) Prove that A is bounded (above and below) if and only if there is
n âˆˆâ„•so that for all x âˆˆA, âˆ’n < x < n.
6.5
Let a, b âˆˆâ„with a < b. Prove that there exists s âˆˆâ„such that a < s < b.
6.6
Let a, b âˆˆâ„with a < b. Prove that there exists s âˆ‰â„šsuch that a < s < b.
(Hint: do not reprove the density theorem to prove this. Rather, use it on
the numbers
a
âˆš
2 and
b
âˆš
2.)
6.7
Prove if a, b âˆˆâ„, with a < b then for all n âˆˆâ„•, there are numbers
x1, x2, â€¦ , xnâˆ’1, xn âˆˆâ„š, all diï¬€erent, so that for all i = 1, 2, 3 â€¦ , n, we
have a < xi < b. (This is easy if you rewrite the theorem in a better
form.)
In problems 8â€“13, consider the sets
A = {r âˆˆâ„¤âˆ£5 < 2r};
B = {r âˆˆâ„¤âˆ£5 â‰¤2r};
C = {r âˆˆâ„šâˆ£5 < r};
D = {r âˆˆâ„šâˆ£5 â‰¤2r};
E = {r âˆˆâ„âˆ£5 < 2r};
F = {r âˆˆâ„âˆ£5 â‰¤2r}.
6.8
For which of the sets A through F is there a rational number that is a
lower bound on the set?
6.9
For which of the sets A through F is there a rational number that is a
greatest lower bound on the set?
6.10
For which of the sets A through F is there a rational number that is a
minimum of the set?
6.11
For which of the sets A through F is there a real number that is a lower
bound on the set?

92
6 The Real Numbers
6.12
For which of the sets A through F is there a real number that is a greatest
lower bound on the set?
6.13
For which of the sets A through F is there a real number that is a mini-
mum of the set?
In problems 6.14â€“6.19, consider the sets
Aâ€² = {r âˆˆâ„¤âˆ£5 < 2r3};
Bâ€² = {r âˆˆâ„¤âˆ£5 â‰¤2r3};
Câ€² = {r âˆˆâ„šâˆ£5 < r3};
Dâ€² = {r âˆˆâ„šâˆ£5 â‰¤2r3};
Eâ€² = {r âˆˆâ„âˆ£5 < 2r3};
Fâ€² = {r âˆˆâ„âˆ£5 â‰¤2r3}.
6.14
For which of the sets Aâ€² through Fâ€² is there a rational number that is a
lower bound on the set?
6.15
For which of the sets Aâ€² through Fâ€² is there a rational number that is a
greatest lower bound on the set?
6.16
For which of the sets Aâ€² through Fâ€² is there a rational number that is a
minimum of the set?
6.17
For which of the sets Aâ€² through Fâ€² is there a real number that is a lower
bound on the set?
6.18
For which of the sets Aâ€² through Fâ€² is there a real number that is a greatest
lower bound on the set?
6.19
For which of the sets Aâ€² through Fâ€² is there a real number that is a mini-
mum of the set?
6.20
Prove that if a âˆˆâ„, then there exists n âˆˆâ„•so that a < 10n.
6.21
Let a âˆˆâ„.
(a) Prove that for all n âˆˆâ„•, there is m âˆˆâ„¤so that 10nm â‰¤a â‰¤10n
(m + 1).
(b) What does notation a say about approximating real numbers with
decimals?
6.22
Let S = {r âˆˆâ„šâˆ£there is an n âˆˆâ„•such that r = 10nâˆ’1
10n }.

6.4 Appendix
93
(a) Prove that S has at least one element.
(b) Prove that S has at least one upper bound.
(c) Prove that S has a real number that is its least upper bound.
(d) What does this tell you about u = 0.99999 Â· Â· Â·?
(e) Can you guess what the real number u is?
6.4
Appendix
If our intuition serves us well, a complete ordered ï¬eld should ï¬ll in all the holes
in the rational numbers and provide us with enough numbers to measure any
length exactly. Of course, we still need to prove this.
One of the goals of this study is to do just that. The intermediate value
theorem will basically guarantee that every polynomial that can have a real
root does have one. It actually does a great deal more.
Until we have all the mathematical machinery necessary to prove this general
result, we should at least see that the problem that alerted us to the need for
more than just rational numbers has been ï¬xed. There is a square root of 2 in
the real numbers. The proof of this is specialized to this one case, and it is only
presented to prove an unsurprising result that follows from completeness.
Theorem 6.4.1.
There is an r âˆˆâ„so that r2 = 2.
Proof. Let
S = {x âˆˆâ„âˆ£x > 0 and x2 â‰¥2}.
(6.18)
Now 4 âˆˆS, so S has at least one element. In addition, by its very deï¬nition, S
has 0 for a lower bound. Since â„is a complete ordered ï¬eld, S has a greatest
lower bound. Call it m.
Thus,
â€¢ If s âˆˆS, then m â‰¤s.
â€¢ If b is a lower bound of S, then b â‰¤m.
â€¢ If c > m, then c is not a lower bound of S.
Claim. We claim that m > 0.
Proof of claim. Now 0 is a lower bound of S, but that is only enough to tell us
that m â‰¥0. We need to be a bit better. We see that if 0 < x < 1, then x2 < 1. So
if s âˆˆS, then s â‰¥1. This makes 1 a lower bound of S; so m â‰¥1 > 0.
â—¾
Consider
r = m
2 + 1
m = m2 + 2
2m
(6.19)

94
6 The Real Numbers
Claim. We claim that r2 â‰¥2.
Proof of claim. Now
r2 âˆ’2 =
(m
2 + 1
m
)2
âˆ’2
(6.20)
= m2
4 + 1 + 1
m2 âˆ’2
= m2
4 âˆ’1 + 1
m2
=
(m
2 âˆ’1
m
)2
â‰¥0.
â—¾
Since m > 0, we also have r > 0. Thus, with this claim, we have r âˆˆS. This
means
m â‰¤r = m
2 + 1
m,
(6.21)
and so,
m
2 â‰¤1
m,
(6.22)
Thus, we have
m2 â‰¤2.
(6.23)
If m2 = 2, then we have completed the proof.
So we assume by way of contradiction that
m2 < 2.
(6.24)
Consider 2
r . Since r2 â‰¥2, we have 1
r2 â‰¤1
2, and so 4
r2 â‰¤2. And so
(2
r
)2
â‰¤2.
(6.25)
But
2
r âˆ’m =
4m
m2 + 2 âˆ’m
(6.26)
= 4m âˆ’m3 âˆ’2m
m2 + 2
= m
(
2 âˆ’m2
m2 + 2
)
.
Since we have m > 0 and m2 < 2, this is positive. So
2
r > m.
(6.27)

6.4 Appendix
95
But m is the greatest lower bound of S; so 2
r cannot be a lower bound of S. There
must be some s âˆˆS so that s < 2
r . But s âˆˆS, so s > 0 and s2 â‰¥2. Since 0 < s < 2
r ,
we have
s2 <
(2
r
)2
.
(6.28)
But then
2 â‰¤s2 <
( r
2
)2
â‰¤2.
(6.29)
This is the contradiction we want. So we must have m2 = 2.
â—½

97
Part II
Logic, Sets, and Other Basics

99
7
Logic
Now that we have a precise deï¬nition of the real numbers, we want to put it to
use proving that the real numbers have all the properties we need. Before we do
this, we want to set the ground rules about the methods we use in our proofs.
Logic is the background of every proof. We will begin by discussing the logic of
mathematical statements. Mathematical statements are sometimes also called
propositions, and their logic is called propositional logic.
7.1
Propositional logic
7.1.1
Logical statements
A logical statement is a declarative sentence that is unambiguously either true
or false but not both. The following are all examples of logical statements in
Mathematics:
â‹…5 is an integer;
â‹…ðœ‹e < eðœ‹;
â‹…âˆ’5 is not a rational number; â‹…11 is even;
â‹…2 â‰¤5;
â‹…
âˆš
2 âˆˆâ„š;
â‹…22 = 5;
â‹…âˆ«
ðœ‹
2
âˆ’ðœ‹
2 Sin(x) dx = 0.
Logical statements must be either true or false, and indeed, some of these
examples are true and others false. Now in English grammar, a simple declara-
tive sentence has a word that is identiï¬ed as the verb, a noun that is identiï¬ed
as the subject, and a noun that is identiï¬ed as the object. Other words are
classiï¬ed as parts of speech such as adjective, adverb, or article. Logically, it
can help to just concentrate on the subject, verb, and object. We can think
of an entire English phrase as serving as the subject, as the verb, or as the
object.
Consider the example ðœ‹e < eðœ‹. The English phrase â€œPi to the e powerâ€ is the
logical subject; the English phrase â€œis less thanâ€ is the logical verb, and the
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

100
7 Logic
phrase â€œe to the power ðœ‹â€ is the logical object. In the example
âˆš
2 âˆˆâ„š: â€œthe
square root of 2â€ is the subject, â€œis an element of â€ is the verb, and â€œthe set of
rational numbersâ€ is the object.
We call the truth or falsity of a logical statement the truth value of that state-
ment. We use the capital letters T and F to denote truth and falsity. So, when
a statement is true, we say that it has truth value T, and when it is false, we say
that it has truth value F.
7.1.2
Logical connectives
Logical statements can be combined to form longer compound logical
statements using logical connectives. The typical connectives correspond to
the English words â€œnot,â€ â€œand,â€ â€œor,â€ and the conditional phrase â€œifâ€¦then.â€ But,
we will see some important diï¬€erences between the typical English usage of
these connectives and their deï¬nitions in logic.
We ï¬rst consider negation.
Deï¬nition 7.1.1.
Let P be a logical statement. Then â€œnot Pâ€ is a logical state-
ment whose truth value is the opposite of the truth value of P.
We will denote â€œnot Pâ€ as â€œâˆ¼P.â€
One way to view the meaning of a compound logical statement is to compare
the truth value of the compound statement to every possible combination of
truth values of the statements that make it up. The table of these comparisons
is called a truth table for the statement. The truth table for âˆ¼P is
P
âˆ¼P
T
F
F
T
The next way of combining logical statements uses â€œand.â€
Deï¬nition 7.1.2.
Let P and Q be logical statements. Then â€œP and Qâ€ is the
logical statement that is true when both P and Q are true, but false otherwise.
We denote â€œP and Qâ€ as â€œP âˆ§Q.â€ The truth table for P âˆ§Q is
P
Q
P âˆ§Q
T
T
T
T
F
F
F
T
F
F
F
F

7.1 Propositional Logic
101
Next is the conjunction â€œor.â€ Here we encounter an important distinction
between how the word â€œorâ€ is typically understood in everyday English and how
it is understood in logic and mathematics.
Consider two examples of the colloquial use of the word â€œor.â€ When a parent
asks a six-year-old if he/she wants chocolate milk or soda with lunch, the parent
almost deï¬nitely means that the child can have one or the other but not both.
This is the exclusive meaning of â€œorâ€: one or the other but not both. On the other
hand, suppose a professor were to say of one of her students, â€œHer grades are so
good that sheâ€™s either very bright or studies hard.â€ In saying this, the professor
should not be interpreted as excluding the possibility that the student is very
bright and also studies hard. This is the inclusive meaning of â€œorâ€: one or the
other or both.
Unlike a natural language such as English, logic cannot allow ambiguity in
statements. We must choose one or the other use of â€œorâ€ for logic. For various
historical and technical reasons, the choice has been made that in logic and
mathematics, the word â€œorâ€ always takes the inclusive meaning of the word. It
always means â€œone, the other, or both.â€ Accordingly, we provide the following
deï¬nition.
Deï¬nition 7.1.3.
Let P and Q be logical statements. Then, â€œP or Qâ€ is the logi-
cal statement that is true when either P or Q or both are true, but false otherwise.
We denote â€œP or Qâ€ as â€œP âˆ¨Q.â€ The truth table for P âˆ¨Q is
P
Q
P âˆ¨Q
T
T
T
T
F
T
F
T
T
F
F
F
If we use this to analyze our idea of allowing an English phrase to be a logical
â€œverb,â€ we can make a very obvious observation that is easy to overlook when it
matters in a proof. The mathematical symbol â€œâ‰¤â€ means â€œless than or equal to.â€
When we say this carefully, we realize that a statement that uses it is logically
compound. Thus, x â‰¤y means
(x < y) âˆ¨(x = y).
(7.1)
Thus, if we know for sure that x < y, then we can also say that x â‰¤y because it
is true by the rules of logic. If we know for sure that x = y, then we can also say
that x â‰¤y because it is true by the rules of logic. On the other hand, if we know
that x â‰¤y is true, then we must consider either possibility. It just may be that
we cannot use this logically without separating it into the two diï¬€erent cases

102
7 Logic
(x < y) and (x = y). We often do this so quickly that we do not notice it, but
there are times when explicitly considering two cases is the only way to go.
This oï¬ƒcial deï¬nition of the word â€œorâ€ also explains an extra word that has
appeared every time we used the term â€œtrichotomy.â€ We say that a number sys-
tem satisï¬es trichotomy whenever it satisï¬es the following: if x, y are numbers,
then exactly one of the following are true: x < y, y < x or x = y. The word â€œex-
actlyâ€ is very important in this deï¬nition; without it, the inclusive â€œorâ€ would
take over and not give us the result we want. By saying â€œexactly one is true,â€ we
move to an exclusive â€œorâ€ and say that no two of the three can be true at the
same time.
Next up is implication, which is used to construct conditional statements
â€“statements of the form â€œifâ€¦then.â€ Conditional statements can have many
interpretations in English. But as we saw with â€œor,â€ in logic and mathematics,
we must avoid ambiguity. The deï¬nition of the conditional statement that we
use in logic and mathematics is as follows.
Deï¬nition 7.1.4.
Let P and Q be logical statements. Then, â€œif P, then Qâ€ is the
logical statement that is true when P is false or Q is true. It is false only when
both P is true and Q is false.
We often denote â€œif P, then Qâ€ as â€œP â‡’Q.â€ It has the following truth table.
P
Q
P â‡’Q
T
T
T
T
F
F
F
T
T
F
F
T
The rules that govern this conjunction of statements can be puzzling at ï¬rst.
Remember that the rules of logic we are using require that a logical statement
be either true or false. You can think of the statement â€œif P, then Qâ€ as a promise,
which says that â€œif it ever happens that P is true, then it must happen that Q is
also true.â€
It makes no claim at all about what happens when P is false. But, if we admit-
ted that â€œif P, then Qâ€ was noncommittal when P is false, and decided not to
add a value in our truth table, then we would not have deï¬ned â€œif P, then Qâ€
as a completely logical statement. So we need to assign it a value of either true
or false in all cases. It would be wrong to call it false for being noncommittal.
Indeed, if P is not true, then the promise that Q will be true whenever P is has
not been broken. So, we give P â‡’Q credit only for what it claims. We do not
fault it for what it does not claim. So if P is false, the promise has not been
broken, and we count the statement P â‡’Q as true in that case.

7.1 Propositional Logic
103
But, this has a somewhat troubling consequence. It means that â€œfalse implies
anythingâ€ in the sense that no matter what the statement Q is, if the statement
P is false, then we count P â‡’Q as true. For example, consider the statements:
If 22 = 5, then
âˆš
2 âˆˆâ„š.
If 22 = 5, then
âˆš
2 âˆ‰â„š.
Logically, these are both true statements. It deï¬nitely seems odd to say that
both of these statements are true. But, logically, it has to work this way. Under-
standing the implication is very important, and we will have much more to say
about it next.
Here we have one last logical connective:
Deï¬nition 7.1.5.
Let P and Q be logical statements. Then, â€œP if and only if Qâ€
is the logical statement (P â‡’Q) âˆ§(Q â‡’P).
We denote â€œP if and only if Qâ€ as either â€œP â‡”Q,â€ or â€œP iï¬€Q.â€ The notation â€œP
iï¬€Qâ€ is read â€œP if and only if Q.â€ The truth table for this is
P
Q
P â‡”Q
T
T
T
T
F
F
F
T
F
F
F
T
Thus, â€œP if and only if Qâ€ means that P and Q have exactly the same logical
truth values.
We often say that this means that P and Q are â€œequivalent.â€ However, there
are two ways that logical statements can be equivalent. We may prove the math-
ematical theorem:
In an ordered ï¬eld, a â‹…b = 0 if and only if either a = 0 or b = 0.
Since this is actually a compound logical statement, we would do this in
two steps: If a â‹…b = 0, then either a = 0 or b = 0. If either a = 0 or b = 0, then
a â‹…b = 0. Thus, the two statements â€œa â‹…b = 0â€ and â€œeither a = 0 or b = 0â€ are
equivalent. They both have the same truth values because of what they mean.
There is a stronger way that two statements can be equivalent that does
not depend on their meaning, but only on their logical form. In this case, we
often say that the statements are â€œlogically equivalent.â€ For example, no matter

104
7 Logic
what the logical statement P says or what it means, it is logically equivalent to
âˆ¼(âˆ¼P). To make this crystal clear, we will look at the truth tables:
P
âˆ¼P
âˆ¼(âˆ¼P)
T
F
T
F
T
F
The ï¬rst and last columns of truth values are exactly the same; the corre-
sponding statements are â€œlogically equivalent.â€
Logical equivalence gives us a handy proof technique. To prove a statement
R, it might be easier to prove a logically equivalent statement S. In a moment,
we will give a number of logical theorems that provide ways of rewriting logical
statements into logically equivalent forms. These will provide alternatives for
proving any number of later theorems.
We now deï¬ne two last logical terms: tautology and contradiction. A tautol-
ogy is a statement that, because of its logical form, is always true. There are
plenty of ways that a tautology can be hidden in a compound logical statement,
but in the end, all tautologies come down to one example:
P âˆ¨(âˆ¼P).
A contradiction is the exact opposite of a tautology; it is a statement that,
because of its logical form, is always false. Again in the end, all contradictions
come down to the example
P âˆ§(âˆ¼P).
Many proofs use a technique called â€œproof by contradiction.â€ To prove the
statement P, the proof argues that the statement (âˆ¼P) implies a contradiction.
The proof begins, as an implication, by assuming (âˆ¼P). The object is to ï¬nd a
statement R that allows us to prove R and allows us to prove (âˆ¼R). Then, we
need to prove
(âˆ¼P) =â‡’(R âˆ§(âˆ¼R)).
If we do prove that this is true, then because the conclusion is a contradiction,
the truth table for â€œimpliesâ€ tells us that (âˆ¼P) must be false. By our ï¬rst example
of a logical equivalence, P must be true.
7.1.3
Logical equivalence
We can now state several theorems about logical equivalence of compound
statements. Many of these look profound from a mathematical point of view,
and they would be if we were looking to develop a mathematical approach to
logic. But our goal is the opposite. We want to understand logic well enough to
help us analyze a mathematical statement or proof when things get confusing.

7.2 Implication
105
As a result, the ï¬rst theorem looks like it should be more useful that it actually
is.
Theorem 7.1.6.
Let P, Q and R be logical statements. Then the following pairs
are logically equivalent:
1. P and âˆ¼(âˆ¼P);
2. P âˆ§Q and Q âˆ§P;
3. P âˆ¨Q and Q âˆ¨P;
4. (P âˆ§Q) âˆ§R and P âˆ§(Q âˆ§R);
5. (P âˆ¨Q) âˆ¨R and P âˆ¨(Q âˆ¨R);
6. P âˆ§(Q âˆ¨R) and (P âˆ§Q) âˆ¨(P âˆ§R);
7. P âˆ¨(Q âˆ§R) and (P âˆ¨Q) âˆ§(P âˆ¨R).
All of these are proved by listing out the values in truth tables for each state-
ment in each pair. These proofs are not as much proofs as they are veriï¬cations.
The last six of these have mathematical descriptions: âˆ§and âˆ¨are both commu-
tative, and both are associative. Each distributes over the other.
The next theorem comes up much more often and is important to remember.
We know this because it has a name.
Theorem 7.1.7
(De Morganâ€™s Laws). Let P and Q be logical statements.
Then, the following pairs are logically equivalent:
1. âˆ¼(P âˆ§Q) and (âˆ¼P) âˆ¨(âˆ¼Q);
2. âˆ¼(P âˆ¨Q) and (âˆ¼P) âˆ§(âˆ¼Q).
De Morganâ€™s laws are easy to remember, but easy to overlook when in a hurry.
To negate an â€œandâ€ statement or an â€œorâ€ statement, negate the parts, but remem-
ber to switch the connective. Again, the proofs simply construct the various
truth tables.
A ï¬nal few that actually do appear in mathematical proofs will ï¬nish this up.
Theorem 7.1.8.
Let P, Q, and R be logical statements. Then, the following pairs
are logically equivalent:
1. (P âˆ§Q) â‡’R and P â‡’(Q â‡’R);
2. (P âˆ¨Q) â‡’R and (P â‡’R) âˆ§(Q â‡’R);
3. P â‡’(Q âˆ¨R) and (Pâˆ§âˆ¼Q) â‡’R.
7.2
Implication
As we have noted, the â€œifâ€¦thenâ€ construction plays a very important role in
logic. Because of this, it has its own terminology.

106
7 Logic
Deï¬nition 7.2.1.
Consider the logical statement P â‡’Q.
1. P is called the hypothesis of the statement.
2. Q is called the conclusion of the statement.
3. When P â‡’Q is true, we say that P is suï¬ƒcient for Q.
4. When P â‡’Q is true, we say that Q is necessary for P.
There are other logical implications associated with the implication P â‡’Q,
but saying that they are related to it is too strong. We will see what this means
in a moment. First,
Deï¬nition 7.2.2.
Consider the logical statement P â‡’Q.
1. The statement Q â‡’P is the converse of P â‡’Q.
2. The statement (âˆ¼P) â‡’(âˆ¼Q) is the inverse of P â‡’Q.
3. The statement (âˆ¼Q) â‡’(âˆ¼P) is the contrapositive of P â‡’Q.
The logical relationships between these various statements are very impor-
tant. Anytime a mathematical theorem takes the time to say that something
is not the case, it is a signal that there is an easy trap to fall into should we
ignore it.
Theorem 7.2.3.
Consider the logical statement P â‡’Q.
1. The statement and its contrapositive are logically equivalent.
2. The converse and its inverse are logically equivalent.
3. The statement and its converse have no logical relation.
4. The negation of the statement and the inverse of the statement have no logical
relation.
Proof. We simply ï¬nd and compare the truth tables:
P
Q
P â‡’Q
(âˆ¼Q) â‡’(âˆ¼P)
Q â‡’P
(âˆ¼P) â‡’(âˆ¼Q)
âˆ¼(P â‡’Q)
T
T
T
T
T
T
F
T
F
F
F
T
T
T
F
T
T
T
F
F
F
F
F
T
T
T
T
F
â—½
We have claimed that some pairs have no logical relation. This is correct
because knowing that one is true does not pin down the other as either true or
false and because knowing that one is false does not pin down the other as either
true or false either. So knowing the truth value of one gives no information
about the truth value of the other. This is important; a common logical fallacy

7.3 Quantiï¬ers
107
is to confuse an implication with its converse. Because these are not logically
related, this is a serious mistake.
So a common trap to fall into is to try to prove a statement of the form P â‡’Q
by proving the converse, Q â‡’P. Since a statement and its converse have no
logical connection, proving or disproving the converse gives no information
about the truth of the statement. Claiming a statement is true by oï¬€ering the
converse as evidence is an all too common logical fallacy. It is important to
avoid it in all situations, but particularly in Mathematics.
There is another common proof technique that does work because of this
theorem. To prove that a statement of the form P â‡’Q is true, we can prove
instead that the logically equivalent contrapositive, (âˆ¼Q) â‡’(âˆ¼P), is true. This
is often confused with a proof by contradiction. We will look at the diï¬€erences
between a direct proof of P â‡’Q and proof of the contrapositive (âˆ¼Q) â‡’(âˆ¼P)
and a proof by contradiction (Pâˆ§âˆ¼Q) â‡’(Râˆ§âˆ¼R) more carefully later.
Proof technique. We say that we have a direct proof of P â‡’Q when the proof
begins by assuming that the hypothesis is true and ends with stating that the
conclusion is true.
Proof technique. We say that we have proof by contrapositive when we prove
P â‡’Q by proving the contrapositive (âˆ¼Q) â‡’(âˆ¼P).
Proof technique. We say that we have proof by contradiction when we prove
P â‡’Q by proving (Pâˆ§âˆ¼Q) â‡’(Râˆ§âˆ¼R).
7.3
Quantiï¬ers
There is much more to propositional logic than we have just said, but rather
than continue to look at abstract logical statements, we will concentrate on,
what we will call mathematical statements.
It is convenient to think of a mathematical statement as a declarative sentence
that contains a parameter (or several parameters). The mathematical statement
only becomes a logical statement when a meaning is given to the parameter. The
truth value of the statement depends on that speciï¬c value of the parameter. For
example,
x2 = 9.
(7.2)
is a mathematical statement; it is by itself neither true or false. Years of algebra
training tempts us to turn it into a command sentence:
Solve x2 = 9 for x.

108
7 Logic
This requires adding extra words and still does not result in a logical statement.
(It is a command.) It is possible to make x2 = 9 true by choosing a good value
of x, but it is just as possible to make x2 = 9 false by choosing a bad value of x.
So, by itself, x2 = 9 is neither true nor false.
Turning any mathematical statement into a logical statement requires adding
extra words that qualify, or quantify, the variable. There are three ways to do
this: specify a value, assert existence, claim a universal.
7.3.1
Speciï¬cation
We can make x2 = 9 a logical statement by assigning a value to x:
For x = 3, x2 = 9.
(7.3)
For x = 7, x2 = 9.
The ï¬rst assignment makes it true, the second one makes it false.
We have been dealing with mathematical statements all through our previous
studies. Typically, they appear after an instruction:
Solve x2 = 9.
The instruction asks us to ï¬nd those values of x that make the mathematical
statement x2 = 9 true. Actually, we all know that it asks more than that, it asks
us to completely distinguish between the numbers x that make it true from
those that make it false. â€œFor x = 3, x2 = 9â€ is a partial solution, but â€œFor x = Â±3,
x2 = 9â€ is a complete solution. It is complete because, for x = Â±3, x2 = 9, and
for x â‰ Â±3, x2 â‰ 9.
Now changing a mathematical statement such as x2 = 9 into a logical
statement using the word â€œforâ€ is called â€œspeciï¬cation.â€ We have qualiï¬ed the
variable x by speciï¬cation.
7.3.2
Existence
There are two other ways to qualify a variable. The ï¬rst is the â€œexistentialâ€ qual-
iï¬er:
There exists x âˆˆâ„, such that x2 = 9.
Notice that typically this qualiï¬er comes with a scope or range that restricts
where a value of the variable may come from. The scope has as much to do
with the meaning of the logical statement as the mathematical statement. For
example, compare
There exists x âˆˆâ„, such that x2 = 9.
There exists x âˆˆâ„•, such that x2 = 9.
There exists x âˆˆâ„š, such that x2 = 2.
There exists x âˆˆâ„, such that x2 = 2.

7.3 Quantiï¬ers
109
To prove a statement with an existential qualiï¬er, we usually need to do some
scratch work outside the proof. Typically, we create our own mathematical
problem to solve. To prove: there exists x âˆˆâ„•such that x2 = 9, we ï¬rst solve
x2 = 9. After extensive algebraic manipulation learned in high school, we
ï¬nd x = Â±3. To write up the proof that there exists x âˆˆâ„•, such that x2 = 9,
we only need to identify one of these that ï¬ts all the requirements, x = 3,
and prove that it works: let x = 3; then 3 âˆˆâ„•and x2 = 32 = 9. Neither the
solution of the equation nor the other integer solution âˆ’3 is required for the
proof. The existence qualiï¬er only requires one example. To prove existence,
we only need to show that there is one. This would be just as true as if
we were writing up a proof of: there exists x âˆˆâ„, such that x2 = 9. The only
diï¬€erence is that we could prove this by letting x = âˆ’3 to show oï¬€our algebraic
skills.
Remember that the scopes matter. Now we have a theorem that says that
â€œThere exists x âˆˆâ„š, such that x2 = 2â€ is false. We have an extreme conï¬dence
in our education, and we believe that â€œThere exists x âˆˆâ„, such that x2 = 2â€
is true.
There is a notation for this qualiï¬er. We write â€œThere exists x in the set S such
that P(x) is trueâ€ in either one of the following ways:
âˆƒx âˆˆS such that P(x);
âˆƒx âˆˆS so that P(x);
âˆƒx âˆˆS s.t. P(x);
âˆƒx âˆˆS Ï¶ P(x),
There is a good strategic reason to make it a point to recognize the â€œsuch thatâ€
as an essential part of the notation.
7.3.3
Universal
The ï¬nal way to qualify a variable is with a universal qualiï¬er. To do this, we say
For all x âˆˆâ„, x2 = 9.
Notice that this qualiï¬er also comes with a scope or range for the variable. To
qualify the variable in this particular example and produce a true logical state-
ment, we need to cut down the scope considerably:
For all x âˆˆ{3, âˆ’3}, x2 = 9.
Or, we could get carried away and say
For all x âˆˆ{âˆ’3}, x2 = 9.

110
7 Logic
There is a notation for this qualiï¬er as well. We write â€œFor all x in the set S,
P(x) is trueâ€ as
âˆ€x âˆˆS, P(x).
There is a good strategic reason to consider the comma as an essential part of
the notation.
To prove: â€œFor all x in the set S, P(x) is true,â€ we can restate it as â€œIf x in the set
S, then P(x) is true.â€ We have seen that we begin the proof of an â€œifâ€¦thenâ€ by
assuming the hypothesis. Actually, this exchange occasionally works the other
way. We may need to prove a statement that has the logical form âˆ¼(P â‡’Q).
There is no nice logical equivalent statement to this that works very well.
(Remember that we cannot get anywhere by proving the inverse statement.)
However, if we can rephrase P â‡’Q as âˆ€x âˆˆS, Q(x), there is a nice logical
negation of that form.
7.3.4
Multiple quantiï¬ers
Many important statements have more than one quantiï¬er in their statements.
Example 7.3.1.
The Archimedean principle states that
if r âˆˆâ„, then there is an n âˆˆâ„•so that r < n.
We can restate this as
for all r âˆˆâ„, there exists an n âˆˆâ„•so that r < n,
or
(âˆ€r âˆˆâ„, (âˆƒn âˆˆâ„•s.t. (r < n)).
The Archimedean principle is a doubly quantiï¬ed statement with a com-
mon form: a universal quantiï¬er (âˆ€) followed by an existential quantiï¬er (âˆƒ).
These are sometimes called AE statements. AE statements lead to the impor-
tant issue of naming objects. In all likelihood, the variable that the statement
says exists will depend on the universal variable that appears before it. Thus, in
the Archimedean principle, if r =
âˆš
99, then n = 10 would do as the n âˆˆâ„•. But
for a diï¬€erent r, say r =
âˆš
400, then n would need to be at least 21. If we are
only going to use the statement
(âˆ€r âˆˆâ„, (âˆƒn âˆˆâ„•s.t. (r < n))
(7.4)
once in the proof, then this is a perfectly ï¬ne way to write it. However, if we
expect that it will be used more than once for diï¬€erent r âˆˆâ„, then it might be
better to make it clear that n depends on r and write
(âˆ€r âˆˆâ„, (âˆƒnr âˆˆâ„•s.t. (r < nr)).
(7.5)

7.4 An Application to Mathematical Deï¬nitions
111
Less confusing, but still very important, are EA statements. Here is an example.
Example 7.3.2.
Let F be an ordered ï¬eld. The statement
there exists e âˆˆF such that for all a âˆˆF, a â‹…e = e â‹…a = a
can be rewritten
âˆƒe âˆˆF s.t. (âˆ€a âˆˆF, (a â‹…e = e â‹…a = a)).
As we have said, naming the variables is always a serious responsibility.
However, in EA statements, this usually does not include adding subscripts.
By its very meaning, âˆƒe âˆˆF s.t. (âˆ€a âˆˆF, (a â‹…e = e â‹…a = a.)) says that one e will
work for all a.
Negating the statements with multiple quantiï¬ers follows our aforemen-
tioned rules for negating the statements with a single quantiï¬er. We can step
through the process as in the example,
âˆ¼(âˆ€r âˆˆâ„, (âˆƒn âˆˆâ„•s.t.( r < n)));
âˆƒr âˆˆâ„, âˆ¼(âˆƒn âˆˆâ„•s.t.( r < n));
âˆƒr âˆˆâ„, (âˆ€n âˆˆâ„•s.t. âˆ¼( r < n));
âˆƒr âˆˆâ„, (âˆ€n âˆˆâ„•s.t. ( r â‰¥n)).
With practice, we can just ï¬‚ip the quantiï¬ers and negate the statement being
quantiï¬ed.
âˆƒr âˆˆâ„, s.t. (âˆ€n âˆˆâ„•, r â‰¥n).
As always, though, we only take a shortcut when we know it works, and if
we get confused, we go back and skip the shortcut. We will continue to see
mathematical statements with multiple quantiï¬ers throughout this course.
7.4
An application to mathematical deï¬nitions
Mathematical deï¬nitions are logically â€œif and only ifâ€ statements. However,
there is a general tendency not to write them that way after they have been
identiï¬ed as deï¬nitions. For example,
Deï¬nition: For n âˆˆâ„¤, n is even if âˆƒk âˆˆâ„¤s.t. n = 2k.
Deï¬nition: For n âˆˆâ„¤, n is odd if âˆƒk âˆˆâ„¤s.t. n = 2k âˆ’1.
Mathematical deï¬nitions are designed to make them easy to use in a proof. For
example,

112
7 Logic
Deï¬nition: Let S be a set of real numbers and m âˆˆâ„. Then, m is a
minimum of S if
m âˆˆS,
(7.6)
and x âˆˆS â‡’m â‰¤x.
This is not the way anyone else would complicate the deï¬nition of such an easy
term. Still we have seen how handy splitting it into parts can be when struggling
with a proof.
Note that proper English grammar sometimes interferes with logical phras-
ing. Mathematicians are not above writing the deï¬nition of a lower bound as
Deï¬nition: If S is a set of real numbers and m âˆˆâ„, then m is a lower
bound of S if, if x âˆˆS, then m â‰¤x.
The English sound of â€œif, ifâ€ is horrible. It is better to use alternate English
phrasing to avoid this:
Deï¬nition: If S is a set of real numbers and m âˆˆâ„, then m is a lower
bound of S if x âˆˆS implies m â‰¤x.
Deï¬nition: If S is a set of real numbers and m âˆˆâ„, then m is a lower
bound of S when, if x âˆˆS, then m â‰¤x.
Deï¬nition: If S is a set of real numbers and m âˆˆâ„, then m is a lower
bound of S if âˆ€x âˆˆS, m â‰¤x.
Deï¬nition: If S is a set of real numbers and m âˆˆâ„, then m is a lower
bound of S, meaning if x âˆˆS, m â‰¤x.
Mathematical deï¬nitions, unlike dictionary deï¬nitions, are not designed to
explain what a term means. A mathematical deï¬nition is a precise logical state-
ment that is interchangeable with the word. Here is an important deï¬nition of
a new mathematical term that we will use from now on in this study.
Deï¬nition 7.4.1.
For S a set of real numbers and m âˆˆâ„, m is an inï¬mum of
S when
if x âˆˆS , then m â‰¤x,
and if l > m, then âˆƒx âˆˆS s.t. l > x.
Most people would say that this gives them no clue as to what the inï¬mum of a
set might actually be or what it might be good for. The thing about mathematical
deï¬nitions is that the people who made them up know very well what the term
they are deï¬ning means. Further, they kind of expect that the people using the
deï¬nition will as well. A deï¬nition is chosen using a deep understanding of the
term as it will be used in Mathematics. The deï¬nition is written to make the idea

7.4 An Application to Mathematical Deï¬nitions
113
behind the term easier to use in proofs. The understanding of a mathematical
term comes before or after the deï¬nition, but only rarely with it.
So what the heck is an inï¬mum? Actually, it is something we have already
seen and used. First, we notice that, whatever an inï¬mum is, it is a lower bound
of S. This is the ï¬rst part of the deï¬nition. The part we need to understand is
the part of the deï¬nition that says
if l > m, then âˆƒx âˆˆS s.t. l > x.
We will slowly rewrite this using some of the logical tricks we have picked up.
Each rewrite in the following list is a simple change that produces a logically
equivalent statement of the one above it.
â€¢ If l > m, then âˆƒx âˆˆS s.t. l > x.
â€¢ If (l > m), then (âˆƒx âˆˆS s.t. l > x). (Parsing)
â€¢ If âˆ¼(âˆƒx âˆˆS s.t. l > x), then âˆ¼(l > m). (Contrapositive)
â€¢ If âˆ¼(âˆƒx âˆˆS s.t. l > x), then l â‰¤m. (Trichotomy)
â€¢ If âˆ€x âˆˆS, âˆ¼(l > x), then l â‰¤m. (De Morgan)
â€¢ If âˆ€x âˆˆS, l â‰¤x, then l â‰¤m. (Trichotomy)
â€¢ If (âˆ€x âˆˆS, l â‰¤x), then l â‰¤m. (Parsing)
â€¢ If (lis a lower bound of S), then l â‰¤m. (Deï¬nition)
â€¢ For all lower bounds l of S, l â‰¤m. (Rephrasing)
The ï¬rst condition tells us that the inï¬mum m is a lower bound of S, and
as it turns out, the second one tells us that for all lower bounds l of S, l â‰¤m.
Putting these together, we realize that the inï¬mum must be another name for
the greatest lower bound. This is worth noting.
Conclusion 7.4.2.
The inï¬mum of a set is the greatest lower bound of the set.
The inï¬mum is the same as the greatest lower bound. Why invent a stupid
new word for it and give it a deï¬nition that actually hides what it is? What is
wrong with saying, â€œthe greatest of all the lower bounds?â€ Of course, there is
nothing wrong with that, but it is strategically better to use inï¬mum. A very
good reason to use the term â€œinï¬mumâ€ and its deï¬nition is that they are much
more helpful when it is time to use them in a proof. The more we use this def-
inition, the more we will appreciate it. Still, why the stupid name? Basically, to
remind us to use the mixed-up deï¬nition. If we insist on using the term â€œgreat-
est lower bound,â€ we will often ï¬nd ourselves repeating the aforementioned
logical steps to convolute a â€œgreatest lower boundâ€ into a form that we can use.
With both names, we can switch back and forth between names at will. In those
times, and they do occur, when a greatest lower bound is easier to use compared
to an inï¬mum, we will be ready to make the switch.
Finally, here is a hint to help remember the deï¬nition of an inï¬mum: â€œm is the
inï¬mum of S means it is the greatest lower bound.â€ We should be ready to write

114
7 Logic
down what â€œm is a lower bound of S,â€ and this is part 1 of the deï¬nition. To say
that m is the greatest of the lower bounds, say â€œif l is a number greater than m,
then it is not a lower bound because there is a number x in S that prevents l from
being a lower bound because it is too small for l.â€ As we say this to ourselves,
we write
â€œIf l is a number greater than mâ€
If l > m,
â€œit is not a lower bound becauseâ€
then
â€œthere is a number x in Sâ€
âˆƒx âˆˆS
â€œthat prevents l from being a lower boundâ€
s.t.
â€œbecause it is too small for lâ€
x < l.
7.5
Logic versus English
A very important thing to remember about the constraints of careful logic is
that they are meant to aid understanding. Logic is a technique of language that
can be used to attach a precise meaning to a phrase. Language itself is much
more expressive, it is not designed to be strictly logical, and it often is not.
Mathematician and writer Blaise Pascal said, â€œWords diï¬€erently arranged have
a diï¬€erent meaning, and meanings diï¬€erently arranged have diï¬€erent eï¬€ects.â€
Turning everyday language into logic involves the translation of meaning
rather than the translation of words. English construction allows one to use
diï¬€erent words to describe the same thing, but it also allows the same word to
describe diï¬€erent ideas. Soon we will see a formal deï¬nition of the union of
two sets. If A and B are sets, the union of A and B is a set containing all the ele-
ments of A and all the elements of B. Notice how this idea is phrased using the
word â€œand.â€ We can also say that an element is in the union of A and B if it is in
either A or B. This time we used the word â€œorâ€ to describe the union. It was the
English phrasing that allowed us to describe the union of two sets using each of
the words â€œandâ€ and â€œor.â€ English grammar has allowed both words to convey
the same ultimate meaning. In logic, these two words have very distinct mean-
ings. De Morganâ€™s laws allow them to describe exactly the opposite meanings,
but not the same meaning.
English provides a method of conveying meaning, but it can be ambiguous.
Writers often delight in taking advantage of the ambiguity of language; and
some of the best examples cannot be attributed to one author or even one lan-
guage. An often quoted book review stated:
Your manuscript is both good and original; but the parts that are good
are not original, and the parts that are original are not good.

7.5 Logic Versus English
115
There is the apocryphal letter of recommendation that said:
You would be very lucky to get John Jones to work for you.
Compare the borderline English-Logic sentences:
a. If x = 2 or x = 5, then x2 + 10 = 7x.
b. For x = 2 or x = 5, x2 + 10 = 7x.
c. If x = 2 and x = 5, then x2 + 10 = 7x.
d. For x = 2 and x = 5, x2 + 10 = 7x.
e. If x = 2 or x = 5, then x2 + 6 = 5x.
f. If x = 2 and x = 5, then x2 + 6 = 5x.
It would be interesting to poll English speakers on what each of these sen-
tences mean and which are true. The results would most likely be far from
unanimous. There is a natural assumption in colloquial speech that a sentence
is meant to make sense and probably be true. So that will inï¬‚uence whatever
meaning we take from each of these sentences, and thus, it will aï¬€ect our judg-
ment about their truth. The question is, which of these sentences are saying that
both the numbers 2 and 5 are solutions to an equation, and which are saying
that at least one of 2 and 5 is a solution. Sentence (f) seems to be saying that
both are; so it is false. So, that would make the sentence (c) appear true and (d)
appear true as well. Sentences (a), (b), and maybe (e) are claiming that both are
solutions or only one is a solution; it is hard to tell. Either way, (a) and (b) seem
to be true, but (e) needs to be clariï¬ed before we can know for sure. As English
sentences, these are pretty ambiguous. They convey a meaning but not a very
precise one.
If we knew for sure that these were meant as logical statements, we could ana-
lyze them using the rules of logic given earlier. Logic will remove the ambiguity
in these sentences as logical statements, but it will not cure the ambiguity as
English sentences. While it is clear what some of these sentences are meant to
say as sentences, forcing them into logical interpretations changes that mean-
ing. Parsed logically, sentence (a) has the form (P âˆ¨Q) â‡’R. This is logically
equivalent to (P â‡’R) âˆ§(Q â‡’R), which makes it true. Sentence (e) has the
same logical structure, and it turns out to be false. Sentences (c) and (f) have the
form (P âˆ§Q) â‡’R; however, in both of these, (P âˆ§Q) is a logical contradiction.
Thus, they both end up logically true, but not at all because of their meaning
as English sentences. We may have noticed this because, in both, the English
grammar is a bit iï¬€y, (sorry, irresistible.) Finally, strictly speaking, neither (b)
or (d) is a logical statement since in logic â€œforâ€ is meant to specify one value for
the coming variable, not two. English allows the assumption that some addi-
tional words are implied by the â€œforâ€ in the sentence; that is not the case in
logic.

116
7 Logic
Remember that, in both directions, the connection between everyday
language and logical writing is about the translation of meaning rather than
the translation of words. In other words, mathematics is supposed to make
unambiguous sense. Usually, logic helps mathematics make precise sense, but
at times it does not. While the rules of logic are exact and unforgiving, these
rules must be placed into English sentences where rules are less precise. A
mathematical proof is an irrefutable argument based on logic that a statement
is true. It is not a proof if it does not make sense or is too ambiguous. We have
no choice about the logical rules we must follow, but we do have a choice in the
words and grammatical structure we use to outline those logical arguments.
We have no choice about the rules for writing a Haiku, a Shakespearean
sonnet, or even a limerick; the quality of the result, however, depends on the
words we use. Writing good poetry and good prose takes practice and care.
The same is true about writing good mathematical proofs.
The Irish writer known as Lord Dunsany once said, â€œLogic, like whiskey, loses
its beneï¬cial eï¬€ect when taken in too large quantities.â€ Or perhaps, a less eru-
dite paraphrase of comedian Steven Wright makes the point better, â€œLogically
speaking, only a recluse can live in a house with a circular driveway.â€
7.6
Problems
7.1
Prove that the following pairs of logical statements are equivalent:
(a) (P âˆ§Q) âˆ§R and P âˆ§(Q âˆ§R).
(b) (P âˆ¨Q) âˆ¨R and P âˆ¨(Q âˆ¨R).
(c) P âˆ§(Q âˆ¨R) and (P âˆ§Q) âˆ¨(P âˆ§R).
(d) P âˆ¨(Q âˆ§R) and (P âˆ¨Q) âˆ§(P âˆ¨R).
7.2
Prove that the following pairs of logical statements are equivalent:
(a) (P âˆ¨Q) â‡’R and (P â‡’R) âˆ§(Q â‡’R).
(b) P â‡’(Q âˆ¨R) and (Pâˆ§âˆ¼Q) â‡’R.
(c) Explain in common terms what these mean.
7.3
Let S be a set of real numbers that is not bounded above. Prove that if
r âˆˆâ„, then there exists an s âˆˆS such that r < s.
7.4
In several of our earlier proofs, we changed the deï¬nition of â€œm is a min-
imum of the set Sâ€ by writing the second condition as
if x < m, then x âˆ‰S .
(a) Why was this logically correct?
(b) How many of those proofs can you identify?

7.6 Problems
117
7.5
Prove for all n âˆˆâ„•, if
n
âˆ‘
k=1
(4k3 âˆ’6k2 + 4k âˆ’1) = n4 âˆ’1,
then
n+1
âˆ‘
k=1
(4k3 âˆ’6k2 + 4k âˆ’1) = (n + 1)4 âˆ’1.
(Hint: Do not try logical tricks, just write a direct proof.)
7.6
Prove that the following logical statements are equivalent:
â€¢ (P âˆ§Q âˆ§R) â‡’S;
â€¢ (P âˆ§Q) â‡’(R â‡’S);
â€¢ (P âˆ§Q) â‡’(âˆ¼S â‡’âˆ¼R).
7.7
Go through the deï¬nition of an ordered ï¬eld and identify the logical
structure of each of the 16 properties. In particular, note any AE state-
ments and any EA statements and explain their meaning as it relates to
subsequent theorems about ordered ï¬elds.
7.8
Let F be an ordered ï¬eld. Let x âˆˆF with x â‰¥0. Consider the statement
if for all ðœ–> 0, x â‰¤ðœ–, then x = 0.
(a) Write a contrapositive of this statement.
(b) Prove the statement.
(c) Why do some people call this result â€œThe Average Theorem?â€
(d) Remember this.
7.9
Prove that if n âˆˆâ„¤with n2 even, then n is even.
7.10
Prove that for all n, m âˆˆâ„¤if nm is even, then either n is even or m is even.
7.11
We will rename the least upper bound of a set S to call it the supremum
of the set S. Write out a mathematical deï¬nition of the supremum of S.
7.12
Let S = {x âˆˆâ„âˆ£xâˆ’1 âˆˆâ„•}. Prove that 0 is the inï¬mum of S.
7.13
Let S = {x âˆˆâ„âˆ£xâˆ’1 > 0}. Prove that 0 is the inï¬mum of S.
7.14
Let S =
{
x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x = n+1
n
}
. Prove that 1 is the inï¬mum of S.
(Hint: Archimedes has a trick for this.)

118
7 Logic
7.15
Use a calculator or computer to calculate
10âˆ‘
k=1
(4k3 âˆ’6k2 + 4k âˆ’1).
(a) Is the answer to part 1 (10)4 âˆ’1?
(b) Is the statement we proved in question 2 true? Is the proof correct?
7.7
Epilogue
There is more to this two-valued logic than we have let on. Even the ancient
Greeks, who almost worshiped logic, recognized that there were certain
problems with insisting that declarative sentences must be either true or false.
Consider the famous
This sentence is false.
We cannot say that this sentence is true, because it says that it is not. But
we cannot say that it is false, because then it would say that it was true. This
sentence references itself, and because of that, it cannot be assigned a value of
true or false without creating a logical contradiction.
Self-reference can cause another logical problem. Consider the apparently
less oï¬€ensive
This sentence is true.
This can certainly be considered a true statement without causing a contra-
diction. However, it can also be considered as false without a contradiction
either. To be a logical statement, it must be one or the other, but not both.
We have just seen two declarative sentences that cannot be logical statements
because of their form.
Consider the examples
The sentence below is false.
The sentence above is true.
and
The sentence below is true.
The sentence above is true.
We see that a statement can be self-referencing in a nondirect way. So we have
just seen declarative sentences that cannot be logical statements because they
reference other statements.
For millennia, logicians eliminated such statements from logical analysis by
simply saying, â€œDo not make self referencing statements.â€ In the early 20th cen-
tury, mathematicians and logicians tried to come up with a more formal set
of logical rules (axioms) that, when followed, would eliminate self-reference

7.7 Epilogue
119
once and for all. Their hopes of doing this were dashed when, in 1931, Kurt
GÃ¶del proved that, in any system of numbers that included the natural num-
bers, self-referencing statements are inevitable.
In essence, GÃ¶del proved that if we set up a set of rules for numbers, it is
always possible that we can make a logical statement that cannot be assigned a
value of true or false using just those rules. This statement will be undecidable
within those rules. That means we will never be able to prove it true or prove it
false using just the rules. Now it is not that mathematicians had no experience
dealing with such statements. At any moment in mathematics history, there
are plenty of mathematical statements that no one can prove are either true or
false. Prior to GÃ¶del, however, mathematicians believed that in time, Mathe-
matics would develop enough power to do one or the other every time. GÃ¶del
introduced the possibility that a speciï¬c mathematical statement might forever
remain undecided within the rules of the subject.
Mathematicians, however, typically remain optimistic, and they continue to
ask questions, give answers, and provide proofs that their answers are correct.
Even the oldest of open questions remain fodder for new mathematical work.
Perfect numbers such as 6 and 28 have been interesting to mathematicians for
over 2500 years. They are perfect because they are the sums of their proper
factors:
6 = 1 + 2 + 3;
(7.7)
28 = 1 + 2 + 4 + 7 + 14.
In all that time, no one has ever found an odd perfect number. But no one has
ever proved that no such number can exist. It could be that the statement â€œThere
are no odd perfect numbersâ€ is true. It could also be that it is false. After GÃ¶del,
one could even speculate that it cannot be assigned a value of true or false using
the deï¬nition of â„•. Undeterred by 2000 years of failure, many mathematicians
expect that it is either true or false, and many would predict that this question
will be resolved within the century. We have been making progress of late. So
a missing proof in Mathematics is more likely to be blamed on a shortage of
appropriate mathematics than on a quirk of GÃ¶delâ€™s logic. Nevertheless, GÃ¶delâ€™s
ideas actually give mathematicians extra tools that might shed light on or even
prove diï¬ƒcult mathematical questions, maybe even this one.
The moral is, although we know that some self-reference is unavoidable in
Mathematics, in practice, we need only to take mild precautions to avoid it.
GÃ¶delâ€™s Incompleteness Theorem is not something that we should worry will
interfere with our study of numbers.

121
8
Advice for Constructing Proofs
8.1
The structure of a proof
8.1.1
Syllogisms
The basic idea behind mathematical proofs is the logical construct known as a
syllogism. Let P, Q, and R be logical statements. A syllogism is an argument of
the form:
If (P â‡’Q) and (Q â‡’R), then (P â‡’R).
We can check that this is valid by constructing a truth table for
((P â‡’Q) âˆ§(Q â‡’R)) â‡’(P â‡’R).
We should see that it is a tautology.
The table is large, so we break it into pieces. Let A stand for (P â‡’Q) âˆ§
(Q â‡’R):
P
Q
R
P â‡’Q
Q â‡’R
A
T
T
T
T
T
T
T
T
F
T
F
F
T
F
T
F
T
F
T
F
F
F
T
F
F
T
T
T
T
T
F
T
F
T
F
F
F
F
T
T
T
T
F
F
F
T
T
T
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

122
8 Advice for Constructing Proofs
P
Q
R
A
P â‡’R
A â‡’(P â‡’R)
T
T
T
T
T
T
T
T
F
F
F
T
T
F
T
F
T
T
T
F
F
F
F
T
F
T
T
T
T
T
F
T
F
F
T
T
F
F
T
T
T
T
F
F
F
T
T
T.
The backbone of any proof is an extended syllogism. Thus, the proof of P â‡’Q
should contain an argument that resembles
P â‡’P1.
P1 â‡’P2.
P2 â‡’P3.
P3 â‡’P4.
P4 â‡’Q.
Therefore, P â‡’Q.
All the statements are declarative sentences, and they are written as impli-
cations using â€œimplies.â€ That requires a lot of repetition, and that can be
eliminated by hiding the implications in connected sentences. However, the
statements are still declarative sentences. The same argument could be written
as a sequence of sentences such as
Assume P.
Therefore P1.
So P2.
Thus P3.
Therefore P4.
And that implies Q.
Therefore, P â‡’Q.
The key is that each statement is true because of the statement directly
preceding it. The syllogism is indicated by any of the leading words: â€œso,â€
â€œthus,â€ â€œtherefore,â€ and â€œand that implies.â€

8.1 The Structure of a Proof
123
8.1.2
The outline of a proof
Basically, a proof is an essay with a particular objective: to give an irrefutable
argument that a statement is true. Similar to any good composition, it is greatly
facilitated by an outline. The outline can include a title and sections with or
without headings. Sections should be organized into paragraphs, and para-
graphs are made up of sentences. In a proof, the role of the title is often played
by the statement being proved written carefully. The sections are any separate
parts, steps, or cases that are necessary for the proof. The sentences are logical
statements that are true under the assumptions of the proof. The paragraphs
should be complete extended syllogisms of the type described earlier. A para-
graph begins with a fact already established in the proof. It ends with a fact that
either completes the proof or cannot be rewritten logically to produce a new
true statement.
Some proofs are one paragraph long. For example,
Example 8.1.1.
If n âˆˆâ„¤is even, then n2 is even.
Proof. Assume n âˆˆâ„¤. Assume that n is even. So there is k âˆˆâ„¤so that n = 2k.
Consider n2. Then n2 = (2k)2 = 2(2k2). Since 2k2 âˆˆâ„¤, n2 is even.
â—½
This is a one-paragraph proof because it is a single extended syllogism. It is
not written as a completely continuous syllogism. It starts with a logical state-
ment that is assumed to be true: â€œn is even.â€ This is rewritten using the deï¬nition
of the term â€œeven.â€ This results in the second logical statement in the syllogism:
â€œThere is k âˆˆâ„¤so that n = 2k.â€ The next sentence is not a logical statement; it
is a command sentence. It is not part of the syllogism, but it is an optional part
of the proof. It is an instruction to the reader and the writer about what to do
next. It is a kindness meant to make the proof easier to follow. The last logical
statement is transformed into the next by considering n2. We consider it by say-
ing something true about it based on the last statement in the syllogism. That
next statement is its own mini-syllogism: â€œn2 = (2k)2 = 2(2k2).â€ It is shorthand
for â€œn2 = (2k)2 and (2k)2 = 2(2k2), imply n2 = 2(2k2).â€ The ï¬nal logical state-
ment in the syllogism is â€œn2 is even.â€ However, the sentence containing â€œn2 is
evenâ€ provides a service for the reader and a check for the writer by ï¬rst pro-
viding a reason for this ï¬nal statement. At this point, the reader could draw the
ï¬nal conclusion obtained from such an argument that the original assumption
implies the ï¬nal conclusion. It could also be written to ï¬t the deï¬nition of even
exactly: â€œLet kâ€² = 2k2. Then kâ€² âˆˆâ„•and n2 = 2kâ€². So by deï¬nition, n2 is even.â€
In addition, the proof could have ï¬nished up with an explicit summary of what
was proved: â€œAnd therefore if n âˆˆâ„¤is even, then n2 is even.â€ Because the proof
is only one paragraph, the writer chose to let the reader draw this observation
alone and just used an end of proof symbol such as â—½.

124
8 Advice for Constructing Proofs
Many proofs require more than one paragraph. This happens when one or
two of the earlier assumptions lead to a conclusion, but that conclusion cannot
be pushed any further without other facts not yet available. The next paragraph
in the proof begins a new syllogism with facts that appeared before this last
paragraph and reaches its own conclusion. Then, a new paragraph begins with
the conclusions of both paragraphs and, by extended syllogism, reaches the
conclusion of the proof (if we are lucky).
Example 8.1.2.
The minimum of a set is unique.
Proof. We will prove: if m1 and m2 are both minimums of the set S, then
m1 = m2.
Comment: So this proof has another feature common in English compositions, a
preamble. Next, we begin the syllogism in the next paragraph.
Assume that m1 is the minimum of the set S. So we have m1 âˆˆS and if s âˆˆS,
then m1 â‰¤s.
Comment: This is the end of this two-sentence paragraph. It has ended with two
conclusions that we have no use for as yet. We know that m1 âˆˆS. We also know
that if s âˆˆS, then m1 â‰¤s. This means that if we ever ï¬nd an element of S, we
know something about it. We do have that m1 âˆˆS, but the conclusion m1 â‰¤m1
is not worth writing down as a new fact. Thus, the two facts we have just stated
are put aside, not yet used in the proof. We proceed by writing a new paragraph.
Assume that m2 is the minimum of the set S. So we have m2 âˆˆS and if s âˆˆS,
then m2 â‰¤s.
Comment: Again, we have a two-sentence paragraph that ends with two more
unused facts. But now all together, we have four unused facts. We can put two of
them together to begin our third paragraph.
We know that m2 âˆˆS and that if s âˆˆS, then m1 â‰¤s. Thus, m1 â‰¤m2.
Comment: We have another two-sentence paragraph. We use two of our earlier
facts and turn them into one new fact: m1 â‰¤m2. We canâ€™t quite use it yet; so we
set it aside as an unused fact. But we return to the two remaining unused facts
from earlier and put them together in the fourth paragraph.
We also know that m1 âˆˆS and that if s âˆˆS, then m2 â‰¤s. Thus, m2 â‰¤m1.
Comment: We have another two-sentence paragraph. We use two of our ear-
lier facts and turn them into one new fact: m2 â‰¤m1. This time, however, we just

8.1 The Structure of a Proof
125
might add to the paragraph and use this right away with our only remaining
unused fact.
So we know that m1 â‰¤m2 and m2 â‰¤m1. By trichotomy, m1 = m2.
Comment: This is our ï¬nal paragraph. We can add one last summary paragraph
if we like.
We have proved that if m1 and m2 are both minimums of the set S, then
m1 = m2. Thus, the minimum of an set is unique.
â—½
Let us write this out without the commentary. In addition, once we have used
the paragraph idea to outline the structure of our proof, maintaining this struc-
ture is optional. We can also add index numbers to make our references clearer,
but again this is optional.
Example 8.1.3.
The minimum of a set is unique.
Proof. We will prove: if m1 and m2 are both minimums of the set S, then
m1 = m2.
Assume that m1 is the minimum of the set S. So we have
(1) m1 âˆˆS, and
(2) if s âˆˆS, then m1 â‰¤s.
Assume that m2 is the minimum of the set S. So we have
(3) m2 âˆˆS, and
(4) if s âˆˆS, then m2 â‰¤s.
We know that (3) m2 âˆˆS and that (2) if s âˆˆS, then m1 â‰¤s. Thus, we have
m1 â‰¤m2.
We also know that (1) m1 âˆˆS and that (4) if s âˆˆS, then m2 â‰¤s. Thus, we have
m2 â‰¤m1.
So we know that m1 â‰¤m2 and m1 â‰¤m2. By trichotomy, m1 = m2.
We have proved that if m1 and m2 are both minimums of the set S, then
m1 = m2. Thus, the minimum of a set is unique.
â—½
Some proofs have parts or steps that separate the paragraphs into sections or
parts.
Example 8.1.4.
For all n âˆˆâ„•,
nâˆ‘
k=1
k = n(n+1)
2
.
Proof. By induction.

126
8 Advice for Constructing Proofs
Step 1, the base step. We claim that if n = 1, then
nâˆ‘
k=1
k = n(n+1)
2
.
Proof of claim. Assume n = 1.
Consider
nâˆ‘
k=1
k. Then
nâˆ‘
k=1
k =
1âˆ‘
k=1
k = 1.
Consider n(n+1)
2
. We have n(n+1)
2
= 1â‹…(1+1)
2
= 1.
So
nâˆ‘
k=1
k = 1 = n(n+1)
2
.
â—¾
Comment: This step is now complete. The proof of the claim it makes is over.
Everything identiï¬ed as true in step 1 is now oï¬€limits for the remaining part
of the proof. If we need a particular statement in this step, it must be reestab-
lished under the assumptions of step 2. Nevertheless the statement itself has been
proved true; so it is fair game if we need it.
Step 2, the induction step. We claim
If
n0âˆ‘
k=1
k = n0(n0+1)
2
, then
n0+1
âˆ‘
k=1
k = (n0+1)(n0+2)
2
.
Proof of claim. Assume
n0âˆ‘
k=1
k = n0(n0+1)
2
.
Comment: What are we proving now? After this assumption, we need to prove
n0+1
âˆ‘
k=1
k = (n0+1)(n0+2)
2
. As we just saw, one way to prove that an equality of numbers
is true is to consider one side and then the other. This is not absolutely necessary if
we can carry out the algebra from one side straight to the other in one calculation.
We can even consider both side on scratch paper and fake the required algebra
skills by rewriting the calculation on one side backwards.
Consider
n0+1
âˆ‘
k=1
k. We have
n0+1
âˆ‘
k=1
k =
n0
âˆ‘
k=1
k + (n0 + 1)
(8.1)
= n0(n0 + 1)
2
+ (n0 + 1)
=
(n0
2 + 1
)
(n0 + 1)
= (n0 + 1)(n0 + 2)
2
.
â—¾

8.2 Methods of Proof
127
Step 3, the conclusion. By the theorem of induction, if a statement P(n) is
true for n = 1, and whenever P(n) is true for a particular n = n0, then it is true
for the next natural number n0 + 1, then we can conclude that it is true for all
n âˆˆâ„•. So
âˆ€n âˆˆâ„•,
n
âˆ‘
k=1
k = n(n + 1)
2
.
â—½
(8.2)
In writing this proof, we have been particularly kind. We added a step 3 where
we explicitly stated the theorem of induction, and we restated the theorem
that was proved. This is not uncommon when the theorem used to draw a
conclusion is surprising or less well known. But a proof by induction is so com-
mon that most proofs by induction end when the induction step is complete.
8.2
Methods of proof
8.2.1
Direct methods
8.2.1.1
Understand how to start
The default method for proving a mathematical statement is to write it as an
implication P â‡’Q and start the proof by assuming the hypothesis P. It is next
to impossible to emphasize how important this simple idea is:
Proof technique. Before we start a proof, we write what we are proving as an
â€œifâ€¦thenâ€ sentence. We start the proof by assuming the hypothesis.
It is astounding how diï¬ƒcult learning and following this simple, one-sentence
lesson can be for even the best mathematics students.
Once we have the right start, a proof proceeds by using any assumption by
rephrasing it or reinterpreting it into a more useful form. If that more useful
form turns out to be the conclusion Q, a one-paragraph proof is complete. Mul-
tiple assumptions can lead to multiple paragraphs each ending with an unused
conclusion. These unused facts are combined in later paragraphs.
If simply working with P and its parts does not directly lead to Q, the focus
must change to Q. We ask ourselves, â€œHow is Q proved?â€ The mistake many
people make in constructing a proof is to concentrate on the conclusion Q too
early.
Proof technique. Once a proof of P â‡’Q is started and assumptions are made,
the object becomes to prove Q. As any proof progresses, the exact statement being
proved at any moment changes as more assumptions are made and more facts
are established.

128
8 Advice for Constructing Proofs
When the question is, â€œHow do I prove Q?â€ it might just as well be â€œWhat
does Q mean?â€ The answer should be phrased in one of four logical types of
mathematical statements:
â€¢ A declarative sentence in math terms;
â€¢ If P, then Q;
â€¢ For all s âˆˆS, P(s);
â€¢ There exists s âˆˆS s.t. P(s).
The important thing in determining the next step in the proof is the ï¬rst few
words in the answer to our â€œhowâ€ question. Are those ï¬rst words: â€œifâ€, â€œthere
existsâ€ or â€œfor allâ€? If not, we rephrase the statement so it has one of these starts.
If we can maintain a logical discipline in constructing a proof, we have a
much better chance of succeeding. We only assume something because it is
the hypothesis of an implication we are proving. We only say things that follow
from the previous statement, and we always have a reason that guarantees that
it does indeed follow. The only valid reasons for making the next logical state-
ment in a theorem are as follows: a deï¬nition, a theorem, a basic property, or
a previously established fact in the proof. Basically, we say things that are true
for a reason and do not say things only because we hope that they are true.
In 1979, Douglas Adams wrote a book called The Hitchhikerâ€™s Guide to the
Galaxy. It is a book about space hitchhikers who rely on the advice contained in
a guidebook as they tour the galaxy. The guide has its problems, but the hitch-
hikers chose it for reasons Adams explains:
â€œIt is said that despite its many glaring (and occasionally fatal) inac-
curacies, the Hitchhikerâ€™s Guide to the Galaxy itself has outsold the
Encyclopedia Galactica because it is slightly cheaper, and because it
has the words â€˜DONâ€™T PANICâ€™ in large, friendly letters on the cover.â€
Adams, Douglas (1979). The Hitchhikerâ€™s Guide to the Galaxy. Pocket
Books. p. 3. ISBN 0-671-46149-4.
As we continue our mathematical studies, we will be asked to prove more and
more mathematical statements. The most important thing to remember while
constructing a proof, especially at the beginning, is
Donâ€™t Panic.
Always carrying a towel, as the Hitchhikerâ€™s Guide also advises, is optional.
Whenever we hit an impasse in constructing a proof, we must not allow our-
selves to panic. We ask, â€œWhat do we know?â€ and â€œCan we simplify what we
know?â€ We ask, â€œWhat are we proving now?â€ and â€œWhat does that mean?â€ Next,
we will look at ways for dealing with â€œthings we knowâ€ and â€œthings we want to
prove.â€ If we are patient, we can often get our proof back on track.

8.2 Methods of Proof
129
8.2.1.2
Parsing logical statements
The ï¬rst step in constructing a proof is to completely understand what it is we
are proving from a logical point of view. That may require parsing the logic of
a compound sentence. Consider the following statement:
If x is less than a lower bound of the set S, then x is a lower bound of S.
This is not that diï¬ƒcult to understand because we have used mathematical
terms to make it clear. If we rephrase it without using as many terms, it might
end up looking like
If x < m and if s âˆˆS, then m â‰¤s, then if s âˆˆS, then x â‰¤s.
This only makes sense, if it does at all, because we know where it came from.
Because of this, as we read it, we know how to parse it logically. We will make
this clear by using parentheses to separate the parts
If [(x < m) and (if s âˆˆS, then m â‰¤s)], then [if s âˆˆS, then x â‰¤s].
We should never be afraid to admit that something like
If x < m and if s âˆˆS, then m â‰¤s, then if s âˆˆS, then x â‰¤s.
is diï¬ƒcult to understand. It could have looked even worse:
x < m âˆ§âˆ€s âˆˆS, m â‰¤s â‡’âˆ€s âˆˆS, x â‰¤s.
If a compound statement is confusing, the thing to do is parse it into its logical
components. We can use mathematical notation (parentheses) to help:
((x < m) âˆ§(âˆ€s âˆˆS, m â‰¤s)) â‡’(âˆ€s âˆˆS, x â‰¤s).
However, sometimes using English to decipher mathematical notation also
works. Here, attention to punctuation and grammar can help a lot.
In English composition and mathematical writing, not everyone follows the
rules we are about to outline; so in a sense, our rules are only guidelines. It
is, however, advisable to have our own ï¬xed rules for punctuation and gram-
mar to act as an aid to parsing logical statements. Making it a point to follow
these rules in our own writing can make them easier to apply when interpret-
ing someone elseâ€™s. How long we should stick to these rules is a matter of how
good we get at interpreting normal language as logically precise phrases. Here
are our grammatical rules.
First, every â€œifâ€ should be associated with a â€œthen.â€ It may be implied in an
English sentence, but in preparation for logical parsing, it helps to add it. The â€œifâ€
and its associated â€œthenâ€ form one logical phrase and must be parsed together as
one statement. It often helps to use a trick from algebra by adding parentheses

130
8 Advice for Constructing Proofs
or brackets about such a statement to hold it together. Remember though, the
phrases between an â€œifâ€ and its â€œthenâ€ are themselves logical statements to be
parsed themselves, and they may deserve their own parentheses.
A â€œfor allâ€ should have a scope, but it will always have a mathematical
statement in the identiï¬ed variable. The identiï¬cation of the variable and the
setting of the scope should be separated from the mathematical statement with
a comma. Just as an â€œifâ€ is followed by a â€œthen,â€ a â€œfor allâ€ is accompanied by
a comma. If it is not there, it should be added. Taking the time to distinguish
between the scope of the variable and the mathematical statement is vital to
understanding the logic of the statement. Both the scope and the mathematical
statement can themselves be compound, but a compound scope is almost
always the result of an â€œand.â€ The â€œâˆ€â€ and its associated comma form one
logical phrase and must be parsed together as one statement.
Similarly, a â€œthere existsâ€ should have a scope, but it will always have a math-
ematical statement in the identiï¬ed variable. Every â€œthere existsâ€ is paired with
a â€œsuch that.â€ If it is not there, it should be added. Again, taking the time to
distinguish between the scope of the variable and the mathematical statement
is vital to understanding the logic of the statement. The â€œâˆƒâ€ and its associated
â€œs.t.â€ form one logical phrase and must be parsed together as one statement.
We have made a big deal about identifying the scopes because, as De Morganâ€™s
laws illustrate, it is important when negating. In negating either a â€œâˆ€â€ or a â€œâˆƒ,â€
the scope does not change.
When parsing a logical statement, the logical phrases are not separated. Each
â€œifâ€ has its â€œ then;â€ each â€œfor allâ€ has its comma, and each â€œthere existsâ€ has its
â€œsuch that.â€ We can use parentheses or brackets to collect phrases and their
parts into groups, but the main point is that components of a logical phrase are
inside nested parentheses.
All this structure helps, but in the end, it always is a matter of interpreting
the English sentence we are given.
Returning to our example,
If x < m and if s âˆˆS, then m â‰¤s, then if s âˆˆS, then x â‰¤s.
becomes
If (x < m and if s âˆˆS, then m â‰¤s), then (if s âˆˆS, then x â‰¤s).
(associating the ï¬rst â€œifâ€ to its proper â€œthen.â€) In turn, this is
If ((x < m) and (if s âˆˆS, then m â‰¤s)), then (if s âˆˆS, then x â‰¤s).
The parts joined by the connectors â€œandâ€ and â€œorâ€ are easier to identify. The
ï¬nal nesting of component phrases may not add that much extra help and might
not be necessary.

8.2 Methods of Proof
131
If ((x < m) and (if (s âˆˆS), then (m â‰¤s))), then (if (s âˆˆS), then (x â‰¤s)).
Once we have understood the logical skeleton of our statement, it is easier to
start a proof correctly.
We see its logical outline as an implication of the form
(P âˆ§Q) â‡’R.
We might even see it parsed further as
(P âˆ§(Q1 â‡’Q2)) â‡’(R1 â‡’R2).
The proof is easy once we assume the hypothesis. We need to assume the
hypothesis of the theorem and not the hypothesis that appears in a component
of the hypothesis. So we concentrate on the simpler outline, (P âˆ§Q) â‡’R.
We assume
â€¢ P: x < m;
â€¢ (Q1 â‡’Q2): if s âˆˆS, then m â‰¤s;
â€¢ R1: s âˆˆS.
We do not assume Q1. The statement we can assume says, â€œIf we ever have
anything in S, then we know something about it.â€ We cannot not assume that
we have s âˆˆS because of this. We can only wait for the proof itself to provide
us an element of S where we can use it. Luckily, the next assumption does just
that, and the proof is easy to complete.
8.2.1.3
Mathematical statements to be proved
One advantage we have in Mathematics is that the logical statements that
appear in our proofs come in only one of four forms:
â€¢ A declarative sentence in math terms;
â€¢ If P, then Q;
â€¢ For all s âˆˆS, P(s);
â€¢ There exists s âˆˆS s.t. P(s).
We can often ï¬nd ourselves in the middle of an extended syllogism and realize
that we are at a loss over what the next step should be. We have made some
assumptions, said what they meant, and left ourselves with paragraphs ending
in unused facts. We have tried but failed to put those facts together to draw
new conclusions. Our only hope to move forward is to try to provide the next
statement we want to prove with one on the three allowable logical beginnings:
â€œif,â€ â€œfor all,â€ or â€œthere exists.â€
Only when we have run out of true things to say, do we ask ourselves, â€œWhat
are we proving now?â€ The answer should be its own full mathematical state-
ment. We have discovered some facts, but have also reduced our attention to
proving a sort of â€œmini-theoremâ€ that will lead to our desired conclusion. As

132
8 Advice for Constructing Proofs
the proof progresses, the answer to the question â€œWhat are we proving now?â€
changes. As we gather more unused facts, our mini-theorems should get easier
to prove.
Each of our mini-theorems will be phrased in one of the four allowable math-
ematical forms. We need a strategy for proving the statements in each of these
forms.
Declarative sentences. To prove a declarative sentence in math terms, we ask
ourselves, â€œWhat does it mean?â€ Since math terms have precise deï¬nitions, we
can rewrite the statement by removing the terms and using their deï¬nitions. For
numbers, â€œequalsâ€ means â€œare the same.â€ Our best hope is to consider each side
and use algebra to show that they are both equal to the same thing. A declarative
sentence such as â€œm is a lower bound of Sâ€ can be changed into an â€œifâ€¦thenâ€
using the following deï¬nition: â€œIf s âˆˆS, then m â‰¤s.â€ Some deï¬nitions will give
us â€œfor allâ€ statements or â€œthere existsâ€ statements. Others, such as â€œm is a mini-
mum of S,â€ will give us several things to prove. Whatever happens, this typically
changes the answer to the question â€œWhat are we proving now?â€ from a declar-
ative into a more manageable logical phrase.
Implications. At this point, we should know how to prove an implication,
P â‡’Q. We assume the hypothesis P. The answer to â€œWhat are we proving
now?â€ has changed to â€œQ.â€ This is what we do even if the implication appears as
a goal right in the middle of a long proof. This is always a very good thing. An
implication lets us assume more facts. More facts mean there are more things
we can combine into new facts. It gives us a second chance to look at any unused
facts that ended earlier paragraphs. If Q happens to be its own implication,
wonderful. That means we can make even more assumptions we get to use.
Universals. Proving a â€œfor allâ€ statement such as âˆ€s âˆˆS, P(s) is basically the
same as implication. We assume that s âˆˆS and try to prove P(s).
Note that things are quite diï¬€erent if we assume â€œâˆ€s âˆˆS, P(s).â€ If we have
found that a statement of the form âˆ€s âˆˆS, P(s) is a true fact by any means, we
should realize that it means
If I ever have an s in S, then I know something about it.
We cannot assume that s âˆˆS. But we will say more about this later.
But right now, we are considering how we prove a â€œfor allâ€ statement. In that
case, we can make a new assumption. In some ways, â€œifâ€¦thenâ€ and â€œfor allâ€
statements are interchangeable. This works quite well when we are proving
them because it allows us to make a new assumption.
Existence. Proving a â€œthere existsâ€ statement is often the trickiest. To prove that
something exists, we need to ï¬nd one, and then prove that it works. Often, we

8.2 Methods of Proof
133
need to set up and solve a word problem in scratch work to even get started.
The key is that we can only use what we know we already have. Again, it will
still be up to the proof itself to give us the ingredients we need to construct the
thing we want. Our best bet is to be sure that we have drawn every possible
conclusion we can from the facts established so far in the proof. We should
take special note of any unused facts, since those are the best places to look for
methods for solving our word problem.
Example 8.2.1.
In this example, we develop a proof of the statement that
If n âˆˆâ„¤and n is odd, then n2 is odd.
The ï¬rst draft of the proof shows how we might think about the proof as we
attempt to discover it. A draft of a proof often includes comments and scratch
work not included in the ï¬nal version.
Proof draft. Assume n âˆˆâ„¤. Assume that n is odd. Then by deï¬nition, there
exists k âˆˆâ„¤so that n = 2k âˆ’1.
Comment: What are we proving now? We want that n2 is odd. What does that
mean? We want to prove that âˆƒk âˆˆâ„¤s.t. n2 = 2k âˆ’1. Wait! Actually, no, we do
not. We have laid a trap for ourselves by choosing a bad name for the variable
we are looking for. We already have used the name k for another number. We
need to choose a better name. Let us start over where we last asked what we are
proving and make a better choice.
Comment: What are we proving now? We want to prove that n2 is odd. What
does that mean? It means we want to prove that âˆƒkâ€² âˆˆâ„¤s.t. n2 = 2kâ€² âˆ’1. Every
time we say â€œthere exists,â€ we should pause and make a deliberate choice of the
variable we use to continue. To prove that something exists, we need to set up a
word problem and solve it.
Scratch work:
Find kâ€² so that n2 = 2kâ€² âˆ’1. We need to solve this for kâ€².
kâ€² = 1
2(n2 + 1)
(8.3)
= 1
2((2k âˆ’1)2 + 1)
= 1
2(4k2 âˆ’4k + 1 + 1)
= 2k2 âˆ’2k + 1.
Since 2k2 âˆ’2k + 1 âˆˆâ„¤this should work. We go back to the proof.

134
8 Advice for Constructing Proofs
Let kâ€² = 2k2 âˆ’2k + 1.
Comment: Notice that this is not a logical statement, it is a command. It belongs
in the proof because it deï¬nes a piece of notation. What are we proving now that
we have identiï¬ed a kâ€²? We need to show that kâ€² âˆˆâ„¤and n = 2kâ€² âˆ’1.
Since k âˆˆâ„¤, we have kâ€² = 2k2 âˆ’2k + 1 âˆˆâ„¤. Also
2kâ€² âˆ’1 = 2(2k2 âˆ’2k + 1) âˆ’1
(8.4)
= 4k2 âˆ’4k + 1
= (2k âˆ’1)2
= n2.
So we have proved that there exists kâ€² âˆˆâ„¤such that n2 = 2kâ€² âˆ’1. By deï¬nition,
n2 is odd.
Î”
We have constructed a proof, but not a written one. In the ï¬nal version of
the proof, we do not need to explain how we got to the proof. We only need to
show that it works.
Theorem 8.2.2.
If n âˆˆâ„¤and n is odd, then n2 is odd.
Proof. Assume n âˆˆâ„¤. Assume that n is odd. Then by deï¬nition, there exists k âˆˆ
â„¤so that n = 2k âˆ’1. Let kâ€² = 2k2 âˆ’2k + 1. Since k âˆˆâ„¤, we have kâ€² = 2k2 âˆ’
2k + 1 âˆˆâ„¤. In addition,
2kâ€² âˆ’1 = 2(2k2 âˆ’2k + 1) âˆ’1
(8.5)
= 4k2 âˆ’4k + 1
= (2k âˆ’1)2
= n2.
So we have proved that there exists kâ€² âˆˆâ„¤such that n2 = 2kâ€² âˆ’1. By deï¬nition,
n2 is odd.
â—½
Notice that the sentence â€œLet kâ€² = 2k2 âˆ’2k + 1.â€ is an instruction. It is neither
true nor false; so it requires no justiï¬cation even though it is required to prove
that â€œthere exists.â€ It must, however, be shown to be a correct instruction using
logical statements that are true because of the statement that follows the â€œlet.â€
So the proof must show that kâ€² has all the properties the â€œâˆƒâ€ statement requires
of it; that includes being within the scope.
Example 8.2.3.
There is another way that we can prove that something exists:
by magic.

8.2 Methods of Proof
135
Proposition 8.2.4.
The set S = {x âˆˆâ„| âˆƒn âˆˆâ„•s.t. x = n3 + 34n + 9} has a
minimum.
Proof. Let S = {x âˆˆâ„| âˆƒn âˆˆâ„•s.t. x = n3 + 34n + 9}.
Comment: We could set up a word problem to solve for a minimum. In the scratch
work we use to solve the problem, we can use any method we choose, from random
guessing to calculus. Once we think that we have it solved, we bring it back to the
proof and prove that it ï¬ts the two requirements necessary for a minimum. But
we prefer to use magic.
We see that if x âˆˆS, then x âˆˆâ„•, because addition and multiplication keep
natural numbers in â„•. In addition, 44 = 13 + 34 â‹…1 + 9 âˆˆS. Since S is a set of
natural numbers with at least one element, well ordering tells us that S has a
minimum.
â—½
A result such as that in the last example is most likely to appear as a
â€œmini-theoremâ€ reaching a goal set in the middle of a proof; thatâ€™s why we
called it a â€œproposition.â€ The word â€œlemmaâ€ would have also been an appro-
priate label. The result is not so much an independently interesting result, as it
is a method of creating a number out of nothing â€“ magic. Typically, it would
allow us to name the minimum, say m; and then use m to continue the longer
proof.
Notice how many of our named theorems, principles, and axioms are set up
to guarantee that things exist. The well-ordering principle, the average theorem,
the division algorithm, the completeness axiom, the archimedean principle,
and the density theorem all give ways to show that a particular thing exists.
Proving that something exists is often the most challenging thing to prove. Any
theorem that makes something appear from a few simple assumptions is worth
remembering.
8.2.1.4
Mathematical statements that are assumed to be true
As we have seen, in a proof we often ï¬nd ourselves assuming things as facts
or drawing conclusions that we accept as new facts. Again, these only come in
four forms:
â€¢ A declarative sentence in math terms;
â€¢ If P, then Q;
â€¢ For all s âˆˆS, P(s);
â€¢ There exists s âˆˆS s.t. P(s).
Declarative sentences. If we have found that a declarative sentence in math
terms is true, we should immediately write it out using the deï¬nitions.
Of course, if we know that two things are equal, that means they are

136
8 Advice for Constructing Proofs
interchangeable. But as we will see, there are times when we are not talking
about the equality of numbers, and then a deï¬nition of that particular type
of equality will be important. This will make more sense as we encounter this
type of fact. More typically, the declarative sentence directly leads us to a
deï¬nition. We have already learned how this works with the minimum of a set.
When we say that m is the minimum of S, we follow it by saying, so m âˆˆS, and
if s âˆˆS, then m â‰¤s. One usable fact then becomes two more speciï¬c usable
facts. Spelling out those facts explicitly can help us ï¬nd them later in the proof.
Implication and universal. If we ï¬nd that either a â€œfor allâ€ or an â€œifâ€¦thenâ€ is true,
we should set oï¬€on a search for a chance to use it. As pointed out earlier, if we
know that â€œâˆ€s âˆˆS, P(s),â€ we can convert it to â€œIf s âˆˆS, then P(s).â€ The important
thing to remember when we ï¬nd a true â€œif P, then Qâ€ statement is that it does
not tell us that P is true. A true â€œIf P, then Qâ€ only means that â€œIf we ever know
that P is true, then we can say something else.â€ We need to avoid the temptation
to assume we know that P is true.
Remembering this trick can help us maintain logical discipline. If we ï¬nd that
a statement such as either â€œP â‡’Qâ€ or â€œâˆ€x âˆˆS, P(x)â€ is true, we make it a point
to say to ourselves:
If I ever know that P is true, then I know something else.
or
If I ever have anything in S, then I know something interesting about it.
If we have identiï¬ed that P â‡’Q is true, we should look for anything earlier
in the proof that tells us that P is true. Otherwise, we wait for the proof to
tell us that P is true from later assumptions. If we do not ï¬nd P earlier in the
proof, we end our current paragraph and put this fact aside unused. We start
a new paragraph with a new valid assumption or an unused fact from earlier
in the proof. If we do not have a good guess as to what to use to start the next
paragraph, we ask ourselves, â€œWhat are we proving now?â€ If we are lucky, it
will be an implication and we will gain a new assumption or two and be able to
conclude that P is true. Once we have established that P is true, we can say for
certain that Q is true.
All this is the same if we identify âˆ€s âˆˆS, P(s) as true. We should look for
anything earlier in the proof that is in the set S. We cannot be sure that the
thing we will use this on will be called s; so we need to look for anything in the
set. Knowing that âˆ€s âˆˆS, P(s) does not allow us to assume that we have an s.
Before the proof is over, we will probably need this fact. But before we can use
it, we must have something in S. (It may not be labeled s.) If we are lucky, there
will be an element x in S in our unused facts. We can say that P(x) is true right
away. Otherwise, we must wait for the proof to provide us with something in S.
Perhaps later, â€œWhat are we proving now?â€ will give us one.

8.2 Methods of Proof
137
Existence. If we ï¬nd that a â€œthere existsâ€ is true, we always know what to do
next. Such a statement is never the end of a syllogism paragraph. If we say, âˆƒ
s âˆˆS s.t. P(s), our next step is to give it a name, but we need to do so wisely.
Never use a name that is already taken. There are two ways to do this: on the
ï¬‚y, we can say
âˆƒsâ€² âˆˆS s.t. P(sâ€²).
Or we can take a few steps:
âˆƒs âˆˆS s.t. P(s). Call it sâ€². Then P(sâ€²) is true.
An existence statement never ends a syllogism paragraph, because it creates a
new object that can be used elsewhere, and it states a fact about that object and
often two or more facts that will eventually be important.
Naming new objects is a great responsibility, and it almost always deserves
extra attention. With practice, it becomes easy to avoid using the same name
for more than one object. However, there is a situation where it is always easy
to slip up. Consider a proof where you assume or conclude an AE statement
such as
âˆ€i âˆˆîˆµ, âˆƒx âˆˆAi s.t. P(x).
It could be that this is a case where one name is inadvertently being used for
more than one thing. It could be that there is only one x that is in every set Ai
for which P(x) is true, but this could be saying quite a bit more than we actually
know. It is much more likely that for each i âˆˆîˆµ, there is a new xi âˆˆAi such
that P(xi) is true. In almost all cases where we see a sequential âˆ€-âˆƒphrase, (an
AE-statement), the â€œfor allâ€ signals the need for multiple names after the â€œthere
exists.â€
For an already familiar illustration of this, consider two familiar basic
properties we have used several times.
â€¢ âˆƒz âˆˆF, s.t. âˆ€r âˆˆF, r + z = z + r = r.
â€¢ âˆ€r âˆˆF, âˆƒs âˆˆF s.t. r + s = s + r = z.
The ï¬rst of these says that there is an additive identity in F. We know that we
can almost always prove that it is unique immediately. Thus, this element can
be given its own name; z will do, but 0 is a more common choice. The second
statement says that additive identities exist. However, because it is in the form
of an AE-statement, the object it says exists can and will depend on r. If we
know that addition is associative, we can prove that s is not completely unique
but is unique to r. When we assign a notation to the inverse, that notation âˆ’r
includes the starting r. In a less familiar setting, we should be more careful when
we hit the â€œâˆƒâ€ and choose the name that follows. It would be better to write
â€¢ âˆ€r âˆˆF, âˆƒsr âˆˆF s.t. r + sr = sr + r = z.

138
8 Advice for Constructing Proofs
If a â€œthere existsâ€ follows a â€œfor all,â€ the name we choose should reï¬‚ect this
sequential logical construction.
8.2.1.5
What do we know and what do we want?
Consider a logical statement of the form P â‡’Q. If we have assumed or con-
cluded that such a statement is true, we only know something if we ï¬nd that
P is true somewhere else in the proof. We need to be patient and let the proof
provide that information. We cannot ever just assume that P is true. However,
if we ask â€œWhat am I proving now?â€ and ï¬nd that the answer is P â‡’Q, that is
a diï¬€erent situation. We can prove that P â‡’Q by assuming that P is true.
Consider a logical statement of the form âˆ€x âˆˆS, P(x). If we have assumed or
concluded that such a statement is true, we only know something if we ï¬nd
something in the set S somewhere else in the proof. We need to be patient
and let the proof provide that element. We cannot ever just assume that we
have x âˆˆS. However if we ask â€œWhat am I proving now?â€ and ï¬nd that the
answer is âˆ€x âˆˆS, P(x), that is a diï¬€erent situation. We can prove âˆ€x âˆˆS, P(x)
by assuming that x âˆˆS. We should change the name, though, if x has already
been used elsewhere.
Consider a logical statement of the form âˆƒx âˆˆS such that P(x). If we have
assumed or concluded that such a statement is true, we name the element any-
thing we like and conclude that P(x) is true about it. Thus, we have created a
new object and a new true fact we can combine with other facts in the proof.
However if we ask â€œWhat am I proving now?â€ and ï¬nd that the answer is âˆƒx âˆˆS
such that P(x). We must ï¬nd one and prove that it works. Finding one requires
setting up and solving a word problem or using some magic theorem. After
that, the answer to the question â€œWhat am I proving now?â€ is P(s).
It is very important to distinguish why we are dealing with a particular state-
ment. How we proceed drastically depends on whether it is an established fact
or a statement to be proved.
8.2.1.6
Construction of a direct proof
With the foregoing discussion in mind, the key to constructing a proof is to
just keep saying things that are true. If we make the right start by assuming the
correct things, we can draw valid conclusions. If we get stuck and ask â€œWhat
am I proving now?,â€ we will know what to do next. If we draw a conclusion, and
that causes us to think of something to say, the question is not â€œShould we say
this?â€ The question is â€œIs this true?â€ If something is true, it is probably worth
saying. In addition, we should not assume that something is true unless there is
a logical reason to do so. Typically, there are only two good reasons to assume
that P is true:
â€¢ We are proving that P â‡’Q.
or

8.2 Methods of Proof
139
â€¢ We are starting a case, and somewhere else, we will assume âˆ¼P and work
with that.
In addition, once a step or case is complete, any assumptions made in that
case are no longer valid. Thus, any conclusions drawn in that case are no longer
available in other parts of the proof. Cases are the equivalent of subroutines
in computer programs: the input comes from outside the subroutine; only the
identiï¬ed output can be used outside the subroutine.
8.2.1.7
Compound hypothesis and conclusions
Finally, there are times where after parsing a statement to be proved, we ï¬nd
that it has the form (P1 âˆ§P2) â‡’Q. This is good because it allows us to start the
proof with two assumed facts: Assume P1. Assume P2. The more facts we know
are true, the more things we have to work with. We might also ï¬nd that we need
to prove a statement of the form (P1 âˆ¨P2) â‡’Q. Here we can only assume P1
or P2. Since either one is potentially true, we have no choice but to break our
proof into two cases where we prove P1 â‡’Q in case 1 and P2 â‡’Q in case 2.
Instead of one mini-theorem to prove, we get two.
The situation is slightly diï¬€erent when the compound sentence is in the con-
clusion. When we ï¬nd that we need to prove a statement of the form P â‡’
(Q1 âˆ§Q2), we actually have two mini-theorems to prove. We break a proof of
this into two steps (or parts): in step 1, we prove P â‡’Q1; in step 2, we prove
P â‡’Q2. This situation often occurs when we are trying to prove a mathemat-
ical deï¬nition that has two parts, such as m =Min(S) or s is the supremum
of A.
Those times where we need to prove a statement of the form P â‡’(Q1 âˆ¨Q2)
can be the most vexing. There is no one rule of thumb that will always result in
progress. It might be that our assumption will need to be dissected into logical
cases before we can continue. We may need to write P as (P1 âˆ¨P2) so that we can
prove P1 â‡’Q1 and P2 â‡’Q2. It is not always obvious how to do this breaking
up. One trick is to try to force a proof of P â‡’Q1. When that proof hits a point
where, with one extra condition, it will be complete, that condition might well
be the P1 and its negation P2. That being said, a lot of times, this whole puzzle
can be avoided. To prove P â‡’(Q1 âˆ¨Q2), we can prove the logically equivalent
(Pâˆ¨âˆ¼Q1) â‡’Q2. The extra assumption could be just what we need.
8.2.2
Alternate methods of proof
8.2.2.1
Contrapositive
Every so often, the direct approach to proving a statement of the form P â‡’Q
bogs down. We should not give up on our proof too early, though. We may
only need to start over at our most recent, â€œWhat are we proving now?â€ Still it
may mean that it is time to erase everything that we have done and start over
completely. Honestly, there are two possible reasons that our proof has bogged

140
8 Advice for Constructing Proofs
down: we are taking the wrong approach or we have made a logical mistake.
Either way, a fresh start at a proof of the statement P â‡’Q can be very helpful.
Once we have honestly concluded that the problem is with our approach to
the proof, we should consider proving the contrapositive (âˆ¼Q) â‡’(âˆ¼P).
Example 8.2.5.
If n, m âˆˆâ„¤and nm is even, then either n is even or m is even.
Proof draft. Assume n, m âˆˆâ„•. Assume that nm is even. Then âˆƒk âˆˆâ„¤s.t.
nm = 2k.
Comment: Now all we need to do is factor. But none of the basic properties of â„•
allow us to factor. We know from school that â„¤has factoring properties, but we
cannot use them unless we prove them. This particular theorem is suspiciously
similar to one of the factoring properties we would want to prove. We have made
our assumptions, we have made a correct observation, but the form of that obser-
vation is not useful given what we know at this point. We could force the proof
onward by considering four cases: n and m are even; n and m are odd; n is even
and m is odd, or m is odd and m is even. But maybe it is just time to start over.
Let us erase the conclusion: âˆƒk âˆˆâ„¤s.t. nm = 2k. That came directly from the
assumption before this, so it should go as well. But we should not get carried away
here. It seems very clear that the assumption that n, m âˆˆâ„¤is something we want
to keep. If we cannot assume that the variables only stand for integers, this proof
will get pretty complicated pretty quickly. We will keep this assumption.
Î”
Proof draft. Assume n, m âˆˆâ„¤.
Comment: Now what are we proving? If nm is even, then either n is even or m is
even. Let us use some mathematical notation and parse this implication clearly:
If (nm is even), then (either n is even or m is even.) The contrapositive of this is:
if âˆ¼(either n is even or m is even), then âˆ¼(nm is even). Using De Morganâ€™s Laws
and the theorem about odd and even numbers, this says: if ( n is odd and m is
odd), then (nm is odd). We go back to the proof.
We will prove: if (n is odd and m is odd), then nm is odd. Assume that n is
odd. Assume that m is odd. Then âˆƒk1 âˆˆâ„¤s.t. n = 2k1 âˆ’1. Also âˆƒk2 âˆˆâ„¤s.t.
n = 2k2 âˆ’1.
Comment: What are we proving now? nm is odd. How should we do this?
Consider nm. Now nm = (2k1 âˆ’1)(2k2 âˆ’1) = 4k1k2 âˆ’2k1 âˆ’2k2 + 1.
Comment: What are we proving now? âˆƒk3 âˆˆâ„¤s.t. nm = 2k3 âˆ’1. We need to set
up a word problem for scratch work.

8.2 Methods of Proof
141
Scratch work:
Solve the following for k3:
2k3 âˆ’1 = 4k1k2 âˆ’2k1 âˆ’2k2 + 1.
(8.6)
Then k3 = 2k1k2 âˆ’k1 âˆ’k2 + 1.
Let k3 = 2k1k2 âˆ’k1 âˆ’k2 + 1.
Comment: What are we proving now? k3 âˆˆâ„¤and nm = 2k3 âˆ’1. Both of these
are easy.
Because these are integers, k3 âˆˆâ„¤. Consider 2k3 âˆ’1. Now 2k3 âˆ’1 =
2(2k1k2 âˆ’k1 âˆ’k2 + 1) âˆ’1 = 4k1k2 âˆ’2k1 âˆ’2k2 + 1 = nm. It follows that nm
is odd.
Î”
So the proof is constructed. We will leave it as an exercise to rewrite the proof
without all of the commentary.
Example 8.2.6.
In this example, we will develop a proof of the statement
If x âˆˆâ„and x â‰¥0, so that âˆ€ðœ€> 0, x â‰¤ðœ€, then x = 0.
Before starting the proof, let us parse the logic just to be sure we know what
this says: If (x âˆˆâ„) and (x â‰¥0) and (âˆ€ðœ€> 0, x â‰¤ðœ€), then (x = 0).
Proof draft. Assume x âˆˆâ„. Assume x â‰¥0. Assume âˆ€ðœ€> 0, x â‰¤ðœ€.
Comment: If we ever have an ðœ€> 0, then we know something else. The proof has
not given us one yet, so we ask â€œWhat am I proving now?â€ The answer is x = 0.
That is absolutely of no help. It is time to try the contrapositive.
Î”
Proof technique. We know from logic that
(P âˆ§Q âˆ§R) â‡’T
is logically equivalent to
(P âˆ§Q) â‡’(R â‡’T).
This means that we can keep any parts of the hypothesis we like and only apply
the contrapositive to the bits we leave behind. This can really save a lot of work.
We will prove
If (x âˆˆâ„) and (x â‰¥0) and (x â‰ 0), then (âˆƒðœ€> 0 s.t. x > ðœ€).

142
8 Advice for Constructing Proofs
Proof draft. Assume x âˆˆâ„and x â‰¥0 and x â‰ 0. Then x > 0. What am I proving
now? (âˆƒðœ€> 0 s.t. x > ðœ€). We need to set up a word problem to ï¬nd ðœ€> 0 so that
x > ðœ€. That is, we want ðœ€so that 0 < ðœ€< x. The magic of the average theorem
does this for us.
Î”
We will rewrite it in the ï¬nal form.
Proposition 8.2.7.
If x âˆˆâ„and x â‰¥0, so that âˆ€ðœ€> 0, x â‰¤ðœ€, then x = 0.
Proof. We will prove the contrapositive: if x âˆˆâ„and x â‰¥0 and x â‰ 0, then âˆƒðœ€>
0 s.t. x > ðœ€.
Assume x âˆˆâ„and x â‰¥0 and x â‰ 0. Then x > 0. Then by the average theorem,
there is an ðœ€âˆˆâ„with 0 < ðœ€< x.
â—½
8.2.2.2
Contradiction
There is one more proof technique that we should have in our tool belt, a proof
by contradiction. It is easy to construct a proof by contradiction that actually
turns out to be either a direct proof or a proof by contrapositive. It is important
to examine every proof by contradiction for this before writing it up. To be a
true proof of P â‡’Q by contradiction, all the assumptions made at the begin-
ning, P and âˆ¼Q, should be part of the reasoning in the middle of the proof, and
they should be used well before the ï¬nal contradiction is reached.
Example 8.2.8.
The inï¬mum of a set is unique.
Proof. We will prove: if m1 is the inï¬mum of S and m2 is the inï¬mum of S, then
m1 = m2.
Assume that m1 is the inï¬mum of S. Assume that m2 is the inï¬mum of S.
Then
1. If x âˆˆS, m1 â‰¤x.
2. If l > m1, then âˆƒx âˆˆS s.t. x < l.
3. If x âˆˆS, m2 â‰¤x.
4. If l > m2, then âˆƒx âˆˆS s.t. x < l.
Comment: We have four rather strong assumptions, but only those four. As far
as what they mean, they are not very helpful right now. Numbers 1 and 3 tell us
something if we ever have an element of S. Number 2 tells us something if we
ever have a number greater than m1. Number 4 tells us something if we ever
have a number greater than m2. None of the four actually give us an object that
any of them can tells us about. We need more! We might think that it is time
to start over by erasing some assumptions and trying a contrapositive. But all
four of these implications look pretty inviting; it would be a shame to give up

8.2 Methods of Proof
143
any of them. We want to keep all four of these facts, but we also need some more
assumptions so that we have a chance to use them.
Assume, by way of contradiction, that m1 â‰ m2.
Comment: Because we kept all four of our facts, we are looking for opportunities
to use them. We are on the lookout for elements of S or numbers greater than m1
or numbers greater than m2. Our last statement doesnâ€™t give any of these exactly,
but we know how it will lead to two cases.
By trichotomy, either m1 < m2 or m2 < m1.
Case 1: Assume m2 > m1. By aforementioned fact 2, we know that âˆƒx âˆˆS s.t.
x < m2.
We now have two more facts to work with: x âˆˆS and x < m2.
Since x âˆˆS, by aforementioned fact 3, m2 â‰¤x. But then by transitivity,
m2 â‰¤x < m2. This is a contradiction.
Case 2: Assume m1 > m2. By aforementioned fact 4, we know that âˆƒx âˆˆS s.t.
x < m1.
Since x âˆˆS, by fact 1, m1 â‰¤x. But then by transitivity, m1 â‰¤x < m1. This is a
contradiction.
In either case, we reach a contradiction, so our most recent assumption
cannot be true. We must have m1 = m2.
â—½
Notice that the four facts drawn from the two original assumptions and the
assumption meant for contradiction are all used in the body of the proof. The
contradiction is reached in two separate cases that appear because of one of
these assumptions. This is truly a proof by contradiction.
There is a direct proof of the result in the last example, if we remember where
our deï¬nition of inï¬mum came from. The deï¬nition of m1 as the inï¬mum of
S is
1. If x âˆˆS, m1 â‰¤x.
2. If l > m1, then âˆƒx âˆˆS s.t. x < l.
But the ï¬rst says that m1 is a lower bound of S. The second is the contraposi-
tive of â€œIf l is a lower bound of S, then m1 â‰¤l.â€ Together they say that m1 is the
greatest lower bound of S. If we remember that an inï¬mum is a greatest lower
bound, we can write a short direct proof.
Example 8.2.9.
The inï¬mum of a set is unique.
Proof. Assume that m1 is the inï¬mum of S. Assume that m2 is the inï¬mum of
S. Then since each is a lower bound, and each is a greatest lower bound, we have
m1 â‰¤m2 â‰¤m1. So m1 = m2.
â—½

144
8 Advice for Constructing Proofs
Right now we are proving the results that are close to our deï¬nitions. It is
always good practice to use those deï¬nitions in our proofs. However, as we
prove more and more theorems, we have more and more results we can use in
our proofs. We are still using the deï¬nitions; it is just that they are hidden in
the proofs of the theorems we use to shorten the proof. Nothing saves time in
constructing and writing a proof as knowing and remembering the previously
proved results.
Example 8.2.10.
In this example, we will attempt a proof by contradiction of
the statement
If n, m âˆˆâ„•and nm is even, then either n is even or m is even.
Notice that we proved this statement earlier for integers and not natural
numbers.
Proof draft. Assume that nm is even. Assume, by way of contradiction and
using De Morganâ€™s Law, that n is not even and m is not even. Then âˆƒk1 âˆˆâ„•
nm = 2k1 and âˆƒk2 âˆˆâ„•s.t. n = 2k2 âˆ’1, and âˆƒk3 âˆˆâ„•s.t. m = 2k3 âˆ’1. So
2k1 = nm
(8.7)
= (2k2 âˆ’1)(2k3 âˆ’1)
= 4k2k3 âˆ’2k2 âˆ’2k3 + 1
= 2(2k1k2 âˆ’k1 âˆ’k2 + 1) âˆ’1.
Claim. If k2, k3 âˆˆâ„•, then 2k2k3 + 1 > k2 + k3.
Proof of claim. Assume k2, k3 âˆˆâ„•. Then k2 â‰¥1 and k3 â‰¥1. So k2k3 â‰¥k3 and
k2k3 â‰¥k2. Adding these, we get 2k2k3 â‰¥k2 + k3. So this tells us that 2k2k3 + 1 >
k2 + k3. Thus, (2k2k3 âˆ’k2 âˆ’k3 + 1) âˆˆâ„•.
â—¾
Thus, 2k1 is odd. This contradicts our theorem that says that a natural number
cannot be both odd and even.
Î”
This proof we gave is not a proof by contradiction. The only place we used
the ï¬rst assumption was to reach the contradiction at the end. Thus, the log-
ical statement we proved was indeed (P âˆ§âˆ¼Q) â‡’(P âˆ§âˆ¼P), but we did it by
actually proving that (âˆ¼Q) â‡’(âˆ¼P).
This is a proof by contrapositive and should be rewritten that way.
Proposition 8.2.11.
If n, m âˆˆâ„•and nm is even, then either n is even or m is
even.

8.3 An Example of a Complicated Proof
145
Proof. We will prove the contrapositive. Assume that n and m are both odd.
Then âˆƒk1 âˆˆâ„•s.t. n = 2k1 âˆ’1; and âˆƒk2 âˆˆâ„•s.t. m = 2k2 âˆ’1. So
nm = (2k1 âˆ’1)(2k2 âˆ’1)
(8.8)
= 4k1k2 âˆ’2k1 âˆ’2k2 + 1
= 2(2k1k2 âˆ’k1 âˆ’k2 + 1) âˆ’1.
Claim. If k1, k2 âˆˆâ„•, then 2k1k2 + 1 > k1 + k2.
Proof of claim. Assume k1, k2 âˆˆâ„•. Then k1 â‰¥1 and k2 â‰¥1. So k1k2 â‰¥k2 and
k1k2 â‰¥k1. Adding these, we get 2k1k2 â‰¥k1 + k2. So this tells us that 2k1k2 + 1 >
k1 + k2.
â—¾
Let k3 = 2k1k2 âˆ’k1 âˆ’k2 + 1. Then k3 âˆˆâ„•and 2k3 âˆ’1 = nm. So nm is odd.â—½
Proof technique. Anytime a proof is originally constructed using contradic-
tion, it should be examined before it is written to see if it is better explained as
either a direct proof or a proof by contrapositive.
8.3
An example of a complicated proof
Example 8.3.1.
Prove the division algorithm for â„•using induction.
Proof draft. We will prove: If n, m âˆˆâ„•and n â‰¤m, then either âˆƒq âˆˆâ„•s.t.
m = nq, or âˆƒq, r âˆˆâ„•s.t. m = nq + r with r < n.
Comment: Induction is used to prove a statement of the form âˆ€n âˆˆâ„•, P(n) is true.
Our theorem seems to be an implication with a hypothesis that is not â€œâˆ€n âˆˆâ„•.â€
No matter what we want to do eventually in a proof, we must ï¬rst maintain our
logical discipline. To prove a statement, begin by writing it as an â€œifâ€¦thenâ€ We
then begin the proof correctly by assuming the hypothesis.
Assume n, m âˆˆâ„•. Assume n â‰¤m.
Comment: Now what are we proving? For all n, m âˆˆâ„•, â€œsomething is true.â€
Remember the important words in what we are proving are the ï¬rst ones. We
are trying to do this by induction. As we just said, induction is used to prove
a statement of the form âˆ€n âˆˆâ„•, P(n). That means we can only induct on one
variable, but it does not mean that the variable must be called n. We have
two variables, n and m, which should we induct on? We cannot forget any
assumptions we have made so far as we make this choice. Induction is all about
all natural numbers, no matter how large. If we induct on n, our assumption

146
8 Advice for Constructing Proofs
that n â‰¤m will mean that n can get no larger than m. That makes it a poor
choice for induction. On the other hand, n â‰¤m means that m can grow to any
size. We should induct on m. While we are doing this, we do not want n to
be moving around. We will prevent this from happening by ï¬xing it, that is,
assuming it to be some particular natural number, but we do not know or care
what number it is. We go back to the proof.
Fix n and use induction on m.
Comment: Let us set up our proof by induction carefully. We are proving âˆ€m,
P(m) is true. So P(m) is
(âˆƒq âˆˆâ„•s.t. m = nq), or (âˆƒq, r âˆˆâ„•s.t. m = nq + r with r < n).
We set up the induction writing out exactly what the two steps will be. The ï¬rst
step is the base, and the second the induction step. The base is the smallest value
of m that the theorem includes. The original theorem certainly includes all values
of m including the smallest number 1. But we have made some assumptions since
then that we have to honor to maintain our logic. We have assumed that m â‰¥n
and n is a ï¬xed number. The smallest value that m can take on at this point is n.
Step 1, The base. Here we must prove that if m = n, then either
1. âˆƒq âˆˆâ„•s.t. m = nq, or
2. âˆƒq, r âˆˆâ„•s.t. m = nq + r with r < n.
Step 2, The induction step. Assume that for m = m0, either
1. âˆƒq âˆˆâ„•s.t. m = nq, or
2. âˆƒq, r âˆˆâ„•s.t. m = nq + r with r < n.
With that assumption, we must prove that for m = m0 + 1, either
1. âˆƒqâ€² âˆˆâ„•s.t. m = nqâ€², or
2. âˆƒqâ€², râ€² âˆˆâ„•s.t. m = nqâ€² + râ€² with râ€² < n.
Comment: It is good that we caught the need for new names in those second â€œthere
exists.â€ That is why it is a good idea to take the eï¬€ort to write out our objective
as an implication and then to read it for its meaning before we start the proof.
Step 1: Assume m = n.
Comment: What are we proving now? Either n divides m with no remainder, or
it leaves a remainder. It looks like we have a choice as to what to prove, but not
really. We can only prove the one that is true. Luckily, because of the â€œor,â€ that is
all we need to prove.

8.3 An Example of a Complicated Proof
147
Let q = 1. Then m = n = n â‹…1 = nq. â—Š
Comment: We chose to prove possibility 1 of the two allowed in the conclusion.
Because that conclusion is in the form of an â€œorâ€ statement, we need only to prove
one of the possibilities. If we prove either one, we have completed the proof. We
chose to prove case 1 for the startlingly obvious reason that it was true under our
assumptions. We chose not to prove possibility 2 for the simple reason that it is
not true under the assumptions in this case.
Step 2: Assume either âˆƒq âˆˆâ„•s.t. m0 = nq, or âˆƒq, r âˆˆâ„•s.t. m0 = nq + r with
r < n.
Comment: We always start the proof of an implication by assuming the hypoth-
esis. In doing so, we have assumed that one of two things is true, but there is no
way to tell which one it is. The only way to proceed is to consider each case one
at a time.
Case 1: Assume âˆƒq âˆˆâ„•s.t. m0 = nq.
Comment: It seems that q is a good enough name for it. The previous q was in
another step, under diï¬€erent assumptions. It is gone by now. But, what are we
proving now? Either âˆƒqâ€² âˆˆâ„•s.t. m0 + 1 = nqâ€², or âˆƒqâ€², râ€² âˆˆâ„•s.t. m0 + 1 = nqâ€² +
râ€² with râ€² < n. We have no way of telling which is true yet, so it looks like cases
exist in the future. But right now it is not clear exactly what those cases are. We
do notice that in either future case we need to say something about m0 + 1. So
we had better consider it and say something true about it.
Consider m0 + 1. Now m0 + 1 = nq + 1.
Comment: That looks good enough that we can take a guess about what to do.
Let qâ€² = q and râ€² = 1.
Comment: What are we proving now? These values work for the second possibility
allowed in the statement. That is, m0 + 1 = nqâ€² + râ€² and râ€² < n. The ï¬rst of these
(m0 + 1 = nqâ€² + râ€²) is so obvious, it seems silly to bother writing it down. We will
anyway.
Now m0 + 1 = nq + 1 = nqâ€² + râ€².
Comment: The second (râ€² < n) seems just as obvious until we look for a reason
to say it. We said that n was ï¬xed, but we never said that it is not ï¬xed at 1. But
let us not panic and just keep moving. We cannot use our â€œ claim it, then prove
itâ€ trick because â€œif n âˆˆâ„•, then n > 1â€ just is not true. We still will not panic,

148
8 Advice for Constructing Proofs
because we must be pretty close. We would have ï¬nished if we have n > 1. Let us
declare this a ï¬rst case and be over with it.
Subcase 1: Assume 1 < n. Then râ€² < n. This proves that the second possibility
in the conclusion holds in this subcase. â—Š
Comment: We indicated that we ï¬nished the proof in this subcase with a
diamond. That does not free us from proving that it works in the other case
though.
Subcase 2: Assume n = 1.
Comment: This is the case where the remainder râ€² = 1 does not seem to work.
But something must. After all, we can divide by any natural number including
n = 1; why canâ€™t we ï¬nd a remainder that works? OK once we say this, we realize
that it is silly. When n = 1, we cannot prove that there is a remainder because
it is not true. When we divide by 1, there is never a remainder. Back to ï¬nishing
the proof of case 1.
Let qâ€² = m0 + 1. Then m0 + 1 = 1 â‹…(m0 + 1) = nqâ€². This is the ï¬rst possibility
in the conclusion of the statement. â—Š
The result is proved in Case 1. â§«
Notice what happened here. At ï¬rst, we chose to prove possibility 2 of the
two allowed in the conclusion. Because that conclusion is in the form of an â€œorâ€
statement, we needed only to prove one of the possibilities. We chose to prove
possibility 2 because it looked like it was true. The â€œ+1â€ in â€œm0 + 1 = nq + 1â€
looked like a ï¬ne remainder. Had it worked, we would have ï¬nished because
we only had to prove one of the allowed possibilities. Unfortunately, it did not
work completely. Had we tried to ï¬x it and prove possibility 2 anyway, we would
have failed. If râ€² = 1 < n is not true, then possibility 2 is not true; so it cannot be
proved. If râ€² = 1 = n, then râ€² is not a valid remainder. If n = 1, only possibility
1 occurs. We need to break the proof in this case into two subcases.
Case 2: Assume âˆƒq, r âˆˆâ„•s.t. m0 = nq + r with r < n. Consider m0 + 1. Then
m0 + 1 = nq + r + 1.
Comment: Why not, it worked the last time? What am I proving now? Either
âˆƒqâ€² âˆˆâ„•s.t. m0 + 1 = nqâ€², or âˆƒqâ€², râ€² âˆˆâ„•s.t. m0 + 1 = nqâ€² + râ€² with râ€² < n. This
time we promise to be less surprised when our ï¬rst guess leads us to a second case.
Let qâ€² = q and râ€² = r + 1. Then m0 + 1 = nq + r + 1 = nqâ€² + râ€².
Subcase 1: Assume r + 1 < n. Then we have râ€² < n, and this proves that the
second possibility in the conclusion holds in this subcase. â—Š
Subcase 2: Assume r + 1 â‰¥n.

8.4 Problems
149
Comment: There must be something that we know that we have not used yet.
It should be close by. We should back up through the proof one statement at a
time looking for it. Working through a speciï¬c example with numbers will help
ï¬nd this.
We said that r < n. So n â‰¤r + 1 < n + 1. But â„•is discrete, so this means
r + 1 = n.
Comment: We are still considering the old m0 + 1.
Then m0 + 1 = nq + r + 1 = nq + n = n(q + 1). If we let, qâ€² = q + 1, we have
proved that the ï¬rst possibility holds in this subcase. â—Š
This ï¬nishes case 2. â—Š
That ï¬nishes the proof.
Î”
We have constructed a proof, but not written it. We should write this proof
by identifying the subcases as early as possible. Outlined, the proof of step 2
will resemble the following:
Assume either âˆƒq âˆˆâ„•s.t. m0 = nq, or âˆƒq, r âˆˆâ„•s.t. m0 = nq + r with r < n.
Case 1: Assume âˆƒq âˆˆâ„•s.t. m0 = nq.
Either n = 1 or n > 1.
Subcase 1: Assume n = 1.
Subcase 2: Assume n > 1.
Case 2: Assume âˆƒq, r âˆˆâ„•s.t. m0 = nq + r with r < n. .
Since r < n and â„•is discrete, we have r + 1 â‰¤n.
Subcase 1: Assume r + 1 = n.
Subcase 2: Assume r + 1 < n.
8.4
Problems
8.1
Prove that the least upper bound of a set is unique.
8.2
Prove that the supremum of a set is unique.
8.3
Prove that if S is a set of real numbers that is not bounded above, then
âˆ€x âˆˆâ„, âˆƒs âˆˆS s.t. x < s.
8.4
Prove that if n âˆˆâ„¤, then n(n + 1) is even.
8.5
Prove that if n âˆˆâ„•and n2 is even, then n is even.

150
8 Advice for Constructing Proofs
8.6
Prove that the set
S = {x âˆˆâ„âˆ£âˆƒs âˆˆâ„such that x = s6 + 19s4 + 11s2 + 14}
has an inï¬mum.
8.7
Let ð›¼, ð›½âˆˆâ„with ð›¼< ð›½.
(a) Prove that there exists s âˆ‰â„šsuch that ð›¼< s < ð›½.
(b) Prove for all n âˆˆâ„•, there are numbers x1, x2, â€¦ , xnâˆ’1, xn âˆ‰â„š, all
diï¬€erent, so that for all i = 1, 2, 3 â€¦ , n, we have a < xi < b.
8.8
Prove for all n âˆˆâ„•,
n
âˆ‘
k=1
(4k3 âˆ’6k2 + 4k âˆ’1) = n4.
8.9
Prove that 1 is the supremum of the set
A =
{
x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x =
n
n + 1
}
.
8.10
Prove that 2 is the inï¬mum of the set
B =
{
x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x = 2n + 3
n + 1
}
.
8.11
Prove that if a âˆˆâ„and for all ðœ€> 0, a â‰¤ðœ€, then a â‰¤0.
8.12
Use the fact that the order in â„•respects addition and has trichotomy to
prove that
(a) If k, n, m âˆˆâ„•with n + k = m + k, then n = m.
(b) If k, n, m âˆˆâ„•with n + k < m + k, then n < m.
8.13
Prove that if r âˆˆâ„then there exists n âˆˆâ„•so that r < n2+100
n
. (Remember
that there is no theorem yet that tells us that every positive real number
has a square root.)

151
9
Sets
Perhaps, the most basic of mathematical objects is the set. Indeed, we have
referred to sets throughout the book so far, relying on an intuitive understand-
ing of the idea.
In Mathematics, a â€œsetâ€ is simply a collection of mathematical objects. We can
build sets of numbers, sets of functions, sets of matrices, and even sets of sets.
Of course, there are contexts in which we might talk about a set of people or a
set of cars. But our context is Mathematics, so we will only concern ourselves
with sets of mathematical objects.
9.1
Deï¬ning sets
To deï¬ne a set, we must precisely specify the members of that set. There are
many ways to do this. For example, we can deï¬ne a set with an English sentence.
For example, we might say
Let A be the set of all even integers.
If A is the set of all even integers, then we would say that any particular even
integer, such as 2, is â€œa member of the set Aâ€ or â€œan element of the set A.â€ The âˆˆ
symbol is used to express this more compactly. So, we write â€œ2 âˆˆAâ€ to say that
2 is a member of the set A. Since 3 is not in A, we would write 3 âˆ‰A.
We have deï¬ned the set A by stating a property that all members of the set
must have. This is very common. Usually, a set is determined by a mathematical
statement that describes a property that all members of the set share. 1 Another
way of writing this is with so-called set-builder notation. This is often more
1 We note here that there are deep and fascinating technical aspects of this description that we
will not address here. These diï¬ƒculties will not matter to us in this course. See the epilogue to this
chapter for more information.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

152
9 Sets
compact than using English alone. Here is one way to deï¬ne A in set-builder
notation:
A = {x âˆ£x is an even integer}.
(9.1)
In general, set-builder notation takes the form
S = {x âˆ£P(x) is true}
(9.2)
where P(x) is some mathematical statement. We read this deï¬nition of the set
S as â€œS is the set of all x such that P(x) is true.â€ So
s âˆˆS if and only if P(s) is true;
s âˆ‰S if and only if P(s) is false.
There are some common variations on set-builder notation that you will see.
For example, people will often use a colon â€œâˆ¶â€ in place of the bar â€œ|â€. That is
ï¬ne; the idea is the same. Sometimes, another condition on elements of a set is
slipped in before the â€œsuch thatâ€ symbol by limiting elements to members of a
larger set. For example, we could have deï¬ned the set of even integers as this:
A = {x âˆˆâ„¤âˆ£x is even}.
(9.3)
Besides using English or set-builder notation to deï¬ne sets, we can deï¬ne sets
by simply listing their elements. For example, we can write
A = { Â· Â· Â· , âˆ’6, âˆ’4, âˆ’2, 0, 2, 4, 6, Â· Â· Â· }
(9.4)
to deï¬ne the set of all even integers. But this really only works when the set
is small enough that all of its elements can be reasonably listed or when the
pattern is strong enough to be recognized. For example, we could write
B = {n âˆˆâ„•âˆ£2 â‰¤n â‰¤5}
or
B = {2, 3, 4, 5}.
(9.5)
And, we could write
C =
{
x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x =
n
n + 1
}
or
C =
{1
2, 2
3, 3
4, 4
5 Â· Â· Â·
}
.
(9.6)
Some people might write that set C in a less standard form that reï¬‚ects the
listed version more closely;
C =
{
n
n + 1 âˆˆâ„šâˆ£n âˆˆâ„•
}
.
(9.7)
Which notation is the best? Well, when it comes to proving something about a
particular set, set-builder notation often works the best. Beyond that, we could
choose to aim for clarity and economy of expression.

9.2 Starting deï¬nitions
153
9.2
Starting deï¬nitions
Deï¬nition 9.2.1.
Let A and B be sets. We say that A is a subset of B when if
x âˆˆA, then x âˆˆB. We write this as A âŠ†B.
For example, if A is a set of even integers, then A âŠ†â„¤. Similarly, {2, 4, 6} âŠ†A.
We know this because we can check that if x âˆˆ{2, 4, 6}, then x âˆˆA. However,
notice that {2, 3, 4} î€–A. It is not true that if x âˆˆ{2, 3, 4}, then x âˆˆA. If A âŠ†B,
we can also say that B is a superset of A and write B âŠ‡A.
Probably the most important thing to take away from the deï¬nition is that it
tells us how to prove that one set is a subset of another:
Proof technique. To prove that one set is a subset of another, A âŠ†B, we
prove the implication if x âˆˆA, then x âˆˆB. Thus, the proof begins with â€œAssume
x âˆˆA.â€
Notice that it would not be correct to say 2 âŠ†A. It is correct to say 2 âˆˆA and
{2} âŠ†A. But {2} and 2 are diï¬€erent objects. That is, 2 â‰ {2}. The set {2} is a
set containing the number 2. That is, 2 âˆˆ{2}. As such, {2} is a subset of A, but
the number 2 is an element of A, not a subset of it.
Deï¬nition 9.2.2.
Let A and B be sets. We say that A equals B when A âŠ†B and
B âŠ†A. We write this as A = B.
This deï¬nition is important: it says that two sets are equal if they have the
same elements. The order in which the elements of a set appear does not matter.
Notice that this is not a requirement we place on sets, but rather it is a result
about sets that follows from the deï¬nition of equality.
Consider the sets
A = {1, 3, 4, 5};
(9.8)
B = {3, 5, 1, 4}.
Checking one element of A at a time, we ï¬nd that 1 âˆˆB, 3 âˆˆB, 4 âˆˆB, and
5 âˆˆB. Therefore, by the deï¬nition of subset, A âŠ†B. Another element-by-
element check on B tells us that B âŠ†A. Once we have both A âŠ†B and B âŠ†A,
by the deï¬nition of equality, A = B. Thus in practice, the order we use to list
or describe the elements of a set does not have an impact on what the set is
because of our deï¬nition of set equality.
Next, consider
C = {1, 3, 4, 5, 1, 4}.
(9.9)
Checking one element of A at a time, we ï¬nd that A âŠ†C. Checking the elements
of C one at a time, we get 1 âˆˆA, 3 âˆˆA, 4 âˆˆA, 5 âˆˆA, 1 âˆˆA, and 4 âˆˆA.

154
9 Sets
So C âŠ†A. We can also check that A âŠ†C, and therefore, by deï¬nition, A = C.
Thus, repeating the elements in a set does not change the set. An element is
either in a set or not in a set; it cannot be in it more than once. Of course,
this could raise the philosophical question, are the two 5s in the list of set C
actually the same thing? After all, there are two of them. And what about the
set
D = {I,III,IV,V}?
(9.10)
The issue is, are we talking about sets of typed letters, symbols for numbers,
or actual numbers? This is Mathematics; so we are deï¬nitely talking about sets
of numbers. As numbers (in Arabic or Roman notation), certainly 1 = 1 = I;
3 = III; 4 = 4 = IV; and 5 =V. In Mathematics, the sets A = C = D are equal.
This is mostly philosophy, but it looks like President Bill Clinton was on to
something when he famously said, â€œIt all depends on what your deï¬nition of
â€˜isâ€™ is.â€
When asked to prove that two sets are equal, it is important to remember the
following:
Proof technique. To prove that two sets are equal, it may be possible to consider
one side and use set properties to show that it is equal to the other. It is more
likely, however, that to prove that two sets are equal, A = B, we must prove the
subset both ways. Thus, proving A = B requires two steps. We must prove both
(1) A âŠ†B and (2) A âŠ‡B.
We have one more deï¬nition related to subsets and set equality.
Deï¬nition 9.2.3.
Let A and B be sets. We say that A is a proper subset of B
when A âŠ†B and A â‰ B. There is no universally used notation for this.
We should note that some people use A âŠ‚B or A âŠŠB for â€œA is a proper subset
of B.â€ Unfortunately, there are also people who use the symbol â€œâŠ‚â€ for any sub-
set instead of the â€œâŠ†â€ that we use. It is an unfortunate loss of a good notational
opportunity, but it is just what has happened. There is no absolute standard
notation for the two subset relations: subset and proper subset. In this study,
we will just stick with the notation â€œâŠ†â€ for subset and explicitly use the word
â€œproperâ€ if we need it. We can still use the symbol â€œâŠ‚â€ for â€œproper subsetâ€ tem-
porarily if that is convenient.
9.3
Set operations
We now discuss how to build new sets from two or more given sets using set
operations. The ï¬rst is the union of two sets.

9.3 Set operations
155
Deï¬nition 9.3.1.
Let A and B be sets. Then
A âˆªB = {x âˆ£x âˆˆA or x âˆˆB}.
(9.11)
We read A âˆªB as â€œA union B.â€ Notice the logical connective word â€œorâ€ in
the deï¬nition of the union. Remember that, in Mathematics, we always take
â€œorâ€ to be inclusive. So, according to this deï¬nition, x âˆˆA âˆªB if and only if
x âˆˆA or x âˆˆB or x is in both A and B. Notice that the language here can be
a bit awkward. In English, we would say that the union of two sets A and B is
obtained by creating a set with all the elements of A and all the elements of B.
This English description of A âˆªB uses the word â€œand,â€ but the mathematically
correct deï¬nition of A âˆªB, the one we will need to prove things, uses the word
â€œor.â€
We also have a set operation that takes two sets and deï¬nes the collection of
objects that are simultaneously in both of those sets. This is called the intersec-
tion of the two sets.
Deï¬nition 9.3.2.
Let A and B be sets. Then
A âˆ©B = {x âˆ£x âˆˆA and x âˆˆB}.
(9.12)
We read A âˆ©B as â€œA intersect B.â€ Notice here the logical connective word
â€œandâ€ in the deï¬nition of intersection. The last set operation we deï¬ne here
employs the logical connective â€œnot.â€
Deï¬nition 9.3.3.
Let A and B be sets. Then
Aâˆ–B = {x âˆ£x âˆˆA and x âˆ‰B}.
(9.13)
We read Aâˆ–B as â€œA not B.â€ We may also say that Aâˆ–B is the complement of
B in A. The direction of the slant in Aâˆ–B is important. We are saving the other
slant for another purpose. In addition, be careful about any English alternatives.
The next theorem is rather obvious. But to prove it formally, we would still
need to prove the subsets in both directions.
Theorem 9.3.4.
Let A, B, C be sets. Then
1. A âˆªB = B âˆªA;
2. A âˆ©B = B âˆ©A;
3. A âˆª(B âˆªC) = (A âˆªB) âˆªC;
4. A âˆ©(B âˆ©C) = (A âˆ©B) âˆ©C.
So in set theory, union and intersection are commutative and associative. We
will not bother to prove these, but notice that we must change one strategy we
use when structuring a proof. If we ï¬nd that we need to prove something like

156
9 Sets
(n + 2)2 = n2 + 4n + 4, we consider each side and use algebra. That is because
both sides are numbers, and algebra applies to numbers. If, however, we ï¬nd
that we need to prove
{n âˆˆâ„¤âˆ£n is even} = {n âˆˆâ„¤âˆ£n âˆ’1 is odd},
(9.14)
these are sets. To prove that sets are equal, we must prove the subset in both
directions. If we see a shortcut using the algebra of set theory, similar to the
aforementioned theorem, we will go for it. But most of the time, to prove for
two sets A = B, we must prove A âŠ†B and B âŠ†A.
Theorem 9.3.5.
Let A, B, C be sets. Then
1. A âˆª(B âˆ©C) = (A âˆªB) âˆ©(A âˆªC);
2. A âˆ©(B âˆªC) = (A âˆ©B) âˆª(A âˆ©C).
So in set theory, union distributes over intersection and intersection dis-
tributes over union. This is a bit of set theory algebra that comes in handy fairly
often. There are several ways to prove this including a pictorial one using Venn
Diagrams. We will stick to using the deï¬nition of set equality just for practice.
We will prove the ï¬rst and use the second as an exercise. The proof of the ï¬rst,
however, uses a logical trick that is worth remembering. (Watch how we avoid
a bunch of subcases in step 2 using the logical equivalence of P â‡’(Q1 âˆ¨Q2)
and (P âˆ§âˆ¼Q1) â‡’Q2.)
Proof. We will prove A âˆª(B âˆ©C) = (A âˆªB) âˆ©(A âˆªC). This is a set equality, so
we must prove two statements
â€¢ A âˆª(B âˆ©C) âŠ†(A âˆªB) âˆ©(A âˆªC), and
â€¢ A âˆª(B âˆ©C) âŠ‡(A âˆªB) âˆ©(A âˆªC).
Step 1. We claim that A âˆª(B âˆ©C) âŠ†(A âˆªB) âˆ©(A âˆªC).
Proof of claim. Assume x âˆˆA âˆª(B âˆ©C). Then, either x âˆˆA or x âˆˆ(B âˆ©C). So
we have two cases to consider.
Case 1: Assume x âˆˆA. Then x âˆˆA âˆªB, no matter what B is. In addition, x âˆˆ
A âˆªC. By the deï¬nition of intersection, x âˆˆ(A âˆªB) âˆ©(A âˆªC). So in this case,
x âˆˆA implies x âˆˆ(A âˆªB) âˆ©(A âˆªC). Thus, A âˆª(B âˆ©C) âŠ†(A âˆªB) âˆ©(A âˆªC).
Case 2: Assume x âˆˆ(B âˆ©C). Then x âˆˆB and x âˆˆC. But x âˆˆB implies x âˆˆ
A âˆªB. And x âˆˆC implies x âˆˆA âˆªC. Since x is in both, x âˆˆ(A âˆªB) âˆ©(A âˆªC).
So in this case, x âˆˆA implies x âˆˆ(A âˆªB) âˆ©(A âˆªC). Thus, A âˆª(B âˆ©C) âŠ†
(A âˆªB) âˆ©(A âˆªC).
Therefore, we have proved A âˆª(B âˆ©C) âŠ†(A âˆªB) âˆ©(A âˆªC).
â—¾
Step 2. We claim that A âˆª(B âˆ©C) âŠ‡(A âˆªB) âˆ©(A âˆªC).

9.3 Set operations
157
Proof of claim. Assume x âˆˆ(A âˆªB) âˆ©(A âˆªC). Then x âˆˆA âˆªB and x âˆˆA âˆªC.
We will prove that x âˆˆA or x âˆˆB âˆ©C by proving that (x âˆ‰A) â‡’(x âˆˆ(B âˆ©C)).
Assume x âˆ‰A. Since x âˆˆA âˆªB, this means we must have x âˆˆB. In addition,
x âˆ‰A and x âˆˆA âˆªC tells us that x âˆˆC. Since x is in both, x âˆˆB âˆ©C.
We have proved that x âˆˆA or x âˆˆB âˆ©C. So we have proved x âˆˆAâˆª(B âˆ©C).
Therefore, (A âˆªB) âˆ©(A âˆªC) âŠ†A âˆª(B âˆ©C).
â—¾
In Step 1, we proved A âˆª(B âˆ©C) âŠ†(A âˆªB) âˆ©(A âˆªC). In Step 2, we proved
(A âˆªB) âˆ©(A âˆªC) âŠ†A âˆª(B âˆ©C). By the deï¬nition of set equality, the two steps
together tell us that A âˆª(B âˆ©C) = (A âˆªB) âˆ©(A âˆªC).
â—½
Theorem 9.3.6.
De Morganâ€™s Laws. Let A, B, C be sets. Then
1. Aâˆ–(B âˆ©C) = (Aâˆ–B) âˆª(Aâˆ–C);
2. Aâˆ–(B âˆªC) = (Aâˆ–B) âˆ©(Aâˆ–C).
We will leave the proofs of these as exercises.
The ï¬nal theorem consists of a few simple facts that appear very often in set
theory arguments.
Theorem 9.3.7.
Let A, B, C be sets. Then
1. If A âŠ†B and B âŠ†C, then A âŠ†C;
2. A âˆªB = A if and only if B âŠ†A;
3. A âˆ©B = B if and only if B âŠ†A.
9.3.1
Families of sets
Occasionally, we need to consider several sets at the same time, as in the afore-
mentioned theorems where A, B, C all stood for sets. There is a point where
using diï¬€erent letters for each set becomes impractical and even confusing,
and three might be that point. If we need to consider, say, 30 sets at once, we
can use one master letter and subscripts that index the sets. So we can write
Ai where i âˆˆ{1, 2, 3, 4 Â· Â· Â· 29, 30}
(9.15)
instead of A1, A2, â€¦, A30.
The real power of this trick is seen when working with inï¬nitely many sets.
For example, we could declare that we have inï¬nitely many sets by giving each
set its own natural number:
Bi where i âˆˆâ„•.
(9.16)
But, there is tremendous ï¬‚exibility here once we observe that there is no rea-
son why our indexes need to count anything; so we could use negative numbers
as indices as well:
Bi where i âˆˆâ„¤.
(9.17)

158
9 Sets
We can use any set at all to index our sets if we want. Suppose that we want to
create a small subset of â„for every real number that contains that number and
the two numbers 7 and 9. No problem,
If x âˆˆâ„, let Ex = {x, 7, 9}.
(9.18)
Then E3 = {3, 7, 9}; Eâˆš
2 = {
âˆš
2, 7, 9}; Eðœ‹= {ðœ‹, 7, 9}; and E7 = {7, 9}. That is a
lot of sets, but they all have their own names, and we know what each name
means. We have a family of sets Ex where x âˆˆâ„. In this case, â„serves as an
index set.
In Mathematics, this is how we indicate a family of sets of any size:
Si where i âˆˆîˆµ.
(9.19)
The index set îˆµcan be any set. The size of the family depends on the size of îˆµ.
We can think of S as the family name and think of îˆµas the list of ï¬rst names
of members of the family. The symbol S stands for nothing on its own, but for
any particular i0 âˆˆîˆµ, Si0 stands for one particular set in the family. Now it can
happen that one member of a family has two or more names in the list (Jack,
Johnny, and John.) The same for families of sets, we can have i â‰ j, and at the
same time Si = Sj. In our aforementioned example, E7 = {7, 9} and E9 = {7, 9},
two names for what turns out to be the same family member. This is a perfectly
ï¬ne family of sets, because no one name stands for diï¬€erent family members.
We can combine and intersect families of sets using the following deï¬nitions:
Deï¬nition 9.3.8.
Let Si where i âˆˆîˆµis a family of sets. Then the union of the
family is
â‹ƒ
iâˆˆîˆµ
Si = {x âˆ£âˆƒi âˆˆîˆµs.t. x âˆˆSi}.
(9.20)
It only takes one i âˆˆI for x to be in the union, and which one works depends
on x. So we might often ï¬nd it better to write
â‹ƒ
iâˆˆîˆµ
Si = {x âˆ£âˆƒix âˆˆîˆµs.t. x âˆˆSix}.
(9.21)
Proof technique. When we ï¬nd that we have a âˆˆâ‹ƒ
iâˆˆîˆµ
Ai, we should usually
name the variables that follow the âˆƒusing the index i and say âˆƒia âˆˆîˆµs.t.
a âˆˆSia.
Notice that this is because, for all x âˆˆâ‹ƒ
iâˆˆîˆµ
Ai, âˆƒix âˆˆîˆµs.t. x âˆˆSix. So the deï¬ni-
tion of a âˆˆâ‹ƒ
iâˆˆîˆµ
Ai is an AE statement in disguise.
Deï¬nition 9.3.9.
Let Si where i âˆˆîˆµis a family of sets. Then, the intersection
of the family is

9.3 Set operations
159
â‹‚
iâˆˆîˆµ
Si = {x âˆ£âˆ€i âˆˆîˆµ, x âˆˆSi}.
(9.22)
After this, we can prove things about families of sets by treating them as sets
and using the deï¬nitions.
Example 9.3.10.
For x âˆˆâ„, let Ex = {x, 7, 9}. This deï¬nes a family of sets.
Then
â‹ƒ
xâˆˆâ„
Ex = â„
and
â‹‚
xâˆˆâ„
Ex = {7, 9}.
Comment: We can prove these by proving the subset each way. But we make sure
not to use the same letter for two diï¬€erent things.
We will ï¬rst prove that â‹ƒ
xâˆˆâ„
Ex = â„.
Proof. This is a set equality; so our proof will have two steps. First, we will prove
that â‹ƒ
xâˆˆâ„
Ex âŠ†â„, and then we will prove that â‹ƒ
xâˆˆâ„
Ex âŠ‡â„.
Step 1. We claim that â‹ƒ
xâˆˆâ„
Ex âŠ†â„.
Proof of claim. Assume y âˆˆâ‹ƒ
xâˆˆâ„
Ex. Then there exists xy âˆˆâ„such that y âˆˆExy =
{xy, 7, 9} âŠ†â„. So y âˆˆâ„.
â—¾
Step 2. We now claim that â‹ƒ
xâˆˆâ„
Ex âŠ‡â„.
Proof of claim. Assume y âˆˆâ„, then y âˆˆ{y, 7, 9} = Ey. So by the deï¬nition of
union, y âˆˆâ‹ƒ
xâˆˆâ„
Ex.
â—¾
We have now proved that both â‹ƒ
xâˆˆâ„
Ex âŠ†â„, and â‹ƒ
xâˆˆâ„
Ex âŠ‡â„. It follows that
â‹ƒ
xâˆˆâ„
Ex = â„.
â—½
Now we will prove that â‹‚
xâˆˆâ„
Ex = {7, 9}.
Proof. This is a set equality, so we must prove both â‹‚
xâˆˆâ„
Ex âŠ†{7, 9} and â‹‚
xâˆˆâ„
Ex âŠ‡
{7, 9}. We will begin by proving the âŠ‡direction.
Step 1. We claim that â‹‚
xâˆˆâ„
Ex âŠ‡{7, 9}.

160
9 Sets
Proof of claim. Assume y âˆˆ{7, 9}. Then, either y = 7, or y = 9. So in either
case, âˆ€x âˆˆâ„, y âˆˆ{x, 7, 9} = Ex. Thus, by the deï¬nition of intersection
y âˆˆâ‹‚
xâˆˆâ„
Ex.
â—¾
Step 2. We claim that â‹‚
xâˆˆâ„
Ex âŠ†{7, 9}.
Proof of claim. To prove â‹‚
xâˆˆâ„
Ex âŠ†{7, 9} we must prove that if x âˆˆâ‹‚
xâˆˆâ„
Ex, then
x âˆˆ{7, 9}. Here we will prove this through the contrapositive. That is, we will
prove that if y âˆ‰{7, 9}, then y âˆ‰â‹‚
xâˆˆâ„
Ex.
Assume y âˆ‰{7, 9}. Then y â‰ 7 and y â‰ 9. Let yâ€² = y + 1. Then y â‰ yâ€². Since
y â‰ 7,and y â‰ 9 and y â‰ yâ€², we know that y âˆ‰{yâ€², 7, 9} = Eyâ€². But then yâ€² âˆˆâ„
such that y âˆ‰Eyâ€². So it is not true that âˆ€x âˆˆâ„, y âˆˆEx. So y âˆ‰â‹‚
xâˆˆâ„
Ex.
â—¾
At this point, we have proved that â‹‚
xâˆˆâ„
Ex âŠ‡{7, 9} and that â‹‚
xâˆˆâ„
Ex âŠ†{7, 9}. It
follows that â‹‚
xâˆˆâ„
Ex = {7, 9}.
â—½
Theorem 9.3.11.
Let A be a set and Bi with i âˆˆîˆµbe a family of sets. Then
1. A âˆª
(â‹‚
iâˆˆîˆµ
Bi
)
= â‹‚
iâˆˆîˆµ
(A âˆªBi);
2. A âˆª
(â‹ƒ
iâˆˆîˆµ
Bi
)
= â‹ƒ
iâˆˆîˆµ
(A âˆªBi);
3. Aâˆ–
(â‹‚
iâˆˆîˆµ
Bi
)
= â‹ƒ
iâˆˆîˆµ
(Aâˆ–Bi);
4. Aâˆ–
(â‹ƒ
iâˆˆîˆµ
Bi
)
= â‹‚
iâˆˆîˆµ
(Aâˆ–Bi).
Notice that each uses the original family of sets Bi with i âˆˆîˆµto deï¬ne another
family. In the ï¬rst, that family is (A âˆªBi) with i âˆˆîˆµ. We will leave the proofs of
these as exercises. Notice, however, that the ï¬rst two are the distributive laws on
steroids. The proofs of these should mirror the proofs of the simpler versions.
The logical trick we used earlier should reappear in the proof of statement 1.
The last two are De Morganâ€™s laws again. And their proofs involve little more
than acknowledging this.
9.4
Special sets
9.4.1
The empty set
There is a set that is deï¬ned by its lack of elements: the empty set. The notation
for the empty set is âˆ…. This set, as simple as it is, can take some getting used to.
The symbol âˆ…stands for a set; thus, âˆ…is an object in Mathematics. So the set

9.4 Special sets
161
{âˆ…} contains an object; that object is a set; that object is the empty set. Thus,
{âˆ…} is not empty because it contains something. So
{âˆ…} â‰ âˆ….
(9.23)
We can, however, say
âˆ…âˆˆ{âˆ…}.
(9.24)
There might be a temptation to write the empty set as { }, but it should be
resisted because { } is just too horrible to be tolerated. The only acceptable
notation for the empty set is âˆ….
Our ï¬rst theorem about sets guarantees that every set has at least one subset.
The empty set is a subset of every set.
Theorem 9.4.1.
If A is a set, then âˆ…âŠ†A.
Proof. We begin as usual: assume that A is a set.
Comment: There is not much we can say about that. So, what are we proving
now? âˆ…âŠ†A. What does this statement in mathematical terms mean? Accord-
ing to the deï¬nition of subset, we must prove: if x âˆˆâˆ…, then x âˆˆA. But x âˆˆâˆ…is
automatically false.
By the rules of logic, the implication â€œif x âˆˆâˆ…, then x âˆˆAâ€ is always true.
â—½
Ignoring the comment, this proof does not say much. This argument used is
often called â€œvacuous implicationâ€ and swallowing it causes some people indi-
gestion. We can try the contrapositive; it is just as vacuous, but often it is easier
to swallow. Again, we will include remarks about how the proof is constructed
that do not belong in a ï¬nal write-up.
Proof. We will prove: if x âˆ‰A, then x âˆ‰âˆ…. Assume x âˆ‰A.
Comment: What are we proving now? x âˆ‰âˆ…. No problem, that is deï¬nitely true.
How do we write this up?
Assuming x âˆ‰A, the conclusion x âˆ‰âˆ…is certainly true. So the statement is
proved.
â—½
The empty set can be a nuisance, but it usually is not if we stick to our logic.
The well-ordering principle in â„•states, if S âŠ†â„•and S â‰ âˆ…, then S has a mini-
mum. To use it, we must know that S âŠ†â„•and that S has at least one element.
As long as we remember to check both conditions, we will be able to say that S
has a minimum. The same goes for the completeness axiom: if S âŠ†â„and S â‰ âˆ…
and S has a lower bound, then S has an inï¬mum in â„. On the other hand, if we
need to prove S âŠ†T, we must prove: if x âˆˆS, then x âˆˆT. Logic allows us to
begin our proof with, â€œAssume x âˆˆS.â€ There is no reason to consider S = âˆ…as

162
9 Sets
a separate case. Here vacuous implication works in our favor. If we are proving
that something exists, we need to be careful before we say, â€œLet x âˆˆS.â€ Before
we say this, we need to be sure that S has at least one element for this to be
valid.
9.4.2
Intervals
There are some subsets of the real numbers that occur so often that they have
their own notation: intervals. An interval is a subset of â„that has no gaps and
has no holes. When we use interval notation, it always applies to all real num-
bers in the set. The following are the notations for various types of intervals:
Deï¬nition 9.4.2.
Let a, b âˆˆâ„and a â‰¤b. Then
(a, b) = {x âˆˆâ„âˆ£a < x < b};
(9.25)
[a, b] = {x âˆˆâ„âˆ£a â‰¤x â‰¤b};
(9.26)
(a, b] = {x âˆˆâ„âˆ£a < x â‰¤b};
(9.27)
[a, b) = {x âˆˆâ„âˆ£a â‰¤x < b};
(9.28)
(a, âˆž) = {x âˆˆâ„âˆ£a < x};
(9.29)
[a, âˆž) = {x âˆˆâ„âˆ£a â‰¤x};
(9.30)
(âˆ’âˆž, b) = {x âˆˆâ„âˆ£x < b};
(9.31)
(âˆ’âˆž, b] = {x âˆˆâ„âˆ£x â‰¤b}.
(9.32)
Note that interval notation always requires that we include all real numbers
in the interval, not just the rational numbers or integers or natural numbers. If
we do want to restrict ourselves to rational numbers in a particular range, we
can use intersection. Thus,
(2, 5) âˆ©â„š= {x âˆˆâ„šâˆ£a < x < b} â‰ (2, 5).
(9.33)
In addition, it is important to note that âˆžis not a real number. It is just a symbol
to tell us that an interval has no upper bound or to tell us that an interval has
no lower bound when âˆ’âˆžis used. In particular, âˆžcannot be in a set of real
numbers. We should not write (although it is not wrong)
(a, âˆž) = {x âˆˆâ„âˆ£a < x < âˆž}
(9.34)
because the second inequality is rather pointless.
There are situations when degenerate forms of this notation pop up. What if
a = b in our ï¬rst four deï¬nitions earlier? For example, we might ï¬nd ourselves
about to write (a, a). We should not write that because there is a much better
name for the set we are trying to describe:
(a, a) = {x âˆˆâ„âˆ£a < x < a} = âˆ….
(9.35)
If we have the empty set, we should always denote it as âˆ….

9.4 Special sets
163
If a = b, we might also ï¬nd ourselves about to write [a, a]. We should not,
because there is a much better name for that set as well:
[a, a] = {x âˆˆâ„âˆ£a â‰¤x â‰¤a} = {a}.
(9.36)
We should use the proper notation for a one-element set. We might also catch
ourselves writing [a, a) or (a, a]. But this is a deï¬nite warning that we might
have a problem with our reasoning. Either one of these sets is a built-in con-
tradiction to trichotomy; so neither of them is well deï¬ned. It might be that all
we have done is discovered the empty set by legitimate reasoning, but it could
just as well be that we have made an algebraic or logical error that has created a
contradiction. One thing is true; something that led us there needs to be ï¬xed!
The ï¬nal degenerate version of interval notation that might appear is actually
a set of all real numbers. We should always replace (âˆ’âˆž, âˆž) with â„.
In the next example, we revisit families of sets, where the sets in the family
are all intervals in â„.
Example 9.4.3.
Prove â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
= {0}.
Proof draft. We are asked to prove a set equality, so we must prove
â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
âŠ†{0} and â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
âŠ‡{0}. Let us start with âŠ‡.
Step 1. We claim â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
âŠ‡{0}.
Proof of claim. We will prove that if x = 0, then x âˆˆâ‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
.
Assume x = 0. Here we have a family of sets indexed by â„•, where for each
n âˆˆâ„•, the associated member of the family is the interval
(
âˆ’1
n, 1
n
)
=
{
x âˆˆâ„âˆ£âˆ’1
n < x < 1
n
}
.
(9.37)
Since âˆ€n âˆˆâ„•, âˆ’1
n < 0 < 1
n, we know âˆ€n âˆˆâ„•, 0 âˆˆ
(
âˆ’1
n, 1
n
)
. Thus, 0 âˆˆ
â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
. So we have proved that if x âˆˆ{0}, then x âˆˆâ‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
. This
means â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
âŠ‡{0}.
â—¾
Step 2. We now claim that â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
âŠ†{0}.
Proof of claim. We will prove that if x âˆˆâ‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
, then x = 0 by proving the
contrapositive. That is, we will prove that if x âˆ‰{0}, then x âˆ‰â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
.

164
9 Sets
Assume x âˆ‰{0}. This means that x â‰ 0.
Comment: What are we proving now? By the deï¬nition of intersection, we need
to prove
âˆƒn âˆˆâ„•s.t. x âˆ‰
(
âˆ’1
n, 1
n
)
.
(9.38)
So we need to set up a word problem to solve in scratch work. Find n âˆˆâ„•so that
x âˆ‰
(
âˆ’1
n, 1
n
)
. That means we need n so that either x < âˆ’1
n or x > 1
n. All we know
is that x â‰ 0. That is not much to go on; all it says is either x > 0 or x < 0. Oh,
oh, two cases.
There are two possibilities, x > 0 or x < 0.
Case 1. Assume x > 0.
Comment: What are we doing now? We want to ï¬nd n so that x < âˆ’1
n or 1
n < x.
Since x > 0, it had better be the latter. We want to ï¬nd n so that 1
n < x. We are
looking for n so we should write this solved for n. We want to ï¬nd n so that n > 1
x.
How do we ï¬nd this? By magic! In this case, magic in the form of the Archimedean
principle.
By the Archimedean principle, since 1
x âˆˆâ„, then there exists nx âˆˆâ„•such that
nx > 1
x. So âˆƒnx âˆˆâ„•s.t. x âˆ‰
(
âˆ’1
nx , 1
nx
)
. All it takes is one member of the family,
so x âˆ‰â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
.
Case 2. Assume x < 0.
Comment: What are we doing now? We want to ï¬nd n so that x < âˆ’1
n or 1
n < x.
Since x < 0, it had better be the former. We want to ï¬nd n so that x < âˆ’1
n. We
are looking for n so we should write this solved for n. We want to ï¬nd n so that
nx < âˆ’1 and so that n > âˆ’1
x because x < 0. (We are lucky we caught that.) How
do we ï¬nd this? By magic again.
By the Archimedean principle, âˆƒnx âˆˆâ„•s.t. nx > âˆ’1
x. So âˆƒnx âˆˆâ„•s.t.
x âˆ‰
(
âˆ’1
nx , 1
nx
)
. All it takes is one member of the family, so x âˆ‰â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
. â—¾
We have now proved that â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
âŠ‡{0} and â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
âŠ†{0}. So it
follows that â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
= {0}.
Î”
If we had remembered that intervals can be written using absolute values,
then we could have avoided the cases in our proof. Let us rewrite this proof in
a more compact form using some previous results.

9.4 Special sets
165
We will prove
â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
= {0}.
(9.39)
Proof. This is a set equality, so we must prove âŠ†and âŠ‡. We begin by proving
the âŠ‡direction.
Step 1. We claim that â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
âŠ‡{0}.
Proof of claim. Assume x = 0. Since âˆ€n âˆˆN, âˆ’1
n < 0 < 1
n, we know that
âˆ€n âˆˆN, 0 âˆˆ
(
âˆ’1
n, 1
n
)
. Thus, 0 âˆˆâ‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
.
â—¾
Step 2. We claim that â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
âŠ†{0}.
Proof of claim. We will prove the contrapositive, if x â‰ 0, then x âˆ‰â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
.
Assume x â‰ 0. Then |x| > 0. So
1
|x| âˆˆâ„. By the Archimedean principle, there
exists nx âˆˆâ„•such that nx >
1
|x|. So |x| >
1
nx . Since for all n,
(
âˆ’1
n, 1
n
)
=
{
y âˆˆâ„âˆ£âˆ’1
n < y < 1
n
}
(9.40)
=
{
y âˆˆâ„âˆ£|y| < 1
n
}
.
We have x âˆ‰
(
âˆ’1
nx , 1
nx
)
. Thus, x âˆ‰â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
.
â—¾
We have now proved that â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
âŠ‡{0} and â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
âŠ†{0}. So it
follows that â‹‚
nâˆˆâ„•
(
âˆ’1
n, 1
n
)
= {0}.
â—½
Proof technique. If we need to prove a statement of the form âˆƒn âˆˆâ„•s.t. P(n),
it is useful to ask ourselves, â€œWhat kind of n do we need?â€ If the answer is â€œa large
one,â€ we should prepare to use the Archimedean principle by asking how large
must it be exactly. If we can solve any resulting inequality so that it has the form
n > P, then we will have exactly what we need to proceed.
Example 9.4.4.
Prove that â‹ƒ
nâˆˆâ„•
(
âˆ’âˆž, 2nâˆ’1
n+1
]
= (âˆ’âˆž, 2).
Proof draft.
Step 1. We claim that â‹ƒ
nâˆˆâ„•
(
âˆ’âˆž, 2nâˆ’1
n+1
]
âŠ†(âˆ’âˆž, 2).

166
9 Sets
Proof
of
claim. Assume
x âˆˆ
â‹ƒ
nâˆˆâ„•
(
âˆ’âˆž, 2nâˆ’1
n+1
]
.
Then
âˆƒnx âˆˆâ„•
s.t.
x âˆˆ
(
âˆ’âˆž, 2nxâˆ’1
nx+1
]
. That is,
x â‰¤2nx âˆ’1
nx + 1 .
(9.41)
Comment: It may be clear to some as to what to do with this inequality, but
we will suppose that it is not. So we ask ourselves, what do we want? We want
x < 2. So we want to ï¬nd something to ï¬t between: x < ? < 2. Since we just found
something that gives one of these inequalities, we might be brave and simply
claim that the other is true. Of course, we will then have to prove it.
We now claim that 2nxâˆ’1
nx+1 < 2.
Comment: We want 2nxâˆ’1
nx+1 < 2. So we want 2nx âˆ’1 < 2(nx + 1). That is, 2nx âˆ’
1 < 2nx + 2, and in turn, âˆ’1 < 2. This is a good thing to want to be true.
To see this, notice that âˆ’1 < 2. Thus, 2nx âˆ’1 < 2nx + 2. So 2nxâˆ’1
nx+1 < 2.
With this claim, we have
x â‰¤2nx âˆ’1
nx + 1 < 2.
(9.42)
So x âˆˆ(âˆ’âˆž, 2).
â—¾
Step 2. We now claim that (âˆ’âˆž, 2) âŠ†â‹ƒ
nâˆˆâ„•
(
âˆ’âˆž, 2nâˆ’1
n+1
]
.
Proof of claim. Assume x âˆˆ(âˆ’âˆž, 2). So x < 2.
Comment: There is not much we can do with this; so we ask, what are we proving
now? The answer is x âˆˆâ‹ƒ
nâˆˆâ„•
(
âˆ’âˆž, 2nâˆ’1
n+1
]
. What does this mean? We need to prove
âˆƒn âˆˆâ„•s.t. x âˆˆ
(
âˆ’âˆž, 2nâˆ’1
n+1
]
. So to prove that something exists, we need to set up
a word problem in scratch work.
Scratch work:
We want n âˆˆâ„•so that x âˆˆ
(
âˆ’âˆž, 2nâˆ’1
n+1
]
. That is, so that x â‰¤2nâˆ’1
n+1 . A bit of
thought, or a good picture, tells us that we want a large natural number n to ï¬t

9.4 Special sets
167
between x < 2. So we want
x â‰¤2n âˆ’1
n + 1
(9.43)
xn + 2x â‰¤2n âˆ’1
2x + 1 â‰¤2n âˆ’nx
2x + 1 â‰¤(2 âˆ’x)n
n â‰¥2x + 1
2 âˆ’x .
Comment: Since we assumed that x < 2, that last division was OK. Now we use
the Archimedean principle to get the n we need. We can return to our proof.
Since x < 2, 2 âˆ’x > 0. Therefore, 2x+1
2âˆ’x âˆˆâ„. By the Archimedean principle,
âˆƒn âˆˆâ„•s.t. n â‰¥2x+1
2âˆ’x . So after some algebra,
x â‰¤2n âˆ’1
n + 1 .
(9.44)
Thus, we have n âˆˆâ„•s.t. x âˆˆ
(
âˆ’âˆž, 2nâˆ’1
n+1
]
. And so x âˆˆâ‹ƒ
nâˆˆâ„•
(
âˆ’âˆž, 2nâˆ’1
n+1
]
.
â—¾
This completes our proof of the set equality.
Î”
This was just a draft, and we can rewrite it into a more direct form.
Theorem 9.4.5.
â‹ƒ
nâˆˆâ„•
(
âˆ’âˆž, 2nâˆ’1
n+1
]
= (âˆ’âˆž, 2).
Proof.
Step 1. We claim that â‹ƒ
nâˆˆâ„•
(
âˆ’âˆž, 2nâˆ’1
n+1
]
âŠ†(âˆ’âˆž, 2).
Proof
of
claim. Assume
x âˆˆ
â‹ƒ
nâˆˆâ„•
(
âˆ’âˆž, 2nâˆ’1
n+1
]
.
Then
âˆƒnx âˆˆâ„•
s.t.
x âˆˆ
(
âˆ’âˆž, 2nxâˆ’1
nx+1
]
. That is, x â‰¤2nxâˆ’1
nx+1 . However, 2nx âˆ’1 < 2nx + 2. So we have
x â‰¤2nx âˆ’1
nx + 1 < 2.
(9.45)
Thus, x âˆˆ(âˆ’âˆž, 2).
â—¾
Step 2. We now claim that (âˆ’âˆž, 2) âŠ†â‹ƒ
nâˆˆâ„•
(
âˆ’âˆž, 2nâˆ’1
n+1
]
.

168
9 Sets
Proof of claim. Assume x âˆˆ(âˆ’âˆž, 2). So x < 2, and 2 âˆ’x > 0. Thus, 2x+1
2âˆ’x âˆˆâ„.
By the Archimedean principle, âˆƒn âˆˆâ„•such that n â‰¥2x+1
2âˆ’x . Now,
n â‰¥2x + 1
2 âˆ’x
(9.46)
2n âˆ’xn â‰¥2x + 1
2n âˆ’1 â‰¥2x + xn
2n âˆ’1 â‰¥(2 + n)x.
Since 2 âˆ’x > 0, this says that x â‰¤2nâˆ’1
n+1 . Since we have n âˆˆâ„•so that
x âˆˆ
(
âˆ’âˆž, 2nâˆ’1
n+1
]
, we can say x âˆˆâ‹ƒ
nâˆˆâ„•
(
âˆ’âˆž, 2nâˆ’1
n+1
]
.
â—¾
â—½
9.5
Problems
9.1
True or false:
(a) âˆ…âˆˆâˆ….
(b) âˆ…âŠ†âˆ….
(c) âˆ…= âˆ….
(d) âˆ…âˆˆ{âˆ…}.
(e) âˆ…âŠ†{âˆ…}.
(f) âˆ…= {âˆ…}.
(g) {âˆ…} âˆˆâˆ….
(h) {âˆ…} âŠ†âˆ….
(i) {âˆ…} = âˆ….
(j) As a subset of â„: âˆ…has a minimum.
(k) As a subset of â„: âˆ…has a lower bound.
(l) As a subset of â„: âˆ…has an inï¬mum.
(m) In the integers, (1, 5) = {2, 3, 4}.
(n) (1, 5) âˆ©â„¤= {2, 3, 4}.
(o) (âˆ’3, 3] has an upper bound.
(p) (âˆ’3, 3] has an inï¬mum.
(q) âˆžâˆˆ[âˆ’3, âˆž].
(r) (0, 4) âŠ†â„š.
(s) (0, âˆž) âˆ©â„¤âŠ†â„š.
(t) (0, âˆž) âˆªâ„¤âŠ†â„š.
(u) (0, 10)âˆ–â„¤âŠ†â„š.
(v) â„¤âˆ–(0, 10) âŠ†â„š.
9.2
Prove {n âˆˆâ„¤âˆ£n is even} = {n âˆˆâ„¤âˆ£n âˆ’1 is odd}.

9.5 Problems
169
9.3
Prove that for all sets A, B, and C:
(a) If A âŠ†B and B âŠ†C, then A âŠ†C.
(b) A âˆªB = A if and only if B âŠ†A.
(c) A âˆ©B = B if and only if B âŠ†A.
9.4
An interval is supposed to be a subset of â„with no gaps and no holes.
Thus, all the following sets are intervals:
â€¢ âˆ…and â„;
â€¢ for a âˆˆâ„, {a}, (a, âˆž), [a, âˆž), (âˆ’âˆž, a) and (âˆ’âˆž, a];
â€¢ and for a < b, (a, b), (a, b], [a, b), and [a, b].
We have deï¬ned every one of these 11 diï¬€erent notations for an inter-
val. We have not, however, said exactly what makes a set an interval.
In this problem, you are asked to give a mathematical deï¬nition of
â€œinterval.â€ You are then asked to prove that any set that satisï¬es that
deï¬nition can be expressed using one of these pieces of notation.
(a) Give a mathematical deï¬nition of â€œintervalâ€ based on the fact that
an interval must contain all the real numbers that lie between any
two numbers in the interval. (Hint: do exactly what this says by start-
ing out your deï¬nition with â€œI âŠ†â„is an interval whenâ€¦â€ To ï¬nish,
interpret the phrase â€œan interval must contain all the real numbers
that lie between any two numbers in the intervalâ€ into logical math-
ematical form using â€œifâ€¦then.â€)
(b) Use your deï¬nition to prove that if A âŠ†â„is a nonempty interval
with upper and lower bounds, then âˆƒa, b âˆˆâ„such that (a, b) âŠ†A âŠ†
[a, b].
(c) Use your deï¬nition to prove that if A âŠ†â„is a nonempty interval
with an upper bound and no lower bound, then âˆƒb âˆˆâ„such that
(âˆ’âˆž, b) âŠ†A âŠ†(âˆ’âˆž, b].
(d) Use your deï¬nition to prove that if A âŠ†â„is a nonempty interval
with a lower bound and no upper bound, then âˆƒa âˆˆâ„such that
(a, âˆž) âŠ†A âŠ†[a, âˆž).
(e) Use your deï¬nition to prove that if A âŠ†â„is a nonempty interval
with no lower bound and no upper bound, then A = â„.
(f) Use your deï¬nition to prove that if A âŠ†â„is an interval, then A has
one of the forms
âˆ…, {a}, (a, b), (a, b], [a, b), [a, b]
(a, âˆž), [a, âˆž), (âˆ’âˆž, b), (âˆ’âˆž, b] or â„.
9.5
Let A, B, C be sets, prove:
(a) A âˆ©(B âˆªC) = (A âˆ©B) âˆª(A âˆ©C).
(b) Aâˆ–(B âˆ©C) = (Aâˆ–B) âˆª(Aâˆ–C).
(c) Aâˆ–(B âˆªC) = (Aâˆ–B) âˆ©(Aâˆ–C).

170
9 Sets
9.6
We suggested that the deï¬nition of the union of a family of sets might
be written as â‹ƒ
iâˆˆîˆµ
Si = {x âˆ£âˆƒix âˆˆîˆµs.t. x âˆˆSix}. Explain how this is related
to the logical structure of an AE statement.
9.7
Deï¬ne a family of sets by: for n âˆˆâ„¤, Sn = {0, Â±n}.
(a) True or false: n = m implies Sn = Sm.
(b) True or false: Sn = Sm implies n = m.
(c) True or false: n â‰ m implies Sn â‰ Sm.
(d) True or false: Sn â‰ Sm implies n â‰ m.
(e) True or false: Every set in the family has three elements.
(f) True or false: If Sn âŠ†Sm, then n = m.
(g) True or false: âˆ€n, m âˆˆâ„¤, Sn âˆ©Sm = {0}.
(h) True or false: âˆ€n, m âˆˆâ„¤, Sn âˆ©Sm â‰ âˆ….
9.8
Deï¬ne a family of sets by: for n âˆˆâ„•, Sn = (âˆ’âˆž, âˆ’1
n) âˆª( 1
n, âˆž).
(a) True or false: n = m implies Sn = Sm.
(b) True or false: Sn = Sm implies n = m.
(c) True or false: n < m implies Sn âŠ†Sm.
(d) True or false: Every set in the family is not empty.
(e) True or false: â‹‚
nâˆˆâ„•
Sn = âˆ….
(f) True or false: âˆ€n âˆˆâ„•, 0 âˆ‰Sn âˆ©Sm.
(g) True or false: If x â‰ 0, then x âˆˆâ‹ƒ
nâˆˆâ„•
Sn.
9.9
Let A be a set and Bi with i âˆˆîˆµbe a family of sets. Prove:
(a) A âˆª
(â‹‚
iâˆˆîˆµ
Bi
)
= â‹‚
iâˆˆîˆµ
(A âˆªBi).
(b) A âˆª
(â‹ƒ
iâˆˆîˆµ
Bi
)
= â‹ƒ
iâˆˆîˆµ
(A âˆªBi).
9.10
Let A âŠ†â„. Prove that A is bounded if and only if there is n âˆˆâ„•such
that A âŠ†(âˆ’n, n).
9.11
Prove that â‹ƒ
nâˆˆâ„•
(âˆ’n, n) = â„.
9.12
Prove that â‹ƒ
nâˆˆâ„•
(
0,
n
n+1
)
= (0, 1).
9.13
Prove that â‹‚
nâˆˆâ„•
(
0, n+1
n
)
= (0, 1].
9.14
True or false, and explain your answer:
(a) â‹‚
ðœ€>0
(1 âˆ’ðœ€, 1 + ðœ€) = â‹‚
ðœ€â‰¥0
(1 âˆ’ðœ€, 1 + ðœ€).

9.6 Epilogue
171
(b) â‹‚
ðœ€>0
[1 âˆ’ðœ€, 1 + ðœ€] = â‹‚
ðœ€â‰¥0
[1 âˆ’ðœ€, 1 + ðœ€].
9.15
Let A be any set. Deï¬ne a family of open sets by Ba = Aâˆ–{a}.
(a) Find â‹‚
aâˆˆA
Ba and prove that your answer is correct.
(b) Find â‹ƒ
aâˆˆA
Ba and prove that your answer is correct.
9.16
Prove that any interval of the form (a, b) can be written as
{x âˆˆâ„âˆ£|x âˆ’c| < d}
for the right numbers c and d.
9.17
For each s âˆˆâ„š, let Es = {1, 1
2, s}.
(a) Find
â‹ƒ
tâˆˆâ„š
Et and prove that your answer is correct.
(b) Find
â‹‚
tâˆˆâ„š
Et and prove that your answer is correct.
9.6
Epilogue
We started out saying,
A set is any collection of objects determined by a mathematical state-
ment P(x).
We noted that
In fact, there are deep technical aspects of sets that this description does
not address.
The â€œdeep technical aspectsâ€ are not much more than adding the informal
phrase â€œbut sets cannot be too big.â€
Consider
S = {x âˆ£x âˆ‰â„š}.
(9.47)
At ï¬rst, this seems to be a reasonable deï¬nition of a set. We know that
âˆš
2 âˆˆS
and ðœ‹âˆˆS. Now {4} is a subset of â„š, but it is not an element of â„š. Thus, we
have {4} âˆˆS. For the same reason, â„•âˆˆS. Pi is the name of the Greek letter ðœ‹,
and Pi âˆˆS. But â€œelevenâ€ is the English word for the rational number 11. That
seems to mean, 11 âˆ‰S, but â€œelevenâ€ âˆˆS. (But that only complicates things even
more. We could also point out that â€œ â€œ elevenâ€ â€ âˆˆS ). The Statue of Liberty is

172
9 Sets
an element of S, as is the island it is on, and the water surrounding the island,
and the ï¬sh in the water, and â€¦
So the set S is really big; is that really a problem? The mathematician, philoso-
pher, and logician Bertrand Russell presented a famous paradox about a set that
is too large. It uses the self-referencing trick. Let
A = {T where T is a set of sets and T âˆ‰T}.
(9.48)
As Russell pointed out, this set cannot exist. If A âˆˆA, that leads to a contra-
diction. But the negation A âˆ‰A leads to a contradiction as well. And this set is
â€œsmallerâ€ than our earlier example S because at least it does not include any of
New York Harbor. Greek logic would have tried to resolve Russellâ€™s paradox by
saying that self-referencing statements are not allowed in logic. But by 1900s,
logicians realized that a self-reference might accidently occur as a result of a
long circular string of legitimate looking statements. A set such as S = {x âˆ£x âˆ‰
â„š} is so large that it accidently does reference itself. After all, it is not a rational
number. Thus, the perfectly legitimate mathematical statement x âˆ‰â„šcannot
be used to deï¬ne a set. But then why should we be so sure that x âˆˆâ„šcan? This
causes us to wonder if sets can be assumed to exist at all. Since we are trying to
base all Mathematics on sets, this is a major philosophical problem!
As Russell discovered, if we are not careful about how we deï¬ne a set, it may
be too big to be a legitimate set. So we need to be more careful. Now GÃ¶del told
us that self-reference is unavoidable, but that does not make it a good thing. As
best we can, we must continue to avoid self-reference in our logic. That is why
once the preliminary ideas of set theory are established, mathematicians always
include a limitation on the size of any set they deï¬ne. Thus, in the standard set
notation, there is usually a condition on elements of the sets that is slipped in
before the â€œsuch thatâ€ symbol. This limits the objects eligible to be included in
the new set to those from a set already known to exist. So we write
A = {x âˆˆâ„|x âˆ‰â„š}
(9.49)
to identify the set of irrational numbers. By limiting the scope of the variable,
we have avoided any possibility of self-reference. We should avoid writing the
set of irrational numbers as
A = {x âˆ£x âˆ‰â„š}
(9.50)
no matter how obvious it is what we mean by that. Still, in a normal mathe-
matics proof, the chances of being sloppy about what we mean like this, and
thus accidently creating a set that is too big is pretty remote. This problem in
deï¬ning large sets mostly occurs in advanced studies of set theory, mathemat-
ical foundations, or Philosophy. In other advanced mathematical studies, there
are logical tricks mathematicians use to skirt this issue. So mostly in this study,
we will just ignore the issue all together.

9.6 Epilogue
173
Finally, in some settings, mathematicians and users of Mathematics ï¬nd it
convenient to create a limit on the size of a set right away by establishing a
â€œuniversal setâ€ from which all elements must be taken. This works best when
the context of the subject will make such an universe obvious. If U is a universal
set, and A âŠ†U, then Uâˆ–A is called the complement of A and is often given its
own notation. In a study of real numbers, choosing â„to be a universal set is
tempting, but we will see that often the best way to study the properties of real
numbers is to study sets of real numbers. So the whole point of introducing
set theory here is to allow us to use sets of real numbers as well as the num-
bers themselves. Declaring a universal set of numbers has only limited value
to us. For that reason, we generally stick to Aâˆ–B where we only consider the
complement of B in the set A. The notation Aâˆ–B eliminates the possibility of
self-reference once A and B are known to be legitimate sets.

175
10
Relations
10.1
Ordered pairs
The next mathematical idea we need to discuss is an ordered pair. This is a famil-
iar concept of algebra. For example, consider the graph of the line y = 2x âˆ’2 in
â„2. We say that the point (3, 4) is on the line y = 2x âˆ’2 because 4 = 2(3) âˆ’2.
The point (3, 4) is an â€œordered pair.â€ It is clearly a pair, and the order matters so
that we know which number to substitute for which variable. That is why we
say that it is an ordered pair.
As we discussed in the previous chapter, order does not matter when deal-
ing with sets. So the two-element set {3, 4} is the same as the two-element set
{4, 3}. So {3, 4} is a pair, but not an ordered pair. Notice that the point (2, 2) is
also on the line y = 2x âˆ’2. Again, (2, 2) is an ordered pair. But the set {2, 2} is
the same as the set {2} â€“ it is not even a pair.
The deï¬nition of equality of sets means that we cannot distinguish the order
in which elements appear in a set and that repeating an element does not change
it. It turns out that there is a way to deï¬ne ordered pairs in terms of sets, but
we must be clever about it. Here is the deï¬nition:
Deï¬nition 10.1.1.
An ordered pair is a set of the form {a, {a, b}}. We write it
as (a, b).
The set {a, {a, b}} is a set with two elements; one is an element of the set
A, and the other is a subset of A. In any case, this is a set, and we know how
sets work.
Assume a, b, c, d âˆˆA, and
{a, {a, b}} = {c, {c, d}}.
(10.1)
The equality of these sets tells us that each is a subset of the other. Since a âˆˆA,
a âˆˆ{c, {c, d}}. So either a = c or a = {c, d}. Of course, this element of A is
not a subset of A; so we must have a = c. Next, {a, b} âˆˆ{a, {a, b}}; so {a, b} âˆˆ
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

176
10 Relations
{c, {c, d}}. Sets must equal sets; so we must have {a, b} = {c, d}. But we just
saw that a = c, so we have {a, b} = {a, d}. So b = d. So we see that
{a, {a, b}} = {c, {c, d}} implies a = c and b = d.
(10.2)
However, we can quickly show that
{a, {a, b}} = {a, {b, a}} = {{b, a}, a}
(10.3)
while {a, {a, b}} â‰ {b, {a, b}} unless a = b.
This means that the set {a, {a, b}} picks out two elements of the set A and dis-
tinguishes one of the two as special. This set, therefore, can denote two elements
of A and indicate that one should be considered as the ï¬rst of the pair. So we
deï¬ned this formally earlier.
The aforementioned observations say that
(a, b) = (c, d) â‡”a = c and b = d
(10.4)
(a, b) â‰ (b, a) unless a = b.
We have tricked our basic set notation to produce a code for a pair of ele-
ments in a particular order. We can be rightfully proud of ourselves for being
clever, but only if we are also clever enough to replace this complicated code for
an ordered pair with something less confusing. Thus, while we have an oï¬ƒcial
set theory deï¬nition of an ordered pair, we try never to think about it that way.
We will never need to use the oï¬ƒcial deï¬nition again except to show oï¬€. A word
of caution about showing oï¬€this way, the only people likely to be impressed by
this tortured bit of logic are those who appreciate the intricacies of fundamen-
tal mathematics and logic. Everyone else will be the opposite of impressed and
think that we are crazy. Our best recourse is to never mention this again espe-
cially in mixed (math/nonmath) company. We will just say that the ordered pair
(a, b) means a ï¬rst and b second as everybody else does.
Deï¬nition 10.1.2.
Let A and B be sets. The (Cartesian) product A Ã— B is the
set
A Ã— B = {(x, y) âˆ£x âˆˆA and y âˆˆB}.
(10.5)
Thus, if A = {1, 2} and B = {2, 3, 4}, then
A Ã— B = {(1, 2), (1, 3), (1, 4), (2, 2), (2, 3), (2, 4)}.
(10.6)
We also write A2 = A Ã— A.
10.1.1
Relations between and on sets
Often, we have relationships between elements in a set that we express by say-
ing â€œa is related to b.â€ What this means will depend upon the context at the

10.1 Ordered pairs
177
moment. Geometric objects might be related by being congruent or, in a diï¬€er-
ent situation, by being similar. Natural numbers might be related by having the
same parity, odd or even. The meaning of â€œrelatedâ€ in â€œa is related to bâ€ is usu-
ally deï¬ned right before or right after the phrase is introduced. As is typical in
Mathematics, we start by investigating the abstract notion of two things being
somehow related without regard to what â€œrelated toâ€ might eventually mean.
One way to say what elements are related to other objects is to simply list
all the pairs of objects where it is meant to be true. This is the basis of our
mathematical deï¬nition of a relation.
Deï¬nition 10.1.3.
Let A and B be sets. A relation between A and B is a subset
îˆ¾âŠ†A Ã— B. If A = B, we say that it is a relation on A and B.
Once we choose to consider such a subset as a relation (and we do not have
to if we do not want to), we usually write
(a, b) âˆˆîˆ¾as aîˆ¾b.
We read this as â€œa is related to b.â€ Once we better understand what a particular
relation is telling us, if anything, we may change the îˆ¾into a symbol that better
represents the meaning of the relationship. We often use symbols such as <, >,
â‰¤, â‰¥, âŠ‚, âŠ†, â‰…, âˆ¼, or â‰ƒ. There are plenty more to choose from. The thing to realize
about all these possibilities for notation is that there are many possible practical
interpretations of a relation with the right properties.
Example 10.1.4.
Let S = {1, 2, 3, 4}. Consider the relation
îˆ¾= {(1, 1), (2, 2), (3, 3), (4, 4)}.
(10.7)
It is pretty clear what relationship this is, and we should choose an appropriate
symbol for it. For (a, b) âˆˆîˆ¾, we write a = b.
Example 10.1.5.
Let S = {1, 2, 3, 4}. Consider the relation
îˆ¾= {(1, 1), (1, 2), (1, 3), (1, 4), (2, 2),
(10.8)
(2, 3), (2, 4), (3, 3), (3, 4), (4, 4)}.
A bit of thought reveals the relationship this is giving us. For (a, b) âˆˆîˆ¾, we
write a â‰¤b.
Example 10.1.6.
Let S = {1, 2, 3, 4}. Consider the relation
îˆ¾= {(1, 2), (2, 4), (3, 3), (4, 2)}.
(10.9)
It is possible that this relation is conveying some meaning, but it could just as
well be random. We could just write (a, b) âˆˆîˆ¾as aîˆ¾b. We could also choose
some arbitrary symbol for which we have no preconceived interpretation as

178
10 Relations
a âŠ©b. We could, and maybe should, just say that it is a relation of some sort
and not give it a notation at all.
Although we have wide latitude in choosing a symbol to represent a new rela-
tion, it would be a very bad idea to choose a symbol that usually has a diï¬€erent
meaning. So we avoid symbols such as =, <, â‰¤, >, â‰¥âˆ¼, â‰…, or â‰¡for newly deï¬ned
relations and instead stick to entirely new symbols. Often, we realize that we
will prove that a relation conveys a particular meaning and choose a symbol
that anticipates that.
It is important to realize that most subsets of A Ã— B are rather useless as rela-
tions. They convey no real information when we try to think of them that way.
The key to identifying when a relation does give useful information is to see if it
has certain speciï¬c properties. We will only consider a few possible properties,
but there are plenty more.
So let us deï¬ne a few properties on relations in sets that we can use later.
Deï¬nition 10.1.7.
Let îˆ¾be a relation on the set A. We say that the relation is
reï¬‚exive when, for all a âˆˆA, aîˆ¾a.
A relation on a set A is reï¬‚exive if â€œeverything is related to itself.â€ Equality is
an example of a reï¬‚exive relation. But â€œless thanâ€ is not a reï¬‚exive relation.
Deï¬nition 10.1.8.
Let îˆ¾be a relation on the set A. We say that the relation is
symmetric when, if aîˆ¾b, then bîˆ¾a.
Equality is symmetric, and again, the â€œless thanâ€ relation is not symmetric.
Deï¬nition 10.1.9.
Let îˆ¾be a relation on the set A. We say that the relation is
transitive when, if aîˆ¾b and bîˆ¾c, then aîˆ¾c.
Both equality and â€œless thanâ€ are transitive relations.
Deï¬nition 10.1.10.
Let îˆ¾be a relation on the set A. We say that the relation
has trichotomy when, for all a, b âˆˆA, exactly one of the following holds: aîˆ¾b,
bîˆ¾a, or a = b.
The ordering relation has trichotomy on all of the number systems we have
studied.
Notice that no relation can be both reï¬‚exive and have trichotomy.
Trichotomy requires that only one of aîˆ¾b or a = b be true at the same time.
Notice also that the deï¬nitions of two of these are phrased as â€œâˆ€a âˆˆA, P(a).â€
The other two are phrased as â€œP â‡’Q.â€ To maintain our logical discipline, we
need to start any proof of these correctly.

10.2 A total order on a set
179
10.2
A total order on a set
10.2.1
Deï¬nition
One thing a relation on a set might tell us is the relative size of the elements of
the set. To do this, the relation must have certain properties.
Deï¬nition 10.2.1.
Let A be a set. A relation on A is a total order when it is
transitive and has trichotomy.
Not surprisingly, once we realize that a relation îˆ¾is a total order, instead of
writing aîˆ¾b, we usually write a < b. There are other symbols available though.
We might write â‹–or â‰ªor âˆor â‹–or â‰ºfor the order relation. Because we will
be working almost exclusively with total orders on sets of numbers, we will
stick with the conventional a < b to refer to the usual ordering of the numbers.
Once we decide to use a < b for a total order, we immediately use a â‰¤b to mean
(a < b) âˆ¨(a = b). We also begin to use other associated notation such as c > d
and g â‰¥h. Notice that, strictly speaking, â€œâ‰¤â€ is not the notation for the total
order. Because a â‰¤b means (a < b) âˆ¨(a = b), it cannot have trichotomy. Now
because of our very general deï¬nition of a relation, â‰¤is still a relation, but that
relation is not a total order. The total order is the relation denoted by <. Because
< has trichotomy, we could have written b â‰®a instead of a â‰¤b, but we choose
not to.
There are other perfectly good orders even for familiar objects. We could
order â„•using alphabetical order, for example. It is a legitimate total order in â„•.
This is a good place to use the notation â‹–for a total order and not <. Thus, we
can truthfully say 8 â‹–7, knowing that we are saying that â€œeightâ€ appears earlier
in the dictionary compared to â€œseven.â€ Unfortunately (or fortunately), neither
addition nor multiplication shows alphabetical order much respect. So it is a
rather useless order for arithmetic in that particular number system.
10.2.2
Deï¬nitions that use a total order
Once we have a set with a total order, every subset inherits that total order.
Now there are a lot of other mathematical terms that come with it. Many of
the terms concentrate on subsets of a large set with the total order. The terms
refer to a property of the large set, but the meaning of the terms refers to its
subsets. The terms are about some overall set that has the total order. We often
call this overall set a â€œuniversal set.â€ This is a useful concept to keep in mind, as
we memorize the following deï¬nitions.
Deï¬nition 10.2.2.
Let U be a set with a total order. Suppose that A âŠ†U.
â€¢ We say that m âˆˆU is a lower bound of A when
if x âˆˆA, then m â‰¤x.

180
10 Relations
â€¢ We say that m âˆˆU is a minimum of A when
m âˆˆA, and
if x âˆˆA, then m â‰¤x.
â€¢ We say that m âˆˆU is an inï¬mum of A when
if x âˆˆA, then m â‰¤x, and
if l > m, then there exists some x âˆˆA with x < l.
Deï¬nition 10.2.3.
Let U be a set with a total order. Suppose that A âŠ†U.
â€¢ We say that m âˆˆU is an upper bound of A when
if x âˆˆA, then x â‰¤m.
â€¢ We say that m âˆˆU is a maximum of A when
m âˆˆA, and
if x âˆˆA, then x â‰¤m.
â€¢ We say that m âˆˆU is a supremum of A when
if x âˆˆA, then x â‰¤m, and
if l < m, then there exists some x âˆˆA such that x > l.
All of these should be familiar by now. So should the proofs of the following
theorems.
Theorem 10.2.4.
Let U be a set with a total order.
1. If A âŠ†U has a minimum, then it is unique. In this case, we can write:
m = Min(A).
2. If A âŠ†U has a maximum, then it is unique. In this case, we can write:
m = Max(A).
3. If A âŠ†U has an inï¬mum, then it is unique. In this case, we can write:
m = Inf (A).
4. If A âŠ†U has a supremum, then it is unique. In this case, we can write:
m = Sup(A).
Theorem 10.2.5.
Let U be a set with a total order.
1. If A âŠ†U and m = Inf (A), then m is the greatest of all lower bounds of A.
2. If A âŠ†U and m = Sup(A), then m is the least of all upper bounds of A.
Of course, if A has a lower bound, it is probably not unique. We can see that
if m is a lower bound on A and mâ€² < m, then mâ€² is also a lower bound on A.
This is why we use the notation m =Min(A) to say that m is the minimum of
A; m =Max(A) to say that m is the maximum of A; m =Inf(A) to say that m
is the inï¬mum of A; and m =Sup(A) to say that m is the supremum of A; but
we absolutely do not use m =Lb(A) to say that m is the lower bound of A. We
always want our notation to be well deï¬ned.

10.2 A total order on a set
181
Deï¬nition 10.2.6.
Let U be a set with a total order. We say that U is well
ordered when, if A âŠ†U is not empty, then A has a minimum.
Be very careful here, for a set U to be well ordered, every nonempty subset of
U must have a minimum. It is not enough for U to have a minimum alone.
Deï¬nition 10.2.7.
Let U be a set with a total order. We say that U is complete
when, if A âŠ†U is not empty and is bounded below, then âˆƒm âˆˆU such that
m = Inf (A).
Again, it is the universal set that is complete. Every nonempty subset of U
that is bounded below must have an inï¬mum. That inï¬mum must come from
the universal set U. That is why â„•is well ordered, but â„¤is not well ordered. In
addition, that is why â„is not well ordered, but it is complete and why â„šis not
complete even though it is a subset of â„which is complete.
We have seen the next theorem and its proof before, but it is worth repeating
in this more general context.
Theorem 10.2.8
(The Alternate Completeness Axiom). Let U be a set with
a total order that is complete. If B âŠ†U is not empty and is bounded above, then
there is an m âˆˆU so that m = Sup(B).
Before we prove this theorem, we create a temporary deï¬nition and state and
prove a lemma. Notice the role that the universal set U plays in the proof.
Let U be a set with a total order. For S âŠ†U, let
UB(S) = {u âˆˆU âˆ£u is an upper bound on the set S}.
(10.10)
Lemma 10.2.9.
If s âˆˆS, then s is a lower bound of UB(S).
Proof. Assume s âˆˆS.
Assume x âˆˆUB (S).
Then
x âˆˆ{u âˆˆâ„âˆ£u is an upper bound on the set S}.
(10.11)
Thus, since s âˆˆS, we have s â‰¤x. So indeed, x âˆˆUB (S) implies s â‰¤x. So s is a
lower bound of UB(S).
â—½
Now we are ready to prove the theorem.
Proof. Assume that U is a set with a total order
Assume that U is complete. Thus, every subset of U that is not empty and
bounded below has an inï¬mum.
Assume B âŠ†U.

182
10 Relations
Assume B â‰ âˆ….
Assume that B has an upper bound t. Then t âˆˆUB(B). So UB(B) â‰ âˆ….
Since B â‰ âˆ…, âˆƒb âˆˆB.
By the lemma, b is a lower bound of UB(B).
Therefore, UB(B) âŠ†U; UB(B) â‰ âˆ…; and UB(B) is bounded below.
But the completeness axiom, âˆƒm âˆˆU s.t. m = Inf (UB(B)).
So if x âˆˆUB(B), then m â‰¤x. The contrapositive of this is: if m > x, then
x âˆ‰UB(B).
And if l > m, then âˆƒx âˆˆUB(B) such that x < l.
Claim. m = Sup (B).
Proof of claim.
Part 1. First, we will prove: if y âˆˆB, then m â‰¤y.
Assume y âˆˆB. Assume by way of contradiction that y > m. Then by the last
observation âˆƒx âˆˆUB(B) such that x < y. But then x is an upper bound on B and
so y â‰¤x. Then x < y â‰¤x is a contradiction.
Part 2. Now we will prove: if l < m, then âˆƒy âˆˆB s.t. y > l.
Assume l < m. By the contrapositive stated just before the claim,
l âˆ‰UB(B).
(10.12)
Thus, l is not an upper bound of B. Thus, there must be an element y âˆˆB that
prevents this. So y âˆˆB with y > l.
These two parts prove that m = Sup(B).
â—¾
Thus, B has a supremum, and our proof is complete.
â—½
10.3
Equivalence relations
10.3.1
Deï¬nitions
Not only can relations on a set be used to measure the size, but they can also
be used to tell when elements are â€œsort ofâ€ the same. Of course, exactly what
this means depends on the context. Typically, the relation is deï¬ned carefully
before it is used. Still, most relations are useless, and a relation cannot mean
â€œsort of the sameâ€ unless it has certain properties.
Deï¬nition 10.3.1.
Let A be a set. A relation on A is an equivalence relation
when it is reï¬‚exive, symmetric, and transitive.
Before we can tell if a relation on a set A is an equivalence relation, we must
be given a very precise deï¬nition telling us which elements are related. To use

10.3 Equivalence relations
183
the relation, we simply assign the deï¬nitions as its complete meaning, no more
and no less.
Example 10.3.2.
Let S = {1, 2, 3, 4}. Consider the relation given by
îˆ¾= {(1, 1), (2, 2), (2, 3), (3, 2), (3, 3), (4, 4)}.
(10.13)
Upon checking, we ï¬nd that this is reï¬‚exive, symmetric, and transitive. It is an
equivalence relation.
Example 10.3.3.
Consider the relation on â„¤given by a â‰b if and only if a âˆ’b
is divisible by 7. Upon checking, we ï¬nd that this is reï¬‚exive, symmetric, and
transitive. It is an equivalence relation.
Example 10.3.4.
Consider the relation on â„given by a âŠªb if and only if
|a âˆ’b| < 1. Upon checking, we ï¬nd that this is reï¬‚exive, symmetric, but it is
not transitive. It is not an equivalence relation.
Not surprisingly, once we realize that a relation îˆ¾is an equivalence relation,
instead of writing aîˆ¾b, we usually write something like a â‰¡b or a âˆ¼b or a â‰ƒb.
There are even more symbols used for equivalence relations than symbols for
order, and any one of them might be used in a particular situation. There is no
real standard. One good thing though, we rarely have more than one equiv-
alence relation on a set to consider at a time. Once we have a deï¬nition and
choose a symbol, that is it until we change the subject entirely.
Example 10.3.5.
Deï¬ne a relation on â„¤by n â‰ƒm if n âˆ’m is even. The answer
to the question â€œWhat does â‰ƒmean?â€ is â€œIt means n âˆ’m is even,â€ no more or no
less. The answer to the question â€œWhat does â‰ƒtell us about integers?â€ requires
a mathematical investigation. The ï¬rst step in such an investigation is to prove
that â‰ƒis an equivalence relation:
Reï¬‚exivity. We claim that â‰ƒis reï¬‚exive. That is, we claim: If n âˆˆâ„¤, then
n â‰ƒn.
Proof of claim. Assume n âˆˆâ„¤. Consider n âˆ’n. Since n âˆ’n = 0 is even,
n â‰ƒn.
â—¾
Symmetry. We now claim that â‰ƒis symmetric. That is, we claim:
If n â‰ƒm, then m â‰ƒn.
Proof of claim. Assume n â‰ƒm. Then n âˆ’m is even. So there exists k âˆˆâ„¤such
that n âˆ’m = 2k. Consider m âˆ’n. Now
m âˆ’n = âˆ’(n âˆ’m) = âˆ’2k = 2 â‹…(âˆ’k)
(10.14)
is even. So m â‰ƒn.
â—¾

184
10 Relations
Transitivity. We ï¬nally claim that â‰ƒis transitive. That is, we claim:
If n â‰ƒm and m â‰ƒp, then n â‰ƒp.
Proof of claim. Assume n â‰ƒm. So n âˆ’m is even. So âˆƒk âˆˆâ„¤s.t. n âˆ’m = 2k.
Assume m â‰ƒp. So m âˆ’p is even. So âˆƒkâ€² âˆˆâ„¤s.t. m âˆ’p = 2kâ€². Consider n âˆ’p.
Now
n âˆ’p = (2k + m) âˆ’(m âˆ’2kâ€²) = 2k + 2kâ€² = 2(k + kâ€²)
(10.15)
is even. So n â‰ƒp.
â—¾
Since â‰ƒis reï¬‚exive, symmetric, and transitive, it follows that â‰ƒis an equiva-
lence relation.
Proving that speciï¬c examples such as this are equivalence relations is not
diï¬ƒcult if we maintain our logical discipline by writing each as an implication.
We just start each part of the proof with the correct assumptions. However, we
must have and use an exact mathematical deï¬nition of the speciï¬c relation.
10.3.2
Equivalence classes
Now we move back to the study of any relation that happens to be an equiva-
lence relation. We see how we can put an equivalence relation to good use.
Deï¬nition 10.3.6.
Let A be a set with an equivalence relation â‰¡. For any
a âˆˆA, the equivalence class of a is the set
[a] = {x âˆˆA âˆ£x â‰¡a}.
(10.16)
Using our aforementioned example where n â‰¡m means n âˆ’m is even (the
notation for the equivalence does not matter), we can see that
[5] = {n âˆˆâ„¤âˆ£x â‰¡5}
(10.17)
= {n âˆˆâ„¤âˆ£x âˆ’5 is even}
= {5, 7, 9, 11 â€¦} âˆª{â€¦ âˆ’3, âˆ’1, 1, 3}
= {â€¦ âˆ’3, âˆ’1, 1, 3, 5, 7, 9, 11 â€¦}.
We need to be sure to ï¬nd all the equivalent n when we create a list. In addition,
[8] = {n âˆˆâ„¤âˆ£x â‰¡8}
(10.18)
= {â€¦ âˆ’2, 0, 2, 4, 6, 8, 10, â€¦ 12, 14 â€¦}.
And
[11] = {â€¦ 1, 3, 5, 7, 9, 11, 13, 15 â€¦}
(10.19)
[0] = {â€¦ âˆ’4, âˆ’2, 0, 2, 4 â€¦}
[1] = {â€¦ âˆ’3, âˆ’1, 1, 3, 5 â€¦}.

10.3 Equivalence relations
185
By our deï¬nition of set equality, many of these are the same:
[5] = [11] = [1];
(10.20)
[8] = [0];
[0] â‰ [1].
In the end, there are actually only two diï¬€erent equivalence classes for this
particular equivalence relation: the set of odd integers and the set of even
integers.
Theorem 10.3.7.
Let A be a set with an equivalence relation â‰¡. Assume that
a, b âˆˆA.
1. a âˆˆ[a].
2. If a âˆˆ[b], then [a] = [b].
3. If [a] âˆ©[b] â‰ âˆ…, then [a] = [b].
Proof. Assume that we have an equivalence relation â‰¡on the set A. Assume
that a, b âˆˆA.
Since we have an equivalence relation, it is reï¬‚exive. So a â‰¡a. This shows that
a âˆˆ[a] and proves part 1.
To prove part 2, assume a âˆˆ[b]. Then a â‰¡b. Since [a] and [b] are sets, we
prove that they are equal by proving subset both ways.
(âŠ†): Assume x âˆˆ[a]. Then x â‰¡a. But we assumed that a â‰¡b. By transitivity,
x â‰¡b. So x âˆˆ[b]. Thus, if x âˆˆ[a], then x âˆˆ[b]. This proves that [a] âŠ†[b].
(âŠ‡): Assume x âˆˆ[b]. Then x â‰¡b. But we assumed that a â‰¡b. So by symmetry,
b â‰¡a. By transitivity, x â‰¡a. So x âˆˆ[a]. Thus, if x âˆˆ[b], then x âˆˆ[a]. This proves
that [b] âŠ†[a].
Since [a] âŠ†[b] and [b] âŠ†[a], it follows that [a] = [b], and part 2 is proved.
Finally, let us prove part (3). Assume [a] âˆ©[b] â‰ âˆ…. So âˆƒc âˆˆ[a] âˆ©[b]. So
c âˆˆ[a] and c âˆˆ[b]. However, part 2 tells us that c âˆˆ[a] implies [c] = [a], and
c âˆˆ[b] implies [c] = [b]. So [a] = [c] = [b].
â—½
10.3.3
Equivalence partitions
This set algebra for equivalence classes is useful in its own right, but we will
rewrite it as another theorem.
Theorem 10.3.8.
Let A be a set with an equivalence relation â‰¡. Then
â‹ƒ
aâˆˆA
[a] = A;
(10.21)
if [a] âˆ©[b] â‰ âˆ…, then [a] = [b].

186
10 Relations
Proof. Assume that A is a set with an equivalence relation â‰¡.
Claim. We ï¬rst prove that â‹ƒ
aâˆˆA
[a] = A.
Proof of claim. This is a set equality, so we must prove set inclusion both ways.
(âŠ†): Since âˆ€a âˆˆA, [a] âŠ†A, â‹ƒ
aâˆˆA
[a] âŠ†A.
(âŠ‡): Assume x âˆˆA. Then by the last theorem, x âˆˆ[x]. So x âˆˆâ‹ƒ
aâˆˆA
[a].
â—¾
Claim. We next claim that if [a] âˆ©[b] â‰ âˆ…, then [a] = [b].
This is exactly what was stated and proved in Theorem 10.3.7
â—½
So if a relation on a set A is reï¬‚exive, symmetric, and transitive, it is an equiv-
alence relation. An equivalence relations tells us that two elements of A are
â€œsort ofâ€ the same. That is, a â‰¡b tells us that a and b are equivalent in some
sense. The exact sense in which they are equivalent depends on the deï¬nition
of the symbol â‰¡at that time. The last theorem tells us that, if we gather the
equivalent elements of A into equivalence classes, every element of A ends up
in exactly one of them. In addition, there is no overlap between two diï¬€erent
classes. Even one element in common to two of the classes means that they are
the same class.
That leads to our next deï¬nition; actually, it is more of a notation.
Deï¬nition 10.3.9.
Let A be a set with an equivalence relation â‰¡. We deï¬ne a
new set called â€œA modulo equivalenceâ€ or â€œA mod â‰¡â€ as
Aâˆ•â‰¡= {[a] âŠ†A âˆ£a âˆˆA}
(10.22)
where [a] = {x âˆˆA âˆ£x â‰¡a}.
Thus, Aâˆ•â‰¡means that the set made up of the equivalence classes deï¬ned by
the relation â‰¡. Thus, Aâˆ•â‰¡is a set of clumps of stuï¬€from A. It is not a subset of
A, but it is a set of subsets of A. It provides a way to treat the elements of A that
are â€œsort ofâ€ the same as if they were actually the same.
In our example, we saw that [0] = [2] = [4] = [âˆ’8] = â€¦ . We also saw that
[1] = [3] = [5] = [âˆ’3] â€¦. It seems that the equivalence class of any even num-
ber is the set of all even numbers, and the equivalence class of any odd number
is the set of all odd numbers. The equivalence relation â‰ƒthat we deï¬ned on â„¤
divides â„¤into two disjoint sets. (Disjoint means that they have no element in
common.) Thus, we can write
(â„¤âˆ•â‰ƒ) = {[0], [1]}
(10.23)
= {The set of even integers, The set of odd integers}.

10.3 Equivalence relations
187
10.3.3.1
Well deï¬ned
There is one last thing to say about the set formed by â€œmod-ing out by equiva-
lence.â€ (That is to say, sets of the form Aâˆ•â‰¡.) The elements in this type of set have
more than one name. By deï¬nition,
Aâˆ•â‰¡= {[a] âŠ†A âˆ£a âˆˆA}.
(10.24)
But if a1 â‰¡a2 even though a1 â‰ a2, we still have [a1] = [a2]. Thus, a1 â‰¡a2 are
diï¬€erent elements of the set A; but they are equivalent elements of A. Each can
be used to identify an element of Aâˆ•â‰¡. The equivalence class of a1 is an element
of Aâˆ•â‰¡, which we write as [a1]. The equivalence class of a2 is an element of Aâˆ•â‰¡,
which we write as [a2]. If a1 â‰¡a2, then their equivalence classes are equal as
sets: [a1] = [a2]. In the set of equivalence classes Aâˆ•â‰¡, they are equal classes; so
they are the same element of Aâˆ•â‰¡. Thus, we can say that a1 and a2 are both valid
names for the same element [a1] = [a2] of Aâˆ•â‰¡. In any set formed by equivalence
classes, any one class can have multiple names.
This matters when it comes time to deï¬ne something on a set such as Aâˆ•â‰¡.
We want all mathematical deï¬nitions to give unique results. When we deï¬ne
something on elements of Aâˆ•â‰¡, we usually use the names of those objects. Thus,
we need to know that the thing we deï¬ne does not depend on the name for
the elements involved. The issue of the uniqueness of a deï¬nition on a set of
the type Aâˆ•â‰¡comes up so often that it has its own terminology; we talk about a
deï¬nition being well deï¬ned.
For example, we go back to the equivalence relation where n â‰ƒm means that
n âˆ’m is even. Thus,
â„¤âˆ•â‰ƒ= { â€¦ [âˆ’3], [âˆ’2], [âˆ’1], [0], [1], [2], [3] â€¦ }
(10.25)
= {[0], [1]}
= {the set of odd integers, the set of even integers}.
Now there are only two elements in â„¤âˆ•â‰ƒbecause all the even numbers are equiv-
alent and all the odd numbers are equivalent.
Suppose that we try to deï¬ne a way to add two elements of â„¤âˆ•â‰ƒby
[n] + [m] = [n + m].
(10.26)
Now suppose that [n] = [6] = [0] and [m] = [âˆ’3] = [1]. We have four choices
when it is time to compute [n + m]:
[6 + (âˆ’3)]; [6 + 1]; [0 + (âˆ’3)] or [0 + 1].
(10.27)
We must check that all four choices give the same answer; that is what â€œwell
deï¬nedâ€ means. Since 3, 7, âˆ’3, and 1 are all odd, they all belong to the same
equivalence class:
[6 + (âˆ’3)] = [6 + 1] = [0 + (âˆ’3)] = [0 + 1].
(10.28)

188
10 Relations
To be sure that this addition is well deï¬ned, we must prove it. We need to prove
that, if we use diï¬€erent names to add elements of â„¤âˆ•â‰ƒ, we still get the same
answer. (We rephrased the problem as an â€œif then.â€)
Proof technique. When asked to prove that something is â€œwell deï¬ned,â€ this
often indicates that the objects involved have more than one possible name,
and the thing being deï¬ned depends on the name used. Thus, we begin a proof
by assuming that each ingredient in deï¬nition is given by two diï¬€erent names.
Application of the deï¬nition should produce a unique result even if not a
unique name.
Claim. We claim that addition of the equivalence classes â„¤âˆ•â‰ƒis well deï¬ned.
That is, we claim that
If [n1] = [n2] and [m1] = [m2], then [n1] + [m1] = [n2] + [m2].
Proof of claim. Assume [n1] = [n2] and [m1] = [m2]. Then n1 âˆ’m1 is even, and
n2 âˆ’m2 is even. By a previous theorem (that we could reprove if we wanted to),
the sum (n1 âˆ’m1)+ (n2 âˆ’m2) is even. And so (n1 + n2) âˆ’(m1 + m2) is even. So
[n1 + n2] = [m1 + m2]. So [n1] + [m1] = [n2] + [m2].
â—¾
10.4
Problems
10.1
Prove:
(a) Let U be a set with a total order. If A âŠ†U has a minimum, then it
is unique.
(b) Let U be a set with a total order. If A âŠ†U has a maximum, then it is
unique.
(c) Let U be a set with a total order. If A âŠ†U has an inï¬mum, then it
is unique.
(d) Let U be a set with a total order. If A âŠ†U has a supremum, then
it is unique.
(e) Let U be a set with a total order. If A âŠ†U and m = Inf(A), then m
is the greatest of all lower bounds of A.
(f) Let U be a set with a total order. If A âŠ†U and m = Sup(A), then m
is the least of all upper bounds of A.
10.2
Let U be the integers. Prove that if S âŠ†U with S â‰ âˆ…and where S is
bounded above, then S has a maximum.

10.4 Problems
189
10.3
Let U be a set with a total order (with at least two elements). For S âŠ†U,
let
UB(S) = {u âˆˆU âˆ£u is an upper bound on the set S};
LB(S) = {l âˆˆU âˆ£l is an upper bound on the set S}.
Prove:
(a) âˆ€S âŠ†U, S âŠ†LB(UB(S)).
(b) âˆ€S âŠ†U, S âŠ†UB(LB(S)).
(c) âˆƒS âŠ†U s.t. S â‰ LB(UB(S)).
(d) âˆƒS âŠ†U s.t. S â‰ UB(LB(S)).
10.4
Consider the relation on â„¤deï¬ned by nîˆ¾m if n + m is even.
(a) Is îˆ¾reï¬‚exive?
(b) Is îˆ¾symmetric?
(c) Is îˆ¾transitive?
(d) Does îˆ¾have trichotomy?
10.5
Consider the relation on â„deï¬ned by n â‰ƒm if n âˆ’m âˆˆâ„¤.
(a) Is â‰ƒreï¬‚exive?
(b) Is â‰ƒsymmetric?
(c) Is â‰ƒtransitive?
(d) Does â‰ƒhave trichotomy?
10.6
Let A = {a, b, c}. Let îˆ¼(îˆ­) = {S | S âŠ†A}.
(a) Is the relation â€œis a subset ofâ€ a relation on A?
(b) Is the relation â€œis a subset ofâ€ a relation on îˆ¼(A)?
(c) Does the relation â€œis a subset ofâ€ have transitivity on îˆ¼(A)?
(d) Does the relation â€œis a subset ofâ€ have trichotomy on îˆ¼(A)?
(e) Is the relation â€œis a subset ofâ€ a total order on îˆ¼(A)?
(f) Is îˆ¼(A) well ordered by the relation â€œis a subset of?â€
10.7
Explain how a set of equivalence classes Aâˆ•â‰ƒis related to a family of sets.
10.8
Consider the relation on a nonempty set A deï¬ned by aîˆ¾b is
always true.
(a) Describe îˆ¾as a set.
(b) Is îˆ¾reï¬‚exive?
(c) Is îˆ¾symmetric?
(d) Is îˆ¾transitive?
(e) Does îˆ¾have trichotomy?
10.9
Consider that the relation on a nonempty set A deï¬ned by aîˆ¾b is
never true.

190
10 Relations
(a) Describe îˆ¾as a set.
(b) Is îˆ¾reï¬‚exive?
(c) Is îˆ¾symmetric?
(d) Is îˆ¾transitive?
(e) Does îˆ¾have trichotomy?
10.10
Consider the set S = {1, 2, â€¦ , 100}. But, consider this set ordered in
alphabetical order. Write â€œn appears in alphabetical order before mâ€ as
n â‰ºm.
(a) Is this a total order on S?
(b) What is the minimum of the set S in alphabetical order?
10.11
Consider the set S = { âˆ’1000, âˆ’999, â€¦ , 0, â€¦ , 999, 1000}. Suppose
that we consider S with alphabetical order.
(a) Is this a total order on S?
(b) Is 8 a lower bound on the set of negative integers in S?
(c) Is 10 a lower bound on the set of negative integers in S?
(d) Does the set S have a minimum in this order?
(e) Is 1 an upper bound on the negative integers in S?
(f) Does the set of negative integers in S have a maximum in this order?
(g) Show that addition does not respect alphabetical order.
10.12
If A is a set with a total order, why do we never use the symbol â‰¤for the
order?
10.13
Let U be a set with a total order that is complete. For S âŠ†U, let
UB(S) = {u âˆˆU âˆ£u is an upper bound on the set S}.
(10.29)
(a) Prove: If s âˆˆS, then s is a lower bound of UB(S).
(b) Prove: If S â‰ âˆ…and UB(S) â‰ âˆ…, then UB(S) has an inï¬mum.
(c) Prove: If S â‰ âˆ…and UB(S) â‰ âˆ…, then UB(S) has a minimum.
10.14
Consider the relation on â„¤given by a â‰b if and only if a âˆ’b is divisible
by 7.
(a) Prove that this is an equivalence relation.
(b) Describe [3] for this relation.
(c) Find â„¤âˆ•â‰.
(d) Prove that an addition on â„¤âˆ•â‰deï¬ned by [n] + [m] = [n + m] is well
deï¬ned.
10.15
Consider the relation on â„given by a âŠªb if and only if |a âˆ’b| < 1.
(a) Prove that this is reï¬‚exive and symmetric.
(b) Find an example where it is not transitive.

10.4 Problems
191
10.16
Let S = â„¤Ã— â„•. Deï¬ne a relation on S by (n, m) â‰¡(p, q) if nq = mp.
(a) Prove that this is an equivalence relation.
(b) The set Sâˆ•â‰¡has a much better and more familiar name. What is it?
(c) Deï¬ne an addition on Sâˆ•â‰¡by [(n, m)] âŠ•[(p, q)] = [(nq + mp, mq)].
Prove that it is well deï¬ned.
(d) We cannot deï¬ne an addition on Sâˆ•â‰¡by [(n, m)] âŠ•[(p, q)] = [(n +
p, m + q)]. Why not?
10.17
Deï¬ne a relation â‹–on the set â„š(
âˆš
2) = {a + bðœ™âˆ£a, b âˆˆâ„š} by
s + tðœ™â‹–u + ð‘£ðœ™if |s âˆ’u|(s âˆ’u) < 2|ð‘£âˆ’t|(ð‘£âˆ’t).
(10.30)
Prove that the relation satisï¬es trichotomy. (You might also prove that
it is transitive, but this is not an exercise for the faint of heart.)
10.18
True or False:
(a) For all sets A and B, A âˆªB âŠ†A Ã— B.
(b) For all sets A, A Ã— âˆ…= A.
(c) â„¤is a well-ordered set.
(d) â„šis a well-ordered set.
(e) â„is a well-ordered set.
(f) â„¤is a complete set.
(g) â„šis a complete set.
(h) â„is a complete set.
(i) âˆ…has a lower bound in â„.
(j) âˆ…has a minimum in â„.
(k) âˆ…has an inï¬mum in â„.
(l) â„•has an inï¬mum in â„.
(m) â„¤has a lower bound in â„.
10.19
Consider the set S = {a, b, c, d, e, f } and the relation îˆ¾âŠ†îˆ¿Ã— îˆ¿given
by
îˆ¾={(a, a), (a, b), (a, d), (b, a), (b, b), (b, d), (c, c),
(10.31)
(c, f ), (d, a), (d, b), (d, d), (e, e), (f , c), (f , f )}.
As it happens, îˆ¾is an equivalence relation on S. Given this, ï¬nd Sâˆ•îˆ¾.
10.20
Consider the set S = {a, b, c, d, e, f } and the relation îˆ¾âŠ†îˆ¿Ã— îˆ¿given
by
îˆ¾= {(a, a), (a, b), (a, d), (a, c), (a, f ),
(10.32)
(b, a), (b, b), (b, d), (c, c),
(c, f ), (d, a), (d, b), (d, d), (e, e), (f , c), (f , f )}
As it happens, îˆ¾is not an equivalence relation on S. Because of this,
Sâˆ•îˆ¾is not deï¬ned. What happens if you try to ï¬nd it anyway?

192
10 Relations
10.21
The alternate completeness axiom is called this because it could be used
in place of our oï¬ƒcial completeness axiom.
Let U be a set with a total order and suppose that if for all B âŠ†U with B
not empty and B bounded above, there is an m âˆˆU so that m = Sup(B).
Prove that if A âŠ†U is not empty and bounded below, then there is an
m âˆˆU so that m = Inf(A).

193
11
Functions
11.1
Deï¬nitions
11.1.1
Preliminary ideas
The next relation we study is a familiar one that relates elements in two sets.
The idea of a function is central to all of Mathematics. Unfortunately, there are
some mild disagreements over the meaning of the most common notation for
functions, and this slips over into any precise deï¬nition that we might give.
Since one of our objectives in this study is to be as careful as possible, we will
need to be very precise as we discuss this very familiar concept especially in
regard to the notation. Luckily, this extremely heightened level of precision for
functions will mostly be restricted to this chapter.
The most familiar functions in algebra and calculus are functions mapping
the real numbers to the real numbers that are given by a formula. Thus, typically
when we ï¬rst learn about functions, we are told that they are given by a rule.
For example, if x is a real number, then f (x) is the number given by the rule
â€œTake the number x; square it, and add 1 to the result.â€ That is, f (x) = x2 + 1.
Eventually, we learn more complicated rules such as
|x| =
âŽ§
âŽª
âŽ¨
âŽªâŽ©
x
if x > 0
0
if x = 0
âˆ’x
if x < 0
.
(11.1)
As long as there is no ambiguity in the rule, we have a function. That is to say,
the result of applying a function to a number should be unique.
Functions mapping the real numbers to the real numbers have nice pictures,
their graphs. Given a curve drawn on the Cartesian plane, we learn to apply the
rule given by the curve:
Find the point x on the x-axis; follow it up or down to a point on the
curve; follow that point over to the y-axis; and the value of that point on
the y-axis is f (x).
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

194
11 Functions
Because the value of f (x) must be unique, we learn to recognize the graph of
a function by applying the â€œvertical line test.â€
Now we are interested in more general types of functions, functions that go
from any set to any other set. For example, suppose that a company is setting
up a lunch for employees from all of its departments. To make sure that people
get a chance to meet others that they might not normally come in contact with,
the organizers create a list of table assignments. Each attendee is given a card
with a table number from 1 to 10. They deliberately assign each table to create
an interesting group of members. This assignment is a function from the set of
attendees to the set of numbers 1 through 10. There is no strict â€œruleâ€ in the
function. An attendee cannot ï¬nd their table by following any rule other than
â€œLook at your card.â€ The organizers have a rationale in creating the function,
but not a speciï¬c rule.
Just before the name cards are placed on the tables, someone drops them.
It is too late to reconstruct the original function, and the table cards are
distributed randomly as people arrive. This creates a new function from the
list of attendees to the numbers 1 through 10. This new assignment is still a
function even though there is no rhyme or reason for the assignments. It is a
function even though there is no rule or even a rationale for the assignments
given by the function. It is a function because it is an assignment of one person
to exactly one table. It passes a type of â€œvertical line testâ€ because no one
person is assigned to two tables. It pairs a person with a table number; it is this
pairing that makes a function.
11.1.2
The technical deï¬nition
Because there is some disagreement about where functions are deï¬ned, our
deï¬nition might not be the exact same as we would see in a diï¬€erent mathe-
matical study. However, as we examine it, it will be clear how close it must be to
any other possible deï¬nition. Our deï¬nition also has the advantage that it con-
forms to the deï¬nitions of related terms that have been used in earlier courses.
This extra careful deï¬nition will mean that we do not have to change the way
we learned to talk about functions in algebra and calculus. In a short time, we
will rely on our old understanding of function. Soon we will no longer need to
be so careful with the technical deï¬nition we give here.
The technical deï¬nition is not the way we were ï¬rst introduced to functions.
And at ï¬rst, it does seem a bit odd.
Deï¬nition 11.1.1.
Let A and B be sets. A function from A to B is a pair (f , B)
where f âŠ†A Ã— B such that if (a, b1) âˆˆf and (a, b2) âˆˆf , then b1 = b2.
Typically, we introduce a function as f âˆ¶â„â†’â„and write (a, b) âˆˆf as
f (a) = b. By now we can recognize a uniqueness property when we see one.

11.1 Deï¬nitions
195
In terms of the notation, the second requirement in the deï¬nition guarantees
that for a function f âˆ¶A â†’B, we know that f (a) âˆˆB is unique to the element
a. In the new notation, the condition in the pairs:
if (a, b1) âˆˆf and (a, b2) âˆˆf , then b1 = b2.
becomes
if f (a) = b1 and f (a) = b2, then b1 = b2.
Thus, when we have a function f âˆ¶A â†’B, the notation f (a) has only one pos-
sible meaning, just as all mathematical notation should.
Notice that the important thing is the assignment, and there is no require-
ment about how that assignment is made except that, once made, it is always
the same for that particular function. That is to say, f can be any relation from
the set A Ã— B as long as it satisï¬es the uniqueness property. It is not hard to see
that this uniqueness property is just a generalized statement of the old famil-
iar vertical line test applied to situations where there are no lines and â€œverticalâ€
makes no sense.
As familiar as some of these are, the idea that a function is a pair (f , B) and not
a â€œruleâ€ is a bit odd. The relation f âŠ†A Ã— B in this pair need not follow any set
â€œrule;â€ rather, it is just an assignment of a unique element in B for each element
of A. The assignment is listed out by the ordered pairs in the relation. If the
function (f , B) has a rule, it is simply â€œlook at the list of assignments given in
the relation f âŠ†A Ã— B.â€
The set A in the pair is a set of things for which the relation could make an
assignment: â€œthe things that may go into the function.â€ For some reason, we
will not require every element of A to actually receive an assignment. Soon
we will give a name to the subset of A for which the function does make an
assignment: â€œthe things that do go into the function.â€ (Not all mathematicians
agree with this decision to not require every element of A to be associated with
a b in B.) The set B denotes â€œthe things that may come out of the function.â€
Again, we do not require that every element of B be used, and this generally is
the way it works in all Mathematics. Soon we will give a name to the subset of
B of â€œthe things that do come out of the function.â€
For some reason, we made a point of including B in the pair (f , B) in deï¬n-
ing a function. This makes the set B an important part of the deï¬nition of a
function. It is every bit as important in identifying the exact function as the
assignment implied by the relation f . We will investigate this very carefully in
a few examples. We start with a function between two rather small sets.
Example 11.1.2.
Let A = {1, 2, 3, 4, 5}, Let B = {2, 4, 6, 8}.
Let f = {(1, 2), (2, 4), (3, 4), (4, 8)}. Then (f , B) satisï¬es the deï¬nition of a
function. It is a bit easier to see this in the following table.

196
11 Functions
x
f (x)
1
2
2
4
3
4
4
8
5
For each x âˆˆA except x = 5, there is a unique value assigned to f (x). It
is certainly possible to describe f (x) as a rule in words, but nothing natu-
ral comes to mind. Nevertheless, it is a perfectly ï¬ne function f âˆ¶A â†’B.
The oï¬ƒcial deï¬nition â€œ(f , B) where A = {1, 2, 3, 4, 5}, B = {2, 4, 6, 8}, and
f = {(1, 2), (2, 4), (3, 4), (4, 8)}â€ indeed gives a function, but after that, the best
way to deal with f (x) is by the table.
Example 11.1.3.
Let
A = B = â„.
Let
f = {(a, b) âˆˆâ„2 âˆ£ab = 1}.
This
describes a diï¬€erent function (f , B). We are not very likely to use the technical
deï¬nition for it. Rather, we would normally say f âˆ¶â„â†’â„is given by f (x) = 1
x.
The technical deï¬nition is still in the background, but we immediately move
to the superior notation to work with the function. Notice that 0 âˆˆA = â„, but
f (0) is not deï¬ned.
Before we look at a few more examples, we give some deï¬nitions that will
help us draw distinctions between similar functions. We will then look at this
last example and other examples related to it very carefully.
Deï¬nition 11.1.4.
Let f âˆ¶A â†’B be a function. The domain of f is
Domain(f ) = {a âˆˆA âˆ£âˆƒb âˆˆB s.t. (a, b) âˆˆf }
= {a âˆˆA âˆ£âˆƒb âˆˆB s.t. f (a) = b}.
Of course, the second form is the one we will use exclusively once we are done
with the technicalities of this chapter. Notice that the deï¬nition of a function
means that Domain(f ) âŠ†A.
Deï¬nition 11.1.5.
Let f âˆ¶A â†’B be a function. The range of f is
Range(f ) = {b âˆˆB | âˆƒa âˆˆA s.t. (a, b) âˆˆf }
= {b âˆˆB | âˆƒa âˆˆA s.t. f (a) = b}.
The deï¬nition of function guarantees that Range(f ) âŠ†B.
Notice that there is nothing in the deï¬nition of a function that requires that
Domain(f ) = A or Range(f ) = B. This is where other deï¬nitions of a function
may diï¬€er from ours.

11.1 Deï¬nitions
197
Deï¬nition 11.1.6.
Let f âˆ¶A â†’B be a function. The codomain of f is:
Codomain(f ) = B.
Deï¬nition 11.1.7.
Let f âˆ¶A â†’B be a function. We say that f (x) is injective
(one-to-one) when
if f (a1) = f (a2), then a1 = a2.
Deï¬nition 11.1.8.
Let f âˆ¶A â†’B be a function. We say that f (x) is surjective
(onto) when
if b âˆˆB, then âˆƒa âˆˆA s.t. f (a) = b.
All of these, except the codomain, should be familiar. The domain of the func-
tion is the set of things you can actually put into the function and get a result
out. The range of a function is the collection of things that actually come out
of the function. The range is a subset of the codomain, which is just a list of
what you think may come out before you get to examine the function closely. A
function is injective, if it satisï¬es the â€œhorizontal line test.â€ It is permission to
â€œcancelâ€ a function in an equation
(f (a) = f (b)) â‡’(a = b)
(11.2)
although no self-respecting mathematician would ever admit doing so. A
function is surjective if everything that might come out actually does. In other
words, a function f âˆ¶A â†’B is surjective when Range(f ) = Codomain(f ).
11.1.2.1
A word about notation
Before we start, we should say a few things about the notation. The common
notation for a function (f , B) is f âˆ¶A â†’B, where we write (a, b) âˆˆf as f (a) =
b. By the uniqueness requirement in the deï¬nition, there is no ambiguity in
the meaning of f (a). Now that we are becoming more mathematically sophis-
ticated, it is good practice to always introduce a function with the notation
f âˆ¶A â†’B. Our deï¬nition of function still allows us to think the way we have
before. In calculus of any sort, it is common to introduce a function f âˆ¶â„â†’â„
by giving a formula for f (x).
For example, we might say
let f âˆ¶â„â†’â„be given by f (x) = 1
x.
The domain of this function is â„âˆ–{0} because 0 has no multiplicative inverse.
We could have admitted that this is the case by saying more precisely
let f âˆ¶â„âˆ–{0} â†’â„be given by f (x) = 1
x.

198
11 Functions
While â„âˆ–{0} is the actual domain of the function, it looked at ï¬rst like it
was â„. Thus saying f âˆ¶â„â†’â„only identiï¬es â„as a potential domain of the
function. This potential domain has no oï¬ƒcial name, and it is used simply as
a matter of convenience. The advantage of this imprecision is that we can say
â€œLet f âˆ¶â„â†’â„be given by f (x) =
1
x3âˆ’3x+5â€ without spelling out the precise real
numbers where the function is not deï¬ned.
We will often need to acknowledge this technicality by making assumptions
about the domain as a part of later deï¬nitions and theorems. Thus, we will say
â€œLet f âˆ¶â„â†’â„have domain Aâ€ when we mean any unspeciï¬ed function with
the exact domain A âŠ†â„.
Example 11.1.9.
Let us explore the similarities and diï¬€erences between the
functions
1. f1 âˆ¶â„â†’â„given by f1(x) = 1
x,
2. f2 âˆ¶â„â†’â„âˆ–{0} given by f2(x) = 1
x,
3. f3 âˆ¶â„âˆ–{0} â†’â„given by f3(x) = 1
x, and
4. f4 âˆ¶â„âˆ–{0} â†’â„âˆ–{0} given by f4(x) = 1
x.
First, there is one obvious similarity between these four functions. In each
case, the rule used to deï¬ne the function is the same, namely the formula 1
x.
As a consequence, none of these four functions are deï¬ned at x = 0. Another
similarity is that y = 0 is not in the range of any of these functions. Thus, all of
these functions have the same graph â€“ namely
{(x, y) âˆˆâ„2 âˆ£xy = 1}.
(11.3)
And, if we were to draw a picture of this graph, it would be the same for all four
functions (Figure 11.1).
As we can see, the ordered pairs form a geometric shape that we call a curve,
and it satisï¬es the vertical line test. Of course, the curve is a geometric rep-
resentation of a set of ordered pairs. It is technically not equal to the set of
ordered pairs. It is technically not the function either. Once we become experts,
we might at times treat the curve as though it were the function. But if that ever
causes confusion, we must return to our roots and use the careful deï¬nitions.
Now we turn to the diï¬€erences between these four functions.
1. f1 âˆ¶â„â†’â„given by f1(x) = 1
x.
Technically, the function is the ordered pair (f1, â„), where
f1 = {(x, y) âˆˆâ„2 âˆ£yx = 1}.
(11.4)
We ï¬nd that f1(x) is injective, but because 0 is not in the range, f1(x) is not
surjective. And
Domain(f1) = â„âˆ–{0};

11.1 Deï¬nitions
199
âˆ’4
âˆ’2
2
4
âˆ’2
âˆ’1
1
2
x
y
Figure 11.1 y = 1
x .
Range(f1) = â„âˆ–{0};
Codomain(f1) = â„.
2. f2 âˆ¶â„â†’â„âˆ–{0} given by f2(x) = 1
x.
Here, technically the function is (f2, â„âˆ–{0}), where
f2 = {(x, y) âˆˆâ„2 âˆ£yx = 1}.
(11.5)
Although as sets of ordered pairs we have f1 = f2 (and drawing the graph of
f2 again gives Figure 11.1), the fact that â„â‰ â„âˆ–{0} makes the pairs diï¬€erent.
That is, the functions, according to our deï¬nition, are diï¬€erent. That is good,
because the answers to the fundamental questions about the two functions
are diï¬€erent.
We ï¬nd that f2(x) is injective, and it is also surjective (unlike f1(x)). We also
have
Domain(f2) = â„âˆ–{0};
Range(f2) = â„âˆ–{0};
Codomain(f2) = â„âˆ–{0}.
3. f3 âˆ¶â„âˆ–{0} â†’â„given by f2(x) = 1
x.
Technically, the function is (f3, â„) where
f3 = {(x, y) âˆˆâ„2 âˆ£yx = 1}.
(11.6)
We can again draw a picture of the relation f3 on the Cartesian plane â„2 and
obtain Figure 11.1. As indicated earlier, it is again quite clear that as sets of
ordered pairs f1 = f2 = f3.
Now the codomain is part of the deï¬nition of functions as pairs (f3, â„). But
the potential domain is conspicuously not. Thus, as pairs (f3, â„) = (f1, â„),
while (f3, â„) â‰ (f2, â„âˆ–{0}). So according to our technical deï¬nition, the func-
tions (f3, â„) and (f1, â„) are the same function, but (f3, â„) is not the same

200
11 Functions
function as (f2, â„âˆ–{0}). We should see this reï¬‚ected in the answers to the
fundamental questions about f1(x), f2(x), and f3(x). We ï¬nd that f3(x) is injec-
tive, but not surjective, and
Domain(f3) = â„âˆ–{0};
Range(f3) = â„âˆ–{0};
Codomain(f3) = â„.
4. f4 âˆ¶â„âˆ–{0} â†’â„âˆ–{0} given by f4(x) = 1
x.
Technically, the function is (f4, â„âˆ–{0}) where
f4 = {(x, y) âˆˆâ„2 âˆ£yx = 1}.
(11.7)
Again, a picture of the relation f4 on the Cartesian plane â„2 would be
Figure 11.1. We have f1 = f2 = f3 = f4.
As pairs (f3, â„) = (f1, â„), and (f4, â„âˆ–{0}) = (f2, â„âˆ–{0}). Thus, we expect that
the answers to the fundamental questions about f2(x) and f4(x) will be the
same, but not the same answers as for f1(x) and f3(x)
We ï¬nd that f4(x) is both injective and surjective, and
Domain(f4) = â„âˆ–{0};
Range(f4) = â„âˆ–{0};
Codomain(f4) = â„âˆ–{0}.
Example 11.1.10.
Let f5 âˆ¶(0, âˆž) â†’â„be given by f4(x) = 1
x.
This looks like it might be f1(x) again since the prospective domain we use
should not matter. But we must be careful. The potential domain has changed
so much that it added a condition on the ordered pairs in the set f5. This time
f5 is given by
f5 = {(x, y) âˆˆâ„2| x > 0 and yx = 1}.
(11.8)
We draw a picture of f5 on the Cartesian plane â„2, as shown in Figure 11.2.
The ordered pairs still form a curve that satisï¬es the vertical line test, but it is
only a part of the curves formed by f1 = f2 = f3 = f4. We have f5 âŠ†f1, because we
used the same formula for both functions, but we do not have f5 = f1 because
the pairs are not equal. Since (f1, â„) â‰ (f5, â„), the functions are diï¬€erent by our
technical deï¬nition.
We ï¬nd that f5(x) is injective but not surjective. In addition,
Domain(f5) = (0, âˆž);
Range(f5) = (0, âˆž);
Codomain(f5) = â„.

11.1 Deï¬nitions
201
âˆ’4
âˆ’2
2
4
âˆ’2
âˆ’1
1
2
x
y
Figure 11.2 y = 1
x for x > 0.
Notice that the formula 1
x is the same for f1(x), f2(x), f3(x), f4(x), and f5(x).
However, we have the functions f1 âˆ¶â„â†’â„, f2 âˆ¶â„â†’â„âˆ–{0}, f3 âˆ¶â„âˆ–{0} â†’â„,
and f4 âˆ¶â„âˆ–{0} â†’â„âˆ–{0}. The codomain immediately made f1(x) diï¬€erent than
f2(x) and f4(x). But because only the potential domain was given in f1 âˆ¶â„â†’â„,
and its actual domain given in f3 âˆ¶â„âˆ–{0} â†’â„, that change had no impact on
the ordered pairs. So the functions are technically the same. On the other hand,
f5 âˆ¶(0, âˆž) â†’â„really restricts the potential domain and thus shrinks the actual
domain. That has the eï¬€ect of making the set f5 a proper subset of f1. Since f5 â‰ f1
as sets of ordered pairs, they cannot be the same function: (f1, â„) â‰ (f5, â„).
The prospective domain in the notation f âˆ¶A â†’B may not be part of the
technical deï¬nition, but it might have an impact on the ordered pairs in that
technical deï¬nition. We need to pay attention to it.
Just as promised, this was pretty technical. Still these distinctions will shift
into the background very soon. Every once in a while the technical deï¬nition of
a function might raise its ugly head â€“but mostly not. If it does appear, it really
is not something that will be hard to deal with. Even in this chapter where the
technical deï¬nition should play a big role, it only really comes up in one place.
In that case, it makes things easier rather than more diï¬ƒcult.
We have one last type of function we want to identify, a bijection. To be a
bijection, a function must meet three conditions:
Deï¬nition 11.1.11.
Let f (x) be a function presented as f âˆ¶A â†’B. We say
that f (x) is bijective when 1) Domain(f ) = A, 2) f (x) is injective, and 3) f (x) is
surjective.
The ï¬rst condition in the deï¬nition of a bijective function is important given
our deï¬nition of a function. To be a bijection, f âˆ¶A â†’B must have the set A as
its full domain. That way, for every a âˆˆA, f (a) is deï¬ned.

202
11 Functions
11.2
Visualizing functions
11.2.1
Graphs in â„2
We learned how to visualize functions f âˆ¶â„â†’â„as curves in the Cartesian
plane long ago, and we can use this skill to a great advantage. However, we need
to adapt some of our ideas about graphing to this new more careful setting. In
our old setting, a curve could be interpreted as a function y = f (x) by looking
at the points on it. Here x was the positive or negative distance of the point
on the curve from the vertical axis, and y is the distance above or below the
horizontal axis. There is nothing wrong with this, but it would be better if we
looked at a curve as a function in a way that ï¬ts our deï¬nition better. For us,
a function f âˆ¶â„â†’â„has three important components: the relation, f âŠ†â„2; a
domain, Domain(f ) âŠ†â„; and a codomain, Codomain(f ) = â„. In a graph, the
relation f denotes the ordered pairs that make up the curve itself. Visually, we
should note that
The domain is on the x-axis, and the codomain is on the y-axis.
The value x = a gives a point on the x-axis, which is in the domain. Above
or below it is a point on the curve, (a, b) âˆˆf âŠ†â„2. The value y = b gives a
point on the y-axis, which is the codomain. The function is best viewed as
an assignment of a point x = a on the x-axis to a point y = b on the y-axis.
The curve describes that assignment through a geometric procedure: up from
a point on the x-axis to a point on the curve over to a point on the y-axis.
That way, a point on the domain goes in and a point on the codomain comes
out. The curve is not the function: the assignment it illustrates this way is the
function.
11.2.2
Tables and arrow graphs
When the sets involved are small, there is another way to illustrate a function.
Let A = {a, b, c, d, e}. We can deï¬ne a function f âˆ¶A â†’A using a table of values
as follows.
A
A
a
b
b
b
c
d
d
c
e

11.2 Visualizing Functions
203
Figure 11.3 An arrow graph.
a
b
c
d
e
a
b
c
d
e
This time the domain appears in the ï¬rst column, the codomain appears in the
second, and the ordered pairs of the relation are rows in the table. We can see
Domain(f ) = {a, b, c, d}, Codomain(f ) = A, Range (f ) = {b, c, d}. The function
is injective, but it is not surjective.
We can make this table even more visual by using arrows to indicate the
assignments. This is shown in Figure 11.3.
Two arrows cannot begin at the same element of the domain because of
the vertical line test. However, two arrows can point to the same value of the
codomain, but that means the function is not injective. In keeping with our
notation, we wrote f âˆ¶A â†’A even though f (e) is not deï¬ned. In addition, the
function is not surjective.
11.2.3
Generic functions
The ï¬nal way to visualize functions is through a generic picture as in Figure 11.4.
To draw f âˆ¶A â†’B, we draw A as a circle, and B as a separate circle. The function
connects points in A with points in B, and we indicate this using an arrow or
several arrows if that serves our purpose.
If we want, we can indicate the actual domain of f (x) as a enclosed section
of the circle denoting A. The same goes for the range of f (x). This picture is
very generic. It works for all sorts of functions between any sorts of sets. It is
very imprecise and does not capture any of the actual details of the function, as
f : A â†’ B
A
Domain( f )
B
Range( f )
Figure 11.4 A generic function.

204
11 Functions
in our other illustrations. In many cases, that actually helps us understand the
general properties of functions.
11.3
Composition
11.3.1
Deï¬nitions and basic results
Deï¬nition 11.3.1.
Let f âˆ¶A â†’B and g âˆ¶B â†’C be two functions. The com-
posite of these two functions is a function
g âˆ˜f âˆ¶A â†’C
(11.9)
deï¬ned by
(g âˆ˜f )(x) = g(f (x)).
(11.10)
Notice the notation. The left-hand side of the notation (g âˆ˜f )(x) collects the
compound function name together in one unit using parenthesis. The normal
notation for a function named h is to write h(x) to mean h applied to the variable
x. The variable always gets its own parenthesis as part of the function nota-
tion. Thus, (g âˆ˜f )(x) means â€œthe function (g âˆ˜f ) applied to the variable x.â€ The
right-hand side starts with a function g; the next parenthesis tells us what it is
applied to: f (x). As usual, f (x) means the value of the function f at the vari-
able x. So algebraically, this deï¬nition is easy to apply. But when translated to
English, it is a bit strange. The function (g âˆ˜f )(x) means â€œapply f to x ï¬rst and
then apply g to the result.â€ So (g âˆ˜f )(x) means f ï¬rst; g second. Nice algebra
is more important than the English; so the notation holds on to this reverse
meaning.
Theorem 11.3.2.
Let f âˆ¶A â†’B, g âˆ¶B â†’C, and h âˆ¶C â†’D be functions.
Then
h âˆ˜(g âˆ˜f ) = (h âˆ˜g) âˆ˜f ;
(11.11)
(h âˆ˜(g âˆ˜f ))(x) = ((h âˆ˜g) âˆ˜f )(x)).
Either way of writing this is ï¬ne; the ï¬rst makes the point easier to see; the
second makes the proof easier to start.
Proof. Consider the right- and left-hand sides.
(h âˆ˜(g âˆ˜f ))(x) = h((g âˆ˜f )(x)) = h(g(f (x))).
(11.12)
((h âˆ˜g) âˆ˜f )(x)) = (h âˆ˜g)(f (x)) = h(g(f (x))).
â—½

11.3 Composition
205
Now the composition of functions is associative, but it is not commutative.
For one thing, if f âˆ¶A â†’B and g âˆ¶B â†’C involve three diï¬€erent sets, f âˆ˜g
makes no sense. (Remember that g comes ï¬rst and thus ends up in the wrong
set for f to act on.) But even in the best possible case where f âˆ¶A â†’A and
g âˆ¶A â†’A, only carefully selected functions commute with each other.
Theorem 11.3.3.
Let f âˆ¶A â†’B and g âˆ¶B â†’A be functions.
1. If f (x) and g(x) are injective, then (g âˆ˜f )(x) is injective.
2. If f (x) and g(x) are surjective, then (g âˆ˜f )(x) is surjective.
3. If f (x) and g(x) are bijective, then (g âˆ˜f )(x) is bijective.
Proof. We will prove each part in turn.
Part 1. We ï¬rst claim that if f (x) and g(x) are injective, then (g âˆ˜f )(x) is
injective.
Proof of claim. Assume that f (x) and g(x) are injective. Then f (a1) = f (a2)
implies a1 = a2. And g(b1) = g(b2) implies b1 = b2.
Comment: What are we proving now? (g âˆ˜f )(x) is injective. That is, if (g âˆ˜f )(a1) =
(g âˆ˜f )(a2), then a1 = a2.
Assume (g âˆ˜f )(a1) = (g âˆ˜f )(a2). Then g(f (a1)) = g(f (a2)). So f (a1) = f (a2) and
in turn a1 = a2.
â—¾
Part 2. We now claim that if f (x) and g(x) are surjective, then (g âˆ˜f )(x) is
surjective.
Proof of claim. Assume that f (x) and g(x) are surjective. Then âˆ€b âˆˆB, âˆƒa âˆˆA
s.t. f (a) = b. And âˆ€c âˆˆC, âˆƒb âˆˆB s.t. g(b) = c.
Comment: What are we proving now? g âˆ˜f âˆ¶A â†’C is surjective. That is, if c âˆˆC,
then there exists a âˆˆA such that (g âˆ˜f )(a) = c.
Assume c âˆˆC. We know that âˆƒb âˆˆB s.t. g(b) = c. Now that we have b âˆˆB,
we know that âˆƒa âˆˆA s.t. f (a) = b. Consider a âˆˆA. Then
(g âˆ˜f )(a) = g(f (a)) = g(b) = c.
(11.13)
â—¾
Part 3. Finally, we claim that if f (x) and g(x) are bijective, then (g âˆ˜f )(x) is
bijective.

206
11 Functions
Proof of claim. Comment: What are we proving now that we know the ï¬rst two
parts are true? If f (x) and g(x) are bijective, then Domain(g âˆ˜f ) = A.
Assume that f (x) and g(x) are bijective. Then both are injective, so the compo-
sition is injective. Both are surjective, so the composition is surjective. In addi-
tion, Domain(f ) = A and Domain(g) = B. Let a âˆˆA. Then a âˆˆDomain(f ) = A.
So âˆƒb âˆˆB s.t. f (a) = b. But b âˆˆB =Domain(g); so âˆƒc âˆˆC s.t. g(b) = c. Then
(g âˆ˜f )(a) = g(f (a)) = g(b) = c.
(11.14)
So a âˆˆDomain (g âˆ˜f ).
â—¾
â—½
11.4
Inverses
Deï¬nition 11.4.1.
Let A be any set. The identity function on A is iA âˆ¶A â†’A
given by iA(x) = x for all x âˆˆA.
Each set has its own identity function; so there is a good reason to include a
subscript when we write it. Nevertheless, many people consider laziness a good
reason not to when there is little chance for confusion.
Theorem 11.4.2.
Let A and B be sets, and iA âˆ¶A â†’A and iB âˆ¶B â†’B be the
identities, then:
1. iA is bijective.
2. If f âˆ¶A â†’B is a function, then (f âˆ˜iA)(x) = f (x).
3. If f âˆ¶A â†’B is a function, then (iB âˆ˜f )(x) = f (x).
There is not much to prove here, but we will prove 1 anyway.
Proof. To prove that iA âˆ¶A â†’A is bijective, we must prove that it is injective,
surjective, and that Domain(iA) = A.
To see that iA is injective, assume iA(a1) = iA(a2). Then a1 = iA(a1) = iA(a2) =
a2, so iA is injective.
Now we claim that ia is surjective. Assume a âˆˆA. Then iA(a) = a; so âˆƒx âˆˆA
s.t. iA(x) = a. So Range(iA) = A; that is, iA is surjective.
Finally, we claim that A =Domain(iA). Clearly, Domain(iA) âŠ†A. We must
show that A âŠ†Domain(iA). Assume a âˆˆA. Then iA(a) = a. So a âˆˆDomain(iA).
Thus, A âŠ†Domain(iA); so A = Domain(iA).
â—½
The only point of value here is that we need to remember that the deï¬nition
of bijective has three parts.

11.4 Inverses
207
Deï¬nition 11.4.3.
Let f âˆ¶A â†’B and g âˆ¶B â†’A be functions. We say that g
is an inverse of the function f when
(g âˆ˜f )(x) = iA(x)
(11.15)
and (f âˆ˜g)(x) = iB(x).
In this case, we write g(x) = f âˆ’1(x).
Before we set this notation, we should have proved that an inverse function,
if it exists, is unique. We have already seen that uniqueness of inverses follows
from associativity. However, recalling that proof does point out that, without
commutativity, it is critical that an inverse works on both sides of the function.
Theorem 11.4.4.
Inverse functions are unique.
Proof. Let f âˆ¶A â†’B; g1 âˆ¶B â†’A; and g2 âˆ¶B â†’A be functions. Assume g1(x)
and g2(x) be inverses of f (x). Consider g1 âˆ˜f âˆ˜g2.
(g1 âˆ˜f âˆ˜g2)(x) = ((g1 âˆ˜f ) âˆ˜g2)(x) = (iA âˆ˜g2)(x) = g2(x).
(11.16)
(g1 âˆ˜f âˆ˜g2)(x) = (g1 âˆ˜(f âˆ˜g2))(x) = (g1 âˆ˜iB)(x) = g1(x).
â—½
There is a consequence of this uniqueness that is worth remembering. While
this might not be completely oï¬ƒcial mathematics terminology, we give it a
name to help us remember it.
Theorem 11.4.5
(The Shoes and Socks Theorem). Let f âˆ¶A â†’B, and g âˆ¶
B â†’C be functions. Assume that f (x) and g(x) are bijections. Then
(g âˆ˜f )âˆ’1 = f âˆ’1 âˆ˜gâˆ’1.
(11.17)
Proof. Assume a âˆˆA. Then
(f âˆ’1 âˆ˜gâˆ’1) âˆ˜(g âˆ˜f ) = f âˆ’1 âˆ˜(gâˆ’1 âˆ˜g) âˆ˜f
(11.18)
= f âˆ’1 âˆ˜iB âˆ˜f
= f âˆ’1 âˆ˜f
= iA.
In addition,
(g âˆ˜f ) âˆ˜(f âˆ’1 âˆ˜gâˆ’1) = f âˆ˜(g âˆ˜gâˆ’1) âˆ˜f âˆ’1
(11.19)
= f âˆ˜iA âˆ˜f âˆ’1
= f âˆ˜f âˆ’1
= iB.

208
11 Functions
Since f âˆ’1 âˆ˜gâˆ’1 acts as the inverse of (g âˆ˜f ) on both sides, and inverses are
unique, (g âˆ˜f )âˆ’1 = f âˆ’1 âˆ˜gâˆ’1.
â—½
All of the careful abstraction, weird deï¬nitions, and precise notation in this
chapter have been leading up to the next famous theorem and its proof. It might
not have been precisely true had we not been so careful.
Theorem 11.4.6.
If f âˆ¶A â†’B is a function, then f (x) has an inverse function
if and only if f (x) is bijective.
Proof. Assume that f âˆ¶A â†’B is a function. This is a biconditional statement,
so we have two statements to prove.
1. If f (x) has an inverse function, then f (x) is bijective.
2. If f (x) is bijective, then f (x) has an inverse function.
We will take each in turn.
Part 1. We claim that if f (x) has an inverse function, then f (x) is bijective.
Proof of claim. Assume that f (x) has an inverse function. Call it f âˆ’1(x). Then
(f âˆ’1 âˆ˜f )(x) = iA(x)
(11.20)
and (f âˆ˜f âˆ’1)(x) = iB(x).
Comment: What are we proving now? 1. Domain(f ) = A; 2. f (x) is injective; and
3. f (x) is surjective.
Step 1. We claim that Domain(f ) = A; that is, given a âˆˆA, we must show that
f (a) is deï¬ned and an element of B.
Assume a âˆˆA. We have iA(a) = a. So
a = iA(a)
(11.21)
= (f âˆ’1 âˆ˜f )(a)
= f âˆ’1(f (a)).
This means that f (a) must be deï¬ned and be an element of B since otherwise
f âˆ’1(f (a)) would not make sense and be equal to a. Thus, a âˆˆDomain(f ). So
we have ï¬nished step 1.
Step 2. We claim that f (x) is injective; that is, if f (a1) = f (a2), then a1 = a2.
Assume f (a1) = f (a2). Now a1, a2 âˆˆA (because we assumed that f (a1) and
f (a2) made sense). Applying f âˆ’1(x) to both sides, we get
f âˆ’1(f (a1)) = f âˆ’1(f (a2)).
So (f âˆ’1 âˆ˜f )(a1) = (f âˆ’1 âˆ˜f )(a2). So iA(a1) = iA(a2), and therefore, a1 = a2.
So if f (a1) = f (a2), then a1 = a2. This ï¬nishes step 2.

11.4 Inverses
209
Step 3. We now claim that f (x) is surjective; that is, if b âˆˆB, then âˆƒa âˆˆA s.t.
f (a) = b.
Assume b âˆˆB. Then iB(b) = b. So
b = iB(b)
(11.22)
= (f âˆ˜f âˆ’1)(b)
= f (f âˆ’1(b)).
Since f âˆ’1(b) âˆˆA, we have ï¬nished step 3.
These three steps complete Part 1.
â—¾
Part 2. We claim that if f (x) is bijective, then f (x) has an inverse.
Proof of claim. Comment: We will almost never bring a function back to its
deï¬nition as an ordered pair to complete a proof, but this is one time where this
helps.
Assume f âˆ¶A â†’B is a function where Domain(f ) = A. Then we have a pair
(f , B) where f âŠ†A Ã— B . And we can say that âˆ€a âˆˆA, âˆƒb âˆˆB s.t. f (a) = b.
Writing this as ordered pairs in the relation, we get
(1) âˆ€a âˆˆA, âˆƒb âˆˆB s.t. (a, b) âˆˆf .
In addition, we have â€œthe vertical line testâ€ requirement:
(2) if (a, b1) âˆˆf and (a, b2) âˆˆf , then b1 = b2.
Next we assume that f (x) is injective. Then f (a1) = f (a2) implies a1 = a2. Let
b = f (a1) = f (a2). Writing this as ordered pairs in the relation, we get
(3) If (a1, b) âˆˆf and (a2, b) âˆˆf , then a1 = a2.
Finally, assume that f (x) is surjective. Then âˆ€b âˆˆB, âˆƒa âˆˆA s.t. f (a) = b.
Writing this as ordered pairs in the relation, we get
(4) âˆ€b âˆˆB, âˆƒa âˆˆA s.t. (a, b) âˆˆf .
Now deï¬ne a function as the pair (g, A) where
g = {(b, a) âˆˆB Ã— A âˆ£(a, b) âˆˆf }.
(11.23)
Thus, g âŠ†B Ã— A.
We must now show (1) that g is actually a function (i.e., g satisï¬es the â€œvertical
line testâ€) and (2) that g is the inverse of f .
We ï¬rst prove that g is a function. Assume that g(b) = a1 and g(b) = a2. That
is, (b, a1) âˆˆg and (b, a2) âˆˆg. By deï¬nition of g, it follows that (a1, b) âˆˆf and
(a1, b) âˆˆf . That is, f (a1) = b and f (a2) = b. But because f is injective, we have

210
11 Functions
property (3). Thus, a1 = a2. Thus, the relation g satisï¬es the â€œvertical line test.â€
So g âˆ¶B â†’A is a function.
Now we prove that g is the inverse of f . First note that by property (4),
Domain(g) = B.
So (b, a) âˆˆg if and only if (a, b) âˆˆf . So in normal notation, we have g(b) = a
if and only if f (a) = b. Thus,
(g âˆ˜f )(x) = iA(x)
(11.24)
and (f âˆ˜g)(x) = iB(x).
So g(x) is an inverse function of f (x).
â—¾
We have now proved both directions of our biconditional statement, so the
proof is complete.
â—½
11.5
Problems
11.1
Explain why the following common errors committed by beginners can
be explained by noting that functions do not always commute under
composition.
(a) (a + b)2 = a2 + b2.
(b)
1
x+4 = 1
x + 1
4.
(c)
âˆš
x2 + y2 = x + y.
(d) 32+x = 9 + 3x.
(e) Sin(2x) = 2Sin(x).
11.2
Let A = {a, b, c, d, e}.
Deï¬ne a function f âˆ¶A â†’A and a function g âˆ¶A â†’A using the table
of values shown as follows.
x
f(x)
g(x)
a
b
b
b
b
c
c
d
d
d
c
e
e
e
a
(a) Is either f (x) or g(x) injective?
(b) Is either f (x) or g(x) surjective?

11.5 Problems
211
(c) Find a table for (f âˆ˜g)(x).
(d) Find a table for (f âˆ˜f )(x).
11.3
Consider the functions f âˆ¶â„â†’â„given by f (x) = xâˆ’1, and g âˆ¶
â„âˆ–{0} â†’â„âˆ–{0} given by g(x) = xâˆ’1.
(a) Prove f (x) is injective.
(b) Prove g(x) is injective.
(c) Prove f (x) is not surjective.
(d) Prove g(x) is surjective.
(e) Carefully evaluate the two functions (f âˆ˜f )(x) and (g âˆ˜g)(x). Be
completely precise about these two results.
11.4
Deï¬ne f âˆ¶â„â†’â„by f (x) = 2xâˆ’1
x+1 .
(a) Prove that f (x) is injective.
(b) Prove that f (x) is not surjective.
(c) Use the formula f1(x) = 2xâˆ’1
x+1 to deï¬ne a bijective function and ï¬nd
its inverse.
11.5
Deï¬ne f âˆ¶â„â†’â„by f (x) = x2âˆ’4
xâˆ’2 .
(a) Is f (x) injective?
(b) Is f (x) surjective?
(c) Is f (x) bijective?
(d) Is this the same as the function f âˆ¶â„â†’â„given by f (x) = x + 2?
11.6
Explain your answers to the following questions.
(a) Can a function f âˆ¶â„â†’â„be deï¬ned by f (x) =
âŽ§
âŽª
âŽ¨
âŽªâŽ©
x
if x > 0
0
if x = 0
âˆ’x
if x < 0
?
(b) Can a function g âˆ¶â„â†’â„be deï¬ned by f (x) = Â±x?
(c) Is it true or false that |x| = Â±x?
(d) Can |x| = Â±x be used as a deï¬nition of the absolute value?
(e) Is it true or false that
âˆš
x2 = Â±x?
(f) Is it true or false that
âˆš
x2 = |x|?
(g) Can |x| =
âˆš
x2 be used as a deï¬nition of the absolute value?
11.7
Deï¬ne f âˆ¶[3, âˆž) â†’[âˆ’6, âˆž) by f (x) = x2 âˆ’6x + 3.
(a) Find a function g âˆ¶[âˆ’6, âˆž) â†’[3, âˆž) so that (g âˆ˜f )(x) = x and
(f âˆ˜g)(x) = x.
(b) Prove that f (x) is bijective.

212
11 Functions
11.8
Let f âˆ¶â„â†’â„be given by f (x) = x3 + 5x âˆ’8. Prove that f (x) is injective.
(Since you cannot use calculus, prove that f (a) âˆ’f (b) = (a âˆ’b) â‹…g(a, b)
and that g(a, b) cannot be zero.)
11.9
Deï¬ne f âˆ¶â„â†’â„by
f (x) =
âŽ§
âŽª
âŽ¨
âŽªâŽ©
x2
if x > 0
0
if x = 0
âˆ’x2
if x < 0
.
(11.25)
(a) Prove that f (x) is bijective.
(b) Find f âˆ’1(x).
(c) Consider g âˆ¶â„â†’â„given by g(x) = x |x|. Compare this to f (x).
11.10
We will not prove it in this course, but ðœ‹is not a rational number. Use
this to prove that f âˆ¶â„šâ†’â„given by f (x) = Sin(x) is injective.
(Yes, because of the â„š, it really is! Hint: use the graph you learned in
trigonometry to ï¬nd all solutions x to Sin(x) = Sin(b), where b is a con-
stant.)
11.11
Let A = {1, 2}. Let Map(A) = {f âˆ¶A â†’A âˆ£Domain(f ) = A}. Deï¬ne a
relation on Map(A) by
f âˆ¼g
if and only if
âˆƒb âˆˆMap(A) s.t. b is a bijection and g = bâˆ’1 âˆ˜f âˆ˜b.
(a) List all the elements of Map(A) by drawing them as arrow diagrams.
(b) Prove that the relation âˆ¼deï¬ned earlier is an equivalence relation.
(c) Find Map(A)âˆ•âˆ¼.
11.12
Let A = {1, 2, 3}. Let Bij(A) = {f âˆ¶A â†’A âˆ£f (x) is a bijection}. Deï¬ne
a relation on Bij(A) by
f âˆ¼g
if and only if
âˆƒb âˆˆBij(A) s.t. g = bâˆ’1 âˆ˜f âˆ˜b.
(a) List all the elements of Bij(A) by drawing them as arrow diagrams.
(b) Prove that the relation âˆ¼deï¬ned earlier is an equivalence relation.
(c) Find Bij(A)âˆ•âˆ¼.

11.5 Problems
213
11.13
Let A = {1, 2, 3}. Let Map(A) = {f âˆ¶A â†’A âˆ£Domain(f ) = A}. Deï¬ne
a relation on Map(A) by
f âˆ¼g
if and only if
âˆƒb âˆˆMap(A) s.t. b is a bijection and g = bâˆ’1 âˆ˜f âˆ˜b.
(a) List all the elements of Map(A). (OK, there are a lot of them.)
(b) Prove that the relation âˆ¼deï¬ned earlier is an equivalence relation.
(c) Find Map(A)âˆ•âˆ¼.

215
12
Images and preimages
12.1
Functions acting on sets
12.1.1
Deï¬nition of image
Let f âˆ¶A â†’B be a function. We say that the function f â€œacts on elements of Aâ€
because we can view the equation f (a) = b as though the function transforms
the a âˆˆA into a b âˆˆB. We say this because f (x) is well deï¬ned and can only
mean one thing. We cannot say that f acts on the elements of B because it is not
clear what a general function f âˆ¶A â†’B would do to b âˆˆB that would produce
a well-deï¬ned result since f (x) may not be injective. We can, however, describe
the ways f âˆ¶A â†’B can act on sets in a well-deï¬ned manner. (Remember that
â€œwell deï¬nedâ€ means â€œgive a unique and unambiguous result.â€) We can get f to
act on subsets of A. In addition, even though f cannot act on elements of B, it
can be made to act on subsets of B.
If S âŠ†A, then f âˆ¶A â†’B acts on S to create an image of S under f (x). To get
an idea on how a function f âˆ¶A â†’B can act on S âŠ†A as this, draw a generic
picture of such a function (Figure 12.1).
As the picture seems to show, the image of a set is the set obtained by
applying f (x) to all the points s âˆˆS. We could choose to write this image as
{f (x) âˆ£x âˆˆS}. That describes rather clearly what the image of S under f (x)
should be. The problem is that it is not in the standard set notation form, and
it could be diï¬ƒcult to use in a proof. It is a great way to give an example, but
a bad way to use the image in a proof. Mathematical deï¬nitions are all about
preparing for proofs; so we have
Deï¬nition 12.1.1.
Let f âˆ¶A â†’B and S âŠ†A. The image of S under f (x) is
f (S) = {y âˆˆB âˆ£âˆƒx âˆˆS s.t. f (x) = y}.
(12.1)
We have now used one notation for two similar things; but â€œsimilarâ€ is not
exactly the same. Thus, if f âˆ¶A â†’B and s âˆˆA, then f (s) is the function applied
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

216
12 Images and Preimages
f : A â†’ B
A
Domain( f )
B
Range( f )
S
f (S)
Figure 12.1 The image of S is f(S).
to s. We have been calling this â€œf of sâ€ for a long time. But now we have a new
notion that we may not have even seen before. If S âŠ†A, then f (S) is the image
of S under f (x). We can read f (S) as either â€œf of Sâ€ or â€œf applied to S.â€ However,
if any confusion arises â€“ as in a proof â€“ over the notation f (S), we should realize
that one way to get out of that confusion is to read f (S) correctly as â€œthe image
of the set S under f (x).â€
The other thing to notice about this deï¬nition is our choice of names for the
variables. The names of the variables have no impact on the meaning of the
deï¬nition. We have 26 small letters and 26 capitals and a slew of Greek letters
to choose from.
There are some conventions that are not so strictly followed but are common
enough that they quickly start to seem standard. We typically use lowercase
letters for elements and uppercase letters for sets, but if a set S has a maximum
and a minimum, it is very tempting to call them M and m. This notation is
so descriptive that it might be worth breaking our habit of saving M for a set.
Another general practice you might begin to pick up: the beginning letters of
the alphabet are often used to denote the ï¬xed elements of a set, as a set of real
numbers. Letters in the middle of the alphabet are often chosen to represent
natural numbers and integers. Letters at the end of the alphabet are chosen
for variables that are actually expected to vary during the discussion. When it
comes to functions, this last convention picks up an extra bit of connotation
left over from our introduction to functions in basic algebra where we write
y = f (x). Thus, x is generally a domain variable that goes into a function, and
y is generally a codomain variable that comes out of a function. In time you
might notice that s and t are also normally domain and codomain pairs. Less
common, but often enough, u and ð‘£get paired like this.
Notice how this convention inï¬‚uenced our choice of variable names in the
deï¬nition of the image. The image of a set S under a function f âˆ¶A â†’B is going
to be a set in the codomain. When we deï¬ne f (S), we choose a variable name
for its members that is a â€œcodomainâ€ variable. We choose y. The set deï¬nition

12.1 Functions Acting on Sets
217
begins â€œthe set of all yâ€¦â€. When we get to the condition for membership in
the set, we need a name for a variable in A; we choose a â€œdomainâ€ variable, x.
Logically, we could have picked these names in the opposite order, but strate-
gically, this would have only set up a great opportunity for confusion.
12.1.2
Examples
We will start with a function with only a few elements in the domain and range.
Example 12.1.2.
Let A = {1, 3, 4, 6, 7} and B = {2, 3, 4, 5, 6, 7}. Let f âˆ¶A â†’B
be given by the following table.
x
f (x)
1
4
3
6
4
4
6
7
7
Then
For S1 = {1, 3, 4}, f (S1) = {4, 6}.
(12.2)
For S2 = {1, 3, 6, 7}, f (S2) = {4, 6, 7}.
(12.3)
We must say that f (6) is not deï¬ned. Still f ({6}) is deï¬ned.
For S3 = {6}, f (S3) = âˆ….
For S4 = âˆ…, f (S4) = âˆ….
For S5 = {1, 3, 4, 6, 7}, f (S5) = {4, 6, 7}.
Notice a few things; the image of a subset of A is always deï¬ned. This is true
whether A is the prospective domain or the actual domain. Thus, even though
f (6) is not deï¬ned, f ({6}) is deï¬ned. This is one of those situations where
reading f (6) as â€œf of 6â€ and reading f ({6}) as â€œthe image of the set {6} under
f (x)â€ pays oï¬€. In addition, the empty set is just like any other set, and we follow
the deï¬nition slavishly.
f ({6}) = {y âˆˆB | âˆƒx âˆˆS s.t. f (x) = 6} = âˆ…;
(12.4)
f (âˆ…) = {y âˆˆB | âˆƒx âˆˆâˆ…s.t. f (x) = y} = âˆ….
Example 12.1.3.
Let f âˆ¶A â†’B be given by f (x) = x2.
It is a good idea to keep a graph of this function in mind as we go through
these examples (Figure 12.2).

218
12 Images and Preimages
âˆ’4
âˆ’2
2
4
10
20
x
y
Figure 12.2 f(x) = x2.
For S1 = {1, 2, 3}, f (S1) = {1, 4, 9}.
(12.5)
For S2 = { âˆ’2, âˆ’1, 0, 1, 2, 3}, f (S2) = {0, 1, 4, 9}.
For S3 = [2, 5), f (S3) = [4, 25).
For S4 = [âˆ’3, âˆ’1), f (S4) = (1, 9].
For S5 = (âˆ’3, 2), f (S5) = [0, 9).
For S6 = (âˆ’âˆž, 4], f (S6) = [0, âˆž).
For S7 = âˆ…, f (S7) = âˆ….
For S8 = â„, f (S8) = [0, âˆž).
We ï¬nish with two last observations; we write these as theorems, but do not
bother to prove them.
Theorem 12.1.4.
Let f âˆ¶A â†’B be a function. Then f (A) = Range( f ).
Theorem 12.1.5.
For any function f âˆ¶A â†’B be a function, f (âˆ…) = âˆ….
12.1.3
Deï¬nition of preimage
Let f âˆ¶A â†’B be a function. We have seen why the function f â€œacts on elements
of Aâ€ and how it can â€œact on a subset of A.â€ We can also get it to â€œact on a subset
of B,â€ but when it does, it will be in reverse (Figure 12.3).
The preimage of a set T âŠ†B under a function f âˆ¶A â†’B is the set of elements
of A that the function takes to elements of T. We are again going to use notation
that is very similar to notation we have used before. The trouble is that this time
the underlying ideas are still similar, but the technicalities are quite diï¬€erent.
We will denote the preimage of T âŠ†B under the function f âˆ¶A â†’B as f âˆ’1(T).

12.1 Functions Acting on Sets
219
T
f âˆ’1(T)
f : A â†’ B
A
B
Domain( f )
Range( f )
Figure 12.3 f âˆ’1(T) is the preimage of T.
Be careful, this is the function f (x) acting on the set T âŠ†B. It is not the inverse
function f âˆ’1(x) acting on anything mainly because there is no reason to believe
the function f âˆ’1(x) exists.
Now the preimage f âˆ’1(T) of any subset T âŠ†B and any function f âˆ¶A â†’B will
always be well deï¬ned. The function need not be bijective; so its inverse need
not exist. Nonetheless, f âˆ’1(T) is deï¬ned. It will be hard to learn not to read
f âˆ’1(T) as â€œf -inverse of T,â€ but doing so is inviting mistakes. The correct way to
read f âˆ’1(T) is as â€œthe preimage of T under f (x).â€
Reviewing our terminology, if f âˆ¶A â†’B and s âˆˆA, then f (s) is the function
applied to s. We read f (s) as â€œf of s.â€ If S âŠ†A, then f (S) is the image of S under
f (x). This is always well deï¬ned, and we can read f (S) as either â€œf of Sâ€ or as â€œf
applied to S,â€ as long as we remember that it is properly read as â€œthe image of
the set S under f (x).â€
If f (x) is bijective, then it has an inverse and if t âˆˆB, then f âˆ’1(t) is the inverse
function applied to t. But only when we are sure an inverse exists can we read
f âˆ’1(t) as â€œf -inverse of t.â€ Whenever we use the notation f âˆ’1(t) for t an element,
we must ask ourselves if we know that f (x) is bijective. However, the preimage
f âˆ’1(T) of a set T âŠ†B will always be deï¬ned for any function f âˆ¶A â†’B. The
function need not be bijective, so its inverse need not exist. Nonetheless, f âˆ’1(T)
is deï¬ned. It is good practice not to read f âˆ’1(T) as â€œf -inverse of Tâ€ but only as
â€œthe preimage of T under f (x).â€
Now we are ready to write down an oï¬ƒcial deï¬nition. Since the preimage of a
set should be a set in the domain, this will be reï¬‚ected in our choice of variable
names.
Deï¬nition 12.1.6.
Let f âˆ¶A â†’B. Let T âŠ†B. The preimage of T under f (x) is
f âˆ’1(T) = {x âˆˆA âˆ£f (x) âˆˆT}.
Finally we have a simple deï¬nition that actually describes the set being
deï¬ned.

220
12 Images and Preimages
12.1.4
Examples
We will use the same two functions we used as examples of images.
Example 12.1.7.
Let A = {1, 3, 4, 6, 7} and B = {2, 3, 4, 5, 6, 7}. Let f âˆ¶A â†’B
be given by the following table.
x
f (x)
1
4
3
6
4
4
6
7
7
This function is not bijective; so f âˆ’1 can only mean â€œpreimage.â€ Now
For T1 = {4, 6}, f âˆ’1(T1) = {1, 3, 4}.
(12.6)
For T2 = {7}, f âˆ’1(T2) = {7}.
(12.7)
We still must say that f âˆ’1(7) is not deï¬ned.
For T3 = {4}, f âˆ’1(S1) = {1, 4}.
For T4 = {2, 3, 5}, f âˆ’1(T4) = âˆ….
For T5 = âˆ…, f âˆ’1(T5) = âˆ….
For T6 = B, f âˆ’1(T6) = {1, 3, 4, 7}.
Notice a few things; the preimage of a subset of B is always deï¬ned. Thus even
though f âˆ’1({7}) is deï¬ned and only contains one element, the inverse of f (x)
does not exist. Thus f âˆ’1(7) is not deï¬ned. This is one of those situations where
reading f âˆ’1(7) as â€œf -inverse of 7â€ and reading f âˆ’1({7}) as â€œthe preimage of the
set {7} under f â€ pays oï¬€. Again the empty set is just like any other set; we follow
the deï¬nition slavishly.
f âˆ’1({2}) = {x âˆˆA âˆ£f (x) = 2} = âˆ…;
(12.8)
f âˆ’1(âˆ…) = {x âˆˆA âˆ£f (x) âˆˆâˆ…} = âˆ….
There are x âˆˆA such that f (x) is not deï¬ned, but that does not make f (x) âˆˆâˆ…,
because the empty set is empty.
Example 12.1.8.
Let f âˆ¶A â†’B be given by f (x) = x2.
Again, it is a good idea to keep an graph of this function in mind as we go
through these examples.

12.1 Functions Acting on Sets
221
âˆ’4
âˆ’2
2
4
10
20
x
y
Figure 12.4 f(x) = x2.
Also, remember the sets going into the preimage are in the range, and so
belong on the y-axis, and the preimages that they produce are in the domain,
and so belong on the x-axis (Figure 12.4).
For T1 = {1, 4, 9}, f âˆ’1(T1) = { Â± 1, Â±2, Â±3}.
(12.9)
For T2 = { âˆ’2, âˆ’1}, f âˆ’1(T2) = âˆ….
For T3 = [0, 25), f âˆ’1(T3) = (âˆ’5, 5).
For T4 = (âˆ’3, 16], f âˆ’1(S4) = [âˆ’4, 4].
For T5 = [4, 9), f âˆ’1(T5) = (âˆ’3, âˆ’2] âˆª[2, 3).
For T6 = (âˆ’âˆž, 4], f âˆ’1(T6) = [âˆ’2, 2].
For T7 = âˆ…, f âˆ’1(T7) = âˆ….
For T8 = â„, f âˆ’1(R8) = â„.
The thing to notice in this example is that a perfectly nice function can also
cause havoc on the form of an interval in reverse. But perhaps even more impor-
tant, it takes a lot of practice to ï¬nd preimages under even the most familiar
of functions without drawing a graph and tracing the set T on the y-axis back
onto the curve, and the pushing it down onto the x-axis to set what you get.
We ï¬nish with three last observations; we write them as theorems, but do not
bother to prove them.
Theorem 12.1.9.
Let f âˆ¶A â†’B be a function. Then f âˆ’1(B) = Domain( f ).
Theorem 12.1.10.
Let f âˆ¶A â†’B be a function and T âŠ†B, then f âˆ’1(T) âŠ†
Domain( f ).
Theorem 12.1.11.
For any function f âˆ¶A â†’B, f âˆ’1(âˆ…) = âˆ….

222
12 Images and Preimages
12.2
Theorems about images and preimages
12.2.1
Basics
The truth about images, preimages, and their notations is that the resulting
algebra involving them is not as reliable as it should be. Many algebraic results
that should be true are not unless extra conditions are placed on either the
function or the sets involved. It is almost impossible to keep track of all these
conditions, so a good practice is to actually reprove (at least in scratch work)
any result we ï¬nd that we need within a longer proof.
Our ï¬rst theorem is less a theorem than a warning.
Theorem 12.2.1.
Let f âˆ¶A â†’B be a function. Let S âŠ†A and T âŠ†B.
1. If s âˆˆDomain( f ) and s âˆˆS, then f (s) âˆˆf (S).
2. s âˆˆf âˆ’1(T) if and only if f (s) âˆˆT.
3. The converse of statement 1 is not true. If f (s) âˆˆf (S), we cannot say that s âˆˆS.
4. If t âˆˆT, we cannot say that f âˆ’1(t) âˆˆf âˆ’1(T).
Proof. Statements 1 and 2 are simply restatements of the deï¬nitions of f (S) and
f âˆ’1(T). We will prove them anyway.
Part 1. We claim that if s âˆˆDomain( f ) and s âˆˆS, then f (s) âˆˆf (S).
Proof of claim. Assume s âˆˆDomain(f ) and s âˆˆS. Now s âˆˆDomain(f ) so
we know that f (s) exists. Since s âˆˆS, f (s) âˆˆ{y âˆˆB âˆ£âˆƒx âˆˆS s.t. f (x) = y} =
f (S).
â—¾
Part 2. We claim that s âˆˆf âˆ’1(T) if and only if f (s) âˆˆT.
Proof of claim. (â‡’) Assume s âˆˆf âˆ’1(T). Since f âˆ’1(T) âŠ†Domain( f ), we have
implicitly assumed that s âˆˆDomain( f ). Thus, f (s) exists and f (s) âˆˆ{x âˆˆA âˆ£
f (x) âˆˆT}. So f (s) âˆˆf (T).
(â‡) Assume f (s) âˆˆT. Since we have assumed something about f (s), it must
exist. Since f (s) âˆˆT, s âˆˆ{x âˆˆA âˆ£f (x) âˆˆT} = f âˆ’1(T).
â—¾
Part 3. The converse of statement 1 is not true. If f (s) âˆˆf (S), we cannot say that
s âˆˆS.
This is true because f (x) might not be injective. Suppose that f (a1) = f (a2)
with a1 â‰ a2. Then f (a2) âˆˆf ({a1}), but a2 âˆ‰{a1}.
Part 4. If t âˆˆT, we cannot say that f âˆ’1(t) âˆˆf âˆ’1(T).
This is true because we cannot even write f âˆ’1(t) unless f (x) is known to be
bijective.
â—½

12.2 Theorems about Images and Preimages
223
Remember the example in the proof of statement 3. The following table will
help:
x
f (x)
a1
b
a2
b
âˆ—
âˆ—
âˆ—
âˆ—
â‹®
â‹®
Proof technique. In real analysis, before we can apply f âˆ¶â„â†’â„to a âˆˆâ„, we
must establish that a âˆˆDomain(f ) and thus be sure that f (a) exists. However, if
S âŠ†â„, then f (S) will always be deï¬ned; and if T âŠ†â„, then f âˆ’1(T) is also always
deï¬ned.
There is one way to remember what is true and what is not true about images
and preimages applied to both sides of a statement. If it looks like we are
applying the function to both sides, then the result is generally true. If it looks
like we are applying the inverse function to both sides, it is generally not true.
This is a good rule of thumb, but when in doubt, make a claim and give a proof.
The next theorem gives us permission to apply images and preimages to both
sides of a subset relation without any extra conditions. It immediately violates
our rule of thumb, but in a positive way. We might expect applying preimages
to both sides of an inequality to go wrong, but it turns out to be OK. The proof
is easy.
Theorem 12.2.2.
Let f âˆ¶A â†’B be a function. Let S1, S2 âŠ†A and T1, T2 âŠ†B.
1. If S1 âŠ†S2, then f (S1) âŠ†f (S2).
2. If T1 âŠ†T2, then f âˆ’1(T1) âŠ†f âˆ’1(T2).
Proof. We will prove part 1. That is, we will prove that if S1 âŠ†S2, then f (S1) âŠ†
f (S2).
Assume S1 âŠ†S2.
Comment: What are we proving now? We are proving that f (S1) âŠ†f (S2). That
is, we are proving that if y âˆˆf (S1), then y âˆˆf (S2).
Assume y âˆˆf (S1). Then âˆƒx âˆˆS1 s.t. f (x) = y. But x âˆˆS1 âŠ†S2. So f (x) âˆˆf (S2).
That proves part 1. Part 2 is left as an exercise.
â—½
The next theorem checks that function composition causes no problems.

224
12 Images and Preimages
Theorem 12.2.3.
Let f âˆ¶A â†’B and gâˆ¶B â†’C be functions. Let S âŠ†A and
T âŠ†C. Then
1. g( f (S)) = (g âˆ˜f )(S), and
2. f âˆ’1(gâˆ’1(T)) = (g âˆ˜f )âˆ’1(T).
Proof. We will prove each part in turn. The proofs of both parts are very easy,
but the notation can be confusing. Adding an extra name along the way will
help make things clearer.
Part 1. We claim that g( f (S)) = (g âˆ˜f )(S).
Proof of claim. For convenience, let h = g âˆ˜f and U = f (S). We are trying
to prove a set equality, so we must prove that g( f (S)) âŠ†(g âˆ˜f )(S) and that
(g âˆ˜f )(S) âŠ†g( f (S)).
Step 1: First we prove g(f (S)) âŠ†(g âˆ˜f )(S).
Assume t âˆˆg( f (S)). Then t âˆˆg(U). So âˆƒu âˆˆU s.t. g(u) = t. But then
u âˆˆU = f (S); so âˆƒs âˆˆS s.t. f (s) = u. Then
h(s) = (g âˆ˜f )(s) = g( f (s)) = g(u) = t.
(12.10)
So we have proved that âˆƒs âˆˆS s.t. h(s) = t. Then t âˆˆh(S). So t âˆˆ(g âˆ˜f )(S).
Thus, g( f (S)) âŠ†(g âˆ˜f )(S).
Step 2: Now we prove that (g âˆ˜f )(S) âŠ†g( f (S)).
Assume t âˆˆ(g âˆ˜f )(S) = h(S). So âˆƒs âˆˆS s.t. h(s) = t. Then
t = (g âˆ˜f )(s) = g( f (s)).
(12.11)
Let u = f (s). Since s âˆˆS, this means u âˆˆf (S) = U. But we also have t = g(u)
with u âˆˆU. So t âˆˆg(U) = g( f (S)). Thus, (g âˆ˜f )(S) âŠ†g( f (S)).
We have now proved both g( f (S)) âŠ†(g âˆ˜f )(S) and that (g âˆ˜f )(S) âŠ†g( f (S)).
Thus, (g âˆ˜f )(S) = g( f (S)).
â—¾
Part 2. We claim that f âˆ’1(gâˆ’1(T)) = (g âˆ˜f )âˆ’1(T).
Proof of claim. Again, this is a set equality, so we must prove that
f âˆ’1(gâˆ’1(T)) âŠ†(g âˆ˜f )âˆ’1(T) and f âˆ’1(gâˆ’1(T)) âŠ‡(g âˆ˜f )âˆ’1(T).
And again, for convenience, let h = g âˆ˜f and V = gâˆ’1(T).
Step 1: First we will prove that f âˆ’1(gâˆ’1(T)) âŠ†(g âˆ˜f )âˆ’1(T).
Assume s âˆˆf âˆ’1(gâˆ’1(T) = f âˆ’1(V). Then f (s) âˆˆV = gâˆ’1(T). So g( f (s)) âˆˆT. So
h(s) âˆˆT. This tells us that s âˆˆhâˆ’1(T). So indeed, s âˆˆ(g âˆ˜f )âˆ’1(T).
Step 2: Now we will prove that f âˆ’1(gâˆ’1(T)) âŠ‡(g âˆ˜f )âˆ’1(T).

12.2 Theorems about Images and Preimages
225
Assume s âˆˆ(g âˆ˜f )âˆ’1(T) = hâˆ’1(T). So h(s) âˆˆT. Then (g âˆ˜f )(s) âˆˆT; so
g( f (s)) âˆˆT. So f (s) âˆˆgâˆ’1(T) = V. And in turn, s âˆˆf âˆ’1(V) = f âˆ’1(gâˆ’1(T)).
We have now proved both f âˆ’1(gâˆ’1(T)) âŠ†(g âˆ˜f )âˆ’1(T) and f âˆ’1(gâˆ’1(T)) âŠ‡
(g âˆ˜f )âˆ’1(T). Thus, f âˆ’1(gâˆ’1(T)) = (g âˆ˜f )âˆ’1(T).
â—¾
â—½
Our next theorems are about the interactions of image and preimage. The
point to remember is that they are not inverse operations, but they have some
qualities of this relationship.
Theorem 12.2.4.
Let f âˆ¶A â†’B be a function.
1. If S âŠ†Domain( f ), then S âŠ†f âˆ’1( f (S)). This says that S is a subset, but allows
the possibility that f âˆ’1( f (S)) has elements not in S.
2. If T âŠ†B, then f (f âˆ’1(T)) âŠ†T. This says that f (f âˆ’1(T)) is a subset, but allows
the possibility that T has elements not in f (f âˆ’1(T)).
3. If f (x) is injective, and if S âŠ†Domain( f ), then S = f âˆ’1( f (S)).
4. If f (x) is surjective, then for all T âŠ†B, f ( f âˆ’1(T)) = T.
5. If f (x) is bijective, then for all S âŠ†A, f âˆ’1( f (S)) = S and f ( f âˆ’1(T)) = T.
Very few people remember the details of this theorem for very long. Well, the
last one says that
When an inverse exists, the notation for images and preimages
works ï¬ne.
And that is easy to remember.
The best course of action is to be very cautious when we ï¬nd we want to cancel
the images and preimages. Generic pictures can help us distinguish between
what is true and what is not. Still, we should make it a point to actually prove
what we need rather than rely on what we remember from this theorem.
Proof draft. Assume that f âˆ¶A â†’B is a function.
Part 1. We claim that if S âŠ†Domain( f ), then S âŠ†f âˆ’1( f (S)).
Proof of claim. Assume S âŠ†Domain( f ).
Comment: What are we proving? If s âˆˆS, then s âˆˆf âˆ’1( f (S)). So we should begin
by assuming that s âˆˆS.
Assume s âˆˆS.
Comment: What are we proving now? We are proving that s âˆˆf âˆ’1( f (S)) =
f âˆ’1(T) for the particular set T = f (S). So how do we prove that? We show that
s âˆˆf âˆ’1(T) = {x âˆˆA âˆ£f (x) âˆˆT}. So how do we prove that? We show f (s) âˆˆf (S).
But this is true by the deï¬nition. It takes longer to ï¬gure out what to say than

226
12 Images and Preimages
it does to say it. Notice that we deï¬nitely need S âŠ†Domain( f ). So itâ€™s time to
write the proof.
Since s âˆˆS âŠ†Domain( f ), f (s) âˆˆf (S). So by the deï¬nition of preimage,
s âˆˆf âˆ’1( f (S)).
â—¾
Part 2. We claim that if T âŠ†B, then f (f âˆ’1(T)) âŠ†T.
Proof of claim. Assume T âŠ†B.
Comment: What are we proving? If t âˆˆf (f âˆ’1(T)), then t âˆˆT. We know what to
do to start the proof.
Assume t âˆˆf (f âˆ’1(T)) = f (S) for the particular S = f âˆ’1(T). Then
t âˆˆf (S);
(12.12)
t âˆˆ{y âˆˆB âˆ£âˆƒx âˆˆS s.t. f (x) = y};
t âˆˆ{y âˆˆB âˆ£âˆƒx âˆˆf âˆ’1(T) s.t. f (x) = y}.
So âˆƒs âˆˆf âˆ’1(T) s.t. f (s) = t.
Comment: When we hear â€œthere exists,â€ we need to choose a name, and s seems
fresher in this part than x. We now ï¬nish the proof.
But s âˆˆf âˆ’1(T) means f (s) âˆˆT. So sure enough, t = f (s) âˆˆT.
â—¾
Part 3. We claim that if f (x) is injective, and if S âŠ†Domain( f ), then
S = f âˆ’1( f (S)).
Proof of claim. Assume that f (x) is injective. Assume S âŠ†Domain( f ).
Comment: What are we proving? That f âˆ’1( f (S)) = S. So, we must prove that the
subset goes both ways. However, one direction is already proved; so we need to
prove: if s âˆˆf âˆ’1( f (S)), then s âˆˆS. At least we know how to start.
Assume s âˆˆf âˆ’1( f (S)). Then f (s) âˆˆf (S).
Comment: We were warned about this. It looks like we need to cancel the
functions, but that is not allowed. We ask, what does this mean?
We have
f (s) âˆˆf (S) = {y âˆˆB âˆ£âˆƒx âˆˆS s.t. f (x) = y}.
(12.13)
So âˆƒsâ€² âˆˆS s.t. f (sâ€²) = f (s).

12.2 Theorems about Images and Preimages
227
Comment: When we hear â€œthere exists,â€ we need to choose a name, but y might
be confusing, and s is already used in this part. So sâ€² seems like a good choice.
Now f (sâ€²) = f (s), and f (x) is injective; so sâ€² = s. So s = sâ€² âˆˆS.
â—¾
Part 4. We claim that if f (x) is surjective, then for all T âŠ†B, f (f âˆ’1(T)) = T.
Proof of claim. Assume that f (x) is surjective. Assume T âŠ†B.
Comment: What are we proving? That f (f âˆ’1(T)) = T. We have already proved
the subset in one direction. So we need to prove: if t âˆˆT, then t âˆˆf (f âˆ’1(T)).
Assume t âˆˆT.
Comment: Now what are we proving?
t âˆˆf (f âˆ’1(T)) = {y âˆˆB âˆ£âˆƒx âˆˆf âˆ’1(T) s.t. f (x) = y}.
(12.14)
So we need to prove that something exists. We set up a word problem: ï¬nd x so
that x âˆˆf âˆ’1(T) and f (x) = t. In other words, ï¬nd x so that f (x) âˆˆT and f (x) = t.
What to do, what to do? Is there something we know that we havenâ€™t used? Well,
we assumed that f (x) is surjective. That means everything in B comes out of the
function. Do I have something in B? Oh, yeah.
Now t âˆˆT âŠ†B. Since f (x) is surjective, there exists s âˆˆS such that f (s) = t.
Then f (s) = t âˆˆT. So s âˆˆf âˆ’1(T) and then t = f (s) âˆˆf (f âˆ’1(T)).
â—¾
Î”
We should rewrite this proof to just include what we need to say.
Proof. Assume f âˆ¶A â†’B as a function with domain A.
Part 1. We claim that if S âŠ†Domain( f ), then S âŠ†f âˆ’1( f (S)).
Proof of claim. Assume S âŠ†Domain( f ). Assume s âˆˆS. Since s âˆˆS âŠ†A =
Domain( f ), we know that f (s) is deï¬ned. Then f (s) âˆˆf (S) by the last theorem.
So s âˆˆf âˆ’1( f (S) by the same theorem.
â—¾
Part 2. We claim that if T âŠ†B, then f (f âˆ’1(T)) âŠ†T.
Proof of claim. Assume T âŠ†B. Assume t âˆˆf ( f âˆ’1(T)). Then
t âˆˆ{y âˆˆB âˆ£âˆƒx âˆˆf âˆ’1(T) s.t. f (x) = y}.
(12.15)
So âˆƒs âˆˆf âˆ’1(T) s.t. f (s) = t. But s âˆˆf âˆ’1(T) means f (s) âˆˆT. So t = f (s) âˆˆT.
Thus, t âˆˆf (f âˆ’1(T)) implies t âˆˆT.
â—¾

228
12 Images and Preimages
Part 3. We claim that if f (x) is injective, and if S âŠ†Domain( f ), then
S = f âˆ’1( f (S)).
Proof of claim. Assume that f (x) is injective. Assume S âŠ†Domain( f ). Assume
s âˆˆf âˆ’1( f (S)).
Then f (s) âˆˆf (S). So by the deï¬nition of image âˆƒsâ€² âˆˆS so that f (sâ€²) = f (s).
We assumed that f (x) is injective, so sâ€² = s. So s = sâ€² âˆˆS. Since this proves
f âˆ’1( f (S)) âŠ†S, by part 1 we are done.
â—¾
Part 4. We claim that if f (x) is surjective, then for all T âŠ†B, f (f âˆ’1(T)) = T.
Proof of claim. Assume that f (x) is surjective. Assume T âŠ†B. Assume t âˆˆT.
Then t âˆˆT âŠ†B. Since f (x) is surjective, there exists s âˆˆS such that f (s) = t.
Then f (s) = t âˆˆT. So s âˆˆf âˆ’1(T) and then t = f (s) âˆˆf (f âˆ’1(T)). So by part 2, we
are done.
â—¾
Part 5 follows immediately from parts 3 and 4. This completes the proof.
â—½
There is a quick corollary to this theorem that shows that our choice to use
the same notation for an inverse function and for the preimage of a set does not
cause too much of a problem. When an inverse exists, both interpretations give
the same results, and any issues with extra conditions go away.
Corollary 12.2.5.
Let f âˆ¶A â†’B and gâˆ¶B â†’A be functions. Let S âŠ†A and
T âŠ†B. If g(x) is the inverse of f (x), then
1. f âˆ’1(T) = g(T);
2. gâˆ’1(S) = f (S);
3. g( f (S)) = S;
4. f (g(T)) = T.
12.2.2
Unions and intersections
Except for the image of an intersection, the algebra of images and preimages
works ï¬ne.
Theorem 12.2.6.
Let f âˆ¶A â†’B have domain A.
1. For all S1 âŠ†A and S2 âŠ†A, f (S1 âˆ©S2) âŠ†f (S1) âˆ©f (S2).
2. For all S1 âŠ†A and S2 âŠ†A, f (S1 âˆªS2) = f (S1) âˆªf (S2).
3. For all T1 âŠ†B and T2 âŠ†B, f âˆ’1(T1 âˆ©T2) = f âˆ’1(T1) âˆ©f âˆ’1(T2).
4. For all T1 âŠ†B and T2 âŠ†B, f âˆ’1(T1 âˆªT2) = f âˆ’1(T1) âˆªf âˆ’1(T2).
5. If f (x) is injective, then for all S1 âŠ†A and S2 âŠ†A, f (S1 âˆ©S2) = f (S1) âˆ©f (S2).

12.2 Theorems about Images and Preimages
229
Proof. The trick to these proofs is to maintain your logical discipline and
choose your variables wisely.
Part 1. We claim that for all S1 âŠ†A and S2 âŠ†A, f (S1 âˆ©S2) âŠ†f (S1) âˆ©f (S2).
Proof of claim. Assume t âˆˆf (S1 âˆ©S2) = {y âˆˆB âˆ£âˆƒx âˆˆS1 âˆ©S2 s.t.f (x) = y}.
Then âˆƒs âˆˆS1 âˆ©S2 s.t. f (s) = t. Now s âˆˆS1 âˆ©S2 means s âˆˆS1 and s âˆˆS2. So
f (s) âˆˆf (S1) and f (s) âˆˆf (s2). So t = f (s) âˆˆf (S1) âˆ©f (S2).
â—¾
Part 2. We claim that for all S1 âŠ†A and S2 âŠ†A, f (S1 âˆªS2) = f (S1) âˆªf (S2).
Proof of claim. Assume that S1 âŠ†A and S2 âŠ†A. We are proving a set equality,
so we must prove that the subset relation holds in both directions.
Step 1: First we will prove that f (S1 âˆªS2) âŠ†f (S1) âˆªf (S2).
Assume t âˆˆf (S1 âˆªS2) = {y âˆˆB âˆ£âˆƒx âˆˆS1 âˆªS2 s.t. f (x) = y}. So âˆƒs âˆˆS1 âˆªS2
s.t. f (s) = t. Now s âˆˆS1 âˆªS2 means s âˆˆS1 or s âˆˆS2.
Case 1: Assume s âˆˆS1, then f (s) âˆˆf (S1) âŠ†f (S1) âˆªf (S2).
Case 2: Assume s âˆˆS2, then f (s) âˆˆf (S2) âŠ†f (S1) âˆªf (S2).
So in either case, t âˆˆf (S1 âˆªS2) implies t = f (s) âˆˆf (S1) âˆªf (S2).
This proves that f (S1 âˆªS2) âŠ†f (S1) âˆªf (S2).
Step 2: Now we will prove that f (S1 âˆªS2) âŠ‡f (S1) âˆªf (S2).
Assume t âˆˆf (S1) âˆªf (S2). Then either t âˆˆf (S1) or t âˆˆ(S2).
Case 1: Assume t âˆˆf (S1). Then âˆƒs1 âˆˆS1 such that f (s1) = t. But s1 âˆˆS1 âŠ†
S1 âˆªS2. So t = f (s1) âˆˆf (S1 âˆªS2).
Case 2: Assume t âˆˆf (S2). Then âˆƒs2 âˆˆS1 such that f (s2) = t. But s2 âˆˆS2 âŠ†
S1 âˆªS2. So t = f (s2) âˆˆf (S1 âˆªS2).
In either case, t âˆˆf (S1) âˆªf (S2) implies t = f (s2) âˆˆf (S1 âˆªS2).
This proves that f (S1 âˆªS2) âŠ‡f (S1) âˆªf (S2).
â—¾
Part 3. We claim that for all T1 âŠ†B and T2 âŠ†B, f âˆ’1(T1 âˆ©T2) = f âˆ’1(T1) âˆ©
f âˆ’1(T2).
Proof of claim. Assume that T1 âŠ†B and T2 âŠ†B. We are proving a set equality,
so we must prove that the subset relation holds in both directions.
Step 1: We will ï¬rst prove that f âˆ’1(T1 âˆ©T2) âŠ†f âˆ’1(T1) âˆ©f âˆ’1(T2).
Assume s âˆˆf âˆ’1(T1 âˆ©T2). So f (s) âˆˆT1 âˆ©T2. So f (s) âˆˆT1 and f (s) âˆˆT2. So s âˆˆ
f âˆ’1(T1) and s âˆˆf âˆ’1(T2). Then s âˆˆf âˆ’1(T1) âˆ©f âˆ’1(T2). This proves that f âˆ’1(T1 âˆ©
T2) âŠ†f âˆ’1(T1) âˆ©f âˆ’1(T2).
Step 2: We will now prove that f âˆ’1(T1 âˆ©T2) âŠ‡f âˆ’1(T1) âˆ©f âˆ’1(T2).

230
12 Images and Preimages
Assume s âˆˆf âˆ’1(T1) âˆ©f âˆ’1(T2). So s âˆˆf âˆ’1(T1) and s âˆˆf âˆ’1(T2). So f (s) âˆˆT1
and f (s) âˆˆT2. So f (s) âˆˆT1 âˆ©T2 . Finally s âˆˆf âˆ’1(T1 âˆ©T2). This proves that
f âˆ’1(T1 âˆ©T2) âŠ‡f âˆ’1(T1) âˆ©f âˆ’1(T2).
â—¾
Part 4. We claim that for all T1 âŠ†B and T2 âŠ†B, f âˆ’1(T1 âˆªT2) = f âˆ’1(T1) âˆª
f âˆ’1(T2).
Proof of claim. Assume that T1 âŠ†B and T2 âŠ†B. We are proving a set equality,
so we must prove that the subset relation holds in both directions.
Step 1: We will ï¬rst prove that f âˆ’1(T1 âˆªT2) âŠ†f âˆ’1(T1) âˆªf âˆ’1(T2).
Assume s âˆˆf âˆ’1(T1 âˆªT2). So f (s) âˆˆT1 âˆªT2. So f (s) âˆˆT1 or f (s) âˆˆT2.
So s âˆˆf âˆ’1(T1) or s âˆˆf âˆ’1(T2). Then s âˆˆf âˆ’1(T1) âˆªf âˆ’1(T2). This proves that
f âˆ’1(T1 âˆªT2) âŠ†f âˆ’1(T1) âˆªf âˆ’1(T2).
Step 2: We will now prove that f âˆ’1(T1 âˆªT2) âŠ‡f âˆ’1(T1) âˆªf âˆ’1(T2).
Assume s âˆˆf âˆ’1(T1) âˆªf âˆ’1(T2). So s âˆˆf âˆ’1(T1) or s âˆˆf âˆ’1(T2). So f (s) âˆˆT1 or
f (s) âˆˆT2. So f (s) âˆˆT1 âˆªT2 . Finally, s âˆˆf âˆ’1(T1 âˆªT2). This proves that f âˆ’1(T1 âˆª
T2) âŠ‡f âˆ’1(T1) âˆªf âˆ’1(T2).
â—¾
Part 5. We claim that if f (x) is injective, then for all S1 âŠ†A and S2 âŠ†A,
f (S1 âˆ©S2) = f (S1) âˆ©f (S2).
Proof of claim. Assume that f (x) is injective. Assume S1 âŠ†A and S2 âŠ†A. We
have already proved that f (S1 âˆ©S2) âŠ†f (S1) âˆ©f (S2). So we need to only prove
that f (S1 âˆ©S2) âŠ‡f (S1) âˆ©f (S2).
Assume t âˆˆf (S1) âˆ©f (S2). Then t âˆˆf (S1) and t âˆˆf (S2). But t âˆˆf (S1) means
âˆƒs âˆˆS1 such that f (s) = t. In addition, t âˆˆf (S2) means âˆƒsâ€² âˆˆS1 such that
f (sâ€²) = t.
Comment: We do not use the same variable for two possible diï¬€erent things just
because we expect that they are the same.
Now f (s) = t = f (sâ€²), and f (x) is injective. So s = sâ€². But then s âˆˆS1
and
sâ€² âˆˆS2.
We
have
s = sâ€² âˆˆS1 âˆ©S2.
So
f (s) âˆˆf (S1 âˆ©S2),
and
then
t = f (s) âˆˆf (S1 âˆ©S2). This proves that f (S1 âˆ©S2) âŠ‡f (S1) âˆ©f (S2).
â—¾
â—½
Properties of the unions and intersections of two sets can often be extended
to any number of sets. That is what happens here:
Theorem 12.2.7.
Let f âˆ¶A â†’B have domain A. Let Si with i âˆˆîˆµbe a family
of sets where âˆ€i âˆˆîˆµ, Si âŠ†A.

12.3 Problems
231
1. f
(â‹‚
iâˆˆîˆµ
Si
)
âŠ†â‹‚
iâˆˆîˆµ
f (Si).
2. f
(â‹ƒ
iâˆˆîˆµ
Si
)
= â‹ƒ
iâˆˆîˆµ
f (Si).
Theorem 12.2.8.
Let f âˆ¶A â†’B have domain A. Let Ti with i âˆˆîˆµbe a family
of sets where âˆ€i âˆˆîˆµ, Ti âŠ†B.
1. f âˆ’1
(â‹‚
iâˆˆîˆµ
Ti
)
= â‹‚
iâˆˆîˆµ
f âˆ’1(Ti).
2. f âˆ’1
(â‹ƒ
iâˆˆîˆµ
Ti
)
= â‹ƒ
iâˆˆîˆµ
f âˆ’1(Ti).
We leave the proofs as exercises.
12.3
Problems
12.1
Draw a generic diagram that illustrates why the theorem:
for all S1 âŠ†A and S2 âŠ†A, f (S1 âˆ©S2) âŠ†f (S1) âˆ©f (S2)
only has a subset in its conclusion.
12.2
Let f âˆ¶A â†’B where A = {1, 2, 3, 4, 5}, B = {1, 2, 3, 4, 5, 6} and f is given
by the following table.
x
f (x)
1
2
2
6
3
4
3
5
4
True or false:
(a) Domain( f ) = A.
(b) Range(f )= B.
(c) Codomain(f )= B.
(d) f (2) = {6}.
(e) f (4) = 3.
(f) f ({1, 2}) = {2, 6}.
(g) f (3) = âˆ….
(h) f (x) is injective.

232
12 Images and Preimages
(i) f (x) is surjective.
(j) f âˆ’1({3, 4}) = {4, 5}.
(k) f âˆ’1({1, 5}) = âˆ….
(l) f âˆ’1(2) = 1.
(m) f âˆ’1(2) = {1}.
12.3
Let f âˆ¶â„â†’â„be given by f (x) = 1
x2 . Find the following (but do not
bother to prove that your answer is correct):
(a) f ((0, 3)).
(b) f ([0, 4)).
(c) f (â„).
(d) f ([âˆ’2, 3]).
(e) f (âˆ…).
(f) f âˆ’1((0, âˆž)).
(g) f âˆ’1((âˆ’1, 1)).
(h) f âˆ’1(( 1
4, 1]).
(i) f âˆ’1(â„).
(j) f âˆ’1(âˆ…).
12.4
Let f âˆ¶â„â†’â„be given by f (x) = x3 âˆ’x. Find the following (but do not
bother to prove that your answer is correct):
(a) f ({ âˆ’1, 0, 1)}).
(b) f ([âˆ’1, 1]).
(c) f ((âˆ’1, 1)).
(d) f ((âˆ’5, 5)).
(e) f (â„).
(f) f (âˆ…).
(g) f âˆ’1({0}).
(h) f âˆ’1((0, âˆž)).
(i) f âˆ’1((âˆ’120,120)).
(j) f âˆ’1(â„).
(k) f âˆ’1(âˆ…).
12.5
Deï¬ne f âˆ¶â„â†’â„by f (x) = x3âˆ’1
xâˆ’1 . Find the following (but do not bother
to prove that your answer is correct):
(a) f ({ âˆ’2, 0, 2)}).
(b) f ([âˆ’5, 5]).
(c) f ({ Â± 1}).
(d) f ({1}).
(e) f (1).
(f) f âˆ’1({7}).
(g) f âˆ’1((0, âˆž)).
(h) f âˆ’1(âˆ…).

12.3 Problems
233
12.6
Let f âˆ¶A â†’B be a function. Let S1, S2 âŠ†A and T1, T2 âŠ†B.
(a) Prove that if S1 âŠ†S2, then f (S1) âŠ†f (S2).
(b) Prove that if T1 âŠ†T2, then f âˆ’1(T1) âŠ†f âˆ’1(T2).
12.7
Prove that if f âˆ¶A â†’B is a function with domain A and Si with i âˆˆîˆµis
a family of sets where âˆ€i âˆˆîˆµ, Si âŠ†A, then
f
(
â‹‚
iâˆˆîˆµ
Si
)
âŠ†
â‹‚
iâˆˆîˆµ
f (Si).
(12.16)
12.8
Prove that if f âˆ¶A â†’B is a function with domain A and Ti with i âˆˆîˆµis
a family of sets where âˆ€i âˆˆîˆµ, Ti âŠ†B, then
f âˆ’1
(
â‹ƒ
iâˆˆîˆµ
Ti
)
=
â‹ƒ
iâˆˆîˆµ
f âˆ’1(Ti).
(12.17)
12.9
Suppose that f âˆ¶A â†’B is an injective function with domain A. Prove
that if Si with i âˆˆîˆµis a family of sets where âˆ€i âˆˆîˆµ, Si âŠ†A, then
f
(
â‹‚
iâˆˆîˆµ
Si
)
=
â‹‚
iâˆˆîˆµ
f (Si).
(12.18)
12.10
Let f âˆ¶A â†’B be a function with domain A. Prove that if âˆ€S âŠ†A,
S = f âˆ’1( f (S)), then f (x) is injective.
12.11
Let f âˆ¶A â†’B be a function with domain A. Prove that if âˆ€T âŠ†B,
T = f (f âˆ’1(T)), then f (x) is surjective.
12.12
Let us call intervals of the form (a, b), (a, âˆž), and (âˆ’âˆž, b) open. And we
will call intervals of the form [a, b], [a, âˆž), and (âˆ’âˆž, b] closed. Then as
usual, we call (a, b), (a, b], [a, b), and [a, b] bounded, and we call (a, âˆž),
[a, âˆž), (âˆ’âˆž, b), and (âˆ’âˆž, b] unbounded.
(a) For f âˆ¶â„â†’â„given by f (x) = 1
x:
i. Is there an open interval A, where f (A) is not an open interval?
ii. Is there a closed interval A, where f (A) is not a closed interval?
iii. Is there a bounded interval A, where f (A) is not a closed
bounded?
iv. Is there an open interval B where f âˆ’1(B) is not an open interval?
v. Is there a closed interval B where f âˆ’1(B) is not a closed interval?
vi. Is there a bounded interval B where f âˆ’1(B) is not a bounded
interval?

234
12 Images and Preimages
12.13
Let us call intervals of the form (a, b), (a, âˆž), and (âˆ’âˆž, b) open. And we
will call intervals of the form [a, b], [a, âˆž), and (âˆ’âˆž, b] closed. Then as
usual, we call (a, b), (a, b], [a, b), and [a, b] bounded, and we call (a, âˆž),
[a, âˆž), (âˆ’âˆž, b), and (âˆ’âˆž, b] unbounded.
(a) Find a function f âˆ¶â„â†’â„with domain â„where:
i. There is an open interval A, where f (A) is not an open interval.
ii. There is a closed interval A, where f (A) is not a closed interval.
iii. There is a bounded interval A, where f (A) is not a bounded
interval.
(b) Find a function f âˆ¶â„â†’â„with domain â„where:
i. There is an open interval B where f âˆ’1(B) is not an open interval.
ii. There is a closed interval B where f âˆ’1(B) is not a closed interval.
iii. There is a bounded interval B where f âˆ’1(B) is not a bounded
interval.
12.14
Let f âˆ¶â„â†’â„. We know that it is common to be asked to solve f (x) = 0
for the variable x. Write out the set of solutions to this problem using
the notation introduced in this section.

235
13
Final Basic Notions
We have two unrelated mathematical ideas to investigate before we can return
to our study of number systems.
13.1
Binary operations
We start with a deï¬nition.
Deï¬nition 13.1.1.
Let A be a set. A binary operation b on A is a function
b âˆ¶A Ã— A â†’A with domain A Ã— A.
Notation. When we consider b âˆ¶A Ã— A â†’A as a binary operation, we write
b((x, y)) as xby. In addition, in place of the variable name, we use a symbol such
as +, Ã—, âˆ—, â‹…, âƒ, âŠ•, âŠ—, âˆª, âˆ©, âˆ¨, âˆ§, or âŠ .
Now suppose that âŠ âˆ¶A Ã— A â†’A is a binary operation of some sort. The fact
that this is a function with domain A Ã— A means that, for all x, y âˆˆA, the value
of x âŠ y is well deï¬ned. The fact that the codomain of âŠ is A means that, for
all x, y âˆˆA, x âŠ y is a unique element of A. This property of binary operations
is often referenced by saying that the operation âŠ is closed.
Now we deï¬ne some properties associated with certain binary operations.
These should be very familiar.
Deï¬nition 13.1.2.
Let A be a set. Let âŠ be a binary operation on A.
1. We say that âŠ is associative if âˆ€a, b, c âˆˆA, (a âŠ b) âŠ c = a âŠ (b âŠ c).
2. We say that âŠ is commutative if âˆ€a, b âˆˆA, a âŠ b = b âŠ a.
3. If âŠžis another binary operation on A, we say that âŠ distributes over âŠžif
âˆ€a, b, c âˆˆA, a âŠ (b âŠžc) = (a âŠ b) âŠž(a âŠ c).
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

236
13 Final Basic Notions
4. We say that i âˆˆA is a âŠ -identity if âˆ€a âˆˆA, a âŠ i = i âŠ a = a.
5. For a, b âˆˆA, we say that b is a âŠ -inverse of a if a âŠ b = b âŠ a = i, where i is
a âŠ -identity.
These are very general deï¬nitions that apply to all sorts of situations, but they
should have very obvious applications to our study of number systems. We have
two equally general theorems.
Theorem 13.1.3.
Let A be a set. Let âŠ be a binary operation on A. If there is
a âŠ -identity in A, it is unique.
Proof. Assume that i1 âˆˆA and i2 âˆˆA are âŠ -identities. Consider i1 âŠ i2. Then
i1 = i1 âŠ i2 = i2.
â—½
So all we need is a true binary operation on a single set A, and we know that,
if one exists, the identity for that operation is unique. (It must be a two-sided
identity, though.)
Theorem 13.1.4.
Let A be a set. Let âŠ be a binary operation on A. If âŠ is
associative, then if a âˆˆA has a âŠ -inverse, then the inverse is unique to a.
Proof. Assume that âŠ be an associative operation on A. Assume that b1 and b2
are inverses of a. Consider b1 âŠ (a âŠ b2). On the one hand,
b1 âŠ (a âŠ b2) = b1 âŠ i
(13.1)
= b1.
On the other, associativity tells us that
b1 âŠ (a âŠ b2) = (b1 âŠ a) âŠ b2
(13.2)
= i âŠ b2
= b2.
Since the results of the operation are unique, b1 = b2.
â—½
Notice how critical it is that the deï¬nitions of identity and inverse require the
element work on both sides.
13.2
Finite and inï¬nite sets
13.2.1
Objectives of this discussion
Even though the object of this study is to understand and master the practice
of mathematical proof, this next discussion will not emphasize proofs of the
theorems it contains. In fact, all the proofs will be relegated to the chapterâ€™s
appendix. This is not because the proofs are diï¬ƒcult. In fact, all but two are

13.2 Finite and Inï¬nite Sets
237
rather straightforward. It is not because they are not interesting. Indeed, several
are just the opposite. Nevertheless, for our purposes, it is the intuitive results
about ï¬nite and inï¬nite sets that are important. All we really need is to know
that they follow from the oï¬ƒcial deï¬nitions.
A mathematical deï¬nition of a ï¬nite set did not appear until the 19th century.
Until then, mathematicians relied on their intuition about ï¬nite sets in their
proofs. On the other hand, mathematicians found that their intuition about
inï¬nite sets was not always reliable. It was generally thought that complete inï¬-
nite sets were nonmathematical and could not be used in rigorous proof. In
the 19th century, mathematician Georg Cantor proposed a rigorous deï¬nition
of an inï¬nite set that could be used to prove the intuitive ideas that worked
and exposed the intuitive notions that caused problems. Finally, mathemati-
cians had a theory of inï¬nite sets that was rigorous. After Cantor, inï¬nite sets
became legitimate objects in Mathematics.
We will give Cantorâ€™s deï¬nitions. We will then state the intuitive results
that follow from them. These intuitive theorems about ï¬nite and inï¬nite
sets are the results that are used most often throughout Mathematics. The
proofs are important and interesting because they show that those results are
consequences of Cantorâ€™s deï¬nitions. Since our goal is to understand how to
read and write mathematical proofs across mathematical subjects, they are
less important to us than they would be if we were studying set theory itself.
Thus, we will emphasize the properties of ï¬nite and inï¬nite sets that appear in
those other subjects. Just in case we do choose to go over the proofs, they are
included in an appendix to this chapter.
13.2.2
Why the fuss?
The idea of a set that is so large that it is inï¬nite is very intuitive. However, apply-
ing logic to this intuitive notion is rather diï¬ƒcult. It can produce conclusions
that are actually contradictory. Early Greek philosophers and mathematicians
explored this and could never ï¬nd a good solution. They decided that the best
course of action was to banish complete inï¬nite sets from formal logic and
mathematics. It is not that they did not consider collections with more than
enough objects to be inï¬nite but that they said that no one should consider
them all at one time. Thus, when Euclid proved that there are inï¬nitely many
prime numbers in his manuscript Elements, he was not allowed to say that was
what he did. Rather he said,
â€œPrime numbers are more than any assigned magnitude of prime
numbers.â€
Mathematicians stuck with this Greek rule against complete inï¬nities,
mostly, for the following 2000 years. However, their resolve had begun to
crack by the beginning of the 18th century with the invention of inï¬nitesimal

238
13 Final Basic Notions
calculus by Isaac Newton and Gottfried Leibniz. (â€œInï¬nitesimalâ€ = â€œinï¬nitely
small.â€) By the middle of the 19th century, the Greek warning about using
complete inï¬nities seemed justiï¬ed as mathematicians pushed calculus to the
point where their results occasionally seemed paradoxical. Finally though,
inï¬nitesimal calculus was placed on ï¬rm ground by Bernard Bolzano, Richard
Dedekind, Charles MË™eray, Georg Cantor, and others. Cantor went further and
came up with rules for dealing with inï¬nitely large sets as a whole. Those rules
are now part of standard mathematical logic.
For mathematicians to know what their theorems mean, the terms they
use must have solid deï¬nitions. Cantor gave solid deï¬nitions for the intuitive
notions of a ï¬nite set and an inï¬nite set. He used his deï¬nitions to prove the
properties of these sets that intuition says they should have. We will retrace his
steps. But the important lesson in this chapter is not quite the same as in every
other chapter. The deï¬nitions of ï¬nite and inï¬nite sets are important to know,
but the theorems they imply are more important. In most of Mathematics, we
use ï¬nite and inï¬nite sets in proofs by using the theorems about them much
more than we use the deï¬nitions. So, while we need to know the deï¬nitions of
ï¬nite and inï¬nite, in practice it is much more important that we know exactly
what intuitive properties of such sets do actually hold.
Once we are past the technical aspects and results that follow from Cantorâ€™s
deï¬nitions of ï¬nite and inï¬nite sets, these deï¬nitions are rarely used to prove
theorems about such sets. It is the properties that follow from those deï¬nitions
that are used in proofs.
The properties that we will use, and the ones we must remember, are as
follows:
â€¢ An inï¬nite set cannot be a subset of a ï¬nite set.
â€¢ If there is a bijection between sets A and B, then either they are both ï¬nite
or they are both inï¬nite.
â€¢ If f âˆ¶A â†’B has domain A and is injective, then if A is inï¬nite, B must be
inï¬nite.
â€¢ If f âˆ¶A â†’B has domain A and is surjective, then if A is ï¬nite, B must be
ï¬nite.
â€¢ The elements in a ï¬nite set can be counted, and the size of the set be given
as a natural number or 0.
â€¢ If U is a set with a total order, and A âŠ†U is any nonempty, ï¬nite subset, then
A has a maximum and a minimum.
â€¢ If A and B are ï¬nite sets, then both A âˆªB and A Ã— B are also ï¬nite.
We will use the deï¬nitions of inï¬nite and ï¬nite to state theorems that follow
from Cantorâ€™s deï¬nitions. We will only state them, and we relegate their proofs
to the appendix of the chapter.

13.2 Finite and Inï¬nite Sets
239
13.2.3
Finite sets
We begin with a theorem that Cantor used to produce his deï¬nition of an inï¬-
nite set. He certainly wanted his deï¬nition to tell us that the set {1, 2, 3, 4 â€¦ , n}
is a ï¬nite set for any natural number n. He knew that this set had the following
property.
Theorem 13.2.1.
For n âˆˆâ„•, let Sn = {x âˆˆâ„•âˆ£x â‰¤n}. For all n âˆˆâ„•, if f âˆ¶
Sn â†’Sn is an injective function with domain Sn, then f (x) is surjective.
Since sets of the form Sn = {x âˆˆâ„•âˆ£x â‰¤n} should be typical ï¬nite sets, this
idea leads to a deï¬nition of a ï¬nite set:
Deï¬nition 13.2.2.
Let A be a set. We say that A is ï¬nite when
if f âˆ¶A â†’A is an injective function with domain A,
then f (x) is surjective.
A set is inï¬nite when it is not ï¬nite. We know how to negate a logical
statement.
Deï¬nition 13.2.3.
Let A be a set. We say that A is inï¬nite when
there exists f âˆ¶A â†’A an injective function with domain A
where f (x) is not surjective.
This might seem strange, but it is reassuring that it is very easy to see that
familiar inï¬nite sets of numbers ï¬t this deï¬nition.
The natural numbers â„•form an inï¬nite set, as the function
f âˆ¶â„•â†’â„•given by f (n) = n + 1
(13.3)
illustrates. It is injective, but 1 âˆ‰Range( f ). Once we have one such function,
there are plenty available:
f2 âˆ¶â„•â†’â„•given by f2(n) = n + 2;
(13.4)
f3 âˆ¶â„•â†’â„•given by f3(n) = n + 3;
f 4 âˆ¶â„•â†’â„•given by f4(n) = n + 4.
Or perhaps
g âˆ¶â„•â†’â„•given by g(n) = 2n.
(13.5)
This last formula also works to prove that the integers form an inï¬nite set:
g1 âˆ¶â„¤â†’â„¤given by g(n) = 2n.
(13.6)

240
13 Final Basic Notions
âˆ’2
âˆ’1
1
2
âˆ’1
1
0
Figure 13.1 j(x) =
x
âˆš
x2+1.
On the other hand, notice that the function g3 âˆ¶â„â†’â„given by g(x) = 2x will
not suï¬ƒce to show that â„is inï¬nite. In this case, g is actually bijective. So, we
need a fancier function to show that â„is inï¬nite. Here is one that will do nicely:
j âˆ¶â„â†’â„given by j(x) =
x
âˆš
x2 + 1
.
(13.7)
We can see from the graph that while j is injective, it is not surjective
(Figure 13.1).
Notice that
h âˆ¶â„â†’â„given by h(x) = Arctan(x)
(13.8)
would also work to show that â„is inï¬nite.
Intuition certainly implies that because, â„•âŠ†â„¤âŠ†â„šâŠ†â„, once we know that
â„•is inï¬nite, the others must also be. It will be gratifying to see a result such as
this in the list of theorems that can be proved from these deï¬nitions.
13.2.4
Intuitive properties of inï¬nite sets
As we have said (repeatedly), the things to remember about ï¬nite and inï¬nite
sets are their useful properties. We will state the theorems that give these prop-
erties. All but the last theorem about ï¬nite sets are followed by their contrapos-
itives, which turn them into equivalent theorems about inï¬nite sets. Typically,
one or both directions will seem like they should be obvious.
Theorem 13.2.4.
Let A and B be sets with ð›½âˆ¶A â†’B a bijection. If A is ï¬nite,
then B is ï¬nite.
Corollary 13.2.5.
Let A and B be sets with ð›½âˆ¶A â†’B a bijection. If A is inï¬-
nite, then B is inï¬nite.

13.2 Finite and Inï¬nite Sets
241
Since the existence of a one-to-one onto relation between the sets A and B
should mean that they are of the same â€œsize,â€ this should certainly be true.
Theorem 13.2.6.
Let A and B be sets with A âŠ†B. If B is ï¬nite, then A is ï¬nite.
Corollary 13.2.7.
Let A and B be sets with A âŠ†B. If A is inï¬nite, then B is
inï¬nite.
It makes sense that you cannot put inï¬nitely many things inside a ï¬nite
collection.
Theorem 13.2.8.
Let A and B be sets with j âˆ¶A â†’B an injection with domain
A. If B is ï¬nite, then A is ï¬nite.
Corollary 13.2.9.
Let A and B be sets with j âˆ¶A â†’B an injection with
domain A. If A is inï¬nite, then B is inï¬nite.
This says to assign inï¬nitely many things so that each gets its own location;
you need inï¬nitely many locations.
Theorem 13.2.10.
Let A and B be sets with j âˆ¶A â†’B a surjection with
domain A. If A is ï¬nite, then B is ï¬nite.
Corollary 13.2.11.
Let A and B be sets with j âˆ¶A â†’B a surjection with
domain A. If B is inï¬nite, then A is inï¬nite.
If there are inï¬nitely many places to put things, it will take inï¬nitely many
things to ï¬ll all those places.
Theorem 13.2.12.
Let A be a nonempty ï¬nite set. Then there exists a unique
n âˆˆâ„•so that there is a bijection b âˆ¶Sn â†’A where Sn = {x âˆˆâ„•âˆ£x â‰¤n}.
This theorem guarantees that our deï¬nition of ï¬nite implies that every ï¬nite
set can be counted using the natural numbers.
13.2.5
Counting ï¬nite sets
Theorem 13.2.12, more than any other, justiï¬es Cantorâ€™s strange deï¬nitions of
ï¬nite and inï¬nite sets. It is the converse of the theorem that inspired these def-
initions in the ï¬rst place.
The proof of theorem 13.2.12 is surprisingly long and technical, especially
compared to the theorems before it. Still we should not be that surprised since it
is the hitch pin that connects our nonintuitive deï¬nition of ï¬nite to our intuitive
expectations of ï¬nite sets. This theorem and its diï¬ƒcult proof would garner a

242
13 Final Basic Notions
lot more attention and examination in a study of set theory or the foundations of
mathematics. Of course, since we are currently only interested in the properties
of ï¬nite sets, the length of this proof is not that important to us.
The result stated in this theorem is critical. The theorem helps us by allowing
us to use a nice notation for ï¬nite sets. If we know that A is a ï¬nite set, we might
choose to write A as
A = {a1, a2, a3 â€¦ an}.
(13.9)
We do not have this option unless we know for sure that A is ï¬nite. For example,
â„is inï¬nite, but we cannot write
â„= {r1, r2, r3 â€¦ rn â€¦ }.
(13.10)
The reason we cannot do this is fodder for other, greater, mathematical studies.
The most important thing about this theorem is that it allows us to prove
things about ï¬nite sets using induction. It says that we can count the number
of elements in any ï¬nite set. We need to set notation for the size of a set. For
the number of elements in a ï¬nite set, we write
|A| = n or #(A) = n
(13.11)
where n is the natural number guaranteed by the theorem. Of course, we also
say that |âˆ…| = 0.
Proof technique. If we know that a set S is ï¬nite and we have not yet
named any of the elements in it, it is often convenient to say, â€œLet |S| = n and
S = {s1, s2, s3 â€¦ sn}.â€ This careful statement means that we have made the
elements distinct; that is, si = sj implies i = j. If there is a total order and we
think that the size of the elements will matter in the proof, we can also add
â€œwhere s1 < s2 < s3 < sn.â€ This also means that the elements are distinct.
The next theorems are all proved by counting the ï¬nite sets and performing
induction on the number of elements they have. Again, it is the results we care
most about:
Theorem 13.2.13.
Let S and T be ï¬nite sets, then S âˆªT is ï¬nite.
Theorem 13.2.14.
Let A be a set, and let
îˆ¼(A) = {S âˆ£S âŠ†A}.
(13.12)
If A is ï¬nite, then îˆ¼(A) is ï¬nite.
We call îˆ¼(A) the power set of A.
Theorem 13.2.15.
Let A and B be ï¬nite sets. Then A Ã— B is a ï¬nite set.

13.2 Finite and Inï¬nite Sets
243
Theorem 13.2.16.
If A and B are ï¬nite sets, then there are only ï¬nitely many
functions f âˆ¶A â†’B.
13.2.6
Finite sets in a set with a total order
We will ï¬nish up with one last theorem about ï¬nite sets, but this time we pro-
vide a proof immediately afterward. The proof illustrates a version of induction
where a two-part base for the induction is required. The issue that requires the
extra step is the one we often encounter when we need an element in a set. If
our proof requires an element of a set, we must prove that the set is not empty.
We have seen many proofs that begin as â€œAssume x âˆˆSâ€ without a previous
assumption that S is not empty. In all of these, we were logically justiï¬ed to
make this assumption because we were proving something like â€œIf x âˆˆS, then
P(x).â€ Logic always allows us to assume the hypothesis of the statement we are
proving. In the next proof, we will hit a point where we need to â€œLet x âˆˆS.â€
We are not proving a statement that allows us to assume such an x exists, so we
must prove that it does before we take this step. As it turns out in the next proof,
the set from which we need an x might have been empty had we not adjusted
an earlier part of the proof to avoid it. Hence, the proof by induction starts
with two base steps. The thing to realize is that, no doubt, the ï¬rst attempt at a
proof probably had the typical one-step base, but that once the proof reached
the point that we needed an x in a set that might be empty, it was rewritten to
ï¬x this problem.
Theorem 13.2.17.
Let U be a set with a total order. If A âŠ†U, A â‰ âˆ…, and A is
ï¬nite, then A has a maximum and a minimum.
Proof draft. Assume that U has a total order. Then that order is transitive and
has trichotomy. Assume A âŠ†U. Assume A â‰ âˆ…. Assume that A is ï¬nite. By the
aforementioned theorem, we can write |A| = n âˆˆâ„•.
We will now prove the result by induction on |A| = n, but we will only prove
that A has a minimum. The proof that A has a maximum is basically the same
argument.
Step 1, the ï¬rst base step. We claim that if n = 1, then A has a minimum.
Proof of claim. Assume |A| = 1. Then let A = {a}. Now a âˆˆA and âˆ€x âˆˆA,
a â‰¤x. So a is the minimum of A.
â—¾
Step 2, the second base step. We claim that if n = 2, then A has a minimum.
Proof of claim. Assume |A| = 2. Then let A = {a, b} âŠ†U with a â‰ b. Since
a, b âˆˆU and the order on U has trichotomy, there are two possibilities:

244
13 Final Basic Notions
a < b or b < a. In case 1 where a < b, a = Min(A). In case 2 where b < a,
b = Min(A). In either case, A has a minimum.
â—¾
Step 3, the induction step. We claim that
If for any set A âŠ†U with |A| = n0 â‰¥1, A has a minimum, then for any set
B âŠ†U with |B| = n0 + 1, B has a minimum.
Comment: Notice that we wrote out this step carefully. We included the required
assumption that A be nonempty, and we did not use the letter A to denote two
diï¬€erent sets.
Proof of claim. Assume that if A is a set and |A| = n0 â‰¥1, then A has a mini-
mum.
Comment: As always, we note that this says, â€œif we ever have such a set A â€¦.â€
This assumption does not give us a set A.
Assume |B| = n0 + 1.
Comment: So this assumption actually gives us a set to work with. But what are
we proving now though? That B has a minimum.
Now because n0 + 1 â‰¥1, B â‰ âˆ…. So we let b âˆˆB. Now let A = Bâˆ–{b}. We have
|A| = n0 + 1 âˆ’1 = n0. By the assumption n0 â‰¥1, so A is not empty, and has a
minimum. Call it m.
Comment: This was the moment when we realized that we could not use the
induction assumption unless we knew that A = Bâˆ–{b} was not empty.
Then m âˆˆA = Bâˆ–{b} âŠ†B âŠ†U.
And if x âˆˆA = Bâˆ–{b}, then m â‰¤x.
Consider {b, m}. This is a subset of U with two elements. By step 2, {b, m} has
a minimum. Call it mâ€².
Comment: Here again, we need this second base step.
We now claim that mâ€² = Min(B).
To show this, we must prove that (1) mâ€² âˆˆB and (2) that for all x âˆˆB, m â‰¤x.
To prove (1), note that we have {b, m} âŠ†B, and mâ€² âˆˆ{b, m}, so we must have
mâ€² âˆˆB as well.
To prove (2), assume that x âˆˆB. There are two possibilities, x = b or x â‰ b. If
x = b, then mâ€² â‰¤b because b âˆˆ{b, m}.
Assume instead that x â‰ b. Then x âˆˆBâˆ–{b} = A. But m is the minimum of
A, so m â‰¤x. But mâ€² = Min({b, m}) â‰¤m â‰¤x. So mâ€² = Min(B).
â—¾

13.2 Finite and Inï¬nite Sets
245
So, by the principle of mathematical induction if A âŠ†U, A â‰ âˆ…, and A is ï¬nite,
then A has a minimum. Again, the proof that A has a maximum is very similar,
and we leave it to the reader.
Î”
This proof should be rewritten.
Proof. Assume that U has a total order. Then that order is transitive and has
trichotomy. Assume A âŠ†U. Assume A â‰ âˆ…. Assume that A is ï¬nite. By the
aforementioned theorem, we can write |A| = n âˆˆâ„•.
We will now prove the result by induction on |A| = n, but we will only prove
that A has a minimum. The proof that A has a maximum is basically the same
argument. Proof by induction on n.
Step 1, the ï¬rst base case. We claim that if n = 1, then A has a minimum.
Proof of claim. Assume |A| = 1. Then let A = {a}. Now a âˆˆA and âˆ€x âˆˆA,
a â‰¤x. So a is the minimum of A.
â—¾
Step 2, the second base case. We claim that if n = 2, then A has a minimum.
Proof of claim. Assume |A| = 2. Then let A = {a, b} âŠ†U with a â‰ b. Since
a, b âˆˆU and the order on U has trichotomy, there are two possibilities:
a < b or b < a. In the case where a < b, a = Min(A). In the case where b < a,
b = Min(A). In either case, A has a minimum.
â—¾
Step 3, the induction step. We claim that
If for |A| = n0 â‰¥1, A has a minimum, then for |B| = n0 + 1, B has a minimum.
Proof of claim. Assume that if A is a set and |A| = n0, then A has a minimum.
Assume |B| = n0 + 1. Now B â‰ âˆ…. So we let b âˆˆB. Now let A = Bâˆ–{b}. Then
|A| = n0 + 1 âˆ’1 = n0.
By assumption, A has a minimum. Call it m. Then m âˆˆA = Bâˆ–{b} âŠ†B âŠ†U.
And if x âˆˆA = Bâˆ–{b}, then m â‰¤x. Consider {b, m}. This is a subset of U with
two elements. By step 2, {b, m} has a minimum. Call it mâ€².
We claim that mâ€² =Min(B).
To show this, we must prove that (1) mâ€² âˆˆB and (2) that for all x âˆˆB, m â‰¤x.
To see (1), note that we have mâ€² âˆˆ{b, m} âŠ†B.
We now show (2). Assume that x âˆˆB. There are two possibilities, x = b
or x â‰ b. In the ï¬rst, mâ€² â‰¤b because b âˆˆ{b, m}. For the second case,
assume x â‰ b; so x âˆˆBâˆ–{b} = A. So m â‰¤x. But mâ€² = Min({b, m}) â‰¤m â‰¤x.
So mâ€² =Min(B).
â—¾
Thus, by the principle of mathematical induction, if A âŠ†U, A â‰ âˆ…, and A is
ï¬nite, then A has a minimum. Again, the proof that A has a maximum is very
similar.
â—½

246
13 Final Basic Notions
13.3
Summary
When it comes to dealing with ï¬nite and inï¬nite sets, it is important to know
the mathematical deï¬nitions of these terms.
Deï¬nition 13.3.1.
Let A be a set. We say that A is ï¬nite when
if f âˆ¶A â†’A is an injective function with domain A, then f (x) is surjective.
Deï¬nition 13.3.2.
Let A be a set. We say that A is inï¬nite when
if there exists f âˆ¶A â†’A an injective function with domain A where f (x) is not
surjective.
In practice, when these terms come up in a proof about number systems,
it is much more important to know the properties that follow from these
deï¬nitions.
â€¢ An inï¬nite set cannot be a subset of a ï¬nite set.
â€¢ If there is a bijection between sets A and B, then either they are both ï¬nite
or they are both inï¬nite.
â€¢ The image of a ï¬nite set under a function will also be ï¬nite.
â€¢ The elements in a ï¬nite set can be counted, and the size of the set be given
as a natural number or 0.
â€¢ If A â‰ âˆ…is ï¬nite, then A can be written as
A = {a1, a2, a3 â€¦ an}.
(13.13)
â€¢ If U is a set with a total order, and A âŠ†U is nonempty and ï¬nite, then A has
a maximum and a minimum. In addition, we can write
A = {a1, a2, a3 â€¦ an}
(13.14)
with
a1 < a2 < a3 â€¦ < an.
(13.15)
â€¢ If A and B are ï¬nite sets, then A âˆªB, and A Ã— B is ï¬nite as will be the set of
all subsets of either set.
Once we are done with this chapter, we will always use these properties of
ï¬nite and inï¬nite sets in our proofs and not the deï¬nitions.
13.4
Problems
13.1
In elementary school, we considered subtraction as a binary operation
on â„•. By our deï¬nition of a binary operation, this is allowed? What about
it as a binary operation on â„¤?

13.4 Problems
247
(a) Is subtraction on â„¤associative?
(b) Is subtraction on â„¤commutative?
(c) Why do mathematicians rarely consider subtraction as a binary
operation in number systems?
13.2
Let A = {f âˆ¶â„â†’â„}. Deï¬ne the following binary operations on A.
( f âŠ•g)(x) = f (x) + g(x).
(13.16)
( f âŠ™g)(x) = f (x) â‹…g(x).
( f âŠšg)(x) = (g âˆ˜f )(x).
(a) Is âŠ•associative?
(b) Is âŠ•commutative?
(c) Does âŠ•have an identity?
(d) Do all elements in A have âŠ•-inverses?
(e) Is âŠ™associative?
(f) Is âŠ™commutative?
(g) Does âŠ™have an identity?
(h) Do all elements in A have âŠ™-inverses?
(i) Is âŠšassociative?
(j) Is âŠšcommutative?
(k) Does âŠšhave an identity?
(l) Do all elements in A have âŠš-inverses?
(m) Does âŠ™distribute over âŠ•?
(n) Does âŠšdistribute over âŠ•?
13.3
In multivariable calculus a binary operation, the cross product, was
deï¬ned on â„3. Thus, if (x, y, z) âˆˆâ„3 and (u, ð‘£, ð‘¤) âˆˆâ„3, then (x, y, z)Ã—
(u, ð‘£, ð‘¤) âˆˆâ„3.
(a) Is the cross product on â„3 associative? Prove your answer.
(b) Is the cross product on â„3 commutative? Prove your answer.
(c) Is there an identity for the cross product on â„3? Prove your answer.
(d) Do elements of â„3 have inverses for the cross product? Prove your
answer.
(e) Are you glad that there is Internet where you can look up mathemat-
ical deï¬nitions?
13.4
Prove the following using the deï¬nition of inï¬nite:
(a) The interval (0, 1) is inï¬nite.
(b) The intervals [0, 1], (0, 1], and [0, 1) are inï¬nite.
(c) The interval (a, b) âŠ†â„is inï¬nite.
(d) The intervals [a, b], (a, b], and [a, b) in â„are inï¬nite.

248
13 Final Basic Notions
13.5
Let S âŠ†â„. Then deï¬ne
îˆ°(S) = {x âˆˆâ„âˆ£âˆƒs, t âˆˆS s.t. s â‰ t and x = |s âˆ’t|}.
(13.17)
(a) Explain why îˆ°(S) is the set of all distances between elements of S.
(b) Why not use the set
îˆ°wrong(S) = {x âˆˆâ„âˆ£âˆƒs, t âˆˆS s.t. x = |s âˆ’t|}
(13.18)
for the set of all distances between elements of S?
(c) Prove that if S is ï¬nite, then îˆ°(S) is ï¬nite. (Do not use the deï¬nition
of ï¬nite!)
(d) True or false: if S is any ï¬nite subset of â„, then there is a nonzero
minimum distance between diï¬€erent elements of S.
13.6
Consider the functions f âˆ¶â„šâ†’â„šgiven by f (x) = x2 and g âˆ¶â„šâ†’â„š
given by g(x) = |x|x. One of these can be used in the deï¬nition to prove
that â„šis inï¬nite. Which one is it? Explain your answer.
13.5
Appendix
Theorem 13.5.1.
For n âˆˆâ„•, let Sn = {x âˆˆâ„•âˆ£x â‰¤n}. For all n âˆˆâ„•, if
f âˆ¶Sn â†’Sn is an injective function with domain Sn, then f (x) is surjective.
Proof. Proof by induction on n.
Step 1, the base step. We claim that if n = 1, then if f âˆ¶Sn â†’Sn is an injective
function with domain Sn, then f (x) is surjective.
Proof of claim. Assume that f âˆ¶S1 â†’S1 is an injective function with domain
S1. So f âˆ¶{1} â†’{1} has domain {1}. Thus, f (1) âˆˆ{1}. This can only mean that
f (1) = 1. So
Range( f ) = f ({1}) = {f (1)} = {1} = Codomain( f ).
(13.19)
So f (x) is surjective.
â—¾
Step 2, the inductive step. We claim that
if for all f âˆ¶Sn0 â†’Sn0 with domain Sn0,
if f (x) is injective, then f (x) is surjective,
then for all g âˆ¶Sn0+1 â†’Sn0+1 with domain Sn0+1,
if g(x) is injective, then g(x) is surjective.
Proof of claim. Assume that for all f âˆ¶Sn0 â†’Sn0 with domain Sn0, if f (x) is
injective, then f (x) is surjective.

13.5 Appendix
249
Assume that g âˆ¶Sn0+1 â†’Sn0+1 has domain Sn0+1.
Assume that g(x) is injective.
Now n0 + 1 âˆˆSn0+1 = Domain(g). So g(n0 + 1) âˆˆSn0+1. There are two possi-
bilities: g(n0 + 1) = n0 + 1 or g(n0 + 1) âˆˆSn0.
Case 1: Assume g(n0 + 1) = n0 + 1.
We claim that in this case g(Sn0) âŠ†Sn0.
To see this, assume BWOC n0 + 1 âˆˆg(Sn0). Then âˆƒx âˆˆSn0 s.t. g(x) = n0 + 1.
Then g(x) = n0 + 1 = g(n0 + 1). Since g(x) is injective, this says that n0 + 1 =
x âˆˆSn0. That is a contradiction. Thus, g(Sn0) âŠ†Sn0.
Deï¬ne f âˆ¶Sn0 â†’Sn0 by
f (x) = g(x).
(13.20)
Note that the claim shows that we have a valid function because the stated
codomain is correct. Note also that Domain( f ) = Sn0, and f (x) is injective,
because g(x) is.
By our assumption, f (x) is surjective. So
f (Sn0) = Range( f ) = Codomain( f ) = Sn0.
So
Range(g) = g(Sn0+1)
(13.21)
= g(Sn0 âˆª{n0 + 1})
= g(Sn0) âˆªg({n0 + 1})
= f (Sn0) âˆª{g(n0 + 1)}
= Sn0 âˆª{n0 + 1}
= Sn0+1
= Codomain( f ).
So g(x) is surjective in this case.
Case 2: Assume g(n0 + 1) âˆˆSn0.
Let g(n0 + 1) = m. Deï¬ne h âˆ¶Sn0+1 â†’Sn0+1 by
h(x) =
âŽ§
âŽª
âŽ¨
âŽªâŽ©
m
if x = n0 + 1
n0 + 1
if x = m
x
if x âˆ‰{n0 + 1, m}.
(13.22)
Now (h âˆ˜h)(x) = iSn0+1. So h(x) has an inverse. We know that h(x) is bijective.
Consider (h âˆ˜g) âˆ¶Sn0+1 â†’Sn0+1. The composition of injections is an injection,
and
(h âˆ˜g)(n0 + 1) = h(g(n0 + 1)) = h(m) = (n0 + 1).
(13.23)

250
13 Final Basic Notions
We now have an injective function (h âˆ˜g) âˆ¶Sn0+1 â†’Sn0+1 with the full domain,
but with the extra property that (h âˆ˜g)(n0 + 1) = (n0 + 1). This is exactly the
type of function covered in case one. Therefore, we know that (h âˆ˜g) is surjec-
tive. But the composition of surjections is a surjection. So h âˆ˜(h âˆ˜g) is a surjec-
tion. But
h âˆ˜(h âˆ˜g) = (h âˆ˜h) âˆ˜g = i âˆ˜g = g.
(13.24)
Thus, g(x) is a surjection in this case as well.
â—¾
So we have proved by induction that for all n âˆˆâ„•, if f âˆ¶Sn â†’Sn is an injective
function with domain Sn, then f (x) is surjective.
â—½
Theorem 13.5.2.
Let A and B be sets with ð›½âˆ¶A â†’B a bijection. If A is ï¬nite,
then B is ï¬nite.
Proof. Assume that ð›½âˆ¶A â†’B is a bijection. Assume that A is ï¬nite. So if f âˆ¶
A â†’A is an injective function with domain A, then f (x) is surjective.
Assume that g âˆ¶B â†’B has domain B. Assume that g(x) is an injection.
Consider ð›½âˆ’1 âˆ˜g âˆ˜ð›½âˆ¶A â†’A. This has domain A, and because it is the com-
position of injections, it is an injection. Because A is ï¬nite, (ð›½âˆ’1 âˆ˜g âˆ˜ð›½)(x) is a
surjection. But the composition of surjections is a surjection; so
ð›½âˆ˜(ð›½âˆ’1 âˆ˜g âˆ˜ð›½) âˆ˜ð›½âˆ’1
(13.25)
is a surjection. But
ð›½âˆ˜(ð›½âˆ’1 âˆ˜g âˆ˜ð›½) âˆ˜ð›½âˆ’1 = g.
(13.26)
We have proved that, if g âˆ¶B â†’B is an injective function with domain B, then
g(x) is surjective. Thus, we have proved that B is ï¬nite.
â—½
Corollary 13.5.3.
Let A and B be sets with ð›½âˆ¶A â†’B a bijection. Then A is
ï¬nite if and only if B is ï¬nite.
Corollary 13.5.4.
Let A and B be sets with ð›½âˆ¶A â†’B a bijection. Then A is
inï¬nite if and only if B is inï¬nite.
Proof. Assume that A and B are sets with ð›½âˆ¶A â†’B a bijection. However, since
ð›½âˆ¶A â†’B is a bijection, so is ð›½âˆ’1 âˆ¶B â†’A a bijection. So the theorem is also its
own converse: If B is ï¬nite, then A is ï¬nite. Together this says that A is ï¬nite, if
and only if B is ï¬nite. The contrapositive of that is: B is inï¬nite if and only if A
is inï¬nite.
â—½
Theorem 13.5.5.
Let A and B be sets with A âŠ†B. If B is ï¬nite, then A is ï¬nite.

13.5 Appendix
251
Proof. Assume A âŠ†B. Assume that B is ï¬nite. So if f âˆ¶B â†’B is an injective
function with domain B, then f (x) is surjective.
Assume that g âˆ¶A â†’A is a function with domain A.
Assume that g(x) is injective.
Deï¬ne f âˆ¶B â†’B by
f (x) =
{
g(x)
if x âˆˆA
x
if x âˆˆBâˆ–A.
(13.27)
Then Domain(f ) = A âˆª(Bâˆ–A) = A. In addition, since A âˆ©(Bâˆ–A) = âˆ…, we can
easily prove that f (x) is injective.
Since B is ï¬nite, we know that f (x) is surjective. So f (B) = B.
Now
B = f (B)
(13.28)
= f (A âˆª(Bâˆ–A))
= f (A) âˆªf (Bâˆ–A)
= g(A) âˆª(Bâˆ–A).
Then we can intersect both sides of B = g(A) âˆª(Bâˆ–A) with A.
A âˆ©B = A âˆ©(g(A) âˆª(Bâˆ–A)).
(13.29)
So
A âˆ©B = A âˆ©(g(A) âˆª(Bâˆ–A))
(13.30)
A = (A âˆ©g(A)) âˆª(A âˆ©(Bâˆ–A))
= (A âˆ©g(A)) âˆªâˆ…
= A âˆ©g(A).
But g(A) âŠ†A, so we have g(A) = A. This proves that g(x) is surjective.
Since if g âˆ¶A â†’A is an injective function with domain A, then g(x) is surjec-
tive; so we have proved that A is ï¬nite.
â—½
Corollary 13.5.6.
Let A and B be sets with A âŠ†B. If A is inï¬nite, then B is
inï¬nite.
Theorem 13.5.7.
Let A and B be sets with j âˆ¶A â†’B an injection with domain
A. If B is ï¬nite, then A is ï¬nite.
Proof. Assume that j âˆ¶A â†’B has domain A. Assume that j(x) is an injection.
Assume that B is ï¬nite. Deï¬ne jâ€² âˆ¶A â†’j(A) by jâ€²(x) = x. By changing the
codomain we have created a bijection jâ€² âˆ¶A â†’j(A). But j(A) âŠ†B a ï¬nite set.
So j(A) is also ï¬nite. Using the bijection jâ€²(x), we know that A is ï¬nite.
â—½

252
13 Final Basic Notions
Corollary 13.5.8.
Let A and B be sets with j âˆ¶A â†’B an injection with
domain A. If A is inï¬nite, then B is inï¬nite.
Theorem 13.5.9.
Let A and B be sets with j âˆ¶A â†’B a surjection with domain
A. If B is ï¬nite, then A is ï¬nite.
Proof. Assume that j âˆ¶A â†’B is a surjection with domain A. Assume that A
is ï¬nite. Since j(x) is surjective, for all b0 âˆˆB, âˆƒa0 âˆˆA s.t. j(a0) = b0. (There
may be more than one, but any one will suï¬ƒce.) Thus, for each b âˆˆB, we have
assigned exactly one a0 âˆˆA so that j(ai) = bi. We can deï¬ne (at least one) func-
tion k âˆ¶B â†’A by k(b0) = a0.
Claim. We claim that k âˆ¶B â†’A is injective.
Proof of claim. Assume k(b1) = k(b2) = a1. Then k(b1) = a1 and k(b2) = a1.
But by our deï¬nition of j(b), this means that j(a1) = b1 and j(a1) = b2.
So b1 = b2.
â—¾
Since we have a injection k âˆ¶B â†’A where the codomain A is ï¬nite, by the
previous theorem, the domain B is ï¬nite.
â—½
The proof of the next theorem is the most complicated in this group. It is,
however, the best indication we have that our deï¬nition of ï¬nite is correct.
Theorem 13.5.10.
Let A be a nonempty ï¬nite set. Then there exists a unique
n âˆˆâ„•so that there is a bijection b âˆ¶Sn â†’A where Sn = {x âˆˆâ„•âˆ£x â‰¤n}.
The statement is: If A is a nonempty ï¬nite set, then âˆƒn âˆˆâ„•such that there
exists some b âˆ¶Sn â†’A, which is a bijection.
Proof. We will prove the contrapositive:
If A is a nonempty set so that, âˆ€n âˆˆâ„•, no function b âˆ¶Sn â†’A is a bijection,
then A is inï¬nite.
Assume that A is a nonempty set.
Assume that for all n âˆˆâ„•, no function b âˆ¶Sn â†’A is a bijection.
Claim. For all n âˆˆâ„•, there exists a function fn âˆ¶Sn â†’A such that fn(x) has
domain Sn, and
â€¢ fn(x) is injective,
â€¢ when n â‰¥2, âˆ€x âˆˆSn , fn(x) = fnâˆ’1(x),
â€¢ and when n â‰¥2, fn(n) âˆ‰fnâˆ’1(Snâˆ’1).

13.5 Appendix
253
Proof of claim. We prove the claim by induction: (We need two base cases
though.)
Statement of Step 1 of Claim: If n = 1, âˆƒfn âˆ¶Sn â†’A s.t fn(x) has domain Sn, and
fn(x) is injective.
Proof of Step 1 of Claim. Since A â‰ âˆ…, let a1 âˆˆA. Deï¬ne f1 âˆ¶{1} â†’A by f1(1) =
a1. Then f1(x) has domain S1, and f1(x) is injective. The other claims in the con-
clusion do not apply to this situation. â—Š
Statement of Step 2 of Claim: For n = 2, âˆƒf2 âˆ¶S2 â†’A s.t
â€¢ f2(x) has domain S2,
â€¢ and f2(x) is injective,
â€¢ and âˆ€x âˆˆS1, f2(x) = f1(x),
â€¢ and f2(n) âˆ‰f1(S1).
Proof of Step 2 of Claim. Starting with f1(x) from step 1, we have f1 âˆ¶S1 â†’A
domain S1, and where f1(x) is injective. But by our overall assumption, no bijec-
tions such as this exist. So f1(x) cannot be bijective. So f1(x) is not surjective.
Then
f1(S1) âŠ†A while f1(S1) â‰ A.
(13.31)
So âˆƒa2 âˆˆAâˆ–f1(S1). Deï¬ne f2 âˆ¶S2 â†’A by
f2(x) =
{
f1(x)
if x âˆˆS1 = {1}
a2
if x = 2.
(13.32)
Then f2(x) has domain S2, and f2(x) is injective. In addition, if x âˆˆS1 = {1}, then
f2(x) = f1(x). And f2(2) âˆ‰f1(S1). â—Š
Statement of Step 3 of Claim: (This one is long!) We must prove that
âŽ¡
âŽ¢
âŽ¢
âŽ¢
âŽ¢
âŽ¢
âŽ¢
âŽ¢
âŽ¢
âŽ¢
âŽ¢
âŽ¢
âŽ¢âŽ£
If
for n = n0,
âˆƒfn0 âˆ¶Sn0 â†’A
such that
fn0(x) has domain Sn0
and
n0(x) is injective
and
âˆ€x âˆˆSn0âˆ’1, fn0(x) = fn0âˆ’1(x)
and
fn0(n0) âˆ‰fn0âˆ’1(Sn0âˆ’1)
then for n = n0 + 1
âˆƒfn0+1 âˆ¶Sn0+1 â†’A
such that
fn0+1(x) has domain Sn0+1
and
fn0+1(x) is injective
and
âˆ€x âˆˆSn0, fn0+1(x) = fn0(x)
and
fn0(n0) âˆ‰fn0âˆ’1(Sn0âˆ’1).
âŽ¤
âŽ¥
âŽ¥
âŽ¥
âŽ¥
âŽ¥
âŽ¥
âŽ¥
âŽ¥
âŽ¥
âŽ¥
âŽ¥
âŽ¥âŽ¦

254
13 Final Basic Notions
Proof of Step 3 of Claim. Assume that âˆƒfn0 âˆ¶Sn0 â†’A such that
âŽ¡
âŽ¢
âŽ¢
âŽ¢âŽ£
fn0(x) has domain Sn0,
and
fn0(x) is injective
and âˆ€x âˆˆSn0âˆ’1, fn0(x) = fn0âˆ’1(x)
and
fn0(n0) âˆ‰fn0âˆ’1(Sn0âˆ’1).
âŽ¤
âŽ¥
âŽ¥
âŽ¥âŽ¦
By our overall assumption, fn0(x) cannot be a bijection. So âˆƒan0+1 âˆˆ
Aâˆ–( fn0(Sn0)).
Deï¬ne fn0+1 âˆ¶Sn0+1 â†’A by
fn0+1(x) =
{
fn0(x)
if x âˆˆSn0
an0+1
if x = n0 + 1.
(13.33)
Then fn0+1(x) has domain Sn0+1. In addition, fn0+1(x) is injective because fn0(x) is
injective and
fn0+1(n0 + 1) = an0+1 âˆˆAâˆ–( fn0(Sn0)).
(13.34)
In addition, if x âˆˆSn0, fn0+1(x) = fn0(x).
Finally, fn0+1(n0 + 1) âˆ‰fn0(Sn0). â—Š
This completes the proof of our claim by induction. Thus, we have proved that
for all n âˆˆâ„•, there exists a function fn âˆ¶Sn â†’A such that fn(x) has domain Sn
and
â€¢ fn(x) is injective,
â€¢ when n â‰¥2, âˆ€x âˆˆSn , fn(x) = fnâˆ’1(x),
â€¢ and when n â‰¥2, fn(n) âˆ‰fnâˆ’1(Snâˆ’1).
â—¾
Now consider the functions fn âˆ¶Sn â†’A as described in their deï¬nitions:
(fn, A) where fn âŠ†Sn Ã— A. Notice that fn âŠ†Sn Ã— A âŠ†â„•Ã— A.
Let
fâˆž=
â‹ƒ
nâˆˆâ„•
fn
(13.35)
as sets. Then fâˆžâŠ†â„•Ã— A. We will prove that the pair ( fâˆž, A) ï¬ts our deï¬nition
of a function by proving the necessary conditions.
The vertical line test. We claim that if (n, a) âˆˆfâˆžand (n, aâ€²) âˆˆfâˆž, then a = aâ€².
Proof of claim. Assume (n, a) âˆˆfâˆžand (n, aâ€²) âˆˆfâˆž. Then (n, a) âˆˆfn and
(n, aâ€²) âˆˆfn. Since ( fn, A) is a function, a = aâ€².
â—¾
We also make a few claims about fâˆž(x).

13.5 Appendix
255
Claim. Domain(fâˆž) = â„•.
Proof of claim. Assume n âˆˆâ„•. Then n âˆˆSn. So fn(n) = a âˆˆA. That is, (n, a) âˆˆ
fn âŠ†fâˆž. So fâˆž(n) âˆˆA.
â—¾
Thus, we have a function fâˆžâˆ¶â„•â†’A.
Claim. We claim that fâˆž(x) is injective.
Proof of claim. Assume fâˆž(n) = fâˆž(nâ€²). We may assume without loss of gener-
ality that nâ€² â‰¤n. Now fn âˆ¶Sn â†’A and fn(x) has domain Sn, and fn(x) is injec-
tive, and âˆ€x âˆˆSn with n â‰¥2, fn(x) = fnâˆ’1(x), and fn(n) âˆ‰fnâˆ’1(Snâˆ’1). So fâˆž(nâ€²) âˆ‰
fnâˆ’1(Snâˆ’1). But since fâˆž(n) = fâˆž(nâ€²), we must have nâ€² = n.
â—¾
Now we have constructed an injective function fâˆžâˆ¶â„•â†’A. We know that â„•
is inï¬nite. So by an earlier result, A must be inï¬nite.
â—½
Theorem 13.5.11.
Let A and B be ï¬nite sets, then A âˆªB is ï¬nite.
Proof. Assume that A and B are ï¬nite sets. By the aforementioned theorem,
there is an injection j âˆ¶Sn â†’A and a bijection k âˆ¶Sm â†’B for integers n and
m. We can deï¬ne i âˆ¶Sn+m â†’A âˆªB by
i(x) =
{
j(x)
if x â‰¤n
k(x âˆ’n)
if x > n.
(13.36)
It is easy to see that i(x) is a surjection (but perhaps not an injection: ). So by a
previous result, A âˆªB is ï¬nite.
â—½
We have also proved the following corollary.
Corollary 13.5.12.
Let S and T be ï¬nite sets, then |S âˆªT| â‰¤|S| + |T|.
Theorem 13.5.13.
Let A be a set. If A is ï¬nite, then îˆ¼(A) is ï¬nite.
Proof. Assume that A is a ï¬nite. We will prove this by induction on |A| = n.
Step 1. We claim that if n = 0, then îˆ¼(A) is ï¬nite.
Proof of claim. Assume n = 0. Then A = âˆ…, and îˆ¼(A) = {âˆ…}. So îˆ¼(A) has one
element, and so it is ï¬nite.
â—¾
Step 2. We claim that

256
13 Final Basic Notions
If, for all A with |A| = n0, îˆ¼(A) is ï¬nite, then, for all Aâ€² with |Aâ€²| = n0 + 1,
îˆ¼(Aâ€²) is ï¬nite.
Proof of claim. Assume that for all sets A with |A| = n0, îˆ¼(A) is ï¬nite. Assume
that Aâ€² is a set with |Aâ€²| = n0 + 1. Now Aâ€² â‰ âˆ…, so let a0 âˆˆAâ€². We can write
îˆ¼(Aâ€²) = {S âˆ£S âŠ†Aâ€²}
(13.37)
= {S âˆ£S âŠ†Aâ€²and a0 âˆ‰S} âˆª{S âˆ£S âŠ†Aâ€²and a0 âˆˆS}.
If we let A = Aâ€² âˆ–{a0}, then
{S âˆ£S âŠ†Aâ€²and a0 âˆ‰S} = îˆ¼(A).
(13.38)
In addition,
{S âˆ£S âŠ†Aâ€²and a0 âˆˆS} = {Sâ€² âˆª{a0} âˆ£Sâ€² âˆˆîˆ¼(A)}.
(13.39)
By the induction assumption, these are both ï¬nite sets. Since the union of ï¬nite
sets is ï¬nite, we have proved that îˆ¼(Aâ€²) is ï¬nite.
â—¾
So it follows by induction that A is a ï¬nite set, then îˆ¼(A) is ï¬nite.
â—½
Next we need a seemingly unrelated lemma.
Lemma 13.5.14.
Let n, m, p, q âˆˆâ„•. If
2n â‹…3m = 2p â‹…3q, then n = p and
m = q.
Proof. Assume n, m, p, q âˆˆâ„•and 2n â‹…3m = 2p â‹…3q. By trichotomy in â„•, exactly
one of the following is true: n < p, p < n, or p = n. Case 1: Assume n < p. Then
âˆƒk âˆˆâ„•s.t. n + k = p. Then
2n â‹…3m = 2p â‹…3q = 2n+k â‹…3m = 2n â‹…2k â‹…3m.
(13.40)
So using the cancellation property,
3m = 2k â‹…3m.
(13.41)
But 3m is odd and since k âˆˆâ„•, 2k â‹…3m. This is a contradiction. This case cannot
hold. Case 2, p < n, can be eliminated in a similar way. The only possibility is
p = n.
But then
2n â‹…3m = 2p â‹…3q = 2n â‹…3q.
(13.42)
So 3m = 3q. By trichotomy, m < q, q < m, or m = q. Again cancellation in â„•
rules out the ï¬rst two possibilities. So we have both n = p and m = q.
â—½
Now we state and prove the result we really want.
Theorem 13.5.15.
Let A and B be ï¬nite sets. Then A Ã— B is a ï¬nite set.

13.6 Epilogue
257
Proof. Assume that A and B are ï¬nite sets. Then there exists n âˆˆâ„•with a bijec-
tion ð›¼âˆ¶A â†’Sn = {1, 2 â€¦ n} and âˆƒm âˆˆâ„•with a bijection ð›½âˆ¶B â†’Sm. Deï¬ne
ð›¾âˆ¶A Ã— B â†’Sn Ã— Sm by ð›¾(s, t) = (ð›¼(s), ð›½(t)).
Claim. We claim that ð›¾(x) is a bijection.
Proof of claim. Since Domain(ð›¼) = A and Domain(ð›½) = B, then Domain(ð›¾) =
A Ã— B.
Assume ð›¾(s, t) = ð›¾(sâ€², tâ€²). Then (ð›¼(s), ð›½(t)) = (ð›¼(sâ€²), ð›½(tâ€²)). So ð›¼(s) = ð›¼(sâ€²), and,
ð›½(t) = ð›½(tâ€²). Since ð›¼and ð›½are injective, s = sâ€² and t = tâ€². So (s, t) = (sâ€², tâ€²). This
proves that ð›¾is injective.
Assume (p, q) âˆˆSn Ã— Sm. Then p âˆˆSn and q âˆˆSm. But ð›¼and ð›½are surjec-
tive; so âˆƒa âˆˆA s.t. ð›¼(a) = p and âˆƒb âˆˆB s.t. ð›½(b) = q. So (a, b) âˆˆA Ã— B so that
ð›¾(a, b) = (ð›¼(a), ð›½(b)) = (p, q). So this proves ð›¾is surjective.
â—¾
Because of this claim and our theorems about bijective sets, if we prove that
Sn Ã— Sm is ï¬nite, it will prove that A Ã— B is ï¬nite.
Note that if (p, q) âˆˆSn Ã— Sm, then 2p â‹…3q â‰¤3n+m. This means that we can
deï¬ne h âˆ¶Sn Ã— Sm â†’S3n+m by
h(p, q) = 2p â‹…3q.
(13.43)
This has domain Sn Ã— Sm, and by the lemma, it is an injection. We also know
that S3n+m is a ï¬nite set by our ï¬rst theorem. So by another previous theorem,
Sn Ã— Sm is ï¬nite.
â—½
13.6
Epilogue
Two of the proofs given in the appendix hide a bit of logical basics we will not
discuss except just a bit here. It is hard to miss the complexity in the proof of
the theorem about counting ï¬nite sets:
Theorem 13.6.1.
Let A be a nonempty ï¬nite set. Then there exists a unique
n âˆˆâ„•so that there is a bijection b âˆ¶Sn â†’A where Sn = {x âˆˆâ„•âˆ£x â‰¤n}.
It says that our deï¬nition of ï¬nite requires the existence of a natural num-
ber and at least one bijection b âˆ¶Sn â†’A. The proof, however, does not give
any instruction on how ï¬nd the number or the bijection from that deï¬nition.
The proof takes full advantage of the consequences of our decision to require
all logical statements be either true or false and not both. We use tricks of
a two-valued logical system to prove that something exists, not by ï¬nding it,
but rather by logical trickery. The proof does not construct the number or the
bijection; it proves that they exist by ruling out the only other possibility. The
assumption â€œA is a non-empty set so that, âˆ€n âˆˆâ„•, no function b âˆ¶Sn â†’A is a

258
13 Final Basic Notions
bijectionâ€ covers so many functions that is only of use through careful logic. For
a large A, it cannot be used to form an actual construction in a ï¬nite amount of
steps. Since the contrapositive requires A to be inï¬nite, this could be a problem.
There are branches of Mathematics that study the algorithms for solving
collections of similar problems. These areas of Mathematics ask questions
such as:
Is there a way to test an equation for rational solutions that produces an
answer, yes or no, for any equation in a ï¬nite amount of time?
Or they may ask a more speciï¬c question:
Is there way to factor natural numbers so that the number of bit opera-
tions that digital computer must accomplish is not an exponential func-
tion of the size of the number to be factored?
In areas such as these, proving that something exists or is possible without
giving an actual construction is not as valuable as it is in most of the rest of
Mathematics. There are also mathematicians, logicians, and philosophers who
wonder if mathematics can be done without resort to any type of nonconstruc-
tive proof. As a result, there are parts of Mathematics where the two-valued
logic system is put aside in favor of logical system that stresses algorithmic
construction more forcefully. We are interested in learning the techniques of
standard Mathematics; so we consider the proof by contradiction as always
valid.
The other bit of logical foundations appears in the proof of the theorem:
Theorem 13.6.2.
Let A and B be sets with j âˆ¶A â†’B a surjection with domain
A. If B is ï¬nite, then A is ï¬nite.
In this proof, we took a surjective function j âˆ¶A â†’B with domain A
and constructed a function k âˆ¶B â†’A so that (j âˆ˜k) âˆ¶B â†’B would give
j âˆ˜k = iB. The function k(x) would only act as an inverse to j(x) on the
right as this; so we are not claiming or requiring that f (x) have a full
(two-sided) inverse. The logical principle behind this construction is known
as â€œThe Axiom of Choice.â€ It is a part of standard Mathematics based on
two-valued logic. However, particularly when applied to inï¬nite sets, it is often
excluded from those branches of Mathematics where ï¬nite constructions are
required.
Our goal is to master the standard two-valued logical system that is used in
most areas of Mathematics. Those areas that require a diï¬€erent approach are
clearly identiï¬ed as distinct. It is not that the techniques of standard two-valued
logic are completely lost, but rather they are adapted to ï¬t the problems at hand.

13.6 Epilogue
259
We might ask, what approach to proving existence is best? The answer mostly
depends on who answers it. As a rule, mathematicians care mostly about the
mathematical consequences of their work; logicians care about the validity of
the logic that goes into Mathematics, but philosophers care most about the
hardest question: what is real truth?

261
Part III
A Second Pass at Deï¬ning â„

263
14
â„•, â„¤, and â„š
14.0.1
Basic properties of the natural numbers
In the beginning of this study, we saw how the natural numbers and their
properties can be developed from four simple observations about how they
must work. But since then, we have developed a great deal of mathematical
terminology and algebraic technique. We can take greater advantage of this
background work by beginning with a deï¬nition of the natural numbers based
on their algebraic properties.
Deï¬nition 14.0.1.
The natural numbers, â„•, form a set with the following
properties:
1. â„•â‰ âˆ….
2. There is a total order on â„•.
3. â„•is a well-ordered set. (Thus, â„•itself has a minimum; call it 1.)
4. There is a binary operation on â„•called addition written as n + m.
5. Addition is associative.
6. Addition is commutative.
7. If n, m âˆˆâ„•, then n < n + m.
8. If n âˆˆâ„•and n â‰ 1, then there exists m âˆˆâ„•so that m + 1 = n.
9. If n, m âˆˆâ„•and n < m, then âˆ€k âˆˆâ„•, n + k < m + k.
10. There is a binary operation on â„•called multiplication written as
n â‹…m = nm.
11. Multiplication is associative.
12. Multiplication is commutative.
13. 1 is a multiplicative identity for â„•.
14. If k, n, m âˆˆâ„•with n < m, then n â‹…k < m â‹…k.
15. Multiplication distributes over addition.
16. If n, m âˆˆâ„•, then n < n + m.
17. If n, m âˆˆâ„•and n â‰¤m â‰¤n + 1, then either m = n or m = n + 1.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

264
14 â„•, â„¤, and â„š
Our general mathematical deï¬nitions have allowed us to make this list more
compact than when we ï¬rst started. This is because the statements we wrote out
completely the last time are hidden in the deï¬nitions of the terms we now can
use. In addition, a careful look will show that some of the basic properties listed
earlier are missing in this deï¬nition. We are missing the general subtraction
property, but we can at least subtract 1. We are also missing the cancellation
properties. This time, we are trying to be more careful about the minimum
properties we need to nail the natural numbers down to one collection. The
missing properties are now presented as theorems that can be proved using
this trimmed-down list.
First, we have four cancellation results that follow from earlier using our
logical tricks.
Theorem 14.0.2.
If k, n, m âˆˆâ„•with n + k = m + k, then n = m.
Proof. We will prove the contrapositive: if n â‰ m, then n + k â‰ m + k. Assume
n â‰ m. By trichotomy, there are two cases n < m or m < n. But addition
respects order; so either n + k < m + k or m + k < n + k. Again by trichotomy,
n + k â‰ m + k.
â—½
Theorem 14.0.3.
If k, n, m âˆˆâ„•with n + k < m + k, then n < m.
Proof. We will prove the contrapositive: if n â‰¥m, then n + k â‰¥m + k. The two
possibilities of â€œgreater than or equal toâ€ follow from the fact that addition is
well deï¬ned and that addition respects order.
â—½
Theorem 14.0.4.
If k, n, m âˆˆâ„•with n â‹…k = m â‹…k, then n = m.
Proof. We will prove the contrapositive: if n â‰ m, then n â‹…k â‰ m â‹…k. Assume
n â‰ m. By trichotomy, there are two cases n < m or m < n. But multiplica-
tion respects order, so either n â‹…k < m â‹…k or m â‹…k < n â‹…k. Again by trichotomy,
nk â‰ mk.
â—½
Theorem 14.0.5.
If k, n, m âˆˆâ„•with n â‹…k < m â‹…k, then n < m.
Proof. We will prove the contrapositive: if n â‰¥m, then nk â‰¥mk. The two possi-
bilities follow from the fact that addition is well deï¬ned and that multiplication
respects order.
â—½
Next we have a conditional subtraction theorem.
Theorem 14.0.6.
If n, m âˆˆâ„•with n < m, then âˆƒk âˆˆâ„•such that m = n + k.

â„•, â„¤, and â„š
265
Proof draft. Assume n, m âˆˆâ„•and assume n < m.
Comment: We now must prove something exists, rarely our favorite thing to
prove. We either need to ï¬nd one by solving a problem or using magic to cre-
ate one out of thin air. We only have 14 things to work with, but one of them is
well ordering. That is a way to make things appear. We need to set up a set for
which the number we want might be the minimum.
Deï¬ne
A = {p âˆˆâ„•âˆ£n + p â‰¥m}.
(14.1)
Comment: Good, but before we declare that it has a minimum, we need to be
sure that it is not empty. That means we are proving a â€œthere existsâ€ statement,
and that requires solving a problem. We need to ï¬nd something in the set, but
we must build it from the objects we have assumed that we have. We might just
take a few guesses until we ï¬nd something that works.
Now the part is greater than the whole, so n + m > m, so we have m âˆˆA.
So A â‰ âˆ…. We have a nonempty subset of a set that is well ordered. So A has a
minimum. Call it k. Then k âˆˆA and if p âˆˆA, then k â‰¤p.
Comment: The contrapositive of this says, if p < k, then p âˆ‰A. We expect to ï¬nd
something smaller than k to put this statement to use.
Since 1 = Min(â„•), there are two possibilities k = 1 or k > 1.
Case 1. Assume k = 1.
Then since k âˆˆA = {p âˆˆâ„•âˆ£n + p â‰¥m}, we know that n + 1 â‰¥m. But we
assumed at the beginning that n < m. By transitivity, n < m â‰¤n + 1. So using
the last property in the list, discreteness, we have m = n + 1, and k = 1 is the
required natural number.
Case 2: Assume k â‰ 1.
Then âˆƒs âˆˆâ„•so that s + 1 = k. Then s < k = Min(A), so s âˆ‰A = {p âˆˆâ„•âˆ£n +
p â‰¥m}. Then n + s < m. But k âˆˆA, so n + k â‰¥m. So n + s + 1 â‰¥m. Then n +
s < m â‰¤n + s + 1. So m = n + s + 1 = n + k.
Î”
Well now we should hide our thought process and rewrite the proof.
Proof. Assume n, m âˆˆâ„•and assume n < m. Deï¬ne
A = {p âˆˆâ„•âˆ£n + p â‰¥m}.
(14.2)
Now n + m > m; so we have m âˆˆA. So A â‰ âˆ…. We have a nonempty subset
of a set that is well ordered. So A has a minimum. Call it k. Then k âˆˆA and if
p âˆˆA, then k â‰¤p.

266
14 â„•, â„¤, and â„š
There are two possibilities k = 1 or k > 1.
Case 1. Assume k = 1.
Then since k âˆˆA = {p âˆˆâ„•âˆ£n + p â‰¥m}, we know that m â‰¤n + 1. But we
assumed at the beginning that n < m. By transitivity, n < m â‰¤n + 1. So using
the last property in the list, we have m = n + 1, and k = 1 is the required natural
number.
Case 2: Assume k â‰ 1.
Then âˆƒs âˆˆâ„•so that s + 1 = k. Then s < k =Min(A), so
s âˆ‰A = {p âˆˆâ„•âˆ£n + p â‰¥m}.
(14.3)
Then n + s < m. But k âˆˆA, so n + k â‰¥m. So n + s + 1 â‰¥m. Then n + s < m â‰¤
n + s + 1. So m = n + s + 1 = n + k.
â—½
14.0.2
Theorems about the natural numbers
There are plenty of interesting things we can prove about the natural numbers,
but we only need one: the theorem of induction.
Theorem 14.0.7
(The theorem of induction). Let P(n) be a mathematical
statement that is deï¬ned on â„•. Let k0 âˆˆâ„•.
If
1. for n = k0, P(n) is true; and
2. if for n = n0, P(n) is true, then for n = n0 + 1, P(n) is true,
then for all n âˆˆâ„•with n â‰¥k0, P(n) is true.
Proof. We will use a minimum counterexample proof.
Assume that P(k0) is true. Assume that P(n0) is true implies that P(n0 + 1)
is true.
Let
A = {k âˆˆâ„•âˆ£k â‰¥k0 and P(k) is false}.
(14.4)
There are two possibilities: A = âˆ…or A â‰ âˆ….
Case 1: Assume BWOC A â‰ âˆ….
Since â„•is well ordered, A has a minimum. Call it m. Then m âˆˆA.
In addition, if k âˆˆA, then m â‰¤k. The contrapositive of this says, if k < m,
then k âˆ‰A.
First
m âˆˆA = {k âˆˆâ„•âˆ£k â‰¥k0 and P(k) is false}.
(14.5)
So P(m) is false. But P(k0) is true. So m â‰ k0. But m âˆˆA also tells us that m â‰¥k0.
By trichotomy, we have 1 â‰¤k0 < m. So m âˆ’1 âˆˆâ„•. In turn, we have (m âˆ’1) +
1 > k0. By the last basic property of â„•, this says m âˆ’1 â‰¥k0.

14.1 The Integers
267
But m âˆ’1 < m =Min(A). So m âˆ’1 âˆ‰A. Since
A = {k âˆˆâ„•âˆ£k â‰¥m0 and P(k) is false},
(14.6)
m âˆ’1 is a natural number and greater than or equal to k0; so the problem must
be that P(m âˆ’1) is not false.
But we can now use our induction hypothesis. Since P(m âˆ’1) is true, we
know that P(m âˆ’1 + 1) is true. But m âˆˆA, so we also have P(m) is false and
true at the same time. We have a contradiction. We have made an assumption
that cannot be true. The set A cannot be nonempty.
So we must have case 2:
A = {k âˆˆâ„•âˆ£k â‰¥k0 and P(k) is false} = âˆ….
(14.7)
Assume n âˆˆâ„•and n â‰¥k0. Certainly, n âˆ‰A, so P(n) must be true.
So only case 2 is possible, and because of that: âˆ€n âˆˆâ„•and n â‰¥k0, P(n)
is true.
â—½
14.1
The integers
14.1.1
An algebraic deï¬nition
This time the description is exactly as it was earlier but with updated
terminology.
Deï¬nition 14.1.1.
The integers form a set â„¤with the following properties:
1. There is a total order on â„¤.
2. If S âŠ†â„¤and S â‰ âˆ…and S is bounded below, then S has a minimum.
3. There is a binary operation on â„¤called addition written as n + m.
4. Addition is associative.
5. Addition is commutative.
6. There is an additive identity in â„¤. Call it 0. (We know that it is unique.)
7. If n âˆˆâ„¤, then n has an additive inverse.
8. If k, n, m âˆˆâ„¤and n < m, then n + k < m + k.
9. There is a binary operation on â„¤called multiplication written n â‹…m.
10. Multiplication is associative.
11. Multiplication is commutative.
12. There is a multiplicative identity in â„¤. Call it 1. (We know that it is unique.)
13. If k, n, m âˆˆâ„¤and n < m and k > 0, then n â‹…k < m â‹…k.
14. Multiplication distributes over addition.
15. If n, m âˆˆâ„¤with nm = 0, then either n = 0 or m = 0.
16. 0 â‰ 1.
Notice that because we have a general theorem that tells us that a two-sided
identity is unique, we can give our identities names immediately after we say

268
14 â„•, â„¤, and â„š
that they exist. Inverses are also unique, but there is a condition that slows us
down, but only slightly. Since addition is associative, and every element of n âˆˆâ„¤
has an inverse, we know that the inverse will be unique to n. We will write the
additive inverse as âˆ’n.
14.1.2
Results about the integers
We have some valuable algebraic properties of integers that follow from this
deï¬nition.
Theorem 14.1.2.
If n âˆˆâ„¤, n â‹…0 = 0 â‹…n = 0.
Proof. Assume n âˆˆâ„¤. Consider n + n â‹…0.
n + n â‹…0 = n â‹…1 + n â‹…0
(14.8)
= n â‹…(1 + 0)
= n â‹…1
= n.
Now
n + n â‹…0 = n.
(14.9)
So
(âˆ’n) + n + n â‹…0 = (âˆ’n) + n
(14.10)
0 + n â‹…0 = 0
n â‹…0 = 0.
â—½
Theorem 14.1.3.
If n, m âˆˆâ„¤, then
1. âˆ’(âˆ’a) = a,
2. âˆ’a = (âˆ’1) â‹…a,
3. âˆ’(a + b) = (âˆ’a) + (âˆ’b), and
4. âˆ’(ab) = (âˆ’a)b = a(âˆ’b).
Proof.
Part 1. We claim that âˆ’(âˆ’a) = a.
Proof of claim. Consider a + (âˆ’a). Then a + (âˆ’a) = 0. So a acts as the inverse
of the integer âˆ’a. So âˆ’(âˆ’a) = a.
â—¾
Part 2. We claim âˆ’a = (âˆ’1) â‹…a.

14.1 The Integers
269
Proof of claim. Consider a + (âˆ’1) â‹…a.
a + (âˆ’1) â‹…a = 1 â‹…a + (âˆ’1) â‹…a
(14.11)
= (1 + (âˆ’1)) â‹…a
= 0 â‹…a
= 0.
Thus, (âˆ’1) â‹…a acts as the inverse of a.
â—¾
Part 3. We claim âˆ’(a + b) = (âˆ’a) + (âˆ’b).
Proof of claim.
âˆ’(a + b) = (âˆ’1)(a + b)
(14.12)
= (âˆ’1)a + (âˆ’1)b
= (âˆ’a) + (âˆ’b).
â—¾
Part 4. We claim âˆ’(ab) = (âˆ’a)b = a(âˆ’b).
Proof of claim.
âˆ’(ab) = (âˆ’1)ab
(14.13)
= (âˆ’a) â‹…b
= a â‹…(âˆ’b).
â—¾
â—½
Theorem 14.1.4.
If k, n, m âˆˆâ„¤with n < m and k < 0, then k â‹…n > k â‹…m.
Proof. Assume k, n, m âˆˆâ„¤. Assume n < m. Assume k < 0.
Then 0 < âˆ’k. Now multiplying n < m by âˆ’k , we get
âˆ’kn < âˆ’km.
(14.14)
So
(k â‹…n + k â‹…m) âˆ’(k â‹…n) < (k â‹…n + k â‹…m) âˆ’(k â‹…m);
(14.15)
(k â‹…n âˆ’k â‹…n) + (k â‹…m) < k â‹…n + (k â‹…m âˆ’k â‹…m);
0 + k â‹…m < k â‹…n + 0;
k â‹…m < k â‹…n.
â—½
Corollary 14.1.5.
If n âˆˆâ„¤and n â‰ 0, then n2 > 0.
Corollary 14.1.6.
In â„¤, 1 > 0.

270
14 â„•, â„¤, and â„š
14.1.3
The relationship between natural numbers and integers
In school, we learn about the integers by constructing them from the natural
numbers. But earlier, we have basically said that any set of numbers that has
all the properties of the integers is the set of integers no matter where it came
from. Our next theorem simply states that these two views of the integers are
the same. Any set of integers by our deï¬nition could have been constructed
from a set of natural numbers as we did in school.
Theorem 14.1.7.
Let N = {n âˆˆâ„¤âˆ£n > 0}. Then N has all the properties of
the natural numbers â„•.
Proof. This are actually 16 smaller proofs done, one at a time.
1. N â‰ âˆ….
Proof. This follows from the corollary; 1 > 0. â—Š
2. There is a total order on N.
Proof. This follows because N âŠ†â„¤, which has a total order. â—Š
3. N is a well ordered set.
Proof. If S âŠ†N and S â‰ âˆ…, then 0 is a lower bound of S; so it has a
minimum. (Note that, in particular, N itself has a minimum by this
argument.) â—Š
Claim. Min(N) = 1 is the multiplicative identity of â„¤.
Proof of claim. We know that 1 âˆˆN. So N â‰ âˆ…. Since 0 is a lower bound
of N, it has a minimum. Suppose BWOC that m = Min(N) â‰ 1. Then m âˆˆ
N with m < 1. Then 0 < m < 1. So 0 â‹…m < m2 < 1 â‹…m. Then m2 âˆˆN and
m2 < Min(N). That is a contradiction.
â—¾
4. There is a binary operation on N called addition written as n + m.
Proof. We have an addition in â„¤, but we need to check that n, m âˆˆN
implies n + m âˆˆN. It does. â—Š
5. Addition is associative.
Proof. This is inherited from addition on â„¤. â—Š

14.1 The Integers
271
6. Addition is commutative.
Proof. This is also inherited from addition on â„¤. â—Š
7. If n âˆˆN and n â‰ 1, then there exists m âˆˆN so that m + 1 = n.
Proof. Now 1 has an additive inverse in â„¤. Assume n âˆˆN and n â‰ 1 =
Min(N). So n > 1, and m = n âˆ’1 > 0 satisï¬es the requirements. â—Š
8. If n, m âˆˆN and n < m, then âˆ€k âˆˆâ„•, n + k < m + k.
Proof. This is inherited from addition on â„¤. â—Š
9. There is a binary operation on N called multiplication written as nm.
Proof. We have a multiplication in â„¤, but we need to check that n, m âˆˆN
implies nm âˆˆN. It does. â—Š
10. Multiplication is associative.
Proof. Inherited from â„¤. â—Š
11. Multiplication is commutative.
Proof. Inherited from â„¤. â—Š
12. If 1 is the minimum natural number, 1 is a multiplicative identity for N.
We already proved this earlier as a claim.
13. If k, n, m âˆˆN with n < m, then n â‹…k < m â‹…k.
Proof. Inherited from â„¤. â—Š
14. Multiplication distributes over addition.
Proof. Inherited from â„¤. â—Š
15. If n, m âˆˆN, then n < n + m.
Proof. Since m âˆˆN, 0 < m. So n < n + m. â—Š
16. If n, m âˆˆN and n â‰¤m â‰¤n + 1, then either m = n or m = n + 1.
Proof. Assume n, m âˆˆN and n < m â‰¤n + 1. Then either n < m â‰¤n + 1.
So 0 < n âˆ’n â‰¤m âˆ’n â‰¤1. But we know that 1 =Min(N); so m âˆ’n = 1. â—Š
â—½

272
14 â„•, â„¤, and â„š
Notation. We identify N as â„•; so â„•âŠ†â„¤.
Corollary 14.1.8.
If â„¤is the set of integers, then â„¤= â„•âˆª{0} âˆª{ âˆ’n âˆ£
n âˆˆâ„•}.
14.2
The rational numbers
Our next algebraic step leads us to the deï¬nition of an ordered ï¬eld. (Now is a
good time to refresh our memory of this deï¬nition.) An ordered ï¬eld has all the
algebraic properties we want. Unlike the natural numbers â„•and the integers â„¤,
these algebraic properties do not uniquely determine one set of numbers. So we
cannot deï¬ne â„šby listing its algebraic properties. The algebraic properties of
â„šalso hold for many other number systems; those systems are called ordered
ï¬elds. The rational numbers form just one example of an ordered ï¬eld. We can
describe â„šuniquely as the smallest ordered ï¬eld, or as the number ratios of
integers to natural numbers (fractions), but those are more like theorems than
deï¬nitions.
We will follow our grade school experience and construct an ordered ï¬eld
using ratios between integers and natural numbers. We will write the results
in this construction as propositions and not theorems because they can be
combined into one theorem that says that the result is indeed an ordered
ï¬eld.
Let îˆ²= â„¤Ã— â„•. Deï¬ne a relation â‰¡on îˆ²by
(n, m) â‰¡(p, q) if and only if nq = mp.
Proposition 14.2.1.
The relation â‰¡on îˆ²is an equivalence relation.
Proof. We must prove that the relation is reï¬‚exive, symmetric, and transitive.
Part 1. We claim that â‰¡is reï¬‚exive. That is, we claim that for all (n, m) âˆˆîˆ²=
â„¤Ã— â„•, (n, m) â‰¡(n, m).
Proof of claim. Assume (n, m) âˆˆîˆ²= â„¤Ã— â„•. Then nm = mn in â„¤; so (n, m) â‰¡
(n, m).
â—¾
Part 2. We claim that â‰¡is symmetric. That is, we claim:
For all (n, m), (p, q) âˆˆîˆ²= â„¤Ã— â„•, if (n, m) â‰¡(p, q), then (p, q) â‰¡(n, m).
Proof of claim. Assume (n, m), (p, q) âˆˆîˆ²= â„¤Ã— â„•. Assume (n, m) â‰¡(p, q).
Then nq = mp. So mp = nq, and therefore, (p, q) â‰¡(n, m).
â—¾

14.2 The Rational Numbers
273
Part 3. We claim that â‰¡is transitive. That is, we claim:
For all (n, m), (p, q), (s, t) âˆˆîˆ²= â„¤Ã— â„•, if (n, m) â‰¡(p, q) and (p, q) â‰¡(s, t),
then (n, m) â‰¡(s, t).
Proof of claim. Assume (n, m), (p, q), (s, t) âˆˆîˆ²= â„¤Ã— â„•.
Assume (n, m) â‰¡(p, q). Assume (p, q) â‰¡(s, t).
Then nq = mp and pt = qs. So
nqt = mpt;
(14.16)
nqt = mqs;
nt = ms
because t, q âˆˆâ„•. Thus (n, m) â‰¡(s, t).
â—¾
Since â‰¡is reï¬‚exive, symmetric, and transitive, it follows that â‰¡is an equiva-
lence relation.
â—½
Once we have an equivalence relation, we have equivalence classes. We will
write the equivalence class using the notation everyone calls â€œfractions:â€
[(n, m)] = {(p, q) âˆˆîˆ²âˆ£(p, q) â‰¡(n, m)} = n
m.
(14.17)
We also have the set îˆ²âˆ•â‰¡. We will write this as â„š.
Deï¬nition 14.2.2.
The rational numbers are the elements of â„š= (îˆ²âˆ•â‰¡
) as
deï¬ned earlier.
Thus for n
m, p
q âˆˆâ„š,
n
m = p
q if and only if nq = mp.
Deï¬nition 14.2.3.
Deï¬ne a relation < on â„šby
n
m < p
q if and only if nq < mp in â„¤.
Notice that this deï¬nition depends on the representations of the two equiv-
alence classes n
m and p
q. We must prove that the result does not.
Proposition 14.2.4.
The relation < on â„šis well deï¬ned.
Proof. Comment: We know that â€œwell deï¬nedâ€ is usually about the names we
choose. We rephrase well deï¬ned as: if we compare the same things using diï¬€erent
names, we get the same results.

274
14 â„•, â„¤, and â„š
We will prove:
If n1
m1
= n2
m2
and p1
q1
= p2
q2
,
then if n1
m1
< p1
q1
, then n2
m2
< p2
q2
.
Assume
n1
m1 = n2
m2 and p1
q1 = p2
q2 . Next assume
n1
m1 < p1
q1 . So n1m2 = n2m1 and
p1q2 = p2q1 and n1q1 < m1p1. Now m1, m2, q1 and q2 are all positive, and we
can multiply or cancel them from both sides of an inequality without changing
the direction of the inequality. Then
n1q1 < m1p1;
(14.18)
n1m2q1 < m1m2p1;
n2m1q1 < m1m2p1;
n2q1 < m2p1;
n2q1q2 < m2p1q2;
n2q1q2 < m2p2q1;
n2q2 < m2p2.
So n2
m2 < p2
q2 .
â—½
Deï¬nition 14.2.5.
Deï¬ne a binary operation on â„šby
For n
m, p
q âˆˆâ„š, n
m + p
q = nq+mp
mq .
Again, we remember that we are working with equivalence classes; so when
we deï¬ne something using particular representations of classes, we must prove
that it is actually well deï¬ned.
Proposition 14.2.6.
The addition on â„šis well deï¬ned.
Proof. We will prove:
If n1
m1 = n2
m2 and p1
q1 = p2
q2 , then n1
m1 + p1
q1 = n2
m2 + p2
q2 .
Assume n1
m1 = n2
m2 and p1
q1 = p2
q2 . So n1m2 = n2m1 and p1q2 = p2q1.
Comment: There is some scratch work that does not appear in the proof. We use
the formula to add n1
m1 + p1
q1 and n2
m2 + p2
q2 . We compare the two results by â€œcross
multiplyingâ€ and run through the algebra to be sure that the two results are
equal. We return to the proof and just write the results logically.

14.2 The Rational Numbers
275
Consider (m2q2)(n1q1 + p1m1).
(m2q2)(n1q1 + p1m1) = m2q2n1q1 + m2q2p1m1
(14.19)
= m1q2n2q1 + m2q1p2m1
= (m1q1)(n2q2 + p2m2).
So
n1q1 + m1p1
m1q1
= n2q2 + m2p2
m2q2
.
(14.20)
So
n1
m1
+ p1
q1
= n2
m2
+ p2
q2
.
(14.21)
â—½
Deï¬nition 14.2.7.
Deï¬ne a binary operation on â„šby
For n
m, p
q âˆˆâ„š, n
m â‹…p
q = np
mq.
We remember that we are working with equivalence classes, so we must prove
that it is actually well deï¬ned.
Proposition 14.2.8.
The multiplication on â„šis well deï¬ned.
Proof. We will prove:
If n1
m1 = n2
m2 and p1
q1 = p2
q2 , then n1
m1 â‹…p1
q1 = n2
m2 â‹…p2
q2 .
Assume
n1
m1 =
n2
m2 and
p1
q1 =
p2
q2 . So n1m2 = n2m1 and p1q2 = p2q1. Consider
n1p1m2q2.
n1p1m2q2 = n2p2m1q1.
(14.22)
So n1p1
m1q1 = n2p2
m2q2 . And so n1
m1 â‹…p1
q1 = n2
m2 â‹…p2
q2 .
â—½
To make things easier, we will prove a few results that will ï¬nally allow to use
rational numbers the way we were taught in school.
Proposition 14.2.9.
Let n
m, p
m âˆˆâ„šand k âˆˆâ„•. Then
1.
nk
mk = n
m.
2.
n
m < p
m if and only if n < p.
3.
n
m + p
m = n+p
m .
4. âˆ’n
m = âˆ’n
m .

276
14 â„•, â„¤, and â„š
Proof.
Part 1. We claim that nk
mk = n
m.
Proof of claim. This follows because nmk = nmk.
â—¾
Part 2. We claim that n
m < p
m if and only if n < p.
Proof of claim. Here we have
(
n
m < p
m
)
â‡”(nm < pm) â‡”n < p.
â—¾
Part 3. We claim that n
m + p
m = n+p
m .
Proof of claim. Notice that n
m + p
m = nm+pm
m2
= (n+p)m
m2
= (n+p)
m .
â—¾
Part 4. We claim that âˆ’n
m = âˆ’n
m .
Proof of claim. We observe that n
m + âˆ’n
m = 0
m = 0
1, which is an additive identity.
So âˆ’n
m is the additive inverse of n
m.
â—¾
â—½
Now that we know that the names we use for rational numbers do not matter
in the arithmetic, we make and prove 15 separate claims about the algebraic
properties of â„š.
Proposition 14.2.10.
The order on â„šis transitive.
Proof. Assume n
m, p
q, s
t âˆˆâ„š. Assume n
m < p
q, and p
q < s
t.
Then nq < mp and pt < qs. Because m, q, t âˆˆâ„•, we can multiply and cancel
inequalities by them. Then
nqt < mpt
and
mpt < mqs.
nqt < mpt < mqs.
(14.23)
nt < ms.
Thus, n
m < s
t.
â—½
Proposition 14.2.11.
The order on â„šhas trichotomy.
Proof. Assume n
m, p
q, s
t âˆˆâ„š. Then mp and nq are integers, and the integers have
trichotomy. So exactly one of the following is true: mp < nq in which case n
m <
p
q; nq < mp in which case p
q < n
m; or mp = nq in which case n
m = p
q.
â—½
Note the two previous propositions together tell us that â„šhas a total order.

14.2 The Rational Numbers
277
Proposition 14.2.12.
Addition on â„šis associative.
Proof. Assume n
m, p
q, s
t âˆˆâ„š. Then
m
n +
(p
q + s
t
)
= m
n + pt + qs
qt
(14.24)
= mqt + npt + nqs
nqt
= (mq + np)t + nqs
nq
= mq + np
nq
+ s
t
=
(
m
n + p
q
)
+ s
t .
â—½
Proposition 14.2.13.
Addition on â„šis commutative.
Proof. Assume n
m, p
q âˆˆâ„š. Then
m
n + p
q = mq + np
nq
= p
q + m
n .
(14.25)
â—½
Proposition 14.2.14.
There is an additive identity in â„š.
Proof. Consider 0
1 âˆˆâ„š. Then 0
1 + n
m = 0â‹…m+1â‹…n
1â‹…m
= n
m.
â—½
Proposition 14.2.15.
If a âˆˆâ„š, then a has an additive inverse.
Proof. Assume n
m âˆˆâ„š. Then âˆ’n
m âˆˆâ„š. And n
m+ âˆ’n
m = nâˆ’n
m = 0
m = 0
1.
â—½
Proposition 14.2.16.
If a, b, c âˆˆâ„šand a < b, then a + c < b + c.
Proof. Assume a, b, c âˆˆâ„š. Assume a < b. Write a = n
m, b = p
q, and c = s
t.
Now nq < mp. Consider tq(nt + ms).
tq(nt + ms) = (qn)t2 + tqms
(14.26)
< (mp)t2 + tqms
< tm(pt + qs).
So
(nt + ms)
mt
< (pt + qs)
qt
.
(14.27)

278
14 â„•, â„¤, and â„š
So
a + c = n
m + s
t < p
q + s
t = b + c.
(14.28)â—½
Proposition 14.2.17.
Multiplication on â„šis associative.
Proof. Assume n
m, p
q, s
t âˆˆâ„š. Then
m
n
(p
q
s
t
)
= mps
nqt =
(
m
n
p
q
)
s
t .
(14.29)â—½
Proposition 14.2.18.
Multiplication on â„šis commutative.
Proof. Assume n
m, p
q âˆˆâ„š. Then
m
n
p
q = mp
nq = p
q
m
n .
(14.30)â—½
Proposition 14.2.19.
There is a multiplicative identity in â„š.
Proof. Consider 1
1 âˆˆâ„š. Assume n
m âˆˆâ„š. Then 1
1 â‹…n
m = n
m = n
m â‹…1
1.
â—½
Proposition 14.2.20.
If a âˆˆâ„šand a â‰ 0, then a has a multiplicative inverse.
Proof. Assume
n
m âˆˆâ„š. Assume
n
m â‰ 0
1. So n â‹…1 â‰ m â‹…0, and we have n2 > 0.
Consider mn
n2 âˆˆâ„š. Then n
m â‹…mn
n2 = mn2
mn2 = 1
1.
â—½
Proposition 14.2.21.
If a, b, c âˆˆâ„šand a < b and 0 < c, then a â‹…c < b â‹…c.
Proof. Write a = n
m, b = p
q, and c = s
t. Assume a = n
m, b = p
q and s
t > 0
1. Then
nq < mp, s > 0 and t âˆˆâ„•. So nqst < mpst. And so n
m
s
t < p
q
s
t.
â—½
Proposition 14.2.22.
If a, b, c âˆˆâ„š, then a â‹…(b + c) = a â‹…b + a â‹…c.
Proof. Write a = n
m, b = p
q, and c = s
t.
Then
n
m
(p
q + s
t
)
= n
m â‹…
(pt + qs
qt
)
(14.31)
= npt + nqs
mqt
= npmt + mqns
mqmt
= np
mq + ns
mt
= n
m
p
q + n
m
s
t .
â—½

14.3 Problems
279
Proposition 14.2.23.
The additive identity and the multiplicative identity on
â„šare not equal.
Proof. Since in â„¤we have 0 â‰ 1, we know in â„š, 0
1 â‰ 1
1.
â—½
There is one last result that is not part of being an ordered ï¬eld, but it does
place our previous number systems back in the game.
Theorem 14.2.24.
The subset Z = { n
1 âˆˆâ„šâˆ£n âˆˆâ„¤} has all the properties of
â„¤. We identify Z and â„¤so we can write n
1 = n.
We have proved most of this in the propositions earlier.
14.3
Problems
14.1
Write a mathematical deï¬nition of â€œ n
m âˆˆâ„šis in lowest terms.â€
14.2
Prove that there is no r âˆˆâ„šsuch that r2 = 2.
14.3
Prove that there is no r âˆˆâ„šsuch that r2 = 6.
14.4
Prove that there is no r âˆˆâ„šsuch that r2 = 8.
14.5
Suppose that we try to deï¬ne a binary operation on â„šby
n
m âŠ•p
q = n + p
m + q.
(14.32)
Show that this is not well deï¬ned.
14.6
For any A âŠ†â„šdeï¬ne the following two sets:
LB(A) = {x âˆˆâ„šâˆ£x is a lower bound of A}.
UB(A) = {x âˆˆâ„šâˆ£x is an upper bound of A}.
(a) Prove: If A has a lower bound, then A âŠ†UB(LB(A)), but they need
not be equal.
(b) Prove: If A has a lower bound, then LB(A) = LB(UB(LB(A))).
(c) Prove: If A has a lower bound, then LB(A) âˆªUB(LB(A)) = â„š.
(d) Prove: If A has a lower bound, then LB(A) âˆ©UB(LB(A)) may be
empty or may have one element, but it will not have 2 or more.
(e) Prove: If A has an upper bound, then A âŠ†LB(UB(A)), but they need
not be equal.

280
14 â„•, â„¤, and â„š
(f) Prove: If A has an upper bound, then UB(A) = UB(LB(UB(A))).
(g) Prove: If A has an upper bound, then UB(A) âˆªLB(UB(A)) = â„š.
(h) Prove: If A has an upper bound, then UB(A) âˆ©LB(UB(A)) may be
empty or may have one element, but it will not have 2 or more.
14.7
State the Division Algorithm for â„¤. Be sure that your requirements for
the remainder are precise.
14.8
Why do we not deï¬ne â€œoddâ€ and â€œevenâ€ rational numbers?

281
15
Ordered Fields and the Real Numbers
15.1
Ordered ï¬elds
Deï¬nitions and easy consequences
We start right out with a deï¬nition that includes all the algebraic properties
that we want.
Deï¬nition 15.1.1.
An ordered ï¬eld is a set F that has the following properties:
1. F has a total order.
2. There is a binary operation a + b on F.
3. Addition is associative.
4. Addition is commutative.
5. There is an additive identity in F. (It is unique, and we will denote it as 0.)
6. If a âˆˆF, then a has an additive inverse. (It is unique to a, and we will denote
it as âˆ’a).
7. If a, b, c âˆˆF and a < b, then a + c < b + c.
8. There is a binary operation a â‹…b on F.
9. Multiplication is associative.
10. Multiplication is commutative.
11. There is a multiplicative identity in F. (It is unique, and we will denote it
as 1.)
12. If a âˆˆF and a â‰ 0, then a has a multiplicative inverse. (It is unique to a,
and we will denote it as aâˆ’1.)
13. If a, b, c âˆˆF and a < b and 0 < c, then a â‹…c < b â‹…c.
14. Multiplication distributes over addition.
15. 0 â‰ 1.
We have seen so many of these properties before that we can write down
several more that follow from them without much fuss.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

282
15 Ordered Fields and the Real Numbers
Theorem 15.1.2.
Let a, b, c âˆˆF, an ordered ï¬eld.
1. a â‹…0 = 0 â‹…a = 0.
2. âˆ’(âˆ’a) = a.
3. âˆ’a = (âˆ’1) â‹…a.
4. âˆ’(a + b) = (âˆ’a) + (âˆ’b).
5. âˆ’(ab) = (âˆ’a)b = a(âˆ’b).
6. If a â‰ 0, then (aâˆ’1)âˆ’1 = a.
7. (ab)âˆ’1 = bâˆ’1aâˆ’1.
8. If a < b and c < 0, then ac > bc.
9. If a â‰ 0, then a2 > 0.
We anticipated this deï¬nition in the last section, and the 16 claims proved
about â„šhave collectively proved the following theorem:
Theorem 15.1.3.
The rational numbers â„šform an ordered ï¬eld.
Next we state (but not bother to prove) a rather strange looking theorem, but
it is the basis for our claim that the rational numbers form the smallest ordered
ï¬eld. We will not go through the lengthy proof, which does not really add much
information about what is going on.
Theorem 15.1.4.
Let F be an ordered ï¬eld. Let
N =
{ n
âˆ‘
k=1
1 âˆ£n âˆˆâ„•
}
.
(15.1)
Then N has all of the properties of the natural numbers â„•. We identify â„•with
N âŠ†F.
Corollary 15.1.5.
Let F be an ordered ï¬eld. Then F contains a subset that has
all the properties of â„¤. We identify it with â„¤.
Of course, this is â„•âˆª{0} âˆª{ âˆ’n âˆ£n âˆˆâ„•}. Let F be an ordered ï¬eld. Then
consider
Q = {nmâˆ’1 âˆ£m âˆˆâ„¤and m âˆˆâ„•}.
(15.2)
We have:
Corollary 15.1.6.
Let F be an ordered ï¬eld. Then F contains a subset that is
essentially the rational numbers. We identify it with â„š.
This set acts exactly as â„š. We will identify it as such and write â„šâŠ†F. After
these identiï¬cations, we have â„•âŠ†â„¤âŠ†â„šâŠ†F for any ordered ï¬eld F. So yes,

15.1 Ordered Fields
283
viewing the subset relation as an order, â„šis the â€œminimumâ€ ordered ï¬eld.
This also gives us an alternate notation for inverses, aâˆ’1 = 1
a that works in any
ordered ï¬eld. This generalizes to a notation for division by nonzero things,
baâˆ’1 = b
a.
More properties of ordered ï¬elds
There are two properties of ordered ï¬elds that come in handy at times. Because
they are proved using the deï¬nition of an ordered ï¬eld, they can be applied to
â„šor â„or any other ordered ï¬eld we might be interested in.
Theorem 15.1.7.
Let a, r âˆˆF, an ordered ï¬eld, and let r â‰¥0. For all x âˆˆF,
1. |x âˆ’a| â‰¤r if and only if a âˆ’r â‰¤x â‰¤a + r;
2. |x âˆ’a| < r if and only if a âˆ’r < x < a + r.
Proof. We will just prove statement 1.
(â‡’). We claim that if |x âˆ’a| â‰¤r then a âˆ’r â‰¤x â‰¤a + r.
Proof of claim. Assume |x âˆ’a| â‰¤r. Then âˆ’|x âˆ’a| â‰¥âˆ’r. And so
âˆ’r â‰¤âˆ’|x âˆ’a| â‰¤x âˆ’a â‰¤|x âˆ’a| â‰¤r.
(15.3)
So âˆ’r â‰¤x âˆ’a â‰¤r. So a âˆ’r â‰¤x â‰¤a + r.
â—¾
(â‡). We claim that if a âˆ’r â‰¤x â‰¤a + r then |x âˆ’a| â‰¤r.
Proof of claim. Assume a âˆ’r â‰¤x â‰¤a + r. Then âˆ’r â‰¤x âˆ’a â‰¤r. So multiplying
all sides by âˆ’1, we get âˆ’r â‰¤a âˆ’x â‰¤r. So âˆ’r â‰¤Â±(x âˆ’a) â‰¤r. So |x âˆ’a| â‰¤r. â—¾
â—½
Corollary 15.1.8.
In â„,
{x âˆˆâ„âˆ£|x âˆ’a| < r} = (a âˆ’r, a + r).
(15.4)
Theorem 15.1.9
(The Triangle Inequality). Let a, b âˆˆF an ordered ï¬eld.
Then
|a + b| â‰¤|a| + |b|.
(15.5)
Proof. Assume a, b âˆˆF. Then
âˆ’|a| â‰¤a â‰¤|a|;
(15.6)
âˆ’|b| â‰¤b â‰¤|b|.
Adding these, we get
âˆ’(|a| + |b|) â‰¤(a + b) â‰¤(|a| + |b|).
(15.7)

284
15 Ordered Fields and the Real Numbers
By the previous theorem,
|a + b| â‰¤|a| + |b|.
(15.8)
â—½
The next theorem also holds for any ordered ï¬eld; its contrapositive is
particularly useful in the real numbers. All it does is guarantee that, between
any two elements of the ï¬eld, there is another. There is nothing special about
the element it guarantees exists, and there are plenty of numbers it could be.
However, there is one that is easy to remember and calculate - the average, and
that is how we tend to remember the theorem. There are two theorems about
the real numbers that mirror this theorem, but they identify the number in the
middle as a member of a speciï¬c subset of â„. Those are both pretty powerful
results when you need numbers of those particular types. In most proofs about
the real numbers, any old real number between two numbers will do. In that
case, it is best to just use the average. Notice that this theorem is almost the
direct opposite of the property of â„•and â„¤that said, if n â‰¤m â‰¤n + 1, then
either n = m or m = n + 1.
Theorem 15.1.10
(The Average Theorem). Let a, b âˆˆF be an ordered ï¬eld.
If a < b, then there exists c âˆˆF with a < c < b.
Proof. Assume a < b. Then 2a < a + b and a + b < 2b. So 2a < a + b < 2b.
And since 2 has an inverse, a < a+b
2
< b. We now have the element of F that
we want.
â—½
Corollary 15.1.11.
Let a âˆˆF be an ordered ï¬eld with a â‰¥0. If âˆ€ðœ€> 0, a < ðœ€,
then a = 0.
15.2
The real numbers
Deï¬nition
Now that we have all the terminology, the deï¬nition of the real numbers is
pretty easy to state.
Deï¬nition 15.2.1.
The real numbers â„form a complete ordered ï¬eld.
Of course, this means that â„is an ordered ï¬eld that satisï¬es the completeness
axiom:
The completeness axiom. If S âŠ†â„and S â‰ âˆ…and S is bounded below, then S
has an inï¬mum in â„.

15.2 The Real Numbers
285
We proved that any ordered set U that is complete also satisï¬es the alternate
completeness axiom:
The alternate completeness axiom. If S âŠ†â„and S â‰ âˆ…and S is bounded
above, then S has a supremum in â„.
Properties of â„
The ï¬rst theorem we prove about â„does not seem like much, but it appears
in all sorts of proofs of theorems about the real numbers. The second theorem
seems more interesting; perhaps because it is, but it tends to mostly be used
to provide examples in early analysis studies. Recall that every ordered ï¬eld
contains the sets â„•âŠ†â„¤âŠ†â„šthat use the exact same arithmetic operations as
â„. So we can state:
Theorem 15.2.2
(The Archimedean Principle). If r âˆˆâ„, then there exists
an n âˆˆâ„•such that r < n.
Proof draft. This theorem is often stated in the form of the logically equivalent
statement: As a subset of â„, â„•is not bounded above.
Comment: Let us see why this is the logical equivalent. The statement
If r âˆˆâ„, then âˆƒn âˆˆâ„•such that r < n
can be rephrased as
âˆ€r âˆˆâ„, âˆƒn âˆˆâ„•such that r < n.
The negation is
âˆ¼(âˆ€r âˆˆâ„, âˆƒn âˆˆâ„•such that r < n)
âˆƒr âˆˆâ„such that âˆ¼(âˆƒn âˆˆâ„•such that r < n)
âˆƒr âˆˆâ„such that âˆ€n âˆˆâ„•, âˆ¼(r < n)
âˆƒr âˆˆâ„such that âˆ€n âˆˆâ„•, r â‰¥n.
That is to say, â€œThere is an upper bound on â„•in â„.â€ So the statement in the
theorem is logically equivalent to â€œThere is no upper bound on â„•in â„.â€
Assume BWOC that â„•is bounded above.
Comment: We could pick one upper bound and name it, but we really should
take the best possible upper bound if one is available to us.
By completeness, â„•has a supremum in â„. Let s = Sup(â„•). Then
1. if n âˆˆâ„•, then n â‰¤s;
2. if l < s, then âˆƒn âˆˆâ„•such that l < n.
Consider s âˆ’1.

286
15 Ordered Fields and the Real Numbers
Comment: Be warned, subtracting 1 to use with a supremum only works here
and almost never anywhere else.
Then s âˆ’1 < s. So by the deï¬nition of the supremum, âˆƒn âˆˆâ„•such that
s âˆ’1 < n. But then s < n + 1. Since n âˆˆâ„•, n + 1 âˆˆâ„•. But s = Sup(â„•); so
n + 1 â‰¤s. Putting these together, n + 1 â‰¤s < n + 1, we get a contradiction. Î”
This deserves to be rewritten.
Proof. We will prove: â„•is not bounded above in â„.
Assume BWOC that â„•is bounded above.
By completeness, â„•has a supremum in â„. Let s = Sup(â„•). Then if n âˆˆâ„•, then
n â‰¤s. And if l < s, then âˆƒn âˆˆâ„•such that l < n.
Consider s âˆ’1. Then s âˆ’1 < s. So by the deï¬nition of the supremum, âˆƒn âˆˆâ„•
such that s âˆ’1 < n. But then s < n + 1. Since n âˆˆâ„•, n + 1 âˆˆâ„•. But s = Sup(â„•);
so n + 1 â‰¤s.
Putting these together, n + 1 â‰¤s < n + 1; so we get a contradiction.
â—½
Corollary 15.2.3.
If r âˆˆâ„, then âˆƒm âˆˆâ„¤such that m < r.
Proof. Assume r âˆˆâ„. Then âˆ’r âˆˆâ„; so by Archimedes, âˆƒn âˆˆâ„•s.t âˆ’r < n. Then
r > âˆ’n âˆˆâ„¤.
â—½
The next theorem is a step up beyond the average theorem. Using the
identiï¬cation that makes â„šâŠ†â„, this theorem guarantees that between any
two real numbers, there is a rational number. We already know that there is
a real number between them. If they are both rational, then the average is
rational, but this says nothing new in that case. However, if we start with any
two real numbers, rational, not rational, or we have no idea, there is still a
rational number between them. No intervals in â„, no matter how small, are
made up of nothing but irrational numbers.
Theorem 15.2.4
(The Density Theorem). If a, b âˆˆâ„and a < b, then there
exists r âˆˆâ„šso that a < r < b.
Proof. First, we make a claim
Claim. If a + 1 < b, then there exists m âˆˆâ„¤with a < m < b.
Proof of claim. Assume a + 1 < b. Let
S = {k âˆˆâ„¤âˆ£a < k}.
(15.9)
Now by the Archimedean principle, S â‰ âˆ…. It also tells us that âˆƒl âˆˆâ„¤such that
l < a. Thus, S is a nonempty subset of â„¤bounded below in â„¤. By the properties

15.2 The Real Numbers
287
of â„¤it has a minimum. Let m = Min(S). Then m âˆˆS, and so a < m. Also if
k âˆˆS, m â‰¤k. But m âˆ’1 < m = Min(S). So m âˆ’1 âˆ‰S. This means m âˆ’1 â‰¤a.
Or equivalently, m â‰¤a + 1. So we have m âˆˆâ„¤such that a < m â‰¤a + 1 < b. â—¾
The theorem follows from this claim. Assume now that a < b. Then
b âˆ’a > 0. So
1
bâˆ’a âˆˆâ„. By the Archimedean principle, âˆƒn âˆˆâ„•, such that
1
bâˆ’a < n. So 1 < n(b âˆ’a). Then na + 1 < nb. If we apply the claim to the
numbers na and nb, we ï¬nd âˆƒm âˆˆâ„¤with na < m < nb. Thus, a < m
n < b with
m âˆˆâ„¤and n âˆˆâ„•. So m
n âˆˆâ„šï¬ts the requirement we need.
â—½
Decimals and real numbers
In school, we learned that real numbers were the numbers that were rep-
resented by possibly inï¬nite decimals. Thus, 7 = 7.0 is a real number. Also
3
4 = 0.75 âˆˆâ„because 0.75 =
75
100 is a rational number and therefore automati-
cally real. Now our calculator hinted that 1
3 = 0.333333 â€¦. This takes a bit more
faith to believe, but if any inï¬nite decimal is a real number, then we can name
ð›¼= 0.33333 â€¦. If inï¬nite arithmetic works the same way ï¬nite arithmetic
works, then 10ð›¼= 3.3333 â€¦. So 10ð›¼= 3 + ð›¼. So by algebra ð›¼= 3
9 = 1
3. There
are two rather major â€œifâ€™sâ€ in here: â€œif any inï¬nite decimal is a real numberâ€
and â€œif inï¬nite arithmetic works the same way ï¬nite arithmetic works.â€ These
certainly seem plausible, but anything involving the inï¬nite needs to be more
than just plausible before we can depend on it.
Consider the real number ðœ‹. Everyone knows ðœ‹= 3.14159 â€¦. But this time
the ellipsis has a very diï¬€erent meaning. This time the digits do not proceed
in a pattern. In fact, someone who knows some Mathematics might well say,
â€œðœ‹= 3.14159 â€¦ and the digits go on forever without a pattern.â€ So if a real
number is given as an inï¬nite decimal, has anyone ever given us ðœ‹? We simply
cannot rely on inï¬nite arithmetic. But what if someone claims to have a formula
for ðœ‹, ðœ‹2, or ðœ‹3? Say
ðœ‹=
âˆž
âˆ‘
k=1
(âˆ’1)k4
2k + 1 .
(15.10)
ðœ‹2 =
âˆž
âˆ‘
k=1
6
k2 .
ðœ‹3 = 87059
8879
âˆš
10.
Inï¬nite arithmetic would be of little use in proving any of these. A very accurate
calculator might be enough to disprove one or to mistakenly prove another.
We know better than to think that the way to prove things about the real
numbers is from their decimal expansions. The workable deï¬nition of the real
numbers is not given using decimal expansions, but algebraically as members of

288
15 Ordered Fields and the Real Numbers
a complete ordered ï¬eld. Using our deï¬nition, however, we can talk about inï¬-
nite decimal expansions of real numbers. We will not be able to overcome the
problem of giving complete decimal expansions when the digits have no pat-
tern. But we can describe the idea of approximating real numbers with ï¬nitely
many digits as closely as you want.
Thus 1
3 = 0.333333 â€¦ means 1
3 = Sup(A) where
A = {0.3, 0.33, 0.333, 0.3333 â€¦}.
(15.11)
Every inï¬nite decimal expansion with a pattern in the digits is the supremum
of a well-deï¬ned set. It is a real number. If we have an irrational number, but
one with a strong enough pattern in the decimals such as
0.123456789 10 11 12 13 14 15 16 â€¦
(15.12)
we can see that it is real by pointing out that it is Sup(B) where
B =
{ 1
10, 12
100, 123
1000, 1234
1000, â€¦
}
(15.13)
(although the numbers in this version of the set are not enough to illustrate the
pattern without the decimal expansion earlier).
The reverse works just as well. Suppose that we have identiï¬ed ð›¼as a real
number. Say, for example, ð›¼= Inf(S) where
S = {x âˆˆâ„âˆ£2 < x2}.
(15.14)
Then 100 â‹…ð›¼and 100 â‹…ð›¼+ 1 âˆˆâ„. By the claim in the proof of the density
theorem, there is an integer n âˆˆâ„•with 100 â‹…ð›¼â‰¤n < 100 â‹…ð›¼+ 1. Then
n
100 is a
two-digit approximation of ð›¼. If we need n digits, we look at 10n â‹…ð›¼. Every real
number has a decimal expansion even if we cannot guarantee that there is a
pattern to those digits.
Of the three proposed formula for ðœ‹earlier, only the ï¬rst two are correct.
Now
P =
{
x âˆˆâ„šâˆ£âˆƒn âˆˆâ„•s.t. x =
2nâˆ’1
âˆ‘
k=1
(âˆ’1)k4
2k + 1
}
(15.15)
can be proved to be nonempty and bounded above. Thus, it will have a real
number as its supremum. Although a proof requires calculus, this can be used
to deï¬ne ðœ‹because
Tanâˆ’1(1) = ðœ‹
4 .
(15.16)
Now
Q =
{
x âˆˆâ„šâˆ£âˆƒn âˆˆâ„•such that x =
n
âˆ‘
k=1
6
k2
}
(15.17)

15.3 Problems
289
can also be proved to be nonempty and have an upper bound. It also will have a
real number as the supremum. In this course, we are setting up the properties
of â„and the proof techniques that (if we take enough more Mathematics) will
allow us to prove
Sup(Q) = (Sup(P))2.
(15.18)
15.3
Problems
15.1
Let a, b, c âˆˆF, an ordered ï¬eld. Prove each of the following:
(a) a â‹…0 = 0 â‹…a = 0.
(b) âˆ’(âˆ’a) = a.
(c) âˆ’a = (âˆ’1) â‹…a.
(d) âˆ’(a + b) = (âˆ’a) + (âˆ’b).
(e) âˆ’(ab) = (âˆ’a)b = a(âˆ’b).
(f) If a â‰ 0, then (aâˆ’1)âˆ’1 = a.
(g) (ab)âˆ’1 = bâˆ’1aâˆ’1.
(h) If a < b and c < 0, then ac > bc.
(i) If a â‰ 0, then a2 > 0.
15.2
We stated a corollary to a theorem as
In â„, {x âˆˆâ„âˆ£|x âˆ’a| < r} = (a âˆ’r, a + r).
(15.19)
Why is this not true in any ordered ï¬eld?
15.3
Let F be any ordered ï¬eld. Prove:
(a) If x > 1, then for all n âˆˆâ„•with n > 1, x < xn.
(b) If 0 < x < 1, then for all n âˆˆâ„•with n > 1, xn < x.
15.4
Let a, b âˆˆâ„so that a < b. Prove that âˆƒs âˆ‰â„šwith a < s < b.
15.5
Let A = {x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x = n+1
n }. Prove that 1 = Inf(A).
15.6
Let A = {x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x = 10âˆ’n}. Prove 0 = Inf(A).
15.7
Notice how the mathematics in the next two proofs is basically the same
but the logic is quite diï¬€erent.
(a) Prove
â‹ƒ
nâˆˆâ„•
( 1
n2 , 1
]
= (0, 1].
(15.20)
(b) Prove
â‹‚
nâˆˆâ„•
(
âˆ’1
n2 , 1
]
= [0, 1].
(15.21)

290
15 Ordered Fields and the Real Numbers
15.8
Use part (a) to prove part (b) in the following:
(a) Prove that If x âˆˆâ„with x â‰¥0 such that âˆ€ðœ€> 0, x â‰¤ðœ€, then x = 0.
(b) Let ð›¼= 0.499999 â€¦ and ð›½= 0.5. Prove that ð›¼= ð›½. Hint: if
an = 0.499999 â€¦ 9 with (n âˆ’1) 9â€™s, then it can be expressed exactly
as a ratio of integers and an âˆˆâ„šand an < ð›¼. You should actually
ï¬nd this expression for an by doing small examples and looking for
a pattern.
15.9
Prove the following:
(a) For all n âˆˆâ„•,
2n
2nâˆ’1 â‹…
2n
2n+1 < 1.
(b) For all n âˆˆâ„•,
2n
2n+1 â‹…2n+2
2nâˆ’1 > 1.
(c) Prove that the set
{ n
âˆ
k=1
(
2k
2k âˆ’1 â‹…
2k
2k + 1
)
âˆ£n âˆˆâ„•
}
(15.22)
=
{(2
1 â‹…2
3
)
,
(2
1 â‹…2
3
) (4
3 â‹…4
5
)
,
(2
1 â‹…2
3
) (4
3 â‹…4
5
) (6
5 â‹…6
7
)
, â€¦
}
has an inï¬mum.
(d) Look up â€œJohn Wallisâ€™ productâ€ and explain why the aforementioned
can lead to a complete inï¬nite description of the real number ðœ‹.
(e) Use the Taylor expansion of ArcTan(x) and its value at x = 1 to ï¬nd
another set that gives a complete inï¬nite description of the real num-
ber ðœ‹similar to the one earlier.
15.4
Epilogue
15.4.1
Constructing the real numbers
We have deï¬ned the real numbers as the elements of a complete ordered
ï¬eld. But how do we know that such an ordered ï¬eld exists? There are two
popular ways to construct the real numbers from the rational numbers: using
equivalence classes of Cauchy sequences or using Dedekind cuts. Certainly,
diï¬€erent constructions lead to diï¬€erent versions of the real numbers. As long
as we use the properties of our numbers as we work with â„, and not the actual
construction of â„, we will not be able to tell the two versions of â„apart. So
we consider both versions as the same real numbers by identifying them as the
same set. It is just a matter of understanding what our deï¬nition of â€œisâ€ is.
Cauchy sequences are useful and interesting in their own right, and so they
are a very popular way to get to the real numbers in undergraduate courses.
We can also study the properties of Cauchy sequences as theorems about the
real numbers and not as part of the construction of â„. If we continue our study
of real analysis further, there is a good chance that we will see an equivalent

15.4 Epilogue
291
version of the completeness axiom designed to work precisely with Cauchy
sequences.
Dedekind cuts are less practical (actually totally impractical), and they are
rarely seen by undergraduate students except to construct â„. However, they
ï¬t our deï¬nition of â€œcompleteâ€ better. Both constructions appear in diï¬€erent
contexts in other parts of Mathematics; so it is basically a tie over which is the
better approach. In the end, it does not really matter what the real numbers
actually are. Once we know that they exist, all that matters are their properties.
We will outline the construction of the real numbers using Dedekind cuts,
but give very little in terms of the proofs of our claims.
Let A âŠ†â„š. Deï¬ne
LB(A) = {x âˆˆâ„šâˆ£x is a lower bound of A};
UB(A) = {x âˆˆâ„šâˆ£x is an upper bound of A}.
If A, B âŠ†â„š, then deï¬ne
A + B = {a + b âˆˆâ„šâˆ£a âˆˆA and b âˆˆB};
(15.23)
A â‹…B = {ab âˆˆâ„šâˆ£a âˆˆA and b âˆˆB}.
Deï¬nition: A Dedekind cut is a pair of nonempty subsets of â„š, (L, U), such
that L = LB(U) and U = UB(L). As it turns out, if (L, U) is a Dedekind cut,
L âˆªU = â„šand |L âˆ©U| â‰¤1.
Claim: If A has a lower bound, then LB(A) and UB(LB(A)) form a
Dedekind cut.
Claim: If A has an upper bound, then LB(UB(A)) and UB(A) form a
Dedekind cut.
Let
â„C = {(L, B) âˆ£(L, B) is a Dedekind cut}.
(15.24)
We deï¬ne an order, an addition, and a multiplication on â„C.
Deï¬nition: We say (L, B) â‰¤(Lâ€², Bâ€²) if L âŠ†Lâ€².
Deï¬nition: Let (L, B), (Lâ€², Bâ€²) âˆˆâ„C. It turns out that L + Lâ€² has an upper
bound. We turn it into a Dedekind cut using the aforementioned claim and get
(Lâ€²â€², Uâ€²â€²). Then (L, B) + (Lâ€², Bâ€²) = (Lâ€²â€², Uâ€²â€²).
Deï¬nition: Let (L, B), (Lâ€², Bâ€²) âˆˆâ„C. Now for each pair, 0 is in one of the two
sets L or B. (Just choose one if it is in both.) Choose the other set from each
pair, O and Oâ€². It turns out that O â‹…Oâ€² will either be bounded above or bounded
below. Either way, we turn it into a Dedekind cut using the appropriate
aforementioned claim and get (Lâ€²â€², Uâ€²â€²). Then (L, B) â‹…(Lâ€², Bâ€²) = (Lâ€²â€², Uâ€²â€²).
As we predicted, all this is completely impractical, but perfectly deï¬ned
nonetheless.
Claim: â„C forms a complete ordered ï¬eld.
The proof of this is long. Still some parts are very easy: the order on â„C
is transitive, it satisï¬es trichotomy, addition is associative and commutative.

292
15 Ordered Fields and the Real Numbers
Other parts are horribly tedious: multiplication is associative, and the
distributive rule. Surprisingly, the most frightening one is actually rather easy:
â„C is complete.
Let S âŠ†â„C. We can think of the lower parts of the elements of S as a family
of subsets of â„šindexed by the elements of S: Li with i âˆˆS. The condition that S
be bounded means that there is a Dedekind cut (M, P) so that âˆ€i âˆˆS, Li âŠ†M.
Then (
â‹ƒ
iâˆˆS
Li
)
âŠ†M.
(15.25)
So every element of P is an upper bound of that union. When we use the lemma
to turn the union into a Dedekind cut (Lâ€², Uâ€²), it is easy to see that the result is
an element of â„C that serves as a least upper bound of S.

293
16
Topology
16.1
Introduction
16.1.1
Preliminaries
Let A âŠ†â„. The deï¬nition of a subset gives a pretty black and white classi-
ï¬cation of real numbers in relation to the set A. For x âˆˆâ„, either x âˆˆA or
x âˆ‰A, and no real number x is both. This partitions â„into two disjoint pieces,
A and â„âˆ–A. This is nothing new, but it does oï¬€er a simple template for what
is to follow. We will point this out rather emphatically by stating an almost silly
theorem that needs absolutely no proof:
Theorem 16.1.1
(The Zeroth Partition Theorem). If A âŠ†â„, then
A âˆª(â„âˆ–A) = â„;
(16.1)
A âˆ©(â„âˆ–A) = âˆ….
We follow this with another theorem about the parts of this partition of the
real numbers that is just as simple, but it will come in handy as we introduce
more complicated partitions.
Theorem 16.1.2.
Let A âŠ†â„, and B âŠ†â„. Then
1. B âŠ†(â„âˆ–A) if and only if A âˆ©B = âˆ…;
2. â„âˆ–(â„âˆ–A) = A;
3. A âŠ†B implies (â„âˆ–B) âŠ†(â„âˆ–A).
We will set a very loose and informal description of our ï¬rst more reï¬ned
partition of the real numbers using a set A âŠ†â„. These ideas are more geomet-
ric than numeric; so instead of talking about numbers in â„, we will talk about
points on the real line. We will start with the interior of the set A. The interior
will be the set of points not just in A, but really inside A. (We said â€œa loose dis-
cussion.â€) The exterior of A will be the points in â„that are not in A, and in fact,
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

294
16 Topology
really outside A. The remaining points in â„may be in A; they may not be in A;
they are not really committed either way. The points not really in and not really
out are on the edge. They form the boundary of A.
This ï¬rst partition is set up using a model set of the form (3, 8]. Certainly,
6 should be in the interior of this set because it is smack dab inside. In addi-
tion, 112 should be in the exterior because it is really outside (3, 8]. If boundary
means what it should, 3 should be in the boundary as should 8. It should not
matter that 3 âˆ‰(3, 8], and 8 âˆˆ(3, 8]. The boundary should be made up of both.
Once we have formal deï¬nitions of these sets, we will prove that the interior,
the exterior, and the boundary of A partition all of â„. This will be â€œthe ï¬rst
partition theorem.â€
The second partition is more social than geometric. This time we think of a set
as a club where members always talk about the club (i.e., Boston Red Sox fans).
Some people are simply not in the club, and no one around them is in either.
They are in the exterior of the club if there is a group around them where no
one talks positively about the club (the locker room of Yankee Stadium). This is
the same exterior that appeared in the ï¬rst partition. Once you are really out,
then you are always really out.
There are always some people on the membership list of the club that are
isolated from the rest of the members. (For example, unfortunate Red Sox fans
who live in NYC.) They are in at least one social group where they are the only
club members. Once their neighborhood is small enough, they will have no one
to talk to about the club in that neighborhood. These isolated members are easy
to spot because they stick out like sore thumbs in the right sized neighborhood.
The second set in our partition will be made up of these isolated members.
But then who is left for a third part of the partition? The remaining people
may be in the club or not, but they have no way of avoiding members of the club.
Because they are not exterior and they are not isolated, every neighborhood
they are in, no matter how small, has members of the club. If they are in the
club, all their neighborhoods have another member of the club for them to talk
to about it. If they are not in the club, then all their neighborhoods will have a
member of the club who insists on talking about it. (For example, anyone living
in Boston proper, even if they love the Sox, hate the Sox, or simply do not care
about baseball.) This ï¬nal group are those in and out of the club who just cannot
avoid club members. They are people around whom the club members always
accumulate.
This second partition is set up using a model set of the form
A =
{
x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x = 1
n
}
.
(16.2)
We have seen this example before, and as before, we should draw a picture
of this set on the real line. Starting with n = 1, 2, 3, we put down dots for 1
n.
See Figure 16.1.

16.1 Introduction
295
Figure 16.1 x = 1
n.
1
1
5
1
4
1
3
1
2
0
Each dot is separated from the previous one, but the separation is getting
smaller and smaller, eventually too small to keep drawing. This is the kind of
set that the second partition is designed for. All the points of A are separated
from the other points of A. Even though the separation is getting smaller and
smaller forever, at any speciï¬c point, the separation is still there. We eventually
have to magnify our drawing to see it, but numerically
1
10347 is between
1
10348 and
1
10346, and no other points of A7 are in that gap. All the points of A are isolated.
Are there any points where A accumulates? If that has anything to do with the
English meaning of the word, the set should accumulate at 0. That should be
the only one. Everything else is exterior. Any point not in A âˆª{0) is far enough
away from the points of A to be really out zoomed into the right scale.
Once we have formal deï¬nitions of these sets, we will prove that the isolated
points, the exterior points, and the accumulation points of A partition all of â„.
This will be â€œthe second partition theorem.â€ These two partitions will provide
two distinct views of the original set A.
16.1.2
Neighborhoods
There is one relation between people that works quite well when applied to
the real numbers, but not as a mathematical relation. The idea behind this is
the notion of a neighbor. We can deï¬ne a relation on the set of all people by
saying that p is related to q if p is a neighbor of q. Most relations are useless
unless they have nice properties. Unfortunately, this particular relation does
not satisfy the mathematical property we like best: transitivity. We turn our
attention away from the relation â€œis a neighborâ€ and toward the set of people
called a neighborhood.
If a person is sitting in a cafe in Paris having a conversation with a stranger and
the stranger asks where they are from, they might answer, â€œthe United States.â€
A good answer, but a rather large neighborhood to use to identify oneself. That
same person in a hotel lobby in Chicago might recognize that the stranger has
already realized that they are from the United States. This time the answer
might be â€œPhiladelphiaâ€ or â€œTucson.â€ The smaller neighborhood better serves
its purpose. It is still a rather vague answer; the Philadelphia answer might mean
that the person was actually from southern New Jersey, across the river and
in another state from Philadelphia. If this conversation was taking place in a
plane headed toward Tucson, Arizona, a more speciï¬c answer might be â€œSam
Hughes,â€ â€œSummer Haven,â€ or â€œEl Rio.â€ These are more traditional uses of the
term â€œneighborhood.â€ There is no real limit to this; two residents of the same

296
16 Topology
high-rise might identify themselves as neighbors because they live on the same
ï¬‚oor. The advantage of the concept of neighborhood is its ï¬‚exibility of size. It
is only as small as it needs to be, but when it needs to be, it can be as tiny as
necessary.
We will make this idea mathematical by giving a precise deï¬nition to the
mathematical term neighborhood.
Deï¬nition 16.1.3.
Let a âˆˆâ„. Let ðœ€> 0. The ðœ€-neighborhood of a is deï¬ned
to be
N(a, ðœ€) = {x âˆˆâ„âˆ£|x âˆ’a| < ðœ€}.
(16.3)
We can also write this as
N(a, ðœ€) = (a âˆ’ðœ€, a + ðœ€).
(16.4)
Thus a number a âˆˆâ„has many, many neighborhoods. It has a neighborhood
for each ðœ€> 0; the smaller the ðœ€, the smaller the neighborhood. When we need
one, an ðœ€-neighborhood of a needs only to be as small as necessary for our pur-
pose, but it can usually be replaced by an even smaller one if that is convenient.
For reasons that will become clear later, we also want to deï¬ne a punctured
or deleted neighborhood.
Deï¬nition 16.1.4.
Let a âˆˆâ„. Let ðœ€> 0. The deleted ðœ€-neighborhood of a is
deï¬ned to be
Nâˆ—(a, ðœ€) = N(a, ðœ€) âˆ–{a}
(16.5)
= (a âˆ’ðœ€, a) âˆª(a, a + ðœ€).
Now we want all our neighborhoods, deleted or not, to be nonempty. For that
reason, the main duty of the radius ðœ€is to be a positive real number.
We have a few quick results about these neighborhoods that we will use quite
a bit.
Theorem 16.1.5.
Let a âˆˆâ„. Let 0 < ðœ€1< ðœ€2. Then
N(a, ðœ€1) âŠ†N(a, ðœ€2);
(16.6)
Nâˆ—(a, ðœ€1) âŠ†Nâˆ—(a, ðœ€2).
Proof. Assume 0 < ðœ€1< ðœ€2.
Comment: What are we proving? One set is a subset of the other. As an â€œifâ€¦
then,â€ this is â€œif x is in one set, then x is in the other.â€

16.1 Introduction
297
Assume x âˆˆN(a, ðœ€1). Then |x âˆ’a|< ðœ€1< ðœ€2. So x âˆˆN(a, ðœ€2). Thus, N(a, ðœ€1) âŠ†
N(a, ðœ€2). The proof is the same to show that Nâˆ—(a, ðœ€1) âŠ†Nâˆ—(a, ðœ€2); we just need
to add the assumption that x â‰ a, and this does not aï¬€ect the proof.
â—½
Corollary 16.1.6.
Let a âˆˆâ„. If ðœ€1 > 0 and ðœ€2 > 0. Then
N(a, ðœ€1) âˆ©N(a, ðœ€2) = N(a, ðœ€3)
(16.7)
where ðœ€3 = Min({ðœ€1, ðœ€2}).
Proof. Assume ðœ€1 > 0 and ðœ€2 > 0. Let ðœ€3 = Min({ðœ€1, ðœ€2}). Then ðœ€3 âˆˆ{ðœ€1, ðœ€2};
so ðœ€3 > 0.
Comment: Remember that being positive is epsilonâ€™s main job; we always need
to be sure it ï¬lls the requirement.
Since we are proving a set equality, we must show that N(a, ðœ€1) âˆ©N(a, ðœ€2) âŠ†
N(a, ðœ€3) and that N(a, ðœ€1) âˆ©N(a, ðœ€2) âŠ‡N(a, ðœ€3).
Claim. N(a, ðœ€1) âˆ©N(a, ðœ€2) âŠ‡N(a, ðœ€3).
Proof of claim. We have ðœ€3 â‰¤ðœ€1 and ðœ€3 â‰¤ðœ€2. So by Theorem 16.1.5,
N(a, ðœ€3) âŠ†N(a, ðœ€1);
(16.8)
N(a, ðœ€3) âŠ†N(a, ðœ€2).
So
N(a, ðœ€3) âŠ†N(a, ðœ€1) âˆ©N(a, ðœ€2).
(16.9)
â—¾
Claim. N(a, ðœ€1) âˆ©N(a, ðœ€2) âŠ†N(a, ðœ€3).
Proof
of
claim. Assume
x âˆˆN(a, ðœ€1) âˆ©N(a, ðœ€2).
Then
|x âˆ’a| < ðœ€1
and
|x âˆ’a| < ðœ€2. So |x âˆ’a| < Min({ðœ€1, ðœ€2}) = ðœ€3. So x âˆˆN(a, ðœ€3).
â—¾
We have now proved both N(a, ðœ€1) âˆ©N(a, ðœ€2) âŠ†N(a, ðœ€3) and N(a, ðœ€1) âˆ©
N(a, ðœ€2) âŠ‡N(a, ðœ€3). It follows that N(a, ðœ€1) âˆ©N(a, ðœ€2) = N(a, ðœ€3).
â—½
As it turns out, ðœ€-neighborhoods are just open intervals that are identiï¬ed by
their center and radius, instead of their ends. Thus,
Theorem 16.1.7.
Let a, b âˆˆâ„and ðœ–> 0. Then
1. N(a, ðœ€) = (a âˆ’ðœ€, a + ðœ€).
2. If a < b, then (a, b) = N
(
a+b
2 , bâˆ’a
2
)
.

298
16 Topology
Proof. Part 1 was seen already as Corollary 15.1.8. Here we will prove part 2.
Assume that a < b. We are asked to prove a set equality, so we must prove that
the subset holds in both directions.
Claim. (a, b) âŠ†N
(
a+b
2 , bâˆ’a
2
)
.
Proof of claim. Assume x âˆˆ(a, b). Then a < x < b. So
x âˆ’a + b
2
> a âˆ’a + b
2
= a âˆ’b
2
= âˆ’
(
b âˆ’a
2
)
;
(16.10)
x âˆ’a + b
2
< b âˆ’a + b
2
= b âˆ’a
2
.
Then since bâˆ’a
2
> 0,
Â±
(
x âˆ’a + b
2
)
< b âˆ’a
2
;
(16.11)
||||
x âˆ’a + b
2
||||
< b âˆ’a
2
.
So x âˆˆN
(
a+b
2 , bâˆ’a
2
)
.
â—¾
Claim. (a, b) âŠ‡N
(
a+b
2 , bâˆ’a
2
)
.
Proof of claim. Assume x âˆˆN
(
a+b
2 , bâˆ’a
2
)
. Then
x âˆˆ
(
a + b
2
âˆ’b âˆ’a
2
, a + b
2
+ b âˆ’a
2
)
(16.12)
âˆˆ(a, b).
â—¾
We have now proved that the subset holds in both directions. Thus, (a, b) =
N
(
a+b
2 , bâˆ’a
2
)
.
â—½
16.1.3
Interior, exterior, and boundary
We can use these neighborhood sets to ï¬nally give formal deï¬nitions of the
interior, the exterior, and the boundary of a set A.
We have already said that these ideas are more geometric than numeric. It
might be helpful to have a picture of the real line to guide us through these
deï¬nitions.
Deï¬nition 16.1.8.
Let A âŠ†â„. The interior of A is given by
Int(A) = {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†A}.
(16.13)

16.1 Introduction
299
The interior points of A are those points really inside of A. Not only are
they in A, but an entire neighborhood around them is in A. It may be a big
neighborhood (such as Philadelphia) or a small neighborhood (such as a
high-rise ï¬‚oor). But we get to say that x âˆˆInt(A) because not only does it
belong, but all of its neighbors belong as well. By deï¬nition, if x âˆˆInt(A),
then âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†A. But because there is no star, we always have
x âˆˆN(x, ðœ€). So Int(A) âŠ†A, and that certainly is something we want to be
true.
Another thing to note is that once we have x âˆˆInt(A), we have an ðœ€0 > 0
so that N(x, ðœ€0) âŠ†A. But because of the way neighborhoods work, this
ðœ€0-neighborhood is not unique. We know for sure that every smaller neigh-
borhood will also work: If ðœ€1< ðœ€0, then N(x, ðœ€1) âŠ†N(x, ðœ€0) âŠ†A. But also there
is nothing in the deï¬nition that requires that the ï¬rst ðœ€0 we identify be even
close to optimal in size. So there could just as well be there is an ðœ€2> ðœ€0 where
it still happens that N(x, ðœ€2) âŠ†A.
Deï¬nition 16.1.9.
Let A âŠ†â„. The exterior of A is given by
Ext(A) = {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†(â„âˆ–A)}.
(16.14)
The exterior points of A are those points really outside of A. Not only are
they outside of A, but an entire neighborhood around them is outside of A.
This time Ext(A) âˆ©A = âˆ…. So sure enough, no points that are in A ever end up
in the exterior.
Now it seems clear that the â€œzerothâ€ partition A and â„âˆ–A is going to play a
large part in our discussion. Because of the properties listed after this simple
partition, we can also write
Int(A) = {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âˆ©(â„âˆ–A) = âˆ…}
= {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†A}.
(16.15)
Ext(A) = {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âˆ©A = âˆ…}
= {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†(â„âˆ–A)}.
(16.16)
We also notice that
Ext(A) = Int(â„âˆ–A).
(16.17)
Now points that are between â€œreally inâ€ and â€œreally outâ€ must be on the
boundary. So, the set of points not in Int(A) and not in Ext(A) will be called
the boundary of A. A boundary point might be in the set, or it might not be.
There are two possible notations for this set. Here is the formal deï¬nition.

300
16 Topology
Deï¬nition 16.1.10.
Let A âŠ†â„. The boundary of A is given by
Bndy(A) = ðœ•(A)
(16.18)
= {x âˆˆâ„âˆ£âˆ€ðœ€> 0 , N(x, ðœ€) âˆ©(â„âˆ–A) â‰ âˆ…
and N(x, ðœ€) âˆ©A â‰ âˆ…}.
Notice that a boundary point might be in A, but it does not have to be there.
So there nothing to say for sure about ðœ•(A) âˆ©A or ðœ•(A) âˆ©(â„âˆ–A). Still it is clear
from the deï¬nition that
ðœ•(A) = ðœ•(â„âˆ–A).
(16.19)
This makes sense if boundary means what it should mean. Notice also that
these three sets account for every possible real number and that their deï¬-
nitions are mutually exclusive. This is important enough to state as a named
theorem.
Theorem 16.1.11
(The First Partition Theorem). For any A âŠ†â„, we have:
Int(A) âˆªðœ•(A) âˆªExt(A) = â„;
(16.20)
Int(A) âˆ©ðœ•(A) = âˆ…;
Int(A) âˆ©Ext(A) = âˆ…;
ðœ•(A) âˆ©Ext(A) = âˆ….
Proof. The proof simply boils down to writing the deï¬nitions of the sets in the
right way and applying De Morganâ€™s Laws for each of the three steps.
Int(A) = {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âˆ©(â„âˆ–A) = âˆ…};
(16.21)
Ext(A) = {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âˆ©A = âˆ…};
ðœ•(A) = {x âˆˆâ„âˆ£âˆ€ðœ€> 0, N(x, ðœ€) âˆ©(â„âˆ–A) â‰ âˆ…
and N(x, ðœ€) âˆ©A â‰ âˆ…}.
â—½
16.1.4
Isolated points and accumulation points
We now translate the ideas of the second partition into precise mathematical
deï¬nitions.
Really out is still really out; so we reuse our deï¬nition:
Ext(A) = {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âˆ©A = âˆ…}.
(16.22)
Next we deï¬ne isolated points of the set. Mathematicians use the term â€œdis-
creteâ€ more than â€œ isolated,â€ but both are common enough.

16.1 Introduction
301
Deï¬nition 16.1.12.
Let A âŠ†â„. The set of discrete (isolated) points of A is
given by
Aâˆ˜= {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âˆ©A = {x}}.
(16.23)
This says that x is a discrete point if there is a neighborhood about it in which
the only point in it and in A is the point x itself. Notice that the deï¬nition tells
us that when x âˆˆAâˆ˜, then x âˆˆN(x, ðœ€) âˆ©A âŠ†A. So for all sets A, Aâˆ˜âŠ†A.
Now discrete points of A and interior points are very diï¬€erent. No point can
possibly be both. But the neighborhoods in their deï¬nitions have something
in common. Once we have x âˆˆAâˆ˜, we have an ðœ€0 > 0 so that N(x, ðœ€0) âˆ©A =
{x}. But because of the way neighborhoods work, this ðœ€0-neighborhood is not
unique. We know for sure that every smaller neighborhood will also work: If
ðœ€1< ðœ€0, then N(x, ðœ€1) âˆ©A âŠ†N(x, ðœ€0) âˆ©A = {x}. In addition, there is nothing in
the deï¬nition that requires that the ï¬rst ðœ€0 we identify be even close to opti-
mal in size. So there could just as well be an ðœ€2> ðœ€0 where it still happens that
N(x, ðœ€2) âˆ©A = {x}.
We described the other points in our analogy as points that are not exterior
or isolated. We will call all points of â„that are not exterior or isolated the accu-
mulation points of A. As we learn more about them, this name will seem more
and more appropriate. For now, however, we just use logic to cover the rest of
â„. So x is an accumulation point of A if, for all neighborhoods, N(x, ðœ€) âˆ©A â‰ âˆ…
and N(x, ðœ€) âˆ©A â‰ {x}. The deï¬nition must be:
Deï¬nition 16.1.13.
Let A âŠ†â„. The set of accumulation points of A is
given by
Aâ€² = {x âˆˆâ„âˆ£âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ…}.
(16.24)
We have ï¬nally used our deleted neighborhood notation. To be an accumu-
lation point, it does not matter whether the point is in A or not; what matters is
what happens around it. The deï¬nition says that x is an accumulation point of
A if every neighborhood of A contains a point of A not equal to x. Now x need
not be in A to be an accumulation point of A. But if it is, every neighborhood
of x will have an element of A. In addition, x could be in A and not be an accu-
mulation point of A. (It could be an isolated point of A.) But if x is in A and Aâ€²,
then every neighborhood of x will have an element of A other than x.
Next we notice that the three sets Ext(A), Aâˆ˜, and Aâ€² have been deï¬ned so
as to account for every possible real number and so that their deï¬nitions are
mutually exclusive. We state this as
Theorem 16.1.14
(The Second Partition Theorem). For any A âŠ†â„,
we have:
Aâˆ˜âˆªAâ€² âˆªExt(A) = â„;
(16.25)

302
16 Topology
Aâˆ˜âˆ©Aâ€² = âˆ…;
Aâˆ˜âˆ©Ext(A) = âˆ…;
Aâ€² âˆ©Ext(A) = âˆ….
Proof. We assume that A âŠ†â„and write out the deï¬nitions:
Ext(A) = {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âˆ©A = âˆ…};
(16.26)
Aâˆ˜= {x âˆˆâ„âˆ£âˆƒðœ€> 0, N(x, ðœ€) âˆ©A = {x}};
Aâ€² = {x âˆˆâ„âˆ£âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ…}.
Since Nâˆ—(x, ðœ€) âˆ©A = âˆ…is the same as either Nâˆ—(x, ðœ€) âˆ©A = âˆ…or Nâˆ—(x, ðœ€) âˆ©A =
{x}, we simply use De Morganâ€™s Laws to complete the proof.
â—½
The two partitions we have found are mostly very diï¬€erent. But because they
cover all the points in â„, their parts must have some interactions. We will note
just one to start. The interior points of A cannot possibly be isolated or exte-
rior; so they should all be accumulation points. The proof is just a formalization
of the idea that, if N(x, ðœ€0) âŠ†A, then every smaller neighborhood N(x, ðœ€1) will
contain lots of points of A besides the center point x.
Theorem 16.1.15.
For all A âŠ†â„, Int(A) âŠ†Aâ€².
Proof. Assume x âˆˆInt(A). Then âˆƒðœ€1 > 0 such that N(x, ðœ€1) âŠ†A.
Comment: In many of these proofs, epsilons occur all over the place. It is a good
idea to start oï¬€with a more individualized name every time one pops up. What
are we proving now? x âˆˆA
â€². That is âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ…. We rewrite this
and prove it as an â€œifâ€¦ then.â€
Assume that we have a new ðœ€2 > 0. Let ðœ€3 = Min({ðœ€1, ðœ€2}). Then ðœ€3 > 0, and
N(x, ðœ€1) âˆ©N(x, ðœ€2) = N(x, ðœ€3). Then
Nâˆ—(x, ðœ€3) âŠ†Nâˆ—(x, ðœ€1);
(16.27)
Nâˆ—(x, ðœ€3) âŠ†Nâˆ—(x, ðœ€2).
So
Nâˆ—(x, ðœ€3) âˆ©A âŠ†Nâˆ—(x, ðœ€1) âˆ©A;
(16.28)
Nâˆ—(x, ðœ€3) âˆ©A âŠ†Nâˆ—(x, ðœ€2) âˆ©A.
But N(x, ðœ€1) âŠ†A; so Nâˆ—(x, ðœ€1) âˆ©A = Nâˆ—(x, ðœ€1). This means
Nâˆ—(x, ðœ€3) âŠ†Nâˆ—(x, ðœ€2) âˆ©A.
(16.29)

16.1 Introduction
303
Since ðœ€3 > 0, Nâˆ—(x, ðœ€3) is not empty. So we have shown that âˆ€ðœ€2 > 0,
Nâˆ—(x, ðœ€2) âˆ©A â‰ âˆ…. And so x âˆˆAâ€².
â—½
Remember though that we do not require that points of Aâ€² be in A; so we
expect that Aâ€² will contain many points that are not in the interior of A. (Not
all the people in Boston are actually Red Sox fans; but people in Boston just
cannot avoid Sox fans.)
16.1.5
The closure
There is one more subset of â„we deï¬ne using A. However, we cannot easily
describe it by giving a condition on the points it contains. Now Ext(A) is the set
of points really outside of A; so â„âˆ–Ext(A) will consist of any point remotely
connected to A. Or we may say that A âˆªðœ•(A) takes all the points in A and
adds the boundary; so it closes oï¬€A. We might consider A âˆªAâ€² as taking A
and including any points of â„where A accumulates enough to be included as
a point involved with the set. Any one of these would make an interesting set
associated with A. As it turns out, they are all the same. There are other descrip-
tions of this set that are just as natural. We need to choose one as the deï¬nition
for our next set; so we settle on the following.
Deï¬nition 16.1.16.
Let A âŠ†â„. The closure of A is given by
Cl(A) = Int(A) âˆªðœ•(A).
(16.30)
This is just one of many ways to describe the exact same set. We will list every
other description of this same set right away.
Theorem 16.1.17.
Let A âŠ†â„. Then
Cl(A) = Int(A) âˆªðœ•(A)
(16.31)
= A âˆªðœ•(A)
= â„âˆ–Ext(A)
= Aâˆ˜âˆªAâ€²
= A âˆªAâ€².
Proof. We will divide the proof into a series of parts, each of which shows some
equality or containment between the sets in the list.
Part 1. We claim that Cl(A) = Int(A) âˆªðœ•(A).
Proof of claim. This follows from the deï¬nition.
â—¾

304
16 Topology
Part 2. We claim that Int(A) âˆªðœ•(A) âŠ†A âˆªðœ•(A).
Proof of claim. Since Int(A) âŠ†A, we can union both sides with ðœ•(A) to get
Int(A) âˆªðœ•(A) âŠ†A âˆªðœ•(A).
â—¾
Part 3. We claim that A âˆªðœ•(A) âŠ†â„âˆ–Ext(A).
Proof of claim. Since Ext(A) = Int(â„âˆ–A) âŠ†(â„âˆ–A), we have A âŠ†â„âˆ–Ext(A).
The ï¬rst partition theorem tells us that ðœ•(A) âŠ†â„âˆ–Ext(A). So A âˆªðœ•(A) âŠ†
â„âˆ–Ext(A).
â—¾
Part 4. We claim that â„âˆ–Ext(A) âŠ†Int(A) âˆªðœ•(A).
Proof of claim. The ï¬rst partition theorem tells us that â„âˆ–Ext(A) âŠ†
Int(A) âˆªðœ•(A).
â—¾
These ï¬rst four parts together say that
Int(A) âˆªðœ•(A) âŠ†A âˆªðœ•(A)
(16.32)
âŠ†â„âˆ–Ext(A)
âŠ†Int(A) âˆªðœ•(A).
This shows that all three sets are equal.
Part 5. We claim that â„âˆ–Ext(A) = Aâˆ˜âˆªAâ€².
Proof of claim. The second partition theorem tells us that â„âˆ–Ext(A) = Aâˆ˜âˆª
Aâ€².
â—¾
Part 6. We claim that Aâˆ˜âˆªAâ€² âŠ†A âˆªAâ€².
Proof of claim. Since Aâˆ˜âŠ†A, we can union both sides with Aâ€² to get Aâˆ˜âˆªAâ€² âŠ†
A âˆªAâ€².
â—¾
Part 7. We claim that â„âˆ–Ext(A) = A âˆªAâ€².
Proof of claim. Again A âŠ†â„âˆ–Ext(A) and the second partition theorem says
that Aâ€² âŠ†â„âˆ–Ext(A). So A âˆªAâ€² âŠ†â„âˆ–Ext(A).
â—¾
This completes another loop, and so the sets in it are equal.
â—½
So we can get to the closure of a set in a number of diï¬€erent ways: we can take
the set A and add in either ðœ•(A) or Aâ€². Or we can lump together the interior and
the boundary. Or we can lump together the discrete points and the accumula-
tion points. What we cannot do is give one simple mathematical statement that
determines the points in the closure.

16.2 Examples
305
16.2
Examples
When we apply the aforementioned deï¬nitions to speciï¬c sets, some of the
associated sets are easier to ï¬nd than others. However, the two partition
theorems and the other relationships between the diï¬€erent sets can turn
one easy answer into several other answers quickly. If we identify any of the
sets quickly, we often make it easier to ï¬nd the others. One word of caution,
the exterior of a set can get pretty nasty to write down explicitly. There are
times when discretion wins out over valor. So after we try to write out Ext(A)
carefully and ï¬nd it pretty messy, we might just write Ext(A) = â„âˆ–Cl(A).
Finally, a drawing of a set A on the number line can be very helpful in working
with particular examples. We may not always include a drawing, but one is
always there in the scratch work.
Example 16.2.18.
Let A1 = (5, 7). Then
Int(A1) = (5, 7);
(16.33)
ðœ•(A1) = {5, 7};
Ext(A1) = (âˆ’âˆž, 5) âˆª(7, âˆž);
Cl(A1) = [5, 7].
The sets in the First Partition Theorem are designed with intervals in mind.
Aâˆ˜
1 = âˆ…;
(16.34)
Aâ€²
1 = [5, 7].
Discrete points in a set should â€œstick out like sore thumbs.â€ No points in this
interval are out on their own. The accumulation points are easy to ï¬nd, if
you remember that we already have the closure and the discrete points. Since
Cl(A) = Aâˆ˜âˆªAâ€², it is easy to identify Aâ€²
1. Once we have it, we check using the
deï¬nition to see that all the points do ï¬t the requirements.
Example 16.2.19.
Let A2 = (5, 7]. Then
Int(A2) = (5, 7);
(16.35)
ðœ•(A2) = {5, 7};
Ext(A2) = (âˆ’âˆž, 5) âˆª(7, âˆž);
Cl(A2) = [5, 7];
Aâˆ˜
2 = âˆ…;
Aâ€²
2 = [5, 7].

306
16 Topology
Example 16.2.20.
Let A3 = [5, 7]. Then
Int(A3) = (5, 7);
(16.36)
ðœ•(A3) = {5, 7};
Ext(A3) = (âˆ’âˆž, 5) âˆª(7, âˆž);
Cl(A3) = [5, 7];
Aâˆ˜
3 = âˆ…;
Aâ€²
3 = [5, 7].
Example 16.2.21.
Let A4 = (2, âˆž). Then
Int(A4) = (2, âˆž);
(16.37)
ðœ•(A4) = {2};
Ext(A4) = (âˆ’âˆž, 2);
Cl(A4) = [2, âˆž);
Aâˆ˜
4 = âˆ…;
Aâ€²
4 = [2, âˆž).
Those examples should give us a pretty good handle on intervals. Now let us
try our hand on a ï¬nite set.
Example 16.2.22.
Let A5 = {2, 4, 5, 7}. Then
Int(A5) = âˆ…;
(16.38)
ðœ•(A5) = {2, 4, 5, 7};
Cl(A5) = {2, 4, 5, 7};
Ext(A5) = â„âˆ–A5.
Now to have an interior that is not empty, a set must contain some intervals.
So that makes this example easy; there can be no interior. Once you see it, the
boundary is just as obvious. That leads to the closure, and while we could write
the exterior as a union of speciï¬c intervals, we are too lazy to do so. Next
Aâˆ˜
5 = {2, 4, 5, 7};
(16.39)
Aâ€²
5 = âˆ….
Discrete points stick out like sore thumbs, and if we draw this set on the real
line, we just have four lonely points. There they are, obviously isolated from
each other.

16.2 Examples
307
Example 16.2.23.
Let A6 = â„¤. Then
Int(A6) = âˆ…;
(16.40)
ðœ•(A6) = â„¤;
Cl(A6) = â„¤;
Ext(A6) =
â‹ƒ
nâˆˆâ„¤
(n âˆ’1, n);
Aâˆ˜
6 = â„¤;
Aâ€²
6 = âˆ….
The set has no intervals, so no interior. We are just showing oï¬€with that exte-
rior; we should have been perfectly satisï¬ed with â„âˆ–â„¤. The integers are dis-
crete. (Oh yeah, that is why we said this a long time ago.) Good old Aâ€²
6 is what
is left in the second partition, and that is nothing.
We have not seen an example where Aâ€² is of any real help in ï¬nding the other
sets. But that is about to end.
Example 16.2.24.
Let A7 =
{
x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x = 1
n
}
.
Again, we need to draw a picture of this set on the real line. Starting with
n = 1, 2, 3, we put down dots for 1
n (Figure 16.2).
Each dot is separated from the previous one, but the separation is getting
smaller and smaller, eventually too small to keep drawing. This is the kind of
set that the second partition is designed for. We will start with it.
Aâˆ˜
7 = A7.
All the points of A7 are separated from the others. Even though the separation
is getting smaller and smaller forever, at any speciï¬c point, the separation is still
there. We eventually have to magnify our drawing to see it, but numerically
1
10347
is between
1
10348 and
1
10346 and no other points of A7 are in that gap. But what
about Aâ€²
7? Are there any points where A7 accumulates? If that has anything to
do with the English meaning of the word, the set should accumulate at 0. Every
neighborhood of 0 has at least one number in A7 in it. All we need do is ï¬nd an
n âˆˆâ„•large enough. (Thank you, Archimedes.) Thus,
0 âˆˆAâ€²
7.
(16.41)
Figure 16.2 x = 1
n.
1
1
5
1
4
1
3
1
2
0

308
16 Topology
Every nonzero point is in A7, below 0, above 1, or in a gap between the points
of A7. Thus, 0 is the only accumulation point of A7. So
Aâ€²
7 = {0}.
(16.42)
After this
Cl(A7) = Aâˆ˜
7 âˆªAâ€²
7 = A7 âˆª{0}.
(16.43)
The complement of this looks horrible; so
Ext(A7) = â„âˆ–Cl(A7).
(16.44)
Now A7 contains no intervals, so
Int(A7) = âˆ….
(16.45)
But then since Cl(A7) = Int(A7) âˆªðœ•(A7), we must have
ðœ•(A7) = A7 âˆª{0}.
(16.46)
It would have been very easy to overlook the 0 in the boundary had we not
found Aâ€²
7 ï¬rst.
Now we mix things up a bit.
Example 16.2.25.
Let A8 = (3, 4] âˆª{5}. Then
Int(A8) = (3, 4);
(16.47)
ðœ•(A8) = {3, 4, 5};
Cl(A8) = [3, 4] âˆª{5};
Ext(A8) = (âˆ’âˆž, 3) âˆª(4, 5) âˆª(5, âˆž);
Aâˆ˜
8 = {5};
Aâ€²
8 = [3, 4].
Notice how 5 sticks out like a sore thumb, and also notice how the interval
accumulates at its ends and its interior.
Next we do the always interesting empty set, and follow it with all of â„.
Example 16.2.26.
Let A9 = âˆ…. Then
Int(A9) = âˆ…;
(16.48)
ðœ•(A9) = âˆ…;
Cl(A9) = âˆ…;
Ext(A9) = â„;
Aâˆ˜
9 = âˆ…;
Aâ€²
9 = âˆ….

16.2 Examples
309
Example 16.2.27.
Let A10 = â„. Then
Int(A10) = â„;
(16.49)
ðœ•(A10) = âˆ…;
Cl(A10) = â„;
Ext(A10) = âˆ…;
Aâˆ˜
10 = âˆ…;
Aâ€²
10 = â„.
We have saved the most interesting for last. Recall that one way to picture
the rational numbers as a subset of the real numbers is as a gray number line.
The gray is a warning that the irrational points are not points in the set, and the
white below them is shining through. This example deï¬nitely uses both versions
of the density theorem.
Example 16.2.28.
Let A11 = â„š. Then
Int(A11) = âˆ….
(16.50)
A consequence of the density theorem tells us that every interval contains real
numbers that are not rational. Thus, â„šcontains no complete intervals: no inter-
vals; no interior.
Next we consider Aâˆ˜
11. No rational numbers stick out like sore thumbs. The
density theorem tells us that every interval about any single point contains
many rational numbers; so every neighborhood of every real number contains
some rational numbers. No real numbers can be isolated from â„š.
Aâˆ˜
11 = âˆ….
(16.51)
It might not be clear what set to work on next, but in time we will see that Aâ€²
is actually very handy to have around. We consider Aâ€²
11. Now â„šis a gray â€“ but
still â€“ solid line in our picture because it has plenty of points, but also plenty
of holes. But the points have accumulated enough to look like a solid line. It
may look solid, but we know it is not complete. The density theorem tells us
that every interval about any single point contains many rational numbers, so
every neighborhood of every real number (rational or irrational) contains plenty
of rational numbers. All neighborhoods of all real numbers contain rational
numbers other than their centers. In other words,
Aâ€²
11 = â„.
(16.52)
Notice that the set of accumulation points has combined the accumulated stuï¬€
(â„š) and the accumulated nonstuï¬€(â„âˆ–â„š) to form a substantial thing (â„). With

310
16 Topology
these sets identiï¬ed, we are oï¬€to the races:
Cl(A11) = â„;
(16.53)
ðœ•(A11) = Int(A11) âˆªðœ•(A11) = Cl(A11) = â„;
Ext(A11) = âˆ….
Just to be safe, we will check these using the deï¬nitions. The density
theorem tells us that every interval contains rational numbers, but it also has
a consequence that also says that all intervals (x âˆ’ðœ€, x + ðœ€) contain at least
one irrational number. So neither â„šnor â„âˆ–â„šcontain any complete intervals
(x âˆ’ðœ€, x + ðœ€). Thus,
Int(A11) = âˆ…;
(16.54)
Ext(A11) = âˆ….
Again the density theorem says that all intervals (x âˆ’ðœ€, x + ðœ€) contain at least
one rational number. We know it also tells us that there are always two. So
all intervals (x âˆ’ðœ€, x + ðœ€) contain at least one rational number other than x,
whether x is rational or not. So
Aâˆ˜
11 = {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âˆ©â„š= {x}}
(16.55)
= âˆ….
But both (x âˆ’ðœ€, x) and (x, x + ðœ€) are true intervals in â„. Yet again, the density
theorem also tells us
Nâˆ—(x, ðœ€) âˆ©â„š= ((x âˆ’ðœ€, x) âˆª(x, x + ðœ€)) âˆ©â„š
(16.56)
= ((x âˆ’ðœ€, x) âˆ©â„š) âˆª((x, x + ðœ€) âˆ©â„š)
â‰ âˆ….
So every real number is in the set
Aâ€²
11 = {x âˆˆâ„âˆ£âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©â„šâ‰ âˆ…}.
(16.57)
The density theorem tells us that every interval contains rational numbers,
and it has a consequence that also says that all intervals (x âˆ’ðœ€, x + ðœ€) contain
at least one irrational number. So every real number is in the set
ðœ•(A11) = {x âˆˆâ„âˆ£âˆ€ðœ€> 0, N(x, ðœ€) âˆ©(â„âˆ–â„š) â‰ âˆ…and N(x, ðœ€) âˆ©â„šâ‰ âˆ…}.
(16.58)
In some sense, the statement â„= ðœ•(A11), is the full consequence of the density
theorem. Finally, by deï¬nition
Cl(A11) = Int(A11) âˆªðœ•(A11) = âˆ…âˆªâ„.
(16.59)

16.3 Open and Closed Sets
311
16.3
Open and closed sets
16.3.1
Deï¬nitions
Taking a clue from intervals, we will say that a subset of â„is open if it does not
include its boundary points, but closed if it does. There a lots of subsets of â„
and most of them are quite terrible. Topology is a way to pick out the best of
these subsets and put them to as much use as possible. The best subsets are the
ones that are either open or closed. There are plenty that are neither, but we
just have to live with that.
Of course, when we write deï¬nitions for open and closed sets, we choose
ones that make these notions easier to use in proofs.
Deï¬nition 16.3.1.
Let A âŠ†â„. We say that A is open when
âˆ€x âˆˆA, âˆƒðœ€> 0 such that N(x, ðœ€) âŠ†A.
(16.60)
Deï¬nition 16.3.2.
Let A âŠ†â„. We say that A is closed when
ðœ•(A) âŠ†A.
(16.61)
So closed is exactly what we want it to be, but open looks more like the deï¬-
nition of Int(A). We spend a lot of time proving that sets are open, and an equal
amount of time drawing conclusions about an open set. Our ï¬rst theorem about
open sets gives us plenty of choices on how to identify and to use open sets. We
really go overboard here to make each part of the proof pretty simple, but the
fact is that the more of these diï¬€erent views of open set we remember, the less
time we will spend reproving things.
Theorem 16.3.3.
Let A âŠ†â„. The following statements are equivalent.
1. A is an open set.
2. âˆ€x âˆˆA, âˆƒðœ€> 0 such that N(x, ðœ€) âŠ†A.
3. A âŠ†Int(A).
4. A = Int(A).
5. A âˆ©ðœ•(A) = âˆ….
6. â„âˆ–A is closed.
Proof. We will show that (1) â‡”(2) â‡’(3) â‡’(4) â‡’(5) â‡’(6) â‡’(2). We get the
ï¬rst one very easily: observe that (1) â‡”(2) because (2) is simply the deï¬nition
of open.
In each following step, assume that A âŠ†â„.
Step 1. We ï¬rst claim that (2) â‡’(3).

312
16 Topology
Proof of claim. Assume that âˆ€x âˆˆA, âˆƒðœ€> 0 such that N(x, ðœ€) âŠ†A. Then âˆ€x âˆˆ
A, x âˆˆInt(A). Thus, if (2) holds, then A âŠ†Int(A).
â—¾
Step 2. We now claim that (3) â‡’(4).
Proof of claim. Assume that (3) holds. That is, assume that A âŠ†Int(A). We
know that for all sets A, Int(A) âŠ†A. So here we have A = Int(A).
â—¾
Step 3. We now claim that (4) â‡’(5).
Proof of claim. Assume now that (4) is true. That is, assume A = Int(A). By the
ï¬rst partition theorem, Int(A) âˆ©ðœ•(A) = âˆ…. So A âˆ©ðœ•(A) = âˆ….
â—¾
Step 4. We now claim that (5) â‡’(6).
Proof of claim. Here assume (5) that A âˆ©ðœ•(A) = âˆ…. Then ðœ•(A) âŠ†â„âˆ–A. But
ðœ•(A) = ðœ•(â„âˆ–A). So ðœ•(â„âˆ–A) âŠ†â„âˆ–A. By deï¬nition â„âˆ–A is closed.
â—¾
Step 5. We ï¬nally claim that (6) â‡’(2).
Proof of claim. Assume that (6) holds. That is, assume â„âˆ–A is closed. So
ðœ•(â„âˆ–A) âŠ†â„âˆ–A. Then A âŠ†â„âˆ–(ðœ•(â„âˆ–A)).
Next assume x âˆˆA. Then x âˆ‰ðœ•(â„âˆ–A). So x âˆ‰ðœ•(â„âˆ–A) = ðœ•(A). Since x âˆ‰
ðœ•(A), âˆƒðœ€> 0 such that either
N(x, ðœ€) âˆ©A = âˆ…or N(x, ðœ€) âˆ©(â„âˆ–A) = âˆ….
(16.62)
However, x âˆˆN(x, ðœ€) âˆ©A; so we must have N(x, ðœ€) âˆ©(â„âˆ–A) = âˆ…. That is
N(x, ðœ€) âŠ†A.
â—¾
Since we have proved a sequence of implications that creates a circle, all the
statements are equivalent.
â—½
Notice that no one of these alone is hard to prove. But using the best version
of open in a proof can save us having to repeat several of the steps in this proof.
In addition, the more we know about open sets, the easier it is to prove things
about them.
Next we give the corresponding theorem about closed sets.
Theorem 16.3.4.
Let A âŠ†â„. The following statements are equivalent.
1. A is a closed set.
2. ðœ•(A) âŠ†A.
3. Cl(A) = A.
4. Cl(A) âŠ†A.

16.3 Open and Closed Sets
313
5. Aâ€² âŠ†A.
6. â„âˆ–A is open.
Proof. We will show that (1) â‡”(2) â‡’(3) â‡’(4) â‡’(5) â‡’(6) â‡’(1). We get the
ï¬rst one very easily: observe that (1) â‡”(2) because (2) is simply the deï¬nition
of closed.
In each following step assume that A âŠ†â„.
Step 1. We ï¬rst claim that (2) â‡’(3).
Proof of claim. Assume that (2) is true, that ðœ•(A) âŠ†A. Then A âˆªðœ•(A) = A. But
A âˆªðœ•(A) = Cl(A).
â—¾
Step 2. We now claim that (3) â‡’(4).
Proof of claim. Assume that (3) holds. That is, assume Cl(A) = A. Then
Cl(A) âŠ†A.
â—¾
Step 3. We now claim that (4) â‡’(5).
Proof of claim. Assume Cl(A) âŠ†A. But for all sets, Aâ€² âŠ†Cl(A). So Aâ€² âŠ†A.
â—¾
Step 4. We now claim that (5) â‡’(6).
Proof of claim. Assume Aâ€² âŠ†A. Let x âˆˆâ„âˆ–A. Now Aâ€² âŠ†A implies â„âˆ–A âŠ†
â„âˆ–Aâ€². So
x âˆ‰Aâ€² = {x âˆˆâ„âˆ£âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ…}.
(16.63)
Therefore, âˆƒðœ€> 0 s.t. Nâˆ—(x, ðœ€) âˆ©A = âˆ…. But then Nâˆ—(x, ðœ€) âŠ†â„âˆ–A. Since x âˆˆ
â„âˆ–A, we have
N(x, ðœ€) = Nâˆ—(x, ðœ€) âˆª{x} âŠ†â„âˆ–A.
(16.64)
Since âˆ€x âˆˆâ„âˆ–A, âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†â„âˆ–A, we have shown that â„âˆ–A is
open.
â—¾
Step 5. We ï¬nally claim that (6) â‡’(1).
Proof of claim. Assume â„âˆ–A is open. Then A = â„âˆ–(â„âˆ–A) is closed.
â—¾
Since we have proved a sequence of implications that creates a circle, all the
statements are equivalent.
â—½
Finally, we give a theorem and proof to illustrate a useful trick that takes
advantage of the neighborhoods that are used in all these deï¬nitions. When-
ever we have multiple neighborhoods of one point on the real line, we can avoid

314
16 Topology
cases by replacing them all with the smallest of the neighborhoods. All of our
deï¬nitions are designed so that this replacement will give us what we want.
Theorem 16.3.5.
Let A âŠ†â„. Then Aâˆ˜âŠ†ðœ•(A).
Proof draft. Assume A âŠ†â„. To prove our subset relation, assume x âˆˆAâˆ˜.
Then âˆƒðœ€1 > 0 so that N(x, ðœ€1) âˆ©A = {x}.
Since we need to prove x âˆˆðœ•(A), we must show that âˆ€ðœ€> 0, N(x, ðœ€) âˆ©
(â„âˆ–A) â‰ âˆ…and N(x, ðœ€) âˆ©A â‰ âˆ….
Comment: We must be careful here. We have found and named one ðœ€1 > 0 ear-
lier in the proof, and we need to prove something for all ðœ€> 0. We cannot use
the same name twice. So our next step is:
Assume that we have a new ðœ€2 > 0.
Comment: We now have two neighborhoods of x in our proof. One with radius
ðœ€1, which we know something about, and the other with radius ðœ€2, which we need
to prove something about. Unfortunately, we do not know which neighborhood
is larger. We could split the proof into cases, but there is a shorter way to choose
the smaller neighborhood.
Let ðœ€3 = Min({ðœ€1, ðœ€2}). Since the minimum is in the set, we know that ðœ€3 > 0.
We also know that ðœ€3 â‰¤ðœ€1 and ðœ€3 â‰¤ðœ€2, which tells us that N(x, ðœ€3) âŠ†N(x, ðœ€1)
and N(x, ðœ€3) âŠ†N(x, ðœ€2). We now can say that
x âˆˆN(x, ðœ€3) âˆ©A âŠ†N(x, ðœ€1) âˆ©A = {x}.
(16.65)
So
N(x, ðœ€3) âˆ©A = {x}.
(16.66)
First we see that x âˆˆA, and so x âˆˆN(x, ðœ€2) âˆ©A. And so N(x, ðœ€2) âˆ©A â‰ âˆ…. This
is half of what we need.
Next we see that y = x + ðœ€3
2 âˆˆN(x, ðœ€3), but y â‰ x. Since N(x, ðœ€3) âˆ©A = {x},
we know that y âˆ‰A. So y âˆˆâ„âˆ–A. We also have y âˆˆN(x, ðœ€3) âŠ†N(x, ðœ€2) So y âˆˆ
N(x, ðœ€2) âˆ©(â„âˆ–A) â‰ âˆ…. All of this shows that âˆ€ðœ€2 > 0, N(x, ðœ€2) âˆ©(â„âˆ–A) â‰ âˆ…
and N(x, ðœ€2) âˆ©A â‰ âˆ….
Î”
We will clean up the proof a bit.
Proof. Assume A âŠ†â„.
Then âˆƒðœ€1 > 0 so that N(x, ðœ€1) âˆ©A = {x}.
Assume ðœ€2 > 0.

16.3 Open and Closed Sets
315
Let ðœ€3 = Min({ðœ€1, ðœ€2}). Thus, ðœ€3 > 0; ðœ€3 â‰¤ðœ€1 and ðœ€3 â‰¤ðœ€2. So N(x, ðœ€3) âŠ†
N(x, ðœ€1) and N(x, ðœ€3) âŠ†N(x, ðœ€2). We now can say that
x âˆˆN(x, ðœ€3) âˆ©A âŠ†N(x, ðœ€2) âˆ©A = {x}.
(16.67)
So
N(x, ðœ€3) âˆ©A = {x}.
(16.68)
First we see that x âˆˆA, and so x âˆˆN(x, ðœ€2) âˆ©A. And so N(x, ðœ€2) âˆ©A â‰ âˆ….
Next we see that y = x + ðœ€3
2 âˆˆN(x, ðœ€3), but y â‰ x. Since N(x, ðœ€3) âˆ©A = {x},
we know that y âˆ‰A. So y âˆˆâ„âˆ–A. We also have y âˆˆN(x, ðœ€3) âŠ†N(x, ðœ€2). So
N(x, ðœ€2) âˆ©(â„âˆ–A) â‰ âˆ….
This shows that âˆ€ðœ€2 > 0, N(x, ðœ€2) âˆ©(â„âˆ–A) â‰ âˆ…and N(x, ðœ€2) âˆ©A â‰ âˆ…. We
have proved that x âˆˆðœ•(A).
â—½
16.3.2
Examples
We will return to our previous examples and use the results we obtained on the
ï¬rst pass.
Example 16.3.6.
Let A1 = (5, 7). Then Int(A1) = (5, 7), and ðœ•(A1) = {5, 7}. So
A1 is open, but not closed.
Example 16.3.7.
Let A2 = (5, 7]. Then Int(A1) = (5, 7), and ðœ•(A1) = {5, 7}. So
A2 is not open, and not closed.
Example 16.3.8.
Let A3 = [5, 7]. Then Int(A3) = (5, 7), and ðœ•(A1) = {5, 7}. So
A3 is not open, but A3 is closed.
Example 16.3.9.
Let A4 = (2, âˆž). Then Int(A4) = (2, âˆž), and ðœ•(A4) = {2}. So
A4 is open, but not closed.
So intervals work as expected.
Example 16.3.10.
Let A5 = {2, 4, 5, 7}. Then Int(A5) = âˆ…, and ðœ•(A5) =
{2, 4, 5, 7}. So A5 is not open, but A5 is closed.
Example 16.3.11.
Let A6 = â„¤. Then Int(A6) = âˆ…, and ðœ•(A6) = {2, 4, 5, 7}. So
A6 is not open, but A6 is closed.
Recall that there are cases where Aâ€² is easier to ï¬nd than ðœ•(A). We can check
Aâ€² instead of ðœ•(A) because of our theorem.
Example 16.3.12.
Let A7 = {x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x = 1
n}. Then Int(A7) = âˆ…,
and Aâ€²
7 = {0}. Thus A7 is not open and not closed.

316
16 Topology
This is interesting because Aâˆ˜
7 = A7. Even though this set is discrete, it is not
closed.
Example 16.3.13.
Let
A8 = (3, 4] âˆª{5}.
Then
Int(A8) = (3, 4),
and
ðœ•(A8) = {3, 4, 5}. Thus, A7 is not open and is not closed.
Example 16.3.14.
Let A9 = âˆ…. Then Int(A9) = âˆ…, and ðœ•(A9) = âˆ…. So âˆ…is both
open and closed! That is strange, but we just have to accept it.
Example 16.3.15.
Let A10 = â„. Then Int(A10) = â„, and ðœ•(A10) = âˆ…. So â„is
both open and closed.
Example 16.3.16.
Let A11 = â„š. Then Int(A11) = âˆ…, and Aâ€²
11 = â„. So â„šis nei-
ther open nor closed.
16.4
Problems
16.1
Prove that for all A âŠ†â„âˆ¶
(a) Int(A) âŠ†A.
(b) A âŠ†Cl(A).
(c) Aâˆ˜âŠ†A.
(d) Aâˆ˜âŠ†ðœ•(A).
(e) Int(A) âŠ†Aâ€².
16.2
Find the interior, boundary, closure, discrete points, and accumulation
points of the following sets. (The exteriors may be helpful, but you
need not write them out since â„âˆ–Cl(A) is as useful as anything more
explicit.) In addition, say if they are open or closed. (No proofs are
required, but you should deï¬nitely draw a picture and outline a proof
before you commit to an answer.)
(a) (2, 3) âˆª(5, 7).
(b) â„•.
(c) (âˆ’âˆž, 10) âˆ©â„¤.
(d) (âˆ’âˆž, 10) âˆªâ„¤.
(e) [âˆ’1, 1) âˆ©â„š.
(f) [âˆ’1, 1) âˆªâ„š.
(g)
{
x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x = n+2
n
}
. (Draw a picture of y = x+2
x in â„2.)
(h)
{
x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x =
n
âˆš
n2+1
}
. (Draw a picture in â„2.)
(i) {r2 âˆ£r âˆˆâ„š}. (Draw a picture in â„2.)
(j) {2n âˆ£n âˆˆâ„•.} (Draw a picture.)
(k) {2n âˆ£n âˆˆâ„¤}. (Draw a picture.)
(l) (0, âˆž) âˆ–â„š.

16.4 Problems
317
16.3
Let S =
{
x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x =
n
n+1
}
. Prove 1 âˆˆSâ€².
16.4
Let A âŠ†â„with A â‰ âˆ…. Prove that if A is bounded below, then Inf(A) âˆˆ
ðœ•(A).
16.5
Let A âŠ†â„. Prove that if B âŠ†A and B is open, then B âŠ†Int(A).
16.6
Let A âŠ†B âŠ†â„. Prove the following: (You may want to prove them in a
diï¬€erent order.)
(a) Int(A) âŠ†Int(B).
(b) Cl(A) âŠ†Cl(B).
(c) Aâ€² âŠ†Bâ€².
(d) Ext(B) âŠ†Ext(A).
16.7
Let A âŠ†B âŠ†â„. Why canâ€™t we use this to prove the following results?
(Give an example.)
(a) ðœ•(A) âŠ†ðœ•(B).
(b) Aâˆ˜âŠ†Bâˆ˜.
16.8
Prove that for all A âŠ†â„, Aâˆ˜âŠ†ðœ•(A).
16.9
Prove that if A âŠ†â„is bounded, then Aâ€² is bounded. (Hint: Use closed
intervals.)
16.10
Prove: If A, B âŠ†â„are both open, then A âˆ©B is open.
16.11
Let (a, b) âŠ†â„. Prove that (a, b) is open.
16.12
Prove: A âŠ†â„is open if and only if âˆ€x âˆˆA, âˆƒB with B open and
x âˆˆB âŠ†A.
16.13
Given a subset A âŠ†â„, there are three partitions of â„associated with
A: The 0th partition: A and â„âˆ–A. The ï¬rst partition: Int(A), ðœ•(A), and
Ext(A); the second partition: Aâ€², Aâˆ˜, and Ext(A). The sets in these par-
titions can be very diï¬€erent or very related.
(a) Identify as many interactions between the sets in these partitions
as you can. (Start with the relations in question 1.)
(b) Assume that the set A is open, add any extra relations to this list
from part (a).
(c) Assume that the set A is closed, add any extra relations to the list
from part (a).

319
17
Theorems in Topology
17.1
Summary of basic topology
Let A âŠ†â„. We deï¬ned two types of sets:
â€¢ A is open if âˆ€x âˆˆA, âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†A.
â€¢ A is closed if ðœ•(A) âŠ†A.
It is a simple fact that most subsets of â„are neither open nor closed. Still
associated with any subset A, we have deï¬ned six associated sets:
â€¢ Int(A) = {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†A}.
â€¢ ðœ•(A) = {x âˆˆâ„âˆ£âˆ€ðœ€> 0, N(x, ðœ€) âˆ©(â„\A) â‰ âˆ…and N(x, ðœ€) âˆ©A â‰ âˆ…}.
â€¢ Cl(A) = Int(A) âˆªðœ•(A).
â€¢ Aâ€² = {x âˆˆâ„âˆ£âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ…}.
â€¢ Aâˆ˜= {x âˆˆâ„âˆ£âˆƒðœ€> 0, N(x, ðœ€) âˆ©A = {x}}.
â€¢ Ext(A) = {x âˆˆâ„âˆ£âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†â„\A}.
Notice that the interior, exterior, and discrete points have â€œthere existsâ€
requirements; while the boundary and accumulation points have â€œfor allâ€
requirements. The closure, however, is not described by a condition on its
points.
There is a trivial partition of â„into two parts given by
â€¢ A âˆª(â„\A) = â„;
â€¢ A âˆ©(â„\A) = âˆ….
More important is the fact that there are two other topological partitions of
â„associated to A. The ï¬rst partition theorem says:
â€¢ Int(A) âˆªðœ•(A) âˆªExt(A) = â„.
â€¢ Int(A) âˆ©ðœ•(A) = âˆ….
â€¢ Int(A) âˆ©Ext(A) = âˆ….
â€¢ ðœ•(A) âˆ©Ext(A) = âˆ….
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

320
17 Theorems in Topology
The second partition theorem says:
â€¢ Aâˆ˜âˆªAâ€² âˆªExt(A) = â„.
â€¢ Aâˆ˜âˆ©Aâ€² = âˆ….
â€¢ Aâˆ˜âˆ©Ext(A) = âˆ….
â€¢ Aâ€² âˆ©Ext(A) = âˆ….
We have the following relationships between these sets in the diï¬€erent par-
titions that hold for all A âŠ†â„:
â€¢ Int(A) âŠ†A.
â€¢ A âŠ†Cl(A).
â€¢ Aâˆ˜âŠ†A.
â€¢ Aâˆ˜âŠ†ðœ•(A).
â€¢ Int(A) âŠ†Aâ€².
In addition,
â€¢ Ext(A) = Int(â„\A).
â€¢ Ext(â„\A) = Int(A).
â€¢ ðœ•(A) = ðœ•(â„\A).
As we noticed earlier, the closure is not described by a condition on its points.
However, to make up for this, the closure can be written in several diï¬€erent ways
other than the deï¬nition. We write down three:
â€¢ Cl(A) = A âˆªðœ•(A) = â„\Ext(A) = A âˆªAâ€².
Notice that the accumulation points and the boundary points both can be
used to close a set.
Some of the sets preserve subset relations, but others do not.
â€¢ If A âŠ†B, then Int(A) âŠ†Int(B).
â€¢ If A âŠ†B, then Cl(A) âŠ†Cl(A).
â€¢ If A âŠ†B, then Aâ€² âŠ†Bâ€².
â€¢ If A âŠ†B, then Ext(B) âŠ†Ext(A).
â€¢ We cannot be sure about ðœ•(A) and ðœ•(B) or about Aâˆ˜and Bâˆ˜. Notice that,
because Aâ€² âŠ†Bâ€², it often happens that accumulation points are a better path
to closure than boundary points.
There are several statements that are equivalent to A is open:
â€¢ A is open if and only if any of the following hold:
â€“ âˆ€x âˆˆA, âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†A.
â€“ A = Int(A).
â€“ A âˆ©ðœ•(A) = âˆ….
â€“ â„\A is closed.

17.2 New Results
321
As it turns out, in a proof, the deï¬nition is often the most important thing
about a set known to be open. Once we know that we have an element of an
open set, we almost always introduce a neighborhood around it. But to prove
that a set is open, any one of the other conditions might be the best way to
proceed.
There are also several diï¬€erent statements equivalent to A is closed:
â€¢ A is closed if and only if any of the following hold:
â€“ ðœ•(A) âŠ†A.
â€“ Aâ€² âŠ†A.
â€“ Cl(A) = A.
â€“ â„\A is open.
In practice, any one of these might be the most valuable in a particular case.
When proving that a set is closed, proving the complement is open is often a
good choice. The deï¬nition is the oï¬ƒcial deï¬nition because it is also useful.
One thing to remember is that, once we get used to them, accumulation points
are our friends. Because of their properties, the accumulation points of a closed
set often tell us important things about elements of the set.
17.2
New results
17.2.1
Unions and intersections
The fact is that interior, boundary, closure, accumulation points, discrete
points, and exterior typically mess up the union or the intersection of sets. So
there are no theorems about how these work on A âˆªB or A âˆ©B. However, the
terms open and closed work pretty well. We can easily prove that if A and B
are open, then both A âˆªB and A âˆ©B are also open. We can also prove that if A
and B are closed, then both A âˆªB and A âˆ©B are also closed. But we are after
bigger game.
Theorem 17.2.1.
Let Ai where i âˆˆîˆµbe a nonempty family of nonempty sets
such that âˆ€i âˆˆîˆµ, Ai is open. Then
â‹ƒ
iâˆˆîˆµ
Ai is open.
And
if îˆµis ï¬nite, then
â‹‚
iâˆˆîˆµ
Ai is open.
We split the proof of this into two proofs. First, we give a proof of the
ï¬rst conclusion in the statement that â‹ƒ
iâˆˆîˆµ
Ai is open; this proof is fairly

322
17 Theorems in Topology
straightforward. Following that we will give a draft proof of the second
conclusion of the proof before cleaning it up to give a ï¬nal proof of that part.
Here is a proof of the ï¬rst part.
Proof. Assume that Ai where i âˆˆîˆµbe a nonempty family of sets such that âˆ€i âˆˆ
îˆµ, Ai is open.
Assume x âˆˆâ‹ƒ
iâˆˆîˆµ
Ai. Then âˆƒix âˆˆîˆµsuch that x âˆˆAix. But Aix is open. So âˆƒðœ€x > 0
such that N(x, ðœ€x) âŠ†Aix. Since we have a union, Aix âŠ†â‹ƒ
iâˆˆîˆµ
Ai. So âˆƒðœ€x > 0 such that
N(x, ðœ€x) âŠ†â‹ƒ
iâˆˆîˆµ
Ai. Thus, the union is open.
â—½
This was simply a matter of assuming the right thing at the start and saying
what each statement meant until we reached the conclusion we wanted. We
just followed our logic as though we were doing an algebra calculation.
We now give a draft of a proof of the second claim in the theorem that if îˆµis
ï¬nite, then â‹‚
iâˆˆîˆµ
Ai is open.
Proof draft. Assume that îˆµis ï¬nite.
Comment: That is funny, but it must be important to the proof. We should be
sure that we use it somewhere.
Assume x âˆˆâ‹‚
iâˆˆîˆµ
Ai . Then âˆ€i âˆˆîˆµwe have x âˆˆAi.
Comment: Notice that, because of the â€œfor allâ€ construction, the i remains vari-
able. We can name it whatever we want, but not adding a subscript will help us
remember that it is a variable.
Now âˆ€i âˆˆîˆµ, Ai is open.
Comment: We might be tempted to say â€œSo âˆƒðœ€> 0 such that N(x, ðœ€) âŠ†Ai.â€ But
then i at the end is still a variable; we should carry its qualiï¬er with it. (Yet again,
we see the logical construction of an AE statement and notice its consequences.)
So we actually say:
So âˆ€i âˆˆîˆµ, âˆƒðœ€i > 0 such that N(x, ðœ€i) âŠ†Ai.
Comment: The qualiï¬er reminds us that there are lots of iâ€™s so there will be lots
of diï¬€erent epsilons â€“one for each set in the intersection.
What are we proving now? âˆƒðœ€> 0 such that N(x, ðœ€) âŠ†â‹‚
iâˆˆîˆµ
Ai. We need a word
problem to solve. We want one ðœ€> 0 so that N(x, ðœ€) âŠ†Ai for all i âˆˆI. We have

17.2 New Results
323
a bunch of ðœ€i > 0; so exactly which one do we want? The smallest, of course.
Whoops, we should say minimum.
Let E = {ðœ€i âˆ£i âˆˆîˆµ}.
Comment: Before we pick its minimum, we need to give a reason that it has one.
We assumed that the family of sets is not empty and that the sets in the family
are not empty; so E â‰ âˆ…. We also assumed that îˆµis ï¬nite; so E is ï¬nite. Thus, E
has a minimum. Let ðœ€= Min(E). Then ðœ€âˆˆE, so ðœ€> 0.
Comment: Thus, ðœ–fulï¬lls its main responsibility of being greater than 0.
In addition, âˆ€i âˆˆîˆµ, ðœ€â‰¤ðœ€i. Thus, âˆ€i âˆˆîˆµ, N(x, ðœ€) âŠ†N(x, ðœ€i) âŠ†Ai. So N(x, ðœ€) âŠ†
â‹‚
iâˆˆîˆµ
Ai.
Î”
We should rewrite this proof.
Proof. Assume that îˆµis ï¬nite and îˆµâ‰ âˆ…. Assume x âˆˆâ‹‚
iâˆˆîˆµ
Ai . Then âˆ€i âˆˆîˆµs.t.
x âˆˆAi. So
âˆ€i âˆˆîˆµ, âˆƒðœ€i > 0 s.t. N(x, ðœ€i) âŠ†Ai.
(17.1)
Let E = {ðœ€i âˆ£i âˆˆîˆµ}. Since îˆµis ï¬nite and not empty, E is ï¬nite and not empty.
Thus, E has a minimum. Let ðœ€= Min(E). Then ðœ€âˆˆE so ðœ€> 0. In addition,
âˆ€i âˆˆîˆµ, ðœ€â‰¤ðœ€i. Thus,
âˆ€i âˆˆîˆµ, N(x, ðœ€) âŠ†N(x, ðœ€i) âŠ†Ai.
(17.2)
So
N(x, ðœ€) âŠ†
â‹‚
iâˆˆîˆµ
Ai.
(17.3)
â—½
It is hard to miss the hypothesis that îˆµis ï¬nite in part 2 of this theorem. It says
that, while we can form union of open sets to our heartâ€™s content, we cannot get
carried away with the intersection of open sets. Consider the example:
â‹‚
x>0
(âˆ’x, x) = {0}.
(17.4)
This is true, because the only |y| that is less than x for all x > 0 is 0. (The
contrapositive of the average theorem.) All the sets in the family are open,
but the one element set that is their intersection is not. We just cannot let
ourselves get carried away with the intersection of open sets.
The next theorem is not unexpected.

324
17 Theorems in Topology
Theorem 17.2.2.
Let Bi where i âˆˆîˆµbe a nonempty family of sets such that
âˆ€i âˆˆîˆµ, Bi is closed. Then
â‹‚
iâˆˆîˆµ
Bi is closed.
and
If îˆµis ï¬nite, then
â‹ƒ
iâˆˆîˆµ
Bi is closed.
Before the proof a comment on proof technique.
Proof technique. Assume that Ai where i âˆˆîˆµbe a nonempty family of sets such
that âˆ€i âˆˆîˆµ, Ai is closed.
To prove that a set is closed, we must prove that it contains its boundary,
right? No we do not! We should not ignore all the hard work we have done prov-
ing theorems. Those theorems provide us with other choices. Just thinking about
proving that
ðœ•
(
â‹‚
iâˆˆîˆµ
Ai
)
âŠ†
â‹‚
iâˆˆîˆµ
Ai
(17.5)
is frightening. We must be able to use the results we have proved to make this
easier. What about accumulation points? That is probably just as bad. (But it
actually is not.) Remember that we should not expect any of the topological sets
associated with subsets of â„to work nicely on unions or intersections. The com-
plement is open? If we remember our set theory, this is deï¬nitely the way to go.
In fact, both parts end up with one-line proofs.
We now prove the theorem.
Proof. Assume that Bi where i âˆˆîˆµbe a nonempty family of sets such that
âˆ€i âˆˆîˆµ, Bi is closed. Notice then that âˆ€i âˆˆîˆµ, â„âˆ–Bi is open.
Part 1. We claim that â‹‚
iâˆˆîˆµ
Bi is closed.
Proof of Part 1. By the last theorem,â‹ƒ
iâˆˆîˆµ
(â„\Bi) is open. But by one of De Morganâ€™s
Laws,
â‹ƒ
iâˆˆîˆµ
(â„\Bi) = â„\
(
â‹‚
iâˆˆîˆµ
Bi
)
.
(17.6)
So â‹‚
iâˆˆîˆµ
Bi is closed.
â—¾

17.2 New Results
325
Part 2. We now claim that if îˆµis ï¬nite, then â‹ƒ
iâˆˆîˆµ
Bi is closed.
Proof of Part 2. Assuming that îˆµis ï¬nite, the last theorem says,â‹‚
iâˆˆîˆµ
(â„\Bi) is
open. But by one of De Morganâ€™s Laws,
â‹‚
iâˆˆîˆµ
(â„\Bi) = â„\
(
â‹ƒ
iâˆˆîˆµ
Bi
)
.
(17.7)
So â‹ƒ
iâˆˆîˆµ
Bi is closed.
â—¾
â—½
This is one place where remembering the proof makes important things
easy to remember. In time, we may recall these two theorems as â€œwe can
union or intersect families of open and closed sets, but sometimes we can
only take ï¬nitely many.â€ The trouble is remembering what case requires only
ï¬nitely many sets. The counterexample for open sets is not too bad, but the
counterexample for closed sets is so easy, it is almost impossible to forget.
For any set A,
A =
â‹ƒ
aâˆˆA
{a}.
(17.8)
Since not every set is closed, we can only take ï¬nitely many closed sets in a
union. So intersecting inï¬nitely many closed sets is OK. Since De Morganâ€™s
Laws switch unions and intersections, open sets work the other way around.
17.2.2
Open intervals are open
Our ï¬rst theorem basically must be true. Nevertheless, we need to prove it.
Theorem 17.2.3.
Let (a, b) âŠ†â„. Then (a, b) is an open set.
Proof draft. Assume (a, b) âŠ†â„. Then a < b.
Comment: What are we proving now? We are proving that âˆ€x âˆˆA, âˆƒðœ€> 0 such
that N(x, ðœ€) âŠ†(a, b).
Assume x âˆˆA. Then a < x < b.
Comment: What are we proving now? We are proving that âˆƒðœ€> 0 such that
N(x, ðœ€) âŠ†A. This means we have a word problem to set up and solve. We need
space around x small enough that it does not reach a or b. We need ðœ€to be smaller

326
17 Theorems in Topology
a
b
x
?
?
?
Figure 17.1 An open interval.
than either x âˆ’a or b âˆ’x. Since we do not know which is closer to x, a or b, maybe
we need cases. But if we realize that we want the one that is the smallest, we have
a way to choose this. As always, a good picture can help to solve a word problem
(Figure 17.1).
Now x âˆ’a > 0 and b âˆ’x > 0. Let ðœ€= Min({x âˆ’a, b âˆ’x}). Then ðœ€> 0;
ðœ€â‰¤x âˆ’a; and ðœ€â‰¤b âˆ’x.
Comment: Assuming that we have the right epsilon, what are we proving now?
N(x, ðœ€) âŠ†(a, b). OK, we know what to do.
Assume y âˆˆN(x, ðœ€). Then x âˆ’ðœ€< y < x + ðœ€.
First, ðœ€â‰¤b âˆ’x; so x + ðœ€â‰¤x + b âˆ’x = b. Second, ðœ€â‰¤x âˆ’a; so âˆ’ðœ€â‰¥a âˆ’x.
Then x âˆ’ðœ€â‰¥x + a âˆ’x = a. These two together say that
a â‰¤x âˆ’ðœ€< y < x + ðœ€â‰¤b.
(17.9)
So y âˆˆ(a, b). We have proved that y âˆˆN(x, ðœ€) implies y âˆˆ(a, b). So N(x, ðœ€) âŠ†
(a, b).
Î”
We should rewrite this, so it is easier to follow:
Proof. Assume (a, b) âŠ†â„. Then a < b. Assume x âˆˆA. Then a < x < b. Then
x âˆ’a > 0 and b âˆ’x > 0. Let ðœ€= Min({x âˆ’a, b âˆ’x}). Then ðœ€> 0; ðœ€â‰¤x âˆ’a;
and ðœ€â‰¤b âˆ’x.
Claim. N(x, ðœ€) âŠ†(a, b).
Proof of claim. Assume y âˆˆN(x, ðœ€). Then x âˆ’ðœ€< y < x + ðœ€. Then
a = a âˆ’(x âˆ’a) â‰¤a âˆ’ðœ€< y.
(17.10)
and
y < x + ðœ€â‰¤x + b âˆ’x = b.
(17.11)
So y âˆˆ(a, b). Thus, N(x, ðœ€) âŠ†(a, b).
â—¾
We have proved that x âˆˆ(a, b) implies âˆƒðœ€> 0 with N(x, ðœ€) âŠ†(a, b).
â—½

17.2 New Results
327
Corollary 17.2.4.
For all x âˆˆâ„and ðœ€> 0, N(x, ðœ€) is an open set.
Proof. For all x âˆˆâ„and ðœ€> 0, N(x, ðœ€) = (x âˆ’ðœ€, x + ðœ€).
â—½
Corollary 17.2.5.
For all x âˆˆâ„and ðœ€> 0, Nâˆ—(x, ðœ€) is open.
Proof. Nâˆ—(x, ðœ€) = (x âˆ’ðœ€, x) âˆª(x, x + ðœ€) is the union of two open sets.
â—½
17.2.3
Open subsets are in the interior
The proof of the next theorem is rather easy, but the result can save us a lot
of time in other proofs. Suppose that A is any set, and B and C are any two
subsets of A. It is unlikely that we can say anything general that would allow us
to conclude that B âŠ†C. But if B is open and C is the interior of A, things are
quite diï¬€erent.
Theorem 17.2.6.
Let A âŠ†â„. If B âŠ†A and B is open, then B âŠ†Int(A).
Proof. Assume B âŠ†A. Assume that B is open. Assume x âˆˆB. Then âˆƒðœ€> 0 s.t.
N(x, ðœ€) âŠ†B. But N(x, ðœ€) âŠ†B âŠ†A. Since âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†A, x âˆˆInt(A). So
B âŠ†Int(A).
â—½
This simple result has a series of rapid consequences.
Theorem 17.2.7.
For all A âŠ†â„, Int(A) is open.
Proof. Assume A âŠ†â„.
Comment: What are we proving now? We are proving that âˆ€x âˆˆInt(A), âˆƒðœ€> 0
such that N(x, ðœ€) âŠ†Int(A).
Assume x âˆˆInt(A). Then âˆƒðœ€> 0 such that N(x, ðœ€) âŠ†A.
Comment: We need to apply the exact deï¬nition. Now N(x, ðœ€) âŠ†A, but Int(A) is
probably smaller than A. How do we get this neighborhood into the smaller set?
Now N(x, ðœ€) is open, and N(x, ðœ€) âŠ†A; so by the theorem, we have
N(x, ðœ€) âŠ†Int(A).
(17.12)
Since âˆ€x âˆˆInt(A), âˆƒðœ€> 0 such that N(x, ðœ€) âŠ†Int(A), Int(A) is open.
â—½
Corollary 17.2.8.
For all A âŠ†â„, Ext(A) is open.
Proof. Ext(A) = Int(â„\A).
â—½

328
17 Theorems in Topology
Corollary 17.2.9.
For all A âŠ†â„, Cl(A) is closed.
Proof. Cl(A) = â„\Ext(A).
â—½
Corollary 17.2.10.
For all A âŠ†â„, ðœ•(A) is closed.
Proof. Assume A âŠ†â„. So Int(A) is open and Ext(A) is open. Then Int(A) âˆª
Ext(A) is open. But by the ï¬rst partition theorem,
ðœ•(A) = â„\(Int(A) âˆªExt(A)).
(17.13)
So ðœ•(A) is closed.
â—½
17.2.4
Topology and completeness
The next result begins to illustrate how the language of topology can help make
the completeness property of the real numbers easier to use.
Theorem 17.2.11.
Let A âŠ†â„.
1. If A has an inï¬mum, then Inf (A) âˆˆðœ•(A).
2. If A has a supremum, then Sup(A) âˆˆðœ•(A).
Proof draft. We will only prove one of these.
Assume m = Inf (A). Then âˆ€a âˆˆA, m â‰¤a. In addition, if l > m, then âˆƒa âˆˆA,
s.t. l > a.
Comment: We should draw a picture of this at least mentally. What are we
proving now? âˆ€ðœ€> 0, N(m, ðœ€) âˆ©A â‰ âˆ…, and N(m, ðœ€) âˆ©(â„\A) â‰ âˆ….
Assume ðœ€> 0.
Comment: We obviously need to use if l > m, then âˆƒa âˆˆA such that l > a. To do
this, we need something greater than m. All we have is ðœ€> 0.
Now m + ðœ€> m. So by the deï¬nition of inï¬mum, âˆƒa âˆˆA s.t. m + ðœ€> a.
However, since a âˆˆA, we also have m â‰¤a. So in fact, m âˆ’ðœ€< m â‰¤a < m + ðœ€.
So a âˆˆN(m, ðœ€) âˆ©A.
Comment: That is half of what we need.
From our mental picture, we need to ï¬nd something in N(m, ðœ€) that is not in
A. Anything below m will do as long as it is close enough. The value m âˆ’ðœ€catches
the edge of the neighborhood; so we use m âˆ’ðœ€
2.

17.3 Accumulation Points
329
Consider m âˆ’ðœ€
2. Since m âˆ’ðœ€
2 < m = Inf(A), m âˆ’ðœ€
2 âˆ‰A. In addition,
||||
(
m âˆ’ðœ€
2
)
âˆ’m
||||
= ðœ€
2 < ðœ€.
So
(
m âˆ’ðœ€
2
)
âˆˆ
N(m, ðœ€).
We
have
(
m âˆ’ðœ€
2
)
âˆˆ
N(m, ðœ€) âˆ©(â„\A).
Î”
Again, rewriting this will make it clearer.
Proof. We will only prove one of these.
Assume m = Inf (A). Then âˆ€a âˆˆA, m â‰¤a. In addition, if l > m, then âˆƒa âˆˆA,
such that l > a.
Assume ðœ€> 0.
Step 1. We claim N(m, ðœ€) âˆ©A â‰ âˆ….
Proof of Step 1. Now m + ðœ€> m. So by the deï¬nition of inï¬mum, âˆƒa âˆˆA, s.t.
m + ðœ€> a. However, since a âˆˆA,, we also have m â‰¤a. So in fact, m âˆ’ðœ€< m â‰¤
a < m + ðœ€. So a âˆˆN(m, ðœ€) âˆ©A.
â—¾
Step 2. We claim that N(m, ðœ€) âˆ©(â„\A) â‰ âˆ….
Proof of Step 2. Consider m âˆ’ðœ€
2. Since m âˆ’ðœ€
2 < m =Inf(A), m âˆ’ðœ€
2 âˆ‰A. In
addition, ||||
(
m âˆ’ðœ€
2
)
âˆ’m||||
= ðœ€
2 < ðœ€. So
(
m âˆ’ðœ€
2
)
âˆˆN(m, ðœ€). We have
(
m âˆ’ðœ€
2
)
âˆˆ
N(m, ðœ€) âˆ©(â„\A).
â—¾
These two steps prove m âˆˆðœ•(A).
â—½
17.3
Accumulation points
17.3.1
Accumulation points are aptly named
At ï¬rst, the accumulation points of a set might seem to be the least valuable of
the sets we have deï¬ned. However, accumulation points have extra properties
that make them very useful. We have already seen that
If A âŠ†B, then Aâ€² âŠ†Bâ€².
Because of this, accumulation points are often easier to use than boundary
points when working with closed sets. We will now see two easy-to-remember
properties of accumulation points with rather intricate proofs. These proofs
may seem to belie the notion that accumulation points are good things to work
with. However, Mathematics works by hiding intricate arguments in the proofs
of theorems and simply using the theorems. A theorem that is easy to state and
easy to remember but hard to prove is a good thing. We can use the result of
the theorem without redoing the diï¬ƒcult argument that makes it work.

330
17 Theorems in Topology
First, we prove that sets really do accumulate at their accumulation points.
By deï¬nition, x is an accumulation point of A if, for all ðœ€> 0, the deleted
neighborhood of x contains at least one point of A. The power of the qualiï¬er
â€œfor allâ€ gives us much more than one point. In fact, it guarantees that the
deleted neighborhood of x contains inï¬nitely many points of A. This is another
property that makes accumulation points easier to use than boundary points.
Both accumulation points and boundary points require that certain sets
be not empty: Nâˆ—(x, ðœ€) âˆ©A; N(x, ðœ€) âˆ©A; and N(x, ðœ€) âˆ©â„\A. However, there
are two sets to deal with for the boundary and only one for accumulation
points. In addition, proving that a set is nonempty means ï¬nding a point in
the set. This may be diï¬ƒcult if there is only one possible point in the set.
But knowing that an accumulation point guarantees that Nâˆ—(x, ðœ€) âˆ©A will be
inï¬nite means that there are inï¬nitely many choices for proving that it is not
empty.
Theorem 17.3.1.
Let A âŠ†â„. Then x âˆˆAâ€² if and only if âˆ€ðœ€> 0, N(x, ðœ€) âˆ©A is
inï¬nite.
Proof draft. This is a biconditional statement, so we have two directions to
prove. We take the easy direction ï¬rst.
(â‡). We claim that if âˆ€ðœ€> 0, N(x, ðœ€) âˆ©A is inï¬nite, then x âˆˆAâ€².
Proof of claim. Assume x âˆˆâ„s.t. âˆ€ðœ€> 0, N(x, ðœ€) âˆ©A is inï¬nite.
Comment: This tells that we know something if we ever have an ðœ€, but it does not
give us one. What are we proving now? x âˆˆAâ€². That is, âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ….
Since â€œfor allâ€ is essentially an â€œifâ€¦thenâ€ we get to make a new assumption.
Assume ðœ€1 > 0. Then N(x, ðœ€1) âˆ©A is inï¬nite. So (N(x, ðœ€1)\{x}) âˆ©A is also inï¬-
nite. But that set is Nâˆ—(x, ðœ€1) âˆ©A; so Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ….
â—¾
(â‡’). We now claim that if x âˆˆAâ€², then âˆ€ðœ€> 0, N(x, ðœ€) âˆ©A is inï¬nite.
Proof of claim. We will prove the contrapositive: if âˆƒðœ€> 0 such that N(x, ðœ€) âˆ©A
is ï¬nite, then x âˆ‰Aâ€².
Assume that âˆƒðœ€1 > 0 such that N(x, ðœ€1) âˆ©A is ï¬nite.
Comment: If we draw a picture of this (and we should), our ï¬rst concern is, â€œwhat
if there is nothing to draw?â€ That is, what if the set N(x, ðœ€1) âˆ©A is empty? That
is actually good for our proof. Our next concern is whether or not to draw x as
an element of the set. But that only reveals the real question, how many points

17.3 Accumulation Points
331
other than x are in the set? If there are none of these, that is just as good for us.
This reasoning leads us to three cases.
There are three possibilities: N(x, ðœ€1) âˆ©A = âˆ…, N(x, ðœ€1) âˆ©A = {x}, or
Nâˆ—(x, ðœ€1) âˆ©A is not empty but ï¬nite. We will prove that in each case x âˆ‰Aâ€².
Case 1: Assume N(x, ðœ€1) âˆ©A = âˆ…. Then x âˆˆExt(A); so x âˆ‰Aâ€².
Case 2: Assume N(x, ðœ€1) âˆ©A = {x}. Then x âˆˆAâˆ˜; so x âˆ‰Aâ€².
Case 3: Assume Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…, and it is ï¬nite.
Comment: What are we proving now? x âˆ‰Aâ€². But we know how to do this, we
prove that âˆƒðœ€> 0 s.t. N(x, ðœ€) âˆ©A is either empty or contains only x. The issue is
how far x is from the nearest point of A.
Nearest means shortest distance or minimum distance. So we know what
to do.
Let
D = {ðœ€> 0 âˆ£âˆƒa âˆˆNâˆ—(x, ðœ€1) âˆ©A s.t. ðœ€= |x âˆ’a|}.
(17.14)
Because Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…, we know that D â‰ âˆ…. Because Nâˆ—(x, ðœ€1) âˆ©A is ï¬nite,
we know that D is ï¬nite. In addition, because x âˆ‰Nâˆ—(x, ðœ€1) âˆ©A, we know that
âˆ€ðœ€âˆˆD, ðœ€> 0. Because of this, D has a minimum. Call it ðœ€2.
Then ðœ€2 âˆˆD; so ðœ€2 > 0.
And âˆ€ðœ€âˆˆD, ðœ€2 â‰¤ðœ€.
Comment: What are we proving now? We are proving that âˆƒðœ€> 0 s.t. N(x, ðœ€) âˆ©A
is either empty or contains only x. If our picture is right, ðœ€2 will work.
Claim. Nâˆ—(x, ðœ€2) âˆ©A = âˆ….
Proof of Claim. Comment: We know how to prove that a set is empty.
Assume BWOC y âˆˆNâˆ—(x, ðœ€2) âˆ©A.
Comment: Is y âˆˆNâˆ—(x, ðœ€1) âˆ©A? Well do we know ðœ€2â‰¤ðœ€1? We have not said so,
but can we prove it now?
Since Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…, we can let z âˆˆNâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…. Then z âˆˆNâˆ—(x, ðœ€1);
so |x âˆ’z|< ðœ€1.
But z âˆˆNâˆ—(x, ðœ€1) âˆ©A. So we also have
|x âˆ’z| âˆˆD = {ðœ€> 0 âˆ£âˆƒa âˆˆNâˆ—(x, ðœ€1) âˆ©A s.t. ðœ€= |x âˆ’a|}.
(17.15)
So ðœ€2 = Min(D) â‰¤|x âˆ’z|< ðœ€1.
Then we have Nâˆ—(x, ðœ€2) âŠ†Nâˆ—(x, ðœ€1).

332
17 Theorems in Topology
Comment: But we are asking, is y âˆˆNâˆ—(x, ðœ€1) âˆ©A?
We know that
y âˆˆNâˆ—(x, ðœ€2) âˆ©A âŠ†Nâˆ—(x, ðœ€1) âˆ©A.
(17.16)
And then
|x âˆ’y| âˆˆD = {ðœ€> 0 âˆ£âˆƒa âˆˆNâˆ—(x, ðœ€1) âˆ©A s.t. ðœ€= |x âˆ’a|}.
(17.17)
So ðœ€2 = Min(D) â‰¤|x âˆ’y|. But
y âˆˆNâˆ—(x, ðœ€2) âˆ©A âŠ†Nâˆ—(x, ðœ€1);
(17.18)
also means that |x âˆ’y|< ðœ€1. We have now proved that ðœ€1 â‰¤|x âˆ’y|< ðœ€1 and that
is a contradiction.
â—¾
Now Nâˆ—(x, ðœ€2) âˆ©A = âˆ…. So there are only two possibilities for N(x, ðœ€2) âˆ©A:
either N(x, ðœ€2) âˆ©A = âˆ…or N(x, ðœ€2) âˆ©A = {x}. In the ï¬rst case, x âˆˆExt(A), so
x âˆ‰Aâ€². In the second case, x âˆˆAâˆ˜; so x âˆ‰Aâ€². Either way, x âˆ‰Aâ€². Thus, in all
three cases, if âˆƒðœ€> 0 such that N(x, ðœ€) âˆ©A is ï¬nite, then x âˆ‰Aâ€²
â—¾
We have now proved both directions of the theorem. That is, x âˆˆAâ€² if and
only if âˆ€ðœ€> 0, N(x, ðœ€) âˆ©A is inï¬nite.
Î”
This deï¬nitely needs to be rewritten.
Proof. This is a biconditional statement, so we have two directions to prove.
For both parts, assume A âŠ†â„. We do the easy direction ï¬rst.
(â‡). We claim that if âˆ€ðœ€> 0, N(x, ðœ€) âˆ©A is inï¬nite, then x âˆˆAâ€².
Proof of claim. Assume x âˆˆâ„such that âˆ€ðœ€> 0, N(x, ðœ€) âˆ©A is inï¬nite. Assume
ðœ€1 > 0. Then by our hypothesis, N(x, ðœ€1) âˆ©A is inï¬nite. So (N(x, ðœ€1)\{x}) âˆ©A
is also inï¬nite. But that is Nâˆ—(x, ðœ€1) âˆ©A; so Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…. So for all ðœ€1 > 0,
Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…. So x âˆˆAâ€².
â—¾
(â‡’). We now claim that if x âˆˆAâ€², then âˆ€ðœ€> 0, N(x, ðœ€) âˆ©A is inï¬nite.
Proof of claim. To prove
if x âˆˆAâ€² , then âˆ€ðœ€> 0, N(x, ðœ€) âˆ©A is inï¬nite,
We will prove the contrapositive:
If âˆƒðœ€> 0 such that N(x, ðœ€) âˆ©A is ï¬nite, then x âˆ‰Aâ€².
Assume that âˆƒðœ€1 > 0 s.t. N(x, ðœ€1) âˆ©A is ï¬nite.
There are three possibilities: N(x, ðœ€1) âˆ©A = âˆ…, N(x, ðœ€1) âˆ©A = {x}, or
Nâˆ—(x, ðœ€1) âˆ©A is not empty but ï¬nite.
Case 1: Assume N(x, ðœ€1) âˆ©A = âˆ…. Then x âˆˆExt(A); so x âˆ‰Aâ€².
Case 2: Assume N(x, ðœ€1) âˆ©A = {x}. Then x âˆˆAâˆ˜; so x âˆ‰Aâ€².

17.3 Accumulation Points
333
Case 3: Assume Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…, and it is ï¬nite. Let
D = {ðœ€> 0 âˆ£âˆƒa âˆˆNâˆ—(x, ðœ€1) âˆ©A s.t. ðœ€= |x âˆ’a|}.
(17.19)
Because Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…, we know that D â‰ âˆ….
Because Nâˆ—(x, ðœ€1) âˆ©A is ï¬nite, we know that D is ï¬nite.
Because x âˆ‰Nâˆ—(x, ðœ€1) âˆ©A, we know âˆ€ðœ€âˆˆD, ðœ€> 0.
Because of this, D has a minimum. Call it ðœ€2. Then ðœ€2 âˆˆD; so ðœ€2 > 0 and
âˆ€ðœ€âˆˆD, ðœ€2 â‰¤ðœ€.
Notice that because Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…, we can ï¬nd z âˆˆNâˆ—(x, ðœ€1) âˆ©A. Then
z âˆˆNâˆ—(x, ðœ€1); so |x âˆ’z|< ðœ€1. But we also have |x âˆ’z| âˆˆD; so ðœ€2 = Min(D) â‰¤
|x âˆ’z|< ðœ€1. Thus, we have ðœ€2< ðœ€1, and in turn, Nâˆ—(x, ðœ€2) âŠ†Nâˆ—(x, ðœ€1).
We now claim that Nâˆ—(x, ðœ€2) âˆ©A = âˆ….
To see this, assume BWOC y âˆˆNâˆ—(x, ðœ€2) âˆ©A. So y âˆˆNâˆ—(x, ðœ€2) âˆ©A âŠ†
Nâˆ—(x, ðœ€1) âˆ©A.
Then |x âˆ’y| âˆˆD. So ðœ€2 = Min(D) â‰¤|x âˆ’y|.
But y âˆˆNâˆ—(x, ðœ€2) âˆ©A âŠ†Nâˆ—(x, ðœ€2); so |x âˆ’y|< ðœ€2. We have now proved that
ðœ€1 â‰¤|x âˆ’y|< ðœ€1 and that is a contradiction. Thus, we must have Nâˆ—(x, ðœ€2) âˆ©
A = âˆ….
Now we summarize the three cases. If we assume that Nâˆ—(x, ðœ€1) âˆ©A is ï¬nite,
there are only three possibilities for N(x, ðœ€1) âˆ©A: N(x, ðœ€1) âˆ©A = âˆ…or N(x, ðœ€1) âˆ©
A = {x} or N(x, ðœ€1) âˆ©A has ï¬nitely many elements that are not x. In the ï¬rst
case, x âˆˆExt(A), so x âˆ‰Aâ€². In the second case, x âˆˆAâˆ˜; so x âˆ‰Aâ€². In the third
case, the distance between x and the closest other point in N(x, ðœ€1) âˆ©A sepa-
rates x from the rest of A; so x is a discrete point and x âˆ‰Aâ€². Thus, we have
proved that if âˆƒðœ€> 0 such that N(x, ðœ€) âˆ©A is ï¬nite, then x âˆ‰Aâ€².
â—¾
This proves both directions of our biconditional, so we have proved that
x âˆˆAâ€² if and only if âˆ€ðœ€> 0, N(x, ðœ€) âˆ©A is inï¬nite.
â—½
17.3.2
For all A âŠ†â„, Aâ€² is closed
Earlier we proved that for any A âŠ†â„, Int(A) and Ext(A) are open, and ðœ•(A)
and Cl(A) are closed. There are two sets associated to A remaining: the discrete
points A and the accumulation points Aâ€². The discrete points are missing for a
reason. It is easy to realize why we cannot say that for all A âŠ†â„, Aâˆ˜is open. It is
actually hard to think of a particular A where Aâˆ˜is open. But why do we not say
that Aâˆ˜is closed? There is one important example that we should always keep
in our pocket. We have seen it before (Figure 17.2).
Let
A =
{
x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x = 1
n
}
.
(17.20)
The topological sets associated with A are
Int(A) = âˆ…;
(17.21)

334
17 Theorems in Topology
1
1
5
1
4
1
3
1
2
0
Figure 17.2 x = 1
n.
Aâˆ˜=
{
x âˆˆâ„âˆ£âˆƒn âˆˆâ„•s.t. x = 1
n
}
;
Aâ€² = {0};
CL(A) = A âˆª{0};
ðœ•(A) = A âˆª{0}.
The set Aâˆ˜= A is not closed; it has 0 as an accumulation point. Since 0 âˆ‰Aâˆ˜,
and 0 âˆˆ(Aâˆ˜)â€², it cannot be closed. One example kills the general theorem.
The accumulation points of A are a diï¬€erent story. We can prove that, for all
A âŠ†â„, Aâ€² is closed. The proof is long no matter how we approach it, but it is
worth the eï¬€ort to see how far we can push an idea. Constructing the best proof
requires trying everything and seeing what works best. Some approaches will
bog down without any possibility of success; others we can push through to a
conclusion. The best proof is the one that seems to be the easiest to reconstruct.
We will take the trouble to try several alternatives just to see what happens.
Theorem 17.3.2.
For all A âŠ†â„, Aâ€²is closed.
First, we just try the deï¬nition: Aâ€² is closed if ðœ•(Aâ€²) âŠ†Aâ€². This is the deï¬nition
because, when it works, it works quickly. However, if it starts to get out of hand,
it is often a good idea to change from boundary points to accumulation points.
Attempt 1. We will prove that ðœ•(Aâ€²) âŠ†Aâ€².
Proof draft. Assume x âˆˆðœ•(Aâ€²). Then
âˆ€ðœ€> 0, N(x, ðœ€) âˆ©Aâ€² â‰ âˆ…and N(x, ðœ€) âˆ©(â„\Aâ€²) â‰ âˆ….
(17.22)
Comment: To put this to use, we will have to have an ðœ€> 0 appear somewhere in
the proof. What are we proving now? x âˆˆAâ€². That is, âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ….
So we have our next step.
Assume ðœ€1 > 0.
Comment: It is always a good idea to give subscripts to numbers we know exist.
This is a good assumption because it allows us to use the constant ðœ€1 as a value
for variable ðœ€we said we were looking for to use or ï¬rst assumption.

17.3 Accumulation Points
335
So
N(x, ðœ€1) âˆ©Aâ€² â‰ âˆ…and N(x, ðœ€1) âˆ©(â„\Aâ€²) â‰ âˆ….
(17.23)
Comment: But now what are we proving? Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…. How do we show
that a set is not empty? We ï¬nd an element in it. We are proving that something
exists. We need to set up a word problem and solve it.
We need y âˆˆNâˆ—(x, ðœ€1) âˆ©A.
What do we know? There is something in N(x, ðœ€1) âˆ©Aâ€² â‰ âˆ…and something else
in N(x, ðœ€1) âˆ©(â„\Aâ€²) â‰ âˆ….
It is not clear why either of those should give us something in A. This might be
a good place to give up and prove that Aâ€² is closed in a diï¬€erent way. Normally,
that is exactly what we would do and only return to this approach if we had no
other choice.
But, out of pure masochism, we will just be pig-headed and root ahead! So oï¬€
we go . . . .
We need to ï¬nd something in A. Of the two facts we have, N(x, ðœ€1) âˆ©Aâ€² â‰ âˆ…
looks like it might give us something in A. This is because the deï¬nition of accu-
mulation points says:
Aâ€² = {x âˆˆâ„âˆ£âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ…}.
(17.24)
The set condition Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ…gives us something in A.
We will see what happens if we use N(x, ðœ€1) âˆ©Aâ€² â‰ âˆ….
Since N(x, ðœ€1) âˆ©Aâ€² â‰ âˆ…, we can let z âˆˆN(x, ðœ€1) âˆ©Aâ€². Then z âˆˆN(x, ðœ€1) and
z âˆˆAâ€². So
âˆ€ðœ€> 0, Nâˆ—(z, ðœ€) âˆ©A â‰ âˆ….
(17.25)
Comment: We only have one small number so far, ðœ€1. We can use it as this last
variable to say that Nâˆ—(z, ðœ€1) âˆ©A â‰ âˆ…. We might guess that this is the y we are
looking for. But we want y âˆˆNâˆ—(x, ðœ€1) âˆ©A, and this gives us y âˆˆNâˆ—(z, ðœ€1) âˆ©A.
Unless we know that Nâˆ—(z, ðœ€1) âŠ†Nâˆ—(x, ðœ€1), it will not work. We need a smaller
neighborhood of z for this to be true. This epsilon and its y are simply not going
to work. We need to ï¬nd a smaller ðœ€.
We have z âˆˆN(x, ðœ€1). This is an open set.
Comment: The proof would have gotten even worse if we did not remember this.
So âˆƒðœ€2 > 0 such that N(z, ðœ€2) âŠ†N(x, ðœ€1).
Comment: Let us use this ï¬xed ðœ€2 as a value for the variable ðœ€in our last â€œfor
allâ€: âˆ€ðœ€> 0, Nâˆ—(z, ðœ€) âˆ©A â‰ âˆ….

336
17 Theorems in Topology
Then Nâˆ—(z, ðœ€2) âˆ©A â‰ âˆ…. Let y âˆˆNâˆ—(z, ðœ€2) âˆ©A. Then
y âˆˆNâˆ—(z, ðœ€2) âˆ©A
âŠ†N(z, ðœ€2) âˆ©A
âŠ†N(x, ðœ€1) âˆ©A.
(17.26)
Comment: This is pretty close, we have y âˆˆN(x, ðœ€1) âˆ©A, but we need
y âˆˆNâˆ—(x, ðœ€1) âˆ©A. We need y â‰ x.
Unfortunately, is does look like x = y can happen. So this looks like a good
place to give up; and normally, we probably would.
But we are still being pig-headed, and surrendering is not an option. We need to
ï¬nd a way to avoid y = x. We will look back on what we have for help. We came
up with y because Nâˆ—(z, ðœ€2) âˆ©A â‰ âˆ…. We know that y âˆˆNâˆ—(x, ðœ€1) âˆ©A because
N(z, ðœ€2) âŠ†N(x, ðœ€1). If we knew that Nâˆ—(z, ðœ€2) âŠ†Nâˆ—(x, ðœ€1), that would be better.
So we wish we knew z â‰ x. Now we came up with z because N(x, ðœ€1) âˆ©Aâ€² â‰ âˆ….
So z âˆˆAâ€². But from the beginning we have been trying to prove that x âˆˆAâ€². So if
z = x, we would be done. If not, we would have our wish and also be done. So we
are done, it appears. Somewhere in this mess is a complete proof. It only barely
deserves a rewrite!
Î”
To ï¬nd our proof, we start over completely. As we go, we need to look for
places where we can rewrite our ï¬nal observations more logically. When we
try to prove complicated things, our ï¬rst attempt at a logical proof often goes
astray. If we think we are close, we need to be willing to start over adding in
what we have learned as we go. It may take three or four attempts before we
actually get to the end.
Attempt 1 (again). We will prove that ðœ•(Aâ€²) âŠ†Aâ€².
Proof. Assume x âˆˆðœ•(Aâ€²).
Then âˆ€ðœ€> 0, N(x, ðœ€) âˆ©Aâ€² â‰ âˆ…and N(x, ðœ€) âˆ©(â„\Aâ€²) â‰ âˆ….
Claim. âˆ€ðœ€1 > 0, Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ….
Comment: After all, we want to prove that x âˆˆAâ€²; why not just claim it and then
prove it?
Proof of claim. Assume ðœ€1 > 0. Then letting ðœ€= ðœ€1 in the last statement, we have
N(x, ðœ€1) âˆ©Aâ€² â‰ âˆ…and N(x, ðœ€1) âˆ©(â„\Aâ€²) â‰ âˆ….
Comment: We recall that it was the ï¬rst of these that we wanted to use.
Since N(x, ðœ€1) âˆ©Aâ€² â‰ âˆ…, let z âˆˆN(x, ðœ€1) âˆ©Aâ€². Then z âˆˆN(x, ðœ€1) and z âˆˆAâ€².

17.3 Accumulation Points
337
Comment: We now remember that the issue is whether z = x or not. Since that
is an â€œor,â€ we should try cases.
There are two possibilities: z = x or z â‰ x.
Case 1: Assume z = x. Then x = z âˆˆAâ€². So Nâˆ—(x, ðœ€1) âˆ©A = Nâˆ—(z, ðœ€1) âˆ©A â‰ âˆ…
as we claimed.
Case 2: Assume z â‰ x. Now z âˆˆN(x, ðœ€1) âˆ©Aâ€²; so we can say that z âˆˆ
Nâˆ—(x, ðœ€1) âˆ©Aâ€². Because Nâˆ—(x, ðœ€1) is an open set, âˆƒðœ€2 > 0 s.t. N(z, ðœ€2) âŠ†Nâˆ—(x, ðœ€1).
Because z âˆˆAâ€², âˆ€ðœ€> 0, Nâˆ—(z, ðœ€) âˆ©A â‰ âˆ….
Letting ðœ€= ðœ€2 in the last statement, we have Nâˆ—(z, ðœ€2) âˆ©A â‰ âˆ…. Let
y âˆˆNâˆ—(z, ðœ€2) âˆ©A. But
Nâˆ—(z, ðœ€2) âˆ©A âŠ†N(z, ðœ€2) âˆ©A
âŠ†Nâˆ—(x, ðœ€1) âˆ©A.
(17.27)
Then y âˆˆNâˆ—(x, ðœ€1) âˆ©A. So again, Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ….
So in case 2, we have proved the claim that Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ….
â—¾
The claim is just the deï¬nition of x âˆˆAâ€². Thus, ðœ•(Aâ€²) âŠ†Aâ€², and this proves
that Aâ€² is closed.
â—½
Finding this proof was not easy at all. Even our rewrite required extra thought
to get it organized. Once it is complete and rewritten carefully, it makes a bit
more sense. One last rewrite will clean it up a lot; hide our wandering logic, and
leave any future reader in admiration of our remarkable cleverness.
Attempt 1 (last time). We will prove that ðœ•(Aâ€²) âŠ†Aâ€².
Proof. Assume x âˆˆðœ•(Aâ€²).
Then âˆ€ðœ€> 0, N(x, ðœ€) âˆ©Aâ€² â‰ âˆ…and N(x, ðœ€) âˆ©(â„\Aâ€²) â‰ âˆ….
Assume ðœ€1 > 0. Then let ðœ€= ðœ€1 in the last statement. We have N(x, ðœ€1) âˆ©Aâ€² â‰ 
âˆ…and N(x, ðœ€1) âˆ©(â„\Aâ€²) â‰ âˆ….
Since N(x, ðœ€1) âˆ©Aâ€² â‰ âˆ…, let z âˆˆN(x, ðœ€1) âˆ©Aâ€². Then z âˆˆN(x, ðœ€1) and z âˆˆAâ€².
There are two possibilities: z = x or z â‰ x.
Case 1: Assume z = x. Then x = z âˆˆAâ€². So x âˆˆAâ€², and we are done.
Case 2: Assume z â‰ x. Now z âˆˆN(x, ðœ€1) âˆ©Aâ€²; so we can say that z âˆˆ
Nâˆ—(x, ðœ€1) âˆ©Aâ€². Because Nâˆ—(x, ðœ€1) is an open set, âˆƒðœ€2 > 0 s.t. N(z, ðœ€2) âŠ†Nâˆ—(x, ðœ€1).
Because z âˆˆAâ€², we also have âˆ€ðœ€> 0, Nâˆ—(z, ðœ€) âˆ©A â‰ âˆ….
Letting ðœ€= ðœ€2 in the last statement, we have Nâˆ—(z, ðœ€2) âˆ©A â‰ âˆ…. Let
y âˆˆNâˆ—(z, ðœ€2) âˆ©A. But
Nâˆ—(z, ðœ€2) âˆ©A âŠ†N(z, ðœ€2) âˆ©A
âŠ†Nâˆ—(x, ðœ€1) âˆ©A.
(17.28)
Then y âˆˆNâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…. So Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…. â—Š
So in case 2, we have proved that x âˆˆAâ€².

338
17 Theorems in Topology
In either case, x âˆˆðœ•(Aâ€²) was used to prove x âˆˆAâ€². Thus ðœ•(Aâ€²) âŠ†Aâ€², and this
proves that Aâ€² is closed.
â—½
As any English essay, the ï¬rst version of a proof will often need to be rewrit-
ten. Even a second version may need extra editing.
Early on in this proof, we realized that it was getting out of hand. We pressed
on anyway. However, there are several ways to prove that a set is closed. It might
have been a good idea to give up on proving that ðœ•(Aâ€²) âŠ†Aâ€² and try proving
that Aâ€² is closed by proving (Aâ€²)â€² âŠ†Aâ€². After all, accumulation points are often
better than boundary points. There is no question that we have gained some
insight at the ï¬rst attempt, so the second attempt might go more smoothly even
though we are using a diï¬€erent approach. But even if we had not pressed on
and learned things in attempt 1, it might be that attempt 2 was easier to bring
to a conclusion. Logically, the accumulation point arguments and boundary
point arguments are not that diï¬€erent; so we will beneï¬t from our experience.
Notice, however, that the accumulation points deï¬nitely do help us avoid the
main problem we ran into in the ï¬rst proof.
Attempt 2. We will prove that (Aâ€²)â€² âŠ†Aâ€².
Proof draft. Comment: We might hope that this is easier than the last because
accumulation points are supposed to be our friends.
Assume x âˆˆ(Aâ€²)â€². Then
âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©Aâ€² â‰ âˆ….
(17.29)
Comment: What are we proving now? x âˆˆAâ€². That is, âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ….
So let us not beat around the bush.
Claim. âˆ€ðœ€1 > 0, Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ….
Proof of claim. Assume ðœ€1 > 0. Then
Nâˆ—(x, ðœ€1) âˆ©Aâ€² â‰ âˆ….
(17.30)
Comment: But now what are we proving? Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…. How do we show
that a set is not empty? We ï¬nd an element in it. We are proving that something
exists. We need to set up a word problem and solve it.
We need y âˆˆNâˆ—(x, ðœ€1) âˆ©A. We need y âˆˆN(x, ðœ€1) âˆ©A with y â‰ x. What do we
know? There is something in Nâˆ—(x, ðœ€1) âˆ©Aâ€² â‰ âˆ….
We have been this way before.
Let z âˆˆNâˆ—(x, ðœ€1) âˆ©Aâ€².

17.3 Accumulation Points
339
Comment: Because we are using accumulation points, we do not need the cases
we had in attempt 1. We almost missed the need for those cases anyway; so this
approach is already better. It leads us past a trap.
So z âˆˆNâˆ—(x, ðœ€1) and z âˆˆAâ€². Since z âˆˆNâˆ—(x, ðœ€1), an open set, âˆƒðœ€2 > 0 s.t.
N(z, ðœ€2) âŠ†Nâˆ—(x, ðœ€1). But z âˆˆAâ€² and ðœ€2 > 0; so Nâˆ—(z, ðœ€2) âˆ©A â‰ âˆ…. Since
Nâˆ—(z, ðœ€2) âˆ©A âŠ†Nâˆ—(x, ðœ€1) âˆ©A,
(17.31)
we know that Nâˆ—(x, ðœ€1) âˆ©A â‰ âˆ…as claimed.
â—¾
The proof tells us that x âˆˆAâ€². So we have (Aâ€²)â€² âŠ†Aâ€². So Aâ€² is closed.
Î”
This proof is not that diï¬€erent than attempt 1. But it was easier to ï¬nd because
accumulation points are more friendly than boundary points.
Neither of these proofs are intuitive, and we needed to struggle with logic to
ï¬nd them. Maybe a whole new approach will work better. What about our old
fallback for diï¬ƒcult proofs, proof by contradiction?
Attempt 3. We will prove that (Aâ€²)â€² âŠ†Aâ€².
Proof draft. Assume x âˆˆ(Aâ€²)â€². Then âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©Aâ€² â‰ âˆ….
Assume BWOC x âˆ‰Aâ€². Then âˆ¼(âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ…). That is,
âˆƒðœ€1 > 0, s.t. Nâˆ—(x, ðœ€1) âˆ©A = âˆ….
(17.32)
Applying the previous statement to ðœ€1 > 0, we see that Nâˆ—(x, ðœ€1) âˆ©Aâ€² â‰ âˆ….
Comment: There is only one way to use this.
Let y âˆˆNâˆ—(x, ðœ€1) âˆ©Aâ€² â‰ âˆ…. Then y âˆˆNâˆ—(x, ðœ€1), and y âˆˆAâ€².
Since y âˆˆNâˆ—(x, ðœ€1) an open set, âˆƒðœ€2 > 0 s.t. N(y, ðœ€2) âŠ†Nâˆ—(x, ðœ€1).
But y âˆˆAâ€²; so Nâˆ—(y, ðœ€2) âˆ©A â‰ âˆ….
This is a problem because
Nâˆ—(y, ðœ€2) âˆ©A âŠ†N(y, ðœ€2) âˆ©A
âŠ†Nâˆ—(x, ðœ€1) âˆ©A.
(17.33)
We said earlier that Nâˆ—(x, ðœ€1) âˆ©A = âˆ…. So we have a contradiction.
So we must have (Aâ€²)â€² âŠ†Aâ€². So Aâ€² is closed.
Î”
In retrospect, this is actually a proof by contrapositive. We should rewrite it
that way.
Attempt 3 (again). We will prove that (Aâ€²)â€² âŠ†Aâ€².
Proof. We will prove that (Aâ€²)â€² âŠ†Aâ€² by proving:

340
17 Theorems in Topology
If x âˆ‰Aâ€², then x âˆ‰(Aâ€²)â€².
Assume
x âˆ‰Aâ€².
Then
âˆ¼(âˆ€ðœ€> 0, Nâˆ—(x, ðœ€) âˆ©A â‰ âˆ…).
That
is,
âˆƒðœ€1 > 0,
Nâˆ—(x, ðœ€1) âˆ©A = âˆ….
Claim. Nâˆ—(x, ðœ€1) âˆ©Aâ€² = âˆ….
Proof of claim. Assume BWOC Nâˆ—(x, ðœ€1) âˆ©Aâ€² â‰ âˆ….
Let y âˆˆNâˆ—(x, ðœ€1) âˆ©Aâ€² â‰ âˆ…. Then y âˆˆNâˆ—(x, ðœ€1), and y âˆˆAâ€².
Since y âˆˆNâˆ—(x, ðœ€1) and an open set, âˆƒðœ€2 > 0 s.t. N(y, ðœ€2) âŠ†Nâˆ—(x, ðœ€1).
But y âˆˆAâ€²; so Nâˆ—(y, ðœ€2) âˆ©A â‰ âˆ….
This is a problem because
Nâˆ—(y, ðœ€2) âˆ©A âŠ†N(y, ðœ€2) âˆ©A
âŠ†Nâˆ—(x, ðœ€1) âˆ©A.
(17.34)
We said earlier that Nâˆ—(x, ðœ€1) âˆ©A = âˆ…. This proves the claim.
â—¾
So we have ðœ€1 > 0 so that Nâˆ—(x, ðœ€1) âˆ©Aâ€² = âˆ…. Thus, x âˆ‰(Aâ€²)â€².
â—½
Another popular way to show that a set is closed is by proving its complement
in â„is open. This is so popular that, with more experience, we would probably
have tried it ï¬rst. Let us give it a try now.
Attempt 4. We will prove that â„\Aâ€² is open.
Proof draft. Comment: What are we proving? âˆ€x âˆˆâ„\Aâ€², âˆƒðœ€> 0 such that
N(x, ðœ€) âŠ†â„\Aâ€². Or we could prove that â„\Aâ€² âŠ†Int(â„\Aâ€²). Since either way we
start out the same way, we should keep an open mind.
Assume x âˆˆâ„\Aâ€². So by the Second Partition Theorem,
x âˆˆExt(A) âˆªAâˆ˜.
(17.35)
There are two possibilities x âˆˆExt(A) or x âˆˆAâˆ˜.
Case 1: Assume x âˆˆExt(A).
Comment: What are we proving now? âˆƒðœ€> 0 s.t. N(x, ðœ€) âŠ†â„\Aâ€². If we know our
theorems, there is a shortcut.
Now Ext(A) âŠ†â„\Aâ€² and it is open. So we know that
x âˆˆExt(A) âŠ†Int(â„\Aâ€²).
(17.36)
Case 2: Assume x âˆˆAâˆ˜. Then âˆƒðœ€1 > 0 such that N(x, ðœ€1) âˆ©A = {x}. So we can
say that Nâˆ—(x, ðœ€1) âˆ©A = âˆ…. So Nâˆ—(x, ðœ€1) âŠ†â„\A. This is an open subset of â„\A; so
Nâˆ—(x, ðœ€1) âŠ†Int(â„\A)

17.4 Problems
341
âŠ†Ext(A)
âŠ†â„\Aâ€².
(17.37)
Since x âˆˆAâˆ˜, we also have x âˆˆâ„\Aâ€². Then
N(x, ðœ€1) = Nâˆ—(x, ðœ€1) âˆª{x} âŠ†â„\Aâ€².
(17.38)
But the neighborhood is an open set; so
x âˆˆN(x, ðœ€1) âŠ†Int(â„\Aâ€²).
(17.39)
So we have proved that in either case, if x âˆˆâ„\Aâ€², then x âˆˆInt(â„\Aâ€²). Thus,
â„\Aâ€² = Int(â„\Aâ€²), and â„\Aâ€² is open.
Î”
This really seems better. It deserves to be rewritten.
All these attempts seem to be more eï¬€ort than one result was worth. But
we have seen that we need to be ï¬‚exible when we need to construct a proof.
If our ï¬rst idea is not going along easily, the best thing to do might be to try
something else from the start. With enough eï¬€ort, we should expect to prove
any true statement. A bad start might make this harder that it needs to be. Our
ï¬rst rule for proofs was: â€œalways start with the deï¬nitions.â€ This is still a good
rule of thumb, but we adjust it with a second rule: â€œstarting a proof using a good
theorem can make things much easier.â€
17.4
Problems
17.1
What, if anything, can you say about:
(a) Int(Int(A))?
(b) ðœ•(Int(A))?
(c) Cl(Int(A))?
(d) (Int(A))âˆ˜?
(e) (Int(A))â€²?
(f) Int(ðœ•(A))?
(g) ðœ•(ðœ•(A))?
(h) Cl(ðœ•(A))?
(i) (ðœ•(A))âˆ˜?
(j) (ðœ•(A))â€²?
(k) Int(Cl(A))?
(l) ðœ•(Cl(A))?
(m) Cl(Cl(A))?
(n) (Cl(A))âˆ˜?
(o) (Cl(A))â€²?
(p) Int(Aâˆ˜)?
(q) ðœ•(Aâˆ˜)?

342
17 Theorems in Topology
(r) Cl(Aâˆ˜)?
(s) (Aâˆ˜)âˆ˜?
(t) (Aâˆ˜)â€²?
(u) Int(Aâ€²)?
(v) ðœ•(Aâ€²)?
(w) Cl(Aâ€²)?
(x) (Aâ€²)âˆ˜?
(y) (Aâ€²)â€²?
17.2
Use proved theorems to easily prove:
(a) If Aâ€² = âˆ…, then A = Aâˆ˜.
(b) If A âŠ†â„is ï¬nite, then A = Aâˆ˜.
17.3
Let A âŠ†â„be a nonempty closed set. Prove if A is bounded below, then
A has a minimum.
17.4
Let Ai where i âˆˆîˆµbe a nonempty family of sets.
(a) Prove that
(
â‹‚
âˆ€iâˆˆîˆµ
Ai
)â€²
âŠ†
â‹‚
âˆ€iâˆˆîˆµ
Aâ€²
i.
(17.40)
(Hint: Accumulation points are your friends.)
(b) Suppose that âˆ€i âˆˆîˆµ, Ai is closed. Use part (a) to prove â‹‚
âˆ€iâˆˆîˆµ
Ai is
closed.
17.5
Let A âŠ†â„.
(a) Prove that if A âŠ†C a closed set, then Cl(A) âŠ†C.
(b) Prove that if A is bounded, then Cl(A) is bounded. (Hint: Use
intervals.)
(c) Prove that if A is bounded, then Aâ€² is bounded.
17.6
Prove using the deï¬nition that, if A and B are open sets, then A âˆ©B
is open.
17.7
Prove using induction that, if Ai where i âˆˆîˆµis a nonempty ï¬nite family
of open sets, then â‹‚
âˆ€iâˆˆîˆµ
Ai is open.
17.8
Let A, B âŠ†â„.
(a) Prove: If ðœ•(A) = âˆ…, then A is closed.
(b) Prove: If ðœ•(A) = âˆ…, then Aâˆ˜= âˆ….
(c) Prove: If Aâˆ˜= âˆ…, then âˆ€x âˆˆâ„, if B = A âˆ©[x, âˆž), then Bâˆ˜= âˆ….

17.4 Problems
343
(d) Prove: If ðœ•(A) = âˆ…, then âˆ€x âˆˆâ„, if B = A âˆ©[x, âˆž), then Bâˆ˜= âˆ….
(e) Prove: If m =Inf(A), then m âˆˆðœ•(A).
(f) Prove: If A â‰ âˆ…, and A is bounded below, then ðœ•(A) â‰ âˆ….
(g) Prove: if A â‰ âˆ…and ðœ•(A) = âˆ…, then âˆ€x âˆˆâ„, for B = A âˆ©[x, âˆž), we
have B â‰ âˆ….
(h) Prove: if A â‰ âˆ…and ðœ•(A) = âˆ…, then âˆ€x âˆˆâ„, for B = A âˆ©[x, âˆž), we
know that B has a inï¬mum. Throughout the rest of the problem, let
mx = Inf (A âˆ©[x, âˆž)).
(i) Prove: if A â‰ âˆ…and ðœ•(A) = âˆ…, then if x âˆˆâ„, then âˆ€ðœ€> 0,
A âˆ©[mx, mx + ðœ€) â‰ âˆ….
(j) Prove: if A â‰ âˆ…and ðœ•(A) = âˆ…, then âˆ€x âˆˆâ„, A âˆ©[x, âˆž) is closed.
(k) Prove: if A â‰ âˆ…and ðœ•(A) = âˆ…, then âˆ€x âˆˆâ„, mx âˆˆA âˆ©[x, âˆž).
(l) Prove: if A â‰ âˆ…and ðœ•(A) = âˆ…and x âˆ‰A, then x < mx.
(m) Prove: if A â‰ âˆ…and ðœ•(A) = âˆ…and x âˆ‰A, then âˆ€ðœ€> 0,
mx âˆ’1
2Min({ âˆ‰, (mx âˆ’x)) âˆ‰A.
(n) Prove: if A â‰ âˆ…and ðœ•(A) = âˆ…and x âˆ‰A, then âˆ€ðœ€> 0, (mx âˆ’ðœ€, mx) âˆ©
(â„\A) â‰ âˆ….
(o) Prove: if A â‰ âˆ…and ðœ•(A) = âˆ…and x âˆ‰A, then âˆ€ðœ€> 0, N(mx, ðœ€) âˆ©
(â„\A) â‰ âˆ…and N(mx, ðœ€) âˆ©A â‰ âˆ….
(p) Prove: if A â‰ âˆ…and ðœ•(A) = âˆ…then âˆ€x âˆˆâ„, x âˆˆA.
(q) Prove: ðœ•(A) = âˆ…then either A = âˆ…or A = â„.
(r) Prove: If A is open and closed, then either A = âˆ…or A = â„.
17.9
Recall our last theorem that stated for all A âŠ†â„, Aâ€² is a closed set. Polish
the draft of attempt 2 into a better written proof.

345
18
Compact Sets
18.1
Closed and bounded sets
18.1.1
Maximums and minimums
If A âŠ†â„is nonempty and closed, it has nice topological properties. If A is
nonempty and bounded, it ï¬ts perfectly into our deï¬nition of the real numbers.
But somehow when the two properties closed and bounded are combined, the
result is much stronger than either one alone. A set that is closed and bounded
has many more strong properties than a set that is just closed or just bounded.
Proving many of the properties of these closed and bounded sets requires
greater logical power than directly applying the two deï¬nitions separately.
Luckily, mathematicians have developed an amazing and powerful trick that
provides a completely diï¬€erent path to such proofs. We will prove a theorem
that says that, for any closed and bounded set, a very nonintuitive trick will
work in a proof. Similarly to a proof by induction, this trick is not always
the method we use, but it is available when necessary. In addition, similar to
induction, it really helps to prove the more interesting results. The only hard
part is remembering this very strange trick.
We start, however, with a result about closed and bounded sets that is not
much more than a combination of the two deï¬nitions.
Theorem 18.1.1.
Let A âŠ†â„with A â‰ âˆ…. If A is closed and bounded, then A
has a maximum and a minimum.
We have seen how useful such guarantees have been in the past; so this is
deï¬nitely a result worth remembering.
Proof. Assume A âŠ†â„with A â‰ âˆ…. Assume that A is closed. Assume that A is
bounded below. Assume that A is bounded above.
Since A is nonempty and bounded below, it has an inï¬mum; call it m.
Similarly, A has a supremum; call it M. We have proved in Theorem 17.2.11
that m âˆˆðœ•(A) and M âˆˆðœ•(A). Since A is closed, ðœ•(A) âŠ†A. Thus, m is a lower
bound of A that is in A. So m = Min(A). Similarly, M = Max(A).
â—½
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

346
18 Compact Sets
The deï¬nition of compact
In the early 19th century, Bernhard Bolzano proved a result about a closed and
bounded subset of â„that used a trick that was so strange that it took other
mathematicians a while to appreciate the power of his ideas. After they did,
they realized that they needed a mechanism for remembering that this trick
was available. Later in the century, two other mathematicians would prove that
Bolzanoâ€™s trick would work exactly when a set was closed and bounded. Now
â€œclosed and boundedâ€ is an easy thing to say, and the deï¬nitions of the parts are
easy to remember. But Bolzanoâ€™s trick is another story. Mathematicians deï¬ne
a new term â€œcompactâ€ whose deï¬nition is a weird statement that amounts to
Bolzanoâ€™s trick. When they are presented with a closed and bounded set, they
automatically call it â€œcompact.â€ That way, when they ask themselves what a
compact set is, they answer with a deï¬nition that outlines Bolzanoâ€™s trick. They
can always change back to â€œclosed and boundedâ€ if they ï¬nd that they do not
need all the power of that trick.
As a result, we have a deï¬nition of â€œA is a compact setâ€ that does absolutely
nothing to explain what the term â€œcompactâ€ means. â€œCompactâ€ is just the word
we use, it is not because the trick has anything to do with the English word. As
one gets used to it, the word â€œcompactâ€ will begin to seem reasonably descrip-
tive. That might have been the case had mathematicians chosen another word
such as â€œï¬rm,â€ â€œsolid,â€ or â€œconcrete.â€ They did not; so in Mathematics, the term
â€œcompact setâ€ means no less and no more than the following bizarre deï¬nition.
Deï¬nition 18.1.2.
Let A âŠ†â„. We say that A is compact when for all families
îˆ»i with i âˆˆîˆµwhere all îˆ»i are open and where A âŠ†â‹ƒ
iâˆˆîˆµ
îˆ»i, there exists îˆ¶âŠ†îˆµwith
îˆ¶ï¬nite so that A âŠ†â‹ƒ
iâˆˆîˆ¶
îˆ»i.
People often state this as, â€œEvery open cover of A has a ï¬nite subcover.â€
As predicted, this is not at all intuitive. It does contain a hint about its power
though. If we cover a set A with a lot of open sets, we can start oï¬€as sloppily as
we want. We can cover everything in sight, and long as we cover all of the set, it
does not matter how carried away we get covering anything extra. Compactness
will guarantee that our sloppiness can later be corrected, and we can trim down
our sloppy cover into a much more manageable ï¬nite subcover. Basically, every
time a mathematician ï¬nds a new or novel way to cover a set known to be com-
pact, that mathematician has a new mathematical theorem. The only drawback
is that it seems that each idea for a cover only gives one mathematical theorem.
Thus, using compactness seems to mean constantly inventing new covers.
The good news is that, in many applications, covers of sets appear automat-
ically. We are given one compact set, and we are asked to prove that another
set is compact. Then the set we want to be compact can assumed to be covered
with open sets. We then ï¬nd a way to change those open sets into open sets

18.1 Closed and Bounded Sets
347
that cover the set we know is compact in a reversible way. The ï¬nite cover of
the second set can then be reversed and used to prove that the desired set is
compact. So instead of having to invent a new cover for a compact set every
time, we are often led to a cover from a bunch of open sets we already have.
Compact sets are closed and bounded sets
The fact is that compact sets are simply sets that are closed and bounded. The
proof of this is long and detailed.
We have ï¬nally hit on the structure that makes Mathematics so valuable.
We are going to name, state, and prove a theorem that we will be able to call
upon in any future proof. We have done this before, but never with a result
that would be as diï¬ƒcult to reconstruct. If we forget the average theorem, but
ï¬nd ourselves needing a real number between two others, we might not have
that much trouble rediscovering the average theorem on our own. Take the
topology theorem that states:
If A âŠ†B and A is open, then A âŠ†Int(B).
This theorem is very handy; it can make it easier to discover a proof. But if it
skips our mind, we can probably avoid it or reprove it as we push through the
logic of a proof.
The fact that compact sets are closed and bounded sets is not something
we might easily stumble upon without help. There is very little chance that
anyone will ever accidentally rediscover its proof. The proof is long enough
that we would not want to have to redo it, perhaps ever. Students may need to
reprove it, but once they have moved on to other things, they can use it simply
by referring to its name. That is exactly why we name and prove mathematical
theorems: to prove them once, and then move on without ever reproving them
again. (Although, mathematicians always enjoy replacing a famous long proof
with a clever short one.) The longer a proof, the more important it is that we
remember the statement of the theorem. If we remember the theorem, we can
use the theorem without recalling the proof.
The reason why the bizarre deï¬nition of compact sets is so useful is the fol-
lowing theorem.
Theorem 18.1.3
(The Heineâ€“Borel Theorem). Let A âŠ†â„. Then A is com-
pact if and only if A is closed and bounded.
There are three parts to the proof of this important theorem:
Part 1. If A is compact, then A is bounded.
Part 2. If A is compact, then A is closed.
Part 3. If A is closed and bounded, then A is compact.

348
18 Compact Sets
The ï¬rst two parts illustrate how a clever open cover of a compact set, no
matter how sloppy, leads to an interesting property of the set. The third part is
the meat of the theorem since it gives us an easy way to tell if a clever open cover
of a set will be of any use. The proof of this theorem is generally something we
are shown and not something we discover on our own. For that reason, it is
worth going through carefully to understand every step.
Part 1. We claim that if A is compact, then A is bounded.
Proof. Assume that A is compact.
Comment: In this case, it really does not pay to write down the deï¬nition. It is
more important to remember its meaning: if we ever have an open cover of A,
then we can trim it down. A compact set does not come with an open cover;
rather we must ï¬nd one to put its compactness to use. The family we will use will
only be useful for proving this theorem.
For n âˆˆâ„•, let îˆ»n = (âˆ’n, n). This is a family of open sets.
Claim. We claim that â‹ƒ
nâˆˆâ„•
îˆ»n = â„.
Proof of claim. The proof is left as an exercise, but it is nothing more than an
application of the absolute value and the Archimedean principle.
â—¾
It follows that A âŠ†â„= â‹ƒ
nâˆˆâ„•
îˆ»n. So we have an open cover îˆ»n, indexed by
n âˆˆâ„•, of the compact set A. So by the deï¬nition of compact, there is a ï¬nite
set îˆ¶âŠ†â„•so that
A âŠ†
â‹ƒ
nâˆˆîˆ¶
îˆ»n.
(18.1)
However, because îˆ¶is a ï¬nite subset of â„•, it has a maximum element. Let us
say that m = Max(îˆ¶).
Then we have that for all n âˆˆîˆ¶, n â‰¤m. It follows that for all n âˆˆîˆ¶,
îˆ»n = (âˆ’n, n) âŠ†(âˆ’m, m).
This implies that
A âŠ†
â‹ƒ
nâˆˆîˆ¶
îˆ»n âŠ†(âˆ’m, m).
(18.2)
Thus, âˆ’m is a lower bound for A and m is an upper bound. This completes the
ï¬rst part of our proof of the Heineâ€“Borel theorem.
â—½
This proof is an excellent example of how careful deï¬nitions can work
together. Compactness is about any open cover no matter how much more

18.1 Closed and Bounded Sets
349
it covers than it needs to. This cover of expanding open intervals covers the
entire real line. Knowing that there is a ï¬nite subcover means that, when
looked at carefully, only one interval is needed. That interval gives a lower
bound and an upper bound. Those bounds may not be optimal at all. But all
we claimed was that the set was bounded; so we do not need better upper and
lower bounds than these.
Proof technique. When we assume that a set is compact (or closed and
bounded after Heineâ€“Borel is proved), it is often a good idea not to write out
the deï¬nition of compact for that set. Writing out that deï¬nition can result into
tricking ourselves into thinking that we have a cover of the set. If we know that a
set is compact, that only tells us that if we ever have an open cover of that set,
we can cut it down to a ï¬nite cover. If we show enough patience, we may be able
to ï¬nd a cover to use this on.
Part 2. We claim that if A is compact, then A is closed.
Proof. Assume that A is compact. We will prove that â„\A is open.
Assume b âˆˆâ„\A.
For ðœ€âˆˆâ„with ðœ€âˆˆ(0, âˆž), let îˆ»ðœ€= (âˆ’âˆž, b âˆ’ðœ€) âˆª(b + ðœ€, âˆž). This is a family
of open sets.
Claim. We claim â‹ƒ
ðœ€>0
îˆ»ðœ€= â„\{b}.
Proof of claim. This is a set equality; so as usual, there are two steps. We must
prove â‹ƒ
ðœ€>0
îˆ»ðœ€âŠ†â„\{b} and â‹ƒ
ðœ€>0
îˆ»ðœ€âŠ‡â„\{b}.
Step 1: First, we will prove that â‹ƒ
ðœ€>0
îˆ»ðœ€âŠ†â„\{b}.
Note that for all ðœ€> 0, b âˆ‰îˆ»ðœ€. That is to say, îˆ»ðœ€âŠ†â„\{b} for all ðœ€> 0. Thus,
â‹ƒ
ðœ€>0
îˆ»ðœ€âŠ†â„\{b}. This proves that â‹ƒ
ðœ€>0
îˆ»ðœ€âŠ†â„\{b}.
Step 2: Now we will prove that â‹ƒ
ðœ€>0
îˆ»ðœ€âŠ‡â„\{b}.
Assume x â‰ b, and let ðœ€x = 1
2|x âˆ’b|. Then ðœ€x > 0. In addition,
x âˆ‰[bâˆ’ðœ€x, b+ðœ€x].
(18.3)
Then
x âˆˆâ„\ [bâˆ’ðœ€x, b+ðœ€x].
(18.4)
So
x âˆˆ(âˆ’âˆž, bâˆ’ðœ€x) âˆª(b+ðœ€x, âˆž) = îˆ»ðœ€x.
(18.5)
And then, x âˆˆâ‹ƒ
ðœ€>0
îˆ»ðœ€. This proves that
â‹ƒ
ðœ€>0
îˆ»ðœ€âŠ‡â„\ {b}. Thus, we have
â‹ƒ
ðœ€>0
îˆ»ðœ€= â„\ {b}.
â—¾

350
18 Compact Sets
We have assumed that b âˆˆâ„\A. This is equivalent to saying that {b} âŠ†â„\ A.
So by taking complements, we obtain A âŠ†â„\ {b}.
By our claim,
A âŠ†â„\ {b} =
â‹ƒ
ðœ€>0
îˆ»ðœ€=
â‹ƒ
ðœ€âˆˆ(0,âˆž)
îˆ»ðœ€.
(18.6)
So we have an open cover of a compact set.
By the deï¬nition of compactness, there exists a ï¬nite set îˆ¶âŠ†(0, âˆž), so that
A âŠ†â‹ƒ
ðœ€âˆˆîˆ¶
îˆ»ðœ€.
However, a ï¬nite subset of â„has a minimum. Let us say that ðœ€0 = Min(îˆ¶).
Then for all ðœ€âˆˆîˆ¶, ðœ€0 â‰¤ðœ€. Also ðœ€0 âˆˆîˆ¶âŠ†(0, âˆž); so ðœ€0 > 0.
So for each ðœ€âˆˆîˆ¶
[bâˆ’ðœ€0, b+ðœ€0] âŠ†[b âˆ’ðœ€, b + ðœ€].
(18.7)
Taking complements, it follows that for each ðœ€âˆˆîˆ¶,
(â„\ [b âˆ’ðœ€, b + ðœ€]) âŠ†(â„\[bâˆ’ðœ€0, b+ðœ€0]).
(18.8)
This is the same as saying that for each ðœ€âˆˆîˆ¶,
(âˆ’âˆž, b âˆ’ðœ€) âˆª(b + ðœ€, âˆž) âŠ†(âˆ’âˆž, bâˆ’ðœ€0) âˆª(b+ðœ€0, âˆž).
(18.9)
Notice that the left-hand side of the previous equation is exactly îˆ»ðœ€. So we have,
âˆ€ðœ€âˆˆîˆ¶, îˆ»ðœ€âŠ†(âˆ’âˆž, bâˆ’ðœ€0) âˆª(b+ðœ€0, âˆž).
(18.10)
And from this we can conclude that
â‹ƒ
ðœ€âˆˆîˆ¶
îˆ»ðœ€âŠ†(âˆ’âˆž, bâˆ’ðœ€0) âˆª(b+ðœ€0, âˆž).
(18.11)
But recall that A âŠ†â‹ƒ
ðœ€âˆˆîˆ¶
îˆ»ðœ€. Therefore, we have
A âŠ†
â‹ƒ
ðœ€âˆˆîˆ¶
îˆ»ðœ€âŠ†(âˆ’âˆž, bâˆ’ðœ€0) âˆª(b+ðœ€0, âˆž).
(18.12)
By taking complements of these sets, we see
[bâˆ’ðœ€0, b+ðœ€0] âŠ†â„\ A.
(18.13)
And so ï¬nally,
N(b, ðœ€0) âŠ†[bâˆ’ðœ€0, b+ðœ€0] âŠ†â„\ A.
(18.14)
Since âˆ€b âˆˆâ„\A, âˆƒðœ€0 > 0 such that N(b, ðœ€0) âŠ†â„\ A, we have shown that â„\A
is open and therefore that A is closed. This completes the second part of our
proof of the Heineâ€“Borel theorem.
â—½
Another very generous cover produces an interesting result. These ï¬rst two
parts demonstrate how the peculiar deï¬nition of a compact set can be put
to use.

18.1 Closed and Bounded Sets
351
The third part is completely diï¬€erent and, at ï¬rst glance at least, seems
quite complicated. The idea behind it is not much more than a sort of
â€œminimum counterexampleâ€ argument or, perhaps better, a â€œsupremum
exampleâ€ argument. In the end, this is a proof of a â€œthere existsâ€ result, and we
need a creative way to produce a ï¬nite set that works. Sliding in from below
will allow us to create a set with a â€œsupremum example.â€ And then we will
show that it cannot exist.
Part 3. If A is closed and bounded, then A is compact.
Proof. Assume A âŠ†â„. Assume that A is bounded above and below, and assume
that A is closed. Since the empty set is automatically compact, we may also
assume that A â‰ âˆ….
We need to show that any open cover of A has a ï¬nite subcover, so we will
begin by assuming that we have some open cover of A.
Thus, assume that îˆ»i with i âˆˆîˆµis a family of sets, and assume that for all
i âˆˆîˆµ, îˆ»i is open. Finally, assume that
A âŠ†
â‹ƒ
iâˆˆîˆµ
îˆ»i.
We begin by observing that since A â‰ âˆ…, there must be at least one set in our
open cover. So we know that îˆµâ‰ âˆ….
For all x âˆˆâ„, let
Ax = A âˆ©(âˆ’âˆž, x).
(18.15)
Let
B =
{
x âˆˆâ„âˆ£âˆƒîˆ¶x âŠ†îˆµ, s.t. îˆ¶x is ï¬nite and Ax âŠ†
â‹ƒ
iâˆˆîˆ¶x
îˆ»i
}
.
(18.16)
Claim. We claim that B â‰ âˆ….
Proof of claim. By assumption, A is bounded below. Let b be any lower bound
of A. Then we know that if a âˆˆA, then b â‰¤a. So,
Ab = A âˆ©(âˆ’âˆž, b)
(18.17)
= {x âˆˆâ„âˆ£x âˆˆA and x âˆˆ(âˆ’âˆž, b)}
= {x âˆˆA âˆ£x < b}
= âˆ….
Since îˆµâ‰ âˆ…, we know that there is some element in îˆµ. Say ib âˆˆîˆµ. Then
îˆ¶b = {ib} is certainly a ï¬nite subset of îˆµand
Ab = âˆ…âŠ†
â‹ƒ
iâˆˆ{ib}
îˆ»i.
(18.18)
This puts b âˆˆB. So B â‰ âˆ…, and we have proved our claim.
â—¾

352
18 Compact Sets
Comment: Notice that this shows that every lower bound of A is in B. So B is
deï¬nitely not bounded below. However, it may or may not be bounded above.
But if we understand what the deï¬nition of B says, the following claim seems
necessary if our theorem is true.
Claim. We claim that B is not bounded above.
Proof of claim. Suppose BWOC that B is bounded above. Then since B âŠ†â„is
nonempty and bounded above, B has a supremum. Let us say m = Sup(B).
Then by deï¬nition of supremum,
â€¢ âˆ€b âˆˆB, b â‰¤m, and
â€¢ if l < m, then âˆƒb âˆˆB such that l < b.
There are two possibilities for m: either m âˆˆA or m âˆ‰A.
Case 1: Assume m âˆˆA.
Then m âˆˆA âŠ†â‹ƒ
iâˆˆîˆµ
îˆ»i. So âˆƒim âˆˆîˆµsuch that m âˆˆîˆ»im. But îˆ»im is an open set;
so there is some ðœ€> 0 such that N(m, ðœ€) âŠ†îˆ»im. Now m âˆ’ðœ€< m; and so by the
deï¬nition of the supremum, âˆƒb âˆˆB such that m âˆ’ðœ€< b. Since b âˆˆB, we also
have
m âˆ’ðœ€< b â‰¤m < m + ðœ€.
(18.19)
Consider the interval (âˆ’âˆž, m + ðœ€).
(âˆ’âˆž, m + ðœ€) = (âˆ’âˆž, b) âˆª(m âˆ’ðœ€, m + ðœ€).
(18.20)
We have
Am+ðœ€= A âˆ©(âˆ’âˆž, m + ðœ€)
(18.21)
= A âˆ©((âˆ’âˆž, b) âˆª(m âˆ’ðœ€, m + ðœ€))
= (A âˆ©(âˆ’âˆž, b)) âˆª(A âˆ©(m âˆ’ðœ€, m + ðœ€))
= Ab âˆª(A âˆ©N(m, ðœ€))
âŠ†Ab âˆªN(m, ðœ€)
âŠ†Ab âˆªîˆ»im.
But b âˆˆB. So by the deï¬nition of B, âˆƒîˆ¶b âŠ†îˆµsuch that îˆ¶b is ï¬nite and
Ab âŠ†â‹ƒ
iâˆˆîˆ¶b
îˆ»i.
Putting the last two observations together, we have
Am+ðœ€âŠ†Ab âˆªîˆ»im
(18.22)
âŠ†
(
â‹ƒ
iâˆˆîˆ¶b
îˆ»i
)
âˆªîˆ»im
âŠ†
â‹ƒ
iâˆˆîˆ¶bâˆª{im}
îˆ»i.

18.1 Closed and Bounded Sets
353
Since îˆ¶b is ï¬nite, so is îˆ¶b âˆª{im}. This shows that Am+ðœ€is covered by ï¬nitely
many of the open sets; so m + ðœ€âˆˆB. But that means m = Sup(B) â‰¥m + ðœ€.
Since ðœ€> 0, this is not possible. So this subcase cannot occur. That is, we
cannot have m âˆˆA.
Case 2: Assume m âˆ‰A.
Then m âˆˆâ„\A. Because A is closed, â„\A is open. So âˆƒðœ€> 0 such that
N(m, ðœ€) âŠ†â„\A. That is, N(m, ðœ€) âˆ©A = âˆ….
Now m âˆ’ðœ€< m, and so by the deï¬nition of the supremum, âˆƒb âˆˆB such that
m âˆ’ðœ€< b. Since b âˆˆB, we also have
m âˆ’ðœ€< b â‰¤m < m + ðœ€.
(18.23)
Consider the interval (âˆ’âˆž, m + ðœ€).
(âˆ’âˆž, m + ðœ€) = (âˆ’âˆž, b) âˆª(m âˆ’ðœ€, m + ðœ€).
(18.24)
So
Am+ðœ€= A âˆ©(âˆ’âˆž, m + ðœ€)
(18.25)
= A âˆ©((âˆ’âˆž, b) âˆª(m âˆ’ðœ€, m + ðœ€))
= (A âˆ©(âˆ’âˆž, b)) âˆª(A âˆ©(m âˆ’ðœ€, m + ðœ€))
= Ab âˆª(A âˆ©N(m, ðœ€))
âŠ†Ab âˆªâˆ…
âŠ†Ab.
But b âˆˆB. So by the deï¬nition of B, âˆƒîˆ¶b âŠ†îˆµsuch that îˆ¶b is ï¬nite and
Ab âŠ†â‹ƒ
iâˆˆîˆ¶b
îˆ»i.
Putting the last two observations together, we have
Am+ðœ€= Ab âŠ†
â‹ƒ
iâˆˆîˆ¶b
îˆ»i.
(18.26)
Since îˆ¶b is ï¬nite, this shows that Am+ðœ€is covered by ï¬nitely many of the open
sets; so m + ðœ€âˆˆB. But that means m =Sup(B) â‰¥m + ðœ€. Since ðœ€> 0, this is not
possible. So this subcase cannot occur either.
Eliminating all the possibilities that follow from the assumption that B is
bounded above means that B cannot be bounded above. This proves our claim
that B is not bounded above.
â—¾
So we now have that B is not empty and not bounded above. There is one last
assumption we have not used: A is bounded above. Let u be any upper bound
of A. Then for all a âˆˆA, a â‰¤u.
Now u âˆˆâ„and B is not bounded above; in particular, u is not an upper bound
on B. There must be b âˆˆB such that u < b. But u is an upper bound of A; so

354
18 Compact Sets
âˆ€a âˆˆA, a â‰¤u < b. That is to say,
A âŠ†(âˆ’âˆž, b).
(18.27)
So
A âŠ†A âˆ©(âˆ’âˆž, b) = Ab.
(18.28)
However, b âˆˆB, so by deï¬nition âˆƒîˆ¶b âŠ†îˆµsuch that îˆ¶b is ï¬nite and Ab âŠ†â‹ƒ
iâˆˆîˆ¶b
îˆ»i.
So A = Ab âŠ†â‹ƒ
iâˆˆîˆ¶b
îˆ»i with îˆ¶b âŠ†îˆµï¬nite. This proves that any open cover of A
can be trimmed to ï¬nitely many sets. So A is compact. This completes the third
and ï¬nal part of our proof of the Heineâ€“Borel theorem.
â—½
18.2
Closed intervals are special
Certainly, because of the Heineâ€“Borel theorem, every closed bounded interval
[a, b] in â„is compact. Intervals have another mathematical property called
inseparability. Basically, an interval is inseparable because it cannot be covered
by the union of two open sets without the sets intersecting in at least one point
- well, without cheating, that is. If we start with two nonempty open sets that
are disjoint (have an empty intersection), then we can always add an interval
in one of them. We need to be sure that we deal with this in the statement of
our theorem.
Inseparability of closed intervals
Theorem 18.2.1
(The Inseparability Theorem). Let I âŠ†â„be an interval,
and îˆ»1 and îˆ»2 be open subsets of â„. If I âŠ†îˆ»1 âˆªîˆ»2 and îˆ»1 âˆ©îˆ»2 = âˆ…, then either
I âŠ†îˆ»1 or I âŠ†îˆ»2.
Proof. Assume that I âŠ†â„is an interval. Assume that îˆ»1 and îˆ»2 are open sets.
Assume I âŠ†îˆ»1 âˆªîˆ»2. Assume îˆ»1 âˆ©îˆ»2 = âˆ….
Assume BWOC I âŠˆîˆ»1 and I âŠˆîˆ»2.
First, I âŠˆîˆ»1 implies that âˆƒt âˆˆI with t âˆ‰îˆ»1. But I âŠ†îˆ»1 âˆªîˆ»2; so t âˆˆîˆ»2.
Second I âŠˆîˆ»1 implies that âˆƒs âˆˆI with s âˆ‰îˆ»2. But I âŠ†îˆ»1 âˆªîˆ»2; so s âˆˆîˆ»1.
Since I is an interval, the interval between s and t is a subset of I.
Thus, we can rename things and say we have an interval [a, b] âŠ†îˆ»1 âˆªîˆ»2
where a âˆˆîˆ»1 and b âˆˆîˆ»2.
Next let
B = {x âˆˆâ„âˆ£[a, x] âŠ†îˆ»1}.
(18.29)
Now [a, a] = {a} âŠ†îˆ»1; so a âˆˆB and B â‰ âˆ…. In addition, b âˆ‰îˆ»1, so âˆ€x âˆˆB,
x â‰¤b. That makes b an upper bound on B. By completeness B has a supremum,

18.2 Closed Intervals are Special
355
call it m. Since a âˆˆB, a â‰¤m. And because m is the least upper bound of B,
m â‰¤b. That says
m âˆˆ[a, b].
(18.30)
But m âˆˆ[a, b] âŠ†îˆ»1 âˆªîˆ»2 which leads to two cases.
Case 1: Assume m âˆˆîˆ»1.
Since this is an open set, âˆƒðœ€> 0, s.t.
N(m, ðœ€) âŠ†îˆ»1.
(18.31)
Now m âˆ’ðœ€< m = Sup(B). So âˆƒs âˆˆB such that m âˆ’ðœ€< s. In addition, by the
average theorem, there is t âˆˆ(s, m + ðœ€). Now
m âˆ’ðœ€< s â‰¤m < t < m + ðœ€.
(18.32)
But s âˆˆB; so [a.s] âŠ†îˆ»1.
Consider [a, t].
[a, t] = [a.s] âˆª(m âˆ’ðœ€, t]
(18.33)
âŠ†[a.s] âˆª(m âˆ’ðœ€, m + ðœ€)
âŠ†[a.s] âˆªN(m, ðœ€)
âŠ†îˆ»1 âˆªîˆ»1 = îˆ»1.
Thus, t âˆˆB. But t > m = Sup(B). This is a contradiction.
Case 2. Assume m âˆˆîˆ»2.
Since this is an open set, âˆƒðœ€> 0, such that
N(m, ðœ€) âŠ†îˆ»2.
(18.34)
Now m âˆ’ðœ€< m = Sup(B). So âˆƒs âˆˆB s.t. m âˆ’ðœ€< s. Now s âˆˆB; so [a, s] âŠ†îˆ»1.
So b âˆˆîˆ»1. But we also have
m âˆ’ðœ€< s â‰¤m < m + ðœ€.
(18.35)
So s âˆˆN(m, ðœ€) âŠ†îˆ»2. Since s âˆˆîˆ»1 âˆ©îˆ»2, this is a contradiction.
Thus, our assumption that I âŠˆîˆ»1 and I âŠˆîˆ»2 must be false. That is, I âŠ†îˆ»1
or I âŠ†îˆ»2.
â—½
Sets that are both open and closed
There is a consequence of the inseparability theorem that settles one question
that arose in our examples.
Theorem 18.2.2.
Let A âŠ†â„. If A is both open and closed, then either A = âˆ…or
A = â„.
Proof. Assume A âŠ†â„. Assume that A is open. Assume that A is closed.

356
18 Compact Sets
Now if we let îˆ»1 = A and îˆ»2 = â„\A, we have two open sets with îˆ»1 âˆ©îˆ»2 â‰ âˆ…
and where â„âŠ†îˆ»1 âˆªîˆ»2. Since â„is an interval, the inseparability theorem
tells us that either â„âŠ†îˆ»1 = A âŠ†â„or â„âŠ†îˆ»2 = â„\A âŠ†â„. So either A = â„or
A = âˆ….
â—½
18.3
Problems
18.1
Is the empty set compact?
18.2
Prove: If A âŠ†â„and ðœ•(A) = âˆ…, then either A = âˆ…or A = â„.
18.3
Prove â‹ƒ
nâˆˆâ„•
(âˆ’n, n) = â„.
18.4
Prove that every ï¬nite subset of â„is compact.
(a) Prove this using the Heineâ€“Borel theorem.
(b) Prove this using the deï¬nition of compact.
18.5
Let A âŠ†B âŠ†â„. Assume that A â‰ âˆ…is closed and B is compact.
(a) Prove that A is compact using the Heineâ€“Borel theorem.
(b) Prove that A is compact using the deï¬nition of compact. (Hint: Start
with an open cover of the correct set and add the set â„\A.)
18.6
Let A âŠ†â„be nonempty and bounded below. Prove that if A is open, then
Inf(A) âˆˆAâ€².
18.7
Let A âŠ†â„be nonempty and bounded below. Prove that if Inf(A) âˆ‰Aâ€²,
then Inf(A) âˆˆAâˆ˜.
18.8
Let A âŠ†â„. Prove the contrapositive of the inseparability theorem: If for
all pairs of open sets îˆ»1 and îˆ»2 such that A âŠ†îˆ»1 âˆªîˆ»2, then either A âŠ†
îˆ»1, or A âŠ†îˆ»2, or îˆ»1 âˆ©îˆ»2 â‰ âˆ…, then A is an interval.
18.9
Let A âŠ†â„be a nonempty set. Prove:
(a) If Aâ€² = âˆ…, then A is closed.
(b) If Aâ€² = âˆ…, then A = Aâˆ˜.
(c) If Aâ€² = âˆ…, then there exists a family of open sets îˆ»a indexed by a âˆˆA
so that âˆ€a âˆˆA, îˆ»a âˆ©A = {a}.

18.3 Problems
357
(d) If Aâ€² = âˆ…, then there exists a family of open sets îˆ»a indexed by a âˆˆA
so that âˆ€a âˆˆA, îˆ»a âˆ©A = {a} and where A âŠ†â‹ƒ
aâˆˆA
îˆ»a.
(e) If A is bounded and Aâ€² = âˆ…, then A is ï¬nite. (Hint: Intersect both
sides of the last subset relation with A.)
(f) The Bolzanoâ€“Weierstrass theorem: If A is an inï¬nite bounded subset
of â„, then Aâ€² â‰ âˆ….

359
19
Continuous Functions
19.1
First semester calculus
19.1.1
An intuitive idea of a continuous function
In any ï¬rst semester calculus course, there is a discussion of continuous func-
tions. Typically, there is an implicit assumption that the functions involved are
deï¬ned on at least an interval in â„. This makes sense because our intuition
about a continuous function is based on our intuition of its graph being a con-
tinuous curve. This seems to only make sense when there is a piece of curve
long enough to be drawn without any holes or gaps. In the end, however, the
deï¬nition of a continuous function contains no requirement that the function
be deï¬ned on any length of interval. In fact, the deï¬nition says what it means for
a function to be continuous at a single point. A function is said to be continuous
on an interval if it is continuous at every single point of the interval.
There is a lot left out of this early introduction to continuous functions.
A good calculus text will at least point out some consequences of this
point-by-point deï¬nition. It will state results such as:
The intermediate value theorem: If f (x) is a function continuous on an
interval [a, b] and y = c is a horizontal line between the points on (a, f (a))
and (b, f (b)) on the graph of y = f (x), then the graph must pass through
the line.
That sounds like something a continuous function should do. Later on, there
is a section in the text where students learn how to solve maximum and min-
imum problems. Many of the word problems of this type involve functions
y = f (x) that only make physical sense on a closed interval [a, b]. A shortcut
for ï¬nding the maximum and minimum values the function takes on in that
interval requires that the function be continuous on [a, b]. The shortcut uses
The extreme value theorem: If f (x) is a function continuous on an
interval [a, b], there are values c, d âˆˆ[a, b] so that f (c) is the minimum
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

360
19 Continuous Functions
value the function has on the interval and f (d) is the maximum
value.
That also sounds like something a continuous function should do. It is also
very useful. The theorem says that there must be a minimum and a maximum,
and calculus tells us that they must occur at either critical points in the inter-
val or the end points of the interval. We know the end points; we can ï¬nd the
critical points. If we just ï¬nd the values of f (x) at these few points, the greatest
must be the maximum of all the values of points in the interval, and the least
must be the minimum.
So our ï¬rst mathematical introduction to continuity left out a lot of detail.
However, one thing is absolutely correct, the deï¬nition of a function being con-
tinuous at a point is the oï¬ƒcial deï¬nition of mathematical continuity. We will
ï¬nally make up for these early shortcomings of our mathematical education
and prove the expected results. Our careful deï¬nitions of functions and inter-
vals and our language of topology were designed to make the whole process
quite logical.
19.1.2
The calculus deï¬nition of continuity
The rather amazing thing is that simply saying what we do not want the graph
of a continuous function to look like at one point on an interval is enough to
give us a mathematical deï¬nition of continuity that has universal application.
While the motivation is based on the curve that forms the graph (the ordered
pairs), we must remember that we are interested in the function (the assign-
ment of numbers in the domain to numbers in the range). Basically, there are
four pictures of the graph of a discontinuous function:
â€¢ The graph of the function has a hole in its graph. This is illustrated in
Figure 19.1.
â€¢ The graph of the function has a hole in its graph, but someone tried to ï¬ll it
in and missed. This is illustrated in Figure 19.2.
âˆ’3
âˆ’2 âˆ’1
1
2
1
2
3
4
5
Figure 19.1 A discontinuity.

19.1 First Semester Calculus
361
Figure 19.2 A second type of discontinuity.
âˆ’3
âˆ’2 âˆ’1
1
2
1
2
3
4
5
Figure 19.3 A third type of discontinuity.
âˆ’3
âˆ’2 âˆ’1
1
2
1
2
3
4
5
Figure 19.4 A fourth type of discontinuity.
âˆ’3
âˆ’2 âˆ’1
1
2
1
2
3
4
5
â€¢ The graph of the function jumps from one height to another with a mark
inside or outside the gap. This is illustrated in Figure 19.3.
â€¢ The graph of the function jumps from one height to another but, on one
side or the other, the graph is capped oï¬€at one end. This is illustrated in
Figure 19.4.
The ï¬rst example is easy to deal with. The graph has a hole at x = a because
the function is not deï¬ned at x = a. (In the ï¬gures, a = 2.) To even stand a

362
19 Continuous Functions
chance to be continuous at x = a, then a must be in the domain of the function.
This is why, in the next three cases, we make sure to place a point directly above
a on the x-axis.
The main thing is to describe the next three cases with one mathematical
phrase. The problem may appear to be with the graph, but we want to con-
centrate on the function. The domain of the function is the x-axis, and the
codomain is the y-axis. The gap we are worried about appears clearly on the
vertical line above x = a. Because it is vertical, we push the graph over to the
codomain to see what the discontinuity looks like there.
We see that we do not want to look at the whole range of the function, because
the gap caused by the discontinuity gets covered up by other parts of the graph
far away from the singularity. We need to stay close to the x = a in the domain
so as to not lose that gap. We stay close to x = a by considering the image of
an appropriate neighborhood of a. In the second and third examples, there is a
neighborhood of a (in the domain) small enough that the image of that neigh-
borhood leaves f (a) an isolated point in the codomain. We can say this in our
new language of topology.
In the second and third examples, the function is not continuous because
there is a ð›¿> 0 so that f (a) is a discrete point of f (N(a, ð›¿)).
This is not the only way a function will be discontinuous, but these two
examples do tell us that the issue is with points in the image of neighborhoods
of a. So we know what to look at in the ï¬nal picture. In this case, f (a) is not
a discrete point of f (N(a, ð›¿)), but it is separated from some of the points in
f (N(a, ð›¿)). Now we will make a series of restatements of this basic notion
of discontinuity that gradually become closer to a logical form we can deal
with:
1. The function f (x) is not continuous at x = a because there is a neighborhood
of f (a) that does not contain the entire image of any neighborhood of a.
2. The function f (x) is not continuous at x = a because there is a neighborhood
N(f (a), ðœ€) of f (a) so that the image of every neighborhood of a contains a
point not in N(f (a), ðœ€).
3. The function f (x) is not continuous at x = a because there is a neighborhood
N(f (a), ðœ€) of f (a) so that, for every neighborhood N(a, ð›¿) of a, the image of
N(a, ð›¿) is not a subset of N(f (a), ðœ€).
4. The function f (x) is not continuous at x = a because there is an ðœ€> 0 so that,
for every neighborhood N(a, ð›¿) of a, f (N(a, ð›¿)) âŠˆN(f (a), ðœ€).
5. The function f (x) is not continuous at x = a because there is an ðœ€> 0 so that
for all ð›¿> 0, f (N(a, ð›¿)) âŠˆN(f (a), ðœ€).
This formulation covers all cases with a in the domain, and f (x) is still not
continuous at x = a. We now know what it means for a function not to be

19.1 First Semester Calculus
363
continuous at x = a in the domain:
âˆƒðœ€> 0 s.t. âˆ€ð›¿> 0, f (N(a, ð›¿)) âŠˆN(f (a), ðœ€).
(19.1)
We negate this to ï¬nd out what it means for a function to be continuous at x = a
in the domain:
âˆ€ðœ€> 0, âˆƒð›¿> 0 s.t. f (N(a, ð›¿)) âŠ†N(f (a), ðœ€).
(19.2)
Let us keep going. This says âˆ€ðœ€> 0, âˆƒð›¿> 0 such that if x âˆˆN(a, ð›¿), then f (x) âˆˆ
N(f (a), ðœ€). In the language of Calculus I, this says:
âˆ€ðœ€> 0, âˆƒð›¿> 0 s.t. if |x âˆ’a| < ð›¿, then |f (x) âˆ’f (a)| < ðœ€.
(19.3)
Just about every calculus textbook in the world contains this deï¬nition.
19.1.3
The oï¬ƒcial mathematical deï¬nition of continuity
Basically, we just stated the oï¬ƒcial deï¬nition; however, we have not been that
careful with our functional notation. We ï¬x that now.
Deï¬nition 19.1.1.
Let f âˆ¶â„â†’â„have domain D. We say that f (x) is contin-
uous at x = a if
1. a âˆˆD;
2. âˆ€ðœ€> 0, âˆƒð›¿> 0, such that if x âˆˆD and |x âˆ’a| < ð›¿, then |f (x) âˆ’f (a)| < ðœ€.
Equivalently,
1. a âˆˆD;
2. âˆ€ðœ€> 0, âˆƒð›¿> 0 s.t. f (N(a, ð›¿)) âŠ†N(f (a), ðœ€).
There are two versions of this deï¬nition. As a rule, the ï¬rst algebraic deï¬ni-
tion is preferred when the function involved is given by an explicit formula, the
kind of function f âˆ¶â„â†’â„we saw in calculus. The second topological deï¬ni-
tion works best on abstract functions, the kind that appear in general theorems
involving continuity. We will see plenty of examples of both.
We also should look into the sudden appearance of the condition x âˆˆD in the
second part of the algebraic version. This is actually there for logical reasons.
We know from logic that P â‡’Q is automatically true if P is false or if Q is
true. But what happens if Q has no truth value at all? For P â‡’Q to be a logical
statement, both P and Q must be logical statements. Look at â€œ|f (x) âˆ’f (a)| < ð›¿;â€
it is not a logical statement until the x is qualiï¬ed. It makes no sense unless
x âˆˆD. The rules of logic tell us that P â‡’Q is automatically true if Q is true,
but they does not cover the situation where Q is not a logical statement at all.
So we add the condition x âˆˆD to the statement just to be sure that it means
something. Then our deï¬nition (if x âˆˆD and |x âˆ’a| < ð›¿, then |f (x) âˆ’f (a)| < ðœ€)

364
19 Continuous Functions
is a logical statement; so it will be either true or false. That is what we use in the
algebraic deï¬nition:
We say that f (x) is continuous at x = a if
1. a âˆˆD;
2. âˆ€ðœ€> 0, âˆƒð›¿> 0, such that if x âˆˆD and |x âˆ’a| < ð›¿, then | f (x) âˆ’f (a)| < ðœ€.
In the topological deï¬nition, the set theory deï¬nition of image takes care of
this problem.
f (N(a, ð›¿)) = {y âˆˆâ„| âˆƒx âˆˆN(a, ð›¿) s.t. f (x) = y}.
(19.4)
Thus, y is not in the set unless f (x) = y for some x âˆˆN(a, ð›¿). But f (x) = y means
that x must be an element of D. The deï¬nition of the image of a set means that
f (N(a, ð›¿) âˆ©D) = f (N(a, ð›¿)).
(19.5)
The algebraic and topological deï¬nitions of continuity are exactly the same.
19.1.4
Examples
Example 19.1.2.
Let f âˆ¶â„â†’â„be given by f (x) = 3x âˆ’5. Prove that this is
continuous at x = 4.
Comment: Linear functions are so easy that this is probably the only time we will
ever see one done carefully. What are we proving? âˆ€ðœ€> 0, âˆƒð›¿> 0 s.t. if x âˆˆD
and |x âˆ’a| < ð›¿, then |f (x) âˆ’f (a)| < ðœ€. We choose the algebraic version because
f (x) is given by a formula. We know how to start such a proof.
Proof draft. Assume ðœ€> 0.
Comment: Now what are we proving? âˆƒð›¿> 0 s.t. â€œsomething weird.â€ We prove
that something exists by setting up a word problem and solving it. We have hit
a point where this really must be done outside the proof using scratch work. We
might be able to guess a good ð›¿in this particular example, but remember, this
example is so easy that we will probably never see one as this again. We are
more interested in the reasoning that produces a correct proof than the proof
itself.
Scratch work:
We want ð›¿so that ð›¿> 0 and so that if x âˆˆD and |x âˆ’a| < ð›¿, then |f (x) âˆ’f (a)| <
ðœ€. Since D = â„we can ignore the ï¬rst condition. We concentrate on
|x âˆ’a| < ð›¿â‡’|f (x) âˆ’f (a)| < ðœ€.
(19.6)

19.1 First Semester Calculus
365
Once we have a ð›¿, the proof of this will begin with: Assume |x âˆ’4| < ð›¿. And it
will end with |f (x) âˆ’f (4)| < ðœ€. We look at the end and work backward.
|f (x) âˆ’f (4)| < ðœ€;
(19.7)
|(3x âˆ’5) âˆ’7| < ðœ€;
|3x âˆ’12| < ðœ€;
|3(x âˆ’4)| < ðœ€;
3|x âˆ’4| < ðœ€.
We must be very lucky. The one thing we have control over is |x âˆ’4|, and it has
appeared in what we need to prove. To get this last inequality, we need
|x âˆ’4| < ðœ€
3.
(19.8)
We can get this by picking ð›¿= ðœ€
3.
Back to our draft of the proof.
Assume ðœ€> 0. Let ð›¿= ðœ€
3.
Claim. If x âˆˆâ„and |x âˆ’4| < ð›¿, then |f (x) âˆ’f (4)| < ðœ€.
Proof of claim. Assume |x âˆ’4| < ð›¿. Then |x âˆ’4| < ðœ€
3. So we have
|x âˆ’4| < ðœ€
3;
(19.9)
3|x âˆ’4| < ðœ€;
|3x âˆ’12| < ðœ€;
|(3x âˆ’5) âˆ’7| < ðœ€;
|f (x) âˆ’f (4)| < ðœ€.
â—¾
Comment: So our scratch work made it into the proof after all, just backward.
This is what we should expect in most proofs that require extensive scratch work.
The work appears logically backward in the written proof. In addition, notice
that as we write up this proof of continuity, we assume that we have an ðœ€and
then assign a value to the ð›¿. We then prove that the ð›¿works by making a claim
that: if x âˆˆD and |x âˆ’a| < ð›¿, then |f (x) âˆ’f (a)| < ðœ€. We then prove the claim.
This is just one option in how the proof is written. It does, however, help organize
the logic of this type of proof. So as we do our ï¬rst continuity proofs, we will stick
with this organization.
Î”
Proof. Assume ðœ€> 0. Let ð›¿= ðœ€
3.

366
19 Continuous Functions
Claim. If x âˆˆâ„and |x âˆ’4| < ð›¿, then |f (x) âˆ’f (4)| < ðœ€.
Proof of claim. Assume |x âˆ’4| < ð›¿. Then |x âˆ’4| < ðœ€
3. So we have
|x âˆ’4| < ðœ€
3;
(19.10)
3|x âˆ’4| < ðœ€;
|3x âˆ’12| < ðœ€;
|(3x âˆ’5) âˆ’7| < ðœ€;
|f (x) âˆ’f (4)| < ðœ€.
â—¾
This completes our proof that f (x) = 3x âˆ’5 is continuous at x = 4.
â—½
What about that moment of luck? Well, the reason we were so lucky is that we
were proving a theorem that was true. It had to work. If we are proving that f (x)
is continuous at x = a and it is true, we should expect to turn |f (x) âˆ’f (a)| < ðœ€
into something involving |x âˆ’a|.
Now that we have done this example, we realize that the choice of ð›¿= ðœ€
3
should have been clear. The slope of this linear function is 3; the way to get
a change in y of ðœ€is to make a change in x of ðœ€
3. Sure enough, the slope at x = a
will always play a role in proving that f (x) is continuous at x = a; however, not
in a very straightforward way. The problem is in any function other than a linear
function, the slope at a point changes with even a small change away from the
point. The power of calculus is that it allows us to deal with a changing slope.
Unfortunately, we do not have calculus yet. Worse, in order to get calculus, we
need to understand continuity.
In the following examples, we illustrate a typical strategy for proving that a
function is continuous at a point. Such proofs will always begin by ï¬xing an
arbitrary ðœ€> 0. The goal then, as we have seen, is to construct ð›¿> 0 so that
if |x âˆ’a| < ð›¿, then |f (x) âˆ’f (a)| < ðœ–. A typical strategy for constructing ð›¿is as
follows.
1. Find an approximation of the slope ma of the function at x = a.
2. Choose a neighborhood N(a, ð›¿a) of x = a where that approximation is valid.
Then a typical choice of ð›¿looks like
ð›¿= Min
({
ðœ€
ma
, ð›¿a
})
.
(19.11)
The result of this choice of ð›¿is that ð›¿â‰¤
ðœ€
ma , and ð›¿â‰¤ð›¿a. That way the
ðœ€
ma will
do a slope-like thing, and ð›¿a will make sure that ma is close enough to the real
slope that the approximation will work.
Oddly enough, we usually pick the ð›¿a ï¬rst, and we pick it by guessing.

19.1 First Semester Calculus
367
Example 19.1.3.
Let f âˆ¶â„â†’â„be given by f (x) = 3x2 âˆ’x âˆ’5. Prove that
this is continuous at x = 4.
Comment: All these proofs begin the same way, by ï¬xing an arbitrary ðœ€> 0 and
then declaring our choice of ð›¿. However, the real work of the proof is ï¬nding that
ð›¿, and we have not even started yet. The process outlined earlier gives us an idea
of what ð›¿might look like. Once we ï¬nd our ð›¿using that process, our proof will
begin as follows.
Proof draft. Assume ðœ€> 0. Let ð›¿= Min({â—½, â—½}). Then ð›¿> 0, and ð›¿â‰¤â—½and
ð›¿â‰¤â—½.
Comment: Yes, those are empty boxes. Again, we expect that our process for ï¬nd-
ing ð›¿will work, but we have not even started that yet! In our draft here, we start
with a simple logical outline for the beginning of the proof even though we have
a lot of parts that we need to ï¬ll in. Once we have built a ð›¿that we know works,
we will rewrite our scratch work as a proof. As we go along, each time we make
a bit of progress, we will see how far we can push the proof.
At this point, we need to prove
If x âˆˆâ„and |x âˆ’4| < ð›¿, then |f (x) âˆ’f (4)| < ðœ€.
So far we can say: assume |x âˆ’4| < ð›¿. Then |x âˆ’4| < â—½and |x âˆ’4| < â—½.
Ok, there is not too much we can do at this point.
We now turn to ï¬lling in the boxes. In one box, we need to pick a range around 4
that will keep the approximation of the slope (once we ï¬nd it) out of trouble. This
value is the ð›¿a referred to in the aforementioned process. As we mentioned, we
start by guessing at this value. In principle, the smaller we choose ð›¿a, the better,
but in practice, choosing something like
1
1000 makes the calculations miserable.
We keep things simple at the start by making our default ï¬rst guess ð›¿a = 1. With
this guess, let us see how far we can push our proof.
Assume ðœ€> 0. Let ð›¿= Min({1, â—½}). Then ð›¿> 0, and ð›¿â‰¤1 and ð›¿â‰¤â—½.
Claim. If x âˆˆâ„and |x âˆ’4| < ð›¿, then |f (x) âˆ’f (4)| < ðœ€.
Draft proof of this claim so far. Assume |x âˆ’4| < ð›¿. Then |x âˆ’4| < 1 and
|x âˆ’4| < â—½.
Now |x âˆ’4| < 1. So
âˆ’1 < x âˆ’4 < 1;
(19.12)
3 < x < 5.
Comment: We carried out the logic to say as much as we can about x. There
might be other useful things to say at this point, but we need to analyze our goal

368
19 Continuous Functions
a little more. We will do some scratch work to ï¬gure out where we need to go
with this.
â—¾
Scratch work:
We want
|x âˆ’4| < ð›¿â‡’|f (x) âˆ’f (4)| < ðœ€.
(19.13)
We try to turn |f (x) âˆ’f (4)| into something involving |x âˆ’4|. To do so, we look
at the end and work backward.
|f (x) âˆ’f (4)| < ðœ€;
(19.14)
|3x2 âˆ’x âˆ’5 âˆ’39| < ðœ€;
|3x2 âˆ’x âˆ’44| < ðœ€;
|(3x + 11)(x âˆ’4)| < ðœ€;
|3x + 11| â‹…|x âˆ’4| < ðœ€.
This tells us that if we can arrange things so that
|3x + 11| â‹…|x âˆ’4| < ðœ€,
then we can show that |f (x) âˆ’f (4)| < ðœ€.
Comment: Our goal in this scratch work was to write |f (x) âˆ’f (4)| with a factor of
|x âˆ’4| because that is the quantity that we can control. In addition, remember
that we know |x âˆ’4| will be a factor. If it is not, either we are trying to prove
something that is false or we have made an algebra mistake.
Now we would like to divide both sides by |3x + 11|, but we cannot be sure
that this is legal unless we are sure that |3x + 11| â‰ 0. But this is exactly what
our control value ð›¿a is for, to keep this factor from being 0. Did it do the job? We
use what we know about x to say as much as we can about |3x + 11|. We stopped
our draft of the proof saying something about x. We start over again in our draft
using that to say something about |3x + 11|.
Assume ðœ€> 0. Let ð›¿= Min({1, â—½}). Then ð›¿> 0, and ð›¿â‰¤1 and ð›¿â‰¤â—½.
Claim. If x âˆˆâ„and |x âˆ’4| < ð›¿, then |f (x) âˆ’f (4)| < ðœ€.
Draft proof of this claim so far. Assume |x âˆ’4| < ð›¿. Then |x âˆ’4| < 1 and
|x âˆ’4| < â—½.
Now |x âˆ’4| < 1. So
âˆ’1 < x âˆ’4 < 1;
(19.15)
3 < x < 5;
9 < 3x < 15;

19.1 First Semester Calculus
369
20 < 3x + 11 < 26;
20 < |3x + 11| < 26;
1
26 <
1
|3x + 11| < 1
20;
ðœ€
26 <
ðœ€
|3x + 11| < ðœ€
20.
â—¾
Comment: On the ï¬fth step of this calculation, we found out that it was safe
to divide by |3x + 11|. We kept going to see what would happen when we did.
Remember where we were when we suspended the scratch work. We wanted
|f (x) âˆ’f (4)| < ðœ€, and we could get it if
|3x + 11| â‹…|x âˆ’4| < ðœ€.
(19.16)
But now we can divide:
|x âˆ’4| <
ðœ€
|3x + 11|.
(19.17)
This tells us that if we can get |x âˆ’4| <
ðœ€
|3x+11|, then we can get |f (x) âˆ’f (4)| < ðœ€.
However, we cannot let ð›¿=
ðœ€
|3x+11| in our proof. This is why we outlined the logic
of the proof ï¬rst. We see that in that logic, x appears when we make our claim.
Part of our assumptions about x involve the value for ð›¿that we choose. So the x
depends on the ð›¿. A choice of a ð›¿that involves x would create circular reasoning
in the proof. We cannot let this happen. This is very important to remember:
The ð›¿in a proof of continuity cannot involve the variable x in the later claim:
If x âˆˆâ„and |x âˆ’a| < ð›¿, then |f (x) âˆ’f (a)| < ðœ€! But we do not need ð›¿=
ðœ€
|3x+11|
to get where we want. All we need is
|x âˆ’4| <
ðœ€
|3x + 11|.
(19.18)
We could use transitivity if we could only ï¬nd some â€œ?â€ that ï¬t between these
|x âˆ’4| < ? <
ðœ€
|3x + 11|.
(19.19)
We know for sure
ðœ€
26 <
ðœ€
|3x + 11|.
(19.20)
If we ï¬ll in the still empty box in the ð›¿(Let ð›¿= Min({1, â—½})) with
ðœ€
26, then
we would know that if |x âˆ’4| < ð›¿, then |x âˆ’4| <
ðœ€
26, and then by transitivity,
|x âˆ’4| <
ðœ€
|3x+11|.
So we have ï¬nally found our ð›¿! We can now return and ï¬nish oï¬€our draft of
a proof. Instead, we will start over completely and write the ï¬nal version of the
whole proof.
Î”

370
19 Continuous Functions
Example 19.1.4.
Let f âˆ¶â„â†’â„be given by f (x) = 3x2 âˆ’x âˆ’5. Prove that
this is continuous at x = 4.
Proof. Assume ðœ€> 0. Let ð›¿= Min({1, ðœ€
26}). Then ð›¿> 0, and ð›¿â‰¤1 and ð›¿â‰¤
ðœ€
26.
Claim. We claim that if x âˆˆâ„and |x âˆ’4| < ð›¿, then |f (x) âˆ’f (4)| < ðœ€.
Proof of claim. Assume |x âˆ’4| < ð›¿. Then |x âˆ’4| < 1 and |x âˆ’4| <
ðœ€
26.
Now |x âˆ’4| < 1. So
âˆ’1 < x âˆ’4 < 1;
(19.21)
3 < x < 5;
9 < 3x < 15;
20 < 3x + 11 < 26;
20 < |3x + 11| < 26;
1
26 <
1
|3x + 11| < 1
20;
ðœ€
26 <
ðœ€
|3x + 11| < ðœ€
20.
But we then have
|x âˆ’4| < ðœ€
26 <
ðœ€
|3x + 11|.
(19.22)
So
|x âˆ’4| <
ðœ€
|3x + 11|;
(19.23)
|3x + 11| â‹…|x âˆ’4| < ðœ€;
|3x2 âˆ’x âˆ’44| < ðœ€;
|3x2 âˆ’x âˆ’44| < ðœ€;
|3x2 âˆ’x âˆ’5 âˆ’39| < ðœ€;
|f (x) âˆ’f (4)| < ðœ€.
â—¾
So if ðœ€> 0 and ð›¿= Min({1, ðœ€
26}), then ð›¿> 0 and if x âˆˆâ„and |x âˆ’4| < ð›¿, then
|f (x) âˆ’f (4)| < ðœ€. We have therefore proved f (x) is continuous at x = 4.
â—½
Notice that our default guess of 1 for a control worked quite well. If it had not,
we would have hit an interval for x âˆ’a that included 0. When this happens, and
it will on occasion, it is simply a matter of choosing a smaller control. By this
time, however, the scratch work may help make a more informed choice. Still
we must remember that 1 is our default guess, but it is still a guess. If we have
the chance to make a more informed guess, we should.

19.1 First Semester Calculus
371
Example 19.1.5.
Let f âˆ¶â„â†’â„be given by f (x) =
1
2xâˆ’5. Prove that this is
continuous at x = 2.
Proof draft. Comment: Notice that the domain of this function is â„âˆ–{ 5
2}. It is
pretty clear then that x = 5
2 is a point that we should steer clear of. Still all the
proofs begin the same way.
Assume ðœ€> 0. Let ð›¿= Min({â—½, â—½}). Then ð›¿> 0, and ð›¿â‰¤â—½and ð›¿â‰¤â—½.
Comment: We want to prove
If x âˆˆâ„and |x âˆ’2| < ð›¿, then |f (x) âˆ’f (2)| < ðœ€.
So far we can say: assume |x âˆ’2| < ð›¿. Then |x âˆ’2| < â—½and |x âˆ’2| < â—½.
Again, not too much to say at this point. But it is a good idea to always keep in
mind where we are headed and to see how much further we can push this each
time we make progress.
Notice that we want to make sure that x is not close to 5
2; so a control of 1 will
be too big because 5
2 is less than one away from 2. In fact, we could be daring and
try 1
2, but that is cutting it very close. Better to make our ï¬rst guess 1
4. Let us work
backward from what we want to ï¬gure out a good choice for our other bound
on ð›¿.
Scratch work:
We want |f (x) âˆ’f (2)| < ðœ€. This is
||||
1
2x âˆ’5 + 1
||||
< ðœ€.
(19.24)
Finding a common denominator and simplifying the left-hand side gives
||||
2x âˆ’4
2x âˆ’5
||||
< ðœ€.
(19.25)
And now we see our desired factor of |x âˆ’2|:
2|x âˆ’2|
|2x âˆ’5| < ðœ€.
(19.26)
So, if we can make sure that
|x âˆ’2| < |2x âˆ’5|ðœ€
2
.
(19.27)
then, since all of these steps are reversible, we can force |f (x) âˆ’f (2)| < ðœ€. Now,
again, x cannot appear in our choice for ð›¿, so we need to ï¬nd a â€œ?â€ that does not
depend on x and satisï¬es
|x âˆ’2| <? < |2x âˆ’5|ðœ€
2
.
(19.28)

372
19 Continuous Functions
That brings up the question of just how big |2x âˆ’5| is anyway. After all, by our
choice of control |x âˆ’2| < 1
4. So
âˆ’1
4 <x âˆ’2 < 1
4;
(19.29)
âˆ’1
2 <2x âˆ’4 < 1
2;
âˆ’3
2 <2x âˆ’5 < âˆ’1
2.
So, 1
2 < |2x âˆ’5| < 3
2. Since 1
2 < |2x âˆ’5|, it follows that ðœ€
4 < |2xâˆ’5|ðœ€
2
.
Comment: Ok, now we have found our ð›¿. If we choose ð›¿= Min
({
ðœ€
4, 1
4
})
then
our proof should work!
Î”
Let us rewrite this all as a formal proof, with all of the calculations going in
the direction we need.
Proof. Here recall that we are proving that f âˆ¶â„â†’â„given by f (x) =
1
2xâˆ’5 is
continuous at x = 2.
Assume ðœ€> 0. Let ð›¿= Min
({
1
4, ðœ€
4
})
. Then ð›¿> 0, and ð›¿â‰¤1
4 and ð›¿â‰¤ðœ€
4.
Claim. If x âˆˆâ„and |x âˆ’2| < ð›¿, then |f (x) âˆ’f (2)| < ðœ€.
Proof of claim. Assume |x âˆ’2| < ð›¿. Then |x âˆ’2| < 1
4 and |x âˆ’2| < ðœ€
4.
First |x âˆ’2| < 1
4. Then
âˆ’1
4 < x âˆ’2 < 1
4;
âˆ’1
2 < 2x âˆ’4 < 1
2;
(19.30)
âˆ’3
2 < 2x âˆ’5 < âˆ’1
2;
1
2 < |2x âˆ’5| < 3
2;
1
4 < |2x âˆ’5|
2
< 3
4.
What is important here is that 1
4 < |2xâˆ’5|
2
because that allows us to conclude
that ðœ€
4 < |2xâˆ’5|ðœ€
2
. Since we also have |x âˆ’2| < ðœ€
4, we can calculate as follows:
|x âˆ’2| < |2x âˆ’5|ðœ€
2
;
(19.31)

19.1 First Semester Calculus
373
2|x âˆ’2|
|2x âˆ’5| < ðœ€;
||||
2x âˆ’4
2x âˆ’5
||||
< ðœ€;
||||
1
2x âˆ’5 + 1
||||
< ðœ€;
|f (x) âˆ’f (2)| < ðœ€.
â—¾
We have now shown that for any ðœ€> 0, we can ï¬nd ð›¿> 0 so that if |x âˆ’2| < ð›¿,
then |f (x) âˆ’f (2)| < ðœ€. It follows that f (x) is continuous at x = 2.
â—½
There is another way to think about the control part of â€œLet ð›¿=
Min({ 1
4, ðœ€
4
}).â€ These arguments are all about small values of ðœ€and ð›¿.
But the formula that uses these variables works for all values no matter how big
or small. Our calculations are meant to cover the cases where these numbers
are small. The control part of the minimum 1
4, makes sure that we are doing
just that; it makes sure that a value of ðœ€= 10100 does not mess up the whole
argument by letting ð›¿be ridiculously large. There are times when we will need
to place this size control on the ðœ€before we get to the ð›¿. It still plays the same
role of keeping both ðœ€and ð›¿reasonably small.
Our next example illustrates this. It solves a technical problem that we have at
this point in our study of the real numbers. While we expect that every positive
real number will have a square root, we have not yet proved this. We will soon
enough, but until then we cannot assume it for fear of creating some circular
reasoning.
Example 19.1.6.
Let f âˆ¶â„â†’â„be given by f (x) = x2. Prove that this is con-
tinuous at x = 0.
Comment: Luckily, the domain is â„, so we do not have to worry about acciden-
tally including a point not in the domain by choosing our control too large.
Again, all these proofs begin the same way. Here, since there are no domain
issues to worry about, we will go back to our default guess of 1 for the control.
Proof draft. Assume ðœ€> 0. Let ð›¿= Min({1, â—½}). Then ð›¿> 0, and ð›¿â‰¤1 and
ð›¿â‰¤â—½.
Comment: We aim to prove that
If x âˆˆâ„and |x âˆ’0| < ð›¿, then |f (x) âˆ’f (0)| < ðœ€.
So far we can say: assume |x âˆ’0| < ð›¿. Then |x âˆ’0| < 1 and |x âˆ’0| < â—½.
Again, not too much to say at this point, but we remind ourselves of what we
need to do.

374
19 Continuous Functions
Scratch work:
We want |f (x) âˆ’f (0)| < ðœ€, but that is simply |x2| < ðœ€. That is |x|2 < ðœ€. Clearly,
we want ð›¿=
âˆš
ðœ€, but that is not yet allowed.1 Whenever we feel we need a
square root to pick the right ð›¿, we should remember the following trick, which
we illustrate in the ï¬nal version of this proof.
Î”
Proof. Assume ðœ€> 0. Let ðœ€0 = Min({ðœ€, 1}). Then ðœ€0 > 0, ðœ€0 â‰¤ðœ€, and ðœ€0 â‰¤1.
However, because ðœ€0 > 0, we can multiply ðœ€0 â‰¤1 by it. So ðœ€2
0 â‰¤ðœ€0, and in turn,
ðœ€2
0 â‰¤ðœ€0 â‰¤ðœ€.
Let ð›¿= ðœ€0.
Claim. If x âˆˆâ„and |x âˆ’0| < ð›¿, then |f (x) âˆ’f (0)| < ðœ€.
Proof of claim. Assume |x| < ð›¿. Then |x|< ðœ€0 and
|x|2 < ðœ€2
0 â‰¤ðœ€0 â‰¤ðœ€.
(19.32)
Thus, |f (x) âˆ’f (0)| = |x2| < ðœ€.
â—¾
We have now shown that, for any ðœ€> 0, we can ï¬nd ð›¿> 0 so that, if |x âˆ’0| <
ð›¿, then |f (x) âˆ’f (0)| < ðœ€. It follows that f (x) is continuous at x = 0.
â—½
In the ï¬rst examples, our ï¬rst drafts of the proofs came out so well that they
can serve as the ï¬nal version. We were lucky, our ï¬rst guess for the control value
worked. In the last example, the original draft needed to be revised, but after
that, the draft came out pretty clean. We cannot count on this always happen-
ing. As always, if the draft is correct but needs rewriting, we are not done with
the proof until it is rewritten.
19.2
Theorems about continuity
The object now is to develop a theory of continuous functions that will eliminate
the need, except as an exercise, to prove that every function is continuous at
every point using the ð›¿-ðœ€-deï¬nition.
19.2.1
Three speciï¬c functions
We begin by proving general continuity results about three functions that will
provide seeds for use in the theorems that follow. The ï¬rst two are very simple.
1 As of now in the text we have only proved that
âˆš
2 exits. We have not yet proved that the
square root of any positive number exists, so we do not want to assume it. But stay tuned!

19.2 Theorems About Continuity
375
Theorem 19.2.1.
Let f âˆ¶â„â†’â„be given by f (x) = c for a constant c âˆˆâ„.
Then f (x) is continuous at all x = a âˆˆâ„.
Proof. Assume a âˆˆâ„. Assume ðœ€> 0. Let ð›¿= 1 (or any other positive number
for that matter).
Claim. If x âˆˆâ„and |x âˆ’a| < ð›¿, then |f (x) âˆ’f (a)| < ðœ€.
Proof of claim. Assume |x âˆ’a| < ð›¿. Then |f (x) âˆ’f (a)| = |c âˆ’c| = 0 < ðœ€.
â—¾
This shows that f (x) = c is continuous at any a âˆˆâ„.
â—½
The moral here is that, if you cannot miss, you do not need to aim.
Theorem 19.2.2.
Let f âˆ¶â„â†’â„be given by f (x) = x. Then f (x) is continuous
at all x = a âˆˆâ„.
Proof. Assume a âˆˆâ„. Assume ðœ€> 0. Let ð›¿= ðœ€.
Claim. We claim that with this choice of ð›¿, if x âˆˆâ„and |x âˆ’a| < ð›¿, then |f (x) âˆ’
f (a)| < ðœ€.
Proof of claim. Assume |x âˆ’a| < ð›¿= ðœ€. Then |f (x) âˆ’f (a)| = |x âˆ’a| < ðœ€.
â—¾
This proves that the function f âˆ¶â„â†’â„given by f (x) = x is continuous at all
x = a âˆˆâ„.
â—½
Theorem 19.2.3.
Let f âˆ¶â„â†’â„be given by f (x) = 1
x. Then f (x) is continuous
at all x = a âˆˆâ„âˆ–{0}.
Proof. Assume a âˆˆâ„.
Comment: This time the domain is â„âˆ–{0}. It is pretty clear then that x = 0 is a
point that we should steer clear of.
Assume a â‰ 0.
Comment: We want to make sure that x is not close to 0; so a control of 1 might be
too big. But no precise number will ever be sure to work because we do not know
the value of a. Our guess must depend on a. Notice that we assume we have an
a â‰ 0 before we choose our ð›¿. That assures us that we can use a in a formula
for ð›¿. Now |a|
2 should work to keep x away from 0. But now that brings up the
question: is a > 0 or a < 0? It looks like we have two cases to consider.

376
19 Continuous Functions
There are two cases a > 0 or a < 0.
Case 1: Assume a > 0.
Comment: All of these proofs begin the same way.
Assume ðœ€> 0.
Comment: Unlike our last two theorems about the continuity of f (x) = c and
f (x) = x, this one requires some scratch work as we saw in our examples to ï¬gure
out what to choose for ð›¿. We are going to leave this scratch work out of this
write-up, but it is an essential part of the construction of the proof. Without it,
our choice for ð›¿will seem like it came out of nowhere.
Let ð›¿= Min({ a
2, a2ðœ€
2 }). Then ð›¿> 0, and ð›¿â‰¤a
2 and ð›¿â‰¤a2ðœ€
2 .
Claim. We claim that with this choice of ð›¿, if x âˆˆâ„and |x âˆ’a| < ð›¿, then |f (x) âˆ’
f (a)| < ðœ€.
Proof of claim. Assume |x âˆ’a| < ð›¿. Then |x âˆ’a| < a
2 and |x âˆ’a| < a2ðœ€
2 .
Since |x âˆ’a| < a
2, we have
âˆ’a
2 < x âˆ’a < a
2;
(19.33)
a
2 < x < 3a
2 ;
a
2 < |x| < 3a
2
because a
2 > 0. Then we multiply by aðœ€> 0;
a2ðœ€
2
< aðœ€|x| < 3a2ðœ€
2
.
(19.34)
But we also have |x âˆ’a| < a2ðœ€
2 . So
|x âˆ’a| < a|x|ðœ€;
(19.35)
|x âˆ’a|
a|x|
< ðœ€;
||||
a âˆ’x
ax
||||
< ðœ€;
||||
1
x âˆ’1
a
||||
< ðœ€;
|f (x) âˆ’f (a)| < ðœ€.
â—¾
We leave case 2, where a < 0, as an exercise.
â—½

19.2 Theorems About Continuity
377
19.2.2
Multiplying a continuous function by a constant
Theorem 19.2.4.
Let f âˆ¶â„â†’â„have domain D. For c âˆˆâ„, let g âˆ¶â„â†’â„be
given by g(x) = cx. If f (x) is continuous at x = a, then g(x) is continuous at x = a.
The proof of this is easy unless we fall into the traps of not remembering our
arithmetic or of losing our logical discipline and assuming the wrong thing.
Proof draft. Assume c âˆˆâ„. Let g(x) = cx. Assume that f (x) is continuous at
x = a. First note that D = Domain(f ) = Domain(g); so since f (x) must be
deï¬ned at x = a to be continuous there, we know that a âˆˆD = Domain(g).
Because f (x) is continuous at x = a, we also know that âˆ€ðœ€> 0, âˆƒð›¿> 0 such
that if x âˆˆD and |x âˆ’a| < ð›¿, then |f (x) âˆ’f (a)| < ðœ€.
Comment: This tells us that if we ever have an ðœ€> 0, then we will know some-
thing. It is important to note that this statement does not give an ðœ€for the proof.
Now, what are we proving? We want to prove that g(x) is continuous at
x = a. That is, if ðœ€> 0, then âˆƒð›¿> 0 such that if x âˆˆD and |x âˆ’a| < ð›¿, then
|g(x) âˆ’g(a)| < ðœ€. Now we can assume that we have an ðœ€. That leads us to some
scratch work.
Scratch work:
Once we have this ðœ€, we want |g(x) âˆ’g(a)| < ðœ€. So we want
|g(x) âˆ’g(a)| < ðœ€;
(19.36)
|cf (x) âˆ’cf (a)| < ðœ€;
|c| â‹…|f (x) âˆ’f (a)| < ðœ€;
|f (x) âˆ’f (a)| < ðœ€
|c|
Comment: With this we see that we are in luck. We can make |f (x) âˆ’f (a)|
smaller than any positive number. We can get what we need by using the
deï¬nition of f (x) continuous at x = a on the positive number
ðœ€
|c|. Ah, but wait,
can we divide by |c|? We need to consider the case where c = 0.
There are two possibilities: c = 0 or c â‰ 0. In the ï¬rst case, g(x) = 0 is a con-
stant function. So it is continuous at x = a.
In case 2, assume c â‰ 0. Thus, |c| > 0.
Comment: What are we proving now? If we have any ðœ€> 0, then we can get g(x)
close to g(a) with a good ð›¿. So we begin as usual.
Assume ðœ€> 0. Then
ðœ€
|c| > 0. Since f (x) is continuous at x = a, âˆƒð›¿> 0 such
that if x âˆˆD and |x âˆ’a| < ð›¿, then |f (x) âˆ’f (a)| <
ðœ€
|c|.

378
19 Continuous Functions
Claim. If x âˆˆD and |x âˆ’a| < ð›¿, then |g(x) âˆ’g(a)| < ðœ€.
Proof of claim. Assume that we have x âˆˆD and |x âˆ’a| < ð›¿. Then
|f (x) âˆ’f (a)| < ðœ€
|c|.
(19.37)
So
|c| â‹…|f (x) âˆ’f (a)| < ðœ€;
(19.38)
|cf (x) âˆ’cf (a)| < ðœ€;
|g(x) âˆ’g(a)| < ðœ€.
â—¾
So g(x) is continuous at x = a.
Î”
This draft should be rewritten to give a nice proof. We leave that as an
exercise.
19.2.3
Adding continuous functions
Theorem 19.2.5.
Let f âˆ¶â„â†’â„have domain D and let g âˆ¶â„â†’â„have
domain E. Deï¬ne h âˆ¶â„â†’â„by h(x) = f (x) + g(x).
If f (x) is continuous at x = a and g(x) is continuous at x = a, then h(x) is con-
tinuous at x = a.
Proof draft. Assume that f (x) is continuous at x = a and g(x) is continuous at
x = a. Then a âˆˆD and a âˆˆE; so a âˆˆD âˆ©E = Domain(h).
Scratch work:
We eventually will want |h(x) âˆ’h(a)| < ðœ€. So we want
|(f (x) + g(x) âˆ’(f (a) + g(a)| < ðœ€;
(19.39)
|(f (x) âˆ’f (a)) + (g(x) âˆ’g(a))| < ðœ€.
Now we can make both |f (x) âˆ’f (a)| and |g(x) âˆ’g(a)| as small as we want. But
what about the combination
|f (x) âˆ’f (a) + g(x) âˆ’g(a)|?
(19.40)
Luckily, we remember everything everyone has ever told us and can recall
things without notice. The triangle inequality says
|f (x) âˆ’f (a) + g(x) âˆ’g(a)| â‰¤|f (x) âˆ’f (a)| + |g(x) âˆ’g(a)|.
(19.41)
We should make |f (x) âˆ’f (a)| and |g(x) âˆ’g(a)| small enough that their sum is ðœ€.
We can return to our draft, but let us proceed to a polished proof.
Î”

19.2 Theorems About Continuity
379
Proof. Assume that f (x) is continuous at x = a and g(x) is continuous at x = a.
Then a âˆˆD and a âˆˆE; so a âˆˆD âˆ©E = Domain(h).
Assume ðœ€> 0. Then ðœ€
2 > 0.
Since f (x) is continuous at x = a, âˆƒð›¿f > 0 such that if x âˆˆD and |x âˆ’a| < ð›¿f ,
then |f (x) âˆ’f (a)| < ðœ€
2.
Since g(x) is continuous at x = a, âˆƒð›¿g > 0 such that if x âˆˆE and |x âˆ’a| < ð›¿g,
then |g(x) âˆ’g(a)| < ðœ€
2.
Let ð›¿h = Min({ð›¿f , ð›¿g}). Then ð›¿h > 0, ð›¿h â‰¤ð›¿f , and ð›¿h â‰¤ð›¿g.
Claim. If x âˆˆD âˆ©E and |x âˆ’a| < ð›¿h, then |h(x) âˆ’h(a)| < ðœ€.
Proof of claim. Assume x âˆˆD âˆ©E and |x âˆ’a| < ð›¿h.
Then x âˆˆD and |x âˆ’a| < ð›¿f ; so |f (x) âˆ’f (a)| < ðœ€
2.
In addition, x âˆˆE and |x âˆ’a| < ð›¿g; so |g(x) âˆ’g(a)| < ðœ€
2.
So
|f (x) âˆ’f (a)| + |g(x) âˆ’g(a)| < ðœ€
2 + ðœ€
2.
(19.42)
|f (x) âˆ’f (a)| + |g(x) âˆ’g(a)| < ðœ€.
But the triangle inequality says
|f (x) âˆ’f (a) + g(x) âˆ’g(a)| â‰¤|f (x) âˆ’f (a)| + |g(x) âˆ’g(a)|.
(19.43)
But
|f (x) âˆ’f (a)âˆ£+ âˆ£g(x) âˆ’g(a)| < ðœ€.
(19.44)
So
|(f (x) âˆ’f (a)) + (g(x) âˆ’g(a))| < ðœ€
(19.45)
and in turn |h(x) âˆ’h(a)| < ðœ€.
â—¾
This completes our proof that if f (x) is continuous at x = a and g(x) is con-
tinuous at x = a, then h(x) = f (x) + g(x) is continuous at x = a.
â—½
19.2.4
Multiplying continuous functions
The reason why we prove theorems is to avoid reproving the same things over
and over. We could try to prove that the product of two continuous functions
is continuous using the deï¬nition, but that ignores the fact that we have proved
the last few theorems. We can save ourselves time by ï¬nding a way to use those
results to save us some work.
Lemma 19.2.6.
Let f âˆ¶â„â†’â„have domain D and let g âˆ¶â„â†’â„have
domain E. Deï¬ne h âˆ¶â„â†’â„by h(x) = f (x)g(x). If f (x) is continuous at x = a

380
19 Continuous Functions
with f (a) = 0 and if g(x) is continuous at x = a with g(a) = 0, then h(x) is
continuous at x = a.
Proof draft. Assume that f (x) is continuous at x = a. Assume f (a) = 0. Assume
g(x) is continuous at x = a. Assume g(a) = 0. Assume ðœ€> 0. We ï¬rst observe
that h(x) has domain D âˆ©E, a âˆˆD âˆ©E, and so h(a) = f (a)g(a) = 0.
Comment: Now we need to ï¬gure out how to make the proof work. As usual, we
do some scratch work, working backward from what we want to ï¬gure out where
to start.
Scratch work:
We want |h(x) âˆ’h(a)| < ðœ€. Since h(a) = 0, we want |h(x)| < ðœ€. We want
|f (x)g(x)| < ðœ€;
(19.46)
|f (x)| â‹…|g(x)| < ðœ€.
Now we can make both |f (x)| = |f (x) âˆ’f (a)| and |g(x)| = |g(x) âˆ’g(a)| as small
as we want.2 But what about the combination |f (x)| â‹…|g(x)|? We should make
|f (x)| and |g(x)| small enough that their product is ðœ€. How about
âˆš
ðœ€? That is
not allowed yet. But we know what to do. Hiding any additional scratch work,
we move to the proof.
Î”
Proof. Assume that f (x) is continuous at x = a. Assume f (a) = 0. Assume g(x)
is continuous at x = a. Assume g(a) = 0. Assume ðœ€> 0.
Let ðœ€0 =Min({ðœ€, 1}). Then ðœ€0 > 0, ðœ€0 â‰¤ðœ€, and ðœ€0 â‰¤1. So ðœ€2
0 â‰¤ðœ€0 â‰¤ðœ€.
Since f (x) is continuous at x = a,
âˆƒð›¿f > 0 s.t. if x âˆˆD and |x âˆ’a| < ð›¿f , then |f (x)| < ðœ€0.
(19.47)
Since g(x) is continuous at x = a,
âˆƒð›¿g > 0 s.t. if x âˆˆD and |x âˆ’a| < ð›¿g, then |g(x))| < ðœ€0.
(19.48)
Let ð›¿h = Min({ð›¿f , ð›¿g}). Then ð›¿h > 0, ð›¿h â‰¤ð›¿f , and ð›¿h â‰¤ð›¿g.
Claim. If x âˆˆD âˆ©E and |x âˆ’a| < ð›¿h, then |h(x) âˆ’h(a)| < ðœ€.
Proof of claim. Assume x âˆˆD âˆ©E and |x âˆ’a| < ð›¿h.
Then x âˆˆD and |x âˆ’a| < ð›¿f ; so |f (x) âˆ’f (a)|< ðœ€0.
In addition, x âˆˆE and |x âˆ’a| < ð›¿g; so |g(x) âˆ’g(a)|< ðœ€0.
2 Admittedly, we all know that we can indeed use
âˆš
ðœ€, but in this book, we are trying hard to only
use what we have proved, and although we know that
âˆš
ðœ€exists, we have not proved it.

19.2 Theorems About Continuity
381
So
|f (x)| â‹…|g(x)| < ðœ€2
0;
(19.49)
|f (x)g(x)| < ðœ€2
0 â‰¤ðœ€;
|h(x) âˆ’h(a)| < ðœ€.
â—¾
This completes our proof that if f (x) is continuous at x = a with f (a) = 0, and
if g(x) is continuous at x = a with g(a) = 0, then h(x) = f (x)g(x) is continuous
at x = a.
â—½
Our assumptions that f (a) = g(a) = 0 made this rather painless. But we want
a much more general result. But with all these theorems, we can avoid using
the deï¬nition of continuous in the proof.
Theorem 19.2.7.
Let f âˆ¶â„â†’â„have domain D, and let g âˆ¶â„â†’â„have
domain E. Deï¬ne h âˆ¶â„â†’â„by h(x) = f (x)g(x).
If f (x) is continuous at x = a and g(x) is continuous at x = a, then h(x) is con-
tinuous at x = a.
Proof. Assume that f (x) is continuous at x = a. Then a âˆˆD. Assume g(x) is
continuous at x = a. Then a âˆˆE. Therefore a âˆˆD âˆ©E. Since h(x) has domain
D âˆ©E, we know that a âˆˆDomain(h).
Now let f1 âˆ¶â„â†’â„be given by f1(x) = f (x) âˆ’f (a). This function has
domain D and is the sum of two functions continuous at x = a: namely f (x)
and the constant function k(x) = âˆ’f (a). So f1(x) is continuous at x = a and
f1(a) = 0.
Similarly, let g1 âˆ¶â„â†’â„be given by g1(x) = g(x) âˆ’g(a). This function has
domain E and g1(x) is continuous at x = a and g1(a) = 0.
By Lemma 19.2.6, f1(x)g1(x) is continuous at x = a.
But consider f (x)g(x).
f (x)g(x) = (f1(x) + f (a)) â‹…(g1(x) + g(a))
(19.50)
= f1(x)g1(x) + f (a)g1(x) + g(a)f1(x) + f (a)g(a).
We know that f1(x)g1(x) is continuous at x = a. By Theorem 19.2.4, if we mul-
tiply continuous functions by constants, they remain continuous, so we know
that f (a)g1(x) and g(a)f1(x) are continuous at x = a. The ï¬nal part is just a con-
stant function; so the sum of all these is continuous at x = a. Thus, we con-
clude that if f (x) is continuous at x = a and g(x) is continuous at x = a, then
h(x) = f (x)g(x) is continuous at x = a.
â—½

382
19 Continuous Functions
19.2.5
Polynomial functions
Theorem 19.2.8.
Let p âˆ¶â„â†’â„be given by a polynomial. Then for all a âˆˆâ„,
p(x) is continuous at x = a.
Proof. Write
p(x) = cnxn + cnâˆ’1xnâˆ’1 + Â· Â· Â· + c1x + c0
with
ci âˆˆâ„
for
all
i = 0, 1, 2 â€¦ n.
Assume a âˆˆâ„.
Proof by induction on n = deg(p(x)).
Step 1, the base step. We claim that if n = 0, then p(x) is continuous at x = a.
Proof of claim. Assume n = 0. In this case, p(x) = c0 is a constant function. â—¾
Step 2, the induction step. Suppose that all polynomials of degree n = n0 are
continuous at x = a. We claim that this implies that all polynomials of degree
n = n0 + 1 are continuous at x = a.
Proof of claim. Assume that any polynomial function of degree n0 is continuous
at x = a.
Assume cn0+1 â‰ 0 and
p(x) = cn0+1xn0+1 + cn0xn0 + Â· Â· Â· + c1x + c0.
(19.51)
Notice that
p(x) = (cn0+1xn0 + cn0xn0âˆ’1 + â€¦ c1)x + c0.
(19.52)
But
cn0+1xn0 + cn0xn0âˆ’1 + â€¦ c1
(19.53)
is a polynomial of degree n0. So by our assumption, as a function it is continuous
at x = a. We know by Theorem 19.2.2 that the identity function is continuous at
x = a, and by Theorem 19.2.1, the constant function is also continuous at x = a.
Since p(x) is the product and sum of functions continuous at x = a, it follows
that p(x) is continuous at x = a.
â—¾
So, it follows by induction that if p âˆ¶â„â†’â„is given by a polynomial, then
for all a âˆˆâ„, p(x) is continuous at x = a.
â—½
19.2.6
Composition of continuous functions
Theorem 19.2.9.
Let f âˆ¶â„â†’â„have domain D and let g âˆ¶â„â†’â„have
domain E. Deï¬ne h âˆ¶â„â†’â„by h = g âˆ˜f . If f (x) is continuous at x = a and g(x)
is continuous at x = f (a), then h(x) is continuous at x = a.

19.2 Theorems About Continuity
383
a
f (a)
f (x)
g( f (a))
g(x)
Target Neighborhood
Figure 19.5 Composition of continuous functions.
Here a good generic picture can save us some scratch work (Figure 19.5).
We will be given an ðœ€target about g(f (a)). We can hit it using the continuity
of g and choosing an aiming radius about f (a). We can hit this aiming radius
about f (a) with f by using the continuity of f and choosing an aiming radius
about f (a). That should work for the composition.
There is one issue though; we cannot be sure what the domain of h(x) is. The
statement of the theorem says nothing about f (D) âˆ©E. The requirement that
g(x) is continuous at f (a) does at least imply that f (a) âˆˆf (D) âˆ©E. However, our
deï¬nitions of a function and of the image of a set combined with the topolog-
ical deï¬nition of continuity allow us to formalize the proof outline easily. By
using its global aspect, this is the ï¬rst place where we can put our topological
deï¬nition of continuity to use:
âˆ€ðœ€> 0, âˆƒð›¿> 0 s.t. f (N(a, ð›¿)) âŠ†N(f (a), ðœ€).
(19.54)
Proof. Assume that f (x) is continuous at x = a.
Assume that g(x) is continuous at x = f (a).
Assume ðœ€> 0. Consider h(a). Now h(a) = g(f (a)). For convenience, let b =
f (a). Thus, h(a) = g(b) and g(x) is continuous at x = f (a) = b.
Since g(x) is continuous at x = b and ðœ€> 0, âˆƒð›¿g > 0 such that g(N(b, ð›¿g)) âŠ†
N(g(b), ðœ€).
Now f (a) = b; f (x) is continuous at x = a and ð›¿g > 0.
Comment: It really does not matter what it is called, as long as a number is
positive, it can be used in the deï¬nition of continuity.
So
âˆƒð›¿f > 0 s.t. f (N(a, ð›¿f )) âŠ†N(f (a), ð›¿g).
(19.55)
But N(f (a), ð›¿g) = N(b, ð›¿g).
Claim. (g âˆ˜f )(N(a, ð›¿f )) âŠ†N((g âˆ˜f )(a), ðœ€).

384
19 Continuous Functions
Proof of claim. We proved a while ago that we can apply images to both sides
of a subset relation. So f (N(a, ð›¿f )) âŠ†N(b, ð›¿g) gives us
g(f (N(a, ð›¿f ))) âŠ†g(N(b, ð›¿g)).
(19.56)
From earlier,
g(f (N(a, ð›¿f ))) âŠ†g(N(b, ð›¿g)) âŠ†N(g(b), ðœ€).
(19.57)
But we also proved that
g(f (N(a, ð›¿f ))) = (g âˆ˜f )(N(a, ð›¿f )).
(19.58)
So
(g âˆ˜f )(N(a, ð›¿f )) âŠ†N(g(f (a)), ðœ€).
(19.59)
Finally, this gives
(g âˆ˜f )(N(a, ð›¿f )) âŠ†N((g âˆ˜f )(a), ðœ€).
(19.60)
â—¾
Comment: Recalling theorems from set theory saved us from a longer direct proof
of this subset relation.
Thus, we have proved that if f (x) is continuous at x = a and g(x) is continuous
at x = f (a), then h(x) is continuous at x = a.
â—½
19.2.7
Dividing continuous functions
Theorem 19.2.10.
Let f âˆ¶â„â†’â„have domain D and let g âˆ¶â„â†’â„have
domain E. Deï¬ne h âˆ¶â„â†’â„by h(x) = f (x)
g(x).
If f (x) is continuous at x = a and, if g(x) is continuous at x = a with g(a) â‰ 0,
then h(x) is continuous at x = a.
Proof. Comment: The important thing in this theorem is the assumption
g(a) â‰ 0.
Let k âˆ¶â„â†’â„be given by k(x) = 1
x. We have proved that this is continuous
at all x = a â‰ 0.
So k(x) is continuous at x = g(a). By Theorem 19.2.9, (k âˆ˜g)(x) is continuous
at x = a. But
(k âˆ˜g)(x) = k(g(x))
(19.61)
=
1
g(x).
By Theorem 19.2.7, f (x) â‹…(k âˆ˜g)(x) is continuous at x = a. But
f (x) â‹…(k âˆ˜g)(x) = f (x)
g(x).
(19.62)
â—½

19.2 Theorems About Continuity
385
Again using the theorems we have already proved, we have avoided a lot of
fussy approximating and limiting that a ð›¿-ðœ€-proof would require. It is possible
to use the deï¬nition, but not a lot of fun unless you like that sort of thing.
Corollary 19.2.11.
Let r âˆ¶â„â†’â„be given by a rational expression; that
is a polynomial divided by a polynomial. Then for all a âˆˆDomain(r), r(x) is
continuous at x = a.
Proof. Let
r(x) = p(x)
q(x)
(19.63)
where p(x) and q(x) are polynomials. All we need do is to note that
Domain(r) = {x âˆˆâ„âˆ£q(x) â‰ 0}.
(19.64)
â—½
19.2.8
Gluing functions together
Theorem 19.2.12
(The Gluing Theorem).
Let f âˆ¶(âˆ’âˆž, a] â†’â„have
domain D and let g âˆ¶[a, âˆž) â†’â„have domain E. Suppose that f (a) = g(a). Let
h âˆ¶â„â†’â„be given by
h(x) =
âŽ§
âŽª
âŽ¨
âŽªâŽ©
f (x)
if x < a
f (a)
if x = a
g(x)
if x > a
.
(19.65)
If f (x) is continuous on D with a âˆˆD, and if g(x) is continuous on E is contin-
uous with a âˆˆE. Then h(x) is continuous on D âˆªE.
Proof. Assume that f (x) is continuous on D âŠ†(âˆ’âˆž, a]. Assume a âˆˆD.
Assume that g(x) is continuous on E âŠ†[a, âˆž). Assume a âˆˆE.
Assume f (a) = g(a).
Notice that h(x) has domain D âˆªE.
To prove that h(x) is continuous on D âˆªE, assume b âˆˆD âˆªE, and assume
ðœ€> 0.
There are three cases to consider: b = a; b âˆˆDâˆ–{a} or b âˆˆEâˆ–{a}.
Case 1: Assume b = a.
Then âˆƒð›¿f > 0 such that if x âˆˆD and |x âˆ’a| < ð›¿f , then |f (x) âˆ’f (a)| < ðœ€.
In addition, âˆƒð›¿g > 0 such that if x âˆˆE and |x âˆ’a| < ð›¿g, then |g(x) âˆ’g(a)| < ðœ€.
Let ð›¿h = Min({ð›¿f , ð›¿g}). Then ð›¿h > 0, ð›¿h â‰¤ð›¿f , and ð›¿h â‰¤ð›¿g.
Claim. If x âˆˆD âˆªE and |x âˆ’a| < ð›¿h, then |h(x) âˆ’h(a)| < ðœ€.

386
19 Continuous Functions
Proof of claim. Assume x âˆˆD âˆªE and |x âˆ’a| < ð›¿h. There are two possibilities,
x âˆˆD or x âˆˆE.
Subcase 1: Assume x âˆˆD âŠ†(âˆ’âˆž, a]. So h(x) = f (x). We still have |x âˆ’a| <
ð›¿h â‰¤ð›¿f . So |f (x) âˆ’f (a)| < ðœ€. This means |h(x) âˆ’h(a)| < ðœ€.
Subcase 2: Assume x âˆˆE âŠ†[a, âˆž). So h(x) = g(x). We still have |x âˆ’a| <
ð›¿h â‰¤ð›¿g. So |g(x) âˆ’g(a)| < ðœ€. This means |h(x) âˆ’h(a)| < ðœ€.
â—¾
Case 2: Assume b âˆˆDâˆ–{a}. Then f (x) is continuous at x = b. Let ð›¿1 = a âˆ’b.
Since Dâˆ–{a} âŠ†(âˆ’âˆž, a), ð›¿1 > 0. So N(b, ð›¿1) âˆ©(D âˆªE) âŠ†N(b, ð›¿1) âˆ©D.
Then âˆƒð›¿f > 0 such that if f (N(b, ð›¿f )) âŠ†N(a, ðœ€).
Let ð›¿= Min({ð›¿1, ð›¿f }). Since ð›¿< ð›¿1 = a âˆ’b, h(x) and f (x) agree on N(b, ð›¿). So
h(N(b, ð›¿)) âŠ†f (N(b, ð›¿))
(19.66)
âŠ†f (N(b, ð›¿f ))
âŠ†N(a, ðœ€).
Thus, h(x)is continuous at all b âˆˆDâˆ–{a}.
Case 3: Similar to case 2.
â—½
19.3
Problems
19.1
Write a polished proof of: Let f âˆ¶â„â†’â„have domain D. For c âˆˆâ„,
let g âˆ¶â„â†’â„be given by g(x) = cx. If f (x) is continuous at x = a, then
g(x) is continuous at x = a.
19.2
Use the deï¬nition to prove f âˆ¶â„â†’â„given by f (x) = x2 + 3x âˆ’11 is
continuous at x = âˆ’4.
19.3
Use the deï¬nition to prove f âˆ¶â„â†’â„given by f (x) = x2 âˆ’x âˆ’8 is
continuous at x = 1.
19.4
Use the deï¬nition to prove f âˆ¶â„â†’â„given by f (x) =
1
4x+3 is
continuous at x = 1.
19.5
Use the deï¬nition to prove f âˆ¶â„â†’â„given by f (x) =
1
4x+3 is
continuous at x = âˆ’1.
19.6
Use the deï¬nition to prove f âˆ¶â„â†’â„given by f (x) = x2 âˆ’6x âˆ’8 is
continuous at x = 3.
19.7
Use the deï¬nition to prove f âˆ¶â„â†’â„given by f (x) = x2 is continuous
at x = 1
3.

19.3 Problems
387
19.8
Use the deï¬nition to prove f âˆ¶â„â†’â„given by f (x) = x3 âˆ’2x + 3 is
continuous at x = 5.
19.9
Use the deï¬nition to prove f âˆ¶â„â†’â„given by f (x) = x3 âˆ’12x âˆ’4 is
continuous at x = âˆ’2.
19.10
Use the deï¬nition to prove f âˆ¶â„â†’â„given by f (x) = x3 is continuous
at x = 0.
19.11
Let f âˆ¶â„â†’â„have domain D. Deï¬ne g âˆ¶â„â†’â„be given by g(x) =
(f (x))2. Thus, g(x) also has domain D.
Prove: If f (x) is continuous at x = a, then g(x) is continuous at x = a.
19.12
Let f âˆ¶â„â†’â„have domain D and let g âˆ¶â„â†’â„have domain E.
Deï¬ne h âˆ¶â„â†’â„by h = g âˆ˜f .
Prove: If f (x) is continuous at x = a and g(x) is continuous at x = f (a),
then h(x) is continuous at x = a.
19.13
Use the deï¬nition to prove f âˆ¶â„â†’â„given by
f (x) =
âŽ§
âŽª
âŽ¨
âŽªâŽ©
âˆ’x2
if x < 0
0
if x = 0
x2
if x > 0
(19.67)
is continuous at x = 0.
19.14
Use the deï¬nition to prove that for all n âˆˆâ„•, f âˆ¶â„â†’â„given by f (x) =
xn is continuous at x = 0.
19.15
Use the induction to prove that for all n âˆˆâ„•, f âˆ¶â„â†’â„given by f (x) =
xn is continuous at x = 0.
19.16
Assume that the function f âˆ¶â„â†’â„given by f (x) = ex is continuous
on â„. Use the theorems in this chapter to prove that the function g âˆ¶
â„â†’â„given by g(x) = 3e2x + 4ex âˆ’2 is continuous on â„.
19.17
Prove that f âˆ¶â„â†’â„given by f (x) = 1
x is continuous at all x = a with
a < 0. (Hint: To avoid confusion over negative and positive numbers,
let a = âˆ’b and prove it for all b > 0.)
19.18
Prove the theorem on multiplication using just the deï¬nition. Let
f âˆ¶â„â†’â„have domain D and let g âˆ¶â„â†’â„have domain E. Deï¬ne

388
19 Continuous Functions
h âˆ¶â„â†’â„be given by h(x) = f (x)g(x). Thus, h(x) has domain D âˆ©E.
If f (x) is continuous at x = a and g(x) is continuous at x = a, then h(x)
is continuous at x = a. Hint:
f (x)g(x) âˆ’f (x)g(x) = f (x)g(x) âˆ’f (a)g(x) + f (a)g(x) âˆ’f (x)g(x)).
(19.68)

389
20
Continuity and Topology
20.1
Preliminaries
Our deï¬nition of continuous tells us what it means for a function f (x) to be
continuous at a single point a. But if our deï¬nition of continuous is to have
anything to do with the normal notion of continuous, we need to start talking
about a function being continuous on sets, preferably intervals. In mathemati-
cal parlance, we want our local deï¬nition to have global implications. The ï¬rst
step is rather obvious.
Deï¬nition 20.1.1.
Let f âˆ¶â„â†’â„. We say that f (x) is continuous on a subset
S âŠ†â„if for all a âˆˆS, f (x) is continuous at x = a.
Thus, our previous results say:
â€¢ Constant functions are continuous on â„.
â€¢ The identity function f âˆ¶â„â†’â„is continuous on â„.
â€¢ Every polynomial function p âˆ¶â„â†’â„is continuous on â„.
â€¢ And every rational function r âˆ¶â„â†’â„is continuous on its domain.
In addition, it almost goes without saying that, if f âˆ¶â„â†’â„is continuous on
D and E âŠ†D, then f (x) is continuous on E.
20.1.1
Continuous images mess up topology
Let S âŠ†â„. There are three topological properties that S may have: S may be
open; S may be closed; S may be bounded. Consider the following examples.
Example 20.1.2.
Let f âˆ¶â„â†’â„given by f (x) = x3 âˆ’x.
Then f (x) is continuous on â„. Now S = (âˆ’1, 1) âŠ†â„is open. However,
f (S) =
[
âˆ’
2
3
âˆš
3
,
2
3
âˆš
3
]
(20.1)
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

390
20 Continuity and Topology
âˆ’1
1
âˆ’1
1
Figure 20.1 f(x) = x3 âˆ’x.
which is deï¬nitely not open (Figure 20.1). This weird interval might be very
startling if you did not know some calculus and know that the end points of this
image are values of the function at the roots of the derivative f â€²(x) = 3x2 âˆ’1.
Example 20.1.3.
Let f âˆ¶â„â†’â„given by f (x) = 1
x.
Then f (x) is continuous on (Figure 20.2) â„âˆ–{0}. Now S = [1, âˆž) âŠ†â„âˆ–{0}
is closed. However,
f (S) = (0, 1]
(20.2)
which is not closed.
Example 20.1.4.
Let f âˆ¶â„â†’â„given by f (x) = 1
x. Then f (x) is continuous
on â„âˆ–{0}. Now S = (0, 1) âŠ†â„âˆ–{0} is bounded. However,
f (S) = (1, âˆž)
(20.3)
which is not bounded.
âˆ’4
âˆ’2
2
4
âˆ’2
âˆ’1
1
2
x
y
Figure 20.2 f(x) = 1
x .

20.2 The Topological Deï¬nitions of Continuity
391
There are circumstances where these properties of sets are preserved by their
images under continuous functions, but in general, we cannot count on it. Any
theorem that allows us to say something about images is worth remembering.
20.2
The topological deï¬nitions of continuity
As we just saw, images of sets under continuous functions are not very well
behaved. As it turns out, preimages work extraordinarily well. The important
thing, however, is that the functions have a good domain: open or closed.
Theorem 20.2.1
(The Topological Deï¬nition of Continuous: Open
Version).
Let f âˆ¶â„â†’â„be a function with domain D. Let D be open. Then
f (x) is continuous on D if and only if âˆ€îˆ»âŠ†â„with îˆ»open, f âˆ’1(îˆ») is open.
Proof draft. Assume that D is open.
Comment: This is important, and we will watch for a place to use it.
This is a biconditional statement, so there are two directions to prove. We
will take each part in turn.
Part 1. First, we claim that if f (x) is continuous on D, then âˆ€îˆ»âŠ†â„with îˆ»open,
f âˆ’1(îˆ») is open.
Proof of claim. Assume that f (x) is continuous on D. Then âˆ€a âˆˆD, f (x) is con-
tinuous at x = a.
Assume îˆ»âŠ†â„with îˆ»open.
Comment: What are we proving now? We are proving that â€œf âˆ’1(O) is open.â€ That
is, â€œâˆ€a âˆˆf âˆ’1(O), âˆƒðœ€> 0 such that N(a, ðœ€) âŠ†f âˆ’1(O).â€
Assume a âˆˆf âˆ’1(îˆ»). Then f (a) âˆˆîˆ».
Comment: Normally, choosing the letter â€œOâ€ in any font is a bad idea, but when
a set is open, it really helps us get to the next step when we ï¬nd an element in it.
So âˆƒðœ€a > 0 such that N(f (a), ðœ€a) âŠ†îˆ».
Comment: What are we proving now? â€œThere exists some new neighborhood of a
such that . . . .â€ That means we have to ï¬nd one. What assumption have we not
used yet? We have not used the fact that âˆ€a âˆˆD, f (x) is continuous at x = a.
Great! We just found a neighborhood of f (a).

392
20 Continuity and Topology
Since f (x) is continuous at x = a and ðœ€a > 0, âˆƒð›¿a > 0 such that f (N(a, ð›¿a)) âŠ†
N(f (a), ðœ€a).
Comment: We are working on theoretical functions; so the topological version of
continuous seems like the better choice. And it is, as we will now see.
We have N(f (a), ðœ€a) âŠ†îˆ». So f (N(a, ð›¿a)) âŠ†N(f (a), ðœ€a) âŠ†îˆ».
Comment: We would ï¬nish the proof if we could prove that N(a, ð›¿a) âŠ†f âˆ’1(îˆ»),
where the ðœ€we set out to ï¬nd ends up begin ð›¿a. However, if we tried to prove this,
we would run into trouble.
We would start by assuming that we have some x âˆˆN(a, ð›¿a). Then by our ear-
lier work, f (x) âˆˆf (N(a, ð›¿a)), right?
Not quite. We chose ð›¿a > 0 so that f (N(a, ð›¿a)) âŠ†N(f (a), ðœ€a). But this actually
only tells that if x âˆˆN(a, ð›¿a) and f (x) is deï¬ned, then f (x) âˆˆN(f (a), ðœ€a). But it
may be that x âˆˆN(a, ð›¿a) but x âˆ‰Domain(f ). In that case, we could not conclude
that x âˆˆf âˆ’1(îˆ»).
We need to ï¬nd a subset of N(a, ð›¿a) that is also a subset of D = Domain(f ).
So, what are we missing? What have not we used yet? We have not used the
fact that the domain D is open. Time to back up and use it when we can.
Now a âˆˆf âˆ’1(îˆ») âŠ†D. So a âˆˆD and a âˆˆN(a, ð›¿a); thus a âˆˆD âˆ©N(a, ð›¿a). Since
both parts are open sets, we know that D âˆ©N(a, ð›¿a) is an open set. So âˆƒð›¿â€²
a > 0
so that N(a, ð›¿â€²
a) âŠ†D âˆ©N(a, ð›¿a).
Comment: We have now found our subset of N(a, ð›¿a) that is also a subset of
D = Domain(f ). Everything in N(a, ð›¿â€²
a) should be in f âˆ’1(îˆ»).
We now claim that N(a, ð›¿â€²
a) âŠ†f âˆ’1(îˆ»).
Assume x âˆˆN(a, ð›¿â€²
a). Then x âˆˆN(a, ð›¿â€²
a) âŠ†D âˆ©N(a, ð›¿a). So x âˆˆD and
x âˆˆN(a, ð›¿a). Since x âˆˆD, f (x) exists and f (x) âˆˆf (N(a, ð›¿a)). Thus, f (x) âˆˆ
f (N(a, ð›¿a)) âŠ†N(f (a), ðœ€a) âŠ†îˆ». And then x âˆˆf âˆ’1(îˆ»).
â—¾
Part 2. Now we claim that if âˆ€îˆ»âŠ†â„with îˆ»open, f âˆ’1(îˆ») is open, then f (x) is
continuous on D.
Proof of claim. Assume that if îˆ»âŠ†â„is open, then f âˆ’1(S) is open.
Comment: What are we proving now? f (x) is continuous on D. That is, âˆ€a âˆˆD,
f (x) is continuous at x = a. That is, âˆ€a âˆˆD, âˆ€ðœ€> 0, there exists a good ð›¿. That
gives us a start.
Assume a âˆˆD. Assume ðœ€> 0.
Consider N(f (a), ðœ€). This is an open set and f (a) âˆˆN(f (a), ðœ€).

20.2 The Topological Deï¬nitions of Continuity
393
By assumption, f âˆ’1(N(f (a), ðœ€)) is open, and we also know that
a âˆˆf âˆ’1(N(f (a), ðœ€)).
So âˆƒð›¿a > 0 so that
N(a, ð›¿a) âŠ†f âˆ’1(N(f (a), ðœ€)).
(20.4)
We now claim that f (N(a, ð›¿a)) âŠ†N(f (a), ðœ€).
Assume y âˆˆf (N(a, ð›¿a)). Then âˆƒx âˆˆN(a, ð›¿a) such that f (x) = y. But
x âˆˆN(a, ð›¿a) âŠ†f âˆ’1(N(f (a), ðœ€)).
Since x âˆˆf âˆ’1(N(f (a), ðœ€)), we have f (x) âˆˆN(f (a), ðœ€). But then y = f (x) âˆˆ
N(f (a), ðœ€).
Thus, we have f (N(a, ð›¿a)) âŠ†N(f (a), ðœ€).
This proves that f (x) is continuous.
â—¾
Now that we have found a proof of both directions of the biconditional, our
proof is complete.
Î”
This ï¬rst part of this deï¬nitely needs to be rewritten; so we should clean up
both parts as we go. Notice that we needed to use the fact that D is open. We
need to remember that every time we apply f (x) to something, we must be sure
that something is in the domain!
Proof. Assume that Domain(f ) = D is open.
Part 1. First, we claim that if f (x) is continuous on D, then âˆ€îˆ»âŠ†â„with îˆ»open,
f âˆ’1(îˆ») is open.
Proof of claim. Assume that f (x) is continuous on D. Then âˆ€a âˆˆD, f (x) is con-
tinuous at x = a.
Assume îˆ»âŠ†â„with îˆ»open.
Assume a âˆˆf âˆ’1(îˆ») âŠ†D. Then f (a) âˆˆîˆ».
So âˆƒðœ€a > 0 such that N( f (a), ðœ€a) âŠ†îˆ».
Since f (x) is continuous at x = a and ðœ€a > 0, âˆƒð›¿a > 0 such that f (N(a, ð›¿a)) âŠ†
N(f (a), ðœ€a).
We have N( f (a), ðœ€a) âŠ†îˆ». So f (N(a, ð›¿a)) âŠ†N(f (a), ðœ€a) âŠ†îˆ».
Now a âˆˆf âˆ’1(îˆ») âŠ†D. So a âˆˆD âˆ©N(a, ð›¿a). This is an open set. So âˆƒð›¿â€²
a > 0 so
that N(a, ð›¿â€²
a) âŠ†D âˆ©N(a, ð›¿a).
We now claim that N(a, ð›¿â€²
a) âŠ†f âˆ’1(O).
To prove this, assume x âˆˆN(a, ð›¿â€²
a). Then x âˆˆN(a, ð›¿â€²
a) âŠ†D âˆ©N(a, ð›¿a). So x âˆˆ
D and x âˆˆN(a, ð›¿a). Since x âˆˆD, f (x) exists and f (x) âˆˆf (N(a, ð›¿a)). Thus,
f (x) âˆˆf (N(a, ð›¿a)) âŠ†N(f (a), ðœ€a) âŠ†îˆ».
(20.5)

394
20 Continuity and Topology
And therefore, x âˆˆf âˆ’1(îˆ»). This proves that N(a, ð›¿â€²
a) âŠ†f âˆ’1(O) and ï¬nishes the
proof of this part of the theorem.
â—¾
Part 2. Now we claim that if âˆ€îˆ»âŠ†â„with îˆ»open, f âˆ’1(îˆ») is open, then f (x) is
continuous on D.
Proof of claim. Assume âˆ€îˆ»âŠ†â„with îˆ»open, f âˆ’1(îˆ») is open.
Assume a âˆˆD. Assume ðœ€> 0.
Consider N(f (a), ðœ€). This is an open set and f (a) âˆˆN(f (a), ðœ€).
By assumption, f âˆ’1(N(f (a), ðœ€)) is open, and a âˆˆf âˆ’1(N(f (a), ðœ€)).
So âˆƒð›¿a > 0 so that
N(a, ð›¿a) âŠ†f âˆ’1(N(f (a), ðœ€)).
(20.6)
We now claim that f (N(a, ð›¿a)) âŠ†N(f (a), ðœ€).
To prove this, assume y âˆˆf (N(a, ð›¿a)). Then âˆƒx âˆˆN(a, ð›¿a) such that
f (x) = y. But x âˆˆN(a, ð›¿a) âŠ†f âˆ’1(N(f (a), ðœ€)). Since x âˆˆf âˆ’1(N(f (a), ðœ€)), we have
y = f (x) âˆˆN(f (a), ðœ€). This proves that f (N(a, ð›¿a)) âŠ†N(f (a), ðœ€).
Thus, f (x) is continuous, and we are now ï¬nished with this direction of the
proof.
â—¾
Now that we have found a proof of both directions of the biconditional, our
proof is complete.
â—½
Theorem 20.2.2
(The Topological Deï¬nition of Continuous: Closed
Version). Let f âˆ¶â„â†’â„be a function with domain D. Let D be closed. Then
f (x) is continuous on D if and only if âˆ€îˆ¯âŠ†â„with îˆ¯closed, f âˆ’1(îˆ¯) is closed.
As we just saw, the deï¬nition of continuity works pretty well with open sets.
That means that it can work with closed sets by considering complements in
â„. Unfortunately, all the negations make this next proof something similar to
untying a knot in your shoelaces while looking at it through a mirror. We will
simply write out the ï¬nal proof.
Proof. Assume that Domain( f ) = D closed.
Part 1. We claim that if f (x) is continuous on D, then âˆ€îˆ¯âŠ†â„with îˆ¯closed,
f âˆ’1(îˆ¯) is closed.
Proof of claim. Assume that f (x) is continuous on D. Then âˆ€a âˆˆD, f (x) is con-
tinuous at x = a.
Assume îˆ¯âŠ†â„with îˆ¯closed.
We will prove that f âˆ’1(îˆ¯) is closed by proving (f âˆ’1(îˆ¯))â€² âŠ†f âˆ’1(îˆ¯). But we will
do so by contradiction.

20.2 The Topological Deï¬nitions of Continuity
395
Assume a âˆˆ(f âˆ’1(îˆ¯))â€².
Assume a âˆ‰f âˆ’1(îˆ¯).
Comment: Before we consider f (a), we need to be sure that it exists.
By the deï¬nition of preimage, f âˆ’1(îˆ¯) âŠ†D. So (f âˆ’1(îˆ¯))â€² âŠ†Dâ€².
Comment: Now we see why we are working with accumulation points and not
boundary points: accumulation points respect subsets.
Since D is closed,
a âˆˆ(f âˆ’1(îˆ¯))â€² âŠ†Dâ€² âŠ†D.
(20.7)
Therefore, f (a) exists.
Because a âˆ‰f âˆ’1(îˆ¯), f (a) âˆ‰îˆ¯. Then f (a) âˆˆâ„âˆ–îˆ¯, which is an open set. So
âˆƒðœ€1 > 0 such that N(f (a), ðœ€1) âŠ†â„âˆ–îˆ¯.
But f (x) is continuous on D, and we have proved that a âˆˆD. So using this
ðœ€1 > 0, we have that âˆƒð›¿1 > 0 such that
f (N(a, ð›¿1)) âŠ†N(f (a), ðœ€1) âŠ†â„âˆ–îˆ¯.
(20.8)
However, we started out with the assumption that a âˆˆ(f âˆ’1(îˆ¯))â€². So by deï¬ni-
tion, âˆ€ðœ€> 0, Nâˆ—(a, ðœ€) âˆ©f âˆ’1(îˆ¯) â‰ âˆ…. Since ð›¿1 > 0, we can use it for the variable
ðœ€, and say
Nâˆ—(a, ð›¿1) âˆ©f âˆ’1(îˆ¯) â‰ âˆ….
(20.9)
We can let x âˆˆNâˆ—(a, ð›¿1) âˆ©f âˆ’1(îˆ¯). Then x âˆˆNâˆ—(a, ð›¿1) and x âˆˆf âˆ’1(îˆ¯). But x âˆˆ
f âˆ’1(îˆ¯) tells us that f (x) âˆˆîˆ¯.
But we also have x âˆˆNâˆ—(a, ð›¿1) âŠ†N(a, ð›¿1). So f (x) âˆˆf (N(a, ð›¿)). This means
f (x) âˆˆf (N(a, ð›¿)) âŠ†N(f (a), ðœ€) âŠ†â„âˆ–îˆ¯.
(20.10)
Since we just found that f (x) âˆˆîˆ¯and that f (x) âˆˆâ„âˆ–îˆ¯, this is the contradiction
we were looking for.
â—¾
Part 2. We now claim that âˆ€îˆ¯âŠ†â„with îˆ¯closed, f âˆ’1(îˆ¯) is closed, then f (x) is
continuous on D.
Proof of claim. Assume âˆ€îˆ¯âŠ†â„with îˆ¯closed, f âˆ’1(îˆ¯) is closed.
Comment: We now want to prove that âˆ€a âˆˆD, f (x) is continuous at x = a.
Assume a âˆˆD.
Comment: So now we want to prove: âˆ€ðœ€> 0, âˆƒð›¿> 0 such that f (N(a, ð›¿)) âŠ†
N(f (a), ðœ€).
Assume ðœ€> 0.

396
20 Continuity and Topology
Consider N(f (a), ðœ€). This is an open set. Let îˆ¯= â„âˆ–N(f (a), ðœ€). Then îˆ¯is a
closed set. So by our assumption about f , f âˆ’1(îˆ¯) is closed.
Comment: Now we need to prove that âˆƒð›¿> 0 such that f (N(a, ð›¿)) âŠ†N(f (a), ðœ€).
We need to ï¬nd a small neighborhood, so we need to solve a problem about its
ð›¿. We just discovered a closed set f âˆ’1(îˆ¯), not an open one. We might guess that
need something is not in that set. The number f (a) ï¬ts the bill, and the neigh-
borhood N(f (a), ðœ€) is deï¬nitely open. Let us see if considering f (a) can ï¬nd us a
small neighborhood of a.
Now f (a) âˆˆN(f (a), ðœ€). So f (a) âˆ‰â„âˆ–N(f (a), ðœ€) = îˆ¯. So a âˆ‰f âˆ’1(îˆ¯). That is,
a âˆˆâ„âˆ–(f âˆ’1(îˆ¯)).
Since f âˆ’1(îˆ¯) is closed, â„âˆ–f âˆ’1(îˆ¯) is open. So we have
âˆƒð›¿>0 s.t. N(a, ð›¿) âŠ†â„âˆ–f âˆ’1(îˆ¯).
(20.11)
That is to say, N(a, ð›¿) âˆ©f âˆ’1(îˆ¯) = âˆ….
We now claim that f (N(a, ð›¿)) âŠ†N(f (a), ðœ€).
To prove this, assume y âˆˆf (N(a, ð›¿)). Then âˆƒx âˆˆN(a, ð›¿) such that f (x) = y.
But
x âˆˆN(a, ð›¿) âŠ†â„âˆ–f âˆ’1(îˆ¯).
(20.12)
So x âˆ‰f âˆ’1(îˆ¯). So y = f (x) âˆ‰îˆ¯= â„âˆ–N(f (a), ðœ€). Thus, y âˆˆN(f (a), ðœ€). There-
fore, we have proved our claim that f (N(a, ð›¿)) âŠ†N(f (a), ðœ€).
That is, we have proved that âˆ€ðœ€> 0, âˆƒð›¿> 0 such that f (N(a, ð›¿)) âŠ†N(f (a), ðœ€).
So f (x) is continuous at x = a.
â—¾
We have now proved both directions of the theorem, so our proof is
complete.
â—½
We can prove one quick corollary from the open version that at ï¬rst glance
has nothing to do with the theorem.
Corollary 20.2.3.
Let r âˆ¶â„â†’â„be given by a rational expression. Then r(x)
is continuous on Domain(r), which is an open set.
Proof. Assume r âˆ¶â„â†’â„be given by a rational expression. Write
r(x) = p(x)
q(x).
(20.13)
where p(x) and q(x) are polynomials. We already proved that r(x) is continuous
on
Domain(r) = {x âˆˆâ„âˆ£q(x) â‰ 0}.
(20.14)

20.3 Compact Images
397
But q âˆ¶â„â†’â„is given by a polynomial, so q(x) is continuous on â„, which is
an open set. Since â„âˆ–{0} âŠ†â„is open, the theorem tells us that
qâˆ’1(â„âˆ–{0}) = {x âˆˆâ„âˆ£q(x) â‰ 0}
(20.15)
is open. But this is Domain(r).
â—½
20.3
Compact images
20.3.1
The main theorem
When we started out, we noted that the image f (S) of a set S under continuous
functions f (x) tended to mess up any topological properties of the S. We gave
examples where this happened to three topological properties that S may have:
open, closed, and bounded.
We showed that if S is a closed set, f (S) may not be closed, and if S is a
bounded set, f (S) may not be bounded. So, you might guess that if S is both
closed and bounded, f (S) may not be closed and bounded. That would be a mis-
take! Somehow the properties closed and bounded together are much stronger
than either alone. We have the following theorem.
Theorem 20.3.1.
Let f âˆ¶â„â†’â„be a function with domain D. Suppose that
D is open, and suppose that f (x) is continuous on D. If S âŠ†D and S is closed and
bounded, then f (S) is closed and bounded.
Of course, we are being obtuse and not in a triangular way. We are not sup-
posed to say that a set is closed and bounded anymore; we are supposed to
say that the set is compact. That should remind us that we do have a (admit-
tedly scary, when you ï¬rst see it) trick to use on such sets. All we have to do is
maintain our logical discipline and see if the trick helps. We must be sure not
to assume that we have something until the logic of the proof permits it. Our
theorem is best stated as follows.
Theorem 20.3.2.
Let f âˆ¶â„â†’â„be a function with domain D. Suppose that
D is open, and suppose that f (x) is continuous on D. If S âŠ†D and S is compact,
then f (S) is compact.
We have now hidden the entire long proof of the Heineâ€“Borel theorem into
the logic of the proof of this theorem.
Proof draft. Assume f âˆ¶â„â†’â„is a function with domain D. Assume that f (x)
is continuous on D. Assume that D is open. Assume S âŠ†D. Assume that S is
compact (Figure 20.3).

398
20 Continuity and Topology
S
Compact Set
f (S)
Image
f
Figure 20.3 f maps S to f(S).
Comment: This means that, if we ever have an open cover of S, then it will have
a ï¬nite subcover. It does not give us such a cover! We will not write this down yet,
but we know that we should be looking for an open cover of S. One thing is for
sure: we cannot assume that S has an open cover.
Comment: What are we proving now? â€œf (S) is compact.â€ That is, â€œif Oi gives an
open cover of f (S), that cover will have a ï¬nite subcover.â€ That at least gives us a
place to start. We can assume that we have an open cover of f (S).
Assume that îˆ»i with i âˆˆîˆµis a family of open sets.
Assume (Figure 20.4) f (S) âŠ†â‹ƒ
iâˆˆîˆµ
îˆ»i.
Comment: So these open sets are in the codomain side of the function.
We have the set f (S) covered in the codomain, but we would prefer to have S
covered in the domain. We need to build on what we have to create what we need.
What assumptions have we not used yet? Well, f (x) is continuous on D, and D
is open. This allows us to use the topological deï¬nition of continuity.
S
Compact Set
f (S)
Image
f
Figure 20.4 The sets îˆ»i for i âˆˆîˆµcover f(S).

20.3 Compact Images
399
S
Compact Set
f (S)
Image
f
Figure 20.5 We claim the sets f âˆ’1(îˆ»i) for i âˆˆîˆµcover S.
We know that for all i âˆˆîˆµ, îˆ»i is open. By the open version of the topological
deï¬nition of continuity, for all i âˆˆîˆµ, f âˆ’1(îˆ»i) is open.
Comment: That gives us a new family of open sets in the domain side of the func-
tion where S is. If there is any justice in the world, we can make the following
claim (Figure 20.5).
Claim. S âŠ†â‹ƒ
iâˆˆîˆµ
f âˆ’1(îˆ»i).
Proof of claim. Assume s âˆˆS. Since S âŠ†D, f (s) is deï¬ned, and f (s) âˆˆf (S). But
then
f (s) âˆˆf (S) âŠ†
â‹ƒ
iâˆˆîˆµ
îˆ»i.
(20.16)
So there exists is âˆˆI such that f (s) âˆˆOis. So s âˆˆf âˆ’1(Ois). So s âˆˆâ‹ƒ
iâˆˆîˆµ
(f âˆ’1(îˆ»i)). â—¾
Now we have an open cover of the set we know is compact. So âˆƒJ âŠ†I such
that J is ï¬nite and
S âŠ†
â‹ƒ
iâˆˆîˆ¶
f âˆ’1(îˆ»i).
(20.17)
Comment: We are looking for a ï¬nite subcover of f (S) from Oi with i âˆˆI. Again
if there is any justice in the world, we can make the following claim.
Claim. f (S) âŠ†â‹ƒ
iâˆˆîˆ¶
Oi.
Proof of claim. Assume y âˆˆf (S). Then âˆƒx âˆˆS such that f (x) = y. Now x âˆˆS âŠ†
â‹ƒ
iâˆˆîˆ¶
f âˆ’1(Oi). So âˆƒix âˆˆJ such that x âˆˆf âˆ’1(Oix). But then f (x) âˆˆOix. So we have
f (x) âˆˆâ‹ƒ
iâˆˆîˆ¶
Oi.
â—¾

400
20 Continuity and Topology
We have proved that if f (S) âŠ†â‹ƒ
iâˆˆîˆµ
Oi with a family of open sets, then there
exists J âŠ†I with J is ï¬nite so that f (S) âŠ†â‹ƒ
iâˆˆîˆ¶
Oi.
That makes f (S) compact.
Î”
This deserves to be rewritten.
Proof. Assume f âˆ¶â„â†’â„be a function with domain D. Assume f (x) to be
continuous on D. Assume D is open. Assume S âŠ†D. Assume that S is compact.
Assume îˆ»i with i âˆˆI is a family of open sets, and assume f (S) âŠ†â‹ƒ
iâˆˆîˆµ
îˆ»i.
We know that for all i âˆˆîˆµ, îˆ»i is open. By the topological deï¬nition of conti-
nuity, for all i âˆˆîˆµ, f âˆ’1(îˆ»i) is open.
Claim. S âŠ†â‹ƒ
iâˆˆîˆµ
f âˆ’1(îˆ»i).
Proof of claim. Assume s âˆˆS. Since S âŠ†D, f (s) is deï¬ned, and f (s) âˆˆf (S). But
then
f (s) âˆˆf (S) âŠ†
â‹ƒ
iâˆˆîˆµ
îˆ»i.
(20.18)
So there exists is âˆˆîˆµs.t. f (s) âˆˆîˆ»is. So s âˆˆf âˆ’1(îˆ»is). So s âˆˆâ‹ƒ
iâˆˆîˆµ
f âˆ’1(îˆ»i).
â—¾
Now we have an open cover of the set we know is compact. So âˆƒîˆ¶âŠ†îˆµsuch
that îˆ¶is ï¬nite and
S âŠ†
â‹ƒ
iâˆˆîˆ¶
f âˆ’1(îˆ»i).
(20.19)
Claim. f (S) âŠ†â‹ƒ
iâˆˆîˆ¶
îˆ»i.
Proof of claim. Assume y âˆˆf (S). Then âˆƒx âˆˆS s.t. f (x) = y. Now x âˆˆS âŠ†
â‹ƒ
iâˆˆîˆ¶
f âˆ’1(îˆ»i). So âˆƒix âˆˆîˆ¶such that x âˆˆf âˆ’1(îˆ»ix). But then f (x) âˆˆîˆ»ix. So we have
f (x) âˆˆâ‹ƒ
iâˆˆîˆ¶
îˆ»i.
â—¾
We have proved that if f (S) âŠ†â‹ƒ
iâˆˆîˆµ
îˆ»i with a family of open sets, then there
exists îˆ¶âŠ†îˆµwith îˆ¶is ï¬nite so that f (S) âŠ†â‹ƒ
iâˆˆîˆ¶
îˆ»i.
That makes f (S) compact.
â—½
20.3.2
The extreme value theorem
The ï¬rst application we have for this theorem is an old friend from Calculus I.

20.3 Compact Images
401
Theorem 20.3.3
(The Extreme Value Theorem).
If f âˆ¶[a, b] â†’â„is con-
tinuous on [a, b], then there exists s, t âˆˆ[a, b] such that for all x âˆˆ[a, b],
f (s) â‰¤f (x) â‰¤f (t).
(20.20)
This is to say that a continuous function on a closed interval achieves its
extreme values, maximum and minimum, at points in the interval. Since [a, b]
is obviously closed and bounded, we expect its image will also be. But we need
to be sure that all the hypotheses of our theorem are satisï¬ed before we reach
its conclusion. The theorem requires that the domain of the function be open,
and the proof deï¬nitely used that condition. Unfortunately, [a, b] is not open.
We have a trick up our sleeves just for this situation.
Proof. Assume that f âˆ¶[a, b] â†’â„has domain [a, b].
Assume that f (x) is continuous on [a, b].
Deï¬ne f1 âˆ¶â„â†’â„by
f1(x) =
âŽ§
âŽª
âŽ¨
âŽªâŽ©
f (a)
if a < x
f (x)
if a â‰¤x â‰¤b
f (b)
if x < b.
(20.21)
Now f1(x) is continuous on â„by the gluing theorem, Theorem 19.2.12.
Then f1(x) is continuous on an open domain (now that is all of â„); [a, b] is a
compact subset of that domain, and
f1([a, b]) = f ([a, b]).
(20.22)
So f ([a, b]) is compact.
Now by Heineâ€“Borel, f ([a, b]) is closed and bounded. Because [a, b] â‰ âˆ…,
f ([a, b]) â‰ âˆ…. By a previous theorem, f ([a, b]) has a maximum and a minimum
(because we know that its inï¬mum and supremum are in the boundary of the
closed set). Call then m and M, respectively.
But m âˆˆf ([a, b]) and M âˆˆf ([a, b]). So âˆƒs âˆˆ[a, b] s.t. f (s) = m and âˆƒt âˆˆ[a, b]
s.t. f (t) = M. So indeed we have
âˆ€x âˆˆ[a, b], f (s) â‰¤f (x) â‰¤f (t).
(20.23)
â—½
20.3.3
The intermediate value theorem
The next application is the ï¬nal result we need to be completely satisï¬ed that â„
contains all the numbers that we might ever need. Well, at least all the numbers
that can be given a total order. Those numbers should be suï¬ƒcient to mea-
sure any quantity we will ever want. In particular, we will ï¬nally know that we
have completely solved the problem with the rational numbers that set us oï¬€in
search of the real numbers.

402
20 Continuity and Topology
Theorem 20.3.4
(The Intermediate Value Theorem).
If f âˆ¶[a, b] â†’â„is
continuous on [a, b], then either
f ([a, b]) = {m}
(20.24)
or f ([a, b]) = [m, M].
This result is called the â€œintermediate value theoremâ€ because it says that not
only does the image contain its extreme values (maximum and minimum), but
it also contains all the intermediate values between them. The proof uses the
inseparability theorem (Theorem 18.2.1) from earlier.
Proof. As in the proof of the extreme value theorem, we may assume without
loss of generality that f âˆ¶â„â†’â„is continuous on â„. Thus, we may assume that
the domain of f is open.
Then by the extreme value theorem,
âˆƒs, t âˆˆ[a, b] s.t. âˆ€x âˆˆ[a, b], f (s) â‰¤f (x) â‰¤f (t).
(20.25)
Let m = f (s) and M = f (t). There are two cases to consider: m = M or m < M.
In case 1, we have f ([a, b]) = {m}.
For case 2, assume m < M. Then we have
f ([a, b]) âŠ†[m, M].
(20.26)
Claim. [m, M] âŠ†f ([a, b]).
Proof of claim. Assume BWOC that âˆƒð‘£âˆˆ[m, M] such that ð‘£âˆ‰f ([a, b]).
Then by the extreme value theorem, m and M are deï¬nitely in f ([a, b]). So we
know that ð‘£â‰ m and ð‘£â‰ M. And in turn, m < ð‘£< M.
Consider the open sets (âˆ’âˆž, ð‘£) and (ð‘£, âˆž). Then
(âˆ’âˆž, ð‘£) âˆª(ð‘£, âˆž) = â„âˆ–{ð‘£};
(20.27)
(âˆ’âˆž, ð‘£) âˆ©(ð‘£, âˆž) = âˆ….
Thus,
f ([a, b]) âŠ†(âˆ’âˆž, ð‘£) âˆª(ð‘£, âˆž).
(20.28)
Now by the topological deï¬nition of continuity (Theorem 20.2.1),
îˆ»1 = f âˆ’1((âˆ’âˆž, ð‘£)) and
îˆ»2 = f âˆ’1((ð‘£, âˆž))
are open sets.
We claim that îˆ»1âˆ©îˆ»2 = âˆ….
Assume BWOC that x âˆˆîˆ»1âˆ©îˆ»2. Then x âˆˆîˆ»1 = f âˆ’1((âˆ’âˆž, ð‘£)) and x âˆˆîˆ»2 =
f âˆ’1((ð‘£, âˆž)). Then f (x) âˆˆ(âˆ’âˆž, ð‘£) and f (x) âˆˆ(ð‘£, âˆž). But then f (x) âˆˆ(âˆ’âˆž, ð‘£) âˆ©
(ð‘£, âˆž) = âˆ…. This is a contradiction. So we must have îˆ»1âˆ©îˆ»2 = âˆ…, as claimed.

20.3 Compact Images
403
We now claim that [a, b] âŠ†îˆ»1 âˆªîˆ»2.
Assume x âˆˆ[a, b]. Since x is in the domain of the function, f (x) âˆˆf ([a, b]).
Now ð‘£âˆ‰f ([a, b]); so f (x) â‰ ð‘£. This means f (x) âˆˆ(âˆ’âˆž, ð‘£) âˆª(ð‘£, âˆž). So
x âˆˆf âˆ’1((âˆ’âˆž, ð‘£) âˆª(ð‘£, âˆž)). Now we know from set theory algebra that
f âˆ’1((âˆ’âˆž, ð‘£) âˆª(ð‘£, âˆž)) = f âˆ’1((âˆ’âˆž, ð‘£)) âˆªf âˆ’1((ð‘£, âˆž))
(20.29)
= îˆ»1 âˆªîˆ»2.
Thus, [a, b] âŠ†îˆ»1 âˆªîˆ»2 as claimed.
We now claim that [a, b] âŠˆîˆ»1.
Now t âˆˆ[a, b] and f (t) = M. But M âˆˆ(ð‘£, âˆž). So t âˆˆf âˆ’1((ð‘£, âˆž)) = îˆ»2. Since
we just saw îˆ»1âˆ©îˆ»2 = âˆ…, we have t âˆ‰îˆ»1. Thus, [a, b] âŠˆîˆ»1 as claimed.
Finally, we claim that [a, b] âŠˆîˆ»2.
Here s âˆˆ[a, b] and f (s) = m. But m âˆˆ(âˆ’âˆž, ð‘£). So s âˆˆf âˆ’1((âˆ’âˆž, ð‘£)) = îˆ»1.
Since we just saw îˆ»1âˆ©îˆ»2 = âˆ…, we have s âˆ‰îˆ»2. Thus, [a, b] âŠˆîˆ»2 as claimed.
Now we have two open sets îˆ»1 and îˆ»2 and a closed interval [a, b] so that
[a, b] âŠ†îˆ»1 âˆªîˆ»2;
(20.30)
îˆ»1 âˆ©îˆ»2 = âˆ…;
[a, b] âŠˆîˆ»1;
[a, b] âŠˆîˆ»2.
This contradicts the inseparability theorem. So we must have [m, M] âŠ†
f ([a, b]).
â—¾
Since we have both f ([a, b]) âŠ†[m, M] and [m, M] âŠ†f ([a, b]), it follows that if
m < M, then we must have f ([a, b]) = [m, M].
So we have proved that if f âˆ¶[a, b] â†’â„is continuous on [a, b], then either
f ([a, b]) = {m}
(20.31)
or f ([a, b]) = [m, M].
â—½
In a Calculus I text where images and set equality may not be properly
deï¬ned, this theorem is stated in the form more like that given in the following
corollary.
Corollary 20.3.5.
Let f âˆ¶[a, b] â†’â„be continuous on [a, b]. If t âˆˆâ„with t
between f (a) and f (b), then there exists s âˆˆ[a, b] so that f (s) = t.
Proof. Assume f âˆ¶[a, b] â†’â„is continuous on [a, b].
Assume without loss of generality that f (a) â‰¤f (b).
Assume ð‘£âˆˆâ„with f (a) â‰¤ð‘£â‰¤f (b). If f (a) = ð‘£or f (b) = ð‘£, we are done, so
suppose that f (a) < ð‘£< f (b).
Comment: We will see that this is a prudent renaming of the variable.

404
20 Continuity and Topology
Then f (a) â‰ f (b).
By the extreme value theorem, âˆƒs, t âˆˆ[a, b] such that
f ([a, b]) âŠ†[f (s), f (t)].
(20.32)
By the intermediate value theorem,
f ([a, b]) = [f (s), f (t)].
(20.33)
Now f (a) âˆˆf ([a, b]) = [f (s), f (t)] and f (b) âˆˆf ([a, b]) = [f (s), f (t)]. Since ð‘£is
between two points in an interval, ð‘£is in that interval.
So ð‘£âˆˆ[f (s), f (t)] = f ([a, b]). So there exists u âˆˆ[a, b] such that f (u) = ð‘£. â—½
Corollary 20.3.6.
For all a âˆˆ[0, âˆž), there exists b âˆˆ[0, âˆž) such that a = b2.
Proof. First we note that 02 = 0 and 12 = 1. That leaves us with two possibilities:
0 < a < 1 and 1 < a.
Next we point out that f âˆ¶â„â†’â„given by f (x) = x2 is continuous on â„.
Case 1: Assume 0 < a < 1. Then a is between f (0) and f (1). By the interme-
diate value theorem, there exists b âˆˆ[0, 1] so that f (b) = a.
Case 2: Assume 1 < a. Then multiplying by a, we get a < a2. So a is between
f (1) and f (a). By the intermediate value theorem, there exists b âˆˆ[1, a] so that
f (b) = a.
â—½
20.4
Problems
20.1
Let f âˆ¶â„â†’â„with domain D. Prove that f (x) is continuous on Dâˆ˜.
20.2
Let f âˆ¶â„â†’â„be a function with domain D. Let D be open. Prove that
if f (x) is continuous on D and îˆ»âŠ†â„with îˆ»open, then f âˆ’1(îˆ») is open.
20.3
Prove: if f âˆ¶â„â†’â„is a function continuous on its open domain D and
S âŠ†D compact, then f (S) is compact.
20.4
Assume that the function s âˆ¶â„â†’â„given by s(x) = Sin(x) is continu-
ous on â„.
(a) Prove that the set
S =
{
x âˆˆâ„âˆ£Sin(x) =
âˆš
2
2
}
is closed.

20.4 Problems
405
(b) Prove that the set
S =
{
x âˆˆâ„âˆ£Sin(x) <
âˆš
2
2
}
is open.
20.5
Let f âˆ¶â„â†’â„be continuous on â„. Prove: if S âŠ†â„is bounded, then
f (S) is bounded. (Hint: Use all the power found in this chapter and not
the deï¬nition of bounded.)
20.6
Let p âˆ¶â„â†’â„be a rational function given by
p(x) = anxn + anâˆ’1xnâˆ’1 + Â· Â· Â· a1x + a0
bmxm + bmâˆ’1xmâˆ’1 + Â· Â· Â· b1x + b0
with ai, bi âˆˆâ„for all i. Prove that the domain of p(x) is open.
20.7
Let f âˆ¶â„â†’â„have domain D and g âˆ¶â„â†’â„have domain E. If a âˆˆ
â„such that âˆƒðœ€> 0 so that N(a, ðœ€) âŠ†D âˆ©E and f (x) = g(x) for all x âˆˆ
N(a, ðœ€), then f (x) is continuous at x = a if and only if g(x) is continuous
at x = a.
20.8
Let f âˆ¶â„â†’â„be given by f (x) = x3 âˆ’18x. Prove that there is an ð›¼âˆˆâ„
so that f (ð›¼) = 5.
20.9
Let p(x) be a polynomial of odd degree. Prove that p(x) has a real root.
(Hint: Consider plus and minus the maximum of the set of coeï¬ƒcients
of p(x) to get a start.)
20.10
Let f âˆ¶[0, âˆž) â†’â„be given by f (x) =
âˆš
x. Prove that f (x) is continuous
on [0, âˆž) using the deï¬nition of continuous. (Be careful with the 0.)
20.11
Prove that the set
S = {b âˆˆâ„|âˆƒa âˆˆâ„with 1 â‰¤a â‰¤3 such that b = a5 âˆ’a3}
is closed.
20.12
Let f âˆ¶[a, b] â†’â„be continuous on [a, b]. We know that either
f ([a, b]) = {M} or f ([a, b]) = [m, M].
(a) Prove: If âˆƒt âˆˆ(a, b) such that f (t) = M, then either f ([a, t]) = {M}
or f ([a, t]) = [m1, M] and that either f ([t, b]) = {M} or f ([t, b]) =
[m2, M].

406
20 Continuity and Topology
(b) Prove: If âˆƒt âˆˆ(a, b) such that f (t) = M, and f ([a, t]) = [m1, M] and
f ([t, b]) = [m2, M], then âˆƒy âˆˆ[m1, M] âˆ©[m2, M] with y â‰ M.
(c) Prove: If âˆƒt âˆˆ(a, b) such that f (t) = M, then f (x) is not injective.
(d) Prove: If f (x) is injective, then the maximum value of f ([a, b]) occurs
at one of the end points.

407
21
A Few Final Observations
We fulï¬lled the mathematical promise of this study in the last chapter when we
proved the intermediate value theorem. Early on we realized that, as familiar as
they might be, the real numbers are pretty diï¬ƒcult to nail down exactly. Dec-
imal approximations will turn any real number into a rational number that is
close enough for any practical application. But for any exact statement about
a real number, it may be necessary to resort to analysis to understand what is
being said. After centuries or work, mathematicians have devised a descrip-
tion of real numbers that makes exact statements possible. The mathematical
description that says the real numbers are any numbers that form a complete
ordered ï¬eld is hardly intuitive, but once we get used to it, it is very powerful.
There is no end to how it can be used.
We scratched the surface of these applications but did manage to prove that
we have all the numbers we need to measure quantities. That is the philo-
sophical consequence of the intermediate value theorem. If something can be
approximated above and below in a â€œcontinuousâ€ way to any level of accuracy,
there is a real number that identiï¬es it exactly. Mathematicians are never con-
tent to let things lie, and they have expanded the notion of â€œnumberâ€ to other
realms. Still the intermediate value theorem says that, for measuring real quan-
tities, all one needs are real numbers.
We end this study with a few ï¬nal observations.
21.1
Inverses of continuous functions
Now that we can deï¬ne a function f âˆ¶[0, âˆž) â†’â„by f (x) =
âˆš
x, we can prove
that f (x) is continuous on [0, âˆž). However, we are after bigger game again. We
would like to prove once and for all that, if a bijective function is continuous on
its domain, then its inverse function is continuous on its domain. The problem
is that this is not as true as it seems to be. There are important properties that
the domain must have before we can say that this result is correct.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
Â© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

408
21 A Few Final Observations
21.1.1
A strange example
We will begin by examining an example where the inverse of a function con-
tinuous on its domain is so far from continuous that it could hardly get much
worse. The trick, however, is to set the original function on a domain that is
pretty bad to start with, â„š. The set of rational numbers is neither open nor
closed. It contains no intervals, and its complement in â„contains no intervals
either.
We do not have a ï¬rm enough deï¬nition of the sine function to prove that it
is continuous on â„. We do, however, expect that this is true and so that is good
enough for an example.
Example 21.1.1.
Let f âˆ¶â„â†’â„be given by f (x) = Sin(x). Then we can
assume that f (x) is continuous on â„. We can also assume that the period of
f (x) is 2ðœ‹and that ðœ‹is not a rational number. These are all true statements well
known in Mathematics, but we have not proved them.
Deï¬ne: g âˆ¶â„šâ†’f (â„š) by g(x) = Sin(x). Since â„šâŠ†â„, g(x) is continuous on its
domain. In addition, because the codomain is f (â„š), g(x) is surjective. But it may
come as a surprise to realize that, because ðœ‹âˆ‰â„š, g(x) is injective!
Assume g(x1) = g(x2) with x1 and x2 in â„š. From trigonometry, we know that
either x2 = x1 + 2kðœ‹for some k âˆˆâ„¤, or x2 = (2k + 1)ðœ‹âˆ’x1 for some k âˆˆâ„¤.
In case 1, if we also know that k â‰ 0, we can solve for ðœ‹to see
ðœ‹= x2 âˆ’x1
2k
.
(21.1)
Since x1, x2, 2 and k are rational, this would make ðœ‹âˆˆâ„šwhich it is not. So k
must be 0 in this cases. Then x2 = x1 + 2kðœ‹= x1
In case 2, we get
ðœ‹= x2 + x1
2k + 1 .
(21.2)
This is not possible, no matter what. So we can only have x1 = x2. Since g(x1) =
g(x2) implies x1 = x2, g(x) is injective.
This seems impossible considering the graph of y = Sin(x), which could not
possibly pass the horizontal line test. But because of all the holes in â„š, every
horizontal line that hits the graph of g(x) once slips through a hole in the graph
every other time it gets close.
Because g(x) is bijective, it has an inverse function gâˆ’1 âˆ¶f (â„š) â†’â„š. Its graph
is the sine curve stood on its head. This is the graph of a function only because
of all the holes. The graph, however, looks just as continuous on its side as it
did in normal position. But recall that we are not talking about the curve being
continuous, but rather the function. And the graph is not the solid curve it
appears to be because of all the irrational holes.
Consider any point b âˆˆf (â„š). Suppose that we make even the slightest move
along the x-axis away from this point. The points on the curve above the x values

21.1 Inverses of Continuous Functions
409
we move through go completely bizonkers (not a precisely deï¬ned math term).
The points jump about so haphazardly as they move on the x-axis that it is
impossible to track any of the actual heights g(x). In fact, no matter how small
ðœ€> 0 might be, the image f (N(a, ðœ€)) will be unbounded above and below. There
is nothing continuous about that functional behavior.
The graph of the curve y = Sin(x) restricted to x âˆˆâ„šis continuous. The func-
tion g âˆ¶â„šâ†’Sin(â„š) is continuous on the domain â„š. The graph of the curve
x = Sin(y) restricted to y âˆˆâ„šis continuous since it is just a 90âˆ˜rotation of the
curve y = Sin(x). However, the function gâˆ’1: Sin(â„š) â†’â„šis not continuous on
its domain. A function is more than the graph of a curve; a function is more
than a set of ordered pairs.
This is a particularly bad example, but it illustrates the point. The theorem
that the inverse of a continuous function is continuous is pretty substantial.
It must be carefully formulated to be true. It would not be surprising if its
proof required a lot of power; power like that embedded in the proofs of: the
Heineâ€“Borel theorem, the inseparability theorem, and the intermediate value
theorem.
21.1.2
The theorem about inverses of continuous functions
First, we need a lemma.
Lemma 21.1.2.
Let f âˆ¶â„â†’â„have domain D. Let D be open, f (x) be con-
tinuous on D, and [a, b] âŠ†D. We know that either f ([a, b]) = {m} or f ([a, b]) =
[m, M].
If f (x) is injective, then
f ((a, b)) = (m, M).
(21.3)
In other words, the maximum and minimum values of the image occur only at
the end points of the interval.
Proof. Assume f âˆ¶â„â†’â„has domain D.
Assume that D is open.
Assume that f (x) is continuous on D.
Assume [a, b] âŠ†D.
Assume that f (x) is injective.
From the intermediate value theorem, we know that either f ([a, b]) = {m}
or f ([a, b]) = [m, M]. But because we have an interval, a â‰ b, and since f (x) is
injective, f (a) â‰ f (b).
So f ([a, b]) = [m, M].
We will only prove that m occurs at an end point of [a, b].
Now m âˆˆ[m, M] = f ([a, b]). So âˆƒs âˆˆ[a, b] such that f (s) = m.

410
21 A Few Final Observations
Assume BWOC that s âˆˆ(a, b).
Consider [a, s] and [s, b]. Now m = f (s) âˆˆf ([a, s]) âŠ†[m, M]. In addition, m =
f (s) âˆˆf ([s, b]) âŠ†[m, M]. By the intermediate value theorem, both f ([a, s]) and
f ([s, b]) are closed intervals. So by the last remark:
f ([a, s]) = [m, M1];
(21.4)
f ([s, b]) = [m, M2].
Since these are true intervals,
[m, M1] âˆ©[m, M2] â‰ âˆ….
(21.5)
Let y âˆˆ(m, M1] âˆ©(m, M2]. Then y âˆˆf ([a, s]) âˆ©f ([s, b]). So y âˆˆf ([a, s]) and
y âˆˆf ([s, b]). Thus, âˆƒx1 âˆˆ[a, s] such that f (x1) = y, and âˆƒx2 âˆˆ[s, b] s.t. f (x2) = y.
But f (x1) = f (x2) with f (x) injective. So
x1 = x2 âˆˆ[a, s] âˆ©[s, b] = {s}.
(21.6)
Then
x1 = x2 = s.
So
m = f (s) = f (x1) = y âˆˆ(m, M1] âˆ©(m, M2].
That
is
a contradiction. So m = a or m = b.
â—½
Notice that this argument is really geometric. If the minimum m of f ([a, b])
occurs in the interior of the interval [a, b], then it is a local minimum. That
means the graph of the function is higher on both sides of that local minimum.
Since the intermediate value theorem requires images to be intervals, there are
plenty of points on either side of that local minimum that have the same y-value
as the point. So the graph cannot pass the â€œhorizontal line test.â€ The function
cannot be injective.
Now we are ready to prove the theorem we want. With all the preimages
that are likely to appear, it is best if we give the inverse of our function its own
new name.
Theorem 21.1.3.
Let f âˆ¶D â†’E where D âŠ†â„and E âŠ†â„. Let D be open, and
f (x) be continuous on D. Assume that f (x) is bijective.
If g âˆ¶E â†’D is an inverse function of f , then g(x) is continuous on E.
Proof. Let f âˆ¶D â†’E where D âŠ†â„and E âŠ†â„.
Assume that D is open. Assume that f (x) is continuous on D. Assume that
f (x) is bijective.
Comment: What are we proving now? â€œg(x) is continuous on E.â€ That is, â€œâˆ€b âˆˆE,
g(x) is continuous at x = b.â€
Assume b âˆˆE.

21.1 Inverses of Continuous Functions
411
Comment: What are we proving now? â€œg(x) is continuous at x = b.â€ That is,
â€œâˆ€ðœ€> 0, âˆƒð›¿> 0 so that g(N(b, ð›¿)) âŠ†N(g(b), ðœ€).â€
Assume ðœ€0 > 0.
Comment: What are we proving now? â€œâˆƒð›¿> 0 so that g(N(b, ð›¿)) âŠ†N(g(b), ðœ€).â€
We need to ï¬nd a small number for the domain side of g(x).
Now b âˆˆE. So g(b) = a âˆˆD. So f (a) = b.
Consider N(g(b), ðœ€0). This is N(a, ðœ€0), which is a neighborhood of a âˆˆD.
Comment: Is it small enough? Perhaps not.
Now a âˆˆN(a, ðœ€0) âˆ©D, which is an open set. So âˆƒðœ€1 > 0 such that N(a, ðœ€1) âŠ†
N(a, ðœ€0) âˆ©D. Thus, N(a, ðœ€1) âŠ†N(a, ðœ€0) and N(a, ðœ€1) âŠ†D. Then
[
a âˆ’ðœ€1
2 , a âˆ’ðœ€1
2
]
âŠ†(a âˆ’ðœ€1, a âˆ’ðœ€1)
(21.7)
âŠ†N(a, ðœ€1)
âŠ†N(a, ðœ€0) âˆ©D.
Since f (x) is continuous on the open set D, the intermediate value theorem tells
us that
f
([
a âˆ’ðœ€1
2 , a âˆ’ðœ€1
2
])
= [m1, M1].
(21.8)
Since f (x) is bijective, the lemma tells us that
f
((
a âˆ’ðœ€1
2 , a âˆ’ðœ€1
2
))
= (m1, M1).
(21.9)
But
f (a) âˆˆf
((
a âˆ’ðœ€1
2 , a âˆ’ðœ€1
2
))
= (m1, M1).
(21.10)
So âˆƒð›¿= ðœ€1
2 > 0 such that N(f (a), ð›¿) âŠ†(m1, M1). That is
N(f (a), ð›¿) âŠ†f
((
a âˆ’ðœ€1
2 , a âˆ’ðœ€1
2
))
.
(21.11)
Claim. g(N(b, ð›¿)) âŠ†N(g(b), ðœ€0).
Proof of claim. Now
N(b, ð›¿) = N(f (a), ð›¿)
(21.12)
âŠ†f
((
a âˆ’ðœ€1
2 , a âˆ’ðœ€1
2
))
.

412
21 A Few Final Observations
So
g(N(b, ð›¿)) âŠ†g
(
f
((
a âˆ’ðœ€1
2 , a âˆ’ðœ€1
2
)))
(21.13)
âŠ†
(
a âˆ’ðœ€1
2 , a âˆ’ðœ€1
2
)
âŠ†
[
a âˆ’ðœ€1
2 , a âˆ’ðœ€1
2
]
âŠ†N(a, ðœ€0) âˆ©D
âŠ†N(a, ðœ€0)
âŠ†N(g(b), ðœ€0).
â—¾
This proves that g(x) is continuous at x = b.
â—½
21.2
The intermediate value theorem and continuity
We went to great lengths to prove that a function continuous on a open domain
satisï¬es the intermediate value theorem. If this was so important, why not use
the theorem as the deï¬nition of continuous? The following example shows why
not (Figure 21.1).
Example 21.2.1.
Let f âˆ¶â„â†’â„be given by f (x) = Sin(xâˆ’1).
This function is not deï¬ned at x = 0. A look at the graph shows that the func-
tion is pretty badly behaved around x = 0. We certainly do not want a deï¬nition
of continuous on â„that called this function continuous there. However, if a and
b are any two real numbers with f (a) â‰ f (b), then for any d between f (a) and
f (b), there is always a c between a and b with f (c) = d.
In mathematical and logical terms, the converse of the intermediate value
theorem is false.
x
âˆ’2
âˆ’1
1
2
y
âˆ’1
1
Figure 21.1 f(x) = Sin(xâˆ’1) .

21.4 Conclusion
413
21.3
Continuity at discrete points
Theorem 21.3.1.
Let f âˆ¶â„â†’â„have domain D. Let a âˆˆDâˆ˜. Then f (x) is con-
tinuous at a.
Proof. Assume a âˆˆDâˆ˜. Then âˆƒð›¿1 > 0 so that N(a, ð›¿1) âˆ©D = {a}. This means,
if x âˆˆD and |x âˆ’a| < ð›¿1, then x = a.
To prove f (x) is continuous at x = a, assume ðœ€> 0. Choose ð›¿= ð›¿1.
To proves this works in the deï¬nition, assume x âˆˆD and |x âˆ’a| < ð›¿= ð›¿1.
The only possibility is x = a. So |f (x) âˆ’f (a)| = 0 < ðœ€. So the proof is
ï¬nished.
â—½
This may seem odd at ï¬rst. If a function is deï¬ned in a way that leaves points
in the domain isolated from any other points where the function is deï¬ned,
then the function is automatically continuous at those isolated points. Thus,
any function f âˆ¶â„•â†’â„is continuous on all of â„•. In addition, any function f âˆ¶
â„¤â†’â„is also continuous on its domain. Since no ordered ï¬eld is ever discrete
(the average theorem), there is no such free lunch on a domain that big.
21.4
Conclusion
All this last material is fodder for later courses. However, the ideas of most
other areas of mathematics are based on the ideas introduced in this study:
logic, set theory, functions, and relations. Analysis, real or not, multivariable or
not, starts with a precise deï¬nition of the real numbers that includes complete-
ness. The basic ideas of topology are essential tools for making sense of complex
numbers, real vector spaces, and complex vector spaces from a geometric point
of view. We have only gotten started.

415
Index
Symbols
âˆ§
100
â‡”
103
âˆ…
160
âˆ€
109, 107
â‡’
102
âˆˆ
19, 153
âˆ¨
100
Â±
75
ðœ‹
212, 287â€“289, 290, 408
âŠ†
153
âˆ¼
104
âˆƒ
109, 107
a
Absolute value
75
Accumulation point
294, 301, 302
330, 333
AE statement
110, 137, 158
Archimedean principle
86, 110, 285
Associative property
7, 9, 105, 155,
235
Average theorem
74, 117, 285
b
Bijective
201
Binary operation
235
Bolzanoâ€“Weierstrass theorem
357
Boundary
300
BWOC (by way of contradiction)
68
c
Cartesian product
176
Closed set
311, 312
Closure
303
Commutative property
7, 8, 105, 155,
235
Compact
346, 347, 357, 397
Complement
155
Completeness axiom
83, 284
alternate
84, 181
Complete set
83, 84, 181, 284
Composition
204
Continuous
on a closed set
394
on an open set
391
at a point
363
on a set
389
Contradiction
104, 107, 142
Contrapositive
34, 106, 107, 139
Converse
106
d
Decimal expansions
287
Dedekind cuts
291
Deleted neighborhoods
296
De Morganâ€™s laws
105, 114, 144, 157,
160, 300, 302, 325
Density theorem
irrationals
91
rationals
88, 286
Discrete points
294, 301, 413

416
Index
Discrete set
11, 46, 78, 300, 307
Distributive property
9, 105, 155,
235
Division algorithm
28, 49
Dummy variable
24
e
EA-statement
110
Equivalence classes
184
Equivalence relation
182
Equivalent fractions
56
Euclid
7, 237
Even numbers
30, 48, 280
Exterior
294, 299
Extreme value theorem
401
f
Families of sets
157â€“158
Finite sets
239, 246
First partition theorem
300
For all
104, 107
Fractions
53â€“56, 272
in lowest terms
68, 71, 279
Function
194
bijective
201, 208
codomain
197
domain
196
injective
197
range
196
surjective
197
g
Gluing theorem
385, 401
GÃ¶del, Kurt
119
Greatest lower bound
81, 83
h
Heineâ€“Borel theorem
347
Hypothesis
106
i
Identity element
9, 37, 236
Identity function
206
Identifying sets
52, 53, 67, 272, 279,
282, 290
iï¬€
103
If...then
102, 107
Image
215
Index set
158
Induction
proof by
15â€“17, 22, 125, 243, 382
theorem of
25, 266
In ï¬mum
112, 113, 180
Inï¬nite sets
239, 240â€“245
Injective function
197
Inseparability theorem
354, 402
Integers
40, 267
Interior
293, 298, 302
Intermediate value theorem
402,
403, 409, 411, 412
Intersection of a family of sets
158
Intersection of sets
155
Intervals
deï¬nition
169
notation
162
properties
254
Inverse function
207, 208, 410
Inverse of an element
236
Inverse statement
106
Irrational numbers
67, 79, 91, 93â€“95
l
Least upper bound
84, 86
Logical equivalence
104
Logical statements
99
Lower bound
39, 179
m
Mathematical statements
107
Maximum
48, 180
Minimum
19, 180
Modulo equivalence
186
n
Natural numbers
21, 263
Necessary condition
106

Index
417
Neighborhood
296
o
Odd numbers
30, 48, 280
Open sets
311
Ordered ï¬eld
50, 63, 73, 83, 281, 284
Ordered pairs
175
p
Parsing
129
Polynomial function
382
Power set
242
Preimage
219
Proof
by contradiction
107
by contrapositive
107
direct
12, 107
by induction, see Induction
by minimum counterexample
25,
266
Proper subset
154
q
Qualiï¬ers
existence
108
speciï¬cation
108
universal
109
r
Rational function
385, 389, 396, 405
Rational numbers
57, 273
Real numbers
84, 284, 290â€“292
Reï¬‚exive property
178
Relation
177
equivalence
182
function
194
total order
179
Russell, Bertrand
172
s
Second partition theorem
301
Set
19, 151
complement
155
equality
153
product
176
Subset
153
Suï¬ƒcient condition
106
Supremum
117, 180, 285
Surjective function
197
Syllogism
121
Symmetric property
178
t
Tautology
104,121
Topological deï¬nition of continuous
closed version
394
open version
391, 398, 402
Total order
179
Transitive property
4, 178
Triangle inequality
77, 283, 378
Trichotomy
5, 102, 178
u
Union of families of sets
158
Union of sets
155
Unique objects
40, 41
Upper bound
48, 84, 180
w
Well deï¬ned term
58, 75, 187,
273â€“275
Well-ordered set
20, 45, 181
z
Zero divisors
40
Zeroth partition theorem
293

