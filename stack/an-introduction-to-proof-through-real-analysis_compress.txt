Daniel J. Madden and Jason A. Aubrey
The University of Arizona
Tucson, Arizona, USA
An Introduction to Proof
through Real Analysis

This edition ﬁrst published 2017
© 2017 John Wiley & Sons, Inc.
Library of Congress Cataloging-in-Publication Data
Names: Madden, Daniel J., 1948- | Aubrey, Jason A., 1975-
Title: An introduction to proof through real analysis / by Daniel J. Madden,
Jason A. Aubrey, The University of Arizona, Tucson, Arizona, USA.
Description: 1st edition. | Hoboken, NJ : Wiley, 2017. | Includes
bibliographical references and index. |
Identiﬁers: LCCN 2017015345 (print) | LCCN 2017023296 (ebook) | ISBN
9781119314738 (pdf) | ISBN 9781119314745 (epub) | ISBN 9781119314721
(cloth)
Subjects: LCSH: Proof theory–Textbooks. | Functions of real
variables–Textbooks. | Numbers, Real–Textbooks. | Mathematical
analysis–Textbooks.
Classiﬁcation: LCC QA9.54 (ebook) | LCC QA9.54 .M335 2017 (print) | DDC
511.3/6–dc23
LC record available at https://lccn.loc.gov/2017015345
Cover design: Wiley
Cover image: © monsitj/Gettyimages
Set in 10/12pt WarnockPro by SPi Global, Chennai, India
Printed in the United States of America

Contents
List of Figures
xiii
Preface
xv
Introduction
xvii
Part I
A First Pass at Deﬁning ℝ
1
1
Beginnings
3
1.1
A naive approach to the natural numbers
3
1.1.1
Preschool: foundations of the natural numbers
3
1.1.2
Kindergarten: addition and subtraction
5
1.1.3
Grade school: multiplication and division
8
1.1.4
Natural numbers: basic properties and theorems
11
1.2
First steps in proof
12
1.2.1
A direct proof
12
1.2.2
Mathematical induction
14
1.3
Problems
17
2
The Algebra of the Natural Numbers
19
2.1
A more sophisticated look at the basics
19
2.1.1
An algebraic approach
21
2.2
Mathematical induction
22
2.2.1
The theorem of induction
24
2.3
Division
27
2.3.1
The division algorithm
27
2.3.2
Odds and evens
30
2.4
Problems
34

3
Integers
37
3.1
The algebraic properties of ℕ
37
3.1.1
The algebraic deﬁnition of the integers
40
3.1.2
Simple results about integers
42
3.1.3
The relationship between ℕand ℤ
45
3.2
Problems
47
4
Rational Numbers
49
4.1
The algebra
49
4.1.1
Surveying the algebraic properties of ℤ
49
4.1.2
Deﬁning an ordered ﬁeld
50
4.1.3
Properties of ordered ﬁelds
51
4.2
Fractions versus rational numbers
53
4.2.1
In some ways they are diﬀerent
53
4.2.2
In some ways they are the same
56
4.3
The rational numbers
58
4.3.1
Operations are well deﬁned
58
4.3.2
ℚis an ordered ﬁeld
63
4.4
The rational numbers are not enough
67
4.4.1
√
2 is irrational
67
4.5
Problems
70
5
Ordered Fields
73
5.1
Other ordered ﬁelds
73
5.2
Properties of ordered ﬁelds
74
5.2.1
The average theorem
74
5.2.2
Absolute values
75
5.2.3
Picturing number systems
78
5.3
Problems
79
6
The Real Numbers
81
6.1
Completeness
81
6.1.1
Greatest lower bounds
81
6.1.2
So what is complete?
82
6.1.3
An alternate version of completeness
84
6.2
Gaps and caps
86
6.2.1
The Archimedean principle
86
6.2.2
The density theorem
87
6.3
Problems
90
6.4
Appendix
93

Part II
Logic, Sets, and Other Basics
97
7
Logic
99
7.1
Propositional logic
99
7.1.1
Logical statements
99
7.1.2
Logical connectives
100
7.1.3
Logical equivalence
104
7.2
Implication
105
7.3
Quantiﬁers
107
7.3.1
Speciﬁcation
108
7.3.2
Existence
108
7.3.3
Universal
109
7.3.4
Multiple quantiﬁers
110
7.4
An application to mathematical deﬁnitions
111
7.5
Logic versus English
114
7.6
Problems
116
7.7
Epilogue
118
8
Advice for Constructing Proofs
121
8.1
The structure of a proof
121
8.1.1
Syllogisms
121
8.1.2
The outline of a proof
123
8.2
Methods of proof
127
8.2.1
Direct methods
127
8.2.1.1
Understand how to start
127
8.2.1.2
Parsing logical statements
129
8.2.1.3
Mathematical statements to be proved
131
8.2.1.4
Mathematical statements that are assumed to be true
135
8.2.1.5
What do we know and what do we want?
138
8.2.1.6
Construction of a direct proof
138
8.2.1.7
Compound hypothesis and conclusions
139
8.2.2
Alternate methods of proof
139
8.2.2.1
Contrapositive
139
8.2.2.2
Contradiction
142
8.3
An example of a complicated proof
145
8.4
Problems
149
9
Sets
151
9.1
Deﬁning sets
151
9.2
Starting deﬁnitions
153
9.3
Set operations
154

9.3.1
Families of sets
157
9.4
Special sets
160
9.4.1
The empty set
160
9.4.2
Intervals
162
9.5
Problems
168
9.6
Epilogue
171
10
Relations
175
10.1
Ordered pairs
175
10.1.1
Relations between and on sets
176
10.2
A total order on a set
179
10.2.1
Deﬁnition
179
10.2.2
Deﬁnitions that use a total order
179
10.3
Equivalence relations
182
10.3.1
Deﬁnitions
182
10.3.2
Equivalence classes
184
10.3.3
Equivalence partitions
185
10.3.3.1 Well deﬁned
187
10.4
Problems
188
11
Functions
193
11.1
Deﬁnitions
193
11.1.1
Preliminary ideas
193
11.1.2
The technical deﬁnition
194
11.1.2.1 A word about notation
197
11.2
Visualizing functions
202
11.2.1
Graphs in ℝ2
202
11.2.2
Tables and arrow graphs
202
11.2.3
Generic functions
203
11.3
Composition
204
11.3.1
Deﬁnitions and basic results
204
11.4
Inverses
206
11.5
Problems
210
12
Images and preimages
215
12.1
Functions acting on sets
215
12.1.1
Deﬁnition of image
215
12.1.2
Examples
217
12.1.3
Deﬁnition of preimage
218
12.1.4
Examples
220
12.2
Theorems about images and preimages
222
12.2.1
Basics
222

12.2.2
Unions and intersections
228
12.3
Problems
231
13
Final Basic Notions
235
13.1
Binary operations
235
13.2
Finite and inﬁnite sets
236
13.2.1
Objectives of this discussion
236
13.2.2
Why the fuss?
237
13.2.3
Finite sets
239
13.2.4
Intuitive properties of inﬁnite sets
240
13.2.5
Counting ﬁnite sets
241
13.2.6
Finite sets in a set with a total order
243
13.3
Summary
246
13.4
Problems
246
13.5
Appendix
248
13.6
Epilogue
257
Part III
A Second Pass at Deﬁning ℝ
261
14
ℕ, ℤ, and ℚ
263
14.0.1
Basic properties of the natural numbers
263
14.0.2
Theorems about the natural numbers
266
14.1
The integers
267
14.1.1
An algebraic deﬁnition
267
14.1.2
Results about the integers
268
14.1.3
The relationship between natural numbers
and integers
270
14.2
The rational numbers
272
14.3
Problems
279
15
Ordered Fields and the Real Numbers
281
15.1
Ordered ﬁelds
281
15.2
The real numbers
284
15.3
Problems
289
15.4
Epilogue
290
15.4.1
Constructing the real numbers
290
16
Topology
293
16.1
Introduction
293
16.1.1
Preliminaries
293
16.1.2
Neighborhoods
295
16.1.3
Interior, exterior, and boundary
298

16.1.4
Isolated points and accumulation points
300
16.1.5
The closure
303
16.2
Examples
305
16.3
Open and closed sets
311
16.3.1
Deﬁnitions
311
16.3.2
Examples
315
16.4
Problems
316
17
Theorems in Topology
319
17.1
Summary of basic topology
319
17.2
New results
321
17.2.1
Unions and intersections
321
17.2.2
Open intervals are open
325
17.2.3
Open subsets are in the interior
327
17.2.4
Topology and completeness
328
17.3
Accumulation points
329
17.3.1
Accumulation points are aptly named
329
17.3.2
For all A ⊆ℝ, A′ is closed
333
17.4
Problems
341
18
Compact Sets
345
18.1
Closed and bounded sets
345
18.1.1
Maximums and minimums
345
18.2
Closed intervals are special
354
18.3
Problems
356
19
Continuous Functions
359
19.1
First semester calculus
359
19.1.1
An intuitive idea of a continuous function
359
19.1.2
The calculus deﬁnition of continuity
360
19.1.3
The oﬃcial mathematical deﬁnition of continuity
363
19.1.4
Examples
364
19.2
Theorems about continuity
374
19.2.1
Three speciﬁc functions
374
19.2.2
Multiplying a continuous function by a constant
377
19.2.3
Adding continuous functions
378
19.2.4
Multiplying continuous functions
379
19.2.5
Polynomial functions
382
19.2.6
Composition of continuous functions
382
19.2.7
Dividing continuous functions
384
19.2.8
Gluing functions together
385
19.3
Problems
386

20
Continuity and Topology
389
20.1
Preliminaries
389
20.1.1
Continuous images mess up topology
389
20.2
The topological deﬁnitions of continuity
391
20.3
Compact images
397
20.3.1
The main theorem
397
20.3.2
The extreme value theorem
400
20.3.3
The intermediate value theorem
401
20.4
Problems
404
21
A Few Final Observations
407
21.1
Inverses of continuous functions
407
21.1.1
A strange example
408
21.1.2
The theorem about inverses of continuous functions
409
21.2
The intermediate value theorem and continuity
412
21.3
Continuity at discrete points
413
21.4
Conclusion
413
Index
415

List of Figures
Figure 11.1 y = 1
x
199
Figure 11.2 y = 1
x for x > 0
201
Figure 11.3 An arrow graph
203
Figure 11.4 A generic function
203
Figure 12.1 The image of S is f (S)
216
Figure 12.2 f (x) = x2
218
Figure 12.3 f −1(T) is the preimage of T
219
Figure 12.4 f (x) = x2
221
Figure 13.1 j(x) =
x
√
x2+1
240
Figure 16.1 x = 1
n
295
Figure 16.2 x = 1
n
307
Figure 17.1 An open interval
326
Figure 17.2 x = 1
n
334
Figure 19.1 A discontinuity
360
Figure 19.2 A second type of discontinuity
361
Figure 19.3 A third type of discontinuity
361
Figure 19.4 A fourth type of discontinuity
361
Figure 19.5 Composition of continuous functions
383
Figure 20.1 f (x) = x3 −x
390
Figure 20.2 f (x) = 1
x
390
Figure 20.3 f maps S to f (S)
398
Figure 20.4 The sets i for i ∈cover f (S)
398
Figure 20.5 We claim the sets f −1(i) for i ∈cover S
399
Figure 21.1 f (x) = Sin(x−1)
412

Preface
Many mathematics departments in universities in the United States now oﬀer
courses intended to introduce students to mathematical proof and transition
students to the study of advanced Mathematics. Such courses typically focus on
proof techniques, mathematical content foundational to the study of advanced
Mathematics, and some explicit attention to the conventions and best practices
of mathematical writing.
Across such courses, there seems to be general agreement about the
important proof techniques students should learn, and similarly, there is
little substantial disagreement regarding the principles of good mathematical
writing. However, these transition courses do vary widely in regard to the
mathematical content taught. Some courses focus almost entirely on proof
techniques and introduce almost no new mathematical content. Some focus
ﬁrst on elementary logic and set theory and then move on to other content,
such as discrete mathematics, geometry, or analysis.
As hinted by the title, this book is intended to be an introduction to proof
through analysis. It is a development of notes Daniel Madden has created over
many years of teaching the proofs course at the University of Arizona, and the
approach taken in this text is diﬀerent in a number of ways.
First, although this is not an analysis book, the content is heavily focused
on analysis. And second, foundational material such as logic, sets, relations,
functions are not explicitly studied until the middle of the book, after we have
had a go at developing the real numbers. We have found that this approach,
while challenging, rewards the eﬀort. Students come away with a solid under-
standing of mathematical proof techniques and ample experience using those
techniques in a robust mathematical context. In addition, students leave the
course very well prepared for their advanced mathematics courses and with
particularly strong readiness for analysis.
This study has three parts. First, there is a careful review of the basic ideas of
numbers, not entirely rigorous, but distinctly careful. This ﬁrst part will cover
select results about natural numbers, integers, rational numbers. We will look
at the things we learned in grade school very carefully. Our goal is to reset the

stage so that we can examine all our basic notions about numbers. This will end
in a deﬁnition of the real numbers based on “the completeness axiom.” This is
the key to truly understanding the real numbers as most people know them,
decimals. As we learn more mathematical analysis in this study and any that
follow, we will learn how to correctly understand and apply all sorts of inﬁnite
processes that describe real numbers.
In the second part, we will shore up our intuitive understanding of logic and
set theory by formalizing both subjects. We will go over basic logic and simple
set theory. Here we begin the mathematical practice of giving precise deﬁni-
tions for even the simplest of mathematical terms. This is not surprising at all,
but it is abstract. We will talk about true and false statements without regard
to what those statements are. We will see how to interpret (parse) a compli-
cated sentence to extract its logical meaning. We will use logic to redeﬁne our
terminology for numbers so that it can be used in more general mathematical
context. We will take the ideas about the various systems of numbers in part
1 to set up a mathematical language that can be used for other mathematical
systems. None of this is diﬃcult, but it will be a challenge to keep up with a
large number of abstract (but very familiar) deﬁnitions.
The third part begins with a repeat of most of part 1. With the terminol-
ogy and logic of part 2, many things that seemed diﬃcult or unnecessarily long
in the ﬁrst pass at numbers will be much clearer. The second pass will go by
quicker, but it should go much easier. A lot of results and proofs will be repeated
almost as new. By this time, the basic structure of all proofs will be much more
familiar and setup time greatly reduced. The ideas behind a proof will be much
more apparent now that the logic and structure of the exposition are more
familiar. Finally, in this third part, the new Mathematics begins with the intro-
duction of topology on the real line. The mathematical goal of the course is to
prove that the real numbers are all that is needed to measure all distances. This
goal is achieved with a proof of “the intermediate value theorem.” The educa-
tional goal of the course, however, is to learn how to use logic to understand,
explain, and prove Mathematics in a careful and rigorous manner.

xvii
Introduction
Why proof?
For most people, Mathematics is about using mathematical facts to solve
practical problems. Users of Mathematics are rarely concerned about why the
methods work and care only that they do work. To too many people, Math-
ematics is a collection of arcane techniques known only to a select few with
“math brains.” It is troublesome when those arcane techniques that confuse
people are diﬀerentiation, integration, or matrix manipulation. It is downright
frightening when the confusing problems are adding fractions or computing
a restaurant tip. The worst way to view Mathematics is as a long collection of
hard-to-remember techniques for solving speciﬁc problems. A much better
way is to think of Mathematics as an organization of basic ideas that can solve all
sorts of problems as needed. When you understand what Mathematics actually
means, you can use that understanding to produce your own problem-solving
techniques. The key to understanding any piece of Mathematics (or anything
else for that matter) is to understand why it works the way it does.
Since the ancient Greeks ﬁrst studied Mathematics in a careful way, the
subject has been built on deductive proof. Mathematical results are accepted
as facts only after they have been logically proved from a few basic facts. Once
mathematical facts are established, they can be used to solve practical and
theoretical mathematical problems. Mathematicians have two reasons for
proving a mathematical statement rigorously: ﬁrst, to be sure that the result is
true, and second, to understand when and how it works.
Following the ancient Greek process, mathematicians want a proof for
everything - whether it is on the cutting edge of mathematics and science or
it is an apparently obvious fact about grade school arithmetic. The idea is to
understand why a mathematical result is true and to move on to what you
know because it is true. Most of the Mathematics we see in school is about
the “moving on” variety. Once school children understand the connection

xviii
Introduction
between combining small groups of objects and adding numbers, they can
move on to the arithmetic algorithm of adding larger numbers. Thus,
278
+
394
672
is just the theoretical way to combining 278 objects and 394 objects and
counting the combination. Once school children understand the connection
between groups of groups and multiplication, they can learn the algorithm for
multiplication. Then
2
5
7
×
3
5
1
2
8
5
7
7
1
8
9
9
5
is just the theoretical way of counting 35 rows of 257 objects.
At the very beginning, every child is given some simple justiﬁcations for
the validity of these algorithms. The strong belief among math educators and
education researchers is that students who understand those justiﬁcations best
are the students that will learn the algorithms best. Granted in the long run,
it is a child’s ability with the algorithm that is considered most important. In
time, greater facility with the algorithms supplants a person’s need for the logic
behind those algorithms. But the complete understanding of the operation
behind the algorithm is always essential for its proper use in odd situations.
There is a popular notion that the logic behind the techniques of Mathemat-
ics can be ignored once the procedures of Mathematics are learned. This notion
seems to work well for the basic arithmetic of whole numbers. There is a lot
of evidence, however, that this is why so many people stumble over problems
involving fractions. Too many people “move on” to memorizing the algorithms
of fractional arithmetic before they understand the meaning of that arithmetic
or why the things they are memorizing work. It is hard to memorize anything
and harder still to hold that memory without knowing the context of what you
are learning. “To add fractions, ﬁnd a common denominator.” “To divide frac-
tions, invert and multiply.” Everyone knows this, but how many can correctly
add 3 3
4 to 5 7
8 or divide 21 by 2
3?
As perplexing as fractions are to the general population, decimal numbers are
even worse. Thanks to calculators, everyone knows 𝜋= 3.14159 … where the
dots tell us a better calculator would give more digits. Everyone also seems to
know that 1
3 = 0.33333 …where here the dots mean that the 3s go on forever, or
at least they would if it were actually possible for written digits to go on forever.
Most people understand decimal numbers well enough that they can move on

Introduction
xix
to using them very well and very eﬀectively without error. But even the most
highly trained person can be tripped up by an unexpected decimal question
that involves inﬁnitely many decimals. In the next section, we consider some
surprisingly confusing questions about simple numbers.
Before we get to these confusing examples, let us set up a plan for curing any
resulting mathematical confusion. Early school mathematical training generally
concentrates on the problem-solving problems using Mathematics. Some the-
oretical or intuitive explanations of the ideas and techniques are given, but the
level of logical rigor in these justiﬁcations varies greatly depending on the topic
under discussion. If we are interested in a more advanced education in Math-
ematics, we must revisit these past justiﬁcations of the mathematical ideas we
now hold so dear. The time must come when we understand and appreciate a
rigorous justiﬁcation of every mathematical result we will use. This turns out
to be a rather diﬃcult step to make. We will work on it in stages.
Why analysis?
Our main objective in this study is to develop a precise description of the real
numbers for use as a foundation for the ideas and methods of calculus. There are
two ingredients in this development: algebra and analysis. “Algebra” generally
refers to the arithmetic of the numbers: addition, subtraction, multiplication,
and division. The ways in which these operations interact form the “algebraic
structure” of the number systems that we will consider. “Analysis” refers to the
study of the distinctions between exact numbers and their approximations. It is
simply a fact that certain real numbers cannot be expressed exactly using only
ﬁnitely many whole numbers. Analysis allows us to say precise things about real
numbers that cannot be precisely described with a ﬁnite expression.
Problems in analysis typically occur when we use numbers to measure things.
Given an isosceles right triangle, two squares drawn with sides the length of
the short sides of the triangle will have a combined area equal to a square
with a side whose length is the same as the hypotenuse. If we measure the
sides as n units, the hypotenuse will measure n
√
2 units. Thus, to measure the
hypotenuse, there must be a number we write as
√
2, which when multiplied by
itself is 2. A good calculator will approximate
√
2 as 1.41421. A better calculator
will approximate it as 1.41421356237, and a sensational one as
1.4142135623730950488016887242096980785696718753769.
But, as the Greeks discovered, the only way to write an exact representation of
the number is by saying that it is a number that when squared is 2 and then to
make up a symbol for it, such as
√
2.
Since our goal is to develop a rigorous description of the real numbers, we
must be able to use it to work with numbers we can describe exactly but cannot

xx
Introduction
calculate exactly. We will use algebra and analysis to allow us to do arithmetic
with numbers such as this. Suppose, for example, that we need a number x so
that x3 + x = 7. Once we are sure that it exists, we can assign it a symbol. For
now, let us say ♮. As it turns out, ♮is like
√
2. We can approximate it as accurately
as we like, but it may be that the only way to write it exactly is ♮. We can use
algebra to do some exact calculations with ♮. For example, ♮4 = 7♮−♮2, but it
is a matter of opinion whether 7♮−♮2 is a better name for ♮4 or if it is the other
way around.
For a more famous example, suppose that we need a number that is the ratio
between the circumference of a circle and the diameter of the circle. First, we
need to know that it exists, but we can thank the ancient Greeks for that. We
can assign it a symbol 𝜋. We can approximate it as accurately as we like, but
the only way to write it exactly is 𝜋. The situation is even worse than
√
2 or
♮; mathematicians have proved that there is no polynomial P(x) of any degree
with rational coeﬃcients so that P(𝜋) = 0. This means that the only possible
way to write 𝜋4 exactly is 𝜋4.
The way most people know 𝜋is “3.14159 . . . . where the digits continue
forever without a pattern.” So the question is, “Does anyone know 𝜋exactly?”
If there is no pattern to the digits and they go on forever, then no one can know
them all. These digits may look random after a while, but because we believe 𝜋
is a real number, we believe that all the digits are exactly described even if they
may never be all known. Most educated people have a working knowledge of
the real numbers, but mostly because they have a reasonable understanding of
decimal approximation. Thus, they are not bothered by questions about exact
values of 𝜋.
On the other hand, consider 2𝜋. With a calculator, almost anyone can ﬁnd
that 2𝜋= 8.8249778, and many will guess that this is simply an approximation
of the exact value. But scratch the surface of this general understanding of real
numbers and you discover a problem: what have we approximated? That is,
“What is the meaning of 2𝜋?” Now 2
22
7 =
7√
222, but 𝜋is not a rational fraction.
So this is of little help describing what the number 2𝜋means. The only reason
most people have to believe that it has a meaning at all is that their calculator
will calculate it.
Next consider a problem with inﬁnite decimal arithmetic that most
people
avoid
by
using
approximations.
Consider
the
numbers:
𝛼=
0.91260 91260 91260 … and 0.142857 142857 142857 …, where the ellip-
sis (…) means that the pattern of digits repeats forever. Now if we believe
that we can make 𝜋a number by saying “𝜋is 3.14159 . . . . where the digits
continue forever without a pattern,” then knowing all the digits of 𝛼and 𝛽
should make them even better known numbers. The question is, can we ﬁnd

Introduction
xxi
an exact decimal expression for 𝛼−𝛽? Does it even have one? If we line them
up to subtract using the familiar algorithm, it is hard to know where to start
working on the digits. If we know enough about real and rational numbers,
we may know a better approach that tells us that the answer will have its
own repeating decimal form. But ﬁnding that exact answer means having the
patience to calculate and recognize the 30 digit repeating pattern it turns out
to have.
The ﬁnal example has been known to be good bait used by trolls on math-
ematical discussion boards since the invention of the internet. Consider two
other numbers 𝛼= 0.5 and 𝛽= 0.499999 …. The question is, “Is one of these
numbers greater than the other, and if so which?” Now as we know, the number
𝛼has a better name. The decimal point in 0.5 is mathematical notation where
the next digits give the number of parts where the previous unit is divided into
10 equal parts. Thus, 𝛼=
5
10 = 1
2. Comparing the ﬁrst decimal digits, we know
that, 𝛼is deﬁnitely greater than or equal to 𝛽. Its ﬁrst digit is larger than the
ﬁrst digit of 𝛽, and some might say that that makes it greater. But it really only
tells us that 𝛼≥𝛽. We might try to subtract to see if the diﬀerence is 0. If we
line them up
0.50000000000000 …
0.49999999999999 …
we run into the same problem we just saw; where to start? The fact that most
of the digits in 𝛽are greater than the ones in 𝛼above them forces us to guess
how that arithmetic will go. Still, we can certainly see that the result will start:
0.00000. We can guess that it will never give a digit other than 0 until it ends
and that it will, in fact, never end. The result of the subtraction will be a decimal
with inﬁnitely many 0 digits. That must be 0, right? In the end, we can only use
the ﬁnite versions of subtraction to approximate the inﬁnite arithmetic. If we
are lucky, we can identify a pattern and guess an answer. But can we be sure? It
does look like 𝛽−𝛼= 0 and so 𝛼= 𝛽, but can one real number really have two
decimal expansions?
In Mathematics, we often describe a precise number that we can only approx-
imate using decimal numbers. We then give the number a name or symbol and
work with the number by working with the name. We did this earlier by setting
𝛼= 0.5 and 𝛽= 0.499999 …. We then interpreted 𝛼= 0.5 to mean 5 divided by
10. We then argued that there was reason to suspect 𝛼= 𝛽. The most famous
case of naming numbers we do not know exactly is 𝜋, but the base of the natural
logarithms e is basically the same. From this point of view, for any positive real
number a, we use the symbol
n√
a as a name for the real solution to xn = a. In
addition, for any real number 𝜃, we use geometry to precisely describe a number

xxii
Introduction
between 0 and 1 that we call sin(𝜃). A lot of Mathematics is about ﬁnding precise
relations between the diﬀerent numbers we have named. If the real numbers
work as we expect, it should come as no surprise that 0.5 = 0.499999 …. We
should be able to prove this from basic undeniable principles. We also should
know that sin
(
𝜋
4
)
=
1
√
2, and we expect someone is able to prove it. A bit more
surprising is that ♮, the real solution of x3 + x = 7 can also be given as
♮= −3
√
2
189 +
√
35829
+
3
√
63 +
√
3981
18
.
However, mathematicians were mostly shocked when Niels Abel proved that
the real solution ♭to x5 + 10x2 = 40 cannot be given precisely in terms of nat-
ural numbers and radical signs alone.
Numbers such as 𝜋and e have no pattern in their decimal expansions. We
can, however, describe 𝜋and e using inﬁnite representations where all the terms
are known:
𝜋= 4
1 −4
3 + 4
5 −4
7 + 4
9 + …
e = 1 + 1
1! + 1
2! + 1
3! + 1
4! + …
𝜋= 2
1 ⋅2
3 ⋅4
3 ⋅4
5 ⋅6
5 ⋅6
7 ⋅· · ·
These are at least a bit better than the decimal approximations because the pat-
terns they follow do give all the terms. If we prove that these inﬁnite expressions
actually give numbers, we can claim to know them exactly. We still cannot write
them down exactly without alluding to inﬁnitely many terms. We can use our
names for them to do calculations with them using algebra. We can do approx-
imate calculations with them by keeping just the ﬁrst terms in their inﬁnite
expressions. However, knowing why the ﬁrst and last inﬁnite expressions can be
given the same name is an issue for analysis. If we can ﬁnd some argument that
the diﬀerence between 𝛾= 4
1 −4
3 + 4
5 −4
7 + 4
9 + … and 𝛿= 2
1 ⋅2
3 ⋅4
3 ⋅4
5 ⋅6
5 ⋅
6
7 ⋅· · · is zero, we can at least say 𝛾= 𝛿. But why either of these make
sin
(
𝜋
4
)
=
1
√
2 true requires analysis.
Our goal is to develop a precise description of the real numbers that allows us
to deal with real numbers we can describe precisely but not write out precisely
with ﬁnite terms. We will generally use analysis to determine when we have
actually described one and only one real number, that is, to determine when a
number exists and is unique. This will allow us to give it a name. We will then
typically use algebra to use the name to study that number or other numbers
we might be interested in.

Introduction
xxiii
We start by reviewing the most basic aspects of numbers. These are things
that we may not have looked at closely since we learned about then in preschool,
kindergarten, or elementary school. The object is to practice being very careful
and precise with the most familiar of all Mathematics. But this time, we have
algebra to help. As we have seen, some things about numbers can be confusing.
We can learn to work past any confusion by starting with an extra careful look
at things we know very well.

1
Part I
A First Pass at Deﬁning ℝ

3
1
Beginnings
1.1
A naive approach to the natural numbers
1.1.1
Preschool: foundations of the natural numbers
One of the ﬁrst things we learn in mathematics is the counting chant: one,
two, three, four, ﬁve . . . . We quickly learn how to count to higher and higher
numbers, and ﬁnally, the day comes when we realize that we can continue on
counting forever. At that point, believe it or not, we have all the necessary
assumptions we need to discover all of mathematics. The counting numbers
are often called whole numbers, but mathematicians call them natural numbers.
We can express our childhood discovery in four adult principles:
• There is a unique ﬁrst natural number.
• Every natural number has a unique immediate successor.
• Every natural number except the ﬁrst has a unique immediate predecessor.
• Every natural number is an eventual successor of the ﬁrst.
Algebra begins when we introduce symbols to express these principles. Now
there is a unique ﬁrst natural number; we will write it as 1. Every natural num-
ber has a unique immediate successor. There are many choices for denoting the
successor of a natural number. In a more rigorous course on the foundations of
mathematics, we might write the successor of a natural number n as s(n). We
will choose a notation that anticipates later deﬁnitions. The successor of a natu-
ral number n will be written as n + 1. Notice that this is not addition (yet); n + 1
means “the successor of n,” no more and no less. Every natural number except
the ﬁrst has a unique immediate predecessor. Again, we choose a notation with
an eye on what is coming later. If n ≠1, the predecessor of a natural number
n will be written as n −1. This is not subtraction; it is simply the symbol for
the predecessor. The relationship between successors and predecessors can be
described using this notation. Notice that 1 −1 is not deﬁned because the ﬁrst
number does not have a predecessor.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

4
1 Beginnings
Remark. If n is a natural number, then (n + 1) −1 = n.
Remark. If n is a natural number and n ≠1, then (n −1) + 1 = n.
These are our ﬁrst algebraic results. Note that they are nothing more than
symbolic representations of the meanings of the words “successor” and “pre-
decessor.” Thus, (n + 1) −1 = n is just a symbolic statement that means “the
predecessor of the successor of a natural number n is just the number n.” Thus,
(n −1) + 1 = n means “the successor of the predecessor of a natural number
n other than the ﬁrst number 1 is just the number n.” That is all algebra really
is: the encoding of ideas expressed in words into symbolic representations of
those ideas.
The fourth principle is the hardest to precisely express in symbols. However,
in this ﬁrst chapter, we are just setting some groundwork to make later logi-
cally rigorous mathematics easier. We are willing to forgo some rigor to lay this
groundwork. To say this more clearly, we are not going to restrict ourselves to
completely logical proofs and deﬁnitions until the end of this chapter.
The fourth principle states: Every natural number is an eventual successor of
the ﬁrst. That is, every natural number is the successor of the successor of the
successor of … the successor of 1. The loose notation for this is: if n is a natural
number, then n can be written as
n = (((… ((1 + 1) + 1) + … + 1) + 1) + 1.
(1.1)
The use of the ellipsis in this bit of algebra kills any hope of making an unam-
biguous statement. It should be clear what this means: n is made up of a series
of (+1)s, each of which signals the successor of a previous number. This is not
the best way to begin a course in rigorous mathematics, and soon we will need
to replace it with something else.
There is one more bit of notation we set for dealing with these basic princi-
ples. We say m is an eventual successor of n if
m = (((… ((n + 1) + 1) + … + 1) + 1) + 1.
(1.2)
Again, the use of ellipsis kills any rigor this idea might have. When m is an even-
tual successor of n, we say “m is greater than n”; and we write m > n. Actually,
we might prefer to move smaller to larger and write n < m and say “n is less than
m.” This leads to some algebra, and a careful name for an important algebraic
property:
Remark. Let k, m and n be natural numbers. If n < m and m < k, then n < k.
We can refer to this remark by saying, “The order of the natural numbers is
transitive.”

1.1 A Naive Approach to the Natural Numbers
5
This remark is true because n < m means
m = (((… ((n + 1) + 1) + … + 1) + 1) + 1,
(1.3)
and m < k means
k = (((… ((m + 1) + 1) + … + 1) + 1) + 1.
(1.4)
Equality means that m is exactly the same as the expression that follows
the equal sign. So we can “substitute” that expression for the m in the later
equation.
k = (((… ((… (n + 1) … + 1) + … + 1) + 1) + 1.
(1.5)
So, indeed, k is an eventual successor of n.
Finally, suppose that we have natural numbers n and m. Since we have not said
otherwise, they could be the same. Thus, it might be that n = m. Both numbers
are eventual successors of 1. If n ≠m, one of the two must be an eventual suc-
cessor of 1 that appears before the ﬁrst. Thus, either n < m or m < n. This leads
to our ﬁnal observation about the order of the natural numbers and another
mathematical term.
Remark. If n and m are natural numbers, then exactly one of the following must
be true: n < m; m < n; or n = m.
We refer to this remark by saying, “The order on the natural numbers has
trichotomy.”
Thus, if n < m is not true, then either m < n or n = m. We have notation that
allows us to abbreviate this further. We write n ≤m to mean either n < m or
n = m. Similarly, we write n ≥m to mean either n > m or n = m. There is no
notational shortcut for saying either n > m or n < m other than n ≠m.
1.1.2
Kindergarten: addition and subtraction
The ﬁrst use we learn for numbers is for counting things. We learn names and
symbols for all the eventual successors of 1.
1 + 1 = 2.
(1.6)
(1 + 1) + 1 = 3.
((1 + 1) + 1) + 1 = 4.
(((1 + 1) + 1) + 1) + 1 = 5.
· · · · · · = · · ·
In the early grades, we add the two numbers 2 and 5 by creating two sets (say,
of marbles), one with 2 marbles and another set with 5 marbles. We combine

6
1 Beginnings
the two sets into one and count to ﬁnd a total of 7 marbles. We learn that the
notation for this is 2 + 5 = 7.
2 = 1 + 1;
(1.7)
5 = (((1 + 1) + 1) + 1) + 1;
2 + 5 = (1 + 1) + ((((1 + 1) + 1) + 1) + 1)
= ((((((1 + 1) + 1) + 1) + 1) + 1) + 1)
= 7.
While a main goal in elementary school arithmetic is learning the algorithm for
adding natural numbers, this would be pointless without a few years of counting
and combining so that we know what the addition algorithm does for us. This
algorithm is a theoretical method that allows us to avoid long counts. We even-
tually learn how to ﬁnd that 27 + 35 = 62 without knowing what objects we
are trying to count. The concrete problem of counting combined sets becomes
the abstract problem of adding numbers. We learn what addition is mostly by
repeated counting. Later, we learn a shortcut that uses an arithmetic procedure.
But addition has never been taught by someone deﬁning it for us, until now.
As adults we need to invent (or deﬁne) an operation on natural numbers
where two natural numbers n and m are combined to produce a new natural
number. We denote this new number as n + m. We deﬁne this new number by
writing n and m as eventual successors of 1:
n = (((… ((1 + 1) + 1) + … + 1) + 1) + 1;
(1.8)
m = (((… ((𝟏+ 𝟏) + 𝟏) + … + 𝟏) + 𝟏.
Then
n + m = [(((… ((1 + 1) + 1) + … + 1) + 1) + 1]
(1.9)
+ [(((… ((𝟏+ 𝟏) + 𝟏) + … + 𝟏) + 𝟏]
= (((… ((1 + 1) + 1) + … + 1) + 1) + 1)
+ · · · + 𝟏) + 𝟏) + 𝟏) + … 𝟏) + 𝟏.
The imprecision of the ellipsis almost renders this deﬁnition useless, but the
bold 1s help a bit. In a course on the rigorous foundations of mathematics,
we would need to do much better than this. Luckily, years of combining sets
of marbles allows us to realize what we are trying to say in this study with
the aforementioned deﬁnition. This almost unintelligible deﬁnition does lead
to one very important algebraic fact. It is clear that the deﬁnition of addition
is just the rearrangement of the parenthesis around 1s and +s. Thus, we have
an algebraic fact about the addition of counting numbers: parentheses do not
matter.
Remark. If k, m, and n are natural numbers, then (k + n) + m = k + (n + m).

1.1 A Naive Approach to the Natural Numbers
7
We refer to this by saying, “Addition of natural numbers is associative.”
A few other algebraic facts follow just as quickly.
Remark. If m and n are natural numbers, then n < n + m.
We refer to this by paraphrasing Euclid, “The whole is greater than the part.”
Remark. If k, m, and n are natural numbers and n < m, then n + k < m + k.
We refer to this by saying, “Addition of natural numbers respects the order.”
If we remember our lessons from counting blocks, we realize that it doesn’t
make a diﬀerence which set of blocks we start with when we combine the two
sets – the total always comes out the same. We can turn this observation into
another useful algebraic fact.
Remark. If m and n are natural numbers, then m + n = n + m.
We refer to this by saying, “Addition of natural numbers is commutative.”
The ﬁrst step after learning the arithmetic operation of addition is the intro-
duction of a new operation, subtraction. At ﬁrst we learned it as the solution
to an addition puzzle, such as “What number added to 5 gives 7?” We all recall
the problem: Fill in the box
5 + [ ] = 7.
(1.10)
Only later, after we understood this type of question better, did we learn a
procedure for subtracting. Soon we learned that there were two arithmetic
operations: addition and subtraction. As mathematicians, we will not talk about
subtraction as its own operation, but rather look at it in terms of addition. It is
not that there is anything wrong with thinking of subtraction as its own oper-
ation, but just that it will help later algebraic ideas to try to keep the language
focused on addition. Subtraction will still be a possibility, but we will not fully
admit it, but rather refer to the following property of the natural numbers:
Remark. If n and m are natural numbers with n < m, then there exists a unique
natural number k so that m = n + k.
We refer to this by saying, “There is a conditional subtraction on the natural
numbers.”
We say that this subtraction is conditional because we cannot subtract the
natural number n from m unless n < m (and get a natural number as a result).
Of course, one of our ﬁrst orders of business will be to create the integers as
a larger collection of numbers that removes this condition on subtraction. As
for notation, it is no surprise that we will eventually write k as m −n. Thus,

8
1 Beginnings
the sign “−” for subtraction is still there. For at least a while, we will not take
advantage of this notation because we are trying to avoid treating subtraction
as an operation. The reason for this should be clearer when we start to discuss
the integers where things work better algebraically.
There are two other “subtraction” properties that we will use frequently.
Remark. If k, n, and m are natural numbers with n + k = m + k, then n = m.
Remark. If k, n, and m are natural numbers with n + k < m + k, then n < m.
Rather than talking about these in terms of subtraction, we will refer to these
as “cancellation properties of addition.”
1.1.3
Grade school: multiplication and division
Once we know that we can add any two natural numbers, we can use that
to invent a new operation, multiplication. Two natural numbers n and m are
combined to produce a new natural number. We denote this new number as
n ⋅m or nm. We deﬁne this new number by writing n as eventual successor
of 1:
n = (((… ((1 + 1) + 1) + … + 1) + 1) + 1.
(1.11)
Then
n ⋅m = (((… ((m + m) + m) + … + m) + m) + m.
(1.12)
Again, because of the ellipsis, the only reason this might be considered a deﬁ-
nition is because we already know what it means: to ﬁnd n ⋅m add m to itself n
times. For example,
3 × 7 = (7 + 7) + 7.
(1.13)
As we move on to a discussion of the properties of multiplication, we lose any
pretense of rigor. We need to refer to geometric intuition to justify our obser-
vations. Luckily, we spent endless hours playing with various objects in the
elementary grades, developing this intuition just to understand the multipli-
cation properties. A geometric representation of n⋅m is the number of objects
arranged in a rectangle n blocks wide and m blocks long. A geometric repre-
sentation of (n ⋅m) ⋅k is the number of objects arranged in k rectangles each
n blocks wide and m blocks long and stacked into a 3-D box. If we turn an n
by m rectangle on its side, it turns into a rectangle that is m objects wide and n
objects long. So we have our ﬁrst algebraic property of multiplication.
Remark. If m and n are natural numbers, then m ⋅n = n ⋅m.
We refer to this by saying, “Multiplication of natural numbers is
commutative.”

1.1 A Naive Approach to the Natural Numbers
9
If we pile k of these rectangles one on top of each other, we get a box n blocks
wide, m blocks long, and k blocks high. The number of blocks in the box is
k ⋅(n ⋅m). But if we stack m walls of rectangles that are m blocks long and k
blocks high, we get the same box. The number of blocks in the box is m ⋅(n ⋅k).
But by commutativity of multiplication, we can say
Remark. If k, m and n are natural numbers, then (k ⋅n) ⋅m = k ⋅(n ⋅m).
We refer to this by saying, “Multiplication of natural numbers is associative.”
The next observation follows directly from the deﬁnition of multiplication.
Remark. If n is a natural number, then n ⋅1 = 1 ⋅n = n.
We refer to this by saying, “1 is a multiplicative identity.”
If n < m, then m is an eventual successor of n, and we can write
m = (((… ((n + 1) + 1) + … + 1) + 1) + 1
(1.14)
= (… (.(𝟏+ 𝟏) + ...𝟏) + … + 1) + 1) + 1.
So
m ⋅k = (… (.(k + k) + ...k) + … + k) + k) + k
(1.15)
= (… (kn + k) … + k) + k) + k.
So we know k ⋅n < k ⋅m. Thus,
Remark. If k, m, and n are natural numbers and n < m, then n ⋅k < m ⋅k.
We refer to this by saying, “Multiplication of natural numbers respects the
order.”
Notice that we have deﬁned three things for the natural numbers: an order
<, and two operations: addition + and multiplication ⋅. We know how addition
interacts with the order. Addition respects the order. We know how multipli-
cation interacts with the order; multiplication respects the order. Next, we see
how multiplication interacts with addition. We leave a geometric justiﬁcation
of this as an exercise.
Remark. If k, m, and n are natural numbers, then k ⋅(n + m) = k ⋅n + k ⋅m.
We refer to this by saying, “Multiplication of natural numbers distributes over
addition.”
If we were reluctant to talk about subtraction of natural numbers simply
because to subtract n from m we must know n < m, we are deﬁnitely going to
wait before we discuss division of natural numbers. Division of natural numbers

10
1 Beginnings
is a much more complicated procedure involving remainders as well as quo-
tients. We will get to it, but not just now.
Still we would like some division-like algebraic results to make things easier.
We have two painfully obvious observations:
Remark. If k, n, and m are natural numbers with n ⋅k = m ⋅k, then n = m.
Remark. If k, n, and m are natural numbers with n ⋅k < m ⋅k, then n < m.
We refer to either of these as “cancellation properties of multiplication.” Be
warned, however, these are very dangerous. We are basically going to ﬁnd safer
replacements for them as soon as we can.
These are “painfully” obvious because while they are quite obvious after
years of practicing arithmetic, the justiﬁcations that they are correct are rather
painful to follow. There are a few ingredients in this justiﬁcation: trichotomy,
the results of multiplication are unique, multiplication respects order, and
logical reasoning. Let us give a justiﬁcation a try.
We know that the results of multiplication are unique; however we multiply
two numbers m and k, the result will always be the same. Thus, we can state this
algebraically as: if n = m, then for all natural numbers k, we have n ⋅k = m ⋅k.
We really want to be clear about what this says.
If it is true that n = m, then it absolutely must be true that n ⋅k = m ⋅k.
(We are just being resolute about our earlier statement.) But then, if we ever see
that n ⋅k = m ⋅k is false, then there is no way that n = m could be true. This is
to say:
If n ⋅k ≠m ⋅k, then n ≠m.
Let us remember this for now.
Because multiplication respects order, we know that if k, m, and n are natural
numbers and n < m, then n ⋅k < m ⋅k. So assuming that k, m, and n are natural
numbers, if it is true that n < m, then it absolutely must be the case that n ⋅k
< m ⋅k. So as before, if we ever see that n ⋅k < m ⋅k is false, then there is no
way that n < m could be true. So
If n ⋅k < m ⋅k is not true, then n < m is not true either.
But by trichotomy, saying that n ⋅k < m ⋅k is false is the same as saying n ⋅k
≥m ⋅k. By basically the same argument, we can also say:
If m ⋅k < n ⋅k is not true, then m < n is not true either.
Now we can justify our ﬁrst statement that, if n⋅k = m⋅k, then n = m. Sup-
pose it is true that n ⋅k = m ⋅k. Then by trichotomy, both (n ⋅k < m ⋅k) and
(m ⋅k < n ⋅k) are not true. (Trichotomy says exactly one must be true.) By our

1.1 A Naive Approach to the Natural Numbers
11
two observations, we know (n < m) is not true, and (m < n) is not true. But
trichotomy leaves only one possibility. It must be that n = m. Thus, as we said
in our second remark: if k, n, and m are natural numbers with n ⋅k < m ⋅k, then
n < m.
Next, we justify our second statement that, if n ⋅k < m ⋅k, then n < m. Sup-
pose n⋅k < m⋅k. Then by trichotomy, both (n⋅k = m⋅k) and (m⋅k < n⋅k) are
not true. By the ﬁrst observation, we know that (n⋅k ≠m⋅k) implies n ≠m. The
last observation says that (m ⋅k < n ⋅k) is not true implies that (m < n) is not
true. But again, trichotomy leaves only one possibility. It must be that n < m.
It was a bit painful to follow these justiﬁcations of those simple remarks, but
we do now see that they are simply consequences of trichotomy and a unique
result from multiplication. One of our goals is to create an algebraic and logical
language that makes arguments such as this easier to understand.
There is only one last remark we need to make about the natural numbers.
Remark. Let n and m be natural numbers with n ≤m ≤n + 1, then either
n = m or m = n + 1.
We refer to this by saying, “The natural numbers are discrete.”
Again, the justiﬁcation for this depends on the statements in the earlier
remarks. Suppose n < m < n + 1. Then by subtraction (whoops), we know
that there is a natural number k so that m = n + k. But then n + k = m and
m < n + 1. So by transitivity, n + k < n + 1. But we have a cancellation rule for
addition; so k < 1. But since every natural number is an eventual successor of
1 and trichotomy holds, this cannot happen.
The purpose of algebra is to help make all these justiﬁcations easier to
manage.
1.1.4
Natural numbers: basic properties and theorems
We have just reviewed several years of elementary school arithmetic so that we
can identify and name various basic algebraic properties of the natural num-
bers. They are as follows:
• There is a ﬁrst natural number, which we call 1.
• There is an order on the natural numbers.
• The order is transitive.
• The order has trichotomy.
• For any two natural numbers n and m, there is a unique natural number
n + m.
• This addition is associative.
• This addition is commutative.
• If m and n are natural numbers, then n < n + m.
• If k, m, and n are natural numbers and n < m, then n + k < m + k.

12
1 Beginnings
• If n and m are natural numbers with n < m, then there exists a unique natural
number k so that m = n + k.
• If k, n, and m are natural numbers with n + k = m + k, then n = m.
• If k, n, and m are natural numbers with n + k < m + k, then n < m.
• For any two natural numbers n and m, there is a unique natural number n ⋅m.
• This multiplication is associative.
• This multiplication is commutative.
• The natural number 1 is a multiplicative identity.
• If k, m, and n are natural numbers and n < m, then n ⋅k < m ⋅k.
• If k, n, and m are natural numbers with n ⋅k = m ⋅k, then n = m.
• If k, n, and m are natural numbers with n ⋅k < m ⋅k, then n < m.
• If m and n are natural numbers and n ≤m ≤n + 1, then either m = n or
m = n + 1.
• Multiplication distributes over addition.
1.2
First steps in proof
There are, of course, many more true facts about the natural numbers, but they
all should follow from these basic properties. We will state many further facts
about these numbers as theorems. We will prove these theorems by using the
aforementioned basic properties. If our justiﬁcations for these properties are
accepted and are correct, then the theorems we prove by using them must be
perfectly true. Granted our justiﬁcations of these properties are a bit dicey, but
we are going to have to start being rigorous somewhere, and it will be easier
starting by assuming a list of basic properties such as those aforementioned.
Let us now use these properties to prove something.
1.2.1
A direct proof
The ﬁrst proof we will give is called a direct proof . Suppose that we wish to
prove a statement of the form “If P, then Q.” In a direct proof of this statement,
we begin by assuming P. Then we deduce Q using P and any other assumptions
we have available. Let us now prove the statement
If n is a natural number, then (n + 1)2 = n2 + 2n + 1
using a direct proof. This is of the form “If P, then Q” where P is the statement
“n is a natural number” and Q is the statement “(n + 1)2 = n2 + 2n + 1.” We will
begin the proof by assuming that n is a natural number. Knowing that, we can
use all of the basic properties of the natural numbers listed earlier. So we will
use those assumptions to deduce that (n + 1)2 = n2 + 2n + 1.
Theorem 1.2.1.
If n is a natural number, then (n + 1)2 = n2 + 2n + 1.

1.2 First Steps in Proof
13
Proof. Assume that n is a natural number. Then n + 1 is a natural number
because addition is always deﬁned. Then
(n + 1)2 = (n + 1)(n + 1),
(1.16)
because that is what the exponent means.
(n + 1)(n + 1) = (n + 1)n + (n + 1) ⋅1,
(1.17)
by the distributive property.
(n + 1)n + (n + 1) ⋅1 = (n + 1)n + (n + 1),
(1.18)
because 1 is a ⋅identity.
(n + 1)n + (n + 1) = n(n + 1) + (n + 1),
(1.19)
because ⋅is commutative.
n(n + 1) + (n + 1) = (n ⋅n + n ⋅1) + (n + 1),
(1.20)
by the distributive property.
(n ⋅n + n ⋅1) + (n + 1) = (n ⋅n + n) + (n + 1),
(1.21)
because 1 is a ⋅identity.
(n ⋅n + n) + (n + 1) = (n2 + n) + (n + 1),
(1.22)
because that is what the exponent means.
(n2 + n) + (n + 1) = n2 + (n + (n + 1)),
(1.23)
because + is associative.
n2 + (n + (n + 1)) = n2 + ((n + n) + 1),
(1.24)
because + is associative.
n2 + ((n + n) + 1) = n2 + ((n ⋅1 + n ⋅1) + 1),
(1.25)
because 1 is a ⋅identity.
n2 + ((n ⋅1 + n ⋅1) + 1) = n2 + (n(1 + 1) + 1),
(1.26)
by the distributive property.
n2 + (n(1 + 1) + 1) = n2 + (n ⋅2 + 1),
(1.27)
because that is what 2 means.
n2 + (n ⋅2 + 1) = n2 + (2n + 1),
(1.28)
because ⋅is commutative.
n2 + (2n + 1) = n2 + 2n + 1,
(1.29)
because + is associative, this is unambiguous.

14
1 Beginnings
Thus, we have
(n + 1)2 = n2 + 2n + 1.
(1.30)
◽
This is a completely algebraic proof; it is also a completely boring proof to
anyone who knows algebra. This is the stuﬀof middle school algebra and is not
the kind of proof that should give us any problems. While we should be able to
justify any step in any algebraic part of any proof we give, there is rarely a reason
to do so. In addition, we can take advantage of algebra’s disregard for the rules
of proper language composition. Notice that each step in the aforementioned
proof is a full English sentence with a subject, a verb (always “equals”), and an
object followed by a prepositional phrase. This is how a paragraph should be in
any English composition.
But in an algebraic proof, we can violate one the major rules of good writing:
no run-on sentences. The aforementioned proof is completely over the top for
mathematical adults. In any work past a high school text, it would be written
more like:
(n + 1)2 = (n + 1)(n + 1)
(1.31)
= (n + 1)n + (n + 1)
= n2 + n + n + 1
= n2 + 2n + 1.
Even this might be longer that necessary. Notice that this is a run-on English
sentence. It has one subject, (n + 1)2, several objects, and one word “equals”
used as a verb four times. This is unacceptable in an English composition, but
perfectly acceptable in an algebraic proof. We need to remember that this proof
is an abbreviation of the full proof written earlier as a composition. Each equal
sign has two subjects: the object of the previous line, and by deduction, the orig-
inal subject of the sentence. The conclusion drawn from the four intermediate
sentences is that the original subject is equal to the ﬁnal object.
In this study, we will not bother to do much more than outline an algebraic
proof such as this. This does not, however, reduce at all our need for detailed
algebraic proofs. As humans we will make algebra mistakes, and we need to
be ready to ﬁnd them before someone else does. Finding an algebraic mistake
is often nothing more than giving a complete and thorough line-by-line step
through the use of our basic properties until the error reveals itself.
1.2.2
Mathematical induction
Unfortunately, not all theorems about the natural numbers are easily proved by
a direct proof or simple algebra. Consider
For all natural numbers n, 2 ⋅(1 + 2 + 3 + … (n −1) + n) = n(n + 1).

1.2 First Steps in Proof
15
The dreaded rigor killer, ellipsis, appears again. Mathematics has notation
that allows us to write such a summation in a more precise mathematical way.
However, in this case, it is pretty clear what this claim is: if we add all the num-
bers starting at 1 and stop when we get to n and then double the result, the
answer would be the same as if we multiplied n by its successor. Unfortunately,
the only direct proof of this involves using geometric intuition. This is a per-
fectly ﬁne proof, but there is an alternate proof that uses a much more general
method with many more applications.
We will prove this claim using a “proof by mathematical induction.” Such a
proof is a two-step process. Both steps must be completed successfully for the
proof to be valid. The ﬁrst step is to prove that the result is true for the ﬁrst nat-
ural number. The second step takes advantage of a logical loophole. To prove a
statement of the form “If something, then something else,” one may assume that
something is true. Once something is assumed true for a valid logical reason,
we can use that assumption to draw additional conclusions. The second step
in induction is to prove the following: “If the statement is true for a particular
natural number, then it will be true for its successor.”
If we can accomplish both these steps, we will know
• that the statement is true for 1;
• that anytime the statement is true for a particular number, it will be true for
its successor.
So we know that the statement is true for 1, and 1 is certainly a particular
number. Since the statement is true for 1, it is true for the successor of 1. But
2 is a particular number, and the statement is true for it; so because we have
proved the second step of induction, the statement is true for the successor of
2. Because every natural number is an eventual successor of 1, we will eventually
know that the statement is true for any number.
Here is the claim written as a theorem, and this is followed by its (mostly
rigorous) proof. Notice that, as we write out exactly what we are proving, our
statement about n reappears three times. It may look like we are proving or
assuming the same thing over and over. But a more careful look reveals that in
each statement, the meaning of the variable n changes. Thus, the statements
are actually about diﬀerent numbers.
Theorem 1.2.2.
For all natural numbers n, 2 ⋅(1 + 2 + 3 + … (n −1) + n) =
n(n + 1).
Proof. The proof is by induction on n. Thus, we will actually prove two other
mini theorems:
1. If n = 1, then 2 ⋅(1 + 2 + 3 + … (n −1) + n) = n(n + 1).

16
1 Beginnings
2. If for a particular n = n0,
2 ⋅(1 + 2 + 3 + … (n −1) + n) = (n + 1)n,
(1.32)
then for n = n0 + 1,
2 ⋅(1 + 2 + 3 + … (n −1) + n) = n(n + 1).
(1.33)
Proof of Step 1. Assume that n = 1. To prove that two expressions are the same,
consider them one at a time. First, (1 + 2 + 3 + … (n −1) + n) means start at 1
and stop when you get to n. But we are working under the assumption that
n = 1. So
(1 + 2 + 3 + … (n −1) + n) = 1.
(1.34)
So
2 ⋅(1 + 2 + 3 + … (n −1) + n) = 2 ⋅1 = 2.
(1.35)
Now consider the other expression, n(n + 1). We are still assuming n = 1.
(n + 1)n = (1 + 1) ⋅1 = 2.
(1.36)
Since 2 = 2, we have shown that if n = 1, then 2 ⋅(1 + … (n −1) + n) =
n(n + 1).
◾
Proof of Step 2. Assume for a particular n = n0, 2 ⋅(1 + … (n −1) + n) =
n(n + 1). Thus, we can say
2 ⋅(1 + … (n0 −1) + n0) = n0.(n0 + 1).
(1.37)
Under this assumption, we want to prove, for n = n0 + 1, that we also have
2 ⋅(1 + 2 + 3 + … (n −1) + n) = n(n + 1). That is to say, we want to show
2 ⋅(1 + 2 + … ((n0 + 1) −1) + (n0 + 1)) = (n0 + 1)((n0 + 1) + 1). (1.38)
To prove that two expressions are equal, we consider each side. Consider
2 ⋅(1 + … ((n0 + 1) −1) + (n0 + 1)). We have
2 ⋅(1 + … ((n0 + 1) −1) + (n0 + 1))
(1.39)
= 2 ⋅[(1 + 2 + 3 + … n0) + (n0 + 1)]
= 2 ⋅[1 + 2 + 3 + … n0] + 2[n0 + 1]
= n0(n0 + 1) + 2(n0 + 1)
because that is the assumption we are working under in this step. Then
2 ⋅(1 + … ((n0 + 1) −1) + (n0 + 1))
(1.40)
= n0(n0 + 1) + 2(n0 + 1)
= (n0 + 2)(n0 + 1).

1.3 Problems
17
Next, consider the other side, (n0 + 1)((n0 + 1) + 1).
(n0 + 1)((n0 + 1) + 1) = (n0 + 1)(n0 + 2).
(1.41)
The two expressions are equal. So we have proved: if for a particular n = n0,
we have 2 ⋅(1 + 2 + 3 + … (n −1) + n) = (n + 1)n, then for n = n0 + 1, we have
2 ⋅(1 + 2 + 3 + … (n −1) + n) = n(n + 1).
◾
These two steps complete the proof by induction. So we have proved: for all
natural numbers n, 2 ⋅(1 + 2 + 3 + … (n −1) + n) = n(n + 1).
◽
There are a few ﬁnal comments on this write-up. Much of the exposition is a
matter of taste, but no matter what, the proof must be an English essay. It may
contain some headings, but everything in the content should be a full sentence.
This includes the algebraic calculations. The logic is easier if all statements to
be proved are written in the “If P, then Q” form. The proof of one of these state-
ments should begin with “Assume P.” After that assumption, the goal becomes
to prove Q. The use of n0 to stand for a particular value of n in the induction
step is completely optional. With more experience in writing induction proofs,
it becomes a distraction. However, even with experience, the second step of
an induction step can get rather confusing when the statement being proved is
long. Using the n0 can be a valuable tool in ﬁghting through that kind of confu-
sion. For beginners, it is not a bad idea to take the time to use that extra notation
so that it will always be available when needed.
1.3
Problems
1.1
(a) Use n = 2, m = 3, and k = 4 to provide an example of the distribu-
tive property n(m + k) = nm + nk using either ellipsis arguments or
a geometric construction.
(b) Provide a justiﬁcation of the general distributive property n(m + k) =
nm + nk using either ellipsis arguments or a geometric construction.
1.2
Provide justiﬁcations for the cancellation properties of addition. (Hint:
look at the justiﬁcations for multiplication.)
1.3
Prove that for all natural numbers n,
n∑
k=1
k2 = n(n+1)(2n+1)
6
.
1.4
Be careful while reading these formulas.
(a) Prove that for all natural numbers n,
n∑
k=1
(2k −1) = n2.

18
1 Beginnings
(b) Prove that for all natural numbers n,
n∑
k=1
2k −1 = n2 + n −1.
1.5
Prove that for all natural numbers n, n2 ≥n.
1.6
Prove that for all natural numbers n ≥2, n2 ≥n + 2. (Hint: when trying to
prove an inequality a ≤b, it can help to write the objective as a ≤? ≤b.
Then the idea is to ﬁnd a value we can use in place of the question mark.
If we can prove the two inequalities a ≤? and ? ≤b, the result we want
follows from transitivity. If we are lucky, one of these two inequalities is
already known to be true.)
1.7
Prove that for all natural numbers n,
n∏
k=1
(
1 + 1
k
)
= n + 1. (Hint: the
symbol ∏is similar to the symbol ∑except it means multiply instead of
add.)
1.8
Let n be any natural number greater than or equal to 7.
(a) Prove that if there is a natural number q so that n = 7 ⋅q, then
n + 1 = 7 ⋅q + 1.
(b) Prove that if there are natural numbers q and r so that n = 7 ⋅q + r
and r < 6, then there is a natural number r′ so that n + 1 = 7 ⋅k + r′
with r′ < 7.
(c) Prove that if there are natural numbers q and r so that n = 7 ⋅q + r
and r = 6, then there is a natural number q′ so that n + 1 = 7 ⋅q′.
(d) Prove the following statement using induction.
For all natural numbers n ≥7, either there exists a natural
number q so that n = 7q or there exists a pair of natural
numbers q and r so that n = 7q + r with r < 7.

19
2
The Algebra of the Natural Numbers
2.1
A more sophisticated look at the basics
In the previous chapter, we expressed a few basic discoveries about counting as
four principles:
• There is a unique ﬁrst natural number.
• Every natural number has a unique immediate successor.
• Every natural number except the ﬁrst has a unique immediate predecessor.
• Every natural number is an eventual successor of the ﬁrst.
We used these principles to deﬁne an order, an addition, and a multiplication
on the natural numbers. We gave a list of basic properties that followed from
these ideas. Our justiﬁcations for these properties might not have all that a logi-
cian would want, but they were all familiar enough that we are not going to let
that bother us. We can sleep soundly knowing that someone, somewhere, can
turn them into rigorous proofs. As it turns out, the process of doing this goes
much better if we add one, rather more sophisticated, principle to the list. That
is, “the well-ordering principle of the natural numbers.”
Before we state this principle, we need some notation and our ﬁrst really for-
mal mathematical deﬁnition. Any collection of objects is a mathematical set.
Things in the collection are elements of the set. In mathematical notation, we
might say S is a set, and s is an element of S. We write s ∈S. Thus, “∈” is a sym-
bol for the phrase “is an element of.” It is the mathematical equivalent to the
verb in the sentence relating the subject s to the object S.
Of course, in mathematics, we often deal with sets of numbers. When we
have a set of numbers, it may have one that is less than all the rest, a minimum.
We want a very precise deﬁnition of this familiar term.
Deﬁnition 2.1.1
Let S be a set of numbers. When we say m is a minimum of
the set S, we mean
1. m ∈S, and
2. If s ∈S, then m ≤s.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

20
2 The Algebra of the Natural Numbers
To be a minimum of the set S, the number m must make both statements true.
This may seem like a rather long-winded way of describing a simple term. It is,
however, a mathematical deﬁnition speciﬁcally designed to be useful in a logical
proof. It is not meant to describe a minimum, although it does. That is the way of
all mathematical deﬁnitions. They are meant to give a precise logical statement
of what a word or phrase means, and – sometimes – not even a clue about
what the word is meant to describe. For a while, we will be giving mathematical
deﬁnitions to terms that we already understand. Later, however, we will give
mathematical meanings to terms we do not know and then we will use those
deﬁnitions to investigate what the terms mean. Therefore, we use the deﬁnition
to understand what the deﬁnition is really all about.
In anticipation of this future, we should take the time to memorize the oﬃcial
mathematical deﬁnitions of even the most well-known terms. As we do this,
we will become more familiar with the structure of mathematical deﬁnitions,
and the process of memorizing speciﬁc deﬁnitions will get easier. There are
more mathematical deﬁnitions ahead than one might imagine; so the faster we
get at memorizing precise mathematical deﬁnitions, the better oﬀwe will be.
Hence, from now on, the answer to the question “What is the deﬁnition of the
minimum of the set A?” is “It is a number s so that s ∈A and if x ∈A, then
s ≤x.” Of course, the letters we use to name the parts have nothing to do with
the deﬁnition. This rephrasing is exactly the same as the aforementioned oﬃcial
version. Variables are called variables for a good reason.
Example 2.1.2.
Let S = {4, 8, 12}. Notice that (1) 4 ∈S, and (2) if x ∈S, then
4 ≤x. Thus, 4 is the minimum of S. Notice that, for example, 3 is not a minimum
of S because 3 ∉S. In addition, 8 is not a minimum of S because it is not true
that 8 ≤x for all x ∈S. In particular, 8 ≰4.
Now we are ready for an oﬃcial statement of the well-ordering principle for
natural numbers.
If S is a set of natural numbers with at least one element, then S has a
minimum.
So a complete set of the basic principles that characterize the natural
numbers is
• There is a unique ﬁrst natural number.
• Every natural number has a unique immediate successor.
• Every natural number except the ﬁrst has a unique immediate predecessor.
• Every natural number is an eventual successor of the ﬁrst.
• If S is a set of natural numbers with at least one element, then S has a
minimum.

2.1 A More Sophisticated Look at the Basics
21
2.1.1
An algebraic approach
Five basic principles are enough to lead us to all sorts of additional properties
of the natural numbers. It is those algebraic properties that allow us to study
and investigate the numbers themselves. We can make it very clear that these
algebraic properties are the starting point in our studies by deﬁning the nat-
ural numbers by these properties. We write most of these properties in full
sentences with the logical form “If P, then Q.” Thus,
Deﬁnition 2.1.3.
The natural numbers form a set ℕwith the following
properties:
1. There is an element of ℕ.
2. There is an order on the natural numbers such that
(a) If k < m and m < n, then k < n.
(b) If n, m ∈ℕ, then exactly one of the following is true: n < m, m < n, or
n = m.
3. If S is a set of natural numbers with at least one element, then S has a
minimum.
4. If n and m are two natural numbers, then there is a unique natural number
n + m.
5. If k, n, m ∈ℕ, then k + (n + m) = (k + n) + m.
6. If n, m ∈ℕ, then n + m = m + n.
7. If n, m ∈ℕ, then n < n + m.
8. If k, n, m ∈ℕand n < m, then n + k < m + k.
9. If n, m ∈ℕwith n < m, then there is a unique natural number k so that
m = n + k.
10. If k, n, m ∈ℕwith n + k = m + k, then n = m.
11. If k, n, m ∈ℕwith n + k < m + k, then n < m.
12. If n and m are two natural numbers, then there is a unique natural number
n ⋅m.
13. If k, n, m ∈ℕ, then k ⋅(n ⋅m) = (k ⋅n) ⋅m.
14. If n, m ∈ℕ, then n ⋅m = m ⋅n.
15. If we write 1 for the minimum natural number, then if n ∈ℕ, then 1 ⋅n =
n ⋅1 = n.
16. If k, n, m ∈ℕwith n < m, then n ⋅k < m ⋅k.
17. If k, n, m ∈ℕwith n ⋅k = m ⋅k, then n = m.
18. If k, n, m ∈ℕwith n ⋅k < m ⋅k, then n < m.
19. If we write 1 for the minimum natural number, then if n, m ∈ℕand n ≤
m ≤n + 1, then either m = n or m = n + 1.
20. If k, n, m ∈ℕ, then k ⋅(n + m) = k ⋅n + k ⋅m.
Now the fact is that some of these can be proved to be true using others on
the list. (We saw that the cancellation properties of multiplication follow from

22
2 The Algebra of the Natural Numbers
the uniqueness of multiplication and trichotomy.) So this is not the most con-
cise of deﬁnitions. However, this is a convenient list of algebraic properties of
ℕ; so that is where we will start. Next, the set ℕitself is a set of natural numbers,
and property 1 says that it has at least one element. By property 3, ℕitself has
a minimum. We will call it 1. Thus, 1 ∈ℕand if n ∈ℕ, then 1 ≤n. Thus, the
notation set in properties 15 and 19 is permanent.
We can use these properties to give direct proofs of many algebraic results.
As before,
Proposition 2.1.4.
If n ∈ℕ, then (n + 1)2 = n2 + 2n + 1.
Proof. Assume n ∈ℕ. Then
(n + 1)2 = (n + 1)(n + 1)
(2.1)
= n2 + n + n + 1
= n2 + 2n + 1.
◽
This is called a direct proof because we started by assuming only that we
have a natural number and then performed a calculation that used the the basic
algebra that ℕhas. As we have seen, not all proofs are direct. We have already
seen a proof that uses mathematical induction.
2.2
Mathematical induction
Mathematical induction is an important proof technique, and it is important
to clearly understand the logic of an induction proof.
In Chapter 1, we looked at a proof that for all natural numbers, 2
n∑
k=1
k =
n(n + 1). We proved this by induction. Let us revisit that proof.
Proposition 2.2.1.
For all natural numbers n, 2
n∑
k=1
k = n(n + 1)
Proof. We begin this proof with a base case.
Step 1, The base case. We claim that if n = 1, then 2
n∑
k=1
k = n(n + 1).
Proof of claim. Assume n = 1. Then
2
n
∑
k=1
k = 2(1) = 2.
(2.2)

2.2 Mathematical Induction
23
In addition,
n(n + 1) = 1(2) = 2.
(2.3)
So 2
n∑
k=1
k = n(n + 1). This completes step 1.
◾
Step 2, The induction step. We claim that
If for n = n0, 2
n∑
k=1
k = n(n + 1), then for n = n0 + 1, 2
n∑
k=1
k = n(n + 1).
Proof of claim. Assume that for n = n0, 2
n∑
k=1
k = n(n + 1). Then 2
n0∑
k=1
k
= n0(n0 + 1).
Consider 2
n0+1
∑
k=1
k.
2
n0+1
∑
k=1
k = 2
(( n0
∑
k=1
k
)
+ (n0 + 1)
)
(2.4)
= 2
( n0
∑
k=1
k
)
+ 2(n0 + 1)
= n0(n0 + 1) + 2(n0 + 1)
= (n0 + 2)(n0 + 1).
Next, consider n(n + 1) for n = n0 + 1. We get
n(n + 1) = (n0 + 1)(n0 + 1 + 1).
(2.5)
So 2
n0+1
∑
k=1
k = (n0 + 1)((n0 + 1) + 1). This completes step 2.
◾
By induction, we have proved that, for all n ∈ℕ, 2
n∑
k=1
k = n(n + 1). This
completes the proof.
◽
We did not prove that the equation 2
n∑
k=1
k = n(n + 1) is true all by itself. We
could not; we do not even know what this equation means until we know what
n means.
In the aforementioned proof, the variable n took on four diﬀerent meanings
before it was over: n = 1; n = n0, n = n0 + 1, and at the end, n stands for any
natural number.
We cannot prove a theorem until we know exactly what it says. Theorems
must, therefore, be in the form of an “if…then” sentence. Thus, we could prove
something like:
If n = 5, then 2
n
∑
k=1
k = n(n + 1).

24
2 The Algebra of the Natural Numbers
To do so, we assume n = 5. The left-hand side is 2
n∑
k=1
k = 2(1 + 2 + 3 +
4 + 5) = 30. The right-hand side is 5(5 + 1) = 30. They are the same. Notice
that we do not need to assume anything about k because it does not play a
role in the result. It is a “dummy variable” that simply gives meaning to the
notation. Computer science calls this a “local variable” to the notation. It only
has meaning within the calculation called for by the notation.
Then we can, and did, prove
For all n ∈ℕ, 2
n
∑
k=1
k = n(n + 1)
because the statement tells us what n stands for.
By the same token, we did not prove
2
n0
∑
k=1
k = n0(n0 + 1) or 2
n0+1
∑
k=1
k = (n0 + 1)(n0 + 2)
(2.6)
by themselves either. We did, however, prove
If 2
n0
∑
k=1
k = n0(n0 + 1),
then 2
n0+1
∑
k=1
k = (n0 + 1)((n0 + 1) + 1).
To do so, we assume that we have an n0 so that
2
n0
∑
k=1
k = n0(n0 + 1).
(2.7)
We have a valid reason for making this assumption. Because we are proving an
“if…then” statement, we are allowed to assume the “if” part of the statement.
Once we begin to work under this assumption, we turn our attention to proving
the “then” part of the statement. At this point, we can prove
2
n0+1
∑
k=1
k = (n0 + 1)((n0 + 1) + 1)
(2.8)
by itself. Since we have assumed we know something about n0, this does have
meaning under that assumption. After this, it is just algebra: using what we
assume we know, to prove what we want.
2.2.1
The theorem of induction
The problem is that none of our basic properties say that a proof by induction
works. For that, we need to prove a theorem using those basic properties.

2.2 Mathematical Induction
25
Theorem 2.2.2
(The Theorem of Induction). Let P(n) be a statement that
is either true or false (but not both) for each n ∈ℕ. If the following statements
are true:
1. if n = 1, then P(n) is true, and
2. if for n = n0, P(n) is true, then for n = n0 + 1, P(n) is true,
then for all n ∈ℕ, P(n) is true.
Proof. Notice that the hypothesis of our “if…then” statement has two parts. So
we begin by the proof by making two assumptions: assume that
1. if n = 1, then P(n) is true;
and
2. if for n = n0, P(n) is true, then for n = n0 + 1, P(n) is true.
Comment: Our second assumption tells us that, if we ever ﬁnd a number n0 (no
matter its actual name) where P(n0) is true, then we will know that P(n0 + 1) is
true. This assumption does not give us an n0 where P(n0) is true; it just tells us
that we know something else if we ﬁnd one. We should be on the lookout for a
number that makes P(n) true.
Let A be the set of all counterexamples to the theorem. That is, A is a set of
all natural numbers k where P(k) is not true. In mathematical notation, we can
write this as follows:
A = {k ∈ℕ∣P(k) is false}.
(2.9)
Comment: There is a name for the argument we use in this proof: a minimum
counterexample argument. As the name suggests, we construct a minimum
counterexample and then show that it cannot exist.
There are two possibilities for this set A: either it has an element or it does
not. We will see what each possibility means by considering cases.
Case 1: Assume by way of contradiction that A has an element.
Comment: Because we promise to consider the other case, this is a logically
valid assumption for this case. It will hold until the case is complete. It is a
valid assumption, but it is also an assumption we hope is a false statement. An
assumption is valid if there is a logical reason to make it. In a proof such as
this, we can make a valid assumption that we fully expect is a false statement.
We hope that making this assumption leads us to a logical contradiction. Once
that happens, we will be sure our assumption (in case 1) is false and that our
alternative assumption (in case 2) must be true.

26
2 The Algebra of the Natural Numbers
Since ℕis well ordered, this assumption tells us that A has a minimum. We
should name it; we call it m. Let us write down what this means:
• m ∈A.
• If x ∈A, then m ≤x.
Comment: This second fact about m says that, if we ever ﬁnd x ∈A, then we
will know m ≤x. But it also says that, if we ever ﬁnd an x where x < m, then
we will know x ∉A. We now write this down.
• If x < m, then x ∉A.
Comment: We should be on the lookout for a number that is less than m, so
we can use this.
We have accumulated a number of facts denoted by bullets. We now use these
facts to draw conclusions.
Our ﬁrst bullet point asserts that
m ∈A = {k ∈ℕ∣P(k) is false}.
(2.10)
This tells us that m ∈ℕand P(m) is false. Next, we recall that we have assumed
that P(1) is true. These two together tell us that m ≠1. But 1 is the minimum
natural number, so 1 ≤m, and we just discovered that m ≠1. By trichotomy,
we have 1 < m.
The subtraction property of ℕtells us that there is a s ∈ℕso that m = s + 1.
(We call it s because we are already using k for something else.) Since the part
is less than the whole, s < m.
But wait – our last bullet point tells us about this situation. Because s < m,
we know that
s ∉A = {k ∈ℕ∣P(k) is false}.
(2.11)
Since we know that s ∈ℕ, the reason s ∉A must be that P(s) is not false. That
is to say, P(s) is true.
Recall now that we started this proof by making two assumptions. By our
second assumption, since P(s) is true, we must have that P(s + 1) is true.
However, s + 1 = m. So that means P(m) is true. But m ∈A, so we also
have P(m) is false. These two conclusions are logically incompatible; there is a
contradiction.
So, somewhere earlier we made an assumption that cannot be true. The last
assumption we made was the one that began this case: “Assume A has an ele-
ment.” So this case cannot actually occur. As hoped for, the valid assumption
we made to begin case 1 has turned out to be false. So it is not true that “A has
an element.”

2.3 Division
27
Case 2: The only logical possibility is case 2: A has no elements. Because
we have eliminated the other possibility, this is a valid assumption, and we
now know that it must be true. It is time to recall what we are proving at this
moment. After our initial two assumptions, we need to prove
If n ∈ℕ, then P(n) is true.
We begin a proof of this particular “if…then” with another assumption:
Assume n ∈ℕ.
Then n ∉A because nothing is. But n ∈ℕand n ∉{k ∈ℕ∣P(k) is false}. So
P(n) is not false. Thus, P(n) is true.
We have proved that under assumptions 1 and 2 in the statement of the
theorem, P(n) must be true for all n ∈ℕ.
◽
It is worth examining the logical outline of this proof. We start by assuming
the “if” parts of our theorem. We create, for the purposes of the proof, a set of
counterexamples – places where the ﬁnal conclusion is false. We identify two
possibilities, of which at least one must be true. At this point in the strict rules
of logic, either or both might be true. In this proof, though, we strongly suspect
that one is not. Since we cannot be logically sure which is true, we must consider
each possibility in its own case. In considering the ﬁrst possibility, it is valid to
assume that it is true even if we suspect that it is not. It is customary to warn
a reader of this by using the phrase “Assume by way of contradiction.” When
we reach a logical contradiction under this assumption, it tells us that this case
cannot actually occur. The assumption is not actually true. That leaves us with
the second possibility as the only one that could be true. Assuming that it is
true, we begin its case and ﬁnd that it leads to the ﬁnal conclusion we wanted.
Since that is the only logically consistent possibility, our theorem is proved.
2.3
Division
2.3.1
The division algorithm
Division in ℕis messy. If we try to divide a natural number by, say 7, several
things can happen. We might be lucky and get one natural number as an answer,
the quotient. For example, 7 goes into 28 exactly 4 times because 28 = 7 ⋅4. But
this might not work out exactly, and even though we can ﬁnd a quotient, it may
be that a remainder will be left over. Thus, 7 goes into 25 about 3 times with a
remainder of 4 because 25 = 7 ⋅3 + 4. But 7 goes into 64 exactly 9 times with
a remainder of 1 because 64 = 7 ⋅9 + 1. Remainders must be smaller than the
number we divide by to be a true remainder. Many a school child has gotten
tripped up by saying that 7 divides into 79 with a quotient of 10 and a remainder
of 9. If we are not careful, we will fall for our own version of this trap.

28
2 The Algebra of the Natural Numbers
We can describe this precisely:
Theorem 2.3.1
(The Division Algorithm for Natural Numbers). If n,
m ∈ℕand n ≤m, then either
1. there is a q ∈ℕso that m = n ⋅q, or
2. there are q, r ∈ℕso that m = n ⋅q + r where r < n.
We will prove this using the tried and true method used by school children
everywhere; we will count with our ﬁngers. To divide 7 into 39, we count by
7s keeping track of how many times we jump on our ﬁngers. We start: 7, 14,
21, 28, 35, 42. We stop here because this is the ﬁrst time our number is greater
than 39. This was the 6-th number we hit; so the quotient we are looking for
is at count 5. That tells us that the quotient is 5; the remainder is easy to ﬁnd,
4. Thus, we check that 39 = 7 ⋅5 + 4 and be sure that 4 < 7. We know that the
remainder is correct because we had the patience to wait until our count by 7
passed out goal of 39 before we stopped. This is the idea of the proof, all we
need do is convert it to algebra. This is not hard once we realize that 6 was the
minimum number where 7 ⋅6 > 39.
Proof. Always start a proof of an “if…then” statement the same way, by
assuming all the statements between the “if” and the “then.”
Assume n, m ∈ℕ. Assume n ≤m. Let
S = {k ∈ℕ∣n ⋅k ≥m}.
(2.12)
Comment: We want S to have a minimum; so we need to ﬁnd a natural number
that is deﬁnitely in S. This requires a bit of thought, but an example or two might
lead us to a guess. Basically though, it must be a number we already have in the
proof.
Claim. m ∈S
Proof of claim. Since n ∈ℕ, we know that n ≥1. Because multiplication
respects order, m ⋅n ≥m ⋅1. So, indeed, m ∈ℕand n ⋅m ≥m. So m ∈S. That
proves the claim.
◾
So by the claim, S is a set of natural numbers with at least one element. By
well ordering, S has a minimum.
Comment: Now we need to name the minimum. However, it would be a real mis-
take to call it m because we have already used that letter to mean something else.
Let p denote the minimum of S. Thus,
• p ∈S.
• If x ∈S, then p ≤x.

2.3 Division
29
As before, we can phrase this second fact as
• If x < p, then x ∉S.
Now
p ∈S = {k ∈ℕ∣n ⋅k ≥m}.
(2.13)
So we know that p ∈ℕand n ⋅p ≥m. In a startlingly obvious, but easily over-
looked, observation, this means either n ⋅p > m or n ⋅p = m. This gives us two
cases to consider.
Case 1: Assume n ⋅p = m. Let q = p. Then m = n ⋅p = n ⋅q. Since q ∈ℕand
m = n ⋅q, we have found a q that the ﬁrst possibility allowed in the theorem
does occur. So we have proved that the ﬁrst conclusion in our theorem can
occur. We have shown that under the assumption of case 1, there is a q ∈ℕso
that m = n ⋅q. This ﬁnishes case 1.
Case 2: Assume n ⋅p > m.
Now p is still an element of S because we made this observation before we
began case 1. We assumed in the beginning that n ⋅1 = n ≤m, and we just
assumed that n ⋅p > m. So 1 ≠p. This means 1 < p, and by our subtraction
rule, there is q ∈ℕso that p = q + 1.
Since p = q + 1, we know that q < p, the minimum element of S. So
q ∉S = {k ∈ℕ∣n ⋅k ≥m}.
(2.14)
We now know that n ⋅q ≥m cannot be true. By trichotomy, we must have n ⋅
q < m. By the subtraction rule, there is an r ∈ℕso that m = n ⋅q + r.
Comment: It may look like we are done, but we are not. We cannot forget that
the remainder must be the right size. That is, we still need to prove r < n.
We still have our assumption that n ⋅p > m. Thus,
m < n ⋅p = n ⋅(q + 1) = n ⋅q + n.
(2.15)
But we have carefully selected q and r so that m = n ⋅q + r. Since m < n ⋅q + n,
we must have
n ⋅q + r = m < n ⋅q + n.
(2.16)
But one of our basic assumptions is a cancellation rule; so, indeed, we have
r < n. Under the assumption of case 2, we have proved that there are q, r ∈ℕ
so that m = n ⋅q + r where r < n.
So assuming that n, m ∈ℕand n ≤m, we have shown that one of two things
must happen: either there is a q ∈ℕso that m = n ⋅q, or there are q, r ∈ℕso
that m = n ⋅q + r where r < n. This completes the proof.
◽
It is worth examining the logical outline of this proof as well. We are dividing
a smaller number into a larger number and looking for a quotient or a quotient

30
2 The Algebra of the Natural Numbers
and a remainder, theoretically. We start by assuming the “if” parts of our
theorem. We create, for the purposes of the proof, a set of numbers too big
to be the quotient. This time we expect the set to have elements, but we must
actually demonstrate that it does. We cannot just assume that it does since we
have no valid reason to do so. Once we have an element, we know that the set
has a minimum. We identify two possibilities from the fact that n ⋅p ≥m, of
which at least one must be true. At this point, logically, either or both might
be true. Depending on the actual numbers n and m, either might indeed occur.
Since we cannot be sure which is true, we must consider each possibility in its
own case. It is valid to assume that one is true to begin case 1 because we have
made an implicit promise to consider the other case later. This assumption
leads to one of the two possibilities the theorem claims must hold. That
completes the proof in this case. That brings us to the second possibility. We
begin by assuming the alternative possibility to case 1 identiﬁed earlier. This
leads to another possibility the theorem claimed might occur. Since the two
cases considered cover every possible way that n ⋅p ≥m and all those cases
led to a version of the conclusion we wanted, our theorem is proved.
2.3.2
Odds and evens
One of the ﬁrst things we learn to do with natural numbers is to distinguish the
odd ones from the even ones. The even numbers are those that can be divided
by 2 without a remainder, the odd ones are those that cannot. Every natural
number is either even or odd, and no number is both. We need to formalize
this with oﬃcial mathematical deﬁnitions.
Deﬁnition 2.3.2.
A natural number n is even if there is k ∈ℕsuch that
n = 2 ⋅k.
Because we said that this is the deﬁnition of an even number, we have actually
said that n is even if and only if there is a k ∈ℕsuch that n = 2 ⋅k.
Deﬁnition 2.3.3.
A natural number n is odd if there is a k ∈ℕsuch that
n = 2 ⋅k −1.
Anyone familiar with mathematics might ask, why 2 ⋅k −1 and not 2 ⋅k + 1?
But the reason is that we are temporarily conﬁned to the natural numbers. Since
1 is a natural number that we want to be considered to be odd, we cannot
require that there be a natural number k where n = 2 ⋅k + 1. The number 1
would fail this requirement. This is a minor problem, but a deﬁnite irritation.
Still we must make it a point to memorize and use this oﬃcial (and perfectly
correct deﬁnition) just in case it ever really matters.
A corollary is a theorem that follows directly from a theorem or the proof of
a theorem. We have one now. The following result is a corollary of the division
algorithm for the natural numbers.

2.3 Division
31
Corollary 2.3.4.
If n is a natural number, then n is either even or odd, but
never both.
Proof. The proof will have two steps. In step 1, we will prove that every natural
number is even or odd. In step 2, we will prove that no natural number is both
even and odd.
Step 1. We claim that if n is a natural number, then n is either even or odd.
Proof of claim. As always, assume n ∈ℕ. Then we have 1 ≤n; so either 1 = n
or 1 < n. We have two cases:
Case 1: Assume n = 1. Then let k = 1. Since n = 2 ⋅k −1, we know that n is
odd. This completes case 1.
Case 2: Assume 1 < n. Since ℕis discrete (remember this?), we have 2 ≤n.
By the division algorithm, either there is a q ∈ℕso that m = 2 ⋅q or there are
q, r ∈ℕso that m = 2 ⋅q + r where r < 2. Thus, we have two subcases.
Subcase 1: Assume that there is a q ∈ℕso that m = 2 ⋅q. Then n is even, and
this subcase is complete.
Subcase 2: Assume that there are q, r ∈ℕso that m = 2 ⋅q + r where r < 2.
Now r < 2 and ℕis discrete, so r ≤1. But 1 is still the minimum natural number.
So r = 1. Thus,
m = 2 ⋅q + r
(2.17)
= 2 ⋅q + 1
= 2 ⋅(q + 1) −1.
Thus, n is odd. This completes the subcase 2 and so the entire case.
So we have proved that n is either even or odd.
◾
Step 2. We claim that n cannot be both even and odd.
Comment: We should rephrase this as an “if…then…” The typical way to
rephrase a claim that something cannot happen is as: “If it does happen, then
that’s ridiculous.” So here we try to prove: If n is even and n is odd, then we can
ﬁnd a logical contradiction.
Proof draft. Assume that n is even. Assume that n is also odd.
Because n is even, there is a k ∈ℕsuch that n = 2 ⋅k.
In addition, because n is odd, there is a k ∈ℕsuch that n = 2 ⋅k −1.
Comment: Leaving this last statement as is would be a horrible mistake! We
have just used the same name for two things that we do not know are the same.
Naming new mathematical objects is a major responsibility, similar to naming
children. In a proof, the words “So there is a number…” should cause a moment’s

32
2 The Algebra of the Natural Numbers
reﬂection before assigning it a name. We should never use the same name twice
in a proof unless we ﬁrst prove that the two things are the same.
Here we used the assumption that n is even to say there is a k ∈ℕsuch that
n = 2 ⋅k. This means that, in this proof, k stands for the one natural number
for which n = 2 ⋅k. This is word for word the deﬁnition of even. We could have
stated that deﬁnition just as well as “A natural number n is even if there is r ∈ℕ
such that n = 2 ⋅r.” The symbolic letter k is not an ﬁxed part of the deﬁnition.
After this, we move to n is odd. The deﬁnition of that is there is a k ∈ℕsuch
that n = 2 ⋅k. However, we cannot simply copy this deﬁnition without taking
into account the context of our proof. The letter k is already been assigned to
stand for a ﬁxed natural number. So we need to adjust our application of the
deﬁnition to the context of our proof where the letter k is not available.
Let us start this step over.
Δ
Step 2. We claim that n cannot be both even and odd.
Proof of claim. Assume that n is even. Assume that n is also odd.
So there is a k ∈ℕsuch that n = 2 ⋅k. In addition, there is a k′ ∈ℕsuch that
n = 2 ⋅k′ −1.
Then 2k = 2k′ −1. Then 2k′ > 2k. And so k′ > k. By subtraction, there is
s ∈ℕsuch that k′ = k + s. But recall that 2k = 2k′ −1; so 2k′ = 2k + 1. And
now we are in trouble. We also have
2k′ = 2(k + s)
(2.18)
= 2k + 2s
But s ≥1, so 2s ≥2 > 1. Thus,
2k′ = 2k + 2s > 2k + 1.
(2.19)
But this contradicts trichotomy, since we also have 2k′ = 2k + 1.
◾
To summarize, in Step 1, we proved that every natural number n is either
even or odd. In Step 2, we proved that no natural number n is both even and
odd. This completes the proof of our corollary.
◽
There are few more theorems about odd and even natural numbers that we
need to state.
Theorem 2.3.5.
If n and m are even natural numbers, then n + m is even.
Theorem 2.3.6.
If n and m are odd natural numbers, then n + m is even.
Theorem 2.3.7.
If n and m are natural numbers with one odd and the other
even, then n + m is odd.

2.3 Division
33
Theorem 2.3.8.
If n and m natural numbers and one of them is even, then
n ⋅m is even.
Theorem 2.3.9.
If n and m are odd natural numbers, then n ⋅m is odd.
Theorem 2.3.10.
If n is a natural number and n2 is even, then n is even.
We will leave the proofs of the ﬁrst ﬁve of these as exercises. We will prove the
last one though. Before we do, let us plan out our proof. As always, we will begin
making the allowed assumptions. Assume that n is a natural number. Assume
that n2 is even. Then there is a k ∈ℕsuch that n2 = 2k. At this point, we are
a bit stymied. None of our basic properties say anything at all about taking a
square root or even any sort of “un-multiplying.” We can try to use the other
assumption, n ∈ℕ. After a bit of thought, we might use the aforementioned
corollary to divide the proof into cases. Since n ∈ℕ, we know either n is even
or n is odd. We can assume that n is odd and hope that it leads to a contradiction,
leaving only the possibility that n is even.
Proof. Assume that n is a natural number.
Assume that n2 is even. Then there is a k ∈ℕsuch that n2 = 2k. Since n ∈ℕ,
the aforementioned corollary gives us two possibilities: n is even or n is odd.
Case 1: Assume that n is odd. Thus, there is r ∈ℕso that n = 2r −1.
Then n2 = (2r −1)2 = 4r2 −4r + 1. But then 2k = 4r2 −4r + 1. So 2k + 4r =
4r2 + 1. Since 2k + 4r = 2(k + 2r) is even, 4r2 + 1 = 2(r2 + 1) −1 is odd. This
gives one number that is both odd and even, and that contradicts the corollary.
Case 1 cannot occur.
Case 2: It must be true that n is even. This completes the proof.
◽
This proof works perfectly well, but we will give another version that might
be considered better. We will rewrite the statement we are proving in a rather
silly, but useful way. We want to prove that whenever n2 is even, it absolutely
must happen that n is also even. So this says, if we happened to know that n is
not even, then n2 cannot be even.
Proof. Assume that n is a natural number.
We will prove if n2 is even, then n is even, by proving
if n is odd, then n2 is odd.
Assume that n is odd. Then there is a k ∈ℕso that n = 2k −1. Now
consider n2.
n2 = (2k −1)2
(2.20)
= 4k2 −4k + 1
= (4k2 −4k + 2) −1
= 2(2k2 + 1 −2k) −1.

34
2 The Algebra of the Natural Numbers
Now we make sure that (2k2 + 1 −2k) ∈ℕby showing that the subtraction is
legal. We know that k ≥1. So 2k2 ≥2k. So 2k2 + 1 > 2k. So by the subtrac-
tion property of ℕ, there is a natural number that is 2k2 + 1 −2k. So we have a
complete proof that n2 is odd.
◽
In general, if we wish to prove a statement of the form “if P, then Q,” then
it suﬃces to prove the contrapositive statement “if not Q, then not P.” Accord-
ingly, a successful proof using this technique is called a proof by contrapositive.
Notice how this worked in the previous proof. We wanted to prove “if n2 is
even, then n is even.” We did this by proving the contrapositive of that state-
ment, which is “if n is not even, then n2 is not even.” Or, more naturally, “if n is
odd, then n2 is odd.”
2.4
Problems
2.1
Prove that for all n ∈ℕ,
n∑
k=1
2k + 3 = n2 + n + 3.
2.2
Prove that for all n ∈ℕ,
n∑
k=1
k3 =
( n∑
k=1
k
)2
.
2.3
Prove that for all n ∈ℕ,
n∑
k=2
1
k2−1 = 3n2−n−2
4n2+4n .
2.4
Prove that for all n, m ∈ℕ, with n < m,
m∑
k=n
k = (n+m)(m−n+1)
2
.
(a) Use the previously proved theorems.
(b) Use induction on m.
2.5
Prove the following statements.
(a) ( 1
9 + 1
10 + 1
11 + 1
12 + 1
13 + 1
14 + 1
15 + 1
16
) >
8
16. (Do this without actu-
ally adding the fractions.)
(b) For all n ∈ℕ,
(
1
2n+1 +
1
2n+2 +
1
2n+3 +
1
2n+4 + …
1
2n+1
)
> 1
2.
(c) For all n ∈ℕ,
2n+1
∑
k=1
1
k > n
2.
2.6
Prove that for all natural numbers n large enough, n2 > n + 200. (Hint:
when trying to prove an inequality a < b, it can help to write the objec-
tive as a <? < b. Then the idea is to ﬁnd a value we can use in place of
the question mark. If we can prove the two inequalities a <? and ? < b,

2.4 Problems
35
the result we want follows from transitivity. If we are lucky, one of these
two inequalities is already known to be true.)
2.7
Look up an oﬃcial mathematical deﬁnition of “factorial.”
(a) Prove that for all natural numbers n large enough, n! ≥n + 200.
(b) Prove that for all natural numbers n large enough, n! ≥2n.
2.8
Prove that the sum of two even natural numbers is even.
2.9
Prove that the product of two even natural numbers is even.
2.10
Prove that the sum of two odd natural numbers is even.
2.11
Prove that the product of two odd natural numbers is odd.
2.12
Prove that the product of any two consecutive natural numbers is even.
2.13
Prove that if n, m ∈ℕand nm is even, then either n is even or m is even.
2.14
Prove the following: Let P(n) be a statement that is either true or false
(but not both) for each n ∈ℕ. Let m ∈ℕ. If the following two statements
hold: if n = m, then P(n) is true; and if for n = n0, P(n) is true, then for
n = n0 + 1, P(n) is true, then for all n ∈ℕwhere n ≥m, P(n) is true.
2.15
Let n be any natural number greater than 7.
(a) Prove that if there is a natural number k so that n = 7 ⋅k, then there
is a number r so that n + 1 = 7 ⋅k + r with r < 7.
(b) Prove that if there is a natural number k so that n = 7 ⋅k + r with
r < 6, then there is a number r′ so that n + 1 = 7 ⋅k + r′ with r′ < 7.
(c) Prove that if there is a natural number k so that n = 7 ⋅k + r with
r = 6, then there is a number k′ so that n + 1 = 7 ⋅k′.
(d) What happens to part (a) if instead of 7 we use 1?
2.16
Assume n, m ∈ℕand n ≤m. Assume that n is a ﬁxed number. (Hint: it
could be ﬁxed at n = 1.)
(a) Prove that if m = n, then either there is a q ∈ℕso that m = n ⋅q or
there are q, r ∈ℕso that m = n ⋅q + r where r < n.
(b) Prove that if for m = m0, there is a q ∈ℕso that m = n ⋅q, then for
m = m0 + 1, either there is a q′ ∈ℕso that m = n ⋅q′ or there are
q′, r′ ∈ℕso that m = n ⋅q′ + r′ where r′ < n.
(c) Prove that if for m = m0, there are q, r ∈ℕso that m = n ⋅q + r
with r < n, then for m = m0 + 1, either there is a q′ ∈ℕso that
m = n ⋅q′ or there are q′, r′ ∈ℕso that m = n ⋅q′ + r′ where r′ < n.

36
2 The Algebra of the Natural Numbers
(Hint: you will need to use the fact that the natural numbers are
discrete to create two cases.)
(d) Use induction to prove the following statement.
If n, m ∈ℕand n ≤m, then either there is a q ∈ℕso that
m = n ⋅q or there are q, r ∈ℕso that m = n ⋅q + r where
r < n.

37
3
Integers
3.1
The algebraic properties of ℕ
One lesson we might take from the previous chapter is that not having 0 in the
natural numbers is a real inconvenience. There are those who support the idea
of simply declaring that 0 (an additive identity) belongs to the natural num-
bers. There is nothing wrong with that, but we will not follow that course. So
for now at least, the smallest natural number is 1. In some ways, this idea of
keeping 0 out of ℕmakes sense. If you are going to add a zero for convenience,
why not move all in and include negative numbers as well. Now that would be
convenient.
That is exactly what we will do next when we deﬁne integers. We will not
begin constructing the integers as we did in school. Now that we have algebra
and are looking at numbers through their algebraic properties, we will stick
with this approach. We will look at this from an algebraic point of view. We will
list out the algebraic properties we want, look at their implications, and then
construct a number system according to the results we ﬁnd.
We begin by looking at the basic properties of ℕ. Our goal is to include an
additive identity and to include numbers that reverse addition. We will see what
we want to keep and what we want to replace as we add more numbers to the
mix. The properties of ℕare
1. There is an element of ℕ.
This is a deﬁnite keeper, but because 0 is as useful a number as 1, we will
insist that the Integers have at least two elements.
2. There is an order on the natural numbers such that
(a) if k < m and m < n, then k < n;
(b) if n, m ∈ℕ, then exactly one of the following is true: n < m, m < n, or
n = m.
We should keep these as well. Together these tell us that our numbers will
line up, and we certainly want that.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

38
3 Integers
3. If S is a set of natural numbers with at least one element, then S has a min-
imum.
We would like to keep the well-ordering principle, but we cannot. We know
enough about the integers to know that there are sets of integers (such as
the negative ones) that have even smaller elements and no possibility of a
minimum. We can, however, salvage the idea by adding a condition that the
set has a lower bound. That will prevent the set in question from having too
many small numbers. This will, of course, require a careful deﬁnition of the
term “lower bound.”
4. For any two natural numbers n and m, there is a unique natural number
n + m.
We deﬁnitely want an addition.
5. If k, n, m ∈ℕ, then k + (n + m) = (k + n) + m.
6. If n, m ∈ℕ, then n + m = m + n.
We should keep both of these so our addition in integers acts as addition
in the natural numbers.
7. If n, m ∈ℕ, then n < n + m.
We actually hope to lose this property if for no other reason than it will not
be true if m is an additive identity.
8. If k, n, m ∈ℕand n < m, then n + k < m + k.
Yes, we want addition to continue to respect the order.
We consider the three cancellation properties as a package:
9. If n, m ∈ℕwith n < m, then there exists a unique natural number k so that
m = n + k.
10. If k, n, m ∈ℕwith n + k = m + k, then n = m.
11. If k, n, m ∈ℕwith n + k < m + k, then n < m.
These three are about subtraction, and we want to keep all three. But we
hope to replace them by inventing numbers that reverse addition. We will
add in one new property and use that property to prove these three as
theorems. We will introduce the notion of additive inverses. Whenever we
need to cancel, we will instead add an inverse. This way we can also continue
our pathological avoidance of subtracting.
12. For any two natural numbers n and m, there is a unique natural number
n ⋅m.
We want a multiplication.
13. If k, n, m ∈ℕ, then k ⋅(n ⋅m) = (k ⋅n) ⋅m.
14. If n, m ∈ℕ, then n ⋅m = m ⋅n.
We should keep both of these so our multiplication in integers acts as mul-
tiplication in natural numbers.
15. If 1 is the minimum natural number, then if n ∈ℕ, then 1 ⋅n = n ⋅1 = n.
We want to keep an identity, but we don’t so much care if the identity is the
minimum of any particular set. If it turns out to be one, then good for it.
Otherwise, all we will ask for is that a multiplicative identity exists.

3.1 The Algebraic Properties of ℕ
39
16. If k, n, m ∈ℕwith n < m, then n ⋅k < m ⋅k.
This looks like something to keep, but we know we need to be careful. We
cannot keep the general statement in integers, but we can keep the condi-
tion that k ∈ℕand still have the conclusion.
17. If k, n, m ∈ℕwith n ⋅k = m ⋅k, then n = m.
18. If k, n, m ∈ℕwith n ⋅k < m ⋅k, then n < m.
We want to keep these, but the introduction of 0 gives us the opportunity
to replace both requirements with a simpler one. That is what we will do.
Slowly but surely, we are eliminating cancellation as an assumed property.
19. If n, m ∈ℕ, then n < m + 1 if and only if n ≤m.
20. If n, m ∈ℕand n ≤m ≤n + 1, then either m = n or m = n + 1.
We want to keep both these. We will, but with the extra basic properties,
they will appear as theorems.
21. If k, n, m ∈ℕ, then k ⋅(n + m) + k ⋅n + k ⋅m.
Deﬁnitely something to keep.
We need a few deﬁnitions just to make the changes we need easier. First,
Deﬁnition 3.1.1.
The number z is an additive identity for a number system, if
for every number n in the system, n + z = z + n = n.
Deﬁnition 3.1.2.
The number u is an multiplicative identity for a number sys-
tem, if for every number n in the system, n ⋅u = u ⋅n = n.
Deﬁnition 3.1.3.
In a number system, we say b is an additive inverse of the
number a, if a + b = b + a is an additive identity.
Deﬁnition 3.1.4.
In an ordered number system, the number l is said to be a
lower bound on a set S when: if s ∈S, then l ≤s.
These may seem a bit strange, but the reason for the peculiar wording of
the ﬁrst three will become clear soon enough. A lower bound on a set is just
that, a number that is less or equal to every number in the set. It is a bound on
how small the numbers in the set actually are. The lower bound deﬁnition is
crafted to be in the most useful form possible. It would be perfectly reasonable
to require a lower bound to be deﬁnitely smaller than every element of the set,
but that would eventually make most mathematical arguments a bit longer than
necessary. Yet again, the best thing to do is memorize this deﬁnition as is, with
the promise that it will be an advantage later.
Some hint as to why a lower bound is the way it is comes from comparing it to
the deﬁnition of minimum. If m is the minimum of a set S, it is automatically a
lower bound. However, a lower bound is most probably not a minimum. To be
a minimum, the lower bound must be in the set. Once a set has a lower bound,

40
3 Integers
every number smaller than it is also a lower bound. Thus, most lower bounds
are not minimums. The upside of this is that if we need to prove that a set has
a lower bound (and we often will), there should be plenty to ﬁnd, and we need
not fear accidentally bumping into an actual minimum when we do identify
one.
In other words, a minimum of a set is always a lower bound for the set. A
lower bound on a set may or may not be a minimum of the set. A lower bound
is a minimum only when it is in the set. An element of the set is a minimum
exactly when it is also a lower bound of the set.
3.1.1
The algebraic deﬁnition of the integers
Deﬁnition 3.1.5.
The integers form a set ℤwith the following properties:
1. There is an order on ℤthat is transitive and has trichotomy.
2. If S is a set of integers with at least one element and at least one lower bound,
then S has a minimum.
3. If n, m ∈ℤ, there is a unique integer n + m.
4. Addition is associative.
5. Addition is commutative.
6. There is an additive identity in ℤ.
7. If n ∈ℤ, then n has an additive inverse.
8. If k, n, m ∈ℤand n < m, then n + k < m + k.
9. If n, m ∈ℤ, there is a unique integer n ⋅m.
10. Multiplication is associative.
11. Multiplication is commutative.
12. There is an multiplicative identity in ℤ.
13. If k, n, m ∈ℤ, n < m, and k is greater than an additive identity, then n ⋅k <
m ⋅k.
14. If k, n, m ∈ℤ, then k ⋅(n + m) = k ⋅n + k ⋅m.
15. If n, m ∈ℤwith nm equal to an additive identity, then one of n or m is equal
to an additive identity.
(We refer to this by saying ℤhas no divisors of 0.)
16. The additive identity and the multiplicative identity are not equal.
Notice that we require that the integers have an additive identity but not
require it be unique. That is because we can prove it is using the deﬁnition.
Theorem 3.1.6.
The additive identity of ℤis unique.
Proof. We will prove: If 0 is an additive identity, and z is an additive identity,
then 0 = z.

3.1 The Algebraic Properties of ℕ
41
Comment: The idea here is that to prove any statement, we rephrase it as an
“if…then.” There is a trick to this when the statement is that something is unique.
To prove that something is unique, prove “if we think we have two of them, then
they are actually equal.”
So the proof begins:
Assume that 0 is an additive identity.
Assume that z is an additive identity.
Consider 0 + z.
Because 0 is an additive identity, 0 + z = z.
Because z is an additive identity, 0 + z = 0.
Because the sum of two integers is unique, 0 = z.
◽
Proof technique. To prove that something is unique, we rephrase it into the
form: “If we think we have two of them, then they are actually equal.”
Now that we know that the additive identity is unique, we can assign it one
symbol and stick with it. We will write it as 0 because that is what everyone
else does.
Theorem 3.1.7.
The multiplicative identity of ℤis unique.
The proof of this should be pretty clear; so we will not write it out. We will
write this multiplicative identity as 1.
Theorem 3.1.8.
If a ∈ℤ, its additive inverse is unique to it.
Proof. We will prove: If b is an additive inverse of a, and c is an additive inverse
of a, then b = c.
Assume that b is an additive inverse of a.
Assume that c is an additive inverse of a.
Consider b + a + c.
b + a + c = (b + a) + c = 0 + c = c;
(3.1)
b + a + c = b + (a + c) = b + 0 = b.
So b = c.
◽
The notation for the inverse is the minus sign. Thus, the additive inverse of a
is written as −a. A few words about this are in order. The symbol “−” is called
a minus sign. Unfortunately, it is used for three diﬀerent (but closely related)
ideas in mathematics. As we have just seen, it is used as a symbol that means
“the additive inverse of.” It is also a symbol for the term “negative,” meaning a

42
3 Integers
number less than 0. Thus, consider the statement: “The additive inverse 5 is −5.”
There are two ways to read this: ﬁrst “The additive inverse of ﬁve is the additive
inverse of ﬁve.” This reading is basically content-free. The other way is to read it
as “The additive inverse of ﬁve is the integer less than 0 named ‘negative ﬁve’.”
At least that says something, if not something that is interesting.
It might seem from this example that the two interpretations “the additive
inverse of” and “negative” are completely interchangeable. They are not, and a
lot of mathematical confusion occurs when they are mixed. For example, −n
should be read as “the additive inverse of n.” Since we do not know what n is,
we do not know if −n is positive or negative.
So, we need to be careful when mixing the words “negative” and “minus” as
if they always mean the same thing. It is a deﬁnite mistake to assume that the
additive inverse of an x is a negative number.
This mess is compounded by the fact that we also use the minus sign to denote
the arithmetic operation of subtraction. Thus, 7 −5 = 2 means “7 minus 5 is
2.” Now 7 −(−5) = 12. This says that 7 minus the inverse of 5 is positive 12.
While 7 + (−5) = 2 says that 7 plus the inverse of 5 is 2. This is all bad enough
when it involves numbers; it can get very confusing when it involves variables.
So one trick when performing algebra is to avoid subtraction all together and
always read the minus sign as “the additive inverse.” This is a good rule, but it is
overkill, and no one should follow it exclusively. But it is a good way to get out of
trouble. If we get confused about what some expression means, we should read
any minus sign as “the additive inverse.” If we are looking for an algebraic error
in a calculation, we try the same trick. It would be silly to always write a −b
as a + (−b), but it can help catch a calculation error. If we ﬁnd it convenient
to write a + (−b), we should deﬁnitely take the time to include the parenthesis.
We never write this as “a + −b.” That is bad mathematical grammar.
3.1.2
Simple results about integers
Theorem 3.1.9.
If n ∈ℤ, then n ⋅0 = 0 ⋅n = 0.
Proof. Assume n ∈ℤ. There is not much we can do with this assumption. It
helps to know what to consider. Consider n + n ⋅0.
n + n ⋅0 = n ⋅1 + n ⋅0
(3.2)
= n ⋅(1 + 0)
= n ⋅1
= n.
Now
n + n ⋅0 = n.
(3.3)

3.1 The Algebraic Properties of ℕ
43
We can add the additive inverse of n to both sides. (Heaven forbid we ever would
subtract.) Then
(−n) + n + n ⋅0 = (−n) + n.
(3.4)
0 + n ⋅0 = 0.
n ⋅0 = 0.
◽
Theorem 3.1.10.
If a, b ∈ℤ, then
1. −(−a) = a;
2. −a = (−1) ⋅a;
3. −(a + b) = (−a) + (−b);
4. −(a ⋅b) = (−a) ⋅b = a ⋅(−b).
Proof. This is really four theorems written as one. Each deserves its own proof.
However, each one makes the later ones easier. The trick is to read what they say.
Number 1 says, “The additive inverse of the additive inverse of a is a.” To
prove that the additive inverse of something is something else, we add them and
see if the result is zero. If it is, since additive inverses are unique, that clinches it.
Consider a + (−a). Clearly, a + (−a) = 0. So a acts as the inverse of the inte-
ger −a. It is the inverse of −a. Thus, in notation, −(−a) = a.
Number 2 says, “The additive inverse of a is given by the formula (−1) ⋅a.”
Of course, −1 is the additive inverse of 1. We need to see if the formula works.
Consider a + (−1) ⋅a.
a + (−1) ⋅a = 1 ⋅a + (−1) ⋅a
(3.5)
= (1 + (−1)) ⋅a
= 0 ⋅a
= 0.
Thus, (−1) ⋅a acts as the inverse of a. Notice that we needed the previous
theorem about multiplication by 0.
Number 3 is just the distributive property now that number 2 is proved.
Number 4 also follows from number 2 and the associative and commutative
properties of multiplication.
◽
Theorem 3.1.11.
If k, n, m ∈ℤwith n < m and k < 0, then k ⋅n > k ⋅m.
Proof. This is the classical observation that multiplying an inequality by a nega-
tive number reverses the direction of the inequality. As we have seen, in algebra,
it is often diﬃcult to tell if something is positive or negative. This theorem has
caused many an algebra student’s heart to break.

44
3 Integers
Assume k, n, m ∈ℤ.
Assume n < m.
Assume k < 0.
We will add the additive inverse of k to both sides of this last inequality. Thus,
0 < −k. Now −k is an integer, and no matter what it looks like, it is positive.
Multiplication by positive numbers in ℤpreserves the order. Thus, we can mul-
tiply n < m by (−k) and get (−k) ⋅n < (−k) ⋅m. From the last theorem, we have
−(k ⋅n) < −(k ⋅m). Finally, we add (k ⋅n + k ⋅m) to both sides of this.
(k ⋅n + k ⋅m) −(k ⋅n) < (k ⋅n + k ⋅m) −(k ⋅m).
(3.6)
(k ⋅n −k ⋅n) + (k ⋅m) < k ⋅n + (k ⋅m −k ⋅m).
0 + k ⋅m < k ⋅n + 0.
k ⋅m < k ⋅n.
Sure enough, the direction has reversed.
◽
Corollary 3.1.12.
If n ∈ℤand n ≠0, then n2 > 0.
Proof. Assume n ∈ℤand n ≠0. By trichotomy, either n > 0 or n < 0. That
gives us two cases:
Case 1: Assume n > 0. Since n > 0, we can multiply both sides of any
inequality by n. So n ⋅n > n ⋅0. So n2 > 0.
Case 2: Assume n < 0. Since n < 0, we can multiply both sides of any
inequality by n as long as we reverse the direction of the inequality. So
n ⋅n > n ⋅0. So n2 > 0.
In all possible cases, n2 > 0.
◽
Corollary 3.1.13.
In ℤ, 1 > 0.
Proof. Since 12 = 1 and 1 ≠0, this follows immediately from the last
result.
◽
Now we promised that several of the properties of ℕthat we wanted to keep
but dropped from the list of properties of ℤwould not be gone for long. Here
are four of them stated as theorems.
Theorem 3.1.14.
If k, n, m ∈ℤwith n + k = m + k, then n = m.
Theorem 3.1.15.
If k, n, m ∈ℤwith n + k < m + k, then n < m.
Both of these can be proved by assuming the “if” and adding the additive
inverse of k to both sides of that assumption.

3.1 The Algebraic Properties of ℕ
45
Theorem 3.1.16.
If k, n, m ∈ℤwith n ⋅k = m ⋅k, then if k ≠0, then n = m.
Proof. Assume k, n, m ∈ℤ.
Assume n ⋅k = m ⋅k.
Assume k ≠0.
Now n ⋅k = m ⋅k implies n ⋅k −m ⋅k = 0. So (n −m) ⋅k = 0. But there are
no 0-divisors in ℤ. So either (n −m) = 0 or k = 0. But our assumption says that
it is not k. So n −m = 0, and thus, n = m.
◽
Theorem 3.1.17.
If k, n, m ∈ℤwith n ⋅k < m ⋅k, then if k > 0, then n < m.
Proof. Assume k, n, m ∈ℤ.
Assume nk < mk.
Assume k > 0.
By trichotomy, there are three possibilities: n < m, m < n, or n = m.
Case 1: Assume m < n. Since k > 0 and multiplication by positive integers
preserves order, this would mean that mk < nk. But we assumed that nk < mk.
So we have ruled out this possibility.
Case 2: Assume m = n. This would mean that mk = nk. But we assumed that
nk < mk. So we have ruled out this possibility as well.
One of the three cases must occur; so case 3 must be true: n < m.
◽
3.1.3
The relationship between ℕand ℤ
The only property of ℤleft to prove is that it is discrete. We will prove: n <
m + 1 if and only if n ≤m. But before we do this, we need to discuss property
2 in terms of the deﬁnition of the integers. It says
If S is a set of integers with at least one element and at least one lower
bound, then S has a minimum.
To be oﬃcially called a well-ordered set, every nonempty set should have a
minimum. The extra condition requiring the set have at least one lower bound
means we cannot say ℤis well ordered. The set of even integers has at least
one element, but it has no minimum element. Even if we cannot say that ℤis
well-ordering, property 2 tells us that it is close. This is just a matter of seman-
tics. Mathematicians say ℕis well ordered and ℤis not well ordered. In math-
ematics, deﬁnitions are precise; so once a deﬁnition is made oﬃcial, we must
use the term exactly as the deﬁnition says.
Now ℤis not well ordered; still property 2 is almost as useful as the
well-ordering principle of ℕ. It has most of the same power as that of well
ordering, and all it is missing is an oﬃcial name. We will use it in the proof
of a lemma. (A lemma is a theorem that makes the proof of a larger theorem
easier.)

46
3 Integers
Lemma 3.1.18.
If A = {k ∈ℤ∣k > 0}, then 1 is the minimum of A.
Proof. Assume
A = {k ∈ℤ∣k > 0}.
(3.7)
By a previous result, 1 ∈A. So A has at least one element.
By its deﬁnition, if k ∈A, then we know that k ≥0. So 0 is a lower bound
of A.
In ℤthis is enough to guarantee that A has a minimum. Call it m. It is a good
idea to spell out what this means using the oﬃcial deﬁnition of minimum. Then
• m ∈A;
• if x ∈A, then m ≤x.
Now m ∈A = {k ∈ℤ∣k > 0}. So m > 0.
Since 1 ∈A, we know that m ≤1. Combining these using transitivity, we can
write 0 < m ≤1.
Because m > 0, we can multiply all sides of any inequalities by it. Thus,
m ⋅0 < m ⋅m ≤m ⋅1. So we have 0 < m2 ≤m. Since m2 > 0, we know that
m2 ∈A. But m is the minimum of A; so this tells us m ≤m2. By transitivity,
m ≤m2 ≤m. By trichotomy, this can only happen if m = m2.
Now m = m2 implies that 0 = m2 −m = m(m −1). Since there are no
0-divisors and m > 0, we must have m −1 = 0. So we have shown that 1 = m,
the minimum of A.
◽
Theorem 3.1.19.
Let n, m ∈ℤ. Then n < m + 1 if and only if n ≤m.
Proof. This is actually two theorems stated as one.
1. If n < m + 1, then n ≤m.
2. If n ≤m, then n < m + 1.
Part 1. Claim: If n < m + 1, then n ≤m.
Comment: Another way of saying “If n < m + 1, then n ≤m” is as “If n ≤m is
not true, then n < m + 1 is not true.” So we will prove that if m < n is true, then
m + 1 ≤n. We begin the proof by assuming the “if.”
Proof of claim. Assume m < n. Then 0 < n −m. Let A = {k ∈ℤ∣k > 0}.
Thus, n −m ∈A. By the previous lemma, 1 is the minimum of the set A. So
1 ≤n −m. So m + 1 ≤n.
◾
Part 2. Claim: If n ≤m, then n < m + 1.

3.2 Problems
47
Proof of claim. Assume n ≤m. We know that 0 < 1. So m + 0 < m + 1. Thus,
n ≤m < m + 1. By transitivity, n < m + 1.
◾
We have now proved both parts and therefore completed the proof of the
theorem.
◽
Theorem 3.1.20.
Let A = {k ∈ℤ∣k > 0}. Then A has all the properties of the
natural numbers.
We leave the proof of this as an exercise. It is quite long, since it requires
proving that A has 20 diﬀerent properties, and each requires a proof. It is not
actually that diﬃcult to go through the list, though. Many of the properties that
need to be proved are part of the deﬁnition of ℤ, and the others have just been
proved as theorems. There are a few technical matters concerning where the
numbers actually come from, but with a little care, they go away.
3.2
Problems
3.1
Give an example of a set of integers with at least one element but no
minimum.
3.2
Prove that 5 is a lower bound of the set A = {m ∈ℤ∣there is
n ∈ℤwith m = 2n2 −8n + 6}. (No Calculus allowed.)
3.3
Consider A = {m ∈ℤ∣m > 17}.
(a) Is 17 a lower bound of A?
(b) Is 12 a lower bound of A?
(c) Is 20 a lower bound of A?
(d) Is 17 a minimum of A?
(e) Is 12 a minimum of A?
(f) Is 20 a minimum of A?
(g) Is 18 a lower bound of A?
(h) Is 18 a minimum of A?
3.4
Prove that if n ∈ℤ, then n ⋅0 = 0 ⋅n = 0.
3.5
Prove that if S is a set of integers and m is a lower bound of S, then if
n < m, then n is also a lower bound of S.
3.6
Prove that if n ∈ℤ, then −n = (−1) ⋅n.
3.7
Prove that every set of natural numbers has a lower bound in ℤ.

48
3 Integers
3.8
Prove that if n, m ∈ℤwith m ≤n ≤m + 1 then either m = n or
n = m + 1.
3.9
Prove that if k, n, m ∈ℤwith n + k < m + k, then n < m.
3.10
Let a, b ∈ℤ. Prove that if a ≠b, then ab ≠1.
3.11
Let A and B be sets of integers so that every element of A is also an ele-
ment of B. Let r, s ∈ℤwith r < s. Are the following true or false?
(a) If r is a lower bound on A, then s is a lower bound on A.
(b) If s is a lower bound on A, then r is a lower bound on A.
(c) If r is a lower bound on A, then s is a lower bound on B.
(d) If s is a lower bound on A, then r is a lower bound on B.
(e) If r is a lower bound on B, then s is a lower bound on A.
(f) If s is a lower bound on B, then r is a lower bound on A.
3.12
Let A be a set of integers and m ∈ℤ. Deﬁne the terms:
(a) m is a maximum of A.
(b) m is an upper bound on A.
3.13
Carefully state the division algorithm for integers. (Remember, you can-
not divide by zero, but you can divide by anything else. In addition, there
is only one case now that zero is a number. Finally, remainders should be
positive no matter what you divide by.)
3.14
Prove that for all n, m ∈ℤwith n < m,
m∑
k=n
k = (n+m)(m−n+1)
2
.
3.15
Deﬁne the terms “odd” and “even” for integers and prove that your def-
initions give the same results as the oﬃcial deﬁnitions of odd and even
natural numbers when applied to the positive integers. (The amount of
work this proof takes depends on the deﬁnition you choose.)
3.16
Let a ∈ℤ. Prove that if a > 1, then for all n ∈ℕwith n > 1, a < an.
3.17
Explain why the last property of ℤ(that the additive identity and the
multiplicative identity are not equal) is necessary.

49
4
Rational Numbers
4.1
The algebra
Neither of the number systems ℕnor ℤhave good division properties. The
natural numbers have a theorem about division that in retrospect is rather com-
plicated. We can also state a division algorithm for the integers that is just a bit
simpler. We will not bother to prove it though.
Theorem 4.1.1.
If n, m ∈ℤand n ≠0, then there exists q, r ∈ℤsuch that
m = n ⋅q + r, where 0 ≤r < |n|.
Technically, to be an arithmetic operation, two numbers should go in, but
only one number should come out. Thus, division in ℤis not an arithmetic
operation. We need to solve this problem by adding more numbers to the mix.
However, just as we did with subtraction, we are not going to introduce divi-
sion as an arithmetic operation. Rather we are going to introduce multiplicative
inverses.
4.1.1
Surveying the algebraic properties of ℤ
We start oﬀby examining the algebraic properties we want to keep as we expand
our number system. We identify the ones we want to keep, and look for ways
to use one property about multiplicative inverses to replace as many other as
possible. Recall the properties of the integers:
• There is an order that is transitive and has trichotomy.
We like this, so let’s keep it.
• If S is a set of integers with at least one element and at least one lower bound,
then S has a minimum.
We like this, and we want to keep it or some weaker version of it. The eventual
replacement will not be very natural at ﬁrst. For right now, we have to leave
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

50
4 Rational Numbers
this property out of our algebra. As we go forward we will look at this issue
very closely.
• If n, m ∈ℤ, there is a unique integer n + m.
• Addition is associative.
• Addition is commutative.
• There is an additive identity in ℤ.
• If n ∈ℤ, then n has an additive inverse.
• If k, n, m ∈ℤand n < m, then n + k < m + k.
All of these need to stay. We know that by keeping them, we will automati-
cally have a unique identity that we will call 0 and unique additive inverses
that we denote with minus signs.
• If n, m ∈ℤ, there is a unique integer n ⋅m.
• Multiplication is associative.
• Multiplication is commutative.
• There is a multiplicative identity in ℤ.
• If k, n, m ∈ℤand n < m and 0 < k, then n ⋅k < m ⋅k.
All of these need to stay, but we know that by keeping them, we will
automatically have a unique multiplicative identity we will call 1.
• If k, n, m ∈ℤ, then k ⋅(n + m) = k ⋅n + k ⋅m.
Deﬁnitely keep this. Distribution is the property that produces the most
useful consequences.
• If n, m ∈ℤwith nm = 0, then either n = 0 or m = 0.
We can drop this, because we will not need it once we have division.
• 0 ≠1.
We keep this to make sure that we have an interesting collection of numbers.
4.1.2
Deﬁning an ordered ﬁeld
To get to division, we need to only add one property that gives us multiplicative
inverses. Of course, ﬁrst, we make this oﬃcial with
Deﬁnition 4.1.2.
We say b is a multiplicative inverse of a when a ⋅b =
b ⋅a = 1.
We want to have at least two numbers, so we assume 0 ≠1. We have seen
how the aforementioned properties lead us to conclude that for all numbers
x, x ⋅0 = 0 ⋅x = 0. Thus, the additive identity cannot have a multiplicative
inverse. We need to leave this number out of any property requiring inverses.
This is all we need to state our next deﬁnition.
Deﬁnition 4.1.3.
An ordered ﬁeld is a set F that has the following properties:
1. There is an order on F that is transitive and has trichotomy.
2. If a, b ∈F, then there is a unique a + b ∈F.

4.1 The Algebra
51
3. Addition is associative.
4. Addition is commutative.
5. There is an additive identity in F. (We know that we can prove it to be unique,
and we will call it 0.)
6. If a ∈F, then a has an additive inverse. (We know that we can prove it to be
unique to a, and we will call it −a.)
7. If a, b, c ∈F and a < b, then a + c < b + c.
8. If a, b ∈F, there is a unique a ⋅b ∈F.
9. Multiplication is associative.
10. Multiplication is commutative.
11. There is a multiplicative identity in F. (We know that we can prove it to be
unique, and we will call it 1.)
12. If a ∈F and a ≠0, then a has a multiplicative inverse. (We can prove it to
be unique to a, and we will call it a−1.)
13. If a, b, c ∈F and a < b and 0 < c, then a ⋅c < b ⋅c.
14. If a, b, c ∈F, then a ⋅(b + c) = a ⋅b + a ⋅c.
15. 0 ≠1.
This is the same process we used in the previous chapter, and it led us to
one new system of numbers: the integers. We might have been expecting that
our next set of numbers would be the rational numbers, and we might expect
that this list of algebraic properties would give us exactly those. Unfortunately,
without any substitute for well ordering, this does not happen. As we will see,
there are plenty of number systems that have all these algebraic properties. The
rational numbers form just one example of an ordered ﬁeld. The real numbers
will be another example. The impact of the loss of an adequate replacement
for well ordering has been greater than expected. Adding algebraic properties
alone does not nail down the next number system as uniquely as we might want.
This is where the mathematical subject called “Analysis” will play an important
role. We will need to deal with this missing “minimum property” before we have
a single ﬁnal system of numbers, the real numbers. For now we will investigate
the algebraic properties of ordered ﬁelds and only later add an extra property
to get us to our ﬁnal goal of real numbers.
4.1.3
Properties of ordered ﬁelds
There are a lot of housekeeping theorems that we can prove using these prop-
erties. The results are as follows: identities are unique, additive inverses are
unique, and the algebra of minus signs. But since the proofs are the same as
those for the integers, we will not bother to even state them. Still we will do
some of this housekeeping:
Theorem 4.1.4.
If a ∈F is an ordered ﬁeld, and a ≠0, then the multiplicative
inverse of a is unique.

52
4 Rational Numbers
Proof. To prove that something is unique, we prove that if we assume that there
are two, then they are actually the same. So we will prove: if b and c are multi-
plicative inverses of a, then b = c. Consider b ⋅a ⋅c.
b ⋅a ⋅c = (b ⋅a) ⋅c = 1 ⋅c = c;
(4.1)
b ⋅a ⋅c = b ⋅(a ⋅c) = b ⋅1 = b.
So c = b.
◽
Now we can deﬁne some notation. We will write the multiplicative inverse of
a as a−1. (We can also write it as 1
a, but let us not for now.)
Theorem 4.1.5.
Let F be an ordered ﬁeld. If a, b ∈F, a ≠0, and b ≠0, then
1. (a−1)−1 = a;
2. (a ⋅b)−1 = (b−1) ⋅(a−1);
3. (−a)−1 = −(a−1).
All three proofs are left as exercises.
If n is a natural number and F is an ordered ﬁeld, none of these properties
tell us that n ∈F. However, if n is a natural number, we can use it to count the
elements of F. Let us use the notation
n∑
k=1
1 to mean the sum of the multiplicative
identity in F added to itself n times. Then consider the set
N =
{ n
∑
k=1
1 | n ∈ℕ
}
.
(4.2)
This is a set made up of elements from the ordered ﬁeld F.
Theorem 4.1.6.
Let F be an ordered ﬁeld. If
N =
{ n
∑
k=1
1 | n ∈ℕ
}
,
(4.3)
then N has all the properties of the natural numbers.
We will not go through the entire proof of this. That proof would look a lot
like what we saw in Chapter 1. The main diﬀerence is that the ellipses can all be
replaced by ∑. The question as to whether this makes this proof even slightly
more rigorous is a matter of opinion. But let us just accept the theorem as
deﬁnitely proved.
Since any set that has all the properties of ℕis basically a copy of ℕ, we see
that every ordered ﬁeld F contains a copy of the natural numbers. We will say
that any ordered ﬁeld actually contains the natural numbers. (A mathemati-
cian would say we identify the subset N – which is a copy of ℕ– with the

4.2 Fractions Versus Rational Numbers
53
actual set ℕ.) Next in the ordered ﬁeld F, there is an additive identity, and every
element has an additive inverse. So every element of N = ℕhas an additive
inverse. Let
N−= {a ∈F | −a ∈N}.
(4.4)
So N ∪{0} ∪N−is a set of numbers in F. This is a copy of ℤ, and so we can
identify this set in F as ℤitself. Every ordered ﬁeld F contains the integers.
(Again, this is because we identify the actual subset N ∪{0} ∪N−with the
integers ℤ.)
Now is the time to use our other notation for the multiplicative inverse. If
n ∈ℕis considered as an element of the ordered ﬁeld F, then n−1 ∈F. If n ∈ℕ
and m ∈ℤare considered as elements of the ordered ﬁeld F, then m ⋅n−1 ∈F.
So we can deﬁne a set
Q = {m ⋅n−1 ∈F | m ∈ℤand n ∈ℕ}.
(4.5)
We might recognize Q as a set of rational numbers. But we don’t actually have
the rational numbers just yet, nor do we have an ordered ﬁeld. At this point,
we only know what properties we want an ordered ﬁeld to have, but we don’t
actually have an example of one yet. We have found a subset of any ordered ﬁeld
that gives us a clue to ﬁnding an example of one for certain. Just as we did with
the integers, we will use the properties of Q to help us construct the rational
numbers we need.
4.2
Fractions versus rational numbers
4.2.1
In some ways they are diﬀerent
We want to create the rational numbers independently. To do this, we need to
look at the rational numbers very carefully. Before we do, one of the authors of
this book would like to relay the story of a tragic incident he experienced as a
child. The experience was so traumatic that it set him oﬀon a lifetime quest.
When I was in about the 4th grade, I was taught the ﬁrst basic ideas about
fractions. The fraction 3
5 meant that I should take a whole and divide it
into 5 equal pieces. To get 3
5, I should set aside 3 of those pieces. This
made perfect sense, and I enjoyed ﬁnding the meaning of many other
fractions.
Now this was the olden days when parents were involved in their
children’s education. One of the students had a birthday on one of the
class days, and the student’s parents baked birthday cookies for the
class. These were naïve times, and instead of declaring an emergency
and calling in a hazmat team to dispose of the cookies, the teacher just
gave them out. There were not enough cookies to be given to every

54
4 Rational Numbers
child, but the cookies were large and each child could have 1
2 of a cookie.
I was happy, because I knew exactly what that meant.
But that happiness turned to horror when I realized that my cookie
had been given to Bruce Moyer, the class bully. Bruce had been through
this grade twice before and considered himself very knowledgeable
about all things fractional. So Bruce immediately mashed up our cookie
into 2000 tiny crumbs and dumped – what he said was – 1000 of them
onto my desk. After all, as he defended himself later, everyone knows
that 1000
2000 = 1
2.
That was not how I understood fractions. My share of the cookie was
most deﬁnitely not 1
2: one of two equal-sized pieces. Sure I would later
learn that, as rational numbers, 1000
2000 and 1
2 were the same. That did not
make my crumbled cookie any more palatable. I never have and never
will accept that 1000
2000 and 1
2 are the same fraction. I will admit that they
are the same rational number, but not at all the same fraction. I vowed
from that moment on that I would forever insist that “Fractions are not
numbers.” Unfortunately, I have yet to convince many other people to go
along with this.
In the next few pages, we need to heed the warning that fractions should not
automatically be considered numbers. Unfortunately, in standard mathemat-
ical notation, they are written exactly the same way. In the next few pages, we
will ignore this standard and use diﬀerent notation for fractions and rational
numbers. When we write
m
n , the double bar will tell us that we mean it is a
fraction. If we write the usual m
n , the single bar will tell us that it is meant as
a rational number. Thus,
1000
2000 ≠
1
2, because the only way fractions are equal
is if they have the same numerator and the same denominator. On the other
hand, 1000
2000 = 1
2 because as rational numbers these are the same. In either case
though, m must be an integer and n must be a natural number.
Now if fractions are to be numbers, they should have all the properties that we
want numbers to have. We should be able to compare them in order, we should
be able to add them, and we should be able to multiply them. Since these are not
oﬃcial mathematical deﬁnitions yet, we will not identify them as deﬁnitions at
all. We look to the order, addition, and multiplication on the set
Q = {m ⋅n−1 ∈F | m ∈ℤand n ∈ℕ}.
(4.6)
in an ordered ﬁeld F to guide us to the following deﬁnitions.
• The inequality of fractions
m
n <
p
q means
mq < np as integers,
(4.7)

4.2 Fractions Versus Rational Numbers
55
or
mq = np and n < q.
(4.8)
• If
m
n and
p
q are fractions, then the sum is given by the formula
m
n +
p
q =
mq + np
nq
.
(4.9)
• If
m
n and
p
q are fractions, then the product is given by the formula
m
n ⋅
p
q =
mp
nq .
(4.10)
We should now go through all 16 of the properties of an ordered ﬁeld to see
if those properties hold using these deﬁnitions. We will just hit a few highlights
since we are interested in studying numbers more than studying mere fractions.
• The order is transitive, and that is not diﬃcult to check. It also has
trichotomy because of the extra “or” condition in the deﬁnition of “less
than.” That condition also makes the fractions as almost well ordered as the
integers.
• Addition is associative.
m
n +
(p
q +
s
t
)
=
m
n +
(pt + qs
qt
)
(4.11)
=
mqt + n(pt + qs)
nqt
=
mqt + npt + nqs
nqt
.
We get this by using the formula as written and using the distributive
property of ℤ. On the other hand,
(m
n +
p
q
)
+
s
t =
mq + np
nq
+
s
t
(4.12)
=
(mq + np)t + nqs
nq
=
mqt + npt + nqs
nqt
.
Since the numerators and denominators are exactly the same, the fractions
are equal.
m
n +
(p
q +
s
t
)
=
(m
n +
p
q
)
+
s
t .
(4.13)

56
4 Rational Numbers
• The fraction
0
1 is an additive identity.
0
1 +
m
n =
0 ⋅n + 1 ⋅m
1 ⋅n
=
m
n .
(4.14)
• The fraction
1
1 is a multiplicative identity.
These high points, however, are just postponing the inevitable. The arithmetic
of fractions is simply not distributive. Consider the following calculations:
m
n ⋅
(p
q +
s
t
)
=
m
n ⋅
(pt + qs
qt
)
(4.15)
=
m(pt + qs)
nqt
=
mpt + mqs
nqt
.
On the other hand,
m
n ⋅
p
q +
m
n ⋅
s
t =
mp
nq +
ms
nt
(4.16)
=
mpnt + nqms
nqnt
=
mpnt + nqms
n2qt
.
These are not exactly the same fractions, and so the fractions are not equal
(unless it so happens that n = 1). Thus, in general,
m
n ⋅
(p
q +
s
t
)
≠
m
n ⋅
p
q +
m
n ⋅
s
t .
(4.17)
Now the distributive property has been with us from the beginning. We
just cannot consider an arithmetic without it being part of any arithmetic of
numbers. So fractions are not numbers (one might say.)
4.2.2
In some ways they are the same
We certainly expect that rational numbers are numbers. So what is going on?
Until now, we have neglected an important deﬁnition from grade school. It is
an oﬃcial mathematical deﬁnition and an important one.
Deﬁnition 4.2.1.
Let
m
n and
p
q be fractions. (That is to say, let m, p ∈ℤand
n, q ∈ℕ.) We say
m
n is equivalent to
p
q if mq = np.

4.2 Fractions Versus Rational Numbers
57
The notation for this is
m
n ≡
p
q. This reminds us that two fractions
m
n and
p
q
represent equal rational numbers if and only if they are equivalent. So what
exactly is a rational number? To mathematicians, a rational number is, quite
literally, a set of equivalent fractions. For example,
1
2 =
{1
2,
2
4,
3
6,
4
8,
5
10 · · ·
}
;
(4.18)
3
5 =
{3
5,
6
10,
9
15,
12
20,
15
25 · · ·
}
;
−11
12 =
{−11
12 ,
−22
24 ,
−33
36 ,
−44
48 ,
−55
60 · · ·
}
;
0
1 =
{0
1,
0
2,
0
3,
0
3,
0
5,
0
6 · · ·
}
;
30
50 =
{3
5,
6
10,
9
15,
12
20,
15
25, …
30
50 · · ·
}
.
The single bar means rational number, and the double bar means fraction. If we
compare the second and the last example, we see that
3
5 ≠
30
50. However the sets
that they represent have exactly the same elements. This is true even though we
explicitly listed more elements when we wrote down the last one. Still:
{3
5,
6
10,
9
15,
12
20,
15
25 · · ·
}
=
{3
5,
6
10,
9
15,
12
20,
15
25, … 30
50 · · ·
}
.
(4.19)
This means that the rational numbers are equal: 3
5 = 30
50.
We can now write down an oﬃcial deﬁnition of rational numbers.
Deﬁnition 4.2.2.
Let m ∈ℤand n ∈ℕ, then
m
n =
{p
q
||
m
n ≡
p
q
}
.
(4.20)
Then,
ℚ=
{m
n
|| m ∈ℤand n ∈ℕ
}
.
(4.21)
Using these deﬁnitions, we can say
m
n = s
t if and only if ns = mt.
Once we have done this, we can drop our double bar notation for fractions
forever. All we need to take from this is that every rational number has many
diﬀerent fractions that could be its name.

58
4 Rational Numbers
4.3
The rational numbers
The set ℚis called the set of rational numbers. While the set of fractions is not
an ordered ﬁeld, the set of rational numbers is. All we need to prove this is to
deﬁne an order, an addition, and a multiplication on ℚand check that all 16
properties hold.
Deﬁnition 4.3.1.
Let f1, f2 ∈ℚ. The inequality of rational numbers f1 < f2
means, if we write f1 = m
n and f2 = p
q, then
mq < np as integers.
(4.22)
Deﬁnition 4.3.2.
Let f1, f2 ∈ℚ. If we write f1 = m
n and f2 = p
q, the sum is given
by the formula
f1 + f2 = mq + np
nq
.
(4.23)
Deﬁnition 4.3.3.
Let f1, f2 ∈ℚ. If we write f1 = m
n and f2 = p
q, the product is
given by the formula
f1 ⋅f2 = mp
nq .
(4.24)
4.3.1
Operations are well deﬁned
The aforementioned three deﬁnitions are written as they are to clearly illustrate
a problem with deﬁning terms involving rational numbers using the fractions
that represent them. Each of these deﬁnitions say, “if we write f1 = m
n and
f2 = p
q…”. The trouble is that there are many diﬀerent ways to do this. Every
rational number has inﬁnitely many diﬀerent fractional names. What if we
apply one of these deﬁnitions using one choice of fractions for f1 and f2 and
someone else applies the deﬁnition using a diﬀerent choice of equivalent
fractions? One very clear requirement for addition in an ordered ﬁeld is that
the sum f1 + f2 be a unique rational number. So adding two equivalent pairs of
fractions must end with equivalent fractions as results.
To illustrate the problem, suppose we tried to deﬁne addition of rational
numbers m∕n and p∕q as
m
n + p
q = m + p
n + q .
(4.25)
This seems to be a very natural deﬁnition. However, notice that although
1∕2 = 4∕8 and 1∕3 = 3∕9 with this deﬁnition of addition, we have
1
2 + 1
3 = 2
5
but
4
8 + 3
9 = 7
17.
(4.26)

4.3 The Rational Numbers
59
But 2∕5 ≠7∕17. Here, adding two equivalent pairs of fractions does not give
equivalent fractions as results. As a result, we say that the operation is not well
deﬁned, and as a result, we must reject that deﬁnition for addition.
The three formal deﬁnitions given earlier do give us well-deﬁned notions. But,
before we begin using them, we must prove that they are well deﬁned. That is,
we must prove that diﬀerent choices for the names of the numbers involved will
give the same results when the deﬁnition is applied.
Theorem 4.3.4.
Let f1, f2 ∈ℚ. The inequality f1 < f2 is well-deﬁned.
Proof draft. We will prove
If m1
n1
= m2
n2
, and p1
q1
= p2
q2
,
then if m1
n1
< p1
q1
, then m2
n2
< p2
q2
.
Comment: The idea here is that to prove any statement, we need to rephrase it
as an “if…then.” When asked to prove that something is “well deﬁned,” that is
usually a hint that there is some choice involved in the deﬁnition. The deﬁnition
is logically sound if in the end that choice does not matter. So when asked to prove
that something is “well deﬁned,” we should try to phrase it as “If I use diﬀerent
names for the ingredients, then the results are the same.” That is what we did
earlier.
We begin as always, assuming the “if.”
Assume m1
n1 = m2
n2 .
Assume p1
q1 = p2
q2 .
Then, we know m1n2 = m2n1.
And, we know p1q2 = p2q1.
Under these assumptions, we want to prove if m1
n1 < p1
q1 , then m2
n2 < p2
q2 . How do
we prove this “if…then” statement? We still assume the “if.”
Assume m1
n1 < p1
q1 .
Then, we know m1q1 < n1p1.
Under these assumptions, we want to prove
m2
n2 < p2
q2 . If we consider the
left-hand side alone, it is not clear what to do with this as either a rational
number or as a fraction. Instead, we ask ourselves, what must we prove to
show that m2
n2 < p2
q2 ? We must show that m2q2 < n2p2. After a bit of thought, we
guess that we need to turn the inequality m1q1 < n1p1 into m2q2 < n2p2 using
our ﬁrst two conclusions m1n2 = m2n1 and p1q2 = p2q1. We come up with the
following argument.

60
4 Rational Numbers
All these are statements about integers; so we have access to all the algebraic
properties of ℤ. We start with the (assumed) fact that m1q1 < n1p:
m1q1 < n1p1.
(4.27)
Multiplying by n2 > 0, we have
n2m1q1 < n2n1p1.
(4.28)
Since m1n2 = m2n1, we have
n1m2q1 < n2n1p1.
(4.29)
Since n1 > 0, we have
m2q1 < n2p1.
(4.30)
Multiplying by q2 > 0, we have
m2q1q2 < n2p1q2.
(4.31)
Since p1q2 = p2q1, we have
m2q1q2 < n2p2q1.
(4.32)
Since q1 > 0, we have
m2q2 < n2p2.
(4.33)
Now that we have m2q2 < n2p2, we can say m2
n2 < p2
q2 .
Δ
This proof is kind of wordy because we explained our reasoning along the
way. We do not need to explain how we discover a proof; all we need to do is
explain the logic of the argument and not its construction. We can, and should,
rewrite the proof to make the argument pithier.
Proof. We will prove
If m1
n1
= m2
n2
, and p1
q1
= p2
q2
,
then if m1
n1
< p1
q1
, then m2
n2
< p2
q2
.
Assume m1
n1 = m2
n2 .
Assume p1
q1 = p2
q2 .
Assume m1
n1 < p1
q1 .
Thus, n1 > 0; n2 > 0; q1 > 0 and q2 > 0.
In addition, we know that m1n2 = m2n1, and p1q2 = p2q1, and m1q1 < n1p1
are true statements about integers.

4.3 The Rational Numbers
61
So
m1q1 < n1p1.
n2m1q1 < n2n1p1.
n1m2q1 < n2n1p1.
m2q1 < n2p1.
(4.34)
m2q1q2 < n2p1q2.
m2q1q2 < n2p2q1.
m2q2 < n2p2.
Now that we have m2q2 < n2p2, we can say m2
n2 < p2
q2 .
◽
Mostly we cleaned up the proof by erasing the nonessential comments about
why we were taking each step and just leaving the step. We did, however, make
it a point to leave the algebraic justiﬁcations for some of the steps by pointing
out that the numbers that we would use later to multiply the inequalities are
positive.
Theorem 4.3.5.
Let f1, f2 ∈ℚ. The sum f1 + f2 is well deﬁned.
Proof draft. We will prove that
If m1
n1 = m2
n2 and p1
q1 = p2
q2 , then m1q1+n1p1
n1q1
= m2q2+n2p2
n2q2
.
Comment: Again, to prove any statement, we need to rephrase it as an if…then.
When asked to prove that something is “well deﬁned,” that is usually a hint that
there is some choice involved in the deﬁnition. The deﬁnition is logically sound
if in the end that choice does not matter. So when asked to prove that something
is “well deﬁned,” we should try to phrase it as “If I use diﬀerent names for the
ingredients, then the results the same.” That is what we did earlier.
Assume m1
n1 = m2
n2 .
Assume p1
q1 = p2
q2 .
Then, we know m1n2 = m2n1.
And, we know p1q2 = p2q1.
Under these assumptions, we want to prove
m1q1 + n1p1
n1q1
= m2q2 + n2p2
n2q2
.
(4.35)
If we consider the left-hand side alone, it is not clear what to do with this as
either a rational number or as a fraction. Instead, we ask ourselves, what must
we prove to show that m1q1+n1p1
n1q1
= m2q2+n2p2
n2q2
?

62
4 Rational Numbers
Comment: Notice that the deﬁnition of “equals” has changed. For natural num-
bers and integers, it means “exactly the same.” For rational numbers written as
fractions, it means “are equivalent.”
We must show that
n2q2(m1q1 + n1p1) = n1q1(m2q2 + n2p2).
(4.36)
Comment: This is a statement about integers and not rational numbers. This
gives us access to all the algebraic properties of ℤ.
Consider n2q2(m1q1 + n1p1).
n2q2(m1q1 + n1p1) = n2q2m1q1 + n2q2n1p1
(4.37)
= (n2m1)(q2q1) + (n2n1)(p1q2)
= (n1m2)(q2q1) + (n2n1)(p2q1).
Here we used our two assumptions. Next, consider the right-hand side of our
equation.
n1q1(m2q2 + n2p2) = n1q1m2q2 + n1q1n2p2
(4.38)
= (n1m2)(q2q1) + (n2n1)(p2q1).
Since the results are the same
n2q2(m1q1 + n1p1) = n1q1(m2q2 + n2p2).
(4.39)
And, so we have
m1q1 + n1p1
n1q1
= m2q2 + n2p2
n2q2
.
(4.40)
Δ
Again, it is a good idea to rewrite this proof more concisely, leaving only the
parts that are directly relevant to the mathematics.
Proof. We will prove
If m1
n1
= m2
n2
, and p1
q1
= p2
q2
,
then m1q1 + n1p1
n1q1
= m2q2 + n2p2
n2q2
.
Assume m1
n1 = m2
n2 .
Assume p1
q1 = p2
q2 .

4.3 The Rational Numbers
63
Then, m1n2 = m2n1, and p1q2 = p2q1.
Consider n2q2(m1q1 + n1p1).
n2q2(m1q1 + n1p1) = n2q2m1q1 + n2q2n1p1
(4.41)
= (n2m1)(q2q1) + (n2n1)(p1q2)
= (n1m2)(q2q1) + (n2n1)(p2q1)
= n1q1(m2q2 + n2p2).
And, so we have
m1q1 + n1p1
n1q1
= m2q2 + n2p2
n2q2
.
(4.42)
◽
Theorem 4.3.6.
Let f1, f2 ∈ℚ. The product f1⋅f2 is well deﬁned.
We will leave the proof of this as an exercise.
4.3.2
ℚis an ordered ﬁeld
Once all the arithmetic is shown to be well deﬁned, we can perform arithmetic
and algebra on rational numbers without explicitly writing them as fractions.
But ﬁrst, we must show that these algebraic properties really work for these
fractional deﬁnitions.
Theorem 4.3.7.
The rational numbers ℚform an ordered ﬁeld.
This actually comprises 17 separate claims
Claim 1. There is a well-deﬁned order on ℚ.
Proof. This was just proved.
◽
Claim 2. That order is transitive.
Proof. We will prove: if a, b, c ∈ℚ, then if a < b and b < c, then a < c.
Assume a, b, c ∈ℚ.
Assume a < b.
Assume b < c.
We can write a = n
m, b = p
q, and c = s
t. Then, m, q, and t are positive.
Then, a < b means nq < mp, while b < c means pt < qs.
Then, nq < mp implies that nqt < mpt. In addition, pt < qs implies that
mpt < mqs. So nqt < mpt < mqs, and nqt < mqs. Then, we have nt < ms.
Thus, n
m < s
t. So a < c.
◽

64
4 Rational Numbers
Claim 3. That order has trichotomy.
Proof. We will prove: if a, b ∈ℚ, then exactly one of the following holds: a < b,
b < a, or a = b.
Assume a, b ∈ℚ.
Then, we can write a = n
m and b = p
q.
Now mp and nq are integers, and the integers have trichotomy. So exactly one
of the following is true:
mp < nq, in which case a = n
m < p
q = b;
nq < mp, in which case b = p
q < n
m = a;
or mp = nq, in which case a = n
m = p
q = b.
◽
Claim 4. If a, b ∈ℚ, there is a unique a + b ∈ℚ.
Proof. This was what we proved when we proved that addition is well
deﬁned.
◽
Claim 5. Addition is associative.
Proof. We leave this as an exercise, but it is the same calculation we performed
when we proved that addition of fractions was associative.
◽
Claim 6. Addition is commutative.
Proof. We leave this as an exercise.
◽
Claim 7. There is an additive identity in ℚ.
Proof. Consider 0
1 ∈ℚ. Assume a ∈ℚ. We can write a = n
m. Then
0
1 + a = 0
1 + n
m = 0 ⋅m + 1 ⋅n
1 ⋅m
= n
m = a.
(4.43)
Since we know that addition is commutative, we also have a + 0
1 = a.
◽
Claim 8. If a ∈ℚ, then a has an additive inverse.
Proof. We leave this as an exercise.
◽
Claim 9. If a, b, c ∈ℚand a < b, then a + c < b + c.
Proof. Assume a, b, c ∈ℚ.
Assume a < b.

4.3 The Rational Numbers
65
We can write a = n
m, b = p
q, and c = s
t.
Since a < b, we know that nq < mp.
Consider tq(nt + ms).
tq(nt + ms) = (qn)t2 + tqms
(4.44)
< (mp)t2 + tqms
< tm(pt + qs).
So
(nt + ms)
mt
< (pt + qs)
qt
.
(4.45)
So
n
m + s
t < p
q + s
t .
(4.46)
So a + c < b + c.
◽
Claim 10. If a, b ∈ℚ, there is a unique a ⋅b ∈ℚ.
Proof. This is what “multiplication is well deﬁned” means; so it was proved
already.
◽
Claim 11. Multiplication is associative.
Proof. We leave this as an exercise.
◽
Claim 12. Multiplication is commutative.
Proof. We leave this as an exercise.
◽
Claim 13. There is a multiplicative identity in ℚ.
Proof. Consider 1
1 ∈ℚ. Assume n
m ∈ℚ. Then 1
1 ⋅n
m = n
m = n
m ⋅1
1.
◽
Claim 14. If a ∈ℚand a ≠0, then a has a multiplicative inverse.
Proof. Assume a ∈ℚ. Assume a ≠0. This means that a is not the additive
identity of ℚ, which we proved is 0
1. We can write a = n
m, where n ∈ℤand
m ∈ℕ. Since a ≠0, we know that n
m ≠0
1. By the deﬁnition of equality of ratio-
nal numbers, n ⋅1 ≠m ⋅0. So n = n ⋅1 ≠m ⋅0 = 0. (Notice that we cannot use
m
n as a legitimate rational number unless we know that n ∈ℕ. We can avoid

66
4 Rational Numbers
such cases by using the fact that multiplication is well deﬁned.) Since n ≠0 ∈ℤ,
n2 > 0, and so n2 ∈ℕ. Then, mn
n2 ∈ℚ. Then
a ⋅mn
n2 = n
m ⋅mn
n2 = mn2
mn2 = 1
1.
(4.47)
So mn
n2 is a multiplicative inverse of n
m = a.
Comment: We can all pretend that, instead of canceling, we checked the last
equality using the deﬁnition of equality by observing that mn2 ⋅1 = mn2 ⋅1.
◽
Claim 15. If a, b, c ∈ℚand a < b and 0 < c, then a ⋅c < b ⋅c.
Proof. We leave this as an exercise.
◽
Claim 16. If a, b, c ∈ℚ, then a ⋅(b + c) = a ⋅b + a ⋅c.
Proof. Assume a, b, c ∈ℚ.
Assume a < b.
Assume b < c.
We can write a = n
m, b = p
q, and c = s
t.
Then
a ⋅(b + c) = n
m ⋅
(p
q + s
t
)
(4.48)
= n
m ⋅
(pt + qs
qt
)
= n(pt + qs)
mqt
= npt + nqs
mqt
.
On the other hand,
n
m ⋅p
q + n
m ⋅s
t = np
mq + ns
mt
(4.49)
= npmt + mqns
mqmt
= mpnt + nqms
m2qt
.
But since
m2qt(npt + nqs) = mqt(mpnt + nqms),
(4.50)

4.4 The Rational Numbers are Not Enough
67
we have
npt + nqs
mqt
= mpnt + nqms
m2qt
(4.51)
as rational numbers. So we have shown that a ⋅(b + c) = a ⋅b + a ⋅c.
◽
Claim 17. The additive identity and the multiplicative identity are not equal.
Proof. Since in ℤwe have 0 ≠1, we know that in ℚ, 0
1 ≠1
1.
◽
Now ℚis an ordered ﬁeld, and earlier we said that every ordered ﬁeld has a
subset that is a copy of ℤ. In ℚthat set is
Z =
{n
1 ∈ℚ| n ∈ℤ
}
.
(4.52)
We said that we would identify this subset of the ordered ﬁeld with ℤ. In this
case, this means that we can write the rational number represented by the
fraction n
1 as simply n. Since technically integers are not sets of equivalent frac-
tions, this identiﬁcation lets us say that, yes, they sort of are. This is deﬁnitely a
convenient trick.
Now suppose that F is an ordered ﬁeld. Through identiﬁcation, we say that
both ℕand ℤare contained in F. In addition, all the elements of ℕhave
multiplicative inverses. Thus,
Q = {mn−1 ∈F | m ∈ℤand n ∈ℕ}
(4.53)
=
{m
n ∈F | m ∈ℤandn ∈ℕ
}
.
is also contained in the ordered ﬁeld. Because of our identiﬁcations, this is a
set of rational numbers. So we can also say that every ordered ﬁeld contains
rational numbers by identiﬁcation.
4.4
The rational numbers are not enough
We have been hinting that the rational numbers are not the only example of
an ordered ﬁeld. That is a good thing because not all the numbers we need are
rational. Suppose that we have a square where the sides all have a length of one
unit. Geometry tells that the exact length of the diagonal will be a number that
when multiplied by itself is 2. To measure the length of this diagonal, we need
a number that has this property.
4.4.1
√
2 is irrational
Theorem 4.4.1.
There is no number r ∈ℚso that r2 = 2.
Proof draft. Assume, by way of contradiction (BWOC), that there is a number
r ∈ℚso that r2 = 2.

68
4 Rational Numbers
Comment: We typically use a proof by contradiction to prove that something is
not true. This allows us a logically valid reason to assume that something is true,
even though we expect that it is not. It is only polite to warn the reader of what
we are doing, so we announced it at the beginning of the proof.
Since r ∈ℚ, we may write r = i
j with i ∈ℤand j ∈ℕ.
Comment: All our elementary school training tells us that we should pick the
best possible choice for the fraction r = i
j, one that is reduced. However, we do
not want to spend the time talking about common factors, nonreduced fractions,
and reduced fractions. Luckily, another way to describe a reduced fraction is as
a fraction in the lowest terms. We have already deﬁned other things that allow
us to talk about the “lowest” terms.
Let
D =
{
q ∈ℕ| there is a p ∈ℤso that p
q = r
}
.
(4.54)
Comment: This is a set of all possible denominators of fractions equivalent to our
rational number.
The set D is a set of natural numbers, and by assumption, j is an element
of D.
By well ordering in ℕ, the set D has a minimum. Call it m. We have m ∈D.
In addition, if k ∈D, then m ≤k. (We should be on the lookout for something
in D so we can use this.)
Now
m ∈D =
{
q ∈ℕ| there is a p ∈ℤso that p
q = r
}
.
(4.55)
So there is an n ∈ℤso that n
m = r.
Comment: We can name it anything we want as long as we have not used the
name already. Of course, we now have written r as a fraction in the lowest terms
without using the common factors.
Now r2 = 2; so
(
n
m
)2
= 2
1. Therefore, n2 = 2m2.
By deﬁnition, this means that n2 is even. We proved a theorem a while ago
that said:
If n2 is even, then n is even.
Luckily, we memorized it so that we would remember it at a critical moment
such as this. So n is even.

4.4 The Rational Numbers are Not Enough
69
By deﬁnition, there is k ∈ℤso that n = 2k. But we still have the equation
n2 = 2m2. So
4k2 = (2k)2 = n2 = 2m2.
(4.56)
So m2 = 2k2. This means that m2 is even as well. By our old theorem, m is even.
So by deﬁnition, there is g ∈ℤso that m = 2g.
But then, r = n
m = 2k
2g = k
g . By the deﬁnition of the set D, we have g ∈D. But
we have been waiting for something in D to appear so we could use “if k ∈D,
then m ≤k.” Therefore, we know that m ≤g.
Of course, this is a problem because it says 2g = m ≤g. This would mean
2 ≤1. This logical contradiction means that we made an assumption that can-
not be true. We only made one; so there is no number r ∈ℚso that r2 = 2. Δ
We should clean up this proof by removing the commentary.
Proof. Assume BWOC that there is a number r ∈ℚso that r2 = 2.
Since r ∈ℚwe may write r = i
j with i ∈ℤand j ∈ℕ.
Let
D =
{
q ∈ℕ| there is a p ∈ℤso that p
q = r
}
.
(4.57)
This is a set of natural numbers, and by assumption, j is an element of D.
By well ordering, the set D has a minimum. Call it m. Then m ∈D, and if
k ∈D, then m ≤k.
Now
m ∈D =
{
q ∈ℕ| there is a p ∈ℤso that p
q = r
}
.
(4.58)
So there is an n ∈ℤso that n
m = r.
Now r2 = 2; so
(
n
m
)2
= 2
1. Therefore n2 = 2m2.
By deﬁnition, this means that n2 is even. We proved a theorem that said:
If n2 is even, then n is even.
By deﬁnition, there is k ∈ℤso that n = 2k. But we still have the equation
n2 = 2m2. So
4k2 = (2k)2 = n2 = 2m2.
(4.59)
So m2 = 2k2. This means that m2is even as well. By our old theorem, m is even.
So by deﬁnition, there is g ∈ℤso that m = 2g.
But then
r = n
m = 2k
2g = k
g .
(4.60)

70
4 Rational Numbers
By the deﬁnition of the set D, we have g ∈D. This means 2g = m ≤g. So 2 ≤1.
This logical contradiction. We have proved that there is no number r ∈ℚso
that r2 = 2.
◽
4.5
Problems
4.1
Let F be an ordered ﬁeld and a, b ∈F, with a ≠0 and b ≠0. Prove the
following.
(a) (a−1)−1 = a.
(b) (a ⋅b)−1 = (b−1) ⋅(a−1).
(c) (−a)−1 = −(a−1).
4.2
Let F be an ordered ﬁeld and a ∈F, where a ≠0. Prove the following.
(a) If a > 0, then a−1 > 0.
(b) If a < 0, then a−1 < 0.
4.3
Let F be an ordered ﬁeld and a, b, c, d ∈F. Prove that if a < b and
c < d, then a + c < b + d. (Remember the trick for proving inequalities:
we want a + c <? < b + d.)
4.4
Let F be an ordered ﬁeld. Suppose that a ∈F and a ≠0. Prove that for
all n ∈ℕ, (an)−1 = (a−1)n.
4.5
We gave an odd deﬁnition for the order of fractions:
m
n <
p
q means that mq < np as integers or mq = np and n < q.
(a) Prove that this order is transitive. (It requires several cases.)
(b) Prove that this order has trichotomy.
(c) Explain why this order makes the fractions well ordered, and if you
are brave, write out a proof.
4.6
Prove that addition in ℚis well deﬁned.
4.7
Prove that multiplication in ℚis well deﬁned.
4.8
Prove that addition in ℚis commutative.
4.9
Prove that the order in ℚis well deﬁned.
4.10
Prove that if a ∈ℚ, then a has an additive inverse.

4.5 Problems
71
4.11
Prove that multiplication in ℚis associative.
4.12
Prove that multiplication in ℚis commutative.
4.13
Prove that if a, b, c ∈ℚand a < b and 0 < c, then a ⋅c < b ⋅c.
4.14
Prove that if a ∈ℚand a ≠0, then a has a multiplicative inverse.
4.15
Let n
m and p
m be elements of ℚ.
(a) Use the deﬁnition of addition in ℚto prove that n
m+ p
m = n+p
m .
(b) Use the algebraic properties of an ordered ﬁeld to prove that
n
m+ p
m = n+p
m .
4.16
Prove that there is no r ∈ℚso that r2 = 6.
4.17
Write a deﬁnition of “the fraction n
m is in lowest terms” that does not
use the idea of common factors but uses the fact that the terms are the
lowest possible.

73
5
Ordered Fields
5.1
Other ordered ﬁelds
So far, we have one example of an ordered ﬁeld, ℚ. We also know that there is
no element r ∈ℚso that r2 = 2. We really want a number such as this though.
We can create an ordered ﬁeld just to have such a thing. We deﬁne
ℚ(
√
2) = {a + b𝜙| a, b ∈ℚ}.
(5.1)
Here 𝜙is just a symbol. Thus, the only way a + b𝜙= c + d𝜙is if a = c and b = d.
To make this an ordered ﬁeld, we need to deﬁne an order, an addition, and a
multiplication. The deﬁnition of the order is rather long and strange, but that is
what makes it work. This is only an example, so the deﬁnitions are not of lasting
importance.
Deﬁnition: we say s + t𝜙⋖u + 𝑣𝜙when |s −u∣(s −u) < 2 ∣𝑣−t∣(𝑣−t).
Deﬁnition: we say (s + t𝜙) ⊕(u + 𝑣𝜙) = (s + u) + (t + 𝑣)𝜙.
Deﬁnition: we say (s + t𝜙) ⊙(u + 𝑣𝜙) = (su + 2t𝑣) + (s𝑣+ tu)𝜙.
Notice that in each of these, we deﬁne things for ℚ(
√
2) by using the order,
addition, and multiplication in ℚ. In the order deﬁnition, the ﬁrst “⋖” refers to
the newly required order for ℚ(
√
2), while the second “<” refers to the already
understood order in ℚ. In addition, notice that because each element in ℚ(
√
2)
has only one name and arithmetic in ℚis completely safe, there is no need to
worry that these are not well deﬁned.
While it is not a pleasant task, we could check that ℚ(
√
2) is indeed an
ordered ﬁeld. We might also note that
𝜙2 = (0 + 1𝜙)2 = (0 + 1𝜙) ⊙(0 + 1𝜙) = 2 + 0 ⋅𝜙= 2.
(5.2)
So we could have written 𝜙=
√
2. So even though ℚdoes not have an r ∈ℚso
that r2 = 2, there is at least one ordered ﬁeld that does.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

74
5 Ordered Fields
But this does not help us if we also want a number s so that s2 = 6. Neither ℚ
nor ℚ(
√
2) will have such a number. We could invent
ℚ(
√
2,
√
6) = {a + b𝜙+ c𝜓+ d𝜙𝜓∣a, b, c, d ∈ℚ}.
(5.3)
But suppose that we need the number 𝜋?
Eventually, we would like to ﬁnd the deﬁnition of a special ordered ﬁeld that
will give us all the numbers we could possibly need at once. We will do this by
adding an adequate replacement for the well ordering that has served us so well
for ℕ. We compromised a bit and found a replacement that worked for ℤ. We
will need to do even more compromising to make the next step.
For now we will concentrate on proving some useful results for any ordered
ﬁeld. That way we will have properties we can apply to ℚor to the ﬁnal ﬁeld we
are hoping for.
5.2
Properties of ordered ﬁelds
5.2.1
The average theorem
Anytime a theorem has a name, that is a signal that it is worth remembering.
The main reason to name a theorem is to make it easier to refer to it later. Some-
times, a theorem has a name because it is complicated, and it takes a while to
state. A theorem with a long or complicated proof is often worth naming, so
we can use the name and avoid having to reproduce the proof. Other theorems
have names even though they are rather simple to understand and prove. That
generally means that they are used in lots of other places. Our ﬁrst theorem is
an example of the latter.
Theorem 5.2.1
(The Average Theorem). If a, b ∈F an ordered ﬁeld with
a < b, then there is an element r ∈F such that a < r < b. In fact, r = a+b
2 is one
example.
Proof. Assume a, b ∈F. Assume a < b. Adding a to both sides gives us
2a < a + b. Adding b to both sides gives us a + b < 2b. We can put these
together using transitivity and say 2a < a + b < 2b. Multiplying by the positive
number 2−1, we get a < a+b
2
< b. (Heaven forbid, we divide by 2.)
◽
Notice that the average theorem tells us that no ordered ﬁeld is discrete. There
is no element o in an ordered ﬁeld so that a ≤b ≤a + o implies that either a = b
or a = b + o. There is never a way to ever say that we have two consecutive
numbers in an ordered ﬁeld. Graphically, the line representing an ordered ﬁeld
has no measurable gaps. It has points, but it may also have one-point holes.
Because of the average theorem, there is no number “in front of a point” or any
number “after a point” on this line. There is no number “in front of a hole” or
any number “after a hole” on the line either.

5.2 Properties of Ordered Fields
75
5.2.2
Absolute values
As we have seen, mathematicians insist that mathematical terms, ideas, and
symbols be well deﬁned. There is, however, one example where this is not the
case. Mathematicians ﬁnd the symbol “±” very useful for dealing with cases in a
proof. But by its very meaning, ± is not well deﬁned. The expression ±x means:
“Either +x or −x; we do not know which or we do not care which.”
We have already used the idea of the absolute value of a number several times.
It is a familiar idea. But what does it mean?
Now
|x| = ±x
(5.4)
is a true statement. It says, “the absolute value of x is either +x or −x.” Someone
who is not careful about logic might try to deﬁne the absolute value of a number
as
|x| = ±x.
(5.5)
This is wrong because it does not make the symbol |x| well deﬁned. We know
that “well deﬁned” means that there should be only one possible value for ∣x∣,
while the symbol ± signiﬁes that there is a choice determining what |x| might
be. The correct deﬁnition of the absolute value is
Deﬁnition 5.2.2.
Let x ∈F an ordered ﬁeld. Then
|x| =
⎧
⎪
⎨
⎪⎩
x
if x > 0
0
if x = 0
−x
if x < 0
.
(5.6)
There is no ambiguity in this deﬁnition. By trichotomy, exactly one of the
following is true about x: x > 0, x < 0, or x = 0. This deﬁnition tells us which
calculation to make in each of these cases. There may be three formula, but each
one only applies in any one circumstance. The absolute value is well deﬁned on
any ordered ﬁeld. (Here, “well deﬁned” is not about the name of the variable,
but it is about the ﬁrst impression that there is a choice to be made. Once we see
that there is no actual choice, the absolute value is deﬁned without ambiguity.)
The ± sign is used in mathematics because it can condense several cases
involving absolute values into one line. This is because
|x| = ±x
(5.7)
and
x = ± ∣x∣
(5.8)
are true mathematical statements. We will see this in the following proof.

76
5 Ordered Fields
Theorem 5.2.3.
Let F be an ordered ﬁeld.
1. If a ∈F, then |a| ≥0.
2. If a ∈F, then −|a| ≤a ≤|a|.
3. Let r ∈F with r ≥0. Consider x as a variable in F. Then |x −a| ≤r if and
only if a −r ≤x ≤a + r.
4. Let r ∈F with r > 0. Consider x as a variable in F. Then, |x −a| < r if and
only if a −r < x < a + r.
5. If a, b ∈F, then |ab| = |a||b|.
Proof. There are ﬁve parts to prove.
Part 1. We claim that if a ∈F, then |a| ≥0.
Proof of claim. Assume a ∈F. By trichotomy, there are three possibilities:
a > 0; a < 0; or a = 0.
Case 1: Assume a > 0. Then |a| = a > 0.
Case 2: Assume a < 0. Then |a| = −a > 0.
Case 3: Assume a = 0. Then |a| = 0.
◾
Part 2. We claim that if a ∈F, then −|a| ≤a ≤|a|.
Proof of claim. Assume a ∈F. By the previous part, |a| ≥0. But then −|a| ≤
0 ≤|a|. So −|a| ≤|a|. However, a = ±|a|, and that is all −|a| ≤a ≤|a| is
saying.
◾
Part 3. Let r ∈F with r ≥0. Consider x as a variable in F. Then |x −a| ≤r if
and only if a −r ≤x ≤a + r.
Proof of claim. This is an “if and only if” statement, so we have two directions
to prove. First, we will prove that
If |x −a| ≤r, then a −r ≤x ≤a + r.
To begin the proof of this, let r ∈F with r ≥0. Assume |x −a| ≤r. Then
−r ≤−|x −a|. By the previous part
−r ≤−|x −a| ≤x −a ≤|x −a| ≤r.
(5.9)
So
−r ≤x −a ≤r;
(5.10)
a −r ≤x ≤a + r.
This completes the proof of the ﬁrst direction.
Now we will prove that
If a −r ≤x ≤a + r, then |x −a| ≤r.

5.2 Properties of Ordered Fields
77
To begin the proof, let r ∈F with r ≥0. Assume a −r ≤x ≤a + r. Then
−r ≤x −a ≤r.
(5.11)
If we multiply both the inequalities by −1, the signs reverse
−r ≤−(x −a) ≤r.
(5.12)
But |x −a| = ±(x −a). So |x −a| ≤r. This completes the proof of the other
direction and ﬁnishes the proof of Step 3.
◾
Part 4. Let r ∈F with r > 0. Consider x as a variable in F. Then, |x −a| < r if
and only if a −r < x < a + r.
Proof of claim. This claim follows from the previous result.
◾
Part 5. If a, b ∈F, then |ab| = |a||b|.
Proof of claim. Assume a, b ∈F. Then |a| = ±a and |b| = ±b. So by multiply-
ing, we ﬁnd the product up to the sign: |a| ⋅|b| = ±ab. Also, ab = ±|ab|. These
statements imply that |a| ⋅|b| = ±|ab|. Now ∣a||b∣≥0 and ∣ab∣≥0. Including
the possibility that these might be zero, the only sign that works in the equation
|a| ⋅|b| = ±|ab| is +.
◾
We have now proved all ﬁve claims in the theorem.
◽
Notice how we avoided writing down a bunch of cases in the later proofs by
lumping them all together and hiding them in the ± signs.
Theorem 5.2.4
(The Triangle Inequality). Let a, b ∈F an ordered ﬁeld.
Then
|a + b| ≤|a| + |b|.
(5.13)
Proof. Assume a, b ∈F. From the last theorem,
−|a| ≤a ≤|a|;
(5.14)
−|b| ≤b ≤|b|.
Adding these inequalities we get
−(|a| + |b|) ≤a + b ≤|a| + |b|.
(5.15)
But since r = |a| + |b| ≥0, we can use part 3 of Theorem 5.2.3 to say
|a + b| ≤|a| + |b|.
(5.16)
◽

78
5 Ordered Fields
5.2.3
Picturing number systems
All our number systems have an order that is transitive and satisﬁes tri-
chotomy. Transitivity means that the numbers proceed from smaller to larger.
Trichotomy means that any two numbers can be compared in size; and that
means that when arranged by size, they appear in a line.
The natural numbers and the integers are discrete. This is because they both
satisfy the condition that
if n < m ≤n + 1, then n = m + 1.
In other words, there are no integers between two consecutive integers. We
might also say that there are gaps between the integers. If we try to draw a
representation of either of these systems, we need to draw the numbers in a
line with gaps between consecutive numbers.
The natural numbers might resemble
⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅
The integers might resemble
⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅
An ordered ﬁeld is not discrete. The average theorem says that, between any two
numbers in a ﬁeld, there is another number. So basically, no drawing depicting
an ordered ﬁeld should show gaps between the points representing the numbers
in the ﬁeld. The drawing should resemble a solid line.
If the ordered ﬁeld is the rational numbers ℚ, or any ordered ﬁeld, the aver-
age theorem says that there is an element between any two. Thus, any line that
represents an ordered ﬁeld should be solid (no gaps), but we cannot think of ℚ
as a complete line. There are distances on the line that indicate distances such
as
√
2 that are not part of ℚ. There may be no gaps in the line, but there are
plenty of one-point holes. None of the “holes” are large enough to create a visi-
ble “gap” at any magniﬁcation. So it is probably not possible to accurately draw
such a thing. One way to try is to depict the line as light gray. It is a solid line, but
we can pretend that the one-point holes let the white background slip through
enough to make it appear gray.
Keeping this analogy, we might say that a drawing of the ordered ﬁeld ℚ(
√
2)
would also be a solid line; it would still be gray because there are still distances
not measurable with numbers from ℚ(
√
2). However, it should be a darker gray
than the line for ℚ, because it has numbers that ﬁll a good many holes in ℚ. In
this graphic analogy, it is easy to describe a picture of the best possible ordered
ﬁeld. It should be a solid line with no gaps, but a complete line without any
holes either. Its picture is a totally dark solid line that remains totally dark.

5.3 Problems
79
Our next step is to add another property to the requirements for an ordered
ﬁeld to produce a complete ordered ﬁeld. The aforementioned geometric anal-
ogy is so compelling that we want to be sure that it survives the added require-
ment. We will add this property and with it include a complete collection of
new, irrational, numbers. However, we want to be sure that we do not add more
than we need. According to the given graphic description, the average theorem
says that any holes that might appear in the lines representing ℚ, ℚ(
√
2) or any
other ordered ﬁeld will not be large enough to create a gap. When we ﬁll in
those holes, we do not want to create a “smudge” of new numbers that creates
a gap between rational numbers. That is, we want one new number in each old
hole; we do not want to jam a whole segment of new numbers into one hole
between old numbers. In addition, the integers and all ordered ﬁelds extend
forever in each direction. We want to be sure that our new property does not
cap oﬀeither end of the line by adding an irrational number larger than all the
numbers we already have.
One of the ﬁrst things we will do when we add an extra property to the num-
bers to complete our ordered ﬁelds once and for all is to check that we have not
created “end caps” or “smudges” in the process. By that time, however, these
will be real mathematical statements we can prove rigorously.
5.3
Problems
5.1
The average theorem states: if a, b ∈F an ordered ﬁeld with a < b, then
there is an element r ∈F such that a < r < b. In fact, r = a+b
2
is one
example. Why would it be wrong to call the average a+b
2 a fraction?
5.2
Let F be an ordered ﬁeld.
(a) Prove that for all ℕ, if a1 ∈F, a2 ∈F, · · · an ∈F, then
n∑
k=1
a2
k ≥0.
(b) Prove that for all ℕ, if a1 ∈F, a2 ∈F, · · · an ∈F, and
n∑
k=1
a2
k = 0, then
a1 = a2 = · · · an = 0.
5.3
Explain why the average theorem means that no ordered ﬁeld is
discrete.
5.4
Prove that there is no r ∈ℚso that r2 = 8.
5.5
Let n ∈ℕbe odd. Prove that there is no r ∈ℚso that r2 = 2n.
5.6
Let F be any ordered ﬁeld and a ∈F with a < 0. Prove that there is no
r ∈F so that r2 = a.

80
5 Ordered Fields
5.7
Let F be any ordered ﬁeld with a, b, c ∈F, prove that ∣a −c∣≤∣a −b∣
+ ∣c −b∣.
5.8
Let F be any ordered ﬁeld.
(a) Prove that if a, b ∈F so that a < b, then for all n ∈ℕ, there are
numbers xi ∈F so that a < x1 < x2 < … xn−1 < xn < b.
(b) Explain why you have just proved that if a, b ∈F so that a < b, then
for all n ∈ℕ, there are numbers xi ∈F all diﬀerent so that for all
i = 1, 2, … n, a < xi < b.
(c) Remember this problem.
5.9
Consider the ﬁeld ℚ(
√
2) = {a + b𝜙∣a, b ∈ℚ}. Prove that if a + b𝜙≠
0 + 0𝜙, then a + b𝜙has a multiplicative inverse in ℚ(
√
2).
5.10
Consider the ﬁeld ℚ(
√
2) = {a + b𝜙∣a, b ∈ℚ} and the order on it given
by
s + t𝜙⋖u + 𝑣𝜙if and only if ∣s −u∣(s −u) < 2 ∣𝑣−t∣(𝑣−t)
(a) Prove that if a, b, c, d ∈ℚ, then exactly one of the following holds
∣a −c∣(a −c) < 2 ∣d −b∣(𝑣−t); ∣a −c∣(a −c) > 2 ∣d −b∣(𝑣−t);
or ∣a −c∣(a −c) = 2 ∣d −b∣(d −b).
(b) Prove that if a, b, c, d ∈ℚ, so that ∣a −c∣(a −c) > 2 ∣d −b∣(𝑣−t),
then ∣c −a∣(c −a) < 2 ∣b −d∣(b −d).
(c) Prove that if a, b, c, d ∈ℚ, so that ∣a −c∣(a −c) = 2 ∣d −b∣(𝑣−t),
then (c −a)2 = 2(b −d)2.
(d) Prove that if a, b, c, d ∈ℚ, so that ∣a −c∣(a −c) = 2 ∣d −b∣(𝑣−t),
then b −d = 0.
(e) Prove that the order ⋖on ℚ(
√
2) = {a + b𝜙∣a, b ∈ℚ} satisﬁes
trichotomy.
5.11
Assuming that it is possible to deﬁne an order, an addition, and a
multiplication that make
ℚ(
√
2,
√
6) = {a + b𝜙+ c𝜓+ d𝜙𝜓∣a, b, c, d ∈ℚ}
an ordered ﬁeld and that the same is true for
ℚ(
√
2,
√
3) = {a + b𝜙+ c𝜓+ d𝜙𝜓∣a, b, c, d ∈ℚ},
explain why one would expect that in some way ℚ(
√
2,
√
6) =
ℚ(
√
2,
√
3).

81
6
The Real Numbers
6.1
Completeness
6.1.1
Greatest lower bounds
If we compare our deﬁnition of an ordered ﬁeld with the deﬁnitions of ℕand
ℤ, there is something missing. The natural numbers have the property of well
ordering, and the integers have a conditional version of it. However, there is no
property that guarantees that a set of elements from an ordered ﬁeld will have a
minimum. One reason for this is that the average theorem guarantees the exact
opposite: there will be plenty of sets that cannot possibly have minimums. And
unlike ℤthere is no one uniform condition that causes this problem.
Consider
A = {r ∈ℚ∣2 < r}.
(6.1)
This set deﬁnitely has elements; and it has the lower bound of 2 built right into
the deﬁnition. The number 2 is not in the set, so it cannot be the minimum.
Suppose we thought we found a minimum m. Then m ∈A; so 2 < m. But by
the average theorem, there is and r ∈ℚso that 2 < r < m. So r ∈A, and m
cannot really be the minimum. This is true in every ordered ﬁeld, not just ℚ!
Except for the insistence in Mathematics that a minimum must exactly ﬁt the
deﬁnition for that term, we might say that 2 is enough of a minimum to be called
one. In Mathematics, close enough is not good enough. The number 2 is at best
a “moral” minimum of A. Here is where our insistence on careful deﬁnitions
pays oﬀ. We can completely describe 2’s relation to the set A using terms we
have already deﬁned. First, 2 is a lower bound of the set A. In addition, by the
average theorem, every number greater than 2 is not a lower bound of A. Thus,
2 is the greatest lower bound of the set A.
Consider the related but diﬀerent set
B = {r ∈ℚ∣2 ≤r}.
(6.2)
This set has a minimum, 2. By deﬁnition, this means that 2 is a lower bound of
the set B. In addition, 2 ∈B, so every other lower bound of B is smaller than 2.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

82
6 The Real Numbers
This makes 2 the greatest lower bound of B. In general, the minimum of a set will
always also be the greatest lower bound of the set. The greatest lower bound,
however, must be in the set to be a minimum. So a greatest lower bound is
close to being a minimum, but not enough to be one in Mathematics. It might,
however, prove to be an adequate alternative for a minimum when a minimum
is not available. If a minimum is available, well it will automatically be a greatest
lower bound.
Because the natural numbers and the integers are discrete, for sets of those
numbers, greatest lower bounds and minima are the same. For example, for the
set
C = {r ∈ℤ∣2 ≤r},
(6.3)
the number 2 is both the minimum and the greatest lower bound. If we consider
the set
D = {r ∈ℤ∣2 < r},
(6.4)
we see that 2 is a lower bound, but not the greatest lower bound. That honor
goes to 3, the minimum of D. Remember that the integers are discrete, so the
strict inequality simply shifts the lower bound 2 up to the next integer and that
is in the set.
The average theorem means that no ordered ﬁeld is discrete, and so the strict
inequality deﬁning the set
A = {r ∈ℚ∣2 < r}.
(6.5)
basically kills the possibility of a minimum. The set A has a greatest lower bound
(2), but it is not a minimum of the set. In the aforementioned example, the set
B has the inequality changed to “less than or equal to.” Thus, the set
B = {r ∈ℚ∣2 ≤r}.
(6.6)
has a greatest lower bound (2) that is in the set; so it has a minimum.
6.1.2
So what is complete?
Certainly, a set in an ordered ﬁeld cannot have a greatest lower bound unless
it has at least one lower bound somewhere. It cannot have a minimum without
a lower bound either. In ℤ, we know that if a set has at least one element and
at least one lower bound, then it has a minimum (and thus a greatest lower
bound.) Unfortunately, not all sets of rational numbers that are bounded below
have greatest lower bounds that are rational numbers. Consider the sets
A = {r ∈ℚ∣0 < r and 2 < r2}
(6.7)
and
B = {r ∈ℚ∣0 < r and 2 ≤r2}.
(6.8)

6.1 Completeness
83
Neither of the sets has a rational number as its greatest lower bound.
Consequently, neither has a rational number that is a minimum either. Both
of these sets have elements and have 0 as a lower bound, but neither has a
rational minimum because there is no rational number that when squared
gives 2.
The rational numbers do not give us all the numbers we need to measure
things. They are not a complete collection of numbers. As the aforementioned
two examples show, the rational numbers do not give us all the numbers we
need to give sets greatest lower bounds. A set such as B should have a mini-
mum, but it has no minimum in ℚ. We do not expect that the set A will have a
minimum at all, but we would like it to have a greatest lower bound. There is no
number in ℚthat works. If we want such thing, we need more numbers than ℚ
can provide.
So what if we consider
C = {r ∈ℚ(
√
2) ∣0 < r and 2 < r2}.
(6.9)
We know that both ℚand ℚ(
√
2) are ordered ﬁelds, but C has more elements
than A, because ℚ(
√
2) has more numbers than ℚ. All three of the sets A, B,
and C have 0 as a lower bound, but not one has a minimum. Neither A nor
B has rational greatest lower bounds. But because we rigged the ordered ﬁeld
ℚ(
√
2) to have a number 𝜙so that 𝜙2 = 2, the set C has a greatest lower bound
in ℚ(
√
2), namely 𝜙=
√
2. There is no such number in ℚ. The sets A and B do
not have a rational number that serves as a greatest lower bound. Even though
A and C are not equal sets, the addition of a
√
2 has given them both greatest
lower bounds, but only in the larger ﬁeld ℚ(
√
2). But neither ℚnor ℚ(
√
2) is
a complete set of required numbers. The lines that represent these ﬁelds have
too many holes. The set
D = {r ∈ℚ∣0 < r and 6 < r2}
(6.10)
needs a
√
6 to have a greatest lower bound, and neither ﬁeld has one.
So what would a complete line without holes do for us? It would ﬁll in any
hole, and then it could include any potential greatest lower bound for any set.
To complete our number line, we need enough numbers to ﬁll in all the holes
in the ℚ-line. Maybe adding an axiom that guarantees greatest lower bounds
will do the trick.
Draft 6.1.1
(The Completeness Axiom).
An ordered ﬁeld F is complete
when: if S is a set of numbers from F, and S has at least one element, and S has
at least one lower bound, then there is an s ∈F that is a greatest lower bound
of the set S.
(The reason why we label this as a draft is that we will state it slightly diﬀer-
ently later simply using a diﬀerent word for “greatest lower bound.”)
Deﬁnition 6.1.2.
Any complete ordered ﬁeld is called the real numbers ℝ.

84
6 The Real Numbers
6.1.3
An alternate version of completeness
All this number business began with the natural numbers, and the ﬁrst and
smallest natural number is 1. Since then, we have introduced smaller num-
bers in ℤ, in ℚand in any ordered ﬁeld. However, the momentum established
in ℕhas limited us to considering the small side of numbers and sets: mini-
mums, lower bounds, and now greatest lower bounds. It is now time to deal
with neglected large side of things.
Deﬁnition 6.1.3.
We say that m is an upper bound of a set S when it satisﬁes
1. if s ∈S, then s ≤m.
Deﬁnition 6.1.4.
We say that m is the maximum of the set S when it satisﬁes
1. m ∈S, and
2. if s ∈S, then s ≤m.
With these deﬁnitions, the notion of a least upper bound makes sense. This
allows us to oﬀer a theorem about complete ordered ﬁelds that could just as
well have been used as the Completeness Axiom. In that case, our stated axiom
would have been a theorem that was proved from the alternate. For us, it is the
alternate that needs proof.
Theorem 6.1.5
(The Alternate Completeness Axiom). For a complete
ordered ﬁeld ℝ: if S is a set of numbers from ℝ, and S has at least one element,
and S has at least one upper bound, then there is an s ∈F that is a least upper
bound of the set S.
We prove this using a lemma and some temporary notation. For the pur-
pose of proving this theorem and stating the following lemma, we deﬁne the
following:
For S a set of real numbers,
UB(S) = {u ∈ℝ∣u is an upper bound on the set S}.
(6.11)
Notice that this deﬁnition means: u ∈UB(S) if and only if u is an upper bound
on the set S.
Lemma 6.1.6.
If s ∈S, then s is a lower bound of UB(S).
Proof. Assume s ∈S. Under this assumption, we want to prove that s is a lower
bound of UB(S). To prove anything, we restate it as an “if…then.” To do this,
we ask ourselves, what does “s is a lower bound of UB(S) mean?” It means: if
u ∈UB(S), then s ≤u. So we can assume
u ∈UB(S) = {u ∈ℝ∣u is an upper bound on the set S}.
(6.12)

6.1 Completeness
85
Since u is an upper bound on the set S, if x ∈S, then x ≤u. But we have s ∈S;
so s ≤u. So indeed, if u ∈UB(S), then s ≤u. That says that s is a lower bound
of UB(S).
◽
That is kind of wordy; so let us trim it down to the essentials.
Proof. Assume s ∈S. Assume u ∈UB(S). Thus, u is an upper bound on S; so
s ≤u. So s is a lower bound on UB(S).
◽
Now we are ready to prove the theorem.
Proof. Assume that S is a set of numbers from ℝ.
Assume that S has at least one element.
Assume that S has at least one upper bound.
Consider UB(S).
UB(S) is a set of numbers from ℝ.
Because S has at least one upper bound, UB(S) has at least one element.
Because elements in S are lower bounds of UB(S), we know that UB(S) has at
least one lower bound.
But by the completeness axiom, UB(S) has a greatest lower bound in ℝ. Call
it t.
Thus, t is a lower bound of UB(S). (Note that it is not enough to tell us that it
is in S since S might have gaps. That is OK, since we expect t to be a least upper
bound on S and not necessarily a maximum.)
In addition, because t is a greatest lower bound of UB(S), if 𝑣is a lower bound
of UB(S), then 𝑣≤t.
Claim. t is a least upper bound on S.
Proof of claim. To prove this, we need to prove both parts of the deﬁnition: (i)
if x ∈S, then s ≤t, and (ii) if u is an upper bound of S, then t ≤u.
To prove the ﬁrst “if … then,” assume x ∈S. Then, as the lemma said,
x is a lower bound on UB(S). But then, we know that x ≤t, the greatest
lower bound of UB(S). Since x ∈S implies x ≤t, we know that t is an upper
bound of S.
To prove the second “if … then,” assume that u is any upper bound of S. Then
u ∈UB(S). So t ≤u since t is a lower bound of UB(S).
Thus, t is an upper bound of S, and if u is an upper bound of S, then t ≤u.
This makes t the least of all upper bounds of S.
◾
This completes the proof of the theorem.
◽

86
6 The Real Numbers
6.2
Gaps and caps
If our intuition is correct, adding the completeness axiom to the properties of
an ordered ﬁeld should provide us with all the numbers we need to measure the
distances on a line. The resulting real numbers ℝshould have all the algebraic
and analytic properties we need. We would still like to be sure that this axiom
does not cap oﬀthe numbers we already have by creating an irrational number
larger than all the rational ones. We also hope that we have ﬁlled each hole with
a single irrational number and not smudged the line up by placing a solid string
of irrational numbers in one hole. These may be rather ﬂippant descriptions
of the reasons why we need the next two theorems, but the theorems them-
selves are interesting and valuable mathematical facts. Both these theorems are
important in our understanding of the real numbers.
6.2.1
The Archimedean principle
First recall that, as in any ordered ﬁeld, the real numbers contain (a copy of) ℕ,
ℤ, and ℚ.
Theorem 6.2.1
(The Archimedean Principle). If r ∈ℝ, then there is an n ∈
ℕso that r < n.
Notice this says that the real numbers have no cap on the high end. The appli-
cations of this seemingly obvious result appear frequently in even the most
advanced studies of the real numbers.
Proof draft. We will prove this by contradiction.
Assume BWOC that there is an r ∈ℝso that if n ∈ℕ, then n ≤r.
Comment: This should remind us of a deﬁnition we have already seen. This
means that r is an upper bound on the set of real numbers ℕ. Clearly ℕhas at
least one element. Our assumption means that ℕhas at least one upper bound.
By the alternate completeness axiom, there is a real number s so that s is a
least upper bound of ℕ.
This means if n ∈ℕ, then n ≤s.
Comment: We should be on the lookout for an interesting natural number to use
this on. In addition, if we ever ﬁnd a real number less than s, there is no way
it can be an upper bound on ℕ. Here is a real number less than s: s −1. Let us
use that.
Since s −1 < s, the real number s −1 is not an upper bound of ℕ.

6.2 Gaps and Caps
87
Comment: What does that mean? It means that there is at least one natural
number that prevents s −1 from being an upper bound of the natural numbers.
Thus, there exists m ∈ℕsuch that s −1 < m.
But then, s < m + 1. And since both m and 1 are natural numbers, so is
m + 1 ∈ℕ.
However, we have been looking for an interesting natural number in ℕ.
Because s is an upper bound of ℕ, this means that m + 1 ≤s. We have reached
the conclusion that m + 1 ≤s < m + 1. This contradicts the properties of an
order in an ordered ﬁeld. We have a contradiction, so our initial assumption
cannot be true.
So indeed, if r ∈ℝ, then there is an n ∈ℕso that r < n.
Δ
This deserves to be cleaned up.
Proof. Assume BWOC that there is an r ∈ℝso that if n ∈ℕ, then n ≤r.
This means that r is an upper bound on the set of natural numbers ℕ.
Now ℕhas at least one element, and it has an upper bound. By the alter-
nate completeness axiom, there is a real number s so that s is a least upper
bound of ℕ.
This means if n ∈ℕ, then n ≤s.
In addition, if we ever ﬁnd a real number less than s, there is no way it can be
an upper bound on ℕ.
But s −1 < s, so the real number s −1 is not an upper bound of ℕ. There is
at least one natural number, call it m, so that s −1 < m.
But then, s < m + 1. And since both m and 1 are natural numbers, so is
m + 1 ∈ℕ.
However, because s is an upper bound of ℕ, this means m + 1 ≤s. So m + 1 ≤
s < m + 1. This is a contradiction, so our initial assumption cannot be true.
So indeed, If r ∈ℝ, then there is an n ∈ℕso that r < n.
◽
What about a cap on the lower side?
Corollary 6.2.2.
If r ∈ℝ, then there is an n ∈ℤso that n < r.
Proof. Assume r ∈ℝ. Then −r ∈ℝ. By the Archimedean principle, there is
n ∈ℕso that −r < n. So −n < r. Of course, −n ∈ℤ, and that is what we were
looking for.
◽
6.2.2
The density theorem
Next, we deal with the possibility of smudges.

88
6 The Real Numbers
Theorem 6.2.3
(The Density Theorem). Let a, b ∈ℝwith a < b. Then, there
exists r ∈ℚso that a < r < b.
This closely resembles the average theorem that holds in any ordered ﬁeld,
but on closer inspection it says much more. The average of two real numbers is
rather unlikely to be a rational number. If the two numbers a and b are ratio-
nal, well, the average will also be. But this is a theorem about any pair of real
numbers. The average theorem says that there is a real number between any
diﬀerent a and b. The density theorem says that there is always a rational num-
ber between them. For example, we expect that
√
2 −1 and
√
2 + 1 are real
numbers. Their average is
√
2. Their average is a real number, but it is not a
rational number. The density theorem says that there is some other real num-
ber between them that is actually a rational number. In addition, for any positive
number 𝜀> 0, no matter how small, the density theorem tells us that there is a
rational number between
√
2 −𝜀and
√
2 + 𝜀. If the completeness axiom had
smudged one of the irrational holes in ℚ, there would be a whole string of new
numbers with no rationals between them. The density theorem tells us that this
does not happen.
To prove it, we prove a lemma that says that with enough room between a
and b, we can actually ﬁnd an integer between them.
Lemma 6.2.4.
Let a, b ∈ℝwith a + 1 < b. Then, there exists m ∈ℤso that
a < m < b.
Proof. Assume a, b ∈ℝ. Assume a + 1 < b.
Comment: We are looking for the integer that is closest to a from above. The word
“closest” reminds us of “smallest,” and that reminds us of “minimum.”
Let
A = {k ∈ℤ∣a < k}.
(6.13)
Comment: We want the minimum of A, but we need to be sure that one exists.
By the Archimedean principle, A has at least one element.
By the corollary to the Archimedean principle, there is a p ∈ℤwith p < a.
Thus, p is an integer lower bound on A. By the well-ordering like property of ℤ,
we know that A has a minimum. Call it m. Then
m ∈A = {k ∈ℤ∣a < k}.
(6.14)
In addition, if x ∈A, then m ≤x.

6.2 Gaps and Caps
89
Comment: This means that if we ever ﬁnd an x so that x < m, then x ∉A. We
should be on the lookout for something less than m to use this on.
Now a < m.
In addition, m −1 < m. So we know m −1 ∉A = {k ∈ℤ∣a < k}. By tri-
chotomy, since a < m −1 is not true, it must be that m −1 ≤a. So, m ≤a + 1.
But now we are done, by transitivity:
a < m ≤a + 1 < b.
(6.15)
◽
Now let us try to prove the theorem.
Proof draft. Assume a, b ∈ℝ. Assume a < b.
Comment: We need to open up some space between the numbers we are given.
If the space is large enough, we can ﬁt an integer in there. We do not want to
ruin any rationality, so we will open the space by multiplying by a large natural
number. (Oh yeah, we will need old Archimedes for this.) The question is how
large an n do we need? If we set up this question as a word problem, perhaps all
our training in algebra will be of help.
Scratch work:
So, the problem we must solve is: Find n ∈ℕso that na + 1 < nb. Now “Find
n” means “Write a sentence that has n as the subject and says what n is.” So, we
want n ∈ℕlarge enough that na + 1 < nb. How large is that?
na + 1 < nb.
(6.16)
1 < nb −nb.
1 < n(b −a).
1
b −a < n.
Comment: Since
1
b−a is a real number, Archimedes tells us that this natural num-
ber will exist. Now we have two real numbers na and nb where na + 1 < nb. We
can apply the lemma to any two numbers no matter what they are called. So
there is m ∈ℤso that na < m < nb. But n ∈ℕ; so we can divide the inequali-
ties by it to get a < m
n < b. We have the rational number we need. We have solved
our problem and can get back to the proof. The problem and solution it contains
are just scratch work we needed to get to a proof. It does not belong in the write-up
of the proof it ﬁnds. Besides, the calculation we used in the solution reappears
backward in the presentation of the result, so it seems to be a waste to write it
twice.
Δ

90
6 The Real Numbers
We start the proof over from scratch.
Proof. Assume a, b ∈ℝ. Assume a < b.
Then b −a > 0. So it has a multiplicative inverse, and
1
b−a ∈ℝ.
By the Archimedean principle, there is n ∈ℕso that n >
1
b−a. Then since
b −a > 0, we can multiply to get
n(b −a) > 1;
(6.17)
nb −nb > 1;
nb > na + 1.
Now we have two real numbers na and nb where na + 1 < nb. We can apply
the lemma to any two real numbers no matter what they are called. So there
is m ∈ℤso that na < m < nb. But n ∈ℕ, so we can divide the inequali-
ties by it to get a < m
n < b. Since m ∈ℤand n ∈ℕ, we have the rational
number we need.
◽
6.3
Problems
6.1
Let S = {x ∈ℝ∣x−1 ∈ℕ}. Prove that 0 is the greatest lower bound of
S. (Hint: you need to prove that “if s is a lower bound of S, then s ≤0.”
Rewrite it in reverse to have the same meaning - the contrapositive.)
6.2
Using the notation
UB(S) = {u ∈ℝ∣u is an upper bound on the set S}
set in the proof of the alternate completeness axiom, ﬁnd
(a) UB(A) for A = {x ∈ℝ∣x < 5}.
(b) UB(B) for B = {x ∈ℝ∣x ≤5}.
(c) UB(C) for C = {5}.
(d) UB(D) for D = {4, 5, 6}.
(e) UB(E) for E = {x ∈ℤ∣x < 5}.
(f) UB(F) for F = {x ∈ℤ∣x ≤5}.
6.3
For any subset S ⊆ℝ, let
LB(S) = {l ∈ℝ∣l is a lower bound on the set S}.
Prove that if s ∈S, then s is an upper bound of LB(S).
6.4
Let A be a set of real numbers.
(a) Prove that if A has an upper bound, then A has an upper bound that
is a natural number.

6.3 Problems
91
(b) Prove that if A has a lower bound, then A has a lower bound that is
an integer.
(c) Prove that if A has a lower bound and an upper bound, then there
is a natural number n so that n is an upper bound and −n is a lower
bound of A.
(d) Prove that A is bounded (above and below) if and only if there is
n ∈ℕso that for all x ∈A, −n ≤x ≤n.
(e) Prove that A is bounded (above and below) if and only if there is
n ∈ℕso that for all x ∈A, −n < x < n.
6.5
Let a, b ∈ℝwith a < b. Prove that there exists s ∈ℝsuch that a < s < b.
6.6
Let a, b ∈ℝwith a < b. Prove that there exists s ∉ℚsuch that a < s < b.
(Hint: do not reprove the density theorem to prove this. Rather, use it on
the numbers
a
√
2 and
b
√
2.)
6.7
Prove if a, b ∈ℝ, with a < b then for all n ∈ℕ, there are numbers
x1, x2, … , xn−1, xn ∈ℚ, all diﬀerent, so that for all i = 1, 2, 3 … , n, we
have a < xi < b. (This is easy if you rewrite the theorem in a better
form.)
In problems 8–13, consider the sets
A = {r ∈ℤ∣5 < 2r};
B = {r ∈ℤ∣5 ≤2r};
C = {r ∈ℚ∣5 < r};
D = {r ∈ℚ∣5 ≤2r};
E = {r ∈ℝ∣5 < 2r};
F = {r ∈ℝ∣5 ≤2r}.
6.8
For which of the sets A through F is there a rational number that is a
lower bound on the set?
6.9
For which of the sets A through F is there a rational number that is a
greatest lower bound on the set?
6.10
For which of the sets A through F is there a rational number that is a
minimum of the set?
6.11
For which of the sets A through F is there a real number that is a lower
bound on the set?

92
6 The Real Numbers
6.12
For which of the sets A through F is there a real number that is a greatest
lower bound on the set?
6.13
For which of the sets A through F is there a real number that is a mini-
mum of the set?
In problems 6.14–6.19, consider the sets
A′ = {r ∈ℤ∣5 < 2r3};
B′ = {r ∈ℤ∣5 ≤2r3};
C′ = {r ∈ℚ∣5 < r3};
D′ = {r ∈ℚ∣5 ≤2r3};
E′ = {r ∈ℝ∣5 < 2r3};
F′ = {r ∈ℝ∣5 ≤2r3}.
6.14
For which of the sets A′ through F′ is there a rational number that is a
lower bound on the set?
6.15
For which of the sets A′ through F′ is there a rational number that is a
greatest lower bound on the set?
6.16
For which of the sets A′ through F′ is there a rational number that is a
minimum of the set?
6.17
For which of the sets A′ through F′ is there a real number that is a lower
bound on the set?
6.18
For which of the sets A′ through F′ is there a real number that is a greatest
lower bound on the set?
6.19
For which of the sets A′ through F′ is there a real number that is a mini-
mum of the set?
6.20
Prove that if a ∈ℝ, then there exists n ∈ℕso that a < 10n.
6.21
Let a ∈ℝ.
(a) Prove that for all n ∈ℕ, there is m ∈ℤso that 10nm ≤a ≤10n
(m + 1).
(b) What does notation a say about approximating real numbers with
decimals?
6.22
Let S = {r ∈ℚ∣there is an n ∈ℕsuch that r = 10n−1
10n }.

6.4 Appendix
93
(a) Prove that S has at least one element.
(b) Prove that S has at least one upper bound.
(c) Prove that S has a real number that is its least upper bound.
(d) What does this tell you about u = 0.99999 · · ·?
(e) Can you guess what the real number u is?
6.4
Appendix
If our intuition serves us well, a complete ordered ﬁeld should ﬁll in all the holes
in the rational numbers and provide us with enough numbers to measure any
length exactly. Of course, we still need to prove this.
One of the goals of this study is to do just that. The intermediate value
theorem will basically guarantee that every polynomial that can have a real
root does have one. It actually does a great deal more.
Until we have all the mathematical machinery necessary to prove this general
result, we should at least see that the problem that alerted us to the need for
more than just rational numbers has been ﬁxed. There is a square root of 2 in
the real numbers. The proof of this is specialized to this one case, and it is only
presented to prove an unsurprising result that follows from completeness.
Theorem 6.4.1.
There is an r ∈ℝso that r2 = 2.
Proof. Let
S = {x ∈ℝ∣x > 0 and x2 ≥2}.
(6.18)
Now 4 ∈S, so S has at least one element. In addition, by its very deﬁnition, S
has 0 for a lower bound. Since ℝis a complete ordered ﬁeld, S has a greatest
lower bound. Call it m.
Thus,
• If s ∈S, then m ≤s.
• If b is a lower bound of S, then b ≤m.
• If c > m, then c is not a lower bound of S.
Claim. We claim that m > 0.
Proof of claim. Now 0 is a lower bound of S, but that is only enough to tell us
that m ≥0. We need to be a bit better. We see that if 0 < x < 1, then x2 < 1. So
if s ∈S, then s ≥1. This makes 1 a lower bound of S; so m ≥1 > 0.
◾
Consider
r = m
2 + 1
m = m2 + 2
2m
(6.19)

94
6 The Real Numbers
Claim. We claim that r2 ≥2.
Proof of claim. Now
r2 −2 =
(m
2 + 1
m
)2
−2
(6.20)
= m2
4 + 1 + 1
m2 −2
= m2
4 −1 + 1
m2
=
(m
2 −1
m
)2
≥0.
◾
Since m > 0, we also have r > 0. Thus, with this claim, we have r ∈S. This
means
m ≤r = m
2 + 1
m,
(6.21)
and so,
m
2 ≤1
m,
(6.22)
Thus, we have
m2 ≤2.
(6.23)
If m2 = 2, then we have completed the proof.
So we assume by way of contradiction that
m2 < 2.
(6.24)
Consider 2
r . Since r2 ≥2, we have 1
r2 ≤1
2, and so 4
r2 ≤2. And so
(2
r
)2
≤2.
(6.25)
But
2
r −m =
4m
m2 + 2 −m
(6.26)
= 4m −m3 −2m
m2 + 2
= m
(
2 −m2
m2 + 2
)
.
Since we have m > 0 and m2 < 2, this is positive. So
2
r > m.
(6.27)

6.4 Appendix
95
But m is the greatest lower bound of S; so 2
r cannot be a lower bound of S. There
must be some s ∈S so that s < 2
r . But s ∈S, so s > 0 and s2 ≥2. Since 0 < s < 2
r ,
we have
s2 <
(2
r
)2
.
(6.28)
But then
2 ≤s2 <
( r
2
)2
≤2.
(6.29)
This is the contradiction we want. So we must have m2 = 2.
◽

97
Part II
Logic, Sets, and Other Basics

99
7
Logic
Now that we have a precise deﬁnition of the real numbers, we want to put it to
use proving that the real numbers have all the properties we need. Before we do
this, we want to set the ground rules about the methods we use in our proofs.
Logic is the background of every proof. We will begin by discussing the logic of
mathematical statements. Mathematical statements are sometimes also called
propositions, and their logic is called propositional logic.
7.1
Propositional logic
7.1.1
Logical statements
A logical statement is a declarative sentence that is unambiguously either true
or false but not both. The following are all examples of logical statements in
Mathematics:
⋅5 is an integer;
⋅𝜋e < e𝜋;
⋅−5 is not a rational number; ⋅11 is even;
⋅2 ≤5;
⋅
√
2 ∈ℚ;
⋅22 = 5;
⋅∫
𝜋
2
−𝜋
2 Sin(x) dx = 0.
Logical statements must be either true or false, and indeed, some of these
examples are true and others false. Now in English grammar, a simple declara-
tive sentence has a word that is identiﬁed as the verb, a noun that is identiﬁed
as the subject, and a noun that is identiﬁed as the object. Other words are
classiﬁed as parts of speech such as adjective, adverb, or article. Logically, it
can help to just concentrate on the subject, verb, and object. We can think
of an entire English phrase as serving as the subject, as the verb, or as the
object.
Consider the example 𝜋e < e𝜋. The English phrase “Pi to the e power” is the
logical subject; the English phrase “is less than” is the logical verb, and the
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

100
7 Logic
phrase “e to the power 𝜋” is the logical object. In the example
√
2 ∈ℚ: “the
square root of 2” is the subject, “is an element of ” is the verb, and “the set of
rational numbers” is the object.
We call the truth or falsity of a logical statement the truth value of that state-
ment. We use the capital letters T and F to denote truth and falsity. So, when
a statement is true, we say that it has truth value T, and when it is false, we say
that it has truth value F.
7.1.2
Logical connectives
Logical statements can be combined to form longer compound logical
statements using logical connectives. The typical connectives correspond to
the English words “not,” “and,” “or,” and the conditional phrase “if…then.” But,
we will see some important diﬀerences between the typical English usage of
these connectives and their deﬁnitions in logic.
We ﬁrst consider negation.
Deﬁnition 7.1.1.
Let P be a logical statement. Then “not P” is a logical state-
ment whose truth value is the opposite of the truth value of P.
We will denote “not P” as “∼P.”
One way to view the meaning of a compound logical statement is to compare
the truth value of the compound statement to every possible combination of
truth values of the statements that make it up. The table of these comparisons
is called a truth table for the statement. The truth table for ∼P is
P
∼P
T
F
F
T
The next way of combining logical statements uses “and.”
Deﬁnition 7.1.2.
Let P and Q be logical statements. Then “P and Q” is the
logical statement that is true when both P and Q are true, but false otherwise.
We denote “P and Q” as “P ∧Q.” The truth table for P ∧Q is
P
Q
P ∧Q
T
T
T
T
F
F
F
T
F
F
F
F

7.1 Propositional Logic
101
Next is the conjunction “or.” Here we encounter an important distinction
between how the word “or” is typically understood in everyday English and how
it is understood in logic and mathematics.
Consider two examples of the colloquial use of the word “or.” When a parent
asks a six-year-old if he/she wants chocolate milk or soda with lunch, the parent
almost deﬁnitely means that the child can have one or the other but not both.
This is the exclusive meaning of “or”: one or the other but not both. On the other
hand, suppose a professor were to say of one of her students, “Her grades are so
good that she’s either very bright or studies hard.” In saying this, the professor
should not be interpreted as excluding the possibility that the student is very
bright and also studies hard. This is the inclusive meaning of “or”: one or the
other or both.
Unlike a natural language such as English, logic cannot allow ambiguity in
statements. We must choose one or the other use of “or” for logic. For various
historical and technical reasons, the choice has been made that in logic and
mathematics, the word “or” always takes the inclusive meaning of the word. It
always means “one, the other, or both.” Accordingly, we provide the following
deﬁnition.
Deﬁnition 7.1.3.
Let P and Q be logical statements. Then, “P or Q” is the logi-
cal statement that is true when either P or Q or both are true, but false otherwise.
We denote “P or Q” as “P ∨Q.” The truth table for P ∨Q is
P
Q
P ∨Q
T
T
T
T
F
T
F
T
T
F
F
F
If we use this to analyze our idea of allowing an English phrase to be a logical
“verb,” we can make a very obvious observation that is easy to overlook when it
matters in a proof. The mathematical symbol “≤” means “less than or equal to.”
When we say this carefully, we realize that a statement that uses it is logically
compound. Thus, x ≤y means
(x < y) ∨(x = y).
(7.1)
Thus, if we know for sure that x < y, then we can also say that x ≤y because it
is true by the rules of logic. If we know for sure that x = y, then we can also say
that x ≤y because it is true by the rules of logic. On the other hand, if we know
that x ≤y is true, then we must consider either possibility. It just may be that
we cannot use this logically without separating it into the two diﬀerent cases

102
7 Logic
(x < y) and (x = y). We often do this so quickly that we do not notice it, but
there are times when explicitly considering two cases is the only way to go.
This oﬃcial deﬁnition of the word “or” also explains an extra word that has
appeared every time we used the term “trichotomy.” We say that a number sys-
tem satisﬁes trichotomy whenever it satisﬁes the following: if x, y are numbers,
then exactly one of the following are true: x < y, y < x or x = y. The word “ex-
actly” is very important in this deﬁnition; without it, the inclusive “or” would
take over and not give us the result we want. By saying “exactly one is true,” we
move to an exclusive “or” and say that no two of the three can be true at the
same time.
Next up is implication, which is used to construct conditional statements
–statements of the form “if…then.” Conditional statements can have many
interpretations in English. But as we saw with “or,” in logic and mathematics,
we must avoid ambiguity. The deﬁnition of the conditional statement that we
use in logic and mathematics is as follows.
Deﬁnition 7.1.4.
Let P and Q be logical statements. Then, “if P, then Q” is the
logical statement that is true when P is false or Q is true. It is false only when
both P is true and Q is false.
We often denote “if P, then Q” as “P ⇒Q.” It has the following truth table.
P
Q
P ⇒Q
T
T
T
T
F
F
F
T
T
F
F
T
The rules that govern this conjunction of statements can be puzzling at ﬁrst.
Remember that the rules of logic we are using require that a logical statement
be either true or false. You can think of the statement “if P, then Q” as a promise,
which says that “if it ever happens that P is true, then it must happen that Q is
also true.”
It makes no claim at all about what happens when P is false. But, if we admit-
ted that “if P, then Q” was noncommittal when P is false, and decided not to
add a value in our truth table, then we would not have deﬁned “if P, then Q”
as a completely logical statement. So we need to assign it a value of either true
or false in all cases. It would be wrong to call it false for being noncommittal.
Indeed, if P is not true, then the promise that Q will be true whenever P is has
not been broken. So, we give P ⇒Q credit only for what it claims. We do not
fault it for what it does not claim. So if P is false, the promise has not been
broken, and we count the statement P ⇒Q as true in that case.

7.1 Propositional Logic
103
But, this has a somewhat troubling consequence. It means that “false implies
anything” in the sense that no matter what the statement Q is, if the statement
P is false, then we count P ⇒Q as true. For example, consider the statements:
If 22 = 5, then
√
2 ∈ℚ.
If 22 = 5, then
√
2 ∉ℚ.
Logically, these are both true statements. It deﬁnitely seems odd to say that
both of these statements are true. But, logically, it has to work this way. Under-
standing the implication is very important, and we will have much more to say
about it next.
Here we have one last logical connective:
Deﬁnition 7.1.5.
Let P and Q be logical statements. Then, “P if and only if Q”
is the logical statement (P ⇒Q) ∧(Q ⇒P).
We denote “P if and only if Q” as either “P ⇔Q,” or “P iﬀQ.” The notation “P
iﬀQ” is read “P if and only if Q.” The truth table for this is
P
Q
P ⇔Q
T
T
T
T
F
F
F
T
F
F
F
T
Thus, “P if and only if Q” means that P and Q have exactly the same logical
truth values.
We often say that this means that P and Q are “equivalent.” However, there
are two ways that logical statements can be equivalent. We may prove the math-
ematical theorem:
In an ordered ﬁeld, a ⋅b = 0 if and only if either a = 0 or b = 0.
Since this is actually a compound logical statement, we would do this in
two steps: If a ⋅b = 0, then either a = 0 or b = 0. If either a = 0 or b = 0, then
a ⋅b = 0. Thus, the two statements “a ⋅b = 0” and “either a = 0 or b = 0” are
equivalent. They both have the same truth values because of what they mean.
There is a stronger way that two statements can be equivalent that does
not depend on their meaning, but only on their logical form. In this case, we
often say that the statements are “logically equivalent.” For example, no matter

104
7 Logic
what the logical statement P says or what it means, it is logically equivalent to
∼(∼P). To make this crystal clear, we will look at the truth tables:
P
∼P
∼(∼P)
T
F
T
F
T
F
The ﬁrst and last columns of truth values are exactly the same; the corre-
sponding statements are “logically equivalent.”
Logical equivalence gives us a handy proof technique. To prove a statement
R, it might be easier to prove a logically equivalent statement S. In a moment,
we will give a number of logical theorems that provide ways of rewriting logical
statements into logically equivalent forms. These will provide alternatives for
proving any number of later theorems.
We now deﬁne two last logical terms: tautology and contradiction. A tautol-
ogy is a statement that, because of its logical form, is always true. There are
plenty of ways that a tautology can be hidden in a compound logical statement,
but in the end, all tautologies come down to one example:
P ∨(∼P).
A contradiction is the exact opposite of a tautology; it is a statement that,
because of its logical form, is always false. Again in the end, all contradictions
come down to the example
P ∧(∼P).
Many proofs use a technique called “proof by contradiction.” To prove the
statement P, the proof argues that the statement (∼P) implies a contradiction.
The proof begins, as an implication, by assuming (∼P). The object is to ﬁnd a
statement R that allows us to prove R and allows us to prove (∼R). Then, we
need to prove
(∼P) =⇒(R ∧(∼R)).
If we do prove that this is true, then because the conclusion is a contradiction,
the truth table for “implies” tells us that (∼P) must be false. By our ﬁrst example
of a logical equivalence, P must be true.
7.1.3
Logical equivalence
We can now state several theorems about logical equivalence of compound
statements. Many of these look profound from a mathematical point of view,
and they would be if we were looking to develop a mathematical approach to
logic. But our goal is the opposite. We want to understand logic well enough to
help us analyze a mathematical statement or proof when things get confusing.

7.2 Implication
105
As a result, the ﬁrst theorem looks like it should be more useful that it actually
is.
Theorem 7.1.6.
Let P, Q and R be logical statements. Then the following pairs
are logically equivalent:
1. P and ∼(∼P);
2. P ∧Q and Q ∧P;
3. P ∨Q and Q ∨P;
4. (P ∧Q) ∧R and P ∧(Q ∧R);
5. (P ∨Q) ∨R and P ∨(Q ∨R);
6. P ∧(Q ∨R) and (P ∧Q) ∨(P ∧R);
7. P ∨(Q ∧R) and (P ∨Q) ∧(P ∨R).
All of these are proved by listing out the values in truth tables for each state-
ment in each pair. These proofs are not as much proofs as they are veriﬁcations.
The last six of these have mathematical descriptions: ∧and ∨are both commu-
tative, and both are associative. Each distributes over the other.
The next theorem comes up much more often and is important to remember.
We know this because it has a name.
Theorem 7.1.7
(De Morgan’s Laws). Let P and Q be logical statements.
Then, the following pairs are logically equivalent:
1. ∼(P ∧Q) and (∼P) ∨(∼Q);
2. ∼(P ∨Q) and (∼P) ∧(∼Q).
De Morgan’s laws are easy to remember, but easy to overlook when in a hurry.
To negate an “and” statement or an “or” statement, negate the parts, but remem-
ber to switch the connective. Again, the proofs simply construct the various
truth tables.
A ﬁnal few that actually do appear in mathematical proofs will ﬁnish this up.
Theorem 7.1.8.
Let P, Q, and R be logical statements. Then, the following pairs
are logically equivalent:
1. (P ∧Q) ⇒R and P ⇒(Q ⇒R);
2. (P ∨Q) ⇒R and (P ⇒R) ∧(Q ⇒R);
3. P ⇒(Q ∨R) and (P∧∼Q) ⇒R.
7.2
Implication
As we have noted, the “if…then” construction plays a very important role in
logic. Because of this, it has its own terminology.

106
7 Logic
Deﬁnition 7.2.1.
Consider the logical statement P ⇒Q.
1. P is called the hypothesis of the statement.
2. Q is called the conclusion of the statement.
3. When P ⇒Q is true, we say that P is suﬃcient for Q.
4. When P ⇒Q is true, we say that Q is necessary for P.
There are other logical implications associated with the implication P ⇒Q,
but saying that they are related to it is too strong. We will see what this means
in a moment. First,
Deﬁnition 7.2.2.
Consider the logical statement P ⇒Q.
1. The statement Q ⇒P is the converse of P ⇒Q.
2. The statement (∼P) ⇒(∼Q) is the inverse of P ⇒Q.
3. The statement (∼Q) ⇒(∼P) is the contrapositive of P ⇒Q.
The logical relationships between these various statements are very impor-
tant. Anytime a mathematical theorem takes the time to say that something
is not the case, it is a signal that there is an easy trap to fall into should we
ignore it.
Theorem 7.2.3.
Consider the logical statement P ⇒Q.
1. The statement and its contrapositive are logically equivalent.
2. The converse and its inverse are logically equivalent.
3. The statement and its converse have no logical relation.
4. The negation of the statement and the inverse of the statement have no logical
relation.
Proof. We simply ﬁnd and compare the truth tables:
P
Q
P ⇒Q
(∼Q) ⇒(∼P)
Q ⇒P
(∼P) ⇒(∼Q)
∼(P ⇒Q)
T
T
T
T
T
T
F
T
F
F
F
T
T
T
F
T
T
T
F
F
F
F
F
T
T
T
T
F
◽
We have claimed that some pairs have no logical relation. This is correct
because knowing that one is true does not pin down the other as either true or
false and because knowing that one is false does not pin down the other as either
true or false either. So knowing the truth value of one gives no information
about the truth value of the other. This is important; a common logical fallacy

7.3 Quantiﬁers
107
is to confuse an implication with its converse. Because these are not logically
related, this is a serious mistake.
So a common trap to fall into is to try to prove a statement of the form P ⇒Q
by proving the converse, Q ⇒P. Since a statement and its converse have no
logical connection, proving or disproving the converse gives no information
about the truth of the statement. Claiming a statement is true by oﬀering the
converse as evidence is an all too common logical fallacy. It is important to
avoid it in all situations, but particularly in Mathematics.
There is another common proof technique that does work because of this
theorem. To prove that a statement of the form P ⇒Q is true, we can prove
instead that the logically equivalent contrapositive, (∼Q) ⇒(∼P), is true. This
is often confused with a proof by contradiction. We will look at the diﬀerences
between a direct proof of P ⇒Q and proof of the contrapositive (∼Q) ⇒(∼P)
and a proof by contradiction (P∧∼Q) ⇒(R∧∼R) more carefully later.
Proof technique. We say that we have a direct proof of P ⇒Q when the proof
begins by assuming that the hypothesis is true and ends with stating that the
conclusion is true.
Proof technique. We say that we have proof by contrapositive when we prove
P ⇒Q by proving the contrapositive (∼Q) ⇒(∼P).
Proof technique. We say that we have proof by contradiction when we prove
P ⇒Q by proving (P∧∼Q) ⇒(R∧∼R).
7.3
Quantiﬁers
There is much more to propositional logic than we have just said, but rather
than continue to look at abstract logical statements, we will concentrate on,
what we will call mathematical statements.
It is convenient to think of a mathematical statement as a declarative sentence
that contains a parameter (or several parameters). The mathematical statement
only becomes a logical statement when a meaning is given to the parameter. The
truth value of the statement depends on that speciﬁc value of the parameter. For
example,
x2 = 9.
(7.2)
is a mathematical statement; it is by itself neither true or false. Years of algebra
training tempts us to turn it into a command sentence:
Solve x2 = 9 for x.

108
7 Logic
This requires adding extra words and still does not result in a logical statement.
(It is a command.) It is possible to make x2 = 9 true by choosing a good value
of x, but it is just as possible to make x2 = 9 false by choosing a bad value of x.
So, by itself, x2 = 9 is neither true nor false.
Turning any mathematical statement into a logical statement requires adding
extra words that qualify, or quantify, the variable. There are three ways to do
this: specify a value, assert existence, claim a universal.
7.3.1
Speciﬁcation
We can make x2 = 9 a logical statement by assigning a value to x:
For x = 3, x2 = 9.
(7.3)
For x = 7, x2 = 9.
The ﬁrst assignment makes it true, the second one makes it false.
We have been dealing with mathematical statements all through our previous
studies. Typically, they appear after an instruction:
Solve x2 = 9.
The instruction asks us to ﬁnd those values of x that make the mathematical
statement x2 = 9 true. Actually, we all know that it asks more than that, it asks
us to completely distinguish between the numbers x that make it true from
those that make it false. “For x = 3, x2 = 9” is a partial solution, but “For x = ±3,
x2 = 9” is a complete solution. It is complete because, for x = ±3, x2 = 9, and
for x ≠±3, x2 ≠9.
Now changing a mathematical statement such as x2 = 9 into a logical
statement using the word “for” is called “speciﬁcation.” We have qualiﬁed the
variable x by speciﬁcation.
7.3.2
Existence
There are two other ways to qualify a variable. The ﬁrst is the “existential” qual-
iﬁer:
There exists x ∈ℝ, such that x2 = 9.
Notice that typically this qualiﬁer comes with a scope or range that restricts
where a value of the variable may come from. The scope has as much to do
with the meaning of the logical statement as the mathematical statement. For
example, compare
There exists x ∈ℝ, such that x2 = 9.
There exists x ∈ℕ, such that x2 = 9.
There exists x ∈ℚ, such that x2 = 2.
There exists x ∈ℝ, such that x2 = 2.

7.3 Quantiﬁers
109
To prove a statement with an existential qualiﬁer, we usually need to do some
scratch work outside the proof. Typically, we create our own mathematical
problem to solve. To prove: there exists x ∈ℕsuch that x2 = 9, we ﬁrst solve
x2 = 9. After extensive algebraic manipulation learned in high school, we
ﬁnd x = ±3. To write up the proof that there exists x ∈ℕ, such that x2 = 9,
we only need to identify one of these that ﬁts all the requirements, x = 3,
and prove that it works: let x = 3; then 3 ∈ℕand x2 = 32 = 9. Neither the
solution of the equation nor the other integer solution −3 is required for the
proof. The existence qualiﬁer only requires one example. To prove existence,
we only need to show that there is one. This would be just as true as if
we were writing up a proof of: there exists x ∈ℝ, such that x2 = 9. The only
diﬀerence is that we could prove this by letting x = −3 to show oﬀour algebraic
skills.
Remember that the scopes matter. Now we have a theorem that says that
“There exists x ∈ℚ, such that x2 = 2” is false. We have an extreme conﬁdence
in our education, and we believe that “There exists x ∈ℝ, such that x2 = 2”
is true.
There is a notation for this qualiﬁer. We write “There exists x in the set S such
that P(x) is true” in either one of the following ways:
∃x ∈S such that P(x);
∃x ∈S so that P(x);
∃x ∈S s.t. P(x);
∃x ∈S ϶ P(x),
There is a good strategic reason to make it a point to recognize the “such that”
as an essential part of the notation.
7.3.3
Universal
The ﬁnal way to qualify a variable is with a universal qualiﬁer. To do this, we say
For all x ∈ℝ, x2 = 9.
Notice that this qualiﬁer also comes with a scope or range for the variable. To
qualify the variable in this particular example and produce a true logical state-
ment, we need to cut down the scope considerably:
For all x ∈{3, −3}, x2 = 9.
Or, we could get carried away and say
For all x ∈{−3}, x2 = 9.

110
7 Logic
There is a notation for this qualiﬁer as well. We write “For all x in the set S,
P(x) is true” as
∀x ∈S, P(x).
There is a good strategic reason to consider the comma as an essential part of
the notation.
To prove: “For all x in the set S, P(x) is true,” we can restate it as “If x in the set
S, then P(x) is true.” We have seen that we begin the proof of an “if…then” by
assuming the hypothesis. Actually, this exchange occasionally works the other
way. We may need to prove a statement that has the logical form ∼(P ⇒Q).
There is no nice logical equivalent statement to this that works very well.
(Remember that we cannot get anywhere by proving the inverse statement.)
However, if we can rephrase P ⇒Q as ∀x ∈S, Q(x), there is a nice logical
negation of that form.
7.3.4
Multiple quantiﬁers
Many important statements have more than one quantiﬁer in their statements.
Example 7.3.1.
The Archimedean principle states that
if r ∈ℝ, then there is an n ∈ℕso that r < n.
We can restate this as
for all r ∈ℝ, there exists an n ∈ℕso that r < n,
or
(∀r ∈ℝ, (∃n ∈ℕs.t. (r < n)).
The Archimedean principle is a doubly quantiﬁed statement with a com-
mon form: a universal quantiﬁer (∀) followed by an existential quantiﬁer (∃).
These are sometimes called AE statements. AE statements lead to the impor-
tant issue of naming objects. In all likelihood, the variable that the statement
says exists will depend on the universal variable that appears before it. Thus, in
the Archimedean principle, if r =
√
99, then n = 10 would do as the n ∈ℕ. But
for a diﬀerent r, say r =
√
400, then n would need to be at least 21. If we are
only going to use the statement
(∀r ∈ℝ, (∃n ∈ℕs.t. (r < n))
(7.4)
once in the proof, then this is a perfectly ﬁne way to write it. However, if we
expect that it will be used more than once for diﬀerent r ∈ℝ, then it might be
better to make it clear that n depends on r and write
(∀r ∈ℝ, (∃nr ∈ℕs.t. (r < nr)).
(7.5)

7.4 An Application to Mathematical Deﬁnitions
111
Less confusing, but still very important, are EA statements. Here is an example.
Example 7.3.2.
Let F be an ordered ﬁeld. The statement
there exists e ∈F such that for all a ∈F, a ⋅e = e ⋅a = a
can be rewritten
∃e ∈F s.t. (∀a ∈F, (a ⋅e = e ⋅a = a)).
As we have said, naming the variables is always a serious responsibility.
However, in EA statements, this usually does not include adding subscripts.
By its very meaning, ∃e ∈F s.t. (∀a ∈F, (a ⋅e = e ⋅a = a.)) says that one e will
work for all a.
Negating the statements with multiple quantiﬁers follows our aforemen-
tioned rules for negating the statements with a single quantiﬁer. We can step
through the process as in the example,
∼(∀r ∈ℝ, (∃n ∈ℕs.t.( r < n)));
∃r ∈ℝ, ∼(∃n ∈ℕs.t.( r < n));
∃r ∈ℝ, (∀n ∈ℕs.t. ∼( r < n));
∃r ∈ℝ, (∀n ∈ℕs.t. ( r ≥n)).
With practice, we can just ﬂip the quantiﬁers and negate the statement being
quantiﬁed.
∃r ∈ℝ, s.t. (∀n ∈ℕ, r ≥n).
As always, though, we only take a shortcut when we know it works, and if
we get confused, we go back and skip the shortcut. We will continue to see
mathematical statements with multiple quantiﬁers throughout this course.
7.4
An application to mathematical deﬁnitions
Mathematical deﬁnitions are logically “if and only if” statements. However,
there is a general tendency not to write them that way after they have been
identiﬁed as deﬁnitions. For example,
Deﬁnition: For n ∈ℤ, n is even if ∃k ∈ℤs.t. n = 2k.
Deﬁnition: For n ∈ℤ, n is odd if ∃k ∈ℤs.t. n = 2k −1.
Mathematical deﬁnitions are designed to make them easy to use in a proof. For
example,

112
7 Logic
Deﬁnition: Let S be a set of real numbers and m ∈ℝ. Then, m is a
minimum of S if
m ∈S,
(7.6)
and x ∈S ⇒m ≤x.
This is not the way anyone else would complicate the deﬁnition of such an easy
term. Still we have seen how handy splitting it into parts can be when struggling
with a proof.
Note that proper English grammar sometimes interferes with logical phras-
ing. Mathematicians are not above writing the deﬁnition of a lower bound as
Deﬁnition: If S is a set of real numbers and m ∈ℝ, then m is a lower
bound of S if, if x ∈S, then m ≤x.
The English sound of “if, if” is horrible. It is better to use alternate English
phrasing to avoid this:
Deﬁnition: If S is a set of real numbers and m ∈ℝ, then m is a lower
bound of S if x ∈S implies m ≤x.
Deﬁnition: If S is a set of real numbers and m ∈ℝ, then m is a lower
bound of S when, if x ∈S, then m ≤x.
Deﬁnition: If S is a set of real numbers and m ∈ℝ, then m is a lower
bound of S if ∀x ∈S, m ≤x.
Deﬁnition: If S is a set of real numbers and m ∈ℝ, then m is a lower
bound of S, meaning if x ∈S, m ≤x.
Mathematical deﬁnitions, unlike dictionary deﬁnitions, are not designed to
explain what a term means. A mathematical deﬁnition is a precise logical state-
ment that is interchangeable with the word. Here is an important deﬁnition of
a new mathematical term that we will use from now on in this study.
Deﬁnition 7.4.1.
For S a set of real numbers and m ∈ℝ, m is an inﬁmum of
S when
if x ∈S , then m ≤x,
and if l > m, then ∃x ∈S s.t. l > x.
Most people would say that this gives them no clue as to what the inﬁmum of a
set might actually be or what it might be good for. The thing about mathematical
deﬁnitions is that the people who made them up know very well what the term
they are deﬁning means. Further, they kind of expect that the people using the
deﬁnition will as well. A deﬁnition is chosen using a deep understanding of the
term as it will be used in Mathematics. The deﬁnition is written to make the idea

7.4 An Application to Mathematical Deﬁnitions
113
behind the term easier to use in proofs. The understanding of a mathematical
term comes before or after the deﬁnition, but only rarely with it.
So what the heck is an inﬁmum? Actually, it is something we have already
seen and used. First, we notice that, whatever an inﬁmum is, it is a lower bound
of S. This is the ﬁrst part of the deﬁnition. The part we need to understand is
the part of the deﬁnition that says
if l > m, then ∃x ∈S s.t. l > x.
We will slowly rewrite this using some of the logical tricks we have picked up.
Each rewrite in the following list is a simple change that produces a logically
equivalent statement of the one above it.
• If l > m, then ∃x ∈S s.t. l > x.
• If (l > m), then (∃x ∈S s.t. l > x). (Parsing)
• If ∼(∃x ∈S s.t. l > x), then ∼(l > m). (Contrapositive)
• If ∼(∃x ∈S s.t. l > x), then l ≤m. (Trichotomy)
• If ∀x ∈S, ∼(l > x), then l ≤m. (De Morgan)
• If ∀x ∈S, l ≤x, then l ≤m. (Trichotomy)
• If (∀x ∈S, l ≤x), then l ≤m. (Parsing)
• If (lis a lower bound of S), then l ≤m. (Deﬁnition)
• For all lower bounds l of S, l ≤m. (Rephrasing)
The ﬁrst condition tells us that the inﬁmum m is a lower bound of S, and
as it turns out, the second one tells us that for all lower bounds l of S, l ≤m.
Putting these together, we realize that the inﬁmum must be another name for
the greatest lower bound. This is worth noting.
Conclusion 7.4.2.
The inﬁmum of a set is the greatest lower bound of the set.
The inﬁmum is the same as the greatest lower bound. Why invent a stupid
new word for it and give it a deﬁnition that actually hides what it is? What is
wrong with saying, “the greatest of all the lower bounds?” Of course, there is
nothing wrong with that, but it is strategically better to use inﬁmum. A very
good reason to use the term “inﬁmum” and its deﬁnition is that they are much
more helpful when it is time to use them in a proof. The more we use this def-
inition, the more we will appreciate it. Still, why the stupid name? Basically, to
remind us to use the mixed-up deﬁnition. If we insist on using the term “great-
est lower bound,” we will often ﬁnd ourselves repeating the aforementioned
logical steps to convolute a “greatest lower bound” into a form that we can use.
With both names, we can switch back and forth between names at will. In those
times, and they do occur, when a greatest lower bound is easier to use compared
to an inﬁmum, we will be ready to make the switch.
Finally, here is a hint to help remember the deﬁnition of an inﬁmum: “m is the
inﬁmum of S means it is the greatest lower bound.” We should be ready to write

114
7 Logic
down what “m is a lower bound of S,” and this is part 1 of the deﬁnition. To say
that m is the greatest of the lower bounds, say “if l is a number greater than m,
then it is not a lower bound because there is a number x in S that prevents l from
being a lower bound because it is too small for l.” As we say this to ourselves,
we write
“If l is a number greater than m”
If l > m,
“it is not a lower bound because”
then
“there is a number x in S”
∃x ∈S
“that prevents l from being a lower bound”
s.t.
“because it is too small for l”
x < l.
7.5
Logic versus English
A very important thing to remember about the constraints of careful logic is
that they are meant to aid understanding. Logic is a technique of language that
can be used to attach a precise meaning to a phrase. Language itself is much
more expressive, it is not designed to be strictly logical, and it often is not.
Mathematician and writer Blaise Pascal said, “Words diﬀerently arranged have
a diﬀerent meaning, and meanings diﬀerently arranged have diﬀerent eﬀects.”
Turning everyday language into logic involves the translation of meaning
rather than the translation of words. English construction allows one to use
diﬀerent words to describe the same thing, but it also allows the same word to
describe diﬀerent ideas. Soon we will see a formal deﬁnition of the union of
two sets. If A and B are sets, the union of A and B is a set containing all the ele-
ments of A and all the elements of B. Notice how this idea is phrased using the
word “and.” We can also say that an element is in the union of A and B if it is in
either A or B. This time we used the word “or” to describe the union. It was the
English phrasing that allowed us to describe the union of two sets using each of
the words “and” and “or.” English grammar has allowed both words to convey
the same ultimate meaning. In logic, these two words have very distinct mean-
ings. De Morgan’s laws allow them to describe exactly the opposite meanings,
but not the same meaning.
English provides a method of conveying meaning, but it can be ambiguous.
Writers often delight in taking advantage of the ambiguity of language; and
some of the best examples cannot be attributed to one author or even one lan-
guage. An often quoted book review stated:
Your manuscript is both good and original; but the parts that are good
are not original, and the parts that are original are not good.

7.5 Logic Versus English
115
There is the apocryphal letter of recommendation that said:
You would be very lucky to get John Jones to work for you.
Compare the borderline English-Logic sentences:
a. If x = 2 or x = 5, then x2 + 10 = 7x.
b. For x = 2 or x = 5, x2 + 10 = 7x.
c. If x = 2 and x = 5, then x2 + 10 = 7x.
d. For x = 2 and x = 5, x2 + 10 = 7x.
e. If x = 2 or x = 5, then x2 + 6 = 5x.
f. If x = 2 and x = 5, then x2 + 6 = 5x.
It would be interesting to poll English speakers on what each of these sen-
tences mean and which are true. The results would most likely be far from
unanimous. There is a natural assumption in colloquial speech that a sentence
is meant to make sense and probably be true. So that will inﬂuence whatever
meaning we take from each of these sentences, and thus, it will aﬀect our judg-
ment about their truth. The question is, which of these sentences are saying that
both the numbers 2 and 5 are solutions to an equation, and which are saying
that at least one of 2 and 5 is a solution. Sentence (f) seems to be saying that
both are; so it is false. So, that would make the sentence (c) appear true and (d)
appear true as well. Sentences (a), (b), and maybe (e) are claiming that both are
solutions or only one is a solution; it is hard to tell. Either way, (a) and (b) seem
to be true, but (e) needs to be clariﬁed before we can know for sure. As English
sentences, these are pretty ambiguous. They convey a meaning but not a very
precise one.
If we knew for sure that these were meant as logical statements, we could ana-
lyze them using the rules of logic given earlier. Logic will remove the ambiguity
in these sentences as logical statements, but it will not cure the ambiguity as
English sentences. While it is clear what some of these sentences are meant to
say as sentences, forcing them into logical interpretations changes that mean-
ing. Parsed logically, sentence (a) has the form (P ∨Q) ⇒R. This is logically
equivalent to (P ⇒R) ∧(Q ⇒R), which makes it true. Sentence (e) has the
same logical structure, and it turns out to be false. Sentences (c) and (f) have the
form (P ∧Q) ⇒R; however, in both of these, (P ∧Q) is a logical contradiction.
Thus, they both end up logically true, but not at all because of their meaning
as English sentences. We may have noticed this because, in both, the English
grammar is a bit iﬀy, (sorry, irresistible.) Finally, strictly speaking, neither (b)
or (d) is a logical statement since in logic “for” is meant to specify one value for
the coming variable, not two. English allows the assumption that some addi-
tional words are implied by the “for” in the sentence; that is not the case in
logic.

116
7 Logic
Remember that, in both directions, the connection between everyday
language and logical writing is about the translation of meaning rather than
the translation of words. In other words, mathematics is supposed to make
unambiguous sense. Usually, logic helps mathematics make precise sense, but
at times it does not. While the rules of logic are exact and unforgiving, these
rules must be placed into English sentences where rules are less precise. A
mathematical proof is an irrefutable argument based on logic that a statement
is true. It is not a proof if it does not make sense or is too ambiguous. We have
no choice about the logical rules we must follow, but we do have a choice in the
words and grammatical structure we use to outline those logical arguments.
We have no choice about the rules for writing a Haiku, a Shakespearean
sonnet, or even a limerick; the quality of the result, however, depends on the
words we use. Writing good poetry and good prose takes practice and care.
The same is true about writing good mathematical proofs.
The Irish writer known as Lord Dunsany once said, “Logic, like whiskey, loses
its beneﬁcial eﬀect when taken in too large quantities.” Or perhaps, a less eru-
dite paraphrase of comedian Steven Wright makes the point better, “Logically
speaking, only a recluse can live in a house with a circular driveway.”
7.6
Problems
7.1
Prove that the following pairs of logical statements are equivalent:
(a) (P ∧Q) ∧R and P ∧(Q ∧R).
(b) (P ∨Q) ∨R and P ∨(Q ∨R).
(c) P ∧(Q ∨R) and (P ∧Q) ∨(P ∧R).
(d) P ∨(Q ∧R) and (P ∨Q) ∧(P ∨R).
7.2
Prove that the following pairs of logical statements are equivalent:
(a) (P ∨Q) ⇒R and (P ⇒R) ∧(Q ⇒R).
(b) P ⇒(Q ∨R) and (P∧∼Q) ⇒R.
(c) Explain in common terms what these mean.
7.3
Let S be a set of real numbers that is not bounded above. Prove that if
r ∈ℝ, then there exists an s ∈S such that r < s.
7.4
In several of our earlier proofs, we changed the deﬁnition of “m is a min-
imum of the set S” by writing the second condition as
if x < m, then x ∉S .
(a) Why was this logically correct?
(b) How many of those proofs can you identify?

7.6 Problems
117
7.5
Prove for all n ∈ℕ, if
n
∑
k=1
(4k3 −6k2 + 4k −1) = n4 −1,
then
n+1
∑
k=1
(4k3 −6k2 + 4k −1) = (n + 1)4 −1.
(Hint: Do not try logical tricks, just write a direct proof.)
7.6
Prove that the following logical statements are equivalent:
• (P ∧Q ∧R) ⇒S;
• (P ∧Q) ⇒(R ⇒S);
• (P ∧Q) ⇒(∼S ⇒∼R).
7.7
Go through the deﬁnition of an ordered ﬁeld and identify the logical
structure of each of the 16 properties. In particular, note any AE state-
ments and any EA statements and explain their meaning as it relates to
subsequent theorems about ordered ﬁelds.
7.8
Let F be an ordered ﬁeld. Let x ∈F with x ≥0. Consider the statement
if for all 𝜖> 0, x ≤𝜖, then x = 0.
(a) Write a contrapositive of this statement.
(b) Prove the statement.
(c) Why do some people call this result “The Average Theorem?”
(d) Remember this.
7.9
Prove that if n ∈ℤwith n2 even, then n is even.
7.10
Prove that for all n, m ∈ℤif nm is even, then either n is even or m is even.
7.11
We will rename the least upper bound of a set S to call it the supremum
of the set S. Write out a mathematical deﬁnition of the supremum of S.
7.12
Let S = {x ∈ℝ∣x−1 ∈ℕ}. Prove that 0 is the inﬁmum of S.
7.13
Let S = {x ∈ℝ∣x−1 > 0}. Prove that 0 is the inﬁmum of S.
7.14
Let S =
{
x ∈ℝ∣∃n ∈ℕs.t. x = n+1
n
}
. Prove that 1 is the inﬁmum of S.
(Hint: Archimedes has a trick for this.)

118
7 Logic
7.15
Use a calculator or computer to calculate
10∑
k=1
(4k3 −6k2 + 4k −1).
(a) Is the answer to part 1 (10)4 −1?
(b) Is the statement we proved in question 2 true? Is the proof correct?
7.7
Epilogue
There is more to this two-valued logic than we have let on. Even the ancient
Greeks, who almost worshiped logic, recognized that there were certain
problems with insisting that declarative sentences must be either true or false.
Consider the famous
This sentence is false.
We cannot say that this sentence is true, because it says that it is not. But
we cannot say that it is false, because then it would say that it was true. This
sentence references itself, and because of that, it cannot be assigned a value of
true or false without creating a logical contradiction.
Self-reference can cause another logical problem. Consider the apparently
less oﬀensive
This sentence is true.
This can certainly be considered a true statement without causing a contra-
diction. However, it can also be considered as false without a contradiction
either. To be a logical statement, it must be one or the other, but not both.
We have just seen two declarative sentences that cannot be logical statements
because of their form.
Consider the examples
The sentence below is false.
The sentence above is true.
and
The sentence below is true.
The sentence above is true.
We see that a statement can be self-referencing in a nondirect way. So we have
just seen declarative sentences that cannot be logical statements because they
reference other statements.
For millennia, logicians eliminated such statements from logical analysis by
simply saying, “Do not make self referencing statements.” In the early 20th cen-
tury, mathematicians and logicians tried to come up with a more formal set
of logical rules (axioms) that, when followed, would eliminate self-reference

7.7 Epilogue
119
once and for all. Their hopes of doing this were dashed when, in 1931, Kurt
Gödel proved that, in any system of numbers that included the natural num-
bers, self-referencing statements are inevitable.
In essence, Gödel proved that if we set up a set of rules for numbers, it is
always possible that we can make a logical statement that cannot be assigned a
value of true or false using just those rules. This statement will be undecidable
within those rules. That means we will never be able to prove it true or prove it
false using just the rules. Now it is not that mathematicians had no experience
dealing with such statements. At any moment in mathematics history, there
are plenty of mathematical statements that no one can prove are either true or
false. Prior to Gödel, however, mathematicians believed that in time, Mathe-
matics would develop enough power to do one or the other every time. Gödel
introduced the possibility that a speciﬁc mathematical statement might forever
remain undecided within the rules of the subject.
Mathematicians, however, typically remain optimistic, and they continue to
ask questions, give answers, and provide proofs that their answers are correct.
Even the oldest of open questions remain fodder for new mathematical work.
Perfect numbers such as 6 and 28 have been interesting to mathematicians for
over 2500 years. They are perfect because they are the sums of their proper
factors:
6 = 1 + 2 + 3;
(7.7)
28 = 1 + 2 + 4 + 7 + 14.
In all that time, no one has ever found an odd perfect number. But no one has
ever proved that no such number can exist. It could be that the statement “There
are no odd perfect numbers” is true. It could also be that it is false. After Gödel,
one could even speculate that it cannot be assigned a value of true or false using
the deﬁnition of ℕ. Undeterred by 2000 years of failure, many mathematicians
expect that it is either true or false, and many would predict that this question
will be resolved within the century. We have been making progress of late. So
a missing proof in Mathematics is more likely to be blamed on a shortage of
appropriate mathematics than on a quirk of Gödel’s logic. Nevertheless, Gödel’s
ideas actually give mathematicians extra tools that might shed light on or even
prove diﬃcult mathematical questions, maybe even this one.
The moral is, although we know that some self-reference is unavoidable in
Mathematics, in practice, we need only to take mild precautions to avoid it.
Gödel’s Incompleteness Theorem is not something that we should worry will
interfere with our study of numbers.

121
8
Advice for Constructing Proofs
8.1
The structure of a proof
8.1.1
Syllogisms
The basic idea behind mathematical proofs is the logical construct known as a
syllogism. Let P, Q, and R be logical statements. A syllogism is an argument of
the form:
If (P ⇒Q) and (Q ⇒R), then (P ⇒R).
We can check that this is valid by constructing a truth table for
((P ⇒Q) ∧(Q ⇒R)) ⇒(P ⇒R).
We should see that it is a tautology.
The table is large, so we break it into pieces. Let A stand for (P ⇒Q) ∧
(Q ⇒R):
P
Q
R
P ⇒Q
Q ⇒R
A
T
T
T
T
T
T
T
T
F
T
F
F
T
F
T
F
T
F
T
F
F
F
T
F
F
T
T
T
T
T
F
T
F
T
F
F
F
F
T
T
T
T
F
F
F
T
T
T
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

122
8 Advice for Constructing Proofs
P
Q
R
A
P ⇒R
A ⇒(P ⇒R)
T
T
T
T
T
T
T
T
F
F
F
T
T
F
T
F
T
T
T
F
F
F
F
T
F
T
T
T
T
T
F
T
F
F
T
T
F
F
T
T
T
T
F
F
F
T
T
T.
The backbone of any proof is an extended syllogism. Thus, the proof of P ⇒Q
should contain an argument that resembles
P ⇒P1.
P1 ⇒P2.
P2 ⇒P3.
P3 ⇒P4.
P4 ⇒Q.
Therefore, P ⇒Q.
All the statements are declarative sentences, and they are written as impli-
cations using “implies.” That requires a lot of repetition, and that can be
eliminated by hiding the implications in connected sentences. However, the
statements are still declarative sentences. The same argument could be written
as a sequence of sentences such as
Assume P.
Therefore P1.
So P2.
Thus P3.
Therefore P4.
And that implies Q.
Therefore, P ⇒Q.
The key is that each statement is true because of the statement directly
preceding it. The syllogism is indicated by any of the leading words: “so,”
“thus,” “therefore,” and “and that implies.”

8.1 The Structure of a Proof
123
8.1.2
The outline of a proof
Basically, a proof is an essay with a particular objective: to give an irrefutable
argument that a statement is true. Similar to any good composition, it is greatly
facilitated by an outline. The outline can include a title and sections with or
without headings. Sections should be organized into paragraphs, and para-
graphs are made up of sentences. In a proof, the role of the title is often played
by the statement being proved written carefully. The sections are any separate
parts, steps, or cases that are necessary for the proof. The sentences are logical
statements that are true under the assumptions of the proof. The paragraphs
should be complete extended syllogisms of the type described earlier. A para-
graph begins with a fact already established in the proof. It ends with a fact that
either completes the proof or cannot be rewritten logically to produce a new
true statement.
Some proofs are one paragraph long. For example,
Example 8.1.1.
If n ∈ℤis even, then n2 is even.
Proof. Assume n ∈ℤ. Assume that n is even. So there is k ∈ℤso that n = 2k.
Consider n2. Then n2 = (2k)2 = 2(2k2). Since 2k2 ∈ℤ, n2 is even.
◽
This is a one-paragraph proof because it is a single extended syllogism. It is
not written as a completely continuous syllogism. It starts with a logical state-
ment that is assumed to be true: “n is even.” This is rewritten using the deﬁnition
of the term “even.” This results in the second logical statement in the syllogism:
“There is k ∈ℤso that n = 2k.” The next sentence is not a logical statement; it
is a command sentence. It is not part of the syllogism, but it is an optional part
of the proof. It is an instruction to the reader and the writer about what to do
next. It is a kindness meant to make the proof easier to follow. The last logical
statement is transformed into the next by considering n2. We consider it by say-
ing something true about it based on the last statement in the syllogism. That
next statement is its own mini-syllogism: “n2 = (2k)2 = 2(2k2).” It is shorthand
for “n2 = (2k)2 and (2k)2 = 2(2k2), imply n2 = 2(2k2).” The ﬁnal logical state-
ment in the syllogism is “n2 is even.” However, the sentence containing “n2 is
even” provides a service for the reader and a check for the writer by ﬁrst pro-
viding a reason for this ﬁnal statement. At this point, the reader could draw the
ﬁnal conclusion obtained from such an argument that the original assumption
implies the ﬁnal conclusion. It could also be written to ﬁt the deﬁnition of even
exactly: “Let k′ = 2k2. Then k′ ∈ℕand n2 = 2k′. So by deﬁnition, n2 is even.”
In addition, the proof could have ﬁnished up with an explicit summary of what
was proved: “And therefore if n ∈ℤis even, then n2 is even.” Because the proof
is only one paragraph, the writer chose to let the reader draw this observation
alone and just used an end of proof symbol such as ◽.

124
8 Advice for Constructing Proofs
Many proofs require more than one paragraph. This happens when one or
two of the earlier assumptions lead to a conclusion, but that conclusion cannot
be pushed any further without other facts not yet available. The next paragraph
in the proof begins a new syllogism with facts that appeared before this last
paragraph and reaches its own conclusion. Then, a new paragraph begins with
the conclusions of both paragraphs and, by extended syllogism, reaches the
conclusion of the proof (if we are lucky).
Example 8.1.2.
The minimum of a set is unique.
Proof. We will prove: if m1 and m2 are both minimums of the set S, then
m1 = m2.
Comment: So this proof has another feature common in English compositions, a
preamble. Next, we begin the syllogism in the next paragraph.
Assume that m1 is the minimum of the set S. So we have m1 ∈S and if s ∈S,
then m1 ≤s.
Comment: This is the end of this two-sentence paragraph. It has ended with two
conclusions that we have no use for as yet. We know that m1 ∈S. We also know
that if s ∈S, then m1 ≤s. This means that if we ever ﬁnd an element of S, we
know something about it. We do have that m1 ∈S, but the conclusion m1 ≤m1
is not worth writing down as a new fact. Thus, the two facts we have just stated
are put aside, not yet used in the proof. We proceed by writing a new paragraph.
Assume that m2 is the minimum of the set S. So we have m2 ∈S and if s ∈S,
then m2 ≤s.
Comment: Again, we have a two-sentence paragraph that ends with two more
unused facts. But now all together, we have four unused facts. We can put two of
them together to begin our third paragraph.
We know that m2 ∈S and that if s ∈S, then m1 ≤s. Thus, m1 ≤m2.
Comment: We have another two-sentence paragraph. We use two of our earlier
facts and turn them into one new fact: m1 ≤m2. We can’t quite use it yet; so we
set it aside as an unused fact. But we return to the two remaining unused facts
from earlier and put them together in the fourth paragraph.
We also know that m1 ∈S and that if s ∈S, then m2 ≤s. Thus, m2 ≤m1.
Comment: We have another two-sentence paragraph. We use two of our ear-
lier facts and turn them into one new fact: m2 ≤m1. This time, however, we just

8.1 The Structure of a Proof
125
might add to the paragraph and use this right away with our only remaining
unused fact.
So we know that m1 ≤m2 and m2 ≤m1. By trichotomy, m1 = m2.
Comment: This is our ﬁnal paragraph. We can add one last summary paragraph
if we like.
We have proved that if m1 and m2 are both minimums of the set S, then
m1 = m2. Thus, the minimum of an set is unique.
◽
Let us write this out without the commentary. In addition, once we have used
the paragraph idea to outline the structure of our proof, maintaining this struc-
ture is optional. We can also add index numbers to make our references clearer,
but again this is optional.
Example 8.1.3.
The minimum of a set is unique.
Proof. We will prove: if m1 and m2 are both minimums of the set S, then
m1 = m2.
Assume that m1 is the minimum of the set S. So we have
(1) m1 ∈S, and
(2) if s ∈S, then m1 ≤s.
Assume that m2 is the minimum of the set S. So we have
(3) m2 ∈S, and
(4) if s ∈S, then m2 ≤s.
We know that (3) m2 ∈S and that (2) if s ∈S, then m1 ≤s. Thus, we have
m1 ≤m2.
We also know that (1) m1 ∈S and that (4) if s ∈S, then m2 ≤s. Thus, we have
m2 ≤m1.
So we know that m1 ≤m2 and m1 ≤m2. By trichotomy, m1 = m2.
We have proved that if m1 and m2 are both minimums of the set S, then
m1 = m2. Thus, the minimum of a set is unique.
◽
Some proofs have parts or steps that separate the paragraphs into sections or
parts.
Example 8.1.4.
For all n ∈ℕ,
n∑
k=1
k = n(n+1)
2
.
Proof. By induction.

126
8 Advice for Constructing Proofs
Step 1, the base step. We claim that if n = 1, then
n∑
k=1
k = n(n+1)
2
.
Proof of claim. Assume n = 1.
Consider
n∑
k=1
k. Then
n∑
k=1
k =
1∑
k=1
k = 1.
Consider n(n+1)
2
. We have n(n+1)
2
= 1⋅(1+1)
2
= 1.
So
n∑
k=1
k = 1 = n(n+1)
2
.
◾
Comment: This step is now complete. The proof of the claim it makes is over.
Everything identiﬁed as true in step 1 is now oﬀlimits for the remaining part
of the proof. If we need a particular statement in this step, it must be reestab-
lished under the assumptions of step 2. Nevertheless the statement itself has been
proved true; so it is fair game if we need it.
Step 2, the induction step. We claim
If
n0∑
k=1
k = n0(n0+1)
2
, then
n0+1
∑
k=1
k = (n0+1)(n0+2)
2
.
Proof of claim. Assume
n0∑
k=1
k = n0(n0+1)
2
.
Comment: What are we proving now? After this assumption, we need to prove
n0+1
∑
k=1
k = (n0+1)(n0+2)
2
. As we just saw, one way to prove that an equality of numbers
is true is to consider one side and then the other. This is not absolutely necessary if
we can carry out the algebra from one side straight to the other in one calculation.
We can even consider both side on scratch paper and fake the required algebra
skills by rewriting the calculation on one side backwards.
Consider
n0+1
∑
k=1
k. We have
n0+1
∑
k=1
k =
n0
∑
k=1
k + (n0 + 1)
(8.1)
= n0(n0 + 1)
2
+ (n0 + 1)
=
(n0
2 + 1
)
(n0 + 1)
= (n0 + 1)(n0 + 2)
2
.
◾

8.2 Methods of Proof
127
Step 3, the conclusion. By the theorem of induction, if a statement P(n) is
true for n = 1, and whenever P(n) is true for a particular n = n0, then it is true
for the next natural number n0 + 1, then we can conclude that it is true for all
n ∈ℕ. So
∀n ∈ℕ,
n
∑
k=1
k = n(n + 1)
2
.
◽
(8.2)
In writing this proof, we have been particularly kind. We added a step 3 where
we explicitly stated the theorem of induction, and we restated the theorem
that was proved. This is not uncommon when the theorem used to draw a
conclusion is surprising or less well known. But a proof by induction is so com-
mon that most proofs by induction end when the induction step is complete.
8.2
Methods of proof
8.2.1
Direct methods
8.2.1.1
Understand how to start
The default method for proving a mathematical statement is to write it as an
implication P ⇒Q and start the proof by assuming the hypothesis P. It is next
to impossible to emphasize how important this simple idea is:
Proof technique. Before we start a proof, we write what we are proving as an
“if…then” sentence. We start the proof by assuming the hypothesis.
It is astounding how diﬃcult learning and following this simple, one-sentence
lesson can be for even the best mathematics students.
Once we have the right start, a proof proceeds by using any assumption by
rephrasing it or reinterpreting it into a more useful form. If that more useful
form turns out to be the conclusion Q, a one-paragraph proof is complete. Mul-
tiple assumptions can lead to multiple paragraphs each ending with an unused
conclusion. These unused facts are combined in later paragraphs.
If simply working with P and its parts does not directly lead to Q, the focus
must change to Q. We ask ourselves, “How is Q proved?” The mistake many
people make in constructing a proof is to concentrate on the conclusion Q too
early.
Proof technique. Once a proof of P ⇒Q is started and assumptions are made,
the object becomes to prove Q. As any proof progresses, the exact statement being
proved at any moment changes as more assumptions are made and more facts
are established.

128
8 Advice for Constructing Proofs
When the question is, “How do I prove Q?” it might just as well be “What
does Q mean?” The answer should be phrased in one of four logical types of
mathematical statements:
• A declarative sentence in math terms;
• If P, then Q;
• For all s ∈S, P(s);
• There exists s ∈S s.t. P(s).
The important thing in determining the next step in the proof is the ﬁrst few
words in the answer to our “how” question. Are those ﬁrst words: “if”, “there
exists” or “for all”? If not, we rephrase the statement so it has one of these starts.
If we can maintain a logical discipline in constructing a proof, we have a
much better chance of succeeding. We only assume something because it is
the hypothesis of an implication we are proving. We only say things that follow
from the previous statement, and we always have a reason that guarantees that
it does indeed follow. The only valid reasons for making the next logical state-
ment in a theorem are as follows: a deﬁnition, a theorem, a basic property, or
a previously established fact in the proof. Basically, we say things that are true
for a reason and do not say things only because we hope that they are true.
In 1979, Douglas Adams wrote a book called The Hitchhiker’s Guide to the
Galaxy. It is a book about space hitchhikers who rely on the advice contained in
a guidebook as they tour the galaxy. The guide has its problems, but the hitch-
hikers chose it for reasons Adams explains:
“It is said that despite its many glaring (and occasionally fatal) inac-
curacies, the Hitchhiker’s Guide to the Galaxy itself has outsold the
Encyclopedia Galactica because it is slightly cheaper, and because it
has the words ‘DON’T PANIC’ in large, friendly letters on the cover.”
Adams, Douglas (1979). The Hitchhiker’s Guide to the Galaxy. Pocket
Books. p. 3. ISBN 0-671-46149-4.
As we continue our mathematical studies, we will be asked to prove more and
more mathematical statements. The most important thing to remember while
constructing a proof, especially at the beginning, is
Don’t Panic.
Always carrying a towel, as the Hitchhiker’s Guide also advises, is optional.
Whenever we hit an impasse in constructing a proof, we must not allow our-
selves to panic. We ask, “What do we know?” and “Can we simplify what we
know?” We ask, “What are we proving now?” and “What does that mean?” Next,
we will look at ways for dealing with “things we know” and “things we want to
prove.” If we are patient, we can often get our proof back on track.

8.2 Methods of Proof
129
8.2.1.2
Parsing logical statements
The ﬁrst step in constructing a proof is to completely understand what it is we
are proving from a logical point of view. That may require parsing the logic of
a compound sentence. Consider the following statement:
If x is less than a lower bound of the set S, then x is a lower bound of S.
This is not that diﬃcult to understand because we have used mathematical
terms to make it clear. If we rephrase it without using as many terms, it might
end up looking like
If x < m and if s ∈S, then m ≤s, then if s ∈S, then x ≤s.
This only makes sense, if it does at all, because we know where it came from.
Because of this, as we read it, we know how to parse it logically. We will make
this clear by using parentheses to separate the parts
If [(x < m) and (if s ∈S, then m ≤s)], then [if s ∈S, then x ≤s].
We should never be afraid to admit that something like
If x < m and if s ∈S, then m ≤s, then if s ∈S, then x ≤s.
is diﬃcult to understand. It could have looked even worse:
x < m ∧∀s ∈S, m ≤s ⇒∀s ∈S, x ≤s.
If a compound statement is confusing, the thing to do is parse it into its logical
components. We can use mathematical notation (parentheses) to help:
((x < m) ∧(∀s ∈S, m ≤s)) ⇒(∀s ∈S, x ≤s).
However, sometimes using English to decipher mathematical notation also
works. Here, attention to punctuation and grammar can help a lot.
In English composition and mathematical writing, not everyone follows the
rules we are about to outline; so in a sense, our rules are only guidelines. It
is, however, advisable to have our own ﬁxed rules for punctuation and gram-
mar to act as an aid to parsing logical statements. Making it a point to follow
these rules in our own writing can make them easier to apply when interpret-
ing someone else’s. How long we should stick to these rules is a matter of how
good we get at interpreting normal language as logically precise phrases. Here
are our grammatical rules.
First, every “if” should be associated with a “then.” It may be implied in an
English sentence, but in preparation for logical parsing, it helps to add it. The “if”
and its associated “then” form one logical phrase and must be parsed together as
one statement. It often helps to use a trick from algebra by adding parentheses

130
8 Advice for Constructing Proofs
or brackets about such a statement to hold it together. Remember though, the
phrases between an “if” and its “then” are themselves logical statements to be
parsed themselves, and they may deserve their own parentheses.
A “for all” should have a scope, but it will always have a mathematical
statement in the identiﬁed variable. The identiﬁcation of the variable and the
setting of the scope should be separated from the mathematical statement with
a comma. Just as an “if” is followed by a “then,” a “for all” is accompanied by
a comma. If it is not there, it should be added. Taking the time to distinguish
between the scope of the variable and the mathematical statement is vital to
understanding the logic of the statement. Both the scope and the mathematical
statement can themselves be compound, but a compound scope is almost
always the result of an “and.” The “∀” and its associated comma form one
logical phrase and must be parsed together as one statement.
Similarly, a “there exists” should have a scope, but it will always have a math-
ematical statement in the identiﬁed variable. Every “there exists” is paired with
a “such that.” If it is not there, it should be added. Again, taking the time to
distinguish between the scope of the variable and the mathematical statement
is vital to understanding the logic of the statement. The “∃” and its associated
“s.t.” form one logical phrase and must be parsed together as one statement.
We have made a big deal about identifying the scopes because, as De Morgan’s
laws illustrate, it is important when negating. In negating either a “∀” or a “∃,”
the scope does not change.
When parsing a logical statement, the logical phrases are not separated. Each
“if” has its “ then;” each “for all” has its comma, and each “there exists” has its
“such that.” We can use parentheses or brackets to collect phrases and their
parts into groups, but the main point is that components of a logical phrase are
inside nested parentheses.
All this structure helps, but in the end, it always is a matter of interpreting
the English sentence we are given.
Returning to our example,
If x < m and if s ∈S, then m ≤s, then if s ∈S, then x ≤s.
becomes
If (x < m and if s ∈S, then m ≤s), then (if s ∈S, then x ≤s).
(associating the ﬁrst “if” to its proper “then.”) In turn, this is
If ((x < m) and (if s ∈S, then m ≤s)), then (if s ∈S, then x ≤s).
The parts joined by the connectors “and” and “or” are easier to identify. The
ﬁnal nesting of component phrases may not add that much extra help and might
not be necessary.

8.2 Methods of Proof
131
If ((x < m) and (if (s ∈S), then (m ≤s))), then (if (s ∈S), then (x ≤s)).
Once we have understood the logical skeleton of our statement, it is easier to
start a proof correctly.
We see its logical outline as an implication of the form
(P ∧Q) ⇒R.
We might even see it parsed further as
(P ∧(Q1 ⇒Q2)) ⇒(R1 ⇒R2).
The proof is easy once we assume the hypothesis. We need to assume the
hypothesis of the theorem and not the hypothesis that appears in a component
of the hypothesis. So we concentrate on the simpler outline, (P ∧Q) ⇒R.
We assume
• P: x < m;
• (Q1 ⇒Q2): if s ∈S, then m ≤s;
• R1: s ∈S.
We do not assume Q1. The statement we can assume says, “If we ever have
anything in S, then we know something about it.” We cannot not assume that
we have s ∈S because of this. We can only wait for the proof itself to provide
us an element of S where we can use it. Luckily, the next assumption does just
that, and the proof is easy to complete.
8.2.1.3
Mathematical statements to be proved
One advantage we have in Mathematics is that the logical statements that
appear in our proofs come in only one of four forms:
• A declarative sentence in math terms;
• If P, then Q;
• For all s ∈S, P(s);
• There exists s ∈S s.t. P(s).
We can often ﬁnd ourselves in the middle of an extended syllogism and realize
that we are at a loss over what the next step should be. We have made some
assumptions, said what they meant, and left ourselves with paragraphs ending
in unused facts. We have tried but failed to put those facts together to draw
new conclusions. Our only hope to move forward is to try to provide the next
statement we want to prove with one on the three allowable logical beginnings:
“if,” “for all,” or “there exists.”
Only when we have run out of true things to say, do we ask ourselves, “What
are we proving now?” The answer should be its own full mathematical state-
ment. We have discovered some facts, but have also reduced our attention to
proving a sort of “mini-theorem” that will lead to our desired conclusion. As

132
8 Advice for Constructing Proofs
the proof progresses, the answer to the question “What are we proving now?”
changes. As we gather more unused facts, our mini-theorems should get easier
to prove.
Each of our mini-theorems will be phrased in one of the four allowable math-
ematical forms. We need a strategy for proving the statements in each of these
forms.
Declarative sentences. To prove a declarative sentence in math terms, we ask
ourselves, “What does it mean?” Since math terms have precise deﬁnitions, we
can rewrite the statement by removing the terms and using their deﬁnitions. For
numbers, “equals” means “are the same.” Our best hope is to consider each side
and use algebra to show that they are both equal to the same thing. A declarative
sentence such as “m is a lower bound of S” can be changed into an “if…then”
using the following deﬁnition: “If s ∈S, then m ≤s.” Some deﬁnitions will give
us “for all” statements or “there exists” statements. Others, such as “m is a mini-
mum of S,” will give us several things to prove. Whatever happens, this typically
changes the answer to the question “What are we proving now?” from a declar-
ative into a more manageable logical phrase.
Implications. At this point, we should know how to prove an implication,
P ⇒Q. We assume the hypothesis P. The answer to “What are we proving
now?” has changed to “Q.” This is what we do even if the implication appears as
a goal right in the middle of a long proof. This is always a very good thing. An
implication lets us assume more facts. More facts mean there are more things
we can combine into new facts. It gives us a second chance to look at any unused
facts that ended earlier paragraphs. If Q happens to be its own implication,
wonderful. That means we can make even more assumptions we get to use.
Universals. Proving a “for all” statement such as ∀s ∈S, P(s) is basically the
same as implication. We assume that s ∈S and try to prove P(s).
Note that things are quite diﬀerent if we assume “∀s ∈S, P(s).” If we have
found that a statement of the form ∀s ∈S, P(s) is a true fact by any means, we
should realize that it means
If I ever have an s in S, then I know something about it.
We cannot assume that s ∈S. But we will say more about this later.
But right now, we are considering how we prove a “for all” statement. In that
case, we can make a new assumption. In some ways, “if…then” and “for all”
statements are interchangeable. This works quite well when we are proving
them because it allows us to make a new assumption.
Existence. Proving a “there exists” statement is often the trickiest. To prove that
something exists, we need to ﬁnd one, and then prove that it works. Often, we

8.2 Methods of Proof
133
need to set up and solve a word problem in scratch work to even get started.
The key is that we can only use what we know we already have. Again, it will
still be up to the proof itself to give us the ingredients we need to construct the
thing we want. Our best bet is to be sure that we have drawn every possible
conclusion we can from the facts established so far in the proof. We should
take special note of any unused facts, since those are the best places to look for
methods for solving our word problem.
Example 8.2.1.
In this example, we develop a proof of the statement that
If n ∈ℤand n is odd, then n2 is odd.
The ﬁrst draft of the proof shows how we might think about the proof as we
attempt to discover it. A draft of a proof often includes comments and scratch
work not included in the ﬁnal version.
Proof draft. Assume n ∈ℤ. Assume that n is odd. Then by deﬁnition, there
exists k ∈ℤso that n = 2k −1.
Comment: What are we proving now? We want that n2 is odd. What does that
mean? We want to prove that ∃k ∈ℤs.t. n2 = 2k −1. Wait! Actually, no, we do
not. We have laid a trap for ourselves by choosing a bad name for the variable
we are looking for. We already have used the name k for another number. We
need to choose a better name. Let us start over where we last asked what we are
proving and make a better choice.
Comment: What are we proving now? We want to prove that n2 is odd. What
does that mean? It means we want to prove that ∃k′ ∈ℤs.t. n2 = 2k′ −1. Every
time we say “there exists,” we should pause and make a deliberate choice of the
variable we use to continue. To prove that something exists, we need to set up a
word problem and solve it.
Scratch work:
Find k′ so that n2 = 2k′ −1. We need to solve this for k′.
k′ = 1
2(n2 + 1)
(8.3)
= 1
2((2k −1)2 + 1)
= 1
2(4k2 −4k + 1 + 1)
= 2k2 −2k + 1.
Since 2k2 −2k + 1 ∈ℤthis should work. We go back to the proof.

134
8 Advice for Constructing Proofs
Let k′ = 2k2 −2k + 1.
Comment: Notice that this is not a logical statement, it is a command. It belongs
in the proof because it deﬁnes a piece of notation. What are we proving now that
we have identiﬁed a k′? We need to show that k′ ∈ℤand n = 2k′ −1.
Since k ∈ℤ, we have k′ = 2k2 −2k + 1 ∈ℤ. Also
2k′ −1 = 2(2k2 −2k + 1) −1
(8.4)
= 4k2 −4k + 1
= (2k −1)2
= n2.
So we have proved that there exists k′ ∈ℤsuch that n2 = 2k′ −1. By deﬁnition,
n2 is odd.
Δ
We have constructed a proof, but not a written one. In the ﬁnal version of
the proof, we do not need to explain how we got to the proof. We only need to
show that it works.
Theorem 8.2.2.
If n ∈ℤand n is odd, then n2 is odd.
Proof. Assume n ∈ℤ. Assume that n is odd. Then by deﬁnition, there exists k ∈
ℤso that n = 2k −1. Let k′ = 2k2 −2k + 1. Since k ∈ℤ, we have k′ = 2k2 −
2k + 1 ∈ℤ. In addition,
2k′ −1 = 2(2k2 −2k + 1) −1
(8.5)
= 4k2 −4k + 1
= (2k −1)2
= n2.
So we have proved that there exists k′ ∈ℤsuch that n2 = 2k′ −1. By deﬁnition,
n2 is odd.
◽
Notice that the sentence “Let k′ = 2k2 −2k + 1.” is an instruction. It is neither
true nor false; so it requires no justiﬁcation even though it is required to prove
that “there exists.” It must, however, be shown to be a correct instruction using
logical statements that are true because of the statement that follows the “let.”
So the proof must show that k′ has all the properties the “∃” statement requires
of it; that includes being within the scope.
Example 8.2.3.
There is another way that we can prove that something exists:
by magic.

8.2 Methods of Proof
135
Proposition 8.2.4.
The set S = {x ∈ℝ| ∃n ∈ℕs.t. x = n3 + 34n + 9} has a
minimum.
Proof. Let S = {x ∈ℝ| ∃n ∈ℕs.t. x = n3 + 34n + 9}.
Comment: We could set up a word problem to solve for a minimum. In the scratch
work we use to solve the problem, we can use any method we choose, from random
guessing to calculus. Once we think that we have it solved, we bring it back to the
proof and prove that it ﬁts the two requirements necessary for a minimum. But
we prefer to use magic.
We see that if x ∈S, then x ∈ℕ, because addition and multiplication keep
natural numbers in ℕ. In addition, 44 = 13 + 34 ⋅1 + 9 ∈S. Since S is a set of
natural numbers with at least one element, well ordering tells us that S has a
minimum.
◽
A result such as that in the last example is most likely to appear as a
“mini-theorem” reaching a goal set in the middle of a proof; that’s why we
called it a “proposition.” The word “lemma” would have also been an appro-
priate label. The result is not so much an independently interesting result, as it
is a method of creating a number out of nothing – magic. Typically, it would
allow us to name the minimum, say m; and then use m to continue the longer
proof.
Notice how many of our named theorems, principles, and axioms are set up
to guarantee that things exist. The well-ordering principle, the average theorem,
the division algorithm, the completeness axiom, the archimedean principle,
and the density theorem all give ways to show that a particular thing exists.
Proving that something exists is often the most challenging thing to prove. Any
theorem that makes something appear from a few simple assumptions is worth
remembering.
8.2.1.4
Mathematical statements that are assumed to be true
As we have seen, in a proof we often ﬁnd ourselves assuming things as facts
or drawing conclusions that we accept as new facts. Again, these only come in
four forms:
• A declarative sentence in math terms;
• If P, then Q;
• For all s ∈S, P(s);
• There exists s ∈S s.t. P(s).
Declarative sentences. If we have found that a declarative sentence in math
terms is true, we should immediately write it out using the deﬁnitions.
Of course, if we know that two things are equal, that means they are

136
8 Advice for Constructing Proofs
interchangeable. But as we will see, there are times when we are not talking
about the equality of numbers, and then a deﬁnition of that particular type
of equality will be important. This will make more sense as we encounter this
type of fact. More typically, the declarative sentence directly leads us to a
deﬁnition. We have already learned how this works with the minimum of a set.
When we say that m is the minimum of S, we follow it by saying, so m ∈S, and
if s ∈S, then m ≤s. One usable fact then becomes two more speciﬁc usable
facts. Spelling out those facts explicitly can help us ﬁnd them later in the proof.
Implication and universal. If we ﬁnd that either a “for all” or an “if…then” is true,
we should set oﬀon a search for a chance to use it. As pointed out earlier, if we
know that “∀s ∈S, P(s),” we can convert it to “If s ∈S, then P(s).” The important
thing to remember when we ﬁnd a true “if P, then Q” statement is that it does
not tell us that P is true. A true “If P, then Q” only means that “If we ever know
that P is true, then we can say something else.” We need to avoid the temptation
to assume we know that P is true.
Remembering this trick can help us maintain logical discipline. If we ﬁnd that
a statement such as either “P ⇒Q” or “∀x ∈S, P(x)” is true, we make it a point
to say to ourselves:
If I ever know that P is true, then I know something else.
or
If I ever have anything in S, then I know something interesting about it.
If we have identiﬁed that P ⇒Q is true, we should look for anything earlier
in the proof that tells us that P is true. Otherwise, we wait for the proof to
tell us that P is true from later assumptions. If we do not ﬁnd P earlier in the
proof, we end our current paragraph and put this fact aside unused. We start
a new paragraph with a new valid assumption or an unused fact from earlier
in the proof. If we do not have a good guess as to what to use to start the next
paragraph, we ask ourselves, “What are we proving now?” If we are lucky, it
will be an implication and we will gain a new assumption or two and be able to
conclude that P is true. Once we have established that P is true, we can say for
certain that Q is true.
All this is the same if we identify ∀s ∈S, P(s) as true. We should look for
anything earlier in the proof that is in the set S. We cannot be sure that the
thing we will use this on will be called s; so we need to look for anything in the
set. Knowing that ∀s ∈S, P(s) does not allow us to assume that we have an s.
Before the proof is over, we will probably need this fact. But before we can use
it, we must have something in S. (It may not be labeled s.) If we are lucky, there
will be an element x in S in our unused facts. We can say that P(x) is true right
away. Otherwise, we must wait for the proof to provide us with something in S.
Perhaps later, “What are we proving now?” will give us one.

8.2 Methods of Proof
137
Existence. If we ﬁnd that a “there exists” is true, we always know what to do
next. Such a statement is never the end of a syllogism paragraph. If we say, ∃
s ∈S s.t. P(s), our next step is to give it a name, but we need to do so wisely.
Never use a name that is already taken. There are two ways to do this: on the
ﬂy, we can say
∃s′ ∈S s.t. P(s′).
Or we can take a few steps:
∃s ∈S s.t. P(s). Call it s′. Then P(s′) is true.
An existence statement never ends a syllogism paragraph, because it creates a
new object that can be used elsewhere, and it states a fact about that object and
often two or more facts that will eventually be important.
Naming new objects is a great responsibility, and it almost always deserves
extra attention. With practice, it becomes easy to avoid using the same name
for more than one object. However, there is a situation where it is always easy
to slip up. Consider a proof where you assume or conclude an AE statement
such as
∀i ∈, ∃x ∈Ai s.t. P(x).
It could be that this is a case where one name is inadvertently being used for
more than one thing. It could be that there is only one x that is in every set Ai
for which P(x) is true, but this could be saying quite a bit more than we actually
know. It is much more likely that for each i ∈, there is a new xi ∈Ai such
that P(xi) is true. In almost all cases where we see a sequential ∀-∃phrase, (an
AE-statement), the “for all” signals the need for multiple names after the “there
exists.”
For an already familiar illustration of this, consider two familiar basic
properties we have used several times.
• ∃z ∈F, s.t. ∀r ∈F, r + z = z + r = r.
• ∀r ∈F, ∃s ∈F s.t. r + s = s + r = z.
The ﬁrst of these says that there is an additive identity in F. We know that we
can almost always prove that it is unique immediately. Thus, this element can
be given its own name; z will do, but 0 is a more common choice. The second
statement says that additive identities exist. However, because it is in the form
of an AE-statement, the object it says exists can and will depend on r. If we
know that addition is associative, we can prove that s is not completely unique
but is unique to r. When we assign a notation to the inverse, that notation −r
includes the starting r. In a less familiar setting, we should be more careful when
we hit the “∃” and choose the name that follows. It would be better to write
• ∀r ∈F, ∃sr ∈F s.t. r + sr = sr + r = z.

138
8 Advice for Constructing Proofs
If a “there exists” follows a “for all,” the name we choose should reﬂect this
sequential logical construction.
8.2.1.5
What do we know and what do we want?
Consider a logical statement of the form P ⇒Q. If we have assumed or con-
cluded that such a statement is true, we only know something if we ﬁnd that
P is true somewhere else in the proof. We need to be patient and let the proof
provide that information. We cannot ever just assume that P is true. However,
if we ask “What am I proving now?” and ﬁnd that the answer is P ⇒Q, that is
a diﬀerent situation. We can prove that P ⇒Q by assuming that P is true.
Consider a logical statement of the form ∀x ∈S, P(x). If we have assumed or
concluded that such a statement is true, we only know something if we ﬁnd
something in the set S somewhere else in the proof. We need to be patient
and let the proof provide that element. We cannot ever just assume that we
have x ∈S. However if we ask “What am I proving now?” and ﬁnd that the
answer is ∀x ∈S, P(x), that is a diﬀerent situation. We can prove ∀x ∈S, P(x)
by assuming that x ∈S. We should change the name, though, if x has already
been used elsewhere.
Consider a logical statement of the form ∃x ∈S such that P(x). If we have
assumed or concluded that such a statement is true, we name the element any-
thing we like and conclude that P(x) is true about it. Thus, we have created a
new object and a new true fact we can combine with other facts in the proof.
However if we ask “What am I proving now?” and ﬁnd that the answer is ∃x ∈S
such that P(x). We must ﬁnd one and prove that it works. Finding one requires
setting up and solving a word problem or using some magic theorem. After
that, the answer to the question “What am I proving now?” is P(s).
It is very important to distinguish why we are dealing with a particular state-
ment. How we proceed drastically depends on whether it is an established fact
or a statement to be proved.
8.2.1.6
Construction of a direct proof
With the foregoing discussion in mind, the key to constructing a proof is to
just keep saying things that are true. If we make the right start by assuming the
correct things, we can draw valid conclusions. If we get stuck and ask “What
am I proving now?,” we will know what to do next. If we draw a conclusion, and
that causes us to think of something to say, the question is not “Should we say
this?” The question is “Is this true?” If something is true, it is probably worth
saying. In addition, we should not assume that something is true unless there is
a logical reason to do so. Typically, there are only two good reasons to assume
that P is true:
• We are proving that P ⇒Q.
or

8.2 Methods of Proof
139
• We are starting a case, and somewhere else, we will assume ∼P and work
with that.
In addition, once a step or case is complete, any assumptions made in that
case are no longer valid. Thus, any conclusions drawn in that case are no longer
available in other parts of the proof. Cases are the equivalent of subroutines
in computer programs: the input comes from outside the subroutine; only the
identiﬁed output can be used outside the subroutine.
8.2.1.7
Compound hypothesis and conclusions
Finally, there are times where after parsing a statement to be proved, we ﬁnd
that it has the form (P1 ∧P2) ⇒Q. This is good because it allows us to start the
proof with two assumed facts: Assume P1. Assume P2. The more facts we know
are true, the more things we have to work with. We might also ﬁnd that we need
to prove a statement of the form (P1 ∨P2) ⇒Q. Here we can only assume P1
or P2. Since either one is potentially true, we have no choice but to break our
proof into two cases where we prove P1 ⇒Q in case 1 and P2 ⇒Q in case 2.
Instead of one mini-theorem to prove, we get two.
The situation is slightly diﬀerent when the compound sentence is in the con-
clusion. When we ﬁnd that we need to prove a statement of the form P ⇒
(Q1 ∧Q2), we actually have two mini-theorems to prove. We break a proof of
this into two steps (or parts): in step 1, we prove P ⇒Q1; in step 2, we prove
P ⇒Q2. This situation often occurs when we are trying to prove a mathemat-
ical deﬁnition that has two parts, such as m =Min(S) or s is the supremum
of A.
Those times where we need to prove a statement of the form P ⇒(Q1 ∨Q2)
can be the most vexing. There is no one rule of thumb that will always result in
progress. It might be that our assumption will need to be dissected into logical
cases before we can continue. We may need to write P as (P1 ∨P2) so that we can
prove P1 ⇒Q1 and P2 ⇒Q2. It is not always obvious how to do this breaking
up. One trick is to try to force a proof of P ⇒Q1. When that proof hits a point
where, with one extra condition, it will be complete, that condition might well
be the P1 and its negation P2. That being said, a lot of times, this whole puzzle
can be avoided. To prove P ⇒(Q1 ∨Q2), we can prove the logically equivalent
(P∨∼Q1) ⇒Q2. The extra assumption could be just what we need.
8.2.2
Alternate methods of proof
8.2.2.1
Contrapositive
Every so often, the direct approach to proving a statement of the form P ⇒Q
bogs down. We should not give up on our proof too early, though. We may
only need to start over at our most recent, “What are we proving now?” Still it
may mean that it is time to erase everything that we have done and start over
completely. Honestly, there are two possible reasons that our proof has bogged

140
8 Advice for Constructing Proofs
down: we are taking the wrong approach or we have made a logical mistake.
Either way, a fresh start at a proof of the statement P ⇒Q can be very helpful.
Once we have honestly concluded that the problem is with our approach to
the proof, we should consider proving the contrapositive (∼Q) ⇒(∼P).
Example 8.2.5.
If n, m ∈ℤand nm is even, then either n is even or m is even.
Proof draft. Assume n, m ∈ℕ. Assume that nm is even. Then ∃k ∈ℤs.t.
nm = 2k.
Comment: Now all we need to do is factor. But none of the basic properties of ℕ
allow us to factor. We know from school that ℤhas factoring properties, but we
cannot use them unless we prove them. This particular theorem is suspiciously
similar to one of the factoring properties we would want to prove. We have made
our assumptions, we have made a correct observation, but the form of that obser-
vation is not useful given what we know at this point. We could force the proof
onward by considering four cases: n and m are even; n and m are odd; n is even
and m is odd, or m is odd and m is even. But maybe it is just time to start over.
Let us erase the conclusion: ∃k ∈ℤs.t. nm = 2k. That came directly from the
assumption before this, so it should go as well. But we should not get carried away
here. It seems very clear that the assumption that n, m ∈ℤis something we want
to keep. If we cannot assume that the variables only stand for integers, this proof
will get pretty complicated pretty quickly. We will keep this assumption.
Δ
Proof draft. Assume n, m ∈ℤ.
Comment: Now what are we proving? If nm is even, then either n is even or m is
even. Let us use some mathematical notation and parse this implication clearly:
If (nm is even), then (either n is even or m is even.) The contrapositive of this is:
if ∼(either n is even or m is even), then ∼(nm is even). Using De Morgan’s Laws
and the theorem about odd and even numbers, this says: if ( n is odd and m is
odd), then (nm is odd). We go back to the proof.
We will prove: if (n is odd and m is odd), then nm is odd. Assume that n is
odd. Assume that m is odd. Then ∃k1 ∈ℤs.t. n = 2k1 −1. Also ∃k2 ∈ℤs.t.
n = 2k2 −1.
Comment: What are we proving now? nm is odd. How should we do this?
Consider nm. Now nm = (2k1 −1)(2k2 −1) = 4k1k2 −2k1 −2k2 + 1.
Comment: What are we proving now? ∃k3 ∈ℤs.t. nm = 2k3 −1. We need to set
up a word problem for scratch work.

8.2 Methods of Proof
141
Scratch work:
Solve the following for k3:
2k3 −1 = 4k1k2 −2k1 −2k2 + 1.
(8.6)
Then k3 = 2k1k2 −k1 −k2 + 1.
Let k3 = 2k1k2 −k1 −k2 + 1.
Comment: What are we proving now? k3 ∈ℤand nm = 2k3 −1. Both of these
are easy.
Because these are integers, k3 ∈ℤ. Consider 2k3 −1. Now 2k3 −1 =
2(2k1k2 −k1 −k2 + 1) −1 = 4k1k2 −2k1 −2k2 + 1 = nm. It follows that nm
is odd.
Δ
So the proof is constructed. We will leave it as an exercise to rewrite the proof
without all of the commentary.
Example 8.2.6.
In this example, we will develop a proof of the statement
If x ∈ℝand x ≥0, so that ∀𝜀> 0, x ≤𝜀, then x = 0.
Before starting the proof, let us parse the logic just to be sure we know what
this says: If (x ∈ℝ) and (x ≥0) and (∀𝜀> 0, x ≤𝜀), then (x = 0).
Proof draft. Assume x ∈ℝ. Assume x ≥0. Assume ∀𝜀> 0, x ≤𝜀.
Comment: If we ever have an 𝜀> 0, then we know something else. The proof has
not given us one yet, so we ask “What am I proving now?” The answer is x = 0.
That is absolutely of no help. It is time to try the contrapositive.
Δ
Proof technique. We know from logic that
(P ∧Q ∧R) ⇒T
is logically equivalent to
(P ∧Q) ⇒(R ⇒T).
This means that we can keep any parts of the hypothesis we like and only apply
the contrapositive to the bits we leave behind. This can really save a lot of work.
We will prove
If (x ∈ℝ) and (x ≥0) and (x ≠0), then (∃𝜀> 0 s.t. x > 𝜀).

142
8 Advice for Constructing Proofs
Proof draft. Assume x ∈ℝand x ≥0 and x ≠0. Then x > 0. What am I proving
now? (∃𝜀> 0 s.t. x > 𝜀). We need to set up a word problem to ﬁnd 𝜀> 0 so that
x > 𝜀. That is, we want 𝜀so that 0 < 𝜀< x. The magic of the average theorem
does this for us.
Δ
We will rewrite it in the ﬁnal form.
Proposition 8.2.7.
If x ∈ℝand x ≥0, so that ∀𝜀> 0, x ≤𝜀, then x = 0.
Proof. We will prove the contrapositive: if x ∈ℝand x ≥0 and x ≠0, then ∃𝜀>
0 s.t. x > 𝜀.
Assume x ∈ℝand x ≥0 and x ≠0. Then x > 0. Then by the average theorem,
there is an 𝜀∈ℝwith 0 < 𝜀< x.
◽
8.2.2.2
Contradiction
There is one more proof technique that we should have in our tool belt, a proof
by contradiction. It is easy to construct a proof by contradiction that actually
turns out to be either a direct proof or a proof by contrapositive. It is important
to examine every proof by contradiction for this before writing it up. To be a
true proof of P ⇒Q by contradiction, all the assumptions made at the begin-
ning, P and ∼Q, should be part of the reasoning in the middle of the proof, and
they should be used well before the ﬁnal contradiction is reached.
Example 8.2.8.
The inﬁmum of a set is unique.
Proof. We will prove: if m1 is the inﬁmum of S and m2 is the inﬁmum of S, then
m1 = m2.
Assume that m1 is the inﬁmum of S. Assume that m2 is the inﬁmum of S.
Then
1. If x ∈S, m1 ≤x.
2. If l > m1, then ∃x ∈S s.t. x < l.
3. If x ∈S, m2 ≤x.
4. If l > m2, then ∃x ∈S s.t. x < l.
Comment: We have four rather strong assumptions, but only those four. As far
as what they mean, they are not very helpful right now. Numbers 1 and 3 tell us
something if we ever have an element of S. Number 2 tells us something if we
ever have a number greater than m1. Number 4 tells us something if we ever
have a number greater than m2. None of the four actually give us an object that
any of them can tells us about. We need more! We might think that it is time
to start over by erasing some assumptions and trying a contrapositive. But all
four of these implications look pretty inviting; it would be a shame to give up

8.2 Methods of Proof
143
any of them. We want to keep all four of these facts, but we also need some more
assumptions so that we have a chance to use them.
Assume, by way of contradiction, that m1 ≠m2.
Comment: Because we kept all four of our facts, we are looking for opportunities
to use them. We are on the lookout for elements of S or numbers greater than m1
or numbers greater than m2. Our last statement doesn’t give any of these exactly,
but we know how it will lead to two cases.
By trichotomy, either m1 < m2 or m2 < m1.
Case 1: Assume m2 > m1. By aforementioned fact 2, we know that ∃x ∈S s.t.
x < m2.
We now have two more facts to work with: x ∈S and x < m2.
Since x ∈S, by aforementioned fact 3, m2 ≤x. But then by transitivity,
m2 ≤x < m2. This is a contradiction.
Case 2: Assume m1 > m2. By aforementioned fact 4, we know that ∃x ∈S s.t.
x < m1.
Since x ∈S, by fact 1, m1 ≤x. But then by transitivity, m1 ≤x < m1. This is a
contradiction.
In either case, we reach a contradiction, so our most recent assumption
cannot be true. We must have m1 = m2.
◽
Notice that the four facts drawn from the two original assumptions and the
assumption meant for contradiction are all used in the body of the proof. The
contradiction is reached in two separate cases that appear because of one of
these assumptions. This is truly a proof by contradiction.
There is a direct proof of the result in the last example, if we remember where
our deﬁnition of inﬁmum came from. The deﬁnition of m1 as the inﬁmum of
S is
1. If x ∈S, m1 ≤x.
2. If l > m1, then ∃x ∈S s.t. x < l.
But the ﬁrst says that m1 is a lower bound of S. The second is the contraposi-
tive of “If l is a lower bound of S, then m1 ≤l.” Together they say that m1 is the
greatest lower bound of S. If we remember that an inﬁmum is a greatest lower
bound, we can write a short direct proof.
Example 8.2.9.
The inﬁmum of a set is unique.
Proof. Assume that m1 is the inﬁmum of S. Assume that m2 is the inﬁmum of
S. Then since each is a lower bound, and each is a greatest lower bound, we have
m1 ≤m2 ≤m1. So m1 = m2.
◽

144
8 Advice for Constructing Proofs
Right now we are proving the results that are close to our deﬁnitions. It is
always good practice to use those deﬁnitions in our proofs. However, as we
prove more and more theorems, we have more and more results we can use in
our proofs. We are still using the deﬁnitions; it is just that they are hidden in
the proofs of the theorems we use to shorten the proof. Nothing saves time in
constructing and writing a proof as knowing and remembering the previously
proved results.
Example 8.2.10.
In this example, we will attempt a proof by contradiction of
the statement
If n, m ∈ℕand nm is even, then either n is even or m is even.
Notice that we proved this statement earlier for integers and not natural
numbers.
Proof draft. Assume that nm is even. Assume, by way of contradiction and
using De Morgan’s Law, that n is not even and m is not even. Then ∃k1 ∈ℕ
nm = 2k1 and ∃k2 ∈ℕs.t. n = 2k2 −1, and ∃k3 ∈ℕs.t. m = 2k3 −1. So
2k1 = nm
(8.7)
= (2k2 −1)(2k3 −1)
= 4k2k3 −2k2 −2k3 + 1
= 2(2k1k2 −k1 −k2 + 1) −1.
Claim. If k2, k3 ∈ℕ, then 2k2k3 + 1 > k2 + k3.
Proof of claim. Assume k2, k3 ∈ℕ. Then k2 ≥1 and k3 ≥1. So k2k3 ≥k3 and
k2k3 ≥k2. Adding these, we get 2k2k3 ≥k2 + k3. So this tells us that 2k2k3 + 1 >
k2 + k3. Thus, (2k2k3 −k2 −k3 + 1) ∈ℕ.
◾
Thus, 2k1 is odd. This contradicts our theorem that says that a natural number
cannot be both odd and even.
Δ
This proof we gave is not a proof by contradiction. The only place we used
the ﬁrst assumption was to reach the contradiction at the end. Thus, the log-
ical statement we proved was indeed (P ∧∼Q) ⇒(P ∧∼P), but we did it by
actually proving that (∼Q) ⇒(∼P).
This is a proof by contrapositive and should be rewritten that way.
Proposition 8.2.11.
If n, m ∈ℕand nm is even, then either n is even or m is
even.

8.3 An Example of a Complicated Proof
145
Proof. We will prove the contrapositive. Assume that n and m are both odd.
Then ∃k1 ∈ℕs.t. n = 2k1 −1; and ∃k2 ∈ℕs.t. m = 2k2 −1. So
nm = (2k1 −1)(2k2 −1)
(8.8)
= 4k1k2 −2k1 −2k2 + 1
= 2(2k1k2 −k1 −k2 + 1) −1.
Claim. If k1, k2 ∈ℕ, then 2k1k2 + 1 > k1 + k2.
Proof of claim. Assume k1, k2 ∈ℕ. Then k1 ≥1 and k2 ≥1. So k1k2 ≥k2 and
k1k2 ≥k1. Adding these, we get 2k1k2 ≥k1 + k2. So this tells us that 2k1k2 + 1 >
k1 + k2.
◾
Let k3 = 2k1k2 −k1 −k2 + 1. Then k3 ∈ℕand 2k3 −1 = nm. So nm is odd.◽
Proof technique. Anytime a proof is originally constructed using contradic-
tion, it should be examined before it is written to see if it is better explained as
either a direct proof or a proof by contrapositive.
8.3
An example of a complicated proof
Example 8.3.1.
Prove the division algorithm for ℕusing induction.
Proof draft. We will prove: If n, m ∈ℕand n ≤m, then either ∃q ∈ℕs.t.
m = nq, or ∃q, r ∈ℕs.t. m = nq + r with r < n.
Comment: Induction is used to prove a statement of the form ∀n ∈ℕ, P(n) is true.
Our theorem seems to be an implication with a hypothesis that is not “∀n ∈ℕ.”
No matter what we want to do eventually in a proof, we must ﬁrst maintain our
logical discipline. To prove a statement, begin by writing it as an “if…then” We
then begin the proof correctly by assuming the hypothesis.
Assume n, m ∈ℕ. Assume n ≤m.
Comment: Now what are we proving? For all n, m ∈ℕ, “something is true.”
Remember the important words in what we are proving are the ﬁrst ones. We
are trying to do this by induction. As we just said, induction is used to prove
a statement of the form ∀n ∈ℕ, P(n). That means we can only induct on one
variable, but it does not mean that the variable must be called n. We have
two variables, n and m, which should we induct on? We cannot forget any
assumptions we have made so far as we make this choice. Induction is all about
all natural numbers, no matter how large. If we induct on n, our assumption

146
8 Advice for Constructing Proofs
that n ≤m will mean that n can get no larger than m. That makes it a poor
choice for induction. On the other hand, n ≤m means that m can grow to any
size. We should induct on m. While we are doing this, we do not want n to
be moving around. We will prevent this from happening by ﬁxing it, that is,
assuming it to be some particular natural number, but we do not know or care
what number it is. We go back to the proof.
Fix n and use induction on m.
Comment: Let us set up our proof by induction carefully. We are proving ∀m,
P(m) is true. So P(m) is
(∃q ∈ℕs.t. m = nq), or (∃q, r ∈ℕs.t. m = nq + r with r < n).
We set up the induction writing out exactly what the two steps will be. The ﬁrst
step is the base, and the second the induction step. The base is the smallest value
of m that the theorem includes. The original theorem certainly includes all values
of m including the smallest number 1. But we have made some assumptions since
then that we have to honor to maintain our logic. We have assumed that m ≥n
and n is a ﬁxed number. The smallest value that m can take on at this point is n.
Step 1, The base. Here we must prove that if m = n, then either
1. ∃q ∈ℕs.t. m = nq, or
2. ∃q, r ∈ℕs.t. m = nq + r with r < n.
Step 2, The induction step. Assume that for m = m0, either
1. ∃q ∈ℕs.t. m = nq, or
2. ∃q, r ∈ℕs.t. m = nq + r with r < n.
With that assumption, we must prove that for m = m0 + 1, either
1. ∃q′ ∈ℕs.t. m = nq′, or
2. ∃q′, r′ ∈ℕs.t. m = nq′ + r′ with r′ < n.
Comment: It is good that we caught the need for new names in those second “there
exists.” That is why it is a good idea to take the eﬀort to write out our objective
as an implication and then to read it for its meaning before we start the proof.
Step 1: Assume m = n.
Comment: What are we proving now? Either n divides m with no remainder, or
it leaves a remainder. It looks like we have a choice as to what to prove, but not
really. We can only prove the one that is true. Luckily, because of the “or,” that is
all we need to prove.

8.3 An Example of a Complicated Proof
147
Let q = 1. Then m = n = n ⋅1 = nq. ◊
Comment: We chose to prove possibility 1 of the two allowed in the conclusion.
Because that conclusion is in the form of an “or” statement, we need only to prove
one of the possibilities. If we prove either one, we have completed the proof. We
chose to prove case 1 for the startlingly obvious reason that it was true under our
assumptions. We chose not to prove possibility 2 for the simple reason that it is
not true under the assumptions in this case.
Step 2: Assume either ∃q ∈ℕs.t. m0 = nq, or ∃q, r ∈ℕs.t. m0 = nq + r with
r < n.
Comment: We always start the proof of an implication by assuming the hypoth-
esis. In doing so, we have assumed that one of two things is true, but there is no
way to tell which one it is. The only way to proceed is to consider each case one
at a time.
Case 1: Assume ∃q ∈ℕs.t. m0 = nq.
Comment: It seems that q is a good enough name for it. The previous q was in
another step, under diﬀerent assumptions. It is gone by now. But, what are we
proving now? Either ∃q′ ∈ℕs.t. m0 + 1 = nq′, or ∃q′, r′ ∈ℕs.t. m0 + 1 = nq′ +
r′ with r′ < n. We have no way of telling which is true yet, so it looks like cases
exist in the future. But right now it is not clear exactly what those cases are. We
do notice that in either future case we need to say something about m0 + 1. So
we had better consider it and say something true about it.
Consider m0 + 1. Now m0 + 1 = nq + 1.
Comment: That looks good enough that we can take a guess about what to do.
Let q′ = q and r′ = 1.
Comment: What are we proving now? These values work for the second possibility
allowed in the statement. That is, m0 + 1 = nq′ + r′ and r′ < n. The ﬁrst of these
(m0 + 1 = nq′ + r′) is so obvious, it seems silly to bother writing it down. We will
anyway.
Now m0 + 1 = nq + 1 = nq′ + r′.
Comment: The second (r′ < n) seems just as obvious until we look for a reason
to say it. We said that n was ﬁxed, but we never said that it is not ﬁxed at 1. But
let us not panic and just keep moving. We cannot use our “ claim it, then prove
it” trick because “if n ∈ℕ, then n > 1” just is not true. We still will not panic,

148
8 Advice for Constructing Proofs
because we must be pretty close. We would have ﬁnished if we have n > 1. Let us
declare this a ﬁrst case and be over with it.
Subcase 1: Assume 1 < n. Then r′ < n. This proves that the second possibility
in the conclusion holds in this subcase. ◊
Comment: We indicated that we ﬁnished the proof in this subcase with a
diamond. That does not free us from proving that it works in the other case
though.
Subcase 2: Assume n = 1.
Comment: This is the case where the remainder r′ = 1 does not seem to work.
But something must. After all, we can divide by any natural number including
n = 1; why can’t we ﬁnd a remainder that works? OK once we say this, we realize
that it is silly. When n = 1, we cannot prove that there is a remainder because
it is not true. When we divide by 1, there is never a remainder. Back to ﬁnishing
the proof of case 1.
Let q′ = m0 + 1. Then m0 + 1 = 1 ⋅(m0 + 1) = nq′. This is the ﬁrst possibility
in the conclusion of the statement. ◊
The result is proved in Case 1. ⧫
Notice what happened here. At ﬁrst, we chose to prove possibility 2 of the
two allowed in the conclusion. Because that conclusion is in the form of an “or”
statement, we needed only to prove one of the possibilities. We chose to prove
possibility 2 because it looked like it was true. The “+1” in “m0 + 1 = nq + 1”
looked like a ﬁne remainder. Had it worked, we would have ﬁnished because
we only had to prove one of the allowed possibilities. Unfortunately, it did not
work completely. Had we tried to ﬁx it and prove possibility 2 anyway, we would
have failed. If r′ = 1 < n is not true, then possibility 2 is not true; so it cannot be
proved. If r′ = 1 = n, then r′ is not a valid remainder. If n = 1, only possibility
1 occurs. We need to break the proof in this case into two subcases.
Case 2: Assume ∃q, r ∈ℕs.t. m0 = nq + r with r < n. Consider m0 + 1. Then
m0 + 1 = nq + r + 1.
Comment: Why not, it worked the last time? What am I proving now? Either
∃q′ ∈ℕs.t. m0 + 1 = nq′, or ∃q′, r′ ∈ℕs.t. m0 + 1 = nq′ + r′ with r′ < n. This
time we promise to be less surprised when our ﬁrst guess leads us to a second case.
Let q′ = q and r′ = r + 1. Then m0 + 1 = nq + r + 1 = nq′ + r′.
Subcase 1: Assume r + 1 < n. Then we have r′ < n, and this proves that the
second possibility in the conclusion holds in this subcase. ◊
Subcase 2: Assume r + 1 ≥n.

8.4 Problems
149
Comment: There must be something that we know that we have not used yet.
It should be close by. We should back up through the proof one statement at a
time looking for it. Working through a speciﬁc example with numbers will help
ﬁnd this.
We said that r < n. So n ≤r + 1 < n + 1. But ℕis discrete, so this means
r + 1 = n.
Comment: We are still considering the old m0 + 1.
Then m0 + 1 = nq + r + 1 = nq + n = n(q + 1). If we let, q′ = q + 1, we have
proved that the ﬁrst possibility holds in this subcase. ◊
This ﬁnishes case 2. ◊
That ﬁnishes the proof.
Δ
We have constructed a proof, but not written it. We should write this proof
by identifying the subcases as early as possible. Outlined, the proof of step 2
will resemble the following:
Assume either ∃q ∈ℕs.t. m0 = nq, or ∃q, r ∈ℕs.t. m0 = nq + r with r < n.
Case 1: Assume ∃q ∈ℕs.t. m0 = nq.
Either n = 1 or n > 1.
Subcase 1: Assume n = 1.
Subcase 2: Assume n > 1.
Case 2: Assume ∃q, r ∈ℕs.t. m0 = nq + r with r < n. .
Since r < n and ℕis discrete, we have r + 1 ≤n.
Subcase 1: Assume r + 1 = n.
Subcase 2: Assume r + 1 < n.
8.4
Problems
8.1
Prove that the least upper bound of a set is unique.
8.2
Prove that the supremum of a set is unique.
8.3
Prove that if S is a set of real numbers that is not bounded above, then
∀x ∈ℝ, ∃s ∈S s.t. x < s.
8.4
Prove that if n ∈ℤ, then n(n + 1) is even.
8.5
Prove that if n ∈ℕand n2 is even, then n is even.

150
8 Advice for Constructing Proofs
8.6
Prove that the set
S = {x ∈ℝ∣∃s ∈ℝsuch that x = s6 + 19s4 + 11s2 + 14}
has an inﬁmum.
8.7
Let 𝛼, 𝛽∈ℝwith 𝛼< 𝛽.
(a) Prove that there exists s ∉ℚsuch that 𝛼< s < 𝛽.
(b) Prove for all n ∈ℕ, there are numbers x1, x2, … , xn−1, xn ∉ℚ, all
diﬀerent, so that for all i = 1, 2, 3 … , n, we have a < xi < b.
8.8
Prove for all n ∈ℕ,
n
∑
k=1
(4k3 −6k2 + 4k −1) = n4.
8.9
Prove that 1 is the supremum of the set
A =
{
x ∈ℝ∣∃n ∈ℕs.t. x =
n
n + 1
}
.
8.10
Prove that 2 is the inﬁmum of the set
B =
{
x ∈ℝ∣∃n ∈ℕs.t. x = 2n + 3
n + 1
}
.
8.11
Prove that if a ∈ℝand for all 𝜀> 0, a ≤𝜀, then a ≤0.
8.12
Use the fact that the order in ℕrespects addition and has trichotomy to
prove that
(a) If k, n, m ∈ℕwith n + k = m + k, then n = m.
(b) If k, n, m ∈ℕwith n + k < m + k, then n < m.
8.13
Prove that if r ∈ℝthen there exists n ∈ℕso that r < n2+100
n
. (Remember
that there is no theorem yet that tells us that every positive real number
has a square root.)

151
9
Sets
Perhaps, the most basic of mathematical objects is the set. Indeed, we have
referred to sets throughout the book so far, relying on an intuitive understand-
ing of the idea.
In Mathematics, a “set” is simply a collection of mathematical objects. We can
build sets of numbers, sets of functions, sets of matrices, and even sets of sets.
Of course, there are contexts in which we might talk about a set of people or a
set of cars. But our context is Mathematics, so we will only concern ourselves
with sets of mathematical objects.
9.1
Deﬁning sets
To deﬁne a set, we must precisely specify the members of that set. There are
many ways to do this. For example, we can deﬁne a set with an English sentence.
For example, we might say
Let A be the set of all even integers.
If A is the set of all even integers, then we would say that any particular even
integer, such as 2, is “a member of the set A” or “an element of the set A.” The ∈
symbol is used to express this more compactly. So, we write “2 ∈A” to say that
2 is a member of the set A. Since 3 is not in A, we would write 3 ∉A.
We have deﬁned the set A by stating a property that all members of the set
must have. This is very common. Usually, a set is determined by a mathematical
statement that describes a property that all members of the set share. 1 Another
way of writing this is with so-called set-builder notation. This is often more
1 We note here that there are deep and fascinating technical aspects of this description that we
will not address here. These diﬃculties will not matter to us in this course. See the epilogue to this
chapter for more information.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

152
9 Sets
compact than using English alone. Here is one way to deﬁne A in set-builder
notation:
A = {x ∣x is an even integer}.
(9.1)
In general, set-builder notation takes the form
S = {x ∣P(x) is true}
(9.2)
where P(x) is some mathematical statement. We read this deﬁnition of the set
S as “S is the set of all x such that P(x) is true.” So
s ∈S if and only if P(s) is true;
s ∉S if and only if P(s) is false.
There are some common variations on set-builder notation that you will see.
For example, people will often use a colon “∶” in place of the bar “|”. That is
ﬁne; the idea is the same. Sometimes, another condition on elements of a set is
slipped in before the “such that” symbol by limiting elements to members of a
larger set. For example, we could have deﬁned the set of even integers as this:
A = {x ∈ℤ∣x is even}.
(9.3)
Besides using English or set-builder notation to deﬁne sets, we can deﬁne sets
by simply listing their elements. For example, we can write
A = { · · · , −6, −4, −2, 0, 2, 4, 6, · · · }
(9.4)
to deﬁne the set of all even integers. But this really only works when the set
is small enough that all of its elements can be reasonably listed or when the
pattern is strong enough to be recognized. For example, we could write
B = {n ∈ℕ∣2 ≤n ≤5}
or
B = {2, 3, 4, 5}.
(9.5)
And, we could write
C =
{
x ∈ℝ∣∃n ∈ℕs.t. x =
n
n + 1
}
or
C =
{1
2, 2
3, 3
4, 4
5 · · ·
}
.
(9.6)
Some people might write that set C in a less standard form that reﬂects the
listed version more closely;
C =
{
n
n + 1 ∈ℚ∣n ∈ℕ
}
.
(9.7)
Which notation is the best? Well, when it comes to proving something about a
particular set, set-builder notation often works the best. Beyond that, we could
choose to aim for clarity and economy of expression.

9.2 Starting deﬁnitions
153
9.2
Starting deﬁnitions
Deﬁnition 9.2.1.
Let A and B be sets. We say that A is a subset of B when if
x ∈A, then x ∈B. We write this as A ⊆B.
For example, if A is a set of even integers, then A ⊆ℤ. Similarly, {2, 4, 6} ⊆A.
We know this because we can check that if x ∈{2, 4, 6}, then x ∈A. However,
notice that {2, 3, 4} A. It is not true that if x ∈{2, 3, 4}, then x ∈A. If A ⊆B,
we can also say that B is a superset of A and write B ⊇A.
Probably the most important thing to take away from the deﬁnition is that it
tells us how to prove that one set is a subset of another:
Proof technique. To prove that one set is a subset of another, A ⊆B, we
prove the implication if x ∈A, then x ∈B. Thus, the proof begins with “Assume
x ∈A.”
Notice that it would not be correct to say 2 ⊆A. It is correct to say 2 ∈A and
{2} ⊆A. But {2} and 2 are diﬀerent objects. That is, 2 ≠{2}. The set {2} is a
set containing the number 2. That is, 2 ∈{2}. As such, {2} is a subset of A, but
the number 2 is an element of A, not a subset of it.
Deﬁnition 9.2.2.
Let A and B be sets. We say that A equals B when A ⊆B and
B ⊆A. We write this as A = B.
This deﬁnition is important: it says that two sets are equal if they have the
same elements. The order in which the elements of a set appear does not matter.
Notice that this is not a requirement we place on sets, but rather it is a result
about sets that follows from the deﬁnition of equality.
Consider the sets
A = {1, 3, 4, 5};
(9.8)
B = {3, 5, 1, 4}.
Checking one element of A at a time, we ﬁnd that 1 ∈B, 3 ∈B, 4 ∈B, and
5 ∈B. Therefore, by the deﬁnition of subset, A ⊆B. Another element-by-
element check on B tells us that B ⊆A. Once we have both A ⊆B and B ⊆A,
by the deﬁnition of equality, A = B. Thus in practice, the order we use to list
or describe the elements of a set does not have an impact on what the set is
because of our deﬁnition of set equality.
Next, consider
C = {1, 3, 4, 5, 1, 4}.
(9.9)
Checking one element of A at a time, we ﬁnd that A ⊆C. Checking the elements
of C one at a time, we get 1 ∈A, 3 ∈A, 4 ∈A, 5 ∈A, 1 ∈A, and 4 ∈A.

154
9 Sets
So C ⊆A. We can also check that A ⊆C, and therefore, by deﬁnition, A = C.
Thus, repeating the elements in a set does not change the set. An element is
either in a set or not in a set; it cannot be in it more than once. Of course,
this could raise the philosophical question, are the two 5s in the list of set C
actually the same thing? After all, there are two of them. And what about the
set
D = {I,III,IV,V}?
(9.10)
The issue is, are we talking about sets of typed letters, symbols for numbers,
or actual numbers? This is Mathematics; so we are deﬁnitely talking about sets
of numbers. As numbers (in Arabic or Roman notation), certainly 1 = 1 = I;
3 = III; 4 = 4 = IV; and 5 =V. In Mathematics, the sets A = C = D are equal.
This is mostly philosophy, but it looks like President Bill Clinton was on to
something when he famously said, “It all depends on what your deﬁnition of
‘is’ is.”
When asked to prove that two sets are equal, it is important to remember the
following:
Proof technique. To prove that two sets are equal, it may be possible to consider
one side and use set properties to show that it is equal to the other. It is more
likely, however, that to prove that two sets are equal, A = B, we must prove the
subset both ways. Thus, proving A = B requires two steps. We must prove both
(1) A ⊆B and (2) A ⊇B.
We have one more deﬁnition related to subsets and set equality.
Deﬁnition 9.2.3.
Let A and B be sets. We say that A is a proper subset of B
when A ⊆B and A ≠B. There is no universally used notation for this.
We should note that some people use A ⊂B or A ⊊B for “A is a proper subset
of B.” Unfortunately, there are also people who use the symbol “⊂” for any sub-
set instead of the “⊆” that we use. It is an unfortunate loss of a good notational
opportunity, but it is just what has happened. There is no absolute standard
notation for the two subset relations: subset and proper subset. In this study,
we will just stick with the notation “⊆” for subset and explicitly use the word
“proper” if we need it. We can still use the symbol “⊂” for “proper subset” tem-
porarily if that is convenient.
9.3
Set operations
We now discuss how to build new sets from two or more given sets using set
operations. The ﬁrst is the union of two sets.

9.3 Set operations
155
Deﬁnition 9.3.1.
Let A and B be sets. Then
A ∪B = {x ∣x ∈A or x ∈B}.
(9.11)
We read A ∪B as “A union B.” Notice the logical connective word “or” in
the deﬁnition of the union. Remember that, in Mathematics, we always take
“or” to be inclusive. So, according to this deﬁnition, x ∈A ∪B if and only if
x ∈A or x ∈B or x is in both A and B. Notice that the language here can be
a bit awkward. In English, we would say that the union of two sets A and B is
obtained by creating a set with all the elements of A and all the elements of B.
This English description of A ∪B uses the word “and,” but the mathematically
correct deﬁnition of A ∪B, the one we will need to prove things, uses the word
“or.”
We also have a set operation that takes two sets and deﬁnes the collection of
objects that are simultaneously in both of those sets. This is called the intersec-
tion of the two sets.
Deﬁnition 9.3.2.
Let A and B be sets. Then
A ∩B = {x ∣x ∈A and x ∈B}.
(9.12)
We read A ∩B as “A intersect B.” Notice here the logical connective word
“and” in the deﬁnition of intersection. The last set operation we deﬁne here
employs the logical connective “not.”
Deﬁnition 9.3.3.
Let A and B be sets. Then
A∖B = {x ∣x ∈A and x ∉B}.
(9.13)
We read A∖B as “A not B.” We may also say that A∖B is the complement of
B in A. The direction of the slant in A∖B is important. We are saving the other
slant for another purpose. In addition, be careful about any English alternatives.
The next theorem is rather obvious. But to prove it formally, we would still
need to prove the subsets in both directions.
Theorem 9.3.4.
Let A, B, C be sets. Then
1. A ∪B = B ∪A;
2. A ∩B = B ∩A;
3. A ∪(B ∪C) = (A ∪B) ∪C;
4. A ∩(B ∩C) = (A ∩B) ∩C.
So in set theory, union and intersection are commutative and associative. We
will not bother to prove these, but notice that we must change one strategy we
use when structuring a proof. If we ﬁnd that we need to prove something like

156
9 Sets
(n + 2)2 = n2 + 4n + 4, we consider each side and use algebra. That is because
both sides are numbers, and algebra applies to numbers. If, however, we ﬁnd
that we need to prove
{n ∈ℤ∣n is even} = {n ∈ℤ∣n −1 is odd},
(9.14)
these are sets. To prove that sets are equal, we must prove the subset in both
directions. If we see a shortcut using the algebra of set theory, similar to the
aforementioned theorem, we will go for it. But most of the time, to prove for
two sets A = B, we must prove A ⊆B and B ⊆A.
Theorem 9.3.5.
Let A, B, C be sets. Then
1. A ∪(B ∩C) = (A ∪B) ∩(A ∪C);
2. A ∩(B ∪C) = (A ∩B) ∪(A ∩C).
So in set theory, union distributes over intersection and intersection dis-
tributes over union. This is a bit of set theory algebra that comes in handy fairly
often. There are several ways to prove this including a pictorial one using Venn
Diagrams. We will stick to using the deﬁnition of set equality just for practice.
We will prove the ﬁrst and use the second as an exercise. The proof of the ﬁrst,
however, uses a logical trick that is worth remembering. (Watch how we avoid
a bunch of subcases in step 2 using the logical equivalence of P ⇒(Q1 ∨Q2)
and (P ∧∼Q1) ⇒Q2.)
Proof. We will prove A ∪(B ∩C) = (A ∪B) ∩(A ∪C). This is a set equality, so
we must prove two statements
• A ∪(B ∩C) ⊆(A ∪B) ∩(A ∪C), and
• A ∪(B ∩C) ⊇(A ∪B) ∩(A ∪C).
Step 1. We claim that A ∪(B ∩C) ⊆(A ∪B) ∩(A ∪C).
Proof of claim. Assume x ∈A ∪(B ∩C). Then, either x ∈A or x ∈(B ∩C). So
we have two cases to consider.
Case 1: Assume x ∈A. Then x ∈A ∪B, no matter what B is. In addition, x ∈
A ∪C. By the deﬁnition of intersection, x ∈(A ∪B) ∩(A ∪C). So in this case,
x ∈A implies x ∈(A ∪B) ∩(A ∪C). Thus, A ∪(B ∩C) ⊆(A ∪B) ∩(A ∪C).
Case 2: Assume x ∈(B ∩C). Then x ∈B and x ∈C. But x ∈B implies x ∈
A ∪B. And x ∈C implies x ∈A ∪C. Since x is in both, x ∈(A ∪B) ∩(A ∪C).
So in this case, x ∈A implies x ∈(A ∪B) ∩(A ∪C). Thus, A ∪(B ∩C) ⊆
(A ∪B) ∩(A ∪C).
Therefore, we have proved A ∪(B ∩C) ⊆(A ∪B) ∩(A ∪C).
◾
Step 2. We claim that A ∪(B ∩C) ⊇(A ∪B) ∩(A ∪C).

9.3 Set operations
157
Proof of claim. Assume x ∈(A ∪B) ∩(A ∪C). Then x ∈A ∪B and x ∈A ∪C.
We will prove that x ∈A or x ∈B ∩C by proving that (x ∉A) ⇒(x ∈(B ∩C)).
Assume x ∉A. Since x ∈A ∪B, this means we must have x ∈B. In addition,
x ∉A and x ∈A ∪C tells us that x ∈C. Since x is in both, x ∈B ∩C.
We have proved that x ∈A or x ∈B ∩C. So we have proved x ∈A∪(B ∩C).
Therefore, (A ∪B) ∩(A ∪C) ⊆A ∪(B ∩C).
◾
In Step 1, we proved A ∪(B ∩C) ⊆(A ∪B) ∩(A ∪C). In Step 2, we proved
(A ∪B) ∩(A ∪C) ⊆A ∪(B ∩C). By the deﬁnition of set equality, the two steps
together tell us that A ∪(B ∩C) = (A ∪B) ∩(A ∪C).
◽
Theorem 9.3.6.
De Morgan’s Laws. Let A, B, C be sets. Then
1. A∖(B ∩C) = (A∖B) ∪(A∖C);
2. A∖(B ∪C) = (A∖B) ∩(A∖C).
We will leave the proofs of these as exercises.
The ﬁnal theorem consists of a few simple facts that appear very often in set
theory arguments.
Theorem 9.3.7.
Let A, B, C be sets. Then
1. If A ⊆B and B ⊆C, then A ⊆C;
2. A ∪B = A if and only if B ⊆A;
3. A ∩B = B if and only if B ⊆A.
9.3.1
Families of sets
Occasionally, we need to consider several sets at the same time, as in the afore-
mentioned theorems where A, B, C all stood for sets. There is a point where
using diﬀerent letters for each set becomes impractical and even confusing,
and three might be that point. If we need to consider, say, 30 sets at once, we
can use one master letter and subscripts that index the sets. So we can write
Ai where i ∈{1, 2, 3, 4 · · · 29, 30}
(9.15)
instead of A1, A2, …, A30.
The real power of this trick is seen when working with inﬁnitely many sets.
For example, we could declare that we have inﬁnitely many sets by giving each
set its own natural number:
Bi where i ∈ℕ.
(9.16)
But, there is tremendous ﬂexibility here once we observe that there is no rea-
son why our indexes need to count anything; so we could use negative numbers
as indices as well:
Bi where i ∈ℤ.
(9.17)

158
9 Sets
We can use any set at all to index our sets if we want. Suppose that we want to
create a small subset of ℝfor every real number that contains that number and
the two numbers 7 and 9. No problem,
If x ∈ℝ, let Ex = {x, 7, 9}.
(9.18)
Then E3 = {3, 7, 9}; E√
2 = {
√
2, 7, 9}; E𝜋= {𝜋, 7, 9}; and E7 = {7, 9}. That is a
lot of sets, but they all have their own names, and we know what each name
means. We have a family of sets Ex where x ∈ℝ. In this case, ℝserves as an
index set.
In Mathematics, this is how we indicate a family of sets of any size:
Si where i ∈.
(9.19)
The index set can be any set. The size of the family depends on the size of .
We can think of S as the family name and think of as the list of ﬁrst names
of members of the family. The symbol S stands for nothing on its own, but for
any particular i0 ∈, Si0 stands for one particular set in the family. Now it can
happen that one member of a family has two or more names in the list (Jack,
Johnny, and John.) The same for families of sets, we can have i ≠j, and at the
same time Si = Sj. In our aforementioned example, E7 = {7, 9} and E9 = {7, 9},
two names for what turns out to be the same family member. This is a perfectly
ﬁne family of sets, because no one name stands for diﬀerent family members.
We can combine and intersect families of sets using the following deﬁnitions:
Deﬁnition 9.3.8.
Let Si where i ∈is a family of sets. Then the union of the
family is
⋃
i∈
Si = {x ∣∃i ∈s.t. x ∈Si}.
(9.20)
It only takes one i ∈I for x to be in the union, and which one works depends
on x. So we might often ﬁnd it better to write
⋃
i∈
Si = {x ∣∃ix ∈s.t. x ∈Six}.
(9.21)
Proof technique. When we ﬁnd that we have a ∈⋃
i∈
Ai, we should usually
name the variables that follow the ∃using the index i and say ∃ia ∈s.t.
a ∈Sia.
Notice that this is because, for all x ∈⋃
i∈
Ai, ∃ix ∈s.t. x ∈Six. So the deﬁni-
tion of a ∈⋃
i∈
Ai is an AE statement in disguise.
Deﬁnition 9.3.9.
Let Si where i ∈is a family of sets. Then, the intersection
of the family is

9.3 Set operations
159
⋂
i∈
Si = {x ∣∀i ∈, x ∈Si}.
(9.22)
After this, we can prove things about families of sets by treating them as sets
and using the deﬁnitions.
Example 9.3.10.
For x ∈ℝ, let Ex = {x, 7, 9}. This deﬁnes a family of sets.
Then
⋃
x∈ℝ
Ex = ℝ
and
⋂
x∈ℝ
Ex = {7, 9}.
Comment: We can prove these by proving the subset each way. But we make sure
not to use the same letter for two diﬀerent things.
We will ﬁrst prove that ⋃
x∈ℝ
Ex = ℝ.
Proof. This is a set equality; so our proof will have two steps. First, we will prove
that ⋃
x∈ℝ
Ex ⊆ℝ, and then we will prove that ⋃
x∈ℝ
Ex ⊇ℝ.
Step 1. We claim that ⋃
x∈ℝ
Ex ⊆ℝ.
Proof of claim. Assume y ∈⋃
x∈ℝ
Ex. Then there exists xy ∈ℝsuch that y ∈Exy =
{xy, 7, 9} ⊆ℝ. So y ∈ℝ.
◾
Step 2. We now claim that ⋃
x∈ℝ
Ex ⊇ℝ.
Proof of claim. Assume y ∈ℝ, then y ∈{y, 7, 9} = Ey. So by the deﬁnition of
union, y ∈⋃
x∈ℝ
Ex.
◾
We have now proved that both ⋃
x∈ℝ
Ex ⊆ℝ, and ⋃
x∈ℝ
Ex ⊇ℝ. It follows that
⋃
x∈ℝ
Ex = ℝ.
◽
Now we will prove that ⋂
x∈ℝ
Ex = {7, 9}.
Proof. This is a set equality, so we must prove both ⋂
x∈ℝ
Ex ⊆{7, 9} and ⋂
x∈ℝ
Ex ⊇
{7, 9}. We will begin by proving the ⊇direction.
Step 1. We claim that ⋂
x∈ℝ
Ex ⊇{7, 9}.

160
9 Sets
Proof of claim. Assume y ∈{7, 9}. Then, either y = 7, or y = 9. So in either
case, ∀x ∈ℝ, y ∈{x, 7, 9} = Ex. Thus, by the deﬁnition of intersection
y ∈⋂
x∈ℝ
Ex.
◾
Step 2. We claim that ⋂
x∈ℝ
Ex ⊆{7, 9}.
Proof of claim. To prove ⋂
x∈ℝ
Ex ⊆{7, 9} we must prove that if x ∈⋂
x∈ℝ
Ex, then
x ∈{7, 9}. Here we will prove this through the contrapositive. That is, we will
prove that if y ∉{7, 9}, then y ∉⋂
x∈ℝ
Ex.
Assume y ∉{7, 9}. Then y ≠7 and y ≠9. Let y′ = y + 1. Then y ≠y′. Since
y ≠7,and y ≠9 and y ≠y′, we know that y ∉{y′, 7, 9} = Ey′. But then y′ ∈ℝ
such that y ∉Ey′. So it is not true that ∀x ∈ℝ, y ∈Ex. So y ∉⋂
x∈ℝ
Ex.
◾
At this point, we have proved that ⋂
x∈ℝ
Ex ⊇{7, 9} and that ⋂
x∈ℝ
Ex ⊆{7, 9}. It
follows that ⋂
x∈ℝ
Ex = {7, 9}.
◽
Theorem 9.3.11.
Let A be a set and Bi with i ∈be a family of sets. Then
1. A ∪
(⋂
i∈
Bi
)
= ⋂
i∈
(A ∪Bi);
2. A ∪
(⋃
i∈
Bi
)
= ⋃
i∈
(A ∪Bi);
3. A∖
(⋂
i∈
Bi
)
= ⋃
i∈
(A∖Bi);
4. A∖
(⋃
i∈
Bi
)
= ⋂
i∈
(A∖Bi).
Notice that each uses the original family of sets Bi with i ∈to deﬁne another
family. In the ﬁrst, that family is (A ∪Bi) with i ∈. We will leave the proofs of
these as exercises. Notice, however, that the ﬁrst two are the distributive laws on
steroids. The proofs of these should mirror the proofs of the simpler versions.
The logical trick we used earlier should reappear in the proof of statement 1.
The last two are De Morgan’s laws again. And their proofs involve little more
than acknowledging this.
9.4
Special sets
9.4.1
The empty set
There is a set that is deﬁned by its lack of elements: the empty set. The notation
for the empty set is ∅. This set, as simple as it is, can take some getting used to.
The symbol ∅stands for a set; thus, ∅is an object in Mathematics. So the set

9.4 Special sets
161
{∅} contains an object; that object is a set; that object is the empty set. Thus,
{∅} is not empty because it contains something. So
{∅} ≠∅.
(9.23)
We can, however, say
∅∈{∅}.
(9.24)
There might be a temptation to write the empty set as { }, but it should be
resisted because { } is just too horrible to be tolerated. The only acceptable
notation for the empty set is ∅.
Our ﬁrst theorem about sets guarantees that every set has at least one subset.
The empty set is a subset of every set.
Theorem 9.4.1.
If A is a set, then ∅⊆A.
Proof. We begin as usual: assume that A is a set.
Comment: There is not much we can say about that. So, what are we proving
now? ∅⊆A. What does this statement in mathematical terms mean? Accord-
ing to the deﬁnition of subset, we must prove: if x ∈∅, then x ∈A. But x ∈∅is
automatically false.
By the rules of logic, the implication “if x ∈∅, then x ∈A” is always true.
◽
Ignoring the comment, this proof does not say much. This argument used is
often called “vacuous implication” and swallowing it causes some people indi-
gestion. We can try the contrapositive; it is just as vacuous, but often it is easier
to swallow. Again, we will include remarks about how the proof is constructed
that do not belong in a ﬁnal write-up.
Proof. We will prove: if x ∉A, then x ∉∅. Assume x ∉A.
Comment: What are we proving now? x ∉∅. No problem, that is deﬁnitely true.
How do we write this up?
Assuming x ∉A, the conclusion x ∉∅is certainly true. So the statement is
proved.
◽
The empty set can be a nuisance, but it usually is not if we stick to our logic.
The well-ordering principle in ℕstates, if S ⊆ℕand S ≠∅, then S has a mini-
mum. To use it, we must know that S ⊆ℕand that S has at least one element.
As long as we remember to check both conditions, we will be able to say that S
has a minimum. The same goes for the completeness axiom: if S ⊆ℝand S ≠∅
and S has a lower bound, then S has an inﬁmum in ℝ. On the other hand, if we
need to prove S ⊆T, we must prove: if x ∈S, then x ∈T. Logic allows us to
begin our proof with, “Assume x ∈S.” There is no reason to consider S = ∅as

162
9 Sets
a separate case. Here vacuous implication works in our favor. If we are proving
that something exists, we need to be careful before we say, “Let x ∈S.” Before
we say this, we need to be sure that S has at least one element for this to be
valid.
9.4.2
Intervals
There are some subsets of the real numbers that occur so often that they have
their own notation: intervals. An interval is a subset of ℝthat has no gaps and
has no holes. When we use interval notation, it always applies to all real num-
bers in the set. The following are the notations for various types of intervals:
Deﬁnition 9.4.2.
Let a, b ∈ℝand a ≤b. Then
(a, b) = {x ∈ℝ∣a < x < b};
(9.25)
[a, b] = {x ∈ℝ∣a ≤x ≤b};
(9.26)
(a, b] = {x ∈ℝ∣a < x ≤b};
(9.27)
[a, b) = {x ∈ℝ∣a ≤x < b};
(9.28)
(a, ∞) = {x ∈ℝ∣a < x};
(9.29)
[a, ∞) = {x ∈ℝ∣a ≤x};
(9.30)
(−∞, b) = {x ∈ℝ∣x < b};
(9.31)
(−∞, b] = {x ∈ℝ∣x ≤b}.
(9.32)
Note that interval notation always requires that we include all real numbers
in the interval, not just the rational numbers or integers or natural numbers. If
we do want to restrict ourselves to rational numbers in a particular range, we
can use intersection. Thus,
(2, 5) ∩ℚ= {x ∈ℚ∣a < x < b} ≠(2, 5).
(9.33)
In addition, it is important to note that ∞is not a real number. It is just a symbol
to tell us that an interval has no upper bound or to tell us that an interval has
no lower bound when −∞is used. In particular, ∞cannot be in a set of real
numbers. We should not write (although it is not wrong)
(a, ∞) = {x ∈ℝ∣a < x < ∞}
(9.34)
because the second inequality is rather pointless.
There are situations when degenerate forms of this notation pop up. What if
a = b in our ﬁrst four deﬁnitions earlier? For example, we might ﬁnd ourselves
about to write (a, a). We should not write that because there is a much better
name for the set we are trying to describe:
(a, a) = {x ∈ℝ∣a < x < a} = ∅.
(9.35)
If we have the empty set, we should always denote it as ∅.

9.4 Special sets
163
If a = b, we might also ﬁnd ourselves about to write [a, a]. We should not,
because there is a much better name for that set as well:
[a, a] = {x ∈ℝ∣a ≤x ≤a} = {a}.
(9.36)
We should use the proper notation for a one-element set. We might also catch
ourselves writing [a, a) or (a, a]. But this is a deﬁnite warning that we might
have a problem with our reasoning. Either one of these sets is a built-in con-
tradiction to trichotomy; so neither of them is well deﬁned. It might be that all
we have done is discovered the empty set by legitimate reasoning, but it could
just as well be that we have made an algebraic or logical error that has created a
contradiction. One thing is true; something that led us there needs to be ﬁxed!
The ﬁnal degenerate version of interval notation that might appear is actually
a set of all real numbers. We should always replace (−∞, ∞) with ℝ.
In the next example, we revisit families of sets, where the sets in the family
are all intervals in ℝ.
Example 9.4.3.
Prove ⋂
n∈ℕ
(
−1
n, 1
n
)
= {0}.
Proof draft. We are asked to prove a set equality, so we must prove
⋂
n∈ℕ
(
−1
n, 1
n
)
⊆{0} and ⋂
n∈ℕ
(
−1
n, 1
n
)
⊇{0}. Let us start with ⊇.
Step 1. We claim ⋂
n∈ℕ
(
−1
n, 1
n
)
⊇{0}.
Proof of claim. We will prove that if x = 0, then x ∈⋂
n∈ℕ
(
−1
n, 1
n
)
.
Assume x = 0. Here we have a family of sets indexed by ℕ, where for each
n ∈ℕ, the associated member of the family is the interval
(
−1
n, 1
n
)
=
{
x ∈ℝ∣−1
n < x < 1
n
}
.
(9.37)
Since ∀n ∈ℕ, −1
n < 0 < 1
n, we know ∀n ∈ℕ, 0 ∈
(
−1
n, 1
n
)
. Thus, 0 ∈
⋂
n∈ℕ
(
−1
n, 1
n
)
. So we have proved that if x ∈{0}, then x ∈⋂
n∈ℕ
(
−1
n, 1
n
)
. This
means ⋂
n∈ℕ
(
−1
n, 1
n
)
⊇{0}.
◾
Step 2. We now claim that ⋂
n∈ℕ
(
−1
n, 1
n
)
⊆{0}.
Proof of claim. We will prove that if x ∈⋂
n∈ℕ
(
−1
n, 1
n
)
, then x = 0 by proving the
contrapositive. That is, we will prove that if x ∉{0}, then x ∉⋂
n∈ℕ
(
−1
n, 1
n
)
.

164
9 Sets
Assume x ∉{0}. This means that x ≠0.
Comment: What are we proving now? By the deﬁnition of intersection, we need
to prove
∃n ∈ℕs.t. x ∉
(
−1
n, 1
n
)
.
(9.38)
So we need to set up a word problem to solve in scratch work. Find n ∈ℕso that
x ∉
(
−1
n, 1
n
)
. That means we need n so that either x < −1
n or x > 1
n. All we know
is that x ≠0. That is not much to go on; all it says is either x > 0 or x < 0. Oh,
oh, two cases.
There are two possibilities, x > 0 or x < 0.
Case 1. Assume x > 0.
Comment: What are we doing now? We want to ﬁnd n so that x < −1
n or 1
n < x.
Since x > 0, it had better be the latter. We want to ﬁnd n so that 1
n < x. We are
looking for n so we should write this solved for n. We want to ﬁnd n so that n > 1
x.
How do we ﬁnd this? By magic! In this case, magic in the form of the Archimedean
principle.
By the Archimedean principle, since 1
x ∈ℝ, then there exists nx ∈ℕsuch that
nx > 1
x. So ∃nx ∈ℕs.t. x ∉
(
−1
nx , 1
nx
)
. All it takes is one member of the family,
so x ∉⋂
n∈ℕ
(
−1
n, 1
n
)
.
Case 2. Assume x < 0.
Comment: What are we doing now? We want to ﬁnd n so that x < −1
n or 1
n < x.
Since x < 0, it had better be the former. We want to ﬁnd n so that x < −1
n. We
are looking for n so we should write this solved for n. We want to ﬁnd n so that
nx < −1 and so that n > −1
x because x < 0. (We are lucky we caught that.) How
do we ﬁnd this? By magic again.
By the Archimedean principle, ∃nx ∈ℕs.t. nx > −1
x. So ∃nx ∈ℕs.t.
x ∉
(
−1
nx , 1
nx
)
. All it takes is one member of the family, so x ∉⋂
n∈ℕ
(
−1
n, 1
n
)
. ◾
We have now proved that ⋂
n∈ℕ
(
−1
n, 1
n
)
⊇{0} and ⋂
n∈ℕ
(
−1
n, 1
n
)
⊆{0}. So it
follows that ⋂
n∈ℕ
(
−1
n, 1
n
)
= {0}.
Δ
If we had remembered that intervals can be written using absolute values,
then we could have avoided the cases in our proof. Let us rewrite this proof in
a more compact form using some previous results.

9.4 Special sets
165
We will prove
⋂
n∈ℕ
(
−1
n, 1
n
)
= {0}.
(9.39)
Proof. This is a set equality, so we must prove ⊆and ⊇. We begin by proving
the ⊇direction.
Step 1. We claim that ⋂
n∈ℕ
(
−1
n, 1
n
)
⊇{0}.
Proof of claim. Assume x = 0. Since ∀n ∈N, −1
n < 0 < 1
n, we know that
∀n ∈N, 0 ∈
(
−1
n, 1
n
)
. Thus, 0 ∈⋂
n∈ℕ
(
−1
n, 1
n
)
.
◾
Step 2. We claim that ⋂
n∈ℕ
(
−1
n, 1
n
)
⊆{0}.
Proof of claim. We will prove the contrapositive, if x ≠0, then x ∉⋂
n∈ℕ
(
−1
n, 1
n
)
.
Assume x ≠0. Then |x| > 0. So
1
|x| ∈ℝ. By the Archimedean principle, there
exists nx ∈ℕsuch that nx >
1
|x|. So |x| >
1
nx . Since for all n,
(
−1
n, 1
n
)
=
{
y ∈ℝ∣−1
n < y < 1
n
}
(9.40)
=
{
y ∈ℝ∣|y| < 1
n
}
.
We have x ∉
(
−1
nx , 1
nx
)
. Thus, x ∉⋂
n∈ℕ
(
−1
n, 1
n
)
.
◾
We have now proved that ⋂
n∈ℕ
(
−1
n, 1
n
)
⊇{0} and ⋂
n∈ℕ
(
−1
n, 1
n
)
⊆{0}. So it
follows that ⋂
n∈ℕ
(
−1
n, 1
n
)
= {0}.
◽
Proof technique. If we need to prove a statement of the form ∃n ∈ℕs.t. P(n),
it is useful to ask ourselves, “What kind of n do we need?” If the answer is “a large
one,” we should prepare to use the Archimedean principle by asking how large
must it be exactly. If we can solve any resulting inequality so that it has the form
n > P, then we will have exactly what we need to proceed.
Example 9.4.4.
Prove that ⋃
n∈ℕ
(
−∞, 2n−1
n+1
]
= (−∞, 2).
Proof draft.
Step 1. We claim that ⋃
n∈ℕ
(
−∞, 2n−1
n+1
]
⊆(−∞, 2).

166
9 Sets
Proof
of
claim. Assume
x ∈
⋃
n∈ℕ
(
−∞, 2n−1
n+1
]
.
Then
∃nx ∈ℕ
s.t.
x ∈
(
−∞, 2nx−1
nx+1
]
. That is,
x ≤2nx −1
nx + 1 .
(9.41)
Comment: It may be clear to some as to what to do with this inequality, but
we will suppose that it is not. So we ask ourselves, what do we want? We want
x < 2. So we want to ﬁnd something to ﬁt between: x < ? < 2. Since we just found
something that gives one of these inequalities, we might be brave and simply
claim that the other is true. Of course, we will then have to prove it.
We now claim that 2nx−1
nx+1 < 2.
Comment: We want 2nx−1
nx+1 < 2. So we want 2nx −1 < 2(nx + 1). That is, 2nx −
1 < 2nx + 2, and in turn, −1 < 2. This is a good thing to want to be true.
To see this, notice that −1 < 2. Thus, 2nx −1 < 2nx + 2. So 2nx−1
nx+1 < 2.
With this claim, we have
x ≤2nx −1
nx + 1 < 2.
(9.42)
So x ∈(−∞, 2).
◾
Step 2. We now claim that (−∞, 2) ⊆⋃
n∈ℕ
(
−∞, 2n−1
n+1
]
.
Proof of claim. Assume x ∈(−∞, 2). So x < 2.
Comment: There is not much we can do with this; so we ask, what are we proving
now? The answer is x ∈⋃
n∈ℕ
(
−∞, 2n−1
n+1
]
. What does this mean? We need to prove
∃n ∈ℕs.t. x ∈
(
−∞, 2n−1
n+1
]
. So to prove that something exists, we need to set up
a word problem in scratch work.
Scratch work:
We want n ∈ℕso that x ∈
(
−∞, 2n−1
n+1
]
. That is, so that x ≤2n−1
n+1 . A bit of
thought, or a good picture, tells us that we want a large natural number n to ﬁt

9.4 Special sets
167
between x < 2. So we want
x ≤2n −1
n + 1
(9.43)
xn + 2x ≤2n −1
2x + 1 ≤2n −nx
2x + 1 ≤(2 −x)n
n ≥2x + 1
2 −x .
Comment: Since we assumed that x < 2, that last division was OK. Now we use
the Archimedean principle to get the n we need. We can return to our proof.
Since x < 2, 2 −x > 0. Therefore, 2x+1
2−x ∈ℝ. By the Archimedean principle,
∃n ∈ℕs.t. n ≥2x+1
2−x . So after some algebra,
x ≤2n −1
n + 1 .
(9.44)
Thus, we have n ∈ℕs.t. x ∈
(
−∞, 2n−1
n+1
]
. And so x ∈⋃
n∈ℕ
(
−∞, 2n−1
n+1
]
.
◾
This completes our proof of the set equality.
Δ
This was just a draft, and we can rewrite it into a more direct form.
Theorem 9.4.5.
⋃
n∈ℕ
(
−∞, 2n−1
n+1
]
= (−∞, 2).
Proof.
Step 1. We claim that ⋃
n∈ℕ
(
−∞, 2n−1
n+1
]
⊆(−∞, 2).
Proof
of
claim. Assume
x ∈
⋃
n∈ℕ
(
−∞, 2n−1
n+1
]
.
Then
∃nx ∈ℕ
s.t.
x ∈
(
−∞, 2nx−1
nx+1
]
. That is, x ≤2nx−1
nx+1 . However, 2nx −1 < 2nx + 2. So we have
x ≤2nx −1
nx + 1 < 2.
(9.45)
Thus, x ∈(−∞, 2).
◾
Step 2. We now claim that (−∞, 2) ⊆⋃
n∈ℕ
(
−∞, 2n−1
n+1
]
.

168
9 Sets
Proof of claim. Assume x ∈(−∞, 2). So x < 2, and 2 −x > 0. Thus, 2x+1
2−x ∈ℝ.
By the Archimedean principle, ∃n ∈ℕsuch that n ≥2x+1
2−x . Now,
n ≥2x + 1
2 −x
(9.46)
2n −xn ≥2x + 1
2n −1 ≥2x + xn
2n −1 ≥(2 + n)x.
Since 2 −x > 0, this says that x ≤2n−1
n+1 . Since we have n ∈ℕso that
x ∈
(
−∞, 2n−1
n+1
]
, we can say x ∈⋃
n∈ℕ
(
−∞, 2n−1
n+1
]
.
◾
◽
9.5
Problems
9.1
True or false:
(a) ∅∈∅.
(b) ∅⊆∅.
(c) ∅= ∅.
(d) ∅∈{∅}.
(e) ∅⊆{∅}.
(f) ∅= {∅}.
(g) {∅} ∈∅.
(h) {∅} ⊆∅.
(i) {∅} = ∅.
(j) As a subset of ℝ: ∅has a minimum.
(k) As a subset of ℝ: ∅has a lower bound.
(l) As a subset of ℝ: ∅has an inﬁmum.
(m) In the integers, (1, 5) = {2, 3, 4}.
(n) (1, 5) ∩ℤ= {2, 3, 4}.
(o) (−3, 3] has an upper bound.
(p) (−3, 3] has an inﬁmum.
(q) ∞∈[−3, ∞].
(r) (0, 4) ⊆ℚ.
(s) (0, ∞) ∩ℤ⊆ℚ.
(t) (0, ∞) ∪ℤ⊆ℚ.
(u) (0, 10)∖ℤ⊆ℚ.
(v) ℤ∖(0, 10) ⊆ℚ.
9.2
Prove {n ∈ℤ∣n is even} = {n ∈ℤ∣n −1 is odd}.

9.5 Problems
169
9.3
Prove that for all sets A, B, and C:
(a) If A ⊆B and B ⊆C, then A ⊆C.
(b) A ∪B = A if and only if B ⊆A.
(c) A ∩B = B if and only if B ⊆A.
9.4
An interval is supposed to be a subset of ℝwith no gaps and no holes.
Thus, all the following sets are intervals:
• ∅and ℝ;
• for a ∈ℝ, {a}, (a, ∞), [a, ∞), (−∞, a) and (−∞, a];
• and for a < b, (a, b), (a, b], [a, b), and [a, b].
We have deﬁned every one of these 11 diﬀerent notations for an inter-
val. We have not, however, said exactly what makes a set an interval.
In this problem, you are asked to give a mathematical deﬁnition of
“interval.” You are then asked to prove that any set that satisﬁes that
deﬁnition can be expressed using one of these pieces of notation.
(a) Give a mathematical deﬁnition of “interval” based on the fact that
an interval must contain all the real numbers that lie between any
two numbers in the interval. (Hint: do exactly what this says by start-
ing out your deﬁnition with “I ⊆ℝis an interval when…” To ﬁnish,
interpret the phrase “an interval must contain all the real numbers
that lie between any two numbers in the interval” into logical math-
ematical form using “if…then.”)
(b) Use your deﬁnition to prove that if A ⊆ℝis a nonempty interval
with upper and lower bounds, then ∃a, b ∈ℝsuch that (a, b) ⊆A ⊆
[a, b].
(c) Use your deﬁnition to prove that if A ⊆ℝis a nonempty interval
with an upper bound and no lower bound, then ∃b ∈ℝsuch that
(−∞, b) ⊆A ⊆(−∞, b].
(d) Use your deﬁnition to prove that if A ⊆ℝis a nonempty interval
with a lower bound and no upper bound, then ∃a ∈ℝsuch that
(a, ∞) ⊆A ⊆[a, ∞).
(e) Use your deﬁnition to prove that if A ⊆ℝis a nonempty interval
with no lower bound and no upper bound, then A = ℝ.
(f) Use your deﬁnition to prove that if A ⊆ℝis an interval, then A has
one of the forms
∅, {a}, (a, b), (a, b], [a, b), [a, b]
(a, ∞), [a, ∞), (−∞, b), (−∞, b] or ℝ.
9.5
Let A, B, C be sets, prove:
(a) A ∩(B ∪C) = (A ∩B) ∪(A ∩C).
(b) A∖(B ∩C) = (A∖B) ∪(A∖C).
(c) A∖(B ∪C) = (A∖B) ∩(A∖C).

170
9 Sets
9.6
We suggested that the deﬁnition of the union of a family of sets might
be written as ⋃
i∈
Si = {x ∣∃ix ∈s.t. x ∈Six}. Explain how this is related
to the logical structure of an AE statement.
9.7
Deﬁne a family of sets by: for n ∈ℤ, Sn = {0, ±n}.
(a) True or false: n = m implies Sn = Sm.
(b) True or false: Sn = Sm implies n = m.
(c) True or false: n ≠m implies Sn ≠Sm.
(d) True or false: Sn ≠Sm implies n ≠m.
(e) True or false: Every set in the family has three elements.
(f) True or false: If Sn ⊆Sm, then n = m.
(g) True or false: ∀n, m ∈ℤ, Sn ∩Sm = {0}.
(h) True or false: ∀n, m ∈ℤ, Sn ∩Sm ≠∅.
9.8
Deﬁne a family of sets by: for n ∈ℕ, Sn = (−∞, −1
n) ∪( 1
n, ∞).
(a) True or false: n = m implies Sn = Sm.
(b) True or false: Sn = Sm implies n = m.
(c) True or false: n < m implies Sn ⊆Sm.
(d) True or false: Every set in the family is not empty.
(e) True or false: ⋂
n∈ℕ
Sn = ∅.
(f) True or false: ∀n ∈ℕ, 0 ∉Sn ∩Sm.
(g) True or false: If x ≠0, then x ∈⋃
n∈ℕ
Sn.
9.9
Let A be a set and Bi with i ∈be a family of sets. Prove:
(a) A ∪
(⋂
i∈
Bi
)
= ⋂
i∈
(A ∪Bi).
(b) A ∪
(⋃
i∈
Bi
)
= ⋃
i∈
(A ∪Bi).
9.10
Let A ⊆ℝ. Prove that A is bounded if and only if there is n ∈ℕsuch
that A ⊆(−n, n).
9.11
Prove that ⋃
n∈ℕ
(−n, n) = ℝ.
9.12
Prove that ⋃
n∈ℕ
(
0,
n
n+1
)
= (0, 1).
9.13
Prove that ⋂
n∈ℕ
(
0, n+1
n
)
= (0, 1].
9.14
True or false, and explain your answer:
(a) ⋂
𝜀>0
(1 −𝜀, 1 + 𝜀) = ⋂
𝜀≥0
(1 −𝜀, 1 + 𝜀).

9.6 Epilogue
171
(b) ⋂
𝜀>0
[1 −𝜀, 1 + 𝜀] = ⋂
𝜀≥0
[1 −𝜀, 1 + 𝜀].
9.15
Let A be any set. Deﬁne a family of open sets by Ba = A∖{a}.
(a) Find ⋂
a∈A
Ba and prove that your answer is correct.
(b) Find ⋃
a∈A
Ba and prove that your answer is correct.
9.16
Prove that any interval of the form (a, b) can be written as
{x ∈ℝ∣|x −c| < d}
for the right numbers c and d.
9.17
For each s ∈ℚ, let Es = {1, 1
2, s}.
(a) Find
⋃
t∈ℚ
Et and prove that your answer is correct.
(b) Find
⋂
t∈ℚ
Et and prove that your answer is correct.
9.6
Epilogue
We started out saying,
A set is any collection of objects determined by a mathematical state-
ment P(x).
We noted that
In fact, there are deep technical aspects of sets that this description does
not address.
The “deep technical aspects” are not much more than adding the informal
phrase “but sets cannot be too big.”
Consider
S = {x ∣x ∉ℚ}.
(9.47)
At ﬁrst, this seems to be a reasonable deﬁnition of a set. We know that
√
2 ∈S
and 𝜋∈S. Now {4} is a subset of ℚ, but it is not an element of ℚ. Thus, we
have {4} ∈S. For the same reason, ℕ∈S. Pi is the name of the Greek letter 𝜋,
and Pi ∈S. But “eleven” is the English word for the rational number 11. That
seems to mean, 11 ∉S, but “eleven” ∈S. (But that only complicates things even
more. We could also point out that “ “ eleven” ” ∈S ). The Statue of Liberty is

172
9 Sets
an element of S, as is the island it is on, and the water surrounding the island,
and the ﬁsh in the water, and …
So the set S is really big; is that really a problem? The mathematician, philoso-
pher, and logician Bertrand Russell presented a famous paradox about a set that
is too large. It uses the self-referencing trick. Let
A = {T where T is a set of sets and T ∉T}.
(9.48)
As Russell pointed out, this set cannot exist. If A ∈A, that leads to a contra-
diction. But the negation A ∉A leads to a contradiction as well. And this set is
“smaller” than our earlier example S because at least it does not include any of
New York Harbor. Greek logic would have tried to resolve Russell’s paradox by
saying that self-referencing statements are not allowed in logic. But by 1900s,
logicians realized that a self-reference might accidently occur as a result of a
long circular string of legitimate looking statements. A set such as S = {x ∣x ∉
ℚ} is so large that it accidently does reference itself. After all, it is not a rational
number. Thus, the perfectly legitimate mathematical statement x ∉ℚcannot
be used to deﬁne a set. But then why should we be so sure that x ∈ℚcan? This
causes us to wonder if sets can be assumed to exist at all. Since we are trying to
base all Mathematics on sets, this is a major philosophical problem!
As Russell discovered, if we are not careful about how we deﬁne a set, it may
be too big to be a legitimate set. So we need to be more careful. Now Gödel told
us that self-reference is unavoidable, but that does not make it a good thing. As
best we can, we must continue to avoid self-reference in our logic. That is why
once the preliminary ideas of set theory are established, mathematicians always
include a limitation on the size of any set they deﬁne. Thus, in the standard set
notation, there is usually a condition on elements of the sets that is slipped in
before the “such that” symbol. This limits the objects eligible to be included in
the new set to those from a set already known to exist. So we write
A = {x ∈ℝ|x ∉ℚ}
(9.49)
to identify the set of irrational numbers. By limiting the scope of the variable,
we have avoided any possibility of self-reference. We should avoid writing the
set of irrational numbers as
A = {x ∣x ∉ℚ}
(9.50)
no matter how obvious it is what we mean by that. Still, in a normal mathe-
matics proof, the chances of being sloppy about what we mean like this, and
thus accidently creating a set that is too big is pretty remote. This problem in
deﬁning large sets mostly occurs in advanced studies of set theory, mathemat-
ical foundations, or Philosophy. In other advanced mathematical studies, there
are logical tricks mathematicians use to skirt this issue. So mostly in this study,
we will just ignore the issue all together.

9.6 Epilogue
173
Finally, in some settings, mathematicians and users of Mathematics ﬁnd it
convenient to create a limit on the size of a set right away by establishing a
“universal set” from which all elements must be taken. This works best when
the context of the subject will make such an universe obvious. If U is a universal
set, and A ⊆U, then U∖A is called the complement of A and is often given its
own notation. In a study of real numbers, choosing ℝto be a universal set is
tempting, but we will see that often the best way to study the properties of real
numbers is to study sets of real numbers. So the whole point of introducing
set theory here is to allow us to use sets of real numbers as well as the num-
bers themselves. Declaring a universal set of numbers has only limited value
to us. For that reason, we generally stick to A∖B where we only consider the
complement of B in the set A. The notation A∖B eliminates the possibility of
self-reference once A and B are known to be legitimate sets.

175
10
Relations
10.1
Ordered pairs
The next mathematical idea we need to discuss is an ordered pair. This is a famil-
iar concept of algebra. For example, consider the graph of the line y = 2x −2 in
ℝ2. We say that the point (3, 4) is on the line y = 2x −2 because 4 = 2(3) −2.
The point (3, 4) is an “ordered pair.” It is clearly a pair, and the order matters so
that we know which number to substitute for which variable. That is why we
say that it is an ordered pair.
As we discussed in the previous chapter, order does not matter when deal-
ing with sets. So the two-element set {3, 4} is the same as the two-element set
{4, 3}. So {3, 4} is a pair, but not an ordered pair. Notice that the point (2, 2) is
also on the line y = 2x −2. Again, (2, 2) is an ordered pair. But the set {2, 2} is
the same as the set {2} – it is not even a pair.
The deﬁnition of equality of sets means that we cannot distinguish the order
in which elements appear in a set and that repeating an element does not change
it. It turns out that there is a way to deﬁne ordered pairs in terms of sets, but
we must be clever about it. Here is the deﬁnition:
Deﬁnition 10.1.1.
An ordered pair is a set of the form {a, {a, b}}. We write it
as (a, b).
The set {a, {a, b}} is a set with two elements; one is an element of the set
A, and the other is a subset of A. In any case, this is a set, and we know how
sets work.
Assume a, b, c, d ∈A, and
{a, {a, b}} = {c, {c, d}}.
(10.1)
The equality of these sets tells us that each is a subset of the other. Since a ∈A,
a ∈{c, {c, d}}. So either a = c or a = {c, d}. Of course, this element of A is
not a subset of A; so we must have a = c. Next, {a, b} ∈{a, {a, b}}; so {a, b} ∈
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

176
10 Relations
{c, {c, d}}. Sets must equal sets; so we must have {a, b} = {c, d}. But we just
saw that a = c, so we have {a, b} = {a, d}. So b = d. So we see that
{a, {a, b}} = {c, {c, d}} implies a = c and b = d.
(10.2)
However, we can quickly show that
{a, {a, b}} = {a, {b, a}} = {{b, a}, a}
(10.3)
while {a, {a, b}} ≠{b, {a, b}} unless a = b.
This means that the set {a, {a, b}} picks out two elements of the set A and dis-
tinguishes one of the two as special. This set, therefore, can denote two elements
of A and indicate that one should be considered as the ﬁrst of the pair. So we
deﬁned this formally earlier.
The aforementioned observations say that
(a, b) = (c, d) ⇔a = c and b = d
(10.4)
(a, b) ≠(b, a) unless a = b.
We have tricked our basic set notation to produce a code for a pair of ele-
ments in a particular order. We can be rightfully proud of ourselves for being
clever, but only if we are also clever enough to replace this complicated code for
an ordered pair with something less confusing. Thus, while we have an oﬃcial
set theory deﬁnition of an ordered pair, we try never to think about it that way.
We will never need to use the oﬃcial deﬁnition again except to show oﬀ. A word
of caution about showing oﬀthis way, the only people likely to be impressed by
this tortured bit of logic are those who appreciate the intricacies of fundamen-
tal mathematics and logic. Everyone else will be the opposite of impressed and
think that we are crazy. Our best recourse is to never mention this again espe-
cially in mixed (math/nonmath) company. We will just say that the ordered pair
(a, b) means a ﬁrst and b second as everybody else does.
Deﬁnition 10.1.2.
Let A and B be sets. The (Cartesian) product A × B is the
set
A × B = {(x, y) ∣x ∈A and y ∈B}.
(10.5)
Thus, if A = {1, 2} and B = {2, 3, 4}, then
A × B = {(1, 2), (1, 3), (1, 4), (2, 2), (2, 3), (2, 4)}.
(10.6)
We also write A2 = A × A.
10.1.1
Relations between and on sets
Often, we have relationships between elements in a set that we express by say-
ing “a is related to b.” What this means will depend upon the context at the

10.1 Ordered pairs
177
moment. Geometric objects might be related by being congruent or, in a diﬀer-
ent situation, by being similar. Natural numbers might be related by having the
same parity, odd or even. The meaning of “related” in “a is related to b” is usu-
ally deﬁned right before or right after the phrase is introduced. As is typical in
Mathematics, we start by investigating the abstract notion of two things being
somehow related without regard to what “related to” might eventually mean.
One way to say what elements are related to other objects is to simply list
all the pairs of objects where it is meant to be true. This is the basis of our
mathematical deﬁnition of a relation.
Deﬁnition 10.1.3.
Let A and B be sets. A relation between A and B is a subset
⊆A × B. If A = B, we say that it is a relation on A and B.
Once we choose to consider such a subset as a relation (and we do not have
to if we do not want to), we usually write
(a, b) ∈as ab.
We read this as “a is related to b.” Once we better understand what a particular
relation is telling us, if anything, we may change the into a symbol that better
represents the meaning of the relationship. We often use symbols such as <, >,
≤, ≥, ⊂, ⊆, ≅, ∼, or ≃. There are plenty more to choose from. The thing to realize
about all these possibilities for notation is that there are many possible practical
interpretations of a relation with the right properties.
Example 10.1.4.
Let S = {1, 2, 3, 4}. Consider the relation
= {(1, 1), (2, 2), (3, 3), (4, 4)}.
(10.7)
It is pretty clear what relationship this is, and we should choose an appropriate
symbol for it. For (a, b) ∈, we write a = b.
Example 10.1.5.
Let S = {1, 2, 3, 4}. Consider the relation
= {(1, 1), (1, 2), (1, 3), (1, 4), (2, 2),
(10.8)
(2, 3), (2, 4), (3, 3), (3, 4), (4, 4)}.
A bit of thought reveals the relationship this is giving us. For (a, b) ∈, we
write a ≤b.
Example 10.1.6.
Let S = {1, 2, 3, 4}. Consider the relation
= {(1, 2), (2, 4), (3, 3), (4, 2)}.
(10.9)
It is possible that this relation is conveying some meaning, but it could just as
well be random. We could just write (a, b) ∈as ab. We could also choose
some arbitrary symbol for which we have no preconceived interpretation as

178
10 Relations
a ⊩b. We could, and maybe should, just say that it is a relation of some sort
and not give it a notation at all.
Although we have wide latitude in choosing a symbol to represent a new rela-
tion, it would be a very bad idea to choose a symbol that usually has a diﬀerent
meaning. So we avoid symbols such as =, <, ≤, >, ≥∼, ≅, or ≡for newly deﬁned
relations and instead stick to entirely new symbols. Often, we realize that we
will prove that a relation conveys a particular meaning and choose a symbol
that anticipates that.
It is important to realize that most subsets of A × B are rather useless as rela-
tions. They convey no real information when we try to think of them that way.
The key to identifying when a relation does give useful information is to see if it
has certain speciﬁc properties. We will only consider a few possible properties,
but there are plenty more.
So let us deﬁne a few properties on relations in sets that we can use later.
Deﬁnition 10.1.7.
Let be a relation on the set A. We say that the relation is
reﬂexive when, for all a ∈A, aa.
A relation on a set A is reﬂexive if “everything is related to itself.” Equality is
an example of a reﬂexive relation. But “less than” is not a reﬂexive relation.
Deﬁnition 10.1.8.
Let be a relation on the set A. We say that the relation is
symmetric when, if ab, then ba.
Equality is symmetric, and again, the “less than” relation is not symmetric.
Deﬁnition 10.1.9.
Let be a relation on the set A. We say that the relation is
transitive when, if ab and bc, then ac.
Both equality and “less than” are transitive relations.
Deﬁnition 10.1.10.
Let be a relation on the set A. We say that the relation
has trichotomy when, for all a, b ∈A, exactly one of the following holds: ab,
ba, or a = b.
The ordering relation has trichotomy on all of the number systems we have
studied.
Notice that no relation can be both reﬂexive and have trichotomy.
Trichotomy requires that only one of ab or a = b be true at the same time.
Notice also that the deﬁnitions of two of these are phrased as “∀a ∈A, P(a).”
The other two are phrased as “P ⇒Q.” To maintain our logical discipline, we
need to start any proof of these correctly.

10.2 A total order on a set
179
10.2
A total order on a set
10.2.1
Deﬁnition
One thing a relation on a set might tell us is the relative size of the elements of
the set. To do this, the relation must have certain properties.
Deﬁnition 10.2.1.
Let A be a set. A relation on A is a total order when it is
transitive and has trichotomy.
Not surprisingly, once we realize that a relation is a total order, instead of
writing ab, we usually write a < b. There are other symbols available though.
We might write ⋖or ≪or ∝or ⋖or ≺for the order relation. Because we will
be working almost exclusively with total orders on sets of numbers, we will
stick with the conventional a < b to refer to the usual ordering of the numbers.
Once we decide to use a < b for a total order, we immediately use a ≤b to mean
(a < b) ∨(a = b). We also begin to use other associated notation such as c > d
and g ≥h. Notice that, strictly speaking, “≤” is not the notation for the total
order. Because a ≤b means (a < b) ∨(a = b), it cannot have trichotomy. Now
because of our very general deﬁnition of a relation, ≤is still a relation, but that
relation is not a total order. The total order is the relation denoted by <. Because
< has trichotomy, we could have written b ≮a instead of a ≤b, but we choose
not to.
There are other perfectly good orders even for familiar objects. We could
order ℕusing alphabetical order, for example. It is a legitimate total order in ℕ.
This is a good place to use the notation ⋖for a total order and not <. Thus, we
can truthfully say 8 ⋖7, knowing that we are saying that “eight” appears earlier
in the dictionary compared to “seven.” Unfortunately (or fortunately), neither
addition nor multiplication shows alphabetical order much respect. So it is a
rather useless order for arithmetic in that particular number system.
10.2.2
Deﬁnitions that use a total order
Once we have a set with a total order, every subset inherits that total order.
Now there are a lot of other mathematical terms that come with it. Many of
the terms concentrate on subsets of a large set with the total order. The terms
refer to a property of the large set, but the meaning of the terms refers to its
subsets. The terms are about some overall set that has the total order. We often
call this overall set a “universal set.” This is a useful concept to keep in mind, as
we memorize the following deﬁnitions.
Deﬁnition 10.2.2.
Let U be a set with a total order. Suppose that A ⊆U.
• We say that m ∈U is a lower bound of A when
if x ∈A, then m ≤x.

180
10 Relations
• We say that m ∈U is a minimum of A when
m ∈A, and
if x ∈A, then m ≤x.
• We say that m ∈U is an inﬁmum of A when
if x ∈A, then m ≤x, and
if l > m, then there exists some x ∈A with x < l.
Deﬁnition 10.2.3.
Let U be a set with a total order. Suppose that A ⊆U.
• We say that m ∈U is an upper bound of A when
if x ∈A, then x ≤m.
• We say that m ∈U is a maximum of A when
m ∈A, and
if x ∈A, then x ≤m.
• We say that m ∈U is a supremum of A when
if x ∈A, then x ≤m, and
if l < m, then there exists some x ∈A such that x > l.
All of these should be familiar by now. So should the proofs of the following
theorems.
Theorem 10.2.4.
Let U be a set with a total order.
1. If A ⊆U has a minimum, then it is unique. In this case, we can write:
m = Min(A).
2. If A ⊆U has a maximum, then it is unique. In this case, we can write:
m = Max(A).
3. If A ⊆U has an inﬁmum, then it is unique. In this case, we can write:
m = Inf (A).
4. If A ⊆U has a supremum, then it is unique. In this case, we can write:
m = Sup(A).
Theorem 10.2.5.
Let U be a set with a total order.
1. If A ⊆U and m = Inf (A), then m is the greatest of all lower bounds of A.
2. If A ⊆U and m = Sup(A), then m is the least of all upper bounds of A.
Of course, if A has a lower bound, it is probably not unique. We can see that
if m is a lower bound on A and m′ < m, then m′ is also a lower bound on A.
This is why we use the notation m =Min(A) to say that m is the minimum of
A; m =Max(A) to say that m is the maximum of A; m =Inf(A) to say that m
is the inﬁmum of A; and m =Sup(A) to say that m is the supremum of A; but
we absolutely do not use m =Lb(A) to say that m is the lower bound of A. We
always want our notation to be well deﬁned.

10.2 A total order on a set
181
Deﬁnition 10.2.6.
Let U be a set with a total order. We say that U is well
ordered when, if A ⊆U is not empty, then A has a minimum.
Be very careful here, for a set U to be well ordered, every nonempty subset of
U must have a minimum. It is not enough for U to have a minimum alone.
Deﬁnition 10.2.7.
Let U be a set with a total order. We say that U is complete
when, if A ⊆U is not empty and is bounded below, then ∃m ∈U such that
m = Inf (A).
Again, it is the universal set that is complete. Every nonempty subset of U
that is bounded below must have an inﬁmum. That inﬁmum must come from
the universal set U. That is why ℕis well ordered, but ℤis not well ordered. In
addition, that is why ℝis not well ordered, but it is complete and why ℚis not
complete even though it is a subset of ℝwhich is complete.
We have seen the next theorem and its proof before, but it is worth repeating
in this more general context.
Theorem 10.2.8
(The Alternate Completeness Axiom). Let U be a set with
a total order that is complete. If B ⊆U is not empty and is bounded above, then
there is an m ∈U so that m = Sup(B).
Before we prove this theorem, we create a temporary deﬁnition and state and
prove a lemma. Notice the role that the universal set U plays in the proof.
Let U be a set with a total order. For S ⊆U, let
UB(S) = {u ∈U ∣u is an upper bound on the set S}.
(10.10)
Lemma 10.2.9.
If s ∈S, then s is a lower bound of UB(S).
Proof. Assume s ∈S.
Assume x ∈UB (S).
Then
x ∈{u ∈ℝ∣u is an upper bound on the set S}.
(10.11)
Thus, since s ∈S, we have s ≤x. So indeed, x ∈UB (S) implies s ≤x. So s is a
lower bound of UB(S).
◽
Now we are ready to prove the theorem.
Proof. Assume that U is a set with a total order
Assume that U is complete. Thus, every subset of U that is not empty and
bounded below has an inﬁmum.
Assume B ⊆U.

182
10 Relations
Assume B ≠∅.
Assume that B has an upper bound t. Then t ∈UB(B). So UB(B) ≠∅.
Since B ≠∅, ∃b ∈B.
By the lemma, b is a lower bound of UB(B).
Therefore, UB(B) ⊆U; UB(B) ≠∅; and UB(B) is bounded below.
But the completeness axiom, ∃m ∈U s.t. m = Inf (UB(B)).
So if x ∈UB(B), then m ≤x. The contrapositive of this is: if m > x, then
x ∉UB(B).
And if l > m, then ∃x ∈UB(B) such that x < l.
Claim. m = Sup (B).
Proof of claim.
Part 1. First, we will prove: if y ∈B, then m ≤y.
Assume y ∈B. Assume by way of contradiction that y > m. Then by the last
observation ∃x ∈UB(B) such that x < y. But then x is an upper bound on B and
so y ≤x. Then x < y ≤x is a contradiction.
Part 2. Now we will prove: if l < m, then ∃y ∈B s.t. y > l.
Assume l < m. By the contrapositive stated just before the claim,
l ∉UB(B).
(10.12)
Thus, l is not an upper bound of B. Thus, there must be an element y ∈B that
prevents this. So y ∈B with y > l.
These two parts prove that m = Sup(B).
◾
Thus, B has a supremum, and our proof is complete.
◽
10.3
Equivalence relations
10.3.1
Deﬁnitions
Not only can relations on a set be used to measure the size, but they can also
be used to tell when elements are “sort of” the same. Of course, exactly what
this means depends on the context. Typically, the relation is deﬁned carefully
before it is used. Still, most relations are useless, and a relation cannot mean
“sort of the same” unless it has certain properties.
Deﬁnition 10.3.1.
Let A be a set. A relation on A is an equivalence relation
when it is reﬂexive, symmetric, and transitive.
Before we can tell if a relation on a set A is an equivalence relation, we must
be given a very precise deﬁnition telling us which elements are related. To use

10.3 Equivalence relations
183
the relation, we simply assign the deﬁnitions as its complete meaning, no more
and no less.
Example 10.3.2.
Let S = {1, 2, 3, 4}. Consider the relation given by
= {(1, 1), (2, 2), (2, 3), (3, 2), (3, 3), (4, 4)}.
(10.13)
Upon checking, we ﬁnd that this is reﬂexive, symmetric, and transitive. It is an
equivalence relation.
Example 10.3.3.
Consider the relation on ℤgiven by a ≏b if and only if a −b
is divisible by 7. Upon checking, we ﬁnd that this is reﬂexive, symmetric, and
transitive. It is an equivalence relation.
Example 10.3.4.
Consider the relation on ℝgiven by a ⊪b if and only if
|a −b| < 1. Upon checking, we ﬁnd that this is reﬂexive, symmetric, but it is
not transitive. It is not an equivalence relation.
Not surprisingly, once we realize that a relation is an equivalence relation,
instead of writing ab, we usually write something like a ≡b or a ∼b or a ≃b.
There are even more symbols used for equivalence relations than symbols for
order, and any one of them might be used in a particular situation. There is no
real standard. One good thing though, we rarely have more than one equiv-
alence relation on a set to consider at a time. Once we have a deﬁnition and
choose a symbol, that is it until we change the subject entirely.
Example 10.3.5.
Deﬁne a relation on ℤby n ≃m if n −m is even. The answer
to the question “What does ≃mean?” is “It means n −m is even,” no more or no
less. The answer to the question “What does ≃tell us about integers?” requires
a mathematical investigation. The ﬁrst step in such an investigation is to prove
that ≃is an equivalence relation:
Reﬂexivity. We claim that ≃is reﬂexive. That is, we claim: If n ∈ℤ, then
n ≃n.
Proof of claim. Assume n ∈ℤ. Consider n −n. Since n −n = 0 is even,
n ≃n.
◾
Symmetry. We now claim that ≃is symmetric. That is, we claim:
If n ≃m, then m ≃n.
Proof of claim. Assume n ≃m. Then n −m is even. So there exists k ∈ℤsuch
that n −m = 2k. Consider m −n. Now
m −n = −(n −m) = −2k = 2 ⋅(−k)
(10.14)
is even. So m ≃n.
◾

184
10 Relations
Transitivity. We ﬁnally claim that ≃is transitive. That is, we claim:
If n ≃m and m ≃p, then n ≃p.
Proof of claim. Assume n ≃m. So n −m is even. So ∃k ∈ℤs.t. n −m = 2k.
Assume m ≃p. So m −p is even. So ∃k′ ∈ℤs.t. m −p = 2k′. Consider n −p.
Now
n −p = (2k + m) −(m −2k′) = 2k + 2k′ = 2(k + k′)
(10.15)
is even. So n ≃p.
◾
Since ≃is reﬂexive, symmetric, and transitive, it follows that ≃is an equiva-
lence relation.
Proving that speciﬁc examples such as this are equivalence relations is not
diﬃcult if we maintain our logical discipline by writing each as an implication.
We just start each part of the proof with the correct assumptions. However, we
must have and use an exact mathematical deﬁnition of the speciﬁc relation.
10.3.2
Equivalence classes
Now we move back to the study of any relation that happens to be an equiva-
lence relation. We see how we can put an equivalence relation to good use.
Deﬁnition 10.3.6.
Let A be a set with an equivalence relation ≡. For any
a ∈A, the equivalence class of a is the set
[a] = {x ∈A ∣x ≡a}.
(10.16)
Using our aforementioned example where n ≡m means n −m is even (the
notation for the equivalence does not matter), we can see that
[5] = {n ∈ℤ∣x ≡5}
(10.17)
= {n ∈ℤ∣x −5 is even}
= {5, 7, 9, 11 …} ∪{… −3, −1, 1, 3}
= {… −3, −1, 1, 3, 5, 7, 9, 11 …}.
We need to be sure to ﬁnd all the equivalent n when we create a list. In addition,
[8] = {n ∈ℤ∣x ≡8}
(10.18)
= {… −2, 0, 2, 4, 6, 8, 10, … 12, 14 …}.
And
[11] = {… 1, 3, 5, 7, 9, 11, 13, 15 …}
(10.19)
[0] = {… −4, −2, 0, 2, 4 …}
[1] = {… −3, −1, 1, 3, 5 …}.

10.3 Equivalence relations
185
By our deﬁnition of set equality, many of these are the same:
[5] = [11] = [1];
(10.20)
[8] = [0];
[0] ≠[1].
In the end, there are actually only two diﬀerent equivalence classes for this
particular equivalence relation: the set of odd integers and the set of even
integers.
Theorem 10.3.7.
Let A be a set with an equivalence relation ≡. Assume that
a, b ∈A.
1. a ∈[a].
2. If a ∈[b], then [a] = [b].
3. If [a] ∩[b] ≠∅, then [a] = [b].
Proof. Assume that we have an equivalence relation ≡on the set A. Assume
that a, b ∈A.
Since we have an equivalence relation, it is reﬂexive. So a ≡a. This shows that
a ∈[a] and proves part 1.
To prove part 2, assume a ∈[b]. Then a ≡b. Since [a] and [b] are sets, we
prove that they are equal by proving subset both ways.
(⊆): Assume x ∈[a]. Then x ≡a. But we assumed that a ≡b. By transitivity,
x ≡b. So x ∈[b]. Thus, if x ∈[a], then x ∈[b]. This proves that [a] ⊆[b].
(⊇): Assume x ∈[b]. Then x ≡b. But we assumed that a ≡b. So by symmetry,
b ≡a. By transitivity, x ≡a. So x ∈[a]. Thus, if x ∈[b], then x ∈[a]. This proves
that [b] ⊆[a].
Since [a] ⊆[b] and [b] ⊆[a], it follows that [a] = [b], and part 2 is proved.
Finally, let us prove part (3). Assume [a] ∩[b] ≠∅. So ∃c ∈[a] ∩[b]. So
c ∈[a] and c ∈[b]. However, part 2 tells us that c ∈[a] implies [c] = [a], and
c ∈[b] implies [c] = [b]. So [a] = [c] = [b].
◽
10.3.3
Equivalence partitions
This set algebra for equivalence classes is useful in its own right, but we will
rewrite it as another theorem.
Theorem 10.3.8.
Let A be a set with an equivalence relation ≡. Then
⋃
a∈A
[a] = A;
(10.21)
if [a] ∩[b] ≠∅, then [a] = [b].

186
10 Relations
Proof. Assume that A is a set with an equivalence relation ≡.
Claim. We ﬁrst prove that ⋃
a∈A
[a] = A.
Proof of claim. This is a set equality, so we must prove set inclusion both ways.
(⊆): Since ∀a ∈A, [a] ⊆A, ⋃
a∈A
[a] ⊆A.
(⊇): Assume x ∈A. Then by the last theorem, x ∈[x]. So x ∈⋃
a∈A
[a].
◾
Claim. We next claim that if [a] ∩[b] ≠∅, then [a] = [b].
This is exactly what was stated and proved in Theorem 10.3.7
◽
So if a relation on a set A is reﬂexive, symmetric, and transitive, it is an equiv-
alence relation. An equivalence relations tells us that two elements of A are
“sort of” the same. That is, a ≡b tells us that a and b are equivalent in some
sense. The exact sense in which they are equivalent depends on the deﬁnition
of the symbol ≡at that time. The last theorem tells us that, if we gather the
equivalent elements of A into equivalence classes, every element of A ends up
in exactly one of them. In addition, there is no overlap between two diﬀerent
classes. Even one element in common to two of the classes means that they are
the same class.
That leads to our next deﬁnition; actually, it is more of a notation.
Deﬁnition 10.3.9.
Let A be a set with an equivalence relation ≡. We deﬁne a
new set called “A modulo equivalence” or “A mod ≡” as
A∕≡= {[a] ⊆A ∣a ∈A}
(10.22)
where [a] = {x ∈A ∣x ≡a}.
Thus, A∕≡means that the set made up of the equivalence classes deﬁned by
the relation ≡. Thus, A∕≡is a set of clumps of stuﬀfrom A. It is not a subset of
A, but it is a set of subsets of A. It provides a way to treat the elements of A that
are “sort of” the same as if they were actually the same.
In our example, we saw that [0] = [2] = [4] = [−8] = … . We also saw that
[1] = [3] = [5] = [−3] …. It seems that the equivalence class of any even num-
ber is the set of all even numbers, and the equivalence class of any odd number
is the set of all odd numbers. The equivalence relation ≃that we deﬁned on ℤ
divides ℤinto two disjoint sets. (Disjoint means that they have no element in
common.) Thus, we can write
(ℤ∕≃) = {[0], [1]}
(10.23)
= {The set of even integers, The set of odd integers}.

10.3 Equivalence relations
187
10.3.3.1
Well deﬁned
There is one last thing to say about the set formed by “mod-ing out by equiva-
lence.” (That is to say, sets of the form A∕≡.) The elements in this type of set have
more than one name. By deﬁnition,
A∕≡= {[a] ⊆A ∣a ∈A}.
(10.24)
But if a1 ≡a2 even though a1 ≠a2, we still have [a1] = [a2]. Thus, a1 ≡a2 are
diﬀerent elements of the set A; but they are equivalent elements of A. Each can
be used to identify an element of A∕≡. The equivalence class of a1 is an element
of A∕≡, which we write as [a1]. The equivalence class of a2 is an element of A∕≡,
which we write as [a2]. If a1 ≡a2, then their equivalence classes are equal as
sets: [a1] = [a2]. In the set of equivalence classes A∕≡, they are equal classes; so
they are the same element of A∕≡. Thus, we can say that a1 and a2 are both valid
names for the same element [a1] = [a2] of A∕≡. In any set formed by equivalence
classes, any one class can have multiple names.
This matters when it comes time to deﬁne something on a set such as A∕≡.
We want all mathematical deﬁnitions to give unique results. When we deﬁne
something on elements of A∕≡, we usually use the names of those objects. Thus,
we need to know that the thing we deﬁne does not depend on the name for
the elements involved. The issue of the uniqueness of a deﬁnition on a set of
the type A∕≡comes up so often that it has its own terminology; we talk about a
deﬁnition being well deﬁned.
For example, we go back to the equivalence relation where n ≃m means that
n −m is even. Thus,
ℤ∕≃= { … [−3], [−2], [−1], [0], [1], [2], [3] … }
(10.25)
= {[0], [1]}
= {the set of odd integers, the set of even integers}.
Now there are only two elements in ℤ∕≃because all the even numbers are equiv-
alent and all the odd numbers are equivalent.
Suppose that we try to deﬁne a way to add two elements of ℤ∕≃by
[n] + [m] = [n + m].
(10.26)
Now suppose that [n] = [6] = [0] and [m] = [−3] = [1]. We have four choices
when it is time to compute [n + m]:
[6 + (−3)]; [6 + 1]; [0 + (−3)] or [0 + 1].
(10.27)
We must check that all four choices give the same answer; that is what “well
deﬁned” means. Since 3, 7, −3, and 1 are all odd, they all belong to the same
equivalence class:
[6 + (−3)] = [6 + 1] = [0 + (−3)] = [0 + 1].
(10.28)

188
10 Relations
To be sure that this addition is well deﬁned, we must prove it. We need to prove
that, if we use diﬀerent names to add elements of ℤ∕≃, we still get the same
answer. (We rephrased the problem as an “if then.”)
Proof technique. When asked to prove that something is “well deﬁned,” this
often indicates that the objects involved have more than one possible name,
and the thing being deﬁned depends on the name used. Thus, we begin a proof
by assuming that each ingredient in deﬁnition is given by two diﬀerent names.
Application of the deﬁnition should produce a unique result even if not a
unique name.
Claim. We claim that addition of the equivalence classes ℤ∕≃is well deﬁned.
That is, we claim that
If [n1] = [n2] and [m1] = [m2], then [n1] + [m1] = [n2] + [m2].
Proof of claim. Assume [n1] = [n2] and [m1] = [m2]. Then n1 −m1 is even, and
n2 −m2 is even. By a previous theorem (that we could reprove if we wanted to),
the sum (n1 −m1)+ (n2 −m2) is even. And so (n1 + n2) −(m1 + m2) is even. So
[n1 + n2] = [m1 + m2]. So [n1] + [m1] = [n2] + [m2].
◾
10.4
Problems
10.1
Prove:
(a) Let U be a set with a total order. If A ⊆U has a minimum, then it
is unique.
(b) Let U be a set with a total order. If A ⊆U has a maximum, then it is
unique.
(c) Let U be a set with a total order. If A ⊆U has an inﬁmum, then it
is unique.
(d) Let U be a set with a total order. If A ⊆U has a supremum, then
it is unique.
(e) Let U be a set with a total order. If A ⊆U and m = Inf(A), then m
is the greatest of all lower bounds of A.
(f) Let U be a set with a total order. If A ⊆U and m = Sup(A), then m
is the least of all upper bounds of A.
10.2
Let U be the integers. Prove that if S ⊆U with S ≠∅and where S is
bounded above, then S has a maximum.

10.4 Problems
189
10.3
Let U be a set with a total order (with at least two elements). For S ⊆U,
let
UB(S) = {u ∈U ∣u is an upper bound on the set S};
LB(S) = {l ∈U ∣l is an upper bound on the set S}.
Prove:
(a) ∀S ⊆U, S ⊆LB(UB(S)).
(b) ∀S ⊆U, S ⊆UB(LB(S)).
(c) ∃S ⊆U s.t. S ≠LB(UB(S)).
(d) ∃S ⊆U s.t. S ≠UB(LB(S)).
10.4
Consider the relation on ℤdeﬁned by nm if n + m is even.
(a) Is reﬂexive?
(b) Is symmetric?
(c) Is transitive?
(d) Does have trichotomy?
10.5
Consider the relation on ℝdeﬁned by n ≃m if n −m ∈ℤ.
(a) Is ≃reﬂexive?
(b) Is ≃symmetric?
(c) Is ≃transitive?
(d) Does ≃have trichotomy?
10.6
Let A = {a, b, c}. Let () = {S | S ⊆A}.
(a) Is the relation “is a subset of” a relation on A?
(b) Is the relation “is a subset of” a relation on (A)?
(c) Does the relation “is a subset of” have transitivity on (A)?
(d) Does the relation “is a subset of” have trichotomy on (A)?
(e) Is the relation “is a subset of” a total order on (A)?
(f) Is (A) well ordered by the relation “is a subset of?”
10.7
Explain how a set of equivalence classes A∕≃is related to a family of sets.
10.8
Consider the relation on a nonempty set A deﬁned by ab is
always true.
(a) Describe as a set.
(b) Is reﬂexive?
(c) Is symmetric?
(d) Is transitive?
(e) Does have trichotomy?
10.9
Consider that the relation on a nonempty set A deﬁned by ab is
never true.

190
10 Relations
(a) Describe as a set.
(b) Is reﬂexive?
(c) Is symmetric?
(d) Is transitive?
(e) Does have trichotomy?
10.10
Consider the set S = {1, 2, … , 100}. But, consider this set ordered in
alphabetical order. Write “n appears in alphabetical order before m” as
n ≺m.
(a) Is this a total order on S?
(b) What is the minimum of the set S in alphabetical order?
10.11
Consider the set S = { −1000, −999, … , 0, … , 999, 1000}. Suppose
that we consider S with alphabetical order.
(a) Is this a total order on S?
(b) Is 8 a lower bound on the set of negative integers in S?
(c) Is 10 a lower bound on the set of negative integers in S?
(d) Does the set S have a minimum in this order?
(e) Is 1 an upper bound on the negative integers in S?
(f) Does the set of negative integers in S have a maximum in this order?
(g) Show that addition does not respect alphabetical order.
10.12
If A is a set with a total order, why do we never use the symbol ≤for the
order?
10.13
Let U be a set with a total order that is complete. For S ⊆U, let
UB(S) = {u ∈U ∣u is an upper bound on the set S}.
(10.29)
(a) Prove: If s ∈S, then s is a lower bound of UB(S).
(b) Prove: If S ≠∅and UB(S) ≠∅, then UB(S) has an inﬁmum.
(c) Prove: If S ≠∅and UB(S) ≠∅, then UB(S) has a minimum.
10.14
Consider the relation on ℤgiven by a ≏b if and only if a −b is divisible
by 7.
(a) Prove that this is an equivalence relation.
(b) Describe [3] for this relation.
(c) Find ℤ∕≏.
(d) Prove that an addition on ℤ∕≏deﬁned by [n] + [m] = [n + m] is well
deﬁned.
10.15
Consider the relation on ℝgiven by a ⊪b if and only if |a −b| < 1.
(a) Prove that this is reﬂexive and symmetric.
(b) Find an example where it is not transitive.

10.4 Problems
191
10.16
Let S = ℤ× ℕ. Deﬁne a relation on S by (n, m) ≡(p, q) if nq = mp.
(a) Prove that this is an equivalence relation.
(b) The set S∕≡has a much better and more familiar name. What is it?
(c) Deﬁne an addition on S∕≡by [(n, m)] ⊕[(p, q)] = [(nq + mp, mq)].
Prove that it is well deﬁned.
(d) We cannot deﬁne an addition on S∕≡by [(n, m)] ⊕[(p, q)] = [(n +
p, m + q)]. Why not?
10.17
Deﬁne a relation ⋖on the set ℚ(
√
2) = {a + b𝜙∣a, b ∈ℚ} by
s + t𝜙⋖u + 𝑣𝜙if |s −u|(s −u) < 2|𝑣−t|(𝑣−t).
(10.30)
Prove that the relation satisﬁes trichotomy. (You might also prove that
it is transitive, but this is not an exercise for the faint of heart.)
10.18
True or False:
(a) For all sets A and B, A ∪B ⊆A × B.
(b) For all sets A, A × ∅= A.
(c) ℤis a well-ordered set.
(d) ℚis a well-ordered set.
(e) ℝis a well-ordered set.
(f) ℤis a complete set.
(g) ℚis a complete set.
(h) ℝis a complete set.
(i) ∅has a lower bound in ℝ.
(j) ∅has a minimum in ℝ.
(k) ∅has an inﬁmum in ℝ.
(l) ℕhas an inﬁmum in ℝ.
(m) ℤhas a lower bound in ℝ.
10.19
Consider the set S = {a, b, c, d, e, f } and the relation ⊆× given
by
={(a, a), (a, b), (a, d), (b, a), (b, b), (b, d), (c, c),
(10.31)
(c, f ), (d, a), (d, b), (d, d), (e, e), (f , c), (f , f )}.
As it happens, is an equivalence relation on S. Given this, ﬁnd S∕.
10.20
Consider the set S = {a, b, c, d, e, f } and the relation ⊆× given
by
= {(a, a), (a, b), (a, d), (a, c), (a, f ),
(10.32)
(b, a), (b, b), (b, d), (c, c),
(c, f ), (d, a), (d, b), (d, d), (e, e), (f , c), (f , f )}
As it happens, is not an equivalence relation on S. Because of this,
S∕is not deﬁned. What happens if you try to ﬁnd it anyway?

192
10 Relations
10.21
The alternate completeness axiom is called this because it could be used
in place of our oﬃcial completeness axiom.
Let U be a set with a total order and suppose that if for all B ⊆U with B
not empty and B bounded above, there is an m ∈U so that m = Sup(B).
Prove that if A ⊆U is not empty and bounded below, then there is an
m ∈U so that m = Inf(A).

193
11
Functions
11.1
Deﬁnitions
11.1.1
Preliminary ideas
The next relation we study is a familiar one that relates elements in two sets.
The idea of a function is central to all of Mathematics. Unfortunately, there are
some mild disagreements over the meaning of the most common notation for
functions, and this slips over into any precise deﬁnition that we might give.
Since one of our objectives in this study is to be as careful as possible, we will
need to be very precise as we discuss this very familiar concept especially in
regard to the notation. Luckily, this extremely heightened level of precision for
functions will mostly be restricted to this chapter.
The most familiar functions in algebra and calculus are functions mapping
the real numbers to the real numbers that are given by a formula. Thus, typically
when we ﬁrst learn about functions, we are told that they are given by a rule.
For example, if x is a real number, then f (x) is the number given by the rule
“Take the number x; square it, and add 1 to the result.” That is, f (x) = x2 + 1.
Eventually, we learn more complicated rules such as
|x| =
⎧
⎪
⎨
⎪⎩
x
if x > 0
0
if x = 0
−x
if x < 0
.
(11.1)
As long as there is no ambiguity in the rule, we have a function. That is to say,
the result of applying a function to a number should be unique.
Functions mapping the real numbers to the real numbers have nice pictures,
their graphs. Given a curve drawn on the Cartesian plane, we learn to apply the
rule given by the curve:
Find the point x on the x-axis; follow it up or down to a point on the
curve; follow that point over to the y-axis; and the value of that point on
the y-axis is f (x).
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

194
11 Functions
Because the value of f (x) must be unique, we learn to recognize the graph of
a function by applying the “vertical line test.”
Now we are interested in more general types of functions, functions that go
from any set to any other set. For example, suppose that a company is setting
up a lunch for employees from all of its departments. To make sure that people
get a chance to meet others that they might not normally come in contact with,
the organizers create a list of table assignments. Each attendee is given a card
with a table number from 1 to 10. They deliberately assign each table to create
an interesting group of members. This assignment is a function from the set of
attendees to the set of numbers 1 through 10. There is no strict “rule” in the
function. An attendee cannot ﬁnd their table by following any rule other than
“Look at your card.” The organizers have a rationale in creating the function,
but not a speciﬁc rule.
Just before the name cards are placed on the tables, someone drops them.
It is too late to reconstruct the original function, and the table cards are
distributed randomly as people arrive. This creates a new function from the
list of attendees to the numbers 1 through 10. This new assignment is still a
function even though there is no rhyme or reason for the assignments. It is a
function even though there is no rule or even a rationale for the assignments
given by the function. It is a function because it is an assignment of one person
to exactly one table. It passes a type of “vertical line test” because no one
person is assigned to two tables. It pairs a person with a table number; it is this
pairing that makes a function.
11.1.2
The technical deﬁnition
Because there is some disagreement about where functions are deﬁned, our
deﬁnition might not be the exact same as we would see in a diﬀerent mathe-
matical study. However, as we examine it, it will be clear how close it must be to
any other possible deﬁnition. Our deﬁnition also has the advantage that it con-
forms to the deﬁnitions of related terms that have been used in earlier courses.
This extra careful deﬁnition will mean that we do not have to change the way
we learned to talk about functions in algebra and calculus. In a short time, we
will rely on our old understanding of function. Soon we will no longer need to
be so careful with the technical deﬁnition we give here.
The technical deﬁnition is not the way we were ﬁrst introduced to functions.
And at ﬁrst, it does seem a bit odd.
Deﬁnition 11.1.1.
Let A and B be sets. A function from A to B is a pair (f , B)
where f ⊆A × B such that if (a, b1) ∈f and (a, b2) ∈f , then b1 = b2.
Typically, we introduce a function as f ∶ℝ→ℝand write (a, b) ∈f as
f (a) = b. By now we can recognize a uniqueness property when we see one.

11.1 Deﬁnitions
195
In terms of the notation, the second requirement in the deﬁnition guarantees
that for a function f ∶A →B, we know that f (a) ∈B is unique to the element
a. In the new notation, the condition in the pairs:
if (a, b1) ∈f and (a, b2) ∈f , then b1 = b2.
becomes
if f (a) = b1 and f (a) = b2, then b1 = b2.
Thus, when we have a function f ∶A →B, the notation f (a) has only one pos-
sible meaning, just as all mathematical notation should.
Notice that the important thing is the assignment, and there is no require-
ment about how that assignment is made except that, once made, it is always
the same for that particular function. That is to say, f can be any relation from
the set A × B as long as it satisﬁes the uniqueness property. It is not hard to see
that this uniqueness property is just a generalized statement of the old famil-
iar vertical line test applied to situations where there are no lines and “vertical”
makes no sense.
As familiar as some of these are, the idea that a function is a pair (f , B) and not
a “rule” is a bit odd. The relation f ⊆A × B in this pair need not follow any set
“rule;” rather, it is just an assignment of a unique element in B for each element
of A. The assignment is listed out by the ordered pairs in the relation. If the
function (f , B) has a rule, it is simply “look at the list of assignments given in
the relation f ⊆A × B.”
The set A in the pair is a set of things for which the relation could make an
assignment: “the things that may go into the function.” For some reason, we
will not require every element of A to actually receive an assignment. Soon
we will give a name to the subset of A for which the function does make an
assignment: “the things that do go into the function.” (Not all mathematicians
agree with this decision to not require every element of A to be associated with
a b in B.) The set B denotes “the things that may come out of the function.”
Again, we do not require that every element of B be used, and this generally is
the way it works in all Mathematics. Soon we will give a name to the subset of
B of “the things that do come out of the function.”
For some reason, we made a point of including B in the pair (f , B) in deﬁn-
ing a function. This makes the set B an important part of the deﬁnition of a
function. It is every bit as important in identifying the exact function as the
assignment implied by the relation f . We will investigate this very carefully in
a few examples. We start with a function between two rather small sets.
Example 11.1.2.
Let A = {1, 2, 3, 4, 5}, Let B = {2, 4, 6, 8}.
Let f = {(1, 2), (2, 4), (3, 4), (4, 8)}. Then (f , B) satisﬁes the deﬁnition of a
function. It is a bit easier to see this in the following table.

196
11 Functions
x
f (x)
1
2
2
4
3
4
4
8
5
For each x ∈A except x = 5, there is a unique value assigned to f (x). It
is certainly possible to describe f (x) as a rule in words, but nothing natu-
ral comes to mind. Nevertheless, it is a perfectly ﬁne function f ∶A →B.
The oﬃcial deﬁnition “(f , B) where A = {1, 2, 3, 4, 5}, B = {2, 4, 6, 8}, and
f = {(1, 2), (2, 4), (3, 4), (4, 8)}” indeed gives a function, but after that, the best
way to deal with f (x) is by the table.
Example 11.1.3.
Let
A = B = ℝ.
Let
f = {(a, b) ∈ℝ2 ∣ab = 1}.
This
describes a diﬀerent function (f , B). We are not very likely to use the technical
deﬁnition for it. Rather, we would normally say f ∶ℝ→ℝis given by f (x) = 1
x.
The technical deﬁnition is still in the background, but we immediately move
to the superior notation to work with the function. Notice that 0 ∈A = ℝ, but
f (0) is not deﬁned.
Before we look at a few more examples, we give some deﬁnitions that will
help us draw distinctions between similar functions. We will then look at this
last example and other examples related to it very carefully.
Deﬁnition 11.1.4.
Let f ∶A →B be a function. The domain of f is
Domain(f ) = {a ∈A ∣∃b ∈B s.t. (a, b) ∈f }
= {a ∈A ∣∃b ∈B s.t. f (a) = b}.
Of course, the second form is the one we will use exclusively once we are done
with the technicalities of this chapter. Notice that the deﬁnition of a function
means that Domain(f ) ⊆A.
Deﬁnition 11.1.5.
Let f ∶A →B be a function. The range of f is
Range(f ) = {b ∈B | ∃a ∈A s.t. (a, b) ∈f }
= {b ∈B | ∃a ∈A s.t. f (a) = b}.
The deﬁnition of function guarantees that Range(f ) ⊆B.
Notice that there is nothing in the deﬁnition of a function that requires that
Domain(f ) = A or Range(f ) = B. This is where other deﬁnitions of a function
may diﬀer from ours.

11.1 Deﬁnitions
197
Deﬁnition 11.1.6.
Let f ∶A →B be a function. The codomain of f is:
Codomain(f ) = B.
Deﬁnition 11.1.7.
Let f ∶A →B be a function. We say that f (x) is injective
(one-to-one) when
if f (a1) = f (a2), then a1 = a2.
Deﬁnition 11.1.8.
Let f ∶A →B be a function. We say that f (x) is surjective
(onto) when
if b ∈B, then ∃a ∈A s.t. f (a) = b.
All of these, except the codomain, should be familiar. The domain of the func-
tion is the set of things you can actually put into the function and get a result
out. The range of a function is the collection of things that actually come out
of the function. The range is a subset of the codomain, which is just a list of
what you think may come out before you get to examine the function closely. A
function is injective, if it satisﬁes the “horizontal line test.” It is permission to
“cancel” a function in an equation
(f (a) = f (b)) ⇒(a = b)
(11.2)
although no self-respecting mathematician would ever admit doing so. A
function is surjective if everything that might come out actually does. In other
words, a function f ∶A →B is surjective when Range(f ) = Codomain(f ).
11.1.2.1
A word about notation
Before we start, we should say a few things about the notation. The common
notation for a function (f , B) is f ∶A →B, where we write (a, b) ∈f as f (a) =
b. By the uniqueness requirement in the deﬁnition, there is no ambiguity in
the meaning of f (a). Now that we are becoming more mathematically sophis-
ticated, it is good practice to always introduce a function with the notation
f ∶A →B. Our deﬁnition of function still allows us to think the way we have
before. In calculus of any sort, it is common to introduce a function f ∶ℝ→ℝ
by giving a formula for f (x).
For example, we might say
let f ∶ℝ→ℝbe given by f (x) = 1
x.
The domain of this function is ℝ∖{0} because 0 has no multiplicative inverse.
We could have admitted that this is the case by saying more precisely
let f ∶ℝ∖{0} →ℝbe given by f (x) = 1
x.

198
11 Functions
While ℝ∖{0} is the actual domain of the function, it looked at ﬁrst like it
was ℝ. Thus saying f ∶ℝ→ℝonly identiﬁes ℝas a potential domain of the
function. This potential domain has no oﬃcial name, and it is used simply as
a matter of convenience. The advantage of this imprecision is that we can say
“Let f ∶ℝ→ℝbe given by f (x) =
1
x3−3x+5” without spelling out the precise real
numbers where the function is not deﬁned.
We will often need to acknowledge this technicality by making assumptions
about the domain as a part of later deﬁnitions and theorems. Thus, we will say
“Let f ∶ℝ→ℝhave domain A” when we mean any unspeciﬁed function with
the exact domain A ⊆ℝ.
Example 11.1.9.
Let us explore the similarities and diﬀerences between the
functions
1. f1 ∶ℝ→ℝgiven by f1(x) = 1
x,
2. f2 ∶ℝ→ℝ∖{0} given by f2(x) = 1
x,
3. f3 ∶ℝ∖{0} →ℝgiven by f3(x) = 1
x, and
4. f4 ∶ℝ∖{0} →ℝ∖{0} given by f4(x) = 1
x.
First, there is one obvious similarity between these four functions. In each
case, the rule used to deﬁne the function is the same, namely the formula 1
x.
As a consequence, none of these four functions are deﬁned at x = 0. Another
similarity is that y = 0 is not in the range of any of these functions. Thus, all of
these functions have the same graph – namely
{(x, y) ∈ℝ2 ∣xy = 1}.
(11.3)
And, if we were to draw a picture of this graph, it would be the same for all four
functions (Figure 11.1).
As we can see, the ordered pairs form a geometric shape that we call a curve,
and it satisﬁes the vertical line test. Of course, the curve is a geometric rep-
resentation of a set of ordered pairs. It is technically not equal to the set of
ordered pairs. It is technically not the function either. Once we become experts,
we might at times treat the curve as though it were the function. But if that ever
causes confusion, we must return to our roots and use the careful deﬁnitions.
Now we turn to the diﬀerences between these four functions.
1. f1 ∶ℝ→ℝgiven by f1(x) = 1
x.
Technically, the function is the ordered pair (f1, ℝ), where
f1 = {(x, y) ∈ℝ2 ∣yx = 1}.
(11.4)
We ﬁnd that f1(x) is injective, but because 0 is not in the range, f1(x) is not
surjective. And
Domain(f1) = ℝ∖{0};

11.1 Deﬁnitions
199
−4
−2
2
4
−2
−1
1
2
x
y
Figure 11.1 y = 1
x .
Range(f1) = ℝ∖{0};
Codomain(f1) = ℝ.
2. f2 ∶ℝ→ℝ∖{0} given by f2(x) = 1
x.
Here, technically the function is (f2, ℝ∖{0}), where
f2 = {(x, y) ∈ℝ2 ∣yx = 1}.
(11.5)
Although as sets of ordered pairs we have f1 = f2 (and drawing the graph of
f2 again gives Figure 11.1), the fact that ℝ≠ℝ∖{0} makes the pairs diﬀerent.
That is, the functions, according to our deﬁnition, are diﬀerent. That is good,
because the answers to the fundamental questions about the two functions
are diﬀerent.
We ﬁnd that f2(x) is injective, and it is also surjective (unlike f1(x)). We also
have
Domain(f2) = ℝ∖{0};
Range(f2) = ℝ∖{0};
Codomain(f2) = ℝ∖{0}.
3. f3 ∶ℝ∖{0} →ℝgiven by f2(x) = 1
x.
Technically, the function is (f3, ℝ) where
f3 = {(x, y) ∈ℝ2 ∣yx = 1}.
(11.6)
We can again draw a picture of the relation f3 on the Cartesian plane ℝ2 and
obtain Figure 11.1. As indicated earlier, it is again quite clear that as sets of
ordered pairs f1 = f2 = f3.
Now the codomain is part of the deﬁnition of functions as pairs (f3, ℝ). But
the potential domain is conspicuously not. Thus, as pairs (f3, ℝ) = (f1, ℝ),
while (f3, ℝ) ≠(f2, ℝ∖{0}). So according to our technical deﬁnition, the func-
tions (f3, ℝ) and (f1, ℝ) are the same function, but (f3, ℝ) is not the same

200
11 Functions
function as (f2, ℝ∖{0}). We should see this reﬂected in the answers to the
fundamental questions about f1(x), f2(x), and f3(x). We ﬁnd that f3(x) is injec-
tive, but not surjective, and
Domain(f3) = ℝ∖{0};
Range(f3) = ℝ∖{0};
Codomain(f3) = ℝ.
4. f4 ∶ℝ∖{0} →ℝ∖{0} given by f4(x) = 1
x.
Technically, the function is (f4, ℝ∖{0}) where
f4 = {(x, y) ∈ℝ2 ∣yx = 1}.
(11.7)
Again, a picture of the relation f4 on the Cartesian plane ℝ2 would be
Figure 11.1. We have f1 = f2 = f3 = f4.
As pairs (f3, ℝ) = (f1, ℝ), and (f4, ℝ∖{0}) = (f2, ℝ∖{0}). Thus, we expect that
the answers to the fundamental questions about f2(x) and f4(x) will be the
same, but not the same answers as for f1(x) and f3(x)
We ﬁnd that f4(x) is both injective and surjective, and
Domain(f4) = ℝ∖{0};
Range(f4) = ℝ∖{0};
Codomain(f4) = ℝ∖{0}.
Example 11.1.10.
Let f5 ∶(0, ∞) →ℝbe given by f4(x) = 1
x.
This looks like it might be f1(x) again since the prospective domain we use
should not matter. But we must be careful. The potential domain has changed
so much that it added a condition on the ordered pairs in the set f5. This time
f5 is given by
f5 = {(x, y) ∈ℝ2| x > 0 and yx = 1}.
(11.8)
We draw a picture of f5 on the Cartesian plane ℝ2, as shown in Figure 11.2.
The ordered pairs still form a curve that satisﬁes the vertical line test, but it is
only a part of the curves formed by f1 = f2 = f3 = f4. We have f5 ⊆f1, because we
used the same formula for both functions, but we do not have f5 = f1 because
the pairs are not equal. Since (f1, ℝ) ≠(f5, ℝ), the functions are diﬀerent by our
technical deﬁnition.
We ﬁnd that f5(x) is injective but not surjective. In addition,
Domain(f5) = (0, ∞);
Range(f5) = (0, ∞);
Codomain(f5) = ℝ.

11.1 Deﬁnitions
201
−4
−2
2
4
−2
−1
1
2
x
y
Figure 11.2 y = 1
x for x > 0.
Notice that the formula 1
x is the same for f1(x), f2(x), f3(x), f4(x), and f5(x).
However, we have the functions f1 ∶ℝ→ℝ, f2 ∶ℝ→ℝ∖{0}, f3 ∶ℝ∖{0} →ℝ,
and f4 ∶ℝ∖{0} →ℝ∖{0}. The codomain immediately made f1(x) diﬀerent than
f2(x) and f4(x). But because only the potential domain was given in f1 ∶ℝ→ℝ,
and its actual domain given in f3 ∶ℝ∖{0} →ℝ, that change had no impact on
the ordered pairs. So the functions are technically the same. On the other hand,
f5 ∶(0, ∞) →ℝreally restricts the potential domain and thus shrinks the actual
domain. That has the eﬀect of making the set f5 a proper subset of f1. Since f5 ≠f1
as sets of ordered pairs, they cannot be the same function: (f1, ℝ) ≠(f5, ℝ).
The prospective domain in the notation f ∶A →B may not be part of the
technical deﬁnition, but it might have an impact on the ordered pairs in that
technical deﬁnition. We need to pay attention to it.
Just as promised, this was pretty technical. Still these distinctions will shift
into the background very soon. Every once in a while the technical deﬁnition of
a function might raise its ugly head –but mostly not. If it does appear, it really
is not something that will be hard to deal with. Even in this chapter where the
technical deﬁnition should play a big role, it only really comes up in one place.
In that case, it makes things easier rather than more diﬃcult.
We have one last type of function we want to identify, a bijection. To be a
bijection, a function must meet three conditions:
Deﬁnition 11.1.11.
Let f (x) be a function presented as f ∶A →B. We say
that f (x) is bijective when 1) Domain(f ) = A, 2) f (x) is injective, and 3) f (x) is
surjective.
The ﬁrst condition in the deﬁnition of a bijective function is important given
our deﬁnition of a function. To be a bijection, f ∶A →B must have the set A as
its full domain. That way, for every a ∈A, f (a) is deﬁned.

202
11 Functions
11.2
Visualizing functions
11.2.1
Graphs in ℝ2
We learned how to visualize functions f ∶ℝ→ℝas curves in the Cartesian
plane long ago, and we can use this skill to a great advantage. However, we need
to adapt some of our ideas about graphing to this new more careful setting. In
our old setting, a curve could be interpreted as a function y = f (x) by looking
at the points on it. Here x was the positive or negative distance of the point
on the curve from the vertical axis, and y is the distance above or below the
horizontal axis. There is nothing wrong with this, but it would be better if we
looked at a curve as a function in a way that ﬁts our deﬁnition better. For us,
a function f ∶ℝ→ℝhas three important components: the relation, f ⊆ℝ2; a
domain, Domain(f ) ⊆ℝ; and a codomain, Codomain(f ) = ℝ. In a graph, the
relation f denotes the ordered pairs that make up the curve itself. Visually, we
should note that
The domain is on the x-axis, and the codomain is on the y-axis.
The value x = a gives a point on the x-axis, which is in the domain. Above
or below it is a point on the curve, (a, b) ∈f ⊆ℝ2. The value y = b gives a
point on the y-axis, which is the codomain. The function is best viewed as
an assignment of a point x = a on the x-axis to a point y = b on the y-axis.
The curve describes that assignment through a geometric procedure: up from
a point on the x-axis to a point on the curve over to a point on the y-axis.
That way, a point on the domain goes in and a point on the codomain comes
out. The curve is not the function: the assignment it illustrates this way is the
function.
11.2.2
Tables and arrow graphs
When the sets involved are small, there is another way to illustrate a function.
Let A = {a, b, c, d, e}. We can deﬁne a function f ∶A →A using a table of values
as follows.
A
A
a
b
b
b
c
d
d
c
e

11.2 Visualizing Functions
203
Figure 11.3 An arrow graph.
a
b
c
d
e
a
b
c
d
e
This time the domain appears in the ﬁrst column, the codomain appears in the
second, and the ordered pairs of the relation are rows in the table. We can see
Domain(f ) = {a, b, c, d}, Codomain(f ) = A, Range (f ) = {b, c, d}. The function
is injective, but it is not surjective.
We can make this table even more visual by using arrows to indicate the
assignments. This is shown in Figure 11.3.
Two arrows cannot begin at the same element of the domain because of
the vertical line test. However, two arrows can point to the same value of the
codomain, but that means the function is not injective. In keeping with our
notation, we wrote f ∶A →A even though f (e) is not deﬁned. In addition, the
function is not surjective.
11.2.3
Generic functions
The ﬁnal way to visualize functions is through a generic picture as in Figure 11.4.
To draw f ∶A →B, we draw A as a circle, and B as a separate circle. The function
connects points in A with points in B, and we indicate this using an arrow or
several arrows if that serves our purpose.
If we want, we can indicate the actual domain of f (x) as a enclosed section
of the circle denoting A. The same goes for the range of f (x). This picture is
very generic. It works for all sorts of functions between any sorts of sets. It is
very imprecise and does not capture any of the actual details of the function, as
f : A → B
A
Domain( f )
B
Range( f )
Figure 11.4 A generic function.

204
11 Functions
in our other illustrations. In many cases, that actually helps us understand the
general properties of functions.
11.3
Composition
11.3.1
Deﬁnitions and basic results
Deﬁnition 11.3.1.
Let f ∶A →B and g ∶B →C be two functions. The com-
posite of these two functions is a function
g ∘f ∶A →C
(11.9)
deﬁned by
(g ∘f )(x) = g(f (x)).
(11.10)
Notice the notation. The left-hand side of the notation (g ∘f )(x) collects the
compound function name together in one unit using parenthesis. The normal
notation for a function named h is to write h(x) to mean h applied to the variable
x. The variable always gets its own parenthesis as part of the function nota-
tion. Thus, (g ∘f )(x) means “the function (g ∘f ) applied to the variable x.” The
right-hand side starts with a function g; the next parenthesis tells us what it is
applied to: f (x). As usual, f (x) means the value of the function f at the vari-
able x. So algebraically, this deﬁnition is easy to apply. But when translated to
English, it is a bit strange. The function (g ∘f )(x) means “apply f to x ﬁrst and
then apply g to the result.” So (g ∘f )(x) means f ﬁrst; g second. Nice algebra
is more important than the English; so the notation holds on to this reverse
meaning.
Theorem 11.3.2.
Let f ∶A →B, g ∶B →C, and h ∶C →D be functions.
Then
h ∘(g ∘f ) = (h ∘g) ∘f ;
(11.11)
(h ∘(g ∘f ))(x) = ((h ∘g) ∘f )(x)).
Either way of writing this is ﬁne; the ﬁrst makes the point easier to see; the
second makes the proof easier to start.
Proof. Consider the right- and left-hand sides.
(h ∘(g ∘f ))(x) = h((g ∘f )(x)) = h(g(f (x))).
(11.12)
((h ∘g) ∘f )(x)) = (h ∘g)(f (x)) = h(g(f (x))).
◽

11.3 Composition
205
Now the composition of functions is associative, but it is not commutative.
For one thing, if f ∶A →B and g ∶B →C involve three diﬀerent sets, f ∘g
makes no sense. (Remember that g comes ﬁrst and thus ends up in the wrong
set for f to act on.) But even in the best possible case where f ∶A →A and
g ∶A →A, only carefully selected functions commute with each other.
Theorem 11.3.3.
Let f ∶A →B and g ∶B →A be functions.
1. If f (x) and g(x) are injective, then (g ∘f )(x) is injective.
2. If f (x) and g(x) are surjective, then (g ∘f )(x) is surjective.
3. If f (x) and g(x) are bijective, then (g ∘f )(x) is bijective.
Proof. We will prove each part in turn.
Part 1. We ﬁrst claim that if f (x) and g(x) are injective, then (g ∘f )(x) is
injective.
Proof of claim. Assume that f (x) and g(x) are injective. Then f (a1) = f (a2)
implies a1 = a2. And g(b1) = g(b2) implies b1 = b2.
Comment: What are we proving now? (g ∘f )(x) is injective. That is, if (g ∘f )(a1) =
(g ∘f )(a2), then a1 = a2.
Assume (g ∘f )(a1) = (g ∘f )(a2). Then g(f (a1)) = g(f (a2)). So f (a1) = f (a2) and
in turn a1 = a2.
◾
Part 2. We now claim that if f (x) and g(x) are surjective, then (g ∘f )(x) is
surjective.
Proof of claim. Assume that f (x) and g(x) are surjective. Then ∀b ∈B, ∃a ∈A
s.t. f (a) = b. And ∀c ∈C, ∃b ∈B s.t. g(b) = c.
Comment: What are we proving now? g ∘f ∶A →C is surjective. That is, if c ∈C,
then there exists a ∈A such that (g ∘f )(a) = c.
Assume c ∈C. We know that ∃b ∈B s.t. g(b) = c. Now that we have b ∈B,
we know that ∃a ∈A s.t. f (a) = b. Consider a ∈A. Then
(g ∘f )(a) = g(f (a)) = g(b) = c.
(11.13)
◾
Part 3. Finally, we claim that if f (x) and g(x) are bijective, then (g ∘f )(x) is
bijective.

206
11 Functions
Proof of claim. Comment: What are we proving now that we know the ﬁrst two
parts are true? If f (x) and g(x) are bijective, then Domain(g ∘f ) = A.
Assume that f (x) and g(x) are bijective. Then both are injective, so the compo-
sition is injective. Both are surjective, so the composition is surjective. In addi-
tion, Domain(f ) = A and Domain(g) = B. Let a ∈A. Then a ∈Domain(f ) = A.
So ∃b ∈B s.t. f (a) = b. But b ∈B =Domain(g); so ∃c ∈C s.t. g(b) = c. Then
(g ∘f )(a) = g(f (a)) = g(b) = c.
(11.14)
So a ∈Domain (g ∘f ).
◾
◽
11.4
Inverses
Deﬁnition 11.4.1.
Let A be any set. The identity function on A is iA ∶A →A
given by iA(x) = x for all x ∈A.
Each set has its own identity function; so there is a good reason to include a
subscript when we write it. Nevertheless, many people consider laziness a good
reason not to when there is little chance for confusion.
Theorem 11.4.2.
Let A and B be sets, and iA ∶A →A and iB ∶B →B be the
identities, then:
1. iA is bijective.
2. If f ∶A →B is a function, then (f ∘iA)(x) = f (x).
3. If f ∶A →B is a function, then (iB ∘f )(x) = f (x).
There is not much to prove here, but we will prove 1 anyway.
Proof. To prove that iA ∶A →A is bijective, we must prove that it is injective,
surjective, and that Domain(iA) = A.
To see that iA is injective, assume iA(a1) = iA(a2). Then a1 = iA(a1) = iA(a2) =
a2, so iA is injective.
Now we claim that ia is surjective. Assume a ∈A. Then iA(a) = a; so ∃x ∈A
s.t. iA(x) = a. So Range(iA) = A; that is, iA is surjective.
Finally, we claim that A =Domain(iA). Clearly, Domain(iA) ⊆A. We must
show that A ⊆Domain(iA). Assume a ∈A. Then iA(a) = a. So a ∈Domain(iA).
Thus, A ⊆Domain(iA); so A = Domain(iA).
◽
The only point of value here is that we need to remember that the deﬁnition
of bijective has three parts.

11.4 Inverses
207
Deﬁnition 11.4.3.
Let f ∶A →B and g ∶B →A be functions. We say that g
is an inverse of the function f when
(g ∘f )(x) = iA(x)
(11.15)
and (f ∘g)(x) = iB(x).
In this case, we write g(x) = f −1(x).
Before we set this notation, we should have proved that an inverse function,
if it exists, is unique. We have already seen that uniqueness of inverses follows
from associativity. However, recalling that proof does point out that, without
commutativity, it is critical that an inverse works on both sides of the function.
Theorem 11.4.4.
Inverse functions are unique.
Proof. Let f ∶A →B; g1 ∶B →A; and g2 ∶B →A be functions. Assume g1(x)
and g2(x) be inverses of f (x). Consider g1 ∘f ∘g2.
(g1 ∘f ∘g2)(x) = ((g1 ∘f ) ∘g2)(x) = (iA ∘g2)(x) = g2(x).
(11.16)
(g1 ∘f ∘g2)(x) = (g1 ∘(f ∘g2))(x) = (g1 ∘iB)(x) = g1(x).
◽
There is a consequence of this uniqueness that is worth remembering. While
this might not be completely oﬃcial mathematics terminology, we give it a
name to help us remember it.
Theorem 11.4.5
(The Shoes and Socks Theorem). Let f ∶A →B, and g ∶
B →C be functions. Assume that f (x) and g(x) are bijections. Then
(g ∘f )−1 = f −1 ∘g−1.
(11.17)
Proof. Assume a ∈A. Then
(f −1 ∘g−1) ∘(g ∘f ) = f −1 ∘(g−1 ∘g) ∘f
(11.18)
= f −1 ∘iB ∘f
= f −1 ∘f
= iA.
In addition,
(g ∘f ) ∘(f −1 ∘g−1) = f ∘(g ∘g−1) ∘f −1
(11.19)
= f ∘iA ∘f −1
= f ∘f −1
= iB.

208
11 Functions
Since f −1 ∘g−1 acts as the inverse of (g ∘f ) on both sides, and inverses are
unique, (g ∘f )−1 = f −1 ∘g−1.
◽
All of the careful abstraction, weird deﬁnitions, and precise notation in this
chapter have been leading up to the next famous theorem and its proof. It might
not have been precisely true had we not been so careful.
Theorem 11.4.6.
If f ∶A →B is a function, then f (x) has an inverse function
if and only if f (x) is bijective.
Proof. Assume that f ∶A →B is a function. This is a biconditional statement,
so we have two statements to prove.
1. If f (x) has an inverse function, then f (x) is bijective.
2. If f (x) is bijective, then f (x) has an inverse function.
We will take each in turn.
Part 1. We claim that if f (x) has an inverse function, then f (x) is bijective.
Proof of claim. Assume that f (x) has an inverse function. Call it f −1(x). Then
(f −1 ∘f )(x) = iA(x)
(11.20)
and (f ∘f −1)(x) = iB(x).
Comment: What are we proving now? 1. Domain(f ) = A; 2. f (x) is injective; and
3. f (x) is surjective.
Step 1. We claim that Domain(f ) = A; that is, given a ∈A, we must show that
f (a) is deﬁned and an element of B.
Assume a ∈A. We have iA(a) = a. So
a = iA(a)
(11.21)
= (f −1 ∘f )(a)
= f −1(f (a)).
This means that f (a) must be deﬁned and be an element of B since otherwise
f −1(f (a)) would not make sense and be equal to a. Thus, a ∈Domain(f ). So
we have ﬁnished step 1.
Step 2. We claim that f (x) is injective; that is, if f (a1) = f (a2), then a1 = a2.
Assume f (a1) = f (a2). Now a1, a2 ∈A (because we assumed that f (a1) and
f (a2) made sense). Applying f −1(x) to both sides, we get
f −1(f (a1)) = f −1(f (a2)).
So (f −1 ∘f )(a1) = (f −1 ∘f )(a2). So iA(a1) = iA(a2), and therefore, a1 = a2.
So if f (a1) = f (a2), then a1 = a2. This ﬁnishes step 2.

11.4 Inverses
209
Step 3. We now claim that f (x) is surjective; that is, if b ∈B, then ∃a ∈A s.t.
f (a) = b.
Assume b ∈B. Then iB(b) = b. So
b = iB(b)
(11.22)
= (f ∘f −1)(b)
= f (f −1(b)).
Since f −1(b) ∈A, we have ﬁnished step 3.
These three steps complete Part 1.
◾
Part 2. We claim that if f (x) is bijective, then f (x) has an inverse.
Proof of claim. Comment: We will almost never bring a function back to its
deﬁnition as an ordered pair to complete a proof, but this is one time where this
helps.
Assume f ∶A →B is a function where Domain(f ) = A. Then we have a pair
(f , B) where f ⊆A × B . And we can say that ∀a ∈A, ∃b ∈B s.t. f (a) = b.
Writing this as ordered pairs in the relation, we get
(1) ∀a ∈A, ∃b ∈B s.t. (a, b) ∈f .
In addition, we have “the vertical line test” requirement:
(2) if (a, b1) ∈f and (a, b2) ∈f , then b1 = b2.
Next we assume that f (x) is injective. Then f (a1) = f (a2) implies a1 = a2. Let
b = f (a1) = f (a2). Writing this as ordered pairs in the relation, we get
(3) If (a1, b) ∈f and (a2, b) ∈f , then a1 = a2.
Finally, assume that f (x) is surjective. Then ∀b ∈B, ∃a ∈A s.t. f (a) = b.
Writing this as ordered pairs in the relation, we get
(4) ∀b ∈B, ∃a ∈A s.t. (a, b) ∈f .
Now deﬁne a function as the pair (g, A) where
g = {(b, a) ∈B × A ∣(a, b) ∈f }.
(11.23)
Thus, g ⊆B × A.
We must now show (1) that g is actually a function (i.e., g satisﬁes the “vertical
line test”) and (2) that g is the inverse of f .
We ﬁrst prove that g is a function. Assume that g(b) = a1 and g(b) = a2. That
is, (b, a1) ∈g and (b, a2) ∈g. By deﬁnition of g, it follows that (a1, b) ∈f and
(a1, b) ∈f . That is, f (a1) = b and f (a2) = b. But because f is injective, we have

210
11 Functions
property (3). Thus, a1 = a2. Thus, the relation g satisﬁes the “vertical line test.”
So g ∶B →A is a function.
Now we prove that g is the inverse of f . First note that by property (4),
Domain(g) = B.
So (b, a) ∈g if and only if (a, b) ∈f . So in normal notation, we have g(b) = a
if and only if f (a) = b. Thus,
(g ∘f )(x) = iA(x)
(11.24)
and (f ∘g)(x) = iB(x).
So g(x) is an inverse function of f (x).
◾
We have now proved both directions of our biconditional statement, so the
proof is complete.
◽
11.5
Problems
11.1
Explain why the following common errors committed by beginners can
be explained by noting that functions do not always commute under
composition.
(a) (a + b)2 = a2 + b2.
(b)
1
x+4 = 1
x + 1
4.
(c)
√
x2 + y2 = x + y.
(d) 32+x = 9 + 3x.
(e) Sin(2x) = 2Sin(x).
11.2
Let A = {a, b, c, d, e}.
Deﬁne a function f ∶A →A and a function g ∶A →A using the table
of values shown as follows.
x
f(x)
g(x)
a
b
b
b
b
c
c
d
d
d
c
e
e
e
a
(a) Is either f (x) or g(x) injective?
(b) Is either f (x) or g(x) surjective?

11.5 Problems
211
(c) Find a table for (f ∘g)(x).
(d) Find a table for (f ∘f )(x).
11.3
Consider the functions f ∶ℝ→ℝgiven by f (x) = x−1, and g ∶
ℝ∖{0} →ℝ∖{0} given by g(x) = x−1.
(a) Prove f (x) is injective.
(b) Prove g(x) is injective.
(c) Prove f (x) is not surjective.
(d) Prove g(x) is surjective.
(e) Carefully evaluate the two functions (f ∘f )(x) and (g ∘g)(x). Be
completely precise about these two results.
11.4
Deﬁne f ∶ℝ→ℝby f (x) = 2x−1
x+1 .
(a) Prove that f (x) is injective.
(b) Prove that f (x) is not surjective.
(c) Use the formula f1(x) = 2x−1
x+1 to deﬁne a bijective function and ﬁnd
its inverse.
11.5
Deﬁne f ∶ℝ→ℝby f (x) = x2−4
x−2 .
(a) Is f (x) injective?
(b) Is f (x) surjective?
(c) Is f (x) bijective?
(d) Is this the same as the function f ∶ℝ→ℝgiven by f (x) = x + 2?
11.6
Explain your answers to the following questions.
(a) Can a function f ∶ℝ→ℝbe deﬁned by f (x) =
⎧
⎪
⎨
⎪⎩
x
if x > 0
0
if x = 0
−x
if x < 0
?
(b) Can a function g ∶ℝ→ℝbe deﬁned by f (x) = ±x?
(c) Is it true or false that |x| = ±x?
(d) Can |x| = ±x be used as a deﬁnition of the absolute value?
(e) Is it true or false that
√
x2 = ±x?
(f) Is it true or false that
√
x2 = |x|?
(g) Can |x| =
√
x2 be used as a deﬁnition of the absolute value?
11.7
Deﬁne f ∶[3, ∞) →[−6, ∞) by f (x) = x2 −6x + 3.
(a) Find a function g ∶[−6, ∞) →[3, ∞) so that (g ∘f )(x) = x and
(f ∘g)(x) = x.
(b) Prove that f (x) is bijective.

212
11 Functions
11.8
Let f ∶ℝ→ℝbe given by f (x) = x3 + 5x −8. Prove that f (x) is injective.
(Since you cannot use calculus, prove that f (a) −f (b) = (a −b) ⋅g(a, b)
and that g(a, b) cannot be zero.)
11.9
Deﬁne f ∶ℝ→ℝby
f (x) =
⎧
⎪
⎨
⎪⎩
x2
if x > 0
0
if x = 0
−x2
if x < 0
.
(11.25)
(a) Prove that f (x) is bijective.
(b) Find f −1(x).
(c) Consider g ∶ℝ→ℝgiven by g(x) = x |x|. Compare this to f (x).
11.10
We will not prove it in this course, but 𝜋is not a rational number. Use
this to prove that f ∶ℚ→ℝgiven by f (x) = Sin(x) is injective.
(Yes, because of the ℚ, it really is! Hint: use the graph you learned in
trigonometry to ﬁnd all solutions x to Sin(x) = Sin(b), where b is a con-
stant.)
11.11
Let A = {1, 2}. Let Map(A) = {f ∶A →A ∣Domain(f ) = A}. Deﬁne a
relation on Map(A) by
f ∼g
if and only if
∃b ∈Map(A) s.t. b is a bijection and g = b−1 ∘f ∘b.
(a) List all the elements of Map(A) by drawing them as arrow diagrams.
(b) Prove that the relation ∼deﬁned earlier is an equivalence relation.
(c) Find Map(A)∕∼.
11.12
Let A = {1, 2, 3}. Let Bij(A) = {f ∶A →A ∣f (x) is a bijection}. Deﬁne
a relation on Bij(A) by
f ∼g
if and only if
∃b ∈Bij(A) s.t. g = b−1 ∘f ∘b.
(a) List all the elements of Bij(A) by drawing them as arrow diagrams.
(b) Prove that the relation ∼deﬁned earlier is an equivalence relation.
(c) Find Bij(A)∕∼.

11.5 Problems
213
11.13
Let A = {1, 2, 3}. Let Map(A) = {f ∶A →A ∣Domain(f ) = A}. Deﬁne
a relation on Map(A) by
f ∼g
if and only if
∃b ∈Map(A) s.t. b is a bijection and g = b−1 ∘f ∘b.
(a) List all the elements of Map(A). (OK, there are a lot of them.)
(b) Prove that the relation ∼deﬁned earlier is an equivalence relation.
(c) Find Map(A)∕∼.

215
12
Images and preimages
12.1
Functions acting on sets
12.1.1
Deﬁnition of image
Let f ∶A →B be a function. We say that the function f “acts on elements of A”
because we can view the equation f (a) = b as though the function transforms
the a ∈A into a b ∈B. We say this because f (x) is well deﬁned and can only
mean one thing. We cannot say that f acts on the elements of B because it is not
clear what a general function f ∶A →B would do to b ∈B that would produce
a well-deﬁned result since f (x) may not be injective. We can, however, describe
the ways f ∶A →B can act on sets in a well-deﬁned manner. (Remember that
“well deﬁned” means “give a unique and unambiguous result.”) We can get f to
act on subsets of A. In addition, even though f cannot act on elements of B, it
can be made to act on subsets of B.
If S ⊆A, then f ∶A →B acts on S to create an image of S under f (x). To get
an idea on how a function f ∶A →B can act on S ⊆A as this, draw a generic
picture of such a function (Figure 12.1).
As the picture seems to show, the image of a set is the set obtained by
applying f (x) to all the points s ∈S. We could choose to write this image as
{f (x) ∣x ∈S}. That describes rather clearly what the image of S under f (x)
should be. The problem is that it is not in the standard set notation form, and
it could be diﬃcult to use in a proof. It is a great way to give an example, but
a bad way to use the image in a proof. Mathematical deﬁnitions are all about
preparing for proofs; so we have
Deﬁnition 12.1.1.
Let f ∶A →B and S ⊆A. The image of S under f (x) is
f (S) = {y ∈B ∣∃x ∈S s.t. f (x) = y}.
(12.1)
We have now used one notation for two similar things; but “similar” is not
exactly the same. Thus, if f ∶A →B and s ∈A, then f (s) is the function applied
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

216
12 Images and Preimages
f : A → B
A
Domain( f )
B
Range( f )
S
f (S)
Figure 12.1 The image of S is f(S).
to s. We have been calling this “f of s” for a long time. But now we have a new
notion that we may not have even seen before. If S ⊆A, then f (S) is the image
of S under f (x). We can read f (S) as either “f of S” or “f applied to S.” However,
if any confusion arises – as in a proof – over the notation f (S), we should realize
that one way to get out of that confusion is to read f (S) correctly as “the image
of the set S under f (x).”
The other thing to notice about this deﬁnition is our choice of names for the
variables. The names of the variables have no impact on the meaning of the
deﬁnition. We have 26 small letters and 26 capitals and a slew of Greek letters
to choose from.
There are some conventions that are not so strictly followed but are common
enough that they quickly start to seem standard. We typically use lowercase
letters for elements and uppercase letters for sets, but if a set S has a maximum
and a minimum, it is very tempting to call them M and m. This notation is
so descriptive that it might be worth breaking our habit of saving M for a set.
Another general practice you might begin to pick up: the beginning letters of
the alphabet are often used to denote the ﬁxed elements of a set, as a set of real
numbers. Letters in the middle of the alphabet are often chosen to represent
natural numbers and integers. Letters at the end of the alphabet are chosen
for variables that are actually expected to vary during the discussion. When it
comes to functions, this last convention picks up an extra bit of connotation
left over from our introduction to functions in basic algebra where we write
y = f (x). Thus, x is generally a domain variable that goes into a function, and
y is generally a codomain variable that comes out of a function. In time you
might notice that s and t are also normally domain and codomain pairs. Less
common, but often enough, u and 𝑣get paired like this.
Notice how this convention inﬂuenced our choice of variable names in the
deﬁnition of the image. The image of a set S under a function f ∶A →B is going
to be a set in the codomain. When we deﬁne f (S), we choose a variable name
for its members that is a “codomain” variable. We choose y. The set deﬁnition

12.1 Functions Acting on Sets
217
begins “the set of all y…”. When we get to the condition for membership in
the set, we need a name for a variable in A; we choose a “domain” variable, x.
Logically, we could have picked these names in the opposite order, but strate-
gically, this would have only set up a great opportunity for confusion.
12.1.2
Examples
We will start with a function with only a few elements in the domain and range.
Example 12.1.2.
Let A = {1, 3, 4, 6, 7} and B = {2, 3, 4, 5, 6, 7}. Let f ∶A →B
be given by the following table.
x
f (x)
1
4
3
6
4
4
6
7
7
Then
For S1 = {1, 3, 4}, f (S1) = {4, 6}.
(12.2)
For S2 = {1, 3, 6, 7}, f (S2) = {4, 6, 7}.
(12.3)
We must say that f (6) is not deﬁned. Still f ({6}) is deﬁned.
For S3 = {6}, f (S3) = ∅.
For S4 = ∅, f (S4) = ∅.
For S5 = {1, 3, 4, 6, 7}, f (S5) = {4, 6, 7}.
Notice a few things; the image of a subset of A is always deﬁned. This is true
whether A is the prospective domain or the actual domain. Thus, even though
f (6) is not deﬁned, f ({6}) is deﬁned. This is one of those situations where
reading f (6) as “f of 6” and reading f ({6}) as “the image of the set {6} under
f (x)” pays oﬀ. In addition, the empty set is just like any other set, and we follow
the deﬁnition slavishly.
f ({6}) = {y ∈B | ∃x ∈S s.t. f (x) = 6} = ∅;
(12.4)
f (∅) = {y ∈B | ∃x ∈∅s.t. f (x) = y} = ∅.
Example 12.1.3.
Let f ∶A →B be given by f (x) = x2.
It is a good idea to keep a graph of this function in mind as we go through
these examples (Figure 12.2).

218
12 Images and Preimages
−4
−2
2
4
10
20
x
y
Figure 12.2 f(x) = x2.
For S1 = {1, 2, 3}, f (S1) = {1, 4, 9}.
(12.5)
For S2 = { −2, −1, 0, 1, 2, 3}, f (S2) = {0, 1, 4, 9}.
For S3 = [2, 5), f (S3) = [4, 25).
For S4 = [−3, −1), f (S4) = (1, 9].
For S5 = (−3, 2), f (S5) = [0, 9).
For S6 = (−∞, 4], f (S6) = [0, ∞).
For S7 = ∅, f (S7) = ∅.
For S8 = ℝ, f (S8) = [0, ∞).
We ﬁnish with two last observations; we write these as theorems, but do not
bother to prove them.
Theorem 12.1.4.
Let f ∶A →B be a function. Then f (A) = Range( f ).
Theorem 12.1.5.
For any function f ∶A →B be a function, f (∅) = ∅.
12.1.3
Deﬁnition of preimage
Let f ∶A →B be a function. We have seen why the function f “acts on elements
of A” and how it can “act on a subset of A.” We can also get it to “act on a subset
of B,” but when it does, it will be in reverse (Figure 12.3).
The preimage of a set T ⊆B under a function f ∶A →B is the set of elements
of A that the function takes to elements of T. We are again going to use notation
that is very similar to notation we have used before. The trouble is that this time
the underlying ideas are still similar, but the technicalities are quite diﬀerent.
We will denote the preimage of T ⊆B under the function f ∶A →B as f −1(T).

12.1 Functions Acting on Sets
219
T
f −1(T)
f : A → B
A
B
Domain( f )
Range( f )
Figure 12.3 f −1(T) is the preimage of T.
Be careful, this is the function f (x) acting on the set T ⊆B. It is not the inverse
function f −1(x) acting on anything mainly because there is no reason to believe
the function f −1(x) exists.
Now the preimage f −1(T) of any subset T ⊆B and any function f ∶A →B will
always be well deﬁned. The function need not be bijective; so its inverse need
not exist. Nonetheless, f −1(T) is deﬁned. It will be hard to learn not to read
f −1(T) as “f -inverse of T,” but doing so is inviting mistakes. The correct way to
read f −1(T) is as “the preimage of T under f (x).”
Reviewing our terminology, if f ∶A →B and s ∈A, then f (s) is the function
applied to s. We read f (s) as “f of s.” If S ⊆A, then f (S) is the image of S under
f (x). This is always well deﬁned, and we can read f (S) as either “f of S” or as “f
applied to S,” as long as we remember that it is properly read as “the image of
the set S under f (x).”
If f (x) is bijective, then it has an inverse and if t ∈B, then f −1(t) is the inverse
function applied to t. But only when we are sure an inverse exists can we read
f −1(t) as “f -inverse of t.” Whenever we use the notation f −1(t) for t an element,
we must ask ourselves if we know that f (x) is bijective. However, the preimage
f −1(T) of a set T ⊆B will always be deﬁned for any function f ∶A →B. The
function need not be bijective, so its inverse need not exist. Nonetheless, f −1(T)
is deﬁned. It is good practice not to read f −1(T) as “f -inverse of T” but only as
“the preimage of T under f (x).”
Now we are ready to write down an oﬃcial deﬁnition. Since the preimage of a
set should be a set in the domain, this will be reﬂected in our choice of variable
names.
Deﬁnition 12.1.6.
Let f ∶A →B. Let T ⊆B. The preimage of T under f (x) is
f −1(T) = {x ∈A ∣f (x) ∈T}.
Finally we have a simple deﬁnition that actually describes the set being
deﬁned.

220
12 Images and Preimages
12.1.4
Examples
We will use the same two functions we used as examples of images.
Example 12.1.7.
Let A = {1, 3, 4, 6, 7} and B = {2, 3, 4, 5, 6, 7}. Let f ∶A →B
be given by the following table.
x
f (x)
1
4
3
6
4
4
6
7
7
This function is not bijective; so f −1 can only mean “preimage.” Now
For T1 = {4, 6}, f −1(T1) = {1, 3, 4}.
(12.6)
For T2 = {7}, f −1(T2) = {7}.
(12.7)
We still must say that f −1(7) is not deﬁned.
For T3 = {4}, f −1(S1) = {1, 4}.
For T4 = {2, 3, 5}, f −1(T4) = ∅.
For T5 = ∅, f −1(T5) = ∅.
For T6 = B, f −1(T6) = {1, 3, 4, 7}.
Notice a few things; the preimage of a subset of B is always deﬁned. Thus even
though f −1({7}) is deﬁned and only contains one element, the inverse of f (x)
does not exist. Thus f −1(7) is not deﬁned. This is one of those situations where
reading f −1(7) as “f -inverse of 7” and reading f −1({7}) as “the preimage of the
set {7} under f ” pays oﬀ. Again the empty set is just like any other set; we follow
the deﬁnition slavishly.
f −1({2}) = {x ∈A ∣f (x) = 2} = ∅;
(12.8)
f −1(∅) = {x ∈A ∣f (x) ∈∅} = ∅.
There are x ∈A such that f (x) is not deﬁned, but that does not make f (x) ∈∅,
because the empty set is empty.
Example 12.1.8.
Let f ∶A →B be given by f (x) = x2.
Again, it is a good idea to keep an graph of this function in mind as we go
through these examples.

12.1 Functions Acting on Sets
221
−4
−2
2
4
10
20
x
y
Figure 12.4 f(x) = x2.
Also, remember the sets going into the preimage are in the range, and so
belong on the y-axis, and the preimages that they produce are in the domain,
and so belong on the x-axis (Figure 12.4).
For T1 = {1, 4, 9}, f −1(T1) = { ± 1, ±2, ±3}.
(12.9)
For T2 = { −2, −1}, f −1(T2) = ∅.
For T3 = [0, 25), f −1(T3) = (−5, 5).
For T4 = (−3, 16], f −1(S4) = [−4, 4].
For T5 = [4, 9), f −1(T5) = (−3, −2] ∪[2, 3).
For T6 = (−∞, 4], f −1(T6) = [−2, 2].
For T7 = ∅, f −1(T7) = ∅.
For T8 = ℝ, f −1(R8) = ℝ.
The thing to notice in this example is that a perfectly nice function can also
cause havoc on the form of an interval in reverse. But perhaps even more impor-
tant, it takes a lot of practice to ﬁnd preimages under even the most familiar
of functions without drawing a graph and tracing the set T on the y-axis back
onto the curve, and the pushing it down onto the x-axis to set what you get.
We ﬁnish with three last observations; we write them as theorems, but do not
bother to prove them.
Theorem 12.1.9.
Let f ∶A →B be a function. Then f −1(B) = Domain( f ).
Theorem 12.1.10.
Let f ∶A →B be a function and T ⊆B, then f −1(T) ⊆
Domain( f ).
Theorem 12.1.11.
For any function f ∶A →B, f −1(∅) = ∅.

222
12 Images and Preimages
12.2
Theorems about images and preimages
12.2.1
Basics
The truth about images, preimages, and their notations is that the resulting
algebra involving them is not as reliable as it should be. Many algebraic results
that should be true are not unless extra conditions are placed on either the
function or the sets involved. It is almost impossible to keep track of all these
conditions, so a good practice is to actually reprove (at least in scratch work)
any result we ﬁnd that we need within a longer proof.
Our ﬁrst theorem is less a theorem than a warning.
Theorem 12.2.1.
Let f ∶A →B be a function. Let S ⊆A and T ⊆B.
1. If s ∈Domain( f ) and s ∈S, then f (s) ∈f (S).
2. s ∈f −1(T) if and only if f (s) ∈T.
3. The converse of statement 1 is not true. If f (s) ∈f (S), we cannot say that s ∈S.
4. If t ∈T, we cannot say that f −1(t) ∈f −1(T).
Proof. Statements 1 and 2 are simply restatements of the deﬁnitions of f (S) and
f −1(T). We will prove them anyway.
Part 1. We claim that if s ∈Domain( f ) and s ∈S, then f (s) ∈f (S).
Proof of claim. Assume s ∈Domain(f ) and s ∈S. Now s ∈Domain(f ) so
we know that f (s) exists. Since s ∈S, f (s) ∈{y ∈B ∣∃x ∈S s.t. f (x) = y} =
f (S).
◾
Part 2. We claim that s ∈f −1(T) if and only if f (s) ∈T.
Proof of claim. (⇒) Assume s ∈f −1(T). Since f −1(T) ⊆Domain( f ), we have
implicitly assumed that s ∈Domain( f ). Thus, f (s) exists and f (s) ∈{x ∈A ∣
f (x) ∈T}. So f (s) ∈f (T).
(⇐) Assume f (s) ∈T. Since we have assumed something about f (s), it must
exist. Since f (s) ∈T, s ∈{x ∈A ∣f (x) ∈T} = f −1(T).
◾
Part 3. The converse of statement 1 is not true. If f (s) ∈f (S), we cannot say that
s ∈S.
This is true because f (x) might not be injective. Suppose that f (a1) = f (a2)
with a1 ≠a2. Then f (a2) ∈f ({a1}), but a2 ∉{a1}.
Part 4. If t ∈T, we cannot say that f −1(t) ∈f −1(T).
This is true because we cannot even write f −1(t) unless f (x) is known to be
bijective.
◽

12.2 Theorems about Images and Preimages
223
Remember the example in the proof of statement 3. The following table will
help:
x
f (x)
a1
b
a2
b
∗
∗
∗
∗
⋮
⋮
Proof technique. In real analysis, before we can apply f ∶ℝ→ℝto a ∈ℝ, we
must establish that a ∈Domain(f ) and thus be sure that f (a) exists. However, if
S ⊆ℝ, then f (S) will always be deﬁned; and if T ⊆ℝ, then f −1(T) is also always
deﬁned.
There is one way to remember what is true and what is not true about images
and preimages applied to both sides of a statement. If it looks like we are
applying the function to both sides, then the result is generally true. If it looks
like we are applying the inverse function to both sides, it is generally not true.
This is a good rule of thumb, but when in doubt, make a claim and give a proof.
The next theorem gives us permission to apply images and preimages to both
sides of a subset relation without any extra conditions. It immediately violates
our rule of thumb, but in a positive way. We might expect applying preimages
to both sides of an inequality to go wrong, but it turns out to be OK. The proof
is easy.
Theorem 12.2.2.
Let f ∶A →B be a function. Let S1, S2 ⊆A and T1, T2 ⊆B.
1. If S1 ⊆S2, then f (S1) ⊆f (S2).
2. If T1 ⊆T2, then f −1(T1) ⊆f −1(T2).
Proof. We will prove part 1. That is, we will prove that if S1 ⊆S2, then f (S1) ⊆
f (S2).
Assume S1 ⊆S2.
Comment: What are we proving now? We are proving that f (S1) ⊆f (S2). That
is, we are proving that if y ∈f (S1), then y ∈f (S2).
Assume y ∈f (S1). Then ∃x ∈S1 s.t. f (x) = y. But x ∈S1 ⊆S2. So f (x) ∈f (S2).
That proves part 1. Part 2 is left as an exercise.
◽
The next theorem checks that function composition causes no problems.

224
12 Images and Preimages
Theorem 12.2.3.
Let f ∶A →B and g∶B →C be functions. Let S ⊆A and
T ⊆C. Then
1. g( f (S)) = (g ∘f )(S), and
2. f −1(g−1(T)) = (g ∘f )−1(T).
Proof. We will prove each part in turn. The proofs of both parts are very easy,
but the notation can be confusing. Adding an extra name along the way will
help make things clearer.
Part 1. We claim that g( f (S)) = (g ∘f )(S).
Proof of claim. For convenience, let h = g ∘f and U = f (S). We are trying
to prove a set equality, so we must prove that g( f (S)) ⊆(g ∘f )(S) and that
(g ∘f )(S) ⊆g( f (S)).
Step 1: First we prove g(f (S)) ⊆(g ∘f )(S).
Assume t ∈g( f (S)). Then t ∈g(U). So ∃u ∈U s.t. g(u) = t. But then
u ∈U = f (S); so ∃s ∈S s.t. f (s) = u. Then
h(s) = (g ∘f )(s) = g( f (s)) = g(u) = t.
(12.10)
So we have proved that ∃s ∈S s.t. h(s) = t. Then t ∈h(S). So t ∈(g ∘f )(S).
Thus, g( f (S)) ⊆(g ∘f )(S).
Step 2: Now we prove that (g ∘f )(S) ⊆g( f (S)).
Assume t ∈(g ∘f )(S) = h(S). So ∃s ∈S s.t. h(s) = t. Then
t = (g ∘f )(s) = g( f (s)).
(12.11)
Let u = f (s). Since s ∈S, this means u ∈f (S) = U. But we also have t = g(u)
with u ∈U. So t ∈g(U) = g( f (S)). Thus, (g ∘f )(S) ⊆g( f (S)).
We have now proved both g( f (S)) ⊆(g ∘f )(S) and that (g ∘f )(S) ⊆g( f (S)).
Thus, (g ∘f )(S) = g( f (S)).
◾
Part 2. We claim that f −1(g−1(T)) = (g ∘f )−1(T).
Proof of claim. Again, this is a set equality, so we must prove that
f −1(g−1(T)) ⊆(g ∘f )−1(T) and f −1(g−1(T)) ⊇(g ∘f )−1(T).
And again, for convenience, let h = g ∘f and V = g−1(T).
Step 1: First we will prove that f −1(g−1(T)) ⊆(g ∘f )−1(T).
Assume s ∈f −1(g−1(T) = f −1(V). Then f (s) ∈V = g−1(T). So g( f (s)) ∈T. So
h(s) ∈T. This tells us that s ∈h−1(T). So indeed, s ∈(g ∘f )−1(T).
Step 2: Now we will prove that f −1(g−1(T)) ⊇(g ∘f )−1(T).

12.2 Theorems about Images and Preimages
225
Assume s ∈(g ∘f )−1(T) = h−1(T). So h(s) ∈T. Then (g ∘f )(s) ∈T; so
g( f (s)) ∈T. So f (s) ∈g−1(T) = V. And in turn, s ∈f −1(V) = f −1(g−1(T)).
We have now proved both f −1(g−1(T)) ⊆(g ∘f )−1(T) and f −1(g−1(T)) ⊇
(g ∘f )−1(T). Thus, f −1(g−1(T)) = (g ∘f )−1(T).
◾
◽
Our next theorems are about the interactions of image and preimage. The
point to remember is that they are not inverse operations, but they have some
qualities of this relationship.
Theorem 12.2.4.
Let f ∶A →B be a function.
1. If S ⊆Domain( f ), then S ⊆f −1( f (S)). This says that S is a subset, but allows
the possibility that f −1( f (S)) has elements not in S.
2. If T ⊆B, then f (f −1(T)) ⊆T. This says that f (f −1(T)) is a subset, but allows
the possibility that T has elements not in f (f −1(T)).
3. If f (x) is injective, and if S ⊆Domain( f ), then S = f −1( f (S)).
4. If f (x) is surjective, then for all T ⊆B, f ( f −1(T)) = T.
5. If f (x) is bijective, then for all S ⊆A, f −1( f (S)) = S and f ( f −1(T)) = T.
Very few people remember the details of this theorem for very long. Well, the
last one says that
When an inverse exists, the notation for images and preimages
works ﬁne.
And that is easy to remember.
The best course of action is to be very cautious when we ﬁnd we want to cancel
the images and preimages. Generic pictures can help us distinguish between
what is true and what is not. Still, we should make it a point to actually prove
what we need rather than rely on what we remember from this theorem.
Proof draft. Assume that f ∶A →B is a function.
Part 1. We claim that if S ⊆Domain( f ), then S ⊆f −1( f (S)).
Proof of claim. Assume S ⊆Domain( f ).
Comment: What are we proving? If s ∈S, then s ∈f −1( f (S)). So we should begin
by assuming that s ∈S.
Assume s ∈S.
Comment: What are we proving now? We are proving that s ∈f −1( f (S)) =
f −1(T) for the particular set T = f (S). So how do we prove that? We show that
s ∈f −1(T) = {x ∈A ∣f (x) ∈T}. So how do we prove that? We show f (s) ∈f (S).
But this is true by the deﬁnition. It takes longer to ﬁgure out what to say than

226
12 Images and Preimages
it does to say it. Notice that we deﬁnitely need S ⊆Domain( f ). So it’s time to
write the proof.
Since s ∈S ⊆Domain( f ), f (s) ∈f (S). So by the deﬁnition of preimage,
s ∈f −1( f (S)).
◾
Part 2. We claim that if T ⊆B, then f (f −1(T)) ⊆T.
Proof of claim. Assume T ⊆B.
Comment: What are we proving? If t ∈f (f −1(T)), then t ∈T. We know what to
do to start the proof.
Assume t ∈f (f −1(T)) = f (S) for the particular S = f −1(T). Then
t ∈f (S);
(12.12)
t ∈{y ∈B ∣∃x ∈S s.t. f (x) = y};
t ∈{y ∈B ∣∃x ∈f −1(T) s.t. f (x) = y}.
So ∃s ∈f −1(T) s.t. f (s) = t.
Comment: When we hear “there exists,” we need to choose a name, and s seems
fresher in this part than x. We now ﬁnish the proof.
But s ∈f −1(T) means f (s) ∈T. So sure enough, t = f (s) ∈T.
◾
Part 3. We claim that if f (x) is injective, and if S ⊆Domain( f ), then
S = f −1( f (S)).
Proof of claim. Assume that f (x) is injective. Assume S ⊆Domain( f ).
Comment: What are we proving? That f −1( f (S)) = S. So, we must prove that the
subset goes both ways. However, one direction is already proved; so we need to
prove: if s ∈f −1( f (S)), then s ∈S. At least we know how to start.
Assume s ∈f −1( f (S)). Then f (s) ∈f (S).
Comment: We were warned about this. It looks like we need to cancel the
functions, but that is not allowed. We ask, what does this mean?
We have
f (s) ∈f (S) = {y ∈B ∣∃x ∈S s.t. f (x) = y}.
(12.13)
So ∃s′ ∈S s.t. f (s′) = f (s).

12.2 Theorems about Images and Preimages
227
Comment: When we hear “there exists,” we need to choose a name, but y might
be confusing, and s is already used in this part. So s′ seems like a good choice.
Now f (s′) = f (s), and f (x) is injective; so s′ = s. So s = s′ ∈S.
◾
Part 4. We claim that if f (x) is surjective, then for all T ⊆B, f (f −1(T)) = T.
Proof of claim. Assume that f (x) is surjective. Assume T ⊆B.
Comment: What are we proving? That f (f −1(T)) = T. We have already proved
the subset in one direction. So we need to prove: if t ∈T, then t ∈f (f −1(T)).
Assume t ∈T.
Comment: Now what are we proving?
t ∈f (f −1(T)) = {y ∈B ∣∃x ∈f −1(T) s.t. f (x) = y}.
(12.14)
So we need to prove that something exists. We set up a word problem: ﬁnd x so
that x ∈f −1(T) and f (x) = t. In other words, ﬁnd x so that f (x) ∈T and f (x) = t.
What to do, what to do? Is there something we know that we haven’t used? Well,
we assumed that f (x) is surjective. That means everything in B comes out of the
function. Do I have something in B? Oh, yeah.
Now t ∈T ⊆B. Since f (x) is surjective, there exists s ∈S such that f (s) = t.
Then f (s) = t ∈T. So s ∈f −1(T) and then t = f (s) ∈f (f −1(T)).
◾
Δ
We should rewrite this proof to just include what we need to say.
Proof. Assume f ∶A →B as a function with domain A.
Part 1. We claim that if S ⊆Domain( f ), then S ⊆f −1( f (S)).
Proof of claim. Assume S ⊆Domain( f ). Assume s ∈S. Since s ∈S ⊆A =
Domain( f ), we know that f (s) is deﬁned. Then f (s) ∈f (S) by the last theorem.
So s ∈f −1( f (S) by the same theorem.
◾
Part 2. We claim that if T ⊆B, then f (f −1(T)) ⊆T.
Proof of claim. Assume T ⊆B. Assume t ∈f ( f −1(T)). Then
t ∈{y ∈B ∣∃x ∈f −1(T) s.t. f (x) = y}.
(12.15)
So ∃s ∈f −1(T) s.t. f (s) = t. But s ∈f −1(T) means f (s) ∈T. So t = f (s) ∈T.
Thus, t ∈f (f −1(T)) implies t ∈T.
◾

228
12 Images and Preimages
Part 3. We claim that if f (x) is injective, and if S ⊆Domain( f ), then
S = f −1( f (S)).
Proof of claim. Assume that f (x) is injective. Assume S ⊆Domain( f ). Assume
s ∈f −1( f (S)).
Then f (s) ∈f (S). So by the deﬁnition of image ∃s′ ∈S so that f (s′) = f (s).
We assumed that f (x) is injective, so s′ = s. So s = s′ ∈S. Since this proves
f −1( f (S)) ⊆S, by part 1 we are done.
◾
Part 4. We claim that if f (x) is surjective, then for all T ⊆B, f (f −1(T)) = T.
Proof of claim. Assume that f (x) is surjective. Assume T ⊆B. Assume t ∈T.
Then t ∈T ⊆B. Since f (x) is surjective, there exists s ∈S such that f (s) = t.
Then f (s) = t ∈T. So s ∈f −1(T) and then t = f (s) ∈f (f −1(T)). So by part 2, we
are done.
◾
Part 5 follows immediately from parts 3 and 4. This completes the proof.
◽
There is a quick corollary to this theorem that shows that our choice to use
the same notation for an inverse function and for the preimage of a set does not
cause too much of a problem. When an inverse exists, both interpretations give
the same results, and any issues with extra conditions go away.
Corollary 12.2.5.
Let f ∶A →B and g∶B →A be functions. Let S ⊆A and
T ⊆B. If g(x) is the inverse of f (x), then
1. f −1(T) = g(T);
2. g−1(S) = f (S);
3. g( f (S)) = S;
4. f (g(T)) = T.
12.2.2
Unions and intersections
Except for the image of an intersection, the algebra of images and preimages
works ﬁne.
Theorem 12.2.6.
Let f ∶A →B have domain A.
1. For all S1 ⊆A and S2 ⊆A, f (S1 ∩S2) ⊆f (S1) ∩f (S2).
2. For all S1 ⊆A and S2 ⊆A, f (S1 ∪S2) = f (S1) ∪f (S2).
3. For all T1 ⊆B and T2 ⊆B, f −1(T1 ∩T2) = f −1(T1) ∩f −1(T2).
4. For all T1 ⊆B and T2 ⊆B, f −1(T1 ∪T2) = f −1(T1) ∪f −1(T2).
5. If f (x) is injective, then for all S1 ⊆A and S2 ⊆A, f (S1 ∩S2) = f (S1) ∩f (S2).

12.2 Theorems about Images and Preimages
229
Proof. The trick to these proofs is to maintain your logical discipline and
choose your variables wisely.
Part 1. We claim that for all S1 ⊆A and S2 ⊆A, f (S1 ∩S2) ⊆f (S1) ∩f (S2).
Proof of claim. Assume t ∈f (S1 ∩S2) = {y ∈B ∣∃x ∈S1 ∩S2 s.t.f (x) = y}.
Then ∃s ∈S1 ∩S2 s.t. f (s) = t. Now s ∈S1 ∩S2 means s ∈S1 and s ∈S2. So
f (s) ∈f (S1) and f (s) ∈f (s2). So t = f (s) ∈f (S1) ∩f (S2).
◾
Part 2. We claim that for all S1 ⊆A and S2 ⊆A, f (S1 ∪S2) = f (S1) ∪f (S2).
Proof of claim. Assume that S1 ⊆A and S2 ⊆A. We are proving a set equality,
so we must prove that the subset relation holds in both directions.
Step 1: First we will prove that f (S1 ∪S2) ⊆f (S1) ∪f (S2).
Assume t ∈f (S1 ∪S2) = {y ∈B ∣∃x ∈S1 ∪S2 s.t. f (x) = y}. So ∃s ∈S1 ∪S2
s.t. f (s) = t. Now s ∈S1 ∪S2 means s ∈S1 or s ∈S2.
Case 1: Assume s ∈S1, then f (s) ∈f (S1) ⊆f (S1) ∪f (S2).
Case 2: Assume s ∈S2, then f (s) ∈f (S2) ⊆f (S1) ∪f (S2).
So in either case, t ∈f (S1 ∪S2) implies t = f (s) ∈f (S1) ∪f (S2).
This proves that f (S1 ∪S2) ⊆f (S1) ∪f (S2).
Step 2: Now we will prove that f (S1 ∪S2) ⊇f (S1) ∪f (S2).
Assume t ∈f (S1) ∪f (S2). Then either t ∈f (S1) or t ∈(S2).
Case 1: Assume t ∈f (S1). Then ∃s1 ∈S1 such that f (s1) = t. But s1 ∈S1 ⊆
S1 ∪S2. So t = f (s1) ∈f (S1 ∪S2).
Case 2: Assume t ∈f (S2). Then ∃s2 ∈S1 such that f (s2) = t. But s2 ∈S2 ⊆
S1 ∪S2. So t = f (s2) ∈f (S1 ∪S2).
In either case, t ∈f (S1) ∪f (S2) implies t = f (s2) ∈f (S1 ∪S2).
This proves that f (S1 ∪S2) ⊇f (S1) ∪f (S2).
◾
Part 3. We claim that for all T1 ⊆B and T2 ⊆B, f −1(T1 ∩T2) = f −1(T1) ∩
f −1(T2).
Proof of claim. Assume that T1 ⊆B and T2 ⊆B. We are proving a set equality,
so we must prove that the subset relation holds in both directions.
Step 1: We will ﬁrst prove that f −1(T1 ∩T2) ⊆f −1(T1) ∩f −1(T2).
Assume s ∈f −1(T1 ∩T2). So f (s) ∈T1 ∩T2. So f (s) ∈T1 and f (s) ∈T2. So s ∈
f −1(T1) and s ∈f −1(T2). Then s ∈f −1(T1) ∩f −1(T2). This proves that f −1(T1 ∩
T2) ⊆f −1(T1) ∩f −1(T2).
Step 2: We will now prove that f −1(T1 ∩T2) ⊇f −1(T1) ∩f −1(T2).

230
12 Images and Preimages
Assume s ∈f −1(T1) ∩f −1(T2). So s ∈f −1(T1) and s ∈f −1(T2). So f (s) ∈T1
and f (s) ∈T2. So f (s) ∈T1 ∩T2 . Finally s ∈f −1(T1 ∩T2). This proves that
f −1(T1 ∩T2) ⊇f −1(T1) ∩f −1(T2).
◾
Part 4. We claim that for all T1 ⊆B and T2 ⊆B, f −1(T1 ∪T2) = f −1(T1) ∪
f −1(T2).
Proof of claim. Assume that T1 ⊆B and T2 ⊆B. We are proving a set equality,
so we must prove that the subset relation holds in both directions.
Step 1: We will ﬁrst prove that f −1(T1 ∪T2) ⊆f −1(T1) ∪f −1(T2).
Assume s ∈f −1(T1 ∪T2). So f (s) ∈T1 ∪T2. So f (s) ∈T1 or f (s) ∈T2.
So s ∈f −1(T1) or s ∈f −1(T2). Then s ∈f −1(T1) ∪f −1(T2). This proves that
f −1(T1 ∪T2) ⊆f −1(T1) ∪f −1(T2).
Step 2: We will now prove that f −1(T1 ∪T2) ⊇f −1(T1) ∪f −1(T2).
Assume s ∈f −1(T1) ∪f −1(T2). So s ∈f −1(T1) or s ∈f −1(T2). So f (s) ∈T1 or
f (s) ∈T2. So f (s) ∈T1 ∪T2 . Finally, s ∈f −1(T1 ∪T2). This proves that f −1(T1 ∪
T2) ⊇f −1(T1) ∪f −1(T2).
◾
Part 5. We claim that if f (x) is injective, then for all S1 ⊆A and S2 ⊆A,
f (S1 ∩S2) = f (S1) ∩f (S2).
Proof of claim. Assume that f (x) is injective. Assume S1 ⊆A and S2 ⊆A. We
have already proved that f (S1 ∩S2) ⊆f (S1) ∩f (S2). So we need to only prove
that f (S1 ∩S2) ⊇f (S1) ∩f (S2).
Assume t ∈f (S1) ∩f (S2). Then t ∈f (S1) and t ∈f (S2). But t ∈f (S1) means
∃s ∈S1 such that f (s) = t. In addition, t ∈f (S2) means ∃s′ ∈S1 such that
f (s′) = t.
Comment: We do not use the same variable for two possible diﬀerent things just
because we expect that they are the same.
Now f (s) = t = f (s′), and f (x) is injective. So s = s′. But then s ∈S1
and
s′ ∈S2.
We
have
s = s′ ∈S1 ∩S2.
So
f (s) ∈f (S1 ∩S2),
and
then
t = f (s) ∈f (S1 ∩S2). This proves that f (S1 ∩S2) ⊇f (S1) ∩f (S2).
◾
◽
Properties of the unions and intersections of two sets can often be extended
to any number of sets. That is what happens here:
Theorem 12.2.7.
Let f ∶A →B have domain A. Let Si with i ∈be a family
of sets where ∀i ∈, Si ⊆A.

12.3 Problems
231
1. f
(⋂
i∈
Si
)
⊆⋂
i∈
f (Si).
2. f
(⋃
i∈
Si
)
= ⋃
i∈
f (Si).
Theorem 12.2.8.
Let f ∶A →B have domain A. Let Ti with i ∈be a family
of sets where ∀i ∈, Ti ⊆B.
1. f −1
(⋂
i∈
Ti
)
= ⋂
i∈
f −1(Ti).
2. f −1
(⋃
i∈
Ti
)
= ⋃
i∈
f −1(Ti).
We leave the proofs as exercises.
12.3
Problems
12.1
Draw a generic diagram that illustrates why the theorem:
for all S1 ⊆A and S2 ⊆A, f (S1 ∩S2) ⊆f (S1) ∩f (S2)
only has a subset in its conclusion.
12.2
Let f ∶A →B where A = {1, 2, 3, 4, 5}, B = {1, 2, 3, 4, 5, 6} and f is given
by the following table.
x
f (x)
1
2
2
6
3
4
3
5
4
True or false:
(a) Domain( f ) = A.
(b) Range(f )= B.
(c) Codomain(f )= B.
(d) f (2) = {6}.
(e) f (4) = 3.
(f) f ({1, 2}) = {2, 6}.
(g) f (3) = ∅.
(h) f (x) is injective.

232
12 Images and Preimages
(i) f (x) is surjective.
(j) f −1({3, 4}) = {4, 5}.
(k) f −1({1, 5}) = ∅.
(l) f −1(2) = 1.
(m) f −1(2) = {1}.
12.3
Let f ∶ℝ→ℝbe given by f (x) = 1
x2 . Find the following (but do not
bother to prove that your answer is correct):
(a) f ((0, 3)).
(b) f ([0, 4)).
(c) f (ℝ).
(d) f ([−2, 3]).
(e) f (∅).
(f) f −1((0, ∞)).
(g) f −1((−1, 1)).
(h) f −1(( 1
4, 1]).
(i) f −1(ℝ).
(j) f −1(∅).
12.4
Let f ∶ℝ→ℝbe given by f (x) = x3 −x. Find the following (but do not
bother to prove that your answer is correct):
(a) f ({ −1, 0, 1)}).
(b) f ([−1, 1]).
(c) f ((−1, 1)).
(d) f ((−5, 5)).
(e) f (ℝ).
(f) f (∅).
(g) f −1({0}).
(h) f −1((0, ∞)).
(i) f −1((−120,120)).
(j) f −1(ℝ).
(k) f −1(∅).
12.5
Deﬁne f ∶ℝ→ℝby f (x) = x3−1
x−1 . Find the following (but do not bother
to prove that your answer is correct):
(a) f ({ −2, 0, 2)}).
(b) f ([−5, 5]).
(c) f ({ ± 1}).
(d) f ({1}).
(e) f (1).
(f) f −1({7}).
(g) f −1((0, ∞)).
(h) f −1(∅).

12.3 Problems
233
12.6
Let f ∶A →B be a function. Let S1, S2 ⊆A and T1, T2 ⊆B.
(a) Prove that if S1 ⊆S2, then f (S1) ⊆f (S2).
(b) Prove that if T1 ⊆T2, then f −1(T1) ⊆f −1(T2).
12.7
Prove that if f ∶A →B is a function with domain A and Si with i ∈is
a family of sets where ∀i ∈, Si ⊆A, then
f
(
⋂
i∈
Si
)
⊆
⋂
i∈
f (Si).
(12.16)
12.8
Prove that if f ∶A →B is a function with domain A and Ti with i ∈is
a family of sets where ∀i ∈, Ti ⊆B, then
f −1
(
⋃
i∈
Ti
)
=
⋃
i∈
f −1(Ti).
(12.17)
12.9
Suppose that f ∶A →B is an injective function with domain A. Prove
that if Si with i ∈is a family of sets where ∀i ∈, Si ⊆A, then
f
(
⋂
i∈
Si
)
=
⋂
i∈
f (Si).
(12.18)
12.10
Let f ∶A →B be a function with domain A. Prove that if ∀S ⊆A,
S = f −1( f (S)), then f (x) is injective.
12.11
Let f ∶A →B be a function with domain A. Prove that if ∀T ⊆B,
T = f (f −1(T)), then f (x) is surjective.
12.12
Let us call intervals of the form (a, b), (a, ∞), and (−∞, b) open. And we
will call intervals of the form [a, b], [a, ∞), and (−∞, b] closed. Then as
usual, we call (a, b), (a, b], [a, b), and [a, b] bounded, and we call (a, ∞),
[a, ∞), (−∞, b), and (−∞, b] unbounded.
(a) For f ∶ℝ→ℝgiven by f (x) = 1
x:
i. Is there an open interval A, where f (A) is not an open interval?
ii. Is there a closed interval A, where f (A) is not a closed interval?
iii. Is there a bounded interval A, where f (A) is not a closed
bounded?
iv. Is there an open interval B where f −1(B) is not an open interval?
v. Is there a closed interval B where f −1(B) is not a closed interval?
vi. Is there a bounded interval B where f −1(B) is not a bounded
interval?

234
12 Images and Preimages
12.13
Let us call intervals of the form (a, b), (a, ∞), and (−∞, b) open. And we
will call intervals of the form [a, b], [a, ∞), and (−∞, b] closed. Then as
usual, we call (a, b), (a, b], [a, b), and [a, b] bounded, and we call (a, ∞),
[a, ∞), (−∞, b), and (−∞, b] unbounded.
(a) Find a function f ∶ℝ→ℝwith domain ℝwhere:
i. There is an open interval A, where f (A) is not an open interval.
ii. There is a closed interval A, where f (A) is not a closed interval.
iii. There is a bounded interval A, where f (A) is not a bounded
interval.
(b) Find a function f ∶ℝ→ℝwith domain ℝwhere:
i. There is an open interval B where f −1(B) is not an open interval.
ii. There is a closed interval B where f −1(B) is not a closed interval.
iii. There is a bounded interval B where f −1(B) is not a bounded
interval.
12.14
Let f ∶ℝ→ℝ. We know that it is common to be asked to solve f (x) = 0
for the variable x. Write out the set of solutions to this problem using
the notation introduced in this section.

235
13
Final Basic Notions
We have two unrelated mathematical ideas to investigate before we can return
to our study of number systems.
13.1
Binary operations
We start with a deﬁnition.
Deﬁnition 13.1.1.
Let A be a set. A binary operation b on A is a function
b ∶A × A →A with domain A × A.
Notation. When we consider b ∶A × A →A as a binary operation, we write
b((x, y)) as xby. In addition, in place of the variable name, we use a symbol such
as +, ×, ∗, ⋅, ⃝, ⊕, ⊗, ∪, ∩, ∨, ∧, or ⊠.
Now suppose that ⊠∶A × A →A is a binary operation of some sort. The fact
that this is a function with domain A × A means that, for all x, y ∈A, the value
of x ⊠y is well deﬁned. The fact that the codomain of ⊠is A means that, for
all x, y ∈A, x ⊠y is a unique element of A. This property of binary operations
is often referenced by saying that the operation ⊠is closed.
Now we deﬁne some properties associated with certain binary operations.
These should be very familiar.
Deﬁnition 13.1.2.
Let A be a set. Let ⊠be a binary operation on A.
1. We say that ⊠is associative if ∀a, b, c ∈A, (a ⊠b) ⊠c = a ⊠(b ⊠c).
2. We say that ⊠is commutative if ∀a, b ∈A, a ⊠b = b ⊠a.
3. If ⊞is another binary operation on A, we say that ⊠distributes over ⊞if
∀a, b, c ∈A, a ⊠(b ⊞c) = (a ⊠b) ⊞(a ⊠c).
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

236
13 Final Basic Notions
4. We say that i ∈A is a ⊠-identity if ∀a ∈A, a ⊠i = i ⊠a = a.
5. For a, b ∈A, we say that b is a ⊠-inverse of a if a ⊠b = b ⊠a = i, where i is
a ⊠-identity.
These are very general deﬁnitions that apply to all sorts of situations, but they
should have very obvious applications to our study of number systems. We have
two equally general theorems.
Theorem 13.1.3.
Let A be a set. Let ⊠be a binary operation on A. If there is
a ⊠-identity in A, it is unique.
Proof. Assume that i1 ∈A and i2 ∈A are ⊠-identities. Consider i1 ⊠i2. Then
i1 = i1 ⊠i2 = i2.
◽
So all we need is a true binary operation on a single set A, and we know that,
if one exists, the identity for that operation is unique. (It must be a two-sided
identity, though.)
Theorem 13.1.4.
Let A be a set. Let ⊠be a binary operation on A. If ⊠is
associative, then if a ∈A has a ⊠-inverse, then the inverse is unique to a.
Proof. Assume that ⊠be an associative operation on A. Assume that b1 and b2
are inverses of a. Consider b1 ⊠(a ⊠b2). On the one hand,
b1 ⊠(a ⊠b2) = b1 ⊠i
(13.1)
= b1.
On the other, associativity tells us that
b1 ⊠(a ⊠b2) = (b1 ⊠a) ⊠b2
(13.2)
= i ⊠b2
= b2.
Since the results of the operation are unique, b1 = b2.
◽
Notice how critical it is that the deﬁnitions of identity and inverse require the
element work on both sides.
13.2
Finite and inﬁnite sets
13.2.1
Objectives of this discussion
Even though the object of this study is to understand and master the practice
of mathematical proof, this next discussion will not emphasize proofs of the
theorems it contains. In fact, all the proofs will be relegated to the chapter’s
appendix. This is not because the proofs are diﬃcult. In fact, all but two are

13.2 Finite and Inﬁnite Sets
237
rather straightforward. It is not because they are not interesting. Indeed, several
are just the opposite. Nevertheless, for our purposes, it is the intuitive results
about ﬁnite and inﬁnite sets that are important. All we really need is to know
that they follow from the oﬃcial deﬁnitions.
A mathematical deﬁnition of a ﬁnite set did not appear until the 19th century.
Until then, mathematicians relied on their intuition about ﬁnite sets in their
proofs. On the other hand, mathematicians found that their intuition about
inﬁnite sets was not always reliable. It was generally thought that complete inﬁ-
nite sets were nonmathematical and could not be used in rigorous proof. In
the 19th century, mathematician Georg Cantor proposed a rigorous deﬁnition
of an inﬁnite set that could be used to prove the intuitive ideas that worked
and exposed the intuitive notions that caused problems. Finally, mathemati-
cians had a theory of inﬁnite sets that was rigorous. After Cantor, inﬁnite sets
became legitimate objects in Mathematics.
We will give Cantor’s deﬁnitions. We will then state the intuitive results
that follow from them. These intuitive theorems about ﬁnite and inﬁnite
sets are the results that are used most often throughout Mathematics. The
proofs are important and interesting because they show that those results are
consequences of Cantor’s deﬁnitions. Since our goal is to understand how to
read and write mathematical proofs across mathematical subjects, they are
less important to us than they would be if we were studying set theory itself.
Thus, we will emphasize the properties of ﬁnite and inﬁnite sets that appear in
those other subjects. Just in case we do choose to go over the proofs, they are
included in an appendix to this chapter.
13.2.2
Why the fuss?
The idea of a set that is so large that it is inﬁnite is very intuitive. However, apply-
ing logic to this intuitive notion is rather diﬃcult. It can produce conclusions
that are actually contradictory. Early Greek philosophers and mathematicians
explored this and could never ﬁnd a good solution. They decided that the best
course of action was to banish complete inﬁnite sets from formal logic and
mathematics. It is not that they did not consider collections with more than
enough objects to be inﬁnite but that they said that no one should consider
them all at one time. Thus, when Euclid proved that there are inﬁnitely many
prime numbers in his manuscript Elements, he was not allowed to say that was
what he did. Rather he said,
“Prime numbers are more than any assigned magnitude of prime
numbers.”
Mathematicians stuck with this Greek rule against complete inﬁnities,
mostly, for the following 2000 years. However, their resolve had begun to
crack by the beginning of the 18th century with the invention of inﬁnitesimal

238
13 Final Basic Notions
calculus by Isaac Newton and Gottfried Leibniz. (“Inﬁnitesimal” = “inﬁnitely
small.”) By the middle of the 19th century, the Greek warning about using
complete inﬁnities seemed justiﬁed as mathematicians pushed calculus to the
point where their results occasionally seemed paradoxical. Finally though,
inﬁnitesimal calculus was placed on ﬁrm ground by Bernard Bolzano, Richard
Dedekind, Charles M˙eray, Georg Cantor, and others. Cantor went further and
came up with rules for dealing with inﬁnitely large sets as a whole. Those rules
are now part of standard mathematical logic.
For mathematicians to know what their theorems mean, the terms they
use must have solid deﬁnitions. Cantor gave solid deﬁnitions for the intuitive
notions of a ﬁnite set and an inﬁnite set. He used his deﬁnitions to prove the
properties of these sets that intuition says they should have. We will retrace his
steps. But the important lesson in this chapter is not quite the same as in every
other chapter. The deﬁnitions of ﬁnite and inﬁnite sets are important to know,
but the theorems they imply are more important. In most of Mathematics, we
use ﬁnite and inﬁnite sets in proofs by using the theorems about them much
more than we use the deﬁnitions. So, while we need to know the deﬁnitions of
ﬁnite and inﬁnite, in practice it is much more important that we know exactly
what intuitive properties of such sets do actually hold.
Once we are past the technical aspects and results that follow from Cantor’s
deﬁnitions of ﬁnite and inﬁnite sets, these deﬁnitions are rarely used to prove
theorems about such sets. It is the properties that follow from those deﬁnitions
that are used in proofs.
The properties that we will use, and the ones we must remember, are as
follows:
• An inﬁnite set cannot be a subset of a ﬁnite set.
• If there is a bijection between sets A and B, then either they are both ﬁnite
or they are both inﬁnite.
• If f ∶A →B has domain A and is injective, then if A is inﬁnite, B must be
inﬁnite.
• If f ∶A →B has domain A and is surjective, then if A is ﬁnite, B must be
ﬁnite.
• The elements in a ﬁnite set can be counted, and the size of the set be given
as a natural number or 0.
• If U is a set with a total order, and A ⊆U is any nonempty, ﬁnite subset, then
A has a maximum and a minimum.
• If A and B are ﬁnite sets, then both A ∪B and A × B are also ﬁnite.
We will use the deﬁnitions of inﬁnite and ﬁnite to state theorems that follow
from Cantor’s deﬁnitions. We will only state them, and we relegate their proofs
to the appendix of the chapter.

13.2 Finite and Inﬁnite Sets
239
13.2.3
Finite sets
We begin with a theorem that Cantor used to produce his deﬁnition of an inﬁ-
nite set. He certainly wanted his deﬁnition to tell us that the set {1, 2, 3, 4 … , n}
is a ﬁnite set for any natural number n. He knew that this set had the following
property.
Theorem 13.2.1.
For n ∈ℕ, let Sn = {x ∈ℕ∣x ≤n}. For all n ∈ℕ, if f ∶
Sn →Sn is an injective function with domain Sn, then f (x) is surjective.
Since sets of the form Sn = {x ∈ℕ∣x ≤n} should be typical ﬁnite sets, this
idea leads to a deﬁnition of a ﬁnite set:
Deﬁnition 13.2.2.
Let A be a set. We say that A is ﬁnite when
if f ∶A →A is an injective function with domain A,
then f (x) is surjective.
A set is inﬁnite when it is not ﬁnite. We know how to negate a logical
statement.
Deﬁnition 13.2.3.
Let A be a set. We say that A is inﬁnite when
there exists f ∶A →A an injective function with domain A
where f (x) is not surjective.
This might seem strange, but it is reassuring that it is very easy to see that
familiar inﬁnite sets of numbers ﬁt this deﬁnition.
The natural numbers ℕform an inﬁnite set, as the function
f ∶ℕ→ℕgiven by f (n) = n + 1
(13.3)
illustrates. It is injective, but 1 ∉Range( f ). Once we have one such function,
there are plenty available:
f2 ∶ℕ→ℕgiven by f2(n) = n + 2;
(13.4)
f3 ∶ℕ→ℕgiven by f3(n) = n + 3;
f 4 ∶ℕ→ℕgiven by f4(n) = n + 4.
Or perhaps
g ∶ℕ→ℕgiven by g(n) = 2n.
(13.5)
This last formula also works to prove that the integers form an inﬁnite set:
g1 ∶ℤ→ℤgiven by g(n) = 2n.
(13.6)

240
13 Final Basic Notions
−2
−1
1
2
−1
1
0
Figure 13.1 j(x) =
x
√
x2+1.
On the other hand, notice that the function g3 ∶ℝ→ℝgiven by g(x) = 2x will
not suﬃce to show that ℝis inﬁnite. In this case, g is actually bijective. So, we
need a fancier function to show that ℝis inﬁnite. Here is one that will do nicely:
j ∶ℝ→ℝgiven by j(x) =
x
√
x2 + 1
.
(13.7)
We can see from the graph that while j is injective, it is not surjective
(Figure 13.1).
Notice that
h ∶ℝ→ℝgiven by h(x) = Arctan(x)
(13.8)
would also work to show that ℝis inﬁnite.
Intuition certainly implies that because, ℕ⊆ℤ⊆ℚ⊆ℝ, once we know that
ℕis inﬁnite, the others must also be. It will be gratifying to see a result such as
this in the list of theorems that can be proved from these deﬁnitions.
13.2.4
Intuitive properties of inﬁnite sets
As we have said (repeatedly), the things to remember about ﬁnite and inﬁnite
sets are their useful properties. We will state the theorems that give these prop-
erties. All but the last theorem about ﬁnite sets are followed by their contrapos-
itives, which turn them into equivalent theorems about inﬁnite sets. Typically,
one or both directions will seem like they should be obvious.
Theorem 13.2.4.
Let A and B be sets with 𝛽∶A →B a bijection. If A is ﬁnite,
then B is ﬁnite.
Corollary 13.2.5.
Let A and B be sets with 𝛽∶A →B a bijection. If A is inﬁ-
nite, then B is inﬁnite.

13.2 Finite and Inﬁnite Sets
241
Since the existence of a one-to-one onto relation between the sets A and B
should mean that they are of the same “size,” this should certainly be true.
Theorem 13.2.6.
Let A and B be sets with A ⊆B. If B is ﬁnite, then A is ﬁnite.
Corollary 13.2.7.
Let A and B be sets with A ⊆B. If A is inﬁnite, then B is
inﬁnite.
It makes sense that you cannot put inﬁnitely many things inside a ﬁnite
collection.
Theorem 13.2.8.
Let A and B be sets with j ∶A →B an injection with domain
A. If B is ﬁnite, then A is ﬁnite.
Corollary 13.2.9.
Let A and B be sets with j ∶A →B an injection with
domain A. If A is inﬁnite, then B is inﬁnite.
This says to assign inﬁnitely many things so that each gets its own location;
you need inﬁnitely many locations.
Theorem 13.2.10.
Let A and B be sets with j ∶A →B a surjection with
domain A. If A is ﬁnite, then B is ﬁnite.
Corollary 13.2.11.
Let A and B be sets with j ∶A →B a surjection with
domain A. If B is inﬁnite, then A is inﬁnite.
If there are inﬁnitely many places to put things, it will take inﬁnitely many
things to ﬁll all those places.
Theorem 13.2.12.
Let A be a nonempty ﬁnite set. Then there exists a unique
n ∈ℕso that there is a bijection b ∶Sn →A where Sn = {x ∈ℕ∣x ≤n}.
This theorem guarantees that our deﬁnition of ﬁnite implies that every ﬁnite
set can be counted using the natural numbers.
13.2.5
Counting ﬁnite sets
Theorem 13.2.12, more than any other, justiﬁes Cantor’s strange deﬁnitions of
ﬁnite and inﬁnite sets. It is the converse of the theorem that inspired these def-
initions in the ﬁrst place.
The proof of theorem 13.2.12 is surprisingly long and technical, especially
compared to the theorems before it. Still we should not be that surprised since it
is the hitch pin that connects our nonintuitive deﬁnition of ﬁnite to our intuitive
expectations of ﬁnite sets. This theorem and its diﬃcult proof would garner a

242
13 Final Basic Notions
lot more attention and examination in a study of set theory or the foundations of
mathematics. Of course, since we are currently only interested in the properties
of ﬁnite sets, the length of this proof is not that important to us.
The result stated in this theorem is critical. The theorem helps us by allowing
us to use a nice notation for ﬁnite sets. If we know that A is a ﬁnite set, we might
choose to write A as
A = {a1, a2, a3 … an}.
(13.9)
We do not have this option unless we know for sure that A is ﬁnite. For example,
ℝis inﬁnite, but we cannot write
ℝ= {r1, r2, r3 … rn … }.
(13.10)
The reason we cannot do this is fodder for other, greater, mathematical studies.
The most important thing about this theorem is that it allows us to prove
things about ﬁnite sets using induction. It says that we can count the number
of elements in any ﬁnite set. We need to set notation for the size of a set. For
the number of elements in a ﬁnite set, we write
|A| = n or #(A) = n
(13.11)
where n is the natural number guaranteed by the theorem. Of course, we also
say that |∅| = 0.
Proof technique. If we know that a set S is ﬁnite and we have not yet
named any of the elements in it, it is often convenient to say, “Let |S| = n and
S = {s1, s2, s3 … sn}.” This careful statement means that we have made the
elements distinct; that is, si = sj implies i = j. If there is a total order and we
think that the size of the elements will matter in the proof, we can also add
“where s1 < s2 < s3 < sn.” This also means that the elements are distinct.
The next theorems are all proved by counting the ﬁnite sets and performing
induction on the number of elements they have. Again, it is the results we care
most about:
Theorem 13.2.13.
Let S and T be ﬁnite sets, then S ∪T is ﬁnite.
Theorem 13.2.14.
Let A be a set, and let
(A) = {S ∣S ⊆A}.
(13.12)
If A is ﬁnite, then (A) is ﬁnite.
We call (A) the power set of A.
Theorem 13.2.15.
Let A and B be ﬁnite sets. Then A × B is a ﬁnite set.

13.2 Finite and Inﬁnite Sets
243
Theorem 13.2.16.
If A and B are ﬁnite sets, then there are only ﬁnitely many
functions f ∶A →B.
13.2.6
Finite sets in a set with a total order
We will ﬁnish up with one last theorem about ﬁnite sets, but this time we pro-
vide a proof immediately afterward. The proof illustrates a version of induction
where a two-part base for the induction is required. The issue that requires the
extra step is the one we often encounter when we need an element in a set. If
our proof requires an element of a set, we must prove that the set is not empty.
We have seen many proofs that begin as “Assume x ∈S” without a previous
assumption that S is not empty. In all of these, we were logically justiﬁed to
make this assumption because we were proving something like “If x ∈S, then
P(x).” Logic always allows us to assume the hypothesis of the statement we are
proving. In the next proof, we will hit a point where we need to “Let x ∈S.”
We are not proving a statement that allows us to assume such an x exists, so we
must prove that it does before we take this step. As it turns out in the next proof,
the set from which we need an x might have been empty had we not adjusted
an earlier part of the proof to avoid it. Hence, the proof by induction starts
with two base steps. The thing to realize is that, no doubt, the ﬁrst attempt at a
proof probably had the typical one-step base, but that once the proof reached
the point that we needed an x in a set that might be empty, it was rewritten to
ﬁx this problem.
Theorem 13.2.17.
Let U be a set with a total order. If A ⊆U, A ≠∅, and A is
ﬁnite, then A has a maximum and a minimum.
Proof draft. Assume that U has a total order. Then that order is transitive and
has trichotomy. Assume A ⊆U. Assume A ≠∅. Assume that A is ﬁnite. By the
aforementioned theorem, we can write |A| = n ∈ℕ.
We will now prove the result by induction on |A| = n, but we will only prove
that A has a minimum. The proof that A has a maximum is basically the same
argument.
Step 1, the ﬁrst base step. We claim that if n = 1, then A has a minimum.
Proof of claim. Assume |A| = 1. Then let A = {a}. Now a ∈A and ∀x ∈A,
a ≤x. So a is the minimum of A.
◾
Step 2, the second base step. We claim that if n = 2, then A has a minimum.
Proof of claim. Assume |A| = 2. Then let A = {a, b} ⊆U with a ≠b. Since
a, b ∈U and the order on U has trichotomy, there are two possibilities:

244
13 Final Basic Notions
a < b or b < a. In case 1 where a < b, a = Min(A). In case 2 where b < a,
b = Min(A). In either case, A has a minimum.
◾
Step 3, the induction step. We claim that
If for any set A ⊆U with |A| = n0 ≥1, A has a minimum, then for any set
B ⊆U with |B| = n0 + 1, B has a minimum.
Comment: Notice that we wrote out this step carefully. We included the required
assumption that A be nonempty, and we did not use the letter A to denote two
diﬀerent sets.
Proof of claim. Assume that if A is a set and |A| = n0 ≥1, then A has a mini-
mum.
Comment: As always, we note that this says, “if we ever have such a set A ….”
This assumption does not give us a set A.
Assume |B| = n0 + 1.
Comment: So this assumption actually gives us a set to work with. But what are
we proving now though? That B has a minimum.
Now because n0 + 1 ≥1, B ≠∅. So we let b ∈B. Now let A = B∖{b}. We have
|A| = n0 + 1 −1 = n0. By the assumption n0 ≥1, so A is not empty, and has a
minimum. Call it m.
Comment: This was the moment when we realized that we could not use the
induction assumption unless we knew that A = B∖{b} was not empty.
Then m ∈A = B∖{b} ⊆B ⊆U.
And if x ∈A = B∖{b}, then m ≤x.
Consider {b, m}. This is a subset of U with two elements. By step 2, {b, m} has
a minimum. Call it m′.
Comment: Here again, we need this second base step.
We now claim that m′ = Min(B).
To show this, we must prove that (1) m′ ∈B and (2) that for all x ∈B, m ≤x.
To prove (1), note that we have {b, m} ⊆B, and m′ ∈{b, m}, so we must have
m′ ∈B as well.
To prove (2), assume that x ∈B. There are two possibilities, x = b or x ≠b. If
x = b, then m′ ≤b because b ∈{b, m}.
Assume instead that x ≠b. Then x ∈B∖{b} = A. But m is the minimum of
A, so m ≤x. But m′ = Min({b, m}) ≤m ≤x. So m′ = Min(B).
◾

13.2 Finite and Inﬁnite Sets
245
So, by the principle of mathematical induction if A ⊆U, A ≠∅, and A is ﬁnite,
then A has a minimum. Again, the proof that A has a maximum is very similar,
and we leave it to the reader.
Δ
This proof should be rewritten.
Proof. Assume that U has a total order. Then that order is transitive and has
trichotomy. Assume A ⊆U. Assume A ≠∅. Assume that A is ﬁnite. By the
aforementioned theorem, we can write |A| = n ∈ℕ.
We will now prove the result by induction on |A| = n, but we will only prove
that A has a minimum. The proof that A has a maximum is basically the same
argument. Proof by induction on n.
Step 1, the ﬁrst base case. We claim that if n = 1, then A has a minimum.
Proof of claim. Assume |A| = 1. Then let A = {a}. Now a ∈A and ∀x ∈A,
a ≤x. So a is the minimum of A.
◾
Step 2, the second base case. We claim that if n = 2, then A has a minimum.
Proof of claim. Assume |A| = 2. Then let A = {a, b} ⊆U with a ≠b. Since
a, b ∈U and the order on U has trichotomy, there are two possibilities:
a < b or b < a. In the case where a < b, a = Min(A). In the case where b < a,
b = Min(A). In either case, A has a minimum.
◾
Step 3, the induction step. We claim that
If for |A| = n0 ≥1, A has a minimum, then for |B| = n0 + 1, B has a minimum.
Proof of claim. Assume that if A is a set and |A| = n0, then A has a minimum.
Assume |B| = n0 + 1. Now B ≠∅. So we let b ∈B. Now let A = B∖{b}. Then
|A| = n0 + 1 −1 = n0.
By assumption, A has a minimum. Call it m. Then m ∈A = B∖{b} ⊆B ⊆U.
And if x ∈A = B∖{b}, then m ≤x. Consider {b, m}. This is a subset of U with
two elements. By step 2, {b, m} has a minimum. Call it m′.
We claim that m′ =Min(B).
To show this, we must prove that (1) m′ ∈B and (2) that for all x ∈B, m ≤x.
To see (1), note that we have m′ ∈{b, m} ⊆B.
We now show (2). Assume that x ∈B. There are two possibilities, x = b
or x ≠b. In the ﬁrst, m′ ≤b because b ∈{b, m}. For the second case,
assume x ≠b; so x ∈B∖{b} = A. So m ≤x. But m′ = Min({b, m}) ≤m ≤x.
So m′ =Min(B).
◾
Thus, by the principle of mathematical induction, if A ⊆U, A ≠∅, and A is
ﬁnite, then A has a minimum. Again, the proof that A has a maximum is very
similar.
◽

246
13 Final Basic Notions
13.3
Summary
When it comes to dealing with ﬁnite and inﬁnite sets, it is important to know
the mathematical deﬁnitions of these terms.
Deﬁnition 13.3.1.
Let A be a set. We say that A is ﬁnite when
if f ∶A →A is an injective function with domain A, then f (x) is surjective.
Deﬁnition 13.3.2.
Let A be a set. We say that A is inﬁnite when
if there exists f ∶A →A an injective function with domain A where f (x) is not
surjective.
In practice, when these terms come up in a proof about number systems,
it is much more important to know the properties that follow from these
deﬁnitions.
• An inﬁnite set cannot be a subset of a ﬁnite set.
• If there is a bijection between sets A and B, then either they are both ﬁnite
or they are both inﬁnite.
• The image of a ﬁnite set under a function will also be ﬁnite.
• The elements in a ﬁnite set can be counted, and the size of the set be given
as a natural number or 0.
• If A ≠∅is ﬁnite, then A can be written as
A = {a1, a2, a3 … an}.
(13.13)
• If U is a set with a total order, and A ⊆U is nonempty and ﬁnite, then A has
a maximum and a minimum. In addition, we can write
A = {a1, a2, a3 … an}
(13.14)
with
a1 < a2 < a3 … < an.
(13.15)
• If A and B are ﬁnite sets, then A ∪B, and A × B is ﬁnite as will be the set of
all subsets of either set.
Once we are done with this chapter, we will always use these properties of
ﬁnite and inﬁnite sets in our proofs and not the deﬁnitions.
13.4
Problems
13.1
In elementary school, we considered subtraction as a binary operation
on ℕ. By our deﬁnition of a binary operation, this is allowed? What about
it as a binary operation on ℤ?

13.4 Problems
247
(a) Is subtraction on ℤassociative?
(b) Is subtraction on ℤcommutative?
(c) Why do mathematicians rarely consider subtraction as a binary
operation in number systems?
13.2
Let A = {f ∶ℝ→ℝ}. Deﬁne the following binary operations on A.
( f ⊕g)(x) = f (x) + g(x).
(13.16)
( f ⊙g)(x) = f (x) ⋅g(x).
( f ⊚g)(x) = (g ∘f )(x).
(a) Is ⊕associative?
(b) Is ⊕commutative?
(c) Does ⊕have an identity?
(d) Do all elements in A have ⊕-inverses?
(e) Is ⊙associative?
(f) Is ⊙commutative?
(g) Does ⊙have an identity?
(h) Do all elements in A have ⊙-inverses?
(i) Is ⊚associative?
(j) Is ⊚commutative?
(k) Does ⊚have an identity?
(l) Do all elements in A have ⊚-inverses?
(m) Does ⊙distribute over ⊕?
(n) Does ⊚distribute over ⊕?
13.3
In multivariable calculus a binary operation, the cross product, was
deﬁned on ℝ3. Thus, if (x, y, z) ∈ℝ3 and (u, 𝑣, 𝑤) ∈ℝ3, then (x, y, z)×
(u, 𝑣, 𝑤) ∈ℝ3.
(a) Is the cross product on ℝ3 associative? Prove your answer.
(b) Is the cross product on ℝ3 commutative? Prove your answer.
(c) Is there an identity for the cross product on ℝ3? Prove your answer.
(d) Do elements of ℝ3 have inverses for the cross product? Prove your
answer.
(e) Are you glad that there is Internet where you can look up mathemat-
ical deﬁnitions?
13.4
Prove the following using the deﬁnition of inﬁnite:
(a) The interval (0, 1) is inﬁnite.
(b) The intervals [0, 1], (0, 1], and [0, 1) are inﬁnite.
(c) The interval (a, b) ⊆ℝis inﬁnite.
(d) The intervals [a, b], (a, b], and [a, b) in ℝare inﬁnite.

248
13 Final Basic Notions
13.5
Let S ⊆ℝ. Then deﬁne
(S) = {x ∈ℝ∣∃s, t ∈S s.t. s ≠t and x = |s −t|}.
(13.17)
(a) Explain why (S) is the set of all distances between elements of S.
(b) Why not use the set
wrong(S) = {x ∈ℝ∣∃s, t ∈S s.t. x = |s −t|}
(13.18)
for the set of all distances between elements of S?
(c) Prove that if S is ﬁnite, then (S) is ﬁnite. (Do not use the deﬁnition
of ﬁnite!)
(d) True or false: if S is any ﬁnite subset of ℝ, then there is a nonzero
minimum distance between diﬀerent elements of S.
13.6
Consider the functions f ∶ℚ→ℚgiven by f (x) = x2 and g ∶ℚ→ℚ
given by g(x) = |x|x. One of these can be used in the deﬁnition to prove
that ℚis inﬁnite. Which one is it? Explain your answer.
13.5
Appendix
Theorem 13.5.1.
For n ∈ℕ, let Sn = {x ∈ℕ∣x ≤n}. For all n ∈ℕ, if
f ∶Sn →Sn is an injective function with domain Sn, then f (x) is surjective.
Proof. Proof by induction on n.
Step 1, the base step. We claim that if n = 1, then if f ∶Sn →Sn is an injective
function with domain Sn, then f (x) is surjective.
Proof of claim. Assume that f ∶S1 →S1 is an injective function with domain
S1. So f ∶{1} →{1} has domain {1}. Thus, f (1) ∈{1}. This can only mean that
f (1) = 1. So
Range( f ) = f ({1}) = {f (1)} = {1} = Codomain( f ).
(13.19)
So f (x) is surjective.
◾
Step 2, the inductive step. We claim that
if for all f ∶Sn0 →Sn0 with domain Sn0,
if f (x) is injective, then f (x) is surjective,
then for all g ∶Sn0+1 →Sn0+1 with domain Sn0+1,
if g(x) is injective, then g(x) is surjective.
Proof of claim. Assume that for all f ∶Sn0 →Sn0 with domain Sn0, if f (x) is
injective, then f (x) is surjective.

13.5 Appendix
249
Assume that g ∶Sn0+1 →Sn0+1 has domain Sn0+1.
Assume that g(x) is injective.
Now n0 + 1 ∈Sn0+1 = Domain(g). So g(n0 + 1) ∈Sn0+1. There are two possi-
bilities: g(n0 + 1) = n0 + 1 or g(n0 + 1) ∈Sn0.
Case 1: Assume g(n0 + 1) = n0 + 1.
We claim that in this case g(Sn0) ⊆Sn0.
To see this, assume BWOC n0 + 1 ∈g(Sn0). Then ∃x ∈Sn0 s.t. g(x) = n0 + 1.
Then g(x) = n0 + 1 = g(n0 + 1). Since g(x) is injective, this says that n0 + 1 =
x ∈Sn0. That is a contradiction. Thus, g(Sn0) ⊆Sn0.
Deﬁne f ∶Sn0 →Sn0 by
f (x) = g(x).
(13.20)
Note that the claim shows that we have a valid function because the stated
codomain is correct. Note also that Domain( f ) = Sn0, and f (x) is injective,
because g(x) is.
By our assumption, f (x) is surjective. So
f (Sn0) = Range( f ) = Codomain( f ) = Sn0.
So
Range(g) = g(Sn0+1)
(13.21)
= g(Sn0 ∪{n0 + 1})
= g(Sn0) ∪g({n0 + 1})
= f (Sn0) ∪{g(n0 + 1)}
= Sn0 ∪{n0 + 1}
= Sn0+1
= Codomain( f ).
So g(x) is surjective in this case.
Case 2: Assume g(n0 + 1) ∈Sn0.
Let g(n0 + 1) = m. Deﬁne h ∶Sn0+1 →Sn0+1 by
h(x) =
⎧
⎪
⎨
⎪⎩
m
if x = n0 + 1
n0 + 1
if x = m
x
if x ∉{n0 + 1, m}.
(13.22)
Now (h ∘h)(x) = iSn0+1. So h(x) has an inverse. We know that h(x) is bijective.
Consider (h ∘g) ∶Sn0+1 →Sn0+1. The composition of injections is an injection,
and
(h ∘g)(n0 + 1) = h(g(n0 + 1)) = h(m) = (n0 + 1).
(13.23)

250
13 Final Basic Notions
We now have an injective function (h ∘g) ∶Sn0+1 →Sn0+1 with the full domain,
but with the extra property that (h ∘g)(n0 + 1) = (n0 + 1). This is exactly the
type of function covered in case one. Therefore, we know that (h ∘g) is surjec-
tive. But the composition of surjections is a surjection. So h ∘(h ∘g) is a surjec-
tion. But
h ∘(h ∘g) = (h ∘h) ∘g = i ∘g = g.
(13.24)
Thus, g(x) is a surjection in this case as well.
◾
So we have proved by induction that for all n ∈ℕ, if f ∶Sn →Sn is an injective
function with domain Sn, then f (x) is surjective.
◽
Theorem 13.5.2.
Let A and B be sets with 𝛽∶A →B a bijection. If A is ﬁnite,
then B is ﬁnite.
Proof. Assume that 𝛽∶A →B is a bijection. Assume that A is ﬁnite. So if f ∶
A →A is an injective function with domain A, then f (x) is surjective.
Assume that g ∶B →B has domain B. Assume that g(x) is an injection.
Consider 𝛽−1 ∘g ∘𝛽∶A →A. This has domain A, and because it is the com-
position of injections, it is an injection. Because A is ﬁnite, (𝛽−1 ∘g ∘𝛽)(x) is a
surjection. But the composition of surjections is a surjection; so
𝛽∘(𝛽−1 ∘g ∘𝛽) ∘𝛽−1
(13.25)
is a surjection. But
𝛽∘(𝛽−1 ∘g ∘𝛽) ∘𝛽−1 = g.
(13.26)
We have proved that, if g ∶B →B is an injective function with domain B, then
g(x) is surjective. Thus, we have proved that B is ﬁnite.
◽
Corollary 13.5.3.
Let A and B be sets with 𝛽∶A →B a bijection. Then A is
ﬁnite if and only if B is ﬁnite.
Corollary 13.5.4.
Let A and B be sets with 𝛽∶A →B a bijection. Then A is
inﬁnite if and only if B is inﬁnite.
Proof. Assume that A and B are sets with 𝛽∶A →B a bijection. However, since
𝛽∶A →B is a bijection, so is 𝛽−1 ∶B →A a bijection. So the theorem is also its
own converse: If B is ﬁnite, then A is ﬁnite. Together this says that A is ﬁnite, if
and only if B is ﬁnite. The contrapositive of that is: B is inﬁnite if and only if A
is inﬁnite.
◽
Theorem 13.5.5.
Let A and B be sets with A ⊆B. If B is ﬁnite, then A is ﬁnite.

13.5 Appendix
251
Proof. Assume A ⊆B. Assume that B is ﬁnite. So if f ∶B →B is an injective
function with domain B, then f (x) is surjective.
Assume that g ∶A →A is a function with domain A.
Assume that g(x) is injective.
Deﬁne f ∶B →B by
f (x) =
{
g(x)
if x ∈A
x
if x ∈B∖A.
(13.27)
Then Domain(f ) = A ∪(B∖A) = A. In addition, since A ∩(B∖A) = ∅, we can
easily prove that f (x) is injective.
Since B is ﬁnite, we know that f (x) is surjective. So f (B) = B.
Now
B = f (B)
(13.28)
= f (A ∪(B∖A))
= f (A) ∪f (B∖A)
= g(A) ∪(B∖A).
Then we can intersect both sides of B = g(A) ∪(B∖A) with A.
A ∩B = A ∩(g(A) ∪(B∖A)).
(13.29)
So
A ∩B = A ∩(g(A) ∪(B∖A))
(13.30)
A = (A ∩g(A)) ∪(A ∩(B∖A))
= (A ∩g(A)) ∪∅
= A ∩g(A).
But g(A) ⊆A, so we have g(A) = A. This proves that g(x) is surjective.
Since if g ∶A →A is an injective function with domain A, then g(x) is surjec-
tive; so we have proved that A is ﬁnite.
◽
Corollary 13.5.6.
Let A and B be sets with A ⊆B. If A is inﬁnite, then B is
inﬁnite.
Theorem 13.5.7.
Let A and B be sets with j ∶A →B an injection with domain
A. If B is ﬁnite, then A is ﬁnite.
Proof. Assume that j ∶A →B has domain A. Assume that j(x) is an injection.
Assume that B is ﬁnite. Deﬁne j′ ∶A →j(A) by j′(x) = x. By changing the
codomain we have created a bijection j′ ∶A →j(A). But j(A) ⊆B a ﬁnite set.
So j(A) is also ﬁnite. Using the bijection j′(x), we know that A is ﬁnite.
◽

252
13 Final Basic Notions
Corollary 13.5.8.
Let A and B be sets with j ∶A →B an injection with
domain A. If A is inﬁnite, then B is inﬁnite.
Theorem 13.5.9.
Let A and B be sets with j ∶A →B a surjection with domain
A. If B is ﬁnite, then A is ﬁnite.
Proof. Assume that j ∶A →B is a surjection with domain A. Assume that A
is ﬁnite. Since j(x) is surjective, for all b0 ∈B, ∃a0 ∈A s.t. j(a0) = b0. (There
may be more than one, but any one will suﬃce.) Thus, for each b ∈B, we have
assigned exactly one a0 ∈A so that j(ai) = bi. We can deﬁne (at least one) func-
tion k ∶B →A by k(b0) = a0.
Claim. We claim that k ∶B →A is injective.
Proof of claim. Assume k(b1) = k(b2) = a1. Then k(b1) = a1 and k(b2) = a1.
But by our deﬁnition of j(b), this means that j(a1) = b1 and j(a1) = b2.
So b1 = b2.
◾
Since we have a injection k ∶B →A where the codomain A is ﬁnite, by the
previous theorem, the domain B is ﬁnite.
◽
The proof of the next theorem is the most complicated in this group. It is,
however, the best indication we have that our deﬁnition of ﬁnite is correct.
Theorem 13.5.10.
Let A be a nonempty ﬁnite set. Then there exists a unique
n ∈ℕso that there is a bijection b ∶Sn →A where Sn = {x ∈ℕ∣x ≤n}.
The statement is: If A is a nonempty ﬁnite set, then ∃n ∈ℕsuch that there
exists some b ∶Sn →A, which is a bijection.
Proof. We will prove the contrapositive:
If A is a nonempty set so that, ∀n ∈ℕ, no function b ∶Sn →A is a bijection,
then A is inﬁnite.
Assume that A is a nonempty set.
Assume that for all n ∈ℕ, no function b ∶Sn →A is a bijection.
Claim. For all n ∈ℕ, there exists a function fn ∶Sn →A such that fn(x) has
domain Sn, and
• fn(x) is injective,
• when n ≥2, ∀x ∈Sn , fn(x) = fn−1(x),
• and when n ≥2, fn(n) ∉fn−1(Sn−1).

13.5 Appendix
253
Proof of claim. We prove the claim by induction: (We need two base cases
though.)
Statement of Step 1 of Claim: If n = 1, ∃fn ∶Sn →A s.t fn(x) has domain Sn, and
fn(x) is injective.
Proof of Step 1 of Claim. Since A ≠∅, let a1 ∈A. Deﬁne f1 ∶{1} →A by f1(1) =
a1. Then f1(x) has domain S1, and f1(x) is injective. The other claims in the con-
clusion do not apply to this situation. ◊
Statement of Step 2 of Claim: For n = 2, ∃f2 ∶S2 →A s.t
• f2(x) has domain S2,
• and f2(x) is injective,
• and ∀x ∈S1, f2(x) = f1(x),
• and f2(n) ∉f1(S1).
Proof of Step 2 of Claim. Starting with f1(x) from step 1, we have f1 ∶S1 →A
domain S1, and where f1(x) is injective. But by our overall assumption, no bijec-
tions such as this exist. So f1(x) cannot be bijective. So f1(x) is not surjective.
Then
f1(S1) ⊆A while f1(S1) ≠A.
(13.31)
So ∃a2 ∈A∖f1(S1). Deﬁne f2 ∶S2 →A by
f2(x) =
{
f1(x)
if x ∈S1 = {1}
a2
if x = 2.
(13.32)
Then f2(x) has domain S2, and f2(x) is injective. In addition, if x ∈S1 = {1}, then
f2(x) = f1(x). And f2(2) ∉f1(S1). ◊
Statement of Step 3 of Claim: (This one is long!) We must prove that
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢⎣
If
for n = n0,
∃fn0 ∶Sn0 →A
such that
fn0(x) has domain Sn0
and
n0(x) is injective
and
∀x ∈Sn0−1, fn0(x) = fn0−1(x)
and
fn0(n0) ∉fn0−1(Sn0−1)
then for n = n0 + 1
∃fn0+1 ∶Sn0+1 →A
such that
fn0+1(x) has domain Sn0+1
and
fn0+1(x) is injective
and
∀x ∈Sn0, fn0+1(x) = fn0(x)
and
fn0(n0) ∉fn0−1(Sn0−1).
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥⎦

254
13 Final Basic Notions
Proof of Step 3 of Claim. Assume that ∃fn0 ∶Sn0 →A such that
⎡
⎢
⎢
⎢⎣
fn0(x) has domain Sn0,
and
fn0(x) is injective
and ∀x ∈Sn0−1, fn0(x) = fn0−1(x)
and
fn0(n0) ∉fn0−1(Sn0−1).
⎤
⎥
⎥
⎥⎦
By our overall assumption, fn0(x) cannot be a bijection. So ∃an0+1 ∈
A∖( fn0(Sn0)).
Deﬁne fn0+1 ∶Sn0+1 →A by
fn0+1(x) =
{
fn0(x)
if x ∈Sn0
an0+1
if x = n0 + 1.
(13.33)
Then fn0+1(x) has domain Sn0+1. In addition, fn0+1(x) is injective because fn0(x) is
injective and
fn0+1(n0 + 1) = an0+1 ∈A∖( fn0(Sn0)).
(13.34)
In addition, if x ∈Sn0, fn0+1(x) = fn0(x).
Finally, fn0+1(n0 + 1) ∉fn0(Sn0). ◊
This completes the proof of our claim by induction. Thus, we have proved that
for all n ∈ℕ, there exists a function fn ∶Sn →A such that fn(x) has domain Sn
and
• fn(x) is injective,
• when n ≥2, ∀x ∈Sn , fn(x) = fn−1(x),
• and when n ≥2, fn(n) ∉fn−1(Sn−1).
◾
Now consider the functions fn ∶Sn →A as described in their deﬁnitions:
(fn, A) where fn ⊆Sn × A. Notice that fn ⊆Sn × A ⊆ℕ× A.
Let
f∞=
⋃
n∈ℕ
fn
(13.35)
as sets. Then f∞⊆ℕ× A. We will prove that the pair ( f∞, A) ﬁts our deﬁnition
of a function by proving the necessary conditions.
The vertical line test. We claim that if (n, a) ∈f∞and (n, a′) ∈f∞, then a = a′.
Proof of claim. Assume (n, a) ∈f∞and (n, a′) ∈f∞. Then (n, a) ∈fn and
(n, a′) ∈fn. Since ( fn, A) is a function, a = a′.
◾
We also make a few claims about f∞(x).

13.5 Appendix
255
Claim. Domain(f∞) = ℕ.
Proof of claim. Assume n ∈ℕ. Then n ∈Sn. So fn(n) = a ∈A. That is, (n, a) ∈
fn ⊆f∞. So f∞(n) ∈A.
◾
Thus, we have a function f∞∶ℕ→A.
Claim. We claim that f∞(x) is injective.
Proof of claim. Assume f∞(n) = f∞(n′). We may assume without loss of gener-
ality that n′ ≤n. Now fn ∶Sn →A and fn(x) has domain Sn, and fn(x) is injec-
tive, and ∀x ∈Sn with n ≥2, fn(x) = fn−1(x), and fn(n) ∉fn−1(Sn−1). So f∞(n′) ∉
fn−1(Sn−1). But since f∞(n) = f∞(n′), we must have n′ = n.
◾
Now we have constructed an injective function f∞∶ℕ→A. We know that ℕ
is inﬁnite. So by an earlier result, A must be inﬁnite.
◽
Theorem 13.5.11.
Let A and B be ﬁnite sets, then A ∪B is ﬁnite.
Proof. Assume that A and B are ﬁnite sets. By the aforementioned theorem,
there is an injection j ∶Sn →A and a bijection k ∶Sm →B for integers n and
m. We can deﬁne i ∶Sn+m →A ∪B by
i(x) =
{
j(x)
if x ≤n
k(x −n)
if x > n.
(13.36)
It is easy to see that i(x) is a surjection (but perhaps not an injection: ). So by a
previous result, A ∪B is ﬁnite.
◽
We have also proved the following corollary.
Corollary 13.5.12.
Let S and T be ﬁnite sets, then |S ∪T| ≤|S| + |T|.
Theorem 13.5.13.
Let A be a set. If A is ﬁnite, then (A) is ﬁnite.
Proof. Assume that A is a ﬁnite. We will prove this by induction on |A| = n.
Step 1. We claim that if n = 0, then (A) is ﬁnite.
Proof of claim. Assume n = 0. Then A = ∅, and (A) = {∅}. So (A) has one
element, and so it is ﬁnite.
◾
Step 2. We claim that

256
13 Final Basic Notions
If, for all A with |A| = n0, (A) is ﬁnite, then, for all A′ with |A′| = n0 + 1,
(A′) is ﬁnite.
Proof of claim. Assume that for all sets A with |A| = n0, (A) is ﬁnite. Assume
that A′ is a set with |A′| = n0 + 1. Now A′ ≠∅, so let a0 ∈A′. We can write
(A′) = {S ∣S ⊆A′}
(13.37)
= {S ∣S ⊆A′and a0 ∉S} ∪{S ∣S ⊆A′and a0 ∈S}.
If we let A = A′ ∖{a0}, then
{S ∣S ⊆A′and a0 ∉S} = (A).
(13.38)
In addition,
{S ∣S ⊆A′and a0 ∈S} = {S′ ∪{a0} ∣S′ ∈(A)}.
(13.39)
By the induction assumption, these are both ﬁnite sets. Since the union of ﬁnite
sets is ﬁnite, we have proved that (A′) is ﬁnite.
◾
So it follows by induction that A is a ﬁnite set, then (A) is ﬁnite.
◽
Next we need a seemingly unrelated lemma.
Lemma 13.5.14.
Let n, m, p, q ∈ℕ. If
2n ⋅3m = 2p ⋅3q, then n = p and
m = q.
Proof. Assume n, m, p, q ∈ℕand 2n ⋅3m = 2p ⋅3q. By trichotomy in ℕ, exactly
one of the following is true: n < p, p < n, or p = n. Case 1: Assume n < p. Then
∃k ∈ℕs.t. n + k = p. Then
2n ⋅3m = 2p ⋅3q = 2n+k ⋅3m = 2n ⋅2k ⋅3m.
(13.40)
So using the cancellation property,
3m = 2k ⋅3m.
(13.41)
But 3m is odd and since k ∈ℕ, 2k ⋅3m. This is a contradiction. This case cannot
hold. Case 2, p < n, can be eliminated in a similar way. The only possibility is
p = n.
But then
2n ⋅3m = 2p ⋅3q = 2n ⋅3q.
(13.42)
So 3m = 3q. By trichotomy, m < q, q < m, or m = q. Again cancellation in ℕ
rules out the ﬁrst two possibilities. So we have both n = p and m = q.
◽
Now we state and prove the result we really want.
Theorem 13.5.15.
Let A and B be ﬁnite sets. Then A × B is a ﬁnite set.

13.6 Epilogue
257
Proof. Assume that A and B are ﬁnite sets. Then there exists n ∈ℕwith a bijec-
tion 𝛼∶A →Sn = {1, 2 … n} and ∃m ∈ℕwith a bijection 𝛽∶B →Sm. Deﬁne
𝛾∶A × B →Sn × Sm by 𝛾(s, t) = (𝛼(s), 𝛽(t)).
Claim. We claim that 𝛾(x) is a bijection.
Proof of claim. Since Domain(𝛼) = A and Domain(𝛽) = B, then Domain(𝛾) =
A × B.
Assume 𝛾(s, t) = 𝛾(s′, t′). Then (𝛼(s), 𝛽(t)) = (𝛼(s′), 𝛽(t′)). So 𝛼(s) = 𝛼(s′), and,
𝛽(t) = 𝛽(t′). Since 𝛼and 𝛽are injective, s = s′ and t = t′. So (s, t) = (s′, t′). This
proves that 𝛾is injective.
Assume (p, q) ∈Sn × Sm. Then p ∈Sn and q ∈Sm. But 𝛼and 𝛽are surjec-
tive; so ∃a ∈A s.t. 𝛼(a) = p and ∃b ∈B s.t. 𝛽(b) = q. So (a, b) ∈A × B so that
𝛾(a, b) = (𝛼(a), 𝛽(b)) = (p, q). So this proves 𝛾is surjective.
◾
Because of this claim and our theorems about bijective sets, if we prove that
Sn × Sm is ﬁnite, it will prove that A × B is ﬁnite.
Note that if (p, q) ∈Sn × Sm, then 2p ⋅3q ≤3n+m. This means that we can
deﬁne h ∶Sn × Sm →S3n+m by
h(p, q) = 2p ⋅3q.
(13.43)
This has domain Sn × Sm, and by the lemma, it is an injection. We also know
that S3n+m is a ﬁnite set by our ﬁrst theorem. So by another previous theorem,
Sn × Sm is ﬁnite.
◽
13.6
Epilogue
Two of the proofs given in the appendix hide a bit of logical basics we will not
discuss except just a bit here. It is hard to miss the complexity in the proof of
the theorem about counting ﬁnite sets:
Theorem 13.6.1.
Let A be a nonempty ﬁnite set. Then there exists a unique
n ∈ℕso that there is a bijection b ∶Sn →A where Sn = {x ∈ℕ∣x ≤n}.
It says that our deﬁnition of ﬁnite requires the existence of a natural num-
ber and at least one bijection b ∶Sn →A. The proof, however, does not give
any instruction on how ﬁnd the number or the bijection from that deﬁnition.
The proof takes full advantage of the consequences of our decision to require
all logical statements be either true or false and not both. We use tricks of
a two-valued logical system to prove that something exists, not by ﬁnding it,
but rather by logical trickery. The proof does not construct the number or the
bijection; it proves that they exist by ruling out the only other possibility. The
assumption “A is a non-empty set so that, ∀n ∈ℕ, no function b ∶Sn →A is a

258
13 Final Basic Notions
bijection” covers so many functions that is only of use through careful logic. For
a large A, it cannot be used to form an actual construction in a ﬁnite amount of
steps. Since the contrapositive requires A to be inﬁnite, this could be a problem.
There are branches of Mathematics that study the algorithms for solving
collections of similar problems. These areas of Mathematics ask questions
such as:
Is there a way to test an equation for rational solutions that produces an
answer, yes or no, for any equation in a ﬁnite amount of time?
Or they may ask a more speciﬁc question:
Is there way to factor natural numbers so that the number of bit opera-
tions that digital computer must accomplish is not an exponential func-
tion of the size of the number to be factored?
In areas such as these, proving that something exists or is possible without
giving an actual construction is not as valuable as it is in most of the rest of
Mathematics. There are also mathematicians, logicians, and philosophers who
wonder if mathematics can be done without resort to any type of nonconstruc-
tive proof. As a result, there are parts of Mathematics where the two-valued
logic system is put aside in favor of logical system that stresses algorithmic
construction more forcefully. We are interested in learning the techniques of
standard Mathematics; so we consider the proof by contradiction as always
valid.
The other bit of logical foundations appears in the proof of the theorem:
Theorem 13.6.2.
Let A and B be sets with j ∶A →B a surjection with domain
A. If B is ﬁnite, then A is ﬁnite.
In this proof, we took a surjective function j ∶A →B with domain A
and constructed a function k ∶B →A so that (j ∘k) ∶B →B would give
j ∘k = iB. The function k(x) would only act as an inverse to j(x) on the
right as this; so we are not claiming or requiring that f (x) have a full
(two-sided) inverse. The logical principle behind this construction is known
as “The Axiom of Choice.” It is a part of standard Mathematics based on
two-valued logic. However, particularly when applied to inﬁnite sets, it is often
excluded from those branches of Mathematics where ﬁnite constructions are
required.
Our goal is to master the standard two-valued logical system that is used in
most areas of Mathematics. Those areas that require a diﬀerent approach are
clearly identiﬁed as distinct. It is not that the techniques of standard two-valued
logic are completely lost, but rather they are adapted to ﬁt the problems at hand.

13.6 Epilogue
259
We might ask, what approach to proving existence is best? The answer mostly
depends on who answers it. As a rule, mathematicians care mostly about the
mathematical consequences of their work; logicians care about the validity of
the logic that goes into Mathematics, but philosophers care most about the
hardest question: what is real truth?

261
Part III
A Second Pass at Deﬁning ℝ

263
14
ℕ, ℤ, and ℚ
14.0.1
Basic properties of the natural numbers
In the beginning of this study, we saw how the natural numbers and their
properties can be developed from four simple observations about how they
must work. But since then, we have developed a great deal of mathematical
terminology and algebraic technique. We can take greater advantage of this
background work by beginning with a deﬁnition of the natural numbers based
on their algebraic properties.
Deﬁnition 14.0.1.
The natural numbers, ℕ, form a set with the following
properties:
1. ℕ≠∅.
2. There is a total order on ℕ.
3. ℕis a well-ordered set. (Thus, ℕitself has a minimum; call it 1.)
4. There is a binary operation on ℕcalled addition written as n + m.
5. Addition is associative.
6. Addition is commutative.
7. If n, m ∈ℕ, then n < n + m.
8. If n ∈ℕand n ≠1, then there exists m ∈ℕso that m + 1 = n.
9. If n, m ∈ℕand n < m, then ∀k ∈ℕ, n + k < m + k.
10. There is a binary operation on ℕcalled multiplication written as
n ⋅m = nm.
11. Multiplication is associative.
12. Multiplication is commutative.
13. 1 is a multiplicative identity for ℕ.
14. If k, n, m ∈ℕwith n < m, then n ⋅k < m ⋅k.
15. Multiplication distributes over addition.
16. If n, m ∈ℕ, then n < n + m.
17. If n, m ∈ℕand n ≤m ≤n + 1, then either m = n or m = n + 1.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

264
14 ℕ, ℤ, and ℚ
Our general mathematical deﬁnitions have allowed us to make this list more
compact than when we ﬁrst started. This is because the statements we wrote out
completely the last time are hidden in the deﬁnitions of the terms we now can
use. In addition, a careful look will show that some of the basic properties listed
earlier are missing in this deﬁnition. We are missing the general subtraction
property, but we can at least subtract 1. We are also missing the cancellation
properties. This time, we are trying to be more careful about the minimum
properties we need to nail the natural numbers down to one collection. The
missing properties are now presented as theorems that can be proved using
this trimmed-down list.
First, we have four cancellation results that follow from earlier using our
logical tricks.
Theorem 14.0.2.
If k, n, m ∈ℕwith n + k = m + k, then n = m.
Proof. We will prove the contrapositive: if n ≠m, then n + k ≠m + k. Assume
n ≠m. By trichotomy, there are two cases n < m or m < n. But addition
respects order; so either n + k < m + k or m + k < n + k. Again by trichotomy,
n + k ≠m + k.
◽
Theorem 14.0.3.
If k, n, m ∈ℕwith n + k < m + k, then n < m.
Proof. We will prove the contrapositive: if n ≥m, then n + k ≥m + k. The two
possibilities of “greater than or equal to” follow from the fact that addition is
well deﬁned and that addition respects order.
◽
Theorem 14.0.4.
If k, n, m ∈ℕwith n ⋅k = m ⋅k, then n = m.
Proof. We will prove the contrapositive: if n ≠m, then n ⋅k ≠m ⋅k. Assume
n ≠m. By trichotomy, there are two cases n < m or m < n. But multiplica-
tion respects order, so either n ⋅k < m ⋅k or m ⋅k < n ⋅k. Again by trichotomy,
nk ≠mk.
◽
Theorem 14.0.5.
If k, n, m ∈ℕwith n ⋅k < m ⋅k, then n < m.
Proof. We will prove the contrapositive: if n ≥m, then nk ≥mk. The two possi-
bilities follow from the fact that addition is well deﬁned and that multiplication
respects order.
◽
Next we have a conditional subtraction theorem.
Theorem 14.0.6.
If n, m ∈ℕwith n < m, then ∃k ∈ℕsuch that m = n + k.

ℕ, ℤ, and ℚ
265
Proof draft. Assume n, m ∈ℕand assume n < m.
Comment: We now must prove something exists, rarely our favorite thing to
prove. We either need to ﬁnd one by solving a problem or using magic to cre-
ate one out of thin air. We only have 14 things to work with, but one of them is
well ordering. That is a way to make things appear. We need to set up a set for
which the number we want might be the minimum.
Deﬁne
A = {p ∈ℕ∣n + p ≥m}.
(14.1)
Comment: Good, but before we declare that it has a minimum, we need to be
sure that it is not empty. That means we are proving a “there exists” statement,
and that requires solving a problem. We need to ﬁnd something in the set, but
we must build it from the objects we have assumed that we have. We might just
take a few guesses until we ﬁnd something that works.
Now the part is greater than the whole, so n + m > m, so we have m ∈A.
So A ≠∅. We have a nonempty subset of a set that is well ordered. So A has a
minimum. Call it k. Then k ∈A and if p ∈A, then k ≤p.
Comment: The contrapositive of this says, if p < k, then p ∉A. We expect to ﬁnd
something smaller than k to put this statement to use.
Since 1 = Min(ℕ), there are two possibilities k = 1 or k > 1.
Case 1. Assume k = 1.
Then since k ∈A = {p ∈ℕ∣n + p ≥m}, we know that n + 1 ≥m. But we
assumed at the beginning that n < m. By transitivity, n < m ≤n + 1. So using
the last property in the list, discreteness, we have m = n + 1, and k = 1 is the
required natural number.
Case 2: Assume k ≠1.
Then ∃s ∈ℕso that s + 1 = k. Then s < k = Min(A), so s ∉A = {p ∈ℕ∣n +
p ≥m}. Then n + s < m. But k ∈A, so n + k ≥m. So n + s + 1 ≥m. Then n +
s < m ≤n + s + 1. So m = n + s + 1 = n + k.
Δ
Well now we should hide our thought process and rewrite the proof.
Proof. Assume n, m ∈ℕand assume n < m. Deﬁne
A = {p ∈ℕ∣n + p ≥m}.
(14.2)
Now n + m > m; so we have m ∈A. So A ≠∅. We have a nonempty subset
of a set that is well ordered. So A has a minimum. Call it k. Then k ∈A and if
p ∈A, then k ≤p.

266
14 ℕ, ℤ, and ℚ
There are two possibilities k = 1 or k > 1.
Case 1. Assume k = 1.
Then since k ∈A = {p ∈ℕ∣n + p ≥m}, we know that m ≤n + 1. But we
assumed at the beginning that n < m. By transitivity, n < m ≤n + 1. So using
the last property in the list, we have m = n + 1, and k = 1 is the required natural
number.
Case 2: Assume k ≠1.
Then ∃s ∈ℕso that s + 1 = k. Then s < k =Min(A), so
s ∉A = {p ∈ℕ∣n + p ≥m}.
(14.3)
Then n + s < m. But k ∈A, so n + k ≥m. So n + s + 1 ≥m. Then n + s < m ≤
n + s + 1. So m = n + s + 1 = n + k.
◽
14.0.2
Theorems about the natural numbers
There are plenty of interesting things we can prove about the natural numbers,
but we only need one: the theorem of induction.
Theorem 14.0.7
(The theorem of induction). Let P(n) be a mathematical
statement that is deﬁned on ℕ. Let k0 ∈ℕ.
If
1. for n = k0, P(n) is true; and
2. if for n = n0, P(n) is true, then for n = n0 + 1, P(n) is true,
then for all n ∈ℕwith n ≥k0, P(n) is true.
Proof. We will use a minimum counterexample proof.
Assume that P(k0) is true. Assume that P(n0) is true implies that P(n0 + 1)
is true.
Let
A = {k ∈ℕ∣k ≥k0 and P(k) is false}.
(14.4)
There are two possibilities: A = ∅or A ≠∅.
Case 1: Assume BWOC A ≠∅.
Since ℕis well ordered, A has a minimum. Call it m. Then m ∈A.
In addition, if k ∈A, then m ≤k. The contrapositive of this says, if k < m,
then k ∉A.
First
m ∈A = {k ∈ℕ∣k ≥k0 and P(k) is false}.
(14.5)
So P(m) is false. But P(k0) is true. So m ≠k0. But m ∈A also tells us that m ≥k0.
By trichotomy, we have 1 ≤k0 < m. So m −1 ∈ℕ. In turn, we have (m −1) +
1 > k0. By the last basic property of ℕ, this says m −1 ≥k0.

14.1 The Integers
267
But m −1 < m =Min(A). So m −1 ∉A. Since
A = {k ∈ℕ∣k ≥m0 and P(k) is false},
(14.6)
m −1 is a natural number and greater than or equal to k0; so the problem must
be that P(m −1) is not false.
But we can now use our induction hypothesis. Since P(m −1) is true, we
know that P(m −1 + 1) is true. But m ∈A, so we also have P(m) is false and
true at the same time. We have a contradiction. We have made an assumption
that cannot be true. The set A cannot be nonempty.
So we must have case 2:
A = {k ∈ℕ∣k ≥k0 and P(k) is false} = ∅.
(14.7)
Assume n ∈ℕand n ≥k0. Certainly, n ∉A, so P(n) must be true.
So only case 2 is possible, and because of that: ∀n ∈ℕand n ≥k0, P(n)
is true.
◽
14.1
The integers
14.1.1
An algebraic deﬁnition
This time the description is exactly as it was earlier but with updated
terminology.
Deﬁnition 14.1.1.
The integers form a set ℤwith the following properties:
1. There is a total order on ℤ.
2. If S ⊆ℤand S ≠∅and S is bounded below, then S has a minimum.
3. There is a binary operation on ℤcalled addition written as n + m.
4. Addition is associative.
5. Addition is commutative.
6. There is an additive identity in ℤ. Call it 0. (We know that it is unique.)
7. If n ∈ℤ, then n has an additive inverse.
8. If k, n, m ∈ℤand n < m, then n + k < m + k.
9. There is a binary operation on ℤcalled multiplication written n ⋅m.
10. Multiplication is associative.
11. Multiplication is commutative.
12. There is a multiplicative identity in ℤ. Call it 1. (We know that it is unique.)
13. If k, n, m ∈ℤand n < m and k > 0, then n ⋅k < m ⋅k.
14. Multiplication distributes over addition.
15. If n, m ∈ℤwith nm = 0, then either n = 0 or m = 0.
16. 0 ≠1.
Notice that because we have a general theorem that tells us that a two-sided
identity is unique, we can give our identities names immediately after we say

268
14 ℕ, ℤ, and ℚ
that they exist. Inverses are also unique, but there is a condition that slows us
down, but only slightly. Since addition is associative, and every element of n ∈ℤ
has an inverse, we know that the inverse will be unique to n. We will write the
additive inverse as −n.
14.1.2
Results about the integers
We have some valuable algebraic properties of integers that follow from this
deﬁnition.
Theorem 14.1.2.
If n ∈ℤ, n ⋅0 = 0 ⋅n = 0.
Proof. Assume n ∈ℤ. Consider n + n ⋅0.
n + n ⋅0 = n ⋅1 + n ⋅0
(14.8)
= n ⋅(1 + 0)
= n ⋅1
= n.
Now
n + n ⋅0 = n.
(14.9)
So
(−n) + n + n ⋅0 = (−n) + n
(14.10)
0 + n ⋅0 = 0
n ⋅0 = 0.
◽
Theorem 14.1.3.
If n, m ∈ℤ, then
1. −(−a) = a,
2. −a = (−1) ⋅a,
3. −(a + b) = (−a) + (−b), and
4. −(ab) = (−a)b = a(−b).
Proof.
Part 1. We claim that −(−a) = a.
Proof of claim. Consider a + (−a). Then a + (−a) = 0. So a acts as the inverse
of the integer −a. So −(−a) = a.
◾
Part 2. We claim −a = (−1) ⋅a.

14.1 The Integers
269
Proof of claim. Consider a + (−1) ⋅a.
a + (−1) ⋅a = 1 ⋅a + (−1) ⋅a
(14.11)
= (1 + (−1)) ⋅a
= 0 ⋅a
= 0.
Thus, (−1) ⋅a acts as the inverse of a.
◾
Part 3. We claim −(a + b) = (−a) + (−b).
Proof of claim.
−(a + b) = (−1)(a + b)
(14.12)
= (−1)a + (−1)b
= (−a) + (−b).
◾
Part 4. We claim −(ab) = (−a)b = a(−b).
Proof of claim.
−(ab) = (−1)ab
(14.13)
= (−a) ⋅b
= a ⋅(−b).
◾
◽
Theorem 14.1.4.
If k, n, m ∈ℤwith n < m and k < 0, then k ⋅n > k ⋅m.
Proof. Assume k, n, m ∈ℤ. Assume n < m. Assume k < 0.
Then 0 < −k. Now multiplying n < m by −k , we get
−kn < −km.
(14.14)
So
(k ⋅n + k ⋅m) −(k ⋅n) < (k ⋅n + k ⋅m) −(k ⋅m);
(14.15)
(k ⋅n −k ⋅n) + (k ⋅m) < k ⋅n + (k ⋅m −k ⋅m);
0 + k ⋅m < k ⋅n + 0;
k ⋅m < k ⋅n.
◽
Corollary 14.1.5.
If n ∈ℤand n ≠0, then n2 > 0.
Corollary 14.1.6.
In ℤ, 1 > 0.

270
14 ℕ, ℤ, and ℚ
14.1.3
The relationship between natural numbers and integers
In school, we learn about the integers by constructing them from the natural
numbers. But earlier, we have basically said that any set of numbers that has
all the properties of the integers is the set of integers no matter where it came
from. Our next theorem simply states that these two views of the integers are
the same. Any set of integers by our deﬁnition could have been constructed
from a set of natural numbers as we did in school.
Theorem 14.1.7.
Let N = {n ∈ℤ∣n > 0}. Then N has all the properties of
the natural numbers ℕ.
Proof. This are actually 16 smaller proofs done, one at a time.
1. N ≠∅.
Proof. This follows from the corollary; 1 > 0. ◊
2. There is a total order on N.
Proof. This follows because N ⊆ℤ, which has a total order. ◊
3. N is a well ordered set.
Proof. If S ⊆N and S ≠∅, then 0 is a lower bound of S; so it has a
minimum. (Note that, in particular, N itself has a minimum by this
argument.) ◊
Claim. Min(N) = 1 is the multiplicative identity of ℤ.
Proof of claim. We know that 1 ∈N. So N ≠∅. Since 0 is a lower bound
of N, it has a minimum. Suppose BWOC that m = Min(N) ≠1. Then m ∈
N with m < 1. Then 0 < m < 1. So 0 ⋅m < m2 < 1 ⋅m. Then m2 ∈N and
m2 < Min(N). That is a contradiction.
◾
4. There is a binary operation on N called addition written as n + m.
Proof. We have an addition in ℤ, but we need to check that n, m ∈N
implies n + m ∈N. It does. ◊
5. Addition is associative.
Proof. This is inherited from addition on ℤ. ◊

14.1 The Integers
271
6. Addition is commutative.
Proof. This is also inherited from addition on ℤ. ◊
7. If n ∈N and n ≠1, then there exists m ∈N so that m + 1 = n.
Proof. Now 1 has an additive inverse in ℤ. Assume n ∈N and n ≠1 =
Min(N). So n > 1, and m = n −1 > 0 satisﬁes the requirements. ◊
8. If n, m ∈N and n < m, then ∀k ∈ℕ, n + k < m + k.
Proof. This is inherited from addition on ℤ. ◊
9. There is a binary operation on N called multiplication written as nm.
Proof. We have a multiplication in ℤ, but we need to check that n, m ∈N
implies nm ∈N. It does. ◊
10. Multiplication is associative.
Proof. Inherited from ℤ. ◊
11. Multiplication is commutative.
Proof. Inherited from ℤ. ◊
12. If 1 is the minimum natural number, 1 is a multiplicative identity for N.
We already proved this earlier as a claim.
13. If k, n, m ∈N with n < m, then n ⋅k < m ⋅k.
Proof. Inherited from ℤ. ◊
14. Multiplication distributes over addition.
Proof. Inherited from ℤ. ◊
15. If n, m ∈N, then n < n + m.
Proof. Since m ∈N, 0 < m. So n < n + m. ◊
16. If n, m ∈N and n ≤m ≤n + 1, then either m = n or m = n + 1.
Proof. Assume n, m ∈N and n < m ≤n + 1. Then either n < m ≤n + 1.
So 0 < n −n ≤m −n ≤1. But we know that 1 =Min(N); so m −n = 1. ◊
◽

272
14 ℕ, ℤ, and ℚ
Notation. We identify N as ℕ; so ℕ⊆ℤ.
Corollary 14.1.8.
If ℤis the set of integers, then ℤ= ℕ∪{0} ∪{ −n ∣
n ∈ℕ}.
14.2
The rational numbers
Our next algebraic step leads us to the deﬁnition of an ordered ﬁeld. (Now is a
good time to refresh our memory of this deﬁnition.) An ordered ﬁeld has all the
algebraic properties we want. Unlike the natural numbers ℕand the integers ℤ,
these algebraic properties do not uniquely determine one set of numbers. So we
cannot deﬁne ℚby listing its algebraic properties. The algebraic properties of
ℚalso hold for many other number systems; those systems are called ordered
ﬁelds. The rational numbers form just one example of an ordered ﬁeld. We can
describe ℚuniquely as the smallest ordered ﬁeld, or as the number ratios of
integers to natural numbers (fractions), but those are more like theorems than
deﬁnitions.
We will follow our grade school experience and construct an ordered ﬁeld
using ratios between integers and natural numbers. We will write the results
in this construction as propositions and not theorems because they can be
combined into one theorem that says that the result is indeed an ordered
ﬁeld.
Let = ℤ× ℕ. Deﬁne a relation ≡on by
(n, m) ≡(p, q) if and only if nq = mp.
Proposition 14.2.1.
The relation ≡on is an equivalence relation.
Proof. We must prove that the relation is reﬂexive, symmetric, and transitive.
Part 1. We claim that ≡is reﬂexive. That is, we claim that for all (n, m) ∈=
ℤ× ℕ, (n, m) ≡(n, m).
Proof of claim. Assume (n, m) ∈= ℤ× ℕ. Then nm = mn in ℤ; so (n, m) ≡
(n, m).
◾
Part 2. We claim that ≡is symmetric. That is, we claim:
For all (n, m), (p, q) ∈= ℤ× ℕ, if (n, m) ≡(p, q), then (p, q) ≡(n, m).
Proof of claim. Assume (n, m), (p, q) ∈= ℤ× ℕ. Assume (n, m) ≡(p, q).
Then nq = mp. So mp = nq, and therefore, (p, q) ≡(n, m).
◾

14.2 The Rational Numbers
273
Part 3. We claim that ≡is transitive. That is, we claim:
For all (n, m), (p, q), (s, t) ∈= ℤ× ℕ, if (n, m) ≡(p, q) and (p, q) ≡(s, t),
then (n, m) ≡(s, t).
Proof of claim. Assume (n, m), (p, q), (s, t) ∈= ℤ× ℕ.
Assume (n, m) ≡(p, q). Assume (p, q) ≡(s, t).
Then nq = mp and pt = qs. So
nqt = mpt;
(14.16)
nqt = mqs;
nt = ms
because t, q ∈ℕ. Thus (n, m) ≡(s, t).
◾
Since ≡is reﬂexive, symmetric, and transitive, it follows that ≡is an equiva-
lence relation.
◽
Once we have an equivalence relation, we have equivalence classes. We will
write the equivalence class using the notation everyone calls “fractions:”
[(n, m)] = {(p, q) ∈∣(p, q) ≡(n, m)} = n
m.
(14.17)
We also have the set ∕≡. We will write this as ℚ.
Deﬁnition 14.2.2.
The rational numbers are the elements of ℚ= (∕≡
) as
deﬁned earlier.
Thus for n
m, p
q ∈ℚ,
n
m = p
q if and only if nq = mp.
Deﬁnition 14.2.3.
Deﬁne a relation < on ℚby
n
m < p
q if and only if nq < mp in ℤ.
Notice that this deﬁnition depends on the representations of the two equiv-
alence classes n
m and p
q. We must prove that the result does not.
Proposition 14.2.4.
The relation < on ℚis well deﬁned.
Proof. Comment: We know that “well deﬁned” is usually about the names we
choose. We rephrase well deﬁned as: if we compare the same things using diﬀerent
names, we get the same results.

274
14 ℕ, ℤ, and ℚ
We will prove:
If n1
m1
= n2
m2
and p1
q1
= p2
q2
,
then if n1
m1
< p1
q1
, then n2
m2
< p2
q2
.
Assume
n1
m1 = n2
m2 and p1
q1 = p2
q2 . Next assume
n1
m1 < p1
q1 . So n1m2 = n2m1 and
p1q2 = p2q1 and n1q1 < m1p1. Now m1, m2, q1 and q2 are all positive, and we
can multiply or cancel them from both sides of an inequality without changing
the direction of the inequality. Then
n1q1 < m1p1;
(14.18)
n1m2q1 < m1m2p1;
n2m1q1 < m1m2p1;
n2q1 < m2p1;
n2q1q2 < m2p1q2;
n2q1q2 < m2p2q1;
n2q2 < m2p2.
So n2
m2 < p2
q2 .
◽
Deﬁnition 14.2.5.
Deﬁne a binary operation on ℚby
For n
m, p
q ∈ℚ, n
m + p
q = nq+mp
mq .
Again, we remember that we are working with equivalence classes; so when
we deﬁne something using particular representations of classes, we must prove
that it is actually well deﬁned.
Proposition 14.2.6.
The addition on ℚis well deﬁned.
Proof. We will prove:
If n1
m1 = n2
m2 and p1
q1 = p2
q2 , then n1
m1 + p1
q1 = n2
m2 + p2
q2 .
Assume n1
m1 = n2
m2 and p1
q1 = p2
q2 . So n1m2 = n2m1 and p1q2 = p2q1.
Comment: There is some scratch work that does not appear in the proof. We use
the formula to add n1
m1 + p1
q1 and n2
m2 + p2
q2 . We compare the two results by “cross
multiplying” and run through the algebra to be sure that the two results are
equal. We return to the proof and just write the results logically.

14.2 The Rational Numbers
275
Consider (m2q2)(n1q1 + p1m1).
(m2q2)(n1q1 + p1m1) = m2q2n1q1 + m2q2p1m1
(14.19)
= m1q2n2q1 + m2q1p2m1
= (m1q1)(n2q2 + p2m2).
So
n1q1 + m1p1
m1q1
= n2q2 + m2p2
m2q2
.
(14.20)
So
n1
m1
+ p1
q1
= n2
m2
+ p2
q2
.
(14.21)
◽
Deﬁnition 14.2.7.
Deﬁne a binary operation on ℚby
For n
m, p
q ∈ℚ, n
m ⋅p
q = np
mq.
We remember that we are working with equivalence classes, so we must prove
that it is actually well deﬁned.
Proposition 14.2.8.
The multiplication on ℚis well deﬁned.
Proof. We will prove:
If n1
m1 = n2
m2 and p1
q1 = p2
q2 , then n1
m1 ⋅p1
q1 = n2
m2 ⋅p2
q2 .
Assume
n1
m1 =
n2
m2 and
p1
q1 =
p2
q2 . So n1m2 = n2m1 and p1q2 = p2q1. Consider
n1p1m2q2.
n1p1m2q2 = n2p2m1q1.
(14.22)
So n1p1
m1q1 = n2p2
m2q2 . And so n1
m1 ⋅p1
q1 = n2
m2 ⋅p2
q2 .
◽
To make things easier, we will prove a few results that will ﬁnally allow to use
rational numbers the way we were taught in school.
Proposition 14.2.9.
Let n
m, p
m ∈ℚand k ∈ℕ. Then
1.
nk
mk = n
m.
2.
n
m < p
m if and only if n < p.
3.
n
m + p
m = n+p
m .
4. −n
m = −n
m .

276
14 ℕ, ℤ, and ℚ
Proof.
Part 1. We claim that nk
mk = n
m.
Proof of claim. This follows because nmk = nmk.
◾
Part 2. We claim that n
m < p
m if and only if n < p.
Proof of claim. Here we have
(
n
m < p
m
)
⇔(nm < pm) ⇔n < p.
◾
Part 3. We claim that n
m + p
m = n+p
m .
Proof of claim. Notice that n
m + p
m = nm+pm
m2
= (n+p)m
m2
= (n+p)
m .
◾
Part 4. We claim that −n
m = −n
m .
Proof of claim. We observe that n
m + −n
m = 0
m = 0
1, which is an additive identity.
So −n
m is the additive inverse of n
m.
◾
◽
Now that we know that the names we use for rational numbers do not matter
in the arithmetic, we make and prove 15 separate claims about the algebraic
properties of ℚ.
Proposition 14.2.10.
The order on ℚis transitive.
Proof. Assume n
m, p
q, s
t ∈ℚ. Assume n
m < p
q, and p
q < s
t.
Then nq < mp and pt < qs. Because m, q, t ∈ℕ, we can multiply and cancel
inequalities by them. Then
nqt < mpt
and
mpt < mqs.
nqt < mpt < mqs.
(14.23)
nt < ms.
Thus, n
m < s
t.
◽
Proposition 14.2.11.
The order on ℚhas trichotomy.
Proof. Assume n
m, p
q, s
t ∈ℚ. Then mp and nq are integers, and the integers have
trichotomy. So exactly one of the following is true: mp < nq in which case n
m <
p
q; nq < mp in which case p
q < n
m; or mp = nq in which case n
m = p
q.
◽
Note the two previous propositions together tell us that ℚhas a total order.

14.2 The Rational Numbers
277
Proposition 14.2.12.
Addition on ℚis associative.
Proof. Assume n
m, p
q, s
t ∈ℚ. Then
m
n +
(p
q + s
t
)
= m
n + pt + qs
qt
(14.24)
= mqt + npt + nqs
nqt
= (mq + np)t + nqs
nq
= mq + np
nq
+ s
t
=
(
m
n + p
q
)
+ s
t .
◽
Proposition 14.2.13.
Addition on ℚis commutative.
Proof. Assume n
m, p
q ∈ℚ. Then
m
n + p
q = mq + np
nq
= p
q + m
n .
(14.25)
◽
Proposition 14.2.14.
There is an additive identity in ℚ.
Proof. Consider 0
1 ∈ℚ. Then 0
1 + n
m = 0⋅m+1⋅n
1⋅m
= n
m.
◽
Proposition 14.2.15.
If a ∈ℚ, then a has an additive inverse.
Proof. Assume n
m ∈ℚ. Then −n
m ∈ℚ. And n
m+ −n
m = n−n
m = 0
m = 0
1.
◽
Proposition 14.2.16.
If a, b, c ∈ℚand a < b, then a + c < b + c.
Proof. Assume a, b, c ∈ℚ. Assume a < b. Write a = n
m, b = p
q, and c = s
t.
Now nq < mp. Consider tq(nt + ms).
tq(nt + ms) = (qn)t2 + tqms
(14.26)
< (mp)t2 + tqms
< tm(pt + qs).
So
(nt + ms)
mt
< (pt + qs)
qt
.
(14.27)

278
14 ℕ, ℤ, and ℚ
So
a + c = n
m + s
t < p
q + s
t = b + c.
(14.28)◽
Proposition 14.2.17.
Multiplication on ℚis associative.
Proof. Assume n
m, p
q, s
t ∈ℚ. Then
m
n
(p
q
s
t
)
= mps
nqt =
(
m
n
p
q
)
s
t .
(14.29)◽
Proposition 14.2.18.
Multiplication on ℚis commutative.
Proof. Assume n
m, p
q ∈ℚ. Then
m
n
p
q = mp
nq = p
q
m
n .
(14.30)◽
Proposition 14.2.19.
There is a multiplicative identity in ℚ.
Proof. Consider 1
1 ∈ℚ. Assume n
m ∈ℚ. Then 1
1 ⋅n
m = n
m = n
m ⋅1
1.
◽
Proposition 14.2.20.
If a ∈ℚand a ≠0, then a has a multiplicative inverse.
Proof. Assume
n
m ∈ℚ. Assume
n
m ≠0
1. So n ⋅1 ≠m ⋅0, and we have n2 > 0.
Consider mn
n2 ∈ℚ. Then n
m ⋅mn
n2 = mn2
mn2 = 1
1.
◽
Proposition 14.2.21.
If a, b, c ∈ℚand a < b and 0 < c, then a ⋅c < b ⋅c.
Proof. Write a = n
m, b = p
q, and c = s
t. Assume a = n
m, b = p
q and s
t > 0
1. Then
nq < mp, s > 0 and t ∈ℕ. So nqst < mpst. And so n
m
s
t < p
q
s
t.
◽
Proposition 14.2.22.
If a, b, c ∈ℚ, then a ⋅(b + c) = a ⋅b + a ⋅c.
Proof. Write a = n
m, b = p
q, and c = s
t.
Then
n
m
(p
q + s
t
)
= n
m ⋅
(pt + qs
qt
)
(14.31)
= npt + nqs
mqt
= npmt + mqns
mqmt
= np
mq + ns
mt
= n
m
p
q + n
m
s
t .
◽

14.3 Problems
279
Proposition 14.2.23.
The additive identity and the multiplicative identity on
ℚare not equal.
Proof. Since in ℤwe have 0 ≠1, we know in ℚ, 0
1 ≠1
1.
◽
There is one last result that is not part of being an ordered ﬁeld, but it does
place our previous number systems back in the game.
Theorem 14.2.24.
The subset Z = { n
1 ∈ℚ∣n ∈ℤ} has all the properties of
ℤ. We identify Z and ℤso we can write n
1 = n.
We have proved most of this in the propositions earlier.
14.3
Problems
14.1
Write a mathematical deﬁnition of “ n
m ∈ℚis in lowest terms.”
14.2
Prove that there is no r ∈ℚsuch that r2 = 2.
14.3
Prove that there is no r ∈ℚsuch that r2 = 6.
14.4
Prove that there is no r ∈ℚsuch that r2 = 8.
14.5
Suppose that we try to deﬁne a binary operation on ℚby
n
m ⊕p
q = n + p
m + q.
(14.32)
Show that this is not well deﬁned.
14.6
For any A ⊆ℚdeﬁne the following two sets:
LB(A) = {x ∈ℚ∣x is a lower bound of A}.
UB(A) = {x ∈ℚ∣x is an upper bound of A}.
(a) Prove: If A has a lower bound, then A ⊆UB(LB(A)), but they need
not be equal.
(b) Prove: If A has a lower bound, then LB(A) = LB(UB(LB(A))).
(c) Prove: If A has a lower bound, then LB(A) ∪UB(LB(A)) = ℚ.
(d) Prove: If A has a lower bound, then LB(A) ∩UB(LB(A)) may be
empty or may have one element, but it will not have 2 or more.
(e) Prove: If A has an upper bound, then A ⊆LB(UB(A)), but they need
not be equal.

280
14 ℕ, ℤ, and ℚ
(f) Prove: If A has an upper bound, then UB(A) = UB(LB(UB(A))).
(g) Prove: If A has an upper bound, then UB(A) ∪LB(UB(A)) = ℚ.
(h) Prove: If A has an upper bound, then UB(A) ∩LB(UB(A)) may be
empty or may have one element, but it will not have 2 or more.
14.7
State the Division Algorithm for ℤ. Be sure that your requirements for
the remainder are precise.
14.8
Why do we not deﬁne “odd” and “even” rational numbers?

281
15
Ordered Fields and the Real Numbers
15.1
Ordered ﬁelds
Deﬁnitions and easy consequences
We start right out with a deﬁnition that includes all the algebraic properties
that we want.
Deﬁnition 15.1.1.
An ordered ﬁeld is a set F that has the following properties:
1. F has a total order.
2. There is a binary operation a + b on F.
3. Addition is associative.
4. Addition is commutative.
5. There is an additive identity in F. (It is unique, and we will denote it as 0.)
6. If a ∈F, then a has an additive inverse. (It is unique to a, and we will denote
it as −a).
7. If a, b, c ∈F and a < b, then a + c < b + c.
8. There is a binary operation a ⋅b on F.
9. Multiplication is associative.
10. Multiplication is commutative.
11. There is a multiplicative identity in F. (It is unique, and we will denote it
as 1.)
12. If a ∈F and a ≠0, then a has a multiplicative inverse. (It is unique to a,
and we will denote it as a−1.)
13. If a, b, c ∈F and a < b and 0 < c, then a ⋅c < b ⋅c.
14. Multiplication distributes over addition.
15. 0 ≠1.
We have seen so many of these properties before that we can write down
several more that follow from them without much fuss.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

282
15 Ordered Fields and the Real Numbers
Theorem 15.1.2.
Let a, b, c ∈F, an ordered ﬁeld.
1. a ⋅0 = 0 ⋅a = 0.
2. −(−a) = a.
3. −a = (−1) ⋅a.
4. −(a + b) = (−a) + (−b).
5. −(ab) = (−a)b = a(−b).
6. If a ≠0, then (a−1)−1 = a.
7. (ab)−1 = b−1a−1.
8. If a < b and c < 0, then ac > bc.
9. If a ≠0, then a2 > 0.
We anticipated this deﬁnition in the last section, and the 16 claims proved
about ℚhave collectively proved the following theorem:
Theorem 15.1.3.
The rational numbers ℚform an ordered ﬁeld.
Next we state (but not bother to prove) a rather strange looking theorem, but
it is the basis for our claim that the rational numbers form the smallest ordered
ﬁeld. We will not go through the lengthy proof, which does not really add much
information about what is going on.
Theorem 15.1.4.
Let F be an ordered ﬁeld. Let
N =
{ n
∑
k=1
1 ∣n ∈ℕ
}
.
(15.1)
Then N has all of the properties of the natural numbers ℕ. We identify ℕwith
N ⊆F.
Corollary 15.1.5.
Let F be an ordered ﬁeld. Then F contains a subset that has
all the properties of ℤ. We identify it with ℤ.
Of course, this is ℕ∪{0} ∪{ −n ∣n ∈ℕ}. Let F be an ordered ﬁeld. Then
consider
Q = {nm−1 ∣m ∈ℤand m ∈ℕ}.
(15.2)
We have:
Corollary 15.1.6.
Let F be an ordered ﬁeld. Then F contains a subset that is
essentially the rational numbers. We identify it with ℚ.
This set acts exactly as ℚ. We will identify it as such and write ℚ⊆F. After
these identiﬁcations, we have ℕ⊆ℤ⊆ℚ⊆F for any ordered ﬁeld F. So yes,

15.1 Ordered Fields
283
viewing the subset relation as an order, ℚis the “minimum” ordered ﬁeld.
This also gives us an alternate notation for inverses, a−1 = 1
a that works in any
ordered ﬁeld. This generalizes to a notation for division by nonzero things,
ba−1 = b
a.
More properties of ordered ﬁelds
There are two properties of ordered ﬁelds that come in handy at times. Because
they are proved using the deﬁnition of an ordered ﬁeld, they can be applied to
ℚor ℝor any other ordered ﬁeld we might be interested in.
Theorem 15.1.7.
Let a, r ∈F, an ordered ﬁeld, and let r ≥0. For all x ∈F,
1. |x −a| ≤r if and only if a −r ≤x ≤a + r;
2. |x −a| < r if and only if a −r < x < a + r.
Proof. We will just prove statement 1.
(⇒). We claim that if |x −a| ≤r then a −r ≤x ≤a + r.
Proof of claim. Assume |x −a| ≤r. Then −|x −a| ≥−r. And so
−r ≤−|x −a| ≤x −a ≤|x −a| ≤r.
(15.3)
So −r ≤x −a ≤r. So a −r ≤x ≤a + r.
◾
(⇐). We claim that if a −r ≤x ≤a + r then |x −a| ≤r.
Proof of claim. Assume a −r ≤x ≤a + r. Then −r ≤x −a ≤r. So multiplying
all sides by −1, we get −r ≤a −x ≤r. So −r ≤±(x −a) ≤r. So |x −a| ≤r. ◾
◽
Corollary 15.1.8.
In ℝ,
{x ∈ℝ∣|x −a| < r} = (a −r, a + r).
(15.4)
Theorem 15.1.9
(The Triangle Inequality). Let a, b ∈F an ordered ﬁeld.
Then
|a + b| ≤|a| + |b|.
(15.5)
Proof. Assume a, b ∈F. Then
−|a| ≤a ≤|a|;
(15.6)
−|b| ≤b ≤|b|.
Adding these, we get
−(|a| + |b|) ≤(a + b) ≤(|a| + |b|).
(15.7)

284
15 Ordered Fields and the Real Numbers
By the previous theorem,
|a + b| ≤|a| + |b|.
(15.8)
◽
The next theorem also holds for any ordered ﬁeld; its contrapositive is
particularly useful in the real numbers. All it does is guarantee that, between
any two elements of the ﬁeld, there is another. There is nothing special about
the element it guarantees exists, and there are plenty of numbers it could be.
However, there is one that is easy to remember and calculate - the average, and
that is how we tend to remember the theorem. There are two theorems about
the real numbers that mirror this theorem, but they identify the number in the
middle as a member of a speciﬁc subset of ℝ. Those are both pretty powerful
results when you need numbers of those particular types. In most proofs about
the real numbers, any old real number between two numbers will do. In that
case, it is best to just use the average. Notice that this theorem is almost the
direct opposite of the property of ℕand ℤthat said, if n ≤m ≤n + 1, then
either n = m or m = n + 1.
Theorem 15.1.10
(The Average Theorem). Let a, b ∈F be an ordered ﬁeld.
If a < b, then there exists c ∈F with a < c < b.
Proof. Assume a < b. Then 2a < a + b and a + b < 2b. So 2a < a + b < 2b.
And since 2 has an inverse, a < a+b
2
< b. We now have the element of F that
we want.
◽
Corollary 15.1.11.
Let a ∈F be an ordered ﬁeld with a ≥0. If ∀𝜀> 0, a < 𝜀,
then a = 0.
15.2
The real numbers
Deﬁnition
Now that we have all the terminology, the deﬁnition of the real numbers is
pretty easy to state.
Deﬁnition 15.2.1.
The real numbers ℝform a complete ordered ﬁeld.
Of course, this means that ℝis an ordered ﬁeld that satisﬁes the completeness
axiom:
The completeness axiom. If S ⊆ℝand S ≠∅and S is bounded below, then S
has an inﬁmum in ℝ.

15.2 The Real Numbers
285
We proved that any ordered set U that is complete also satisﬁes the alternate
completeness axiom:
The alternate completeness axiom. If S ⊆ℝand S ≠∅and S is bounded
above, then S has a supremum in ℝ.
Properties of ℝ
The ﬁrst theorem we prove about ℝdoes not seem like much, but it appears
in all sorts of proofs of theorems about the real numbers. The second theorem
seems more interesting; perhaps because it is, but it tends to mostly be used
to provide examples in early analysis studies. Recall that every ordered ﬁeld
contains the sets ℕ⊆ℤ⊆ℚthat use the exact same arithmetic operations as
ℝ. So we can state:
Theorem 15.2.2
(The Archimedean Principle). If r ∈ℝ, then there exists
an n ∈ℕsuch that r < n.
Proof draft. This theorem is often stated in the form of the logically equivalent
statement: As a subset of ℝ, ℕis not bounded above.
Comment: Let us see why this is the logical equivalent. The statement
If r ∈ℝ, then ∃n ∈ℕsuch that r < n
can be rephrased as
∀r ∈ℝ, ∃n ∈ℕsuch that r < n.
The negation is
∼(∀r ∈ℝ, ∃n ∈ℕsuch that r < n)
∃r ∈ℝsuch that ∼(∃n ∈ℕsuch that r < n)
∃r ∈ℝsuch that ∀n ∈ℕ, ∼(r < n)
∃r ∈ℝsuch that ∀n ∈ℕ, r ≥n.
That is to say, “There is an upper bound on ℕin ℝ.” So the statement in the
theorem is logically equivalent to “There is no upper bound on ℕin ℝ.”
Assume BWOC that ℕis bounded above.
Comment: We could pick one upper bound and name it, but we really should
take the best possible upper bound if one is available to us.
By completeness, ℕhas a supremum in ℝ. Let s = Sup(ℕ). Then
1. if n ∈ℕ, then n ≤s;
2. if l < s, then ∃n ∈ℕsuch that l < n.
Consider s −1.

286
15 Ordered Fields and the Real Numbers
Comment: Be warned, subtracting 1 to use with a supremum only works here
and almost never anywhere else.
Then s −1 < s. So by the deﬁnition of the supremum, ∃n ∈ℕsuch that
s −1 < n. But then s < n + 1. Since n ∈ℕ, n + 1 ∈ℕ. But s = Sup(ℕ); so
n + 1 ≤s. Putting these together, n + 1 ≤s < n + 1, we get a contradiction. Δ
This deserves to be rewritten.
Proof. We will prove: ℕis not bounded above in ℝ.
Assume BWOC that ℕis bounded above.
By completeness, ℕhas a supremum in ℝ. Let s = Sup(ℕ). Then if n ∈ℕ, then
n ≤s. And if l < s, then ∃n ∈ℕsuch that l < n.
Consider s −1. Then s −1 < s. So by the deﬁnition of the supremum, ∃n ∈ℕ
such that s −1 < n. But then s < n + 1. Since n ∈ℕ, n + 1 ∈ℕ. But s = Sup(ℕ);
so n + 1 ≤s.
Putting these together, n + 1 ≤s < n + 1; so we get a contradiction.
◽
Corollary 15.2.3.
If r ∈ℝ, then ∃m ∈ℤsuch that m < r.
Proof. Assume r ∈ℝ. Then −r ∈ℝ; so by Archimedes, ∃n ∈ℕs.t −r < n. Then
r > −n ∈ℤ.
◽
The next theorem is a step up beyond the average theorem. Using the
identiﬁcation that makes ℚ⊆ℝ, this theorem guarantees that between any
two real numbers, there is a rational number. We already know that there is
a real number between them. If they are both rational, then the average is
rational, but this says nothing new in that case. However, if we start with any
two real numbers, rational, not rational, or we have no idea, there is still a
rational number between them. No intervals in ℝ, no matter how small, are
made up of nothing but irrational numbers.
Theorem 15.2.4
(The Density Theorem). If a, b ∈ℝand a < b, then there
exists r ∈ℚso that a < r < b.
Proof. First, we make a claim
Claim. If a + 1 < b, then there exists m ∈ℤwith a < m < b.
Proof of claim. Assume a + 1 < b. Let
S = {k ∈ℤ∣a < k}.
(15.9)
Now by the Archimedean principle, S ≠∅. It also tells us that ∃l ∈ℤsuch that
l < a. Thus, S is a nonempty subset of ℤbounded below in ℤ. By the properties

15.2 The Real Numbers
287
of ℤit has a minimum. Let m = Min(S). Then m ∈S, and so a < m. Also if
k ∈S, m ≤k. But m −1 < m = Min(S). So m −1 ∉S. This means m −1 ≤a.
Or equivalently, m ≤a + 1. So we have m ∈ℤsuch that a < m ≤a + 1 < b. ◾
The theorem follows from this claim. Assume now that a < b. Then
b −a > 0. So
1
b−a ∈ℝ. By the Archimedean principle, ∃n ∈ℕ, such that
1
b−a < n. So 1 < n(b −a). Then na + 1 < nb. If we apply the claim to the
numbers na and nb, we ﬁnd ∃m ∈ℤwith na < m < nb. Thus, a < m
n < b with
m ∈ℤand n ∈ℕ. So m
n ∈ℚﬁts the requirement we need.
◽
Decimals and real numbers
In school, we learned that real numbers were the numbers that were rep-
resented by possibly inﬁnite decimals. Thus, 7 = 7.0 is a real number. Also
3
4 = 0.75 ∈ℝbecause 0.75 =
75
100 is a rational number and therefore automati-
cally real. Now our calculator hinted that 1
3 = 0.333333 …. This takes a bit more
faith to believe, but if any inﬁnite decimal is a real number, then we can name
𝛼= 0.33333 …. If inﬁnite arithmetic works the same way ﬁnite arithmetic
works, then 10𝛼= 3.3333 …. So 10𝛼= 3 + 𝛼. So by algebra 𝛼= 3
9 = 1
3. There
are two rather major “if’s” in here: “if any inﬁnite decimal is a real number”
and “if inﬁnite arithmetic works the same way ﬁnite arithmetic works.” These
certainly seem plausible, but anything involving the inﬁnite needs to be more
than just plausible before we can depend on it.
Consider the real number 𝜋. Everyone knows 𝜋= 3.14159 …. But this time
the ellipsis has a very diﬀerent meaning. This time the digits do not proceed
in a pattern. In fact, someone who knows some Mathematics might well say,
“𝜋= 3.14159 … and the digits go on forever without a pattern.” So if a real
number is given as an inﬁnite decimal, has anyone ever given us 𝜋? We simply
cannot rely on inﬁnite arithmetic. But what if someone claims to have a formula
for 𝜋, 𝜋2, or 𝜋3? Say
𝜋=
∞
∑
k=1
(−1)k4
2k + 1 .
(15.10)
𝜋2 =
∞
∑
k=1
6
k2 .
𝜋3 = 87059
8879
√
10.
Inﬁnite arithmetic would be of little use in proving any of these. A very accurate
calculator might be enough to disprove one or to mistakenly prove another.
We know better than to think that the way to prove things about the real
numbers is from their decimal expansions. The workable deﬁnition of the real
numbers is not given using decimal expansions, but algebraically as members of

288
15 Ordered Fields and the Real Numbers
a complete ordered ﬁeld. Using our deﬁnition, however, we can talk about inﬁ-
nite decimal expansions of real numbers. We will not be able to overcome the
problem of giving complete decimal expansions when the digits have no pat-
tern. But we can describe the idea of approximating real numbers with ﬁnitely
many digits as closely as you want.
Thus 1
3 = 0.333333 … means 1
3 = Sup(A) where
A = {0.3, 0.33, 0.333, 0.3333 …}.
(15.11)
Every inﬁnite decimal expansion with a pattern in the digits is the supremum
of a well-deﬁned set. It is a real number. If we have an irrational number, but
one with a strong enough pattern in the decimals such as
0.123456789 10 11 12 13 14 15 16 …
(15.12)
we can see that it is real by pointing out that it is Sup(B) where
B =
{ 1
10, 12
100, 123
1000, 1234
1000, …
}
(15.13)
(although the numbers in this version of the set are not enough to illustrate the
pattern without the decimal expansion earlier).
The reverse works just as well. Suppose that we have identiﬁed 𝛼as a real
number. Say, for example, 𝛼= Inf(S) where
S = {x ∈ℝ∣2 < x2}.
(15.14)
Then 100 ⋅𝛼and 100 ⋅𝛼+ 1 ∈ℝ. By the claim in the proof of the density
theorem, there is an integer n ∈ℕwith 100 ⋅𝛼≤n < 100 ⋅𝛼+ 1. Then
n
100 is a
two-digit approximation of 𝛼. If we need n digits, we look at 10n ⋅𝛼. Every real
number has a decimal expansion even if we cannot guarantee that there is a
pattern to those digits.
Of the three proposed formula for 𝜋earlier, only the ﬁrst two are correct.
Now
P =
{
x ∈ℚ∣∃n ∈ℕs.t. x =
2n−1
∑
k=1
(−1)k4
2k + 1
}
(15.15)
can be proved to be nonempty and bounded above. Thus, it will have a real
number as its supremum. Although a proof requires calculus, this can be used
to deﬁne 𝜋because
Tan−1(1) = 𝜋
4 .
(15.16)
Now
Q =
{
x ∈ℚ∣∃n ∈ℕsuch that x =
n
∑
k=1
6
k2
}
(15.17)

15.3 Problems
289
can also be proved to be nonempty and have an upper bound. It also will have a
real number as the supremum. In this course, we are setting up the properties
of ℝand the proof techniques that (if we take enough more Mathematics) will
allow us to prove
Sup(Q) = (Sup(P))2.
(15.18)
15.3
Problems
15.1
Let a, b, c ∈F, an ordered ﬁeld. Prove each of the following:
(a) a ⋅0 = 0 ⋅a = 0.
(b) −(−a) = a.
(c) −a = (−1) ⋅a.
(d) −(a + b) = (−a) + (−b).
(e) −(ab) = (−a)b = a(−b).
(f) If a ≠0, then (a−1)−1 = a.
(g) (ab)−1 = b−1a−1.
(h) If a < b and c < 0, then ac > bc.
(i) If a ≠0, then a2 > 0.
15.2
We stated a corollary to a theorem as
In ℝ, {x ∈ℝ∣|x −a| < r} = (a −r, a + r).
(15.19)
Why is this not true in any ordered ﬁeld?
15.3
Let F be any ordered ﬁeld. Prove:
(a) If x > 1, then for all n ∈ℕwith n > 1, x < xn.
(b) If 0 < x < 1, then for all n ∈ℕwith n > 1, xn < x.
15.4
Let a, b ∈ℝso that a < b. Prove that ∃s ∉ℚwith a < s < b.
15.5
Let A = {x ∈ℝ∣∃n ∈ℕs.t. x = n+1
n }. Prove that 1 = Inf(A).
15.6
Let A = {x ∈ℝ∣∃n ∈ℕs.t. x = 10−n}. Prove 0 = Inf(A).
15.7
Notice how the mathematics in the next two proofs is basically the same
but the logic is quite diﬀerent.
(a) Prove
⋃
n∈ℕ
( 1
n2 , 1
]
= (0, 1].
(15.20)
(b) Prove
⋂
n∈ℕ
(
−1
n2 , 1
]
= [0, 1].
(15.21)

290
15 Ordered Fields and the Real Numbers
15.8
Use part (a) to prove part (b) in the following:
(a) Prove that If x ∈ℝwith x ≥0 such that ∀𝜀> 0, x ≤𝜀, then x = 0.
(b) Let 𝛼= 0.499999 … and 𝛽= 0.5. Prove that 𝛼= 𝛽. Hint: if
an = 0.499999 … 9 with (n −1) 9’s, then it can be expressed exactly
as a ratio of integers and an ∈ℚand an < 𝛼. You should actually
ﬁnd this expression for an by doing small examples and looking for
a pattern.
15.9
Prove the following:
(a) For all n ∈ℕ,
2n
2n−1 ⋅
2n
2n+1 < 1.
(b) For all n ∈ℕ,
2n
2n+1 ⋅2n+2
2n−1 > 1.
(c) Prove that the set
{ n
∏
k=1
(
2k
2k −1 ⋅
2k
2k + 1
)
∣n ∈ℕ
}
(15.22)
=
{(2
1 ⋅2
3
)
,
(2
1 ⋅2
3
) (4
3 ⋅4
5
)
,
(2
1 ⋅2
3
) (4
3 ⋅4
5
) (6
5 ⋅6
7
)
, …
}
has an inﬁmum.
(d) Look up “John Wallis’ product” and explain why the aforementioned
can lead to a complete inﬁnite description of the real number 𝜋.
(e) Use the Taylor expansion of ArcTan(x) and its value at x = 1 to ﬁnd
another set that gives a complete inﬁnite description of the real num-
ber 𝜋similar to the one earlier.
15.4
Epilogue
15.4.1
Constructing the real numbers
We have deﬁned the real numbers as the elements of a complete ordered
ﬁeld. But how do we know that such an ordered ﬁeld exists? There are two
popular ways to construct the real numbers from the rational numbers: using
equivalence classes of Cauchy sequences or using Dedekind cuts. Certainly,
diﬀerent constructions lead to diﬀerent versions of the real numbers. As long
as we use the properties of our numbers as we work with ℝ, and not the actual
construction of ℝ, we will not be able to tell the two versions of ℝapart. So
we consider both versions as the same real numbers by identifying them as the
same set. It is just a matter of understanding what our deﬁnition of “is” is.
Cauchy sequences are useful and interesting in their own right, and so they
are a very popular way to get to the real numbers in undergraduate courses.
We can also study the properties of Cauchy sequences as theorems about the
real numbers and not as part of the construction of ℝ. If we continue our study
of real analysis further, there is a good chance that we will see an equivalent

15.4 Epilogue
291
version of the completeness axiom designed to work precisely with Cauchy
sequences.
Dedekind cuts are less practical (actually totally impractical), and they are
rarely seen by undergraduate students except to construct ℝ. However, they
ﬁt our deﬁnition of “complete” better. Both constructions appear in diﬀerent
contexts in other parts of Mathematics; so it is basically a tie over which is the
better approach. In the end, it does not really matter what the real numbers
actually are. Once we know that they exist, all that matters are their properties.
We will outline the construction of the real numbers using Dedekind cuts,
but give very little in terms of the proofs of our claims.
Let A ⊆ℚ. Deﬁne
LB(A) = {x ∈ℚ∣x is a lower bound of A};
UB(A) = {x ∈ℚ∣x is an upper bound of A}.
If A, B ⊆ℚ, then deﬁne
A + B = {a + b ∈ℚ∣a ∈A and b ∈B};
(15.23)
A ⋅B = {ab ∈ℚ∣a ∈A and b ∈B}.
Deﬁnition: A Dedekind cut is a pair of nonempty subsets of ℚ, (L, U), such
that L = LB(U) and U = UB(L). As it turns out, if (L, U) is a Dedekind cut,
L ∪U = ℚand |L ∩U| ≤1.
Claim: If A has a lower bound, then LB(A) and UB(LB(A)) form a
Dedekind cut.
Claim: If A has an upper bound, then LB(UB(A)) and UB(A) form a
Dedekind cut.
Let
ℝC = {(L, B) ∣(L, B) is a Dedekind cut}.
(15.24)
We deﬁne an order, an addition, and a multiplication on ℝC.
Deﬁnition: We say (L, B) ≤(L′, B′) if L ⊆L′.
Deﬁnition: Let (L, B), (L′, B′) ∈ℝC. It turns out that L + L′ has an upper
bound. We turn it into a Dedekind cut using the aforementioned claim and get
(L′′, U′′). Then (L, B) + (L′, B′) = (L′′, U′′).
Deﬁnition: Let (L, B), (L′, B′) ∈ℝC. Now for each pair, 0 is in one of the two
sets L or B. (Just choose one if it is in both.) Choose the other set from each
pair, O and O′. It turns out that O ⋅O′ will either be bounded above or bounded
below. Either way, we turn it into a Dedekind cut using the appropriate
aforementioned claim and get (L′′, U′′). Then (L, B) ⋅(L′, B′) = (L′′, U′′).
As we predicted, all this is completely impractical, but perfectly deﬁned
nonetheless.
Claim: ℝC forms a complete ordered ﬁeld.
The proof of this is long. Still some parts are very easy: the order on ℝC
is transitive, it satisﬁes trichotomy, addition is associative and commutative.

292
15 Ordered Fields and the Real Numbers
Other parts are horribly tedious: multiplication is associative, and the
distributive rule. Surprisingly, the most frightening one is actually rather easy:
ℝC is complete.
Let S ⊆ℝC. We can think of the lower parts of the elements of S as a family
of subsets of ℚindexed by the elements of S: Li with i ∈S. The condition that S
be bounded means that there is a Dedekind cut (M, P) so that ∀i ∈S, Li ⊆M.
Then (
⋃
i∈S
Li
)
⊆M.
(15.25)
So every element of P is an upper bound of that union. When we use the lemma
to turn the union into a Dedekind cut (L′, U′), it is easy to see that the result is
an element of ℝC that serves as a least upper bound of S.

293
16
Topology
16.1
Introduction
16.1.1
Preliminaries
Let A ⊆ℝ. The deﬁnition of a subset gives a pretty black and white classi-
ﬁcation of real numbers in relation to the set A. For x ∈ℝ, either x ∈A or
x ∉A, and no real number x is both. This partitions ℝinto two disjoint pieces,
A and ℝ∖A. This is nothing new, but it does oﬀer a simple template for what
is to follow. We will point this out rather emphatically by stating an almost silly
theorem that needs absolutely no proof:
Theorem 16.1.1
(The Zeroth Partition Theorem). If A ⊆ℝ, then
A ∪(ℝ∖A) = ℝ;
(16.1)
A ∩(ℝ∖A) = ∅.
We follow this with another theorem about the parts of this partition of the
real numbers that is just as simple, but it will come in handy as we introduce
more complicated partitions.
Theorem 16.1.2.
Let A ⊆ℝ, and B ⊆ℝ. Then
1. B ⊆(ℝ∖A) if and only if A ∩B = ∅;
2. ℝ∖(ℝ∖A) = A;
3. A ⊆B implies (ℝ∖B) ⊆(ℝ∖A).
We will set a very loose and informal description of our ﬁrst more reﬁned
partition of the real numbers using a set A ⊆ℝ. These ideas are more geomet-
ric than numeric; so instead of talking about numbers in ℝ, we will talk about
points on the real line. We will start with the interior of the set A. The interior
will be the set of points not just in A, but really inside A. (We said “a loose dis-
cussion.”) The exterior of A will be the points in ℝthat are not in A, and in fact,
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

294
16 Topology
really outside A. The remaining points in ℝmay be in A; they may not be in A;
they are not really committed either way. The points not really in and not really
out are on the edge. They form the boundary of A.
This ﬁrst partition is set up using a model set of the form (3, 8]. Certainly,
6 should be in the interior of this set because it is smack dab inside. In addi-
tion, 112 should be in the exterior because it is really outside (3, 8]. If boundary
means what it should, 3 should be in the boundary as should 8. It should not
matter that 3 ∉(3, 8], and 8 ∈(3, 8]. The boundary should be made up of both.
Once we have formal deﬁnitions of these sets, we will prove that the interior,
the exterior, and the boundary of A partition all of ℝ. This will be “the ﬁrst
partition theorem.”
The second partition is more social than geometric. This time we think of a set
as a club where members always talk about the club (i.e., Boston Red Sox fans).
Some people are simply not in the club, and no one around them is in either.
They are in the exterior of the club if there is a group around them where no
one talks positively about the club (the locker room of Yankee Stadium). This is
the same exterior that appeared in the ﬁrst partition. Once you are really out,
then you are always really out.
There are always some people on the membership list of the club that are
isolated from the rest of the members. (For example, unfortunate Red Sox fans
who live in NYC.) They are in at least one social group where they are the only
club members. Once their neighborhood is small enough, they will have no one
to talk to about the club in that neighborhood. These isolated members are easy
to spot because they stick out like sore thumbs in the right sized neighborhood.
The second set in our partition will be made up of these isolated members.
But then who is left for a third part of the partition? The remaining people
may be in the club or not, but they have no way of avoiding members of the club.
Because they are not exterior and they are not isolated, every neighborhood
they are in, no matter how small, has members of the club. If they are in the
club, all their neighborhoods have another member of the club for them to talk
to about it. If they are not in the club, then all their neighborhoods will have a
member of the club who insists on talking about it. (For example, anyone living
in Boston proper, even if they love the Sox, hate the Sox, or simply do not care
about baseball.) This ﬁnal group are those in and out of the club who just cannot
avoid club members. They are people around whom the club members always
accumulate.
This second partition is set up using a model set of the form
A =
{
x ∈ℝ∣∃n ∈ℕs.t. x = 1
n
}
.
(16.2)
We have seen this example before, and as before, we should draw a picture
of this set on the real line. Starting with n = 1, 2, 3, we put down dots for 1
n.
See Figure 16.1.

16.1 Introduction
295
Figure 16.1 x = 1
n.
1
1
5
1
4
1
3
1
2
0
Each dot is separated from the previous one, but the separation is getting
smaller and smaller, eventually too small to keep drawing. This is the kind of
set that the second partition is designed for. All the points of A are separated
from the other points of A. Even though the separation is getting smaller and
smaller forever, at any speciﬁc point, the separation is still there. We eventually
have to magnify our drawing to see it, but numerically
1
10347 is between
1
10348 and
1
10346, and no other points of A7 are in that gap. All the points of A are isolated.
Are there any points where A accumulates? If that has anything to do with the
English meaning of the word, the set should accumulate at 0. That should be
the only one. Everything else is exterior. Any point not in A ∪{0) is far enough
away from the points of A to be really out zoomed into the right scale.
Once we have formal deﬁnitions of these sets, we will prove that the isolated
points, the exterior points, and the accumulation points of A partition all of ℝ.
This will be “the second partition theorem.” These two partitions will provide
two distinct views of the original set A.
16.1.2
Neighborhoods
There is one relation between people that works quite well when applied to
the real numbers, but not as a mathematical relation. The idea behind this is
the notion of a neighbor. We can deﬁne a relation on the set of all people by
saying that p is related to q if p is a neighbor of q. Most relations are useless
unless they have nice properties. Unfortunately, this particular relation does
not satisfy the mathematical property we like best: transitivity. We turn our
attention away from the relation “is a neighbor” and toward the set of people
called a neighborhood.
If a person is sitting in a cafe in Paris having a conversation with a stranger and
the stranger asks where they are from, they might answer, “the United States.”
A good answer, but a rather large neighborhood to use to identify oneself. That
same person in a hotel lobby in Chicago might recognize that the stranger has
already realized that they are from the United States. This time the answer
might be “Philadelphia” or “Tucson.” The smaller neighborhood better serves
its purpose. It is still a rather vague answer; the Philadelphia answer might mean
that the person was actually from southern New Jersey, across the river and
in another state from Philadelphia. If this conversation was taking place in a
plane headed toward Tucson, Arizona, a more speciﬁc answer might be “Sam
Hughes,” “Summer Haven,” or “El Rio.” These are more traditional uses of the
term “neighborhood.” There is no real limit to this; two residents of the same

296
16 Topology
high-rise might identify themselves as neighbors because they live on the same
ﬂoor. The advantage of the concept of neighborhood is its ﬂexibility of size. It
is only as small as it needs to be, but when it needs to be, it can be as tiny as
necessary.
We will make this idea mathematical by giving a precise deﬁnition to the
mathematical term neighborhood.
Deﬁnition 16.1.3.
Let a ∈ℝ. Let 𝜀> 0. The 𝜀-neighborhood of a is deﬁned
to be
N(a, 𝜀) = {x ∈ℝ∣|x −a| < 𝜀}.
(16.3)
We can also write this as
N(a, 𝜀) = (a −𝜀, a + 𝜀).
(16.4)
Thus a number a ∈ℝhas many, many neighborhoods. It has a neighborhood
for each 𝜀> 0; the smaller the 𝜀, the smaller the neighborhood. When we need
one, an 𝜀-neighborhood of a needs only to be as small as necessary for our pur-
pose, but it can usually be replaced by an even smaller one if that is convenient.
For reasons that will become clear later, we also want to deﬁne a punctured
or deleted neighborhood.
Deﬁnition 16.1.4.
Let a ∈ℝ. Let 𝜀> 0. The deleted 𝜀-neighborhood of a is
deﬁned to be
N∗(a, 𝜀) = N(a, 𝜀) ∖{a}
(16.5)
= (a −𝜀, a) ∪(a, a + 𝜀).
Now we want all our neighborhoods, deleted or not, to be nonempty. For that
reason, the main duty of the radius 𝜀is to be a positive real number.
We have a few quick results about these neighborhoods that we will use quite
a bit.
Theorem 16.1.5.
Let a ∈ℝ. Let 0 < 𝜀1< 𝜀2. Then
N(a, 𝜀1) ⊆N(a, 𝜀2);
(16.6)
N∗(a, 𝜀1) ⊆N∗(a, 𝜀2).
Proof. Assume 0 < 𝜀1< 𝜀2.
Comment: What are we proving? One set is a subset of the other. As an “if…
then,” this is “if x is in one set, then x is in the other.”

16.1 Introduction
297
Assume x ∈N(a, 𝜀1). Then |x −a|< 𝜀1< 𝜀2. So x ∈N(a, 𝜀2). Thus, N(a, 𝜀1) ⊆
N(a, 𝜀2). The proof is the same to show that N∗(a, 𝜀1) ⊆N∗(a, 𝜀2); we just need
to add the assumption that x ≠a, and this does not aﬀect the proof.
◽
Corollary 16.1.6.
Let a ∈ℝ. If 𝜀1 > 0 and 𝜀2 > 0. Then
N(a, 𝜀1) ∩N(a, 𝜀2) = N(a, 𝜀3)
(16.7)
where 𝜀3 = Min({𝜀1, 𝜀2}).
Proof. Assume 𝜀1 > 0 and 𝜀2 > 0. Let 𝜀3 = Min({𝜀1, 𝜀2}). Then 𝜀3 ∈{𝜀1, 𝜀2};
so 𝜀3 > 0.
Comment: Remember that being positive is epsilon’s main job; we always need
to be sure it ﬁlls the requirement.
Since we are proving a set equality, we must show that N(a, 𝜀1) ∩N(a, 𝜀2) ⊆
N(a, 𝜀3) and that N(a, 𝜀1) ∩N(a, 𝜀2) ⊇N(a, 𝜀3).
Claim. N(a, 𝜀1) ∩N(a, 𝜀2) ⊇N(a, 𝜀3).
Proof of claim. We have 𝜀3 ≤𝜀1 and 𝜀3 ≤𝜀2. So by Theorem 16.1.5,
N(a, 𝜀3) ⊆N(a, 𝜀1);
(16.8)
N(a, 𝜀3) ⊆N(a, 𝜀2).
So
N(a, 𝜀3) ⊆N(a, 𝜀1) ∩N(a, 𝜀2).
(16.9)
◾
Claim. N(a, 𝜀1) ∩N(a, 𝜀2) ⊆N(a, 𝜀3).
Proof
of
claim. Assume
x ∈N(a, 𝜀1) ∩N(a, 𝜀2).
Then
|x −a| < 𝜀1
and
|x −a| < 𝜀2. So |x −a| < Min({𝜀1, 𝜀2}) = 𝜀3. So x ∈N(a, 𝜀3).
◾
We have now proved both N(a, 𝜀1) ∩N(a, 𝜀2) ⊆N(a, 𝜀3) and N(a, 𝜀1) ∩
N(a, 𝜀2) ⊇N(a, 𝜀3). It follows that N(a, 𝜀1) ∩N(a, 𝜀2) = N(a, 𝜀3).
◽
As it turns out, 𝜀-neighborhoods are just open intervals that are identiﬁed by
their center and radius, instead of their ends. Thus,
Theorem 16.1.7.
Let a, b ∈ℝand 𝜖> 0. Then
1. N(a, 𝜀) = (a −𝜀, a + 𝜀).
2. If a < b, then (a, b) = N
(
a+b
2 , b−a
2
)
.

298
16 Topology
Proof. Part 1 was seen already as Corollary 15.1.8. Here we will prove part 2.
Assume that a < b. We are asked to prove a set equality, so we must prove that
the subset holds in both directions.
Claim. (a, b) ⊆N
(
a+b
2 , b−a
2
)
.
Proof of claim. Assume x ∈(a, b). Then a < x < b. So
x −a + b
2
> a −a + b
2
= a −b
2
= −
(
b −a
2
)
;
(16.10)
x −a + b
2
< b −a + b
2
= b −a
2
.
Then since b−a
2
> 0,
±
(
x −a + b
2
)
< b −a
2
;
(16.11)
||||
x −a + b
2
||||
< b −a
2
.
So x ∈N
(
a+b
2 , b−a
2
)
.
◾
Claim. (a, b) ⊇N
(
a+b
2 , b−a
2
)
.
Proof of claim. Assume x ∈N
(
a+b
2 , b−a
2
)
. Then
x ∈
(
a + b
2
−b −a
2
, a + b
2
+ b −a
2
)
(16.12)
∈(a, b).
◾
We have now proved that the subset holds in both directions. Thus, (a, b) =
N
(
a+b
2 , b−a
2
)
.
◽
16.1.3
Interior, exterior, and boundary
We can use these neighborhood sets to ﬁnally give formal deﬁnitions of the
interior, the exterior, and the boundary of a set A.
We have already said that these ideas are more geometric than numeric. It
might be helpful to have a picture of the real line to guide us through these
deﬁnitions.
Deﬁnition 16.1.8.
Let A ⊆ℝ. The interior of A is given by
Int(A) = {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ⊆A}.
(16.13)

16.1 Introduction
299
The interior points of A are those points really inside of A. Not only are
they in A, but an entire neighborhood around them is in A. It may be a big
neighborhood (such as Philadelphia) or a small neighborhood (such as a
high-rise ﬂoor). But we get to say that x ∈Int(A) because not only does it
belong, but all of its neighbors belong as well. By deﬁnition, if x ∈Int(A),
then ∃𝜀> 0 s.t. N(x, 𝜀) ⊆A. But because there is no star, we always have
x ∈N(x, 𝜀). So Int(A) ⊆A, and that certainly is something we want to be
true.
Another thing to note is that once we have x ∈Int(A), we have an 𝜀0 > 0
so that N(x, 𝜀0) ⊆A. But because of the way neighborhoods work, this
𝜀0-neighborhood is not unique. We know for sure that every smaller neigh-
borhood will also work: If 𝜀1< 𝜀0, then N(x, 𝜀1) ⊆N(x, 𝜀0) ⊆A. But also there
is nothing in the deﬁnition that requires that the ﬁrst 𝜀0 we identify be even
close to optimal in size. So there could just as well be there is an 𝜀2> 𝜀0 where
it still happens that N(x, 𝜀2) ⊆A.
Deﬁnition 16.1.9.
Let A ⊆ℝ. The exterior of A is given by
Ext(A) = {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ⊆(ℝ∖A)}.
(16.14)
The exterior points of A are those points really outside of A. Not only are
they outside of A, but an entire neighborhood around them is outside of A.
This time Ext(A) ∩A = ∅. So sure enough, no points that are in A ever end up
in the exterior.
Now it seems clear that the “zeroth” partition A and ℝ∖A is going to play a
large part in our discussion. Because of the properties listed after this simple
partition, we can also write
Int(A) = {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ∩(ℝ∖A) = ∅}
= {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ⊆A}.
(16.15)
Ext(A) = {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ∩A = ∅}
= {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ⊆(ℝ∖A)}.
(16.16)
We also notice that
Ext(A) = Int(ℝ∖A).
(16.17)
Now points that are between “really in” and “really out” must be on the
boundary. So, the set of points not in Int(A) and not in Ext(A) will be called
the boundary of A. A boundary point might be in the set, or it might not be.
There are two possible notations for this set. Here is the formal deﬁnition.

300
16 Topology
Deﬁnition 16.1.10.
Let A ⊆ℝ. The boundary of A is given by
Bndy(A) = 𝜕(A)
(16.18)
= {x ∈ℝ∣∀𝜀> 0 , N(x, 𝜀) ∩(ℝ∖A) ≠∅
and N(x, 𝜀) ∩A ≠∅}.
Notice that a boundary point might be in A, but it does not have to be there.
So there nothing to say for sure about 𝜕(A) ∩A or 𝜕(A) ∩(ℝ∖A). Still it is clear
from the deﬁnition that
𝜕(A) = 𝜕(ℝ∖A).
(16.19)
This makes sense if boundary means what it should mean. Notice also that
these three sets account for every possible real number and that their deﬁ-
nitions are mutually exclusive. This is important enough to state as a named
theorem.
Theorem 16.1.11
(The First Partition Theorem). For any A ⊆ℝ, we have:
Int(A) ∪𝜕(A) ∪Ext(A) = ℝ;
(16.20)
Int(A) ∩𝜕(A) = ∅;
Int(A) ∩Ext(A) = ∅;
𝜕(A) ∩Ext(A) = ∅.
Proof. The proof simply boils down to writing the deﬁnitions of the sets in the
right way and applying De Morgan’s Laws for each of the three steps.
Int(A) = {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ∩(ℝ∖A) = ∅};
(16.21)
Ext(A) = {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ∩A = ∅};
𝜕(A) = {x ∈ℝ∣∀𝜀> 0, N(x, 𝜀) ∩(ℝ∖A) ≠∅
and N(x, 𝜀) ∩A ≠∅}.
◽
16.1.4
Isolated points and accumulation points
We now translate the ideas of the second partition into precise mathematical
deﬁnitions.
Really out is still really out; so we reuse our deﬁnition:
Ext(A) = {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ∩A = ∅}.
(16.22)
Next we deﬁne isolated points of the set. Mathematicians use the term “dis-
crete” more than “ isolated,” but both are common enough.

16.1 Introduction
301
Deﬁnition 16.1.12.
Let A ⊆ℝ. The set of discrete (isolated) points of A is
given by
A∘= {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ∩A = {x}}.
(16.23)
This says that x is a discrete point if there is a neighborhood about it in which
the only point in it and in A is the point x itself. Notice that the deﬁnition tells
us that when x ∈A∘, then x ∈N(x, 𝜀) ∩A ⊆A. So for all sets A, A∘⊆A.
Now discrete points of A and interior points are very diﬀerent. No point can
possibly be both. But the neighborhoods in their deﬁnitions have something
in common. Once we have x ∈A∘, we have an 𝜀0 > 0 so that N(x, 𝜀0) ∩A =
{x}. But because of the way neighborhoods work, this 𝜀0-neighborhood is not
unique. We know for sure that every smaller neighborhood will also work: If
𝜀1< 𝜀0, then N(x, 𝜀1) ∩A ⊆N(x, 𝜀0) ∩A = {x}. In addition, there is nothing in
the deﬁnition that requires that the ﬁrst 𝜀0 we identify be even close to opti-
mal in size. So there could just as well be an 𝜀2> 𝜀0 where it still happens that
N(x, 𝜀2) ∩A = {x}.
We described the other points in our analogy as points that are not exterior
or isolated. We will call all points of ℝthat are not exterior or isolated the accu-
mulation points of A. As we learn more about them, this name will seem more
and more appropriate. For now, however, we just use logic to cover the rest of
ℝ. So x is an accumulation point of A if, for all neighborhoods, N(x, 𝜀) ∩A ≠∅
and N(x, 𝜀) ∩A ≠{x}. The deﬁnition must be:
Deﬁnition 16.1.13.
Let A ⊆ℝ. The set of accumulation points of A is
given by
A′ = {x ∈ℝ∣∀𝜀> 0, N∗(x, 𝜀) ∩A ≠∅}.
(16.24)
We have ﬁnally used our deleted neighborhood notation. To be an accumu-
lation point, it does not matter whether the point is in A or not; what matters is
what happens around it. The deﬁnition says that x is an accumulation point of
A if every neighborhood of A contains a point of A not equal to x. Now x need
not be in A to be an accumulation point of A. But if it is, every neighborhood
of x will have an element of A. In addition, x could be in A and not be an accu-
mulation point of A. (It could be an isolated point of A.) But if x is in A and A′,
then every neighborhood of x will have an element of A other than x.
Next we notice that the three sets Ext(A), A∘, and A′ have been deﬁned so
as to account for every possible real number and so that their deﬁnitions are
mutually exclusive. We state this as
Theorem 16.1.14
(The Second Partition Theorem). For any A ⊆ℝ,
we have:
A∘∪A′ ∪Ext(A) = ℝ;
(16.25)

302
16 Topology
A∘∩A′ = ∅;
A∘∩Ext(A) = ∅;
A′ ∩Ext(A) = ∅.
Proof. We assume that A ⊆ℝand write out the deﬁnitions:
Ext(A) = {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ∩A = ∅};
(16.26)
A∘= {x ∈ℝ∣∃𝜀> 0, N(x, 𝜀) ∩A = {x}};
A′ = {x ∈ℝ∣∀𝜀> 0, N∗(x, 𝜀) ∩A ≠∅}.
Since N∗(x, 𝜀) ∩A = ∅is the same as either N∗(x, 𝜀) ∩A = ∅or N∗(x, 𝜀) ∩A =
{x}, we simply use De Morgan’s Laws to complete the proof.
◽
The two partitions we have found are mostly very diﬀerent. But because they
cover all the points in ℝ, their parts must have some interactions. We will note
just one to start. The interior points of A cannot possibly be isolated or exte-
rior; so they should all be accumulation points. The proof is just a formalization
of the idea that, if N(x, 𝜀0) ⊆A, then every smaller neighborhood N(x, 𝜀1) will
contain lots of points of A besides the center point x.
Theorem 16.1.15.
For all A ⊆ℝ, Int(A) ⊆A′.
Proof. Assume x ∈Int(A). Then ∃𝜀1 > 0 such that N(x, 𝜀1) ⊆A.
Comment: In many of these proofs, epsilons occur all over the place. It is a good
idea to start oﬀwith a more individualized name every time one pops up. What
are we proving now? x ∈A
′. That is ∀𝜀> 0, N∗(x, 𝜀) ∩A ≠∅. We rewrite this
and prove it as an “if… then.”
Assume that we have a new 𝜀2 > 0. Let 𝜀3 = Min({𝜀1, 𝜀2}). Then 𝜀3 > 0, and
N(x, 𝜀1) ∩N(x, 𝜀2) = N(x, 𝜀3). Then
N∗(x, 𝜀3) ⊆N∗(x, 𝜀1);
(16.27)
N∗(x, 𝜀3) ⊆N∗(x, 𝜀2).
So
N∗(x, 𝜀3) ∩A ⊆N∗(x, 𝜀1) ∩A;
(16.28)
N∗(x, 𝜀3) ∩A ⊆N∗(x, 𝜀2) ∩A.
But N(x, 𝜀1) ⊆A; so N∗(x, 𝜀1) ∩A = N∗(x, 𝜀1). This means
N∗(x, 𝜀3) ⊆N∗(x, 𝜀2) ∩A.
(16.29)

16.1 Introduction
303
Since 𝜀3 > 0, N∗(x, 𝜀3) is not empty. So we have shown that ∀𝜀2 > 0,
N∗(x, 𝜀2) ∩A ≠∅. And so x ∈A′.
◽
Remember though that we do not require that points of A′ be in A; so we
expect that A′ will contain many points that are not in the interior of A. (Not
all the people in Boston are actually Red Sox fans; but people in Boston just
cannot avoid Sox fans.)
16.1.5
The closure
There is one more subset of ℝwe deﬁne using A. However, we cannot easily
describe it by giving a condition on the points it contains. Now Ext(A) is the set
of points really outside of A; so ℝ∖Ext(A) will consist of any point remotely
connected to A. Or we may say that A ∪𝜕(A) takes all the points in A and
adds the boundary; so it closes oﬀA. We might consider A ∪A′ as taking A
and including any points of ℝwhere A accumulates enough to be included as
a point involved with the set. Any one of these would make an interesting set
associated with A. As it turns out, they are all the same. There are other descrip-
tions of this set that are just as natural. We need to choose one as the deﬁnition
for our next set; so we settle on the following.
Deﬁnition 16.1.16.
Let A ⊆ℝ. The closure of A is given by
Cl(A) = Int(A) ∪𝜕(A).
(16.30)
This is just one of many ways to describe the exact same set. We will list every
other description of this same set right away.
Theorem 16.1.17.
Let A ⊆ℝ. Then
Cl(A) = Int(A) ∪𝜕(A)
(16.31)
= A ∪𝜕(A)
= ℝ∖Ext(A)
= A∘∪A′
= A ∪A′.
Proof. We will divide the proof into a series of parts, each of which shows some
equality or containment between the sets in the list.
Part 1. We claim that Cl(A) = Int(A) ∪𝜕(A).
Proof of claim. This follows from the deﬁnition.
◾

304
16 Topology
Part 2. We claim that Int(A) ∪𝜕(A) ⊆A ∪𝜕(A).
Proof of claim. Since Int(A) ⊆A, we can union both sides with 𝜕(A) to get
Int(A) ∪𝜕(A) ⊆A ∪𝜕(A).
◾
Part 3. We claim that A ∪𝜕(A) ⊆ℝ∖Ext(A).
Proof of claim. Since Ext(A) = Int(ℝ∖A) ⊆(ℝ∖A), we have A ⊆ℝ∖Ext(A).
The ﬁrst partition theorem tells us that 𝜕(A) ⊆ℝ∖Ext(A). So A ∪𝜕(A) ⊆
ℝ∖Ext(A).
◾
Part 4. We claim that ℝ∖Ext(A) ⊆Int(A) ∪𝜕(A).
Proof of claim. The ﬁrst partition theorem tells us that ℝ∖Ext(A) ⊆
Int(A) ∪𝜕(A).
◾
These ﬁrst four parts together say that
Int(A) ∪𝜕(A) ⊆A ∪𝜕(A)
(16.32)
⊆ℝ∖Ext(A)
⊆Int(A) ∪𝜕(A).
This shows that all three sets are equal.
Part 5. We claim that ℝ∖Ext(A) = A∘∪A′.
Proof of claim. The second partition theorem tells us that ℝ∖Ext(A) = A∘∪
A′.
◾
Part 6. We claim that A∘∪A′ ⊆A ∪A′.
Proof of claim. Since A∘⊆A, we can union both sides with A′ to get A∘∪A′ ⊆
A ∪A′.
◾
Part 7. We claim that ℝ∖Ext(A) = A ∪A′.
Proof of claim. Again A ⊆ℝ∖Ext(A) and the second partition theorem says
that A′ ⊆ℝ∖Ext(A). So A ∪A′ ⊆ℝ∖Ext(A).
◾
This completes another loop, and so the sets in it are equal.
◽
So we can get to the closure of a set in a number of diﬀerent ways: we can take
the set A and add in either 𝜕(A) or A′. Or we can lump together the interior and
the boundary. Or we can lump together the discrete points and the accumula-
tion points. What we cannot do is give one simple mathematical statement that
determines the points in the closure.

16.2 Examples
305
16.2
Examples
When we apply the aforementioned deﬁnitions to speciﬁc sets, some of the
associated sets are easier to ﬁnd than others. However, the two partition
theorems and the other relationships between the diﬀerent sets can turn
one easy answer into several other answers quickly. If we identify any of the
sets quickly, we often make it easier to ﬁnd the others. One word of caution,
the exterior of a set can get pretty nasty to write down explicitly. There are
times when discretion wins out over valor. So after we try to write out Ext(A)
carefully and ﬁnd it pretty messy, we might just write Ext(A) = ℝ∖Cl(A).
Finally, a drawing of a set A on the number line can be very helpful in working
with particular examples. We may not always include a drawing, but one is
always there in the scratch work.
Example 16.2.18.
Let A1 = (5, 7). Then
Int(A1) = (5, 7);
(16.33)
𝜕(A1) = {5, 7};
Ext(A1) = (−∞, 5) ∪(7, ∞);
Cl(A1) = [5, 7].
The sets in the First Partition Theorem are designed with intervals in mind.
A∘
1 = ∅;
(16.34)
A′
1 = [5, 7].
Discrete points in a set should “stick out like sore thumbs.” No points in this
interval are out on their own. The accumulation points are easy to ﬁnd, if
you remember that we already have the closure and the discrete points. Since
Cl(A) = A∘∪A′, it is easy to identify A′
1. Once we have it, we check using the
deﬁnition to see that all the points do ﬁt the requirements.
Example 16.2.19.
Let A2 = (5, 7]. Then
Int(A2) = (5, 7);
(16.35)
𝜕(A2) = {5, 7};
Ext(A2) = (−∞, 5) ∪(7, ∞);
Cl(A2) = [5, 7];
A∘
2 = ∅;
A′
2 = [5, 7].

306
16 Topology
Example 16.2.20.
Let A3 = [5, 7]. Then
Int(A3) = (5, 7);
(16.36)
𝜕(A3) = {5, 7};
Ext(A3) = (−∞, 5) ∪(7, ∞);
Cl(A3) = [5, 7];
A∘
3 = ∅;
A′
3 = [5, 7].
Example 16.2.21.
Let A4 = (2, ∞). Then
Int(A4) = (2, ∞);
(16.37)
𝜕(A4) = {2};
Ext(A4) = (−∞, 2);
Cl(A4) = [2, ∞);
A∘
4 = ∅;
A′
4 = [2, ∞).
Those examples should give us a pretty good handle on intervals. Now let us
try our hand on a ﬁnite set.
Example 16.2.22.
Let A5 = {2, 4, 5, 7}. Then
Int(A5) = ∅;
(16.38)
𝜕(A5) = {2, 4, 5, 7};
Cl(A5) = {2, 4, 5, 7};
Ext(A5) = ℝ∖A5.
Now to have an interior that is not empty, a set must contain some intervals.
So that makes this example easy; there can be no interior. Once you see it, the
boundary is just as obvious. That leads to the closure, and while we could write
the exterior as a union of speciﬁc intervals, we are too lazy to do so. Next
A∘
5 = {2, 4, 5, 7};
(16.39)
A′
5 = ∅.
Discrete points stick out like sore thumbs, and if we draw this set on the real
line, we just have four lonely points. There they are, obviously isolated from
each other.

16.2 Examples
307
Example 16.2.23.
Let A6 = ℤ. Then
Int(A6) = ∅;
(16.40)
𝜕(A6) = ℤ;
Cl(A6) = ℤ;
Ext(A6) =
⋃
n∈ℤ
(n −1, n);
A∘
6 = ℤ;
A′
6 = ∅.
The set has no intervals, so no interior. We are just showing oﬀwith that exte-
rior; we should have been perfectly satisﬁed with ℝ∖ℤ. The integers are dis-
crete. (Oh yeah, that is why we said this a long time ago.) Good old A′
6 is what
is left in the second partition, and that is nothing.
We have not seen an example where A′ is of any real help in ﬁnding the other
sets. But that is about to end.
Example 16.2.24.
Let A7 =
{
x ∈ℝ∣∃n ∈ℕs.t. x = 1
n
}
.
Again, we need to draw a picture of this set on the real line. Starting with
n = 1, 2, 3, we put down dots for 1
n (Figure 16.2).
Each dot is separated from the previous one, but the separation is getting
smaller and smaller, eventually too small to keep drawing. This is the kind of
set that the second partition is designed for. We will start with it.
A∘
7 = A7.
All the points of A7 are separated from the others. Even though the separation
is getting smaller and smaller forever, at any speciﬁc point, the separation is still
there. We eventually have to magnify our drawing to see it, but numerically
1
10347
is between
1
10348 and
1
10346 and no other points of A7 are in that gap. But what
about A′
7? Are there any points where A7 accumulates? If that has anything to
do with the English meaning of the word, the set should accumulate at 0. Every
neighborhood of 0 has at least one number in A7 in it. All we need do is ﬁnd an
n ∈ℕlarge enough. (Thank you, Archimedes.) Thus,
0 ∈A′
7.
(16.41)
Figure 16.2 x = 1
n.
1
1
5
1
4
1
3
1
2
0

308
16 Topology
Every nonzero point is in A7, below 0, above 1, or in a gap between the points
of A7. Thus, 0 is the only accumulation point of A7. So
A′
7 = {0}.
(16.42)
After this
Cl(A7) = A∘
7 ∪A′
7 = A7 ∪{0}.
(16.43)
The complement of this looks horrible; so
Ext(A7) = ℝ∖Cl(A7).
(16.44)
Now A7 contains no intervals, so
Int(A7) = ∅.
(16.45)
But then since Cl(A7) = Int(A7) ∪𝜕(A7), we must have
𝜕(A7) = A7 ∪{0}.
(16.46)
It would have been very easy to overlook the 0 in the boundary had we not
found A′
7 ﬁrst.
Now we mix things up a bit.
Example 16.2.25.
Let A8 = (3, 4] ∪{5}. Then
Int(A8) = (3, 4);
(16.47)
𝜕(A8) = {3, 4, 5};
Cl(A8) = [3, 4] ∪{5};
Ext(A8) = (−∞, 3) ∪(4, 5) ∪(5, ∞);
A∘
8 = {5};
A′
8 = [3, 4].
Notice how 5 sticks out like a sore thumb, and also notice how the interval
accumulates at its ends and its interior.
Next we do the always interesting empty set, and follow it with all of ℝ.
Example 16.2.26.
Let A9 = ∅. Then
Int(A9) = ∅;
(16.48)
𝜕(A9) = ∅;
Cl(A9) = ∅;
Ext(A9) = ℝ;
A∘
9 = ∅;
A′
9 = ∅.

16.2 Examples
309
Example 16.2.27.
Let A10 = ℝ. Then
Int(A10) = ℝ;
(16.49)
𝜕(A10) = ∅;
Cl(A10) = ℝ;
Ext(A10) = ∅;
A∘
10 = ∅;
A′
10 = ℝ.
We have saved the most interesting for last. Recall that one way to picture
the rational numbers as a subset of the real numbers is as a gray number line.
The gray is a warning that the irrational points are not points in the set, and the
white below them is shining through. This example deﬁnitely uses both versions
of the density theorem.
Example 16.2.28.
Let A11 = ℚ. Then
Int(A11) = ∅.
(16.50)
A consequence of the density theorem tells us that every interval contains real
numbers that are not rational. Thus, ℚcontains no complete intervals: no inter-
vals; no interior.
Next we consider A∘
11. No rational numbers stick out like sore thumbs. The
density theorem tells us that every interval about any single point contains
many rational numbers; so every neighborhood of every real number contains
some rational numbers. No real numbers can be isolated from ℚ.
A∘
11 = ∅.
(16.51)
It might not be clear what set to work on next, but in time we will see that A′
is actually very handy to have around. We consider A′
11. Now ℚis a gray – but
still – solid line in our picture because it has plenty of points, but also plenty
of holes. But the points have accumulated enough to look like a solid line. It
may look solid, but we know it is not complete. The density theorem tells us
that every interval about any single point contains many rational numbers, so
every neighborhood of every real number (rational or irrational) contains plenty
of rational numbers. All neighborhoods of all real numbers contain rational
numbers other than their centers. In other words,
A′
11 = ℝ.
(16.52)
Notice that the set of accumulation points has combined the accumulated stuﬀ
(ℚ) and the accumulated nonstuﬀ(ℝ∖ℚ) to form a substantial thing (ℝ). With

310
16 Topology
these sets identiﬁed, we are oﬀto the races:
Cl(A11) = ℝ;
(16.53)
𝜕(A11) = Int(A11) ∪𝜕(A11) = Cl(A11) = ℝ;
Ext(A11) = ∅.
Just to be safe, we will check these using the deﬁnitions. The density
theorem tells us that every interval contains rational numbers, but it also has
a consequence that also says that all intervals (x −𝜀, x + 𝜀) contain at least
one irrational number. So neither ℚnor ℝ∖ℚcontain any complete intervals
(x −𝜀, x + 𝜀). Thus,
Int(A11) = ∅;
(16.54)
Ext(A11) = ∅.
Again the density theorem says that all intervals (x −𝜀, x + 𝜀) contain at least
one rational number. We know it also tells us that there are always two. So
all intervals (x −𝜀, x + 𝜀) contain at least one rational number other than x,
whether x is rational or not. So
A∘
11 = {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ∩ℚ= {x}}
(16.55)
= ∅.
But both (x −𝜀, x) and (x, x + 𝜀) are true intervals in ℝ. Yet again, the density
theorem also tells us
N∗(x, 𝜀) ∩ℚ= ((x −𝜀, x) ∪(x, x + 𝜀)) ∩ℚ
(16.56)
= ((x −𝜀, x) ∩ℚ) ∪((x, x + 𝜀) ∩ℚ)
≠∅.
So every real number is in the set
A′
11 = {x ∈ℝ∣∀𝜀> 0, N∗(x, 𝜀) ∩ℚ≠∅}.
(16.57)
The density theorem tells us that every interval contains rational numbers,
and it has a consequence that also says that all intervals (x −𝜀, x + 𝜀) contain
at least one irrational number. So every real number is in the set
𝜕(A11) = {x ∈ℝ∣∀𝜀> 0, N(x, 𝜀) ∩(ℝ∖ℚ) ≠∅and N(x, 𝜀) ∩ℚ≠∅}.
(16.58)
In some sense, the statement ℝ= 𝜕(A11), is the full consequence of the density
theorem. Finally, by deﬁnition
Cl(A11) = Int(A11) ∪𝜕(A11) = ∅∪ℝ.
(16.59)

16.3 Open and Closed Sets
311
16.3
Open and closed sets
16.3.1
Deﬁnitions
Taking a clue from intervals, we will say that a subset of ℝis open if it does not
include its boundary points, but closed if it does. There a lots of subsets of ℝ
and most of them are quite terrible. Topology is a way to pick out the best of
these subsets and put them to as much use as possible. The best subsets are the
ones that are either open or closed. There are plenty that are neither, but we
just have to live with that.
Of course, when we write deﬁnitions for open and closed sets, we choose
ones that make these notions easier to use in proofs.
Deﬁnition 16.3.1.
Let A ⊆ℝ. We say that A is open when
∀x ∈A, ∃𝜀> 0 such that N(x, 𝜀) ⊆A.
(16.60)
Deﬁnition 16.3.2.
Let A ⊆ℝ. We say that A is closed when
𝜕(A) ⊆A.
(16.61)
So closed is exactly what we want it to be, but open looks more like the deﬁ-
nition of Int(A). We spend a lot of time proving that sets are open, and an equal
amount of time drawing conclusions about an open set. Our ﬁrst theorem about
open sets gives us plenty of choices on how to identify and to use open sets. We
really go overboard here to make each part of the proof pretty simple, but the
fact is that the more of these diﬀerent views of open set we remember, the less
time we will spend reproving things.
Theorem 16.3.3.
Let A ⊆ℝ. The following statements are equivalent.
1. A is an open set.
2. ∀x ∈A, ∃𝜀> 0 such that N(x, 𝜀) ⊆A.
3. A ⊆Int(A).
4. A = Int(A).
5. A ∩𝜕(A) = ∅.
6. ℝ∖A is closed.
Proof. We will show that (1) ⇔(2) ⇒(3) ⇒(4) ⇒(5) ⇒(6) ⇒(2). We get the
ﬁrst one very easily: observe that (1) ⇔(2) because (2) is simply the deﬁnition
of open.
In each following step, assume that A ⊆ℝ.
Step 1. We ﬁrst claim that (2) ⇒(3).

312
16 Topology
Proof of claim. Assume that ∀x ∈A, ∃𝜀> 0 such that N(x, 𝜀) ⊆A. Then ∀x ∈
A, x ∈Int(A). Thus, if (2) holds, then A ⊆Int(A).
◾
Step 2. We now claim that (3) ⇒(4).
Proof of claim. Assume that (3) holds. That is, assume that A ⊆Int(A). We
know that for all sets A, Int(A) ⊆A. So here we have A = Int(A).
◾
Step 3. We now claim that (4) ⇒(5).
Proof of claim. Assume now that (4) is true. That is, assume A = Int(A). By the
ﬁrst partition theorem, Int(A) ∩𝜕(A) = ∅. So A ∩𝜕(A) = ∅.
◾
Step 4. We now claim that (5) ⇒(6).
Proof of claim. Here assume (5) that A ∩𝜕(A) = ∅. Then 𝜕(A) ⊆ℝ∖A. But
𝜕(A) = 𝜕(ℝ∖A). So 𝜕(ℝ∖A) ⊆ℝ∖A. By deﬁnition ℝ∖A is closed.
◾
Step 5. We ﬁnally claim that (6) ⇒(2).
Proof of claim. Assume that (6) holds. That is, assume ℝ∖A is closed. So
𝜕(ℝ∖A) ⊆ℝ∖A. Then A ⊆ℝ∖(𝜕(ℝ∖A)).
Next assume x ∈A. Then x ∉𝜕(ℝ∖A). So x ∉𝜕(ℝ∖A) = 𝜕(A). Since x ∉
𝜕(A), ∃𝜀> 0 such that either
N(x, 𝜀) ∩A = ∅or N(x, 𝜀) ∩(ℝ∖A) = ∅.
(16.62)
However, x ∈N(x, 𝜀) ∩A; so we must have N(x, 𝜀) ∩(ℝ∖A) = ∅. That is
N(x, 𝜀) ⊆A.
◾
Since we have proved a sequence of implications that creates a circle, all the
statements are equivalent.
◽
Notice that no one of these alone is hard to prove. But using the best version
of open in a proof can save us having to repeat several of the steps in this proof.
In addition, the more we know about open sets, the easier it is to prove things
about them.
Next we give the corresponding theorem about closed sets.
Theorem 16.3.4.
Let A ⊆ℝ. The following statements are equivalent.
1. A is a closed set.
2. 𝜕(A) ⊆A.
3. Cl(A) = A.
4. Cl(A) ⊆A.

16.3 Open and Closed Sets
313
5. A′ ⊆A.
6. ℝ∖A is open.
Proof. We will show that (1) ⇔(2) ⇒(3) ⇒(4) ⇒(5) ⇒(6) ⇒(1). We get the
ﬁrst one very easily: observe that (1) ⇔(2) because (2) is simply the deﬁnition
of closed.
In each following step assume that A ⊆ℝ.
Step 1. We ﬁrst claim that (2) ⇒(3).
Proof of claim. Assume that (2) is true, that 𝜕(A) ⊆A. Then A ∪𝜕(A) = A. But
A ∪𝜕(A) = Cl(A).
◾
Step 2. We now claim that (3) ⇒(4).
Proof of claim. Assume that (3) holds. That is, assume Cl(A) = A. Then
Cl(A) ⊆A.
◾
Step 3. We now claim that (4) ⇒(5).
Proof of claim. Assume Cl(A) ⊆A. But for all sets, A′ ⊆Cl(A). So A′ ⊆A.
◾
Step 4. We now claim that (5) ⇒(6).
Proof of claim. Assume A′ ⊆A. Let x ∈ℝ∖A. Now A′ ⊆A implies ℝ∖A ⊆
ℝ∖A′. So
x ∉A′ = {x ∈ℝ∣∀𝜀> 0, N∗(x, 𝜀) ∩A ≠∅}.
(16.63)
Therefore, ∃𝜀> 0 s.t. N∗(x, 𝜀) ∩A = ∅. But then N∗(x, 𝜀) ⊆ℝ∖A. Since x ∈
ℝ∖A, we have
N(x, 𝜀) = N∗(x, 𝜀) ∪{x} ⊆ℝ∖A.
(16.64)
Since ∀x ∈ℝ∖A, ∃𝜀> 0 s.t. N(x, 𝜀) ⊆ℝ∖A, we have shown that ℝ∖A is
open.
◾
Step 5. We ﬁnally claim that (6) ⇒(1).
Proof of claim. Assume ℝ∖A is open. Then A = ℝ∖(ℝ∖A) is closed.
◾
Since we have proved a sequence of implications that creates a circle, all the
statements are equivalent.
◽
Finally, we give a theorem and proof to illustrate a useful trick that takes
advantage of the neighborhoods that are used in all these deﬁnitions. When-
ever we have multiple neighborhoods of one point on the real line, we can avoid

314
16 Topology
cases by replacing them all with the smallest of the neighborhoods. All of our
deﬁnitions are designed so that this replacement will give us what we want.
Theorem 16.3.5.
Let A ⊆ℝ. Then A∘⊆𝜕(A).
Proof draft. Assume A ⊆ℝ. To prove our subset relation, assume x ∈A∘.
Then ∃𝜀1 > 0 so that N(x, 𝜀1) ∩A = {x}.
Since we need to prove x ∈𝜕(A), we must show that ∀𝜀> 0, N(x, 𝜀) ∩
(ℝ∖A) ≠∅and N(x, 𝜀) ∩A ≠∅.
Comment: We must be careful here. We have found and named one 𝜀1 > 0 ear-
lier in the proof, and we need to prove something for all 𝜀> 0. We cannot use
the same name twice. So our next step is:
Assume that we have a new 𝜀2 > 0.
Comment: We now have two neighborhoods of x in our proof. One with radius
𝜀1, which we know something about, and the other with radius 𝜀2, which we need
to prove something about. Unfortunately, we do not know which neighborhood
is larger. We could split the proof into cases, but there is a shorter way to choose
the smaller neighborhood.
Let 𝜀3 = Min({𝜀1, 𝜀2}). Since the minimum is in the set, we know that 𝜀3 > 0.
We also know that 𝜀3 ≤𝜀1 and 𝜀3 ≤𝜀2, which tells us that N(x, 𝜀3) ⊆N(x, 𝜀1)
and N(x, 𝜀3) ⊆N(x, 𝜀2). We now can say that
x ∈N(x, 𝜀3) ∩A ⊆N(x, 𝜀1) ∩A = {x}.
(16.65)
So
N(x, 𝜀3) ∩A = {x}.
(16.66)
First we see that x ∈A, and so x ∈N(x, 𝜀2) ∩A. And so N(x, 𝜀2) ∩A ≠∅. This
is half of what we need.
Next we see that y = x + 𝜀3
2 ∈N(x, 𝜀3), but y ≠x. Since N(x, 𝜀3) ∩A = {x},
we know that y ∉A. So y ∈ℝ∖A. We also have y ∈N(x, 𝜀3) ⊆N(x, 𝜀2) So y ∈
N(x, 𝜀2) ∩(ℝ∖A) ≠∅. All of this shows that ∀𝜀2 > 0, N(x, 𝜀2) ∩(ℝ∖A) ≠∅
and N(x, 𝜀2) ∩A ≠∅.
Δ
We will clean up the proof a bit.
Proof. Assume A ⊆ℝ.
Then ∃𝜀1 > 0 so that N(x, 𝜀1) ∩A = {x}.
Assume 𝜀2 > 0.

16.3 Open and Closed Sets
315
Let 𝜀3 = Min({𝜀1, 𝜀2}). Thus, 𝜀3 > 0; 𝜀3 ≤𝜀1 and 𝜀3 ≤𝜀2. So N(x, 𝜀3) ⊆
N(x, 𝜀1) and N(x, 𝜀3) ⊆N(x, 𝜀2). We now can say that
x ∈N(x, 𝜀3) ∩A ⊆N(x, 𝜀2) ∩A = {x}.
(16.67)
So
N(x, 𝜀3) ∩A = {x}.
(16.68)
First we see that x ∈A, and so x ∈N(x, 𝜀2) ∩A. And so N(x, 𝜀2) ∩A ≠∅.
Next we see that y = x + 𝜀3
2 ∈N(x, 𝜀3), but y ≠x. Since N(x, 𝜀3) ∩A = {x},
we know that y ∉A. So y ∈ℝ∖A. We also have y ∈N(x, 𝜀3) ⊆N(x, 𝜀2). So
N(x, 𝜀2) ∩(ℝ∖A) ≠∅.
This shows that ∀𝜀2 > 0, N(x, 𝜀2) ∩(ℝ∖A) ≠∅and N(x, 𝜀2) ∩A ≠∅. We
have proved that x ∈𝜕(A).
◽
16.3.2
Examples
We will return to our previous examples and use the results we obtained on the
ﬁrst pass.
Example 16.3.6.
Let A1 = (5, 7). Then Int(A1) = (5, 7), and 𝜕(A1) = {5, 7}. So
A1 is open, but not closed.
Example 16.3.7.
Let A2 = (5, 7]. Then Int(A1) = (5, 7), and 𝜕(A1) = {5, 7}. So
A2 is not open, and not closed.
Example 16.3.8.
Let A3 = [5, 7]. Then Int(A3) = (5, 7), and 𝜕(A1) = {5, 7}. So
A3 is not open, but A3 is closed.
Example 16.3.9.
Let A4 = (2, ∞). Then Int(A4) = (2, ∞), and 𝜕(A4) = {2}. So
A4 is open, but not closed.
So intervals work as expected.
Example 16.3.10.
Let A5 = {2, 4, 5, 7}. Then Int(A5) = ∅, and 𝜕(A5) =
{2, 4, 5, 7}. So A5 is not open, but A5 is closed.
Example 16.3.11.
Let A6 = ℤ. Then Int(A6) = ∅, and 𝜕(A6) = {2, 4, 5, 7}. So
A6 is not open, but A6 is closed.
Recall that there are cases where A′ is easier to ﬁnd than 𝜕(A). We can check
A′ instead of 𝜕(A) because of our theorem.
Example 16.3.12.
Let A7 = {x ∈ℝ∣∃n ∈ℕs.t. x = 1
n}. Then Int(A7) = ∅,
and A′
7 = {0}. Thus A7 is not open and not closed.

316
16 Topology
This is interesting because A∘
7 = A7. Even though this set is discrete, it is not
closed.
Example 16.3.13.
Let
A8 = (3, 4] ∪{5}.
Then
Int(A8) = (3, 4),
and
𝜕(A8) = {3, 4, 5}. Thus, A7 is not open and is not closed.
Example 16.3.14.
Let A9 = ∅. Then Int(A9) = ∅, and 𝜕(A9) = ∅. So ∅is both
open and closed! That is strange, but we just have to accept it.
Example 16.3.15.
Let A10 = ℝ. Then Int(A10) = ℝ, and 𝜕(A10) = ∅. So ℝis
both open and closed.
Example 16.3.16.
Let A11 = ℚ. Then Int(A11) = ∅, and A′
11 = ℝ. So ℚis nei-
ther open nor closed.
16.4
Problems
16.1
Prove that for all A ⊆ℝ∶
(a) Int(A) ⊆A.
(b) A ⊆Cl(A).
(c) A∘⊆A.
(d) A∘⊆𝜕(A).
(e) Int(A) ⊆A′.
16.2
Find the interior, boundary, closure, discrete points, and accumulation
points of the following sets. (The exteriors may be helpful, but you
need not write them out since ℝ∖Cl(A) is as useful as anything more
explicit.) In addition, say if they are open or closed. (No proofs are
required, but you should deﬁnitely draw a picture and outline a proof
before you commit to an answer.)
(a) (2, 3) ∪(5, 7).
(b) ℕ.
(c) (−∞, 10) ∩ℤ.
(d) (−∞, 10) ∪ℤ.
(e) [−1, 1) ∩ℚ.
(f) [−1, 1) ∪ℚ.
(g)
{
x ∈ℝ∣∃n ∈ℕs.t. x = n+2
n
}
. (Draw a picture of y = x+2
x in ℝ2.)
(h)
{
x ∈ℝ∣∃n ∈ℕs.t. x =
n
√
n2+1
}
. (Draw a picture in ℝ2.)
(i) {r2 ∣r ∈ℚ}. (Draw a picture in ℝ2.)
(j) {2n ∣n ∈ℕ.} (Draw a picture.)
(k) {2n ∣n ∈ℤ}. (Draw a picture.)
(l) (0, ∞) ∖ℚ.

16.4 Problems
317
16.3
Let S =
{
x ∈ℝ∣∃n ∈ℕs.t. x =
n
n+1
}
. Prove 1 ∈S′.
16.4
Let A ⊆ℝwith A ≠∅. Prove that if A is bounded below, then Inf(A) ∈
𝜕(A).
16.5
Let A ⊆ℝ. Prove that if B ⊆A and B is open, then B ⊆Int(A).
16.6
Let A ⊆B ⊆ℝ. Prove the following: (You may want to prove them in a
diﬀerent order.)
(a) Int(A) ⊆Int(B).
(b) Cl(A) ⊆Cl(B).
(c) A′ ⊆B′.
(d) Ext(B) ⊆Ext(A).
16.7
Let A ⊆B ⊆ℝ. Why can’t we use this to prove the following results?
(Give an example.)
(a) 𝜕(A) ⊆𝜕(B).
(b) A∘⊆B∘.
16.8
Prove that for all A ⊆ℝ, A∘⊆𝜕(A).
16.9
Prove that if A ⊆ℝis bounded, then A′ is bounded. (Hint: Use closed
intervals.)
16.10
Prove: If A, B ⊆ℝare both open, then A ∩B is open.
16.11
Let (a, b) ⊆ℝ. Prove that (a, b) is open.
16.12
Prove: A ⊆ℝis open if and only if ∀x ∈A, ∃B with B open and
x ∈B ⊆A.
16.13
Given a subset A ⊆ℝ, there are three partitions of ℝassociated with
A: The 0th partition: A and ℝ∖A. The ﬁrst partition: Int(A), 𝜕(A), and
Ext(A); the second partition: A′, A∘, and Ext(A). The sets in these par-
titions can be very diﬀerent or very related.
(a) Identify as many interactions between the sets in these partitions
as you can. (Start with the relations in question 1.)
(b) Assume that the set A is open, add any extra relations to this list
from part (a).
(c) Assume that the set A is closed, add any extra relations to the list
from part (a).

319
17
Theorems in Topology
17.1
Summary of basic topology
Let A ⊆ℝ. We deﬁned two types of sets:
• A is open if ∀x ∈A, ∃𝜀> 0 s.t. N(x, 𝜀) ⊆A.
• A is closed if 𝜕(A) ⊆A.
It is a simple fact that most subsets of ℝare neither open nor closed. Still
associated with any subset A, we have deﬁned six associated sets:
• Int(A) = {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ⊆A}.
• 𝜕(A) = {x ∈ℝ∣∀𝜀> 0, N(x, 𝜀) ∩(ℝ\A) ≠∅and N(x, 𝜀) ∩A ≠∅}.
• Cl(A) = Int(A) ∪𝜕(A).
• A′ = {x ∈ℝ∣∀𝜀> 0, N∗(x, 𝜀) ∩A ≠∅}.
• A∘= {x ∈ℝ∣∃𝜀> 0, N(x, 𝜀) ∩A = {x}}.
• Ext(A) = {x ∈ℝ∣∃𝜀> 0 s.t. N(x, 𝜀) ⊆ℝ\A}.
Notice that the interior, exterior, and discrete points have “there exists”
requirements; while the boundary and accumulation points have “for all”
requirements. The closure, however, is not described by a condition on its
points.
There is a trivial partition of ℝinto two parts given by
• A ∪(ℝ\A) = ℝ;
• A ∩(ℝ\A) = ∅.
More important is the fact that there are two other topological partitions of
ℝassociated to A. The ﬁrst partition theorem says:
• Int(A) ∪𝜕(A) ∪Ext(A) = ℝ.
• Int(A) ∩𝜕(A) = ∅.
• Int(A) ∩Ext(A) = ∅.
• 𝜕(A) ∩Ext(A) = ∅.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

320
17 Theorems in Topology
The second partition theorem says:
• A∘∪A′ ∪Ext(A) = ℝ.
• A∘∩A′ = ∅.
• A∘∩Ext(A) = ∅.
• A′ ∩Ext(A) = ∅.
We have the following relationships between these sets in the diﬀerent par-
titions that hold for all A ⊆ℝ:
• Int(A) ⊆A.
• A ⊆Cl(A).
• A∘⊆A.
• A∘⊆𝜕(A).
• Int(A) ⊆A′.
In addition,
• Ext(A) = Int(ℝ\A).
• Ext(ℝ\A) = Int(A).
• 𝜕(A) = 𝜕(ℝ\A).
As we noticed earlier, the closure is not described by a condition on its points.
However, to make up for this, the closure can be written in several diﬀerent ways
other than the deﬁnition. We write down three:
• Cl(A) = A ∪𝜕(A) = ℝ\Ext(A) = A ∪A′.
Notice that the accumulation points and the boundary points both can be
used to close a set.
Some of the sets preserve subset relations, but others do not.
• If A ⊆B, then Int(A) ⊆Int(B).
• If A ⊆B, then Cl(A) ⊆Cl(A).
• If A ⊆B, then A′ ⊆B′.
• If A ⊆B, then Ext(B) ⊆Ext(A).
• We cannot be sure about 𝜕(A) and 𝜕(B) or about A∘and B∘. Notice that,
because A′ ⊆B′, it often happens that accumulation points are a better path
to closure than boundary points.
There are several statements that are equivalent to A is open:
• A is open if and only if any of the following hold:
– ∀x ∈A, ∃𝜀> 0 s.t. N(x, 𝜀) ⊆A.
– A = Int(A).
– A ∩𝜕(A) = ∅.
– ℝ\A is closed.

17.2 New Results
321
As it turns out, in a proof, the deﬁnition is often the most important thing
about a set known to be open. Once we know that we have an element of an
open set, we almost always introduce a neighborhood around it. But to prove
that a set is open, any one of the other conditions might be the best way to
proceed.
There are also several diﬀerent statements equivalent to A is closed:
• A is closed if and only if any of the following hold:
– 𝜕(A) ⊆A.
– A′ ⊆A.
– Cl(A) = A.
– ℝ\A is open.
In practice, any one of these might be the most valuable in a particular case.
When proving that a set is closed, proving the complement is open is often a
good choice. The deﬁnition is the oﬃcial deﬁnition because it is also useful.
One thing to remember is that, once we get used to them, accumulation points
are our friends. Because of their properties, the accumulation points of a closed
set often tell us important things about elements of the set.
17.2
New results
17.2.1
Unions and intersections
The fact is that interior, boundary, closure, accumulation points, discrete
points, and exterior typically mess up the union or the intersection of sets. So
there are no theorems about how these work on A ∪B or A ∩B. However, the
terms open and closed work pretty well. We can easily prove that if A and B
are open, then both A ∪B and A ∩B are also open. We can also prove that if A
and B are closed, then both A ∪B and A ∩B are also closed. But we are after
bigger game.
Theorem 17.2.1.
Let Ai where i ∈be a nonempty family of nonempty sets
such that ∀i ∈, Ai is open. Then
⋃
i∈
Ai is open.
And
if is ﬁnite, then
⋂
i∈
Ai is open.
We split the proof of this into two proofs. First, we give a proof of the
ﬁrst conclusion in the statement that ⋃
i∈
Ai is open; this proof is fairly

322
17 Theorems in Topology
straightforward. Following that we will give a draft proof of the second
conclusion of the proof before cleaning it up to give a ﬁnal proof of that part.
Here is a proof of the ﬁrst part.
Proof. Assume that Ai where i ∈be a nonempty family of sets such that ∀i ∈
, Ai is open.
Assume x ∈⋃
i∈
Ai. Then ∃ix ∈such that x ∈Aix. But Aix is open. So ∃𝜀x > 0
such that N(x, 𝜀x) ⊆Aix. Since we have a union, Aix ⊆⋃
i∈
Ai. So ∃𝜀x > 0 such that
N(x, 𝜀x) ⊆⋃
i∈
Ai. Thus, the union is open.
◽
This was simply a matter of assuming the right thing at the start and saying
what each statement meant until we reached the conclusion we wanted. We
just followed our logic as though we were doing an algebra calculation.
We now give a draft of a proof of the second claim in the theorem that if is
ﬁnite, then ⋂
i∈
Ai is open.
Proof draft. Assume that is ﬁnite.
Comment: That is funny, but it must be important to the proof. We should be
sure that we use it somewhere.
Assume x ∈⋂
i∈
Ai . Then ∀i ∈we have x ∈Ai.
Comment: Notice that, because of the “for all” construction, the i remains vari-
able. We can name it whatever we want, but not adding a subscript will help us
remember that it is a variable.
Now ∀i ∈, Ai is open.
Comment: We might be tempted to say “So ∃𝜀> 0 such that N(x, 𝜀) ⊆Ai.” But
then i at the end is still a variable; we should carry its qualiﬁer with it. (Yet again,
we see the logical construction of an AE statement and notice its consequences.)
So we actually say:
So ∀i ∈, ∃𝜀i > 0 such that N(x, 𝜀i) ⊆Ai.
Comment: The qualiﬁer reminds us that there are lots of i’s so there will be lots
of diﬀerent epsilons –one for each set in the intersection.
What are we proving now? ∃𝜀> 0 such that N(x, 𝜀) ⊆⋂
i∈
Ai. We need a word
problem to solve. We want one 𝜀> 0 so that N(x, 𝜀) ⊆Ai for all i ∈I. We have

17.2 New Results
323
a bunch of 𝜀i > 0; so exactly which one do we want? The smallest, of course.
Whoops, we should say minimum.
Let E = {𝜀i ∣i ∈}.
Comment: Before we pick its minimum, we need to give a reason that it has one.
We assumed that the family of sets is not empty and that the sets in the family
are not empty; so E ≠∅. We also assumed that is ﬁnite; so E is ﬁnite. Thus, E
has a minimum. Let 𝜀= Min(E). Then 𝜀∈E, so 𝜀> 0.
Comment: Thus, 𝜖fulﬁlls its main responsibility of being greater than 0.
In addition, ∀i ∈, 𝜀≤𝜀i. Thus, ∀i ∈, N(x, 𝜀) ⊆N(x, 𝜀i) ⊆Ai. So N(x, 𝜀) ⊆
⋂
i∈
Ai.
Δ
We should rewrite this proof.
Proof. Assume that is ﬁnite and ≠∅. Assume x ∈⋂
i∈
Ai . Then ∀i ∈s.t.
x ∈Ai. So
∀i ∈, ∃𝜀i > 0 s.t. N(x, 𝜀i) ⊆Ai.
(17.1)
Let E = {𝜀i ∣i ∈}. Since is ﬁnite and not empty, E is ﬁnite and not empty.
Thus, E has a minimum. Let 𝜀= Min(E). Then 𝜀∈E so 𝜀> 0. In addition,
∀i ∈, 𝜀≤𝜀i. Thus,
∀i ∈, N(x, 𝜀) ⊆N(x, 𝜀i) ⊆Ai.
(17.2)
So
N(x, 𝜀) ⊆
⋂
i∈
Ai.
(17.3)
◽
It is hard to miss the hypothesis that is ﬁnite in part 2 of this theorem. It says
that, while we can form union of open sets to our heart’s content, we cannot get
carried away with the intersection of open sets. Consider the example:
⋂
x>0
(−x, x) = {0}.
(17.4)
This is true, because the only |y| that is less than x for all x > 0 is 0. (The
contrapositive of the average theorem.) All the sets in the family are open,
but the one element set that is their intersection is not. We just cannot let
ourselves get carried away with the intersection of open sets.
The next theorem is not unexpected.

324
17 Theorems in Topology
Theorem 17.2.2.
Let Bi where i ∈be a nonempty family of sets such that
∀i ∈, Bi is closed. Then
⋂
i∈
Bi is closed.
and
If is ﬁnite, then
⋃
i∈
Bi is closed.
Before the proof a comment on proof technique.
Proof technique. Assume that Ai where i ∈be a nonempty family of sets such
that ∀i ∈, Ai is closed.
To prove that a set is closed, we must prove that it contains its boundary,
right? No we do not! We should not ignore all the hard work we have done prov-
ing theorems. Those theorems provide us with other choices. Just thinking about
proving that
𝜕
(
⋂
i∈
Ai
)
⊆
⋂
i∈
Ai
(17.5)
is frightening. We must be able to use the results we have proved to make this
easier. What about accumulation points? That is probably just as bad. (But it
actually is not.) Remember that we should not expect any of the topological sets
associated with subsets of ℝto work nicely on unions or intersections. The com-
plement is open? If we remember our set theory, this is deﬁnitely the way to go.
In fact, both parts end up with one-line proofs.
We now prove the theorem.
Proof. Assume that Bi where i ∈be a nonempty family of sets such that
∀i ∈, Bi is closed. Notice then that ∀i ∈, ℝ∖Bi is open.
Part 1. We claim that ⋂
i∈
Bi is closed.
Proof of Part 1. By the last theorem,⋃
i∈
(ℝ\Bi) is open. But by one of De Morgan’s
Laws,
⋃
i∈
(ℝ\Bi) = ℝ\
(
⋂
i∈
Bi
)
.
(17.6)
So ⋂
i∈
Bi is closed.
◾

17.2 New Results
325
Part 2. We now claim that if is ﬁnite, then ⋃
i∈
Bi is closed.
Proof of Part 2. Assuming that is ﬁnite, the last theorem says,⋂
i∈
(ℝ\Bi) is
open. But by one of De Morgan’s Laws,
⋂
i∈
(ℝ\Bi) = ℝ\
(
⋃
i∈
Bi
)
.
(17.7)
So ⋃
i∈
Bi is closed.
◾
◽
This is one place where remembering the proof makes important things
easy to remember. In time, we may recall these two theorems as “we can
union or intersect families of open and closed sets, but sometimes we can
only take ﬁnitely many.” The trouble is remembering what case requires only
ﬁnitely many sets. The counterexample for open sets is not too bad, but the
counterexample for closed sets is so easy, it is almost impossible to forget.
For any set A,
A =
⋃
a∈A
{a}.
(17.8)
Since not every set is closed, we can only take ﬁnitely many closed sets in a
union. So intersecting inﬁnitely many closed sets is OK. Since De Morgan’s
Laws switch unions and intersections, open sets work the other way around.
17.2.2
Open intervals are open
Our ﬁrst theorem basically must be true. Nevertheless, we need to prove it.
Theorem 17.2.3.
Let (a, b) ⊆ℝ. Then (a, b) is an open set.
Proof draft. Assume (a, b) ⊆ℝ. Then a < b.
Comment: What are we proving now? We are proving that ∀x ∈A, ∃𝜀> 0 such
that N(x, 𝜀) ⊆(a, b).
Assume x ∈A. Then a < x < b.
Comment: What are we proving now? We are proving that ∃𝜀> 0 such that
N(x, 𝜀) ⊆A. This means we have a word problem to set up and solve. We need
space around x small enough that it does not reach a or b. We need 𝜀to be smaller

326
17 Theorems in Topology
a
b
x
?
?
?
Figure 17.1 An open interval.
than either x −a or b −x. Since we do not know which is closer to x, a or b, maybe
we need cases. But if we realize that we want the one that is the smallest, we have
a way to choose this. As always, a good picture can help to solve a word problem
(Figure 17.1).
Now x −a > 0 and b −x > 0. Let 𝜀= Min({x −a, b −x}). Then 𝜀> 0;
𝜀≤x −a; and 𝜀≤b −x.
Comment: Assuming that we have the right epsilon, what are we proving now?
N(x, 𝜀) ⊆(a, b). OK, we know what to do.
Assume y ∈N(x, 𝜀). Then x −𝜀< y < x + 𝜀.
First, 𝜀≤b −x; so x + 𝜀≤x + b −x = b. Second, 𝜀≤x −a; so −𝜀≥a −x.
Then x −𝜀≥x + a −x = a. These two together say that
a ≤x −𝜀< y < x + 𝜀≤b.
(17.9)
So y ∈(a, b). We have proved that y ∈N(x, 𝜀) implies y ∈(a, b). So N(x, 𝜀) ⊆
(a, b).
Δ
We should rewrite this, so it is easier to follow:
Proof. Assume (a, b) ⊆ℝ. Then a < b. Assume x ∈A. Then a < x < b. Then
x −a > 0 and b −x > 0. Let 𝜀= Min({x −a, b −x}). Then 𝜀> 0; 𝜀≤x −a;
and 𝜀≤b −x.
Claim. N(x, 𝜀) ⊆(a, b).
Proof of claim. Assume y ∈N(x, 𝜀). Then x −𝜀< y < x + 𝜀. Then
a = a −(x −a) ≤a −𝜀< y.
(17.10)
and
y < x + 𝜀≤x + b −x = b.
(17.11)
So y ∈(a, b). Thus, N(x, 𝜀) ⊆(a, b).
◾
We have proved that x ∈(a, b) implies ∃𝜀> 0 with N(x, 𝜀) ⊆(a, b).
◽

17.2 New Results
327
Corollary 17.2.4.
For all x ∈ℝand 𝜀> 0, N(x, 𝜀) is an open set.
Proof. For all x ∈ℝand 𝜀> 0, N(x, 𝜀) = (x −𝜀, x + 𝜀).
◽
Corollary 17.2.5.
For all x ∈ℝand 𝜀> 0, N∗(x, 𝜀) is open.
Proof. N∗(x, 𝜀) = (x −𝜀, x) ∪(x, x + 𝜀) is the union of two open sets.
◽
17.2.3
Open subsets are in the interior
The proof of the next theorem is rather easy, but the result can save us a lot
of time in other proofs. Suppose that A is any set, and B and C are any two
subsets of A. It is unlikely that we can say anything general that would allow us
to conclude that B ⊆C. But if B is open and C is the interior of A, things are
quite diﬀerent.
Theorem 17.2.6.
Let A ⊆ℝ. If B ⊆A and B is open, then B ⊆Int(A).
Proof. Assume B ⊆A. Assume that B is open. Assume x ∈B. Then ∃𝜀> 0 s.t.
N(x, 𝜀) ⊆B. But N(x, 𝜀) ⊆B ⊆A. Since ∃𝜀> 0 s.t. N(x, 𝜀) ⊆A, x ∈Int(A). So
B ⊆Int(A).
◽
This simple result has a series of rapid consequences.
Theorem 17.2.7.
For all A ⊆ℝ, Int(A) is open.
Proof. Assume A ⊆ℝ.
Comment: What are we proving now? We are proving that ∀x ∈Int(A), ∃𝜀> 0
such that N(x, 𝜀) ⊆Int(A).
Assume x ∈Int(A). Then ∃𝜀> 0 such that N(x, 𝜀) ⊆A.
Comment: We need to apply the exact deﬁnition. Now N(x, 𝜀) ⊆A, but Int(A) is
probably smaller than A. How do we get this neighborhood into the smaller set?
Now N(x, 𝜀) is open, and N(x, 𝜀) ⊆A; so by the theorem, we have
N(x, 𝜀) ⊆Int(A).
(17.12)
Since ∀x ∈Int(A), ∃𝜀> 0 such that N(x, 𝜀) ⊆Int(A), Int(A) is open.
◽
Corollary 17.2.8.
For all A ⊆ℝ, Ext(A) is open.
Proof. Ext(A) = Int(ℝ\A).
◽

328
17 Theorems in Topology
Corollary 17.2.9.
For all A ⊆ℝ, Cl(A) is closed.
Proof. Cl(A) = ℝ\Ext(A).
◽
Corollary 17.2.10.
For all A ⊆ℝ, 𝜕(A) is closed.
Proof. Assume A ⊆ℝ. So Int(A) is open and Ext(A) is open. Then Int(A) ∪
Ext(A) is open. But by the ﬁrst partition theorem,
𝜕(A) = ℝ\(Int(A) ∪Ext(A)).
(17.13)
So 𝜕(A) is closed.
◽
17.2.4
Topology and completeness
The next result begins to illustrate how the language of topology can help make
the completeness property of the real numbers easier to use.
Theorem 17.2.11.
Let A ⊆ℝ.
1. If A has an inﬁmum, then Inf (A) ∈𝜕(A).
2. If A has a supremum, then Sup(A) ∈𝜕(A).
Proof draft. We will only prove one of these.
Assume m = Inf (A). Then ∀a ∈A, m ≤a. In addition, if l > m, then ∃a ∈A,
s.t. l > a.
Comment: We should draw a picture of this at least mentally. What are we
proving now? ∀𝜀> 0, N(m, 𝜀) ∩A ≠∅, and N(m, 𝜀) ∩(ℝ\A) ≠∅.
Assume 𝜀> 0.
Comment: We obviously need to use if l > m, then ∃a ∈A such that l > a. To do
this, we need something greater than m. All we have is 𝜀> 0.
Now m + 𝜀> m. So by the deﬁnition of inﬁmum, ∃a ∈A s.t. m + 𝜀> a.
However, since a ∈A, we also have m ≤a. So in fact, m −𝜀< m ≤a < m + 𝜀.
So a ∈N(m, 𝜀) ∩A.
Comment: That is half of what we need.
From our mental picture, we need to ﬁnd something in N(m, 𝜀) that is not in
A. Anything below m will do as long as it is close enough. The value m −𝜀catches
the edge of the neighborhood; so we use m −𝜀
2.

17.3 Accumulation Points
329
Consider m −𝜀
2. Since m −𝜀
2 < m = Inf(A), m −𝜀
2 ∉A. In addition,
||||
(
m −𝜀
2
)
−m
||||
= 𝜀
2 < 𝜀.
So
(
m −𝜀
2
)
∈
N(m, 𝜀).
We
have
(
m −𝜀
2
)
∈
N(m, 𝜀) ∩(ℝ\A).
Δ
Again, rewriting this will make it clearer.
Proof. We will only prove one of these.
Assume m = Inf (A). Then ∀a ∈A, m ≤a. In addition, if l > m, then ∃a ∈A,
such that l > a.
Assume 𝜀> 0.
Step 1. We claim N(m, 𝜀) ∩A ≠∅.
Proof of Step 1. Now m + 𝜀> m. So by the deﬁnition of inﬁmum, ∃a ∈A, s.t.
m + 𝜀> a. However, since a ∈A,, we also have m ≤a. So in fact, m −𝜀< m ≤
a < m + 𝜀. So a ∈N(m, 𝜀) ∩A.
◾
Step 2. We claim that N(m, 𝜀) ∩(ℝ\A) ≠∅.
Proof of Step 2. Consider m −𝜀
2. Since m −𝜀
2 < m =Inf(A), m −𝜀
2 ∉A. In
addition, ||||
(
m −𝜀
2
)
−m||||
= 𝜀
2 < 𝜀. So
(
m −𝜀
2
)
∈N(m, 𝜀). We have
(
m −𝜀
2
)
∈
N(m, 𝜀) ∩(ℝ\A).
◾
These two steps prove m ∈𝜕(A).
◽
17.3
Accumulation points
17.3.1
Accumulation points are aptly named
At ﬁrst, the accumulation points of a set might seem to be the least valuable of
the sets we have deﬁned. However, accumulation points have extra properties
that make them very useful. We have already seen that
If A ⊆B, then A′ ⊆B′.
Because of this, accumulation points are often easier to use than boundary
points when working with closed sets. We will now see two easy-to-remember
properties of accumulation points with rather intricate proofs. These proofs
may seem to belie the notion that accumulation points are good things to work
with. However, Mathematics works by hiding intricate arguments in the proofs
of theorems and simply using the theorems. A theorem that is easy to state and
easy to remember but hard to prove is a good thing. We can use the result of
the theorem without redoing the diﬃcult argument that makes it work.

330
17 Theorems in Topology
First, we prove that sets really do accumulate at their accumulation points.
By deﬁnition, x is an accumulation point of A if, for all 𝜀> 0, the deleted
neighborhood of x contains at least one point of A. The power of the qualiﬁer
“for all” gives us much more than one point. In fact, it guarantees that the
deleted neighborhood of x contains inﬁnitely many points of A. This is another
property that makes accumulation points easier to use than boundary points.
Both accumulation points and boundary points require that certain sets
be not empty: N∗(x, 𝜀) ∩A; N(x, 𝜀) ∩A; and N(x, 𝜀) ∩ℝ\A. However, there
are two sets to deal with for the boundary and only one for accumulation
points. In addition, proving that a set is nonempty means ﬁnding a point in
the set. This may be diﬃcult if there is only one possible point in the set.
But knowing that an accumulation point guarantees that N∗(x, 𝜀) ∩A will be
inﬁnite means that there are inﬁnitely many choices for proving that it is not
empty.
Theorem 17.3.1.
Let A ⊆ℝ. Then x ∈A′ if and only if ∀𝜀> 0, N(x, 𝜀) ∩A is
inﬁnite.
Proof draft. This is a biconditional statement, so we have two directions to
prove. We take the easy direction ﬁrst.
(⇐). We claim that if ∀𝜀> 0, N(x, 𝜀) ∩A is inﬁnite, then x ∈A′.
Proof of claim. Assume x ∈ℝs.t. ∀𝜀> 0, N(x, 𝜀) ∩A is inﬁnite.
Comment: This tells that we know something if we ever have an 𝜀, but it does not
give us one. What are we proving now? x ∈A′. That is, ∀𝜀> 0, N∗(x, 𝜀) ∩A ≠∅.
Since “for all” is essentially an “if…then” we get to make a new assumption.
Assume 𝜀1 > 0. Then N(x, 𝜀1) ∩A is inﬁnite. So (N(x, 𝜀1)\{x}) ∩A is also inﬁ-
nite. But that set is N∗(x, 𝜀1) ∩A; so N∗(x, 𝜀1) ∩A ≠∅.
◾
(⇒). We now claim that if x ∈A′, then ∀𝜀> 0, N(x, 𝜀) ∩A is inﬁnite.
Proof of claim. We will prove the contrapositive: if ∃𝜀> 0 such that N(x, 𝜀) ∩A
is ﬁnite, then x ∉A′.
Assume that ∃𝜀1 > 0 such that N(x, 𝜀1) ∩A is ﬁnite.
Comment: If we draw a picture of this (and we should), our ﬁrst concern is, “what
if there is nothing to draw?” That is, what if the set N(x, 𝜀1) ∩A is empty? That
is actually good for our proof. Our next concern is whether or not to draw x as
an element of the set. But that only reveals the real question, how many points

17.3 Accumulation Points
331
other than x are in the set? If there are none of these, that is just as good for us.
This reasoning leads us to three cases.
There are three possibilities: N(x, 𝜀1) ∩A = ∅, N(x, 𝜀1) ∩A = {x}, or
N∗(x, 𝜀1) ∩A is not empty but ﬁnite. We will prove that in each case x ∉A′.
Case 1: Assume N(x, 𝜀1) ∩A = ∅. Then x ∈Ext(A); so x ∉A′.
Case 2: Assume N(x, 𝜀1) ∩A = {x}. Then x ∈A∘; so x ∉A′.
Case 3: Assume N∗(x, 𝜀1) ∩A ≠∅, and it is ﬁnite.
Comment: What are we proving now? x ∉A′. But we know how to do this, we
prove that ∃𝜀> 0 s.t. N(x, 𝜀) ∩A is either empty or contains only x. The issue is
how far x is from the nearest point of A.
Nearest means shortest distance or minimum distance. So we know what
to do.
Let
D = {𝜀> 0 ∣∃a ∈N∗(x, 𝜀1) ∩A s.t. 𝜀= |x −a|}.
(17.14)
Because N∗(x, 𝜀1) ∩A ≠∅, we know that D ≠∅. Because N∗(x, 𝜀1) ∩A is ﬁnite,
we know that D is ﬁnite. In addition, because x ∉N∗(x, 𝜀1) ∩A, we know that
∀𝜀∈D, 𝜀> 0. Because of this, D has a minimum. Call it 𝜀2.
Then 𝜀2 ∈D; so 𝜀2 > 0.
And ∀𝜀∈D, 𝜀2 ≤𝜀.
Comment: What are we proving now? We are proving that ∃𝜀> 0 s.t. N(x, 𝜀) ∩A
is either empty or contains only x. If our picture is right, 𝜀2 will work.
Claim. N∗(x, 𝜀2) ∩A = ∅.
Proof of Claim. Comment: We know how to prove that a set is empty.
Assume BWOC y ∈N∗(x, 𝜀2) ∩A.
Comment: Is y ∈N∗(x, 𝜀1) ∩A? Well do we know 𝜀2≤𝜀1? We have not said so,
but can we prove it now?
Since N∗(x, 𝜀1) ∩A ≠∅, we can let z ∈N∗(x, 𝜀1) ∩A ≠∅. Then z ∈N∗(x, 𝜀1);
so |x −z|< 𝜀1.
But z ∈N∗(x, 𝜀1) ∩A. So we also have
|x −z| ∈D = {𝜀> 0 ∣∃a ∈N∗(x, 𝜀1) ∩A s.t. 𝜀= |x −a|}.
(17.15)
So 𝜀2 = Min(D) ≤|x −z|< 𝜀1.
Then we have N∗(x, 𝜀2) ⊆N∗(x, 𝜀1).

332
17 Theorems in Topology
Comment: But we are asking, is y ∈N∗(x, 𝜀1) ∩A?
We know that
y ∈N∗(x, 𝜀2) ∩A ⊆N∗(x, 𝜀1) ∩A.
(17.16)
And then
|x −y| ∈D = {𝜀> 0 ∣∃a ∈N∗(x, 𝜀1) ∩A s.t. 𝜀= |x −a|}.
(17.17)
So 𝜀2 = Min(D) ≤|x −y|. But
y ∈N∗(x, 𝜀2) ∩A ⊆N∗(x, 𝜀1);
(17.18)
also means that |x −y|< 𝜀1. We have now proved that 𝜀1 ≤|x −y|< 𝜀1 and that
is a contradiction.
◾
Now N∗(x, 𝜀2) ∩A = ∅. So there are only two possibilities for N(x, 𝜀2) ∩A:
either N(x, 𝜀2) ∩A = ∅or N(x, 𝜀2) ∩A = {x}. In the ﬁrst case, x ∈Ext(A), so
x ∉A′. In the second case, x ∈A∘; so x ∉A′. Either way, x ∉A′. Thus, in all
three cases, if ∃𝜀> 0 such that N(x, 𝜀) ∩A is ﬁnite, then x ∉A′
◾
We have now proved both directions of the theorem. That is, x ∈A′ if and
only if ∀𝜀> 0, N(x, 𝜀) ∩A is inﬁnite.
Δ
This deﬁnitely needs to be rewritten.
Proof. This is a biconditional statement, so we have two directions to prove.
For both parts, assume A ⊆ℝ. We do the easy direction ﬁrst.
(⇐). We claim that if ∀𝜀> 0, N(x, 𝜀) ∩A is inﬁnite, then x ∈A′.
Proof of claim. Assume x ∈ℝsuch that ∀𝜀> 0, N(x, 𝜀) ∩A is inﬁnite. Assume
𝜀1 > 0. Then by our hypothesis, N(x, 𝜀1) ∩A is inﬁnite. So (N(x, 𝜀1)\{x}) ∩A
is also inﬁnite. But that is N∗(x, 𝜀1) ∩A; so N∗(x, 𝜀1) ∩A ≠∅. So for all 𝜀1 > 0,
N∗(x, 𝜀1) ∩A ≠∅. So x ∈A′.
◾
(⇒). We now claim that if x ∈A′, then ∀𝜀> 0, N(x, 𝜀) ∩A is inﬁnite.
Proof of claim. To prove
if x ∈A′ , then ∀𝜀> 0, N(x, 𝜀) ∩A is inﬁnite,
We will prove the contrapositive:
If ∃𝜀> 0 such that N(x, 𝜀) ∩A is ﬁnite, then x ∉A′.
Assume that ∃𝜀1 > 0 s.t. N(x, 𝜀1) ∩A is ﬁnite.
There are three possibilities: N(x, 𝜀1) ∩A = ∅, N(x, 𝜀1) ∩A = {x}, or
N∗(x, 𝜀1) ∩A is not empty but ﬁnite.
Case 1: Assume N(x, 𝜀1) ∩A = ∅. Then x ∈Ext(A); so x ∉A′.
Case 2: Assume N(x, 𝜀1) ∩A = {x}. Then x ∈A∘; so x ∉A′.

17.3 Accumulation Points
333
Case 3: Assume N∗(x, 𝜀1) ∩A ≠∅, and it is ﬁnite. Let
D = {𝜀> 0 ∣∃a ∈N∗(x, 𝜀1) ∩A s.t. 𝜀= |x −a|}.
(17.19)
Because N∗(x, 𝜀1) ∩A ≠∅, we know that D ≠∅.
Because N∗(x, 𝜀1) ∩A is ﬁnite, we know that D is ﬁnite.
Because x ∉N∗(x, 𝜀1) ∩A, we know ∀𝜀∈D, 𝜀> 0.
Because of this, D has a minimum. Call it 𝜀2. Then 𝜀2 ∈D; so 𝜀2 > 0 and
∀𝜀∈D, 𝜀2 ≤𝜀.
Notice that because N∗(x, 𝜀1) ∩A ≠∅, we can ﬁnd z ∈N∗(x, 𝜀1) ∩A. Then
z ∈N∗(x, 𝜀1); so |x −z|< 𝜀1. But we also have |x −z| ∈D; so 𝜀2 = Min(D) ≤
|x −z|< 𝜀1. Thus, we have 𝜀2< 𝜀1, and in turn, N∗(x, 𝜀2) ⊆N∗(x, 𝜀1).
We now claim that N∗(x, 𝜀2) ∩A = ∅.
To see this, assume BWOC y ∈N∗(x, 𝜀2) ∩A. So y ∈N∗(x, 𝜀2) ∩A ⊆
N∗(x, 𝜀1) ∩A.
Then |x −y| ∈D. So 𝜀2 = Min(D) ≤|x −y|.
But y ∈N∗(x, 𝜀2) ∩A ⊆N∗(x, 𝜀2); so |x −y|< 𝜀2. We have now proved that
𝜀1 ≤|x −y|< 𝜀1 and that is a contradiction. Thus, we must have N∗(x, 𝜀2) ∩
A = ∅.
Now we summarize the three cases. If we assume that N∗(x, 𝜀1) ∩A is ﬁnite,
there are only three possibilities for N(x, 𝜀1) ∩A: N(x, 𝜀1) ∩A = ∅or N(x, 𝜀1) ∩
A = {x} or N(x, 𝜀1) ∩A has ﬁnitely many elements that are not x. In the ﬁrst
case, x ∈Ext(A), so x ∉A′. In the second case, x ∈A∘; so x ∉A′. In the third
case, the distance between x and the closest other point in N(x, 𝜀1) ∩A sepa-
rates x from the rest of A; so x is a discrete point and x ∉A′. Thus, we have
proved that if ∃𝜀> 0 such that N(x, 𝜀) ∩A is ﬁnite, then x ∉A′.
◾
This proves both directions of our biconditional, so we have proved that
x ∈A′ if and only if ∀𝜀> 0, N(x, 𝜀) ∩A is inﬁnite.
◽
17.3.2
For all A ⊆ℝ, A′ is closed
Earlier we proved that for any A ⊆ℝ, Int(A) and Ext(A) are open, and 𝜕(A)
and Cl(A) are closed. There are two sets associated to A remaining: the discrete
points A and the accumulation points A′. The discrete points are missing for a
reason. It is easy to realize why we cannot say that for all A ⊆ℝ, A∘is open. It is
actually hard to think of a particular A where A∘is open. But why do we not say
that A∘is closed? There is one important example that we should always keep
in our pocket. We have seen it before (Figure 17.2).
Let
A =
{
x ∈ℝ∣∃n ∈ℕs.t. x = 1
n
}
.
(17.20)
The topological sets associated with A are
Int(A) = ∅;
(17.21)

334
17 Theorems in Topology
1
1
5
1
4
1
3
1
2
0
Figure 17.2 x = 1
n.
A∘=
{
x ∈ℝ∣∃n ∈ℕs.t. x = 1
n
}
;
A′ = {0};
CL(A) = A ∪{0};
𝜕(A) = A ∪{0}.
The set A∘= A is not closed; it has 0 as an accumulation point. Since 0 ∉A∘,
and 0 ∈(A∘)′, it cannot be closed. One example kills the general theorem.
The accumulation points of A are a diﬀerent story. We can prove that, for all
A ⊆ℝ, A′ is closed. The proof is long no matter how we approach it, but it is
worth the eﬀort to see how far we can push an idea. Constructing the best proof
requires trying everything and seeing what works best. Some approaches will
bog down without any possibility of success; others we can push through to a
conclusion. The best proof is the one that seems to be the easiest to reconstruct.
We will take the trouble to try several alternatives just to see what happens.
Theorem 17.3.2.
For all A ⊆ℝ, A′is closed.
First, we just try the deﬁnition: A′ is closed if 𝜕(A′) ⊆A′. This is the deﬁnition
because, when it works, it works quickly. However, if it starts to get out of hand,
it is often a good idea to change from boundary points to accumulation points.
Attempt 1. We will prove that 𝜕(A′) ⊆A′.
Proof draft. Assume x ∈𝜕(A′). Then
∀𝜀> 0, N(x, 𝜀) ∩A′ ≠∅and N(x, 𝜀) ∩(ℝ\A′) ≠∅.
(17.22)
Comment: To put this to use, we will have to have an 𝜀> 0 appear somewhere in
the proof. What are we proving now? x ∈A′. That is, ∀𝜀> 0, N∗(x, 𝜀) ∩A ≠∅.
So we have our next step.
Assume 𝜀1 > 0.
Comment: It is always a good idea to give subscripts to numbers we know exist.
This is a good assumption because it allows us to use the constant 𝜀1 as a value
for variable 𝜀we said we were looking for to use or ﬁrst assumption.

17.3 Accumulation Points
335
So
N(x, 𝜀1) ∩A′ ≠∅and N(x, 𝜀1) ∩(ℝ\A′) ≠∅.
(17.23)
Comment: But now what are we proving? N∗(x, 𝜀1) ∩A ≠∅. How do we show
that a set is not empty? We ﬁnd an element in it. We are proving that something
exists. We need to set up a word problem and solve it.
We need y ∈N∗(x, 𝜀1) ∩A.
What do we know? There is something in N(x, 𝜀1) ∩A′ ≠∅and something else
in N(x, 𝜀1) ∩(ℝ\A′) ≠∅.
It is not clear why either of those should give us something in A. This might be
a good place to give up and prove that A′ is closed in a diﬀerent way. Normally,
that is exactly what we would do and only return to this approach if we had no
other choice.
But, out of pure masochism, we will just be pig-headed and root ahead! So oﬀ
we go . . . .
We need to ﬁnd something in A. Of the two facts we have, N(x, 𝜀1) ∩A′ ≠∅
looks like it might give us something in A. This is because the deﬁnition of accu-
mulation points says:
A′ = {x ∈ℝ∣∀𝜀> 0, N∗(x, 𝜀) ∩A ≠∅}.
(17.24)
The set condition N∗(x, 𝜀) ∩A ≠∅gives us something in A.
We will see what happens if we use N(x, 𝜀1) ∩A′ ≠∅.
Since N(x, 𝜀1) ∩A′ ≠∅, we can let z ∈N(x, 𝜀1) ∩A′. Then z ∈N(x, 𝜀1) and
z ∈A′. So
∀𝜀> 0, N∗(z, 𝜀) ∩A ≠∅.
(17.25)
Comment: We only have one small number so far, 𝜀1. We can use it as this last
variable to say that N∗(z, 𝜀1) ∩A ≠∅. We might guess that this is the y we are
looking for. But we want y ∈N∗(x, 𝜀1) ∩A, and this gives us y ∈N∗(z, 𝜀1) ∩A.
Unless we know that N∗(z, 𝜀1) ⊆N∗(x, 𝜀1), it will not work. We need a smaller
neighborhood of z for this to be true. This epsilon and its y are simply not going
to work. We need to ﬁnd a smaller 𝜀.
We have z ∈N(x, 𝜀1). This is an open set.
Comment: The proof would have gotten even worse if we did not remember this.
So ∃𝜀2 > 0 such that N(z, 𝜀2) ⊆N(x, 𝜀1).
Comment: Let us use this ﬁxed 𝜀2 as a value for the variable 𝜀in our last “for
all”: ∀𝜀> 0, N∗(z, 𝜀) ∩A ≠∅.

336
17 Theorems in Topology
Then N∗(z, 𝜀2) ∩A ≠∅. Let y ∈N∗(z, 𝜀2) ∩A. Then
y ∈N∗(z, 𝜀2) ∩A
⊆N(z, 𝜀2) ∩A
⊆N(x, 𝜀1) ∩A.
(17.26)
Comment: This is pretty close, we have y ∈N(x, 𝜀1) ∩A, but we need
y ∈N∗(x, 𝜀1) ∩A. We need y ≠x.
Unfortunately, is does look like x = y can happen. So this looks like a good
place to give up; and normally, we probably would.
But we are still being pig-headed, and surrendering is not an option. We need to
ﬁnd a way to avoid y = x. We will look back on what we have for help. We came
up with y because N∗(z, 𝜀2) ∩A ≠∅. We know that y ∈N∗(x, 𝜀1) ∩A because
N(z, 𝜀2) ⊆N(x, 𝜀1). If we knew that N∗(z, 𝜀2) ⊆N∗(x, 𝜀1), that would be better.
So we wish we knew z ≠x. Now we came up with z because N(x, 𝜀1) ∩A′ ≠∅.
So z ∈A′. But from the beginning we have been trying to prove that x ∈A′. So if
z = x, we would be done. If not, we would have our wish and also be done. So we
are done, it appears. Somewhere in this mess is a complete proof. It only barely
deserves a rewrite!
Δ
To ﬁnd our proof, we start over completely. As we go, we need to look for
places where we can rewrite our ﬁnal observations more logically. When we
try to prove complicated things, our ﬁrst attempt at a logical proof often goes
astray. If we think we are close, we need to be willing to start over adding in
what we have learned as we go. It may take three or four attempts before we
actually get to the end.
Attempt 1 (again). We will prove that 𝜕(A′) ⊆A′.
Proof. Assume x ∈𝜕(A′).
Then ∀𝜀> 0, N(x, 𝜀) ∩A′ ≠∅and N(x, 𝜀) ∩(ℝ\A′) ≠∅.
Claim. ∀𝜀1 > 0, N∗(x, 𝜀1) ∩A ≠∅.
Comment: After all, we want to prove that x ∈A′; why not just claim it and then
prove it?
Proof of claim. Assume 𝜀1 > 0. Then letting 𝜀= 𝜀1 in the last statement, we have
N(x, 𝜀1) ∩A′ ≠∅and N(x, 𝜀1) ∩(ℝ\A′) ≠∅.
Comment: We recall that it was the ﬁrst of these that we wanted to use.
Since N(x, 𝜀1) ∩A′ ≠∅, let z ∈N(x, 𝜀1) ∩A′. Then z ∈N(x, 𝜀1) and z ∈A′.

17.3 Accumulation Points
337
Comment: We now remember that the issue is whether z = x or not. Since that
is an “or,” we should try cases.
There are two possibilities: z = x or z ≠x.
Case 1: Assume z = x. Then x = z ∈A′. So N∗(x, 𝜀1) ∩A = N∗(z, 𝜀1) ∩A ≠∅
as we claimed.
Case 2: Assume z ≠x. Now z ∈N(x, 𝜀1) ∩A′; so we can say that z ∈
N∗(x, 𝜀1) ∩A′. Because N∗(x, 𝜀1) is an open set, ∃𝜀2 > 0 s.t. N(z, 𝜀2) ⊆N∗(x, 𝜀1).
Because z ∈A′, ∀𝜀> 0, N∗(z, 𝜀) ∩A ≠∅.
Letting 𝜀= 𝜀2 in the last statement, we have N∗(z, 𝜀2) ∩A ≠∅. Let
y ∈N∗(z, 𝜀2) ∩A. But
N∗(z, 𝜀2) ∩A ⊆N(z, 𝜀2) ∩A
⊆N∗(x, 𝜀1) ∩A.
(17.27)
Then y ∈N∗(x, 𝜀1) ∩A. So again, N∗(x, 𝜀1) ∩A ≠∅.
So in case 2, we have proved the claim that N∗(x, 𝜀1) ∩A ≠∅.
◾
The claim is just the deﬁnition of x ∈A′. Thus, 𝜕(A′) ⊆A′, and this proves
that A′ is closed.
◽
Finding this proof was not easy at all. Even our rewrite required extra thought
to get it organized. Once it is complete and rewritten carefully, it makes a bit
more sense. One last rewrite will clean it up a lot; hide our wandering logic, and
leave any future reader in admiration of our remarkable cleverness.
Attempt 1 (last time). We will prove that 𝜕(A′) ⊆A′.
Proof. Assume x ∈𝜕(A′).
Then ∀𝜀> 0, N(x, 𝜀) ∩A′ ≠∅and N(x, 𝜀) ∩(ℝ\A′) ≠∅.
Assume 𝜀1 > 0. Then let 𝜀= 𝜀1 in the last statement. We have N(x, 𝜀1) ∩A′ ≠
∅and N(x, 𝜀1) ∩(ℝ\A′) ≠∅.
Since N(x, 𝜀1) ∩A′ ≠∅, let z ∈N(x, 𝜀1) ∩A′. Then z ∈N(x, 𝜀1) and z ∈A′.
There are two possibilities: z = x or z ≠x.
Case 1: Assume z = x. Then x = z ∈A′. So x ∈A′, and we are done.
Case 2: Assume z ≠x. Now z ∈N(x, 𝜀1) ∩A′; so we can say that z ∈
N∗(x, 𝜀1) ∩A′. Because N∗(x, 𝜀1) is an open set, ∃𝜀2 > 0 s.t. N(z, 𝜀2) ⊆N∗(x, 𝜀1).
Because z ∈A′, we also have ∀𝜀> 0, N∗(z, 𝜀) ∩A ≠∅.
Letting 𝜀= 𝜀2 in the last statement, we have N∗(z, 𝜀2) ∩A ≠∅. Let
y ∈N∗(z, 𝜀2) ∩A. But
N∗(z, 𝜀2) ∩A ⊆N(z, 𝜀2) ∩A
⊆N∗(x, 𝜀1) ∩A.
(17.28)
Then y ∈N∗(x, 𝜀1) ∩A ≠∅. So N∗(x, 𝜀1) ∩A ≠∅. ◊
So in case 2, we have proved that x ∈A′.

338
17 Theorems in Topology
In either case, x ∈𝜕(A′) was used to prove x ∈A′. Thus 𝜕(A′) ⊆A′, and this
proves that A′ is closed.
◽
As any English essay, the ﬁrst version of a proof will often need to be rewrit-
ten. Even a second version may need extra editing.
Early on in this proof, we realized that it was getting out of hand. We pressed
on anyway. However, there are several ways to prove that a set is closed. It might
have been a good idea to give up on proving that 𝜕(A′) ⊆A′ and try proving
that A′ is closed by proving (A′)′ ⊆A′. After all, accumulation points are often
better than boundary points. There is no question that we have gained some
insight at the ﬁrst attempt, so the second attempt might go more smoothly even
though we are using a diﬀerent approach. But even if we had not pressed on
and learned things in attempt 1, it might be that attempt 2 was easier to bring
to a conclusion. Logically, the accumulation point arguments and boundary
point arguments are not that diﬀerent; so we will beneﬁt from our experience.
Notice, however, that the accumulation points deﬁnitely do help us avoid the
main problem we ran into in the ﬁrst proof.
Attempt 2. We will prove that (A′)′ ⊆A′.
Proof draft. Comment: We might hope that this is easier than the last because
accumulation points are supposed to be our friends.
Assume x ∈(A′)′. Then
∀𝜀> 0, N∗(x, 𝜀) ∩A′ ≠∅.
(17.29)
Comment: What are we proving now? x ∈A′. That is, ∀𝜀> 0, N∗(x, 𝜀) ∩A ≠∅.
So let us not beat around the bush.
Claim. ∀𝜀1 > 0, N∗(x, 𝜀1) ∩A ≠∅.
Proof of claim. Assume 𝜀1 > 0. Then
N∗(x, 𝜀1) ∩A′ ≠∅.
(17.30)
Comment: But now what are we proving? N∗(x, 𝜀1) ∩A ≠∅. How do we show
that a set is not empty? We ﬁnd an element in it. We are proving that something
exists. We need to set up a word problem and solve it.
We need y ∈N∗(x, 𝜀1) ∩A. We need y ∈N(x, 𝜀1) ∩A with y ≠x. What do we
know? There is something in N∗(x, 𝜀1) ∩A′ ≠∅.
We have been this way before.
Let z ∈N∗(x, 𝜀1) ∩A′.

17.3 Accumulation Points
339
Comment: Because we are using accumulation points, we do not need the cases
we had in attempt 1. We almost missed the need for those cases anyway; so this
approach is already better. It leads us past a trap.
So z ∈N∗(x, 𝜀1) and z ∈A′. Since z ∈N∗(x, 𝜀1), an open set, ∃𝜀2 > 0 s.t.
N(z, 𝜀2) ⊆N∗(x, 𝜀1). But z ∈A′ and 𝜀2 > 0; so N∗(z, 𝜀2) ∩A ≠∅. Since
N∗(z, 𝜀2) ∩A ⊆N∗(x, 𝜀1) ∩A,
(17.31)
we know that N∗(x, 𝜀1) ∩A ≠∅as claimed.
◾
The proof tells us that x ∈A′. So we have (A′)′ ⊆A′. So A′ is closed.
Δ
This proof is not that diﬀerent than attempt 1. But it was easier to ﬁnd because
accumulation points are more friendly than boundary points.
Neither of these proofs are intuitive, and we needed to struggle with logic to
ﬁnd them. Maybe a whole new approach will work better. What about our old
fallback for diﬃcult proofs, proof by contradiction?
Attempt 3. We will prove that (A′)′ ⊆A′.
Proof draft. Assume x ∈(A′)′. Then ∀𝜀> 0, N∗(x, 𝜀) ∩A′ ≠∅.
Assume BWOC x ∉A′. Then ∼(∀𝜀> 0, N∗(x, 𝜀) ∩A ≠∅). That is,
∃𝜀1 > 0, s.t. N∗(x, 𝜀1) ∩A = ∅.
(17.32)
Applying the previous statement to 𝜀1 > 0, we see that N∗(x, 𝜀1) ∩A′ ≠∅.
Comment: There is only one way to use this.
Let y ∈N∗(x, 𝜀1) ∩A′ ≠∅. Then y ∈N∗(x, 𝜀1), and y ∈A′.
Since y ∈N∗(x, 𝜀1) an open set, ∃𝜀2 > 0 s.t. N(y, 𝜀2) ⊆N∗(x, 𝜀1).
But y ∈A′; so N∗(y, 𝜀2) ∩A ≠∅.
This is a problem because
N∗(y, 𝜀2) ∩A ⊆N(y, 𝜀2) ∩A
⊆N∗(x, 𝜀1) ∩A.
(17.33)
We said earlier that N∗(x, 𝜀1) ∩A = ∅. So we have a contradiction.
So we must have (A′)′ ⊆A′. So A′ is closed.
Δ
In retrospect, this is actually a proof by contrapositive. We should rewrite it
that way.
Attempt 3 (again). We will prove that (A′)′ ⊆A′.
Proof. We will prove that (A′)′ ⊆A′ by proving:

340
17 Theorems in Topology
If x ∉A′, then x ∉(A′)′.
Assume
x ∉A′.
Then
∼(∀𝜀> 0, N∗(x, 𝜀) ∩A ≠∅).
That
is,
∃𝜀1 > 0,
N∗(x, 𝜀1) ∩A = ∅.
Claim. N∗(x, 𝜀1) ∩A′ = ∅.
Proof of claim. Assume BWOC N∗(x, 𝜀1) ∩A′ ≠∅.
Let y ∈N∗(x, 𝜀1) ∩A′ ≠∅. Then y ∈N∗(x, 𝜀1), and y ∈A′.
Since y ∈N∗(x, 𝜀1) and an open set, ∃𝜀2 > 0 s.t. N(y, 𝜀2) ⊆N∗(x, 𝜀1).
But y ∈A′; so N∗(y, 𝜀2) ∩A ≠∅.
This is a problem because
N∗(y, 𝜀2) ∩A ⊆N(y, 𝜀2) ∩A
⊆N∗(x, 𝜀1) ∩A.
(17.34)
We said earlier that N∗(x, 𝜀1) ∩A = ∅. This proves the claim.
◾
So we have 𝜀1 > 0 so that N∗(x, 𝜀1) ∩A′ = ∅. Thus, x ∉(A′)′.
◽
Another popular way to show that a set is closed is by proving its complement
in ℝis open. This is so popular that, with more experience, we would probably
have tried it ﬁrst. Let us give it a try now.
Attempt 4. We will prove that ℝ\A′ is open.
Proof draft. Comment: What are we proving? ∀x ∈ℝ\A′, ∃𝜀> 0 such that
N(x, 𝜀) ⊆ℝ\A′. Or we could prove that ℝ\A′ ⊆Int(ℝ\A′). Since either way we
start out the same way, we should keep an open mind.
Assume x ∈ℝ\A′. So by the Second Partition Theorem,
x ∈Ext(A) ∪A∘.
(17.35)
There are two possibilities x ∈Ext(A) or x ∈A∘.
Case 1: Assume x ∈Ext(A).
Comment: What are we proving now? ∃𝜀> 0 s.t. N(x, 𝜀) ⊆ℝ\A′. If we know our
theorems, there is a shortcut.
Now Ext(A) ⊆ℝ\A′ and it is open. So we know that
x ∈Ext(A) ⊆Int(ℝ\A′).
(17.36)
Case 2: Assume x ∈A∘. Then ∃𝜀1 > 0 such that N(x, 𝜀1) ∩A = {x}. So we can
say that N∗(x, 𝜀1) ∩A = ∅. So N∗(x, 𝜀1) ⊆ℝ\A. This is an open subset of ℝ\A; so
N∗(x, 𝜀1) ⊆Int(ℝ\A)

17.4 Problems
341
⊆Ext(A)
⊆ℝ\A′.
(17.37)
Since x ∈A∘, we also have x ∈ℝ\A′. Then
N(x, 𝜀1) = N∗(x, 𝜀1) ∪{x} ⊆ℝ\A′.
(17.38)
But the neighborhood is an open set; so
x ∈N(x, 𝜀1) ⊆Int(ℝ\A′).
(17.39)
So we have proved that in either case, if x ∈ℝ\A′, then x ∈Int(ℝ\A′). Thus,
ℝ\A′ = Int(ℝ\A′), and ℝ\A′ is open.
Δ
This really seems better. It deserves to be rewritten.
All these attempts seem to be more eﬀort than one result was worth. But
we have seen that we need to be ﬂexible when we need to construct a proof.
If our ﬁrst idea is not going along easily, the best thing to do might be to try
something else from the start. With enough eﬀort, we should expect to prove
any true statement. A bad start might make this harder that it needs to be. Our
ﬁrst rule for proofs was: “always start with the deﬁnitions.” This is still a good
rule of thumb, but we adjust it with a second rule: “starting a proof using a good
theorem can make things much easier.”
17.4
Problems
17.1
What, if anything, can you say about:
(a) Int(Int(A))?
(b) 𝜕(Int(A))?
(c) Cl(Int(A))?
(d) (Int(A))∘?
(e) (Int(A))′?
(f) Int(𝜕(A))?
(g) 𝜕(𝜕(A))?
(h) Cl(𝜕(A))?
(i) (𝜕(A))∘?
(j) (𝜕(A))′?
(k) Int(Cl(A))?
(l) 𝜕(Cl(A))?
(m) Cl(Cl(A))?
(n) (Cl(A))∘?
(o) (Cl(A))′?
(p) Int(A∘)?
(q) 𝜕(A∘)?

342
17 Theorems in Topology
(r) Cl(A∘)?
(s) (A∘)∘?
(t) (A∘)′?
(u) Int(A′)?
(v) 𝜕(A′)?
(w) Cl(A′)?
(x) (A′)∘?
(y) (A′)′?
17.2
Use proved theorems to easily prove:
(a) If A′ = ∅, then A = A∘.
(b) If A ⊆ℝis ﬁnite, then A = A∘.
17.3
Let A ⊆ℝbe a nonempty closed set. Prove if A is bounded below, then
A has a minimum.
17.4
Let Ai where i ∈be a nonempty family of sets.
(a) Prove that
(
⋂
∀i∈
Ai
)′
⊆
⋂
∀i∈
A′
i.
(17.40)
(Hint: Accumulation points are your friends.)
(b) Suppose that ∀i ∈, Ai is closed. Use part (a) to prove ⋂
∀i∈
Ai is
closed.
17.5
Let A ⊆ℝ.
(a) Prove that if A ⊆C a closed set, then Cl(A) ⊆C.
(b) Prove that if A is bounded, then Cl(A) is bounded. (Hint: Use
intervals.)
(c) Prove that if A is bounded, then A′ is bounded.
17.6
Prove using the deﬁnition that, if A and B are open sets, then A ∩B
is open.
17.7
Prove using induction that, if Ai where i ∈is a nonempty ﬁnite family
of open sets, then ⋂
∀i∈
Ai is open.
17.8
Let A, B ⊆ℝ.
(a) Prove: If 𝜕(A) = ∅, then A is closed.
(b) Prove: If 𝜕(A) = ∅, then A∘= ∅.
(c) Prove: If A∘= ∅, then ∀x ∈ℝ, if B = A ∩[x, ∞), then B∘= ∅.

17.4 Problems
343
(d) Prove: If 𝜕(A) = ∅, then ∀x ∈ℝ, if B = A ∩[x, ∞), then B∘= ∅.
(e) Prove: If m =Inf(A), then m ∈𝜕(A).
(f) Prove: If A ≠∅, and A is bounded below, then 𝜕(A) ≠∅.
(g) Prove: if A ≠∅and 𝜕(A) = ∅, then ∀x ∈ℝ, for B = A ∩[x, ∞), we
have B ≠∅.
(h) Prove: if A ≠∅and 𝜕(A) = ∅, then ∀x ∈ℝ, for B = A ∩[x, ∞), we
know that B has a inﬁmum. Throughout the rest of the problem, let
mx = Inf (A ∩[x, ∞)).
(i) Prove: if A ≠∅and 𝜕(A) = ∅, then if x ∈ℝ, then ∀𝜀> 0,
A ∩[mx, mx + 𝜀) ≠∅.
(j) Prove: if A ≠∅and 𝜕(A) = ∅, then ∀x ∈ℝ, A ∩[x, ∞) is closed.
(k) Prove: if A ≠∅and 𝜕(A) = ∅, then ∀x ∈ℝ, mx ∈A ∩[x, ∞).
(l) Prove: if A ≠∅and 𝜕(A) = ∅and x ∉A, then x < mx.
(m) Prove: if A ≠∅and 𝜕(A) = ∅and x ∉A, then ∀𝜀> 0,
mx −1
2Min({ ∉, (mx −x)) ∉A.
(n) Prove: if A ≠∅and 𝜕(A) = ∅and x ∉A, then ∀𝜀> 0, (mx −𝜀, mx) ∩
(ℝ\A) ≠∅.
(o) Prove: if A ≠∅and 𝜕(A) = ∅and x ∉A, then ∀𝜀> 0, N(mx, 𝜀) ∩
(ℝ\A) ≠∅and N(mx, 𝜀) ∩A ≠∅.
(p) Prove: if A ≠∅and 𝜕(A) = ∅then ∀x ∈ℝ, x ∈A.
(q) Prove: 𝜕(A) = ∅then either A = ∅or A = ℝ.
(r) Prove: If A is open and closed, then either A = ∅or A = ℝ.
17.9
Recall our last theorem that stated for all A ⊆ℝ, A′ is a closed set. Polish
the draft of attempt 2 into a better written proof.

345
18
Compact Sets
18.1
Closed and bounded sets
18.1.1
Maximums and minimums
If A ⊆ℝis nonempty and closed, it has nice topological properties. If A is
nonempty and bounded, it ﬁts perfectly into our deﬁnition of the real numbers.
But somehow when the two properties closed and bounded are combined, the
result is much stronger than either one alone. A set that is closed and bounded
has many more strong properties than a set that is just closed or just bounded.
Proving many of the properties of these closed and bounded sets requires
greater logical power than directly applying the two deﬁnitions separately.
Luckily, mathematicians have developed an amazing and powerful trick that
provides a completely diﬀerent path to such proofs. We will prove a theorem
that says that, for any closed and bounded set, a very nonintuitive trick will
work in a proof. Similarly to a proof by induction, this trick is not always
the method we use, but it is available when necessary. In addition, similar to
induction, it really helps to prove the more interesting results. The only hard
part is remembering this very strange trick.
We start, however, with a result about closed and bounded sets that is not
much more than a combination of the two deﬁnitions.
Theorem 18.1.1.
Let A ⊆ℝwith A ≠∅. If A is closed and bounded, then A
has a maximum and a minimum.
We have seen how useful such guarantees have been in the past; so this is
deﬁnitely a result worth remembering.
Proof. Assume A ⊆ℝwith A ≠∅. Assume that A is closed. Assume that A is
bounded below. Assume that A is bounded above.
Since A is nonempty and bounded below, it has an inﬁmum; call it m.
Similarly, A has a supremum; call it M. We have proved in Theorem 17.2.11
that m ∈𝜕(A) and M ∈𝜕(A). Since A is closed, 𝜕(A) ⊆A. Thus, m is a lower
bound of A that is in A. So m = Min(A). Similarly, M = Max(A).
◽
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

346
18 Compact Sets
The deﬁnition of compact
In the early 19th century, Bernhard Bolzano proved a result about a closed and
bounded subset of ℝthat used a trick that was so strange that it took other
mathematicians a while to appreciate the power of his ideas. After they did,
they realized that they needed a mechanism for remembering that this trick
was available. Later in the century, two other mathematicians would prove that
Bolzano’s trick would work exactly when a set was closed and bounded. Now
“closed and bounded” is an easy thing to say, and the deﬁnitions of the parts are
easy to remember. But Bolzano’s trick is another story. Mathematicians deﬁne
a new term “compact” whose deﬁnition is a weird statement that amounts to
Bolzano’s trick. When they are presented with a closed and bounded set, they
automatically call it “compact.” That way, when they ask themselves what a
compact set is, they answer with a deﬁnition that outlines Bolzano’s trick. They
can always change back to “closed and bounded” if they ﬁnd that they do not
need all the power of that trick.
As a result, we have a deﬁnition of “A is a compact set” that does absolutely
nothing to explain what the term “compact” means. “Compact” is just the word
we use, it is not because the trick has anything to do with the English word. As
one gets used to it, the word “compact” will begin to seem reasonably descrip-
tive. That might have been the case had mathematicians chosen another word
such as “ﬁrm,” “solid,” or “concrete.” They did not; so in Mathematics, the term
“compact set” means no less and no more than the following bizarre deﬁnition.
Deﬁnition 18.1.2.
Let A ⊆ℝ. We say that A is compact when for all families
i with i ∈where all i are open and where A ⊆⋃
i∈
i, there exists ⊆with
ﬁnite so that A ⊆⋃
i∈
i.
People often state this as, “Every open cover of A has a ﬁnite subcover.”
As predicted, this is not at all intuitive. It does contain a hint about its power
though. If we cover a set A with a lot of open sets, we can start oﬀas sloppily as
we want. We can cover everything in sight, and long as we cover all of the set, it
does not matter how carried away we get covering anything extra. Compactness
will guarantee that our sloppiness can later be corrected, and we can trim down
our sloppy cover into a much more manageable ﬁnite subcover. Basically, every
time a mathematician ﬁnds a new or novel way to cover a set known to be com-
pact, that mathematician has a new mathematical theorem. The only drawback
is that it seems that each idea for a cover only gives one mathematical theorem.
Thus, using compactness seems to mean constantly inventing new covers.
The good news is that, in many applications, covers of sets appear automat-
ically. We are given one compact set, and we are asked to prove that another
set is compact. Then the set we want to be compact can assumed to be covered
with open sets. We then ﬁnd a way to change those open sets into open sets

18.1 Closed and Bounded Sets
347
that cover the set we know is compact in a reversible way. The ﬁnite cover of
the second set can then be reversed and used to prove that the desired set is
compact. So instead of having to invent a new cover for a compact set every
time, we are often led to a cover from a bunch of open sets we already have.
Compact sets are closed and bounded sets
The fact is that compact sets are simply sets that are closed and bounded. The
proof of this is long and detailed.
We have ﬁnally hit on the structure that makes Mathematics so valuable.
We are going to name, state, and prove a theorem that we will be able to call
upon in any future proof. We have done this before, but never with a result
that would be as diﬃcult to reconstruct. If we forget the average theorem, but
ﬁnd ourselves needing a real number between two others, we might not have
that much trouble rediscovering the average theorem on our own. Take the
topology theorem that states:
If A ⊆B and A is open, then A ⊆Int(B).
This theorem is very handy; it can make it easier to discover a proof. But if it
skips our mind, we can probably avoid it or reprove it as we push through the
logic of a proof.
The fact that compact sets are closed and bounded sets is not something
we might easily stumble upon without help. There is very little chance that
anyone will ever accidentally rediscover its proof. The proof is long enough
that we would not want to have to redo it, perhaps ever. Students may need to
reprove it, but once they have moved on to other things, they can use it simply
by referring to its name. That is exactly why we name and prove mathematical
theorems: to prove them once, and then move on without ever reproving them
again. (Although, mathematicians always enjoy replacing a famous long proof
with a clever short one.) The longer a proof, the more important it is that we
remember the statement of the theorem. If we remember the theorem, we can
use the theorem without recalling the proof.
The reason why the bizarre deﬁnition of compact sets is so useful is the fol-
lowing theorem.
Theorem 18.1.3
(The Heine–Borel Theorem). Let A ⊆ℝ. Then A is com-
pact if and only if A is closed and bounded.
There are three parts to the proof of this important theorem:
Part 1. If A is compact, then A is bounded.
Part 2. If A is compact, then A is closed.
Part 3. If A is closed and bounded, then A is compact.

348
18 Compact Sets
The ﬁrst two parts illustrate how a clever open cover of a compact set, no
matter how sloppy, leads to an interesting property of the set. The third part is
the meat of the theorem since it gives us an easy way to tell if a clever open cover
of a set will be of any use. The proof of this theorem is generally something we
are shown and not something we discover on our own. For that reason, it is
worth going through carefully to understand every step.
Part 1. We claim that if A is compact, then A is bounded.
Proof. Assume that A is compact.
Comment: In this case, it really does not pay to write down the deﬁnition. It is
more important to remember its meaning: if we ever have an open cover of A,
then we can trim it down. A compact set does not come with an open cover;
rather we must ﬁnd one to put its compactness to use. The family we will use will
only be useful for proving this theorem.
For n ∈ℕ, let n = (−n, n). This is a family of open sets.
Claim. We claim that ⋃
n∈ℕ
n = ℝ.
Proof of claim. The proof is left as an exercise, but it is nothing more than an
application of the absolute value and the Archimedean principle.
◾
It follows that A ⊆ℝ= ⋃
n∈ℕ
n. So we have an open cover n, indexed by
n ∈ℕ, of the compact set A. So by the deﬁnition of compact, there is a ﬁnite
set ⊆ℕso that
A ⊆
⋃
n∈
n.
(18.1)
However, because is a ﬁnite subset of ℕ, it has a maximum element. Let us
say that m = Max().
Then we have that for all n ∈, n ≤m. It follows that for all n ∈,
n = (−n, n) ⊆(−m, m).
This implies that
A ⊆
⋃
n∈
n ⊆(−m, m).
(18.2)
Thus, −m is a lower bound for A and m is an upper bound. This completes the
ﬁrst part of our proof of the Heine–Borel theorem.
◽
This proof is an excellent example of how careful deﬁnitions can work
together. Compactness is about any open cover no matter how much more

18.1 Closed and Bounded Sets
349
it covers than it needs to. This cover of expanding open intervals covers the
entire real line. Knowing that there is a ﬁnite subcover means that, when
looked at carefully, only one interval is needed. That interval gives a lower
bound and an upper bound. Those bounds may not be optimal at all. But all
we claimed was that the set was bounded; so we do not need better upper and
lower bounds than these.
Proof technique. When we assume that a set is compact (or closed and
bounded after Heine–Borel is proved), it is often a good idea not to write out
the deﬁnition of compact for that set. Writing out that deﬁnition can result into
tricking ourselves into thinking that we have a cover of the set. If we know that a
set is compact, that only tells us that if we ever have an open cover of that set,
we can cut it down to a ﬁnite cover. If we show enough patience, we may be able
to ﬁnd a cover to use this on.
Part 2. We claim that if A is compact, then A is closed.
Proof. Assume that A is compact. We will prove that ℝ\A is open.
Assume b ∈ℝ\A.
For 𝜀∈ℝwith 𝜀∈(0, ∞), let 𝜀= (−∞, b −𝜀) ∪(b + 𝜀, ∞). This is a family
of open sets.
Claim. We claim ⋃
𝜀>0
𝜀= ℝ\{b}.
Proof of claim. This is a set equality; so as usual, there are two steps. We must
prove ⋃
𝜀>0
𝜀⊆ℝ\{b} and ⋃
𝜀>0
𝜀⊇ℝ\{b}.
Step 1: First, we will prove that ⋃
𝜀>0
𝜀⊆ℝ\{b}.
Note that for all 𝜀> 0, b ∉𝜀. That is to say, 𝜀⊆ℝ\{b} for all 𝜀> 0. Thus,
⋃
𝜀>0
𝜀⊆ℝ\{b}. This proves that ⋃
𝜀>0
𝜀⊆ℝ\{b}.
Step 2: Now we will prove that ⋃
𝜀>0
𝜀⊇ℝ\{b}.
Assume x ≠b, and let 𝜀x = 1
2|x −b|. Then 𝜀x > 0. In addition,
x ∉[b−𝜀x, b+𝜀x].
(18.3)
Then
x ∈ℝ\ [b−𝜀x, b+𝜀x].
(18.4)
So
x ∈(−∞, b−𝜀x) ∪(b+𝜀x, ∞) = 𝜀x.
(18.5)
And then, x ∈⋃
𝜀>0
𝜀. This proves that
⋃
𝜀>0
𝜀⊇ℝ\ {b}. Thus, we have
⋃
𝜀>0
𝜀= ℝ\ {b}.
◾

350
18 Compact Sets
We have assumed that b ∈ℝ\A. This is equivalent to saying that {b} ⊆ℝ\ A.
So by taking complements, we obtain A ⊆ℝ\ {b}.
By our claim,
A ⊆ℝ\ {b} =
⋃
𝜀>0
𝜀=
⋃
𝜀∈(0,∞)
𝜀.
(18.6)
So we have an open cover of a compact set.
By the deﬁnition of compactness, there exists a ﬁnite set ⊆(0, ∞), so that
A ⊆⋃
𝜀∈
𝜀.
However, a ﬁnite subset of ℝhas a minimum. Let us say that 𝜀0 = Min().
Then for all 𝜀∈, 𝜀0 ≤𝜀. Also 𝜀0 ∈⊆(0, ∞); so 𝜀0 > 0.
So for each 𝜀∈
[b−𝜀0, b+𝜀0] ⊆[b −𝜀, b + 𝜀].
(18.7)
Taking complements, it follows that for each 𝜀∈,
(ℝ\ [b −𝜀, b + 𝜀]) ⊆(ℝ\[b−𝜀0, b+𝜀0]).
(18.8)
This is the same as saying that for each 𝜀∈,
(−∞, b −𝜀) ∪(b + 𝜀, ∞) ⊆(−∞, b−𝜀0) ∪(b+𝜀0, ∞).
(18.9)
Notice that the left-hand side of the previous equation is exactly 𝜀. So we have,
∀𝜀∈, 𝜀⊆(−∞, b−𝜀0) ∪(b+𝜀0, ∞).
(18.10)
And from this we can conclude that
⋃
𝜀∈
𝜀⊆(−∞, b−𝜀0) ∪(b+𝜀0, ∞).
(18.11)
But recall that A ⊆⋃
𝜀∈
𝜀. Therefore, we have
A ⊆
⋃
𝜀∈
𝜀⊆(−∞, b−𝜀0) ∪(b+𝜀0, ∞).
(18.12)
By taking complements of these sets, we see
[b−𝜀0, b+𝜀0] ⊆ℝ\ A.
(18.13)
And so ﬁnally,
N(b, 𝜀0) ⊆[b−𝜀0, b+𝜀0] ⊆ℝ\ A.
(18.14)
Since ∀b ∈ℝ\A, ∃𝜀0 > 0 such that N(b, 𝜀0) ⊆ℝ\ A, we have shown that ℝ\A
is open and therefore that A is closed. This completes the second part of our
proof of the Heine–Borel theorem.
◽
Another very generous cover produces an interesting result. These ﬁrst two
parts demonstrate how the peculiar deﬁnition of a compact set can be put
to use.

18.1 Closed and Bounded Sets
351
The third part is completely diﬀerent and, at ﬁrst glance at least, seems
quite complicated. The idea behind it is not much more than a sort of
“minimum counterexample” argument or, perhaps better, a “supremum
example” argument. In the end, this is a proof of a “there exists” result, and we
need a creative way to produce a ﬁnite set that works. Sliding in from below
will allow us to create a set with a “supremum example.” And then we will
show that it cannot exist.
Part 3. If A is closed and bounded, then A is compact.
Proof. Assume A ⊆ℝ. Assume that A is bounded above and below, and assume
that A is closed. Since the empty set is automatically compact, we may also
assume that A ≠∅.
We need to show that any open cover of A has a ﬁnite subcover, so we will
begin by assuming that we have some open cover of A.
Thus, assume that i with i ∈is a family of sets, and assume that for all
i ∈, i is open. Finally, assume that
A ⊆
⋃
i∈
i.
We begin by observing that since A ≠∅, there must be at least one set in our
open cover. So we know that ≠∅.
For all x ∈ℝ, let
Ax = A ∩(−∞, x).
(18.15)
Let
B =
{
x ∈ℝ∣∃x ⊆, s.t. x is ﬁnite and Ax ⊆
⋃
i∈x
i
}
.
(18.16)
Claim. We claim that B ≠∅.
Proof of claim. By assumption, A is bounded below. Let b be any lower bound
of A. Then we know that if a ∈A, then b ≤a. So,
Ab = A ∩(−∞, b)
(18.17)
= {x ∈ℝ∣x ∈A and x ∈(−∞, b)}
= {x ∈A ∣x < b}
= ∅.
Since ≠∅, we know that there is some element in . Say ib ∈. Then
b = {ib} is certainly a ﬁnite subset of and
Ab = ∅⊆
⋃
i∈{ib}
i.
(18.18)
This puts b ∈B. So B ≠∅, and we have proved our claim.
◾

352
18 Compact Sets
Comment: Notice that this shows that every lower bound of A is in B. So B is
deﬁnitely not bounded below. However, it may or may not be bounded above.
But if we understand what the deﬁnition of B says, the following claim seems
necessary if our theorem is true.
Claim. We claim that B is not bounded above.
Proof of claim. Suppose BWOC that B is bounded above. Then since B ⊆ℝis
nonempty and bounded above, B has a supremum. Let us say m = Sup(B).
Then by deﬁnition of supremum,
• ∀b ∈B, b ≤m, and
• if l < m, then ∃b ∈B such that l < b.
There are two possibilities for m: either m ∈A or m ∉A.
Case 1: Assume m ∈A.
Then m ∈A ⊆⋃
i∈
i. So ∃im ∈such that m ∈im. But im is an open set;
so there is some 𝜀> 0 such that N(m, 𝜀) ⊆im. Now m −𝜀< m; and so by the
deﬁnition of the supremum, ∃b ∈B such that m −𝜀< b. Since b ∈B, we also
have
m −𝜀< b ≤m < m + 𝜀.
(18.19)
Consider the interval (−∞, m + 𝜀).
(−∞, m + 𝜀) = (−∞, b) ∪(m −𝜀, m + 𝜀).
(18.20)
We have
Am+𝜀= A ∩(−∞, m + 𝜀)
(18.21)
= A ∩((−∞, b) ∪(m −𝜀, m + 𝜀))
= (A ∩(−∞, b)) ∪(A ∩(m −𝜀, m + 𝜀))
= Ab ∪(A ∩N(m, 𝜀))
⊆Ab ∪N(m, 𝜀)
⊆Ab ∪im.
But b ∈B. So by the deﬁnition of B, ∃b ⊆such that b is ﬁnite and
Ab ⊆⋃
i∈b
i.
Putting the last two observations together, we have
Am+𝜀⊆Ab ∪im
(18.22)
⊆
(
⋃
i∈b
i
)
∪im
⊆
⋃
i∈b∪{im}
i.

18.1 Closed and Bounded Sets
353
Since b is ﬁnite, so is b ∪{im}. This shows that Am+𝜀is covered by ﬁnitely
many of the open sets; so m + 𝜀∈B. But that means m = Sup(B) ≥m + 𝜀.
Since 𝜀> 0, this is not possible. So this subcase cannot occur. That is, we
cannot have m ∈A.
Case 2: Assume m ∉A.
Then m ∈ℝ\A. Because A is closed, ℝ\A is open. So ∃𝜀> 0 such that
N(m, 𝜀) ⊆ℝ\A. That is, N(m, 𝜀) ∩A = ∅.
Now m −𝜀< m, and so by the deﬁnition of the supremum, ∃b ∈B such that
m −𝜀< b. Since b ∈B, we also have
m −𝜀< b ≤m < m + 𝜀.
(18.23)
Consider the interval (−∞, m + 𝜀).
(−∞, m + 𝜀) = (−∞, b) ∪(m −𝜀, m + 𝜀).
(18.24)
So
Am+𝜀= A ∩(−∞, m + 𝜀)
(18.25)
= A ∩((−∞, b) ∪(m −𝜀, m + 𝜀))
= (A ∩(−∞, b)) ∪(A ∩(m −𝜀, m + 𝜀))
= Ab ∪(A ∩N(m, 𝜀))
⊆Ab ∪∅
⊆Ab.
But b ∈B. So by the deﬁnition of B, ∃b ⊆such that b is ﬁnite and
Ab ⊆⋃
i∈b
i.
Putting the last two observations together, we have
Am+𝜀= Ab ⊆
⋃
i∈b
i.
(18.26)
Since b is ﬁnite, this shows that Am+𝜀is covered by ﬁnitely many of the open
sets; so m + 𝜀∈B. But that means m =Sup(B) ≥m + 𝜀. Since 𝜀> 0, this is not
possible. So this subcase cannot occur either.
Eliminating all the possibilities that follow from the assumption that B is
bounded above means that B cannot be bounded above. This proves our claim
that B is not bounded above.
◾
So we now have that B is not empty and not bounded above. There is one last
assumption we have not used: A is bounded above. Let u be any upper bound
of A. Then for all a ∈A, a ≤u.
Now u ∈ℝand B is not bounded above; in particular, u is not an upper bound
on B. There must be b ∈B such that u < b. But u is an upper bound of A; so

354
18 Compact Sets
∀a ∈A, a ≤u < b. That is to say,
A ⊆(−∞, b).
(18.27)
So
A ⊆A ∩(−∞, b) = Ab.
(18.28)
However, b ∈B, so by deﬁnition ∃b ⊆such that b is ﬁnite and Ab ⊆⋃
i∈b
i.
So A = Ab ⊆⋃
i∈b
i with b ⊆ﬁnite. This proves that any open cover of A
can be trimmed to ﬁnitely many sets. So A is compact. This completes the third
and ﬁnal part of our proof of the Heine–Borel theorem.
◽
18.2
Closed intervals are special
Certainly, because of the Heine–Borel theorem, every closed bounded interval
[a, b] in ℝis compact. Intervals have another mathematical property called
inseparability. Basically, an interval is inseparable because it cannot be covered
by the union of two open sets without the sets intersecting in at least one point
- well, without cheating, that is. If we start with two nonempty open sets that
are disjoint (have an empty intersection), then we can always add an interval
in one of them. We need to be sure that we deal with this in the statement of
our theorem.
Inseparability of closed intervals
Theorem 18.2.1
(The Inseparability Theorem). Let I ⊆ℝbe an interval,
and 1 and 2 be open subsets of ℝ. If I ⊆1 ∪2 and 1 ∩2 = ∅, then either
I ⊆1 or I ⊆2.
Proof. Assume that I ⊆ℝis an interval. Assume that 1 and 2 are open sets.
Assume I ⊆1 ∪2. Assume 1 ∩2 = ∅.
Assume BWOC I ⊈1 and I ⊈2.
First, I ⊈1 implies that ∃t ∈I with t ∉1. But I ⊆1 ∪2; so t ∈2.
Second I ⊈1 implies that ∃s ∈I with s ∉2. But I ⊆1 ∪2; so s ∈1.
Since I is an interval, the interval between s and t is a subset of I.
Thus, we can rename things and say we have an interval [a, b] ⊆1 ∪2
where a ∈1 and b ∈2.
Next let
B = {x ∈ℝ∣[a, x] ⊆1}.
(18.29)
Now [a, a] = {a} ⊆1; so a ∈B and B ≠∅. In addition, b ∉1, so ∀x ∈B,
x ≤b. That makes b an upper bound on B. By completeness B has a supremum,

18.2 Closed Intervals are Special
355
call it m. Since a ∈B, a ≤m. And because m is the least upper bound of B,
m ≤b. That says
m ∈[a, b].
(18.30)
But m ∈[a, b] ⊆1 ∪2 which leads to two cases.
Case 1: Assume m ∈1.
Since this is an open set, ∃𝜀> 0, s.t.
N(m, 𝜀) ⊆1.
(18.31)
Now m −𝜀< m = Sup(B). So ∃s ∈B such that m −𝜀< s. In addition, by the
average theorem, there is t ∈(s, m + 𝜀). Now
m −𝜀< s ≤m < t < m + 𝜀.
(18.32)
But s ∈B; so [a.s] ⊆1.
Consider [a, t].
[a, t] = [a.s] ∪(m −𝜀, t]
(18.33)
⊆[a.s] ∪(m −𝜀, m + 𝜀)
⊆[a.s] ∪N(m, 𝜀)
⊆1 ∪1 = 1.
Thus, t ∈B. But t > m = Sup(B). This is a contradiction.
Case 2. Assume m ∈2.
Since this is an open set, ∃𝜀> 0, such that
N(m, 𝜀) ⊆2.
(18.34)
Now m −𝜀< m = Sup(B). So ∃s ∈B s.t. m −𝜀< s. Now s ∈B; so [a, s] ⊆1.
So b ∈1. But we also have
m −𝜀< s ≤m < m + 𝜀.
(18.35)
So s ∈N(m, 𝜀) ⊆2. Since s ∈1 ∩2, this is a contradiction.
Thus, our assumption that I ⊈1 and I ⊈2 must be false. That is, I ⊆1
or I ⊆2.
◽
Sets that are both open and closed
There is a consequence of the inseparability theorem that settles one question
that arose in our examples.
Theorem 18.2.2.
Let A ⊆ℝ. If A is both open and closed, then either A = ∅or
A = ℝ.
Proof. Assume A ⊆ℝ. Assume that A is open. Assume that A is closed.

356
18 Compact Sets
Now if we let 1 = A and 2 = ℝ\A, we have two open sets with 1 ∩2 ≠∅
and where ℝ⊆1 ∪2. Since ℝis an interval, the inseparability theorem
tells us that either ℝ⊆1 = A ⊆ℝor ℝ⊆2 = ℝ\A ⊆ℝ. So either A = ℝor
A = ∅.
◽
18.3
Problems
18.1
Is the empty set compact?
18.2
Prove: If A ⊆ℝand 𝜕(A) = ∅, then either A = ∅or A = ℝ.
18.3
Prove ⋃
n∈ℕ
(−n, n) = ℝ.
18.4
Prove that every ﬁnite subset of ℝis compact.
(a) Prove this using the Heine–Borel theorem.
(b) Prove this using the deﬁnition of compact.
18.5
Let A ⊆B ⊆ℝ. Assume that A ≠∅is closed and B is compact.
(a) Prove that A is compact using the Heine–Borel theorem.
(b) Prove that A is compact using the deﬁnition of compact. (Hint: Start
with an open cover of the correct set and add the set ℝ\A.)
18.6
Let A ⊆ℝbe nonempty and bounded below. Prove that if A is open, then
Inf(A) ∈A′.
18.7
Let A ⊆ℝbe nonempty and bounded below. Prove that if Inf(A) ∉A′,
then Inf(A) ∈A∘.
18.8
Let A ⊆ℝ. Prove the contrapositive of the inseparability theorem: If for
all pairs of open sets 1 and 2 such that A ⊆1 ∪2, then either A ⊆
1, or A ⊆2, or 1 ∩2 ≠∅, then A is an interval.
18.9
Let A ⊆ℝbe a nonempty set. Prove:
(a) If A′ = ∅, then A is closed.
(b) If A′ = ∅, then A = A∘.
(c) If A′ = ∅, then there exists a family of open sets a indexed by a ∈A
so that ∀a ∈A, a ∩A = {a}.

18.3 Problems
357
(d) If A′ = ∅, then there exists a family of open sets a indexed by a ∈A
so that ∀a ∈A, a ∩A = {a} and where A ⊆⋃
a∈A
a.
(e) If A is bounded and A′ = ∅, then A is ﬁnite. (Hint: Intersect both
sides of the last subset relation with A.)
(f) The Bolzano–Weierstrass theorem: If A is an inﬁnite bounded subset
of ℝ, then A′ ≠∅.

359
19
Continuous Functions
19.1
First semester calculus
19.1.1
An intuitive idea of a continuous function
In any ﬁrst semester calculus course, there is a discussion of continuous func-
tions. Typically, there is an implicit assumption that the functions involved are
deﬁned on at least an interval in ℝ. This makes sense because our intuition
about a continuous function is based on our intuition of its graph being a con-
tinuous curve. This seems to only make sense when there is a piece of curve
long enough to be drawn without any holes or gaps. In the end, however, the
deﬁnition of a continuous function contains no requirement that the function
be deﬁned on any length of interval. In fact, the deﬁnition says what it means for
a function to be continuous at a single point. A function is said to be continuous
on an interval if it is continuous at every single point of the interval.
There is a lot left out of this early introduction to continuous functions.
A good calculus text will at least point out some consequences of this
point-by-point deﬁnition. It will state results such as:
The intermediate value theorem: If f (x) is a function continuous on an
interval [a, b] and y = c is a horizontal line between the points on (a, f (a))
and (b, f (b)) on the graph of y = f (x), then the graph must pass through
the line.
That sounds like something a continuous function should do. Later on, there
is a section in the text where students learn how to solve maximum and min-
imum problems. Many of the word problems of this type involve functions
y = f (x) that only make physical sense on a closed interval [a, b]. A shortcut
for ﬁnding the maximum and minimum values the function takes on in that
interval requires that the function be continuous on [a, b]. The shortcut uses
The extreme value theorem: If f (x) is a function continuous on an
interval [a, b], there are values c, d ∈[a, b] so that f (c) is the minimum
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

360
19 Continuous Functions
value the function has on the interval and f (d) is the maximum
value.
That also sounds like something a continuous function should do. It is also
very useful. The theorem says that there must be a minimum and a maximum,
and calculus tells us that they must occur at either critical points in the inter-
val or the end points of the interval. We know the end points; we can ﬁnd the
critical points. If we just ﬁnd the values of f (x) at these few points, the greatest
must be the maximum of all the values of points in the interval, and the least
must be the minimum.
So our ﬁrst mathematical introduction to continuity left out a lot of detail.
However, one thing is absolutely correct, the deﬁnition of a function being con-
tinuous at a point is the oﬃcial deﬁnition of mathematical continuity. We will
ﬁnally make up for these early shortcomings of our mathematical education
and prove the expected results. Our careful deﬁnitions of functions and inter-
vals and our language of topology were designed to make the whole process
quite logical.
19.1.2
The calculus deﬁnition of continuity
The rather amazing thing is that simply saying what we do not want the graph
of a continuous function to look like at one point on an interval is enough to
give us a mathematical deﬁnition of continuity that has universal application.
While the motivation is based on the curve that forms the graph (the ordered
pairs), we must remember that we are interested in the function (the assign-
ment of numbers in the domain to numbers in the range). Basically, there are
four pictures of the graph of a discontinuous function:
• The graph of the function has a hole in its graph. This is illustrated in
Figure 19.1.
• The graph of the function has a hole in its graph, but someone tried to ﬁll it
in and missed. This is illustrated in Figure 19.2.
−3
−2 −1
1
2
1
2
3
4
5
Figure 19.1 A discontinuity.

19.1 First Semester Calculus
361
Figure 19.2 A second type of discontinuity.
−3
−2 −1
1
2
1
2
3
4
5
Figure 19.3 A third type of discontinuity.
−3
−2 −1
1
2
1
2
3
4
5
Figure 19.4 A fourth type of discontinuity.
−3
−2 −1
1
2
1
2
3
4
5
• The graph of the function jumps from one height to another with a mark
inside or outside the gap. This is illustrated in Figure 19.3.
• The graph of the function jumps from one height to another but, on one
side or the other, the graph is capped oﬀat one end. This is illustrated in
Figure 19.4.
The ﬁrst example is easy to deal with. The graph has a hole at x = a because
the function is not deﬁned at x = a. (In the ﬁgures, a = 2.) To even stand a

362
19 Continuous Functions
chance to be continuous at x = a, then a must be in the domain of the function.
This is why, in the next three cases, we make sure to place a point directly above
a on the x-axis.
The main thing is to describe the next three cases with one mathematical
phrase. The problem may appear to be with the graph, but we want to con-
centrate on the function. The domain of the function is the x-axis, and the
codomain is the y-axis. The gap we are worried about appears clearly on the
vertical line above x = a. Because it is vertical, we push the graph over to the
codomain to see what the discontinuity looks like there.
We see that we do not want to look at the whole range of the function, because
the gap caused by the discontinuity gets covered up by other parts of the graph
far away from the singularity. We need to stay close to the x = a in the domain
so as to not lose that gap. We stay close to x = a by considering the image of
an appropriate neighborhood of a. In the second and third examples, there is a
neighborhood of a (in the domain) small enough that the image of that neigh-
borhood leaves f (a) an isolated point in the codomain. We can say this in our
new language of topology.
In the second and third examples, the function is not continuous because
there is a 𝛿> 0 so that f (a) is a discrete point of f (N(a, 𝛿)).
This is not the only way a function will be discontinuous, but these two
examples do tell us that the issue is with points in the image of neighborhoods
of a. So we know what to look at in the ﬁnal picture. In this case, f (a) is not
a discrete point of f (N(a, 𝛿)), but it is separated from some of the points in
f (N(a, 𝛿)). Now we will make a series of restatements of this basic notion
of discontinuity that gradually become closer to a logical form we can deal
with:
1. The function f (x) is not continuous at x = a because there is a neighborhood
of f (a) that does not contain the entire image of any neighborhood of a.
2. The function f (x) is not continuous at x = a because there is a neighborhood
N(f (a), 𝜀) of f (a) so that the image of every neighborhood of a contains a
point not in N(f (a), 𝜀).
3. The function f (x) is not continuous at x = a because there is a neighborhood
N(f (a), 𝜀) of f (a) so that, for every neighborhood N(a, 𝛿) of a, the image of
N(a, 𝛿) is not a subset of N(f (a), 𝜀).
4. The function f (x) is not continuous at x = a because there is an 𝜀> 0 so that,
for every neighborhood N(a, 𝛿) of a, f (N(a, 𝛿)) ⊈N(f (a), 𝜀).
5. The function f (x) is not continuous at x = a because there is an 𝜀> 0 so that
for all 𝛿> 0, f (N(a, 𝛿)) ⊈N(f (a), 𝜀).
This formulation covers all cases with a in the domain, and f (x) is still not
continuous at x = a. We now know what it means for a function not to be

19.1 First Semester Calculus
363
continuous at x = a in the domain:
∃𝜀> 0 s.t. ∀𝛿> 0, f (N(a, 𝛿)) ⊈N(f (a), 𝜀).
(19.1)
We negate this to ﬁnd out what it means for a function to be continuous at x = a
in the domain:
∀𝜀> 0, ∃𝛿> 0 s.t. f (N(a, 𝛿)) ⊆N(f (a), 𝜀).
(19.2)
Let us keep going. This says ∀𝜀> 0, ∃𝛿> 0 such that if x ∈N(a, 𝛿), then f (x) ∈
N(f (a), 𝜀). In the language of Calculus I, this says:
∀𝜀> 0, ∃𝛿> 0 s.t. if |x −a| < 𝛿, then |f (x) −f (a)| < 𝜀.
(19.3)
Just about every calculus textbook in the world contains this deﬁnition.
19.1.3
The oﬃcial mathematical deﬁnition of continuity
Basically, we just stated the oﬃcial deﬁnition; however, we have not been that
careful with our functional notation. We ﬁx that now.
Deﬁnition 19.1.1.
Let f ∶ℝ→ℝhave domain D. We say that f (x) is contin-
uous at x = a if
1. a ∈D;
2. ∀𝜀> 0, ∃𝛿> 0, such that if x ∈D and |x −a| < 𝛿, then |f (x) −f (a)| < 𝜀.
Equivalently,
1. a ∈D;
2. ∀𝜀> 0, ∃𝛿> 0 s.t. f (N(a, 𝛿)) ⊆N(f (a), 𝜀).
There are two versions of this deﬁnition. As a rule, the ﬁrst algebraic deﬁni-
tion is preferred when the function involved is given by an explicit formula, the
kind of function f ∶ℝ→ℝwe saw in calculus. The second topological deﬁni-
tion works best on abstract functions, the kind that appear in general theorems
involving continuity. We will see plenty of examples of both.
We also should look into the sudden appearance of the condition x ∈D in the
second part of the algebraic version. This is actually there for logical reasons.
We know from logic that P ⇒Q is automatically true if P is false or if Q is
true. But what happens if Q has no truth value at all? For P ⇒Q to be a logical
statement, both P and Q must be logical statements. Look at “|f (x) −f (a)| < 𝛿;”
it is not a logical statement until the x is qualiﬁed. It makes no sense unless
x ∈D. The rules of logic tell us that P ⇒Q is automatically true if Q is true,
but they does not cover the situation where Q is not a logical statement at all.
So we add the condition x ∈D to the statement just to be sure that it means
something. Then our deﬁnition (if x ∈D and |x −a| < 𝛿, then |f (x) −f (a)| < 𝜀)

364
19 Continuous Functions
is a logical statement; so it will be either true or false. That is what we use in the
algebraic deﬁnition:
We say that f (x) is continuous at x = a if
1. a ∈D;
2. ∀𝜀> 0, ∃𝛿> 0, such that if x ∈D and |x −a| < 𝛿, then | f (x) −f (a)| < 𝜀.
In the topological deﬁnition, the set theory deﬁnition of image takes care of
this problem.
f (N(a, 𝛿)) = {y ∈ℝ| ∃x ∈N(a, 𝛿) s.t. f (x) = y}.
(19.4)
Thus, y is not in the set unless f (x) = y for some x ∈N(a, 𝛿). But f (x) = y means
that x must be an element of D. The deﬁnition of the image of a set means that
f (N(a, 𝛿) ∩D) = f (N(a, 𝛿)).
(19.5)
The algebraic and topological deﬁnitions of continuity are exactly the same.
19.1.4
Examples
Example 19.1.2.
Let f ∶ℝ→ℝbe given by f (x) = 3x −5. Prove that this is
continuous at x = 4.
Comment: Linear functions are so easy that this is probably the only time we will
ever see one done carefully. What are we proving? ∀𝜀> 0, ∃𝛿> 0 s.t. if x ∈D
and |x −a| < 𝛿, then |f (x) −f (a)| < 𝜀. We choose the algebraic version because
f (x) is given by a formula. We know how to start such a proof.
Proof draft. Assume 𝜀> 0.
Comment: Now what are we proving? ∃𝛿> 0 s.t. “something weird.” We prove
that something exists by setting up a word problem and solving it. We have hit
a point where this really must be done outside the proof using scratch work. We
might be able to guess a good 𝛿in this particular example, but remember, this
example is so easy that we will probably never see one as this again. We are
more interested in the reasoning that produces a correct proof than the proof
itself.
Scratch work:
We want 𝛿so that 𝛿> 0 and so that if x ∈D and |x −a| < 𝛿, then |f (x) −f (a)| <
𝜀. Since D = ℝwe can ignore the ﬁrst condition. We concentrate on
|x −a| < 𝛿⇒|f (x) −f (a)| < 𝜀.
(19.6)

19.1 First Semester Calculus
365
Once we have a 𝛿, the proof of this will begin with: Assume |x −4| < 𝛿. And it
will end with |f (x) −f (4)| < 𝜀. We look at the end and work backward.
|f (x) −f (4)| < 𝜀;
(19.7)
|(3x −5) −7| < 𝜀;
|3x −12| < 𝜀;
|3(x −4)| < 𝜀;
3|x −4| < 𝜀.
We must be very lucky. The one thing we have control over is |x −4|, and it has
appeared in what we need to prove. To get this last inequality, we need
|x −4| < 𝜀
3.
(19.8)
We can get this by picking 𝛿= 𝜀
3.
Back to our draft of the proof.
Assume 𝜀> 0. Let 𝛿= 𝜀
3.
Claim. If x ∈ℝand |x −4| < 𝛿, then |f (x) −f (4)| < 𝜀.
Proof of claim. Assume |x −4| < 𝛿. Then |x −4| < 𝜀
3. So we have
|x −4| < 𝜀
3;
(19.9)
3|x −4| < 𝜀;
|3x −12| < 𝜀;
|(3x −5) −7| < 𝜀;
|f (x) −f (4)| < 𝜀.
◾
Comment: So our scratch work made it into the proof after all, just backward.
This is what we should expect in most proofs that require extensive scratch work.
The work appears logically backward in the written proof. In addition, notice
that as we write up this proof of continuity, we assume that we have an 𝜀and
then assign a value to the 𝛿. We then prove that the 𝛿works by making a claim
that: if x ∈D and |x −a| < 𝛿, then |f (x) −f (a)| < 𝜀. We then prove the claim.
This is just one option in how the proof is written. It does, however, help organize
the logic of this type of proof. So as we do our ﬁrst continuity proofs, we will stick
with this organization.
Δ
Proof. Assume 𝜀> 0. Let 𝛿= 𝜀
3.

366
19 Continuous Functions
Claim. If x ∈ℝand |x −4| < 𝛿, then |f (x) −f (4)| < 𝜀.
Proof of claim. Assume |x −4| < 𝛿. Then |x −4| < 𝜀
3. So we have
|x −4| < 𝜀
3;
(19.10)
3|x −4| < 𝜀;
|3x −12| < 𝜀;
|(3x −5) −7| < 𝜀;
|f (x) −f (4)| < 𝜀.
◾
This completes our proof that f (x) = 3x −5 is continuous at x = 4.
◽
What about that moment of luck? Well, the reason we were so lucky is that we
were proving a theorem that was true. It had to work. If we are proving that f (x)
is continuous at x = a and it is true, we should expect to turn |f (x) −f (a)| < 𝜀
into something involving |x −a|.
Now that we have done this example, we realize that the choice of 𝛿= 𝜀
3
should have been clear. The slope of this linear function is 3; the way to get
a change in y of 𝜀is to make a change in x of 𝜀
3. Sure enough, the slope at x = a
will always play a role in proving that f (x) is continuous at x = a; however, not
in a very straightforward way. The problem is in any function other than a linear
function, the slope at a point changes with even a small change away from the
point. The power of calculus is that it allows us to deal with a changing slope.
Unfortunately, we do not have calculus yet. Worse, in order to get calculus, we
need to understand continuity.
In the following examples, we illustrate a typical strategy for proving that a
function is continuous at a point. Such proofs will always begin by ﬁxing an
arbitrary 𝜀> 0. The goal then, as we have seen, is to construct 𝛿> 0 so that
if |x −a| < 𝛿, then |f (x) −f (a)| < 𝜖. A typical strategy for constructing 𝛿is as
follows.
1. Find an approximation of the slope ma of the function at x = a.
2. Choose a neighborhood N(a, 𝛿a) of x = a where that approximation is valid.
Then a typical choice of 𝛿looks like
𝛿= Min
({
𝜀
ma
, 𝛿a
})
.
(19.11)
The result of this choice of 𝛿is that 𝛿≤
𝜀
ma , and 𝛿≤𝛿a. That way the
𝜀
ma will
do a slope-like thing, and 𝛿a will make sure that ma is close enough to the real
slope that the approximation will work.
Oddly enough, we usually pick the 𝛿a ﬁrst, and we pick it by guessing.

19.1 First Semester Calculus
367
Example 19.1.3.
Let f ∶ℝ→ℝbe given by f (x) = 3x2 −x −5. Prove that
this is continuous at x = 4.
Comment: All these proofs begin the same way, by ﬁxing an arbitrary 𝜀> 0 and
then declaring our choice of 𝛿. However, the real work of the proof is ﬁnding that
𝛿, and we have not even started yet. The process outlined earlier gives us an idea
of what 𝛿might look like. Once we ﬁnd our 𝛿using that process, our proof will
begin as follows.
Proof draft. Assume 𝜀> 0. Let 𝛿= Min({◽, ◽}). Then 𝛿> 0, and 𝛿≤◽and
𝛿≤◽.
Comment: Yes, those are empty boxes. Again, we expect that our process for ﬁnd-
ing 𝛿will work, but we have not even started that yet! In our draft here, we start
with a simple logical outline for the beginning of the proof even though we have
a lot of parts that we need to ﬁll in. Once we have built a 𝛿that we know works,
we will rewrite our scratch work as a proof. As we go along, each time we make
a bit of progress, we will see how far we can push the proof.
At this point, we need to prove
If x ∈ℝand |x −4| < 𝛿, then |f (x) −f (4)| < 𝜀.
So far we can say: assume |x −4| < 𝛿. Then |x −4| < ◽and |x −4| < ◽.
Ok, there is not too much we can do at this point.
We now turn to ﬁlling in the boxes. In one box, we need to pick a range around 4
that will keep the approximation of the slope (once we ﬁnd it) out of trouble. This
value is the 𝛿a referred to in the aforementioned process. As we mentioned, we
start by guessing at this value. In principle, the smaller we choose 𝛿a, the better,
but in practice, choosing something like
1
1000 makes the calculations miserable.
We keep things simple at the start by making our default ﬁrst guess 𝛿a = 1. With
this guess, let us see how far we can push our proof.
Assume 𝜀> 0. Let 𝛿= Min({1, ◽}). Then 𝛿> 0, and 𝛿≤1 and 𝛿≤◽.
Claim. If x ∈ℝand |x −4| < 𝛿, then |f (x) −f (4)| < 𝜀.
Draft proof of this claim so far. Assume |x −4| < 𝛿. Then |x −4| < 1 and
|x −4| < ◽.
Now |x −4| < 1. So
−1 < x −4 < 1;
(19.12)
3 < x < 5.
Comment: We carried out the logic to say as much as we can about x. There
might be other useful things to say at this point, but we need to analyze our goal

368
19 Continuous Functions
a little more. We will do some scratch work to ﬁgure out where we need to go
with this.
◾
Scratch work:
We want
|x −4| < 𝛿⇒|f (x) −f (4)| < 𝜀.
(19.13)
We try to turn |f (x) −f (4)| into something involving |x −4|. To do so, we look
at the end and work backward.
|f (x) −f (4)| < 𝜀;
(19.14)
|3x2 −x −5 −39| < 𝜀;
|3x2 −x −44| < 𝜀;
|(3x + 11)(x −4)| < 𝜀;
|3x + 11| ⋅|x −4| < 𝜀.
This tells us that if we can arrange things so that
|3x + 11| ⋅|x −4| < 𝜀,
then we can show that |f (x) −f (4)| < 𝜀.
Comment: Our goal in this scratch work was to write |f (x) −f (4)| with a factor of
|x −4| because that is the quantity that we can control. In addition, remember
that we know |x −4| will be a factor. If it is not, either we are trying to prove
something that is false or we have made an algebra mistake.
Now we would like to divide both sides by |3x + 11|, but we cannot be sure
that this is legal unless we are sure that |3x + 11| ≠0. But this is exactly what
our control value 𝛿a is for, to keep this factor from being 0. Did it do the job? We
use what we know about x to say as much as we can about |3x + 11|. We stopped
our draft of the proof saying something about x. We start over again in our draft
using that to say something about |3x + 11|.
Assume 𝜀> 0. Let 𝛿= Min({1, ◽}). Then 𝛿> 0, and 𝛿≤1 and 𝛿≤◽.
Claim. If x ∈ℝand |x −4| < 𝛿, then |f (x) −f (4)| < 𝜀.
Draft proof of this claim so far. Assume |x −4| < 𝛿. Then |x −4| < 1 and
|x −4| < ◽.
Now |x −4| < 1. So
−1 < x −4 < 1;
(19.15)
3 < x < 5;
9 < 3x < 15;

19.1 First Semester Calculus
369
20 < 3x + 11 < 26;
20 < |3x + 11| < 26;
1
26 <
1
|3x + 11| < 1
20;
𝜀
26 <
𝜀
|3x + 11| < 𝜀
20.
◾
Comment: On the ﬁfth step of this calculation, we found out that it was safe
to divide by |3x + 11|. We kept going to see what would happen when we did.
Remember where we were when we suspended the scratch work. We wanted
|f (x) −f (4)| < 𝜀, and we could get it if
|3x + 11| ⋅|x −4| < 𝜀.
(19.16)
But now we can divide:
|x −4| <
𝜀
|3x + 11|.
(19.17)
This tells us that if we can get |x −4| <
𝜀
|3x+11|, then we can get |f (x) −f (4)| < 𝜀.
However, we cannot let 𝛿=
𝜀
|3x+11| in our proof. This is why we outlined the logic
of the proof ﬁrst. We see that in that logic, x appears when we make our claim.
Part of our assumptions about x involve the value for 𝛿that we choose. So the x
depends on the 𝛿. A choice of a 𝛿that involves x would create circular reasoning
in the proof. We cannot let this happen. This is very important to remember:
The 𝛿in a proof of continuity cannot involve the variable x in the later claim:
If x ∈ℝand |x −a| < 𝛿, then |f (x) −f (a)| < 𝜀! But we do not need 𝛿=
𝜀
|3x+11|
to get where we want. All we need is
|x −4| <
𝜀
|3x + 11|.
(19.18)
We could use transitivity if we could only ﬁnd some “?” that ﬁt between these
|x −4| < ? <
𝜀
|3x + 11|.
(19.19)
We know for sure
𝜀
26 <
𝜀
|3x + 11|.
(19.20)
If we ﬁll in the still empty box in the 𝛿(Let 𝛿= Min({1, ◽})) with
𝜀
26, then
we would know that if |x −4| < 𝛿, then |x −4| <
𝜀
26, and then by transitivity,
|x −4| <
𝜀
|3x+11|.
So we have ﬁnally found our 𝛿! We can now return and ﬁnish oﬀour draft of
a proof. Instead, we will start over completely and write the ﬁnal version of the
whole proof.
Δ

370
19 Continuous Functions
Example 19.1.4.
Let f ∶ℝ→ℝbe given by f (x) = 3x2 −x −5. Prove that
this is continuous at x = 4.
Proof. Assume 𝜀> 0. Let 𝛿= Min({1, 𝜀
26}). Then 𝛿> 0, and 𝛿≤1 and 𝛿≤
𝜀
26.
Claim. We claim that if x ∈ℝand |x −4| < 𝛿, then |f (x) −f (4)| < 𝜀.
Proof of claim. Assume |x −4| < 𝛿. Then |x −4| < 1 and |x −4| <
𝜀
26.
Now |x −4| < 1. So
−1 < x −4 < 1;
(19.21)
3 < x < 5;
9 < 3x < 15;
20 < 3x + 11 < 26;
20 < |3x + 11| < 26;
1
26 <
1
|3x + 11| < 1
20;
𝜀
26 <
𝜀
|3x + 11| < 𝜀
20.
But we then have
|x −4| < 𝜀
26 <
𝜀
|3x + 11|.
(19.22)
So
|x −4| <
𝜀
|3x + 11|;
(19.23)
|3x + 11| ⋅|x −4| < 𝜀;
|3x2 −x −44| < 𝜀;
|3x2 −x −44| < 𝜀;
|3x2 −x −5 −39| < 𝜀;
|f (x) −f (4)| < 𝜀.
◾
So if 𝜀> 0 and 𝛿= Min({1, 𝜀
26}), then 𝛿> 0 and if x ∈ℝand |x −4| < 𝛿, then
|f (x) −f (4)| < 𝜀. We have therefore proved f (x) is continuous at x = 4.
◽
Notice that our default guess of 1 for a control worked quite well. If it had not,
we would have hit an interval for x −a that included 0. When this happens, and
it will on occasion, it is simply a matter of choosing a smaller control. By this
time, however, the scratch work may help make a more informed choice. Still
we must remember that 1 is our default guess, but it is still a guess. If we have
the chance to make a more informed guess, we should.

19.1 First Semester Calculus
371
Example 19.1.5.
Let f ∶ℝ→ℝbe given by f (x) =
1
2x−5. Prove that this is
continuous at x = 2.
Proof draft. Comment: Notice that the domain of this function is ℝ∖{ 5
2}. It is
pretty clear then that x = 5
2 is a point that we should steer clear of. Still all the
proofs begin the same way.
Assume 𝜀> 0. Let 𝛿= Min({◽, ◽}). Then 𝛿> 0, and 𝛿≤◽and 𝛿≤◽.
Comment: We want to prove
If x ∈ℝand |x −2| < 𝛿, then |f (x) −f (2)| < 𝜀.
So far we can say: assume |x −2| < 𝛿. Then |x −2| < ◽and |x −2| < ◽.
Again, not too much to say at this point. But it is a good idea to always keep in
mind where we are headed and to see how much further we can push this each
time we make progress.
Notice that we want to make sure that x is not close to 5
2; so a control of 1 will
be too big because 5
2 is less than one away from 2. In fact, we could be daring and
try 1
2, but that is cutting it very close. Better to make our ﬁrst guess 1
4. Let us work
backward from what we want to ﬁgure out a good choice for our other bound
on 𝛿.
Scratch work:
We want |f (x) −f (2)| < 𝜀. This is
||||
1
2x −5 + 1
||||
< 𝜀.
(19.24)
Finding a common denominator and simplifying the left-hand side gives
||||
2x −4
2x −5
||||
< 𝜀.
(19.25)
And now we see our desired factor of |x −2|:
2|x −2|
|2x −5| < 𝜀.
(19.26)
So, if we can make sure that
|x −2| < |2x −5|𝜀
2
.
(19.27)
then, since all of these steps are reversible, we can force |f (x) −f (2)| < 𝜀. Now,
again, x cannot appear in our choice for 𝛿, so we need to ﬁnd a “?” that does not
depend on x and satisﬁes
|x −2| <? < |2x −5|𝜀
2
.
(19.28)

372
19 Continuous Functions
That brings up the question of just how big |2x −5| is anyway. After all, by our
choice of control |x −2| < 1
4. So
−1
4 <x −2 < 1
4;
(19.29)
−1
2 <2x −4 < 1
2;
−3
2 <2x −5 < −1
2.
So, 1
2 < |2x −5| < 3
2. Since 1
2 < |2x −5|, it follows that 𝜀
4 < |2x−5|𝜀
2
.
Comment: Ok, now we have found our 𝛿. If we choose 𝛿= Min
({
𝜀
4, 1
4
})
then
our proof should work!
Δ
Let us rewrite this all as a formal proof, with all of the calculations going in
the direction we need.
Proof. Here recall that we are proving that f ∶ℝ→ℝgiven by f (x) =
1
2x−5 is
continuous at x = 2.
Assume 𝜀> 0. Let 𝛿= Min
({
1
4, 𝜀
4
})
. Then 𝛿> 0, and 𝛿≤1
4 and 𝛿≤𝜀
4.
Claim. If x ∈ℝand |x −2| < 𝛿, then |f (x) −f (2)| < 𝜀.
Proof of claim. Assume |x −2| < 𝛿. Then |x −2| < 1
4 and |x −2| < 𝜀
4.
First |x −2| < 1
4. Then
−1
4 < x −2 < 1
4;
−1
2 < 2x −4 < 1
2;
(19.30)
−3
2 < 2x −5 < −1
2;
1
2 < |2x −5| < 3
2;
1
4 < |2x −5|
2
< 3
4.
What is important here is that 1
4 < |2x−5|
2
because that allows us to conclude
that 𝜀
4 < |2x−5|𝜀
2
. Since we also have |x −2| < 𝜀
4, we can calculate as follows:
|x −2| < |2x −5|𝜀
2
;
(19.31)

19.1 First Semester Calculus
373
2|x −2|
|2x −5| < 𝜀;
||||
2x −4
2x −5
||||
< 𝜀;
||||
1
2x −5 + 1
||||
< 𝜀;
|f (x) −f (2)| < 𝜀.
◾
We have now shown that for any 𝜀> 0, we can ﬁnd 𝛿> 0 so that if |x −2| < 𝛿,
then |f (x) −f (2)| < 𝜀. It follows that f (x) is continuous at x = 2.
◽
There is another way to think about the control part of “Let 𝛿=
Min({ 1
4, 𝜀
4
}).” These arguments are all about small values of 𝜀and 𝛿.
But the formula that uses these variables works for all values no matter how big
or small. Our calculations are meant to cover the cases where these numbers
are small. The control part of the minimum 1
4, makes sure that we are doing
just that; it makes sure that a value of 𝜀= 10100 does not mess up the whole
argument by letting 𝛿be ridiculously large. There are times when we will need
to place this size control on the 𝜀before we get to the 𝛿. It still plays the same
role of keeping both 𝜀and 𝛿reasonably small.
Our next example illustrates this. It solves a technical problem that we have at
this point in our study of the real numbers. While we expect that every positive
real number will have a square root, we have not yet proved this. We will soon
enough, but until then we cannot assume it for fear of creating some circular
reasoning.
Example 19.1.6.
Let f ∶ℝ→ℝbe given by f (x) = x2. Prove that this is con-
tinuous at x = 0.
Comment: Luckily, the domain is ℝ, so we do not have to worry about acciden-
tally including a point not in the domain by choosing our control too large.
Again, all these proofs begin the same way. Here, since there are no domain
issues to worry about, we will go back to our default guess of 1 for the control.
Proof draft. Assume 𝜀> 0. Let 𝛿= Min({1, ◽}). Then 𝛿> 0, and 𝛿≤1 and
𝛿≤◽.
Comment: We aim to prove that
If x ∈ℝand |x −0| < 𝛿, then |f (x) −f (0)| < 𝜀.
So far we can say: assume |x −0| < 𝛿. Then |x −0| < 1 and |x −0| < ◽.
Again, not too much to say at this point, but we remind ourselves of what we
need to do.

374
19 Continuous Functions
Scratch work:
We want |f (x) −f (0)| < 𝜀, but that is simply |x2| < 𝜀. That is |x|2 < 𝜀. Clearly,
we want 𝛿=
√
𝜀, but that is not yet allowed.1 Whenever we feel we need a
square root to pick the right 𝛿, we should remember the following trick, which
we illustrate in the ﬁnal version of this proof.
Δ
Proof. Assume 𝜀> 0. Let 𝜀0 = Min({𝜀, 1}). Then 𝜀0 > 0, 𝜀0 ≤𝜀, and 𝜀0 ≤1.
However, because 𝜀0 > 0, we can multiply 𝜀0 ≤1 by it. So 𝜀2
0 ≤𝜀0, and in turn,
𝜀2
0 ≤𝜀0 ≤𝜀.
Let 𝛿= 𝜀0.
Claim. If x ∈ℝand |x −0| < 𝛿, then |f (x) −f (0)| < 𝜀.
Proof of claim. Assume |x| < 𝛿. Then |x|< 𝜀0 and
|x|2 < 𝜀2
0 ≤𝜀0 ≤𝜀.
(19.32)
Thus, |f (x) −f (0)| = |x2| < 𝜀.
◾
We have now shown that, for any 𝜀> 0, we can ﬁnd 𝛿> 0 so that, if |x −0| <
𝛿, then |f (x) −f (0)| < 𝜀. It follows that f (x) is continuous at x = 0.
◽
In the ﬁrst examples, our ﬁrst drafts of the proofs came out so well that they
can serve as the ﬁnal version. We were lucky, our ﬁrst guess for the control value
worked. In the last example, the original draft needed to be revised, but after
that, the draft came out pretty clean. We cannot count on this always happen-
ing. As always, if the draft is correct but needs rewriting, we are not done with
the proof until it is rewritten.
19.2
Theorems about continuity
The object now is to develop a theory of continuous functions that will eliminate
the need, except as an exercise, to prove that every function is continuous at
every point using the 𝛿-𝜀-deﬁnition.
19.2.1
Three speciﬁc functions
We begin by proving general continuity results about three functions that will
provide seeds for use in the theorems that follow. The ﬁrst two are very simple.
1 As of now in the text we have only proved that
√
2 exits. We have not yet proved that the
square root of any positive number exists, so we do not want to assume it. But stay tuned!

19.2 Theorems About Continuity
375
Theorem 19.2.1.
Let f ∶ℝ→ℝbe given by f (x) = c for a constant c ∈ℝ.
Then f (x) is continuous at all x = a ∈ℝ.
Proof. Assume a ∈ℝ. Assume 𝜀> 0. Let 𝛿= 1 (or any other positive number
for that matter).
Claim. If x ∈ℝand |x −a| < 𝛿, then |f (x) −f (a)| < 𝜀.
Proof of claim. Assume |x −a| < 𝛿. Then |f (x) −f (a)| = |c −c| = 0 < 𝜀.
◾
This shows that f (x) = c is continuous at any a ∈ℝ.
◽
The moral here is that, if you cannot miss, you do not need to aim.
Theorem 19.2.2.
Let f ∶ℝ→ℝbe given by f (x) = x. Then f (x) is continuous
at all x = a ∈ℝ.
Proof. Assume a ∈ℝ. Assume 𝜀> 0. Let 𝛿= 𝜀.
Claim. We claim that with this choice of 𝛿, if x ∈ℝand |x −a| < 𝛿, then |f (x) −
f (a)| < 𝜀.
Proof of claim. Assume |x −a| < 𝛿= 𝜀. Then |f (x) −f (a)| = |x −a| < 𝜀.
◾
This proves that the function f ∶ℝ→ℝgiven by f (x) = x is continuous at all
x = a ∈ℝ.
◽
Theorem 19.2.3.
Let f ∶ℝ→ℝbe given by f (x) = 1
x. Then f (x) is continuous
at all x = a ∈ℝ∖{0}.
Proof. Assume a ∈ℝ.
Comment: This time the domain is ℝ∖{0}. It is pretty clear then that x = 0 is a
point that we should steer clear of.
Assume a ≠0.
Comment: We want to make sure that x is not close to 0; so a control of 1 might be
too big. But no precise number will ever be sure to work because we do not know
the value of a. Our guess must depend on a. Notice that we assume we have an
a ≠0 before we choose our 𝛿. That assures us that we can use a in a formula
for 𝛿. Now |a|
2 should work to keep x away from 0. But now that brings up the
question: is a > 0 or a < 0? It looks like we have two cases to consider.

376
19 Continuous Functions
There are two cases a > 0 or a < 0.
Case 1: Assume a > 0.
Comment: All of these proofs begin the same way.
Assume 𝜀> 0.
Comment: Unlike our last two theorems about the continuity of f (x) = c and
f (x) = x, this one requires some scratch work as we saw in our examples to ﬁgure
out what to choose for 𝛿. We are going to leave this scratch work out of this
write-up, but it is an essential part of the construction of the proof. Without it,
our choice for 𝛿will seem like it came out of nowhere.
Let 𝛿= Min({ a
2, a2𝜀
2 }). Then 𝛿> 0, and 𝛿≤a
2 and 𝛿≤a2𝜀
2 .
Claim. We claim that with this choice of 𝛿, if x ∈ℝand |x −a| < 𝛿, then |f (x) −
f (a)| < 𝜀.
Proof of claim. Assume |x −a| < 𝛿. Then |x −a| < a
2 and |x −a| < a2𝜀
2 .
Since |x −a| < a
2, we have
−a
2 < x −a < a
2;
(19.33)
a
2 < x < 3a
2 ;
a
2 < |x| < 3a
2
because a
2 > 0. Then we multiply by a𝜀> 0;
a2𝜀
2
< a𝜀|x| < 3a2𝜀
2
.
(19.34)
But we also have |x −a| < a2𝜀
2 . So
|x −a| < a|x|𝜀;
(19.35)
|x −a|
a|x|
< 𝜀;
||||
a −x
ax
||||
< 𝜀;
||||
1
x −1
a
||||
< 𝜀;
|f (x) −f (a)| < 𝜀.
◾
We leave case 2, where a < 0, as an exercise.
◽

19.2 Theorems About Continuity
377
19.2.2
Multiplying a continuous function by a constant
Theorem 19.2.4.
Let f ∶ℝ→ℝhave domain D. For c ∈ℝ, let g ∶ℝ→ℝbe
given by g(x) = cx. If f (x) is continuous at x = a, then g(x) is continuous at x = a.
The proof of this is easy unless we fall into the traps of not remembering our
arithmetic or of losing our logical discipline and assuming the wrong thing.
Proof draft. Assume c ∈ℝ. Let g(x) = cx. Assume that f (x) is continuous at
x = a. First note that D = Domain(f ) = Domain(g); so since f (x) must be
deﬁned at x = a to be continuous there, we know that a ∈D = Domain(g).
Because f (x) is continuous at x = a, we also know that ∀𝜀> 0, ∃𝛿> 0 such
that if x ∈D and |x −a| < 𝛿, then |f (x) −f (a)| < 𝜀.
Comment: This tells us that if we ever have an 𝜀> 0, then we will know some-
thing. It is important to note that this statement does not give an 𝜀for the proof.
Now, what are we proving? We want to prove that g(x) is continuous at
x = a. That is, if 𝜀> 0, then ∃𝛿> 0 such that if x ∈D and |x −a| < 𝛿, then
|g(x) −g(a)| < 𝜀. Now we can assume that we have an 𝜀. That leads us to some
scratch work.
Scratch work:
Once we have this 𝜀, we want |g(x) −g(a)| < 𝜀. So we want
|g(x) −g(a)| < 𝜀;
(19.36)
|cf (x) −cf (a)| < 𝜀;
|c| ⋅|f (x) −f (a)| < 𝜀;
|f (x) −f (a)| < 𝜀
|c|
Comment: With this we see that we are in luck. We can make |f (x) −f (a)|
smaller than any positive number. We can get what we need by using the
deﬁnition of f (x) continuous at x = a on the positive number
𝜀
|c|. Ah, but wait,
can we divide by |c|? We need to consider the case where c = 0.
There are two possibilities: c = 0 or c ≠0. In the ﬁrst case, g(x) = 0 is a con-
stant function. So it is continuous at x = a.
In case 2, assume c ≠0. Thus, |c| > 0.
Comment: What are we proving now? If we have any 𝜀> 0, then we can get g(x)
close to g(a) with a good 𝛿. So we begin as usual.
Assume 𝜀> 0. Then
𝜀
|c| > 0. Since f (x) is continuous at x = a, ∃𝛿> 0 such
that if x ∈D and |x −a| < 𝛿, then |f (x) −f (a)| <
𝜀
|c|.

378
19 Continuous Functions
Claim. If x ∈D and |x −a| < 𝛿, then |g(x) −g(a)| < 𝜀.
Proof of claim. Assume that we have x ∈D and |x −a| < 𝛿. Then
|f (x) −f (a)| < 𝜀
|c|.
(19.37)
So
|c| ⋅|f (x) −f (a)| < 𝜀;
(19.38)
|cf (x) −cf (a)| < 𝜀;
|g(x) −g(a)| < 𝜀.
◾
So g(x) is continuous at x = a.
Δ
This draft should be rewritten to give a nice proof. We leave that as an
exercise.
19.2.3
Adding continuous functions
Theorem 19.2.5.
Let f ∶ℝ→ℝhave domain D and let g ∶ℝ→ℝhave
domain E. Deﬁne h ∶ℝ→ℝby h(x) = f (x) + g(x).
If f (x) is continuous at x = a and g(x) is continuous at x = a, then h(x) is con-
tinuous at x = a.
Proof draft. Assume that f (x) is continuous at x = a and g(x) is continuous at
x = a. Then a ∈D and a ∈E; so a ∈D ∩E = Domain(h).
Scratch work:
We eventually will want |h(x) −h(a)| < 𝜀. So we want
|(f (x) + g(x) −(f (a) + g(a)| < 𝜀;
(19.39)
|(f (x) −f (a)) + (g(x) −g(a))| < 𝜀.
Now we can make both |f (x) −f (a)| and |g(x) −g(a)| as small as we want. But
what about the combination
|f (x) −f (a) + g(x) −g(a)|?
(19.40)
Luckily, we remember everything everyone has ever told us and can recall
things without notice. The triangle inequality says
|f (x) −f (a) + g(x) −g(a)| ≤|f (x) −f (a)| + |g(x) −g(a)|.
(19.41)
We should make |f (x) −f (a)| and |g(x) −g(a)| small enough that their sum is 𝜀.
We can return to our draft, but let us proceed to a polished proof.
Δ

19.2 Theorems About Continuity
379
Proof. Assume that f (x) is continuous at x = a and g(x) is continuous at x = a.
Then a ∈D and a ∈E; so a ∈D ∩E = Domain(h).
Assume 𝜀> 0. Then 𝜀
2 > 0.
Since f (x) is continuous at x = a, ∃𝛿f > 0 such that if x ∈D and |x −a| < 𝛿f ,
then |f (x) −f (a)| < 𝜀
2.
Since g(x) is continuous at x = a, ∃𝛿g > 0 such that if x ∈E and |x −a| < 𝛿g,
then |g(x) −g(a)| < 𝜀
2.
Let 𝛿h = Min({𝛿f , 𝛿g}). Then 𝛿h > 0, 𝛿h ≤𝛿f , and 𝛿h ≤𝛿g.
Claim. If x ∈D ∩E and |x −a| < 𝛿h, then |h(x) −h(a)| < 𝜀.
Proof of claim. Assume x ∈D ∩E and |x −a| < 𝛿h.
Then x ∈D and |x −a| < 𝛿f ; so |f (x) −f (a)| < 𝜀
2.
In addition, x ∈E and |x −a| < 𝛿g; so |g(x) −g(a)| < 𝜀
2.
So
|f (x) −f (a)| + |g(x) −g(a)| < 𝜀
2 + 𝜀
2.
(19.42)
|f (x) −f (a)| + |g(x) −g(a)| < 𝜀.
But the triangle inequality says
|f (x) −f (a) + g(x) −g(a)| ≤|f (x) −f (a)| + |g(x) −g(a)|.
(19.43)
But
|f (x) −f (a)∣+ ∣g(x) −g(a)| < 𝜀.
(19.44)
So
|(f (x) −f (a)) + (g(x) −g(a))| < 𝜀
(19.45)
and in turn |h(x) −h(a)| < 𝜀.
◾
This completes our proof that if f (x) is continuous at x = a and g(x) is con-
tinuous at x = a, then h(x) = f (x) + g(x) is continuous at x = a.
◽
19.2.4
Multiplying continuous functions
The reason why we prove theorems is to avoid reproving the same things over
and over. We could try to prove that the product of two continuous functions
is continuous using the deﬁnition, but that ignores the fact that we have proved
the last few theorems. We can save ourselves time by ﬁnding a way to use those
results to save us some work.
Lemma 19.2.6.
Let f ∶ℝ→ℝhave domain D and let g ∶ℝ→ℝhave
domain E. Deﬁne h ∶ℝ→ℝby h(x) = f (x)g(x). If f (x) is continuous at x = a

380
19 Continuous Functions
with f (a) = 0 and if g(x) is continuous at x = a with g(a) = 0, then h(x) is
continuous at x = a.
Proof draft. Assume that f (x) is continuous at x = a. Assume f (a) = 0. Assume
g(x) is continuous at x = a. Assume g(a) = 0. Assume 𝜀> 0. We ﬁrst observe
that h(x) has domain D ∩E, a ∈D ∩E, and so h(a) = f (a)g(a) = 0.
Comment: Now we need to ﬁgure out how to make the proof work. As usual, we
do some scratch work, working backward from what we want to ﬁgure out where
to start.
Scratch work:
We want |h(x) −h(a)| < 𝜀. Since h(a) = 0, we want |h(x)| < 𝜀. We want
|f (x)g(x)| < 𝜀;
(19.46)
|f (x)| ⋅|g(x)| < 𝜀.
Now we can make both |f (x)| = |f (x) −f (a)| and |g(x)| = |g(x) −g(a)| as small
as we want.2 But what about the combination |f (x)| ⋅|g(x)|? We should make
|f (x)| and |g(x)| small enough that their product is 𝜀. How about
√
𝜀? That is
not allowed yet. But we know what to do. Hiding any additional scratch work,
we move to the proof.
Δ
Proof. Assume that f (x) is continuous at x = a. Assume f (a) = 0. Assume g(x)
is continuous at x = a. Assume g(a) = 0. Assume 𝜀> 0.
Let 𝜀0 =Min({𝜀, 1}). Then 𝜀0 > 0, 𝜀0 ≤𝜀, and 𝜀0 ≤1. So 𝜀2
0 ≤𝜀0 ≤𝜀.
Since f (x) is continuous at x = a,
∃𝛿f > 0 s.t. if x ∈D and |x −a| < 𝛿f , then |f (x)| < 𝜀0.
(19.47)
Since g(x) is continuous at x = a,
∃𝛿g > 0 s.t. if x ∈D and |x −a| < 𝛿g, then |g(x))| < 𝜀0.
(19.48)
Let 𝛿h = Min({𝛿f , 𝛿g}). Then 𝛿h > 0, 𝛿h ≤𝛿f , and 𝛿h ≤𝛿g.
Claim. If x ∈D ∩E and |x −a| < 𝛿h, then |h(x) −h(a)| < 𝜀.
Proof of claim. Assume x ∈D ∩E and |x −a| < 𝛿h.
Then x ∈D and |x −a| < 𝛿f ; so |f (x) −f (a)|< 𝜀0.
In addition, x ∈E and |x −a| < 𝛿g; so |g(x) −g(a)|< 𝜀0.
2 Admittedly, we all know that we can indeed use
√
𝜀, but in this book, we are trying hard to only
use what we have proved, and although we know that
√
𝜀exists, we have not proved it.

19.2 Theorems About Continuity
381
So
|f (x)| ⋅|g(x)| < 𝜀2
0;
(19.49)
|f (x)g(x)| < 𝜀2
0 ≤𝜀;
|h(x) −h(a)| < 𝜀.
◾
This completes our proof that if f (x) is continuous at x = a with f (a) = 0, and
if g(x) is continuous at x = a with g(a) = 0, then h(x) = f (x)g(x) is continuous
at x = a.
◽
Our assumptions that f (a) = g(a) = 0 made this rather painless. But we want
a much more general result. But with all these theorems, we can avoid using
the deﬁnition of continuous in the proof.
Theorem 19.2.7.
Let f ∶ℝ→ℝhave domain D, and let g ∶ℝ→ℝhave
domain E. Deﬁne h ∶ℝ→ℝby h(x) = f (x)g(x).
If f (x) is continuous at x = a and g(x) is continuous at x = a, then h(x) is con-
tinuous at x = a.
Proof. Assume that f (x) is continuous at x = a. Then a ∈D. Assume g(x) is
continuous at x = a. Then a ∈E. Therefore a ∈D ∩E. Since h(x) has domain
D ∩E, we know that a ∈Domain(h).
Now let f1 ∶ℝ→ℝbe given by f1(x) = f (x) −f (a). This function has
domain D and is the sum of two functions continuous at x = a: namely f (x)
and the constant function k(x) = −f (a). So f1(x) is continuous at x = a and
f1(a) = 0.
Similarly, let g1 ∶ℝ→ℝbe given by g1(x) = g(x) −g(a). This function has
domain E and g1(x) is continuous at x = a and g1(a) = 0.
By Lemma 19.2.6, f1(x)g1(x) is continuous at x = a.
But consider f (x)g(x).
f (x)g(x) = (f1(x) + f (a)) ⋅(g1(x) + g(a))
(19.50)
= f1(x)g1(x) + f (a)g1(x) + g(a)f1(x) + f (a)g(a).
We know that f1(x)g1(x) is continuous at x = a. By Theorem 19.2.4, if we mul-
tiply continuous functions by constants, they remain continuous, so we know
that f (a)g1(x) and g(a)f1(x) are continuous at x = a. The ﬁnal part is just a con-
stant function; so the sum of all these is continuous at x = a. Thus, we con-
clude that if f (x) is continuous at x = a and g(x) is continuous at x = a, then
h(x) = f (x)g(x) is continuous at x = a.
◽

382
19 Continuous Functions
19.2.5
Polynomial functions
Theorem 19.2.8.
Let p ∶ℝ→ℝbe given by a polynomial. Then for all a ∈ℝ,
p(x) is continuous at x = a.
Proof. Write
p(x) = cnxn + cn−1xn−1 + · · · + c1x + c0
with
ci ∈ℝ
for
all
i = 0, 1, 2 … n.
Assume a ∈ℝ.
Proof by induction on n = deg(p(x)).
Step 1, the base step. We claim that if n = 0, then p(x) is continuous at x = a.
Proof of claim. Assume n = 0. In this case, p(x) = c0 is a constant function. ◾
Step 2, the induction step. Suppose that all polynomials of degree n = n0 are
continuous at x = a. We claim that this implies that all polynomials of degree
n = n0 + 1 are continuous at x = a.
Proof of claim. Assume that any polynomial function of degree n0 is continuous
at x = a.
Assume cn0+1 ≠0 and
p(x) = cn0+1xn0+1 + cn0xn0 + · · · + c1x + c0.
(19.51)
Notice that
p(x) = (cn0+1xn0 + cn0xn0−1 + … c1)x + c0.
(19.52)
But
cn0+1xn0 + cn0xn0−1 + … c1
(19.53)
is a polynomial of degree n0. So by our assumption, as a function it is continuous
at x = a. We know by Theorem 19.2.2 that the identity function is continuous at
x = a, and by Theorem 19.2.1, the constant function is also continuous at x = a.
Since p(x) is the product and sum of functions continuous at x = a, it follows
that p(x) is continuous at x = a.
◾
So, it follows by induction that if p ∶ℝ→ℝis given by a polynomial, then
for all a ∈ℝ, p(x) is continuous at x = a.
◽
19.2.6
Composition of continuous functions
Theorem 19.2.9.
Let f ∶ℝ→ℝhave domain D and let g ∶ℝ→ℝhave
domain E. Deﬁne h ∶ℝ→ℝby h = g ∘f . If f (x) is continuous at x = a and g(x)
is continuous at x = f (a), then h(x) is continuous at x = a.

19.2 Theorems About Continuity
383
a
f (a)
f (x)
g( f (a))
g(x)
Target Neighborhood
Figure 19.5 Composition of continuous functions.
Here a good generic picture can save us some scratch work (Figure 19.5).
We will be given an 𝜀target about g(f (a)). We can hit it using the continuity
of g and choosing an aiming radius about f (a). We can hit this aiming radius
about f (a) with f by using the continuity of f and choosing an aiming radius
about f (a). That should work for the composition.
There is one issue though; we cannot be sure what the domain of h(x) is. The
statement of the theorem says nothing about f (D) ∩E. The requirement that
g(x) is continuous at f (a) does at least imply that f (a) ∈f (D) ∩E. However, our
deﬁnitions of a function and of the image of a set combined with the topolog-
ical deﬁnition of continuity allow us to formalize the proof outline easily. By
using its global aspect, this is the ﬁrst place where we can put our topological
deﬁnition of continuity to use:
∀𝜀> 0, ∃𝛿> 0 s.t. f (N(a, 𝛿)) ⊆N(f (a), 𝜀).
(19.54)
Proof. Assume that f (x) is continuous at x = a.
Assume that g(x) is continuous at x = f (a).
Assume 𝜀> 0. Consider h(a). Now h(a) = g(f (a)). For convenience, let b =
f (a). Thus, h(a) = g(b) and g(x) is continuous at x = f (a) = b.
Since g(x) is continuous at x = b and 𝜀> 0, ∃𝛿g > 0 such that g(N(b, 𝛿g)) ⊆
N(g(b), 𝜀).
Now f (a) = b; f (x) is continuous at x = a and 𝛿g > 0.
Comment: It really does not matter what it is called, as long as a number is
positive, it can be used in the deﬁnition of continuity.
So
∃𝛿f > 0 s.t. f (N(a, 𝛿f )) ⊆N(f (a), 𝛿g).
(19.55)
But N(f (a), 𝛿g) = N(b, 𝛿g).
Claim. (g ∘f )(N(a, 𝛿f )) ⊆N((g ∘f )(a), 𝜀).

384
19 Continuous Functions
Proof of claim. We proved a while ago that we can apply images to both sides
of a subset relation. So f (N(a, 𝛿f )) ⊆N(b, 𝛿g) gives us
g(f (N(a, 𝛿f ))) ⊆g(N(b, 𝛿g)).
(19.56)
From earlier,
g(f (N(a, 𝛿f ))) ⊆g(N(b, 𝛿g)) ⊆N(g(b), 𝜀).
(19.57)
But we also proved that
g(f (N(a, 𝛿f ))) = (g ∘f )(N(a, 𝛿f )).
(19.58)
So
(g ∘f )(N(a, 𝛿f )) ⊆N(g(f (a)), 𝜀).
(19.59)
Finally, this gives
(g ∘f )(N(a, 𝛿f )) ⊆N((g ∘f )(a), 𝜀).
(19.60)
◾
Comment: Recalling theorems from set theory saved us from a longer direct proof
of this subset relation.
Thus, we have proved that if f (x) is continuous at x = a and g(x) is continuous
at x = f (a), then h(x) is continuous at x = a.
◽
19.2.7
Dividing continuous functions
Theorem 19.2.10.
Let f ∶ℝ→ℝhave domain D and let g ∶ℝ→ℝhave
domain E. Deﬁne h ∶ℝ→ℝby h(x) = f (x)
g(x).
If f (x) is continuous at x = a and, if g(x) is continuous at x = a with g(a) ≠0,
then h(x) is continuous at x = a.
Proof. Comment: The important thing in this theorem is the assumption
g(a) ≠0.
Let k ∶ℝ→ℝbe given by k(x) = 1
x. We have proved that this is continuous
at all x = a ≠0.
So k(x) is continuous at x = g(a). By Theorem 19.2.9, (k ∘g)(x) is continuous
at x = a. But
(k ∘g)(x) = k(g(x))
(19.61)
=
1
g(x).
By Theorem 19.2.7, f (x) ⋅(k ∘g)(x) is continuous at x = a. But
f (x) ⋅(k ∘g)(x) = f (x)
g(x).
(19.62)
◽

19.2 Theorems About Continuity
385
Again using the theorems we have already proved, we have avoided a lot of
fussy approximating and limiting that a 𝛿-𝜀-proof would require. It is possible
to use the deﬁnition, but not a lot of fun unless you like that sort of thing.
Corollary 19.2.11.
Let r ∶ℝ→ℝbe given by a rational expression; that
is a polynomial divided by a polynomial. Then for all a ∈Domain(r), r(x) is
continuous at x = a.
Proof. Let
r(x) = p(x)
q(x)
(19.63)
where p(x) and q(x) are polynomials. All we need do is to note that
Domain(r) = {x ∈ℝ∣q(x) ≠0}.
(19.64)
◽
19.2.8
Gluing functions together
Theorem 19.2.12
(The Gluing Theorem).
Let f ∶(−∞, a] →ℝhave
domain D and let g ∶[a, ∞) →ℝhave domain E. Suppose that f (a) = g(a). Let
h ∶ℝ→ℝbe given by
h(x) =
⎧
⎪
⎨
⎪⎩
f (x)
if x < a
f (a)
if x = a
g(x)
if x > a
.
(19.65)
If f (x) is continuous on D with a ∈D, and if g(x) is continuous on E is contin-
uous with a ∈E. Then h(x) is continuous on D ∪E.
Proof. Assume that f (x) is continuous on D ⊆(−∞, a]. Assume a ∈D.
Assume that g(x) is continuous on E ⊆[a, ∞). Assume a ∈E.
Assume f (a) = g(a).
Notice that h(x) has domain D ∪E.
To prove that h(x) is continuous on D ∪E, assume b ∈D ∪E, and assume
𝜀> 0.
There are three cases to consider: b = a; b ∈D∖{a} or b ∈E∖{a}.
Case 1: Assume b = a.
Then ∃𝛿f > 0 such that if x ∈D and |x −a| < 𝛿f , then |f (x) −f (a)| < 𝜀.
In addition, ∃𝛿g > 0 such that if x ∈E and |x −a| < 𝛿g, then |g(x) −g(a)| < 𝜀.
Let 𝛿h = Min({𝛿f , 𝛿g}). Then 𝛿h > 0, 𝛿h ≤𝛿f , and 𝛿h ≤𝛿g.
Claim. If x ∈D ∪E and |x −a| < 𝛿h, then |h(x) −h(a)| < 𝜀.

386
19 Continuous Functions
Proof of claim. Assume x ∈D ∪E and |x −a| < 𝛿h. There are two possibilities,
x ∈D or x ∈E.
Subcase 1: Assume x ∈D ⊆(−∞, a]. So h(x) = f (x). We still have |x −a| <
𝛿h ≤𝛿f . So |f (x) −f (a)| < 𝜀. This means |h(x) −h(a)| < 𝜀.
Subcase 2: Assume x ∈E ⊆[a, ∞). So h(x) = g(x). We still have |x −a| <
𝛿h ≤𝛿g. So |g(x) −g(a)| < 𝜀. This means |h(x) −h(a)| < 𝜀.
◾
Case 2: Assume b ∈D∖{a}. Then f (x) is continuous at x = b. Let 𝛿1 = a −b.
Since D∖{a} ⊆(−∞, a), 𝛿1 > 0. So N(b, 𝛿1) ∩(D ∪E) ⊆N(b, 𝛿1) ∩D.
Then ∃𝛿f > 0 such that if f (N(b, 𝛿f )) ⊆N(a, 𝜀).
Let 𝛿= Min({𝛿1, 𝛿f }). Since 𝛿< 𝛿1 = a −b, h(x) and f (x) agree on N(b, 𝛿). So
h(N(b, 𝛿)) ⊆f (N(b, 𝛿))
(19.66)
⊆f (N(b, 𝛿f ))
⊆N(a, 𝜀).
Thus, h(x)is continuous at all b ∈D∖{a}.
Case 3: Similar to case 2.
◽
19.3
Problems
19.1
Write a polished proof of: Let f ∶ℝ→ℝhave domain D. For c ∈ℝ,
let g ∶ℝ→ℝbe given by g(x) = cx. If f (x) is continuous at x = a, then
g(x) is continuous at x = a.
19.2
Use the deﬁnition to prove f ∶ℝ→ℝgiven by f (x) = x2 + 3x −11 is
continuous at x = −4.
19.3
Use the deﬁnition to prove f ∶ℝ→ℝgiven by f (x) = x2 −x −8 is
continuous at x = 1.
19.4
Use the deﬁnition to prove f ∶ℝ→ℝgiven by f (x) =
1
4x+3 is
continuous at x = 1.
19.5
Use the deﬁnition to prove f ∶ℝ→ℝgiven by f (x) =
1
4x+3 is
continuous at x = −1.
19.6
Use the deﬁnition to prove f ∶ℝ→ℝgiven by f (x) = x2 −6x −8 is
continuous at x = 3.
19.7
Use the deﬁnition to prove f ∶ℝ→ℝgiven by f (x) = x2 is continuous
at x = 1
3.

19.3 Problems
387
19.8
Use the deﬁnition to prove f ∶ℝ→ℝgiven by f (x) = x3 −2x + 3 is
continuous at x = 5.
19.9
Use the deﬁnition to prove f ∶ℝ→ℝgiven by f (x) = x3 −12x −4 is
continuous at x = −2.
19.10
Use the deﬁnition to prove f ∶ℝ→ℝgiven by f (x) = x3 is continuous
at x = 0.
19.11
Let f ∶ℝ→ℝhave domain D. Deﬁne g ∶ℝ→ℝbe given by g(x) =
(f (x))2. Thus, g(x) also has domain D.
Prove: If f (x) is continuous at x = a, then g(x) is continuous at x = a.
19.12
Let f ∶ℝ→ℝhave domain D and let g ∶ℝ→ℝhave domain E.
Deﬁne h ∶ℝ→ℝby h = g ∘f .
Prove: If f (x) is continuous at x = a and g(x) is continuous at x = f (a),
then h(x) is continuous at x = a.
19.13
Use the deﬁnition to prove f ∶ℝ→ℝgiven by
f (x) =
⎧
⎪
⎨
⎪⎩
−x2
if x < 0
0
if x = 0
x2
if x > 0
(19.67)
is continuous at x = 0.
19.14
Use the deﬁnition to prove that for all n ∈ℕ, f ∶ℝ→ℝgiven by f (x) =
xn is continuous at x = 0.
19.15
Use the induction to prove that for all n ∈ℕ, f ∶ℝ→ℝgiven by f (x) =
xn is continuous at x = 0.
19.16
Assume that the function f ∶ℝ→ℝgiven by f (x) = ex is continuous
on ℝ. Use the theorems in this chapter to prove that the function g ∶
ℝ→ℝgiven by g(x) = 3e2x + 4ex −2 is continuous on ℝ.
19.17
Prove that f ∶ℝ→ℝgiven by f (x) = 1
x is continuous at all x = a with
a < 0. (Hint: To avoid confusion over negative and positive numbers,
let a = −b and prove it for all b > 0.)
19.18
Prove the theorem on multiplication using just the deﬁnition. Let
f ∶ℝ→ℝhave domain D and let g ∶ℝ→ℝhave domain E. Deﬁne

388
19 Continuous Functions
h ∶ℝ→ℝbe given by h(x) = f (x)g(x). Thus, h(x) has domain D ∩E.
If f (x) is continuous at x = a and g(x) is continuous at x = a, then h(x)
is continuous at x = a. Hint:
f (x)g(x) −f (x)g(x) = f (x)g(x) −f (a)g(x) + f (a)g(x) −f (x)g(x)).
(19.68)

389
20
Continuity and Topology
20.1
Preliminaries
Our deﬁnition of continuous tells us what it means for a function f (x) to be
continuous at a single point a. But if our deﬁnition of continuous is to have
anything to do with the normal notion of continuous, we need to start talking
about a function being continuous on sets, preferably intervals. In mathemati-
cal parlance, we want our local deﬁnition to have global implications. The ﬁrst
step is rather obvious.
Deﬁnition 20.1.1.
Let f ∶ℝ→ℝ. We say that f (x) is continuous on a subset
S ⊆ℝif for all a ∈S, f (x) is continuous at x = a.
Thus, our previous results say:
• Constant functions are continuous on ℝ.
• The identity function f ∶ℝ→ℝis continuous on ℝ.
• Every polynomial function p ∶ℝ→ℝis continuous on ℝ.
• And every rational function r ∶ℝ→ℝis continuous on its domain.
In addition, it almost goes without saying that, if f ∶ℝ→ℝis continuous on
D and E ⊆D, then f (x) is continuous on E.
20.1.1
Continuous images mess up topology
Let S ⊆ℝ. There are three topological properties that S may have: S may be
open; S may be closed; S may be bounded. Consider the following examples.
Example 20.1.2.
Let f ∶ℝ→ℝgiven by f (x) = x3 −x.
Then f (x) is continuous on ℝ. Now S = (−1, 1) ⊆ℝis open. However,
f (S) =
[
−
2
3
√
3
,
2
3
√
3
]
(20.1)
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

390
20 Continuity and Topology
−1
1
−1
1
Figure 20.1 f(x) = x3 −x.
which is deﬁnitely not open (Figure 20.1). This weird interval might be very
startling if you did not know some calculus and know that the end points of this
image are values of the function at the roots of the derivative f ′(x) = 3x2 −1.
Example 20.1.3.
Let f ∶ℝ→ℝgiven by f (x) = 1
x.
Then f (x) is continuous on (Figure 20.2) ℝ∖{0}. Now S = [1, ∞) ⊆ℝ∖{0}
is closed. However,
f (S) = (0, 1]
(20.2)
which is not closed.
Example 20.1.4.
Let f ∶ℝ→ℝgiven by f (x) = 1
x. Then f (x) is continuous
on ℝ∖{0}. Now S = (0, 1) ⊆ℝ∖{0} is bounded. However,
f (S) = (1, ∞)
(20.3)
which is not bounded.
−4
−2
2
4
−2
−1
1
2
x
y
Figure 20.2 f(x) = 1
x .

20.2 The Topological Deﬁnitions of Continuity
391
There are circumstances where these properties of sets are preserved by their
images under continuous functions, but in general, we cannot count on it. Any
theorem that allows us to say something about images is worth remembering.
20.2
The topological deﬁnitions of continuity
As we just saw, images of sets under continuous functions are not very well
behaved. As it turns out, preimages work extraordinarily well. The important
thing, however, is that the functions have a good domain: open or closed.
Theorem 20.2.1
(The Topological Deﬁnition of Continuous: Open
Version).
Let f ∶ℝ→ℝbe a function with domain D. Let D be open. Then
f (x) is continuous on D if and only if ∀⊆ℝwith open, f −1() is open.
Proof draft. Assume that D is open.
Comment: This is important, and we will watch for a place to use it.
This is a biconditional statement, so there are two directions to prove. We
will take each part in turn.
Part 1. First, we claim that if f (x) is continuous on D, then ∀⊆ℝwith open,
f −1() is open.
Proof of claim. Assume that f (x) is continuous on D. Then ∀a ∈D, f (x) is con-
tinuous at x = a.
Assume ⊆ℝwith open.
Comment: What are we proving now? We are proving that “f −1(O) is open.” That
is, “∀a ∈f −1(O), ∃𝜀> 0 such that N(a, 𝜀) ⊆f −1(O).”
Assume a ∈f −1(). Then f (a) ∈.
Comment: Normally, choosing the letter “O” in any font is a bad idea, but when
a set is open, it really helps us get to the next step when we ﬁnd an element in it.
So ∃𝜀a > 0 such that N(f (a), 𝜀a) ⊆.
Comment: What are we proving now? “There exists some new neighborhood of a
such that . . . .” That means we have to ﬁnd one. What assumption have we not
used yet? We have not used the fact that ∀a ∈D, f (x) is continuous at x = a.
Great! We just found a neighborhood of f (a).

392
20 Continuity and Topology
Since f (x) is continuous at x = a and 𝜀a > 0, ∃𝛿a > 0 such that f (N(a, 𝛿a)) ⊆
N(f (a), 𝜀a).
Comment: We are working on theoretical functions; so the topological version of
continuous seems like the better choice. And it is, as we will now see.
We have N(f (a), 𝜀a) ⊆. So f (N(a, 𝛿a)) ⊆N(f (a), 𝜀a) ⊆.
Comment: We would ﬁnish the proof if we could prove that N(a, 𝛿a) ⊆f −1(),
where the 𝜀we set out to ﬁnd ends up begin 𝛿a. However, if we tried to prove this,
we would run into trouble.
We would start by assuming that we have some x ∈N(a, 𝛿a). Then by our ear-
lier work, f (x) ∈f (N(a, 𝛿a)), right?
Not quite. We chose 𝛿a > 0 so that f (N(a, 𝛿a)) ⊆N(f (a), 𝜀a). But this actually
only tells that if x ∈N(a, 𝛿a) and f (x) is deﬁned, then f (x) ∈N(f (a), 𝜀a). But it
may be that x ∈N(a, 𝛿a) but x ∉Domain(f ). In that case, we could not conclude
that x ∈f −1().
We need to ﬁnd a subset of N(a, 𝛿a) that is also a subset of D = Domain(f ).
So, what are we missing? What have not we used yet? We have not used the
fact that the domain D is open. Time to back up and use it when we can.
Now a ∈f −1() ⊆D. So a ∈D and a ∈N(a, 𝛿a); thus a ∈D ∩N(a, 𝛿a). Since
both parts are open sets, we know that D ∩N(a, 𝛿a) is an open set. So ∃𝛿′
a > 0
so that N(a, 𝛿′
a) ⊆D ∩N(a, 𝛿a).
Comment: We have now found our subset of N(a, 𝛿a) that is also a subset of
D = Domain(f ). Everything in N(a, 𝛿′
a) should be in f −1().
We now claim that N(a, 𝛿′
a) ⊆f −1().
Assume x ∈N(a, 𝛿′
a). Then x ∈N(a, 𝛿′
a) ⊆D ∩N(a, 𝛿a). So x ∈D and
x ∈N(a, 𝛿a). Since x ∈D, f (x) exists and f (x) ∈f (N(a, 𝛿a)). Thus, f (x) ∈
f (N(a, 𝛿a)) ⊆N(f (a), 𝜀a) ⊆. And then x ∈f −1().
◾
Part 2. Now we claim that if ∀⊆ℝwith open, f −1() is open, then f (x) is
continuous on D.
Proof of claim. Assume that if ⊆ℝis open, then f −1(S) is open.
Comment: What are we proving now? f (x) is continuous on D. That is, ∀a ∈D,
f (x) is continuous at x = a. That is, ∀a ∈D, ∀𝜀> 0, there exists a good 𝛿. That
gives us a start.
Assume a ∈D. Assume 𝜀> 0.
Consider N(f (a), 𝜀). This is an open set and f (a) ∈N(f (a), 𝜀).

20.2 The Topological Deﬁnitions of Continuity
393
By assumption, f −1(N(f (a), 𝜀)) is open, and we also know that
a ∈f −1(N(f (a), 𝜀)).
So ∃𝛿a > 0 so that
N(a, 𝛿a) ⊆f −1(N(f (a), 𝜀)).
(20.4)
We now claim that f (N(a, 𝛿a)) ⊆N(f (a), 𝜀).
Assume y ∈f (N(a, 𝛿a)). Then ∃x ∈N(a, 𝛿a) such that f (x) = y. But
x ∈N(a, 𝛿a) ⊆f −1(N(f (a), 𝜀)).
Since x ∈f −1(N(f (a), 𝜀)), we have f (x) ∈N(f (a), 𝜀). But then y = f (x) ∈
N(f (a), 𝜀).
Thus, we have f (N(a, 𝛿a)) ⊆N(f (a), 𝜀).
This proves that f (x) is continuous.
◾
Now that we have found a proof of both directions of the biconditional, our
proof is complete.
Δ
This ﬁrst part of this deﬁnitely needs to be rewritten; so we should clean up
both parts as we go. Notice that we needed to use the fact that D is open. We
need to remember that every time we apply f (x) to something, we must be sure
that something is in the domain!
Proof. Assume that Domain(f ) = D is open.
Part 1. First, we claim that if f (x) is continuous on D, then ∀⊆ℝwith open,
f −1() is open.
Proof of claim. Assume that f (x) is continuous on D. Then ∀a ∈D, f (x) is con-
tinuous at x = a.
Assume ⊆ℝwith open.
Assume a ∈f −1() ⊆D. Then f (a) ∈.
So ∃𝜀a > 0 such that N( f (a), 𝜀a) ⊆.
Since f (x) is continuous at x = a and 𝜀a > 0, ∃𝛿a > 0 such that f (N(a, 𝛿a)) ⊆
N(f (a), 𝜀a).
We have N( f (a), 𝜀a) ⊆. So f (N(a, 𝛿a)) ⊆N(f (a), 𝜀a) ⊆.
Now a ∈f −1() ⊆D. So a ∈D ∩N(a, 𝛿a). This is an open set. So ∃𝛿′
a > 0 so
that N(a, 𝛿′
a) ⊆D ∩N(a, 𝛿a).
We now claim that N(a, 𝛿′
a) ⊆f −1(O).
To prove this, assume x ∈N(a, 𝛿′
a). Then x ∈N(a, 𝛿′
a) ⊆D ∩N(a, 𝛿a). So x ∈
D and x ∈N(a, 𝛿a). Since x ∈D, f (x) exists and f (x) ∈f (N(a, 𝛿a)). Thus,
f (x) ∈f (N(a, 𝛿a)) ⊆N(f (a), 𝜀a) ⊆.
(20.5)

394
20 Continuity and Topology
And therefore, x ∈f −1(). This proves that N(a, 𝛿′
a) ⊆f −1(O) and ﬁnishes the
proof of this part of the theorem.
◾
Part 2. Now we claim that if ∀⊆ℝwith open, f −1() is open, then f (x) is
continuous on D.
Proof of claim. Assume ∀⊆ℝwith open, f −1() is open.
Assume a ∈D. Assume 𝜀> 0.
Consider N(f (a), 𝜀). This is an open set and f (a) ∈N(f (a), 𝜀).
By assumption, f −1(N(f (a), 𝜀)) is open, and a ∈f −1(N(f (a), 𝜀)).
So ∃𝛿a > 0 so that
N(a, 𝛿a) ⊆f −1(N(f (a), 𝜀)).
(20.6)
We now claim that f (N(a, 𝛿a)) ⊆N(f (a), 𝜀).
To prove this, assume y ∈f (N(a, 𝛿a)). Then ∃x ∈N(a, 𝛿a) such that
f (x) = y. But x ∈N(a, 𝛿a) ⊆f −1(N(f (a), 𝜀)). Since x ∈f −1(N(f (a), 𝜀)), we have
y = f (x) ∈N(f (a), 𝜀). This proves that f (N(a, 𝛿a)) ⊆N(f (a), 𝜀).
Thus, f (x) is continuous, and we are now ﬁnished with this direction of the
proof.
◾
Now that we have found a proof of both directions of the biconditional, our
proof is complete.
◽
Theorem 20.2.2
(The Topological Deﬁnition of Continuous: Closed
Version). Let f ∶ℝ→ℝbe a function with domain D. Let D be closed. Then
f (x) is continuous on D if and only if ∀⊆ℝwith closed, f −1() is closed.
As we just saw, the deﬁnition of continuity works pretty well with open sets.
That means that it can work with closed sets by considering complements in
ℝ. Unfortunately, all the negations make this next proof something similar to
untying a knot in your shoelaces while looking at it through a mirror. We will
simply write out the ﬁnal proof.
Proof. Assume that Domain( f ) = D closed.
Part 1. We claim that if f (x) is continuous on D, then ∀⊆ℝwith closed,
f −1() is closed.
Proof of claim. Assume that f (x) is continuous on D. Then ∀a ∈D, f (x) is con-
tinuous at x = a.
Assume ⊆ℝwith closed.
We will prove that f −1() is closed by proving (f −1())′ ⊆f −1(). But we will
do so by contradiction.

20.2 The Topological Deﬁnitions of Continuity
395
Assume a ∈(f −1())′.
Assume a ∉f −1().
Comment: Before we consider f (a), we need to be sure that it exists.
By the deﬁnition of preimage, f −1() ⊆D. So (f −1())′ ⊆D′.
Comment: Now we see why we are working with accumulation points and not
boundary points: accumulation points respect subsets.
Since D is closed,
a ∈(f −1())′ ⊆D′ ⊆D.
(20.7)
Therefore, f (a) exists.
Because a ∉f −1(), f (a) ∉. Then f (a) ∈ℝ∖, which is an open set. So
∃𝜀1 > 0 such that N(f (a), 𝜀1) ⊆ℝ∖.
But f (x) is continuous on D, and we have proved that a ∈D. So using this
𝜀1 > 0, we have that ∃𝛿1 > 0 such that
f (N(a, 𝛿1)) ⊆N(f (a), 𝜀1) ⊆ℝ∖.
(20.8)
However, we started out with the assumption that a ∈(f −1())′. So by deﬁni-
tion, ∀𝜀> 0, N∗(a, 𝜀) ∩f −1() ≠∅. Since 𝛿1 > 0, we can use it for the variable
𝜀, and say
N∗(a, 𝛿1) ∩f −1() ≠∅.
(20.9)
We can let x ∈N∗(a, 𝛿1) ∩f −1(). Then x ∈N∗(a, 𝛿1) and x ∈f −1(). But x ∈
f −1() tells us that f (x) ∈.
But we also have x ∈N∗(a, 𝛿1) ⊆N(a, 𝛿1). So f (x) ∈f (N(a, 𝛿)). This means
f (x) ∈f (N(a, 𝛿)) ⊆N(f (a), 𝜀) ⊆ℝ∖.
(20.10)
Since we just found that f (x) ∈and that f (x) ∈ℝ∖, this is the contradiction
we were looking for.
◾
Part 2. We now claim that ∀⊆ℝwith closed, f −1() is closed, then f (x) is
continuous on D.
Proof of claim. Assume ∀⊆ℝwith closed, f −1() is closed.
Comment: We now want to prove that ∀a ∈D, f (x) is continuous at x = a.
Assume a ∈D.
Comment: So now we want to prove: ∀𝜀> 0, ∃𝛿> 0 such that f (N(a, 𝛿)) ⊆
N(f (a), 𝜀).
Assume 𝜀> 0.

396
20 Continuity and Topology
Consider N(f (a), 𝜀). This is an open set. Let = ℝ∖N(f (a), 𝜀). Then is a
closed set. So by our assumption about f , f −1() is closed.
Comment: Now we need to prove that ∃𝛿> 0 such that f (N(a, 𝛿)) ⊆N(f (a), 𝜀).
We need to ﬁnd a small neighborhood, so we need to solve a problem about its
𝛿. We just discovered a closed set f −1(), not an open one. We might guess that
need something is not in that set. The number f (a) ﬁts the bill, and the neigh-
borhood N(f (a), 𝜀) is deﬁnitely open. Let us see if considering f (a) can ﬁnd us a
small neighborhood of a.
Now f (a) ∈N(f (a), 𝜀). So f (a) ∉ℝ∖N(f (a), 𝜀) = . So a ∉f −1(). That is,
a ∈ℝ∖(f −1()).
Since f −1() is closed, ℝ∖f −1() is open. So we have
∃𝛿>0 s.t. N(a, 𝛿) ⊆ℝ∖f −1().
(20.11)
That is to say, N(a, 𝛿) ∩f −1() = ∅.
We now claim that f (N(a, 𝛿)) ⊆N(f (a), 𝜀).
To prove this, assume y ∈f (N(a, 𝛿)). Then ∃x ∈N(a, 𝛿) such that f (x) = y.
But
x ∈N(a, 𝛿) ⊆ℝ∖f −1().
(20.12)
So x ∉f −1(). So y = f (x) ∉= ℝ∖N(f (a), 𝜀). Thus, y ∈N(f (a), 𝜀). There-
fore, we have proved our claim that f (N(a, 𝛿)) ⊆N(f (a), 𝜀).
That is, we have proved that ∀𝜀> 0, ∃𝛿> 0 such that f (N(a, 𝛿)) ⊆N(f (a), 𝜀).
So f (x) is continuous at x = a.
◾
We have now proved both directions of the theorem, so our proof is
complete.
◽
We can prove one quick corollary from the open version that at ﬁrst glance
has nothing to do with the theorem.
Corollary 20.2.3.
Let r ∶ℝ→ℝbe given by a rational expression. Then r(x)
is continuous on Domain(r), which is an open set.
Proof. Assume r ∶ℝ→ℝbe given by a rational expression. Write
r(x) = p(x)
q(x).
(20.13)
where p(x) and q(x) are polynomials. We already proved that r(x) is continuous
on
Domain(r) = {x ∈ℝ∣q(x) ≠0}.
(20.14)

20.3 Compact Images
397
But q ∶ℝ→ℝis given by a polynomial, so q(x) is continuous on ℝ, which is
an open set. Since ℝ∖{0} ⊆ℝis open, the theorem tells us that
q−1(ℝ∖{0}) = {x ∈ℝ∣q(x) ≠0}
(20.15)
is open. But this is Domain(r).
◽
20.3
Compact images
20.3.1
The main theorem
When we started out, we noted that the image f (S) of a set S under continuous
functions f (x) tended to mess up any topological properties of the S. We gave
examples where this happened to three topological properties that S may have:
open, closed, and bounded.
We showed that if S is a closed set, f (S) may not be closed, and if S is a
bounded set, f (S) may not be bounded. So, you might guess that if S is both
closed and bounded, f (S) may not be closed and bounded. That would be a mis-
take! Somehow the properties closed and bounded together are much stronger
than either alone. We have the following theorem.
Theorem 20.3.1.
Let f ∶ℝ→ℝbe a function with domain D. Suppose that
D is open, and suppose that f (x) is continuous on D. If S ⊆D and S is closed and
bounded, then f (S) is closed and bounded.
Of course, we are being obtuse and not in a triangular way. We are not sup-
posed to say that a set is closed and bounded anymore; we are supposed to
say that the set is compact. That should remind us that we do have a (admit-
tedly scary, when you ﬁrst see it) trick to use on such sets. All we have to do is
maintain our logical discipline and see if the trick helps. We must be sure not
to assume that we have something until the logic of the proof permits it. Our
theorem is best stated as follows.
Theorem 20.3.2.
Let f ∶ℝ→ℝbe a function with domain D. Suppose that
D is open, and suppose that f (x) is continuous on D. If S ⊆D and S is compact,
then f (S) is compact.
We have now hidden the entire long proof of the Heine–Borel theorem into
the logic of the proof of this theorem.
Proof draft. Assume f ∶ℝ→ℝis a function with domain D. Assume that f (x)
is continuous on D. Assume that D is open. Assume S ⊆D. Assume that S is
compact (Figure 20.3).

398
20 Continuity and Topology
S
Compact Set
f (S)
Image
f
Figure 20.3 f maps S to f(S).
Comment: This means that, if we ever have an open cover of S, then it will have
a ﬁnite subcover. It does not give us such a cover! We will not write this down yet,
but we know that we should be looking for an open cover of S. One thing is for
sure: we cannot assume that S has an open cover.
Comment: What are we proving now? “f (S) is compact.” That is, “if Oi gives an
open cover of f (S), that cover will have a ﬁnite subcover.” That at least gives us a
place to start. We can assume that we have an open cover of f (S).
Assume that i with i ∈is a family of open sets.
Assume (Figure 20.4) f (S) ⊆⋃
i∈
i.
Comment: So these open sets are in the codomain side of the function.
We have the set f (S) covered in the codomain, but we would prefer to have S
covered in the domain. We need to build on what we have to create what we need.
What assumptions have we not used yet? Well, f (x) is continuous on D, and D
is open. This allows us to use the topological deﬁnition of continuity.
S
Compact Set
f (S)
Image
f
Figure 20.4 The sets i for i ∈cover f(S).

20.3 Compact Images
399
S
Compact Set
f (S)
Image
f
Figure 20.5 We claim the sets f −1(i) for i ∈cover S.
We know that for all i ∈, i is open. By the open version of the topological
deﬁnition of continuity, for all i ∈, f −1(i) is open.
Comment: That gives us a new family of open sets in the domain side of the func-
tion where S is. If there is any justice in the world, we can make the following
claim (Figure 20.5).
Claim. S ⊆⋃
i∈
f −1(i).
Proof of claim. Assume s ∈S. Since S ⊆D, f (s) is deﬁned, and f (s) ∈f (S). But
then
f (s) ∈f (S) ⊆
⋃
i∈
i.
(20.16)
So there exists is ∈I such that f (s) ∈Ois. So s ∈f −1(Ois). So s ∈⋃
i∈
(f −1(i)). ◾
Now we have an open cover of the set we know is compact. So ∃J ⊆I such
that J is ﬁnite and
S ⊆
⋃
i∈
f −1(i).
(20.17)
Comment: We are looking for a ﬁnite subcover of f (S) from Oi with i ∈I. Again
if there is any justice in the world, we can make the following claim.
Claim. f (S) ⊆⋃
i∈
Oi.
Proof of claim. Assume y ∈f (S). Then ∃x ∈S such that f (x) = y. Now x ∈S ⊆
⋃
i∈
f −1(Oi). So ∃ix ∈J such that x ∈f −1(Oix). But then f (x) ∈Oix. So we have
f (x) ∈⋃
i∈
Oi.
◾

400
20 Continuity and Topology
We have proved that if f (S) ⊆⋃
i∈
Oi with a family of open sets, then there
exists J ⊆I with J is ﬁnite so that f (S) ⊆⋃
i∈
Oi.
That makes f (S) compact.
Δ
This deserves to be rewritten.
Proof. Assume f ∶ℝ→ℝbe a function with domain D. Assume f (x) to be
continuous on D. Assume D is open. Assume S ⊆D. Assume that S is compact.
Assume i with i ∈I is a family of open sets, and assume f (S) ⊆⋃
i∈
i.
We know that for all i ∈, i is open. By the topological deﬁnition of conti-
nuity, for all i ∈, f −1(i) is open.
Claim. S ⊆⋃
i∈
f −1(i).
Proof of claim. Assume s ∈S. Since S ⊆D, f (s) is deﬁned, and f (s) ∈f (S). But
then
f (s) ∈f (S) ⊆
⋃
i∈
i.
(20.18)
So there exists is ∈s.t. f (s) ∈is. So s ∈f −1(is). So s ∈⋃
i∈
f −1(i).
◾
Now we have an open cover of the set we know is compact. So ∃⊆such
that is ﬁnite and
S ⊆
⋃
i∈
f −1(i).
(20.19)
Claim. f (S) ⊆⋃
i∈
i.
Proof of claim. Assume y ∈f (S). Then ∃x ∈S s.t. f (x) = y. Now x ∈S ⊆
⋃
i∈
f −1(i). So ∃ix ∈such that x ∈f −1(ix). But then f (x) ∈ix. So we have
f (x) ∈⋃
i∈
i.
◾
We have proved that if f (S) ⊆⋃
i∈
i with a family of open sets, then there
exists ⊆with is ﬁnite so that f (S) ⊆⋃
i∈
i.
That makes f (S) compact.
◽
20.3.2
The extreme value theorem
The ﬁrst application we have for this theorem is an old friend from Calculus I.

20.3 Compact Images
401
Theorem 20.3.3
(The Extreme Value Theorem).
If f ∶[a, b] →ℝis con-
tinuous on [a, b], then there exists s, t ∈[a, b] such that for all x ∈[a, b],
f (s) ≤f (x) ≤f (t).
(20.20)
This is to say that a continuous function on a closed interval achieves its
extreme values, maximum and minimum, at points in the interval. Since [a, b]
is obviously closed and bounded, we expect its image will also be. But we need
to be sure that all the hypotheses of our theorem are satisﬁed before we reach
its conclusion. The theorem requires that the domain of the function be open,
and the proof deﬁnitely used that condition. Unfortunately, [a, b] is not open.
We have a trick up our sleeves just for this situation.
Proof. Assume that f ∶[a, b] →ℝhas domain [a, b].
Assume that f (x) is continuous on [a, b].
Deﬁne f1 ∶ℝ→ℝby
f1(x) =
⎧
⎪
⎨
⎪⎩
f (a)
if a < x
f (x)
if a ≤x ≤b
f (b)
if x < b.
(20.21)
Now f1(x) is continuous on ℝby the gluing theorem, Theorem 19.2.12.
Then f1(x) is continuous on an open domain (now that is all of ℝ); [a, b] is a
compact subset of that domain, and
f1([a, b]) = f ([a, b]).
(20.22)
So f ([a, b]) is compact.
Now by Heine–Borel, f ([a, b]) is closed and bounded. Because [a, b] ≠∅,
f ([a, b]) ≠∅. By a previous theorem, f ([a, b]) has a maximum and a minimum
(because we know that its inﬁmum and supremum are in the boundary of the
closed set). Call then m and M, respectively.
But m ∈f ([a, b]) and M ∈f ([a, b]). So ∃s ∈[a, b] s.t. f (s) = m and ∃t ∈[a, b]
s.t. f (t) = M. So indeed we have
∀x ∈[a, b], f (s) ≤f (x) ≤f (t).
(20.23)
◽
20.3.3
The intermediate value theorem
The next application is the ﬁnal result we need to be completely satisﬁed that ℝ
contains all the numbers that we might ever need. Well, at least all the numbers
that can be given a total order. Those numbers should be suﬃcient to mea-
sure any quantity we will ever want. In particular, we will ﬁnally know that we
have completely solved the problem with the rational numbers that set us oﬀin
search of the real numbers.

402
20 Continuity and Topology
Theorem 20.3.4
(The Intermediate Value Theorem).
If f ∶[a, b] →ℝis
continuous on [a, b], then either
f ([a, b]) = {m}
(20.24)
or f ([a, b]) = [m, M].
This result is called the “intermediate value theorem” because it says that not
only does the image contain its extreme values (maximum and minimum), but
it also contains all the intermediate values between them. The proof uses the
inseparability theorem (Theorem 18.2.1) from earlier.
Proof. As in the proof of the extreme value theorem, we may assume without
loss of generality that f ∶ℝ→ℝis continuous on ℝ. Thus, we may assume that
the domain of f is open.
Then by the extreme value theorem,
∃s, t ∈[a, b] s.t. ∀x ∈[a, b], f (s) ≤f (x) ≤f (t).
(20.25)
Let m = f (s) and M = f (t). There are two cases to consider: m = M or m < M.
In case 1, we have f ([a, b]) = {m}.
For case 2, assume m < M. Then we have
f ([a, b]) ⊆[m, M].
(20.26)
Claim. [m, M] ⊆f ([a, b]).
Proof of claim. Assume BWOC that ∃𝑣∈[m, M] such that 𝑣∉f ([a, b]).
Then by the extreme value theorem, m and M are deﬁnitely in f ([a, b]). So we
know that 𝑣≠m and 𝑣≠M. And in turn, m < 𝑣< M.
Consider the open sets (−∞, 𝑣) and (𝑣, ∞). Then
(−∞, 𝑣) ∪(𝑣, ∞) = ℝ∖{𝑣};
(20.27)
(−∞, 𝑣) ∩(𝑣, ∞) = ∅.
Thus,
f ([a, b]) ⊆(−∞, 𝑣) ∪(𝑣, ∞).
(20.28)
Now by the topological deﬁnition of continuity (Theorem 20.2.1),
1 = f −1((−∞, 𝑣)) and
2 = f −1((𝑣, ∞))
are open sets.
We claim that 1∩2 = ∅.
Assume BWOC that x ∈1∩2. Then x ∈1 = f −1((−∞, 𝑣)) and x ∈2 =
f −1((𝑣, ∞)). Then f (x) ∈(−∞, 𝑣) and f (x) ∈(𝑣, ∞). But then f (x) ∈(−∞, 𝑣) ∩
(𝑣, ∞) = ∅. This is a contradiction. So we must have 1∩2 = ∅, as claimed.

20.3 Compact Images
403
We now claim that [a, b] ⊆1 ∪2.
Assume x ∈[a, b]. Since x is in the domain of the function, f (x) ∈f ([a, b]).
Now 𝑣∉f ([a, b]); so f (x) ≠𝑣. This means f (x) ∈(−∞, 𝑣) ∪(𝑣, ∞). So
x ∈f −1((−∞, 𝑣) ∪(𝑣, ∞)). Now we know from set theory algebra that
f −1((−∞, 𝑣) ∪(𝑣, ∞)) = f −1((−∞, 𝑣)) ∪f −1((𝑣, ∞))
(20.29)
= 1 ∪2.
Thus, [a, b] ⊆1 ∪2 as claimed.
We now claim that [a, b] ⊈1.
Now t ∈[a, b] and f (t) = M. But M ∈(𝑣, ∞). So t ∈f −1((𝑣, ∞)) = 2. Since
we just saw 1∩2 = ∅, we have t ∉1. Thus, [a, b] ⊈1 as claimed.
Finally, we claim that [a, b] ⊈2.
Here s ∈[a, b] and f (s) = m. But m ∈(−∞, 𝑣). So s ∈f −1((−∞, 𝑣)) = 1.
Since we just saw 1∩2 = ∅, we have s ∉2. Thus, [a, b] ⊈2 as claimed.
Now we have two open sets 1 and 2 and a closed interval [a, b] so that
[a, b] ⊆1 ∪2;
(20.30)
1 ∩2 = ∅;
[a, b] ⊈1;
[a, b] ⊈2.
This contradicts the inseparability theorem. So we must have [m, M] ⊆
f ([a, b]).
◾
Since we have both f ([a, b]) ⊆[m, M] and [m, M] ⊆f ([a, b]), it follows that if
m < M, then we must have f ([a, b]) = [m, M].
So we have proved that if f ∶[a, b] →ℝis continuous on [a, b], then either
f ([a, b]) = {m}
(20.31)
or f ([a, b]) = [m, M].
◽
In a Calculus I text where images and set equality may not be properly
deﬁned, this theorem is stated in the form more like that given in the following
corollary.
Corollary 20.3.5.
Let f ∶[a, b] →ℝbe continuous on [a, b]. If t ∈ℝwith t
between f (a) and f (b), then there exists s ∈[a, b] so that f (s) = t.
Proof. Assume f ∶[a, b] →ℝis continuous on [a, b].
Assume without loss of generality that f (a) ≤f (b).
Assume 𝑣∈ℝwith f (a) ≤𝑣≤f (b). If f (a) = 𝑣or f (b) = 𝑣, we are done, so
suppose that f (a) < 𝑣< f (b).
Comment: We will see that this is a prudent renaming of the variable.

404
20 Continuity and Topology
Then f (a) ≠f (b).
By the extreme value theorem, ∃s, t ∈[a, b] such that
f ([a, b]) ⊆[f (s), f (t)].
(20.32)
By the intermediate value theorem,
f ([a, b]) = [f (s), f (t)].
(20.33)
Now f (a) ∈f ([a, b]) = [f (s), f (t)] and f (b) ∈f ([a, b]) = [f (s), f (t)]. Since 𝑣is
between two points in an interval, 𝑣is in that interval.
So 𝑣∈[f (s), f (t)] = f ([a, b]). So there exists u ∈[a, b] such that f (u) = 𝑣. ◽
Corollary 20.3.6.
For all a ∈[0, ∞), there exists b ∈[0, ∞) such that a = b2.
Proof. First we note that 02 = 0 and 12 = 1. That leaves us with two possibilities:
0 < a < 1 and 1 < a.
Next we point out that f ∶ℝ→ℝgiven by f (x) = x2 is continuous on ℝ.
Case 1: Assume 0 < a < 1. Then a is between f (0) and f (1). By the interme-
diate value theorem, there exists b ∈[0, 1] so that f (b) = a.
Case 2: Assume 1 < a. Then multiplying by a, we get a < a2. So a is between
f (1) and f (a). By the intermediate value theorem, there exists b ∈[1, a] so that
f (b) = a.
◽
20.4
Problems
20.1
Let f ∶ℝ→ℝwith domain D. Prove that f (x) is continuous on D∘.
20.2
Let f ∶ℝ→ℝbe a function with domain D. Let D be open. Prove that
if f (x) is continuous on D and ⊆ℝwith open, then f −1() is open.
20.3
Prove: if f ∶ℝ→ℝis a function continuous on its open domain D and
S ⊆D compact, then f (S) is compact.
20.4
Assume that the function s ∶ℝ→ℝgiven by s(x) = Sin(x) is continu-
ous on ℝ.
(a) Prove that the set
S =
{
x ∈ℝ∣Sin(x) =
√
2
2
}
is closed.

20.4 Problems
405
(b) Prove that the set
S =
{
x ∈ℝ∣Sin(x) <
√
2
2
}
is open.
20.5
Let f ∶ℝ→ℝbe continuous on ℝ. Prove: if S ⊆ℝis bounded, then
f (S) is bounded. (Hint: Use all the power found in this chapter and not
the deﬁnition of bounded.)
20.6
Let p ∶ℝ→ℝbe a rational function given by
p(x) = anxn + an−1xn−1 + · · · a1x + a0
bmxm + bm−1xm−1 + · · · b1x + b0
with ai, bi ∈ℝfor all i. Prove that the domain of p(x) is open.
20.7
Let f ∶ℝ→ℝhave domain D and g ∶ℝ→ℝhave domain E. If a ∈
ℝsuch that ∃𝜀> 0 so that N(a, 𝜀) ⊆D ∩E and f (x) = g(x) for all x ∈
N(a, 𝜀), then f (x) is continuous at x = a if and only if g(x) is continuous
at x = a.
20.8
Let f ∶ℝ→ℝbe given by f (x) = x3 −18x. Prove that there is an 𝛼∈ℝ
so that f (𝛼) = 5.
20.9
Let p(x) be a polynomial of odd degree. Prove that p(x) has a real root.
(Hint: Consider plus and minus the maximum of the set of coeﬃcients
of p(x) to get a start.)
20.10
Let f ∶[0, ∞) →ℝbe given by f (x) =
√
x. Prove that f (x) is continuous
on [0, ∞) using the deﬁnition of continuous. (Be careful with the 0.)
20.11
Prove that the set
S = {b ∈ℝ|∃a ∈ℝwith 1 ≤a ≤3 such that b = a5 −a3}
is closed.
20.12
Let f ∶[a, b] →ℝbe continuous on [a, b]. We know that either
f ([a, b]) = {M} or f ([a, b]) = [m, M].
(a) Prove: If ∃t ∈(a, b) such that f (t) = M, then either f ([a, t]) = {M}
or f ([a, t]) = [m1, M] and that either f ([t, b]) = {M} or f ([t, b]) =
[m2, M].

406
20 Continuity and Topology
(b) Prove: If ∃t ∈(a, b) such that f (t) = M, and f ([a, t]) = [m1, M] and
f ([t, b]) = [m2, M], then ∃y ∈[m1, M] ∩[m2, M] with y ≠M.
(c) Prove: If ∃t ∈(a, b) such that f (t) = M, then f (x) is not injective.
(d) Prove: If f (x) is injective, then the maximum value of f ([a, b]) occurs
at one of the end points.

407
21
A Few Final Observations
We fulﬁlled the mathematical promise of this study in the last chapter when we
proved the intermediate value theorem. Early on we realized that, as familiar as
they might be, the real numbers are pretty diﬃcult to nail down exactly. Dec-
imal approximations will turn any real number into a rational number that is
close enough for any practical application. But for any exact statement about
a real number, it may be necessary to resort to analysis to understand what is
being said. After centuries or work, mathematicians have devised a descrip-
tion of real numbers that makes exact statements possible. The mathematical
description that says the real numbers are any numbers that form a complete
ordered ﬁeld is hardly intuitive, but once we get used to it, it is very powerful.
There is no end to how it can be used.
We scratched the surface of these applications but did manage to prove that
we have all the numbers we need to measure quantities. That is the philo-
sophical consequence of the intermediate value theorem. If something can be
approximated above and below in a “continuous” way to any level of accuracy,
there is a real number that identiﬁes it exactly. Mathematicians are never con-
tent to let things lie, and they have expanded the notion of “number” to other
realms. Still the intermediate value theorem says that, for measuring real quan-
tities, all one needs are real numbers.
We end this study with a few ﬁnal observations.
21.1
Inverses of continuous functions
Now that we can deﬁne a function f ∶[0, ∞) →ℝby f (x) =
√
x, we can prove
that f (x) is continuous on [0, ∞). However, we are after bigger game again. We
would like to prove once and for all that, if a bijective function is continuous on
its domain, then its inverse function is continuous on its domain. The problem
is that this is not as true as it seems to be. There are important properties that
the domain must have before we can say that this result is correct.
An Introduction to Proof through Real Analysis, First Edition. Daniel J. Madden and Jason A. Aubrey.
© 2017 John Wiley & Sons, Inc. Published 2017 by John Wiley & Sons, Inc.

408
21 A Few Final Observations
21.1.1
A strange example
We will begin by examining an example where the inverse of a function con-
tinuous on its domain is so far from continuous that it could hardly get much
worse. The trick, however, is to set the original function on a domain that is
pretty bad to start with, ℚ. The set of rational numbers is neither open nor
closed. It contains no intervals, and its complement in ℝcontains no intervals
either.
We do not have a ﬁrm enough deﬁnition of the sine function to prove that it
is continuous on ℝ. We do, however, expect that this is true and so that is good
enough for an example.
Example 21.1.1.
Let f ∶ℝ→ℝbe given by f (x) = Sin(x). Then we can
assume that f (x) is continuous on ℝ. We can also assume that the period of
f (x) is 2𝜋and that 𝜋is not a rational number. These are all true statements well
known in Mathematics, but we have not proved them.
Deﬁne: g ∶ℚ→f (ℚ) by g(x) = Sin(x). Since ℚ⊆ℝ, g(x) is continuous on its
domain. In addition, because the codomain is f (ℚ), g(x) is surjective. But it may
come as a surprise to realize that, because 𝜋∉ℚ, g(x) is injective!
Assume g(x1) = g(x2) with x1 and x2 in ℚ. From trigonometry, we know that
either x2 = x1 + 2k𝜋for some k ∈ℤ, or x2 = (2k + 1)𝜋−x1 for some k ∈ℤ.
In case 1, if we also know that k ≠0, we can solve for 𝜋to see
𝜋= x2 −x1
2k
.
(21.1)
Since x1, x2, 2 and k are rational, this would make 𝜋∈ℚwhich it is not. So k
must be 0 in this cases. Then x2 = x1 + 2k𝜋= x1
In case 2, we get
𝜋= x2 + x1
2k + 1 .
(21.2)
This is not possible, no matter what. So we can only have x1 = x2. Since g(x1) =
g(x2) implies x1 = x2, g(x) is injective.
This seems impossible considering the graph of y = Sin(x), which could not
possibly pass the horizontal line test. But because of all the holes in ℚ, every
horizontal line that hits the graph of g(x) once slips through a hole in the graph
every other time it gets close.
Because g(x) is bijective, it has an inverse function g−1 ∶f (ℚ) →ℚ. Its graph
is the sine curve stood on its head. This is the graph of a function only because
of all the holes. The graph, however, looks just as continuous on its side as it
did in normal position. But recall that we are not talking about the curve being
continuous, but rather the function. And the graph is not the solid curve it
appears to be because of all the irrational holes.
Consider any point b ∈f (ℚ). Suppose that we make even the slightest move
along the x-axis away from this point. The points on the curve above the x values

21.1 Inverses of Continuous Functions
409
we move through go completely bizonkers (not a precisely deﬁned math term).
The points jump about so haphazardly as they move on the x-axis that it is
impossible to track any of the actual heights g(x). In fact, no matter how small
𝜀> 0 might be, the image f (N(a, 𝜀)) will be unbounded above and below. There
is nothing continuous about that functional behavior.
The graph of the curve y = Sin(x) restricted to x ∈ℚis continuous. The func-
tion g ∶ℚ→Sin(ℚ) is continuous on the domain ℚ. The graph of the curve
x = Sin(y) restricted to y ∈ℚis continuous since it is just a 90∘rotation of the
curve y = Sin(x). However, the function g−1: Sin(ℚ) →ℚis not continuous on
its domain. A function is more than the graph of a curve; a function is more
than a set of ordered pairs.
This is a particularly bad example, but it illustrates the point. The theorem
that the inverse of a continuous function is continuous is pretty substantial.
It must be carefully formulated to be true. It would not be surprising if its
proof required a lot of power; power like that embedded in the proofs of: the
Heine–Borel theorem, the inseparability theorem, and the intermediate value
theorem.
21.1.2
The theorem about inverses of continuous functions
First, we need a lemma.
Lemma 21.1.2.
Let f ∶ℝ→ℝhave domain D. Let D be open, f (x) be con-
tinuous on D, and [a, b] ⊆D. We know that either f ([a, b]) = {m} or f ([a, b]) =
[m, M].
If f (x) is injective, then
f ((a, b)) = (m, M).
(21.3)
In other words, the maximum and minimum values of the image occur only at
the end points of the interval.
Proof. Assume f ∶ℝ→ℝhas domain D.
Assume that D is open.
Assume that f (x) is continuous on D.
Assume [a, b] ⊆D.
Assume that f (x) is injective.
From the intermediate value theorem, we know that either f ([a, b]) = {m}
or f ([a, b]) = [m, M]. But because we have an interval, a ≠b, and since f (x) is
injective, f (a) ≠f (b).
So f ([a, b]) = [m, M].
We will only prove that m occurs at an end point of [a, b].
Now m ∈[m, M] = f ([a, b]). So ∃s ∈[a, b] such that f (s) = m.

410
21 A Few Final Observations
Assume BWOC that s ∈(a, b).
Consider [a, s] and [s, b]. Now m = f (s) ∈f ([a, s]) ⊆[m, M]. In addition, m =
f (s) ∈f ([s, b]) ⊆[m, M]. By the intermediate value theorem, both f ([a, s]) and
f ([s, b]) are closed intervals. So by the last remark:
f ([a, s]) = [m, M1];
(21.4)
f ([s, b]) = [m, M2].
Since these are true intervals,
[m, M1] ∩[m, M2] ≠∅.
(21.5)
Let y ∈(m, M1] ∩(m, M2]. Then y ∈f ([a, s]) ∩f ([s, b]). So y ∈f ([a, s]) and
y ∈f ([s, b]). Thus, ∃x1 ∈[a, s] such that f (x1) = y, and ∃x2 ∈[s, b] s.t. f (x2) = y.
But f (x1) = f (x2) with f (x) injective. So
x1 = x2 ∈[a, s] ∩[s, b] = {s}.
(21.6)
Then
x1 = x2 = s.
So
m = f (s) = f (x1) = y ∈(m, M1] ∩(m, M2].
That
is
a contradiction. So m = a or m = b.
◽
Notice that this argument is really geometric. If the minimum m of f ([a, b])
occurs in the interior of the interval [a, b], then it is a local minimum. That
means the graph of the function is higher on both sides of that local minimum.
Since the intermediate value theorem requires images to be intervals, there are
plenty of points on either side of that local minimum that have the same y-value
as the point. So the graph cannot pass the “horizontal line test.” The function
cannot be injective.
Now we are ready to prove the theorem we want. With all the preimages
that are likely to appear, it is best if we give the inverse of our function its own
new name.
Theorem 21.1.3.
Let f ∶D →E where D ⊆ℝand E ⊆ℝ. Let D be open, and
f (x) be continuous on D. Assume that f (x) is bijective.
If g ∶E →D is an inverse function of f , then g(x) is continuous on E.
Proof. Let f ∶D →E where D ⊆ℝand E ⊆ℝ.
Assume that D is open. Assume that f (x) is continuous on D. Assume that
f (x) is bijective.
Comment: What are we proving now? “g(x) is continuous on E.” That is, “∀b ∈E,
g(x) is continuous at x = b.”
Assume b ∈E.

21.1 Inverses of Continuous Functions
411
Comment: What are we proving now? “g(x) is continuous at x = b.” That is,
“∀𝜀> 0, ∃𝛿> 0 so that g(N(b, 𝛿)) ⊆N(g(b), 𝜀).”
Assume 𝜀0 > 0.
Comment: What are we proving now? “∃𝛿> 0 so that g(N(b, 𝛿)) ⊆N(g(b), 𝜀).”
We need to ﬁnd a small number for the domain side of g(x).
Now b ∈E. So g(b) = a ∈D. So f (a) = b.
Consider N(g(b), 𝜀0). This is N(a, 𝜀0), which is a neighborhood of a ∈D.
Comment: Is it small enough? Perhaps not.
Now a ∈N(a, 𝜀0) ∩D, which is an open set. So ∃𝜀1 > 0 such that N(a, 𝜀1) ⊆
N(a, 𝜀0) ∩D. Thus, N(a, 𝜀1) ⊆N(a, 𝜀0) and N(a, 𝜀1) ⊆D. Then
[
a −𝜀1
2 , a −𝜀1
2
]
⊆(a −𝜀1, a −𝜀1)
(21.7)
⊆N(a, 𝜀1)
⊆N(a, 𝜀0) ∩D.
Since f (x) is continuous on the open set D, the intermediate value theorem tells
us that
f
([
a −𝜀1
2 , a −𝜀1
2
])
= [m1, M1].
(21.8)
Since f (x) is bijective, the lemma tells us that
f
((
a −𝜀1
2 , a −𝜀1
2
))
= (m1, M1).
(21.9)
But
f (a) ∈f
((
a −𝜀1
2 , a −𝜀1
2
))
= (m1, M1).
(21.10)
So ∃𝛿= 𝜀1
2 > 0 such that N(f (a), 𝛿) ⊆(m1, M1). That is
N(f (a), 𝛿) ⊆f
((
a −𝜀1
2 , a −𝜀1
2
))
.
(21.11)
Claim. g(N(b, 𝛿)) ⊆N(g(b), 𝜀0).
Proof of claim. Now
N(b, 𝛿) = N(f (a), 𝛿)
(21.12)
⊆f
((
a −𝜀1
2 , a −𝜀1
2
))
.

412
21 A Few Final Observations
So
g(N(b, 𝛿)) ⊆g
(
f
((
a −𝜀1
2 , a −𝜀1
2
)))
(21.13)
⊆
(
a −𝜀1
2 , a −𝜀1
2
)
⊆
[
a −𝜀1
2 , a −𝜀1
2
]
⊆N(a, 𝜀0) ∩D
⊆N(a, 𝜀0)
⊆N(g(b), 𝜀0).
◾
This proves that g(x) is continuous at x = b.
◽
21.2
The intermediate value theorem and continuity
We went to great lengths to prove that a function continuous on a open domain
satisﬁes the intermediate value theorem. If this was so important, why not use
the theorem as the deﬁnition of continuous? The following example shows why
not (Figure 21.1).
Example 21.2.1.
Let f ∶ℝ→ℝbe given by f (x) = Sin(x−1).
This function is not deﬁned at x = 0. A look at the graph shows that the func-
tion is pretty badly behaved around x = 0. We certainly do not want a deﬁnition
of continuous on ℝthat called this function continuous there. However, if a and
b are any two real numbers with f (a) ≠f (b), then for any d between f (a) and
f (b), there is always a c between a and b with f (c) = d.
In mathematical and logical terms, the converse of the intermediate value
theorem is false.
x
−2
−1
1
2
y
−1
1
Figure 21.1 f(x) = Sin(x−1) .

21.4 Conclusion
413
21.3
Continuity at discrete points
Theorem 21.3.1.
Let f ∶ℝ→ℝhave domain D. Let a ∈D∘. Then f (x) is con-
tinuous at a.
Proof. Assume a ∈D∘. Then ∃𝛿1 > 0 so that N(a, 𝛿1) ∩D = {a}. This means,
if x ∈D and |x −a| < 𝛿1, then x = a.
To prove f (x) is continuous at x = a, assume 𝜀> 0. Choose 𝛿= 𝛿1.
To proves this works in the deﬁnition, assume x ∈D and |x −a| < 𝛿= 𝛿1.
The only possibility is x = a. So |f (x) −f (a)| = 0 < 𝜀. So the proof is
ﬁnished.
◽
This may seem odd at ﬁrst. If a function is deﬁned in a way that leaves points
in the domain isolated from any other points where the function is deﬁned,
then the function is automatically continuous at those isolated points. Thus,
any function f ∶ℕ→ℝis continuous on all of ℕ. In addition, any function f ∶
ℤ→ℝis also continuous on its domain. Since no ordered ﬁeld is ever discrete
(the average theorem), there is no such free lunch on a domain that big.
21.4
Conclusion
All this last material is fodder for later courses. However, the ideas of most
other areas of mathematics are based on the ideas introduced in this study:
logic, set theory, functions, and relations. Analysis, real or not, multivariable or
not, starts with a precise deﬁnition of the real numbers that includes complete-
ness. The basic ideas of topology are essential tools for making sense of complex
numbers, real vector spaces, and complex vector spaces from a geometric point
of view. We have only gotten started.

415
Index
Symbols
∧
100
⇔
103
∅
160
∀
109, 107
⇒
102
∈
19, 153
∨
100
±
75
𝜋
212, 287–289, 290, 408
⊆
153
∼
104
∃
109, 107
a
Absolute value
75
Accumulation point
294, 301, 302
330, 333
AE statement
110, 137, 158
Archimedean principle
86, 110, 285
Associative property
7, 9, 105, 155,
235
Average theorem
74, 117, 285
b
Bijective
201
Binary operation
235
Bolzano–Weierstrass theorem
357
Boundary
300
BWOC (by way of contradiction)
68
c
Cartesian product
176
Closed set
311, 312
Closure
303
Commutative property
7, 8, 105, 155,
235
Compact
346, 347, 357, 397
Complement
155
Completeness axiom
83, 284
alternate
84, 181
Complete set
83, 84, 181, 284
Composition
204
Continuous
on a closed set
394
on an open set
391
at a point
363
on a set
389
Contradiction
104, 107, 142
Contrapositive
34, 106, 107, 139
Converse
106
d
Decimal expansions
287
Dedekind cuts
291
Deleted neighborhoods
296
De Morgan’s laws
105, 114, 144, 157,
160, 300, 302, 325
Density theorem
irrationals
91
rationals
88, 286
Discrete points
294, 301, 413

416
Index
Discrete set
11, 46, 78, 300, 307
Distributive property
9, 105, 155,
235
Division algorithm
28, 49
Dummy variable
24
e
EA-statement
110
Equivalence classes
184
Equivalence relation
182
Equivalent fractions
56
Euclid
7, 237
Even numbers
30, 48, 280
Exterior
294, 299
Extreme value theorem
401
f
Families of sets
157–158
Finite sets
239, 246
First partition theorem
300
For all
104, 107
Fractions
53–56, 272
in lowest terms
68, 71, 279
Function
194
bijective
201, 208
codomain
197
domain
196
injective
197
range
196
surjective
197
g
Gluing theorem
385, 401
Gödel, Kurt
119
Greatest lower bound
81, 83
h
Heine–Borel theorem
347
Hypothesis
106
i
Identity element
9, 37, 236
Identity function
206
Identifying sets
52, 53, 67, 272, 279,
282, 290
iﬀ
103
If...then
102, 107
Image
215
Index set
158
Induction
proof by
15–17, 22, 125, 243, 382
theorem of
25, 266
In ﬁmum
112, 113, 180
Inﬁnite sets
239, 240–245
Injective function
197
Inseparability theorem
354, 402
Integers
40, 267
Interior
293, 298, 302
Intermediate value theorem
402,
403, 409, 411, 412
Intersection of a family of sets
158
Intersection of sets
155
Intervals
deﬁnition
169
notation
162
properties
254
Inverse function
207, 208, 410
Inverse of an element
236
Inverse statement
106
Irrational numbers
67, 79, 91, 93–95
l
Least upper bound
84, 86
Logical equivalence
104
Logical statements
99
Lower bound
39, 179
m
Mathematical statements
107
Maximum
48, 180
Minimum
19, 180
Modulo equivalence
186
n
Natural numbers
21, 263
Necessary condition
106

Index
417
Neighborhood
296
o
Odd numbers
30, 48, 280
Open sets
311
Ordered ﬁeld
50, 63, 73, 83, 281, 284
Ordered pairs
175
p
Parsing
129
Polynomial function
382
Power set
242
Preimage
219
Proof
by contradiction
107
by contrapositive
107
direct
12, 107
by induction, see Induction
by minimum counterexample
25,
266
Proper subset
154
q
Qualiﬁers
existence
108
speciﬁcation
108
universal
109
r
Rational function
385, 389, 396, 405
Rational numbers
57, 273
Real numbers
84, 284, 290–292
Reﬂexive property
178
Relation
177
equivalence
182
function
194
total order
179
Russell, Bertrand
172
s
Second partition theorem
301
Set
19, 151
complement
155
equality
153
product
176
Subset
153
Suﬃcient condition
106
Supremum
117, 180, 285
Surjective function
197
Syllogism
121
Symmetric property
178
t
Tautology
104,121
Topological deﬁnition of continuous
closed version
394
open version
391, 398, 402
Total order
179
Transitive property
4, 178
Triangle inequality
77, 283, 378
Trichotomy
5, 102, 178
u
Union of families of sets
158
Union of sets
155
Unique objects
40, 41
Upper bound
48, 84, 180
w
Well deﬁned term
58, 75, 187,
273–275
Well-ordered set
20, 45, 181
z
Zero divisors
40
Zeroth partition theorem
293

