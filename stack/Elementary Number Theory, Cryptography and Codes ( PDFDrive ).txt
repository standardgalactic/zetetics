

123
Number Theory, 
Elementary 
Cryptography 
and Codes
Giulia Maria Piacentini Cattaneo
Maria Welleda Baldoni • Ciro Ciliberto

Printed on acid-free paper
9 8 7 6 5 4 3 2 1
springer.com
Cover design: WMX Design GmbH, Heidelberg
c⃝
ISBN 978-3-540-69199-0
e-ISBN 978-3-540-69200-3
                                   
 Italy
2009 Springer-Verlag Berlin Heidelberg
Mathematics Subject Classiﬁcation (2000):
Library of Congress Control Number: 2008938959
This work is subject to copyright. All rights are reserved, whether the whole or part of the material
is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation, broad-
casting, reproduction on microﬁlm or in any other way, and storage in data banks. Duplication of
this publication or parts thereof is permitted only under the provisions of the German Copyright Law
of September 9, 1965, in its current version, and permission for use must always be obtained from
Springer. Violations are liable to prosecution under the German Copyright Law.
The use of general descriptive names, registered names, trademarks, etc. in this publication does not
imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
 Via della Ricerca Scientifica, 1
baldoni@mat.uniroma2.it
 00133 Roma
Ciro Ciliberto 
piacentini@mat.uniroma2.it
11G05, 14G50, 94B05
Giulia Maria Piacentini Cattaneo
Università di Roma - Tor Vergata 
Maria Welleda Baldoni
 Dipartimento di Matematica
cilibert@mat.uniroma2.it
Cover figure from Balla, Ciacomo  © VG Bild-Kunst, Bonn 2008

Introduction
Mathematics, possibly due to its intrinsic abstraction, is considered to be a
merely intellectual subject, and therefore extremely remote from everyday
human activities. Surprisingly, this idea is sometimes found not only among
laymen, but among working mathematicians as well. So much so that math-
ematicians often talk about pure mathematics as opposed to applied mathe-
matics and sometimes attribute to the former a questionable birthright.
On the other hand, it has been remarked that those two categories do
not exist but, just as we have good and bad literature, or painting, or music,
so we have good or bad mathematics: the former is applicable, even if at
ﬁrst sight this is not apparent, in any number of ﬁelds, while the latter is
worthless, even within mathematics itself. However, one must recognise the
truth in the interesting sentence with which two of our colleagues, experts
about applications, begin the preface to the book [47]: In theory there is no
diﬀerence between theory and practice. In practice there is.
We believe that this diﬀerence cannot be ascribed to the intrinsic nature
of mathematical theories, but to the stance of each single mathematician who
creates or uses these theories. For instance, until recently the branch of math-
ematics regarded as the closest to applications was undoubtedly mathematical
analysis and especially the theory of diﬀerential equations. The branches of
mathematics supposed to be farthest from applications were algebra and num-
ber theory. So much so that a mathematician of the calibre of G. H. Hardy
claimed in his book [25] the supremacy of number theory, which was to be
considered the true queen of mathematics, precisely due to its distance from
the petty concerns of everyday life. This made mathematics, in his words,
“gentle and clean”. A strange opinion indeed, since the ﬁrst developments of
algebra and number theory among the Arabs and the European merchants
in the Middle Ages ﬁnd their motivation exactly in very concrete problems
arising in business and accountancy.
Hardy’s opinion, dating back to the 1940s, was based upon a prejudice,
then largely shared among scientists. It is quite peculiar that Hardy did not
know, or pretended not to know, that A. Turing, whom he knew very well, had

VI
Introduction
used that very mathematics he considered so detached to break the Enigma
code, working for English secret services, dealing a deadly blow to German
espionage (cf. [28]). However, the role played by algebra and number theory
in military and industrial cryptography is well known from time immemorial.
Perhaps Hardy incorrectly believed that the mathematical tools then used in
cryptography, though sometimes quite complex, were nevertheless essentially
elementary, not more than combinatorial tricks requiring a measure of extem-
poraneous talent to be devised or cracked, but leading to no solid, important,
and enduring theories.
The advances in computer science in the last sixty years have made cryp-
tography a fundamental part of all aspects of contemporary life. More pre-
cisely, cryptography studies transmission of data, coded in such a way that
authorised receivers only may decode them, and be sure about their prove-
nience, integrity and authenticity. The development of new, non-classical cryp-
tographic techniques, like public-key cryptography, have promoted and en-
hanced the applications of this branch of the so-called discrete mathematics,
which studies, for instance, the enumeration of symbols and objects, the con-
struction of complex structures starting with simpler ones, and so on. Algebra
and number theory are essential tools for this branch of mathematics, which
is in a natural way suitable for the workings of computers, whose language
is intrinsically discrete rather than continuous, and is essential in the con-
struction of all security systems for data transmission. So, even if we are not
completely aware of it, each time we use credit cards, on-line bank accounts
or e-mail, we are actually fully using algebra and numbers. But there is more:
the same techniques have been applied since the 1940s to the transmission
of data on channels where interference is present. This is the subject of the
theory of error-correcting codes which, though unwittingly, we use daily in
countless ways: for instance when we listen to music recorded on a CD or
when surﬁng the Web.
This textbook originated from the teaching experience of the authors at
the University of Rome “Tor Vergata” where, in the past years, they taught
this subject to Mathematics, Computer Science, Electronic Engineering and
Information Technology students, as well as for the “Scuola di Insegnamento
a Distanza”, and at several diﬀerent levels. They gave courses with a strong
algebraic or geometric content, but keeping in mind the algorithmic and con-
structive aspects of the theories and the applications we have been mentioning.
The point of view of this textbook is to be friendly and elementary. Let
us try to explain what we mean by these terms.
By friendly we mean our attempt to always give motivations of the theo-
retical results we show to the reader, by means of examples we consider to be
simple, meaningful, sometimes entertaining, and useful for the applications.
Indeed, starting from the examples, we have expounded the general methods
of resolution of problems that only apparently look diﬀerent in form, setting
and language. With this in mind, we have aimed to a simple and colloquial

Introduction
VII
style, while never losing sight of the formal rigour required in a mathematical
treatise.
By elementary we mean that we assume our readers to have a quite limited
background in basic mathematical knowledge. As a rule of the thumb, a stu-
dent having followed a good ﬁrst semester in Mathematics, Physics, Computer
Science or Engineering may conﬁdently venture through this book. However,
we have tried to make the treatment as self-contained as possible regarding the
elements of algebra and number theory needed in cryptography and coding
theory applications. Elementary, however, does not mean easy: we introduced
quite advanced concepts, but did so gradually and always trying to accompany
the reader, without assuming previous advanced knowledge.
The starting point of this book is the well-known set of integer numbers
and their arithmetic, that is the study of the operations of addition e multi-
plication. Chapter 1 aims to make the reader familiar with integer numbers.
Here mathematical induction and recursion are covered, giving applications
to several concrete problems, such as the analysis of dynamics of populations
with assigned reproduction rules, the computation of numbers of moves in
several games, and so on. The next topics are divisions, the greatest common
divisor and how to compute it using the well-known Euclidean algorithm, the
resolution of Diophantine equations, and numeral systems in diﬀerent bases.
These basic notions are ﬁrst presented in an elementary way and then a more
general theoretical approach is given, by introducing the concept of Euclidean
ring. The last part of the chapter is devoted to continued fractions.
One of the goals of Chapter 1 is to show how, in order to solve concrete
problems using mathematical methods, the ﬁrst step is to build a mathemat-
ical model that allows a translation into one or more mathematical problems.
The next step is the determination of suitable algorithms, that is procedures
consisting of a ﬁnite sequence of elementary operations yielding the solution
to the mathematical problems describing the initial question. In Chapter 2
we discuss the fundamental concept of computational complexity of an algo-
rithm, which basically counts the elementary operations an algorithm consists
of, thus evaluating the time needed to execute it. The importance of this con-
cept is manifest: among the algorithms we have to distinguish the feasible
ones, that is those executable in a suﬃciently short time, and the unfeasible
ones, due to the time needed for their execution being too long independently
of the computing device used. The algorithms of the ﬁrst kind are the poly-
nomial ones, while among those of the second kind there are, for instance,
the exponential ones. We proceed then to calculate the complexity of some
fundamental algorithms used to perform elementary operations with integer
numbers.
In Chapter 3 we introduce the concept of congruence, which allows the
passage from the inﬁnite set of integer numbers to the ﬁnite set of residue
classes. This passage from inﬁnite to ﬁnite enables us to implement the el-
ementary operations on integers in computer programming: a computer, in
fact, can work on a ﬁnite number of data only.

VIII
Introduction
Chapter 4 is devoted to the fundamental problem of factoring integer
numbers. So we discuss prime numbers, which are the building blocks of the
structure of integer numbers, in the sense that each integer number may be
represented as a product of prime numbers: this is the so-called factorisation
of an integer number. Factoring an integer number is an apparently harmless
problem from a theoretical viewpoint: the factorisation exists, it is essentially
unique, and it can be found by the famous sieve of Eratosthenes. We show,
however, the unfeasibility of this exponential algorithm. For instance, in 1979
it has been proved that the number 244497 −1, having 13395 decimal digits, is
prime: by using the sieve of Eratosthenes, it would take a computer executing
one million multiplications per second about 106684 years to get this result!
The modern public-key cryptography, covered in Chapter 7, basically relies
on the diﬃculty of factoring an integer number. In Chapter 4 elements of the
general theory of factorial rings can also be found, in particular as regards its
application to polynomials.
In Chapter 5 ﬁnite ﬁelds are introduced; they are a generalisation of the
rings of residue classes of integers modulo a prime number. Finite ﬁelds are
fundamental for the applications to cryptography and codes. Here we present
their main properties, expounded with several examples. We give an appli-
cation of ﬁnite ﬁelds to the resolution of polynomial Diophantine equations.
In particular, we prove the law of quadratic reciprocity, the key to solving
second degree congruences.
In Chapter 6 most of the theory presented so far is applied to the search for
primality tests, that is algorithms to determine whether a number is prime
or not, and for factorisation methods more sophisticated than the sieve of
Eratosthenes; even if they are in general exponential algorithms, just like
Eratosthenes’, in special situations they may become much more eﬃcient. In
particular, we present some primality tests of probabilistic type: they are able
to discover in a very short time whether a number has a high probability of
being a prime number. Moreover, we give the proof of a recent polynomial
primality test due to M. Agrawal, N. Kayal and N. Saxena; its publication
has aroused a wide interest among the experts.
Chapter 7 describes the applications to cryptography. Firstly, we describe
several classical cryptographic methods, and discuss the general laying out
of a cryptographic system and the problem of cryptanalysis, which studies
the techniques to break such a system. We introduce next the revolutionary
concept of public-key cryptography, on which the transmission of the bulk
of conﬁdential information, distinctive of our modern society, relies. We dis-
cuss several public-key ciphers, main among them the well-known RSA sys-
tem, whose security relies on the computational diﬃculty of factoring large
numbers, and some of its variants making it possible, for instance, the elec-
tronic authentication of signatures. Recently new frontiers for cryptography,
especially regarding security, have been opened by the interaction of classical
algebra and arithmetic with ideas and concepts originating from algebraic ge-
ometry, and especially the study of a class of plane curves known as elliptic

Introduction
IX
curves. At the end of the chapter an introduction to these important devel-
opments is given.
Chapter 8 presents an introduction to coding theory, already mentioned
above. This is a recent branch of mathematics in which sophisticated combi-
natorial, algebraic and geometric techniques converge, in order to study the
mathematical aspects of the problem of transmitting data through noisy chan-
nels. In other words, coding theory studies techniques to send data through a
channel when we give for granted that some errors will happen during trans-
mission. These techniques enable us to correct the errors that might arise, as
well as to quickly encode and decode the data we intend to send.
In Chapter 9 we give a quick glance at the new frontiers oﬀered by quan-
tum cryptography, which relies on ideas originating in quantum mechanics.
This branch of physics makes the creation of a quantum computer at least
conceivable; if such a computer were actually built, it could execute in poly-
nomial time computations a usual computer would need an exponential time
to perform. This would make all present cryptographic systems vulnerable,
seriously endangering civil, military, ﬁnancial security systems. This might re-
sult in the collapse of our civilisation, largely based on such systems. On the
other hand, by its very nature, the concept of a quantum computer allows the
design of absolutely unassailable quantum cryptographic systems, even by a
quantum computer; furthermore, such systems have the astonishing property
of being able to detect if eavesdroppers attempt, even unsuccessfully, to hear
in on a restricted communication.
Each chapter is followed by an appendix containing:
•
a list of exercises on the theory presented there, with several levels of
diﬃculty; in some of them proofs of supplementary theorems or alternative
proofs of theorems already proved in the text are given;
•
a list of exercises from a computational viewpoint;
•
suggestions for programming exercises.
The most diﬃcult exercises are marked by an asterisk. At the end of the
book many of the exercises are solved, especially the hardest theoretical ones.
Some sections of the text may be omitted in a ﬁrst reading. They are set
in a smaller type, and so are the appendices.
We wrote this book having in mind students of Mathematics, Physics,
Computer Science, Engineering, as well as researchers who are looking for an
introduction, without entering in too many details, to the themes we have
quickly described above.
In particular, the book can be useful as a complementary text for ﬁrst and
second year students in Mathematics, Physics or Computer Science taking
a course in Algebra or Discrete Mathematics. In Chapters 1, 3, and 4 they
will ﬁnd a concrete approach, with many examples and exercises, to some
basic algebraic theories. Chapters 5 and 6, though more advanced, are in our
opinion within the reach of a reader of this category.

X
Introduction
The text is particularly suitable for a second or third year course giving
an introduction to cryptography or to codes. Students of such a course will
probably already have been exposed to the contents of Chapters 1, 3, and 4;
so teachers can limit themselves to quick references to them, suggesting to
the students only to solve some exercises. They can then devote more time to
the material from Chapter 5 on, and particularly to Chapter 7, giving more
or less space to Chapters 8 and 9.
The bibliography lists texts suggested for further studies in cryptography
and codes, useful for more advanced courses.
A ﬁrst version of this book, titled “Note di matematica discreta”, was
published in 2002 by Aracne; we are very grateful to the publishers for their
permission for the publication of this book. This edition is widely expanded
and modiﬁed: the material is presented diﬀerently, several new sections and
in-depth analysis have been added, a wider selection of solved exercises is
oﬀered.
Lastly, we thank Dr Alberto Calabri for supervising the layout of the book
and the editing of the text, especially as regards the exercise sections.
M. Welleda Baldoni
Rome,
Ciro Ciliberto
August 2008
Giulia Maria Piacentini Cattaneo

Contents
1
A round-up on numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Mathematical induction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
The concept of recursion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.2.1
Fibonacci numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.2.2
Further examples of population dynamics . . . . . . . . . . . . . 11
1.2.3
The tower of Hanoi: a non-homogeneous linear case . . . . 13
1.3
The Euclidean algorithm. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
1.3.1
Division . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
1.3.2
The greatest common divisor . . . . . . . . . . . . . . . . . . . . . . . . 16
1.3.3
B´ezout’s identity. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
1.3.4
Linear Diophantine equations . . . . . . . . . . . . . . . . . . . . . . . 20
1.3.5
Euclidean rings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
1.3.6
Polynomials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
1.4
Counting in diﬀerent bases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
1.4.1
Positional notation of numbers . . . . . . . . . . . . . . . . . . . . . . 30
1.4.2
Base 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
1.4.3
The four operations in base 2 . . . . . . . . . . . . . . . . . . . . . . . . 33
1.4.4
Integer numbers in an arbitrary base . . . . . . . . . . . . . . . . . 39
1.4.5
Representation of real numbers in an arbitrary base . . . . 40
1.5
Continued fractions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
1.5.1
Finite simple continued fractions and rational numbers . 44
1.5.2
Inﬁnite simple continued fractions and irrational
numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
1.5.3
Periodic continued fractions . . . . . . . . . . . . . . . . . . . . . . . . . 56
1.5.4
A geometrical model for continued fractions . . . . . . . . . . . 57
1.5.5
The approximation of irrational numbers by convergents 58
1.5.6
Continued fractions and Diophantine equations . . . . . . . . 61
Appendix to Chapter 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
A1
Theoretical exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
B1
Computational exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
C1
Programming exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84

XII
Contents
2
Computational complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
2.1
The idea of computational complexity . . . . . . . . . . . . . . . . . . . . . . 87
2.2
The symbol O . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
2.3
Polynomial time, exponential time . . . . . . . . . . . . . . . . . . . . . . . . . 92
2.4
Complexity of elementary operations . . . . . . . . . . . . . . . . . . . . . . . 95
2.5
Algorithms and complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
2.5.1
Complexity of the Euclidean algorithm . . . . . . . . . . . . . . . 98
2.5.2
From binary to decimal representation: complexity . . . . . 101
2.5.3
Complexity of operations on polynomials . . . . . . . . . . . . . 101
2.5.4
A more eﬃcient multiplication algorithm. . . . . . . . . . . . . . 103
2.5.5
The Ruﬃni–Horner method . . . . . . . . . . . . . . . . . . . . . . . . . 105
Appendix to Chapter 2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
A2
Theoretical exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
B2
Computational exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
C2
Programming exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
3
From inﬁnite to ﬁnite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
3.1
Congruence: fundamental properties . . . . . . . . . . . . . . . . . . . . . . . . 115
3.2
Elementary applications of congruence . . . . . . . . . . . . . . . . . . . . . . 120
3.2.1
Casting out nines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
3.2.2
Tests of divisibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
3.3
Linear congruences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
3.3.1
Powers modulo n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
3.4
The Chinese remainder theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
3.5
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
3.5.1
Perpetual calendar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
3.5.2
Round-robin tournaments . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
Appendix to Chapter 3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
A3
Theoretical exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
B3
Computational exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
C3
Programming exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
4
Finite is not enough: factoring integers . . . . . . . . . . . . . . . . . . . . . 149
4.1
Prime numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
4.1.1
The Fundamental Theorem of Arithmetic . . . . . . . . . . . . . 150
4.1.2
The distribution of prime numbers . . . . . . . . . . . . . . . . . . . 152
4.1.3
The sieve of Eratosthenes . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
4.2
Prime numbers and congruences . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
4.2.1
How to compute Euler function . . . . . . . . . . . . . . . . . . . . . . 160
4.2.2
Fermat’s little theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
4.2.3
Wilson’s theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
4.3
Representation of rational numbers in an arbitrary base . . . . . . 166
4.4
Fermat primes, Mersenne primes and perfect numbers . . . . . . . . 168
4.4.1
Factorisation of integers of the form bn ± 1 . . . . . . . . . . . . 168
4.4.2
Fermat primes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170

Contents
XIII
4.4.3
Mersenne primes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
4.4.4
Perfect numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
4.5
Factorisation in an integral domain. . . . . . . . . . . . . . . . . . . . . . . . . 173
4.5.1
Prime and irreducible elements in a ring . . . . . . . . . . . . . . 174
4.5.2
Factorial domains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
4.5.3
Noetherian rings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
4.5.4
Factorisation of polynomials over a ﬁeld . . . . . . . . . . . . . . 179
4.5.5
Factorisation of polynomials over a factorial ring . . . . . . . 182
4.5.6
Polynomials with rational or integer coeﬃcients . . . . . . . . 188
4.6
Lagrange interpolation and its applications . . . . . . . . . . . . . . . . . . 191
4.7
Kronecker’s factorisation method . . . . . . . . . . . . . . . . . . . . . . . . . . 195
Appendix to Chapter 4. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
A4
Theoretical exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
B4
Computational exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204
C4
Programming exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
5
Finite ﬁelds and polynomial congruences . . . . . . . . . . . . . . . . . . . 213
5.1
Some ﬁeld theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
5.1.1
Field extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
5.1.2
Algebraic extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
5.1.3
Splitting ﬁeld of a polynomial . . . . . . . . . . . . . . . . . . . . . . . 217
5.1.4
Roots of unity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
5.1.5
Algebraic closure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
5.1.6
Finite ﬁelds and their subﬁelds . . . . . . . . . . . . . . . . . . . . . . 220
5.1.7
Automorphisms of ﬁnite ﬁelds . . . . . . . . . . . . . . . . . . . . . . . 222
5.1.8
Irreducible polynomials over Zp . . . . . . . . . . . . . . . . . . . . . . 222
5.1.9
The ﬁeld F4 of order four . . . . . . . . . . . . . . . . . . . . . . . . . . . 224
5.1.10 The ﬁeld F8 of order eight . . . . . . . . . . . . . . . . . . . . . . . . . . 225
5.1.11 The ﬁeld F16 of order sixteen . . . . . . . . . . . . . . . . . . . . . . . . 226
5.1.12 The ﬁeld F9 of order nine . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
5.1.13 About the generators of a ﬁnite ﬁeld . . . . . . . . . . . . . . . . . 227
5.1.14 Complexity of operations in a ﬁnite ﬁeld . . . . . . . . . . . . . . 228
5.2
Non-linear polynomial congruences . . . . . . . . . . . . . . . . . . . . . . . . . 229
5.2.1
Degree two congruences. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
5.2.2
Quadratic residues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
5.2.3
Legendre symbol and its properties. . . . . . . . . . . . . . . . . . . 238
5.2.4
The law of quadratic reciprocity . . . . . . . . . . . . . . . . . . . . . 243
5.2.5
The Jacobi symbol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
5.2.6
An algorithm to compute square roots . . . . . . . . . . . . . . . . 248
Appendix to Chapter 5. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251
A5
Theoretical exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251
B5
Computational exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
C5
Programming exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260

XIV
Contents
6
Primality and factorisation tests . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
6.1
Pseudoprime numbers and probabilistic tests . . . . . . . . . . . . . . . . 261
6.1.1
Pseudoprime numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
6.1.2
Probabilistic tests and deterministic tests . . . . . . . . . . . . . 263
6.1.3
A ﬁrst probabilistic primality test . . . . . . . . . . . . . . . . . . . . 263
6.1.4
Carmichael numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
6.1.5
Euler pseudoprimes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
6.1.6
The Solovay–Strassen probabilistic primality test . . . . . . 268
6.1.7
Strong pseudoprimes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
6.1.8
The Miller–Rabin probabilistic primality test . . . . . . . . . . 272
6.2
Primitive roots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
6.2.1
Primitive roots and index . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
6.2.2
More about the Miller–Rabin test . . . . . . . . . . . . . . . . . . . . 279
6.3
A polynomial deterministic primality test . . . . . . . . . . . . . . . . . . . 281
6.4
Factorisation methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
6.4.1
Fermat factorisation method . . . . . . . . . . . . . . . . . . . . . . . . 291
6.4.2
Generalisation of Fermat factorisation method . . . . . . . . . 292
6.4.3
The method of factor bases . . . . . . . . . . . . . . . . . . . . . . . . . 294
6.4.4
Factorisation and continued fractions . . . . . . . . . . . . . . . . . 299
6.4.5
The quadratic sieve algorithm . . . . . . . . . . . . . . . . . . . . . . . 300
6.4.6
The ρ method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
6.4.7
Variation of ρ method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311
Appendix to Chapter 6. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
A6
Theoretical exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
B6
Computational exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315
C6
Programming exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
7
Secrets. . . and lies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
7.1
The classic ciphers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
7.1.1
The earliest secret messages in history . . . . . . . . . . . . . . . . 319
7.2
The analysis of the ciphertext . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
7.2.1
Enciphering machines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329
7.3
Mathematical setting of a cryptosystem. . . . . . . . . . . . . . . . . . . . . 330
7.4
Some classic ciphers based on modular arithmetic . . . . . . . . . . . . 334
7.4.1
Aﬃne ciphers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336
7.4.2
Matrix or Hill ciphers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 340
7.5
The basic idea of public key cryptography. . . . . . . . . . . . . . . . . . . 341
7.5.1
An algorithm to compute discrete logarithms . . . . . . . . . . 344
7.6
The knapsack problem and its applications to cryptography . . . 345
7.6.1
Public key cipher based on the knapsack problem,
or Merkle–Hellman cipher . . . . . . . . . . . . . . . . . . . . . . . . . . . 348
7.7
The RSA system. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349
7.7.1
Accessing the RSA system . . . . . . . . . . . . . . . . . . . . . . . . . . 351
7.7.2
Sending a message enciphered with the RSA system . . . . 352
7.7.3
Deciphering a message enciphered with the
RSA system . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354

Contents
XV
7.7.4
Why did it work? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 356
7.7.5
Authentication of signatures with the RSA system . . . . . 360
7.7.6
A remark about the security of RSA system . . . . . . . . . . . 362
7.8
Variants of RSA system and beyond . . . . . . . . . . . . . . . . . . . . . . . . 363
7.8.1
Exchanging private keys . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363
7.8.2
ElGamal cryptosystem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364
7.8.3
Zero-knowledge proof: persuading that a result is
known without revealing its content nor its proof . . . . . . 365
7.8.4
Historical note. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366
7.9
Cryptography and elliptic curves . . . . . . . . . . . . . . . . . . . . . . . . . . . 366
7.9.1
Cryptography in a group. . . . . . . . . . . . . . . . . . . . . . . . . . . . 367
7.9.2
Algebraic curves in a numerical aﬃne plane . . . . . . . . . . . 368
7.9.3
Lines and rational curves . . . . . . . . . . . . . . . . . . . . . . . . . . . 369
7.9.4
Hyperelliptic curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370
7.9.5
Elliptic curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372
7.9.6
Group law on elliptic curves . . . . . . . . . . . . . . . . . . . . . . . . . 374
7.9.7
Elliptic curves over R, C and Q . . . . . . . . . . . . . . . . . . . . . . 380
7.9.8
Elliptic curves over ﬁnite ﬁelds . . . . . . . . . . . . . . . . . . . . . . 381
7.9.9
Elliptic curves and cryptography . . . . . . . . . . . . . . . . . . . . . 384
7.9.10 Pollard’s p −1 factorisation method . . . . . . . . . . . . . . . . . . 385
Appendix to Chapter 7. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
A7
Theoretical exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
B7
Computational exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
C7
Programming exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401
8
Transmitting without. . . fear of errors . . . . . . . . . . . . . . . . . . . . . 405
8.1
Birthday greetings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406
8.2
Taking photos in space or tossing coins, we end up at codes . . . 407
8.3
Error-correcting codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410
8.4
Bounds on the invariants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 413
8.5
Linear codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419
8.6
Cyclic codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 425
8.7
Goppa codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 429
Appendix to Chapter 8. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436
A8
Theoretical exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436
B8
Computational exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439
C8
Programming exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 443
9
The future is already here: quantum cryptography . . . . . . . . . 445
9.1
A ﬁrst foray into the quantum world: Young’s experiment . . . . . 446
9.2
Quantum computers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449
9.3
Vernam’s cipher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451
9.4
A short glossary of quantum mechanics . . . . . . . . . . . . . . . . . . . . . 454
9.5
Quantum cryptography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 460
Appendix to Chapter 9. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 467

XVI
Contents
A9
Theoretical exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 467
B9
Computational exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 468
C9
Programming exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 469
Solution to selected exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 471
Exercises of Chapter 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 471
Exercises of Chapter 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 482
Exercises of Chapter 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 483
Exercises of Chapter 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 487
Exercises of Chapter 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 492
Exercises of Chapter 6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 496
Exercises of Chapter 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 498
Exercises of Chapter 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 501
Exercises of Chapter 9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 504
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 507
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 511

1
A round-up on numbers
This chapter rounds up some basic notions about numbers; we shall need them
later on, and it is useful to ﬁx the ideas on some concepts and techniques which
will be investigated in this book. Some of what follows will be studied again
in more detail, but we shall assume a basic knowledge about:
•
some elements of set theory and logic (see for instance [43]);
•
the construction of the fundamental number sets:
N = the set of natural numbers,
Z = the set of integer numbers,
Q = the set of rational numbers,
R = the set of real numbers,
C = the set of complex numbers,
and of the operations on them (see [15] or [22]);
•
the idea of limit and of numerical series (as given in any calculus text, for
instance [12]);
•
some elements of algebra (see [4], [15], [32] or [45]): in particular, the reader
will need the deﬁnitions of the main algebraic structures, like semigroups,
groups, rings, integral domains, ﬁelds;
•
basic notions of linear algebra (see [13]): vector spaces, matrices, eigenval-
ues, and eigenvectors;
•
elementary concepts of probability theory (see [5] or [29]).
1.1 Mathematical induction
In this section we shall ﬁx our attention on the set N = {0, 1, 2, 3, . . .} of
natural numbers on which, as is well known, the operations +, the addition,
and ·, the multiplication, as well as a natural order relation ≤are given. Recall

2
1 A round-up on numbers
that both (N, +) and (N, ·) are semigroups, that is to say, the operations are
associative, and admit an identity element.
On the set N the map
succ : n ∈N →n + 1 ∈N
is deﬁned, associating with each natural number its successor. This mapping
is injective but not surjective, as 0 is not the successor of any natural number.
The existence of such an injective but not surjective mapping of N in itself
implies that it is an inﬁnite set.
Furthermore, the following fundamental property holds in N:
Mathematical induction. Let A be a subset of N satisfying the following
two properties:
(1) n0 ∈A;
(2) if n ∈A then, for each n, succ(n) = n + 1 ∈A.
Then A includes all natural numbers greater or equal than n0. In particular,
if n0 = 0, then A coincides with N.
It is well known that the existence of the mapping succ and mathematical
induction uniquely determine the set of natural numbers. Mathematical in-
duction is important not only for the formal construction of the set N, but is
also a fundamental proof tool to which we want to draw the reader’s attention.
Let us look at a simple example. Suppose we want to solve the follow-
ing problem: compute the sum of the ﬁrst n natural numbers, that is to say
compute the number
1 + 2 + · · · + (n −1) + n.
Some of the readers might already know that this problem, in the case
n = 100, appears in an episode of Carl Friedrich Gauss’s life. When he was
six years old, his teacher gave it to his unruly pupils, in the hope that it
would take them some time to solve it, to keep them quiet in the meantime.
Unfortunately (for the teacher), Gauss noticed that
n + 1 = (n −1) + 2 = (n −2) + 3 = · · · ,
that is, the sum of the last term and of the ﬁrst one equals the sum of the
last but one plus the second one, and so forth; so he guessed in a few seconds
the general formula
1 + 2 + · · · + (n −1) + n = n(n + 1)
2
(1.1)
and immediately obtained
1 + 2 + · · · + 99 + 100 = 5050.

1.1 Mathematical induction
3
But how may we prove that, as young Gauss guessed, formula (1.1) always
holds? Of course, it is not possible to check it for each n by actually summing
up the terms, because we should verify an inﬁnite number of cases. What
mathematical induction allows us to do is precisely solving problems of this
kind, even in more general cases.
Consider a set X and a sequence {Pn} of propositions deﬁned in X, that
is, for each number n ∈N, Pn is a proposition about the elements of X. For
instance, in the case X = N, we may take
Pn = formula (1.1) holds,
that is, Pn is the claim that for the number n ∈N the sum 1+2+· · ·+(n−1)+n
equals n(n + 1)/2. Suppose we want to prove that the proposition Pn is true
for each n. Thus, we have to prove inﬁnitely many propositions. Consider the
set
A := {n ∈N | Pn is true}.
We have to prove that A coincides with N. Applying mathematical induction
it suﬃces to proceed as follows:
(1) basis of the induction: prove that P0 is true;
(2) inductive step: prove that, for each k ≥0, from the truth of Pk (induction
hypothesis), it follows that Pk+1 is true.
Then we may conclude that Pn is true for each n ∈N.
With a proof by induction we may obtain inﬁnitely many results in just
two steps. In this sense, it is a method of reduction from inﬁnite to ﬁnite, and
so it has a crucial importance, inﬁnity being by its very nature intractable.
Further on we shall show several methods, techniques and ideas in the same
spirit of reducing from inﬁnite to ﬁnite.
An apparently more restrictive, but actually equivalent (see Exercises
A1.1–A1.3) formulation of the same principle is as follows:
Complete induction (or Strong induction) (CI). Let A be a subset of N
satisfying the following properties:
(1) n0 ∈A;
(2) if k ∈A for each k such that n0 ≤k < n, then n ∈A as well.
Then A includes all natural numbers greater than n0. In particular, if n0 = 0,
then A coincides with N.
This yields, as above, the following formulation:
(1) basis of the induction: prove that P0 is true;
(2) inductive step: prove that, for each k ≥0, from the truth of Ph for each
h ≤k, it follows that Pk+1 is true.

4
1 A round-up on numbers
Then we may conclude that Pn is true for each n ∈N.
Let the reader be warned that, as implicitely stated above, mathematical
induction, in itself, does not yield formulas, but allows us to prove them if
we already know them. In other words, if we already are in possession of the
sequence of propositions Pn we may hope to prove their truth by mathemat-
ical induction, but this method in itself will not give us the sequence Pn. In
practice, if we have a problem like the one given to Gauss as a young boy, in
order to guess the right sequence of propositions Pn it is necessary to study
what happens for the ﬁrst values of n and, following Gauss’s example, venture
a conjecture about the general situation.
As an example, we prove by induction formula (1.1).
The basis of the induction lies just in observing that the formula is obvi-
ously true for n = 1. Suppose now that the formula is true for a particular
value of n, and let us prove its truth for its successor n + 1. We have:
1 + 2 + · · · + (n −1) + n + (n + 1) =
= [1 + 2 + · · · + (n −1) + n] + (n + 1) =
(by induction hypothesis)
= n(n + 1)
2
+ (n + 1) = (n + 1)(n + 2)
2
.
This proves the inductive step for each n, and so proves formula (1.1).
Other examples in which mathematical induction is used to prove formulas
similar to (1.1) are given in the appendix at the end of this chapter (see
Exercises B1.5–B1.11).
Remark 1.1.1. Before carrying on, it might be useful to warn readers of the snares
deriving by erroneous applications of mathematical induction. In a proof by induc-
tion, both steps, the basis of the induction and the inductive step, are indispensable
to a correct application of the procedure, and both are to be correctly carried out.
Otherwise, we are in danger of making gross mistakes. For instance, an erroneous
application of mathematical induction might yield a proof of the following ludicrous
claim: All cats are the same colour.
Let us proceed by induction, by proving that for each n ∈N, any set of n cats
is made up of cats of the same colour:
•
basis of the induction: It is obvious; indeed any set including a single cat is made
up of cats of the same colour, that is, the colour of the unique cat in the set.
•
inductive step: Suppose that every time we have n −1 cats they are the same
colour and let us prove that the same claim holds for n cats. Examine the
following picture, where the dots represent cats:
n−1



• • • • • · · · • • • • •



n−1
.
(1.2)
By induction hypothesis, the ﬁrst n −1 cats are all the same colour. By the
same reason, the last n −1 cats are the same colour as well, this colour being
a priori diﬀerent from the colour of the ﬁrst cats. But the common cats, that is
the cats appearing both among the ﬁrst n −1 and the last n −1, must be the
same colour. So all the cats are the same colour.

1.2 The concept of recursion
5
Since, fortunately, there are cats of diﬀerent colours, we are conﬁdent that we
have made a mistake. Where is it? In the inductive step we used the fact that there
are cats in common to the two sets we were considering, the ﬁrst n −1 cats and the
last n −1 cats. But this is true only if n ≥3. So the inductive step does not hold
for each n because the implication from the case n = 1 to n = 2 does not hold.
Notice that if we want to prove a proposition Pn not for all values of n, but for
all n ≥n0, it is enough to prove as the basis for the induction the proposition Pn0
and then verifying the inductive step for each n ≥n0. Studying again the example
about cats, the inductive steps holds for n ≥2, but the basis of the induction does
not hold for n = 2, that is, it is not true that each pair of cats consists of cats of
the same colour!
1.2 The concept of recursion
Recursion is a fundamental concept, strictly connected to mathematical in-
duction. Suppose we have a function deﬁned on the set N of natural numbers
taking values in a set X. Such a function is commonly said to be a sequence
in X and denoted by {an}n∈N, or simply {an}, where an is the value taken
by the function on the integer n. The values an are said to be the terms of
the sequence.
Suppose now we have a method allowing us to determine the term an for
each integer n greater or equal than a ﬁxed integer n0 when we know the term
an−1. Suppose moreover we know the initial terms of the sequence, that is
a0, a1, a2, . . ., an0−1, an0. We claim that, with these premises, we are able
to compute the value of the sequence for each natural number n. This is a
consequence of mathematical induction and its easy proof is left to the reader
(see Exercise A1.10).
A particular but very interesting example of this procedure is the case of
numeric sequences satisfying linear recurrence relations. Let us give a general
deﬁnition:
Deﬁnition 1.2.1. Let {an}n∈N be a sequence of elements in a vector space V
on a ﬁeld K. A linear recurrence relation, or formula, for the sequence is a
formula of the kind
an+k = fk−1(an+k−1) + fk−2(an+k−2) + · · · + f0(an) + dn,
(1.3)
holding for each integer n ≥0; here k is a positive integer, a0, a1, . . ., ak−1 are
the initial values or conditions, f0, f1, . . ., fk−1 are linear maps of V in itself,
called coeﬃcients of the recurrence relation, and {dn} is a (possibly constant)
sequence of elements in V said constant term. If dn = 0, the relation is said
to be homogeneous.
So, formula (1.3) gives an expression for the (n+k)-th term of the sequence
{an} as a function of the k preceding terms. We shall mostly consider the case
where {dn} is a constant sequence with each term equal to d. The word linear

6
1 A round-up on numbers
refers to the fact that we are working in a vector space V . In particular, it is
possible to consider sequences {an}n∈N of elements of K verifying a recurrence
relation. In this case f0, f1, . . ., fk−1 are the product by elements b0, b1, . . .,
bk−1 of K and relation (1.3) is of the form
an+k = bk−1an+k−1 + bk−2an+k−2 + · · · + b0an + dn.
(1.4)
A sequence {an}n∈N is said to be a solution of a linear recurrence relation
of the form (1.3) if the terms an of the sequence satisfy the relation. It is
obvious that the sequence is uniquely determined by relation (1.3) and by the
initial terms a0, a1, . . ., ak−1.
On the other hand, if we know that a sequence {an}n∈N of elements of the
ﬁeld K veriﬁes a linear recurrence relation of the form (1.4), but we do not
know the coeﬃcients b0, b1, . . ., bk−1 and the constant term d, we may expect
to be able to determine these coeﬃcients, and then the whole sequence, if we
know suﬃciently many terms of the sequence (see, as a particular instance,
Exercise A1.27).
Recurrence relations appear in a natural way when studying several dif-
ferent kinds of problems, like computing increments or decrements of popula-
tions with given reproduction rules, colouring pictures with just two colours,
computing the number of moves in diﬀerent games, computing compounded
interests, solving geometrical problems and so forth. Some of these problems
will be shown as examples or suggested as exercises in the appendix.
1.2.1 Fibonacci numbers
Example 1.2.2. Two newborn rabbits, a male and a female, are left on a
desert island on the 1st of January. This couple becomes fertile after two
months and, starting on the 1st of March, they give birth to two more rabbits,
a male and a female, the ﬁrst day of each month. Each couple of newborn
rabbits, analogously, becomes fertile after two months and, starting on the
ﬁrst day of their third month, gives birth to a new couple of rabbits. How
many couples are there on the island after n months?
In order to answer this question, we must construct a mathematical model
for the population increase of rabbits, as described in the example. Denote by
fn the number of couples of rabbits, a male and a female, that are present in
the island during the nth month. It is clear that fn is the sum of two numbers
completely determined by the situation in the preceding months, that is fn is
the sum
(1) of the number fn−1 of the couples of rabbits in the island in the (n−1)-th
month, as no rabbit dies;
(2) of the number of the couples of rabbits born on the ﬁrst day of n-th
month, which are as many as the couples of rabbits which are fertile on
that day, and these in turn are as many as the fn−2 couples of rabbits
that were in the island two months before.

1.2 The concept of recursion
7
As a consequence, we may write for the sequence {fn}n∈N the following
recurrence relation:
fn = fn−1 + fn−2
for each n ≥2 with the obvious initial conditions f0 = 0 e f1 = 1.
The sequence {fn} of natural numbers satisfying the following recurrence
relation with given initial conditions
f0 = 0,
f1 = 1,
fn = fn−1 + fn−2
for n > 1,
(1.5)
is called Fibonacci sequence, and the terms of the sequence are called Fibonacci
numbers. Each term of the sequence is the sum of the two preceding terms and
knowing this sequence it is possible to give an answer to the problem described
in Example 1.2.2. The ﬁrst terms of the sequence are easy to compute:
0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, . . .
Fibonacci numbers are not only related to population increase, but are of-
ten found in the description of several natural phenomenona. For instance,
sunﬂowers’ heads display ﬂorets in spirals which are generally arranged with
34 spirals in one direction and 55 in the other. If the sunﬂower is smaller, it
has 21 spirals in one direction and 34 in the other, or 13 and 21. If it is very
large, it has 89 and 144 spirals! In each case these numbers are, not by chance,
Fibonacci numbers.
Fibonacci numbers were introduced by Leonardo Fibonacci, or Leonardo
Pisano, in 1202, with the goal of describing the increase of a rabbit popula-
tion. These numbers have many interesting mathematical properties, so much
that along the centuries they have been, and still are, studied by many math-
ematicians. For instance, at the end of the 19th century Edouard Lucas used
some properties of Fibonacci numbers to show that the 39-digit number
170141183460469231731687303715884105727 = 2127 −1
is a prime number (see Chapter 4).
Let us remark that writing relation (1.5) is not an altogether satisfying
way of answering the question posed in Example 1.2.2. We would like, in fact,
to have a solution of the recurrence relation (1.5), that is a closed formula
giving the n-th term of Fibonacci sequence, without having to compute all
the preceding terms. In order to do so, we shall use matrix operations and
some principles of linear algebra.
Consider the matrix on R
A =
 0 1
1 1

.
(1.6)
We may rewrite conditions (1.5) in the following way:
A
fn−2
fn−1

=
fn−1
fn

for all n ≥2,

8
1 A round-up on numbers
that is, setting Xn =

fn−1
fn

, consider the linear system
AXn−1 = Xn,
for all n ≥2,
and so
AnX0 = Xn.
Thus, if we know An, to ﬁnd the closed formula expressing fn as a function
of the initial conditions it suﬃces to multiply the second row of An by X0.
In this case it is easy to prove by induction, using formula (1.5), that (see
Exercise A1.28):
Proposition 1.2.3. For each integer number n ≥1 we have
An =
 fn−1
fn
fn
fn+1

,
where {fn} is Fibonacci sequence.
Unfortunately, in the general case it is not easy to compute the powers of
a matrix: in Chapter 2 we shall fully appreciate this problem, when we study
the computational complexity of some operations. In some cases, however, as
in the present one, the computation is not diﬃcult, as we are going to show.
If we have a diagonal matrix D, that is one of the form
D =
 a 0
0 b

,
then computing Dn is trivial, because we have
Dn =
 an
0
0
bn

.
Let us recall that a matrix B on a ﬁeld K is said to be diagonalisable
if there exists a matrix C whose determinant is not equal to zero such that
B = C · D · C−1, where D is a diagonal matrix. For diagonalisable matrices
computing powers is also simple. In fact, if B is as above, we trivially have
Bn = C · Dn · C−1. As Dn is easy to compute, it suﬃces to know D and C
in order to know the powers of B. Now, there is an easy criterion to ascertain
whether a matrix is diagonalisable: an m×m matrix B is diagonalisable if its
characteristic polynomial PB(t) has m distinct roots in K (see the deﬁnitions
recalled in § 1.3.6). Let us recall that PB(t) is the polynomial of degree m on
K deﬁned as the determinant |B −tIm|, where Im is identity matrix, that is
the square m×m matrix with entries equal to 1 on the main diagonal and zero
elsewhere. The roots of the characteristic polynomial PB(t) that are elements
of K are called the eigenvalues of B. If B = C · D · C−1 with diagonal D, the
elements on the main diagonal of D are the eigenvalues of B.

1.2 The concept of recursion
9
For the real matrix A in (1.6) we have that
PA(t) = det
 −t
1
1
1 −t

= t2 −t −1
is a polynomial having two distinct real roots given by
λ1 = 1 +
√
5
2
,
λ2 = 1 −
√
5
2
.
(1.7)
Thus A is diagonalisable and as a consequence we have an expression of the
form A = C · D · C−1, with
D =
 (1 +
√
5)/2
0
0
(1 −
√
5)/2

.
(1.8)
The matrix C is easy to write down. The reader may verify (see Exercises
B1.12 and B1.13) that
C =

1
1
(1 +
√
5)/2 (1 −
√
5)/2

,
C−1 =
1
√
5

−(1 −
√
5)/2
1
(1 +
√
5)/2
−1

. (1.9)
In conclusion, by Proposition 1.2.3, we have the relation

fn−1
fn
fn
fn+1

= C ·
 
(1 +
√
5)/2
	n
0
0

(1 −
√
5)/2
	n

· C−1.
Hence, by multiplying the matrices in the right-hand side, we get the following
closed formula for the n-th Fibonacci number:
fn =
1
√
5


1 +
√
5
2
n
−

1 −
√
5
2
n 
.
(1.10)
We give the following proposition, which generalises what we have proved
in the case of the recurrence relation (1.5).
Proposition 1.2.4. Given a positive integer k, consider the homogeneous lin-
ear recurrence relation deﬁned on a ﬁeld K
an+k = bk−1an+k−1 + bk−2an+k−2 + · · · + b0an,
for n ≥0,
(1.11)
where b0, b1, . . . , bk−1 are the coeﬃcients and a0, a1, . . . , ak−1 the initial values.
Consider the square k × k matrix deﬁned by
A =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0
1
0
0 . . .
0
0
0
1
0 . . .
0
0
0
0
1 . . .
0
...
...
...
...
...
...
0
0
0
0 . . .
1
b0 b1 b2 b3 . . . bk−1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠

10
1 A round-up on numbers
whose characteristic polynomial is
PA(t) = tk −bk−1tk−1 −bk−2tk−2 −· · · −b1t −b0.
Suppose that PA(t) has k distinct roots λi, 1 ≤i ≤k, in K. Then the solutions
of the recurrence relation are of the form
an =
k

i=1
ciλn
i ,
for each n ≥0,
with ci constants uniquely determined by the linear system
k

i=1
ciλh
i = ah,
with
0 ≤h ≤k −1,
determined by the initial values a0, a1, . . . , ak−1.
So we can now solve homogeneous linear recurrence relations when the
characteristic polynomial of the matrix associated with the recurrence relation
has distinct roots.
Remark 1.2.5. The proof of Proposition 1.2.4 is not substantially diﬀerent from
the one that led us to formula (1.10). So we omit its proof, leaving to the interested
readers the task of rediscovering it, by following the indications given above.
Remark 1.2.6. When the eigenvalues are not distinct, it is still possible, with anal-
ogous but less simple techniques, to ﬁnd a formula giving the solution of the recur-
rence relation, but it has a more involved form.
Remark 1.2.7. The number
1 +
√
5
2
(1.12)
we have met when computing Fibonacci numbers is called golden ratio or divine
proportion. The origin of this name lies in the fact that two quantities a and b
were considered by the Greeks to be connected by the most harmonious ratio if the
relation
a
b = a + b
a
(1.13)
held. For instance, the side lengths of the Parthenon’s fa¸cade satisfy this property.
The ratio (1.13) can be reworded by saying that the whole is to the larger part as
the larger part is to the smaller one. By solving the ratio (1.13), we easily get
a
b = 1 +
√
5
2
= 1, 618033989 . . .
In Exercise A1.29 we describe the geometric construction that, given a line segment
of length a, determines a segment of length b such that a/b is the golden ratio.
The number (1.12) is sometimes denoted by the letter Φ, from the name of the
Greek artist Phidias who often used this ratio in his sculptures. The other root

1.2 The concept of recursion
11
1 −
√
5
2
= −1
Φ = 1 −Φ = −0, 618033989 . . .
shares many of the properties of Φ, and is often denoted by ˆΦ. For further infor-
mation about golden ratio in ancient mathematics, the reader may refer to [10],
[61].
Let us lastly remark that formula (1.10) says that fn is the nearest integer
number to the irrational number Φn/
√
5, as |ˆΦn/
√
5| < 1/2 for each n.
In the rest of this section we shall give further examples of problems that
may be solved by using recurrence formulas. These examples are interesting,
but not strictly necessary for what follows.
1.2.2 Further examples of population dynamics
Example 1.2.8. An entomologist observes a population of beetles whose evolution
is subject to the following rules:
•
one half of the beetles die one year after their birth;
•
2/3 of the survivors die two years after their birth;
•
in its third year each beetle spawns 6 beetles and dies.
Study the population’s evolution.
Denote by:
an: the number of beetles between 0 and 1 year old, observed by the entomologist
in the n-th year of his study of the population;
bn: the number of beetles between 1 and 2 year old, observed by the entomologist
in the n-th year;
cn: the number of beetles between 2 and 3 year old, observed by the entomologist
in the n-th year.
With these numbers we form a column vector
Xn =
⎛
⎝
an
bn
cn
⎞
⎠
describing the distribution of the ages in the population of beetles in the n-th year,
which is what we intend to determine. The initial value we are assuming as known
is the vector X0.
We want to describe the evolution of the population by a recurrence formula of
the form
Xn+1 = A · Xn
for each n ≥0,
where A is a 3 × 3 matrix; so we have
Xn = An · X0
for each n ≥1.
How can we determine A? It is suﬃcient to observe that the evolution rules are
described by the following relations:

12
1 A round-up on numbers
an+1 = 6cn,
bn+1 = an
2 ,
cn+1 =

1 −2
3

bn = bn
3 ,
which can be written in matrix form as follows:
Xn+1 =
⎛
⎝
an+1
bn+1
cn+1
⎞
⎠=
⎛
⎝
0
0
6
1/2
0
0
0
1/3
0
⎞
⎠·
⎛
⎝
an
bn
cn
⎞
⎠= A · Xn,
where
A =
⎛
⎝
0
0
6
1/2
0
0
0
1/3
0
⎞
⎠.
The characteristic polynomial PA(t) of A is 1−t3, having the three distinct complex
roots 1, (−1 + i
√
3)/2, and (−1 −i
√
3)/2, where i is the imaginary unit. So, A is
diagonalisable on C; this allows us to compute without diﬃculty the powers of A.
This, in turn, yields a way of computing a closed formula for vector Xn; we leave
this to the interested reader (see Exercise B1.17).
Example 1.2.9. Each year one tenth of Italian people living in an Italian region
other than Liguria arrive in Liguria and start living there, and simultaneously one
ﬁfth of those living in Liguria depart from it. How does Liguria’s population evolve?
Denote by:
yn: the number of persons living outside of Liguria in the n-th year of our study of
this region’s population;
zn: the number of persons living in Liguria in the n-th year.
By constructing the usual vector
Xn =
yn
zn

,
we see that the phenomenon may be recursively described by the formula
Xn = A · Xn−1
for each n ≥1, where A is the matrix
A = 1
10
 9
2
1
8

.
So, for each n ≥1 the following holds
Xn = An · X0.
The eigenvalues of matrix A are 7/10 and 1. So A is diagonalisable and it is easy to
compute its powers. This allows to readily compute a closed formula for the vector
Xn. This is left to the reader (see Exercise B1.19).

1.2 The concept of recursion
13
1.2.3 The tower of Hanoi: a non-homogeneous linear case
Example 1.2.10. The game of the tower of Hanoi was invented by the mathe-
matician E. Lucas in 1883. The tower of Hanoi consists of n circular holed discs,
with a vertical peg A running through all of them; the discs are stacked with their
diameters decreasing from bottom up.
The goal of the game is to transfer all discs, in the same order, that is to say, with
their diameters decreasing from bottom up, on another peg C, by using a support
peg B (see ﬁgure 1.1) and observing the following rules:
(i) the discs must be transferred one at a time from one peg to another one;
(ii) never during the game, on any peg, a disc with a greater diameter may be
located above a disc with a smaller diameter.
A
B
C
Fig. 1.1. The tower of Hanoi with n = 5 discs
We want to determine the number Mn of moves necessary to conclude the game
starting with n discs.
This game apparently has the following origin. The priests of Brahma’s temple
were required to continuously transfer 64 gold discs placed on three gold pegs stand-
ing on diamond bases. According to a legend, were the transfer accomplished, the
world would come to an end!
We shall proceed by induction on n. For n = 1, of course, one move is suﬃcient:
M1 = 1. Assume now n discs are on peg A. By the inductive hypothesis, we may
move the upper n −1 discs from peg A to peg B with Mn−1 moves. In doing so,
the largest disc on peg A is never moved. With a single move we now transfer this
largest disc from peg A to peg C. Then we transfer with Mn−1 moves the n −1
discs on peg B to peg C, putting them on the larger disc. So we accomplished our
task with 2Mn−1 + 1 moves, and it is plainly clear that it is not possible to solve
the game with fewer moves.
So we have the following recurrence relation:
Mn = 2Mn−1 + 1,
M1 = 1,
which we may solve to get a closed formula, as follows:

14
1 A round-up on numbers
Mn = 2Mn−1 + 1 = 2(2Mn−2 + 1) + 1 = 22Mn−2 + 2 + 1 =
= 22(2Mn−3 + 1) + 2 + 1 = 23Mn−3 + 22 + 2 + 1 =
= · · · = 2n−1M1 + 2n−2 + 2n−3 + · · · + 22 + 2 + 1 =
= 2n−1 + 2n−2 + 2n−3 + · · · + 22 + 2 + 1 = 2n −1,
so the total number of moves is
Mn = 2n −1.
If it takes to the priests of Brahma’s temple thirty seconds to move a disc and if
they never make a mistake, it would take them 30 · (264 −1) seconds to complete
their task. The reader may give an estimate of the number of years before the end
of the world: a very long time! (see Exercise B1.33).
1.3 The Euclidean algorithm
In this section we work in the set Z = {. . . , −3, −2, −1, 0, 1, 2, 3, . . .} of integer
numbers. As is well known, on Z the two operations + (addition) and · (mul-
tiplication) are deﬁned; with these operations Z is a commutative ring with
unity, with no zero-divisors, that is to say, a ring in which the zero-product
property holds (saying that ab = 0 implies that either a = 0 or b = 0); so
Z is an integral domain. Moreover, in Z there is a natural order relation ≤,
allowing us to deﬁne the function absolute value
n ∈Z →|n| ∈Z,
where |n| = n if n ≥0, while |n| = −n if n ≤0.
1.3.1 Division
We begin by recalling a very simple fact, already learnt in primary school:
we can perform division between integer numbers. This operation is made
possible by an algorithm presented in the following proposition:
Proposition 1.3.1. Let a and b be integer numbers, with b ̸= 0. Then two
integers q and r exist, and are uniquely determined, such that
a = bq + r,
with
0 ≤r < |b|.
Proof. Suppose initially that b is a positive integer. Consider the set of all
integer multiples of b:
. . . , −kb, . . . , −2b, −b, 0, b, 2b, . . ., kb, . . . ,
where k is a positive integer. There exists a unique q ∈Z such that (see
Exercise A1.8)

1.3 The Euclidean algorithm
15
qb ≤a < (q + 1)b.
Deﬁne
r = a −qb;
this determines the two numbers q and r, as required. Notice that 0 ≤r < b
by costruction and q is unique because it is the greatest integer whose product
by b is less than or equal than a. Consequently, r is unique too.
If b is negative, by virtue of what we have just proved, we have, in a unique
way, a = q′(−b)+r, with 0 ≤r < −b = |b|. So it is suﬃcient to deﬁne q = −q′
to ﬁnd the numbers q and r as required; their uniqueness follows from what
has been proved in the case b > 0.
⊓⊔
Thus, the algorithm described in Proposition (1.3.1) allows us to determine
the integers q and r starting from a and b, and is called division of a by b.
The term a will be called the dividend, b the divisor, q the quotient and r
the remainder of the division. For instance, dividing 34 by 8 or by −8, we get
respectively
34 = 8 · 4 + 2,
34 = (−8) · (−4) + 2,
so the quotient and the remainder are 4 and 2 in the ﬁrst case, −4 and 2 in
the second one. On the other hand, dividing −34 by 8 or by −8, we get
−34 = 8 · (−5) + 6,
−34 = (−8) · 5 + 6,
so the quotient and the remainder are −5 and 6 in the ﬁrst case, 5 and 6 in
the second one.
Deﬁnition 1.3.2. A number a is said to be divisible by a number b ̸= 0 (or
we say that b is a divisor of a, or that b divides a, and we denote this by
b | a), if the remainder of the division of a by b is zero. In other words, a is
divisible by b if there exists an integer m such that a = mb, that is if a is an
integer multiple of b.
Each integer a has, among its divisors, 1, −1, a and −a. These are said to
be the trivial divisors of a. The numbers a and −a, which only diﬀer by the
sign, are said to be associated with a. Of course 1 and −1 have no divisors
diﬀerent from 1 and −1, so they are the only invertible numbers in Z (a
number a is said to be invertible if there exists a number b such that ab = 1).
Notice further that if both a | b and b | c hold, then a | c. We write down the
following simple fact:
Lemma 1.3.3. Let a and b be non zero integers. We have a | b and b | a if
and only if a and b are associated, that is either a = b or a = −b holds.
Proof. By the hypothesis, there exist two integer numbers n, m such that
b = na and a = mb. Then b = nmb and so nm = 1. Therefore, either
n = m = 1 or n = m = −1.
⊓⊔

16
1 A round-up on numbers
If a > 1 has only trivial divisors, it is said to be an irreducible or prime
number. As we shall see, prime numbers are important, as they are the build-
ing blocks from which, by multiplication, all integers may be built. For the
time being, however, we pass over this fundamental topic, delaying it until
Chapter 4, to deal now with a simple and natural question: given two integers
a and b diﬀerent from zero, which are their common divisors? We shall show
that, by repeatedly performing divisions, the problem reduces to computing
the divisors of a single integer d.
1.3.2 The greatest common divisor
We begin with a trivial remark: the divisors of the integer a are the same as
those of the integer −a. Thus, in the problem we are studying, it is suﬃcient
to consider the case in which a and b are both positive, and to look for their
positive common divisors. So we shall study just this case.
We perform the following divisions; we suppose that in the ﬁrst n divisions
the remainder is positive, while in the last one it is zero:
1.
a = b q1 + r1,
0 < r1 < b,
2.
b = r1 q2 + r2,
0 < r2 < r1,
3.
r1 = r2 q3 + r3,
0 < r3 < r2,
...
i + 2.
ri = ri+1 qi+2 + ri+2,
0 < ri+2 < ri+1,
...
n −1.
rn−3 = rn−2 qn−1 + rn−1,
0 < rn−1 < rn−2,
n.
rn−2 = rn−1 qn + rn ,
0 < rn < rn−1,
n + 1.
rn−1 = rn qn+1 + 0.
Notice that, when successively dividing in this way, in any case, within at
most b divisions, we ﬁnd a remainder equal to zero. Indeed, we have that
b > r1 > r2 > r3 > · · · is a strictly decreasing sequence of non-negative
integers. We also remark that the common divisors of a and b are the same
as the common divisors of b and r1: in fact, if an integer divides both a and
b, it divides each multiple of b, and the diﬀerence between a and q1b, that is,
r1. On the other hand, by reasoning in the same way, if an integer divides b
and r1, it also divides a = bq1 + r1. Using the second of the above divisions,
we may see that the common divisors of b and r1 are the common divisors of
r1 and r2. Going on like this, we ﬁnd that the common divisors of a and b are
the common divisors of rn−1 and rn. Clearly, as rn−1 is a multiple of rn, the
common divisors of rn−1 and rn coincide with the divisors of rn.
Deﬁne d = rn, the last remainder in the sequence of those divisions. We
have seen that d is a common divisor of a and b. Furthermore, it is the greatest

1.3 The Euclidean algorithm
17
among the common divisors of a and b: indeed, if d′ divides both a and b then,
as we have seen, d′ divides d. Hence comes the name, for d, of greatest common
divisor and the symbol GCD(a, b) to denote it. If GCD(a, b) = 1, the numbers
a and b have no non trivial common divisors: in this case we say that they are
coprime, or relatively prime.
The algorithm we have just described is called Euclidean algorithm and
yields a method to eﬃciently compute the greatest common divisor of two
integers a and b.
Remark 1.3.4. Given two positive integers a and b, if we know all their divisors,
clearly we can immediately ﬁnd their greatest common divisor. In particular, let us
announce in advance something we shall see in Chapter 4 but everyone knows since
primary school: this holds if we know the prime factorisations of a and b. In fact,
as is well known, GCD(a, b) is the product of the prime factors common to a and b,
taken each raised to the smallest exponent with which it appears in the factorisations.
Nevertheless, as we shall see in Chapter 4, ﬁnding the factorisation of an integer n
is a computationally hard problem, that is, in general it requires a computation time
that increases enormously as n increases, so much so that for a large enough n this
time becomes longer than the estimated life of the universe! So the method we learnt
in school, requiring the prime factorisation of a and b, is theoretically faultless, but
is possibly less than useful in practice. The strong point of the Euclidean algorithm
is that it enables us to ﬁnd the greatest common divisor of two numbers a and b
without having to know their prime factorisation. As we shall see in Chapter 2 this
algorithm is more eﬃcient, in a sense that will be made precise.
1.3.3 B´ezout’s identity
The Euclidean algorithm also provides a way of proving that a relation of the
form
GCD(a, b) = αa + βb
(1.14)
holds, with α and β suitable integers. Equation (1.14) is called B´ezout’s iden-
tity and turns out to be very useful. For instance, it is the starting point for
the resolution of linear Diophantine equations, which we shall shortly deal
with, and linear congruences, which will be covered in the next chapter. To
prove this identity, it is suﬃcient to show that all the remainders of the suc-
cessive divisions can be written as combinations of a and b. In fact, notice
that
r1 = a −b q1,
r2 = b −r1 q2,
...
rn = rn−2 −rn−1 qn;
hence
r2 = b −r1q2 = b −(a −bq1)q2 = (−q2)a + (1 + q1q2)b,

18
1 A round-up on numbers
that is, r1 and r2 may be written as combinations of a and b. So r3, being
a combination with integer coeﬃcients of r1 and r2, is a combination with
integer coeﬃcients of a and b too. In conclusion, d = rn is a combination with
integer coeﬃcients of rn−1 and rn−2, and so of a and b.
Here follow some important consequences of B´ezout’s identity:
Proposition 1.3.5. Let a and b be two positive integers. They are coprime if
and only if there exist two integers α, β such that
αa + βb = 1.
(1.15)
Proof. If a and b are coprime, we have GCD(a, b) = 1 and the claim follows
from B´ezout’s identity.
On the other hand, suppose equation (1.15) holds. Let d be a common
divisor of a and b. Then clearly d divides αa + βb too, and so divides 1. Thus
either d = 1 or d = −1, and consequently a and b are relatively prime.
⊓⊔
Corollary 1.3.6. Let a and b be two positive integers and let d = GCD(a, b).
If a = dn e b = dm, we have GCD(n, m) = 1.
Proof. Equation (1.14) may now be written as
d = dnα + dmβ.
By dividing by d both sides we get
αn + βm = 1
and by applying Proposition 1.3.5 we conclude that n and m are relatively
prime.
⊓⊔
Corollary 1.3.7. Let a, b1, and b2 be integers such that a and b1 are coprime,
and so are a and b2. Then a is coprime with b1b2.
Proof. The following relations hold:
1 = αa + β1b1,
1 = α′a + β2b2.
By multiplying them, we get
1 = (αα′a + αβ2b2 + α′β1b1)a + (β1β2)(b1b2),
proving the claim.
⊓⊔
Corollary 1.3.8. Let a, b, and n be integers such that a | n, b | n and
GCD(a, b) = 1. Then ab | n.
Proof. We have n = n1a = n2b. Moreover, a relation of the form (1.15)
holds. Multiplying it by n we get
n = αna + βnb = αn2(ab) + βn1(ab),
proving the claim.
⊓⊔

1.3 The Euclidean algorithm
19
Corollary 1.3.9. Let a and b be two coprime positive integers, and let n be
any integer. If a | bn then a | n.
Proof. By hypothesis there exists an integer m such that
bn = am.
(1.16)
By B´ezout’s identity, there exist integers α and β satisfying equation (1.15).
Multiplying both sides of this equation by n and keeping in mind equation
(1.16), we get
n = αan + βbn = αan + βam;
hence, a | n.
⊓⊔
Notice that the expression for GCD(a, b) yielded by equation (1.14) is not
at all unique. For instance: 1 = 3 · 7 + (−4) · 5 = (−2) · 7 + 3 · 5.
Example 1.3.10. We are now going to analyse an example to understand
how to use Euclidean algorithm to ﬁnd a B´ezout relation. In doing so, we
shall use a notation quite useful both for programming a computer to execute
the algorithm and for applying it by hand.
We intend to ﬁnd a B´ezout’s identity for GCD(1245, 56). Following the
Euclidean algorithm, we proceed as follows:
1245 = 56 · 22 + 13,
56 = 13 · 4 + 4,
13 = 4 · 3 + 1 ,
4 = 1 · 4 + 0.
(1.17)
So we ﬁnd GCD(1245, 56) = 1. Now we want to express 1 in the form αa+βb,
with a = 1245, b = 56. In order to do this, it is convenient to use the following
notation:
αa + βb ≡(α, β).
In other words, we forget a and b and just write the coeﬃcients of the linear
combination as the elements of a pair. So we associate to a the pair (1, 0),
and to b the pair (0, 1). Addition is deﬁned on pairs by
(α, β) + (α′, β′)
def
= (α + α′, β + β′);
moreover,
γ(α, β)
def
= (γ · α, γ · β)
for all α, β, γ, α′, β′ ∈Z.
So we may rewrite the steps of Euclidean algorithm as follows:
r1 = 13 = a + b · (−22),
r2 = 4 = b + r1 · (−4),
r3 = 1 = r1 + r2 · (−3),

20
1 A round-up on numbers
which, in the new notation, become
r1 = 13 = a + b · (−22) ≡(1, 0) + (0, 1)(−22) = (1, −22),
r2 = 4 = b + r1 · (−4) ≡(0, 1) + (1, −22)(−4) = (−4, 89),
r3 = 1 = r1 + r2 · (−3) ≡(1, −22) + (−4, 89)(−3) = (13, −289),
so a B´ezout’s identity for GCD(1245, 56) is
1 = 13 · 1245 + (−289) · 56.
Notice that, as the algorithm puts in evidence, in determining the pair
associated with a remainder ri we only use the two pairs associated with the
two preceding remainders ri−1 and ri−2. So we may directly work with the
pairs, without having to pass through the intermediate expressions.
1.3.4 Linear Diophantine equations
A ﬁrst application of the material of this section concerns the study of so-
called linear Diophantine equations. These are equations of the form
ax + by = c,
(1.18)
where a, b, c are in Z. The case when a or b is equal to zero is trivial, so we
omit it. We want to ascertain whether the equation admits integer solutions,
that is solutions (x, y) with x, y ∈Z.
In a geometrical setting this equation represents, in a Cartesian plane, a
line not parallel to either axis: we are interested in determining whether it
passes through integer points, that is, points with integer numbers as coordi-
nates.
The following proposition gives a necessary and suﬃcient condition for the
equation ax + by = c to admit integer solutions.
Proposition 1.3.11. Equation ax+by = c, with a, b, c ∈Z and a, b diﬀerent
from zero, admits an integer solution (x, y) if and only if GCD(a, b) divides
c.
Proof. Let (¯x, ¯y) be an integer solution of equation (1.18) and set d =
GCD(a, b). Then d, being a divisor of both a and b, divides the left-hand
side of the equation and so divides c.
On the other hand, suppose that d divides c, that is, c may be written as
c = d · h. Write d in the form d = αa + βb. Multiplying both sides by h we get
c = αha + βhb
and, setting ¯x = αh and ¯y = βh, we ﬁnd that (¯x, ¯y) is a solution of equation
(1.18).
⊓⊔

1.3 The Euclidean algorithm
21
For instance, equation
3x + 4y = −1
(1.19)
has solutions in Z, because GCD(3, 4) = 1 divides −1. We may write 1 =
3(−1) + 4(1), and so we have −1 = 3(1) + 4(−1). Thus a solution is (1, −1).
Notice that this solution is not unique: other solutions of equation (1.19) are
(−3, 2), (−7, 5) e (5, −4) (see ﬁgure 1.2).
x
y
•1
•1
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
•
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
•
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
•
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
•
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
Fig. 1.2. The line 3x + 4y = −1 in a Cartesian plane
1.3.5 Euclidean rings
It is useful to put what has been said about the division algorithm in Z in a wider,
abstract context. For this purpose, let us recall some general notions about divisi-
bility in a ring and in particular in Euclidean rings.
Consider a commutative ring with unity and no zero-divisors A. We may extend
to A most of the deﬁnitions about divisibility we have given regarding the ring Z of
integer numbers.
First of all, an element a ∈A is said to be invertible if there exists an element
b ∈A such that ab = 1. Clearly, 1 and −1 are invertible, all invertible elements are
diﬀerent from zero, and they form a group with respect to multiplication: this group
is denoted by A∗or U(A).
Let a and b be elements of A such that b ̸= 0. We say that b divides a, or that
it is a divisor of a, or that a is a multiple of b, and we write b | a, if there exists an
element x ∈A such that a = bx. Notice that if a | b and b | c then a | c. Clearly, each
invertible element divides each element of A. Two elements a, b diﬀerent from zero
are said to be associated if a = bx with x an invertible element. A result analogous
to Lemma 1.3.3 holds, that is a | b and b | a if and only if a and b are associated.

22
1 A round-up on numbers
Consider an integral domain A, that is a commutative ring with unity A with
no zero-divisors. An integral domain A is said to be Euclidean if there exists a map
v : A \ {0} →N
that satisﬁes the following properties:
(1) for each pair (a, b) of elements diﬀerent from zero we have v(ab) ≥v(a);
(2) for each a ∈A and for each b ∈A \ {0}, there exist q, r ∈A (respectively said
quotient and remainder of the division of a by b) such that a = bq+r and either
r = 0 or v(r) < v(b).
Clearly, Z is a Euclidean ring, by taking v(a) = |a|, for each a ∈Z. So, A is a
Euclidean ring if there exists in A a division algorithm analogous to the one in Z.
Another trivial example of a Euclidean ring is given by any ﬁeld A. It suﬃces
to take as v the constant map equal to 1 and, as quotient q and remainder r of the
division of a by b, respectively q = a/b and r = 0.
Given an integral domain A and given two elements a, b diﬀerent from zero, it
is possible to consider the set D(a, b) of common divisors of a and b. Notice that
for each c ∈D(a, b) and for each invertible x, we also have cx ∈D(a, b). We deﬁne
d ∈D(a, b) to be a greatest common divisor of a and b, and denote it by GCD(a, b),
if for each c ∈D(a, b) we have c | d. Notice that if each of d and d′ is a greatest
common divisor of a e b, they are associated, and conversely, if d = GCD(a, b) and if
d′ is associated to d, then d′ is a GCD(a, b) too (see Exercise A1.44). If the greatest
common divisor of a e b is invertible, and so we may assume that GCD(a, b) = 1,
then a e b are said to be relatively prime.
In an integral domain A two elements may well not admit a greatest common
divisor. However, if A is Euclidean, greatest common divisors always exist, as it
is always possible to apply the same procedure as in Z. So we have the following
theorem.
Theorem 1.3.12. Let A be a Euclidean ring. If a, b ∈A are elements diﬀerent from
zero, there exists a GCD(a, b), which can be determined by the Euclidean algorithm.
Moreover, B´ezout’s identity holds, that is, there exist α, β ∈A such that equation
(1.14) holds.
It is interesting to give a diﬀerent interpretation of the greatest common divisor
in a Euclidean ring. Recall that in a commutative ring with unity A an ideal I is a
subset such that
(1) for each x, y ∈I we have x + y ∈I;
(2) for each x ∈I and for each y ∈A, we have xy ∈I.
In general, A and {0} are ideals that are said to be trivial. The ideal {0} is
simply denoted by 0 and is called zero ideal.
Given x1, . . . , xn ∈A, consider the set I of all the elements of A of the form
x1y1 + · · · + xnyn, with y1, . . . , yn elements of A. The set I is an ideal said to be
(ﬁnitely) generated by x1, . . . , xn; it is denoted by the symbol (x1, . . . , xn). An ideal
(x) generated by a single element x ∈A is said to be principal and exactly consists
of the multiples of x. For instance, A = (1) and 0 = (0) are principal ideals. Notice
that if A is an integral domain, then (x) = (y) if and only if x and y are associated
(see Exercise A1.46). A commutative ring is said to be a principal ideal ring if every
ideal of the ring is principal.
The following result is noteworthy.

1.3 The Euclidean algorithm
23
Proposition 1.3.13. If A is a principal ideal integral domain then, for each pair
of elements a, b of A diﬀerent from zero, there exists the GCD(a, b), and every
generator of the ideal (a, b) is a GCD(a, b).
Proof. Let d be a generator of the ideal (a, b). As a, b ∈(a, b), clearly d divides
both a and b. We know that B´ezout’s identity d = αa + βb holds; so, if c ∈D(a, b)
is a common divisor of a and b, clearly c divides d.
⊓⊔
For Euclidean rings the following remarkable theorem holds.
Theorem 1.3.14. Every Euclidean ring is a principal ideal ring.
Proof. Let A be a Euclidean ring, and let I be an ideal of A. If I = 0 there is
nothing to prove. If I ̸= 0 let b ∈I be a non-zero element such that for each non-
zero a ∈I inequality v(b) ≤v(a) holds (here we use the well-ordering principle, see
Exercise A1.2). Let a ∈I be any element. There exist q, r such that a = bq + r with
v(r) < v(b). Notice that r ∈I and, by the deﬁnition of b, we have r = 0. Thus a is
a multiple of b, and the theorem is proved.
⊓⊔
As a consequence we get the following.
Corollary 1.3.15. Let A be a Euclidean ring and let a, b be non-zero elements of
A. Then d = GCD(a, b) if and only if d is a generator of the ideal (a, b).
In particular, Z is a principal ideal ring. Another interesting example of a Eu-
clidean ring will be shown in Exercise A1.49. Still another important example is
described in the next section.
1.3.6 Polynomials
This is a good moment to recall some basics about polynomials, emphasising their
similarities with integers, and giving an interpretation of some of their fundamental
properties in terms of divisibility.
Deﬁnition 1.3.16. A polynomial p(x) with coeﬃcients in a commutative ring with
unity A is a formal expression of the form
p(x) = a0 + a1x + a2x2 + · · · + anxn =
n

i=0
aixi,
ai ∈A,
(1.20)
where x is an indeterminate or variable. The elements a0, a1, . . . , an ∈K are said
to be the coeﬃcients of the polynomial. If an ̸= 0, the integer n is the degree of the
polynomial and is denoted by deg(p(x)) or by ∂p(x). The polynomials of degree 0
are called constants and may be identiﬁed with the elements of A. The polynomials
of degree one are called linear, those of degree two quadratic, those of degree three
cubic, and so on. The coeﬃcient an is called the leading coeﬃcient of p(x). If it is
equal to 1, the polynomial is said to be monic.

24
1 A round-up on numbers
Notice that the degree of a non-zero constant is zero. It is usual not to assign
any degree to the zero polynomial, that is, the polynomial with all coeﬃcients equal
to zero.
In a more formal way, we may identify polynomial (1.20) with the sequence of
elements of A
{ a0, a1, . . . , an, 0, 0, . . . },
all terms of which are zero from a certain point onwards. We usually set ai = 0 for
each i > n; we may also write p(x) = ∞
i=0 aixi, keeping in mind that in any case
it is a ﬁnite sum.
So, in general, if we use the “equal” sign to denote the above identiﬁcation, we
have
a = {a, 0, 0, 0, . . .},
x = {0, 1, 0, 0, . . .},
x2 = {0, 0, 1, 0, . . .},
...
xi = {0, 0, . . . , 0,
1

(i+1)-th position
, 0, 0, . . .).
The polynomial that corresponds to the sequence {0, 0, . . .}, that is to the con-
stant 0, is the zero polynomial, which is denoted by the symbol 0.
Let us look at an example:
x3 + 2x −1
is a degree 3 polynomial with integer, and so rational (or real, or complex) coeﬃ-
cients. Using the notation just introduced, the polynomial becomes
{ −1, 2, 0, 1, 0, 0, . . . }.
It follows from the deﬁnition that two polynomials p(x) = n
i=0 aixi and
q(x) = m
j=0 bjxj, with ai, bj ∈K, are equal if and only if ai=bi, for each i ∈N. In
particular, if m > n, then bn+1 = bn+2 = · · · = bm = 0.
The set of all polynomials with coeﬃcients in A is denoted by A[x]. In A[x]
two operation are deﬁned: an addition and a multiplication, as follows. Let p(x) =
n
i=0 aixi and q(x) = m
j=0 bjxj in A[x] be two polynomials, with n ≤m. We put
p(x) + q(x)
def
=
m

h=0
(ah + bh)xh,
p(x)q(x)
def
=
n+m

h=0
 
i+j=h
aibj

xh.
The zero polynomials is the identity element for addition, and the opposite (or
additive inverse) of the polynomial p(x) = n
i=0 aixi is the polynomial having as
its coeﬃcients the opposite of the coeﬃcients ai, for each i.
Let us explicitly remark the following relations between the degrees of two poly-
nomials with coeﬃcients in a ﬁeld, or in an integral domain, and the degrees of their
sum and their product:
∂(p(x) + q(x)) ≤max(∂p(x), ∂q(x)),
∂(p(x)q(x)) = ∂p(x) + ∂q(x).
(1.21)

1.3 The Euclidean algorithm
25
With respect to the operations of addition and multiplication (1.21), polynomials
form a ring. If A is an integral domain, so is A[x] (see Exercise A1.51). If this
is the case, the invertible elements in A[x] are the invertible elements of A. By
iterating the construction of A[x] it is possible to construct more generally the
ring A[x1, . . . , xn] of polynomials in variables x1, . . . , xn on the ring A. The typical
element of A[x1, . . . , xn] is a ﬁnite sum of monomials of the form axm1
1
· · · xmn
n
, with
a ∈A and m1, . . . , mn non-negative integers. If a = 0, we get the zero monomial,
otherwise the integer m1 +· · ·+mn is called degree of the monomial, and the degree
of a polynomial is the maximum of the degrees of its non-zero monomials.
In general we shall consider polynomials over ﬁelds.
The following remarkable result holds.
Theorem 1.3.17. The ring K[x] of the polynomials over a ﬁeld K, endowed with
the map
∂: K[x] \ {0} →N,
is a Euclidean ring. In particular, let f(x), g(x) ∈K[x] be two polynomials, with
g(x) ̸= 0. Then there exist, and are uniquely determined, two polynomials q(x) e
r(x) in K[x] such that
f(x) = g(x) · q(x) + r(x),
with ∂r(x) < ∂g(x) or r(x) = 0.
Proof. First of all, it is easy to verify that the map ∂satisﬁes property (1) of the
deﬁnition of Euclidean rings.
As to the uniqueness of division, notice that if f(x) = g(x) · q1(x) + r1(x) =
g(x) · q2(x) + r2(x) such that ∂ri(x) < ∂g(x) or ri(x) = 0 with i = 1, 2, then we
would get
(q1(x) −q2(x))g(x) = r2(x) −r1(x).
If it is the case that q1(x) −q2(x) ̸= 0, the left-hand side would have a greater
degree than the second one, which is not possible. So we must have q1(x) = q2(x),
which also implies r2(x) = r1(x).
As to the the existence of the algorithm for the division, if f(x) = 0 there is
nothing to prove. So let f(x) ̸= 0 and let n, m be respectively the degrees of f(x)
and g(x). If m > n it suﬃces to take q(x) = 0 and r(x) = f(x). So suppose n ≥m.
As the theorem is trivially true for n = 0, we proceed by induction on n. If
f(x) = a0 + a1x + · · · + anxn,
g(x) = b0 + b1x + · · · + bmxm,
we put
h(x) = f(x) −an
bm xn−mg(x).
The degree of h(x) is smaller than n, so we may apply to h(x) the induction hypoth-
esis. So there exist q1(x), r1(x), with r1(x) either the zero polynomial or of degree
smaller than m, such that
f(x) −an
bm xn−mg(x) = h(x) = q1(x)g(x) + r1(x).
Then it is enough to take r(x) = r1(x) and q(x) = q1(x) + (an/bm)xn−m.
⊓⊔

26
1 A round-up on numbers
As a consequence of this result and of those given in the previous section, we
conclude that it is possible to consider the greatest common divisor of non-zero
polynomials over a ﬁeld, and to compute it with the Euclidean algorithm. Notice
that sometimes we identify the greatest common divisor of two polynomials with
the unique monic polynomial having the same property (see Exercise A1.52).
Example 1.3.18. We shall compute the greatest common divisor of two polynomi-
als
f(x) = x3 + 1,
g(x) = x2 + 1
on Q. We have
x3 + 1 = x(x2 + 1) −x + 1,
x2 + 1 = (−x −1)(−x + 1) + 2,
−x + 1 = 1
2(−x −1) · 2,
and so GCD(f(x), g(x)) = 2. As 2 is invertible, we have that f(x) and g(x) are
relatively prime. From the above divisions we get
1 = 1
2(x2 + 1) + 1
2(x + 1)(1 −x) =
= 1
2(x2 + 1) + 1
2(x + 1)[(x3 + 1) −x(x2 + 1)] =
= 1
2(x2 + 1)(−x2 −x + 1) + 1
2(x3 + 1)(x + 1)
that is, a B´ezout’s identity.
If we consider the polynomials
p(x) = x3 −1,
q(x) = x2 −1
on Q, we have
x3 −1 = x(x2 −1) + x −1,
x2 −1 = (x + 1)(x −1),
and so GCD(f(x), g(x)) = x −1.
We determine next the greatest common divisor of the real polynomials f(x) =
x3 + 3x2 −x −3 and g(x) = x2 + 3x + 2, and ﬁnd a B´ezout’s identity.
Applying the Euclidean algorithm we get
x3 + 3x2 −x −3 = (x2 + 3x + 2)x −3(x + 1),
x2 + 3x + 2 = −3(x + 1)

−1
3x −2
3

+ 0.
So,
GCD(x3 + 3x2 −x −3, x2 + 3x + 2) = x + 1.
Clearly, −3(x+1) is a greatest common divisor too, but it is not monic. The greatest
common divisor can be written down by generalising Equation (1.14) to polynomials
as follows:
x + 1 = −1
3(x3 + 3x2 −x −3) + 1
3x(x2 + 3x + 2)
with h(x) = −1/3 and k(x) = (1/3)x.

1.3 The Euclidean algorithm
27
Remember that, given a polynomial f(x) ∈K[x], an element α ∈K such that
f(α) = 0 is said to be a root, or a zero, of f(x). A renowned theorem due to Ruﬃni,
known as factor theorem, translates the question of the existence of roots into the
context of divisibility.
Theorem 1.3.19. If f(x) ∈K[x] and α ∈K is an element such that f(α) = 0, then
(x −α) | f(x).
Proof. By dividing f(x) by x −α we have
f(x) = q(x)(x −α) + r(x)
(1.22)
where r(x) has a smaller degree than x −α; so, it is a constant r. By putting x = α
in (1.22), we ﬁnd r = 0.
⊓⊔
Corollary 1.3.20. If f(x) ∈K[x] is a non-zero polynomial of degree n, it has at
most n roots in K.
Proof. If α1, . . . , αh are distinct roots of f(x), Ruﬃni’s theorem implies that f(x)
is divisible by the polynomial (x −α1) · · · (x −αh) of degree h and so n ≥h.
⊓⊔
Given a polynomial f(x) ∈K[x], we may consider the function
ϕf : x ∈K →f(x) ∈K,
called the polynomial function determined by f(x).
Proposition 1.3.21. If K is inﬁnite, and if f(x), g(x) are polynomials on K, then
f(x) = g(x) if and only if ϕf = ϕg.
Proof. We have ϕf = ϕg if and only if each α ∈K is a root of the polynomial
f(x) −g(x). By Corollary 1.3.20 this happens if and only if f(x) −g(x) = 0 and so
if and only if f(x) = g(x).
⊓⊔
Deﬁnition 1.3.22. A root α ∈K of f(x) ∈K[x] is said to be simple if (x −α) |
f(x) but (x −α)2 ∤f(x). It is said to be of multiplicity m if (x −α)m | f(x), but
(x −α)m+1 ∤f(x). A root of multiplicity m > 1 is said to be a multiple root.
For instance, −1 is a root of multiplicity 2 or, as it is also called, a double root
of the polynomial (x + 1)2.
Given a polynomial
f(x) = a0 + a1x + a2x2 + a3x3 + · · · + anxn
over a ﬁeld K, the derivative polynomial f ′(x), also denoted by D(f(x)), is deﬁned
as
f ′(x) = a1 + 2a2x + 3a3x2 + · · · + nanxn−1.
For instance, if
f(x) = 4x4 + 6x3 −5x2 + x −1
is a polynomial with real coeﬃcients, then
f ′(x) = 16x3 + 18x2 −10x + 1.
The derivative is a function
D : K[x] →K[x]
(1.23)
satisfying the following properties (see Exercises A1.58 and A1.59):

28
1 A round-up on numbers
•
linearity: D(f(x) + g(x)) = D(f(x)) + D(g(x)), for each pair of polynomials
f(x), g(x) ∈K[x];
•
Leibniz’s law: D(f(x) · g(x)) = D(f(x)) · g(x) + D(g(x)) · f(x), for each pair of
polynomials f(x), g(x) ∈K[x].
The derivative composed with itself h times, with h ≥2, applied to a polyno-
mial f(x), is denoted by the symbol f(h)(x), or D(h)(f(x)), and is called the h-th
derivative of f(x). It is usual to understand D(1) as meaning the same as D, while
D(0) is the identity function in K[x].
Notice that D(i)(xn) = 0 if i > n, and so D(i)(f(x)) = 0 if i is greater than the
degree of f(x) (see Exercise A1.61). Moreover, it follows from Leibniz’s law that, if
c ∈K and if i ≤n, then
D(i)((x −c)n) = n(n −1) · · · (n −i + 1)(x −c)n−i;
(1.24)
in particular, we have
D(n)((x −c)n) = n!
(1.25)
(see Exercise A1.62).
The next proposition relates the concept of derivative of a polynomial with the
multiplicity of its roots. Recall that the symbol m! denotes the factorial of the
integer number m (see Exercise A1.12).
Proposition 1.3.23. If f(x) is a polynomial on the ﬁeld K and if α is a root of f
of multiplicity m, we have (D(i)f)(α) = 0 for each i ≤m −1. Moreover, if m! ̸= 0
in K, we have (D(m)f)(α) ̸= 0.
Proof. We have f(x) = (x −α)mg(x) with g(α) ̸= 0. By repeatedly applying
Leibniz’s law, we ﬁnd
D(i)(f(x)) =
i

j=0
D(j)((x −α)m)D(i−j)(g(x)).
Keeping in mind Equation (1.24), we get (D(i)f)(α) = 0 for each i ≤m −1, while
(D(m)f)(α) = m!g(α). So we get what was claimed.
⊓⊔
This result gives a useful criterion to ascertain whether a polynomial admits
multiple roots or not.
Example 1.3.24. Let us solve the following problem: ﬁnd a polynomial with real
coeﬃcients
f(x) = x3 −3λ2x + 2
admitting a double root. We may proceed as follows. For f(x) to admit a double
root α, it also has to be a root of its derivative
f ′(x) = 3x2 −3λ2,
so α = ±λ. Thus
(±λ)3 −3λ2(±λ) + 2 = 0,
must hold; this implies λ3 = ±1 and so λ = ±1. The polynomial we are looking for
is
f(x) = x3 −3x + 2
and its unique double root is α = ±λ = ±(±1) = 1.

1.3 The Euclidean algorithm
29
In conclusion we prove the following theorem, whose usefulness will become clear
later on.
Theorem 1.3.25 (Taylor’s formula). Let
f(x) = a0 + a1x + · · · + anxn
be a polynomial over a ﬁeld K = Q, R or C. If y is another indeterminate on K,
we may consider the polynomial in two variables f(x + y) on K. For it the following
formula holds, called Taylor’s formula:
f(x + y) = f(x) + f ′(x)y + f (2)(x)
2
y2 + · · · + f (n)(x)
n!
yn =
n

i=0
f (i)(x)
i!
yi.
(1.26)
Moreover, for each i = 1, . . . , n, we have
ai = f (i)(0)
i!
.
(1.27)
Proof. The last claim follows from the ﬁrst one by exchanging x and y and putting
y = 0. For the ﬁrst claim, notice that Taylor’s formula is linear, that is, if it is
true for two polynomials f(x) and g(x) it is also true for every linear combination
αf(x) + βg(x) with constant coeﬃcients α, β. Moreover, the formula is true for
constants. So, to prove it for an arbitrary polynomial it suﬃces to prove it for
monomials of the form xn. In this case Taylor’s formula is just the binomial theorem
(see Exercise A1.18).
⊓⊔
Taylor’s formula may also be written in a slightly diﬀerent form. Choose a con-
stant k ∈K and substitute k for x and x −k for y in the formula. Then we get
f(x) = f(k) + f ′(k)(x −k) + f (2)(k)
2
(x −k)2 + · · · + f (n)(k)
n!
(x −k)n =
=
n

i=0
f (i)(k)
i!
(x −k)i.
Written like this, the formula is called Maclaurin’s formula around the point k.
For instance, the real polynomial
f(x) = x3 + 2x −1
may also be written, by applying Maclaurin’s formula around 1, as
f(x) = 2 + 5(x −1) + 6(x −1)2 + 6(x −1)3.
Remark 1.3.26. Let A be a ring with unity. We may consider the map
f : Z →A
deﬁned as follows: if n is a positive number deﬁne f(n) = 1 + · · · + 1



n
, if n is a
negative number, deﬁne f(n) = −f(−n), and put f(0) = 0. The value f(n) is
usually denoted by n. Clearly, we have

30
1 A round-up on numbers
f(n + m) = f(n) + f(m),
f(nm) = f(n)f(m).
So f(Z) is a subring of A, called the prime subring of A. When f is injective, A is
said to have characteristic zero and the prime subring of A can be identiﬁed with
Z.
If the characteristic of A is diﬀerent from zero, then there exists a least integer
p > 1 such that f(p) = 0. It is said to be the characteristic of A. If A is an integral
domain, then p is a prime number, that is, it is not a product of two positive integers
smaller than p. In fact, if p = nm with n, m positive integers smaller than p, we
would get 0 = f(p) = f(nm) = f(n)f(m) and so either f(n) = 0 or f(m) = 0,
which is impossible.
Taylor’s formula does not only hold for polynomials on Q, R and C, but more
in general for polynomials over a ﬁeld of characteristic zero. Also, the hypothesis
m! ̸= 0 in Proposition 1.3.23 is certainly satisﬁed if the characteristic of K is zero.
1.4 Counting in diﬀerent bases
To use numbers it is necessary to represent them in a simple and eﬃcient
manner. There are several ways of doing so. In this section we shall expound
the most well-known way, the one used since primary school by all of us, and
by computers too, that is the representation of numbers in a given base. In
the next section we shall however see another interesting and useful way of
representing numbers.
1.4.1 Positional notation of numbers
When we write the number 3013 in base 10, we mean the following expression:
3013 = 3 · 103 + 0 · 102 + 1 · 101 + 3 · 100.
In this example it is clear that equal digits, for instance 3, represent diﬀerent
numbers, depending on the position it occupies within the number. Indeed,
it represents number 3 if 3 is the coeﬃcient of 100, and number 3000 if it
multiplies 103. So it is a positional notation in base 10, in which the ten digits
from 0 to 9 are used.
Examining further this example, notice that by dividing 3013 by 10 we get
3013 = 10 · 301 + 3,
that is, 3, the rightmost digit, gives the remainder of the division by 10 of the
original number. Going on, we divide the quotient we found by 10 again. We
get
301 = 10 · 30 + 1.

1.4 Counting in diﬀerent bases
31
So the second digit from the right, that is 1, once more gives the remainder
of a division, and is so uniquely determined. In conclusion, the digits appear-
ing in the decimal representation of the number are uniquely determined by
successive divisions.
The choice of 10 as a notational base is purely conventional: in fact, along
the centuries diﬀerent cultures used diﬀerent bases in their numeral systems:
Babylonians used the base 60, Mayans the base 20 and so on. Computers use
the base 2, that is they use just two digits, 0 and 1, to represent a number. In
fact, in the binary system, that is to say in base 2, each digit conveys one bit of
information: the symbol 0 is interpreted by the computer as the command oﬀ
and the symbol 1 as the command on. Other bases used in computer science
are β = 8 and β = 16.
So the role played in numeral systems by the number 10 may be played by
any other integer greater than 1. For instance, if we choose 9 as a base, the
number 3 · 93 + 0 · 92 + 1 · 91 + 3 · 90 is represented in base 10 as 2199. On the
other hand, the number 3013 is represented in base 9 by 4117.
The result on which the possibility of counting in any base depends is the
following theorem.
Theorem 1.4.1. Let β be an integer greater than or equal to 2. Then, for each
n ∈N, there exist a non-negative integer k and k + 1 integers a0, a1, . . . , ak
such that 0 ≤ai < β, for each i = 0, . . . , k, these being the only such integers
satisfying:
n = akβk + ak−1βk−1 + · · · + a2β2 + a1β + a0.
(1.28)
Proof. Apply the Euclidean algorithm in the following way: divide n by β
obtaining
n = β · q0 + a0,
0 ≤a0 < β.
Now, if q0 ̸= 0, divide again q0 by β obtaining
q0 = β · q1 + a1,
0 ≤a1 < β.
Going on in the same way we get
q1 = β · q2 + a2,
0 ≤a2 < β,
...
qs−2 = β · qs−1 + as−1,
0 ≤as−1 < β,
qs−1 = β · qs + as,
0 ≤as < β.
As n > q0 > q1 > · · · > qs ≥0 is a strictly decreasing sequence of non-
negative integers, it necessarily reaches zero. Let k be the ﬁrst integer such
that qk = 0.

32
1 A round-up on numbers
Rewrite the list of relations obtained above:
n = β · q0 + a0,
0 ≤a0 < β,
q0 = β · q1 + a1,
0 ≤a1 < β,
q1 = β · q2 + a2,
0 ≤a2 < β,
...
qk−3 = β · qk−2 + ak−2,
0 ≤ak−2 < β,
qk−2 = β · qk−1 + ak−1,
0 ≤ak−1 < β,
qk−1 = β · 0 + ak,
0 ≤ak < β.
Proceed backwards by substituting the value qk−1 = ak, obtained from last
equation, in the previous one. We ﬁnd
qk−2 = β · ak + ak−1.
Substituting in the previous equation we ﬁnd
qk−3 = β · (β · ak + ak−1) + ak−2 = β2 · ak + β · ak−1 + ak−2.
Going on like this up to the ﬁrst equation we ﬁnally get expression (1.28).
The uniqueness of this expression is clear, as the digits ai appearing in it are
uniquely determined as the remainders of the successive divisions.
⊓⊔
In conclusion, each number stricly smaller than the base β is represented by
a unique symbol or digit. To represent a number in base β, β diﬀerent symbols
are necessary. The number having as its expression (1.28) is usually denoted
by the symbol (akak−1 . . . a1a0)β or simply by the symbol akak−1 . . . a1a0,
without explicitly mentioning the base, when no confusion can possibly arise.
1.4.2 Base 2
How are the representations of a number in diﬀerent bases related? To under-
stand this, it suﬃces to keep in mind the proof of Theorem 1.4.1, which gives
an algorithm based on division to determine the expression of a number in a
base β. For instance, to go from the base 10 to the base 2, it suﬃces to divide
the given number by 2, and to divide successively each quotient by 2, till we
arrive to a zero quotient. The remainders we obtain, read from the bottom
up, give the representation in base 2 of the given number.
Suppose for instance we want to write the number 8112 in base 2:
8112 = 2 · 4056 + 0,
r0 = 0,
4056 = 2 · 2028 + 0,
r1 = 0,
2028 = 2 · 1014 + 0,
r2 = 0,
1014 = 2 · 507 + 0,
r3 = 0,
507 = 2 · 253 + 1,
r4 = 1,

1.4 Counting in diﬀerent bases
33
253 = 2 · 126 + 1,
r5 = 1,
126 = 2 · 63 + 0,
r6 = 0,
63 = 2 · 31 + 1,
r7 = 1,
31 = 2 · 15 + 1,
r8 = 1,
15 = 2 · 7 + 1,
r9 = 1,
7 = 2 · 3 + 1,
r10 = 1,
3 = 2 · 1 + 1,
r11 = 1,
1 = 2 · 0 + 1,
r12 = 1.
Thus, the number which is written as 8112 in base 10, in base 2 is written as
(8112)10 = (r12r11r10r9r8r7r6r5r4r3r2r1r0)2 = (1111110110000)2.
To reverse this operation, that is, to go from base 2 to base 10, it suﬃces
to sum up the right powers of two. For instance, to go back from the number
(1111110110000)2 to its decimal representation, we just write
(1111110110000)2 = 1 · 212 + 1 · 211 + 1 · 210 + 1 · 29 + 1 · 28 + 1 · 27+
+ 0 · 26 + 1 · 25 + 1 · 24 + 0 · 23 + 0 · 22 + 0 · 21 + 0 · 20 =
= 212 + 211 + 210 + 29 + 28 + 27 + 25 + 24 = 8112
using, when developing the powers of two, the 10 digits from 0 to 9.
Notice that in every base the expression “10” denotes the base itself, as
(1 0)β = 1 · β + 0 · β0 = β.
1.4.3 The four operations in base 2
Positional notation in base 10 represented a substantial advancement with
respect to non-positional notations, for instance the Roman one, where per-
forming calculations was far from easy. The binary system brings about a
further simpliﬁcation in this direction. Let us see why.
We describe now the rules to perform the four operations when we rep-
resent the numbers in base 2. The reader will notice that they are not too
diﬀerent from the calculation in base 10, well known since primary school.
On the other hand, using base 2 is particularly simple and, moreover, useful
and of practical use because, as we already recalled, this is the base used by
computers. Notice that 1 + 1 = 2 is written 1 + 1 = 10 in base 2. So the
addition tables we must learn in order to perform additions in base 2 are very
simple:
0 + 0 = 0,
0 + 1 = 1,
1 + 0 = 1,
1 + 1 = 1 0.

34
1 A round-up on numbers
Let a = n
i=0 ai · 2i and b = n
i=0 bi · 2i be two positive integers. Then
a + b =
n

i=0
(ai + bi) · 2i.
If we want to write this in base 2, we must act as follows. Suppose ai+bi is the
lowest-indexed coeﬃcient diﬀerent from 0 and 1. This means that ai = bi = 1.
Now use the addition table and remember that 1 + 1 = 10. This means
that the term (ai + bi) · 2i = 2 · 2i = 2i+1, and so we must carry 1 to the
next coeﬃcient, so the coeﬃcient of 2i+1 becomes ai+1 + bi+1 + 1, while the
coeﬃcient of 2i is 0. We go on like this for all indices.
Let us see an example to demonstrate this procedure. Suppose we have to
sum the numbers 10111111 e 1011:
carries
1 1 1 1 1 1
1 0 1 1 1 1 1 1 +
1 0 1 1 =
1 1 0 0 1 0 1 0
Recall that the terms on the columns represent the coeﬃcients of powers of
2, increasing from right and beginning with 20. In this case a0 = b0 = 1 and
a1 = b1 = 1, so the coeﬃcient of 20 becomes 0 and the coeﬃcient of 2 becomes
(1+1)+1 = 21 +20, so that the coeﬃcient of 21 is 1 while that of 22 becomes
a2 + b2 + 1 = (1 + 0) + 1, as shown in the table. Iterating this reasoning,
write zero for the coeﬃcient of 22, and carry one, that is, add one to the next
coeﬃcient, and so on. For the curious reader: the numbers we are adding up
are respectively, in base 10, 191 e 11 and their sum is 202, corresponding to
the base 2 result as shown.
In the same way, if
a =
n

i=0
ai · 2i,
b =
n

i=0
bi · 2i
and a ≥b, then
a −b =
n

i=0
(ai −bi) · 2i.
Here we face the problem of having all coeﬃcient in this operation become
0 or 1. The problem obviously only arises if for some i we have ai = 0 and
bi = 1. In this case, in the row representing a, we borrow a 1 from the ﬁrst 1
appearing when we move leftwards starting from ai.
Let us see an example, with
a = 33 = 25 + 1 · 20 = (1 0 0 0 0 1)2,
b = 10 = 23 + 1 · 21 = (1 0 1 0)2.

1.4 Counting in diﬀerent bases
35
Then
a −b = 25 −23 −21 + 20 = 25 −23 −22 + (2 −1) · 21 + 20 =
= 25 −23 −22 + 1 · 21 + 20 =
= 25 −23 −23 + 23 −22 + 21 + 20 =
= 25 −23 −23 + (2 −1) · 22 + 21 + 20 =
= 25 −2 · 23 + 1 · 22 + 21 + 20 = 25 −24 + 22 + 21 + 20 =
= (2 −1) · 24 + 22 + 21 + 20 = 24 + 22 + 21 + 20 =
= (1 0 1 1 1)2
which represents in base 2 the number 23.
Let us see how we actually perform the subtraction of the same two num-
bers:
•
a0 −b0 = 1 −0 = 1, so we may write 1 under the rightmost column:
1 0 0 0 0 1 −
1 0 1 0 =
1
•
notice now that a1 −b1 = 0−1 is negative: so we must begin “borrowing”.
The ﬁrst 1 we meet going leftwards is the coeﬃcient of 25. We must move
the coeﬃcient 1 to the right, until it is over the second column from right,
keeping in mind that for each i we have 2i = 2i−1 + 2i−1. So we perform
the following steps:
1.
borrowings
1
̸ 1 1 0 0 0 1 −
1 0 1 0 =
1
2.
borrowings ̸ 1 1
0 1 1 0 0 1 −
1 0 1 0 =
1
3.
borrowings
̸ 1 1
0 1 1 1 0 1 −
1 0 1 0 =
1
4.
borrowings
̸ 1 1
0 1 1 1 1 1 −
1 0 1 0 =
1

36
1 A round-up on numbers
Finally,
borrowings
1
0 1 1 1 1 1 −
1 0 1 0 =
1 0 1 1 1
and so the result of the subtraction is
1 0 1 1 1 .
Remark 1.4.2. Computers actually transform each subtraction operation into an
addition by a method called two’s complement. To demonstrate this method, let us
take a step backward. We write down in the following table the integer numbers
from 0 to 15, written in base 2.
base 10 base 2
base 10 base 2
0
0000
8
1000
1
0001
9
1001
2
0010
10
1010
3
0011
11
1011
4
0100
12
1100
5
0101
13
1101
6
0110
14
1110
7
0111
15
1111
(1.29)
Notice that to represent all of them we need 4 bits, where each bit represents a
symbol: 0 or 1. In the above table we added zeros on the left in order to ﬁll up all
4 available positions. With ﬁve bits we may represent numbers up to 31 = 32 −1 =
25 −1.
In general, with n bits we may represent all positive integers a with 0 ≤a < 2n.
In a computer, information is stored in 8-bit units called bytes; so a machine with
a 1-byte memory unit can represent in a single cell any integer number between 0
and 28 −1 = 255, while a machine with 2-byte cells can represent in a single cell
numbers up to 216 −1 = 65535. Finally, a machine with 4-byte cells can store in a
single cell numbers up to 232 −1 = 4,294,967,295.
In n-bit representation we add to the left all the zeros necessary to ﬁll up the
available positions.
To get back to how computers actually perform subtractions by transforming
them into additions, the critical point is the maximum length of the strings com-
puters use to represent integers. In other words, if the maximum length is 4, the
number 10001 is read as 0001, that is, the computer forgets all the coeﬃcients of the
terms of the form 2h, with h ≥4 and, for instance, read the number 17 = (10001)2
as 1.
Suppose the computer has 4-bit cells and we want to subtract b = 0111 from
a = 1001.
The following steps are performed:
•
ones’ complement: exchange 1 and 0 in the digits of the binary representation
of b, obtaining b′ = 1000;

1.4 Counting in diﬀerent bases
37
•
two’s complement: add the number 0001 to b′, obtaining b′′ = 1001;
•
sum: add b′′ = 1001 to a = 1001.
We shall call b′′ the opposite of b. But care is needed! This is not the true opposite
of b, that is −b. However, for the computer it works as such, because the computer
only reads digits up to the fourth one. So b′′ + b = 1001 + 0111 = 1|0000 which the
computer reads as 0000. In the example, subtracting b from a as above we obtain
1 0 0 1 −
0 1 1 1 =
0 0 1 0
By using the computer’s method, that is two’s complement, we have to compute
a + b′′ obtaining
1 0 0 1 +
1 0 0 1 =
̸ 1 0 0 1 0
which is the right result because, as already remarked, the initial 1, crossed out here,
does not exist for the computer!
Let us now explain theoretically why things work. Let a, b be positive integers
with a ≥b and a, b both smaller than 2n. We have
a −b + 2n = a + ((2n −1) −b + 1).
As 2n = (1 0 . . . 0), a string of length n + 1, and 2n −1 = (1 1 . . . 1 1), a string of
length n, then b′, the complement to 1 of b, is
(2n −1) −b = (1 1 . . . 1 1) −b
and so b′′, the opposite of b, is (2n −1) −b + 1 = 2n −b. Thus, we have
a + b′′ = 2n + a −b,
which is read by the computer as a −b, if it uses an n-bit cell.
Let us discuss now multiplication. It easily reduces to addition, due to the
following simple remark. If we are considering the number
a =
n

i=0
ai · 2i,
then
2j · a =
n

i=0
ai · 2i+j,
that is, 2j ·a may be written simply moving leftwards by j positions the digits
of a and putting on their right the same number of zeros. On the other hand,
suppose we have the numbers
a =
n

i=0
ai · 2i,
b =
m

j=0
bj · 2j.

38
1 A round-up on numbers
Suppose the non-zero (and so equal to 1) digits of b are exactly the h digits
bj1, · · · , bjh, that is, let
b =
h

l=1
2jl.
In this case we have
a · b =
h

l=1
n

i=0
(ai · 2i+jl).
In conclusion, multiplying a and b reduces to summing up the h numbers
obtained from a by moving leftwards its digits by bj1, . . . , bjh positions, and
putting on the right the same number of zeros. These zeros are usually omitted:
we may simply draw up in a column and sum up the numbers obtained by
suitably moving leftwards the digits of a. For instance,
1 1 1 0 1 ×
1 1 0 1 =
1 1 1 0 1
1 1 1 0 1 - -
1 1 1 0 1 - - -
1 0 1 1 1 1 0 0 1
(1.30)
The reader is encouraged to verify the correctness of this calculation by per-
forming it in base 10 too (see Exercise B1.56).
Finally, as regards division, we may proceed in the same way as in base 10,
with thing made easier by the successive divisions having quotients equal to
1 or 0 only, while the remainders are computed by subtractions, as described
above. For instance, consider a = 30 = (11110)2 and b = 4 = (100)2. Let us
see the steps to compute the quotient and the remainder of the division of a
by b:
1 1 1 1 0 1 0 0
1 0 0
1 1 1
1 1 1
1 0 0
1 1 0
1 0 0
1 0
Analogously, let a = 26 = (11010)2 and b = 5 = (101)2. The division of a by
b is
1 1 0 1 0 1 0 1
1 0 1
1 0 1
1 1 0
1 0 1
1

1.4 Counting in diﬀerent bases
39
Remark 1.4.3. Writing a number in base 2, the ease of performing operations
notwithstanding, requires on the other hand more space than writing it in a larger
base, for instance in the usual base 10. A remedy to this inconvenient situation is
given by proceeding as follows, using table (1.29): consider the 16-element set of
all 4-digit strings formed by the digits in {0, 1}. Each of these strings represents a
number in base 2, as shown in table (1.29).
By putting 1010 = A, 1011 = B, 1100 = C, 1101 = D, 1110 = E and 1111 = F,
we have 16 symbols 0, . . . , 9, A, B, C, D, E, F which we may take as the digits of
a hexadecimal system. It is very easy to obtain a number written in base 16 from a
number written in base 2: it is suﬃcient to subdivide the binary number, from right
leftwards, in 4-digit groups (four bits = half a byte, one byte consisting of 8 bits).
Here is an example:
(1000

8
1110

E
1101

D
0110

6
0001

1
)2 = (8ED61)16 =
= 8 · (16)4 + 14 · (16)3 + 13 · (16)2 + 6 · 16 + 1 = (585057)10.
To go from a binary system to a base 8 system, it suﬃces to group digits in
3-digit groups, starting from the right.
1.4.4 Integer numbers in an arbitrary base
Coming back to arbitrary bases we point out, without delving too much into
concepts that are by now quite clear and are studied further in the exercises,
that here too the four fundamental operations on numbers may be performed.
It is enough to know the addition and multiplication tables of 1-digit numbers,
and to follow the ordinary rules for carries, as expounded in the case of base
2. Here are the addition and multiplication tables in base 3:
+
0
1
2
0
0
1
2
1
1
2
10
2
2
10
11
·
0
1
2
0
0
0
0
1
0
1
2
2
0
2
11
For instance, to calculate (221)3 +(12)3 it is enough to proceed as follows.
Write 1 + 2 = 1 0, then write 0 and carry 1. Then compute 1 + 2 + 1 = 1 1.
Write 1 and carry 1. Finally, 1 + 2 = 1 0. In conclusion, we have
1 1
2 2 1 +
1 2
1 0 1 0
We proceed analogously for multiplication. For instance, the reader will be
able to verify that (221)3 · (12)3 = (11122)3.

40
1 A round-up on numbers
1.4.5 Representation of real numbers in an arbitrary base
Not just integer numbers but more in general real numbers may be represented
in a given base β. Indeed, the following result holds.
Theorem 1.4.4. Let a be a real number such that 0 ≤a < 1 and let β > 1 be
an integer. Then a may be written as the sum of a series
a =
∞

i=1
ci
βi
(1.31)
where the coeﬃcients are integers ci such that 0 ≤ci ≤β −1. This series is
unique if we require that for each positive integer m there is an integer n ≥m
such that cn ̸= β −1.
Proof. When the interval [0, 1] is partitioned into β equal parts there exists
a unique integer c1 such that
c1
β ≤a < c1 + 1
β
.
Partitioning further the interval [c1/β, (c1 + 1)/β] into β equal parts, there
exists a unique integer c2 such that
c1
β + c2
β2 ≤a < c1
β + c2 + 1
β2
.
By iterating this procedure, we prove the existence of the series in (1.31). As
to the uniqueness, the procedure just described is obviously unique and cannot
give a series such that for some positive integer m one has cm−1 < β −1 and
for each n ≥m one has cn = β −1. Indeed, keeping in mind that
∞

i=0
1
βi =
β
β −1,
in this case we would get
a =
∞

i=1
ci
βi =
m−1

i=1
ci
βi +
∞

i=m
β −1
βi
=
m−1

i=1
ci
βi + β −1
βm
∞

i=0
1
βi =
=
m−1

i=1
ci
βi +
1
βm−1 .
Thus, the above procedure would yield the series
a =
m−2

i=1
ci
βi + cm−1 + 1
βm−1
rather than
a =
m−1

i=1
ci
βi +
∞

i=m
β −1
βi
.
⊓⊔

1.4 Counting in diﬀerent bases
41
By this theorem it is possible to write real numbers in base β. Indeed, if
a is a positive real number, its integral part [a], deﬁned as the unique integer
x such that x ≤a < x + 1, may be written in base β as (akak−1 . . . a1a0)β.
Moreover, we may apply the above theorem to the real number a −[a], which
belongs to the interval [0, 1) and is usually written
a −[a] = (0.c1c2c3 . . .)β.
In conclusion, we write
a = (akak−1 . . . a1a0.c1c2c3 . . .)β,
or simply
a = akak−1 . . . a1a0.c1c2c3 . . . ,
without mentioning base β if no confusion can possibly arise. This expression
is unique if it satisﬁes the conditions of Theorem 1.4.4. As regards the non-
uniqueness, in general, of expression (1.31), notice that, for instance, in base
10 we have 1 = 0.9999 . . .
The above remarks apply in particular to rational numbers, that is to the el-
ements of ﬁeld Q. We recall that the elements of Q are the fractions, that is they
may be written as n/m with n, m integers, m ̸= 0. Clearly it is always possible to
assume that GCD(n, m) = 1, and in this case the fraction n/m is said to be reduced.
Notice the following fact, an immediate consequence of Corollary 1.3.9 which is left
to the reader as an exercise (see Exercise A1.70).
Lemma 1.4.5. If n/m and n′/m′ are equal reduced fractions, then n is associated
with n′ and m to m′.
Some quick remarks about the representation of a rational number in a given
base β follow. The watchful readers will recognise notions learnt in school about the
base 10.
As a ﬁrst step, we call β–deﬁned, or just deﬁned a number a written as
akak−1 . . . a1a0.c1c2c3 . . . in base β, if there exist a positive integer m such that
ci = 0 for each i ≥m. In this case we simply write
a = akak−1 . . . a1a0.c1c2c3 . . . cm.
The digits c1c2c3 . . . cm are said to be the β–mantissa, or simply the mantissa,
of a. It is clear that a deﬁned number is rational. It is not true that every rational
number is deﬁned. Indeed, the following proposition holds, and its easy proof is left
to the reader (see Exercise A1.71).
Proposition 1.4.6. A rational number a is β–deﬁned if and only if it may be written
as a = n/m, with m a divisor of a power of β with non-negative integer exponent.
So we are left with the question of understanding how to represent in base β,
in general, rational numbers, and in particular those which are not β–deﬁned or, as
they are called, β–undeﬁned, or simply undeﬁned.

42
1 A round-up on numbers
We shall need some deﬁnitions. Given a = akak−1 . . . a1a0.c1c2c3 . . ., a is said to
be β–recurring, or simply recurring, if there exist integers m ≥0 and h ≥1 such
that for each positive integer n and for each i = 1, . . . , h one has cm+nh+i = cm+i.
In other words, after the digits c1, . . . , cm, we ﬁnd the digits cm+1, . . . , cm+h, and
they are periodically repeated:
a −[a] = 0.c1 . . . cmcm+1 . . . cm+hcm+1 . . . cm+h . . . cm+1 . . . cm+h . . . ;
this may be written more concisely as
a −[a] = 0.c1 . . . cmcm+1 . . . cm+h.
The digits cm+1 . . . cm+h are called recurring digits of a = akak−1 . . . a1a0.c1c2c3 . . .,
the digits c1 . . . cm are the non-recurring digits (after the decimal separator). If
m = 0, that is if there are no non-recurring digits, a is said to be a simple recurring
number, otherwise it is said to be mixed recurring.
Coming back to the problem of understanding the representation in base β of
rational numbers, we may clearly reduce to considering numbers in the interval
(0, 1). The problem is completely settled by the following result:
Proposition 1.4.7. Let a be a real number such that 0 < a < 1. The number a is
rational if and only if it is β–recurring. More precisely, we have
a = 0.c1 . . . cmcm+1 . . . cm+h
if and only if
a = (c1 . . . cmcm+1 . . . cm+h)β −(c1 . . . cm)β
(β −1, . . . , β −1



h
, 0, . . . , 0
  
m
)β
:
the digit β −1 is repeated h times, that is a number of times equal to the number of
repeating digits, and 0 is repeated m times, that is a number of times equal to the
number of non-repeating digits after the decimal separator.
In general, if
a = akak−1 . . . a0.c1 . . . cmcm+1 . . . cm+h,
we have
a = akak−1 . . . a0 + (c1 . . . cmcm+1 . . . cm+h)β −(c1 . . . cm)β
(β −1, . . . , β −1



h
, 0, . . . , 0
  
m
)β
and this fraction is sometimes called generating fraction of a.
For instance, the recurring number written in base 10 as
107.45510
is the rational number
107 + 45510 −455
99000
= 107 + 45055
99000 .
We postpone the proof of this proposition to Chapter 4 (see § 4.3), where we
shall give further information about the structure of the recurring digits of a rational
number in a given base.

1.5 Continued fractions
43
1.5 Continued fractions
A very important application of the Euclidean algorithm lies in the continued
fractions, which also gives an alternative way of representing real numbers. In
this section we shall examine this subject and shall see its link with the solu-
tion of linear Diophantine equations. We shall again ﬁnd them when studying
the problem of factoring.
Let us begin with the numbers a = 214 and b = 35. By applying the
Euclidean algorithm to these numbers we ﬁnd
214 = 35 · 6 + 4,
(1.32)
35 = 4 · 8 + 3,
(1.33)
4 = 3 · 1 + 1,
(1.34)
3 = 1 · 3 + 0.
(1.35)
We now divide both sides of Equation (1.32) by 35, obtaining
214
35 = 6 + 4
35.
(1.36)
So we have obtained a ﬁrst piece of information: the rational number 214/35
lies between 6 and 7, as 0 < 4/35 < 1. By writing 4/35 as the inverse of a
number greater than 1, formula (1.36) becomes
214
35 = 6 +
1
35
4
.
(1.37)
Divide the next formula (1.33) by 4:
35
4 = 8 + 3
4
(1.38)
and rewrite it in the form
35
4 = 8 + 1
4
3
.
(1.39)
Finally, dividing Equation (1.34) by 3 we get
4
3 = 1 + 1
3.
In this way we have found the following expression for 214/35:
214
35 = 6 +
1
8 +
1
1 + 1
3
.
It is called the continued fraction representation of 214/35.

44
1 A round-up on numbers
Representing a rational number by a continued fraction might seem just
a useless curiosity: actually, it yields in a natural way simple and eﬀective
approximations of the rational number we are considering. For instance, in
the present case the two fractions
6,
6 + 1
8 = 49
8 = 6.125,
approximate quite well the rational number 214/35 = 6.1142857. The meaning
of “quite well” will be speciﬁed later.
Let us see one more example.
Example 1.5.1. Find the expression of 17/7 as a continued fraction.
The Euclidean algorithm is as follows.
17 = 7 · 2 + 3,
7 = 3 · 2 + 1,
3 = 1 · 3 + 0;
from this we get
17
7 = 2 + 3
7 ,
7
3 = 2 + 1
3 ,
so the expression of 17/7 as a continued fraction is
17
7 = 2 +
1
2 + 1
3
.
The fractions approximating 17/7 are the following:
2,
2 + 1
2 = 5
2 = 2.5,
while the exact value of 17/7 is 2.428571.
1.5.1 Finite simple continued fractions and rational numbers
We have just seen an example of a continued fraction. In order to formalise
what we have seen, we give the following deﬁnition.
Deﬁnition 1.5.2. A ﬁnite continued fraction is a fraction of the form
a1 +
1
a2 +
1
a3 +
1
a4 + ...
1
an−1 + 1
an
(1.40)

1.5 Continued fractions
45
with a1, a2, . . . , an real numbers, all positive with the possible exception of a1.
The numbers a2, . . . , an are called partial denominators, or partial quotients,
of the fraction.
A ﬁnite continued fraction is said to be simple if all of its partial quotients
are integer.
We shall mostly deal with simple continued fractions.
Clearly, every simple ﬁnite continued fraction is a rational number. On the
other hand, as the Euclidean algorithm can be applied to arbitrary integers a
and b, with b ̸= 0, it is easily understood, keeping also in mind the above ex-
ample, that any rational number can be expanded as a ﬁnite simple continued
fraction. This is the gist of the following proposition.
Proposition 1.5.3. Every ﬁnite simple continued fraction is equal to a ra-
tional number, and every rational number can be written as a ﬁnite simple
continued fraction.
Proof. The ﬁrst part is trivial. For the second one, let a/b be the rational
number, b > 0. Apply the Euclidean algorithm to ﬁnd the GCD of a and b:
a = ba1 + r1,
0 < r1 < b,
b = r1a2 + r2,
0 < r2 < r1,
r1 = r2a3 + r3,
0 < r3 < r2,
...
ri = ri+1ai+2 + ri+2,
0 < ri+2 < ri+1,
...
rn−3 = rn−2an−1 + rn−1,
0 < rn−1 < rn−2,
rn−2 = rn−1an + 0.
As all the remainders are positive, so are all the quotients ai, with the pos-
sibe exception of the ﬁrst one. Rewrite the equations given by the Euclidean
algorithm dividing the ﬁrst one by b, the second one by r1, the third one by
r2 and so on, till the last one, to be divided by rn. So we obtain
a
b = a1 + r1
b = a1 +
1
b
r1
,
b
r1
= a2 + r2
r1
= a2 +
1
r1
r2
,
r1
r2
= a3 + r3
r2
= a3 +
1
r2
r3
,

46
1 A round-up on numbers
r2
r3
= a4 + r4
r3
= a4 +
1
r3
r4
,
...
rn−2
rn−1
= an.
The left-hand sides of these equations are rational numbers, which are rewrit-
ten as the sum of an integer and a fraction with numerator equal to 1. By
successive eliminations, we get
a
b = a1 +
1
b
r1
= a1 +
1
a2 +
1
r1
r2
;
hence
a
b = a1 +
1
b
r1
= a1 +
1
a2 +
1
r1
r2
= a1 +
1
a2 +
1
a3 +
1
r2
r3
,
until we obtain the expression
a
b = a1 +
1
a2 +
1
a3 +
1
a4 + ...
1
an−1 + 1
an
.
So we have represented the rational number a/b as a ﬁnite simple continued
fraction.
⊓⊔
The expression (1.40) is visually quite bulky, so it is more convenient to
denote the same continued fraction as follows.
[a1; a2, a3, . . . , an],
that is, as the ﬁnite sequence of its partial quotients. For instance, the fraction
in the above example can be written as
214
35 = [6; 8, 1, 3].

1.5 Continued fractions
47
Notice that the initial integer a1 is equal to zero if and only if the fraction is
positive and smaller than 1. Moreover, notice that a1 is the integer value that
approximates a/b from below, that is a1 = [a/b]; a2 is the value approximating
b/r1 from below, that is a2 = [b/r1], and in general
ai =
ri−2
ri−1

.
Remark 1.5.4. The representation of a rational number as a ﬁnite simple
continued fraction is not unique. Indeed, having found the representation as
shown, we always may modify its last term. In fact, if the last term an is
greater than 1, we may write
an = (an −1) + 1 = (an −1) + 1
1
where an −1 is positive, and so
[a1; a2, a3, . . . , an−1, an] = [a1; a2, . . . , an−1, an −1, 1].
If, on the other hand, the last term an is equal to 1, then
[a1; a2, a3, . . . , an] = [a1; a2, a3, . . . , an−2, an−1 + 1].
It is easy to verify that this is the only indeterminacy in the possible
expression of a continued fraction (see Exercise A1.73). So, every rational
number may be written as a ﬁnite simple continued fraction in exactly two
ways: one with the last partial quotient equal to 1, and one with the last
partial quotient greater than 1.
Example 1.5.5. Write the ratio fn/fn−1 of two consecutive Fibonacci num-
bers as a continued fraction.
From the relations
fn = fn−1 · 1 + fn−2,
0 < fn−2 < fn−1,
fn−1 = fn−2 · 1 + fn−3,
0 < fn−3 < fn−2,
...
f3 = f2 · 2 + 0,
we get
fn
fn−1
= 1 + fn−2
fn−1
= 1 +
1
fn−1
fn−2
,

48
1 A round-up on numbers
fn−1
fn−2
= 1 + fn−3
fn−2
= 1 +
1
fn−2
fn−3
,
...
f3
f2
= 2 + 0,
and hence
fn
fn−1
= 1 +
1
1 +
1
1 +
1
1 + ... 1
2
,
or
fn
fn−1
= [1; 1, 1, 1, . . ., 1, 2



n−2
] = [1; 1, 1, 1, . . ., 1



n−1
].
1.5.2 Inﬁnite simple continued fractions and irrational numbers
We have seen that all rational numbers, and no other number, can be repre-
sented as ﬁnite simple continued fractions.
The main reason of interest of continued fractions, however, is in their
application to the representation of irrational numbers. To that end we shall
need inﬁnite simple continued fractions.
As a quick historical aside, recall that studies about continued fractions are
found in Indian mathematics of 6th and 12th century, where they were used
to study linear equations. Fibonacci in his Liber Abaci attempted to give a
general deﬁnition of a continued fraction. The ﬁrst rigorous investigations into
continued fraction appeared in a 1572 book by Rafael Bombelli, the inventor,
among other things, of complex numbers. He wrote that “methods to form
fractions can be found in other authors’ works which attack and accuse each
other, in my opinion without reason because all of them are bent on the same
goal”. This same goal was, as Bolognese mathematician P.A. Cataldi wrote
in 1613 in his Trattato del modo brevissimo di trovare la radice quadrata dei
numeri (Treatise about the shortest way of ﬁnding square roots of numbers),
the problem of approximating the square roots of a non-square integer by a
rational expression. The phrase continued fraction ﬁrst appeared in the 1653
edition of J. Wallis’s Arithmetica inﬁnitorum. Other great mathematicians
studied inﬁnite continued fractions: among them, Euler in his De fractionibus
continuis, Lagrange, Gauss, and Liouville, who used them in his famous proof
of the existence of transcendental numbers.
In order to approach the idea of inﬁnite continued fractions, consider, as
a simple example, the number
√
2. As it is greater than 1 and smaller than 2,
we may write it in the form

1.5 Continued fractions
49
√
2 = 1 + 1
x
for some real number x > 1. Alternatively, we may write x =
√
2 + 1 and
hence
x =
√
2 + 1 =

1 + 1
x

+ 1 = 2 + 1
x.
From this equation the following ones may be deduced.
1
x =
1
2 + 1
x
=
1
2 +
1
2 + 1
x
= · · · =
1
2 +
1
2 +
1
2 + ...
1
2 +
1
2 + 1
x
⎫
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎭
n
.
As n approaches inﬁnity we obtain
√
2 = 1 +
1
2 +
1
2 +
1
2 +
1
2 +
1
2 + · · ·
.
This is, intuitively, the way of writing
√
2 as a continued fraction. We have
proved that ﬁnite simple continued fractions are rational numbers, while
√
2
is not (see Exercise A1.72), so it is to be expected that the continued fraction
we get for
√
2 is not ﬁnite, even if we have not yet deﬁned the concept of an
inﬁnite continued fraction.
The expression of
√
2 as a continued fraction uncovers a remarkable ele-
gance and regularity, as opposed to its decimal representation, which does not
show any regularity.
By using a generalised form of continued fraction, in which the numerators
are allowed not to be equal to 1, we may write the real number
√
a2 + b, where
a, b are integer numbers, in the following form:

a2 + b =
b
2a
b +
b
2a +
b
2a +
b
2a +
b
2a + · · ·
.

50
1 A round-up on numbers
In particular, we get

a2 + 1 = [a; 2a, 2a, . . .] = [a, 2a],
where 2a means that the continued fraction is periodic, that is to say, 2a is
repeated inﬁnitely many times. The case of
√
2 corresponds to putting a = 1
and b = 1.
Here follow some more examples.
√
3 = [1; 1, 2],
√
5 = [2; ¯4],
√
10 = [3; ¯6],
while the golden ratio has a truly perfect representation as a continued frac-
tion:
√
5 + 1
2
= [1; 1, 1, 1, . . .].
Before going on, we must attribute a meaning to the concept of contin-
ued fraction with inﬁnitely many terms. We begin by giving the following
deﬁnition.
Deﬁnition 1.5.6. Let [a1; a2, a3, . . . , an] be a ﬁnite simple continued fraction.
The continued fraction obtained by truncating this continued fraction after the
k-th partial quotient is called k-th convergent and is denoted as follows:
Ck = [a1; a2, a3, . . . , ak],
for each 1 ≤k ≤n.
Notice that Ck+1 may be obtained from Ck by substituting ak + 1/ak+1
for ak. Clearly, for k = n we get the complete original continued fraction.
Every Ck = [a1; a2, . . . , ak] is a rational number which will be denoted
by pk/qk, where GCD(pk, qk) = 1. It is important to ﬁnd formulas for the
numerator pk and the denominator qk when the ais are known. Clearly, if
C1 = [a1] = p1/q1, then p1 = a1 and q1 = 1. Moreover, if
C2 = [a1; a2] = a1 + 1
a2
= a1a2 + 1
a2
= p2
q2
,
then p2 = a1a2 + 1 and q2 = a2. Analogously, if
C3 = [a1; a2, a3] = a1 +
1
a2 + 1
a3
= a3(a2a1 + 1) + a1
a3a2 + 1
,
then p3 = a3(a2a1 + 1) + a1 = a3p2 + a1 and q3 = a3a2 + 1 = a3q2 + q1.
It can be shown (see Exercise A1.75) that in general the following recur-
rence relations hold:
pk = akpk−1 + pk−2,
qk = akqk−1 + qk−2.
(1.41)

1.5 Continued fractions
51
From these relations it is straightforward to obtain
pkqk−1 −qkpk−1 = −(pk−1qk−2 −qk−1pk−2).
As
p2q1 −q2p1 = (a1a2 + 1) · 1 −a2a1 = 1,
it follows that
pkqk−1 −qkpk−1 = (−1)k :
(1.42)
hence, in particular, for each k = 1, . . . , n, the numbers pk and qk are relatively
prime. By dividing the last relation by qkqk−1 we get
pk
qk
−pk−1
qk−1
= (−1)k
qkqk−1
,
that is,
Ck −Ck−1 = (−1)k
qkqk−1
,
(1.43)
which holds for each k ≥1. It can be shown in a completely analogous way
that the following relation
Ck −Ck−2 = (−1)k+1ak
qkqk−2
(1.44)
holds for each k ≥2 (see Exercise A1.76). We shall shortly use these equations.
The following formula is a direct consequence of Equation (1.41), and it
is more convenient in practice. The convergents Ck = pk/qk of the continued
fraction [a1; a2, a3, . . . , an], for 2 ≤k ≤n, may be obtained with the following
formula (see Exercise A1.77).
 a1 1
1
0

·
 a2 1
1
0

·
 a3 1
1
0

· · ·
 ak 1
1
0

=
 pk
pk−1
qk
qk−1

.
(1.45)
Example 1.5.7. Determine with the above method the convergents of the
continued fraction 17/7 = [2; 2, 3].
We have

2 1
1 0
 
2 1
1 0

=

5 2
2 1

=

p2
p1
q2
q1

,
hence p2/q2 = 5/2, and p1/q1 = 2/1, as we saw above. Going on, we ﬁnd
 5 2
2 1
  3 1
1 0

=
 17 5
7
2

=
 p3
p2
q3
q2

,
or, as it is supposed to be, p3/q3 = 17/7.

52
1 A round-up on numbers
Example 1.5.8. Find the convergents of 214/35 = [6; 8, 1, 3].
Applying the same method as above, we have

6 1
1 0
 
8 1
1 0

=

49 6
8
1

=

p2
p1
q2
q1

,
hence p2/q2 = 49/8, and p1/q1 = 6/1. Moreover,

49 6
8
1
 
1 1
1 0

=

55 49
9
8

=

p3
p2
q3
q2

,
hence p3/q3 = 55/9. It is obvious that p4/q4 = 214/35 and it is not necessary
to compute it.
Example 1.5.9. Which rational number is [1; 2, 3]?
We have

p3
p2
q3
q2

=

1 1
1 0

·

2 1
1 0

·

3 1
1 0

=

10 3
7
2

,
which means
[1; 2, 3] = C3 = p3
q3
= 10
7 .
Example 1.5.10. The orbital period of Saturn, that is to say the time taken
for it to complete one orbit around the Sun, is 29.46 years. In Huygens’s times,
it was believed to be 29.43 years. In order to simulate Saturn’s trajectory
around the Sun, Huygens had to build two gears, one with p teeth and the
other with q teeth, such that p/q were approximately 29.43. Which values did
Huygens choose for p and q? To be useful, p and q had to be quite small: he
could not use a gear with 2943 teeth and one with 100 teeth. So he computed
the convergents of 29.43 = 2943/100. Using the Euclidean algorithm, one gets
2943 = 100 · 29 + 43,
100 = 43 · 2 + 14,
43 = 14 · 3 + 1,
14 = 1 · 14 = 0;
hence
2943
100 = 29 + 43
100,
100
43 = 2 + 14
43,
43
14 = 3 + 1
14,
so the expression 2943/100 as a continued fraction is
2943
100 = [29; 2, 3, 14].
Thus, the ﬁrst three convergents are

1.5 Continued fractions
53
C1 = 29
1 ,
C2 = a1a2 + 1
a2
= 59
2 ,
C3 = a3(a2a1 + 1) + a1a3a2 + 1 = 3 · 59 + 29
7
= 206
7 .
A quite good approximation of 29.43 is given by the fraction 206/7 = 29.4285.
So, in order to simulate the motion of Saturn with respect to Earth’s motion,
Huygens built two gears, one with 7 teeth and one with 206 teeth.
Notice that the convergents Ck of a ﬁnite simple continued fraction oscil-
late. Indeed, the following lemma holds, the easy proof of which is left as an
exercise to the reader (see Exercise A1.78).
Lemma 1.5.11. Let a/b = [a1; a2, . . . , an] be a simple continued fraction.
Then its convergents satisfy the following properties:
•
C1 < C3 < C5 < · · · ,
•
C2 > C4 > C6 > · · · ,
•
C2k > C2j−1, for each j, k ≥1.
Hence we deduce that
C1 < C3 < C5 < · · · ≤a
b ≤· · · < C6 < C4 < C2,
(1.46)
that is to say that the convergents approximate the continued fraction, but
oscillating: the odd-indexed ones increase and approximate it by defect, while
the even-indexed ones decrease and approximate it by excess, and each even-
indexed convergent is greater than all odd-indexed convergent.
We may ﬁnally attribute a precise meaning to an expression of the form
[a1; a2, a3, . . .], with a1, a2, a3, . . . an inﬁnite sequence of integers such that
ai > 0 for i > 1: it will be called inﬁnite simple continued fraction with
partial quotients a1; a2, a3, . . . , an, . . . Having put Cn = [a1; a2, a3, . . . , an],
which shall be called convergents of the inﬁnite continued fraction, deﬁne
[a1; a2, a3, . . .] = lim
n→∞Cn.
The existence of this limit is ensured by the following theorem.
Theorem 1.5.12. The concept of an inﬁnite simple continued fraction is
well-deﬁned, that is to say the following limit exists and it is an irrational
number:
lim
n→∞Cn = lim
n→∞[a1; a2, a3, . . . , an].

54
1 A round-up on numbers
Proof. As we have seen, the sequence of odd-indexed convergents, C1, C3,
C5, . . ., is increasing, while the sequence of even-indexed ones, C2, C4, C6, . . .,
is decreasing. Moreover, the ﬁrst sequence is bounded above and the second
is bounded below. It is well-known that
lim
n→∞C2n−1 = sup{C2n−1},
lim
n→∞C2n = inf{C2n};
we shall denote these two numbers by α1 and α2. We have next, by using
Equation (1.43),
α2 −α1 = lim
n→∞(C2n −C2n−1) = lim
n→∞
1
q2nq2n−1
= 0,
as limn→∞qn = +∞. Consequently, α1 = α2. If we put α = α1 = α2, we get
α = lim
n→∞Cn.
As to the irrationality of α, assume by contradiction α = p/q, for integer p, q,
q ̸= 0. For each n ≥1 we have
C2n−1 < α < C2n,
and so we also have
0 < α −C2n−1 < C2n −C2n−1,
or
0 < α −p2n−1
q2n−1
<
1
q2nq2n−1
,
that is
0 < αq2n−1 −p2n−1 <
1
q2n
,
and ﬁnally
0 < pq2n−1 −qp2n−1 <
q
q2n
.
This last relation immediately leads to a contradiction. Indeed, the central
term is a non-zero integer because α > C2n−1, while the right-hand term has
limit zero as n approaches inﬁnity.
⊓⊔
We have so clariﬁed the concept of an inﬁnite simple continued fraction
and its convergents. For instance, in the case of
√
2, we have C1 = 1, C2 =
3/2 = 1.5, C3 = 1.4 and then
C4 = 1 + 5
12 = 1.41¯6,
C5 = 1 + 12
29 = 1.4137931034482758620689655172,
C6 = 1 + 29
70 = 1.4142857,
...

1.5 Continued fractions
55
The convergents are oscillating for inﬁnite continued fractions too. In the case
of
√
2, all the C2k are greater than
√
2, while all the C2k+1 are smaller than
it. In other words, the sequence {C2k+1} is monotonically increasing, while
{C2k} is monotonically decreasing, and both sequences have limit
√
2.
We may complete the last theorem as follows.
Theorem 1.5.13. Every positive irrational number α may be expressed as an
inﬁnite simple continued fraction in a unique way.
Proof. We give a sketch of the proof, leaving the details to the reader (see
Exercise A1.79). We deﬁne recursively the partial quotients a1, a2, . . . , an, . . .
of the continued fraction expressing α. We may do this as follows.
•
put α1 = α;
•
suppose α1, . . . , αn have been deﬁned; put an = [αn] and deﬁne recursively
αn+1 = 1/(αn −an).
It is possible to verify that α = [a1; a2, . . . , an, . . .].
Suppose now that α = [a1; a2, . . . , an, . . .] = [b1; b2, . . . , bn, . . .]. We have
C1 = a1 < α < a1 + 1
a2
= C2,
and so a1 = [α]. Analogously b1 = [α] must hold, and so a1 = b1. Notice now
that
α = [a1; a2, . . . , an, . . .] = a1 +
1
[a2; a3, . . . , an, . . .],
α = [b1; b2, . . . , bn, . . .] = a1 +
1
[b2; b3, . . . , bn, . . .];
hence [a2; a3, . . . , an, . . .] = [b2; b3, . . . , bn, . . .], and so a2 = b2. By induction
one has an = bn for each n > 0.
⊓⊔
Example 1.5.14. Write
√
6 as a continued fraction.
Put a1 = [
√
6] = 2. Consequently, deﬁne
α2 =
1
√
6 −2 =
√
6 + 2
2
,
a2 = [α2] = 2,
and successively
α3 =
1
√
6 + 2
2
−2
=
√
6 + 2,
a3 = [α3] = 4,
α4 =
1
√
6 −2 =
√
6 + 2
2
,
a4 = [α3] = 2,
and so forth. Hence,
√
6 = [2; 2, 4, 2, 4, . . .] = [2, 2, 4].

56
1 A round-up on numbers
1.5.3 Periodic continued fractions
It is not by chance that the continued fraction of
√
6, as well as that of
√
2 studied
above, are periodic. First of all, in order to better deﬁne and extend the concept of
a periodic continued fraction, which has already been partially shown, we shall say
that a continued fraction [a1; a2, a3, a4, . . .] is periodic if there exist positive integers
m, t ∈N such that an = an+t for each n > m. In this case the following notation is
used
[a1; a2, a3, a4, . . .] = [a1; a2, . . . , am, am+1, . . . , am+t]
and a1, . . ., am are said to be the non-repeating quotients of the fraction, while
am+1, . . ., am+t are said to be the repeating quotients of the fraction. If there are no
non-repeating quotients, that is to say if the fraction is of the form [a1; a2, . . . , at],
it is said to be purely periodic.
Let us now determine the irrational numbers such that their expression as con-
tinued fractions is periodic. We need a deﬁnition ﬁrst. A real number α is said to
be quadratic if α is a root of a quadratic equation with integer coeﬃcients. In this
case α is of the form
α = a + b
√
d,
a, b ∈Q,
with d a positive integer (see Exercise A1.81). The number
α′ = a −b
√
d,
which is the other root of the same quadratic equation, is said to be the conjugate
of α. For instance,
1 +
√
5
4 ,
1 −
√
5
4
are irrational conjugate quadratic numbers.
A quadratic number α is said to be reduced if α > 0 while −1 < α′ < 0. For
instance, if n is any non-square positive integer, it is clear that the number √n+[√n]
is reduced (see Exercise A1.85). For instance, 2 +
√
5 is reduced.
The proof of the following theorem will be given to the reader through a series
of exercises (see Exercises A1.87 to A1.94).
Theorem 1.5.15 (Lagrange). A continued fraction α = [a1; a2, a3, a4, . . .] is
periodic if and only if α is an irrational quadratic number. Moreover, [a1; a2, a3,
a4, . . .] is purely periodic if and only if α is reduced. In this case we have
α = [a1; a2, . . . , at],
−1
α′ = [at; at−1, . . . , a1].
Example 1.5.16. A positive integer n is said to be a perfect square or simply a
square if there exists an integer a such that n = a2. If n is a positive integer that is
not a perfect square, then √n is an irrational number (see Exercise A1.80). Let us
see now the structure of the expression of √n as a continued fraction. Put a0 = √n.
We have already seen that √n + [√n] is reduced. By applying Theorem 1.5.15
and noticing that [√n + [√n]] = 2a0, we obtain an expression of the form
√n + [√n] = [2a0; a1, a2, . . . , an] = [2a0; a1, a2, . . . , an, 2a0, a1, a2, . . . , an];
hence,

1.5 Continued fractions
57
√n = [a0; a1, a2, . . . , an, 2a0, a1, a2, . . . , an] = [a0; a1, a2, . . . , an, 2a0].
Thus
√n −[√n] = [0; a1, a2, . . . , an, 2a0],
and
1
√n + [√n] = [a1; a2, . . . , an, 2a0].
On the other hand, by applying Theorem 1.5.15 again, we get
1
√n + [√n] = [an; an−1, an−2, . . . , a1, 2a0].
So we obtain
a1 = an,
a2 = an−1,
. . . ,
an = a1,
that is to say, the expression of √n as a continued fraction has an interesting sym-
metry:
√n = [a0; a1, a2, . . . , a2, a1, 2a0].
We have already seen several instances of this state of things. The curious reader
might wish to ﬁnd a further conﬁrmation of what we have seen here by having a
look at the table of the expressions as continued fractions of all irrational numbers
of the form √n, with n a positive integer not greater than 100, in [49] (Table 5).
1.5.4 A geometrical model for continued fractions
We quickly mention a very simple and quite interesting geometrical model for con-
tinued fractions and their convergents. This interpretation was found by F. Klein in
1895 (see [16]).
Let α be an irrational positive number. In a given Cartesian coordinate system
consider the line y = αx. As α is irrational, this line does not pass through any
point with integer coordinates (see ﬁgure 1.3).
Imagine now nails driven in all points with positive integer coordinates, that is
in all points with integer coordinates which lie in the ﬁrst quadrant of the plane,
and imagine to lay along the line y = αx a string with one end ﬁxed in an inﬁnitely
far point and the other end ﬁxed in the origin. If we move downwards the end
of the string that was placed in the origin, the whole string will be moved and
it will run into some of the nails, that is some of the points with positive integer
coordinates. Analogously, by moving upwards the same end of the string, it will run
into some nails, that is some points with integer coordinates: so the string will form
two polygonal curves, one lying completely under the line y = αx and one above.
If we denote by (n1, m1), (n3, m3), (n5, m5), . . ., the nails hit by string in its
movement downwards, that is to say the vertices of the ﬁrst polygonal curve, and
by (n2, m2), (n4, m4), (n6, m6), . . ., the nails hit in its movement upwards, that is
to say the vertices of the second polygonal curve, the quotients mi/ni are exactly
the convergents Ci = pi/qi of the continued fraction [a1; a2, a3, . . .], which represents
the irrational number α (see ﬁgure 1.3), that is
mi
ni = Ci = pi
qi
for all i .

58
1 A round-up on numbers
x
y
•1
•
1
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
y = αx
•
•
•
Fig. 1.3. Approximating polygonal curves for the line y = αx in the Cartesian
Plane
1.5.5 The approximation of irrational numbers by convergents
Given an inﬁnite simple continued fraction [a1; a2, a3, . . .] it is possible to approx-
imate the corresponding irrational number α by rational numbers with arbitrary
precision, by computing the convergents Cn. Formulas (1.43) together with (1.46)
tell us that by using Cn−1 to approximate α the error is smaller than
1
qnqn−1 .
This fact may also be veriﬁed keeping in mind the geometrical model we have de-
scribed above.
As already mentioned, one of the reasons for the importance of the representation
of numbers by continued fractions lies in the fact that the convergents yield, in a
sense we are now making precise, the best possible approximation of an irrational
number by rational numbers. We prove some results in this spirit.
Theorem 1.5.17. Let α be an irrational number and let α = [a1; a2, a3, . . . , an, . . .]
be its expression as a continued fraction, and let Cn = pn/qn be its convergents. If
p, q are integers with q > 0 and if n is a positive integer such that
|qα −p| < |qnα −pn|,
(1.47)
then q ≥qn+1. Moreover, if
α −p
q
 < |α −Cn|,
(1.48)

1.5 Continued fractions
59
then q > qn. In other words, every convergent Cn = pn/qn approximates the value
of α better than any fraction whose denominator is smaller than or equal to qn.
Proof. Assume that Equation (1.47) hold and assume by contradiction that q <
qn+1. Consider the system

pnx + pn+1y = p,
qnx + qn+1y = q.
By using Equation (1.42), we ﬁnd
y = (−1)n+1(pqn −qpn),
x = (−1)n+1(qpn+1 −pqn+1).
Notice that x ̸= 0, or else we would have q = qn+1y ≥qn+1, contradicting the
hypothesis. Analogously, we have y ̸= 0, or we would have p = pnx, q = qnx and
then
|qα −p| = |x||qnα −pn| ≥|qnα −pn|
contradicting Equation (1.47).
We verify now that x and y have opposite signs. Let y < 0. Then qnx = q −
qn+1y > 0 and so x > 0 because qn > 0. Let y > 0. As qn+1y ≥qn+1 > q, we have
qnx = q −qn+1y < 0, and so x < 0.
It immediately follows from the fact that the convergents oscillate that qnα−pn
and qn+1α−pn+1 have opposite signs. Thus, x(qnα−pn) and y(qn+1α−pn+1) have
equal signs. As
|qα −p| = |(qnx + qn+1y)α −(pnx + pn+1y)|,
we have
|qα −p| = |x||qnα −pn| + |y||qn+1α −pn+1| ≥|qnα −pn|
contradicting Equation (1.47). This proves the ﬁrst part of the theorem.
Assume now that Equation (1.48) holds and, by contradiction, that q ≤qn. Then
we have
q
α −p
q
 < qn|α −Cn|,
that is, Equation (1.47). But in this case it follows that q ≥qn+1, and so we would
have qn ≥qn+1, contradicting Equation (1.41).
⊓⊔
Example 1.5.18. We have seen that the convergent C3 of the continued fraction
√
2 = [1, 2] equals 7/5 = 1.4. By approximating
√
2 with 1.4 the error is
√
2 −1.4 <
C4−C3 = 1.416−1.4 = 0.016. We show now that every fraction having, for instance,
denominator equal to 4 approximates
√
2 worse than 1.4. The only fractions to be
considered are 5/4 = 1.25, 6/4 = 3/2 = 1.5, and 7/4 = 1.75, as
√
2 is greater than
1 and smaller than 2. We have 1.25 < 1.4, and so it is clear that 1.25 approximates
√
2 worse than 1.4. On the other hand,
1.5 −
√
2 > 1.5 −C4 = 1.5 −1.416 = 0.183 > 0.016.
Thus 1.5 approximates
√
2 worse than 1.4 too. This holds a fortiori for 1.75 > 1.5.

60
1 A round-up on numbers
Theorem 1.5.19. Let α be an irrational number, let α = [a1; a2, a3, . . . , an, . . .] be
its expression as a continued fraction, and let Cn = pn/qn be its convergents. If p, q
are relatively prime integers with q > 0 and such that
α −p
q
 <
1
2q2 ,
then p/q is a convergent of the continued fraction [a1; a2, a3, . . . , an, . . .].
Proof. Suppose that p/q is not a convergent. We may ﬁnd two consecutive con-
vergents, Cn, Cn+1 such that qn ≤q < qn+1. By Theorem 1.5.17 we have
|qnα −pn| ≤|qα −p| = q
α −p
q
 < 1
2q ,
hence
|α −Cn| <
1
2qqn .
As p/q ̸= Cn, we have |qpn −pqn| ≥1, and so
1
qqn ≤|qpn −pqn|
qqn
=
Cn −p
q
 ≤|α −Cn| +
α −p
q
 <
1
2qqn +
1
2q2 ,
which yields
1
2qqn <
1
2q2 ,
that is to say, qn > q, contradicting the hypothesis.
⊓⊔
Proposition 1.5.20. Let α be an irrational number, let α = [a1; a2, a3, . . . , an, . . .]
be its expression as a continued fraction, and let Cn = pn/qn be its convergents. For
each n ≥1, we have
|p2
n −α2q2
n| < 2α.
Proof. Keeping in mind Equations (1.43) and (1.46), we have
|p2
k −α2q2
k| = q2
k|α2 −C2
k| = q2
k|α −Ck| · |α + Ck| <
<
qk
qk+1

α + α +
1
qkqk+1

and so
|p2
k −α2q2
k| −2α < 2α

−1 +
qk
qk+1
+
1
2αq2
k+1

<
< 2α

−1 +
qk
qk+1 +
1
qk+1

< 2α

−1 + qk+1
qk+1

= 0,
as was to be proved.
⊓⊔
We may apply the above result to obtain an information that will be useful later
on (see Chapter 6). Let n and a be positive integers and let r be the remainder of
the division of a by n. So 0 ≤r < n. Deﬁne least absolute residue of a with respect
to n, or modulo n, the integer r, if 0 ≤r ≤n/2, or the integer r −n if n/2 < r < n.
In this last case, we have 0 > r −n > −n/2. Denote the least absolute residue of a

1.5 Continued fractions
61
with respect to n by the symbol LAR(a, n). As a consequence of the deﬁnition, we
always have
−n
2 < LAR(a, n) ≤n
2
(1.49)
and LAR(a, n) is the only integer satisfying Equation (1.49) such that a−LAR(a, n)
is divisible by n.
For instance, LAR(35, 9) = −1.
Proposition 1.5.21. Let n ≥17 be a non-square positive integer and let Ck =
pk/qk be the k-th convergent of the continued fraction expressing √n. Then for each
k ≥1 we have
| LAR(p2
k, n)| < 2√n.
Proof. Last proposition implies that
|p2
k −nq2
k| < 2√n
for each k ≥1. As n ≥17, we have √n < n/4 and so
|p2
k −nq2
k| < n
2 .
It follows that LAR(p2
k, n) = p2
k −nq2
k, hence the the claim.
⊓⊔
1.5.6 Continued fractions and Diophantine equations
We mention now an interesting relation between the solution of linear Diophantine
equations and continued fractions, given by the following theorem.
Theorem 1.5.22. If Cn−1 = pn−1/qn−1 is the last but one convergent of a/b, with
a and b relatively prime positive integers, then
x = (−1)nqn−1,
y = (−1)npn−1
is a solution of the equation ax −by = 1.
The proof is not diﬃcult and is left as an exercise to the interested reader (see
Exercise A1.84); we give just an example of its application.
Example 1.5.23. Solve the Diophantine equation 214x −35y = 1.
It has already been shown that
214
35 = [6; 8, 1, 3],
its convergents being
C1 = 6
1,
C2 = 49
8 ,
C3 = 55
9 ,
C4 = 214
35 ,
so a solution of the equation is x = 9, y = 55.

62
1 A round-up on numbers
Appendix to Chapter 1
In this appendix we give several exercises, as we shall do for each chapter: ﬁrst those
of a theoretical nature, then more practical ones and ﬁnally a set of programming
exercises. Some exercises consist in a guide to the proof of some of the results which
have not been proved in the text. The exercises we regard as more diﬃcult are
marked by an asterisk.
Sometimes we have given multiple choice questions. We urge the reader to at-
tempt their solution without trying to exclude the less likely answers by following
a process of elimination or (even worse) by guessing at the right answer. Indeed, to
randomly ﬁnd the correct solution is quite useless and by far less worthwhile than
ﬁnding a wrong solution that has been reasoned through.
A1 Theoretical exercises
A1.1. Prove that complete induction (or strong induction) (CI) implies mathemat-
ical induction.
A1.2.* Prove that mathematical induction implies the following result.
Well-ordering principle (WOP). Any non-empty subset A of N contains a least
element, that is to say, there exists an element m ∈A such that for each a ∈A we
have m ≤a.
A1.3.* Prove that the well-ordering principle (WOP) implies complete induction
(or strong induction) (CI).
A1.4. Exactly one of the following claims is true. Which one?
(a) Complete induction implies mathematical induction, but not the other way
around.
(b) Mathematical induction is equivalent to complete induction, which in turn is
equivalent to the well-ordering principle.
(c) Mathematical induction is equivalent to complete induction which is a conse-
quence of, but is not equivalent to, the well-ordering principle.
(d) None of the above.
A1.5. We prove that every city is small, by induction on the number of its inhab-
itants. Clearly, if a city has just one inhabitant, it is small. Assume a city has n
inhabitants. If this city is small, it is still so even if we add one inhabitant. So we
deduce that all cities are small. Is everything right or is something amiss?
(a) Everything is right and it proves that mathematics cannot possibly be applied
to concrete questions.
(b) The basis of the induction is not right: if there is a single inhabitant, it is not a
city.
(c) The basis of the induction is right, but the proof of the inductive step depends
upon the deﬁnition of a small city.
(d) None of the above.

A1 Theoretical exercises
63
A1.6. Assume we have deﬁned a city to be small if it has less than 50,000 inhabi-
tants. Which one of the statements (a)–(d) of Exercise A1.5 is correct? (N.B. It is
not the same one as in Exercise A1.5!)
A1.7. We are going to show that all students in a course get the same mark in a
given written test, by proving it by induction on the number n of students. The basis
of the induction, for n = 1, is trivial. Assume each of the n students has completed
his test: we mark all the tests and put them in a stack. By induction hypothesis,
all the tests but the last one get the same mark. For the same reason, all the tests
but the ﬁrst one get the same mark. Then, all the tests under the ﬁrst one and on
the last one get the same mark, which is then the same for all the tests, including
the ﬁrst and last ones. We deduce from this that it is a waste of energy to correct
all the tests, it being enough to correct just one of them. What is wrong with this
reasoning?
(a) The basis of the induction is false.
(b) The inductive step is not true for n = 2.
(c) The ﬁnal deduction is not right: correcting the tests would be a waste of energy
even if the marks are diﬀerent.
(d) None of the above.
A1.8. By using the well-ordering principle, prove that there exist two integers qb
and (q + 1)b as needed in the proof of Proposition 1.3.1.
A1.9. Assume we know the initial values a0, a1, a2, . . ., an0−1, an0 of a sequence
{an} of elements from a set X; assume further that we are able to determine an,
for each n > n0, if the preceding terms am, with m < n, are known. Prove that it is
possible to determine an for each n ∈N.
A1.10. Assume we know the initial values a0, a1, a2, . . ., an0−1, an0 of a sequence
{an} of elements from a set X; assume further that we are able to determine an, for
each n > n0, if the term an−1 is known. Prove that it is possible to determine an
for each n ∈N.
The goal of the exercises from A1.11 to A1.25 is to recall some notions of com-
binatorial analysis.
A1.11. Given a non-empty set X, a permutation of X is deﬁned to be any bijection
of X in itself. Denote by In the set {1, . . . , n} of the ﬁrst n natural numbers. The
set of all bijections of In, n ≥1, in itself is denoted by the symbol Sn.
Given an element f of Sn, put f(1) = i1, . . . , f(n) = in. So we associate to f
the ordered n-tuple (i1, . . . , in) of elements of In, which is said to be the symbol of
the permutation f and is denoted by σ(f). In particular (1, . . . , n) is the symbol of
the identity map of In in itself, also called identity permutation.
Prove that the mapping
σ : f ∈Sn →σ(f) ∈In × · · · × In



n
is injective; hence a bijection is uniquely determined by its symbol. So we may
identify a permutation with its symbol, as we shall do in what follows.
A1.12. Let n ∈N be a natural number. Deﬁne the factorial of n as the number,
denoted by n!, equal to 1 if n = 0 or 1 and to n! = (n−1)!·n = n(n−1)(n−2) · · · 2·1

64
1 A round-up on numbers
if n > 1. Prove by induction that, for each integer n ≥1, the number of elements of
Sn is n!.
A1.13.* How many injective mappings A →B are there between two sets A and
B having n elements each? How many surjective mappings?
(a) The injective mappings are 2n, while the surjective ones are 2n + 1.
(b) All injective maps are surjective as well, and vice versa, and there are nn of
them.
(c) There are as many surjective mappings as injective ones, that is to say n!.
(d) None of the above.
A1.14. Let n and k be two positive integer numbers such that n ≥k. Recall the
deﬁnition of binomial coeﬃcient:

n
k

=
n!
k!(n −k)! = n(n −1)(n −2) · · · (n −k + 1)
k!
.
(1.50)
Notice that

n
k

=

n
n −k

.
Prove that

n + 1
k

=

n
k

+

n
k −1

.
(1.51)
From this, deduce that

n + 1
k + 1

=

n
k + 1

+

n
k

=

n
k + 1

+

n −1
k

+

n −1
k −1

=

n
k + 1

n −1
k

n −2
k −1

n −2
k −2

(1.52)
and so on.
A1.15.* Prove by induction on n that the binomial coeﬃcient
 n
m
	
is the number
of subsets of In having size equal to m.
A1.16. Prove the inequality

n + m −1
m

≥
 n
m
 m
.
A1.17. Prove that the subset of In × In consisting of the pairs (i, j) with 1 ≤i <
j < n has the same size as the set of subsets of In of size 2, that is to say, has size
n
2
	
= n(n −1)/2.
Prove that, on the other hand, the subset of In × In consisting of the pairs (i, j)
with 1 ≤i ≤j < n, has size
n+1
2
	
= n(n + 1)/2.
A1.18. Let a, b be two elements of a ﬁeld. Prove the binomial theorem:

A1 Theoretical exercises
65
(a + b)n = an + nan−1b +

n
2

an−2b2 +

n
3

an−3b3 + · · · + bn =
n

i=0

n
i

an−ibi.
(Hint: prove it by induction on n; it is convenient to use formula (1.51) for the
inductive step.)
A1.19.* Let A and B be two sets of size, respectively, n and m, and assume n ≤m.
How many injective functions A →B are there?
(a) m! −n!.
(b) (n + m)(n + m −1)(n + m −2) · · · (n + 1).
(c) m(m −1)(m −2) · · · (m −n + 1).
(d) None of the above.
Why did we assume n ≤m?
A1.20.* Let A and B be two sets of size, respectively, n and m. How many functions
A →B are there?
(a) mn.
(b) n · m.
(c) nm.
(d) None of the above.
A1.21. Let A be a set of size n and let m be a positive integer. Prove that the set
A × · · · × A



m
consisting of the ordered m–tuples of elements of A has size nm.
A1.22.* Recall that the power set P(X) of a set X is the set whose elements are
all the subsets of X, including X itself and the empty set. If X is a ﬁnite set of size
n, which is the size of P(X)?
(a) 2n −1.
(b) 2n.
(c) 2(2n−1 −1).
(d) None of the above.
A1.23. Prove that for each integer n ≥0 the following holds:
2n =

n
n

+

n
n −1

+ · · · +

n
1

+

n
0

.
A1.24.* Let K be a ﬁeld and let x1, . . . , xn be variables over K. We call monic mono-
mial of degree h in x1, . . . , xn an expression of the form xi1
1 · · · xin
n , with i1, . . . , in
non-negative integers such that i1 + · · · + in = h. Denote by s(n, h) the number of
such monomials.
Prove by induction on n that
s(n, h) =

n + h −1
h

.
A1.25.* Let a1, . . . , ar be distinct elements of a ﬁeld. Prove by induction the fol-
lowing generalisation of the binomial theorem

66
1 A round-up on numbers
(a1 + · · · + ar)n =
r

s=1

{ai1 ,...,ais }
ni1 +···+nis =n
n!
ni1! · · · nis! a
ni1
i1
· · · a
nis
is ,
where the internal sum is over all subsets {ai1, . . . , ais} of size s of {a1, . . . , ar}
and over all s-tuples consisting of positive integers ni1, . . . , nis and such that
ni1 + · · · + nis = n.
A1.26. Compare Equation (1.4) with the homogeneous linear recurrence relation
a′
n = bk−1a′
n−1 + bk−2a′
n−2 + · · · + b0a′
n−k.
(1.53)
Prove that if {yn} is a solution of the linear recurrence relation (1.4), then
every solution is of the form {yn + xn}, where {xn} is a solution of the associated
homogeneous linear recurrence relation (1.53).
A1.27. Let {an}n∈N be a sequence of elements of the ﬁeld K satisfying a linear
recurrence relation of the form
an+1 = ban + c,
with b, c ∈K. Prove that if a0, a1, a2 are known, it is possible to determine all the
elements of the sequence.
A1.28. Let A be the matrix (1.6). Prove Proposition 1.2.3 by induction on n.
A1.29. Given a line segment of length a, construct using ruler and compasses a line
segment of length b such that a/b is the golden ratio.
(Hint: if M is the midpoint of a side AB of a square having side-length a, the
the line segment joining M and a vertex of the square diﬀerent from A and B has
length r = (
√
5/2)a; the line segment of length b we are looking for has endpoints B
and the intersection of the circumference with centre M and radius r with the line
on which AB lies, on B’s side.)
The following exercises, from A1.30 to A1.35, are about Fibonacci numbers and
some of their properties.
A1.30. Prove that for each n and each k in N the following holds
fn+k = fkfn+1 + fk−1fn.
(1.54)
Deduce that fkn is a multiple of fn.
A1.31.* Prove by induction that each positive integer can be written as a sum of
ﬁnitely many distinct Fibonacci numbers.
A1.32. Prove, using Formula (1.10), that is to say, assuming not to know the re-
currence relation (1.5), that Fibonacci numbers are integers.
A1.33. Prove by induction that for each n ≥1 the following holds:
fn ≥
 1 +
√
5
2
n−2
(1.55)
and the inequality is strict if n ≥3.

A1 Theoretical exercises
67
A1.34. Prove that for each n we have
f2n = f1 + f3 + f5 + · · · + f2n−1.
A1.35. Prove that for each n we have
fn+1 =

h+k=n
h≥k≥0

h
k

.
(Hint: prove it by induction on n, using the recurrence relation (1.5) and Formula
(1.51).)
A1.36. Study the following variant of the division algorithm. Let a, b be integer
numbers, with b ̸= 0. Prove that there exist and are uniquely determined two integers
q, r with −|b|/2 < r ≤|b|/2 such that a = qb + r.
A1.37. Let a, b, c ∈Z be diﬀerent from zero. Prove that if GCD(a, b) = 1 and if
c | a then GCD(c, b) = 1 too.
A1.38. Let a, b ∈Z be diﬀerent from zero. Prove that if GCD(a, b) = 1 and if b | a
then b = ±1.
A1.39.* This exercise leads to a theoretical but non-constructive proof of the ex-
istence in Z of the greatest common divisor of two integers a and b at least one of
which is diﬀerent from zero. Let S = { xa + yb | x, y ∈Z, xa + yb > 0 } ⊆N. Prove
that this set has a least element d = x0a + y0b. Prove that d is the greatest common
divisor of a and b.
A1.40. Work out an algorithm to determine the greatest common divisor of two
integer numbers that uses the alternative division algorithm described in Exercise
A1.36 rather than the usual division algorithm.
A1.41. Let (¯x, ¯y) be an integer solution of the Equation (1.18). Prove that all
the pairs obtained by adding to (¯x, ¯y) an integer solution (x0, y0) of the associated
homogeneous equation ax + by = 0 are integer solutions of (1.18), and all of them
can be obtained in this way.
A1.42. Suppose we have to divide 123456 by 365, that is to say we have to ﬁnd the
integers q and r such that 123456 = q · 365 + r, with 0 ≤r < 365. We do not feel
like calculating them by hand, so we take a calculator and ﬁnd that the result of
the division of 123456 by 365 is 338.23561644. How may we determine q and r as
requested?
A1.43. Prove that in a Euclidean ring results analogous to those in Proposition
1.3.5 and in its Corollaries 1.3.6, 1.3.7, 1.3.8, and 1.3.9 hold.
A1.44. Let A be an integral domain and let a and b be non-zero elements of A.
Prove that if each of d and d′ is a greatest common divisor of a and b, they are
associated. Conversely, if d = GCD(a, b) and if d′ is associated to d, then d′ is a
GCD(a, b) too.
A1.45. Let A be an integral domain. Prove that the relation in A deﬁned by x ∼y
if and only if x is associated with y is an equivalence relation.

68
1 A round-up on numbers
A1.46. Let A be an integral domain. Prove that in A the ideals (x) and (y) coincide
if and only if x and y are associated. Deduce that for each ideal I of Z there exists
a unique positive integer x such that I = (x).
A1.47.* Let n, m be positive integers. Prove that the subset (n) ∩(m) of Z is an
ideal. Let D be the positive integer such that (D) = (n) ∩(m). Prove that D is the
unique positive integer that is a multiple both of n and m and such that, for each
positive multiple N of n and m, we have D | N. The integer D is said to be the
least common multiple of n and m and is denoted by lcm(n, m).
A1.48.* Let A be an integral domain. Notice that for each a ̸= 0, the map x ∈A →
ax ∈A is injective. Deduce that in a ﬁnite integral domain each non-zero element
has an inverse; hence, every ﬁnite integral domain is a ﬁeld.
Finally, deduce that a ﬁnite ring with unity is a ﬁeld if and only if it is an integral
domain.
A1.49.* Consider the subset G of the set C of complex numbers consisting of the
numbers, called Gaussian integers, of the form x + iy, with x, y ∈Z. Prove that G
is a subring of C.
Deﬁne in G the map
v : x + iy ∈G →x2 + y2 ∈N.
In other words, v(x + iy) is the norm ||x + iy|| of the complex number x + iy. Prove
that it satisﬁes property (1) of the deﬁnition of a Euclidean ring.
Let a, b ∈G, with b ̸= 0. Consider the complex number x + iy = a/b. Prove that
there exist integers x1, y1 such that |x −x1| ≤1/2 and |y −y1| ≤1/2.
Put x2 = x −x1, y2 = y −y1; hence
a = b(x1 + iy1) + b(x2 + iy2).
Notice that x1 + iy1 and b(x2 + iy2) are Gaussian integers. Moreover, notice that
v(b(x2 + iy2)) = v(b)||x2 + iy2|| ≤v(b)
2
< v(b).
Deduce that G is a Euclidean ring.
A1.50.* If α is a complex number, denote by Z[α] the smallest subring of C contain-
ing both Z and α. Prove that if α2 ∈Z, then Z[α] consists of all complex numbers
of the form x + αy, with x, y ∈Z.
A1.51. Prove that the ring A[x] of polynomials with coeﬃcients in an integral
domain A is an integral domain.
A1.52. Let f(x) be a polynomial with coeﬃcients in a ﬁeld K. Prove that there
exists a unique monic polynomial associated with f(x).
(Hint: divide f(x) by its leading coeﬃcient.)
A1.53. Let f1(x), f2(x) be polynomials with coeﬃcients in a ﬁeld K and let α ∈K.
Prove that if α is a root both of f1(x) and of f2(x) with multiplicity respectively
k1 and k2, then α is a root of the polynomial f1(x)f2(x) with multiplicity k1 + k2.
Let k the multiplicity of α as a root of the polynomial f1(x) + f2(x). Prove that
k ≥min{k1, k2} and that if k1 ̸= k2, then k = min{k1, k2}.
(Hint: use the factor theorem.)

A1 Theoretical exercises
69
A1.54.* Let K be a ﬁeld, c an element of K, and f(x) ∈K[x] a polynomial of degree
t > 0 such that f(c) ̸= 0. Prove that there exists exactly one polynomial g(x) ∈K[x]
of degree smaller than t such that (x −c) · g(x) −1 is divisible by f(x).
A1.55. Let f(x) be a polynomial with coeﬃcients in a ﬁeld K. If f(x) has degree
n, then f(x) admits at most n roots, counting each with its multiplicity.
(Hint: use the factor theorem and reason by induction.)
A1.56. Recall the following theorem, which shall be proved in Chapter 4 (see The-
orem 4.5.21):
Theorem A1.1 (Fundamental theorem of algebra).
Every non-zero polyno-
mial with coeﬃcients in C has at least one root in C.
Using this theorem, prove that a polynomial f(x) ∈C[x] of degree n has exactly
n roots, counted with multiplicity.
(Hint: use the factor theorem and reason by induction on n.)
A1.57. Let f(x) be a polynomial in R[x], of degree greater than 1. Let α ∈C be a
root of f(x) considered as a polynomial with complex coeﬃcients. Prove that among
the roots f(x) there is also ¯α, the complex conjugate of α.
A1.58. Prove that the derivative mapping D : K[x] →K[x], deﬁned on page 27, is
linear, that is to say, D(f(x)+g(x)) = D(f(x))+D(g(x)), for all pairs of polynomials
f(x), g(x) ∈K[x].
A1.59.* Prove that Leibniz’s law for the derivative of polynomials: D(f(x)·g(x)) =
D(f(x)) · g(x) + D(g(x)) · f(x) holds for all pairs of polynomials f(x), g(x) ∈K[x].
A1.60.* Prove that the derivative mapping is uniquely determined by its being
linear, by Leibniz’s law and by the fact that D(x) = 1.
A1.61. Prove that if f(x) is a polynomials of degree n, then the ith derivative
f(i)(x) of f is 0 for all i > n.
(Hint: prove the claim for f(x) = cxn, by induction on n).
A1.62. Prove Formula (1.25) on page 28.
A1.63. Let f(x) be a polynomial with coeﬃcients in Z and let s ∈Z. Prove that,
for each positive integer n, n! divides f (n)(s).
(Hint: prove the claim for monomials.)
The following exercises, from A1.64 to A1.69, will underline the importance of
Fibonacci numbers with respect to the Euclidean algorithm.
A1.64. Prove by induction that two consecutive Fibonacci numbers are relatively
prime.
A1.65.* Prove that the greatest common divisor of two Fibonacci numbers is again
a Fibonacci number. Precisely, GCD(fn, fm) = fd, where d = GCD(m, n).
A1.66.* Prove that fk divides fn if and only if k divides n.
A1.67. Which is the value of limn→∞(fn+1/fn) ?

70
1 A round-up on numbers
(a) 1.
(b) (1 +
√
5)/2.
(c)
√
5/2.
(d) None of the above.
A1.68.* Prove by induction on k that if rn is the ﬁrst remainder equal to zero in
the Euclidean algorithm applied to two numbers a and b, then
rn−k ≥fk,
where fk is the kth Fibonacci number.
A1.69.* Use the result found in Exercise A1.68 to prove that if b < fn, then, for each
a ≥b, the number D(a, b) of divisions that are necessary to get a zero remainder in
the Euclidean algorithm is smaller than n.
A1.70. Prove Lemma 1.4.5.
A1.71. Prove Proposition 1.4.6.
A1.72. Prove that
√
2 is not a rational number.
A1.73. Prove that the expression of a rational number as a continued fraction is
unique, if we assume that the last partial quotient is greater than 1.
A1.74. Let α > 1 be a real number. Prove that the nth convergent of the expression
of 1/α as a continued fraction is equal to the reciprocal of the (n −1)th convergent
of the expression of α as a continued fraction.
A1.75. Prove Formula (1.41) of page 50.
(Hint: reason by induction on k.)
A1.76. Prove Formula (1.44) of page 51.
A1.77. Prove by induction Formula (1.45) of page 51.
A1.78. Prove Lemma 1.5.11 of page 53.
A1.79. Fill in the missing details of the proof of Theorem 1.5.13 of page 55.
(Hint: denoting, as usual, by Cn = pn/qn the convergents of the continued
fraction [a0; a1, . . . , an, . . .], prove that, for each positive integer n, the following
holds:
α = αn+1pn + pn−1
αn+1qn + qn−1 .
(1.56)
Using Equation (1.42), deduce that
α −Cn =
(−1)n−1
qn(αn+1qn + qn−1)
and so that limn→∞Cn = α.)
A1.80. Prove that, if n is a non-square positive integer, then √n is not a rational
number.
A1.81. Prove that each root α of a quadratic equation with integer coeﬃcients is of
the form α = a + b
√
d, where d is a positive integer and a, b are rational. Determine
a, b and d as functions of the coeﬃcients of the quadratic equation.

A1 Theoretical exercises
71
(Hint: write down the quadratic formula for the equation.)
Conversely, prove that if α = a + b
√
d, where d is a positive integer and a, b are
rational, then α is a quadratic number.
A1.82. Prove that, if α is a quadratic number and a, b, c, d are rational numbers
such that cα + d ̸= 0, then (aα + b)/(cα + d) is a quadratic number too.
A1.83. Recall that if α is a quadratic number, we can consider its conjugate α′.
Prove that α = α′ if and only if α is a rational number. Moreover, if α and β are
quadratic numbers, we have
(1) (α + β)′ = α′ + β′;
(2) (α −β)′ = α′ −β′;
(3) (αβ)′ = α′β′;
(4) (1/α)′ = 1/α′.
A1.84. Prove Theorem 1.5.22 of page 61.
A1.85. Prove that, for each non-square positive integer n, the number √n + [√n]
is reduced.
A1.86.* Let α be an irrational number and let α = [a1; a2, a3, . . . , an, . . .] be its
expression as a continued fraction, and let Cn = pn/qn be its convergents. If we take
two consecutive convergents Cn = pn/qn and Cn+1 = pn+1/qn+1, at least one, say
Ci, satisﬁes the relation
|α −Ci| <
1
2q2
i
.
The next exercises, from A1.87 to A1.94, lead to the proof of the theorem of
Lagrange 1.5.15 and to the description of an algorithm to compute the expression
of an irrational number, and in particular of a quadratic irrational number, as a
continued fraction.
A1.87.* Let α = [a1; a2, . . . , at]. Notice that α = [a1; a2, . . . , at, α]. Using Equations
(1.41) deduce that
α = αpt + pt−1
αqt + qt−1
where Cn = pn/qn are the convergents of [a1; a2, . . . , at]. Deduce that α is a
quadratic number satisfying the equation
x2qt + x(qt−1 −pt) −pt−1 = 0.
A1.88.* Let α = [a1; a2, . . . , am, am+1, . . . , am+t] be a periodic continued fraction.
Put β = [am+1; am+2, . . . , am+t], which is a quadratic number by the result of the
previous exercise. Notice that α = [a1; a2, . . . , am, β]. Mimicking the argument of the
previous exercise and keeping in mind Exercise A1.82 prove that α is a quadratic
number.
A1.89.* Prove that an irrational quadratic number α may be written as α =
(p +
√
d)/q, where p, q, d are integers, q ̸= 0, d > 0 is not a perfect square, and
q divides d −p2.
A1.90.* Let α be an irrational quadratic number; so, by the previous exercise, we
may write

72
1 A round-up on numbers
α = p0 +
√
d
q0
,
where p0, q0, d are integers, q0 ̸= 0, d > 0 is not a perfect square, and q0 divides
d −p2
0.
Deﬁne recursively
αn = pn +
√
d
qn
,
an = [αn],
pn+1 = anqn −pn,
qn+1 = d −p2
n+1
qn
.
Prove that for each positive integer n the numbers pn, qn are integers, qn ̸= 0 and
qn divides d −p2
n.
A1.91.* Continuing the previous exercise, consider the continued fraction [a0; a1,
. . . , an, . . .], and denote as usual by Cn = pn/qn the convergents. Using Theorem
1.5.13, prove that α = [a0; a1, . . . , an, . . .].
A1.92.* Continuing the previous exercises, notice that, for each positive integer
n we have α = [a0; a1, . . . , an, αn+1], and so Equation (1.56). Conjugating all the
terms in it (use here Exercise A1.83), verify that
α′
n = −qn−1
qn
α′ −Cn−1
α′ −Cn .
Keeping in mind that limn→∞Cn = α, deduce that there exists an integer number
m such that, for n > m, we have α′
n < 0.
A1.93.* Still continuing the previous exercises, prove that there exists an integer m
such that, for n > m, we have qn > 0. Keeping in mind that qnqn+1 = d−p2
n+1 < d,
deduce that for each n > m we have qn < d.
Analogously, notice that for each n > m one has p2
n+1 = d−qnqn+1 < d. Deduce
that there are inﬁnitely many integers i, j such that (pi, qi) = (pj, qj); hence it
follows that [a0; a1, . . . , an, αn+1] is periodic.
A1.94.* Assume now that α is an irrational reduced quadratic number. Using again
the notation of the previous exercises, prove by induction that for each positive
integer n one has −1 < α′
n < 0. Deduce that an = [−1/α′
n+1].
Using what has been proved in the previous exercises, we know that there exist
integer numbers i, j, with j > i, such that αi = αj, and so also ai−1 = aj−1. Deduce
that αi−1 = αj−1, and so α = α0 = αj−i. Noticing that
α = [a0; a1, . . . , aj−i−1, αj−i] = [a0; a1, . . . , aj−i−1, α],
deduce that [a0; a1, . . . , an, . . .] is purely periodic.
A1.95.* Assume now that α = [a1; a2, . . . , at] with Cn = pn/qn convergents of
the continued fraction. Put β = [at; at−1, . . . , a1], and denote by C′
n = p′
n/q′
n the
convergents of the latter continued fraction. Using Equation (1.41), prove that
C′
t =
pt
pt−1 ,
C′
t−1 =
qt
qt−1 .
Deduce that
pt = p′
t,
q′
t = pt−1,
p′
t−1 = qt,
q′
t−1 = qt−1.
Keeping in mind Exercise A1.87, prove that α and −1/β are solutions of the same
equation with integer coeﬃcients, and so they are conjugate numbers. Notice that,
as at > 0, one has β > 1. Deduce that α is reduced.

B1 Computational exercises
73
B1 Computational exercises
B1.1. For which natural numbers n does the inequality n < 2n hold?
(a) Every even n.
(b) Every n > 0.
(c) Every n > 1.
(d) None of the above.
Prove by induction the correct claim.
B1.2. Let S(n) be the sum of the ﬁrst n odd natural numbers. Which of the following
is a recurrence relation satisﬁed by S(n)?
(a) S(n + 1) = S(n) + 2n + 1.
(b) S(n + 1) = S(n) + n + 1.
(c) S(n + 1) = S(n) + 2n −1.
(d) None of the above.
B1.3. Let S(n) be the sum of the ﬁrst n odd natural numbers. Which is the closed
formula to compute S(n)?
(a) S(n) = n(n + 1)/2.
(b) S(n) = n2 −n + 1.
(c) S(n) = n2.
(d) None of the above.
Prove by induction the correct formula.
B1.4. Let S(n) be the sum of the ﬁrst n even positive numbers. Which of the
following is a recurrence relation satisﬁed by S(n)?
(a) S(n + 1) = S(n) + n + 2.
(b) S(n + 1) = S(n) + 2n.
(c) S(n + 1) = S(n) + 2n + 2.
(d) None of the above.
B1.5. Let S(n) be the sum of the ﬁrst n even positive numbers. Which is the closed
formula to compute S(n)?
(a) S(n) = n(n + 1)/2.
(b) S(n) = n2 + 1.
(c) S(n) = n(n + 1).
(d) None of the above.
It is recommended to prove it by induction on n.
B1.6. For each natural number n, which is the value of
n

k=0
(4k + 1) ?
(a) n2 + 4n + 1.
(b) (2n + 1)(n + 1).
(c) 3n2 + 2n + 1.

74
1 A round-up on numbers
(d) None of the above.
Prove by induction the correct formula.
B1.7. For each natural number n, which is the value of the sum of the ﬁrst n squared
numbers
n

k=1
k2 = 12 + 22 + 32 + · · · + n2 ?
(a) (n + 1)(2n + 1)/2.
(b) (n + 1)(n + 2)(n + 3)/6.
(c) n(n + 1)(2n + 1)/6.
(d) None of the above.
Prove by induction the correct formula.
B1.8. For each natural number n, which is the value of the sum of the ﬁrst n cubed
numbers
n

k=1
k3 = 13 + 23 + 33 + · · · + n3 ?
(a) (n4 + 2n3 + n2)/4.
(b) (n4 + 18n3 −19n2 + 12n)/12.
(c) (6n3 −17n2 + 25n −12)/2.
(d) None of the above.
B1.9. For each natural number n, which is the value of the sum of the ﬁrst n cubed
even numbers
n

k=1
(2k)3 = 23 + 43 + · · · + (2n)3 ?
(a) 2n(n + 1)(n + 2)(n + 3).
(b) n(n + 1)(n + 2)(n + 3)/3.
(c) 2n2(n + 1)2.
(d) None of the above.
Prove by induction the correct formula.
B1.10. Which is the value of
n−1

k=0
2 · 3k ?
(a) 3n −1.
(b) 3(3n −1)/2.
(c) 3n+1 −1.
(d) None of the above.
Prove by induction the correct formula.
B1.11. Which is the value of
n

k=0
5 · 9k ?
(a) 4(9n+1 −1)/5.

B1 Computational exercises
75
(b) 5(9n+1 −1)/8.
(c) 5(9n −1)/4.
(d) None of the above.
Prove by induction the correct formula.
B1.12. Find the eigenvectors of the matrix A deﬁned in Equation (1.6). In partic-
ular, verify that (1, λ1) and (1, λ2) are eigenvectors with corresponding eigenvalues
λ1 and λ2, as deﬁned by formula (1.7) on page 9.
B1.13. Let C and C−1 be the matrices of formula (1.9), D the matrix (1.8) and A
the matrix (1.6). Verify that C · C−1 = C−1 · C = I, and that C · D · C−1 = A.
B1.14. Which is the solution of the geometric progression
an = r · an−1,
a0 = k,
where r and k are ﬁxed integers?
(a) an = krn, for each n > 0.
(b) an = rkn, for each n > 0.
(c) an = nkr, for each n > 0.
(d) None of the above.
B1.15. Assume the world population increases by 3% each year. Which is the re-
currence relation giving world population P(n)?
(a) P(n) = P(n −1) · 3/100.
(b) P(n) = P(n −1) · 103/100.
(c) P(n) = P(n −1) + 3/100.
(d) None of the above.
B1.16. Assume that in 2000 the world population were of 5 billion people, and that
it evolves according to the recurrence relation given in Exercise B1.15. How many
billions people will live in the world in 2024?
(a) About 50 billion.
(b) About 20 billion.
(c) About 10 billion.
(d) None of the above.
B1.17. Give a closed formula for the beetle population of Example 1.2.8.
B1.18. Consider Example 1.2.8 on page 11. Assume that in a given year there were
120 newborn beetles and 20 two-year beetles. How many beetles will live 10 years
later?
(a) 180.
(b) 140.
(c) 120 (60 newborn and 60 one-year beetles).
(d) 120 (all newborn).

76
1 A round-up on numbers
B1.19. Give a closed formula for the population of Liguria, as described in Example
1.2.9.
B1.20. Consider Example 1.2.9. Assume that in a given year 5 million people live
in Liguria and 10 million outside. How many inhabitants will Liguria have 30 years
later?
(a) 20 million.
(b) 10 million.
(c) 7 million.
(d) None of the above.
B1.21. Consider the regions a plane is divided into by n lines in generic position
(that is to say, no two lines are parallel and no three lines meet in a point). How
many regions are there?
(a) n2 + 1.
(b) n2 + n −1.
(c) n(n + 1)/2 + 1.
(d) None of the above.
B1.22. Consider the regions a plane is divided into by n circles in generic position
(that is to say, no three circles meet in a point and any two circles meet in exactly
two points). How many regions are there?
(a) (n3 −5n2 + 14n −8)/2.
(b) (n2 + 3n −2)/2.
(c) (n3 −3n2 + 20n −4)/6.
(d) None of the above.
B1.23. Prove that it is possible to colour the regions into which an arbitrary number
of lines divides the plane (even when some of the lines are not in generic position)
with just two colours. Notice that by colouring we mean to assign colours to the
regions in such a way that neighbouring regions (that is, with a side in common)
always have distinct colours.
B1.24. Mark has opened a bank account for which there are no charges and yielding
a yearly 4% interest which is computed and paid to his account every third month.
Suppose Mark deposited a certain amount of money when he opened the account
and after that he neither withdrew nor deposited money from the account. Which
is the recurrence relation determining the amount of money S(n) Mark has in his
account after n years?
(a) S(n) = S(n −1) · (101/100)4.
(b) S(n) = S(n −1) · 104/100.
(c) S(n) = S(n −1) + 4/100.
(d) None of the above.
B1.25. Consider Mark’s bank account as in Exercise B1.24. Suppose now that Mark
deposited 5,000 euros when he opened the account. How much money will Mark have
in his account 20 years later?
(a) About 15,000 euros.

B1 Computational exercises
77
(b) About 11,000 euros.
(c) About 9,000 euros.
(d) None of the above.
B1.26. Compute the ﬁrst 10 terms a1, . . . , a10 of each of the following recurrence
relations, always assuming the initial value is a0 = 1:
an+1 = an + 3;
an+1 = 3an + 1;
an+1 = 2an −n;
an+1 = a2
n −an + 2.
B1.27. Compute the terms a2, . . . , a10 of each of the following recurrence relations,
always assuming the initial values are a0 = a1 = 1:
an+2 = 3an+1 −an;
an+2 = an+1 + an + 1;
an+2 = −an+1 + 2an + n2;
an+2 = 2an+1 · an.
B1.28. Which is the solution of the recurrence relation
an+2 = an+1 + 2an
with initial values a0 = 2 and a1 = 7?
(a) an = 3 · 2n −(−1)n.
(b) an = 2n −1.
(c) an = 2n −3 · (−1)n.
(d) None of the above.
B1.29. Which is the solution of the recurrence relation
an = 2an−1 + n + 5
with initial value a0 = 4?
(a) an = 11 · 2n −n −7.
(b) an = 9 · 2n −n −5.
(c) an = 11 · 2n −n + 7.
(d) None of the above.
(Hint: ﬁrst, ﬁnd a solution of the given recurrence relation, ignoring the initial
condition, in the form αn + β, where α and β are constants, then try to solve the
associated homogeneous recurrence relation.)
B1.30. Which is the solution of the recurrence relation
an+1 = 2an
with initial value a0 = 3?
(a) an = 3 · 2n.
(b) an = 2n.
(c) an = 2n + 3.
(d) None of the above.

78
1 A round-up on numbers
B1.31. Which is the solution of the recurrence relation
an = 2an−1 + 2n
with initial value a0 = 2?
(a) an = n2n.
(b) an = 2n + 3n.
(c) an = (1 + n)2n.
(d) None of the above.
(Hint: ﬁrst, ﬁnd a solution of the given recurrence relation, ignoring the ini-
tial condition, in the form nαn, where α is a constant, then solve the associated
homogeneous recurrence relation.)
B1.32. How many moves must the priests of Brahma’s temple perform in order to
transfer the tower of Hanoi consisting of 64 discs (see Example 1.2.10)?
(a) 18,446,744,073,709,551,615.
(b) 18,446,744,073,709,541,615.
(c) 18,446,744,073,709,541,613.
(d) None of the above.
B1.33. Assuming that it takes to the priests of Brahma’s temple 30 seconds to
perform a move (the discs are very heavy!) and that they started in 1999 BCE, in
how many years should the end of the world arrive?
(a) About 1 · 1012.
(b) About 1 · 1013.
(c) About 2 · 1013.
(d) None of the above.
B1.34. Which is the greatest common divisor of 491 and 245?
(a) 1.
(b) 7.
(c) 13.
(d) None of the above.
B1.35. How many steps does the Euclidean algorithm require to compute GCD
(491, 245)?
(a) 1.
(b) 2.
(c) 3.
(d) None of the above.
B1.36. How many steps does the Euclidean algorithm require to compute GCD
(3072, 165)?
(a) 7.
(b) 8.
(c) 9.
(d) None of the above.

B1 Computational exercises
79
B1.37. Compute GCD(34567, 457) using the algorithm described in Exercise A1.40
and verify that it requires just ﬁve steps, while the one based on the usual division
algorithm requires eight steps (see Example 2.5.5 on page 100).
B1.38. Which are the coeﬃcients of 491 and of 245 in B´ezout’s identity for
GCD(491, 245), obtained using the Euclidean algorithm?
(a) 1 e −2.
(b) −1 e 2.
(c) −244 e 489.
(d) None of the above.
B1.39. Which is the greatest common divisor of 28762 and 1515?
(a) 3.
(b) 7.
(c) 1.
(d) None of the above.
B1.40. How many steps of the Euclidean algorithm are required to compute
GCD(28762, 1515)?
(a) 3.
(b) 5.
(c) 7.
(d) None of the above.
B1.41. Which are the coeﬃcients of 28762 and of 1515 in B´ezout’s identity for
GCD(28762, 1515), obtained using the Euclidean algorithm?
(a) −527 e 10005.
(b) −1 e 2.
(c) −244 e 489.
(d) None of the above.
B1.42. Determine all integers x, y satisfying the equation
92x + 28y = 180.
(a) The equation has no integer solutions.
(b) (−135 −7t, 450 + 23t) for each integer t.
(c) (−135 + 7t, 450 + 23t) for each integer t.
(d) None of the above.
B1.43. Determine all integers x, y satisfying the equation
482x + 20y = 35.
(a) The equation has no integer solutions.
(b) (12 −7t, −33 + 5t) for each integer t.
(c) (15 −7t, −31 + 5t) for each integer t.
(d) None of the above.

80
1 A round-up on numbers
B1.44. Determine all integers x, y satisfying the equation
1859x + 2057y = 143.
(a) The equation has no integer solutions.
(b) (37 + 187t, −41 −169t) for each integer t.
(c) (−676 + 187t, 611 −169t) for each integer t.
(d) None of the above.
B1.45. Which sequence does the polynomial x7 −2x3 + x −1 correspond to?
(a) { 1, 0, 0, −2, 0, 1, −1, 0, . . . }.
(b) { 1, 0, 0, 0, −2, 0, 1, −1, 0, . . . }.
(c) { −1, 1, 0, −2, 0, 0, 0, 1, 0, . . . }.
(d) None of the above.
B1.46. Which sequence does the product of the polynomials x2 −1 and x2 + 1
correspond to?
(a) { 1, 0, 2, 0, −1, 0, . . . }.
(b) { 1, 0, 1, 0, −1, 0, . . . }.
(c) { −1, 0, 0, 0, 1, 0, . . . }.
(d) None of the above.
B1.47. Is it true that the polynomial x2 −3x4 −2x + 1 + x3 ∈Q[x] is monic?
(a) Yes, because its ﬁrst coeﬃcient is 1.
(b) Yes, because its leading coeﬃcient is 1.
(c) No.
(d) None of the above.
B1.48. Which are the quotient and the remainder of the division in Q[x] of the
polynomial x4 −2x3 −2x −1 by 2x3 −x −1?
(a) The quotient is x/2 and the remainder is x2/2 −5x/2 −2.
(b) The quotient is x/2 −1 and the remainder is x2/2 −5x/2 −2.
(c) The quotient is x/2 −1 and the remainder is x2/2 −3x/2 −1.
(d) The quotient is x/2 and the remainder is x2/2 −3x/2 −1.
B1.49. Is it true that −x −1 is the greatest common divisor of the polynomials
2x3 −x + 1 and x2 + 2x + 1 in Q[x]?
(a) No, because the greatest common divisor of those polynomials is 1.
(b) No, because −x −1 does not divide 2x3 −x + 1.
(c) Yes.
(d) None of the above.
B1.50. Is it true that 2x + 2 is a greatest common divisor of the polynomials
2x4 + x −1 and x2 −1 in Q[x]?
(a) No, because the greatest common divisor of those polynomials is 1.
(b) No, because it is not a monic polynomial.
(c) Yes.
(d) None of the above.

B1 Computational exercises
81
B1.51. Using the Euclidean algorithm, how many steps are necessary to ﬁnd the
greatest common divisor of the polynomials 2x3 −x + 1 and x2 + 2x + 1 in Q[x]?
(Remember that the last step is the one in which the zero remainder is found.)
(a) 1.
(b) 2.
(c) 3.
(d) 4.
B1.52. Do two polynomials f(x) and g(x) in Q[x] such that
(x2 + 2x + 1)f(x) + (2x3 −x + 1)g(x) = 4x + 4
exist?
(a) No, they do not exist, because the GCD of x2 +2x+1 and 2x3 −x+1 is −x−1.
(b) No, because the GCD of x2 + 2x + 1 and 2x3 −x + 1 is 1.
(c) Yes, they have to exist, but there is no way to compute them.
(d) None of the above.
B1.53. Which is the derivative of 3x3 −5x5 + 123 −2x4 in Q[x]?
(a) 9x2 + 5x4 −8x3.
(b) 9x2 −5x4 −8x3.
(c) 3x2 −5x4 −8x3.
(d) None of the above.
B1.54. Let f(x) = 15/7+3x−24/13x3. Which polynomial is a primitive polynomial
with integer coeﬃcients, associated to f(x)?
(a) 195 + 293x −168x3.
(b) 195 + 271x −168x3.
(c) 56x3 −91x −65.
(d) None of the above.
B1.55.* Consider the Euclidean ring G described in Exercise A1.49. Find a greatest
common divisor of 2 and 1 −5i in G.
B1.56. Verify formula (1.30) carrying out the same multiplication in base 10.
B1.57. Consider the numbers 100100101110111 and 1101 in base 2. Carry out the
division in base 2 step by step and ﬁnd the quotient and the remainder.
B1.58. Consider a number system in base b where b = n2 + 1, with n ∈N. Write in
base b the following numbers:
n2 + 2,
n2 + 2n,
(n2 + 2)2,
n4,
n2(n2 + 2)2.
B1.59. Convert the number (2345)10 to base 3.
(a) 10012212.
(b) 10111212.
(c) 10102212.
(d) None of the above.

82
1 A round-up on numbers
B1.60. Convert (234)10 to base 8.
(a) 352.
(b) 344.
(c) 350.
(d) None of the above.
B1.61. Convert (456)8 to base 2.
(a) 1001101110.
(b) 1001010110.
(c) 100101110.
(d) None of the above.
B1.62. Which are the sum and the product of 10010111 e 11101 in base 2?
(a) 10110100, 1001000011011.
(b) 11110100, 1010100011011.
(c) 11110100, 1000100011011.
(d) None of the above.
B1.63. Determine the sum and the product of 12323 e 321 in base 4.
(a) 12310, 12023203.
(b) 13310, 12023203.
(c) 13310, 12022203.
(d) None of the above.
B1.64. Consider base 21 integer numbers, where the digits are denoted by the 21
alphabet letters A, B, C, D, E, F, G, H, I, L, M, N, O, P, Q, R, S, T, U, V, Z, with A =
1, B = 2, . . ., V = 20 e Z = 0. Which are the sum and the product of QUI and
QUO?
(a) ANTA, LAEQUA.
(b) ALTA, NAQTCN.
(c) ALTA, NAPTCN.
(d) ANTA, NAQTCN.
B1.65. Consider base 21 numbers, where the digits are denoted by the 21 alphabet
letters A, B, C, D, E, F, G, H, I, L, M, N, O, P, Q, R, S, T, U, V, Z, with A = 1, B = 2,
. . ., V = 20 e Z = 0. Which are the sum and the diﬀerence of CASA e CANE?
(a) FCHF, ES.
(b) FBHF, DS.
(c) FCHF, DS.
(d) FBHF, ES.

B1 Computational exercises
83
It is advisable to write down a table with correspondence between alphabet
letters and integer numbers in {0, 1, . . . , 20}.
B1.66. Determine the base 10 fraction corresponding to the number 0.40.
B1.67. Determine the base 10 fraction corresponding to the number 55.35.
B1.68. Determine the base 2 fraction corresponding to the number 0.101.
B1.69. Determine the base 2 fraction corresponding to the number 101.101101.
B1.70. Determine the base 7 fraction corresponding to the number 0.40.
B1.71. Determine the base 7 fraction corresponding to the number 55.35.
B1.72. Write the fraction 7/3 as a recurring number in base 10.
B1.73. Write the fraction 31/5 as a recurring number in base 7.
B1.74. Write the fraction 1011/11 as a recurring number in base 2.
B1.75. Which is the expression of 113/90 as a continued fraction?
(a) [1; 3, 1, 2].
(b) [1; 3, 1, 10].
(c) [1; 3, 10, 2].
(d) None of the above.
B1.76. Which rational number does the continued fraction [1; 3, 1, 4, 1, 1, 2] repre-
sent?
(a) 135/107.
(b) 133/107.
(c) 133/105.
(d) None of the above.
B1.77. How many terms are there in the expression of 350/211 as a continued
fraction? (Assume that the last term is not 1.)
(a) 6 terms.
(b) 5 terms.
(c) 4 terms.
(d) None of the above.
B1.78. Prove that
√
3 = [1; 1, 2].
B1.79. Prove that
√
5 = [2, 4].
B1.80. Prove that the expression of the golden ratio as a continued fraction is [1; 1].
B1.81. Find the positive number corresponding to the periodic simple continued
fraction [4; 1, 3].
B1.82. Which is the expression of
√
27 as a continued fraction?
(a) [5; 5].
(b) [5; 6].
(c) [5; 10].
(d) None of the above.

84
1 A round-up on numbers
C1 Programming exercises
C1.1. Write a program that computes the factorial of a positive integer number.
C1.2. Write a program that computes the binomial coeﬃcients.
C1.3. Consider the following recurrence relation:
an+k = b1an+k−1 + b2an+k−2 + · · · + bkan + d(n),
where bis are constants, d(n) is an arbitrary function of n, and the initial values are
a1 = α1, a2 = α2, . . . , ar = αr.
Write a program that computes the term an.
C1.4. Write a program that computes Fibonacci numbers.
C1.5. Write a program that determines whether a given integer n is a Fibonacci
number. Use this program to verify Exercises A1.30, A1.66, and A1.33.
C1.6. Write a program that computes the greatest common divisor of two integers
a and b using the Euclidean algorithm.
C1.7. Write a program that computes the greatest common divisor of two integers
a and b using the algorithm described in Exercise A1.40.
C1.8. Write a program that computes a B´ezout’s identity for two integer numbers
a and b, that is to say, that expresses the greatest common divisor of two numbers
a and b in the form αa + βb for suitable coeﬃcients α and β in Z, by using the
Euclidean algorithm.
C1.9. Write a program that computes the greatest common divisor of two Fibonacci
numbers, and use this program to verify Exercises A1.64 and A1.65.
C1.10. Write a program that expresses each integer n as a sum of distinct Fibonacci
numbers (see Exercise A1.31).
C1.11. Write a program that computes, given two integers a and b, with a ≥b, the
number of divisions occurring during the execution of the Euclidean algorithm (see
Exercise A1.69).
C1.12. Write a program that carries out the division of two given polynomials,
computing the quotient polynomial and the remainder,
C1.13. Write a program that computes the greatest common divisor of two poly-
nomials f(x) and g(x) over a ﬁeld using the Euclidean algorithm.
C1.14. Write a program that computes a B´ezout’s identity d(x) = f(x)h(x) +
g(x)k(x) for two polynomials f(x) and g(x), where d(x) is their greatest common
divisor.
C1.15. Write a program that computes the nth derivative of a given polynomial.
C1.16. Write a program that converts the base 10 expression of integer numbers to
an arbitrary base b > 1 and vice versa.

C1 Programming exercises
85
C1.17. Write a program that, for any fraction, determines its decimal representa-
tion, ﬁnding its recurring and non-recurring digits.
C1.18. Write a program that computes the expression of an arbitrary rational num-
ber as a continued fraction.
C1.19. Write a program that computes the convergents of an inﬁnite continued
fraction, up to an assigned approximation of the irrational number represented by
the continued fraction.
C1.20. Write a program that computes the expression of √n as a continued fraction,
for a positive integer n.

2
Computational complexity
2.1 The idea of computational complexity
In Chapter 1 we have recalled some basic notions about natural, integer, ra-
tional numbers, and about the operations on numbers. The need to solve
concrete problems leads, as we have discussed in § 1.2, to devise mathematical
models; they in turn pose the question of developing computing procedures,
which may be very complex, but that in any case result in the solution of the
studied problem in ﬁnitely many steps. Such a procedure is called an algo-
rithm, from the name of the Arab-language mathematician and astronomer
al-Khowarizmi, who lived in the 9th century. This is a good moment to pose
the main question: which is the cost of an algorithm, in terms of eﬀort and
time needed to execute its steps from the beginning to the end of the necessary
operations? For instance, if we use a computer to perform the computations,
which is the cost of a given algorithm, in terms of computation time and
programming diﬃculty? Is there a mathematically sound way to distinguish
good algorithms, those requiring little time and little programming eﬀort, from
those requiring too much time, in relative or absolute terms, for their execu-
tion?
As we have said, an algorithm is just a ﬁnite sequence of elementary opera-
tions. Thus, in order to answer the above questions, that is to say, to determine
the computational complexity of a given algorithm, it is necessary to calculate
with precision the number of basic operations composing the algorithm. Mul-
tiplying this number by the time taken to program or perform a single basic
operation with the available computing devices, we obtain a measure of the
total time needed to perform the calculations the algorithm consists of. Notice
that, while this measure of complexity is crucially aﬀected by the character-
istics of the computing devices we are using, the computational complexity is
an intrinsic property of the algorithm. In any case, the computation time of
an algorithm is proportional to its computational complexity, and the ratio is
determined by the characteristics of the computing devices.

88
2 Computational complexity
We shall only deal with computational complexity rather than with actual
computation time, because the former only requires mathematical notions,
while the latter concerns computer science. So in what follows when we shall
refer to time, we shall only mean computational time.
The importance of the notion of computational complexity is obvious. For
instance, it allows us to distinguish between:
•
algorithms than can be executed in a reasonable time with the available
computing devices;
•
algorithms that cannot be possibly executed in a reasonable time with
the available computing devices, for instance by hand, but than can be
executed in a reasonable time using more advanced instruments, of which
we may estimate the power, i.e. it is possible to evaluate the time they
need to perform a single basic operation;
•
algorithms only theoretically feasible, because in practice their execution
requires a time either unconditionally too long or exceeding the time at
our disposal, independently of the available computing resources.
The unit which will be used to measure the complexity of an algorithm
is the bit operation which, basically, corresponds to one of the elementary
operations the algorithm consists of. Let us give this notion in detail.
We shall limit our treatment to algorithms operating on integer numbers.
To ﬁx the ideas, when performing the operations prescribed by an algorithm
we shall use base 2 integer numbers. The reason for doing so lies in the fact
that this is what happens when operates with a computer, and we assume
that most of the calculations that follow will be performed using a computer.
Moreover, we shall soon see that this choice does not modify the complexity
of the algorithms, in a sense that will be made precise.
We shall write a number n as n = (ak−1 . . . a0)2, or simply as
n = ak−1ak−2 . . . a0
if n = k−1
i=0 2i ai, where ai = 0, 1, and i = 0, . . . , k −1. The terms ai are
called binary digits.
By a bit operation we mean one of the following elementary operations:
(1) addition of two binary digits (e.g. 0 + 1);
(2) subtraction of two binary digits (e.g. 1 −0);
(3) multiplication of two binary digits (e.g. 1 · 1);
(4) division of a two binary digit integer by 1;
(5) left translation by one place, that is multiplication by 2 (for instance 111
becomes 1110), and right translation by one place, that is division by 2.
Clearly, each of the four basic arithmetic operations on integers can be
expressed by means of a sequence of bit operations. Thus, every algorithm
can be expressed by means of a sequence of bit operations.

2.2 The symbol O
89
Deﬁnition 2.1.1. The computational complexity of an algorithm operating on
integer numbers is given by the number of bit operations necessary to execute
it.
Notice that the computational complexity of an algorithm is not a num-
ber, but a function. Indeed, it depends in general on the integer numbers on
which the algorithm operates. In other words, it is to be expected that the
larger the integers on which the algorithm operates, the larger the number
of bit operations necessary to execute the algorithm, and so the larger its
complexity. We shall come back shortly, in § 2.3, on this fundamental notion
of the dependence of an algorithm on the numbers on which it operates.
We are not usually interested in a precise determination of the complexity
of an algorithm, but in a reasonable estimate from above. This is, in fact,
what we need in order to evaluate the time necessary for the execution of the
algorithm. To express this estimate in an eﬃcient way, that is to say with-
out unnecessary details or redundancy, it is common to use the O notation,
commonly said Big-Oh notation, introduced by Paul Bachmann in 1894. It is
described in next section.
One further note of caution: so far we deﬁned the notion of computational
complexity just for algorithms operating on integer numbers. We shall later
extend this notion to algorithms operating on other objects, for instance on
polynomials or on elements of a ﬁeld (see § 2.5.3, § 5.1.14).
2.2 The symbol O
The importance of the symbol O lies in the fact that it describes in a very
simple and explicit way, as we shall soon make clear, the asymptotic behaviour
of a given function.
Deﬁnition 2.2.1. Let f and g be two positive-valued functions, deﬁned on a
subset S of R containing N. We shall say that f is dominated by g (or that
g dominates f, or that g has higher order than f) if there exist constants k
and c in R such that
f(x) ≤k · g(x),
for all x ∈S, with x > c.
(2.1)
We shall denote by O(g) the set of the functions dominated by g, that is
those increasing not faster than g. If f ∈O(g), we say that the function f
is in the class O(g) and that we have given a O-estimate for the function f
by means of the reference function g. Notice that, if f ∈O(g) and g ∈O(h),
then f ∈O(h) (see Exercise A2.1). If f ∈O(g) and g ∈O(f), we shall say
that f and g have the same order.
When we write f ∈O(g), one does not usually try to determine the least
value of the constant k for which Equation (2.1) holds, as we are generally
interested only in giving an estimate for the function f(x). It is only when

90
2 Computational complexity
dealing with subtler questions that we take in account the problem of improv-
ing the constants.
Let us see some examples with S = N.
Example 2.2.2. Let f = n4 e g = n4 + 8n2 + 5n + 10. Then f ∈O(g), with
k = 1 and c = 0. Moreover, g ∈O(f) too, with k = 24 and c = 0.
Indeed, we have that 8n2 + 5n + 10 > 0 for all n ∈N, and so
f(n) = n4 < 1 · (n4 + 8n2 + 5n + 10) = 1 · g(n)
∀n ∈N.
Moreover it is straightforward to check that, for all n ∈N,
g(n) = n4 + 8n2 + 5n + 10 < n4 + 8n4 + 5n4 + 10n4 = 24n4;
hence g(n) < 24 · f(n) for all n.
Example 2.2.3. Let f(n) = n2 log n. Then f ∈O(n3).
Indeed, it is well known that if α is a positive real number, then
lim
x→∞
log x
xα
= 0.
Hence, there exists c such that log n ≤n for all n > c.
The symbol O is suitable to express properties regarding the asymptotic
behaviour of functions. In what follows, we shall assume that all the functions
studied are deﬁned in the same domain S, implying, when necessary, that we
are redeﬁning them taking as domain the intersection of their domains, so as
to be able to talk about sum and product of functions, and so on.
Consider two functions f and g; the following table summarises the possible
cases (see Exercises A2.3, A2.2, A2.4):
∃a ﬁnite lim
n→∞
f(n)
g(n) = a ̸= 0
f ∈O(g) e g ∈O(f),
that is, f and g are of the same order;
g ∈O(f), that is, f dominates g,
lim
n→∞
f(n)
g(n) = ∞
and we say that
f is of higher order than g;
f ∈O(g), that is, g dominates f,
lim
n→∞
f(n)
g(n) = 0
and we say that
g is of higher order than f;
∄lim
n→∞
f(n)
g(n)
we cannot say anything in general,
neither that g ∈O(f), nor that g /∈O(f).
We give some more examples.

2.2 The symbol O
91
Example 2.2.4. (1) If f(n) = n2 + 1 and g(n) = n3, then f ∈O(g), as
limn→∞(n2 + 1)/n3 = 0.
(2) Let g(n) = (2 +(−1)n)n2. Clearly, we have g ∈O(n2) and f = n2 ∈O(g),
while the ratio
(2 + (−1)n)n2
n2
= 2 + (−1)n
has no limit.
(3) Consider the functions f(n) = (n+1)+n(−1)n and g(n) = (n+1)−n(−1)n.
Then the ratios f/g and g/f have no limit. Moreover, g /∈O(f) and
f /∈O(g).
Indeed, the functions f and g are such that
f(n) =

2n + 1
if n is even,
1
if n is odd,
g(n) =

1
if n is even,
2n + 1
if n is odd,
and this entails that neither function dominates the other.
The following result gives some useful properties of the symbol O with
respect to the main algebraic operations on functions.
Theorem 2.2.5. If f ∈O(g) and c > 0, then c · f ∈O(g). Moreover, if
f1 ∈O(g1) and f2 ∈O(g2), then
f1 + f2 ∈O(g1 + g2),
f1 · f2 ∈O(g1 · g2).
In particular, if f1 ∈O(g) and f2 ∈O(g), then f1 + f2 ∈O(g).
Proof. As an example, we just prove that if f1 ∈O(g1) and f2 ∈O(g2),
then f1 + f2 ∈O(g1 + g2).
Let S be the domain of f1 and f2. As f1 ∈O(g1) and f2 ∈O(g2), there
exist constants k1, k2, c1, c2 such that
f1(x) ≤k1 · g1(x),
for all x ∈S, with x > c1,
f2(x) ≤k2 · g2(x),
for all x ∈S, with x > c2.
If we deﬁne k = max(k1, k2) and c = max(c1, c2), then clearly
(f1 + f2)(x) ≤k · (g1 + g2)(x),
for all x ∈S, with x > c,
proving the claimed formula.
In the case where f1 ∈O(g) and f2 ∈O(g), then f1 + f2 ∈O(2 · g) and,
by the ﬁrst claim of Theorem 2.2.5, 2 · g ∈O(g); hence the result follows.
⊓⊔
Example 2.2.6. Let f1(n) = n + 3 log n and f2(n) = 5n log n + 28n3. Then
f1 · f2 ∈O(n4), as n + 3 log n ∈O(n) and 5n log n + 28n3 ∈O(n3).

92
2 Computational complexity
Notice that estimates of O type are used in everyday life too, whenever,
rather than needing a precise information, we can content ourselves with know-
ing its order of magnitude. For instance, we might say that we have to walk for
a dozen metres, without implying that the metres are exactly 12, but rather
10, 20 or a similar amount. If we have to go from London to Manchester, we
might say that we must travel hundreds of kilometres, and so forth.
So it is natural to look for estimates of O type for the complexity of an
algorithm too. In this case, saying that an algorithm depending on n data has
a complexity given by the function f(n) with f ∈O(g), means that, for n big
enough, the number of bit operations necessary to execute the algorithm never
exceeds k·g(n) for some constant k. As the computational time is proportional
to computational complexity, neither does the time exceed k · g(n) for some
constant k. In general one looks for an easy way to compute the reference
function g(n), which clearly is not uniquely determined. For instance, if we
have evaluated the complexity of an algorithm by the function n4 + 8n2 +
5n + 10, it is natural to choose as reference function the function g = n4 and
to say that the complexity of the algorithm is O(n4).
2.3 Polynomial time, exponential time
In this section we start by discussing the fundamental notion, touched upon
at the end of § 2, of the dependence of the complexity of an algorithm on the
integers on which it operates.
As we mentioned, the larger the integers on which a given algorithm works,
the larger the expected number of bit operations necessary to execute the
algorithm, and so the larger its complexity. In other words, it is to be expected
that the complexity of an algorithm is a function of the size of the numbers
on which it operates. To attribute a mathematical meaning to this idea, it is
useful to introduce a new notion, the length of a number, which basically is a
measure of the size of a number.
Deﬁnition 2.3.1. Let n be an integer number and β an integer number
greater than 1. Call length Lβ(n) of n in base β the number k such that
the following holds:
βk−1 ≤n < βk,
(2.2)
that is to say, n = k−1
i=0 aiβi = (ak−1, . . . , a0)β, with ak−1 ̸= 0.
By L(n) without subscript we shall mean the length of the number n in
base 2, that is L(n) = L2(n).
Example 2.3.2. We have L10(205) = 3, while L2(205) = 8, as 205 =
(11001101)2.
In particular, by Equation (2.2), taking logarithms, we get
k −1 ≤logβ n < k

2.3 Polynomial time, exponential time
93
and so
Lβ(k) = [logβ n] + 1
and
Lβ(n) ∈O(logβ n).
This can be rephrased by saying that the length of an integer n in a ﬁxed base
β, that is the number of digits necessary to write the number in that base, is
of size logβ n.
Although the length of a number obviously depends on the base in which
it is expressed, it is important to notice that it is possible to give a O-type
estimate of the length, independently of the base. Indeed, recall the well-known
relation between logarithms in diﬀerent bases
logβ n = logα n
logα β .
Thus, if by log n without any subscript we denote the natural logarithm, that
is the logarithm to the base e, we obtain
logβ n = log n
log β .
Using this relation, we get
Lβ(n) =
log n
log β

+ 1;
(2.3)
hence, assuming the base β in which we are expressing numbers is ﬁxed once
and for all, and so is a constant, we have
Lβ(n) ∈O(log n).
(2.4)
Suppose now we have an algorithm A operating on integers n1, . . . , ns,
and denote by T (A) the complexity of A, where the letter T stands for time.
Notice that T (A) is approximated from above by a function of the greatest
length of the integers n1, . . . , ns in the base in which we are operating. Thus,
if n is greater than all of n1, . . . , ns, we may approximate from above T (A)
by a function of log n.
We can now come back to another important question mentioned in § 2.
When performing calculations, whatever instrument we use, it is necessary
to assess the time the algorithms require for their execution: some of them
require a reasonable time, while others do not possess this property. It is now
possible to give a precise mathematical meaning to this claim.
Having this in mind, it is useful to recall that, asymptotically, a polyno-
mial function grows far more slowly than an exponential function. In other
words, if we have a function f(n) ∈O(nk), we may say that f(n) ∈O(an),
independently on the positive integer k and the real number a > 1 (see Ta-
ble 2.1 on page 111). The following two deﬁnitions are based on this simple
remark; they are of fundamental importance in the analysis of algorithms.

94
2 Computational complexity
Deﬁnition 2.3.3. An algorithm A to perform a calculation on integer num-
bers is said to be a polynomial time algorithm, or simply a polynomial algo-
rithm, if there is a positive integer d, called the order of the algorithm, such
that the number of bit operations required to execute the algorithm on integers
of binary length smaller than or equal to k is O(kd).
From what precedes we have then that A is polynomial if T (A) ∈
O((log n)d), where n is the greatest integer on which A operates.
Deﬁnition 2.3.4. An algorithm A is said to be an exponential time algo-
rithm, or simply an exponential algorithm, if the number of bit operations
required to execute the algorithm on integers of binary length smaller than or
equal to k is the same order as eck, for some constant c > 0 (see page 90).
An algorithm that is not exponential is said to be subexponential if the
number of bit operations required to execute the algorithm on integers of binary
length smaller than or equal to k is O(ek).
For instance, A is exponential if T (A) has the same order as n, where n
is the greatest integer on which A operates. On the contrary, an algorithm
requiring f(k) = ek/log(log k) operations is subexponential. Indeed,
lim
k→∞
f(k)
ek
= 0;
hence f(k) ∈O(ek) while, for all c > 0, eck /∈O(f), and so it is not exponen-
tial.
A typical example of an exponential algorithm is the so-called sieve of
Eratosthenes everybody knows since primary school. It is used to determine
whether a number is prime, as well as to factor an integer. We shall take up
this subject again in Chapter 4.
Basically, the diﬀerence between a polynomial time algorithm and an ex-
ponential time one is the following. Suppose we have to work with very large
numbers, otherwise we might perform mentally or by hand our calculations
and we would not need to make too many distinctions. Then, if an algorithm is
polynomial, we may expect it to be feasible, if not by hand, by using suitable
computing devices, in a reasonable time. On the other hand, if the algorithm
is exponential, we cannot in general obtain the answer in a reasonable time,
even by using the most powerful computers: the whole life span of the uni-
verse might not be enough! In other words, polynomial algorithms are feasible,
while exponential ones are not.
Notice that there are other kinds of complexity too, such as factorial com-
plexity, including algorithms requiring a time of the order of k!, where k is
the length of the greatest integer the algorithm operates on.
Example 2.3.5. Let t be the time it takes to perform a single bit operation.
If an algorithm is polynomial of order 2, and if we want it to work with rather
large numbers, for instance in the order of 10100, the time required to perform

2.4 Complexity of elementary operations
95
the algorithm will be bounded by 10000 · C · t, where C is a suitable constant.
Notice that t depends on the computing power of the device we use and may
be made very small. For instance, it is realistic to assume t = 10−9 seconds,
and so 10000 · C · t = 10−5 · C: this shows what is meant by the sentence
“the time required to execute the algorithm is reasonable”. However, notice
that the larger the order of the algorithm, the smaller is its convenience. For
instance, if the algorithm were of order 10, an estimate of the time required
to execute it on numbers of the order of 10100 would be of 1011 · C seconds,
and unless C is tiny this is a substantial amount of time (see Exercise B2.15
and the table 2.1 on page 111).
If on the other hand we have an exponential algorithm and we want it
to work on numbers of the order of 10100, the time required will be of the
order of 10100 ·t. Even if we were able to dramatically improve our computers’
performances, arriving for instance to t = 10−20, we would have 10100 · t =
1080, and this is an enormous number: in order to get an idea of its magnitude,
recall that the number of protons in the universe is a number with 79 decimal
digits. Moreover, it is clear that, no matter how we improve our computers’
power, an exponential algorithm will never allow us to work with very large
numbers.
However, it must be emphasised that even an exponential algorithm may
be feasible, and sometimes even better than a polynomial one, if applied to
small numbers. A typical example is the above mentioned sieve of Eratos-
thenes, which we used at school to factor small numbers.
2.4 Complexity of elementary operations
We shall now study the complexity of elementary operations. The complexity
of any algorithm operating on integers may be obtained by applying the results
from this section.
Recall the notation T (A) to denote the complexity of an algorithm A. For
instance, we shall denote by T (a + b) [T (a −b), T (a · b), T (a/b) and so on,
respectively] the complexity of the algorithm yielding the sum [the diﬀerence,
the product, the quotient and so on, respectively] of two integers a and b.
Proposition 2.4.1. Let a and b be two positive integers
a =
k−1

i=0
ai · 2i = ak−1 . . . a0,
b =
l−1

i=0
bi · 2i = bl−1 . . . b0
of length L(a) = k and L(b) = l, respectively, with k ≥l. Then the following
relations hold:
L(a + b) =

max(L(a), L(b))
or
max(L(a), L(b)) + 1,
(2.5)

96
2 Computational complexity
L(a · b) =

L(a) + L(b) = k + l
or
L(a) + L(b) = k + l −1,
(2.6)
T (a ± b) ∈O(k),
(2.7)
T (a · b) ∈O(L(a) · L(b)) = O(k · l),
(2.8)
T
a
b
 
∈O(L(a) · L(b)) = O(k · l).
(2.9)
Proof. We have the following inequalities:
2k−1 ≤2k−1 + 2l−1 ≤a + b < 2k + 2l ≤2k+1,
2k+l−2 ≤a · b < 2k+l.
Hence the estimates for L(a + b) and for L(a · b) immediately follow. Further,
let q and r be the quotient and the remainder of the division of a by b, that
is, a = qb + r, with 0 ≤r < b.
If b > a, then L(q) = 0, while if b ≤a, then L(a) = L(qb + r). Thus, from
what precedes we immediately get
L(a) −L(b) −1 ≤L(q) ≤L(a) −L(b) + 1.
Let us now compute the complexity of elementary operations.
By adding some zero digits in front of the smaller number if necessary, we
may assume that a and b have the same number of digits even if they have
diﬀerent length. That is, we may write b = k−1
i=0 bi · 2i = bk−1 . . . b0, with
bi = 0 if k ≥l. Recall that the sum is given by
a + b =
k−1

i=0
(ai + bi) · 2i
and so in order to compute the sum we have to compute ai + bi, for 0 ≤i ≤
k −1. The calculation of ai + bi corresponds to a bit operation, and so to
compute a + b we have to perform at least k bit operations. Moreover, we
have to consider the possible carries, as we know from § 1.4.3. This increases
the number of bit operations required, but not to a great extent. Indeed, for
each i = 1, . . ., k, we have to perform two bit operations: the sum ai + bi
and the sum of the number so obtained with the carry, possibly equal to
zero, obtained in the previous sum ai−1 + bi−1. In conclusion, to compute
a+b we have to perform at most 2k bit operations. Notice that the operation
consisting of remembering the carry is not considered a bit operation , as it is
an operation of data storing, which is negligible with respect to the execution
of a bit operation. In conclusion, we have
T (a + b) ∈O(k) = O(max(L(a), L(b)).
It can be seen analogously (see Exercise A2.12) that

2.5 Algorithms and complexity
97
T (a −b) ∈O(k) = O(max(L(a), L(b)).
Suppose now we want to multiply a and b. Recall from § 1.4.3 that, in
order to compute this multiplication, it is necessary to perform the sum of l
numbers, obtained from a by multiplying it by the successive digits of b and by
progressively moving leftwards the digits in the results, inserting to the right
the same number of zeros. So we have to carry out l −1 sums of numbers
of length at most k + l −1. However, all these numbers end in a sequence of
zeros, whose addition to the number that precedes does not contribute any
bit operation. Thus, the number of required bit operations can be estimated
by the number of operations required in order to carry out the sum of l −1
numbers of length k. Hence, by what has already been shown, we deduce that
T (a · b) ∈O((l −1)k) = O(lk) = O(L(a) · L(b)).
Let us now consider the question of giving an estimate for the compu-
tational complexity of division, that is to say for ﬁnding the quotient q and
the remainder r of the division of a by b. The situation is analogous to what
happens for multiplication.
Notice that when we carry out divisions in base two there is no need to
proceed by trial and error: at each step the corresponding digit in the quotient
is 0 or 1 depending on whether the divisor is greater than the dividend or not:
the computer only has to compare the two numbers and this requires a time
negligible with respect to a bit operation.
If a < b, then the quotient q is zero and r = a.
So, suppose a ≥b. In order to ﬁnd q and r we have to compute the ﬁrst
digit of q, which is necessarily 1, multiply 1·b (an operation whose complexity
is O(l)), and then subtract the result from the number consisting of the ﬁrst
l digits of a (again, an operation whose complexity is O(l)). So the time
necessary for this ﬁrst step is O(2l). How many times is this step iterated?
As many as the length of q which, as already shown, is at most k −l + 1. In
conclusion, we have
T
a
b
 
∈O(2l(k −l + 1)) = O(L(a) · L(b)),
as k = L(a) ≥L(b) = l.
⊓⊔
2.5 Algorithms and complexity
In this section we shall determine the computational complexity of some al-
gorithms already described in Chapter 1 and we shall introduce some new
algorithms, computing their complexity as well. Further algorithms shall be
outlined in the exercises.

98
2 Computational complexity
2.5.1 Complexity of the Euclidean algorithm
We are now going to estimate the complexity of the Euclidean algorithm
GCDE(a, b) for the determination of the greatest common divisor of two in-
tegers a and b. When we examined the Euclidean algorithm in section 1.3, we
remarked that it terminates after at most b steps. Using this estimate for the
number div(a, b) of divisions that are necessary to execute the algorithm, we
would ﬁnd ourselves in a mess, as we should deduce that we are dealing with
an exponential time algorithm, and so an unfeasible one, its complexity being
O(bL(a)2) = O(2log2 bL(a)2) = O(2L(b)L(a)2),
where O(L(a)2) is, by Proposition 2.4.1, an estimate for the cost of each
division.
So we have to improve our estimate of the number div(a, b). We shall need
the following lemma, which determines div(a, b) in the particular case in which
the numbers a and b are two consecutive Fibonacci numbers.
Lemma 2.5.1. Let fn be the nth Fibonacci number. The number of divisions
that are necessary to compute GCD(fn+1, fn) by using the Euclidean algorithm
is n −1.
Proof. We have
fn+1 = fn · 1 + fn−1,
0 < fn−1 < fn,
fn = fn−1 · 1 + fn−2,
0 < fn−2 < fn−1,
fn−1 = fn−2 · 1 + fn−3,
0 < fn−3 < fn−2,
...
f4 = f3 · 1 + f2,
0 < f2 < f3,
f3 = f2 · 2 + f0.
As f0 = 0, we have GCD(fn+1, fn) = f2 = 1 and so there are exactly n −1
divisions to be carried out to compute the greatest common divisor.
⊓⊔
The Euclidean algorithm we have described has as its input the pair
(fn+1, fn) and then executes n −1 steps, as the following diagram shows
(fn+1, fn) →(fn, fn−1) →· · · →(f3, f2).
Any other choice of a pair of integers (a, b), with a ≥b, for which the Euclidean
algorithm terminates after n steps is bounded from below by the corresponding
pair (fn+2, fn+1) of elements of Fibonacci sequence. This is the gist of the
following theorem, due to Lam´e:
Theorem 2.5.2 (Lam´e). Let a and b be two positive integers with 0 < b < a
and let d = GCD(a, b). If the Euclidean algorithm to calculate GCD(a, b)
terminates after n steps, then a ≥d · fn+2 and b ≥d · fn+1.

2.5 Algorithms and complexity
99
Proof. The basis of the induction is true because if n = 1 then the Euclidean
algorithm yields a single step: a = qb + 0, that is to say b | a, and so
GCD(a, b) = b = d = d · 1 = d · f2.
Moreover, we have a = qb ≥2b = 2d = d · f3. Assume now that the result is
true when the algorithm terminates after at most n −1 steps. For n steps we
have
a = b q1 + r1,
0 < r1 < b,
b = r1 q2 + r2,
0 < r2 < r1,
r1 = r2 q3 + r3,
0 < r3 < r2,
...
ri = ri+1 qi+2 + ri+2,
0 < ri+2 < ri+1,
...
rn−3 = rn−2 qn−1 + rn−1,
0 < rn−1 < rn−2,
rn−2 = rn−1 qn + 0.
Apply the induction hypothesis to the pair (b, r1), noticing that GCD(b, r1) =
d = GCD(a, b). We obtain
b ≥dfn+1,
r1 ≥dfn,
hence
a = r1 + bq1 ≥r1 + b ≥d(fn+1 + fn) = dfn+2,
which is what was to be proved.
⊓⊔
The above theorem makes it possible to determine a good upper bound
for div(a, b).
Proposition 2.5.3. Let a and b be two positive integers with 0 < b < a. Then
we have
div(a, b) ≤5L10(b).
(2.10)
Proof. From Theorem 2.5.2 it can be immediately deduced that for all pairs
of positive integers a and b such that a > b and b < fn+1, the number
of divisions necessary in order to get a zero remainder when applying the
Euclidean algorithm is smaller than n.
Let then n = div(a, b), and so b ≥fn+1. Recall that if λ1 = (1 +
√
5)/2
then fn+1 > λn−1
1
, for all n ≥3 (see Exercise A1.33). Thus, from b ≥fn+1 it
follows that b > λn−1
1
. As log10 λ1 > 1/5, we have that
log10 b > (n −1) log10 λ1 > n −1
5

100
2 Computational complexity
and so
n −1 < 5 log10 b.
By the deﬁniton of length (2.2) we have b < 10L10(b): so
n −1 < 5L10(b),
and (2.10) follows.
⊓⊔
With the bound on the number on divisions given by Equation (2.10), the
state of things is distinctly improved with respect to the previous situation
which gave an exponential estimate for complexity. Indeed, now we have:
Proposition 2.5.4. Let a and b be two positive integers with 0 < b < a. Then
T (GCDE(a, b)) ∈O(L(a)3).
Proof. We have
T (GCDE(a, b)) ∈O(log b log2 a) = O(log3 a) = O(L(a)3),
as O(log b) gives an estimate of the complexity with regard to the number of
divisions, while O(log2 a) estimates the complexity of each division.
⊓⊔
This shows that the complexity of the Euclidean algorithm is polynomial.
Let us see now an example.
Example 2.5.5. Give an estimate for the number of divisions to complete
the Euclidean algorithm to search the GCD of the two numbers a = 34567
and b = 457.
The number b has 3 digits, and so L10(b) = 3. Then we are conﬁdent
that we can bring to an end the Euclidean algorithm after at most 5 · 3 = 15
divisions. Let us see how many divisions are actually necessary:
34567 = 457 · 75 + 292,
457 = 292 · 1 + 165,
292 = 165 · 1 + 127,
165 = 127 · 1 + 38,
127 = 38 · 3 + 13,
38 = 13 · 2 + 12,
13 = 12 · 1 + 1,
12 = 1 · 12 + 0.
So 8 divisions have been suﬃcient, rather than 15, in order to verify that
GCD(34567, 457) = 1.
Keeping in mind the remarks in § 1.3.3 and the estimate (2.5.4) we may
conclude (see Exercise A2.13) that:

2.5 Algorithms and complexity
101
Corollary 2.5.6. Let a and b be two positive integers with 0 < b < a. The
complexity of computing a B´ezout’s relation of the form (1.14) by means of
the Euclidean algorithm is O(L(a)3).
Analogously, we have (see again Exercise A2.13):
Corollary 2.5.7. The complexity of the algorithm to ﬁnd the solution of a
linear Diophantine equation of the form ax+by = c by means of the algorithm
given in the proof of Proposition 1.3.11 is O(k3), where k is the greatest length
of the integers a, b, c.
2.5.2 From binary to decimal representation: complexity
Recall that in Section 1.4 we described how the coeﬃcients of an integer with
respect to an arbitrary base can be found. In particular, if our base is 10, and
d is a positive integer such that d = (dk−1 . . . d0)10, then, by denoting by q
the quotient and by r the remainder of the divisions of d by 10, we have that
d0 is the remainder r, d1 is the remainder of the division of q by 10 and so on.
As 10 = (1010)2, the division of d by 10, when working in base 2, has
complexity O(4L2(d)) = O(log d). In this way we get the remainder r = d0
in binary form, that is to say, one of the numbers in {0, 1, . . ., 9}, in binary
representation. Now repeat the procedure, dividing the quotient q by 10. This
operation has again complexity estimated by O(log d). So we determine d1,
that is the remainder of the division, and the quotient becomes the starting
point to compute d2. This procedure is to be iterated a number of times equal
to the length of d in base 10, that is the number of decimal digits of d. This
number, by Equation (2.4), is L10(d) ∈O(log d).
In conclusion, the complexity of this algorithm to convert d from its binary
representation to the decimal one is
O(L(d)2) = O(log2 d).
By following the same reasoning, the following can be veriﬁed (see Exercise
A2.14):
Proposition 2.5.8. Let α and β two integers greater than 1. There is an
algorithm to convert its representation in base α of a number n to the repre-
sentation in base β having complexity O(log2 n).
2.5.3 Complexity of operations on polynomials
We frequently work with polynomials and with operations on them. So it is
useful to give an estimate of the complexity of operations on polynomials with
integer coeﬃcients. The following holds.

102
2 Computational complexity
Proposition 2.5.9. Let f(x) and g(x) be two polynomials with integer coef-
ﬁcients, of degree n and m, with n ≥m; assume that their coeﬃcients have
length at most k. Then:
(a) computing the sum or the diﬀerence of f(x) and g(x) has complexity
O(mk);
(b) computing the product of f(x) and g(x) has complexity O(m(n + m)(k2 +
log m)).
Proof. To carry out the sum [or the diﬀerence, respectively] of f(x) and
g(x) it is necessary to complete m additions or subtractions. Hence, from
Proposition 2.4.1 claim (a) immediately follows.
If
f(x) = a0 + a1x + a2x2 + · · · + anxn,
g(x) = b0 + b1x + b2x2 + · · · + bmxm,
then the product f(x) · g(x) has degree n + m and the coeﬃcient of xh is

i+j=h aibj. In order to compute this coeﬃcient we need at most m + 1
multiplications among numbers of length at most k and at most m additions
of numbers of length at most 2k. As we have to perform m such additions, the
length of the summands may be bounded by 2k+L(m). As a consequence, the
complexity we are determining is O((n+m+1)((m+1)k2+m(2k+log m+1)),
hence claim (b) holds.
⊓⊔
It is also useful to determine the number of operations which are necessary
to carry out operations on polynomials on an arbitrary ﬁeld K in which it is
meaningful to deﬁne the computational cost of the operations. More precisely,
assume the following:
•
computing the sum or the diﬀerence of two elements in K has complexity
O(u);
•
computing the product of two elements in K has complexity O(t), with
t ≥u;
•
computing the inverse of an element in K has complexity O(s), with s ≥t.
We shall see later that ﬁnite ﬁelds are examples of this state of things (see
Chapter 5).
Thus, we have:
Proposition 2.5.10. Let K be a ﬁeld in which the above conditions hold. If
f(x) = a0 +a1x+· · ·+anxn and g(x) = b0 +b1x+· · ·+bmxm are polynomials
on K, with n ≥m, then:
•
the complexity of computing f(x) ± g(x) is O(nu);
•
the complexity of computing f(x) · g(x) is O(n2t);
•
the complexity of computing the division of f(x) by g(x) is O(n2s);
•
the complexity of computing the greatest common divisor of f(x) and g(x)
is O(n3s);

2.5 Algorithms and complexity
103
•
the complexity of computing a B´ezout’s relation for the above greatest com-
mon divisor is O(n3s).
Proof. The complexities of the sum, the diﬀerence, and the product of poly-
nomials are computed as in Proposition 2.5.9 and so are omitted. Let us ﬁx
our attention on computing the remaining complexities.
From the proof of Theorem 1.3.17 it follows that, in order to carry out the
division of f(x) by g(x), it is necessary to perform the following operations:
•
compute the inverse of bm;
•
compute g(x)/bm, which requires m multiplications of the coeﬃcients of
g(x) that are diﬀerent from bm, by 1/bm;
•
multiply g(x)/bm by the leading coeﬃcient of the polynomial to be divided,
which requires m+1 multiplications of elements of K; this is to be repeated
n −m + 1 times;
•
carry out a diﬀerence of polynomials of degree at most n, which requires
at most n+1 subtractions in K; this too is to be repeated n−m+1 times.
In conclusion, the division we are studying has complexity O(s+mt+(n−
m + 1)(m + 1)t + (n −m + 1)(n + 1)u), which, keeping in mind the hypothesis
s ≥t ≥u, can be estimated by O(2(n + 1)2s); hence the thesis.
In order to compute the greatest common divisor, the division is to be
repeated at most m times; so the complexity can be estimated by O(n3s).
In order to compute a B´ezout’s relation, after the Euclidean algorithm its
steps are again considered backwards as in the case of integers, as seen in
§ 1.3.3. This requires at most m multiplications and additions of polynomials
of degrees at most m. Hence the claim easily follows.
⊓⊔
2.5.4 A more eﬃcient multiplication algorithm
The algorithms we have described can often be improved, as they can be made more
eﬃcient by means of some clever idea. As an example, we describe in this section
an algorithm which substantially reduces the number of bit operations necessary to
compute the product of a and b, where a, b are two positive integers of length an
even number 2n, that is to say
a = (a2n−1 . . . a0)2
and
b = (b2n−1 . . . b0)2.
Notice that this hypothesis does not actually impose any restriction. Write
a = A1 · 2n + A0
with A1 = (a2n−1 . . . an)2, A0 = (an−1 . . . a0)2,
b = B1 · 2n + B0
with B1 = (b2n−1 . . . bn)2, B0 = (bn−1 . . . b0)2.
So
a · b = (A1 · 2n + A0)(B1 · 2n + B0) =
= A1B1 · 22n + (A1B0 + A0B1) · 2n + A0B0.
(2.11)

104
2 Computational complexity
Example 2.5.11. If a = 23 +2+1, then a is a 4-bit number; hence a = A1 ·22 +A0,
where A1 = (1, 0) and A0 = (1, 1).
So the problem reduces to carrying out the following operations on n-bit integers
A1B1,
A1B0 + A0B1,
A0B0.
Actually, Equation (2.11) yields
a · b = A1B1(22n + 2n) + (A1 −A0)(B0 −B1)2n + A0B0(2n + 1),
(2.12)
so the problem reduces to computing the three products on n-bit integers
A1B1,
(A1 −A0)(B0 −B1),
A0B0,
in addition, evidently, to some additions and digit translations.
Denote by M(n) the number of bit operations that are necessary to compute
the product of two positive n-bit integers. Then, by Equation (2.12), we have
M(2n) ≤3 · M(n) + C0 · n,
(2.13)
because the number of additions and translations necessary to compute a · b by
Equation (2.11) is of class O(n). Now we can prove the following.
Lemma 2.5.12. Set C = max(M(2), C0); then M(2k) ≤(3k −2k) · C.
Proof. Prove the formula by induction on k. By the deﬁnition of C, we have
M(2) ≤max(M(2), C0) = C = (31 −21) · C,
so the theorem is true for k = 1. Assume the theorem is true for k and prove it for
k + 1. We have
M(2k+1) = M(2 · 2k) ≤3 · M(2k) + C0 · 2k ≤3 · (3k −2k)C · +C · 2k =
= (3k+1 −3 · 2k + 2k) · C = (3k+1 −2k+1) · C,
where the ﬁrst inequality is a consequence of Equation (2.13), while the second one
is true by the induction hypothesis and because C ≥C0.
⊓⊔
Thus, for n = 2k we obtain
M(n) = M(2k) ≤M(2[log2 n]+1) ≤(3[log2 n]+1 −2[log2 n]+1) · C ≤
≤3[log2 n]+1 · C = 3C · 3[log2 n] ≤3C · 3log2 n = 3C · nlog2 3,
because obviously the equality 3log2 n = nlog2 3 holds.
So we may conclude:
Proposition 2.5.13. The complexity of the above algorithm for computing the prod-
uct of two n-bit integers, with n = 2k, is O(nlog2 3).
Notice that this estimate is better than the estimate O(n2) obtained with the
usual method, as discussed in Proposition 2.4.1, as log2 3 < 2.

2.5 Algorithms and complexity
105
2.5.5 The Ruﬃni–Horner method
Let us now turn to the study of the problem of evaluating a polynomial p(x)
with integer coeﬃcient at x = α, with α ∈Z, that is of calculating p(α). This
value is exactly the remainder of the division of p(x) by x −α. Let
p(x) = a0 + a1x + · · · + an−1xn−1 + anxn ∈Z[x],
which we shall also write p(x) = anxn + an−1xn−1 + · · · + a1x + a0. The
most immediate way of computing the value of the polynomial in α is by
substituting in the polynomial, wherever the indeterminate x appears, the
element α, and then carrying out all the required operations. However, this
method is not eﬃcient, as it requires the following steps:
•
computing αi, for all i, 2 ≤i ≤n;
•
computing aiαi for 1 ≤i ≤n;
•
computing, one after another, the sums
a0 + a1α,
. . . ,
(a0 + · · · + an−1αn−1) + anαn.
So we have to perform n −1 multiplications in the ﬁrst step, n more multi-
plications in the second, and n additions in the third.
A better method is the Ruﬃni–Horner one. It relies on the fact that we
may write the polynomial in nested form, as follows:
p(x) = a0 + (a1 + (a2 + · · · + (an−1 + anx)x) · · · )x.
This expression relies on the following recursive formula:
pk(x) =

an
for k = 0,
an−k + pk−1(x)
for 0 < k ≤n.
So we have
p0(x) = an,
p1(x) = an−1 + p0(x),
p2(x) = an−2 + p1(x),
...
pn(x) = p(x) = a0 + pn−1(x).
For instance, let p(x) = 3x4 + 2x3 + x2 −x + 4. Then
p0(x) = 3,
p1(x) = a3 + p0(x) = 2 + 3x,
p2(x) = a2 + p1(x) = 1 + (2 + 3x)x,
p3(x) = a1 + p2(x) = −1 + (1 + (2 + 3x)x)x,
p4(x) = a0 + p3(x) = 4 + (−1 + (1 + (2 + 3x)x)x)x,
which represents the nested form of the polynomial p(x).

106
2 Computational complexity
Let us see how to actually use this algorithm. Write down two lines: in the
ﬁrst line put all the coeﬃcients of p(x), starting with the leading coeﬃcient,
including zero coeﬃcients. The leftmost term of the second line is to be the
leading coeﬃcient of p(x); the second term is the previous term multiplied by
α, plus the second term of the ﬁrst line, that is p1(α). In general, the ith term
in the second line is equal to the previous term times α, plus the corresponding
term of the ﬁrst line: this is precisely pi−1(α). The last term so obtained is
pn(α), that is the value p(α) we were looking for.
Basically, the two lines the algorithm constructs are
an
an−1
. . .
a2
a1
a0
p0
p1(α)
. . .
pn−2(α)
pn−1(α)
pn(α) .
(2.14)
Notice that from this table the quotient of p(x) by x −α can be read oﬀ:
it is
p0xn−1 + p1(α)xn−2 + · · · + pn−2(α)x + pn−1(α)
(2.15)
(see Exercise A2.16). This method to get the quotient of the division is called
synthetic division.
It can also be easily seen (see again Exercise A2.16) that the total number
of multiplications that are necessary to write down the second line is exactly
n. Let us see an example.
Example 2.5.14. Evaluate the polynomial p(x) = x5 −3x4 + x2 + x −1 at
x = −3 using this algorithm.
The two lines generated by the algorithm are
1
−3
0
1
1
−1
1
−6
18
−53
160
−481
and the value we are looking for, p(−3), is −481, that is the remainder of the
division of x5 −3x4 + x2 + x −1 by x + 3. Notice that from this table the
quotient of this division can be read oﬀtoo: x4 −6x3 + 18x2 −53x + 160.
As for the complexity of this algorithm, the number of operations to be
performed in order to evaluate at α the polynomial written in nested form is
smaller than the number of operation which would be necessary if the poly-
nomial were written in the usual form. Indeed, we only need n multiplications
and n additions. To simplify things, assume α > 0; if α were negative the
formulas would become true by putting |α| in place of α. Notice that the
absolute value of
pk(α) = an−k + (an−k+1 + (· · · + (an−1 + anα)α)α . . .)α
is smaller than or equal to

A2 Theoretical exercises
107
d + (d + · · · + (d + (d + dα)α)α) · · · α
(2.16)
where d = max{ |ai| }. Suppose that d has length h and α has length k. Notice
that the number appearing in (2.16) is the polynomial d(1 + x + · · · + xk)
evaluated at α. So we may conclude that for all i = 0, . . . , n, we have
|pi(α)| ≤(n + 1)dαn;
thus L(pi(α)) is O(nhk log n). In order to pass from pi(α) to pi+1(α) we have
to carry out a multiplication and an addition: so the complexity of the com-
putation of pi+1(α) is O(nh2k log n). Moreover, i may assume values between
0 and n, so the complexity is O(n2h2k log n).
Appendix to Chapter 2
A2 Theoretical exercises
A2.1. Prove that if f ∈O(g) and g ∈O(h), then f ∈O(h).
A2.2. Assume that limx→∞(f(n)/g(n)) = ∞. Prove that g ∈O(f).
A2.3. Assume that limx→∞(f(n)/g(n)) = a ̸= 0. Prove that, in this case, f ∈O(g)
e g ∈O(f).
A2.4. Assume that limx→∞(f(n)/g(n)) = 0. Prove that f ∈O(g).
A2.5. Prove that, if f(n) = (n + 1) + n(−1)n and g(n) = (n + 1) −n(−1)n, then
neither of the following limits exist:
lim
n→∞
f(n)
g(n) ,
lim
n→∞
g(n)
f(n).
A2.6. Prove that if f ∈O(g) and c > 0, then c · f ∈O(g).
A2.7. Prove that if f1 ∈O(g1) and f2 ∈O(g2), then f1 · f2 ∈O(g1 · g2).
A2.8. Suppose we want to multiply n numbers of length at most k. Which of the
following is an upper bound for the length of the result?
(a) k3.
(b) k2.
(c) nk.
(d) None of the above.
A2.9.* Give an estimate of the length L(n!) of n! with a simple reference function,
where n is an integer of length k.
(a) L(n!) ∈O(nk).
(b) L(n!) ∈O(k2).
(c) L(n!) ∈O(k3).
(d) None of the above.

108
2 Computational complexity
A2.10.* Give an estimate of the length L = L
 n
m
		
, where n has length h and m
has length k.
(a) L ∈O(m2k2).
(b) L ∈O(n2h2).
(c) L ∈O(hk).
(d) None of the above.
A2.11. Given n numbers with length k1, . . . , kn, prove that the length of their sum
is smaller than or equal to the greatest length, plus L(n). What about the product?
A2.12. Let a and b be integers with length k and l respectively, with k ≥l. Prove
that
T(a −b) ∈O(k) = O(max{L(a), L(b)}).
A2.13. Prove Corollaries 2.5.6 and 2.5.7 (page 101).
A2.14. Prove Proposition 2.5.8.
A2.15. Give an estimate of the complexity (that is, the number of bit operations
needed) of computing the expression of a rational number as a continued fraction.
A2.16. Verify that the polynomial given in Equation (2.15) is the quotient of the
division of p(x) by x−α and that the number of multiplications needed to write the
second row of table (2.14) is exactly n.
A2.17. Keeping in mind Exercises A1.36, A1.40 and B1.37, prove that the algo-
rithm to compute the greatest common divisor described in Exercise A1.40 is faster
than the one based on the usual division algorithm. Prove that, nevertheless, the
asymptotic estimate given in Proposition 2.5.4 cannot be improved in this way.
A2.18.* Prove that the computational complexity of computing the row-by-column
product of two n × n matrices with integer entries bounded in absolute value by a
positive integer number m is O(n3(log2 m + log n)).
A2.19. Prove that the computational complexity of computing the product A · X,
where A is a square matrix of order n and X is a column vector with n components,
when their entries are integer numbers bounded in absolute value by a positive
integer number m, is O(n2 log2 m).
A2.20.* Prove that the number of operations that are needed to reduce a m × n
matrix (with m ≤n) on a ﬁeld in row echelon form using Gaussian elimination (see
[13], Chap. 8) is O(n3).
A2.21.* Prove that the number of operations that are needed to compute the de-
terminant of a square matrix of order n on a ﬁeld is O(n3).
A2.22.* Prove that the number of operations that are needed to compute the inverse
of a square matrix of order n on a ﬁeld is O(n3).
A2.23.* Give an estimate for the number of bit operations necessary in order to
compute n!, where n is an integer of length k.
(a) T(n!) ∈O(ek).
(b) T(n!) ∈O(n3k3).

B2 Computational exercises
109
(c) T (n!) ∈O(n2k2).
(d) None of the above.
A2.24.* Give an estimate for the complexity of computing
 n
m
	
.
A2.25.* Give an estimate for the complexity of computing mn.
B2 Computational exercises
B2.1. Let f(n) = n3 −2n2 −1. Determine the best O-estimate for f(n) among the
following ones.
(a) f(n) ∈O(n4).
(b) f(n) ∈O(n3).
(c) f(n) ∈O(n2).
(d) f(n) ∈O(n2 log n).
B2.2. Let f(n) = 2 log n + n. Determine the best O-estimate for f(n) among the
following ones.
(a) f(n) ∈O(log n).
(b) f(n) ∈O(n2).
(c) f(n) ∈O(n log n).
(d) f(n) ∈O(n).
B2.3. Let f(n) be the sum of the cubes of the ﬁrst n even numbers (see Exercise
B1.9). Determine the best O-estimate for f(n) among the following ones.
(a) f(n) ∈O(n4).
(b) f(n) ∈O(n3).
(c) f(n) ∈O(2n).
(d) f(n) ∈O(3n).
B2.4. Let f(n) =
n
4
	
. Determine the best O-estimate for f(n) among the following
ones.
(a) f(n) ∈O(n4).
(b) f(n) ∈O(4n).
(c) f(n) ∈O(n3).
(d) f(n) ∈O(3n).
B2.5. Determine the best O-estimate for f(n) = 3n + n! among the following ones.
(a) f(n) ∈O((3n)!).
(b) f(n) ∈O(n!).
(c) f(n) ∈O(3n).
(d) f(n) ∈O(n3).
B2.6. Let f(n) = 3 log5 n+log n+2. Determine the best O-estimate for f(n) among
the following ones.

110
2 Computational complexity
(a) f(n) ∈O(n).
(b) f(n) ∈O(log n).
(c) f(n) ∈O(n log n).
(d) f(n) ∈O(log5 n).
B2.7. Which is the length of 2047 in base 2?
(a) 13.
(b) 12.
(c) 11.
(d) None of the above.
B2.8. Which is the length of (110110110110)2 in base 10?
(a) 3.
(b) 4.
(c) 5.
(d) None of the above.
B2.9. Which is the length of (110110110110)2 in base 16? (Remember Remark
1.4.3.)
(a) 3.
(b) 4.
(c) 5.
(d) None of the above.
B2.10. Which is the length of 32769 in base 8?
(a) 4.
(b) 5.
(c) 6.
(d) None of the above.
B2.11. Which is the length in base 10 of the hexadecimal number (F424B)16?
(a) 7.
(b) 6.
(c) 5.
(d) None of the above.
B2.12. Which is the length of (7424B)16 in base 2?
(a) 21.
(b) 20.
(c) 19.
(d) None of the above.
B2.13. Which is the length in base 2 of the sum of (100100110)2 and (11100101)2?
(a) 9.
(b) 10.
(c) 11.
(d) None of the above.

B2 Computational exercises
111
B2.14. Which is the length in base 2 of the product of the binary numbers 11101
and 1101?
(a) 8.
(b) 9.
(c) 10.
(d) None of the above.
B2.15. Assume that an algorithm is given which, receiving as input an integer of
length n, has complexity log n (or n, n log n, n2, 2n, n!). Suppose the time needed
to carry out each bit operation is 10−9 seconds.
In these hypotheses verify Table 2.1, which gives the time needed for the algo-
rithm to come to an end.
Table 2.1. Time to carry out the bit operations needed
n
log n
n
n log n
n2
2n
n!
10
3 · 10−9 s
10−8 s 3 · 10−8 s 10−7 s 10−6 s
3 · 10−3 s
102
7 · 10−9 s
10−7 s 7 · 10−7 s 10−5 s 4 · 1013 y ∗
103
1,0 · 10−8 s 10−6 s 1 · 10−5 s 10−3 s ∗
∗
104
1,3 · 10−8 s 10−5 s 1 · 10−4 s 10−1 s ∗
∗
105
1,7 · 10−8 s 10−4 s 2 · 10−3 s 10 s
∗
∗
106
2 · 10−8 s
10−3 s 2 · 10−2 s 17 m
∗
∗
The ﬁrst column of the table gives the size of the input, while the other columns
display the complexity, and “s”, “m” and “y” denote seconds, minutes and years
necessary to execute the algorithm, respectively. The asterisk means that the time
taken is greater than 10100 years.
B2.16. Order the exponential, factorial, linear, logarithmic and polynomial com-
plexities from the most intractable to the most tractable one.
(a) Factorial, exponential, logarithmic, polynomial, and linear.
(b) Exponential, factorial, polynomial, logarithmic, and linear.
(c) Exponential, factorial, logarithmic, polynomial, and linear.
(d) Factorial, exponential, polynomial, linear, and logarithmic.
B2.17. Let k be a positive integer and let a, b be integers of length [e2k] and [ek],
respectively. Which is the best estimate for the computation time of a + b?
(a) O(ek).
(b) O(2ek).
(c) O(e2k).
(d) O(e3k).

112
2 Computational complexity
B2.18. Let k be a positive integer and let a, b be integers of length k3 and [log2 k],
respectively. Which is the best estimate for the computation time of a −b?
(a) O(k).
(b) O(k3).
(c) O(log k).
(d) O(log2 k).
B2.19. Let k be a positive integer and let a, b be integers of length [e2k] and [ek],
respectively. Which is the best estimate for the computation time of a · b?
(a) O(e2k).
(b) O(e3k).
(c) O(e2k2).
(d) O(eek).
B2.20. Let a, b be integers of length k3 and [log2 k], respectively. Which is the best
estimate for the computation time of a · b?
(a) O(k2 log k).
(b) O(k3 log k).
(c) O(log3 k).
(d) O(k3 log2 k).
B2.21. Consider the formula expressing the sum of the ﬁrst n squares
n

j=1
j2 = n(n + 1)(2n + 1)
6
.
(2.17)
Which of the following is an estimate for the number of bit operations that are
needed to compute the left-hand side of Equation (2.17)?
(a) O(n log n).
(b) O(n2 log n).
(c) O(n log2 n).
(d) None of the above.
B2.22. Consider again Formula (2.17). Which of the following is an estimate for
the number of bit operations that are needed to compute the right-hand side of
Equation (2.17)?
(a) O(n log n).
(b) O(n2).
(c) O(log2 n).
(d) None of the above.
B2.23. In the last two exercises we saw two diﬀerent methods to compute Formula
(2.17). Which is the faster method?
(a) The two methods have the same complexity.
(b) The ﬁrst method is the faster one.
(c) The second method is the faster one.
(d) None of the above.

C2 Programming exercises
113
B2.24. How many steps are necessary to compute GCD(1176, 159) using the variant
to the Euclidean algorithm described in Exercise A1.40?
(a) 4.
(b) 5.
(c) 6.
(d) None of the above.
C2 Programming exercises
C2.1. Write a program that computes the length of an integer number a in base 2.
C2.2. Write a program that computes the length of an integer number a in base b,
where b is an integer greater than 1.
C2.3. Write a program that computes the product of two integer numbers of length
2n using the algorithm described in §2.5.4.
C2.4. Write a program that evaluates a polynomial at an integer using Ruﬃni–
Horner method.

3
From inﬁnite to ﬁnite
In this chapter we shall deﬁne an important relation on Z: the congruence
relation modulo a positive integer n. We shall give here the fundamental prop-
erties of this relation, but we shall repeatedly come back to it in later parts
of the book.
3.1 Congruence: fundamental properties
The congruence relation modulo a positive integer n identiﬁes two integers if
and only if their diﬀerence is a multiple of n: so it may be regarded as an
“equality” up to multiples of n. At ﬁrst sight, this might look quite strange.
Actually, we use this relation in everyday life. Consider the way the time is
displayed by a clock: at six p.m., that is to say 18 hours after midnight, we
read the digit 6. So, with respect to keeping the time, the number 18 equals
the number 6. This means that we are working modulo 12.
We are now going to give a formal treatment of the subject.
Deﬁnition 3.1.1. Let n be a ﬁxed positive integer. The congruence relation
modulo n is the relation on Z deﬁned as follows: a ≡b (mod n) if and only
if there exists an integer h such that a −b = nh, that is
a ≡b
(mod n)
if and only if
n | (a −b);
in this case we say that a is congruent to b modulo n.
We shall sometimes write a ≡n b rather than a ≡b (mod n), and even ≡
rather than ≡n if no misunderstanding can possibly arise.
It is easy to verify (see Exercise A3.1) that the congruence modulo any
ﬁxed positive integer n is an equivalence relation, that is to say:
•
it is reﬂexive, i.e. for every integer a ∈Z, it one has a ≡n a;
•
it is symmetric, i.e. for every pair of integers (a, b) ∈Z×Z, one has a ≡n b
if and only if b ≡n a;

116
3 From inﬁnite to ﬁnite
•
it is transitive, i.e. for every triple of integers (a, b, c) ∈Z×Z×Z, if a ≡n b
and b ≡n c then a ≡n c.
Notice that an integer is congruent to every other integer modulo 1, that
is to say congruence modulo 1 is a trivial equivalence relation; for this reason
in what follows we shall in general assume n > 1.
Given an integer a, we shall denote by [a]n, or, if no confusion may possibly
arise, by [a], or by ¯a, the congruence class of a modulo n, that is,
[a]n = { b ∈Z | b ≡n a } = { a + hn | h ∈Z } =
= {. . . , a −2n, a −n, a, a + n, a + 2n, . . .}.
As we may always divide an integer a by n (see Proposition 1.3.1), if we
denote by r the remainder of the division, we immediatly obtain:
Proposition 3.1.2. Every integer a is congruent modulo n to a unique integer
r such that 0 ≤r < n.
In particular, notice that for every integer a there is a unique element r of
[a]n such that 0 ≤r < n, that is to say the remainder of the division of a by
n. This element is denoted by the symbol:
a mod n .
Remark 3.1.3. Let us remark that, keeping in mind Proposition 2.4.1, it
is possible to deduce that the complexity of computing a mod n is O(log a ·
log n). If we work modulo a ﬁxed integer n, considering it as a constant, the
complexity is O(log a).
There are exactly n equivalence classes, namely (see Exercise A3.4):
¯0 = {integers that, divided by n, give a remainder equal to 0} =
= { kn | k ∈Z } = {multiples of n},
¯1 = {integers that, divided by n, give a remainder equal to 1} =
= { kn + 1 | k ∈Z },
...
n −1 = {integers that, divided by n, give a remainder equal to n −1} =
= { kn + n −1 | k ∈Z }.
This is the reason why the equivalence classes modulo n are also called residue
classes modulo n.
To give a graphical representation of this situation, we can envisage integer
numbers as arranged at equal distances on a circumference of length n. So it
becomes clear that all integer multiples of n coincide with 0, the integers that,
divided by n, give a remainder equal to 1 coincide with 1, those that, divided
by n, give a remainder equal to 2 coincide with 2 and so on.

3.1 Congruence: fundamental properties
117
We shall denote by Zn the quotient set of Z with respect to the congruence
modulo n, that is to say, Zn consists of n distinct residue classes modulo n:
Zn
def
= { ¯0, ¯1, ¯2, . . . , n −2, n −1 } = Z/≡n .
Thus, using the congruence relation modulo n
we passed from the inﬁnite set Z to the ﬁnite set Zn.
This passage from inﬁnite to ﬁnite is often very useful, especially when
calculations or checks are to be performed with a computer which, as is well
known, only works with ﬁnitely many objects. We shall see examples of this
fact, beginning with this chapter and even more in the following ones.
The congruence shares several properties with equality among integer num-
bers. The symbol ≡has been introduced by Gauss, by virtue of the analogy
with the equality relation. In particular, we may add, subtract and multiply
congruent elements preserving the congruence:
Proposition 3.1.4. Let n > 1 be a ﬁxed integer. If a, b, c, d are integers with
a ≡n b and c ≡n d, then the following properties hold:
a ± c ≡b ± d
(mod n),
ac ≡bd
(mod n).
Proof. The easy proof is left as an exercise to the reader (see Exercise A3.5).
⊓⊔
Proposition 3.1.4 says that the congruence relation deﬁned on Z is com-
patible with the operations of addition and multiplication deﬁned on Z. In
other words, the two operations on Zn given by
¯a + ¯b
def
= a + b,
¯a · ¯b
def
= a · b
(3.1)
are well deﬁned, as they do not depend on the representative elements chosen.
So, exactly as Z, Zn is also an example of a commutative ring with unity, called
ring of residue classes modulo n (see Exercise A3.6).
Remark 3.1.5. By keeping in mind Remark 3.1.3 and Proposition 2.4.1, we
ﬁnd that the complexity of computing the sum of two elements in Zn is
O(log n). Indeed, we may consider those elements as numbers smaller than
n, and so of length O(log n). Their sum still has length O(log n), but now we
have to reduce it modulo n, which requires at most subtracting n. Hence the
claim follows.
Analogously, the complexity of computing the product of two elements
in Zn is O(log2 n). Indeed, the product of two elements in Zn has length at
most O(2 log n). Then it is necessary to reduce modulo n, and this requires a
division by n. Hence the assertion follows.

118
3 From inﬁnite to ﬁnite
Remark 3.1.6. This is a convenient moment to recall some algebraic notions, in
order to put in a wider context the operation that led us from the ring Z to the ring
Zn.
Let A be a commutative ring, and let I be an ideal of A (see § 1.3.5). In A it
is possible to deﬁne the relation of congruence modulo I, denoted by ≡I, as follows:
given a, b ∈A, we put a ≡I b if and only if a −b ∈I. It is easy to verify that ≡I
is an equivalence relation (see Exercise A3.7), whose quotient set is denoted by the
symbol A/I. If a ∈A, its class modulo I is denoted by the usual symbols [a]I, [a],
a and also by a + I, it consisting of all the elements of the form a + b, with b ∈I.
Notice that I is exactly the equivalence class of 0 modulo I. Also notice that ≡(0) is
the equality relation, and so A/(0) = A, while any two elements of A are congruent
modulo A, that is to say A/A consists of a single element.
An analogue of Proposition 3.1.4 holds: if a, b, c, d are elements of A and a ≡I b
and c ≡I d, then we have (see Exercise A3.8)
a ± c ≡I b ± d,
ac ≡I bd.
(3.2)
This implies that the two operations on A/I given by
¯a + ¯b
def
= a + b,
¯a · ¯b
def
= a · b
(3.3)
are well deﬁned in A/I, that is they do not depend on the representative elements
chosen. With these operations, A/I is a commutative ring, called the quotient ring
of A modulo I (see Exercise A3.9).
In this setting, we can see that Zn is just the quotient of Z modulo the ideal
(n). As Z is an Euclidean ring (see § 1.3.5), and consequently its ideals are principal
(see Theorem 1.3.14), each proper ideal of Z is of the form (n), with n positive
integer and so, when n varies in the set of positive integers, Zn describes the set of
all quotients of Z that are commutative ring with unity.
However, it would be wrong to assume that every property holding for the
equality holds for congruences as well. For instance, in Z we have the following
cancellation property:
ac = bc
implies
a = b,
as long as c ̸= 0. In other words, Z is an integral domain. This property does
not hold, in general, for congruences, as the following example shows:
2 · 3 = 6 ≡6 12 = 4 · 3,
but
2 ̸≡6 4.
(3.4)
Nevertheless, the following result holds:
Proposition 3.1.7. Let n > 1 be an integer. If ac ≡n bc and if c and n are
coprime, that is if GCD(c, n) = 1, then a ≡n b.
Proof. If ac ≡n bc, then n | (a −b)c. As GCD(c, n) = 1, it follows from
Corollary 1.3.9 that n | a −b, that is a ≡b (mod n).
⊓⊔
Notice that in the example (3.4) given above, the hypothesis was not sat-
isﬁed, as GCD(3, 6) = 3 ̸= 1. Proposition 3.1.7 is actually a consequence of
the following more general result.

3.1 Congruence: fundamental properties
119
Proposition 3.1.8. Let n > 1 be an integer. If ac ≡bc (mod n), then a ≡b
(mod m), where d = GCD(c, n) and n = md.
Proof. Notice that, by the deﬁnition of d, m = n/d and f = c/d are integer
numbers. The hypothesis implies that (a −b)c = kn for some integer k, and
so, by dividing by d, we ﬁnd that
(a −b)f = km.
Then m divides the product (a −b)f, and m and f are coprime, that is
GCD(m, f) = 1 (see Corollary 1.3.6), and so m divides a −b, as already
proved in Proposition 3.1.7; thus a ≡m b.
⊓⊔
Basically, Proposition 3.1.8 says that simplifying a congruence by can-
celling out a common factor is always possible, as long as the modulo is suit-
ably modiﬁed. For instance, 21 = 3 · 7 ≡9 30 = 3 · 10 and 7 ̸≡10 (mod 9),
while 7 ≡10 (mod 3).
Remark 3.1.9. As a consequence of the above, we may see, for instance, that
in Z5 the same cancellation property holds as in Z; in other words, Z5 is, like
Z, an integral domain, and consequently, since it is ﬁnite, a ﬁeld (see Exercise
A1.48). Indeed, if ¯a·¯b = ¯0, with ¯a,¯b ∈Z5 and ¯b ̸= ¯0, then ¯a = ¯0 by Proposition
3.1.7, as GCD(b, 5) = 1. So Z5 is an integral domain. On the other hand, the
same results say nothing about Z4. In fact, in Z4 there are zero-divisors: we
have ¯2 · ¯2 = ¯0, con ¯2 ̸= ¯0.
Remark 3.1.10. Returning to Remark 3.1.6, assume A is an integral domain. Keep-
ing in mind that [0]I = I, it is easy to verify (see Exercise A3.12) that A/I is itself
an integral domain if and only if I is a prime ideal, that is if and only if: for all pairs
(a, b) of elements of A such that ab ∈I, either a ∈I or b ∈I.
Now, in the case of Z we may ask for which positive integer numbers n greater
than 1 it is the case that the ideal (n) is prime, this being a necessary and suﬃcient
condition for Zn to be an integral domain as well, and consequently a ﬁeld (see
Exercise A1.48). Clearly this happens if and only if: for all pairs (a, b) of integers
such that n | ab, either n | a or n | b. In this case we say that n is a prime number.
At ﬁrst sight, it is not evident that this deﬁnition of a prime number is equivalent
to the deﬁnition given in § 1.3.1. Indeed, this deserves to be further investigated,
and this will be done in Chapter 4.
For instance 2, 3, 5, 7 and so forth are prime numbers, and so Z2, Z3, Z5, Z7 and
so forth are integral domains and, being ﬁnite, they are ﬁelds.
Notice that Proposition 3.1.8 is the ﬁrst result connecting two congruences
modulo diﬀerent numbers. We collect now further useful properties relating
congruences modulo diﬀerent numbers, leaving the easy proof to the reader
(see Exercise A3.13; see also Exercise A1.47).
Proposition 3.1.11. The following properties hold:
(1) if a ≡n b and d | n, then a ≡d b;
(2) if a ≡n b and a ≡m b, then a ≡b (mod lcm(n, m)).

120
3 From inﬁnite to ﬁnite
3.2 Elementary applications of congruence
3.2.1 Casting out nines
Let us recall how the so-called casting out nines works: the reader is certainly familiar
with this procedure since primary school. It is used to check the results of operations
on integers.
Suppose we want to multiply two integers, say 123 and 456 and ﬁnd the result
56088. We want to check its correctness.
We act as follows. Write down the sum of the digits of the factors, casting out
nines, which are substituted by zeros, and iterate this procedure until we get a one-
digit number. Multiply the one-digit numbers obtained in this way and reduce the
result of this operation as well to a one-digit number x. Finally, the result to be
checked is reduced in the same way to a one-digit number: it must be the same as
x, or the operation was not carried out correctly.
In our case we have
123
1 + 2 + 3 = 6
6 = 6
× 456
4 + 5 + 6 = 15
1 + 5 = 6
= 56088,
5 + 6 + 0 + 8 + 8 = 27,
2 + 7 = 9 = 0 .
Now, carry out the product 6·6 = 36, whose digit sum is 3+6 = 9 = 0, which equals
the sum of the digits of the result of the multiplication of the original numbers (that
is, 0). If we had found a number diﬀerent from 0, we would be sure to have made
a mistake while multiplying. On the other hand, the agreement of the two number
does not assure us that the multiplication was carried out correctly.
Let us now investigate the meaning of this “casting out nines” procedures, and
in particular what is so special about the number 9.
As we know from section 1.4, when we write 123 in base 10 we mean the number
1 · 102 + 2 · 10 + 3 · 100. Now, for all n > 0, we have that
10n −1 = 999 · · · 9



n
= 9 · 111 · · · 1



n
,
that is,
10n ≡9 1.
Then, by exploiting the properties of congruence, it follows that
123 = 1 · 102 + 2 · 10 + 3 ≡9 1 + 2 + 3,
that is, the number 123, as all numbers written in base 10, is congruent modulo 9
to the sum of its digits. So if z is the positive integer number
z = (anan−1an−2 . . . a1a0)10 = an10n + · · · + a1 · 10 + a0,
(3.5)
then
z ≡an + an−1 + · · · + a0
(mod 9).
Here lies the magic of number 9 and the explanation of casting out nines. In fact,
if two numbers are diﬀerent modulo 9 they are plainly diﬀerent, while two numbers
that are congruent modulo 9 are not necessarily equal. Now, if we carry out an
operation, cast out nines and get a match, we only deduce that the right result and
the one we found are congruent modulo nine. So we are not certain the operation

3.2 Elementary applications of congruence
121
was carried out correctly. On the other hand, if the procedures fails, we are certain
that the result was wrong. In other words, casting out nines is a necessary but not
suﬃcient condition for the calculation to be correct. For instance, if we by mistake
get 65817 as result of multiplying 123 and 456, we would not notice it by casting
out nines, as the wrong result and the correct one are in the same class modulo 9,
as both are multiples of 9.
3.2.2 Tests of divisibility
As another useful application, congruences yield some tests of divisibility without
having to explicitly carry out the division. We keep writing numbers in base 10, that
is to say in the form (3.5). So we have the following tests:
•
test of divisibility by 3 and by 9: an integer number z = (anan−1 . . . a1a0)10 is
divisible by 3 (or by 9, respectively) if and only if the sum of its digits
a0 + a1 + a2 + · · · + an
is divisible by 3 (or by 9, respectively);
•
test of divisibility by 2 and by 5: an integer number z = (anan−1 . . . a1a0)10 is
divisible by 3 or by 5 if and only if its rightmost digit, a0, is divisible by 2 or by
5;
•
test of divisibility by 4 and by 25: an integer number z = (anan−1 . . . a1a0)10 is
divisible by 4 (or by 25, respectively) if and only if the number (a1a0)10 formed
by its last two digits is divisible by 4 (or by 25, respectively);
•
test of divisibility by 2k: an integer z = (anan−1an−2 . . . a1a0)10 is divisible by
2k if and only if 2k divides the number (ak−1ak−2 . . . a1a0)10 formed by the last
k digits of z; so, in particular, an integer is divisible by 8 if and only if (a2a1a0)10
is divisible by 8;
•
test of divisibility by 11: an integer z = (anan−1an−2 . . . a1a0)10 is divisible by
11 if and only if the sum of its digits taken with alternating signs
a0 −a1 + a2 −· · · + (−1)nan
is divisible by 11.
Proof. The test of divisibility by 3 and by 9 follows from the fact that z ≡an +
an−1 + · · · + a0 both modulo 3 and modulo 9.
Notice that 10n ≡0 both modulo 2 and modulo 5, for all n ≥1. So, z ≡a0 both
modulo 2 and modulo 5, and this proves the corresponding divisibility tests.
Analogously, 100 = 2252 ≡0 both modulo 4 and modulo 25, and so every integer
is congruent modulo 4 and modulo 25 to the integer formed by its rightmost two
digits.
More generally, 10n = 2n5n ≡0 (mod 2k) for all k ≥n, proving the divisibility
test for 2k.
Finally, notice that 10 ≡−1 (mod 11), and so for all p ≥1, we have 102p ≡1
(mod 11) and 102p+1 ≡−1 (mod 11); hence the divisibility test for 11 follows.
⊓⊔
Part of the remarks discussed in this section can be extended to numbers written
in an arbitrary base (see the exercises in the appendix).

122
3 From inﬁnite to ﬁnite
3.3 Linear congruences
As for equalities, for congruences too the problem can be posed of solving a
congruence with respect to one or more variables. The simplest equation is
x ≡a
(mod n),
which admits as its solutions all the integers of the form a + hn with h ∈Z.
We may generalise and give the following deﬁnition:
Deﬁnition 3.3.1. A linear congruence or linear congruence equation in the
unknown x is an equation of the form
ax ≡b
(mod n)
with a, b in Z and n a positive integer greater than 1.
We are going to study if and when such a congruence admits solutions,
where by a solution we mean an integer x0 such that ax0 ≡n b. If a solution
exists, we say that the equation is soluble.
The examples that follow show that both solvable linear congruences and
insolvable ones exist.
Example 3.3.2. The equation 3x ≡2 (mod 6) does not admit solutions:
if it did, we would ﬁnd solutions in Z for the equation 3x + 6y = 2, but
Proposition 1.3.11 tells us that this equation does not admit integer solutions,
as GCD(3, 6) = 3, which does not divide 2.
Example 3.3.3. The equation 4x ≡6 (mod 10) admits the solution x = 4,
which is not unique, as x = 9 is a solution too.
We now give the general conditions for a linear congruence to be solvable
and, for solvable congruences, its solutions.
Proposition 3.3.4. Consider the congruence ax ≡b (mod n).
(1) It admits solutions if and only if d = GCD(a, n) divides b.
(2) If the congruence is solvable, denote by x0 one of its solutions; then all
numbers of the form x0 + hm, with h ∈Z and m = n/d, are solutions,
and there are no other solutions. Among these, the solutions
x0,
x0 + m,
x0 + 2m,
. . . ,
x0 + (d −1)m
(3.6)
are pairwise non-congruent and all other solutions are congruent to one of
them. So the congruence admits exactly d non-congruent solutions modulo
n.

3.3 Linear congruences
123
Proof. Solving the congruence is equivalent to ﬁnding integer solutions of
the equation ax + ny = b, and by Proposition 1.3.11 these exist if and only if
GCD(a, n) | b.
Let us prove now that x0 + hm is a solution, for all h ∈Z. Indeed,
a(x0 + hm) = ax0 + ahn
d = ax0 + hna
d ≡n ax0 ≡n b.
We prove next that each solution is of this form. Let x0 and x′
0 be two solu-
tions. Then
ax0 = b + hn,
ax′
0 = b + kn,
for suitable integers h and k, so
a(x0 −x′
0) = (h −k)n.
By dividing both sides by d we get
a′(x0 −x′
0) = (h −k)m,
where a′ = a/d. As a′ and m are relatively prime (see Corollary 1.3.6), by
applying Proposition 1.3.9 we see that m divides x0 −x′
0, that is x0 −x′
0 = zm
for some integer z.
We prove now that, among the solutions x0 + hm, when h varies in Z,
exactly d of them are non-congruent modulo n. To this end, we shall show
that the solutions (3.6) are non-congruent modulo n and that every solution is
congruent to one of them. Assume by contradiction that two of the solutions
(3.6) are congruent modulo n, that is to say,
x0 + h1m ≡x0 + h2m
(mod n),
for some h1, h2 ∈Z with 0 ≤h1 < h2 ≤d −1. Then we would get
h1m ≡h2m
(mod n);
hence, by dividing by m = GCD(m, n), it would follow that
h1 ≡h2
(mod d),
which yields a contradiction because we assumed 0 < h2 −h1 < d.
To prove that each solution of the form x0 + hm, when h varies in Z, is
congruent to one of the solutions (3.6), it suﬃces to divide h by d, that is to
say, deﬁning h = dq + r, with 0 ≤r ≤d −1, we have
x0 + hm = x0 + (dq + r)m = x0 + qn + rm ≡n x0 + rm,
which is exactly one of the solutions (3.6).
⊓⊔
Example 3.3.5. The congruence 4x ≡6 (mod 10) form Example 3.3.3 ad-
mits exactly 2 = GCD(4, 10) solutions that are non-congruent modulo 10:
x = 4 e x = 9.

124
3 From inﬁnite to ﬁnite
Corollary 3.3.6. If a and n are relatively prime, then the congruence ax ≡b
(mod n) admits exactly one solution modulo n.
The above results allow us, in particular, to ﬁnd the invertible elements of
Zn, that is the elements ¯x ∈Zn for which an element ¯y ∈Zn such that ¯x¯y = 1
exists.
Corollary 3.3.7. An element ¯a ∈Zn is invertible if and only if a and n are
relatively prime.
Proof. Determining the classes ¯a that are invertible in Zn is equivalent to
solving the congruence
ax ≡1
(mod n).
Now, this congruence admits a solution, and this solution is unique, if and only
if GCD(a, n) = 1. So the invertible classes are the classes ¯a with 0 < a < n
and GCD(a, n) = 1.
⊓⊔
Remark 3.3.8. To solve a linear congruence of the form ax ≡b (mod n) we
have essentially to solve a linear Diophantine equation of the form ax+ny = b.
Let us study the complexity of this operation. We may assume that n is ﬁxed,
and so is constant. The ﬁrst steps consist in computing d = GCD(a, n); this
has complexity O(log3 a) by Proposition 2.5.4. Next, we have to divide b by
GCD(a, n), which has complexity O(log a log b) by Proposition 2.4.1. Now
we are able to decide whether the equation is solvable or not, depending on b
being or not a multiple of d. Thus, the complexity of the algorithm that decides
whether the equation is solvable has complexity O(log3 a + log a log b). As to
actually solving the equation recall that, by the results in § 1.3.4, in order
to ﬁnd a solution of ax + ny = b, and consequently a solution x0 of ax ≡b
(mod n), it is necessary to compute a B´ezout’s identity for GCD(a, n) and
to multiply it by b/d. By Corollary 2.5.6 and by Proposition 2.4.1 this does
not increase the complexity. Neither does, for similar reasons, computing the
further solutions (3.6) of the congruence, which are obtained using Proposition
3.3.4.
In particular, in order to decide if ¯a ∈Zn is invertible and, if so, to
determine an inverse, the complexity is simply O(log3 a).
If, on the other hand, in this kind of problem we consider a < n as ﬁxed,
that is, we take a as a constant and n as a variable, we get that the complexity
of deciding if ¯a ∈Zn is invertible and, if so, of ﬁnding an inverse is O(log3 n).
We give now an important deﬁnition.
Deﬁnition 3.3.9. For all n ≥1, denote by ϕ(n) the number of positive inte-
gers smaller than n that are coprime to n. The function ϕ : N →N deﬁned in
this way is called Euler function or ϕ function.

3.3 Linear congruences
125
For instance, ϕ(24) = 8 as the numbers that are smaller than 24 and
coprime to it are: 1, 5, 7, 11, 13, 17, 19 and 23.
The Euler function will be, as we shall see, very important in what follows:
we shall return to it again, in particular in Chapter 4. At present we remark
that, as Zn = {[0], [1], . . ., [n−1]}, the multiplicative group U(Zn) of invertible
elements of Zn consists of all classes [a], with 0 < a < n such that a is coprime
to n. So U(Zn) has order ϕ(n).
Example 3.3.10. Let us see some examples of U(Zn) for some n:
Z4 = {¯0, ¯1, ¯2, ¯3},
U(Z4) = {¯1, ¯3},
Z6 = {¯0, ¯1, ¯2, ¯3, ¯4, ¯5},
U(Z6) = {¯1, ¯5},
Z8 = {¯0, ¯1, · · · , ¯7},
U(Z8) = {¯1, ¯3, ¯5, ¯7}.
Notice that ϕ(4) = |U(Z4)| = 2, ϕ(6) = |U(Z6)| = 2, and ϕ(8) = |U(Z8)| = 4.
We conclude this section with an important theorem, whose scope will
be better appreciated when we shall be able to compute Euler function (see
Proposition 4.2.3).
Theorem 3.3.11 (Euler’s Theorem). If a and n are relatively prime, then
aϕ(n) ≡1
(mod n).
Proof. We have [a] ∈U(Zn), and the order of the group U(Zn) is ϕ(n).
So the claim follows from general group-theoretical properties (see Exercise
A3.37) which we recall in the following Remark 3.3.12 for the convenience of
the reader.
⊓⊔
Remark 3.3.12. It is convenient to recall here the group-theoretical properties used
in the proof of Euler’s Theorem.
Let G be a group and let x be an element of G. The elements of G of the form
xm, with m an integer, that is to say the powers of x, form a subgroup of G, denoted
by ⟨x⟩, known as the subgroup of G generated by x. If there exists in G an element
x such that G = ⟨x⟩, the group G is said to be cyclic.
Some general properties of cyclic groups which will be used again later in the
book are recalled in Exercises A3.23-A3.35.
Let G be a group and let x be an element of G. The element x is said to have
ﬁnite order if ⟨x⟩is ﬁnite; clearly, this happens if and only if there exists a positive
integer n such that xn = 1. The least positive integer n such that xn = 1 is said to
be the order or period of x and is denoted by ord(x). If x has not ﬁnite order, it is
said to have inﬁnite order. In other words, ord(x) is the order of the cyclic subgroup
⟨x⟩(see Exercise A3.28). If x has ﬁnite order, then xm = 1 for an integer m if and
only if ord(x) | m and so xi = xj if and only if i ≡j (mod ord(x)) (see Exercise
A3.27).
Now let G be a ﬁnite group and let H be a subgroup of G. Recall that Lagrange’s
theorem states that the order of H divides the order of G (see Exercise A3.36). In
particular, if G is ﬁnite, the order of any of its elements divides the order of the
group. So, if G has order n and x ∈G it is always true that xn = 1.
The original proof by Euler relies on the Fundamental Theorem of Arithmetic
and is given in the exercises.

126
3 From inﬁnite to ﬁnite
3.3.1 Powers modulo n
Given an integer a and two positive integers m and n, we want to compute
am
(mod n).
It is a kind of computation we shall frequenly need in the rest of the book.
Let us start with an example:
Example 3.3.13. Compute
1731 mod 58.
We may successively divide the exponent by 2, as follows:
1731 = (1715)
2 · 17 =

(177)
2 · 17
 2
· 17 =

(173)
2 · 17
 2
· 17
2
· 17 =
=

(172 · 17)
2 · 17
 2
· 17
2
· 17.
(3.7)
Then we carry out the operations reducing each time modulo n = 58. The reader
will easily verify (see Exercise B3.37) that
1731 ≡41
(mod 58).
Let us see a description of the steps we take, and from this we shall deduce a
general algorithm. In base 2, the number 31 is written
31 = (11111)2.
(3.8)
It is a 5-digit number. So write four (= 5 −1) letters E
E E E E
and, going from left rightwards, insert among them an M for each digit 1 we read
in (3.8), while for each 0 simply step forward by one place. The ﬁnal result will be
MEMEMEMEM.
(3.9)
We attribute now a meaning to the letters M and E. M denotes the multiplica-
tion by 17 (and its subsequent reduction modulo 58), while E (for “exponentiation”)
denotes the squaring (and reduction modulo 58). Now, apply the operation (3.9) to
1 (starting from the left), that is, evaluate
(1)MEMEMEMEM.
The result is exactly the last term in equalities (3.7).
Now we describe the algorithm in general and compute its complexity. Start
from the problem of reducing a power am modulo n when both the exponent m and
the modulo n are very large. Using this algorithm, we do not need to carry out m
multiplications of a times itself. We may assume a < n, and every time we carry
out a multiplication, we reduce the result modulo n. So we shall never work with
integers grater than n2.
Write the exponent m in base 2

3.3 Linear congruences
127
m = n0 + n1 · 2 + n2 · 22 + · · · + nk−1 · 2k−1,
with nj ∈{0, 1}; then
am = an0+n1·2+n2·22+···+nk−1·2k−1 = an0(a2)n1 · · ·

a2j nj · · ·

a2k−1 nk−1 .
At the beginning of the procedure we set p0 = 1. Then we perform k −1 steps
deﬁning successively p1, p2, . . . , pk−1, pk, ﬁnding at the end pk = am mod n.
If n0 = 1, then we set p1 = a, that is, we set p1 = a · p0 mod n, else we leave
p1 = 1.
Then we square a and set a1 = a2 mod n. If n1 = 1, then we set p2 = a1 ·
p1 mod n, else we leave p2 = p1.
Square now a1 and set a2 = a2
1 mod n. If n2 = 1, then set p3 = a2 · p2 mod n,
else leave p3 = p2.
By continuing in this way, in the jth step we compute
aj = a2j mod n.
If nj = 1, that is, if 2j appears in the binary expression of m, then pj+1 = aj ·
pj mod n, else we leave pj+1 = pj. After k −1 steps we get pk = am mod n.
We now compute the complexity of this algorithm, called exponentiation by
squaring or square-and-multiply: in each step we may have one or two multiplications
of numbers smaller than n2; so each step involves O(log2(n2)) = O(log2 n) bit
operations. There are k −1 steps, so the estimate of the time to compute am mod n
is
O((log m)(log2 n)).
Let us see another example.
Example 3.3.14. Compute 313 mod 7 using the method just described.
We have 13 = 1 + 22 + 23, so n0 = 1, n1 = 0, n2 = n3 = 1, k −1 = 3 and a = 3.
(1) Set p0 = 1.
(2) As n0 = 1, we set p1 = a = 3.
(3) Square a = 3 and reduce it modulo 7, obtaining a1 = 2. As n1 = 0, set p2 =
p1 = 3.
(4) Square a1 and reduce it modulo 7, obtaining a2 = 4. As n2 = 1, set p3 = a2p2 =
12 ≡5 mod 7.
(5) Square a2 and reduce it modulo 7, obtaining a3 = 2. As n3 = 1, set p4 = a3p3 =
10 ≡3 mod 7.
The result is p4, that is 3. The reader may verify that the result is right using
Euler’s theorem (see Exercise B3.38).
Remark 3.3.15. As suggested in Example 3.3.13, another way of carrying out the
algorithm is the following:
•
write the exponent m in base 2 as a sequence of 0 and 1;
•
write a sequence of L2(m) −1 letters E
E E E E · · · E



L2(m)−1
;

128
3 From inﬁnite to ﬁnite
•
beginning from the left, insert among the Es an M for each digit 1 we read in
the binary expression of m, while for each 0 simply step forward by one place;
the meaning of the letters is as follows: E (for “exponentiation”) denotes the
squaring and reduction modulo m, M denotes the multiplication by a and its
subsequent reduction modulo m;
•
the result is obtained by applying this sequence of Ms and Es to 1, starting from
the left.
Let us give an illustration of the above by computing 313 (mod 7). We have
m = 13 and 13 = (1101)2. As L2(13) = 4, write three letters E
E E E
Now, by inserting as many letters M from the left, as the 1s in the expression of m
and just stepping forward for each 0, we get
MEMEEM.
Compute now
(1)MEMEEM,
where M means multiplying by 3, and E squaring: we get back
((32 · 3)2)2 · 3 ≡3
(mod 7).
We have used again the operators introduced in the previous example: the op-
erations we need are multiplying by a = 3 (M) and squaring (E).
Remark 3.3.16. When computing am mod n it may happen that a and n are rel-
atively prime. In this case in order to simplify the calculations we might use Euler’s
theorem 3.3.11, but this implies knowing how to evaluate the Euler function ϕ(n).
If we know ϕ(n) and if GCD(a, n) = 1, then it may be veriﬁed that the complexity
of computing am mod n becomes O(log3 n) (see Exercise A3.38).
3.4 The Chinese remainder theorem
Suppose we have to count quickly the students in a school but we have not
time for calling each of them individually. We only know that there are less
than 1000 of them. What can we do?
The solution to this problem is ancient and amounts to the so-called Chi-
nese remainder theorem, which appears in Chinese texts from the ﬁrst century
CE. This theorem allows us to solve a system of linear congruences, which we
may translate our original problem into.
So, consider the following system:
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
a1x ≡b1
(mod n1),
a2x ≡b2
(mod n2),
...
asx ≡bs
(mod ns).
(3.10)

3.4 The Chinese remainder theorem
129
Solving this system means ﬁnding an integer x0 such that
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
a1x0 ≡b1
(mod n1),
a2x0 ≡b2
(mod n2),
...
asx0 ≡bs
(mod ns).
(3.11)
Such an integer x0 is said to be a solution of system 3.10 and, if a solution
exists, the system is said to be solvable or compatible. So, if even one of the
equations is not solvable, the whole system does not admit solutions. The
problem is easily solved when GCD(ni, nj) = 1 for all pairs (i, j) with i ̸= j.
Lemma 3.4.1. Consider a system of the form (3.10) consisting of solvable
congruences and such that GCD(ni, nj) = 1 for all pairs (i, j) such that i ̸= j.
Then solving (3.10) is equivalent to solving a system of the form
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
x ≡c1
(mod r1),
x ≡c2
(mod r2),
...
x ≡cs
(mod rs)
(3.12)
with GCD(ri, rj) = 1 for all pairs (i, j) such that i ̸= j.
Proof. For the system (3.10) to admit solutions we must necessarily have
dk = GCD(ak, nk) | bk, for all k = 1, . . . , s. If these conditions are satisﬁed,
we may divide the kth congruence by dk, obtaining
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
a′
1x ≡b′
1
(mod r1),
a′
2x ≡b′
2
(mod r2),
...
a′
sx ≡b′
s
(mod rs),
(3.13)
where a′
k = ak/dk, b′
k = bk/dk and rk = nk/dk and the condition GCD(ri, rj) =
1 still holds for each pair (i, j) such that i ̸= j. Notice that the new system
(3.13) is equivalent to the previous one, in the sense the they both admit the
same solutions.
Notice now that GCD(a′
k, rk) = 1, for all k = 1, . . . , s; so, by Corollary
3.3.6, each of the congruences of the system admits a unique solution ck
modulo rk. Thus we may substitute (3.12) for system (3.13).
⊓⊔
So we study now systems of congruences of the form (3.12).
Theorem 3.4.2 (Chinese remainder theorem). A systems of congruences
(3.12), with GCD(ri, rj) = 1 for all pairs (i, j) with i ̸= j, admits a solution.
This solution is unique modulo R = r1r2 · · · rs.

130
3 From inﬁnite to ﬁnite
Proof. Let Rk = R/rk. As GCD(ri, rj) = 1 for all pairs (i, j) with i ̸= j, we
have, by repeatedly applying Corollary 1.3.7, that GCD(Rk, rk) = 1 for all
k = 1, . . . , s. So, for each k = 1, . . . , s, the congruence
Rkxk ≡ck
(mod rk)
admits a unique solution modulo rk which will be denoted by ¯xk. Thus the
number
¯x = R1¯x1 + R2¯x2 + · · · + Rs¯xs
is a solution of the system (3.12). Indeed, as Ri is a multiple of rk for i ̸= k,
we have
Ri ≡0
(mod rk)
for i ̸= k,
and so
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
¯x ≡R1¯x1 ≡c1
(mod r1),
¯x ≡R2¯x2 ≡c2
(mod r2),
...
¯x ≡Rs¯xs ≡cs
(mod rs).
As to the unicity modulo R, let ¯y be another solution of the system; in
other words, assume that
¯x ≡ck ≡¯y
(mod rk),
for k = 1, . . . , s.
Then ¯x −¯y ≡0 (mod rk), for k = 1, . . . , s; hence ¯x −¯y ≡R 0 (see Corollary
1.3.8).
⊓⊔
Remark 3.4.3. Analogously it can be seen that, if we want to solve a system
of the form
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
a1x ≡b1
(mod r1),
a2x ≡b2
(mod r2),
...
asx ≡bs
(mod rs).
with GCD(ai, ri) = 1 for all i = 1, . . . , s and GCD(ri, rj) = 1 for all pairs
(i, j) such that i ̸= j, then the solution is
¯x = R1¯x1 + R2¯x2 + · · · + Rs¯xs
where ¯xk satisﬁes akRk¯xk ≡bk (mod rk), for all k = 1, . . . , s.
Example 3.4.4. Let us study again the example about students we started
with. In order to count them, it is suﬃcient to request the children to line up
5 abreast, then 8, then 19, and to count each time how many students are not
lined up: these remainders ci, for i = 1, 2 and 3, are smaller than 5, 8, and
19, respectively. Then the system

3.4 The Chinese remainder theorem
131
⎧
⎪
⎨
⎪
⎩
x ≡c1
(mod 5),
x ≡c2
(mod 8),
x ≡c3
(mod 19),
is solved. By the Chinese remainder theorem, it admits a unique solution
modulo R = 5 · 8 · 19 = 760. This solution is the total number of students.
Suppose, for example, that lining up the students ﬁve abreast, one of them
is not lined up, when eight abreast, 2 are not lined up, and when 19 abreast,
3 are not lined up. Then c1 = 1, c2 = 2 and c3 = 3. In this case the number
of the students is found by ﬁnding the solution, unique modulo 760, of the
system
⎧
⎪
⎨
⎪
⎩
x ≡1
(mod 5),
x ≡2
(mod 8),
x ≡3
(mod 19).
(3.14)
So, how many students are there? The proof itself of the Chinese remainder
theorem tells us how to ﬁnd the solution. Indeed, we have R1 = 8 · 19 = 152,
R2 = 5 · 19 = 95, R3 = 5 · 8 = 40; so, a solution is 3 · 152 + 6 · 95 + 11 · 40 =
1466 ≡706 mod 760. As 706 is the only solution smaller than 1000, this is the
number we were looking for.
There is a useful consequence or, rather, a diﬀerent interpretation of the
Chinese remainder theorem. Let Zr × Zs be the Cartesian product of Zr and
Zs. As Zr and Zs are rings, the set Zr ×Zs itself is in a natural way a product
ring, in which the operations are deﬁned by
(¯ar,¯bs) + (¯cr, ¯ds)
def
= (¯ar + ¯cr,¯bs + ¯ds),
(¯ar,¯bs) · (¯cr, ¯ds)
def
= (¯ar · ¯cr,¯bs · ¯ds).
The following proposition is an immediate consequence of the Chinese remain-
der theorem.
Proposition 3.4.5. Let r and s be two relatively prime integers greater than
1. The map
f : Zrs −→Zr × Zs,
deﬁned by
f([x]rs) = ([x]r, [x]s),
is a ring isomorphism.
Proof. By the Chinese remainder theorem the system of congruences

x ≡a
(mod r),
x ≡b
(mod s)
admits exactly one solution modulo rs. This implies the surjectivity and the
injectivity of the map. The fact that this map preserves the operations is left
to the reader (see Exercise A3.40).
⊓⊔

132
3 From inﬁnite to ﬁnite
Example 3.4.6. We write explicitly the correspondence f in the case r = 2
and s = 3.
Z6
Z2
Z3
0
0
0
1
1
1
2
0
2
3
1
0
4
0
1
5
1
2
The map deﬁned in Proposition 3.4.5 may also be described as follows.
Write down all the elements of Zrs in a column. Next to it, in a second
column write down s times the elements of Zr. In a third column write down
r times the elements of Zs. The correspondence f associates to each element
of Zrs the pair in Zr × Zs that can be read on its right. The reader will easily
be able to check this result.
Proposition 3.4.5 has an important application in computer science, as it
allows to translate calculations in Zn into independent calculations in several
Zni, for i = 1, . . . , r, when n = n1n2 · · · nr, with GCD(ni, nj) = 1 for i ̸= j.
The following example allows us to fully appreciate the advantages of this
method.
Example 3.4.7. Assume we have to carry out some operations in Z21: in
particular we have to multiply the class 17 by the class 19. As 21 = 3 · 7, with
GCD(3, 7) = 1, rather than performing the calculations in Z21, we may use
the correspondence f of Proposition 3.4.5, which we explicitly write down in
table 3.1 for the convenience of the reader.
Table 3.1. Identifying Z21 with Z3 × Z7
Z21
Z3
Z7
0
0
0
1
1
1
2
2
2
3
0
3
4
1
4
5
2
5
6
0
6
Z21
Z3
Z7
7
1
0
8
2
1
9
0
2
10
1
3
11
2
4
12
0
5
13
1
6
Z21
Z3
Z7
14
2
0
15
0
1
16
1
2
17
2
3
18
0
4
19
1
5
20
2
6
It can be seen from the table that 17 is identiﬁed with the pair (¯23, ¯37),
while 19 is identiﬁed with (¯13, ¯57). Then, rather than carrying out the product
17·19 in Z21, it suﬃces to carry out the product ¯2·¯1 in Z3 and the product ¯3·¯5

3.5 Examples
133
in Z7. So we get the pair (¯23, ¯17), which corresponds to the element ¯8 of Z21,
the same class we would get by making calculations in Z21. As the operations
in Z3 and in Z7 can be performed separately, that is, they are independent
from each other, we can for example use two diﬀerent computers working in
parallel.
3.5 Examples
3.5.1 Perpetual calendar
As a simple application of congruences, consider the drawing up of a calendar.
Congruences are well suited to this application due to the periodicity of the years’
structure.
Suppose we want to know the day of the week corresponding to a given date:
for instance, we might want to know which day of the week corresponded to 5 May
1851.
Clearly, the answer depends on how we measure time. Recall that a calendar is an
organisation of time for civil or rerligious purposes, ﬁxed according to astronomical
phenomena. In solar calendars, like the Julian one, one year corresponds to the time
it takes the Earth to complete one orbit around the Sun. This kind of calendar is
used in Europe and in America.
The Julian calendar, introduced by Julius Caesar in 46 BCE, considered the year
to be exactly 365 days long and added a day every four years, obtaining a leap year
366 days long, to allow for what then was deemed to be the true length of a year,
that is to say 365 days and 6 hours. But this was just a rough approximation of the
year’s real duration, which is actually 365.2422 days, slightly shorter than the one
Julius Caesar knew. Using that approximation caused, over the centuries, an ever
increasing gap between the civil and the astronomical calendar, so much so that the
former did not agree with the important dates of the latter: in particular, equinoxes
and solstices, and so the beginning of the seasons, did not fall in the corresponding
days.
So it was necessary to introduce a correction, brought about in 1582 by Pope
Gregory XIII, whose astronomers observed that the civil calendar was ten days
behind the astronomical one. Pope Gregory decided with a papal bull promulgated
from Villa Mondragone in Frascati (near Rome), which presently is a property of
“Tor Vergata” University of Rome, that these ten days were to be deleted, so that 5
October 1582 was immediately followed by 15 October 1582. Moreover, he declared
the leap years to be all years divisible by 4, with the exception of those divisible
by 100, that were to be leap years only if divisible by 400. So the years 1700, 1800,
1900 were not leap years, while 1600 and 2000 were. Thus, the year’s measure is
almost the actual one: there is an error of just 3 days per 10000 years! The resulting
calendar, the one we use today, was called Gregorian calendar.
So we tackle our problem using the Gregorian calendar. As the extra day in
leap years is added at the end of February by convention, it is convenient to give
a number to each month starting from March: so January and February will be
reckoned in the previous year.
For instance, we shall consider February 1952 as the twelfth month of 1951, while
October 1952 will be the eighth month of 1952.

134
3 From inﬁnite to ﬁnite
We shall do something similar for the days of the week, assigning a number to
each of them beginning with zero, corresponding to Sunday. For the convenience of
the reader we give explicitly the correspondence tables for days and months in Table
3.2.
Table 3.2. Numbering of days and months
Sunday
= 0
March = 1
September = 7
Monday
= 1
April
= 2
October
= 8
Tuesday
= 2
May
= 3
November = 9
Wednesday = 3
June
= 4
December = 10
Thursday
= 4
July
= 5
January
= 11
Friday
= 5
August = 6
February
= 12
Saturday
= 6
As the days of the weeks repeat every seven days, in tackling our problem it will
be necessary to count modulo 7. This way, the same day in each week will always
be identiﬁed by the same number. Denote now by
d = day of the month,
m = month,
y = year,
c = century,
n = years in the century.
For instance, if we talk about 1 April 1673, then d = 1, m = 2 and y = 1673 = 100c+
n, where c = 16 and n = 73. Now, denote by x the day of the week corresponding the
the data (d, m, y). Using the ﬁrst day of March 1600 as our starting point, compute
successively:
•
the day of the week dy of 1 March in any year y, with y ≥1600;
•
the day of the week of the ﬁrst day of any month of any year;
•
the day of the week of any day in any month of any year.
As there are 366 or 365 days between 1 March of year y −1 and 1 March of year
y, depending on y being a leap year or not, clearly the following recurrence relation
holds:

dy ≡7 dy−1 + 366 ≡7 dy−1 + 2
if y is a leap year,
dy ≡7 dy−1 + 365 ≡7 dy−1 + 1
if y is not a leap year.
In conclusion,
dy ≡d1600 + (y −1600) + l
(mod 7),
where l is the number of leap year between 1600 exclusive (as we start from 1 March)
and year y inclusive, while y −1600 is the number of years between 1600 and year
y.
In order to compute l we have to ﬁnd all numbers of the form 1600 + p with
1 ≤p ≤y −1600 that are divisible by 4, remove from these the numbers divisible
by 100 and add again those divisible by 400.
Dividing y −1600 by 4 we ﬁnd
y −1600 = q · 4 + r

3.5 Examples
135
with 0 ≤r < 4; so { 4, 8, . . . , 4q } is the set of positive numbers smaller than or
equal to y −1600 that are divisible by 4. There are exactly q of them, with
q =
y −1600
4

.
So we have
l =
 y −1600
4

−
y −1600
100

+
y −1600
400

=
=
$y
4
%
−400 −
$ y
100
%
+ 16 +
$ y
400
%
−4 =
$y
4
%
−
$ y
100
%
+
$ y
400
%
−388
so, keeping in mind that y = 100 · c + n, in terms of c and n we ﬁnd
dy ≡d1600 −2c + n +
$ c
4
%
+
$n
4
%
−3 −1600
(mod 7) ≡
≡d1600 −2c + n +
$ c
4
%
+
$n
4
%
(mod 7).
Now we are able to compute dy for any year y, as soon as we know d1600. But to do
so, it is suﬃcient to have a look at a recent calendar and learn that 1 March 2006
falls on a Wednesday, that is to say, d2006 = 3. As for y = 2006 = 100 c + n we have
c = 20, n = 6, from what precedes we get 3 ≡d1600 −40 + 6 + 5 + 1 (mod 7), and
so d1600 ≡31 ≡3 (mod 7), that is to say, 1 March 1600 was a Wednesday. So we
get the general formula
dy ≡3 −2c + n +
$ c
4
%
+
$ n
4
%
(mod 7).
(3.15)
Now, reasoning in the same way, we may compute the day of the week corresponding
to the ﬁrst day of an arbitrary month. For instance, if 1 October of year y falls on
a Thursday, then 1 November of the same year falls on a Sunday. Indeed, denote
by t the day of the week corresponding to the ﬁrst of November: then we have
t ≡4 + 31 (mod 7), as October has 31 days, Thursday corresponds to the number
4, and t = 3 + 4 = 7 ≡0 (mod 7) represents Sunday. In conclusion, the ﬁrst of the
month is found by adding a ﬁxed amount of days, depending on the length of the
month, to the ﬁrst of previous month. In detail, we have
form 1 March to 1 April
we must add 3 days,
from 1 April to 1 May
”
2 days,
from 1 May to 1 June
”
3 days,
from 1 June to 1 July
”
2 days,
from 1 July to 1 August
”
3 days,
from 1 August to 1 September
”
3 days,
from 1 September to 1 October
”
2 days,
from 1 October to 1 November
”
3 days,
from 1 November to 1 December
”
2 days,
from 1 December to 1 January
”
3 days,
from 1 January to 1 February
”
3 days.
The function that represents the increment described is
13m −1
5

−2.

136
3 From inﬁnite to ﬁnite
This may be veriﬁed by simply substituting for m the values corresponding to the
months.
In conclusion, if we denote by x the day of the week we intend to compute and
which corresponds to the data d, m, y, we get the required formula by adding d −1
(days) to the formula that gives the day of the week corresponding to the ﬁrst day
of the same month and year, that is to say,
x ≡d −1 +
 13m −1
5

−2 + 3 −2c + n +
$ c
4
%
+
$n
4
%
(mod 7) ≡
≡d +
13m −1
5

−2c + n +
$ c
4
%
+
$n
4
%
(mod 7).
As an example, we show how to compute the day of the week corresponding to
9 May 1973. As d = 9, m = 3 e 1973 = 100c + n with c = 19 and n = 73 we get
x ≡9 + 7 −38 + 73 + 4 + 18 ≡3
(mod 7),
that is to say, that day was a Wednesday.
3.5.2 Round-robin tournaments
We want to draw up the schedule for a tournament involving N football teams (or
of any other team sport) in which each team is to play each other team exactly once.
If N is odd, as each play involves exactly two teams, we add a ﬁctitious team and
make the team playing it sit out that round. This way, no team is at an advantage
and we may suppose N to be an even number. Clearly, the number of rounds to be
scheduled in such a way that each team may play each of the others exactly once is
N −1.
Assign the numbers from 1 to N to the teams and suppose we want to schedule
the games of the kth round, with 1 ≤k ≤N −1. If 1 ≤i ≤N −1, have team i play
team j if
i + j ≡k
(mod (N −1)).
(3.16)
This assigns to each team a single adversary team in the kth round, unless the team
has as number the value of i for which 2i ≡k (mod (N −1)). As N −1 is odd, this
congruence has a unique solution. This determines the single team that in the kth
round will play team N.
We leave to the reader the easy task of checking that the rule just described
actually has the eﬀect of having each team play each other team exactly once in the
N −1 rounds (see Exercise A3.42).
Appendix to Chapter 3
A3 Theoretical exercises
A3.1. Prove that the congruence relation modulo n given in Deﬁnition 3.1.1 is an
equivalence relation, that is to say, it is reﬂexive, symmetric and transitive.

A3 Theoretical exercises
137
A3.2. Recall that a relation R on a set A is a subset of A × A. It is customary to
write a R b to mean that (a, b) ∈R. A relation R is said to be reﬂexive if a R a for
all a ∈A. We say that R is symmetric if a R b implies that b R a, for all a, b ∈A.
Finally, R is said to be transitive if a R b and b R c imply that a R c, for all a, b,
c ∈A. A relation R is said to be an equivalence relation if it is reﬂexive, symmetric
and transitive.
Prove that the conditions deﬁning an equivalence relation are independent, by
giving examples of a:
(a) reﬂexive and symmetric, but not transitive, relation;
(b) reﬂexive and transitive, but not symmetric, relation;
(c) symmetric and transitive, but not reﬂexive, relation.
A3.3. Recall that a relation R in a set A is said to be antisymmetric if a R b and
b R a imply that a = b, for all a, b ∈A. An order relation is a reﬂexive, antisymmetric
and transitive relation.
Let R be the following relation deﬁned on natural numbers: a R b if and only if
there exists a natural number c such that b = ac. Is it an order relation? And what
if we consider the same relation R on integer numbers?
A3.4. Prove that the residue classes modulo the positive integer n are exactly the
n classes described on page 116.
A3.5. Prove Proposition 3.1.4 on page 117.
A3.6. Prove that the operations deﬁned in Zn, with n ≥1, on page 117 are well-
deﬁned and make Zn a ring with unity.
A3.7.* Let A be a ring and I an ideal of A. Prove that ≡I is an equivalence relation.
A3.8.* Let A be a ring and I an ideal of A. Prove that Equations (3.2) hold.
A3.9.* Let A be a ring and I a proper ideal of A. Prove that the operations deﬁned
in A/I on page 118 in Remark 3.1.6 are well-deﬁned and make A/I a ring.
A3.10.* Let A be a commutative ring with unity and I an ideal of A. Consider the
map π : A →A/I that associates with each a ∈A its class in A/I. Prove that if J is
an ideal of A/I then π−1(J) is an ideal of A containing I and, vice versa, that if K is
an ideal of A containing I then π(K) is an ideal of A/I such that π−1(π(K)) = K.
A3.11. Prove that in Z the following cancellation property holds:
if ac = bc and c ̸= 0, then a = b.
(3.17)
Prove that this cancellation property holds, more generally, in any integral domain.
A3.12.* Let A be a ring with unity and I a proper ideal of A. Prove that A/I is
an integral domain if and only if I is a prime ideal.
A3.13. Prove Proposition 3.1.11.
A3.14. Is it true that Zn is a ﬁeld if and only if it is an integral domain?
(a) Yes, because a commutative ring with unity is a ﬁeld if and only if it is an
integral domain with unity.
(b) Yes.

138
3 From inﬁnite to ﬁnite
(c) No.
(d) No, because there are integral domains that are not ﬁelds.
A3.15. Is it true that Zn is a ﬁeld if and only if n is a prime number?
(a) Yes.
(b) No.
(c) No, because Zn being a ﬁeld does not imply n being a prime.
(d) None of the above.
A3.16. Fix a positive integer b and associate with each integer number n, written
in base b as (ah . . . a1a0)b, and consequently of length h+ 1, the polynomial fn(x) =
a0 + a1x + · · · + ahxh of degree h in Zb[x]. Prove that the map f : N →Zb[x] so
deﬁned is a bijection but it is not true in general that
fn+m(x) = fn(x) + fm(x),
nor
fn·m(x) = fn(x) · fm(x).
A3.17. Prove that the complexity of adding up two polynomials of degree at most
m in Zn[x] is O(m log n).
A3.18. Prove that the complexity of multiplying two polynomials of degree at most
m in Zn[x] is O(m2 log2 n).
A3.19. Describe a “casting out elevens” procedure to verify computations with base
10 numbers.
A3.20.* Prove that for any positive integer n we have (b −1) | bn −1 and (b + 1) |
(bn + (−1)n+1). Deduce a test of divisibility for b −1 and one for b + 1 based on the
digits of integer numbers written in base b. (Hint: mimic the b = 10 case.)
A3.21. Find a procedure to carry out casting out nines or casting out elevens in an
arbitrary base b.
A3.22.* Use the congruence 40 ≡1 (mod 13) to deduce a test of divisibility for 13.
In the exercises that follow some useful properties of cyclic groups are recalled.
The group operation will usually be written multiplicatively.
A3.23. Prove that (Z, +) is an inﬁnite cyclic group. Prove that (Zn, +) is a cyclic
group of order n.
A3.24.* Prove that an inﬁnite cyclic group is isomorphic to the additive group of
Z, while a cyclic group of order n is isomorphic to the additive group of Zn.
A3.25.* Prove that a subgroup of a cyclic group is itself cyclic.
A3.26.* If G is a cyclic group generated by an element x and has ﬁnite order n,
prove that the elements of G are 1, x, x2, . . . , xn−1.
A3.27.* Let x be an element of period m of a group G. Prove that xn = 1 if and
only if m | n.

A3 Theoretical exercises
139
A3.28.* Let x be an element of ﬁnite order m of a group G. Prove that the powers
of x form a cyclic subgroup of G of order m.
A3.29.* If G is a cyclic group generated by an element x and has ﬁnite order n,
prove that xh = xk if and only if h ≡k (mod n). In particular, xm = 1 if and only
if n | m.
A3.30.* If G is a cyclic group generated by an element x and has ﬁnite order n,
the element xm is a generator of G if and only if GCD(m, n) = 1. Deduce that in G
there are ϕ(n) distinct generators.
A3.31.* If G is an inﬁnite cyclic group generated by an element x, then the only
generators are x and x−1.
A3.32.* If G is a cyclic group generated by an element x and has ﬁnite order n,
and if d is a divisor of n, then there exists exactly one subgroup of G of order d.
A3.33.* Let G be a cyclic group generated by an element x and having ﬁnite order
n. Let n = dm. The element xh has order d if and only if h ≡mi (mod n) with
GCD(i, d) = 1. Deduce that in G there are ϕ(d) distinct elements of order d.
A3.34.* Let G be a cyclic group generated by an element x and having ﬁnite order
n, and let y1 = xn1 and y2 = xn2 be two elements of G. Find the integers m, if any,
such that ym
1 = y2.
A3.35.* If G is an inﬁnite cyclic group, every subgroup of G other than (1) is inﬁnite
cyclic.
A3.36.* Prove Lagrange’s theorem: if G is a ﬁnite group and H is a subgroup of G,
then the order of H divides the order of G.
A3.37.* Prove Euler’s Theorem as a consequence of the fact that the period of an
element divides the order of a ﬁnite group.
A3.38. Prove that if we know ϕ(n) and if GCD(a, n) = 1, then the complexity of
computing am mod n is O(log3 n).
A3.39. Consider the system of congruences

x ≡a
(mod n),
x ≡b
(mod m),
where we are not assuming GCD(n, m) = 1. Find the conditions for the system to
be solvable. (Hint: the solvability is equivalent to the existence of an integer t such
that a −b + tn ≡0 (mod m). Then apply Proposition 3.3.4).
A3.40. Prove that the map f deﬁned in Proposition 3.4.5 preserves the sum and
the product, that is to say f(y + z) = f(y) + f(z) and f(yz) = f(y)f(z) for all
y, z ∈Zrs.
A3.41. Extend Proposition 3.4.5 to more than two factors, that is to say, prove
that if r1, . . . , rs are positive integers relatively prime to each other, if we deﬁne
r = r1 · · · rs, then the map
[x]r ∈Zr →([x]r1, . . . , [x]rs) ∈Zr1 × · · · × Zrs
is a ring isomorphism.
A3.42. Verify that, following the rule described on page 136, each of the N teams
play all the other teams once each over the N−1 rounds of a round-robin tournament.

140
3 From inﬁnite to ﬁnite
B3 Computational exercises
B3.1. How many elements are there in Z1472?
(a) No element.
(b) 1471.
(c) 1472.
(d) None of the above.
B3.2. Which of the following equals 36728 mod 11?
(a) 10.
(b) 5.
(c) 1.
(d) None of the above.
B3.3. Are there zero-divisors in Z6?
(a) No.
(b) Yes, there are exactly two zero-divisors.
(c) Yes, there are exactly three zero-divisors.
(d) None of the above.
B3.4. Are there zero-divisors in Z19?
(a) No.
(b) Yes, there are exactly three zero-divisors.
(c) Yes, there are exactly nine zero-divisors.
(d) None of the above.
B3.5. Is it true that Z27 is a ﬁeld?
(a) Yes.
(b) No.
(c) No, it is not, even if it is zero-divisor free.
(d) None of the above.
B3.6. Determine the last digit of the number 725843594.
B3.7. Find the residue class modulo 9 of 746h, when h varies in N.
B3.8. Find the remainder of the division by 10 of the number 4381620321.
B3.9. Find the remainder of the division by 6 of the number 29345362971.
B3.10. Find the remainder of the division by 6 of the number 36297129345.
B3.11. In which residue class modulo 9 is 725843594?
B3.12. Which is the remainder of the division of 239487192387 by 6?
(a) 3.
(b) 2.
(c) 1.
(d) None of the above.

B3 Computational exercises
141
B3.13. Which is the remainder of the division of 75746322845301 by 7?
(a) 2.
(b) 3.
(c) 4.
(d) None of the above.
B3.14. Which is the remainder of the division of 75746322845301 by 11?
(a) 0.
(b) 1.
(c) 10.
(d) None of the above.
B3.15. Find the inverse, if it exists, of the following classes in Z8: ¯6, ¯3.
B3.16. Which is the inverse of 4 modulo 9?
(a) 4 is not invertible.
(b) 5.
(c) 7.
(d) None of the above.
B3.17. Which is the inverse of 4 modulo 18?
(a) 4 is not invertible.
(b) 11.
(c) 15.
(d) None of the above.
B3.18. Find the last two digits of all the numbers x ≥0 such that

3x ≡1
(mod 4),
2x ≡3
(mod 25).
B3.19. Without carrying out the division, determine whether the number
129873498712738753786
is divisible by 11.
(a) No, it is not divisible by 11.
(b) It is impossible to say without carrying out the division.
(c) Yes, it is divisible by 11.
(d) None of the above.
B3.20. Is the operation 273498 · 587234 = 160607234532 correct?
(a) Yes, it is correct, as it satisﬁes the ‘casting out nines’ procedure.
(b) Yes, it is correct.
(c) No, it is not correct, as it does not satisfy the ‘casting out nines’ procedure.
(d) No, it is not correct, even though it satisﬁes the ‘casting out nines’ procedure.

142
3 From inﬁnite to ﬁnite
B3.21. Determine whether the base 2 number 100100110 is divisible by 2, 4, 3.
B3.22. Determine whether the base 3 number 12002122 is divisible by 2, 3, 9, 4.
B3.23. Determine a test of divisibility by 3 that uses the digits of numbers written
in base 9.
B3.24. Determine all the solutions of the congruence
3x ≡5
(mod 4).
(a) x = 3 + 4k, for all k ∈Z.
(b) x = 1 + 2k, for all k ∈Z.
(c) It does not admit any solution.
(d) None of the above.
B3.25. Determine all the solutions of the congruence
3x ≡9
(mod 6).
(a) x = 3 + 6k, for all k ∈Z.
(b) x = 1 + 2k, for all k ∈Z.
(c) It does not admit any solution.
(d) None of the above.
B3.26. Determine all the solutions of the congruence
4x ≡7
(mod 9).
(a) x = −5 + 9k, for all k ∈Z.
(b) x = 1 + 3k, for all k ∈Z.
(c) x = 5 + 9k, for all k ∈Z.
(d) None of the above.
B3.27. Determine all the solutions of the congruence
6x ≡8
(mod 9).
(a) x = 3 + 9k, for all k ∈Z.
(b) x = −1 + 3k, for all k ∈Z.
(c) It does not admit any solution.
(d) None of the above.
B3.28. Determine all the solutions of the congruence
4x ≡3
(mod 385).
(a) x = 74 + 385k, for all k ∈Z.
(b) x = 75 + 385k, for all k ∈Z.
(c) x = −1 + 385k, for all k ∈Z.
(d) None of the above.

B3 Computational exercises
143
B3.29. Construct, if possible, a linear congruence of the form
ax ≡b
(mod 319)
admitting exactly 11 solutions that are not congruent to each other modulo 319.
Then determine all the solutions of such a congruence.
B3.30. Determine two integers a and b (if it is possible) in such a way that the
congruence
ax ≡b
(mod 299)
has exactly 13 non-congruent solutions modulo 299. If such a and b are found, solve
the congruence and determine all the solutions.
B3.31. Determine all the solutions of the linear congruence
128x ≡10
(mod 17).
(a) It does not admit any solution.
(b) 3 + 17k, per ogni k ∈Z.
(c) 5 + 17k, per ogni k ∈Z.
(d) None of the above.
B3.32. Determine all the solutions of the linear congruence
3128x ≡3
(mod 1024).
(a) It does not admit any solution.
(b) 513 + 1024k, for all k ∈Z.
(c) 1007 + 1024k, for all k ∈Z.
(d) None of the above.
B3.33. Determine all the solutions of the linear congruence
2047x ≡3
(mod 1024).
(a) 3 + 1024k, for all k ∈Z.
(b) 319 + 1024k, for all k ∈Z.
(c) 1021 + 1024k, for all k ∈Z.
(d) None of the above.
B3.34. B3.35. Determine all the solutions of the linear congruence
2047x ≡1022
(mod 1024).
(a) 2 + 1024k, for all k ∈Z.
(b) 3 + 1024k, for all k ∈Z.
(c) −1 + 1024k, for all k ∈Z.
(d) None of the above.

144
3 From inﬁnite to ﬁnite
B3.36. Find the remainder of the division by 17 of
190597.
B3.37. Verify that 1731 ≡41 (mod 58).
B3.38. Prove that 313 ≡3 (mod 7) by using Euler’s Theorem.
B3.39. Which of the following equals 4065 mod 199?
(a) 5.
(b) 71.
(c) 193.
(d) None of the above.
B3.40. Which of the following equals 2733 mod 157?
(a) 2.
(b) 64.
(c) 82.
(d) None of the above.
B3.41. Which of the following equals 3196 mod 359?
(a) 1.
(b) 79.
(c) 283.
(d) None of the above.
B3.42. Consider the system of congruences

x ≡3
(mod 5),
x ≡7
(mod 9).
Does this system admit solutions? If it does, which are the solutions?
(a) Yes, the solutions are x = −34 + 45k, for all k ∈Z.
(b) Yes, the solutions are x = 34 + 45k, for all k ∈Z.
(c) Yes, the solutions are x = 43 + 45k, for all k ∈Z.
(d) None of the above.
B3.43. Consider the system of congruences
⎧
⎪
⎨
⎪
⎩
1025x ≡5312065
(mod 8),
36x ≡322
(mod 5),
4x ≡7
(mod 3).
Does this system admit solutions? If it does, which are the solutions?
(a) Yes, the solutions are x = 77 + 120k, for all k ∈Z.
(b) Yes, the solutions are x = −21 + 120k, for all k ∈Z.
(c) Yes, the solutions are x = 82 + 120k, for all k ∈Z.
(d) None of the above.

B3 Computational exercises
145
B3.44. Determine all the solutions of the system of linear congruences

3x ≡65
(mod 7),
11x ≡4
(mod 17).
(a) 111 + 119k, for all k ∈Z.
(b) 11 + 119k, for all k ∈Z.
(c) −12 + 119k, for all k ∈Z.
(d) None of the above.
B3.45. Determine all the solutions of the system of linear congruences
⎧
⎪
⎨
⎪
⎩
2x ≡1
(mod 3),
8x ≡7
(mod 11),
5x ≡3
(mod 13).
(a) There are no solutions.
(b) 368 + 429k, for all k ∈Z.
(c) 5 + 429k, for all k ∈Z.
(d) None of the above.
B3.46. Determine all the solutions of the system of linear congruences
⎧
⎪
⎨
⎪
⎩
2x ≡4
(mod 6),
8x ≡3
(mod 13),
12x ≡1
(mod 18).
(a) There are no solutions.
(b) 107 + 351k, for all k ∈Z.
(c) −107 + 351k, for all k ∈Z.
(d) None of the above.
B3.47. Determine all the solutions of the system of linear congruences
⎧
⎪
⎨
⎪
⎩
4x + 2 ≡3x −1
(mod 5),
6x −3 ≡2(x −1)
(mod 7),
2x ≡1
(mod 3).
(a) 57 + 105k, for all k ∈Z.
(b) 101 + 105k, for all k ∈Z.
(c) −103 + 105k, for all k ∈Z.
(d) None of the above.
B3.48. Each Saturday morning, Mrs Smith does the shopping for her family, while
every ﬁve days she baths her puppy. This week she bathed her puppy on a Sunday
(11 March). When will she ﬁrst (if ever) have to do the shopping and bathing the
puppy on the same day?
B3.49. We are rearranging the books of a library. By stacking them 11 at a time,
four books are left out; stacking them 13 at a time, ﬁve books are left out; and, by

146
3 From inﬁnite to ﬁnite
stacking them 17 at a time, a single book is left out. If we know that in the library
there are less than 2500 books, is it possible to ﬁnd the exact number of books?
B3.50. We have a tray full of sweets and we know that there are less then 200 of
them. Moreover, we know that by dividing them in 11 shares two sweets are left out,
dividing them in 5 shares three are left out, while dividing them in three shares no
one is left out. Find the number of sweets on the tray.
(a) 123.
(b) 138.
(c) 153.
(d) None of the above.
B3.51. If from a box full of buttons they are removed two at a time, three at a
time, four at a time, ﬁve at a time, or six at a time, in the box is always left a single
button. If they are removed seven at a time, no button remains. Which is the least
number of buttons the box can possibly contain?
(a) 241.
(b) 601.
(c) 301.
(d) None of the above.
B3.52. Solve the system of congruences
⎧
⎪
⎨
⎪
⎩
−11 · x ≡117
(mod 4),
395 · x ≡−7
(mod 3),
18 · x ≡−25
(mod 7).
B3.53. What day of the week did 31 December 2000 fall on?
(a) Thursday.
(b) Friday.
(c) Saturday.
(d) Sunday.
B3.54. What day of the week did 28 February 2004 fall on?
(a) Thursday.
(b) Friday.
(c) Saturday.
(d) Sunday.
B3.55. What day of the week did 14 July 1789 fall on?
(a) Saturday.
(b) Sunday.
(c) Monday.
(d) Tuesday.
B3.56. What day of the week will 1 January 3001 fall on?
(a) Sunday.
(b) Monday.
(c) Tuesday.
(d) Thursday.
B3.57. Draw up explicitly the calendar of a round-robin tournament with 6 teams,
following the method described in this chapter.

C3 Programming exercises
147
C3 Programming exercises
C3.1. Write a program that computes the sum of two integer numbers a and b
modulo a positive integer n.
C3.2. Write a program that computes the product of two integer numbers a and b
modulo a positive integer n.
C3.3. Write a program that computes the inverse of a number a modulo n, that is
the number x such that ax ≡1 (mod n).
C3.4. Write a program that computes am mod n using the method described in the
text.
C3.5. Write a program that veriﬁes if a linear congruence ax ≡b (mod n) admits
solutions and that, if it does, ﬁnds them.
C3.6. Write a program that veriﬁes if a system of m linear congruences admits
solutions and that, if it does, ﬁnds them.
C3.7. Write a program that, given r, s and x, computes the image of x under the
function f : Zrs →Zr × Zs deﬁned in Proposition 3.4.5.
C3.8. Write a program that, given two relatively prime integers r and s and a pair
(y, z), computes the preimage of (y, z) under the function f : Zrs →Zr × Zs deﬁned
in Proposition 3.4.5.
C3.9. Write a program that computes the day of the week of a date according the
Gregorian calendar.
C3.10. Write a program that draws up the calendar of a round-robin tournament
with n teams.

4
Finite is not enough: factoring integers
In the previous chapters, we met more than once the notion of a prime num-
ber (see § 1.3.1, Remark 3.1.10 and so forth). In this chapter we are going
to investigate further this notion, ﬁrst by proving the Fundamental Theorem
of Arithmetic 4.1.2, well known since primary school, which basically states
that prime numbers are the building blocks from which, by multiplication, all
integer numbers can be obtained. This theorem will yield several important
consequences: we shall for instance deduce a formula to compute Euler func-
tion ϕ(n) (see § 3.3), and much more. Moreover, we shall frame the notion
of prime number in a more general context, studying similar notions in an
arbitrary ring, among them the ring of polynomials over a ﬁeld.
As we shall see, prime numbers and the Fundamental Theorem of Arith-
metic play a basic role in the applications to cryptography and to coding
theory. But how can we tell if a number is prime? And how can we write an
arbitrary number as a product of prime numbers? In this chapter we shall
discuss some classic, and therefore elementary, algorithms for these tasks. We
shall see that, unfortunately, these algorithms are in general exponential and
are so of little practical use. It will then be necessary to ﬁnd more eﬃcient
algorithms requiring more advanced mathematical tools: we shall discuss such
algorithms later (see Chapter 6).
4.1 Prime numbers
Recall (see Section 1.3) that a prime number p is an integer greater than 1
having no divisors other than ±p and ±1.
A prime number is sometimes also called irreducible, in agreement with the
more general deﬁnition we shall discuss later (see Deﬁnition 4.5.1). Clearly, a
number that is not prime is said to be reducible or composite.

150
4 Finite is not enough: factoring integers
4.1.1 The Fundamental Theorem of Arithmetic
As is well known since primary school, by multiplying prime numbers we can
get in an essentially unique way each positive integer number. This is the gist
of the Fundamental Theorem of Arithmetic, which Euclid already knew and
expounded in Book VII of his Elements. Before discussing the Fundamen-
tal Theorem of Arithmetic, it is necessary to state the following simple but
crucial characterisation of prime numbers, which we shall return to for some
important remarks.
Proposition 4.1.1. A positive integer number p > 1 is irreducible if and only
if the following property holds:
(P) whenever p divides a product ab, p divides a or b.
Proof. We assume that p is irreducible and prove that (P) holds. So, assume
that p divides ab and that p does not divide a. As p does not divide a, and as p
has no factors other than ±p and ±1, we have that p and a have no non-trivial
common factors, that is to say, GCD(a, p) = 1. So there exist integers s and t
such that 1 = sa+tp. By multiplying both sides by b we obtain b = sab+tpb.
As p | ab and p | p, we may conclude that p | b.
Vice versa, assume that (P) holds. If p were not prime, we would have
p = hk with h, k positive integers smaller than p. But we have p | hk = p, so
either p | h or p | k, both of which are impossible because h and k are smaller
than p.
⊓⊔
We are now in a position to prove the:
Theorem 4.1.2 (Fundamental Theorem of Arithmetic). Let n be an
integer greater than 1. Then
n = ph1
1 ph2
2 ph3
3 · · · phs
s ,
(4.1)
where p1, p2, . . . , ps are distinct prime numbers and the exponents hj are posi-
tive, for all j = 1, . . . , s. Moreover, the representation (4.1) for n, called prime
decomposition or factorisation of n, is unique up to the order of the factors.
Proof. We shall prove separately the existence and the uniqueness of the
factorisation.
• Existence of a factorisation.
The proof is by induction on the integer n to be factored. If n = 2, there is
nothing to prove. So, we may assume that the existence of a factorisation has
been proved for each positive integer k with 2 ≤k < n, and prove the same
for n. If n is prime, again there is nothing to prove. Thus, let n be reducible,
so it may be written as n = ab, with positive a and b, both greater than 1
and therefore smaller than n. Then, by the induction hypothesis, a and b are
factorisable as products of primes

4.1 Prime numbers
151
a = p1p2 · · · pr,
b = p1p2 · · · ps.
Then,
n = p1p2 · · · prp1p2 · · · ps.
Clearly, it suﬃces to group together, in the right-hand side, equal prime num-
bers in order to get the result in the form (4.1).
• Uniqueness of the factorisation.
In order to prove the uniqueness of the factorisation for any integer n,
we proceed by induction, this time on the number m of irreducible factors
in any factorisation of n. Notice that the number of factors appearing in the
factorisation (4.1) is m = h1 + h2 + · · · + hs. If m = 1, then the number n
having that factorisation is a prime number p. Assume that n = p has another
factorisation
p = qk1
1 qk2
2 · · · qkt
t .
As p is a prime that divides the right-hand side, it divides one of the factors of
the right-hand side, for instance p | q1 (see Proposition 4.1.1). But q1 is prime
as well, so it has no non-trivial factors: hence p = q1. By the cancellation
property, which holds in Z, we get
1 = qk1−1
1
qk2
2 · · · qkt
t .
This relation implies that all the right-hand side exponents are zero, otherwise
we would have a product equal to 1 of integers greater than 1. Then the
original right-hand side equals q1, so p = q1 is the only factorisation of n. So
we have proved the basis of the induction.
Assume now that the uniqueness of the factorisation has been proved for
all integers admitting a factorisation into m −1 irreducible factors. Let n be
an integer admitting a factorisation into m irreducible factors. Let then
n = ph1
1 ph2
2 · · · phs
s
= qk1
1 qk2
2 · · · qkt
t
be two factorisations of n into irreducible factors, the ﬁrst one consisting of
m irreducible factors, that is to say, h1 + h2 + · · · + hs = m. Now, p1 is a
prime dividing the right-hand side, so it divides for instance q1 (see again
Proposition 4.1.1). As before, we have p1 = q1 and then, by the cancellation
property, we get
ph1−1
1
ph2
2 · · · phs
s = qk1−1
1
qk2
2 · · · qkt
t
where the number of irreducible factors in the left-hand side is m −1. By the
induction hypothesis, in this case the uniqueness of the factorisation holds,
so the primes qj and the primes pi are the same, up to the order. Then the
factorisation of n is also unique.
⊓⊔

152
4 Finite is not enough: factoring integers
4.1.2 The distribution of prime numbers
How many prime numbers are there? Euclid already knew the following the-
orem which can be proved in several ways. We give here the completely ele-
mentary proof dating back to Euclid himself.
Theorem 4.1.3. There are inﬁnitely many prime numbers.
Proof. Assume the set of prime numbers to be ﬁnite, consisting for instance
of the numbers p1 < p2 < · · · < pn. Consider the number N = p1 · · · pn + 1.
This number is not prime, as it is greater than pn which, by hypothesis is
the greatest prime number. So N has a prime decomposition which can be
written as
N = ph1
1 · · · phn
n
with at least one of the numbers h1, . . . , hn positive. Assume hi > 0. Then
pi | N. Moreover, pi | (N −1) = p1 · · · pn. Thus, pi | 1 = N −(N −1), which
is not possible, as pi > 1.
⊓⊔
As already mentioned, there are several proofs of this theorem. We give now
another proof, which relies on a famous theorem by Euler (for still another proof,
again by Euler, see Exercise A4.6).
Theorem 4.1.4 (Euler).
The sum of the reciprocals of the primes diverges. In
other words, if {p1, . . . , pn, . . .} is the sequence, possibly ﬁnite, of all prime numbers
in increasing order, we have
∞

n=1
1
pn = ∞.
It is not hard to give a sketch of the proof of this theorem relying on the prop-
erties of the famous zeta function deﬁned by
ζ(s) =
∞

n=1
1
ns .
First of all, notice that:
(1) ζ is well deﬁned and converges if s ∈R ∩(1, +∞);
(2) lims→1(s −1)ζ(s) = 1, and then, clearly,
(3) lims→1 ζ(s) = +∞.
To prove (1) it is suﬃcient to remark that
& ∞
1
dt
ts =
lim
x→+∞
& x
1
dt
ts = lim
x→∞
x1−s −1
1 −s
=
1
s −1,
so it converges.
To prove (2) notice that

n

t=1
1
ts −
& n+1
1
dt
ts
 < 1.
(4.2)

4.1 Prime numbers
153
Indeed, it is suﬃcient to consider the graph of the function y = 1/xs and to interpret
geometrically the diﬀerence in the left-hand side: we leave the details to the reader
(see Exercise A4.5).
Computing the integral in the left-hand side we ﬁnd

n

t=1
1
ts −
1
s −1

1 −
1
(n + 1)s−1
  < 1;
taking the limit as n approaches to ∞we get
 ζ(s) −
1
s −1
 < 1,
which concludes the proof of (2).
Before going further, notice that the zeta function has a fundamental importance
in number theory. For further information, see [59].
Notice now that:
Lemma 4.1.5. If {pn}n∈N is the sequence in increasing order of the prime numbers,
we have
ζ(s) =
'
n
1
1 −1
psn
.
Proof. One has
1
1 −1
psn
=

1 + 1
psn
+ 1
p2s
n
+ · · ·

and so
'
n
1
1 −1
psn
=
'
n

1 + 1
psn
+ 1
p2s
n
+ · · ·

.
By carrying out the product and keeping in mind the Fundamental Theorem of
Arithmetic we get the claim.
⊓⊔
Now we may give the:
Proof of Euler’s Theorem 4.1.4.
Keeping in mind that log(1 + t)
=

n(−1)n+1tn/n, compute:
log ζ(s) =

n
log
1
1 −1
psn
= −

n
log

1 +

−1
psn

=
=

n
 1
psn
+
1
2p2s
n
+ · · ·

=

n
1
psn
+ E.
If we prove that the error E is bounded, the theorem follows from property (3) of
ζ(s). Indeed, we have

154
4 Finite is not enough: factoring integers
E =

n

1
2p2s
n
+
1
3p3s
n
+ · · ·

≤

n
1
2p2s
n

1 + 1
ps + 1
p2s + · · ·

=
=

n
1
2p2s
n
1
1 −1
psn
=

n
1
2psn(psn −1) ≤

n
1
p2s
n
<

n
1
p2n
< ζ(2).
⊓⊔
The similarity of this theorem and of the well-known fact that the harmonic
series ∞
n=1 1/n diverges will not escape the reader. The other proof, again by
Euler, of Theorem 4.1.3 relies on this similarity (see Exercise A4.6).
Here follows another famous result which also can be used to prove that prime
numbers are inﬁnitely many.
Theorem 4.1.6 (Dirichlet). Let n and k be relatively prime positive integers. Then
there are inﬁnitely many prime numbers p such that p ≡k (mod n).
The proof can be found in [26].
Unfortunately, no known proof of Theorem 4.1.3 is constructive. In other words,
none of them gives even a hint on how to ﬁnd a formula for the nth prime number
pn, nor a recursive formula to get inﬁnitely many prime numbers. Notice, however,
that such a formula would certainly be, in any case, very elaborate, as the following
proposition suggests.
Proposition 4.1.7. No non-constant polynomial f(x) in one indeterminate x, with
coeﬃcients in Z, may assume prime values for all suﬃciently large n ∈N.
Proof. Assume f(x) is not constant and that f(y) = p is a prime number. By using
Taylor’s formula (1.26), it is clear that p divides f(y +kp) for all k ∈N. If f(n) were
a prime number for all suﬃciently large n ∈N, we would have f(y + kp) = p for all
suﬃciently large k. On the other hand, g(t) = f(y + tp) is a polynomial in t having
the same degree as f(x). As g(k) = p for all suﬃciently large k, it follows that g(t)
is a constant, that is to say, it has degree 0. Then f(x) would have degree 0 too, so
it would be a constant, a contradiction.
⊓⊔
Notice however that there exist integer-valued polynomials assuming prime val-
ues for many consecutive values of n. For instance, it may be veriﬁed that the
polynomial
x2 −x + 41
takes prime values for x = n, for all n ∈{ 0, . . . , 40 }, but of course not for x = 41
(see Exercise C4.3).
A further, important remark is that no proof of Theorem 4.1.3 allows us to
tell how many prime numbers are smaller than a ﬁxed number. In particular,
if for all real numbers x > 0 we denote by π(x) the number of primes p such
that p ≤x, there is no formula to compute this function in terms of elementary
functions. However, Gauss, in 1792, when he was 15 years old, and Legendre
before that, conjectured that π(x) is asymptotically equal to a very simple
function, that is, x/(log x); in other words they conjectured that the following
holds:

4.1 Prime numbers
155
lim
x→∞
π(x)
x
log x
= 1.
An important step toward proving this conjecture was made in 1851 by Cheby-
shev, who proved the following result:
Theorem 4.1.8 (Chebyshev). There exist two numbers A and B, with
0 < A ≤1 and 1 ≤B ≤2, such that for all suﬃciently large n ∈N the
following relation holds
A
n
log n ≤π(n) ≤B
n
log n.
The conjecture by Legendre and Gauss was proved only at the end of the
19th century by Hadamard and de la Vall´ee Poussin using analytic methods:
the theorem is known as Prime Number Theorem (see [59]).
The Prime Number Theorem may be given a probabilistic interpretation:
given a positive integer n, the probability that a positive integer p < n ran-
domly chosen between 2 and n is prime is π(n)/n which, for large n, is of the
same magnitude as 1/log n.
Let us look at a simple example: suppose we are interested in ﬁnding a
100-digit prime number, that is to say, a number of the order of n = 10100.
The probability that a randomly chosen number among those with at most
100 digits is prime is, according to what precedes, 1/log(10100) ∼1/230.
This means that, in 230 tries, we may hope to ﬁnd a prime number of that
magnitude. We may improve our chances by excluding even numbers (one
half of all numbers) and multiples of 3 (1/3 of the numbers): in conclusion,
the fraction of numbers we may exclude is 2/3 = 1/2 + 1/6 (the multiples of
two, plus the odd multiples of three). So the probability of ﬁnding a prime
numbers becomes 1/77.
To demonstrate how things work, we give the values of π(x), of [x/(log x)]
and of their ratio for x = 103, x = 106 and 109:
x
103
106
109
π(x)
168
78,498
50,847,478
[x/(log x)]
145
72,382
48,254,942
[π(x)(log x)/x]
1.159 . . .
1.084 . . .
1.053 . . .
A further simple remark complements what precedes: given a positive integer
n, there exist n consecutive integers that are not prime. In fact, it is suﬃcient to
consider the consecutive integers
(n + 1)! + 2, (n + 1)! + 3, (n + 1)! + 4, . . . , (n + 1)! + (n + 1).
Each of these numbers is reducible: the ﬁrst one is divisible by 2, the second one by
3, up to the last one, which is divisible by n + 1.

156
4 Finite is not enough: factoring integers
This would seem to mean that the larger the prime numbers become, the more
apart they are. But. . . Is this really the case?
To illustrate how little is known about this simple question, we need yet another
deﬁnition:
Deﬁnition 4.1.9. Given two positive integers p and p+2, if both of them are prime
they are said to be twin prime numbers.
Examples of pairs of twin primes are:
(3, 5), (5, 7), (11, 13), (17, 19), (41, 43), . . . , (2111, 2113).
The number of twin prime numbers smaller than 1011 is 224,376,048 (see for instance
[48]). There are isolated examples of twin primes with more than one thousand digits.
Nonetheless, we do not yet know whether there exist inﬁnitely many pairs of twin
primes or not, but it is conjectured that this is the case. Contrast this with the
following theorem, to be compared with Euler’s theorem 4.1.4 above (again, see
[59]):
Theorem 4.1.10 (Brun, 1919). The sum of the reciprocals of the twin primes
converges. In other words, if
{ p1, p1 + 2, . . . , pn, pn + 2, . . . }
{p1, . . . , pn, . . .} is the possibly ﬁnite sequence of all twin prime numbers in increasing
order, we have
∞

n=1
 1
pn +
1
pn + 2

< ∞.
Notice that this does not imply at all that the sequence of twin primes is ﬁnite.
The investigation about the existence of arbitrarily large twin primes is not
simply a matter of curiosity: it is relevant in computer science, as the possibility of
some eﬃcient systems for computer data storing is connected with the existence of
suitable twin primes (see [49], § 4.4).
Let us close this section by stating the most famous conjecture still unsettled
about prime numbers, the Goldbach conjecture (1742):
every even positive number greater than 2 is a sum of two primes.
The conjecture has been veriﬁed for all even numbers smaller than 3 · 1017. Let us
see some examples for small numbers:
4 = 2 + 2,
14 = 7 + 7,
6 = 3 + 3,
16 = 3 + 13,
8 = 3 + 5,
18 = 5 + 13,
10 = 5 + 5,
20 = 3 + 17,
12 = 5 + 7,
22 = 11 + 11.
The reader might ﬁnd it entertaining to read the ﬁne novel by A. Doxiadis [21]
about this famous conjecture.

4.1 Prime numbers
157
4.1.3 The sieve of Eratosthenes
It is important to remark that the Fundamental Theorem of Arithmetic as-
sures us that every positive integer can be written in a unique way as a product
of prime numbers, but does not give any algorithm to ﬁnd the factorisation
of a given number. It is a typical example of purely theoretical, rather than
constructive, result. Actually, ﬁnding the prime decomposition of a number
is far from easy; in fact, by the present-day mathematical and technological
knowledge it is practically unfeasible when we are dealing with very large
numbers. This is a very important point to keep in mind, now and in what
follows!
As we shall see, no polynomial time factoring algorithm that could be
implemented on an existing computer is known. It is precisely on the diﬃculty
of factoring a number into prime factors that the current security of some
cryptographic techniques relies, that is to say, of being able to transmit secret
data between two subjects without allowing third parties to eavesdrop. We
shall return on these topics in the next chapters.
Another important question, partially connected to the previous one is:
how do we tell if a number is prime? The algorithms to recognise whether
a given number is prime or not are called primality tests. The most ancient
method is the so-called sieve of Eratosthenes which we are dealing with in
this section. As we shall see, this is an exponential algorithm, so it is quite
ineﬃcient when applied to large numbers, as it is basically a factoring al-
gorithm more than a simple primality test. However, there are diﬀerent, far
more eﬃcient primality tests: among them a polynomial one recently found
by Agrawal, Kayal, and Saxena (see [2]). We shall return on this subject in
Chapter 6.
Let us see now the sieve of Eratosthenes (276-194 BCE), which allows,
in principle, to determine all prime numbers smaller than or equal to a ﬁxed
positive integer number n.
The most natural, but by far not the most eﬃcient way to determine
whether a number n is prime consists in verifying that it is not divisible by
any number preceding it, that is to say, by 2, 3, 4, . . ., n −1. The following
result, based on the Fundamental Theorem of Arithmetic, reduces the number
of necessary divisions.
Proposition 4.1.11. If a positive integer n is not divisible by any prime num-
ber smaller than or equal to √n, then n is prime.
Proof. Assume n to be reducible, that is to say that n = ab with a and b
integers such that 1 < a < n and 1 < b < n. One of the factors, a or b, is
necessarily smaller than or equal to √n: otherwise we would have n = ab >
√n · √n = n, which is impossible. So n has a factor, say a, smaller than or
equal to √n. If it is prime, the proposition is proved. Otherwise, a has a prime
factor p, and p < a ≤√n.
⊓⊔

158
4 Finite is not enough: factoring integers
Example 4.1.12. To prove that the number 397 is prime, it is suﬃcient to
prove that it is not divisible by any prime smaller than or equal to
√
397, that
is to say that it is not divisible by 2, 3, 5, 7, 11, 13, 17 and 19. The reader
may easily check that this is the case.
The remark contained in Proposition 4.1.11 might look unimportant when
dealing with small numbers, but when the numbers we are working with are
large the time saved in the computations necessary to check the primality
becomes evident.
In order to use the last result, however, we need to know the prime numbers
smaller than or equal to √n, and this may result troublesome. So we may use
that result in a weaker form, and check if n is divisible by 2, 3, 4, 5, . . ., [√n],
that is, by all integer numbers smaller than or equal to √n. In conclusion:
(1) if n is not divisible by any of these numbers, then n is a prime number;
(2) else, denoting by n1 a factor of n, apply the same procedure to n1 and
n/n1 (which is an integer), arriving ﬁnally to the complete factorisation
of n in prime factors.
Unfortunately, this is not an eﬃcient method, as its complexity is expo-
nential. Let us give an estimate of the number of bit operations necessary to
verify whether a number n is prime or not using this method. According to
the prime number theorem, there are approximately
√n
log √n = 2√n
log n
prime numbers smaller than or equal to √n. Keeping in mind formula (2.9),
we see that the number of bit operations necessary to verify if n is prime by
dividing it by all prime numbers smaller than or equal to √n is at least
O
 2√n
log n log2 n

= O(√n log n) = O(keck),
where k is the length of n and c is a constant.
Thus, the algorithm is exponential.
However, it is necessary to stress the fact that this procedure is more then
just a primality test, as it does not only determine if a given number is prime,
but also provides a factorisation if the number turns out to be composite.
To determine just the prime numbers smaller than or equal to a given
number n, we can proceed in a slightly diﬀerent way. Write down all the
numbers smaller than or equal to n, starting with 2; underline it, as it is
prime. Then delete all the multiples of 2 (as they are not prime). Underline
the ﬁrst number that has not been deleted, that is 3, and then delete all the
multiples of 3, because again they are not prime, and so forth until there are
no non-deleted nor non-underlined numbers smaller than or equal to √n.

4.1 Prime numbers
159
Now, all the underlined numbers, together with all the numbers that have
not been deleted, provide the complete list of all prime numbers smaller than
or equal to n The non-deleted numbers are prime because, not being divisible
by any prime smaller than or equal to √n, they have no non-trivial divisor,
by Proposition 4.1.11.
The term sieve describes precisely this procedure of successive deletion of
non-prime numbers.
Let us see step by step how the procedure works when we want to ﬁnd all
the primes smaller than or equal to 100.
•
Step 1. Write down all the numbers from 2 to 100:
2
3
4
5
6
7
8
9
10
11 12 13 14 15 16 17 18 19 20
21 22 23 24 25 26 27 28 29 30
31 32 33 34 35 36 37 38 39 40
41 42 43 44 45 46 47 48 49 50
51 52 53 54 55 56 57 58 59 60
61 62 63 64 65 66 67 68 69 70
71 72 73 74 75 76 77 78 79 80
81 82 83 84 85 86 87 88 89 90
91 92 93 94 95 96 97 98 99 100
•
Step 2. Underline 2 and remove all the multiples of 2:
2
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
49
51
53
55
57
59
61
63
65
67
69
71
73
75
77
79
81
83
85
87
89
91
93
95
97
99
•
Step 3. Underline the next prime number, 3, and remove all the multiples of 3:
2
3
5
7
11
13
17
19
23
25
29
31
35
37
41
43
47
49
53
55
59
61
65
67
71
73
77
79
83
85
89
91
95
97
91
95
97

160
4 Finite is not enough: factoring integers
•
Step 4. Underline the next prime number, 5, and remove all its multiples:
2
3
5
7
11
13
17
19
23
29
31
37
41
43
47
49
53
59
61
67
71
73
77
79
83
89
91
97
•
Step 5. Underline the next prime number, 7, and remove all its multiples:
2
3
5
7
11
13
17
19
23
29
31
37
41
43
47
53
59
61
67
71
73
79
83
89
97
Now we are done, as the next prime is 11, which is greater than 10 =
√
100.
The underlined numbers, together with those that survived the deletions are
the prime number smaller than 100.
Unfortunately, this is another ineﬃcient method to ﬁnd the prime numbers
smaller than a given number: a computation analogous to that given above
shows that it is exponential (see Exercise A4.7). For instance, in 1979 it has
been proved with completely diﬀerent methods that the 13395-digit number
244497−1 is prime: had we used the sieve of Eratosthenes, a computer carrying
out one million multiplications per second would have taken 106684 years to
obtain this result!
4.2 Prime numbers and congruences
We begin this section by going back to an important question left open in
Section § 3.3: how to compute Euler function ϕ.
4.2.1 How to compute Euler function
We need a deﬁnition ﬁrst.

4.2 Prime numbers and congruences
161
Deﬁnition 4.2.1. A function f : N\{0} →N\{0} is said to be multiplicative
if
f(r · s) = f(r) · f(s)
∀r, s : GCD(r, s) = 1.
The function f is said to be completely multiplicative if
f(r · s) = f(r) · f(s)
∀r, s ∈N \ {0}.
The deﬁnition itself of multiplicative function and the Fundamental The-
orem of Arithmetic imply that:
Proposition 4.2.2. Let f : N \ {0} →N \ {0} be a multiplicative function. If
n = ph1
1 ph2
2 · · · phs
s , with pi distinct primes for i = 1, . . ., s, then
f(n) = f(ph1
1 )f(ph2
2 ) · · · f(phs
s ).
(4.3)
In other words, we may compute the value f(n) of a multiplicative function
f for an integer n if:
•
we know the factorisation of n;
•
we know the value of f on all the prime powers.
The fundamental property of Euler function is that it is multiplicative,
and this is the key ingredient to compute Euler function for all integers we
know the prime decomposition of:
Proposition 4.2.3. The Euler function ϕ is multiplicative. Thus, if n =
ph1
1 ph2
2 · · · phs
s , with pi distinct primes for i = 1, . . ., s, then
ϕ(n) = ϕ(ph1
1 )ϕ(ph2
2 ) · · · ϕ(phs
s ).
(4.4)
Moreover, if p is a prime number, then
ϕ(ph) = ph −ph−1.
(4.5)
In particular, ϕ(p) = p −1. So we have
ϕ(n) = n ·

1 −1
p1

· · ·

1 −1
ps

.
(4.6)
Proof. Formula (4.4) follows from Proposition 4.2.2, once the multiplica-
tivity of the function ϕ is known. Formula (4.6) immediately follows from
Equations (4.4) and (4.5).
So we have to prove the multiplicativity of the function ϕ. Let n = rs,
with GCD(r, s) = 1. The numbers m such that 0 ≤m < n can be represented
(see Proposition 3.4.5) as pairs of the form
(m mod r, m mod s).

162
4 Finite is not enough: factoring integers
The reader may also verify (Exercise A4.2) that an integer m and the product
rs of r and s are relatively prime if and only if
GCD(m mod r, r) = 1
and
GCD(m mod s, s) = 1.
So the total number ϕ(rs) of elements m modulo rs that are coprime with rs
is ϕ(r) · ϕ(s), as there are ϕ(r) elements modulo r that are coprime with r
in the ﬁrst element of the pair and ϕ(s) elements modulo s that are coprime
with s in the second element of the pair.
In order to complete the proof, we have to prove Formula (4.5). To this
end, it is suﬃcient to remark that the only numbers that are not coprime with
ph are the multiples of p, which are of the form
p · i,
con 1 ≤i ≤ph−1,
so there are ph−1 of them.
⊓⊔
This proposition allows us to compute Euler function for every integer n
for which the prime decomposition is known. For instance,
ϕ(108) = ϕ(22 · 33) = ϕ(22)ϕ(33) = (22 −2)(33 −32) = 36.
An immediate consequence of Proposition 4.2.3 and of Euler’s theorem
3.3.11 is the following result (see also the Exercises A3.14, A3.15):
Proposition 4.2.4. Let n > 1 be a positive integer. Then Zn is a ﬁeld if and
only if n is prime.
Proof. Clearly, Zn is a ﬁeld if and only if U(Zn) = Zn \ {0}. By Corollary
3.3.7, U(Zn) has order ϕ(n) and so Zn is a ﬁeld if and only if ϕ(n) = n −1;
by Proposition 4.2.3, this happens if and only if n is prime.
⊓⊔
4.2.2 Fermat’s little theorem
Keeping in mind Euler’s theorem 3.3.11, we may immediately deduce from it
the following result:
Theorem 4.2.5 (Fermat’s little theorem).
Let a be an integer and p a
prime number. Then
ap ≡a
(mod p)
(4.7)
and, if a is not divisible by p:
ap−1 ≡1
(mod p).
(4.8)
Proof. If a is divisible by p, then (4.7) is trivially true, as ap ≡a ≡0
(mod p). If a is not divisible by p, then (4.8) follows from Euler’s theorem,
and (4.7) follows by multiplying both sides by a.
⊓⊔

4.2 Prime numbers and congruences
163
Notice that it is possible to give elementary, direct proofs of Fermat’s lit-
tle theorem and of Euler’s theorem without using group-theoretic properties,
only relying on the Fundamental Theorem of Arithmetic (see Exercises A4.11,
A4.12).
Fermat’s little theorem may be used to create a primality test or, more
precisely, to verify if a number is not prime, as
if there exists a number a such that an ̸≡a
(mod n), then n is not prime.
For instance, n = 10 is not prime because 210 ̸≡2 (mod 10).
Generally, we look for a small a (for instance, a = 2) to keep computations
as simple as possible.
Notice that this non-primality test, if it works, guarantees that the number
is not prime, but does not give a factorisation of n.
The ancient Chinese mathematicians believed a number to be prime if and
only if
2n−1 ≡1
(mod n).
(4.9)
However, this is not true, as the following example shows.
Example 4.2.6. The composite number 341 = 11 · 31 satisﬁes congruence
2340 ≡1 (mod 341). Indeed, by Fermat’s little theorem, we have 210 ≡1
(mod 11), and so
2340 = (210)34 ≡1
(mod 11);
moreover,
2340 = (25)68 = 3268 ≡1
(mod 31).
The two congruences imply the result, by Proposition 3.1.11.
This means that (4.9) is a necessary, but not suﬃcient, condition for a
number to be prime.
The following result shows that, by adding an extra hypothesis, Formula
(4.9) becomes a suﬃcient condition for n to be prime.
We need a deﬁnition ﬁrst.
Deﬁnition 4.2.7. Let n be a positive integer and let a be an integer coprime
with n. The order of [a] as an element of the group U(Zn), that is to say the
least positive integer m such that am ≡1 (mod n), will be called Gaussian of
n with respect to a and will be denoted by Gss(n, a).
For instance, it is clear that Gss(7, 2) = 3. Computing the Gaussian of two
numbers is not at all trivial. Keeping in mind what was mentioned in Remark
3.3.12, we immediately obtain:
Corollary 4.2.8. Let a and n be relatively prime numbers. Then:
•
Gss(n, a) divides ϕ(n);

164
4 Finite is not enough: factoring integers
•
if m is an integer, then am ≡1 (mod n) if and only if Gss(n, a) | m;
•
if i, j ∈Z, then ai ≡aj (mod n) if and only if i ≡j (mod Gss(n, a)).
For some further elementary properties of the Gaussian, see Exercise
A4.30.
We may now state the following result.
Proposition 4.2.9 (Lucas, 1876). Let n > 1. If there exists an integer a,
with 1 < a < n, such that Gss(n, a) = n −1, that is to say such that
(1) an−1 ≡1 (mod n), and
(2) am ̸≡1 (mod n), for all m = 1, 2, . . ., n −2,
then n is prime.
Proof. Firstly, notice that GCD(a, n) = 1, as this is the necessary and suf-
ﬁcient condition for the congruence ax ≡1 (mod n) to admit solutions (see
(3.3.4)).
So, suppose by way of contradiction that n is not prime. Then ϕ(n) is
strictly smaller than n −1 and, as GCD(a, n) = 1, by Euler’s theorem the
order of a would divide ϕ(n) < n −1, contradicting the hypothesis. So n is
prime.
⊓⊔
In conclusion, we have
n is prime if and only if there is an element a such that Gss(n, a) = n −1.
Indeed, we may say that if there exists an integer a such that an−1 ̸≡1
(mod n), then n is not prime by Fermat’s little theorem. On the other hand,
if there exists an integer a of order n −1 modulo n, then n is prime.
This test is not eﬃcient, as it is necessary to carry out n−2 multiplications
to get the powers of a, and to ﬁnd their remainders modulo n, which entails
an exponential complexity. However, Lucas himself improved this criterion,
by remarking that:
Proposition 4.2.10. Let n > 1. If there exists an integer a, with 1 < a < n,
such that
(1) an−1 ≡1 (mod n), and
(2) am ̸≡1 (mod n), for all m < n dividing n −1,
then n is prime.
Proof. Analogous to the proof of Proposition 4.2.9.
⊓⊔
It is clear that by using this proposition it is possible to reduce the number
of multiplications and of reductions modulo n. However, in order to apply this
test it is necessary to know all the factors of n −1, and this is feasible only
when n −1 is of some special form. So, unless n −1 is easily factorisable, this
test is exponential too.
Although these tests have exponential complexity, we shall see later that
they can nevertheless be used to construct new primality tests of a diﬀerent
type: the probabilistic ones (see § 6.1).

4.2 Prime numbers and congruences
165
4.2.3 Wilson’s theorem
Theorem 4.2.11 (Wilson). If p is a prime number, then
(p −1)! ≡−1
(mod p).
Proof. For p = 2 and p = 3 the theorem is straightforward. So, assume p > 3.
Consider the congruence ax ≡1 (mod p), where a is one of the integers 1, 2, . . . , p−1.
As GCD(a, p) = 1, this congruence admits exactly one solution a′ modulo p, with
1 ≤a′ < p. For which values of a does a = a′ hold? When a = a′ the congruence
becomes a2 ≡1 (mod p), which amounts to saying that p divides (a + 1)(a −1). So,
either p divides a + 1 or p divides a −1. It follows that either a −1 ≡0 (mod p),
that is, a = 1, or a+1 ≡0, that is, a = p−1. Leaving out these two extremal values,
the other elements 2, 3, . . ., p −2 can be paired up into (p −3)/2 pairs {a, a′}, with
a ̸= a′ such that aa′ ≡1 (mod p). By multiplying together all the congruences, we
obtain
2 · 3 · · · · (p −2) = (p −2)! ≡1
(mod p).
Now, by multiplying both sides by p−1 ≡−1 (mod p), we ﬁnd that (p−1)! ≡p−1
(mod p), which is our claim.
⊓⊔
The inverse of this theorem is also true:
Proposition 4.2.12. If (n −1)! ≡−1 (mod n), then n is prime.
Proof. If n were not a prime, it would have a divisor c, with 1 < c < n, which,
being a divisor of n, would divide (n −1)! + 1 as well. But c should appear among
the factors of (n −1)!, as 1 < c < n, so c | (n −1)!. These two relations imply that
c divides 1, which is a contradiction.
⊓⊔
Wilson’s theorem 4.2.11, together with its inverse 4.2.12, give us another char-
acterisation of prime numbers:
n is prime if and only if (n −1)! + 1 is divisible by n.
For instance, n = 5 is prime, as (5 −1)! = 24 ≡−1 (mod 5), that is to say,
24 + 1 is divisible by 5.
Just like Fermat’s little theorem, Wilson’s theorem provides a primality test. In
principle, the test works as follows: given n, compute (n−1)!+1 and verify whether
it is divisible by n or not. If it is not, and only in this case, n is prime.
However, such a test is unfeasible in practice, because it relies on an exponential
algorithm. Indeed, given n we have to compute (n −1)! ﬁrst, and, if n is an integer
of length k, we have T (n!) ∈O(n2k2) (see Chapter 2, in particular Exercises A2.9
and A2.23). In other words, computing (n −1)! is exponential. It is suﬃcient to
consider that, even if n is a number with, say, 4 decimal digits, the number (n −1)!
may have up to 35652 digits: an impressive and intractable number.

166
4 Finite is not enough: factoring integers
4.3 Representation of rational numbers in an arbitrary
base
In this section we prove Proposition 1.4.7, which was left unproved.
Proof of Proposition 1.4.7. Given a rational number a such that 0 < a <
1, we shall show that a is β–recurring, that is to say that it has an expression
of the form
a = (0, c1 . . . cmcm+1 . . . cm+h)β
(4.10)
in base β. Moreover, we shall show that
(c1 . . . cmcm+1 . . . cm+h)β −(c1 . . . cm)β
(β −1, . . . , β −1



h
, 0, . . . , 0
  
m
)β
=
= (0, c1 . . . cmcm+1 . . . cm+h)β.
(4.11)
Let us prove the ﬁrst claim. Given a = c/d, where the fraction is reduced,
we shall distinguish three cases:
(1) every prime divisor of d is a divisor of β too;
(2) d and β are relatively prime;
(3) d and β are not relatively prime, but there is some prime divisor of d that
does not divide β.
Case (1). In this case there are powers of β that are divisible by d. Let βm be
the least such power, so we have βm = dk. Then
a = c
d = ck
dk = ck
βm .
On the other hand,
ck = (am−1 . . . a0)β = a0 + a1β + · · · + am−1βm−1,
as a < 1 and so ck < βm. In conclusion, we have
a = ck
βm = a0 + a1β + · · · + am−1βm−1
βm
= (0, am−1am−2 . . . a0)β,
that is Equation (4.10) holds, with h = 0 and ci = am−i, i = 1, . . . , m.
Case (2). In this case a cannot be expressed as a fraction with a power of β
as its denominator. However, given a positive integer h, there exists exactly
one fraction of the form ah/βk that approximates a from below within 1/βh,
that is, such that
ah
βh < a < ah + 1
βh
:

4.3 Representation of rational numbers in an arbitrary base
167
clearly, this is the fraction having βh as its denominator and ⌊βha⌋as it
numerator, where by ⌊x⌋we denote the greatest integer less than or equal to
x.
Consider a particular value of h, which certainly exists, such that βh ≡1
(mod d): for instance we may take h = Gss(d, β) (see § 4.2.2) and determine
b := ah. Clearly, we get
b =
(
βh c
d
)
= (βh −1) c
d,
that is to say,
a = c
d =
b
βh −1.
(4.12)
Keeping in mind the identity
βhk −1 = (βh −1)(1 + βh + · · · + βhk−h),
which holds for every pair of non-negative integers h, k (see polynomial equal-
ity (4.13) below), we immediately ﬁnd
a = b
βh +
b
β2h + · · · +
b
βkh +
1
βkh a
for all positive integers k. Deﬁne
Ak = b
βh +
b
β2h + · · · +
b
βkh .
This is a β–deﬁned number, and precisely, if b = (am−1 . . . a0)β, then
Ak = (0, a0 . . . am−1a0 . . . am−1 . . . a0 . . . am−1



k
)β.
Moreover, we have
0 < a −Ak =
a
βkh <
1
βkh
and so limk→∞Ak = a. Keeping in mind Theorem 1.4.4, we may conclude
that a = 0, a0 . . . am−1 is a simple recurring number. Equation (4.12) is just
Equation (4.11) in this case.
Case (3). In this case let d = ph1
1 · · · phs
s
be a factorisation of d with p1, . . . , ps
distinct prime numbers, and let p1, . . . , pk be the only primes among those
dividing β as well. Deﬁne b = ph1
1 · · · phk
k , so d′ = d/b and β are relatively
prime, and we may consider the least positive integer m such that b | βm. We
have
βma = βm
b
c
d′ .

168
4 Finite is not enough: factoring integers
It follows from this relation that the denominator of the reduced fraction
of βma −[βma] is divisible by d′ and so is relatively prime with β, while
[βma] < βm. Thus, keeping in mind case (2), we get an expression of the form
βma = (c1 . . . cm, cm+1 . . . cm+h)β
and from it (4.10) follows.
Finally, we prove Equation (4.11):
(c1 . . . cmcm+1 . . . cm+h)β −(c1 . . . cm)β
(β −1, . . . , β −1



h
, 0, . . . , 0
  
m
)β
=
= (c1 . . . cm)ββh + (cm+1 . . . cm+h)β −(c1 . . . cm)β
(β −1)βm(1 + β + · · · + βh)
=
= (c1 . . . cm)β
βm
+
(cm+1 . . . cm+h)β
(β −1, . . . , β −1



h
)ββm ;
keeping in mind case (2), this number coincides with 0, c1 . . . cmcm+1 . . . cm+h.
⊓⊔
Remark 4.3.1. This proof shows that cases (1), (2) and (3) correspond to
the three cases in which the rational number is β–deﬁned, simple recurring
or mixed recurring, respectively. Moreover, the proof itself shows how to ﬁnd
the mantissa and the number of recurring digits in the three cases.
4.4 Fermat primes, Mersenne primes and perfect
numbers
4.4.1 Factorisation of integers of the form bn ± 1
Although the problem of factoring a number is in general very hard, it may
be far easier for numbers of particular forms. We show next an example.
Consider the following two identities among polynomials on Z:
xn −1 = (x −1)(xn−1 + xn−2 + · · · + x2 + x + 1),
(4.13)
xn + 1 = (x + 1)(xn−1 −xn−2 + · · · + x2 −x + 1).
(4.14)
The ﬁrst one holds for every positive integer n and the second one holds for
every odd positive integer n (see Exercises A4.32 and A4.33). It follows from
them that:

4.4 Fermat primes, Mersenne primes and perfect numbers
169
Proposition 4.4.1.
(i) If m is an integer of the form an −1, it may be
decomposed as
an −1 = (a −1)(an−1 + an−2 + · · · + a2 + a + 1).
Moreover, if n = rs, then m may be further factored as follows:
ars −1 = (ar −1)(ar(s−1) + ar(s−2) + · · · + a2r + ar + 1).
In particular, if m = an −1 is prime, then a = 2 and n is prime.
(ii) If m is an integer of the form an + 1, with odd n, it may be decomposed
as
an + 1 = (a + 1)(an−1 −an−2 + · · · + a2 −a + 1).
Moreover, if n = rs, with odd s, then m may be further factored as follows:
ars + 1 = (ar + 1)(ar(s−1) −ar(s−2) + · · · + a2r −ar + 1).
In particular, if m = an + 1 is prime, then n is a power of two.
Example 4.4.2. We want to factor the number 16383. It is useful to keep at
hand the values of the powers of 2 up to, say, 214. Inspecting the list of these
powers, we ﬁnd that 16383 = 214 −1. Then
16383 = 214 −1 = (27 −1)(27 + 1) = 127 · 129 = 127 · 3 · 43,
which is a prime decomposition.
Clearly, we could have immediately checked that 16383 is divisible by 3:
16383 = 3 · 5461.
However, we would have come across the problem of factoring 5461, which
would probably have taken more time. When a number is recognised as having
the form an −1, it is always convenient to use this information. The problem,
of course, lies exactly in recognising that the number has this form.
Here follows another useful result.
Proposition 4.4.3. Let p be a prime dividing an −1. Then, either
(i) p divides ad −1 for some proper divisor d of n, or
(ii) p ≡1 (mod n).
If both p and n are odd, then p ≡1 (mod 2n).
Proof. By hypothesis, an ≡1 (mod p), and by Fermat’s little theorem we
also have ap−1 ≡1 (mod p). Then (see Exercise A4.8) ad ≡1 (mod p), with
d = GCD(n, p −1), that is p | (ad −1). If d is strictly smaller than n, then (i)
holds, otherwise, if d = n, it follows from d | (p −1) that p ≡1 (mod d), that
is, (ii). Further, if both p and n are odd, n | (p −1) implies that 2n | (p −1).
⊓⊔

170
4 Finite is not enough: factoring integers
Let us see how one can apply this proposition to factor integers of the form
an −1.
Example 4.4.4. We want to factor the number 221−1 = 2097151. By Propo-
sition 4.4.3, we know that if a prime p is a factor of 221 −1, then either p
divides 2d −1, with d a proper divisor of 21, that is to say, it divides 23 −1
or 27 −1, or p ≡1 (mod 21). In the ﬁrst case p may be either 7 or 127. Let
us check if 2097151 is divisible by 7 or by 127.
It may be seen that it is divisible by both numbers, and so we get the
factorisation
2097151 = 7 · 127 · 2359.
Now, if 2359 were a prime number, as it does not divide 27 −1 nor 23 −1,
we would have 2359 ≡1 (mod 42), as in this case both p and n are odd. But
it may be checked that this is not the case, and so 2359 is not a prime. It is
now easily seen that 2359 = 7 · 337. The prime decomposition is
2097151 = 72 · 127 · 337.
We shall shortly see further applications of Proposition 4.4.1.
4.4.2 Fermat primes
How are prime numbers found? As we have already said, there are no known
recurrence formulas to compute prime numbers, and so there is no eﬃcient
method to generate prime numbers. Still, in the past, several mathematicians
have dreamed of the possible existence of such formulas, perhaps even quite
simple ones. Among them there were Fermat and Mersenne, both of whom
lived in the 17th century.
Fermat remarked what follows, as an immediate consequence of our Propo-
sition 4.4.1, (ii):
Corollary 4.4.5. If the number n = 2k +1 is prime, then k has no odd factor
and so it is a power of 2.
We have the following deﬁnition.
Deﬁnition 4.4.6. A Fermat number is an integer of the form
Fn = 22n + 1.
The Fermat numbers corresponding to the ﬁrst few values of n are
F0 = 3,
F1 = 5,
F2 = 17,
F3 = 257,
F4 = 65537.
It is not diﬃcult to verify that each of these ﬁve numbers is a prime number.
Fermat believed that all the numbers of the form 22n + 1 are prime. His

4.4 Fermat primes, Mersenne primes and perfect numbers
171
conjecture was disproved by Euler, who proved that the next Fermat number,
F5, is not prime, by showing the factorisation
F5 = 4294967297 = 641 · 6700417,
which is quite easy to ﬁnd. In fact,
641 = 5 · 27 + 1 = 24 + 54
and so
F5 = 232 + 1 = 24 · 228 + 1 = (641 −54) · 228 + 1 =
= 641 · 228 −(5 · 27)4 + 1 = 641 · 228 −(641 −1)4 + 1 =
= 641(228 −6413 + 4 · 6412 −6 · 641 + 4).
The problem of ﬁnding Fermat numbers that are prime is still open. The
largest known prime Fermat number is F4. The largest known non-prime Fer-
mat number is F23471. The factorisations of F5, F6, F7, F8, F9 and F11 are
known. F10 and F14 are known not to be prime, but their complete factori-
sation is not known. It is still an open problem whether there are inﬁnitely
many Fermat primes or not, and whether there are inﬁnitely many composite
Fermat numbers or not. Surprisingly, Fermat primes appear in the solution to
the geometric problem of constructing regular polygons with ruler and com-
passes. In fact, the following result from Galois theory holds (see [4], [32],
[45]).
Theorem 4.4.7. A regular polygon with n sides can be constructed with ruler
and compasses if and only if n = 2ap1 · · · pt, where p1, . . . , pt are distinct
Fermat primes and a is a non-negative integer.
So, among the ruler-and-compasses constructible regular polygons there
are: the triangle, the hexagon, the pentagon, the decagon, the 17-gon, but not
a regular polygon with nine sides (as 9 is the product of two equal Fermat
numbers), nor a 7-gon or a 25-gon.
There are some primality tests for Fermat numbers, like the following
P´epin’s test.
Theorem 4.4.8. The Fermat number Fn is prime if and only if there exists
an integer a such that
a2(2n−1) = a(Fn−1)/2 ≡−1
(mod Fn).
(4.15)
Proof. We prove now only a part of theorem, that is, that if (4.15) holds
then Fn is prime. We shall complete the proof of the theorem in Section 5.2.4
(see Proposition 5.2.33), as an application of the law of quadratic reciprocity.
From Equation (4.15) we deduce aFn−1 ≡1 (mod Fn). Thus, if p is a prime
dividing Fn we have aFn−1 ≡1 (mod p) and so Gss(p, a) | Fn −1 = 22n. On

172
4 Finite is not enough: factoring integers
the other hand, as Equation (4.15) holds, we have a2(2n−1) ≡−1 (mod p)
as well, and so Gss(p, a) ∤Fn −1 = 22n−1: then Gss(p, a) = Fn −1 = 22n.
Moreover, Gss(p, a) < p, so Fn ≤p, implying Fn = p.
⊓⊔
It is interesting to notice that if n ̸= m then GCD(Fn, Fm) = 1 (see
Exercise A4.39), which yields a new proof that there are inﬁnitely many prime
numbers (see Exercise A4.40).
4.4.3 Mersenne primes
Mersenne observed something which, again, is a consequence of Proposition
4.4.1, (i): if a number of the form 2p −1 is prime, then p is prime. So we may
deﬁne:
Deﬁnition 4.4.9. A Mersenne number is a number of the form
Mp = 2p −1,
with p prime.
If Mp is itself a prime number, then it is called a Mersenne prime. However,
not for all primes p the number Mp is prime. For instance, if p = 11, we have
M11 = 211 −1 = 2047 = 23 · 89.
Mersenne proved in 1644 that Mp is prime for the following values of p:
2, 3, 5, 7, 13, 17, 19, 31, 67, 127, 257,
claiming further that Mp is reducible for all other primes smaller than 257.
More than 200 years later, this claim was proved false, as it has been shown
that there are other values of p smaller than 257, such as p = 61, 89, 107, for
which the number Mp is prime. For Mersenne numbers we have the following
ad hoc primality test, devised by Lucas at the end of the 19th century (its
proof can be found in [34]):
Theorem 4.4.10 (Lucas test). The number Mp = 2p −1, with p a prime
greater than 2, is a prime number if and only if Mp divides Sp, where Sk is
deﬁned recursively as follows:
S2 = 4,
Sk = S2
k−1 −2.
For instance,
S2 = 4, S3 = 14, S4 = 194, S5 = 37634.
Lucas test 4.4.10 is quite eﬃcient. Indeed, we have:
Corollary 4.4.11. Lucas test determines if Mp = 2p −1, with p a prime
greater than 2, is a prime number using O(p3) bit operations.

4.5 Factorisation in an integral domain
173
Proof. It is necessary to compute p −1 squares modulo Mp, and each of
them requires O(log2 Mp) = O(p2) bit operations.
⊓⊔
Only 43 Mersenne primes are known. The last Mersenne prime was found
in December 2005: it is M30402457 and has 9152052 digits. It is also the largest
known prime.
Exactly as for Fermat numbers, for Mersenne numbers too there are several
open problems: are there inﬁnitely many Mersenne primes? Are there inﬁnitely
many composite Mersenne numbers? It is conjectured that the answer to
both questions is positive. We do not dwell further on Mersenne primes, just
mentioning the large quantity of such numbers that has been found, which
suggests that many among Mersenne numbers are prime (see [48]).
4.4.4 Perfect numbers
Given a positive integer n we deﬁne
σ(n) =

m>0,m|n
m;
notice that for all n ∈N we have σ(n) ≥n+1. Further, n is prime if and only
if σ(n) = n + 1. It is useful to give a deﬁnition:
Deﬁnition 4.4.12. An integer n > 0 is said to be perfect if σ(n) = 2n.
In other words, n is perfect if and only if the sum of its proper divisors is
equal to n.
For instance, 6 and 28 are perfect numbers, as σ(6) = 1 + 2 + 3 + 6 = 12
e σ(28) = 1 + 2 + 4 + 7 + 14 + 28 = 56.
Apparently, the ancient Greeks already knew the following theorem; it pro-
vides an unexpected relation between perfect numbers and Mersenne primes.
Theorem 4.4.13. A positive, even integer n is a perfect number if and only
if there exists a Mersenne prime Mp such that n = 2p−1 · Mp.
The proof is not hard, but we omit it and give a short sketch of it in
Exercise A4.41.
So this theorem reduces the determination of even perfect numbers to that
of Mersenne primes. As for the odd ones, things are far more diﬃcult: it is
not even known whether odd perfect numbers exist or not. It is known, for
instance, that there are none smaller than 10200.
4.5 Factorisation in an integral domain
In this section we shall recast the results of Section 4.1 in a more general frame,
which will turn out to be quite useful later. Basically, we shall deﬁne a class of
rings, the so-called factorial rings or unique factorisation domains, which have the
property that for them a suitable form of the Fundamental Theorem of Arithmetic
holds. This section is a natural continuation of Section 1.3.5.

174
4 Finite is not enough: factoring integers
4.5.1 Prime and irreducible elements in a ring
Let A be a ring with unity. We shall need the following deﬁnitions.
Deﬁnition 4.5.1. A non-zero, non-invertible element a ∈A is said to be irreducible
if whenever a is written as a product a = bc with b and c in A, either the element b
or the element c is invertible.
Deﬁnition 4.5.2. A non-zero, non-invertible element a ∈A is said to be prime if
whenever a divides a product bc with b and c in A, it divides one of the factors. In
other words,
a | bc implies either a | b or a | c.
Notice that associate elements are either both irreducible or non-irreducible, as
they share the same divisors. Analogously, associate elements are either both prime
or non-prime.
We have already remarked that in Z these two notions coincide: this is the
content of Proposition 4.1.1. It is useful to remark here two facts the reader will
easily be persuaded of by going again over the results in § 4.1:
•
the Fundamental Theorem of Arithmetic is an immediate consequence of Propo-
sition 4.1.1;
•
Proposition 4.1.1 is, in its turn, a consequence of the fact that in Z B´ezout’s
identity for the greatest common divisor holds; this, in turn, follows from Z
being a principal ideal domain, that is, from the existence of the Euclidean
algorithm.
As to the relationship between the notions of prime and irreducible element, we
have immediately the following lemma.
Lemma 4.5.3. In an integral domain every prime element is also irreducible.
The proof is left as an exercise for the reader, who will only have to repeat part
of the proof of Proposition 4.1.1 (see Exercise A4.43).
However, it is not true that in an arbitrary integral domain every irreducible
element is prime. Here follows an example.
Example 4.5.4. Consider the following set of complex numbers:
Z[
√
−3] = {a + b
√
−3 | a, b ∈Z}.
It is easy to see that Z[√−3] is stable under the operations of addition and
multiplication as deﬁned in C, that is to say, by adding and multiplying elements
of Z[√−3], we obtain elements of Z[√−3]. Clearly, with these operations, Z[√−3]
is an integral domain with unity (see Exercise A4.45 and A4.46).
Let us determine the invertible elements of Z[√−3]. For each element α = a +
b√−3 of Z[√−3] its complex norm is deﬁned: ||α|| = a2 + 3b2. If α = a + b√−3 is
invertible, its norm must be 1. Indeed, if α is invertible, there exists a β = c+d√−3
such that α·β = 1. But then ||α||·||β|| = ||α·β|| = ||1|| = 1. As ||α|| is a non-negative
integer, it must be ||α|| = 1. Now, the relation a2 + 3b2 = 1 with a, b ∈Z implies
b = 0 and a = ±1. Vice versa, if ||α|| = 1 then α = ±1 is invertible. Thus,

4.5 Factorisation in an integral domain
175
the invertible elements in Z[
√
−3] are ±1
or
the invertible elements in Z[
√
−3] are those with norm equal to 1.
Having established this, we want to prove that in Z[√−3] there exist irreducible
elements that are not prime; for instance, the number 1 + √−3 ∈Z[√−3] has this
property.
We prove ﬁrst that 1+√−3 is irreducible. Suppose that 1+√−3 = (a+b√−3)(c+
d√−3) in Z[√−3]. Taking the norms, we have
4 = ||a + b
√
−3|| · ||c + d
√
−3|| = (a2 + 3b2)(c2 + 3d2).
The only possible case is either a2 +3b2 = 1 or a2 +3b2 = 4, as it is not possible that
a2 +3b2 = 2. The ﬁrst relation implies, as we have seen, that a = ±1 and b = 0, that
is a + b√−3 invertible, while in the second case c + d√−3 is invertible. As 1 + √−3
is non-zero and non-invertible, we have proved that 1 + √−3 is irreducible.
We now prove that 1 + √−3 is not prime. From the obvious relation

1 +
√
−3
	 
1 −
√
−3
	
= 2 · 2,
(4.16)
it follows that 1 + √−3 divides 2 · 2, but does not divide 2. Indeed, if 1 + √−3
divided 2, then 2 = (1 + √−3)(a + b√−3), hence, taking the norms, we would ﬁnd
the following equality in N:
4 = 4 · (a2 + 3b2),
so a2 + 3b2 = 1, that is a = ±1 and b = 0, which means that a + b√−3 =±1,
implying
2 = ±

1 +
√
−3
	
,
a contradiction.
4.5.2 Factorial domains
So we may ask: which are the integral domains where each irreducible element is
also prime? In order to answer this question, we give a deﬁnition.
Deﬁnition 4.5.5. An integral domain is said to be a factorial domain or a unique
factorisation domain or a factorial ring if every non-zero, non-invertible element a
admits a factorisation into irreducible elements, that is to say, can be written as a
product of irreducible elements
a = p1p2 · · · pn
in such a way that, if
a = p′
1p′
2 · · · p′
m
is another factorisation into irreducibles, then m = n and each of the p′
i is associate
to a pj.
Basically, this deﬁnition identiﬁes the class of domains in which an analogue of
the Fundamental Theorem of Arithmetic holds. We have the following result.
Theorem 4.5.6. An integral domain A is factorial if and only if:
(1) every non-zero, non-invertible element of A can be written as a product of irre-
ducible elements;
(2) the prime elements of A coincide with the irreducible elements.

176
4 Finite is not enough: factoring integers
Proof. If (1) and (2) hold, then A is factorial: this can be proved exactly as we
did for the Fundamental Theorem of Arithmetic.
Vice versa, assume A is factorial. Property (1) is clearly true. Assume now that
a is irreducible and that it divides bc, that is bc = ap. If p is invertible, then ap is
irreducible as a, and so either b or c is invertible. If c [b, respectively] is invertible
then a is associate to b [to c, resp.], and so divides it. So we may assume that p is not
invertible. Moreover, as a, which is not invertible, divides bc, bc is not invertible. So,
either b or c is non-invertible. Assume both elements are non-invertible: the other
case is analogous and is left to the reader. Let
b = p1p2 · · · pn,
c = q1q2 · · · qm,
p = r1r2 · · · rs
be the factorisations of b, c, p. Then we have
p1p2 · · · pnq1q2 · · · qm = bc = ap = ar1r2 · · · rs.
By the uniqueness of the factorisation, a has to be associate to one of the irreducibles
in the left-hand side, and so it must divide either b or c.
⊓⊔
Example 4.5.7. Keeping in mind Example 4.5.4 and Theorem 4.5.6, we see that
Z[√−3] is not a unique factorisation domain. For instance, formula (4.16) shows two
factorisations of the same element of Z[√−3] into irreducibles. The two factorisations
are diﬀerent, in the sense that 2 is not associate either to 1 + √−3 or to 1 −√−3.
We further remark that in Z[√−3] part (1) of Theorem 4.5.6 holds. Indeed, if
α ∈Z[√−3] is non-zero and non-invertible, either it is irreducible, or α = α1β1, with
α1, β1 non-invertible and so with norm greater than 1. Thus, 0 < ||α1|| < ||α||, 0 <
||β1|| < ||α||. By iterating this argument on α1 and β1, we arrive to a factorisation.
Remark 4.5.8. Let A be a factorial ring and let a ∈A be a non-zero element.
Consider the factorisation of a into irreducible elements
a = ph1
1 · · · phs
s ,
where p1, . . . , ps are pairwise non-associate irreducibles and h1, . . . , hs are positive
integers. It is clear that all divisors of a, and no other number, are associate to
elements of the form pk1
1 · · · pks
s , with 0 ≤ki ≤hi, i = 1, . . . , s.
It follows from this that in A the greatest common divisor of two non-zero
elements a, b always exists. Indeed, we always may write the factorisations of a and
b as
a = ph1
1 · · · phs
s ,
b = pk1
1 · · · pks
s ,
where p1, . . . , ps are pairwise non-associate irreducibles and h1, . . . , hs, k1, . . . , ks are
non-negative integers. Then
GCD(a, b) = pn1
1 · · · pns
s ,
where ni = min{hi, ki}, i = 1, . . . , s.

4.5 Factorisation in an integral domain
177
4.5.3 Noetherian rings
Let us momentarily go back to condition (1) in Theorem 4.5.6, in order to deﬁne
an interesting class of rings where it is always satisﬁed. Recall the following two
deﬁnitions:
Deﬁnition 4.5.9. A commutative ring A is said to be Noetherian if every ideal of
A is ﬁnitely generated.
Deﬁnition 4.5.10. A commutative ring A is said to satisfy the ascending chain
condition if every ascending chain
I1 ⊆I2 ⊆· · · ⊆In ⊆· · ·
(4.17)
of ideals of A is stationary, that is there is an element m ∈N such that In = Im for
all n ∈N such that n ≥m.
The relation among these two deﬁnitions is given by the following proposition.
Proposition 4.5.11. A commutative ring A is Noetherian if and only if it satisﬁes
the ascending chain condition.
Proof. Assume A to be Noetherian. Let (4.17) be an ascending chain of ideals
of A. Set I = ∪n∈NIn. It is clear that I is an ideal of A (see Exercise A4.49). As
A is Noetherian, we have I = (x1, . . . , xn). So there exists an integer m such that
xi ∈Im, for all i = 1, . . . , n. Thus, I = Im and so, In = Im for all n ∈N such that
n ≥m.
Assume that A satisﬁes the ascending chain condition and let I be an ideal of
A. If I were not ﬁnitely generated, we could ﬁnd a sequence {xn}n∈N of elements
of I such that, if In = (x1, . . . , xn), we would have In ⊂In+1 and In ̸= In+1, for
all n ∈N (see Exercise A4.50). Clearly, this contradicts the fact that A satisﬁes the
ascending chain condition.
⊓⊔
We have some lemmas.
Lemma 4.5.12. Let A be a Noetherian integral domain. Let {xn}n∈N be a sequence
of non-zero elements in A such that xn+1 | xn for all n ∈N. Then there exists an
integer m ∈N such that, for all n ≥m, xn is associate to xm.
Proof. Deﬁne In = (xn). Clearly, (4.17) holds, and so, by Proposition 4.5.11, there
exists an element m ∈N such that In = Im for all n ∈N such that n ≥m. Hence
the claim follows (see Exercise A1.46).
⊓⊔
Lemma 4.5.13. Let A be a Noetherian integral domain. Then every non-zero, non-
invertible element of A is divisible by some irreducible element.
Proof. Let a be a non-zero, non-invertible element of A. If a is irreducible, we
are done. Otherwise, we can ﬁnd an element a1 of A, not associate to a, such that
a1 | a. If a1 is irreducible, then we are done. If a1 is reducible, we iterate the previous
argument. Keeping in mind Lemma 4.5.12, we see that this procedure ends, proving
the claim.
⊓⊔

178
4 Finite is not enough: factoring integers
We may now prove that condition (1) of Theorem 4.5.6 is always veriﬁed in
Noetherian rings:
Proposition 4.5.14. Let A be a Noetherian integral domain. Then every non-zero,
non-invertible element of A can be written as a product of irreducible elements.
Proof. Let a be a non-zero, non-invertible element of A. We want to prove that
a can be written as a product of irreducible elements. In order to do so, we use
the following procedure. If a is irreducible, there is nothing to prove. Otherwise,
by Lemma 4.5.13, we have a = a1b1 with a1 irreducible. If b1 is invertible, there
is nothing more to prove and our procedure terminates. Otherwise, we repeat the
procedure. The proposition is true if the procedure terminates. If it did not, we
would ﬁnd in this way two sequences {an}n∈N and {bn}n∈N of elements of A, such
that an is irreducible and bn is non-zero and non-invertible for all n ∈N, and
bn = an+1bn+1.
(4.18)
By Lemma 4.5.12, there exists a positive integer m such that bn is associate to bm for
all n ≥m. In particular, bn and bn+1 would be associate for all n ≥m, and so, from
(4.18) it follows that an+1 is invertible for all n ≥m, which is a contradiction.
⊓⊔
As a consequence we have that several remarkable rings are factorial. For in-
stance:
Theorem 4.5.15. Every principal ideal ring is factorial.
Proof. As already remarked in Section 4.5.1, part (2) of Theorem 4.5.6 can be
proved by reasoning as in the proof of Proposition 4.1.1 and keeping in mind that
in A a B´ezout’s identity holds for the greatest common divisor (see Proposition
1.3.13).
⊓⊔
Moreover:
Corollary 4.5.16. Every Euclidean ring is factorial.
Proof. Recall Theorem 1.3.14.
⊓⊔
Let us put on record the following important theorem concerning Noetherian
rings.
Theorem 4.5.17 (Hilbert’s basis theorem). If A is a Noetherian commutative
ring, then A[x1, . . . , xn] is Noetherian too.
Proof. It is suﬃcient to prove that if A is Noetherian, then A[x] is too, and then
to proceed by induction. Then, let I be an ideal of A[x]. For every integer n ∈N
let Jn be the set of elements of A that are leading coeﬃcients of some polynomial of
degree n in I. It is clear that Jn is an ideal of A and that Jn ⊆Jn+1 for all n ∈N.
Then there exists an m ∈N such that Jn = Jm for all integers n ≥m.
Let ai,1, . . . , ai,hi be a system of generators of Ji and let fi,j(x) be a polynomial of
I of degree i having ai,j as its leading coeﬃcient, for all i = 1, . . . , m and j = 1 . . . , hi.
We want to show that I coincides with the ideal I′ generated by all polynomials
fi,j(x) for i = 1, . . . , m and j = 1, . . . , hi. Reasoning by contradiction, assume that

4.5 Factorisation in an integral domain
179
this is not the case, and let f(x) ∈I be a polynomial of least degree not in I′ and
let a be its leading coeﬃcient.
Suppose f(x) has degree r ≤m. Then a ∈Jr and so there is a relation of the
form a = α1ar,1 + · · · + αhrar,hr with αj ∈A, j = 1, . . . , hr. So the polynomial
f(x) −(α1fr,1(x) + · · · + αhrfr,hr(x))
has degree smaller than r and is in I. By the minimality of r, it is in I′ and hence
it immediately follows that f(x) is in I′ too, which is a contradiction.
Assume f(x) has degree r > m. Then a ∈Jr = Jm and so there is a relation
of the form a = α1am,1 + · · · + αhmam,hm with αj ∈A, j = 1, . . . , hm. Again, the
following polynomial has degree smaller than r and is in I:
f(x) −xr−m(α1fm,1(x) + · · · + αhmfm,hm(x)).
Reasoning as above we get a contradiction.
⊓⊔
4.5.4 Factorisation of polynomials over a ﬁeld
Theorem 1.3.17 tells us the the ring of polynomials over a ﬁeld is Euclidean and so,
by Corollary 4.5.16, we have:
Corollary 4.5.18. The ring K[x] of polynomials over a ﬁeld K is factorial.
Then, given a ﬁeld K, the problem arises of ﬁnding a factorisation of a given
polynomial as a product of irreducible polynomials. Recall that a polynomial in
K[x] is invertible if and only if it is a non-zero constant. But which polynomials are
irreducible in K[x] or, as is commonly said, irreducible over K? The answer to this
question depends not so much on the polynomials as on the properties of the ﬁeld
K.
We begin by giving some remarks which can be proved by the reader as an
exercise (see Exercise A4.51):
Lemma 4.5.19. Let K be an arbitrary ﬁeld. Then:
(1) every polynomial is associate to a monic polynomial;
(2) all polynomials of degree one in K[x] are irreducible;
(3) a non-zero polynomial f(x) ∈K[x] has a factor of degree one if and only if it
has a root in K.
Recall that a ﬁeld K is said to be algebraically closed if every polynomial of
positive degree over K has some root in K.
Example 4.5.20. The polynomial x2 −2 is reducible over R as
x2 −2 = (x +
√
2)(x −
√
2),
and x +
√
2 and x −
√
2 are irreducible polynomials with coeﬃcients in R, while
it is irreducible over Q, as the polynomial x2 −2 has no roots in Q, that is,
√
2 /∈Q
and so x ±
√
2 /∈Q[x].
The polynomial x2 + 1 is reducible over C and
x2 + 1 = (x −i)(x + i)
is a factorisation into irreducibles, but it is irreducible over R and over Q as x2 + 1
has no roots in R, and therefore it cannot factor (into linear factors).

180
4 Finite is not enough: factoring integers
The following well known theorem says that C is an algebraically closed ﬁeld:
Theorem 4.5.21 (Fundamental theorem of algebra). A polynomial f(x) in
C[x] of degree n ≥1 admits at least one root in C.
Proof. We prove ﬁrst that, given a polynomial f(x) ∈C[x], the function |f(x)| has
a minimum in C.
Indeed, we have lim|x|→+∞|f(x)| = +∞(see Exercise A4.52). Let c ∈R be the
inﬁmum of |f(x)|. There exists a sequence {xn}n∈N of complex numbers such that
limn→∞|f(xn)| = c. On the other hand, the sequence {|xn|}n∈N is not unbounded.
So we can extract from {xn}n∈N a sequence converging to a point x ∈C and so
|f(x)| = c.
The theorem is now a consequence of the following claim: given a non-constant
polynomial f(x) ∈C[x], let z be a point such that f(z) ̸= 0. Then |f(z)| is not the
minimum of |f(x)|.
We may perform the change of variables x →x + z and assume that z = 0.
Moreover, we may multiply f(x) by a suitable constant and assume that f(0) = 1.
Then we have
f(x) = 1 + axk + terms of degree greater than k.
If we perform the change of variables x →αx with αk = −1/a (see Exercise A4.53),
we have just to consider the case
f(x) = 1 −xk + xk+1g(x)
with g(x) a suitable polynomial. Let now x be a positive real number very close to
0. Then
|f(x)| ≤|1 −xk| + xk+1|g(x)| = 1 −xk + xk+1|g(x)| = 1 −xk(1 −x|g(x)|).
As limx→0 x|g(x)| = 0, we may suppose that xk(1 −x|g(x)|) > 0 and so for x a
positive real number very close to 0 we have |f(x)| < 1 = f(0).
⊓⊔
If K is an algebraically closed ﬁeld, every polynomial f(x) ∈K[x] of degree n
admits in K exactly n roots, counting each with its multiplicity. That is to say, the
decomposition of f(x) into irreducible factors is
f(x) = a(x −a1)n1 · · · (x −ah)nh,
where a is the leading coeﬃcient of f(x), a1, . . . , ah are the distinct roots of f(x),
n1, . . . , nh are their multiplicities, and n = n1 + · · · + nh (see Exercise A1.56).
We may conclude that K is an algebraically closed ﬁeld if and only if
the irreducible polynomials in K[x] are exactly
the polynomials of degree one
that is, if and only if
every polynomial with coeﬃcients in K decomposes into linear fac-
tors.

4.5 Factorisation in an integral domain
181
The above holds, as already said, for polynomials over C. As regards a polynomial
over R, notice that, if α ∈C is one of its roots and is not real, then its conjugate α
is a root as well (see Exercise A1.57). Then, by the factor theorem, f(x) is divisible
by the real polynomial (x −α)(x −α) = x2 −2Re(α)x + |α|2, having discriminant
Δ < 0 as this polynomial has no real roots. Whence we can deduce (see Exercise
A4.60) that
the irreducible polynomials in R[x] are exactly the polynomials
of degree one and the ones of degree two with Δ < 0.
Example 4.5.22. We have that
x3 + x2 + 5x + 5 = (x + 1)(x2 + 5)
is a factorisation into irreducibles over R, while over C it factors into irreducibles as
x3 + x2 + 5x + 5 = (x + 1)(x −i
√
5)(x + i
√
5).
Remark 4.5.23. Notice that a polynomial with coeﬃcients in R with no real roots
may nevertheless be reducible. For instance, the polynomial
x4 + 8x2 + 15
has no real roots, but it factors as follows
x4 + 8x2 + 15 = (x2 + 3)(x2 + 5).
However notice the following:
Lemma 4.5.24. Let K be a ﬁeld and let f(x) ∈K[x] be a polynomial of degree 2 or
3. Then f(x) is irreducible in K[x] if and only if it has no roots in K.
Proof. Indeed, if f(x) had a factorisation, at least one of its factors would have
degree 1, so it would have a root in K.
⊓⊔
To sum up:
if a polynomial f(x) of degree > 1 with coeﬃcients in a ﬁeld K has a root in
K, then f(x) has a non trivial factorisation (and a factor is linear).
On the other hand,
a polynomial may well factor even if it has no roots in the ﬁeld (apart from
degree 2 and 3 polynomials, for which the existence of a root is equivalent to
reducibility).

182
4 Finite is not enough: factoring integers
4.5.5 Factorisation of polynomials over a factorial ring
Corollary 4.5.18 is a special case of the following general result:
Theorem 4.5.25. Consider a factorial integral domain A. Then A[x1, . . . , xn] is
factorial too.
This section is devoted to the proof of this result. Clearly, it is suﬃcient to prove
that if A is factorial then A[x] is factorial, and then proceed by induction.
We begin with the following remark. Given an integral domain A, we may con-
sider its ﬁeld of fractions Q(A), that is, the smallest ﬁeld containing A. It consists
of all fractions a/b with a, b ∈A and b ̸= 0. Clearly, a/b = c/d if and only if ad = bc.
If A is factorial, we always may assume the fractions a/b to be reduced, that is to
say, GCD(a, b) to be invertible.
For instance, Q is the ﬁeld of fractions of Z. If K is an arbitrary ﬁeld, the ﬁeld of
fractions of K[x] is denoted by K(x), is called ﬁeld of rational functions over K, and
consists of all the fractions f(x)/g(x) with f(x), g(x) relatively prime polynomials
with g(x) diﬀerent from zero.
Of course, A[x] is a subring of Q(A)[x], which is a factorial ring. However, we
cannot immediately deduce from this that A[x] is factorial, because, as we shall see
shortly, reducibility or irreducibility in Q(A)[x] and in A[x] are distinct concepts.
Before going on, we need a deﬁnition:
Deﬁnition 4.5.26. Let A be a factorial ring and let f(x) ∈A[x] be a non-zero
polynomial. The divisor, or content, of f(x) is a greatest common divisor c(f(x))
of its coeﬃcients. A polynomial is said to be primitive if its content is invertible.
Notice that, given a polynomial f(x) ∈A[x], we have
f(x) = c(f(x))f∗(x)
with f ∗(x) a primitive polynomial.
We may prove the following:
Proposition 4.5.27. Let A be a factorial ring and let f(x) ∈Q(A)[x]. Then
f(x) = d
mf ∗(x),
(4.19)
where d, m ∈A and GCD(d, m) = 1, and f∗(x) ∈A[x] is associate to f(x) in Q[x],
primitive and uniquely determined up to multiplication by an invertible element of
A.
Proof. Let f(x) = q0 + q1x + q2x2 + · · · + qnxn, where qi = bi/ci ∈Q(A) and bi, ci
in A, for all i = 0, . . . , n. Thus,
f(x) = b0
c0 + b1
c1 x + · · · + bn
cn xn.
Denoting by m′ a common multiple of c0, c1, . . . , cn, the polynomial
φ(x) = m′f(x) = b′
0 + b′
1x + · · · + b′
nxn

4.5 Factorisation in an integral domain
183
is a polynomial with coeﬃcients in A. We have
φ(x) = c(φ(x))f ∗(x)
with f ∗(x) = φ∗(x) ∈A[x] primitive. So,
f(x) = c(φ(x))
m′
f ∗(x)
and by reducing the fraction c(φ(x))/m′ we have (4.19).
Suppose now that
f(x) = d
mf ∗(x) = d′
m′ g∗(x),
with d′, m′ ∈A and GCD(d′, m′) = 1 and g∗(x) ∈A[x] primitive. So we have
m′df ∗(x) = md′g∗(x).
As f ∗(x) and g∗(x) are primitive, it follows that m′d and md′ are associate, so
d/m = ϵd′/m′, with ϵ ∈U(A). Hence the claim follows.
⊓⊔
Example 4.5.28. Consider the following polynomial with coeﬃcients in Q
f(x) = 5
7 + 5
8x −10
3 x2.
If m = 7 · 8 · 3 = 168, we have
168f(x) = 24 · 5 + 21 · 5x −56 · 10x2 = 5(24 + 121x −112x2).
So
f(x) = 5
7 + 5
8x −10
3 x2 =
5
168(24 + 121x −112x2),
or
f(x) =
5
168f ∗(x),
where f ∗(x) = 24 + 121x −112x2 is primitive, as GCD(24, 121, 112) = 1.
Let us now deal with the following general question: how are factorisation in
A[x] and those in Q(A)[x] related? First, we give some examples.
Example 4.5.29. Consider the primitive polynomial in Z[x]
f(x) = x4 + 7x2 + 10.
Suppose we know a factorisation over Q, for instance the following one:
f(x) =
5
3x2 + 10
3
 3
5x2 + 3

.
Then
f(x) = 5
3 (x2 + 2) 3
5 (x2 + 5) = (x2 + 2)(x2 + 5),
which is a factorisation over Z. Notice that the polynomial x2 + 2, which has coeﬃ-
cients in Z, is the primitive polynomial associate to the polynomial (5/3)x2 + 10/3,

184
4 Finite is not enough: factoring integers
and the polynomial x2 + 5 is the primitive associate polynomial to the polynomial
(3/5)x2 + 3.
Consider now with a non primitive polynomial
f(x) = 3x4 + 30x2 + 72
and let
f(x) =

2x2 + 8
	  3
2x2 + 9

be a factorisation of f(x) over Q. In order to ﬁnd a factorisation over Z we may
proceed as follows. Write ﬁrst
f(x) = df ∗(x) = 3(x4 + 10x2 + 24),
d = GCD(3, 30, 72).
Then
f ∗(x) = 1
3f(x) = 1
3

2x2 + 8
	  3
2x2 + 9

.
As f ∗(x) is primitive, we may repeat what we did above, that is,
f ∗(x) = 1
3 2 (x2 + 4) 3
2 (x2 + 6) = (x2 + 4)(x2 + 6),
which is a factorisation of f ∗(x) over Z. Then we have
f(x) = 3f ∗(x) = 3(x2 + 4)(x2 + 6).
In these examples we were able to ﬁnd a factorisation over Z of polynomial with
integer coeﬃcients when we had a factorisation over Q. This is possible in general,
and this is the content of Gauss Theorem 4.5.32 we shall prove shortly. To this end,
we need some preliminary results.
Proposition 4.5.30 (Gauss lemma). Let A be a factorial ring. The product of
two primitive polynomials in A[x] is again a primitive polynomial.
Proof. Let
f(x) = a0 + a1x + · · · + anxn,
g(x) = b0 + b1x + · · · + bmxm
be the two primitive polynomials. Assume by contradiction that f(x)g(x) is not
primitive. Then there exists an irreducible element p ∈A dividing all the coeﬃcients
of f(x)g(x). This element p cannot divide all the coeﬃcients of f(x) and of g(x) by
the hypothesis of primitivity. Let ah and bk be the smallest-indexed coeﬃcients of
f(x) and g(x), respectively, that are not divided by p. Look at the coeﬃcient with
index h + k in f(x)g(x). It is
ch+k = ahbk + (ah−1bk+1 + · · · + a0bh+k) + (ah+1bk−1 + · · · + ah+kb0).
Now, p divides ch+k and both summands in the parentheses, and so it divides ahbk.
Thus, it divides one of the two factors, contradicting the hypothesis.
⊓⊔
Corollary 4.5.31. Let A be a factorial ring. The content of the product of two
polynomials over A equals the product of the contents of the two polynomials.

4.5 Factorisation in an integral domain
185
Proof. Let f(x) = g(x)h(x), where f(x), g(x) and h(x) are polynomials in A[x].
Extract the content of the polynomials
f(x) = c(f(x))f∗(x) = c(g(x)) · g∗(x) · c(h(x)) · h∗(x) = c(g(x))c(h(x)) · g∗(x)h∗(x).
As g∗(x)h∗(x) is primitive, we have c(f(x)) = c(g(x))c(h(x)), up to product by
invertibles, as was to be proved.
⊓⊔
The following result is the key step to prove the Theorem 4.5.25:
Theorem 4.5.32 (Gauss theorem). Let A be a factorial ring. If a polynomial
f(x) ∈A[x] factors as a product of two polynomials g(x), h(x) with coeﬃcients in
Q(A), then it also factors as the product of two polynomials with coeﬃcients in A,
associate in Q(A)[x] to g(x) and to h(x).
Proof. Assume ﬁrst that f(x) is primitive. So let f(x) = g(x)h(x), g(x), h(x) ∈
Q(A)[x]. By Proposition 4.5.27 we have g(x)
=
(d1/m1)g∗(x) and h(x)
=
(d2/m2)h∗(x), with di, mi ∈A relatively prime, and g∗(x), h∗(x) primitive poly-
nomials in A[x]. As a consequence, f(x) = (d/m)g∗(x)h∗(x), d = d1d2, m = m1m2.
By Gauss lemma, the polynomial f ∗(x) = g∗(x)h∗(x) is primitive and we have
mf(x) = df ∗(x),
with f(x), f ∗(x) primitive. The left-hand-side polynomial and the right-hand-side
one have the same content. But as f(x) and f ∗(x) are primitive, we have m = d
and so
f(x) = g∗(x)h∗(x),
which is a factorisation over A with associate factors in Q(A)[x] to g(x), h(x).
When f(x) ∈A[x] is not primitive, we write f(x) = c(f(x))f∗(x) with f ∗(x)
primitive. If f(x) = c(f(x))f ∗(x) = g(x)h(x) is a factorisation of f(x) over Q(A),
then
f ∗(x) =
1
c(f(x))g(x)h(x)
is a factorisation over Q(A) and f ∗(x) is primitive. Thus, by what has already been
proved, f ∗(x) is factorisable over Z as well, that is,
f ∗(x) = ¯g(x)¯h(x)
with ¯g(x), ¯h(x) ∈A[x] associate in Q(A)[x] to g(x), h(x). But this implies that
f(x) = c(f(x))f∗(x) = c(f(x))¯g(x)¯h(x)
is a factorisation of f(x) over A as required.
⊓⊔
Corollary 4.5.33. Let A be a factorial ring and let f(x), g(x) be polynomials with
coeﬃcients in A. If f(x) is primitive and divides g(x) in Q(A)[x] then this happens
in A[x] too.
Proof. If f(x) divides g(x) in Q(A)[x], by Gauss theorem, there is a polynomial in
A[x] associate to f(x) in Q(A)[x], dividing g(x). Such a polynomial is of the form
(a/b)f(x), with GCD(a, b) = 1. As (a/b)f(x) ∈A[x], b has to divide every coeﬃcient
of f(x), and so b is invertible because f(x) is primitive. So a/b ∈A, and from this
the claim easily follows.
⊓⊔

186
4 Finite is not enough: factoring integers
Now somebody might want to venture the hypothesis that a polynomial with
coeﬃcients in a factorial domain A is irreducible if and only if it is irreducible over
Q(A). Beware! This is not true. The reason is that A is not a ﬁeld, so it contains
non-invertible elements. Let us demonstrate this point with an example:
Example 4.5.34. Consider the polynomial
f(x) = 3x2 + 6,
which is irreducible over Q, as it is associate to the polynomial x2 + 2 which is
irreducible over Q. However, f(x) is reducible over Z, as the factorisation
3x2 + 6 = 3(x2 + 2)
is a non-trivial factorisation over Z because 3 is not invertible over Z!
In other words, the two polynomials 3x2 + 6 and x2 + 2 are not associate in
Z[x], as the invertible elements in Z[x] are not all non-zero constants, but only ±1.
It should now be clear why reducibility of polynomials over Z does not imply their
reducibility over Q. On the other hand, if a polynomial is reducible over Q, then
it is reducible over R. Indeed, both Q and R are ﬁelds, one contained in the other,
and an element of Q is invertible in Q if and only if it is invertible in R. Thus, if a
polynomial in Q[x] is irreducible over R it is obviously also irreducible over Q.
It is also clear that:
Lemma 4.5.35. Let A be a factorial ring. A primitive polynomial f(x) ∈A[x] is
irreducible over A if and only if it is irreducible over Q(A).
The easy proof of this fact is left to the reader (see Exercise A4.54).
We are now in a position to give the:
Proof of Theorem 4.5.25. First of all, we prove that every f(x) ∈A[x] can be
written as a product of irreducible elements. Clearly, it suﬃces to consider the case
in which f(x) is primitive. If f(x) is irreducible, there is nothing to prove. Otherwise,
by Lemma 4.5.35, f(x) is reducible in Q(A), and so, by Gauss theorem, we have
f(x) = g(x)h(x) with g(x), h(x) ∈A[x], both of positive degree. By iterating this
reasoning, we arrive to a decomposition into irreducibles.
We have yet to prove that every element f(x) irreducible in A[x] is prime. If f(x)
is a constant, the claim follows from the fact that A is factorial. If f(x) has positive
degree, the hypothesis of it being irreducible implies that f(x) is primitive and that
it is irreducible in in Q(A) too (see Lemma 4.5.35). Suppose now that f(x) divides
g(x)h(x). Then it divides one of the two factors in Q[x], as Q(A)[x] is factorial. By
Corollary 4.5.33 we may conclude that f(x) divides the same factor in A[x].
⊓⊔
Remark 4.5.36. Theorem 4.5.25 implies in particular that, if K is a ﬁeld, the ring
of polynomials K[x1, . . . , xn] in n ≥2 variables over K is factorial. However, it is
not at all easy, not even when K is algebraically closed, to determine the irreducible
polynomials, and even less so to factor into irreducible polynomials an arbitrary
polynomial of K[x1, . . . , xn]. On the other hand, it is clear that all degree one poly-
nomials are irreducible (see Exercise A4.56). As regards degree two polynomials, see
[13], Chapter 22.

4.5 Factorisation in an integral domain
187
We close this section with a useful remark. Let A be a factorial ring. In order
to decide about the reducibility of a polynomial f(x) ∈A[x] over Q(A) it is useful
in the ﬁrst place to have a criterion to establish whether the polynomial has roots
in Q(A) or not. If it has roots, it is sure to be reducible. The following proposition
teaches us something useful in this regard.
Proposition 4.5.37 (Newton). Let A be a factorial ring. Let f(x) = a0 + a1x +
a2x2 + · · · + anxn ∈A[x]. Let α = r/s ∈Q(A) be a root of f(x), with r and s
relatively prime. Then r | a0 and s | an.
Proof. If α = r/s is a root of f(x), we ﬁnd: 0 = f(r/s) = a0+a1r/s+· · ·+anrn/sn.
Multiplying by sn we get
0 = sna0 + sn−1a1r + · · · + anrn =
= s(sn−1a0 + sn−2a1r + · · · + an−1rn−1) + anrn =
= sna0 + r(sn−1a1 + · · · + anrn−1).
From the relation 0 = s(sn−1a0+· · ·+an−1rn−1)+anrn it follows that s | anrn, and
from 0 = sna0 + r(sn−1a1 + · · ·+ anrn−1) it follows that r | a0sn. As GCD(r, s) = 1,
we may conclude that s | an and r | a0.
⊓⊔
Corollary 4.5.38. Let A be a factorial ring. If a polynomial with coeﬃcients in A
has a root in A, this root divides the constant term.
Corollary 4.5.39. Let A be a factorial ring. If a monic polynomial with coeﬃcients
in A has a root in Q(A), this root is in A.
Proposition 4.5.37 gives a set of elements of Q(A) which are candidates to be
roots of the polynomial f(x) ∈A[x]. This set can be used to construct an algorithm,
which unfortunately is not eﬃcient in the case A = Z (see Exercise A4.59), to
determine the rational roots of f(x): ﬁnd these candidates, which are ﬁnitely many,
ﬁrst, and then compute the value of f(x) in these candidates, to verify if they are
actually roots or not.
Example 4.5.40. Determine whether the polynomial
f(x) = 3x3 −4x2 + 2
has rational roots. By applying the algorithm described above, the possible rational
roots of f(x) must lie in the set
*
±1, ±2, ±1
3, ±2
3
+
.
As it may be easily veriﬁed, none of these rational numbers is a root of f(x), so f(x)
admits no rational roots. Being of degree 3, the polynomial is irreducible over Q.

188
4 Finite is not enough: factoring integers
4.5.6 Polynomials with rational or integer coeﬃcients
The results given in the previous section imply a strong connection between the
factorisation of polynomials over Q and over Z. However, in general it is not easy to
solve either problem. For instance, we have characterised the irreducible polynomials
over C and over R, but there is no similar result for polynomials over Q or Z. There
are only a few criteria to determine whether a given polynomial is irreducible over
Q or Z and some indications on how to attack the general problem.
As for criteria to determine whether a polynomial of arbitrary degree is irre-
ducible over Q, here is one of them.
Proposition 4.5.41 (Eisenstein’s irreducibility criterion). Consider a poly-
nomial f(x) = a0 + a1x + · · · + anxn ∈Z[x]. Let p be a prime number such that:
(1) p ∤an;
(2) p | ai for all i = 0, . . . , n −1;
(3) p2 ∤a0.
Then f(x) is irreducible over Q.
Proof. By Gauss theorem 4.5.32 it is suﬃcient to prove that f(x) is irreducible
over Z. Assume by contradiction that f(x) = g(x)h(x), with
g(x) = b0 + b1x + · · · + brxr,
h(x) = c0 + c1x + · · · + csxs,
polynomials with integer coeﬃcients of degree r < n and s < n respectively. Then
r + s = n and b0c0 = a0. As p | a0, we have p | b0 or p | c0. Notice that p | b0
and p | c0 cannot hold simultaneously, or else we would have p2 | a0. So assume
that p divides, say, b0 but not c0. Notice that p cannot divide all the bis, or else p
would divide all the ais, contradicting the hypothesis. Let bi be the lowest-indexed
coeﬃcient not divided by p. Then, for i ≤r < n,
ai = bic0 + bi−1c1 + · · · + b0ci.
Notice that p divides ai (i < n) and also divides all the bks with k = 0, . . . , i −1.
Hence p divides bic0 and, as it may not divide bi, it has to divide c0, yielding a
contradiction, derived from assuming f(x) to be reducible.
⊓⊔
Notice that Eisenstein’s criterion gives a suﬃcient condition for irreducibility,
but not a necessary one.
Eisenstein’s criterion extends to polynomials over factorial domains.
If Eisenstein’s criterion does not directly apply to a polynomial, it might never-
theless be possible to apply it after having suitably modiﬁed the polynomial. Given
a constant α, it is for instance possible to consider, rather than the polynomial f(x),
a new polynomial f(x −α) or, for α ̸= 0, the polynomial f(x/α), by observing that
f(x) ∈K[x] is irreducible over the ﬁeld K if and only if f(x −α) and f(x/α) with
α ∈K are as well (see Exercise A4.57). As an application of this idea, we prove the
following result:
Proposition 4.5.42. If p is a prime number, the polynomial
xp−1 + xp−2 + · · · + x2 + x + 1
is irreducible over Q.

4.5 Factorisation in an integral domain
189
Proof. Notice that xp−1+xp−2+· · ·+x2+x+1 = (xp −1)/(x −1). So, substituting
x + 1 for x, we get
(x + 1)p−1 + (x + 1)p−2 + · · · + (x + 1)2 + (x + 1) + 1 = (x + 1)p −1
(x + 1) −1 =
= 1
x

p

k=0

p
k

xp−k −1

= xp−1 +

p
1

xp−2 +

p
2

xp−3 + · · · + p.
We may now apply Eisenstein’s criterion with respect to the prime p, and so prove
that the originary polynomial is irreducible.
⊓⊔
Another method, which is practical only when the degree of the polynomial
under consideration is not too large, amounts to looking directly for a factorisation.
For instance, if f(x) is primitive (as we may suppose without loss of generality)
of degree 5 and if we have previously checked that the polynomial has no rational
roots, then, if f(x) is reducible, it may only decompose as the product of a degree two
polynomial and a degree three one. So, writing down the factors with indeterminate
coeﬃcients and equating the coeﬃcients of the polynomial and those of the product,
we obtain a system and we are interested in its integer solutions: indeed, as we know,
we may always reduce to a factorisation in Z[x]. If the system is not compatible,
then the originary polynomial is irreducible.
Example 4.5.43. Prove, using the method just described, that x4 +1 is irreducible
over Q. Indeed, the polynomial has no rational roots, so it may only factor into the
product of two degree two polynomials. Keeping in mind that the leading coeﬃcient
of the product is the product of the leading coeﬃcients, and the constant term of
the product is the product of the constant terms of the factors, we may write
x4 + 1 = (x2 + αx ± 1)(x2 + βx ± 1),
where either both plus signs or both minus signs will be chosen. The system obtained
by equating the coeﬃcients is

α + β = 0,
αβ = ∓2,
which does not admit integer solutions. Notice that, over R, x4+1 factors as x4+1 =
(x2 +
√
2x + 1)(x2 −
√
2x + 1).
This method is not at all computationally eﬃcient (see Exercise A4.61): in partic-
ular, it becomes more and more infeasible as the degree of the polynomial increases.
Another useful method is the following. Let f(x) = n
i=0 aixi be a primitive
polynomial with coeﬃcients in Z. Reduce the coeﬃcients modulo a prime number p,
that is to say, consider the polynomial f(x) as having coeﬃcients in Zp. Denote by
¯f(x) ∈Zp[x] the new polynomial, which we shall call the reduction of f(x) modulo
p. Notice that if we choose a value of p not dividing an, then f(x) and ¯f(x) have the
same degree. If f(x) = g(x)h(x), with g(x) and h(x) of positive degree in Z[x], then
we also have ¯f(x) = ¯g(x)¯h(x). If p ∤an, then p does not divide the leading coeﬃcients
of g(x) and h(x), so ¯g(x) and ¯h(x) have positive degree too. In conclusion, if f(x)
is reducible in Q, then ¯f(x) it is reducible in Zp[x]. So we may deduce that:

190
4 Finite is not enough: factoring integers
if ¯f(x) is irreducible over Zp for some p ∤an,
then f(x) is irreducible over Q as well.
Notice that the converse is not true, that is to say, it is not the case that if, for
some p, ¯f(x) is reducible over Zp, then f(x) is reducible over Q.
Example 4.5.44. We have seen that x4 + 1 is irreducible over Q. Still, x4 + 1 is
reducible over Z2; indeed, x4 + 1 = (x2 + 1)(x2 + 1) in Z2[x].
Now, as the irreducibility test in Zp[x] is a ﬁnite test, working modulo p is
convenient and not computationally expensive (see Exercise A4.62). Let us see an
example to show how this method works.
Example 4.5.45. We shall verify that the polynomial 5x4−2x3+9x−1 is irreducible
over Q. If we consider it as a polynomial with coeﬃcients in Z2, the polynomial is
x4 + x + 1. This polynomial has no roots in Z2, so, if it factors, it does so into the
product of two second degree factors: that is, we would get
x4 + x + 1 = (x2 + ax + 1)(x2 + bx + 1),
or
x4 + x + 1 = x4 + (a + b)x3 + abx2 + (a + b)x + 1,
which is clearly impossible. So x4 + x + 1 is irreducible over Z2, which implies that
the originary polynomial is irreducible over Q.
For the convenience of the reader, we give now a summary of the methods we
have seen to study the reducibility or irreducibility of a polynomial with rational
coeﬃcients.
Methods to study the irreducibility of a polynomial over Q:
•
consider without loss of generality only primitive polynomials f(x) ∈Z[x];
•
use the test for the existence of rational roots based upon Proposition 4.5.37 to
conclude that f(x) is reducible: the existence of roots implies the reducibility of
the polynomial; in particular, if f(x) is of degree 2 or 3, it is irreducible over Q
if and only if it has no roots in Q;
•
if possible, especially for low degrees, look for a factorisation into polynomials
with integer coeﬃcients;
•
apply Eisenstein’s criterion, when there is a prime p verifying the hypotheses,
to conclude that f(x) is irreducible over Q;
•
use transformations of the form x →x + α to be able to apply Eisenstein’s
criterion;
•
consider ¯f(x) ∈Zp[x] rather than f(x) ∈Z[x]: if there exists a p not dividing
the leading coeﬃcient of f(x) and such that ¯f(x) is irreducible over Zp, then
f(x) is irreducible over Q.

4.6 Lagrange interpolation and its applications
191
4.6 Lagrange interpolation and its applications
In this section we are going to describe a classical idea, that is, the so-called
Lagrange interpolation. In order to do so, we shall start with a concrete cryp-
tographic problem, the secret sharing problem, which can be solved using
Lagrange interpolation. In the next section we shall see another application
of Lagrange interpolation to the factorisation of polynomials.
So, we begin by describing a concrete problem which apparently has noth-
ing to do with polynomials.
Suppose that the chairman of a pharmaceutical company has the formula
for a new chemical compound of the utmost importance. To prevent indus-
trial espionage, he hides the formula into a safe, the access code for which
nobody knows but him. However, it is necessary that the people working on
the molecule will be able to open the safe even when he is away. His problem
is a security one: he does not want all the information to be in the hands
of just one or two persons, but neither it is advisable that, in order to open
the safe, all the heads of the laboratories have to be present, their number n
being quite high. So the chairman would like to divide the information about
the access code into n blocks of information, sharing them among n people,
but in such a way that k people, with k ≤n, are suﬃcient to reconstruct the
secret. The number k is, for instance, the least number of people necessary to
perform the experiment to produce the important molecule.
A solution to this problem is given by Lagrange interpolation (for a dif-
ferent kind of solution to the same problem, using integers rather than poly-
nomials, see Exercise A4.66). Before seeing how it works, we give some useful
results.
We have seen that many properties of the integers also hold for polyno-
mials. For instance, for polynomials too a Chinese remainder theorem holds,
analogous to the one for integers (see Theorem 3.4.2 on page 129). It will
just be stated here, the proof being left as an exercise to the reader, who can
mimic the argument given in the case of integers (see Exercise A4.67).
Proposition 4.6.1 (Chinese remainder theorem for polynomials). Let
K be a ﬁeld. Let a1(x), a2(x), . . . , at(x) be arbitrary polynomials in K[x] and let
m1(x), m2(x), . . . , mt(x) be pairwise relatively prime polynomials. Then there
exists a unique polynomial f(x) ∈K[x], of degree smaller than the degree of
m1(x)m2(x) · · · mt(x) such that
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
f(x)
≡a1(x)
(mod m1(x)),
f(x)
≡a2(x)
(mod m2(x)),
...
f(x)
≡at(x)
(mod mt(x)).
Clearly, f(x) ≡g(x) (mod h(x)) means that f(x) −g(x) is divisible by
h(x). The following result is a consequence of the Chinese remainder theorem
(for another proof, see Exercise A4.63).

192
4 Finite is not enough: factoring integers
Corollary 4.6.2. If a0, a1, . . . , aM are distinct elements of a ﬁeld K and
s0, s1, . . . , sM are elements of K, there exists a unique polynomial p(x) ∈K[x]
of degree n ≤M such that
p(ai) = si,
i = 0, 1, . . ., M.
(4.20)
Proof. It suﬃces to remark that p(x) ≡b (mod (x −a)) if and only if
p(a) = b and to apply the Chinese remainder theorem with mi(x) = x −ai.
⊓⊔
The unique polynomial satisfying the conditions of the corollary is called
the Lagrange interpolation polynomial with respect to the data a0, a1, . . . , aM
and s0, s1, . . . , sM. How is this polynomial found? Here follows an algorithm
to solve this problem. It is called the Lagrange interpolation algorithm.
Consider the polynomial of degree M + 1
h(x) = (x −a0)(x −a1) · · · (x −aM)
with its derivative h′(x) (see § 1.3.6).
The polynomial
(x −a0)(x −a1) · · · 
(x −ai) · · · (x −aM)
(where by

(x −ai) we mean that the factor (x −ai) is omitted) has degree M,
its value in ai is diﬀerent from zero and coincides with h′(ai). The polynomial
Li(x) =
h(x)
(x −ai)h′(ai) =
,
i̸=j(x −aj)
,
i̸=j(ai −aj)
has degree M and is such that

Li(aj) = 1
if i = j,
Li(aj) = 0
if i ̸= j.
The polynomials Li(x) are called the Lagrange polynomials with respect to
a0, a1, . . . , aM.
The polynomial
L(x) =
M

i=0
siLi(x)
has degree M and is such that L(ai) = si for all i = 0, . . . , M. So L(x) = p(x)
is the Lagrange interpolating polynomial we were looking for: so we have
proved that
p(x) =
M

i=0
siLi(x).
Here follows an example:

4.6 Lagrange interpolation and its applications
193
Example 4.6.3. Determine a polynomial p(x) ∈Q[x] of degree at most 3
satisfying the following conditions:
p(0) = 1,
p(1) = −1,
p(−1) = 4,
p(2) = 3.
We compute the polynomial h(x) ﬁrst:
h(x) = x(x −1)(x + 1)(x −2)
and the values h′(ai):
h′(0) = (0 −1)(0 + 1)(0 −2) = 2,
h′(1) = (1 −0)(1 + 1)(1 −2) = −2,
h′(−1) = (−1 −0)(−1 −1)(−1 −2) = −6,
h′(2) = (2 −0)(2 −1)(2 + 1) = 6.
Next, we compute the Lagrange polynomials Li(x):
L0 = (x −1)(x + 1)(x −2)
2
,
L1 = x(x + 1)(x −2)
−2
,
L2 = x(x −1)(x −2)
−6
,
L3 = x(x −1)(x + 1)
6
.
The polynomial we are looking for is
p(x) = 1 · L0 + (−1) · L1 + 4 · L2 + 3 · L3 = 5
6x3 + 1
2x2 −10
3 x + 1.
Let us come back to the problem of the chairman of the pharmaceutical
company.
Example 4.6.4. Suppose the secret, that is the access code of the safe, is
represented by a number, and to simplify computations assume this number
to be −1.
Recall that the chairman of the pharmaceutical company wants to di-
vide the information, that is, the access code, into n blocks of information
P0, P1, . . . , Pn−1 and distribute them among n of his oﬃcers in such a way
that it is necessary for at least k people to be present (k ≤n) to reconstruct
the secret. Which is the most convenient way to choose k?
The chairman knows that the experiment to produce the important chem-
ical compound requires at least four people to be present, so he decides to
choose k = 4. He decides next to hide the secret key −1 among the coeﬃ-
cients of a polynomial of degree k −1 = 3, for instance
p(x) = x3 −x2 + 1.
In this way he has chosen a polynomial of degree 3 with arbitrary integer
coeﬃcients, except for the degree two coeﬃcient, which equals −1, that is,

194
4 Finite is not enough: factoring integers
the key to access the secret formula. Now the sharing of the n blocks of
information Pi among the n oﬃcers may be done as follows: the chairman
randomly chooses n distinct numbers a0, a1, . . . , an−1 and gives the ith oﬃcer
(i = 0, 1, . . . , n −1) the information
Pi = (ai, p(ai)).
So each oﬃcer receives a pair of numbers and knows that the second el-
ement of the pair Pi he has received is the value the unknown degree three
polynomial assumes in the ﬁrst element of the pair. Moreover, each oﬃcer
knows that the secret key is the coeﬃcient of the degree two term.
No single oﬃcer, nor any two or three of them, has enough information to
solve the problem of ﬁnding the degree three polynomial. But if four people
collaborate, they can discover the secret, that is, reconstruct the polynomial.
Indeed, let C0, C1, C2 and C3 be the four people and suppose they have
received the following pieces of information:
P0 = (−1, −1), P1 = (0, 1), P2 = (2, 5), P3 = (3, 19).
Let us see how they can reconstruct the polynomial chosen by the chairman:
they know that the unknown polynomial p(x) is such that
p(a0) = −1,
with a0 = −1,
p(a1) = 1,
with a1 = 0,
p(a2) = 5,
with a2 = 2,
p(a3) = 19,
with a3 = 3.
So they have to construct a degree three polynomial for which the values
it assumes at 4 distinct points are known. This may be done by applying
Lagrange interpolation algorithm. Indeed
h(x) = (x + 1)x(x −2)(x −3)
can be determined, and hence
h′(−1) = (−1 −0)(−1 −2)(−1 −3) = −12,
h′(0) = (0 + 1)(0 −2)(0 −3) = 6,
h′(2) = (2 + 1)(2 −0)(2 −3) = −6,
h′(3) = (3 + 1)(3 −0)(3 −2) = 12.
Then

4.7 Kronecker’s factorisation method
195
L0(x) = x(x −2)(x −3)
−12
= −1
12(x3 −5x2 + 6x),
L1(x) = (x + 1)(x −2)(x −3)
6
= 1
6(x3 −4x2 + x + 6),
L2(x) = (x + 1)x(x −3)
−6
= −1
6(x3 −2x2 −3x),
L3(x) = (x + 1)x(x −2)
12
= 1
12(x3 −x2 −2x),
3

i=0
siLi(x) = (−1)L0 + 1L1(x) + 5L2(x) + 19L3(x) =
= 1
12(12x3 −12x2 + 0 · x + 12) = x3 −x2 + 1.
So the four oﬃcers discover that the secret key is −1, may open the safe
containing the formula, and perform the experiment.
We emphasise the fact that ﬁve or more people could have opened the safe
as well, but that would have been impossible for three or less.
And if the four people, rather than C0, C1, C2, C3, were C′
0, C′
1, C′
2, C′
3,
each with the following pieces of information
P ′
0 = (−2, −11), P ′
1 = (−3, −35), P ′
2 = (1, 1), P ′
3 = (0, 1),
how could they proceed to ﬁnd the key? The reader may now answer on his
own to this question (see Exercise A4.68).
4.7 Kronecker’s factorisation method
In this section we shall describe a factorisation method found by Kronecker,
which is a consequence of Lagrange interpolation. It gives the factorisation on
Z of a polynomial with integer coeﬃcients.
Let f(x) ∈Z[x] be the polynomial to be factorised. Notice that, if f(x)
has degree n and is not irreducible, then it certainly has a factor of degree
≤n/2. Deﬁne M = ⌊n/2⌋.
Pick M + 1 distinct integer ‘samples’ a0, a1, . . . , aM. Set:
r0 = f(a0),
r1 = f(a1),
. . . ,
rM = f(aM).
Clearly, the ris are themselves integer, as the polynomial f(x) has coeﬃcients
in Z. Construct the following (M + 1)–tuples of numbers:
s = (s0, s1, . . . , sM)
with si | ri, for any i = 0, . . . , M.
For each of these (M +1)–tuple s, there exists exactly one polynomial fs(x) ∈
Q[x] of degree ≤M such that

196
4 Finite is not enough: factoring integers
fs(ai) = si,
for all i = 0, . . . , M.
Now, each ri has a ﬁnite number of divisors, so there are ﬁnitely many (M+1)–
tuples s = (s0, . . . , sM), where si are integers dividing ri. Corresponding to
these (M+1)–tuples s there are ﬁnitely many polynomials fs(x). The following
result, basically, says that the divisors of f(x) are to be searched for among
these polynomials fs(x).
Proposition 4.7.1. Let f(x) be a polynomial of degree n with coeﬃcients in
Z and let M = ⌊n/2⌋. Chosen M + 1 distinct integers a0, a1, . . . , aM, let S
be the set of all (M + 1)–tuples s = (s0, s1, . . . , sM) of integers si such that
si | ri = f(ai) for all i = 0, . . . , M. Then, if fs(x) is the unique polynomial
with coeﬃcients in Q such that fs(ai) = si for all i = 0, . . . , M, each divisor
of f(x) of degree ≤M is one of the polynomials fs(x), with s ∈S.
Proof. Let p(x) ∈Z[x] be a factor of f(x) of degree at most M. So, f(x) =
p(x)q(x) for some q(x) ∈Z[x].
For all i = 0, 1, . . ., M, if p(ai)q(ai) = f(ai), then p(ai) | f(ai) = ri. Thus,
the (M+1)–tuple s = (p(a0), p(a1), . . . , p(aM)) belongs to S, as each p(ai) | ri.
By the Chinese remainder theorem, there exists exactly one polynomial fs(x)
such that
fs(a0) = p(a0), fs(a1) = p(a1), . . . , fs(aM) = p(aM).
The two polynomials fs(x) and p(x) have degree at most M; so they are
equal.
⊓⊔
This proposition enables us to ﬁnd the factors of a polynomial f(x) of
Z[x]. Indeed, it suﬃces to divide f(x) by each of the fs(x). If no fs(x) divides
f(x), it follows that f(x) is irreducible. Otherwise, proceeding by induction
on the degree of f(x), it si possible to completely factorise f(x) in a ﬁnite
number of steps.
Notice that the size of the set S of all strings may be very large, and
the computing time required by this algorithm is exponential: it may not be
eﬃcient for polynomials of degrees as low as 5. Nevertheless, it is a useful
method for low degrees.
Example 4.7.2. Factorise using Lagrange interpolation the polynomial
f(x) = x4 + 3x + 1, or prove that it is irreducible.
Here M = 2. Choose as sample integers the following ones:
a0 = 0,
a1 = 1,
a2 = −1.
Then
r0 = f(0) = 1,
r1 = f(1) = 5,
r2 = f(−1) = −1.
The set S consists then of the following triples s = (s0, s1, s2):

4.7 Kronecker’s factorisation method
197
(±1, ±5, ±1),
(±1, ±1, ±1).
Compute next
h(x) = x(x −1)(x + 1),
h′(a0) = −1,
h′(a1) = 2,
h′(a2) = 2.
The Lagrange interpolation polynomial fs(x) is
fs(x) = s0L0(x) + s1L1(x) + s2L2(x),
where
Li(x) =
h(x)
(x −ai)h′(ai) =
,
i̸=j(x −aj)
,
i̸=j(ai −aj).
So
fs(x) = s0
(x −1)(x + 1)
−1
+ s1
x(x + 1)
2
+ s2
x(x −1)
2
.
Corresponding to each of the 16 triples we ﬁnd the following candidate divisors
of f(x).
(1, 5, 1)
2x2 + 2x + 1
(1, 1, 1)
1
(1, 5, −1)
x2 + 3x + 1
(1, 1, −1)
−x2 + x + 1
(−1, 5, 1)
4x2 + 2x −1
(−1, 1, 1)
2x2 −1
(−1, 5, −1)
3x2 + 3x −1
(−1, 1, −1)
x2 + x −1
(1, −5, 1)
−3x2 −3x + 1
(1, −1, 1)
−x2 −x + 1
(1, −5, −1)
−4x2 −2x + 1
(1, −1, −1)
−2x2 + 1
(−1, −5, 1)
−x2 −3x −1
(−1, −1, 1)
x2 −x −1
(−1, −5, −1)
−2x2 −2x −1
(−1, −1, −1)
−1
As we began with a primitive polynomial f(x) we may assume that all
factors of f(x) are primitive. Moreover, as f(x) is monic, its factors have
leading coeﬃcient ±1. So we may exclude from the list all the polynomials
that are not primitive (in this case, all the polynomials are primitive) and
those with leading coeﬃcient diﬀerent from ±1. Excluding ±1 as well, the
following polynomials remain:
x2 + 3x + 1, −x2 −3x −1, −x2 + x + 1, x2 + x −1, −x2 −x + 1, x2 −x −1.
Finally, notice that three of these polynomials coincide with the remaining
three up to a factor −1, so it suﬃces to consider the following polynomials:
x2 + 3x + 1,
x2 + x −1,
x2 −x −1.
None of them divides f(x), so f(x) is irreducible.
In the previous example we were lucky, as the number of triples s, and so
of possible divisors, was quite small, due to the fact that each triple includes
two elements equal to 1, which has as only divisors ±1. Let us see how the
situation changes with a diﬀerent polynomial, even of the same degree 4.

198
4 Finite is not enough: factoring integers
Example 4.7.3. Consider the polynomial
f(x) = x4 + 3x3 + 4x2 + 9x + 3.
Then M = 2. Chose M + 1 = 3 sample integers, for instance
a0 = 0,
a1 = 1,
a2 = −1.
We have
f(0) = 3,
f(1) = 20,
f(−1) = −4.
The number 3 has 4 divisors, namely ±1 and ±3; 20 has 12 divisors: ±1, ±2,
±4, ±5, ±10 and ±20; −4 has 6 divisors: ±1, ±2 and ±4. There are 288 triples
s on the whole. We might change our sample integers trying to improve the
situation, but it will still be diﬃcult. It is often convenient to compute f(ai)
for more than M + 1 sample values ai so to be able to choose those values of
f(ai) having as few divisors as possible.
Finally, this method can be used to look just for divisors having a given
degree k ≤M. In this case, the sample integers have to be k + 1 rather
than M + 1: if we are looking for the linear factors, we are taking k = 1,
and consequently 2 sample integers; for the second degree divisors, 3 sample
integers, and so on.
Appendix to Chapter 4
A4 Theoretical exercises
A4.1.* Given two positive integers a, b, we may consider their least common multiple
lcm(a, b), that is to say, the least element in the set M(a, b) of the positive numbers
n that are multiples of both a and b. Prove that if
a = ph1
1 ph2
2 · · · phr
r ,
b = pk1
1 ph2
2 · · · pkr
r
are the factorisations of a and b with p1, . . . , pr distinct prime numbers and
h1, . . . , hr, k1, . . . , kr non-negative numbers, we have
lcm(a, b) = ps1
1 ps2
2 · · · psr
r ,
where si = max{hi, ki}, i = 1, . . . , r. Deduce that
lcm(a, b) =
ab
GCD(a, b).
A4.2. Prove that the product rs of two integers r and s is relatively prime with
another integer m if and only if r is relatively prime with (m mod r) and s is
relatively prime (m mod s).

A4 Theoretical exercises
199
A4.3. Let f(x) be a non-constant polynomial with integer coeﬃcients. Assume that,
for some y, f(y) is a prime number p. Prove that in this case p divides f(y + kp) for
all k ∈N.
A4.4. Using the Fundamental Theorem of Arithmetic, prove that if p is a prime
integer number, then √p is an irrational number.
A4.5.* Prove formula (4.2).
A4.6.* In this exercise we outline a diﬀerent proof, found by Euler, of Theorem 4.1.3.
Recall that the geometric series ∞
n=0 xn converges to 1/(1 −x) for all positive x
smaller than 1. Deduce that, if p1, . . . , pr are integer numbers greater than 1, we
have
r
'
i=1
∞

n=0
1
pn
i
=
r
'
i=1
pi
pi −1.
Notice that, if there were no prime numbers other than p1, . . . , pr, then, by the Fun-
damental Theorem of Arithmetic, the left-hand side would be exactly ∞
m=0 1/m,
that is the harmonic series which, as is well known, diverges. Deduce that there are
inﬁnitely many prime numbers.
A4.7.* Verify that the complexity of the sieve of Eratosthenes to ﬁnd all prime
numbers smaller than a given positive integer number n is O(√n log n), so it is
exponential.
A4.8. Prove that if a, n, m, p are positive integers and if an ≡1 (mod p) and am ≡1
(mod p), then ad ≡1 (mod p), where d = GCD(n, m).
A4.9. Prove that, if p is prime, the binomial coeﬃcient
p
k
	
is multiple of p for all
p > k > 0.
A4.10. Verify that for every prime number p and for all pair of integers x, y the
following congruence holds:
(x + y)p ≡xp + yp
(mod p).
This formula is called the Freshman’s dream.
A4.11.* In this exercise we give an elementary proof of Fermat’s little theorem 4.2.5
based on the Fundamental Theorem of Arithmetic.
Fix p and prove ﬁrst the theorem for a ≥0. Proceed by induction on a, the
theorem being true for a = 0. Apply the previous exercise to prove that
(a + 1)p ≡ap + 1p
(mod p).
Apply next the induction hypothesis and conclude. In the case a < 0, notice that
0 ≡0p = (a + (−a))p ≡ap + (−a)p
(mod p)
And conclude by applying what has already been proved in the case a ≥0.
A4.12.* In this exercise we give an elementary proof of Euler’s Theorem 3.3.11
based on the Fundamental Theorem of Arithmetic.
Let n = pk1
1 pk2
2 · · · pkr
r
be an integer such that GCD(a, n) = 1. Assume we have
proved that

200
4 Finite is not enough: factoring integers
aϕ(pki
i ) ≡1
(mod pki
i ),
∀i = 1, 2, . . . , r.
As ϕ(n)/ϕ(pki
i ) is an integer (for all i = 1, . . . , r), by the multiplicativity of Euler
function (see Proposition 4.2.3) it follows that

aϕ(pki
i )
ϕ(n)/ϕ(pki
i )
= aϕ(n) ≡1
(mod pki
i )
and so
aϕ(n) ≡1
(mod n).
Now it remains to be proved that, if p is a prime not dividing a, then
aϕ(pk) ≡1
(mod pk).
(4.21)
Proceed by induction on k. For k = 1, (4.21) follows from Fermat’s little theorem.
Assume that (4.21) is true for k and prove it for k + 1. Equation (4.21) can be
written as
aϕ(pk) = 1 + hpk
for some h ∈Z. Also notice that
ϕ(pk+1) = pk+1 −pk = p(pk −pk−1) = p · ϕ(pk).
Conclude the proof in this case by remarking that
aϕ(pk+1) = ap·ϕ(pk) = (1 + hpk)p =
= 1 + phpk +

p
2

h2p2k + · · · + php−1pk(p−1) + hppkp ≡1
(mod pk+1).
A4.13. Prove that if n is a product of two distinct prime numbers, knowing ϕ(n),
the two prime factors of n can be obtained and vice versa.
In the following exercises, from A4.14 to A4.29, we shall give some important
properties of the Euler function and, more in general, of multiplicative functions:
A4.14. Let n and d be positive integers, with d ≤n. Let Cd be the subset of
{1, . . . , n} consisting of all the integers m ∈{1, . . . , n} such that GCD(m, n) = d,
that is to say, such that GCD(m/d, n/d) = 1. Prove that the order of Cd is ϕ(n/d).
Deduce that:
n =

d|n
ϕ
 n
d
 
=

d|n
ϕ(d).
A4.15.* An integer n > 1 is said to be square-free if it is not divisible by any
square of an integer m ̸= ±1. If n is square-free, then its factorisation has the form
n = p1, . . . , pr with p1, . . . , pr distinct prime numbers. Deﬁne μ(n) = (−1)r. Deﬁne
next μ(1) = 1 and μ(n) = 0 if n is not square-free. So we have deﬁned the M¨obius
function μ : N \ {0} →N \ {0}. Verify that μ is multiplicative.
A4.16.* Prove that if n > 1 the following holds:

d|n
μ(d) = 0.

A4 Theoretical exercises
201
A4.17.* Given two functions f : N \ {0} →N \ {0}, g : N \ {0} →N \ {0}, deﬁne
the Dirichlet product of f and g as
f ∗g =

d|n
f(d)g
 n
d
 
.
Prove that this product is associative and commutative.
A4.18.* Consider the function Π : N \ {0} →N \ {0} deﬁned by Π(1) = 1 and
Π(n) = 0 if n > 1. Prove that for every function f : N \ {0} →N \ {0}, one has
Π ∗f = f ∗Π = f.
A4.19.* Consider the function I : N \ {0} →N \ {0} deﬁned by I(n) = 1 for all
n ≥1. For every function f : N \ {0} →N \ {0}, consider the function Ef :=
I ∗f(n) = f ∗I(n) = 
d|n f(d), for all n ≥1. Prove that Eϕ = ι, where ι is the
identity function on N \ {0}.
A4.20.* Prove that if f and g are multiplicative, so is f ∗g. Prove that if the function
f : N \ {0} →N \ {0} is multiplicative, so is Ef.
A4.21.* Prove that I ∗μ = μ ∗I = Π, where I and Π are the functions deﬁned in
Exercises A4.19 and A4.18, respectively.
A4.22.* Prove M¨obius inversion theorem, which states that for every function f :
N \ {0} →N \ {0}, one has f = μ ∗Ef, that is to say, for all positive integers n:
f(n) =

d|n
μ(d)Ef
 n
d
 
.
A4.23.* Prove that f is multiplicative if and only if Ef is multiplicative. Deduce
that ϕ is multiplicative.
A4.24.* Apply M¨obius inversion theorem to the function ϕ to deduce another proof
of Equation (4.4).
A4.25.* Deﬁne σ = Eι, that is to say, for all positive integers n we put σ(n) =

d|n d. Deduce that σ is multiplicative. Prove that for all positive integers n we
have
n =

d|n
σ(d)μ
 n
d
 
.
A4.26.* Deﬁne ν = EI, that is to say, for all positive integers n we put ν(n) =

d|n 1, that is, ν(n) is the number of divisors of n. Deduce that ν is multiplicative.
Prove that for all positive integers n we have

d|n
ν(d)μ
 n
d
 
= 1.
A4.27.* Let n = ph1
1 · · · phr
r
be the prime decomposition of n. Prove that
ν(n) = (h1 + 1) · · · (hr + 1),
σ(n) = ph1+1
1
−1
p1 −1
· · · phr+1
r
−1
pr −1
.
A4.28.* Let n = p1 · · · pr be the prime decomposition of a square-free number n.
Prove that

202
4 Finite is not enough: factoring integers
ν(n) = 2r,
σ(n) = (p1 + 1) · · · (pr + 1).
A4.29.* Prove the following identities:
1
ζ(s) =
∞

n=1
μ(n)
ns ,
ζ(s)2 =
∞

n=1
ν(n)
ns ,
ζ(s)ζ(s −1) =
∞

n=1
σ(n)
ns .
A4.30.* Let n, m, a be positive numbers pairwise relatively prime. Prove that
Gss(nm, a) = lcm(Gss(n, a), Gss(m, a)).
A4.31.* Let p be a prime number and a a positive integer not divisible by p. Prove
that for all positive integers r the following holds:
Gss(p, ar) =
Gss(p, a)
GCD(r, Gss(p, a)).
If moreover b is a positive integer not divisible by p and of GCD(Gss(p, a),
Gss(p, b)) = 1, then prove that
Gss(p, ab) = Gss(p, a) · Gss(p, b).
A4.32. Verify identity (4.13).
A4.33. Verify identity (4.14).
A4.34. Prove that if m | n then the polynomial xm−1 divides the polynomial xn−1
in Z[x].
A4.35. Prove that if m | n and n is odd, then the polynomial xm + 1 divides the
polynomial xn + 1 in Z[x].
A4.36. Prove that if a polynomial h(x) ∈Z[x] divides xn−1 and if m ≡m′ (mod n)
then h(x) also divides xm −xm′ in Z[x].
A4.37. Give another proof of Proposition 4.4.1 by writing numbers in base a.
A4.38. Prove that for all integers n ≥2 one has F0F1 · · · Fn−1 = Fn −2.
A4.39. Prove that if n ̸= m, then GCD(Fn, Fm) = 1.
A4.40. Deduce from Exercise A4.39 a new proof of the fact that there are inﬁnitely
many prime numbers.
A4.41.* Prove Theorem 4.4.13.
A4.42.* A number n is said to be multiplicatively perfect if the product of its
positive divisors equals n2. Prove that a number is multiplicatively perfect if and
only if either it is the product of two distinct prime numbers, or it is the cube of a
prime number.
A4.43. Prove that in an integral domain a prime element is irreducible.
A4.44. Prove that in a factorial ring A the least common multiple of two non-zero
elements a, b always exists.

A4 Theoretical exercises
203
A4.45. Prove that Z[√−3] is closed under addition and multiplication as deﬁned
on C.
A4.46. Prove that Z[√−3] is an integral domain with unity.
A4.47.* Determine the invertible elements in the ring Z[√−6].
A4.48.* Let A be a Noetherian integral domain and let a, b be two non-zero elements
of A; assume a not to be invertible. Prove that the set of positive integers n such
that an | b is bounded.
A4.49.* Let A be a Noetherian commutative ring. Let (4.17) be an ascending chain
of ideals of A. Prove that I = ∪n∈NIn is an ideal of A.
A4.50.* Let A be a commutative ring and let I be an ideal of A. Prove that, if I
is not ﬁnitely generated, then there exists a sequence {xn}n∈N of elements of I such
that, if In = (x1, . . . , xn) then In ⊂In+1 e In ̸= In+1, for all n ∈N.
A4.51. Prove Lemma 4.5.19.
A4.52. Prove that, given a polynomial f(x) ∈C[x], we have lim|x|→+∞|f(x)| =
+∞.
A4.53. Let f(x) = 1 + axk + (terms of degree greater than k) be a polynomial
with complex coeﬃcients. Verify that, after the change of variables x = αy with
αk = −1/a one has f(x) = f(αy) = φ(y) with φ(y) = 1 −yk + yk+1g(y), where g(y)
is a suitable polynomial.
A4.54. Prove Lemma 4.5.35.
A4.55. Consider a ﬁeld K. Denote by K(x1, . . . , xn) the ﬁeld of fractions of
K[x1, . . . , xn], called ﬁeld of rational functions in n variables on K. Let f(x1, . . . , xn)
be a polynomial on K. Prove that, if f = gh with g, h ∈K(x1, . . . , xn−1)[xn], both
of positive degree, then f is reducible in K[x1, . . . , xn].
A4.56. Let K be a ﬁeld. Prove that every linear polynomial in K[x1, . . . , xn] is
irreducible.
A4.57. Consider a polynomial f(x) with coeﬃcients in a ﬁeld K and an element
α ∈K diﬀerent from zero. Prove that f(x) is irreducible (on the ﬁeld K) if and only
if f(x −α) and f(x/α) are irreducible.
A4.58. Let p(x) be a ﬁxed polynomial in K[x]. Prove that the map Tp : K[x] →K[x]
deﬁned by Tp(f(x)) = f(p(x)) for all f(x) ∈K[x] is a ring homomorphism.
A4.59.* Compute the complexity of the algorithm based on Proposition 4.5.37
to ﬁnd the rational roots of a polynomial in Z[x]. Verify that this complexity is
exponential in the length of the coeﬃcients of the polynomial.
A4.60. Prove that all the polynomials in R[x] that are irreducible over R are the
linear ones and the second degree ones with negative discriminant.
A4.61. Let f(x) be a polynomial of degree n in Z[x] with coeﬃcients bounded by
N. Prove that the algorithm described on page 189 to verify if f(x) is irreducible
has complexity O(Nn).
A4.62.* Let f(x) be a polynomial of degree n in Z[x] with coeﬃcients of length
at most N. Let ¯f(x) ∈Zp[x] be its reduction modulo p. Prove that the algorithm

204
4 Finite is not enough: factoring integers
described on page 190 to verify if f(x) is irreducible has complexity O(N). However,
notice that the algorithm is exponential in p and more than exponential in n.
A4.63.* Find a proof of Corollary 4.6.2 that does not use the Chinese remainder
theorem.
A4.64.* If x1, . . . , xm are distinct elements of a ﬁeld K, consider the determinant
V (x1, . . . , xm) of the matrix
⎛
⎜
⎜
⎜
⎜
⎜
⎝
1
1
. . .
1
x1
x2
. . .
xm
x2
1
x2
2
. . .
x2
m
...
...
...
...
xm−1
1
xm−1
2
. . . xm−1
m
⎞
⎟
⎟
⎟
⎟
⎟
⎠
,
called the Vandermonde determinant of x1, . . . , xm. Prove that it is diﬀerent from
zero and that
V (x1, . . . , xm) =
'
i>j
(xi −xj).
A4.65.* Let n be a positive integer and let a1, . . . , ah be elements of a ﬁeld K. Fix
h non-negative integers m1, . . . , mh such that m1 + · · · + mh + h = n + 1 and assign
n + 1 elements fi,j ∈K, with i = 1, . . . , h and j = 0, . . . , mh. Prove that there exists
exactly one polynomial f(x) ∈K[x] of degree at most n such that D(j)(ai) = fi,j
for all i = 1, . . . , h and j = 0, . . . , mh.
A4.66. Consider the security problem regarding the formula owned by the chairman
of the pharmaceutical company, as described on page 191. Suppose that the code
of the safe containing the formula is a very large integer N. The chairman wants to
share the knowledge of N among n people in such a way that k of them, together,
are able to know N, but this is impossible to any k −1 of them.
In order to do so, the chairman chooses n distinct prime numbers p1, . . . , pn,
each of them greater than
k√
N but much smaller than
k−1√
N. Next, he lets the ith
person know pi and N mod pi. Prove how and why k of these people, pooling their
information, learn N, while k −1 of them do not. (Hint: consider the case k = 3
ﬁrst; use the Chinese remainder theorem.)
A4.67. Prove the the Chinese remainder theorem for polynomials 4.6.1 stated on
page 191. (Hint: follow the proof of the Chinese remainder theorem for integer
numbers.)
A4.68. Explain in detail how the four oﬃcers of the pharmaceutical company may
proceed in order to discover the coeﬃcient of the degree two term of the polynomial
interpolating the following data (see page 195):
P ′
0 = (−2, −11), P ′
1 = (−3, −35), P ′
2 = (1, 1), P ′
3 = (0, 1).
B4 Computational exercises
B4.1. Verify that 91 is not prime.

B4 Computational exercises
205
B4.2. Decompose 151 into prime factors. How many distinct prime factors are
found?
(a) Exactly one, namely 151 itself, a prime.
(b) Two distinct primes.
(c) Three distinct primes.
(d) None of the above.
B4.3. Verify that 397 is prime, by computing all remainders of the divisions of 397
by 2, 3, 5, 7, 11, 13, 17 and 19.
B4.4. Decompose 1411 into prime factors. How many distinct prime factors are
found?
(a) Exactly one, namely 1411 itself, a prime.
(b) Two distinct primes.
(c) Three distinct primes.
(d) None of the above.
B4.5. Decompose 1369 into prime factors. How many distinct prime factors are
found?
(a) Exactly one, namely 1369 itself, a prime.
(b) Two distinct primes.
(c) Three distinct primes.
(d) None of the above.
B4.6. Decompose 65535 into prime factors. How many distinct prime factors are
found?
(a) 2.
(b) 3.
(c) 4.
(d) None of the above.
B4.7. Which is the least common multiple of 150 and 345?
(a) 3450.
(b) 51750.
(c) 10350.
(d) None of the above.
B4.8. Compute the greatest common divisor of 34891 and 3977.
(a) 1.
(b) 41.
(c) 53.
(d) None of the above.
B4.9. Compute the greatest common divisor of 4096 and 2854673912301.
(a) 1.
(b) 7.

206
4 Finite is not enough: factoring integers
(c) 19.
(d) None of the above.
B4.10. Compute the greatest common divisor of 1296 and 122678322.
(a) 1.
(b) 6.
(c) 8.
(d) None of the above.
B4.11. Does the pair (59, 61) consist of twin primes?
(a) Yes.
(b) No, because 59 is not prime.
(c) No, because 61 is not prime.
(d) None of the above.
B4.12. Which of the following is a pair of twin primes?
(a) (131, 133).
(b) (107, 109).
(c) (103, 105).
(d) None of the above.
B4.13. Which of the following is a pair of twin primes?
(a) (497, 499).
(b) (509, 511).
(c) (521, 523).
(d) None of the above.
B4.14. Find all the primes between 200 and 250 using the sieve of Eratosthenes.
How many are there?
(a) 7.
(b) 8.
(c) 10.
(d) None of the above.
B4.15. Find all the primes between 300 and 400 using the sieve of Eratosthenes.
How many are there?
(a) 13.
(b) 14.
(c) 15.
(d) None of the above.
B4.16. Compute ϕ(151), ϕ(1411), ϕ(1369).
B4.17. Find ¯a1000 for all ¯a ∈Z7.
B4.18. Compute 450 modulo 7.
B4.19. Compute Gss(8, a) for every odd a (with a ̸= 1).

B4 Computational exercises
207
B4.20. Compute Gss(16, a) for every odd a.
B4.21. Compute 22! modulo 23.
B4.22. Let n be a positive integer greater than 2. Prove that n is prime if and only
if (n −2)! ≡1 (mod n).
B4.23. Consider the fraction 161/621 in base 10. Determine the bases β ≤10 in
which this number is β–deﬁned.
B4.24. Consider the fraction 162/621 in base 10. Determine the bases β ≤10 in
which this number is a simple recurring number.
B4.25. Consider the fraction 163/621 in base 10. Determine the bases β, with
20 ≤β ≤100 and β not divisible by 3, in which this number is a mixed recurring
number.
B4.26. Consider the reduced fraction a = c/d, and let p be a prime number and n
a positive integer. Prove that a is pn-deﬁned if and only if d is a power of p; that it
is simple recurring in base pn if and only if it is not divisible by p; that it is mixed
recurring in base pn if and only if d is divisible by p but is not a power of p.
B4.27. Let p, q be distinct prime numbers. Which are the pq-deﬁned reduced frac-
tions?
B4.28. Prove that the number 235 −1 is divisible by 35 and 127.
B4.29.* Factor 211 −1.
B4.30. Is it possible to construct with ruler and compasses a regular 20-sided poly-
gon?
(a) Yes.
(b) No.
(c) No, as 20 is not a product of distinct Fermat numbers.
(d) None of the above.
B4.31. What is known about perfect numbers?
(a) There are as many of them as Mersenne primes.
(b) There are inﬁnitely many of them.
(c) There are no odd perfect numbers.
(d) None of the above.
B4.32.* Let Z[i] be the ring of Gaussian integers (see Exercise A1.49). Prove that
it is a factorial ring.
B4.33. Are the elements 2 and 2 + 3i prime in Z[i]?
B4.34. Consider the ring Z[√−6]. Which one of the following properties does it
verify?
(a) It is a ﬁeld.
(b) It is an integral domain.
(c) It is a unique factorisation domain.
(d) None of the above.

208
4 Finite is not enough: factoring integers
B4.35. Consider Z[√−6]. List some irreducible element. Verify which of those ele-
ments are prime as well.
B4.36. Consider 10 ∈Z[√−6]. Is it irreducible?
(a) Yes.
(b) No, because it is not prime.
(c) No.
(d) None of the above.
B4.37. Find a primitive polynomial with integer coeﬃcients associate to the poly-
nomial
f(x) = 5
3x3 + 3
5x2 −1
4x?
(a) 60x3 + 36x −15x.
(b) 20x3 + 12x −5x.
(c) 20x3 + 36x −15x.
(d) None of the above.
B4.38. Find a primitive polynomial with integer coeﬃcients associate to the poly-
nomial
f(x) = 15
7 + 3x −21
13x3?
(a) 195 + 293x −147x3.
(b) 195 + 271x −147x3.
(c) 49x3 −91x −65.
(d) None of the above.
B4.39. Is the polynomial x3 −1 reducible?
(a) Yes.
(b) No.
(c) No, because it is irreducible in the ﬁeld Z37.
(d) It is impossible to answer if the ﬁeld in which the coeﬃcients are to be considered
is not speciﬁed.
B4.40. Is the polynomial x3 −3x + 1 irreducible over Q?
(a) Yes, because it is irreducible over Z2.
(b) Yes, because it is irreducible over Z3.
(c) Yes, because it is irreducible over Z19.
(d) No.
B4.41. Is the polynomial x3 + x2 + x + 1 irreducible over Q?
(a) Yes, by Eisenstein’s criterion by substituting x + 1 for x.
(b) Yes, because it has no roots.
(c) No, as it does not verify Eisenstein’s criterion.
(d) No, as it has a root.

B4 Computational exercises
209
B4.42. Is the polynomial x4 + x3 + x2 + x + 1 irreducible over Q?
(a) Yes, by Eisenstein’s criterion by substituting x + 1 for x.
(b) Yes, because it has no roots.
(c) No, as it does not verify Eisenstein’s criterion.
(d) No, as it has a root.
B4.43. Is the polynomial x5 −x + 1 irreducible over Q?
(a) Yes, by Eisenstein’s criterion.
(b) Yes, because it is irreducible over Z3.
(c) No, because it is reducible over Z2.
(d) No, as it has a root.
B4.44. Is the polynomial x4 −x2 −1 irreducible over Q?
(a) Yes, by Eisenstein’s criterion.
(b) Yes, because it is irreducible over Z2.
(c) No, because it is reducible over Z3.
(d) None of the above.
B4.45. Is the polynomial x6 + x5 + x4 + x3 + x2 + x + 1 irreducible over Q?
(a) Yes, by Eisenstein’s criterion by substituting x + 1 for x.
(b) Yes, because it has no roots.
(c) No, as it does not verify Eisenstein’s criterion.
(d) No, as it has a root.
B4.46. How many irreducible factors has the polynomial x5 −x + 1 over Z2?
(a) 1.
(b) 2.
(c) 3.
(d) 5.
B4.47. How many irreducible factors has the polynomial x3 −3x + 1 over Z3?
(a) Three, one of them with multiplicity two and the other with multiplicity one.
(b) Three, all equal to a same factor, which has multiplicity three.
(c) Two.
(d) One.
B4.48. How many irreducible factors has the polynomial x4 −x2 −1 over Z3?
(a) 1.
(b) 2.
(c) 3.
(d) 4.
B4.49. How many distinct irreducible factors has the polynomial x6 + x5 + x4 +
x3 + x2 + x + 1 over Z2?
(a) 1.
(b) 2.
(c) 3.
(d) 6.
B4.50. How many distinct irreducible factors has the polynomial x6 + x5 + x4 +
x3 + x2 + x + 1 over Z7?
(a) 1.
(b) 2.
(c) 3.
(d) 6.

210
4 Finite is not enough: factoring integers
B4.51. Exactly one of the following claims is false. Which one?
(a) A polynomial that is irreducible over R is so over Q too.
(b) A polynomial that is irreducible over Zp is so over Q too.
(c) A third degree polynomial over C is always reducible.
(d) A third degree polynomial over R is always reducible.
B4.52. Which is a polynomial p(x) ∈Q[x] of degree at most three such that p(0) = 0,
p(1) = 3 e p(2) = 8?
(a) Such a polynomial does not exist, as a third degree polynomial is determined
by at least four values.
(b) Such a polynomial exists but is not uniquely determined, so we cannot use
Lagrange interpolation polynomial to compute it.
(c) 5x2 −2x.
(d) x2 + 2x.
B4.53. Which ones are the Lagrange interpolation polynomials Li needed to inter-
polate a degree two polynomial for which the values in a0 = 2, a1 = 3 and a2 = 4
are known?
(a) L0 = (x −3)(x −4)/2, L1 = (x −2)(4 −x), L2 = (x −2)(x −3)/2.
(b) L0 = (x + 3)(x + 4)/2, L1 = (x + 2)(x + 4), L2 = (x + 2)(x + 3)/2.
(c) It is impossible to answer, as a degree two polynomial is not uniquely determined
if only three values are known.
(d) It is impossible to answer unless we know the values the polynomial takes in a0,
a1 and a2.
B4.54. Determine the degree two polynomial over R that vanishes at 0 with deriva-
tive equal to 1 there, and takes the value 3 at 2.
B4.55. Which is the polynomial p(x) ∈Q[x] of degree at most two such that
p(2) = 0, p(3) = 3 and p(4) = 8?
(a) Such a polynomial exists, but it is not unique, as a second degree polynomial is
not uniquely determined if only three of its values are known.
(b) 3(x −2)(4 −x) + 8(x −2)(x −3).
(c) 3(x −2)(x −4) −4(x −2)(x −3).
(d) x2 −2x.
B4.56. Which ones are the Lagrange interpolation polynomials Li needed to inter-
polate a degree four polynomial for which the values in a0 = 0, a1 = −1, a2 = 1 and
a3 = 2 are known?
(a) L0 = (x −1)(x + 1)(x −2)/2, L1 = x(x + 1)(2 −x)/2, L2 = x(x −1)(2 −x)/6
and L3 = x(x −1)(x + 1)/6.
(b) L0 = (x −1)(x + 1)(x −2)/2, L1 = x(x + 1)(x −2)/2, L2 = x(x −1)(x −2)/6
and L3 = x(x −1)(x + 1)/6.
(c) It is impossible to answer, as a fourth degree polynomial is not uniquely deter-
mined if only four values are known.
(d) It is impossible to answer unless we know the values the polynomial takes in a0,
a1, a2 and a3.

C4 Programming exercises
211
B4.57. Which is a polynomial p(x) ∈Q[x] of degree at most four such that p(0) = 1,
p(1) = −1, p(−1) = 4 and p(2) = 3?
(a) Such a polynomial does not exist, as a fourth degree polynomial is not deter-
mined by just four values.
(b) Such a polynomial exists but is not uniquely determined, so we cannot use
Lagrange interpolation polynomial to compute it.
(c) (5/6)x3 + (1/2)x2 −(10/3)x + 1.
(d) (5/6)x3 + (1/2)x2 −(11/3)x + 1.
B4.58. Which is the derivative of the polynomial x5 + 2x4 −5x3 −10x2 + 6x + 12
in Z2[x]?
(a) −x2 −x4.
(b) x −x2 + x4.
(c) x + x2 −x5.
(d) None of the above.
B4.59. Which is the derivative of the polynomial 2x5 −x2 + 3 in Z3[x]?
(a) x4 −x.
(b) x −x4.
(c) x + x4.
(d) None of the above.
C4 Programming exercises
C4.1. Write a program that factors an integer n into primes, by trying to divide it
by all integers smaller than √n.
C4.2. Write a program that computes all primes smaller than a ﬁxed integer n,
using the sieve of Eratosthenes.
C4.3. Write a program that veriﬁes that the polynomial x2 −x + 41 assumes prime
values for x = n, for all n ∈{ 0, . . . , 40 }.
C4.4. Write a program that veriﬁes if a number is prime by applying Fermat’s little
theorem.
C4.5. Write a program that veriﬁes if a number is prime by applying Wilson’s
theorem.
C4.6. Write a program that computes Euler function.
C4.7. Write a program that determines whether a given fraction written in base 10
is a deﬁned, simple recurring or mixed recurring number in a given base β.
C4.8. Write a program that computes all perfect numbers smaller than 1000.
C4.9. Write a program that determines all irreducible polynomials of degree smaller
than 100 over Zp, for all primes p smaller than 20.

212
4 Finite is not enough: factoring integers
C4.10. Write a program that associates to a polynomial f(x) with rational coeﬃ-
cients a primitive polynomial f ∗(x) with integer coeﬃcients such that f(x) = qf ∗(x),
where q ∈Q.
C4.11. Write a program that ﬁnds the rational roots of a polynomial with integer
coeﬃcients using Newton’s method.
C4.12. Write a program that implements the factorisation method for polynomials,
based on reduction modulo p.
C4.13. Write a program that determines the unique complex polynomial of degree
10 that assumes given values at 11 given points of C.
C4.14. Write a program that implements Kronecker’s factorisation method.

5
Finite ﬁelds and polynomial congruences
The subjects covered in this chapter, that is to say, ﬁnite ﬁelds and the law
of quadratic reciprocity, are both a natural development of notions seen in
the previous chapters and important in their own right. However they are
mostly signiﬁcant in connection with some of their applications, for instance to
cryptography and codes, to the problem of factoring integers and to primality
tests, as we shall see in the next chapters.
5.1 Some ﬁeld theory
In this section we shall mostly deal with ﬁnite ﬁelds, that is to say, with ﬁelds
containing ﬁnitely many elements. We have already seen that every ring Zp,
with p a prime, is a ﬁnite ﬁeld. Our goal is to describe all ﬁnite ﬁelds. In order
to do so, we need to recall some notions from ﬁeld theory.
5.1.1 Field extensions
Consider two ﬁelds A, B, with A a subﬁeld of B. Then B is said to be an
extension of A.
For instance, if b1, . . . , bn are elements of B, we denote by A(b1, . . . , bn)
the smallest subﬁeld of B containing A and b1, . . . , bn. Clearly, A(b1, . . . , bn)
is an extension of A, consisting of all elements of B of the form
f(b1, . . . , bn)
g(b1, . . . , bn) ,
(5.1)
where f(x1, . . . , xn), g(x1, . . . , xn) ∈A[x1, . . . , xn] and g(b1, . . . , bn) ̸= 0
(see Exercise A5.3). These elements are called rational expressions in b1, . . . ,
bn with coeﬃcients in A. Rational expressions are said to be integral if
g(x1, . . . , xn) = 1.

214
5 Finite ﬁelds and polynomial congruences
As A is included in B, the latter can be seen as a vector space over A, so
it makes sense to consider the dimension of B as a vector space over A. This
dimension is denoted by [B : A] and is called degree of B over A. Clearly,
[B : A] = 1 if and only if A = B.
However, [B : A] is not necessarily ﬁnite. In any case it is obvious that if
A, B, C are ﬁelds and A ⊆B ⊆C, then, if [C : A] is ﬁnite, [B : A] and [C : B]
are ﬁnite too (see Exercise A5.5). Moreover, in this case an interesting result
holds.
Theorem 5.1.1 (Multiplicativity of degrees).
Let A, B, C ﬁelds such
that A ⊆B ⊆C and suppose that [C : A] is ﬁnite. Then:
[C : A] = [C : B] · [B : A].
Proof. Let n = [B : A] and m = [C : B]; let {a1, . . . , an} be a basis of B as
a vector space over A and {b1, . . . , bm} a basis of C as a vector space over B.
It is suﬃcient to prove that the elements aibj, i = 1, . . . , n, j = 1, . . . , m form
a basis of C as a vector space over A. The proof is not hard and is left as an
exercise for the reader (see Exercise A5.6).
⊓⊔
5.1.2 Algebraic extensions
We begin with two important deﬁnitions.
Deﬁnition 5.1.2. Let A ⊂B be a ﬁeld extension. An element b ∈B is said
to be algebraic over A if there exists a non-zero polynomial f(x) ∈A[x] such
that f(b) = 0. Else, b is said to be transcendental over A.
The elements of C that are algebraic over Q are called algebraic numbers.
The set of algebraic numbers is countable (see Exercise A5.16), so in C and
also in R there are certainly transcendental numbers. However, it is not easy
to verify whether a given number is transcendental or not. For instance, it has
been proved only quite recently that e (Hermite, 1873) and π (Lindemann,
1882) are transcendental (see [26], pages 170–177).
If b ∈B is algebraic over A, we may consider the non-zero ideal Ib of A[x]
consisting of all polynomials f(x) ∈A[x] such that f(b) = 0. It is exactly the
kernel of the homomorphism
vb : f(x) ∈A[x] →f(b) ∈A(b),
called valutation of polynomials in b, which is clearly a ring homomorphism
(see Exercise A5.7).
Notice that, as A[x] is a Euclidean ring, and so its ideals are principal
(see § 1.3.6), Ib is principal, and so is generated by a polynomial fb(x), which
is unique if it is taken to be monic. This polynomial is called the minimal
polynomial of b over A. It is straightforward to verify that fb(x) is irreducible

5.1 Some ﬁeld theory
215
over A or, equivalently, that Ib is a prime ideal (see Exercise A5.8). The degree
n of fb(x) is called degree of b over A. Given b, b′ ∈B algebraic elements over
A, they are said to be conjugate with respect to A if fb(x) = fb′(x), that is
to say, if they have the same minimal polynomial over A.
Consider now the quotient ring A[x]/Ib (see Remark 3.1.6). The existence
of the map vb implies the existence of an injective map
wb : A[x]/Ib →A(b).
Moreover:
Lemma 5.1.3. The map wb is an isomorphism.
Proof. As wb is injective, it is suﬃcient to prove that it is surjective too.
The image of wb includes A and b, so it is enough to show that this image is
a ﬁeld, that is, that A[x]/Ib is a ﬁeld. To obtain this, we show that each non-
zero element ξ of A[x]/Ib has an inverse. Clearly, this is true if (ξ) = A[x]/Ib.
Let then ξ ∈A[x]/Ib be a non-zero element and suppose (ξ) ̸= A[x]/Ib. Let
π : A[x] →A[x]/Ib be the canonical projection map. Then I = π−1((ξ)) is a
proper ideal of A[x] properly including Ib. Let g(x) be a generator of this ideal.
Then g(x) divides fb(x), which is irreducible. Then either g(x) is a constant
or g(x) and fb(x) are associates. In the ﬁrst case I = A[x], in the second one
I = Ib, obtaining in each case a contradiction.
⊓⊔
As a consequence, we get the following corollary.
Corollary 5.1.4. Let A ⊆B be a ﬁeld extension and let b ∈B be algebraic
over A of degree n. Then [A(b) : A] = n and a basis of A(b) over A is given
by {1, b, . . ., bn−1}.
Proof. From Lemma 5.1.3 it follows that a system of generators of A(b) is
given by a sequence {bm}m∈N. On the other hand, as in A(b) we have fb(b) = 0,
it follows that bn depends linearly on {1, b, . . ., bn−1}.
We next prove by induction that bm depends linearly on {1, b, . . ., bn−1}
for every m ≥n. Indeed, this is true for m = n. Assume it is true for a given
integer m > n. Then we have a relation of the form
bm = a0 + a1b + · · · + an−1bn−1.
Multiplying both sides by b, we have
bm+1 = a0b + a1b2 + · · · + an−1bn.
But bn depends linearly on {1, b, . . ., bn−1} too, hence bm+1 depends linearly
on {1, b, . . ., bn−1}.
Finally, it is clear from the deﬁnition of minimal polynomial that {1, b, . . .,
bn−1} are linearly independent over A.
⊓⊔

216
5 Finite ﬁelds and polynomial congruences
The above remarks suggest how to proceed the other way around. Suppose
we have a ﬁeld A and an irreducible monic polynomial f(x) ∈A[x]. We ask
if it is possible to ﬁnd a ﬁeld B such that:
•
A is a subﬁeld of B;
•
there exists an element c ∈B, algebraic over A, such that fc(x) = f(x)
and B = A(c).
Such a ﬁeld B is said to be obtained by adjoining the root c of f(x) to A.
The answer to the question is clearly yes: it suﬃces to take B = A[x]/(f(x)),
and as c the image of x in B. We leave to the reader the details (see Exercise
A5.11).
Consider now the following situation. We have two ﬁelds A1, A2 and an
isomorphism f : A1 →A2. The map f induces in a natural way an isomor-
phism φf : A1[x] →A2[x], acting on the constants as f and mapping x in x.
In this situation the following holds:
Theorem 5.1.5. Let A1, A2 be two ﬁelds and f : A1 →A2 an isomorphism.
Let fi(x) ∈Ai[x], i = 1, 2, be two irreducible polynomials such that f2(x) =
φf(f1(x)). Let Ai(bi) be obtained by adjoining to Ai a root bi of fi(x), i = 1, 2.
Then there exists a unique isomorphism ϕf : A1(b1) →A2(b2) that restricted
to A1 coincides with f and such that ϕf(b1) = b2.
The easy proof is left as an exercise for the reader (see Exercise A5.12).
Example 5.1.6. The ﬁeld obtained from R by adjoining a root of x2 + 1 is
the complex ﬁeld C. If we denote by i and −i the roots of x2 + 1, we may
consider the extensions R(i) and R(−i). The isomorphism existing between
these two ﬁelds according to Theorem 5.1.5 is the conjugation in C.
Deﬁnition 5.1.7. A ﬁeld extension A ⊆B is said to be algebraic if every
element of B is algebraic over A; otherwise it is said to be transcendental.
For instance R ⊂C is an algebraic extension, while Q ⊂R is transcenden-
tal.
Lemma 5.1.8. Let A ⊆B be an extension. Given c ∈B, c is algebraic over
A if and only if [A(c) : A] is ﬁnite, and in this case [A(c) : A] is the degree of
c over A. Finally, if c ∈B is algebraic over A, then A(c) is algebraic over A.
Proof. If [A(c) : A] is ﬁnite, c is algebraic, or else the sequence {cn}n∈N
would consist of elements that are independent on A. The second claim follows
from Corollary 5.1.4.
Finally, if c is algebraic over A and if d ∈A(c), multiplicativity of degrees
implies that [A(d) : A] < [A(c) : A] and so d is algebraic over A.
⊓⊔
As a consequence we have:

5.1 Some ﬁeld theory
217
Proposition 5.1.9. Let A ⊆B be an extension of ﬁnite degree. Then every
element c ∈B is algebraic over A and its degree over A divides [B : A].
Proof. Considering the extensions A ⊆A(c) ⊆B, we ﬁnd that [A(c) : A] is
ﬁnite. The claim follows from the previous Lemma and the multiplicativity of
degrees Theorem.
⊓⊔
5.1.3 Splitting ﬁeld of a polynomial
Here is another deﬁnition.
Deﬁnition 5.1.10. Let A be a ﬁeld and f(x) a polynomial of degree n over
A. An extension A ⊆B is said to be a splitting ﬁeld of f(x) over A if there
exist elements b1, . . . , bn ∈B and a ∈A such that
•
f(x) = a(x −b1) · · · (x −bn);
•
B = A(b1, . . . , bn).
Clearly, [B : A] is ﬁnite. Moreover, if n ≤1 of course A = B.
Splitting ﬁelds always exist:
Theorem 5.1.11. Let A be a ﬁeld and f(x) a polynomial of degree n over A.
Then there exists a splitting ﬁeld B of f(x) over A.
Proof. The claim is true if n ≤1, because in this case it suﬃces to take
B = A. Proceed by induction on n. Let A′ = A(c) be the ﬁeld obtained
adjoining to A a root c of f(x). Then in A′[x] the polynomial f(x) is divisible
by x−c, that is, we have f(x) = (x−c)g(x) with g(x) ∈A′[x], of degree n−1.
By induction a splitting ﬁeld B of g(x) over A′ exists, and clearly it also is a
splitting ﬁeld of f(x) over A.
⊓⊔
Example 5.1.12. Let K be a ﬁeld and a an element of K that is not a square,
that is to say, there is no b ∈K such that b2 = a. If we denote by √a a root
of the polynomial x2 −a, the splitting ﬁeld of x2 −a over K is K(√a).
For instance, the splitting ﬁeld of x2−5 over Q is the ﬁeld Q(
√
5), consisting
of all real numbers a + b
√
5, with a, b ∈Q.
The splitting ﬁeld of a polynomial is essentially unique. This is the gist of
the following theorem.
Theorem 5.1.13. Let A1, A2 be two ﬁelds and f : A1 →A2 an isomor-
phism. Let fi(x) ∈Ai[x], i = 1, 2, be irreducible polynomials such that
f2(x) = φf(f1(x)). Let Bi be a splitting ﬁeld of fi(x) over Ai, i = 1, 2. Then
there exists an isomorphism ϕf : B1 →B2 that, restricted to A1, coincides
with f.

218
5 Finite ﬁelds and polynomial congruences
Proof. Let n = [B1 : A1]. If n = 1, then A1 = B1 and f1(x) is a product of
linear factors in A1[x]. As f is an isomorphism, so is f2(x), implying B2 = A2.
Thus, is is suﬃcient to take ϕf = f.
If n > 1 we proceed by induction. In this case there exists in B1 a root
b1 of f1(x) that is not in A1. Let g1(x) be its minimal polynomial, which is
an irreducible polynomial dividing f1(x). Set g2(x) = φf(g1(x)). This is an
irreducible polynomial dividing f2(x). So in B2 there is a root b2 of g2(x)
not belonging to A2. By Theorem 5.1.5 we may extend f to an isomorphism
between A1(b1) and A2(b2). Notice now that Bi is also a splitting ﬁeld of fi(x)
over Ai(bi), i = 1, 2. By induction we may easily conclude. The details are left
to the reader (see Exercise A5.17).
⊓⊔
Remark 5.1.14. Notice that the isomorphism ϕf described in the statement
of Theorem 5.1.13 maps the roots of f1(x) to those of f2(x).
In particular, we have:
Corollary 5.1.15. Let A be a ﬁeld and let f(x) be a polynomial of degree n
over A. The splitting ﬁeld of f(x) over A is unique up to isomorphisms.
5.1.4 Roots of unity
Let K be a ﬁeld. If K has characteristic zero (see Remark 1.3.26), then the
fundamental subring of K is Z, and so K includes Q.
If the characteristic K is not zero, then its characteristic is a prime number
p. This means that its fundamental subring is Zp, which is, as we know, itself
a ﬁeld. So every ﬁeld of characteristic p is an extension of Zp. We shall say
that K is a prime ﬁeld, or fundamental, if K = Q or K = Zp with p a prime
number.
Consider now the polynomial fn(x) = xn −1 over a prime ﬁeld K and
let Fn be a splitting ﬁeld of fn(x). The roots of fn(x) are called nth roots of
unity. It is straightforward to verify (see Exercise A5.20) that the set Rn of
nth roots of unity is a subgroup of the multiplicative group of Fn. Notice that
if m | n then Rm ⊆Rn (see Exercise A5.23). We want to study the structure
of the group Rn. The following holds:
Proposition 5.1.16. If K has characteristic 0 or a number p coprime with
n, then Rn is a cyclic group of order n.
Proof. We have D(fn(x)) = nxn−1. In our hypotheses, n ̸= 0 in K, so
D(fn(x)) has the unique root 0, with multiplicity n−1. By the factor theorem,
the polynomial fn(x) has exactly n distinct roots, that is to say, Rn has order
n.
We now prove that Rn is cyclic. First of all, consider the case in which
n = qm is a power of a prime number q. If in Rn there were no element of
order n, then for all ξ ∈Rn an integer mξ < m would exist such that ξ has

5.1 Some ﬁeld theory
219
order qmξ. Let m′ = max{mξ | ξ ∈Rn}. Clearly m′ < m, so all elements of
Rn would have order n′ = qm′ < n. Consequently we would have Rn ⊂Rn′,
which yields a contradiction, as Rn has order n while Rn′ has order n′ < n.
Suppose now that the factorisation of n is n = qm1
1
· · · qmh
h . Call ni = qmi
i
,
i = 1, . . . , h. We have Rni ⊂Rn and Rni is cyclic of order ni; let ξi be a
generator of Rni for all i = 1, . . . , h. If ξ = ξ1 · · · ξh, one can easily verify that
the order of ξ is exactly n (see Exercise A5.24).
⊓⊔
The main general properties of cyclic groups are recalled in Exercises
A3.23-A3.35.
In the hypotheses of Proposition 5.1.16, a generator of the group Rn is
said to be a primitive nth root of unity.
Example 5.1.17. If K = C, the nth roots of unity are the numbers
ξn,j = cos 2jπ
n
+ i sin 2jπ
n ,
j = 0, . . . , n −1
and ξn,j is a primitive root if and only if GCD(j, n) = 1.
Proposition 5.1.18. If K has characteristic p and p divides n, setting n =
mph, with p coprime with m, we have Rn = Rm, that is, every nth root is
mth as well, and has multiplicity ph as a root of fn(x).
Proof. In this case the freshman’s dream (see Exercise A4.10) tells us that
fn(x) = (xm −1)ph. Hence the claim immediately follows.
⊓⊔
5.1.5 Algebraic closure
Recall that a ﬁeld A is said to be algebraically closed if every polynomial of
positive degree over A has some root in A.
We leave as an exercise to the reader (see Exercise A5.25) the following
proposition.
Proposition 5.1.19. Let A be a ﬁeld. The following are equivalent:
•
A is algebraically closed;
•
the irreducible polynomials over A are exactly those of degree one;
•
for each polynomial f(x) ∈A[x] of degree n we have
f(x) = a(x −a1)n1(x −a2)n2 · · · (x −ah)nh,
where a is the leading coeﬃcient of f(x), a1, . . . , ah are its distinct roots,
and n1, . . . , nh their multiplicities, so n1 + · · · + nh = n.

220
5 Finite ﬁelds and polynomial congruences
Example 5.1.20. As the Fundamental theorem of algebra 4.5.21 showed us,
C is algebraically closed, but neither Q nor R are.
If p is a prime, Zp is not algebraically closed. Indeed, consider the poly-
nomial f(x) = xn −1, with n not divisible by p. Then D(f(x)) = nxn−1 is
diﬀerent from zero and has as its only root 0, which is not a root of f(x).
So f(x) has no multiple roots, and so it has n distinct roots. If n > p, it is
clear that Zp cannot contain all the roots of f(x) (see Exercise A5.26 for the
obvious extension to general ﬁnite ﬁelds).
Deﬁnition 5.1.21. An extension A ⊆B is said to be an algebraic closure of
A if it is an algebraic extension and if B is algebraically closed. We also say
that B is an algebraic closure of A.
Example 5.1.22. The ﬁeld C is an algebraic closure of R but is not an alge-
braic closure of Q, as it includes elements that are transcendental on Q (see
Exercise A5.27).
The following two theorems are very important. Their proofs are omitted
as they will not be used in what follows.
Theorem 5.1.23. Every ﬁeld has an algebraic closure.
Theorem 5.1.24. Let A1, A2 be two ﬁelds and f : A1 →A2 an isomorphism.
Let Ai ⊆Bi be an algebraic closure of Ai, i = 1, 2. Then there exists an
isomorphism ϕf : B1 →B2, whose restriction to A1 coincides with f. In
particular, all algebraic closures of a given ﬁeld are isomorphic.
5.1.6 Finite ﬁelds and their subﬁelds
We are now going to study ﬁnite ﬁelds. Let F be such a ﬁeld. By Remark
1.3.26, F has characteristic p, where p is a prime number. This means that its
fundamental subring is Zp, which, as we know, is also a ﬁeld.
Remark 5.1.25. Notice that if a ﬁeld is ﬁnite its characteristic is positive,
but the converse is not true, that is, it is not true that if a ﬁeld’s characteristic
is positive, then the ﬁeld is necessarily ﬁnite. It suﬃces to consider the example
of the ﬁeld Zp(x) of rational functions on Zp (see § 4.5.5). This ﬁeld is obviously
inﬁnite and, as it contains Zp, it has characteristic p (see Exercise A5.2).
So every ﬁnite ﬁeld is an extension of Zp for some prime p. As F is ﬁnite,
clearly [F : Zp] is ﬁnite too.
Proposition 5.1.26. Let F be a ﬁnite ﬁeld of characteristic p and let f =
[F : Zp]. Then the order of F is pf.
Proof. By deﬁnition, f = [F : Zp] is the dimension of F as a vector space
over Zp. So F is isomorphic, as a vector space, to Zf
p. Hence the thesis follows.
⊓⊔

5.1 Some ﬁeld theory
221
Proposition 5.1.27. Let F be a ﬁnite ﬁeld of characteristic p and let f =
[F : Zp]. Then F consists exactly of the roots of the polynomial xpf −x over
Zp: so it is a splitting ﬁeld of this polynomial over Zp.
Proof. Consider the polynomial gn(x) = xn −x over Zp. If n = pf, then
D(gn(x)) = −1, so gn(x) has n = pf distinct roots a1, . . . , an. It is easy to
verify that every element of F is a root of gn(x) and F = {a1, . . . , an} (see
Exercise A5.29). This proves the claim.
⊓⊔
Corollary 5.1.28. Finite ﬁelds of the same order are isomorphic.
Proof. This immediately follows from the previous Proposition and from
Theorem 5.1.13.
⊓⊔
The following theorem completes and, in a sense, inverts Proposition
5.1.26:
Theorem 5.1.29. Let p be a prime number. For every positive integer f there
exists a ﬁeld F of order pf.
Proof. Keeping in mind Proposition 5.1.27 and its proof, it suﬃces to remark
that a splitting ﬁeld of the polynomial xpf −x over Zp has order pf.
⊓⊔
A remarkable piece of information regarding ﬁnite ﬁelds is given by the
following theorem.
Theorem 5.1.30. The multiplicative group F∗of a ﬁnite ﬁeld F is cyclic.
Proof. Consider a ﬁnite ﬁeld F of order pf; it is a splitting ﬁeld of the
polynomial xpf −x over Zp. The multiplicative group F∗consists of the non-
zero roots of xpf −x, so of the roots of xpf −1 −1; thus, F∗= Rpf −1. The
claim follows from Proposition 5.1.16.
⊓⊔
Corollary 5.1.31. Let F be a ﬁnite ﬁeld of order pf. For all divisors m of
pf −1, F∗contains Rm and so contains a primitive mth root of unity.
Proof. From the proof of Theorem 5.1.30 follows the fact that F∗= Rpf −1.
The proof is concluded keeping in mind the result of Exercise A5.23.
⊓⊔
A generator of the cyclic group F∗is also called a generator of the ﬁeld F.
Notice now an immediate consequence of the theorem about the multi-
plicativity of degrees:
Proposition 5.1.32. Let F ⊂F′ be an extension of ﬁnite ﬁelds of character-
istic p, and let f = [F : Zp], f ′ = [F′ : Zp]. Then f divides f ′, and precisely:
f ′ = f · [F′ : F].
This result too may be completed and, in a sense, inverted:

222
5 Finite ﬁelds and polynomial congruences
Theorem 5.1.33. Let F be a ﬁnite ﬁeld of order pf with p a prime number.
For all f ′ > 0 divisors of f there exists a unique subﬁeld F′ of F of order pf ′.
Proof. As we have seen, F is the splitting ﬁeld of the polynomial xpf −x over
Zp. Notice now that xpf′
−x = x(xpf′ −1 −1) divides xpf −x = x(xpf −1 −1)
(see Exercise A4.34); so, every root of xpf′
−x is also a root of xpf −x. Thus
F also contains a splitting ﬁeld F′ of xpf′
−x over Zp, having order pf ′. This
ﬁeld is unique because it consists of 0 and Rpf′−1.
⊓⊔
Remark 5.1.34. As ﬁnite ﬁelds of the same order n are isomorphic, it is
customary to denote each such ﬁeld by a unique symbol. Usually they are
denoted by the symbol Fn. Clearly, n has to be of the form n = pf with p a
prime number.
5.1.7 Automorphisms of ﬁnite ﬁelds
Let A be a ﬁeld of characteristic p > 0. Consider the map
φA : x ∈A →xp ∈A,
called Frobenius map. The freshman’s dream (see Exercise A4.10) implies that φA
is an homomorphism. As φA is clearly injective, if A is ﬁnite then φA is an auto-
morphism.
Theorem 5.1.35. Let F be a ﬁnite ﬁeld of order pf. Its automorphism group Aut(F)
is cyclic of order f, generated by φF.
Proof. As a ﬁrst thing, notice that each automorphism of F ﬁxes each element of
Zp, as it ﬁxes 1.
Further, F = Zp(a) with a a generator of F. As [F : Zp] = f, the minimal
polynomial fa(x) of a has degree f. Now, an automorphism φ of F is uniquely
determined by its value φ(a). Clearly, φ(a) is, just like a, a root of fa(x), that is to
say, φ(a) is a conjugate of a. Let Ca be the set of conjugates of a in F, a set having
size at most f, the degree of fa(x). So there is an injective map Aut(F) →Ca,
implying that the order of Aut(F) is at most f. On the other hand it is clear that
φF has exactly order f, proving the claim.
⊓⊔
The following result is proved in an analogous way.
Corollary 5.1.36. Let F be a ﬁnite ﬁeld of order pf. For all a ∈F the conjugates
of a are exactly the elements of the form a, ap, ap2, . . . , apf−1.
5.1.8 Irreducible polynomials over Zp
Let F be a ﬁnite ﬁeld of order pf with p a prime number. As we have seen in
Section 5.1.6, F is a splitting ﬁeld of the polynomial xpf −x over Zp. However, this
polynomial is not irreducible over Zp; for instance it is divisible by x and by x −1.
More precisely, we have:

5.1 Some ﬁeld theory
223
Proposition 5.1.37. For every prime number p and every positive integer f, the
polynomial xpf −x is divisible by all polynomials of degree d | f that are irreducible
over Zp, but not by their squares.
Proof. Recall that all the roots of xpf −x are simple; so for every prime factor of
xpf −x, its square does not divide xpf −x.
If g(x) is an irreducible factor of degree d of xpf −x over Zp, a splitting ﬁeld of
g(x) is included in F and has degree d over Zp and consequently has order pd. Thus,
d | f.
Vice versa, let g(x) be an irreducible polynomial over Zp of degree d | f. Then,
by adjoining to Zp a root b of g(x) we obtain a ﬁeld of order pd which, by Theorem
5.1.33 and Theorem 5.1.5, may be assumed to be a subﬁeld of F. So every root of
g(x) is also a root of xpf −x; hence, g(x) divides xpf −x.
⊓⊔
This enables us to count the irreducible monic polynomials of degree d over Zp.
Let their number be nd,p.
Corollary 5.1.38. For every prime number p and every positive integer f the fol-
lowing holds:
pf =

d|f
dnd,p.
In particular, if f is prime, we have
nf,p = pf −p
f
.
Proof. It suﬃces to remark that, for all d | f, the polynomial xpf −x has nd,p
simple monic factors of degree d, and these are all the monic factors of xpf −x.
⊓⊔
Remark 5.1.39. If f = 2 we have n2,p = p(p −1)/2. It is immediate to compute
n2,p. The monic polynomials of degree two over Zp are of the form x2 + ax + b,
with a, b ∈Zp, so they are p2. The reducible ones are all polynomials of the form
(x −α)(x −β), with α, β ∈Zp. The number of these may be computed like this:
there are p of them with α = β, all distinct, and p(p −1)/2 distinct with α ̸= β.
Hence the formula for n2,p immediately follows.
Notice that Theorem 5.1.37 and Corollary 5.1.38 may be easily extended to
compute the number nd,pf of irreducible monic polynomials of degree d over Fpf
(see Exercises A5.31 and A5.32).
Example 5.1.40. We know that n2,2 = 1. The monic polynomials of degree two
that are reducible over Z2 are x2, (x −1)2 = x2 + 1, x(x −1) = x2 −x = x2 + x and
so the only irreducible monic polynomial of degree two is x2 + x + 1.
Analogously, we know that n2,3 = 3. The monic polynomials of degree two
that are reducible over Z3 are x2, (x −1)2 = x2 + x + 1, (x + 1)2 = x2 −x + 1,
x(x −1) = x2 −x, x(x + 1) = x2 + x, (x + 1)(x −1) = x2 −1; so, the irreducible
monic polynomials of degree two are x2 + 1, x2 −x −1, x2 + x −1.

224
5 Finite ﬁelds and polynomial congruences
5.1.9 The ﬁeld F4 of order four
In this section and in the next ones we shall give explicit examples of ﬁnite
ﬁelds. We begin by describing the ﬁeld F4. It is an extension of degree two of
Z2. Its elements are the roots of the polynomial
x4 −x.
Notice that
x4 −x = x(x −1)(x2 + x + 1).
So the roots are 0, 1, and the two roots of the polynomial x2 +x+1. Denoting
by α a root of x2 + x + 1, we ﬁnd that, in agreement with Corollary 5.1.36,
the other root is α2 = α + 1, as in a ﬁeld of characteristic 2 we have 1 = −1:
indeed, (α + 1)2 + (α + 1) + 1 = α2 + 1 + α + 1 + 1 = 0. Thus,
F4 = {0, 1, α, β},
where β = α + 1 = α2. The addition and multiplication tables of the ﬁeld are
as follows:
+
0
1
α
β
0
0
1
α
β
1
1
0
β
α
α
α β
0
1
β
β α
1
0
·
0
1 α β
0
0
0
0
0
1
0
1 α β
α
0 α β
1
β
0 β
1 α
We may determine the ﬁeld of order 4 in another way as well, without
resorting to ﬁnding the roots of the polynomial x4 −x. It is suﬃcient to ﬁnd
an irreducible polynomial f(x) of degree 2 over Z2 and to adjoin to Z2 a
root of f(x). By Corollary 5.1.38, there is a unique irreducible polynomial of
degree 2 over Z2, and precisely x2 + x + 1 (see Example 5.1.40). Thus, F4
is isomorphic to Z2[x]/(x2 + x + 1). In other words, F4 is simply Z2[x] with
the condition that x2 + x + 1 = 0, or x2 = x + 1. So we are identifying two
polynomials f(x) and g(x) when their diﬀerence is a multiple of x2 + x + 1:
f(x) ≡g(x)
(mod x2 + x + 1).
(5.2)
As already remarked for x = α, we have
x2 ≡x + 1
(mod x2 + x + 1).
(5.3)
Moreover:
x3 ≡1
(mod x2 + x + 1)
because x3 −1 = (x −1)(x2 + x + 1). Further,
x4 = x · x3 ≡x · 1 = x
(mod x2 + x + 1)

5.1 Some ﬁeld theory
225
and
x5 + x4 + 1 ≡0
(mod x2 + x + 1)
as x5 + x4 + 1 = (x3 + x + 1)(x2 + x + 1).
So, every time we ﬁnd x2 in a polynomial, we may simply substitute x + 1
for it; when we ﬁnd x3 we may substitute 1 for it; when we ﬁnd x4 we may
substitute x for it and so on. For instance, the polynomial
x4 + x + 1
is identiﬁed with the polynomial 1. The reasoning is analogous when working
modulo any other polynomial.
Relation (5.2) is an equivalence relation and, keeping in mind formula (5.3),
it may be seen that in every equivalence class there is a linear polynomial (see
Exercise A5.36). The quotient ring is denoted by
Z2[x]/(x2 + x + 1)
and it is a ﬁeld whose elements are the four classes
0, 1, x, 1 + x.
5.1.10 The ﬁeld F8 of order eight
It is an extension of degree 3 of Z2. Its elements are all the roots of the
polynomial x8 −x.
The factorisation of x8 −x into irreducible factors over Z is
x8 −x = x(x −1)(x6 + x5 + x4 + x3 + x2 + x + 1)
(5.4)
(see Exercise B5.15). But the last factor splits into two irreducible factors over
Z2, that is, the factorisation of x8 −x over Z2 is (see Exercise B5.16):
x8 −x = x(x −1)(x3 + x + 1)(x3 + x2 + 1).
(5.5)
Rather than ﬁnding all the roots of this polynomial, it is more convenient
to choose one of the two irreducible polynomials of degree three over Z2 in the
factorisation of x8−x, for instance x3 +x+1, and notice that F8 is isomorphic
to Z2[x]/(x3 + x + 1).
Analogously to what happened in the previous case, every class modulo
x3 + x + 1 is represented by a polynomial of degree at most two, as we may
identify x3 with x + 1, x4 with x2 + x, x5 with x2 + x + 1, x6 with x2 + 1, x7
with 1 and so on. So, if we denote by α a root of x3 + x + 1, α satisﬁes
α3 = α + 1,
and the ﬁeld F8 will consist of the following elements:

226
5 Finite ﬁelds and polynomial congruences
F8 = {a0 + a1α + a2α2 | ai ∈Z2} =
= {0, 1, α, α2, 1 + α, 1 + α2, α + α2, 1 + α + α2}.
We leave to the reader the task of writing down the addition and multiplication
tables of these elements (see Exercise B5.5). Moreover, notice that F4 is not
a subﬁeld of F8: indeed this would contradict the multiplicativity of degrees,
as [F8 : F2] = 3 and [F4 : F2] = 2, and 2 does not divide 3. The reader may
directly verify from the addition and multiplication tables he has written that
the only subﬁeld of F8 is F2 and that the same holds for F4.
5.1.11 The ﬁeld F16 of order sixteen
It is an extension of degree 4 of Z2. Its elements are the roots of the polynomial
x16 −x.
The factorisation of x16 −x into irreducible factors in Z[x] is as follows (see
Exercise B5.17):
x16 −x = x(x −1)(x2 + x + 1)(x4 + x3 + x2 + x + 1) ·
· (x8 −x7 + x5 −x4 + x3 −x + 1),
(5.6)
but over Z2 we have the following factorisation into irreducible polynomials
(see Exercise B5.18):
x16 −x = x(x −1)(x2 + x + 1)(x4 + x + 1) ·
· (x4 + x3 + 1)(x4 + x3 + x2 + x + 1).
(5.7)
So x4 +x3 +1 is irreducible of degree 4 over Z2 and F16 is just Z2[x]/(x4 +
x3 +1). Proceeding as above, we may see that each class in Z2[x]/(x4 +x3 +1)
has a representative of degree at most three. We leave to the reader the task
of writing down the elements of F16, as well as its addition and multiplication
tables (see Exercise B5.6).
The reader will easily verify that F8 is not a subﬁeld of F16, while F4 is
(see Exercise B5.14).
5.1.12 The ﬁeld F9 of order nine
Start with Z3 and consider the polynomial
x9 −x = x(x4 −1)(x4 + 1) =
= x(x −1)(x + 1)(x2 + 1)(x4 + 1) =
= x(x −1)(x + 1)(x2 + 1)(x2 + x −1)(x2 −x −1)
(5.8)

5.1 Some ﬁeld theory
227
(see Proposition 5.1.37 and Example 5.1.40). To obtain F9 it suﬃces to con-
sider, analogously to what precedes, Z3[x]/(x2 + 1). Once more, each equiva-
lence class modulo x2 +1 contains a polynomial of degree at most 1. Denoting
by i, as in C, a root of x2 + 1, we get
F9 = {a0 + a1i| ai ∈Z3} =
= {0, 1, i, −1, −i, 1 + i, 1 −i, −1 + i, −1 −i}.
The reader will ﬁnd no diﬃculty in writing down the addition and multipli-
cation tables of the elements of F9 written in this way (see Exercise B5.7).
Alternatively, we may consider F9 as Z3[x]/(x2 −x−1). In this case too, each
equivalence class in Z3[x]/(x2 −x −1) contains a polynomial of degree at
most 1. So, if we denote by α a root of the polynomial x2 −x −1, which is
irreducible over Z3, we have an element such that α2 = α + 1, and it is easily
seen that F9 consists of the following 9 elements:
0, 1, 2, α, 2α, 1 + α, 1 + 2α, 2 + α, 2 + 2α.
So we have α = −1 ± i. It is interesting to observe that all non-zero elements
of F9 are powers of α (see Exercise A5.37), that is, α is a generator of F9,
while the same is not true of i, as the distinct powers of i are just 4: i0 = 1,
i1 = i, i2 = −1, i3 = −i, while i4 = 1.
5.1.13 About the generators of a ﬁnite ﬁeld
It is very useful to know a generator of a ﬁnite ﬁeld, as in this case every
element of the ﬁeld may be written in a simple way as a power of this gener-
ator. On the other hand, what has been said about F9 shows that the ﬁnite
ﬁeld constructions that might seem the most obvious ones do not yield in a
natural way a generator of the multiplicative group of the ﬁeld. In general, to
determine such a generator is a quite delicate computational problem, even
when the ﬁeld is Zp with p prime. Here we shall restrict ourselves to a couple
of remarks. The ﬁrst one is given by the following proposition.
Proposition 5.1.41. Let F be a ﬁnite ﬁeld of order q. If a is a generator, and
if i is a positive integer, then ai is a generator if and only if GCD(i, q−1) = 1.
In particular, the number of generators of Fq is ϕ(q −1).
This is a consequence of a well-known result about cyclic groups (see Ex-
ercise A3.30).
Keeping in mind the previous proposition we get:
Corollary 5.1.42. Let p be a prime number and a < p any positive number.
The probability for the class of a in Zp to be a generator of Zp is
πp = ϕ(p −1)
p −1
'
q prime, q|p−1

1 −1
q

.

228
5 Finite ﬁelds and polynomial congruences
So the behaviour of the probability πp depends on the factorisation of p−1.
However, not too much can be hoped from a random choice. Indeed, it may
be proved that:
Proposition 5.1.43. There exists a sequence {pn}n∈N of prime numbers such
that the sequence of probabilities {πpn}n∈N converges to zero.
Proof. By Dirichlet’s Theorem 4.1.6, for every positive integer n there exists
a prime pn such that pn ≡1 (mod n!). Then the primes dividing pn−1 include
all the primes dividing n, and so
πpn ≤
'
q prime, q|n

1 −1
q

.
To conclude it suﬃces to remark that, for n →∞, the right-hand side con-
verges to 0 (see Lemma 4.1.5).
⊓⊔
5.1.14 Complexity of operations in a ﬁnite ﬁeld
In Chapter 3 we have discussed the computational cost of operations in Zn
and consequently of operations in the ﬁelds Zp, with p a prime.
Recall that (see Remark 3.1.5 and Section 3.3):
•
computing the sum or the diﬀerence of two elements in Zp has complexity
O(log p);
•
computing the product of two elements in Zp has complexity O(log2 p);
•
computing the inverse of an element in Zp has complexity O(log3 p).
Here we intend to extend these results to operations in ﬁnite ﬁelds.
Let F be a ﬁnite ﬁeld of order q = pf with p a prime. First of all, we
have to keep in mind how we are representing the elements of F. Recall that
F = Zp[x]/(f(x)), with f(x) an irreducible polynomial of degree f over Zp.
So we may represent the elements of F as polynomials in Zp[x] of degree at
most f −1.
Keeping this in mind, we prove the following proposition, which extends
the results of Chapter 3 about Zp:
Proposition 5.1.44. Let F be a ﬁnite ﬁeld of order q = pf with p a prime.
Then:
(a) the addition of two elements of F has complexity O(log2 q);
(b) the multiplication of two elements of F has complexity O(log3 q);
(c) computing the inverse of a non-zero element of F has complexity O(log3 q);
(d) if h is a positive integer and ξ is an element of F, computing ξh has
complexity O(log h log3 q).

5.2 Non-linear polynomial congruences
229
Proof. We shall only prove the claim about multiplication, as that about
addition is proved in an analogous way.
We may consider two elements of F as polynomials of degree at most f −1
over Zp. Keeping in mind Proposition 2.5.10, we know that computing the
product of these polynomials has complexity O(f 2 log2 p). We next have to
divide the result by f(x) and to take the remainder of the division. Again
by Proposition 2.5.10, the latter operation has complexity O(f 2 log3 p). In
conclusion, the complexity is O(f 3 log3 p) = O(log3 q).
In order to prove the claim about the computation of the inverse of an
element, we may argue as follows. Suppose we are given a non-zero element
ξ of F, represented by a polynomial g(x) of degree at most f −1 over Zp.
As f(x) is irreducible over Zp, we have GCD(f(x), g(x)) = 1, so there exists
a B´ezout relation A(x)f(x) + B(x)g(x) = 1, which may be found using the
Euclidean algorithm applied to g(x) and f(x). The class of B(x) in F is the
inverse of ξ. Again by Proposition 2.5.10, the computational cost is once more
O(f 3 log3 p), so we may conclude as above.
As regards computing powers, the reasoning is analogous to that of § 3.3.1.
So O(log h) successive multiplications of elements of F are needed, taking
O(log h log3 q) bit operations.
⊓⊔
5.2 Non-linear polynomial congruences
Consider a congruence of the form
f(x) ≡0
(mod m),
(5.9)
where f(x) = n
i=0 aixi is a polynomial in x with integer coeﬃcients: we are
looking for solutions of the congruence modulo an arbitrary positive integer
m. Such a congruence is said to be polynomial. Clearly, we may assume f(x)
to be reduced modulo m, that is, the coeﬃcients may be reduced modulo m;
hence f(x) may be supposed to be a polynomial in Zm[x]. So it has a degree
which is said to be the degree of the polynomial congruence (5.9). In other
words, the degree of the polynomial congruence (5.9) is the greatest exponent
of x in f(x) such that its coeﬃcient is not divisible by m.
The following is an example of polynomial congruence:
x2 + 2x −3 ≡0
(mod 121);
its degree is 2.
In Chapter 3 we have studied linear congruences, that is to say, polynomial
congruences of degree 1. Now we shall examine non-linear polynomial congru-
ences. Their solution is one of the greatest problems in number theory and
involves many still unsolved questions. We shall mainly dwell on congruences
of degree 2.

230
5 Finite ﬁelds and polynomial congruences
We start with the case in which the modulus is a prime number p. As an
immediate consequence of the factor theorem, a polynomial with coeﬃcients
in a ﬁeld cannot have more roots than its degree (see Exercise A1.55). So the
congruence
f(x) ≡0
(mod p),
where p is prime, cannot have more than n solutions, if n is the degree of
f(x) ∈Zp[x].
This is not true modulo a non-prime number. For instance, the congruence
x2 −1 ≡0
(mod 8)
admits 4 solutions: x = 1, 3, 5 and 7.
Let us see some examples.
Example 5.2.1. Solve the congruence x3 + 2x2 −1 ≡0 (mod 5).
In order to ﬁnd all the solutions, it suﬃces to substitute in f(x) = x3 +
2x2 −1 the values x = 0, 1, 2, 3, 4 and check whether the integer so obtained
is congruent to 0 modulo 5 or not. So we have
x
0
1
2
3
4
f(x)
−1
2
15
44
95 ,
and the values of x that are solutions of f(x) ≡0 (mod 5) are x = 2 and
x = 4. Notice that, as regards the computations involved, it would have been
simpler to choose x = 1, 2, −1, −2, obtaining
x
0
1
2
−2
−1
f(x)
−1
2
15
−1
0
.
Thus, we ﬁnd the solutions x = 2 e x = −1 ≡4 (mod 5).
Example 5.2.2. Solve the congruence x3 + 2x2 −1 ≡0 (mod 7).
Compute f(x) = x3 + 2x2 −1 for the values x = 0, 1, 2, 3, 4, 5, 6, or
x = 0, 1, 2, 3, −3, −2, −1, modulo 7:
x
0
1
2
3
−3
−2
−1
f(x)
−1
2
15 ≡1
44 ≡2
−10 ≡4
−1
0
.
The congruence admits the unique solution x = −1, that is, x = 6.
Example 5.2.3. Solve the congruence x3 + 2x2 −1 ≡0 (mod 10).
We could proceed as above, that is to say, evaluating f(x) = x3+2x2−1 for
x = 0, 1, 2, . . ., 9 modulo 10, and checking for which values of x f(x) is found
to be congruent to 0. However, it is more convenient to proceed as follows.
Recall that if m and n are relatively prime, then a ≡b (mod mn) if and only
if a ≡b (mod m) and a ≡b (mod n). This means that the congruence

5.2 Non-linear polynomial congruences
231
x3 + 2x2 −1 ≡0
(mod 10)
is equivalent to the system of two congruences

x3 + 2x2 −1 ≡0
(mod 2),
x3 + 2x2 −1 ≡0
(mod 5).
Now, it is easy to verify that the ﬁrst congruence admits the unique solution
x ≡1 (mod 2) while the second one admits, as seen in the ﬁrst example, the
solutions x ≡2 (mod 5) and x ≡4 (mod 5). So x is a solution of x3+2x2−1 ≡
0 (mod 10) if and only if
x ≡1
(mod 2)
and
x ≡2 or 4
(mod 5).
Now we apply the Chinese remainder theorem 3.4.2 (see page 129). We know
that for each pair of solutions modulo 2 and modulo 5 there is a unique solution
modulo 10, as GCD(2, 5) = 1. So we only have to solve the two systems of
linear congruences

x ≡1
(mod 2),
x ≡2
(mod 5),
and

x ≡1
(mod 2),
x ≡4
(mod 5).
So we ﬁnd the two solutions x = 7 and x = 9 modulo 10. The reader may ﬁnd
again the same result by evaluating f(x) for x = 0, 1, 2, . . ., 9 (see Exercise
B5.38).
Example 5.2.4. Solve the congruence x3 + 6x2 + 1 ≡0 (mod 12).
As 12 = 3·4 and GCD(3, 4) = 1, it follows that x is a solution of x3+6x2+1
(mod 12) if and only if

x3 + 6x2 + 1 ≡0
(mod 3),
x3 + 6x2 + 1 ≡0
(mod 4);
then we proceed as in the previous example (see Exercise B5.39).
In these examples we were able to reduce the original congruences to con-
gruences modulo primes or prime powers. In the following lemma we shall
prove that this is always the case. Indeed, we shall prove that, in general,
given a congruence of the form
f(x) ≡0
(mod m),
it is always possible solve it through the solution of polynomial congruences
of the form
f(x) ≡0
(mod pα),
with p a prime,
(5.10)
and an application, as in the previous examples, of the Chinese remainder
theorem.

232
5 Finite ﬁelds and polynomial congruences
Lemma 5.2.5. Let m = pα1
1 pα2
2 · · · pαk
k
be the factorisation of the positive
integer m into distinct primes. Then the polynomial congruence
f(x) ≡0
(mod m)
(5.11)
is soluble if and only if each of the congruences f(x) ≡0 (mod pαi
i ), is soluble,
for i = 1, 2, . . ., k.
Proof. Let x0 be a solution of the congruence (5.11), that is, f(x0) ≡0
(mod m). As pαi
i
| m for all i = 1, . . . , k, it follows that f(x0) ≡0 (mod pαi
i )
for all i = 1, . . . , k.
Vice versa, if there exists xi such that f(xi) ≡0 (mod pαi
i ), for i =
1, . . . , k, by the Chinese remainder theorem there exists x such that x ≡xi
(mod pαi
i ), for i = 1, . . . , k, and so x is a solution (5.11).
⊓⊔
Remark 5.2.6. By applying the previous lemma and the Chinese remainder
theorem, it is clear that if every congruence
f(x) ≡0
(mod pαi
i )
admits ti solutions, then congruence (5.11) has ,k
i=1 ti solutions.
We shall now show that, if the solutions of the congruence
f(x) ≡0
(mod p)
are known, it is possible to ﬁnd the solutions of f(x) ≡0 (mod pα), enabling
us to reduce every polynomial congruence to a congruence modulo a prime
number. We shall prove this fact by showing that, for every positive integer
α, the solutions of f(x) ≡0 (mod pα+1) can be obtained from the solutions
of f(x) ≡0 (mod pα).
We start by discussing a simple example.
Example 5.2.7. Solve the congruence
f(x) = x3 + 3x + 2 ≡0
(mod 49).
(5.12)
We need not compute f(¯x) for all ¯x = 0, 1, . . . , 48, by noticing that a
solution of (5.12) is clearly also a solution of
f(x) = x3 + 3x + 2 ≡0
(mod 7).
(5.13)
But (5.13) has no solutions (see Exercise B5.40), so (5.12) has no solutions
either.
Example 5.2.8. Solve the congruence x4 + x + 3 ≡0 (mod 25).
The solutions of x4 + x + 3 ≡0 (mod 25) must also be solutions of x4 +
x + 3 ≡0 (mod 5). This congruence x4 + x + 3 ≡0 (mod 5) has the unique
solution x = 1, which is not a solution of x4 + x + 3 ≡0 (mod 25).

5.2 Non-linear polynomial congruences
233
We now prove the following general result:
Proposition 5.2.9. Let f(x) be a polynomial with integer coeﬃcients, p a
prime and α a positive integer. If xα, with 0 ≤xα < pα, is a solution of
f(x) ≡0
(mod pα)
(5.14)
and t, with 0 ≤t < p, is a solution of
f(xα)
pα
+ tf ′(xα) ≡0
(mod p)
(5.15)
(with f ′ the derivative polynomial of f), then xα+1 = xα + tpα is a solution
of
f(x) ≡0
(mod pα+1).
(5.16)
Vice versa, every solution xα+1, with 0 ≤xα+1 < pα+1, of the congruence
(5.16) can be obtained in this way.
Proof. As regards the ﬁrst part of the proposition, let n be the degree of
f(x). By Taylor’s formula 1.3.25 we can write
f(xα+1) = f(xα + tpα) =
= f(xα) + tpαf ′(xα) + (tpα)2 f (2)(xα)
2
+ · · · + (tpα)n f (n)(xα)
n!
≡
≡f(xα) + tpαf ′(xα)
(mod pα+1),
as pα+1 divides phα for all h ≥2. Moreover, notice that f (2)(xα)/2, . . .,
f (n)(xα)/n! are integers (see Exercise A1.63). On the other hand, by Equa-
tion (5.15) we have f(xα)/pα + tf ′(xα) = Np, where N is an integer. Thus,
f(xα) + tpαf ′(xα) = (Np)pα = Npα+1, and so
f(xα+1) ≡f(xα) + tpαf ′(xα) ≡0
(mod pα+1).
Vice versa, as clearly every solution of (5.16) is a solution of (5.14) as well,
if xα+1, with 0 ≤xα+1 < pα+1, satisﬁes f(xα+1) ≡0 (mod pα+1), then there
exists a xα, with 0 ≤xα < pα, such that f(xα) ≡0 (mod pα), with xα+1 ≡xα
(mod pα), that is to say, xα+1 = xα+tpα, with 0 ≤t < p. Using again Taylor’s
formula as above, we obtain
f(xα) + tpαf ′(xα) ≡0
(mod pα+1).
As f(xα) ≡0 (mod pα), f(xα)/pα is an integer N, that is, f(xα) = Npα;
hence
Npα + tpαf ′(xα) ≡0
(mod pα+1).
Dividing by pα we get N + tf ′(xα) ≡0 (mod p).
⊓⊔

234
5 Finite ﬁelds and polynomial congruences
The previous proposition says that if the congruence of degree n
f(x) ≡0
(mod p)
(5.17)
has ν (≤n) distinct solutions modulo p, then in general the equation
f(x) ≡0
(mod pα)
also has ν distinct solutions modulo pα. For instance, if α = 2, for every
solution xα of (5.17), a unique solution f(x) ≡0 (mod p2) is found, as long
as f ′(xα) is not divisible by p.
Example 5.2.10. Consider the equation
x2 ≡n2
(mod m)
(5.18)
with m = pα1
1 pα2
2 · · · pαk
k
the factorisation of m. Suppose m to be odd and
n ̸≡0 (mod m). Notice that the equation x2 ≡n (mod pi) has exactly two
solutions ±xi for all i = 1, . . . , k. Moreover, clearly ±2xi ̸≡0 (mod pi), i =
1, . . . , k. Proposition 5.2.9 and Remark 5.2.6 imply that (5.18) has exactly 2k
distinct solutions modulo m.
Example 5.2.11. Solve the congruence x2 + 8 ≡0 (mod 121).
We reduce to solving the equation
x2 + 8 ≡0
(mod 11),
whose solutions are x ≡5, 6 (mod 11). They lead to the following linear
congruences in t:
3 −t ≡0
(mod 11),
4 + t ≡0
(mod 11),
whose solutions are t ≡3 (mod 11) and t ≡7 (mod 11), respectively. Corre-
spondingly we ﬁnd the solutions 5 + 3 · 11 = 38 (mod 121) and 6 + 7 · 11 = 83
modulo 121 of the original congruence.
Remark 5.2.12. Notice that Equation (5.15) has a unique solution if and
only if f ′(xα) ̸≡0 (mod p). If on the other hand f ′(xα) ≡0 (mod p), then
Equation (5.15) has no solutions, unless one has f(xα)/pα ≡0 (mod p), that
is, f(xα) ≡0 (mod pα+1). In this case Equation (5.15) is satisﬁed by all
t = 0, . . . , p −1, so there are p solutions of (5.16).
5.2.1 Degree two congruences
We are now going to study in detail polynomial congruences of degree two or,
as they are called, quadratic congruences, that is to say, of the form
ax2 + bx + c ≡0
(mod m).

5.2 Non-linear polynomial congruences
235
Using the results of the previous section we may assume the modulus m to be
a prime number p. Further, as the case p = 2 is trivial (see Exercise B5.37),
we may directly assume p to be an odd prime. So, consider the congruence
ax2 + bx + c ≡0
(mod p),
p odd prime, p ∤a.
(5.19)
It may be solved by the classic method of completing the square we are
now going to recall. Let a′ ∈Z be such that 2aa′ ≡1 (mod p): such an a′
always exists, as 2a ̸= 0 in Zp. Multiplying Equation (5.19) by 2a′ we get an
equivalent congruence of the form
x2 + 2b′x + c′ ≡0
(mod p).
It can be written in the equivalent form
(x + b′)2 ≡b′2 −c′
(mod p).
By setting y = x + b′ and k = b′2 −c′, Equation (5.19) reduces to the form
y2 ≡k
(mod p).
(5.20)
In order to solve Equation (5.19) it suﬃces then to solve x + b′ ≡y (mod p),
where y is a solution of y2 ≡k (mod p). Notice that the congruence x+b′ ≡y
(mod p) always admits a unique solution. On the other hand, equation y2 ≡k
(mod p) may either admit no solution or admit two solutions, opposite each
other, which are the two square roots of k in Zp. These two solutions may
coincide, and yield a solution with multiplicity two, if k ≡0 (mod p). In the
ﬁrst case the original equation (5.19) has no solutions in Zp, while in the
second one it has two solutions (see Exercise A5.42).
Gauss was the ﬁrst to observe that to solve quadratic congruences it suﬃces
to solve congruence of the particular form (5.20).
Example 5.2.13. Find the solutions of the quadratic congruence
2x2 + x + 3 ≡0
(mod 5).
(5.21)
Using the same notation as above, we ﬁnd a′ ∈Z such that 2 · 2a′ ≡1
(mod 5), and precisely a′ = −1. Multiplying the congruence by 2a′ = −2 we
get
x2 −2x −1 ≡0
(mod 5),
or
(x −1)2 ≡2
(mod 5).
Setting y = x −1, the congruence to be solved becomes
y2 ≡2
(mod 5).
This congruence has no solutions, so neither has the original congruence
(5.21).

236
5 Finite ﬁelds and polynomial congruences
Example 5.2.14. Find the solutions of the quadratic congruence
3x2 + x + 1 ≡0
(mod 5).
(5.22)
The congruence is equivalent to
(x + 1)2 −4 ≡0
(mod 5),
or
y2 ≡4
(mod 5),
which admits two solutions, y1 = 2 and y2 = 3. So the original congruence
(5.22) has the solutions x1 = y1 −1 = 1 and x2 = y2 −1 = 2.
In the above examples we found a congruence of the form (5.20) that did
not admit solutions and one that did. We would like to ﬁnd general criteria
enabling us to decide when a quadratic congruence of the form (5.20) admits
solutions and when it does not admit any. This is the purpose of the next
section.
5.2.2 Quadratic residues
Deﬁnition 5.2.15. Let p be an odd prime and a an integer such that p ∤a.
If the congruence
x2 ≡a
(mod p)
is soluble, then a is said to be a quadratic residue of p, else a is said to be a
quadratic non-residue of p.
In other words, a quadratic residue of p is an element of the group Z∗
p =
Zp \ {0} that is a square. So we shall indiﬀerently speak about quadratic
residues of p, or of squares modulo p, or of squares in Z∗
p. Looking at the
above examples, we see that 2 is not a square modulo 5, while 4 is.
The squares in Z∗
5 are
1 = 12 = 42,
4 = 22 = 32.
The squares in Z∗
7 are
1 = 12 = 62,
2 = 32 = 42,
4 = 22 = 52.
The squares in Z∗
11 are
1 = 12 = 102,
3 = 52 = 62,
4 = 22 = 92,
5 = 42 = 72,
9 = 32 = 82.
One may guess from these examples that the squares are exactly one half
of all elements of Z∗
p. Indeed, the following proposition holds.

5.2 Non-linear polynomial congruences
237
Proposition 5.2.16. Let p an odd prime. Then there are exactly (p −1)/2
quadratic residues of p:
12, 22, . . . ,
p −3
2
2
,
p −1
2
2
.
Proof. We can write the p elements of Zp as follows:
−p −1
2
, −p −3
2
, . . . , −1, 0, 1, . . ., p −3
2
, p −1
2
.
Now, in a ﬁeld the relation a2 −b2 = (a−b)(a+b) = 0 implies a = ±b. So,
in a ﬁeld, if two squares a2 and b2 coincide, then a = ±b. This tells us that
the squares of the elements 1, . . . , (p −3)/2, (p −1)/2 ∈Z∗
p are all distinct
and there are (p −1)/2 of them.
⊓⊔
Example 5.2.17. Determine all the quadratic residues of 23.
By Proposition 5.2.16, the squares modulo p = 23 are the squares of the
integers from 1 to (p −1)/2 = 11, that is
12, 22, 32, 42, 52, 62, 72, 82, 92, 102, 112,
or
1, 4, 9, 16, 2, 13, 3, 18, 12, 8, 6.
For not too large values of p we may easily ﬁnd the squares (and so the
non-squares) using Proposition 5.2.16. But what about large moduli? Are
there criteria to recognise whether an integer is a square modulo a prime p or
not? Here follows a quite simple remark.
Lemma 5.2.18. Let g ∈Z∗
p be a generator of the multiplicative group Z∗
p.
Then a = gj (for 0 ≤j < p−1) is a quadratic residue if and only if j is even.
The proof is left to the reader (see Exercise A5.43).
The following result, due to Euler, is simple but important.
Proposition 5.2.19 (Euler’s criterion). Let p be an odd prime not divid-
ing a. If a is a quadratic residue of p, then
a(p−1)/2 ≡1
(mod p).
If, on the other hand, a is not a quadratic residue of p, then
a(p−1)/2 ≡−1
(mod p).
Proof. We have
(a(p−1)/2)2 = ap−1 ≡1
(mod p),

238
5 Finite ﬁelds and polynomial congruences
so
a(p−1)/2 ≡±1
(mod p).
If g ∈Z∗
p is a generator of the multiplicative group and a = gj (mod p), then
a(p−1)/2 ≡gj(p−1)/2
(mod p).
On the other hand,
gj(p−1)/2 ≡1
(mod p)
if and only if j(p −1)/2 is divisible by p −1, that is, if and only if j is even,
that is, if and only if a is a quadratic residue.
⊓⊔
Remark 5.2.20. Euler’s criterion is quite expensive computationally when
p is very large. Indeed, the computational complexity of computing a(p−1)/2
modulo p is O(log3 p) (see § 3.3.1 or Proposition 5.1.44). However, we shall
see in the next chapter how it may nevertheless be used as the theoretical
basis for some primality tests.
5.2.3 Legendre symbol and its properties
A criterion simpler than Euler’s is obtained by exploiting the law of quadratic
reciprocity, which will shortly be stated. To this purpose, we deﬁne a symbol,
the so-called Legendre symbol, to denote whether an integer a is a square
modulo an odd prime p or not.
Deﬁnition 5.2.21. Let p be an odd prime and a an integer. Deﬁne the Leg-
endre symbol as follows:
a
p

=
⎧
⎪
⎨
⎪
⎩
1
if a is a quadratic residue of p,
0
if a is divisible by p,
−1
if a is not a quadratic residue of p.
For instance,
 2
11

= −1
as 2 is not a quadratic residue of 11, while
 3
11

= 1
as 3 ≡52 (mod 11). Analogously,
 4
13

= 1
as 4 = 22. Finally,

5.2 Non-linear polynomial congruences
239
6
3

= 0
as 6 is divisible by 3.
Our goal is to compute Legendre symbol
 a
p
	
to decide whether the con-
gruence
x2 ≡a
(mod p)
has solutions or not. To this purpose, we shall need some basic properties of
the Legendre symbol, collected in the following proposition.
Proposition 5.2.22. Let p be an odd prime and a, b two integers coprime
with p. Then the Legendre symbol enjoys the following properties:
(1) if a ≡b (mod p), then
 a
p
	
=
 b
p
	
;
(2)
 a2
p
	
= 1;
(3)
 a
p
	
≡a(p−1)/2 (mod p);
(4)
 ab
p
	
=
 a
p
	 b
p
	
;
(5)
 1
p
	
= 1 and
 −1
p
	
= (−1)(p−1)/2.
We leave the easy proof of these properties to the reader (see Exercise
A5.44). An immediate consequence is the following corollary, also left to the
reader (see Exercise A5.45):
Corollary 5.2.23. If p is an odd prime, then
−1
p

=

1
if p ≡1
(mod 4),
−1
if p ≡3
(mod 4).
Example 5.2.24. Solve the congruence x2 ≡−46 (mod 17).
Use the properties of the Legendre symbol to check whether −46 is a
square in Z∗
17 or not. We have to compute the Legendre symbol
−46
17

.
We have
−46
17

=
−1
17
 46
17

=
46
17

because 17 ≡1 (mod 4). As 46 ≡12 (mod 17),
−46
17

=
12
17

=
3 · 22
17

=
 3
17

.
Finally,
 3
17

≡316/2 = 38 ≡−1
(mod 17).
In conclusion, −46 is not a square modulo 17.

240
5 Finite ﬁelds and polynomial congruences
Another useful information about the Legendre symbol is given by the
following proposition.
Proposition 5.2.25 (Gauss Lemma). Let p be an odd prime and let a ∈Z
be such that GCD(a, p) = 1. Then
a
p

= (−1)n(a,p),
where n(a, p) denotes the number of integers in the set
A :=
*
a, 2a, . . ., (p −1)a
2
+
such that the remainder of the division by p is greater than p/2.
Proof. First of all, notice that the size of A modulo p is (p −1)/2. Indeed,
as GCD(a, p) = 1, no element in A is congruent to zero modulo p and all of
them are distinct. Then divide the elements of A into two disjoint subsets A1
and A2. Put in subset A1 the elements of A that are congruent, modulo p,
to positive numbers smaller than (p −1)/2, and in subset A2 the remaining
elements of A, that is to say, those congruent to numbers between p/2 and p.
Denote by m the size of A1, while the size of A2 is exactly n = n(a, p). Thus,
n + m = (p −1)/2.
Denote now by r1, r2, . . . , rm the remainders modulo p of the elements of
A1 and by s1, s2, . . . , sn the remainders modulo p of the elements of A2. Then
the integers r1, . . . , rm, p −s1, . . . , p −sn satisfy the following:
0 < r1, . . . , rm, p −s1, . . . , p −sn < p
2.
(5.23)
We shall prove that they are all distinct, and so coincide, up to the ordering,
with the integers 1, 2, 3, . . ., (p −1)/2. Indeed, suppose by contradiction that
for some choice of h and k
p −sk = rh.
By deﬁnition there exist two integers α, β, with 1 ≤α, β ≤(p −1)/2 and such
that
rh ≡αa
(mod p),
e
sk ≡βa
(mod p),
hence
(α + β)a ≡rh + sk = p ≡0
(mod p),
which implies α + β ≡0 (mod p). But this relation yields a contradiction, as
0 < α + β ≤p −1.
As all of r1, . . . rm, p −s1, . . . , p −sn are distinct, it follows from the
relations (5.23) that they coincide, up to the ordering, with the integers
1, 2, 3, . . ., (p −1)/2. So we have

5.2 Non-linear polynomial congruences
241
p −1
2

! = r1 · rm(p −s1) . . . (p −sn) ≡(−1)nr1 . . . rms1 . . . sn
(mod p).
As the numbers rh and sk, for h = 1, . . . , m and k = 1, . . . , n, are the remain-
ders modulo p of the elements of A, we have
p −1
2

! ≡(−1)na · 2a · 3a · · ·
p −1
2

a ≡(−1)na
p−1
2
p −1
2

!
(mod p).
As GCD(((p −1)/2)!, p) = 1, we get
a(p−1)/2 ≡(−1)n
(mod p).
It is now possible to conclude immediately by using part (3) of Proposition
5.2.22.
⊓⊔
The following proposition can be proved in a similar way as Gauss Lemma:
Proposition 5.2.26. Let p be an odd prime number and let a be an odd in-
teger such that a and p are relatively prime. Deﬁne:
τ(a, p) =
(p−1)/2

i=1
ia
p

.
Then:
a
p

= (−1)τ(a,p).
Proof. By Gauss Lemma, it is suﬃcient to prove that
τ(a, p) ≡n(a, p)
(mod 2).
(5.24)
Dividing the integer ia, i = 1, . . . , (p −1)/2, by p, we get
ia = p
ia
p

+ ρi,
(5.25)
where ρi is the remainder of the division. Using the same notation as in the
proof of Gauss Lemma, ρi = rh or ρi = sk depending on ia being in A1 or in
A2. Summing Equation (5.25) for i = 1, . . . , (p −1)/2, we obtain
(p−1)/2

i=1
ia = p
(p−1)/2

i=1
ia
p

+
m

h=1
rh +
n

k=1
sk,
(5.26)
where n = n(a, p). As we saw in the proof of Gauss Lemma, the integers
r1, . . . rm, p −s1, . . . p −sn coincide, up to the ordering, with the integers
1, 2, 3, . . ., (p −1)/2. So we have

242
5 Finite ﬁelds and polynomial congruences
(p−1)/2

i=1
i =
m

h=1
rh +
n

k=1
(p −sk) = p · n(a, p) +
m

h=1
rh −
n

k=1
sk.
(5.27)
By subtracting Equation (5.27) from Equation (5.26), we get
(a −1)
(p−1)/2

i=1
i = p · τ(a, p) −p · n(a, p) + 2
n

k=1
sk.
Considering it modulo 2, as a and p are odd, (5.24) is found.
⊓⊔
As a consequence of Gauss Lemma we have the following corollary.
Corollary 5.2.27. If p is an odd prime, then
2
p

= (−1)(p2−1)/8 =

1
if p ≡±1
(mod 8),
−1
if p ≡±3
(mod 8).
Proof. Apply Gauss Lemma to the case a = 2, where A = {2, 4, . . ., p −1}
and so we have to ﬁnd the number n of elements of A that are greater than
p/2. An integer 2i, with 1 ≤i ≤(p −1)/2 is smaller than p/2 if and only if
1 ≤i ≤[p/4]. Then n = (p −1)/2 −[p/4]. We prove next that
p −1
2
−
$p
4
%
≡p2 −1
8
(mod 2).
(5.28)
We must simply check that both sides of (5.28) have the same parity.
During this check, we shall also prove that (p2 −1)/8 is even or odd depending
on p ≡±1 (mod 8) or p ≡±3 (mod 8). Indeed:
•
if p ≡±1 (mod 8), that is, if p = 8h ± 1, with h a positive integer, we
have
p2 −1
8
= (8h ± 1)2 −1
8
= 64h2 ± 16h
8
= 8h2 ± 2h ≡0
(mod 2);
•
if p ≡±3 (mod 8), that is, if p = 8h ± 3, with h a positive integer, we
have
p2 −1
8
= (8h ± 3)2 −1
8
= 64h2 ± 48h + 8
8
= 8h2 ± 6h + 1 ≡1
(mod 2);
On the other hand:
•
if p ≡1 (mod 8), that is, if p = 8h + 1, with h a positive integer, we have
p −1
2
−
$p
4
%
= 4h −
8h + 1
4

= 4h −2h ≡0
(mod 2);

5.2 Non-linear polynomial congruences
243
•
if p ≡−1 ≡7 (mod 8), that is, if p = 8h + 7, with h a positive integer, we
have
p −1
2
−
$p
4
%
= 4h + 3 −
8h + 7
4

= 4h −2h + 2 ≡0
(mod 2);
•
if p ≡3 (mod 8), that is, if p = 8h + 3, with h a positive integer, we have
p −1
2
−
$p
4
%
= 4h + 1 −
8h + 3
4

= 4h −2h + 1 ≡1
(mod 2);
•
if p ≡−3 ≡5 (mod 8), that is, if p = 8h + 5, with h a positive integer, we
have
p −1
2
−
$p
4
%
= 4h + 2 −
8h + 5
4

= 4h −2h + 1 ≡1
(mod 2).
So the proof is complete.
⊓⊔
A diﬀerent proof of Corollary 5.2.27, which exploits some properties of
ﬁnite ﬁelds, will be outlined in the exercises (see Exercise A5.50).
5.2.4 The law of quadratic reciprocity
The next theorem is a milestone of number theory, and is, together with
Proposition 5.2.22 and Corollary 5.2.27, the fundamental tool to compute ef-
ﬁciently the Legendre symbols. This theorem, conjectured in the 18th century
by Euler and Legendre, who did not succeed in giving a complete proof, was
proved by Gauss when he was 19 years old. Since then, several more proofs
have been found. We show here a very simple proof, referring to the exer-
cises for a more technical one, based upon the properties of ﬁnite ﬁelds (see
Exercises A5.47-A5.54).
Theorem 5.2.28 (Law of quadratic reciprocity). Let p and q be distinct
odd primes. Then
p
q

=
q
p

unless p ≡q ≡3 (mod 4), in which case
p
q

= −
q
p

.
Equivalently,
p
q
 q
p

= (−1)(p−1)(q−1)/4.

244
5 Finite ﬁelds and polynomial congruences
Proof. Consider the open rectangle R in the plane xy, having vertices
(0, 0), (p/2, 0), (0, q/2), (p/2, q/2). Clearly, it includes (p −1)(q −1)/4 points
having integer coordinates, that is, all the points of the form (i, j), with
1 ≤i ≤(p −1)/2, 1 ≤j ≤(q −1)/2.
Let D be the diagonal from (0, 0) to (p/2, q/2) of the rectangle, having
equation py = qx. As GCD(p, q) = 1, no point with integer coordinates in R
lies on D. Denote by R1 the subset of R lying below D, that is, where py < qx,
and by R2 the subset of R lying above D, that is, where py > qx.
Count the points of R1 having integer coordinates. They are all the points
of the form (i, j), with 1 ≤i ≤(p −1)/2, 1 ≤j ≤[qi/p]. So the number of
points of R1 having integer coordinates is exactly τ(q, p) = (p−1)/2
i=1
[qi/p].
Analogously, the number of points of R2 having integer coordinates is τ(p, q) =
(q−1)/2
i=1
[pi/q].
So we have
(p −1)(q −1)
4
= τ(p, q) + τ(q, p).
The theorem immediately follows from Proposition 5.2.26.
⊓⊔
Remark 5.2.29. The Legendre symbol
 p
q
	
is connected with the solution of
the congruence x2 ≡p (mod q), while
 q
p
	
is connected with the solution of
the congruence x2 ≡q (mod p). The law of quadratic reciprocity connects
the two congruences, modulo diﬀerent integers, x2 ≡q (mod p) and x2 ≡p
(mod q), which a priori have not much in common. As can be guessed, and as
we shall shortly see, the law of quadratic reciprocity helps greatly in computing
the Legendre symbols, and so enables us to ﬁnd easily the quadratic residues.
Example 5.2.30. Compute
 59
131
	
.
Using by turns the properties of the Legendre symbol and the law of
quadratic reciprocity, we obtain:
 59
131

= −
131
59

= −
13
59

= −
59
13

= −
 7
13

= −
13
7

=
= −
−1
7

= 1.
This theorem has many consequences in several ﬁelds of mathematics. In
the next chapter we shall see an application to the problem of recognising
whether a number is a prime or not. Let us now see two more elementary
examples.
Example 5.2.31. Characterise the odd primes p such that the congruence
x2 ≡5
(mod p)
admits a solution.

5.2 Non-linear polynomial congruences
245
By the law of quadratic reciprocity, the equation x2 ≡5 (mod p) admits
a solution if and only if the congruence
x2 ≡p
(mod 5).
admits a solution. This congruence has solutions only if p = ±1 (mod 5) (see
Exercise B5.41). So the odd primes for which x2 ≡5 (mod p) admits solutions
are those of the form p = ±1 + 5h; for instance 11, 19, 29. Recall that, by
Dirichlet’s Theorem 4.1.6, there are inﬁnitely many such primes.
Example 5.2.32. Determine the odd primes p such that −3 is a quadratic
residue of p.
It is necessary to ﬁnd for which values of p the congruence
x2 + 3 ≡0
(mod p)
(5.29)
has a solution. By the law of quadratic reciprocity and the properties of the
Legendre symbol,
−3
p

=
−1
p
p
3

(−1)(p−1)/2 =
p
3

.
So (5.29) has solutions if and only if the congruence
x2 ≡p
(mod 3),
has solutions, and this happens if and only if p ≡1 (mod 3). In conclusion,
(5.29) has a solution if and only if p is a prime of the form 3h + 1.
A ﬁrst, simple application of the law of quadratic reciprocity lies in a
complete proof of P´epin’s test 4.4.8. So we prove the following.
Proposition 5.2.33. If the Fermat number Fn is prime, then
3(Fn−1)/2 ≡−1
(mod Fn).
(5.30)
Proof. If Fn is prime, by applying the law of quadratic reciprocity we have
 3
Fn

=
Fn
3

=
2
3

= −1.
We may now conclude by applying Euler’s Criterion 5.2.19 or part (3) of
Proposition 5.2.22.
⊓⊔
5.2.5 The Jacobi symbol
The law of quadratic reciprocity is not completely suﬃcient to compute the
Legendre symbol
 a
p
	
, with p odd prime and a an arbitrary number. It is
convenient to put ourselves in a more general setting, as follows.

246
5 Finite ﬁelds and polynomial congruences
First of all, we introduce a generalisation of the Legendre symbol, the
Jacobi symbol
 a
n
	
, where a is an arbitrary integer and n an odd positive
integer. If the factorisation of n is n = pα1
1 · · · pαr
r , with p1, . . . , pr distinct odd
prime numbers, we deﬁne the Jacobi symbol
 a
n
	
as
a
n
 
=
 a
p1
α1
· · ·
 a
pr
αr
.
It is important to remark that if n is not a prime, the fact that
 a
n
	
= 1 does
not at all mean that a is a square modulo n. For instance
 2
15

=
2
3

·
2
5

= (−1) · (−1) = 1,
(5.31)
but the equation x2 ≡2 (mod 15) has no solution (see Exercise B5.42). Nev-
ertheless, the Jacobi symbol enjoys some formal properties analogous to those
of the Legendre symbol.
Proposition 5.2.34. Let n be a positive odd number and let a and b be inte-
gers relatively prime with n. Then:
(1) if a ≡b (mod n), then
 a
n
	
=
 b
n
	
;
(2)
 ab
n
	
=
 a
n
	 b
n
	
;
(3)
 1
n
	
= 1 e
 −1
n
	
= (−1)(n−1)/2.
Proof. We shall prove only part (3), leaving the easy veriﬁcation of (1) and
(2) as an exercise to the reader (see Exercise A5.55).
If n = pα1
1 · · · pαr
r , with p1, . . . , pr distinct odd prime numbers, we have
−1
n

=
−1
p1
α1
· · ·
−1
pr
αr
= (−1)(α1(p1−1)+···+αr(pr−1))/2.
(5.32)
Notice now that, for every odd prime number p and positive integer α, we
have
pα = (1 + (p −1))α ≡1 + α(p −1)
(mod 4)
(see Exercise A5.57). So we have
n ≡(1 + α1(p1 −1)) · · · (1 + αr(pr −1))
(mod 4)
and, keeping in mind that all of p1 −1, . . . , pr −1 are even numbers, we have
n ≡1 + α1(p1 −1) + · · · + αr(pr −1)
(mod 4),
or
n −1
2
≡α1(p1 −1) + · · · + αr(pr −1)
2
(mod 2).
This, together with Equation (5.32) proves (3).
⊓⊔

5.2 Non-linear polynomial congruences
247
Further, the following holds:
Proposition 5.2.35. If n is a positive odd integer, then
 2
n

= (−1)(n2−1)/8
and if m is another positive odd integer, then
 n
m
 
=
m
n
 
unless n ≡m ≡3 (mod 4), in which case
 n
m
 
= −
m
n
 
.
Equivalently,
m
n
  n
m
 
= (−1)(n−1)(m−1)/4.
Proof. Deﬁne ϵ(n) = (−1)(n2−1)/8 for all odd positive integers n. It is easy
to verify (see Exercise A5.58) that ϵ is a completely multiplicative function in
its domain Z \ 2Z = {1, 3, 5, . . .}, that is, for each pair (n, m) of odd positive
integers, ϵ(nm) = ϵ(n)ϵ(m).
Thus, if n factors as n = pα1
1 · · · pαr
r , with p1, . . . , pr distinct odd prime
numbers, we have
ϵ(n) = ϵ(p1)α1 · · · ϵ(pr)αr.
By applying Corollary 5.2.27, we get ϵ(pi) =
 2
pi
	
, and so ϵ(pi)αi =
 2
pi
	αi,
i = 1, . . . , r. Thus,
ϵ(n) =
 2
p1
α1
· · ·
 2
pr
αr
which, by deﬁnition, is
 2
n
	
. This proves the ﬁrst part of the proposition.
As regards the second part, notice ﬁrst that if GCD(n, m) ̸= 1, from the
deﬁnition itself of Legendre and Jacobi symbols, we have
 n
m
	
=
 m
n
	
= 0.
So, suppose that GCD(n, m) = 1. Write n = p1 · · · ph and m = q1 · · · qk,
with p1, . . . , ph, q1, . . . , qk not necessarily distinct primes. By deﬁnition of the
Jacobi symbol and the properties of the Legendre symbol, we ﬁnd
 n
m
 
=
h
'
i=1
k
'
j=1
pi
qj

,
m
n
 
=
h
'
i=1
k
'
j=1
qj
pi

.
Apply now the law of quadratic reciprocity to each of the hk symbols
 pi
qj
	
.
Let ℓbe the number of pairs (i, j) with 1 ≤i ≤h, 1 ≤j ≤k, such that both
pi and qj are congruent to 3 modulo 4. Then we have
 n
m
 
= (−1)ℓm
n
 
.

248
5 Finite ﬁelds and polynomial congruences
On the other hand, it is clear that ℓ= ℓ1ℓ2 where ℓ1 [ℓ2, respectively] is
the number of is [of js, resp.] such that 1 ≤i ≤h [1 ≤j ≤k, resp.] and pi [qj,
resp.] is congruent to 3 modulo 4. So we have n ≡3ℓ1 ≡(−1)ℓ1 (mod 4), and
analogously m ≡(−1)ℓ2 (mod 4). In conclusion, we have
 n
m
	
=
 m
n
	
unless
both ℓ1 and ℓ2 are odd, that is, unless n ≡m ≡−1 ≡3 (mod 4), and in this
case
 n
m
	
= −
 m
n
	
.
⊓⊔
This proposition enables us, in principle, to compute any Legendre symbol
in a way analogous to what has been done in Example 5.2.30.
Example 5.2.36. Compute
 3083
3911
	
.
We have
3083
3911

= −
3911
3083

because both 3911 and 3083 are congruent to 3 modulo 4. Dividing 3911 by
3083 the remainder is 828 = 4 · 207. So,
3083
3911

= −

4
3083
  207
3083

.
Going on, we ﬁnd
3083
3911

= −
 207
3083

=
3083
207

=
185
207

=
207
185

=
 2
185
  11
185

=
=
 11
185

=
185
11

=
 9
11

=
11
9

=
2
9

= 1.
Remark 5.2.37. The law of quadratic reciprocity, which as we have seen
holds in general for the Jacobi symbols, together with the formal properties
of the latter, enables us to compute the symbol without having to know the
factorisation of the numbers involved. In conclusion, computing
 n
m
	
, with
n > m, has the same complexity as computing the greatest common divisor
of n and m, that is, has complexity O(log3 n).
5.2.6 An algorithm to compute square roots
The law of quadratic reciprocity makes it possible to ascertain whether the square
root of an integer a modulo a prime p exists or not, but does not give a method
to compute it. We conclude this chapter showing an algorithm to compute square
roots in Zp with p an odd prime. It relies on the knowledge of an integer n that is
not a quadratic residue modulo p.
Let a be an integer such that
 a
p
	
= 1, so we know that there is a solution of
the equation x2 ≡a (mod p). We want to determine a solution of this equation. We
may proceed as follows.
First of all, we may assume a to be positive and smaller than p, and we may
consider a as an element of Zp. Write next p −1 = 2rs with odd s. Compute the
remainder ξ of ns modulo p, and consider ξ as an element of Zp.

5.2 Non-linear polynomial congruences
249
Lemma 5.2.38. The number ξ is a primitive 2rth root of unity in Zp.
Proof. We begin by verifying that ξ is a 2rth root of unity. Indeed, in Zp we have
ξ2r = [n]2rs
p
= [n]p−1
p
= 1,
having denoted by [n]p the residue class modulo p.
Suppose ξ is not a primitive root. Let η be a primitive 2rth root and let ξ = ηt,
with 2 ≤t < 2r. Then GCD(t, 2r) ̸= 1 (see Exercise A3.30), so t = 2u with
0 < u < r. So we would have ξ = η2u =

η2u−1	2. But this is not possible, as
 ξ
p

=
 ns
p

=
 n
p
s
= (−1)s = −1.
⊓⊔
Remark 5.2.39. Notice that the previous lemma guarantees that R2r ⊆Zp, as
ξ ∈Zp is generator of R2r. So for all positive integers u < r we have R2u ⊂R2r ⊆Zp.
We now compute the remainder ρ of the division of a(s+1)/2 by p and, once more,
we consider it as an element of Zp.
Lemma 5.2.40. In Zp, (a−1ρ2)2r−1 = 1.
Proof. In Zp we have
(a−1ρ2)2r−1 = as2r−1 = a(p−1)/2 =
a
p

= 1.
⊓⊔
Notice that in R2r−1 the element a−1ρ2 has an inverse x, and xρ2 = a. As
R2r−1 ⊂R2r, by Lemma 5.2.38 we have x = ξt, with 0 ≤t < 2r. If we prove that
t = 2v is even, then we have a = xρ2 = (ξvρ)2, so we have found the square root
ξvρ of a.
In conclusion, we have to ﬁnd an element v such that 0 ≤v < 2r−1 and such
that ξvρ is a square root of a in Zp. We write v = v0 + 2v1 + 22v2 + · · ·+ vr−22r−2 in
binary form and show that there is an algorithm to compute successively the digits
v0, v1, v2, . . . , vr−2.
Step 1: determining v0. By Lemma 5.2.40, in Zp we have
(a−1ρ2)2r−2 = ±1.
If (a−1ρ2)2r−2 = 1, take v0 = 0, else take v0 = 1. In both cases, as ξ2r−1 = −1, in
Zp we have
(a−1(ξv0ρ)2)2r−2 = 1.
Step h + 1: determining vh, with 0 < h < r −3. Suppose we have found v0, . . . , vh−1
in such a way that in Zp we have
(a−1(ξv0+2v1+···+2h−1vh−1ρ)2)2r−h−1 = 1.
Then in Zp we have
(a−1(ξv0+2v1+···+2h−1vh−1ρ)2)2r−h−2 = ±1.
In the case “+1” we take vh = 0, else we take vh = 1. After this choice in Zp we
have
(a−1(ξv0+2v1+···+2hvhρ)2)2r−h = 1.
Going on like this, after r −1 steps we ﬁnd the required root.

250
5 Finite ﬁelds and polynomial congruences
Example 5.2.41. The simplest case is when p ≡3 (mod 4). Then, and only then,
we have p−1 = 2s with s = (p −1)/2 odd and, with the notation introduced above,
r = 1. In this case, by Lemma 5.2.40 we know that ρ2 = a and so the required root
is ρ, that is, the residue class modulo p of a(s+1)/2, that is, a(p+1)/4.
For instance, the square root of 7 in Z19 is the residue class modulo 19 of 75 =
16807, that is 11.
Example 5.2.42. We apply now the algorithm, as an example, to a very simple
case, that of ﬁnding a square root of a = 2 in Z17. Indeed, notice that ( 2
17) = 1.
On the other hand,
 3
17
	
=
 17
3
	
=
 2
3
	
= −1. So we may take n = 3. Moreover,
a−1 = 9.
Here r = 4 e s = 1, so ξ = n = 3 and ρ = a = 2, and it is necessary to compute
v = v0 + 2v1 + 4v2 such that ξvρ = 2 · 3v is a square root of 2.
The algorithm tells us that a−1ρ2 = a = 2 is an eighth root of unity. In the ﬁrst
step of the algorithm we have to consider (a−1ρ2)4 = a4 = 24 = 16 ≡−1 (mod 17).
This tells us that v0 = 1 and so that a−1(ξ · ρ)2 is a fourth root of unity. However,
a−1(ξ · ρ)2 = 9 · (3 · 2)2 = 1, and so the algorithm stops here, as we have found the
required root, which is ξ · ρ = 3 · 2 = 6. This means that v1 = v2 = 0.
Remark 5.2.43. It is easy to compute the complexity of the algorithm just de-
scribed. Suppose a positive and smaller than p. Otherwise, computing its remainder
modulo p has complexity O(log a · log p) (see Proposition 2.4.1).
First of all, it is necessary to compute r and s. This involves dividing successively,
r < log2 p times, p−1 by 2. Hence, the complexity of this computation is O(r log2 p),
that is, O(log3 p).
Netx, we must compute ξ, which is the class modulo p of ns. The complexity of
this operation is O(log a log2 p), that is, again, O(log3 p) (see Section 3.3.1). Simi-
larly, computing ρ, which is the class modulo p of a(p+1)/2, has complexity O(log3 p).
To carry out the (h + 1)th step of the algorithm, that is to determine vh, it is
again necessary to compute a power modulo p of the class modulo p of
a−1(ξv0+2v1+···+2h−1vh−1ρ)2,
which was already computed in the previous step. This has again complexity
O(log3 p). Finally, it is necessary to compute the class modulo p of the number
a−1(ξv0+2v1+···+2hvhρ)2, which has again complexity O(log3 p).
As it is necessary to perform r −1 steps to complete the algorithm, and as
r < log2 p, in conclusion the complexity is O(log4 p), so it is polynomial.
Remark 5.2.44. The algorithm discussed in this section relies on the knowledge
of an integer n that is not a square modulo p. Unfortunately there are no known
algorithms to compute such an integer. However, it is quite easy to devise a very
eﬃcient probabilistic algorithm to ﬁnd such a number.
As this is the ﬁrst time we are dealing with this notion, let us tell something
about it. The algorithms we have discussed so far are called deterministic: they
compute exactly what they are devised for. A probabilistic algorithm to compute,
say, a number x, on the contrary, consists of a sequence of steps such that in the nth
step a number xn is computed, and there exists a sequence of positive real numbers
{ϵn}n∈N converging to 0, such that the probability for xn to be diﬀerent from the
thing we are looking for is smaller than ϵn.

A5 Theoretical exercises
251
Thus, a probabilistic algorithm does not give the certainty of having computed
what we are interested in. However, if the sequence {ϵn}n∈N converges to 0 very
quickly, for instance if ϵn = 1/2n, the probability of having found the correct answer
is very high after just a few steps. For all intents and purposes, we may consider
very diﬃcult to observe an event having a probability smaller than 2−100.
It is quite easy to devise a polynomial probabilistic algorithm to ﬁnd a non-
square in Zp. The algorithm consists in choosing randomly in the nth step a number
xn such that 0 < xn < p and xn ̸= xi, with 0 < i < n. Compute next
 xn
p
	
, which
can be done in polynomial time (see Remark 5.2.37) and verify whether xn is a
square in Zp or not. Keeping in mind that the number of squares is equal to that of
non-squares in Zp (see Proposition 5.2.16), we observe that the probability that at
the nth step the algorithm has not found a quadratic non-residue is exactly 1/2n.
Notice that the same algorithm also ﬁnds a quadratic residue modulo p.
Appendix to Chapter 5
A5 Theoretical exercises
A5.1. Given an arbitrary ﬁeld K the intersection of all subﬁelds of K is called the
prime or fundamental subﬁeld of K. Prove that the fundamental subﬁeld of K is the
smallest subﬁeld of K, that is to say it is included in any other subﬁeld of K. Verify
further that the fundamental subﬁeld of K is the ﬁeld Q if K has characteristic 0,
while it is the ﬁeld Zp if K has characteristic p.
A5.2. Prove that the ﬁeld Zp(x) of rational functions over Zp is inﬁnite and has
characteristic p.
A5.3. Let A ⊆B be a ﬁeld extension and let b1, . . . , bn be elements of B. Prove
that A(b1, . . . , bn) consists exactly of the rational expressions in b1, . . . , bn with co-
eﬃcients in A, that is to say the elements of B of the form (5.1).
A5.4. Let A, B be rings with A ⊂B and let b1, . . . , bn be elements of B. Let
A[b1, . . . , bn] be the smallest subring of B containing A and b1, . . . , bn. Prove that
A[b1, . . . , bn] consists of all integral rational expressions in b1, . . . , bn with coeﬃcients
in A.
A5.5.* Let A, B, C be ﬁelds such that A ⊆B ⊆C, with [C : A] ﬁnite. Prove that
[B : A] and [C : B] are ﬁnite as well.
A5.6.* Verify the claim made in the proof of the theorem about the multiplicativity
of degrees: if {a1, . . . , an} is a basis of B as a vector space over A and {b1, . . . , bm} is a
basis of C as a vector space over B, then the elements aibj, i = 1, . . . , n, j = 1, . . . , m
form a basis of C as a vector space over A.
A5.7. Let A, B be rings with A ⊂B, and ﬁx b ∈B. Prove that the map vb : f(x) ∈
A[x] →f(b) ∈A(b) is a ring homomorphism.
A5.8.* Let A ⊆B be a ﬁeld extension, and let b ∈B be algebraic over A. Prove
that the minimal polynomial fb(x) ∈A[x] of b is irreducible or, equivalently, that
the ideal Ib generated by it is prime.

252
5 Finite ﬁelds and polynomial congruences
A5.9. Let A be an integral domain and let I be an ideal of A. Prove that I = A if
and only if 1 ∈I.
A5.10.* Let A be a commutative ring with unity. Prove that A is a ﬁeld if and only
if the only ideals of A are A and (0).
A5.11.* Given a ﬁeld A and an irreducible monic polynomial f(x) ∈A[x], deﬁne
B = A[x]/(f(x)). Verify that B is a ﬁeld and that a ∈A →a + (f(x)) ∈B is an
injective map. Identify A with its image and set c = x + (f(x)); then prove that
f(c) = 0 and that fc(x) = f(x).
A5.12. Prove Theorem 5.1.5.
A5.13.* Let A ⊆B a ﬁeld extension and let b1, . . . , bn elements of B. Prove that
b1, . . . , bn are algebraic over A if and only if [A(b1, . . . , bn) : A] is ﬁnite. Prove next
that if b1, . . . , bn are algebraic over A, then A(b1, . . . , bn) is algebraic over A.
A5.14.* Let A, B, C be ﬁelds such that A ⊆B ⊆C. Prove that if the extensions
A ⊂B and B ⊂C are algebraic, then the extension A ⊂C is algebraic too.
A5.15.* Let A ⊆B be a ﬁeld extension. Prove that the elements of B algebraic
over A form a subﬁeld C of B, which is an extension of A called algebraic closure of
A in B. Prove that C is algebraically closed in B, that is, its algebraic closure in B
is C itself.
A5.16.* Prove that if A ⊂B is a ﬁeld extension and if A is countable, then the
algebraic closure of A in B is countable (this result is sometimes called Cantor’s
theorem). Deduce that there are countably many algebraic numbers.
A5.17. Conclude the proof of Theorem 5.1.13.
A5.18. Prove that if q = pf and GCD(n, p) = 1, then the polynomial xn −1 has no
multiple roots over Fq.
A5.19. Let K be a ﬁeld, let f(x) = xn + a1xn−1 + · · · + an be a monic polyno-
mial of degree n and let α1, . . . , αn be its roots, each repeated as many times as
its multiplicity, considered as elements of the splitting ﬁeld of f(x). Consider the
polynomials over K, called elementary symmetric polynomials,
p1(x1, . . . , xn) =
n

i=1
xi,
p2 =

1≤i<j≤n
xixj,
. . . ,
pn = x1 · · · xn;
prove that for all i = 1, . . . , n we have
ai = (−1)ipi(α1, . . . , αn).
The Exercises A5.20–A5.23 deal with the set Rn of nth roots of unity.
A5.20. Verify that the set Rn of nth roots of unity is a subgroup of the multiplicative
group of the splitting ﬁeld F of the polynomial xn −1 over a prime ﬁeld K.
A5.21. Prove that ,
ξ∈Rn ξ = (−1)n+1.
A5.22. Let Rn be the set of nth roots of unity. Prove that 
ξ∈Rn ξ = 0.

A5 Theoretical exercises
253
A5.23. Given two positive integers n, m, prove that if m | n, then Rm ⊆Rn. Prove
that the converse holds as well, as long as the characteristic of the ﬁeld is 0 or does
not divide neither n nor m.
A5.24.* Prove that the element ξ = ξ1 · · · ξh in the proof of Proposition 5.1.16 has
order n.
A5.25. Prove Proposition 5.1.19.
A5.26. Prove that no ﬁnite ﬁeld is algebraically closed.
A5.27. Let A ⊆B be a ﬁeld extension and let B be algebraically closed. Prove that
the algebraic closure of A in B is an algebraic closure of A. Deduce that if A is ﬁnite
or countable (in particular, if A = Q), its algebraic closure is countable.
A5.28. Prove that the roots of the polynomial xpn −x over Zp, considered in its
splitting ﬁeld, form a ﬁeld. Deduce that the splitting ﬁeld of xpn −x consists exactly
of the roots of the polynomial xpn −x.
A5.29. Let F be a ﬁnite ﬁeld of characteristic p and let f = [F : Zp]. Prove that
every element of F is a root of the polynomial xpf −x.
A5.30.* Let F be a ﬁnite ﬁeld of order pf with p prime, and let F′ be a subﬁeld of
F of order pf′. Prove that F is the splitting ﬁeld over F′ of the polynomial gf,f′(x)
such that xpf −x = gf,f′(x)(xpf′
−x) (see Exercise A4.34 and the proof of Theorem
5.1.33).
A5.31.* Let F be a ﬁnite ﬁeld of order pf with p prime. Prove that, for all positive
integers m, the polynomial xpmf −x is divisible by all irreducible polynomials over
F of degree d | m and by no other polynomial, in particular not by the squares of
these polynomials.
A5.32.* Let p be a prime number and denote by nd,pf the number of irreducible
monic polynomials of degree d over Fpf . Prove the relation pmf = 
d|m dnd,pf . In
particular, if m is prime, nm,pf = (pmf −pf)/m.
A5.33.* Set q = pf and prove that
nd,q >
qd

1 −
1
q−d/2+1
 .
A5.34.* Let F be a ﬁnite ﬁeld of order pf with p prime, and let F′ be a subﬁeld of
order pf′. Describe the automorphism group of F ﬁxing every element of F′.
A5.35.* Let F be a ﬁnite ﬁeld of order pf, f ≥d. Let f(x) ∈Zp[x] be an irreducible
monic polynomial of degree d and let α ∈F be one of its roots. Prove that αpd = α
and that αpi, i = 0, . . . , d−1, are all its distinct roots. In particular, every irreducible
monic polynomial over Zp has distinct roots.
A5.36.* Prove that in the ring K[x]/(f(x)) every element can be represented
uniquely as a polynomial of degree smaller than f(x). (Hint: by induction on the
degree of a representative element.)

254
5 Finite ﬁelds and polynomial congruences
A5.37. Prove that every non-zero element of the ﬁeld F9 can be written as αj for
some integer j, where α is an element of F9 such that α2 = α + 1.
A5.38.* Prove that the computational complexity of performing the reduction in
row echelon form of a m × n (m ≤n) matrix with entries in a ﬁnite ﬁeld Fq using
Gaussian elimination (see [13], Cap. 8) is O(n3 log3 q).
A5.39.* Prove that the computational complexity of computing the determinant of
a square n × n matrix with entries in a ﬁnite ﬁeld Fq is O(n3 log3 q).
A5.40.* Prove that the computational complexity of computing the inverse of a
square s × s matrix with entries in a ﬁnite ﬁeld Fq is O(n3 log3 q).
A5.41.* Let f(x), g(x) be polynomials of degree at most d over the ﬁnite ﬁeld Fq.
Prove that the complexity of computing the greater common divisor of f(x) and
g(x) using the Euclidean algorithm is O(d3 log3 p).
A5.42. Let K be a ﬁeld of characteristic diﬀerent from 2. Let f(x) = ax2 + bx + c
be a polynomial of degree two. Prove that the roots of f(x) in the splitting ﬁeld of
f(x) are given by the formula (−b ±
√
b2 −4ac)/2a, called quadratic formula. Prove
that they are in K if and only if Δ = b2 −4ac, called discriminant of f(x), is a
square in K, that is, if and only if the equation x2 = Δ is soluble in K. Prove that
f(x) has two distinct roots if and only if Δ ̸= 0.
A5.43. Prove Lemma 5.2.18 on page 237.
A5.44. Prove Proposition 5.2.22 on page 239.
A5.45. Prove Corollary 5.2.23 on page 239.
A5.46. Let p be an odd prime. Prove that p
i=1( i
p) = p
i=0
 i
p
	
= p−1
i=1
 i
p
	
= 0.
In the following exercises we outline a proof of the law of quadratic reciprocity,
based on some properties of ﬁnite ﬁelds, diﬀerent from the one given in the main
text.
A5.47. Let n be an odd number. Prove that n2 ≡1 (mod 8).
A5.48.* Let p be a prime number. Prove that the ﬁeld Fp2 contains a primitive
eighth root ξ of unity.
A5.49.* Recall the deﬁnition of the function ϵ(n) = (−1)(n2−1)/8 (for odd n) given
in the proof of Proposition 5.2.35. Deﬁne G = 7
i=0 ϵ(i)ξi ∈Fp2 (the sum is over
odd values of i). Prove that G2 = 8 and deduce that Gp =
 2
p
	
G.
A5.50.* Following the previous exercise, prove by a direct computation that Gp =
ϵ(p)G and deduce Corollary 5.2.27.
A5.51. Let p and q be distinct odd primes. Prove that there exists a positive integer
f such that pf ≡1 (mod q). Deduce that the ﬁeld Fpf contains a primitive qth root
ξ of unity.
A5.52.* Following the previous exercise, deﬁne G = q−1
i=0
 i
q
	
ξi ∈Fpf . Prove by a
direct computation that Gp =
 p
q
	
G.
A5.53.* Following the previous exercises, prove that G2 = (−1)(q−1)/2q and deduce
that G ̸= 0.

B5 Computational exercises
255
A5.54.* Following the previous exercise, prove that Gp = (−1)(p−1)(q−1)/4 q
p
	
G
and deduce the law of quadratic reciprocity.
A5.55. Complete the proof of Proposition 5.2.34 on page 246.
A5.56. Let n be a positive odd integer number. Prove that the map a ∈Z∗
n →
 a
n
	
∈{1, −1} = Z∗
3 is well-deﬁned and is a group homomorphism.
A5.57. Let p be an odd number. Prove that for all positive integer α, we have
pα = (1 + (p −1))α ≡1 + α(p −1) (mod 4).
A5.58. For all positive odd integers n, set ϵ(n) = (−1)(n2−1)/8. Verify that for all
pairs (n, m) of positive odd integers, we have ϵ(nm) = ϵ(n)ϵ(m).
B5 Computational exercises
B5.1. Is there a ﬁeld of characteristic 91?
(a) Yes, because 91 is a prime number.
(b) No, because 91 is not a prime number.
(c) No, although 91 is a prime number.
(d) None of the above.
B5.2. Is there a ﬁeld of characteristic 997?
(a) Yes, because 997 is a prime number.
(b) No, because 997 is not a prime number.
(c) No, although 997 is a prime number.
(d) None of the above.
B5.3. Is there a ﬁeld consisting of 64 elements?
(a) Yes, because 64 is a prime power.
(b) No, because 64 is not a prime number.
(c) No, because 64 = 82 and 8 is not a prime number.
(d) None of the above.
B5.4. Is there a ﬁeld consisting of 323 elements?
(a) Yes, because 323 is a prime number.
(b) No, because 323 is not a prime number.
(c) No, although 323 is a prime number.
(d) None of the above.
B5.5. Write down the addition and multiplication tables of the elements of the ﬁeld
F8.
B5.6. Write down the addition and multiplication tables of the elements of the ﬁeld
F16.
B5.7. Write down the addition and multiplication tables of the elements of the ﬁeld
F9.
B5.8. Which is the fundamental subﬁeld of F32?

256
5 Finite ﬁelds and polynomial congruences
(a) Z2.
(b) F4.
(c) F16.
(d) F32.
B5.9. Verify that the multiplicative group F∗
4 = F4 \ {0} of the ﬁeld F4 is a cyclic
group. How many generators has F∗
4?
B5.10. Verify that the multiplicative group F∗
8 of the ﬁeld F8 is a cyclic group and
write down all its generators.
B5.11. Verify that the multiplicative group F∗
16 of the ﬁeld F16 is a cyclic group and
write down all its generators.
B5.12. How many generators has the multiplicative group F∗
9?
(a) 1.
(b) 2.
(c) 3.
(d) 4.
B5.13. Which is the degree of F16 as an extension of Z2?
(a) 1.
(b) 2.
(c) 4.
(d) 8.
B5.14. Prove that F4 is a subﬁeld of F16.
B5.15. Prove that (5.4) on page 225 is a factorisation into irreducible polynomials
over Z.
B5.16. Prove that (5.5) on page 225 is a factorisation into irreducible polynomials
over Z2.
B5.17. Prove that (5.6) on page 226 is a factorisation into irreducible polynomials
over Q.
B5.18. Prove that (5.7) on page 226 is a factorisation into irreducible polynomials
over Z2.
B5.19. Prove that (5.8) on page 226 is a factorisation into irreducible polynomials
over Z3.
B5.20. How many irreducible polynomials of fourth degree are there in Z2[x]?
(a) 1.
(b) 2.
(c) 3.
(d) 4.
B5.21. Is x4 + x2 + 1 irreducible over Z2?
(a) Yes.

B5 Computational exercises
257
(b) No, as it factors into a degree two polynomial and a degree three one.
(c) No, as it factors into four ﬁrst degree polynomials.
(d) No, as it factors into two degree two polynomials.
B5.22. How many irreducible factors has x27 −x over Z?
(a) 5.
(b) 7.
(c) 9.
(d) 10.
B5.23. How many irreducible factors has x25 −x over Z5?
(a) 8.
(b) 10.
(c) 12.
(d) 15.
B5.24. How many degree two irreducible polynomials are there in Z3[x]?
(a) 2.
(b) 3.
(c) 4.
(d) 6.
B5.25. How many irreducible factors has x27 −x over Z3?
(a) 5.
(b) 7.
(c) 9.
(d) 11.
B5.26. How many irreducible factors has x27 −x over Z9?
B5.27. Is it true that F25 is a subﬁeld of F125?
(a) No.
(b) Yes, as it is its fundamental subﬁeld.
(c) Yes, as 25 divides 125.
(d) None of the above.
B5.28. How many proper (i.e., strictly included) subﬁelds has F125, up to isomor-
phism?
(a) 1.
(b) 2.
(c) 3.
(d) 5.
B5.29. Is it true that F9 is a subﬁeld of F27?
(a) Yes, as it is its fundamental subﬁeld.
(b) Yes, as 9 divides 27.

258
5 Finite ﬁelds and polynomial congruences
(c) No.
(d) None of the above.
B5.30. How many proper (i.e., strictly included) subﬁelds has F32, up to isomor-
phism?
(a) 1.
(b) 2.
(c) 3.
(d) 5.
B5.31. Write all automorphisms of F4, F8 e F16.
B5.32. Write all automorphisms of F9.
B5.33. Write all irreducible monic polynomials of degree d ≤6 over Z2.
B5.34. Write all irreducible monic polynomials of degree 3 over Z3.
B5.35. Write all irreducible monic polynomials of degree d ≤3 over Z4.
B5.36. Write all irreducible monic polynomials of degree d ≤3 over Z9.
B5.37. Solve all quadratic equations over Zp, p = 2, 3, 5.
B5.38. Solve the congruence of Example 5.2.3 on page 230 by evaluating x3+2x2−1
modulo 10 for all x with −4 ≤x ≤5.
B5.39. Solve the congruence of Example 5.2.4 on page 231.
B5.40. Prove that the congruence x3 + 3x + 2 ≡0 (mod 7) has no solutions (see
Example 5.2.7 on page 232).
B5.41. Prove that the congruence x2 ≡p (mod 5) admits solutions if and only if
p ≡1 (mod 5) or p ≡−1 (mod 5).
B5.42. Prove that the congruence x2 ≡2 (mod 15) has no solutions.
B5.43. How many solutions has the congruence x2 −3x −1 ≡0 (mod 7)?
(a) 0.
(b) 1.
(c) 2.
(d) 3.
B5.44. How many solutions has the congruence x2 −3x −4 ≡0 (mod 14)?
(a) 0.
(b) 1.
(c) 2.
(d) 4.
B5.45. How many solutions has the congruence x2 −2x + 1 ≡0 (mod 8)?
(a) 0.
(b) 1.
(c) 2.
(d) 4.

B5 Computational exercises
259
B5.46. How many solutions has the congruence x3 + 5x −4 ≡0 (mod 11)?
(a) 0.
(b) 1.
(c) 2.
(d) 3.
B5.47. How many solutions has the congruence x4 −x3 −1 ≡0 (mod 49)?
(a) 0.
(b) 1.
(c) 2.
(d) 4.
B5.48. Which is the value of the Legendre symbol
 95
11
	
?
(a) 0.
(b) 1.
(c) −1.
(d) None of the above.
B5.49. Which is the value of the Legendre symbol
 65
13
	
?
(a) 0.
(b) 1.
(c) −1.
(d) None of the above.
B5.50. Which is the value of the Legendre symbol
 271
143
	
?
(a) 0.
(b) 1.
(c) −1.
(d) None of the above.
B5.51. Which is the value of the Legendre symbol
 1001
971
	
?
(a) 0.
(b) 1.
(c) −1.
(d) None of the above.
B5.52. Which is the value of the Jacobi symbol
 41
35
	
?
(a) 0.
(b) 1.
(c) −1.
(d) None of the above.

260
5 Finite ﬁelds and polynomial congruences
B5.53. Which is the value of the Jacobi symbol
 105
91
	
?
(a) 0.
(b) 1.
(c) −1.
(d) None of the above.
B5.54. Which is the value of the Jacobi symbol
 1003
973
	
?
(a) 0.
(b) 1.
(c) −1.
(d) None of the above.
C5 Programming exercises
C5.1. Write a program that writes out the addition and multiplication tables of the
ﬁeld Fq, with q = ph, for a prime number p and a positive integer h.
C5.2. Write a program that ﬁnds a generator of the multiplicative group F∗
q of the
ﬁeld Fq.
C5.3. Write a program that solves a polynomial congruence (linear or not) by trial
and error.
C5.4. Write a program that solves a polynomial congruence using the method de-
scribed in Section 5.2 (see Proposition 5.2.9).
C5.5. Write a program that computes the Legendre symbol
 a
p
	
, where a is an
integer and p is an odd prime.
C5.6. Write a program that computes the Jacobi symbol
 a
n
	
, where a is an integer
and n is an odd positive integer.
C5.7. Write a program that determines all the irreducible polynomials of degree d
over Zp, for a prime p and a positive integer d.
C5.8. Write a program that ﬁnds a quadratic residue or a quadratic non-residue
modulo a prime p using the probabilistic algorithm described in Remark 5.2.44.
C5.9. Write a program that ﬁnds a square root in Zp using the algorithm described
in § 5.2.6.

6
Primality and factorisation tests
In this chapter we shall discuss primality tests and factorisation methods. The
former are used to check whether a given number is prime or not, the latter
to decompose a given number into prime factors. We shall encounter again a
probabilistic approach, already mentioned in Chapter 5.
6.1 Pseudoprime numbers and probabilistic tests
In Chapter 4 we saw some naive primality tests relying upon Fermat’s little
theorem and Wilson’s theorem (see Section 4.2.2 and Section 4.2.3). Those
tests are not computationally eﬃcient, as they are exponential. Nevertheless,
as we shall see, it is useful to investigate further the analysis of the test based
upon Fermat’s little theorem.
6.1.1 Pseudoprime numbers
The test based upon Fermat’s little theorem 4.2.5 can be used to verify if
a given number n is not a prime. So, given n > 2, which obviously is not
an even number, otherwise clearly it is not prime, we begin by applying the
test described in Section 4.2.2 by computing, for instance, 2n−1 (mod n). If
2n−1 ̸≡1 (mod n) we are sure that n is not a prime, as we know, by Fermat’s
little theorem, that if n is a prime, then for all integers a that are coprime
with n:
an−1 ≡1
(mod n).
(6.1)
But what may we conclude if 2n−1 ≡1 (mod n)? May we say that n is a
prime number? More in general, we may ask: is it suﬃcient to ﬁnd an integer
a that is coprime with n and such that (6.1) holds, in order to claim that n is
prime?
The answer to this question is no, as the following example shows.

262
6 Primality and factorisation tests
Example 6.1.1. The number 91 = 7·13 is not a prime, but 390 ≡1 (mod 91).
Indeed, it suﬃces to verify that
390 ≡1
(mod 7)
and
390 ≡1
(mod 13).
(6.2)
Fermat’s little theorem guarantees that 36 ≡1 (mod 7) and, as 90 = 6·15, we
immediately get the ﬁrst part of (6.2). The second one is veriﬁed analogously
and is left to the reader (see Exercise B6.1).
Notice that, on the other hand, 290 ̸≡1 (mod 91) (see Exercise B6.4);
hence, if we had not already known 91 not to be a prime, we would have
discovered it by applying to it the Fermat test described in § 4.2.2, with
respect to the integer a = 2.
These remarks justify the following deﬁnition.
Deﬁnition 6.1.2. If n is an odd, non-prime number and a is an integer rela-
tively prime with n, then n is said to be a pseudoprime in base a if an−1 ≡1
(mod n).
For instance, n = 91 is a pseudoprime in base 3 but not in base 2.
An important question is, how many pseudoprimes are there in a given base
a? If we knew they to be ﬁnitely many and we were able to compute them all,
we could apply Fermat’s little theorem to determine an eﬃcient polynomial
primality test. Unfortunately, this is not how things go: for instance, there are
inﬁnitely many pseudoprimes in base 2 (see Exercise A6.1). Nevertheless, it
is interesting to be aware of the following proposition.
Proposition 6.1.3. Let n > 1 a non-prime odd number.
(a) If n is pseudoprime in the bases a1 and a2 such that GCD(a1, n) = 1
and GCD(a2, n) = 1, then n is pseudoprime in the bases a1a2 and a1a−1
2 ,
where a−1
2
is the inverse of a2 modulo n.
(b) If there exists an integer a, with 1 < a < n and GCD(a, n) = 1, such that
n is not a pseudoprime in base a, then n is not a pseudoprime in base b for
at least one half of the values of b such that 1 < b < n and GCD(b, n) = 1.
Proof. The proof of (a) is left as an exercise (see Exercise A6.3). We prove
now (b).
Consider a as an element of U(Zn). Let P the subset of U(Zn) consisting
of the classes whose remainder b modulo n is such that n is pseudoprime in
base b. Keeping in mind (a), it is clear that if b ∈P then ab /∈P. So there
is an injective map f : b ∈P →ab ∈U(Zn) \ P. So the order of P equals at
most the order of U(Zn) \ P. This proves (b).
⊓⊔

6.1 Pseudoprime numbers and probabilistic tests
263
6.1.2 Probabilistic tests and deterministic tests
The previous proposition is the base for a quite eﬃcient primality test of
a completely new kind, that is, a probabilistic test. The diﬀerence between
probabilistic and deterministic tests, the ones we have encountered so far, is
similar to the diﬀerence between probabilistic and deterministic algorithms,
discussed in Remark 5.2.44. Indeed, deterministic tests are designed to deter-
mine with certainty whether a number is prime or not. On the other hand,
probabilistic tests T consist of a sequence of tests {Tm}m∈N, for which there
is a sequence {ϵm}m∈N converging to 0 of positive real numbers smaller than
1, such that if a positive integer number n does not pass a test Tm then it is
not prime, while the probability that a positive integer number n passes tests
T1, . . . , Tm and is not a prime is smaller than ϵm.
So a probabilistic test does not give the certainty that a number passing
the test is prime. However, especially if the sequence {ϵm}m∈N converges to 0
very quickly, for instance if ϵm = 1/2m, the probability that a number passing
the tests T1, . . . , Tm is not prime is extremely low, even for a small value of
m, that is, after just a few steps.
It is true that deterministic tests, like the sieve of Eratosthenes or the test
based on Wilson’s theorem, give in principle a reliable answer to the question
whether a given number is prime or not. However, as we have seen, they
are often so computationally expensive to be useless. On the contrary, some
probabilistic tests are computationally very eﬃcient.
6.1.3 A ﬁrst probabilistic primality test
The probabilistic test T we are about to discuss works as follows. Fix an odd
integer n > 1. The test T1 consists of the following steps:
(1) choose randomly an integer a1 with 1 < a1 < n and compute GCD(a1, n);
(2) if GCD(a1, n) > 1 then n is not prime, and the test is over;
(3) if GCD(a1, n) = 1 and condition (6.1) with a = a1 does not hold, then n
is not prime, and the test is over;
(4) otherwise, apply test T2 to n.
Deﬁne next recursively test Tm as follows:
(1) choose randomly an integer am such that 1 < am < n with am diﬀerent
from a1, . . . , am−1, and compute GCD(am, n);
(2) if GCD(am, n) > 1 then n is not prime, and the test is over;
(3) if GCD(am, n) = 1 and condition (6.1) with a = am does not hold, then
n is not prime, and the test is over;
(4) otherwise, apply test Tm+1 to n.

264
6 Primality and factorisation tests
Now assume the following hypothesis, which we shall call hypothesis H:
if n is not prime, there is an a, with 1 < a < n, relatively
prime with n, such that n is not a pseudoprime in base a.
If this is veriﬁed, then by (b) of Proposition 6.1.3, when we perform test
Tm, the probability of n being a pseudoprime in base am is smaller than
1/2. So the probability of n not being a prime but passing tests T1, . . . , Tm is
smaller than 1/2m.
Remark 6.1.4. Notice that, if n is ﬁxed, the number of tests Tm we have to
perform is ﬁnite, equal to ϕ(n). However, if n is very large, we might not want
to perform all the ϕ(n) tests of the sequence. Indeed, after the ﬁrst, say, 50
steps a number n successfully got through we may claim that, with a good
degree of probability, n is prime.
Notice that the complexity of each test Tm is polynomial. Indeed, after hav-
ing randomly chosen a number a with 1 < a < n, verifying that GCD(a, n) = 1
has polynomial complexity O(log3 n) (see Proposition 2.5.4). Moreover, the
third step of test Tm has complexity O(log3 n) too (see Section 3.3.1).
In conclusion, if hypothesis H holds and we want to ascertain whether
n is prime with a probability greater or equal than (250 −1)/250, the test’s
computational cost is O(log3 n).
6.1.4 Carmichael numbers
For the above probabilistic test to be meaningful it is necessary that hypoth-
esis H holds. Unfortunately, this hypothesis is not true. However, we shall
shortly see that by exploiting ideas that are very similar to those leading to
the above test it is possible to devise sound probabilistic primality tests.
Let us give a deﬁnition which is useful to elucidate the state of things
about hypothesis H.
Deﬁnition 6.1.5. If n is an non-prime odd number that is pseudoprime in
base a for all a such that 1 < a < n and GCD(a, n) = 1, then n is said to be
a Carmichael number.
So, if Carmichael numbers exist, hypothesis H does not hold. And such
numbers do exist, as we shall see, although not much is known about them.
Recently it has been proved that there are inﬁnitely many Carmichael numbers
(see [3]).
The following proposition contains a very important information about
Carmichael numbers.
Proposition 6.1.6. Let n > 1 be a non-prime odd number.
(a) If n is divisible by a square greater than 1, then n is not a Carmichael
number.

6.1 Pseudoprime numbers and probabilistic tests
265
(b) If n is not divisible by a square greater than 1, then n is a Carmichael
number if and only if p −1 divides n −1 for every prime factor p of n.
Proof. We shall prove here just a part of (b): the fact that if n is not divisible
by a square greater than 1 and if p −1 divides n −1 for every prime factor p
of n, then n is a Carmichael number. The remaining claims will be proved in
Section 6.2.
By hypothesis we have n = p1 · · · ph with p1, . . . , ph distinct primes. Let a
be an integer such that 1 < a < n and GCD(a, n) = 1, so also GCD(a, pi) =
1, i = 1, . . . , h. By Fermat’s little theorem we have api−1 ≡1 (mod pi),
i = 1, . . . , h. As pi −1 | n −1, i = 1, . . . , h, we also have an−1 ≡1 (mod pi),
i = 1, . . . , h; hence an−1 ≡1 (mod n).
⊓⊔
For instance, 561 = 3 · 11 · 17 is a Carmichael number, as 560 is divisible
by 3 −1, 11 −1, 17 −1.
Proposition 6.1.7. Every Carmichael number is a product of at least three
distinct primes.
Proof. By part (a) of Proposition 6.1.6 we know that every Carmichael
number is a product of distinct primes. Assume by contradiction that n = pq
is a Carmichael number that is a product of exactly two distinct primes,
with p < q. Again by Proposition 6.1.6, part (b), we know that n −1 ≡0
(mod q −1). But
n −1 = p(q −1 + 1) −1 = p(q −1) + p −1 ≡p −1
(mod q −1);
on the other hand, p −1 ̸≡0 (mod q −1), as 0 < p −1 < q −1. So we have
reached a contradiction.
⊓⊔
Keeping this result in mind, it is easy to see that 561 is the smallest
Carmichael number (see Exercise B6.8).
6.1.5 Euler pseudoprimes
Euler’s criterion 5.2.19, or equivalently part (3) of Proposition 5.2.22 may also
be used as a primality test, to verify that an odd number is not prime. Indeed,
if there is an a such that
a
n
 
̸≡a(n−1)/2
(mod n), then n is not a prime.
For instance, n = 15 is not prime because 27 = 128 ≡8 (mod 15), while
 2
15
	
= 1 (see (5.31) on page 246).
Analogously to Deﬁnition 6.1.2 of pseudoprime numbers, we may give the
following deﬁnition.

266
6 Primality and factorisation tests
Deﬁnition 6.1.8. Let b be an integer number. A non-prime odd positive in-
teger n such that GCD(n, b) = 1 is said to be an Euler pseudoprime in base b
if
b(n−1)/2 ≡
 b
n

(mod n).
(6.3)
This deﬁnition is related to Deﬁnition 6.1.2 as follows.
Lemma 6.1.9. If n is an Euler pseudoprime in base b, then n is also a pseu-
doprime in base b.
Proof. By squaring both sides of (6.3), we ﬁnd bn−1 ≡
 b
n
	2 = 1 (mod n).
⊓⊔
We explicitly remark that the converse of Lemma 6.1.9 does not hold. In-
deed, for instance, 91 is a pseudoprime in base 3, but not an Euler pseudoprime
in base 3 (see Exercise B6.14).
We may further remark that every odd number is an Euler pseudoprime
in base b = ±1; for this reason, from now on we shall exclude b = ±1 from
the bases of Euler pseudoprimes.
The probabilistic test of Section 6.1.3 relies upon two premises:
•
the hope – unfounded, as we have seen – of hypothesis H being true;
•
part (b) of Proposition 6.1.3, which says that, if hypothesis H holds, then
if a number n is not prime, the bases a in which it is pseudoprime, with
1 < a < n, are at most ϕ(n)/2.
In the case of Euler pseudoprimes we are in a better position. Indeed,
the analogue of hypothesis H is always veriﬁed and the analogue of (b) of
Proposition 6.1.3 holds too. More precisely, the following holds.
Proposition 6.1.10. Let n be a non-prime odd, positive integer. The positive
numbers b < n coprime with n, such that (6.3) holds, that is, such that n is
an Euler pseudoprime in base b, are at most half of all positive numbers b < n
such that GCD(b, n) = 1.
The proof needs several steps. The ﬁrst one is the following proposition,
which is the analogue of (a) of Proposition 6.1.3: its easy proof is left as an
exercise to the reader (see Exercise A6.5).
Proposition 6.1.11. Let n > 1 be a non-prime odd number. If n is an Euler
pseudoprime in bases b1 and b2 such that GCD(b1, n) = GCD(b2, n) = 1,
then n is pseudoprime in bases b1b2 and b1b−1
2 , where b−1
2
is the inverse of b2
modulo n.
We prove next:
Lemma 6.1.12. Let n > 1 be an odd number that is not a perfect square.
Then there is a positive integer b < n, relatively prime with n, such that
 b
n
	
= −1.

6.1 Pseudoprime numbers and probabilistic tests
267
Proof. If n is prime, the claim is obvious, as quadratic non-residues modulo
n are known to exist.
If n is not a prime, there exists a prime factor p of n appearing in the fac-
torisation of n with an odd exponent e. Write n = pem. Let t be a quadratic
non-residue modulo p. By the Chinese remainder theorem, there exists a pos-
itive number b relatively prime with n and smaller than n such that
b ≡t
(mod p),
b ≡1
(mod m).
So we have
 b
n

=
 b
p
e  b
m

= (−1)e = −1.
⊓⊔
The key step in the proof of Proposition 6.1.10 is the following proposition
which, basically, guarantees that for Euler pseudoprimes there is no analogue
of Carmichael numbers:
Proposition 6.1.13. Let n > 1 be a non-prime odd number. Then there is a
positive integer number b < n that is coprime with n and such that n is not
an Euler pseudoprime in base b.
Proof. If the claim were false, by Lemma 6.1.9, n would be a Carmichael
number. By Proposition 6.1.6, then, we have n = p1 · · · ph with p1, . . . , ph
distinct primes.
We prove now that for every positive integer b < n coprime with n the
following holds:
 b
n

≡b(n−1)/2 ≡1
(mod n).
(6.4)
This will contradict Lemma 6.1.12, thus proving the present Proposition.
As we are supposing the claim not to be true, n is an Euler pseudoprime
with respect to every base b, with b a positive integer smaller than n and
coprime with n. So, for every such integer b (6.3) holds.
Assume the existence of a positive integer b < n coprime with n such that
b(n−1)/2 ̸≡1 (mod n); then we must have b(n−1)/2 ≡−1 (mod n). By the
Chinese remainder theorem, we may ﬁnd a positive integer a < n, coprime
with n and such that
a ≡b
(mod p1),
a ≡1
(mod p2 · · · ph).
Then we have
a(n−1)/2 ≡b(n−1)/2 ≡−1
(mod p1)
and
a(n−1)/2 ≡1
(mod p2 · · · ph).
Thus
a(n−1)/2 ̸≡±1
(mod n),
but this yields a contradiction, as (6.3) must hold in particular for b = a.
⊓⊔

268
6 Primality and factorisation tests
Now it is easy to conclude the proof of Proposition 6.1.10: it suﬃces to
argue in a pretty similar way to what has been done in the proof of part (b)
of Proposition 6.1.3. We leave the details as an exercise for the reader (see
Exercise A6.6).
6.1.6 The Solovay–Strassen probabilistic primality test
The Solovay–Strassen probabilistic primality test T relies on the notions dis-
cussed in the previous section about Euler pseudoprimes. It is pretty analogous
to the test described in § 6.1.3, as follows.
Fix an odd integer n > 1. The test T1 consists of the following steps:
1. choose randomly an integer b1 with 1 < b1 < n, and compute GCD(b1, n);
2. if GCD(b1, n) > 1 then n is not prime, and the test is over;
3. if GCD(b1, n) = 1 and condition (6.3) with b = b1 does not hold, then n is
not prime, and the test is over;
4. otherwise, apply test T2 to n.
Deﬁne next recursively test Tm as follows:
1. choose randomly an integer bm such that 1 < bm < n with bm diﬀerent
from b1, . . . , bm−1, and compute GCD(bm, n);
2. if GCD(bm, n) > 1 then n is not prime, and the test is over;
3. if GCD(bm, n) = 1 and condition (6.3) with b = bm does not hold, then n
is not prime, and the test is over;
4. otherwise, apply test Tm+1 to n.
Keeping in mind Proposition 6.1.10, when we perform test Tm, the prob-
ability that n is a pseudoprime in base bm is smaller than 1/2. So, the prob-
ability that n passes tests T1, . . . , Tm without being a prime is smaller than
1/2m.
Remark 6.1.14. Similar comments to those given in Remark 6.1.4 hold here
as well. In particular, the complexity of each test Tm is polynomial. In-
deed, having chosen randomly a number a with 1 < a < n, verifying that
GCD(a, n) = 1 has polynomial complexity O(log3 n) (see Proposition 2.5.4).
Moreover, the third step of test Tm also has complexity O(log3 n) (see Section
3.3.1 and Remark 5.2.37).
6.1.7 Strong pseudoprimes
Solovay–Strassen test can be improved. This improvement relies on the fol-
lowing remark.

6.1 Pseudoprime numbers and probabilistic tests
269
Remark 6.1.15. Let n be an odd positive integer and b < n a positive integer
such that GCD(b, n) = 1. Let n be a pseudoprime in base b, that is,
bn−1 ≡1
(mod n).
If n is prime, we must have
b(n−1)/2 ≡±1
(mod n),
(6.5)
as in Zp the only square roots of 1 are ±1. Iterating, if
b(n−1)/2 ≡1
(mod n)
and if (n −1)/2 is even, we must have
b(n−1)/4 ≡±1
(mod n)
and so forth.
This remark motivates the following deﬁnition.
Deﬁnition 6.1.16. Let n be a non-prime odd positive integer and b < n a
positive integer such that GCD(b, n) = 1. Set n = 2st + 1, with odd t. The
number n is said to be a strong pseudoprime in base b if one of the following
conditions holds: either
bt ≡1
(mod n),
or there exists a non-negative integer r < s such that
b2rt ≡−1
(mod n).
Example 6.1.17. The number n = 25 is a strongpseudoprime for the base
b = 7. Indeed, 72 = 49 ≡−1 (mod 25) and so 712 = 7(n−1)/2 ≡1 (mod 25).
It is easy to verify that n = 2047 is a strong pseudoprime in base 2:
actually, it is possible to verify that this is the smallest strong pseudoprime
in base 2 (see [46]). Notice that (n −1)/2 = 2046/2 = 1023 = 11 · 93. Now,
211 = 2048 ≡1 (mod 2047), and so 22046 ≡1 (mod 2047).
It is clear that a strong pseudoprime in base b is a pseudoprime in base
b as well (see Exercise A6.7). But how are strong pseudoprimes and Euler
pseudoprimes related? The answer is given by the following two propositions.
Proposition 6.1.18. Let n be an odd positive integer and b < n a positive
integer such that GCD(b, n) = 1. If n ≡3 (mod 4) then n is a strong pseudo-
prime in base b if and only if n is an Euler pseudoprime in base b.
Proof. In this case, keeping the notation of Deﬁnition (6.1.16), as n ≡3
(mod 4), s must be equal to 1. So n is a strong pseudoprime in base b if and
only of (6.5) holds.

270
6 Primality and factorisation tests
Now, if n is an Euler pseudoprime in base b, then
b(n−1)/2 ≡
 b
n

= ±1
(mod n),
that is, (6.5) holds and n is a strong pseudoprime in base b. Conversely, let n
be a strong pseudoprime in base b. As n ≡3 (mod 4), we have
±1
n

= ±1
and so
 b
n

=

b · b2(n−3)/4
n

=
b(n−1)/2
n

=
±1
n

= ±1 ≡b(n−1)/2
(mod n),
proving that n is an Euler pseudoprime in base b.
⊓⊔
Proposition 6.1.19. Let n be an odd positive integer and b < n a positive
integer such that GCD(b, n) = 1. If n is a strong pseudoprime in base b then
n is an Euler pseudoprime in base b.
Proof. Keeping the notation of Deﬁnition 6.1.16, consider ﬁrst the case in
which bt ≡1 (mod n). Let p be a prime divisor of n. Then we have bt ≡1
(mod p), and so Gss(p, b) | t. As t is odd, we ﬁnd that Gss(p, b) is too. On the
other hand, Gss(p, b) | ϕ(p) = p−1 and so Gss(p, b) | (p −1)/2. So b(p−1)/2 ≡1
(mod p) and Euler’s criterion implies that
 b
p
	
= 1. Hence
 b
n
	
= 1. On the
other hand, b(n−1)/2 = (bt)2s ≡1 (mod n) and so (6.3) holds, that is n is an
Euler pseudoprime in base b.
Consider now the case in which there exists a non-negative integer r < s
such that b2rt ≡−1 (mod n). Let p be a prime divisor of n. We have b2rt ≡−1
(mod p) and so b2r+1t ≡1 (mod p); hence Gss(p, b) | 2r+1t but Gss(p, b) ∤2rt.
So Gss(p, b) = 2r+1s where s is an odd number. As Gss(p, b) | p −1, we have
2r+1 | p −1, that is, p = 2r+1q + 1. Hence
 b
p

≡b
p−1
2
= b
Gss(p,b)
2
p−1
Gss(p,b) ≡(−1)
p−1
Gss(p,b) = (−1)
q
s
(mod p).
In conclusion, as s is odd, we have
 b
p

= (−1)q.
(6.6)
Let now n = ph1
1 · · · phm
m
be the factorisation of n. Set pi = 2r+1di + 1,
i = 1, . . . , m. Then we have
n =
m
'
i=1
(2r+1di + 1)hi ≡
m
'
i=1
(1 + 2r+1hidi) ≡1 + 2r+1
m

i=1
hidi
(mod 2r+2).

6.1 Pseudoprime numbers and probabilistic tests
271
So
2s−1t = (n −1)/2 ≡2r
m

i=1
hidi
(mod 2r+1);
from this follows
2s−r−1t ≡
m

i=1
hidi
(mod 2).
(6.7)
Now, if r < s −1, we have
b(n−1)/2 = b2s−1t = (b2rt)2s−r−1 ≡(−1)2s−r−1 = 1
(mod n).
From (6.7) we deduce that m
i=1 hidi is even and, keeping in mind (6.6), we
obtain
 b
n

=
m
'
i=1
 b
pi
hi
=
m
'
i=1
(−1)dihi = (−1)
 m
i=1 dihi = 1.
So in this case (6.3) holds, that is, n is an Euler pseudoprime in base b.
The case r = s −1 is pretty analogous and is left as an exercise for the
reader (see Exercise A6.9).
⊓⊔
The results of Propositions 6.1.18 and 6.1.19 are described by the following
diagram, where PS (or SPS, EPS, respectively) stays for pseudoprime (strong
pseudoprime, Euler pseudoprime, respectively):
EPS
(∗)
PS
SPS
where (∗) means that the implication holds only if n ≡3 (mod 4).
In the light of the previous proposition we may expect strong pseudoprimes
to be, in a sense, even less numerous than Euler pseudoprimes. This is true,
although there still are many of them (see Exercise A6.8).
The ﬁrst strong pseudoprime in base 2 is 2047. We give the table, originally
in [46], with data about the number of pseudoprimes and strong pseudoprimes
in base 2. Let Ps(n) the number of pseudoprimes in base 2 smaller than n, and
Sps(n) the number of strong pseudoprimes in base 2 smaller than n. Then:
n
Ps(n)
Sps(n)
103
3
0
106
245
46
109
5597
1282
25 · 109
21853
4842
This table conﬁrms the already mentioned fact that we expect strong pseu-
doprimes to be far less numerous than pseudoprimes.
This expectation is given a precise meaning by the following proposition,
which will be proved in Section 6.2.2:

272
6 Primality and factorisation tests
Proposition 6.1.20. Let n be a non-prime odd positive integer. The positive
numbers b < n such that GCD(b, n) = 1 and n is a strong pseudoprime in base
b are at most a quarter of all positive numbers b < n such that GCD(b, n) = 1.
6.1.8 The Miller–Rabin probabilistic primality test
Proposition 6.1.20 is the foundation for the Miller–Rabin probabilistic primal-
ity test T .
Fix an odd integer n > 1. Write n = 2st + 1 with odd t. The test T1
consists of the following steps:
1. choose randomly an integer b1 with 1 < b1 < n, and compute GCD(b1, n);
2. if GCD(b1, n) > 1 then n is not prime, and the test is over;
3. if GCD(b1, n) = 1 compute bt
1 modulo n. If bt
1 ≡±1 (mod n), either n is
prime or it is a strong pseudoprime in base b1;
4. if bt
1 ̸≡±1 (mod n), compute b2t
1 modulo n. If b2t
1 ≡−1 (mod n), then
either n is prime or it is a strong pseudoprime in base b1;
5. if b2t
1 ̸≡−1 (mod n) proceed as above. If all the successive powers b2rt
1 , for
r = 1, . . . , s −1, are never congruent to −1 modulo n, then, by Remark
6.1.15, n is not a prime. Otherwise, n is a strong pseudoprime in base b1.
The test Tm is deﬁned recursively in a similar way:
1. choose randomly an integer bm such that 1 < bm < n with bm diﬀerent
from b1, . . . , bm−1, and compute GCD(bm, n);
2. if GCD(bm, n) > 1 then n is not prime, and the test is over;
3. if GCD(bm, n) = 1, compute bt
m modulo n and proceed as from step (3)
of T1 on. Either n is found to be non-prime or n is a strong pseudoprime
with respect to bm.
Keeping in mind Proposition 6.1.20, when we perform the test Tm, the
probability of n not being a prime while being a strong pseudoprime in base bm
is smaller than 1/4. So, the probability of n passing tests T1, . . . , Tm without
being a prime is smaller than 1/4m.
Remark 6.1.21. Miller–Rabin test is even better than Solovay–Strassen test.
In practice, it is not necessary to take too large a value of m to be almost
certain that n is prime if it passes tests T1, . . . , Tm. For instance, it has been
veriﬁed that the only strong pseudoprime in base 2, 3, 5 and 7 smaller than
2.5 · 1010 is n = 3215031751.
It is not diﬃcult to verify that the complexity of Miller–Rabin algorithm
is O(k log4 n), where k is the number of times the test is repeated (see Ex-
ercise A6.11). Thus, if we ﬁx k, we have a probabilistic primality test with
polynomial complexity. So we might get the idea of using Miller–Rabin algo-
rithm as a deterministic test, by trying out all the values of b with 1 < b < n,
GCD(b, n) = 1. Unfortunately, the complexity becomes O(n log4 n), that is
exponential, and so it is computationally unfeasible.

6.2 Primitive roots
273
In order to be able to use Miller–Rabin algorithm to get a polynomial
deterministic test, we would have to know that if n > 0 is a non-prime odd
number, then n does not pass Miller–Rabin test for at least one value of b and
to have an eﬃcient estimate for such a b, that is, it would be necessary to know
that b is small with respect to n, i.e., b must be O(logh n) with h a constant.
It is conjectured that such an estimate actually exists and that b is O(log2 n).
This is a consequence of the so-called generalised Riemann hypothesis.
The classic Riemann hypothesis is a conjecture about the zeros of Riemann
zeta function, which is obtained by analytic continuation to the complex ﬁeld
of the function ζ(s) = ∞
n=0 1/ns, deﬁned for s > 1, considered in this book
in Section 4.1.2 (see [59]).
The generalised Riemann hypothesis is an analogous conjecture about the
zeros of similar, more general functions, called Dirichlet L-series. Unfortu-
nately, neither the classic Riemann hypothesis and even less so the gener-
alised one, have been proved. In fact, their solution is among the greatest
open problems in mathematics.
6.2 Primitive roots
The notions discussed in this section will help, as we shall see, in dealing compu-
tationally with arithmetic modulo n. In order to do so, we shall investigate further
the group U(Zn) for an arbitrary positive integer n. This will enable us to prove
some results already mentioned and used in the previous sections. In this section we
shall often use basic properties of cyclic groups recalled in Exercises A3.23-A3.35,
and the notion of Gaussian and its properties (see Exercises A4.30 and B4.20).
Notice that if n is prime, Zn is a ﬁeld and the structure of U(Zn) is made clear
in Theorem 5.1.30: this group is cyclic of order n −1. Recall further that, for all n,
U(Zn) has order ϕ(n).
Deﬁnition 6.2.1. Let n, r be positive integers such that GCD(r, n) = 1. Then r is
said to be a primitive root modulo n if Gss(n, r) = ϕ(n), that is, if U(Zn) is a cyclic
group and if the residue class of r modulo n is a generator of the group. Then we
also say that r is a generator of U(Zn).
Example 6.2.2. As already recalled, there is always a primitive root modulo a
prime number. As Gss(4, 3) = 2 = ϕ(4), we have that 3 is a primitive root modulo
4.
However, there are integers for which there are no primitive roots. For instance,
there are no primitive roots modulo 8, as
Gss(8, 1) = 1,
Gss(8, 3) = 2,
Gss(8, 5) = 2,
Gss(8, 7) = 2.
Remark 6.2.3. If r is a primitive root modulo n, then there are ϕ(ϕ(n)) primitive
roots modulo n (see Exercise A3.30). They can be obtained by taking the powers
rm, with GCD(m, ϕ(n)) = 1.

274
6 Primality and factorisation tests
Knowing that a primitive root r modulo n exists and eﬀectively ﬁnding it is
important, as this makes arithmetic modulo n much less computationally expensive.
For instance, multiplying two elements of U(Zn), both expressed as powers of r, just
amounts to summing their exponents.
The following theorem gives a complete answer to the basic problem of ﬁnding
all integers n such that a primitive root modulo n exists.
Theorem 6.2.4. Let n be a positive integer number. A primitive root modulo n
exists if and only if n is one of the following numbers: 2, 4, ph, 2ph, with p an odd
prime and h a positive integer.
The proof consists of several steps, and we shall give it by dividing it into lemmas.
Clearly, cases n = 2, 4 are trivial.
The following three lemmas prove that the integers of the form ph and 2ph, with
p an odd prime and h a positive integer, have a primitive root.
Lemma 6.2.5. Let p be an odd prime. If r is a primitive root modulo p and if r is
not a primitive root modulo p2, then r + p is a primitive root modulo p2.
Proof. Set m = Gss(p2, r). By the hypothesis, m is a proper divisor of ϕ(p2) =
p(p −1). On the other hand, rm ≡1 (mod p2) and so rm ≡1 (mod p); hence,
p −1 = Gss(p, r) | m. So, m = p −1.
Notice next that, as r + p ≡r (mod p), reasoning in the same way as above we
ﬁnd that either Gss(p2, r + p) = p −1 or Gss(p2, r + p) = p(p −1). To conclude, we
prove that the ﬁrst case never happens.
We have
(r + p)p−1 = rp−1 + (p −1)prp−2 +

p −1
2

p2rp−3 + · · · ,
so
(r + p)p−1 ≡rp−1 −prp−2 ≡1 −prp−2
(mod p2).
If Gss(p2, r + p) = p −1, then prp−2 ≡0 (mod p2), which is false.
⊓⊔
Remark 6.2.6. The previous lemma implies that it is possible to ﬁnd a common
primitive root of p and p2, for every odd prime p.
Lemma 6.2.7. Let p be an odd prime and let h ≥2 be an integer. If r is a primitive
root modulo both p and p2, then r is a primitive root modulo ph as well.
Proof. The lemma is trivially veriﬁed for h = 2. Then proceed by induction on h,
with h ≥3, assuming that r is a primitive root modulo pℓwith 2 ≤ℓ≤h −1 and
proving that it is so modulo ph as well.
Let m = Gss(ph, r). We have m | ϕ(ph) = ph−1(p−1). Reasoning as in the proof
of the previous lemma we also ﬁnd p −1 | m. So m = pk(p −1), with 0 ≤k ≤h −1.
To prove the claim, that is, k = h −1, it is suﬃcient to prove that it is not the case
that
rph−2(p−1) ≡1
(mod ph),
(6.8)
but, on the contrary, one has
rph−2(p−1) ̸≡1
(mod ph).
(6.9)

6.2 Primitive roots
275
We proceed in a way pretty analogous to that of the proof of the previous lemma.
Notice that, by the induction hypothesis,
rϕ(pℓ) = rpℓ−1(p−1) ≡1
(mod pℓ),
(6.10)
while
rpℓ−2(p−1) ̸≡1
(mod pℓ)
(6.11)
for all ℓsuch that 2 ≤ℓ≤h −1. In particular, taking ℓ= h −2 in (6.10) we have
rph−3(p−1) = 1 + dph−2,
(6.12)
while taking ℓ= h −1 in (6.11) we see that p ∤d. From (6.12) we ﬁnd
rph−2(p−1) = 1 + p · dph−2 +

p
2

d2p2h−4 + · · ·
and so (see Exercise A4.9)
rph−2(p−1) ≡1 + dph−1
(mod ph).
If (6.9) did not hold, and (6.8) held instead, we would have
dph−1 ≡0
(mod ph)
and so p | d, yielding a contradiction.
⊓⊔
Lemma 6.2.8. Let n = 2ph with p an odd prime and h a positive integer. Then
there exists a primitive root modulo n.
Proof. Let r be a primitive root modulo ph. Notice that ϕ(n) = ϕ(ph). Let d be a
proper divisor of ϕ(n). Then rd ̸≡1 (mod ph). So we cannot have rd ̸≡1 (mod 2ph)
either, proving that Gss(n, r) = ϕ(n).
⊓⊔
We study now the case of the numbers that are powers of two:
Lemma 6.2.9. Let m be an odd positive integer.
(1) For all integer h ≥3:
m2h−2 = mϕ(2h)/2 ≡1
(mod 2h)
so 2h has no primitive roots.
(2) There are odd positive integers m such that Gss(2h, m) = 2h−2 = ϕ(2h)/2; for
instance, this is true for m = 5.
Proof. We prove the ﬁrst part of the lemma. The claim is true for h = 3. Proceed
by induction on h, with h ≥4, assuming the claim for every integer k, with 3 ≤k ≤
h −1. By induction:
m2h−3 = 1 + 2h−1d.
Squaring:
m2h−2 = 1 + 22h−2d2 + 2hd ≡1
(mod 2h).

276
6 Primality and factorisation tests
We prove now the second part of the lemma. We show that, for every integer
h ≥3, we have
52h−3 ≡1 + 2h−1 ̸≡1
(mod 2h).
(6.13)
This relation is true for h = 3. Proceed by induction on h, with h ≥4, assuming
the claim for every integer k, with 3 ≤k ≤h −1. By induction:
52h−4 = 1 + 2h−2 + 2h−1d,
so
52h−3 = 1 + 22h−4 + 22h−2d2 + 2h−1 + 2hd + 22h−2d,
hence (6.13) follows.
⊓⊔
Remark 6.2.10. The previous lemma completely describes the structure of the
group U(2h), whose order is ϕ(2h) = 2h−1. It is cyclic if h = 1, 2. Otherwise, it is
a direct product of a cyclic group of order 2h−2 and of a cyclic group of order 2.
Indeed, if h ≥3, in U(2h) there is the element −1 which has order 2, and 5 which
has order 2h−2, and the cyclic groups ⟨5⟩and ⟨−1⟩, clearly, intersect only in 1 (see
Exercise A6.12), so their direct product is included in U(Zp) and is an abelian group
of order 2h−1, hence, it is the whole U(2h).
To conclude the proof of the Theorem 6.2.4 we prove the following lemma.
Lemma 6.2.11. If the positive integer n ≥5 is not a prime power or a product of
2 and a prime power, then there are no primitive roots modulo n.
Proof. Let n = ph1
1 · · · pht
t
be the prime decomposition of n. Assume r to be a
primitive root modulo n.
As GCD(n, r) = 1, then also GCD(pi, r) = 1, so
rϕ(phi
i
) ≡1
(mod phi)
for all i = 1, . . . , t. Set s = lcm(ϕ(ph1
1 ), . . . , ϕ(pht
t )) and notice that s | ϕ(ph1
1 ) · · ·
ϕ(pht
t ) = ϕ(n).
On the other hand,
rs ≡1
(mod phi),
so
rs ≡1
(mod n)
hence ϕ(n) = Gss(n, r) | s. In conclusion, lcm(ϕ(ph1
1 ), . . . , ϕ(pht
t )) = ϕ(ph1
1 ) · · ·
ϕ(pht
t ), which implies that the numbers ϕ(phi
i ) = phi−1(pi −1) are relatively prime
(see Exercise A4.1). This yields that in the factorisation of n no two odd primes
can appear. Moreover, if one odd prime appears, then 2 cannot have an exponent
greater than 1.
⊓⊔
We still have to determine the structure of the group U(Zn) if it is not cyclic,
that is, if n is diﬀerent from a number of the form 2, 4, ph, 2ph, with p an odd prime
and h a positive integer. This is achieved by the following theorem.
Theorem 6.2.12. Let n be a positive integer and let n = ph1
1 · · · phm
m
be its prime
decomposition. Then the group U(Zn) is the direct product of the groups U(Zphi
i ),
i = 1, . . . , m.

6.2 Primitive roots
277
Proof. From Proposition 3.4.5 follows that the obvious map
U(Zn) →U(Zph1
1 ) × · · · × U(Zphm
m )
is a group isomorphism.
⊓⊔
Here follows a new deﬁnition.
Deﬁnition 6.2.13. Let n be a positive integer. A positive integer s is said to be a
universal exponent for n if for every positive integer a < n one has as ≡1 (mod n).
Notice that for all positive integer n there is some universal exponent. For in-
stance, by Euler’s Theorem 3.3.11, ϕ(n) is such an exponent. So it makes sense to
look for the least universal exponent u(n) for n. Clearly, u(n) is the least common
multiple of the orders of the elements of U(Zn) (see Exercise A6.13). Hence:
Proposition 6.2.14. Let n be a positive integer and let n = 2hph1
1 · · · phm
m
be its
prime decomposition. Then
u(n) = lcm(u(2h), ϕ(ph1
1 ), . . . , ϕ(phm
m )),
where u(2) = 1, u(4) = 2, u(2h) = 2h−2, if h ≥3. Moreover, there are elements of
U(Zn) of order u(n), that is to say, there exist numbers a, relatively prime with n
such that Gss(n, a) = u(n).
Proof. It is clear that
u(n) = lcm(u(2h), u(ph1
1 ), . . . , u(phm
m )).
As U(Zphi
i ) is cyclic, obviously u(phi
i ) = ϕ(phi
i ), i = 1, . . . , m. The claims about
u(2h) are an immediate consequence of what has been said in Remark 6.2.10.
Choose now 2 = p0, h = h0. Identify U(Zn) with U(Zph0
0 ) × · · · × U(Zphm
m ) by
the isomorphism described in the proof of Proposition 6.2.12. Notice that in every
group U(Zphi
i ) there is some element xi of order u(phi
i ). Clearly, x = (x0, . . . , xm)
has order equal to lcm(u(2h), u(ph1
1 ), . . . , u(phm
m )) = u(n).
⊓⊔
Now we are able to complete the:
Proof of Proposition 6.1.6. Proof of (a). Assume n to be a Carmichael number.
Let a be a number relatively prime with n such that Gss(n, a) = u(n). As n is a
Carmichael number, we have an−1 ≡1 (mod n), so u(n) | n −1.
Let n = ph1
1 · · · phm
m
be the prime decomposition of n. As n is odd, p1, . . . , pm
are odd primes. Moreover, ph1−1
i
(pi −1) | u(n) | n −1, i = 1, . . . , m. This implies
that hi = 1, i = 1, . . . , m, or else we would ﬁnd an i = 1, . . . , m such that pi | n −1,
yielding a contradiction. This proves (a).
The proof of the part of (b) not already proved is pretty analogous (see Exercise
A6.14).
⊓⊔

278
6 Primality and factorisation tests
6.2.1 Primitive roots and index
As we already mentioned, if n has a primitive root, arithmetic modulo n is compu-
tationally much easier. Let us see why.
Let r be a primitive root modulo n. Then U(Zn) = {1, r, r2, . . . , rϕ(n)−1}.
Deﬁnition 6.2.15. Let m be an integer relatively prime with n, and assume that n
has a primitive root r. The least non-negative integer h such that rh ≡m (mod n)
is said to be the index of m with respect to r and is denoted by indr m.
Example 6.2.16. As we already know, a primitive root modulo 14 exists. The num-
ber r = 5 is such a root. Indeed, ϕ(14) = 6 and 52 = 11 ≡−3 (mod 14), 53 ≡−1
(mod 14), 54 ≡−5 (mod 14), 55 ≡3 (mod 14), 56 ≡1 (mod 14).
As U(Z14) = {1, 3, 5, 9, 11, 13}, we have
ind5 1 = 0,
ind5 3 = 5,
ind5 5 = 1,
ind5 9 = 4,
ind5 11 = 2,
ind5 13 = 3.
The proof of the following lemma is easy and is left as an exercise for the reader
(see Exercise A6.15):
Lemma 6.2.17. Let r be a primitive root modulo n. Then:
(1) indr 1 = 0;
(2) if m is an integer relatively prime with n, then rh ≡m (mod n) if and only if
h ≡indr m (mod ϕ(n));
(3) if m is an integer relatively prime with n and if h is an arbitrary integer, then
indr mh ≡h indr m (mod ϕ(n));
(4) if m, m′ are integers relatively prime with n, then indr mm′ ≡indr m + indr m′
(mod ϕ(n)).
Knowing the index makes it easier to solve several problems about congruences.
For instance, suppose we want to solve a congruence of the form axh ≡b (mod n).
If r is a primitive root modulo n, the congruence may be rephrased as
indr a + h indr x ≡indr b
(mod ϕ(n))
which we can solve.
Example 6.2.18. Suppose we want to solve the equation 3x5 ≡11 (mod 14). Keep-
ing in mind Example 6.2.16, if y = ind5 x, then the congruence becomes 5 + 5y ≡2
(mod 6), which has solution y ≡3 (mod 6). Thus, the solution modulo 14 of the
originary equation is 53 = −1.
The following deﬁnition is especially interesting.
Deﬁnition 6.2.19. Let n be a positive integer, m an integer relatively prime with
n, and h a positive integer. The number m is said to be an h-ple residue modulo n,
if the equation
xh ≡m
(mod n).
(6.14)
has a solution.
We have the following result.

6.2 Primitive roots
279
Proposition 6.2.20. Let n be a positive integer, m an integer relatively prime with
n, and h a positive integer. Assume n has a primitive root r. Let d = GCD(h, ϕ(n)).
Then m is an h–ple residue modulo n if and only if
mϕ(n)/d ≡1
(mod n).
(6.15)
In this case Equation (6.14) admits exactly d solutions not congruent to each other
modulo n.
Proof. Equation (6.14) can be rephrased as the equation
h indr x ≡indr m
(mod ϕ(n)).
This equation has solutions, and if so it has d solutions not congruent to each
other modulo ϕ(n), yielding d distinct solutions of (6.14) modulo n, if and only if
d | indr m, that is, if and only if indr m = da (see Proposition 3.3.4). If this happens,
then
mϕ(n)/d ≡raϕ(n) ≡1
(mod n).
Conversely, if (6.15) holds, by Lemma 6.2.17 we have
indr m · ϕ(n)
d
≡0
(mod ϕ(n))
and so d | indr m.
⊓⊔
Example 6.2.21. For instance, we ask: is 9 a 4-ple residue modulo 14? We have
GCD(4, ϕ(14)) = GCD(4, 6) = 2. As 93 ≡(−5)3 ≡1 (mod 14) the answer is
aﬃrmative and the equation x4 ≡9 (mod 14) has 2 non-congruent solutions modulo
14. They are found by solving the equation 4 ind5 x ≡4 (mod 6). It gives ind5 x =
1, 4 and so x = 5, 9 modulo 14.
Corollary 6.2.22. Let n and h be positive integers. Assume n to have a primitive
root r. Let d = GCD(h, ϕ(n)). Then the equation xh ≡1 (mod n) admits exactly d
solutions not congruent to each other modulo n.
Moreover, if ϕ(n)/d is even, and only in this case, the equation xh ≡−1 (mod n)
also admits exactly d solutions not congruent to each other modulo n.
6.2.2 More about the Miller–Rabin test
In this section we give the proof of Proposition 6.1.20, which is the key for Miller–
Rabin test we have discussed in Section 6.1.8.
Proof of Proposition 6.1.20. Notice that if b is a positive integer number such
that n is a strong pseudoprime in base b then n is a pseudoprime too in base b;
hence such values of b are solutions of the equation
xn−1 ≡1
(mod n).
(6.16)
Let n = ph1
1 · · · phm
m
be the factorisation of n. By Corollary 6.2.22, the equation
xn−1 ≡1
(mod phi
i ),
i = 1, . . . , m,

280
6 Primality and factorisation tests
has di = GCD(n −1, phi−1
i
(pi −1)) = GCD(n −1, pi −1) solutions. By the Chinese
remainder theorem 3.4.2, Equation (6.16) has d = ,m
i=1 di solutions.
We examine ﬁrst the case in which h1 > 1. Set p1 = p and h1 = h. We have
ph
p −1 ≥
p2
p −1 = p2 −1 + 1
p −1
= p + 1 +
1
p −1 > 4.
Then
d =
m
'
i=1
di ≤
m
'
i=1
(pi −1) < 1
4ph
m
'
i=2
pi ≤n
4
and this proves the theorem in this case.
So we may assume that hi = 1 for all i = 1, . . . , m. Set
n −1 = 2st,
pi −1 = 2siti,
i = 1, . . . , m,
with t, ti odd for all i = 1, . . . , m and s1 ≤s2 ≤· · · ≤sm. Set next
GCD(n −1, pi −1) = 2σiτi,
i = 1, . . . , m,
where
σi = min{s, si},
τi = GCD(t, ti).
By Corollary 6.2.22, the equation
xt ≡1
(mod pi),
i = 1, . . . , m,
has GCD(t, pi −1) = GCD(t, ti) = τi solutions. Consider the equation
x2rt ≡−1
(mod pi),
i = 1, . . . , m,
(6.17)
with r < s a non-negative integer. We have
δi = GCD(2rt, pi −1) = GCD(2rt, 2siti) = 2σ′
iτi,
with σ′
i = min{r, si}.
Notice that ϕ(pi)/δi = (2siti)/(2σ′
iτi), and this number is even if and only if
si > σ′
i, that is, if and only if r < si. In this case σ′
i = r, and Equation (6.17) has
exactly δi = 2rτi solutions (see Corollary 6.2.22), otherwise it has none.
By applying the Chinese remainder theorem we ﬁnd that the equation
xt ≡1
(mod n)
has τ = τ1 · · · τm solutions, while the equation
x2rt ≡−1
(mod n),
with r < s a non-negative integer, has δ = δ1 · · · δm = 2mrτ solutions if r ≤s1 −1 ≤
si −1, i = 1, . . . , m, otherwise it has none.
In conclusion, the number of integers b < n such that GCD(b, n) = 1 and that
n is a strong pseudoprime in base b is
N(n) = τ

1 +
s1−1

r=1
2mr

= τ

1 + 2ms1 −1
2m −1

.

6.3 A polynomial deterministic primality test
281
Notice that
ϕ(n) =
m
'
i=1
(pi −1) = 2s1+···+smT,
where we set T = t1 · · · tm. We have to prove that
N(n) ≤ϕ(n)
4
(6.18)
and, as τi ≤ti, i = 1, . . . , m, it suﬃces to prove that
1
2s1+···+sm

1 + 2ms1 −1
2m −1

≤1
4.
(6.19)
As s1 ≤s2 ≤· · · ≤sm, we have
1
2s1+···+sm

1 + 2ms1 −1
2m −1

≤
1
2ms1

1 + 2ms1 −1
2m −1

=
=
1
2ms1 +
1
2m −1 −
1
2ms1(2m −1) =
1
2m −1 +
2m −2
2ms1(2m −1) ≤
2
2m −1.
If m ≥4, then 2/(2m −1) ≤1/4 and this proves Equation (6.19) in this case. If
m = 3, then 1/(2m −1) + (2m −2)/(2ms1(2m −1)) ≤1/4, and Equation (6.19) is
proved again.
The last case we have to examine is m = 2. Here we have
1
2s1+s2

1 + 22s1 −1
3

=
1
22s1+s2−s1

1 + 22s1 −1
3

=
1
2s2−s1
1
3 +
1
3 · 22s1−1

.
If s2 > s1 the last number is smaller than 1/4 and so Equation (6.19) is proved
in this case. Assume ﬁnally that m = 2, s1 = s2 = σ. It follows from n = p1p2 =
(2σt1 + 1)(2σt2 + 1) that s ≥σ.
Let p1 > p2. If τ1 = t1 then we would have p1 −1 | n −1 and 1 ≡n ≡p1p2 ≡p2
(mod p1 −1), which is a contradiction. Then we have τ1 < t1 and, as t1 is an odd
number, we have τ1 ≤t1/3. Thus, τ ≤T/3. Finally, to prove Equation (6.18), notice
that
N(n) = τ

1 + 22σ −1
3

≤T22σ
6
= ϕ(n)
6
.
⊓⊔
6.3 A polynomial deterministic primality test
We describe in this section a recent primality test, due to M. Agrawal,
N. Kayal, and N. Saxena [2], and thus called “AKS test”. In order to de-
cide whether a number is prime we have described, in the previous sections,
several probabilistic algorithms. The reason why those algorithms have been
successful is that deterministic algorithms that where known until recently,
for instance the sieve of Eratosthenes (see Section 4.1.3), or the tests based on
Fermat’s little theorem (see Section 4.2.2) or on Wilson’s theorem (see Section
4.2.3), have exponential complexity and so are unfeasible for large numbers.
The AKS test, on the other hand, is deterministic and has polynomial com-
plexity. When it was found, it immediately aroused a great interest, as it was

282
6 Primality and factorisation tests
all but certain that such an algorithm existed, even if, of course, nobody had
proved that it did not exist.
The AKS algorithm relies on the following polynomial version of Fermat’s
little theorem.
Proposition 6.3.1. Let a ∈Z, n ∈N, n ≥2 be numbers such that
GCD(a, n) = 1. Then n is prime if and only if
(x + a)n ≡xn + a
(mod n).
(6.20)
Proof. Recall that the coeﬃcient of xi in (x + a)n −(xn + a) for 0 < i < n,
is
n
i
	
an−i and, if n is prime,
n
i
	
≡0 (mod n) (see Exercise A4.9). So, by
Fermat’s little theorem, (6.20) holds.
Assume now n to be a composite number and q to be a prime dividing n. If
α is the greatest positive integer such that qα | n, then qα does not divide
n
q
	
(see Exercise A6.30) and is relatively prime with an−q. So the coeﬃcient of
xq is not zero modulo n, and so (x+a)n −(xn +a) is not the zero polynomial
in Zn[x], that is to say, Equation (6.20) does not hold.
⊓⊔
The identity (6.20) characterises prime numbers and so it gives a primality
test: to verify whether a number n is prime it suﬃces to choose an a ∈Z such
that GCD(a, n) = 1 and to check whether Equation (6.20) holds. However,
this test has exponential complexity, as there are n + 1 coeﬃcients in the
polynomial (x + a)n, and computing all of them may be quite burdensome
(see Exercise A2.24).
An idea to make the algorithm more eﬃcient consists in trying to reduce
the number of coeﬃcients to be computed. A way to do so is to evaluate both
sides of (6.20) modulo a suitable polynomial. For instance, we could choose a
polynomial of the form xr −1 for a suitable, not too large, positive integer r.
In other words, we require for Equation (6.20) to be veriﬁed in the quotient
ring Zn[x]/(xr −1), rather that in Zn[x]: that is, we require that the following
equation holds:
(x + a)n = xn + a
in Zn[x]/(xr −1).
(6.21)
Clearly, if n is prime, (6.20) holds, and so (6.21) holds as well. But is the
converse true? That is to say, is Equation (6.21) a suﬃcient condition too,
and not only a necessary one, for n to be prime? Unfortunately, the answer
to this question is negative, as the following simple example shows.
Example 6.3.2. We have
(x + 3)4 ≡x4 + 3
in Z4[x]/(x2 −1).
(6.22)
Indeed, in Z4[x] we have
(x + 3)4 = (x −1)4 = x4 −4x3 + 6x2 −4x + 1 = x4 + 2x2 + 1,
so in Z4[x]/(x2 −1), (6.22) clearly holds. Thus, Equation (6.21) is veriﬁed
even though 4 is not a prime.

6.3 A polynomial deterministic primality test
283
If we intend to carry on our idea of working in Zn[x]/(xr −1) rather than
in Zn[x], we have to extend in a suitable way Equation (6.20). Luckily, the
right extension exists: it involves proving that there is an r, not too large with
respect to n, such that, if (6.21) is veriﬁed for a suﬃcient number of as, then
n is prime. In order to obtain a polynomial algorithm we have to show that
both r and the number of as for which (6.21) must be veriﬁed for n to be
deemed a prime, are bounded by a polynomial in log n.
We show now in detail how it is possible to prove the above. We begin by
the following lemma.
Lemma 6.3.3. Let n be a positive integer. There exists an integer r ≤
[16 log5
2 n] + 1 such that Gss(r, n) > 4 log2
2 n.
Proof. Let r1, . . . , rt be the positive numbers such that Gss(ri, n) ≤4 log2
2 n
for all i = 1, . . . , t. This means that for all ri, i = 1, . . . , t, we have
nk ≡1
(mod ri),
for some k = 1, . . . , [4 log2
2 n],
that is, every ri, i = 1, . . . , t, divides the product
[4 log2
2 n]
'
i=1
(ni −1) < n16 log4
2 n ≤216 log5
2 n.
(6.23)
If we ﬁx a positive integer m, it is easy to prove that, for all m ≥7, we
have
lcm(1, 2, . . ., m) ≥2m
(see Exercise A6.22). Set M = [16 log5
2 n] + 1. So, keeping in mind (6.23), we
have
lcm(r1, . . . , rt) < 2M ≤lcm(1, 2, . . . , M).
If the claim were not true, it would mean that the set {r1, . . . , rt} includes
the set {1, . . . , M} and so we would have
lcm(1, 2, . . . , M) ≤lcm(r1, . . . , rt) < lcm(1, 2, . . . , M),
a contradiction.
⊓⊔
In a short while the following remark will be useful.
Remark 6.3.4. Let r be a positive integer and p a prime number not dividing
r. Consider the polynomial xr −1 over Zp whose roots, in its splitting ﬁeld,
are all rth roots of unity which, as we know, form a cyclic group Rr of order r
(see Theorem 5.1.16). So there exists ξ ∈Rr of order r. Consider its minimal
polynomial h(x) in Zp[x] and let d be its degree. Then Zp[x]/(h(x)) = Zp(ξ),
and this ﬁeld F has order pd.
Notice that as F contains ξ, it also contains all the powers of ξ and so it
contains Rr; thus F is exactly the splitting ﬁeld of xr −1 over Zp.

284
6 Primality and factorisation tests
We prove now that d = Gss(r, p), even though this is not strictly necessary
for what follows. Set Gss(r, p) = n; then pn ≡1 (mod r). As h(x) divides
xr −1, keeping in mind Exercise A4.36, we have that h(x) divides xpn−1 −1.
So, for all η ∈F we have ηpn−1 = 1. In particular, this holds for a generator
of F ∗(see Theorem 5.1.30). It follows that pd −1 | pn −1, and so d ≤n.
On the other hand, there are in F elements of period r: for instance, ξ.
Thus, r | pd −1, that is, pd ≡1 (mod r), and so n = Gss(r, p) | d. Hence
d = n.
The following terminology will be useful.
Deﬁnition 6.3.5. Let p be a prime number and r a positive integer. Given a
polynomial f(x) ∈Z[x] and a positive integer m, m is said to be introspective
for f(x) modulo p, with respect to r, or simply introspective, if no confusion
is possible, if
(f(x))m = f(xm)
in Zp[x]/(xr −1).
Clearly, a prime p is introspective modulo p itself with respect to any
positive integer r, due to the freshman’s dream (see Exercise A4.10). Moreover,
it is not diﬃcult to prove that the product of numbers that are introspective
for a polynomial f(x) is still introspective for the same polynomial, and that
if a number is introspective for two polynomials then it is introspective for
their sum and their product (see Exercise A6.23).
We may now prove the following result, which is fundamental for the AKS
algorithm.
Theorem 6.3.6. Let n > 1 be an integer that is not a prime power with
exponent greater than 1. Let r < n be a positive integer relatively prime with
n such that
r ≤[16 log5
2 n] + 1,
Gss(r, n) > 4 log2
2 n.
Assume further that n has no prime factors smaller than or equal to r. Then
n is prime if and only if for all a = 1, . . . , [2

ϕ(r) log2 n] Equation (6.21)
holds, that is,
(x + a)n = xn + a
in Zn[x]/(xr −1).
Proof. We have already seen that, by Proposition 6.3.1, if n is prime, then
(6.21) holds for all a. So we only have to prove that the condition given in
Theorem 6.3.6 is suﬃcient to ensure that n is prime.
Assume by contradiction that p is a prime divisor of n: so p < n/2 and
p > r, and so GCD(p, r) = 1.
Set
l := [2

ϕ(r) log2 n]
and notice that
l < r −1.
(6.24)

6.3 A polynomial deterministic primality test
285
Indeed, if formula (6.24) did not hold, we would have r−1 ≤2

ϕ(r) log2 n ≤
2√r −1 log2 n, and so √r −1 ≤2 log2 n. Hence r −1 ≤4 log2
2 n < Gss(n, r),
which is not possible.
By hypothesis, Equation (6.21) is veriﬁed for all a = 1, . . . , l. As p | n, the
following relations are veriﬁed too:
(x + a)n = xn + a
in Zp[x]/(xr −1),
for all a = 1, . . . , l,
(6.25)
that is, n is introspective, modulo p with respect to r, for the l polynomials
x + 1, x + 2, . . . , x + l.
Consider the following two sets:
I := {ni · pj | i, j ≥0},
P :=
*
l'
a=1
(x + a)ia | ia ≥0
+
.
Then every number in the set I is introspective for every polynomial in
the set P. Now let us deﬁne two groups G and Q connected with the sets I
and P. Deﬁne
G := {x mod r | x ∈I}.
Recalling that GCD(n, r) = GCD(p, r) = 1, G is the subgroup of U(Zr)
generated by n and p modulo r, that is, G consists of the residue classes
modulo r of the elements of I. If |G| = t, we have
ϕ(r) ≥t ≥Gss(n, r) > 4 log2
2 n,
t ≥Gss(p, r).
(6.26)
Consider now the ﬁeld F = Zp(ξ) = Zp[x]/(h(x)), as in Remark 6.3.4.
Denote by Q the subgroup of the multiplicative group F ∗generated by the
classes of the polynomials x + 1, x + 2, . . . , x + l, that is, the subgroup of F ∗
generated by the classes in F = Zp[x]/(h(x)) of the polynomials of the set P.
Set q = |Q|.
Notice that Q, as F ∗of which it is a subgroup, is a cyclic group, and
so it has a generator γ, which is the class, modulo p and modulo h(x), of a
polynomial G(x) ∈Z[x]. It is important to remark that
m, m′ introspective for G(x), m ≡m′ (mod r) =⇒m ≡m′ (mod q). (6.27)
Indeed, if m′ = m + rv, we have
(G(x))m+rv = G(xm+rv)
in Zp[x]/(xr −1),
hence
(G(x))m(G(x))rv = G(xm) = (G(x))m
in Zp[x]/(xr −1).
As h(x) divides xr −1, we also have
(G(x))m(G(x))rv = (G(x))m
in F

286
6 Primality and factorisation tests
and from here it can be deduced that γrv = 1 in F ∗, and so q | rv = m −m′.
We shall prove that q veriﬁes simultaneously the following two inequalities:
q ≥
t + l −2
t −1

,
(6.28)
q < 1
4n2
√
t.
(6.29)
The formulas (6.28) and (6.29) will be proved later; we see how to conclude
the proof of the theorem ﬁrst. Set s = [2
√
t log2 n]. From (6.26) we have
t −1 ≥s, and, by (6.28), we have
q ≥
s + l −1
s

.
Notice now that l ≥2

ϕ(r) log2 n ≥2
√
t log2 n, which implies that l ≥s and
so we have
q ≥
2s −1
s

.
On the other hand, for s ≥3, we have
2s −1
s

= 2s −1
s −1 · 2s −2
s −2 · · · · · s + 2
2
· (s + 1) ≥2s−1
and so
q ≥2s−1 ≥22
√
t log2 n−2 = 1
4n2
√
t,
contradicting (6.29): the contradiction is a consequence of assuming n not to
be prime.
We only have to prove the two inequalities (6.28) and (6.29). To this end,
consider the set P ′ of polynomials in P of the form ,l
a=1 (x + a)ia and whose
degree is l
a=1 ia ≤t −1. Notice that their number is exactly
t+l−2
t−1
	
(see
Exercise A1.24). We claim that their classes in F ∗are all distinct. From this
fact the formula in (6.28) immediately follows.
To prove the above claim, ﬁrst of all notice that the polynomials in P ′
are all distinct modulo p, that is, in Zp[x]. This follows from the fact that
x + 1, x + 2, . . . , x + l are distinct as elements of Zp[x], and this in turn is an
immediate consequence of the fact that l < p, or else by (6.24) we would have
p ≤l < r −1, against the hypothesis p > r.
So, let f(x), g(x) be two polynomials in P ′ and assume that their classes
in F are not distinct. Set k(x) = f(x) −g(x) and denote by ¯k(x) the class of
k(x) in Zp[x]. Then, the polynomial ¯k(x) is divisible by h(x), and so it has as
a root the rth primitive root of unity ξ, that is to say, we have
¯k(ξ) = 0.

6.3 A polynomial deterministic primality test
287
As all numbers in I are introspective modulo p with respect to r both for
f(x) and g(x), these numbers are introspective for k(x) too, that is, we have
(¯k(x))ni·pj = ¯k(xni·pj)
in
Zp[x]/(xr −1)
for every pair of non-negative integers i, j. As h(x) divides xr −1, we also
have
(¯k(x))ni·pj = ¯k(xni·pj)
in
F = Zp[x]/(h(x))
for every pair of non-negative integers i, j. Consequently, we have
¯k(ξni·pj) = ¯k(ξ)ni·pj = 0
for every pair of non-negative integers i, j. When i and j run over the non-
negative integers the classes modulo r of the numbers ni · pj are as many as
the elements of G, that is, they are t; so the polynomial ¯k(x) ∈Zp[x] has as
its t distinct roots ξ, ξ2, . . . , ξt. As ¯k(x) has degree smaller than t, we have
that ¯k(x) is the zero polynomial in Zp[x]. This means that f(x) and g(x) are
equal modulo p, and as we have seen this implies f(x) = g(x). This concludes
the proof of (6.28).
Finally, we prove (6.29). Assume it not to be true, and so
q ≥1
4n2
√
t.
(6.30)
Consider the elements of the set I of the form nipj with 0 ≤i ≤
√
t and
0 ≤j ≤
√
t. The number of such elements is ([
√
t] + 1)2 > t. So in G the
classes of these elements are not all distinct. Then there are i, i′, j, j′ with
0 ≤i, i′, j, j′ ≤
√
t, i ̸= i′ and j ̸= j′, such that
nipj ≡ni′pj′
(mod r).
As nipj and ni′pj′ are introspective for the polynomials of P, they are
also for the polynomial G(x) ∈Z[x] whose class in F generates Q; so (6.27)
implies
nipj ≡ni′pj′
(mod q).
(6.31)
Suppose i ≥i′ and j ≥j′. We have i, j ≤
√
t and so ni ≤n
√
t, pj ≤
(n/2)
√
t; then, as t > 4 (see (6.26)), we have 1 ≤nipj ≤1/4n2
√
t ≤q and
analogously 1 ≤ni′pj′ ≤q. Then Equation (6.31) implies nipj = ni′pj′, thus
i = i′, j = j′ against the assumptions.
Suppose now that i ≥i′ and j ≤j′. In this case we have
ni−i′ ≡pj′−j
(mod q).
Arguing as before, we see that this relation implies that ni−i′ = pj′−j. But in
this case n, if it were not a prime number, would be a power of p, yielding a
contradiction.
⊓⊔

288
6 Primality and factorisation tests
Using these results we can now outline the AKS algorithm.
The AKS(n) algorithm
Input: an integer n > 1;
1. if (n = mk, m ∈N, k ∈N, k > 1), then return n COMPOSITE;
2. determine the least integer r such that Gss(r, n) > 4 log2
2 n;
3. if 1 < GCD(a, n) < n for some a ≤r, then return n COMPOSITE;
4. if n ≤r, output n PRIME;
5. if (x + a)n ̸= xn + a in Zn[x]/(xr −1) ∀a = 1, . . . , ⌊2

ϕ(r) log2 n⌋,
then return n COMPOSITE;
6. return n PRIME.
Comments about the algorithm:
(1) if n is a power of an integer with exponent greater than 1, that is, n = mk,
with m, k ∈N and k > 1, this fact can be recognised in polynomial time
(see Proposition 6.3.7 below) and clearly in this case n is not prime;
(2) in Lemma 6.3.3 we proved that there is a r ≤⌈16 log5 n⌉such that
Gss(r, n) > 4 log2 n;
(3) we are computing a greatest common divisor r times: if one of these is
strictly greater than 1 and strictly smaller than n, clearly n is composite;
(4) if n ≤r were composite, by the previous remark it would have be identiﬁed
as such: in fact, in this case it would be suﬃcient to take as a a non-
trivial factor of n and, as n ≤r, then a ≤r and so we would have
1 < GCD(a, n) = a < n;
(5) see Theorem 6.3.6.
As promised, we prove the following result.
Proposition 6.3.7. Let n > 1 be a positive integer. There is a polynomial
algorithm of complexity O(log4 n) that recognises if there are positive integers
m, k, with k > 1, such that n = mk.
Proof. If there are positive integers m, k, with k > 1, such that n = mk,
then k = logm n < log2 n. So, if h = ⌊log2 n⌋, we have 2 ≤k ≤h. Therefore,
for all such k, we have to verify whether the polynomial fk(x) = xk −n has
a positive integer root.
Notice that fk(x) is strictly increasing in the interval [0, n] and that
fk(0) = −n < 0, while fk(n) = nk −n > 0, so fk(x) has exactly one root in
the interval [0, n]. We have to verify whether this root is integer or not.
To this end we may proceed as follows. Evaluate the sign of fk(n/2): we
have to compute nk −2k · n, which has complexity O(k log n) = O(log2 n).
If it were the case that fk(n/2) = 0, which does not happen in practice, we
would have found the kth root of n in [0, n] and the procedure would be over.
Assume now that fk(n/2) is positive, which is what happens in practice. Then
evaluate fk(x) in the midpoint of the interval [0, n/2], that is, in the point

6.3 A polynomial deterministic primality test
289
n/4. To do so, we have to compute nk −4k · n, which has again complexity
O(log2 n). If by chance fk(n/4) = 0, we would be through, otherwise repeat
this procedure and assume that, in the successive evaluations of fk(x) in the
midpoints of the successive intervals at whose endpoints fk(x) has values of
opposite signs, we never ﬁnd the kth root of n in [0, n]. After h + 1 steps we
have then recursively deﬁned a ﬁnite sequence x0, . . . , xh+1 of points in the
interval [0, n] such that:
•
for all i = 1, . . . , h + 1, fk(x) has values with opposite signs in xi−1 and in
xi;
•
|xi −xi−1| = n/2i.
The computational cost of constructing this sequence is polynomial, as it
is O(h log2 n) = O(log3 n).
In particular, we ﬁnd the kth root of n in [0, n], which has to lie in the
interval having as endpoints xh and xh+1. This interval has length n/2h+1 <
1, so it includes at most one integer. If it includes no integers, then n has
no integer kth roots, otherwise if in this interval there is an integer m, by
computing mk we verify at last whether the kth root of n is an integer or not.
As we have to repeat this procedure for every k such that 2 ≤k ≤h, the
complexity of the algorithm is O(h log3 n) = O(log4 n).
⊓⊔
The algorithm AKS gives an eﬀective characterisation of prime numbers
and has polynomial running time.
Theorem 6.3.8. Let n be an integer greater than 1. Then the algorithm AKS
applied to n:
(1) outputs PRIME if and only if n is a prime number;
(2) has polynomial running time.
Proof. The proof of the ﬁrst claim is contained in the previous remarks.
We prove now that AKS applied to n has polynomial running time. To this
end, it suﬃces to prove that each of the steps of the algorithm is polynomial.
We shall use the following notation:
O∼(f(n)) := O(f(n) · p(log(f(n)))), for some polynomial p in log(f(n))
In particular,
O∼(logk n) = O(logk n · p(log(log n))) = O(logk+ϵ n)
for all ϵ > 0.
(6.32)
First step. By Proposition 6.3.7 this step has complexity O(log4 n).
Second step. To verify that, for a ﬁxed positive integer r, Gss(r, n) >
4 log2 n, we have to check that nk ̸= 1 (mod r) for all k ≤4 log2 n: this re-
quires computing at most O(log2 n) powers modulo r, and this has complexity
O(log2 n log3 r) (see § 3.3.1). Now, by Lemma 6.3.3 we know that we need to

290
6 Primality and factorisation tests
test at most ⌈16 log5 n⌉integers r. In conclusion, the complexity of this step
is O∼(log7 n).
Third step. Here we have to compute r times a greater common divisor.
Each of these computations takes a time O(log3 n) (see § 2.5.1); so the total
complexity is O(r · log3 n) = O(log8 n).
Fourth step. As in the previous step.
Fifth step. We have to check ⌊2

ϕ(r) log n⌋equations. Keeping in mind
Exercise A6.26, it is easily seen that each check has complexity O(r2 log3 n).
Thus, the total complexity of this step is
O(r2
ϕ(r) log4 n) = O(r5/2 log4 n) = O(log16.5 n).
The complexity of this step dominates all the complexities of the other
ones; hence, the complexity of the whole algorithm is O(log16.5 n).
Notice that in [2] a better estimate of this complexity is given, and it has
been further improved by other authors, but we shall not go into these details.
⊓⊔
6.4 Factorisation methods
In the previous sections we have seen some primality tests. Suppose we ascer-
tained, by using one of those tests, that a given number n is not prime. As we
have already remarked, this tells us nothing about the prime decomposition
of n.
From now on we shall discuss this problem: knowing that a number is not
prime, we are looking for its prime factors.
First of all, when we are about to factor a number, the ﬁrst thing to be
done is to ensure that it is not a prime, verifying that it does not pass one
of the primality tests seen above. In fact, if the number is prime, most of the
factorisation methods we shall shortly see could take an incredibly long time.
As we have already remarked, the question of factoring an integer is com-
putationally very hard. We pointed out this when we discussed the sieve of
Eratosthenes (see § 4.1.3), which may be considered to be the ﬁrst, albeit
rather naive, algorithm to factorise integers. As we shall see, all the results we
are going to describe provide exponential algorithms, which however in some
case work remarkably well.
We face the question of factoring a number in its whole scope when the
number is very large, for instance having about one hundred digits. Knowing
how such a number decomposes into the product of two primes is like being
in possess of a secret information. This is the principle on which public-key
cryptography relies (we shall return to it in Chapter 7): the public information
is the integer, while the secret is its factorisation into two primes. So it is
easily understood that the knowledge of large prime numbers is precious in
this context. It is well known that the research in this sector is carried out

6.4 Factorisation methods
291
by professional mathematicians, sometimes funded by agencies dealing with
security systems.
6.4.1 Fermat factorisation method
We saw, while discussing the sieve of Eratosthenes, that, in order to factor a
number n, it is necessary to ascertain whether it is divisible by the numbers
smaller than or equal to √n. However, we also noticed that this method is in
general quite expensive in terms of computational complexity. The following
method due to Fermat is sometimes more eﬃcient. It relies on the following
facts:
1. n may be assumed to be odd;
2. when n is odd, factoring n is equivalent to determining two integers x and
y such that
n = x2 −y2.
Indeed, if n = x2 −y2, then n = (x + y)(x −y) is a factorisation of n. On
the other hand, if n = ab, then, assuming a ≥b ≥1, we may write
n =
a + b
2
2
−
a −b
2
2
where (a + b)/2 e (a −b)/2 are non-negative integers. In fact, as n is odd,
a and b are odd too, so a ± b is even;
3. determining x and y such that n = x2 −y2 is equivalent to determining x
such that x2 −n is a square, that is, equal to y2.
Fermat factorisation method works as follows: ﬁrst of all determine the
smallest positive integer k such that k2 ≥n; then successively compute the
diﬀerences
k2 −n,
(k + 1)2 −n,
(k + 2)2 −n,
. . .
until a value t ≥k is found such that t2 −n is a square. Notice that this
process terminates at most when t = (n + 1)/2, as
n + 1
2
2
−n =
n −1
2
2
,
a value that can be obtained only when the number n is prime, so that it has
only the trivial factorisation
n =
n + 1
2
+ n −1
2

·
n + 1
2
−n −1
2

= n · 1.
Example 6.4.1. Find the prime factors of the number 29591 using Fermat
factorisation method.

292
6 Primality and factorisation tests
In this case k = 173 and
1732 −29591 = 338
is not a square,
1742 −29591 = 685
is not a square,
1752 −29591 = 1034
is not a square,
1762 −29591 = 1385
is not a square,
1772 −29591 = 1738
is not a square,
1782 −29591 = 2093
is not a square,
1792 −29591 = 2450
is not a square,
1802 −29591 = 2809 = (53)2
is a square.
So, by the last formula
29591 = (180 + 53)(180 −53) = 233 · 127.
Now it is easily seen that 233 and 127 are prime numbers, so this is the
required factorisation.
It is clear that Fermat factorisation method is eﬃcient in the cases in which
n has factors, which can be prime or not, that are close to √n, just like the
factorisation method based upon the sieve of Eratosthenes is eﬃcient only if
n has small prime factors. Nonetheless, both methods are equally expensive,
that is to say, they are exponential (see § 4.1.3 and Exercise A6.27).
However, the next example shows the remarkable eﬃciency of Fermat fac-
torisation method when there are (even not prime) factors of n that are large,
that is, close to √n.
Example 6.4.2. Factor the number n = 127433.
Here k = 357. Now
3572 −127433 = 127449 −127433 = 16
which is a square; hence,
127433 = (357 −4)(357 + 4) = 353 · 361.
The number 353 is prime, while 361 = 192. So the prime factorisation of
127433 is
127433 = 353 · 192.
6.4.2 Generalisation of Fermat factorisation method
We shall now describe a factorisation method extending Fermat’s method
described in last section.

6.4 Factorisation methods
293
Kraitchick in [31] generalised Fermat method as follows: rather than look-
ing for two integers x and y such that x2 −y2 = n, we are requested to ﬁnd
two integers x and y such that
x2 −y2 ≡0
(mod n).
(6.33)
Clearly, a pair of integers x and y satisfying (6.33) does not ensure that n
factors it just says that n divides x2 −y2 = (x + y)(x −y). Nonetheless, each
prime divisor of n must be a divisor of either x−y or x+y. It may well happen
that all prime factors of n divide only one of the two numbers x −y, x + y: in
this case we would have x ≡y (mod n) or x ≡−y (mod n).
But if x ̸≡±y (mod n), in order to ﬁnd a non-trivial factor of n it suﬃces
to compute GCD(n, x −y) or GCD(n, x + y).
Example 6.4.3. Factor with this method the number 559.
Notice that
412 ≡4
(mod 559)
and that 4 = 22. So we found two integers x = 41 and y = 2 such that x2 ≡y2
(mod 559). Determine next GCD(41 −2, 559) using the Euclidean algorithm:
559 = 39 · 14 + 13,
39 = 13 · 3 + 0;
hence GCD(39, 559) = 13, which is a prime factor of 559. So the factorisation
of 559 is
559 = 13 · 559
13 = 13 · 43.
Example 6.4.4. Factor with this method the number 437.
We have
632 ≡36 = 62
(mod 437).
Moreover, GCD(63 −6, 437) = 19, so the factorisation of 437 is
437 = 19 · 23.
Consider now all pairs of numbers (x, y) for which (6.33) holds. In order
to get a ﬁnite set, we take |x| < N with N a ﬁxed positive integer. Let us ask:
which is the probability that for such a pair x ≡±y (mod n)? Notice that for
such pairs the above method does not work.
To give an answer to our question, recall Example 5.2.10 on page 234. It
says that if n is odd and not a prime, then there are exactly 2k square roots
of y2 modulo n, where k is the number of distinct primes dividing n. Notice
that 2k ≥4. So, if we randomly choose (x, y) in our set, it makes sense to
suppose that y is a random square root of x2 modulo n. So the probability
for it to coincide with ±x is 2/2k ≤1/2.

294
6 Primality and factorisation tests
In conclusion, if n is not a prime, the probability of not ﬁnding a non-
trivial factor with this method, by randomly choosing the numbers (x, y) for
which (6.33) holds, is, at each step, smaller than 50%.
This gives rise to a rather eﬃcient factorisation method, with a high prob-
ability of success. We shall discuss it in the next section, where we shall try
to give an answer to a natural question: how may we ﬁnd pairs (x, y), and in
particular random pairs, satisfying (6.33)? This looks even more problematic
than solving the equation x2 −y2 = n and we cannot even think about doing
it by trial and error. In particular, in Example 6.4.3, how did we ﬁnd that
number 41 having the property that 412 is congruent to a square modulo 559,
or, in Example 6.4.4, that number 63 such that 632 is congruent to a square
modulo 437? The answer will shortly be given in what follows.
6.4.3 The method of factor bases
In order to solve Equation (6.33), we have to ﬁnd a number b such that
b2 mod n is a square.
The point of the method we are going to describe is as follows: take an
arbitrary integer b, compute b2 mod n, and factor this into primes. If b2 mod n
is a square, that is, if all the exponents of its factorisation into prime numbers
are even, we are done, otherwise iterate this procedure. We shall see that along
the way we obtain enough data to ensure that the procedure is successful.
Let us describe the method in detail. To this end it is necessary to give a
deﬁnition, which justiﬁes the method’s name itself.
Deﬁnition 6.4.5. A factor basis B is an N-tuple (p1, . . . , pN) of distinct
prime numbers, called the prime numbers of the basis.
An integer m is said to be a B-number modulo an odd positive integer n,
if in the factorisation of m mod n only the primes p1, . . . , pN appear, that is
to say, if
m mod n = pα1
1 · · · pαN
N .
The vector v(m) = (α1, α2, . . . , αN) ∈NN is said to be the B-vector of m
modulo n. We may reduce v(m) modulo 2, that is, take the vector w(m) =
(e1, . . . , eN) ∈ZN
2 , such that ei = αi mod 2, for i = 1, . . . , N. We shall call
w(m) the reduced B-vector of m modulo n.
Consider again the Examples 6.4.3 and 6.4.4: 412 is a B-number modulo
559 with respect to the factorisation basis B = {2}, while 632 is a B-number
modulo 437 with respect to the basis B = {2, 3}.
Let n be the integer to be factored. Having ﬁxed a factorisation basis B,
the method we are discussing consists in looking for a large enough number
K of integers b1, b2, . . . , bK with b2
1, b2
2, . . . , b2
K B-numbers mod n such that
starting with them it is possible to determine a B-number b2 that is a square
modulo n, but in a non-trivial way, that is such that b2 ≡c2 (mod n) but
b ̸≡±c (mod n). Notice that we are not asking for the B-number to be one

6.4 Factorisation methods
295
of the B-numbers b1, b2, . . . , bK, but that it is possible for it to be determined
from them.
To this end, notice that the set of B-numbers is closed under multiplication,
namely, by multiplying B-numbers we still obtain B-numbers. Moreover, the
set of squares modulo n is closed with respect to multiplication too. So b might
be obtained as a product of the numbers b1, b2, . . . , bK or of some of them.
Let now b2
i , i = 1, . . . , K, be positive B-numbers mod n. Let αij be the
exponents of the prime factorisation of b2
i mod n of B and let eij := αij mod 2,
with i = 1, . . . , K, j = 1, . . . , N. We may consider the matrix E over Z2, with
K rows and N columns,
⎛
⎜
⎜
⎜
⎝
e11
e12
. . . e1N
e21
e22
. . . e2N
...
...
...
...
eK1 eK2 . . . eKN
⎞
⎟
⎟
⎟
⎠
its rows being w(b2
1), . . . , w(b2
K).
Assume K > N. Then the number of rows of E is strictly larger than the
number of columns, so the rows of E are certainly linearly dependent over Z2,
as the rank of E is not greater than N. So there is a linear combination of the
rows of E, with coeﬃcients 0 or 1, not all zero, equal to the zero vector. Such
a linear combination can be easily found using Gaussian elimination (see [13],
Chapter 8), which over Z2 only involves row exchanges and sums. So we ﬁnd
a relation of the form
0 = ϵ1w(b2
1) + · · · + ϵKw(b2
K),
where ϵi = 0, 1, i = 1, . . . , K. We may assume that ϵ1 = · · · = ϵp = 1, ϵp+1 =
· · · = ϵK = 0. Then, setting b = b1 · · · bp, b2 = b2
1 · · · b2
p is a square modulo
n, as required. More precisely, for all i = 1, . . . , p, setting ai = b2
i mod n, we
have
ai = pαi1
1
· · · pαiN
N
.
Then
a := a1 · · · ap = pα11+···+α1p
1
· · · pαN1+···+αNp
N
and α11 + · · · + α1p, . . . , αN1 + · · · + αNp are even numbers which we shall
write as 2γ1, . . . , 2γN, respectively. In conclusion, setting
c = pγ1
1 · · · pγN
h ,
we have b2 ≡c2 (mod n).
Remark 6.4.6. This method is not completely foolproof. In fact, it may hap-
pen that c ≡±b (mod n), which in particular is the case if the method has
been applied in a not judicious way. For instance, if all of b1, . . . , bK have been
chosen too small, that is, smaller than √n, then b2
i < n and so b2
i mod n = b2
i

296
6 Primality and factorisation tests
for all i = 1, . . . , K. Then it is clear that E is the zero matrix and we ﬁnd a
trivial relation.
In any case, if we ﬁnd a trivial relation, we have to repeat the procedure,
hoping that the next attempt gives better results. In other words, we have
to increase K in order to have more chances of ﬁnding non trivial relations
between the rows of E.
On the other hand, if b1, . . . , bK have been chosen in a suﬃciently random
way, we may expect that, for all i = 1, . . . , K, bi mod n is a random square
root of b2
i modulo n, so c is a random square root of b2 modulo n. So, by what
we said at the end of the previous section, we know that after k steps the
probability of ﬁnding a trivial relation at each step is smaller than 1/2k.
To sum up, in order to factor an integer n with this method, we proceed
as follows:
•
ﬁx a factor basis B consisting of N prime numbers;
•
choose K > N integers such that b2
i is a B-number mod n for every i;
•
construct the K×N-matrix E having as rows the corresponding B-vectors;
•
by Gaussian elimination on the rows ﬁnd a set of rows of E having zero
sum;
•
the product of the B-numbers corresponding to these rows is a B-number
b mod n for which there is a relation b2 ≡c2 (mod n);
•
if this relation is non-trivial, that is if b ̸≡±c (mod n), proceed as in the
generalisation of Fermat method to ﬁnd a factor of n.
In practice, how can we choose the factor basis B and the numbers
b1, . . . , bK?
First of all, notice that the larger the number N of elements of B, the
higher the probability of ﬁnding a factor of n, as more numbers are in play
and so there is a greater chance of ﬁnding non-trivial solutions of (6.33).
Analogously, the larger the number K, the higher the probability of ﬁnding a
factor of n, as in this case the number of possible relations between rows of E
increases. On the other hand, the larger N and K, the more computationally
expensive the method becomes. So it is necessary to ﬁnd an eﬃcient way of
choosing B and the B-numbers b2
i , i = 1, . . . , K.
The ﬁrst problem lies in factoring the numbers b2
i mod n: they are certainly
smaller than n, and as such possibly easier to factor than n itself, but how
easier? Probably not too much, as these numbers cannot be too small either,
as discussed in Remark 6.4.6. In any case, we want to be able to factor them
easily. A way to reach this goal consists in choosing as factor basis a set B of
suﬃciently small primes. In this way, given a bi, to factor b2
i mod n we have to
divide it by all the primes in B, a rather undemanding task. In order to obtain
b1, . . . , bK, take random numbers b: if b2 mod n cannot be factored using the
primes in B, take a diﬀerent b.

6.4 Factorisation methods
297
In concrete, we may proceed as follows:
(1) choose B ﬁrst;
(2) depending on the choice of B, ﬁnd next the numbers bi choosing them
randomly and verifying for each of them that every b2
i mod n is factored
by the primes in B, until a number K of them is found that is suﬃcient
to apply the above procedure.
This method, as may be easily understood, is not that eﬃcient: it is quite
diﬃcult that the randomly chosen numbers b will be factored by the few
primes in B! However, there are other ways.
For instance, we may proceed as follows.
(1) choose a certain number of b′
is, such that b2
i mod n is small, but not too
much (see Remark 6.4.6): for instance, take bk = ⌊
√
nk⌋+ 1, for k =
1, 2, 3, . . .;
(2) factor these numbers, rejecting those having in their factorisation too large
prime factors, for instance greater than a number M ﬁxed beforehand;
(3) choose the factor basis B starting from the factorisation of the numbers
b2
i mod n, including in it, in increasing order, the primes appearing in the
factorisation of the numbers b2
i mod n.
This is a more realistic method, but it requires anyhow the preliminary
factorisation of several quite large numbers, if the method is to work.
In the next examples we shall consider some factorisations we already
know, getting them again using this method.
Example 6.4.7. Factor 559 using the method of factor bases.
Set bk = ⌊
√
nk⌋+ 1, k = 1, 2, 3, . . . Depending on the primes appear-
ing in the factorisation of these numbers we shall decide how to choose the
factorisation basis B. The ﬁrst values are:
b
b2
b2 mod 559 Prime decomposition of b2 mod 559
b1 = 24
576
17
17
b2 = 34 1156
38
2 · 19
b3 = 41 1681
4
22
Now we stop, using only the third line, as we have found b = 41 such
that b2 ≡22 (mod 559). So we take B = {2} and b = 41 and c = 2. Then
b ̸≡±2, so computing GCD(41 −2, 559) we obtain the non-trivial factor 13.
Thus, 559 = 13 · 43.
Example 6.4.8. Factor 2183 using the method of factor bases.
Again, set bk = ⌊
√
nk⌋+ 1, k = 1, 2, 3, . . .

298
6 Primality and factorisation tests
b
b2
b2 mod 2183 Prime decomposition of b2 mod 2183
b1 = 47
2209
26
2 · 13
b2 = 67
4489
123
123
b3 = 81
6561
12
22 · 3
b4 = 94
8836
104
23 · 13
b5 = 105 11025
110
2 · 5 · 11
b6 = 115 13225
127
127
b7 = 124 15376
95
5 · 19
b8 = 133 17689
225
32 · 52
b9 = 141 19881
234
22 · 3 · 13
Since b8 is a product of two squares, we can ﬁnd from this the required
factorisation: indeed, 1332 ≡152 (mod 2183), 133 ̸≡±15 (mod 2183) and
GCD(148, 2183) = 37. Thus 2183 = 37 × 59.
However, in order to illustrate how the method works, suppose we did not
recognise the squares in b8. This forces us to go on in the algorithm.
Notice that four of the b′
is, and precisely b1, b3, b4, b9, factor with three
primes, 2, 3, and 13. So we may take as factor basis B = {2, 3, 13}. The
corresponding matrix E of the exponents modulo 2 is
E =
⎛
⎜
⎜
⎝
1 0 1
0 1 0
1 0 1
0 1 1
⎞
⎟
⎟
⎠.
Summing the ﬁrst and third row we get a row of zeros. These rows corre-
spond to b1 and b4. Taking the element b = b1·b4 we get b2 mod 2183 = 24·132.
So b2 ≡c2 (mod 2183) with b = 4418 and c = 22 · 13 = 52.
We check now whether b ≡±c (mod 2183): unfortunately 4418 −52 =
4366 ≡0 (mod 2183). As there is no other way to add the rows so as to get a
zero row, we have to add more B-numbers, possibly changing B itself. Notice
that:
b
b2
b2 mod 2183 Prime decomposition of b2 mod 2183
b10 = 48
2183
74
2 · 37
b11 = 155 24025
12
22 · 3
b15 = 181 32761
16
24
We have found a B-number, b15 = 181, and b2
15 is a square mod 2183.
As 181 ̸≡±4 (mod 2183), computing GCD(181 + 4, 2183) = 37 yields the
factorisation 2183 = 37 · 59.
In the previous example we have seen that, before ﬁnding a B-number mod
2183 that is a square and gives a non-trivial relation yielding a factorisation
of 2183, some work has been necessary. This suggests that we should look for
a more eﬃcient method for ﬁnding b′
is such that the numbers b2
i mod n factor
into small enough primes. We shall see in next section how to do so.

6.4 Factorisation methods
299
Remark 6.4.9. We may ask the computational cost of the algorithm de-
scribed in this section. It is not easy to estimate it. A quite rough estimate may
be obtained under some hypotheses with only probabilistic justiﬁcations. The
estimate for the computational cost of the algorithm is O(eC√log n log log n),
where C is a constant. So it is exponential. We do not give here the details
of the long and complex derivation of this estimate: the interested reader can
ﬁnd it in [30], pages 148–153.
6.4.4 Factorisation and continued fractions
To attack the problem left unsolved at the end of the previous section, the theory
of continued fraction comes to our aid (see § 1.5).
Recall the notion of least absolute residue, deﬁned on page 61.
Proposition 1.5.21 on page 61 implies that the least absolute residues of the
squares of the numerators of the convergents of the continued fraction of √n are
reasonably small with respect to n. So it is likely that they are easier to factor than
n. Thus these convergents are good candidates for the choice of numbers b1, . . . , bK
in the method of factor bases. As now the integer LAR(m, n) may well be negative,
we modify slightly the deﬁnition of a B-number modulo an odd positive integer n
with respect to a factor basis B:
Deﬁnition 6.4.10. If B = (p1, . . . , pN) is a factor basis in which p1, . . . , pN are
distinct prime numbers, a number is said to be a B-number modulo an odd positive
integer n if in the factorisation of LAR(m, n) only the primes p1, . . . , pN occur,
possibly taken with the minus sign, that is, if
LAR(m, n) = ±pα1
1 · · · pαh
h .
For a B-number m the B-vector v(m) ∈N and the reduced B-vector w(m) ∈ZN
2
of m modulo n may be considered, as in Deﬁnition 6.4.5.
Example 6.4.11. If B = {2, 3}, the number 989 is a B-number modulo 205. Indeed,
LAR(989, 205) = −36 and 36 = 22 ·32. The B-vector of 989 is (2, 2) and the reduced
B-vector is the zero vector (0, 0).
We now show how to choose a B-basis and the numbers b1, . . . , bK to factor a
non-square number n using the expression of √n as a continued fraction:
(1) consider the numerators u1, . . . , uH of the ﬁrst H convergents of the continued
fraction of √n, which is periodic, as seen in § 1.5.3;
(2) compute next the numbers LAR(u2
i , n), for i = 1, . . . , H, and factor them. This
operation, by Proposition 1.5.21, is distinctly easier than factoring n, so we may
hope to be able to carry it out;
(3) among the numbers LAR(u2
i , n), for i = 1, . . . , H, reject the numbers in whose
factorisation too large prime factors appear, for instance larger than a number
M ﬁxed in advance. Let b1, . . . , bK be the numbers among u1, . . . , uH chosen in
this way;
(4) choose the factorisation basis B = (p1, . . . , pN) considering the factorisation of
the numbers LAR(b2
i , n), i = 1, . . . , K, including in it, in increasing order, the
primes appearing in these factorisations.

300
6 Primality and factorisation tests
Even in the case when N is not too large, so K is not either, starting from B
and b1, . . . , bK usually we get in a short time the factorisation of n, if n is not prime.
Let us see an example of use of this method.
Example 6.4.12. Factor the number n = 2921.
We need to compute the expression of
√
2921 as a continued fraction, by ﬁnding
its convergents Ck = uk/vk for the ﬁrst values of k:
k
1
2
3
4
5
uk
1135 1189 2324 3513 5837
vk
21
22
43
65
108
and draw the corresponding list of values u′
k = uk (mod 2921) and ak = LAR
(u2
k, 2921):
k
1
2
3
4
5
u′
k
1135 1189 2324 592 2916
ak
64
−43
47
−56
25
Then it makes sense to choose B = {2, 5} and to take as B-numbers the aks for
k = 1, 5, as they are already squares. The method just described guarantees that
b = 1135·2916 ≡167 (mod 2921) and c = 23 ·5 = 40 are such that b2 ≡c2 (mod n),
that is 1672 ≡402 (mod 2921). On the other hand, 167 ̸≡±40 (mod 2921). Thus,
GCD(167 + 40, 2921) = 23 is a proper factor of 2921, hence we get the factorisation
2921 = 23 · 127.
6.4.5 The quadratic sieve algorithm
This method was invented by C. Pomerance in 1981. We shall decribe it heuristically,
without giving a proof of why it works. Nor we shall discuss its computational cost
which, although exponential as all known factorisation methods, is in some cases
more convenient than others. Before more recent techniques, as the number ﬁeld
sieve [33], the quadratic sieve, which is a variation of the method of the factor bases,
was the most eﬃcient factorisation algorithm. It is still the fastest way to factor
numbers up to about one hundred digits.
Here too, the goal is to have a factor basis B containing small enough numbers
and to ﬁnd a suﬃcient number of B-numbers mod n that are easy to be factored.
To this end we may proceed as follows:
•
take as B the set of all primes smaller than a suitably chosen integer M, and
such that ( n
p ) = 1;
•
choose as b′
is, as for the originary Fermat factorisation method, the integers
⌊√n⌋+ i, i = 1, 2, 3, . . . , T , with T suitably ﬁxed in advance too;
•
usually both M and T are chosen around e
√log n log log n with M < T < M 2;
•
deﬁne next
q(bi) := b2
i −n.
The q(bi)′s are in the set
S := {b2 −n |⌊√n⌋+ 1 ≤b ≤⌊√n⌋+ T}
and are our candidates for B-numbers mod n.

6.4 Factorisation methods
301
Let us see how the algorithm works:
•
begin by constructing a table T with the rows corresponding to the integers
q(bi) = b2
i −n, i = 1, . . . , T ;
•
ﬁx a prime p in B, with p odd. All the operations (a), (b), (c) and (d) that follow
refer to this ﬁxed prime p;
(a) solve the congruences
x2 ≡n
(mod ph),
h = 1, 2, . . . ,
until there are no more solutions b in the interval I = [⌊√n⌋+ 1, ⌊√n⌋+ T];
(b) call α the largest integer such that the equation
x2 ≡n
(mod pα)
(6.34)
admits a solution in the interval I and let ¯b1 and ¯b2 ≡−¯b1 be two solutions
of (6.34) (see Example 5.2.10). These solution do not necessarily belong to
the interval I;
(c) keep building on the table T inserting a 1 near each q(bi) such that bi ≡¯b1
(mod p), a 2 (possibly substituting it for a previous 1) near each q(bi) such
that bi ≡¯b1 (mod p2), a 3 (possibly substituting it for a previous 2) near
each q(bi) such that bi ≡¯b1 (mod p3) and so on. In this way, under the ﬁrst
p we obtain a column in which some integers h ∈{0, 1, . . . , α} appear;
(d) each time a 1 is inserted, or a 1 is increased to 2, or a 2 to 3 and so on, at
the same time divide by p the corresponding q(bi) and write down the new
result;
(e) repeat the same operation starting with ¯b2;
•
repeat the previous operations (a), (b), (c) and (d) for every odd prime in B;
•
if p = 2:
(a) if n ̸≡1 (mod 8) insert a 1 near the q(bi)s with odd bi and at the same time
divide q(bi) by 2;
(b) if n ≡1 (mod 8), denoting as in (b) above by α the largest integer such that
the equation
x2 ≡n
(mod 2α)
admits a solution in the interval I = [⌊√n⌋+1, ⌊√n⌋+T], proceed as for odd
p, but for the fact that we can ﬁnd four congruent roots modulo 2α rather
than two (see Exercise A6.20);
•
after concluding the previous operations for all p in B, eliminate (hence the name
of sieve) all the q(bi)′s, except those that became 1 after the division by all the
powers of the ps in B. After this sieving, the remaining q(bi)′s are B-numbers,
with bi ∈[⌊√n⌋+ 1, ⌊√n⌋+ T];
•
to ﬁnd a square q(bi), proceed as in the method of the factor bases, using Gaus-
sian elimination in order to ﬁnd a zero row.
Remark 6.4.13. Before an example we give some remarks about the steps of the
algorithm:
•
the ﬁrst check that the integer n to be factored is a quadratic residue with respect
to the primes in the factor basis, that is to say, that ( n
p ) = 1, is done using the
properties of Legendre symbol and the law of quadratic reciprocity (see § 5.2.4).

302
6 Primality and factorisation tests
For instance, assume we want to factor n = 1003. To construct a factor basis we
have to exclude the primes with respect to which n is not a quadratic residue.
We have
1003
3

=
1
3

= 1
so 3 may be included in B,
1003
5

=
3
5

=
5
3

=
 2
3

= −1
so 5 must be rejected,
1003
7

=
2
7

= 1
so 7 may be included in B;
•
as regards step (a) in the algorithm, we are able to solve congruences modulo
odd prime powers with the techniques seen in § 5.2;
•
as regards step (c), once we know two solutions ¯b1 and ¯b2 ≡−¯b1 (mod pα), in
order to ﬁnd the values bi ≡¯b1 it suﬃces to take every p-th bi, as they are
consecutive integers, then skip to every p2-th one, and so on, with p in B;
•
when the operations are over with all primes in B, the only q(bi)′s to be kept
are the ones that, after the divisions by the p′s in B, became 1, because this
means that in their factorisation only primes in B appear.
Let us now show an example which, by obvious reasons, will not involve numbers
with many digits. So the eﬃciency of this method cannot be fully appreciated.
Example 6.4.14. Factor n = 56851 by using the quadratic sieve method.
Take as factor basis B the set of primes ≤M = 7, that is,
B := (2, 3, 5, 7).
Among the odd primes in B we have only to take those such that n is a quadratic
residue modulo p. As 56851 ≡1 both modulo 3 and modulo 5, and 56851 ≡4
(mod 7), which implies
 56851
7

=
4
7

= 1,
we get that 56851 is a quadratic residue modulo 3, modulo 5 and modulo 7. So we
keep all the primes in B.
Now set bi = ⌊√n⌋+ i, i = 1, 2, 3, . . . , T = 20.
By choosing T = 20 rather than T = 72 = 49, we are being optimist: to avoid a
column of 49 integers bi we prefer to risk some ineﬃciency, hoping for the best. Let
us see if our optimism will be rewarded.
We have ⌊
√
56851⌋= 238. Compute now q(bi) = b2
i −n, i = 1, . . . , T = 20:

6.4 Factorisation methods
303
b
q(b) = b2 −n
b1 = 239
57121 −56851 = 270
b2 = 240
57600 −56851 = 749
b3 = 241
58081 −56851 = 1230
b4 = 242
58564 −56851 = 1713
b5 = 243
59049 −56851 = 2189
b6 = 244
59536 −56851 = 2685
b7 = 245
60025 −56851 = 3174
b8 = 246
60516 −56851 = 3665
b9 = 247
61009 −56851 = 4158
b10 = 248
61504 −56851 = 4653
b11 = 249
62001 −56851 = 5150
b12 = 250
62500 −56851 = 5649
b13 = 251
63001 −56851 = 6150
b14 = 252
63504 −56851 = 6653
b15 = 253
64009 −56851 = 7158
b16 = 254
64516 −56851 = 7665
b17 = 255
65025 −56851 = 8174
b18 = 256
65536 −56851 = 8685
b19 = 257
66049 −56851 = 9198
b20 = 258
66564 −56851 = 9713
As we remarked, we shall work separately with each p ∈B. In the tables we are
going to construct we set up the columns for all p′s, but we shall ﬁll them in only
later.
We shall denote by Mp(I) the greatest exponent h of p for which the equation
x2 ≡n
(mod ph)
(6.35)
admits solutions in the interval I = [⌊√n⌋+ 1, ⌊√n⌋+ 20].
Begin with the odd prime 3 in B. By solving the congruences x2 ≡n (mod ph),
h = 1, 2, . . ., we conclude that M3(I) is 3. The solutions of the equation x2 ≡n
(mod 33) are ¯b1 = b1 and ¯b2 ≡−¯b1 (mod 33).
Begin with b1 = 239, which shall be written in bold in the tables, as it is the
starting point for the skips for 3. By taking all bi ≡b1 (mod 3), that is, by skipping
to every third value starting from b1, we clearly obtain b1, b4, b7, b10, b13, b16, b19.
Put a 1 near them and at the same time divide the correponding q(bi)′s (i =
1, 4, 7, 10, 13, 16, 19) by 3: we know that they are divisible by 3, as these b′
is are
congruent to b1 modulo 3.

304
6 Primality and factorisation tests
b
q(b) = b2 −n
p = 2
p = 3
p = 5
p = 7
b1 = 239
90
1
b2 = 240
749
b3 = 241
1230
b4 = 242
571
1
b5 = 243
2198
b6 = 244
2685
b7 = 245
1058
1
b8 = 246
3665
b9 = 247
4158
b10 = 248
1551
1
b11 = 249
5150
b12 = 250
5649
b13 = 251
2050
1
b14 = 252
6653
b15 = 253
7158
b16 = 254
2555
1
b17 = 255
8174
b18 = 256
8685
b19 = 257
3066
1
b20 = 258
9713
Skipping to every 32-th term starting from b1, that is in b1, b10 and b19, we
change 1 into 2 and divide the corresponding q(bi) (which shall still be called this
way, even if it has already been divided by 3): we are certain that q(b10), q(b19) are
again divisible by 3.
b
q(b) = b2 −n
p = 2
p = 3
p = 5
p = 7
b1 = 239
30
2
b2 = 240
749
b3 = 241
1230
b4 = 242
571
1
b5 = 243
2198
b6 = 244
2685
b7 = 245
1058
1
b8 = 246
3665
b9 = 247
4158
b10 = 248
517
2
b11 = 249
5150
b12 = 250
5649
b13 = 251
2050
1
b14 = 252
6653
b15 = 253
7158
b16 = 254
2555
1
b17 = 255
8174
b18 = 256
8685
b19 = 257
1022
2
b20 = 258
9713

6.4 Factorisation methods
305
If we now skip to every 33-th term starting from b1 we do not ﬁnd any bi in our
interval, apart from b1, so change 2 into 3 and divide q(b1) by 3. We get:
b
q(b) = b2 −n
p = 2
p = 3
p = 5
p = 7
b1 = 239
10
3
b2 = 240
749
b3 = 241
1230
b4 = 242
571
1
b5 = 243
2198
b6 = 244
2685
b7 = 245
1058
1
b8 = 246
3665
b9 = 247
4158
b10 = 248
517
2
b11 = 249
5150
b12 = 250
5649
b13 = 251
2050
1
b14 = 252
6653
b15 = 253
7158
b16 = 254
2555
1
b17 = 255
8174
b18 = 256
8685
b19 = 257
1022
2
b20 = 258
9713
Now repeat everything starting from −b1 = −239, which does not belong to our
interval. The ﬁrst bi that is congruent to −239 modulo 27 is b9, which we write in
bold; we now repeat the previous operations on all the bi ≡b9 (mod 3): b3, b6, b9,
b12, b15, b18.

306
6 Primality and factorisation tests
b
q(b) = b2 −n
p = 2
p = 3
p = 5
p = 7
b1 = 239
10
3
b2 = 240
749
b3 = 241
410
1
b4 = 242
571
1
b5 = 243
2198
b6 = 244
895
1
b7 = 245
1058
1
b8 = 246
3665
b9 = 247
1386
1
b10 = 248
517
2
b11 = 249
5150
b12 = 250
1883
1
b13 = 251
2050
1
b14 = 252
6653
b15 = 253
2386
1
b16 = 254
2555
1
b17 = 255
8174
b18 = 256
2895
1
b19 = 257
1022
2
b20 = 258
9713
We inserted a 1 near b3, b6, b9, b12, b15, b18 and divided the corresponding q(bi)′s by
3: we knew that they were divisible by 3, as these b′
is are congruent to b9 modulo 3.
Skip now to every 9-th term, again starting from b9, and change 1 into 2 for b9
and b18, and divide q(b9) and q(b18) by 3. We obtain:
b
q(b) = b2 −n
p = 2
p = 3
p = 5
p = 7
b1 = 239
10
3
b2 = 240
749
b3 = 241
410
1
b4 = 242
571
1
b5 = 243
2198
b6 = 244
895
1
b7 = 245
1058
1
b8 = 246
3665
b9 = 247
462
2
b10 = 248
517
2
b11 = 249
5150
b12 = 250
1883
1
b13 = 251
2050
1
b14 = 252
6653
b15 = 253
2386
1
b16 = 254
2555
1
b17 = 255
8174
b18 = 256
965
2
b19 = 257
1022
2
b20 = 258
9713
and ﬁnally:

6.4 Factorisation methods
307
b
q(b) = b2 −n
p = 2
p = 3
p = 5
p = 7
b1 = 239
10
3
b2 = 240
749
b3 = 241
410
1
b4 = 242
571
1
b5 = 243
2198
b6 = 244
895
1
b7 = 245
1058
1
b8 = 246
3665
b9 = 247
154
3
b10 = 248
517
2
b11 = 249
5150
b12 = 250
1883
1
b13 = 251
2050
1
b14 = 252
6653
b15 = 253
2386
1
b16 = 254
2555
1
b17 = 255
8174
b18 = 256
965
2
b19 = 257
1022
2
b20 = 258
9713
So the case p = 3 is over. Consider now p = 5. We ﬁnd M5(I) = 2.
Starting from b11, which is a solution of b2 ≡n (mod 52) and which we shall
write as usual in bold, the b′
is congruent to b11 (mod 5) are b1, b6, b16.
Take next the other solution −b11 = −249 (mod 52). The solution congruent
mod 52 that lies in the interval I is b13 = 251: we shall write it in bold. The b′
is
congruent to b13 modulo 5 lying in the interval are b3, b8, b13, b18. By performing the
usual operations we obtain the following table:

308
6 Primality and factorisation tests
b
q(b) = b2 −n
p = 2
p = 3
p = 5
p = 7
b1 = 239
2
3
1
b2 = 240
749
b3 = 241
82
1
1
b4 = 242
571
1
b5 = 243
2198
b6 = 244
179
1
1
b7 = 245
1058
1
b8 = 246
733
1
b9 = 247
154
3
b10 = 248
517
2
b11 = 249
206
2
b12 = 250
1883
1
b13 = 251
82
1
2
b14 = 252
6653
b15 = 253
2386
1
b16 = 254
511
1
1
b17 = 255
8174
b18 = 256
193
2
1
b19 = 257
1022
2
b20 = 258
9713
Consider now the prime p = 7 in B and repeat the same procedure. We ﬁnd
M7(I) = 1.
The ﬁrst solution of x2 ≡n (mod 7) in the interval I is b2: write it in bold. The
bis that are congruent to b2 modulo 7 are b2, b9, b16. The other solution −b2 = −240
is congruent to b5 modulo 7: write down it in bold. All the b′s congruent modulo 7
in the interval are b5, b12, b19. In conclusion we obtain the Table 6.1 on page 309.
We performed the operations with all the odd primes in B. We still have the
prime p = 2. As 56851 ̸≡1 (mod 8), the column under the prime p = 2 is completed
by inserting a 1 near the odd b′s, as in Table 6.2 on page 310.
There is a single bi such that the corresponding q(bi) became 1. This means that
b1 is the only B-number in I. As q(b1) is not a square, we are forced to enlarge the
interval I to a larger interval I′, that is to say, we have to add more b′
is. It appears
we have been too optimist when choosing T = 20. We enlarge the interval I by
setting T = 40 rather than T = 20, adding b21, . . . , b40. From the previous elements
q(bi), i = 1, . . . , 20, we can only keep the unique B-number, discarding all the others
which are useless, unless we enlarge the basis B.
Now, however, we have to study again the congruences
x2 ≡n
(mod ph),
for p ∈B and the diﬀerent values of h.
In fact, it might well happen that Mp(I′) increases, the interval being diﬀerent. We
ﬁnd indeed that b36 = 274 is such that q(b36) is a multiple of 36.
We insert b36 in bold: for the ﬁrst p = 3 the value b36 will be the new starting
point. As regards p = 5, instead, the previous numbers remain, while M7(I′) = 2,
corresponding to b40. But we are in for a surprise, which luckily saves us from further
computations. In fact, from the table

6.4 Factorisation methods
309
Table 6.1. Procedure applied to p = 7
b
q(b) = b2 −n
p = 2
p = 3
p = 5
p = 7
b1 = 239
2
3
1
b2 = 240
107
1
b3 = 241
82
1
1
b4 = 242
571
1
b5 = 243
314
1
b6 = 244
179
1
1
b7 = 245
1058
1
b8 = 246
733
1
b9 = 247
22
3
1
b10 = 248
517
2
b11 = 249
206
2
b12 = 250
269
1
1
b13 = 251
82
1
2
b14 = 252
6653
b15 = 253
2386
1
b16 = 254
73
1
1
1
b17 = 255
8174
b18 = 256
193
2
1
b19 = 257
146
2
1
b20 = 258
9713
b
q(b) = b2 −n
post-divisioni
p = 2
p = 3
p = 5
p = 7
b1 = 239
270
1
1
3
1
b36 = 274
18225
1
6
2
we read that q(b36) is a B-number and is a square, being equal to 36 ·52. Notice that
it might have happened that no q(bi) had these properties. In this case we should
either further widen the interval I′ or enlarge the factor basis. Luckily, it was right
as it were.
In conclusion, with the old simple Fermat factorisation method, we have
n = 56851 = (274)2 −(33 · 5)2 = (274 −135)(274 + 135) = 139 · 409.
6.4.6 The ρ method
The factorisation methods described in the previous sections are essentially more
or less reﬁned variations of the simple Fermat factorisation method expounded in
§ 6.4.1. The factorisation method we describe now relies on a completely diﬀerent
idea.
Assume we know that a number n is composite. To decompose it into primes we
proceed as follows, working in Zn:
•
in the ﬁrst step we choose an easily computable map from Zn to itself, for in-
stance a non-linear polynomial f(x) with integer coeﬃcients that does not induce
a bijection of Zn to itself: most of the times, a good choice is the polynomial
f(x) = x2 + 1;

310
6 Primality and factorisation tests
•
choose next an arbitrary element x0 of Zn. Construct the following sequence
{ x1, x2, . . . , xj, . . . } of integers modulo n:
x1 = f(x0),
x2 = f(x1) = f(f(x0)) = f 2(x0),
...
xj = f(xj−1) = f j(x0),
and so on. Notice that this sequence has a ﬁnite number of distinct elements, as
Zn is ﬁnite. So there are positive integers k and h with xk ≡xh (mod n) and
k > h. If h is the least positive integer such that this happens, it is clear that the
meaningful elements of the sequence {xn}n∈N are x1, . . . , xk−1, as xk+i = xh+i
for all i ∈N;
•
for every pair xi and xj compute GCD(xi −xj, n). If this greatest common
divisor is not equal to 1 nor to n, we have found a proper divisor of n.
Example 6.4.15. Assume we want to factor the number 111.
Choose the polynomial f(x) = x2 + 1.
Set x0 = 1. We have
x0 = 1,
x1 = 2,
x2 = 5,
x3 = 26,
x4 = 677 ≡11
(mod 111),
x5 = 122 ≡11
(mod 111).
Table 6.2. Procedure applied to p = 2
b
q(b) = b2 −n
p = 2
p = 3
p = 5
p = 7
b1 = 239
1
1
3
1
b2 = 240
107
1
b3 = 241
41
1
1
1
b4 = 242
571
1
b5 = 243
157
1
1
b6 = 244
179
1
1
b7 = 245
529
1
1
b8 = 246
733
1
b9 = 247
11
1
3
1
b10 = 248
517
2
b11 = 249
103
1
2
b12 = 250
269
1
1
b13 = 251
41
1
1
2
b14 = 252
6653
b15 = 253
1193
1
1
b16 = 254
73
1
1
1
b17 = 255
4087
1
b18 = 256
193
2
1
b19 = 257
73
1
2
1
b20 = 258
9713

6.4 Factorisation methods
311
We have found the same class, so we stop. Let us compute the diﬀerences and the
GCD(xi −xj, 111):
x1 −x0 ≡1
x2 −x0 ≡4,
GCD(4, 111) = 1,
x3 −x0 ≡25,
GCD(25, 111) = 1,
x4 −x0 ≡10,
GCD(10, 111) = 1,
x2 −x1 = 3,
GCD(3, 111) = 3.
We found a proper divisor of 111 and we may conclude 111 = 3 · 37. It is obvious
that for small numbers we do not actually need these algorithms; it is clear, in fact,
that 111 is divisible by 3.
When the number n is large, computing all the GCD(xi −xj, n), for all j < i,
may be very expensive. Here follows a variation of the algorithm which improves its
eﬃciency.
6.4.7 Variation of ρ method
We keep the above notation. If i and j satisfy xi ≡xj (mod r) with r a proper
divisor of n, then it will also be the case that xi′ ≡xj′ (mod r) for all i′ and j′
such that i −j = i′ −j′. Indeed, if i −j = i′ −j′, setting i′ = i + t, j′ = j + t and
keeping in mind that f t(xi) = xi+t, it suﬃces to apply t times the polynomial f to
both sides of congruence xi ≡xj (mod r), to get xi′ ≡xj′ (mod r).
Compute again xk for every k and then proceed as follows. Assume k has length
h + 1 in base 2, that is, 2h ≤k < 2h+1. Compute GCD(xk −xj, n), for j = 2h −1.
If this gives a proper factor of n we stop, otherwise we consider k + 1 next.
The interest of this method lies in the fact that, for each k, we have to compute
a single greatest common divisor. The disadvantage, of course, is that we might fail
to detect a proper factor of n the ﬁrst time it might appear: that is, the ﬁrst time
we encounter a pair (k0, j0) with j0 < k0 such that GCD(xk0 −xj0, n) = r > 1.
However, after a while, we are sure to ﬁnd the factor we are looking for. Indeed,
if k0 has length h+1 in base 2, set j = 2h+1−1 and let k = j+(k0−j0). By what has
been said, we have GCD(xk −xj, n) > 1. Notice that k < 2h+2 = 4 · 2h ≤4k0, so we
shall not have to wait long, when compared with the standard ρ method described
above, before getting a proper factor of n.
Example 6.4.16. Factor n = 3713 using the polynomial f(x) = x2 +1 and starting
from x0 = 1 with the improved ρ method.
Here are the steps of the procedure (checking the computations is left to the
reader):
x1 = f(x0) = 2,
GCD(x1 −x0, n) = 1,
x2 = f(x1) = 5,
GCD(x2 −x1, n) = 1,
x3 = f(x2) = 26,
GCD(x3 −x1, n) = 1,
x4 = f(x3) = 677,
GCD(x4 −x3, n) = 1,
x5 = f(x4) ≡1631
(mod n),
GCD(x5 −x3, n) = 1,
x6 = f(x5) ≡1654
(mod n),
GCD(x6 −x3, n) = 1,
x7 = f(x6) ≡2949
(mod n),
GCD(x7 −x3, n) = 79

312
6 Primality and factorisation tests
obtaining the factorisation 3713 = 79 · 47. The reader will fruitfully compare this
method with the standard ρ method (see Exercises B6.37 and B6.38).
As to the computational complexity of the ρ method, here follows the main
result. Notice the probabilistic quality and the exponential nature of the method.
Theorem 6.4.17. Let n be a composite odd positive integer. Assume x0 and f(x)
have been chosen in a suﬃciently general way. For every real number λ > 0 the
probability that the ρ method does not yield a proper factor of n in O( 4√n log3 n) bit
operations is smaller than e−λ.
We give now a sketch of the proof.
Let X be a set of order k. Let F(X) be set of all maps f : X →X. Notice that
F(X) has order kk (see Exercise A1.20).
Let f : X →X be a map. Let x ∈X and deﬁne recursively a sequence {xf,x
n }n∈N
of elements of X as follows:
xf,x
0
= x,
xf,x
i+1 = f(xf,x
i
),
i ≥0.
Let m a positive integer number. We shall denote by Gm(X) the subset of
X × F(X) consisting of all pairs (x, f) such that xf,x
0 , . . . , xf,x
m
are all distinct.
Denote by gm(X) the order of the set Gm(X). Clearly, gm(X) = 0 if m > k. The
reader can verify as an exercise (see Exercise A6.28) that, if m ≤k, we have
gm(X) = kk−m
m
'
i=0
(k −i).
(6.36)
Lemma 6.4.18. Let α be a positive real number. Set a = 1 + ⌊
√
2αk⌋. We have
eαga(X) < kk+1,
that is to say, the ratio between the order of Ga(X) and the order of X × F(X) is
smaller than e−α.
Proof. That ratio is
ga(X)
kk+1 ≤k−a−1
a
'
i=0
(k −i) =
a
'
i=1

1 −i
k

.
Keeping in mind that log(1 −x) < −x if 0 < x < 1 (see Exercise A6.29), we have
log
 a
'
i=1

1 −i
k

< −
a

i=1
i
k = −a(a + 1)
2k
< −a2
2k
< −α,
as was to be proved.
⊓⊔
This lemma gives a crucial information about the possible duration of the ρ
method, yielding the following proof.

A6 Theoretical exercises
313
Proof of Theorem 6.4.17. Remember that computing m mod n has complexity
O(log2 n) and computing a greatest common divisor GCD(m, n) with 0 < m < n
has complexity O(log3 n).
Fix a proper divisor r of n, with r < √n. If k0 is the least index such that there
exists a j0 < k0 with xk0 ≡xj0 (mod r), then the ρ method, improved as described
in this section, ﬁnds a divisor of n in the k-th step, with k < 4k0. So the complexity
of the algorithm is O(k0 log3 n). On the other hand, by Lemma 6.4.18 the probability
that k0 > 1 + ⌊
√
2λr⌋is smaller than e−λ. If, instead, k0 ≤1 + ⌊
√
2λr⌋, then the
complexity of the algorithm is O(
√
2λr log3 n) = O( 4√n log3 n).
⊓⊔
Remark 6.4.19. In the preceding proof a fundamental role is played by the hy-
pothesis that x0 and f(x) are chosen in a suﬃciently general way, namely that the
pair (x0, f) is suﬃciently general in X ×F(X). If this is not the case, the probability
computation we carried out in the proof does not work. The assumption can be trans-
lated in the fact that we may choose an easily computable function f : Zn →Zn,
for instance a polynomial that both has this property and is suﬃciently general as
said. This has not been fully proved, but practical knowledge suggests that several
polynomials, among which x2 + 1, behave well in this regard.
Appendix to Chapter 6
A6 Theoretical exercises
A6.1.* Prove that if n is a pseudoprime in base 2, then m = 2n −1 is a pseudoprime
in base 2 too. Deduce that there exist inﬁnitely many pseudoprimes in base 2.
A6.2. Prove that if n is a pseudoprime in base b and if b−1 is coprime with n, then
(bn −1)/(b −1) is pseudoprime in base b. Deduce that there exist inﬁnitely many
pseudoprimes in base 3 and in base 5.
A6.3. Prove part (a) of Proposition 6.1.3.
A6.4. Which properties do Carmichael numbers possess?
(a) They are prime numbers.
(b) They are product of at most two distinct primes.
(c) There are ﬁnitely many of them.
(d) None of the above.
A6.5. Prove Proposition 6.1.11.
A6.6. Conclude the proof of Proposition 6.1.10.
A6.7. Prove that if n is a strong pseudoprime in base b, then n is a pseudoprime in
base b as well.
A6.8.* Prove that if n is pseudoprime in base 2 then m = 2n −1 is a strong
pseudoprime in base 2. Deduce that there are inﬁnitely many strong pseudoprimes
in base 2.

314
6 Primality and factorisation tests
A6.9.* Conclude the proof of Proposition 6.1.19 discussing the case r = s −1.
A6.10. Prove that, if n is an Euler pseudoprime in base b and if ( b
n) = −1, then n
is a strong pseudoprime in base b.
A6.11.* Verify that the complexity of the Miller–Rabin algorithm is O(k log4 n),
where k is the number of times the test is repeated.
A6.12.* Show that, if h ≥3, in the group U(2h) the cyclic groups ⟨5⟩and ⟨−1⟩
have the single element 1 in common.
A6.13.* Let G be a direct product of cyclic groups of orders g1, . . . , gn. Prove that
the least g such that xg = 1 for all x ∈G is the least common multiple of g1, . . . , gn.
A6.14. Complete the proof of part (b) of Proposition 6.1.6 (see 277).
A6.15. Prove Lemma 6.2.17.
A6.16.* Let n be a positive integer. Prove that ,
0<m<n,GCD(n,m)=1 m ≡1 (mod n)
unless n is one of the numbers 2, 4, ph, 2ph, with p an odd prime and h a positive
integer; in this case, ,
0<m<n,GCD(n,m)=1 m ≡−1 (mod n). This result is due to
Gauss.
A6.17. Let n = 2lpl1
1 · · · pls
s be a positive integer with its factorisation. Consider the
equation xh ≡m (mod n), where h is a positive integer and m is an integer coprime
with n. Prove that this equation admits solutions if and only if the equations xh ≡m
(mod 2l), xh ≡m (mod pli
i ) (i = 1, . . . , s) do, and that the number d of its solutions
equals the product of the numbers of solutions of the latter equations.
A6.18. Consider the equation xh ≡m (mod pl), where either h is an integer, p
an odd prime and l an arbitrary positive integer, or p = 2 and 1 ≤l ≤2, and
moreover p ∤m and p ∤h. Prove that this equation admits solutions if and only
if the equation xh ≡m (mod p) does, and that they have the same number of
solutions d = GCD(h, p −1).
A6.19.* Consider the equation xh ≡m (mod 2l), where h is an integer, l ≥3 is a
positive integer and m is odd. Prove that if h is odd the equation admits exactly
one solution. Prove next that if h is even, setting d = GCD(h, 2l−2), the equation
admits solutions if and only if m2l−2/d ≡1 (mod 2l) and m ≡1 (mod 4), and in
this case it has exactly 2d solutions.
A6.20. Prove that, for p = 2 and n odd, the congruence equation (6.34) has at most
four solutions.
A6.21.* Keeping in mind the structure theorems about U(Zn), extend the notion of
index to the case where there are no primitive roots modulo n. For instance, extend
Proposition 6.2.20.
A6.22. Prove that, for all positive integer m, lcm(1, 2, . . . , m) ≥2m.
A6.23.* Prove that a product of numbers that are introspective for a polynomial
f(x) is introspective for the same polynomial and that if a number is introspective
for two polynomials, then it is introspective for their sum and their product.
A6.24.* Verify Equation (6.32).

B6 Computational exercises
315
A6.25.* Prove that there is an algorithm of complexity O∼(log4 n) that determines
whether a positive integer n is a power of another positive integer m. (Recall the
deﬁnition of O∼, introduced in the proof of Theorem 6.3.8)
A6.26.* Verify that there is an algorithm of complexity O(r2 log3 n) that computes
(x + a)n modulo xr −1 and modulo n.
A6.27. Verify that the Fermat factorisation method has exponential complexity.
A6.28.* Verify Equation (6.36) on page 312.
A6.29. Prove that log(1 −x) < −x se 0 < x < 1.
A6.30. Let n be a positive integer and let q be a prime number dividing n. Prove
that, if α is the greatest positive integer such that qα | n, then qα does not divide
n
q
	
.
A6.31. Assume that an integer number is composite and its factors are small. Which
factorisation method is the most convenient?
(a) The ρ method.
(b) Fermat method.
(c) The sieve of Eratosthenes.
(d) The quadratic sieve.
B6 Computational exercises
B6.1. Verify that 390 ≡1 (mod 13).
B6.2. Determine all the bases b for which 14 is a pseudoprime.
B6.3. Determine the least positive integer n that is a pseudoprime in base 3.
B6.4. Which of the following equals 290 (mod 91)?
(a) 1.
(b) 57.
(c) 64.
(d) None of the above.
B6.5. Is the number 179 a pseudoprime in base 2?
(a) Yes.
(b) No, because 2178 ̸≡1 (mod 179).
(c) No.
(d) None of the above.
B6.6. Is the number 341 a pseudoprime in base 2?
(a) Yes.
(b) No, because 2340 ̸≡1 (mod 341).
(c) No.
(d) None of the above.

316
6 Primality and factorisation tests
B6.7. Is the number 561 a pseudoprime in base 2?
(a) Yes.
(b) No, because 2560 ̸≡1 (mod 561).
(c) No, because 561 is prime.
(d) None of the above.
B6.8. Prove that 561 is the smallest Carmichael number.
B6.9. Are there Carmichael numbers of the form 5p with p a prime number?
B6.10. Are there Carmichael numbers of the form 15p with p a prime number?
B6.11. Find a Carmichael number that is divisible by 91.
B6.12. Show that 15841 is a Carmichael number.
B6.13. Show that 6601 is a Carmichael number.
B6.14. Show that the integer number 91 is not an Euler pseudoprime in base 3.
B6.15. Show that 15841 is an Euler pseudoprime in base 2.
B6.16. Find all bs such that 15 is an Euler pseudoprime in base b.
B6.17. Show that 15841 is a strong pseudoprime in base 2.
B6.18. Show that 65 is a strong pseudoprime in base 8.
B6.19. Find all bs such that 15 is a strong pseudoprime in base b.
B6.20. Find a primitive root modulo 9.
B6.21. Find a primitive root modulo 49.
B6.22. Find a primitive root modulo 81.
B6.23. Determine modulo which of the integers n = 2, 5, 35, 14, 25, 121 there is a
primitive root.
B6.24. Describe the structure of the group U(Z15).
B6.25. Describe the structure of the group U(Z16).
B6.26. Describe the structure of the group U(Z17).
B6.27. Describe the structure of the group U(Z18).
B6.28. Determine |U(15)|, |U(16)|, |U(17)|, |U(18)|.
B6.29. Determine ind5 7 modulo 9.
B6.30. Study the equation x3 ≡5 (mod 9).
B6.31. Study the equation x6 ≡7 (mod 25).
B6.32. Study the equation x4 ≡3 (mod 14).
B6.33. Find how many solutions has, at most, the equation x5 ≡3 (mod 21).
B6.34. Factor into primes the number 86989 using Fermat’s method. How many
steps are necessary to ﬁnd a factor of this number?

C6 Programming exercises
317
(a) 1.
(b) 3.
(c) 5.
(d) None of the above.
B6.35. Factor into primes the number 141553 using Fermat method. How many
steps are necessary to ﬁnd a factor of this number?
(a) 1.
(b) 3.
(c) 5.
(d) None of the above.
B6.36. Factor using the method of factor bases the number 906113.
B6.37. Factor 589 using the standard ρ method, using the polynomial f(x) = x2 +1
and starting from x0 = 2.
B6.38. Factor 589 using the improved ρ method, using the polynomial f(x) = x2+1
and starting from x0 = 2.
C6 Programming exercises
C6.1. Write a program that, given a non-prime positive integer n, ﬁnds all the bases
for which it is not a pseudoprime.
C6.2. Write a program that, given a positive integer b, ﬁnds the least n that is a
pseudoprime in base b.
C6.3. Write a program that ﬁnds all Carmichael numbers smaller than 10,000.
C6.4. Write a program that, given a non-prime positive integer n, ﬁnds all the bases
for which it is not an Euler pseudoprime.
C6.5. Write a program that, given a positive integer b, ﬁnds the least n that is an
Euler pseudoprime in base b.
C6.6. Write a program that performs the probabilistic primality test described in
§ 6.1.3.
C6.7. Write a program that performs the Solovay–Strassen probabilistic primality
test.
C6.8. Write a program that performs Miller–Rabin primality test.
C6.9. Write a program that determines whether a given integer is a k-th power of
another integer.
C6.10. Write a program that performs the AKS test.
C6.11. Write a program that, for every positive integer n < 100,000 ﬁnds whether
a primitive root modulo n exists and, if it does, ﬁnds such a root.

318
6 Primality and factorisation tests
C6.12. Write a program that decides whether a given integer m is an h-tuple residue
modulo n, when a primitive root modulo n exists.
C6.13. Write a program that factors an integer using Fermat factorisation method
described in § 6.4.2.
C6.14. Write a program that factors an integer using the method of factor bases
described in § 6.4.3.
C6.15. Write a program that factors an integer using the improved method of factor
bases described in § 6.4.4.
C6.16. Write a program that factors an integer using the quadratic sieve method
described in § 6.4.5.
C6.17. Write a program that factors an integer using the ρ method as described in
§ 6.4.6 or in § 6.4.7.

7
Secrets. . . and lies
How can we transmit information in such a way that only authorised persons
can understand it? How can we be sure that the information we transmit
reaches its destination without being altered? Moreover, how can we be sure
of the origin of a message, and so trust its content? In this chapter we shall deal
with these problems. We shall ﬁrst examine the earliest classic cryptographic
methods, rapidly outlining their development along the centuries, and then
we shall discuss the most recent research about public key cryptography. For
further details about the history and development of cryptography, the reader
can have a look at the good popular scientiﬁc book [58].
7.1 The classic ciphers
Humanity has always felt the need for eﬃcient methods to communicate in a
secret and secure way: by this we mean the ability of sending messages that
can be easily read by the addressees and cannot possibly be deciphered by
unauthorised people. This millennium-old problem is extremely important to-
day, when the advances in electronic communication systems make exchanging
information both easier and more vulnerable.
The earliest examples of secret messages appear in the Histories by
Herodotus, the Greek historian who lived in the 5th century BCE and chron-
icled the contemporary Greco-Persian wars.
7.1.1 The earliest secret messages in history
Herodotus was an extraordinary narrator: he had an unbelievable talent for reporting
what he had seen and been told in his travels in Asia Minor, Greece, Africa, Sicily
and so on.
In Book VII of the Histories he tell how Xerxes, having succeeded his father Dar-
ius, after crushing a repellion in Egypt, is about to wage war on Greece: preparations
for the expedition are made by creating a formidable army. The pages narrating this

320
7 Secrets. . . and lies
preparations are engrossing, with a survey of the army, a detailed portrayal of the
costumes and the armours of each of the peoples composing the Persian army, the
description of the ﬂeet. Finally, the expedition leaves: but somebody has warned the
Greeks of Xerxes’s actions and Book VII ends with following passage:
The Lacedemonians [= Spartans] had been informed before all others that the
king was preparing an expedition against Hellas; and thus it happened that they sent
to the Oracle at Delphi, where that reply was given them which I reported shortly
before this. And they got this information in a strange manner; for Demaratos the
son of Ariston after he had ﬂed for refuge to the Medes was not friendly to the
Lacedemonians, as I am of opinion and as likelihood suggests supporting my opinion;
but it is open to any man to make conjecture whether he did this thing which follows
in a friendly spirit or in malicious triumph over them. When Xerxes had resolved to
make a campaign against Hellas, Demaratos, being in Susa and having been informed
of this, had a desire to report it to the Lacedemonians. Now in no other way was he
able to signify it, for there was danger that he should be discovered, but he contrived
thus, that is to say, he took a folding tablet and scraped oﬀthe wax which was
upon it, and then he wrote the design of the king upon the wood of the tablet, and
having done so he melted the wax and poured it over the writing, so that the tablet
(being carried without writing upon it) might not cause any trouble to be given by
the keepers of the road. Then when it had arrived at Lacedemon, the Lacedemonians
were not able to make conjecture of the matter; until at last, as I am informed,
Gorgo, the daughter of Cleomenes and wife of Leonidas, suggested a plan of which
she had herself thought, bidding them scrape the wax and they would ﬁnd writing
upon the wood; and doing as she said they found the writing and read it, and after
that they sent notice to the other Hellenes. These things are said to have come to
pass in this manner. (Translation by G.C. Macaulay.)
Moreover, it is well known that in the Battle of Salamis the Greeks, having
been informed of Xerxes’s expedition thanks to this stratagem and so being ready
to confront him, managed in 480 BCE to defeat the Persians. So a secret, cleverly
hidden message, changed the outcome of a war.
Herodotus himself, in Book V of the Histories, tells the story of Histiaios who
desiring to signify to Aristagoras that he should revolt, was not able to do it safely
in any other way, because the roads were guarded, but shaved oﬀthe hair of the most
faithful of his slaves, and having marked his head by pricking it, waited till the hair
had grown again; and as soon as it was grown, he sent him away to Miletos, giving
him no other charge but this, namely that when he should have arrived at Miletos he
should bid Aristagoras shave his hair and look at his head: and the marks, as I have
said before, signiﬁed revolt. This thing Histiaios was doing, because he was greatly
vexed by being detained at Susa. He had great hopes then that if a revolt occurred
he would be let go to the sea-coast; but if no change was made at Miletos he had no
expectation of ever returning thither again. (Translation by G.C. Macaulay.)
It is clear that as soon as the enemy suspects the existence of a hidden message,
the obvious countermove is to inspect with the greatest care all possible hiding
places. In the episodes told by Herodotus, the suspect would be searched until the
message hidden under the hair is found, or the tablet would be examined meticu-
lously until the place where the message was written is spotted.
We conclude this historical preamble with a last anecdote (see [58]).

7.1 The classic ciphers
321
Mary Stuart, Queen of Scots, imprisoned in 1568 by Queen Elizabeth, was a
prisoner for 18 years. In 1586 a plot to free her and simultaneously assassinate
Queen Elizabeth was organised: the conspirators deemed it necessary for their plan
to be approved by the Queen of Scots. To do so, they used hidden and ciphered
secret messages. But both the presence of a double-crosser and the deluded certainty
of being able to write freely in the messages, in the (mistaken) conﬁdence in the
cryptosystem they used being indecipherable, drove Mary to write more than she
should have; this gave Queen Elizabeth the proof of her involvement in the plot and
led to her death sentence.
These examples and many more show how, mainly during wartime, the
need for devices to send messages in such a way that the adversaries could
not discover them has been felt for centuries. The most spontaneous way
is to hide the message as the above episodes relate: this technique is called
steganography.
Another way to send a message in such a way that the enemy cannot
understand it is obtained by hiding not the message, but its meaning. In this
case we are dealing with cryptography. We are enciphering a message so that
it can be read by whomever obtains it, but only the actual addressee is able to
decipher it, while the enemy cannot, even if he gets hold of it. A ﬁrst, simple
example of ciphering of a message consisted in substituting Greek characters
for Latin ones. But perhaps one of the ﬁrst recorded examples of a ciphered
message in the history dates back to Julius Caesar. Thanks to Suetonius’s On
the Life of the Caesars (2nd century CE), we know one of the systems used
by Caesar to encipher his messages: he shifted by three positions, with respect
to its position in the alphabet, each letter of the message to be sent.
If we denote by lower case letters the 26 letters of the alphabet, each letter
of the message (plaintext) will be substituted with the letter following it by
three positions, which we shall write in upper case: so we get a new message
(ciphertext). The explicit correspondence between the letters is described in
Table 7.1.
The enciphering or encryption is the rule describing how to pass from one
alphabet to the other one, that is, allowing us to rewrite a message so to make
it unreadable for those who do not know the rule. For instance, if the message
to be sent is
attack tomorrow
(plaintext),
the result after enciphering is
DWWDFN WRPRUURZ
(ciphertext).
Table 7.1. Cipher used by Caesar
a
b
c
d
e
f
g
h
i
j
k
l
m
n
o
p
q
r
s
t
u
v
w
x
y
z
D
E
F
G
H
I
J
K
L
M
N
O
P
Q
R
S
T
U
V
W
X
Y
Z
A
B
C

322
7 Secrets. . . and lies
A system like this, in which the cipher alphabet is obtained from the plain
alphabet by moving each letter by a ﬁxed number of positions, is called Caesar
cipher. In English there are altogether 26 possible Caesar ciphers, or rather
25, as clearly if a letter is moved by 26 positions it comes back to its starting
point and the ciphered message is equal to the original one. In other words, we
may deﬁne a bijection between the possible cipher alphabets and the residue
classes modulo 26, that is with the integers n such that 0 ≤n ≤25. Given
such an integer n, called key, the corresponding cipher alphabet is the one
moving the letters of the plaintext by n positions, that is to say, the alphabet
obtained by an n-position shift. Clearly the value n = 0 corresponds to the
initial alphabet, that is to the plaintext.
If a message that has possibly been enciphered using a Caesar cipher has
been intercepted, it suﬃces, in order to decrypt it, to use the 26, or rather
the 25, keys of the possible cipher alphabets. So this enciphering can be
sidestepped very easily, especially so if one has good computing instruments,
as we have today, while Caesar and his enemies had not.
Reﬁning this principle, we may use as enciphering, rather than just the
shifts, all possible permutations of the 26 letters. In practice, each permutation
of the set {0, 1, 2, . . ., 25}, called key as above, determines a cipher alphabet,
and the other way around: for instance, for the identity permutation it suﬃces
to have 0 correspond to A, 1 to B, 2 to C and so forth.
But how can we remember the key? We should remember the whole letter
sequence, lacking a speciﬁc scheme to memorise it. However, there is a good
system to generate a permutation of the alphabet that can be easily memo-
rised: it consists in using a key that is itself determined by a key word or a key
phrase, or any letter string we can easily remember. Let us see an example to
clarify this method.
Example 7.1.1. Assume we have chosen as key phrase the following:
to be or not to be that is the question.
First of all, remove the spaces between the words of the key phrase and then the
repetitions, obtaining in our case
tobernhaisqu.
The cipher alphabet will be constructed by putting in the order, under the plain
alphabet, ﬁrst the letters of the key word modiﬁed as above, and then the letters of
the plain alphabet not appearing in the key phrase, in the usual alphabetic order.
So we get:
a
b
c
d
e
f
g
h
i
j
k
l
m
n
o
p
q
r
s
t
u
v
w
x
y
z
T
O
B
E
R
N
H
A
I
S
Q
U
C
D
F
G
J
K
L
M
P
V
W
X
Y
Z
In this way we have associated to the key, that is to the phrase to be or not to be
that is the question, the cipher alphabet shown. We may verify that the permutation
determined by the key word and that determines the alphabet is described by the
following table:

7.1 The classic ciphers
323
0
1 2 3 4
5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
19 14 1 4 17 13 7 0 8 18 16 20 2
3
5
6
9 10 11 12 15 21 22 23 24 25
So, if the message to send were
it is the early bird that gets the worm ,
the result after being enciphered in this way would become
IM IL MAR RTKUY OIKE MATM HRML MAR WFKC .
In general, in this way the number of possible keys, and so of cipher al-
phabets, increases quickly form 26 (Caesar ciphers) to 26!, the number of all
possible permutations of 26 elements (see Exercise A1.11). This number is
51090942171709440000,
that is, about 51 · 1018, or more than ﬁfty billion billion: if an adversary
intercepts the message and suspects this enciphering method has been used
he cannot possibly try to decrypt it by trial and error. To realise the hugeness
of this number it suﬃces to recall that the Big Bang occurred approximately
15 billion years ago. So whoever has to send secret messages may rest easy
and relax: nobody can possibly decrypt them! But are things really like this?
Unfortunately, the answer is no: the frequency with which a given letter
appears in a text long enough, and other factors depending on the alphabet
used can reduce substantially the number of attempts necessary to ﬁnd the
key! We shall return on this in next section.
As regards our ciphers, an enciphering using a single cipher alphabet, as
those seen so far, is called monoalphabetic cipher. However, we may consider
using more than one cipher alphabet. How?
Suppose we want to use s ∈N \ {0} cipher alphabets. Then, divide the
message into s-letter blocks and successively encipher the letters in each block
with the s alphabets, always using them in the same order. In other words,
denoting by Ai, 1 ≤i ≤s, the s alphabets, all the letters that are in the
ith position of a block will be enciphered with the same alphabet Ai. Such
a cipher is called periodic polyalphabetic cipher. If s is equal or greater than
the length of the message we shall simply have what is called an (aperiodic)
polyalphabetic cipher.
The ﬁrst example of this kind is apparently due to Leon Battista Alberti, in the
second half of 15th century: he proposed the use of two cipher alphabets for each
message. His idea was improved later by Vigen`ere in the second half of 16th century.
Vigen`ere proposed that each message should be enciphered using 26 cipher alpha-
bets. The 26 cipher alphabets are shown in table 7.2, where the integer appearing
in each line is exactly the shift key giving the cipher alphabet.
To ﬁx ideas, and prepare the mathematical model, we may label the letters
of the message using integers as described by table 7.3.
The integers from 0 to 25 are called numerical equivalents of the alphabet
letters. In this way, as already remarked, we write 0 in the place of a, 12 in

324
7 Secrets. . . and lies
Table 7.2. Vigen`ere table
a b c d e f g h i j k l m n o p q r s t u v w x y z
0 A B C D E F G H I J K L M N O P Q R S T U V W X Y Z
1 B C D E F G H I J K L M N O P Q R S T U V W X Y Z A
2 C D E F G H I J K L M N O P Q R S T U V W X Y Z A B
3 D E F G H I J K L M N O P Q R S T U V W X Y Z A B C
4 E F G H I J K L M N O P Q R S T U V W X Y Z A B C D
5 F G H I J K L M N O P Q R S T U V W X Y Z A B C D E
6 G H I J K L M N O P Q R S T U V W X Y Z A B C D E F
7 H I J K L M N O P Q R S T U V W X Y Z A B C D E F G
8 I J K L M N O P Q R S T U V W X Y Z A B C D E F G H
9 J K L M N O P Q R S T U V W X Y Z A B C D E F G H I
10 K L M N O P Q R S T U V W X Y Z A B C D E F G H I J
11 L M N O P Q R S T U V W X Y Z A B C D E F G H I J K
12 M N O P Q R S T U V W X Y Z A B C D E F G H I J K L
13 N O P Q R S T U V W X Y Z A B C D E F G H I J K L M
14 O P Q R S T U V W X Y Z A B C D E F G H I J K L M N
15 P Q R S T U V W X Y Z A B C D E F G H I J K L M N O
16 Q R S T U V W X Y Z A B C D E F G H I J K L M N O P
17 R S T U V W X Y Z A B C D E F G H I J K L M N O P Q
18 S T U V W X Y Z A B C D E F G H I J K L M N O P Q R
19 T U V W X Y Z A B C D E F G H I J K L M N O P Q R S
20 U V W X Y Z A B C D E F G H I J K L M N O P Q R S T
21 V W X Y Z A B C D E F G H I J K L M N O P Q R S T U
22 W X Y Z A B C D E F G H I J K L M N O P Q R S T U V
23 X Y Z A B C D E F G H I J K L M N O P Q R S T U V W
24 Y Z A B C D E F G H I J K L M N O P Q R S T U V W X
25 Z A B C D E F G H I J K L M N O P Q R S T U V W X Y
the place of m, and so forth; if necessary, we shall use the notation a ↔0,
m ↔12. We might further use other numbers to denote spaces in the text,
commas, diacritics and every other symbol that might be useful to reconstruct
more easily the text. For simplicity, we shall not use these signs.
Table 7.3. Numerical equivalents of the 26 letters
a −→
0
h −→
7
o −→
14
u −→
20
b −→
1
i
−→
8
p −→15
v −→21
c −→
2
j
−→
9
q −→16
w −→22
d −→
3
k −→10
r −→17
x −→23
e −→
4
l
−→11
s −→18
y −→24
f −→
5
m −→12
t −→19
z −→25
g −→
6
n −→13

7.2 The analysis of the ciphertext
325
How may we remember the sequence of the s alphabets to be used in enci-
phering our message? By memorising it using a key word. We may use a word
whose length s represents the period by which the alphabets are repeated.
Example 7.1.2. Assume we have chosen the key word FISH and we want to encipher
the sentence “shoot now”.
The rules to be followed in the encipher are contained in the key word we have
chosen, in the sense that we shall use as cipher alphabets, repeating each in each
4-letter word (shoo | tnow), the lines of Vigen`ere table corresponding successively
to the letters F, I, S, H. In our example, the lines are the ones numbered 5, 8, 18,
and 7. Then the ﬁrst letter of the message, the s, shall be enciphered with the letter
that is in the position of s using as cipher alphabet that of line 5, corresponding
to the letter F of the key word, up to the second letter o that shall be enciphered
with the line corresponding to the letter H; then we start again, using the alphabet
corresponding to the letter F for the letter t, and so on.
We conclude this section with another anecdote (see Scientiﬁc American,
August 1977).
In 1839, Edgar Allan Poe, from the pages of a Philadelphia periodical, asked
his readers for cryptograms with monoalphabetic substitutions, and guaranteed he
would solve them. Among many other ones, he received the following handwritten
cryptogram:
GE JEASGDXV,
ZIJ GL MW LAAM XZY ZMLWHFZEK EJLVDXW KWKE TX LBR ATGH LBMX AANU BAI
VSMUKKSS PWNVLWK AGH GNUMK WDLNZWEG JNBXVV OAEG ENWBZWMGY MO MLW WNBX MW
AL PNFDCFPKH WZKEX HSSF XKIYAHUL?
MK NUM YEXDM WBXY SBC HV WYX PHWKGNAMCUK?
The letters in bold correspond to upper case letters.
Having read the message, Poe replied that it consisted of random symbols, not
corresponding to any monoalphabetic substitution. More than one hundred years
later, in 1975, the mathematician Bryan J. Winkel, and the research chemist Mark
Lyster, who took part in the course in cryptography given by by Winkel, decrypted
the message. In fact, it was not a monoalphabetic substitution, but did not even
consist of random letters. Moreover, there were some errors probably due to the
transcription of the text (see Exercise B7.20). The solution is as follows:
Mr. Alexander,
How is it that the messenger arrives here at the same time with the Saturday
courier and other Saturday papers when according to the date it is published three
days previous? Is the fault with you or the postmasters?
7.2 The analysis of the ciphertext
We have just described some techniques to encipher messages that look to be
unbreakable, at least if our only way is to proceed by trial and error and we
are not incredibly lucky. Is this all, or is there some other information we can
use?

326
7 Secrets. . . and lies
Let us look at things from the point of view of the adversary, who wants to
decrypt the message at any cost. We know the message has been enciphered
using a monoalphabetic substitution and, as we have remarked, we cannot
proceed by trial and error, if we are to solve the problem in an admissible
time.
So we have to use other methods, independent of the kind of key that has
been used, and so of the cipher alphabet it determines. How may we proceed,
having only a page of ciphertext? We subject it to a text analysis: depending
on the language the text is written in, we take into account its properties. In a
language like Italian, where most words end with a vowel, most of the symbols
at the end of the words of the ciphertext will be vowels. More in general,
much information is given by frequency analysis. In each language some letters
appear with greater frequency, some more rarely. Linguistic and statistical
studies have found the frequency of the 26 letters of English alphabet:
Letter
%
Letter
%
Letter
%
Letter
%
a
7,3
h
3,5
o
7,4
u
2,7
b
0,9
i
7,4
p
2,7
v
1,3
c
3,0
j
0,2
q
0,3
w
1,6
d
4,4
k
0,3
r
7,7
x
0,5
e
13,0
l
3,5
s
6,3
y
1,9
f
2,8
m
2,5
t
9,3
z
0,1
g
1,6
n
7,8
So if we know that the text to decrypt is written in English, and if it
is long enough, we may determine the frequencies of the letters in the text.
Those appearing with the greatest frequency might possibly be es, or ts. Then
we may look for correspondences by trial and error, examining successively
the letters with smaller frequency, looking for pieces of the puzzle falling
into place. If we get meaningless words, we adjust our tentative assignations.
Further information is given by the frequency of double letters, the greater or
smaller likelihood that certain letters are found close together, and so on.
Example 7.2.1. We get back to the example we saw in the previous section, to
see how to use eﬃciently the techniques just described to decrypt the enciphered
message
IM IL MAR RTKUY OIKE MATM HRML MAR WFKC .
We write down the frequency of the letters in the message:

7.2 The analysis of the ciphertext
327
Letter Times Letter Times Letter Times
A
3
J
0
S
0
B
0
K
3
T
2
C
1
L
2
U
1
D
0
M
6
V
0
E
1
N
0
W
1
F
1
O
1
X
0
G
0
P
0
Y
1
H
1
Q
0
Z
0
I
3
R
4
As this is a short message, frequency analysis might be misleading, but in any
case we may try to use it. We might also exploit the fact that certain letters are more
likely to end a word, or the length of the words, but this attempts are easily foiled
by breaking up the message in blocks of the same length, which makes it diﬃcult to
reconstruct the single words. However, at this stage we shall use everything we know.
So let us analyse our text. The most frequent letters, M and R, might correspond
to e and t. Moreover, the repeating subsequence MAR is likely to be the article the.
So we may tentatively try the correspondences
M = t,
A = h,
R = e,
and for the next most frequent letters of the ciphertext, I and K, we might try the
next most frequent alphabet letters n and r. In this way we obtain:
nt nL the eTrUY OIrE thTt HetL the WFrC .
Clearly, the choice I = n is not promising, and anyway, if the other choices are
right, it looks like I must represent a vowel, or the sentence would begin with the
“word” nt. Trying out o, i and a, the best choice appears to be i. So we get:
it iL the eTrUY OIrE thTt HetL the WFrC
and after some more attempts and frequency analyses we get the solution.
It is clear that this example is not too typical because we are analysing a very
short text, but the important thing is to emphasise the fact that the far too many
theoretical possibilities to be considered in order to ﬁnd the key decrease enor-
mously by using data about the language and making some educated guesses and
backtracking.
Analysing a Caesar cipher by studying frequencies is clearly even easier.
Vigen`ere system too can be attacked with a suitably adapted frequency
analysis, if its period is known. For instance, if we assume that the period,
that is to say the length of the key word is four, then we have to line up the
letters of the ciphertext in four columns, as follows:
∗∗∗∗
∗∗∗∗
∗∗∗∗
. . . . . .
. . . . . .

328
7 Secrets. . . and lies
If in the same column there are equal cipher letters, they represent the
same letter of the plaintext, as all the letters in the same column are enci-
phered with the same cipher alphabet.
Coming back to Example 7.1.2, the pattern is
shoo
tnow −→
XPGV
YVGD −→
23 15 6 21
24 21 6 3
and, as is immediately seen, the letter G (or its numerical equivalent 6) ap-
pearing in the third column is repeated and corresponds to the same letter o
of the plaintext.
These remarks allow us, with due caution, to use frequency analysis on
each column separately to reconstruct the key word. Moreover, a German
cryptologist who lived at the end of 19th century, F. W. Kasiski, found a
method to determine the period of the alphabet, and this partly explains the
loss of interest for this kind of ciphers.
Remark 7.2.2. Some of these methods can also be applied to ancient inscriptions:
clearly the people writing them did not, in general, intend to encipher a message, but
for us those texts actually are enciphered messages we have to decrypt. Decrypting
an unknown form of writing is something of a magic, as it allows to enter a past world,
to get to know a dead civilisation, to call to mind a remote age. The main example
are Egyptian hieroglyphics: the most ancient ones date back to fourth millennium
BCE. Interest in them was aroused in 16th century when Pope Sixtus V decreed
that a new road network should be built in Rome, putting at the crossroads some
Egyptian obelisks: confronted with those puzzles, many tried to understand their
meaning. The most famous archaeological ﬁnd with hieroglyphics is undoubtedly
the Rosetta stone, made of black basalt, discovered in 1799 near Nile’s delta and
engraved in 196 BCE: it is an inscription regarding a decree by an assembly of
priests honouring the Pharaoh and, as is well known, it carries the same text in
three versions: hieroglyphic Egyptian, Demotic Egyptian and Greek. The Greek
text was easily translated and so it became, in a sense, the plaintext against which
the two other texts could be compared: it yielded both a great opportunity and an
irresistible challenge. J.F. Champollion measured himself against it and, in 1822,
solved the mystery. Today the stone is kept in the British Museum in London.
Archaeologists have deciphered several ancient writing systems and languages,
but many of them are still undeciphered, among them Etruscan. The most intrigu-
ing deciphering has perhaps been that of Linear B, a Mediterranean script, dating
back to Bronze Age. The renowned English archaeologist Sir Arthur Evans, during
his excavations in Crete in 1900, unearthed a great number of clay tablets bear-
ing writings, partly in a script which was called Linear B. These tablets made up
the archives of Cretan palaces. They were deciphered in 1953 by M. Ventris and
J. Chadwick. It would be very long to relate the whole story of the deciphering:
suﬃce it to say that it could form the plot of a thrilling detective novel. Due to the
understanding of Linear B, the political and social situation of Cretan society has
been now reconstructed, at least in its main lines.
We have said above that the purpose of the authors of the inscriptions was not,
in general, to encipher them. We kept on the safe side by saying in general: indeed,

7.2 The analysis of the ciphertext
329
some scholars have recently discovered the presence of cryptographical methods in
Egyptian hieroglyphics. Apparently, some of them were enciphered by order of the
Pharaohs, using several techniques, among which enciphering by substitution.
We are coming to the end of our digression, which teaches us that history is
full of messages to be deciphered. Every discovery unearths a secret whose key was
hidden.
Notice that, in trying to understand a message enciphered using a monoalpha-
betic substitution, we have used quite subtle statistical techniques. Apparently, these
cryptanalytical techniques have been invented by Arabs during Middle Ages. A sub-
ject like this, in fact, can only appear and ﬂourish within a civilisation possessing
an advanced knowledge of mathematics, linguistics, and statistics. Arab civilisation
undoubtedly had these traits. The most ancient document describing explicitly the
frequency method dates back to 9th century, and is due to Ab¯u Y¯usuf ibn Ish¯aq
al-Kind¯ı, known as the Arab Philosopher, who in his monograph On Deciphering
Cryptographic Messages described in detail techniques based on statistics and Ara-
bic phonetics and syntax to be used to decrypt documents.
To complete the historical sketch of cryptography we deal in brief with
the machines that, along the centuries, have been devised to put in practice
various ciphers.
7.2.1 Enciphering machines
The ﬁrst enciphering machine is the so-called cipher disc by Leon Battista Alberti,
which is made up of two concentric copper discs, of diﬀerent diameters, which can
rotate one with respect to the other around a central axis. Along the circumferences
of the two discs two alphabets are engraved. To encipher a message using Caesar
cipher shifting letters by two positions, it suﬃces to put the a of the internal disc,
representing the plain alphabet, next to the C of the external disc, representing
the cipher alphabet (with key n = 2). After this simple operation, to encipher the
message it suﬃces, without any further rotation of the discs, to read successively the
letters on the external disc corresponding to the letters on the internal one. It is a
very simple and eﬀective device, which has been in use for several centuries.
The same device can be also used, in quite a natural way, for a polyalphabetic
enciphering: changing the position of the second disc means exactly choosing a new
alphabet.
As already remarked, this enciphering machine has lived on for several centuries,
up to the moment, towards the end of World War I, it has been superseded by the
famous Enigma machine, invented and constructed by Arthur Scherbius and Richard
Ritter, and used until World War II by the German army. In a ﬁrst form, it consisted
of the following three elements, connected by electric wires (see ﬁgure 7.1):
•
an alphabetic keyboard, to input the plaintext;
•
a scrambler unit, which is the part actually performing the enciphering;
•
a board with as many light bulbs as the letters of the plain alphabet, devised in
such a way that the processed electric signal would light the lamp corresponding
to the enciphered letter.

330
7 Secrets. . . and lies
The scrambler unit is the system’s main part. It is the device actually enciphering
the message: it consisted of a thick rubber disc through which a complex network
of electric wires passed. For instance, to encipher the letter a with the letter D, a is
input on the keyboard: in this way the electric current enters the scrambler, follows
the route through the electric wires, and lights the lamp corresponding to the letter
D.
Later, Scherbius modiﬁed the machine, substituting a scrambling rotor for the
original scrambler: in this way, the scrambling disc automatically rotated by one
twentysixth of a revolution (if the alphabet consisted of 26 letters) after enciphering
each letter. So, to encipher the next letter, a diﬀerent cipher alphabet is used. The
rotating scrambler deﬁnes 26 cipher alphabets. Further improvements substituted
the single scrambler with three scrambling rotors, and introduced a reﬂector, which
could reﬂect the signals processed by the rotors, adding complexity to the machine.
In short, it was a very sophisticated enciphering machine, so much so that Scher-
bius believed that Enigma generated unbreakable coded messages. In 1943, during
World War II, the English used the Colossus computers to decrypt messages gen-
erated by Enigma. It is very interesting to notice that many of the researchers who
collaborated to the breaking of Enigma, among which the mathematician A. Turing,
perhaps inspired by the peculiarities of the problem, went on to give fundamental
contributions to the development of computer science and artiﬁcial intelligence.
7.3 Mathematical setting of a cryptosystem
Let us go back to enciphered messages. The science of decrypting messages
for which the key is not known is called cryptanalysis.
Fig. 7.1. Enigma’s keyboard and display

7.3 Mathematical setting of a cryptosystem
331
So on the one hand there are the cryptologists, designing methods to enci-
pher messages in such a way that they cannot be read by unauthorised people,
on the other there are the cryptanalysts, who try to decrypt messages, looking
for weaknesses in the cryptographic system. The interaction of these two sub-
jects, cryptology and cryptanalysis, which taken together form cryptography
and deal, from diﬀerent viewpoints, with the same object, leads, as can be
expected, to ever more complex and secure enciphering systems.
In this section we shall show how to give a proper mathematical layout to
cryptology-cryptanalysis.
In table 7.4 we give a short glossary of the terms used in cryptography.
We further remark that the root crypt- derives from Greek kryptos, meaning
“hidden, secret”.
Before going on, some remarks are in order.
•
The alphabets used for plaintexts and ciphertexts can be diﬀerent among them
and with respect to the one commonly used in the language. In general, it is con-
venient to write messages using, rather than letters, integer numbers, which are
more suitable to the description of the transformations, that is, the enciphering
methods, to be used.
•
The transformation procedure, that is, the function describing the passage from
plaintext to ciphertext, must be bijective if we want to be able to reverse the
procedure to decipher the message and ﬁnd back the original text rather than
something else. The crucial thing is that the person who shall have to decipher
the message has to be in possession of the key!
Table 7.4. Glossary of cryptography
Lexeme
Meaning
Plaintext
Original message to be sent in a secret way, or string of
symbols in a given alphabet representing the message or
text to be enciphered
Ciphertext
Modiﬁed, disguised version of the plaintext
Encipher, (encrypt)
Convert a plaintext into a ciphertext
Decypher, decrypt
Convert a ciphertext into a plaintext
Cipher
Method used to convert a plaintext into a ciphertext
Key
Data determining both a particular enciphering and the
correponding deciphering rule, among all the possible
ones: in the ﬁrst case it is called cipher key, in the second
decipher key
Cryptology
Science of enciphering messages
Cryptanalysis
Science of interpreting enciphered messages

332
7 Secrets. . . and lies
•
Why do we need a key? Is it not suﬃcient to deal with the enciphering and
deciphering transformations? The fact is, once we have perfectioned a system
to send enciphered messages, changing often the key oﬀers a greater security
without having to modify the whole enciphering system. In other words, we
could describe the system as a combination lock, and the key as one of several
possible combinations. The lock is the enciphering system we are using, while
the key is the combination.
•
We are not especially interested here in detailing precisely the set of possible
keys. The important thing we want to emphasise is that it has to have a size
that is not too small, or else it would be feasible for a cryptanalyst to try out all
possible keys for that kind of cipher. For instance, Caesar cipher has a far too
small number of keys.
All in all,
•
the task of the cryptologist is to invent systems to transform a plain mes-
sage into a cipher message; such systems are called cryptosystems;
•
the task of the cryptanalyst is to oppose this activity, ﬁnding ways to
interpret enciphered messages, in general without the authorisation of the
sender.
In conclusion, a cryptosystem consists of:
•
a set P, consisting of the possible plaintexts; a single plaintext shall be
denoted by the letter p;
•
a set K, called key set. We shall denote a key by the letter k. Each element
k ∈K determines an enciphering transformation Ck and a deciphering
transformation Dk, inverse of each other. In particular, Dk · Ck(p) = p;
•
a set C consisting of the enciphered messages. We shall denote one of these
ciphertexts by the letter c.
So, given a cryptosystem determined by the triple (P, C, K) with
P = {plaintexts},
C = {ciphertexts},
K = {keys},
the communication between two persons, Ariadne and Blanche, is described
by the following diagram:
key k ∈K
Ariadne picks a message
p to be sent and a
key k to encipher it
enciphering of
the plaintext p
Ck(p) = c
deciphering of c
Dk(c) = p
plaintext
p ∈P
Blanche reads
Ariadne’s
message p

7.3 Mathematical setting of a cryptosystem
333
In general the messages, both plain and enciphered ones, are split up into
unitary messages. A unitary message may consist of a single letter, or a pair of
letters (digraph), a triple of letters (trigraph), or s-letter blocks. The advantage
of dividing a message into blocks of a ﬁxed length is in preventing the easy
recognition of the beginning and end of the words, making the cryptanalysis
based on frequencies more diﬃcult.
Suppose for the time being to have unitary messages consisting of a single
letter each, in a given alphabet. To describe mathematically a cryptosystem,
the most eﬀective way, as already remarked, is to associate with each symbol
of our alphabet an integer number. Assume for simplicity the alphabet in
which we write our messages to be the English one, and consider its numerical
equivalents (see Table 7.3 on page 324).
As we are using a 26-letter alphabet, it is natural to perform all mathe-
matical operations on the numerical equivalent of letters modulo 26. In this
way 26 is identiﬁed with 0, that is with the letter a, and so forth. As already
suggested, we might use other numbers to denote spaces in the text, commas,
diacritics and other symbols which may help in reconstructing more easily the
text, but we are not presently interested in them. In general, if the unitary
message is an s-letter block a1a2 . . . as, then we would like to label the uni-
tary message a1a2 . . . as by the string of integers x1x2 . . . xs, where xi, with
1 ≤i ≤s, is the numerical equivalent of ai. Why are we prevented from doing
so? Unfortunately, there is a notational ambiguity which we want to draw
attention to.
Indeed, assume we want to transmit a message consisting of 2-letter blocks,
using the numerical equivalent of the letters. Then the numerical sequence 114
might correspond to the message bo, but also to the message le, depending
on whether we look at the number 114 as consisting of 1 and 14 or 11 and 4.
This is due to having a correspondence with numbers not all consisting of the
same number of digits.
When the unitary message consists of more than one letter, in order to
avoid ambiguities we may use other correspondences: for instance 2-digit nu-
merical equivalents for the letters or binary numerical equivalents, as described
by Table 7.5.
Table 7.5. 2-digit and binary numerical equivalents
a
−→00 = 00000
j
−→09 = 01001
s
−→18 = 10010
b
−→01 = 00001
k −→10 = 01010
t
−→19 = 10011
c
−→02 = 00010
l
−→11 = 01011
u −→20 = 10100
d
−→03 = 00011
m −→12 = 01100
v −→21 = 10101
e
−→04 = 00100
n −→13 = 01101
w −→22 = 10110
f
−→05 = 00101
o −→14 = 01110
x −→23 = 10111
g
−→06 = 00110
p −→15 = 01111
y −→24 = 11000
h
−→07 = 00111
q −→16 = 10000
z
−→25 = 11001
i
−→08 = 01000
r
−→17 = 10001

334
7 Secrets. . . and lies
Table 7.6. ASCII code
32
44 ,
56 8
68 D
80 P
92
\
104 h
116 t
33
!
45 –
57 9
69 E
81 Q
93
]
105
i
117 u
34 ”
46 .
58
:
70 F
82 R
94
ˆ
106
j
118 v
35 #
47 /
59
;
71 G
83
S
95
107 k
119 w
36 $
48 0
60 <
72 H
84 T
96
‘
108
l
120 x
37 %
49 1
61 =
73
I
85 U
97
a
109 m
121 y
38 &
50 2
62 >
74 J
86 V
98
b
110 n
122 z
39
’
51 3
63 ?
75 K
87 W
99
c
111 o
123 {
40 (
52 4
64 @
76 L
88 X
100 d
112 p
124
|
41 )
53 5
65 A
77 M
89 Y
101 e
113 q
125 }
42 *
54 6
66 B
78 N
90 Z
102 f
114
r
126 ˜
43 +
55 7
67 C
79 O
91
[
103 g
115
s
By using the binary or 2-digit numerical correspondence, the ambiguity
disappears. For instance, the messages le and bo, which had the same numer-
ical equivalent, now have diﬀerent ones:
Num. eq.
2-digit
Binary
le
114
1104
0101100100
bo
114
0114
0000101110
In next section we shall discuss further how to avoid this ambiguity. How-
ever, notice that for the sake of simplicity we might keep using the standard
numerical correspondence using the simple device of separating with spaces
the numbers corresponding to diﬀerent letters. This is the method we shall use
in the simplest examples. For instance, the message CIAO will be transcribed
2 8 0 14 rather than 28014.
Another standard way of associating with each alphabet letter and with
each character a number is described, as in the American Standard Code for
Information Interchange (ASCII), by Table 7.6: it is a usual code used to
translate the symbols, more commonly employed when inputting a text into a
computer. In Table 7.6 numbers start from 32, as the integers smaller than 32
represent special control characters aﬀecting the operation of the computer.
7.4 Some classic ciphers based on modular arithmetic
We shall now describe the mathematical aspects of some of the ciphers seen
up to now. For each of them we shall give some examples according to the
following pattern:
•
ﬁx the length of the unitary message, appending at the end of the message,
if necessary, the letter x a number of times suﬃcient for the whole message
to have a length suitable to divide it in blocks of the same length;

7.4 Some classic ciphers based on modular arithmetic
335
•
transform the blocks into numerical equivalents following a procedure to
be described;
•
choose a key k and a corresponding cipher: that is, deﬁne the function Ck
that determines the cipher on the alphabet in its numerical form;
•
determine Dk = C−1
k ;
•
reconstruct the message in the usual alphabet.
Remark 7.4.1. Let N be the length of the alphabet. As remarked, usually we
take N = 26. Once the length s of the unitary message consisting of s letters
is ﬁxed, if we call x1, . . . , xs the numerical equivalents of these letters, we
describe a procedure that uniquely determines what shall be written taking
x1, . . . , xs as starting point. We shall associate with the block x1 . . . xs the
number a that in base N is (x1 . . . xs)N. We know that a ∈{0, . . . , N s −1},
that is to say, we may identify the set of unitary messages (s-letter blocks)
with ZN s. So it is clear that an enciphering is just an invertible function on,
and taking values in, ZN s. In the previous example, where N = 26, we shall
have
le −→26 · 11 + 4 = 290,
bo −→26 · 1 + 14 = 40.
On the other hand, if we begin with the number 40, knowing that N = 26, we
ﬁnd that the corresponding plaintext is bo and only this. So we have solved
in yet another way the ambiguity issue mentioned in the previous section.
An alternative way of denoting the s-letter block x1 . . . xs with no ambi-
guity is to represent it as an element of Zs
N = ZN × ZN × · · · × ZN



s
, as each
xi is in ZN.
This deﬁnes an obvious bijection between Zs
N and ZN s given by
Zs
N = ZN × ZN × · · · × ZN



s
→ZN s,
(x1, x2, . . . , xs) →x1 + x2N + · · · + xs−1N s−2 + xsN s−1 = (xs · · · x1)N.
(7.1)
So, in general, if we split up the message in s-letter blocks, on an N-letter
alphabet, the enciphering function is a bijection
f : Zs
N −→Zs
N.
A feature of the cipher we are going to describe in this section, the “classic”
ciphers, is that the deciphering key Dk is easily computed from the encipher-
ing key Ck. In other words, from a computational viewpoint, the knowledge
of the deciphering key is essentially equivalent to the knowledge of the enci-
phering key. In public key ciphers we shall describe later, which rely on very
diﬀerent mathematical ideas, it is possible, on the contrary, to divulge the
enciphering key without compromising the secrecy of Dk. Indeed, in these
systems, computing Dk from Ck is so computationally hard to be unfeasible
in practice. For these reasons, classic ciphers are called two-way or symmetric,

336
7 Secrets. . . and lies
while public key ciphers are also called one-way or asymmetric. But more on
this later.
Let us now examine systematically some kinds of classic ciphers, all relying
on modular arithmetic, which admit as particular instances those considered
above. For the sake of simplicity, in the examples we shall use the numerical
equivalents, inserting spaces between the numbers to avoid any ambiguity.
7.4.1 Aﬃne ciphers
Assume the unitary message consists of a single letter, that is to say, the numerical
alphabet of the messages is P = Z26. If P is a letter, we shall also denote by P
its numerical equivalent. We shall use the same convention for the letters C in the
ciphertext.
Aﬃne ciphers are described by an enciphering function that uses an aﬃne trans-
formation, that is a bijection
Ck : Z26 −→Z26,
P −→(aP + b) mod 26,
where a, b ∈Z and the pair k = (a, b) represents the key of the system. For Ck to be
bijective, it is necessary for a to be relatively prime with 26, that is, GCD(a, 26) = 1
(see Exercise A7.3). In this case the congruence xa ≡1 (mod 26) has a unique
solution a′ modulo 26. Then the inverse deciphering function Dk is
Dk = C−1
k
: Z26 −→Z26,
C −→a′(C −b) mod 26.
Consider now a key k = (a, b) ∈K. Notice that Caesar or translation ciphers
are aﬃne ciphers with a = 1.
Clearly, we may assume 0 ≤b ≤25 and 1 ≤a ≤25, taking a and b modulo 26.
Recalling that a is relatively prime with 26 if and only if a is an invertible element
in Z26, that is, if a ∈U(Z26), it follows that the key set is
K = U(Z26) × Z26.
How many aﬃne ciphers are there? In other words, how many elements are ther in
K?
Recall (see § 3.3 and § 4.2.1) that
|U(Z26)| = ϕ(26) = |{ 1 ≤a ≤25 | GCD(a, b) = 1 }| = 12;
so there are 12 · 26 = 312 aﬃne ciphers, including a trivial one, corresponding to
k = (1, 0).
In Table 7.7 on page 337 we give a step-by-step example of one of these ciphers,
with a = 7 and b = 10, that is, k = (7, 10). Notice that a B´ezout’s identity for 7 and
26 is
−11 · 7 + 3 · 26 = 1,
as can be found by applying the Euclidean algorithm (see § 1.3.3), and so a′ =
−11 ≡15 (mod 26) and the deciphering function is
D(7,10)(C) = 15(C −10) mod 26,
that is, D(7,10) = C(15,6), as −150 ≡6 (mod 26).

7.4 Some classic ciphers based on modular arithmetic
337
Suppose we have intercepted a message which is known to be in English and
to have been enciphered with this system. How do we decrypt it? That is, how do
we ﬁnd the coeﬃcients a and b of the aﬃne transformation? Once more, with a
frequency analysis.
Assume that in the ciphertext the two letters appearing with the least frequency
are R and S: it stands to reason to guess that these letters correspond, in the
plaintext, to j or z. If we suppose that R ↔17 corresponds to the letter q ↔16,
and S ↔18 corresponds to z ↔25, then, according to the relation C = aP + b, the
following congruence system must hold

17 ≡a · 16 + b
(mod 26),
18 ≡a · 25 + b
(mod 26).
Table 7.7. Aﬃne enciphering with k = (7, 10) modulo 26
Plaintext
attack at dawn
Unitary message
in 3-letter blocks
att
ack
atd
awn
Numerical equivalent
of the plaintext
0 19 19
0 2 10
0 19 3
0 22 13
Numerical equivalent
of the ciphertext
C(7,10)(P) =
= 7P + 10 mod 26
10 13 13
10 24 2
10 13 5
10 8 23
Ciphertext
KNN KYC KNF KIX
Numerical equivalent of
the deciphered text
D(7,10)(C) =
= 15C + 6 mod 26
0 19 19
0 2 10
0 19 3
0 22 13
Deciphered text
in 3-letter blocks
att ack atd awn
Deciphered text
attack at dawn

338
7 Secrets. . . and lies
An eﬀective way of describing the system is using matrices. In this way, we may
write down the system as
A ·
a
b

≡
17
18

(mod 26),
with A =
16 1
25 1

.
To solve the system it is necessary for the matrix A to be invertible modulo 26.
In fact, it is easy to prove the following proposition (see Exercise A7.7).
Proposition 7.4.2. Let
A =
⎛
⎜
⎜
⎜
⎝
a11 a12 . . . a1s
a21 a22 . . . a2s
...
...
...
...
as1 as2 . . . ass
⎞
⎟
⎟
⎟
⎠
with aij ∈ZN. The following are equivalent:
•
GCD(det(A), N) = 1;
•
A is invertible, that is, there is a unique matrix A−1 deﬁned over ZN such that
A · A−1 = A−1 · A is the identity matrix. The matrix A−1 is given by
A−1 = det(A)−1
⎛
⎜
⎜
⎜
⎝
A11 A21 . . . As1
A12 A22 . . . As2
...
...
...
...
A1s A2s . . . Ass
⎞
⎟
⎟
⎟
⎠
where det(A)−1 is the inverse of det(A) in ZN and Aij denotes the cofactor
corresponding to the element aij in A;
•
the map f : X ∈Zs
N →A · X ∈Zs
N is bijective (X ∈Zs
N is thought of as a
column vector of order s);
•
for every column vector Y ∈Zs
N, the system A · X = Y has a unique solution.
Notice that if N is prime, that is, if we are working in a ﬁeld, the condition for A
to be invertible is det(A) ̸= 0. In this case, Proposition 7.4.2 is a well-known result
in linear algebra.
Coming back to our example, in which det A = −9 ≡17 (mod 26) and
GCD(17, 26) = 1, we have
A−1 ≡

23 3
23 4

(mod 26)
is the inverse modulo 26 of the system matrix. So the solutions a and b are imme-
diately found as follows:
a
b

≡A−1 ·
17
18

≡
 3
21

(mod 26).
In this particular case the simplest way of solving the original system would have
been to subtract the second equation from the ﬁrst one, immediately ﬁnding a ≡3
(mod 26) and then b ≡21 (mod 26). But we have given the general solution method
for this kind of problems.

7.4 Some classic ciphers based on modular arithmetic
339
Remark 7.4.3. A word of caution is necessary about the cryptanalytical method
to ﬁnd a and b just described. It leads to linear congruence systems of the form
A ·
a
b

≡
α
β

(mod m),
where α, β and the square 2 × 2 matrix A are known. If the determinant of A is
invertible modulo m, then A has an inverse modulo m and the system admits a
unique solution (a, b), given by
a
b

≡A−1 ·
α
β

(mod m).
The reader is encouraged to verify this claim and to extend it to systems in several
unknowns (see Proposition 7.4.2 and Exercise A7.8).
If, on the other hand, the determinant of A is not invertible modulo m, the
system might have no solutions (see Exercise A7.4) or more than one solution (see
Exercise A7.5). In the ﬁrst case this means that our guesses about frequency analysis
are certainly wrong and we shall make diﬀerent cryptanalytical attempts.
If there is more than one solution, we might try out each one of them and check
whether it works. For instance, if the determinant of A is not invertible modulo m
but is invertible modulo a prime number q divisor of m, we might solve the problem
modulo q. This shall give a unique solution modulo q, but several solutions modulo
m, each one to be analysed to check whether it works (see Exercise A7.6).
We conclude with an example, in the context of Caesar ciphers, which uses an
enciphering in Zs
N, leaving as an exercise an example that relies on the identiﬁcation
of Zs
N with ZNs described by (7.1).
Example 7.4.4. Assume the numerical alphabet of the unitary messages to be rep-
resented by P = Zs
26 with s a ﬁxed integer, that is, the unitary messages to consist
of an s-letter block. Given the key k ∈K = {1, 2, . . . , 25}, as we have seen, the
enciphering function is
Ck : Zs
26 −→Zs
26,
p −→p + k mod 26,
where p is the unitary message having numerical entries p1 . . . ps, and k = (k, . . . , k)
is the element of Zs
26 having all entries equal to k. By mod 26, it is meant that each
entry of an element of Zs
26 is computed modulo 26. Notice that if we take as our key
a vector (k1, . . . , ks) ∈Zs
26, where k1, . . . , ks are not all equal, then we construct a
polyalphabetic cipher; we shall deal with it again later.
Table 7.8 on page 340 shows an example with k = 5.
If, instead, we identify an element (p1, . . . , ps) of Zs
26 with the number written
in base 26 as
p = p1 + p2 · 26 + p3 · 262 + · · · + ps · 26s−1,
where, clearly, p1, . . . , ps are in {0, 1, . . . , 25}, we may, as remarked above, identify
Zs
26 with Z26s via the map
(p1, . . . , ps) ∈Zs
26 −→p = p1 + p2 · 26 + · · · + ps · 26s−1 ∈Z26s.
So we have P = Z26s and K = Z26s. Exercise B7.25 uses this diﬀerent enciphering,
with key k = 100.

340
7 Secrets. . . and lies
Table 7.8. Translation enciphering with k = 5
Plaintext
attack today
Message in
4-letter blocks
atta ckto dayx
Numerical equivalent
of the plaintext
0 19 19 0
2 10 19 14
3 0 24 23
Numerical equivalent
of the ciphertext
C5(P) = P + 5 mod 26
5 24 24 5
7 15 24 19
8 5
3
2
Ciphertext
FYYF HPYT IFDC
Numerical equivalent
of the deciphered text
D5(C) = C −5 mod 26
0 19 19 0
2 10 19 14
3 0 24 23
Deciphered text
in 4-letter blocks
atta ckto dayx
Deciphered text
attack today
7.4.2 Matrix or Hill ciphers
These ciphers split up the text into blocks of length s, translate each letter of the
block into its numerical equivalent and then apply an enciphering function, deﬁned
on the blocks, of the form
c = Ap + b mod 26,
(7.2)
where A is a square s × s matrix, b is a ﬁxed column vector of length s, and p and
c are the column vectors corresponding numerically to plaintext p and ciphertext c.
Moreover, if we want to be able to decipher the message, that is, have a bijective
enciphering function, it is necessary for the matrix A to be invertible modulo 26.
The map
C(A,b) : Zs
26 →Zs
26,
p →Ap + b mod 26
is also called an aﬃne transformation deﬁned by the key k = (A, b).
Notice that in the case s = 1 we ﬁnd again the aﬃne ciphers described above.
Example 7.4.5. We conclude giving an example of aﬃne transformation deﬁned
by the key

7.5 The basic idea of public key cryptography
341
k = (A, b),
with A =
1 2
4 3

,
b = 0 =
0
0

.
So the enciphering function is
C(A,0)
p1
p2

=
1 2
4 3

·
p1
p2

=
 p1 + 2p2
4p1 + 3p2

mod 26.
Notice that A is invertible modulo 26, as det(A) = −5 ≡21 (mod 26) is relatively
prime with 26. So we may compute the inverse modulo 26 of A (see Proposition
7.4.2). The inverse of 21 modulo 26 is 5, as B´ezout’s identity found with the Eu-
clidean algorithm is
5 · 21 −4 · 26 = 1.
So the inverse modulo 26 of A is
A−1 = 5 ·

3 −2
−4 1

=

15 −10
−20
5

≡

15 16
6
5

(mod 26)
and the deciphering function is
D(A,0)
c1
c2

=
15 16
6
5

·
c1
c2

=
15c1 + 16c2
6c1 + 5c2

mod 26.
In Table 7.9 we show the complete procedure to encipher with the key given the
plaintext true.
7.5 The basic idea of public key cryptography
In this section we are going to continue the description of some cryptographic
systems, outlining the genesis of the so-called public key systems. Later we
shall illustrate speciﬁc cryptographic systems of this kind, like the system
based on the knapsack problem and the RSA system: the security of the
former relies on the diﬃculty of some combinatorial problems, while that of
the latter on the diﬃculty of factoring large numbers.
In the ciphers described so far the deciphering procedure is not diﬃcult,
once the enciphering method, and so the key, are known. In fact, in those
cases the deciphering function is, in a way, symmetric with respect to the
enciphering function: it is, both computationally and logically, a function of
the same kind. In particular, all classic cryptosystems concern the exchange
of messages between two users and rely on exchanging a key which, basically,
enables both enciphering and deciphering.
In an age like the present one, when most information is transmitted by
telephone or electronic mail or radio, every sent message, as well as every sent
key, is susceptible to being easily eavesdropped. Moreover, it is necessary to
make it possible to communicate for users who have never met and so have not
had, in principle, the opportunity of exchanging private enciphering keys. So
it is indispensable to ﬁnd new, and more secure, ways of enciphering messages.
This is the goal of public key cryptography.

342
7 Secrets. . . and lies
Table 7.9. Matrix cipher as in Example 7.4.5
Plaintext
true
Message in
2-letter blocks
tr ue
Numerical equivalent
of the plaintext
19 17
20 4
Numerical eq. of the ciphertext
C(A,0)(p1, p2) =
= (p1 + 2p2, 4p1 + 3p2) mod 26
53 127
28 92 = 1 23
2 14
Ciphertext
BX CO
Numerical eq. of the deciphered text
D(A,0)(c1, c2) =
= (15c1 + 16c2, 6c1 + 5c2) mod 26
383 121
254 82 = 19 17
20 4
Deciphered text in
2-letter blocks
tr ue
Deciphered text
true
A public key cipher is a cipher that allows both the method employed and
the enciphering key to be made public - hence the name of public key cipher
- without revealing how to decipher the messages. In other words, in these
systems, to be able to compute in a reasonably short time the deciphering
transformation, which is the inverse of the enciphering one, it is necessary to
be in possession of a further piece of information, besides the public ones. So
this information is kept secret and without it the complexity of the decipher-
ing is enough to make it unfeasible: in essence, to decipher without further
information would require a time exceedingly long with respect to the time
required to encipher.
Remark 7.5.1. For an example which illustrates quite well the fact that being able
to do something does not imply being able to perform the inverse operation, consider
the telephone directory of a big city. It is easy to look up the telephone number of
a certain person, but it might be impossible, that is to say, it might take too long
with respect to the available time, to trace a person from his number.

7.5 The basic idea of public key cryptography
343
From a mathematical viewpoint, carrying out this idea relies on the notion
of one-way function.
We shall call a function f : S →T from a set S to a set T one-way if it can
be computed easily (for instance, because it is computed in polynomial time),
but, having chosen a random y ∈f(S), it is computationally much harder,
and impossible in practice (for instance because it takes an exponential time),
to ﬁnd an x ∈S such that y = f(x).
This notion may appear quite vague, as it uses terms as “easy”, “chosen a
random y ∈f(S)”, or “impossible in practice”, which have not the mathemat-
ical rigour of a deﬁnition. Nevertheless, we believe that it gives a suﬃciently
clear idea of the meaning of a one-way function.
Example 7.5.2. Consider a ﬁnite group G of order n and an element b ∈G.
Set
S = Zn = {0, 1, . . ., n −1};
then we may consider the exponential function
f : S →G,
f(x) = bx.
If y = f(x), we call x a discrete logarithm of y over G in base b and denote
it by the symbol logb y. When G is the multiplicative group F∗
q of a ﬁnite
ﬁeld Fq, if b ∈F∗
q is one of its generators, then f is bijective and its inverse
function is called discrete logarithm over Fq in base b. In this case, computing
f requires a polynomial time (see Proposition 5.1.44). On the other hand, all
known algorithms to compute discrete logarithms are exponential and it is
conjectured that there are no polynomial ones. So the exponential function
over Fq can be regarded as a one-way function. However, it must be remarked
that some algorithms to compute discrete logarithms, one example of which
we shall shortly illustrate with the so-called Baby step–giant step algorithm,
are, in particular cases, quite eﬀective.
In general, in cryptography it is interesting to consider those groups G
for which, as for F∗
q, computing powers is computationally easy (for instance,
requiring polynomial time), while computing discrete logarithms is computa-
tionally far harder (for instance, exponential). This may yield one-way func-
tions.
Example 7.5.3. Let Fq be a large enough ﬁnite ﬁeld, that is of order q = pf
with p a large prime number, and let f(x) ∈Fq[x] be a polynomial such that
the corresponding polynomial function f : Fq →Fq is injective. As we are well
aware, the function f can be computed in polynomial time, while the inverse
function f −1 may be quite hard to compute in practice. It is conjectured that
such a polynomial function is in many cases a one-way function.
The next example describes another kind of function f which is computed
more easily than f −1, but in which, unlike exponential and logarithmic func-
tions, both are computed in polynomial time.

344
7 Secrets. . . and lies
Example 7.5.4. We may consider enciphering a message X ∈Zs
N by multi-
plying it on the left by a square matrix A of order s. We have
f : X ∈Zs
N →A · X ∈Zs
N.
Computing Y = f(X) = A · X requires about s2 operations (see Exercise
A2.19). Computing X = f −1(Y ) = A−1Y , on the contrary, has a much greater
computational cost, as it requires inverting a square matrix of order s, which
implies about s3 operations (see Exercise A2.22).
The existence of one-way functions has not yet been rigorously proved.
However, there are many good candidates, like the exponential functions on
ﬁnite ﬁelds, mentioned above. In practice, we are interested in a speciﬁc kind
of one-way functions that can be deﬁned in a vague but suﬃciently eloquent
way, as follows:
Deﬁnition 7.5.5. A one-way function f : S →T is said to be a trapdoor
function if with some further information it becomes computationally feasible
to ﬁnd, for all y ∈f(S), an element x ∈S such that f(x) = y.
Public key techniques make use of functions of this kind, in the sense that,
basically, they are used as enciphering functions. We shall shortly show two
examples which shall illustrate this basic idea, which has remained so far quite
indeterminate.
7.5.1 An algorithm to compute discrete logarithms
We devote a short section to describe an algorithm, the so-called Baby step–giant
step algorithm, to compute discrete logarithms over the ﬁeld Zp with p a prime
number. So we work in Z∗
p, whose elements shall be identiﬁed with 1, 2, . . . , p −1.
Let g be a generator of Z∗
p. We want to determine the discrete logarithm x of y ∈Zp
in base g. We proceed as follows:
•
baby steps: set n equal to the least integer greater than √p and compute the
values gi ∈{1, . . . , p −1}, for all i ∈{0, . . . , n −1}, inserting them in a list to
be kept in the memory;
•
giant steps: compute gn and then g−n and successively yg−n, yg−2n, yg−3n, . . .,
yg−n2. After each of these computations, compare the result with the numbers
in the list created in the ﬁrst step. As soon as we obtain an equality of the form
yg−jn = gi, we have found the logarithm x = jn + i.
First of all, notice that the algorithm terminates and gives the desired logarithm.
In fact, the logarithm exists and is a number x in {1, . . . , p −1}. Then, dividing x
by n we have x = nj + i, with 0 ≤i ≤n −1. On the other hand, as x < p < n2 we
also have 1 ≤j ≤n.
We estimate next the complexity of the algorithm. There are n baby steps, each
having complexity O(log n). So the total complexity of the baby steps is O(n log n).
Notice that the baby steps can be thought of as a kind of precomputation, in the

7.6 The knapsack problem and its applications to cryptography
345
sense that they are performed just once, independently of the number y of which we
are computing the logarithm.
Reasoning in a similar way, we see that the giant steps too, which do depend on
the number whose logarithm we are computing, have complexity O(n log n); so this
is the complexity of the whole algorithm. It is exponential in n. There are further
issues with this algorithm:
•
the algorithm needs a large amount of memory if p is large, as a list consisting
of [√p] + 1 integers must be kept in memory;
•
moreover, comparing the numbers in this list and the numbers computed in
the giant steps has a computational cost, even if we have neglected it so far. A
possible way to perform this comparison consists in dividing a number by the
other one and checking whether the quotient is greater than zero or not. Clearly,
the algorithm leads us to carry out n2 comparisons, so all of them taken together
yield an exponential complexity.
Example 7.5.6. Let us illustrate the above by means of a very simple example. Take
p = 11 and g = 2, which is a generator of Z∗
11. In this case we have 3 <
√
11 < 4, so
n = 4. The baby steps yield the list
20 = 1,
21 = 2,
22 = 4,
23 = 8.
(7.3)
Compute next 24, which equals 5 modulo 11, while its inverse is 9.
Suppose we want to compute the logarithm log2 6. So we perform the giant steps.
In the ﬁrst step we compute 6 · 2−4, which equals 10 modulo 11. As this number
is not included in the list (7.3), we have not found the required logarithm. Perform
another giant step, computing 6 · 2−8, which, modulo 11, equals 2. So we ﬁnd the
relation 6 · 2−8 = 2, or 6 = 29 (mod 11), that is, log2 6 = 9.
For other algorithms to compute discrete logarithms, see [30], Ch. IV, or [44].
7.6 The knapsack problem and its applications
to cryptography
Suppose we are about to leave for an excursion. We have to pack our knapsack
and we want to make maximum use of the available space. We have a number,
say n, of diﬀerent objects, having volume v1, v2, . . . , vn; we know that the
knapsack contains a volume V , and we want to carry the greatest possible
load. How do we ﬁnd it? We are looking for a subset J ⊆{1, 2, . . ., n} such
that
V =

j∈J
vj.
(7.4)
This scheme may be applied to several similar problems. Assume we have
to pay 2 Euros and have at our disposal 2-, 5-, and 10-cent coins: how can
we pay with the least number of coins? Or with the largest number, so as to
rid ourselves of as many coins as possible? Moreover, how many possible ways
are there of paying?

346
7 Secrets. . . and lies
Let us turn back to the knapsack problem and describe a cryptographic
system relying on it, devised by Merkle and Hellman in 1978.
First of all, rephrase the problem as follows. Given n positive integers
a1, a2, . . . , an and a positive integer m, can we ﬁnd n integers x1, x2, . . . , xn
with xi ∈{0, 1} so that our integer m can be written as
m = a1x1 + a2x2 + · · · + anxn?
(7.5)
In other words, is it possible to write m as a sum of some of the ais? It
is not always possible and a solution, if it exists, may or may not be unique.
The three following examples demonstrate the diﬀerent possible cases.
Example 7.6.1. Set n = 5, (a1, a2, . . . , a5) = (2, 7, 8, 11, 12) and m = 21. It
is immediate to see that 21 = 2 + 8 + 11 and 21 = 2 + 7 + 12; so we have
two solutions, and they are the only ones. In explicit form, the ﬁrst solution is
x1 = x3 = x4 = 1 and x2 = x5 = 0, while the second one is x1 = x2 = x5 = 1
and x3 = x4 = 0.
Example 7.6.2. Consider now the same ais as before, but m = 1. As m is
smaller than each of the ais, it is not possible to write m as a combination of
the ais with coeﬃcients 0 or 1.
Example 7.6.3. If ai = 2i−1, for i = 1, . . . , n, solving the knapsack problem
means ﬁnding the binary representation of m which, as we know, exists and
is unique.
In principle, in order to ﬁnd the solution, if it exists, it suﬃces to con-
sider all the sums of the form (7.4) with J ranging among all the subsets of
{1, . . ., n}. As is well known (see Exercise A1.22), there are 2n such subsets,
including the empty set.
If n is small, this kind of inspection can be carried out, but if n is large, it is
computationally unfeasible, as it is likely to require an exponential algorithm.
In general, in fact, no algorithm to solve the knapsack problem is known, apart
from trying out all the possibilities.
We may ask if there are integer solutions xi ∈N of Equation (7.5). How-
ever, this general formulation of the knapsack problem is beyond the scope of
this text.
Remark 7.6.4. The knapsack problem is known to belong to a category of very
hard problems, the so-called NP-problems, for which it is conjectured that no al-
gorithm giving the solution in polynomial time exists.
More in detail, let P be the class of problems P for which a deterministic algo-
rithm that solves P in polynomial time exists. We have seen so far several examples
of problems lying in class P: for instance, the problem of ﬁnding the greatest com-
mon divisor of two integer numbers, or that of recognising whether a number is
prime.
A problem P is said to belong to class NP if there are algorithms - not necessarily
polynomial ones - solving it and if it is possible to verify whether given data solve
the problem or not, using a polynomial deterministic algorithm.

7.6 The knapsack problem and its applications to cryptography
347
For instance, the problem of factoring an integer number n is of this kind. The
sieve of Eratosthenes is a non-polynomial algorithm solving the problem, while,
given a number m, we can verify in polynomial time, using the Euclidean algorithm,
whether m divides n or not.
It is easy to see that the knapsack problem is too in NP.
Clearly, P ⊆NP; the main conjecture in complexity theory states that P ̸= NP.
A problem P in NP is said to be NP–complete if, for every other problem
Q in NP, there is a polynomial deterministic algorithm that reduces solving Q to
solving P. Clearly, if P is NP–complete and if there were a polynomial deterministic
algorithm that solves P, then every problem in NP would also be in P. So, if the
main conjecture in complexity theory is true, there are no polynomial deterministic
algorithms that solve NP–complete problems. These problems are, basically, the
most computationally diﬃcult problems in NP.
As we said at the beginning of this remark, the knapsack problem is known to
be NP–complete (see [23]).
A special case of our problem is the one in which the sequence a1, a2, . . .,
an is superincreasing, in the sense of the following deﬁnition.
Deﬁnition 7.6.5. A sequence of n positive integers a1, a2, . . ., an is super-
increasing if the following inequalities hold
a1 < a2,
a1 + a2 < a3,
a1 + a2 + a3 < a4,
...
a1 + a2 + · · · + an−1 < an.
Is there a solution to the knapsack problem in this case? The answer is not
always in the aﬃrmative but, if a solution exists, then it is unique and can
be found in polynomial time. Indeed, to ﬁnd the value x1, . . . , xn such that
m = n
i=1 xiai with xi ∈{0, 1} the following algorithm may be used
As a ﬁrst thing, determine xn, by noticing that necessarily:
xn =

1
if m ≥an,
0
if m < an.
To determine xn−1, do the same, substituting m−xnan for m. In other words,
we look for a solution to the knapsack problem by trying to express m−xnan
as
m −anxn = a1x1 + a2x2 + · · · + an−1xn−1.
Notice that, clearly, the sequence a1, a2, . . . , an−1 is superincreasing too. So
we have
xn−1 =

1
if m −xnan ≥an−1,
0
if m −xnan < an−1.

348
7 Secrets. . . and lies
In general, having found xn, . . . , xj+1, we shall set
xj =
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
1
if m −
n

i=j+1
xiai ≥aj,
0
if m −
n

i=j+1
xiai < aj.
It is clear that if m −n
i=j+1 xiai = 0, we have found the solution, which is
clearly unique. If on the other hand m −n
i=j+1 xiai > 0 but aj, . . . , a1 are
greater than m −n
i=j+1 xiai, then no solution exists.
It is not hard to see that the algorithm just described is of polynomial
type (see Exercise A7.9).
Let us illustrate with an example this algorithm.
Example 7.6.6. Consider the superincreasing sequence (1, 4, 6, 13, 25). How
do we compute the solution when m = 26 according to the algorithm?
As the rightmost term of our sequence is 25 and 25 < 26, then we have to
choose x5 = 1. Now we carry on the procedure with 26 −1 · 25 = 1 < 13, so
we set x4 = 0. As 26 −1 · 25 −0 · 13 = 1 < 6, then x3 = 0, hence again x2 = 0.
The last step, applied to 26 −1 · 25 −0 · 13 −0 · 6 −0 · 4 = 1 = a1 gives x1 = 1
and so the solution. In fact, we have
26 = 1 · 1 + 0 · 4 + 0 · 6 + 0 · 13 + 1 · 25.
Notice that if the sequence were (2, 3, 6, 13, 25), there would have been no
solution, as in the last step we should have written 1 as x1 · 2, which is
not possible. In other words, the solution does not exist because a1 = 2 >
26 −1 · 25 −0 · 13 −0 · 6 −0 · 3.
Let us see now how to construct a cipher related to the knapsack problem.
7.6.1 Public key cipher based on the knapsack problem,
or Merkle–Hellman cipher
The cipher consists of the following steps.
•
Each user X chooses a superincreasing sequence a1, a2, . . . , aN of a ﬁxed
length N, an integer m such that m > 2aN, and an integer w relatively
prime with m. These data are kept secret.
•
User X computes the transformed sequence
bj = waj mod m,
for j = 1, . . . , N.
The sequence b1, b2, . . . , bN is made public by X and is the enciphering
key.

7.7 The RSA system
349
•
A user Y may send a message p to X acting as follows. First of all, he
transforms each letter of the text into its binary equivalent using Table
7.5 on page 333. Next, he splits up the resulting sequence of 0s and 1s
into blocks of length N, adding at the end, if necessary, a number of
1s so as to have blocks all of the same length N. For each block, say
p = x1x2 . . . xN, the user Y applies the transformation to encipher p →
c = b1x1 + · · · + bNxN, and sends the enciphered text c to X.
•
How has X to proceed to decipher Y ’s message? As a ﬁrst thing, X com-
putes the deciphering key, that is, kd = (m, ¯w) with w ¯w = 1 (mod m).
Next, he computes
v = ¯wc mod m = ¯w · (b1x1 + · · · + bNxN) mod m.
(7.6)
By deﬁnition of ¯w and of the bis, we have
v = ( ¯wb1x1 + · · · + ¯wbNxN) ≡
N

i=1
xiai
(mod m).
(7.7)
As the sequence a1, a2, . . . , aN is superincreasing, we have
a1 + · · · + aN−1 + aN < aN + aN = 2aN < m
and so v = N
i=1 xiai.
•
Now, X knows the integer N
i=1 xiai and the superincreasing sequence a1,
a2, . . ., aN; from them he has to reconstruct the integers x1, x2, . . ., xN.
This is easily done, in polynomial time, by using the knapsack algorithm
for superincreasing sequences.
Remark 7.6.7. Choosing the data in a suﬃciently general way, the sequence b1, . . .,
bN is no more superincreasing, and decrypting illegitimately the message starting
with c = b1x1 + · · · + bNxN is a computationally hard problem.
Actually, in 1982 Shamir [52] found a polynomial algorithm that allows one to
decrypt the message. The main remark by Shamir is that the knapsack problem
to be solved for a sequence of the form b1, . . . , bN is not completely general. Indeed
b1, . . . , bN, even if it is not a superincreasing sequence, may be obtained from a
superincreasing sequence a1, . . . , aN by means of a very simple transformation.
For these reasons, the cipher just described cannot be considered secure. There
are several ways to get around this problem, and quite recently some variations of
Merkle–Hellman cipher have been found, that have not yet succumbed to cryptan-
alysts’ attacks. However, the description of these variations goes beyond the scope
of this book.
In Table 7.10 on page 350 we show an example of the use of this cipher.
7.7 The RSA system
In this section we describe a public key cryptosystem devised by W. Diﬃe
and M. E. Hellman [19], but commonly called RSA system, from the names

350
7 Secrets. . . and lies
Table 7.10. Knapsack problem cipher
Choice of secret data
(a1, . . . , an), m, w
(a1, a2, a3, a4) = (1, 2, 4, 27),
m = 61, w = 17
Public key to encipher:
b1 = wa1 mod m,
. . ., bn = wan mod m
(b1, b2, b3, b4) =
= (17, 34, 68, 459) mod 61
= (17, 34, 7, 32)
Private key to
decipher: (m, ¯w) with
¯ww ≡1
(mod m)
m = 61, ¯w = 18
Plaintext
ciao
Numerical equiv. of the message
00010 01000 00000 01110
Into blocks of length n = 4
0001 0010 0000 0000 1110
Numerical equiv. of the ciphertext
p = (x1, x2, x3, x4) →
→c = 4
i=1 xibi mod m
32 7 0 0 58
Compute v = ¯wc mod 61 =
= x1a1 + · · · + x4a4
576 126 0 0 1044 =
= 27
4
0 0
7
Binary num. equiv. of the
deciphered text: knapsack
algorithm for v and the ais
0001 0010 0000 0000 1110
Deciphered text
ciao
of those who ﬁrst implemented it: L. M. Adleman, R. L. Rivest, A. Shamir at
M.I.T. (Massachusetts Institute of Technology) [1]. This system, as already
remarked, uses a public key that allows enciphering a message but not deci-
phering it. Each user divulges his enciphering key, so anybody may securely
communicate with him. This happens using an enciphering method which is a
trapdoor function. The user who divulges the enciphering key keeps secret an
additional piece of information, by which he alone will be able, by inverting
the trapdoor function, to decipher the messages he will receive.

7.7 The RSA system
351
Applications of systems of this kind are innumerable: sending enciphered
messages among several users, digital authentication of signatures, access to
secure archives or databases or simply services such as credit cards, pay-per-
view television programmes, and so forth. We shall not enter into the technical
details, leaving the reader with the task of thinking about how the systems
we are going to describe can be applied to these situations.
7.7.1 Accessing the RSA system
Suppose we want to use the RSA system to exchange messages that are to be
read only by the intended addressees and not by eavesdroppers. Then we have
to join the system, divulging the enciphering key, which is a pair of positive
integers (n, e), where n is the product of two large prime numbers p and q we
only know, and e must be relatively prime with ϕ(n) = (p −1)(q −1), that
is, GCD(e, ϕ(n)) = 1, or GCD(e, p −1) = GCD(e, q −1) = 1. This pair of
integers (n, e) we divulge is kept in a publicly accessible directory.
Remark 7.7.1. How do we proceed in practice to ﬁnd two large prime numbers
having, for instance, 100 decimal digits? We generate a random 100-digit odd num-
ber m. Random generation of numbers is an interesting topic in mathematics and
computer science, upon which we cannot dwell here. Here it suﬃces to know that
there are programs that generate random numbers.
Apply next to m a primality test. If m passes it, then we have found a prime.
Otherwise, we apply the primality test to m + 2. If m + 2 is not prime either, we
test m + 4, and so on, until a prime number is found. Recall that, by the prime
number theorem, the number π(m) of prime numbers smaller than m is of the same
order as m/log m (see page 155). A probabilistic rephrasing of the same theorem
states that the frequency with which prime numbers appear near m is 1/log m. So
we may expect to have to perform O(log m) primality tests before ﬁnding the ﬁrst
prime number larger than m. So the number of tests to be performed is polynomial,
and so it is feasible. On the other hand, the computational cost of the test itself is
usually high.
Returning to the RSA system, each user U will act in the same way, that
is to say, divulging a pair of integers (nU, eU) verifying the same conditions:
nU has to be the product of two prime numbers pU and qU that must be
large and have to be kept secret, only known to user U, while the second
number has to be chosen by U in such a way that GCD(eU, pU −1) = 1 and
GCD(eU, qU −1) = 1.
We emphasise the fact that the pair (nU, eU) is publicly known, that is,
every user who so desires may look it up, while the factorisation of nU is
not public and is only known to U. To see how the RSA system works, let
us consider an example in detail. The general scheme of the procedure is
described in Table 7.12 on page 360.
Example 7.7.2. In the public directory, next to the name of each person,
their enciphering key will be shown, that is, the pair of integers the user has
chosen: for instance,

352
7 Secrets. . . and lies
Ariadne divulges A = (77, 13),
Beatrix divulges B = (1003, 3),
Charles divulges C = (247, 5),
David divulges D = (703, 7).
(7.8)
The numbers have been chosen by the users according the requisites, as
nA = 77 = 7 · 11,
GCD(13, 6) = GCD(13, 10) = 1,
nB = 1003 = 17 · 59,
GCD(3, 16) = GCD(3, 58) = 1,
nC = 247 = 13 · 19,
GCD(5, 12) = GCD(5, 18) = 1,
nP = 703 = 19 · 37,
GCD(7, 18) = GCD(7, 36) = 1.
Notice that in this example we have chosen small numbers, for which it
is easy to ﬁnd the two prime numbers pU and qU such that nU = pUqU. In
general, user U, to be safe, shall use an integer nU that is the product of two
primes of about 100 decimal digits, so the number nU that is their product
and that will be divulged, will have about 200 digits. Notice that in order to
implement these kinds of ciphers there is a crucial need for many large prime
numbers. By the way, this fact largely justiﬁes the research about primality
tests, as well as the hunt for ever larger prime numbers, which is often covered
even by the media. Returning to our example, let us see the next steps, after
the publication of the key chosen by each of the users.
7.7.2 Sending a message enciphered with the RSA system
User A, Ariadne, has received from user B, Beatrix, a message saying: Which
course do you prefer? She wants to answer:
algebra .
To send her answer to Beatrix, Ariadne will have to proceed as follows.
(1) As a ﬁrst thing, she transforms each letter of the message into an integer
using the 2-digit numerical equivalence, as in Table 7.5 on page 333. Indeed,
for the enciphering we are about to describe we shall need the letter-
number correspondence assigning two digits to each number associated
with a letter. The number sequence corresponding to our message will be
00 11 06 04 01 17 00 .
(2) Next, Ariadne looks up in the oﬃcial directory (7.8) the pair of num-
bers (nB, eB) corresponding to Beatrix. Presently she just needs the ﬁrst
number, nB = 1003.
(3) Now she has to split up the message to be sent into unitary messages
so that the integer associated with each unitary message is smaller than

7.7 The RSA system
353
nB = 1003 and relatively prime with 1003. She notices that, having split
up the message algebra into 2-letter blocks (or digraphs) as follows
al
ge
br
ax ,
the numbers corresponding with the unitary messages are
0011
0604
0117
0023 ,
that is, the numbers 11, 604, 117, and 23, respectively, which are smaller
than 1003 and relatively prime with 1003. Notice that, to ﬁnd the GCD
between these numbers and 1003, Ariadne uses the Euclidean algorithm,
as she does not know the prime decomposition of nB.
Notice further that Ariadne added the letter x at the end of the last
unitary message, to make it a digraph. If she had split up the message
into 3- rather than 2-letter blocks, she would have found some unitary
messages corresponding to integers greater than nB:
alg −→606 < 1003,
ebr −→40117 > 1003,
axx −→2323 > 1003,
which would not have satisﬁed our requisites.
So the segments of the plaintext will be represented by the following num-
bers:
P1 = 11,
P2 = 604,
P3 = 117,
P4 = 23.
If the numbers Pi were not relatively prime with 1003, we might neverthe-
less proceed in a way not dissimilar from the one we are about to describe;
we are not dwelling on the diﬀerences, which the reader may study in
Exercise A7.12.
After these operations, we may assume without loss of generality that each
unitary message Pi meets the following two conditions:
Pi < nB,
GCD(Pi, nB) = 1.
(4) Now the actual enciphering of the message to Beatrix begins, in such a
way that the latter may decipher it and be the only person able to do so in
a reasonable time. To encipher the message to be sent to Beatrix, Ariadne
raises each Pi to the eBth power, eB being the second element of the pair
associated with Beatrix.
So the enciphering function is
CB : P −→C,
P −→C = P eB mod nB.
Thus, the enciphered message Ariadne will have to send will consist of the
following numbers:

354
7 Secrets. . . and lies
C1 = P eB
1
mod nB = 113 mod 1003 = 328,
C2 = P eB
2
mod nB = 6043 mod 1003 = 797,
C3 = P eB
3
mod nB = 1173 mod 1003 = 825,
C4 = P eB
4
mod nB = 233 mod 1003 = 131.
Then Beatrix receives the following message:
C1 = 328,
C2 = 797,
C3 = 825,
C4 = 131,
consisting of the unitary messages Ci, i = 1, . . . , 4. Now Ariadne has carried
out her task: she has sent Beatrix the enciphered message. Now Beatrix will
have to decipher it.
7.7.3 Deciphering a message enciphered with the RSA system
Beatrix has received the message
C1 = 328,
C2 = 797,
C3 = 825,
C4 = 131,
and has to decipher it, that is, for every Ci has to ﬁnd the original message
Pi, knowing that
Ci = P eB
i
mod nB.
So Beatrix has to determine the deciphering function
DB : C −→P
such that DB(EB(Pi)) = Pi for all i. How can she ﬁnd it? A priori it would
seem that, to solve this problem, Beatrix would have to ﬁnd a discrete loga-
rithm which, as we have remarked, is computationally quite hard. However,
we have already remarked at the beginning that Beatrix actually has an ad-
ditional piece of information enabling her to decipher the message she has
received without diﬃculty. Let us see which piece of information she has and
how she uses it. First of all, Beatrix determines dB, with
1 ≤dB < ϕ(nB) = (pB −1)(qB −1),
such that dB is a solution of the following congruence
eBdB ≡1
(mod ϕ(nB)) .
(7.9)
Such a solution exists and is unique, as GCD(eB, ϕ(nB)) = 1.
In our case, nB = 1003, and Beatrix knows ϕ(1003) because she knows
that 1003 = 17 · 59. So ϕ(1003) = 16 · 58 = 928. Then the solution dB of the
congruence (7.9), that is of 3x ≡1 (mod 928), is

7.7 The RSA system
355
dB = 619 .
This number is truly to be framed, because, as we shall shortly see, Beatrix
is the only person who can decipher the message because she is the only one
who, knowing the factorisation of 1003, is able to compute its Euler function
and so dB, which is Beatrix’s private key to decipher the messages sent to
her. Let us what she does to decipher the messages Ci.
Beatrix raises each Ci to the power dB = 619, that is, computes
328619,
797619,
825619,
131619.
The exponent 619 is large, but we know how to proceed in situations like this
(see § 3.3.1). The number 619 is written in base 2, that is
619 = (1001101011)2 = 512 + 64 + 32 + 8 + 2 + 1.
So we have
C619
i
= C512
i
· C64
i
· C32
i
· C8
i · C2
i · C1
i
and the powers are easily computed according to the following table, for C1 =
328:
k
Ck
1 mod 1003
1
328
2
3282 mod 1003 = 263
22=4
2632 mod 1003 = 965
23 = 8
9652 mod 1003 = 441
24 = 16
4412 mod 1003 = 902
25 = 32
9022 mod 1003 = 171
26 = 64
1712 mod 1003 = 154
27 = 128
1542 mod 1003 = 647
28 = 256
6472 mod 1003 = 358
29 = 512
3582 mod 1003 = 783
where we have framed the factors to be multiplied. From the table we may
easily see that
328619 = 328512 · 32864 · 32832 · 3288 · 3282 · 3281 ≡
≡783 · 154 · 171 · 441 · 263 · 328 ≡11
(mod 1003).
Notice that, by raising C1 = 328 to the exponent dB = 619, we have obtained
the number 11 = P1, which is the number corresponding to the ﬁrst part of
the original message.
We do the same for the three other message segments C2, C3 and C4. So
we get Table 7.11 on page 356 where, as above, we have framed the factors to
be multiplied. In conclusion,

356
7 Secrets. . . and lies
Table 7.11. Powers of the numbers Ci
k
Ck
2 mod 1003
Ck
3 mod 1003
Ck
4 mod 1003
1
797
825
131
2
7972 ≡310
8252 ≡591
1312 ≡110
4
3102 ≡815
5912 ≡237
1102 ≡64
8
8152 ≡239
2372 ≡1
642 ≡84
16
2392 ≡953
1
842 ≡35
32
9532 ≡494
1
352 ≡222
64
4942 ≡307
1
2222 ≡137
128
3072 ≡970
1
1372 ≡715
256
9702 ≡86
1
7152 ≡698
512
862 ≡375
1
6982 ≡749
328619 mod 1003 = 11,
797619 mod 1003 = 604,
825619 mod 1003 = 117,
131619 mod 1003 = 23.
These are to be seen as 4-digit numbers:
0011,
0604,
0117,
0023,
and correspond to the four original message segments, which were digraphs.
So we have to split each of them into two parts, each of which represents a
letter. So Beatrix, using Table 7.5 on page 333, ﬁnds
00 11 06 04 01 17 00 23
a
l
g
e
b
r
a x
and gets to know the course Ariadne likes best.
With did this work? That is, why raising Ci to the exponent dB we get
back Pi such that Ci = P eB
i
? In other words, why is
DB : C −→P,
Ci −→CdB
i
the deciphering function? Here follows the reason.
7.7.4 Why did it work?
First of all, notice that the congruence (7.9) has exactly one solution modulo
ϕ(nB), because the coeﬃcient eB is such that
GCD(eB, pB −1) = 1,
GCD(eB, qB −1) = 1,
so also GCD(eB, (pB −1)(qB −1)) = 1.

7.7 The RSA system
357
Remark 7.7.3. Beatrix is the only person able to solve congruence (7.9),
because she is the only one to know the Euler function ϕ(nB) = (pB −1)(qB −
1), as she knows the prime factors pB and qB of nB. In fact, notice that, as
pB and qB are large prime numbers, factoring nB normally takes a very long
time. So, in fact, Beatrix is the only one to know this factorisation.
Actually, one might doubt that knowing ϕ(nB) is equivalent to knowing
the prime factors pB and qB. Of course, whoever knows these factors knows
ϕ(nB) too. But, is it possible to know ϕ(nB) without knowing pB and qB?
The answer is no: if ϕ(nB) is known, then pB and qB can be reconstructed
immediately, in polynomial time. The easy proof is left as an exercise (see
Exercise A7.10).
Notice now that dB is actually the private key allowing Beatrix to decipher
the message. Indeed, setting P = Pi and C = Ci, we have
P ≡CdB
(mod nB),
as
CdB ≡(P eB)dB = P eBdB
(mod nB).
On the other hand, eBdB ≡1 (mod ϕ(nB)) implies that eBdB−1 is a multiple
of ϕ(nB), that is eBdB = 1 + ϕ(nB)k for some k. So,
P eBdB = P 1+ϕ(nB)·k = P · (P ϕ(nB))
k.
As GCD(P, nB) = 1, by Euler’s theorem we have P ϕ(nB) ≡1 (mod nB);
hence
P eBdB ≡P
(mod nB).
So,
P ≡CdB
(mod nB).
As Ariadne has chosen P < nB, there is no ambiguity in determining the
number congruent to CdB modulo nB: it is the only such number between 0
and nB −1. Once this P is found, Beatrix can read Ariadne’s message.
Remark 7.7.4. We have said that the unitary message has to be smaller than nB.
We have just explained the reason of this request. An example will illustrate the
need for it. Consider the message
no
to be sent to Ariadne, whose pair is (nA = 77, eA = 13). We opt to consider the
whole word no as unitary message (digraph). We proceed as above:
(1) transform the message into a number by associating to each letter its numerical
equivalent. The associated number is found to be
1314;
notice that 1314 is greater than nA = 77;

358
7 Secrets. . . and lies
(2) raise 1314 to the power eA = 13; we have
C1 = 131413 ≡26
(mod 77);
(3) Ariadne receives the message
26.
To decipher this message Ariadne uses her private key, which is dA = 37, the
solution of the congruence
13dA ≡1
(mod ϕ(77)),
that is
13dA ≡1
(mod 60).
Raising 26 to the power 37, Ariadne gets 5 (mod 77), which she interprets as
f
so she cannot reconstruct the message she was sent. Also notice that 1314
(mod 77) = 5.
So, if we do not request for the unitary message to be smaller than nA, that
is, than the ﬁrst element of the pair of numbers published by the addressee, it
becomes impossible to deﬁne the deciphering transformation.
Remark 7.7.5. We have seen that, in order to send the message algebra to Beatrix,
Ariadne split it up into digraphs. She had to do so by trial and error, verifying all the
numbers corresponding to the single digraphs to be smaller than nB and relatively
prime with it.
However, there is a better way of choosing how to split up the message: rather
that splitting the original message algebra, it is more convenient to split the numer-
ical message obtained by associating a 2-digit number with each letter. In this way
there is a natural way of splitting it, as follows.
After transforming the message into a sequence of 2-digit numbers, consider the
number consisting of the sequence of all the digits, which will be called numerical
message. Split it up into k-digit blocks, where
k = (number of digits of nB) −1 .
In this way, without even having to examine the message, each unitary numerical
message is smaller than nB. What’s more, everybody concerned knows nB and knows
that the sender will split up the message into blocks like this.
Let us illustrate this new method with an example.
Example 7.7.6. Suppose Ariadne, user A, sends Beatrix, user B, the message
come here
Then:
(1) ﬁrst of all Ariadne transforms the message, ignoring spaces, into the sequence of
2-digits numbers
02
14
12
04
07
04
17
04
which will be written as
0214120407041704.
There is no ambiguity, as we know that the number associated with each letter
of the original message consists of two digits. This is the numerical message;

7.7 The RSA system
359
(2) as the number nB = 1003 has 4 digits, A splits the numerical message into blocks
of length 4 −1 = 3, that is, into trigraphs, as follows:
021
412
040
704
170
423 .
Notice that A has added 23, corresponding to the letter x, at the end of the
message, so all unitary numerical messages consist of three digits. In this way,
she has split the numerical message into unitary numerical messages that are
trigraphs, and each unitary message is certainly smaller than nB = 1003. Notice
that this partitioning is not a partition of the original message come here, as the
3-digit unitary numerical blocks do not correspond to any letter group. As we
shall see, this will not create any diﬃculty.
We still have to check that each Pi is relatively prime with 1003. It is easily
veriﬁed that the only exception is 170. However, we have no reason to worry:
keeping in mind Exercise A7.12, we may go on.
So, the unitary numerical messages are
P1 = 21,
P2 = 412,
P3 = 40,
P4 = 704,
P5 = 170,
P6 = 423.
Notice that the operations carried out so far do not amount to any enciphering,
as transforming a message into a numerical sequence is a standard operation,
and so is partitioning it into 3-digit blocks according to the value nB, which is
known to everybody;
(3) the enciphered message will be represented by the following numbers:
C1 = P eB
1
mod nB = 213 mod 1003 = 234,
C2 = P eB
2
mod nB = 4123 mod 1003 = 353,
C3 = P eB
3
mod nB = 403 mod 1003 = 811,
C4 = P eB
4
mod nB = 7043 mod 1003 = 54,
C5 = P eB
5
mod nB = 1703 mod 1003 = 306,
C6 = P eB
6
mod nB = 4233 mod 1003 = 587.
So Beatrix receives the following sequence of unitary messages:
C1 = 234, C2 = 353, C3 = 811, C4 = 54, C5 = 306, C6 = 587.
To decipher it, she raises each Ci to her private key dB = 619, that is, she computes
234619, 353619, 811619, 54619, 306619, 587619.
In this way, Beatrix ﬁnds
234619 mod 1003 = 21,
353619 mod 1003 = 412,
811619 mod 1003 = 40,
54619 mod 1003 = 704,
306619 mod 1003 = 170,
587619 mod 1003 = 423.
This 3-digit blocks (completed with a leading zero where necessary), regrouped in
twos, give
02, 14, 12, 04, 07, 04, 17, 04, 23
and now Beatrix can read the message comeherex, which she understand as come
here. This example is shown in Table 7.12 on page 360.

360
7 Secrets. . . and lies
Table 7.12. Example of use of RSA system
Each user U publishes
the pair (nU, eU), where
nU = pUqU is the product
of two secret primes
and GCD(eU, ϕ(nU)) = 1
A publishes
(nA, eA) = (77, 13),
B publishes
(nB, eB) = (1003, 3)
Plaintext
A wants to send B
come here
2-digit numerical equiv.
of the message
02 14 12 04 07 04 17 04
k-letter blocks Pi
where k is the number of
digits of nB, minus 1
P1 = 021, P2 = 412,
P3 = 040, P4 = 704,
P5 = 170, P6 = 423
Sending B the enciphered
unitary messages
Ci = P eB
i
mod nB
C1 = 234, C2 = 353,
C3 = 811, C4 = 54,
C5 = 306, C6 = 587
B deciphers the enciphered messages:
Pi = CdB
i
mod nB
where dB is such that
eBdB ≡1
(mod ϕ(nB))
P1 = 021, P2 = 412,
P3 = 040, P4 = 704,
P5 = 170, P6 = 423
Deciphered text
comeherex
7.7.5 Authentication of signatures with the RSA system
The RSA system allows one to solve of an important problem which is more and
more relevant in this era of telecommunications: the problem of digitally authenti-
cating a signature.
If Beatrix receives a message from a person signing herself Ariadne, how can she
be sure the sender was actually Ariadne? The certainty may be achieved as follows.
Ariadne writes her message P1, putting at the end her signature F; to authen-
ticate the signature, Ariadne adds after the message P1 the message
P2 = F dA mod nA,
where dA is her private key, that is, the key known only to her, because only she
knows the factorisation of her public key nA. Then she sends Beatrix the message
P consisting of the two messages P1 and P2 as usual, that is, raising P1 and P2 to
the power eB and reducing them modulo nB.

7.7 The RSA system
361
On receiving the message, Beatrix reads it using her private key dB. Deciphering
message P1, she learns that the message was sent by Ariadne, because the message
is signed with Ariadne’s signature F. But was really Ariadne, and not someone else,
who used that signature? Here the section P2 of the message gives an answer. Indeed,
it consists of some undecipherable characters, which nevertheless contain the proof
of the authenticity of the signature.
Now Beatrix, to verify the authenticity, has to proceed as follows. To decipher P2
she cannot use her private key dB, which would be useless, as the original message
F was enciphered raising it not to the power eB but to dA. Instead, Beatrix uses
Ariadne’s public key eA. In this way she obtains Ariadne’s signature F, because
P2
eA ≡(F dA)
eA = F dAeA ≡F
(mod nA).
This signature has to be authentic, as only Ariadne knows her private key. If what
appeared were not Ariadne’s signature F, the message would have been a fake.
Basically, to authenticate a signature, the sender uses her private key, rather than
the addressee.
Example 7.7.7. Recall that Ariadne published the pair (nA = 77, eA = 13). As
77 = 11 · 7, Ariadne’s private key is dA = 37, because 37 · 13 ≡1 (mod 60), where
60 = ϕ(77). In sending a message to Beatrix, Ariadne authenticates her signature,
which we assume to be F = 5, raising 5 to the power dA modulo nA:
537 mod 77 = 47.
Beatrix veriﬁes the authenticity of the signature by raising 47 to the power eA = 13
modulo nA:
4713 mod 77 = 5,
that is, she gets again Ariadne’s signature. So Beatrix is sure that the message’s
author is Ariadne.
The previous example is summarised in Table 7.13.
Table 7.13. Authentication of a signature with the RSA system
A sends B her
signature F and
G = F dA mod nA
F = 5
G = 537 mod 77 = 47
B computes GeA mod nA
4713 mod 77 = 5
If GeA mod nA = F,
the signature is authentic
OK!

362
7 Secrets. . . and lies
7.7.6 A remark about the security of RSA system
The security of RSA system lies in the fact that, as already emphasised several times
in earlier chapters, so far there is no eﬃcient algorithm to factor large numbers. If A
sends B a message C, an unauthorised eavesdropper who tried to decrypt it should
be able to ﬁnd the factorisation of nB. To ﬁnd it, when nB is the product of two
60-digit primes, even using the most advanced algorithms and the fastest computers,
would require several months, if not years. The situation is even more unfeasible if
we choose primes with 100 or more digits: in this case factoring n is, in practice,
impossible. However, if this is true in general, it is not always so, as the following
episode shows.
In August 1977 the three inventors of the public key RSA cryptosystem, Rivest,
Shamir and Adleman, at MIT, challenged from Martin Gardner’s column Mathemat-
ical Games the readers of Scientiﬁc American to decrypt a message corresponding
to a 129-digit number, an operation they believed to require billions years. They
oﬀered a reward of $100 to whomever found the solution.
We are not going to give all the details of Rivest, Shamir and Adleman’s problem.
Suﬃce it to say that, in order to decrypt their original message it was necessary to
factor the number
N =11438162575788886766923577997614661201021829672124236256256184293
5706935245733897830597123563958705058989075147599290026879543541,
which had been published together with the number e = 9007. Basically, (N, e) was
the public key of Rivest, Shamir and Adleman.
To ensure that the message came from the MIT team, the following digital
signature was added, using the private key of the algorithm, that is the number d
such that ed ≡1 (mod N):
1671786115038084424601527138916839824543690103235831121783503844
6929062655448792237114490509578608655662496577974840004057020373.
Raising this number to the power 9007, then reducing it modulo N, one obtained
the number
0609181920001915122205180023091419001
5140500082114041805040004151212011819
corresponding, in Rivest, Shamir and Adleman’s cipher, to the sentence:
First solver wins one hundred dollars,
which guaranteed that the message really came from MIT.
Seventeen years later, the Dutch mathematician Arjen K. Lenstra, together with
a team of hundreds, in just 8 months managed to ﬁnd the solution. The technique
used in tackling the problem is the so-called multiple polynomial quadratic sieve,
a technique that allows to split up the task into several smaller subtasks. Using
this sieve, the possible factors are found among millions of candidates. To organise
the work, Lenstra needed hundreds of collaborators all over the world and involved
thousands of computers, the whole enterprise being coordinated via the Internet.

7.8 Variants of RSA system and beyond
363
The results of this collective eﬀort were sent Lenstra: two days’ computations with
a supercomputer produced a 64-digit and a 65-digit factor. This allowed Lenstra to
decrypt the message by Rivest, Shamir and Adleman.
Are you curious to know what the message said? It said:
the magic words are squeamish ossifrage.
The three scientists themselves said that it was a meaningless sentence: they
would never have supposed, when they wrote it, that it would someday emerge. What
had seemed an impossible challenge, seventeen years later turned out to be within
the grasp of the most advanced researchers. The conclusion is that cryptography is
still, in several regards, an experimental science. It still relies on several conjectures,
such as Diﬃe–Hellman hypothesis, we shall deal with shortly, which might be, if
not completely contradicted, at least quite diminished when new algorithms are
invented that, at least in many cases, do a good work to elude them. So, when there
are no theorems telling us whether a given cryptographic procedure is secure, it is
convenient to be careful rather than doing as if it were certainly so. A system that
today is believed to be secure might not be so tomorrow, as we shall see in Chapter 9.
7.8 Variants of RSA system and beyond
We are now going to describe some cryptosystems, the ﬁrst of which is a variant of
RSA system. Its security relies on the problem of computing discrete logarithms.
7.8.1 Exchanging private keys
The RSA system, or rather a slight modiﬁcation of it, allows two users to exchange
a private key with which, independently of the public key system, they can exchange
enciphered messages using one of the classic methods discussed at the beginning of
this chapter.
Let us modify the RSA system as follows. Choose a very large prime number p,
which is divulged, and work in the ﬁeld Zp. Actually, we might work in any ﬁnite ﬁeld
Fq, but we shall limit ourselves to p-element ﬁelds. Choose next a non-zero element
g ∈Zp, which is divulged too. The most convenient choice, to use in the best way
the system’s resources, would be to choose as g a generator of the multiplicative
group of the ﬁeld Zp. However, this is not strictly necessary.
Moreover, each user U chooses his private key eU, which is a positive number
smaller than p −1, and divulges geU ∈Zp, that is, the positive number XU =
geU mod p. Notice that, from XU, it is not possible to reconstruct in a reasonable
time U’s private key eU. Indeed, this would imply ﬁnding a discrete logarithm which,
as we know, requires in general an exponential time.
Let us see now how two users A and B may proceed to exchange a private
key. There is a very simple method: A and B may agree to use as a private key
geAeB ∈Zp, that is, the number
XAB = geAeB mod p.
Indeed, both A and B can compute XAB in polynomial time. For instance, A knows
XB, which is public. Moreover, she knows her private key eA. So she computes

364
7 Secrets. . . and lies
XeA
B
= (geB)eA mod p = XAB. Similarly, B knows XA and eB, so can compute
XeB
A
= (geA)eB mod p = XAB.
On the other hand, an eavesdropper C will ﬁnd it hard to compute XAB. In
fact, he knows XA and XB, but how can he reconstruct XAB from them? In order
to do so, he probably should ﬁnd ﬁrst eA and eB, and compute next geAeB, which
would ﬁnally allow him to ﬁgure out XAB. But in order to ﬁnd eA and eB, C should
compute some discrete logarithms, which is computationally unfeasible.
But, are we certain that to compute XAB knowing XA and XB it is necessary
to compute some discrete logarithms? In other words, are we sure that in order to
compute geAeB knowing geA and geB it is necessary to know eA and eB? So far,
nobody has proved nor disproved this fact. Nevertheless, it is conjectured that the
complexity of computing geAeB knowing geA and geB is equal to that of ﬁnding dis-
crete logarithms: this is the so-called Diﬃe–Hellman hypothesis. On this hypothesis
the security of this method of exchange of private keys is based.
Example 7.8.1. Assume p = 19 and g = 2 have been divulged. Let eA = 16 and
eB = 11 be the private keys of A and B, respectively. Then A and B publish the
values
XA = 216 mod 19 = 5,
XB = 211 mod 19 = 15,
respectively. The common key A and B will use to exchange messages is XAB =
geAeB mod 19. A will compute it as follows:
XAB = XeA
B
mod 19 = 1516 mod 19 = 6.
Clearly B gets the same result by computing
XeB
A
mod 19 = 511 mod 19 = 6.
Notice that A and B can now use the key 6 to exchange messages enciphered, for
instance, using a Caesar cipher operating on 26 letters: 6 might be the enciphering
key, that is, the number of positions the letters are shifted in Caesar cipher.
7.8.2 ElGamal cryptosystem
Fix a large ﬁnite ﬁeld Fq (we may well take Zp, for a large p) and an element
g ∈F∗
q (preferably, but not necessarily, a generator of F∗
q). We shall assume that the
numerical equivalents of the messages are in Fq.
Each user A has a public key and a private key: the private key is an integer
a = aA, randomly chosen by A (0 < a < q −1), while the public key is ga ∈Fq.
Assume B wants to send A a message P. Then B proceeds as follows:
•
B randomly chooses an integer k < q;
•
he computes gk in Fq;
•
he computes gak in Fq;
•
he multiplies the message P by gak in Fq;
•
he sends A the pair (y1 = gk, y2 = P · gak).
Notice that in order to compute gak it is not necessary to know A’s private key;
it suﬃces to know ga, as gak = (ga)k.

7.8 Variants of RSA system and beyond
365
On receiving the pair (y1, y2), A, who knows a, which is her own private key,
can discover the message P by raising y1 to the exponent a and dividing y2 by the
result found. Indeed,
y2 · ((y1)a)−1 = P · gak · ((gk)a)−1 = P.
Somebody who could solve the discrete logarithm problem could violate the
cryptosystem by determining the private key a from the knowledge of ga. In theory,
it could be possible to obtain gak knowing ga and gk (and so to arrive at the message
P), but here too, as already said in § 7.8.1, it is conjectured that solving this kind of
problem without solving the problem of computing discrete logarithms is impossible.
7.8.3 Zero-knowledge proof: or, persuading that a result is known
without revealing its content nor its proof
Suppose Paul has found a very important formula: he wants to persuade a colleague
he has found it, but without giving him any indication about the formula itself nor
about the way he has proved it. Is it possible? This kind of communication is said
to be a zero-knowledge protocol, that is to say, it is a communication that does not
transmit any information that could give away the formula or its proof, but lets the
addressee know we actually have it. It looks like an impossible feat. However, we
shall see that it is possible. Let us see an example to illustrate how to proceed.
Let G be a ﬁnite group with N elements, and let b and y be two elements of
G. Suppose Paul has found a discrete logarithm for y in base b, that is, he has
determined a positive integer x such that
bx = y.
His friend Sylvia is sceptical: Paul wants to convince her he knows x without telling
her x. Assume Sylvia knows the order N of the group G (the case in which Sylvia
does not know N can also be dealt with, but we shall not do so). They may proceed
as follows:
(1) Paul generates a random positive integer e < N and sends Sylvia
b′ = be;
(2) Sylvia tosses a coin: if it shows heads, Paul must disclose e to Sylvia and she
checks whether actually b′ = be;
(3) if the coin shows tails, then Paul must disclose the positive integer x+e mod N.
As bx = y and be = b′, we have bx+e = yb′. Sylvia will check that the number
has the required property (notice that Sylvia knows both y and b′).
The three steps are repeated (and so there will be a new choice of a random
integer e, a new coin toss, and so on), until Sylvia is convinced that Paul has actually
found the discrete logarithm of y.
How can she be convinced? If Paul did not really know the discrete logarithm
of y and were cheating, he would be able to answer just one of the two possible
questions. If the coin comes up as heads he certainly may disclose e, but if it comes
up as tails, how can he disclose x + e mod N without knowing x? He might try to
elude the problem by sending, in step (1), b′ = be/y rather than be: so, if tails shows

366
7 Secrets. . . and lies
up, he may reveal e = (e−x)+x (which he can easily do). But in this case he would
be exposed if the coin shows heads: indeed, in this case he should reveal e −x, and
how could he without knowing x?
By iterating the procedure a suﬃcient number of times, sooner or later Sylvia
will be persuaded that Paul actually knows what he claims to know.
So Paul manages to prove Sylvia that he knows the discrete logarithm x of y
without explicitly exhibiting x, and so his secret remains his own.
7.8.4 Historical note
This challenge scheme calls to mind the challenges that took place centuries ago.
In the 16th century a mathematician’s ability was demonstrated through “public
challenges”: these scientiﬁc duels were actual tournaments with witnesses, judges,
referees and so on. In these challenges fame and money were at stake. For this reason,
the most important discoveries were kept jealously secret. So, when a mathematician
came in possession of a new discovery, he sent a cartello di matematica disﬁda (public
mathematical challenge), in which he claimed to be able to solve a class of problems
and proposed in turn some of them, and the “contenders” engaged in proposing and
solving such problems.
Among the most famous challenges, there were those between Dal Fior and
Tartaglia (Nicol`o Fontana): the problems presented by Dal Fior can be reduced to
solving equations of the form x3 + px = q, which Dal Fior could solve because
their solution was transmitted him by his teacher Scipione Dal Ferro before dying.
Tartaglia proposed a series of problems reducible to the solution of equations of the
form x3 + mx2 = q, which he could solve. It happened that, even without knowing
the general formula for the equations in possession of Dal Fior, Tartaglia managed
to ﬁnd it in time to solve all the problems, while Dal Fior could not solve any.
Another renowned challenge was the one between Ferrari and Tartaglia in 1548:
Tartaglia in 1539 had given Cardano the solution of a class of third degree equations
(the casus non irriducibilis), making him promise he would not divulge it. In 1545
Cardano published his work “Ars Magna” in which, violating his promises, he gave
the formula to solve cubic equations. Tartaglia took oﬀence and Cardano’s pupil
Ferrari challenged him in another famous confrontation.
7.9 Cryptography and elliptic curves
So far we have only described the development of several classic and mod-
ern cryptographic methods, all based on algebraic, and mostly arithmetic,
ideas. In other words, these methods rely on properties of numbers or their
congruence classes.
In this section we are going to discuss some new frontiers recently opened
to cryptography, especially for what regards the security and the prevention of
cryptanalysis. This is due to the interaction of classic algebra and arithmetic
with ideas and notions from geometry, and in particular from the study of
certain plane curves called elliptic curves.

7.9 Cryptography and elliptic curves
367
7.9.1 Cryptography in a group
Before going on, we give explicitly a remark that, in an implicit form, we
have already mentioned elsewhere in this chapter. To ﬁx ideas, consider the
exchange of private keys through the RSA system, described in the previous
section. It relies on exponentiation in Zp, with p a prime number. Its easy
execution is due to the fact that exponentiating in Zp is computationally
easy, that is, requires a polynomial time. Its security, on the other hand,
depends on the fact that ﬁnding discrete logarithms in Zp is apparently much
harder computationally. More precisely, as we have seen, the Diﬃe–Hellman
hypothesis is relevant here (see page 364).
On the other hand, the theoretical basis of this cryptographic system works
with no changes if, rather than in the multiplicative group Z∗
p, we work in any
other ﬁnite group G. Leaving the description of the details of the scheme as an
exercise, we just remark that actually, to put in practice the theory, and so to
implement a cryptosystem to exchange private keys based on exponentiation
in an arbitrary ﬁnite group G, we must ask that:
•
it is possible to perform computations in G, that is, it is necessary that G
is given not only in a theoretical way, but operatively, in such a way that
we can actually work with its elements;
•
exponentiating in G is easy, that is, requires, for instance, a polynomial
computational cost;
•
determining discrete logarithms in G is computationally much harder, for
instance exponential, and that in G the Diﬃe–Hellman hypothesis holds,
that is, for a randomly chosen element g ∈G and for a, b ∈Z, computing
gab knowing ga and gb has the same computational diﬃculty as determining
discrete logarithms in G.
For instance, if Fq, q = pf, with p a prime number, is a ﬁnite ﬁeld and
G = F∗
q is its multiplicative group, then G has these properties, as:
•
G can be described concretely as an extension of Zp. Some of the examples
in Chapter 5 show how to describe its elements;
•
exponentiating is easy in group G, that is, it requires a polynomial com-
putational cost (see § 5.1.14);
•
just like in Zp, it is conjectured that determining discrete logarithms in
G has at least an exponential cost, and that in G the Diﬃe–Hellman
hypothesis holds: indeed, it is clear that if it holds in Zp then it holds in
F∗
q too.
So we may use in cryptography, and it is actually used, the multiplicative
group of a ﬁnite ﬁeld Fq rather than that of Zp with p a large prime. This
yields remarkable advantages. For instance, we may use ﬁelds of the form
F2n of characteristic 2, which are very suitable for a computational approach
because their elements can be described as n-tuples of 0s and 1s. Moreover,
by choosing a large n, F2n becomes in turn large very quickly, removing the

368
7 Secrets. . . and lies
need for a large prime p to construct Zp. Unfortunately, choosing F2n makes
life easier for cryptanalysis. Indeed, recently, in 1984, D. Coppersmith found
eﬃcient algorithms to compute discrete logarithms in these ﬁelds (see [14],
[44]).
So, which groups may we use to do cryptography? We would like groups
quite similar to F∗
q, which would make them familiar-looking and, most im-
portant, computationally easy to use. At the same time, we would have many
of them, to be able to choose among them, perhaps change them frequently,
to avoid too easy a cryptanalysis.
Here geometry lends us a helping hand. Let us explore the ideas that lead
to considering elliptic curves.
7.9.2 Algebraic curves in a numerical aﬃne plane
Rather than considering speciﬁcally Fq, consider an arbitrary ﬁeld K. So we
may deﬁne the numerical aﬃne plane A2
K with coordinates on this ﬁeld (see
[51]). Basically, this is just K×K. This terminology is not surprising, and has
already been used before. In fact, just consider the case K = R, leading to the
usual plane A2
R with cartesian coordinates (x, y).
In the aﬃne plane A2
K we may do geometry exactly as in the real cartesian
plane. For instance, we may consider algebraic curves. These are subsets of
A2
K deﬁned by an equation of the form
f(x, y) = 0,
(7.10)
where f(x, y) is a polynomial with coeﬃcients in K, which we assume to be
non-constant and without repeated factors. The curve deﬁned by (7.10) is
the set of points (u, v) ∈A2
K such that f(u, v) = 0. Clearly, substituting the
polynomial kf(x, y) for f(x, y), where k ∈K∗, we obtain the same curve.
The curve deﬁned by Equation (7.10) is said to be irreducible if the poly-
nomial f(x, y) is irreducible over K. Notice that this notion depends on the
ﬁeld K, because, as we know, a polynomial may be irreducible over K but not
over an extension of K.
Example 7.9.1. Consider the curve in A2
R having equation x2 + y2 = 0. It is
irreducible because such is the polynomial x2 + y2 over R. On the contrary,
the curve in A2
C with the same equation is reducible because we have x2+y2 =
(x + iy)(x −iy) over C.
Notice that the curve in A2
R having equation x2 + y2 = 0 consists of
the single point having coordinates (0, 0). So the deﬁnition must be studied
carefully: the notion of a curve includes sets which do not always correspond
to the intuitive idea of a curve as the reader may picture it!
If f(x, y) has degree d, we say that d is the degree of the curve of equation
(7.10). The curves of degree 1, which are clearly irreducible (see Exercise
A7.13), are called lines, those of degree 2 conic curves, those of degree 3
cubic, those of degree 4 quartic and so forth.

7.9 Cryptography and elliptic curves
369
7.9.3 Lines and rational curves
The x-axis, which has equation y = 0, may be identiﬁed in a natural way
with the ﬁeld K, as it consists of all points (x, 0), with x ranging in K. An
analogous remark can be made about the y-axis, which has equation x = 0.
More in general, every straight line may be easily identiﬁed with the ﬁeld
K. Indeed, a line R has equation of the form
ax + by + c = 0
(7.11)
where a and b are not both equal to zero. Assume b ̸= 0. Then we may project
the line R on the x-axis, associating with each point (u, v) of R the point
(u, 0) of the x-axis, which will be identiﬁed with u ∈K (see Figure 7.2). This
,
,
,
,
,
,
,
,
,
,
,
,
x
y
R : ax + by + c = 0
(u, v)
u
q
q
-
6
Fig. 7.2. Projection of a line R on the x-axis
mapping is bijective. Indeed, given u, we must have v = −(au + c)/b if the
point (u, v) is to lie on R. In other words, the projection is given by
π : (u, v) ∈R →u ∈K
and the inverse mapping is given by
π−1 : u ∈K →(u, −(au + c)/b) ∈R.
Analogously, if a ̸= 0, the line R of equation (7.11) can be projected on the
y-axis and the projection is bijective (see Exercise A7.14).
In conclusion, lines are not interesting from our viewpoint: in fact, recall
that our goal, in cryptography, is to ﬁnd groups diﬀerent from K∗.
The idea of projecting a curve on the x-axis to study it looks ﬁne. So let us
keep it. From this viewpoint, which are the simplest curves after the straight
lines? We might answer, for instance, those for which the projection, even if
not bijective, is almost always so, that is, is bijective but for a ﬁnite number
of points. For instance, this property is enjoyed by the curves C of equation

370
7 Secrets. . . and lies
g(x)y = f(x),
(7.12)
where f(x), g(x) are polynomials in x, with f(x), g(x) diﬀerent from zero and
without common factors. Every curve with these properties is irreducible (see
Exercise A7.16). The projection is deﬁned again as
π : (u, v) ∈C →u ∈K
and the inverse mapping is given by
ρ : u ∈K →

u, f(u)
g(u)

∈R.
Notice that ρ is not deﬁned where g(x) = 0, so, strictly speaking, it is not the
inverse of π; however it is its inverse out of ﬁnitely many points, the points
u ∈K such that g(u) = 0. Curves of this kind belong to the class of rational
curves. These are irreducible curves C deﬁned by an equation of the form
(7.10), and such that there are rational functions φ(u), ψ(u), deﬁned over K
or an algebraic extension of K, such that the rational function f(φ(u), ψ(u))
is the zero function. In other words,
x = φ(u),
y = ψ(u)
is a so-called parametric representation by rational functions of the curve C.
For instance, the irreducible conic curves are curves of this kind (see Exercise
A7.17).
Clearly, rational curves are again too similar to K to be of interest to us,
so we reject them too.
7.9.4 Hyperelliptic curves
The next case is given by curves for which the projection on the x-axis has
no inverse, even after removing a ﬁnite number of points. Among these, the
simplest case is that of curves for which the preimage of a point under the
projection mapping consists in general not of a single point, but of two points.
Curves of this kind are called hyperelliptic: examples of hyperelliptic curves
are given by the irreducible curves C of degree greater than 2 having equation
of the form
y2 + yg(x) = f(x),
(7.13)
where f(x), g(x) ∈K[x]. Assume further that g(x) is not the zero polynomial
if the characteristic of K is two: we shall shortly see why this hypothesis is
necessary.
If (u, v) is a point on the curve C, this means that v is a solution of the
equation
y2 + yg(u) = f(u),
(7.14)
which has in general two distinct solutions.

7.9 Cryptography and elliptic curves
371
Remark 7.9.2. Let us clarify the meaning of the previous claim.
If K has characteristic diﬀerent from 2, Equation (7.14) has a single solu-
tion if and only if its discriminant is zero, that is, if and only if
g(u)2 + 4f(u) = 0.
(7.15)
It might happen that Equation (7.15) holds for all (u, v) ∈C. However, if we
suppose that the size of the set C′ of points u ∈K such that there is a point
(u, v) ∈C is large enough, for instance that its size is greater than the degree
of the polynomial g(x)2 + 4f(x), the factor theorem (see Theorem 1.3.19 and
its Corollary 1.3.20) implies that g(x)2 + 4f(x) is the zero polynomial, and
this yields a contradiction, because in this case we would ﬁnd
y2 + yg(x) −f(x) =

y + g(x)
2
2
,
against the hypothesis that the curve C is irreducible.
If the characteristic of K is 2, the derivative of the polynomial y2 +yg(u)−
f(u) is g(u). Assume that for all u ∈C′ we have g(u) = 0, so Equation (7.14)
has a unique solution. Again, assuming that C′ has size greater than the degree
of g(x), this would imply that g(x) is the zero polynomial, contradicting the
hypothesis.
Example 7.9.3. Consider the simple case in which g(x) is the zero polyno-
mial, which by hypothesis can happen only if the characteristic of K is not 2.
In this case, if (u, v) is a point on the curve C, this means that v2 = f(u),
that is, f(u) is a square in K. So, not only (u, v) lies on C but (u, −v) as
well, and these are the only two points of C that project on the point u ∈K.
They are symmetric with respect to the x-axis, in the sense that their second
coordinates are one the opposite of the other. Of course, if f(u) = 0 these
points coincide, otherwise they are distinct.
In conclusion, hyperelliptic curves can be thought of as double coverings
of K. This concept is particularly clear when K is algebraically closed. In this
case, by Remark 7.9.2, if K has characteristic diﬀerent from 2, for all u ∈K
that are not roots of the polynomial g(x)2 +4f(x), we have exactly two points
of C over the point (u, 0) of the x-axis. If u ∈K is a root of g(x)2 + 4f(x),
the unique point (u, −g(u)/2) of C corresponds to it.
If, on the other hand, K has characteristic 2, for all u ∈K that are not
roots of the polynomial g(x), we have exactly two points of C over the point
(u, 0) of the x-axis. If u ∈K is a root of g(x), the unique point (u,

f(u)) of
C corresponds to it.
Clearly, we may consider curves for which the behaviour of the projection
on the x-axis is even more complex: for instance, the preimage of a general
point of K may have size greater than two. But we shall not go into these
cases because, as already remarked, we want to consider interesting curves
which are nevertheless constructible in the easiest possible way.

372
7 Secrets. . . and lies
7.9.5 Elliptic curves
So we are left with the problem of ﬁnding hyperelliptic curves which also
are groups. This may be done, as we shall shortly see, if f(x) and g(x) have
the simplest possible form compatible with the hypothesis that the curve has
degree greater than 2. Indeed, assume that g(x) = mx + n is of ﬁrst degree
and that f(x) = x3 + px2 + qx + r. In this case the curve C of equation (7.13)
is cubic.
It is important to observe that, with suitable changes of variable, the
equation of curve C may be simpliﬁed.
Proposition 7.9.4. Let C be the curve of equation
y2 + y(mx + n) = x3 + px2 + qx + r.
(7.16)
It is possible to change coordinates in A2
K in such a way that in the new
coordinate system
•
if K has characteristic diﬀerent from 2 or 3, C has equation of the form
y2 = x3 + ax + b;
(7.17)
•
if K has characteristic 3, C has equation of the form
y2 = x3 + ax2 + bx + c;
(7.18)
•
if K has characteristic 2, C has equation of the form
y2 + cy = x3 + ax + b;
(7.19)
or of the form
y2 + xy = x3 + ax2 + b.
(7.20)
Proof. To begin, assume K not to have characteristic 2. Change variables
as follows:
x →x,
y →y −mx −n
2
.
The equation of C becomes of the form (7.16) where m = n = 0. This con-
cludes the proof in the case of characteristic 3. If the characteristic is not 3,
change again variables as follows:
x →x −p
3,
y →y.
(7.21)
The equation of C becomes now of the form (7.17), concluding the proof if
the characteristic is neither 2 nor 3.
Assume now the characteristic of K to be 2. By performing the change of
variable (7.21) the equation of C becomes of the form

7.9 Cryptography and elliptic curves
373
y2 + y(mx + n) = x3 + ax + b.
If m = 0 the equation is of the form (7.19). Assume then m ̸= 0. In this
case, perform the change of variable
x →m2x + n
m,
y →m3y + m2a + n2
m3
,
obtaining an equation of the form (7.20).
⊓⊔
The equations of the form (7.17), (7.18), (7.19), (7.20) are called canonical
equations in Weierstrass form of a cubic curve.
Now we shall put ourselves in a regularity hypothesis. We shall assume
that, if K has characteristic diﬀerent from 2, the right-hand side of Equation
(7.17) or (7.18) has no multiple roots in the algebraic closure of K. If K has
neither characteristic 2 nor 3, that is, when the equation in Weierstrass form is
Equation (7.17), this is equivalent to saying that 27b2 + 4a3 ̸= 0 (see Exercise
A7.18). If, on the other hand, K has characteristic 2 and if the equation in
Weierstrass form is Equation (7.20), then we shall assume b ̸= 0. We shall
shortly see the meaning of this hypothesis.
Finally, we shall add to C a point O called point at inﬁnity, whose meaning
is well known to the reader acquainted with projective geometry (see [51]).
Next, we shall denote by E the set C ∪{O}, call E an elliptic curve, and say
that (7.17), (7.18), (7.19) or (7.20) is its equation.
Remark 7.9.5. As is well known, the aﬃne plane A2
K can be naturally embedded in
the projective plane P2
K, whose points are non-zero ordered triples [x0, x1, x2] of ele-
ments of K, up to a multiplication by a constant, that is, [x0, x1, x2] = [kx0, kx1, kx2]
for all k ∈K∗. Given the point [x0, x1, x2] of P2
K, x0, x1, x2 are said to form a triple
of homogeneous coordinates of the point. The embedding of A2
K in P2
K happens as
follows:
(x, y) ∈A2
K →[1, x, y] ∈P2
K.
The complement of A2
K in P2
K is the set of points satisfying the equation x0 = 0, that
is, the set of points of the form [0, a, b], called points at inﬁnity. This set is called
line at inﬁnity of the projective plane. If [x0, x1, x2] is not on the line at inﬁnity, its
cartesian coordinates in A2
K are
x = x1
x0 ,
x = x2
x0 .
These are the formulas to pass from homogeneous coordinates to cartesian coordi-
nates.
If we consider a line R in the plane A2
K, with equation bx −ay + k = 0, passing
to homogeneous coordinates and multiplying both sides by x0, we ﬁnd the equation
kx0+bx1−ax2 = 0. Clearly all the solutions to this equation having x0 ̸= 0, and they
alone, correspond to the points of A2
K lying on R. On the other hand, by intersecting
it with the line at inﬁnity, we obtain the system
x0 = bx1 −ax2 = 0,

374
7 Secrets. . . and lies
which uniquely determines the point 0 = [0, a, b]. This leads to the well-known
interpretation of the points at inﬁnity: the point [0, a, b] is to be considered as the
common point of all parallel lines of the plane A2
K having equation of the form
bx −ay + k = 0 with k ranging in K.
Similarly, considering the curve C of equation (7.17), passing to homogeneous
coordinates and multiplying both sides by x3
0, we ﬁnd the equation
x0x2
2 = x3
1 + ax2
0x1 + bx3
0.
(7.22)
All the solutions to this equation having x0 ̸= 0, and they alone, correspond to the
points of A2
K lying on C. On the other hand, intersecting it with the line at inﬁnity,
we obtain the system
x0 = x1 = 0,
which uniquely determines the point 0 = [0, 0, 1]. So it is natural to consider Equa-
tion (7.22) as deﬁning the projective closure E of C. It diﬀers from C only by the
point at inﬁnity O. We may reason analogously if the curve has equation (7.18),
(7.19) or (7.20).
Remark 7.9.6. We might wonder whether a curve having equation (7.17), (7.18),
(7.19) or (7.20) could itself be rational, and so devoid of interest for our uses. It
is not so in the regularity hypothesis we have stipulated: for instance when K has
characteristic diﬀerent from 2 and 3, the equation is of the form (7.17) and 27b2 +
4a3 ̸= 0, while it can be shown that the curve is rational if 27b2 + 4a3 = 0 (see
Exercise A7.23). The simplest case is that of the curve of equation y2 = x3, which
has parametric representation
x = u2,
y = u3.
To study the matter more in depth, see [56].
7.9.6 Group law on elliptic curves
Let us discuss now the group law on an elliptic curve E. We shall consider
here in detail the case in which K has characteristic diﬀerent from 2 or 3
and the equation is of the form (7.17), leaving to the reader as an exercise
the analogous discussion of the remaining cases (see Exercises A7.27 and [56],
Chapter III, § 2).
The key observation is that given two points p = (x1, y1) and q = (x2, y2)
of the curve, the line through them intersects the curve in a third point r =
(x3, y3). This observation is to be taken with a grain of salt, in the sense we
are going to explain.
First of all, we verify it in the case in which p and q are distinct and the
line R through them is not vertical, that is, has not an equation of the form
x = u. This means, as already remarked, that x1 ̸= x2.
The equation of R is
y = mx + n,
(7.23)
with

7.9 Cryptography and elliptic curves
375
m = y2 −y1
x2 −x1
,
n = y1 −mx1
(7.24)
(see Exercise A7.19). To ﬁnd the points of intersection of R with C, substitute
(7.23) in (7.17), and solve with respect to x. So one gets the third degree
equation
x3 −(mx + n)2 + ax + b = 0;
clearly x1 and x2 are two of its roots. Let x3 be the third root. As
x1 + x2 + x3 = m2
(see Exercise A7.20), we have
x3 = m2 −x1 −x2,
which gives the ﬁrst coordinate of the third point r of intersection of R with
C. The second coordinate of r is given by
y3 = mx3 + n.
Let us see what happens if the line through two distinct points p and q is
the vertical line x = u. As we have seen in Example 7.9.3, this means that the
two points have coordinates (u, v) and (u, −v), where ±v are the square roots
of u3 + au + b. The intersection of the line of equation x = u with the curve
of equation (7.17) in A2
K consists only of the points p and q. But passing to
homogeneous coordinates, the equation of the line becomes x1 = ux0 and we
see that it passes through the point O lying in E. So it is natural to regard
O as the third intersection point of the line through p and q with the curve.
Example 7.9.7. We demonstrate the preceding remarks by examining the real
curve of equation
y2 = x3 −x.
The curve corresponds to the union of the graph of the function
y =

x3 −x
and of its symmetric with respect to the x-axis. Fix a point on the curve, say
p = (2,
√
6). Write the equation of a non-vertical line through p. It is of the form
y −
√
6 = 1
m(x −2),
(7.25)
with m ̸= 0. Intersect this line with the curve, obtaining, besides p, two more points,
q and r. We leave to the reader the task of ﬁnding their coordinates as functions
of m and of verifying that, as m approaches 0, that is, when the line tends to
becoming the vertical line x = 2, one of the two points q and r tends to the point
p′ = (2, −
√
6), symmetric of p with respect to the x-axis, which lies indeed on the
vertical line x = 2, while the other’s second coordinate tends to inﬁnity (see Figure
7.3). Basically, this second point tends to inﬁnity and its limit position, which may
be thought of as inﬁnitely far along the y-axis, to which the line of equation (7.25)
becomes parallel as m approaches 0, is exactly that of the point O we have added
to C in order to get E. These heuristic remarks are quite natural and should not
sound strange to readers acquainted with projective geometry.

376
7 Secrets. . . and lies
x
y
p = (2,
√
6)
p′ = (2, −
√
6)
r
r














































































r
r
r
r
r
q
r
-
6
Fig. 7.3. Elliptic curve of equation y2 = x3 −x
Finally, what happens if p = q? Here we cannot consider the line through
p and q. Nevertheless, among the inﬁnitely many lines through p = q one is
special, with respect to the elliptic curve: the tangent line to the curve in p,
which may be thought of as the line joining p with a point q on the curve that
is so close to p to be undistinguishable from p. This notion is well known in
the real case: it is the limit line of the line through p and another point q of
the curve, when q approaches p.
If a real curve C has equation
f(x, y) = 0
and if p = (ξ, η) is a point of C, the condition for the tangent, seen as the
above limit, to exist is that in (ξ, η) not both partial derivatives of f(x, y) are
zero (see [51]), that is, it is not the case that
∂f
∂x(ξ, η) = 0,
∂f
∂y (ξ, η) = 0.
(7.26)
So the tangent line to C in p has equation
∂f
∂x(ξ, η)(x −ξ) + ∂f
∂y (ξ, η)(y −η) = 0.
(7.27)

7.9 Cryptography and elliptic curves
377
More in general, these notions extend without any diﬀerence to the case
of a curve on an arbitrary ﬁeld (see [56], Ch. I, § 1). A point p = (ξ, η) of the
curve C of equation f(x, y) = 0 for which (7.26) hold is said to be singular.
In it the tangent line does not exist. A non-singular point is said to be simple
or smooth, and in it the tangent line exists and is given by Equation (7.27).
A curve having a singular point in p is said to be singular in p.
Remark 7.9.8. A curve of equation f(x, y) = 0 is singular, that is, has some
singular point, if and only if the system
f(x, y) = 0,
∂f
∂x(x, y) = 0,
∂f
∂y (x, y) = 0
(7.28)
admits solutions. Notice that this deﬁnition depends on the ﬁeld K, as it is
possible that the system (7.28) has no solutions in K but has solutions in some
extension of K (see Exercise B7.58).
When a curve is said to be non-singular, without specifying the ﬁeld on
which it is considered, the curve is meant to be considered on the algebraic
closure of the ﬁeld K containing the coeﬃcients of the equation deﬁning the
curve.
The reader may easily verify that the regularity hypothesis on page 373
makes sure that the curves C deﬁned by equations in Weierstrass form of the
kind (7.17), (7.18), (7.19) or (7.20) are non-singular (see Exercise A7.22). Let
us ﬁx our attention, as usual, on the case in which the equation is of the form
(7.17). Then, given a point p = (ξ, η) of the curve, the tangent line Rp in that
point has equation
(−3ξ2 −a)(x −ξ) + 2η(y −η) = 0.
It is vertical if and only if η = 0, that is on the points in which C intersects
the x-axis. We leave to the reader the task of verifying that if η ̸= 0, then
Rp intersects C in a further point r the coordinates of which may be easily
computed (see Exercise A7.25). The point r is to be interpreted as the third
intersection with the elliptic curve of the line through p and q when p = q =
(ξ, η). Of course, if p = q = (ξ, 0), the tangent line is the vertical line of
equation x = ξ and, as we have already seen, it is the point at inﬁnity O that
has to be regarded as the third intersection of this line with the curve.
What can be said about the lines through O? By our interpretation of
points at inﬁnity, they are all the lines that are parallel to the y-axis, that is,
the vertical lines of equation x = u.
So, if p = (ξ, η) lies on the curve, the line through p and O is the line of
equation x = ξ, which, as we know, intersects the curve in the further point
q = (ξ, −η).
Finally, for reasons we shall not discuss at length (see Exercise A7.26), it
can be seen that the line at inﬁnity must be considered as the tangent line to
the curve E in O and, as already seen, it intersects the curve only in O. So we

378
7 Secrets. . . and lies
may say that this line, which must be considered as the line through p and q
when p = q = O, intersects further the curve in O itself.
In conclusion, we may say that, in the sense made clear above, given two
points p and q of E, distinct or equal, there is a third point r of E such that
p, q and r are collinear.
So we are very close to deﬁning the group law on E, which will be described
using an additive notation. One is tempted to deﬁne deﬁne the sum p + q of
two points p and q of E as the third point of E that is collinear with p and q.
But this is not a completely correct idea. We have to take O as the identity
element, that is the zero, of the group, and deﬁne the sum p + q as follows:
•
consider ﬁrst the third point r of E collinear with p and q;
•
deﬁne p + q as the third point s of E collinear with r and O.
In other words, if we consider an elliptic curve deﬁned by an equation of the
form (7.17), p + q is the symmetric point with respect to the x-axis of the
third point r of E collinear with p and q (see Figure 7.4). In this way, the
opposite of each point p is exactly its symmetric with respect to the x-axis.
x
y
r
p + q
r
r


















r
r
p
q
-
6
Fig. 7.4. Group law on an elliptic curve
Keeping in mind what has been said in this section, as well as in Exercise
A7.25, we may compute the coordinates of the point s = p + q = (x3, y3)
as a function of the points p = (x1, y1) and q = (x2, y2) of an elliptic curve
(see Exercise A7.27). Here we give the details only for the case in which the
equation in Weierstrass form is of the kind (7.17).

7.9 Cryptography and elliptic curves
379
Proposition 7.9.9. Let E be an elliptic curve on a ﬁeld K of characteristic
diﬀerent from 2 and 3, of equation y2 = x3 + ax + b with 27b2 + 4a3 ̸= 0.
Consider the binary operation + in E
E × E −→E,
(p, q) −→s
deﬁned as follows:
•
if p = O, then s = q;
•
if p ̸= q are both diﬀerent from O, p = (x1, y1) and q = (x2, y2), and if
x1 = x2 and y1 = −y2, then s = O;
•
if p ̸= q are both diﬀerent from O, p = (x1, y1) and q = (x2, y2) with
x1 ̸= x2, then s ̸= O and s = (x3, y3) with
x3 =
 y2 −y1
x2 −x1
2
−x1 −x2,
y3 = (y2 −y1)
(x2 −x1)(x1 −x3) −y1;
•
if p = q is diﬀerent from O and p = (ξ, 0), then s = O;
•
if p = q is diﬀerent from O and p = (ξ, η), with η ̸= 0, then s ̸= O and
s = (ξ′, η′) with
ξ′ =
3ξ2 + a
2η
2
−2ξ,
η′ = (3ξ2 + a)
2η
(ξ −ξ′) −η.
With this operation, (E, +) is an abelian group, whose identity element is
the point at inﬁnity O and the opposite of the point (ξ, η) of E is the point
(ξ, −η).
Proof. The commutativity of the operation just deﬁned is a simple algebraic
computation we leave to the reader as an exercise (see Exercise A7.28). The
most delicate check is that the operation is associative: for it see [56], Propo-
sition 2.2.
⊓⊔
Remark 7.9.10. Notice that without the hypothesis 27b2 + 4a3 ̸= 0, we may
have anomalous situations, as the following one. Let E be the real curve of
equation
y2 = x3 −3x −2.
We have 27 · 4 + 4 · (−3)3 = 0. Now it is easy to verify that, if we keep the
deﬁnition of the sum as given above, for every (x, y) ∈E we have
(−1, 0) + (x, y) = (−1, 0).

380
7 Secrets. . . and lies
7.9.7 Elliptic curves over R, C and Q
We have ﬁnally come in possession of a group for each elliptic curve, and we
may use these groups in cryptography, as we intended. But which ones of
these curves should we use? and over which ﬁelds?
Real elliptic curves possess inﬁnitely many points. Indeed, a real elliptic
curve E is deﬁned by the equation (7.16). The curve E consists of the graph
of the function y =

f(x) and of its symmetric with respect to the x-axis.
As x approaches +∞, f(x) tends to +∞. Thus

f(x) is deﬁned at least on a
half-line, so E has inﬁnitely many points. It is easily veriﬁed that E consists
of either one or two arcs, depending on the number (one or three) of real roots
of f(x) (see Exercise A7.29). In cryptography we need ﬁnite groups, so real
elliptic curves are useful to draw inspiration from, but cannot be used for our
goals.
Elliptic curves over C are even less useful. C being algebraically closed,
those curves are, as mentioned, double covers of C. They can be parametrised
using suitable functions, called elliptic functions, which are not rational func-
tions, but have properties quite similar to those of trigonometric functions
and cannot be expressed in terms of elementary functions. The theory of
these functions is very interesting but too complex to allow us more than the
briefest mention (see [55]). It is interesting to remark that elliptic curves take
their name from these functions.
We may next consider elliptic curves over Q. In this regard, the following
fundamental theorem is well known (see [56], pag. 188):
Theorem 7.9.11 (Mordell–Weil).
If E is an elliptic curve over Q, then
E is a ﬁnitely generated abelian group, that is,
E ≃Tors(E) ⊕Zr,
where Tors(E) is the torsion subgroup of E, that is to say, the subgroup of E
consisting of the points of ﬁnite order, while r is called rank of E.
The dependence of the rank of an elliptic curve over Q from its equation
is not yet well understood.
Example 7.9.12. The point p = (2, 3) of the elliptic curve over Q of equation
y2 = x3 + 1 is a torsion point. Indeed, by using the group law on the curve
we ﬁnd that 2p = p + p = (0, 1), 4p = (0, −1) and so 6p = O.
Excluding the case in which the rank of a rational elliptic curve E is 0, E
is an inﬁnite group too, and so unsuitable for use in cryptography.
So we are only left with elliptic curves on ﬁnite ﬁelds Fq. This is a classical
and intriguing subject which has played a central role in last century’s math-
ematics, culminating in the momentous proof by A. Wiles of the well-known
so-called Fermat’s Last Theorem, which states that the equation xn +yn = zn
has no solutions (x, y, z) ∈Z × Z × Z with x, y, z diﬀerent from zero, if n > 2
(see the popular science book [57] or Wiles’s paper [63]; see also Exercises
A7.30-A7.35 for the case n = 2).

7.9 Cryptography and elliptic curves
381
7.9.8 Elliptic curves over ﬁnite ﬁelds
On the road to describe elliptic curves over a ﬁnite ﬁeld Fq, we begin by
remarking that such a curve E, of equation (7.16), has ﬁnitely many points,
their number being denoted by |E/Fq|. We also have an estimate
|E/Fq| ≤2q + 1
(7.29)
because, apart from O, for all x ∈Fq, the equation (7.16) has at most two
solutions in Fq.
The estimate (7.29) is very rough: indeed, only one half of the elements of
Fq are squares, so only one half of the elements of Fq has a square root. To
be more precise, we can give the following deﬁnition, which is the analogous,
for ﬁnite ﬁelds, of the Legendre symbol:
Deﬁnition 7.9.13. The quadratic character in Fq is the function
χ : u ∈Fq →χ(u) ∈{0, 1, −1}
deﬁned as follows:
χ(u) =
⎧
⎪
⎨
⎪
⎩
0
if u = 0,
1
if u is a square,
−1
if u is not a square.
In particular, χ(u) = ( u
q ) if q is a prime number.
Notice that the number of solutions of the equation x2 = u in Fq equals
1 + χ(u) (see Exercise A7.36). Moreover, χ(uv) = χ(u)χ(v) for every pair
(u, v) of elements of Fq (see Exercise A7.37).
Then, if the characteristic of Fq is diﬀerent from 2 and 3 (hence the equa-
tion becomes (7.17)), we have
|E/Fq| = 1 +

x∈Fq
(1 + χ(x3 + ax + b)) = q + 1 +

x∈Fq
χ(x3 + ax + b).
Now, let us reason heuristically: we expect that, for general a and b, for a
given x ∈Fq, χ(x3 + ax + b) has the same probability of being equal to 1 or
−1. That is, for all x ∈Fq, computing χ(x3 + ax + b) is like tossing a coin to
see whether it shows heads or tails.
In probability theory a situation of this kind is called random walk. Assume
we are on a line, in the coordinate origin. We have a coin and we toss it. If it
shows heads, we take a step towards the positive semiaxis, while if it shows
tails we take a step towards the negative semiaxis. After n steps, how far may
we expect to be from the origin? The answer given by probability theory is
that we expect a distance of about √n steps, in one of the two directions (see
[29]).

382
7 Secrets. . . and lies
In our case n = q, that is, the number of points of Fq. So we expect, by
this heuristic argument, that the number |E/Fq| of points in the elliptic curve
E is on the average bounded by q + 1 + √q. The following result by Hasse
(see [56], p. 131) gives us an actual, not just a heuristic, estimate for |E/Fq|.
Notice that this estimate is not very far from the previous one.
Theorem 7.9.14 (Hasse’s Theorem). If N = |E/Fq|, then
|N −(q + 1)| ≤2√q.
Hasse’s theorem says that an elliptic curve over Fq has, after all, not many
more points than Fq itself. So elliptic curves over ﬁnite ﬁelds are actually not
too complicated objects. Good news for cryptographers!
Example 7.9.15. Let us compute now the number of points of the elliptic
curve of equation y2 = x3 +x over Fp, with p a prime number such that p ≡3
(mod 4). We have
N = p + 1 +

x∈Fp
χ(x3 + x) = p + 1 +

x∈F∗p
χ(x3 + x).
But
χ((−x3) + (−x)) = χ((−1)(x3 + x)) = χ(−1)χ(x3 + x) =
=
−1
p

χ(x3 + x) = −χ(x3 + x);
hence it follows that N = p + 1, as the summands in the sum giving N cancel
out in pairs.
A result more precise than Hasse’s Theorem is Weil’s theorem. It is one
of the most important theorems of 20th century mathematics; it led Weil to
conjecture more general results which were later proved by Deligne, giving a
great boost both to algebraic geometry and number theory.
To state Weil’s theorem (see [56], Ch. V, §2), associate with an elliptic
curve E deﬁned over Fq a function called zeta function of E, denoted by
ZE,Fq(t). If Nr = |E/Fqr|, deﬁne
ZE,Fq(t) := e
 ∞
r=1 Nrtr/r.
Theorem 7.9.16 (A. Weil). The function ZE,Fq(t) is rational, of the form
1 −at + qt2
(1 −t)(1 −qt)
(7.30)
and only depends on E. More precisely,
a = q + 1 −N1.

7.9 Cryptography and elliptic curves
383
Notice that the discriminant Δ = a2 −4q of the numerator of (7.30) is
negative by Hasse’s theorem, so the latter has two complex conjugate roots
α′, β′. It is easy to verify, and we leave it as an exercise to the reader (see
Exercise A7.38), that, by setting
α = 1
α′ ,
β = 1
β′ ,
we have |α| = |β| = √q.
Corollary 7.9.17. For all r we have
Nr = 1 + qr −αr −βr.
Proof. From Weil’s theorem it follows that:
∞

r=1
Nr
tr
r = log (1 −αt)(1 −βt)
(1 −t)(1 −qt) =
= log(1 −αt) + log(1 −βt) −log(1 −t) −log(1 −qt).
Taking derivatives on both sides we ﬁnd
∞

r=1
Nrtr−1 = −
α
1 −αt −
β
1 −βt +
1
1 −t +
q
1 −qt =
= −α
∞

r=0
(αt)r −β
∞

r=0
(βt)r +
∞

r=0
tr + q
∞

r=0
(qt)r =
=
∞

r=0
(−αr+1 −βr+1 + 1 + qr+1)tr,
hence the corollary immediately follows.
⊓⊔
Let us see how to apply these results to computing the number of points
on an elliptic curve on a ﬁnite ﬁeld.
Example 7.9.18. Let us compute the number N1 of points over F2, and the
number Nr of points over any ﬁnite extension of degree r, of the elliptic curve
E of equation y2 + y = x3 + 1. Computing the number of points of any curve
over F2 is trivial. We may easily proceed by trial and error, keeping in mind
that in the aﬃne plane there are exactly 4 points. Then Weil’s theorem gives
the number of points of the curve over any extension of F2.
In this case we have N1 = 3, because E, apart from the point at inﬁnity
O, has over Z2 only the points (1, 0) and (1, 1) (see Exercise B7.66). Then the
zeta function is
Z(t) =
1 + 2t2
(1 −t)(1 −2t).
The roots of the numerator are ±i/
√
2, so
Nr = 1 + 2r −(i
√
2)r −(−i
√
2)r =

1 + 2r
if r is odd,
1 + 2r −2(−2)r/2
if r is even.

384
7 Secrets. . . and lies
7.9.9 Elliptic curves and cryptography
Let us come back to cryptography. Now we have at our disposal not only the
multiplicative groups of the ﬁelds Fq, but also the elliptic curves deﬁned on
them, and there are many more of them. So, as already mentioned, we have
more diversity, and this gives more security to our cryptosystems.
But are elliptic curves on ﬁnite ﬁelds actually appropriate for cryptogra-
phy? The answer is essentially in the aﬃrmative. Let us see why, discussing
separately the issues already hinted at at the beginning of this section.
•
Elliptic curves are given in a concrete way: it suﬃces to give their equation.
This does not always mean that determining their points is easy. Indeed,
there is no known polynomial algorithm to generate points on an ellip-
tic curve over Fq. However, there are probabilistic polynomial algorithms,
which are able to determine points on an elliptic curve with a very high
probability (see Exercise A7.39 and A7.40). Let us further mention that
there is in fact a polynomial algorithm, due to R. Schoof, that determines
the number of points of an elliptic curve over Fq, but without determining
the points themselves (see [50]).
•
Exponentiating on an elliptic curve E, which amounts now actually to
multiplying a point of E by an integer, has a polynomial computational
cost: keeping in mind Proposition 7.9.9, this can be shown in a similar way
as in Zp or in Fq.
•
A. Menezes, T. Okamoto and S. A. Vanstone ([42]) have shown that the
problem of discrete logarithms on an elliptic curve is not less hard than
on a ﬁnite ﬁeld. It is conjectured that, a fortiori, for an elliptic curve on
Fq the Diﬃe–Hellman hypothesis holds.
In conclusion, let us sum up how it is possible to exchange a private key
using an RSA system relying on the use of an elliptic curve. We choose: a
ﬁeld Fq, an elliptic curve E and a point p ∈E, which are made public. As
we shall see shortly, it is convenient for the system to work best, that E has
many points over Fq. To determine such an E, the results described above are
helpful.
Each user U chooses a key eU, a positive integer, he will keep private.
However he publishes pU = eUp, which is again a point of E, computed by U
in polynomial time. It is convenient that if U ̸= V then pU ̸= pV . To this end,
it helps if p has a very large order, far larger than the number of users of the
system. So, when the numbers eU are chosen randomly the points pU will be
diﬀerent.
If two users A and B want to exchange a private key, they may do so
by agreeing about using as their private key the point pAB = (eAeB)p. They
both may determine it in polynomial time, while, due to the diﬃculty of
computing discrete logarithms on E and Diﬃe–Hellman hypothesis, pAB will
be unreachable by anybody else.

7.9 Cryptography and elliptic curves
385
Clearly, A and B may use as their private key a number deduced from
pAB: for instance, one of the coordinates of this point, or their sum, and so
on.
We leave to the reader the task of devising a way of applying the general
RSA method using elliptic curves (see Exercise A7.41).
7.9.10 Pollard’s p −1 factorisation method
Surprisingly, elliptic curves are not only greatly useful in cryptography, but are
also suitable to solving several other problems we have previously discussed, such
as primality tests (S. Goldwasser, J. Kilian; A.O.L. Atkin, see [30], Ch. VI) and
factorisation (H.W. Lenstra, see [30], l.c.). The ideas are not very diﬀerent from
those described in this book, but elliptic curves make it possible to implement them
with an accuracy and a ﬂexibility that make them very eﬀective. We conclude this
part by examining a factorisation method (Pollard’s p −1 method) which does not
rely on elliptic curves. Without going into too many details, we mention the fact
that the restrictions of this method can be overcome by using elliptic curves, and
this yields Lenstra’s factorisation mentioned.
Assume we have to factor an integer N. The method we are going to describe
works when N has a prime factor p, to be determined, such that p −1 has not too
large prime divisors. So we give an a priori estimate of the greatest prime T dividing
p −1.
We have to ﬁnd a number k divided by p −1. To this end, we may proceed as
follows. Let
p −1 = 2α3β5γ · · · T ω
be the prime factorisation of p −1. As p is not known, the exponents α, β, γ etc.
are not known either. However, as 2α ≤p −1 < N, we have α < (log N)/(log 2),
and so β < (log N)/(log 3), etc. Thus, setting
k := 2⌊(log N)/(log 2)⌋· 3⌊(log N)/(log 3)⌋· · · T ⌊(log N)/(log T )⌋,
we have that p −1 divides k.
Let now a be an integer between 2 and N −2, such that GCD(a, N) = 1, so a
is relatively prime with all prime factors of N. By Fermat’s little theorem we have
ap−1 ≡1 (mod p) and so, as p −1|k,
ak ≡1
(mod p).
Compute now ak (mod N) in polynomial time (see § 3.3.1) and simultaneously,
using the Euclidean algorithm, compute d = GCD(ak −1, N). Clearly, the ﬁrst p we
are looking for is such that p|d, so d ̸= 1. If d ̸= N, we have found a (not necessarily
prime) factor of N and we are done. Otherwise, if d = N, that is, if N|(ak −1),
modify the choice of the integer a or of the integer k and start over. In practice,
take as k a multiple of all integers smaller than or equal to a ﬁxed integer M, which
is supposed to be greater than all the powers of the prime numbers dividing p −1.
For instance, we may take k = M!.
Example 7.9.19. Factor with this method the number 156203. Choose M = 6,
k = 6!, and a = 2. Compute 2k (mod 156203) = 32219. Find next

386
7 Secrets. . . and lies
GCD(2k −1, 156203) = 181.
We have found that 181 (which is a prime) is a factor of 156203 and the factorisation
of 156203 is
156203 = 181 · 863.
Remark 7.9.20. While the single steps just described have polynomial cost, the
algorithm itself is exponential because, when d = N, we have to modify, for instance,
our choice of the integer a, which may be done in N ways. Moreover, it may happen
that for each choice of a we have N|(ak −1), and so the algorithm might never give
a positive result.
Nevertheless, there are probabilistic reasons for this algorithm to work in some
cases. For instance, suppose exactly one of the prime factors of N, say p, has the
property that the prime factors of p−1 are bounded by T, while for all other factors
q, q is large with respect to k.
In this situation, if q|(ak −1) then a is a kth root of unity modulo q, and the
probability of this happening for a random choice of a is k/q, because the kth roots
of unity are at most k in Z∗
q. So this probability is very small, if q ≫k. Hence the
probability that N|(ak −1) is even smaller, and this is exactly the case in which the
algorithm has to be repeated.
Which are the limitations of this algorithm? In it, we exploit the structure of
the groups Z∗
p, with p ranging among the prime factors of N. For a ﬁxed N, these
groups are ﬁxed and cannot be exchanged for others; and, as we have remarked, the
algorithm might not give positive result for any of them. This happens, in particular,
if the order p −1 of each of these groups has at least a prime factor not bounded by
the number T we have chosen at the beginning and which, as seen, determines the
number k. How may we obtain a larger choice? By using elliptic curves, on which
H. W. Lenstra’s factorisation method relies (see [35], [30], Ch. VI, § 4). Here is a
sketch of the idea: substitute the group E/Zp of the points of an elliptic curve E
over Zp for Z∗
p. The new group, by Hasse’s theorem 7.9.14, has order
|E/Zp| = p + 1 −s,
with |s| ≤2√p.
Diﬀerent elliptic curves E yield diﬀerent values of s and we have at our disposal
several groups: so it is realistic to expect one of them to have order with small prime
factors.
Appendix to Chapter 7
A7 Theoretical exercises
A7.1. We have seen the frequencies of the diﬀerent letters in English. Assume we
have messages written in two languages, for instance containing an English text
and its translation in another language, or the other way around. Explain how to
get a frequency table for these messages, assuming we have the tables for the two
languages, knowing that each message is written half in one of the languages and
half in the other one.

A7 Theoretical exercises
387
A7.2. We have seen how to carry out the cryptanalysis of an enciphered message
by using frequency analysis. Exercise C7.2 requests the reader to write a program
that computes the frequencies with which the letters appear in a given text. Assume
we have a program saying whether a word exists in English language or not: more
precisely, on receiving as its input a word, its output is either true or false, depend-
ing on the word being present or not in English lexicon. Describe an algorithm to
decrypt a message, enciphered using a monoalphabetic substitution, using these two
programs.
A7.3. Prove that an aﬃne transformation f : Z26 →Z26 deﬁned by f(n) = an +
b mod 26, where a, b ∈Z, is bijective if and only if GCD(a, 26) = 1.
A7.4.* Show by an example that there are systems of two linear congruences modulo
26 in two unknowns having no solutions. (Hint: try a diagonal matrix. Indeed, in
this case the system reduces to two independent linear congruences; the system does
not admit solutions if and only if one of the two congruences does not.)
A7.5.* Show by an example that there are systems of two linear congruences modulo
26 in two unknowns having more than one solution modulo 26. (Hint: try a diagonal
matrix.)
A7.6. Explain how to carry out the cryptanalysis of an aﬃne cipher, with 2-letter
unitary messages, when the system of linear congruences modulo 26 obtained as
explained in Remark 7.4.3 on page 339 has more than one solution.
A7.7.* Prove Proposition 7.4.2 on page 338.
A7.8.* Consider a system of two linear congruences of the form
A ·
⎛
⎜
⎜
⎜
⎝
a1
a2
...
an
⎞
⎟
⎟
⎟
⎠≡
⎛
⎜
⎜
⎜
⎝
α1
α2
...
αn
⎞
⎟
⎟
⎟
⎠
(mod m),
where A is a square n×n matrix with integer coeﬃcients. Prove that if the determi-
nant of A is invertible modulo m, then A has an inverse modulo m and the system
admits a unique solution in a1, a2, . . . , an, given by
⎛
⎜
⎜
⎜
⎝
a1
a2
...
an
⎞
⎟
⎟
⎟
⎠≡A−1 ·
⎛
⎜
⎜
⎜
⎝
α1
α2
...
αn
⎞
⎟
⎟
⎟
⎠
(mod m).
A7.9. Prove that the computational complexity of the knapsack problem, when
a1, . . . , an is a superincreasing sequence of integers, is polynomial.
A7.10.* Assume we know that an integer n is the product of two prime numbers p
and q. Explain how to ﬁnd p and q in polynomial time if one knows ϕ(n).
A7.11.* Let n be a product of distinct primes. If d and e are positive integers such
that de −1 is divisible by p −1 for every prime p | n, then we have ade ≡a (mod n)
for every integer a, even if a is not relatively prime with n.

388
7 Secrets. . . and lies
A7.12. Explain why Exercise A7.11 proves that we have not to worry if in the RSA
cryptosystem it happens that a unitary message Pi we want to send to the user B
is not relatively prime with nB.
A7.13. Prove that lines are irreducible curves. (Hint: ﬁrst degree polynomials are
always irreducible.)
A7.14. Consider the line R of equation (7.11). Prove that if a ̸= 0 the projection
(u, v) ∈R →v ∈K on the y-axis is bijective, and write its inverse.
A7.15. Prove that the reducible conics are unions of two lines.
A7.16.* Prove that a curve of equation (7.12) is irreducible.
A7.17.* Prove that an irreducible conic, that is an irreducible curve deﬁned by a
degree two equation, is a rational curve, that is admits a parametric representation
by rational functions.
A7.18.* Prove that the polynomial f(x) = x3 + ax + b has no multiple roots if and
only if 27b2 + 4a3 ̸= 0. (Hint: a root of a polynomial f(x) is a multiple root if and
only if it is a root of the derivative of f(x) too.)
A7.19. Prove that the line through the points (x1, y1) and (x2, y2) has equation
(7.23) with m, n determined by (7.24). (Hint: the (non vertical) lines through (x1, y1)
have equation y −y1 = m(x −x1) and m can be found by imposing that the point
(x2, y2) lies on the line.)
A7.20. Prove that if x1, x2, x3 are the three roots of a degree three monic polyno-
mial, then the degree two coeﬃcient of the polynomial is −x1 −x2 −x3 and the
constant term is −x1x2x3. (Hint: the polynomial may be written as (x −x1)(x −
x2)(x −x3).)
A7.21. Let K be a ﬁeld and consider the curve in A2
K deﬁned by an equation of the
form y2+y(mx+n) = ℓx3+px2+qx+r with ℓ̸= 0. Prove that, if K contains the cubic
roots of each of its elements, then it is possible to reduce it in Weierstrass canonical
form as in Proposition 7.9.4. (Hint: begin by changing variables by x →x/
3√
ℓ,
y →y, and go on as in the proof of Proposition 7.9.4.)
A7.22.* Prove that a curve deﬁned by an equation in Weierstrass form of the kind
(7.17), (7.18), (7.19) or (7.20) is singular in the algebraic closure of K if and only if
it does not verify the regularity hypothesis on page 373.
A7.23.* Prove that if a curve deﬁned by an equation in Weierstrass form of the
kind (7.17), (7.18), (7.19) or (7.20) is singular, then it is rational. (Hint: work in the
algebraic closure of K and prove that almost all the lines through a singular point
intersect the curve in a unique point out of the singular point.)
A7.24. Prove that, if 27b2 + 4a3 = 0, then the curve of equation (7.17) is rational.
A7.25.* Let p = (ξ, η) be a point of the elliptic curve (7.17), with η ̸= 0. Determine
the intersection point diﬀerent from p of the tangent line to the curve in p. (Hint:
obtain y from the equation of the tangent line and substitute it in the equation of
the curve; so one ﬁnds an equation of degree three in x having a double solution in
x = ξ; the further solution of the equation is the abscissa of the required point.)

A7 Theoretical exercises
389
A7.26.* Explain why the line at inﬁnity is to be considered as the tangent line to an
elliptic curve in Weierstrass form in the point at inﬁnity. (Hint: write everything in
cartesian coordinates u = x0/x3, v = x1/x3 and consider the point O as the origin
of a new plane A2
K.)
A7.27.* Compute the coordinates of the point p + q = (x3, y3) in function of the
points p = (x1, y1) and q = (x2, y2) of an elliptic curve in each of the cases (7.17),
(7.18), (7.19) and (7.20) (see page 379).
A7.28. Prove that the operation of sum of points on an elliptic curve is commutative,
that is, p + q = q + p. (Hint: carry out the calculations, or consider the geometric
deﬁnition of the group law.)
A7.29. Prove that an elliptic curve y2 = f(x) deﬁned on the real ﬁeld consists of a
single arc if f(x) has a single real root, while it consists of a closed arc and an open
one if f(x) has three real roots. In Figure 7.4 this second case is represented. Give
an example of a curve for which the ﬁrst case is veriﬁed. (Hint: study the sign of
f(x), since the curve has no point (x, y) if f(x) is negative.)
In the following Exercises A7.30-A7.35 all the solutions (x, y, z) ∈N × N × N
with non-zero x, y, z of the equation x2 + y2 = z2 are determined. These solutions
are called Pythagorean triples as, by Pythagoras’s theorem, they are the lengths of
the legs and of the hypotenuse of a right triangle. A Pythagorean triple (x, y, z) is
said to be primitive if GCD(x, y, z) = 1.
A7.30. Let (x, y, z) be a Pythagorean triple such that GCD(x, y, z) = d. Prove that
(x/d, y/d, z/d) is a primitive Pythagorean triple.
A7.31. Let (x, y, z) be a primitive Pythagorean triple. Prove that GCD(x, y) =
GCD(x, z) = GCD(y, z) = 1.
A7.32. Let (x, y, z) be a primitive Pythagorean triple. Prove that one out of x and
y is even, and the other is odd.
A7.33. Let r, s be positive integers such that GCD(r, s) = 1. Prove that if rs is a
square, so are r and s.
A7.34.* Let (x, y, z) be a primitive Pythagorean triple with even y. Prove that there
exist positive integers n, m, with GCD(m, n) = 1 and m > n, such that
x = m2 −n2,
y = 2mn,
z = m2 + n2.
(7.31)
A7.35. Verify that if (x, y, z) is a triple given by (7.31) with n, m positive integers
such that GCD(m, n) = 1 and m > n, then (x, y, z) is a primitive Pythagorean
triple.
A7.36. Prove that the number of solutions of the equation x2 = u in Fq is 1 + χ(u),
where χ(u) is the quadratic character of u in Fq.
A7.37. Prove that the quadratic character χ in Fq satisﬁes χ(uv) = χ(u)χ(v) for
all u, v ∈Fq.
A7.38. Let α′, β′ be the roots of the numerator of (7.30). Prove that |α| = |β| = √q
where α = 1/α′, β = 1/β′.

390
7 Secrets. . . and lies
In the following two exercises we describe a simple polynomial probabilistic
algorithm to determine points over an elliptic curve deﬁned over Zp.
A7.39.* Let p be a prime number. Prove that there is a polynomial probabilistic
algorithm that determines an integer n that is not a quadratic residue modulo p.
(Hint: keep in mind the fact that half the elements of Zp are not quadratic residues
and that computing Jacobi symbols takes a polynomial time.)
A7.40.* Let p > 2 be a prime number and let C be a hyperelliptic curve of equation
y2 = f(x) deﬁned over Zp. Prove that there is a polynomial probabilistic algorithm
that determines a point of C. (Hint: for all x ∈K the probability that f(x) is a square
is 1/2; keep in mind the previous exercise and apply the algorithm of § 5.2.6.)
A7.41.* Explain how to use the groups deﬁned over elliptic curves to implement the
RSA public-key cryptosystem. (Hint: follow exactly the same steps already seen for
the RSA system, substituting the points of an elliptic curve for the integer numbers
and the operation of addition of points on the curve for the multiplication among
integers.)
A7.42.* Explain how to use the groups deﬁned over elliptic curves to implement
the method to exchange private keys as described in § 7.8.1.
A7.43.* Explain how to use the groups deﬁned over elliptic curves to implement
the cryptosystem described in § 7.8.2.
B7 Computational exercises
B7.1. Which is the 2-digit numerical equivalent of exercise?
(a) 0423041602081804.
(b) 0423041702091804.
(c) 0423041602091804.
(d) None of the above
B7.2. Which string corresponds to the number sequence
021418040002001814,
if we have used the 2-digit numerical equivalent?
(a) coseacoso.
(b) coseacasa.
(c) coseacosa.
(d) None of the above
B7.3. Which is the binary numerical equivalent of codes?
(a) 0001001100001010010010010.
(b) 0001001110001010010010010.
(c) 0001001100000110010010010.
(d) 0001001110000110010010010.

B7 Computational exercises
391
B7.4. To which word does the number sequence
01100010000110100100
correspond if we have used the binary numerical equivalent?
(a) mine.
(b) mien.
(c) main.
(d) nine.
B7.5. Which is the most frequent consonant in English language texts?
(a) N.
(b) S.
(c) R.
(d) T.
B7.6. Write the vowels a, e, i, o, u in decreasing order of their frequency in a long
English language text.
(a) A, e, i, o, u.
(b) E, i or o, o or i, a, u.
(c) A, e or o, o or e, i, u.
(d) None of the above.
B7.7. Determine the most frequent consonant in the following text: analysing fre-
quencies often is the key to a successful cryptanalysis of messages enciphered using
a monoalphabetic substitution.
(a) N.
(b) T.
(c) C.
(d) S.
B7.8. Analyse the letter frequencies in the following text: the frequencies with which
the letters appear in a short text might be very diﬀerent from what we would expect
Order the vowels a, e, i, o, u in the order of frequency in this text.
(a) A, e, i, o, u.
(b) E, a, i, o, u.
(c) E, o, i, u, a.
(d) E, i, a, o, u.
B7.9. Encipher using Caesar method, shifting each letter forward by three positions,
the following message: i am ready to attack gaul.
(a) L DP UHDGB WR DWWDFN JDWO.
(b) L DP UIDGB WR DWWDFN JDWO.
(c) L DP UHDGB WR DWWDFN JDXO.
(d) L DP UIDGB WR DWWDFN JDXO.

392
7 Secrets. . . and lies
B7.10. Suppose a Roman centurion received the following message sent him directly
by Caesar:
DOHD NDFZAP HVZ.
After deciphering it, the centurion is very puzzled, as in the plaintext there is a
patent Latin grammar error. Which is the plaintext of the message the centurion
received?
(a) alea iacta est.
(b) alea iactae est.
(c) alea iactum est.
(d) alea iactus est.
B7.11. Consider the plaintext stiff upper lip. Which is the ciphertext in a Caesar
cipher with a 13-letter shift?
(a) FGVSS HCCRE YVC.
(b) FGUSS HCCRE YUC.
(c) FGVTT HCCRE YVC.
(d) None of the above.
B7.12. Suppose we have received the message XYXCOXCO, known to have been enci-
phered by a 10 letter shift in a Caesar cipher. Which is the plaintext?
(a) popcorns.
(b) nonsense.
(c) ascience.
(d) None of the above.
B7.13. Verify that the cipher with to be or not to be that is the question as its key
phrase determines the permutation:
0
1 2 3 4
5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
19 14 1 4 17 13 7 0 8 18 16 20 2
3
5
6
9 10 11 12 15 21 22 23 24 25
B7.14. We want to encipher a message using a monoalphabetic substitution. Sup-
pose we have chosen as our key phrase there are more things in heaven and earth.
Which is the enciphering alphabet we get?
(a)
a b c d e
f
g h i
j k l m n o p q r
s t u v w x y z
T H E R A M O I N G S V D B C F J K L P Q U W X Y Z
(b)
a b c d e
f
g h i j
k l m n o p q r s
t u v w x y z
T H E R A M O T I N G S V D B C F J K P Q U W X Y Z
(c)
a b c d e
f
g h i j
k l m n o p q r
s t u v w x y z
T H E R A M O T I N G S D B C F J K L P Q U W X Y Z
(d)
a b c d
e
f
g h i
j k l m n o p q r s
t
u v w x y z
T H E A M O R I N G S D B C F J K L P Q U V W X Y Z
B7.15. Consider the monoalphabetic substitution of the previous exercise. Which ci-
phertext is obtained from the plaintext than are dreamt of in your philosophy?
(a) PITB TKM AKMTDP CO NB YCQK FINVCLCFIY.

B7 Computational exercises
393
(b) PITB TLA RLATDP CM NB YCQL FINVCLCFIY.
(c) PITB TKA RKATDP CM NB YCQK FINVCLCFIY.
(d) PITB TKE AKETDP CO NB YCQK FINVCLCFIY.
B7.16. Suppose we are reading a text enciphered using the monoalphabetic sub-
stitution given in the two previous exercises. If this text is LWCKR, which is the
plaintext?
(a) swear.
(b) sword.
(c) swore.
(d) None of the above.
B7.17. We want to encipher a message using a monoalphabetic substitution. Sup-
pose we have chosen as our key phrase
Tyger Tyger, burning bright,
in the forests of the night.
Which is the enciphering alphabet we get from this key phrase?
(a)
a b c d e
f
g h i j
k
l m n o p q r s
t
u
v w x
y z
T Y G E R B U N I H F O R S A C D J K L M Q V W X Z
(b)
a b c d e
f
g h
i j k
l m n o p q r
s
t
u v w x
y z
T Y G E R B U N F I H O S A C D J K L M P Q V W X Z
(c)
a b c d e
f
g h i j
k
l m n o p q r
s
t
u v w x
y z
T Y G E R B U N I H F O S A C D J K L M P Q V W X Z
(d)
a b c d e
f
g h
i j k
l m n o p q r s
t
u
v w x
y z
T Y G E R B U N F I H O R S A C D J K L M Q V W X Z
B7.18. Consider the monoalphabetic substitution determined by the key phrase
Tyger Tyger, burning bright, in the forests of the night,
for
which
we
have determined the enciphering alphabet in Exercise B7.17. Which is the enci-
phered text we obtain from the plaintext poem by blake?
(a) DCRS YX YOTFR.
(b) DCSR XY XOTHR.
(c) DCSR YX YOTHR.
(d) DCRS XY XOTFR.
B7.19. Suppose we are reading a text enciphered using the monoalphabetic substi-
tution of the previous exercise, that is, using the key phrase Tyger Tyger, burning
bright, in the forests of the night. If this text is LIAUTOCAU, which is the
plaintext?
(a) singasong.
(b) longsongs.
(c) alongsong.
(d) None of the above.

394
7 Secrets. . . and lies
B7.20. Use the program of exercise C7.3 to encipher the message sent to Edgar
Allan Poe, using the key phrase UNITED STATES. Check the mistakes that were
made in the message as given in the text.
B7.21. Let ALGEBRA be the key word chosen to encipher a message using Vigen`ere
method (see pp. 323-325). If the plaintext is very hard to decrypt, which is the
enciphered text?
(a) VPXC IRRD EU HFTRYAZ.
(b) VPXC IRRD EU HFTRYAZ.
(c) VPXC IRRD EU HFTRYAZ.
(d) VPXC IRRD EU HFTRYAZ.
B7.22. Let again ALGEBRA be the key word chosen to encipher a message using
Vigen`ere method. If the ciphertext is I SGZF JOLGKH OZNE PDISTISPY, which is the
plaintext?
(a) i have solved five exercises.
(b) i have solved four exercises.
(c) i have solved nine exercises.
(d) None of the above.
B7.23. Let HARDWORK be the key word chosen to encipher a message using Vigen`ere
method. If the plaintext is all work and no play makes jack a dull boy, which
is the ciphertext?
(a) HLC ZFKB KUD ES LZRI TABHO XRMR A WXHZ SYF
(b) HLC ZKFB KUD ES LZRI YABHO XRMR A UXHZ SYF
(c) HLC ZFKB KUD ER LZRI YABHO XRMR A UXHZ SYF
(d) HLC ZKFB KUD ER LZRI TABHO XRMR A UXHZ SYF
B7.24. Let again HARDWORK be the key word chosen to encipher using Vigen`ere
method. If the ciphertext is AABHWRRIVUK, which is the plaintext?
(a) have a day out.
(b) just one more.
(c) too much work.
(d) None of the above.
B7.25. Encipher the message attack today in 4-letter blocks using the translation
method in P = Z4
26 described in section 7.4.1 using the key k = 100 (see Table 7.8
on page 340).
B7.26. Consider the plaintext happy birthday. Which is the text enciphered using
the aﬃne transformation with key k = (7, 3)?
(a) ADEEP KHSGAYDP.
(b) ADEEM JHSGAYDM.
(c) ADEEP JHSGAYDP.
(d) ADEEM KHSGAYDM.
B7.27. Suppose we receive the message ZDB AHJ FDSCP, knowing that it has been
enciphered using the aﬃne transformation with key k = (7, 3). Which is the plain-
text?

B7 Computational exercises
395
(a) see him later.
(b) saw you early.
(c) see you later.
(d) saw him early.
B7.28. Compute, if it exists, the inverse modulo 26 of the matrix
 7
3
−5 −10

.
(a) The inverse does not exist because the determinant of the matrix is not relatively
prime with 26.
(b) The inverse is
 12
−1
7
−11

.
(c) The inverse is
 11
1
7
−11

.
(d) None of the above.
B7.29. Compute, if it exists, the inverse modulo 26 of the matrix
 19 13
2
11

.
(a) The inverse does not exist because the determinant of the matrix is not relatively
prime with 26.
(b) The inverse is
 11
13
−2 −19

.
(c) The inverse is
 −11 13
−2
19

.
(d) None of the above.
B7.30. We want to encipher the plaintext computer using an aﬃne transformation
of Z2
26 deﬁned by the key k = (A, b), with
A =

7
3
−5 −10

,
b =

1
2

.
Which is the ciphertext?
(a) FIAAQYCU.
(b) FIABQZCU.
(c) FIABQYCU.
(d) FIABQZCU.
B7.31. Consider a text enciphered using the aﬃne transformation given in the
previous exercise. If the ciphertext is VOITJOCHGN, which is the plaintext?
(a) twosecrets.
(b) tensecrets.
(c) anysecrets.
(d) sixsecrets.

396
7 Secrets. . . and lies
B7.32. Trying to perform the cryptanalysis of a message we have intercepted, we are
confronted with the problem of solving the following system of linear congruences:

19 ≡6a + b
(mod 26),
13 ≡3a + b
(mod 26).
How many solutions does this system admit modulo 26?
(a) One.
(b) No one.
(c) Inﬁnitely many.
(d) None of the above.
B7.33. Trying to perform the cryptanalysis of a message we have intercepted, we are
confronted with the problem of solving the following system of linear congruences:

11 ≡21a + b
(mod 26),
−7 ≡−5a + b
(mod 26).
How many solutions does this system admit modulo 26?
(a) One.
(b) No one.
(c) Inﬁnitely many.
(d) None of the above.
B7.34. Let S = {1, . . . , 15}. Consider the function f : S →S, f(x) = 5x mod 16.
What can be said about f?
(a) It is bijective.
(b) It is injective but not surjective.
(c) It is surjective but not injective.
(d) It is neither surjective nor injective.
B7.35. Consider the function f : Z4 →F∗
5, f(x) = 4x mod 5. What can be said
about f?
(a) It is bijective.
(b) It is injective but not surjective.
(c) It is surjective but not injective.
(d) It is neither surjective nor injective.
B7.36. Consider the function f : Z8 →F∗
9, f(x) = ix, where i is an element of F9
such that i2 = −1. What can be said about f?
(a) It is bijective.
(b) It is injective but not surjective.
(c) It is surjective but not injective.
(d) It is neither surjective nor injective.
B7.37. Consider the function f : Zq−1 →F∗
q, f(x) = bx, where b is an element of
F∗
q. What can be said about f?

B7 Computational exercises
397
(a) The function f is bijective for all b.
(b) There exists at least a value of b such that f is bijective.
(c) There exists exactly one b such that f is bijective.
(d) In general there is no b such that f is bijective.
B7.38. Verify that ¯2 is a generator of U(Z101). Compute the discrete logarithm
log2 ¯3.
B7.39. Using the Baby step–giant step algorithm determine log2 7 in base 13. The
answer is:
(a) 4.
(b) 5.
(c) 7.
(d) 11.
B7.40. Using the Baby step–giant step algorithm determine log3 7 in base 17. The
answer is:
(a) 4.
(b) 11.
(c) 7.
(d) 16.
B7.41. Consider the sequence 1, 3, 4, 8, 13, 20. How many solutions has the knapsack
problem for this sequence and m = 34?
(a) None.
(b) One.
(c) Two.
(d) Three.
B7.42. Consider the sequence 2, 3, 7, 8, 15, 27. How many solutions has the knapsack
problem for this sequence and m = 35?
(a) None.
(b) One.
(c) Two.
(d) Three.
B7.43. Is the sequence 1, 5, 8, 15, 30, 60 superincreasing?
(a) Yes.
(b) No, because 2 · 5 > 8 and 2 · 8 > 15.
(c) No, because 60 ≤1 + 5 + 8 + 15 + 30.
(d) None of the above.
B7.44. Is the sequence 1, 2, 5, 9, 17, 45 superincreasing?
(a) Yes.
(b) No, because 2 · 5 > 9.
(c) No, because 17 ≤1 + 2 + 5 + 9.
(d) None of the above.

398
7 Secrets. . . and lies
B7.45. Consider the superincreasing sequence 1, 2, 5, 11, 22, 44, 88. How many
solutions has the corresponding knapsack problem for m = 147?
(a) None.
(b) The only solution is x1 = x2 = x4 = x6 = x7 = 1 and x3 = x5 = 0.
(c) The only solution is x3 = x4 = x6 = x7 = 1 and x1 = x2 = x4 = 0.
(d) None of the above.
B7.46. Consider the superincreasing sequence 1, 4, 7, 13, 28, 54. How many solutions
has the corresponding knapsack problem for m = 76?
(a) None.
(b) The only solution is x1 = x3 = x4 = x6 = 1 and x2 = x5 = 0.
(c) The only solution is x1 = x2 = x3 = x6 = 1 and x4 = x5 = 0.
(d) None of the above.
B7.47. Consider the knapsack problem cipher. We have chosen the superincreasing
sequence 1, 3, 6, 12, m = 29 and w = 10. Which is the public key we have to publish
to have people send us enciphered messages?
(a) It is the sequence 10, 1, 2, 4.
(b) It is the sequence 10, 2, 4, 8.
(c) It is the sequence 10, 2, 3, 6.
(d) None of the above.
B7.48. Let 1, 2, 5, 20 be our superincreasing sequence, m = 43 and w = 25. Which
is the public key we have to publish to have people send us enciphered messages?
(a) It is the sequence 25, 7, 39, 29.
(b) It is the sequence 25, 7, 37, 27.
(c) It is the sequence 25, 7, 39, 27.
(d) None of the above.
B7.49. Consider the example of knapsack problem cipher illustrated in Table 7.10
on page 350. If the plaintext to be sent is otto, which is the numerical equivalent
of the ciphertext?
(a) 73 17 58 41 58.
(b) 73 17 50 41 58.
(c) 73 34 50 41 58.
(d) 73 34 58 41 58.
B7.50. Consider again the example in Table 7.10 on page 350. If the plaintext to
be sent is casa, which is the numerical equivalent of the ciphertext?
(a) 32 0 7 34 0.
(b) 32 0 17 34 0.
(c) 32 0 7 0 17.
(d) 32 0 7 17 0.
B7.51. To access the RSA system, Blanche wants to publish the enciphering key
(7927, 37), but the system does not accept this key. Why?

B7 Computational exercises
399
(a) Because 7927 is too large.
(b) Because 37 is too small.
(c) Because 7927 is not the product of two prime numbers.
(d) Because 37 is not relatively prime with ϕ(7927).
B7.52. To access the RSA system, Ariadne wants to publish the enciphering key
(9991, 119), but the system does not accept this key. Why?
(a) Because 9991 is too large.
(b) Because 119 is too small.
(c) Because 9991 is not the product of two prime numbers.
(d) Because 119 is not relatively prime with ϕ(9991).
B7.53. Consider the user directory (7.8) on page 352. A user of the RSA system
wants to send the message baba to the user B, Beatrix. Which enciphered message
does Beatrix receive?
(a) C1 = 9, C2 = 9.
(b) C1 = 999, C2 = 9.
(c) C1 = 999, C2 = 999.
(d) None of the above.
B7.54. Another user of the RSA system wants to send Beatrice a message. If the
plaintext is coda, which enciphered message does Beatrix receive?
(a) C1 = 31, C2 = 243.
(b) C1 = 546, C2 = 243.
(c) C1 = 546, C2 = 576.
(d) C1 = 31, C2 = 576.
B7.55. Consider again the user directory (7.8) on page 352. Beatrix has received
the following message:
C1 = 31,
C2 = 722,
C3 = 272.
Which is the numerical equivalent of the plaintext?
(a) 0214 0308 0204.
(b) 0214 0300 0208.
(c) 0214 0308 0208.
(d) None of the above.
B7.56. Beatrix has received the following message:
C1 = 243,
C2 = 722.
Which is the numerical equivalent of the plaintext?
(a) 0308 0200.
(b) 0300 0308.
(c) 0200 0308.
(d) None of the above.

400
7 Secrets. . . and lies
B7.57. Beatrix has received the following message:
C1 = 546,
C2 = 722,
C3 = 999.
Which is the numerical equivalent of the plaintext?
(a) 0314 0308 0208.
(b) 0308 0208 0314.
(c) 0308 0314 0208.
(d) 0314 0208 0308.
B7.58. Verify that the real curve of equation x3 + xy2 −x −3x2 −3y2 + 3 = 0 is
not singular, but it is so as a curve over C.
B7.59. Give an example of a curve that is not singular over Q but is singular over
R.
B7.60. Consider the elliptic curve over R of equation y2 = x3 −x. Let p = (−1, 0)
and q = (2, −
√
6). Which are the coordinates of p + q?
(a) p + q is the point at inﬁnity O.
(b) p + q = (−1/3, 2
√
6/9).
(c) p + q = (−1/3, −2
√
6/9).
(d) None of the above.
B7.61. Consider the elliptic curve over R of equation y2 = x3 −x. Let p = (1, 0)
and q = (2,
√
6). Which are the coordinates of p + q?
(a) p + q is the point at inﬁnity O.
(b) p + q = (3, 2
√
3).
(c) p + q = (3, −2
√
3).
(d) None of the above.
B7.62. Consider the elliptic curve over R of equation y2 = x3 −x. Let p = (−1, 0).
Which are the coordinates of 2p = p + p (in the group law on the curve)?
(a) 2p is the point at inﬁnity O.
(b) 2p = (−1, 0).
(c) 2p = (0, 0).
(d) None of the above.
B7.63. Consider the elliptic curve over R of equation y2 = x3 −x. Let p = (2, −
√
6)
e q = (0, 0). Which are the coordinates of p + q?
(a) p + q is the point at inﬁnity O.
(b) p + q = (−1/2,
√
6/4).
(c) p + q = (−1/2, −
√
6/4).
(d) None of the above.
B7.64. Let C be the elliptic curve of equation y2 = x3 −x over the ﬁeld F7. Are
p = (1, 0) and q = (−2, −1) points of C?
(a) Both p and q are points of C.
(b) The point p is on C, but q is not.

C7 Programming exercises
401
(c) The point q is on C, but p is not.
(d) Neither p nor q belong to C.
B7.65. Let C be the elliptic curve of equation y2 = x3 −x over the ﬁeld F5. Are
p = (2, 1) and q = (−2, 2) points of C?
(a) Both p and q are points of C.
(b) The point p is on C, but q is not.
(c) The point q is on C, but p is not.
(d) Neither p nor q belong to C.
B7.66. Prove that the elliptic curve of equation y2 + y = x3 + 1 has three points
over Z2, including the point at inﬁnity.
B7.67. How many points has the curve y2 = x3 −x over F7?
(a) 3.
(b) 6.
(c) 8.
(d) 10.
B7.68. How many points has the curve y2 + y = x3 over F8?
(a) 4.
(b) 5.
(c) 7.
(d) 9.
C7 Programming exercises
C7.1. Write a program that implements any Caesar cipher, that is, given in input
a number n, with 1 ≤n ≤25, and a text, it outputs the text enciphered by shift-
ing each letter by n positions. Then write a program that deciphers a message so
enciphered.
C7.2. Write a program that, given a text as its input, outputs a frequency table of
the letters appearing in the text.
C7.3. Write a program that, given as input a key word and a text, outputs the text
enciphered using Vigen`ere method (see pp. 323-325) with the given key word.
C7.4. Write a program that, given in input a text enciphered with Vigen`ere method
and the key word, outputs the plaintext.
C7.5. Write a program that computes the inverse of a square matrix modulo a
positive integer, if it exists.
C7.6. Write a program that, given in input a text and two integers a, b, outputs the
text enciphered with the aﬃne transformation Ca,b : Z26 →Z26, Ca,b(P) = aP + b
(mod 26).

402
7 Secrets. . . and lies
C7.7. Write a program that, given in input a text, an s × s square matrix A and
a vector b of length s, outputs the text enciphered with the aﬃne transformation
CA,b : Zs
26 →Zs
26, CA,b(p) = Ap + b (mod 26), where p is a vector of length s.
C7.8. Write a program that computes discrete logarithms using the Baby step–giant
step algorithm.
C7.9. Write a program that veriﬁes whether an n-integer sequence is superincreasing
or not.
C7.10. Write a program that generates a superincreasing n-integer sequence.
C7.11. Write a program that, given in input a superincreasing sequence a1, . . . , an
and an integer m, outputs the solution to the corresponding knapsack problem, if
it exists. (Hint: use the algorithm described in the text.)
C7.12. Write a program that, given in input an integer N, outputs: (1) a superin-
creasing sequence a1, . . . , aN, an integer m > 2aN and an integer w relatively prime
with n (the private data of a user X); (2) the sequence bj = waj mod m (the public
key of user X).
C7.13. Write a program that, given in input a sequence (bj), constituting the public
key in a Merkle–Hellman system, and a plaintext, outputs the text enciphered with
the bjs to be sent to the user X.
C7.14. Write a program that, given in input a ciphertext and the deciphering private
key, outputs the plaintext. (Hint: use the program solving the knapsack problem for
a superincreasing sequence.)
C7.15. Write a program that randomly generates a prime number with a given
number of digits. (Hint: use the algorithm described in Remark 7.7.1.)
C7.16. Write a program that, given in input a positive integer N, outputs a pair of
integers (n, e) such that n is the product of two prime numbers p, q each having N
digits, and e is relatively prime with both p −1 and q −1 (so we may use the pair
(n, e) as public key to use an RSA system).
C7.17. Write a program that, given in input a plaintext and the public key (n, e)
of a user A, outputs the ciphertext to be sent to A using the RSA system.
C7.18. Write a program that, given in input the ciphertext and the private infor-
mation n = pq in an RSA system, outputs the deciphered text.
C7.19. Write a program that ﬁnds points on an elliptic curve on a ﬁnite ﬁeld of
characteristic diﬀerent from 2.
C7.20. Write a program that, given in input a prime number p (suﬃciently small)
and the equation of an elliptic curve over Zp, computes how many points of the
plane lie on the curve. (Hint: proceed by trial and error for all the values in Zp of x
in the equation in Weierstrass form.)
C7.21. Write a program that, given in input the coordinates of two points p and p′
of an elliptic curve over a ﬁnite ﬁeld Fq, outputs the coordinates of the point p + p′.
(Hint: use the equations given in the text.)

C7 Programming exercises
403
C7.22. Write a program that, given in input the coordinates of a point p of an
elliptic curve deﬁned over a ﬁnite ﬁeld Fq, determines the order of p.
C7.23. Write a program that factors a number using Pollard’s p −1 algorithm.
C7.24. Write a program that computes [√n] for an integer n.

8
Transmitting without. . . fear of errors
This chapter gives a short introduction to codes and coding theory. The reader
has nothing to worry about: Justinian the Great, the Eastern Roman Emperor
who in 6th century rewrote Roman law has got nothing to do with it! Coding
theory studies the mathematical problem of transmitting data through chan-
nels in which interference is present. During the transmission, it may happen
that the noise present in the channel modiﬁes some of the transmitted data,
jeopardising the intelligibility of the message on arrival.
So it is necessary to ﬁnd techniques allowing the detection of the errors
and, possibly, their correction, and of course fast coding and decoding of the
data to be sent. It is clear that the cost to pay for this requirement consists in
having to transmit additional data: on the one hand, they allow us to verify if
an error has occurred, and possibly to correct it, on the other hand, they make
the transmission operations more complex. So, for the system to be eﬃcient
it is necessary to ﬁnd the best balance between redundancy and correctness
of the information. Coding theory is a quite recent branch of mathematics,
living in an important border area close to computer science, an aspect we
shall not dwell upon here. It also has signiﬁcant applications in other sciences,
mainly biology: DNA, for instance, is a code. In coding theory we see a con-
vergence of several subtle combinatorial, algebraic, and geometric techniques,
partly discussed in previous chapters. We shall try here, without aiming at
completeness, and leaving apart several important aspects of the theory, to
give a taste of what is happening in this area in which, we are certain, remark-
able developments will be seen in the next few years. So this chapter, more
than a systematic treatment, is an invitation to further reading; in particular,
we recommend the classic references [36], [41], [39], where a rich bibliography
will be found. Several more recent texts can also be suggested, such as [6]. A
last warning: in this chapter we shall only discuss the so-called block codes,
which can be more directly studied using the algebraic and geometric tech-
niques we have mentioned. We shall omit a treatment of the variable-length
codes, which are very important too, both from a theoretical, mathematical

406
8 Transmitting without. . . fear of errors
viewpoint and for the applications. The interested reader may look them up
in the references.
8.1 Birthday greetings
If on your birthday you receive a greeting card saying
WARM BIRTKDAY WISHES!
you will be glad, even if you cannot avoid noticing that the sender made a
mistake. . . But let us reﬂect a moment and ask ourselves: (a) how can we be
sure that in the message there is an error? (b) how can we be certain about
the number and the position of the errors? (c) why are we sure of being able
to correct the error or errors? (d) in other, analogous situations, how could
we recognise and correct the errors?
Let us tackle the questions one at a time, starting from (a). English words,
as in any other language, consist of letters of an alphabet. However, not all
combinations of letters from the alphabet correspond to words. It is this re-
dundancy of the words in a language with respect to all possible words that
makes it possible to recognise errors. For instance, WARM is a word belonging
to the English language, while BIRTKDAY is not. So we are sure that in the
message there is an error.
As to questions (b) and (c), the above reasoning already suggests part of
the answer: certainly, there is an error in the word BIRTKDAY. There could
be other ones: we might not notice them because we recognise a mistaken
word as another English word. For instance, WARM might have been writ-
ten in the place of WORM. However we look at the signature and ascertain
that the author is a friend who can spell quite well and is not particularly
absent-minded. He might well have made a mistake, say in a hurry or through
carelessness, but we doubt very much he made two in the same, very short
message! As we are certain that he made one in the word BIRTKDAY, we
believe that there are no other mistakes. Reasoning in the same way, we also
believe that a single letter is wrong in this word, so we read BIRTHDAY
rather that BIRTKDAY, and the error is corrected.
As to question (d), it is the more complex one. What if we had received a
card saying
HARM BIRTHDAY FISHES
in which all words are English words? How could we be certain that there are
errors? And how could we correct them? We shall see that in order to be able
to come to a conclusion about this last question other elements may be taken
in account: for instance, an encouragement to harm something would be out
of place in a greeting card, our friend is not especially interested in ﬁshes, and
so on.
In conclusion, we desire to indicate at least three points displayed by our
reasoning:

8.2 Taking photos in space or tossing coins, we end up at codes
407
(i) English language, as every language, by the way it is written down, has
an inborn high measure of redundancy, which is what makes it possible
to recognise and correct errors;
(ii) the lower we may assume the probability of each error, the more errors
we are able to correct;
(iii) it may happen that, even if we are aware of an error being present in
a sentence, we are not be able to correct it with a reasonable degree of
certainty.
What has this rambling speech about greeting cards to do with codes,
which are the subject of this chapter? There is a very strict link! Coding the-
ory is exactly about this problem. A message is sent through a transmission
channel, which might be an optical cable, a satellite link, or any other com-
munication medium. During the transmission the initially correct message
sustains modiﬁcations, due to imperfections in the optical ﬁbre, interference
of other signals and so on. We want to recognise if it contains errors and, if so,
to be able to correct them. It turns out that it is a problem quite similar to
the one of the greeting, so the remarks we made about the latter may help us
in giving a correct mathematical formulation to our treatment of the former.
8.2 Taking photos in space or tossing coins, we end up at
codes
A typical example of a problem solved by coding theory is a quite important
one. It was faced by the technicians at the Jet Propulsion Laboratory of
the California Institute of Technology at Pasadena, when, at the end of the
1960’s, they were working on the Mariner and Voyager space probes designed
to approach Mars or Jupiter, photograph these planets and send black and
white pictures back to the Earth. How does transmitting one of these pictures
work?
Consider a 30 cm × 30 cm photograph. It is divided by a grid consisting of
0.1 mm2 squares, and for each square the corresponding intensity of grey, on
a scale, say from 0 to 63, where 0 represents white and 63 black, is sent to the
Earth. If numbers are represented in binary form, the probe computer sends
a 0 - 1 string of length six for each square. By collecting all these numbers
and assigning to each of them its colour, the image can be reconstructed.
Quite easy, isn’t it? But what if there are errors, perhaps due to some kind
of interference, a natural thing to be expected for such unusual transmissions?
For instance, it may happen that there is an error probability p, say of the
order of p = 0.001; that is, we may expect on the average one error for
every 1000 transmitted digits. The reader will immediately realise, with simple
calculations left to him, that the transmission may be seriously disrupted, and
the photograph irreparably altered.

408
8 Transmitting without. . . fear of errors
To remedy this problem, it is necessary to introduce in the procedure we
are implementing in the probe computer the redundancy we have been talking
about in the previous section: it allows us to recognise and correct errors.
To simplify the model we are dealing with, without reducing the scope
of the problem, consider the following situation. A man in Australia tosses a
coin and transmits us, via email, 0 if it comes up as HEADS and 1 if it shows
TAILS. But during the transmission there is an error probability p which, as
usual, is a number between 0 and 1. For instance, if p = 0.01, it happens just
once in one hundred transmissions that 1 is transmitted instead of 0 or the
other way around.
If we receive 0, we cannot be certain that the result was HEADS. However,
in this situation, as in the case of Mars photographs, there is no redundancy.
Let us introduce it, as follows.
We ask the man in Australia to send 00 if the result is HEADS, and 11
if it is TAILS. Assume HEADS shows up. The probability for us to receive
11, that is to say, that two errors have occurred during the transmission, is
p2 = 0.0001, very very small! The probability of receiving 01 or 10, that is,
that a single error occurs, is 2 · 0.99 · 0.01 = 0.0198, while the probability of
receiving the correct information 00 is 0.99·0.99 = 0.9801. On the other hand,
if we receive 01 or 10 we are certain that a transmission error has occurred,
and we may ask the man in Australia to send again the result. So we are led
into error only in one case out of 10000.
If we have at our disposal plenty of time and money to use the commu-
nication channel with Australia, we may improve the situation even more.
We ﬁx an odd positive integer n, and have the man send us a string of n 0’s
if the result is HEADS, and one of n 1s if the result is TAILS. On arrival,
we interpret as HEAD a string containing more 0’s than 1’s and as TAILS a
string containing more 1’s than 0’s. A simple computation we do not make
here shows that the probability of an error becomes
Pn =

0≤i<⌊n/2⌋
n
i

pn−i(1 −p)i
and it tends to zero when n approaches inﬁnity (see Exercise A8.1).
The scheme we are using is a code, called repetition code. Let us expound
this notion.
We ﬁx ﬁrst our attention upon the set of words we use in our transmissions.
To write these words we need an alphabet, that is, a set of symbols to be used
in our messages. For instance, in the situation discussed above, the alphabet
is Z2, a not unusual choice because transmitting data, as we know, often
occurs by transmitting information bits. More in general, we may consider as
our alphabet a ﬁnite ﬁeld Fq. We may further assume that the words we use
consist of a bounded number of alphabet letters, say at most k: consider the
fact that the longest (non-technical, non-made up) word in English is
ANTIDISESTABLISHMENTARIANISM

8.2 Taking photos in space or tossing coins, we end up at codes
409
which consists of 28 letters. On the other hand, it is not restrictive to assume
that all the words we are using have the same length k. Indeed, we may use
an alphabetic symbol as a dummy symbol to be added at the end of the words
of length smaller than k to write them with exactly k letters.
So, once we have ﬁxed the alphabet Fq, we may assume that the set of
words we shall use, that is our dictionary is a subset C of Fk
q.
For instance, in the case of the Australian coin tosser, the word set is
C = F2, as the only two words we want to communicate are 0 for HEADS
and 1 for TAILS.
But so far there is no space for the redundancy mentioned more than
once, which is essential to discover whether the message contains errors and,
possibly, to correct them. To introduce redundancy we need to represent each
word in our dictionary using more symbols than strictly necessary to represent
it. In order to do so, it suﬃces to ﬁx another positive integer n ≥k and give,
for instance, an injective mapping
f : Fk
q →Fn
q ,
by which we may identify our dictionary C ⊆Fk
q with a subset of C of Fn
q .
For instance, for the coin tosser, the mapping f is the one mapping
x ∈F2 to (x, x, . . . , x) ∈Fn
2; hence, C = F2 is identiﬁed with the subset
{(0, 0, . . ., 0), (1, 1, . . . , 1)} of Fn
2, which is called a repetition code.
In conclusion, we may give the following deﬁnition.
Deﬁnition 8.2.1. A code over the alphabet Fq is a subset C of Fn
q , where n
is a positive integer, called length of the code. The number M of elements
of C is called size of the code. Codes having as alphabet F2 are called binary
codes.
Such a code, in which both the length of the words and the size of the
code are ﬁxed, are called block codes. It is also possible to consider a more
general notion of code, in which length and size may vary. This codes are
called variable-length codes and we shall not consider them here.
Notice that the code used by the Australian coin tosser, based on a double
repetition of each digit, allows the detection of a single error. The code in
which digits are repeated three times allows the detection of at most two
errors and so on. Unfortunately, as we have seen, ﬁnding an error does not
imply correcting it. We shall work a bit to obtain codes that also enable us to
correct errors.
Moreover, notice that the length n of code C may be seen as a measure of
the cost of the code. The longer a code, the more time and energy are needed
to send messages and so the higher the cost of using it. The size M of the
code C may be seen instead as a measure of how rich the code is. The more
words a code consists of, the larger and more various amount of information
it can transmit. A very rich code cannot be too short. This ratio quality/price
may be represented by the number

410
8 Transmitting without. . . fear of errors
R = logq M
n
,
(8.1)
which equals k/n if the original dictionary is Fk
q. The number R is called
information rate of the code. In principle, one would like it to be as close as
possible to 1 for the code not to be too expensive, but it cannot be too close
to 1 if the code has to be suﬃciently eﬃcient as to its capability of detecting
and correcting errors.
8.3 Error-correcting codes
Let us see now how to improve the eﬃciency of the codes, enabling them not
only to detect errors but also to correct them. At the same time, we want
also to minimise the cost of this operation, better than we have done, in a
somewhat naive way, in the previous section in the case of the Australian coin
tosser.
The inventor of the procedure we are about to describe is R. Hamming
(1948), then at the Bell Telephone Laboratories. Consider again a particular
example, the one Hamming himself actually examined. It is very similar to
that of Mars photographs, mentioned in the previous section. Suppose we
want to send messages consisting of numbers from 0 to 15 written in base
2. So they are 4-tuples of 0 and 1 digits. In other words, our code has as its
alphabet F2, and C = F4
2, so M = 24 = 16.
When transmitting the 4-tuple (a1, a2, a3, a4), we do not transmit just it
alone, but we transmit instead the 7-tuple
(a1, a2, a3, a4, a1 + a3 + a4, a1 + a2 + a4, a1 + a2 + a3).
(8.2)
The sums, of course, are computed in F2. For instance, rather than the 4-tuple
(0, 1, 0, 0) we transmit the 7-tuple (0, 1, 0, 0, 0, 1, 1).
Basically, we are constructing a code of length n = 7, embedding C = F4
2 in
F7
2 according to the injective mapping that associates the element (8.2) of F7
2
to (a1, a2, a3, a4) ∈F4
2. This code, called Hamming (7, 4) code has information
rate R = 4/7: not bad, if compared to the ratio 1/n of the coin tosser.
Let us see now what has been gained by increasing the length of the code.
First of all, notice that, if (x1, . . . , x7) is a word of our code, we have
⎧
⎪
⎨
⎪
⎩
x1 + x3 + x4 + x5 = 0,
x1 + x2 + x4 + x6 = 0,
x1 + x2 + x3 + x7 = 0.
(8.3)
Indeed, for instance, the left-hand side of the ﬁrst equation is 2x1 +2x3 +2x4,
which is equal to 0 in F2.
We may interpret (8.3) as a linear system of equations over the ﬁeld F2.
This system is said to be the parity check system of the code we are consider-
ing. It is easy to understand that every solution of this system is an element of

8.3 Error-correcting codes
411
F7
2 that is a word of our code (see Exercise A8.2). So if we receive the message
(x1, . . . , x7) and it does not verify the system (8.3), we are certain that there
is a transmission error. So this is an error-detecting code.
But more can be said. Suppose we know, or regard as likely enough, that
there is no more than one transmission error. From the form itself of the
system (8.3), it is clear that, if there is exactly one error, all possible cases
are the following ones:
•
if (x1, . . . , x7) does not verify any equation of the linear system (8.3), the
error is in the ﬁrst position;
•
if (x1, . . . , x7) veriﬁes the ﬁrst equation of the linear system (8.3), but not
the other two, the error is in the second position;
•
if (x1, . . . , x7) veriﬁes the second equation of the linear system (8.3), but
not the other two, the error is in the third position;
•
if (x1, . . . , x7) veriﬁes the third equation of the linear system (8.3), but not
the other two, the error is in the fourth position;
•
if (x1, . . . , x7) veriﬁes the second and third equation of the linear system
(8.3), but not the ﬁrst one, the error is in the ﬁfth position;
•
if (x1, . . . , x7) veriﬁes the ﬁrst and third equation of the linear system
(8.3), but not the second one, the error is in the sixth position;
•
if (x1, . . . , x7) veriﬁes the ﬁrst and second equation of the linear system
(8.3), but not the third one, the error is in the seventh position.
In conclusion, if we know that there is a single error, the system (8.3) also
allows us to ﬁnd where the error is, and so to correct it. Indeed, as the code
is binary, if we know where an error is, to correct it it suﬃces to change the
symbol lying in the speciﬁed place.
Example 8.3.1. Suppose we receive the word p = (0, 1, 0, 1, 0, 1, 0), which
contains errors, as it does not satisfy linear system (8.3), and assume that
there is exactly one error.
As p does not satisfy any of the three equations of linear system (8.3), by
the remarks above we know that the error is in the ﬁrst coordinate, so the
correct word is (1, 1, 0, 1, 0, 1, 0).
Why does this code work so well with respect to correcting one error? The
crucial remark is that two distinct words of the code diﬀer in at least three
coordinates. We ask the reader to check this claim as an exercise (see Exercise
A8.3).
Let (x1, . . . , x7) be a word of the code which, during the transmission, un-
dergoes a change in a single coordinate, for instance the ﬁrst one, so we receive
(x′
1, x2, . . . , x7). As every other codeword diﬀers form (x1, . . . , x7) in at least
three coordinates, it diﬀers from (x′
1, x2, . . . , x7) in at least two coordinates.
Thus, we may correct the error by applying the maximum likelihood principle,
that is, by assuming that the corrected form of (x′
1, x2, . . . , x7) is (x1, . . . , x7)
because the latter is the nearest codeword, that is to say, the most similar
one, being the only one diﬀering from (x′
1, x2, . . . , x7) in a single coordinate.

412
8 Transmitting without. . . fear of errors
The reader will immediately understand that this way of proceeding is
completely analogous to the correction of the mistake in the greeting card of
the ﬁrst section.
These remarks suggest an immediate extension of these notions, which will
now be formalised.
Deﬁnition 8.3.2. Let x, x′ be two elements of Fn
q . The Hamming distance
between x and x′ is the number of coordinates in which x diﬀers from x′ and
is denoted by the symbol d(x, x′).
Assume we have a code C of length n. The minimum Hamming distance
between two words of C is denoted by the symbol d and is called minimum
distance of C.
If a code C which uses a q-symbol alphabet has size M, length n and
minimum distance d, it is said to be a code of type (n, M, d)q or a (n, M, d)q-
code. The numbers q, n, M, d are called the parameters of the code.
For instance, the Hamming (7, 4) code is a code of type (7, 16, 3)2.
It is not by chance that we use the term distance to designate d(x, x′). It
satisﬁes the same formal properties of the distance between points in a plane
or in the space, namely:
•
positivity: for all x and x′, d(x, x′) ≥0; moreover, d(x, x′) = 0 if and only
if x = x′;
•
symmetry: for all x and x′, d(x, x′) = d(x′, x);
•
triangle inequality: for all x, x′ e x′′,
d(x, x′) ≤d(x, x′′) + d(x′′, x′).
We urge the reader to verify these properties (see Exercise A8.4).
Let us see the connection between the Hamming distance and the problem
of error correction. First of all, yet another deﬁnition.
Deﬁnition 8.3.3. We say that a code C detects h errors if, whenever in the
transmission of a word at most h errors occur, it is possible to ﬁnd out this
fact, as the string obtained does not correspond to any codeword. We say next
that a code C corrects h errors if, whenever in the transmission of a word at
most h errors occur, it is possible to ﬁnd it out, and moreover it is possible to
correct the errors by applying the maximum likelihood principle, as there is a
single codeword having least Hamming distance from the received string.
For instance, the Hamming (7, 4) code detects and corrects one error
The connection between error correction and Hamming distance is given
by the following theorem, whose proof is left to the reader as an exercise (see
Exercise A8.5):
Theorem 8.3.4. Assume a code C has minimum distance d. Then:
(i) C detects k errors if and only if d ≥k + 1;

8.4 Bounds on the invariants
413
(ii) C corrects k errors if and only if d ≥2k + 1.
Remark 8.3.5. Suppose we are working with a code C having length n, which
uses a transmission channel having error probability p < 1/2. We receive a
word x having Hamming distance d from the word y. Then the probability of
having received x instead of y equals
P = pd(1 −p)n−d =

p
1 −p
d
(1 −p)n.
(8.4)
(see Exercise A8.6). As p < 1/2, then p/(1 −p) < 1 and (1 −p)n does not
depend on d. Thus, P decreases when d increases. So error correction by the
maximum likelihood principle, which coincides with the minimum Hamming
distance principle, puts into practice the need for minimising the error prob-
ability when decoding.
We conclude this section mentioning a simpliﬁed version of a fundamental
result, due to C. E. Shannon (1948), which may be said to have originated
coding theory. We need some more notation.
Let C = {x1, . . . , xM} be a code having length n, which does not necessar-
ily detect or correct errors. We shall use the maximum likelihood principle to
correct errors. Let Pi be the probability of being wrong by decoding like this
when the word xi had been transmitted erroneously. Then the probability of
being wrong somewhere when decoding a word of C is
PC = 1
M
M

i=1
Pi.
We have the following result.
Theorem 8.3.6 (Shannon’s theorem).
Suppose we are using codes with
alphabet F2 over a transmission channel admitting an error probability p. For
every real number ε > 0 and for every positive real number R < 1 + p log p +
(1 −p) log(1 −p) there is a code C with information rate at least equal to R
and for which the error probability PC is smaller than ε.
A more general version of this theorem may be given for codes over an
arbitrary alphabet. For its proof, see for instance [36], pp. 27–29.
8.4 Bounds on the invariants
The Hamming (7, 4) code is a good code, in the sense that it allows not only
to detect if in transmitting data an error has occurred, but also to correct it,
if it occurred. This code, as we have seen, is of type (7, 16, 3)2, that is to say,
it has parameters n = 7, M = 16 and d = 3.

414
8 Transmitting without. . . fear of errors
There is a natural question: is it possible to construct a better code? To
make this question meaningful, we must ask ﬁrst when a code may be consid-
ered better than another.
It is clear that we would consider a code better than the Hamming (7, 4)
code if it were of type (n, M, d)2 with, for instance, n < 7, M ≥16 and d ≥3,
or n ≤7, M > 16 and d ≥3, or n ≤7, M ≥16 and d > 3. In the ﬁrst case,
the rest of the performance being equal, the code would be shorter because
n < 7, and so less expensive; in the second case, the code would have more
words because M > 16, in the third case it might detect and even correct
more errors, because d > 3. The fact is that the parameters of a code are
not at all independent of each other, as we shall see shortly. In fact, there are
several relations between n, M, and d; we shall describe the main ones. As a
consequence of these relations, it is possible to prove that there is no better
code, in the sense just discussed, than the Hamming (7, 4) code.
The relations between the parameters of a code are of two kinds: upper
bounds for M and lower bounds for M, in terms of n and d. For instance, it
is clear that M ≤qn, because C, which is a set with M elements, may be
regarded as a subset of Fn
q , which has qn elements. The bound M ≤qn is
clearly very rough. A better one is given by the following theorem.
Theorem 8.4.1 (Singleton bound). Let n, M, d and q be the parameters
of a code C. Then:
M ≤qn−d+1.
Proof. Write all words of the code C in a table as follows:
a1,1
a1,2 . . . a1,d−1
a1,d . . . a1,n
a2,1
a2,2 . . . a2,d−1
a2,d . . . a2,n
a3,1
a3,2 . . . a3,d−1
a3,d . . . a3,n
...
...
...
...
...
...
...
aM,1 aM,2 . . . aM,d−1 aM,d . . . aM,n
(8.5)
where every line (a1,1, . . . , a1,n) is a word of the code C. Now consider the
strings consisting of the last n −d + 1 coordinates of every word of C, that
is to say, the right part of Table (8.5). They make up a new code C′ having
length n −d + 1. Two words of C′ are never equal, or else the corresponding
words of C would diﬀer in at most d −1 coordinates, which is impossible by
the hypothesis that C has minimum distance d. So the size of C′ is again M.
On the other hand, since C has length n −d + 1, we have M ≤qn−d+1.
⊓⊔
Notice that equality in Singleton bound holds if and only if, however n −
d + 1 coordinates are chosen, the codewords have on them all possible values
(see Exercise A8.7).
A more reﬁned upper bound for M is obtained by a geometric reasoning
due to Hamming, which shall now be described.

8.4 Bounds on the invariants
415
Assume we have a code C of type (n, M, d)q. The code is a subset of Fn
q .
Consider the latter as an n-dimensional vector space. Now, for every point
x ∈C consider the set of points Sq(x, r) of Fn
q having Hamming distance from
x smaller than or equal to r, that is,
Sq(x, r) = {y ∈Fn
q : d(x, y) ≤r}.
Carrying on the geometric analogy, it is natural to call Sq(x, r) a sphere of
centre x and radius r. We leave the reader the easy task (see Exercise A8.8)
of proving that the volume of Sq(x, r), that is to say, the number of elements
in Sq(x, r), equals
Vq(n, r) =
r

i=0
n
i

(q −1)i.
(8.6)
Using this formula the following estimate is found:
Theorem 8.4.2 (Hamming bound). Let C be a code of type (n, M, d)q that
corrects k errors. Then
M ≤
qn
k

i=0
n
i

(q −1)i
.
(8.7)
In particular, Equation (8.7) holds for k = ⌊(d −1)/2⌋.
Proof. By Theorem 8.3.4, we have d ≥2k + 1, so for every pair of points
x, y ∈C, the two spheres Sq(x, k) and Sq(y, k) are disjoint, that is, have no
points in common. On the other hand, Fn
q includes the union S of all spheres
Sq(x, k) when x ranges in C, and as there are M such spheres and they are
pairwise disjoint, S contains M · Vq(n, k) elements, and so
M · Vq(n, k) ≤qn.
⊓⊔
The Hamming bound is, most of the times, better than Singleton’s. For in-
stance, the following result holds (see Exercises A8.10–A8.13; see also Exercise
A8.9):
Proposition 8.4.3. The codes of type (n, M, d)2 for which the Singleton
bound is better than the Hamming bound are only those with
(i) d = 2 and arbitrary n;
(ii) d = 4 and n = 4, 5, 6;
(iii) d = 6 and n = 6, 7;
(iv) d even, d ≥8 and n = d.

416
8 Transmitting without. . . fear of errors
The codes C for which in (8.7) the equality holds are called perfect. They
are characterised by the fact that they correct k errors and are such that
the union of the spheres Sq(x, k), with x ∈C, equals the set of all possible
words. In other words, perfect codes use very wisely the words that may be
constructed with a q-symbol alphabet. In particular, a perfect code cannot
ever correct more than k errors. Finally, it is clear that a perfect code cannot
be improved, in the sense discussed at the beginning of this section.
Notice that the Hamming (7, 4) code is a perfect code (see Exercise A8.14).
Another upper bound for M can be obtained by computing the maximum
possible value of the distance between two distinct codewords.
Theorem 8.4.4 (Plotkin bound). If C is a code of type (n, M, d)q, and if
qd −n(q −1) > 0, we have
M ≤
qd
qd −n(q −1).
Proof. Let Σ be the sum of the distances of all ordered pairs of distinct
words of C. There are M(M −1) such ordered pairs (see Exercise A8.15) and,
for each of them, the distance is at least d. So we have
Σ ≥M(M −1)d.
(8.8)
Compute now Σ in another way. Number from 0 to q −1 the symbols in the
alphabet of C. List the words of C as in Table (8.5), which may be considered
as a M × n matrix with values in Fq. Consider the ith column in the list.
Suppose that, for all j = 0, . . . , q −1, the symbol j of the alphabet appears
mi,j times in this column. As the column is a vector of length M, we have
q−1
j=0 mi,j = M. Then the contribution of this column to the sum Σ is
q−1

j=0
mi,j(M −mi,j) = M 2 −
q−1

j=0
m2
i,j.
By Cauchy–Schwarz inequality (see Exercise A8.16), we have
q
q−1

j=0
m2
i,j =
q−1

j=0
1 ·
q−1

j=0
m2
i,j ≥
⎛
⎝
q−1

j=0
1 · mj
⎞
⎠
2
=
⎛
⎝
q−1

j=0
mi,j
⎞
⎠
2
and so
q−1

j=0
mi,j(M −mi,j) ≤M 2 −
(q−1
j=0 mi,j)2
q
= M 2 q −1
q
.
In conclusion, summing over all columns, we have

8.4 Bounds on the invariants
417
Σ =
n

i=1
q−1

j=0
mi,j(M −mi,j) ≤
n

i=1
M 2 q −1
q
= M 2nq −1
q
.
Keeping in mind (8.8), the claim follows.
⊓⊔
Next we estimate M from below. The reasoning that led us to proving
the Hamming bound also suggests how to obtain a remarkable optimal lower
bound for the parameter M.
Indeed, deﬁne Aq(n, d) as the greatest M for which a code of type
(n, M, d)q exists. We want to give an estimate for Aq(n, d).
Theorem 8.4.5 (Gilbert–Varshamov bound). We have
Aq(n, d) ≥
qn
d−1

i=0
n
i

(q −1)i
.
Proof. Suppose we want to explicitly construct a code C of type (n, M, d)q.
In order to do so, we begin by choosing any word x1 ∈Fn
q and putting it in
C. Next, we choose a second word x2 ∈Fn
q having distance at least d from
x1 and put it in C. We proceed like this, recursively: after having chosen the
ﬁrst h words x1, . . . , xh of C, all having pairwise distance at least d, we choose
the (h + 1)th word xh+1 having distance at least d from all words x1, . . . , xh,
if this is possible. Indeed, we shall reach a point where we shall have to stop
because there will be no more space for choosing one more word. So we shall
have constructed a code C enjoying the following property: the union of all
spheres Sq(x, d−1) having centre in the points x ∈C coincides with the whole
Fn
q . Otherwise, clearly, we might choose one more word. So for this code we
have
M · Vq(n, d −1) ≥qn;
hence immediately the bound for Aq(n, d) follows.
⊓⊔
In the applications, we are often more interested in asymptotic estimates
of codes’ eﬃciency than in the estimate of the parameters of a single code. For
instance, we want to answer the following question: is it possible to construct
a sequence of codes, each more eﬃcient than the previous one?
A way of measuring the eﬃciency of a code C of type (n, M, d)q is, as
mentioned, the information rate R = (logq M)/n.
Another measure could be the number δ = d/n, which could be called
separation ratio or normalised distance of the code. The larger δ, the abler
the code to correct errors.
Consider now sequences of codes of increasing length and suppose we want
an asymptotic description of the behaviour of their information rate as a
function of the separation ratio, to answer questions such as: by increasing the
separation ratio is it possible, and to what extent, to increase the information
rate?

418
8 Transmitting without. . . fear of errors
Remark 8.4.6. Recall that, given a sequence {xn}n∈N of real numbers, we
may deﬁne two new sequences {an}n∈N and {bn}n∈N as follows:
an = inf{xm}m≥n,
bn = sup{xm}m≥n.
Call limit inferior [resp., limit superior] of {xn}n∈N, and denote by
lim infn→∞xn
[resp.,
lim supn→∞xn],
the
number
sup{an}n∈N
[resp.,
inf{bn}n∈N].
Clearly, lim supn→∞xn = +∞if and only if the sequence {xn}n∈N has no
upper bound (see Exercise A8.17). Moreover, lim supn→∞xn = −∞if and
only if limn→∞xn = −∞(see Exercise A8.18).
If, on the other hand, the sequence has an upper bound and has not as
its limit −∞, then the limit superior exists and is ﬁnite, and it can be shown
(see Exercise A8.19) that in this case the limit superior ξ is characterised by
the following property: for all real number ϵ > 0 there is an integer M ∈N
such that, for all n > M, we have xn < ξ + ϵ. Analogous properties hold for
the limit inferior (see Exercise A8.19). A sequence converges if and only if the
limits inferior and superior coincide.
It is useful to deﬁne the so-called entropy function Hq(t) on the interval
[0, (q −1)/q], such that Hq(0) = 0 and
Hq(t) := t logq(q −1) −t logq t −(1 −t) logq(1 −t)
for 0 < t ≤(q −1)/q.
We may translate Plotkin and Gilbert–Varshamov bounds into bounds for
the limit
α(δ) := lim sup
n→∞
logq Aq(n, d)
n
= lim sup
n→∞
logq Aq(n, nδ)
n
,
which is an asymptotic measure of the information rate.
We have the following lemma; for its proof see Exercise A8.21:
Lemma 8.4.7. For 0 ≤δ ≤(q −1)/q we have
lim
n→∞
logq Vq(n, [δn])
n
= Hq(δ).
(8.9)
Hence immediately follows (see Exercise A8.22):
Theorem 8.4.8 (Asmyptotic Gilbert–Varshamov bound). We have
α(δ) ≥1 −Hq(δ).
In an analogous way (see Exercise A8.23) it is possible to give the asymp-
totic version of the Plotkin bound:

8.5 Linear codes
419
Theorem 8.4.9 (Asmyptotic Plotkin bound). We have
⎧
⎪
⎨
⎪
⎩
α(δ) ≤1 −
qδ
q −1
for 0 ≤δ ≤q −1
q
,
α(δ) = 0
for
q −1
q
≤δ ≤1.
These two estimates leave as possible values of α(δ) the region denoted by
A in Figure 8.1.
8.5 Linear codes
As we have already seen for cryptography, it is very useful, when considering
codes of length n, to use subsets of Fn
q having much algebraic structure. This
makes it greatly easier to perform several operations such as:
•
computing code parameters;
•
coding and transmitting messages;
•
decoding messages;
•
detecting and correcting errors;
•
computing the probability of a correct decoding.
We shall be able to discuss only some of these points. We hope this will
suﬃce to show, once more, the power of algebraic methods and also to rouse
the readers’ curiosity, leading them to further exploration of the subject.
The most natural algebraic structure to be used on Fn
q is that of a vector
space over the ﬁeld Fq. The elements of Fn
q are called numerical vectors of
length n over the ﬁeld Fq, whose elements are called scalars. When we want
@
@
@
@
@
@
@
@
@
@
@
@
O
1
α(δ)
(q −1)/q
δ
A
Plotkin


Gilbert–Varshamov


-
6
Fig. 8.1. Estimates for α(δ)

420
8 Transmitting without. . . fear of errors
to emphasise the vector space structure of Fn
q , we shall often denote its el-
ements, that is to say, the numerical vectors, by boldface symbols, such as
x = (x1, . . . , xn).
A (n, M, d)q–code C is said to be linear if C is a vector subspace of Fn
q ,
that is, if and only if the sum of two words is still a word and the product of
a word by a scalar is still a word of the code. If C has dimension k, we say
that C is a [n, k]q-code. Notice that in this case M = qk, as a vector space
of dimension k over Fq is isomorphic to Fk
q and so has size qk. As to d, we
immediately see that computing it is far easier for linear codes than in the
general case.
First of all, from Singleton bound it follows that:
Proposition 8.5.1. For a [n, k]q-code:
d ≤n −k + 1.
(8.10)
Deﬁnition 8.5.2. A linear code for which in Formula (8.10) the equality holds
is said to be a maximum-distance separable code.
These codes are characterised by the fact that, for any choice of k co-
ordinates, the codewords have on them all possible qk values (see Exercise
A8.7).
Now, for every vector x ∈Fn
q deﬁne the weight w(x) of x as the number
of non-zero coordinates of x. Notice that
d(x, y) = w(x −y)
(8.11)
(see Exercise A8.24). Hence the reader will easily deduce (see Exercise A8.25)
the following result:
Proposition 8.5.3. If C is a linear code, its minimum distance d equals the
minimum weight of its non-zero words.
Basically, for a generic code, ﬁnding the minimum distance implies com-
puting the distance of all pairs of codewords (see Exercise A8.38), while, for
linear codes, the problem is solved by computing the weight of the single
codewords. The computational beneﬁt is obvious.
Another beneﬁt is given by the possibility of describing rapidly the code
and the consequent easier coding of the words, and so their fast transmission.
One of the methods to do so is the following one.
Consider a linear [n, k]q-code and ﬁx a basis x1, . . . , xk of the code, seen
as a vector space over Fq. For all i = 1, . . . , k write
xi = (xi,1, . . . , xi,n)
and consider the k × n matrix X having as its rows the vectors xi, that is,

8.5 Linear codes
421
X =
⎛
⎜
⎜
⎜
⎝
x1,1 x1,2 . . . x1,n
x2,1 x2,2 . . . x2,n
...
...
...
...
xk,1 xk,2 . . . xk,n
⎞
⎟
⎟
⎟
⎠.
A matrix of this kind is called a generating matrix of the code. As the code-
words are linear combinations of the matrix rows, coding works as follows.
Given a word a = (a1, . . . , ak) ∈Fk
q, it is coded mapping it to the word
x = a1x1 + · · · + akxk. On the other hand, this vector is just
x = a · X
with the usual row-by-column multiplication. That is, the ith coordinate of
the product a · X is the scalar product
a1x1,i + · · · + akxk,i
of a by the ith column of X. In conclusion, coding is performed by simple
algebraic operations of product and sum.
Notice that the generating matrix of a linear code is not unique, as a sub-
space has, in general, several bases, and to each basis corresponds a diﬀerent
generating matrix. In particular, it makes sense to choose generating matrices
that are as simple as possible. For instance, a very simple form for a generating
matrix is the so-called standard form, that is
X =
⎛
⎜
⎜
⎜
⎝
1 0 . . . 0 x1,k+1 . . . x1,n
0 1 . . . 0 x2,k+1 . . . x2,n
...
... ... ...
...
...
...
0 0 . . . 1 xk,k+1 . . . xk,n
⎞
⎟
⎟
⎟
⎠.
In a more compact form, this matrix can be written as follows:
X = (Ik | A),
where Ik is the identity matrix of order k, here consisting of the ﬁrst k columns
of X, and A is the remaining matrix. The convenience of such a matrix lies
in the fact that, having codiﬁed the vector a = (a1, . . . , ak), we get a vector
whose ﬁrst k coordinates coincide with those of a. So it is clear that the
redundancy of the code is concentrated exactly in the last n −k coordinates.
Using some linear algebra, it is easy to prove (see Exercise A8.26) the
following result:
Proposition 8.5.4. Given a [n, k]q-code, it is possible, may be up to renaming
some of its coordinates, to ﬁnd a generating matrix in standard form.
On the other hand, a [n, k]q-code can be assigned by giving a k × n gen-
erating matrix for it. The only restriction is for the rank of the matrix to be

422
8 Transmitting without. . . fear of errors
equal to k, that is to say, for the matrix rows to give a basis for the code
and, to this end, it is necessary and suﬃcient that the k rows are linearly
independent, that is, the only linear combination of these vectors giving the
zero vector is the one in which the scalar coeﬃcients are all equal to zero.
Finally, notice that if, instead of a basis of a code C, we took a spanning
set x1, . . . , xh for it, with h ≥k, we would arrive, proceeding as above, to an
h × n matrix having rank k, which may still be viewed as a generating matrix
for C. Basically, the restriction about the rows of the generating matrix having
to be independent is not strictly necessary, even if it is useful to minimise the
algorithmic and data-recording encumbrance.
Example 8.5.5. Consider the linear code C of type [3, 2]3 having as its gen-
erating matrix
X =

2 0 1
1 1 2

.
(8.12)
Clearly, the matrix has rank 2. The words of C are all the vectors of the form
a(2, 0, 1) + b(1, 1, 2), with 0 ≤a, b ≤2, so they are the nine vectors
(2, 0, 1), (1, 1, 2), (0, 0, 0), (1, 0, 2), (2, 2, 1),
(0, 1, 0), (1, 2, 2), (2, 1, 1), (0, 2, 0).
The minimum distance of the code is 1, as this is the minimum weight of the
non-zero elements: for instance, that of (0, 1, 0) and of (0, 2, 0). Unfortunately,
this is not a good code, as it does not correct errors.
A dual way of individuating a code is as follows. Consider a subspace V of
Fn
q and consider the set V ⊥of vectors of Fn
q having zero scalar product with
all vectors of V (see Exercise A8.16). Formally:
V ⊥= { p ∈Fn
q | p × x = 0, for all x ∈V }.
The reader will not miss the analogy with the usual notion of perpendicularity
from elementary geometry. However, the analogy stops with the notation.
Not many usual properties of perpendicularity extend to the situation we are
studying. For instance, it may well happen that a non-zero vector of Fn
q is
orthogonal to iself, as the vector (1, 1) ∈F2
2 does.
In any case, if V has dimension k, then V ⊥is itself a subspace and has
dimension n −k (see Exercise A8.27). In particular, if C is a linear [n, k]q-
code, then C⊥is a linear [n, n −k]q-code, called dual code of C. Moreover,
(C⊥)⊥= C (see again Exercise A8.27).
Consider a generating matrix H of C⊥. It is called parity check matrix for
C. It is a (n−k)×n matrix enjoying the following, easy to verify (see Exercise
A8.28), property:
x ∈C
if and only if
x · Ht = 0,
(8.13)

8.5 Linear codes
423
where 0 is the zero vector of length n −k. Recall that if A is an arbitrary
matrix, At denotes the transpose of A, that is to say, the matrix having as
columns the rows of A. Clearly, the rows of At coincide with the columns of
A.
Notice that, analogously to what happened for the generating matrix, the
parity check matrix of a code is in general not unique.
Example 8.5.6. If C has generating matrix in standard form
X = (Ik | A),
a parity check matrix for C is given by (see Exercise A8.29)
H = (−At | In−k).
A [n, k]q-code may also be assigned by a parity check matrix. In other
words, if we give a (n −k) × n matrix H having rank n −k, we may de-
ﬁne a [n, k]q-code C by the condition (8.13). The reader may verify that the
deﬁnition is meaningful and that C actually has dimension k (see Exercise
A8.30).
Example 8.5.7. With the above remarks in mind, we may now see that our
old friend the Hamming (7, 4) code is a [7, 4]2-code. Keeping in mind the linear
system (8.3), we see that a parity check matrix for this code is
H =
⎛
⎝
1 0 1 1 1 0 0
1 1 0 1 0 1 0
1 1 1 0 0 0 1
⎞
⎠,
which has rank 3.
Knowing a parity check matrix of a linear code is very useful to decode
messages. The method we are about to explain is called syndrome decoding
method.
Assume a [n, k]q-code is given by a parity check matrix H. Given any
vector x ∈Fn
q , we deﬁne its syndrome as the vector x · Ht di Fn−k
q
. The
syndrome is the zero vector only for the words of C.
Let e be any vector of Fn
q . By summing e to each codeword, we get a set
containing e, which we shall denote by e + C and call a coset of C. Notice
that the cosets of C are pairwise disjoint and each of them is bijective to C,
so each contains qk elements and there are qn−k of them (see Exercise A8.33).
Remark further that the vectors in the coset e + C are exactly those having
the syndrome e · Ht (see Exercise A8.34).
From every coset of C we choose a minimum weight element, which will
be called the leader of the coset. Make a list of all leaders and corresponding
syndromes, which are all possible syndromes of elements of Fn
q . If we receive
a message and we discern in it a word x having non-zero syndrome, we realise

424
8 Transmitting without. . . fear of errors
that an error has occurred. Looking at the leader table, we ﬁnd the leader
ℓhaving the same syndrome as x and decode x by subtracting from it the
leader. So we obtain an element y = x −ℓhaving zero syndrome, and so an
element of the code. Moreover, by the deﬁnition itself of a leader as an element
having minimum weight in its coset, y is an element of C having minimum
Hamming distance from x. So the decoding is carried out adhering to the
maximum likelihood principle.
Example 8.5.8. Consider the [4, 2]3-code having as its parity check matrix
H =

1 1 0 2
0 2 1 2

.
The reader will easily verify (see Exercise B8.27) that the nine leaders and
the corresponding syndromes are
leaders
(0, 0, 0, 0)
(1, 0, 0, 0)
(2, 0, 0, 0)
(0, 1, 0, 0)
(0, 2, 0, 0)
syndromes
(0, 0)
(1, 0)
(2, 0)
(1, 2)
(2, 1)
leaders
(0, 0, 1, 0)
(0, 0, 2, 0)
(0, 0, 0, 1)
(0, 0, 0, 2)
syndromes
(0, 1)
(0, 2)
(2, 2)
(1, 1)
If we receive (2, 1, 2, 1) we observe that its syndrome is (2, 0). The correspond-
ing leader is (2, 0, 0, 0), so we decode (2, 1, 2, 1) as (2, 1, 2, 1) −(2, 0, 0, 0) =
(0, 1, 2, 1). The reader should verify that in each coset of C diﬀerent from C
there is a single leader and that this leader has weight 1. This implies that, if
there is a single transmission error, the syndrome decoding correctly removes
it.
We conclude this section by showing how it is possible to compute the
minimum distance of a code from its parity check matrix.
Theorem 8.5.9. The minimum distance d of a [n, k]q−code having parity
check matrix H is the minimum size of a linearly dependent set of columns of
matrix H.
Proof. Let h1, . . . , hn be the columns of H and let x = (x1, . . . , xn) be a
non-zero word of C. We have x1h1 +· · ·+xnhn = 0, that is x ∈C determines
a non-trivial linear dependency relation among the columns of H and vice
versa. The weight of x, on the other hand, determines the number of columns
of H involved in this relation. From this and from Proposition 8.5.3 the claim
immediately follows.
⊓⊔
Example 8.5.10. Considering again Example 8.5.8, we may see that every
pair of columns of the matrix H consists of independent columns. So d = 3
and the code, as already seen, corrects one error. Moreover, it is maximum-
distance separable, that is, d = n −k + 1 (see page 420).

8.6 Cyclic codes
425
8.6 Cyclic codes
In this section we shall discuss a class of codes which are very interesting,
due to their rich algebraic structure. They are the cyclic codes, that is to say,
the codes that, whenever a word belongs to them, all its cyclic permutations
belong to the code. Let us ﬁx notation and deﬁnitions necessary to introduce
these codes.
Recall the notion of a permutation of the set In = {1, . . . , n} consisting of
the ﬁrst n natural numbers (see Exercise A1.11). Consider the permutation γ
such that
(γ(1), γ(2), . . . , γ(n)) = (n, 1, 2, . . ., n −1).
Following the notation introduced in Exercise A1.11, we shall say that γ has
symbol (n, 1, 2, . . . , n −1). Notice that, for all j = 0, . . . , n −1, the symbol of
γj is
(n −j + 1, . . . , n, 1, 2, . . ., n −j),
while γn is the identical permutation. So, γ generates a cyclic subgroup of
order n of the group Sn of permutations of In. By this reason, γ is called a
cyclic permutation on the elements of In.
Notice now that, if f is a permutation of Sn having symbol (i1, . . . , in),
we may deﬁne the mapping
ωf : (x1, . . . , xn) ∈Fn
q →(xi1, . . . , xin) ∈Fn
q ,
which clearly is an isomorphism of Fn
q in itself (see Exercise A8.35). In par-
ticular,
ωγ : (x1, . . . , xn) ∈Fn
q →(xn, x1, x2, . . . , xn−1) ∈Fn
q
generates a cyclic group Γ(n, q) of order n of isomorphisms of Fn
q in itself (see
again Exercise A8.35). For the sake of notational simplicity, we shall denote
the linear mapping ωγ again by γ.
Now we may give the deﬁnition of a cyclic code.
Deﬁnition 8.6.1. A linear code C of type [n, k]q is said to be cyclic if C is
stable under the action of Γ(n, q), that is to say, if for every word x ∈C we
have γ(x) ∈C.
Example 8.6.2. Given an element a = (a1, . . . , an) ∈Fn
q , the vector space
generated by the elements γi(a), for i = 0, . . . , n−1, is an example of a cyclic
code, called cyclic code generated by the element a (see Exercise A8.44).
We are now going to discuss an eﬃcient way to describe cyclic codes using
polynomials. It relies on an Fq-vector space isomorphism between Fn
q and the
quotient ring Fq[x]/(xn −1). With an abuse of notation, we shall denote a
polynomial p(x) ∈Fq[x] and its class in Fq[x]/(xn −1) with the same symbol.
In particular, xn = 1 in Fq[x]/(xn −1).
So we have the following proposition, whose easy proof is left as an exercise
for the reader (see Exercise A8.45):

426
8 Transmitting without. . . fear of errors
Proposition 8.6.3. Let f : Fn
q −→Fq[x]/(xn −1) be the mapping deﬁned as
follows: for all a = (a0, . . . , an−1) ∈Fn
q , we have f(a) = a0 + a1x + · · · +
an−1xn−1. Then:
•
f is a vector space isomorphism;
•
f(γ(a)) = x · f(a).
Proposition 8.6.3 allows us to identify Fn
q with Fq[x]/(xn −1) as vector
spaces, so we may equally consider the element (a0, a1, . . . , an−1) in Fn
q or the
polynomial a0 + a1x + · · · + an−1xn−1 in Fq[x]/(xn −1).
Remark 8.6.4. The proposition shows that cyclic codes may be identiﬁed
with vector subspaces of Fq[x]/(xn −1) that are stable under multiplication
by x, and so also under multiplication by any polynomial g(x) ∈F[x]. This
is the same as saying that cyclic codes are exactly the ideals of the ring
Fq[x]/(xn−1), and correspond to the ideals of Fq[x] containing the polynomial
xn −1 (see Exercise A3.10).
As Fq[x] is a principal ideal ring (see § 1.3.6), every ideal has a generator
a(x), which is the monic polynomial having least degree in the ideal. Moreover,
the ideal contains xn−1 if and only if a(x) divides xn−1. In conclusion, cyclic
codes are in bijection with monic divisors a(x) of the polynomial xn −1 in
Fq[x]. The polynomial a(x) is said to be a generator of the corresponding
code.
Assume xn −1 = a(x) · b(x), with monic a(x), b(x). Let h be the degree of
a(x), so n −h = k is the degree of b(x). Modulo xn −1, we have the relation
a(x)·b(x) = 0, so a(x), xa(x), . . . , xka(x) are linearly dependent in Fq[x]/(xn−
1), while clearly a(x), xa(x), . . . , xk−1a(x) are not. Thus, the dimension of the
cyclic code corresponding to the monic divisor a(x) of xn −1 is k = n −h,
where h is the degree of a(x) and a(x), xa(x), . . . , xk−1a(x) form a basis.
The following proposition sums up and completes what we have been say-
ing and characterises the cyclic codes C of type [n, k]q.
Proposition 8.6.5. Let a(x) = a0+a1x+· · ·+an−kxn−k, with an−k = 1, be a
polynomial in Fq[x] that divides xn −1, and let a = (a0, a1, . . . , an−k, 0, . . . , 0)
be the corresponding word in Fn
q . Then the k words a, γ(a), . . . , γk−1(a) give
a basis for a cyclic code C of type [n, k]q. Vice versa, all cyclic codes of length
n over Fq can be obtained in this way.
Now it is clear why it is interesting to ﬁnd the divisors of xn −1 in Fq[x], a
problem we have already encountered, under diﬀerent guises (see for example
§ 5.1.8 and § 6.3). Without too many details, assume that GCD(n, q) = 1 and
let xn −1 = p1(x) · · · ps(x) be the decomposition of xn −1 into irreducible,
monic factors in Fq[x]. These polynomials are all distinct by the hypothesis
GCD(n, q) = 1 (see Proposition 5.1.16 or Exercise A5.18). The divisors of xn−
1 may be obtained by taking in all possible ways a subset of {p1(x), . . . , ps(x)}

8.6 Cyclic codes
427
and multiplying its elements. Thus, these divisors are in bijection with the
power set of {p1(x), . . . , ps(x)}, so there are 2s of them (see Exercise A1.22).
Let a(x) = n−k
i=0 aixi be the monic polynomial generator of a code C
of length n. If a(x) has degree n −k, we have seen that the words a(x),
xa(x), . . . , xk−1a(x) form a base for C, that is, C is a [n, k]-code. So the
matrix
G =
⎛
⎜
⎜
⎜
⎜
⎜
⎝
a0 a1 · · · an−k
0
0
· · ·
0
0
a0 a1
· · ·
an−k
0
· · ·
0
0
0
a0
a1
· · ·
an−k · · ·
0
0
0
0
...
...
...
...
0
0
0
0
0
a0
a1
· · · an−k
⎞
⎟
⎟
⎟
⎟
⎟
⎠
is a generating matrix for C. As we have seen, we may use it to encode
information as follows: if c = (c0, c1, . . . , ck−1) is the word we have to transmit,
we may encode it by the product of matrices c · G, which corresponds to the
polynomial
c(x) = (c0 + c1x + c2x2 + · · · + ck−1xk−1)a(x)
modulo xn −1.
Let again xn −1 = a(x) · b(x), with b(x) = k
i=0 bixi a monic polyno-
mial. The polynomial b(x) is called check polynomial of the code C. From the
above we deduce that the code C consists exactly of all polynomials c(x) in
Fq[x]/(xn −1) such that c(x)b(x) = 0 modulo xn −1 (see Exercise A8.46).
The reason for the name of b(x) comes from the following remark. From
xn −1 = a(x) · b(x), we may deduce that

r+s=i
arbs = 0,
for i = 1, . . . , n −1.
So the matrix
H =
⎛
⎜
⎜
⎜
⎜
⎜
⎝
0
. . .
0
0
bk
bk−1 . . . b0
0
. . .
0
bk
bk−1
. . .
b0
0
0
. . .
bk bk−1
. . .
b0
0
0
0
...
...
...
...
...
...
0
bk bk−1 . . .
b0
0
0
. . . 0
⎞
⎟
⎟
⎟
⎟
⎟
⎠
is a parity check matrix for code C.
In conclusion, it is clear that the codes determined by a(x) and b(x) are
dual each other.
Example 8.6.6. Determine all binary cyclic codes of length 7.
We have to factor the polynomial x7 −1 over Z2. We ﬁnd
x7 −1 = (x −1)(x3 + x + 1)(x3 + x2 + 1).

428
8 Transmitting without. . . fear of errors
The third degree polynomials are irreducible because they have no roots in
Z2. So there are 23 = 8 cyclic codes of length 7 over Z2, and the generating
polynomials are
1,
x + 1,
x3 + x + 1,
x3 + x2 + 1,
(x + 1)(x3 + x + 1) = x4 + x3 + x2 + 1,
(x + 1)(x3 + x2 + 1) = x4 + x2 + x + 1,
(x3 + x + 1)(x3 + x2 + 1) = x6 + x5 + x4 + x3 + x2 + x + 1,
x7 −1.
The corresponding codes are:
Generating polynomial
Corresponding code
(1) 1
F7
2,
(2) x + 1
called parity check code,
(3) x3 + x + 1
Hamming code,
(4) x3 + x2 + 1
Hamming code,
(5) x4 + x3 + x2 + 1
dual code of Hamming code,
(6) x4 + x2 + x + 1
dual code of Hamming code,
(7) x6 + x5 + x4 + x3 + x2 + x + 1
called repetition code,
(8) x7 −1
zero code.
In case (2), the parity check matrix is the vector (1, 1, 1, 1, 1, 1, 1). So x =
(x1, . . . , x7) belongs to the code if and only if x1 + · · · + x7 = 0 in Z2, that is,
if and only if x1 + · · · + x7 is even; whence the name of the code.
Dually, in case (7), the generating matrix is (1, 1, 1, 1, 1, 1, 1). So the code
consists of the words x = (x1, . . . , x7) ∈F7
2 such that x1 = x2 = x3 = x4 =
x5 = x6 = x7. Hence the code consists of the two 7-tuples (0, 0, 0, 0, 0, 0, 0)
and (1, 1, 1, 1, 1, 1, 1). This justiﬁes the name of this code (compare it with the
code used by the Australian coin tosser in § 8.2).
In case (4), the parity check matrix is
H =
⎛
⎝
0 0 1 1 1 0 1
0 1 1 1 0 1 0
1 1 1 0 1 0 0
⎞
⎠.
It may be immediately veriﬁed that, by changing names to the coordinates,
it coincides with the parity check matrix of the Hamming code (see Example
8.5.7). An analogous reasoning holds for case (3) (see Exercise A8.47).
An interesting class of codes is that of the so-called BCH codes, from the initials
of their inventors R. C. Bose, D. K. Ray–Chaudhuri and A. Hocquenghem (1959–60).

8.7 Goppa codes
429
Deﬁnition 8.6.7. A cyclic code of length n over Fq is called BCH code with as-
signed distance δ if, denoting by a(x) its generator and by β an nth primitive root
of unity, we have
a(x) = l.c.m. of the minimal polynomials of βl, βl+1, . . . , βl+δ−2 for some l.
In what follows we shall take n = qm −1, so β is a generator of Fqm (see § 5.1.4
and Corollary 5.1.31). Then β and its powers may be regarded as numerical vectors
of length m over Fq. Moreover, we shall assume l + δ −2 < n.
Why are these codes called with assigned distance? The answer comes from the
following result.
Proposition 8.6.8. The minimum distance of a BCH code with assigned distance
δ over Fq, with n = qm −1, is greater or equal than δ.
Proof. Consider the matrix
H :=
⎛
⎜
⎜
⎜
⎝
1
βl
β2l
. . .
β(n−1)l
1
βl+1
β2(l+1)
. . .
β(n−1)(l+1)
...
...
...
. . .
...
1 βl+δ−2 β2(l+δ−2) . . . β(n−1)(l+δ−2)
⎞
⎟
⎟
⎟
⎠.
Considering every entry of the matrix as a column vector with m components over
Fq, the matrix H can be thought of as a m(δ −1) × n matrix. A word c belongs to
the BCH code if and only if c · Ht = 0. So H is a parity check matrix of the code.
The ﬁrst δ −1 columns of H are linearly independent, as the corresponding
determinant is the Vandermonde determinant V (βl, βl+1, . . . , βl+δ−2) (see Exercise
A4.64). On the other hand, every other (δ −1)-tuple of columns is linearly indepen-
dent because the corresponding determinant is the product of a power of β by an
analogous Vandermonde determinant. The claim follows from Theorem 8.5.9.
⊓⊔
We shall not dwell further on these codes. Suﬃce it to remark that the reasoning
relying on Vandermonde determinants that led us to conclude that every BCH code
of length n = qm −1 and assigned distance δ over Fq has minimum distance at least
δ, also holds for codes with parity check matrices of the form
H′ :=
⎛
⎜
⎜
⎜
⎝
h0
h1
. . .
hn−1
h0β0
h1β1
. . . hn−1βn−1
...
...
. . .
...
h0βδ−1
0
h1βδ−1
1
. . . hn−1βδ−1
n−1
⎞
⎟
⎟
⎟
⎠,
where the his and the βjs are distinct elements of F∗
qm. In fact, the codes we are
going to discuss in next section, called Goppa codes, are exactly of this kind.
8.7 Goppa codes
The world of linear codes is very heterogeneous and interesting, and it would
be both pleasant and useful to explore it, armed with the algebraic equipment

430
8 Transmitting without. . . fear of errors
we have built up so far. The reader could appreciate how many algebraic no-
tions expounded so far are put to use in this setting. Moreover, there are very
simple linear codes, used since the 1950’s or the 1960’s, which are unbelievably
eﬃcient, just like the Hamming (7, 4) code, and still used in many applica-
tions. However, we have already covered together a very long path and, for
the sake of brevity, we cannot explore more together: we encourage the most
curious readers to browse the references we gave so far. However, we want to
give one last example, Goppa codes. The reason why we want to discuss them
before bringing this chapter to an end is that they pave the way for the use
of ideas and techniques from algebraic geometry in coding theory, as we shall
mention at the end of this section. As we have already seen, this is what has
already happened in the most recent advances in cryptography.
In order to deﬁne a Goppa code, we need some preliminary remarks. Con-
sider the polynomial ring over a ﬁeld K and ﬁx an element γ of the ﬁeld and a
polynomial f(x) ∈K[x] of degree t > 0 such that f(γ) ̸= 0, and so such that
GCD(x −γ, f(x)) = 1. Then there exists a unique polynomial g(x) ∈K[x] of
degree smaller than t, given by
g(x) = f(γ) −f(x)
f(γ) · (x −γ),
(8.14)
such that
(x −γ) · g(x) ≡1
(mod f(x)),
(8.15)
that is, such that (x −γ) · g(x) −1 is divisible by f(x) (see Exercise A1.54).
As usual, with a slight abuse of notation, we shall identify a polynomial with
its class in K[x]/(f(x)). We may say that g(x) is the multiplicative inverse of
x −γ in K[x]/(f(x)). So 1/(x −γ) is not a polynomial, but we consider it as
such modulo f(x), that, is, in the ring K[x]/(f(x)). Thus from now on we shall
consider the symbol 1/(x −γ) as meaningful, when we shall work modulo a
polynomial that has not γ as a root.
Example 8.7.1. If f(x) = x and if γ ̸= 0 then the polynomial g(x) of (8.14)
is given by −1/γ, or
1
x −γ ≡−1
γ
(mod x).
This is obvious, as x = 0 (mod x).
This said, we may deﬁne Goppa codes:
Deﬁnition 8.7.2. Let Fq be a ﬁnite ﬁeld, let m be a positive integer and f(x)
a monic polynomial of degree t > 0 over Fqm. Let further L = {γ1, . . . , γn} be
a set of n distinct elements of Fqm such that f(γh) ̸= 0, for h = 1, . . . , n. The
Goppa code C(L, f(x))q,m is the subset of n-tuples (c1, . . . , cn) of elements of
Fq such that
n

i=1
ci
x −γi
≡0
(mod f(x)).
(8.16)
Notice that a Goppa code is linear (see Exercise A8.48).

8.7 Goppa codes
431
Example 8.7.3. If f(x) = x and L = Fqm \ {0}, that is n = qm −1, then
by Example 8.7.1, C(L, x)q,m is the [qm −1, qm −2]q-code with parity check
matrix the vector having as entries the non-zero elements of Fq. By applying
Theorem 8.5.9 we see that it has minimum distance d = 2.
Example 8.7.4. Consider a ﬁnite ﬁeld Fq and let β be an nth primitive root of unity,
with n = qm −1, that is, β is a generator of Fqm. Consider the polynomial f(x) =
xδ−1 and let L = Fqm \ {0} = {β−i, 0 ≤i ≤n −1}. The Goppa code C(L, xδ−1)q,m
coincides with the BCH code corresponding to the case l = 1 considered in the
previous section.
To verify this, proceed as follows. First of all, notice the polynomial identity (see
Exercise A8.49):
xn −1 = (x −β−i) ·
n−1

k=0
(β−i)n−k−1xk = (x −β−i) ·
n−1

k=0
βi(k+1)xk,
(8.17)
Next, keep in mind (see the proof of Proposition 8.6.8) that the word (c0, . . . ,
cn−1) belongs to the BCH code corresponding to the case l = 1 if and only if
c0 + c1 · βj + c2 · β2j + · · · + cn−1 · β(n−1)j = 0,
for all 1 ≤j < δ.
Notice that by (8.17) we have
xn −1
x −β−i =
n−1

k=0
βi(k+1)xk;
hence,
(xn −1) ·
n−1

k=0
ci
x −β−i =
n−1

k=0
xk
n−1

k=0
ciβi(k+1),
(8.18)
so it follows that the word (c0, . . . , cn−1) belongs to the BCH code if and only if
the polynomial appearing in the right-hand side of (8.18) is divisible by xδ−1. In
conclusion, (c0, . . . , cn−1) belongs to the BCH code if and only if n−1
k=0 ci/(x −β−i)
is zero modulo xδ−1, that is, if and only if the word (c0, . . . , cn−1) belongs to the
code C(L, xδ−1)q,m.
Let us now determine a parity check matrix for a Goppa code
C(L, f(x))q,m.
Keeping in mind Equation (8.16), which determines the codewords, we
might be tempted to say that the matrix

1
x −γ1
1
x −γ2
· · ·
1
x −γn

(8.19)
is the parity check matrix of C(L, f(x))q,m, were it not the case that this
is not a matrix of constants, but of polynomials and what’s more not even
polynomials over Fq but over the larger ﬁeld Fqm or, rather, over a quotient
ring of Fqm[x]. It is only in special cases, as the one discussed in Example

432
8 Transmitting without. . . fear of errors
8.7.3, that it is a matrix of constants. But from (8.19) we may get an actual
parity check matrix.
Recall that we are taking everything modulo f(x) and that, for i =
1, . . . , n, we have
1
x −γi
=
f(γi) −f(x)
f(γi) · (x −γi).
Setting
f(x) =
t

i=0
fixi,
the following polynomial identity is easily veriﬁed (see Exercise A8.50):
f(x) −f(y) = (x −y) ·

0≤h+k≤t−1
fh+k+1xhyk;
(8.20)
it may be rewritten as
f(x) −f(y)
x −y
=

0≤h+k≤t−1
fh+k+1xhyk.
Set now gi = 1/f(γi), i = 1, . . . , n, hence we may write
1
x −γi
= −gi ·

0≤h+k≤t−1
fh+k+1xhγk.
So the necessary and suﬃcient condition for a word c = (c1, . . . , cn) to belong
to the code C(L, f(x))q,m, that is, the orthogonality of c to the vector (8.19),
is translated into the orthogonality condition of c to the matrix
K =
⎛
⎜
⎜
⎜
⎝
g1ft
. . .
gnft
g1(ft−1 + ftγ1)
. . .
gn(ft−1 + ftγn)
...
. . .
...
g1(f1 + f2γ1 + · · · + ftγt−1
1
) . . . gn(f1 + f2γn + · · · + ftγt−1
n
)
⎞
⎟
⎟
⎟
⎠,
that is,
c · Kt = 0,
so K is a parity check matrix for the code C(L, f(x))q,m. On the other hand,
keeping in mind Exercise A8.32, we deduce that another parity check matrix
of C(L, f(x))q,m, having a simpler form, is given by
H =
⎛
⎜
⎜
⎜
⎝
g1
. . .
gn
g1γ1
. . .
gnγn
...
...
...
g1γt−1
1
. . . gnγt−1
n
⎞
⎟
⎟
⎟
⎠.
(8.21)

8.7 Goppa codes
433
Beware! We are somewhat cheating, here. In fact, stricly speaking H is not
yet a parity check matrix, as its elements are not constants, that is, elements
of Fq. Indeed, as f(x) is a polynomial with coeﬃcients in Fqm, the elements
of H, for instance g1, . . . , gn, belong to Fqm rather than to Fq. But this is
easily ﬁxed, in a way analogous to what has been done for BCH codes in the
previous section. Indeed, it suﬃces to keep in mind that Fqm is a vector space
of dimension m over Fq, so its elements can been regarded as column vectors
of length m over Fq. Thus, we are considering the elements of H as columns
of m elements of Fq. So H, as a matrix over Fq, becomes a mt × n matrix,
rather than a t × n one. Of course, the rows of this matrix are not necessarily
independent: we might have to remove some to make H an actual parity check
matrix in the sense of the previous section (see Exercise A8.31).
A ﬁrst conclusion to be drawn from this analysis is the following proposi-
tion:
Proposition 8.7.5. A Goppa code C(L, f(x))q,m with L of size n and f(x)
of degree t is a [n, k]q-code, with k ≥n −mt.
What can be said about the minimum distance of a Goppa code? This
question can be given only a partial answer. Indeed, we have the following
proposition, whose proof can be left as an exercise to the reader (see Exercise
A8.51), who might want to argue in a similar as for BCH codes, using Theo-
rem 8.5.9 and the properties of Vandermonde determinants. Here we provide
instead a diﬀerent proof, which will enable us to give an interesting extension.
Proposition 8.7.6. A Goppa code C(L, f(x))q,m with f(x) of degree t has
minimum distance d ≥t + 1.
Proof. Identify c = (c1, . . . , cn) ∈Fn
q with the rational function
φ(x) =
n

i=0
ci
x −γi
,
which is an element of the ﬁeld of fractions of Fp[x].
We may write φ(x) = n(x)/d(x), where d(x) = (x −γ1)ϵ1 · · · (x −γn)ϵn,
where ϵi = 0 if ci = 0, while ϵi = 1 if ci ̸= 0, for all i = 1, . . . , n. So the degree
of d(x) equals the weight w(c). Moreover, n(x) is a polynomial of degree
smaller than that of d(x) and GCD(n(x), d(x)) = 1.
On the other hand, c belongs to the code if and only if φ(x) ≡0
(mod f(x)), that is, if and only if f(x) divides n(x). In this case, ∂(n(x)) ≥t,
so ∂(d(x)) ≥t + 1. But as ∂(d(x)) = w(c), the claim follows from Proposition
8.5.3.
⊓⊔
The previous proof suggests that, under particular conditions, it is possible
to improve the estimate on the minimum distance. For instance, we have:
Proposition 8.7.7. A Goppa code C(L, f(x))2,m with f(x) of degree t with-
out multiple roots has minimum distance d ≥2t + 1, so it corrects t errors.

434
8 Transmitting without. . . fear of errors
Proof. Consider a word c = (c1, . . . , cn) of the Goppa code C(L, f(x))2,m.
Setting
g(x) = (x −γ1)c1 · (x −γ2)c2 · · · · · (x −γn)cn,
we have
φ(x) =
n

i=1
ci
x −γi
= g′(x)
g(x) ,
(8.22)
where g′(x) is the derivative of g(x) (see Exercise A8.52). Moreover, GCD(g(x),
g′(x)) = 1 as g(x) has no multiple roots.
Notice that, as we are working in characteristic 2, in g′(x) only powers of
x with even exponent appear, that is, g′(x) is a perfect square.
On the other hand, as f(x) divides φ(x), then f(x) divides g′(x). But in
this case, as g′(x) is a perfect square and f(x) as no multiple roots, g′(x) is
divisible by f(x)2 too. So reasoning as in the proof of Proposition 8.7.6, we
conclude that the degree of the denominator of φ(x), that is, the weight of c,
is at least 2t + 1.
⊓⊔
The previous propositions make it plain that Goppa codes have good sep-
aration characteristics and so good error-correcting capabilities.
Now, to conclude, we shall see that Goppa codes are eﬃcient in other ways
too. Indeed, the following result holds:
Theorem 8.7.8. There is a sequence of Goppa codes in which the information
rate tends to the Gilbert–Varshamov bound.
Proof. Choose the parameters n = qm, t and d, and try to determine a
Goppa code C(L, f(x))q,m having these parameters. As n = qm, the choice of
L is forced: we have to take L = Fqm. Try next to ﬁnd a monic polynomial
f(x) ∈Fqm[x], irreducible over Fqm, of degree t. In this case f(x) has no roots
in Fqm, so we have f(c) ̸= 0 for all c ∈L = Fqm.
Finally, we want the code C(L, f(x))q,m to have minimum distance at least
equal to d. For this to happen, we must exclude all polynomials f(x) of degree t
such that there is a word c = (c1, . . . , cn) ∈C(L, f(x))q,m with w(c) = w < d.
Let us give an estimate for the number ν(t, d) of such polynomials.
In order to do so, let c = (c1, . . . , cn) be an element of Fn
q of weight
w(c) = w < d. Notice that the number of such elements is
μw =
n
w

(q −1)w
(see the solution of Exercise A8.8). As we have seen, w(c) = w means that
the numerator n(x) of φ(x) = n
i=0 γi/(x −ci) has degree at most w −1.
Recall that n(x) must be divisible by f(x) for c to be in C(L, f(x))q,m. Thus,
f(x) can be chosen in at most ⌊(w −1)/t⌋ways for c to be in the code. In
conclusion, we have the following estimate for ν(t, d):

8.7 Goppa codes
435
ν(t, d) ≤
d−1

w=1
-w −1
t
.
μw =
d−1

w=1
-w −1
t
. n
w

(q −1)w.
Keeping in mind formula (8.6) on page 415, we ﬁnd that
ν(t, d) ≤d
t Vq(n, d −1).
We use now the estimate for the number nt,qm of monic irreducible poly-
nomials of degree t found in Exercise A5.33, that is,
nt,qm > qmt
t

1 −q−mt/2+m 
.
So, in conclusion, a suﬃcient condition for the existence of our code
C(L, f(x))q,m, that is, of the polynomial f(x), is
d Vq(n, d −1) ≤qmt 
1 −q−mt/2+m 
.
Take the logarithms in base q of both sides of the previous inequality,
divide by n and take the limit for n →∞, so that the separation ratio d/n
tends to a number δ. This may be done because we may choose n and d
arbitrarily. Then, keeping in mind formula (8.9) on page 418, we ﬁnd that for
our Goppa codes to exist it suﬃces that
Hq(δ) + O(1) ≤mt
n + O(1).
(8.23)
Having ﬁxed δ, it is clear that this relation can be satisﬁed by some t, so there
are inﬁnitely many codes verifying the properties necessary for n →∞. By
Proposition 8.7.5, a code obtained in this way has dimension at least n −mt.
The most unlucky situation is when this dimension is the lowest possible one,
that is n −mt. In this case, the information rate is R = 1 −mt/n. To make
this ratio as large as possible, we shall have to take t minimal under the
condition (8.23). So, for n →∞, we have that mt/n tends to Hq(δ) and so
the information rate tends to 1 −Hq(δ). Keeping in mind Theorem 8.4.8, this
concludes the proof.
⊓⊔
Notice that, by Equation (8.23), which gives a suﬃcient condition to con-
struct an inﬁnite sequence of Goppa codes with a given separation ratio δ,
these codes have, at least asymptotically, an information rate that cannot
exceed the Gilbert–Varshamov bound 1 −Hp(δ), but tends to it from below.
To construct sequences of Goppa codes with a given separation ratio δ
for which the information rate tends to a number greater than the Gilbert–
Varshamov bound 1 −Hp(δ), one may use analogous but more complex con-
structions. Here algebraic curves make their appearance, as in cryptography.
The starting point is given by the following remark.

436
8 Transmitting without. . . fear of errors
The classical Goppa codes considered so far use rational functions over a
ﬁnite ﬁeld F. Considered geometrically, F may be regarded as a line of the
numerical aﬃne plane F2, for instance the x-axis having equation y = 0 (see
the remarks in § 7.9.2).
Now we may take a step forward: we may use algebraic curves in F2, deﬁned
by equations of the form f(x, y) = 0 with f(x, y) ∈F[x, y]. If we consider
such a curve Γ rather than the line y = 0, by using suitable rational functions
deﬁned on it we may construct natural extensions of the classical Goppa codes.
The only restriction for everything to work well is that Γ has many rational
points, that is, that there are many points (a, b) ∈F2 verifying the equation
f(x, y) = 0. This condition is obviously veriﬁed for the equation y = 0 deﬁning
F. Now, by using these generalised, or as they are usually called, geometric
Goppa codes, for suitable algebraic curves with many rational points, one may
improve Theorem 8.7.8. One proves indeed the following result, due to three
Russian mathematicians, M. A. Tsfaman, S. G. Vladut and T. Zink (see [60]),
which will be only stated here:
Theorem 8.7.9. There is a sequence of geometric Goppa codes over Fp2, for
p ≥7, such that the information rate tends to a number greater than the
Gilbert–Varshamov bound.
Appendix to Chapter 8
A8 Theoretical exercises
A8.1.* Prove that the error probability of a repetition binary code repeated n times
is
Pn =

0≤i<⌊n/2⌋

n
i

pn−i(1 −p)i,
where p is the probability of an error along the transmission channel. Verify that
0 < Pn < 1 and prove that Pn tends to 0 as n approaches inﬁnity.
A8.2. Prove that a word of the Hamming (7, 4) code is a solution of the linear
system (8.3) on page 410, and vice versa (see formula (8.2)).
A8.3. Prove that two distinct words of the Hamming (7, 4) code diﬀer in at least
three coordinates.
A8.4.* Prove the three properties of the Hamming distance d(x, x′) between two
words x, x′ of a code (see Deﬁnition 8.3.2 on page 412).
A8.5.* Prove Theorem 8.3.4 on page 412.
A8.6. Prove formula (8.4) in Remark 8.3.5 on page 413.
A8.7. Prove that for a code of type (n, M, d)q equality holds in Singleton bound if
and only if, for every choice of n−d+1 coordinates, the codewords assume on them
all possible values.

A8 Theoretical exercises
437
A8.8.* Prove formula (8.6) on page 415.
A8.9. Let C be a code of type (n, M, d)q. Prove that n ≥d and that if q = 2 and
d = n then M = 2.
In the following Exercises A8.10–A8.13 we sketch the proof of Proposition 8.4.3.
A8.10. Verify that, for a binary code, Singleton bound is better than Hamming
bound if and only if k
i=1
n
i
	
< 2d−1, where k = ⌊(d −1)/2⌋.
A8.11.* Verify that, if d is odd, we have k
i=1
n
i
	
= 2d−1.
A8.12. Verify that, if d is even, the inequality k
i=1
n
i
	
< 2d−1 holds: (i) if d = 2,
for all n; (ii) if d = 4, only for n = 4, 5, 6; (iii) if d = 6, only for n = 6, 7; (iv) if
d = 8, 10, only for n = d.
A8.13.* Complete the proof of part (iv) of Proposition 8.4.3.
A8.14. Prove that the Hamming (7, 4) code is a perfect code.
A8.15. Prove that the ordered pairs of distinct elements of a set consisting of M
elements are exactly M(M −1). Hint: recall Exercise A1.17.
A8.16.* Prove Cauchy–Schwarz inequality: given x = (x1, . . . , xn) and y =
(y1, . . . , yn) in Rn, we have
(x × x) · (y × y) ≥(x × y)2,
(8.24)
where x × y denotes the usual euclidean scalar product
x × y =
n

i=1
x1y1 + · · · + xnyn.
Moreover, in (8.24) equality holds if and only if x and y are linearly dependent.
A8.17. Prove that the limit superior [respectively, the limit inferior] of a sequence
is +∞[resp., −∞] if and only if the sequence is not bounded above [resp., below].
A8.18. Prove that the limit superior [respectively, the limit inferior] of a sequence
is −∞[resp., +∞] if and only if the sequence has limit −∞[resp., +∞].
A8.19.* Prove that, if {xn}n∈N is bounded above [resp., below] and has not inﬁnite
limit, then its limit superior ξ [resp., inferior η] exists and is ﬁnite and is characterised
by the property that for all real number ϵ > 0 there is an M ∈N such that for all
n > M we have xn ≤ξ + ϵ [resp., η −ϵ ≤xn]. Deduce that a sequence has limit if
and only if the limits inferior and superior coincide.
A8.20.* Prove Stirling formula: log n! = n log n −n + O(log n).
A8.21.* Prove Lemma 8.4.7.
A8.22.* Prove the asymptotic Gilbert–Varshamov bound (see Theorem 8.4.8).
A8.23.* Prove the asymptotic Plotkin bound of Theorem 8.4.9.
A8.24. Prove formula (8.11) on page 420.

438
8 Transmitting without. . . fear of errors
A8.25. Prove Proposition 8.5.3 on page 420.
A8.26.* Prove Proposition 8.5.4 on page 421.
A8.27. Prove that if V is a vector subspace of Fn
q , then V ⊥is too. Moreover, if V
has dimension k, then V ⊥has dimension n −k. Finally, prve that (V ⊥)⊥= V .
A8.28. Prove formula (8.13) on page 422.
A8.29. Prove the claim in Example 8.5.6 on page 423.
A8.30. Prove that an (n−k)× n matrix H of rank n−k deﬁnes, by formula (8.13),
a code C of type [n, k]q.
A8.31. Prove that it is not necessary for the rows of a parity check matrix to be
linearly independent.
A8.32. Prove that, acting on the rows of a generating matrix [resp., of a parity check
matrix] of a code C by elementary operations, which consist in: (1) exchanging two
rows; (2) multiplying a row by a non-zero scalar; (3) add to a row a multiple of
another row; we get again a generating matrix [resp., a parity check matrix] for the
same code.
A8.33. Prove that a [n, k]q-code C has qn−k cosets (see page 423), and each coset
e + C of C contains exactly qk elements.
A8.34. Consider a [n, k]q-code C with parity check matrix H. Prove that the vectors
in the coset e + C are all the vectors having the same syndrome e · Ht. Show by an
example that the syndrome may change if the parity check matrix H is modiﬁed.
A8.35. Prove that, if f is a permutation in Sn, the mapping ωf deﬁned on page
425 is linear and bijective. Let GL(n, q) be the group of isomorphisms of Fn
q in
itself. Prove that the mapping f ∈Sn →ωf ∈GL(n, q) is an injective group
homomorphism.
A8.36. Two codes C, C′ of length n over the same alphabet Fq are said to be
equivalent if there is a permutation p of Fq and a permutation f ∈Sn having
symbol (i1, . . . , in) such that the mapping
ωp,f : (x1, . . . , xn) ∈Fn
q →(p(xi1), . . . , p(xin)) ∈Fn
q
tranforms C into C′. If, in the above situation, p is the identity permutation, C and
C′ are said to be equivalent by positional permutation; if instead f is the identity
permutation C and C′ are said to be equivalent by symbol permutation. Prove that
two equivalent codes have the same size.
A8.37. Two codes C and C′ over the same alphabet Fq are said to be distance
equivalent if there is a bijective mapping f : C →C′ that is an isometry for the
Hamming distance, that is to say, for all x, x′ ∈C one has d(x, x′) = d(f(x), f(x′)).
Prove that two equivalent codes are distance equivalent.
A8.38. Let C be a code of size M. Order the elements of C into an M-tuple
(x1, . . . , xM). Let D(C) be the M × M matrix whose entry in position (i, j) is
d(xi, xj). Verify that D(C) is a symmetric matrix whose entries on the principal
diagonal are zero. Prove next that two codes C, C′ are distance equivalent if and

B8 Computational exercises
439
only if there are orderings of the elements such that the matrices D(C) and D(C′)
are equal.
A8.39. Let C be a code of size M. Order the elements of C into an M-tuple
(x1, . . . , xM). Let d(C) be the vector of length M whose ith component is w(xi).
Describe the connection between d(C) and the matrix D(C). Prove that two linear
codes C, C′ are distance equivalent if and only if there are orderings of the elements
such that the vectors d(C) and d(C′) are equal.
A8.40.* Give an example of codes that are distance equivalent but not equivalent.
A8.41. Two codes C, C′ of length n over the same alphabet Fq are said to be linearly
equivalent if there is a vector space isomorphism f of Fn
q such that f(C) = C′. Show
that two codes that are equivalent by positional permutation are linearly equivalent.
A8.42. Give an example of codes that are equivalent but not linearly equivalent.
A8.43. Give an example of codes that are linearly equivalent but not distance
equivalent.
A8.44. Verify the claim made in Example 8.6.2.
A8.45. Prove Proposition 8.6.3.
A8.46. Let b(x) be the check polynomial of a cyclic code C of type [n, k]q. Prove
that C consists of all polynomials c(x) in Fq[x]/(xn −1) such that c(x)b(x) = 0
modulo xn −1.
A8.47. Verify that, by renaming coordinates, the parity check matrices correspond-
ing to cases (3) and (4) of Example 8.6.6 coincide with the parity check matrix of
the Hamming code of Example 8.5.7.
A8.48. Verify that Goppa codes (see Deﬁnition 8.7.2) are linear.
A8.49. Verify identity (8.17) on page 431.
A8.50. Verify identity (8.20) on page 432.
A8.51. Prove Proposition 8.7.6 on page 433, by showing that a Goppa code
C(L, f(x))q,m with f(x) of degree t has a parity check matrix in which every t-
tuple of columns is linearly independent.
A8.52. Prove formula (8.22) on page 434.
B8 Computational exercises
B8.1. Is c = (0, 1, 1, 1, 1, 1, 1) a word of the Hamming (7, 4) code? If it is not, in
which position did the error occur, assuming that no more than one transmission
error has occurred?
(a) c is a word of the Hamming code.
(b) The ﬁrst coordinate of c is wrong.
(c) The third coordinate of c is wrong.
(d) The seventh coordinate of c is wrong.

440
8 Transmitting without. . . fear of errors
B8.2. Is c = (0, 1, 1, 0, 1, 1, 0) a word of the Hamming (7, 4) code? If it is not, in
which position did the error occur, assuming that no more than one transmission
error has occurred?
(a) c is a word of the Hamming code.
(b) The ﬁrst coordinate of c is wrong.
(c) The third coordinate of c is wrong.
(d) The seventh coordinate of c is wrong.
B8.3. Is c = (0, 1, 0, 0, 0, 1, 0) a word of the Hamming (7, 4) code? If it is not, in
which position did the error occur, assuming that no more than one transmission
error has occurred?
(a) c is a word of the Hamming code.
(b) The ﬁrst coordinate of c is wrong.
(c) The third coordinate of c is wrong.
(d) The seventh coordinate of c is wrong.
B8.4. Compute the Hamming distance of (0, 0, 0, 0, 0, 0, 0) from (0, 1, 1, 0, 1, 1, 0).
(a) 2.
(b) 3.
(c) 4.
(d) 5.
B8.5. Compute the Hamming distance of (1, 0, 1, 0, 0, 1, 0) from (0, 0, 1, 1, 0, 1, 1).
(a) 3.
(b) 4.
(c) 5.
(d) 7.
B8.6. Is {(0, 0, 1), (0, 0, 0), (0, 1, 0), (0, 1, 1)} a vector subspace of F3
2? If so, ﬁnd its
dimension.
(a) No, it is not a subspace.
(b) Yes, it is a subspace of dimension 1.
(c) Yes, it is a subspace of dimension 2.
(d) Yes, it is a subspace of dimension 3.
B8.7. Is {(1, 0, 1, 0, 1, 0), (0, 0, 0, 0, 0, 0), (0, 1, 0, 0, 0, 1), (1, 1, 1, 1, 1, 1)} a vector sub-
space of F6
2? If so, ﬁnd its dimension.
(a) No, it is not a subspace.
(b) Yes, it is a subspace of dimension 1.
(c) Yes, it is a subspace of dimension 2.
(d) Yes, it is a subspace of dimension 3.
B8.8. Compute the dimension and the minimum distance of the linear code
{(0, 0, 0, 0, 0), (1, 1, 1, 1, 0), (1, 0, 0, 0, 1), (0, 1, 1, 1, 1)} ⊂F5
2.
(a) The dimension is 2 and the minimum distance is 2.
(b) The dimension is 2 and the minimum distance is 3.

B8 Computational exercises
441
(c) The dimension is 3 and the minimum distance is 2.
(d) The dimension is 3 and the minimum distance is 3.
B8.9. Is the linear code of the previous exercise maximum-distance separable? Does
it detect or correct errors?
(a) It is not maximum-distance separable and detects and corrects one error.
(b) It is not maximum-distance separable and detects and corrects two errors.
(c) It is not maximum-distance separable and detects, but does not correct, one
error.
(d) It is maximum-distance separable and detects and corrects one error.
B8.10. Determine the dimension of the vector subspace of F4
2 generated by the set
{(1, 1, 0, 0), (1, 0, 1, 0), (0, 0, 0, 0), (1, 0, 0, 1), (0, 1, 0, 1)}.
(a) 1.
(b) 2.
(c) 3.
(d) 4.
B8.11. Determine the dimensione of the vector subspace of F4
3 generated by the set
{(1, 0, 1, 1), (0, 1, 1, 2), (1, 1, 2, 0)}.
(a) 1.
(b) 2.
(c) 3.
(d) 4.
B8.12. Compute the minimum distance of the linear code given by the vector sub-
space of the previous exercise, determine if it is maximum-distance separable and if
it detects or corrects errors.
(a) The minimum distance is 2, the code is not maximum-distance separable and
does neither detect nor correct errors.
(b) The minimum distance is 2, the code is maximum-distance separable and detects
and corrects one error.
(c) The minimum distance is 3, the code is not maximum-distance separable and
detects, but does not correct, one error.
(d) The minimum distance is 3, the code is maximum-distance separable, detects
two errors, and corrects one error.
B8.13. Compute Vq(n, r) for q = 2.
B8.14. Compute V7(9, 4).
B8.15. Consider a binary code deﬁned by the parity check matrix
⎛
⎜
⎜
⎝
1 0 0 1 0 0 0
0 0 1 0 1 0 1
0 0 1 0 0 1 1
0 1 0 1 0 0 1
⎞
⎟
⎟
⎠.
Which is the minimum distance of this code?

442
8 Transmitting without. . . fear of errors
(a) 1.
(b) 2.
(c) 3.
(d) 4.
B8.16. Is the code of the previous exercise perfect?
B8.17. Consider a code over F7 deﬁned by the parity check matrix
⎛
⎝
2 1 0 6 0 0 1
0 1 3 0 2 3 4
4 0 4 6 5 3 0
⎞
⎠.
Which is the minimum distance of this code?
(a) 1.
(b) 2.
(c) 3.
(d) 4.
B8.18. Consider the binary code deﬁned by the parity check matrix
⎛
⎜
⎜
⎝
1 0 0 0 1 0 1 1
0 1 0 0 0 1 1 1
0 0 1 0 1 1 0 1
0 0 0 1 1 1 1 0
⎞
⎟
⎟
⎠.
Which is the minimum distance of this code?
(a) 1.
(b) 2.
(c) 3.
(d) 4.
B8.19. Determine the dual code of the code deﬁned in the previous exercise.
B8.20. Determine all cosets and syndromes of the code of Exercise B8.17.
B8.21. Determine the dual of the code deﬁned in Exercise B8.18.
B8.22. Determine all cosets and syndromes of the code of Exercise B8.18.
B8.23. Determine a generating matrix in standard form of the code deﬁned in
Exercise B8.17.
B8.24. Determine a generating matrix in standard form of the code deﬁned in
Exercise B8.18.
B8.25. Compute the information rate of the code deﬁned in Exercise B8.12 and of
its dual.
B8.26. Compute the separation ratio of the code deﬁned in Exercise B8.12 and of
its dual.
B8.27. Verify all calculations and claims in Example 8.5.8 on page 424.

C8 Programming exercises
443
B8.28. Prove that the cyclic codes of Example 8.6.6 of page 427, for cases (3) and
(4) are equivalent by positional permutation to the Hamming code.
B8.29. Determine all binary cyclic codes of length smaller or equal than 6.
B8.30. Determine the cyclic codes over Z3 of length 5.
B8.31. Determine the generating polynomial and the dimension of the smallest
cyclic code over Z3 that contains the word (1, 2, 0, 0, 2).
B8.32. Determine the generating polynomial and the dimension of the smallest
cyclic code over Z5 that contains the word (4, 2, 0, 3, 1, 0, 2).
B8.33. Determine the BCH code with assigned distance δ = 3 over F2 with param-
eters l = 1 and n = 3.
B8.34. Determine the Goppa code over F2 with f(x) = x2 + x + 1 and L = F2.
B8.35. Determine the Goppa code over F7 with f(x) = x2 + 1 and L = F7.
C8 Programming exercises
C8.1. Write a program that takes in input an arbitrary sequence of binary digits
and outputs the N-time repetition of each digit, where N is a ﬁxed digit.
C8.2. Write a program that implements the Hamming (7, 4) code, that is, given
in input 4-tuples of binary digits, it outputs 7-tuples according to formula (8.2) on
page 410.
C8.3. Write a program that checks if a 7-tuple of binary digits is a word of the Ham-
ming code. If it is not, it corrects the 7-tuple by applying the maximum likelihood
principle, assuming a single transmission error has occurred.
C8.4. Write a program that measures the distance between two words of the Ham-
ming code.
C8.5. Write a program that carries out the syndrome decoding.
C8.6. Write a program that determines all binary cyclic codes of length n, for
n ≤10.
C8.7. Write a program that determines all Goppa codes over Zp, with p a prime
smaller than 20, and L = Zp, with f(x) a polynomial of degree at most 4.

9
The future is already here: quantum
cryptography
In this last chapter we shall have a look at the new frontier of cryptography,
the quantum cryptography, which relies on ideas originating in quantum me-
chanics. On the one hand, quantum cryptography envisions the creation of
a computer completely diﬀerent and unprecedented with respect to classical
computers, the so-called quantum computer. At present, it is only conceived
as a theoretical possibility; but if it were actually developed, it would be
able to perform in polynomial time some of the computations that a classi-
cal computer performs in exponential time. As we know, this would make all
present cryptosystems, such as RSA, vulnerable, seriously jeopardising civil,
military, ﬁnancial security systems. The result could lead to the collapse of
our very civilisation, which largely relies on such systems. On the other hand,
the same ideas on which the notion of a quantum computer is based lead to
new, completely unbreakable quantum cryptosystems, impervious even to an
hypothetic quantum computer, and having further the surprising feature of
discovering if an eavesdropper has attempted, even unsuccesfully, to intrude
a private communication.
As we said, quantum cryptography is based on fundamental ideas of quan-
tum mechanics. This is a relatively recent branch of physics, developed during
the last century, which builds on the observation that the mostly deterministic
laws of physics, which explain macroscopic phenomena cannot be succesfully
applied to microscopic ones. Physicists had to devise completely new ways
of looking at phenomena regarding the extremely small scale, sometimes ap-
parently weird ones, opposite to everyday intuition and often controversial.
Moreover, very elegant mathematical models have been constructed in order
to deal with these phenomena. All this is crucial in quantum cryptography,
but we shall be able to mention it only ﬂeetingly. The interested reader can
delve further into this subject by browsing the works listed in bibliography.
This chapter, even more than the previous one, is meant to give general in-
formation rather than going into details, about a non-classical part of cryp-
tography which is certain to have a major role in the future. A future that
has already begun because, as we shall see, the theory, if not the practice, of

446
9 The future is already here: quantum cryptography
quantum computers is already quite developed, and there are already working
quantum cryptosystems, although only on a small scale.
9.1 A ﬁrst foray into the quantum world: Young’s
experiment
Recall that, in classical mechanics, the position of a point or of a particle
is described by the vector x of its coordinates in a given spatial reference
system. The vector x = x(t) is a function of time t and satisﬁes a system of
diﬀerential equations, the equations of motion. The classical physical problem
consists in determining the motion of a point, that is to say, in computing
the function x(t) when its value x0 and possibly some of its derivatives at
initial time t = t0 are known. The answer is found by solving the system
of diﬀerential equations describing the motion of the particle with the given
initial conditions. As is known from mathematical analysis, under suitable
conditions, usually veriﬁed for ordinary physical systems, the equations of
motion have exactly one solution verifying the initial conditions. This means
that the whole motion of the particle, and in particular its position and its
velocity in every instant, are completely determined by the information we
have about the particle in a given instant. This is the reason why classical
mechanics is said to be deterministic, because everything within its scope is
uniquely determined by initial conditions.
As we shall see, this model, although valid for macroscopic systems, fails
for very small systems, such as elementary particles, which are ruled by
probabilistic, rather than deterministic, laws. This is the scope of quantum
mechanics.
We begin our brief travel through the world of quantum mechanics from
afar, that is, from an experiment carried out by an English scientist who lived
in Cambridge at the end of 18th century, Thomas Young. Recall that at that
time there was a heated debate among physicists about whether light had
the nature of a particle or of a wave. The scientists supporting the former
theory claimed that light consisted of particles, called photons, which, trav-
elling through space, hit objects and, to put it roughly, light them up. The
supporters of the wave theory contended instead that light is, like sound, car-
ried by waves that somehow propagate in space. Modern quantum physics
settled the question by proving both theories right: it is true that light con-
sists of single particles, photons, but they also have a wavelike behaviour.
Our perceiving light as a undulatory or as a particle phenomenon depends on
the circumstances. This seeming paradox is part of an unavoidable ambiva-
lence, called wave–particle duality, which is a particular instance of a general
principle, known as Heisenberg uncertainty principle which is, in turn, the cor-
nerstone of quantum mechanics, marking its radical diﬀerence from the deter-
minism of classical mechanics. Heisenberg uncertainty principle, put forward
in the 1920’s, states, in a qualitative form, that there are pairs of observable

9.1 A ﬁrst foray into the quantum world: Young’s experiment
447
properties of a microscopic physical system, such as position and velocity, or
energy and time, that cannot be both determined or measured exactly at the
same time. In other words, measuring one of the two conjugated properties
irreparably modiﬁes the other. And this modiﬁcation, and the consequent im-
possibility of simultaneously measuring two conjugated properties, does not
depend on the limits of our ways of measuring, but is an objective impossi-
bility that has a mathematical proof, and we shall come back to it later (see
Section 9.4).
Let us turn back our attention to Young, who was far from dreaming up the
uncertainty principle. With his experiment he succeeded instead in giving a
convincing evidence to the wavelike nature of light. As apparently happens to
English physicists – remember Newton’s apple – he got his idea while relaxing
and enjoying nature. Unlike Newton, Young was not under an apple tree, but
on the shore of a lake. He saw two swans swimming on the surface of the lake,
parallel to each other. Young noticed that the two swans left behind them two
semicircles of waves, which interfered creating on the calm surface of the lake
a peculiar pattern. This was due to the fact that when two wave crests met,
a crest higher than each of the two appeared; when two wave troughs met, a
trough lower than each of the two starting troughs formed, and when a crest
and a trough met they cancelled out. All this has nothing special; it is a scene
we have likely witnessed several times. What made the episode so interesting
for Young was that he recalled in that moment having seen exactly the same
pattern formed by the waves left by the swans, during on optical experiment.
The experiment was as follows (see ﬁgure 9.1).
A
F1
F2
B
L1
L2
L′
1,2
L1,2
Fig. 9.1. Young’s experiment
Assume we have a light source A in front of a plate with two narrow slits
F1 and F2; behind the plate there is a screen B. The distribution of light
on the screen, that is, from a particle viewpoint, the distribution of photons
absorbed by the screen B, is described by a surface whose curvilinear section is
given by curves L1, L2 and L1,2 is shown in ﬁgure 9.1. The curve L1 describes
the distribution in the case in which the slit F1 is open and F2 is closed, while

448
9 The future is already here: quantum cryptography
the curve L2 describes the distribution in the case in which the slit F2 is open
and F1 is closed. According to classical mechanics and considering light as
a particle phenomenon, that is, having in mind the propagation of photons,
Young would have expected that, when both slits are open, the distribution
of photons would have followed the the curve L′
1,2, that is, the sum of L1 and
L2. The experiment showed instead that this is not true: the distribution was
described by the curve L1,2 and the pattern on the screen was exactly that
formed by the waves left by the swans on the lake!
This, Young thought reasonably enough, was the ﬁnal proof of the wavelike
nature of light: the light rays passing through the slits F1 and F2 behave
exactly like the waves left by the swans on the lake and this is why the image
on the screen is analogous to the pattern formed by the waves.
Quantum physics seems not to be involved so far: in fact, we are talking
about 1799. Nevertheless, there is a modern way of repeating the experiment
using the most recent technology, to obtain truly surprising results. Modern
technology, indeed, allows us to emit from the light source A single photons,
one each second, say, at a ﬁxed speed but with randomly variable directions
within a sector D, as shown in ﬁgure 9.1. Now each photon travels alone
toward the plate, some passing through slit F1, some other through slit F2,
some more not passing through any of the two slits, everything happening
in a completely random way. Our eye cannot of course see a single photon,
but there are photon detectors which can be put on the screen B. Let the
experiment proceed for some hours, until as many photons passed as with
Young’s original experiment, which used a substantial light source, such as a
candle or a lightbulb. Which image do we expect on the screen? A moment’s
thought would lead us to reason like this: the image we saw in Young’s original
experiment was caused by undulatory interaction of several photons among
them, while here, where photons travel independently of one another, there is
no reason why they should interfere, so we do not expect to see on the screen
the same image as before. If we trust classical mechanics, we rather expect
to see on the screen two bright zones, which are the projections on B of the
slits F1 and F2. On the contrary – lo and behold! – the result of this second
experiment is absolutely analogous to that of Young’s original experiment.
This, as we have seen, is completely unexplainable within classical mechanics:
indeed, it is a quantum phenomenon, whose deep explanation is at the heart
of this modern branch of physics.
The explanation of this phenomenon given by quantum mechanics lies in
the so-called superposition of states. Alternative interpretations, based for in-
stance on the idea of parallel uninverses or multiverses, or of hidden variables,
have not yet been experimentally veriﬁed. We shall now give an intuitive ex-
position of it. The description of the mathematical machinery necessary for
modelling it shall be given later (see Section 9.4).
Something is certain: each photon starts from A and, if it passes through
one of the two slits F1 or F2, then it reaches the screen B. What happens in
the interval between the photon’s departure from A and its arrival on B is

9.2 Quantum computers
449
for us a mystery which appears not to be ruled by deterministic laws, but by
probabilistic ones. Basically, the photon, if it passes through one of the slits,
has the same probability of passing through F1 or F2 and, strange as it may
seem, we may adopt the viewpoint that it passes through both F1 and F2, so
interacting with itself and determining the undulatory eﬀect which emerges
in Young’s experiment. Each of the two possibilities, the passage through F1
or F2, is called a state of the photon, and as we are supposing that in the
intermediate phase of the travel from A to B, when we do not carry out any
observation, the two states somehow take place simultaneously, this explains
why this phenomenon is called superposition of states. This viewpoint, unusual
as it may seem, can be formalised mathematically – in a while we shall brieﬂy
outline how – and leads to an explanation of the result of Young’s experiment.
In conclusion the superposition of states is a way of describing an object during
a period of ambiguity when no observations or measures are performed.
Clearly, when we perform an observation or a measure to ﬁnd out the
actual state of the photon, the ambiguity stops and consequently the super-
position of states ceases. But this, in accordance with the uncertainty prin-
ciple, irreversibly modiﬁes the system itself. So we expect that, if we modify
Young’s experiment in such a way that it is possible to ascertain, for each
photon, the slit it passes through, this very act modiﬁes the result of the ex-
periment. And, however contrary to intuition, this is what happens. In this
second case, indeed, the distribution of the photons absorbed by the screen
B is no longer ruled by the curve L1,2, but by the curve L′
1,2: it is as if, by
observing and measuring the trajectory of the photons, we treated them as
particles having motions ruled by classical mechanics, obtaining exactly the
result classical mechanics would have predicted!
9.2 Quantum computers
We are now going to discuss how Young’s experiment and its odd explanation
may lead to the invention of a quantum computer able to perform computa-
tions in such a way to reduce the time necessary for some algorithms from
exponential to polynomial.
The idea is due to an English physicist, David Deutsch, who introduced
this notion in 1984 (see [17], [18]). Deutsch ﬁrst remarked that usual computers
operated essentialy by using the laws of classical physics, while it would have
been desirable to have computers operating in accordance with the laws of
quantum physics, as they can lead to a quicker carrying out of operations.
Let us see why.
If a classical computer is to examine a problem requiring a number of
attempts, it has to proceed serially. Consider, for instance, the factorisation
of a number n. Basically, the computer may proceed by using the sieve of
Eratosthenes, so it divides the number ﬁrst by 2, then by 3, and so on, up to
[√n], if necessary. And this seriality is responsible for the exponential time

450
9 The future is already here: quantum cryptography
needed by the computation. On the contrary, if we had at our disposal a
quantum computer, we might envision using the superposition of states to
avoid specifying serially the numbers from 2 to [√n]. Basically, just as the
photon in Young’s experiment, if not observed, is in a superposition of states
when passing from A to B, and thus we may regard it as simultaneously
passing through both F1 and F2, in the same way we may imagine the existence
of a computer in which, by exploiting the same principle, while a computation
is carried out and it is not interfered with by external factors, the input may
assume simultaneously a whole set of numerical values, somewhat as if it were
a variable rather than a number. So the quantum computer, which will work,
rather than with simple bits, with quantum bits or qubits, might be able to
factor the number n proceeding not serially, but performing a single division.
Of course, this reduces the computing time for the sieve of Eratosthenes from
exponential to polynomial.
This, which might look like pure fantasy, is actually not such, at least from
a theoretical viewpoint. Indeed, it suﬃces to use the properties of elementary
particles and their quantum mechanics to represent numbers and operate on
them. The basic idea is as follows. Many elementary particles have an observ-
able property, or simply an observable, called spin, which is, broadly speaking,
analogous to the angular momentum of a macroscopic ball rotating around
its axis. It is important to emphasise the words broadly speaking, warning
that this analogy is not to be taken too literally. In any case, some particles
called fermions have half-integer spin and some of these, like electrons, have
spin with absolute value 1/2. The spin, that is, this intrinsic angular momen-
tum, if computed with respect to a particular directed axis, which we shall
call z-axis, may assume the values Sz = 1/2 and Sz = −1/2, corresponding
intuitively to a clockwise or a counterclockwise rotation. So consider such a
particle p and decide that it represents 0 if it has clockwise spin and 1 if it has
counterclockwise spin. Take h particles of this kind, p1, . . . , ph, and put them
in an equal number of boxes numbered from 1 to h, one each, not communi-
cating with each other, so as not to interfere. Thus, proceeding as usual we
may represent all numbers with h binary digit (m1 · · · mh)2, that is to say, all
numbers from 0 to 2h −1. Actually, in order to represent diﬀerent numbers
we have to be able to give the particles diﬀerent spin components Sz along
the z-axis. This can be done by subjecting the particle to an energy pulse: if
the pulse is high enough, the particle changes its spin, else it keeps the spin it
had. But we want to use the superposition of states, to let the particle have
simultaneously, in a quantum sense, diﬀerent components Sz of the spin. To
obtain this, we enclose each particle in its box, so as not to observe it, and
subject each particle to an energy pulse of random strength. So each particle
enters a superposition of states and represents simultaneously 0 or 1. This is
a qubit. Now, a number consisting of h qubits is a quantum number which
may be any number from 0 to 2h −1. If we learn how to operate on these
numbers, we have solved, at least theoretically, the problem of constructing a
quantum computer.

9.3 Vernam’s cipher
451
This is Deutsch’s contribution, which left open an important theoreti-
cal problem and innumerable, huge practical ones. The theoretical problem
amounted to conceiving algorithms that actually worked, at least in principle,
on such a thing as a quantum computer. This problem has been solved in 1994
by Peter Shor, who found polynomial algorithms for a quantum computer to
factor large integers and to determine discrete logarithms (see [54]).
The union of Deutsch’s and Shor’s results would seem to be disastrous for
cryptography: are all cryptographic systems that, such as RSA, rely on the
diﬃculty of factoring large numbers or on the Diﬃe–Hellman hypothesis (see
Section 7.7, Section 7.7.6), unreliable? Can they be easily eluded by using
a quantum computer? The answer is “yes”, but, at present, only in theory.
Indeed, the practical issues related with the actual construction of quantum
computers seem currently diﬃcult to overcome. In particular, for a quantum
computer to be able to operate, it must be completely isolated from the ex-
terior, an isolation impossible to attain with today knowledge. This problem,
the so-called quantum decoherence, like other problems related to quantum
computing, is among those most actively investigated by physicists and might
one day be solved. However, it is not easy to estimate when this will happen.
Certainly, the day a quantum computer will become a reality, all cryptographic
systems we have been discussing so far will be easily circumvented, and this
shall put in serious danger our very safety, which relies on them. However,
as we shall brieﬂy see, the same ideas that lead to quantum computers also
lead to unassailable techniques of quantum cryptography. We shall discuss
this subject in the next sections.
9.3 Vernam’s cipher
Before discussing quantum cryptography, let us get momentarily back to the
classical case, and give the reader some good news. There are ciphers that
are theoretically completely unassailable, and we shall deal with them in this
section. So, even if one day quantum computers will be made a reality, we
will be able to resort to these ciphers, and trust them with our safety. Why
then, the reader will ask, did not we mention them till now, taking pains to
discuss classical cryptography, RSA, elliptic curves and so on? The answer
will be given in due course: we shall explain ﬁrst how these ciphers work, and
then we shall answer the above natural and crucial question. Finally we shall
see, in the next sections, how quantum cryptography may yield a method for
reasonably and eﬀectively using these ciphers.
The cipher we are talking about is the so-called Vernam’s cipher, which
bears the name of Gilbert S. Vernam, an employee of the American Telephone
& Telegraph Company who, together with Joseph O. Mauborgne, a Major
General in the United States Army, proposed it during World War I. In his
fundamental text [53], already cited in the chapter about codes, C. E. Shannon
proved that Vernam’s ciphers are secure against cryptanalysis and, further,

452
9 The future is already here: quantum cryptography
that every cipher that is secure against cryptanalysis is a Vernam’s cipher. In
other words, there exists a unique perfectly safe cryptographic system, and it
is the Vernam’s cipher.
Let us describe it. This cipher is also called one time pad, because the
enciphering key used to be written on the sheets of a notepad to be made
known to the users (the sender and receiver) and should not be used more
than one time.
The system is very easy. The sender and the receiver have the same key,
which has to satisfy the following properties:
(i) it must be the same length as the message to be sent;
(ii) it must be a completely random sequence of characters;
(iii) it must never be used more than once.
Under these hypotheses it is not necessary to use an intricate enciphering
function: we may use a simple one, say, addition or subtraction. For instance,
if we choose the binary alphabet {0, 1} consisting of the two digits 0 and 1,
we may deﬁne a Vernam’s cipher as follows:
Deﬁnition 9.3.1. Let m = m1m2 . . . mr be a binary message to be sent. Let
K = k1k2 . . . kr be the key, which is a binary string of the same length of
the message, consisting of random digits. The enciphering is carried out by
substituting the message m with the message c = c1c2 . . . cr, where
ci = mi + ki,
i = 1, . . . r.
The key must not be used again. This cipher is called a Vernam’s cipher.
Clearly, we may do the same if we use any other alphabet, as shown in the
following example.
Example 9.3.2. Suppose the message to be sent is the word HOME. We
choose as a key the sequence of random letters DXT G, having the same
length as the message. Associating, as usual, with each letter a number in
{0, 1, . . ., 25} (see Table 7.3 on page 324) we may encipher the message by
summing the word DXT G to the word HOME, where the sum is taken
modulo 26:
H + D −→7 + 3 = 10
−→K,
O + X −→14 + 23 = 37 ≡11 (mod26) −→L,
M + T −→12 + 19 = 31 ≡5 (mod26)
−→F,
E + G −→4 + 6 = 10
−→K.
So the enciphered message is KLFK. To reconstruct the original message,
the receiver will only have to subtract the sequence DXT G from the message
he received.

9.3 Vernam’s cipher
453
Let us understand why Vernam’s ciphers are unbreakable. The reason lies
in the randomness of the character constituting the key. Indeed, if a person
who does not possess the key wanted to decipher the message, he could in
principle try out each possible key. This operation has an enormous computa-
tional complexity, as the number of keys increases exponentially as a function
of the length r of the message (see Exercise A9.1). However, this is not the
reason why the cipher is unbreakable. In fact, we saw that, with a possible fu-
ture appearance of quantum computers, computing limitations like this might
not be relevant anymore. The true reason for this cipher’s unbreakability is
the fact that, by the arbitrariness of the key, one would obtain, in the course of
the analysis, all possible plaintexts of length r. Moreover, by the randomness
of the key, all these plaintexts would be equally probable. Now, most of them
would certainly be meaningless, but all meaningful ones of length r would be
possible. In other words, if a 4-letter words is sent, as in Example 9.3.2, the
cryptanalysis we just outlined – the only possible one – gives as a result that
the plaintexts HOME, AWAY , NICE, UGLY , BOOK, and so on, are all
equally probable!
Example 9.3.3. If we try to carry out the cryptanalysis of the message
KLFK sent in Example 9.3.2, we have to try out all 4-letter keys. Among
them, we shall meet IDFW, which leads to the following deciphering:
K −I −→10 −8 = 2
−→C,
L −D −→11 −3 = 8
−→I,
F −F −→5 −5 = 0
−→A,
K −W −→10 −22 = −12 ≡14 (mod26) −→O.
So we obtain the word CIAO.
However, it is crucial that the key is never used twice. Indeed, if the sender
made the fatal mistake of using again the same key, the cipher would become
open to attempts of cryptanalysis. To see why, rather than expound it theo-
retically, let us consider an example.
Example 9.3.4. Consider again Example 9.3.2. Suppose the sender uses
again the key DXT G to encipher the word T OWN. As is readily seen, the
result is the word WLPT . Suppose further the cryptanalyst knows that the
letter O appears in both words in the same place. By comparing the words
WLPT and KLFK, he deduces that the letter O corresponds to the letter
L, and so that the key has X in second position. It is not a lot of informa-
tion, but it is better than nothing. If the sender keeps using the same key, the
cryptanalyst, in an analogous way, sooner or later will discover it.
This example shows how frequency analysis may help cryptanalysts when
the sender makes the ill-omened mistake of using several times the same key.
As already mentioned, there must be some weak point in this cipher, in
itself unbreakable. Otherwise, it would be used universally, yielding security
and satisfaction. Actually, there are weak points, and quite serious ones.

454
9 The future is already here: quantum cryptography
The ﬁrst, but not the main one, lies in how to generate keys. They must
be long enough to allow exchanging complex messages, randomly generated,
and, as they must not be used twice, lots of them are needed, to be able
to communicate frequently. Now, generating random numbers is not at all a
trivial problem in computer science, and even less so generating long strings
of random numbers. But, as we have said, this is not the main problem of this
cipher, so we do not dwell further on this issue, important as it may be.
The main problem lies in the fact that, in order to be able to communicate
securely using a Vernam’s cipher, it is necessary to send in advance the key,
through a channel that must be absolutely secure. In other words, before being
able to communicate secretly, we must communicate secretly the key. But the
key has the same length as the message to be sent, so we have a vicious circle.
In conclusion, the only ciphers that are theoretically secure, Vernam’s
ciphers, are very diﬃcult to use in practice. In fact, they have been used
very rarely: for instance for communicating between the White House and
the Kremlin, where the keys were transferred by hand, in the presence of
witnesses, in conditions of maximum security. Of course, in general it is not
possible to operate this way, so other methods are used, as RSA, which, even
if not theoretically completely secure, ensure a reasonable level of security.
Nonetheless, if we were able to produce random, suﬃciently long keys and
we could send them in a secure way, that is to say, with the certainty that
no third party eavesdropped and intercepted the key, we migh use, securely
and without qualms, Vernam’s ciphers. This is made possible by quantum
cryptography, as we shall see brieﬂy.
9.4 A short glossary of quantum mechanics
In this section we collect, without any claim of completeness, some basics
of the mathematical machinery necessary to discuss quantum mechanics. We
shall need all of this when, in next section, we shall talk about quantum
cryptography.
First of all, the mathematical setting is a real vector space H endowed
with a scalar product
⟨, ⟩: H × H →R
with the property of being positive-deﬁnite, that is to say, such that ⟨u, u⟩> 0
for every non-zero vector u ∈H. As usual, we also deﬁne the norm of a vector
u ∈H as
||u|| = ⟨u, u⟩
and the length of u as
|u| =

||u|| =

⟨u, u⟩.
The vectors of length 1 are called unit vectors or versors. Two vectors u, v
are said to be orthogonal if ⟨u, v⟩= 0.

9.4 A short glossary of quantum mechanics
455
Sometimes, in addition to H, we also consider the complexiﬁcation of H,
which with a slight abuse of notation we shall sometimes again denote by
H rather than, as usual, by HC. This is a complex vector space of the same
dimension as H, containing H as a real subspace: we have HC = H ⊕iH.
Moreover, HC is endowed with a positive-deﬁnite hermitian scalar product
extending the scalar product on H and denoted again by ⟨, ⟩. It is uniquely
determined by these conditions and is called complexiﬁcation of the scalar
product in H (see [13]). In this chapter we shall mostly need the real case.
Moreover, in what follows, it will suﬃce to ﬁx our attention to the case in
which H has dimension 2.
The vector space H is called the state space and each of its non-zero
vectors is said to be a state vector. Usually a state vector is assigned up to a
multiplicative constant t, that is, we consider two non-zero vectors u and tu,
with t ̸= 0, as equivalent. So, rather than in H, we might work in the associate
projective space P(H), which is a projective line. Alternatively, and we shall
take this approach, we may represent an equivalence class of state vectors by
a versor. This leaves an indeterminacy we may live with: namely, two versors
u, v are equivalent if and only if u = tv, with |t| = 1.
To begin browsing our glossary, let us see a physical situation where this
mathematical model may be applied. Recall that the smallest unit or quantum
of light is the photon. As we saw, in quantum physics it may be regarded as a
particle, but it has a wavelike behaviour too. In a very simpliﬁed way, we may
describe this wavelike behaviour as follows: the photon may be regarded as a
tiny electromagnetic ﬁeld that propagates describing a sinusoid along an axis
given by a line d, as shown in Figure 9.2. Of course, the sinusoid lies in a plane
π containing the line d. The direction of the lines of π that are orthogonal to
d is the direction along which the photon oscillates, and is called polarisation
of the photon.
π
d
Fig. 9.2. Polarisation of the photon
So, the way of representing mathematically this undulatory behaviour of
the photon is to consider it not as a point, but rather as a vector whose direc-
tion is the polarisation of the photon. This explains the mathematical setting
we introduced: namely, we may consider our vector space H as the set of po-
larisation states of photons. The reason why we may assume H of dimension
2 is clear: indeed, if the photons, leaving from a light source, propagate along

456
9 The future is already here: quantum cryptography
direction d in the three-dimensional space, then the polarisations of the pho-
tons emitted by the light source are space vectors lying in the plane orthogonal
to d.
It is well known that in H there are orthonormal bases, that is, ordered
pairs (u, v) of mutually orthogonal versors. Such pairs of vectors form a basis
of H and allow us to identify H with R2 [with C2 in the complex case],
by identifying the vector xu + yv with the ordered pair (x, y). Under this
identiﬁcation, the scalar product ⟨, ⟩is identiﬁed with the euclidean scalar
product (x1, y1)×(x2, y2) = x1x2 +y1y2 [with the standard hermitian product
(x1, y1)×(x2, y2) = x1x2+y1y2 in the complex case] (see Exercises A9.2–A9.3).
Of course, there are inﬁnitely many orthonormal bases of H. However,
suppose we have chosen one, by which we identify H with R2 as we just
explained: in other words, we introduced a coordinate system on H. This or-
thonormal reference system is usually denoted by (↑, →), and its states cor-
respond to vertically and horizontally polarised photons. We shall call this
reference frame rectilinear. Another natural orthonormal reference frame is
the diagonal reference (↗, ↘), where ↗and ↘correspond to the states of
the photons polarised at 45 and −45 degrees with respect to the rectilinear
reference, respectively. The connection between the two references is given by
the following relations:
↗
↘

=
1
√
2
 1
1
1 −1
  ↑
→

,
 ↑
→

=
1
√
2
 1
1
1 −1
 ↗
↘

.
It is necessary now to formalise mathematically the notion of observation
or measure of a photon. In our mathematical setting consisting of the vector
space H, we shall call observable any linear mapping
A : H →H
that is symmetric [hermitian in the complex case], namely, such that for every
pair of vectors u, v ∈H we have
⟨A(u), v⟩= ⟨u, A(v)⟩.
As is well known, given a reference frame, and so having identiﬁed H with
R2 [with C2 in the complex case], every mapping A as above is identiﬁed with
a square 2 × 2 matrix over R [over C, resp.]. If the reference is orthonormal,
the matrix is symmetric [hermitian in the complex case].
It is further well known that a linear mapping A : H →H that is symmetric
[hermitian, resp.] is orthogonally diagonalisable, that is to say, there is an
orthonormal basis (v1, v2) consisting of eigenvectors of A. This is the content
of the so-called spectral theorem (see [13], pag. 428). In such a basis, the
matrix of A becomes diagonal
 λ1
0
0
λ2

,
(9.1)

9.4 A short glossary of quantum mechanics
457
where λ1, λ2 are the eigenvalues of A. They are the possible outcomes of a
measurement of the observable A. So the observable A has measure λi only if
applied to the eigenvector vi, i = 1, 2, or to a multiple of it.
In general, give a system state v ∈H, which may be assumed to be a
versor, we have
v = ⟨v, v1⟩v1 + ⟨v, v2⟩v2
(9.2)
and so
A(v) = λ1⟨v, v1⟩v1 + λ2⟨v, v2⟩v2.
(9.3)
(see Exercise A9.2). By Cauchy–Schwarz inequality (see Exercise A9.5 and
Exercise A9.6), we have 0 < |⟨v, vi⟩| ≤1 and |⟨v, vi⟩| = 1 if and only if v is
proportional to vi, i = 1, 2. As (see Exercise A9.4)
1 = ||v|| = |⟨v, v1⟩|2 + |⟨v, v2⟩|2,
the larger |⟨v, v1⟩|, the smaller |⟨v, v2⟩|, and so the closer v is to v1. We get an
analogous result if we exchange v1 and v2.
So it is natural to deﬁne |⟨v, vi⟩|2 as the probability P(A, v, λi) for A to
have measure λi in state v, i = 1, 2. In particular, if this value equals one,
that is if the probability is 1, then the measure of A in state v is exactly the
eigenvalue λi. Moreover, as can be expected,
P(A, v, λ1) + P(A, v, λ2) = |⟨v, v1⟩|2 + |⟨v, v2⟩|2 = 1.
Notice further that, by (9.2) and (9.3), we have
⟨A(v), v⟩= λ1P(A, v, λ1) + λ2P(A, v, λ2).
This quantity is denoted by the symbol E(A)(v) and is called mean or expected
value of the measure of the observable A in state v. We may also consider the
non-negative quantity ΔA(v) such that
ΔA(v)2 = E

(A −E(A)(v) · I)2	
(v) = ⟨(A −E(A)(v) · I)2(v), v⟩=
= ⟨A −E(A)(v) · v, A −E(A)(v) · v⟩.
Notice that, if v is a versor,
ΔA(v)2 = ⟨A(v), A(v)⟩−E(A)(v)2 = ⟨A2(v), v⟩−E(A)(v)2 =
= E(A2)(v) −E(A)(v)2.
The number ΔA(v)2 [ΔA(v), resp.] is called the variance [standard deviation,
resp.] of the measure of the observable A in state v. These numbers quantify
how the measure of the observable A in state v deviates from its expected
value. This terminology is consistent with the usual one in probability theory
(see [29]).
Let us return to our glossary and have a look at how this mathematical
language applies to speciﬁc physical questions.

458
9 The future is already here: quantum cryptography
So, consider again light and photons which, as we have seen, are repre-
sented as state vectors keeping trace of their polarisation. But the light we
see usually consists of a huge number of photons with widely diﬀerent polar-
isations, so usually we do not perceive at all the polarisation phenomenon.
Unless, as we know from experience, we wear polarising glasses. Let us ex-
plain their eﬀect. There are transparent materials having a unidirectional
crystalline structure. If light passes through these materials, the photons that
are polarised in the same direction as the crystals making up the material
get through undisturbed, those having orthogonal polarisation are absorbed,
that is, their passage is stopped, and the remaining ones have a probability of
getting through but, if they pass, they emerge all with the same polarisation.
In conclusion, if such a ﬁlter is located between the light source and our eye,
we only perceive light that is polarised in the direction allowed by the ﬁlter.
It is clear that, by rotating the ﬁlter, we may let through light with diﬀerent
polarisations. For instance, if a ﬁlter only lets through vertically polarised
light, rotating it by 45 degrees it will let through diagonally polarised light,
rotating it by 90 degrees it will let through horizontally polarised light and so
on.
Let us see now the mathematical formulation of this phenomenon. In order
to do so, let us ﬁx our attention on the observable A, which in the rectilinear
reference frame has matrix
 1
0
0
0

.
Which eﬀect do we obtain by applying A to an arbitrary state given by a
versor v? Clearly, if v = ↑then A(v) = v = ↑, if instead v = →then A(v) = 0.
In general, if
v = (x, y) = x · ↑+y · →,
we have
A(v) = ⟨v, ↑⟩· ↑= x · ↑.
So the eﬀect of A is that of a vertical polarising ﬁlter, which we shall call
ﬁlter of type ↑. The photons with vertical polarisation get through undis-
turbed, those with horizontal polarisation do not get through, and those with
polarisation v = (x, y) have, according to our mathematical description, a
probability equal to x2 of getting through, with vertical polarisation.
For instance, the photon ↗= (↑+ →)/
√
2 has probability 1/2 of passing,
and the same happens for the photon ↘. In other words, recalling a concept
introduced in Section 9.1, the photons ↗and ↘are in a situation of super-
position of states with respect to the observable A. Having photon ↗pass
through a polariser of type ↑, we subject it to an observation: we observe
whether the light goes out vertically polarised or does not go out. The eﬀect
of this observation is, in the words of P. A. M. Dirac, one of the fathers of
quantum mechanics, of forcing the photon entirely in the state of vertical or
horizontal polarisation. It will have to jump abruptly from the condition of par-
tially belonging to each of these states to exclusively belonging to one of them.

9.4 A short glossary of quantum mechanics
459
We cannot foresee which of the two states it will jump to: the phenomenon is
governed by probabilistic laws (see also [20]).
Of course, the observable
 0
0
0
1

acts as a horizontal polarising ﬁlter, that is, of type →, while the observables
1
√
2

1
1
1
1

,
1
√
2

1 −1
−1
1

act as polarising ﬁlters of type ↗and ↘, respectively.
In general, the observable (9.1), with λ1 ̸= λ2 both non zero, acts as a
polarising ﬁlter that lets through the photons having rectilinear polarisation,
preserving the polarisation. We shall call this a polarising ﬁlter of rectilinear
type, or of type +. The photons having polarisation ↗and ↘always have
probability 1/2 of passing with polarisation ↑or →. Of course there are analo-
gous ﬁlters of diagonal type or of type ×, which let through the photons having
diagonal polarisation preserving their polarisation, while the photons having
rectilinear polarisation subjected to them have probability 1/2 of passing with
polarisation ↗or ↘(see Exercise A9.11).
We conclude this section giving a sketch of the mathematical formulation of
Heisenberg uncertainty principle.
First of all, some remarks about the product of two observables are in order.
Given two observables A and B, we deﬁne their commutator [B, A] as the observable
such that
[B, A](v) := B(A(v)) −A(B(v))
for all v ∈HC. It is useful to remark that, for each pair of observables A, B, we have
⟨[B, A](v), v⟩= ⟨A(v), B(v)⟩−⟨B(v), A(v)⟩=
= ⟨A(v), B(v)⟩−⟨A(v), B(v)⟩= 2 Im(⟨A(v), B(v)⟩).
(9.4)
Clearly, we have [B, A] = 0 if and only if A and B commute, that is to say, if and
only if A · B = B · A, where the product is the composition of mappings. Notice
further that if A and B are observables, it is not always the case that A · B is an
observable, but it is if A and B commute (see Exercises A9.8 and A9.9). Moreover,
A and B have a common orthonormal basis consisting of eigenvectors if and only if
A and B commute (see Exercise A9.10). Physically, this means that two observables
commute if and only if they may be measured simultaneously, that is, if and only
if there are states v on which, for both observables, it is possible to compute the
measure with probability 1. In this case, the observables are said to be compatible. If
instead [B, A] ̸= 0, the observables are not simultaneously measurable and are said
to be incompatible.
After these premises, we may state Heisenberg uncertainty principle in the form
given by Dirac:

460
9 The future is already here: quantum cryptography
Theorem 9.4.1 (Heisenberg uncertainty principle). Let A and B be observ-
ables and let v be a state determined by a versor in HC. We have
ΔA(v)2 · ΔB(v)2 ≥1
4 |⟨[B, A](v), v⟩|2 .
(9.5)
Proof. Notice that it suﬃces to prove (9.5) for the observables A′ = A−E(A)(v)·I,
and B′ = B −E(B)(v) · I, where I is identity. Indeed, we have [B, A] = [B′, A′],
ΔA(v) = ΔA′(v) and ΔB(v) = ΔB′(v). Notice further that E(A′)(v) = E(B′)(v) =
0 and so ΔA′(v)2 = ⟨A′(v), A′(v)⟩and ΔB′(v)2 = ⟨B′(v), B′(v)⟩.
From (9.4) it follows that
|⟨[B′, A′](v), v⟩| = 2| Im(⟨A′(v), B′(v)⟩)| ≤2|⟨A′(v), B′(v)⟩|.
We may conclude by applying Cauchy–Schwarz inequality.
⊓⊔
Notice that here it is actually important to consider everything in HC rather than
in H. Indeed, if A and B are observables over H, by (9.4) we have ⟨[B, A](v), v⟩= 0
for all v ∈H, and Heisenberg uncertainty principle becomes trivial. Heisenberg
principle becomes relevant for pairs of observables A, B such that ⟨[B, A](v), v⟩=
2 Im(⟨A(v), B(v)⟩) is non-zero for every versor v. In this case, (⟨[B, A](v), v⟩2)/4 is
a continuous function that never becomes zero on the compact set U = {v ∈HC :
|v| = 1}. So it has a minimum M > 0 and Equation (9.5) implies that
ΔA(v)2 · ΔB(v)2 ≥M.
This relation says that the smaller we make the standard deviation ΔA(v), the
larger ΔB(v) is forced to become, so: whenever we try to improve the measurement
of one of the two observables, making it arbitrarily precise, we are compelled to
increase the inaccuracy with which we measure the other observable.
9.5 Quantum cryptography
The principles of quantum mechanics we have very quickly recalled may be
used, as already mentioned, to solve the problem of creating and transmitting
random keys, so making it possible to use Vernam’s ciphers. The transmission
will be, as we shall see, completely secure, that is to say, both the sender
and the receiver are able to detect possible third parties trying to eavesdrop
in order to get, even partially, information about the key being transmitted.
As we shall see, the uncertainty of quantum world provides certainty about
communication security.
The ﬁrst ideas about quantum cryptography can be found in an important
contribution by S. Wiesner (see [62]), which already circulated as a manuscript
around 1970, but was published only in 1983, having been rejected by several
journals that did not realise its groundbreaking importance. These ideas were
then developed by C. H. Bennet and G. Brassard around 1980. They worked
out a protocol, that we shall describe here, for a quantum distribution of keys.
This protocol is known today as the BB84 protocol, as the paper [7] in which

9.5 Quantum cryptography
461
it was described appeared in 1984 (see also the expository article [9], which
contains interesting remarks about technical aspects, which we shall overlook
here, concerning the setting up of the machinery for the actual implementation
of the protocol).
Here is the gist of the idea of Bennet and Brassard. To discuss it, consider
again what we said at the end of section 9.1. In that situation we may suppose
that A, the photon source, is the sender of a message, call her Alice, and the
screen B is the receiver of the message, call him Bob. As we saw, the message,
in the absence of intrusions, consists in an image which is described by the
curve L1,2. But if there is an eavesdropper, calk her Eve, who tries to measure
the photons while they pass through the slits F1 and F2, this attempt would
modify the image, which would now be described by the curve L′
1,2 rather
than by the curve L1,2. So Bob, conversing, say by telephone, with Alice and
describing, if not the whole image at least some of its features, would certainly
notice the intrusion and could communicate it to Alice.
The idea of quantum cryptography is not very diﬀerent. Transmitting in-
formations between Alice and Bob takes place through two channels: the ﬁrst
part through a quantum channel, for instance an optical ﬁbre transmitting
polarised photons, the second one, which consists itself of two parts, through
an ordinary, not necessarily secure, channel.
In describing the BB84 protocol we shall use the mathematical machinery
we introduced in the previous section. In particular, the polarised photons
will be vectors in H. We shall assume that a rectilinear orthonormal reference
frame (↑, →) has been introduced. In addition to photons having state ↑and
→, we shall only use those with states ↗and ↘. We shall also use ﬁlters of
type + and ×.
Step 1: communicating by transmitting photons through a quantum channel.
A) Alice has at her disposal, for the transmission, four polarised ﬁlters
which she may use to send through the transmission channel photons having
one of the four polarisations ↑, →, ↗and ↘. Alice and Bob, who receives,
ﬁxed beforehand a binary numerical value to be attributed to a polarised
photon, as follows:
Polarised photons
↑
→
↗
↘
Corresponding binary digits
1
0
1
0
Alice chooses a number r far greater than the length of the key she wants
to send Bob. Moreover, Alice randomly chooses a string, that is an ordered
r-tuple of polarisers, and sends Bob the corresponding string of polarised
photons, keeping a record of it. So Alice has, in fact, sent Bob a sequence of
r binary digits, which represents the number that is Alice’s actual message to
Bob.
For instance, we might have the following situation:

462
9 The future is already here: quantum cryptography
Polarisation of photons sent by Alice
↑
↑
↗
↘
↑
↘
↑
→
Message sent by Alice
1
1
1
0
1
0
1
0
Of course, if Bob just received the polarised photons and read the number
sent by Alice and used it as a key, then no security would be guaranteed,
because Eve, the possible eavesdropper, could, just like Bob, read the same
number spying on the channel. On the other hand, so far we have not used
any quantum phenomenon. Let us see now how Bob may proceed to ensure
the secrecy of the key.
B) Bob has at his disposal four ﬁlters, two of rectilinear type +, that is,
↑and →, and two of diagonal type ×, that is, ↗and ↘, which operate as
explained in section 9.4. Bob does not know the polarisations of the photons
sent him by Alice. So he lets the received photons pass randomly through his
ﬁlters and measures their polarisation. He attributes next to each polarised
photon its numerical equivalent and determines a received message.
For instance, we might have:
Message sent by Alice
1
1
1
0
1
0
1
0
Polarisation of the photons sent by Alice
↑
↑
↗
↘
↑
↘
↑
→
Filters used by Bob
↑
↗
↘
→
↑
↘
↗
↗
Polarisation of the photons measured by Bob
↑
↘
∅
↑
↑
↘
↗
↘
Message received by Bob
1
0
1
1
1
0
1
0
Notice that, for the third photon sent by Alice during the transmission,
Bob used a ﬁlter that absorbs it and does not let it go through, so in this posi-
tion no light arrived. We denoted this situation by the symbol ∅. Nevertheless,
Bob deduces that the message sent by Alice is 1, as the only polarisation in-
compatible with the ﬁlter he used corresponds to 1.
Notice that, in doing so, Bob might or might not make some error. Indeed,
if he uses the ﬁlter + [the ﬁlter ×, resp.] on a photon having rectilinear
[diagonal, resp.] polarisation, no error occurs. But if he uses the ﬁlter + [the
ﬁlter ×, resp.] on a photon having diagonal [rectilinear, resp.] polarisation, this
modiﬁes the reception of the corresponding photon. As both the polarisation
of the photons sent by Alice and the ﬁlters used by Bob are randomly chosen,
we may expect such errors to occur with probability 1/2. But these errors
do not necessarily imply an error in the ﬁnal received message. Indeed, for
each error caused by using the wrong ﬁlter on one of Alice’s photons, there
is an even chance that the corresponding digit is the right one, although the
polarisation of the photon is wrong. For instance, as the previous table shows,
if Alice sends a photon with polarisation ↑, as in the steps 2 and 7 of the
transmission, and if Bob erroneously uses the ﬁlter ×, it may happen with
probability 1/2 that either Bob receives a photon with polarisation ↘, which
is what happens in step 2 of the transmission, or he receives a photon with

9.5 Quantum cryptography
463
polarisation ↗, as happens in step 7 of the transmission. In the ﬁrst case, the
corresponding digit will be wrong, in the second one it will be correct. So the
probability P of Bob receiving correctly the message is
P = 1
2 · 1 + 1
2 · 1
2 = 3
4 = 75%.
The ﬁrst summand corresponds to the case, having probability 1/2, in which
Bob chooses the correct ﬁlter, while the second one corresponds to the case,
having again probability 1/2, in which the ﬁlter is not the correct one. So the
probability of an error by Bob is 25%. This is also the probability of anybody
else committing an error, including Eve, if she taps the transmission channel
without authorisation and tries to read the message.
The table above demonstrates what we have been saying: Bob’s errors in
choosing ﬁlters occur in steps 2, 4, 7 and 8 of the transmission, that is, in one
half of the cases, while there is an error in the received message only in steps
2 and 4 of the transmission, that is, in one quarter of the cases.
Now, the message has been transmitted and, in order to do so, Alice and
Bob have used in an essential way quantum properties. However, due to the
presence of errors, they cannot stop here. These errors, as we are going to
see, can be removed, and their existence is in fact crucial to discover potential
attempts of eavesdropping by Eve. So we need further steps in the protocol.
Step 2: communicating through an unprotected channel to remove errors and
extract the raw key.
In this step Alice and Bob, before worrying about potential attempts of
eavesdropping by Eve, act to detect and remove the errors made by Bob
in receiving the message, that is to say, in choosing ﬁlters. If there were no
attempts of eavesdropping, the resulting message, with the errors removed,
could be used as the key for a Vernam’s cipher. But as Alice and Bob cannot
be certain that Eve did not interfere, the key they obtained, called a raw key,
could be both insecure and erroneous. So a further step is needed in order to
verify the possible presence of interferences.
Removing the errors committed by Bob is easy. Indeed, now both Alice
and Bob know each a part of the information: Alice knows the string of photon
polarisations sent to Bob, while Bob knows which ﬁlters he chose for each of
them. Then by using a possibly insecure channel, like email or telephone, Bob
lets Alice know which ﬁlters (+ or ×) were used and Alice tells him which
ones were the right ones. After this exchange of information, Alice and Bob
delete in both the sent and the received message all digits corresponding to
the positions in which Bob used a wrong ﬁlter. In the remaining positions Bob
did not commit errors, so if there are no intrusions in the quantum channel,
the remaining part of the message, the raw key, is the same for Alice and
Bob. In the example we are studying, which continues the one of the previous
tables, Bob communicates to Alice the ﬁlter sequence

464
9 The future is already here: quantum cryptography
+
×
×
+
+
×
×
×
and Alice lets him know that Bob only used the right ﬁlter in steps 1, 3, 5 and
6 of the transmission. So, deleting from the sent and received messages the
digits in positions 2, 4, 7 and 8, which correspond to the wrong ﬁlters used
by Bob, they deduce the raw key
1
1
1
0,
which is kept secret. Notice that in exchanging information about the errors
committed by Bob, he and Alice do not disclose to Eve, were she to illicitly
listen in on the insecure channel, any information about the raw key. Indeed,
if Eve did not tamper with the quantum channel, her knowing that in steps
1, 3, 5 and 6 of the transmission Bob used the right ﬁlter on the photon sent
by Alice does not give her any information about the photons actually sent,
so the corresponding digits, which make up the raw key, remain secret.
Step 3: communicating on an unprotected channel to verify Eve’s presence.
Now Alice and Bob must ascertain whether Eve tried to eavesdrop on
the quantum channel or not. Recall that if Eve only eavesdropped on the
unprotected channel over which they communicated in step 2, this has no
importance at all. If no intrusion occurred, Alice and Bob may use the raw
key, or a part of it, as the key for a Vernam’s cipher. If on the other hand an
intrusion occurred, Alice and Bob have to throw everything away and start
afresh, in the hope that Eve grows tired of eavesdropping, or they should use
a more secure quantum channel.
To understand how to proceed in this step, some remarks are in order.
Notice ﬁrst that detecting whether an attempt of eavesdropping occurred is
the reason why Alice and Bob use both rectilinearly and diagonally polarised
photons. Indeed, if they only used rectilinearly polarised photons, they might
not ﬁnd out an intrusion by Eve, as she could intercept Alice transmission
with a 100% accuracy, using for instance a vertical ﬁlter, and then mimic
Alice by sending again the same data to Bob. Such a strategy on the part of
Eve is called opaque eavesdropping.
By contrast, as we are going to see, the use by Alice and Bob of two
diﬀerent kinds of polarisation for the photons makes any eavesdropping by
Eve plain. Indeed, if Eve listens in on the quantum channel and wants to read
Alice’s message, she must ﬁrst measure the polarisation of the transmitted
photons. As she is now in the same conditions as Bob, she has no choice but
to proceed like him, which forces her, as we know, to committ some error. So,
if she later resends Bob the message she read, the message she sends will be
diﬀerent from the one Alice sent, that is to say, it will contain some errors,
so Alice and Bob, comparing their raw keys, have a good chance of detecting
any eavesdropping.
To give a mathematical formulation to what we have been saying, notice
that an attempt of eavesdropping by Eve has an immediate eﬀect on the

9.5 Quantum cryptography
465
probability of the presence of errors in the message received by Bob, which
has been computed in step 1 to be equal to P = 1/4.
Assume Eve interferes with probability s, with 0 ≤s ≤1, that is, s is the
proportion of photons Eve tampers with when eavesdropping on Alice and
Bob. If s = 0, this means that Eve never interferes, while s = 1 means that
Eve measures every photon Alice sends to Bob. Intermediate values of s mean
that Eve sometimes listens on, sometimes does not.
Due to the randomness hypotheses we made, Bob’s and Eve’s choices when
using ﬁlters are independent of each other and of the polarisations chosen by
Alice when sending photons, so an error in the message received by Bob may
occur only if:
•
Bob is wrong, which as we know happens with probability 1/4, and Eve
does not interfere, which has a probability equal to 1 −s;
•
Bob is correct, which happens with probability 3/4, but Eve interferes,
with probability s, and causes an error in the choice of the ﬁlter, which in
turn causes an error in the received message with probability 1/2.
In conclusion, the new error probability P ′ when Bob receives the message
is given by the formula
P ′ = 1
4(1 −s) + 3
4 · 1
2s = 1
4 + s
8.
For instance, if s = 1, that is, if Eve interferes each time, then Bob’s error
probability of 1/4 becomes 3/8, a substantial and appreciable increase.
Let us understand how this reﬂects on the probability that there are dis-
crepancies between Alice’s and Bob’s raw key: recall that, when Eve interferes,
these keys could be diﬀerent. So there is a discrepancy only if Eve interferes,
and this happens with probability s. In this case Eve commits a mistake in
choosing the ﬁlter with probability 1/2, and an error occurs in the message
with probability, again, 1/2. In conclusion, the probability PK of discrepancy
between the two keys is
PK = 1
2 · 1
2s = s
4.
This argument leads us to understand how Alice and Bob may act to detect
Eve’s potential presence. As every discrepancy between Alice’s and Bob’s raw
keys is due to Eve’s presence, they will be certain of Eve’s eavesdropping even
if they ﬁnd a single discrepancy. So they ﬁx, by communicating through the
insecure channel, a random m-digit subset of their raw keys, which might
now be diﬀerent, and compare these digits, again communicating through
the insecure channel. If Eve interfered, they will ﬁnd about ms/4 diﬀerences
between the two keys. So, if m is very large, it makes sense to foresee that
Alice and Bob will sooner or later ﬁnd a discrepancy, thus becoming certain
of Eve’s interference.

466
9 The future is already here: quantum cryptography
For instance, if they estimate the probability of Eve eavesdropping around
s ≤1/1000, by comparing 20, 000 digits of the raw key they may expect to
ﬁnd about 5 discrepancies.
If, on the other hand, Alice and Bob found no discrepancies in any of the
m digits they have chosen, the probability of Eve having interfered without
her interference being detected is

1 −s
4
 m
.
If m is very large, this probability is very low. For instance, if s = 1 and
m = 150, we have
3
4
150
< 2−50,
a very small number.
In conclusion, if after this check Alice and Bob are reasonably, even if not
completely, conﬁdent that Eve did not interfere, then they may use as the key
for a Vernam’s cipher what remains after deleting from the raw key the m
digits used up during the check. If, on the other hand, they ﬁnd a discrepancy
between the two raw keys, so they know that Eve interfered, they must start
over. This is not pleasant, but it is better than laying themselves open to
Eve’s spying.
Before concluding, there are some ﬁnal remarks about the BB84 protocol.
What we have been describing here gives only its basic traits, leaving out the
technical issues emerging when actually implementing it, which in turn leads
to further interesting theoretical problems. Without giving details, it is useful
to sketch the most important questions of this kind, referring the reader to
the article [9] for further information.
The main problem lies perhaps in the fact that the model we outlined does
not consider the potential errors that might occur during the transmission of
the photons through the quantum channel, that is errors due to noise in the
channel. This is, in other word, a noiseless model. To remedy the presence of
noise, it is possible to use the coding theory techniques discussed in Chapter
8. It is not possible, however, to completely ignore errors due to noise, and
their presence seriously jeopardises step 3 of our protocol, as it may induce
Alice and Bob to believe that Eve interfered even if she did not, so it might
block the communication between them. This problem may be obviated by
estimating the measure in which noise aﬀects the error probability in the
raw key, and then proceeding as in step 3 to determine whether Eve really
interfered or not. The procedure for determining a common key without errors
due to noise, after Alice and Bob ascertained that Eve did not eavesdrop, is
more complex. We do not describe it, referring instead to [8].
Another important technical problem is as follows: in the protocol outlined
above it is vital for the transmission to send one photon at a time. This is a
very complex operation, which is virtually impossible when transmitting in

A9 Theoretical exercises
467
a vacuum or, even worse, through air. The way to manage it is transmitting
through an optical ﬁbre, and this presently limits the practical realisation of
this system. Anyway, imagine sending, rather than a single photon at a time,
beams of polarised light consisting of many photons. This immediately lay
Alice and Bob open to Eve’s eavesdropping. Indeed, she could subtract one
of the photons from each photon packet, measure it, sending the remaining
ones the Bob with no alteration. Clearly, this thwarts the search for Eve’s
interferences in step 3 of the protocol. Of course, the reader may think, when
Bob detects a missing photon among those sent by Alice he realises from this
that Eve stepped in. This is true, but only if the number of photons sent by
Alice in each ray is low. Otherwise, it is very diﬃcult on the part of Bob to
estimate the absence of a single photon from each packet and, even if he were
able to do so, he might ascribe the fact to a natural loss of photons due to
the transmission medium.
In any case, quantum cryptography, unlike quantum computer which is
presently only hypotethical, actually exists. C. Bennet and J. Smolin, in 1988,
have brought about a ﬁrst system to send keys using the BB84 protocol. At
the time, they could only send messages over a distance of a few centimetres.
Presently, by using optical ﬁbres, it is possible to send messages over quite
long distances. For instance, in 1995, researchers of the University of Geneva
were able to send numerical keys with the BB84 protocol over a distance of 23
kilometres. Research is presently carried out about the possibility of sending
messages through air or via satellite. So, as we have often seen in history so
far, cryptologists are once more at an advantage over cryptanalysts. And this
time the gap appears to be unbridgeable!
Appendix to Chapter 9
A9 Theoretical exercises
A9.1. Prove that the number of random r-letter keys out of an alphabet of length
k is kr.
A9.2. Let V be a real [complex, resp.] vector space of dimension n endowed with a
scalar [hermitian, resp.] product. Let v1, . . . , vn be an orthonormal system of vectors,
that is to say, ⟨vi, vj⟩= 0 if 1 ≤i < j ≤n while ⟨vi, vi⟩= 1, for all i = 1, . . . , n.
Prove that v1, . . . , vn is a basis of V and that for every vector v ∈V we have
v = ⟨v, v1⟩v1 + · · · + ⟨v, vn⟩vn.
A9.3. In the same hypotheses as the previous exercise, prove that if v = a1v1 +
· · · + anvn e w = b1v1 + · · · + bnvn, then we have
⟨v, w⟩= a1b1 + · · · + anbn,
[⟨v, w⟩= a1b1 + · · · + anbn , resp. ].
A9.4. In the same hypotheses as the previous exercise, prove that

468
9 The future is already here: quantum cryptography
||v|| = ⟨v, v⟩= |⟨v, v1⟩|2 + · · · + |⟨v, vn⟩|2
and consequently that
|v| =

||v|| =

|⟨v, v1⟩|2 + · · · + |⟨v, vn⟩|2.
A9.5.* Extend Cauchy–Schwarz inequality to an arbitrary real vector space V of
dimension n endowed with a positive-deﬁnite scalar product V × V →R, that is,
such that v × v ≥0 with equality holding only if v = 0.
A9.6.* Extend Cauchy–Schwarz inequality to an arbitrary complex vector space V
of dimension n endowed with a positive-deﬁnite hermitian scalar product (see [13],
Ch. 18) V ×V →C, that is, such that v ×v ≥0 with equality holding only if v = 0.
A9.7.* Extend the constructions given in section 9.4 to an arbitrary complex vector
space of dimension n endowed with a positive-deﬁnite hermitian scalar product.
A9.8. Prove that if two observables A, B in a real or complex vector space of
dimension n commute, then A · B and B · A are observables too.
A9.9. Give an example of two noncommuting observables A, B whose product is
not an observable.
A9.10.* Prove that if A ad B are observables in a real or complex vector space of
dimension n, they have a common orthonormal basis consisting of eigenvectors if
and only they commute.
A9.11. Write the equation of an observable acting as a ﬁlter of type ×.
B9 Computational exercises
B9.1. Mimicking Example 9.3.2, send the message NOON using a Vernam’s cipher
with key UCDP.
B9.2. Consider the ciphertext obtained in the previous exercise and ﬁnd the key
with which it would be eciphered as DAWN.
B9.3. Assume that in exercise B9.1 the sender uses again the key UCDP to send
the message MOON and that a cryptanalyst knows that the letter O appears twice
in both messages. What may the cryptanalyst deduce about the key?
B9.4. Mimicking Example 9.3.2, send the message TOMORROW AT NOON using
a Vernam’s cipher with key PDTKCDPTMFTGTQ.
B9.5. Consider the ciphertext obtained in the previous exercise and ﬁnd the key
with which it would be deciphered as EAT TWO PORK PIES.
B9.6. Verify that the product of the two observables
A =
 1 1
1 0

,
B =
 0 1
1 1

over C2 is not an observable. Are the two observables compatible?
B9.7. Write the commutator [B, A] of the observables of the previous exercise.
B9.8. Determine the eigenvalues and the eigenvectors of the observables deﬁned in
Exercise B9.6.

C9 Programming exercises
469
C9 Programming exercises
C9.1. Write a program that produces a Vernam’s cipher.
C9.2. Write a program that veriﬁes whether the product of two observables is an
observable.
C9.3. Write a program that veriﬁes whether two observables are compatible.
C9.4. Write a program that simulates the transmission of a key using the BB84
protocol.

Solution to selected exercises
Exercises of Chapter 1
A1.1. The basis of induction, that is, property 1 of (CI), is the same as for math-
ematical induction. Property 2 of (CI) is weaker than 2 of mathematical induction,
so if (CI) is true, mathematical induction is true a fortiori.
A1.2. Assume by contradiction that there is a non-empty subset T of N that has
no least element. Let A be the complement of T in N. Then 0 ∈A, or else 0 would
be the least element in T. Moreover, if n ∈A, then n + 1 ∈A as well, or else n + 1
would be the least element in T. Then, by mathematical induction, A = N, against
the hypothesis that T is non-empty.
A1.3. Let A be a non-empty subset of N that satisﬁes the two properties of (CI),
where we assume, for the sake of simplicity, n0 = 0. Assume by contradiction that
A is not equal to N. Then the complement U of A is not empty, so it has a least
element m ∈U by the well-ordering principle, with m ̸= 0 because 0 ∈A. As m
is the least element of U, for all k such that 0 ≤k < m we have k ∈A, so from
property 2 it follows that m ∈A, yielding a contradiction.
A1.5. The correct answer is (d). It is necessary to deﬁne mathematically what we
mean by a “small city”, or else neither the basis of the induction nor the inductive
step make sense.
A1.6. The correct answer is (c); indeed, the inductive step does not hold for n =
49, 999.
A1.8. Recall that in the proof of Proposition 1.3.1 we have assumed b > 0. Assume
further that a ≥0. Consider the subset S = { n | (n + 1)b > a } of N. Clearly S is
not empty, because for instance a ∈S. So, by the well-ordering principle, S has a
least element, which will be called q. Then (q + 1)b > a, because q ∈S, and qb ≤a,
or else we would have q −1 ∈S, contradicting the fact that q is the least element of
S.
A1.9. Let A be the set of the ns for which we may compute an. Then A satisﬁes the
two properties of mathematical induction, so for all n > n0 we have n ∈A, while
n ∈A for n = 1, 2, . . . , n0 by hypothesis.

472
Solution to selected exercises
A1.12. The claim is true for n = 1. Suppose the number of elements of Sn−1 is
(n −1)!. Deﬁne the mapping f : Sn →Sn−1 that maps the permutation having
symbol (i1, . . . , in) to the permutation having the symbol obtained deleting n from
(i1, . . . , in). Prove that f is surjective and that the preimage of every element of
Sn−1 consists of n elements of Sn. Deduce that the number of elements of Sn is n!.
A1.13. The correct answer is (c). Indeed, a function between sets having the same
(ﬁnite) size is injective if and only if it is bijective, and this happens if and only if it
is surjective. So we prove by induction on n that there are n! bijective functions from
A to B. The basis of the induction, for n = 1, is trivial. Assume that A and B have
n + 1 elements. Fix an element a ∈A. Then there are n + 1 possible choices for the
image of A under a function f. Now, if f is bijective, then f : A\{a} →B\{f(a)} is
bijective too, and by the inductive hypothesis there are n! such bijective functions.
So there are n! · (n + 1) = (n + 1)! bijective functions from A to B.
A1.14. The reader might want to prove Formula (1.51) by induction on n. We give
here a direct proof. Start with the identity
n + 1
k(n −k + 1) = 1
k +
1
n −k + 1.
Multiplying both sides by
n!
(k −1)!(n −k)! we obtain
(n + 1)!
k!(n −k + 1)! =
n!
k!(n −k)! +
n!
(k −1)!(n −k + 1)!,
that is, Formula (1.51), as wanted.
A1.15. The claim is true if n = 1. Notice next that the subsets of size m of In that
include n are as many as the subsets of size m −1 of In−1, while the subsets of size
m of In that do not include n are as many as the subsets of size m of In−1. Apply
now the inductive hypothesis and Formula (1.51).
A1.19. The correct answer is (c). We have assumed n ≤m, else, if n > m there
would be no injective functions A →B.
A1.20. The correct answer is (a), as may be proved by induction, or directly by
noticing that for every element a of A there are m possible choices for its image.
A1.21. It suﬃces to remark that every ordered m–tuple of elements of A determines
a mapping from Im to A; apply then the previous exercise.
A1.22. The correct answer is (b). Indeed, given a subset Y of X, consider the
function fY : X →I2, called characteristic function of Y , that takes the value 1
on all elements of Y and nowhere else. Prove that the mapping associating with
Y ∈P(X) its characteristic function is a bijection of P(X) in the set of mappings
from X to In. Apply then Exercise A1.20.
A1.24. The formula for s(n, h) is true for n = 1. As to s(n, h) for n > 1, it is
the sum of the number of monomials in which x1 appears to the degree i, for all
i = 0, . . . , h, and this number is s(n −1, h −i). Conclude by applying the inductive
hypothesis and (1.52).
A1.26. In the hypotheses of the exercise we have

Exercises of Chapter 1
473
yn + xn = bk−1yn−1 + · · · + b0yn−k + dn + bk−1xn−1 + · · · + b0xn−k =
= bk−1(yn−1 + xn−1) + · · · + b0(yn−k + xn−k) + dn,
that is, {yn + xn} is a solution of (1.4). Moreover, if zn is another solution of (1.4),
then
yn −zn = bk−1yn−1 + · · · + b0yn−k + dn+
−bk−1zn−1 −· · · −b0zn−k −dn =
= bk−1(yn−1 −zn−1) + · · · + b0(yn−k −zn−k),
that is, {yn −zn} is a solution of (1.53).
A1.27. We have
a1 = ba0 + c,
a2 = ba1 + c
which may be interpreted as a linear system in b and c. If a0 ̸= a1, this system
uniquely determines b and c and so the whole sequence starting from a0. If a0 = a1,
also a2 = a1 = a0, else the system would not be compatible, which is not possible.
Prove next by induction that the sequence {an} is constant.
A1.28. The basis of the induction is obvious by the deﬁnition of A and of Fibonacci
numbers fn. Suppose Proposition 1.2.3 is true for n −1 and prove it for n. We have
An = An−1 · A =
(by the inductive hypothesis)
=
fn−2 fn−1
fn−1
fn

·
 0
1
1
1

=
fn−1 fn−2 + fn−1
fn
fn−1 + fn

=
fn−1
fn
fn
fn+1

,
where the last equality follows from Deﬁnition (1.5) of Fibonacci sequence.
A1.30. Fix k and proceed by induction on n. For n = 1, Formula (1.54) becomes
fk+1 = fk+fk−1, which is true. So, assume the truth of the formula for all 0 ≤m < n
and prove it for n. By the inductive hypothesis we have
fn−1+k = fkfn + fk−1fn−1
and
fn−2+k = fkfn−1 + fk−1fn−2;
hence, summing, we get
fn+k = fn−1+k + fn−2+k = fk(fn + fn−1) + fk−1(fn−1 + fn−2) =
= fkfn+1 + fk−1fn.
We want to prove now that fkn is a multiple of fn. Proceed by induction on k. For
k = 1 this is obvious. Assume that fmn is a multiple of fn for all m ≤k and prove
it for k + 1. The previous relation implies
f(k+1)n = fkn+n = fknfn+1 + fkn−1fn,
so, by the inductive hypothesis, both fn and fkn are multiples of fn, so f(k+1)n is
too.
A1.31. Proceed by induction on n, the result being trivial for n = 1. Assume the
result to be true for every integer smaller than n and prove it for n. If n is a Fibonacci
number, the result is true. If fk < n < fk+1, then 0 < n−fk < fk+1 −fk = fk−1. By

474
Solution to selected exercises
induction, n−fk is a sum of distinct Fibonacci numbers, n−fk = fk1 +fk2 +· · ·+fkr.
So, n = fk + fk1 + fk2 + · · · + fkr is a sum of distinct Fibonacci numbers.
A1.33. For n = 1, Formula (1.55) is true. Deﬁne λ = (1 +
√
5)/2, assume Formula
(1.55) to be true for all m < n and prove it for n. We have fn = fn−1 + fn−2 ≥
λn−3 + λn−4 = λn−4(λ + 1) = λn−4λ2 = λn−2.
A1.34. The result is obtained by summing the following relations:
f1 = f2,
f3 = f4 −f2,
f5 = f6 −f4,
...
f2n−1 = f2n −f2(n−1).
A1.36. We know that there are q′, r′ such that a = q′b + r′, with 0 ≤r′ < |b|. If
r′ ≤|b|/2, set q = q′, r = r′. If not, set q = q′ + |b|/b and r = r′ −|b| and verify that
a = qb + r. As we are assuming r′ > |b|/2, we have 0 > r > |b|/2 −|b| = −|b|/2. The
task of verifying the uniqueness is left to the reader.
A1.37. Let d = GCD(b, c). Then d | b and d | c, so d | a. But then d, which divides
both a and b, must be invertible.
A1.38. Using B´ezout’s identity, verify that b divides 1 and is so invertible.
A1.39. The subset S is not empty (why?), so it has a least element d by the well-
ordering principle.
A1.41. Let (¯x, ¯y) be an integer solution of (1.18). Let (x0, y0) be a solution of
ax + by = 0, that is, a pair such that ax0 + by0 = 0. Then (¯x + x0, ¯y + y0) is a
solution of (1.18). Indeed,
a(¯x + x0) + b(¯y + y0) = a¯x + b¯y + ax0 + by0 = c + 0 = c.
Vice versa, let (¯x, ¯y) and (x′, y′) be two solutions of (1.18). Then
a(¯x −x′) + b(¯y −y′) = a¯x + b¯y −ax′ −by′ = c −c = 0,
so (x′, y′) diﬀers from (¯x, ¯y) by a solution of the associate homogeneous equation
ax + by = 0.
A1.42. Notice that q represents the largest integer such that q · 365 is not greater
than a, so q is the integer number 338. To determine r, it suﬃces to observe that
r = a −bq, so
r = 123456 −338 · 365 = 86.
A1.44. If both d and d′ are greatest common divisors of a and b, we have d | d′
and d′ | d. So d and d′ are associate. On the other hand, if d = GCD(a, b) and if
d′ is associate to d, then d′ | a and d′ | b and moreover d′ | d, which implies that
d′ = GCD(a, b).
A1.46. Notice that (x) = (y) if and only if x | y and y | x.

Exercises of Chapter 1
475
A1.51. It suﬃces to prove that it has no zero-divisors. Let p(x) = n
i=0 aixi and
q(x) = m
j=0 bjxj be two non-zero polynomials (so they have at least one non-zero
coeﬃcient). Assume that ∂p(x) = n and ∂q(x) = m; this means that an ̸= 0 and
bm ̸= 0. From the deﬁnition of product polynomial p(x)q(x), it follows that the
coeﬃcient of xm+n is anbm, which is diﬀerent from zero because an and bm are
diﬀerent from zero and are elements of an integral domain, in which there are no
zero-divisors. So p(x)q(x) cannot be the zero polynomial.
A1.54. By the factor theorem, g(x) = (f(c) −f(x))/(f(c) · (x −c)) is a polynomial,
as f(c) −f(x) is divisible by x −c. Verify that g(x) has degree less than t and that
(x−c)·g(x)−1 is divisible by f(x). This proves the existence. As for the uniqueness,
notice that, if h(x) is another polynomial of degree less than t such that (x−c)·h(x)
is divisible by f(x), then (x −c) · (g(x) −h(x)) is divisible by f(x) too. As f(x) is
relatively prime with x −c, f(x) should divide g(x) −h(x). The polynomials g(x)
and h(x) having both degree less than t, the same holds for g(x)−h(x), so the only
possibility is g(x) −h(x) = 0. This proves the uniqueness.
A1.55. Proceed by induction on n. If n = 0, then f(x) is a non-zero constant, which
has no roots, so the thesis is trivial and the basis of induction is proved. Suppose
then the thesis is true for every polynomial of degree less than n. Let f(x) be a
polynomial of degree n. If f(x) has no roots, the thesis is trivial. If f(x) has a root
α, then by the factor theorem we have f(x) = (x −α)q(x), where q(x) has degree
n −1. Moreover, the set of roots of f(x) consists exactly of α and of the roots of
q(x), which by the inductive hypothesis are at most n −1, so f(x) has at most n
roots.
A1.56. Proceed by induction on n. The basis of induction is obvious, because a
linear polynomial has exactly a root. Let n > 1. If we denote by α1 ∈C a root
of f(x) (which is sure to exist, by the Fundamental theorem of algebra) the factor
theorem implies that
f(x) = (x −α1)q(x)
where q(x) still has coeﬃcients in C and ∂q(x) = n −1. So, by the inductive hy-
pothesis, q(x) has exactly n −1 roots α2, . . . , αn and by the factor theorem we
have
q(x) = a(x −α2) · · · (x −αn),
so f(x) has exactly n solutions and
f(x) = a(x −α1)(x −α2) · · · (x −αn).
A1.57. Let f(x) = n
k=0 akxk. Then
0 = f(α) =
n

k=0
akαk;
hence, by conjugating both sides, and observing that real numbers are self-conjugate,
0 = ¯0 = f(α) =

k=0,n
akαk =
n

k=0
ak ¯αk = f(¯α),
that is, ¯α is also a root of f(x).

476
Solution to selected exercises
A1.59. Keeping in mind the linearity of the derivative, it suﬃces to observe that
Leibniz’s law holds for monomials.
A1.64. Assume by contradiction that there is a d > 1 that divides fn and fn+1.
Then it also divides fn−1 = fn+1 −fn. Going backwards, we shall ﬁnd that d divide
f2 = 1, which is impossible.
A1.65. Prove ﬁrst that, if m = nq + r, then GCD(fm, fn) = GCD(fn, fr). We have
the following chain of equalities:
GCD(fm, fn) = GCD(fnq+r, fn) = GCD(frfnq−1 + fr+1fnq, fn),
where the last equality follows from (1.54). Now, fnq is a multiple of fn, so
GCD(frfnq−1 + fr+1fnq, fn) = GCD(frfnq−1, fn).
If we prove that GCD(fnq−1, fn) = 1, we may conclude that GCD(frfnq−1, fn) =
GCD(fr, fn), which was what had to be proved. Let GCD(fnq−1, fn) = d: then
d | fn (so, also, fqn) and fqn−1. As it divides two consecutive Fibonacci numbers, it
must be d = 1.
Having this result, the fact that GCD(fn, fm)=fd, with d = GCD(n, m), is
immediate. Indeed, applying the Euclidean algorithm starting with m and n, and
denoting by rt the last non-zero remainder (which is so GCD(m, n)), we ﬁnd
GCD(fm, fn) = GCD(fr1, fn) = . . . = GCD(frt−1, frt) = frt,
the last equality holding because, as rt divides rt−1, then (by the above) frt divides
frt−1.
A1.66. It has already been proved in Exercise A1.30 that, if n | m, then fn | fm.
We have now to prove the converse, that is to say, fn | fm implies that n | m. Let
fn | fm. Then GCD(fn, fm) = fn. But, by Exercise A1.65, GCD(fn, fm) = fd, with
d = GCD(n, m). So d = n, and if GCD(n, m) = n, this means that n | m.
A1.67. The correct answer is (b). Indeed, for n ≥1, we have the relation
fn+1
fn
= 1 + fn−1
fn ,
so, setting x = limn→∞fn+1/fn, we have
x = 1 + 1
x.
A1.68. For k = 0, rn = 0 = f0 = 0, so the basis of induction is veriﬁed. Assume the
inequality to be veriﬁed for every m such that 0 ≤m < k and prove it for k. From
rn−k = rn−k+1qn−k+2 + rn−k+2,
as the inductive hypothesis is rn−k+1 ≥fk−1 and rn−k+2 ≥fk−2, and as we have
further qn−k+2 ≥1, we get
rn−k ≥fk−1 + fk−2 = fk.

Exercises of Chapter 1
477
A1.69. If a and b (a ≥b) are two integers such that D(a, b) ≥n, this means that the
last non-zero remainder is ≥rn−1, so, using the result of the previous exercise, we
have rn−k ≥fk. In particular, b = r0 ≥fn. So, if b < fn, then certainly D(a, b) < n
must be true.
A1.74. If α = [a0; a1, . . . , an, . . .], with a0 positive integer, we have 1/α =
[1; a0, a1, . . ., an, . . .].
A1.75. Proceed by induction, observing that Ck = [a0; a1, . . . , ak−1, ak + 1/ak+1],
so
Ck =

ak +
1
ak+1

pk−1 + pk−2

ak +
1
ak+1

qk−1 + qk−2
.
A1.76. From formula (1.43) we get
Ck −Ck−2 = (−1)k(qk −qk−2)
qkqk−1qk−2
.
Hence, conclude by using (1.41).
A1.78. The ﬁrst two claims follow from formula (1.44). The third one follows from
formula (1.43).
A1.80. Let √n ∈Q, so √n = p/q, with p/q a reduced fraction. Then we have
p2 = nq2. By applying Corollary 1.3.9 we see that p | n. Deduce that q | p. By
applying Exercise A1.38 deduce that q = ±1 and consequently that n is a square.
A1.84. Keep in mind that a/b = Cn and use formula (2.11).
A1.86. Prove that
|α −Cn+1| + |α −Cn| = |Cn+1 −Cn| =
1
qnqn+1
and conclude from here.
A1.89. We may write α = (a +
√
b)/c with integers a, b, c, b > 0 and c ̸= 0. So
α = (a|c| +
√
bc2)/(c|c|). Set p = a|c|, q = c|c|, d = bc2 and conclude.
B1.1. The correct answer is (d); indeed, n < 2n for all n ∈N. The basis of induction
is true because 0 < 20 = 1. Suppose n < 2n for a natural number n. Then n + 1 <
2n + 1 ≤2n + 2n = 2n+1, where the inequality ≤follows from the fact that 1 ≤2n
for all n ∈N.
B1.2. The correct answer is (a); indeed S(n) may be obtained from S(n −1) by
adding to it the nth odd natural number, that is, 2n −1.
B1.3. The correct answer is (c). The basis of induction is obvious. Suppose the
formula holds for n−1. From Exercise B1.2 we know that S(n) = S(n−1)+ 2n−1,
so from the inductive hypothesis we ﬁnd that S(n) = (n −1)2 + 2n −1 = n2.
B1.6. The correct answer is (b), that is,
n

k=0
(4k + 1) = (2n + 1)(n + 1).
(1)

478
Solution to selected exercises
For n = 0 formula (1) becomes 1 = 1, so the basis of induction is true. Suppose (1)
is true for n and prove it for n + 1:
n+1

k=0
(4k + 1) = 4(n + 1) + 1 +
n

k=0
(4k + 1) = (by the induct. hyp.)
= 4n + 5 + (2n + 1)(n + 1) = (2n + 3)(n + 2).
B1.7. The correct answer is (c), that is
n

k=1
k2 = n(n + 1)(2n + 1)
6
.
(2)
The basis of induction is obvious, because for n = 1 the equation (2) becomes 1 = 1.
Suppose (2) is true for n and prove it for n + 1:
n+1

k=1
k2 = (n + 1)2 +
n

k=1
k2 = (by the induct. hyp.)
= (n + 1)2 + n(n + 1)(2n + 1)
6
= (n + 1)(n + 2)(2n + 3)
6
.
B1.8. The correct answer is (a). Verify it by induction.
B1.9. The correct answer is (c). The basis of induction is trivial. Assume (c) to be
true for n −1 and prove it for n:
n

k=1
(2k)3 = (2n)3 +
n−1

k=1
(2k)3 = (2n)3 + 2(n −1)2n2 =
= 2n2[(n −1)2 + 4n] = 2n2(n + 1)2.
B1.10. The correct answer is (a). The basis of induction is trivial. Assume the result
to be true for n −1. Then n
k=0 2 · 3k = 2 · 3n + (3n −1) = 3n+1 −1.
B1.11. The correct answer is (b).
B1.14. The correct answer is (a).
B1.15. The correct answer is (b).
B1.16. The correct answer is (c), because (103/100)24 is about 2, so there will be
about 2 · 5 = 10 billion people.
B1.17. Deﬁne λ1 = (−1 + i
√
3)/2 and λ2 = (−1 −i
√
3)/2. With the usual method
the eigenvectors relative to λ1, λ2 and 1, respectively, are found:

2λ1, 1, λ2
3

,

2λ2, 1, λ1
3

,
(6, 3, 1).
Deﬁne next
D =
⎛
⎝
λ1
0
0
0
λ2
0
0
0
1
⎞
⎠,
C =
⎛
⎝
2λ1
2λ2
6
1
1
3
λ2/3
λ1/3
1
⎞
⎠.

Exercises of Chapter 1
479
The inverse of C is
C−1 = 1
3
⎛
⎝
λ2/2
1
3λ1
λ1/2
1
3λ2
1/6
1/3
1
⎞
⎠.
We have A = C·D·C−1, so a closed formula is found by multiplying An = C·Dn·C−1
for X0.
B1.18. The correct answer is (a), as can be veriﬁed directly, without using the
closed formula found in Exercise B1.17. Indeed, after one year there will be 120
newborn beetles and 60 one-year beetles (180 altogether). After two years there will
be 60 one-year ones and 20 two-year ones (80 altogether), while after three years
there will be 120 newborn ones and 20 two-year ones (140 altogether), exactly as in
the starting year. So the same situation repeats every third year; hence the result
follows.
B1.19. Two eigenvectors corresponding to 1 and 7/10, respectively, are (2, 1) and
(−1, 1). Set
C =
 2 −1
1
1

,
quindi
C−1 = 1
3

1 1
−1 2

.
So we may compute
An = C ·
 1
0
0
(7/10)n

· C−1 = 1
3
 2 + (7/10)n
2 −2(7/10)n
1 −(7/10)n
1 + 2(7/10)n

;
hance it is possible to compute Xn multiplying by X0.
B1.20. The correct answer is (d), because there will be 5 million inhabitants, as
may also be directly veriﬁed, without applying the formula found in Exercise B1.19.
B1.21. The correct answer is (c). Let S(n) be the number sought. We have S(1) = 2.
Moreover, given n lines in general position, forming S(n) regions, one more line, in
general position with respect to the other ones, intersects them in n points, so meets
n+1 regions, dividing each into two parts. The number of regions, with those added
after the (n+ 1)th line increases by n+ 1. So we have S(n+ 1)−S(n) = n+ 1. From
here it is easy to conclude.
B1.22. The correct answer is (d). Reasoning as in the previous exercise, prove that
the right answer is n2 −n + 2.
B1.23. By induction on the number n of all lines. If n = 1, clearly two colours
suﬃce. Suppose then we have proved that it is possible to colour with just two
colours the regions formed by less than n lines, and prove it in the case in which
the nth line, r, is added. Divide the regions into two groups, depending on which
side of r they are on. Then it suﬃces to leave the colour of those on one side as it
was, and to change the colour of those on the other side. We have to verify that
this is a “good” colouring: indeed, if two bordering regions are on the same side
with respect to r, they will have diﬀerent colours (they had diﬀerent colours before
the appearance of r, and now, either they both keep their colours or the colours are
changed in both, but in any case will be diﬀerent). If the two regions are on diﬀerent
sides with respect to r, their colours are diﬀerent because one of them has had its
colour changed.

480
Solution to selected exercises
B1.24. The correct answer is (a), because every third month Mark gets a 1% interest,
which so becomes 4,060401% yearly.
B1.28. The correct answer is (a). Indeed, the roots of the characteristic equation of
the recurrence relation are 2 and −1. So the solution has the form c12n + c2(−1)n,
where c1 and c2 are determined by the initial values a0 = 2 = c1 + c2 and a1 = 7 =
2c1 −c2.
B1.29. The correct answer is (a). Indeed, a solution is found to be of the form
−n −7.
B1.32. The correct answer is (a).
B1.33. The correct answer is (c).
B1.34. The correct answer is (a). Indeed, 491 = 2 · 245 + 1 and 245 = 245 · 1 + 0.
B1.35. The correct answer is (b), because the Euclidean algorithm ends after just
two steps, as shown in the solution of Exercise B1.34.
B1.37. We have 34567 = 457 · 76 −165, then 457 = (−165)(−3) −38, after which
−165 = (−38) · 4 −13, then −38 = (−13) · 3 + 1 and ﬁnally −13 = 1 · (−13) + 0.
B1.38. The correct answer is (a).
B1.39. The correct answer is (c). Indeed 28762 = 18 · 1515 + 1492, then 1515 =
1492 + 23, hence 1492 = 64 · 23 + 20, then 23 = 20 + 3, 20 = 6 · 3 + 2, 3 = 2 + 1 and
ﬁnally 2 = 2 · 1 + 0.
B1.40. The correct answer is (c), as the solution of Exercise B1.39 shows.
B1.42. The correct answer is (b). There are integer solutions because GCD(92, 18) =
4 and 4 divides 180. Using the Euclidean algorithm to ﬁnd the GCD it is possible
to ﬁnd B´ezout’s identity
4 = 92 · (−3) + 28 · 10;
hence
180 = 45 · 4 = 92 · (−135) + 28 · 450
so a solution is (¯x, ¯y) = (−135, 450). To ﬁnd all solutions, consider the associate
homogeneous equation:
0 = 92x + 28y = 4(23x + 7y).
It admits as its solutions the pairs (x0, y0) = (−7t, 23t), with t ranging in Z. So all
the solutions of 92x + 28y = 180 are the pairs
(x, y) = (−135 −7t, 450 + 23t),
for all t ∈Z.
B1.43. The correct answer is (a); indeed, there are no integer solutions because
GCD(482, 20) = 2 ∤35.
B1.47. The correct answer is (c), as the leading coeﬃcient, that is to say, the
coeﬃcient of the highest degree term, is −3 ̸= 1.
B1.48. The correct answer is (b).

Exercises of Chapter 1
481
B1.49. The correct answer is (d), because −x−1 is only a greatest common divisor,
but the greatest common divisor of the two polynomials is x + 1.
B1.51. The correct answer is (b).
B1.52. The correct answer is (d), because the greatest common divisor of these
polynomials is x + 1 (see Exercise B1.49), and if h(x), k(x) are the polynomials
appearing in B´ezout’s identity, then f(x) = 4h(x) and g(x) = 4k(x).
B1.53. The correct answer is −25x4 −8x3 + 9x2, hence (d).
B1.55. The greatest common divisor is 1 + i.
B1.56. In base 10, the two factors of the multiplication are 29 and 13, while the
result is 377, so the operation is correct.
B1.59. The correct answer is (a).
B1.60. The correct answer is (a).
B1.61. The correct answer is (c).
B1.62. The correct answer is (d), because the sum is 10110100, while the product
is 1000100011011.
B1.63. The correct answer is (c).
B1.64. The correct answer is (b).
B1.65. The correct answer is (c).
B1.66. 40/99.
B1.67. 2491/45.
B1.68. 101/111.
B1.69. 10001001/11000.
B1.70. 40/66 = 10/15.
B1.71. 10342/60 = 3521/30.
B1.72. 2, 3.
B1.73. 4, 1254.
B1.74. 11, 10.
B1.75. The correct answer is (d), because the continued fraction is [1; 3, 1, 10, 2].
B1.76. The correct answer is (a).
B1.77. The correct answer is (d), because the continued fraction is [1; 1, 1, 1, 13,
2, 2], which consists of 7 terms.
B1.81. The continued fraction of α may be written as follows:
α = 4 +
1
1 +
1
3 + 1
α
.

482
Solution to selected exercises
Developing fractions, we get the equation
α = 19α + 5
4α + 1
which is equivalent to the second degree equation 4α2 −18α −5 = 0, so
α = 9 +
√
101
4
.
B1.82. The correct answer is (d), because the continued fraction is [5; 5, 10].
Exercises of Chapter 2
A2.1. By hypothesis we have f(x) ≤k1g(x) for x > c1 and g(x) ≤k2h(x) for
x > c2. Then, having set c3 = max{c1, c2}, we ﬁnd that
f(x) ≤k1g(x) ≤k1k2h(x) = k3h(x)
for x > c3, where k3 = k1k2.
A2.5. For n even, we have that f(n)/g(n) = 2n+1 and so limm→∞f(2m)/g(2m) =
∞. On the other hand, for n odd we have f(n)/g(n) = 1/(2n+1), so limm→∞f(2m+
1)/g(2m + 1) = 0. It can be found analogously that limm→∞g(2m)/f(2m) = 0 and
limm→∞g(2m + 1)/f(2m + 1) = ∞. So we deduce that those limits do no exist.
A2.8. The correct answer is (c).
A2.9. The correct answer is (a). Indeed, by observing that all factors of n! have
length less than or equal to L(n) and using the previous exercise, we conclude that
L(n!) ≤nL(n) ∈O(n ln n) = O(nk).
Notice that this estimate can be improved, as many factors of n! have length less
than the length of n.
A2.10. None of (a), (b), (c) is a reasonable estimate. Indeed,
 n
m
	
is the ratio of
the two numbers n(n −1) · · · (n −m + 1) and m! having length O(mh) and O(mk),
respectively. So the length of
 n
m
	
is O(mh −mk), so it is O(mh) as well.
A2.15. Let a/b be the number being considered. We may assume a > b. Developing
a/b as a continued fraction is equivalent to searching GCD(a, b), which requires
O(log3 a) bit operations.
A2.16. We have to verify the relation
p(x) = (x −α)(pnxn−1 + p1(α)xn−2 + · · · + pn−2(α)x + pn−1(α)) + p(α),
which can be easily done keeping in mind Table (2.14) and the meaning of its second
row.
A2.18. Every n × n matrix has n2 entries. We have to carry out n multiplications
and n additions for each of them: so, in all, n3 multiplications and n3 additions are
to be carried out. So the algorithm has complexity O(n3(log2 m + log n)).

Exercises of Chapter 3
483
A2.20. See [13], Cap. 24, §1.
A2.21. Apply ﬁrst Exercise A2.20 to reduce the matrices in row echelon form and
notice that the determinant of the matrix is the product of the pivot elements (see
[13], Cap. 8).
A2.22. Hint: use Gaussian algorithm to compute the inverse (see [13], pag. 146).
A2.23. The correct answer is (c). Indeed, to compute n! we have to carry out
successively n multiplications of two integers whose length can be estimated with
that of n (which is k) and with that of n! (which is nk).
A2.24. A reasonable estimate is O(m2 log2 n). Keep in mind what was said in the
solution to Exercise A2.10.
A2.25. A reasonable estimate is O(n2 log2 m). Indeed, the length of mn is O(n log m)
and to compute mn it is necessary to carry out n multiplications of two integers
whose length can be estimated with that of m (which is O(log m)) and with that of
mn (which is O(n log m)).
B2.1. The correct answer is (b). In fact, (a) is an estimate of the complexity of f(n)
too, but one which is worse than (b).
B2.2. The correct answer is (d); indeed, log n is negligible with respect to n
B2.7. The correct answer is (c).
B2.13. The correct answer is (b).
B2.14. The correct answer is (b).
B2.17. The correct answer is (c).
B2.19. The correct answer is (b).
B2.21. The correct answer is (c). Each squaring requires at most O(log2 n) bit
operations, and it is necessary to carry out n of them, so obtaining the estimate
O(n log2 n). The computation time of additions is negligible with respect to this
one.
B2.22. The correct answer is (c).
B2.23. The correct answer is (c).
B2.24. The correct answer is (a); indeed, 1176 = 159 · 7 + 63, 159 = 63 · 3 −30,
63 = −30 · (−2) + 3 and −30 = 3 · (−10) + 0.
Exercises of Chapter 3
A3.1. For every integer a, a −a = 0 is a multiple of n for any n, so a ≡a (mod n),
that is to say, congruence modulo n is a reﬂexive relation. We prove next that this
relation is symmetric. If a ≡b (mod n), this means that a−b = hn, for some h ∈Z;
hence follows that b −a = −(a −b) = −(hn) = (−h)n, which proves that b ≡a
(mod n). Finally, if a ≡b (mod n) and b ≡c (mod n), this means that a −b = hn
and b −c = kn with h, k ∈Z, so a −c = (a −b) + (b −c) = hn + kn = (h + k)n,

484
Solution to selected exercises
which implies that a ≡c (mod n). So we have proved that congruence relation is
transitive too, for all n, so it is an equivalence relation.
A3.2. Let A = {a, b, c} be a set consisting of three distinct elements. Con-
sider the relation R on A deﬁned as follows: R = {(a, a), (b, b), (c, c), (a, b), (b, a),
(b, c), (c, b)}. Clearly, R is reﬂexive and symmetric, but is not transitive as a R b
and b R c, while it is not true that a R c, so R is an example of a). Consider now
R′ = {(a, a), (b, b), (c, c), (a, b)} over the same A. Clearly, R′ is reﬂexive and transi-
tive but not symmetric, because a R′ b but it is not true that b R′ a. Other examples
of relations of type b) are order relations on sets with at least two distinct elements.
Finally, consider the set B of the students in a same secondary school form, and let
the relation R′′ be deﬁned on B as follows: a R′′ b if and only if a and b got the same
mark in the ﬁrst maths test this year. The relation R′′ is clearly symmetric and
transitive, but is not necessarily reﬂexive, as some student might have been absent
the day of the test. Clearly the relation R′′ is an equivalence relation if we do not
take it on the whole set B, but only on the subset of B consisting of the students
who actually took the test.
A3.3. It is the relation being a divisor of, which we have denoted by |, that is, a R b
if and only if a | b. Clearly, a = 1 · a for all a ∈N, so a | a and | is a reﬂexive
relation. Moreover, it is transitive, because if a | b and b | c, then b = ah and c = bj,
so c = a(jh), that is a | c. Suppose now a | b and b | a for two natural numbers a
and b. Then there exist h, k ∈N such that a = bh and b = ak, so a = a(hk) and,
cancelling out a, we ﬁnd hk = 1, which in N implies that h = k = 1, that is a = b
and | is antisymmetric. So we have shown that | is an order relation in N. In Z, on
the other hand, we cannot conclude from hk = 1 that h = k = 1, because we might
also have h = k = −1, so | is not antisymmetric (nor an order relation) in Z.
A3.11. If ac = bc with c ̸= 0, then (a −b)c = 0. In an integral domain (and in
particular in Z) there are no zero-divisors, so a −b = 0, that is a = b.
A3.14. The correct answer is (b). Indeed, a ﬁnite commutative ring with unity is a
ﬁeld if and only if it is an integral domain (see Exercise A1.48).
A3.15. The correct answer is (a).
A3.17. Consider the coeﬃcients of the two polynomials as numbers in {0, . . . , n},
so they have length bounded by the length of n. To sum the two polynomials we
need at most m + 1 sums of such numbers and then reducing modulo n. But as the
coeﬃcients so obtained are bounded by 2n, to reduce them modulo n it suﬃces to
carry out at most one subtraction. From this it is possible to deduce the claim.
A3.18. Consider the coeﬃcients of the two polynomials as numbers in {0, . . . , n},
so they have length bounded by the length of n. By applying Proposition 2.5.9,
verify that the product of the two polynomials has complexity O(m2 log2 n). As the
coeﬃcients of the polynomial so obtained have to be reduced modulo n, from this
it is possible to deduce the claim.
A3.19. It suﬃces to recall that a number is congruent modulo 11 to the sum of its
decimal digits, taken with alternate signs, starting from the rightmost one. Then
proceed as when casting out nines.
A3.24. If G is cyclic with generator x, there is a surjective homomorphism n ∈Z →
xn ∈G. If G is inﬁnite, this is an isomorphism. If not, G is a quotient of Z.

Exercises of Chapter 3
485
A3.25. If G is cyclic with generator x and if H is a non-trivial subgroup, let n be
the smallest positive integer such that xn ∈H. Using the division algorithm, prove
that xn is a generator of H.
A3.27. Suppose m divides n. Then n = mk for some integer k, so xn = (xm)k =
1k = 1. Vice versa, suppose xn = 1. We may write n = qm + r, with 0 ≤r < m.
So 1 = xn = (xm)qxr = xr. Then, by deﬁnition of order we have r = 0, or else the
order of x would be r < m. So m | n.
A3.28. The powers x, x2, . . ., xm are all diﬀerent by deﬁnition of order. Apply now
the same reasoning as in the previous exercise to show that every other power is
equal to one of these.
A3.30. Let GCD(m, n) = 1. For all k ∈Z, there is an h such that hm ≡k
(mod n). Then (xm)h = xk, so xm is a generator. Vice versa, if xm is a generator,
there is an integer h such that (xm)h = x. Then hm ≡1 (mod n), which implies
GCD(m, n) = 1.
A3.32. Let n = dm. Then ⟨xm⟩has order d. Vice versa, if H is a subgroup of order
d of G, we have n = dm by Lagrange’s theorem. We have seen that a generator of
H is given by xh with h the smallest positive integer such that xh ∈H (see Exercise
A3.25). As (xh)d = 1, we have a relation of the form dh = nk. Dividing by d we
have h = mk. So xh = (xm)k ∈⟨xm⟩; hence, H ⊂⟨xm⟩. As ⟨xm⟩has order d, we
have H = ⟨xm⟩(and k = 1).
A3.33. Hint: the element xh has order d if and only if it is a generator of the
subgroup ⟨xm⟩.
A3.34. Hint: the relation ym
1 = y2 is equivalent to the congruence equation mn1 ≡
n2 (mod n).
A3.36. Deﬁne in G the relation RH as follows: xRHy if and only if xy−1 ∈H.
Verify that this is an equivalence relation. Verify that the equivalence class of an
element x is the set denoted by Hx and called right coset of H, consisting of all
the elements of the form tx with t ∈H. Prove that Hx has the same number of
elements as H. Conclude that the order of G is equal to the order of H times the
order of the quotient set of G with respect to the relation RH.
A3.37. We know that ϕ(n) is the order of the ﬁnite group U(Zn). Let m be the
period of an element a of U(Zn). Then m divides ϕ(n), so aϕ(n) = e (see Exercise
A3.27).
A3.38. In the situation described, it suﬃces to divide m by ϕ(n), that is, m =
qϕ(n) + r, so am ≡ar (mod n), then compute ar (mod n).
B3.1. The correct answer is (c).
B3.2. The correct answer is (a).
B3.3. The correct answer is (c): the zero-divisors are classes [2], [3], [4].
B3.4. The correct answer is (a) as 19 is a prime number. The reader might want to
verify explicitly the absence of zero-divisors.
B3.5. The correct answer is (b) as 27 is not a prime number. For instance, class [3]
is a zero-divisor in Z27.

486
Solution to selected exercises
B3.6. We have 725843 ≡3 (mod 10), so
(725843)594 ≡3594
(mod 10).
Moreover,
3594 = 34·148+2 = (34)148 · 32 ≡1148 · 32 = 9
(mod 10).
So the last digit is 9.
B3.7. As 74 ≡2 (mod 9), then 746h ≡26h (mod 9). Moreover, 26h = (26)
h and
26 ≡1 (mod 9), so, for all h ∈N, we ﬁnd that 746h ≡1h ≡1 (mod 9) and the
required congruence class is 1.
B3.8. We have 43816 ≡6 (mod 10), and further 62 ≡6 (mod 10). Then, 6k ≡6
(mod 10) for all k > 0; it follows that
4381620321 ≡6
(mod 10).
B3.9. We have 29345 ≡5 (mod 6). Moreover, 52 = 25 ≡1 (mod 6), so
29345362971 ≡5362971 = (52)181485 · 51 ≡1 · 5 ≡5
(mod 6).
B3.10. We have 362971 ≡1 (mod 6), so 36297129345 ≡1 (mod 6).
B3.11. In class 1 modulo 9.
B3.16. The correct answer is (c).
B3.17. The correct answer is (a), as 4 is not relatively prime with 18.
B3.18. 39.
B3.23. As 9 ≡0 (mod 3), we have that 3 divides an integer n written in base 9 if
and only if 3 divides the last digit of n.
B3.24. The correct answer is (a). Let us see why. First of all, 5 mod 4 = 1, so the
congruence given is equivalent to 3x ≡1 (mod 4). By Corollary 3.3.6, the congru-
ence has exactly one solution modulo 4. Moreover, the solution is the inverse of 3
modulo 4, by the very deﬁnition of inverse. In order to ﬁnd this inverse we may either
proceed by trial and error, or with B´ezout’s identity, that is to say, computing the
numbers α and β such that 3α+4β = 1 = GCD(3, 4) using the Euclidean algorithm
(see formula (1.14) on page 17 foll.). Indeed, from B´ezout’s identity it follows that
α is the inverse of 3 modulo 4. In our case, we ﬁnd α = −1 ≡3 (mod 4) and β = 1.
So we conclude that the only solution modulo 4 of the congruence is 3.
B3.25. The correct answer is (b). Indeed, by Proposition 3.1.8 the congruence is
found to be equivalent (by dividing all coeﬃcients by 3) to x ≡3 ≡1 (mod 2).
B3.26. The correct answer is (a). By Corollary 3.3.6 the congruence has exactly
one solution modulo 9. We compute the inverse of 4 modulo 9, that is the solution
of 4y ≡1 (mod 9). A way of ﬁnding y consists in computing B´ezout’s identity
4α + 9β = 1 using the Euclidean algorithm, ﬁnding α = 7. Multiply both sides of
the congruence by 7 we ﬁnd the equivalent congruence x ≡7 · 7 ≡4 (mod 9). On
the other hand, 4 ≡−5 (mod 9).

Exercises of Chapter 4
487
B3.27. The correct answer is (c), by Proposition 3.3.4.
B3.28. The correct answer is (d).
B3.36. We have 190 ≡3 (mod 17). So
190597 ≡3597
(mod 17).
As GCD(3, 17) = 1, it follows that 316 ≡1 (mod 17) by Euler’s Theorem, as ϕ(17) =
16 (verify this directly). So,
3597 = 316·37+5 = (316)37 · 35 ≡137 · 35 = 35 ≡5
(mod 17).
B3.38. As GCD(3, 7) = 1 and ϕ(7) = 6, then Euler’s Theorem says that 36 ≡1
(mod 7), so 313 = (36)2 · 3 ≡3 (mod 7).
B3.39. The correct answer is (a).
B3.40. The correct answer is (c).
B3.41. The correct answer is (c).
B3.42. The correct answer is (c). Let us see why. By the Chinese remainder theorem
3.4.2, there exists exactly one solution modulo 5 · 9 = 45. The method for ﬁnding
this solution is described in the proof of the theorem: with those notation we have
s = 2, r1 = 5, r2 = 9, c1 = 3 and c2 = 7. So R = 45, R1 = 9 and R2 = 5. We have
now to solve congruences 9x ≡3 (mod 5) and 5x ≡7 (mod 9). The only solution
modulo 5 of the ﬁrst one is ¯x1 = 2, while the only solution modulo 9 of the second
one is ¯x2 = 5. So we may conclude that the solution of the congruence given is
¯x = 9 · 2 + 5 · 5 = 43.
B3.43. The correct answer is (d), because the system has solution x ≡97 (mod 120).
B3.48. It will happen on Saturday 31 March.
B3.49. There are 1786 books.
B3.53. The correct answer is (d), as may be veriﬁed by browsing any engagement
diary, but we are sure the reader has applied instead the formula proved in the
text, by substituting the values g = 31, m = 10 (as we are considering March as
the ﬁrst month of the year!), s = 20 and y = 0, because 2000 = 20 · 100, ﬁnding
x ≡31 + 25 −40 + 5 = 21 ≡0 (mod 7).
B3.54. The correct answer is (c); indeed, in this case we have g = 28, m = 12,
2003 = 20 · 100 + 3, that is, s = 20 and y = 3, because we consider February 2004
as the last month of year 2003, so x ≡28 + 31 −40 + 3 + 5 = 27 ≡6 (mod 7).
Exercises of Chapter 4
A4.4. If √p = a/b, with a, b integers and relatively prime, then b2p = a2. Now
the irreducible factor p appears an odd number of times in the left-hand side and
an even number of times in the right-hand side. This contradicts the Fundamental
Theorem of Arithmetic.

488
Solution to selected exercises
A4.5. Notice that n
t=1 1/ts is the sum of the areas of n rectangles, each of width
1 and heights 1, 1/2s, . . . , 1/ns. We may assume these rectangles to be located in
the cartesian plane with the bases along the x-axis, on the line segments having as
endpoints the points of abscissas 1, 2, . . . , n and with the heights having as endpoints
(1, 1), (2, 1/2s), . . . , (n, 1/ns). The graph of the function y = 1/xs is completely
included in the union of these rectangles and the diﬀerence in the right-hand side of
(4.2) is the area of the ﬁgure Σ between the graph and the union of the rectangles.
This ﬁgure is the union of the ﬁgures Σ1, . . . , Σn such that Σi, i = 1, . . . , n, is the
ﬁgure between the ith rectangle and the segment of the graph of y = 1/xs which
lies above the ith interval [i, i+ 1]. For all i = 2, . . . , n, translate Σi along the x-axis
by a vector of length i −1 with negative orientation. So we get a new ﬁgure Σ′
i
included in the ﬁrst rectangle R, which is a square of area 1. Notice that the area of
Σ is equal to the area of the ﬁgure Σ′, the union of Σ1, Σ′
2, . . . , Σ′
n, which is strictly
included in R.
A4.7. The prime numbers less than or equal to √n are approximately 2√n/log n.
For each of these numbers it is necessary to delete all its multiples that are less than
n, so it is necessary to carry out a number of operations that may be estimated by
log2 n.
A4.9. Recall that
p
k
	
= p!/k!(p −k)!, and p divides the numerator, but cannot
divide the denominator, because it does not divide any of its factors.
A4.10. The binomial theorem yields
(x + y)p = xp +
p−1

k=1

p
k

xp−kyk + yp.
So we have to prove that the sum is divisible by p. But this is true, as in the sum
we have both k < p and p −k < p, so
p
k
	
is an integer divisible by p, by Exercise
A4.9.
A4.13. Let n = pq, where p and q are distinct primes. Then ϕ(n) = ϕ(p)ϕ(q) =
(p −1)(q −1) = n + 1 −(p + q). Vice versa, if we know n and ϕ(n), then p and q
are the solutions of the second degree equation x2 −(n −ϕ(n) + 1)x + n.
A4.16. Write out the factorisation of n = ph1
1 · · · phr
r
di n. Then

d|n
μ(d) =

0≤ki≤1,i=1,...,r
μ(pk1
1 · · · pkr
r ) =
= 1 −r +

r
2

−

r
3

+ · · · + (−1)r = (1 −1)r = 0.
A4.17.It suﬃces to verify that ((f ∗g) ∗h)(n) and (f ∗(g ∗h))(n) both coincide
with 
d1d2d3=n f(d1)g(d2)h(d3).
A4.20. Let n, m relatively prime. We have
(f ∗g)(n) =

d|n
f(d)g
 n
d
 
,
(f ∗g)(m) =

d′|m
f(d′)g
 m
d′
 
so, by the multiplicativity of f and g,

Exercises of Chapter 4
489
((f ∗g)(n))((f ∗g)(m)) =

d|n,d′|m
f(d)f(d′)g
n
d
 
g
 m
d′
 
=

d|n,d′|m
f(dd′)g
 nm
dd′
 
.
Hence the claim immediately follows.
A4.22. We have μ ∗Ef = μ ∗(I ∗f) = (μ ∗I) ∗f = Π ∗f = f.
A4.24. M¨obius inversion theorem says that φ = μ ∗ι because Eϕ = ι. So if n =
ph1
1 · · · phr
r , then
ϕ(n) =

d|n
μ(d)n
d = n −
r

i=1
n
pi +
r

i,j=1
n
pipj −· · ·
hence (4.4) may be imediately deduced.
A4.26. Apply Proposition 4.2.2. So it suﬃces to compute the functions ν and σ on
prime numbers, for which it is trivial to compute the functions.
A4.30. Keeping in mind the proof of Proposition 4.2.3, prove that the obvious
mapping [x]nm ∈Znm →([x]n, [x]m) ∈Zn × Zm induces a group isomorphism
U(Znm) →U(Zn) × U(Zm). The claim immediately follows.
A4.31. The claims follow from easy properties of cyclic groups. For instance, for
the second identity, notice that a and b generate in U(Zp) cyclic groups of order
Gss(p, a) and Gss(p, b), respectively. As GCD(Gss(p, a), Gss(p, b)) = 1, these cyclic
groups only intersect in 1, so their direct product is in U(Zp) and is a cyclic group
of order Gss(p, a) · Gss(p, b), which is generated by ab.
A4.36. We have m′ = m + hn. Then xm −xm′ = xm(1 −xhn). Notice that h(x)
divides xhn −1.
A4.37. In base a the number an−1 + an−2 + · · · + a2 + a + 1 is written as (1 . . . 1)a,
where n digits 1 appear. Multiplying by a −1 we get the number (a −1 . . . a −1)a,
where n digits a −1 appear, and this is exactly an −1. This proves part (i). Part
(ii) is proved analogously.
A4.38. Proceed by induction.
A4.41. Assume Mp to be prime and n = 2p−1 · Mp. Then, by Exercise A4.26,
we have σ(n) = 2p · Mp = 2n. Vice versa, let n = 2st be even and perfect, with
t odd. Then, again by Exercise A4.26 and by the multiplicativity of σ, we have
2s+1t = 2n = σ(n) = (2s+1 −1)σ(t); hence follows that 2s+1 | σ(t), so we may write
σ(t) = 2s+1q and so σ(n) = (2s+1 −1)σ(t) = 2s+1(2s+1 −1)q. As σ(n) = 2s+1t, we
have t = (2s+1 −1)q. Moreover, σ(t) = 2s+1q = t + q, so q = 1 as 1, q, t divide t.
Thus, t = 2s+1 −1 and σ(t) = t + 1, so t is prime.
A4.48. If the claim were not true, there would be a decreasing sequence {hn}n∈N
of positive integers such that b = ahnbn for all n ∈N. Let I be the ideal generated
by the elements of the sequence {bn}n∈N. As A is Noetherian, I is ﬁnitely gener-
ated. Assume I = (b1, . . . , bn), so bn+1 = a1b1 + · · · + anbm and b = ahn+1bn+1 =
ahn+1(a1b1+· · ·+anbn). Hence deduce that b = b(a1ahn+1−h1 +· · ·+b(anahn+1−hn),
so 1 = ahn+1−hn(a1ahn−h1 + · · · + an). Thus, a would be invertible, yielding a con-
tradiction.

490
Solution to selected exercises
A4.49. Verify for instance that it is closed under addition. If a, b ∈I there are
positive integers n, m such that a ∈In and b ∈Im. If we assume n ≤m, then
a, b ∈Im, so a + b ∈Im ⊆I.
A4.50. To construct the sequence, proceed inductively. Choose x1 ∈I, any element
of I. Having chosen next x1, . . . , xn, notice that In = (x1, . . . , xn) ̸= I as I is not
ﬁnitely generated. So we may choose xn+1 ∈I −In, and clearly In+1 ̸= In.
A4.52. Let n be the degree of f(x) and let a be its leading coeﬃcient. Notice that
limx→+∞f(x)/xn = a. Hence deduce the claim.
A4.61. For all positive integers m < n and for all pairs of polynomials of degree m
and n −m with coeﬃcients bounded by N, we have to take their product and check
whether it is equal to f(x). Multiplying two of these polynomials has complexity
O((m + 1)(n −m + 1) log2 N). Notice however that the pairs of such polynomials
are O(N n).
A4.62. First of all, to compute ¯f(x) it is necessary to divide the n + 1 coeﬃcients
by p and to take the remainder. This has complexity O((n + 1)N log p). Once ¯f(x)
has been found, for all positive integers m < n and for all pairs of polynomials of
degree m and n −m in Zp[x] we must take their product and check whether it is
equal to ¯f(x). Multiplying two of these polynomials and reducing the result modulo
p has complexity O((m + 1)(n −m + 1) log3 p). Moreover, there are pn such pairs of
polynomials.
A4.63. Consider the coeﬃcients of p(x) as indeterminates and interpret (4.20) as a
system of M + 1 equations in M + 1 unknowns. So it certainly has some solution. If
there were two distinct solutions, we would ﬁnd two distinct polynomials p(x), q(x)
of degree n ≤M verifying (4.20). Then the non-zero polynomial p(x)−q(x) of degree
n ≤M would have the M + 1 distinct roots a0, a1, . . . , aM, which is impossible (see
Exercise A1.55).
A4.64. Notice that the determinant of the matrix of the system (4.20) is equal to
V (a0, a1, . . . , aM), so the uniqueness of the solution of (4.20) implies that it is not
zero. Notice next that V (x1, . . . , xm), as a polynomial in K(x1, . . . , xm−1)[xm], has
the solutions xm = xi, i = 1, . . . , m −1, so V (x1, . . . , xm) is divisible by xm −xi,
i = 1, . . . , m −1 in K(x1, . . . , xm−1)[xm]. The claim can be deduced using Gauss
theorem.
A4.65. Proceed as in Exercise A4.63 considering the coeﬃcients of f(x) as inde-
terminates. The given conditions determine a system of n + 1 equations in n + 1
unknowns that always has a solution. It is unique, or else we would have a poly-
nomial of degree n having h roots with multiplicities m1 + 1, . . . , mh + 1, which is
impossible.
B4.2. The correct answer is (a).
B4.4. The correct answer is (b).
B4.5. The correct answer is (d), because 1369 = 372.
B4.11. The correct answer is (a).
B4.12. The correct answer is (b).

Exercises of Chapter 4
491
B4.14. The correct answer is (a), because the primes are 211, 223, 227, 229, 233,
239 and 241.
B4.19. Gss(8, a) = 2.
B4.23. β = 3, 6, 9.
B4.24. β = 2, 4, 5, 7, 8, 10.
B4.25. β = 23, 46, 92.
B4.29. By Proposition 4.4.3, for every prime factor p of 211 −1 = 2047, we have
p ≡1 (mod 22). As 45 <
√
2047 < 46, we see that p = 23, and 2047 = 23 · 89.
B4.33. The number 2 is not prime in Z[i]. Indeed, 2 = (1 + i)(1 −i), so 2 divides
the product (1 + i)(1 −i), but 2 does not divide 1 + i nor 1 −i: assume 2 divides
1+i, that is, 1+i = 2(a+bi), a, b ∈Z. Denoting by N(a+ib) = a2 +b2 the complex
norm of the number a + ib, we would have
N(1 + i) = 2 = N(2(a + ib)) = N(2)N(a + ib) = 4(a2 + b2);
now, the relation 2 = 4(a2 + b2) is a clearly impossible to be satisﬁed in N.
Analogously for 1 −i. On the other hand, 2 + 3i is prime.
B4.35. For instance, 2, 5 and 2 ± √−6 are irreducible. Which of them are prime?
B4.36. The correct answer is (c), because 10 = (2 + √−6)(2 −√−6).
B4.37. The correct answer is (d), because no one of the three polynomials is asso-
ciate to the given polynomial; the primitive polynomials are ±(100x3 + 36x2 −15x).
B4.40. The correct answer is (a). Let us see why. The polynomial x3 −3x + 1, as
every third degree polynomial, is irreducible over Q if and only if it has no roots,
because if it were reducible it would necessarily have a factorisation into a ﬁrst degree
polynomial and a second degree polynomial (or into three degree one polynomials);
see page 190. But 1 and −1 are not roots of x3 −3x + 1, so by Proposition 4.5.37
this polynomial has no roots, so it is irreducible.
Let us see now what happens by considering the coeﬃcients in Z2, Z3 or Z19.
Over Z2 the polynomial becomes x3 + x + 1, which is irreducible over Z2 because it
has no roots, as may be veriﬁed by substituting x = 0 and x = 1 in the polynomial.
As the polynomial is irreducible over Z2, it must be so a fortiori over Q (see page
190). It may be veriﬁed that the polynomial is reducible over Z3 and over Z19;
indeed, over Z3 it becomes x3 + 1 which admits −1 as a root, while 3 is a root over
Z19.
B4.42. The correct answer is (a). Indeed, by substituting x + 1 for x, we ﬁnd
the polynomial x4 + 5x3 + 10x2 + 10x + 5, which satisﬁes Eisenstein’s criterion of
irreducibility (Proposition 4.5.41 on page 188), so it is irreducible, and the given
polynomial must be as well. We have argued exactly as in Example 4.5.42 on page
188 (with p = 5).
B4.47. The correct answer is (b), because x3 −3x + 1 = x3 + 1 = (x + 1)3 over Z3.
B4.52. The correct answer is (d); indeed, the polynomial in (d) veriﬁes the required
conditions, has degree two and may be computed using the Lagrange interpola-
tion polynomial for this degree. Notice that there are inﬁnitely many degree three
polynomials that verify those conditions.

492
Solution to selected exercises
Exercises of Chapter 5
A5.3. Every ﬁeld containing A and b1, . . . , bn must also contain all rational expres-
sions in b1, . . . , bn with coeﬃcients in A. Conclude by verifying that these expressions
form a ﬁeld.
A5.5. A basis of C as a vector space over A is also a basis of C as a vector space
over B, so [C : B] is ﬁnite. On the other hand, B is a vector subspace of C as a
vector space over A, so [B : A] is ﬁnite, because [C : A] is ﬁnite.
A5.6. To prove that the given elements are linearly independent, suppose we
have a relation of the form 
i,j αijaibj = 0, with αij
∈A. Then we have
m
j=1(n
i=1 αijai)bj = 0. By the linear independence of {b1, . . . , bm} over B we have
n
i=1 αijai = 0 for all j = 1, . . . , m. By the linear independence of {a1, . . . , an} over
A we have αij = 0 for all i = 1, . . . , n, j = 1, . . . , m.
To prove that this is a system of generators, notice that for all c ∈C we have
c = m
j=1 βjbj, with βj ∈B for all j = 1, . . . , m. Use now the fact that {a1, . . . , an}
is a basis of B as a vector space over A to express every βj as a combination of
{a1, . . . , an} with coeﬃcients in A and conclude.
A5.8. Let fb(x) = f1(x) · f2(x) with f1(x), f2(x) ∈A[x] be monic polynomials of
positive degree. We have f1(b) · f2(b) = fb(b) = 0 so either f1(b) = 0 or f2(b) = 0;
thus, either f1(x) ∈Ib or f2(x) ∈Ib. Hence fb(x) divides either f1(x) or f2(x),
leading to a contradiction. The fact that Ib is prime may be proved analogously.
A5.10. If A is a ﬁeld and I is a non-zero ideal of A, there is a non-zero element
a ∈I. Then 1 = a−1 · a ∈I, so I = A (see Exercise A5.9). Vice versa, let a ̸= 0 be
an element of A. Then (a) is a non-zero ideal, so (a) = A. Hence, 1 ∈(a), so there is
a b such that ab = 1. This proves that every non-zero element of A has an inverse,
so A is a ﬁeld.
A5.11. B is an integral domain (see Exercise A5.8 and Exercise A3.12). Let I be an
ideal of B. Let J be the preimage of I under the natural mapping A[x] →B. Verify
that J is an ideal and observe that f(x) ∈J. Let g(x) be the monic generator of J.
Then g(x) divides f(x). Conclude that either g(x) = f(x) or g(x) = 1, so J = I or
J = A[x]; hence either I = (0) or I = B. Conclude by applying Exercise A5.10.
A5.13. Hint: use Lemma 5.1.8 and proceed by induction.
A5.14. Let c ∈C. As B ⊂C is algebraic, there are b0, . . . , bn ∈B not all zero
such that b0 + b1c + · · · + bncn = 0. Then c is algebraic over A(b0, . . . , bn), so
[A(b0, . . . , bn, c) : A(b0, . . . , bn)] is ﬁnite. As A ⊂B is algebraic, [A(b0, . . . , bn) : A]
is also ﬁnite, so by the multiplicativity of degrees [A(b0, . . . , bn, c) : A] is ﬁnite.
Conclude by applying Exercise A5.13.
A5.15. Let a, b be elements of B that are algebraic over A. Then [A(a, b) : A] is
ﬁnite. As a ± b, ab, and a−1, if a ̸= 0, are in A(a, b), this implies that they are
algebraic over A. Hence we deduce that C is a ﬁeld. If c ∈B is algebraic over C, it
is algebraic over A as well, so c ∈C.
A5.16. Prove ﬁrst that A[x] is countable. Using this fact, prove that the set X ⊂
B × A[x] of pairs (α, f(x)) such that f(α) = 0 is countable. Conclude by observing
that the projection of X on B has as its image the algebraic closure of A in B.

Exercises of Chapter 5
493
A5.19. Observe that f(x) = (x −α1) · · · (x −αn). Then carry out the product.
A5.22. Apply the previous exercise.
A5.23. If n = mh and if ξm = 1 then ξn = (ξm)h = 1. Vice versa, let Rm ⊆Rn.
If either K has characteristic 0 or p is relatively prime with n and m, then Rn has
order n and Rm has order m and we conclude by applying Lagrange’s theorem (see
Exercise A3.36).
A5.24. Suppose it has order d < n. Then d = qμ1
1 · · · qμh
h
with μ1, . . . , μh non-
negative integers and μi ≤mi, i = 1, . . . , h, where for at least one i the inequality
holds. Set di = qμi
i
and ei = d/di, i = 1, . . . , h. We have ξd = ,h
i=1(ξdi
i )ei. At
least one of the elements ξdi
i
is not 1: assume this happens exactly for the indices
i = 1, . . . , k. So, ξd = ,k
i=1(ξdi
i )ei. Notice that ξdi
i
has order δi = ni/di = qmi−μi
i
and δi ∤ei, for i = 1, . . . , k. So, for all i = 1, . . . , k we have ξd
i = (ξdi
i )ei ̸= 1. In
conclusion, notice that ξd
1ξd
2 ̸= 1 as Rn1 ∩Rn2 = (1). Analogously, ξd
1ξd
2ξd
3 ̸= 1 as
Rn1n2 ∩Rn3 = (1), and so on.
A5.29. The roots of xpf −x are 0, plus those of the polynomial xpf −1 −1. As F∗
has order pf −1, every non-zero element a ∈F satisﬁes apf −1 = 1, so is a root of
xpf −1 −1.
A5.31. Mimic the proof of Proposition 5.1.37.
A5.32. Mimic the proof of Corollary 5.1.38.
A5.33. Keeping in mind Exercise A5.32 and M¨obius inversion theorem (see Exercise
A4.22), one can ﬁnd the formula nd,q = (1/d) 
h|d μ(h)qd/h; hence nd,q > (1/d)(qd−
qd/2 −qd/3 −· · · ) > (1/d)(qd −[d/2]
i=0 qi). From here, the claim immediately follows.
A5.34. Every automorphism of F ﬁxes F′. So we have an obvious restriction ho-
momorphism r : Aut(F) →Aut(F′). Recall that Aut(F) [Aut(F′), respectively] is
cyclic of order f [f ′, resp.] generated by φF [φF, resp.]. As obviousy r(φF) = φF′, the
homomorphism r is surjective. Its kernel, which is the group we are looking for, has
order f/f ′ and is generated by (φF)f′.
A5.35. We have Fpd = Zp[x]/(f(x)) = Zp(α) ⊂F. Conclude keeping in mind
Theorem 5.1.35.
A5.36. Every element g(x) ∈K[x] is congruent modulo (f(x)), to the remainder of
its division by f(x).
A5.38. Keep in mind Exercise A2.20 and Proposition 5.1.44.
A5.39. Keep in mind Exercise A2.21 and Proposition 5.1.44.
A5.40. Keep in mind Exercise A2.22 and Proposition 5.1.44.
A5.41. In each division, d2 multiplications are carried out, each having complexity
O(log3 q). Moreover, at most d division have to be performed. For more information,
see Section 2.5.3.
A5.42. Use the method of completing the square discussed on page 234.
A5.48. Use Exercise A5.47 and Corollary 5.1.31.

494
Solution to selected exercises
A5.49. Notice that ξ4 = −1, so ξ5 = −ξ, ξ7 = −ξ3, then G = 2(ξ −ξ3). Hence,
G2 = 4(ξ2 −2ξ4 + ξ6) = 8. So we have Gp−1 = (G2)
(p−1)/2 = 8(p−1)/2. Using
Proposition 5.2.22, we get Gp = (8/p)G = (2/p)G.
A5.50. We have Gp = (7
i=0 ϵ(i)ξi)p = 7
i=0 ϵ(i)ξpi = 7
i=0 ϵ(pi)ξi. Keep in mind
Exercise A5.58, we have ϵ(p)ϵ(pi) = ϵ(p2i) = ϵ(p2)ϵ(i) = ϵ(i). Hence, ϵ(p)Gp =
7
i=0 ϵ(p)ϵ(pi)ξi = 7
i=0 ϵ(i)ξi = G. Finally, notice that G ̸= 0, as G2 = 8 ̸= 0.
A5.52. With the same idea as Exercise A5.50, we have Gp = q−1
i=0 ( i
q )pξip =
q−1
i=0 ( i
q )ξip. Now notice that ( i
q ) = ( i
q )( p2
q ) = ( p2i
q ) = ( pi
q )( p
q ). So Gp
=
q−1
i=0 ( i
q )ξip = q−1
i=0 ( pi
q )( p
q )ξip = ( p
q )(q−1
i=0 ( pi
q )ξip) = ( p
q )(q−1
i=0 ( i
q )ξi) = ( p
q )G.
A5.53. Using Proposition 5.2.22, we have
G2 = G · G =
q−1

i=1
 i
q

ξi
 q−1

j=1
 j
q

ξj

=
q−1

i=1
 i
q

ξi
 q−1

j=1
 −j
q

ξ−j

=
=
−1
q
 q−1

i=1
q−1

j=1
ij
q

ξi−j = (−1)(q−1)/2
q−1

i=1
q−1

j=1
ij
q

ξi−j.
Notice that we may consider the indices i, j as non-zero elements of Zq. For
every index i in the external sum, perform in Z∗
q the variable change j = ik.
This may be done, as when k ranges in Z∗
q, also j ranges in Z∗
q. So we have
G2 = (−1)(q−1)/2 q−1
i=1
q−1
k=1(i2k/q)ξi(1−k) = (−1)(q−1)/2 q−1
i=1
q−1
k=1(k/q)ξi(1−k).
Keeping in mind Exercise A5.46, we get
G2 = (−1)(q−1)/2
q−1

i=0
q−1

k=0
k
q

ξi(1−k) = (−1)(q−1)/2
q−1

k=0
k
q
 q−1

i=0
ξi(1−k)

.
For every k ̸= 1 the internal sum equals zero: indeed, ξ is a primitive qth root
of unity, and being q prime, every power ξh with q ∤h is too, so for the values
i = 0, . . . , q −1, the powers ξi(1−k) span the whole set Rq (see Exercise A5.22). In
conclusion, we have G2 = (−1)(q−1)/2 q−1
i=0 ξ0 = (−1)(q−1)/2q.
A5.54. We have Gp = (G2)(p−1)/2G = ((−1)(q−1)/2q)(p−1)/2G. Conclude keeping in
mind Proposition 5.2.22 and Exercise A5.52.
A5.57. The claim is trivial if α = 1. Proceed next by induction on α.
A5.58. Hint: notice that
ϵ(n) =

1
if
n ≡±1
(mod 8),
−1
if
n ≡±3
(mod 8),
and examine separately the diﬀerent cases for n, m modulo 8.
B5.2. The correct answer is (a).
B5.3. The correct answer is (a), because 64 = 26 and F64 may be constructed, for
instance, as a quotient of Z2[x] with respect to an irreducible polynomial of degree
6.

Exercises of Chapter 5
495
B5.4. The correct answer is (d), because 323 = 17 · 19 is not a prime number, but
this is not suﬃcient to rule out the existence of a ﬁeld of order 323. It is necessary
to remark that 323 is neither a prime nor a prime power.
B5.8. The correct answer is (a).
B5.13. The correct answer is (c), as 16 = 24.
B5.20. The correct answer is (c).
B5.21. The correct answer is (d), as x4 + x2 + 1 = (x2 + x + 1)2 over Z2. Let us see
how to get this factorisation.
First of all, we check whether x4 +x2 +1 has roots in Z2, but we do not ﬁnd any.
Verify next if the polynomial splits into two degree two polynomials. We may assume
that there is a factorisation of the form: x4 + x2 + 1 = (x2 + ax + 1)(x2 + bx + 1)
where a and b are unknowns. In general, we should have written x4 + x2 + 1 =
(cx2 + ax + d)(ex2 + bx + f) where c, d, e and f are further unknowns. But a factor
of a monic polynomial with coeﬃcients in a ﬁeld may always be chosen to be monic,
so we may assume c = 1. Then also e = 1, as in the right-hand side the highest
degree term is cex4. Moreover, the constant term must be 1 = df, which in Z2 is
possible only if d = f = 1. Back to the factorisation of x4 + x2 + 1, by carrying out
the product in the right-hand side we get x4 +(a+b)x3+(1+ab+1)x2+(a+b)x+1,
so 0 = a + b and 1 = ab. Both equations are satisﬁed only if a = b = 1. So we get
the factorisation given at the beginning.
Another possible way of ﬁnding this factorisation consists in noticing that the
degree two factors, if they exist, have to be irreducible, otherwise they would have a
degree one factor which would also be a factor of the original polynomial. There are
only four degree two polynomial over Z2: x2, x2+1, x2+x, x2+x+1. The ﬁrst three
of them are reducible, because they have a root equal to 0, 1 and 0, respectively. So
x2 + x + 1 is the only degree two irreducible polynomial over Z2. If we divide our
polynomial by x2+x+1, we ﬁnd a zero remainder and a quotient equal to x2+x+1,
so we get again the above factorisation.
B5.22. The correct answer is (a).
B5.25. The correct answer is (d). First of all, notice that x27 −x has linear factors,
because it has roots 0, 1 and −1 (= 2). Next, dividing by x(x −1)(x + 1), we ﬁnd
that the quotient is
x24 + x22 + x20 + x18 + x16 + x14 + x12 + x10 + x8 + x6 + x4 + x2 + 1,
and we must try to factor this. Verify that it has no linear factors, because 0, 1 and
−1 are not roots of this polynomial. Then we have to look for its factors among the
monic, irreducible polynomials of degree two or greater. We may verify that there
are three monic, irreducible polynomials of degree two over Z3, but they do not
divide our polynomial. So we look at the monic, irreducible polynomials of degree
three. After some calculations, we ﬁnd the following polynomials:
x3 + 2x + 1,
x3 + 2x + 2,
x3 + x2 + 2,
x3 + x2 + x + 2,
x3 + x2 + 2x + 1,
x3 + 2x2 + 1,
x3 + 2x2 + x + 1,
x3 + 2x2 + 2x + 2
and they are exactly all the factors of the degree 24 polynomial (so also of x27 −x),
as may be veriﬁed by carrying out the divisions. So we have found 11 factors: three
linear ones and eight of degree three.

496
Solution to selected exercises
B5.27. The correct answer is (a).
B5.28. The correct answer is (a), as only Z5 is a subﬁeld of F125.
B5.43. The correct answer is (a).
B5.44. The correct answer is (d), as the solutions are x = −1, x = −3, x = 4 and
x = 6 modulo 14.
B5.49. The correct answer is (a), as 13 divides 65.
B5.50. The correct answer is (d), as Legendre symbol is deﬁned only if the denom-
inator is a prime number.
B5.51. The correct answer is (c).
B5.54. The correct answer is (b). Let us see why. First of all, 973 = 7·139, so ( 1003
973 ) is
equal, by deﬁnition of Jacobi symbol, to the product of the Legendre symbols ( 1003
7 )
e ( 1003
139 ). Now, 1003 mod 7 = 2, so ( 1003
7 ) = ( 2
7) = 1, where the last equality follows
from Proposition 5.2.27. On the other hand, 1003 mod 139 = 30, so ( 1003
139 ) = ( 30
139).
By part (4) of Proposition 5.2.22, we have ( 30
139) = (
2
139)(
3
139)(
5
139). Proposition
5.2.27 tells us also that (
2
139) = −1, while the law of quadratic reciprocity (Theorem
5.2.28) implies that (
3
139) = −( 139
3 ) and (
5
139) = ( 139
5 ). Finally, 139 mod 3 = 1 and
139 mod 5 = −1, so ( 139
3 ) = ( 1
3) = 1 and ( 139
5 ) = ( −1
5 ) = 1. So we may conclude
that ( 1003
973 ) = (−1)(−1) = 1.
Exercises of Chapter 6
A6.1. As n is not a prime, it is clear that neither is m (see Section 4.4.1). As n
is a pseudoprime in base 2, we have m −1 = 2n −2 = kn for some integer k. So
2m−1 −1 = 2kn −1 ≡0 (mod m).
A6.3. As n is a pseudoprime in bases a1 and a2, then an−1
1
≡1 (mod n) and
an−1
2
≡1 (mod n), so (a1a2)n−1 = an−1
1
an−1
2
≡1 (mod n). Moreover, (a−1
2 )n−1 ≡
a1−n
2
≡1−1 ≡1 (mod n).
A6.8. As for Exercise A6.1, we have that m is not prime. We have 2n−1 −1 = nk
and k is odd. So m −1 = 2n −2 = 2kn with kn odd. Moreover, 2(m−1)/2 = 2nk =
(2n)k ≡1 (mod m). Indeed, 2n = m + 1 ≡1 (mod m).
A6.10. Write n = 2st + 1 with odd t. From the hypotheses, it follows that b2s−1t ≡
−1 (mod n).
A6.12. It suﬃces to observe that for all positive integers k we have 5k ̸≡−1
(mod 4).
A6.15. Use the properties of cyclic groups (see Exercises A3.23–A3.35).
A6.16. We have to compute the product of all elements of the group U(Zn). As
two reciprocal elements cancel out in the product, the result is ,
x∈G x, where G is
the subgroup of the elements of order 2 of U(Zn). Consider G as an additive group,
so the above product becomes the sum of the elements. The group G is a Z2-vector
space as well. If it has dimension 1, then G has order 2; this corresponds exactly to

Exercises of Chapter 6
497
the cases n = 2, 4, ph, 2ph, and the sum of its elements is of course 1. If the dimension
of G is greater than 1, we see that the sum of its elememts is 0. Indeed, we may
interpret G as Zd
2, d > 1. Put the 2d elements of Zd
2 in a 2d ×d matrix. Every column
has 2d−1 entries equal to 0 and as many equal to 1. Summing the elements of Zd
2
columnwise, it is clear that the sum of the entries in each column is 0.
A6.19. We are working in U(Z2l). So we may write x = (−1)s5t, m ≡(−1)σ5τ
(mod 2l) (see Remark 6.2.10). Then the equation to be solved is translated into the
system consisting of the two equations
sh ≡σ
(mod 2),
th ≡τ
(mod 2l−2)
in s and t. If h is odd, then this system admits a unique solution. If h is even, the
ﬁrst equation admits solutions, and exactly two of them, if and only if σ is even, that
is, m ≡1 (mod 4). If h is even, the second equation admits solutions, and exactly
d of them, if and only if d | τ that is, if and only if τ = dk, that is m = 5dk, so
m2l−2/d (mod 5)2l−2 ≡1 (mod 2l).
A6.21. Assume, for instance, n to be odd. Let n = pl1
1 · · · pls
s be its factorisation.
Then U(Zn) is the direct product of U(Zpli
i ), i = 1, . . . , s. Let ri be a generator of
U(Zpli
i ), i = 1, . . . , s. Then for every integer m that is relatively prime with n the
class of m in U(Zn) may be written uniquely as rd1
1 · · · rds
s with 0 ≤di ≤pli−1
i
(pi−1),
i = 1, . . . , s. The vector (d1, . . . , ds) is called index system of m with respect to
(r1, . . . , rs).
A6.22. Proceed by induction.
A6.25. If n = mk, then k ≤log2 n. For all k ﬁnd an estimate for the kth root of n
and then compute a kth power. The latter computation has complexity O(log3 n),
while for the ﬁrst estimate the complexity is O∼(log2 n).
A6.26. Proceed as in § 3.3.1.
A6.28. A pair (x, f) is found by assigning arbitrarily x1 = f(x), in k ways, x2 =
f(x1) arbitrarily in X \ {x1}, in k −1 ways, . . . , xm = f(xm−1) arbitrarily in
X \{x1, . . . , xm−1}, in k−m ways, and the remaining values of f arbitrarily without
restrictions.
B6.4. The correct answer is (c).
B6.20. For instance, 5.
B6.23. The answer is 2, 5, 25, 121.
B6.24. The group U(Z15) is the product of a cyclic group of order 2 and of a cyclic
group of order 4.
B6.25. The group U(Z16) is the product of a cyclic group of order 2 and of a cyclic
group of order 4.
B6.26. The group U(Z17) is cyclic of order 16.
B6.27. The group U(Z18) is cyclic of order 6.
B6.28. |U(15)| = |U(16)| = 8, |U(17)| = 16, |U(18)| = 6.
B6.35. The correct answer is (a).
B6.36. The factorisation is found to be 906113 = 13 · 47 · 1483.

498
Solution to selected exercises
Exercises of Chapter 7
A7.10. The solution is trivial if n is even. Let n be odd. Then ϕ(n) = (p−1)(q−1) =
n+1−(p+q). So we know the sum of p and q, that is p+q = n+1−ϕ(n) = 2b, which
is even, and their product n = pq. Thus, p and q are equal to b±
√
b2 −n. Now there
is a simple algorithm, having complexity O(log3 n), which computes ⌊√n⌋. Indeed,
if n has k + 1 binary digits, a ﬁrst approximation m1 of ⌊√n⌋is given by 1 followed
by ⌊k/2⌋zeros. If m1 is not the correct value, change its second digit from left, a 0,
into a 1, obtaining a value m2. If it is too large, put the second digit back to 0 and
repeat the above with the third digit, obtaining m3. If on the other hand m2 is too
small, change its second digit into a 1 obtaining a diﬀerent m3, and so on.
A7.11. By the Chinese remainder theorem, it suﬃces to prove that ade ≡a (mod p)
for all a and for all prime p | n. This is obvious if p | a, else it follows from Fermat’s
little theorem.
A7.16. If g(x)y−f(x) were reducible, we would have g(x)y −f(x) = a(x, y)·b(x, y)
where the two polynomials a(x, y), b(x, y) have positive degree and at least one of
them does not depend on y. Let a(x, y) = a(x) be such a polynomial. Then a(x) is
a common factor of f(x) and of g(x), which is impossible.
A7.17. Hint: study the case in which the conic curve contains the point O = (0, 1)
ﬁrst; deﬁne the projection of the conic on the x-axis, associating with each point
P ̸= O of the conic the intersection of the line through P and O with the x-axis.
A7.27. Here is the proof in the case p ̸= q. We have already shown in the text that
the line through p and q has equation y −y1 = (y2 −y1)(x −x1)/(x2 −x1), so the
ordinate yr of the point r collinear with p and q is
yr = y1 + y2 −y1
x2 −x1 (x3 −x1),
where x3 is the abscissa of r; hence follows the formula for y3, because p + q is the
symmetric point of r with respect to the x-axis. On the other hand, the fact that r
lies on the elliptic curve says that (x3, yr) is a solution of the following system:
⎧
⎨
⎩
y = y1 + y2 −y1
x2 −x1 (x −x1),
y2 = x3 + ax + b.
Squaring the ﬁrst equation, we ﬁnd that the right-hand side of the second equation
is equal to the square of the right-hand side of the ﬁrst equation, so we ﬁnd a third
degree equation in x, equivalent to
x3 −
 y2 −y1
x2 −x1
2
x2 + (terms of degree 1 and 0 in x) = 0,
whose solutions are x1, x2 and x3. So the left-hand side of the last equation is a
polynomial equal to
(x −x1)(x −x2)(x −x3) = x3 −(x1 + x2 + x3)x2 + (· · · )x −x1x2x3;
hence follows that

Exercises of Chapter 7
499
x1 + x2 + x3 =
 y2 −y1
x2 −x1
2
,
giving the formula for x3.
A7.34. By Exercise A7.32, x and z are odd. Set r = (z + x)/2, s = (z −x)/2. Using
Exercise A7.31, prove that GCD(r, s) = 1. As y2 = 4rs, deduce that rs is a square
and, by Exercise A7.33, that there exist two integers n, m such that r = m2, s = n2.
Deduce (7.31).
B7.1. The correct answer is (d).
B7.5. The correct answer is (d).
B7.7. The correct answer is (d).
B7.9. The correct answer is (c).
B7.11. The correct answer is (a).
B7.14. The correct answer is (a).
B7.15. The correct answer is (c).
B7.16. The correct answer is (b).
B7.20. Consider the plaintext of the message sent to Edgar Allan Poe (see page
325). By applying Vigen`ere enciphering using as key word UNITED STATES, for
instance using the program of Exercise C7.3, the following ciphertext is found:
GE IEIASGDXV, ZIJ QL MW LAAM XZY ZMLWHFZEK EJLVDXW KWKE TX LBR ATQH
LBMX AANU BAI VSMUKHSS PWN VLWKAGH GNUMK WDLNRWEQ JNXXVV OAEG EUWBZWMQY MO
MLW XNBX MW AL PNFDCFPXH WZKEX HSSF XKIYAHUL? MK NUM YEXDM WBXZ SBC HV WZX
PHWLGNAMIUK?
It is straightforward to check that in the ciphertext given by Poe there are
exactly 16 transcription errors: the third letter should be I rather than J, the ﬁfth
letter (a I) was omitted. The reader might want to check the remaining errors.
B7.23. The correct answer is (d).
B7.24. The correct answer is (d), as the plaintext is take a day out.
B7.26. The correct answer is (a).
B7.27. The correct answer is (d).
B7.28. The correct answer is (d), as the inverse matrix exists and is
12
1
7 −11

.
B7.30. The correct answer is (a).
B7.31. The correct answer is (d).
B7.33. The correct answer is (b).
B7.35. The correct answer is (d), because the image of f is {1, 4}, so f is not
surjective. It follows that f is not injective either, because the domain and the
codomain have the same (ﬁnite) size: when this happens, the function is bijective if

500
Solution to selected exercises
and only if it is surjective, and this happens if and only if it is injective. Or, more
simply, f is not injective because f(1) = 4 = f(3).
B7.38. We have 270 = 250+20 = 250220 = (−¯1)(−¯6) = ¯6 = ¯2·¯3, so 269 = ¯3; therefore
69 is the required discrete logarithm.
B7.39. The correct answer is (d).
B7.40. The correct answer is (b).
B7.41. The correct answer is (b), because the only solution is 34 = 20 + 13 + 1.
B7.43. The correct answer is (a).
B7.45. The correct answer is (a).
B7.47. The correct answer is (a).
B7.49. The correct answer is (d).
B7.51. The correct answer is (c), because 7927 is a prime number.
B7.53. The correct answer is (a).
B7.55. The correct answer is (a).
B7.60. The correct answer is (b).
B7.61. The correct answer is p + q = (3, −2
√
6), so (d).
B7.64. The correct answer is (a).
B7.67. The correct answer is (c). A way of solving this exercise is by trial and error.
In the aﬃne plane with coordinates in F7 there are 7 · 7 = 49 points. In particular,
ﬁxing an abscissa (which is a number modulo 7), there are exactly 7 points having
that abscissa (and diﬀerent ordinates). We shall see if any of these poins lies on the
elliptic curve, and how many (at most two).
Consider ﬁrst x = 0. Then, of the 7 points having abscissa 0, only (0, 0) belongs
to the elliptic curve, because by substituting x = 0 in the curve equation we ﬁnd
y2 = 0 that has 0 as its only solution. Consider now x = 1. Substituting it in the
curve equation we ﬁnd y2 = 0, so among the points with abscissa 1 only (1, 0)
belongs to the curve. For x = 2, we ﬁnd y2 = 6, which has no solutions, so there are
no points having abscissa 2 on the elliptic curve. Analogously, by substituting x = 3
we ﬁnd y2 = 3, which admits no solutions either. For x = 4, on the other hand, we
ﬁnd y2 = 4, which admits two solutions: y = 2 e y = 5, so (4, 2) and (4, 5) are points
of the elliptic curve (the only ones with abscissa 4). For x = 5, we have y2 = 1,
which has two solutions: y = 1 and y = 6, that is (5, 1) and (5, 6) are points of the
elliptic curve. Finally, for x = 6 we ﬁnd y2 = 0, that is, (6, 0) is a further point of
the elliptic curve. And this is all: in the aﬃne plane we have found 7 points, so the
curve has 8 points, including the point at inﬁnity.
B7.68. The correct answer is (d). Proceed as in example 7.9.18.

Exercises of Chapter 8
501
Exercises of Chapter 8
A8.1. This a variation of the classic binomial probability distribution (see [29], p. 63).
Fix a value of i, 0 ≤i ≤n. The probability of n −i errors occurring in n −i ﬁxed
positions of a binary string of length n is pn−i(1 −p)i. So the probability of n −i
occurring in any given string of length n is
n
i
	
pn−i(1−p)i (see Exercise A1.15). If we
have more 0’s than 1’s and decode as HEADS the incoming string, the probability
of having made a mistake is that of at least ⌊n/2⌋errors having occurred, and the
formula follows from the above. Notice that 1 = (p+(1−p))n = n
i=0
n
i
	
pn−i(1−p)i.
Hence follows that 0 < Pn < 1. Finally, we have (see Exercise A1.23)
Pn < [p(1 −p)]n/2

0≤i<[n/2]

n
i

< 2n−1[p(1 −p)]n/2.
Notice that (2p −1)2 > 0, that is, 4p2 −4p + 1 > 0, so p(1 −p) < 1/4 and from this
it immediately follows that Pn tends to zero when n tends to inﬁnity.
A8.2. Using the theorems about linear systems over a ﬁeld, prove that there is
exactly one solution of the system (8.3) when the values of x1, x2, x3, x4 are assigned
arbitrarily.
A8.4. The triangle inequality is the only property whose truth it is interesting to
verify. Notice that, if x and x′ diﬀer in the ith coordinate, then in that coordinate
either x diﬀers from x′′ or x′ diﬀers from x′′.
A8.5. A code detects k errors if and only if, by modifying a codeword in h ≤
k coordinates, we never get another codeword. This happens if and only if two
codeword always have distance at least k + 1. This proves (i). A code corrects k
errors if and only if by modifying a codeword in h ≤k coordinates, the n-tuple we
get has distance greater than k from every other codeword. This happens if and only
if two codewords always have distance at least 2k + 1. This proves (ii).
A8.6. See the solution of Exercise A8.1.
A8.8. Let i be a positive integer smaller than n. The elements of Fn
q having Hamming
distance exactly i from x = (x1, . . . , xn) are those diﬀering from x in exactly i
coordinates. They can be obtained as follows: choose in
n
i
	
ways the coordinates
xh1, . . . , xhi, with 1 ≤h1 < · · · < hi, of x to be modiﬁed and, for each j = 1, . . . , i,
modify the coordinate of x in position hj in q −1 ways, as many as the elements of
Fq diﬀerent from xhj.
A8.11. By the properties of the binomials (see Exercise A1.14), we have 2d =
d
i=1
n
i
	
= 2 · k
i=1
n
i
	
.
A8.13. If Singleton bound is better than Hamming one, we have k
i=1
n
i
	
< 2d−1,
where k = (d −2)/2. By proceeding as in the previous solution, verify that this
relation is equivalent to k
i=0
d
i
	
+ 1/2

d
k+1
	
> k
i=0
n
i
	
. Notice that n ≥d and
that the previous inequality holds for n = d. Prove instead that it does not hold for
n = d + 1, and deduce that it does not hold for n ≥d + 1. Indeed, for n = d + 1, by
using Equation (1.51), the inequality may be written as 1/2

d
k+1
	
> k
i=0[
d+1
i
	
−

502
Solution to selected exercises
d
i
	
] = k
i=1
 d
i−1
	
and notice that for d ≥12 we have 2

d
k−1
	
>

d
k+1
	
. Directly
verify cases d = 8, 10.
A8.16. Suppose x diﬀerent from zero and notice that the degree two polynomial
f(t) = (tx + y) × (tx + y) only assumes positive or zero values. So its discriminant
is non-positive.
A8.17. If the sequence {xn}n∈N is bounded from above, its least upper bound is
also an upper bound for the sequence {bn}n∈N, so ξ = lim supn→∞xn is ﬁnite.
A8.20. Set n! = nne−na(n). It suﬃces to prove that a(n) is O(n). Notice that
a(n + 1)/a(n) = e(1 + 1/n)−n and that we have the inequality (1 + 1/n)n+1/2 > e.
The latter follows from the well-known formula
log 1 + x
1 −x = log(1 + x) −log(1 −x) = 2

x + x3
3 + x5
5 + · · ·

> 2x,
which holds for 0 < x < 1, setting x = 1/(2n + 1). Then we have a(n + 1)/a(n) <
(1 + 1/n)1/2, that is, the function b(n) = a(n)/√n is positive and decreasing, so it
tends to a ﬁnite, positive limit. Hence follows the claims.
A8.21. Set r = [δn]. The last term in the sum that appears in (8.6) is the largest
one. So we have

n
r

(q −1)r ≤Vq(n, r) ≤(1 + r)

n
r

(q −1)r.
Take the logarithm in base q and divide by n. Applying Stirling formula we get
1
n logq

n
r

(q −1)r = δ logq(q −1) + logq n −δ logq r −(1 −δ) logq(n −r) + O(1),
so
1
n logq

n
r

(q −1)r = Hq(δ) + O(1).
Hence follows the claim.
A8.22. By the Gilbert–Varshamov bound, we have
α(δ) = lim sup
n→∞
logq Aq(n, nδ)
n
≥lim
n→∞

1 −logq Vq(n, nδ)
n

.
The claim follows from Lemma 8.4.7.
A8.23. We have (q −1)/q ≤δ if and only if dq−nq+n > 0. In this case the Plotkin
bound implies Aq(n, d) ≤qd/(qd −n(q −1)). Then
0 ≤α(δ)= lim sup
n→∞
logq Aq(n, nδ)
n
≤lim sup
n→∞
 logq(nδq)
n
−logq(nδq −nq + n)
n

= 0.
Suppose now 0 ≤δ ≤(q −1)/q, which implies that dq −nq + n ≤0. Set
m = [q(d −1)/(q −1)] and notice that m < n. Let C be a code of type (n, M, d)q.
Considering the mapping p : C →Fn−m
q
which, to each x ∈C, associates the vector
in Fn−m
q
consisting of its last n −m coordinates, notice that there is a subset C′ of

Exercises of Chapter 8
503
C of size M ′ ≥qm−nM such that all elements of C′ have the same image in p. We
may consider C′ as a code of type (m, M ′, d)q. We may apply the Plotkin bound,
which yields qm−nM ≤M ′ ≤qd/(qd −mq + m) ≤d. So we have qm−nAq(n, d) ≤d,
hence, by taking d = nδ and n ≫0 we obtain the claim.
A8.26. The rows of a generating matrix X are linearly independent. So there is a
non-zero minor of order k. Up to renaming the coordinates, we may assume that
this minor is determined by the ﬁrst k columns. Let A be the submatrix of X
determined by the ﬁrst k columns. The matrix A−1 · X is in standard form and is
again a generating matrix for the same code, obtained with a basis change.
A8.29. It is suﬃcient to verify that X · Ht = 0, where 0 is here the k × (n −k) zero
matrix.
A8.33. The mapping x ∈C →e + x ∈e + C is a bijection between the words of C
and the elements of the coset e + C. Show, further, that every element of Fq
n lies in
exactly one coset.
A8.40. Consider the two binary codes
C = {(1, 0, 1, 1, 1, 0, 1, 1, 1, 0), (1, 0, 1, 1, 0, 1, 1, 1, 0, 1), (0, 1, 1, 1, 0, 1, 0, 1, 0, 1),
(1, 1, 0, 1, 1, 0, 1, 1, 0, 1), (0, 0, 0, 0, 1, 1, 1, 1, 0, 0)},
C′ = {(1, 1, 1, 1, 1, 0, 0, 1, 1, 0), (1, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 1, 1, 0, 0, 0, 0, 0, 0, 0),
(0, 1, 1, 1, 1, 1, 1, 0, 0, 0), (1, 1, 1, 1, 0, 1, 0, 0, 0, 1)}.
Verify that D(C) = D(C′). To prove that C and C′ are not equivalent, show that
there is a coordinate such that all the elements of C have the same symbol on that
coordinate, while for no coordinate the same happens in C′.
A8.45. Hint: prove that the ring of classes modulo xn −1 admits as a representative
system the set of polynomials {a0 + a1x + · · · + an−1xn−1, ai ∈Fq, 0 ≤i < n}.
A8.46. Let xn −1 = a(x) · b(x). A polynomial c(x) in Fq[x]/(xn −1) is in C if and
only if it is divisible by a(x) in Fq[x], so if and only if its product by b(x) is zero
modulo xn −1.
B8.1. The correct answer is (b). Let us see why. The vector (0, 1, 1, 1, 1, 1, 1) is
a word of the Hamming code if and only if it satisﬁes the system of three linear
equations (8.3) on page 410, where the calculations are carried out in Z2. As the
given vector does not satisfy any of the three equations of the system, this means
that it is not a word of the Hamming code. Moreover, by the reasoning on page 410,
it follows that the error is in the ﬁrst position, so the correct word is (1, 1, 1, 1, 1, 1, 1).
To check that the calculations are correct, it is useful to verify that (1, 1, 1, 1, 1, 1, 1)
is actually a word of the Hamming code, that is, it satisﬁes the system (8.3). If this
happens, as in our case, we may be sure that no mistake has been made.
B8.2. The correct answer is (a); indeed the vector satisﬁes all three equations of
the system (8.3).
B8.3. The correct answer is (d), because the vector satisﬁes the ﬁrst two equations
of the system (8.3), but not the third one, so the error is in the seventh position,
by what has been argued on page 410. To double-check this, notice that the correct

504
Solution to selected exercises
vector (0, 1, 0, 0, 0, 1, 1) veriﬁes the system (8.3), that is to say, it is a word of the
Hamming code.
B8.4. The correct answer is (c); indeed Hamming distance is by deﬁnition the
number of diﬀerent coordinates, which in this case are the second, third, ﬁfth and
sixth ones.
B8.6. The correct answer is (c). Indeed, a subset of a vector space is a vector
subspace if: (1) it is closed under addition, (2) it is closed under the product by
scalars. When we consider binary codes, the scalars are only 0 and 1, so condition
(2) is automatically veriﬁed. We have only to check condition (1). Notice now that
(0, 0, 1) + (0, 1, 0) = (0, 1, 1); hence follows that all other possible sums, that is,
(0, 0, 1) + (0, 1, 1) = (0, 1, 0) and (0, 1, 0) + (0, 1, 1) = (0, 0, 1), always give elements
belonging to the subset, so it is a vector subspace. Finally, the relation we have
found among the elements of the subspace says that the dimension is 2, because
(0, 1, 0) and (0, 0, 1) clearly are linearly independent vectors.
B8.11. The correct answer is (b); indeed, (1, 1, 2, 0) = (1, 0, 1, 1)+(0, 1, 1, 2), so there
are no more than two linearly independent generators (recall that the dimension of
a vector space is equal to the greatest number of linearly independent generators).
B8.12. The correct answer is (d). Let us see why. To compute the minimum distance
of the code, write all codewords and compute their weight, that is, the number of
non-zero coordinates. By Proposition 8.5.3, the minimum distance is equal to the
minimum weight of the non-zero words. In our case, we ﬁnd that the minimum
distance is d = 3. On the other hand, we know that n = 4 and that k = 2 by
Exercise B8.11, so d = 3 = n −k + 1, that is to say, the code is maximum-distance
separable, according to Deﬁnition 8.5.2 on page 420. Finally, d = 3 implies that the
code detects two errors and corrects one, by Theorem 8.3.4 on page 412.
B8.18. The correct answer is (d). Theorem 8.5.9 on page 424, indeed, says that the
minimum distance of the linear code is equal to the minimum number of linearly
independent columns of the parity check matrix. So, examine the columns of the
matrix given in the exercise. Considering all possible combinations, we see that there
are no three columns whose sum is zero (thus being linearly dependent), while there
are four columns, for instance, the third, fourth, seventh and eighth one, whose sum
is zero (so they are linearly dependent). So we may conclude that the minimum
distance of the linear code is four.
Exercises of Chapter 9
A9.1. Notice that every key is an ordered r-tuple of elements of the alphabet (see
Exercise A1.21).
A9.5. Start as in the solution of Exercise A8.16.
A9.6. Again, start as in the solution of Exercise A8.16.
A9.10. The claim is trivial if the vector space has dimension 1. Moreover, one
implication is trivial. Finally, assume that AB = BA. Deduce that A and B have a
common eigenvector v. So the subspace ⟨v⟩is invariant under A and B. But then

Exercises of Chapter 9
505
the orthogonal subspace ⟨v⟩⊥is also invariant under A and B. Then proceed by
induction.
A9.11. Every observable of the form
1
2
 λ1 + λ2
λ1 −λ2
λ1 −λ2
λ1 + λ2

with λ1 ̸= λ2.
B9.1. The solution is HQRC.
B9.2. The solution is QMIA.
B9.6. The answer is NO.
B9.7. We have
[B, A] =
 0 −2
2
0

.

References
1. Adleman, L.M., Rivest, R.L., Shamir, A.: A method for obtaining digital signa-
tures and public–key cryptosystems. Communications of the ACM, 21, 120–126
(1978)
2. Agrawal, M., Kayal, N., Saxena, N.: PRIMES in P. Ann. of Math., 160, n. 2,
781–793 (2004)
3. Alford, W.R., Granville A., Pomerance, C.: There are inﬁnitely many Carmich-
ael numbers. Ann. of Math., 139, n. 3, 703–722 (1994)
4. Artin, M.: Algebra. Prentice Hall, Englewood Cliﬀs, NJ, USA (1991)
5. Baldi, P.: Introduzione alla probabilit`a con elementi di statistica. McGraw-Hill,
Milano (2003)
6. Baylis, J.: Error–correcting codes. Chapman and Hall Math., Londra (1998)
7. Bennet, C.H., Brassard, G.: Quantum cryptography: public key distribution and
coin tossing. Proceedings of IEEE International Conference on Computers, Sys-
tems and Signal Processing, Bangalore, India, December 1984, 175–179 (1984)
8. Bennet, C.H., Bessette, F., Brassard, G., Salvail, L., Smolin, J.: Experimental
quantum cryptography. J. Cryptology, 5, 3–28 (1992)
9. Bennet, C.H., Brassard, G., Ekert, A.: Quantum cryptography. Scientiﬁc Amer-
ican October 1992, 50–57 (1992)
10. Boyer, C.B.: A History of Mathematics. Wiley, New York (1968).
11. Burton, D.M.: Elementary number theory. Allyn and Bacon, Inc., Boston, Mass.-
Londra (1980)
12. Canuto, C., Tabacco, A.: Analisi Matematica 1. Unitext, Springer-Verlag, Mi-
lano (2003)
13. Ciliberto, C.: Algebra lineare. Bollati Boringhieri, Torino (1994)
14. Coppersmith, D.: Fast evaluation of logarithms in ﬁelds of characteristic two.
IEEE Transactions on Information Theory IT, 30, 587–594 (1984)
15. Curzio, M.: Lezioni di algebra. Liguori, Napoli (1970)
16. Davenport, H.: The higher arithmetic. An introduction to the theory of numbers.
Cambridge University Press, Cambridge (1999)
17. Deutsch, D.: The fabric of Reality. Allen Lane, Londra (1977)
18. Deutsch, D., Ekert, A.: Quantum Computation. Physics World, 11, n. 3, 33–56
(1998)
19. Diﬃe, W., Hellman, M.E.: New directions in cryptography. IEEE Transactions
on Information Theory IT, 22, 644–654 (1976)

508
References
20. Dirac, P.A.M.: The principles of quantum mechanics. Oxford University Press,
New York (1958)
21. Doxiadis, A.: Uncle Petros and Goldbach’s Conjecture. Bloombsbury Publ., New
York and London (2000)
22. Ebbinghaus, H.D., et al.: Numbers. Springer-Verlag, Berlin Heidelberg New York
(1991)
23. Garey, M.R., Johnson, D.S.: Computers and intractability. A guide to the theory
of NP–completeness. W. H. Freeman & C., San Francisco, Calif. (1979)
24. Grimaldi, R.: Discrete and Combinatorial Mathematics. Addison–Wesley, 5th
ed., Reading, Mass. (1988)
25. Hardy, G. H.: A Mathematician’s Apology. Cambridge University Press (1940)
26. Hardy, G.H., Wright, E.M.: An introduction to the theory of numbers. Oxford
Science Publ., 5th ed., New York (1979)
27. Herstein, I.N.: Topics in Algebra. Wiley, New York (1975)
28. Hodges, A.: A. Turing: the Enigma of Intelligence. Unwin Paperbacks, Londra
(1983)
29. Isaac, R.: The pleasures of probability. Springer-Verlag, Berlin Heidelberg New
York (1995)
30. Koblitz, N.: A course in number theory and cryptography. Springer-Verlag,
Berlin Heidelberg New York (1994)
31. Kraitchick, M.: Recherches sur la th´eorie des nombres. Gauthiers-Villars, Parigi
(1929)
32. Lang, S.: Algebra. Addison Wesley, New York (1978)
33. Lenstra, A., Jr., Lenstra, H.W., Jr. (ed.): The development of the number ﬁeld
sieve. Springer-Verlag, Berlin Heidelberg New York (1993)
34. Lenstra, H.W., Jr.: Primality testing. In: Studiezweek Getaltheorie en Comput-
ers, 1–5 September 1980, Stichting Mathematisch Centrum, Amsterdam (1982)
35. Lenstra, H.W., Jr.: Factoring integers with elliptic curves. Ann. of Math., 126,
n. 2, 649–673 (1987)
36. van Lint, J.H.: Introduction to coding theory. II ed., Springer-Verlag, Berlin
Heidelberg New York (1992)
37. van Lint, J.H., van der Geer, G.: Introduction to coding theory and algebraic
geometry. DMV Seminar 12, Birkh¨auser, Basel (1988)
38. Lomonaco, S.J.: A talk on quantum cryptography or how Alice outwits Eve. Proc.
Sympos. Appl. Math. 58, American Math. Soc., Providence, R.I., 237–264 (2002)
39. McEliece, R.J.: The theory of information and coding. Encyclopedia of Math.
and its Appl., vol. 3. Addison–Wesley, Reading, Mass. (1977)
40. McEliece, R.J., Ash, R.B., Ash, C.: Introduction To Discrete Mathematics.
McGraw-Hill, New York, (1989)
41. MacWilliams, F.J., Sloane, N.J.A.: The theory of error–correcting codes. North
Holland, Amsterdam (1977)
42. Menezes, A., Okamoto, T., Vanstone, S.A.: Reducing elliptic curves logarithms
to logarithms in a ﬁnite ﬁeld. IEEE Transactions on Information Theory IT, 39,
1639–1646 (1993)
43. Monk, J. D.: Introduction to set theory, McGraw-Hill, New York (1969)
44. Odlyzko, A.M.: Discrete logarithms in ﬁnite ﬁelds and their cryptographic sig-
niﬁcance. Advances in Cryptology, Proc. Eurocrypt, 84, 224–314 (1985)
45. Piacentini Cattaneo, G.M.: Algebra, un approccio algoritmico. Decibel Zanichel-
li, Bologna (1996)

References
509
46. Pomerance, C., Selfridge, J.L., Wagstaﬀ, S.S.: The pseudoprimes to 25 · 109.
Math. Comp., 35, 1003–1026 (1980)
47. Quarteroni, A., Saleri, F.: Introduzione al calcolo scientiﬁco. Unitext, Springer-
Verlag, Milano (2004)
48. Ribenboim, P.: The new book of prime numbers records. Springer-Verlag, Berlin
Heidelberg New York (1996)
49. Rosen, K.H.: Elementary number theory. Addison–Wesley, Reading, Mass.
(1988)
50. Schoof, R.: Elliptic curves over ﬁnite ﬁelds and the computation of square roots
mod p. Math. Comp., 44, 483–494 (1985)
51. Sernesi, E.: Geometria I. Bollati Boringhieri, Torino (1989); published in English
as Sernesi, E., Montaldi J.: Linear Algebra: A Geometric Approach. Kluwer
Academic Publishers Group (1992)
52. Shamir, A.: A polynomial time algorithm for breaking the basic Merkle–Hellman
cryptosystem. Proc. 23rd annual symposium on the foundation of computer
science (Chicago, Ill., 1982), IEEE, New York, 145–152 (1982)
53. Shannon, C.E.: Communication theory of secrecy systems. Bell Systems Techni-
cal Journal, 28, 656–715 (1949)
54. Shor, P.W.: Polynomial–time algorithms for prime factorization and discrete
logarithm on a quantum computer. SIAM J. Computing, 26, 14–84 (1997)
55. Siegel, C.L.: Topics in complex function theory, Vol. I. Wiley, New York (1969)
56. Silverman, J.H.: The arithmetic of elliptic curves. Springer-Verlag, Berlin Hei-
delberg New York (1985)
57. Singh, S.: Fermat’s Last Theorem. Anchor Books, New York (1998)
58. Singh, S.: The Code Book: The Science of Secrecy from Ancient Egypt to Quan-
tum Cryptography. Anchor Books, New York (2000)
59. Tenenbaum, G., Mend`es France, M.: The prime numbers and their distribution.
Student Math. Library, vol. 6, American Mathematical Society (2000)
60. Tsfaman, M.A., Vladut, S.G., Zink, T.: On Goppa codes which are better than
the Varshamov–Gilbert bound. Math. Nachr., 109, 21–28 (1982)
61. Weil, A.: Number Theory. An approach through history from Hammurabi to
Legendre. Birkh¨auser, Boston (1983)
62. Wiesner, S.: Conjugate coding. SIGACT News, 15, n. 1, 78–88 (1983; original
manuscript, around 1970)
63. Wiles, A.: Modular elliptic curves and Fermat’s Last Theorem. Ann. of Math.,
142, 443–551 (1995)

Index
addition, VII, 1, 14, 97, 102, 104, 106,
107, 117, 174, 203, 255
in a ﬁeld, 228, 260
in arbitrary base, 39
in base 2, 33–34, 36, 37, 88
in the ﬁeld F4, 224
of polynomials, 24, 25, 102, 103
Adleman, 350, 362, 363
Agrawal, VIII, 157, 281
AKS, VIII, 157, 281, 282, 284, 288, 289,
317
al-Khowarizmi, 87
al-Kind¯ı, 329
algebraic, 214, 215
algorithm, VII, VIII, 87–89, 92–94, 111
baby step–giant step, 343–345
deterministic, 250, 263, 272, 273, 281,
346, 347
division, 14, 15, 21, 22, 25
variant, 67
Euclidean, 14, 17, 19, 22, 26, 31,
43–45, 52, 69, 70, 78, 79, 81, 84,
98–101, 103, 174, 229, 254, 293,
336, 341, 347, 353, 385, 476, 480,
486
complexity, 98–100
variant, 67, 79, 84, 108, 113
exponential, VII, VIII, 94
exponentiation by squaring, 127
knapsack, 346–350, 387, 402
Miller–Rabin, 272–273, 317
multiplication, 103, 104
polynomial, VII, 94
probabilistic, VIII, 164, 250, 251, 260,
263, 264, 272, 281, 384, 390
subexponential, 94
to compute a continued fraction, 71
to compute discrete logarithms, 344
to compute square roots, 248–251
to compute the roots of a polynomial,
187
to write a binary number in base 10,
101
to write an integer in a base, 32
alphabet, 321–323, 406, 408, 409
approximation
of a rational number, 44, 53
of a square root, 48
of an irrational number, 58–61
authentication of signatures, 351,
360–362
automorphism of a ﬁnite ﬁeld, 222, 253,
258, 493
B-number, 294, 299
B-vector, 294, 299
Bachmann, 89
Bennet, 460, 461, 467
β–deﬁned, 41, 167, 168, 207, 211
B´ezout’s identity, 17–20, 22, 23, 26, 79,
84, 101, 103, 124, 174, 178, 229,
336, 341, 474, 480, 481, 486
complexity, 101, 103
for polynomials, 84
binary digit, 88, 443, 450, 452, 461, 498
binary system, 31, 33, 39
Bombelli, 48

512
Index
Bose, 428
bound
Gilbert–Varshamov, 417–419,
434–436, 502
asymptotic, 418, 437
Hamming, 415, 417, 437, 501
Plotkin, 416, 418, 419, 502, 503
asymptotic, 419, 437
Singleton, 414, 415, 420, 436, 437, 501
Brassard, 460, 461
Brun’s theorem, 156
Cantor’s theorem, 252
Cardano, 366
Carmichael number, 264, 265, 267, 277,
313, 316, 317
carry, 34, 39, 96
casting out nines, 120–141
Cauchy–Schwarz inequality, 416, 437,
457, 460, 468
challenge, 362, 363, 366
Champollion, 328
characteristic
of a ﬁeld, 218–220, 222, 224, 251,
253–255, 367, 370–372, 374, 379,
402, 434
of a ring, 30
zero, 30, 218
Chebyshev, 155
Chebyshev’s theorem, 155
cipher, VIII, 328, 329, 334, 335, 341,
362, 392, 451
aﬃne, 336–340, 387
Caesar, 321, 322, 327, 336, 364, 392,
401
classic, 319, 334, 335
Hill, 340, 342
Merkle–Hellman, 348–350, 398, 402
monoalphabetic, 323
polyalphabetic, 323, 339
public-key, 335, 336, 341, 342, 344,
348, 349, 362, 363, 390
shift, 322
translation, 336
Vernam, 451–454, 460, 463, 464, 466,
468, 469
key, 452
closure
algebraic, 219–220, 252, 253, 377
theorem of existence, 220
projective, 374
code, VII–X, 149, 213, 405, 407–410,
412, 451, 466
ASCII, 334
BCH, 428, 431, 433
binary, 409, 411, 427, 436, 437,
441–443, 503, 504
block, 409
cyclic, 425–429, 443
dual, 422, 442
equivalent, 438
by positional permutation, 438
by symbol permutation, 438
distance, 438
error-correcting, VI, IX, 405, 410–413,
415–417, 424, 433, 434, 441, 443,
501
error-detecting, 412
Goppa, 429–431, 433–436, 439, 443
geometric, 436
Hamming, 410, 412–414, 416, 423,
428, 430, 436, 437, 439, 440, 443,
503, 504
length, 409, 412–414, 417, 419, 426,
427, 429, 438, 439, 443
linear, 419, 420
linearly equivalent, 439
maximum-distance separable, 420,
424, 441, 504
perfect, 416, 437, 442
repetition, 408, 409, 428, 436
size, 409
variable-length, 405, 409
with assigned distance, 429
coeﬃcient
leading, 23, 178
of a polynomial, 23
of a recurrence relation, 5
completing the square, 235, 493
complexity, VII, 87–111, 453
computational, 87
exponential, 94, 111
factorial, 94, 111
linear, 111
logarithmic, 111
of addition, 96
in a ﬁeld, 228
of polynomials, 138

Index
513
of AKS test, 290
of an algorithm, 88, 89
of B´ezout’s identity, 101, 103
of computing a continued fraction,
108
of computing a square root, 250
of computing the rational roots of a
polynomial, 203
of division, 97
of elementary operations, 95–97
of exponential modulo an integer, 128
of Fermat factorisation method, 315
of Gaussian elimination, 108, 254
of Jacobi symbol, 248
of matrix multiplication, 108
of Miller–Rabin test, 272, 314
of multiplication, 96, 104
in a ﬁeld, 228
of polynomials, 138
of operations in a ﬁeld, 102, 228–229
of operations on polynomials, 101–103
of Ruﬃni–Horner method, 106, 107
of Solovay–Strassen tests, 268
of the baby step–giant step algorithm,
345
of the binomial coeﬃcient, 109
of the determinant of a matrix, 108,
254
of the Euclidean algorithm, 98–100
of the factorial of an integer, 108
of the inverse of a matrix, 108, 254
of the knapsack problem, 387
of the representation of an integer in
a base, 101
of the ρ method, 312, 313
of the sieve of Eratosthenes, 158, 199
of the solution of a Diophantine
equation, 101
polynomial, 94, 111, 281
condition
ascending chain, 177
initial, for a recurrence relation, 5
congruence, VII, 115–120, 136, 138, 142,
163–165, 199, 235, 311, 336, 354,
356, 358, 366, 486, 487
linear, 17, 122–124, 136, 143, 147,
278, 387, 396
modulo an ideal, 118
polynomial, 229–234, 258–260, 278
second degree, VIII, 230, 234–236,
239, 244, 245, 258, 260
conic, 368, 370, 388
conjecture
Goldbach, 156
main, complexity theory, 347
constructibility of polygons, 171
content of a polynomial, 182, 184
continued fraction, VII, 43–61, 70–72,
83, 108, 299, 300
ﬁnite, 44, 49
generalised, 49
geometrical model, 57
inﬁnite, 48–50, 85
periodic, 50, 56, 57, 71, 72, 83, 85,
299
simple, 44
ﬁnite, 45–48, 53
inﬁnite, 48, 53–55, 58
convergent of a continued fraction,
50–55, 57–61, 70–72, 85, 299, 300
recurrence relation, 50
Coppersmith, 368
coprime numbers, 17, 18, 161–163, 168,
198, 202, 218, 219, 230, 239
coset, 423, 424, 438, 442, 485
criterion
Eisenstein, 188–190, 208, 209, 491
Euler, 237, 238, 245, 265, 270
cryptanalysis, VIII, 329–331, 333, 339,
366, 368, 387, 396, 451, 453
in a group, 367
cryptanalyst, 332, 453, 468
cryptography, VI–VIII, X, 149, 157,
191, 213, 319, 321, 329, 331, 343,
345, 346, 363, 366–369, 380, 382,
384, 385, 419, 435
glossary, 331
in a group, 368
over elliptic curves, 384–385
public-key, VI, VIII, 290, 319, 336,
341, 342, 344, 348, 362, 363, 390
quantum, IX, 445, 446, 451, 460, 467
cryptologist, 331, 332, 467
cryptosystem, 330, 332, 333, 341, 363,
365
ElGamal, 364
public-key, 349
cubic curve, 368, 372

514
Index
curve, 368–370, 372
algebraic, 368
elliptic, IX, 366, 368, 372–373
over ﬁnite ﬁelds, 381–383
over Q, 380
real, 375, 380
hyperelliptic, 370–372
irreducible, 368
non-singular, 377
rational, 369, 370, 374
singular, 377
Dal Ferro, Scipione, 366
Dal Fior, 366
decoding, syndrome, 423, 424, 443
degree
of a curve, 368
of a monomial, 25
of a polynomial, 23
Deligne, 382
derivative, 27, 28, 69, 81, 84, 192, 210,
211, 233, 371, 376, 388, 434, 446
determinant
of a matrix, 8, 108, 204, 254, 339,
387, 395, 483
Vandermonde, 204, 429, 433, 490
Deutsch, 449, 451
Diﬃe, 349
Diﬃe–Hellman hypothesis, 363, 364,
367, 384, 451
digit
non-recurring, 42, 85
recurring, 42, 85, 168
Dirichlet
product, 201
series, 273
theorem, 154, 228, 245
distance
between two words, 416, 443
Hamming, 412, 413, 415, 424, 436,
438, 440, 501, 504
minimum, 412–414, 420, 422, 424,
429, 431, 433, 434, 440–442
dividend, 15
divisibility
test of, 138
divisibility, test of, 121, 138, 142
division, VII, 14–17, 21, 22, 31, 32, 60,
116, 117, 121, 141, 157, 205, 249,
250, 301, 302, 450
in base 2, 38–39
of polynomials, 84, 105, 106
synthetic, 106
divisor, 15, 16, 41, 97, 139, 149, 159,
165, 166, 169, 170, 173, 174, 176,
196, 198, 201, 202, 221, 222, 270,
274, 284, 293, 484
of a polynomial, 182, 197
domain
integral, 1, 14, 22, 24, 25, 30, 67, 68,
118, 119, 137, 173–175, 182, 202,
203, 207, 252
Euclidean, 22
ﬁnite, 68
Noetherian, 177
unique factorisation, 175, 176, 182,
188
eigenvalue, 1, 8, 12, 457, 468
eigenvector, 1, 75, 456, 457, 459, 468,
478, 479, 504
element
algebraic, 214, 215
irreducible, 174, 175, 177, 178, 184,
202, 208
not prime, 175
prime, 174, 175, 186, 202, 207, 208
transcendental, 214
ElGamal cryptosystem, 364
Enigma, VI, 329, 330
entropy, 418
equation
Diophantine
ﬁrst degree, VII, 17, 20, 43, 61, 101,
124
polynomial, VIII
second degree
discriminant, 181, 203, 254, 371,
383, 502
quadratic formula, 254
third degree, 366
equivalent
numerical, 323, 324, 333–337, 340,
342, 357, 364, 390, 398–400
2-digit, 333, 334
binary, 333, 334, 349, 390, 391

Index
515
estimate
asymptotic, 417, 418
O−, 89–92
of the complexity of an algorithm, 89,
92
Euclid, 150, 152
algorithm, VII, 14, 17, 19, 22, 26, 31,
43–45, 52, 67, 69, 70, 78, 79, 81,
84, 98–101, 103, 108, 113, 174,
229, 254, 293, 336, 341, 347, 353,
385, 476, 480, 486
Euler, 48, 125, 152, 154, 171, 199, 237,
243
criterion, 237, 238, 245, 265, 270
function, 124, 128, 139, 149, 160–162,
200, 211, 355, 357
pseudoprime, 265–271, 314, 316
theorem, 125, 127, 128, 139, 144, 152,
153, 156, 162–164, 199, 277, 357,
487
exchange of private keys, 363–364, 367,
384, 390
exponential modulo an integer, 126–128,
229, 238, 250, 289, 355, 385
expression of a real number in base β,
40
factor basis, 294, 299
factorial of an integer, 28, 63, 84
factorisation, VIII, 17, 43, 157, 158,
161–163, 167, 171, 175, 176
in an integral domain, 173–176
of a Fermat number, 171
of a polynomial, 191, 196, 225, 226,
256
over a factorial ring, 182–187
over a ﬁeld, 179–181
with integer coeﬃcients, 188
with rational coeﬃcients, 188–190
of an integer, 149–151, 168, 170, 198,
200, 213, 219, 228, 232, 234, 248,
267, 270, 276, 279, 290
factorisation method, VIII, 261, 290–313
factor bases, 294
factorisation bases, 300
Fermat, 291–292, 300, 309, 315–318
generalisation, 292–294, 296
Kronecker, 195–198, 212
Pollard, 385, 403
reduction modulo p, 212
Fermat, 170, 291
last theorem, 380
little theorem, 162–165, 169, 199, 200,
211, 261, 262, 265, 281, 282, 385,
498
number, 168, 170, 171, 173, 207, 245
Ferrari, 366
Fibonacci, 7, 48
number, 6–11, 47, 66, 67, 69, 70, 84,
98, 473, 474, 476
ﬁeld, 1, 5, 6, 8, 9, 22, 24, 64–66, 102,
119, 137, 138, 162, 179, 181, 186,
188, 191, 192, 203, 204, 207, 208,
213–220, 237, 251–255, 260, 273,
338, 368, 369, 377, 379, 380, 388,
400, 401, 419, 430, 492
algebraically closed, 179, 180, 219,
253
complex, 273
ﬁnite, VIII, 68, 102, 213, 220–222,
227–229, 243, 253, 254, 343, 344,
363, 364, 367, 380–384, 402, 408,
430, 431, 436
theorem of existence, 221
fundamental, 218
of fractions, 182, 433
of order 16, 226, 255, 256
of order 4, 224–225, 256
of order 8, 225, 255, 256
of order 9, 226, 254–256
of rational functions, 182, 203, 251
real, 389
splitting, of a polynomial, 217–218,
221–223, 252–254, 283
ﬁeld extension, 213–218, 220, 221,
251–253, 256
algebraic, 214–217
transcendental, 216
formula
Stirling, 437, 502
Taylor, 29, 30, 154, 233
frequency, 323, 326, 327, 329, 386, 391,
401
frequency analysis, 326–327, 329, 333,
337, 339, 387, 453
freshman’s dream, 199, 219, 222, 284
Frobenius, 222
function

516
Index
characteristic of a set, 472
completely multiplicative, 161, 247
dominating, 89
elliptic, 380
Euler, 124, 128, 139, 149, 160–162,
200, 211, 355, 357
multiplicative, 161
M¨obius, 200
multiplicative, 161, 200, 201, 488, 489
ϕ, 124, 128, 139, 149, 160, 161, 200,
357
polynomial, 27, 343
trapdoor, 344, 350
fundamental subring, 218, 220
Galois theory, 171
Gauss, 2–4, 48, 117, 154, 155, 235, 243,
314
lemma, 184, 185, 240–242
theorem, 184–186, 188, 490
Gaussian, 163, 164, 167, 171, 202, 206,
207, 270, 273–277, 283–285, 288
Gaussian elimination, 108, 254, 295,
296, 301, 483
Gaussian integers, 68, 81, 207
GCD, VII, 16–20, 22, 23, 41, 45, 50, 67,
79, 84, 98–100, 102, 103, 108, 119,
122–124, 128–130, 132, 139, 150,
161, 162, 164, 165, 169, 172, 174,
176, 178, 182–185, 187, 198–200,
202, 219, 227, 229, 231, 240,
241, 244, 247–249, 252, 262–266,
268–270, 272, 273, 276, 279, 280,
282, 284, 285, 288, 290, 293, 297,
298, 300, 310, 311, 313, 314, 336,
338, 346, 351–354, 356, 357, 360,
385–387, 389, 426, 430, 433, 434,
474, 476, 480–482, 485–487, 489,
499
exercises, 78
in a Euclidean ring, 22, 23, 81
of Fibonacci numbers, 69, 84
of polynomials, 26, 84, 254, 481
exercises, 80–81
generator
of a code, 426–429, 443
of a ﬁeld, 221, 222, 227, 256, 260, 284,
343–345, 364, 429, 431
of a group, 138, 219, 221, 227, 237,
238, 249, 273, 285, 363, 397, 484,
497
of a vector space, 492, 504
of an ideal, 23, 178, 215, 426, 492
of U(Zn), 273
geometric progression, 75
Gilbert–Varshamov bound, 417–419,
434–437, 502
Goldbach conjecture, 156
golden ratio, 10, 11, 66
continued fraction, 50, 83
greatest common divisor, see GCD
group
cyclic, 125
multiplicative of a ﬁnite ﬁeld
cyclic, 221
Gss, 163, 164, 167, 171, 202, 206, 207,
270, 273–277, 283–285, 288
Hadamard, 155
Hamming, 410, 414
bound, 415, 417, 437, 501
code, 410, 412–414, 416, 423, 428,
430, 436, 437, 439, 440, 443, 503,
504
distance, 412, 413, 415, 424, 436, 438,
440, 501, 504
Hanoi, tower of, 13, 14, 78
Hardy, V, VI
Hasse’s theorem, 382, 383, 386
Heisenberg uncertainty principle, 446,
459, 460
Hellman, 346, 349
Diﬃe–H. hypothesis, 363, 364, 367,
384, 451
Merkle–H. cipher, 348–350, 398, 402
Hermite, 214
Hilbert’s basis theorem, 178
Hill cipher, 340, 342
Hocquenghem, 428
homogeneous coordinates, 373–375
Horner, Ruﬃni–H. method, 105, 113
Huygens, 52, 53
hypothesis
Diﬃe–Hellman, 363, 364, 367, 384,
451
Riemann, 273
generalised, 273

Index
517
ideal, 22
ﬁnitely generated, 22
identity
B´ezout, 17–20, 23, 79, 84, 101, 103,
124, 174, 178, 336, 341, 474, 480,
481, 486
for polynomials, 26, 229
in a Euclidean ring, 22
indeterminate, 23
index of an integer, 278
inequality, Cauchy–Schwarz, 416, 437,
457, 460, 468
integral part of a real number, 41
interpolation
Lagrange, 191, 192, 194–196
introspective, 284, 285, 287, 314
inverse
of a matrix, 108
of an element, 68
in a ﬁeld, 102
isometry, 438
Jacobi symbol, 245–248, 255, 259, 260,
390, 496
Kasiski, 328
Kayal, VIII, 157, 281
key, 193–195, 322, 323, 326, 327,
329–332, 335, 336, 339–341, 364,
394, 395, 452–454, 460, 464–469,
499
private, 349, 350, 355, 357–365, 367,
384, 385, 390, 402
exchange, 367, 384, 390
public, 348, 350–352, 360–362, 364,
398, 399, 402
raw, 463–466
key phrase, 322, 392–394
knapsack problem, 341, 345–350, 387,
397, 398, 402
Kraitchick, 293
Kronecker, 195
factorisation method, 195–198, 212
Lagrange, 48
interpolation, 191, 192, 194–196
Lam´e’s theorem, 98, 99
LAR, 60, 61, 299, 300
law
group l. on an elliptic curve, 374–380,
389, 400
leader of a coset, 423, 424
least absolute residue, 60, 61, 299, 300
least common multiple, 68, 119, 198,
202, 205, 276, 277, 283, 314
Legendre, 154, 155, 243
symbol, 238–240, 242–248, 254, 259,
260, 301, 381, 496
Leibniz’s law, 28, 69, 476
length, 117, 203, 327, 467
binary, 94, 113
of a block, 333–335, 340, 349
of a code, 409, 412–414, 417, 419,
426, 427, 429, 438, 439, 443
of a message, 323, 452–454
of a number, 93
of a vector, 402, 454
of a word, 327, 409
of an alphabet, 335
of an integer, 92–97, 100–103, 107,
108, 110, 111, 113, 138, 158, 165,
311
of the key, 452, 461
Lenstra, 362, 363, 386
Leon Battista Alberti, 323, 329
Leonardo Pisano, see Fibonacci
Liber Abaci, 48
Lindemann, 214
line, 20, 21, 57, 58, 369, 374–377, 381,
388, 436, 455
at inﬁnity, 373, 374, 377, 389
tangent, 376, 377, 388, 389
linear recurrence relation, 5, 6, 10, 11,
66, 73–84
for the convergents of a continued
fraction, 50
for the tower of Hanoi, 13
homogeneous, 5, 9, 10, 66
non-homogeneous, 13
Liouville, 48
logarithm, 92, 93, 435
discrete, 343–345, 354, 363–368, 384,
397, 402, 451, 500
natural, 93
Lucas, 7, 13, 164, 172
Lucas test, 172
Lyster, 325

518
Index
mantissa, 41, 168
mathematical induction, VII, 1–5, 62,
471
complete, 3, 62
matrix
generating m. of a code, 421–423,
427, 428, 438, 503
standard form, 421, 423, 442, 503
identity, 8, 421
of polynomials, 431
parity check, 422–424, 427–429,
431–433, 438, 439, 441, 442
transpose, 423
maximum likelihood, 411
Merkle, 346
Merkle–Hellman cipher, 348–350, 398,
402
Mersenne, 170
Miller–Rabin test, 272–273, 279, 317
minimum distance, 412–414, 420, 422,
424, 429, 431, 433, 434, 440–442
monomial, 25
Mordell–Weil theorem, 380
multiple, 15
multiplication, VII, VIII, 1, 14, 16, 97,
102, 103, 105–108, 117, 120, 126,
128, 149, 160, 164, 174, 203, 255,
274, 384, 390, 426
in a ﬁeld, 228, 260
in arbitrary base, 39
in base 2, 37–38, 88
in the ﬁeld F4, 224
more eﬃcient algorithm, 103, 104
of polynomials, 24, 25, 102, 103
multiplicity of a root, 27
Newton, 187, 212, 447
non-repeating quotients
of a continued fraction, 56
norm
of a complex number, 68, 174
of a vector, 454
NP–complete, 347
number
algebraic, 214
Carmichael, 264, 265, 267, 277, 313,
316, 317
composite, 149, 158, 163, 309, 315
Fermat, 168, 170, 171, 173, 207, 245
Fibonacci, 6, 7, 9, 10, 47, 66–67,
69–70, 84, 98, 473, 474, 476
closed formula, 7–11, 66
recurrence relation, 7, 9, 66, 67
sequence, 7, 8, 98, 473
hexadecimal, 39, 110
integer
binary representation, 32, 33, 36,
101, 128, 249, 346, 407
in arbitrary base, 39
in base 16, 39
in base β, 31, 32
introspective, 284, 285, 287, 314
irrational, 11, 48–50, 53–61, 71, 85,
199
as a continued fraction, 55
Mersenne, 168, 172, 173, 207
multiplicatively perfect, 202
perfect, 168, 173, 207, 211
prime, VIII, 7, 16, 17, 149–162, 164,
165, 188–190, 198–202, 204–207,
211, 213, 218, 220–223, 227, 228,
230, 265, 282, 290, 294
distribution, 152
inﬁnitely many, 152, 154, 199, 202
theorem, 155, 158, 351
twin, 156, 206
pseudoprime, 261
Euler, 265–271, 314, 316, 317
strong, 268–272, 279, 280, 313, 314,
316
in base a, 262
quadratic, 56, 71
reduced, 56, 72
rational
in arbitrary base, 41–42
undeﬁned, 41
real
in arbitrary base, 40–42
recurring, 42, 83, 166–168, 207, 211
square-free, 200
transcendental, 214
numerical vector, 419
O, 89
estimate, 89–92
observable, 450, 456–460, 468, 469, 505
operation

Index
519
bit, 88–89, 92, 94, 96, 97, 103, 104,
108, 111, 112, 127, 158, 172, 173,
229, 312, 482
in base 2, 33–39
order of a group element, 125, 139
parity check matrix, 422–424, 427–429,
431–433, 438, 439, 441, 442
partial denominator, 45
P´epin’s test, 171, 245
perfect square, 56, 70–72, 217, 266, 434
period
of a group element, 125, 138, 139, 284
of an alphabet, 325, 327, 328
perpetual calendar, 133–136
photon, 446–450, 455, 458
plane
aﬃne, 368
projective, 373–374
Plotkin bound, 416, 418, 419, 437, 502,
503
Poe, 325, 394, 499
point
at inﬁnity, 373, 374, 377, 379, 383,
389, 400, 401, 408, 500
singular, 377
torsion, 380
polarisation of the photon, 455, 458
horizontal, 456, 458
vertical, 456, 458
Pollard’s factorisation method, 385, 403
polynomial, VIII, 23–30, 68, 69, 80, 81,
89, 105–107, 113, 138, 154, 167,
168, 178, 179, 185, 343, 368, 388,
425–427, 430–433, 435, 443
characteristic, 8, 10, 12
check p. of a code, 427, 439
derivative, 27, 233
elementary symmetric, 252
generator of a code, 426–429, 443
irreducible, 179–181, 186–190, 203,
208–211, 214, 216, 217, 219, 224,
228, 251–253, 257, 258, 260, 368,
434, 435
over Zp, 222–223
Lagrange, 192, 193, 197, 210, 211
linear, 23
monic, 23, 26, 68, 187, 388, 426, 427,
430, 434, 435
nested form, 105
over a ﬁeld, 25, 29, 149, 179–181
primitive, 81, 182–186
quadratic, 23
with coeﬃcients
in a factorial ring, 182–187
in a ring, 23
with complex coeﬃcients, 69
zero, 24
polynomials
irreducible, 256
Pomerance, 300
positional notation of a number, 30–32
primality, 262
prime subring, 30
principle
Heisenberg uncertainty p., 446, 459,
460
problem, knapsack, 341, 345–350, 387,
397, 398, 402
product
Dirichlet, 201
property
cancellation, 118, 119, 137, 151
zero-product, 14
public
key, 350
Pythagoras’s theorem, 389
Pythagorean triple, 389
quadratic character, 381, 389
quadratic reciprocity, VIII, 171, 213,
238, 243–245, 247, 248, 254, 301,
496
quantum computer, IX, 445, 446,
449–451, 453, 467
quantum cryptography, 454, 461
quantum mechanics, IX, 445–449, 454,
455, 458, 460
quantum physics, 454, 455, 458
quotient, 15, 22, 32, 84, 95, 97, 106, 108
of a ring, 118
partial, 45, 53, 55
quotient set, 117, 118, 225
Rabin, Miller–R. test, 272–273, 279, 317
rank
of a matrix, 421
of an elliptic curve, 380

520
Index
rational expression, 48, 213, 251
integer, 251
integral, 213
Ray–Chaudhuri, 428
recursion, VII, 5
reduction modulo p, 189, 203, 212, 490
remainder, 15, 17, 22, 31, 60, 84, 97,
116, 140, 144, 205, 229, 240, 241
repeating quotients
of a continued fraction, 56
residue
h-ple, 278
quadratic, 236–238, 244, 245, 248,
251, 260, 267, 301, 302, 390
residue class, VIII, 116, 117, 137, 140,
141, 249, 250, 262, 273, 285, 322
ρ method, 309–312, 315, 317, 318
complexity, 312
variation, 311, 313, 317, 318
ring, 1
Euclidean, VII, 21–23, 25, 67, 68, 81,
118, 178, 179, 214
principal ideal, 23
factorial, VIII, 173, 175, 176, 178,
179, 182, 184–188, 202, 207
Noetherian, 177–178, 203, 489
of polynomials, 25, 68, 149, 178
over a ﬁeld, 430
principal ideal, 22
factorial, 178
quotient, 118, 215, 282, 425, 431
Rivest, 350, 362, 363
root, 69
cubic, 388
double, 27, 28
multiple, 27, 28, 68, 388
of a polynomial, 27, 371
of unity, 218–219
primitive nth, 219
primitive, of unity, 219, 221, 249, 254,
273–279, 286, 314, 316–318, 429,
431, 494
simple, 27
square, 48, 234, 235, 248–251, 260,
269, 293, 296, 301
Rosetta stone, 328
round-robin tournament, 136
RSA system, VIII, 341, 349, 351, 360,
362, 367, 384, 385, 388, 390, 398,
399, 402, 445, 451, 454
accessing, 351
authentication of signatures, 360, 361
decipher a message, 354–356
exchange of private keys, 363
security, 362
sending a message, 352–354
variants, 363
Ruﬃni–Horner method, 105, 113
Saxena, VIII, 157, 281
scalar, 419, 422, 438
scalar product, 421, 422, 437, 454–456,
467
hermitian, 455, 456, 467, 468
positive-deﬁnite, 455, 468
Schoof, 384
Schwarz, Cauchy–S. inequality, 416,
437, 457, 460, 468
Shamir, 349, 350, 362, 363
Shannon, 413, 451
theorem, 413
Shor, 451
sieve
number ﬁeld, 300
of Eratosthenes, VIII, 94, 95, 157,
159, 160, 199, 206, 211, 263, 281,
290–292, 315, 347, 449, 450
quadratic, 300–302, 315, 318, 362
Singleton
bound, 414, 415, 420, 436, 437, 501
size of a code, 409
Smolin, 467
Solovay–Strassen probabilistic test, 268,
272, 317
spanning set, 422
sphere, 415
spin, 450
stationary chain, 177
steganography, 321
Strassen, Solovay–S. probabilistic test,
268, 272, 317
subﬁeld, 220, 223, 226, 251, 253, 256,
257
fundamental, 251, 255, 257
of a ﬁnite ﬁeld, 222
subtraction in base 2, 34–37

Index
521
sum of points on an elliptic curve,
374–380, 389, 400
superincreasing sequence, 347
symbol
Jacobi, 245–248, 259, 260, 390, 496
properties, 246, 247, 255
Legendre, 238–240, 243–247, 259,
260, 381, 496
computing, 244
properties, 239, 242, 247, 248, 254,
301
syndrome, 423, 424, 438, 442
decoding, 423, 424, 443
table
addition
in base 3, 39
in the ﬁeld F4, 224
multiplication
in base 3, 39
in the ﬁeld F4, 224
Vigen`ere, 324, 325
Tartaglia, 366
Taylor’s formula, 29, 30, 154, 233
test
Lucas, 172
of divisibility, 121, 138, 142
P´epin, 171, 245
primality, VIII, 157, 158, 163–165,
172, 213, 238, 261, 265, 281, 282,
290, 351, 352, 385
AKS, VIII, 157, 281, 282, 284, 288,
289, 317
deterministic, 281
probabilistic, VIII, 263–264, 266,
268, 272–273, 317
probabilistic
Miller–Rabin, 272–317
Solovay–Strassen, 268, 272, 317
theorem
binomial, 29, 64, 65
Brun, 156
Cantor, 252
Chebyshev, 155
Chinese remainder, 128, 129, 131,
191, 204, 231, 232, 267, 280, 487,
498
for polynomials, 191, 192, 196, 204
Dirichlet, 154, 228, 245
Euler, 125, 127, 128, 139, 144,
162–164, 199, 277, 357, 487
sum of the reciprocals of the primes,
152, 153, 156
existence
of algebraic closure, 220
of ﬁnite ﬁelds, 221
of the splitting ﬁeld of a polynomial,
217
factor, 27, 68, 69, 181, 218, 230, 371,
475
Fermat’s little, 162–165, 169, 199,
200, 211, 261, 262, 265, 281, 282,
385, 498
polynomial version, 282
fundamental – of algebra, 69, 180
fundamental – of arithmetic, 125, 149,
150, 153, 157, 161, 163, 173–176,
199, 487
Gauss, 184–186, 188, 490
Hasse, 382, 383, 386
Hilbert’s basis, 178
Lagrange, 56, 57, 71, 125, 139, 485,
493
Lam´e, 98, 99
M¨obius inversion, 201
Mordell–Weil, 380
multiplicativity of degrees, 214
prime number, 155, 158, 351
Pythagoras, 389
Ruﬃni, 27, 68, 69, 475
Shannon, 413
Weil, 382, 383
Wilson, 165, 211, 261, 263, 281
inverse, 165
time, 88, 93
torsion point, 380
torsion subgroup of an elliptic curve,
380
tower of Hanoi, 13, 14, 78
transcendental, 214
Turing, V, 330
two’s complement, 36
universal exponent, 277
Vall´ee Poussin, de la, 155
Varshamov, Gilbert–V. bound, 417–419,
434–437, 502

522
Index
vector space, 419
Vernam, 451
cipher, 451–454, 460, 463, 464, 466,
468, 469
versor, 454
Vigen`ere, 323, 327, 394, 401
table, 324, 325
Wallis, 48
Weierstrass form of a cubic curve, 373,
377, 378, 388, 389, 402
weight of a word, 420
Weil, 382
Mordell–W. theorem, 380
theorem, 382, 383
Wiesner, 460
Wiles, 380
Wilson’s theorem, 165, 211, 261, 263,
281
Winkel, 325
word, 406, 408
key, 322, 325, 327, 328, 394, 401
of a code, 409–414, 416, 420
Young, 446–448
experiment, 446–450
zero of a polynomial, 27
zero-divisor, 14, 22, 140, 475, 484
in Z4, 119
in Z6, 140, 485
zero-knowledge proof, 365

