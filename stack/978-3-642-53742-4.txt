Lecture Notes in Mechanical Engineering
Dependability of 
Self-optimizing 
Mechatronic Systems
Jürgen Gausemeier
Franz Josef Rammig
Wilhelm Schäfer
Walter Sextro Editors

Lecture Notes in Mechanical Engineering
For further volumes:
http://www.springer.com/series/11236

About this Series
Lecture Notes in Mechanical Engineering (LNME) publishes the latest develop-
ments in Mechanical Engineering - quickly, informally and with high quality. Orig-
inal research reported in proceedings and post-proceedings represents the core
of LNME. Also considered for publication are monographs, contributed volumes
and lecture notes of exceptionally high quality and interest. Volumes published in
LNME embrace all aspects, subﬁelds and new challenges of mechanical engineer-
ing. Topics in the series include:
• Engineering Design
• Machinery and Machine Elements
• Mechanical Structures and Stress Analysis
• Automotive Engineering
• Engine Technology
• Aerospace Technology and Astronautics
• Nanotechnology and Microengineering
• Control, Robotics, Mechatronics
• MEMS
• Theoretical and Applied Mechanics
• Dynamical Systems, Control
• Fluid Mechanics
• Engineering Thermodynamics, Heat and Mass Transfer
• Manufacturing
• Precision Engineering, Instrumentation, Measurement
• Materials Engineering
• Tribology and Surface Technology

Jürgen Gausemeier · Franz Josef Rammig
Wilhelm Schäfer · Walter Sextro
Editors
Dependability of
Self-optimizing
Mechatronic Systems
ABC

Editors
Jürgen Gausemeier
Product Engineering
Heinz Nixdorf Institute
University of Paderborn
Paderborn
Germany
Franz Josef Rammig
Design of Distributed Embedded Systems
Heinz Nixdorf Institute
University of Paderborn
Paderborn
Germany
Wilhelm Schäfer
Software Engineering
Heinz Nixdorf Institute
University of Paderborn
Paderborn
Germany
Walter Sextro
Chair of Mechatronics and Dynamics
University of Paderborn
Paderborn
Germany
ISSN 2195-4356
ISSN 2195-4364
(electronic)
ISBN 978-3-642-53741-7
ISBN 978-3-642-53742-4
(eBook)
DOI 10.1007/978-3-642-53742-4
Springer Heidelberg New York Dordrecht London
Library of Congress Control Number: 2013956528
c⃝Springer-Verlag Berlin Heidelberg 2014
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of
the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology
now known or hereafter developed. Exempted from this legal reservation are brief excerpts in connection
with reviews or scholarly analysis or material supplied speciﬁcally for the purpose of being entered
and executed on a computer system, for exclusive use by the purchaser of the work. Duplication of
this publication or parts thereof is permitted only under the provisions of the Copyright Law of the
Publisher’s location, in its current version, and permission for use must always be obtained from Springer.
Permissions for use may be obtained through RightsLink at the Copyright Clearance Center. Violations
are liable to prosecution under the respective Copyright Law.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
While the advice and information in this book are believed to be true and accurate at the date of pub-
lication, neither the authors nor the editors nor the publisher can accept any legal responsibility for any
errors or omissions that may be made. The publisher makes no warranty, express or implied, with respect
to the material contained herein.
Printed on acid-free paper
Springer is part of Springer Science+Business Media (www.springer.com)

Preface
Intelligent technical systems offer the tempting possibility to create products that are
far more capable than today’s mechatronic systems. However, the system-inherent
intelligence comes with increased system complexity. This leads to an increased risk
for system-inherent faults, which might have devastating effects such as a complete
breakdown or might even compromise the safety of users. Yet at the same time
the new capabilities can be used to actively compensate for faults. Among these
intelligent technical systems are self-optimizing systems, which are able to adapt
their behavior based on user demands, the current situation or the system state itself.
Within the Collaborative Research Center (CRC) 614 "Self-Optimizing Concepts
and Structures in Mechanical Engineering" at the University of Paderborn, we de-
voted our research to the development of these self-optimizing systems. They are
based on mechatronics, which is formed by close collaboration of mechanical, elec-
trical and software engineering. To make a system intelligent, the software engi-
neering aspects gain further signiﬁcance and are enhanced by advanced control
engineering and mathematical methods. One result of our work is the accompanying
book "Design Methodology for Intelligent Technical Systems", which introduces
our proposed development process for self-optimizing systems. This process needs
be accompanied by dedicated methods to assure or increase system dependability
as early as possible in order to avoid costly design changes. We found that this aug-
menting process is so important yet also challenging that we decided to separate
all related works into this book. It was written by the members of the CRC 614’s
working group "Safety and Stability" and coordinated by Tobias Meyer, to whom
I’d like to express my sincerest gratitude.
The results of the CRC 614 and the book at hand present a major milestone
towards the development of dependable intelligent systems. We hope that it inspires
you to create tomorrow’s products!
Your CRC-Team
Paderborn,
Prof. Dr.-Ing. Jürgen Gausemeier
October 2013
Speaker of the Collaborative Research Center 614

Acknowledgements
This book was written within the context of the Collaborative Research Center 614
"Self-Optimizing Concepts and Structures in Mechanical Engineering", which has
been funded by the Deutsche Forschungsgemeinschaft (DFG).

Contents
1
Introduction to Self-optimization and Dependability . . . . . . . . . . . . . .
1
1.1
Self-optimizing Mechatronic Systems . . . . . . . . . . . . . . . . . . . . . . .
3
1.1.1
Operator Controller Module (OCM) . . . . . . . . . . . . . . . .
6
1.1.2
Basic Procedures for Self-optimization. . . . . . . . . . . . . . .
7
1.2
Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
1.2.1
Deﬁnition of the Term Dependability . . . . . . . . . . . . . . . .
13
1.2.2
Dependability as a Challenge . . . . . . . . . . . . . . . . . . . . . . .
13
1.2.3
Ensuring Dependability during the Development Process
14
1.3
Applications of Self-optimizing Systems . . . . . . . . . . . . . . . . . . . . .
16
1.3.1
Rail Technology – The RailCab System . . . . . . . . . . . . . .
16
1.3.2
Miniature Robot BeBot . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
1.3.3
X-by-Wire Test Vehicle . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
1.4
Structure of This Book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
2
Development of Self-optimizing Systems . . . . . . . . . . . . . . . . . . . . . . . . .
25
2.1
Domain-Spanning Conceptual Design . . . . . . . . . . . . . . . . . . . . . . .
27
2.2
Domain-Speciﬁc Design and Development . . . . . . . . . . . . . . . . . . .
31
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
3
Methods of Improving the Dependability
of Self-optimizing Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
3.1
Conceptual Design Phase. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
3.1.1
Early Probabilistic Reliability Analysis of an
Advanced Mechatronic System Based on Its
Principle Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.1.2
Early Design of the Multi-Level Dependability Concept
47
3.2
Design and Development . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
3.2.1
Increasing the Dependability of Self-optimizing
Systems during Operation Using the Multi-Level
Dependability Concept . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55

X
Contents
3.2.2
Iterative Learning of Stochastic Disturbance Proﬁles . . .
62
3.2.3
Mutation Testing of Electronic Component Design. . . . .
69
3.2.4
Optimal Control with Uncertainty . . . . . . . . . . . . . . . . . . .
76
3.2.5
Behavior Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
3.2.6
Computation of Robust Pareto Points . . . . . . . . . . . . . . . .
89
3.2.7
Behavior-Based Adaptation of Differing Model
Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
3.2.8
Analysis of Self-healing Operations . . . . . . . . . . . . . . . . . 102
3.2.9
Safe Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
3.2.10
Veriﬁcation for Interacting Mechatronic Systems
with Motion Proﬁles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
3.2.11
Dependability-Oriented Multiobjective Optimization . . . 128
3.2.12
Self-healing in Operating Systems . . . . . . . . . . . . . . . . . . 133
3.2.13
Self-healing via Dynamic Reconﬁguration. . . . . . . . . . . . 141
3.2.14
Online Model Checking . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
3.2.15
Virtualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
3.3
Methodology for the Selection of Dependability Methods for
the Development of Self-optimizing Systems . . . . . . . . . . . . . . . . . 158
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
4
Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
4.1
Selecting Suitable Methods Using the Methodology . . . . . . . . . . . 174
4.2
Development of the Active Guidance Module . . . . . . . . . . . . . . . . . 178
4.2.1
Early Probabilistic Reliability Analysis of an
Advanced Mechatronic Systems Based on Its
Principle Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
4.2.2
Early Design of the Multi-Level Dependability Concept
181
4.3
Development of the RailCab Vehicle . . . . . . . . . . . . . . . . . . . . . . . . 182
4.3.1
Veriﬁcation with Motion Proﬁles for Interacting
Mechatronic Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
4.3.2
Analysis of Self-healing Operations . . . . . . . . . . . . . . . . . 183
4.3.3
Safe Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
4.3.4
Behavior Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
4.3.5
Behavior-Based Adaptation of Differing Model
Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
4.3.6
Virtualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
5
Conclusion and Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191

List of Contributors
Prof. Dr.-Ing. habil. Wilhelm Dangelmaier
Heinz Nixdorf Institute, University of Paderborn, Business Computing, especially
CIM, Fuerstenallee 11, D-33102 Paderborn, Germany,
e-mail: wilhelm.dangelmaier@hni.uni-paderborn.de
Prof. Dr. Michael Dellnitz
Chair of Applied Mathematics, University of Paderborn, Warburger Straße 100,
33098 Paderborn, Germany,
e-mail: dellnitz@uni-paderborn.de
Rafal Dorociak
Heinz Nixdorf Institute, University of Paderborn, Product Engineering,
Fuerstenallee 11, D-33102 Paderborn, Germany,
e-mail: rafal.dorociak@hni.uni-paderborn.de
Kathrin Flaßkamp
Computational Dynamics and Optimal Control, University of Paderborn, Warburger
Straße 100, 33098 Paderborn, Germany,
e-mail: kathrinf@math.uni-paderborn.de
Prof. Dr.-Ing. Juergen Gausemeier
Heinz Nixdorf Institute, University of Paderborn, Product Engineering, Fuerste-
nallee 11, D-33102 Paderborn, Germany,
e-mail: juergen.gausemeier@hni.uni-paderborn.de
Stefan Groesbrink
Heinz Nixdorf Institute, University of Paderborn, Design of Distributed Embedded
Systems, Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: stefan.groesbrink@hni.uni-paderborn.de
Philip Hartmann
Heinz Nixdorf Institute, University of Paderborn, Business Computing, especially
CIM, Fuerstenallee 11, D-33102 Paderborn, Germany,
e-mail: philip.hartmann@hni.uni-paderborn.de

XII
List of Contributors
Christian Heinzemann
Heinz Nixdorf Institute, University of Paderborn, Software Engineering Group,
Zukunftsmeile 1, 33102 Paderborn, Germany,
e-mail: c.heinzemann@uni-paderborn.de
Christian Hölscher
Design and Drive Technology, University of Paderborn, Pohlweg 47-49, 33098
Paderborn, Germany,
e-mail: c.hoelscher@uni-paderborn.de
Peter Iwanek
Heinz Nixdorf Institute, University of Paderborn, Product Engineering,
Fuerstenallee 11, D-33102 Paderborn, Germany,
e-mail: peter.iwanek@hni.uni-paderborn.de
Jan Henning Keßler
Heinz Nixdorf Institute, University of Paderborn, Control Engineering and
Mechatronics, Fuerstenallee 11, D-33102 Paderborn, Germany,
e-mail: jan.henning.kessler@hni.uni-paderborn.de
Dr. Bernd Kleinjohann
Heinz Nixdorf Institute, University of Paderborn, Design of Distributed Embedded
Systems, Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: bernd@c-lab.de
Dr. Lisa Kleinjohann
Heinz Nixdorf Institute, University of Paderborn, Design of Distributed Embedded
Systems, Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: lisa@c-lab.de
Sebastian Korf
Heinz Nixdorf Institute, University of Paderborn, System and Circuit Technology,
Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: korf@hni.uni-paderborn.de
Martin Krüger
Heinz Nixdorf Institute, University of Paderborn, Control Engineering and
Mechatronics, Fuerstenallee 11, D-33102 Paderborn, Germany,
e-mail: kruemar@uni-paderborn.de
Tobias Meyer
Mechatronics and Dynamics, University of Paderborn, Pohlweg 47-49, 33098
Paderborn, Germany,
e-mail: tobias.meyer@uni-paderborn.de
Dr. Wolfgang Müller
Heinz Nixdorf Institute, University of Paderborn, Design of Distributed Embedded
Systems, Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: wolfgang@c-lab.de

List of Contributors
XIII
Jun.-Prof. Dr. Sina Ober-Blöbaum
Computational Dynamics and Optimal Control, University of Paderborn, Warburger
Straße 100, 33098 Paderborn, Germany,
e-mail: sinaob@math.uni-paderborn.de
Dr.-Ing. Mario Porrmann
Cognitronics and Sensor Systems, Center of Excellence Cognitive Interaction
Technology, Bielefeld University,Universitätsstraße 21-23, 33615 Bielefeld,
Germany,
e-mail: mporrmann@cit-ec.uni-bielefeld.de
Claudia Priesterjahn
Heinz Nixdorf Institute, University of Paderborn, Software Engineering Group,
Zukunftsmeile 1, 33102 Paderborn, Germany,
e-mail: c.priesterjahn@uni-paderborn.de
Prof. Dr. Franz-Josef Rammig
Heinz Nixdorf Institute, University Paderborn, Design of Distributed Embedded
Systems, Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: franz@uni-paderborn.de
Christoph Rasche
Heinz Nixdorf Institute, University of Paderborn, Design of Distributed Embedded
Systems, Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: crasche@c-lab.de
Peter Reinold
Heinz Nixdorf Institute, University of Paderborn, Control Engineering and
Mechatronics, Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: peter.reinold@hni.upb.de
Prof. Dr. Wilhelm Schäfer
Heinz Nixdorf Institute, University of Paderborn, Software Engineering Group,
Zukunftsmeile 1, 33102 Paderborn, Germany,
e-mail: wilhelm@uni-paderborn.de
Albert Seifried
University of Paderborn, Warburger Straße 100, 33098 Paderborn, Germany,
e-mail: seifried@math.uni-paderborn.de
Prof. Dr.-Ing. habil Walter Sextro
Mechatronics and Dynamics, University of Paderborn, Pohlweg 47-49, 33098
Paderborn, Germany,
e-mail: walter.sextro@uni-paderborn.de
Christoph Sondermann-Woelke
Mechatronics and Dynamics, University of Paderborn, Pohlweg 47-49, 33098
Paderborn, Germany,
e-mail: christoph.sondermann-woelke@uni-paderborn.de

XIV
List of Contributors
Katharina Stahl
Heinz Nixdorf Institute, University of Paderborn, Design of Distributed Embedded
Systems, Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: katharina.stahl@uni-paderborn.de
Dominik Steenken
Speciﬁcation and Modelling of Software Systems, University of Paderborn,
Warburger Straße 100, 33098 Paderborn, Germany,
e-mail: dominik@uni-paderborn.de
Robert Timmermann
Applied Mathematics, University of Paderborn, Warburger Straße 100, 33098
Paderborn, Germany,
e-mail: robert.timmermann@math.upb.de
Prof. Dr.-Ing. habil. Ansgar Trächtler
Heinz Nixdorf Institute, University of Paderborn, Control Engineering and
Mechatronics, Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: ansgar.traechtler@hni.upb.de
Mareen Vaßholz
Heinz Nixdorf Institute, University of Paderborn, Product Engineering, Fuerste-
nallee 11, 33102 Paderborn, Germany,
e-mail: mareen.vassholz@hni.uni-paderborn.de
Prof. Dr. Heike Wehrheim
Speciﬁcation and Modelling of Software Systems, University of Paderborn,
Warburger Straße 100, 33098 Paderborn, Germany,
e-mail: wehrheim@uni-paderborn.de
Dr. Katrin Witting
Applied Mathematics, University of Paderborn, Warburger Straße 100, 33098
Paderborn, Germany,
e-mail: witting@math.upb.de
Tao Xie
Heinz Nixdorf Institute, University of Paderborn, Design of Distributed Embedded
Systems, Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: tao@c-lab.de
Yuhong Zhao
Heinz Nixdorf Institute, University of Paderborn, Design of Distributed Embedded
Systems, Fuerstenallee 11, 33102 Paderborn, Germany,
e-mail: zhao@uni-paderborn.de

List of Contributors
XV
Steffen Ziegert
Speciﬁcation and Modelling of Software Systems, University of Paderborn,
Warburger Straße 100, 33098 Paderborn, Germany,
e-mail: steffen.ziegert@uni-paderborn.de
Prof. Dr.-Ing. Detmar Zimmer
Design and Drive Technology, University of Paderborn, Pohlweg 47-49, 33098
Paderborn, Germany,
e-mail: detmar.zimmer@uni-paderborn.de

Chapter 1
Introduction to Self-optimization and
Dependability
Abstract. This chapter gives an introduction to self-optimizing mechatronic sys-
tems and the risks and possibilities that arise with these. Self-optimizing mecha-
tronic systems have capabilities that go far beyond those of traditional mechatronic
systems. They are able to autonomously adapt their behavior and so react to outer
inﬂuences, which can originate e.g. from the environment, changed user require-
ments or the current system status. The basic process of self-optimization, the pro-
cedures employed within and the main components of a self-optimizing system are
explained here.
However, during the development of such a system, several challenges need to be
met. On this note, both the concept of dependability and our proposed development
process for self-optimizing systems are introduced. This process is used to derive a
methodology for the selection of dependability methods in the development of self-
optimizing systems.
To illustrate the proposed process and methods, several demonstrators are intro-
duced. These are self-optimizing systems from different ﬁelds of engineering, e.g.
robotics, automotive engineering and railroad engineering.
The chapter concludes with an overview of the content of the remainder of the
book.
Tobias Meyer, Claudia Priesterjahn, and Walter Sextro
In today’s market, a growing number of competitive and successful products are
mechatronic systems. Mechatronic systems provide an advanced functionality that
is achieved by a collaboration between mechanical engineering, electrical engineer-
ing, control engineering, software engineering, and mathematics. The combination
of these domains allows the implementation of self-optimizing capabilities, which
enable a system to react autonomously to changes in the system requirements or the
environment. Moreover, high dependability of these systems is an absolute must, as
self-optimizing mechatronic systems are often used in environments in which safety
is critical. However, due to the complexity of self-optimizing mechatronic systems,
ensuring dependability becomes a difﬁcult task.
J. Gausemeier et al. (eds.), Dependability of Self-optimizing Mechatronic Systems,
1
Lecture Notes in Mechanical Engineering,
DOI: 10.1007/978-3-642-53742-4_1, c⃝Springer-Verlag Berlin Heidelberg 2014

2
T. Meyer, C. Priesterjahn, and W. Sextro
Fig. 1.1 Two RailCabs
forming a convoy (artist’s
interpretation)
One practical example of a self-optimizing mechatronic system is the RailCab
system, shown in Fig. 1.1. The vision of the RailCab project is a mechatronic rail
system where small autonomous vehicles, called RailCabs, provide ﬂexible trans-
port on rail tracks. RailCabs form convoys without being rigidly coupled, in or-
der to reduce energy consumption caused by air resistance. Such convoys are es-
tablished on demand, and require only small distances between the RailCabs. The
small distances required make the RailCabs a safety-critical system requiring high
dependability.
No prior approach to the development of self-optimizing systems has taken the
inherent risks and capabilities of these systems into account. The development pro-
cess, which is presented in the book "Design Methodology for Intelligent Technical
Systems" [14], coordinates the different domains that are involved in the develop-
ment of a mechatronic system. However, this process needs to be complemented by
methods enabling the developer to guarantee the dependability of self-optimizing
mechatronic systems.
In order to overcome the apparent contradiction between the additional complex-
ity introduced by self-optimization and the high dependability requirements, self-
optimization capabilites within the system itself can be employed to increase the
dependability of a system. This can be achieved by using behavior adaptation based
on the current system state. In this book, we present methods for the development of
self-optimizing mechatronic systems that either focus on ensuring the dependability
of such systems or that use the capability of self-optimizing systems to increase their
dependability system-internally. These methods are integrated into the development
process for self-optimizing mechatronic systems in the book "Design Methodology
for Intelligent Technical Systems" [14] and thus allow for early reaction to possible
risks.
Using the development process presented in this book, the RailCab has become
an example of a dependable self-optimizing mechatronic system.

1 Introduction to Self-optimization and Dependability
3
1.1
Self-optimizing Mechatronic Systems
Michael Dellnitz, Kathrin Flaßkamp, Philip Hartmann, Martin Krüger, Tobias Mey-
er, Claudia Priesterjahn, Sina Ober-Blöbaum, Christoph Rasche, Walter Sextro,
Katharina Stahl, and Ansgar Trächtler
Self-optimizing systems are intelligent mechatronic systems that are able to adapt
their behavior autonomously to changing operating conditions and user demands.
To this end, three steps are continuously cycled, as discussed in [12, 13], see also
Fig. 1.2:
1. Analysis of current situation:
During this step, the user requirements, the system state and based on direct
observations the environment are identiﬁed and considered. Observations can
also be indirectly obtained by communicating with other systems, and the state
of the system may include prior observations. A major aspect of this step is the
evaluation in how far the given objectives have been fulﬁlled.
2. Determination of objectives:
In the second step, the new system objectives can be selected, adapted or gener-
ated from the system’s previous objectives. Selection is possible if a ﬁnite number
of discrete possible objectives exist. Adaptation is carried out if the system’s ob-
jectives can be altered gradually. The generation of new objectives is performed
if new objectives must be created independently of known objectives.
3. Adaptation of system behavior:
The system behavior is adapted to account for changes necessitated by the de-
termination of objectives. Changes to system parameters as well as changes to
the system structure are possible. This action constitutes the feedback of the self-
optimization cycle to the system.
As already mentioned, the objectives are of major importance for a self-optimiz-
ing system. They are organized in the System of Objectives, which in general is a set
Fig. 1.2 Cycle of the be-
havior adaptation of a self-
optimizing mechatronic
system
2
3
11
Analysis of
current situation
Adaptation of
system behavior
Determination of
objectives
Self-optimization
process

4
M. Dellnitz et al.
of all objectives. If there are additional relations among the objectives, an objective
hierarchy or an objective graph can be created.
Figure 1.3 shows the key aspects and the mode of operation of a self-optimizing
system. Factors inﬂuencing the technical system originate in its surroundings (envi-
ronment, users, etc.) or from the system itself, and can support the system’s objec-
tives or hinder them. Inﬂuences from the environment, for example strong winds or
icy conditions, are unstructured and often unpredictable. If they hinder the system in
fulﬁlling its pursued objectives, they are called disturbance variables. The user can
inﬂuence the system, for instance by choosing preferred objectives. It is also possi-
ble for the system itself or other technical systems to inﬂuence the system’s objec-
tives, for example if mechanical components are damaged. Based on these changes
in the environment, the System of O bjectives and therefore the system’s behavior is
adjusted. The adjustment of the system behavior can either be effected by changing
control parameters or by changing the structure, e.g. through reconﬁguration [13].
The objectives are the required, desired and/or undesired properties of the sys-
tem. They are pre-determined during system development, but their desired char-
acteristics are deﬁned only during operation. Objectives are classiﬁed into external,
internal and inherent objectives.
Inherent objectives constitute part of the functionality of the system, and are de-
ﬁned by the system itself. External objectives describe objectives that are charac-
terized outside of the system; this can be due to other systems or human users, for
example. Internal objectives are those objectives that are being pursued at any given
moment by the system. They can be formulated using inherent and external ob-
jectives by selecting, weighting or setting them in relation to one another. Unless
otherwise stated, the term objectives refers to internal objectives.
Fig. 1.3 Aspects of self-
optimizing systems
System of Objectives
(internal objectives)
Technical system (e.g. RailCab)
O1.1 O1.2 O2.1 O2.2 O2.3
O1
O2
O
Inﬂuences on the technical system
User
e.g. changed
user behavior
System
e.g. wear and
tear
Environment
e.g. changes of
the track-proﬁle
Behavior
Mathematical
description of
behavior
Specialized representation
of system structure
Specialized representation
of system parameters
x(t)= A
y(t)= C
.
.
x(t)+B
x(t)+D
.
.
u(t)
u(t)
RailCab
Structure
Parameters
U(s)
Y(s)
+
+
+
..
X2
X1
Xn
C1
C2
Cn
1
s -λ
..
1
1
s -λ
1
s -λ
2
n
λ1
0
0
0
λ2
0
0
0
0
...
...
...
0
0
λn
A =
,
1
1
1
C = c = c
c
c
1
2
n
. ..
D = 0
T
B
b
=
=
...
...
...
...
...

1 Introduction to Self-optimization and Dependability
5
Self-optimization, as described above, relates mainly to improving the perfor-
mance of mechatronic system by considering the given or derived set of system ob-
jectives. Describing dependability attributes as system objectives allows engineers
to use self-optimization as a means of achieving dependability. However, autono-
mous adaptations potentially introduce additional risks as well, because they may
lead to unintended or even malicious system behavior. Additional mechanisms are
required to assure the system’s dependability at runtime in an autonomous manner.
This may be accomplished by self-healing.
For the understanding of self-healing, we must ﬁrst clarify what a healthy sys-
tem is. Shaw [26] has deﬁned a healthy system as follows: "A system is considered
healthy as long as it works according to its speciﬁcation.” In other words, a sys-
tem is healthy as long as it shows the intended behavior. Self-healing is the ability
of a system to autonomously recover from an unhealthy system state. This means
that in the case the system shows unintended behavior, it will recover and return to
the desired behavior. Self-healing may consequently be used to prevent dangerous
situations in the case of failure.
We can map the self-healing process onto the self-optimization process as de-
scribed above. According to Gorla et al. [15], the self-healing process comprises
the following steps: failure detection, failure cause identiﬁcation, and execution of
self-healing operation. The steps failure detection and failure cause identiﬁcation
are integrated into the step “Analysis of the current situation”. The execution of the
self-healing operation is part of the “Adaptation of the system behavior”.
Failure detection requires knowledge of the system state, which is usually ob-
tained by online monitoring. The system state is evaluated and classiﬁed as either
a healthy or unhealthy state. Distinguishing between healthy and unhealthy system
states is the most challenging part of failure detection. Runtime failure detection
mechanisms may be implemented based on either system models, simulations re-
sults or anomaly detection methods [5].
When a failure has been detected, its cause needs to be located and its type deter-
mined [22] in order to select an appropriate self-healing operation in the next step.
The failure can occur anywhere in the system, far away from the failure cause. The
signal of a broken sensor, for example, may result in an actuator failure and only the
actuator failure may be detected. The actuator and the sensor may be separated by
many software components that process the sensor signal and output control com-
mands. Moreover, the relation between failure cause and failure is usually not a
one-to-one correlation. Failure causes may result in several failures, and/or a failure
can be caused by many failure causes. The effect of a failure cause may result in a
failure after only after long-term operation [15].
The self-healing operation removes the failure cause from the system and stops
failures from propagating further. In this book, we particularly focus on self-healing
in the form of structural reconﬁguration. Once a failure cause has been identiﬁed,
the failed components are removed from the basic system. This must happen before
failures propagate to critical parts in the system, e.g., before they may cause hazards.
Self-healing is only applied if the system is in an unhealthy state. Failures
are detected automatically and the system is returned to a healthy state without

6
M. Dellnitz et al.
interrupting its operation. Self-healing thereby enhances the system’s dependabil-
ity by introducing robustness against failures.
1.1.1
Operator Controller Module (OCM)
The information processing unit of a self-optimizing system has to perform a mul-
titude of functions: quasi-continuous control of the system motion, monitoring in
view of occurring malfunctions, adaptation of the control strategy to react to chang-
ing environmental conditions and communication with other systems, to name just
a few of these functions.
In order to ensure clear and manageable information processing, an architec-
ture is needed which contains all these functions. The Operator Controller Module
(OCM) [16] is an architecture with three levels that has been proved to be both an
advantageous as well as an effective structure for self-optimizing systems. It consists
of three levels, which can be also found in cognition science [27]. The architecture
is shown in Fig. 1.4 and can be used for structuring the information processing of
subsystems as well as of the entire system.
On the lowest level of an OCM, there is the Controller, which ensures the desired
dynamical behavior of the plant and is similar to a classic control loop. Measure-
ments are used to compute control signals for the actuators. The Controller oper-
ates in a quasi-continuous way under hard real-time constraints. Several types of
controllers can be implemented at the same time with the possibility of switching
between them.
The Reﬂective Operator monitors and regulates the Controller. It consists of
sequential control, emergency routines and adaptation algorithms for the control
strategies. The Reﬂective Operator does not access the actuators of the system di-
rectly, but modiﬁes the Controller by initiating changes to the controller parameters
or by switching between different controllers; this modiﬁcation is undertaken by the
Conﬁguration Control. The Reﬂective Operator is event-oriented and has to oper-
ate under hard real-time constraints, because it is tightly linked to the Controller.
However, it is also the connecting element to the cognitive level of the OCM and
provides an interface between the Controller and those elements that are not capable
to operate in real-time.
The topmost level of the OCM is represented by the Cognitive Operator. Var-
ious methods such as learning, use of knowledge-based systems or model-based
optimization can be implemented on this level. The results can be used to improve
the system behavior. This optimizing information processing can be roughly di-
vided into model-based and behavior-based optimization, introduced in Sect. 1.1.2.
While both the Controller and the Reﬂective Operator are subject to hard real-time
constraints, the Cognitive Operator can also operate asynchronously to real time.
Nevertheless, it has to respond within a certain amount of time. Otherwise, self-
optimization would not ﬁnd utilizable results in view of changing environmental
conditions. Hence, the Cognitive Operator is subject to soft real-time.

1 Introduction to Self-optimization and Dependability
7
Fig. 1.4 Structure of Opera-
tor Controller Module
Action Level
Planning Level
Monitoring
Sequencer
Reflective Operator
Controller
Operator Controller Module (OCM)
...
Configuration-
Control
Emergency
Soft real-time
Hard real-time
Model-based Self-optimization
Behavior-based Self-optimization
Cognitive information processing
Cognitive Operator
Cognitive loop
Reflective loop
Reflective information processing
Motor information processing
Configurations
Controlled system
Motor loop
A
C
B
 C
B
A
1.1.2
Basic Procedures for Self-optimization
To achieve the step "Determination of Objectives" of the self-optimization cycle,
there are some basic concepts which we will introduce brieﬂy in the following.
Originally, these procedures were not necessarily intended to be self-optimization
speciﬁc, but they turn out to be well suited for the behavioral adaptation of self-
optimizing systems.
For self-optimizing systems, there typically arise a number of different objectives
which have to be considered simultaneously. During operation, a self-optimizing
system may, for instance, change from a primarily energy-saving or time-saving
operation mode to another conﬁguration which corresponds to a safer behavior
or a longer lifetime. Firstly, this leads to multiobjective optimization problems
(cf. Sect. 1.1.2.1), which have to be considered while still in the design phase of
intelligent mechatronic systems. Secondly, during operation, Pareto optimal points,
i.e. optimal compromises between conﬂicting objectives, have to be selected. This
can be accomplished using planning techniques (cf. Sect. 1.1.2.2). To further adapt

8
M. Dellnitz et al.
the system’s behavior and objectives to environmental inﬂuences, learning proce-
dures (cf. Sect. 1.1.2.3) can be applied. Speciﬁc methods for dependability and
self-optimization which are based on these basic concepts are presented in detail
in Chap. 3.
1.1.2.1
Multiobjective Optimization
The principle of multiobjective optimization enables the model-based, automated
identiﬁcation of objectives in the second step of the self-optimization process. A
mathematical formulation of a multiobjective optimization problem1 is given by
min
p∈S{F(p)},
S := {p ∈Rn|g(p) = 0,a(p) ≤0},
(1.1)
with functions F : Rn →Rk,k > 1, g : Rn →Rm and a : Rn →Rq.
Here, F is the vector of objectives, i.e. functions f1,..., fk : Rn →R with
F(p) = (f1(p),..., fk(p)). Usually, the objectives are conﬂicting, i.e. an improve-
ment of one objective causes a worsening of the other objectives. Typical examples
of trade-offs between conﬂicting objectives are “minimal energy consumption ver-
sus minimal time” or “maximal quality, but minimal time and minimal (e.g. produc-
tion) costs”. The objectives depend on the optimization parameters p, e.g. controller
conﬁgurations. An evaluation of the objective functions for a given set of optimiza-
tion parameters often requires simulating a model of the continuous-time dynamical
behavior of the technical system. Additionally, there may be equality or inequality
conditions on the minimization problem, denoted by g and a, respectively. They
deﬁne S ⊂Rn, the admissible set of optimization parameters.
While ordinary optimization problems typically have a single global optimum,
the solution of multiobjective optimization problems results in an entire set of Pareto
points, the Pareto set. Minimization is intended with respect to the following partial
ordering ≤p on Rn: given u,v ∈Rn, the vector u is smaller than the vector v, u ≤p v,
if ui ≤vi for all i ∈{1,...,k}. The solutions of multiobjective optimization problems
can then be deﬁned as follows: a point p⋆∈Rn is called globally Pareto optimal for
the multiobjective optimization problem (or a global Pareto point) if there does
not exist any p ∈Rn with F(p) ≤p F(p⋆) and f j(p) < f j(p⋆) for at least one j ∈
{1,...,k}. That means, no other point p gives a better or equal (but not entirely
identical) value in all objectives. However, there typically exist other Pareto optimal
points which are, compared to p⋆, better with regard to one objective but worse in
another.
Figure 1.5 gives an illustration of a multiobjective optimization problem and
Pareto optimal points. If the Pareto optimality property only holds for some neigh-
borhood U(p⋆) ⊂Rn, p⋆is called locally Pareto optimal. The image of the Pareto
set, i.e. the corresponding function values, is called the Pareto front (cf. Fig. 1.5).
1 By convention, only minimization problems are considered, since every maximization
problem can be turned into a minimization problem.

1 Introduction to Self-optimization and Dependability
9
Fig. 1.5 Sketch of a mul-
tiobjective optimization
problem with two objectives
f1 and f2; while the points
(A) and (B) are not optimal,
(C) is a point of the Pareto
set.
f2
f1
A
B
C
Pareto set
Pareto front
f1
f2
For the solution of real-world multiobjective optimization problems, numerical
techniques have to be applied. There exist a number of methods for the computa-
tion of single Pareto points; for an overview we refer to [10]. However, for self-
optimizing systems, it is important to gather knowledge about the entire Pareto set.
In the last few decades, a number of techniques for the computation of entire Pareto
sets have been developed (cf. e.g. [6,7,17,21,24]). In the course of the research of
the Collaborative Research Center 614, set-oriented methods for multiobjective op-
timization (cf. e.g. [8] for an early reference or [25] for an overview) have been de-
veloped. Due to the approximation of the entire Pareto set (or the front, respectively)
by box coverings, the methods are outstanding in their robustness and applicability
to real-world multiobjective optimization problems, in particular for self-optimizing
technical systems.
The computation of entire Pareto sets of multiobjective optimization or optimal
control problems is computationally costly but important for the design of a knowl-
edge base on which self-optimization relied during operation. The Pareto optimal
alternatives are computed ofﬂine in advance and stored in this knowledge base. Dur-
ing operation, one speciﬁc optimal conﬁguration of the Pareto set has to be chosen
at any given time: this process is called decision making. Current information about
the system’s state (e.g. state of charge of the onboard power systems) and on the
environment, such as weather conditions, can be taken into account in the decision-
making process. To decide which Pareto optimal conﬁguration should be applied,
additional optimization or planning techniques can be used.
1.1.2.2
Planning
Any task for a mechatronic system (e.g. the transportation of persons or goods be-
tween two locations) can be expressed by a function [23]. This function deﬁnes
the relationship between input and output variables [9] of the system by convert-
ing incoming energy, material and information ﬂows into outgoing ﬂows of the
same types. Subtasks (such as driving with an active suspension system) are rep-
resented by analogous partial functions which are logically connected which make
up the hierarchy of the overall function. The effect of a partial function also de-
pends on the physical effect leading to a particular partial function solution [23].
Thus, partial functions can be implemented using various solutions (e.g. high or low

10
M. Dellnitz et al.
compensation of disturbances). The choice of solutions to these partial functions
determines the solution to the overall function and its effect on the mechatronic
system.
Let PFlea f be the set of all partial functions at the lowest level in the overall
function hierarchy. Then, the selected solutions in the overall function at time tj
(see Fig. 1.6, black circles) can be listed as a sequence to solutions of partial func-
tions [20]:
so f (t) = (sp f 1,...,sp f k),
(1.2)
with sp fi ∈Sp fi and 1 ≤i ≤k = |PFlea f |.
The behavior of the overall system at time t
can be described by
V(t) = (xt,so f (t),yt) with xt as input vector and yt as output vector. Consequently,
the behavior of one time period is: V(ta,tb) = (V(ta),...,V(tb)) with ta < tb (see
Fig. 1.6).
The mechatronic system reacts to each input variable by converting it to the
output variables; it does so by executing the currently implemented overall func-
tion (linked partial functions of the functional hierarchy, reactive behavior). The
information processing takes time and there is a latency involved according to the
response to input variables. Because of that, the effect of the overall function on
the output variables is delayed. Since the system execution takes place under real-
time conditions, this has to be taken into account during the development of self-
optimizing systems.
For autonomous control [9] of behavior, the system has to independently select
solutions to the partial functions at certain times in order to achieve the desired effect
(active behavior). The selection is made by considering speciﬁc objectives. This is
the decision problem of aself-optimizing mechatronic system: selecting of solutions
to partial functions which achieve these objectives with a high degree of fulﬁlment
(goal-directed behavior). Mechatronic systems with advanced information proces-
sing are able to autonomously and proactively plan their behavior. The goal of this
behavior planning is to minimize or maximize economic objectives, e.g. minimiz-
ing energy consumption. Consideration of the nondeterministic system environment
and continuous processes are particular challenges. First, a planner is used to gener-
ate a plan for the behavior of the mechatronic system. Subsequently, the execution
of this plan is carried out by the system.
Fig. 1.6 Behavior of a
mechatronic system
x
y
V(t , t  )
a     b
t a
t b
t j
l   (  )
gf t j
t b
t a

1 Introduction to Self-optimization and Dependability
11
While planning is used to determine the optimal overall sequence of Pareto alter-
natives for task fulﬁllment (short term), learning is another approach to adapting the
systems’s behavior by itself based on data gathered by monitoring the environmental
inﬂuences (long-term).
1.1.2.3
Learning
Apart from multiobjective optimization or planning several other approaches can be
used to design a self-optimizing system. One of these approaches is machine learn-
ing. In general, machine learning involves the programming of computers to opti-
mize a performance criterion based on example data or past experience [2]. Such an
approach may be necessary when, for example, there is no human expertise avail-
able to solve a particular problem. Learning techniques may also be useful when a
system’s environment shows nondeterministic behavior or its behavior is not known.
Considering a complex mechatronic system moving from one destination to an-
other destination, several unpredictable occurrences may crop up during movement.
The system should be able to adapt itself as a reaction to the occurrences such that
it can still optimize its performance criterion.
Another example would be if the problem to be optimized changes over time. If a
mechatronic system plans its paths from one destination to another, this initial plan
might at some point no longer be feasible, for instance due to trafﬁc. In such a case,
a learning program is able to adapt itself to the best path based on data gathered by
monitoring trafﬁc.
In learning approaches, a model is deﬁned based upon certain parameters. Learn-
ing, then, is the optimization of the model parameters using training data or past
experience. Using such an approach, it is possible to design a model capable of
predicting the future [2].
Learning itself is a two-step procedure. The ﬁrst step is called training. Efﬁcient
algorithms for solving the optimization problem itself, as well as for storing and
processing the massive amount of data, are needed for the training phase. When the
model has been trained, the second step, i. e. the use of this model during action,
takes place. This step requires an efﬁcient representation of the model and efﬁcient
algorithmic solutions for inference.
Machine learning is subdivided into three main learning techniques: supervised
learning, unsupervised learning and reinforcement learning. The aim of supervised
learning is to learn how to map input to an output, whereby the correct values are
given by a supervisor. Such a supervisor is removed in unsupervised learning, which
is based only on input data. The aim of unsupervised learning is to ﬁnd regularities in
the input. Normally, a certain kind of structure exists in the input data; thus, certain
patterns occur more frequently than others and the system must determine what hap-
pens in general and what does not. In statistics, this is called density estimation, one
example of which is clustering [2]. Another example is the learning of road distur-
bance proﬁles as described in Sect. 3.2.2. These road disturbances are described as
a Bayesian network. Parameters and structure of this network are iteratively learned
from observations.

12
P. Iwanek et al.
The last learning technique introduced here is reinforcement learning. It is typi-
cally used to determine a sequence of actions such as planning; however, a planning
approach, as described above, usually relies on a detailed description of a system’s
states and its actions, including their preconditions and effects, i.e. how they per-
form a transition from one state to another. Based on this knowledge, it determines
a sequence of actions leading from an initial state to a goal state. If such knowl-
edge is not available, reinforcement learning may be used to determine a sequence
of actions to reach the goal. Such a sequence is called a policy. In this case, no
single best action at every intermediate state exists. Thus, not a single action but
rather a policy is important, and a single action is called good if it is part of a good
policy [2]. The learning program should be able to assess whether a policy is good
or not; in doing so, it then learns from good action sequences executed in the past
and improves the policy with knowledge gained from these observations. This is of-
ten done using rewards, whereby the agent or program obtains a speciﬁc reward for
each action. The ﬁnal aim of the agent is to maximize some notion of the cumulative
reward. Reinforcement learning is, for instance, used by the BeBot miniature robots
for learning how to act in different environments: they adapt their behavior based
on environmental changes. The approach is described in detail in D.M.f.I.T.S, [14],
Sect. 5.3.9.
1.2
Challenges
Peter Iwanek, Tobias Meyer, Claudia Priesterjahn, Walter Sextro, and Mareen
Vaßholz
Self-optimizing systems are usually subdivided into modules, each of which is then
developed individually by a group of developers from all domains involved. All
modules as well as all domains within one module have to be synchronized in order
to result in a comprehensive system. This challenge can only be overcome with a
development process and methods tailored to the tasks of self-optimizing systems.
The proposed development process for self-optimizing systems is the core of the
companion work to this volume, titled Design Methodology for Intelligent Tech-
nical Systems ("D.M.f.I.T.S."), [14]. This companion work not only introduces the
development process of self-optimizing systems, but also provides several methods
which aid in creating the technology required for such systems. However, develop-
ing a self-optimizing system with its additional complexity brings along new risks
concerning safety, reliability, maintainability and other attributes that are important
for a dependable system. There is, of course, the possibility of improving some of
these attributes by using the behavior adaptation capabilities of a self-optimizating
system, thus counteracting the negative effects of self-optimization and, as a re-
sult, creating a self-optimizing system that offers better reliability, availability or is
safer than a comparable conventional mechatronic system. These risks and possi-
bilities are not covered in the book D.M.f.I.T.S. but need to be taken into account
nonetheless.

1 Introduction to Self-optimization and Dependability
13
1.2.1
Deﬁnition of the Term Dependability
The usage of the term dependability as it is used throughout this book is based upon
the most common usage in computer sciences, which itself is well deﬁned by Laprie
et. al in [3]. According to this article, "the dependability of a system is the ability to
avoid service failures that are more frequent and more severe than is acceptable",
with a service failure being "an event that occurs when the delivered service deviates
from correct service". This dependability is comprised of ﬁve attributes: availability,
reliability, safety, integrity and maintainability2.
In order to attain dependability in a system, several means are used. These can
be grouped into four categories: fault prevention, fault tolerance, fault removal and
fault forecasting. There are several threats to the dependability of a system because
of failures, which are characterized by a deviation of at least one external state of
the system from the correct service state, with the deviation called error and faults
being the adjudged or hypothesized root cause. The complete taxonomy is depicted
in Fig. 1.7.
To obtain a dependable self-optimizating system, all ﬁve attributes need to be
considered. However, a self-optimizing system does not differ from a regular mecha-
tronic system with regard to the attributes integrity and maintainability and thus can
be treated much the same way; specialized methods are not required to make al-
lowance for these factors. The three attributes that need to be regarded separately
and for which prior methods are not fully suitable are availability, reliability and
safety. Due to the interdisciplinarity of the development process, the means of
achieving dependability are highly dependent on the development task.
Fig. 1.7 Dependability tree
according to [3]
dependability
failures
errors
means
fault prevention
availability
attributes
faults
threats
fault tolerance
fault removal
fault forecasting
reliability
safety
maintainability
integrity
1.2.2
Dependability as a Challenge
Self-optimizing mechatronic systems are subject to additional threats to their de-
pendability. This is not only due to their additional complexity, which increases the
2 Note that conﬁdentiality can be omitted, since it is not an attribute of dependability.

14
P. Iwanek et al.
risk of systematic errors and makes the system more prone to failures, but also due
to their non-deterministic behavior. The internal adaptation of the system makes it
difﬁcult to predict every system state in advance, making an exhaustive system anal-
ysis beforehand impossible. To obtain a safe system, special emphasis must be put
on the software, which must be free of systematic ﬂaws and which must be able to
handle random faults. It must be possible to guarantee that the software meets the
safety requirements.
In order to solve many engineering problems, domain-spanning or domain-
speciﬁc models of the system are used. For example, in software development,
models are used to guarantee the fulﬁllment of safety requirements and to identify
systematic faults via veriﬁcation. Random faults are analyzed using model-based
hazard analysis. The program source code is then generated automatically from the
system models.
However, any model can only represent a limited excerpt of reality. To handle
the complexity of the models, it is necessary to omit certain aspects during model-
ing and thus to idealize a given real system. For example, uncertain parameters or
perturbations can only be modeled with a limited level of detail. All these limita-
tions lead to a deviation between the real system and the model. If a model is used
to synthesize further elements of the system, e.g. if a model of the system dynam-
ics is used to design a controller, such deviations can lead to unexpected problems
when exchanging the model for the real system. While it is certainly possible to
model uncertainties, only known uncertainties and anticipated magnitudes can be
considered.
To overcome these limitations, detected deviations or uncertainties can be com-
pensated for during system operation and potential failures or failures that have been
detected during operation can be counteracted by the use of self-optimization, thus
increasing the system’s dependability. Yet while exploiting self-optimization as a
means of increasing the dependability is a real possibility, the additional threats that
arise with it must be controlled at the same time.
By introducing the use of additional methods during the development process,
these aspects can be taken into account. However, this is not sufﬁcient if the meth-
ods are used inefﬁciently or without adequate system data as input. Additionally, it
might not be easily possible to select suitable methods in the ﬁrst place.
A self-optimizing system relies heavily on the close integration of mechanical,
electrical and software components, making the development not only of the system
itself, but also of the system’s dependability, a joint effort of developers from several
domains. This requires domain-spanning methods, making collaboration between
developers even more challenging.
1.2.3
Ensuring Dependability during the Development Process
The development of dependable self-optimizing systems is challenging due to the
multidisciplinarity of mechatronics, the cross-linking between the subsystems, the
lack of current knowledge in the ﬁelds of advanced mathematics and artiﬁcial

1 Introduction to Self-optimization and Dependability
15
intelligence, and increased dependability requirements. Existing and established ap-
proaches for the development of mechatronic systems such as the VDI
guideline 2206 [28], the approach by Isermann [18] or Ehrlenspiel [11], the iPeM-
Modell [1] or the V-Model by Bender [4], do not address self-optimization
speciﬁcally and therefore cannot fulﬁll the requirements set by a self-optimizing
system. To overcomethese shortcomings,a design methodology3 for self-optimizing
systems was developed by the Collaborative Research Center 614. It expands the
existing methodologies and supports developers by providing domain-spanning and
self-optimization-speciﬁc methods and tools [19]. The methodology consists of a
reference process, methods and tools for the development of self-optimizing sys-
tems. It is presented brieﬂy in Chap. 2 and in detail in the book "Design Methodol-
ogy for Intelligent Technical Systems" D.M.f.I.T.S, [14], Chap. 3.
The design methodology for self-optimizing systems supports the developers
with knowledge and methods from self-optimization experts, offering an exper-
tise which is generally not available in companies. The reference process provides
recommendations for how to apply self-optimization methods, and therefore com-
plements the existing development processes. For the application of the reference
process to a speciﬁc development task and enterprise, the development process has
to be applied on a case-by-case basis. To ensure the dependability of self-optimizing
systems, te current book extends the presented methodology with dependability-
speciﬁc methods. In practice, the developers are confronted with a large number of
methods increasing the dependability of a system. To ensure the dependability of
the system, it is necessary to select those engineering methods that are suitable to
the underlying development task. This selection is tedious and error-prone; thus, the
approach presented in Sect. 3.3 supports the developer during the selection of the
appropriate dependability engineering method.
The methodology for improving the dependability of self-optimizing systems
consists of a method database, a guide to the selection and planning of dependabil-
ity engineering methods, and a software tool. The methods of the database that are
appropriate for ensuring the dependability of a self-optimizing system are presented
in Chap. 3. These methods need to be implemented during certain development
phases. The procedure for using the method is integrated into the reference process
for each selected dependability-speciﬁc method. Moreover, the interactions between
the methods are considered, because some methods need the output of another as
input. Therefore, both methods need to be employed during the development to get
the desired result. However, even applying the methodology for improving depend-
ability of self-optimizing systems,it cannot be guaranteed that a fully dependable
system results. As with most engineering problems, certain assumptions and delib-
erate choices have to be made, which may all result in possible failures or in critical
system states being neglected. In summary, the presented methodology can reduce
the risk of failures during the development process, but nevertheless care must be
taken to not omit important aspects and to always use proper engineering judgment.
3 In this book the following deﬁnition of the used terms method and methodology provided
by Pahl et al. are used: a method explains a procedure to reach a certain target; a method-
ology explains a procedure including several methods and tools [23].

16
C. Hölscher et al.
1.3
Applications of Self-optimizing Systems
Christian Hölscher, Jan Henning Keßler, Tobias Meyer, Christoph Rasche, Peter
Reinold, Walter Sextro, Christoph Sondermann-Woelke, and Detmar Zimmer
Several self-optimizing systems have been developed using the processes and meth-
ods explained within this book. Throughout this book, these systems are used as
successful examples of how to apply these methods. These systems all have in com-
mon that they closely integrate mechanics, electronics and information technology.
They use real-time hardware to run sophisticated control algorithms which produce
the desired system behavior by means of electrical or hydraulic actuators. There are
several contradictory objectives that need to be pursued at the same time. Depending
on the current situation, these objectives are selected or characterized, thus forming
the system behavior. On one hand, the challenge is the sheer complexity of these
systems, with additional challenges arising when several systems are collaborating,
e.g. RailCabs that have formed a convoy. On the other hand, the major possibility
which opens up is an increase of the system’s reliability and availability by adapting
the system behavior when existing or prospective faults are detected.
As it is shown later on, all these challenges can be overcome and chances taken
advantage of using a suitable development process with supplemental methods, as
described in the following chapters.
1.3.1
Rail Technology – The RailCab System
The RailCab is an innovative rail-bound transportation system. It consists of auton-
omous vehicles, so-called RailCabs, which are capable of driving individually on
regular rail tracks. In order to save energy, they can form convoys without being me-
chanically coupled by following one another at small distances. They are equipped
with an active guidance system which enables a single RailCab to autonomously
leave convoys, e.g. at passive switches.
Several safety risks for both the vehicles themselves and for passengers are as-
sociated with the forming of convoys and the passive switches used. To allow safe
transportation, these had to be reduced and eliminated.
In order to simplify system development, the RailCab vehicles consist of sepa-
rate modules for different basic functions. In the following chapters, several of these
modules are used as example systems. Special attention is given to the intelligent
Drive Module (iDM), which is required for propulsion by a linear drive unit, the Ac-
tive Guidance Module as a steering subsystem, and the Active Suspension Module,
which actively compensates for undesired body motions.
1.3.1.1
Intelligent Drive Module
The Driving efﬁciency of the RailCab depends on the distance, i.e. the air gap,
between the two linear motor parts, called the primary- and the secondary part.
The intelligent Drive Module has the task of minimizing the air gap in order to

1 Introduction to Self-optimization and Dependability
17
Fig. 1.8 Test rig of the
intelligent Drive Module
increase the efﬁciency, while ensuring collision-free operation at the same time.
The minimization depends on the RailCab velocity and the track characteristics in
relation to the dynamic behavior of the adjustment actuator.
The iDM test rig, see Fig. 1.8, consists of two acuator groups. Each of them is
comprised of the primary part of a linear drive and an air gap adjustment actuator.
Additionally, there are spring assemblies to reduce the actuator load and to raise
the primary part in case of an actuator failure. Hall sensors on each actuator group
measure the magnetic ﬁeld of the secondary parts to determine the electric rota-
tion angle, the track velocity and the air gap. The secondary parts of the iDM are
arranged in a circle and can be adjusted vertically to simulate different track char-
acteristics (see Fig. 1.9). In contrast to the RailCab, a synchronous motor without
the capability of an energy transfer is installed in the test rig, because the focus of
Load cell for
propulsion force
Primary part
Spring assembly
Adjustment
actuator
Load cell for
normal force
Load cell for
shear force
Hall sensors
Secondary part
Fig. 1.9 Actuator group of the intelligent Drive Module

18
C. Hölscher et al.
current work is on the improvement of the driving efﬁciency via an active air gap
adjustment.
If the air gap is too small, a collision between the primary and secondary parts
occur. Since this could lead to catastrophic failures of the whole system, the infor-
mation processing not only has to be set up to compensate for such failures, but the
mechanical system itself must also be able to cope with sudden actuator failures.
1.3.1.2
Active Guidance Module
At the high velocities of the RailCabs (intended maximum velocity is approximately
180 km/h), normal switches would not be able to change direction sufﬁciently
quickly to be able to split up convoys; hence, passive switches are used. When
passing over these, each RailCab steers individually towards its desired direction.
The system module for this steering action is called the Active Guidance Module
and is shown in Figure 1.10. In addition to steering on passive switches, the guid-
ance module actively controls vehicle guidance on normal tracks. This reduces wear
on both the wheels and the rails because ﬂange contacts on straight tracks as well
as in curves are avoided. Consequently, the rigid coupling of both wheels, as within
normal rail wheel sets, is omitted and wheel slip is minimized. Further, disturbances
such as track irregularities and cross wind are compensated for. There are also other
inﬂuences on the Active Guidance Module that originate from the RailCab itself,
such as, for example, the necessity of restricting energy consumption or varying the
velocity. For the steering actions on the track, an optimal trajectory is calculated,
which is based on the current and stored values of the clearance as well as on the
lateral displacement. Both values are measured by installed redundant eddy-current
sensors.
However, if the steering fails, the direction might not be deterministically se-
lectable, thus making the RailCab prone to derailments. To eliminate this risk,
Center pivot axle
Steering actuator
(hydraulic cylinder)
Eddy-current sensors
Axle-carrier
Emergency brakes
Mechanical
guidance
wheels
Fig. 1.10 Active Guidance Module of the RailCab

1 Introduction to Self-optimization and Dependability
19
Fig. 1.11 Test rig of the
Active Suspension Module
several counter-measures, in both hardware and information processing, have been
incorporated.
1.3.1.3
Active Suspension Module
The Active Suspension Module of the RailCab is designed to increase passenger
comfort. The test rig of the Active Suspension Module is illustrated in Fig. 1.11 and
its hierarchical structure is shown in Fig. 1.12. The main task of this module is a
nearly complete decoupling of the coach body from the excitations of the railroad
track, especially in the upper frequency range. Its secondary task is to tilt the coach
body into curves in order to reduce the lateral acceleration for passengers. Both
can be achieved by a secondary suspension mounted under the chassis ﬂoor. The
Vehicle
suspension
Pressure
supply
Communica-
tion link
Mechanical
joint
Hydraulic
link
Actuator
group left
Actuator
group right
Cylinder
left 1
Cylinder
left 2
Cylinder
left 3
Cylinder
right 1
Cylinder
right 2
Cylinder
right 3
Fig. 1.12 Structure of the Active Suspension Module

20
C. Hölscher et al.
active suspension of one RailCab consists of four actuator groups, each with a pas-
sive spring made of glass-ﬁber reinforced plastic (GRP) with a low damping charac-
teristic and three hydraulic cylinders. By transmitting the motion of the cylinders via
sophisticated guide kinematics to the spring base, the motion of the coach body can
be damped and in some cases strong vibrations can be absorbed almost completely.
A failure of one such module would not only lead to a less comfortable ride,
but also to possibly dangerous coach body excitations which would necessitate a
lowered top speed. Thus, intelligently exploited redundancy for the actuators at risk
has to be implemented.
1.3.2
Miniature Robot BeBot
The BeBot, illustrated in Fig. 1.13, is a small robot serving as a technology plat-
form. It is used for research in the domains of dynamic reconﬁgurable systems,
multi-agent systems and swarm intelligence. The dimensions of the miniature robot
BeBot are approximately 9cm × 9cm × 9cm. The chassis is a molded intercon-
nect device (MID). An embedded Linux operating system allows the execution
of programs directly on the robot. The robot is equipped with a camera and in-
frared distance sensors to observe its environment. Two chain drives provide the
robot with robust motion capabilities, even on rough ground. Furthermore, the Be-
Bot is equipped with a light guide and can be extended with different modules to
interact with its environment. Further information can be found in D.M.f.I.T.S, [14],
Sect. 2.2.
The BeBots are used as a system to test various self-optimizing applications,
one example of which would be dynamic threshold adaption. A Bebot activates or
deactivates energy efﬁciency measures depending on the state of its batteries. The
Light guide
cover plate
and
with integrated
WLAN-Antenna
Base module: 60 MHz-processor (ARM7), 256 B Flash,
k
32 B RAM for drive control, sensor analysis and energy
k
management.
Sensor system: 12 Infrared-sensors on the body for
360°-coverage of the environment and an SVGA-
camera.
Drives: Two electro-miniature drives with
each 2,8 W power and high efﬁciency and
high acceleration.
Expansion module: 600 MHz-processor, Linux OS,
512
B Flash, 256
B RAM and 430 MHz-DSP for
M
M
real-time image processing.
Fig. 1.13 The miniature robot BeBot: the two boards of the robot, the sensor system, the light
guide and the chain drive are depicted

1 Introduction to Self-optimization and Dependability
21
thresholds for its decisions about the activation or deactivation change dynamically
due to the battery capacity. This capacity decreases over the course of its life period.
Another example is the use of learning strategies for statistical planning ap-
proaches, combined with partially observable Markov decision process (POMDPs).
In this scenario, the BeBots learn to act in different environments. They adapt their
behavior based on environmental changes. The statistical planning approach is de-
scribed in detail in D.M.f.I.T.S, [14], Sect. 5.3.9, and includes the previously men-
tioned dynamic threshold adaptation.
1.3.3
X-by-Wire Test Vehicle
The demonstrator "Chameleon" is an X-by-wire vehicle, meaning that there are no
mechanical couplings between the control elements and the actuators; it is shown
in Fig. 1.14. This test vehicle is entirely actuated electrically and has four corner
modules with three DC motors each: one for steering, one for driving and one for an
active suspension. These enable an all-wheel drive, a single-wheel steering and an
active suspension. The driver is able to control the vehicle dynamics via a joystick.
The maximum speed is about 50 km/h and the empty weight is appr. 280 kg.
The driving motors not only drive but also brake, i.e. decelerate the vehicle. Addi-
tionally, the single-wheel steering enables the deceleration of the vehicle by steering
the wheels inwards. With these two possibilities and their combination, it is up to
the information processing to decide which possibility is optimal for the current
situation, also considering wear and possible breakdown of actuators.
Fig. 1.14 Test vehicle
"Chameleon"

22
T. Meyer and W. Sextro
1.4
Structure of This Book
Tobias Meyer and Walter Sextro
After giving a short outline of the possibilities and challenges when developing de-
pendable self-optimizing mechatronic systems, the necessity of a concise, system-
atic approach has been made apparent. Our suggested approach is presented in the
following chapters, an overview of which is given in this section.
In Chap. 2, a detailed introduction to the development process of self-optimizing
mechatronic systems is given. This introduction is focused on dependability-related
steps, which can be augmented by suitable methods.
Chapter 3 explains these methods in detail and also gives individual examples.
It is meant to be used as a reference, with all methods having the exact same basic
outline and with both required prerequisites and the output being mentioned promi-
nently. Its main sections 3.1 and 3.2 are structured according to the phases of the
development process.
Section 3.3 explains the process of selecting methods to be conducted during the
development process. For this purpose, selection guidelines are introduced.
One example spanning the complete development process is given in Chap. 4. In
this, the selection of methods using the guidelines from Sect. 3.3 is explained and
the individual method’s input and results are mentioned; the primary focus is on the
interaction of several methods that are employed consecutively.
The book concludes with Chap. 5, which contains a summary of the results. Ad-
ditionally, suggestions for further research are made.
References
1. Albers, A.: Five Hypotheses about Engineering Processes and their Consequences. In:
Proceedings of the 8th International Symposium on Tools and Methods of Competitive,
Ancona, IT (2010)
2. Alpaydın, E.: Introduction to Machine Learning. The MIT Press (2004)
3. Avizienis, A., Laprie, J.C., Randell, B., Landwehr, C.: Basic Concepts and Taxonomy
of Dependable and Secure Computing. IEEE Transactions on Dependable and Secure
Computing 1(1), 11–33 (2004), doi:10.1109/TDSC.2004.2
4. Bender, K.: Embedded Systems – Qualitätsorientierte Entwicklung. Springer, Berlin
(2005), doi:10.1007/b138984
5. Chandola, V., Banerjee, A., Kumar, V.: Anomaly detection: A survey. ACM Comput.
Surv. (2009), doi:10.1145/1541880.1541882
6. Coello Coello, C.A., Lamont, G., van Veldhuizen, D.: Evolutionary Algorithms for
Solving Multi-Objective Optimization Problems, 2nd edn. Springer, Berlin (2007),
doi:10.1007/978-0-387-36797-2
7. Das, I., Dennis, J.: A Closer Look at Drawbacks of Minimizing Weighted Sums of Ob-
jectives for Pareto Set Generation in Multicriteria Optimization Problems. Structural Op-
timization 14(1), 63–69 (1997), doi:10.1007/BF01197559

1 Introduction to Self-optimization and Dependability
23
8. Dellnitz, M., Schütze, O., Hestermeyer, T.: Covering Pareto Sets by Multilevel Subdi-
vision Techniques. Journal of Optimization Theory and Application 124(1), 113–136
(2005), doi:10.1007/s10957-004-6468-7
9. Deutsches Institut für Normung e.V.: DIN 19 226 Teil 1: Leittechnik – Regelungstechnik
und Steuerungstechnik – Allgemeine Grundbegriffe. German National Standard (1994)
10. Ehrgott, M.: Multicriteria Optimization, 2nd edn. Springer, Berlin (2005), doi:10.1007/3-
540-27659-9
11. Ehrlenspiel, K.: Integrierte Produktentwicklung, 3rd edn. Carl Hanser Verlag, Munich
(2007)
12. Gausemeier,
J.
(ed.):
Selbstoptimierende
Systeme
des
Maschinenbaus,
HNI-
Verlagsschriftenreihe, vol. 155. Heinz Nixdorf Institute, University of Paderborn,
Paderborn, DE (2004)
13. Gausemeier, J., Rammig, F.J., Schäfer, W. (eds.): Selbstoptimierende Systeme des
Maschinenbaus. HNI-Verlagsschriftenreihe, vol. 234. Heinz Nixdorf Institute, Univer-
sity of Paderborn, Paderborn, DE (2009)
14. Gausemeier, J., Rammig, F.J., Schäfer, W. (eds.): Design Methodology for Intelligent
Technical Systems. Lecture Notes in Mechanical Engineering. Springer, Heidelberg
(2014), doi:10.1007/978-3-642-45435-6_2
15. Gorla, A., Mariani, L., Pastore, F., Pezzè, M., Wuttke, J.: Achieving Cost-Effective
Software Reliability Through Self-Healing. Computing and Informatics 29(1), 93–115
(2010)
16. Hestermeyer, T., Oberschelp, O., Giese, H.: Structured Information Processing for Self-
Optimizing Mechatronic Systems. In: 1st International Conference on Informatics in
Control, Automation and Robotics, Setubal, PT (2004)
17. Hillermeier, C.: Nonlinear Multiobjective Optimization – A Generalized Homotopy Ap-
proach. Birkhäuser, Berlin (2001)
18. Isermann, R.: Mechatronische Systeme – Grundlagen. Springer, Berlin (2008),
doi:10.1007/978-3-540-32512-3
19. Kahl, S., Gausemeier, J., Dumitrescu, R.: Interactive Visualization of Development Pro-
cesses. In: Proceedings of the 1st International Conference on Modelling and Manage-
ment of Engineering Processes (2010)
20. Klöpper, B.: Ein Beitrag zur Verhaltensplanung für interagierende intelligente mecha-
tronische Systeme in nicht-deterministischen Umgebungen, HNI-Verlagsschriftenreihe,
vol. 253. Heinz Nixdorf Institute, University of Paderborn, Paderborn, DE (2009)
21. Knowles, J., Corne, D., Deb, K.: Multiobjective Problem Solving from Nature: From
Concepts to Applications. Springer, Heidelberg, doi:10.1007/978-3-540-72964-8
22. Lanigan, P.E., Kavulya, S., Narasimhan, P., Fuhrman, T.E., Salman, M.A.: Diagnosis in
Automotive Systems: A Survey. Tech. Rep. CMU-PDL-11-110, Carnegie Mellon Uni-
versity Parallel Data Lab (2011), doi:10.1.1.208.1611
23. Pahl, G., Beitz, W., Feldhusen, J., Grote, K.H.: Kontruktionslehre – Grundlagen erfolgre-
icher Produktentwicklung – Methoden und Anwendung, 6th edn. Springer, Heidelberg
(2005), doi:10.1007/b137606
24. Schäfﬂer, S., Schultz, R., Weinzierl, K.: A Stochastic Method for the Solution of Un-
constrained Vector Optimization Problems. Journal of Optimization Theory and Appli-
cations 114(1), 209–222 (2002), doi:10.1023/A:1015472306888
25. Schütze, O., Witting, K., Ober-Blöbaum, S., Dellnitz, M.: Set Oriented Methods for the
Numerical Treatment of Multi-Objective Optimization Problems. In: Tantar, E., Tantar,
A.-A., Bouvry, P., Del Moral, P., Legrand, P., Coello Coello, C.A., Schütze, O. (eds.)
EVOLVE- A Bridge between Probability. SCI, vol. 447, pp. 187–219. Springer, Heidel-
berg (2013)

24
References
26. Shaw, M.: “Self-healing": softening precision to avoid brittleness: position paper for
WOSS 2002: workshop on self-healing systems. In: Proceedings of the First Work-
shop on Self-Healing Systems, WOSS 2002, pp. 111–114. ACM, New York (2002),
doi:10.1145/582128.582152
27. Strube, G.: Modelling Motivation and Action Control in Cognitive Systems. In: Mind
Modelling, pp. 89–108. Pabst, Berlin (1998), doi:10.1.1.89.9346
28. Verein Deutscher Ingenieure (VDI): VDI 2206 – Entwicklungsmethodik für mechatron-
ische Systeme. Technical Guideline (2004)

Chapter 2
Development of Self-optimizing Systems
Abstract. In the development of self-optimizing systems, developers have to face
different challenges, such as the multidisciplinarity of mechatronics, cross-linking
between the subsystems, the lack of current knowledge in the ﬁelds of advanced
mathematics and artiﬁcial intelligence, and increased dependability requirements.
To support the developer in this challenging task adequately, the Collaborative Re-
search Center 614 has developed a design methodology consisting of a reference
process, methods and tools. The reference process is divided into two phases: the
"Domain-Spanning Conceptual Design" and the "Domain-Speciﬁc Design and De-
velopment". In the ﬁrst phase, the domain-spanning model-based aproach CON-
SENS (CONceptual design Speciﬁcation technique for the ENgineering of complex
Systems) is used to create a common understanding basis between the different
domains involved. Based on the Principle Solution developed in this phase, the
"Domain-Speciﬁc Design and Development" is planned and implemented. To en-
sure the development of dependable self-optimizing systems, domain-spanning and
domain-speciﬁc dependability engineering methods can be used. The developer en-
counters a signiﬁcant number of these methods, that have to be integrated into the
process to obtain an individualized development process for the speciﬁc develop-
ment task.
Jürgen Gausemeier and Mareen Vaßholz
The Collaborative Research Center 614 has developed a design methodology that
expands existing ones for mechatronic systems such as the VDI guideline 2206 [12],
the approach by Isermann (2008) [8] or Ehrlenspiel (2007) [4], the iPeM-Modell [1]
or the V-Model by Bender (2005) [2] and supports developers by providing domain-
spanning and self-optimization-speciﬁc methods and tools [9]. The methodology
consists of a reference process, methods and tools for the development of self-
optimizing systems, and is presented in detail in the book "Design Methodology
for Intelligent Technical Systems" D.M.f.I.T.S, [7], Chap. 3.
During the development of self-optimizing systems, different domains, such as
mechanical, electrical/electronic, software and control engineering and experts from
J. Gausemeier et al. (eds.), Dependability of Self-optimizing Mechatronic Systems,
25
Lecture Notes in Mechanical Engineering,
DOI: 10.1007/978-3-642-53742-4_2, c⃝Springer-Verlag Berlin Heidelberg 2014

26
J. Gausemeier and M. Vaßholz
advanced mathematics and artiﬁcial intelligence, are involved. Therefore, a domain-
spanning development process is needed which supports common understanding of
the product development activities and their cross-domain relationship for all par-
ticipating developers. The development of self-optimizing systems (cf. Fig. 2.1) is
basically structured into two main phases: the "Domain-spanning Conceptual De-
sign" and the "Domain-speciﬁc Design and Development". The result of the ﬁrst
phase is the speciﬁcation of a Principle Solution for the system to be developed. It
describes the basic structure and operational mode of the system, as well as its de-
sired behavior, computer-internally as partial models. In particular, the speciﬁcation
of the Principle Solution contains the description of the System of Objectives (cf.
Sect. 2.1). Based on the Principle Solution, a ﬁrst analysis of the dependability can
be carried out.
This speciﬁcation of the Principle Solution constitutes the basis for the Domain-
speciﬁc Design and Development (cf. Sect. 2.2). During this phase, the domains in-
volved work in parallel and use their domain-speciﬁc methods, models and tools.
The partial solutions developed by the domains involved are continuously inte-
grated into the overall solution with model transformation and synchronization tech-
niques [11]. During the Domain-speciﬁc Design and Development, the ability of the
system to adapt its behavior during operation is implemented in the domains. For
example, multiobjective optimization is used in the domain control engineering to
enable the system to adapt its behavior by changing the control parameter during
operation.
These steps particularly require the involvement of experts of advanced mathe-
matics and artiﬁcial intelligence. The optimization is speciﬁc to self-optimizing sys-
tems, as the main focus is on the implementation of the self-optimization process.
In addition, system tests are performed; both virtual and real prototypes are used for
Mechanical Engineering
    
         Subsystem Integration
Control Engineering
Software Engineering
 
Electrical Engineering
  
     
          
       
Mechanical Engineering
    
         Subsystem Integration
Control Engineering
Software Engineering
 
Subsystem 1
System Integration
Subsystem n
Production
Documents
Principle
Solution 
Design and Development
Conceptual 
Design
Electrical Engineering
Fig. 2.1 Macro cycle for the development of self-optimizing systems

2 Development of Self-optimizing Systems
27
this purpose. The result of the Design and Development phase is engineering data
such as manufacturing drawings and part lists.
The reference process for the development of self-optimizing systems is recom-
mendatory and gives an overview of the tasks that have to be performed during
the development. It is based on our experiences from the development of the Rail-
Cab and its function modules. It serves as basis for the application to a speciﬁc
development task and company in form of an implementation model. This model
provides a detailed process sequence according to the project, the system type and
the environment of the development project. It consists of process steps from the
reference process and builds the starting point for the project management. For ex-
ample the implementation model for the RailCab consists of about 850 steps and
900 development objects. During the development project execution, deviations
and changes from the planned development process can occur, for example due
to changing development objectives such as time and costs. To support the man-
agement during the project execution to react to these changes we adopted the self-
optimization approach to the management of the development process (cf. D.M.f.I.
T.S, [7], Sect. 3.5). In the following sections the reference process is described in
more detail.
2.1
Domain-Spanning Conceptual Design
The aim of the "Domain-spanning Conceptual Design" is to create a common un-
derstanding of the system between the domains involved. The main result of this
phase is the Principle Solution, which is described by the speciﬁcation technique
CONSENS.
There are eight separate but highly interrelated aspects that need to be covered by
the Principle Solution. Computer-internally, these aspects are represented as partial
models. The eight aspects and their respective partial models are shown in Fig. 2.2
(cf. [6]). While each partial model represents only one individual aspect of the sys-
tem, together they form a coherent model of the complete system [6]. The partial
models are:
Environment:
This model describes the environment of the system to be developed and the
system’s embedment into the environment. Relevant spheres of inﬂuence and
inﬂuences will be identiﬁed and interactions between them will be examined [6].
Application Scenarios:
These scenarios concretize the behavior of the system in a particular state and
situation. Application Scenarios characterize a problem which needs to be solved
in certain cases and also brieﬂy outline the possible solution [6].
Requirements:
This partial model presents an organized collection of requirements that need to
be fulﬁlled during product development.Every requirement is described textually
and, if possible, concretized by attributes and their characteristics [6].

28
J. Gausemeier and M. Vaßholz
System of coherent
partial models
Shape
Application Scenarios
Knowledge
base
Track-
section x
Track-
section y
Requirements
Geometry
2
2.1
Length lges: 6600 mm
2.2
Width bges: 2420 mm
2.3
Height hges: 2855 mm
2.4
Distance hBo.: >400 mm
Behavior
System of Objectives
Environment
Functions
Active Structure
1
1
3
1
1..2
0..10
1
*
*
influences
influences
*
*
1
..
*
uses
transports
controls
connects
connects
bursts open
feeds and
conducts
User
influences
influences
bursts 
open
FSky
   FSky=dS*Vabs
!?
ds adjustable
S2
Z7
Z7.1
Z7.2
Z8
Z8.3
Z8.2
Z9.1
Z9.2
Z9.4
Z9.5
max.
max.
Abrasion
Maintenance
interval
min.
min.
min.
max.
In-
put
Controller
Working-
point
control
Drive
module1
Drive
module2
V
F*
...
Adjust air 
gap
Determine
control input
Optimize
control input
Determine
influences
External System of Objectives
Internal System of Objectives
Shuttle (excerpt)
Shuttle (excerpt)
Internal System of 
Objectives Shuttle (excerpt)
Targets of 
the cluster
Safety/
reliability
Lateral 
acceleration
Cost
Serial 
interface
Knowledge
base
Environ-
ment
Trace-
segment
RailCab
Switch
Calculate 
damping 
interaction
Calculate 
speed
skyhook
VSky
y
y
z2
z2
z1
Measured 
value
z1
Measured 
value
Measured 
value
y
z
z
Fig. 2.2 Partial models of the domain-spanning description of the Principle Solution of a
self-optimizing system [6]
Functions:
A function is the general and required relationship between input and output pa-
rameters with the aim to fulﬁll a task. Functions are implemented using solution
patterns and their concretizations. Functions should be speciﬁed in a hierarchical
manner [6].
Active Structure:
This partial model describes the system elements (e.g. drive and brake modules,
energy management) and their attributes, as well as their relations (energy, ma-
terial or information ﬂow). Incoming parameters are also described (e.g. com-
fort) [6].
Shape:
The Shape is usually created by a 3D CAD-System and gives a ﬁrst impression
of the physical appearance of the system [6].
Behavior:
The partial model Behavior is subdivided into the aspects Behavior – State and
Behavior – Activities. The aspect Behavior–State deﬁnes the states of the system
and the state transitions. The state transitions describe the reactive behavior of
the system towards incoming events, which can also be system activities. The

2 Development of Self-optimizing Systems
29
aspect Behavior – Activities describes the logical sequence of activities which are
carried out by the different system elements. Activities describe how functions
are executed within different system states [6].
System of Objectives:
This partial model includes external, inherent and internal objectives, as well as
the connections between them. Internal objectives are achieved by the system
itself during operation mode and as a consequence represent the system’s inten-
tionality [6] (see also Sect. 1.1).
In particular, the partial model System of Objectives is of high importance for
self-optimizing systems: it describes the objectives of the system during operations,
their hierarchical relationship, and potential conﬂicts between objectives [10]. The
speciﬁcation of the Principle Sution provides a holistic domain-spanning descrip-
tion of the self-optimizing system and forms the basis for the communication and
cooperation between the developers from the domains involved. As such, it enables
them to avoid design mistakes and corresponding iteration loops in later develop-
ment phases, which would otherwise occur due to differences in understanding of
the system [3].
To develop the Principle Solution the reference process for the Domain-spanning
Conceptual Design consists of four main phases: "Planning and Clarifying the
Task", "Conceptual Design on the System Level", "Conceptual Design on the Sub-
system Level" and "Concept Integration" (cf. Fig. 2.3).
In "Planning and Clarifying the Task", the design task of the system and the
requirements are identiﬁed and evaluated. The results are the List of Requirements,
the Environment model, the recommended product structure type and the design
rules for this, as well as the Application Scenarios.
Based on previously determined requirements the system must fulﬁll, the main
functions of the system are identiﬁed and set into a function hierarchy in the "Con-
ceptual Design on the System Level". Each function has to be fulﬁlled to satisfy the
requirements; therefore solution patterns are sought which can execute the desired
functions. Within a morphologic box, the solution patterns are combined to obtain
consistent solution variants. These are evaluated and the best one is chosen and in-
tegrated into the Principle Solution on the system level. The resulting solution does
Subsystem 1
Subsystem 2
Subsystem n
List of Requirements,
Application Scenarios
Principle Solution
on System Level
Principle Solution
on Subsystem Level
Decomposition
Complete
Principle
Solution
Planning and 
Clarifying the Task
Conceptual Design 
on the System Level
 Conceptual Design on
the Subsystem Level
Concept 
Integration
Domain-spanning Conceptual Design
Fig. 2.3 The four main phases of the Domain-spanning Conceptual Design

30
J. Gausemeier and M. Vaßholz
not have to be self-optimizing at this stage. The consistent grouping of solution pat-
terns allow the modeling of the Active Structure, an initial construction shape and
the System Behavior.
At this point the potential for the use of self-optimization can be identiﬁed, based
on contradictions within the System of Objectives. These can be solved either by
compromise or by self-optimization. In the latter case, the System of Objectives is
developed, and the List of Requirements and the function hierarchy are extended. In
preparing the self-optimization concept, the self-optimization processes will even-
tually be deﬁned, whether there is the necessary absence of conﬂicts of the self-
optimization process will be analyze, and the boundary conditions within which
self-optimization has to be working in, will be deﬁned as well. For the newly inte-
grated cognitive functions, solution patterns for self-optimization are identiﬁed and
integrated into the partial models of the Principle Solution. The Principle Solution
on the system level is the result of this phase.
To describe the system in detail, it is modularized and a Principle Solution for
each single subsystem is developed in the "Conceptual Design on the Subsystem
Level". This procedure corresponds to the Conceptual Design on the system level,
starting out with planning and clariﬁcation of the task. This phase results in the Prin-
ciple Solutions on the subsystem level. This process can be conducted recursively,
because the subsystem itself can be a system with subsystems, and so forth.
The Principle Solutions of the subsystems are integrated into one Principle So-
lution during the phase "Concept Integration" to represent the whole system. After-
wards the thus-speciﬁed system is analyzed regarding its dynamical behavior and
dependability. In this analysis phase, contradictions between the Principle Solu-
tion on the subsystem level are identiﬁed. Again, it must be determined whether
these contradictions can be solved by self-optimization. At the end of this step, a
technical-economical evaluation of the solution is made. The result of this phase
is the Principle Solution of the whole system, which serves as a starting point for
the subsequent Domain-speciﬁc Design and Development. This is carried out si-
multaneously in the speciﬁc domains (mechanical engineering, electrical/electronic
engineering, control engineering and software engineering) [5].
In this early development phase, the consistency of the system is ensured by this
domain-spanning approach. Development failures and therefore time-consuming
and costly iteration loops can be avoided. To eliminate failures in this early stage,
the dependability of the system is analyzed at the end of the concept integration.
A number of methods can be used here to analyze the Principle Solution, such as
the early Failure Mode Effect Analysis (FMEA) in combination with the Fault Tree
Analysis (FTA) (cf. Sect. 3.1.1). To ensure the dependability of the self-optimization
itself, the Multi-Level Dependability Concept can be applied (cf. Sect. 3.1.2). Dur-
ing the Design and Development, the Multi-Level Dependability Concept is real-
ized in the domains where the failure has been identiﬁed (cf. Sect. 3.2.1). As long
as failures or failure modes cannot be eliminated, the Principle Solution is tweaked
and readjusted. The resulting Principle Solution forms the basis for the following
Domain-speciﬁc Design and Development.

2 Development of Self-optimizing Systems
31
2.2
Domain-Speciﬁc Design and Development
As mentioned above, the Principle Solution is the starting point for the Domain-
speciﬁc Design and Development. The Principle Solution contains the information
that forms the basis for domain-speciﬁc development tasks. The transition of the
Principle Solution to the domains involved is described brieﬂy in D.M.f.I.T.S, [7],
Sect. 5.1. In classical mechatronic development processes, the four domains me-
chanical, control, software, and electrical/electronic engineering are involved. For
self-optimizing systems the optimization during operation needs to be additionally
taken into account in the domains. The domains involved use their speciﬁc methods,
tools and modeling languages to concretize the system. This phase is characterized
by a high coordination effort; to ensure the consistency of the system, the results
of the domains are continuously integrated. For this purpose, model transformation
and synchronization techniques are used. The integrated system is tested as a virtual
prototype to identify faults. This allows a short response time concerning design
failures and therefore reduces time and cost-intensive iterations.
The reference process for the Design and Development of self-optimizing sys-
tems shows the ideal approach in which the particularities that need to be considered
for the development of a self-optimizing system are pointed out. It is based on the
development of the RailCab and its function modules. To reduce development time
and therefore costs, the domains work in parallel where possible. Within the pro-
cess, important synchronization points are depicted, where the domains exchange
their results and get informations needed for further development. Even though the
process gives the impression of being overly stringent, iterations can emerge in par-
ticular at these synchronization points, although they are possible at every stage of
the process. The application of the presented approach for the Design and Develop-
ment of a speciﬁc development task and company must be developed individually.
The approach presented here is recursive and conducted on different hierarchy
levels of the system. The system itself consists of subsystems, whereby the subsys-
tems are also systems themselves that consist of subsystems, and so forth. Fig. 2.4
presents a schematic representation of the process for one subsystem. (A detailed
description is given in D.M.f.I.T.S, [7], Sect. 3.3.) It is intended to supplement the
existing Design and Development process of the domains involved. In the following,
we will give an overview of the tasks belonging to the various domains.

32
J. Gausemeier and M. Vaßholz
Mechanical Engineering
Control Engineering
Software Engineering
Electrical/Electric Engineering
EM
Analyze the
Requirements
Identify Interaction 
and Interfaces of 
the Virtual Model
Modelling the 
Self-Optimizing 
Test Environment
Building the Virtual 
Shape Model
Requirements for
the Virtual Prototype
Static 
Prototype
Interactive 
Prototype
Subsystem Integration
Integrate and
Modify Plant
Models
Finalize 
Control
Strategie
Plant Model
Control
Strategie
Requirements 
Analysis of 
the Hardware
Requierements of 
the Hardware
Chosen
Hardware
Existing Hardware
for Requirements
No Existing Hardware
for Requirements 
E2
E1
Selection of 
Information 
Processing Hardware
Concretize
Model
Simulate
Model
Analyze
Model
Choose
Solution Elements
Model
Simulation
Results
Analysis
Results
Solution
Elements
Intial Component
Model
Communication
Requirements
Derive Component
Model
Decompose 
Communication
Requirements
Coordination Pattern
Determine
Coordination
Pattern
Select System
Components
Properties of Systems
Software and Services
System 
Components
Derive
 Component Model
Refine and Analyze
Kinematics
Determine Forces
Roughly
Select 
Raw Material
Refine 
System Shape
Movement Posibilities,
Displacement
Static
Forces
List of 
Raw Materials
Rough
System Shape
Analyze 
Permeatation
Permeatation-Analysis
Resuts
Intergrate 
Substitution 
Models and HW
Define Test
Perform Tests
Evaluate Tests
Extended
Prototype
Substitution
Model is
Intergrable
Test Evaluation 
Based on the Metric
Quality of the 
Tests Sufficent
Quality of the 
Tests 
Unsufficent
Real
Prototype
Test Results
Test Results
Substitution Model is 
not Intergrable
Real Prototype
Evaluate the Real
Prototype
Test Results
Substitution
Model is
Intergrable
Identify
Parameter
Adjust Control
Parameter
Parameter
Control 
Parameter
Analyze 
Closed-loop 
System
Closed
Loop System
Analyze 
Closed-loop 
System
Analysis
Results
Modelling of 
Information pro-
cessing Hardware
Synthesis
Module 
Integration
System Software 
Integration
E1
Model of the Information
Processing Hardware
Validated Model of the
Information Processing
 Hardware
Structural
Description
Dynamically
Reconfigurable
Hardware Model
Validated Model of the
Dynamically Reconfigurable
 Hardware
Validated Model of the
Dynamically Reconfigurable
 Hardware
Structural Description of Dyn.
Reconfigurable Hardware
All Components
are Available
Components 
Missing
Hardware Implementation 
and Datasheet
Hardware Abstraction Layer of the 
System Software
Simulation/Verifica-tion 
of the Inf. Processing 
Hardware
Hardware Technology
Selection of Hardware 
Technology
Modelling of Dynami-
cally Reconfigur-
able Hardware
Simulation/Verificat-
ion of the Inf. Dyn. 
Reconfig. Hardware
Simulation/Verificat-
ion of the Inf. Dyn. 
Reconfig. Hardware
Synthesis of Dyn. 
Reconfigurable 
Hardware
Static
Dynamic
Produce
Functional Model
Build Test
Bench
Validate
Model
Functional
Model
Test
Bench
Validated
Model
Discrete Component
Behavior
Specify Discrete 
Behavior
Integrate Self-Healing
Behvaior
Generate Hardware
Specific Code
Self-Healing Behavior
Hardware-Specific 
Code
Simulate Controller 
and Discrete Behavior
Specify Deployment
Simulated Discrete and 
Continuous Behavior
Deployment
Executeable 
System
Deploy Software to 
Hardware
SCL Configuration 
of the System
Software
Experiment Results
Evaluated 
Prototype
Code of 
System Software
Simulation Results
S3
S2
S3
Determine
Appropriate Models/
Algorithms
Implement new 
Approach
Int. of new Ap. into 
Sys. Soft. 
Components
Extend System 
Software
Specify Evaluation
Function
Model/Algorithm
Implemented 
new Approach
Assignment of System 
Components to Model
and Integrated new Approach
Illustration 
not Possible
Illustration 
Possible
Extended 
System Software
Evaluation Function 
and Thresholds
Proven
Method
New 
Method
System Software
 not Extendable
System Software
Extendable
Develop Dynamic
Model
Determine Dynamic 
Forces
Dynamics
Model
Dynamic 
Forces
Determine Actuator 
Energy
Select 
Actuator
Select Supply 
Component
Develop
Hydraulic Plan
Develop 
Pneumatic Plan
Perform Collision
Analysis
Design Detailed 
System Shpae
Needed Actuator
Energy
Actuator
Datasheets
Supply Comonent
Datasheets
Hydraulic 
Plan
Pneumatic 
Plan
Collision-Analysis
Results
Detailed
System Shape
Perform 
FEM-Analysis
FEM-Analysis
Results
Evaluation on 
Prototype
Evaluation through
Simulation
Evaluation in 
Experimental 
Environment
Formulate
Optimization
Problem
Identify Potential 
for Multiobjective
Optimization
Choose 
Optimization 
Method
Apply Optimization
Method
Planning on
Pareto Points
Formulation of 
Optimization Problem
Multiobjective Optimization 
Potential
Chosen Optimization 
Method
Konowledge 
Base
Online
Optimization
Online Optimization
Method
Offline
Optimization
Single Optimal Design
Configuration
Chosen Optimization 
Control Engineering
Software Engineering
Electrical/Electric Engineering
EM
Analyze the
Requirements
Identify Interaction
and Interfaces of 
the Virtual Model
Modelling the 
Self-Optimizing
Te
T st Environment
Building the Virtual
Shape Model
Requirements for
the Virtual Prototype
Static
Prototype
Interactive 
Prototype
Subsystem Integration
Integrate and
Modify Plant
Models
Finalize
Control
Strategie
Plant Model
Control
Strategie
Requirements
Analysis of 
the Hardware
Requierements of 
the Hardware
Chosen
Hardware
Existing Hardware
for Requirements
No Existing Hardware
for Requirements 
E2
E1
Selection of 
Information 
Processing Hardware
Concretize
Model
Simulate
Model
Analyze
Model
Choose
Solution Elements
Model
Simulation
Results
Analysis
Results
Solution
Elements
Intial Component
Model
Communication
Requirements
Derive Component
Model
Decompose
Communication
Requirements
Coordination Pattern
Determine
Coordination
Pattern
Select System
Components
Properties of Systems
Software and Services
System
Components
Derive
 Component Model
Intergrate 
Substitution 
Models and HW
Define Te
T st
Perform Tests
T
Evaluate Te
T sts
Extended
Prototype
Substitution
Model is
Intergrable
Test E
T
valuation 
Based on the Metric
Quality of the 
Test
T
s Suffif cent
Quality of the 
Test
T
s
Unsuffif cent
Real
Prototype
Test Results
T
Test Results
T
Substitution Model is
not Intergrable
Real Prototype
Evaluate the Real
Prototype
Te
T st Results
Substitution
Model is
Intergrable
Identify
Parameter
Adjust Control
Parameter
Parameter
Control 
Parameter
Analyze 
Closed-loop 
System
Closed
Loop System
Analyze 
Closed-loop 
System
Analysis
Results
Modelling of 
Information pro-
cessing Hardware
Synthesis
Module
Integration
System Software
Integration
E1
Model of the Information
Processing Hardware
Validated 
V
Model of the
Information Processing
 Hardware
Structural
Description
Dynamically
Reconfigurable
Hardware Model
Validated 
V
Model of the
Dynamically Reconfigurable
 Hardware
Validated 
V
Model of the
Dynamically Reconfigurable
 Hardware
Structural Description of Dyn.
Reconfigurable Hardware
All Components
are Available
A
Components
Missing
Hardware Implementation
and Datasheet
Hardware Abstraction Layer of the
System Software
Simulation/Verifica-tion
V
of the Inf. Processing 
Hardware
Hardware Te
T chnology
Selection of Hardware 
Technology
T
Modelling of Dynami-
cally Reconfigur-
able Hardware
Simulation/Verificat-
V
ion of the Inf. Dyn. 
Reconfig. Hardware
Simulation/Verificat-
V
ion of the Inf. Dyn.
Reconfig. Hardware
Synthesis of Dyn.
Reconfigurable
Hardware
Static
Dynamic
Produce
Functional Model
Build Te
T st
Bench
Validate
V
Model
Functional
Model
Test
T
Bench
Validated
V
Model
Discrete Component
Behavior
Specify Discrete 
Behavior
Integrate Self-Healing
Behvaior
Generate Hardware
Specific Code
Self-Healing Behavior
Hardware-Specific
Code
Simulate Controller 
and Discrete Behavior
Specify Deployment
Simulated Discrete and
Continuous Behavior
Deployment
Executeable
System
Deploy Software to 
Hardware
SCL Configuration
L
of the System
Software
Experiment Results
Evaluated 
Prototype
Code of 
System Software
Simulation Results
S3
S2
S3
Determine
Appropriate Models/
Algorithms
Implement new
Approach
Int. of new Ap. into
Sys. Soft. 
Components
Extend System 
Software
Specify Evaluation
Function
Model/Algorithm
Implemented
new Approach
Assignment of System
Components to Model
and Integrated new Approach
Illustration 
not Possible
Illustration 
Possible
Extended
System Software
Evaluation Function 
and Thresholds
Proven
Method
New
Method
System Software
 not Extendable
System Software
Extendable
Mechanical Engineering
Refine and Analyze
Kinematics
Determine Forces
Roughly
Select 
Raw Material
Refine
System Shape
Movement Posibilities,
Displacement
Static
Forces
List of 
Raw Materials
Rough
System Shape
Analyze 
Permeatation
Permeatation-Analysis
Resuts
Develop Dynamic
Model
Determine Dynamic
Forces
Dynamics
Model
Dynamic
Forces
Determine Actuator 
Energy
Select 
Actuator
Select Supply
Component
Develop
Hydraulic Plan
Develop
Pneumatic Plan
Perform Collision
Analysis
Design Detailed 
System Shpae
Needed Actuator
Energy
Actuator
Datasheets
Supply Comonent
Datasheets
Hydraulic
Plan
Pneumatic 
Plan
Collision-Analysis
Results
Detailed
System Shape
Perform 
FEM-Analysis
FEM-Analysis
Results
Evaluation on 
Prototype
Evaluation through
Simulation
Evaluation in
Experimental 
Environment
Formulate
Optimization
Problem
Identify Potential 
for Multiobjective
Optimization
Choose
Optimization
Method
Apply Optimization
Method
Planning on
Pareto Points
Formulation of 
Optimization Problem
Multiobjective Optimization 
Potential
Chosen Optimization
Method
Konowledge
Base
Online
Optimization
Online Optimization
Method
Offline
f
Optimization
Single Optimal Design
Configuration
Chosen Optimization 
Subsystem Integration
Mechanical Engineering
Control Engineering
Software Engineering
Electrical/Electric Engineering
Fig. 2.4 Schematic representation of the Domain-speciﬁc Design and Development

2 Development of Self-optimizing Systems
33
Mechanical engineering:
The domain mechanical engineering has as its goal the Design and Development
of the system shape of the self-optimizing system. Its starting point are the par-
tial models Requirements, Active Structure and Shape of the Principle Solution.
Based on these partial models, solution elements are selected and a ﬁrst Shape
model is built. This model serves as input for the domains control and electrical
engineering, as well as for (sub)system integration. Using the Shape model, the
domain control engineering is able to ﬁnalize the control strategy and the do-
main electrical engineering can develop a ﬁrst model of the power electronics.
Furthermore, a ﬁrst virtual prototype can be modeled in the (sub)system inte-
gration. The result is a dynamic model that enables a simulation of the dynamic
behavior. Based on these results, the Shape model can be further developed using
a 3D-CAD software tool. The results of the work in this domain are the mechan-
ical structure and derived manufacturing documents.
Control engineering:
The aim of control engineering is the design of the controller to guarantee the
desired dynamical behavior of the self-optimizing system. Based on the Shape
model from mechanical and electrical engineering, the control strategy can be
ﬁnalized. The given dynamic model is the input for the optimization; resulting
optimization strategies are integrated into the control strategy and the closed-loop
system is analyzed. The analysis results are then passed along to the (sub)system
integration and can be tested in the virtual prototype as hardware-in-the-loop-
tests. Based on these tests, necessary parameters can be identiﬁed, control pa-
rameters adjusted, and the closed-loop can be analyzed again. These adjustments
need to be done again after testing the real prototype; only then can the control
strategy be ﬁnalized and implemented into the real system.
Software engineering:
The system software and discrete software are developed in the domain software
engineering. The system software provides services for the discrete software;
its development process is structured into three main phases. First, the required
methods need to be identiﬁed and designed. Second, the developed methods need
to be implemented; third they need to be evaluated.
In the ﬁrst phase, the components of the system that will contain system soft-
ware are selected. This information is derived from the Requirements of the
Principle Solution. For each of these components, appropriate models or algo-
rithms need to be determined if not already available. For example, self-healing
may be implemented to improve the dependability of the system software (cf.
Sect. 3.2.12). In the case of a high demand for processing power and memory,
virtualization can reconcile the opposing requirements (cf. Sect. 3.2.15). Follow-
ing this in the second phase, the new components need to be integrated into the
system software and, if applicable, the system software is extended. If this exten-
sion is not possible, an iteration is necessary and the new approach needs to be
adjusted or further models with their respective algorithms need to be developed.
In the third phase, the system software components are assigned, including the

34
J. Gausemeier and M. Vaßholz
speciﬁcation of evaluation functions. The three phases are run through until all
requirements are met.
During the Conceptual Design of the discrete software, a component structure
is derived from the Requirements. The component structure of the discrete soft-
ware is modeled by the Active Structure, while the communication between the
components is modeled by Modal Sequence Diagrams.
During Design and Development, we use MechatronicUML (cf. D.M.f.I.T.
S, [7], Chap. 5) to design the discrete software. In MechatronicUML, the compo-
nent structure of the Active Structure is further reﬁned and coordination patterns
(cf. D.M.f.I.T.S, [7], Chap. 5) are derived from the Modal Sequence Diagrams;
these coordination patterns specify communication protocols. Next, the discrete
internal component behavior and the reconﬁguration behavior are speciﬁed. We
use model checking to guarantee that this behavior satisﬁes the requirements
(cf. D.M.f.I.T.S, [7], Chap. 5); model checking also supports checking the inte-
gration of control engineering (cf. Sect. 3.2.10). The deployment of the software
is based on the description of the hardware that is provided by electronic engi-
neering. A hazard analysis is also performed at this stage to guarantee that the
occurance of severe hazards remains below a speciﬁc probability limit. Hazards
whose occurrence probabilities are higher may be reduced by self-healing op-
erations, which are speciﬁed by means of reconﬁgurations. Then, it is analyzed
whether the self-healing operations are able to achieve the intended probability
reduction (cf. Sect. 3.2.8). Afterwards, the reconﬁguration behavior is veriﬁed.
The system computes reconﬁguration plans at runtime that avoid unsafe conﬁgu-
rations (cf. Sect. 3.2.9); this planning process is simulated at design time to vali-
date its reliability. In addition, we apply online model checking (cf. Sect. 3.2.14).
If all the requirements are fulﬁlled, the controller and the discrete behavior are
simulated using the virtual prototype in the (sub)system integration (cf. D.M.f.I.
T.S, [7], Chap. 5). If the simulation displays correct functionality, the hardware-
speciﬁc code is generated and deployed on the hardware.
Electrical/electronic engineering:
Self-optimizing systems demand high ﬂexibility in order to be able to adapt their
behavior during operation. Dynamically reconﬁgurable hardware can ensure this
ﬂexibility. Furthermore, such systems demand high power transmission. There-
fore, in the domain electrical/electronic engineering, both microelectronic de-
vices for information processing and power electronics need to be developed. In-
put for the development of the microelectronics is given by the Requirements of
the Principle Solution. After analyzing these requirements, a set of appropriate
information processing hardware components is collected. In case the require-
ments cannot be fulﬁlled by existing hardware, additional hardware, for exam-
ple embedded processor architecture or FPGA (Field Programmable Gate Array)
technology is chosen. At this point the developer needs to decide whether the
hardware to be developed consists only of static components, or of both static and
dynamic ones. In the ﬁrst case, the standard design ﬂow from the Y-diagram for
electronic engineering is used, whereas if dynamic reconﬁguration of the hard-
ware is considered necessary, the procedure needs to be extended with respect

2 Development of Self-optimizing Systems
35
to the characteristics of these architectures. The concrete process is part of the
design environment INDRA (Integrated Design Flow for Reconﬁgurable Archi-
tectures, cf. D.M.f.I.T.S, [7], Chap. 5. First, the dynamic reconﬁgurable hardware
is modeled; while doing this, the requirements that are derived from system soft-
ware are taken into account. The model is simulated and veriﬁed and afterwards
synthesized until all of the components have been integrated. Finally, the sys-
tem software can be ported to the new architecture. To increase the dependability
of the system, self-healing via dynamic reconﬁguration can be implemented (cf.
Sect. 3.2.13). For the development of the power electronics, the partial model
Requirements and Active Structure serve as input. Based on these, the type of
electrical drive is selected and its capacity is analyzed. In the next step, the appro-
priate engine is chosen. This information is passed on to mechanical engineering
and is integrated into the system model, after which the thermal resilience of the
engine is tested and the data sheet of the electrical engine is derived. Afterwards,
the power electronics can be deﬁned. The results of these tasks are integrated into
the overall system.
(Sub)System Integration:
To ensure the consistency of the domain-speciﬁc models, the results of the do-
mains are integrated continuously into an interdisciplinary system model that
is based on the Principle Solution; additionally the functionality of the system
model is secured by a virtual prototype. To do so, a self-optimizing test bench
and the environment are modeled. The basis for the virtual prototype are given by
the Requirements of the Principle Solution. The virtual prototype is ﬁrst modeled
based on the basic Shape model developed by the domain mechanical engineer-
ing. This prototype is improved and expanded continuously over the course of
development process by integrating the results from other domains. To make the
simulation of the virtual prototype possible, the interactions and interfaces of the
model need to be identiﬁed. For the system test, the test cases and a metric are
ﬁrst deﬁned. Based on these cases, the virtual prototype is tested (cf. Sect. 3.2.3).
The quality of the test results can be evaluated using the pre-deﬁned metric. If the
quality of the tests is not sufﬁcient new tests are deﬁned, performed and evaluated
until the quality is sufﬁcient. Then the test results are returned to the domains.
When all subsystems are fully implemented into the virtual prototype and the test
results are failure-free, the real prototype can be built and evaluated.
Within the development process, the dependability of the self-optimizing sys-
tem needs to be continuously ensured. This can be done with dependability-speciﬁc
methods such as those presented in Chap. 3. The Methodology for the Selection of
Dependability Methods for the Development of Self-Optimizing Systems presented
in Sect. 3.3 supports the developer in choosing the appropriate dependability method
and in integrating it into the development process.

36
References
References
1. Albers, A.: Five Hypotheses about Engineering Processes and their Consequences. In:
Proceedings of the 8th International Symposium on Tools and Methods of Competitive,
Ancona, IT (2010)
2. Bender, K.: Embedded Systems – Qualitätsorientierte Entwicklung. Springer, Berlin
(2005), doi:10.1007/b138984
3. Dorociak, R., Gaukstern, T., Gausemeier, J., Iwanek, P., Vaßholz, M.: A Methodology for
the Improvement of Dependability of Self-Optimizing Systems. Production Engineering
– Research and Development 7(1), 53–67 (2013), doi:10.1007/s11740-012-0425-3
4. Ehrlenspiel, K.: Integrierte Produktentwicklung, 3rd edn. Carl Hanser Verlag, Munich
(2007)
5. Gausemeier, J., Frank, U., Donoth, J., Kahl, S.: Speciﬁcation Technique for the Descrip-
tion of Self-Optimizing Mechatronic Systems. Research in Engineering Design 20(4),
201–223 (2009), doi:10.1007/s00163-008-0058-x
6. Gausemeier, J., Rammig, F.J., Schäfer, W. (eds.): Selbstoptimierende Systeme des
Maschinenbaus. In: HNI-Verlagsschriftenreihe, vol. 234. Heinz Nixdorf Institute, Uni-
versity of Paderborn, Paderborn (2009)
7. Gausemeier, J., Rammig, F.J., Schäfer, W. (eds.): Design Methodology for Intelligent
Technical Systems. Lecture Notes in Mechanical Engineering. Springer, Heidelberg
(2014), doi:10.1007/978-3-642-45435-6_2
8. Isermann, R.: Mechatronische Systeme – Grundlagen. Springer, Berlin (2008),
doi:10.1007/978-3-540-32512-3
9. Kahl, S., Gausemeier, J., Dumitrescu, R.: Interactive Visualization of Development Pro-
cesses. In: Proceedings of the 1st International Conference on Modelling and Manage-
ment of Engineering Processes (2010)
10. Pook, S., Gausemeier, J., Dorociak, R.: Securing the Reliability of Tomorrow’s Systems
with Self-Optimization. In: Proceedings of the Reliability and Maintainability Sympo-
sium, Reno, NV, US (2012)
11. Rieke, J., Dorociak, R., Sudmann, O., Gausemeier, J., Schäfer, W.: Management of
Cross-Domain Model Consistency for Behavioral Models of Mechatronic Systems. In:
Proceedings of the 12th International Design Conference, Dubrovnik (2012)
12. Verein Deutscher Ingenieure (VDI): VDI 2206 – Entwicklungsmethodik für mechatron-
ische Systeme. Technical Guideline (2004)

Chapter 3
Methods of Improving the Dependability
of Self-optimizing Systems
Abstract. Various methods have been developed in the Collaborative Research
Center 614 which can be used to improve the dependability of self-optimizing
systems. These methods are presented in this chapter. They are sorted into two
categories with regard to the development process of self-optimizing systems. On
one hand, there are methods which can be applied during the Conceptual Design
Phase. On the other hand, there are methods that are applicable during Design and
Development.
There are domain-spanning methods as well as methods that have been speciﬁ-
cally developed for particular domains, e.g., software engineering or control
engineering. The methods address different attributes of dependability, such as reli-
ability, availability or safety.
Each section is prefaced with a short overview of the classiﬁcation of the de-
scribed method regarding the corresponding domain(s), as well as its dependability
attributes, to provide the reader with a brief outline of the methods’ areas of applica-
tion. Information about independently applicable methods or existing relationships
and interactions with other methods or third-party literature is also provided.
The development process for self-optimizing mechatronic systems which was intro-
duced in Chap. 2 consists of two main phases: Conceptual Design and Design and
Development. The main result of the Conceptual Design is the Principle Solution,
which includes all information required for the concrete development during the
second phase.
3.1
Conceptual Design Phase
Even as early as during the speciﬁcation of the Principle Solution, the dependability
of self-optimizing mechatronic systems can be evaluated and improved by employ-
ing appropriate methods. The result is an improved Principle Solution, as such meth-
ods take the whole system into account before splitting it up into domain-speciﬁc
tasks for the following development phase.
J. Gausemeier et al. (eds.), Dependability of Self-optimizing Mechatronic Systems,
37
Lecture Notes in Mechanical Engineering,
DOI: 10.1007/978-3-642-53742-4_3, c⃝Springer-Verlag Berlin Heidelberg 2014

38
R. Dorociak and J. Gausemeier
3.1.1
Early Probabilistic Reliability Analysis of an Advanced
Mechatronic System Based on Its Principle Solution
Rafal Dorociak and Juergen Gausemeier
The Early Probabilistic Reliability Analysis of an Advanced Mechatronic System
based on its Principle Solution is a method of improving the attributes reliability,
safety and availability in the early development phase of Conceptual Design. The
method can be used to ensure the dependability of the Principle Solution. Thus, it is
necessary to use the speciﬁcation technique CONSENS for the domain-spanning de-
scription of the system. Furthermore, the method for the early probabilistic analysis
of the reliability of a self-optimizing mechatronic system uses two complementary
reliability assurance methods, FMEA and FTA, in interplay. The method can be seen
as a further development of FMEA and FTA to use both methods in the early phase
of the development and in combination.
In the following, we will introduce the method for the early probabilistic analysis
of the reliability of a self-optimizing mechatronic system based on its Principle
Solution. This method allows for ﬁrst statements regarding to the reliability of the
system in the early engineering phase of Conceptual Design. In particular, the weak
points of the system with respect to reliability are found. For those weak points,
measures to detect and counter them are derived and implemented directly in the
Principle Solution of the system. Altogether, the system under consideration is made
more reliable at an early development stage.
3.1.1.1
Prerequisites and Input
The main input of our method is the domain-spanning speciﬁcation of the Princi-
ple Solution. This Principle Solution is determined by means of the speciﬁcation
technique CONSENS for the domain-spanning [54] (cf. Sect. 2.1). As explained in
Sect. 2.1, the description of the Principle Solution is divided into 8 partial models:
Environment, Application Scenarios, Requirements, Functions, Active Structure,
Shape, Behavior and System of Objectives. The focus of our method lies on the
analysis of the partial models Environment, Application Scenarios, Requirements,
Functions, Active Structure and Behavior.
3.1.1.2
Description
Following the recommendation of the CENELEC EN 50129 standard [45], the
method for the early probabilistic analysis of the reliability of a self-optimizing
mechatronic system uses two complementary reliability assurance methods FMEA
(Failure Mode and Effects Analysis) [21,73] and Fault Tree Analysis (FTA) [21,74]
in cooperation with each other. Some concepts known from the FHA (Functional
Hazard Analysis) [150] method have been adapted as well, in particular, the use of
a failure taxonomy for the identiﬁcation of possible failures. By using these com-
plementary methods, the completeness of the list of possible failure modes, failure

3 Methods of Improving the Dependability of Self-optimizing Systems
39
causes and failure effects, as well as of the speciﬁcation of failure propagation, is
increased; both failure speciﬁcations are held mutually consistent.
Figure 3.1 shows the procedure model of our method iterations are not shown.
Phase 1 – speciﬁcation of the Principle Solution:
The starting point of this phase are moderated workshops, where the experts from
the involved disciplines work together in order to specify the system using the
speciﬁcation technique CONSENS, as well as to analyze and improve it with
regard to reliability. In particular, the partial models Functions, Active Structure,
and Behavior are described.
Phase 2 – early FMEA based on the Principle Solution:
The system structure and the corresponding functions are automatically derived
from the description of the partial models Functions, Active Structures, and
Behavior; they are recorded in the FMEA table. Failure modes, failure causes
and failure effects are then identiﬁed. Checklists and failure taxonomies (e.g.
as shown in Fig. 3.2) assist the failure identiﬁcation process [47], [147]. In
addition, combinations are identiﬁed of failure models which can conceivably
Principle Solution
FMEA table
Specification of the
failure propagation
Improved failure 
speciﬁ cation
Improved Principle
Solution
Phases/Milestones
Tasks/Methods
Results
Specification of the 
Principle Solution
 
●Specify and analyze the Active 
Structure
 
●Identify the functions of the system 
elements
 
●Identify failure modes, failure causes 
and failure effects; use of failure 
classiﬁ cations
 
●Identify relevant failure combina-
tions
 
●Specify the failure propagation 
within the Principle Solution
 
●Compare failure specifications
 
from FMEA and FTA
 
●Update and extend the FMEA table 
and the failure propagation speciﬁ -
cation accordingly
 
●Conduct further analyses; e.g. 
minimal cut sets
 
●Derive counter-measures; optimize 
the speciﬁ cation of the Principle 
Solution
2
Early FMEA based on the 
Principle Solution
Early FTA based on the 
principle solution
Comparison of both
 failure speciﬁ cations
Reﬁnement of the
principle solution
1
3
4
5
Fig. 3.1 The procedure model of the method for the early probabilistic analysis of the relia-
bility of a self-optimizing mechatronic system

40
R. Dorociak and J. Gausemeier
Provision
Timing
Value
Omission
Commission
Early
Late
Subtle 
incorrect
Coarse 
incorrect
Failure classification (according to Fenelon et al.)
Fig. 3.2 Failure classiﬁcation (according to Fenelon et al.) [47]
occur together and have a negative impact on the system (pairs of failures,
triplets of failures, etc.). Failure modes and relevant failure mode combinations
are recorded in the FMEA table. For each failure mode (and failure mode combi-
nation), the possible failure causes and failure effects are analyzed. Again, check
lists can be used to accomplish this step, as they describe system elements known
to be possible sources of problems with regard to reliability [43]. A number of
failure effects can be found by analyzing the Principle Solution of the system;
this, especially regarding the partial models Active Structure and Behavior. A risk
assessment of the failure modes, failure causes and failure effects then take place
using the risk priority number (cf. the norm IEC 60812 [73]). Finally, counter
and detection measures are deﬁned in addition as the corresponding responsibili-
ties. This occurs analogously to the classical FMEA. The FMEA table is updated
accordingly.
Phase 3 – early FTA based on the Principle Solution:
Here, the speciﬁcation of the failure propagation within the Principle Solution is
performed. The process is very similar to traditional FTA. For each system ele-
ment, its internal failures as well as incoming and outgoing failures are speciﬁed
and related to each other.
Figure 3.3 shows an example of the speciﬁcation of the failure propagation within
a prototypical system element SE. The output O1 exhibits an undesired system
behavior if the internal failure "failure1" occurs if one of the two inputs (I1, I2) is
faulty. Based on such a description of the failure propagation, a fault tree can be
generated (semi)-automatically (Fig. 3.3).
Phase 4 – improvement of the completeness of the failure speciﬁcation:
The FMEA table and the speciﬁcation of failure propagation both contain infor-
mation about causal relationships between failures. Following the recommenda-
tion of the CENELEC EN 50129 [45], we use both methods in combination, to
ensure a higher completeness of the failure speciﬁcation. This can be achieved
by comparing the information content of the FMEA and of the failure propaga-
tion speciﬁcation: e.g. failures and causal relationships between failures can po-
tentially be found in the failure propagation speciﬁcation, which were not been
found during the FMEA and are thus not documented in the FMEA table; the
FMEA table is in that case updated accordingly. This also applies in the other

3 Methods of Improving the Dependability of Self-optimizing Systems
41
Fig. 3.3 Speciﬁcation of the
failure propagation and the
corresponding fault tree
SE.failure1
SE.O1.not(ok)
SE.I1.not(ok)
SE.I2.not(ok)
OR
System element SE
not(ok)
not(ok)
I1
I2
O1
failure1
OR
not(ok)
ok
ok
ok
Boolean
gate
System
element
Failure
Port failure
states
CanImply 
relationship
Legend
comparison direction: For example, if a causal relationship between two failures
(e.g. between a failure mode and a failure effect) has been recorded in the FMEA
table, there should be a corresponding causal relationship given in the failure
propagation speciﬁcation. If this is not the case, the causal relationship is incor-
porated into the failure propagation speciﬁcation. During the process, additional
failures can be found as well, which have not been speciﬁed at that point. The
completeness of the identiﬁed failure modes, failure effects and failure causes,
as well as of the failure propagation speciﬁcation, is improved. Examples are
provided at the end of this section, when our applied example is explained.
Phase 5 – Improving the Principle Solution:
Both failure speciﬁcations are analyzed. For instance, the classical analyses
known from the FTA ﬁeld, such as minimal cut sets, are used [21]. In particular,
the importance analysis is performed. For this purpose, the Bayesian network-
driven approach is used [38]; it enables the computation of the Fussell-Vesely
importance measure. In such a manner, the most critical system elements are
identiﬁed. Counter and detection measures are deﬁned based on the analysis
results. If possible, they are incorporated directly into the Principle Solution
(e.g. redundancy, condition monitoring [90], etc.). Otherwise, they are recorded
for further discipline-speciﬁc Design and Development (e.g. test and simulation
measures, etc.).
3.1.1.3
Results
The result of this method is a revised Principle Solution of the system which is im-
proved with regard to reliability. As a consequence, the system under consideration
is made more reliable at an early development stage and a great number of time-
intensive and costly iteration loops during the further development phases can be
avoided. The failure speciﬁcations and analyses results from the Conceptual Design
are used in the further development phase of domain-speciﬁc Design and Develop-
ment. During this phase, with the increasing concretization of the system, reliability
analyses such as FTA and FMEA are performed again.

42
R. Dorociak and J. Gausemeier
3.1.1.4
Application Example
The complete RailCab system has been speciﬁed using the speciﬁcation technique
CONSENS. In the following, some of the results for the active suspension module
of the RailCab are shown. Each active suspension module consists of three servo
cylinders, which dampen vibrations and tilt the vehicle body in curves. Each servo
cylinder consists of a hydraulic cylinder, a 4/4-way valve, a servo cylinder regula-
tion and a hydraulic valve regulation [126]. The method for the early probabilistic
analysis of the reliability of a self-optimizing mechatronic system has been applied
to the active suspension module. As a ﬁrst step, the Principle Solution of the active
suspension module was modeled using the speciﬁcation technique CONSENS. Fig-
ure 3.4 shows an excerpt of the partial model Active Structure of the servo cylinder
that is used in the active suspension module.
Based on the speciﬁcation of the Principle Solution, an early FMEA is performed.
An excerpt of the resulting FMEA table for the servo cylinder is shown in Fig. 3.5.
Using the failure taxonomy by [47], the failure mode hydraulic valve regulation
provides no switch position for the 4/4-way valve can be found. This failure mode
occurs, for instance, if the energy supply of the system element hydraulic valve
regulation is interrupted. According to the FMEA, the risk priority number for this
case is 252. In order to eliminate or at least mitigate the failure mode, the energy
supply of the hydraulic valve regulation should be monitored. One possible solution
is the incorporation of an additional monitoring system element into the Principle
Solution. In this case, additional measures, such as a redundant energy supply, have
to be implemented.
Using the method for the early FTA, the speciﬁcation of the Principle Solution
is supplemented by the speciﬁcation of failure propagation (Fig. 3.6). For each
Servo cylinder
hy
Hydraulic valve 
regulation
Servo cylinder 
regulation
X*valve (set value of the hydraulic
valve position)
4/4-way valve
Hydraulic 
cylinder
Xvalve 
(current position of
hydraulic valve)
Yvalve (switch                                
position valve)                               
Information flow
System element
Energy flow
Material flow
Measurement 
information flow
Hydraulic connection 1
Hydraulic connection 2
X*cylinder (set value for
cylinder position)
Xcylinder
(current position of
the cylinder position)
Legend
Fig. 3.4 Active Structure of the active suspension module (excerpt)

3 Methods of Improving the Dependability of Self-optimizing Systems
43
Sensor wired in wrong 
way
Sensor damaged
Wrong calibration
Failure Mode and Effects Analysis (FMEA)
Module: Servo cylinder
System
element
Failure 
mode
Failure effect
S Failure cause
...
Hydraulic 
valve 
regulation
Hydraulic 
valve 
regulation 
provides no 
switch 
position for 
the 4/4-way 
valve
Valve no 
longer changes
pressure on  
output 
6
Servo cylinder regulation 
does not set value for 
valve slider position
Hydraulic valve regulation 
broken
Energy supply of 
hydraulic valve regulation 
interrupted
4/4-way 
valve
Valve closes 
in an 
unwanted 
manner
Hydraulic valve 
is stuck in 
current position 
Energy supply 
interrupted
Magnetic coil damaged
Function
Regulate 
position of 
the valve
Close valve
Servo
cylinder 
regulation
An incorrect 
value for the
position has
been deter-
mined
Control 
deviation e = 
X*cylinder –
Xcylinder has an 
incorrect value;
the desired 
action is not 
generated
9
Cable broken
Determine
current
position of 
cylinder 
piston
8
D
2
9
7
7
8
3
8
2
9
O
7
3
6
4
3
2
3
5
2
RPN
84
162
252
224
192
54
216
90
162
Counter- or detection-
measure 
Monitor outgoing 
communication towards 
4/4-way valve
Generate warning 
message if needed
Monitor energy supply
Monitor energy supply
Generate warning 
message if needed
Monitor current value of
cylinder lifting way 
Xcylinder
Redundant design of
measuring system 
...
...
...
...
...
...
...
...
...
...
...
...
...
...
S:
Severity of the failure effect
D:
Detection probability of the failure cause
O:
Occurence probability of the failure cause
RPN:
Risk priority number (RPN=S·D·O)
Fig. 3.5 FMEA table of the servo cylinder (excerpt)

44
R. Dorociak and J. Gausemeier
System element
CanImply relationship
Boolean operator
Failure
Servo cylinder
4/4-way valve
Hydraulic valve 
regulation
Servo cylinder
regulation
X*Ventil
Hydraulic cylinder
XVentil
YVentil
Hydr.conn 2
X*Cylinder
XCylinder
F2
F1
OR
F4
F3
OR
F1:
Hydraulic valve regulation error
F2:
Energy supply of hydraulic valve regulation interrupted
F3:
Energy supply of regulation servo cylinder interrupted
F4:
Servo cylinder regulation error
 
F5:
Sealing between cylinder piston and cylinder wall leaks
HV1
HV2
WV1
WV2
WV3
SV1
HZ3
HZ1
F5
Actuating
power
cylinder A 
Port state
OR
not (ok)
not (ok)
not (ok)
not (ok)
not (ok)
not (ok)
not (ok)
not (ok)
Hydr.conn 1
not (ok)
Legend
Fig. 3.6 Speciﬁcation of the failure propagation of the servo cylinder (excerpt)
sensor has been wired in
a wrong way
sensor is damaged
wrong calibration
Failure Mode and Effects Analysis (FMEA)
Module: Servo cylinder
System
element
Failure
Failure effect
S Failure cause 
...
Hydraulic
valve
regulation
Hydraulic
valve
regulation
provides no
switch
position for
the 4/4-way
valve
Valve no
longer changes
pressure on
output
6
Servo cylinder regulation
does not set value for
valve slider position
Hydraulic valve regulation
broken
Energy supply of
hydraulic valve regulation
interrupted
4/4-way
valve
valve closes
in an
unwanted
manner
Hydraulic valve
is stuck in
current position
Energy supply
interrupted
magnetic coil is damaged
Function
Regulate
position of
the valve
Close valve
servo-
cylinder
regulation
a wrong as-
is value for
the cylinder
lifting way
has been
determined
control
deviation e =
X*cylinder –
Xcylinder has a
wrong value;
the desired
lifting way will
not be
accomplished
9
cable break
determine
the as-is
value for the
cylinder
lifting way
8
D
2
9
7
7
8
3
8
2
9
O
7
3
6
4
3
2
3
5
2
RPN
84
162
252
224
192
54
216
90
162
Counter- or detection-
measure
Monitor outgoing
communication towards
4/4-way-valve
Generate warning
message if needed
Monitor energy supply
Monitor energy supply
Generate warning
message if needed
Monitor current value of
cylinder lifting way
Xcylinder
Redundant design of
measuring system
...
...
...
...
...
...
...
...
...
...
...
...
...
...
System element
canImply relationship
Boolean operator
Failure
Servo cylinder
4/4-way valve
hHdraulic valve
regulation
Servo cylinder
regulation
X*valve
Hydraulic cylinder
Xvalve
Yvalve
hydr. conn. 1
hydr. conn.2
X*cylinder
Xcylinder
not(ok)
not(ok)
F2
F1
OR
not ok)
not(ok)
not(ok)
not(ok)
F4
F3
not(ok)
not(ok)
not(ok)
OR
HV1
HV2
WV1
WV2
WV3
SV1
HZ3
HZ1
HZ2
F5
actuating
power
cylinder A
Port state
OR
1
2
3
4
5
FMEA (excerpt)
Partial model Active Structure
(excerpt)
F1:     Hydraulic valve regulation defect
F2:     Energy supply of the hydraulic valve regulation interrupted
F3:     Energy supply of the regulation servo cylinder interrupted
F4:     Servo cylinder regulation defect
F5:     Sealing betweencylinder pistons and cylinder wall leaks
Fig. 3.7 Interrelation between the FMEA table and the speciﬁcation of the failure
propagation

3 Methods of Improving the Dependability of Self-optimizing Systems
45
system element, the relationship between incoming, local and outgoing failures
is described. Figure 3.7 depicts the interrelation between both failure representa-
tions. The failure cause servo cylinder regulation does not provide desired position
of valve switch from the FMEA table (Fig. 3.7, (1)) corresponds to the port state
not(ok) of the input HV1 of the system element hydraulic valve regulation. The
failure causes hydraulic valve regulation is broken (2) and energy supply of the hy-
draulic valve regulation is interrupted (3) correspond to the internal failures F1 and
F2 of the hydraulic valve regulation. The aforementioned failure causes (2) and (3)
may lead to the failure hydraulic valve regulation provides no switch position for
the 4/4-way valve (4); This failure is recorded in the FMEA table, as well as in the
speciﬁcation of the failure propagation (port state not(ok) of the output HV2 of the
hydraulic valve regulation).
According to the FMEA table, there is a causal failure relationship between the
failure hydraulic valve regulation provides no switch position for the 4/4-way valve
(4) and the failure effect valve no longer changes the pressure on the output (5).
Although both failures were speciﬁed in the failure propagation model (input WV1
of the 4/4-way valve as well as inputs HZ1 and HZ2 of the hydraulic cylinder, re-
spectively), the causal relationship between them had not been modeled; in a conse-
quence, a more thorough analysis of this causal relationship was performed. In the
course of the analysis, the respective failure propagation path was modeled, as well
as an additional failure F6 (valve position can no longer be changed mechanically;
the valve slider stays in its current position) (Fig. 3.8).
System element
CanImply relationship
Boolean operator
Failure
Servo cylinder
4/4-way valve
Hydraulic valve 
regulation
Servo-cylinder
regulation
X*Ventil
Hydraulic cylinder
XVentil
YVentil
Hydr.conn 2
X*Cylinder
XCylinder
F2
F1
OR
F6
OR
F4
F3
OR
F1:
Hydraulic valve regulation error
F2:
Energy supply of hydraulic valve regulation interrupted
F3:
Energy supply of regulation servo cylinder interrupted
F4:
Servo cylinder regulation error
 
F5:
Sealing between cylinder piston and cylinder wall leaks
F6:
Valve position can no longer be changed mechanically;
valve slider stays in its current position
HV1
HV2
WV1
WV2
WV3
SV1
HZ3
HZ1
F5
Actuating
power
cylinder A 
Port state
OR
not (ok)
not (ok)
not (ok)
not (ok)
not (ok)
not (ok)
not (ok)
not (ok)
Hydr.conn 1
not (ok)
Legend
Additional failure 
propagation path 
and additional 
failure (F6).
Fig. 3.8 The extended failure propagation speciﬁcation of the servo cylinder

46
R. Dorociak and J. Gausemeier
Fig. 3.9 Excerpt from the
translation dictionary [38]
System element SE
AND
B
A
not (ok)
ok
O1
O1.not (ok)
A
B
0
0
1
1
0
1
0
1
0
0
0
1
Pr O1.not (ok) │⌐A, ⌐B, ) = 0
Pr O1.not (ok) │⌐A, B, ) = 0
Pr O1.not (ok) │A, ⌐B, ) = 0
Pr O1.not (ok) │A, B, ) = 0
A
B
O1.
not(ok)
System
element
Boolean
gate
Failure
State
tuple
CanImply
relationship
Node of the
Bayesian network
Legend
The speciﬁcation of the failure propagation is translated into a Bayesian network.
The translation algorithm proceeds as follows: for each system element, its internal
failures and port states of its inputs and outputs are translated into nodes of the
Bayesian network. The relationships between them are represented as edges in the
Bayesian network. The Conditional Probability Table (CPT) of the Bayesian net-
work is then populated: for each value of variables associated with a node or a node
state, its conditional probabilities are described with respect to each combination of
values associated with variables of the parent nodes in the network. To support the
translation, a dictionary of translation rules has been developed [38].
Figure 3.9 shows the translation rule for the AND gate with two internal fail-
ures A and B and the outgoing failure "O1.not(ok)". The corresponding probability
table of the AND gate is also shown. The failures are translated into nodes of the
Bayesian network. The edges of the Bayesian network correspond to the "canImply"
relationships modeled in the speciﬁcation of the system element SE: nodes A and
B representing the internal failures are parents of the outgoing failure "O1.not(ok)".
An excerpt of the CPT for node "O1.not(ok)" is shown. It corresponds to the respec-
tive probability table of the AND gate. The translation rules for other Boolean gates
are analogue. For other examples of translation rules and a more detailed description
of the respective translation algorithm, please refer to [38].
The result is a comprehensive Bayesian network which describes the part of the
system that is relevant for the examination of the chosen top event. Based on the
Bayesian network representation, some further analyses are performed [89]. In par-
ticular, the Fussell-Vesely importance measure is computed, i.e. it is determined
with what probability a particular system element (failure cause) had led to a par-
ticular failure (the so-called posterior probability). The top event that we examine
is valve no longer changes the pressure on the output (corresponds to the port state
WV2.not(ok)). Let us consider the state of the failure speciﬁcation before the addi-
tional failure F6 and the corresponding propagation path were incorporated into the

3 Methods of Improving the Dependability of Self-optimizing Systems
47
Table 3.1 Failures, the failure rates and the Fussell-Vesely importance measure (before and
after the failure speciﬁcation had been extended) (Top-Event is WV2.not(ok))
Failure
Failure rate (per hour)
Fussel-Vesely
importance (before)
Fussel-Vesely
importance (after)
F1
5.11 × 10−7
0.2897
0.2416
F2
4.02 × 10−7
0.2279
0.1901
F3
3.28 × 10−7
0.1859
0.1551
F4
5.23 × 10−7
0.2965
0.2473
F6
3.51 × 10−7
N/A
0.1660
speciﬁcation. The failure rates of the failures are shown in Tab. 3.1. We will further
assume that the output WV2 of system element hydraulic valve regulation is in state
not(ok), as this is our top event. According to the speciﬁcation of the failure propa-
gation (Fig. 3.6) failures F1, F2, F3 and F4 all contribute to this. Table 3.1 reports
Fussell-Vesely importance measures for each failure, i.e. the posterior probability of
the contributing failures given the occurrence of the aforementioned failure. Failures
F1 and F4 are especially important, with importance greater than 28 %.
Now let us consider the extended speciﬁcation of the failure propagation (includ-
ing failure F6). The failure rate of failure F6 and the respective importance measures
are shown in Tab. 3.1. The failures F1, F2, and F4 are of highest importance with
importance with an approximately 25 %.
By using our method, the completeness of the failure speciﬁcation has been im-
proved. In particular, failures and failure relationships were identiﬁed that could eas-
ily have been omitted otherwise. In particular, the failure F6 has been identiﬁed, the
importance of which is quite high (approximately 17 %). Based on the failure spec-
iﬁcation, further analyses are conducted. Counter and detection measures are then
derived and, if possible, implemented directly in the Principle Solution. Altogether,
the system under consideration is made more reliable at an early development stage.
3.1.2
Early Design of the Multi-Level Dependability Concept
Rafal Dorociak, Jürgen Gausemeier, Tobias Meyer, Walter Sextro,
and Christoph Sondermann-Woelke
The Multi-Level Dependability Concept (M-LD Concept) is an approach for im-
proving the dependability, speciﬁcally the attributes reliability, safety and availabil-
ity, of a self-optimizing system by using self-optimization. It is advantageous to
develop the M-LD Concept within a single task once the Principle Solution has
been fully speciﬁed and before the domain-speciﬁc phase begins.
To this end, this method has been developed, which allows a structured setup
of the M-LD Concept based on the Principle Solution. It is a modiﬁcation and an
expansion of the procedure described in ISO 17359 [1,140]. Since it is a multidisci-
plinary approach, information from several partial models (Active Structure, System

48
R. Dorociak et al.
of Objectives, Behavior, Functions, Environment and Application Scenarios) is re-
quired to best use the full potential of a self-optimizing system.
3.1.2.1
Prerequisites and Input
Since changes in late development phases usually come at great expense, it is advan-
tageous to develop and insert the M-LD Concept into as early a development phase
as possible. To do so, information from the Principle Solution is required; therefore,
the system needs to be completely speciﬁed by a Principle Solution according to D.
M.f.I.T.S, [55], Sect. 4.1.
Additionally, the system’s information processing must be set up as an Operator
Controller Module (see also Sect. 1.1.1) in order to be able to carry out the inter-
actions between M-LD Concept and the system itself. The OCM already contains
a preliminary Conﬁguration Control, which can be improved using this method. In
order to adapt the system behavior, multiobjective optimization must be feasible and
it must be possible to implement additional objective functions, as will be discussed
in Sect. 3.2.1.
To obtain information about the system itself, an FMEA (see also [73]) is re-
quired, which can be conducted according to the method Early Probabilistic Anal-
ysis of an Advanced Mechatronic Systems based on its Principle Solution, see
Sect. 3.1.1. Since this method requires the Principle Solution as well, it does not
pose further challenges.
3.1.2.2
Description
The basic approach is outlined in Figure 3.10. As shown, there are ﬁve phases with
corresponding milestones which will be explained in detail. Phases and steps are not
to be seen as a sequence; the procedure is characterized by a number of iterations,
which are not depicted.
Step 1: System Analysis
The system analysis is conducted in three steps: analysis of the current system de-
sign, determination of the relevant system’s objectives, and identiﬁcation of possi-
bilities of adapting the system behavior during operation. The required pieces of
information and the relations between them have already been in the Principle Solu-
tion, so it is natural to use the partial models Active Structure, System of Objectives
and Behavior for this analysis.
For the ﬁrst step of the system analysis, the partial model Active Structure is
used. It describes the system elements chosen to fulﬁll the required functions of the
system. To obtain an overview of the system’s capability to monitor its momentary
state, a list of all sensors and the corresponding measurement points is generated by
the program Mechatronic Modeller, which is used to model the Principle Solution.
In the second step of the system analysis, the objectives that are relevant with
regard to the dependability of the system are identiﬁed. The objectives regarding

3 Methods of Improving the Dependability of Self-optimizing Systems
49
Phases/Milestones
Results
System analysis
 
 
2
Dependability analysis
Select measurement
method
Design of the Multi-Level
Dependability Concept
 
Design or extend 
Configuration Control
1
3
4
5
 
• Dependability objectives and
  corresponding sensors
• Dependability-related behavior 
  specification
• System elements to monitor
• Potential safe-guarding measures
• Fall-safe state definition
• Estimation procedure for the
  determination of the RUL
• Transitioncritera
• Extended partial model group
  Behavior
   • Evaluation of sensor signals
   • Feedback to the self- 
     optimization process  
• Extended partial model group
  Behavior containing the
  specification of the Configuration
  Control
Active Structure
Controller
Working-
point
Control
Drive
Module1
Drive
Module2
V
F*
Serial 
Interface
System of Objectives
Z7
Z7.1
Z7.2
Z8
Z8.3
Z8.2
Z9.1
Z9.2
Z9.4
Z9.5
max.
max.
Abrasion
Maintenance
Interval
min.
min.
min.
max.
External System of Objectives
Internal system of objectives
Shuttle (cut-out)
Shuttle (Cut-out)
Internal System of 
Objectives Shuttle (Cut-out)
Targets of 
the Cluster
Safety/
Reliability
Lateral 
Acceleration
Costs
Behavior
FSky
   FSky=dS*Vabs
!?
ds Adjustable
with s.o.
S2
Calculate 
Damping 
Interaction
Calculate 
Speed
kyhook
VSky
y
y
z2
z2
z1
Measured 
Value
z1
Measured 
Value
Measured 
Value
y
z
z
Functions
...
Adjust Air 
Gap
Determine
Control Input
Optimize
Control Input
Determine
Influences
Active Structure
In-
put
Controller
Working-
point
Control
Drive
Module1
Drive
Module2
V
F*
Serial 
Interface Environment
1
1
3
1
1..2
0..10
1
*
*
influences
influences
*
*
1
..
*
uses
transports
controls
connects
connects
bursts open
feeds and
conducts
User
influences
influences
bursts 
open
Environ-
ment
Trace-
segment
RailCab
Switch
Application Scenarios
Knowledge
Base
Track-
section x
Track-
section y
Knowledge
Base
Fig. 3.10 Procedure for the design of the Multi-Level Dependability Concept; information
contained in the partial models of the Principle Solution serves as input, as depicted by the
partial models in the left column
dependability, e.g. “Maximize reliability”, “Minimize down-time”, “Minimize
wear”, which are inﬂuenced later on by the M-LD Concept, are extracted from the
partial model System of Objectives. In most cases, these objectives are not as ob-
vious as stated above; thus, the relevance of each objective concerning reliability
needs to be evaluated. Afterwards, the previous list of sensors is examined in light
of the dependability-oriented objectives to determine which sensors are to be used
to determine the current system state and how they should be classiﬁed in the M-LD
Concept.
The third step is to identify possibilities of inﬂuencing the system behavior. The
relevant partial model group Behavior illustrates the different system states and re-
conﬁguration options. These states and reconﬁguration options will be part of the
Conﬁguration Control, which is designed to switch to the desired control strategy.
The behavior speciﬁcations that support dependability-oriented actions will be used
during Step 5.

50
R. Dorociak et al.
Step 2: Dependability Analysis
The second step – the dependability analysis – is primarily conducted on the par-
tial models Functions and Active Structure. Usually, the established reliability en-
gineering method of Failure Mode and Effects Analysis (FMEA) is used. In order
to conduct the FMEA, the system elements of the Active Structure are exported to
a FMEA tool [39]. This procedure is supported by the program Mechatronic Mod-
eller, as it is capable of exporting the Active Structure model. Based on this data, the
failure modes and counter-measures are determined together among the engineers
developing the system. Not only effects inherent in the system, but also effects from
the surrounding environment could be a reason for failures. The partial models Ap-
plication Scenarios and Environment are used for the process of identifying these
inﬂuences.
For the design of the M-LD Concept, several results from the FMEA are impor-
tant. Firstly, the failure modes point out which system elements are subject to wear
and fatigue failures. These system elements are primary candidates for condition
monitoring in combination with an estimation of the remaining life time. The risk
priority number obtained from the FMEA is crucial for the decision of which system
elements to monitor. If a critical system element’s failure mode is not related to an
objective of the system, an additional corresponding objective must be added to the
System of Objectives. Furthermore, counter-measures also indicate which system
elements are of special interest due to the fact that a failure would lead to low avail-
ability or even severe damage. The counter-measure list also shows failures which
lead to a state in which operation of the system is still safe, thus forming the fail-
safe state, which has to be deﬁned for any self-optimizing system. Finally, failures
of those system elements which have a negative inﬂuence on the dependability-
oriented objectives are identiﬁed. For these, safeguarding against failures, e.g. re-
dundancy, might be required [75]. If safeguards are used, the Principle Solution has
to be updated accordingly.
Step 3: Select Measurement Method
In the system and dependability analysis, sensors for monitoring the dependability-
related objectives as well as critical system elements are identiﬁed. Based on this
information, the dependability-oriented objectives are related to quantiﬁable general
measures, such as the remaining useful life (RUL) or the current failure probability
of the system. These general quantities simplify the comparison between different
system elements and subordinated system elements. The estimation of the RUL can
be based on model-based approaches in which the actual load of the system elements
is compared to the maximally tolerable load. In combination with damage accumu-
lation hypotheses, e.g. Palmgren-Miner [103], the RUL can then be estimated. If
desired, the failure probability of the system elements is also calculated using the
corresponding distribution functions.

3 Methods of Improving the Dependability of Self-optimizing Systems
51
Step 4: Design of the Multi-Level Dependability Concept
The M-LD Concept is intended to inﬂuence system behavior; for this, an evaluation
of the current system state and feedback to the system is needed. The system behav-
ior can be inﬂuenced in two ways: by adapting the prioritization of the objectives of
the system and/or by switching between different control strategies.
To determine whether the objectives need to be adapted, thresholds between four
levels, based on the RUL or other general criteria, as selected in Step 3, need to
be deﬁned. For this, the safety requirements of the module have to be taken into
account. As will be explained in Sect. 3.2.1, the dependability-oriented objectives,
which support different attributes of the dependability such as reliability, availabil-
ity, and safety (cf. [11]), are adapted if the second level is reached. Should the third
level be reached, the objectives for safety must have absolute priority. In both cases,
the system is inﬂuenced later on by an increase in priority of the dependability-
related objective, which leads to more dependable operation. In order to increase
the priority, a suitable ﬁxed value for the priority or a strategy to increase it has
to be implemented in the Cognitive Operator. Both evaluation of the sensor signals
and feedback to the optimization process are integrated into the partial model group
Behavior.
If a failure requires a switching action, this is set into motion by the Conﬁguration
Control; how exactly to implement this is explained in Step 5. The fourth level
corresponds to the fail-safe state determined in the dependability analysis. If it is
reached, emergency routines are engaged.
Step 5: Design or Expand Conﬁguration Control
Certain failures (identiﬁed by the FMEA) could lead to a switch in control strategy,
e.g. if a required sensor fails and redundancy controls require the system to switch
to another sensor signal. This reconﬁguration is conducted by the Conﬁguration
Control, which is embedded into the Reﬂective Operator. For the reconﬁguration,
different control strategies are designed. If switching actions are necessary, they
have to be included in the Conﬁguration Control. Since switching actions have to
be initiated quickly, the required failure detection methods are implemented in the
Conﬁguration Control as well. The preliminary Conﬁguration Control included in
the partial model group Behavior is expanded to include dependability aspects.
3.1.2.3
Results
The M-LD Concept is fully speciﬁed and its components are embedded into the cor-
responding partial models of the Principle Solution. These components are both new
system elements, i.e. hardware, as well as additional components in the information
processing, which are mainly embedded into the Reﬂective Operator in the Operator
Controller Module. The determination of the current system state, its classiﬁcation
according to the four levels and the initiation of the corresponding counter-measures
are included in the partial model group Behavior. The Conﬁguration Control is

52
R. Dorociak et al.
expanded or initially designed using this method and new dependability-related ob-
jectives are included in the multiobjective optimization.
3.1.2.4
Application Example
As a demonstrator for this method, the Active Guidance Module (see also Sect. 1.3)
has been selected. It is a key element of a RailCab and, as such, needs to function de-
pendably. To ensure this, the M-LD Concept has been implemented. The execution
of the ﬁve main steps to design the M-LD Concept, as described in Sect. 3.1.2.2, is
explained in the following.
Step 1: System Analysis
To analyze the current situation, the Active Guidance Module is equipped with sev-
eral sensors. One incremental sensor at each wheel determines the longitudinal po-
sition of the RailCab. Since a drift of the incremental sensor’s signal is unavoidable,
the longitudinal position is regularly corrected by a proximity switch which passes
over a reference plate. Furthermore, eddy-current sensors on each side of each wheel
are used to measure the current lateral position as the deviation from the center line
within the track, as well as the current clearance which could be used for optimiza-
tion of the trajectory within the track limits. Two acceleration sensors and a yaw
rate sensor are integrated into the construction in order to obtain further informa-
tion about the RailCab movements. A displacement sensor is integrated into the
hydraulic steering actuator.
The Active Guidance Module uses multiobjective optimization for the steering
control strategy. The qualitative representation of the optimization objectives are
given in the partial model System of Objectives; an extract is depicted in Fig. 3.11.
The main goal is to steer within the track clearance while neither having ﬂange
contacts nor wasting energy on unnecessary steering actuator movements. At the
same time, lateral acceleration has to be kept low to ensure passenger comfort and
to be sure a certain safety margin is upheld [56].
The main dependability issue is the minimization of ﬂange contacts in order to
increase the reliability and thus the availability of the RailCab. Another objective
is to minimize the wear of the hydraulic actuator. This is similar to the objectives
“Maximize comfort” and “Minimize energy consumption”, since all three lead to
minimal actuator movements. For this reason, no additional objective is required.
The conﬁguration control in the Active Guidance Module used for this example
comprises several control strategies. The most advanced strategy uses the optimiza-
tion described above and both a feedforward controller as well as a feedback con-
troller. If no optimization is available, the trajectory generated for the feedforward
controller is oriented towards the center line between the rails. If the eddy-current
sensors fail, and with these the determination of the lateral position, the feedforward
control can still be used to keep the vehicle on the center of the track. If all systems
fail, the steering will become stuck, which leads to rapid wear on the ﬂanges. In this
case, the mechanical guidance wheels are activated and the vehicle is slowed.

3 Methods of Improving the Dependability of Self-optimizing Systems
53
Fig. 3.11 System of Objec-
tives of the Active Guidance
Module (excerpt)
Z2
Wear
min.
Z3
Comfort
max.
Z3.1
Lateral 
acceleration
min.
Z4.1
Safety margin
for steering
max.
Z1.1
Movement of
hydraulic 
actuator
min.
Z2.1
Probability of 
flange contacts
min.
Z4
Quality of
control
max.
Z1
Energy
consumption
min.
Step 2: Dependability Analysis
For the active guidance module, the system elements to be monitored are the wheels,
since the rolling contact leads to wear. Besides the continuous wear due to the un-
avoidable motion between wheel and rail, ﬂange contacts increase wear consider-
ably. This is represented in the objective “Minimize probability of ﬂange contacts”.
These contacts cannot be avoided completely, since steering along energy-efﬁcient
trajectories requires reducing the safety margin as much as possible, making ﬂange
contacts highly probable if unexpected disturbances are encountered.
By taking the Application Scenarios into account, it becomes obvious that severe
accidents could occur while going over passive switches. Therefore, two different
counter-measures are integrated into the partial model Behavior. The ﬁrst counter-
measure is the fail-safe state. In this state, the steering axle is ﬁxed, if possible in
center position; the velocity of the RailCab is reduced; and mechanical guidance
wheels for going over passive switches are engaged. The second counter-measure is
to safeguard the eddy-current sensors.
Step 3: Select Measurement Method
To determine the wear of the wheels, ﬂange contacts are registered by the eddy-
current sensors and the distance travelled is monitored via the incremental sensors.
The maximum running length of the ﬂanges in contact is compared to this value to
obtain the RUL. The wear of the actuator is assumed to be proportional to its total
distance travelled, which is calculated using the displacement sensor integrated into
the actuator.

54
R. Dorociak et al.
Step 4: Design of the Multi-Level Dependability Concept
In the ﬁrst level of the multi-level dependability concept, the self-optimization pro-
cess is able to choose from all objectives without any constraints. The second level
is reached if the monitored parameter, in this case the rate of reduction of the RUL
of the wheel due to wear, rises above a certain threshold which has been previously
deﬁned by an expert. If one of the eddy-current sensors fails, redundancy is lost,
and this failure is also classiﬁed as level 2 since an error has occurred. However,
self-optimization can be used to ensure dependable operation. In order to increase
the reliability, the objective “Minimize probability of ﬂange contacts” receives a
higher priority. The third level is reached when the loss about the lateral position is
detected. It is now of paramount importance to minimize the probability of ﬂange
contacts, which leads to a feedforward trajectory following the center line of the
track. The fail-safe state “axle ﬁxed and mechanical guidance activated” is activated
if the loss of the longitudinal position data is ascertained. Purely closed loop control
is not possible, since passive switches would then lead to a derailment.
The partial model group Behavior is extended to include the evaluation of the
sensor signals, as described in Sect. 3.1.2.4, in addition to all required switching
actions or adaptations of the objectives.
Step 5: Design or Expand Conﬁguration Control
For the Active Guidance Module, switching is required if one of the redundant eddy-
current sensors fails. If this is the case, the failed sensor’s signal has to be neglected,
requiring a switch to a different sensor evaluation algorithm and possibly to another
control strategy. Both the detection of the failure as well as the switching process
are embedded within the Conﬁguration Control.
The ﬁnal Conﬁguration Control is based on a preliminary Conﬁguration Con-
trol, which is already in place for general steering purposes. The additional actions
expand the partial model group Behavior.
When all required components have been included in the Principle Solution, the
design of the Multi-Level Dependability Concept is concluded.
3.2
Design and Development
In the phase Design and Development, particular emphasis is laid on software. Self-
optimizing mechatronic systems contain discrete software as well as continuous
software. Continuous software is used in control engineering, discrete software in
software engineering. We use a component-based approach to develop the systems;
the component structure is derived from the Active Structure of the Principle Solu-
tion and provides the basis for the methods presented below.

3 Methods of Improving the Dependability of Self-optimizing Systems
55
3.2.1
Increasing the Dependability of Self-optimizing Systems
during Operation Using the Multi-Level Dependability
Concept
Jan Henning Keßler, Tobias Meyer, Walter Sextro, Christoph Sondermann-Woelke,
and Ansgar Trächtler
Self-optimizing systems offer the possibility of enhancing system dependability by
adapting the system behavior to the current level of deterioration. An adaptation of
the system behavior can be used to reduce the loads on individual system compo-
nents, e.g. actuators, in order to make them less prone to failure. As this can be car-
ried out during operation, a signiﬁcant increase in reliability and usable lifetime or a
limitation of the risk during operation can be achieved, thus improving the attributes
reliability and availability or safety. However, implementing the necessary behav-
ioral adaptation is challenging. The concept introduced in the previous section, the
M-LD Concept, can be used to overcome these challenges and adjust system behav-
ior during operation by applying self-optimization speciﬁc counter-measures, such
as an adaptation of the objectives of the system, which are included in the partial
model System of Objectives, and system reconﬁguration.
3.2.1.1
Prerequisites and Input
The M-LD Concept has been developed to inﬂuence the behavior of a self-optimiz-
ing system during operation. To this end, it uses self-optimization as a tool to adapt
objectives and to initiate switching actions, e.g. to switch between different con-
troller conﬁgurations. The M-LD Concept is designed for the Operator Controller
Module information processing architecture, see also Sect. 1.1.1, and has to be em-
bedded into the Reﬂective Operator. As part of the Reﬂective Operator, the M-LD
Concept can inﬂuence Self-Optimization on the Cognitive Operator level and also
initiate switching actions by interacting directly with the Conﬁguration Control.
For the framework of the M-LD Concept, model-based self-optimization is used.
It is based on multiobjective optimization for calculating optimal system conﬁg-
urations, which consist of certain parameters that set the working point (see also
Sect. 3.2.11). In order to use multiobjective optimization, a model of the dynamical
behavior of the system is required, which can be gleaned from the partial models
Environment, Application Scenarios and Active Structure. To adapt the system be-
havior, debendability-related objective functions, which are included in the partial
model System of Objectives, need to be incoporated into the multiobjective opti-
mization. These have to be deﬁned so that their prioritization results in more de-
pendable system behavior.
3.2.1.2
Description
The M-LD Concept can be developed and included in a self-optimizing system
to increase the dependability of the system. It contains four hierarchically ordered

56
J.H. Keßler et al.
levels for the characterization of the deterioration of the system (see Fig. 3.12) and
is part of the Reﬂective Operator.
For each level, certain counter-measures affecting the system behavior have to be
deﬁned. To adapt the system’s behavior using self-optimization, the priority rank-
ings of the system’s objectives are modiﬁed. The objectives in turn inﬂuence the
behavior and thus the dependability of the system. The levels of the dependability
concept and the resulting change of the system behavior are as follows:
Level I:
The system operates dependably. Dependability is one objective among others;
no counter-measures are required.
Level II:
A minor error has occurred. Self-optimization is used to ensure dependable op-
eration. The priority of the dependability objective affected by the error is in-
creased, altering the system behavior. If the priority of a dependability-related
objective is increased, the system behavior becomes more dependable, but at the
same time other objectives must be subordinated.
Level III:
A severe error has occurred, but the system can still be controlled. First emer-
gency mechanisms are triggered to achieve a safer state. Of all the objectives,
those objectives that lead to safe behavior become the primary objectives in or-
der to avoid the failure of the whole system and the consequences involved. If
there are separate objectives, the other attributes of dependability (e.g. reliabil-
ity, availability) may occur as secondary objectives after those that are important
to ensure safe operation. It is also possible for the concept to execute switching
actions, e.g. to deactive failed system components.
Level IV:
Control over the system is lost. Emergency routines are executed to reach a pre-
deﬁned fail-safe state.
Fig. 3.12 The four levels
of the Multi-Level Depend-
ability Concept
Reflective Operator
Sole objective
“Safety”
Achievement
of safe-states
Partial objective
“Dependability”
Objectives of
Self-optimization
Level I
- Safe and optimal
- Utilization of Self-optimization
- No restrictions or defaults
Level II
- Safe, but tendency towards “unsafe”
- Utilization of Self-optimization to
optimize dependability
Level III
- Critical state
- First emergency measures
Level IV
- Potential accident
- Safe due to emergency
measures

3 Methods of Improving the Dependability of Self-optimizing Systems
57
As a component of the Reﬂective Operator, the concept is both able to get sen-
sor information from the Controller layer of the Operator Controller Module and
to communicate directly with the Cognitive Operator to inﬂuence the optimization
process of the system. Situated in the Reﬂective Operator, the concept is also able
to initiate switching operations between different control strategies via the Conﬁg-
uration Control.
3.2.1.3
Results
The M-LD Concept is set up to increase the dependability of a self-optimizing sys-
tem during operation. Additional components, which allow a classiﬁcation of the
current system deterioration into four levels, are added to the Reﬂective Operator.
According to these levels, counter-measures are initiated. These are either an adap-
tation of the system behavior via self-optimization, i.e. an adaptation of the priorities
of the objectives to suit the current situation, or switching to a different controller
strategy.
3.2.1.4
Application Example
To show the interaction of the M-LD Concept with the other components of the sys-
tem, the Active Suspension Module (see also Sect. 1.3) is used as an example. The
purpose of this module is to generate additional damping forces between the chas-
sis and the body to actively control body motion. It consists of several major parts:
A body framework, which represents the vehicle’s body mass, and two actuator
modules, each with one glass-ﬁber-reinforced plastic-spring (GRP-spring) mounted
symmetrically beneath. The GRP-springs are connected via sophisticated nonlinear
guiding kinematics to the coach body and, at the lower end, rest on the excitation
unit representing the vehicle’s axle, where three hydraulic cylinders actively dis-
place each spring base. With its six actuators and three degrees of freedom in verti-
cal, horizontal and rotational direction, the actuated system is over-determined. The
actuator redundancy is an important feature in increasing the system’s dependabil-
ity. However, due to the nonlinear kinematics, control reconﬁguration is required in
case of faults.
The main failure mode is a fault in one or more of the six hydraulic actuator mod-
ules, which each consist of one servo valve and the corresponding linear actuator,
that inhibits oil ﬂow in the affected system. As a result, the corresponding actuator
becomes stuck. To be able to continue controlling the body motions in case of such
a fault, redundancy had to be implemented.
The four levels of the M-LD Concept are described in detail as part of the design
process. Level I, being the nominal case, does not require any further action. Level
II is reached when the estimated remaining useful life of the actuators falls below
a pre-deﬁned threshold. To be able to use self-optimization to increase the depend-
ability, an objective corresponding to the actuators’ state of deterioration needs to
be deﬁned. If the remaining useful life of one of the actuators becomes critically
low, Level III is reached. To avoid the system becoming uncontrollable, the critical

58
J.H. Keßler et al.
actuator is deliberately deactivated at this stage, whereby its function is compen-
sated by the remaining actuators. However, the potential of the parallel redundancy
given by the six actuators cannot be used with a conventional controller design, since
a conventional controller would not be able to handle the change in system behavior
and would thus become unstable. In order to maintain desired system behavior in
case of actuator failures, control reconﬁguration is used. Level IV corresponds to
the fail-safe-state and is reached if more actuators fail than can be compensated for.
In this case, the active suspension system is shut down and, to prevent dangerously
high excitations, the vehicle’s drive system is restricted to a low speed.
During normal usage, i.e. if the current system state is classiﬁed as Lvel I of the
M-LD Concept, the active suspension system pursues two main objectives: on one
hand, the energy consumption of the Active Suspension should be minimized, and
on the other hand, passenger comfort should be maximized. This is achieved by
minimizing the discomfort, which corresponds to vertical and lateral accelerations
of the body [71]. These two objectives conﬂict, as a reduction in body accelerations
results in a higher energy consumption. The corresponding objective functions are:
f1,E = 1
T ·
 T
0
6
∑
j=1
Phyd,j (τ)dτ,
(3.1)
f2,comf = 1
T ·
 T
0
2
∑
i=1
|Wi (ai (τ))|dτ.
(3.2)
Equation 3.1 describes the average hydraulic power of the six actuators Phyd,j;
Eqn. 3.2 describes the comfort with reference to the weighted body accelerations
ai. The accelerations are weighted according to [148] to represent the subjective
perception of a passenger.
If individual actuators show signs of wear that cannot be tolerated at the current
operating time, Level II is reached and the self-optimization procedure chooses a
new Pareto optimal point, which focuses on a higher dependability, as explained in
Sect. 3.2.11. This requires a third objective taking dependability into account, called
"minimize undependability". For the given system, this objective needs to relate the
current controller conﬁguration to the resulting deterioration of the hydraulic valve,
taking the characteristics of hydraulic valve deterioration into account. In order to
reduce the rate at which the actuators deteriorate, this objective is prioritized over
the others. However, if the rate cannot be reduced sufﬁciently using the results of
the multiobjective optimization, the least reliable hydraulic cylinders have to be shut
off. This leads to a change of the structure and the dynamic behavior of the system
and usually to an unstable behavior of the closed-loop system if using the standard
control structure. Control reconﬁguration is used to keep the system operational by
taking advantage of the redundancy and using the remaining ﬁve cylinders.
In order to adapt the system behavior, the objective "minimize undependability"
has to be deﬁned and integrated into the optimization problem. It has to take the
mean amount of motion of all actuators into consideration as well as considering
the possibility of an uneven load on the actuators which could lead to premature

3 Methods of Improving the Dependability of Self-optimizing Systems
59
failure of individual actuators. A prioritization of the objective corresponding to
this function has to lead to less motion of the actuators, which increases their de-
pendability. Unfortunately, at the same time other system objectives are decreased,
such as high passenger comfort or low energy consumption. During operation, the
three objectives can be inﬂuenced by a variation of the controller parameters. The
optimization parameters are the three Sky-Hook controller parameters in vertical,
horizontal and rotational direction.
The main cause of hydraulic actuator failures is due to wear [127]. When in
motion, the oil ﬂow passes through the valve, leading to residue build up [112].
Since the system behavior is highly dynamic during normal operation, the valves are
also subject to thermal strain due to dissipated electrical energy. This heating effect
in turn inﬂuences the residue buildup and increases the probability of failures due
to varnish. In order to increase the dependability of the valves, both the dissipated
energy as well as the valve motion have to be minimized. However, if the valve were
to be simply shut down and left at rest, the possibility of the valve becoming stuck
permanently would rise unacceptably [111].
All these effects of hydraulic valve deterioration correspond to either the oil ﬂow,
which depends on the position of the spool, or the electric energy dissipated in
the coil of the valve, which corresponds to the position and velocity of the spool.
The position of the spool corresponds to the potential energy EP,j (t) stored in the
valve spool return spring (stiffness cv) while the spool velocity corresponds to the
kinetic energy EK,j (t) stored in the spool (moving mass mv). To include all effects
of hydraulic valve deterioration, the kinetic and potential energy of the jth valve are
weighted separately using a weighting function Wj (EP,j,EK,j):
Wj (EP,j,EK,j) = a(d + EP,j)−b +
1
c(e+ EK,j)(d + EP,j).
The function has been parameterized to give the desired properties (a = 10/9,
b = 19/81, c = 2916000/361,d = 1/180, e = 1/100). If the valve is open (EP,j ̸= 0),
thus leading to oil ﬂow and actuator motion, the value of the weighting function
rises almost linearly with the potential Energy EP,j. If the valve is at rest (EP,j = 0,
EK,j = 0), a ﬁnite result Wj = 2 is obtained, thus penalizing very low valve motions.
The potential and the kinetic energy are given by:
EP,j (t) = 1
2 ·cv ·xj (t)2 ,
EK,j (t) = 1
2 ·mv ·vj (t)2 .
To obtain the spool’s position xj (t) and velocity vj (t), an observer is used for the
valve.
The signal is then averaged for one full simulation run ending at time T:
Wa,j = 1
T ·
 T
0 Wj (EP,j (τ),EK,j (τ))dτ.

60
J.H. Keßler et al.
Fig. 3.13 Objectives in the
nominal case (light gray)
and objectives of the recon-
ﬁgured system (black). The
three objectives depicted
here are: f1,E: required
power; f2,com f : passenger
discomfort; f3,dep,nom/rec:
undependability in the nom-
inal and in the reconﬁgured
case.
0
20
40
2
4
6
0
1
2
3
f1,E
f2,comf
f3,dep,nom, f3,dep,rec
The ﬁnal dependability value for the nominal case is calculated assuming that the
actuator’s signals are normally distributed and by calculating mean μ and standard
deviation σ:
f3,dep,nom = μ

pμ ·

Wavg,1,...,Wavg,6

+ σ

pσ ·

Wavg,1,...,Wavg,6

The weighting factors pμ and pσ have been parameterized empirically [101].
When the system is classiﬁed as Level II, the results of the optimization with
the additional objective "minimize undependability" are used to inﬂuence the sys-
tem behavior. The objectives are depicted in Fig. 3.13 (light gray). The shape of
the Pareto optimal points is restricted almost entirely to a one-dimensional line.
An optimal parameter set of the Sky-Hook controllers pertains to each point. The
original behavior regarding the two objectives "minimize energy" and "minimize
discomfort" is maintained as expected. The objective "minimize undependability"
is plotted on the Z-axis. Note that f3,dep depends on the system state, giving rise
to two individual functions: f3,dep,nom for the nominal case with six actuators and
f3,dep,rec for the reconﬁgured case with less than six actuators. It is obvious that the
two objective functions "minimize energy" and "minimize undependability" are in
the same direction over a wide range. The more energy consumed by displacing the
hydraulic cylinders, the less dependable the system is. At the other end of the curve,
the opposite effect occurs. With less cylinder motion, the probability rises that the
valve will become stuck. To obtain dependability-optimal operation, which corre-
sponds to f3 "minimize undependability" being minimal, it is necessary to use small
actuator motions with low dynamics without bringing the actuators to a stop.
In the case of falling below a certain threshold of remaining useful life, the system
deterioration state is classiﬁed as Level III. As a result, the vulnerable actuator is
shut down and the control of the remaining actuators has to be reconﬁgured to take

3 Methods of Improving the Dependability of Self-optimizing Systems
61
the altered system structure into account. Depending on the position of the actuators,
up to three actuators can be shut down.
Many approaches have been developed for the reconﬁguration of an entire control
system. In our work, a method based on the system description with a linear state
space equation is applied to reconﬁgure the system [22] . This linear control recon-
ﬁguration method was originally developed for systems subject to actuator failures;
nevertheless, it can be used for an intended actuator shutdown as well. A reconﬁgu-
ration block is integrated between the altered system and the nominal controller. It
modiﬁes the control inputs of the remaining actuators and thus compensates for the
effects of the deactivated actuator on the dynamical behavior. The main advantage
of this method is the retention of the nominal controller in the closed-loop system.
In this example, the ﬁve remaining cylinders have to perform the task of the nominal
six cylinders.
At Level III of the M-LD Concept, it is still possible to apply the aforementioned
multiobjective optimization even though the system structure has been reconﬁgured.
If, for example, only one cylinder is switched off intentionally, the three objectives
and the optimization parameters still remain, except that the vulnerable cylinder is
not taken into account while calculating the energy- and dependability-objective
functions. To achieve this, the objective "minimize undependability" is altered
accordingly.
The result of the multiobjective optimization of the reconﬁgured system with an
intended actuator shutdown is shown in Fig. 3.13 (black). The shape of the set of
the Pareto optimal points is still mostly the same as in the fully operational case.
However, for a given level of undependability, the reconﬁgured system achieves the
same level of comfort for each Pareto optimal point, with less energy consumption
than the non-reconﬁgured system.
The adaption in Level II is carried out by modifying the priority level of the
individual objectives using the set of objective functions f1, f2 and f3,nom. Since
certain damping parameters are tied to each Pareto optimal combination of the
three objectives’ priorities, the system behavior is adapted by setting the parame-
ters accordingly. An increased priority for the objective "minimize undependability"
leads to beneﬁcial system behavior. However, one of the other objectives will be
affected negatively, leading to either increased body motions or increased energy
consumption.
For Level III, an intended actuator shutdown is initiated. Upon initiation, the re-
conﬁguration block is activated in the model of the dynamical behavior and, in addi-
tion, the objective functions used for the multiobjective optimization are changed as
well. During operation, a different set of results from prior optimization calculations
is selected in order to adapt the system behavior.
3.2.1.5
Further Reading
The application example is explained in more detail in [101]. Another example of
an application of this method is shown in [82].

62
M. Krüger and A. Trächtler
Several additional methods have been developed to support the development pro-
cess. The M-LD Concept can be implemented using information that is available
during early development phases; this method is explained in detail in Sect. 3.1.2.
To determine suitable counter-measures, a close interaction with multiobjective op-
timization (see Sect. 3.2.11) is required.
3.2.2
Iterative Learning of Stochastic Disturbance Proﬁles
Martin Krüger and Ansgar Trächtler
This section deals with learning excitation data from a speciﬁc class from distur-
bances. The quality of information about the momentary situation is particularly
important in determining the success of any self-optimization strategy. Model-based
methods for estimation of system states and physical parameters have been de-
veloped and implemented and have proven to be effective for the application of
classical control techniques, e.g. [93]. A self-optimizing system, however, requires
additional information about its environment, e.g. about future excitations and dis-
turbances. With this information, it is possible to develop a system that is able to
react intelligently and results can be achieved that surpass those of classical control
strategies.
In recent research the combination of model-based disturbance observers and
iterative learning methods has proven to be effective. In [146], the RailCab, an au-
tonomously driven railway vehicle [126], serves as an application example: the rail-
track deﬂections in lateral and vertical directions were learned and later used for
disturbance compensation and self-optimization tasks.
In this section, we transfer this approach to the task of learning road distur-
bance proﬁles. In contrast to rail-track deﬂections the excitations and disturbances
of roads do not occur deterministically when driving over the same road section
several times, due to possible changes of the lateral position of the vehicle. Hence, a
purely model-based approach is no longer beneﬁcial. Instead, we use a combination
of a behavior-based model of the road excitations and a model-based disturbance
observer. These road excitations are modeled as nodes in a Bayesian network and a
method is implemented to learn both parameters and parts of the network structure.
The main idea is to use stochastic dependencies between different excitations (see
Fig. 3.14). Disturbance proﬁles can help to increase the safety of self-optimizing
systems, as they can be used for planning tasks or speciﬁc controller adaptation.
The iterative learning approach is based on the Principle Solution. Several as-
pects of the domain-spanning description are used: the partial models “Application
Scenarios” and “Environment” yield general information about disturbances and in
which situations they occur, while the partial models “Active Structure” as well as
“Environment” show how disturbances inﬂuence the system and which sensors are
available for the disturbance observer.

3 Methods of Improving the Dependability of Self-optimizing Systems
63
Fig. 3.14 Three Distur-
bances S1, S2 and S3 on
a sample road and corre-
sponding Bayesian network
y
x
S
S
S
3
2
1
P(S    S , S  )  
3
2
1
S2
S3
S1
P(S    S  ) 
2
1
P(S  )  
1
3.2.2.1
Prerequisites and Input
The presented approach is applicable to the disturbance estimation of road vehicles.
It can also be generalised to other systems with stochastically dependent occurences
of disturbances; however, we will only focus on road proﬁles at this stage.
In order to learn road proﬁles, several prerequisites have to be fulﬁlled in addition
to the above-mentioned partial models of the Principle Solution. Firstly, data about
road excitations are necessary. Mostly, the excitation cannot be measured directly,
as sensors cannot be put between the wheel and the road surface. Therefore, we
have developed a model-based disturbance observer to detect disturbances. A model
of the vehicle as well as a disturbance model, are needed to design the observer.
Additionally, sufﬁcient empirical data, such as vertical accelerations of the body
and wheel have to be available. By means of the disturbance observer, a current
road proﬁle of a particular road section can be computed based on the measured
values. This constitutes the input for the learning method. We also assume that the
current longitudinal position of the vehicle on the road is known.
3.2.2.2
Description
The developed learning method consists of three sequential steps (Fig. 3.15). To
start, the disturbances due to road unevenness have to be detected and identiﬁed
on the basis of different passages. Each disturbance is then set up as a node of
the Bayesian network. Additionally the parameters, i. e. the conditional probability
distributions for every single node, have to be acquired from the data. After compi-
lation, the Bayesian network can be used to predict disturbances during following
driving sequences over the same road section. A description of these three steps is
presented in the following section.
Construction of Bayesian network
Specifying
structure
Learning
parameters
Evaluation
of 
network
Identification 
of
disturbances
Fig. 3.15 Structure of the learning process

64
M. Krüger and A. Trächtler
Identiﬁcation of Disturbances
A disturbance is caused by unevenness in the road surface. These “defects” can be
described by a discrete surface proﬁle, which assigns a height (the position in ver-
tical direction) to each two-dimensional point on the road. Disturbances are abrupt
changes in this height, for example those caused by potholes.
Data on the disturbances on the road are acquired by means of a vertical velocity
proﬁle. In our case, it is easier to detect the velocity than the position, as an absolute
road proﬁle is hard to determine by means of acceleration-based sensor concepts.
The derivative of the position yields peaks that can be used for a precise detection
of relevant disturbances.
Due to inaccuracies in the measurements (e.g. sensor noise), both the position
and the strength of the disturbance are slightly different for every measurement;
hence, different clustering methods are used for the identiﬁcation of disturbances.
Clustering has to be employed because the total number of disturbances can only be
detected using the data from different driving sequences. Using clustering the data
can be suitably merged because it describes the combination of similar objects in
groups.
The actual position of the disturbances is determined by a hierarchical clustering
of the positions detected on different passages [4]. In this context, “hierarchical"
means that several levels of clusters are created in consecutive steps. On every hier-
archical level, the elements of the previous level with the shortest distance between
them are merged into new clusters, thus yielding a binary tree structure with the sin-
gle elements as leaves. This hierarchical clustering produces very good results for
our application, as shown in Sect. 3.2.2.4.
In the second step, the strength of each disturbance is determined by cluster-
ing with Gaussian mixture distributions [4]. This method has been applied because,
presumably, the strength of the disturbance (vertical direction) during different pas-
sages is distributed normally due to measurement errors or irregular obstacles. In
our approach, the density estimation of each expected disturbance is reduced to
the determination of the expected value and the standard deviation of the Gaussian
distribution. With the help of the Expectation-Maximization algorithm [4] a mixed
distribution can be found which best ﬁts the distribution of the disturbances, i. e. it
describes the data with a high degree of probability.
With the results of the cluster analysis, which we carried out using the methods
described, the expected disturbances and thus the nodes of the Bayesian network
can be determined, i. e. each cluster results in one node as a detected disturbance.
Construction of Bayesian Network
As a result of the clustering, the nodes of the Bayesian network are identiﬁed. In
order to determine the structure of the Bayesian network, we deﬁne the following
rules:
• The nodes have to follow each other in chronological order; otherwise a causal
relation makes no sense.

3 Methods of Improving the Dependability of Self-optimizing Systems
65
• Two disturbances located next to each other in lateral direction cannot be crossed
one after another. Therefore, no edge is allowed between such nodes.
• A stochastic dependence of nodes that lie far apart from one another is improb-
able, so there should be no edge between nodes with a distance between them
exceeding a pre-determined value.
These rules yield the complete structure of the Bayesian network.
The parameters are determined by means of the Maximum-Likelihood algorithm
on the basis of measured data. So the construction of the Bayesian network is
completed.
Evaluation of the Network
After construction, the Bayesian network can be used for predicting disturbances
during later driving sequences. On one hand, we can determine the a priori probabil-
ity, i. e. the unconditional probability, of the occurrence of every disturbance. On the
other hand, we can obtain more detailed information from an input of information,
so-called evidence, into the network. By evaluating random variables (evidence),
i. e. the information of wether single disturbances were driven over or not, we can
evaluate the conditional probability distributions by drawing conclusions within the
network, so-called inference. These calculated probabilities, along with the saved
data in the nodes, allow a prediction of the position and strength of the following
disturbances.
3.2.2.3
Results
The result of the described iterative learning method is a Bayesian network that
represents road disturbances for a particular road segment. The nodes provide infor-
mation about position and strength of the disturbances in a compact format. But the
main beneﬁt is given by evaluation of the probabilities inside the Bayesian network.
The unconditional probailities can be used to classify roads in general. In addition,
upcoming disturbances can be predicted by means of the conditional probabilities.
3.2.2.4
Application Example
The iterative learning process has been tested and validated using a simpliﬁed model
of the X-by-wire test vehicle “Chameleon" , introduced in Sect. 1.3.3. We have here
only considered the vertical dynamics. As usual, we use a quarter vehicle model be-
cause it provides the essential aspects for a ﬁrst veriﬁcation of the iterative learning
approach. This leads to the model topology presented in Fig. 3.16.
In contrast to common quarter-vehicle models, we have more than just two de-
grees of freedom, zB and zW , for the body mass and the wheel mass respectively.
Because the driving motor with its non-negligible mass is used as a mass absorber,
it must be accounted for in the model by an additional degree of freedom zD. The
elasticity between the driving motor and the wheel is modeled by a simple gen-
eralized Maxwell element representing the real elastomer mounting. The vertical

66
M. Krüger and A. Trächtler
Drive motor
Suspension motor
Acceleration sensor
Torsion bar spring
Body mass
Wheel mass
Drive
motor
Actuator
zB
u
zD
zW
zS
Fig. 3.16 Corner module of the test vehicle (left) and physical surrogate model of vertical
dynamics (right)
dynamics can be controlled by forces between the body and the wheel, which are
applied by the motor of the active suspension.
Building the simulation model now comprises two steps. Firstly, we need an ap-
propriate model of the dynamics to simulate the effects of road disturbances. Addi-
tionally, we have to design a disturbance observer to compute the input data for the
iterative learning process.
The dynamics of the system shown in Fig. 3.16 can be represented by a linear
system with seven states, i.e. x ∈R7, one control input u and one disturbance in-
put z. The model has two outputs y ∈R2 which are composed of both the wheel
and the body acceleration and conform to the real sensor concept. With matrices of
appropriate size we get the linear state-space representation
˙x = Ax+ Bu + Ez,
y = Cx+ Du + Fz.
(3.3)
The observer model will not represent the real behavior exactly. To consider this
effect in our simulations, we use parameters for generating the vehicle model that
vary slightly from the parameters used in the model of the disturbance observer.
We use a simple ﬁrst order transfer function GM to model the dynamics of the
acceleration sensors combined with an additional Gaussian noise signal. The con-
troller has been designed as an optimal Linear-Quadratic (LQ) controller [106].
The resulting simulation model with all relevant components has the structure
shown in Fig. 3.17. It can be seen that the disturbance observer has to fulﬁll two
tasks. On one hand, it has to estimate the state variables for use by the controller,
and on the other hand, it has to detect the disturbance ˆz and estimate the derivative
ˆz′ for the learning process.

3 Methods of Improving the Dependability of Self-optimizing Systems
67
Fig. 3.17 Structure of the
simulation model
Acceleration
  sensor
Disturbance
 observer
Controller
Vehicle
 model
z
y
y M
x
u
z‘
An estimation of the disturbances can be obtained by adding a disturbance model
to the standard state observer. This disturbance model is the linear model
˙xS = ASxS,
ˆz ˆz′T =
CS CZ
T xS
(3.4)
with two outputs ˆz and ˆz′. ˆz is needed by the observer itself to consider the inﬂuence
of the disturbance on the vehicle dynamics. ˆz′ can be used directly by the learning
process. The dynamics of the disturbances are characterized by additional states
xS and a disturbance dynamic matrix AS. For our example, we have chosen a two-
dimensional disturbance model and have assumed that the second derivative of the
disturbance is constant, which leads to a singular matrix AS.
The complete observer is implemented as a continuous-time Kalman ﬁlter [106].
It combines the quarter vehicle-model (Eqn. 3.3) and the disturbance dynamics in
one dynamical system
 ˙ˆx
˙xS

=

A ECS
0 AS

ˆx
xS

+

B
0

u + LS(yM −ˆy),

ˆy
ˆz′

=

C FCS
0 CZ

ˆx
xS

+

D
0

u.
(3.5)
The observer matrix LS ∈R9×2 deﬁnes the dynamics of the observer. It is com-
puted using the standard techniques for designing Kalman ﬁlters, i.e. by deﬁning
two covariance matrices describing the noise of the system and computing the op-
timal matrix LS. In our example, the covariance matrices are chosen so as to yield
best results for the estimation of ˆz′. In speciﬁc terms, this means that the variances
corresponding to xS are higher than those corresponding to the remaining ones.
For testing purposes, excitation data for the quarter-vehicle model were generated
in three steps:
• A simple road model was built, representing the road surface by a plane divided
into discrete sections. Road disturbances, such as potholes, were deﬁned by as-
signing a height value to each section. For the tests presented below, a number of
simple disturbances have been used to generate excitation data.
• In the next step, 20 straight trajectories along the road were created randomly.

68
M. Krüger and A. Trächtler
Fig. 3.18 Road with distur-
bances and three trajectories
Longitudinal position x [m]
Lateral position y [m]
20
18
16
14
12
10
8
6
4
2
0
T1
T3
T2
• The height proﬁle of the road along the trajectories deﬁnes the excitation given
as input for the vehicle model.
With these steps, road proﬁles of 20 trajectories have been generated. Their data
were used as excitations for the quarter-vehicle model, simulating 20 driving se-
quences along the road. During each iteration, the excitation was estimated by the
disturbance observer. The occurring disturbances were learned by providing the
learning algorithm with data from the observed excitation and with the longitudi-
nal position of the vehicle.
To verify the results, we used the constructed Bayesian network to predict distur-
bances during three other simulated passages on random trajectories. During those
passages, probabilities of the occurrence of learned disturbances were calculated
and constantly updated. These probabilities were calculated using the Bayesian net-
work and were based on evidence given by disturbances already struck or passed
during the current driving sequence.
Figures 3.18 and 3.19 illustrate the results of the test runs. Figure 3.18 shows
the road model with the disturbances that were learned. The three lines represent
the trajectories used for the prediction test. The driving direction of the modeled
quarter-vehicle is from left to right.
The excitations (ˆz′) observed by the model are shown in Fig. 3.19 in relation to the
longitudinal position x. The disturbances are visible as peaks. The circles, squares
and crosses mark the position and intensity of learned disturbances. The numbers in-
dicate the calculated probability of hitting the corresponding disturbance, obtained
by inference in the Bayesian network. The plotted values are calculated online dur-
ing the driving sequence considering all evidence obtained up to that point. The
crosses mark the position of learned disturbances which are assumed to be hit ac-
cording to their probability. The circles show disturbances with low probabilities,
which are considered as not being hit during that particular iteration.
It can be seen in the ﬁgures that most predictions based on the calculated prob-
abilities are correct, which means that the disturbances are considered correctly as
either being missed (circles) or being hit (crosses). As it turns out, of 25 disturbances
hit during the three runs shown in Fig. 3.19, 21 have been predicted correctly, which
is more than 80 %. Furthermore, the forecasts for all disturbances that were not hit
were accurate. Altogether, the occurrence or non-occurrence of about 90 % of the
learned disturbances could be predicted correctly.

3 Methods of Improving the Dependability of Self-optimizing Systems
69
 
16.6667%
100%
100%
100%
0%
0%
100%
100%
0%
0%
100%
100%
100%
0%
0%
Disturbance z’
16.6667%
0%
28%
0%
5.5556%
100%
100%
100%
100%
100%
0%
0%
100%
100%
100%
0
2
4
6
8
10
12
14
16
18
20
Longitudinal position x [m]
 
16.6667%
0%
28%
100%
0%
0%
100%
100%
0%
0%
14.2857%
100%
100%
0%
0%
T1
T2
T3
Fig. 3.19 Derivative of excitations (trajectories of Fig. 3.18) and results of prediction. (Cir-
cles: correct prediction of non-occurence, Cross: correct prediction of occurence, Squares:
false prediction (false-negative))
Summing up the results, we can state that the probabilistic iterative learning
method based on Bayesian networks can be successfully used to learn and predict
randomly occurring, stochastically dependent excitations in the context of road ve-
hicles. The learned data could conceivably be used in different ways. In the context
of self-optimizing systems, applications such as classiﬁcation of road segments or
planning tasks become possible. The method can also be beneﬁcial for the system
safety, as it offers additional information about the environment; e. g. dependability-
oriented conﬁgurations could be used by the system for road segments with espe-
cially uneven surfaces.
3.2.2.5
Further Reading
A more detailed describtion of the method can be found in [19].
3.2.3
Mutation Testing of Electronic Component Design
Wolfgang Müller and Tao Xie
The complexity of self-optimizing systems requires systematic and thorough veriﬁ-
cation of their designs, in order to guarantee adaptive yet desired runtime behavior.
In this section, we focus on the design veriﬁcation of electronic components, such
as an embedded microprocessor, and propose an adaptive veriﬁcation method that
is directed by coverage metrics.
Together with other electronic peripherals, microprocessors comprise the central
platform hosting hardware dependent software and application software, which is
the seat of system intelligence. The design of these components must be veriﬁed as

70
W. Müller and T. Xie
comprehensively as possible, as their later integration into a complex system makes
in-system veriﬁcation difﬁcult and their functional correctness should be ensured
beforehand. We assume that simulation remains the primary platform for functional
veriﬁcation and prototyping of electronic designs, though other alternatives do exist,
such as the model-checking used in Section 3.2.7.
In this context, we can ﬁnd coverage metrics at the heart of veriﬁcation thorough-
ness. With coverage, we systematically and quantitatively measure the progress of
a simulation-based veriﬁcation process. Various code coverage and toggle cover-
age are the primary metrics. Recent research extends to more complex functional
coverage [50] and assertion-based coverage.
Mutation testing, also called mutation analysis, is a unique coverage metric that
assesses the quality of test data in a more stringent manner. It was originally in-
troduced and studied as a theory for software testing [36]. Later, mutation testing
was increasingly considered for hardware design veriﬁcation [136] and an industrial
EDA (Electronic Design Automation) tool for Hardware Description Languages
(HDLs) mutation testing became available [67].
We have chosen mutation analysis as the advanced, representable coverage metric
most suitable for our purposes. In the following section, we will ﬁrst introduce the
basic principle of mutation analysis and then present a mutation analysis feedback-
directed adaptive testbench for functional veriﬁcation of electronic component de-
signs. The method has been evaluated using a typical embedded microprocessor
design.
3.2.3.1
Prerequisites and Input
Mutation testing is a fault-based simulation metric. It highlights an intrinsic require-
ment for simulation test data that they should be capable of stimulating potential
design errors and propagating the erroneous behavior to checking points. Mutation
testing measures and enhances the simulation process as shown by Fig. 3.20.
A so-called mutation is a single fault injection into the code of a copy of the
Design Under Veriﬁcation (DUV), such as this HDL statement modiﬁcation:
a <= b and c; mutation
−−−−−→a <= b or c;
The fault-injected copy is called a mutant of the design. For each test case, the
mutant is simulated after the simulation of the original design and the results of
both simulations are compared. If any difference appears at the output during the
simulation, this test is said to be able to "kill" the mutant. Each type of fault injection
is called a mutation operator and dozens of such operators can be deﬁned based on
the applied design language. By deploying these pre-deﬁned mutation operators at
different locations of a design, we can obtain a huge database of mutants. Then
the number of killed mutants determines a mutation coverage metric, which can be
used to measure the overall quality and thoroughness of the testbench and the entire
simulation process.
We consider random simulation a long-recognized useful lightweight method of
carrying out mutation testing. However, the lightweight nature of random simulation

3 Methods of Improving the Dependability of Self-optimizing Systems
71
Mutation testing
Simulation-based
functional verification of electronic design
(Automated) Selection of more test data
Simulate
Mutation Operator
Simulate
Correct Design
Verification
closure
Tests
Monitor/
checker
Electronic component
Design Under Test
(e.g. an embedded
microprocessor)
Measure
quality of tests by 
number of
killed Mutants
Adequate?
Bug?
Mutant N
M1
Fig. 3.20 Mutation testing for the functional veriﬁcation of electronic component designs
is in contrast with the inherent computation expensiveness of mutation testing. In
essence, each time a random test is generated, it should be simulated against not
only the original Design Under Veriﬁcation, but also against all the mutants that
have been created as the cover points, of which there is a massive amount. Since
the test is randomly selected and relatively undirected, this ampliﬁes the mutation
testing problem.
3.2.3.2
Description
Therefore, we propose a mutation testing feedback-directed adaptive random simu-
lation method. Our proposal improves the efﬁciency of the mutation testing cover-
age and solves the inherent conﬂict between random test generation and mutation
analysis. We propose the use of a constrained Markov chain to enable effective
adjustment to the probability model of random simulation. An efﬁciency-improving
heuristic makes this adjustment by utilizing two-phase mutation testing results. Such
a testbench is shown in Fig. 3.21. The idea is to integrate an in-loop heuristic process
that dynamically adapts the test probability model to a more efﬁcient distribution
for mutation coverage. On-line results from each mutation-testing run are analyzed
to derive the adjustment. Our evaluations demonstrate that the heuristic reaches a
higher mutation coverage in less simulation time.
As a prerequisite for the dynamic adjustment, a probability model of test se-
quences is required that provides the possibility of parameter steering. Considering
that an electronic component design has a precisely deﬁned instruction interface,
such as the ISA (Instruction Set Architecture) of a microprocessor, or the communi-
cation protocol of a bus controller, test inputs in a random test generator are modeled

72
W. Müller and T. Xie
mutants
Weak MA
(locally activated)
one simulation run for
all un-killed mutants
Strong MA
(killed)
one simulation run for
each activated mutant
Mutation analysis (MA)
Constrained random 
test generator
Probability model
0.8
0.1
0.1
........
test
(0<IMM<4) weight: 0.1
(IMM==4) weight: 0.05
.
.
.
sw
addi
beq
P            = min{P           * (1 + Efficiency    ),P      }
Edge_new
Edge_old
rel
MAX
add i
Fig. 3.21 A mutation testing directed adaptive simulation framework for the functional veri-
ﬁcation of electronic component designs
in two layers as shown in Fig. 3.21. In a ﬁrst step, a Markov chain is used to repre-
sent sequences of tests. Each node models one type of test instruction. The selection
probability on edges enables us to establish the correlation between mutation anal-
ysis efﬁciency and a short pattern of test sequences. Second, weighted constraints
are deﬁned on the ﬁelds of an instruction. This provides the possibility of steering
test patterns towards more effective areas, such as corner cases.
Each time a test is generated, we record the pair of Markov edge and constraint
selected for the generation. The basic idea is to estimate the efﬁciency of each test
on mutation analysis and use the estimation to adjust the probability of the cor-
responding Markov edge and constraint. This efﬁciency estimation should follow
the unique simulation process of mutation analysis. As the right half of Fig. 3.21
shows, we ﬁrst introduce an extra weak mutation analysis [72] phase. It uses one
simulation cycle to identify the locally activated mutants. Only those are fed into a
traditional, strong mutation analysis phase and are fully simulated, so that we can
see whether they are killed using the criterion that a different value appears at de-
sign output ports. Consider that ϕ is the test probability distribution from a Markov
chain/constraint model, which further implies PMi_activated and PMi_kill for each mu-
tant Mi as its probabilities of being activated and killed using the current test model.
On a set of NMutant design mutants, this leads to an expected simulation effort for
the mutation analysis ﬂow in Fig. 3.21, represented as
max
1≤i≤Nmutant(1/PMi_kill)+
∑
1≤i≤Nmutant
(PMi_activate/PMi_kill)

3 Methods of Improving the Dependability of Self-optimizing Systems
73
Based on this expected simulation effort, we use the number of mutants acti-
vated by the test Nactivated and the number of mutants killed Nkilled to estimate the
efﬁciency of this test as
Efﬁciency =
Nkilled
Nactivated
A low ratio means that too many mutants are merely activated and that a large
number of simulations are wasted in the second phase without killing the mutants.
We also record this efﬁciency value for the last 10 tests generated and use the aver-
age Efﬁciencyaverage_last_ten to derive a relative value that lies between 0 and 1
Efﬁciencyrel =
Efﬁciency
Efﬁciencyaverage_last_ten + Efﬁciency
According to this, at the early stage of a random simulation, test patterns with
high mutation kill/activation rates are encouraged. However, we observed in our
experiment that in the last stage, it may well happen that no single mutant is killed in
ten consecutive iterations. In such a case, the heuristic approach changes to another
mode that encourages more activation of mutants, by ﬁrst calculating efﬁciency as
an adjustment value and then increasing the probability/weight of the corresponding
Markov chain edge/constraint with the following value:
Efﬁciencyrel =
Nactivated
Nactivated_average_last_ten + Nactivated
It is safe to assume that there will always be some mutants activated.
Initially, all Markov chain edges have the same probability of being selected and
instruction constraints have the same weight. At the end of each iteration for test
generation, the probability of the edge used as well as the weight of the constraint
used is adjusted by
	
PEdge_new = min{PEdgeold ∗(1 + Efﬁciencyrel),PMAX}
PConstr_new = min{WConstrold ∗(1 + Efﬁciencyrel),WMAX}
PMAX and WMAX are efforts to prevent the starvation of other edges/constraints
by setting an upper bound of probability on one edge/constraint. In a real-world
application that follows, these two numbers were set to 0.9 for a model of 58 Markov
edges, for instance.
For each Edgei that branches out from the same instruction node and eachConstri
on this node, we adjust their probability/weight proportionally to their old values
⎧
⎪
⎪
⎨
⎪
⎪
⎩
PEdgei_new = (1 −PEdge_new)∗
PEdgei_old
1 −PEdgei_old
PConstri_new = (1 −PConstr_new)∗
PConstri_old
1 −PConstri_old

74
W. Müller and T. Xie
As a heuristic approach, the formulation of the adjustment is motivated by two
points.
First, the ultimate problem of test generation in mutation analysis is to kill a de-
sign mutant, the mutant simulation is required to ﬁrst reach the mutation statement,
then activate this mutant by executing the mutated statement in such a manner that
a local deviation is created, and propagate this deviation to any output of the design.
Second, there are two hypotheses that we consider reasonable for correlat-
ing mutation analysis feedback to the test generation problem: activation-kill and
similar-test.
The activation-kill hypothesis states that if a test activates a large number of
mutants in a simulation, it also leads to a simulation that kills many mutants in the
end. In other words, the mutant-activation efﬁciency of a test is coupled with its
ﬁnal mutant-killing efﬁciency. This is actually straightforward based on the problem
of mutation analysis test generation – activation is a necessity condition for killing
mutants, preceding propagation.
The similar-test hypothesis states that if a test activates a lot of mutants, the pair
of Markov chain edge/constraint that was used for generating this test will further
generate tests that activate similarly many mutants. In short, a pair of Markov chain
edge/constraint represents a type of test. We expect that tests generated from the
same type have similar mutant-activation efﬁciency.
This can be taken as an explanation for why the heuristic adaptation approach is
described as it is in this section.
3.2.3.3
Results
The result of our adaptive veriﬁcation method, when applied to an electronic com-
ponent design, is a random simulation testbench that is able to achieve a higher
mutation coverage with less simulation effort.
3.2.3.4
Application Example
We have created an experimental version of the mutation analysis directed sim-
ulation method and applied it to the functional veriﬁcation of the MB-LITE mi-
croprocessor design [85]. This soft microprocessor core realizes MicroBlaze ISA
in VHDL and is a widely used architecture in embedded systems. It is able to exe-
cute binary code compiled with the standard MicroBlaze compiler mb-gcc (included
in the XILINX FPGA tool). Mutation testing was implemented by Certitude(TM),
an industrial EDA tool, which selectively generated 732 mutants for the MB-LITE
design.
The MicroBlaze instructions [153] were modeled by 58 Markov-chain nodes.
Similar instructions are not considered distinctly, such as add, addc, addk and ad-
dkc. Further, 17 constraints were deﬁned to partition instruction areas. We used the
SystemC Veriﬁcation Library for implementing the Markov chain and the associated
instruction constraints, as it provides a convenient framework for probability mod-
eling and constraint solving. SystemC and VHDL co-simulation is also supported

3 Methods of Improving the Dependability of Self-optimizing Systems
75
by the ModelSim simulator. All the edges and constraints have an equal probability
of being selected at the beginning.
We compared the following test generation processes: i) the random test gener-
ation under the constrained Markov-chain probability model and dynamically di-
rected by the in-loop heuristics, ii) the same random test generation, but without
the in-loop adjustment, and iii) two software programs: a basic “hello world” and
a Dhrystone benchmark. These programs can be seen as competitive comparisons,
since they are generated by the compiler’s extensive knowledge of the instruction
set.
Figure 3.22 shows their efﬁciency in terms of mutation analysis coverage, i.e.
number of killed mutants versus test instructions used. The simulations lasted for
several hours on a computer with a 2.4 Ghz processor. The data are drawn only to
the points after which there was no further change in coverage.
The mutation analysis feedback-directed random simulation reached a status of
killing 691 mutants within about 8.3 hours, compared to the non-adaptive variant
that killed 625 mutants in 11 hours. The coverage is 94.4% versus 85.4%. The im-
provement in performance came ﬁrstly from the ability of the heuristics to steer the
test generation towards more effective patterns in the early phase. Secondly, this
efﬁciency is also ampliﬁed continuously in mutation analysis, as the early killing
of mutants eliminated the cost of their simulation afterwards. Further, the heuristics
encouraged more activation in the late phase, which showed the effect of trying-
and-killing more mutants.
Both random simulations outperformed the other two software binaries. The ba-
sic “hello world” was able to kill 507 mutants and the Dhrystone able to kill 565
mutants. At the initial stage, they displayed an identical coverage curve. In the mid-
dle period, both had a long sequence of wasted cycles without contributing any
coverage improvement. This is inferior to the continuous increase of killed mutants
in random simulations.
Fig. 3.22 Efﬁciency im-
provement with adaptive
random simulation, by
comparing four simula-
tion processes with regard to
mutation testing
700
600
500
400
300
200
Killed mutants
Tests - MicroBlaze instructions
1
10
100
1000
10000
random_MA_directed
random
sw_basis
sw_dhrystone
Legend

76
S. Ober-Blöbaum and A. Seifried
In the end, we came to the conclusion that the proposed adaptive random simu-
lation method is able to substantially improve the testbench efﬁciency of targeting
mutation testing and functions admirably as an advanced quality metric for the func-
tional simulation of electronic component design in our self-optimizing systems.
3.2.4
Optimal Control with Uncertainty
Sina Ober-Blöbaum and Albert Seifried
The goal in classical optimal control theory is to determine control strategies that,
if applied to the system, fulﬁll some predeﬁned task optimally with respect to some
given quantity. However, for many applications, speciﬁc system parameters such as
e.g. friction coefﬁcients or geometry parameters are unknown or cannot be measured
exactly. Due to this uncertainty, the correct execution of the desired task can no
longer be guaranteed by the control system. In this section, strategies for the optimal
control of technical systems with uncertainties are presented under the aspect of the
attributes safety and reliability by introducing a performance measure.
While in the deterministic setting, we characterize the maximal performance of
the control system in fulﬁlling a predeﬁned task exactly (e.g. a robot arm has to
grab some tool in a speciﬁc position); in the presence of uncertainty we introduce a
performance measure whose mean has to be minimized in order to guarantee max-
imal performance by the control system and thus lead to reliable system behavior.
Regarding this notion of system performance as an additional objective leads to a
multiobjective optimal control problem. Based on numerical solution methods for
optimal control [107] and multiobjective optimization problems [34,135], a numer-
ical method is presented in this section to approximate the so-called Pareto optimal
solutions of this multiobjective optimal control problem. The approach is veriﬁed
by means of a robot arm maneuver for which the arm lengths are assumed to be
uncertain.
For the application of the presented method, input from different partial models
of the Principle Solution (cf. Sect. 2.1) is required. Concerning the control engineer-
ing methods, all information about the models of the dynamics have to be provided
in order to formulate the control problem. The partial models “Application Scenar-
ios” and “System of Objectives” provide all the necessary information for the task to
be fulﬁlled by the control system, as well as the information with respect to which
criterion this task has to be optimized. Furthermore, the partial models “Require-
ments” and “Environment” provide important information about uncertain model
parameters and their ranges for the optimal control problem.
Let us consider a technical system with uncertainty given by the differential
equation
˙x(t) = f(x(t),u(t),ξ)
(3.6)
with Lipschitz continuous f, the state function x : I →Rn, the control function
u : I →Rm, I = [t0,tf ], and random variables ξ ∈Rs with known distributions as-
sociated with the uncertainty of system parameters. It is assumed that x(t) can be

3 Methods of Improving the Dependability of Self-optimizing Systems
77
expressed as a function of ξ, i.e. x(t,ξ).4 Let J(x,u) =

I C(x(t),u(t))dt be a cost
functional which measures a quantity of interest with the continuously differentiable
cost function C. Then the expected value of J is given by
ˆJ(u) =

J(x,u)ρ(ξ)dξ,
(3.7)
where ρ(ξ) is the probability density function (pdf) of ξ. A general optimal con-
trol problem is to ﬁnd a control u∗that minimizes (3.7), subject to the differential
equation (3.6). Common solution methods for solving these single optimal control
problems are e.g. sample average approximation methods [25, 79], for which the
expected value function is approximated by some sample average function based on
Monte Carlo simulations. The resulting sample average optimization problem can
be solved by standard optimization techniques (see e.g. [98]).
Typically, the intent is to design an optimal control such that the fulﬁllment of a
task is guaranteed by the system (expressed by the terminal constraint r(x(tf )) = 0).
In this case, we say that system performance is maximal. Note that in the presence
of uncertainty, the value of the terminal constraint r(x(tf ,ξ)) will be different for
different values of the random variables ξ. Thus, the execution of the task can no
longer be guaranteed by the control system. Instead, the goal is to design a control
that, on one hand, is still optimal with respect to the prescribed objective functional
and, on the other hand, optimizes the system performance, i.e. the system should
fulﬁll the desired task as well as possible. To this end, we deﬁne a single perfor-
mance measure Y(x,ξ) ≥0 that depends on the random variables and which is, in
the deterministic case, zero for maximal performance, i.e. Y = 0 if r(x(tf )) = 0.
As measure of performance, we choose Y = ∥r(x(tf ))∥2
2. In the presence of uncer-
tainty, the performance of the system is deﬁned as optimal if the expected value of
the performance measure Y is minimized, i.e. we want to minimize
ˆJ2 =

Y(x,ξ)ρ(ξ)dξ.
(3.8)
For the chosen measure of performance this means that maximal system perfor-
mance corresponds to minimal mean violation of the terminal constraint.5 This is
in contrast to other approaches in robust optimal control, where, for example, the
probability of a state constraint violation is required to be less than some small,
but given probability, which is then included as an inequality constraint or as new
single objective function in the optimal control problem (see e.g. [94]). Instead,
Equation (3.8) is treated as an additional objective functional in the optimal control
problem. By minimizing (3.7) and (3.8) subject to the differential equation (3.6),
we are faced with a multiobjective optimal control problem, i.e. the optimization
of not only one but several objectives at the same time is required. If the different
4 In the following, we will simply write x(t) but assume that x is also a function of ξ.
5 Note that the expected value is only one choice among many robustness measures and
could be easily replaced.

78
S. Ober-Blöbaum and A. Seifried
objectives are conﬂicting, no unique optimum can be determined. Rather, we at-
tempt to determine a set of compromise solutions: the Pareto optimal solutions [49].
3.2.4.1
Prerequisites and Input
Without loss of generality, a multiobjective optimization problem can be viewed as
a minimization problem; however, in contrast to a (single) objective problem, the
objective function is vector-valued (cf. Chapter 1.1.2.1).
Problem 3.1. A multiobjective optimization problem is given by
min
y∈S {F(y)},
S := {y ∈Rn |g(y) = 0, a(y) ≤0},
(3.9)
with objective functions F : Rn →Rk,k > 1 and constraint functions g : Rn →Rm
and a : Rn →Rq.
For the computation of the set of Pareto optimal solutions (cf. Chapter 1.1.2.1)
of Problem 3.1, there exists an extremely broad variety of different methods. The
methods are classiﬁed as global or local methods, whereby the global methods it-
erate step-for-step a complete set of parameters to obtain an approximation of the
Pareto set. Contrary to global methods, local methods use local information from
single Pareto points to compute proximate solutions. Well-known global methods
are evolutionary algorithms (e.g. [32]) or subdivision methods (e.g. [34]). Typical
local methods are the weighted sum method (e.g. [32, 102]), continuation methods
(e.g. [70, 131]) or reference point methods (e.g. [33,102]). The latter methods are
appropriate for approximating the Pareto set, especially for a high dimension n. The
basic idea is to generate unreachable targets (or reference points) T ∈Rk in the
image space of F, where each of these targets is used for the following distance
minimization:6
min
y∈S ∥F(y)−T∥,
S := {y ∈Rn |g(y) = 0, a(y) ≤0}.
(3.10)
Standard minimization algorithms like SQP [60], which is implemented in the NAG
library7 (Numerical Algorithms Group), or Ipopt8 can be applied to solve these
single-objective minimization problems. This yields a set P of minima which ap-
proximates the whole Pareto set if it is convex, and a continuous connected part of
it in the nonconvex case.
To be more precise, for the given multiobjective optimization problem 3.1, a norm
∥·∥, and an optimal point y0 ∈P the reference point optimization algorithm works
as follows:
P := {y0}
FP := {F(y0)}
6 For the numerical computations, we minimize the squared distance to ensure
differentiability.
7 http://www.nag.co.uk
8 https://projects.coin-or.org/Ipopt

3 Methods of Improving the Dependability of Self-optimizing Systems
79
for i = 0,...,M do
for j = 1,...,k do
Choose Ti
j ∈Rk near F(yi) but outside of F(S)
Solve y∗
j := argminy∈S ∥F(y)−Ti
j∥
if ∥F(y∗
j)−Ti
j∥> 0 then
y|P|+1 := y∗
j
P := P∪{y|P|+1}
FP := FP∪{F(y|P|+1)}
end if
end for
end for
Here, M ∈N is a predeﬁned maximum number of steps, P is the resulting set that ap-
proximates P (at least in parts) and FP is the corresponding front. The if-condition
ensures that the chosen targets are not reachable, at least for the chosen local min-
imizer. For target generation, we have chosen a strategy designed to approximate
the Pareto front for a bi-criteria optimization problem with evenly spread points
very quickly. Details can be found in [133]. Different possibilities relating to the
generation of good targets are proposed in e.g. [33].
3.2.4.2
Description
A general formulation of a multiobjective optimal control problem with uncertainty
is stated as follows.
Problem 3.2. Find a control u∗that solves
min
u
ˆJ(u) = min
u

J(x,u)ρ(ξ)dξ
(3.11)
subject to
˙x(t) = f(x(t),u(t),ξ),
(3.12)
with vector-valued objective functionals ˆJ = ( ˆJ1,..., ˆJk) and J = (J1,...,Jk) such
that ˆJi(u) =
 Ji(x,u)ρ(ξ)dξ. Each Ji(x,u) may consist of a Lagrange and a Mayer
term of the form Ji(x,u) =

I Ci(x(t),u(t))dt + ψi(x(tf )), i = 1,...,k, with C =
(C1,...,Ck) and ψ = (ψ1,...,ψk) being vector-valued, continuously differentiable
functions.
The numerical solution to Problem 3.2 involves three key tasks: (i) the numerical
solution of the state equation (3.6), (ii) a simulation strategy to evaluate the objective
functional ˆJ, and (iii) an optimization algorithm to approximate the Pareto set.
For the ﬁrst task, a numerical integrator based on a prescribed time grid Δt =
{t0,...,tN = tf } is used. Let ud = {uk}N
k=0 be a discretization of the time-dependent
function u(t), where uk is an approximation of u(tk). For a ﬁxed control sequence
ud and ﬁxed parameter ξ a variational integrator is applied to compute an approxi-
mation xd = {xk}N
k=0 of the curve x(t).9 Variational integrators [97] are particularly
9 Note that each xk, k = 0,...,N, is a function of ξ.

80
S. Ober-Blöbaum and A. Seifried
efﬁcient for Hamiltonian and Lagrangian systems, since they preserve structural
properties such as symmetries in the discrete approximation.
For the second task, in general two approximations have to be performed in order
to evaluate an objective functional of the form (3.11). In the following, we use the
same approximation rules for each objective functional ˆJi, i = 1,...,k but omit the
index i and the Mayer term for simplicity in this section. Based on the discrete time
grid {tk}N
k=0, ﬁrst the objective functional J is approximated by
Jd(xd(ξ),ud) =
N−1
∑
k=0
Cd(xk,xk+1,uk) ≈

I C(x(t,ξ),u(t))dt
(3.13)
where Cd(xk,xk+1,uk) is an approximation of
 tk+1
tk
C(x(t,ξ),u(t))dt for a ﬁxed
parameter ξ = (ξ1,...,ξs) ∈Rs using numerical quadrature rules (see e.g. [107]).
Thus,
 Jd(xd(ξ),ud)ρ(ξ)dξ is already an approximation of ˆJ based on the discrete
time grid {tk}N
k=0.
For the approximation of the remaining integral, we use a straightforward ap-
proximation technique based on a simple sampling of the uncertain parameters. We
assume a bounded support of the pdf which is effective by cutting the pdf at ap-
propriate boundaries. For our numerical examples, such a support is chosen to be
ﬁve times the standard deviation, since it is unlikely that the parameters are outside
this region. Note that also, in most practical applications, the region of uncertainty
is bounded (system parameters can only change within a prescribed region). Thus,
we introduce lower and upper bounds ξ l
i and ξ u
i on the random variables, such that
ξi ∈[ξ l
i ,ξ u
i ] for i = 1,...,s. We discretize ξ with Mi + 1 discretization points for
each component ξi, i=1,...,s. Thus, we deﬁne equidistant discrete grids {ξiki}Mi
ki=0
with ξi0 = ξ l
i , ξiki = ξi0+Δξiki and ξiMi = ξi0+MiΔξi = ξ u
i with grid sizes Δξi ∈R,
i = 1,...,s.10 We deﬁne a discretized probability density function ρd as
ρd(ξ) =
ρ((ξ1k1,··· ,ξsks))
Δξ1 ···Δξs ∑M1
l1=1···∑Ms
ls=1 ρ((ξ1l1,··· ,ξsls))
(3.14)
for
ξiki−1 < ξi ≤ξiki
for
i = 1,...,s,
ki = 1,...,Mi, i = 1,...,s and ρd(ξ) = 0 if ξi ̸∈[ξ l
i ,ξ u
i ] for at least one i. Note that
this choice of ρd guarantees that
 ρd(ξ)dξ = 1. Finally, ˆJ(u) is approximated by
ˆJd(ud) = Δξ1 ···Δξs
M1
∑
l1=1
···
Ms
∑
ls=1
Jd(xd(ξ1l1,··· ,ξsls),ud)ρd((ξ1l1,··· ,ξsls))
= ∑M1
l1=1···∑Ms
ls=1 Jd(xd(ξ1l1,··· ,ξsls),ud)ρ((ξ1l1,··· ,ξsls))
∑M1
l1=1 ···∑Ms
ls=1 ρ((ξ1l1,··· ,ξsls))
.
(3.15)
10 In the following, the ﬁrst index of ξ refers to the vector component, while the second index
represents the grid point.

3 Methods of Improving the Dependability of Self-optimizing Systems
81
Note that the probability P of ξ being in [ξ1k1−1,ξ1k1] × ··· × [ξsks−1,ξsks] can be
approximated by
Pk1···ks =
 ξ1k1
ξ1k1−1
···
 ξsks
ξsks−1
ρd(ξ)dξ =
ρ((ξ1k1,··· ,ξsks))
∑M1
l1=1···∑Ms
ls=1 ρ((ξ1l1,··· ,ξsls))
.
(3.16)
The multiobjective optimal control problem is thus transformed into a multiob-
jective optimization problem with objective function ˆJd = ( ˆJd,1,..., ˆJd,k) and opti-
mization parameters y = ud = {u0,...,uN}. The discretization of the time interval
determines the problem dimension and is typically high in order to comply with the
desired accuracy requirements. Thus, for the computation of Pareto optimal con-
trol sequences ud = {u0,...,uN} and for the approximation of the Pareto set (the
third task), the reference point optimization method is applied. The discretization of
the uncertain parameter space signiﬁcantly inﬂuences the duration of the objective
function evaluation. Note that for each evaluation of ˆJd(ud), (M1 + 1)···(Ms + 1)
simulations of the differential equation (3.12) are required.
3.2.4.3
Results
As a result, a set of Pareto optimal control sequences ud is obtained. By apply-
ing these control sequences to the technical system described by the differential
equation (3.6), the system behaves Pareto optimally with respect to the prescribed
quantity of interest (e.g. control effort) and performance in the presence of uncertain
parameters.
3.2.4.4
Application Example
In this section, a robot arm modeled as a two-link mechanism (see Fig. 3.23) is
considered for which the lengths L1 and L2 of the two links are assumed to be
unknown or not measurable exactly. The mechanism consists of two coupled pla-
nar rigid bodies, where θi, i = 1,2, denote the orientation of the ith link measured
counterclockwise from the positive horizontal axis. The system is controlled via
two control torques denoted with u(t) = (τ1(t),τ2(t)), acting in both joints of the
two time-dependent links (see [107] for a detailed model description). The goal is
to determine a control sequence u(t) which steers the robot arm tip (modeled as
the end point of the two-link mechanism) from a prescribed initial state x0 to a
Fig. 3.23 Model of the
two-link manipulator with
uncertain link lengths

82
S. Ober-Blöbaum and A. Seifried
prescribed ﬁnal state xref = (0,1.5,0,0) at time tf = 1.0, where x consists of the
arm tip’s position q = (L1 cosθ1 + L2 cosθ2,L1 sinθ1 + L2 sinθ2)T and its velocity
v = (−L1 ˙θ1 sinθ1 −L2 ˙θ2 sinθ2,L1 ˙θ1 cosθ1 + L2 ˙θ2 cosθ2)T . This maneuver should
be performed in such a way that, on one hand, the required control effort is mini-
mized, and on the other hand, the deviation from the prescribed goal state xref is as
small as possible in the presence of uncertain length parameters ξ = (L1,L2).11
In the ﬁrst step, the deterministic optimal control problem is solved, for which
the lengths are ﬁxed as some reference value ξ = ˆξ = (ˆL1, ˆL2). The endpoint
condition x(tf ) −xref = 0 is incorporated as a terminal constraint in the optimal
control problem, such that only one objective functional, the control effort given
as J1(u) =
 tf
t0
1
2∥u(t)∥2
2 dt, is considered. To determine the optimal control se-
quence u∗
d(ˆξ), the numerical method DMOC (Discrete Mechanics and Optimal
Control) [107] is utilized, which is based on the discretization of the underlying
optimal control problem. For the discretization, a discrete time grid with N +1 = 20
discretization points is chosen.
In a second step, the control problem is reconsidered including uncertainty. The
unknown lenghts L1 and L2 are assumed to be independent and normally distributed
around the reference value ˆLi = 1.0, i = 1,2, with a standard deviation of 0.001.
For the numerical treatment, the space of uncertain parameters [0.995,1.005] ×
[0.995,1.005] is discretized by two equidistant grids {ξi0,ξi1,...,ξiMi}, Mi = 33,
i = 1,2, and we approximate the pdf with the discretized probability density func-
tion ρd(ξ) (3.14). In Fig. 3.24 (left), the probability P of ξ being in [ξ1k−1,ξ1k] ×
[ξ2l−1,ξ2l] is depicted as given by Pkl in (3.16).
0.995
1
1.005
0.995
1
1.0050
0.005
0.01
0.015
L1 
L2
Probability
-0.4
0
0.4
1.2
1.3
1.4
1.5
1.6
q1
q2
 
 
Final point probability
2
4
6
8
10
12
14
x 10
−3
Fig. 3.24 Left: discretization of uncertain parameter space and approximated probability;
Right: ﬁnal positions q(t f ,ξ) for different values of lengths parameters ξ and optimal control
sequence u∗
d(ˆξ)
11 Note that the robot arm tip’s state is dependent on the uncertain lengths ξ.

3 Methods of Improving the Dependability of Self-optimizing Systems
83
0
50
100
150
200
0
0.005
0.01
0.015
0.02
0.025
0.03
Control effort
Mean deviation
1
2
3
4
5
-0.4
0
0.4
1
1.2
1.4
1.6
1.8
q1
q2
 
 
Final point probability
2
4
6
8
10
12
14
x 10
−3
(a) Approximation of Pareto front with ﬁve
chosen points.
(b) Final conﬁgurations for Pareto point 1.
-0.4
0
0.4
1
1.2
1.4
1.6
1.8
q1
q2
 
Final point probability
2
4
6
8
10
12
14
x 10
−3
 
Final point probability
2
4
6
8
10
12
14
x 10
−3
-0.4
0
0.4
1
1.2
1.4
1.6
1.8
q1
q2
(c) Final conﬁgurations for Pareto point 2.
(d) Final conﬁgurations for Pareto point 3.
 
Final point probability
2
4
6
8
10
12
14
x 10
−3
-0.4
0
0.4
1
1.2
1.4
1.6
1.8
q1
q2
 
 
Final point probability
2
4
6
8
10
12
14
x 10
−3
-0.4
0
0.4
1
1.2
1.4
1.6
1.8
q1
q2
(e) Final conﬁgurations for Pareto point 4.
(f) Final conﬁgurations for Pareto point 5.
Fig. 3.25 Behavior of ﬁnal points in conﬁguration space for ﬁve chosen points of the approx-
imated Pareto front

84
P. Hartmann
First, we investigate the inﬂuence of uncertainty on the system performance if the
optimal control u∗
d(ˆξ), which was computed for the deterministic case, is applied to
the system. We integrate the differential equation (3.6) with ﬁxed optimal control
sequence ud = u∗
d(ˆξ) and different grid values ξij = (ξ1i,ξ2 j), i, j = 0,...,M. In
Fig. 3.24 (right), it can be seen that the different ﬁnal conﬁgurations q(tf ,ξij) of the
arm tip strongly deviate from the reference value for the ﬁnal position qref = (0,1.5).
A similar behavior can be observed for the ﬁnal velocities. The colors indicate the
probability values as given in Fig. 3.24 (left). Thus, the performance of the system is
relatively poor in the presence of uncertain lengths and new control sequences have
to be determined to improve the system performance.
To reduce the deviation from the reference goal state, the mean of the perfor-
mance measure (3.8) is treated as additional objective function, and the reference
point optimization method is employed to determine Pareto optimal control se-
quences (minimal control effort and minimal mean deviation from the reference
point). For the minimization of (3.10), a SQP method implemented in NAG is used.
Figure 3.25 (a) shows the approximation of the Pareto front. It can be observed
that for increasing control effort, the mean of the deviation from the ﬁnal goal state
(marked as a cross) decreases. In Fig. 3.25 (b)–(f), the ﬁnal conﬁgurations for un-
certain lengths are illustrated for ﬁve selected Pareto points. Along the Pareto front,
the area of reached ﬁnal points contracts and thus system performance increases as
desired.12 A similar behavior can be observed for the ﬁnal velocities.
3.2.4.5
Further Reading
For a more detailed description of numerical methods, the problem formulation and
an overview of related literature, we refer to [107,108,135].
3.2.5
Behavior Planning
Philip Hartmann
In order to increase the dependability of self-optimizing mechatronic systems, cog-
nitive planning components with enhanced information processing are also inte-
grated into the system. These components allow mechatronic systems to plan their
behavior in order to fulﬁll individual tasks independently and proactively. A single
task represents a sequence of actions executed by the mechatronic system within
a limited time frame in order to reach a given goal state. Along with bare fulﬁll-
ment of that task, i.e. ﬁnding an arbitrary sequence of actions to reach the desired
goal-state, planning tries to minimize or maximize objectives, such as minimizing
energy consumption. For this reason, actions are only selected if their expected
results ﬁt the desired objectives. With respect to dependability, it is possible to
create alternative plans for critical situations before they arise, i.e. for particular
12 For the illustration of the distributions in Fig. 3.24 (right) and Fig. 3.25 (b)-(f), only the
ﬁnal points with probability P ≥10−6 are depicted.

3 Methods of Improving the Dependability of Self-optimizing Systems
85
environmental or low energy situations. However, this may decrease the Availabil-
ity of the mechatronic system and the Reliability of subsequent task fulﬁllment.
Furthermore, behavior planning considers the continuous and nondeterministic en-
vironment of the system (cf. [80]).
3.2.5.1
Prerequisites and Input
When modeling a planning domain for behavior planning of intelligent mechatronic
systems (cf. [80–82]), the main challenge is to map the partial function solutions
onto actions within the framework of PDDL (Planning Domain Deﬁnition Lan-
guage, cf. [53]). Depending on the amount of detail desired when modeling these
functions, this approach results in a higher or lower abstraction of actions. In case
the of behavior planning, the executed partial function solutions are called opera-
tion modes. Thus, a planning problem for mechatronic systems can be formulated
as follows (adapted from [81]):
• OM is a ﬁnite set of available operation modes,
• S is a ﬁnite set of possible system states, and
• s ∈S is a state vector with s(i) ∈R for the i-th component.
Furthermore, for each operation mode om ∈OM:
• precom := {(xlower < s(i) < xupper)|xlower,xupper ∈R} is the set of preconditions
which must be true for the execution of operation mode om and
• postom is a set of conditional numerical functions describing the change of in-
ﬂuenced state variables. A condition is a logical expression (conjunctions and
disjuctions) of comparison operations; if a condition is true, the result of the cor-
responding numerical function is assigned to state variable in the next state s′ of
the plan ( [81]).
3.2.5.2
Description
A speciﬁc planning problem is the ﬁnding of a sequence of operation modes which
describes a transition from an initial system state si ∈S to a predetermined goal state
sg ∈S. Thus, a single task of a mechatronic system is given as a 2-tuple O = (si,sg).
A solution to the planning problem can be determined by applying a state space
search algorithm (cf. [57]), for example. The optimal solution (e.g. minimum of en-
ergy consumption) can be found by computing the speciﬁc solutions with respect
to the given System of Objectives. For this purpose, Ω is a set of objectives and
f : S × Ω →[0,1] is a function that indicates how well the execution of an oper-
ation mode in a given state satisﬁes the objective. Using the weighted sum of the
objectives, the optimal sequence of operation modes can be determined (cf. [81]).
During runtime in a non-deterministic environment with continuous processes,
behavior planning has to include methods for handling resulting problems. For ex-
ample, Klöpper [80] uses a modeling approach to integrate continuous processes
based on optimal control and continuous multiobjective optimization (also cf. [56]),

86
P. Hartmann
as well as estimation obtained by fuzzy approximation. To manage planning un-
der uncertain conditions, different techniques can be combined in a hybrid planning
architecture (cf. [81]).
Figure 3.26 shows the hybrid planning architecture with the corresponding
components for planning, execution and monitoring of plans. The total planning
is divided into three separate sections: ofﬂine, just-in-case and online planning. The
ofﬂine planning represents a planning process where, initially, a deterministic and
optimal plan in view of the objectives is fully created before execution. The resulting
plan is used in the just-in-case planning to do a probabilistic analysis for plan de-
viations. The present and deterministic plan is examined for estimated variances in
order to proactively generate conditional branches, with alternative plans for critical
system conditions. A threshold speciﬁes the maximum probability of state devia-
tions which would results in a generation of conditional branches (See [82], cf. in
particular also [82] and [80].)
For this purpose, an additional stochastic planning model is formulated based on
the deterministic planning model. This consists of stochastic states sp with |sp| = |s|,
where range(sp(i)) →P(R) is the values range and distribution(sp(i)) the proba-
bility distribution of the state variable sp(i) and a stochastic variant of the operation
modes. Let inom
s
⊆preom be a subset of input variables and outom
s
⊆postom a subset
of output variables. For each output variable o ∈outom
s , a Bayesian network (cf. [17])
bnom
o
is created to formulate the stochastic relation (cf. [80, 81]; for a concrete ex-
ample of creating a stochastic model cf. [82]). As a result, it is now possible to use
the just-in-case-planning to generate alternative plans for situations that could occur
with high probability during operation.
The online planning (cf. Fig. 3.26) serves as a fallback mechanism; it selects the
optimal operation mode for the next execution step. Thus, operation in previously
unplanned situations is guaranteed. A simulation of the continuous system behavior
will check whether the current action of the active plan is executable under the given
environmental conditions. If this is not possible, online planning is necessary, e.g.
for a situation with extreme environmental inﬂuences such as heavy rain. While
Fig. 3.26 Hybrid planning
architecture (source: [81])
Execution
Just-in-case
planning
Offline
planning
Online
planning
Real-time plan
modification
Active
plan
Plan update
Comparison
Simulation
Available
plans

3 Methods of Improving the Dependability of Self-optimizing Systems
87
completing the execution of previously planned operation modes, a comparison of
planned and actually reached system states is carried out.
A process for plan updating will check whether a pre-determined plan is avail-
able or whether a plan modiﬁcation by the online planning is necessary. This will
guarantee the immediate availability of the next operation mode (cf. Fig. 3.26).
The just-in-case and online planning are implemented as anytime algorithms (for
the usage of anytime algorithms in intelligent systems cf. [155]). The planning pro-
cess can be interrupted at any time to obtain a result, but with increasing time for
calculations it provides a higher quality of result, as it is possible to generate more
branches and to reach a higher depth of planning.
3.2.5.3
Results
The dependability our type of system can be inﬂuenced by various factors. A major
factor is the availability of energy, as this is crucial for the operationf of the sys-
tem. To ensure the dependability of the mechatronic system, it is essential to use
the energy storage in a valid range and in particular to observe the state of charge
continuously. Energy management can use behavior planning to proactively sched-
ule future energy demands according to the fulﬁllment of the current task, which
increase the dependability of the mechatronic system (cf. [82]).
Table 3.2 Values for f1 (weighted average body acceleration in m/s2) and f2 (energy con-
sumption in ws) of operation modes derived from the multiobjective optimization of the active
suspension module. (source: [81])
OM Objective Track type
function
I
II
III
IV
V
VI
VII
VIII
IX
X
a f1
0.117 0.233 0.350 0.466 0.583 0.699 0.816 0.932 1.049 1.166
f2
196
393
589
786
982
1179 1375 1572 1768 1965
b f1
0.152 0.304 0.457 0.609 0.761 0.913 1.066 1.218 1.370 1.522
f2
165
329
494
659
823
988
1153 1317 1482 1647
c f1
0.192 0.385 0.577 0.770 0.962 1.155 1.347 1.540 1.732 1.925
f2
142
283
425
567
709
850
992
1134 1275 1417
d f1
0.224 0.449 0.673 0.897 1.122 1.346 1.570 1.794 2.019 2.243
f2
122
245
367
489
612
734
856
979
1101 1224
e f1
0.262 0.523 0.785 1.047 1.308 1.570 1.832 2.093 2.355 2.617
f2
104
208
313
417
521
625
730
834
938
1042
f f1
0.298 0.595 0.893 1.191 1.488 1.786 2.084 2.381 2.679 2.977
f2
87
173
260
346
433
520
606
693
779
866
g f1
0.331 0.662 0.994 1.325 1.656 1.987 2.318 2.649 2.981 3.312
f2
69
138
206
275
344
413
482
550
619
688
h f1
0.375 0.749 1.124 1.499 1.873 2.248 2.623 2.997 3.372 3.747
f2
50
99
149
199
248
298
348
398
447
497
i f1
0.435 0.870 1.305 1.739 2.174 2.609 3.044 3.479 3.914 4.349
f2
27
55
82
110
137
164
192
219
247
274

88
P. Hartmann
Initial
70
60
50
40
30
20
10
0
0.01
0.11
0.2
0.3
0.4
(b)
(a)
2
4
6
8
10
(a) # plans
(b) tresholds
(c) failure in %
a
b
c
d
Initial
Initial
Initial
70
60
50
40
30
20
10
0
0.01
0.11
0.2
0.3
0.4
(b)
(a)
2
4
6
8
10
70
60
50
40
30
20
10
0
0.01
0.11
0.2
0.3
0.4
(b)
(a)
2
4
6
8
10
70
60
50
40
30
20
10
0
0.01
0.11
0.2
0.3
0.4
(b)
(a)
2
4
6
8
10
Fig. 3.27 Percentage of failed execution depending on threshold probability and number
of available alternative plans: (a) Return to standard plan (±0%); (b) No return to stan-
dard plan (±0%); (c) Return to standard plan (±15%); (d) Return to standard plan (+15%)
(source: [81])
3.2.5.4
Application Example
Table 3.2 shows the values for operation modes derived from the multiobjective
optimization from the active suspension module of the RailCab system.
The experiments described here were intended to allow an evaluation of three
hypotheses (cf. [81]). One of these hypotheses in connection with the dependability
was that a lower threshold probability and a higher number of alternative plans in-
creases the reliability of the just-in-case planning ( [82]). The simulated experiments
included four scenarios (source [81]):
1. (±0%): The energy consumptions drawn from track networks were not changed
during simulation.
2. (±15%): The energy consumptions drawn from track networks were either de-
creased or increased by a random value up to 15%.
3. (+15%): The energy consumptions drawn from track networks were always
decreased by a random value up to 15%.
4. (−15%): The energy consumptions drawn from track networks were always
increased by a random value up to 15%.

3 Methods of Improving the Dependability of Self-optimizing Systems
89
The Results are shown in Fig. 3.27 (for a detailed description of the simulation
parameters and the executed scenarious cf. [81]) When regarding the percentage of
failed plan execution during the simulation runs for different scenarios, adjusting the
two parameters threshold value and number of alternative plans reduces the number
of failed plans signiﬁcantly.
3.2.5.5
Further Reading
A detailed explanation of behavior planning for mechatronic systems can be found
in [81,82]. In particular, [82] gives a deeper understanding of the probabilistic plan
structure used in the analysis of the just-in-case planning. The basic methods were
originally published in the dissertation [80], which may also be a good starting point
for further reading.
3.2.6
Computation of Robust Pareto Points
Michael Dellnitz, Robert Timmermann, and Katrin Witting
During the development of self-optimizing systems, the technical system under con-
sideration usually has to be optimized with respect to several different objectives.
Typically, these objectives are in conﬂict with each other, such as safety and en-
ergy efﬁciency, for instance. In mathematical terms, the problems to be solved in
this case are multiobjective optimization problems. Here, the attributes of depend-
ability, in particular safety and reliability, can be considered as objective functions.
The solution to multiobjective optimization problems is given by the set of opti-
mal compromises, the previously introduced Pareto set. The elements of this set
deﬁne the respective status of the system and are called Pareto points. A multiobjec-
tive optimization method is often applied in combination with control engineering
methods. It requires the same information about the models of the dynamics from
the appropriate partial models of the Principle Solution (cf. Sect. 2.1). Of particu-
lar importance is the partial model “System of Objectives”. It contains information
about the relevant objectives which have to be considered to solve the multiobjective
optimization problem.
Both during the system’s design phase and during operation, it is an important
concern to choose a Pareto point which is appropriate for the current system envi-
ronment. For instance, the objective “safety” should receive a higher priority when
a moving vehicle is operating in a rainy or windy environment. Thus, the partial
model “Environment” provides important information on environmental parame-
ters and their ranges which has to be considered in the multiobjective optimization
methods. In general, the choice of Pareto points must be adapted to the variation of
external parameters.
In this section, parametric multiobjective optimization problems are considered
in which an external parameter inﬂuences the system’s behavior; this parameter
may vary during runtime. We introduce here two methods which allow the compu-
tation of so-called robust Pareto points. These points are characterized by minimal

90
M. Dellnitz, R. Timmermann, and K. Witting
variation with respect to changes of external parameters. The ﬁrst method is based
on the calculus of variations; the goal of this method is to identify a Pareto point
which changes very little when the external parameter is varied over an entire inter-
val. The second method is based on numerical path-following techniques. Here, a
local strategy is used in order to update the status of the system in response to the
variation of an external parameter.
3.2.6.1
Prerequisites and Input
Multiobjective Optimization
Consider an unconstrained multiobjective optimization problem (cf. also Sect.
3.2.4.1) which additionally depends on an external parameter λ ∈R. This parameter
is not intended for optimization, but it nonetheless inﬂuences the system objectives.
This unconstrained parametric multiobjective optimization problem can be formu-
lated as
min
y {F(y,λ) : y ∈Rn,λ ∈[λstart,λend]}
where F is deﬁned as the vector of objective functions f1,..., fk,k > 1,
F : Rn × R →Rk,F(y,λ) = (f1(y,λ),..., fk(y,λ))T .
A point y∗∈Rn is called Pareto optimal for a given parameter λ, if there exists no
y ∈Rn with
F(y,λ) ≤p F(y∗,λ) and f j(y,λ) < f j(y∗,λ) for at least one j ∈{1,...,k}.
The set of all Pareto points is the Pareto set. A necessary condition for Pareto
optimality is given by the (in this case parameter-dependent) Kuhn-Tucker equa-
tions (cf. [87]): for each Pareto optimal point y ∈Rn there exists a vector α(λ) =
(α1(λ),...,αk(λ))T ∈Rk with αi(λ) > 0 such that
HKT (y(λ),α(λ),λ) =

∑k
i=1 αi(λ)∇y fi(y(λ),λ)
∑k
i=1 αi(λ)−1

= 0.
(3.17)
The set of all y for which there exists a weight vector α, such that (y,α,λ) is a so-
lution of (3.17), is called the set of substationary points Sλ. In numerical computa-
tions, it is often easier to work with αi = t2
i and solve H(y,t,λ), but both approaches
compute the same set Sλ and thus ti and αi will be used synonymously throughout
this section.
3.2.6.2
Description
In this section, the two methods (relying on variational calculus or numerical path-
following techniques) used here for the computation of robust Pareto points are
introduced in more detail.

3 Methods of Improving the Dependability of Self-optimizing Systems
91
Variational Approach
Our goal is to determine a curve γ(λ) = (y(λ),t(λ))T of minimal length from an
arbitrary starting point on the set of substationary points Sλstart to an arbitrary end
point on Sλend that lies within the λ-dependent set of substationary points. Using
calculus of variations, this problem can be formulated as follows:
min
γ
 λend
λstart
∥y′(λ)∥2 dλ s.t. HKT(y(λ),t(λ),λ) = 0.
(3.18)
This functional calculates the length of the curve y(λ), which is guaranteed to lie
on the set of substationary points.
A necessary condition for the optimality of (3.18) is given by the Euler-Lagrange
equations (cf. [58]). In [151,152]a discrete formulation of the Euler-Lagrangeequa-
tions is described which goes back to [97]. This leads to a system of nonlinear equa-
tions that characterize candidates for robust Pareto points:
HKT(y j,t j,λ j) = 0 ∀j = 0,...,N
μT
j
∂
∂tj
HKT(y j,t j,λ j) = 0 ∀j = 0,...,N
y j+1 −2yj + yj−1
h2
μT
j
∂
∂t j
HKT(y j,t j,λ j) = 0 ∀j = 1,...,N −1
(3.19)
y1 −y0
h2
−1
2μT
0
∂
∂t0
HKT (y0,t0,λstart) = 0
−yN −yN−1
h2
−1
2 μT
N
∂
∂tN
HKT(yN,tN,λend) = 0
where N + 1 is the number of discretization points on the curves y(λ), t(λ) and
μ(λ). μ is the Lagrangian multiplier. This system of equations (3.19) can be solved
using numerical techniques in order to compute robust Pareto points. An applica-
tion of this method for the RailCab’s active suspension system can be found in
Sect. 3.2.6.4.
Numerical Path-Following Approach
Given an initial Pareto set, we investigate if there exist points y ∈Rn that are sub-
stationary points for all λ ∈[λstart,λend]; if this is not the case we investigate which
points y ∈Rn do not vary signiﬁcantly during variation of λ. Analogously, it can be
examined which points vary as little as possible in the respective image space.
Numerical path-following techniques are used to track a Pareto point during vari-
ation of the parameter λ. A predictor-corrector method was adapted to follow a
Pareto point on the set of substationary points S (cf. [3] or [37] for an introduction
to numerical path-following and the predictor-corrector method).
For this task, we are searching for the set of zeros c(s) of a continuous func-
tion H : Rn × R →Rn. The aim of the predictor-corrector method is to calculate a

92
M. Dellnitz, R. Timmermann, and K. Witting
sequence of points (pi,λi), such that H(pi,λi) = 0 for all i = 1,2,.... The numer-
ical procedure consists of two steps, which are executed alternatingly: during the
predictor step, a new point in the vicinity of the zero set is calculated; starting at this
point, a new point on the zero set is calculated in the following corrector step.
Using necessary and sufﬁcient conditions formulated by Luenberger in [96] and
introducing Lagrangian multipliers μ, one can construct a path-following routine to
compute paths containing substationary points for varying values of λ. These paths
are computed in such a way that the distance from the previously computed point
to the next point, which has to lie on the set of substationary points for the new
λ-value, is minimal.
At ﬁrst, a Pareto set for λ = λstart is computed (e.g. using the software GAIO,
cf. [34]); for which t can be computed using the Kuhn-Tucker equations. We initially
set u = (y,t,λ,μ) = (ystart,tstart,λstart,0).
Predictor Step
In this step λ is increased while y, t, and μ are left unchanged
uPred = u+
⎛
⎜
⎜
⎝
0
0
h
0
⎞
⎟
⎟
⎠=
⎛
⎜
⎜
⎝
y
t
˜λ
μ
⎞
⎟
⎟
⎠
where h is an adequately controlled stepsize.
Corrector Step
During the corrector step, ˜λ is ﬁxed and y, t, and μ are adjusted until the point with
minimal distance from the preceding set S˜λ is determined. The minimal distance
computation can be formulated as a zero ﬁnding problem:
HCorr(y,t,μ) =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
∑k
i=1t2
i ∇y fi(y, ˜λ)
∑k
i=1t2
i −1

d(y;yold,λold, ˜λ)
0

−μ1∇(y,t)H1
KT(y,t, ˜λ)...
...−μn∇(y,t)Hn
KT (y,t, ˜λ)−μn+1
⎛
⎜
⎜
⎜
⎝
0
2t1
...
2tk
⎞
⎟
⎟
⎟
⎠
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
= 0
with HKT = (H1
KT ,...,Hn
KT )T. The function d(·;yold,λold, ˜λ) : Rn →Rn is a deci-
sion function, which is deﬁned as
(a)
x →d(x;yold,λold, ˜λ) = 2(x−yold) or
(b)
x →d(x;yold,λold, ˜λ) = 2

∑k
i=1

fi(x, ˜λ)−fi(y0,λold)

∇x fi(x, ˜λ)

.

3 Methods of Improving the Dependability of Self-optimizing Systems
93
The choice of version (a) or (b) depends on the space within which we are seeking
paths of minimal length: if we consider paths of minimal length in pre-image space,
version (a) is used, and if paths of minimal length in image space are considered,
version (b) is used.
The predictor and the corrector step are repeated alternatingly until λ = λend, and
thus a path from Sλstart to Sλend, has been found.
3.2.6.3
Results
Both methods, the variational approach as well as the path-following method, have
been applied very successfully to realistic technical examples. The path-following
approach has been used to compute robust Pareto points for the design of inte-
grated circuits (ICs, cf. [23,151]). In this context, the decision maker is interested in
parameters for the IC design, which result in similar behavior of the IC across a wide
range of external parameters (e.g. temperature or supply voltage); the concept of ro-
bust Pareto points can help identify these parameters. This approach has also been
used to compute robust Pareto points for the RailCab’s active suspension module
in [145]. Another example of a technical application in which we use the variational
approach to compute robust Pareto points is discussed in the following section.
3.2.6.4
Application Example
In [86], the variational method is used to compute robust Pareto points for the Rail-
Cab’s active suspension module (ASM, cf. Sect. 1.3.1.3). An external parameter λ
is used to model the varying crosswind conditions which affect the ASM. In this
example, a simple sky-hook controller is used to control the system. The system
depends on three parameters p = {p1, p2, p3}, which represent the damping of each
degree of freedom of the coach body by the active suspension system. Furthermore,
the two objectives comfort (f1) and energy consumption (f2) for the multiobjective
optimization are deﬁned as
f1,2 : R3 →R,
p →f1,2(p) =
 T
0 y(t)TQ1,2 y(t)dt ,
with positive deﬁnite matrices Q1,2. These objectives depend on the response y(t) of
the linear model of the ASM, which itself depends on the parameters p. The model
is simulated with a ﬁxed excitation u(t) for a constant time T. Additionally, the
crosswind is modeled as a further disturbance z(t). An example crosswind proﬁle is
shown in Fig. 3.28.
We chose N = 10 discretization points from the mean crosswind λ between 0 m/s
and 16.3 m/s. Based on this choice, the values of λ j are given by λ j = 0+ j ·0.163,
j = 0,...,N. In this case, the system of equations (3.19) consists of 99 equa-
tions with 99 unknowns. Solutions were computed numerically using the MATLAB
solver fsolve and are plotted as black points in Fig. 3.29.
The robust Pareto point at (0,0,0) can be easily explained, as one would expect
the energy-optimal solution at this point, regardless of the crosswind. The second

94
M. Dellnitz, R. Timmermann, and K. Witting
Fig. 3.28 One example:
crosswind velocity proﬁle
acting as an external dis-
turbance on the RailCab’s
active suspension module
0
1
2
3
4
5
6
8
10
12
14
Time [s]
Velocity [m/s]
robust Pareto point is nontrivial, though, and was not expected prior to the calcula-
tions. Thus, this provides some additional information about the active suspension
system which might be used for the self-optimization process in future. The avail-
ability of robust Pareto points introduces a classiﬁcation of optimal system conﬁg-
urations that can be used during system operation, for example when dependability
is one of the design objectives.
3.2.6.5
Further Reading
A more detailed explanation of the variational approach can be found in [152],
the path-following method has been published in [35], and the dissertation [151]
gives a comprehensive overview of all topics covered in this section. The exam-
ples of the application of the numerical path-following method have been published
Fig. 3.29 Pareto sets for
three speciﬁc crosswind
values and robust Pareto
points
0
20
40
60
80
0
5
0
1
2
3
4
5
6
7
8
9
 
 
Pareto sets
p3
p2
p1
Without crosswind
Crosswind λ = 8.15
Crosswind λ= 16.3
Robust pareto points

3 Methods of Improving the Dependability of Self-optimizing Systems
95
in [23] (ICs) and [145] (RailCab) and the RailCab example of the variational method
in [86].
3.2.7
Behavior-Based Adaptation of Differing Model Parameters
Bernd Kleinjohann, Lisa Kleinjohann, and Christoph Rasche
As discussed in previous chapters, continuous monitoring and behavior-based adap-
tation of self-optimizing mechatronic systems can considerably increase their de-
pendability. Typically, such complex systems plan their actions as described in
Sect. 3.2.5, for example. During the execution of a previously computed plan, the
environment in which a mechatronic system is active may change in such a way that
unsafe system states occur. Hence, in order to achieve dependability, environmen-
tal changes affecting a self-optimizing mechatronic system have to be taken into
account to prevent system failures.
The method presented in this section has been designed to work with mechatronic
systems that compute plans in order to move from one position to another. These
plans consist of, for example, a set of Pareto points provided by multiobjective op-
timization [34, 135], as described in Sect. 3.2.6 and D.M.f.I.T.S, [55], Sect. 1.2.3.
Similar to planning and multiobjective optimization the behavior-based adaptation
of self-optimizing mechatronic systems is implemented in the Cognitive Operator
of the OCM (cf. Sect. 1.1.1).
To ensure that a mechatronic system is able to move from an initial position
to a destination, several conditions have to be considered. The passengers, for in-
stance, most likely desire a certain level of comfort during operation, while only
limited energy resources are available, and the destination has to be reached at some
given time. These conditions then conﬂict with each other. To ﬁnd optimal solu-
tions, Pareto fronts can be calculated a priori, using a model of the system. Based
on single points of the Pareto fronts, a plan can then be computed which ensures
that all conditions are fulﬁlled as far as possible for the overall plan. Such a plan
consists of several Pareto points, one for each part of the route. It is computed by a
planner such as the one presented in D.M.f.I.T.S, [55], Sect. 5.3.8. Each Pareto point
leads to speciﬁc parameter settings and inﬂuences how well the conditions, whether
of primary importance, such as energy consumption, or of secondary importance,
such as level of comfort, are fulﬁlled.
Computing Pareto fronts is of high computational complexity; therefore, the
computation of the single Pareto fronts, used to determine speciﬁc settings for each
track section, is performed prior to the ﬁrst movement and stored in a database.
This decreases the computational effort needed to compute a plan. The fronts in the
database may be updated due to changing conditions.
As mentioned, the resulting plan is based on precalculated Pareto fronts. Hence,
only the preliminary parameters of the mechatronic system model used to calcu-
late the Pareto fronts could be taken into account while computing a workable plan.
Therefore, deviations between the model or its parameters and the real system can-
not be ruled out. One example is drag, which can lead to an increase or decrease

96
B. Kleinjohann, L. Kleinjohann, and C. Rasche
Fig. 3.30 The line shows
a model Pareto front; the
left point is the Pareto point
selected by the planner. The
right point is the determined
working point, based on the
current measurements.
Pareto front            Pareto point            Measured point
Legend
0.0       0.06        0.12        0.18         0.24       0.3 
f2
0.7
0.56
0.42
0.28
0.14
0.0
f1
in energy consumption of the real system compared to the energy consumption ex-
pected from the model values. To prevent the higher consumption from causing the
mechatronic system to run out of energy before reaching its destination, a change in
the plan has to be performed at runtime, thus possibly preventing a severe failure in
system availability.
Figure 3.30 shows an example of such a case. The line denotes the Pareto front
given by the model values and the point on the front denotes the Pareto point se-
lected by the planner. Each Pareto point has a comfort value, given by the objective
function f1, and an energy consumption value, given by f2. The momentary com-
fort and the energy consumption measured, result in the working point, i. e. the
right point outlined by a circle. While there is only a small change in the energy
consumption, the difference between the measured comfort value and the comfort
value given by the Pareto front differ signiﬁcantly. Such differences can invalidate
the entire plan and a recalculation, based on the newly determined working point,
has to be conducted.
To be able to detect such deviations and to change the plan, several values, such
as energy consumption and passenger comfort, have to be measured continuously
during operation. Based on the measured values, the current working point has to
be calculated. If this working point differs too much from the model Pareto point
which was selected by the planner, replanning is necessary to still be able to fulﬁll
all conditions.
It is not possible to simply compute new Pareto fronts, which would lead to the
measured working point. Each Pareto front is based on several parameters and if
the model Pareto front does not ﬁt the measurements, at least one of the parameters
must have changed to an unknown value. This means that an approximation of the

3 Methods of Improving the Dependability of Self-optimizing Systems
97
model Pareto front using parameter ﬁtting to shift it closer to the measurements has
to be conducted as described in the following sections.
3.2.7.1
Prerequisites and Input
The method Behavior-Based Adaptation of Differing Model Parameters needs sev-
eral inputs. A plan and the corresponding Pareto points for the complete route are
needed. Additionally, the multiobjective functions and the parameter values, used to
compute the Pareto fronts a priori, are needed, as well as the previously calculated
Pareto fronts, in order to compute an initial plan. Computing Pareto fronts is per-
formed by the program GAIO [34,135]. It is also necessary to obtain measurement
data which can be used to determine the current working point, in order to be able
to compare the model Pareto point with the working point to ﬁnd out whether or
how far they differ from each other. In order to obtain the necessary data, the partial
models Environment, Function, Behavior, Active Structure and System of Objectives
from the domain-spanning Conceptual Design Phase (cf. Sect. 2.1) are needed.
3.2.7.2
Description
As mentioned before, the approach described here approximates Pareto fronts, based
on selected Pareto points and moving towards a measured working point. This pa-
rameter adaptation of a Pareto front must only be carried out if, e. g., environmental
changes inﬂuence the self-optimizing system to the point that the initial plan be-
comes invalid. It is possible that an initially computed plan remains feasible during
the entire journey of the mechatronic system to its destination. Adapting the pa-
rameters is costly, and therefore only beneﬁcial if the initially computed plan is
not feasible any longer. This section describes the approach using simple example
objective functions for the computation of Pareto fronts.
In order to keep the description simple, we are assuming two-dimensional Pareto
fronts with one dimension describing the energy consumption and the other dimen-
sion describing the comfort. We assume that a model Pareto point, selected by the
planner, and a working point computed using measured values are given. Such a
working point can easily be computed if it is possible to measure the current energy
consumption and the current comfort.
If these two points are unequal, the model parameters used to compute the model
Pareto point deviate from the actual parameters during operation. This can be for
several reasons, e. g., due to strong headwind, movement in a convoy or changes
of the route. Therefore, the parameters of the multiobjective functions must be
re-determined. We distinguish two different cases that allow us to approximate the
new Pareto fronts by parameter-ﬁtting.
It is necessary to know both the current model Pareto point being used by the
planner and the measured working point. Based on these two points, a part of the
model Pareto front close to the selected model Pareto point is selected and recalcu-
lated in such a way that it it is shifted towards the working point.

98
B. Kleinjohann, L. Kleinjohann, and C. Rasche
Two approaches are presented here. The ﬁrst one directly computes new param-
eter values leading to a Pareto front close to the measured working point. This ap-
proach is efﬁcient, but not universally applicable. The second approach uses Taylor
series to approximate the Pareto front stepwise and shift it towards the working
point.
Parameter Value Determination
If it is possible to determine the changed parameter values, a direct computation is
possible. Assume the example objective functions
Fmodel =

f1(ax2 + bx+ 1)
f2(cx2 + dx+ 4)

(3.20)
were used to calculate model data for a Pareto front. Let a,b,c and d be the param-
eters of the objective functions. The selected Pareto point Fmodel from the Pareto
front, computed using a given model, is selected to be (4,1). We assume now that
the working point Fmeasured = (5,2) has been determined using measured values
from sensors. The variable x is always set to the constant value x0 and only the vari-
ables a,b,c and d can increase or decrease by the values Δa,Δb,Δc and Δd. For
this example, we set x0 = 1. The two functions for the model parameter (p) and the
measured parameter p = p+Δ p are shown in Equation 3.21 and Equation 3.22. The
points used for the description are example points and can take any possible values.
Fmodel(x0, p) = (f1(x0, p1), f2(x0, p2))T = (4,1)
(3.21)
Fmeasured(x0, p) = (f1(x0, p1), f2(x0, p2))T = (5,2)
(3.22)
To obtain the difference between the Pareto point selected by the planner and the
working point calculated using the measured values, the functions can be subtracted
from each other. This subtraction leads to the following equations:
f1(x0, p1)−f1(x0, p1) = 5 −4
f2(x0, p2)−f2(x0, p2) = 2 −1
Inserting the values from the model and the measured values leads to
x2
0(1 + Δa)+ x0(2 + Δb)+ 1 −(x2
0+ 2x0 + 1) = 1
x2
0(1 + Δc)+ x0(−2 + Δd)+ 4 −(x2
0−2x0 + 4) = 1.
This result shows the difference between the two points in the given dimensions.
Simplifying the equations leads to the following notation with the distance between
the two points being (1,1).
x2
0Δa + x0Δb = 1
x2
0Δc+ x0Δd = 1.

3 Methods of Improving the Dependability of Self-optimizing Systems
99
Solving the equations for Δa and Δc gives the notation shown below.
Δa = 1 −x0 ·Δb
x2
0
Δc = 1 −x0 ·Δd
x2
0
These equations are independent,making it impossible to solve them using Gaussian
elimination in order to compute the value changes Δa and Δc. Thus, it is necessary
to set Δb and Δd to ﬁxed values in order to be able to solve the equations for Δa
and Δc.
As mentioned before, this example describes a case for which it is possible to
determine the parameters that have changed. It is assumed that the values a and c
have changed. Additionally, it is assumed that Δb = Δd = 0 for the computation of
the model Pareto front. This leads to:
Δa = 1
x2
0
Δc = 1
x2
0
.
As shown before, x0 is 1, which leads to Δa = 1 and Δc = 1.
It is now possible to compute a new Pareto front using the calculated values
for a and c. This Pareto front includes the computed working point, based on the
measured values. Based on this new parameter, the Pareto fronts for the upcoming
track sections can be calculated and, based on these Pareto fronts, a new plan can be
computed.
One disadvantage of this approach is that it must be possible to determine which
parameter has changed in the objective functions. If this is impossible, multiple so-
lutions exist. Depending on the assumed values for Δb and Δd, the resulting values
for Δa and Δc can be computed. If the assumption is wrong or if the measured
working point is far from optimal, the newly computed Pareto front will not be
close enough to the measured point to achieve dependability. If the objective func-
tions are inﬁnitely differentiable, another approach can be used to approximate the
Pareto front, computed using preliminary parameters close to the measured working
point.
Taylor Series Approximation
In a case where it is impossible to determine the changed parameters of the objective
functions, an approximation using a Taylor Series expansion can be performed to
successively approximate a Pareto front given by model parameters close to a Pareto
front obtained using measured values [95].
Assume the differentiable functions, shown in Equation 3.23, which were used
to compute a model Pareto front:

100
B. Kleinjohann, L. Kleinjohann, and C. Rasche
Fmodel =
f1(cos(a ·x)+ b)
f2(sin(c·x)+ d)

(3.23)
Furthermore, assume that the planner has selected a Pareto point at position (2,3)
and the measured data revealed a working point at position (6,7). The value of x is
always constant. In this example, x0 = 1 is set to a constant value and only the values
of the parameters a, b, c, and d are variable. The equations can now be written as
follows:
Fmodel(x0, p) = (f1(x0, p1), f2(x0, p2))T = (2,3)
Fmeasured(x0, p + Δ p) = (f1(x0, p1 + Δ p1), f2(x0, p2 + Δ p2))T = (6,7).
First, the difference between the two points has to be calculated.
f1(x0, p1)−f1(x0, p1) = 6 −2
f2(x0, p2)−f2(x0, p2) = 7 −3
Let x0 be the Pareto point and let xm be the working point. To move a Pareto point
closer to a working point, each dimension is considered individually. First, a Taylor
series for each parameter (p1, p2) of the multiobjective function is computed, using
the partial derivatives as follows:
Ti(x) = f(x0)+
∂f(x0)
∂xi
1!
(x−x0)+
∂2 f(x0)
∂xi
2!
(x−x0)2
+
∂3 f(x0)
∂xi
3!
(x−x0)3 + ···
Additionally, the differences between the Pareto point and the working point for
each parameter Δ pi = ∥x0 −xm∥i are computed. These differences are used to com-
pute new parameter values pin, as shown in the following equation:
pin = pi + Δ pi
Ti(xm) : Δ pi = {Δ p1,Δ p2}
The Pareto front is then newly computed, based on this new parameters and
the procedure is started over again until no further reduction of the differences is
achieved. The resulting Pareto front is close to the working point and based on the
new environmental parameters. The planner then uses Pareto fronts, based on the
newly determined parameters to conduct a replanning, leading to a new and feasible
path.
3.2.7.3
Results
As result, a new Pareto front can be computed during runtime, using adapted model
parameters. This Pareto front is based on the model parameters which were succes-
sively adapted to approximate the model Pareto point towards a measured Pareto
point by using the objective functions. Based on the new values obtained for the
objective functions, Pareto points for the upcoming track sections can be computed.

3 Methods of Improving the Dependability of Self-optimizing Systems
101
These Pareto points can be used to create a new plan using the planner; this new plan
will then include current real-world measurements, which leads to an optimized plan
for the upcoming track sections and avoids, e. g., an energy consumption that is con-
tinuously too high for reaching the goal position. The approach is costly and should
therefore only be employed if the existing plan becomes invalid.
3.2.7.4
Application Example
The approach has been implemented and several tests have been performed. A
screenshot of the implemented program is shown in Fig. 3.31. It allows the behavior-
based adaptation of differing model parameters for various multiobjective functions.
The measured working points as well as the model Pareto fronts can be selected as
required. The program has also been used to test the combination of the Behavior-
Based Adaptation of Differing Model Parameters and a planning approach, which
is not considererd in this section.
The approach can be applied to single systems (cf. Sect. 1.3.1), as well as to com-
binations of multiple mechatronic systems for which the resulting settings are based
on Pareto points. In general, the approach leads to beneﬁts in all self-optimizing
systems that are based on Pareto fronts, if an adaptation of these fronts is necessary,
e. g., if the system can be inﬂuenced by unpredictable events.
Fig. 3.31 Recalculated Pareto front based on measurement point: the left Pareto front was
given by model parameters and the right Pareto front was approximated using the change
in the corresponding parameter and the Taylor series expansion. The debug view shows the
single parameter settings for the value a to determine the new Pareto front. A measured value
as well as the Pareto point selected by a planner can be entered on the right side of the
program, for which the Pareto front is then approximated.

102
C. Priesterjahn
Fig. 3.31 shows an example of a recalculated Pareto front based on the Taylor se-
ries approach introduced above. The function f1 = cos(a·x)+b represents the energy
consumption, while the function f2 = sin(c·x)+d represents passenger comfort. On
the left side of Fig. 3.31, the axis f1 depicts the current energy consumption and the
axis f2 the current passenger comfort. The planner always receives several Pareto
points – in the presented example 11 different Pareto points – from which it has to
select one for each track segment. In the depicted example scenario, the planner has
selected the Pareto point at position (0.2, 0.04) from the model Pareto front for the
current track section (circled point on the left) in order to achieve the required comfort
without consuming too much energy. The measured data reveals a current working
point at position (0.25, 0.04), visualized by the circled point on the right.
Based on the model Pareto front, a Taylor series expansion is used for stepwise
approximation of the given Pareto front close to the working point, obtained from
measured values. An approximation is performed in order to be able to compute
new Pareto sets online, as the computation of a Pareto front is of high computa-
tional complexity. The passenger comfort is still close to the model Pareto point,
which means that there must be some model deviation, leading to a higher energy
consumption without, however, inﬂuencing passenger comfort. To compute the
model Pareto front, the values a = 0.5 and b = 1 were used to calculate the power
consumption. One of these variables must differ from the model values, for exam-
ple because of headwind. As can be see in the debug part of Fig. 3.31, the value
a has changed, which moves the complete Pareto front. The single values used in
each step are also shown in the debug view. To determine which values have to be
changed, the distance from the measured point to the model point is considered.
In the case presented, the result leads to a value a ≈0.48. Using this value, a new
Pareto front can be approximated which takes changed values, e. g., higher energy
consumption, into account. Based on these new values, the planner is able to re-plan
in order to compute a new consistent plan to the destination.
3.2.8
Analysis of Self-healing Operations
Claudia Priesterjahn
The software in dependable systems must satisfy both safety and liveness properties.
To achieve this, we have utilized a model-based approach for software development
as presented in D.M.f.I.T.S, [55], Chap. 5: a model of the software is constructed, the
model is veriﬁed with respect to safety and liveness properties, and program code is
generated that maintains the veriﬁed properties.
However, random errors may still occur due to the wear of hardware components,
such as sensors, which may affect the software and lead to hazards. Hazards are
considered situations that “together with other conditions [...] will lead inevitably to
an accident” [92]. For example, a speed sensor of the RailCab may fail and lead to
the hazard wrong distance, which may result in a collision.
Hazards cannot be avoided completely. However, for a dependable system, the
developer must guarantee that hazards will only occur with a certain probability. If

3 Methods of Improving the Dependability of Self-optimizing Systems
103
the occurrence probability of a hazard is too high, the system must be redesigned so
that the hazard occurrence probability becomes acceptable [92].
Self-healing (see Sect. 1.1) as a special case of self-optimization may be used to
reduce the occurrence probabilities of hazards in mechatronic systems. We propose
to use the reconﬁguration of the system architecture as a way to stop the propaga-
tion of detected failures before a hazard occurs. This is, for example, achieved by
disconnecting failed system components and shifting to intact components.
For the speciﬁcation of failure propagation, we follow the terminology of Laprie
et al. [11]. Failures are externally visible deviations from the component’s desired
behavior. They are associated with ports where the component instances interact
with their environment. Errors are the manifestation of a fault in the state of a com-
ponent, whereas a fault is the cause of an error. Errors are restricted to the internals
of hardware nodes.
The errors in hardware components may be detected at runtime using, for ex-
ample, model-based fault diagnosis [137]. But the error is not observed directly.
Rather, the detection will observe a failure at the port of the hardware component or
at the port of another component. The errors causing the failure and an appropriate
self-healing operation are stored in a fault dictionary [113]. This fault dictionary
associates failures in the system with sets of errors causing these failures. The fault
dictionary is expanded to include self-healing operations, such that the fault detec-
tion not only identiﬁes the causes of a failure, but also triggers a reaction in form of
a self-healing operation.
Figure 3.32 shows the architecture of a simpliﬁed subsystem of a RailCab that
controls the speed of a RailCab in a convoy (see Sect. 1.3.1). The component
sc:SpeedCtrl represents the speed controller which is responsible for setting the
electric current belonging to the linear drive of the rear RailCab in order to have
the vehicle drive at a speciﬁc speed. The speed controller computes the electric cur-
rent using the distance between the two RailCabs. This distance is provided by the
component ds:DSelect which selects the measured distance from two types of sen-
sors, depending on the quality of their data: a distance sensor dr:DSensor and a
distance computed by dg:DistGPS. dg:DistGPS computes the distance between the
two RailCabs from the position data provided by its gps sensor gps:GPS regarding
the rear RailCab and the front RailCab. The position data of the adjacent RailCab is
provided via wireless network by the components wlan:WLAN and ref:RefData.
An error in the distance sensor dr:DSensor will eventually lead to a failure in the
speed controller sc:SpeedCtrl. In Fig. 3.32, this error is illustrated by a black circle.
Fig. 3.32 Architecture of
the speed control subsystem
gps : GPS o
dr : DSensor
o
dg : DistGPS
ds : DSelect
sc : SpeedCtrl
ref : RefData
wlan : WLAN
o
e

104
C. Priesterjahn
The propagation of the error and the resulting failures is depicted by a gray arrow.
The failure of the speed controller causes the hazard wrong speed. This means the
RailCab will drive at wrong speed, which may result in a collision with another
RailCab in the convoy.
Based on the computed hazard occurrence probabilities and the system architec-
ture, the developer constructs a self-healing operation for the hazard wrong speed.
The self-healing operation is shown in Fig. 3.33; it is triggered when the error
{edr} in the distance sensor is detected. The connectors between ds:DSelect and
dg:DistGPS, and ds:DSelect and sc:SpeedCtrl are removed and, instead, a connec-
tor between dg:DistGPS and sc:SpeedCtrl is created, thereby disconnecting the dis-
tance sensor from the subsystem. Distances are then only measured by GPS-based
position data.
In order to judge whether such a self-healing operation successfully reduces the
occurrence probability of the hazard, we must take into account that the execution
of operations as well as the propagation of failures in a real system take a certain
amount of time. As a consequence, an analysis of self-healing operations must take
the propagation times of failures, the duration of the self-healing operation, and the
change that results from the self-healing operation into account. However, current
approaches that analyze hazard occurrence probabilities in reconﬁgurable systems
do not consider these properties [59,64].
Our solution is an analysis of self-healing operations [122,123] that considers in
particular the timing characteristics of failure propagation and the effect of a self-
healing operation on the propagation of failures.
The self-healing operations are analyzed when the discrete behavior and the re-
conﬁgurations have been speciﬁed and veriﬁed. The models Environment and Ap-
plication Scenarios of the Principle Solution (cf. D.M.f.I.T.S, [55], Chap. 3) are used
to identify hazards. The component structure and behavior models of the MECHA-
TRONICUML (see D.M.f.I.T.S, [55], Chap. 5) are used to derive failure propagation
models. These models are used to compute hazard occurrence probabilities and to
decide which hazard occurrence probabilities need to be reduced via self-healing op-
erations. Then, the self-healing operations are speciﬁed and analyzed as described
in this section.
Fig. 3.33 Timed component
story diagram for healing the
system of a faulty distance
sensor
<<create>>
<<destroy>>
: DSensor
o
: DistGPS
: DSelect
: SpeedCtrl
o
<<destroy>>
[90,115]
disconnectDistSensor()

3 Methods of Improving the Dependability of Self-optimizing Systems
105
3.2.8.1
Prerequisites and Input
Our analysis of self-healing operations requires information about architecture and
behavior of the system, as well as information about the hazards which may occur
in the said system.
The architecture and behavior are speciﬁed by MECHATRONICUML models
(see D.M.f.I.T.S, [55], Chap. 5), which have to be constructed manually by the de-
veloper. This set of MECHATRONICUML models consists of a deployment diagram
specifying the system architecture, the real-time statecharts from the component
instances of the deployment diagram specifying the system behavior, and timed
component story diagrams (TCSD) specifying the self-healing operations. Addition-
ally, real-time statecharts must be deﬁned for the hardware nodes in the deployment
diagram.
The information about the hazard includes a threshold of a hazard occurrence
probability for each hazard that may occur. These thresholds are needed to judge
whether the self-healing operations reduce hazard occurrence probabilities such that
they become acceptable. Further, our analysis requires a set of minimal cut sets
(MCS) [92]; these MCSs specify all combinations of errors that could cause the
hazard. In order to analyze the reduction of the occurrence probability of a hazard,
we need to analyze the self-healing operation for each MCS.
3.2.8.2
Description
Figure 3.34 shows an overview of our analysis of self-healing operations. The re-
quired input models were mentioned in Sect 3.2.8.1.
Before our analysis can be applied, the input models need to be created. Our anal-
ysis uses timed failure propagation graphs (TFPG); which are failure propagation
models with timing annotations. They are generated from the real-time statecharts
of the system components.
After creation of the models, a hazard analysis is carried out to compute the
occurrence probabilities and MCSs of the system’s hazards. Based on the occurrence
Real-time
statechart
TFPGs
e
f
Occurence
probilities
+ MCS
e1
e2 e3
Verdict
Acceptable
hazard
probability
Self-healing
operation
Deployment
diagram
Generate
FPM
Hazard
analysis
Analyze
self-healing
operation
Fig. 3.34 Overview of the analysis of self-healing operations

106
C. Priesterjahn
probabilities, the developer decides which hazards need to be countered by self-
healing. For each of these hazards, the developer constructs self-healing operations.
This is the only manual step.
Then, each self-healing operation is analyzed. The result is a verdict about the
success of the analyzed self-healing operation; it is considered successful if the
occurrence probability of the hazard is below the threshold deﬁned in the safety
requirements.
Timed Failure Propagation Graphs
Tracing a failure in a system is based on failure propagation models. For analyzing
failure propagation times, failure propagation models must include the additional
notion of time. Only then it is possible to check whether a self-healing operation has
been executed quickly enough. Consequently, our analysis of self-healing operations
uses timed failure propagation models called Timed Failure Propagation Graphs
(TFPG). TFPGs, like common failure propagation models [149], deﬁne a cause-
and-effect relation between failures. In particular, TFPGs include propagation time
intervals that specify minimum and maximum propagation times between failures.
The beneﬁt of TFPGs is their minimal level of information needed for the analysis
of failure propagation times. This analysis actually requires taking the reachable
behavior of the whole system into account, which comprises the complete data and
control ﬂow of the system. However, for analyzing the propagation times of failures,
we only need to take the relations between failures at the ports of components into
account. We therefore analyze the reachable behavior of each component type (see
D.M.f.I.T.S, [55], Chap. 5) only once to identify these relations and store them in a
TFPG. During our analysis of self-healing operations, we abstract from the system
behavior using TFPGs.
Failures are classiﬁed using a failure classiﬁcation like the one by Fenelon et
al. [47]. We distinguish the failure classes value, service, early timing, and late
timing. A value failure speciﬁes a deviation from a correct value, e.g., an erroneous
parameter of a message. A service failure speciﬁes that no value is present at all,
e.g., a component crashed and is not providing any output values. A timing failure
speciﬁes that a message has been delivered outside a deﬁned time interval, i.e., too
early or too late.
Figure 3.35 shows the TFPG of the deployment diagram from Fig. 3.32. In
TFPGs, failures are represented by rectangles labeled with the according failure.
Operators are represented by circles labeled with the according logical operator.
Edges are labeled with propagation time intervals that specify the minimum and
maximum propagation time that a failure needs to propagate from the edge’s source
to the edge’s target.
The TFPG of the component instance ds:DSelect from Fig. 3.35 relates the out-
going failure f o
ds3 to the incoming failures f i
ds1 and f i
ds2. The operator OR speciﬁes
that f o
ds3 occurs if either of the incoming failures occurs. The failures of the TFPG
of ds:DSelect are connected to failures of connected component instances according
to the connectors of the deployment. For example, the outgoing value failure f o
ds3 of

3 Methods of Improving the Dependability of Self-optimizing Systems
107
ds:DSelect is connected to the incoming failure f i
sc1 of the speed controller, because
ds:DSelect and sc:SpeedCtrl are connected. The edge is labeled with the propaga-
tion time interval [5,6] of the connector. This edge speciﬁes that the propagation of
a failure from ds:DSelect to the distance controller takes between 5 and 6 time units.
The propagation time interval at the edge from f i
ds2 to the OR-node (see Fig. 3.35)
speciﬁes that a failure needs at minimum 24 and at maximum 28 time units to prop-
agate from the port of the component instance ds:DSelect to the OR-node. The edge
originating from the OR-node has a propagation time interval of [0,0]. This means
that between the OR-node and the outgoing port, failures propagate in zero time.
These time intervals are introduced by automatic generation. Thus, a failure needs
between 24 and 28 time units to propagate from the incoming ports of ds:DSelect
to the outgoing port.
The edges connecting the errors in the hardware components and their outgoing
failures have relatively high propagation times compared to real-life sensors. This is
because we have adjusted these times to reﬂect the fact that sensor failures may not
have an immediate negative impact on the system. If, for example, a sensor delivers
a single peak value, this peak value may be corrected by smoothing the signal using
a low-pass ﬁlter. It is only when the deviation from the correct signal occurs in a
number of subsequent signals that this is interpreted as possibly having an adverse
effect on the system. This fact needs to be taken into account during the analysis
of the self-healing operations because there is more time for the system to react by
self-healing if a controller tolerates a certain amount of deviating values. We call
this time tolerance time.
Fig. 3.35 Timed failure propagation graph of the deployment diagram from Fig. 3.32

108
C. Priesterjahn
In order to take this fact into account in our analysis of self-healing operations,
we include the tolerance time in the TFPG. The tolerance time is computed from
the product of the data rates of sensors and the number of repeated deviations the
controller is able to tolerate. The tolerance time is added to the propagation times
that errors need to propagate to cause a failure at the ports of the sensors.
In order to analyze how far failures propagate within a given time span, we need
to deﬁne a semantics for TFPGs. Therefore, we map TFPGs onto Time Petri Nets
(TPN) [129]. TPNs are marked petri nets [129] with a time extension. Each transi-
tion in the TPN has an interval that speciﬁes its earliest and latest ﬁring time. The
propagation of failures over time is then analyzed by the reachability analysis of
TPNs espoused by Cassez et al. [26].
Generation of Timed Failure Propagation Graphs
The goal of our TFPG generation is to compute relations and propagation times
between incoming and outgoing failures of a particular component type. Figure 3.36
shows an overview of our TFPG generation as published in [119]. The input is the
real-time statechart that speciﬁes the behavior of the component type.
In order to construct the TFPGs, we ﬁrst identify which incoming failures cause
which outgoing failures for each component type. Each time such a relation is iden-
tiﬁed, the propagation times between the related failures are computed and the
relation is stored in a TFPG. This is repeated until all combinations of incoming
failures have been evaluated.
We must distinguish between the identiﬁcation of relationships between outgoing
and incoming timing and service failures on one hand, and outgoing and incoming
value failures on the other hand. Service and timing failures change the control ﬂow
such that either no message is sent, or a message is sent too early/too late. Causes
for these deviations may be that either transitions which should have been ﬁred
could not be activated or that other transitions with other time constraints have ﬁred.
Relations between incoming and outgoing timing and service failures are therefore
identiﬁed by deviations in the control ﬂow.
Real-time
statechart
Identify relations between
incoming and outgoing failures
Service and timing failures
Value failures
e
f
TFPGs
Compute
propagation
times
Fig. 3.36 TFPG generation for a component type

3 Methods of Improving the Dependability of Self-optimizing Systems
109
To provoke these deviations, the control ﬂow is modiﬁed by injecting failures
into the real-time statechart. Failures enter a component via faulty messages; thus,
to inject a timing failure, a message is sent earlier or later than speciﬁed by the
real-time statechart. For a service failure, a message expected by the real-time state-
chart is not sent at all. These modiﬁed messages may change the control ﬂow of the
real-time statechart, allowing outgoing timing and service failures to be identiﬁed
by deviations between the original and the modiﬁed control ﬂow.
Value failures cannot be detected by deviations in the control ﬂow, because even
though the same transition is ﬁred, the values of variables may differ. Consequently,
we need to identify relations between incoming and outgoing value failures from
the data ﬂow.
Identifying relations between incoming and outgoing value failures is based on
the slicing of extended ﬁnite state machines shown by Androutsopoulos et al. [8]. It
is the only approach for slicing nonterminating automata, which makes it the only
approach suitable for embedded real-time systems.
To apply this slicing, we map real-time statecharts onto extended ﬁnite state ma-
chines. The resulting slice is an extended ﬁnite state machine that contains only the
parts of the real-time statechart which affect a speciﬁc variable. To identify which
incoming value failures cause outgoing value failures, we compute the slice of each
variable v sent by the real-time statechart as a message parameter. The remaining
variable assignments are those which inﬂuence v or are inﬂuenced by v.
Analysis of Self-healing Operations
Our analysis of self-healing operations as published in [122, 123] checks for each
MCS of the hazard, whether the MCSs can still cause the said hazard after the self-
healing operation has been completed. MCSs that still cause the hazard after self-
healing are called critical MCSs. If the number of MCSs of the hazard is reduced, the
number of events that cause the hazard will be reduced as well. As a consequence,
the occurrence probability of the hazard is decreased.
The TFPGs which provide the input for our analysis of self-healing operations
have been generated from the real-time statecharts of system components, as ex-
plained above. The TFPGs are used to compute the MCSs and the hazard occurrence
probabilities by the component-based hazard analysis of Giese et al. [59]. Therefore
during this analysis, the timing annotations of the TFPGs are ignored.
Based on the computed hazard occurrence probabilities and the system architec-
ture, the developer constructs a self-healing operation for the hazard. Based on the
real-time statecharts, our analysis computes the critical time. The critical time is the
maximum amount of time between the detection of the error or failure and the last
point in time when the self-healing operation can successfully be executed. This is
the time span during which a failure will propagate through the system before the
self-healing operation has been completed, and may vary within a certain interval
due to system-speciﬁc properties. We take the maximum value of this interval in
order to analyze the worst case: the failures propagate as far as possible.

110
C. Priesterjahn
Next, our analysis computes how far the errors of the MCS have propagated
through the system during the critical time. The result are the errors and failures
which are reachable before the execution of the self-healing operation.
Then, the self-healing operation is applied. It changes the structure of the de-
ployment and thereby the structure of the TFPG. This may cut off propagation paths
along which failures propagate to the hazard, or may remove errors and failures
from the system. The result of this step are the errors and failures that remain in the
system after the application of the self-healing operation.
In the next step, the criticality of the MCS is evaluated based on the errors and
failures which remain in the system meaning that the analysis checks whether the
errors and failures which remain in the system after the application of the self-
healing operation still lead to the hazard. If this is the case, the MCS is critical.
After the criticality of all MCSs has been analyzed, the occurrence probabil-
ity of the hazard is computed based on the critical MCSs. Finally, our analysis
checks whether this computed occurrence probability is acceptable. If it is accept-
able, the self-healing operation has been successful in reducing the hazard. Other-
wise, the self-healing operation has failed and the developer has to either modify the
self-healing operation or utilize another technique to reduce the hazard occurrence
probability.
3.2.8.3
Results
The analysis of self-healing operations is used to implement a system such that all
hazard occurrence probabilities are acceptable. This analysis is used in two ways: It
enables the developer to either guarantee that the self-healing operations will reduce
the occurrence probabilities to an acceptable level or the analysis shows that the
resulting hazard occurrence probabilities are not acceptable. In the latter case, the
developer will change the system and analyze it again. This change may affect all
preceding steps of the development process which have already been carried out
before.
3.2.8.4
Application Example
In our example, the result of the component-based hazard analysis are the mini-
mal cut sets {ewlan}, {egps}, and {edr}, because any of the errors in the hardware
components of the speed control subsystem may cause the hazard. The occurrence
probability of each of the errors is 0.001 leading to the occurrence probability of the
hazard of 0.003.
Based on the computed hazard occurrence probabilities and the system architec-
ture, the developer constructs a self-healing operation for the hazard wrong speed.
The self-healing operation is shown in Fig. 3.33.
Next, our analysis computes how far the errors of the MCS have propagated
through the system during the critical time. In our example, we compute a critical
time of [120,140]. This means the amount of time between the detection of {edr}

3 Methods of Improving the Dependability of Self-optimizing Systems
111
and the completion of the self-healing operation lies between 120 and 140 time
units.
Then, the self-healing operation is applied. Figure 3.37 shows the TFPG of the
speed control subsystem after the application of the self-healing operation. The fail-
ures, which are reachable within the critical time, are highlighted in gray.
The self-healing operation of our example in Fig. 3.33 removes the connectors
between dg:DistGPS and ds:DSelect and between ds:DSelect and sc:SpeedCtrl. It
further creates a connector between dg:DistGPS and sc:SpeedCtrl. By deleting the
connectors, the corresponding edges in the TFPG are deleted, as well. Consequently,
the edges between f o
dg3 and f i
ds2 and between f o
ds3 and f i
sc1 are removed.
In our example, none of the errors and failures which remain in the system after
the application of the self-healing operation can propagate to the speed controller.
The MCS {edr} is consequently not critical.
The critical MCSs after the self-healing operation are {ewlan} and {egps}. These
errors may still cause the hazard.
The reduced occurrence probability of the hazard is p(egps)∨p(edr) = 1−((1−
p(egps))(1−p(edr))) = 1−((1−0.0001)(1−0.0001))= 0.0002. Thus, the occur-
rence probability of the hazard has been reduced below the maximum acceptable
occurrence probability of 0.001.
Fig. 3.37 TFPG after the reachability analysis and the application of self-healing operation

112
C. Priesterjahn
3.2.8.5
Further Reading
Consistency
The architecture of the system is provided by the Conceptual Design Phase (see
Sect. 3.1) in order to guarantee a consistent transition into Design and Development.
For our analysis of self-healing operations, these architecture models are reﬁned and
expanded to include real-time statecharts and reconﬁguration behavior. The system
model is changed if the occurrence probability of the hazard is still too high after
self-healing. These changes are fed back into the models of the Conceptual Design
Phase. This scenario was carried out in the student project "SafeBots II" [9].
Hazard Analysis for the Entire Mechatronic System
For mechatronic systems, uniting four disciplines in one system requires the devel-
opment and analysis of the system as a whole. The key difference between this pro-
cess and pure software architecture is that (hardware) connectors that are connected
to hardware components transport information but also physical items, i.e., material
and energy. The partial model Active Structure (see D.M.f.I.T.S, [55], Chap. 4) spec-
iﬁes the architecture of the entire mechatronic system, including both hardware and
software. Hardware connectors are only represented as simple connections, even
though they may correspond to additional system components. In [121], we present
a component-based hazard analysis that considers the whole mechatronic system,
including hardware connectors, and that introduces reusable patterns for the failure
behavior of hardware connectors which can be generated automatically. In this way,
the component-based hazard analysis of Giese et al. [59] can be applied to the entire
mechatronic system.
Runtime Hazard Analysis
In self-optimizing systems, it is possible that certain system architectures may occur
only at runtime and cannot be foreseen at design time. Consequently, in the domain
of self-optimizing systems, not all system architectures can be analyzed at design
time. In order to still be able to guarantee certain hazard probabilities for the system,
hazard analysis needs to be performed at runtime.
When, for example, RailCabs become ready for the market, they will be produced
by more than one source. In such a case, it is possible that two vehicles must interact
which have been produced by different manufacturers. Of course, it would be useful
for both vehicles to form a convoy to save energy. However, the developer needs to
analyze whether the communication between the two RailCabs does not violate the
safety requirements of either RailCab. This analysis may not have been possible at
design time, because the developer of one RailCab may not have known the system
models of the other RailCab. Such a scenario is one reason to compute the hazard
probabilities of a system at runtime, in order to guarantee safety requirements for
component architectures unknown at design time, as presented in [120,124].

3 Methods of Improving the Dependability of Self-optimizing Systems
113
3.2.9
Safe Planning
Steffen Ziegert
The goal of this method is to provide the self-optimizing mechatronic system with a
means of making decisions autonomously about the application of reconﬁgurations
which affect the system’s architecture. This is an important ability of the system
in connection with the dependability attribute “availability”. By considering safety
requirements when making its decisions, this method also meets requirements of
the dependability attribute “safety”. The method is applied in the software engineer-
ing domain and assumes a prior veriﬁcation of the system’s communication behav-
ior and reconﬁguration operations with the method presented in D.M.f.I.T.S, [55],
Sect. 5.2.3.2.
Adapting to a new situation calls for a number of runtime reconﬁgurations that
may include changes to the system’s architecture, such as the creation and deletion
of component instances or communication links between them. For each conﬁgu-
ration of the system, there may be a large set of applicable runtime reconﬁgura-
tions. Selecting which runtime reconﬁgurations to apply can be a complex task.
Self-optimizing systems often have superordinated goals that are supposed to be
reached during operation, such as optimizing the energy consumption or achieving
user-speciﬁed objectives. These goals have to be taken into account when selecting
which runtime reconﬁgurations to apply. However, selecting runtime reconﬁgura-
tions that are likely to help in achieving the goal is no trivial task. Since the selec-
tion of runtime reconﬁgurations is intended to be autonomous (human intervention
would not meet the response-time requirements of self-optimizing mechatronic sys-
tems), it has to be planned by a software system.
To prevent unsafe conﬁgurations, e.g. an unsafe distance between two RailCabs,
from occurring in a plan, the planning system should further take safety require-
ments into account. The safety requirements restrict the set of valid conﬁgurations,
i.e. they specify which conﬁgurations are not allowed to occur in a resulting plan.
In contrast to the design-time veriﬁcation, where the absence of unsafe states is cat-
egorically guaranteed, this technique allows unsafe states to exist in the reachability
graph, but plans the reconﬁgurations in such a way that no unsafe state is actually
reached.
3.2.9.1
Prerequisites and Input
For this method to be applicable, a set of possible runtime reconﬁgurations has to
be speciﬁed beforehand. This in turn necessitates both the speciﬁcation of the sys-
tem’s structure as a MECHATRONICUML component model (cf. D.M.f.I.T.S, [55],
Sect. 5.2) and the mutual comparison of this component model with the models
used by other methods, encompassing the agreement on a common model for the
rail system. This speciﬁcation is based on the partial models “Active Structure” for
the system’s structure and “Behavior – Activities” for the runtime reconﬁgurations
of the system.

114
S. Ziegert
To meet the safety requirements, a set of forbidden patterns, i.e. the speciﬁcation
of subconﬁgurations that are not allowed to appear in a safe plan, is required. Fur-
thermore, this method requires either a set of initial conﬁgurations given as MECHA-
TRONICUML component instance conﬁgurations when used for simulation or the
capability of perceiving the current conﬁguration of the system when used online.
3.2.9.2
Description
Depending on the application domain, it can be very complicated to guarantee the
absense of all forbidden patterns by means of design-time veriﬁcation (cf. D.M.f.I.
T.S, [55], Sect. 5.2.3.2). The exclusion of a forbidden pattern via design-time veri-
ﬁcation imposes restrictions on the state space of the system, as it is not allowed to
contain states matching the forbidden pattern. This, in turn, transfers these restric-
tions to the design of the application domain’s reconﬁgurations. If these restrictions
prove too cumbersome, we can instead allow the forbidden patterns to appear in the
state space in principle, but plan such that they do not appear on the path to the target
conﬁguration. Of course, when applying the method Safe Planning, we do not need
to take forbidden patterns into account whose absense has already been veriﬁed by
the design-time veriﬁcation.
Problem
Our approach uses graph transformation systems as the underlying formalism. A
graph transformation system consists of a graph representing the initial conﬁgura-
tion of the system, plus a set of graph transformation rules (GT rules). These rules
schematically deﬁne how the graph can be transformed into new conﬁgurations by
means of two graphs, called left-hand side (LHS) and right-hand side (RHS), and
a morphism between them. The morphism identiﬁes the objects and links that are
preserved when the GT rule is applied. Other elements speciﬁed in the LHS and
RHS are deleted and created, respectively, when the GT rule is applied. Syntacti-
cally, such a rule can be represented by a story pattern that integrates the LHS and
RHS into one graph by using stereotypes [51].
To apply a GT rule to a host graph, a match from its LHS to the host graph ﬁrst has
to be found. This match deﬁnes the subgraph of the host graph being manipulated
by the rule application. Note that by ﬁnding multiple matches in the host graph, one
GT rule can spawn multiple graph transformations. In other terms, the GT rule can
be seen as a parameterized action and the graph transformation can be seen as a
grounded action in which the elements of the LHS have been substituted with the
elements from the host graph.
The transition system of the graph transformation system can be constructed by
successively applying the graph transformations to the initial conﬁguration and its
successor conﬁgurations. The planning task is to ﬁnd a path in this transition system
ending in a target conﬁguration. A safe planning task is principally the same, but
includes the requirement that no potentially unsafe conﬁguration is reached.

3 Methods of Improving the Dependability of Self-optimizing Systems
115
We can now give a general deﬁnition of the safe planning problem and relate it
to our modeling approach:
Deﬁnition 3.1. A safe planning problem is a tuple P = (I,A,G,F) where
• I is the initial conﬁguration,
• A is a set of (parameterized) actions,
• G is a goal speciﬁcation that deﬁnes whether a conﬁguration is a target conﬁgu-
ration, and
• F is a safety speciﬁcation that deﬁnes whether a conﬁguration meets the safety
requirements and is allowed in a safe plan.
In our case, the initial conﬁguration corresponds to a UML object diagram that
has been derived from a MECHATRONICUML component instance conﬁguration.
Each parameterized action is given as a story pattern. For a given conﬁguration, the
set of successor conﬁgurations can be computed by matching the story patterns’
LHS’s to the host graph and applying the graph transformations that are deﬁned in
doing so.
The goal speciﬁcation is a function that maps from the set of states to booleans.
Within the context of this method, the goal speciﬁcation is given as a graph pattern,
i.e. a story pattern without a RHS. Each host graph that the pattern matches onto is
a target conﬁguration.
The safety speciﬁcation is also a function that maps from the set of states to
booleans. It is given as a set of graph patterns, called forbidden patterns. If any
one of the forbidden patterns matches the host graph, the host graph is a forbidden
conﬁguration that does not meet the safety requirements. In contrast to the goal
speciﬁcation, the safety speciﬁcation does not map to true, but rather to false when
any pattern matches.
Solution
Different algorithms and techniques exist to solve these planning tasks. One of the
approaches is to translate the planning problem into an input for available off-the-
shelf planning system. These traditional planning systems, however, work on mod-
els which are different from graph transformation systems. They are used for models
with ﬁrst-order literals that are usually compiled into a propositional representation
by grounding predicates and actions. While a translation is technically possible,
there are some restrictions because typical planning languages, such as the Plan-
ning Domain Deﬁnition Language (PDDL), which is the current de facto standard
in academia, have a different expressive power than graph transformation systems.
Today’s proposed translation schemes [100, 144] do not support arbitrary negative
application conditions and cannot work with an unlimited number of objects. For
instance, a planning model designer would have to specify the maximum number
of objects beforehand. Howver, this number is not necessarily ﬁnite. By planning
directly within the transition system deﬁned by the graph transformation system,
we avoid these problems.

116
S. Ziegert
For planning with graph transformations, we have developed two approaches that
complement each other. The ﬁrst approach diverts a model checker from its intended
use of searching for a counterexample of a given property [132]. It plans by refor-
mulating the planning problem into a model-checking problem and then asking a
model checker to verify the property that no plan exists. If the property is false, i.e.
a plan exists, the model checker delivers a plan as counter example of the prop-
erty. While this approach is very generic and fully automatic, it is not competitive
in terms of speed and quality compared to other planning techniques because the
state space search of a model checker is generally not optimized for planning, i.e.
for ﬁnding a plan quickly or for ﬁnding a short plan.
Our second approach is based on heuristic search. We use search algorithms like
A* or Best First (cf. [134]) with a domain-speciﬁc heuristic to search through the
state space. The advantage of this approach is at the same time its disadvantage:
on the plus side, this planning technique uses guided search, which is in general
faster than the model-checking-based approach; however, the disadvantage is that
a heuristic suitable for the given application domain ﬁrst has to be developed. A
solution to this problem is to learn heuristic functions automatically [44]. A learning
algorithm derives a regression function that predicts the costs of solving the problem
from a given state. To derive the regression function, the learning algorithm needs
a pre-deﬁned declaration of state features and a training set with problem instances.
While this solution is an improvement over developing heuristic functions manually,
it still requires the developer to declare a set of state features that is suitable for the
given application domain. To overcome this issue, we are currently investigating the
use of domain-independent heuristics for planning with graph transformations.
Both approaches support forbidden patterns and thus are capable of solving
the safe planning problem. In the model-checking-based approach, the problem is
solved by including the safety requirements into the property to be veriﬁed. Now
the property states that no safe plan exists, i.e. there is no path to a goal state free
of intermediate (on-the-way) states containing forbidden patterns. Thus, the model
checker must also consider whether any state on the path to the goal state contains
a forbidden pattern. In the heuristic search-based approach, checking for forbidden
patterns is simply integrated into the search algorithm.
Translations into dedicated planning languages do not support forbidden patterns
at the moment. Although planning languages which support constraints exist, trans-
lation schemes do not yet support the translation of forbidden patterns into such
constraints. Proposed translation schemes [100,144] only support the translation of
GT rules into the action representations known from PDDL. As remarked above,
their capability to support negative application conditions is also limited.
Which one of the two approaches to planning with graph transformations is
preferable, depends on the application domain. If the application domain allows
for a straightforward design of a suitable heuristic using human intuition, or
provides a meaningful set of state features to derive a heuristic function using
machine learning techniques, then the heuristic search is to be preferred. If, how-
ever, the domain does not provide a meaningful set of state features, meaning that

3 Methods of Improving the Dependability of Self-optimizing Systems
117
heuristic knowledge is not easy to obtain, then the model-checking-based planner
might be the better choice.
3.2.9.3
Results
The result of the integration of this technique into the Operator Controller Module
(cf. Sect. 1.1.1) is its ability to autonomously plan which runtime reconﬁgurations
to execute for a given state of the system. The planning process itself is performed
by the Cognitive Operator of the OCM. The outcome of this process is a plan, i.e. a
sequence of graph transformations, to reach a target conﬁguration. These resulting
runtime reconﬁgurations are executed by the Reﬂective Operator of the OCM.
Since the planning process considers safety requirements in the form of forbidden
patterns, the Reﬂective Operator is guaranteed not to execute any runtime reconﬁg-
urations leading to a dangerous situation.
3.2.9.4
Application Example
A real-time coordination pattern represents a communication protocol between sub-
systems that is speciﬁed by real-time statecharts (cf. D.M.f.I.T.S, [55], Sect. 5.2.1).
We use the activation and deactivation of real-time coordination patterns in the Rail-
Cab system (cf. Sect. 1.3.1) as an Application Scenario. In this scenario, the railway
network consists of a set of tracks that are connected via successor links. Each track
is further monitored by one or more base stations. A RailCab has to register itself
at such a base station in order to continuously provide information about its exact
position and enable itself to request information about the properties of the track
segment (cf. D.M.f.I.T.S, [55], Sect. 2.1.6).
An initial conﬁguration is given in Fig. 3.38. It shows two RailCabs on a track
that belongs to the station Paderborn and a railway network that connects this station
to the stations Berlin and Leipzig.
The story patterns specify the runtime reconﬁgurations that allow the transforma-
tion of this conﬁguration into the target conﬁguration. One of these story patterns,
the story pattern cPublication, is shown in Fig. 3.39.
It speciﬁes the creation of a real-time coordination pattern between a RailCab
and a base station under the condition that the RailCab is occupying a track segment
monitored by the base station. For unregistering a RailCab there is a similar story
pattern called dPublication. In addition to the story patterns for registering and un-
registering a RailCab at a base station, there are story patterns for moving a RailCab,
initiating the formation of dissolving of a convoy of RailCabs, joining and leaving
a convoy, and moving a convoy.
One of the safety requirements for this application scenario states that a Rail-
Cab may not operate in a convoy if it holds dangerous cargo. This requirement is
formalized by the forbidden pattern dangerInConvoy which is shown in Fig. 3.40.
Other requirements state that there may be no collision or a distance small enough
to be unsafe between two RailCabs, and that a RailCab may not be registered at an

118
S. Ziegert
Berlin:Station
r1:RailCab
r2:RailCab
t7:Track
bs1:BaseStation
bs2:BaseStation
t6:Track
t1:Track
t2:Track
t3:Track
t4:Track
t5:Track
Paderborn:Station
bs3:BaseStation
t8:Track
Leipzig:Station
next
next
next
next
next
next
next
on
on
monitors
monitors
monitors
monitors
monitors
monitors
monitors
monitors
monitors
monitors
contains
contains
contains
Fig. 3.38 An initial conﬁguration given as a UML object diagram derived from a MECHA-
TRONICUML component instance conﬁguration
incorrect base station, i.e. a base station that does not monitor the track segment the
RailCab is occupying.
Given a goal speciﬁcation, e.g. a graph pattern which states that the RailCab
r1 is occupying a track segment connected to Berlin and r2 is occupying a track
segment connected to Leipzig, this model can be fed into one of the planning systems
introduced above. The planning system then directly plans in the transition system
corresponding to the given model. Therefore, no translation to a dedicated planning
language and thus no restriction on the expressive power of graph transformation
systems is necessary. Unsafe conﬁgurations are recognized by the planning system
and not allowed in a valid plan. The resulting plan speciﬁes a sequence of runtime
reconﬁgurations that safely turn the system from its initial conﬁguration into a target
conﬁguration.
Fig. 3.39 A story pattern
specifying the instantiation
of a real-time coordination
pattern for the communica-
tion between a RailCab and
a base station
«++»
:Publication
:RailCab
:Publication
:BaseStation
:Track
on
monitors
«++»
publisher
«++»
distributor
publisher

3 Methods of Improving the Dependability of Self-optimizing Systems
119
Fig. 3.40 A forbidden pat-
tern that prohibits a Rail-
Cab’s inclusion in a convoy
if it holds dangerous cargo
:Convoy
:RailCab
:DangerousCargo
member
carrier
3.2.10
Veriﬁcation for Interacting Mechatronic Systems with
Motion Proﬁles
Kathrin Flaßkamp, Christian Heinzemann, Martin Krüger, Sina Ober-Blöbaum,
Wilhelm Schäfer, Dominik Steenken, Ansgar Trächtler, and Heike Wehrheim
The method is intended to verify the correctness of the behavior of interacting
self-optimizing mechatronic systems in speciﬁc Application Scenarios. Veriﬁcation
methods play a crucial role in ensuring dependability, most importantly the attribute
“safety”, in a technical system. In this section, we present an ofﬂine veriﬁcation
method which is applied during the development phase of the system. It requires
input from several partial models of the Principle Solution (cf. Sect. 2.1), as the
dynamical (time-discrete and time-continuous) behavior can be derived from the
partial models “Behavior” and “Active Structure”, in some cases in combination
with the “Environment” model. Certain details of our veriﬁcation method have to
be adapted to the speciﬁc scenario chosen from the list of relevant scenarios stored
in the partial model “Application Scenarios”; for example, we will use a speciﬁc
convoy braking scenario in the following. Motion proﬁles which abstract the con-
tinuous time behavior can be computed via multiobjective optimization to take into
account objectives from the partial model “System of Objectives”.
A central aspect of mechatronic systems is their hybrid nature, i.e. they have
continuous (formalized, e.g., by differential equations), as well as discrete (formal-
ized, e.g., by timed automata) behavior. Most state-of-the-art modeling approaches
which deal with such hybrid systems use formalisms such as hybrid automata [69].
In doing so, they move into areas of complexity that make veriﬁcation impossible
or at least unfeasible, except for tiny “toy” examples [5]. In contrast, our approach
relies on so-called motion proﬁles that fulﬁll a given set of properties. A motion pro-
ﬁle is essentially a curve or set of curves that shows the development over time of
physical parameters describing the motion of the vehicle. These motion proﬁles can
be generated with simulation and optimization methods which use models of the
system’s dynamics. The distribution of these motion proﬁles can be modeled with
(timed) discrete formalisms that can be veriﬁed with much less effort. Correctness
is implied if the distribution satisﬁes certain constraints, based on the properties of
the proﬁles.
The veriﬁcation of a behavior speciﬁcation based on motion proﬁles seems es-
pecially suitable for interacting mechatronic systems. Classically, the dynamics of
each individual system is controlled by a feedback / feedforward control strat-
egy based on a model of the time-continuous dynamics. In addition to this, the

120
K. Flaßkamp et al.
interaction of the systems is speciﬁed by a communication protocol in terms of
discrete automata that have to be checked for correctness using formal veriﬁcation
techniques. For illustration, we will continuously refer to the example of a convoy
of RailCabs (cf. Sect. 1.3.1) throughout this section.
The method described in this section provides the user with tools and proces-
ses that allow the correct implementation of motion proﬁle creation, distribution
and usage. There are two substantially different ways to approach proﬁle creation
and distribution: online generation and ofﬂine generation. While we will mainly fo-
cus on ofﬂine generation in this text, we will also give a short overview of online
generation.
In ofﬂine generation, each RailCab is equipped at the time of design with a set of
motion proﬁles for every maneuver it will need to perform in the future. Based on
analytical functions comparing two motion proﬁles, a communication protocol dis-
tributes the available motion proﬁles and determines which of these motion proﬁles
is active for any given maneuver at runtime. Both the analytical functions and the
communication protocol can be veriﬁed at design time. The following subsections
will go into some detail of ofﬂine proﬁle generation, the analytical functions, the
communication protocol and its veriﬁcation.
In contrast, for online generation, the RailCab is only equipped with some basic
physical information about itself at design time. At runtime, motion proﬁles are
generated on the ﬂy when the situation is about to change, for instance when the
RailCab is about to enter a convoy. From environmental data and the physical data
about the RailCab, new instances of prepared constraints are derived for motion
proﬁles for each maneuver that will be affected, and proﬁles are constructed that ﬁt
these constraints. Once all proﬁles are complete, the RailCab can proceed; it will
either enter the convoy, or will be forced to abort if one of the computations fails to
come up with a valid proﬁle in time.
3.2.10.1
Application Example
The example we will use to illustrate this method is convoy maintenance; the partic-
ular situation under consideration is that a RailCab wants to join an existing convoy
(see Fig. 3.41). In such a situation, multiple motion proﬁles have to be chosen and
exchanged; for the sake of simplicity, however, we will focus on only one of them:
controlled braking. This motion proﬁle is responsible for the controlled stop at a
train station or switch. In convoy mode, it is of great importance that the braking
proﬁles present in the convoy are compatible with each other; if one of the RailCabs
were to decelerate faster than the RailCab following it, they would collide.
Thus, for a candidate position in the convoy, the joining RailCab must choose a
proﬁle that is compatible (as described in Proﬁle Compatibility, Sect. 3.2.10.3) with
the proﬁle of the RailCab preceding it and the proﬁle of the RailCab following it.
From our point of view, this means that the RailCab must choose a proﬁle for which
the analytical function mentioned above indicates that it is compatible with the two
motion proﬁles concerned. If there is no such proﬁle for any position in the convoy,
then the RailCab cannot safely enter the convoy and must abort the process.

3 Methods of Improving the Dependability of Self-optimizing Systems
121
Fig. 3.41 The convoy merging scenario
In all, three components inﬂuence the correctness of the process that assigns mo-
tion proﬁles: the selection of proﬁles with which a RailCab should be equipped,
the analytical function used for comparing proﬁles and the communication protocol
used for distributing proﬁles in a convoy.
The crucial steps of the method involving ofﬂine proﬁle generation are the fol-
lowing:
1. generation of proﬁles,
2. design of the communication protocol for distributing the proﬁles,
3. veriﬁcation of the communication protocol,
4. modeling of the compatibility function,
5. checking the proﬁle compatibility, and
6. distribution of proﬁles.
Steps 1-4 are performed at design time, while Steps 5 and 6 are performed at
runtime. We will touch on each of these subjects in turn in the following sections.
3.2.10.2
Prerequisites and Input
For ofﬂine proﬁle generation, the following pieces of information are required at
design time:
• The full range of the physical parameters of the RailCab relevant to its dynamics,
such as mass, external dimensions, motor strength, etc., together with a model
that describes its continuous time dynamics
• A description of every behavior (maneuver) the RailCab may engage in during
runtime, such as entering convoys, leaving convoys, allowing others to enter,
stopping at train stations, etc.

122
K. Flaßkamp et al.
• A mathematical formulation of the set of objectives related to these different
behaviors, such as, for example, minimizing energy consumption, minimizing
travel time or maximizing passenger comfort
3.2.10.3
Description
Proﬁle Generation
To begin with, a set of proﬁles has to be generated for each RailCab. This can be
done using model-based optimization techniques, such as optimal control, for the
computation of optimal braking maneuvers. This process is dependent on a number
of different parameters that can be categorized as
constant parameters:
These parameters do not vary during operation of the RailCab. An example of
such a parameter is the physical shape of the RailCab.
discrete parameters:
These parameters span a ﬁnite set of values – each combination of such param-
eters necessitates at least one motion proﬁle per maneuver. One such instance of
discrete partameters could be a predeﬁned (small) number of different cruising
speeds of convoys.
continuous physical parameters:
These parameters change from one operation to the next and span a subset of the
real numbers, an example of this type being the RailCab’s mass. They have to be
discretized into regions.
objectives’ priority parameters:
These continuous parameters weight the objectives and may vary during opera-
tion of a self-optimizing system. For a ﬁnite set of motion proﬁles, only a small
number of representatives of Pareto optimal regions are chosen.
inﬁnite control parameters (trajectories):
For speciﬁed maneuvers, time-dependent control trajectories are required that,
for instance, guarantee braking that fulﬁlls prescribed conditions (e.g. braking
time and distance). These curves have to be approximated by a ﬁnite number of
continuous parameters in order to apply numerical optimization methods.
The (continuous time) dynamical behavior of mechatronic systems is typically
modeled by ordinary differential equations of the form ˙x(t) = f(x(t),u(t)). Here,
x(t) denotes the physical state of the system and u(t) the time-dependent control
inputs, such as the braking forces. The function f is comprised of the physical prin-
ciples drawn on in the technical system’s model. These physical laws in turn depend
on different kinds of parameters (constant, discrete or continuous). We assume that
the continuous parameters can be quantized into regions for proﬁle generation. In
a real application, due to model discrepancies, optimal proﬁles would be combined
with an underlying time-continuous controller. Thus, moderate additional deviations
resulting from the quantization could be compensated for by this controller.
For convoy braking strategies, the vehicle mass can be examined to illustrate an
example of a continuous parameter. In passenger as well as in freight RailCabs,

3 Methods of Improving the Dependability of Self-optimizing Systems
123
mass can vary widely and does so in a continuous fashion. Each RailCab possesses
an underlying lateral controller, which is crucial for traveling in convoys. Among
others, this requires a large safety margin between the RailCabs. The controller
ensures that the system maintains the optimal feedforward trajectory as long as the
current RailCab mass deviates only slightly from the parameter value assumed in
the model. An additional, smaller, safety margin in the compatibility function takes
into account unavoidable deviations.
The feedforward optimal trajectories are solutions to optimal control problems.
Such an optimal control problem is formally stated as
min
u(t),T J(u(t),T) =
 T
0 C(u(t))dt
(3.24)
with respect to
˙x(t) = f(x(t),u(t)), x(0) = x0, x(T) = xT and 0 ≥g(x(t),u(t))∀t ∈[0,T]. (3.25)
J(u(t),T) is the objective that has to be minimized and depends both on the control
trajectory and on the ﬁnal time of the control maneuver. The equations of motion,
i.e. the ordinary differential equations, appear as constraints on the optimization
problem. Boundary constraints are given by initial and ﬁnal states x0 and xT, for
instance the convoy speed at the beginning of the braking maneuver and the prede-
ﬁned braking distance at its conclusion. Additional constraints, e.g. bounds on the
braking forces, can be modeled in the function g.
Self-optimizing systems possess several optimization objectives that may be-
come relevant during operation. This leads to multiobjective optimization problems
(cf. D.M.f.I.T.S, [55], Sect. 1.2.3) which result in Pareto sets of optimal compromises
between the concurring objectives. Therefore, our method includes the computation
of a knowledge base of several Pareto optimal solutions corresponding to varying
prioritizations of the objectives. We consider the objectives “optimize passenger
comfort” (by minimizing acceleration) and “minimize braking time”.
In real applications, optimal control problems have to be solved numerically. One
class of numerical methods is based on direct discretization of the optimal control
problem, by which, the original problem is transformed into a nonlinear restricted
optimization problem that can be addressed by state-of-the-art software. Discretiz-
ing the optimal control problem means approximating the control trajectory with a
relatively small number of continuous parameters. By using numerical integration
schemes for the model simulations, the system’s states can be discretized as well.
For the example application, optimal control trajectories for different RailCabs
are computed. All of them are restricted by maximum control forces (40kN for a
passenger RailCab and 80kN for a freight RailCab), a convoy speed of 30m/s and
a desired braking distance of 350m. In Fig. 3.42, examples of braking trajectories
for a freight RailCab are shown. Each control trajectory is deﬁned by ﬁve points
(equidistant in time) that are turned into a continuous signal via linear interpola-
tion. This deﬁnes the input given to the system’s dynamical model, by which the
corresponding optimal state trajectories are generated.

124
K. Flaßkamp et al.
0
5
10
15
20
25
30
0
2
4
6
8
x 10
4
Time [s]
Braking force [N]
 
 
90% comfort
30% comfort
20% comfort
10% comfort
0% comfort
0
5
10
15
20
25
30
0
100
200
300
400
Time [s]
Longitudinal position [m]
 
 
 
90% comfort
30% comfort
20% comfort
10% comfort
0% comfort
Fig. 3.42 Optimal control trajectories depending on an objective’s priority ranking (top) and
the resulting position trajectories (bottom)
Proﬁle Compatibility
When a RailCab is traveling alone, i.e. not in a convoy, it can freely choose among
the available motion proﬁles for each maneuver. This is because any condition that
could invalidate a motion proﬁle in such a situation would have been noted at de-
sign time and thus would have been removed (or rather, not been constructed in
the ﬁrst place by the optimal control algorithm). Therefore, the only safety-relevant
restrictions that apply to the choice of a motion proﬁle at runtime derive from the
interaction of motion proﬁles from different RailCabs.
The most obvious example of such a situation is convoy travel. Each RailCab
must choose motion proﬁles that fulﬁll certain compatibility criteria with respect
to the motion proﬁles of RailCabs it will directly interact with, i.e. the RailCabs
preceding and following in the convoy. One of the central ideas of this method
is to encapsulate these compatibility criteria in simple algorithms (the analytical
functions) to compare two motion proﬁles to each other.
These analytical functions have to return a boolean value, i.e. two proﬁles are
either compatible or they are not. Furthermore, they have to be transitive, meaning

3 Methods of Improving the Dependability of Self-optimizing Systems
125
that, if proﬁle f is deemed compatible with proﬁle g, and g is deemed compatible
with proﬁle h, then f must also be compatible with h. The analytical functions do
not, however, have to be symmetric. Thus, even if f is compatible with g, g does
not necessarily have to be compatible with f. This enables us to take the ordering
of RailCabs on the tracks into account.
For each maneuver (e.g. controlled braking) and each situation (e.g. convoy
travel), such an algorithm must be created. For controlled braking of a RailCab in
a convoy, the required algorithm is fairly simple: assuming the minimum distance
required for convoy travel, and taking into account the dimensions of each RailCab,
do the adjacent RailCabs get closer to each other than a given minimum distance?
This algorithm can easily be implemented by slightly modifying each motion proﬁle
to compensate for distance and form, subtracting the results and seeing if they ever
drop below the safety margin. If so, the motion proﬁles are deemed incompatible; if
not, they are compatible. This process is shown in Fig. 3.43.
Consider again our example of controlled braking maneuvers. It should be clear
that if the motion proﬁle of the RailCab joining the convoy is compatible with the
motion proﬁles of both the preceding and following RailCabs, then adding the Rail-
Cab at that position will not make the controlled braking maneuver unsafe.
Thus, the question of whether the convoy will be able to safely execute maneu-
vers after the additional RailCab is added at the speciﬁed position is reduced to the
question of whether the motion proﬁles are distributed in such a way that consecu-
tive proﬁles for the same maneuver are always compatible.
Proﬁle Distribution
In this method, correct distribution of motion proﬁles is ensured by communication
protocols modeling message exchange between RailCabs. These communication
protocols are executed before a RailCab enters a new situation, such as a convoy.
First, the RailCab wishing to enter a convoy sends the set of its proﬁles to the convoy
coordinator. Secondly, the convoy coordinator searches for a position where the
RailCab may enter the convoy and which proﬁles it needs to use when doing so.
Distance function
Safety margin
Profile
Vehicle length
Time
Distance
F
r
o
n
t 
R
ai
l
C
a
b
R
e
ar
 R
ail
Ca
b
Fig. 3.43 Comparing two motion proﬁles with regard to minimum distance

126
K. Flaßkamp et al.
We specify the communication protocol using real-time coordination protocols
of MECHATRONICUML ( D.M.f.I.T.S, [55], Sect. 5.2, [42]). Real-time coordination
protocols use a state-based behavior speciﬁcation technique called real-time state-
charts to deﬁne this message exchange. Real-time statecharts are a combination of
UML state machines [110] and timed automata [6] that enables the veriﬁcation of
real-time coordination protocols for safety and liveness properties.
In our example scenario, we have modeled the message exchange between a sin-
gle RailCab attempting to join a convoy and a convoy of up to ﬁve other RailCabs.
The modeling guidelines of MECHATRONICUML impose the restriction that the
convoy coordinator is connected to all convoy members, but the convoy members
are not connected to each other. This restriction enforces a kind of star topology
(see Fig. 3.44). Fig. 3.45 shows the real-time statechart of the convoy coordinator.
At runtime, the convoy coordinator has one thread executing the behavior deﬁned
by the real-time statechart adaptation. The convoy coordinator has one additional
thread for each convoy member; this thread executes the behavior deﬁned by the
real-time statechart sub-role.
The manner in which the protocol implemented by these real-time statecharts
works is loosely explained in the following. RailCab (A) wants to join a convoy led
by RailCab B; it contacts B and proposes a merging maneuver using the message
requestConvoyEntry. B either rejects the proposal outright (this may happen due to
economic or safety reasons) by sending declineConvoyEntry or otherwise requests
the set of all proﬁles that A possesses for all relevant maneuvers (using among others
the messages startProﬁleTransmission and proﬁle). A sends this information. Then,
B invokes the operation calculateProﬁles (circled in Fig. 3.45), which iterates all
possible entrance positions for A. For each position, B goes through all maneuvers
and checks whether A possesses a proﬁle for every maneuver that is compatible with
the proﬁles of the adjacent RailCabs for the corresponding maneuvers using the an-
alytical functions. If possible entrance positions exist, B will use a heuristic to select
one of them. The selected position is stored in the variable newRailCabPosition
while the selected proﬁles are written to the variable currentProﬁles. B sends the
position and the selected proﬁles to A using the message enterConvoyAt; A can then
Convoy coordinator
Convoy member 1
Convoy member 2
Convoy member 3
Fig. 3.44 The communication structure in the Convoy Merging example

3 Methods of Improving the Dependability of Self-optimizing Systems
127
ProfileTransmission_coordinator
ProfileTransmission_Coordinator_Main
adaptation
Idle
NewQuery
newMember? /
{createSubRoleInstance()}
sub-role
1
2
ch: newMember, newMemberPossible, entryFail, entrySuccess, requestPosition, enterAt,
sendNewProfile[Role], finished[Role];
clock: c;
clock: c_inv;
var: int n, bool memberPossible, int requestedPosition, int newRailCabPosition,
Profile newProfile, Profile currentProfiles[], Profile[][] allProfiles;
op: bool isMemberPossible(), bool calculateProfiles();
HandleNewMember
NewMember
Calculate
newMemberPossible? /
{memberPossible := isMemberPossible ( ) }
[not memberPossible] entryFail! /
[memberPossible]
entrySuccess! /
requestPosition? /
{calculateProfiles()}
[newRailCabPosition >= 0] enterAt! /
[newRailCabPosition< 0]
entryFail! /
Idle
Request
requestConvoyEntry
newMemberPossible! /
{requestedPosition :=
requestConvoyEntry.position}
EntryPossible
entrySuccess? /
approveConvoyEntry()
entryFail? / declineConvoyEntry()
Perform
Transmission
startProfileTransmission /
{i:=0;} readyForProfileTransmission()
Profiles
Received
endOfProfileTransmission
requestPosition! /
Wait
Convoy
enterAt? / {newPos := newRailCabPosition}
enterConvoyAt(newPos, newProfile)
clock: c;
var: int newPos;
acceptPosition /
startConvoy()
entryFail? /
declineConvoyEntry()
profile /
{allProfiles[n-1][i] := profile.p; i := i+1;}
profileReceived()
Fig. 3.45 Real-time statechart of the convoy coordinator
initiate the merging maneuver. If no locations have been deemed safe, A’s proposal
is rejected and the process ends.
The operation calculateProﬁles of the real-time coordination protocol calls the
implementation of the analytical functions as an external method. The veriﬁcation of
the real-time coordination protocol thus guarantees the following: If the analytical
functions are correctly implemented, i.e. they return true if and only if the given
proﬁle combination is safe from a mathematical perspective, then the distribution of
motion proﬁles across a convoy performed by this real-time coordination protocol
guarantees safe operation of the convoy as a whole.
The MECHATRONICUML model of the communication protocol can be used as
an input for formal veriﬁcation using, for example, the design-time veriﬁcation in-
troduced in D.M.f.I.T.S, [55], Sect. 5.2.2, or the timed model checker UPPAAL [16].
We have veriﬁed the model for a convoy of 5 RailCabs; we have also successfully
formalized and veriﬁed the following properties given in natural language using
UPPAAL.

128
P. Reinold et al.
• The real-time coordination protocol is free of deadlocks.
• If a RailCab sends requestConvoyEntry to the coordinator, it receives a startCon-
voy message or a declineConvoyEntry message eventually.
• If a sub-role statechart is in state convoy, then the corresponding convoy member
is also in state convoy.
The restriction to a convoy of 5 RailCabs is a result of limitations in the model
checker UPPAAL. It is not imposed by the method itself.
3.2.10.4
Results
The ﬁrst result of this method is a set of motion proﬁles for every maneuver in
the input; another result is the implementation of a set of analytical functions for
comparing said proﬁles. Finally, the method results in a model of a real-time co-
ordination protocol designed to distribute the proﬁles across a convoy according to
compatibility constraints.
3.2.10.5
Further Reading
The application of the veriﬁcation method with motion proﬁles is described in [52].
An introduction to multiobjective optimization and optimal control is given in D.
M.f.I.T.S, [55], Sect. 5.3, including a number of example applications. An introduc-
tion to MECHATRONICUML is given in D.M.f.I.T.S, [55], Sect. 5.2; the complete
speciﬁcation of the MECHATRONICUML method is available in [15].
3.2.11
Dependability-Oriented Multiobjective Optimization
Peter Reinold, Walter Sextro, Christoph Sondermann-Woelke,and Ansgar Traechtler
The goal of this method is to evaluate the dependability of a self-optimizing system
by considering one or several dependability-oriented objectives in a multiobjective
optimization process. The Multi-Level Dependability Concept (M-LD Concept) de-
scribed in Sect. 3.1.2 is used to deﬁne the necessary weighting of dependability-
oriented objectives. With this concept, it is possible to weight or prioritize objectives
related to the dependability attributes reliability, availability and safety, depending
on the momentary situation.
This section describes a method of strengthening the Design and Development of
the M-LD Concept; the method described analyzes the effect(s) that dependability-
oriented objectives, derived from multiobjective optimization, can have on the
dependability of the system. The results of the analysis are used to reﬁne the in-
tegration of the aforementioned objectives into the M-LD Concept.
Additionally, the effects of possible failures of sensors and actuators are consid-
ered. In particular, failures of actuators can be integrated in the optimization process
as constraints; however, this aspect is only relevant for redundantly actuated systems
which can compensate for such failures.

3 Methods of Improving the Dependability of Self-optimizing Systems
129
3.2.11.1
Prerequisites and Input
This method is based on the method Early Design of the Multi-Level Dependability
Concept (Sect. 3.1.2), which identiﬁes dependability-oriented objectives based on
the partial model System of Objectives that should be considered within the M-LD
Concept. To take full advantage of this method, a redundantly actuated system
and/or a system with sensor redundancies is needed. These necessary redundancies
are often already installed in safety-critical systems to compensate for the failures
of individual components. Further information about the sensors and actuators used
can be found in the partial model Active Structure. Information concerning the event
and the type of a failure is additionally required. The method Early Probabilistic Re-
liability Analysis of an Advanced Mechatronic Systems based on its Principle Solu-
tion (Sect. 3.1.1) assists in determining possible failures. It is assumed that actuator
or sensor failures can, in fact, be detected and that if one such failure occurs, the
particular actuator or sensor in question nonetheless has a deﬁned behavior, i.e. it
is not performing an unknown movement. A suitable model including information
about the system and the reliability of the different components themselves (espe-
cially the probability of failure for each relevant component) is also needed. This
model can be derived from the partial models Environment, Application Scenarios,
Active Structure and Shape.
3.2.11.2
Description
The method consists of two principle areas, as described in the following. The ﬁrst
deals with multiobjective optimization and focuses on dependability-oriented ob-
jectives and the integration of actuator failures as additional constraints within this
optimization. The second consists of a reliability assessment of redundant system
structures and uses the M-LD Concept to assess different system states.
For the ﬁrst part, the dependability-oriented objectives are identiﬁed in the par-
tial model System of Objectives and are included in the model of the system dy-
namics. In addition, possible actuator failures are integrated as constraints in the
multiobjective optimization. The modeling of a failing actuator is reﬂected in the
optimization, for example by constraining the force of this actuator to zero for that
case. The Pareto sets are calculated using model-based multiobjective optimization
(cf. Sect. 1.1.2.1). Using the optimization results, the possibilities of altering the
system behavior in order to improve dependability are analyzed.
The reliability assessment in the second part of this method focuses on the re-
dundant structures in the system, beginning with a qualitative analysis in which the
different combinations of operable and inoperable components are identiﬁed. These
combinations are evaluated and afterwards classiﬁed according to the M-LD Con-
cept. In Level I of the M-LD Concept, the system is functioning as desired and is
failure-free. The weighting of the objectives can be chosen without special consid-
eration of the dependability. At Level II, one or more redundant components are
already non-functional. Thus, the weighting of dependability-oriented objectives is
increased. In Level III, the situation becomes more critical; safety becomes the most

130
P. Reinold et al.
important aspect and the functionality of the system may be reduced to avoid ad-
ditional failures and dangerous situations. Level IV is deﬁned by the fact that the
system is in danger of becoming uncontrollable should an additional failure oc-
cur. To avoid this situation, the system is forced into a fail-safe-state upon reaching
Level IV.
Two types of failures can be differentiated: On one hand, there are failures for
which the rate of failure increases over time. These failures are primarily caused by
wear and tear; prognostic models are used to predict the remaining useful life of
the component. On the other hand, there are failures with a constant failure proba-
bility, such as cable breaks, etc. These failures are more or less unpredictable, but
often require a rapid reaction, e.g. adaption of the system. Both types of failure are
considered in a statistical evaluation to calculate the failure probability of the entire
system. This reliability assessment aids in classifying the momentary conﬁguration
as one of the four levels of the M-LD Concept. This classiﬁcation inﬂuences the
selection of priority levels for system objectives within the self-optimization pro-
cess. It is implemented during design, but is also used during operation to assess the
situation. In such conditions, the assessment considers existing failures to compute
the current failure probability.
3.2.11.3
Results
The results can be summarized by two important considerations. For one, combina-
tions of failures are assessed by reliability methods and afterwards classiﬁed by the
M-LD Concept. These results are used during operation to evaluate the current sys-
tem status. In addition to this, a system of several objectives is also analyzed and the
inﬂuence of each dependability-oriented objective is simulated. As part of the multi-
objective optimization process, actuator failures in particular are taken into account
by including them as constraints in the optimization. Thus, a detailed analysis of the
behavior of the system in case of sensor or actuator failures can be provided. This
method enables the system to react to failures of redundant components adequately
and thus, by implementing counter-measures, to improve its dependability.
3.2.11.4
Application Example
The method explained above has been used to increase the dependability of the test
vehicle “Chameleon” (cf. Sect. 1.3). Only the test vehicle’s horizontal dynamics
are considered. Due to its special actuator concept, the “Chameleon” can deceler-
ate in several ways, by turning the wheels inwards, by using the driving motors as
generators, or by some combination of the two. With these possibilities it is up to
the information processing unit to decide which possibility is optimal for the current
situation while also considering possible actuator failures and wear. In this applica-
tion, the effect different prioritizations of the objectives have on the reliability of the
system is of particular interest. Another focus here is on the use of existing redun-
dancies at runtime. Depending on the curent situation, suitable objective functions
(e.g. reducing tire wear) and the appropriate weighting of objectives is selected.

3 Methods of Improving the Dependability of Self-optimizing Systems
131
This guarantees that the necessary forces can be optimally distributed among the
four wheels even in changing driving situations.
Any desired maneuver is described by the yaw rate, the velocity and the slip
angle. By using the inverse dynamics, it is possible to compute the necessary longi-
tudinal and lateral force as well as the desired yaw moment to effect the maneuver.
Based on the model, there are eight tire forces (longitudinal and lateral force of each
tire) to produce the desired forces in the center of gravity. Hence, there are redun-
dant possibilities of completing the driving task, i.e. there are degrees of freedom
for the allocation of the tire forces. Within the technical restrictions, it is possible to
use these degrees of freedom to optimally produce the desired movement. Despite
this freedom, the system is subject here to the constraint that the execution of the
desired movement must be guaranteed. Optimization objectives are the minimiza-
tion of the tire wear, the energy consumption and the most effective utilization of
the limited transmittable forces due to friction. In the following, a braking maneuver
while traveling straight forward is analyzed. As described above, there are several
possibilities for braking the vehicle. For decelerating while moving forward, there
are no conﬂicts between the optimization objectives: for all of the above-mentioned
objectives, it is optimal to brake by using the driving motors as generators. However,
in order to achieve stronger deceleration, it is necessary to turn the wheels inwards
in addition to reversing the motors..
The vehicle has four steering motors and four driving motors. Each of them can
be functional or non-functional, giving a total of 2(4+4) = 256 different actuator
conﬁgurations. The failure probability of the whole system is computed using a
Bayesian network. Similar to a fault tree, the top event "system failure" is com-
posed of logical connections between the components. The failure probability of
each component is calculated for the current point in time and the system probabil-
ity is calculated by the predeﬁned logical connections; in addition, combinations of
actuator failures are assessed. Based on the reliability assessment of the system, the
multi-dependability concept is used to assess the system status in case of actuator
failures. As a basis for this, the reliability assessment conducted across the Bayesian
networks is used in the operating phase as well to assess the system status. Through
the dependability-oriented optimization, actuator failures can be counterbalanced.
The M-LD Concept is used to derive suitable measures based on the assessment of
the current system status. In Level I, all actuators are functional and, in most cases,
the focus is not on the dependability-oriented objectives. In Level II, one or more
actuators has failed. The objectives of minimizing the actuator loads are taken into
account in addition to the normal objectives. If there are only two possibilities re-
maining for decelerating the vehicle, Level III is reached and additional measures,
such as protecting the critical actuators by reducing the speed of the vehicle, are
considered. Level IV is reached if only one possibility of decelerating the vehicle is
still functional. In this case, the vehicle is forced to a fail-safe-state, meaning it will
be brought to a stop.
The vehicle is intended to perform a desired maneuver in an optimal way; during
operation, the control strategy can increase safety by using the redundancy provided
by the vehicle: actuator failures can be included as additional constraints. This idea

132
P. Reinold et al.
can be illustrated by an example: the driving motor of the front wheel on the left-
hand side may be out of action. The constraint connected to this failure is that the
driving force of the left front wheel is zero. By accepting this as a constraint, the
optimization result will guarantee the desired movement of the vehicle. Fig. 3.46
presents the simulation results for braking in this situation. The applied braking
force for the vehicle should be 200N. The vehicle is traveling in straight line while
braking, so the values for lateral movement as well as the yaw rate are zero. If all
actuators would be functional, the total braking force of 200N could be allocated
to the wheels equally, i.e. each wheel would provide a braking force of 50N. The
ﬁgure presents two possible options for a braking maneuver in the case of the sup-
posed failure. For each wheel and each option, the braking force produced by the
driving motor Fdm and those produced by the steering motors Fsm are given. In the
ﬁrst option, braking is achieved by the driving motors alone. To compensate for
the actuator failure of the left front wheel, the left rear wheel has to brake with the
doubled amount of longitudinal force than in the case of a fully functional vehicle,
which in this case is 100N. The right front and rear wheel brake with 50N each to
achieve the desired braking force of 200N. The second option uses the symmetric
inward turn of all four wheels. This option could make sense if further constraints
are imposed on the driving motors. The force produced by the driving motors is sig-
niﬁcantly reduced compared to the ﬁrst option. Online, the M-LD Concept chooses
the suitable option.
left
right
0
50
100
Front wheel
 
 
Braking force realized by driving motor
Braking force realized by steering motor
left
right
0
50
100
Rear wheel
Braking force [N]
Braking force [N]
left
right
0
50
100
Front wheel
Braking force [N]
 
 
Braking force realized by driving motor
Braking force realized by steering motor
left
right
0
50
100
Rear wheel
Braking force [N]
(a) Exempliﬁed Option 1
(b) Exempliﬁed Option 2
Fig. 3.46 Compensation for the failure of the left front wheel driving motor

3 Methods of Improving the Dependability of Self-optimizing Systems
133
3.2.11.5
Further Reading
The method and this example application are also described in [141]. A possible ma-
neuver accounting for the breakdown of a steering motor and the suitable optimiza-
tion is explained in [128]. The focus on dependability-oriented system objectives
is also described for different applications. In [101] the objectives and behavior in
the case of actuator failures for an active suspension module are analyzed (see also
Sect. 3.2.1); sensor failures are discussed in [140].
3.2.12
Self-healing in Operating Systems
Katharina Stahl
In the context of self-optimizing systems, the operating system has to cope with
complex and changing behavior of dynamically reconﬁguring hardware and soft-
ware. As part of its functionality, it has to ensure the reliability of the entire system.
Methods such as Hazard Analysis (described in Sect. 3.2.8) and Online Model-
Checking (described in Sect. 3.2.14) aim to verify and control the correct execu-
tion of the software system. However, these methods basically rely on speciﬁcation
knowledge or an system model generated ofﬂine. The system state analysis is com-
puted based on an exhaustive system model, and is therefore resource-intensive. For
this reason, it can only be executed ofﬂine or outside of the system while the system
continues to operate.
Furthermore, the behavior of systems that operate in a self-organizing manner
in uncertain environments can lead to unforeseen and unpredictable system states.
Autonomous reconﬁgurations of the system may produce system states that lead to
unstable or malicious system behavior. Self-organization opens up some degree of
freedom for system behavior, so that system designers and development tools are
not able to determine all potential system states in the speciﬁcation model. This
leaves a gap in terms of dependability at runtime.
To ensure dependability of the entire system, the operating system requires mech-
anisms to cope with dynamic behavior and to monitor system behavior at runtime in
order to identify potentially malicious system states caused by autonomous recon-
ﬁguration, and potentially being unidentiﬁed by any speciﬁcation or model. With
our self-healing framework, the operating system is able to proﬁle system behav-
ior. It builds up a knowledge base of normal system behavior at runtime without
predeﬁned system model. This knowledge base is incorporated directly into the op-
erating system, and thus is continuously updated. The framework provides a mech-
anism for detecting deviations from normal system behavior. In this context, the
self-reconﬁguration abilities of the applications and the hardware constitute an addi-
tional challenge, as in a self-reconﬁgurable system it is hard to distinguish between
intended and malicious deviations from normal system behavior. Further proper-
ties and information about the system state are considered for the evaluation of
the anomalous system behavior in order to identify if it could potentially degrade
the system’s dependability. The main objective of the framework is therefore to

134
K. Stahl
maintain, or at least re-establish the system’s overall performance and service deliv-
ery by reconﬁguring the operating system.
3.2.12.1
Prerequisites and Input
ORCOS (Organic ReConﬁgurable Operating System [48]) is a highly customizable
and (re-)conﬁgurable real-time operating system (OS) for embedded systems. We
use this platform to implement self-healing properties in the operating system.
Customizability of the Operating System
The operating system ORCOS is composed of kernel modules that can be conﬁg-
ured individually at compile time. For example, the scheduling strategy, the mem-
ory management method, or even hardware-dependent functions can all be set up
according to system requirements by an XML-based conﬁguration language SCL
(Skeleton Customization Language, see [48]). Dependencies between particular ker-
nel modules can be speciﬁed to ensure correct functionality and dependability of the
customized operating system. In resource-restricted environments such as mecha-
tronic systems, efﬁciency is an important factor. Conﬁgurability ensures that only
the necessary code will be compiled into the executable and loaded onto the device.
3.2.12.2
Description
The basis for integrating such a self-healing framework into the operating system
(OS) is an adequate OS architecture that encompasses both the ability to monitor
and analyze system behavior, and the ability to reconﬁgure the system in order to
react to a malicious system state. This section ﬁrst describes the architecture of the
real-time operating system and then the according components that constitute the
self-healing framework.
The main challenge of this approach is the problem of anomaly detection. Within
this context, we deﬁne what actually determines system behavior and which inter-
nal and external factors have an impact on and can cause changes in the system’s
behavior. Then, we present our approach for online anomaly detection within the
self-reconﬁguring system, which relies on the Danger theory [99] of Artiﬁcial Im-
mune Systems (AIS) [27,31]. The applied algorithm and further adjustments on the
OS architecture that are necessary to implement the AIS algorithm are presented in
the later part of this section.
Operating System Architecture
To integrate self-healing capabilities into the operating system ORCOS, we have
adjusted the OS architecture following the example of the Observer-Controller Ar-
chitecture ﬁrst instantiated by the Organic Computing Initiative [130].
We have expanded the ORCOS architecture to include an observer component
that is responsible for monitoring the system and for collecting and providing
knowledge about the system behavior.

3 Methods of Improving the Dependability of Self-optimizing Systems
135
Monitor
Controller
Functional OS Kernel Components
Board
Interrupt 
handler
Timer
Syscall
manager
Analyzer
DeviceDriver
Memory
manager
CPU
dispatcher
File
Manager
Scheduler
Communication
Fig. 3.47 Architecture of a self-healing operating system
Although the Observer implements two functions that are strongly coupled (col-
lecting data and analazing), they exhibit self-contained tasks which can be executed
in a timely decoupled manner. Therefore, the Observer is subdivided into the two
separate entities: a Monitor and an Analyzer. The Monitor collects behavioral data
and aggregates the data for the Analyzer. Then, the Analyzer evaluates the data and
passes its evaluation results to the Controller. Based on the results of the analy-
sis, the Controller is responsible for planning and executing decisions for system
reconﬁguration.
The resulting architecture of the operating system ORCOS is shown in Fig. 3.47.
In this operating system design, the self-healing framework is strongly isolated from
the remaining functional OS kernel components. This isolation ensures that the
functional OS kernel components are not integrated into the self-healing process,
so that for the functional OS kernel components the execution of the self-healing
framework can take place in an imperceptive manner. Furthermore, the self-healing
framework must not degrade the execution of the real-time applications in terms of
reaching their deadlines so that it can only be implemented having soft real-time
requirements or at lowest system priority.
Reconﬁguration
In the context of dependability and self-healing, reconﬁguration is used to re-
establish an acceptable system state where, for instance, components exhibiting
faulty behavior can be replaced by other components. Hence, reconﬁguration es-
sentially requires the existence of alternatives for the Controller.

136
K. Stahl
Fig. 3.48 Proﬁle Frame-
work: example of a system
conﬁguration
Task C
System configuration
Task B
Task A
Profile 1
Profile 2
Profile 3
Profile 1
Profile 2
Profile 1
Profile 2
Profile 3
Legend
Active profile
The basis for reconﬁguration in ORCOS is provided by the Proﬁle Framework.
Originally, this framework was developed in the context of the Flexible Resource
Manager (FRM) [109] to self-optimize resource consumption in resource-restricted
real-time systems (for further description see D.M.f.I.T.S, [55], Sect. 5.5.2). How-
ever, the principle of the Proﬁle Framework offers potential for other purposes: the
Proﬁle Framework enables alternative implementations of an application task. Each
alternative implementation is represented by a deﬁned proﬁle for that task. Im-
plementations may vary, as originally intended in the FRM, by different resource
requirements.
At each point in time only one proﬁle of a task is active (see Fig. 3.48). A conﬁg-
uration c of the system is deﬁned as Conﬁguration c = (p1, p2,..., pn), with n being
the number of running tasks τ, p1 ∈P1, p2 ∈P2,..., pn ∈Pn and Pi being the proﬁle
set of task τi. Each task must deﬁne at least one proﬁle to be executed.
For the purpose of our self-healing framework, we can extend this deﬁnition:
proﬁles are not only restricted to tasks, but are also deﬁned for OS components.
The former deﬁnition of proﬁles is extended so that proﬁles may now differ in
their demand for resources. in the choice of which resources are applied (e.g. a
speciﬁc communication resource), in the implemented algorithm (e.g. in terms of
accuracy of the algorithm or strategy), in execution times, in deadlines etc.
During runtime, the Controller may switch between the proﬁles of a task or a
OS component in order to reconﬁgure the system according to some system restric-
tions. A reconﬁguration is required when the analyzing algorithm detects anomalous
system behavior, which, for example, could be caused by a defective hardware re-
source and could lead to malicious behavior. In such a case, the Controller must
deactivate all proﬁles that use that resource and, consequently, it must activate an-
other proﬁle for each affected task or OS Component. To maintain ﬂexibility of the
operating system at runtime, an extension of the operating system kernel allows ex-
ecutable OS modules to be uploaded online and thereby to add new proﬁles for this
component. Kernel components (e.g. the memory manager) can be exchanged based
on changing requirements of the self-optimizing system.

3 Methods of Improving the Dependability of Self-optimizing Systems
137
System Behavior
The state of an operating system consists of a range of system status information,
such as the CPU usage, resource and memory consumption, values of kernel pa-
rameters, etc. These system state parameters are discrete values for a speciﬁc time
stamp. However, behavior is usually understood as a course of actions and derived
from an observable course of changes within discrete system states.
The operating system is a service platform for applications that are running on
the system. Hence, the characteristics of these applications have a major impact on
the operating system state parameters. Due to security aspects, ORCOS provides
system calls as the only interface for the applications to the operating system so
that the system state and the derived system behavior are strongly dependent on the
applications’ system calls.
Based on this, we deﬁne that the operating system behavior is determined by
(sequences of) system call invocations executed by the applications tasks with the
associated information (arguments, return values, return addresses etc.) .
External Impact on System Behavior
Autonomous reconﬁguration of the operating system is not the only challenge when
considering the entire system. Self-optimization is present in all system layers.
Therefore, our operating system must additionally deal with self-reconﬁguring hard-
ware and self-reconﬁguring software. A reconﬁguration, either in the underlying
hardware or in the overlying software layer, will obviously cause deviations in the
normal system behavior. Even if the particular reconﬁguration was not induced by
the operating system itself, it was intended by system-internal source, meaning that
the behavioral changes must be accepted as non-malicious. Therefore, interfaces
must exist that allow other system layers (such as the hardware or software) to in-
form the OS whenever a reconﬁguration has been initiated by a source outside its
own control (by e.g. interrupts or signals).
Inspiring Paradigm
The self-healing mechanism depends heavily on the efﬁciency of the algorithm used
for runtime analysis and behavior evaluation. As we have to deal with dynamically
changing system behavior in a resource-restricted environment, a suitable approach
must possess certain qualities, such as:
• disposability,
• autonomy,
• dynamical adaptivity,
• abililty to cope with new system states,
• learning mechanism for remembering correct and malicious states, and
• simple algorithms with a low resource consumption.
Considering the context of self-healing systems, Artiﬁcial Immune Systems (AIS)
[27,31] are a good source of inspiration for problem solving.

138
K. Stahl
Self-healing Framework
The workﬂow of the self-healing framework in the operating system is deﬁned by:
Monitor:
Step 1:
Data collection of system state and behavior data, composed of :
• data about OS parameters: CPU utilization, resource usage, etc.
• data about tasks being executed: system calls, system call arguments, return
addresses and other related information
Step 2:
Data interpretation and generation of a system behavior representation
Analyzer:
Step 3:
Identiﬁcation of system behavior; detection of deviations/anomalies by pat-
tern matching
Controller:
Step 4:
Analysis of results from behavior identiﬁcation and evaluation of effect on the
overall system
Step 5:
Reaction to system behavior, in particular to behavioral anomalies: reconﬁg-
uration of the system
Danger Theory from Artiﬁcial Immune Systems [2, 99] offers appropriate fea-
tures to serve as an inspiration for implementing the self-healing framework in
our dynamically reconﬁgurable system. Dendritic Cells build up the core of this
population-based approach. In immunology, a Dendritic Cell (DC) initially serves
as an Antigen Presenting Cell (APC), which means that this cell signals the presence
of substances that indicate an anomaly and stimulates an immune response.
During its lifetime, a DC can obtain three different states: immature, mature and
semi-mature. The initial state of the DC is immature. Residing in this state for a
particular period of time, the DC will observe and examine the structures for which
it is speciﬁed. Then, the DC migrates either into the semi-mature or into the mature
state. This migration is illustrated in Fig. 3.49. The decision for state migration
depends on two factors: ﬁrst, its own evaluation of the observation, and second,
input signals from the surrounding system.
According to Danger Theory, the following input signals are deﬁned:
Safe signal:
indicates that no threat has been identiﬁed in the system
PAMP (pathogen-associated molecular pattern) signal:
indicator that a known threat has been localized

3 Methods of Improving the Dependability of Self-optimizing Systems
139
Fig. 3.49 DC state migra-
tion in correlation to input
signals
Immature
PAMP
Danger signal
Mature
Semi-mature
Safe signal
Danger signal:
indicates a potential danger suspected due to local behavior deviations
Inﬂammation signal:
general alarm signal
The DC’S state transitions are probabilistic decisions that depend heavily on sev-
eral thresholds. To decide on a state transition, the DC sends out an output signal
reﬂecting its local evaluation and adjusts the system input signals.
We are deploying Dendritic Cells for self-healing in the operating system with
the objective of evaluating the behavior of the system entity that the DC is assigned
to monitor. In this context, we have deﬁned the system behavior using OS state in-
formation and system call invocation by tasks. Hence, we use a DC for proﬁling
the behavior of a task or a speciﬁc OS kernel property. Referring to the self-healing
workﬂow described above, the set of DCs takes over the responsibility of the Mon-
itor in a distributed manner.
Local evaluations by DCs are collected by the shared DCA Monitor. Addition-
ally, the DCA Monitor supplies the DCs with values of input signals from a central
location and stores the knowledge base containing the normal behavior proﬁles, as
well as already-detected dangerous system states (PAMP); the latter are recorded in
order to enhance immediate detection of known dangers. The resulting architecture
for the self-healing framework in the operating system is illustrated in Fig. 3.50.
Each DC starts its local evaluation in the immature state. In this state, the DC
samples selected system behavior data for the behavior analysis and evaluation. The
process of data sampling of a DC is limited by a predeﬁned data amount or by
a timing condition. Parameters are monitored and collected in order to establish
system behavior data based on the requirements of the analyzing algorithms. The
data set is conﬁgurable at runtime according to the analyzing method. As any OS
component of ORCOS is conﬁgurable and exchangeable at runtime, the analyzing
algorithm can also be exchanged according to the given restrictions (e.g. available
free resources for execution).
After data collection, the behavioral data has to be analyzed. Therefore, each DC
provides a normal behavior proﬁle for the component (e.g. task) it is monitoring.
The objective of the data processing is to identify deviations in the real behavior
from the normal behavior proﬁle. The DC executes a (simple) pattern-matching
mechanism in order to pre-evaluate the real local behavior monitored. Based on its

140
K. Stahl
Fig. 3.50 Resulting ar-
chitecture for a DC-based
operating system
Controller 
(T-cell)
DCA 
monitor
DC
DC
DC
DC
Syscall
manager
Functional OS
kernel components
Task2
Task3
Task1
local knowledge, a DC classiﬁes the behavior; if the real behavior complies with the
normal behavior proﬁle, the actual behavior is classiﬁed as safe. In that case, the
DC switches to the semi-mature state and ampliﬁes the value of the safe signal.
If the local behavior is outside the range of the normal behavior proﬁle, in the
ﬁrst instance the system behavior is classiﬁed as suspicious. From here, the DC can
either migrate into the semi-mature or the mature state. The migration of the DC
requires further evaluation that is related to the system context as represented by the
system’s input signals.
If the local behavior corresponds to a system behavior that has been already iden-
tiﬁed as malicious or dangerous, then the DC migrates to the mature state and out-
puts a PAMP signal. If the current local behavior exceeds the range of the normal
behavior proﬁle and is combined with the presence of the danger signal, the DC
tends to migrate to the mature state and consequently increases the value of the dan-
ger signal. If, on the other hand, the actual current behavior is outside the range
of the normal behavior proﬁle with no danger signal, but rather within a dominant
presence of the safe signal, then the behavior tends to be tolerated. Consequently,
the DC migrates to the semi-mature state.
In order to inform the OS about a reconﬁguration at the software application or
the hardware layer, the system provides the inﬂammation signal as a general alarm
signal. The occurrence of the inﬂammation signal instructs the DCs to build up new
system behavior knowledge which is based on the behavior produced by the new
system conﬁguration.
In the context of AIS, the Controller is an immune T-cell that is responsible for
the immune response and, thus a reaction to the present system behavior. It re-
ceives the collected information from the DCA Monitor and decides - based on
thresholds and predeﬁned conditions - whether the observed behavior may lead to a
system failure. As already described, it can then initiate a system reconﬁguration, if
necessary.

3 Methods of Improving the Dependability of Self-optimizing Systems
141
3.2.12.3
Results
The self-healing framework offers the operating system the ability to monitor and
analyze system behavior. Its main potential is for evaluating unspeciﬁed and un-
known system states for which there is no previously speciﬁed behavioral model. In
correlation with environmental input signals, the framework ensures that behavior
evaluation results are not determined based only on local information. Thus, this
AIS-inspired approach substantially enhances the system’s dependability using a
runtime method with low computation efforts.
3.2.13
Self-healing via Dynamic Reconﬁguration
Sebastian Korf and Mario Porrmann
The goal of this method is to increase the reliability of a self-optimizing system
by taking advantage of the reconﬁgurability of the underlying hardware. Recon-
ﬁgurable devices such as FPGAs are increasingly being used in several areas of
application. With the advent of the new generation of SRAM-based partially recon-
ﬁgurable FPGAs, the implementation of System on Programmable Chips (SoPCs)
has become a feasible alternative to traditional options [83]. Nowadays, it is possi-
ble to implement a comprehensive system which embeds hardwired microproces-
sors, custom computational units, and general-purpose cores on a single chip. This
technology is able to cope with today’s requirements for a short time-to-market and
high resource efﬁciency.
Since nanoelectronics with feature sizes of 45 nm and below has become reality
for reconﬁgurable devices, designers have to consider the fact that faults – static
and dynamic – will increasingly affect their products. Hence, yield and reliability
are becoming key aspects in SoPC design [24]. These architectures are receiving
increasing interest from various application domains. Even safety-critical missions,
driven by avionics and space applications, are especially attracted to using SoPCs
due to low non-recurring engineering costs, reconﬁgurability and the large number
of logic resources available. One of the most signiﬁcant problems in choosing to
use SoPCs in safety-critical applications are the effects induced by different types
of radiations such as alpha particles, atmospheric neutrons and heavy ions [118].
These particles may induce non-destructive loss of information within an integrated
circuit, provoking Single Event Upsets (SEUs) [138].
Partial dynamic reconﬁguration, i.e., changing parts of a reconﬁgurable fabric
at runtime while leaving other regions untouched, can be used to further increase
resource efﬁciency and ﬂexibility of SoPCs [116]. Additionally, dynamic recon-
ﬁguration can be used to correct a corrupted conﬁguration of a device, caused,
for example, by an SEU, at runtime. Together with continuous monitoring of the
conﬁguration memory, this enables self-healing capabilities for the implemented
information processing system. Furthermore, partial reconﬁguration can be used
to implement adaptive redundancy schemes. Based on sophisticated error moni-
toring and on user-deﬁned security levels for each implemented hardware module,

142
S. Korf and M. Porrmann
redundancy can be adapted at runtime. Critical modules can, for instance, be im-
plemented with triple modular redundancy (TMR) [142]. Depending on changing
environmental conditions and on the application requirements, the level of redun-
dancy can be dynamically adapted for each module.
3.2.13.1
Prerequisites and Input
For the effective implementation of dynamically reconﬁgurable systems, we pro-
posed a layer-based approach in D.M.f.I.T.S, [55], Sect. 5.4.3.1. This model sys-
tematically abstracts from the underlying reconﬁgurable hardware to the application
level by means of six speciﬁed layers and well-deﬁned interfaces between these lay-
ers. The main objective of this model is to reduce the error-proneness of the system
design while increasing the reusability of existing system components.
Typically, a partially reconﬁgurable system is partitioned into a Static Region
and a Partially Reconﬁgurable Region, abbreviated as PR Region (Fig. 3.51). The
conﬁguration of the Static Region is not changed at runtime; all static components
of the system are located in the Static Region (e.g., the reconﬁguration manager or
the memory controller). The PR Region is used for runtime reconﬁguration, and all
dynamic system components are located in a PR Region; a partially reconﬁgurable
system can be composed of one or several separate PR Regions.
In addition to the partitioning of the FPGA, the concept of partial reconﬁguration
requires a suitable communication infrastructure for connecting the PR modules
and the Static Region. The communication infrastructure should not introduce any
further heterogeneity in the system; this is so that the ﬂexibility of placement is
maintained by preserving the number of feasible positions of the PR modules. Ho-
mogeneity implies that the individually reconﬁgurable resources are connected via
Fig. 3.51 Overview of a
partially reconﬁgurable
system divided into static
and dynamic system
components
Static System Components
Configuration
Manager
Processor
Memory
Hierarchial Communication Infrastructure
(Application Data, Config. Data, I/O Data)  
On-Chip Communication Infrastructure 
PR
Module
PR
Module
PR
Module
...
Partially Reconfigurable Region
Dynamic System Components

3 Methods of Improving the Dependability of Self-optimizing Systems
143
the same routing infrastructure. Thus, modules cannot only be placed at one dedi-
cated position, but at any position with sufﬁcient free contiguous resources [66].
In addition to utilizing the reconﬁgurable resources, applications can also be
mapped onto the embedded processor of the SoPC. The hierarchical communication
infrastructure ensures that all system components can access the internal memory,
which stores all relevant data for applications, IO, and PR module conﬁguration.
3.2.13.2
Description
In our approach, dynamic reconﬁguration is provided by a combination of dy-
namically reconﬁgurable hardware and a reconﬁgurable real-time operating system
(RTOS), running on the embedded processor of the SoPC. While the proposed hard-
ware platform offers the fundamental mechanisms that are required both to execute
arbitrary software and to adapt the system to new requirements (e.g., by dynamic
reconﬁguration), the RTOS provides an interface between the hardware and the
software application and decides whether a task will be executed in software, in
hardware, or in a combination of both. Thus, depending on the actual environmental
conditions, the high ﬂexibility of the approach can be used to optimize the SoPC for
energy efﬁciency or resource utilization.
Furthermore, the high ﬂexibility of the approach can be utilized to increase the
dependability of the system. This can be done on three different levels: system level,
module level, or gate level. The selection and combination of appropriate methods
depends on the desired level of reliability and the expected failure rate.
System Level:
A basic requirement for PR module placement is the availability of sufﬁcient con-
tiguous resources in the PR Region of the FPGA. In case of a detected failure of a
complete FPGA, PR modules located on this FPGA can be migrated to other FP-
GAs. If the amount of available resources is not sufﬁcient, modules that have low
priority can be replaced by simpler modules with lower resource requirements, or
can even be removed from the system entirely. The goal of this approach is to pro-
vide sufﬁcient resources for high-priority modules so that a basic functionality of
the system can be guaranteed. Additionally, spare FPGA devices can be integrated
into the system to further increase reliability.
SEUs are especially critical for reconﬁgurable devices, since they can affect the
conﬁguration memory and therefore change the behavior of the system. A frequently
occurring reconﬁguration (blind scrubbing) can increase the reliability, as newly
conﬁgured SRAM cells are correctly set and potential bit-ﬂips are removed. In
addition to blind scrubbing, a continuous readback of the conﬁguration bitstream
combined with an online integrity check can be implemented (readback scrubbing).
While blind scrubbing does not provide any information about detected faults, read-
back scrubbing enables continuous monitoring of the failure conditions.

144
S. Korf and M. Porrmann
Module Level:
Dynamic reconﬁguration enables the implementation of different, adaptive levels of
redundancy and reliability on the level of PR modules. Components in which faults
are unacceptable could be implemented using very safe but space-consuming tech-
niques such as TMR. In less critical PR modules, faults may be acceptable, as long
as they can be detected and corrected within a given time frame. Furthermore, scrub-
bing, as described above, can be performed on module level. Critical PR modules
can be checked or reconﬁgured more often than less critical PR modules.
Gate Level:
Also permanent faults can be detected and located using the methods described
above. Once a permanent fault has been located, it can be considered as non-usable
during module placement. Therefore, the complete device does not have to be turned
off, but rather, only a single module is deactivated. This module can even be used
for future PR modules, if the defect is taken into account (i.e., masked out) during
PR module implementations.
3.2.13.3
Results
Partial dynamic reconﬁguration can be used to increase the ﬂexibility and resource
efﬁciency of microelectronic systems. The proposed strategies for scrubbing, mod-
ule relocation, and adaptive redundancy enhance the reliability of the whole system
at much lower cost than traditional approaches, such as triple modular redundancy
of the complete system architecture.
3.2.13.4
Application Example
Methods of increasing the reliability of microelectronic systems will be of increas-
ing importance when utilizing nanoscale semiconductor technologies in the future.
However, even today, special system architectures are necessary if high dependabil-
ity is a major concern (as in automotive and aerospace applications) or when target-
ing operation in harsh environments. Information processing in space combines the
aforementioned requirements and has therefore been chosen as an example of using
dynamic hardware reconﬁguration for self-healing.
Performance requirements for onboard processing of satellite instrument data
are steadily increasing. A prime issue is that high volume data, produced by the
next generation of earth observation instruments, cannot be transmitted to earth ef-
ﬁciently, since science data downlinks only offer limited capacity. Therefore, novel
approaches to onboard processing are required. Utilizing reconﬁgurable hardware
promises a signiﬁcant improvementin the performance of onboard payload data pro-
cessing. For this purpose, a system architecture has been developed that integrates
avionic interfaces (e.g., SpaceWire and WizardLink) in combination with reconﬁg-
urable hardware for use by satellite payload systems [65]. SRAM-based FPGAs are
used as the core components of this architecture and dynamic reconﬁguration is

3 Methods of Improving the Dependability of Self-optimizing Systems
145
utilized to exchange hardware modules for data processing at runtime in order to
enable new or updated functionalities, for one. Secondly, dynamic reconﬁguration
is used to increase reliability by mitigating the above-mentioned radiation effects. In
this context, dynamic reconﬁguration can be subdivided into scheduled and event-
driven reconﬁguration, as in D.M.f.I.T.S, [55], Sect. 5.4.5.2. Scheduled reconﬁgu-
ration can be used to implement resource-sharing on hardware level by utilizing
time-division multiplexing across the available FPGA area. Furthermore, scheduled
reconﬁguration can be used to minimize radiation effects by employing continuous
scrubbing, in which a continuous readback of the conﬁguration data is combined
with an online check of the integrity of the data as it is obtained. While scrubbing
is performed periodically with a period (scrubbing rate) in the range of seconds or
milliseconds, scheduled reconﬁguration can also be used to execute maintenance
functions which are executed in longer time intervals. In our implementation, the
scrubbing rate is limited solely by the clock frequency of the FPGA’s conﬁgura-
tion interface. The Xilinx Virtex-4 FPGAs used in the proposed satellite payload
processing system offer a maximum conﬁguration rate of 400 MB/s, resulting in
a maximum scrubbing frequency of 100 Hz when scrubbing the complete FPGA.
Higher frequencies are possible if only certain sections of the FPGA are scrubbed.
The priority of each scrubbing task is a direct result of the deﬁned reconﬁguration
schedule.
In event-driven reconﬁguration, the loading and unloading of hardware modules
is triggered by events. This could mean mission events, where, for instance, a sensor
has detected an object of interest which requires further investigation using new
hardware modules. It could, however, also be failure events, in which parts of the
system fail to operate correctly; in this case, reconﬁguration is used for self-healing
by restoring the hardware conﬁguration in an error-free area of the device.
Faults should not only be detected (and corrected), but should also be monitored
at runtime; therefore, all monitored data are analyzed and the results are used as
additional control inputs for the system. Using self-optimization, the system can
be reconﬁgured to a very safe mode (i.e., high redundancy but low performance)
if the error rate increases, while it can operate with higher performance and less
redundancy if low error rates are detected.
The proposed scheme of adaptive redundancy can also be implemented on a
more ﬁne-grained level. Dynamic reconﬁguration, as described above, will enable
the implementation of different levels of redundancy and reliability for the par-
tially reconﬁgurable hardware modules. As mentioned above, modules representing
components where faults are unacceptable are implemented using very safe but
space-consuming techniques such as TMR. Additionally, since TMR is a modular
approach, it can be efﬁciently combined with our approach for dynamic reconﬁgu-
ration. In this case, redundancy is adapted at run-time by inserting additional mod-
ule instances, as well as the required majority-voting system. Other PR modules
may implement components where faults are acceptable; however, these faults have
to be detected immediately (e.g., communication using automatic repeat request).
Moreover, PR modules may exist where faults are both acceptable, and can be
detected or corrected later.

146
S. Korf and M. Porrmann
Communication module
Configuration and control communication
Processing module
 
 
Processing module
 
Working 
memory
(DDR2 
SDRAM)
 
Reconfigurable
processing 
unit 
(Virtex-4 FPGA)
System
controller
(SpW-
RTC)
Memory
(SRAM/
Flash)
Communi-
cation
controller
(FPGA)
Working
memory
(DDR2 
SDRAM)
Reconfigurable
processing unit
(Virtex-4 FPGA)
Source data
Interfaces
- SpaceWires - Can
- WizardLink - Serial
- ADC/DAC - GPO
Avionic
interfaces
- SpaceWire
- MIL
- GPIO
Inter-module communication
Fig. 3.52 Overview of a scalable system architecture for a payload processing system and
the realization on the RAPTOR prototyping system
For validation of the proposed concepts, a hardware implementation of a self-
optimizing satellite payload processing system with self-healing capabilities has
been created based on the RAPTOR [117] prototyping system, as depicted in
Fig. 3.52. The architecture can be easily scaled by the integration of additional Pro-
cessing Modules integrating dynamically reconﬁgurable resources (Xilinx Virtex-4
FX100 FPGA) and by additional Communication Modules providing the required
avionic and source data interfaces. The System Controller, a SpaceWire-RTC which
consists of a LEON2-FT CPU, two SpaceWire interfaces and additional source data
interfaces, controls the communication between the modules.

3 Methods of Improving the Dependability of Self-optimizing Systems
147
3.2.14
Online Model Checking
Franz-Josef Rammig and Yuhong Zhao
As we have already seen several times in preceding chapters, self-optimizing sys-
tems are capable of adjusting their behavior at runtime in response to changes in
application objectives and the environment. Ensuring the dependability of such
dynamic systems has given rise to new demands on veriﬁcation techniques. The
dynamic nature of these systems makes it difﬁcult for traditional model checking
techniques [30] to investigate the state space of the system model ofﬂine with rea-
sonable time and space consumption. To overcome this problem, many efﬁcient
techniques have been presented in the literature so far: partial order reduction [91],
compositional reasoning [18], abstraction technique [29] and bounded model check-
ing [20], to name just a few. These improvements enable model checking to verify
more complex systems, unfortunately, however, at the cost of making the model
checking process more complicated. Self-optimizing systems further exacerbate the
state-space explosion problem. Using the above-mentioned veriﬁcation techniques
to check self-optimizing systems ofﬂine still leaves much to be desired.
Traditional testing [104] provides a partial proof of correctness at the level of
system implementation. For untested inputs, undiscovered errors in deep corners
might show up during system execution.
Runtime Veriﬁcation [10, 14, 28, 40,41, 68, 143] also works on a system imple-
mentation level. It attempts to check the correctness of the sequence of states moni-
tored or derived from the current execution trace. Runtime veriﬁcation can proceed
further only after a new state has been observed. Therefore, it is difﬁcult to detect
errors before they have already occurred.
Online Model Checking [154] works on the system implementation level as well,
but it checks the correctness of the corresponding system model. Errors at the model
level might indicate potential errors at the implementation level. Simply speaking,
online model checking is a lightweight veriﬁcation technique to ensure at runtime
the correctness of the current execution trace of the system application under test by
means of checking a partial state space of the system model covering the execution
trace. For this purpose, we need to monitor the system execution trace from time
to time; in doing so, we can avoid the state-space explosion problem. The observed
(current) states are used to locate the partial state space to be explored. Online model
checking aims to “look” into the near future in the state space of the system model,
in order to see whether potential errors are lurking there or not. As a side effect, the
conformance of the implementation to the corresponding model can also be checked
during the process. The counterexample provided by online model checking is a
clue to help locate the error(s), which might be in a deep corner and thus hard to
reproduce.
Notice that we do not directly check the actual execution trace itself; thus, the
progress of our online model checking is not tightly bound to that of the system
execution. This means that, if we can make online model checking sufﬁciently efﬁ-
cient, it is possible to predict potential errors before they have actually occurred. The

148
F.-J. Rammig and Y. Zhao
efﬁciency of online model checking depends primarily on the search algorithm and
the underlying hardware architecture, as well as on the complexity of the checking
problem. In the following, we present our efﬁcient online model checking mecha-
nism and its implementation as a system service of a Real-time Operating System.
3.2.14.1
Prerequisites and Input
Our online model checking mechanism is integrated into a Real-time Operating Sys-
tem called ORCOS (Organic ReConﬁgurable Operating System [48]) as a system
service. The system application (source code) under test and its formal model, as
well as the property to be checked, are known in advance to ORCOS. The formal
model is derived from the system speciﬁcation or extracted from the system im-
plementation. The property is given in form of an invariant or of a general Linear
Temporal Logic (LTL) formula.
3.2.14.2
Description
Online model checking attempts to check (at the model level) whether the current
execution trace (at the implementation level) could run into a predeﬁned unsafe
region (error states) or not.
Basic Idea
Without loss of generality, suppose that the current state si of the system application
under test can be monitored in some way from time to time and that the unsafe
region is derived ofﬂine from the property to be checked. Fig. 3.53 illustrates the
basic idea of our online model checking mechanism.
For each checking cycle, whenever a new current state si is monitored during
system execution, we can use the corresponding abstract state si = α(si), where
the function α(·) maps a concrete state si to an abstract state si, to reduce the state
S0
S1
^
^
S2
^
S3
^
S3
S2
S1
S0
Runtime execution trace
Online model checking
Error states
Reachable?
Fig. 3.53 Online model checking

3 Methods of Improving the Dependability of Self-optimizing Systems
149
Fig. 3.54 Communication
mechanism
put
take
Ring
buffer
Runtime
execution trace
Online
model checking
space to be explored by online model checking. It is therefore is sufﬁcient to ex-
plore a partial state space starting from the corresponding abstract state si. It is
worth mentioning that, if no abstract state is consistent with α(si), it means that the
implementation of the system application does not conform to its model. This con-
sistency checking is a byproduct of online model checking. Because of the limited
checking time allocated to online model checking, for each checking cycle, only a
ﬁnite number of transition steps, say the next k steps, starting from the observed
state will be explored. Therefore, online model checking is, in essence, Bounded
Model Checking (BMC) [20] applied at runtime.
An SAT solver can be used as a veriﬁcation engine for online model checking.
In case of a relatively small k, [20] concludes that “SAT based BMC is typically
faster in ﬁnding bugs compared to BDDs”. Unfortunately, [20] also concludes that
“The deeper the bug is, the less advantage BMC has.” However, by doing BMC at
runtime, it is quite possible to ﬁnd deep corner bugs (if any) in the state space of a
large complex system. If no error is detected, then the execution trace is safe for at
least the next k steps. Once an error has been detected, online model checking will
inform the underlying operating system in time. It is then up to the operating system
to decide how to deal with the particular case.
Communication Mechanism
In order to obtain current state information, we can have our online model check-
ing communicate with the system application through a ring buffer, as shown in
Fig. 3.54. A special monitor, which can observe the current state while the system
application is running, puts the states into the buffer from time to time, while the
online model checking periodically tries to take a state from the buffer. This state is
used to decide a partial state space of the system model to be explored by the online
model checking. If the buffer is full, the oldest state is overwritten by the latest one.
It is easy to see that the progress of the online model checking is not strongly bound
to the system execution due to its working at the model level. Online model check-
ing does not check the actual execution trace itself; it merely uses the monitored
states to reduce the state space to be explored. This is different from state-of-the-art
runtime veriﬁcation, which checks the observed execution trace itself.
Accelerating Online Model Checking
In practice, online model checking could run ahead of or fall behind the execution of
the system application. In the former case, it is possible for online model checking
to predict the potential errors before they’ve actually occurred. Therefore, it would
be advantageous to speed up online model checking [125], so that we have a bet-
ter chance to fulﬁlling this goal. One possibility would bet to speed up the search

150
F.-J. Rammig and Y. Zhao
S0
S1
^
^
S2
^
S3
^
S3
S2
S1
S0
Online forward exploration
Offline backwards exploration
Extended
error states
Error states
F´ =
F3
F2
F1
F0
n
0
3
2
1
Runtime execution trace
Fig. 3.55 Accelerating online model checking
algorithm by using an efﬁcient SAT solver optimized and customized for online
model checking. The second possibility is to reduce the workload of online model
checking by introducing ofﬂine backward exploration, as shown in Fig. 3.55.
For this purpose, we need to derive (initial) unsafe condition from the LTL for-
mula to be checked. In case of a safety property, it is trivially a reachability problem,
i.e., the error path is ﬁnite; the unsafe condition can be obtained easily by means of a
negation operation. However, in case of a liveness property, the error path is inﬁnite.
For ﬁnite state systems, this means, the error path must end at some accepting state
that satisﬁes the fairness condition and that has some loop back to it in the mean-
time. Online checking of a loop condition will substantially increase the workload
of online model checking. Fortunately, we can always obtain the fairness condition
in advance from the Büchi automaton derived from the liveness property. There-
fore, we can calculate ofﬂine a set of states that satisfy the fairness condition and
that have some loop back to them. This set of states can be seen as the (initial) error
states.
Now we can extend the (initial) unsafe region F0 to become F′ = F0∨F1∨···∨Fn
by ofﬂine backward exploration up to n time steps, as shown in Fig. 3.55. As a result,
online model checking is reduced to online reachability checking [125], a simple
form of Bounded Model Checking.
Many existing efﬁcient solutions to traditional model checking can be directly
applied to ofﬂine backward exploration. Given enough time and memory, it is pos-
sible to explore backwards much deeper in the state space of the system model to
be checked. Doing so will thus substantially reduce the workload of online forward
exploration.
3.2.14.3
Results
The existence of a Real-time Operating System (RTOS) implies that any effect of
a closed-loop control system, be it sending a control value to or receiving an input

3 Methods of Improving the Dependability of Self-optimizing Systems
151
Fig. 3.56 Underlying
system architecture
Runtime
execution trace
Online
model checking
put
take
Ring
buffer
system call
/write state
system call
/write state
system call
/write state
system call
/write state
system call
/write state
trigger model checking
system call
handler 0
system call
handler 1
system call
handler 0
system call
handler 0
system call
handler 0
Real-time operating system
value from the controlled object or be it any kind of communication with another
application task, happens under the control (and this includes notion) of the RTOS.
All such actions of an application can happen only by means of system calls. A
failure can be malign according to Kopetz [84] only when passed to the outside via
a system call, while all other failures are benign.
That is, the implementation of any such application has to contain a sequence
of system calls. Whenever a system call is invoked, we can monitor the state
information of the implementation. Therefore the sequence of system calls of an ap-
plication is the appropriate level of granularity, at which we can monitor state infor-
mation used by online model checking. Such system calls happen anyhow during the
system execution. Online veriﬁcation can thus be integrated as part of the system call
handler of an RTOS, thereby causing no additional context switch overhead and with
the necessary information already available without crossing address space borders.
We assume that there exist two versions of a system call handler, one with integrated
online model checking and one without. When entering a critical application or crit-
ical part of an application, then it just means to switch to the proper mode of system
calls. In this sense online model checking becomes an RTOS service, as shown in
Fig. 3.56.
3.2.14.4
Application Example
Nowadays industries rely increasingly on (embedded) software for their product
safety. For instance, the vehicles’ electronics systems are usually controlled by soft-
ware with millions of lines. Online model checking mechanism can increase the
dependability of the safety-critical systems to some degree. If an error is detected in

152
S. Groesbrink
Fig. 3.57 Online model
checking problem for hybrid
systems
Control mode
dx
dt = f (x, u, d)
Fig. 3.58 Online hybrid
reachability checking
Control mode
dx
dt = f (x, u, d)
time, the underlying operating system then has time to react to the error. At the very
least, the counterexample provided by online model checking can help the user to
ﬁgure out the location of and reason for the subtle error, which is usually difﬁcult to
reproduce in a laboratory environment for the large complex software systems.
On the other hand, our online model checking mechanism can also be used to
increase the safety of the hybrid systems as shown in Fig. 3.57, where the symbol 
represents the unsafe region of the continuous state space associated with the given
control mode. Starting from the unsafe region, we can calculate ofﬂine a backward
reachable set up to n time steps. At runtime, the system states are sampled from time
to time. Then, we can check online, as shown in Fig. 3.58, whether the trajectory
from each observed state could reach the extended unsafe region in the near future
or not.
3.2.15
Virtualization
Stefan Groesbrink
Self-optimizing mechatronic systems are in many cases characterized by higher de-
mands on processing power and memory compared to traditional control systems.
Due to space constraints, merely increasing the number of processing units and the
resulting extension of the cable infrastructure is often not feasible. Virtualization can
reconcile these opposing requirements and increase the processing power without
increasing the space. It achieves this by providing multiple execution environments,
which enable the consolidation of multiple systems onto a single hardware plat-
form (system virtualization). Instead of adding control units, more powerful control
units increase the system’s processing power. Virtualization’s architectural abstrac-
tion supports the migration from single-core to multi-core platforms and helps to

3 Methods of Improving the Dependability of Self-optimizing Systems
153
utilize this multi-core hardware efﬁciently. Multi-core platforms enable higher pro-
cessing performance at lower electrical power per frequency, resulting in less heat
dissipation.
Mechatronic systems are typically safety-critical. Therefore, it is of paramount
importance that the integrated subsystems do not interfere with each other. Virtual-
ization’s integration of multiple systems does not lead to a loss of isolation; both
spatial and temporal separation can be maintained (brick wall partitioning). By
consequence, independently developed software components, such as third party
components, trusted legacy software, and newly developed application-speciﬁc soft-
ware, can be combined to achieve the required functionality. The reusability of soft-
ware is increased without endangering reliability and safety.
In addition to fostering safety-related characteristics, the application of virtu-
alization can actively improve two major attributes of dependability, namely reli-
ability and availability. The virtual machine concept, with its encapsulation of a
subsystem’s state, supports migration; by enabling the migration of virtual ma-
chines, a system can respond to unforeseen failures at runtime. In case of a partially
failed processor unit, partial memory failures, or a breakdown of acceleration co-
processors, the operation of the subsystem can be continued on another processor,
as long as it is still possible to save and transfer the virtual machine’s state. One par-
ticular beneﬁt is self-diagnosing hardware that signals upcoming hardware failures
on the basis of built-in self-tests.
Virtualization is an architectural measure to improve safety, reliability and avail-
ability. In addition to this, by applying the methods Analysis of Self-Healing Op-
erations (Sect. 3.2.8) and Online Model Checking Mechanism (Sect. 3.2.14) , the
system behavior can be monitored at runtime in order to identify malicious system
states.
3.2.15.1
Prerequisites and Input
The application of system virtualization requires a software layer that virtualizes
the hardware resources in order to provide multiple execution environments; this
system software component is called a hypervisor or virtual machine monitor. The
hypervisor has to be conﬁgured for each speciﬁc application according to the char-
acteristics of the subsystems consisting of operating system and applications, which
are to be consolidated. For paravirtualization (modiﬁcation of the operating system
to be aware of the fact that it is executed on top of a hypervisor) neither technical nor
legal issues should preclude the modiﬁcation of the operating system source code.
3.2.15.2
Description
System virtualization describes the methodology of dividing the resources of a
complete computer system into multiple execution environments (platform repli-
cation) [139]. The underlying physical hardware can be shared among multiple
operating system instances, even among different operating systems, in order to

154
S. Groesbrink
Fig. 3.59 System
virtualization
Tasks
Tasks
Tasks
Tasks
Operating 
system 1
Operating 
system 2
Operating 
system 1
Operating 
system 2
Hardware
Hardware
Hardware
Hypervisor
Separation
provide each software component with a suitable system-software interface (see
Fig. 3.59).
The hypervisor (also known as virtual machine monitor) implements the virtual-
ization layer. It creates and manages virtual machines, also referred to as partitions,
which are isolated conceptual duplicates of the real machine [115]. Guest systems
are executed within these virtual machines. The real machine is the hardware envi-
ronment, including processor, memory, and I/O resources, with the instruction set
architecture as the interface for the system software. A virtual machine does not
have to be characterized by exactly the same hardware environment as the real ma-
chine. For example, the instruction set architectures might not be identical, in which
case the hypervisor maps the instruction set of the virtual machine onto the instruc-
tion set of the physical machine. Some physical resources, such as memory, can be
partitioned so that each virtual machine uses a certain fraction. This is not possible
for other resources, for example the processor in a uniprocessor system, in which
case time-sharing has to be applied [139].
The hypervisor retains control of the real hardware resources, without excep-
tion. If a resource is made available to multiple virtual machines, the illusion for
the operating systems of having exclusive access to this resource is maintained by
the hypervisor. When an operating system performs a privileged instruction, i.e. an
instruction that directly accesses the machine state, the hypervisor intercepts the
operation. If an operating system tries, for example, to set a control ﬂag of the mi-
croprocessor, this cannot be allowed, since the modiﬁcation would inﬂuence the
behavior of the other operating systems and destroy their illusion. Therefore, the
hypervisor intercepts this privileged instruction, stores the current value of the ﬂag
and sets the control ﬂag, but resets it before it performs a virtual machine switch.
Hypervisors are classiﬁed by their capability to host unmodiﬁed operating sys-
tems. In terms of full virtualization, unmodiﬁed operating systems can be executed
within a virtual machine. In contrast, paravirtualization requires a porting to the hy-
pervisor’s paravirtualization application programming interface [13]. The operating
system is aware of being executed within a virtual machine and can use hypercalls
to request hypervisor services. Paravirtualization can often be exploited to increase
the performance [78]; however, the major drawback is the need to perform modi-
ﬁcations of critical kernel parts of an operating system. If legal or technical issues
preclude this, for example in case of a commercial operating system, it is not possi-
ble to host it.
The application of system virtualization to embedded real-time systems requires
guaranteeing spatial and temporal separation of the hosted guest systems. Spa-
tial separation refers to protecting the integrity of the memory spaces of both the

3 Methods of Improving the Dependability of Self-optimizing Systems
155
hypervisor and the guests. Any possibility of a harmful activity going beyond the
boundaries of a virtual machine has to be precluded. Spatial separation can be
ensured by hardware components such as memory management units or memory
protection units, which are available for many embedded processors. Temporal
separation is fulﬁlled, if all guest systems are executed in compliance with their
timing requirements, meaning that a predictable, deterministic behavior of every
single real-time guest must be guaranteed. System virtualization implies scheduling
decisions on two levels (hierarchical scheduling): the hypervisor schedules the vir-
tual machines and the hosted operating systems schedule their tasks with their own
schedulers. The hypervisor has the responsibility of scheduling the virtual machines
in a manner that assigns the subsystems early enough and gives them enough time
to complete their computations on schedule.
3.2.15.3
Results
Proteus [12, 61] is a real-time hypervisor for multi-core PowerPC platforms. The
software design (depicted in Fig. 3.60) is based on the Multiple Independent Lev-
els of Security (MILS) approach for highly robust systems [7]. According to this
design concept, a system is divided into multiple isolated components, consisting
of program code, data, and system resources, with no way for information to ﬂow
except through the deﬁned paths. Only the minimal set of components runs in super-
visor mode (privileged mode): interrupt and hypercall handlers, the virtual machine
scheduler, and the inter-partition communication manager (IPCM), which is respon-
sible for communication between virtual machines. All other components, such as
Hardware
Supervisor
mode
Problem
mode
IRQ Handler
Dispatcher
ISA emulator
Hypercall
handler
VM scheduler
IPCM
Untrusted VMP
modules
Full virtualized
application
Hypercalls
Program IRQ
Syscall IRQ
PIT IRQ
External IRQ
Para-virtualized
application
Fig. 3.60 Design of the Proteus hypervisor

156
S. Groesbrink
I/O device drivers, are placed inside a separate partition (Untrusted VMP Modules)
and executed in problem mode (user mode). The interrupt handling is the central
component of the Proteus architecture. Any occurring interrupt is delegated to the
hypervisor, which saves the context of the running virtual machine and forwards the
interrupt request to either the responsible component or back to the guest operating
system.
Proteus is a symmetrical hypervisor with no distinction between cores; all cores
execute guest systems. When required, for example in case of a guest’s call for a
hypervisor service, the hypervisor takes control and its own code is executed on that
core. Different guests on different cores can perform this context switch, from guest
to hypervisor, simultaneously.
As a bare-metal hypervisor, Proteus runs directly on top of the hardware, without
an underlying host operating system [139]. Controlling the hardware directly facil-
itates a more efﬁcient virtualization solution. Resource management and especially
scheduling is not at the mercy of a host operating system; the amount of code exe-
cuted in privileged mode is smaller; and no operating system is incorporated in the
trusted computing base, which increases the overall security and the certiﬁability of
functional safety.
Proteus features both paravirtualization and full virtualization. Paravirtualiza-
tion can be exploited to increase the efﬁciency, but is characterized by a limited
applicability. The support of non-modiﬁable guests requires full virtualization. In
addition, tasks without underlying operating system can be executed on top of the
hypervisor. The concurrent hosting of any combination of paravirtualized guests,
fully virtualized guests, and guest tasks without an operating system is possible
unrestrictedly.
The paravirtualization interface is characterized by two main functionalities.
In addition to providing a handler routine for each privileged instruction which
emulates the instruction, the paravirtualization interface offers additional services.
Paravirtualized operating systems can communicate with other guests through hy-
percalls, call I/O functionality, pass scheduling information to the hypervisor, or
yield the CPU.
As mentioned above, Proteus guarantees spatial and temporal separation of the
guest systems. To achieve spatial separation, each virtual machine operates in its
own address space, which is statically mapped onto a region of the shared mem-
ory. This mapping is protected by the memory management unit of the underlying
hardware platform (e.g. PowerPC 405). If systems are consolidated that have to
communicate with each other, it is mandatory to ensure that this communication is
still possible. The only path of data ﬂow between virtual machines is communica-
tion via the hypervisor’s inter-partition communication manager. If the hypervisor
authorizes the communication, it creates a shared memory tunnel and controls the
correct use.
Ensuring temporal separation requires multiple methods. As a precondition, the
worst-case execution times of all hypervisor routines were determined by path
analysis of the executable ﬁles. The knowledge of these bounded execution times
make it possible to determine the worst-case execution time of a program executed

3 Methods of Improving the Dependability of Self-optimizing Systems
157
on top of Proteus. Each virtual machine can be executed on any core; if this is
undesired, a virtual machine can be assigned to one speciﬁc core or a subset of
cores; for example, a core exclusively to a safety-critical guest. If multiple virtual
machines are assigned to one core, they share it in a time-division multiplexing
manner. The virtual machine scheduling is implemented based on ﬁxed time slices.
The guests’ task sets have to be analyzed and execution time slots within a repetitive
major cycle are assigned to the virtual machines, based on the required utilization
and execution frequency. A real-time response time conserving calculation of the
time slots was developed [76].
Access to shared resources, such as peripheral devices, has to be synchronized.
One common solution is the use of semaphores assigned exclusively to one core
at any time. The PowerPC 405 does not feature any hardware support for mutual
exclusion in a multi-core architecture, which is why Proteus uses a software im-
plementation that does not explicitly rely on hardware support: Leslie Lamport’s
Bakery Algorithm [88]. It was selected since it does not require atomic operations,
such as compare-and-swap or test-and-set; it also satisﬁes FIFO fairness and ex-
cludes starvation. The software synchronization mechanism extends the applicabil-
ity of the hypervisor to shared memory multiprocessor platforms. The processors
work on their own random access memory, but are connected by a bus hierarchy
and can use shared memory. In such a multiprocessor system, virtual machines can
be relocated through migration from one processor to another one. We developed an-
alytical means to evaluate whether a migration of a virtual machine with real-time
constraints can be performed without risking a deadline miss [63].
By the application of processor emulation, Proteus supports even heterogeneous
multiprocessor platforms, which are characterized by processors with differing in-
struction set architectures. Heterogeneous platforms provide suitable processors for
different applications, such as general processing, network control, or signal pro-
cessing. The combination of emulation and heterogeneous platforms enables the
consolidation of legacy systems that were developed for different architectures. Em-
ulation enables the execution of program binaries that were initially compiled for a
different architecture; it translates between instruction set architectures and there-
fore makes cross-platform software portability possible. With the use of emulation
techniques, Proteus supports the migration of virtual machines even from one pro-
cessor to one processor with a different instruction set architecture at runtime [62].
We developed an emulation approach that maintains real-time capability [77]; it
minimizes the worst-case execution time overhead and combines interpretation
and binary translation for an optimal trade-off between required memory and
performance.
In a pre-processing step, critical basic blocks are identiﬁed; these blocks are char-
acterized by a high performance ratio between the emulated execution on the host
as compared to native execution. These blocks are translated once and the result
is stored, meaning that the size of the available memory limits this optimization.
Interpretation is used for non-selected blocks.
Proteus offers static conﬁgurability. Depending on the requirements of the ac-
tual system, the system designer can conﬁgure the hypervisor by modifying a

158
R. Dorociak, J. Gausemeier, and P. Iwanek
conﬁguration ﬁle. According to these speciﬁcations, the preprocessor manipulates
the implementation ﬁles and removes unneeded code. The system designer can de-
cide to enable TLB virtualization, device driver support, inter-partition communica-
tion and multiple performance-enhancement features.
3.2.15.4
Application Example
The basic idea of system virtualization is to create an integrated system that com-
bines the functionality of multiple systems in order to attain a complex behavior.
This modular synthesis has the potential to reduce development time by increasingly
reusing trusted systems. The consolidation on a single hardware platform can often
provide more efﬁcient implementations as concerns regarding power consumption,
hardware footprint and system costs. Multiple operating systems can be hosted to
provide all applications with a suitable interface. Industrial automation systems, for
example, often require both a deterministic real-time operating system for the con-
trol of actuators and a feature-rich general-purpose operating system for the human-
machine interface and connection to the corporate IT. Of paramount importance
from a dependability point of view, system virtualization maintains the isolation
between the integrated systems. Spatial separation precludes any possibility of a
harmful activity going beyond the boundaries of a virtual machine and temporal
separation precludes a guest not being able to meet its timing requirements due to
interference from another guest.
3.3
Methodology for the Selection of Dependability Methods
for the Development of Self-optimizing Systems
Rafal Dorociak, Jürgen Gausemeier, and Peter Iwanek
The development of dependable self-optimizing systems is a difﬁcult task that en-
gineers have to face, involving many complex aspects such as non-deterministic
behavior and cross-domain fault propagation. There is also an immense number of
engineering methods which can be used to improve the dependability of such self-
optimizing systems. Many of these speciﬁcally intend to improve the dependability
of self-optimizing systems have already been discussed in this chapter, such as It-
erative Learning Stochastic Disturbance Proﬁles in Sect. 3.2.2, or Online Model
Checking in Sect. 3.2.14. Beyond the scope of this book, there are also many more
methods which can be used during the development phase of technical systems,
such as the FTA, FMEA etc. (some of the existing databases provide information
on more than 700 such methods [105]). Which of them are suitable for a particular
system depends on the underlying development task and the Principle Solution of
the system. The developer faces the challenge of how to choose suitable engineering
methods from the vast number of available methods and how to embed them into the
product development process. Nowadays, as a rule, the search for and selection of a
method have to be done manually, which is tedious and often error-prone. Therefore,

3 Methods of Improving the Dependability of Self-optimizing Systems
159
there is an evident need for a methodology which can aid developers in choosing and
applying appropriate dependability engineering methods. Such a methodology has
been developed within the Collaborative Research Center (CRC) 614 and is pre-
sented in the following. This methodology includes a method database, a guide to
selection and planning the use of dependability engineering methods throughout the
entire product development process, and a software tool. It enables the developer to
choose and plan the use of suitable dependability engineering methods for the par-
ticular development task. The developer receives suggestions on which methods can
be used, how they depend on each other, and how these methods can be combined,
as well as what their optimal chronological order is. The end result of this process is
a proposed workﬂow of process steps and methods. In the following, the constituent
parts of the methodology are explained in more detail.
The method database contains the description of dependability engineering meth-
ods, which have been manually entered into the database. They are characterized
by their inputs (e.g. speciﬁcation of the Principle Solution) and outputs (e.g. de-
scription of the failure propagation) as well as by a number of criteria, such as the
dependability attributs (e.g. safety), the domain (e.g. control engineering), the de-
velopment phase (e.g. Conceptual Design), the industrial sector (e.g. automotive),
relevant standards (e.g. CENELEC 50128 [46]), etc. Links to the development pro-
cess and external documentation are also included. In addition, useful documents
(e.g. templates, usage in former projects) and the relationships between methods
are described as well. The following relationships between methods are those most
frequently used in the methodology:
• "is a prerequisite for",
• "requires",
• "is the further development/continuation of",
• "has been further developed to" and
• "can be complemented by".
As a example: the Early Probabilistic Reliability Analysis of an Advanced
Mechatronic System based on its Principle Solution (Sect. 3.1.1) "is a further de-
velopment/continuation of" the classic FTA and FMEA. To use the Early Proba-
bilistic Reliability Analysis, the speciﬁcation of the system should be carried out
using the speciﬁcation technique CONSENS meaning that the speciﬁcation tech-
nique CONSENS "is a prerequisite for" the Early Probabilistic Reliability Analysis.
From another perspective, the Early Probabilistic Reliability Analysis "requires"
the usage of the speciﬁcation technique CONSENS. By showing these relationships
between methods, the links between methods as well as their interactions can be
clearly represented, providing an easily intelligible overview of how the methods
are connected to one another.
Additionally, the methods can be classiﬁed with regard to their self-optimizing
relevance as dependability engineering methods which are either speciﬁc to or
which are not speciﬁc to self-optimizing systems:

160
R. Dorociak, J. Gausemeier, and P. Iwanek
Methods which are not speciﬁc to self-optimizing systems:
A number of classical dependability engineering methods can be used to im-
prove the dependability of a self-optimizing system. Examples are FMEA, FTA,
FHA, etc. They are usually performed on detailed system designs, and thus rela-
tively late in the product development process. Some methods have been adapted
for use in the Conceptual Design, such as the early FMEA method [38]. These
classical methods allow initial statements with respect to the dependability of
the system to be made. Based on those statements, potential weaknesses can be
found in the Principle Solutions and counter-measures derived; one example of a
possible counter-measure is the use of redundancy for a particular dependability-
critical system element.
Methods which are speciﬁc to self-optimizing systems:
In addition, some dependability engineering methods have been developed within
the CRC 614 which are speciﬁcally designed for use with self-optimizing sys-
tems (see also previous sections). They are usually used during operation i.e. the
self-optimizing system is able to compensate for failures during operation and to
alter its behavior to reach a dependable state. One example is the Multi-Level de-
pendability concept (see Sect. 3.2.1), which integrates advanced condition mon-
itoring [90, 140] into a self-optimizing system. Another example is a method
for the Conceptual Design of the System of Objectives for a self-optimizing
system [114].
The above-mentioned classiﬁcation systems have been incorporated into our
methodology for aiding developers during the improvement of the dependability
of self-optimizing systems.
A software tool has also been developed for use in this methodology. It supports
the insertion of new and the modiﬁcation of existing method descriptions and offers
a search function to make it easier for the user to ﬁnd suitable methods. It allows
users to search for dependability engineering methods with regard to their charac-
terization criteria (see Chap. 4 for a more detailed example).
The guide for planning methods proposes in which sequence the selected depend-
ability engineering methods should be used. Methods will be selected by the user
based on the list of methods returned by the software tool. This recommendation
is based on two pieces of information, both of which are stored in the database:
The ﬁrst piece of information is the description of the input and output relationships
between the methods, and the development tasks and their sequences, which are
deﬁned for each of the methods. These sequences are also saved in the database’s
method description; if the user selects one of the displayed methods, the correspond-
ing sequence will be presented.
In the following, a brief description of how the methodology can be used is
provided: First, a search for speciﬁc dependability engineering methods is per-
formed using the method database (Step 1 in Fig. 3.61). The result is a list of all
recommended methods which match the search criteria. As stated before, these
search criteria (corresponding domain, relevant dependability attributes, respective
development phase, relevant standards, etc.) are provided by the safety engineer

3 Methods of Improving the Dependability of Self-optimizing Systems
161
...
Method 2
Method
database
Method 1
Abstract
Summary
Associated disciplines
Dependability atributes
Reliability
Availability
Safety
Development phase
Conceptual
Design
Design and 
Development
Operation
ME
E/E
CE
SE
Relevant standards
Literature/Links
In
Method
Out
Useful supporting
documents
Relevant industrial
sectors
Related 
methods
Contact
person
Analyze system 
dependability
Impr.
Principle 
Solution
Active
Structure
Behavior
Function
Hierarchy
Funct.
descr.
Funct.
descr.
Impr.
Principle
Solution
...
...
...
RPN,
rel. 
relev.
System
analysis
Failure
analysis
Derivation of
improv. measures
Improvement of
the Principle Sol.
Search for 
dependability 
methods in 
the database
1
Characterization of the methods
2
Development process (excerpt)
3
Generic dependability workflow for specific method usage (excerpt)
4
Early 
FMEA
Fig. 3.61 Selection and planning of dependability engineering methods with regard to the
underlying development task

162
R. Dorociak, J. Gausemeier, and P. Iwanek
and correspond to the development task at hand. The user selects the appropriate de-
pendability engineering methods manually from the list (Step 2). From the method
database, the user navigates to the corresponding process steps in the process model
(Step 3). The software tool supports the planning and the application of the chosen
methods based on the underlying process model descriptions. The result is a work-
ﬂow diagram (Step 4) which suggests the sequence of process steps and methods
to be used. The planning is performed with regard to the underlying development
task; for example, for a safety engineer, a sequence of methods is proposed which
complies with a given safety standard. The usage of the methodology and the cor-
rosponding methods will be discussed further in Chap. 4.
By using the presented methodology, the developer can decide both more easily
and more quickly which of the vast number of available dependability engineering
methods is best suited to the developmenttask at hand. In addition, this methodology
can assist him or her in planning the application of the selected methods during the
development process. It also encourages the documentation of best practice, i.e.
exemplary combinations of methods used in projects which can be repeated later.
New projects can later be structured upon those best practices.
The concrete use of this methodology is shown in Chap. 4.
References
1. Condition monitoring and diagnostics of machines – General guidelines (ISO
17359:2011). International Standard (2011)
2. Aickelin, U., Cayzer, S.: The Danger Theory and Its Application to Artiﬁcial Immune
Systems. In: 1st International Conference on ARtiﬁcial Immune Systems (ICARIS
2002), Canterbury, UK, pp. 141–148 (2002)
3. Allgower, E.L., Georg, K.: Numerical continuation methods, vol. 33. Springer, Berlin
(1990), doi:10.1007/978-3-642-61257-2
4. Alpaydın, E.: Introduction to Machine Learning. The MIT Press (2004)
5. Alur, R.: Formal Veriﬁcation of Hybrid Systems. In: Proceedings of the 9th ACM In-
ternational Conference on Embedded Software, Taipei, TW, pp. 273–278. ACM, New
York (2011), doi:10.1145/2038642.2038685
6. Alur, R., Dill, D.L.: A Theory of Timed Automata. Theoretical Computer Science 126,
183–235 (1994), doi:10.1016/0304-3975(94)90010-8
7. Alves-Foss, J., Harrison, W.S., Taylor, C.: The MILS Architecture for High Assurance
Embedded Systems. International Journal of Embedded Systems 2(3), 239–247 (2006),
doi:10.1504/IJES.2006.014859
8. Androutsopoulos, K., Clark, D., Harman, M., Hierons, R.M., Li, Z., Tratt, L.: Amor-
phous Slicing of Extended Finite State Machines. IEEE Transactions on Software En-
gineering 99(PrePrints), 1 (2012), doi:10.1109/TSE.2012.72
9. Anis, A., Goschin, S., Lehrig, S., Stritzke, C., Zolynski, T.: Developer Documentation
of the Project Group SafeBots II. Project group. University of Paderborn, Department
of Computer Science, Paderborn, DE (2012)
10. Arkoudas, K., Rinard, M.: Deductive Runtime Certiﬁcation. In: Proceedings of
the 2004 Workshop on Runtime Veriﬁcation (RV 2004), Barcelona, ES (2004),
doi:10.1016/j.entcs.2004.01.035

3 Methods of Improving the Dependability of Self-optimizing Systems
163
11. Avizienis, A., Laprie, J.C., Randell, B., Landwehr, C.: Basic Concepts and Taxonomy
of Dependable and Secure Computing. IEEE Transactions on Dependable and Secure
Computing 1(1), 11–33 (2004), doi:10.1109/TDSC.2004.2
12. Baldin, D., Kerstan, T.: Proteus, a Hybrid Virtualization Platform for Embedded Sys-
tems. In: Rettberg, A., Zanella, M.C., Amann, M., Keckeisen, M., Rammig, F.J. (eds.)
IESS 2009. IFIP AICT, vol. 310, pp. 185–194. Springer, Heidelberg (2009)
13. Barham, P., Dragovic, B., Fraser, K., Hand, S., Harris, T., Ho, A., Neugebauer, R.,
Pratt, I., Warﬁeld, A.: Xen and the Art of Virtualization. In: Proceedings of the 19th
ACM Symposium on Operating Systems Principles, Bolton Landing, NY, US (2003),
doi:10.1145/945445.945462
14. Barnett, M., Schulte, W.: Spying on Components: A Runtime Veriﬁcation Technique.
In: Leavens, G.T., Sitaraman, M., Giannakopoulou, D. (eds.) Workshop on Speciﬁca-
tion and Veriﬁcation of Component-Based Systems, pp. 1–9. Published as Iowa State
Technical Report 01-09a (2001)
15. Becker, S., Brenner, C., Brink, C., Dziwok, S., Heinzemann, C., Löfﬂer, R., Pohlmann,
U., Schäfer, W., Suck, J., Sudmann, O.: The MechatronicUML Design Method – Pro-
cess, Syntax, and Semantics. Tech. Rep. tr-ri-12-326, Software Engineering Group.
Heinz Nixdorf Institute, University of Paderborn (2012)
16. Behrmann, G., David, A., Larsen, K.G., Pettersson, P., Yi, W., Hendriks, M.: Uppaal
4.0. In: Quantitative Evaluation of Systems, QEST 2006, pp. 125–126. IEEE Computer
Society (2006), doi:10.1109/QEST.2006.59
17. Ben-Gal, I.: Bayesian Networks. Encyclopedia of Statistics in Quality and Reliability
(2007), doi:10.1002/9780470061572.eqr089
18. Berezin, S., Campos, S.V.A., Clarke, E.M.: Compositional Reasoning in Model Check-
ing. In: de Roever, W.-P., Langmaack, H., Pnueli, A. (eds.) COMPOS 1997. LNCS,
vol. 1536, pp. 81–102. Springer, Heidelberg (1998)
19. Bielawny, D., Krüger, M., Reinold, P., Timmermann, J., Trächtler, A.: Iterative
learning of Stochastic Disturbance Proﬁles Using Bayesian Networks. In: 9th
International Conference on Industrial Informatics (INDIN), Lisbon, PT (2011),
doi:10.1109/INDIN.2011.6034920
20. Biere, A., Cimatti, A., Clarke, E.M., Strichman, O., Zhu, Y.: Bounded model checking.
Advances in Computers 58, 118–149 (2003),
http://repository.cmu.edu/compsci/451
21. Birolini, A.: Reliability Engineering – Theory and Practice, 5th edn. Springer, Heidel-
berg (2007), doi:10.1007/978-3-662-03792-8
22. Blanke, M., Kinnaert, M., Lunze, J., Staroswiecki, M.: Diagnosis and Fault-Tolerant
Control. Springer (2006), doi:10.1007/978-3-662-05344-7
23. Blesken, M., Rückert, U., Steenken, D., Witting, K., Dellnitz, M.: Multiobjective opti-
mization for transistor sizing of CMOS logic standard cells using set-oriented numerical
techniques. In: NORCHIP 2009, pp. 1–4 (2009), doi:10.1109/NORCHP.2009.5397800
24. Borkar, S.: Designing Reliable Systems from Unreliable Components: The Chal-
lenges of Transistor Variability and Degradation. IEEE Micro 25(6), 10–16 (2005),
doi:10.1109/MM.2005.110
25. Cao, Y., Hussaini, M., Zang, T.: An Efﬁcient Monte Carlo Method for Optimal Control
Problems with Uncertainty. Computational Optimization and Applications 26, 219–230
(2003), doi:10.1023/A:1026079021836
26. Cassez, F., Roux, O.H.: Structural Translation from Time Petri Nets to Timed Au-
tomata. Electron. Notes Theor. Comput. Sci. 128, 145–160 (2005), doi:10.1016/
j.jss.2005.12.021

164
References
27. de Castro, L., Timmis, J.: Artiﬁcial Immune Systems: A New Computational Approach.
Springer, London (2002), http://www.cs.kent.ac.uk/pubs/2002/1507
28. Chen, F., Rosu, G.: Towards Monitoring-Oriented Programming: A Paradigm Com-
bining Speciﬁcation and Implementation. In: Proceedings of the 2003 Workshop
on Runtime Veriﬁcation (RV 2003), Boulder, CO, US (2003), doi:10.1016/S1571-
0661(04)81045-4
29. Clarke, E.M., Grumberg, O., Long, D.E.: Model checking and abstraction. ACM Trans.
Program. Lang. Syst. 16(5), 1512–1542 (1994), doi:10.1145/186025.186051
30. Clarke, E.M., Grumberg, O., Peled, D.A.: Model Checking. MIT Press (1999)
31. Dasgupta, D., Nino, F.: Immunological Computation: Theory and Applications, 1st edn.
Auerbach Publications, Boston (2008)
32. Deb, K.: Multi-Objective Optimization Using Evolutionary Algorithms. Wiley (2001)
33. Dell’Aere, A.: Numerical Methods for the Solution of Bi-level Multi-objective Opti-
mization Problems. HNI-Verlagsschriftenreihe. Heinz Nixdorf Institute, University of
Paderborn, Paderborn (2008)
34. Dellnitz, M., Schütze, O., Hestermeyer, T.: Covering Pareto Sets by Multilevel Subdi-
vision Techniques. Journal of Optimization Theory and Application 124(1), 113–136
(2005), doi:10.1007/s10957-004-6468-7
35. Dellnitz, M., Witting, K.: Computation of robust Pareto points. International Jour-
nal of Computing Science and Mathematics 2(3), 243–266 (2009), doi:10.1504/
IJCSM.2009.027876
36. DeMillo, R.A., Offutt, A.J.: Constraint-based Automatic Test Data Generation. IEEE
Transactions on Software Engineering 17(9) (1991), doi:10.1109/32.92910
37. Deuﬂhard, P., Hohmann, A.: Numerical analysis in modern scientiﬁc computing: an
introduction, 2nd edn. Springer, New York (2003), doi:10.1007/978-0-387-21584-6
38. Dorociak,
R.:
Early
Probabilistic
Reliability
Analysis
of
Mechatronic
Sys-
tems. In: Proceedings of the Reliability and Maintainability Symposium (2012),
doi:10.1109/RAMS.2012.6175464
39. Dorociak, R., Gausemeier, J.: Absicherung der Zuverlässigkeit komplexer mechatronis-
cher Systeme auf Basis der domänenübergreifenden Prinziplösung. In: 25. Fachtagung:
Technische Zuverlässigkeit (TTZ), Leonberg, DE (2011)
40. Drusinsky, D.: The Temporal Rover and the ATG Rover. In: Havelund, K., Penix, J.,
Visser, W. (eds.) SPIN 2000. LNCS, vol. 1885, pp. 323–330. Springer, Heidelberg
(2000)
41. Easwaran, A., Kannan, S., Sokolsky, O.: Steering of Discrete Event Systems: Con-
trol Theory Approach. Electr. Notes Theor. Comput. Sci. 144(4), 21–39 (2006),
doi:10.1016/j.entcs.2005.02.066
42. Eckardt, T., Heinzemann, C., Henkler, S., Hirsch, M., Priesterjahn, C., Schäfer, W.:
Modeling and Verifying Dynamic Communication Structures Based on Graph Trans-
formations, pp. 3–22. Springer (2013), doi:10.1007/s00450-011-0184-y
43. Ericson, C.: Hazard Analysis Techniques for System Safety. John Wiley & Sons, Hobo-
ken (2005), doi:10.1002/0471739421
44. Estler, H.C., Wehrheim, H.: Heuristic Search-Based Planning for Graph Transformation
Systems. In: Proceedings of the Workshop on Knowledge Engineering for Planning and
Scheduling, Freiburg, DE, pp. 54–61 (2011)
45. European Committee for Electrotechnical Standardization (CENELEC): CENELEC
EN 50129: 2003. Railway Applications – Communication, Signalling and Processing
Systems – Safety Related Electronic Systems for Signalling. European Standard (2003)
46. European Committee for Electrotechnical Standardization (CENELEC): Railway appli-
cations Communication, signalling and processing systems Software for railway control
and protection systems, CENELEC EN 50128. European Standard (2011)

3 Methods of Improving the Dependability of Self-optimizing Systems
165
47. Fenelon, P., McDermid, J.A., Nicolson, M., Pumfrey, D.J.: Towards Integrated Safety
Analysis and Design. ACM SIGAPP Applied Computing Review 2(1), 21–32 (1994),
doi:10.1145/381766.381770
48. FG Rammig, University of Paderborn: ORCOS – Organic Reconﬁgurable Operating
System, https://orcos.cs.uni-paderborn.de/doxygen/html
(accessed August 12, 2013)
49. Figueira, J., Greco, S., Ehrgott, M.: Multiple Criteria Decision Analysis: State of the
Art Surveys. Kluwer Academic Publishers, Boston (2005), doi:10.1007/b100605
50. Fine, S., Ziv, A.: Coverage Directed Test Generation for Functional Veriﬁcation Using
Bayesian Networks. In: Proceedings of the 40th annual Design Automation Conference,
Anaheim, CA, US (2003), doi:10.1145/775832.775907
51. Fischer, T., Niere, J., Torunski, L., Zündorf, A.: Story Diagrams: A New Graph Rewrite
Language based on the Uniﬁed Modeling Language. In: 6th Int. Workshop on Theory
and Application of Graph Transformations (TAGT 1998) (1998)
52. Flaßkamp, K., Heinzemann, C., Krüger, M., Steenken, D., Ober-Blöbaum, S.,
Schäfer, W., Trächtler, A., Wehrheim, H.: Sichere Konvoibildung mit Hilfe opti-
maler Bremsproﬁle. In: Gausemeier, J., Rammig, F.J., Schäfer, W., Trächtler, A. (eds.)
Tagungsband zum 9. Paderborner Workshop Entwurf Mechatronischer Systeme, HNI-
Verlagsschriftenreihe. Heinz Nixdorf Institute, University of Paderborn, Paderborn
(2013)
53. Fox, M., Long, D.: PDDL 2.1: An Extension to PDDL for Expressing Tempo-
ral Planning Domains. Journal of Artiﬁcial Intelligence Research, 189–208 (2003),
doi:10.1613/jair.1129
54. Gausemeier, J., Frank, U., Donoth, J., Kahl, S.: Speciﬁcation Technique for the Descrip-
tion of Self-Optimizing Mechatronic Systems. Research in Engineering Design 20(4),
201–223 (2009), doi:10.1007/s00163-008-0058-x
55. Gausemeier, J., Rammig, F.J., Schäfer, W. (eds.): Design Methodology for Intelligent
Technical Systems. Lecture Notes in Mechanical Engineering. Springer, Heidelberg
(2014), doi:10.1007/978-3-642-45435-6_2
56. Geisler, J., Witting, K., Trächtler, A., Dellnitz, M.: Multiobjective Optimization of Con-
trol Trajectories for the Guidance of a Rail-bound Vehicle. In: Proceedings of the 17th
IFAC World Congress of The International Federation of Automatic Control, Seoul, KR
(2008), doi:10.3182/20080706-5-KR-1001.00738
57. Ghallab, M., Nau, D., Traverso, P.: Automated Planning – Theory and Practice. Morgan
Kaufmann (2004)
58. Giaquinta, M., Hildebrandt, S.: Calculus of variations. Springer, Berlin (1996)
59. Giese, H., Tichy, M.: Component-Based Hazard Analysis: Optimal Designs, Prod-
uct Lines, and Online-Reconﬁguration. In: Górski, J. (ed.) SAFECOMP 2006. LNCS,
vol. 4166, pp. 156–169. Springer, Heidelberg (2006)
60. Gill, P.E., Jay, L.O., Leonard, M.W., Petzold, L.R., Sharma, V.: An SQP Method for
the Optimal Control of Large-scale Dynamical Systems. Journal of Computational and
Applied Mathematics 120, 197–213 (2000), doi:10.1016/S0377-0427(00)00310-1
61. Gilles, K., Groesbrink, S., Baldin, D., Kerstan, T.: Proteus Hypervisor – Full Virtualiza-
tion and Paravirtualization for Multi-Core Embedded Systems. In: Schirner, G., Götz,
M., Rettberg, A., Zanella, M.C., Rammig, F.J. (eds.) IESS 2013. IFIP AICT, vol. 403,
pp. 293–305. Springer, Heidelberg (2013)
62. Groesbrink, S.: A First Step Towards Real-time Virtual Machine Migration in Het-
erogeneous Multi-Processor Systems. In: Proceedings of the 1st Joint Symposium on
System-Integrated Intelligence, Hannover, DE (2012)

166
References
63. Groesbrink, S.: Basics of Virtual Machine Migration on Heterogeneous Architectures
for Self-Optimizing Mechatronic Systems. Necessary Conditions and Implementation
Issues 7, 69–79 (2013)
64. Güdemann, M., Ortmeier, F., Reif, W.: Safety and Dependability Analysis of Self-
Adaptive Systems. In: Proccedings of the 2nd International Symposium on Leverag-
ing Applications of Formal Methods, Veriﬁcation and Validation, ISoLA 2006 (2006),
doi:10.1109/ISoLA.2006.38
65. Hagemeyer, J., Hilgenstein, A., Jungewelter, D., Cozzi, D., Felicetti, C., Rueckert, U.,
Korf, S., Koester, M., Margaglia, F., Porrmann, M., Dittmann, F., Ditze, M., Harris, J.,
Sterpone, L., Ilstad, J.: A scalable platform for run-time reconﬁgurable satellite payload
processing. In: AHS, pp. 9–16. IEEE (2012), doi:10.1109/AHS.2012.6268642
66. Hagemeyer, J., Kettelhoit, B., Koester, M., Porrmann, M.: Design of Homogeneous
Communication Infrastructures for Partially Reconﬁgurable FPGAs. In: Proceedings
of the International Conference on Engineering of Reconﬁgurable Systems and Algo-
rithms, Las Vegas, NV, US. CSREA Press (2007)
67. Hampton, M., Petithomme, S.: Leveraging a Commercial Mutation Analysis Tool for
Research. In: Proceedings of the Testing Academic & Industrial Conference Practice
and Research Techniques, Windsor, UK (2007), doi:10.1109/TAIC.PART.2007.39
68. Havelund, K., Rosu, G.: Java PathExplorer – A runtime veriﬁcation tool. In: Proceed-
ings 6th International Symposium on Artiﬁcial Intelligence, Robotics and Automation
in Space (ISAIRAS 2001), Montreal, QC, CA (2001), doi:10.1.1.16.1774
69. Henzinger, T.A.: The theory of hybrid automata. In: Proceedings of the 11th Annual
IEEE Symposium on Logic in Computer Science, New Brunswick, NJ, US, pp. 278–
292. IEEE Computer Society (1996), doi:10.1109/LICS.1996.561342
70. Hillermeier, C.: Nonlinear Multiobjective Optimization – A Generalized Homotopy
Approach. Birkhäuser, Berlin (2001)
71. Hölscher, C., Keßler, J.H., Krüger, M., Trächtler, A., Zimmer, D.: Hierarchi-
cal Optimization of Coupled Self-Optimizing Systems. In: Proceedings of the
10th IEEE International Conference on Industrial Informatics, Beijing, CN (2012),
doi:10.1109/INDIN.2012.6301199
72. Howden, W.E.: Weak Mutation Testing and Completeness of Test Sets. IEEE Transac-
tions on Software Engineering 8(4) (1982), doi:10.1109/TSE.1982.235571
73. International Electrotechnical Commission (IEC): IEC 60812: 2006. Analysis tech-
niques for system reliability – Procedure for failure mode and effects analysis (FMEA).
International Standard (2006)
74. International Electrotechnical Commission (IEC): IEC 61025: Fault Tree Analysis
(FTA). International Standard (2006)
75. Isermann, R.: Fault-Diagnosis Systems – An Introduction from Fault Detection to Fault
Tolerance. Springer, Berlin (2005), doi:10.1007/3-540-30368-5
76. Kerstan, T., Baldin, D., Groesbrink, S.: Full Virtualization of Real-Time Systems by
Temporal Partitioning. In: Proceedings of the of the 6th International Workshop on Op-
erating Systems Platforms for Embedded Real-Time Applications, Brussels, BE (2010)
77. Kerstan, T., Oertel, M.: Design of a Real-time Optimized Emulation Method. In:
Proceedings of the Design, Automation and Test in Europe, Dresden, DE (2010),
doi:10.1109/DATE.2010.5457126
78. King, S., Dunlap, G., Chen, P.: Operating System Support for Virtual Machines. In:
Proc. of the USENIX Annual Technical Conference (2003)
79. Kleywegt, A.J., Shapiro, A., Homem-de Mello, T.: The Sample Average Approximation
Method for Stochastic Discrete Optimization. SIAM J. on Optimization 12(2), 479–502
(2002), doi:10.1137/S1052623499363220

3 Methods of Improving the Dependability of Self-optimizing Systems
167
80. Klöpper, B.: Ein Beitrag zur Verhaltensplanung für interagierende intelligente
mechatronische
Systeme
in
nicht-deterministischen
Umgebungen.
In:
HNI-
Verlagsschriftenreihe, vol. 253. Heinz Nixdorf Institute, University of Paderborn,
Paderborn (2009)
81. Klöpper, B., Aufenanger, M., Adelt, P.: Planning for Mechatronics Systems – Ar-
chitechture, Methods and Case Study. Engineering Applications of Artiﬁcial Intelli-
gence 25(1), 174–188 (2012), doi:10.1016/j.engappai.2011.08.004
82. Klöpper, B., Sondermann-Wölke, C., Romaus, C.: Probabilistic Planning for Predictive
Condition Monitoring and Adaptation within the Self-Optimizing Energy Management
of an Autonomous Railway Vehicle. Journal for Robotics and Mechatronics 24(1), 5–15
(2012)
83. Koester, M., Luk, W., Hagemeyer, J., Porrmann, M., Rueckert, U.: Design Opti-
mizations for Tiled Partially Reconﬁgurable Systems. IEEE Transactions on Very
Large Scale Integration (VLSI) Systems 19(6), 1048–1061 (2011), doi:10.1109/
TVLSI.2010.2044902
84. Kopetz, H.: Real-time systems: design principles for distributed embedded applications.
Kluwer international series in engineering and computer science: Real-time systems.
Kluwer Academic Publishers (2011), doi:10.1007/978-1-4419-8237-7
85. Kranenburg, T., van Leuken, R.: MB-LITE: A Robust, Light-weight Soft-core Imple-
mentation of the MicroBlaze Architecture. In: Proceedings of Design, Automation, and
Test in Europe Conference, Dresden, DE (2010), doi:10.1109/DATE.2010.5456903
86. Krüger, M., Witting, K., Dellnitz, M., Trächtler, A.: Robust Pareto Points with Respect
to Crosswind of an Active Suspension System. In: Proceedings of the 1st Joint Interna-
tional Symposium on System-Integrated Intelligence, Hannover, DE (2012)
87. Kuhn, H., Tucker, A.: Nonlinear Programming. In: Neumann, J. (ed.) Proceedings of
the 2nd Berkeley Symposium on Mathematical Statistics and Probability, Berkeley, CA,
US, pp. 481–492 (1951)
88. Lamport, L.: A new solution of Dijkstra’s concurrent programming problem. Commu-
nunications of the ACM 17, 453–455 (1974), doi:10.1145/361082.361093
89. Langseth, H., Portinale, L.: Bayesian Networks in Reliability. Reliability Engineering
& System Safety 92(1), 92–108 (2007), doi:10.1016/j.ress.2005.11.037
90. Lee, J., Ni, D., Djurdjanovic, H., Qiu, H., Liao, H.: Intelligent prognostic tools
and e-maintenance. Computers in Industry 57, 476–489 (2006), doi:10.1016/
j.compind.2006.02.014
91. van Leeuwen, J., Hartmanis, J., Goos, G. (eds.): Partial-Order Methods for the Veriﬁ-
cation of Concurrent Systems: An Approach to the State-Explosion Problem. Springer,
New York (1996), doi:10.1.1.56.8794
92. Leveson, N.G.: Safeware: System Safety and Computers. ACM (1995)
93. Levine, W.: The Control Handbook: Control System Fundamentals, Control System
Applications, Control System Advanced Methods. Electrical Engineering Handbook
Series. Taylor & Francis Group (2010)
94. Leyendecker, S., Lucas, L.J., Owhadi, H., Ortiz, M.: Optimal control strategies for ro-
bust certiﬁcation. Journal of Computational and Nonlinear Dynamics 5(3), 031,008–
031,008 (2010), doi:10.1115/1.4001375
95. Li, J., Zhang, H.C., Lin, Z.: Asymmetric negotiation based collaborative product design
for component reuse in disparate products. Computers & Industrial Engineering 57(1),
80–90 (2009), doi:10.1016/j.cie.2008.11.021
96. Luenberger, D.G.: Linear and nonlinear programming, 2nd edn. Addison-Wesley, Read-
ing (1987)

168
References
97. Marsden, J.E., West, M.: Discrete Mechanics and Variational Integrators. Acta Numer-
ica 10, 357–514 (2001)
98. Mathew, G., Pinto, A.: Optimal design of a class of hybrid systems with uncertain
parameters. In: 50th IEEE Conference on Decision and Control and European Control
Conference, Orlando, FL, US, pp. 539–544 (2011), doi:10.1109/CDC.2011.6161357
99. Matzinger, P.: Tolerance, danger, and the extended family. Annual Review of Immunol-
ogy 12(1), 991–1045 (1994), doi:10.1146/annurev.iy.12.040194.005015
100. Meijer, R.: PDDL Planning Problems and GROOVE Graph Transformations: Combin-
ing Two Worlds with a Translator. In: 17th Twente Student Conference on IT (2012)
101. Meyer, T., Keßler, J.H., Sextro, W., Trächtler, A.: Increasing Intelligent Systems’ Reli-
ability by using Reconﬁguration. In: Proceedings of the Annual Reliability and Main-
tainability Symposium, RAMS (2013), doi:10.1109/RAMS.2013.6517636
102. Miettinen, K.: Nonlinear Multiobjective Optimization. Kluwer Academic Publishers
(1999), doi:10.1007/978-1-4615-5563-6
103. Miner, M.: Cumulative Damage in Fatigue. ASME Journal of Applied Mechanics 12,
A159–A164 (1945)
104. Myers, G.J., Sandler, C.: The Art of Software Testing. John Wiley & Sons (2004)
105. National Aerospace Laboratory in the Netherlands: The Safety Methods Database
(2012), http://www.nlr.nl/documents/flyers/SATdb.pdf
(accessed September 12, 2012)
106. Newcomb, R.W. (ed.): Linear Optimal Control. Networks Series. Prentice-Hall (1971)
107. Ober-Blöbaum, S., Junge, O., Marsden, J.E.: Discrete Mechanics and Optimal Control:
An Analysis. Control, Optimisation and Calculus of Variations 17(2), 322–352 (2011),
doi:10.1051/cocv/2010012
108. Ober-Blöbaum, S., Seifried, A.: A multiobjective optimization approach for the optimal
control of technical systems with uncertainties. In: Proceedings of the European Control
Conference, Zürich, CH, pp. 204–209 (2013)
109. Oberthür, S.: Towards an RTOS for Self-Optimizing Mechatronic Systems. In: HNI-
Verlagsschriftenreihe. Heinz Nixdorf Institute, University of Paderborn, Paderborn
(2010)
110. Object Management Group: Uniﬁed Modeling Language (UML) 2.3 Superstructure
Speciﬁcation (2010), http://www.omg.org/spec/UML/2.3/
(Document formal/2010-05-05)
111. Park, R.: Contamination Control, and OEM Perspective. In: Workshop on Total Con-
tamination Control. Centre for Machine Condition Monitoring. Monash University
(1997)
112. Peterson, M., Winer, W.: Wear Control Handbook. The American Society of Mechani-
cal Engineers (1980)
113. Pomeranz, I., Reddy, S.M.: On the generation of small dictionaries for fault location.
In: Proceedings of the 1992 IEEE/ACM International Conference on Computer-Aided
Design, ICCAD 1992, pp. 272–279. IEEE Computer Society Press, Los Alami-
tos
(1992),
http://dl.acm.org/citation.cfm?id=304032.304116,
doi:10.1109/ICCAD.1992.279361
114. Pook, S., Gausemeier, J., Dorociak, R.: Securing the Reliability of Tomorrow’s Systems
with Self-Optimization. In: Proceedings of the Reliability and Maintainability Sympo-
sium, Reno, NV, US (2012)
115. Popek, G.J., Goldberg, R.P.: Formal Requirements for Virtualizable Third Gen-
eration Architectures. Communications
of
the ACM 17(7), 412–421
(1974),
doi:10.1145/361011.361073

3 Methods of Improving the Dependability of Self-optimizing Systems
169
116. Porrmann, M.: Adaptive Hardware Platforms for Self-Optimizing Mechatronic Sys-
tems. In: International Workshop on Computing in Heterogeneous, Autonomous ’N’
Goal-oriented Environments, DAC – Design Automation Conference (2012)
117. Porrmann, M., Hagemeyer, J., Pohl, C., Romoth, J., Strugholtz, M.: RAPTOR–A Scal-
able Platform for Rapid Prototyping and FPGA-based Cluster Computing, vol. 19. IOS
Press (2010), doi:10.3233/978-1-60750-530-3-592
118. Pradhan, D.K. (ed.): Fault-tolerant computer system design. Prentice-Hall, Inc., Upper
Saddle River (1996)
119. Priesterjahn, C., Heinzemann, C., Schäfer, W.: From Timed Automata to Timed Failure
Propagation Graphs. In: Proceedings of the Fourth IEEE Workshop on Self-Organizing
Real-time Systems (2013)
120. Priesterjahn, C., Heinzemann, C., Schäfer, W., Tichy, M.: Runtime Safety Analysis for
Safe Reconﬁguration. In: IEEE International Conference on Industrial Informatics Pro-
ceedings of the 3rd Workshop Self-X and Autonomous Control in Engineering Appli-
cations, Beijing, CN, July 25-27 (2012), doi:10.1109/INDIN.2012.6300900
121. Priesterjahn, C., Sondermann-Wölke, C., Tichy, M., Hölscher, C.: Component-based
Hazard Analysis for Mechatronic Systems. In: Object/Component/Service-Oriented
Real-Time Distributed Computing Workshops, IEEE International Symposium on
Object/Component/Service-oriented Real-time Distributed Computing (ISORC), pp.
80–87 (2011), doi:10.1109/ISORCW.2011.19
122. Priesterjahn, C., Steenken, D., Tichy, M.: Component-based timed hazard analy-
sis of self-healing systems. In: Proceedings of the 8th Workshop on Assurances
for Self-Adaptive Systems, ASAS 2011, pp. 34–43. ACM, New York (2011),
doi:10.1145/2024436.2024444
123. Priesterjahn, C., Steenken, D., Tichy, M.: Timed Hazard Analysis of Self-healing Sys-
tems. In: Cámara, J., de Lemos, R., Ghezzi, C., Lopes, A. (eds.) Assurances for Self-
Adaptive Systems. LNCS, vol. 7740, pp. 112–151. Springer, Heidelberg (2013)
124. Priesterjahn, C., Tichy, M.: Modeling Safe Reconﬁguration with the FUJABA Real-
Time Tool Suite. In: Proceedings of the 7th International Fujaba Days (2009)
125. Qanadilo, M., Samara, S., Zhao, Y.: Accelerating Online Model Checking. In: Proceed-
ings of the 6th Latin-American Symposium on Dependable Computing, LADC (2013),
doi:10.1109/LADC.2013.20
126. RailCab – Neue Bahntechnik Paderborn: The Project Web Site,
http://railcab.de (accessed March 5, 2012)
127. Rao, B. (ed.): Handbook of Condition Monitoring. Elsevier (1996)
128. Reinold, P., Nachtigal, V., Trächtler, A.: An Advanced Electric Vehicle for
the Development and Test of New Vehicle-Dynamics Control Strategies (2010),
doi:10.3182/20100712-3-DE-2013.00172
129. Reutenauer, C.: The mathematics of Petri nets. Prentice-Hall, Inc., Upper Saddle River
(1990)
130. Richter, U., Mnif, M., Branke, J., Müller-Schloer, C., Schmeck, H.: Towards a
Generic Observer/Controller Architecture for Organic Computing. In: Hochberger, C.,
Liskowsky, R. (eds.) Tagungsband zur 36. Jahrestagung der Gesellschaft für Infor-
matik – Informatik für Menschen, Dresden, DE. LNI, vol. P-93, pp. 112–119. Bonner
Köllen Verlag (2006)
131. Ringkamp, M., Ober-Blöbaum, S., Dellnitz, M., Schütze, O.: Handling High Dimen-
sional Problems with Multi-Objective Continuation Methods via Successive Approx-
imation of the Tangent Space. Engineering Optimization 44(9), 1117–1146 (2012),
doi:10.1080/0305215X.2011.634407

170
References
132. Röhs, M., Wehrheim, H.: Sichere Konﬁgurationsplanung selbst-adaptierender Systeme
durch Model Checking. In: Gausemeier, J., Rammig, F., Schäfer, W., Trächtler, A. (eds.)
Entwurf Mechatronischer Systeme. HNI-Verlagsschriftenreihe, vol. 272, pp. 253–265.
Heinz Nixdorf Institute, University of Paderborn, Paderborn (2010)
133. Romaus, C., Bocker, J., Witting, K., Seifried, A., Znamenshchykov, O.: Optimal Energy
Management for a Hybrid Energy Storage System Combining Batteries and Double
Layer Capacitors. In: Proceedings of the Energy Conversion Congress and Exposition,
San Jose, CA, US, pp. 1640–1647 (2009), doi:10.1109/ECCE.2009.5316428
134. Russel, S., Norvig, P.: Artiﬁcial Intelligence – A Modern Approach, 2nd edn., pp. 94–
136. Prentice Hall (2003)
135. Schütze, O., Witting, K., Ober-Blöbaum, S., Dellnitz, M.: Set Oriented Methods for the
Numerical Treatment of Multi-Objective Optimization Problems. In: Tantar, E., Tantar,
A.-A., Bouvry, P., Del Moral, P., Legrand, P., Coello Coello, C.A., Schütze, O. (eds.)
EVOLVE- A Bridge between Probability. SCI, vol. 447, pp. 185–218. Springer, Hei-
delberg (2013)
136. Serrestou, Y., Beroulle, V., Robach, C.: Functional Veriﬁcation of RTL De-
signs Driven by Mutation Testing Metrics. In: Proceedings of the 10th Euromi-
cro Conference on Digital System Design, Lebeck, DE, pp. 222–227 (2007),
doi:10.1109/DSD.2007.4341472
137. Simani, S., Fantuzzi, C., Patton, R.J.: Model-based Fault Diagnosis in Dynamic Sys-
tems Using Identiﬁcation Techniques. Springer, Heidelberg (2002)
138. Slayman, C.: JEDEC Standards on Measurement and Reporting of Alpha Particle and
Terrestrial Cosmic Ray Induced Soft Errors. In: Nicolaidis, M. (ed.) Soft Errors in Mod-
ern Electronic Systems. Frontiers in Electronic Testing, vol. 41, pp. 55–76. Springer, US
(2011), doi:10.1007/978-1-4419-6993-4_3
139. Smith, J.E., Nair, R.: The Architecture of Virtual Machines, vol. 38. IEEE Computer
(2005), doi:10.1109/MC.2005.173
140. Sondermann-Wölke, C., Sextro, W.: Integration of Condition Monitoring in Self-
Optimizing Function Modules Applied to the Active Railway Guidance Module. In-
ternational Journal on Advances in Intelligent Systems 3(1&2), 65–74 (2010)
141. Sondermann-Wölke, C., Sextro, W., Reinold, P., Trächtler, A.: Zuverlässigkeitsorien-
tierte Mehrzieloptimierung zur Aktorrekonﬁguration eines X-by-wire-Fahrzeugs. In:
25. Tagung Technische Zuverlässigkeit (TTZ 2011) – Entwicklung und Betrieb zuver-
lässiger Produkte, Leonberg, DE. VDI-Berichte, vol. 2146, pp. 291–302. Düsseldorf
(2011)
142. Sterpone, L., Violante, M.: Analysis of the robustness of the TMR architecture
in SRAM-based FPGAs. IEEE Transactions on Nuclear Science 52(5), 1545–1549
(2005), doi:10.1109/TNS.2005.856543
143. Tasiran, S., Qadeer, S.: Runtime Reﬁnement Checking of Concurrent Data Structures.
In: Proceedings of the 2004 Workshop on Runtime Veriﬁcation (RV 2004), Barcelona,
ES (2004), doi:10.1016/j.entcs.2004.01.028
144. Tichy, M., Klöpper, B.: Planning Self-Adaptation with Graph Transformations. In:
Schürr, A., Varró, D., Varró, G. (eds.) AGTIVE 2011. LNCS, vol. 7233, pp. 137–152.
Springer, Heidelberg (2012)
145. Timmermann, R., Horenkamp, C., Dellnitz, M., Keßler, J.H., Trächtler, A.: Optimale
Umschaltstrategien bei Aktorausfall mit Pfadverfolgungstechniken. In: Gausemeier, J.,
Rammig, F.J., Schäfer, W., Trächtler, A. (eds.) Tagungsband vom 9. Paderborner Work-
shop Entwurf mechatronischer Systeme. HNI-Verlagsschriftenreihe. Heinz Nixdorf In-
stitute, University of Paderborn, Paderborn (2013)

3 Methods of Improving the Dependability of Self-optimizing Systems
171
146. Trächtler, A., Münch, E., Vöcking, H.: Iterative Learning and Self-Optimization
Techniques for the Innovative Railcab-System. In: 32nd Annual Conference of the
IEEE Industrial Electronics Society (IECON), Paris, FR, pp. 4683–4688 (2006),
doi:10.1109/IECON.2006.347957
147. Tumer, I., Stone, R., Bell, D.: Requirements for a Failure Mode Taxonomy for Use
in Conceptual Design. In: Proceedings of the International Conference on Engineering
Design, Stockholm, SE (2003)
148. Verein Deutscher Ingenieure (VDI): VDI 2057:2002. Human exposure to mechanical
vibrations. Technical Guideline (2002)
149. Vesely, W.E., Goldberg, F.F., Roberts, N.H., Haasl, D.F.: Fault tree handbook –
NUREG-0492209. Tech. rep., U.S. Nuclear Regulatory Commission (1981)
150. Wilkinson,
P., Kelly,
T.:
Functional
Hazard
Analysis
for
Highly
Integrated
Aerospace Systems. In: Proceedings of the Ground/Air Systems Seminar (1998),
doi:10.1.1.28.8417
151. Witting, K.: Numerical Algorithms for the Treatment of Parametric Multiobjective Op-
timization Problems and Applications. In: HNI-Verlagsschriftenreihe. Heinz Nixdorf
Institute, University of Paderborn, Paderborn (2011)
152. Witting, K., Ober-Blöbaum, S., Dellnitz, M.: A Variational Approach to Deﬁne Ro-
bustness for Parametric Multiobjective Optimization Problems. Journal of Global Op-
timization (2012), doi:10.1007/s10898-012-9972-6
153. XILINX: MicroBlaze Processor Reference Guide, V9.0 (2008)
154. Zhao, Y., Rammig, F.: Online Model Checking for Dependable Real-Time Systems.
In: 15th IEEE International Symposium on Object/Component/Service-Oriented Real-
Time Distributed Computing (ISORC), pp. 154–161. IEEE Computer Society, Shen-
zhen (2012), doi:10.1109/ISORC.2012.28
155. Zilberstein, S.: Using Anytime Algorithms in Intelligent Systems. AI Magazine 17(3),
73–83 (1996), doi:10.1.1.41.3559

Chapter 4
Case Study
Abstract. The challenge of increasing the dependability of a self-optimizing system
is best addressed by a development process which seamlessly integrates appropriate
dependability-oriented methods. The developer is assisted during this process by a
set of guidelines to help him or her select the most suitable methods for the current
development step.
In this chapter, a development process making use of these guidlines for the ef-
fective development of a self-optimizing system is shown exemplarily and advan-
tages are highlighted that can be obtained by expanding the development process to
include methods of increasing the dependability of the resulting system . Further-
more, the interaction between and sequence of these methods is outlined. As a case
study, the RailCab system is presented and an abstract of its development process is
illustrated.
In general, the development process is structured into the two phases: "Concep-
tual Design" and "Design and Development". During Conceptual Design of the Ac-
tive Guidance Module of the RailCab, methods based on the speciﬁcation of the
Principle Solution are employed to being increasing the dependability as early as
possible. This is followed by the Design and Development phase, during which
methods of analyzing the dependability of the whole RailCab system, as well as of
optimizing the system behavior, are employed.
In Sect. 3.3, a methodology was presented, which supports the improvement of
the dependability of self-optimizing systems. Its constituent elements are a method
database, a guide for planning the use of the selected methods in the development
process, and the appropriate software tool. By using the presented methodology, the
developer can decide easier and faster which of the vast number of available depend-
ability engineering methods (like shown for self-optimizing systems in Chap. 3)
suits the development task best. In the following, the use of this methodology in
an actual development project (the RailCab mentioned in previous chapters) will be
discussed as a concrete application of the strategies presented thus far in the book.
Additionally, the methods, selected by engineering teams to improve the depend-
ability of the RailCab will be discussed in detail.
J. Gausemeier et al. (eds.), Dependability of Self-optimizing Mechatronic Systems,
173
Lecture Notes in Mechanical Engineering,
DOI: 10.1007/978-3-642-53742-4_4, c⃝Springer-Verlag Berlin Heidelberg 2014

174
R. Dorociak et al.
4.1
Selecting Suitable Methods Using the Methodology
Rafal Dorociak, Jürgen Gausemeier, Peter Iwanek, Tobias Meyer, and Walter Sextro
As mentioned above, the development of self-optimizing systems is divided into two
main phases: the (domain-spanning) conceptual design and the (domain-speciﬁc)
design and development. Within the conceptual design phase, the principle solu-
tion is developed by using the speciﬁcation technique CONSENS (Sect. 2.1). After
the speciﬁcation of the domain-spanning models, these models are used as the ﬁrst
inputs to analyze the system’s dependability (Chap. 2.1). There are certain meth-
ods that can be used for this analysis from which the developer may choose (e.g.
the Early Probabilistic Reliability Analysis (cf. Sect. 3.1.1)). In the domain-speciﬁc
design and development phase, more models are created by the experts from the dif-
ferent domains (e.g. models speciﬁed in MECHATRONICUML or MCAD). Based
on these domain-speciﬁc models, further analyses can be performed. In the follow-
ing, we will show the support available to a developer when using the methodol-
ogy to search for and select suitable dependability methods for particular tasks (cf.
Sect. 3.3), using the railway system RailCab as an example.
In our example, we show how an engineer can search for suitable methods of
improving the dependability of a system. Figure 4.1 displays a diagram excerpt of
the development process.
In this ﬁgure, the bubbles show where the methodology is used to choose suitable
dependability engineering methods according to the speciﬁc development task. At
this point, the safety engineer has just started to search explicitly for dependability
methods, so he has selected the following search criteria: "conceptual design" for
the development phase, "rail engineering" for the industry sector and the CENELEC
50128 [4] standard, which is the industrial standard for the rail engineering industry.
Based on the chosen criteria, the irrelevant methods are ﬁltered out and displayed in
the graphical user interface (GUI) of the software tool13 (Fig. 4.2).
Three methods are proposed, all of which conform to the recommendations of
the CENELEC 50128 standard and can be conducted during the conceptual design:
1) early FMEA (Failure Mode and Effects Analysis) based on the principle solution,
2) early FTA (Fault Tree Analysis) based on the principle solution and a combina-
tion of both early integrated FMEA and FTA based on the principle solution. The
engineer can now select the early FMEA based on the principle solution (1) for use,
which is based on the principle solution of the subsystem Active Guidance Module.
With this method the critical weak points of the system can be identiﬁed and respec-
tive counter-measures can be deﬁned; the principle solution will be more reliable.
The safety engineer is provided with additional information regarding the proposed
method in form of a method description, which is shown in the GUI. Figure 4.3
shows a section of the method description for the early FMEA method. The method
description contains relevant information, for example the summary, the required
13 The graphical user interface shown in Fig. 4.2 is a prototypical version of the software
tool. What is important for the usage of the methodology is the core concept behind the
software (e.g. classiﬁcation of dependability engineering methods, etc.).

4 Case Study
175
Mechanical Engineering
    
         Subsystem Integration
Control Engineering
Software Engineering
 
Electrical Engineering
Planning and 
Clarifying the Task
Conceptual Design 
on System Level
Conceptual Design of the Railcab
Active guidance
module 
Intelligent 
drive module
•
•
•
List of Requirements,
Application Scenarios
Principle Solution
on System Level
Principle Solution
on Subsystem Level
Conceptual Design 
on Subsystem Level
Bubble 
1
2
3
4
5
6
7
8
Name
Early Probabilistic Reliability Analysis of an Advanced Mechatronic 
System based on its Principle Solution
Early Design of the Multi-Level Dependability Concept
Verification with Motion Profiles for Interacting Mechatronic Systems
Self-Healing in Operating Systems
Safe Planning
Behavior Planning
Behavioral Adaption of Differing Model Parameters
Virtualization
Section
3.1.1
3.1.2
3.2.10
3.2.12
3.2.9
3.2.5
3.2.7
3.2.15
2
11
Active Guidance 
Module 
  
     
          
       
Mechanical Engineering
    
         Subsystem Integration
Control Engineering
Software Engineering
 
System Integration
Intelligent Drive Module
Production
Documents
Design and Development
Electrical Engineering
7
8
3
4
5
6
Principle
Solution 
Concept 
Integration
Fig. 4.1 Development Process and related methods

176
R. Dorociak et al.
Search Criteria
Proposed Methods
Fig. 4.2 The search function of the method database
input could be the result of the method, as well as some supporting documents.
These documents could be for instance, phases and milestones diagrams, templates
for the usage of the method, and exemple usages of the method (e.g. older projects
where the method has already been used successfully). In addition, the information
concerning phases and milestones is stored in the database as a formal model which
can be used for the generation of a dependability workﬂow, as explained in Sect. 3.3.
After using early FMEA the engineer found that the reliability of the system
could end up too low and thus not fulﬁll the given requirements. The engineer runs
another search using the methodology and decides to use the early design of the
Multi-Level Dependability Concept (2) (Figure 4.1). This method allows an early
implementation of the Multi-Level Dependability Concept, which allows a self-
optimizing system to react to its own deteriorating state by adapting the system
behavior, thus increasing one or several attributes of dependability, i.e. the system’s
reliability. After the phase "Concept Integration", the development process is split

4 Case Study
177
Early FMEA based on the principle solution
Abstract
…
In
Input
Output
method
Out
Mechanics
Software
engineering
Control
engineering
Electrics/
Electronics
Reliability
Safety
Availability
Supporting documents
Summary
…
Associated disciplines
Dependability attributes
Conceptual Design
Operation
Des. and Dvlpment
Development phase
Relevant standards
Literature/Links
Relevant industrial sectors
all 
Related methods
[-] requires
|     specification technique
[-] is the further development of
FMEA
Contact
Rafal Dorociak
Not self-optimization specific
Self-optimization specific
Self-optimization relevance 
Fig. 4.3 The method description for the early FMEA based on the principle solution (excerpt)
up into several parallel development domains (mechanics, electrics/electronics etc.)
and the system integration. In the system integration phase, the safety engineer rec-
ognizes that varying braking capabilities of several RailCabs in a convoy could lead
to severe accidents. Thus, a solution must be found and implemented. To do so, the
safety engineer can use the veriﬁcation with motion proﬁles for interacting mecha-
tronic systems (3), which is excellently suited to this task. This method identiﬁes the
braking capabilities and deﬁnes safety conditions for them, allowing the engineer to
eliminate the possibility of accidents from this error source.
In order to obtain dependable software, a model-based development approach
using MECHATRONICUML was selected, within which the software architecture
and communication behavior of several RailCab vehicles could be modeled. It was
then found that failures in certain components could lead to severe faults, necessi-
tating a resistant system. To design this system, the method Analysis of Self-healing
behavior (4) is selected and used. To allow for online adaptation of the system’s
communication structure, the software architecture of the RailCab system has to
able to be reconﬁgured dynamically. Such reconﬁgurations can be modeled using
the story pattern formalism of MECHATRONICUML. In order to decide when and
how to reconﬁgure the architecture of the system at runtime, an integrated planning
system is used, which selects appropriate reconﬁgurations and decides upon their
ordering. The resulting sequence of reconﬁgurations is not permitted to produce un-
safe conﬁgurations, which is why the method Safe Planning (5) must be employed.
This method takes safety requirements under consideration while searching for a
given target conﬁguration.
At the same time, other engineering groups which are evaluating the dynamic be-
havior of the vehicle system can employ the method Behavior Planning (6). During

178
R. Dorociak et al.
operation, this method proactively generates plans for selecting the overall sequence
of optimal solutions from the Pareto sets of multiobjective optimization. In addi-
tion, a probabilistic model is used to determine deviations from the deterministic
plan. These, deviations between the actual and the planned system behavior, unfor-
tunately, cannot always be avoided and may have a multitude of causes. Deviations
may be caused by unquantiﬁable environmental inﬂuences; however, they may also
be caused by deviations between the model parameters used for the multiobjective
optimization and those measured during system operation. These deviations have
to be detecteted and corrected during system operation in order to achieve system
dependability. For this purpose, the safety engineer, control engineers and mathe-
maticians in the team can employ the method Behavior-Based Adaption of Differing
Model Parameters (7).
The last method, which the safety engineer will use together with experts in soft-
ware engineering during the development phase, is Virtualization (8). The dynamic
mapping of virtual machines onto physical platforms increases the runtime ﬂex-
ibility of the system software architecture, which can be exploited to improve the
reliability and availability of software components. By applying virtual machine mi-
gration, a software component can potentially be kept functional despite a possible
hardware failure. In case of a partial memory failure or the breakdown of a copro-
cessor, the input/output relationship with the component can be shifted to another
unit. The execution of the VM (virtual machines) is suspended and the executable
code, memory content, and processor state are communicated to the target processor,
where the execution is resumed. Virtual machine migration is therefore a technique
for controlling hazards. In the next section, the usage of the methods mentioned here
will be described in more detail.
4.2
Development of the Active Guidance Module
Rafal Dorociak, Jürgen Gausemeier, Peter Iwanek, Tobias Meyer, Walter Sextro,
and Christoph Sondermann-Woelke
The development process, see also Fig. 4.1, is subdivided into two major phases.
During the ﬁrst phase, the whole system is modularized and then a conceptual de-
sign for the individual modules is developed. The RailCab has been subdivided into
several modules all of which serve separate primary functions. Among these is the
Active Guidance Module, which has already been introduced in Sect. 1.3.1.2. The
use of methods chosen using the guidelines as shown in Sect. 4.1 will be examined
here in detail.
4.2.1
Early Probabilistic Reliability Analysis of an Advanced
Mechatronic Systems Based on Its Principle Solution
First, the early FMEA is performed based on the speciﬁcation of the Principle So-
lution. In order to do so, the entire RailCab system has to be speciﬁed, using the

4 Case Study
179
sensor has been wired in 
a wrong way
sensor is damaged
wrong calibration
Failure Mode and Effects Analysis (FMEA)
module: servo-cylinder
system
element
failure 
mode
failure effect
s
failure cause
...
hydraulic 
valve 
regulation
hydraulic 
valve 
regulation 
provides no 
switch 
position for 
the 4/4-way 
valve
valve does not 
change the 
pressure on 
the output 
anymore
6
servo cylinder regulation 
does not provide to-be 
valve slider position
hydraulic valve regulation 
is broken
energy supply of the 
hydraulic valve regulation 
is interrupted
4/4-way 
valve
valve closes 
in an 
unwanted 
manner
hydraulic valve 
stays in the 
current position 
energy supply is 
interrupted
magnetic coil is damaged
function
regulate 
position of 
the valve
close the 
valve
servo-
cylinder 
regulation
a wrong as-
is value  for 
the cylinder 
lifting way 
has been 
determined
control 
deviation e = 
X*cylinder –
Xcylinder has a 
wrong value; 
the desired 
lifting way will 
not be 
accomplished
9
cable break
determine 
the as-is 
value for the 
cylinder 
lifting way 
8
d
2
9
7
7
8
3
8
2
9
o
7
3
6
4
3
2
3
5
2
rpn
84
162
252
224
192
54
216
90
162
counter or detection
measure
monitor the outgoing 
communication towards 
the 4/4-way valve
generate a warning 
message, if needed
monitor energy supply
monitor energy supply
generate a warning 
message, if needed
monitor as-is value of the 
cylinder lifting way 
Xcylinder
redundant design of the 
measuring system 
...
...
...
...
...
...
...
...
...
...
...
...
...
...
s:
severity of the failure effect
d:
detection probability of the failure cause
o:
occurence probability of the failure cause
rpn:
risk priority number (rpn = s*d*o)
Fig. 4.4 FMEA of the Active Guidance Module (excerpt)

180
R. Dorociak et al.
speciﬁcation technique CONSENS (cf. Sect. 2.1). For each system element, all pos-
sible failures, their possible causes and the consequences are described in tabular
form. For the identiﬁed causes and consequences, the corresponding detection and
counter-measures are determined and also recorded in the FMEA table. The FMEA
table has to be ﬁlled out manually, which usually happens in moderated workshops
with a safety engineer and experts from the involved domains. The counter-measures
are usually proposed and developed by the respective developers. A subtask of
FMEA is risk prioritization by assigning a the risk priority number (RPN, cf. [1,8]).
By using the RPN, dependability-critical system elements can be determined. Fig-
ure 4.4 shows a section of the FMEA table of the Active Guidance Module. For
example, we see that the actuator can be damaged, the ﬂange could break or the
RailCab could derail.
According to the workﬂow generated by the software tool (cf. Sect. 4.1), the
phases of the early FTA based on the Principle Solution are executed next [2]. The
speciﬁcation of the Principle Solution (mainly the partial model Active Structure) is
expanded to include the description of the failure propagation; the underlying proce-
dure is based on the FTA method. Figure 4.5 shows a section of the speciﬁcation of
the failure propagation within the Active Guidance Module. It shows, in particular,
that the failure of the eddy-current sensor causes a failure of the actuator, because
the actuator cannot receive any control values; the consequence is a complete failure
F1:     Eddy-current densor defect
F2:     Hydraulic actuator defect
Active guidance module
Axle module
hy
Hydraulic 
actuator
Information flow
System element
Energy flow
Material flow
Measurement 
information flow
Sensor data
Eddy-current
sensor
Rail
Distance 
flange – rail
Displacement 
force
Wheel
Axle
Mechanical 
force
Mechanical force
System element of 
the environment
F2
OR
not(ok)
not(ok)
F1
not(ok)
not(ok)
OR
not(ok)
CanImply 
relationship
Boolean operator
Failure
Port state
Fig. 4.5 FTA of the Active Guidance Module (excerpt)

4 Case Study
181
of the track guidance module. A complete failure of the track guidance is critical for
the dependability, particularly when driving onto a passive switch. In this case, the
risk of derailing is very high. To prevent this scenario, mechanical track guidance
can be installed and a railway extension is attached next to the passive switches.
The mechanical track guidance switches to the desired side before passing a pas-
sive switch. If the active steering breaks down, the RailCab is led by an interlocked
connection in the given direction [3,5].
Using the early integrated FMEA and FTA, weak points in the system with regard
to dependability can be found and respective counter-measures can be implemented
before critical failure states are reached. Both methods are carried out based on the
domain-spanning description of the Principle Solution. Thus, especially fault prop-
agation paths which cross domain boundaries can be analyzed. Further information
about the usage of the early FMEA and the FTA based on the Principle Solution in
combination with the methodology described here (c.f. Sect. 3.3) can be read in [3].
4.2.2
Early Design of the Multi-Level Dependability Concept
To increase the dependability of the Active Guidance Module during runtime, the
Multi-Level Dependability Concept, see Sect. 3.2.1, has been chosen. This method
has been developed to enable a self-optimizing system to actively adapt its behav-
ior according to the current system deterioration. To do so, pre-calculated optimal
workings points that offer better dependability than those in use are selected during
runtime. This method is used to include the Multi-Level Dependability Concept at
an early design phase.
To utilize the method Early Design of the Multi-Level Dependability Concept,
input from several sources is required. As has been explained in Sect. 3.1.2, the
main source of information is the Principle Solution. The Principle Solution is com-
prised of several partial models that each contain information about one area of
interest. Using the development process outlined in Sect. 1.2.3, it is the main result
of the Conceptual Design Phase. Additionally, information obtained by completing
an FMEA is required. It is therefore only natural at this point to employ the method
Early Probabilistic Analysis of an Advanced Mechatronic System based on its Prin-
ciple Solution (see Sect. 3.1.1). This method itself is based on information included
in the Principle Solution as well and thus requires no further sources of information.
For the calulation of the required optimal working-points, multiobjective opti-
mization is used. Thus, this method heavily relies on the availability of multiobjec-
tive optimization and its required foundations. It is also necessary to ensure that ad-
ditional dependability-related objectives can be included in the optimization model.
The method Reliability-Oriented Multiobjective Optimization, see Sect. 3.2.11, as-
sists the developer by analyzing the effects of objectives intended to increase the
dependability.
All of the results from this method are embedded into the Principle Solution,
which serves as input for the phase "Design and Development". By carrying this
part of development out in the "traditional" way, i.e. separated into domains, all

182
K. Flaßkamp et al.
components of the Multi-Level Dependability Concept are implemented just like
other system components. These in turn require other methods to ensure dependable
system behavior, which are not speciﬁc to the implementation of the Multi-Level
Dependability Concept.
4.3
Development of the RailCab Vehicle
Kathrin Flaßkamp, Stefan Groesbrink, Philip Hartmann, Christian Heinzemann,
Bernd Kleinjohann, Lisa Kleinjohann, Martin Krüger, Sina Ober-Blöbaum, Clau-
dia Priesterjahn, Christoph Rasche, Wilhelm Schäfer, Dominik Steenken, Ansgar
Trächtler, Heike Wehrheim, and Steffen Ziegert
Following the conceptual design of the individual modules, the resulting concepts
must be integrated and the second phase of the development process, the Design and
Development, is begun. This phase consists of individual design and development
processes for each module. They are conducted individually in each domain using
the results from the Conceptual Design Phase, the Principle Solution, as speciﬁca-
tions. If domain-spanning partial models have been engineered, the results must be
synchronized.
Parallel to the development of the individual modules the results of the domains
are integrated into the overall system model in the system integration. These span
all of the modules and take the full system into account. During this phase and in
these processes, methods are one more chosen using the guidelines as described in
Sect. 4.1.
4.3.1
Veriﬁcation with Motion Proﬁles for Interacting
Mechatronic Systems
In Sect. 3.2.10, we gave an overview of a method combining several tools, processes
and methods to create a set of software solutions that would bridge the gap between
continuous and discrete behavior. As an example, we used the proposed RailCab
system. In this section, we will examine how that method works in the broader
context of the design process of the RailCab system and how it interacts with other
design and dependability methods.
Prior to employing this method, the required inputs ﬁrst need to be generated.
For the RailCab system, this means the physical parameters of the RailCab need to
be determined ﬁrst. This applies to the outer shape of the RailCab (or at least an
abstracted box to represent the boundaries) and any physical parameters that have
an inﬂuence on the performance of actuators, such as vehicle mass.
Furthermore we need a clear idea of the behavior the RailCab will exhibit in the
ﬁnished system. That means we need to know all the different situations a RailCab
may encounter, e.g. single drive, convoy drive, track switching, entering and exiting
stations and so on. Each of these situations will need a motion proﬁle, as will any
transition between them.

4 Case Study
183
The ﬁnal piece of information for the continuous part of the method are the goal
functions, with regard to which the motion proﬁles must be optimized. These are
part of the overall optimization concept and should have been ﬁxed earlier in the
development process D.M.f.I.T.S, [6], Sect. 3.6. Based on these pieces of informa-
tion, motion proﬁles will be generated for the RailCabs, relying on the techniques
of optimal control, D.M.f.I.T.S, [6], Sect. 5.3.6.
In constructing the communication protocol that will assign these motion pro-
ﬁles at runtime, we must rely on a pre-existing communication topology. This is
provided by the modeling of the system in MECHATRONICUML D.M.f.I.T.S, [6],
Sect. 5.2. Here we ﬁnd communication topologies for all the different situations
speciﬁed above, as well as basic protocol implementations that do not yet take the
motion proﬁles into account.
Based on the existing communication topology, we expand the existing commu-
nication protocols by adding proﬁle distribution protocols and compatibility checks
as described in Sect. 3.2.10. These protocols are then veriﬁed using design-time
veriﬁcation D.M.f.I.T.S, [6], Sect. 5.2.3.
As a result, we get MECHATRONICUML models of the commmunication pro-
tocols guiding the RailCab that have been made aware of the physical dimensions
and characteristics of the vehicles and the resulting safety restrictions. These proto-
cols can then be used in the remaining process just as the previous MECHATRON-
ICUML models would have been, including their eventual implementation in actual
code. Once in place, the modiﬁcations of the communication protocols produced
using this method interlock with the artefacts created by several other methods.
For safe planning (see Sect. 4.3.3), the new protocols introduce an added layer of
complexity, since actions that are planned to take place in the future may be rejected
by the inherent safety check now implemented in the communication protocols. For
example, a convoy merge that was planned may be rejected by the target convoy
because there is no combination of motion proﬁle choices that satisﬁes the safety
requirements.
The control engineers creating the actuator controllers that will actually drive the
RailCab must be made aware of the motion proﬁles that have been constructed, as
they will need to support these motion proﬁles in the Controller.
4.3.2
Analysis of Self-healing Operations
Veriﬁcation identiﬁes systematic faults, i.e., faults in the system design. It does not
consider random faults that occur, e.g. due to the wear of hardware parts. Random
faults may lead to hazards, which in turn may lead to accidents, such as the collision
of two RailCabs in a convoy. These faults cannot be eliminated completely. How-
ever for a dependable system like the RailCab, the developer has to guarantee that
hazards can only occur within an acceptable probability.
Should a hazard occurrence probability be too high, the system design must be
changed in order to reduce this probability. One means for the reduction of hazard
occurrence probabilities is self-healing. The self-healing system detects an error at

184
K. Flaßkamp et al.
runtime and reacts by initiating a self-healing operation that removes the error from
the system or stops it from propagating to a critical point in the system. However,
the hazard occurrence probability is only reduced if the self-healing operation is
executed quickly enough. To guarantee this, the analysis of self-healing operations
is employed as presented in Sect. 3.2.8.
The analysis of the self-healing operations requires information from earlier de-
sign phases as input: the thresholds for hazard occurrence probabilities of the system
are provided by the Requirements, which result from the Domain-spanning Con-
ceptual design (cf. Sect. 2.1). MECHATRONICUML as described in D.M.f.I.T.S, [6],
Chap. 5, provides models which specify the system architecture, as well as the state-
based and reconﬁguration behavior.
The analysis of self-healing operations uses the behavior models to generate fail-
ure propagation models with timing information which are needed to analyze the
propagation times of failures. The system architecture and the reconﬁguration rules
which specify self-healing operations are needed to analyze how the self-healing
operation affects the propagation of failures in the system architecture.
Before the self-healing operations are analyzed, the system models need, of
course, to be veriﬁed. We apply the veriﬁcation approach which is explained in
D.M.f.I.T.S, [6], Chap. 5.
The hazard analysis according to Giese et al. [7] is a prerequisite and part of our
analysis of self-healing operations. During the analysis of self-healing operations, it
is used to compute hazard occurrence probabilities before and after the self-healing;
thus, the developer can assess whether the self-healing operation has reduced the
hazard occurrence probability according to the safety requirements.
During safe planning, the results of the online hazard analysis must be taken into
account. If a transition is locked that was part of a safe plan, the safe plan needs to
be adapted accordingly.
4.3.3
Safe Planning
To reconﬁgure the communication structure of the RailCab system, the method Safe
Planning is used, cf. Sect. 3.2.9. This method allows runtime reconﬁgurations to be
planned by an integrated software system. It also obeys safety requirements, i.e. it
prevents the system from reconﬁguring into dangerous conﬁgurations.
MECHATRONICUML introduces real-time coordination patterns that represent
communication protocols between subsystems, cf. D.M.f.I.T.S, [6], Sect. 5.2.1. A
real-time coordination pattern speciﬁes the behavior of subsystems as real-time stat-
echarts and determines their communication link. These real-time coordination pat-
terns can be activated and deactivated dynamically by runtime reconﬁgurations.
The application scenario in Sect. 3.2.9.4 uses the activation and deactivation of
speciﬁc real-time coordination patterns during a RailCab’s movement as an exam-
ple, e.g. the story pattern cConvoy to operate in convoy mode or cPublication to reg-
ister at a base station. A runtime reconﬁguration specifying the creation of a Convoy
real-time coordination pattern affects not only the system’s software; to operate in

4 Case Study
185
convoy mode, a RailCab changes its subcomponents’ conﬁgurations and thus gives
a different subcomponent control over the velocity of the RailCab. While planning
these runtime reconﬁgurations can be done on a discrete level, abstracting aspects
of the subcomponents away, the actual execution of these runtime reconﬁgurations
necessarily involves these subcomponents. One of these subcomponents is the Rail-
Cab’s hybrid energy storage system, cf. D.M.f.I.T.S, [6], Sect. 2.1.5. This system also
applies a planning technique for its internal behavior and an online adaptation of this
behavior, e.g. to decide how much energy to invest in the passengers’ comfort, cf.
the methods Behavior Planning and Behavior-Based Adaptation of Differing Model
Parameters in Sect. 3.2.5 and 3.2.7. Its output constitutes a single Pareto point for
each track segment. The system continuously measures sensor data and ensures that
its intended operation mode will always be met by recalculating the Pareto point
during operation if necessary.
Another subcomponent integrates the hazard analysis of self-healing behavior
presented in Sect. 3.2.8. It speciﬁes runtime reconﬁgurations to be executed when
a speciﬁc error is detected. In principle, it is possible to associate a target conﬁg-
uration instead of a runtime reconﬁguration with an error or failure, and plan a
sequence of runtime reconﬁgurations that reduces the hazard probability with the
method Safe Planning. A similar approach is used in [11]. Applied to the RailCab
system, this means that the method Safe Planning can be used at two different levels
of abstraction: to plan the de-/instantiation of real-time coordination patterns during
a RailCab’s movement in the Cognitive Operator of the OCM and to compute self-
healing plans in the Reﬂective Operator of the OCM, cf. Sect. 1.1.1. The latter was
not done for the RailCab system because the employed planning system would have
had to provide runtime guarantees in order not to invalidate the timing predictions
made by the hazard analysis.
4.3.4
Behavior Planning
By using the Method Behavior Planning (cf. Sect. 3.2.5), the RailCab has to choose
from different behaviors (operation modes) on each section of track. This choice
represents a trade-off between several objective functions (e.g. minimization of the
body movement or energy losses). Because of the complexity of solving multiob-
jective optimization problems, this process is done during the design phase of the
RailCab system for each track section. During operation, the RailCab chooses solu-
tions from the Pareto sets.
In the case of the RailCab, the state space is a combination of the operation modes
and the state of charge (SOC) of the on-board energy storage. Planning procedures
such as state space search algorithms explore this state space in order to deﬁne the
operation mode to be executed for each track section. Of course, the availability of
the operation modes depends on the current state of charge, and thus the planning
procedure should choose them in such a way that a given objective function (e.g.
minimizing the total energy consumption) is optimized across all track sections [9].

186
K. Flaßkamp et al.
During operation, deviations from the deterministic plan are caused by unquan-
tiﬁable not-exactly-quanitiﬁable (sounds odd, though) inﬂuences (e.g. wind speed
or rain fall). To build up a probabilistic model of environmental inﬂuences and
the energy transfer resulting from the operation modes, Bayesian networks have
to be deﬁned for the RailCab-domain at design time. For each operation mode, a
corresponding Bayesian networks describes the conditional probability distribution
P(Δi
SOC|εi) with Δi
SOC denoting the change in the state of charge and εi the relevant
environmental inﬂuences. An inference made through the Bayes Networks can then
determine the probability distribution in the change of state of charge Δi
SOC from the
probability distribution of the environmental inﬂuences (cf. [10]).
4.3.5
Behavior-Based Adaptation of Differing Model Parameters
The method Behavior-Based Adaptation of Differing Model Parameters as intro-
duced in Sect. 3.2.7 is used to increase the dependability of self-optimizing systems
during movement. The method has been developed to enable systems which create
plans based on Pareto points to adapt themselves to environmental changes.
The method should be utilized if several unexpected conditions can occur dur-
ing operation to which the system has to react. The system under consideration has
a restricted energy supply and has to travel with the available energy to its arrival
station. During travel, the passengers expect a certain degree of comfort, which
has a direct inﬂuence on the expected energy consumption, resulting in conﬂicting
requirements. As these two requirements are only a part of all requirements, a mul-
tiobjective optimization process, as presented in Sect. 3.2.6, has to be performed.
Based on the resulting Pareto points, computed by the method Computation of
Robust Pareto Points as described in Sect. 3.2.6, it is possible to create a plan (cf. D.
M.f.I.T.S, [6], Sect. 5.3.8), consisting of several Pareto points, which leads the Rail-
Cab from its initial position to its destination. This plan has to provide a sequence
of safe conﬁgurations, as described in Sect. 3.2.9.
Nevertheless, a plan computed ofﬂine does not take into account the actual op-
erating conditions of the RailCab. One example might be strong headwind, leading
to an increase in power consumption. Such an event can make it impossible for the
RailCab to reach its arrival station before it runs out of energy.
Another use case for which this method should be selected is if convoy travel is
possible but has not been considered by the planner during ofﬂine planning. In this
case, the energy consumption decreases for all RailCabs except the ﬁrst one. This
makes it possible to expend more energy on, for example, passenger comfort. In
both cases, the model Pareto fronts might not take the current situation into account.
It is then necessary to compute new points in order to ﬁnd a feasible plan.
A method such as the Behavior-Based Adaptation of Differing Model Parame-
ters can overcome the described problem. It takes the initially computed plan and
compares the computed Pareto point currently being used to determine the RailCab
properties with a Pareto point computed from currently measured data. To take mea-
suring errors into account, a threshold is implemented. If the difference between the

4 Case Study
187
Pareto point selected using the initial plan and the Pareto point computed using the
measured data is above this threshold, an adaptation of the Pareto front used for the
initial plan is conducted.
The measured points must not necessarily be Pareto points; hence, it might not be
possible to compute a new Pareto front which includes the measured point. If that is
the case, the Pareto front given by the model parameters will be approximated such
that it approaches the measured point.
The resulting Pareto points are delivered to the planner, which takes them into
account for replanning.This leads directly to a self-optimizing behavior based on the
current system state. The method reacts quickly to changing inﬂuences and allows
the behavior-based adaptation of the system before it is too late to react, such as
reacting to an unexpected energy demand before it becomes impossible to reach the
arrival station.
4.3.6
Virtualization
Virtualization as introduced in Sect. 3.2.15 is utilized in order to increase both run-
time ﬂexibility and dependability of the system software architecture. Virtual ma-
chine migration improves two major attributes of dependability, namely reliability
and availability. It enables a coarse-grained dynamic load balancing and can increase
the robustness by fostering fault resilience in case of hardware failures, such as par-
tial memory failures, a breakdown of I/O if there is an I/O connection to other pro-
cessing elements remaining, or the failures of a coprocessor. If the hardware failure
does not preclude the saving and transfer of the virtual machine state, the operation
of the subsystems on the affected electronic control unit can be continued on another
unit. Virtual machine migration is an additional technique for controlling hazards,
and consequently reduce the likelihood that the hazards pose a threat to life, health,
property or environment. Failures such as the breakdown of the power supply or the
central processing unit usually prevent a transfer of code and data to another proces-
sing element. In some cases, the system can beneﬁt from self-diagnosing hardware
that signals upcoming hardware failures on the basis of built-in self-tests, and can
then use this information to perform the migration before it becomes impossible.
In the Operator Controller Module architecture for self-optimizing systems (see
Sect. 1.1.1), virtualization can be applied to the components of the Cognitive Op-
erator and the components of the Reﬂective Operator. The OCM includes timing
requirements for the applications on all of its three levels. The actuator-controlling
software on the lowest level and the supervising Reﬂective Operator on the level
above have to meet hard real-time requirements. Virtualization is an integration ap-
proach of coarse granularity and introduces both an execution time and a memory
overhead, which is inappropriately high for low-level controllers with signiﬁcantly
higher real-time requirements. This holds true especially for migration and the in-
volved downtime of the migrated component. It is feasible for components on the
higher levels, but much less suited for actuator-controlling low-level software with
its high execution frequencies.

188
References
The self-optimization procedures of the Cognitive Operator have to fulﬁll soft
real-time requirements and a violation of the timing requirements does not result
in a safety-critical malfunctioning of the mechatronic system. The self-optimization
applications of the Cognitive Operator execute the most computationally intensive
algorithms. There are often execution mode alternatives with differing resource de-
mands, associated with different optimization levels. Switching between them at
runtime leads to varying resource consumption, which the ﬂexible resource assign-
ment of virtualization and migration can be applied to adapt. A migration manager
has to decide which virtual machine should be migrated where and when. Advanced
planning approaches should be applied in order to take into account smart migration
decisions based on the current resource utilization and the timing constraints of the
virtual machines, such as the Safe Planning introduced in Sect. 3.2.9.
References
1. Birolini, A.: Reliability Engineering – Theory and Practice, 5th edn. Springer, Heidelberg
(2007), doi:10.1007/978-3-662-03792-8
2. Dorociak,
R.:
Early
Probabilistic
Reliability
Analysis
of
Mechatronic
Sys-
tems. In: Proceedings of the Reliability and Maintainability Symposium (2012),
doi:10.1109/RAMS.2012.6175464
3. Dorociak, R., Gaukstern, T., Gausemeier, J., Iwanek, P., Vaßholz, M.: A Methodology for
the Improvement of Dependability of Self-Optimizing Systems. Production Engineering
– Research and Development 7(1), 53–67 (2013), doi:10.1007/s11740-012-0425-3
4. European Committee for Electrotechnical Standardization (CENELEC): Railway appli-
cations Communication, signalling and processing systems Software for railway control
and protection systems, CENELEC EN 50128. European Standard (2011)
5. Gausemeier, J., Rammig, F.J., Schäfer, W. (eds.): Selbstoptimierende Systeme des
Maschinenbaus. HNI-Verlagsschriftenreihe, vol. 234. Heinz Nixdorf Institute, Univer-
sity of Paderborn, Paderborn, DE (2009)
6. Gausemeier, J., Rammig, F.J., Schäfer, W. (eds.): Design Methodology for Intelligent
Technical Systems. Lecture Notes in Mechanical Engineering. Springer, Heidelberg
(2014), doi:10.1007/978-3-642-45435-6_2
7. Giese, H., Tichy, M.: Component-Based Hazard Analysis: Optimal Designs, Prod-
uct Lines, and Online-Reconﬁguration. In: Górski, J. (ed.) SAFECOMP 2006. LNCS,
vol. 4166, pp. 156–169. Springer, Heidelberg (2006)
8. International Electrotechnical Commission (IEC): IEC 61025: Fault Tree Analysis
(FTA). International Standard (2006)
9. Klöpper, B., Aufenanger, M., Adelt, P.: Planning for Mechatronics Systems – Architech-
ture, Methods and Case Study. Engineering Applications of Artiﬁcial Intelligence 25(1),
174–188 (2012), doi:10.1016/j.engappai.2011.08.004
10. Klöpper, B., Sondermann-Wölke, C., Romaus, C.: Probabilistic Planning for Predictive
Condition Monitoring and Adaptation within the Self-Optimizing Energy Management
of an Autonomous Railway Vehicle. Journal for Robotics and Mechatronics 24(1), 5–15
(2012)
11. Tichy, M., Klöpper, B.: Planning Self-Adaptation with Graph Transformations. In:
Schürr, A., Varró, D., Varró, G. (eds.) AGTIVE 2011. LNCS, vol. 7233, pp. 137–152.
Springer, Heidelberg (2012)

Chapter 5
Conclusion and Outlook
Tobias Meyer, Claudia Priesterjahn, and Walter Sextro
Self-optimizing mechatronic systems offer capabilities well beyond those of tra-
ditional technical systems. They are able to react autonomously to changing sys-
tem objectives based on an evaluation of their current situation. Their development
requires the joint effort of several domains: mechanical engineering, electrical
engineering, control engineering, software engineering and mathematics, and their
advanced functionality makes self-optimizing mechatronic systems complex a chal-
lenge to develop. This challenge is taken up by a custom-tailored development
process which is introduced in the accompanying book "Design Methodology for
Intelligent Technical Systems" [1].
However, self-optimizing mechatronic systems require high dependability, as
they are often used in safety-critical environments or are subject to high demands
on availability. In this book, the development process of [1] has been expanded to
include methods that enable the developer to guarantee or increase the dependability
of a self-optimizing mechatronic system. Guidelines for the selection of these meth-
ods is proposed and all necessary selection criteria are given; this should enable
the developer to quickly select a suitable method for his or her current engineering
problem.
In Chap. 1, self-optimizing mechatronic systems were introduced to the reader.
Self-optimization not only offers expanded capabilities, but also poses challenges
in particular the challenge of how to ensure the dependability of such systems.
Here, we have presented our deﬁnition of dependability and its application to self-
optimizing systems. A brief introduction to our proposed development process,
which is the subject of the accompanying book “Design Methodology for Intelli-
gent Technical Systems” [1], is given. One main challenge arises due to the multi-
disciplinary approach that is required to develop a self-optimizing system, for which
we have also suggested certain coordination strategies to overcome the difﬁculties
inherent here. Throughout this book, several demonstrators were used to exemplify
different aspects of self-optimizing systems introduced in the chapters. Among these
is the RailCab, a system of innovative rail vehicles that offer individual transport for
freight or passengers.
J. Gausemeier et al. (eds.), Dependability of Self-optimizing Mechatronic Systems,
189
Lecture Notes in Mechanical Engineering,
DOI: 10.1007/978-3-642-53742-4_5, c⃝Springer-Verlag Berlin Heidelberg 2014

190
Reference
In Chap. 2, we presented the parts of the development process which focus on
dependability. Based on the development process, we have presented a methodol-
ogy which helps the developer of a self-optimizing system ensure its dependability.
The information in this chapter should help in deciding whether the system’s de-
pendability needs to be increased further and offers methods of doing so.
Chapter 3 presents methods which focus on guaranteeing and improving the de-
pendability of self-optimizing mechatronic systems. These methods cover multiple
domains which are involved in the development of these systems. All of the method
descriptions follow the same structure in order to facilitate their application. Their
goal, the prerequisites, a detailed description of their application and the results are
given sequentially for each section. Additionally, the methods contain real-world
examples using the demonstrators which were introduced in Chap. 1. Each method
also contains the necessary criteria.
In Chap. 4, we apply the methodology and the methods presented in Chaps. 2
and 3 to the RailCab. We have improved parts of the RailCab that did not fulﬁll
dependability requirements using the methods described within this book. The Rail-
Cab is now a dependable self-optimizing mechatronic system.
The methods which have been presented in this book were developed in the
course of the Collaborative Research Center 614. Methods that do not focus on
self-optimizing systems, such as standard methods, are thus outside the scope of
this book. They have to be incorporated into the development process presented
here while it is being used in the development of new products.
The RailCab system and all other demonstrators used in this book are academic
research projects. To fully evaluate the suitability of these methods and the accom-
panying guidelines, an evaluation based on industrial development processes and
the problems arising in that environment might prove worthwhile.
Reference
1. Gausemeier, J., Rammig, F.J., Schäfer, W. (eds.): Design Methodology for Intelligent
Technical Systems. Lecture Notes in Mechanical Engineering. Springer, Heidelberg
(2014), doi:10.1007/978-3-642-45435-6_2

Index
Active Guidance Module
18, 178
Active Structure
28, 34, 42, 129
Active Suspension Module
19, 42, 57, 93
Advanced mathematics
26
Air gap
16
Application Scenarios
27, 129
Architecture
6
Artiﬁcial Immune System
138
Artiﬁcial intelligence
26
Availability
13
Bayesian network
46, 62
BeBot
20
Behavior
4, 10, 28
adaptation
14
planning
84, 185
Chameleon, see X-by-wire vehicle
Clustering
hierarchical
64
with Gaussian mixture distributions
64
Cognitive Operator
6, 51, 55, 117, 185
Component model
114
Conceptual design
26, 29, 38
concept integration
29, 30
on the subsystem level
29, 30
on the system level
29
planning and clarifying the task
29
Conﬁdentiality
13
Conﬁguration Control
48, 54, 55
Continuation method
78
Control architecture
6
Control engineering
25, 33
Controller
6, 33, 34, 52, 57
linear-quadratic (LQ)
66
Convoy, see RailCab
Coordination pattern
34
Cross-domain relationship
26
Danger Theory
138
Decision making
9
Dendritic Cells
138
Dependability
12
attributes
12, 13
deﬁnition
13
means
13
methodology for the selection of
dependability methods
159, 160
method classiﬁcation
159
method database
159
software tool
160
taxonomy
13
threats
13
Design and Development
26
Design methodology
15, 25
tools
25
Deterioration level
55
Development process
2, 12, 15, 26
guidelines
160
Dictionary of translation rules
46
Disturbance
identiﬁcation of
64
model
67
observer
66
stochastic disturbance proﬁle
62
variable
4
Domain
2, 25
Domain-spanning
30

192
Index
Efﬁciency
16
Electrical engineering
25, 34
Emulation
157
Environment
1, 4, 27, 129
Error
13
Euler-Lagrange equations
91
Failure
cause
40
effect
40
mode
40
propagation
40
service failure
13
taxonomy
38, 42
Failure Mode and Effects Analysis (FMEA)
38, 48, 50
Fault
13
forecasting
13
prevention
13
removal
13
tolerance
13
Fault Tree Analysis (FTA)
38
Forbidden pattern
113
Functional Hazard Analysis (FHA)
38
Functions
28
Fussell-Vesely importance measure
46
Graph transformation system
114
negative application condition
115
rule
114
Hazard analysis
14
at runtime
112
of self-healing behavior
185
Heuristic search
116
regression function
116
Hierarchical scheduling
155
Hybrid planning architecture
85
Hybrid system
veriﬁcation of
119
Hypervisor
154
Integrity
13
Intelligent Drive Module
16
Kuhn-Tucker equations
90
Learning
11
iterative
62
machine
11
reinforcement
12
supervised
11
unsupervised
11
Linear motor
16
Linear state-space system
66
Maintainability
13
Mechanical engineering
25, 33
Mechatronic Modeller
50
Mechatronic System
1
MechatronicUML
34
component instance conﬁguration
114
Method
12, 15
Method database
15
Modal Sequence Diagrams
34
Model
14
parameter
95
software
14
Model checking
34, 116
Multi-agent system
20
Multi-Level Dependability Concept
47
development of
47
Multiobjective optimal control
with uncertainty
79
Multiobjective optimal control problem
76
Multiobjective optimization
8, 52, 55, 89,
90, 95, 123, 128
problem
76
Objective
3, 8, 10, 49, 58, 98
external
4
inherent
4
internal
4
Objective function, see Objective
OCM, see Operator Controller Module
Online Model Checking
147
Operating system
133
architecture
134
reconﬁguration
135
Operator Controller Module
6, 48, 55, 117
Optimal control
76, 123
Discrete Mechanics and Optimal Control
82
problem
76
Parameter ﬁtting
97
Paravirtualization
154
Pareto
front
8
optimal
8, 90

Index
193
point
8, 89, 95
robust
89
set
8, 89
Partial function
10
Partial models, see Principle Solution
Passive switch
18
Path-following
91
Performance measure
76
Planning
10, 85
behavior-based adaptation
95, 185
Planning Domain Deﬁnition Language
115
Posterior probability
46
Principle Solution
26, 41, 48
on the subsystem level
30
on the system level
29
speciﬁcation
38
speciﬁcation technique CONSENS
27
Probabilistic reliability analysis
38
Probability density function
77
Quarter vehicle
65
RailCab
2, 16, 42
actuators
183
base station
117
behavior
182
communication protocol
120, 183
communication topology
183
convoy
2, 16, 120
goal functions
183
motion proﬁles
183
optimization
183
physical parameters
182
Real-time coordination pattern
117, 184
Reconﬁguration
20, 55
control -
57, 61
Redundancy
41
Reference point
method
78
optimization
78
Reference process
15, 25–27
Reﬂective Operator
6, 51, 55, 117, 185
Reliability
13
Remaining useful life
53, 57
Requirements
1, 27
Risk priority number
40
Robot arm
81
Runtime reconﬁguration
113, 114, 184
Runtime Veriﬁcation
147
Safe planning
113, 184
forbidden pattern, see Forbidden pattern
goal speciﬁcation
115
Safety
13
Self-healing
4
analysis of s.h. operations
102, 109
self-healing framework
138
Self-Optimization
1, 3
cycle
3, 7
model-based
8, 55
Shape
28, 33, 35, 129
Software
14
development
14
Software engineering
25, 33
Speciﬁcation technique CONSENS
39
Stochastic planning model
86
Substationary point
90
Swarm intelligence
20
System Integration
35
System of Objectives
3, 4, 26, 29, 129
System virtualization
152
Taylor series expansion
99
Testing
147
Timed Failure Propagation Graph
106
Translation algorithm
46
Two-link mechanism
81
Uncertainty
14, 76
Veriﬁcation
14, 119
compatibility function
120
design-time
113, 114
motion proﬁles
119
Virtual machine
154
Virtual prototype
31, 33, 35
Virtualization
152
Wear
18, 53
X-by-wire vehicle
21, 65, 130

