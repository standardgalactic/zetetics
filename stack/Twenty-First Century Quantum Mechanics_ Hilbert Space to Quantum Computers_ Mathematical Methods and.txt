UNITEXT for Physics
Guido Fano
S.M. Blinder
Twenty-First 
Century Quantum 
Mechanics: Hilbert 
Space to Quantum 
Computers
Mathematical Methods and Conceptual 
Foundations

UNITEXT for Physics
Series editors
Michele Cini, Roma, Italy
Attilio Ferrari, Torino, Italy
Stefano Forte, Milano, Italy
Guido Montagna, Pavia, Italy
Oreste Nicrosini, Pavia, Italy
Luca Peliti, Napoli, Italy
Alberto Rotondi, Pavia, Italy
Paolo Biscari, Milano, Italy
Nicola Manini, Milano, Italy
Morten Hjorth-Jensen, East Lansing, USA

UNITEXT for Physics series, formerly UNITEXT Collana di Fisica e Astronomia,
publishes textbooks and monographs in Physics and Astronomy, mainly in English
language, characterized of a didactic style and comprehensiveness. The books
published in UNITEXT for Physics series are addressed to graduate and advanced
graduate students, but also to scientists and researchers as important resources for
their education, knowledge and teaching.
More information about this series at http://www.springer.com/series/13351

Guido Fano
• S.M. Blinder
Twenty-First Century
Quantum Mechanics: Hilbert
Space to Quantum
Computers
Mathematical Methods and Conceptual
Foundations
123

Guido Fano
Dipartimento di Fisica e Astronomia
Università di Bologna
Bologna
Italy
S.M. Blinder
University of Michigan
Ann Arbor, MI
USA
ISSN 2198-7882
ISSN 2198-7890
(electronic)
UNITEXT for Physics
ISBN 978-3-319-58731-8
ISBN 978-3-319-58732-5
(eBook)
DOI 10.1007/978-3-319-58732-5
Library of Congress Control Number: 2017940230
© Springer International Publishing AG 2017
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made. The publisher remains neutral with regard to
jurisdictional claims in published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Foreword
Many years ago, my math teacher assigned me the task to give a presentation to the
rest of the class. Time to prepare, 2 weeks; topic, group theory and its application to
quantum mechanics. I politely observed that I had not yet had a course on quantum
theory; I knew nothing about it. Teacher’s reply was: “Well, you study it.” His
name was Guido Fano.
This is how Guido Fano had me learning quantum theory. At home, alone, with
a bunch of books on my desk, Dirac’s one on top of all. I have been forever grateful
to him, for this and much more. If I got into theoretical physics, it’s thanks to him,
the trust that I found, with surprise, from him. Today, when I realize that there is
something that I should know and do not know (which of course happen contin-
uously), I hear his voice in my mind saying “Well, you study it.”
But the second lesson I learned from Guido Fano, both about life and quantum
theory, was even more crucial. After my presentation to the class, I thanked him and
said: “I have now learned quantum mechanics.” His reply was “No you haven’t.”
How true.
And not just because a couple of weeks couldn’t sufﬁce to digest the theory, but
because nearly a century from Heisenberg and Dirac hasn’t sufﬁced the community
of us all to come to terms with this theory. In the months after my presentation,
I kept discovering, ﬁrst from Fano himself, and then over and over for the rest of
my life, how multifaceted is this theory, and how slippery our actual understanding
to it. The more I have learned about the theory, the less clear it has become. When
comes the moment of saying what we really have learned about the world in ﬁnding
that quantum mechanics works so effectively—well, we disagree among ourselves,
and there are nearly as many opinions as physicists (not counting the philosophers).
Long time later, with this new book on quantum theory, once again Guido Fano,
together with his overseas colleague S.M. Blinder, opens up new sides of quantum
mechanics for me. The beauty of this book, in my opinion, is that it merges very
different traditions of thinking about the theory and teaching it. For a theory still so
perplexing, this is what we need; in order to understand it better, to learn it better,
but also to learn how to better use it.
v

If had to start again learning quantum theory from scratch, as I did 40 years ago,
I would do as I did: at home, alone, with many texts on my desk. But I would
certainly have, next to Dirac’s one, this book.
Marseille, France
February 2017
Carlo Rovelli
vi
Foreword

Preface
This monograph is the result of many years of experience and contemplation by two
octogenarian mathematical physicists, on opposite sides of the Atlantic, who, after
all these years, are still endlessly fascinated by the marvelous intellectual ediﬁce
that has become quantum mechanics. And which, in the twenty-ﬁrst century,
continues its proliferation into entirely new avenues of human accomplishment,
including experiment-based answers to metaphysical questions and the limitless
potential of quantum computation.
The main purpose of the book is to make accessible to nonspecialists the still
evolving fundamental concepts of QM and the terminology in which these are
expressed. Hence our title: “Twenty-First Century Quantum Mechanics: Hilbert
Space to Quantum Computers.” Among the concepts which we emphasize are the
following:
• The wavefunction of a particle: associated with a “cloud” of probability, such
that the density of the cloud is greater in regions which have a higher probability
of containing the particle.
• The Heisenberg uncertainty principle: conjugate pairs of observables, such as
the position and the velocity of a particle, cannot both be precisely determined at
the same time.
• Isotropic vectors: vectors with complex components, which are orthogonal to
the rotation axis and thus remain invariant under rotation; these are used to
construct spinors.
• The spin of elementary particles: the quantum counterpart of rotations of clas-
sical objects, described by spinors.
• The question of whether the fundamental laws of physics violate local realism.
Locality means that the inﬂuence of one particle on another cannot exceed the
speed of light. Realism means that quantum states have well-deﬁned properties,
independent of our knowledge of them.
• The possible existence of hidden variables: something analogous to the enor-
mous number of microscopic details of molecular motions, which exhibit
vii

themselves in the determinate macroscopic properties of matter, such as
temperature, pressure, etc.
• Conceptual problems associated with measurement, superposition and deco-
herence in quantum systems: collapse of the wavefunction, Schrödinger’s cat,
and quantum entanglement.
• Quantum computers: if they can be made practicable, enormous enhancements
in computing power, artiﬁcial intelligence and secure communication will
follow.
Needless to say, the quantum theory raises very profound metaphysical and
epistemological questions on the description about the “objective world.”
An important precept of Felix Klein’s famous Erlangen program was that “A
geometry is the study of invariants under a group of transformations.” These ideas,
subsequently elaborated in the contributions of Einstein, Dirac, and the philosopher
Nozick, have led to, at least, a provisional understanding of what constitutes reality.
The need for an observer to “search for invariants” is of such generality that it
must apply even in the lives of animals. Imagine a gazelle cautiously eying two
lions. Suppose that she glances at the ﬁrst lion, and then the second. In doing so, she
must turn her head. But there must be some process in her brain that enables her to
realize that, even after she turns her head (and thus registers a different image), the
ﬁrst lion is still there, surely an instance of “invariance.” If we wanted to build a
robot capable of distinguishing objects, then, when the robot’s eyes move, its
programming must include the capability of performing mathematical transforma-
tions among images viewed at varying angles at different times. Nature probably
does not work in precisely the same way, but the fundamental conceptual features:
(1) variability of images and (2) recognition of invariants, or common elements,
must still be applicable.
These ideas certainly pertain to the classical view of Nature; what are their
manifestations in quantum mechanics? The analog of the rotation of a classical
observer is the evolution of the wavefunction. However there are two distinctly
different modes of evolution in quantum mechanics. One is a continuous evolution,
following the time-dependent Schrödinger equation; the second, called collapse
of the wave function, is a random and instantaneous event brought about by a
measurement or perturbation of the quantum system. This was, at least, the point of
view of the founding fathers of quantum mechanics, mainly Bohr, Heisenberg, and
Dirac. The most eminent critic of such ideas (a probabilistic interpretation of QM)
was none other than Albert Einstein, as epitomized in his famous pronouncement:
“God does not play dice with the Universe!”
A major aspect of the epistemological problem has been resolved by actual
experiments (by Alain Aspect and others), motivated by the deep insights of John
Stewart Bell. This has revealed a major incompatibility between the worldviews of
classical and quantum physics. Bell’s theorem states that it is impossible to explain
viii
Preface

the results of quantum physics using the causality of classical physics, thus negating
the possible existence of local hidden variables. Quantum mechanics differs fun-
damentally from classical mechanics in that the underlying microscopic behavior
is not determinate.
Measurement and decoherence: according to the traditional (“Copenhagen”)
interpretation of quantum mechanics, wave function collapse occurs when a mea-
surement is performed. However there remains the problem of when the collapse
actually occurs? In the past, some physicists thought that collapse is brought about
when a conscious observer “takes note” of the new state of a system; but this point
of view is now in the minority, since it is more reasonable to think that any
inanimate apparatus can also make a measurement and produce a “quantum jump.”
A more realistic approach to this problem is to consider the microscopic system, the
measuring apparatus and the environment as a single composite system. The
wavefunction of the complete system must change during an exceedingly short
interval of time from a “superposition of states,” to just one of these states. This
phenomenon is called decoherence; it can be proved mathematically rigorously in
some models, although there is still much work to be done.
The superposition of two wavefunctions for a macroscopic object is also con-
sidered in the infamous Schrödinger’s cat Gedankenexperiment. A cat is conﬁned to
a closed box with a Geiger counter, which detects randomly-occurring radioactive
decays in a sample of radium. The Geiger counter is connected to a vial of cyanide,
which is broken when a decay particle is detected, killing the unfortunate cat. Until
the box is opened, its state can only be described as a “superposition,” of a “live
cat” and a “dead cat.” According to the Copenhagen version of quantum mechanics,
the cat “becomes” dead or alive only after an observer opens the box. As para-
doxical as it seems, superposition of quantum states of macroscopic objects has
now been achieved, for example, in a SQUID (superconducting quantum inter-
ference device).
Quantum computing proposes to apply uniquely quantum-mechanical phe-
nomena, such as superposition and entanglement to operate on quantum units of
information, called qubits. In contrast to classical bits, which can represent a
variable with just two values, say 0 and 1, qubits can, in concept, contain an inﬁnite
continuum of information, in terms of superpositions of two basis qubits, such as
jWi ¼ aj0i þ bj1i. A quantum computer could, in principal, be capable of solving
problems in a matter of seconds, which might take a classical computer several
centuries to accomplish. Several hypothetical quantum algorithms have already
been proposed for large-integer factorization and other applications. Current real-
izations of quantum computers are still very far from having such capabilities. But
apart from potential practical applications, quantum computing remains a profound
subject of fundamental interest for both computer science and quantum mechanics.
Preface
ix

Acknowledgements
The authors wish to thank: Prof. Sergio Doplicher, for his enlightened clariﬁcations
on the concept of decoherence; Prof. Carlo Rovelli for correspondence on questions
concerning the philosophy of science; Prof. Angelo Vistoli and Dr. Alessandro
Malusà for their assistance in the beautiful proof presented in Appendix to Chap. 6;
and, ﬁnaly, Lorenzo Felice for his skillful and imaginative sketches of most of the
ﬁgures.
Bologna, Italy
Guido Fano
Ann Arbor, USA
S.M. Blinder
January 2017
x
Preface

Contents
1
Twentieth-Century Quantum Mechanics . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Quantum Theory and Atomic Structure . . . . . . . . . . . . . . . . . . . .
1
1.1.1
Wave Nature of Light. . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.1.2
Corpuscular Nature of Light . . . . . . . . . . . . . . . . . . . . . .
4
1.1.3
Corpuscular Nature of the Electron. . . . . . . . . . . . . . . . .
8
1.1.4
Wave Nature of the Electron . . . . . . . . . . . . . . . . . . . . .
9
1.1.5
Early Models of Atomic Structure . . . . . . . . . . . . . . . . .
11
1.2
Probability and Statistical Mechanics . . . . . . . . . . . . . . . . . . . . . .
16
1.2.1
Introduction to Probability . . . . . . . . . . . . . . . . . . . . . . .
17
1.2.2
Statistical Mechanics. . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
1.2.3
Combinatorial Analysis. . . . . . . . . . . . . . . . . . . . . . . . . .
23
1.2.4
Gaussian Integrals. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
1.2.5
Maxwell–Boltzmann Distribution . . . . . . . . . . . . . . . . . .
29
1.3
The Birth of Quantum Mechanics . . . . . . . . . . . . . . . . . . . . . . . .
32
1.3.1
Hilbert Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
2
Mathematical Methods in Quantum Mechanics . . . . . . . . . . . . . . . . .
43
2.1
Vector Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
2.2
Matrices in Quantum Mechanics . . . . . . . . . . . . . . . . . . . . . . . . .
49
2.3
Quantum Mechanics in Toy Hilbert Space. . . . . . . . . . . . . . . . . .
58
2.4
The Hilbert Space of Real Wavefunctions . . . . . . . . . . . . . . . . . .
63
2.5
Complex Variables. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
2.6
Complex Vector Spaces and Dirac Notation . . . . . . . . . . . . . . . .
75
2.7
Coordinates and Momenta in Quantum Mechanics . . . . . . . . . . .
79
2.8
Heisenberg Uncertainty Principle . . . . . . . . . . . . . . . . . . . . . . . . .
83
3
The Schrödinger Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
3.1
Heuristic Derivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
3.2
Particle in a Box . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
3.3
The Harmonic Oscillator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
xi

3.4
Angular Momentum. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
96
3.4.1
Particle in a Ring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
96
3.4.2
Angular Momentum Operators . . . . . . . . . . . . . . . . . . . .
98
3.4.3
Eigenvalues and Eigenfunctions . . . . . . . . . . . . . . . . . . .
99
3.4.4
Matrix Representations . . . . . . . . . . . . . . . . . . . . . . . . . .
102
3.4.5
Electron Spin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
102
3.4.6
Abstract Theory of Angular Momentum . . . . . . . . . . . . .
103
3.5
The Hydrogen Atom . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
104
3.5.1
Spherical Polar Coordinates . . . . . . . . . . . . . . . . . . . . . .
105
3.5.2
Solution of the Schrödinger Equation . . . . . . . . . . . . . . .
106
3.5.3
Atomic Structure. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
109
3.6
Time Evolution and Collapse of the Wavefunction . . . . . . . . . . .
111
3.6.1
The Evolution Operator . . . . . . . . . . . . . . . . . . . . . . . . .
111
3.6.2
Schrödinger and Heisenberg Pictures . . . . . . . . . . . . . . .
113
3.6.3
Collapse of the Wavefunction. . . . . . . . . . . . . . . . . . . . .
115
3.7
Philosophical Issues in Quantum Mechanics . . . . . . . . . . . . . . . .
117
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and
Groups. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
121
4.1
Invariance and the Objective World. . . . . . . . . . . . . . . . . . . . . . .
121
4.2
Isotropic Vectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
126
4.3
The Stereographic Projection . . . . . . . . . . . . . . . . . . . . . . . . . . . .
127
4.3.1
Spinors in Spherical Coordinates . . . . . . . . . . . . . . . . . .
136
4.4
Lie Groups: SO(3) and Vector Rotation, SU(2) and Spinor
Rotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
137
5
Quantum Entanglement and Bell’s Theorem . . . . . . . . . . . . . . . . . . .
153
5.1
Product States in Hilbert Space . . . . . . . . . . . . . . . . . . . . . . . . . .
153
5.2
Bohm’s Version of the Einstein–Podolsky–Rosen Experiment. . .
160
5.3
Hidden Variables and Bell’s Inequality . . . . . . . . . . . . . . . . . . . .
164
5.4
Generalized Bell’s Inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . .
169
5.5
Maxwell’s Equations, the Nature of Light, and All That . . . . . . .
173
5.6
Light Polarization and the Spin of the Photon . . . . . . . . . . . . . . .
177
5.7
The Hilbert Space of One Photon and Aspect’s Experiment . . . .
179
5.7.1
Photon Polarization. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
179
5.7.2
Aspect’s Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . .
182
5.8
Measurement and Decoherence . . . . . . . . . . . . . . . . . . . . . . . . . .
184
6
Digital and Quantum Computers . . . . . . . . . . . . . . . . . . . . . . . . . . . .
195
6.1
Binary Number System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
195
6.2
Boolean Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
196
6.2.1
Venn Diagrams. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
198
6.3
Classical Computers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
201
6.3.1
Logic Gates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
201
6.3.2
Binary Multiplication . . . . . . . . . . . . . . . . . . . . . . . . . . .
205
6.3.3
A Living Computer. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
207
xii
Contents

6.4
Quantum Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
207
6.4.1
Quantum Gates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
210
6.5
Deutsch’s Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
216
6.6
Bell States . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
218
6.7
Quantum Teleportation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
220
6.8
The Toffoli Logic Gate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
222
6.9
Quantum Fourier Transform. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
224
6.9.1
Phase Estimation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
230
6.10
Some Results from Number Theory. . . . . . . . . . . . . . . . . . . . . . .
233
6.10.1
The Euclidean Algorithm . . . . . . . . . . . . . . . . . . . . . . . .
233
6.10.2
Bezout’s Lemma. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
234
6.10.3
Modular Arithmetic . . . . . . . . . . . . . . . . . . . . . . . . . . . .
235
6.10.4
Fermat’s Little Theorem . . . . . . . . . . . . . . . . . . . . . . . . .
238
6.10.5
Chinese Remainder Theorem . . . . . . . . . . . . . . . . . . . . .
240
6.10.6
More Group Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . .
242
6.10.7
Factorization of Large Numbers . . . . . . . . . . . . . . . . . . .
244
6.10.8
Quantum Order Finding . . . . . . . . . . . . . . . . . . . . . . . . .
248
6.10.9
Continued Fractions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
252
6.10.10 Prime Number Theorem . . . . . . . . . . . . . . . . . . . . . . . . .
253
6.11
Quantum Cryptography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
254
6.11.1
RSA Cryptography . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
255
6.11.2
Code Breaking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
257
Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
258
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
263
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
267
Contents
xiii

About the Authors
Guido Fano graduated Magna Cum Laude in Physics
at the University of Rome in 1955. He was Assistant
Lecturer, later Senior Lecturer, and ﬁnally Professor of
Mathematical Methods of Physics. He earned univer-
sity degrees in Theoretical Physics and Mathematical
Methods of Physics. He taught at several universities,
including Naples, Ferrara, Bologna, and Marseille.
Professor
Fano
is
a
specialist
in
the
quantum
many-body problem, with particular emphasis on the
mathematical aspects; he has about 60 publications in
international journals. Some particularly signiﬁcant
results
concern
the
existence
problem
for
the
time-dependent Hartree–Fock equations, the use of
non-orthogonal orbitals in Quantum Chemistry, and
the asymptotic behavior of the Taylor expansion
coefﬁcients of some sequences of polynomials. He is
the author of several textbooks, notably Mathematical
Methods
of
Quantum
Mechanics
(McGraw-Hill,
1971).
xv

S.M. Blinder is Professor Emeritus of Chemistry and
Physics at the University of Michigan, Ann Arbor,
USA. He completed his Ph.D. at Harvard University in
1958, under the supervision of Profs. W.E. Mofﬁtt and
J.H. Van Vleck (Nobel Prize in Physics, 1977).
Professor Blinder has over 200 publications in both
Theoretical Chemistry and Mathematical Physics. He
was the ﬁrst to derive a closed-form expression for the
Feynman path-integral propagator for the Coulomb
problem (the hydrogen atom). He is the author of
several books and monographs, most notably,Quantum
Mechanics in Chemistry, Materials Science, and
Biology (Elsevier Academic Press, 2004). Professor
Blinder is currently a telecommuting Senior Scientist
for Wolfram Research (the developers of Mathematica
and other scientiﬁc software).
xvi
About the Authors

Chapter 1
Twentieth-Century Quantum Mechanics
Abstract The historical development and fundamental principles of quantum
mechanics are reviewed. Fundamental differences with classical statistical mechan-
ics are emphasized. The representation of quantum phenomena in Hilbert space is
introduced.
Keywords Quantum mechanics · Atomic structure · Wave-particle duality · Prob-
ability theory · Quantum states · Hilbert space
The fundamental ideas at the root of quantum mechanics are introduced in this
chapter. Beginning at an elementary level, the necessary mathematical background
will be developed as we go along, so that readers will be able to understand such
concepts as the superposition of quantum states, time evolution of quantum systems
and the Heisenberg uncertainty principle. Starting out, these will be represented in
terms of a highly simpliﬁed version of Hilbert space, a “toy Hilbert space,” equivalent
to the two-dimensional Cartesian plane. The more advanced mathematical structure
of an inﬁnite-dimensional Hilbert space will thereby be rendered more accessible in
our later work. In some cases, we will sacriﬁce some mathematical rigor in order
to achieve greater clarity. In the words of the British author H.H. Munro (pen name
Saki): “A little inaccuracy sometimes saves tons of explanation.” Also, in this chapter,
we will brieﬂy allude to some of the philosophical problems created by quantum
mechanics, as a prelude to more detailed discussions in later chapters.
1.1
Quantum Theory and Atomic Structure
We will ﬁrst expound on a very elementary level some of the mathematical concepts
which are basic in quantum mechanics (QM). These constitute, to a large extent, the
theory of linear operators in a Hilbert space. This subject matter is as fundamen-
tal for QM as differential calculus was for classical mechanics. The mathematical
tools of QM are not as familiar as those used in classical mechanics, at least at the
© Springer International Publishing AG 2017
G. Fano and S.M. Blinder, Twenty-First Century Quantum Mechanics:
Hilbert Space to Quantum Computers, UNITEXT for Physics,
DOI 10.1007/978-3-319-58732-5_1
1

2
1
Twentieth-Century Quantum Mechanics
Table 1.1 Corpuscles and waves
Corpuscular nature of light: Photoelectric
effect, Compton effect, etc.
Wave nature of light: Interference and
diffraction
Corpuscular nature of the electron: Millikan oil
drop experiment
Wave nature of the electron: X-ray
crystallography, electron diffraction
present time. But it is likely that this will not always be the case, since the process
of “knowledge compression” continually enables beginning students of science to
become acquainted with modern techniques earlier in their academic careers. We will
brieﬂy outline, without any attempt at historical narrative, the seminal ideas which
gave rise to the quantum theory. These new concepts and experimental facts have
resulted in a major revolution—a “paradigm shift,” as described by Kuhn (1996)—in
the transition from classical to quantum physics.
Theadventofthequantumtheorywasmadeinevitable,bythenecessitytorational-
ize experimental evidence that both light and electrons have a dual nature, behaving
sometimes as particles, and at other times as waves. Let us summarize the principal
deﬁning experimental facts in a small table divided into four quadrants (Table1.1).
1.1.1
Wave Nature of Light
If we drop a stone into a calm lake, a train of circular waves of increasing radius
is produced (see Fig.1.1). Let us suppose that we observe the waves as their radii
become increasingly larger. Two fundamental parameters which describe waves are
the wavelength λ and the period T . The wavelength λ is the distance between the
maxima of successive wave crests (see Fig.1.2).
Fig. 1.1 Waves generated by a stone dropped into a body of water. Note the sinusoidal proﬁle of
the waves

1.1 Quantum Theory and Atomic Structure
3
Fig. 1.2 The wavelength λ
is the distance between two
successive maxima (or
minima) of a wave
Suppose now that the wave encounters a small piece of wood ﬂoating on the water;
this will cause the wood to oscillate up and down. The time between two successive
maxima (highest points) is called the period T of the wave. The frequency ν of the
wave and its propagation velocity c are related by
ν = 1
T ,
c = λ
T .
(1.1)
One of the legendary giants of modern physics, James Clerk Maxwell, proposed
in 1864 that light consists of propagating electromagnetic waves. This discovery is
one of the most extraordinary achievements of the human intellect; a more detailed
discussion will be given in Chap.5. To begin, we consider the classic double-slit
experiment, performed by Thomas Young in 1801 Young (1807), from which it
could be inferred that light is a wavelike phenomenon. Consider two identical waves
A, B, slightly displaced with respect to one another (see Fig.1.3). When the two
waves overlap in the same region of space, their resultant is the algebraic sum of A
and B. There are two limiting possibilities (see Fig.1.4):
(1) Constructive interference, in which the resulting wave is larger than either A or B.
(2) Destructive interference, in which the two waves annihilate one another and sum
to zero.
In Young’s experiment, a beam of monochromatic light illuminates a screen with
two narrow vertical slits. According to Huygens’s principle, every point on the slits
becomes the source of a new spherical wave. An analogous effect can be observed
when waves in the lake collide with a barrier with a small hole, as shown in Fig.1.5.
In this way light deviates from its original propagation direction, and is incident on a
second screen, parallel to the ﬁrst. This phenomenon is called diffraction. In Young’s
experiment the waves A, B produced by the two slits interfere on the second screen.
Since the paths of A, B have different lengths, the two waves gives rise to bright bands
when the path difference δ of A, B is an integer multiple m of the wavelength: δ =
mλ, resulting in constructive interference. However, when the path difference is an
odd half integer multiple of the wavelength: δ = (m + 1
2)λ, destructive interference
produces a dark band on the screen (see Fig.1.6). The inescapable conclusion from
these experiments is that light is a wavelike phenomenon.

4
1
Twentieth-Century Quantum Mechanics
Fig. 1.3 Two identical waves approaching one another
Fig. 1.4 a Constructive interference of two waves. b Destructive interference
Fig. 1.5 A wave
encountering a barrier with a
hole, giving rise to a new
circular wave. This is an
analog of Huygens’s
principle
1.1.2
Corpuscular Nature of Light
Before demonstrating the remarkable fact that light also exhibits a corpuscular nature,
we brieﬂy summarize some aspects of the interaction between matter and radiation.
It is well known that solid bodies emit radiation with maximum wavelength depend-
ing on the temperature T . If the temperature is very high, the body can become
incandescent, emitting visible light (thus the term “red hot”). Even a moderately
hot iron emits infrared radiation, which can be experienced by holding your hand
near its surface. To isolate the phenomenon of emission from irrelevant factors such

1.1 Quantum Theory and Atomic Structure
5
Fig. 1.6 Young’s
experiment showing
interference of light waves
as the shape, composition or color of the emitting body, physicists have idealized
the concept of a blackbody, which is assumed to absorb and emit radiation of all
wavelengths. An approximation to a blackbody might consist of a box with perfectly
absorbing walls, accessible through a small hole (called a Hohlraum in German).
A narrow beam of radiation entering the box interacts with the dark walls through
absorption and emission processes. The radiation inside consists of a superposition
of many different wavelengths, while the walls are maintained at a speciﬁed temper-
ature T . The intensity (or spectral radiance) I of the radiation emitted through the
hole is proportional to the energy density ρ of the radiation inside the cavity, which is
assumed to be a universal function of wavelength λ (or frequency ν) and temperature
T , which can be written ρ = ρ(ν, T ). As early as 1859, Kirchhoff recognized the
central signiﬁcance of the form of the function ρ, which must contain some important
clue to the fundamental nature of light. In his words: “Es ist eine Aufgabe von hoher
Wichtigkeit, diese Funktion zu ﬁnden’’ (It is very important to ﬁnd this function).
Many attempts to derive such a function were based on Rayleigh’s picture of radi-
ation interacting with electric oscillators in the walls. Based on classical mechanics
and electromagnetism, the Rayleigh–Jeans formula at given temperature T predicts
a quadratic increase of intensity with frequency (see Fig.1.7a). But this is manifestly
contrary to everyday experience, for it would imply that the total energy emitted
by the blackbody, at any temperature T , increases without limit as the frequency
increases (known as the “ultraviolet catastrophe”). We would not be able to sit by a
ﬁreplace without being roasted like marshmallows by high intensity ultraviolet (and
gamma) rays.
Planck (1900) conjectured a form of the function ρ(ν, T ) which agreed with
experiment, based on the ansatz that the energy of each electromagnetic oscillator
within the cavity did not vary continuously, but rather was an integer multiple of an
elementary quantum of energy ε, proportional to the frequency ν of the oscillator.
He proposed that

6
1
Twentieth-Century Quantum Mechanics
Fig. 1.7 Blackbody
radiation: a Rayleigh–Jeans
quadratic behavior. b Planck
distribution law
ε = hν,
(1.2)
where h is a fundamental constant, now called Planck’s constant. Setting h = 6.55 ×
10−34 J s gave quantitative agreement with the experimental spectral energy density ρ
(see Fig.1.7b). By taking account of the frequency distribution of oscillators in three
dimensions and the Boltzmann distribution at temperature T , Planck’s distribution
function can be derived:
ρ(ν, T ) = 8πhν3
c3
1
ehν/kT −1,
(1.3)
where c is the speed of light. We now have a more accurate value of Planck’s constant:
h = 6.62606876 × 10−34 J s.
Another phenomenon that furthered the acceptance of the quantum theory was the
photoelectric effect: the emission of electrons from certain metals when illuminated
by electromagnetic radiation, such as light, ultraviolet, X-rays, etc. It was expected,
from classical theory, that increasing the intensity of the incident radiation would
increase the kinetic energy of the emitted electrons; but this is not the case. In fact,
increasing the radiation intensity increases only the number of emitted electrons.
Furthermore no electrons are emitted if the radiation frequency is below a certain
threshold. Einstein (1906) explained such behavior by assuming that the incoming
radiation is not continuous, but is made up of individual quanta, each of energy
hν, where h is again Planck’s constant. Suppose that an electron receives one such
quantum of radiation, and leaves the crystal to which it is bound with a binding
energy ε0. Then by conservation of energy, the kinetic energy T must be equal to the
energy hν of the quantum minus the binding energy ε0. Einstein proposed the law:
T = hν −ε0.
(1.4)

1.1 Quantum Theory and Atomic Structure
7
Fig. 1.8 Kinetic energy of
the ejected electron in the
photoelectric effect
This relation is shown in Fig.1.8 and has been extensively tested experimentally.
Since the kinetic energy must be positive, no electrons are released if the quantum
energy is less than the threshold ε0. Thus we must add to Eq. (1.4) the condition:
T = 0 for hν < ε0. The paradox about the number of emitted electrons is thereby
resolved, since, with light of low intensity, there are fewer atoms absorbing a quan-
tum. Increasing the intensity just produces more quanta, but all with the same energy
hν. The introduction of light quanta, later called photons, was the most signiﬁcant
advance in our modern understanding of the nature of light.
Arthur Compton (1923) bombarded atomic electrons, which are relatively loosely
bound, with high-energy photons. The result was that the photons were deﬂected from
their original directions, while the electrons were ejected from their atoms with a
measurable kinetic energy T . In classical mechanics, an elastic collision between
two particles must obey the two fundamental principles: conservation of energy and
conservation of momentum. If ν denotes the frequency of the incoming photon, and ν′
that of the scattered photon, the ﬁrst of the two laws implies that hν = hν′ + T . The
law of conservation of momentum, a vector relation, is a little more complicated to
apply. We skip the details but note only that the momentum pν of the incoming photon
is the resultant of the momentum pν′ of the scattered photon and the momentum mv
acquired by the electron (see Fig.1.9). As a result, the frequency of the incoming
radiation is shifted by ν −ν′, which can easily be computed. The Compton effect,
which we have just described, lent further support of the Planck–Einstein theory of
radiation.
The various phenomena described above presents a major metaphysical question
that continues to defy a simple answer: “Is light a particle or a wave? Or somehow,
both?” Possibly, the most sensible answer is that photons (and electrons) behave
neither as classical particles nor waves, but in an idiosyncratic way in accordance
with the laws of quantum mechanics.

8
1
Twentieth-Century Quantum Mechanics
Fig. 1.9 The Compton effect: the energy of the scattered photon is equal to the energy of the
incoming photon minus the energy gained by the atomic electron
1.1.3
Corpuscular Nature of the Electron
More than 2400 years ago, Democritus and Leucippus claimed that everything in the
world is composed of atoms. As Feynman emphasized “all things are made of atoms”
contains“anenormousamountsofinformationabouttheworld.”Certainlytheatomic
hypothesis was a critical breakthrough (or paradigm shift) for our understanding of
the nature of matter.1 In the mid-nineteenth century, Richard Laming proposed that
atoms are composed by a core of matter with electrically charged balls surrounding
it. In 1870, William Crookes built the ﬁrst cathode ray tube, in which a ﬂux of charged
particles from a positively charged cathode impinged on a negatively charged anode.
He was able to deﬂect the rays with a magnetic ﬁeld, and concluded that they were
negatively charged. In 1881, Hermann von Helmholtz postulated the existence of
elementary negative and positive charges, each behaving like atoms of electricity.
Now we call them electrons and positive ions. In 1890, Arthur Schuster showed that
the cathode rays of the Crookes tube are deﬂected by an electric ﬁeld, and was able to
calculate the charge to mass ratio e/m of the electrons. J.J. Thomson gave estimates
of both m and e and observed that these values were independent of the metallic
composition of the cathode.
In1909,MillikanandFletcher(1913)carriedoutthefamous“oildropexperiment”
which conﬁrmed the discrete negative charge of electrons. Very small oil droplets are
observed through a microscope while they are subjected to a uniform electric ﬁeld of
known intensity E (see Fig.1.10). The oil is sprayed into a chamber above a capacitor.
The droplets fall by gravity into the region of the electric ﬁeld. They have become
electrically charged by friction with the nozzle of the sprayer; alternatively they can
be subjected to ionizing radiation. Since the size and density of the droplets can be
estimated, their mass M can be computed. In this way, the three forces acting on a
given droplet are known: electrostatic force, gravitational force Mg, and frictional
drag of the air. It was observed that the charges absorbed by the droplets were all
multiples of a fundamental value, which we now recognize as the charge −e of a
single electron. Millikan and Fletcher found the value e = 1.592 × 10−19 C, within
one percent of the presently accepted value, e = 1.6021764 × 10−19 C.
1There was no accepted coherent theory of atoms during the middle of the eighteenth century.

1.1 Quantum Theory and Atomic Structure
9
Fig. 1.10 Simpliﬁed pictorial of Millikan’s oil drop experiment
1.1.4
Wave Nature of the Electron
A young French physicist, De Broglie (1924), conjectured that not only light, but
also particles of matter can exhibit a wave–particle duality. Denote by p = mv the
momentum of a particle (such as an electron) with mass m traveling with velocity v.
He proposed that the motion of the electron is associated with a “matter wave” with
wavelength given by:
λ = h
mv = h
p .
(1.5)
De Broglie’s formula can be arrived at by the following heuristic argument. In rela-
tivity theory, space and time are connected, as the components of a four-dimensional
vector in spacetime, (x0, x1, x2, x3) = (ct, x, y, z). Analogously, momentum p and
energy ε can be combined into a 4-vector (p0, p1, p2, p3) = (ε/c, px, py, pz). Since
time is conceptually the zeroth component of spacetime, it can be surmised that
energy is equivalent to the
zeroth component of 4-momentum. Recall now the
wavelength–frequency relation λ = c/ν. By the Planck–Einstein relation, ε = hν,
we can write λ = hc/ε = h/(ε/c). But ε/c is the zeroth component of 4-momentum
and has the dimensions of p. Thus we can propose that λ = h/p might be the space-
like analog of the relation ε = hν, which contains the timelike variable ε. It turns out
that, in the Compton effect, the momentum of a photon is indeed given by p = h/λ.
Both the de Broglie and Planck–Einstein relations, p = h/λ and ε = hν, are
quantitativerepresentationsofthewave–particleduality:wavelengthλandfrequency
ν being wavelike attributes, while momentum p and energy ε are particle-like.
Von Laue (1913) and the Braggs (William Henry and William Lawrence, father
and son) Bragg and Bragg (1913) showed that X-rays impinging on a crystal lattice

10
1
Twentieth-Century Quantum Mechanics
Fig. 1.11 Schematic of the Davisson and Germer experiment: a beam of electrons passes through
two apertures D and D′ and is diffracted by a nickel crystal
gave waves reﬂected by every plane of atoms in the lattice (including oblique planes),
interfering constructively or destructively according to their angle of incidence.
Davisson and Germer (1927) carried out an analog of this experiment using a beam of
electrons in place of X-rays. Let us describe in some detail their beautiful experiment.
A beam of electrons is emitted by a cathode in a vacuum apparatus and accelerated
by an electric ﬁeld (see Fig.1.11). The beam is columnated (narrowed) by passing
it through the apertures D, D′ in two screens and is directed perpendicularly onto
a nickel crystal. The angle θ between the scattered electrons and the normal to the
crystal is measured by the electron detector C (shielded in a Faraday cage). Davisson
and Germer found that for certain values of θ, the intensity of the reﬂected beam
was enhanced, precisely analogous to the diffraction of X-rays. Indeed one can use
the Bragg formula that connects the wavelength λ of the radiation with the spacing
d between the planes of the atomic lattice:
nλ = 2d sin θ,
(1.6)
where n is an integer. Formula (1.6) is readily apparent in Fig.1.12. The difference
between the lengths of the two “rays” a, b reﬂected at the points P, Q, respectively, is
equal to the length of the path APC. Since AP = PC = d sin θ, the Bragg condition
(1.6) gives constructive interference between the two rays. Davisson and Germer

1.1 Quantum Theory and Atomic Structure
11
Fig. 1.12 The difference of
the pathlengths of a and b is
the sum of the distances AP
and PC
were able to compute the wavelength λ of the mysterious “matter wave” associated
with the motion of the electrons. The result was in complete agreement with de
Broglie’s hypothesis, Eq. (1.5).
1.1.5
Early Models of Atomic Structure
In 1902, J.J. Thomson hypothesized that atoms are made up of electrons embedded in
a homogeneous sphere of positive electricity (known as the “plum-pudding” model).
However this model was shown to be ﬂawed by Rutherford’s famous experiments
Rutherford (1911). A beam of alpha particles (doubly ionized helium atoms), emitted
by a radioactive source, was directed onto a gold foil. A very small fraction of the
alpha particles were reﬂected almost straight back, as if they had struck something
very hard inside the atoms of the foil. Since alpha particles are positively charged,
Rutherford proposed that the repelling force was due to the presence of a small pos-
itively charged “nucleus” in each atom. Niels Bohr subsequently proposed, in 1913,
a “planetary model” of the atom, in which electrons orbit around a positive nucleus,
similar to the motions of planets around the Sun. It was evident that this model
egregiously violated the laws of classical mechanics and electromagnetism, since all
the energy of the electrons ought to be radiated away in 10−10 s, as the electrons
spiral into the nucleus. This has been called the “atomic Hindenburg disaster” (the
Hindenberg, a hydrogen-ﬁlled dirigible, crashed and burned in a famous disaster in
1937).
The richest source of information on atomic structure is provided by the spec-
tral lines of light emitted and absorbed by atoms. The continuous spectrum is not
relevant for our present considerations (although it produces the beautiful colors of

12
1
Twentieth-Century Quantum Mechanics
Fig. 1.13 Emission spectrum of atomic hydrogen in the visible region
Fig. 1.14 Interaction of light with atoms: emission of a photon of energy E4 −E3 and absorption
of a photon of energy E2 −E1
the rainbow). In the years 1814–1823, Fraunhofer (1817) begin a systematic study
of the dark lines in sunlight, caused by absorption of light by the solar atmosphere
against the continuous background of blackbody radiation. The absorption spectrum
of atomic hydrogen in the visible region, shown in Fig.1.13, consists of ﬁve lines
at wavelengths of 656.3 nm (red), 486.1 nm (blue-green), 434.0 nm (blue-violet),
410.2 nm (violet) and 397.0 nm (violet). Discrete absorption or emission frequencies
cannot be accounted for by classical electromagnetic theory, since the oscillation of
charges generally produces a continuum of frequencies. Bohr (1913), postulated that
the energy levels of the atoms form a discrete series of values E1, E2, E3, . . . (see
Fig.1.14). It then becomes possible to explain the discrete spectral lines. When an
electron jumps from a higher energy level E4 to a lower energy level E3, it emits a
photon of energy
hν = E4 −E3.
(1.7)

1.1 Quantum Theory and Atomic Structure
13
These photons give rise to an emission line of frequency ν. Conversely, an electron
in a lower energy level E1 that absorbs a photon of energy E2 −E1 jumps to the E2
energy level, producing an absorption line. Rydberg (1890) proposed the following
empirical formula for the spectral lines of the hydrogen atom:
1
λ = R
 1
n2 −1
m2

n, m = 1, 2, 3, . . .
m > n,
(1.8)
where R is a constant whose value is about 109737 cm−1. Bohr proposed a planetary
model of the atom in which the electronic energy levels are quantized in a new way.
We will see in a moment that the Bohr model is not only in complete agreement with
Eq. (1.8), but also results in an explicit formula for the Rydberg constant R, in terms
of the fundamental constants h, e, m, c. And this, in our opinion, is really magical.
Let us now consider the analytical mechanics leading to Bohr’s quantization pos-
tulate. In the simplest case, an electron moves around the nucleus in a circular orbit.
Let v denote the speed of the electron, m its mass, r the radius of the orbit, and +Ze
the positive charge of the nucleus. Two forces, in balance, maintain the electron in
its circular orbit, as shown in Fig.1.15, namely:
(1) Coulomb attraction by the nucleus Ze2/r2 (note the similarity to the Newtonian
gravitational force).
(2) This attraction acts as a centripetal force mv2/r to restrain the electron to a cir-
cular orbit. (From another point of view, this can be regarded as a centrifugal force
in the rotating frame of reference.)
Ze2
r2
= m v2
r .
(1.9)
Fig. 1.15 Uniform circular motion of an electron; the centrifugal force is equal and opposite to the
attraction towards the nucleus

14
1
Twentieth-Century Quantum Mechanics
Fig. 1.16 A standing de Broglie’s wave around an electronic orbit
Let us now consider the electron’s de Broglie wave that “travels” around the orbit.
For stationary or standing waves, the wave must overlap with itself after a complete
revolution. A standing wave can be constructed only if the locations of the wave nodes
do not change with time. Thus the length of the orbit must be an integer multiple
n = 1, 2, 3, . . . of the wavelength λ as shown in Fig.1.16:
2πr = nλ.
(1.10)
Substituting the value Eq. (1.5) of the de Broglie wavelength, we obtain 2πr =
nh/mv, or rp = nℏ. Orbital angular momentum is deﬁned by the vector relation
L = r × p. For a circular orbit this reduces simply to L = rp. We obtain thereby the
condition for quantization of angular momentum, which turns out to be a result of
fundamental signiﬁcance in quantum mechanics.
L = rp = nℏ,
(1.11)
This relation leads, as we will next show, to Bohr’s quantization of energy. From
Eq. (1.9), we obtain r = Ze2/mv2. Substituting this expression for r into Eq. (1.11),
(Ze2/mv2)mv = Ze2/v = nℏ; thus v = Ze2/nℏ, and ﬁnally:
rn =
Ze2
m(Z2e4/n2ℏ2) = n2ℏ2
Zme2 .
(1.12)
It follows that the orbital radii are proportional to n2, where n is called the principal
quantum number. For the case of the hydrogen atom, Z = 1. The smallest value of
the principal quantum number, n = 1, gives the Bohr radius:
a0 = r1 = ℏ2
me2 = 0.529 × 10−10 m.
(1.13)

1.1 Quantum Theory and Atomic Structure
15
The energy En of the electron is the sum of its kinetic and potential energies:
En = 1
2mv2 −Ze2
rn
= 1
2
Ze2
rn
−Ze2
rn
= −1
2
Ze2
rn
.
(1.14)
Substituting in the last equation the expression (1.12) for the radius rn, we obtain the
ﬁnal form for the energy levels:
En = −Z2e4m
2 ℏ2
1
n2 .
(1.15)
With Z = 1 and n = 1, we get the ground-state energy of the hydrogen atom,
expressed in electron volts:
E1 = −e4m
2 ℏ2 = −13.6 eV
(1.16)
From Eq. (1.15) and the equation hν = En −En′, (n > n′), we obtain an explicit
expression for the frequency of the photon associated with an electronic jump from
the n to the n′ energy level:
hν = −Z2e4m
2ℏ2
 1
n2 −
1
n′2

, (n > n′),
(1.17)
In terms of the wavelength λ of the photon, use ν = c
λ, so that 1
λ = hν
hc . Thus, Eq.
(1.17) can be written:
1
λ = −Z2R
 1
n2 −
1
n′2

, (n > n′).
(1.18)
with the Rydberg constant given by
R = 2π2e4m
ch3
,
(1.19)
which agrees closely with the empirical value in Rydberg’s formula. The similarities
between the spectra of hydrogen atoms on Earth and those from stars more than 10
billion light years away from us indicate that electrons in both places have exactly
the same mass m and charge e. Furthermore the speed c of light must be the same
throughout the whole Universe. Again, from our naive perspective, we ﬁnd this all
very magical.

16
1
Twentieth-Century Quantum Mechanics
1.2
Probability and Statistical Mechanics
Before introducing the principles of quantum mechanics, a few concepts of probabil-
ity and statistical mechanics provide a useful preliminary. It is well known that clas-
sical mechanics presents us with a precise deterministic worldview which enables,
in principle, exact prediction of the evolution of a macroscopic physical system at all
future times. Consider, for example, the system consisting of an artiﬁcial satellite,
the Earth, the Sun, and the Moon: once the positions and the velocities at a given
instant of time are known, Newton’s laws allow us to determine with precision posi-
tions and velocities of the bodies at any later time. It was recognized by Poincaré
that sometimes the motions depend very sensitively on the initial conditions and this
can lead to chaotic behavior (the details of which are not relevant to our treatment
of QM).
Let us reﬂect on the actual situation in the dynamics of complex systems.
Newton’s laws do indeed have the “absolute predictive ability” which their deter-
ministic formulation would imply. This is true if we apply them in the appropriate
domain of size and speed, possibly with the help of modern computers. The motion
of a small number of macroscopic bodies (as, in the example above, an artiﬁcial
satellite, the Earth, etc., neglecting interactions with far-off planets) can be predicted
with fairly high accuracy. But what happens if we try to apply Newton’s laws to a
system with a much larger number of degrees of freedom? For example, the motion
of air violently escaping from a punctured tire: it is impossible, from a practical point
of view, to know with precision the positions and velocities of all the gas molecules
at a given instant. Their number is too large, and the precision required in order to
make reasonable predictions by integrating the equation of motion is beyond our
capability. We are not dealing only with a practical difﬁculty, which perhaps will be
solved some time in the future, but rather a conceptual difﬁculty. Very appropriate is
a quote by Feynman (1965): “…given an arbitrary accuracy, no matter how precise,
one can ﬁnd a time long enough that we cannot make predictions valid for that long
a time. Now the point is that this length of time is not very large …The time goes, in
fact, logarithmically with the error, and it turns out that in only a very, very tiny time
we lose all our information.” But let us return to the above example, air leaking from
a tire. In such cases, physicists generally make assumptions of a statistical nature: it
sufﬁces to assume that the huge number of air molecules, both inside and outside the
tire, have uniform initial position probabilities, and a distribution of velocities in a
range of magnitudes, moving in arbitrary directions. It is assumed, of course, that the
pressure inside is greater than that outside. At this point, we can apply the laws of clas-
sical mechanics on a statistical level for a reasonable description of the phenomenon,
what has developed into the subject of statistical mechanics. This approach can, for
example, demonstrate how the laws of thermodynamics, which involve macroscopic
quantities such as heat, temperature, pressure, etc., have microscopic analogs on a
molecular level. Thus, gas temperature is a measure of the average kinetic energy of
its molecules, pressure is an average measure of the frequency and intensity of the

1.2 Probability and Statistical Mechanics
17
collisions of the molecules with the walls of the container, etc. The conceptual foun-
dation of statistical mechanics is based on classical mechanics, applied to probability
distributions in phase space, representing all possible microscopic conﬁgurations
of a system. Since the position of a single mass point is described by 3 coordinates
x, y, z, and its velocity by the 3 components vx, vy, vz, a system of N mass points is
represented in a phase space by a point in 6N dimensions. For technical reasons, it
is better to specify the momentum px = mvx rather than the velocity vx, where m is
the mass of the particle, although this does not change things very much. A point in
phase space completely describes, in concept, the detailed microscopic state of the
system. However one should keep in mind that N is an enormous number (for one
mole of gas, N ≈6.02 × 1023). Of course, phase space is not be confused with the
real physical space in which the particles move.
1.2.1
Introduction to Probability
As an elementary example of probability deﬁned on a set (in the above example, it was
phase space): let us assume that an American tourist has decided to go on vacation in
one, and only one, European country. We ask him where he will go, and he answers: “I
do not know yet, but I am 10% certain about going to England, 30% to France, 20% to
Germany and 40% to Italy.” You can see that he has assigned some positive numbers,
between 0 and 1, to some regions of Europe. If E stands for England, F stands for
France, G stands for Germany and I for Italy, the probabilities of the four events
(vacation in England, vacation in France, etc.) are: P(E) =
1
10, P(F) =
3
10, P(G) =
2
10, and P(I) =
4
10. Of course we have P(E) + P(F) + P(G) + P(I) = 1, since
the tourist is sure to spend his vacation in one of these countries. Some simple and
very general logical properties must be satisﬁed by the probability function deﬁned
on a set S (in our case S is the set of the four countries): if A and B denote two disjoint
subsets2 of S, we must have P(A  B) = P(A) + P(B). In our example, if G  F
is the set constituted by Germany and France, clearly P(G  F) =
2
10 + 3
10 =
5
10
is the probability of vacation in Germany or France. Furthermore P(S) = 1 and
P(φ) = 0, where φ denotes the empty set.
Another elementary example: consider an urn containing N balls, of which M are
red. If we withdraw a ball from the urn, and we want to calculate the probability that
the ball is red, the set S now represents all N balls, and a possible subset A is formed
2We recall the meaning of intersection and union of two sets. Consider the following elementary
example: let P be the set of the positive integers less or equal to 12: P = {1, 2, 3, . . . , 12}, E
the subset of the even numbers, E = {2, 4, 6, 8, 10, 12}, O the subset of the odd numbers, O =
{1, 3, 5, 7, 9, 11}, and T the subset of the multiples of 3: T = {3, 6, 9, 12}. The intersection of E
and T is composed of the numbers that are even and multiples of 3: E  T = {6, 12}; The union
of E and T by the number that are even or multiples of 3: E  T = {2, 3, 4, 6, 8, 9, 10, 12}; since
a number cannot be even and odd at the same time, the intersection E  O = φ, where φ denotes
the empty set. We say, in this case, that the sets E and O are disjoint. See also the geometrical
representation of union and intersection in Fig.1.17.

18
1
Twentieth-Century Quantum Mechanics
Fig. 1.17 Given two sets: a circle A and a triangle B. The shaded area shows a the intersection
A  B and b the union A  B
by the M red balls. Let us associate to any ball a probability 1
N of being extracted; then
P(A) = M
N and of course P(S) = N
N = 1. From this example we understand why a
very common deﬁnition of probability is the following: In a situation where there
are equally likely outcomes, the probability of an event is the ratio of the number of
favorable outcomes to the number of possible outcomes.
In probability theory, two events A, B are said to be independent if p(A  B) =
p(A)p(B), where A  B denotes the occurrence of both A and B; to clarify this
concept let us consider again the example of the two urns, containing, respectively, N1
and N2 balls. In the ﬁrst urn, there are M1 red balls, and in the second there are M2 red
balls. Clearly, the probability p1 of extracting a red ball from the ﬁrst urn is p1 = M1
N1
and the probability p2 of extracting a red ball from the second urn is p2 = M2
N2 . Now
if we extract two balls at random, one from the ﬁrst and one from the second urn, the
possible pairs are N1N2; of these pairs M1M2 are constituted by two red balls. Then
using the rule deﬁned above: probability p = number of favorable cases divided by
the number of possible cases, we have (see Fig.1.18) p = M1M2/N1N2 = p1 p2;
thus, denoting by A the event “removal of a red ball from the ﬁrst urn” and by B the
event “removal of a red ball from the second urn”, we have p(A  B) = p(A)p(B);
indeed, the two events are independent.
Suppose now that we have a function f , representing a random variable, deﬁned
on the set S. Returning to the example of the tourist in Europe, suppose he considers
the daily cost of living in his choice. Assuming that this cost is ﬁxed for each coun-
try: for example, 40 euros for England, 60 for France, 80 for Germany and 50 for
Italy. Suppose also that the tourist repeats the same travel itinerary for many years,
always with the same probabilities. We can ask: “What is the average price the tourist
will pay during his travels?” The answer is a suitable weighted sum extended over

1.2 Probability and Statistical Mechanics
19
Fig. 1.18 Points of the large
rectangle represents possible
choices of two balls, one
from the ﬁrst and one from
the second urn; points of the
crosshatched rectangle
represent the choice of two
red balls
the four countries E, F, G, I. We will see in this elementary example that a prob-
ability distribution allows us to compute averages or means of random variables.
If the set S is divided into N disjoint subsets S1, S2, . . . , SN, the probabilities are
P(S1), P(S2), . . . , P(SN), and the function f assumes the value fi on the set Si, the
average value of f is given by:
f =
N

i=1
fi P(Si),
(1.20)
so the average daily cost is
f = 1
1040 +
3
1060 +
2
1080 +
4
1050 = 58.
(1.21)
To quantify the spread in the distribution of costs, we deﬁne a simple mathematical
quantity: the variance σ 2 of a probability distribution, or the standard deviation σ,
the square root of the variance. The variance is deﬁned as the average of the squares
of the deviations fi −f
(the reason for using the squares is that the average of
the deviations always equals zero, with the sum of the positive and negative entries
canceling out). Accordingly, we deﬁne:
σ 2 =
N

i=1
( fi −f )2P(Si) = ( f −f )2.
(1.22)
In the case of the tourist we have:
σ 2 = 1
10(40 −58)2 + 3
10(60 −58)2 + 2
10(80 −58)2 + 4
10(50 −58)2 = 156.
(1.23)

20
1
Twentieth-Century Quantum Mechanics
Therefore σ =
√
156 = 12.49. σ is a measure of the spread; if the prices had been
59, 60, 61, 62, we would have σ = 1.044. If the N probabilities P(Si) are equal,
their value should be 1
N , and formulas (1.20), (1.22) become:
f = 1
N
N

i=1
fi,
(1.24)
σ 2 = 1
N
N

i=1
( fi −f )2.
(1.25)
1.2.2
Statistical Mechanics
We will see that probability distributions in phase space, of coordinates and momenta,
enable us to compute average values of physical quantities of systems with many
degrees of freedom, avoiding the difﬁculties inherent in an (impossible) detailed
microscopic description. Let us begin with a very simple and elementary example:
a gas composed of a very large number, N, of molecules, each of mass m, contained
in a box. David Bernoulli (1738), and later Newton, proposed that the pressure of
the gas on the walls of the box is due to the impact of the particles colliding with
the walls. In order to make the calculation as simple as possible, we assume that
the box is a cube of side a, and that the total volume occupied by the molecules
themselves is negligible compared to the volume of the container, V = a3. Assume,
in addition, that the collisions with the walls are perfectly elastic, with every particle
bouncing back and forth between the two faces orthogonal to the x axis. If vx is
the component of a particle’s velocity before the collision, it will be changed to
−vx after the collision, as shown in Fig.1.19. The momentum communicated to one
face equals 2mvx, and the time interval between successive impacts is 2a/vx. From
classical mechanics, the force F acting on the wall equals the change in momentum
2mvx divided by the time interval, so that
F = 2mvx
2a/vx
= mv2
x
a .
(1.26)
Then the increment of pressure (force per unit area) p exerted by the particle is
p = F
a2 = mv2
x
a3 ,
(1.27)
since the area of one face is a2.
In order to ﬁnd the total pressure exerted by all the molecules, we must take the
sum of (1.26) over all the contributions of the individual molecules. Since the values
of vx differ from one molecule to another, it is hopeless to perform the sum with all

1.2 Probability and Statistical Mechanics
21
Fig. 1.19 Elastic collision
of a particle with a wall: the
components of the incoming
velocity v are (vx, vy), while
the components of the
outgoing velocity v′ are
(−vx, vy)
the exact details. However, we can use the deﬁnition (1.20) of average, where now
the subset Si is the ith molecule, and the function f is v2
x. We have:
v2x = 1
N
N

i=1
v2
x(i),
thus
N

i=1
v2
x(i) = Nv2x.
(1.28)
Suppose now that there is exactly one mole of gas in the container, so that the total
number of molecules equals Avogadro’s number NA ≈6.02 × 1023; for example,
if the gas is hydrogen, this corresponds to 1g of gas in the container. The overall
pressure P exerted by the gas will then be:
P = NAm v2x
a3 = NAm v2x
V .
(1.29)
By extension of the Pythagorean theorem to three dimensions (see Fig.1.20), we
have v2 = v2
x + v2
y + v2
z. Ignoring the negligible effect due to gravity, the average
values of v2
x, v2
y, v2
z are equal. Therefore:

22
1
Twentieth-Century Quantum Mechanics
Fig. 1.20 The square of the
diagonal of a rectangular
parallelepiped is the sum of
the squares of the three sides.
Thus the total velocity and
its components are related by
v2 = v2
x + v2
y + v2
z
v2 = 3 v2x,
(1.30)
and (1.29) becomes:
PV = 1
3 NAmv2.
(1.31)
Experimentally, gases under normal conditions are known to obey the ideal gas law,
to a good approximation. Then, for one mole of gas (V ≈22.4 dm3) we have:
PV = RT
(1.32)
where R isthegasconstantand T istheabsolutetemperature.Boltzmann’sconstantis
given by kB = R/NA = 1.38065 × 10−23J K−1. From Eqs. (1.31), (1.32) we obtain:
1
2mv2 = 3
2kBT.
(1.33)
Thus the average kinetic energy of a gas molecule is proportional to the absolute
temperature, a simple yet profound relation between a microscopic quantity—the
average kinetic energy of a system of particles—and a macroscopic thermodynamic
variable—the absolute temperature.
The gas law (1.32) determines the average value of the square of the velocity of the
molecules, but contains no information about the detailed distribution of velocities.
How many molecules have more than twice the average speed? or more than three
times the average speed? Before trying to answer these questions, there is another
one, concerning not the velocities, but the positions of the molecules. This can be
approached by applying some results from combinatorial analysis.

1.2 Probability and Statistical Mechanics
23
1.2.3
Combinatorial Analysis
If we conceptually divide the air of a closed room into many “compartments,” each of
dimension 1 cubic centimeter, why do all the compartments contain approximately
the same number of molecules? Or, in other words, why is the density of the air
practically constant? We all breathe calmly, without worrying that suddenly a vacuum
pocketwillformaroundourheads!Whywillthisneverhappen,despitethedisordered
motion of molecules moving in all directions? Returning to our considerations of
balls in urns, suppose we have two identical compartments, which we call L and R,
respectively. Suppose we have a small number of balls, say, 4 balls, and we begin
putting the balls into the two compartments. For the ﬁrst ball we have just two
possibilities: L or R. For simplicity we assume that L and R are equally likely; the
relative probabilities of the two choices are equal. For the second ball we have again
two possibilities, therefore we can represent the possible choices in the upper part
of a graph (see Fig.1.21), containing two bifurcations, and four possible oblique
segments: LL, LR, RL, RR. For example, LL denotes the ﬁrst and second ball in
the L compartment, LR denotes the ﬁrst ball in the left compartment, second ball in
the right compartment, etc. Since the third ball has again two possibilities, the ﬁrst
three rows of the graph contain the following eight ways each constituted by two
segments: LLL, LLR, LRL, LRR, RLL, RLR, RRL, RRR. For example, LRR
denotes the ﬁrst ball in the left compartment, the second and the third ball in the
right compartment, etc. Finally adding the fourth ball gives 16 possibilities, which
we order in the following way (see Fig.1.21):
(A) all the balls are in L: LLLL.
(B) 3 balls are in L and 1 in R: RLLL, LRLL, LLRL, LLLR.
(C) 2 balls are in L and 2 in R: LLRR, LRLR, LRRL, RLLR, RLRL, RRLL.
(D) 1 ball is in L and 3 in R: LRRR, RLRR, RRLR, RRRL.
(E) All the balls are in R: RRRR.
In combinatorial analysis, we often encounter the symbol n!, called n factorial,
equal to the product of all positive integers less than or equal to n. For example,
Fig. 1.21 Sixteen possible paths that start from an initial choice (L or R) and fall along the graph,
giving rise to sixteen possible composite possibilities: LLLL, LLLR, etc

24
1
Twentieth-Century Quantum Mechanics
5! = 5 × 4 × 3 × 2 × 1 = 120. By deﬁnition, 0! = 1! = 1. The number of ways of
choosing k objects from a set of n objects equals
n!
k!(n−k)!, the binomial coefﬁcient
denoted by
n
k

. Thus, in the above example, the number of ways of distributing 4 balls
into 2 compartments are given by: (A)
4
4

= 1, (B)
4
3

= 4, (C)
4
2

= 6, (D)
4
1

= 4, (E)
4
0

= 1. The total number of possibilities equals 1 + 4 + 6 + 4 + 1 = 16 = 24. Now
to return to the problem of the distribution of molecules in the air of a tightly closed
room. If we mentally divide the room into two equal parts, L and R, we can repeat the
same line of reasoning as before, the only difference being that in place of balls now
we have molecules, and the number of “compartments,” possible partitions of space,
is huge. The factorial n! increases very steeply, much more rapidly than exponentially.
For example 20! = 2 432 902 008 176 640 000. Since the number of molecules in a
room is usually much larger than Avogadro’s number, the factorials involved become
exceedingly huge numbers, and a new domain of behavior comes into play. From a
practical point of view, it can be decreed that microscopic conﬁgurations that are very
unlikely become impossible, and the most probable conﬁguration become certain. In
philosophical terminology, this is sometimes referred to as moral certainty.
In the example of the balls in four compartments, the probability of the partition
with equal numbers, such as 2 in compartment L and 2in compartment R, is
6
16,
slightly larger than the others. But in the case of molecules, with the room divided
into two equal parts, the conﬁgurations with nearly equal densities of air overwhelm
all the other possibilities. Here a subtle question arises: denoting by NL, NR, the
number of molecules in L and R respectively, and by N the total number of molecules
N = NL + NR, what is the probability that NL−NR
N
> 0.1 or > 0.01? In order to
answer this type of question, we must relate the global behavior of the air to some
propertyofitsindividualmolecules.Thatcanbedonesinceourmodelofthecontainer
of air is based on an independent particle model. It is a generally true in physics
that problems in which particles behave independently are relatively easy to solve,
but become very difﬁcult when interactions between the particles have to be taken
into account. Let us again return to the colored balls; the combinatorial calculus is
obviously the same as with molecules. We introduce a “small” random variable xi,
with the values xi = 1 if the ith ball is in the L box, and xi = 0 if it is in the R box.
Clearly the “global” random variable
X =
N

k=1
xk,
(1.34)
is equal to the ﬁnal number of balls in the L compartment. Since we have assumed
that the choices L and R are equally likely, the average xk = 1+0
2
= 1
2 and from
(1.34) we have:
X =
N

k=1
1
2 = N
2 .
(1.35)

1.2 Probability and Statistical Mechanics
25
Fig. 1.22 Graph obtained by plotting ﬁve rectangles of height
4
4

= 1,
4
3

=4,
4
2

= 6,
4
1

= 4,
4
0

= 1, respectively. The graph approaches a Gaussian or normal distribution (bell curve) as the
number of rectangles is increased
As a check, let us compute X for N = 4, using the partitions A, B, C, D, E. We have:
X = 4P(A) + 3P(B) + 2P(C) + 1P(D) + 0 P(E) =
4 × 1
16 + 3 × 4
16 + 2 × 6
16 + 1 × 4
16 + 0 × 1
16 = 2.
(1.36)
A graph of the ﬁve probabilities P(A), P(B), . . . , P(E) is shown in Fig.1.22. It
closely resembles the famous “bell curve” or normal distribution, which is supposed
to model the distribution of IQs and other characteristics of a human population.
The standard deviation σ measures the half-width of the curve. Using the deﬁnition
Eq. (1.22), we have:
σ 2 = 22P(A) + 12P(B) + 02P(C) + 12P(D) + 22P(E) =
4 × 1
16 + 1 × 4
16 + 1 × 4
16 + 4 × 1
16 = 1.
(1.37)
However 4 balls (or 4 molecules) and 24 = 16 possible cases are too few to
draw any general conclusion. Let us consider the general case of N balls and 2N
possibilities. Equation (1.35) tells us that in the L half of a room the average number
of molecules is exactly half of the total, which is quite reasonable. How about the
standard deviation? From (1.22) we have:

26
1
Twentieth-Century Quantum Mechanics
σ 2 =
	
X −
N

k=1
xk

2
=
	 N

k=1
xk −
N

k=1
1
2

2
=
	 N

k=1

xk −1
2

2
=
N

k=1

xk −1
2

N

j=1

x j −1
2

.
(1.38)
The double sum N
k=1
N
j=1 can be split into two terms: the ﬁrst with k ̸= j and
the second with k = j:
σ 2 =
N

k̸= j

xk −1
2
 
x j −1
2

+
N

k=1

xk −1
2
2
.
(1.39)
It is easy to check that the ﬁrst term vanishes. Write the 4 contributions to the sum
of a given pair k, j:
xk = 1, x j = 1:
(xk −1
2)(x j −1
2) = 1
4,
xk = 1, x j = 0:
(xk −1
2)(x j −1
2) = −1
4,
xk = 0, x j = 1:
(xk −1
2)(x j −1
2) = −1
4,
xk = 0, x j = 0:
(xk −1
2)(x j −1
2) = 1
4.
Since 1
4 −1
4 −1
4 + 1
4 = 0, we are left with:
σ 2 =
N

k=1

xk −1
2
2
=
N

k=1

x2
k −xk + 1
4

=
N

k=1
1
4 = N
4 .
(1.40)
(We have used the equality x2
k −xk = 0, which holds for xk = 1 or xk = 0). If we
set N = 4, we ﬁnd σ 2 = 1, in agreement with (1.37). Furthermore
σ = 1
2
√
N
(1.41)
and
σ
X
=
1
2
√
N
N/2 =
1
√
N
.
(1.42)
The expression σ/X is sometimes called the relative ﬂuctuation. Formula (1.42) is of
extraordinary importance for our understanding of the Universe, and even inﬂuences
our daily lives.
Look again at Fig.1.22. If we draw analogous graphs for increasingly larger N,
the probability peak around the average value N/2 becomes ever more narrow, since
the limit of
1
√
N for N →∞vanishes. Coming back to the problem of the ﬂuctuations
of the air in the L half of a room, we can take, for example, N = 1026, so the ratio
(1.42) becomes 10−13. This means that the density ﬂuctuations of the air, due to

1.2 Probability and Statistical Mechanics
27
statistical factors alone, are vanishingly small. Thus the reader can breathe a sigh of
relief and continue to breathe easily, without fearing that vacuum pockets (or even
a signiﬁcant variation in the air density) are suddenly going to form in front of his
mouth!
1.2.4
Gaussian Integrals
We digress brieﬂy to consider the evaluation of integrals containing Gaussian func-
tions. We need these now in order to treat the distribution of molecular velocities;
later they will occur in consideration of the quantum mechanical harmonic oscillator.
The indeﬁnite integral

e−x2dx (or antiderivative of the function e−x2) cannot be
expressed in terms of elementary functions. (One can, however, deﬁne the related
error function by erf(x) =
2
√π
 x
0 e−t2dt.) It turns out, however, that certain deﬁnite
integrals with inﬁnite limits can be evaluated without knowing the corresponding
indeﬁnite integrals. Consider ﬁrst the deﬁnite integral
I =
 +∞
−∞
e−x2dx.
(1.43)
The square of this integral is given by
I 2 =
 +∞
−∞
e−x2dx
2
=
 +∞
−∞
e−x2dx
  +∞
−∞
e−y2dy

=
 +∞
−∞
 +∞
−∞
e−(x2+y2)dx dy.
(1.44)
Note that, in writing the square, that the second factor must be written with a different
dummy variable, y. The last double integral can be interpreted as an integration
over the entire xy-plane (−∞≤x, y ≤+∞) of the function e−(x2+y2), expressed in
Cartesian coordinates. The trick now is to transform to polar coordinates, with x =
r cos φ, y = r sin φ and r2 = x2 + y2. The element of area transforms from dx dy
to r dr dφ with the variable ranges 0 ≤r ≤∞, 0 ≤φ ≤2π. Since the integrand is
now independent of φ, we can integrate immediately to get a factor 2π, so that Eq.
(1.46) reduces to
I 2 = 2π
 ∞
0
e−r2r dr.
(1.45)
We note now that the indeﬁnite integral of the above, with the added factor r, can be
evaluated. With a change of variable u = r2, du = 2r dr, we ﬁnd
2

e−r2r dr =

e−udu = −e−u
(1.46)

28
1
Twentieth-Century Quantum Mechanics
and the corresponding deﬁnite integral with, 0 ≤u ≤∞, equals e−∞−(−e0) = 1.
Thus I 2 = π, and we obtain ﬁnally
I =
 +∞
−∞
e−x2dx = √π.
(1.47)
This remarkable (and totally amazing) result was evidently ﬁrst derived by Euler in
1729.
In applications, we often need the following slightly generalized Gaussian inte-
gral:
Iα =
 +∞
−∞
e−αx2dx
(1.48)
with α > 0. This integral can be reduced to the case with α = 1 making a change of
variables to t = √αx, dx =
1
√αdt. Then we have:
Iα =
 +∞
−∞
e−αx2dx =
π
a .
(1.49)
Another generalization of Gaussian integrals, which we will encounter, are the forms
 +∞
−∞
xn e−αx2,
n = 2, 4, . . .
(1.50)
Note that when n is odd, the integral equals zero, since the integrand is an odd func-
tion. The trick involves differentiation of the integral with respect to the parameter
α. For example,
∂
∂α
 +∞
−∞
e−αx2dx =
 +∞
−∞
(−x2)e−αx2dx = ∂
∂α
π
α

.
(1.51)
This works out to
 +∞
−∞
x2e−αx2dx = π1/2
2α3/2 .
(1.52)
Differentiating once more with respect to α gives
 +∞
−∞
x4e−αx2dx = 3π1/2
4α5/2 .
(1.53)
This trick was famously exploited by Feynman, in deriving a number of useful
results in quantum electrodynamics. However, the maneuver can actually traced
back to Leibniz. It is rigorously valid, provided that the integrand and its x- and
α-derivatives are continuous in the domain of integration.

1.2 Probability and Statistical Mechanics
29
1.2.5
Maxwell–Boltzmann Distribution
Having settled the questions about the average positions of the molecules, we turn to
the distribution of velocities. This problem is more difﬁcult, since, while it is true that
the positions of a molecule are equally probable, the velocities are not. As before, we
denote by m the mass of a molecule, and by v its velocity. Since the kinetic energy
is E = 1
2mv2, it will be sufﬁcient to ﬁnd the distribution of energies ρ(E). This is
actually a reduced distribution in phase space, having implicitly integrated over all
dynamical variables other than molecular translational kinetic energy. Let us consider
one molecule of an ideal gas, and denote by ρ1(E)dE the probability that the energy
of the molecule is in the interval E to E + dE. Since the total probability is 1, we
must have
 ∞
0 ρ1(E)dE = 1. Consider now two molecules, with the energy of the
ﬁrst molecule lying in the inﬁnitesimal interval E1 to E1 + dE1, and the energy of
the second in the interval E2 to E2 + dE2. The joint probability is then given by:
p(A

B) = p(A)p(B) = ρ1(E1)ρ1(E2)dE1dE2.
(1.54)
This result can be obviously generalized for the probability distribution of N mole-
cules:
ρ(E1, E2, ...EN) = ρ1(E1)ρ1(E2) . . . ρ1(EN).
(1.55)
Let us assume that the total energy
E1 + E2 + . . . + EN = E,
(1.56)
is constant, meaning that the air in the room is effectively a closed system.
Taking the logarithm of (1.55) we ﬁnd:
log ρ = log ρ1(E1) + log ρ1(E2) + log ρ1(E3) + . . . + log ρ1(EN).
(1.57)
The logarithm of the probability distribution is an additive function, as are the mass,
the number of molecules, and the energy. This suggests that log ρ is a linear function
of the energy, such that:
log ρ1(Ei) = α −βEi,
for i = 1, 2, . . . , N,
(1.58)
with a minus sign in front of βEi, since for large Ei the probability should approach
zero. From (1.58) it follows that:
ρ1(Ei) = A e−βEi ,
(1.59)
where A and β are appropriate constants. Taking the sum over i of (1.58), we get:
log ρ =
N

i=1
log ρ1(Ei) = αN −βE,
(1.60)

30
1
Twentieth-Century Quantum Mechanics
where E is the total energy. It follows that:
ρ(E) = Z−1e−βE,
(1.61)
where Z−1 is the conventional notation for another constant. This is called the Boltz-
mann distribution Boltzman (2005), which is of central signiﬁcance in the physics
of thermal phenomena and in astrophysics. Since the total probability must be equal
to 1, from Eq. (1.59) we must have:

ρ(E)d3v = A

e−βm(v2
x+v2
y+v2
z )/2d3v = 1.
(1.62)
The symbol d3v denotes that the integration is extended to the whole three-
dimensional space of velocities: d3v = dvx dvy dvz. Thus Eq. (1.62) reduces to
A times the product of three identical Gaussian integrals:
A
 +∞
−∞
e−βmv2
x/2 dvx
 +∞
−∞
e−βmv2
y/2 dvy
 +∞
−∞
e−βmv2
z /2 dvz =
A
 +∞
−∞
e−βmv2/2 dv
3
= 1.
(1.63)
The integrals in Eq. (1.63) are of the form of Eq. (1.48). The three integrals in Eq.
(1.63) are equal, so that we can write:
A
 +∞
−∞
e−βmv2/2dv
3
= A
 2π
mβ
3/2
= 1.
(1.64)
Thus, the constant A, normalizing the distribution, is determined:
A =
mβ
2π
3/2
.
(1.65)
We are now able to compute the average value E of the kinetic energy E = 1
2m(v2
x +
v2
y + v2
z) of a single molecule. We ﬁnd:
E = A
 1
2m(v2
x + v2
y + v2
z)e−βm(v2
x+v2
y+v2
z )/2d3v
(1.66)
The triple integral can be evaluated by transforming from Cartesian to spherical polar
coordinates in velocity space (v, θ, φ), such that
d3v = dvx dvy dvz →v2 sin θdv dθ dφ,
(1.67)

1.2 Probability and Statistical Mechanics
31
where v represents the magnitude of the velocity vector (the speed), with v2 =
v2
x + v2
y + v2
z, while θ, φ specify the direction in three-dimensional space. Since the
integrand is independent of the angles, integration over θ and φ gives a factor 4π,
so that Eq. (1.66) reduces to
E = A
 ∞
0
1
2mv2e−βmv2/24πv2dv = 3
2β .
(1.68)
Comparing this result to E = 3
2kBT (Eq.1.33), we ﬁnd β =
1
kBT . Substituting from
(1.65) for A, we arrive at the famous Maxwell–Boltzmann distribution of molecular
velocities:
f (v) = 4π

m
2πkBT
3/2
v2e−mv2/2kBT
(1.69)
A plot of the distribution f (v) is shown in Fig.1.23. It has the form of a skewed
Gaussian function, with f (0) = 0. The half-width of the curve is w =

2kBT
m , not
very different from u =

v2. In fact, u = 1.225 w. Using (1.69) we can compute
how many molecules have velocities belonging to a given interval. For example, for
a sample of one billion molecules, there are:
427 million with velocity 0 < v < w,
526 million with velocity w < v < 2w,
45 million with velocity 2w < v < 3w,
0.4 million with velocity 3w < v < 4w, etc.
The purpose of this section was to review some basic concepts of statistical
mechanics and probability theory because, as we will see, the results of quan-
tum mechanics are of a fundamentally probabilistic character. Statistical mechanics
allows us to understand the microscopic causation underlying the behavior of macro-
scopic systems. These causes are so hidden from our senses that it was necessary
for the genius of Maxwell, Boltzmann, Gibbs, and others to discover and describe
the microscopic world of molecular motion. We understand now how some common
Fig. 1.23 Plot of
Maxwell–Boltzmann
distribution of velocities
f (v) at two temperatures,
with T2 > T1

32
1
Twentieth-Century Quantum Mechanics
experimental facts, for example, that heat always ﬂows spontaneously from hotter
to colder bodies, or that air escapes from a puncture in a high-pressure tire, are sim-
ply probabilistic events that effectively become certainties because of the statistical
behavior of enormously large numbers of molecules. It is deﬁnitely true that macro-
scopic systems exhibit a sort of classical “hidden variable” behavior. We will see
that, in quantum mechanics, the probabilistic character is inherent in the fundamen-
tal structure of the theory, as conﬁrmed by a very large number of experimental results
(Bell’s theorem, etc.). Up to now nobody has been able to deﬁnitively observe any
“hidden variables” which might make QM a deterministic theory, reducible merely
to statistical behavior analogous to classical systems. It is the present consensus
that quantum mechanical hidden variables do not exist, although the foundations of
quantum mechanics still involve some very profound and controversial questions of
a metaphysical nature.
1.3
The Birth of Quantum Mechanics
The celebrated experiments by Young and Fresnel and the marvelous theoretical syn-
thesis of Maxwell demonstrated the fundamental nature of light as an electromagnetic
wave propagating through space. Schrödinger (1926), inspired by de Broglie’s ideas,
wrote an equation for the “matter waves” accompanying the motion of electrons.
This was, in concept, analogous to Maxwell’s equations for light waves (although
Maxwell’s equations are relativistically invariant, while Schrödinger’s original equa-
tion was nonrelativistic, but this is not relevant for our purposes). Successful appli-
cations of the Schrödinger equation came soon afterward. It became possible to
describe both the motion of free electrons (such as those considered by de Broglie)
and electrons bound in matter. Schrödinger demonstrated that in analogy with the
way that a violin string or a drumhead vibrates, with a set of discrete frequencies,
so too must the energy levels of electrons in atoms exhibit discrete values. This was
already known from the old Bohr theory, but Schrödinger arrived at these results by
a much more rational approach, rather than by ad hoc assumptions. Schrödinger’s
theory can be applied, in principle, to a much larger class of problems, including
atomic and molecular structure, solid-state physics and the molecular biology of
life processes. The only limitations are difﬁculties in carrying out very lengthy and
laborious computations. Quoting Dirac3:
The fundamental laws necessary for the mathematical treatment of a large part of physics
and the whole of chemistry are thus completely known, and the difﬁculty lies only in the
fact that application of these laws leads to equations that are too complex to be solved.
From the very beginnings of QM (originally called wave mechanics), the physical
interpretation of the waves associated with the motion of electrons was controver-
sial, even though the spatial conformation and temporal evolution of these waves
3Dirac PAM (1929) Proc Roy Soc A (London) 123, 714–733.

1.3 The Birth of Quantum Mechanics
33
are unambiguously determined by the Schrödinger equation. In the case of light, the
physical quantities that vibrate and propagate in space are clearly the electric and
magnetic ﬁelds, but it was not as easy to answer the question “what is vibrating?”
in the case of waves that accompany the motion of an electron. At ﬁrst, Schrödinger
thought it was a charge density distributed in space, but soon it became clear that
this interpretation was ﬂawed. Since this is a crucial point in our development, let us
brieﬂy describe a beautiful experiment of electron interference that has been carried
out with a modern electronic microscope. In this apparatus, electric and magnetic
ﬁelds deﬂect the trajectories of beams of electrons, analogous to the way that optical
lenses control the trajectories of light rays. It is then possible to observe interference
on a photographic plate between two electron beams emitted from the same source,
but which have followed different trajectories; we can observe typical interference
patterns (see Fig.1.24), taken from Merli et al. (1976)4 there are fringes which are
more intense, where a larger number of electrons has hit the plate, and darker where
fewer electrons struck. This behavior contradicts Schrödinger’s primitive interpreta-
tion, that the electron instead of being localized at one point, is “spread out”, giving a
cloud of charge distributed in a region of space, similar to an electromagnetic wave.
In fact, with an electron beam of very low intensity, we can observe the arrival of
individual electrons as pointlike ﬂashes of light. With a low-intensity exposure over
a long period of time, the electrons randomly fall here and there, but in the end, they
accumulate in interference fringe patterns, analogous to those in Young’s experiment
with light waves. The sequence of pictures in Fig.1.24 shows how the image is built
up from ﬂashes of individual electrons. In some places on the photographic plate, the
probability of an electron striking is larger, in other places it is smaller. Like the bullet
marks in target practice, in which, by increasing the number of shots, hits become
more numerous near the bull’s eye, so too do the electrons create fringe patterns.
Now in the case of target practice, the difference of the various bullet marks can be
explained by small variations in the initial conditions, such as minute differences
in the marksman’s steady hand, while nothing of this sort can be identiﬁed in the
case of electrons. In fact the “electronic probability clouds” around the nucleus are
identical for all hydrogen atoms (even those in the stars!).
Richard Feynman described two-slit-diffraction experiments, for both electrons
and photons, as “the experiment with the two holes.” He considered this to be the
“central mystery of quantum mechanics.”5 See Fig.1.25 for a cartoon capturing the
conceptual problem. In the words of Yogi Berra (an American baseball player known
for witty quips), “When you come to a fork in the road, take it!”
At this point, we state the celebrated Born interpretation of the wavefunction,
which can be considered one of the fundamental postulates of QM: the waves rep-
resenting solutions of the Schrödinger equation do not describe electronic charge
density, but are rather probability waves of electron distribution. More precisely, the
wave function is a pre-probability or probability amplitude since we must square its
4In2002,PhysicsWorldvotedthisdouble-slitexperimentwithsingleelectronsas“themostbeautiful
experiment in physics” of all time.
5Feynman RP (1965) The Character of Physical Law, BBC Publications, London.

34
1
Twentieth-Century Quantum Mechanics
Fig. 1.24 The experiment of Merli, et al. Electron interference fringe patterns displayed on a TV
monitor with increasing current densities. Reproduced from American Journal of Physics 44, 306-
307 (1976), Fig.1.1, with permission of the American Association of Physics Teachers. Enhanced
photograph courtesy of Prof. Giulio Pozzi
absolute value to obtain an observable probability density. In the microscopic world,
we cannot imagine particles in the same way as we usually picture macroscopic
objects in everyday life. Instead, we must picture probability clouds that move and
ﬂuctuate in space; where the cloud is more “dense” it is more likely to observe
the particle. Outside of the cloud, no particle will be found. A small, dense cloud
corresponds to a well-localized particle, while a more diffuse cloud distributed over
a larger region of space corresponds to a delocalized particle. As a very important
consequence: before actually carrying out a measurement of a particle’s position, the
question “where is the particle located?” is meaningless.

1.3 The Birth of Quantum Mechanics
35
Fig. 1.25 Cartoon parodying the counterintuitive nature of quantum mechanics. Drawn by Lorenzo
Felice. Inspired by the famous cartoon of Charles Addams on the cover of Aharonov Y, Rohrlich
D (2005) Quantum Paradoxes: Quantum Theory for the Perplexed, Wiley, New York
The term “wave mechanics” was suggested by the oscillation and propagation of
“probability clouds,” closely resembling the behavior of classical wave propagation.
However, we are faced with a completely different situation, which becomes para-
doxical if we insist on maintaining the classical concepts of position and velocity.
In fact, from de Broglie’s relation λ =
h
mv, which was, in fact, the inspiration for
the Schrödinger equation, it follows that if the velocity v is small, the wavelength of
the “cloud” becomes large, and therefore the electron cannot be localized in a small
region of space. Conversely, if the particle is well localized, its “average wavelength”
must also be small, and therefore the possible values of its velocity (or momentum)
arebroadlyspread.ThisisoneaspectofthefamousHeisenberguncertaintyprinciple:
it is not possible to simultaneously measure the exact position and exact momen-
tum of a particle. In some books on QM the uncertainty principle is explained by
emphasizing the “perturbation” of the observed object by the measuring instrument.
This statement contains some grain of truth but it is somewhat misleading. Often we
read that “if we measure the position of a particle with great accuracy, we perturb it
in such a way that the momentum becomes highly uncertain, and, conversely, if we
try to accurately measure its momentum, the position becomes uncertain.” But, in
our view, we must imagine the particle, not as a mass point, but as a nebulous cloud.
Then, we have clouds (which resemble the waves created on the surface of a lake by
a falling stone) in which the wavelength (related to momentum) is well deﬁned, but

36
1
Twentieth-Century Quantum Mechanics
the position is diffuse. Where is the perturbation of a measurement apparatus now? A
more logical analysis is the impossibility for the cloud to assume the two contrasting
shapes at the same time. It must either be delocalized like a wave or localized like a
particle. A “perturbation” is nothing more than an attempt to prepare the cloud in one
such form and show that it can no longer be described in terms of the other. These
concepts should become clearer in the following pages, where we will show how
Hilbert space provides a coherent description of the fundamental state of a quantum
system.
1.3.1
Hilbert Space
During the years of the “Cambrian explosion” of QM, physicists (notably Dirac
and Wigner) and mathematicians (von Neumann, Weyl) recognized that there was a
particular mathematical structure that could provide a logical basis of the new theory.
It will turn out that this new formalism is as fundamental for the new mechanics as the
concepts of differential calculus were for Newtonian mechanics. As ﬁrst emphasized
by von Neumann (1932), this mathematical structure features vectors in a Hilbert
space H, and linear operators acting on these vectors. In our development of QM
in Hilbert space, we will proceed by small, intuitively accessible steps. The strictly
axiomatic method, in which theorems (and their applications) are developed from a
set of axioms, is more difﬁcult for nonspecialists to follow.
To each “probability wave,” physicists associate a detailed “condition” or state
for the system in question. This holds true both for a single particle and for a system
of many particles. This is analogous to the classical case, which we described above,
in which the state of the system is represented by a point in the appropriate phase
space. As it turns out, the quantum mechanical description of a physical system is
considerably more complicated than the classical description, essentially because it is
necessary to describe with accuracy the shape of a cloud rather than the position and
velocity of a pointlike particle. But, apart from this complication, Hilbert space is for
the quantum description quite analogous to phase space for the classical description.
To begin:
Postulate: Any state of a quantum system corresponds to a point in an abstract multidimen-
sional (usually inﬁnite-dimensional) Hilbert space.
Therefore, any possible probability cloud is represented by a corresponding point in
Hilbert space. When the cloud undergoes some change, the point will correspond-
ingly move along some trajectory in Hilbert space. The following paragraphs will
introduce a more pictorial description of a Hilbert space. We might, of course, give the
mathematical deﬁnition right away: “a Hilbert space is a real or complex abstract vec-
tor space endowed with an inner product.” But this sort of deﬁnition would be readily
understood only by those who are already familiar with higher algebra. Instead, we
will develop, in a concrete physical application, a highly simpliﬁed version, in which
the Hilbert space is reduced to a simple Cartesian plane with two coordinates x, y. We

1.3 The Birth of Quantum Mechanics
37
Fig. 1.26 Correspondence
between points P of the
plane and vectors O P from
the origin
Φ
Ψ
Ψ Φ
+
O
P
x
y
will call this a “toy Hilbert space.” This can be classiﬁed as a vector space, since we
can associate every point P in this plane with a vector O P, from the origin to a point
in P, as shown in Fig.1.26. The two coordinates of P are called the components of
O P. Figure1.26 shows two vectors −→
Ψ , −→
Φ in the plane. Vectors in Hilbert space can
be manipulated in much of the same way as the more familiar vectors in Euclidean
space. For example, a vector sum could be constructed using the parallelogram rule,
as shown in Fig.1.26.
We describe, as a highly simpliﬁed example, the “probability waves” or “clouds”
associated with an electron in the vicinity of two protons, localized at points A
and B. These are actually the ingredients of the hydrogen molecular ion, H+
2 . We
consider two hypothetical states: ΨA, in which the electron is localized around proton
A and ΨB, in which it is localized around proton B. These two states are sketched in
Fig.1.27. Now let us propose a correspondence between the wave ΨA and a vector
with coordinates (1, 0) in our toy Hilbert space (the Cartesian plane). Similarly, let
the wave ΨB correspond to the vector (0, 1), as shown in Fig.1.28. Since there is
a unique correspondence between probability waves and points (or vectors) in our
Hilbert space, we will denote the vector (1, 0) by −→
ΨA, and the vector (0, 1) by −→
ΨB.
Thus we have now created a unique representation of probability clouds Ψ as vectors
in Hilbert space.6
Now let us introduce a new set of points S in the Cartesian plane that lie on
the circumference of a circle of radius 1, about the origin (see Fig.1.29). These
points have coordinates (cos θ, sin θ), where θ is the angle between the vector OS
and the x-axis. When we vary θ the point S revolves around the circumference,
since cos2 θ + sin2 θ = 1. The point S represents a “mixed” wave, obtained by
interference (or better, superposition) of wave ΨA with wave ΨB. Correspondingly,
6To be technically correct, the negative of a vector, say −−→
ΨA, represents the same state as −→
ΨA,
differing only by a phase factor (−1) of magnitude 1. Only when there is interference between two
waves does their phase difference becomes signiﬁcant, as in the superpositions Ψ+ and Ψ−.

38
1
Twentieth-Century Quantum Mechanics
Fig. 1.27 “Probability waves” ΨA and ΨB associated with an electron localized around protons A
and B, respectively
Fig. 1.28 The vectors (1, 0)
and (0, 1) in Hilbert space,
representing the quantum
states ΨA and ΨB,
respectively
−→
OS = cos θ −→
ΨA + sin θ −→
ΨB. The physical situation corresponds to a wave which is
delocalized: not concentrated, either around center A or around center B, but rather
diffusely distributed around both centers. Two particular examples of superpositions
are the normalized vectors Ψ+ =
1
√
2(ΨA + ΨB) and Ψ−=
1
√
2(ΨA −ΨB). The prob-
ability waves for these states are sketched in Figs.1.30 and 1.31, respectively. Note
that Ψ−has regions where the wave amplitude is positive, indicated by plus signs (+),
and regions of negative amplitude, indicated by minus signs (−), so that phase fac-
tors are evidently important here. The superposition Ψ+, called the bonding orbital,
is a simple approximation to the ground electronic state of H+
2 , while Ψ−, the anti-

1.3 The Birth of Quantum Mechanics
39
Fig. 1.29 The wave represented by the vector OS′ or OS′′ is the superposition of the waves ΨA
and ΨB, with PA = P(A), PB = P(B). Left the vector OS′ for PA > PB. Right OS′′ for PB > PA
Fig. 1.30 Probability wave
obtained by “constructive
interference” in
superposition of ΨA and ΨB,
The factor 1/
√
2 gives a
normalized function Ψ+
bonding orbital, is a repulsive state, in which no stable molecule is formed. Looking
again at Fig.1.29, we note that OS′ and OS′′ are the orthogonal projections of point
S onto the x, y axes, respectively. Therefore the lengths of OS′ and OS′′, denoted
|OS′| and |OS′′|, respectively, are the coordinates of S. This leads to a fundamental
interpretative postulate of QM, in terms of our toy Hilbert space:
Postulate: Any point S on the circumference of radius 1 corresponds to a possible state of the
electron. The square of the length, |OS′|2, is equal to the probability P(A) that the electron
is localized around A, while |OS′′|2 is equal to the probability P(B) that the electron is
localized around B.

40
1
Twentieth-Century Quantum Mechanics
Fig. 1.31 Probability wave obtained by “destructive interference” of ΨA and ΨB
At this point some readers will perhaps experience a feeling of puzzlement or
disorientation and might ask: “But what is this circle, what are these vectors, that
have suddenly shown up?” The following discussion might make the geometrical
Fig. 1.32 Geometric construction to show conservation of probability

1.3 The Birth of Quantum Mechanics
41
construction in Fig.1.32 appear more plausible, in particular, the representation of
“clouds” by vectors. This will be discussed further in Chap.5. However, such expla-
nations cannot go beyond a certain limit of plausibility; any mathematical postulate,
any recipe, even if it conﬂicts with everyday intuition, can be accepted by physicists
if it is part of a consistent formalism and if it explains a large number of experimental
facts. Let us show that our postulate is consistent with the property that the sum of
all the probabilities adds up to 1. Indeed, by applying the Pythagorean theorem to
the right triangle OSASB of Fig.1.32, we ﬁnd:
|OSA|2 + |OSB|2 = |SASB|2 = |OS|2 = 1,
(1.70)
so that, P(A) + P(B) = 1. In Fig.1.29, a vector to the point S′ on the circumference
indicates that it is likely that the electron would be found closer to atom A, while a
vector to point S′′ indicates that it is likely that the electron is closer to B.
To summarize, the fundamental interpretative postulate of quantum mechanics
implies that the probability in an individual measurement of a physical observable,
such as position, velocity, etc., does not give a predictable result, since QM is inher-
ently of an irreducibly statistical and probabilistic character. The maximal knowledge,
the maximal information, that we can possibly have of a physical system, is repre-
sented by its state vector OS. (Physicists often use the term state to designate vectors
of unit length in Hilbert space.) And this information does not allow us to predict the
actual results of individual microscopic events, but only their probabilities: speciﬁ-
cally, the average number of times these results show up in a statistical analysis of a
large number of repeated measurements on identical systems.
How does the probabilistic nature of QM compare with the situation in classical
statisticalmechanics?Classically,moleculeshaveacertainprobabilityofbeingfound
ingivenregions of space, of movingwithacertainrangeof velocities, etc.; but, at least
in principle, there is correlation between this apparently probabilistic behavior and
the detailed motions of individual molecules. Thus, we have seen that the pressure
of a gas can be calculated from a suitable average over phase space. We actually
know, in principle, “what happens behind the scenes.” For example, pressure is the
result of a large number of collisions of individual molecules with the walls of the
container. By contrast, a detailed understanding of this nature does not exist for
quantum mechanics; there do not appear to be any hidden variables which, once
known, might explain why the electron is found on atom A, rather than on atom B
(as in the above example); or, in the more realistic case of Fig.1.24, why an electron
ends up on a particular interference fringe rather than on another. We will return to
this question later, in much greater detail.
In the following two chapters, we will introduce some advanced mathematical
tools, which will enable a deeper understanding of the structure of QM. We will
continue to exploit our toy Hilbert space and gently transition to the “grown-up”
version of Hilbert space.

Chapter 2
Mathematical Methods in Quantum
Mechanics
Abstract The mathematical methods used in quantum mechanics are developed,
with emphasis on linear algebra and complex variables. Dirac notation for vectors
in Hilbert space is introduced. The representation of coordinates and momenta in
quantum mechanics is analyzed and applied to the Heisenberg uncertainty principle.
Keywords Vectors · Matrices · Hilbert space · Heisenberg uncertainty principle
2.1
Vector Analysis
From a geometric point of view, any point P in the Cartesian x-y plane can be
associated with a vector −→
OP, from the origin O to the point P. The corresponding
algebraic interpretation of a vector is an ordered pair of real numbers (the coordinates
of P). We will write either v = (v1, v2) or −→v = (v1, v2). Both the boldface and the
arrow notation are extensively used in the literature and we will use whichever one
looks better in a formula. The origin O is the vector (0, 0). The space of all these
vectors is denoted by R2. The superscript 2 reminds us that two coordinates are
sufﬁcient to determine v. Once we adopt the convention that all our vectors start
from the origin, the terms vectors and points are equivalent. The generalization from
two to three dimension is straightforward: a vector −→
OP in three-dimensional space is
speciﬁed by three real numbers. The origin O is now (0, 0, 0). This space, containing
all sets of ordered triples of real numbers, is denoted by R3. A vector in 3-space is
shown in Fig.2.1.
Vectors in classical physics are used to represent forces, velocities, etc. What is
the mathematical counterpart of the physical concept of doubling or tripling a force?
It is easy to see that this is equivalent to doubling or tripling the coordinates of
the endpoint P. Therefore 2v has the same direction of v, but is twice as long. Its
coordinates are (2v1, 2v2). More generally, for any real number a, we can deﬁne:
av = (av1, av2).
(2.1)
© Springer International Publishing AG 2017
G. Fano and S.M. Blinder, Twenty-First Century Quantum Mechanics:
Hilbert Space to Quantum Computers, UNITEXT for Physics,
DOI 10.1007/978-3-319-58732-5_2
43

44
2
Mathematical Methods in Quantum Mechanics
x
y
z
O
P
Fig. 2.1 A three-dimensional vector OP
v
v
v
u
u
u
2
1
u + v
O
y
x
u
v
+
u + v
1
2
2
1
1
2
Fig. 2.2 Vectors u = (u1, u2), v = (v1, v2) and their sum, using the parallegram rule
From elementary physics, we know also that forces can be added by means of the
parallelogram rule (see Fig.2.2). Given two vectors u = (u1, u2), v = (v1, v2), what
are the coordinates of the sum u + v? It is easy to see that the following deﬁnition:
u + v = (u1 + u2, v1 + v2),
(2.2)
is in agreement with the parallelogram rule.
We have shown, both from geometric and algebraic points of view, the two fun-
damental operations of the vector space R2: multiplication by a real number, and
summation of two vectors. Following are some properties implied by the fundamen-
tal operations of a real vector space (a, b denote real numbers, while 0 = (0, 0) is
the null vector):

2.1 Vector Analysis
45
u + v = v + u,
(2.3)
u + 0 = u,
(2.4)
a(u + v) = au + av,
(2.5)
(a + b)u = au + bu.
(2.6)
Let us now introduce the very important concept of linear combination of vectors.
Given two vectors u and v and two real numbers a and b the vector
w = au + bv
(2.7)
a u + b v
u
u
a
v
b
v
Fig. 2.3 Linear combinations of the ﬁxed two-dimensional vectors u, v generate the whole plane
R2 by running over all the coefﬁcients a, b
π
x
y
au
u
v
bv
au + bv
O
z
Fig. 2.4 Linear combinations of the three-dimensional vectors u, v generate the plane π, by varying
the coefﬁcients a, b

46
2
Mathematical Methods in Quantum Mechanics
is called a linear combination of u and v, with coefﬁcients a and b. It is evident
that, except for the particular case in which u and v are parallel, two vectors with
varying coefﬁcients a, b can cover the entire plane R2 (see Fig.2.3). Since u and v
generate, with their linear combinations, the entire plane R2, we say that u and v
form a basis in R2. Vectors of the form −→
OS = cos θ u + sin θ v are a particular case
of (2.7), representing vectors of unit length (unit vectors). If the two vectors u, v live
in a space of larger dimension, such as R3 (ordinary 3D physical space), the linear
combination (2.7) still belongs to the plane containing u and v, and the set generated
by u and v is the plane π, shown in Fig.2.4. The construction of Fig.2.3 is still
valid, and the plane π still contains the two basis vectors u and v. Furthermore when
a = b = 0 we get w = (0, 0, 0), the null vector sitting at the origin. Therefore π
must contain the origin O. The plane π is an example of linear subspace of R3 since
it is both a subset of R3 and it is itself a linear space (indeed, if two vectors belong to
π, their sum also belongs to π, etc.). Linear subspaces will play an important role in
QM. The only nontrivial linear subspaces of R2 are straight lines through the origin
O.
We have seen that in the fundamental postulate of QM the distance of a point
S from the origin O (the length of the vector −→
OS) plays an important role. For an
arbitrary vector v = (v1, v2) we know by the Pythagorean theorem that its length
(which we denote by |v| or v) is given by:
v = |v| =

v2
1 + v2
2
(2.8)
If v = (v1, v2, v3) is a vector belonging to the space R3, its length being given by a
simple generalization of Eq.(2.8):
v = |v| =

v2
1 + v2
2 + v2
3
(2.9)
The angle between two vectors is also important. If φ denotes the angle between the
vectors u = (u1, u2) and v = (v1, v2) of the plane, the following relation holds:
u v cos φ = u1v1 + u2v2
(2.10)
In three-dimensional space, a similar formula holds: denoting by u = (u1, u2, u3),
v = (v1, v2, v3) two vectors of R3, and with the same meaning of the angle φ, it is
possible to prove that:
u v cos φ = u1v1 + u2v2 + u3v3
(2.11)
The reader will note that the expressions (2.10), (2.11) are quite similar. Indeed these
expressions are more fundamental than the concept of “angle between two vectors,”
which cannot be visualized in dimension higher then three. These expressions deﬁne
the scalar product u · v of two vectors. Thus in R2 we have u · v = u1v1 + u2v2, in

2.1 Vector Analysis
47
R3 we have u · v = u1v1 + u2v2 + u3v3, etc. When writing the scalar product, the
two vectors u, v can be represented by the symbols ||u1, u2||,


v1
v2

, called a row
vector and a column vector, respectively. When a row vector is placed in front of a
column vector, you can perform vector multiplication using a “row times column”
sum, as follows:
||u1, u2||


v1
v2

 = u · v = u1v1 + u2v2
(2.12)
The scalar product has the following properties:
1. The scalar product of a vector v with itself is equal to the square of its length:
v · v = v2
1 + v2
2 = |v|2 = v2.
(2.13)
2. The commutative property:
u · v = v · u.
(2.14)
3. The distributive property:
u · (v + w) = u · v + u · w.
(2.15)
4. Multiplying u or v by a real number a, gives the same multiple of the scalar
product u · v:
(au) · v = u · (av) = a u · v
(2.16)
The scalar product is related to the projection of a vector onto a straight line. Consider
a vector v in the plane R2 and a straight line r through the origin O. Denote by u a unit
vector (whose length is equal to 1) directed along r. The scalar product u · v is equal
to u v cos φ, where φ is the angle between v, u (for simplicity we assume cos φ ≥0).
Therefore u · v is equal to the length of the vector v′ obtained by projecting v onto r
(see Fig.2.5). Clearly then:
v′ = (u · v)u.
(2.17)
Equations(2.13)–(2.17) can readily be generalized to a higher dimensional space.
For example, in the four-dimensional space R4, which is the set of ordered quadru-
ples of real numbers, the scalar product of two vectors u = (u1, u2, u3, u4),
v = (v1, v2, v3, v4) is given by:
u · v = u1v1 + u2v2 + u3v3 + u4v4
(2.18)
Setting u = v we obtain the square of the length of u:
|u|2 = u2
1 + u2
2 + u2
3 + u2
4.
(2.19)

48
2
Mathematical Methods in Quantum Mechanics
r
v
u
v ’
x
y
O
Fig. 2.5 Projection v′ of vector v on the straight line r
Let us return to the simple case of the plane R2, and consider two orthogonal
non-null vectors u, v; from Eq.(2.10) we have:
u · v = u v cos φ = 0
(2.20)
since the cosine of a right angle vanishes. The same happens in dimension 3. When
the dimension of the vector space is greater than 3, Eq.(2.20) can be regarded as
the deﬁnition of orthogonality of two vectors. Finally, we consider the important
concept for the spaces R2, R3, . . . of an orthonormal basis. Recall that the vectors
−→
ΨA = (1, 0) and −→
ΨB = (0, 1) in our toy Hilbert space also were both of unit length
and mutually orthogonal (see Fig.1.28), therefore:
−→
ΨA · −→
ΨA = |−→
ΨA|2 = 1; −→
ΨB · −→
ΨB = |−→
ΨB|2 = 1; −→
ΨA · −→
ΨB = 0.
(2.21)
The same property holds for the vectors −→
Ψ1 and −→
Ψ2, which were also of unit length
and orthogonal. Since any vector v = (v1, v2) of R2 can be written as a linear
combination of −→
ΨA and −→
ΨB, for example, v = v1
−→
ΨA + v2
−→
ΨB, we can say that they
form a basis. In R3, the vectors i = (1, 0, 0), j = (0, 1, 0), k = (0, 0, 1) form an
orthonormal basis, since they are of unit length, pairwise orthogonal, and any vector
v = (v1, v2, v3) can be written as the linear combination of i, j, k:
v = v1i + v2j + v3k
(2.22)
In general, in an n-dimensional space Rn (the set of all n-tuples of real numbers),
n orthonormal vectors are required to form a basis; it is then possible to write any
vector of the space as a linear combination of basis vectors.

2.2 Matrices in Quantum Mechanics
49
2.2
Matrices in Quantum Mechanics
The earliest formulation of QM, developed around 1925 by Heisenberg, Born and
Jordan, was called matrix mechanics. Classical observables, such as the position q or
momentum p of a particle, were represented, in this theory, not by simple numbers,
but rather by arrays Q and P containing an inﬁnite number of rows and columns.
The numbers appearing in an array might, for example, be related to the frequencies
of radiation observed in a transition between two energy levels of an atom. Indeed
the dimension of the array is equal to the number of these levels, and for a complete
theory of even a simple system, such as the hydrogen atom, this number is inﬁnite.
The theory of inﬁnite matrices is not at all simple, and this is a part of the reason that
matrix mechanics is the less popular formulation of QM. Let us consider a simple
situation, in which a quantum system has just two levels, which corresponds perfectly
to our toy Hilbert space; it will be instructive to see how physical observables are
represented in this model. All the formulas we have already encountered will turn
out to have counterparts in the general case, almost without modiﬁcation.
Consider the following 2 × 2 array of real numbers:

A11 A12
A21 A22
 ,
(2.23)
which is called a 2×2 matrix. The numbers A11, A12, . . . are called matrix elements.
In the following, unless otherwise speciﬁed, we refer to objects such as the array
(2.23) as a matrix of dimension 2 × 2.
We can also think of this matrix as an “operator,” since it determines a trans-
formation among the vectors of R2. Let us see how this happens. Given a vector
v = (v1, v2), we can produce a new vector w = (w1, w2) using the formulas:
w1 = A11v1 + A12v2,
w2 = A21v1 + A22v2.
(2.24)
A useful mnemonic for Eq.(2.24) is to consider the ﬁrst row of the matrix as the row
vector A1 = ||A11, A12||, and the second row as the row vector A2 = ||A21, A22||;
then Eq.(2.24) can be written using the row times column products:
w1 = ||A11, A12||


v1
v2

 = A1 · v,
w2 = ||A21, A22||


v1
v2

 = A2 · v.
(2.25)
Equation(2.24) can be written symbolically as:
w = Av
(2.26)
We say that the vector w is the image of v under the mapping A. Physicists use
the term operator to denote the mapping A and, for them, the terms “matrix” and
“operator” are used interchangeably (of course physicists are less meticulous than

50
2
Mathematical Methods in Quantum Mechanics
mathematicians). As an elementary example, let A =

3 5
7 2
 and v = (6, 4). Then
w = (3 × 6 + 5 × 4, 7 × 6 + 2 × 4) = (38, 50).
A simple, but essential, matrix is the following:
I =

1 0
0 1

(2.27)
It has the property that it maps any vector into itself: Iv = v. It is called the
identity matrix or simply the identity. The matrix with all elements vanishing is
called the null matrix. We will use the same symbol (in capital letters) for a matrix
and the corresponding mapping. An important class of matrices represent rotations.
For example, let R denote the matrix:
R =

cos θ −sin θ
sin θ
cos θ

(2.28)
Equation(2.24) becomes:
w1 = cos θ v1 −sin θ v2
w2 = sin θ v1 + cos θ v2
(2.29)
It is easy to verify that for any vector v the vector w = Rv is obtained by a coun-
terclockwise rotation through an angle θ. Indeed, if α denotes the angle between v
and the x axis of the Cartesian plane, we have: v1 = |v| cos α, v2 = |v| sin α, and
substituting in Eq.(2.29) we have: w1 = |v| cos(α + θ), w2 = |v| sin(α + θ) (see
Fig.2.6). It is simple to verify that multiplying the matrix (2.28), which corresponds
to a rotation through an angle θ, by an analogous matrix with θ replaced by α, gives
another rotation matrix with the angle θ + α, in agreement with the interpretation of
successive applications of the two rotations.
v = (v , v )
1
2
2
1
w = (w , w )
α
θ
O
Fig. 2.6 The vector w is obtained from the vector v by rotation by an angle θ

2.2 Matrices in Quantum Mechanics
51
A characteristic property of the mapping deﬁned by Eq.(2.24) is linearity. This
means that sums of vectors are sent into sums of images (geometrically, parallelo-
grams are sent into parallelograms), linear combinations are sent into linear combi-
nations, and so forth. In formulas, for all vectors u, v and all real numbers c:
A(u + v) = Au + Av,
A(cv) = c(Av).
(2.30)
These algebraic properties are essential in QM, consistent with the notion that matri-
ces constitute a generalization of real numbers. Mathematicians tell us that, given a
suitable deﬁnition of addition and multiplication, matrices form a ring, as do the real
and complex numbers1; thus it is not entirely surprising that physical quantities can
be represented by matrices.
We deﬁne the sum C of two matrices A, B, written C = A + B. if the matrix
elements of C are sums of the corresponding matrix elements of A, B:
Cik = Aik + Bik,
(i, k = 1, 2).
(2.31)
We can multiply a matrix A by a real number c:
(cA)ik = cAik,
(i, k = 1, 2).
(2.32)
The simple rules of algebra also apply to matrices, for example:
(A + B)v = Av + Bv,
(cA)v = c(Av).
(2.33)
Let us now deﬁne the product of two matrices. The idea is that the product of the
two successive linear mappings A, B, on a vector, can be done by ﬁrst applying B,
then A:
(AB)v = A(Bv)
for any vector v.
(2.34)
In Fig.2.7, we see that if the mapping B sends u in v, and the mapping A sends v
in w, then C = AB sends u directly into w; these are pictorial representations of
the operations: v = Bu, w = Av, and w = Cu. In terms of matrix elements, the
corresponding matrix products are given by
C11 = A11B11 + A12B21, C12 = A11B12 + A12B22,
C21 = A21B11 + A22B21, C22 = A21B12 + A22B22.
(2.35)
Againthemultiplicationrule“rowstimescolumns”applies.WritingA1=||A11, A12||,
A2 = ||A21, A22||, two row vectors, and B1 =


B11
B21

, B2 =


B12
B22

, two column
vectors, Eq.(2.35) can be written as:
1A ﬁeld is a ring in which multiplication is commutative and every nonzero element has a multi-
plicative inverse. Thus real and complex numbers are also ﬁelds, while matrices are just rings.

52
2
Mathematical Methods in Quantum Mechanics
w
v
u
A
C
O
B
Fig. 2.7 The mapping C = AB is obtained by successive applications of the mappings B, then A
C11 = A1 · B1, C12 = A1 · B2,
C21 = A2 · B1, C22 = A2 · B2.
(2.36)
In general, an m × n matrix is a rectangular array of numbers with m rows and n
columns. For example, if m = 2 and n = 3 we have the matrix A:
A =


A11 A12 A13
A21 A22 A23

 .
(2.37)
We denote by Ai j the matrix element in the ith row and the jth column. Given a
second matrix B, the matrix product AB requires that the number n of columns of A
must match the number of rows of B; thus B must be a n ×l matrix, l being arbitrary.
In the general case, the matrix elements (AB)ik are given by:
(AB)ik =
n

j=1
Ai j B jk, i = 1, 2, . . . , m, k = 1, 2, . . . ,l
(2.38)
For example, if A is the matrix (2.37) and B is the 3 × 2 matrix:
B =


B11 B12
B21 B22
B31 B32


,
(2.39)
the matrix multiplication row times columns thus gives:
AB =


A11B11 + A12B21 + A13B31
A11B12 + A12B22 + A13B32
A21B11 + A22B21 + A23B31
A21B12 + A22B22 + A23B32

 ,
(2.40)
so that AB is a 2 × 2 square matrix. The geometrical meaning of the “operators”
A, B and AB is the following: B maps vectors belonging to R2 into R3, while A
maps vectors of R3 into R2; therefore AB maps vectors of R2 into vectors of R2.

2.2 Matrices in Quantum Mechanics
53
The application of a square matrix m × m to a vector in Rm is a particular case of
Eq.(2.38); for example, setting n = m = 2, B11 = v1, B21 = v2, we obtain:
(AB)11 = A11v1 + A12v2,
(AB)21 = A21v1 + A22v2.
(2.41)
Thus:
AB =

A11 A12
A21 A22


v1
v2
 =

A11v1 + A12v2
A21v1 + A22v2
 .
(2.42)
Many of the familiar formulas of elementary algebra still apply; for example,
the associative property C(AB) = (C A)B; the distributive property (A + B)C =
AC + BC, etc., but a new feature appears: the commutative property does not hold!
It is not true, in general, that AB = B A, as in elementary arithmetic. This fact has
profound consequences in QM. (It is, in fact, the root of the uncertainty principle.)
Let us give an example of two non-commuting matrices:
A =

0 1
0 0
 ,
B =

0 0
1 0
 .
(2.43)
Their products are then given by:
AB =

1 0
0 0
 ,
B A =

0 0
0 1
 .
(2.44)
Since matrices represent operations, it is not unexpected that they sometimes do
not commute. In everyday life, we can experience situations in which the order of
operations is important: such as writing a letter and sealing it in an envelope. The
result in elementary mathematics, that multiplying ﬁrst by a and then by b, gives the
same result as multiplying ﬁrst by b and then by a, turns out to be rather exceptional
in higher mathematics. The commutator of two matrices is deﬁned by

A, B

= AB −B A.
(2.45)
If the commutator equals 0, then the matrices A and B commute: AB = B A.
The inverse A−1 of a matrix A is deﬁned by the following property:
AA−1 = A−1 A = I.
(2.46)
where I denotes the identity matrix; A−1 corresponds to the inverse transformation.
For example, the inverse of a rotation matrix through an angle θ in a counterclockwise
sense, is a rotation matrix through the same angle in a clockwise sense; in order to
obtain R−1 it sufﬁces to substitute −θ in the place of θ into Eq.(2.28). For the case of
real numbers, the inverse (here, meaning the reciprocal) always exists except for the
number zero. For 2 × 2 matrices, the inverse exists unless the following expression

54
2
Mathematical Methods in Quantum Mechanics
Fig. 2.8 There are an inﬁnite number of vectors v whose projection on the x axis is equal to v ′
vanishes: D = A11A22 −A12 A21. The geometric meaning of D (which is a 2 × 2
determinant) is the ratio of the area of the parallelogram of two images Av, Au to
the area of the parallelogram of v, u. It is a scale dilatation of the space R2 under the
action of the operator A. It is necessary that D ̸= 0 for the inverse of A to exist.
An important class of operators (or matrices) that usually do not admit an inverse2
are projection operators. The simplest projection operator can be represented by the
matrix:
P =

1 0
0 0
 .
(2.47)
If v = (v1, v2) is an arbitrary vector, the image Pv = (v1, 0) is the vector v ′ obtained
by projecting v onto the x axis, as shown in Fig.2.8. The reason P does not admit
an inverse is that there exist an inﬁnite number of vectors v ′′ whose images Pv ′′
coincide with v ′. These vectors v ′′ have their free end on a straight line parallel to
the y axis. Mathematicians say that the mapping P is not injective. The inverse P−1
does not exist since it is ill-deﬁned: which vector do we choose? v ′, v ′′, . . . ? Even
in the simple space R2 there are many projection operators. Given any straight line
r through the origin, let us denote by Pr the projection operator onto the line r, as
shown in Fig.2.9. The matrix corresponding to Pr is easily found: Let u = (c, s) be
a unit vector directed along the line r; since |u| = 1, c2 + s2 = 1. Therefore:
Pr =

c2 cs
cs s2
 .
(2.48)
An example of a projection operator in R3 is PL, deﬁned as follows: given a vector
v = (v1, v2, v3) belonging to R3, and a plane L through the origin O, PLv is the
vector obtained taking the orthogonal projection of v on the plane L, as shown in
Fig.2.10.
2Only the identity I is a projection operator that admits an inverse.

2.2 Matrices in Quantum Mechanics
55
Pr
r
v
v ’
x
y
O
u = (c, s)
Fig. 2.9 The action of the projection operator Pr in two dimensions
x
y
P v
L
L
v
O
z
Fig. 2.10 The action of the projection operator PL in three dimensions
Some matrices can be associated with physical observables. Apart from some
subtle points that we will discuss later, only matrices A such that A12 = A21 are
possible candidates. (We are still limiting ourselves to real matrices.) These matrices
are symmetric matrices, for example,

a b
b c
 ,
(2.49)
which is the most general 2 × 2 symmetric matrix. Of course, the matrix R of
Eq.(2.28) is not symmetric, since R12 = −sin θ, while R21 = sin θ.

56
2
Mathematical Methods in Quantum Mechanics
We have noted above that matrices can be regarded as generalizations of numbers
(which can be considered 1 × 1 matrices). But in some cases, a matrix A can behave
like a number in another way. This happens when it operates on particular vectors,
called eigenvectors. For these vectors, the application of A is equivalent to the multi-
plication by a real number λ. More precisely, we shall say that a vector v = (v1, v2)
(excluding (0, 0)) is an eigenvector of the matrix A corresponding to the eigenvalue
λ, if the following relation holds:
Av = λv.
(2.50)
For example, if λ = 3, the image vector Av is three times longer than v, if λ = 1
2, Av
is half of v, and so forth. The important point is that the direction of the eigenvector
remains unchanged. Equation(2.50) for a symmetric matrix A is equivalent to the
two scalar equations:
A11v1 + A12v2 = λv1,
A12v1 + A22v2 = λv2.
(2.51)
Symmetric matrices have the remarkable property (which is at the root of their utility
in QM) of admitting an orthonormal basis of eigenvectors. In our toy space, for any
symmetric matrix A there exist two vectors −→
Ψ1, −→
Ψ2 such that:
A−→
Ψ1 = λ1
−→
Ψ1,
A−→
Ψ2 = λ2
−→
Ψ2.
(2.52)
Since these equations do not imply any restriction on their lengths, −→
Ψ1 and −→
Ψ2 can
be chosen with unit lengths. Furthermore it can be shown that if λ1 is different from
λ2, −→
Ψ1 and −→
Ψ2 are orthogonal to each other.
Matrices, such as the 2 × 2 with A12 = A21 = 0, are called diagonal. They have
the nice property that the eigenvectors are directed along the coordinate axis. We
will denote them by −→
ΨA, −→
ΨB, in agreement with our notation in toy Hilbert space. As
an example, let Q be the matrix:
Q =

3 0
0 2
 .
(2.53)
We can easily verify that
Q−→
ΨA = 3−→
ΨA,
Q−→
ΨB = 2−→
ΨB,
(2.54)
where −→
ΨA = (1, 0) and −→
ΨB = (0, 1). Two diagonal matrices always commute. As
an example, consider the matrix:
R =

5 0
0 7

(2.55)

2.2 Matrices in Quantum Mechanics
57
and compute the commutator QR −RQ; one ﬁnds a matrix with all elements equal
to zero, namely, the null matrix, which we denote by 0. Therefore QR −RQ = 0. Of
course, R admits as eigenvectors the same eigenvectors as Q, so that the vectors −→
ΨA
and −→
ΨB are the same; only the eigenvalues of Q and R are different. This is a general
rule: if two symmetric matrices commute, they possess a common set of orthonormal
eigenvectors.
Returning to Eq.(2.51) for a symmetric matrix, we can now ﬁnd the eigenvalues
λ. Assuming, for simplicity, that v2 is not equal to zero, we can divide both equations
by v2. Denoting by r the quotient v1/v2, we get:
A11r + A12 = λr,
A12r + A22 = λ.
(2.56)
Solving forr in the second equation and substituting in the ﬁrst, we obtain an equation
determining the eigenvalues:
(A11 −λ)(A22 −λ) −A2
12 = 0,
(2.57)
which is a simple quadratic equation in the variable λ. In the most general case, it has
two solutions λ1, λ2, and for each solution, the relation A12r + A22 = λ determines
a possible value of r, which gives the direction of the corresponding eigenvector.
(For simplicity, we neglect here the possibility of degeneracy, when more than one
eigenvector corresponds to the same eigenvalue.) As an example, if all the matrix
elements Aik are equal to 1, the matrix A is simply:
A =

1 1
1 1
 .
(2.58)
and the eigenvalue Eq.(2.57) reduces to (1 −λ)2 = 1, so that (1 −λ) = ±1, and the
eigenvalues have the values 0 and 2. For λ = 0 we get r = −1, thus the eigenvector
is −→
Ψ1 = (1, −1), and for λ = 2 we get r = 1 and the eigenvector −→
Ψ2 = (1, 1).
Note that −→
Ψ1 and −→
Ψ2 are orthogonal, as they should be. However, their lengths are
not equal to 1 (actually to
√
2). Normalizing the eigenvectors by dividing −→
Ψ1 and −→
Ψ2
by
√
2, we obtain two orthonormal eigenvectors (which we still denote by −→
Ψ1, −→
Ψ2,
since they also obey Eq.(2.52) and no confusion need arise):
−→
Ψ1 =
 1
√
2
, −1
√
2
	
,
−→
Ψ2 =
 1
√
2
, 1
√
2
	
.
(2.59)
Let us compute the commutator Q A −AQ of the matrices (2.53), (2.58). We ﬁnd,
using Eq.(2.35):
Q A =

3 0
0 2


1 1
1 1
 =

3 3
2 2
 ,
(2.60)

58
2
Mathematical Methods in Quantum Mechanics
AQ =

1 1
1 1


3 0
0 2
 =

3 2
3 2
 .
(2.61)
Evidently, Q A and AQ have rows and columns interchanged, so the commutator
Q A −AQ does not vanish. The noncommutativity of Q, A and the differing eigen-
vectors of Q and A are, in fact, related. Indeed, we can state the following theorem:
Theorem 2.1 Two symmetric matrices admit a common basis of orthonormal eigen-
vectors if and only if they commute.
2.3
Quantum Mechanics in Toy Hilbert Space
In Sect.1.3, we introduced a “toy Hilbert space,” an extremely simpliﬁed representa-
tion for a two-state quantum system, whereby quantum states can be represented by
unit vectors in the 2D Cartesian plane, with coordinates x, y. Physical observables
are correspondingly represented by real symmetric 2 × 2 matrices. The theorem at
the end of the last section is relevant to a fundamental interpretative postulate of QM:
Postulate 1: To any possible state of a physical system there corresponds a vector −→
OS of
length 1. To any physical quantity F there corresponds a symmetric matrix (also denoted
by F). The possible results of a measurement of F on any state are the eigenvalues of the
matrix F. If −→
Ψ is a normalized eigenvector of F corresponding to the eigenvalue λ, so that
F−→
Ψ = λ−→
Ψ ,
(2.62)
then |−→
Ψ · −→
OS|2 is the probability that the result of a measurement of F is λ.
To this we add:
Postulate 2: After the measurement of F, if the result is λ, the state vector −→
OS coincides
with the eigenvector −→
Ψ , thus verifying Eq.(2.62).
In order to explain the motivation for Postulate 2, we quote from Dirac (Dirac 1958):
From physical continuity, if we make a second measurement immediately after the ﬁrst, the
result of the second measurement must be the same as that of the ﬁrst. Thus after the ﬁrst
measurement has been made, there is no indeterminacy in the result of the second …This
conclusion must still hold if the second measurement is not actually made.
Physical quantities like F are called observables by physicists. They correspond to
symmetric matrices (more precisely, Hermitian matrices, see Sect.2.6). Likewise,
the corresponding physical states are represented by state vectors.
Suppose now that the matrices Q and A correspond to position q and velocity v,
respectively. The matrix Q has the eigenvectors −→
ΨA, −→
ΨB, while A has the eigenvectors
−→
Ψ1 and −→
Ψ2. In our toy Hilbert space, the possible results of a measurement of q are
3 and 2 (the eigenvalues of Q), while the possible results of a measurement of v are
0 and 2 (the eigenvalues of A). Furthermore, the expression |−→
Ψ1 · −→
OS|2 is the square

2.3 Quantum Mechanics in Toy Hilbert Space
59
of the projection of −→
OS on the straight line determined by −→
Ψ1, etc. The pair of “axis”
−→
Ψ1, −→
Ψ2 is “rotated” with respect to the “axes” −→
ΨA, −→
ΨB by virtue of the fact that the
commutator Q A−AQ does not vanish. By Postulate 2, if we ﬁrst measure Q, the state
vector −→
OS will “jump” to either −→
ΨA or −→
ΨB. In either case, a subsequent measurement
of A will be uncertain. Physicists say that the observables Q and A are not compatible.
When physicists realized that the matrices corresponding to very simple observables
such as q and p (position and momentum of a particle) do not commute, it is not
surprising that this possibility was initially regarded with skepticism. Actually, the
matrices representing q and p are of inﬁnite dimension, but the geometry of our toy
Hilbert space is still a valid analogy. As a consequence of the mathematical structure
of the theory, q and p do not admit common eigenvectors, similar to the situation we
found for the matrices Q, A above. No state vector exists such that we can obtain with
certainty (probability 1) a value of q and a value of p. The conclusion follows that
the observables q and p cannot be simultaneously measured. An analogous result
applies for any pair of non-commuting observables; and, since symmetric matrices
do not, in general, commute, indeterminacy relations are quite commonplace, rather
than an exception. Other than position and velocity, some well-known cases of non-
commuting observables include two different components of angular momentum, as
well as operators representing time and energy.
An important quantity in QM is the average or expectation value of an observable
in a given state. Suppose the observable F is represented by the simple diagonal
matrix:
F =

FA 0
0 FB
 .
(2.63)
We consider a completely general state vector −→
OS = (x, y), requiring only the
normalization condition x2 + y2 = 1, such that S lies on a circle of radius 1 centered
at the origin. As always, we suppose, that −→
OS represents the state of the system.
Let us perform a measurement of F. We already know that the eigenvalues of F
are the numbers FA, FB, and therefore the probability of ﬁnding the value FA is
x2, and the probability of ﬁnding the value FB is y2. Then the average F of the
results of a measurement of F can be computed by the standard formula of statistics,
F = 
i Fi Pi, and we can write:
F = FAx2 + FB y2.
(2.64)
Alternatively, by taking the scalar product of the vectors −→
OS and F−→
OS, we get the
same result. In fact, the vector obtained applying the operator F to −→
OS is simply
(FAx, FB y); taking the scalar product of this vector with −→
OS = (x, y) we obtain the
right-hand side of Eq.(2.64), whereby
F = −→
OS · F−→
OS.
(2.65)

60
2
Mathematical Methods in Quantum Mechanics
The last formula, which has been obtained in a very particular case, is actually a
completely general and very elegant result.
Postulate 1 does not say anything about the time evolution of the state vector.
Actually, the motion in the Hilbert space of vector −→
OS is determined by the time-
dependent Schrödinger equation. In our toy space, the path of point S is simply the
circumference of a circle of radius 1. Clearly, in spaces of higher dimension, this
path is more complicated. We must imagine a point S moving continuously (without
sudden jumps), maintaining its unit distance from the origin, just like a mass point
constrained to the circumference of a circle. In the original formulation of QM,
sudden jumps might occur when a measurement is made (see Postulate 2). We will
come back to this subtle (and controversial) point later, exempliﬁed by the question:
“Are there quantum jumps?”.
In the work we have done thus far, observables F have been independent of time
(as have both the eigenvectors and the eigenvalues), while the vector state −→
OS carries
all the dependence on time. This is known as the Schrödinger picture. It is not difﬁcult
to formulate an alternative interpretation in Hilbert space, which corresponds to the
same physical situation, but uses a ﬁxed state vector but time-dependent operators.
The idea is to rotate the eigenvectors of F back in such a way that their relative
position with −→
OS (which now is ﬁxed) is the same as in the Schrödinger picture. We
need ﬁrst the following result:
Lemma 2.1 If R is a rotation matrix, and A, B are arbitrary vectors, the scalar
product of A with RB is equal to the scalar product of B with R−1A.
An algebraic proof is elementary. The matrix of R−1 is obtained from the matrix R
simply by changing the sign of θ in Eq.(2.28). The following intuitive argument is
perhaps more direct: consider the angle φ between the vectors A, B (see Fig.2.11).
Rotating B in a counterclockwise sense through an angle θ, we obtain the vector
RB, while the angle between A and RB becomes θ + φ. And if we keep B ﬁxed and
rotate the vector A back in a clockwise sense (by applying R−1) through an angle θ,
the angle between B and R−1A remains equal to φ + θ. From Eq.(2.10), we see that
the scalar product of two vectors depends on the lengths of the vectors and the angle
between them. But rotations do not change lengths, and since the angle is θ + φ in
both cases, the Lemma is proved.
Let us denote by −→
Ψ (t) the state vector −→
OS as a function of time t. Suppose, for
simplicity, that at t = 0 the state vector coincides with the x axis, −→
Ψ (0) = (1, 0),
and at time t = T, the state vector −→
Ψ (T) makes an angle θ(T) with the x axis; in
other words, during the time from t = 0 and t = T the state vector is rotated through
an angle θ. Therefore the mapping from −→
Ψ (0) to −→
Ψ (T) can be obtained by means
of the rotation matrix (2.28) and we have:
−→
Ψ (T) = R(T)−→
Ψ (0).
(2.66)
In the last equation, we have written R(T) to emphasize the dependence of the rotation
R on time T. In the more general situation, the analog of Eq.(2.66) provides the

2.3 Quantum Mechanics in Toy Hilbert Space
61
B
A
θ
θ
ϕ
O
R    A
−1
RB
Fig. 2.11 The scalar products ⟨RB|A⟩and ⟨B|R−1A⟩are equal
solution of the time-dependent Schrödinger equation, once the initial wave function
−→
Ψ (0) is speciﬁed. Substituting (2.66) in place of −→
OS into Eq.(2.65) we get:
F = R(T )−→
Ψ (0) · F R(T )−→
Ψ (0).
(2.67)
Let us apply Lemma1 with A = F R(T )−→
Ψ (0) and B = −→
Ψ (0). This allows us to
move the rotation operator R(T ) to the other side of the scalar product, then replacing
R by R−1. We obtain:
F = −→
Ψ (0) · R(T )−1F R(T )−→
Ψ (0).
(2.68)
We call the time-dependent operator F(T ) = R(T )−1F R(T ) operator F in the
Heisenberg picture, and we write:
F = −→
Ψ (0) · F(T )−→
Ψ (0).
(2.69)
Of course, the state vector in the Heisenberg picture is −→
Ψ (0). We see from formulas
(2.69), (2.65) that the expression for F is the same in the two pictures. However,
in the Heisenberg picture, the time dependence has been entirely transferred to the
operatorrepresentingtheobservable.Thisisquiteanalogoustothepictureinclassical
mechanics, in which we seek the changes in observables with time, as described by
equations of motion.
A ﬁnal topic we want to introduce for our toy Hilbert space is the density matrix.
For any matrix Ai j, the sum of the elements of the main diagonal is called the trace
of A, denoted by Tr A. Therefore:

62
2
Mathematical Methods in Quantum Mechanics
Tr A = A11 + A22.
(2.70)
Given a unit vector −→
OS = (x, y), the projection operator P on the line determined
by −→
OS is given, using Eq.(2.48) and setting c = x, s = y:
P =

x2 xy
xy y2
 .
(2.71)
Given the operator F, the trace of the product P F is given by:
Tr(P F) = Tr

x2F11 + xyF12 x2F12 + xyF22
xyF11 + y2F12 xyF12 + y2F22
 = x2F11 + 2xyF12 + y2F22.
(2.72)
Let us prove that the last expression constitutes a generalization of Eq.(2.64) when
F is not diagonal. First compute (2.65): the coordinates of the vector F −→
OS are
(F11x + F12y, F12x + F22y); then take the scalar product of this vector with −→
OS =
(x, y), giving precisely the expression (2.72). Therefore:
Tr(P F) = ⟨−→
OS|F −→
OS⟩= F.
(2.73)
Note that if F equals the identity I, Eq.(2.27) reduces to
Tr(P I) = Tr P = x2 + y2 = 1.
(2.74)
Consider now two orthogonal states −→
Ψ1, −→
Ψ2 and suppose that there is a probability
p1 that the state vector −→
OS of a physical system coincides with −→
Ψ1, and a probability
p2 that it coincides with −→
Ψ2. Note that in the actual case the probabilities p1 and p2
are not the fundamental probabilities of QM (which Heaven only knows!). Here, p1
and p2 might represent classical probabilities of distinct physical situations, as we
encounter, in classical statistical mechanics. In any event, we must have p1+ p2 = 1.
In order to obtain the average value of an observable F, we compute a double average:
ﬁrst we ﬁnd the two quantum averages ⟨−→
Ψ1|F −→
Ψ1⟩, ⟨−→
Ψ2|F −→
Ψ2⟩, and then we average
these results, making use of the probabilities p1, p2; at the end of this procedure we
get:
F = p1⟨−→
Ψ1|F −→
Ψ1⟩+ p2⟨−→
Ψ2|F −→
Ψ2⟩.
(2.75)
Now let P1, P2 be the projection operators onto the straight lines determined by −→
Ψ1,
−→
Ψ2. Using Eq.(2.73) we have ⟨−→
Ψ1|F−→
Ψ1⟩= Tr(P1F), and ⟨−→
Ψ2|F−→
Ψ2⟩= Tr(P2F).
Therefore, introducing the density matrix ρ = p1P1 + p2P2 and using the fact that
taking the trace is a linear operation, we can write:
F = p1Tr(P1F) + p2Tr(P2F) = Tr [ (p1P1 + p2P2)F ] = Tr(ρF).
(2.76)

2.3 Quantum Mechanics in Toy Hilbert Space
63
Equation(2.76) constitutes a generalization of Eq.(2.73); knowledge of the density
matrix ρ allows us to compute averages of any observable F; therefore ρ determines
the state of the system in way analogous to the state vector −→
OS. When p1 = 1 and
p2 = 0, or p1 = 0 and p2 = 1, this reduces to the previous case; we say that the
system is in a pure state. The more general state deﬁned by ρ = p1P1 + p2P2 is
called a mixed state. Let us verify that p1, p2 are the eigenvalues of ρ, and −→
Ψ1, −→
Ψ2,
its eigenvectors. Denoting by 0 the null vector, we have:
P1
−→
Ψ1 = −→
Ψ1,
P2
−→
Ψ1 = −→
0 ,
(2.77)
and therefore:
ρ−→
Ψ1 = (p1P1 + p2P2)−→
Ψ1 = p1
−→
Ψ1 + p2
−→
0 = p1
−→
Ψ1.
(2.78)
In the same way we can prove that ρ−→
Ψ2 = p2
−→
Ψ2. Since there is no restriction on the
pair of orthogonal vectors −→
Ψ1, −→
Ψ2, we see that the most general density matrix is a
symmetric matrix whose eigenvalues are positive numbers p1, p2 less than or equal
to 1, and such that p1 + p2 = 1. Using the relation x2 + y2 = 1, it can be veriﬁed
that the projection operator P, given by Eq.(2.71), is idempotent, meaning that it
obeys the relation P2 = P. This condition is, in fact, a deﬁning characteristic of a
pure state.
2.4
The Hilbert Space of Real Wavefunctions
We have now acquired an understanding of the toy model, but it may still not be
entirely clear why wave functions representing “clouds of probability” have anything
to do with vectors of the plane R2. The answer of a mathematician might again run:
“Both R2 and the set of wave functions of a physical system are vector spaces
endowed with a scalar product.” However, to show that wave functions do indeed
belong in a Hilbert space, we will follow a more elementary, less abstract, line of
development: we will exhibit an “analogy” between the vectors of R2, R3, . . . , and
the set C(a, b) of continuous wavefunctions deﬁned on an interval [a, b] of the real
axis. Actually, physical wave functions ψ(x, y, z) are deﬁned on points (x, y, z) of
three-dimensional space; indeed |ψ(x, y, z)|2 is actually the probability density in
the clouds drawn in Chap.1. To simplify the mathematics, we can imagine that our
physical system to be one-dimensional, so that the wavefunctions depend on just a
single variable x, on a line segment [a, b].
Two of the fundamental operations of a vector space, given in Eqs.(2.1) and (2.2),
have obvious analogs for our set of functions: given two continuous functions f (x),
g(x), their sum is the function f (x)+g(x), as shown in Fig.2.12. Also, just as we can
multiply the coordinates of a vector; by a real number λ, to obtain a new vector λf in
the same direction as the original, we can likewise multiply a function f (x), to give
the analogous scaled function λf (x). The operations of addition and multiplication

64
2
Mathematical Methods in Quantum Mechanics
a
b
g
f + g
f
Fig. 2.12 Sum of two functions f , g
by a real number suggests the terminology linear combination of two functions f (x),
g(x), with real coefﬁcients a, b, namely, the function af (x)+bg(x). The set of such
linear combinations can be thought of as a three-dimensional subspace of C(a, b),
provided f (x), g(x) do not have the same “direction,” meaning that f (x) is not
simply a multiple of g(x). This two-dimensional subspace can be thought of as a
plane through the origin. What is the origin? The object analogous to the null vector
(0, 0) of R2 is a function which equals zero everywhere: f (x) = 0 for all x.
A more challenging question is: what constitutes the coordinates of a function,
which are somehow the analogs of the components of a vector? Later we will give
a more rigorous answer to this question; for the moment, we tentatively settle for
a more heuristic approach, which will enable us to understand the meaning of the
scalar product of two wavefunctions. Let f be a continuous function deﬁned on [a,b];
see Fig.2.13, where the graph of f (x) is shown. We choose n equally spaced points
x1, x2, . . . , xn in the interval (so that x1 = a and xn = b), and we compute the values
of the functions f (x1), f (x2), . . . , f (xn). We can then imagine these numbers to be
f(x   )
1
f(x   )
2
f(x   )
3
f(x   )
n
a = x1
b = xn
f
x
y
Δ
Ο
Fig. 2.13 A function f (x) is approximated by a vector in Rn, f = ( f (x1), f (x2), . . . , f (xn))

2.4 The Hilbert Space of Real Wavefunctions
65
the coordinates of a vector belonging to Rn. For example, let us take a = 0, b = 3,
n = 4 and consider the simple function f (x) = x2. Then x1 = 0, x2 = 1, x3 = 2,
x4 = 3, and f (x1) = 0, f (x2) = 1, f (x3) = 4, f (x4) = 9. We have obtained the
vector (0, 1, 4, 9) of R4. You may ask: How do we choose the number n? Indeed
this number is arbitrary, since given a function on an interval, we can compute it
at as many points as we want. This is an inherent weakness in the identiﬁcation of
the values f (x1), f (x2), . . . , f (xn) as “coordinates of f .” However, let us boldly
proceed nonetheless, and try to ﬁnd a tentative deﬁnition of the scalar product of two
functions which is analogous to the deﬁnitions (2.10), (2.11) of the scalar product of
two vectors?
Given two functions f and g, both continuous on the interval [a,b], let us compute
these functions on the equally spaced points x1 = a, x2, . . ., xn = b, as above. We
will obtain, in this way, two vectors f, g belonging to Rn:
f = ( f (x1), f (x2), . . . , f (xn)),
g = (g(x1), g(x2), . . . , g(xn)),
(2.79)
whose scalar product is given by (see the analog in R4, Eq.(2.18)):
f (x1)g(x1) + f (x2)g(x2) + · · · + f (xn)g(xn).
(2.80)
However this expression depends on the number n, which is arbitrary. Since our
knowledge of a function becomes more precise when we know more and more values
f (xi) (think, for example, of these values as data in an experiment), we can take the
limit of Eq.(2.80) as n approaches inﬁnity. Even for the elementary case of two
constant functions, say f (x) = 2 and g(x) = 3, this limit is not ﬁnite. On the other
hand, there exists an expression which is similar to Eq.(2.80) that admits a ﬁnite limit
when n →∞, and will provide us with a more rigorous deﬁnition. Denoting by Δn
the distance between two consecutive points, we have Δn = x2−x1 = x3−x2, . . . =
(b−a)
(n−1). It is easy to see that the limit:
lim
n→∞Δn [ f (x1)g(x1) + f (x2)g(x2) + · · · + f (xn)g(xn)]
(2.81)
exists and corresponds to the deﬁnition of a Riemann integral:
 b
a
f (x)g(x) dx.
(2.82)
Thus the expression (2.82) provides us with a consistent deﬁnition of scalar product
of two real functions f (x), g(x). To emphasize the analogy with vectors, we can
write:
f · g =
 b
a
f (x)g(x) dx.
(2.83)

66
2
Mathematical Methods in Quantum Mechanics
The importance of this deﬁnition of scalar product can hardly be overestimated. It
allows us to continue using a geometric language in the space of wavefunctions, and
suggests an intuitive picture of physical states, even when we are referring, not to
physical space, but to an abstract function space. We continue to deﬁne the norm or
length of the vector f using the expression:
|f| =
√
f · f =
 b
a
dx f (x)2.
(2.84)
As an example, let us evaluate the scalar product of the functions x and 1 + x2 on
the interval [ 0, 1]. We must perform the integration:
 1
0
(1 + x2)x =
x2
2 + x4
4
1
0
dx = 3
4.
(2.85)
Table2.1 shows the analogies between vectors in Rn and the corresponding func-
tional relations. On the left of the table, we show expressions involving the vectors
v, w, . . .; on the right are the analogs, in terms of the functions f (x), g(x) or
f, g, . . .. Such correspondences will be particularly useful in Dirac’s bra/ket formu-
lation of QM.
Table 2.1 Analogies between vectors and functions
Vectors
Functions
Components of a vector v = (v1, v2, . . . , vn)
Values of a function
f (x1), f (x2), . . . , f (xn)
Sum of two vectors v + w
Sum of two functions f (x) + g(x)
Linear combination of two vectors c1v + c2w
Linear combination of two functions
c1 f (x) + c2g(x)
Scalar product of two vectors
v · w = v1w1 + v2w2 + · · · + vnwn
Scalar product of two functions
f · g =
 b
a f (x)g(x) dx
Norm of a vector |v| = √v · v =

v2
1 + v2
2 + · · · + v2n
Norm of a function |f| =
√
f · f =
 b
a dx f (x)2
Linearity of the scalar product
⟨c v|w⟩= c ⟨v|w⟩
⟨v|w1 + w2⟩= ⟨v|w1⟩+ ⟨v|w2⟩
Linearity of the scalar product
⟨c f|g⟩= c ⟨f|g⟩
⟨f|g1 + g2⟩= ⟨f|g1⟩+ ⟨f|g2⟩
Distance between two vectors
d = |v −w| = √⟨v −w|v −w⟩=

(v1 −w1)2 + (v2 −w2)2 + · · · + (vn −wn)2 1
2
Distance between two functions
d = |f −g| = √⟨f −g|f −g⟩=
 b
a dx ( f (x) −g(x))2 1
2

2.4 The Hilbert Space of Real Wavefunctions
67
The proof of the relations: ⟨cf|g⟩= c⟨f|g⟩, and ⟨f|g1 + g2⟩= ⟨f|g1⟩+ ⟨f|g2⟩is
elementary also in the case of functions, since
 b
a

cf (x)

g(x) dx = c
 b
a
f (x)g(x) dx,
(2.86)
and
 b
a
f (x)

g1(x) + g2(x)

dx =
 b
a
f (x)g1(x) dx +
 b
a
f (x)g2(x) dx.
(2.87)
The analogy between the distance between vectors and the “distance” between func-
tions deserves a word of comment: if distance d is very small the coordinates of the
vectors v, w are almost equal, since the sum of the positive numbers (v1 −w1)2,
(v2 −w2)2, . . . , cannot be small unless every one of these contributions is small.
In an analogous way, for functions, a very small value of d means, by and large,
that the graphs of the functions f (x), g(x) are very close together. (There might be
exceptions, in which the difference of the functions is large in small intervals on the
x-axis.)
Another case to be considered is the existence of functions that do not have ﬁnite
norm. A simple example is the function f (x) =
1
√x , deﬁned on the open interval
(0, 1), that is, the interval excluding the endpoints 0, 1. In fact,
 1
0 f (x)2 dx =
 1
0
1
x dx = ∞or, better, limϵ→0
 1
ϵ
1
x dx = ∞, since the function x−1 becomes very
large for small x. Such behavior is excluded from our formalism, since we have
restricted functions to be continuous and well deﬁned in the whole interval [a, b] ( 1
x
is not deﬁned for x = 0). However, in physics, the interval [a, b] is often the entire
x axis, so that our integration
 b
a becomes
 +∞
−∞. Therefore, even some very simple
functions such as x2, x4, etc., must be excluded since their integrals diverge to ∞.
However, since a wave function f (x) gives the probability amplitude of ﬁnding a
particle at point x, it is reasonable to assume that this amplitude goes to zero when x
becomes very large (for example, an electron bound to an atom has practically zero
probability of being found on the Moon). Coming back to the purely mathematical
aspects of the theory (while leaving aside certain mathematical subtleties), we will
deﬁne as a Hilbert space, denoted by L2(a, b), the set of functions f (x) such that
 b
a
[ f (x)]2 dx < ∞,
(2.88)
meaning that the integral must be ﬁnite. Therefore, 1
x , for example, does not belong
to L2(0, 1). In many physical applications, we will have a = −∞, b = +∞, with
the corresponding Hilbert space denoted by L2(−∞, +∞).
We usually assume that functions belonging to the Hilbert space correspond to
vectors of ﬁnite length. The scalar product must then also be ﬁnite. As an example,
the wave function:

68
2
Mathematical Methods in Quantum Mechanics
Table 2.2 Vector products and integrals of functions
Two vectors v, w are are orthogonal if
v · w = 0, so that
v1w1 + v2w2 + · · · + vnwn = 0
Two functions f, g orthogonal if f · g = 0, so
that
 b
a f (x)g(x) dx = 0
A vector v is normalized if
|v|2 = v2
1 + v2
2 + · · · + v2
n = 1
A function f (x) is normalized if
|f|2 =
 b
a f (x)2 dx = 1
A basis of n orthonormal vectors in Rn is a set
of n vectors v (1), v (2), . . . , v (n) such that
v (i).v ( j) =

1 if i = j
0 if i ̸= j
A basis of orthonormal functions in L2 is a
sequence of (∞) functions
f1(x), f2(x), . . . , fn(x) . . . such that
fi.f j =
 b
a fi(x) f j(x) dx =

1 if i = j
0 if i ̸= j
Expansion of a vector in an orthonormal basis:
v = 
n
i=1 vie (i) vi = e (i) · v
Expansion of a function in an orthonormal
basis: f (x) = 
∞
i=1 ci fi(x)
ci = fi · f =
 b
a fi(x) f (x)dx
1
4√π e−(x−a)2/2
(2.89)
has norm equal to one and represents a “cloud” of probability localized around
the point x = a, decreasing rapidly as |x −a| becomes large. To complete our
analogy between vectors and functions, there is no problem in extending the concept
of orthogonality to functions; by the deﬁnition of scalar product, we can say that
two functions f (x), g(x) are orthogonal in L2(a, b) if ⟨f|g⟩=
 b
a f (x)g(x) dx =
0. With this deﬁnition in mind, we deﬁne an orthonormal set of functions f1(x),
f2(x),…, fn(x), such that all functions have “length” 1 and are orthogonal to one
other, as in the simple example of the vectors (1, 0), (0, 1) in the plane R2 or the
vectors i = (1, 0, 0), j = (0, 1, 0) and k = (0, 0, 1) in the space R3. We know
(see Eq.(2.22)) that any vector v = (v1, v2, v2) ∈R3 can be written as the linear
combination v = v1i + v2j + v3k. Furthermore, the components v1, v2, v3 satisfy the
relations:
v · i = v1,
v · j = v2,
v · k = v3,
(2.90)
which can be generalized to any orthonormal basis of n vectors in Rn. In other words,
the scalar product of any vector v with the ith basis vector, gives the magnitude of
the ith “coordinate” of v with respect to the ith “axis.” This result suggests other
analogous deﬁnitions and formulas, which we summarize in Table2.2.
According to the last row of the table, for the case of vectors in Rn, the equality
v = 
n
i=1 vie(i) has an obvious meaning. It implies that n orthonormal vectors do
form a basis on which we can expand any vector; we know that in order to have
such a basis we need two vectors in R2 or three vectors in R3, etc. What happens in
the Hilbert space L2(a, b)? There must then exist sequences of an inﬁnite number
of orthonormal functions. For example, if we take a = 0 and b = 2π, the following
functions:

2.4 The Hilbert Space of Real Wavefunctions
69
f1(x) =
1
√
2π
,
f2(x) = cos x
√π ,
f3(x) = sin x
√π ,
f4(x) = cos 2x
√π ,
f5(x) = sin 2x
√π ,
. . . ,
(2.91)
do form an orthonormal system in L2(0, 2π). The function f (x) is now represented
by an inﬁnite sum over these basis functions (this might be recognized as a Fourier
series):
f (x) =
∞

i=1
ci fi(x).
(2.92)
There remain questions of convergence and such, but we will not worry about
these. If, indeed, Eq.(2.92) does hold for some orthonormal system of functions,
such as the sequence (2.91), this set of functions is called complete and thereby
provides a basis for expanding any admissible function in the Hilbert space. Given
a function f (x), the coefﬁcients ci (for i = 1, 2, 3 . . .) are the best candidates to
be designated “coordinates” of the vector f; this interpretation has a more rigor-
ous foundation than the one we have introduced earlier, when we cited the values
f (x1), f (x2), . . . , f (xn). In Dirac’s formalism, the two interpretation can be uniﬁed
in an elegant (but not entirely rigorous) way, which is beyond the scope of our cov-
erage. The limit implied by the inﬁnite summation appearing in Eq.(2.92) must be
understood in the following sense: the Hilbert space distance |f −fn| between the
function fn(x) = 
n
i=1 ci fi(x) and the function f (x) tends to zero when n →∞.
Now that we have a better understanding of what the Hilbert space is, we can
further extend our analogy between vectors and functions, and ask: what are the
“matrices” or better the linear operators relevant to QM which act in the Hilbert
space L2(−∞, +∞), analogous to the way 2×2 matrices act on vectors in the plane?
Let us give two key examples of operators deﬁned in this Hilbert space (leaving aside
mathematical subtleties, that are treated, for example, in Fano 1971):
1. The operator that multiplies any function ψ(x) by the variable x. This operator
is the famous q operator of QM, which represents the position of a particle. The
result of the application of q to ψ is the function xψ(x), as follows:
(qψ)(x) = xψ(x),
(2.93)
where (qψ)(x) is the image function qψ computed at the point x. For example,
q maps xn into xn+1, sin x into x sin x, etc.
2. The operator that takes the derivative of a function ψ(x). Denoting this operator
by
d
dx , we write:
d
dx ψ(x) = dψ(x)
dx
.
(2.94)
This means that
d
dx maps xn into nxn−1, sin x into cos x, etc.

70
2
Mathematical Methods in Quantum Mechanics
Clearly, the operators q and
d
dx are linear. They satisfy the analog of Eq.(2.30).
Thus for
d
dx , since the derivative of the sum of two functions is the sum of the
derivatives, we have, for example,
d
dx ( f + g) = d
dx f + d
dx g.
(2.95)
The operators q and d
dx are of primary importance in QM, since the ﬁrst represents the
position of a particle, and the second is proportional to its momentum. An important
fact about these two operators, is that they do not commute. Let us denote by D the
operator
d
dx . For “any” function ψ(x)3 we have:
q Dψ = q d
dx ψ = x dψ
dx ,
D qψ =
d
dx qψ =
d
dx (xψ) = ψ + x dψ
dx .
(2.96)
Subtracting the two equations, we obtain, for “any” ψ, Dqψ −q Dψ = ψ, or:
Dq −q D = I.
(2.97)
Powers of the operators q and D are easy to compute. For example, the functions
q2 ψ and D2 ψ are:
q2ψ = x(xψ) = x2ψ,
D2ψ =
d
dx
d
dx ψ =
d2
d2x ψ.
(2.98)
2.5
Complex Variables
To extend our repertoire of mathematical proﬁciency, this section will review some
aspects of complex numbers and complex functions. (Our apologies to readers
already well versed in this subject.) Mathematicians deﬁne an algebraic structure
called a ﬁeld as a set of (usually) numbers, along with two operations, which can be
identiﬁed with addition and multiplication (subtraction and division are implicitly
included), and satisﬁes the associative and distributive laws. The most commonly
encountered ﬁelds are the real numbers, the rational numbers and, the subject of
this section, the complex numbers. Complex analysis turns out to be mandatory for
understanding the full mathematical structure of quantum mechanics. It is not strictly
necessary for classical mechanics or electrodynamics, although complex variables
can provide very useful enhancements to their mathematical formulation.
3The quotation marks refer to some mathematical conditions that the function ψ(x) must fulﬁll: in
essence, ψ must be differentiable almost everywhere and Dψ must remain in the Hilbert space.

2.5 Complex Variables
71
Fig. 2.14 The circle Γ and the straight line Σ do not intersect; therefore their equations admit no
simultaneous solution in the ﬁeld of real numbers
To begin, consider a circle Γ in the Cartesian plane and a straight line Σ lying
outside Γ (see Fig.2.14), for example, the circle with center at the origin and radius
1, represented by the equation
x2 + y2 = 1,
(2.99)
and the straight line represented by the equation:
x + y = 2.
(2.100)
The simultaneous equations for the circle Γ and the line Σ, Eqs.(2.99) and
(2.100), therefore do not have any real simultaneous solutions. Let us nevertheless
solve (2.100) for y, to get y = 2 −x, and substitute this into (2.99). We obtain
x2 + (2 −x)2 = 1; therefore:
2x2 −4x + 3 = 0.
(2.101)
The solutions of the quadratic equation ax2 + bx + c = 0 are:
x = −b ±
√
b2 −4ac
2a
.
(2.102)
In our case a = 2, b = −4, and c = 3. Thus
x = 4 ± √16 −24
4
= 2 ± √−2
2
.
(2.103)
The square root of a negative number appears. This appears contradictory: since the
square of a real number is always positive (for example (+2) × (+2) = +4 and
(−2) × (−2) = +4), the argument of a square root should always be a positive

72
2
Mathematical Methods in Quantum Mechanics
number. For many centuries, it was believed that roots of negative numbers have
no meaning, consistent with the nonexistence of points common to a circle and a
nonintersecting straight line. But in 1572, Rafael Bombelli in his book L’Algebra,
gave meaning to the expression √−1.
We will denote √−1 by the usual symbol i and call it the imaginary unit. Thus,
by deﬁnition i2 = −1, and (2.103) becomes x = 2±
√
2 i
2
We are now dealing with a
new kind of numbers, which we call complex numbers. If z = a + ib, with a and b
real; a is called the real part and b the imaginary part of z. (In the above case a = 1
and b = ±
√
2
2 ). Complex numbers have the following properties:
(1) a + ib = c + id if and only if a = c and b = d.
(2) (a + ib) + (c + id) = (a + c) + i(b + d).
(3) (a + ib)(c + id) = ac −bd + i(ad + bc).
The multiplication law (3) is consistent with the usual properties of real numbers
with the addition of a new rule: i2 = −1. Furthermore, Items (1) and (2) suggest a
representation of the complex number x + iy by the vector (x, y) in the Cartesian
plane R2. The x-axis now serves as the real axis, while the y-axis is the imaginary
axis, since it consists of points of type (0, y). The x-y plane is now called the
complex plane or an Argand diagram. Figure2.15 shows the vector corresponding to
the complex number z = a + ib, while Fig.2.16 shows the vector corresponding to
the complex number −z = −a −ib. Item (2) above implies that the parallelogram
rule applies to the sum of two complex numbers (see Fig.2.17).
A suggestive property is the following: if we multiply the complex number a +ib
times the imaginary unit i, the corresponding vector is rotated by π
2 (90 degrees).
Indeed the complex number i(a + ib) = −b + ia corresponds to the vector (−b, a)
which is rotated by π
2 with respect to (a, b) (see Fig.2.18). The “vectors” i, i2 = −1,
i3 = −i, i4 = +1 are related by successive rotations by π
2 (see Fig.2.19). The
complex conjugate z∗(alternatively written z in many texts) of the number z = a+ib
Fig. 2.15 Identiﬁcation of the complex number a + ib with the point (a, b) in the Cartesian plane

2.5 Complex Variables
73
Fig. 2.16 Identiﬁcation of the complex number −z = −a −ib with the point (−a, −b) of the
Cartesian plane
Fig. 2.17 The parallelogram’s rule holds for the sum of two complex numbers a + ib and c + id
Fig. 2.18 The complex number i(a + ib) = −b + ia corresponds to the vector (−b, a) which is
rotated by 90 degrees with respect to (a, b)
is deﬁned as z∗= a −ib. Notice that a + ib and a −ib are symmetric with respect
to reﬂection in the real axis (see Fig.2.20). Clearly, (a −ib)∗= a + ib, so that
(z∗)∗= z. If we multiply a + ib times its complex conjugate a −ib, we obtain the
square of the length of the vector (a, b); indeed,
(a + ib)(a −ib) = a2 −iab + iab + b2 = a2 + b2.
(2.104)
The modulus r of the complex number a +ib is deﬁned as its length, r =
√
a2 + b2.
If θ denotes the angle measured counterclockwise from the real axis to (a, b), we

74
2
Mathematical Methods in Quantum Mechanics
Fig. 2.19 The complex numbers i, i2, i3, i4, correspond, respectively, to the points (0, 1), (−1, 0),
(0, −1), (1, 0). This is a simple example of a cyclic group (designated Z4)
Fig. 2.20 The complex conjugate a −ib of a + ib can be obtained by reﬂection through the real
axis
have (see Fig.2.15):
a = r cos θ,
b = r sin θ.
(2.105)
Thus
z = a + ib = r(cos θ + i sin θ).
(2.106)
The angle θ is called argument of z. The real numbers r and θ uniquely determine the
complex number z. For example, if r = 1 and θ = π
4 (45 degrees), z =
1
√
2(1+i). In
general, complex numbers of modulus 1 are represented by points on the unit circle
(with center at the origin and radius 1). For z = a + ib, the angle θ is given by:
θ = arctan b
a ,
(2.107)
with θ determined up to multiples of 2π (360 degrees). For example, the pair r, θ
and the pair r, θ + 2π correspond to the same complex number.
The following very useful and beautiful formula can be used in place of (2.106):
z = a + ib = reiθ,
(2.108)

2.5 Complex Variables
75
Fig. 2.21
eiθ z can be obtained from z by rotation by the angle θ
where e is Euler’s constant, e = 2.7182818 . . . (the base of natural logarithms). The
usual algebraic properties of the exponential function: e0 = 1, eaeb = ea+b, e−a =
1/ea, etc., still hold even when the exponent is imaginary or complex. However,
the corresponding geometric representation is entirely different from the real case. A
complex number eiθ can alternatively be regarded as an operator. Given the complex
number z = reiϕ, eiθz = zeiθeiϕ = rei(θ+ϕ) is a number with the same modulus r
but a new argument ϕ + θ (see Fig.2.21). The factor eiθ “rotates” z by an angle θ,
similar to the way an orthogonal matrix, such as Eq.(2.28) rotates a two component
vector.
2.6
Complex Vector Spaces and Dirac Notation
In order to make our development as simple as possible up to now, we have consid-
ered only real vector spaces, totally avoiding complex numbers. However, complex
quantities turn out to be mandatory for complete understanding of the fundamental
equations of QM, in particular, the Schrödinger equation itself. We have already
noted that in QM, the operator D is proportional to the momentum p = mv of a
particle. In fact, the proportionality factor is −iℏ, where i = √−1, the imaginary
unit. We will also, in this section, be introducing Dirac’s bra/ket notation, invented
in 1939 by P.A.M. Dirac (1958), one of the founding fathers of quantum mechanics.
This is now a standard notation for describing quantum states, using angle brackets
and vertical bars to represent abstract vectors and linear operations. The notation has
also become popular in other mathematical applications.
We denote by Cn the set of the ordered n-tuples (z1, z2, . . . , zn) of complex num-
bers. An element z = (z1, z2, . . . , zn) of such a set is now what we designate a
vector. Thus, for n = 2, a vector (z1, z2) = (x1 + iy1, x2 + iy2) of C2 is determined
by 4 real numbers. In the following, unless explicitly stated, we will consider the

76
2
Mathematical Methods in Quantum Mechanics
complex space C2. In Dirac notation, a vector z = (z1, z2) will be denoted by |z⟩, in
place of z. The null vector |0⟩is the vector with all components equal to zero. There-
fore, in Cn, |0⟩= (0, 0, . . . , 0). Dirac denoted vectors, such as |ψ⟩, representing
quantum states, as “kets.” Adjoint vectors (associated with the complex conjugate
of a wavefunction), such as ⟨φ|, were called “bras.” The product of a bra and a ket is
a bracket, representing a scalar product ⟨φ|ψ⟩. This connects with the notation we
have already introduced for scalar products.
In C2 space, all the familiar linear properties still apply,. The linear combination
z = a|u⟩+ b|v⟩is, in general, constructed with complex a, b. We can visualize the
sum |z⟩= |u⟩+ |v⟩as in Fig.2.2, but to determine |z⟩now requires 4 real numbers
(although our physical space remains R3, not R4). For example, if u1 = 1 + i,
u2 = 2 + 3i, v1 = 1 −2i, v2 = 3 −2i, then |u⟩+ |v⟩= (2 −i, 5 + i). The scalar
product used in quantum mechanics is a generalization of the form of Eqs.(2.11) and
(2.18), used in real spaces. Instead, an Hermitian scalar product is deﬁned in Cn, as
follows:
Deﬁnition 2.1 Given two vectors |z⟩= (z1, z2, . . . , zn), |w⟩= (w1, w2, . . . , wn),
the Hermitian scalar product ⟨z|w⟩(sometimes written ⟨z|w⟩H) is deﬁned by:
⟨z|w⟩= z∗
1 w1 + z∗
2 w2 + . . .
(2.109)
Clearly, if |z⟩, |w⟩have only real components, ⟨z|w⟩reduces to z · w. The Hermitian
scalar product is not necessarily symmetrical: ⟨z|w⟩is not, in general, equal to ⟨w|z⟩.
Instead:
⟨v|u⟩= ⟨u|v⟩∗.
(2.110)
The norm or length |u| of a vector |u⟩is deﬁned by a formula analogous to Eqs.(2.8)
and (2.9):
|u| = +

⟨u|u⟩.
(2.111)
It is still, of course, a nonnegative real number. It is also easy to verify that |u| = 0,
if and only if |u⟩= |0⟩. The Hermitian scalar product ⟨u|v⟩is linear with respect to
|v⟩, but antilinear with respect to ⟨u|, thus,
⟨u|cv⟩= c⟨u|v⟩,
⟨cu|v⟩= c∗⟨u|v⟩,
(2.112)
and
⟨u|v + w⟩= ⟨u|v⟩+ ⟨u|w⟩.
(2.113)
The notion of orthonormal basis can be extended. The vectors u, v form an ortho-
normal basis in C2 if they are of unit length and orthogonal:
⟨u|u⟩= ⟨v|v⟩= 1,
⟨u|v⟩= 0.
(2.114)

2.6 Complex Vector Spaces and Dirac Notation
77
The deﬁnition of the scalar product, as integrals over complex-valued functions,
must be generalized from the form of Eq.(2.83). Using Dirac notation and extending
the integration over the whole real axis, we now write
⟨f |g⟩=
 +∞
−∞
f (x)∗g(x) dx.
(2.115)
If | f | and |g| are ﬁnite, the scalar product ⟨f |g⟩is also ﬁnite, as implied by the
Cauchy–Schwarz inequality:
| f | |g| ≥|⟨f |g⟩|.
(2.116)
In our toy Hilbert space R2, the Cauchy–Schwarz inequality follows simply from
| cos φ| ≤1 in Eq.(2.10).
The generalization of matrices to the complex ﬁeld is straightforward. All the
matrix formulas in Sect.2.2 remain valid, with the real numbers replaced by complex
numbers. A very important operation for complex n × n matrices, leading to the
deﬁnition of the adjoint matrix, can deﬁned as follows:
Deﬁnition 2.2 Given an operator A, represented in an orthonormal basis by the
matrix Ai j, the operator whose matrix is obtained by taking the complex conjugate
and interchanging rows and columns is called the adjoint of A, denoted by A†. Thus:
A†
i j = A∗
ji (i, j = 1, 2, . . . , n).
(2.117)
The adjoint has the following properties:
(AB)† = B†A†,
(A†)† = A,
(A + B)† = A† + B†,
(cA)† = c∗A†,
(2.118)
where c is a complex number. The identity is the operator I such that I|x⟩= |x⟩
for any |x⟩. The matrix representing the identity has all elements along the main
diagonal equal to 1, and 0 everywhere else (the same as for real matrices).
The adjoint operation allows us to move an operator from one side of a scalar
product to the other, by virtue of the following Theorem:
Theorem 2.2 For every pair of vectors |x⟩, |y⟩and every operator A the following
relations hold:
⟨y|Ax⟩= ⟨A†y| x⟩,
⟨Ay|x⟩= ⟨y|A†x⟩.
(2.119)

78
2
Mathematical Methods in Quantum Mechanics
The proof of the ﬁrst equality follows from the sequence of operations:
⟨A†y|x⟩= ⟨x|A†y⟩∗=

k
x∗
k (A†y)k
∗
=

k
x∗
k

i
A†
ki yi
∗
=

k

i
x∗
k A∗
ik yi
∗
=

i,k
xk Aik y∗
i = ⟨y|Ax⟩.
(2.120)
The second equality follows from the ﬁrst, since (A†)† = A. The relations (2.119)
are easy to verify explicitly for the case n = 2.
Recall that rotations leave the lengths of real vectors invariant. What are the
corresponding linear operators that leave the lengths of complex vectors in C2 or Cn
invariant? The answer is unitary operators.
Deﬁnition 2.3 An operator U is called unitary if
U U † = U †U = I,
(2.121)
where, as usual, I denotes the identity.
A unitary operation leaves invariant the scalar product of two vectors |x⟩, |y⟩, since,
using (2.119), we have:
⟨Ux|Uy⟩= ⟨x|U †Uy⟩= ⟨x|I y⟩= ⟨x|y⟩.
(2.122)
Thus the norm (or length) of a vector is left invariant by a unitary transformation.
The correct generalization of ordinary rotations of vectors (which are generated by
orthogonal matrices) are thus unitary operations on complex vectors. Our tentative
postulate was that dynamical variables are represented by symmetric matrices; more
generally, these should be Hermitian matrices. A matrix Hi j (i, j = 1, 2 . . . , n) is
Hermitian (or self-adjoint) if H = H †, so that its elements are related by
Hi j = H ∗
ji (i, j = 1, 2, . . . , n).
(2.123)
For example, if n = 2, H11 and H22 are real, and H21 = H ∗
12. Thus, the matrix


3
1 + i
1 −i
4


(2.124)
is Hermitian. If H is both Hermitian and real, it is again simply a symmetric matrix.
Hermitian matrices admit an orthonormal basis of eigenvectors, just like symmet-
ric matrices in the real case. Furthermore, the eigenvalues of an Hermitian matrix H
are real; indeed, taking the scalar product of both sides of the equation
H|x⟩= λ|x⟩
(2.125)

2.6 Complex Vector Spaces and Dirac Notation
79
by the eigenvector |x⟩we obtain:
⟨x|H|x⟩= λ⟨x|x⟩,
λ = ⟨x|H|x⟩
⟨x|x⟩.
(2.126)
and by (2.110), we have:
⟨x|H|x⟩∗= ⟨x|H †|x⟩= ⟨x|H|x⟩.
(2.127)
Thus, both numerator and denominator of (2.126) are real, therefore the eigenvalue
λ must be real. The matrix (2.124) has the eigenvectors |u⟩=

1+i
√
3 , −1
√
3

, |v⟩=
 1+i
2 , 1

, thus
H|u⟩= 2|u⟩,
H|v⟩= 5|v⟩,
⟨u|v⟩= 0.
(2.128)
Two Hermitian matrices A, B admit a common basis of eigenvectors, if and only if
they commute, that is, if

A, B

= 0 or A B = B A. We omit the simple proof of these
results for Hermitian matrices. We note that the fundamental interpretative postulate
of QM (Postulate 1) is generalized with the simply substitution of “Hermitian” for
“symmetric.”
Observables are represented in QM by Hermitian matrices (more precisely, linear
Hermitian operators), and states of a physical system by real or complex vectors. Of
course, the case of two component vectors or spinors is the simplest (see Chap.4).
However, as noted above, the Hilbert space of realistic physical systems is usually
inﬁnite dimensional.
2.7
Coordinates and Momenta in Quantum Mechanics
We have seen in Chap.1 that de Broglie’s formula associates a “matter wave” with
the rectilinear motion of a particle, with a wavelength λ = h/mv = h/p, where m
is the mass, v the velocity and p the momentum of the particle. Accordingly, let us
consider a very general instance of wave motion propagating in the x-direction. At
a given instant of time, a periodic wave with wavelength λ might be represented by
a function of the form
ψ(x) = f
2πx
λ
	
,
(2.129)
where f (θ) is most often a sinusoidal function such as sin θ, cos θ, e±iθ, or some
linear combination of these. Each of these is a periodic function, its value repeating
every time its argument increases by 2π. This happens when x increases by one
wavelength λ. The most useful form will turn out to be the complex exponential,
which is related to the sine and cosine by Euler’s formulaeiθ = cos θ + i sin θ. We

80
2
Mathematical Methods in Quantum Mechanics
consider the wavefunction
ψ(x) = ei2πx/λ,
(2.130)
apart from an arbitrary multiplicative constant. The wavelength λ of this complex-
valued wavefunction can be replaced by h/p, where p is the particle momentum, in
accordance with the de Broglie formula. Thus,
ψ(x) = ei2πpx/h = eipx/ℏ,
(−∞< x < ∞),
(2.131)
where ℏ≡h/2π. Since Planck’s constant occurs in most formulas with the denom-
inator 2π, this symbol, pronounced “aitch-bar,” was introduced by Dirac in 1930.
Now that we have a mathematical representation of a matter wave, we should
next try to ﬁnd a “wave equation,” a differential equation which the wavefunction
satisﬁes. As a ﬁrst step let us apply the operator D =
d
dx to Eq.(2.131). We ﬁnd
d
dx ψ(x) = ip
ℏψ(x),
(2.132)
which can be rearranged to
−iℏd
dx ψ(x) = pψ(x).
(2.133)
This can be recognized as an eigenvalue equation (see Eqs.2.50 and 2.125) for the
x-component of momentum px:
pxψ(x) = pψ(x),
(2.134)
with the momentum operator evidently given by
px = −iℏd
dx .
(2.135)
This, incidentally, conﬁrms our earlier speculation that the operator D =
d
dx is
proportional to the velocity v (hence the momentum p) of a particle. In Dirac notation,
the eigenvalue equation can be written
px|ψ⟩= p |ψ⟩.
(2.136)
Evidently, an eigenvalue p = mv for a free particle, can be any real number:
−∞< p < ∞. This is a continuous spectrum of eigenvalues, in contrast to the
energy levels of a bound atom or molecule, which was a distinguishing feature in
the early development of quantum theory. Actually, highly excited states of atoms or
molecules, in which ionization or dissociation has occurred, also show a continuum
of energy eigenvalues. The momentum eigenfunctions ψ(x) are complex-valued

2.7 Coordinates and Momenta in Quantum Mechanics
81
(except when p = 0). If ψp(x) = eipx/ℏand ψp′(x) = eip′x/ℏrepresent eigenstates
with different eigenvalues, p and p′, respectively, then the corresponding eigen-
functions are orthogonal. This can be shown by an intuitive (although not entirely
mathematically rigorous) argument:
⟨p|p′⟩=
 +∞
−∞
ψp(x)∗ψp′(x) dx =
 +∞
−∞
ei(p′−p)x/ℏdx =
 +∞
−∞

cos

(p′ −p)x/ℏ

+ i sin

(p′ −p)x/ℏ

dx = 0 (p′ ̸= p).
(2.137)
In the last line, the inﬁnite number of positive and negative contributions to the sine
or the cosine integrals cancel each other out to give a result of zero.
The Hilbert space L2(−∞, +∞) appropriate for QM is a set of complex valued
functions ψ(x) such that the following integral is ﬁnite:
 +∞
−∞
ψ(x)∗ψ(x) dx =
 +∞
−∞
|ψ(x)|2 dx < ∞.
(2.138)
An apparent disaster occurs when we try to evaluate Eq.(2.138) using a momen-
tum eigenfunction (2.131). With ψ(x) = eipx/ℏ, the complex conjugate is ψ(x)∗=
e−ipx/ℏ. Thus ψ(x)∗ψ(x) = |ψ(x)|2 = 1 and
 +∞
−∞1 dx = ∞, violating the condi-
tion for a valid Hilbert space. There are several ways that we can talk our way out of
this difﬁculty.
(1) We might limit our consideration to quantum systems with bound states, for
which wavefunctions conforming to (2.138) can always be found. This could be
done, for example, by replacing the inﬁnite domain −∞< x < ∞by a ﬁnite inter-
val −a ≤x ≤a. This excludes the free particle, Eq.(2.131), despite the fact that
this system has been so fundamental in deriving some essential results in QM.
(2) We recognize that for a system in a momentum eigenstate, the probability den-
sity function |ψ(x)|2 = 1 for all values of x, −∞< x < ∞(even beyond the
bounds of the known Universe!). This is in accord with the uncertainty principle,
since a precisely known momentum p implies a completely indeﬁnite position x.
More realistically, a free particle should be described by a wavepacket, which is a
superposition of momentum eigenstates ψp(x) of the form
ψ(x) =

φ(p)ψp(x) dp.
(2.139)
Then the integral (2.138) converges, provided that

|φ(p)|2 dp is ﬁnite.
(3) Hilbert space is redeﬁned to accommodate continuous spectra and divergent
integrals. Dirac himself was aware that “the bra and ket vectors that we now use
form a more general space than a Hilbert space.” A modern extension, known as

82
2
Mathematical Methods in Quantum Mechanics
rigged Hilbert space4 has the desired structure (the term “rigged” here implies
“well-equipped and ready for action”). A “conventional” Hilbert space can accom-
modate a denumerably inﬁnite number of basis vectors, labeled, for example, by
n = 1, 2, 3, . . . . But, in a rigged Hilbert space, the number of basis vectors can be
nondenumerably inﬁnite, labeled, perhaps by indices with a continuum of allowed
values, such as ν, with −∞< ν < ∞.
Fortunately, we can carry on, using naive conventional Hilbert space, knowing
that the mathematicians (however reluctantly) have us well covered regarding any
inconsistencies or complications. As an illustrative example, consider the scalar
product of eigenstates. For the discrete spectrum, we have
⟨m|n⟩=
 +∞
−∞
ψm(x)∗ψn(x) dx = δm,n,
(2.140)
where δm,n is the Kronecker delta, equal to 1 for m = n and 0 for m ̸= n. For
eigenstates belonging to a continuous spectrum, we can write
⟨μ|ν⟩=
 +∞
−∞
ψμ(x)∗ψν(x) dx = δ(μ −ν).
(2.141)
We have already seen that ⟨μ|ν⟩= 0 for μ ̸= ν (Eq.(2.137)). We have also found
that ⟨ν|ν⟩= ∞for μ = ν. But Dirac here introduced a special kind of inﬁnity, as
represented by the delta function, δ(μ −ν).
The Dirac delta function was intended as the continuum analog of the Kronecker
delta. It is, however, not a true function in the mathematical sense, but rather a
generalized function or distribution. The delta function was regarded with much
disdain by mathematicians, until a rigorous theory was proposed by Laurent Schwartz
in 1950.5 It is deﬁned as a hypothetical “function” such that δ(x −a) = 0, if x ̸= a,
and δ(x −a) = ∞, if x = a. However, the inﬁnite value is somewhat special:
an integral over that singular point is presumed to equal 1. Intuitively, the delta
function can be pictured as the limit of a distribution with integrated area 1, of
inﬁnitesimal width but very large height, centered around the point x = a. The
delta function is presumed to satisfy the integral relations:
 +∞
−∞δ(x −a) dx = 1
and
 +∞
−∞f (x)δ(x −a) dx = f (a). To physicists, the delta function is invaluable
for representing idealized objects such as point masses and point charges and for
constructing Green’s functions.
The eigenvalues and eigenvectors of the position operator q are rather tricky,
but, fortunately, rarely needed. A particle localized around a point x = a might be
represented by a delta function: ψ(x) = δ(x−a). The relation xδ(x−a) = aδ(x−a)
can then be interpreted as an eigenvalue equation xψ(x) = aψ(x). As a consequence
4R de la Madrid (2005), The role of the rigged Hilbert space in Quantum Mechanics, Eur J Phys
26:287–312.
5Schwartz L (1950–51) Théorie des distributions, Hermann, Paris. See also: Lighthill MJ (1958)
An Introduction to Fourier Analysis and Generalised Functions. Cambridge University Press.

2.7 Coordinates and Momenta in Quantum Mechanics
83
of the uncertainty principle, a particle with an exactly known value of x, has a totally
undetermined value of px, the possible values being spread over −∞< p < ∞.
The commutators of components of position and momentum are of central impor-
tance in the formalism of QM. Let us ﬁrst evaluate

x, px

= x px −px x, where
px = −iℏd
dx . These operators have meaning only when applied to a function of x,
say φ(x). Now,

x, px

φ(x) = x(−iℏ) d
dx φ(x) −(−iℏ) d
dx

xφ(x)

= iℏdx
dx φ(x) = iℏφ(x),
(2.142)
in which we have taken the derivative of a product xψ(x) and simpliﬁed by cance-
lation. Since the function φ(x) is arbitrary, we can abstract the operator relation

x, px

= iℏ.
(2.143)
Obvious analogs of Eq.(2.135) for the y- and z-components of momentum are
py = −iℏd
dy ,
pz = −iℏd
dz .
(2.144)
It is then simple to derive the analogous commutation relations:
[y, py] = iℏ,
[z, pz] = iℏ.
(2.145)
Since x commutes with pz, etc., and the different components of position commute
with one another, as do the different components of momentum, we can collect the
entire set of commutation relations in the following compact form:
[qi, q j] = [pi, p j] = 0,
[qi, p j] = iℏδi, j,
(2.146)
where i, j = 1, 2, 3 and q1 = x, p1 = px, etc.
2.8
Heisenberg Uncertainty Principle
The Heisenberg uncertainty principle is a fundamental consequence of the noncom-
mutativity of position and momentum operators. Let us consider the one-dimensional
case with x and px, which we write simply as p. The average, mean or expectation
variable of a dynamical variable A in a quantum state |Ψ ⟩is written
A = ⟨Ψ |A|Ψ ⟩.
(2.147)
The mean square deviation from the mean is then given by

84
2
Mathematical Methods in Quantum Mechanics
(ΔA)2 = ⟨Ψ |(A −A)2|Ψ ⟩,
(2.148)
where ΔA is the root mean square, which is designated as the uncertainty in A. Now
deﬁne two functions
f = (x −x)Ψ,
and
g = i(p −p)Ψ.
(2.149)
We then ﬁnd
⟨f | f ⟩= ⟨(x −x)Ψ |(x −x)Ψ ⟩= ⟨Ψ |(x −x)2|Ψ ⟩= (Δx)2,
(2.150)
and, analogously,
⟨g|g⟩= ⟨i(p −p)Ψ |i(p −p)Ψ ⟩= ⟨Ψ |(p −p)2|Ψ ⟩= (Δp)2.
(2.151)
Next, let us evaluate:
⟨f |g⟩+ ⟨g| f ⟩= ⟨Ψ |(x −x)i(p −p) −i(p −p)(x −x)|Ψ ⟩.
(2.152)
After some cancelation, we ﬁnd
⟨f |g⟩+ ⟨g| f ⟩= i⟨Ψ |

x, p

|Ψ ⟩= −ℏ,
(2.153)
recalling the commutation relation

x, p

= iℏ. From the Cauchy–Schwarz inequal-
ity, Eq.(2.116),

⟨f | f ⟩)

⟨g|g⟩) ≥
⟨f |g⟩
.
(2.154)
Finally, we arrive at the Heisenberg uncertainty principle:
Δx Δp ≥ℏ
2.
(2.155)
This implies that exact values of a position variable and its conjugate momentum
cannot be simultaneously known. Thus the trajectories of Bohr orbits are illusory:
quantum behavior is not deterministic with regard to classical variables.

Chapter 3
The Schrödinger Equation
Abstract The Schrödinger equation is introduced and applied to some elemen-
tary problems: particle-in-a box, harmonic oscillator, angular momentum, and the
hydrogen atom. The representation of eigenfunctions and eigenvalues is discussed,
employing linear operators and matrices. The quantum theory of spin, as well as the
Pauli exclusion principle, are described. These enable a theoretical understanding of
atomic structure and the periodic table. The two disparate modes of time-dependence
of a quantum system–unitary evolution and collapse of the wavefunction–are con-
trasted.
Keywords Schrödinger equation · spin · eigenfunctions and eigenvalues · atomic
structure · evolution operator · collapse of the wavefunction
3.1
Heuristic Derivation
The Schrödinger equation, like Newton’s equations of motion, expresses a funda-
mental law of nature and cannot, in the usual sense, be derived. The best we can do
is to offer a heuristic argument to make the Schrödinger equation appear plausible.
In Sect.2.7, we sought a wave equation to describe de Broglie matter waves. We
found there that a one-dimensional wave for a particle of wavelength λ, at a single
instant of time, can be represented by a complex exponential ψ(x) = exp(2πix/λ).
We consider now the time dependence of the wave. At a ﬁxed point x in space, the
wave will also be sinusoidal in time, with a frequency ν. This can be represented
by a sinusoidal function, which we again choose as a complex exponential, now,
exp(−2πiνt). This is now periodic in the time T = 1/2πν, which is known as the
period of the oscillation. The product of the x and t functions will evidently represent
both the space and time variation of a matter wave1:
Ψ0(x, t) = exp
2πix
λ

× exp(−2πiνt) = exp

2πi
x
λ −νt

.
(3.1)
1We choose the negative exponential for the time factor since the scalar product of the relativistic
4-vectors (ct, x1, x2, x3) and (E/c, p1, p2, p3) gives Et −p · x.
© Springer International Publishing AG 2017
G. Fano and S.M. Blinder, Twenty-First Century Quantum Mechanics:
Hilbert Space to Quantum Computers, UNITEXT for Physics,
DOI 10.1007/978-3-319-58732-5_3
85

86
3
The Schrödinger Equation
The next step is to replace the wavelike variables λ and ν by particle variables, as
given by the de Broglie and Planck–Einstein formulas: λ = h/p and ν = E/h,
respectively. Introducing ℏ= h/2π again, we obtain
Ψ0(x, t) = exp
 i
ℏ(px −Et)
	
,
(3.2)
as the wavefunction of a free particle (as indicated by the subscript 0). As we saw in
the last chapter, taking the x-derivative of (3.2) gives
∂
∂x Ψ0(x, t) = i
ℏp exp
 i
ℏ(px −Et)
	
= i
ℏp Ψ0(x, t),
(3.3)
whichsuggeststhedeﬁnitionofamomentumoperator(p means px inonedimension)
px = −iℏ∂
∂x .
(3.4)
Now that we have time dependence, we can also consider the time derivative
∂
∂t Ψ0(x, t) = −i
ℏE exp
 i
ℏ(px −Et)
	
= i
ℏE Ψ0(x, t).
(3.5)
This suggests an “energy operator”
E = iℏ∂
∂t .
(3.6)
The energy of a particle of mass m in classical mechanics is equal to the sum of
its kinetic and potential energies. In one dimension, as a function of position and
velocity,
E = 1
2mv2 + V (x)
(3.7)
Energy expressed as a function of position and momentum, using p = mv, is more
directly applicable in quantum mechanics. This function is called the Hamiltonian,
H(x, p). We can write
E = p2
2m + V (x) = H(x, p).
(3.8)
Suppose we now promote (3.8) to an operator equation, replacing E and p (px)
using (3.6) and (3.4), and apply it to a wavefunction Ψ (x, t) (more general than a
free particle). Note that the operator for the square of the momentum is given by:
p2 = −iℏ∂
∂x

−iℏ∂
∂x

= −ℏ2 ∂2
∂x2 .
(3.9)
The potential energy function V (x) can be treated as simply a multiplicative operator.
Thereby we can transform (3.8) to a wave equation:

3.1 Heuristic Derivation
87
iℏ∂Ψ
∂t = −ℏ2
2m
∂2Ψ
∂x2 + V (x)Ψ.
(3.10)
We have thereby arrived at the one-dimensional time-dependent Schrödinger equa-
tion (TDSE).
The generalization for a particle in three dimensions is fairly straightforward.
Note ﬁrst that the momentum is a 3-component vector, so that p2 = p2
x + p2
y + p2
z
and the corresponding operator is given by
p2 = −ℏ2
 ∂2
∂x2 + ∂2
∂y2 + ∂2
∂z2

= −ℏ2∇2,
(3.11)
where ∇2 is the Laplacian operator, also called “del-squared.” The potential energy
can now be a function of three variables, V (x, y, z), written more compactly as V (r).
We can now extend the TDSE for a particle moving in three dimensions:
iℏ∂Ψ
∂t = −ℏ2
2m ∇2Ψ + V (r)Ψ.
(3.12)
In terms of the Hamiltonian operator H, the TDSE for a quantum system of any
complexity can be expressed in the very compact form:
iℏ∂Ψ
∂t = HΨ.
(3.13)
The subsidiary conditions placed on the wavefunction Ψ are that it be ﬁnite, single-
valued and continuous (collectively designated as well behaved). This famous and
very fundamental equation is the starting point for most computational applications
of quantum mechanics.
In many practical applications, including most of our subsequent development, we
encounter a quantum system in a stationary state, meaning that it has no observable
variation with time. If the potential energy V is independent of t, the Schrödinger
equation (3.12) can be separated into two independent differential equations involv-
ing the space and time coordinates. This follows if the wavefunction can be written
Ψ (r, t) = ψ(r)T (t). Putting this into (3.12), then dividing by ψ(r)T (t), we obtain
iℏ∂T (t)
∂t
T (t)
= −ℏ2
2m ∇2ψ(r) + V (r)ψ(r)
ψ(r)
= K.
(3.14)
The left-hand side of the equation is a function of t alone, while the right-hand side
is a function only of r. The only way for the equality to be valid is for both sides to
be equal to a constant, say K. We now have two separate equations for the functions
T (t) and ψ(r). The ﬁrst of these can be written out as
iℏdT (t)
dt
= K T (t).
(3.15)

88
3
The Schrödinger Equation
This differential equation is readily solved to give T (t) = exp(−i Kt/ℏ), which
corresponds exactly to the time factor in Ψ0(x, t), Eq. (3.2), provided that the sepa-
ration constant K is identiﬁed as the energy E. The equation for ψ(r) in (3.14) then
becomes the time-independent Schrödinger equation (TISE):
−ℏ2
2m ∇2ψ(r) + V (r)ψ(r) = E ψ(r).
(3.16)
The quantum mechanical Hamiltonian operator H, corresponding to the classical
Hamiltonian function
H(r, p) = p2
2m + V (r)
(3.17)
(compare Eq.3.8), can be written
H = −ℏ2
2m ∇2 + V (r).
(3.18)
Thus the TISE has the form of an eigenvalue equation
Hψ(r) = E ψ(r),
(3.19)
where the eigenvalues of the Hamiltonian evidently correspond to the allowed ener-
gies of the quantum system.
For a system in a stationary state, the complete wavefunction has the form
Ψ (r, t) = ψ(r)e−i Et/ℏ, where the time dependence simply contributes a phase factor
of modulus 1.
3.2
Particle in a Box
In this section and the next, we will consider solutions of the one-dimensional time-
independent Schrödinger equation
−ℏ2
2m ψ′′(x) + V (x)ψ(x) = Eψ(x),
(3.20)
where, in the usual notation, ψ′(x) = dψ
dx and ψ′′(x) = d2ψ
dx2 . For a free particle,
with V (x) = 0, the momentum eigenfunctions ψ0(x) = exp(ipx/ℏ) are solutions
to (3.20). The corresponding energy eigenvalues are E = p2/2m, just as in classical
mechanics. Since −∞< p < ∞, the allowed energy values belong to a continuum,
with 0 ≤E < ∞.
The particle in a box is the simplest nontrivial application of the Schrödinger
equation, but one which illustrates many of the fundamental concepts of quantum

3.2 Particle in a Box
89
mechanics. Assume that a particle can move freely between two endpoints x = 0 and
x = a, but cannot penetrate either end. This can be represented by a potential energy
V (x) =

0
if
0 ≤x ≤a
∞
if
x < 0 or x > a
(3.21)
Inﬁnite potential energy constitutes an impenetrable barrier. The particle is thus
bound in a potential well, as represented by the dark lines in Fig.3.1.
Since the particle cannot penetrate beyond x = 0 or x = a, we must have
ψ(x) = 0 for x < 0 and x > a. By the requirement that the wavefunction be
continuous, it must be true as well that
ψ(0) = 0 and ψ(a) = 0,
(3.22)
which constitutes a pair of boundary conditions on the wavefunction within the box.
Inside the box, V (x) = 0, so the Schrödinger equation reduces to the free particle
form. It is convenient to lump together the constants and write
ψ′′(x) + k2ψ(x) = 0,
(3.23)
where
k2 = 2mE
ℏ2
(3.24)
The general solution to Eq. (3.23) can be written
ψ(x) = A sin kx + B cos kx,
(3.25)
where A and B are constants to be determined by the boundary conditions (3.22).
By the ﬁrst condition, we ﬁnd ψ(0) = A sin 0 + B cos 0 = B = 0, which reduces
the solution to
ψ(x) = A sin kx.
(3.26)
The second boundary condition at x = a then implies ψ(a) = A sin ka = 0. It is
assumed that A ̸= 0, for otherwise ψ(x) would be zero everywhere and the particle
would disappear. The condition that sin kx = 0 implies that
ka = nπ,
(3.27)
where n is a positive integer (n = 0 again gives ψ(x) = 0). Eliminating k between
(3.27) and (3.24), we obtain
En = ℏ2k2
2m = ℏ2π2n2
2ma2
=
h2
8ma2 n2
(3.28)

90
3
The Schrödinger Equation
Fig. 3.1 Potential well and
lowest energy levels for
particle in a box
These are the only values of the energy which allow solution of the Schrödinger
equation (3.23) consistent with the boundary conditions (3.22). The integer n, called
a quantum number, is appended as a subscript on E to label the allowed energy levels.
Figure3.1 shows an energy-level diagram for the particle in a box. The occurrence
of discrete or quantized energy levels is characteristic of a bound system, that is, one
conﬁned to a ﬁnite region in space. For the free particle, the absence of conﬁnement
gave rise to an energy continuum. Note that, in both cases, the number of energy
levels is inﬁnite—denumerably inﬁnite for the particle in a box but nondenumerably
inﬁnite for the free particle.
The particle in a box assumes its lowest possible energy when n = 1, namely
E1 =
h2
8ma2
(3.29)
The state of lowest energy for a quantum system is termed its ground state. An inter-
esting point is that E1 > 0, whereas the corresponding classical system would have
a minimum energy of zero. This is a recurrent phenomenon in quantum mechanics.
The residual energy of the ground state, that is, the energy in excess of the classical
minimum, is known as zero point energy. In effect, the kinetic energy, hence the
momentum, of a bound particle cannot be reduced to zero. The minimum value of
momentum is found by equating E1 to p2/2m, giving pmin = ±h/2a. This can be
expressed as an uncertainty in momentum given by p ≈h/a. Coupling this with
the uncertainty in position, x ≈a, the size of the box, we can write xp ≈h,
which is in qualitative accord with the Heisenberg uncertainty principle.

3.2 Particle in a Box
91
The particle-in-a-box eigenfunctions are given by Eq. (3.26), with k = nπ/a, in
accordance with (3.27). This gives
ψn(x) = A sin
nπx
a

,
n = 1, 2, 3, . . .
(3.30)
The eigenfunctions, like the eigenvalues, can be labeled by the quantum number n.
The constant A, thus far arbitrary, can be adjusted so that ψn(x) is normalized. The
normalization condition is, in this case,
 a
0
[ψn(x)]2 dx = 1,
(3.31)
the integration running over the domain of the particle, 0 ≤x ≤a. Substituting
(3.30) into (3.31) and integrating after the substitution θ = nπx/a
A2
 a
0
sin2 nπx
a

dx = A2 a
nπ
 nπ
0
sin2 θ dθ = A2 a
2 = 1.
(3.32)
We have made the substitution θ = nπx/a and used the fact that the average value
of sin2 θ over an integral number of half wavelengths equals 1
2. We can thus identify
the normalization constant A = (2/a)1/2, for all values of n.
Finally we can write the normalized eigenfunctions:
ψn(x) =
2
a
1/2
sin
nπx
a

,
n = 1, 2, 3, . . .
(3.33)
The ﬁrst few eigenfunctions ψn(x) and the corresponding probability distributions
ρn(x) = [ψn(x)]2 are plotted in Fig.3.2. There is a close analogy between the states
of this quantum system and the modes of vibration of a violin string. The patterns
of standing waves on the string are, in fact, identical in form with particle-in-a-
box wavefunctions, as shown on the left side of Fig.3.2. A noteworthy feature of
particle-in-a-box quantum states is the occurrence of nodes. These are points, other
than the two end points (which are ﬁxed by the boundary conditions), at which
the wavefunction vanishes. At a node there is exactly zero probability of ﬁnding
the particle. The nth quantum state has, in fact, n −1 nodes. It is generally true
that the number of nodes increases with the energy of a quantum state, which can be
rationalized by the following qualitative argument. As the number of nodes increases,
so does the number and steepness of the “wiggles” in the wavefunction. It is like
skiing down a slalom course. Accordingly, the average curvature, given by the second
derivative, must increase. But the second derivative is proportional to the kinetic
energy operator. Therefore, the more nodes, the higher the energy. This will prove
to be an invaluable guide in more complex quantum systems. Another important
property is the mutual orthogonality of two different eigenfunctions. It is easy to see
from Fig.3.3 that the integral

92
3
The Schrödinger Equation
Fig. 3.2 Eigenfunctions and probability densities for particle in a box
Fig. 3.3 Product of n = 1 and n = 2 eigenfunctions
 a
0
ψ2(x)ψ1(x) dx = 0
(3.34)
As we have shown in Chap.2, this is a general result for quantum mechanical eigen-
functions. The normalization, together with the orthogonality of the eigenfunctions,
can be combined into a single relationship
 a
0
ψm(x)ψn(x) dx = δmn.
(3.35)
A set of functions {ψn} which obeys Eq. (3.35) is called orthonormal.

3.3 The Harmonic Oscillator
93
3.3
The Harmonic Oscillator
Oscillatory motion is frequently encountered in everyday experience. Among numer-
ous examples are pendulums, springs slightly displaced from equilibrium, strings of
a musical instrument, etc. In all these cases there is a restoring force F proportional
to the displacement x of the object; thus F = −kx, which is known as Hooke’s law.
Newton’s law F = ma becomes:
m d2x
dt2 = −kx.
(3.36)
This has the general solution:
x(t) = A cos ωt + B sin ωt,
(3.37)
where ω =

k
m . Classically, the harmonic oscillator has just this one natural fre-
quency ω.
With a potential energy V (x) = 1
2kx2, the force is given by F = −dV
dx and the
total energy E of a classical oscillator is
E = 1
2m p2 + V (x) = 1
2m p2 + 1
2kx2 = 1
2m

p2 + m2ω2x2
.
(3.38)
The corresponding quantum problem begins with a Hamiltonian operator of the same
form:
H = 1
2m

p2 + m2ω2x2
.
(3.39)
An elegant method to ﬁnd the eigenfunctions and eigenvalues of H makes use of
two new operators, a and a+, deﬁned by
a =
1
√
2mℏω
(mωx + ip),
a+ =
1
√
2mℏω
(mωx −ip).
(3.40)
These are called “raising” and “lowering” operators: ordering the eigenstates ψn,
or |n⟩in Dirac notation, in order of increasing energy En, they transform |n⟩into
|n + 1⟩or |n −1⟩(up to a constant). In a different context they have more dramatic
(magical?) names. a+ is called a “creation operator” and a is called an “annihilation”
operator. We will explain later the reason for these designations. The product of a+
and a works out to
a+a =
1
2mℏω (mωx −ip)(mωx + ip) =
1
2mℏω[m2ω2x2 + p2 + imω(xp −px)].
(3.41)

94
3
The Schrödinger Equation
Using the commutation relation [x, p] = xp −px = iℏ, we ﬁnd,
a+a = H
ℏω + i(iℏ)I
2ℏ
= H
ℏω −1
2 I.
(3.42)
Thus we can write the Hamiltonian H, in terms of a, a+, in the form
H = ℏω

a+a + 1
2 I

.
(3.43)
Some relevant relations involving the raising and lowering operators are the fol-
lowing. The fundamental commutation relation for a and a+:
[a, a+] = aa+ −a+a = I.
(3.44)
The corresponding anticommutation relation is
{a, a+} = aa+ + a+a = 2H
ℏω ,
(3.45)
with an anticommutator deﬁned by {F, G} = FG + GF. We obtain thereby:
[a, H] = aH −Ha = ℏω(aa+a −a+aa) = ℏω(aa+ −a+a)a = ℏωa
(3.46)
and
[a+, H] = a+H −Ha+ = ℏω(a+a+a −a+aa+) = ℏωa+(a+a −aa+) = −ℏωa+.
(3.47)
The following theorem summarizes the structure of the eigenvalues and eigen-
functions of the quantum harmonic oscillator:
Theorem 3.1 If |n⟩is an eigenfunction of H corresponding to the eigenvalue En,
then a|n⟩either equals zero or else is an eigenfunction of H corresponding to the
eigenvalue En −ℏω. Conversely, a+|n⟩is an eigenfunction of H corresponding to
the eigenvalue En + ℏω. The eigenvalues of H are the numbers En = (n + 1
2)ℏω,
n = 0, 1, 2, 3, . . ..
Proof From the eigenvalue equation:
H|n⟩= En|n⟩
(3.48)
and Eqs.(3.46), (3.47) we obtain:
(aH −Ha)|n⟩= (aEn −Ha)|n⟩= ℏωa|n⟩,
(a+H −Ha+)|n⟩= (a+En −Ha+)|n⟩= −ℏωa+|n⟩.
(3.49)

3.3 The Harmonic Oscillator
95
Therefore:
Ha |n⟩= (En −ℏω)a |n⟩,
Ha+|n⟩= (En + ℏω)a+|n⟩.
(3.50)
Thus, if En is an eigenvalue, then En −ℏω and En + ℏω are also eigenvalues, unless
one of the functions a|n⟩or a+|n⟩vanishes. But a+|n⟩never vanishes, since
|a+|n⟩|2 = ⟨a+n|a+n⟩= ⟨n|aa+n⟩= ⟨n|(I + a+a)|n⟩= ⟨n|n⟩+ ⟨an|an⟩≥⟨n|n⟩> 0.
By contrast, a|n⟩can equal the null vector. Assuming this is the case, let us solve
the equation a|ψ0⟩= 0. Neglecting a numerical factor:
(mωx + ip)ψ0(x) = mωxψ0(x) + ℏdψ0
dx = 0
(3.51)
This simpliﬁes to d log ψ0
dx
= −mω
ℏx, and integrating, log ψ0(x) = −mω
2ℏx2 + const.
Thus
ψ0(x) = A exp

−mω
2ℏx2
(3.52)
where A is a normalization constant. Using the well-known Gaussian integral
 +∞
−∞e−αx2dx =
 π
α
 1
2 , we can ﬁnd A by imposing the condition
 +∞
−∞ψ0(x)2 dx
= 1. The result is A =
 2mω
h
 1
4 . Since H = ℏω(a+a +
1
2 I), we obtain ﬁnally:
H |ψ0⟩= ℏω
2 |ψ0⟩,
(3.53)
where ψ0 is the ground state |0⟩and E0 = 1
2ℏω is the lowest energy level. Indeed,
this must be the lowest possible energy, since, applying the lowering operator a, we
obtain the null vector. The higher energy levels are E1 =
3
2ℏω, E2 =
5
2ℏω, . . .,
En = (n + 1
2)ℏω (see Fig.3.4). The corresponding eigenfunctions |n⟩are easily
obtained by repeatedly applying the operator a+. Clearly then:
|n⟩= An(a+)n|0⟩,
(3.54)
where An is a normalization constant. This completes the proof of the Theorem.
Figure 3.5 shows a sketch of the ground-state wavefunction.
Remarkably, the quantization of the electromagnetic ﬁeld in free space requires
operators very similar to a and a+. The underlying reason is that the Hamiltonian
for electromagnetic radiation can also be written as a quadratic form in the operators
ak, a+
k where k denotes a three-dimensional momentum. We will not go into any
more detail here, but note only that a+
k sends a state |k1⟩into a state |k2⟩, as a
photon of momentum k is absorbed, and conversely, ak sends |k2⟩back into |k1⟩,

96
3
The Schrödinger Equation
Fig. 3.4 Energy levels of the
quantum harmonic oscillator
Fig. 3.5 Ground-state
wavefunction for the
harmonic oscillator
as a photon is emitted. Accordingly, a+
k , ak are designated, respectively, as creation
and annihilation operators for light quanta.
3.4
Angular Momentum
3.4.1
Particle in a Ring
As a preliminary, let us consider ﬁrst a particle in a ring, a variant of the one-
dimensional particle-in-a-box problem in which the x-axis is bent into a ring of
radius R. We can write the same Schrödinger equation
−ℏ2
2M
d2ψ(x)
dx2
= Eψ(x),
(3.55)
where the particle mass is now designated M. There are no boundary conditions
in this case since the x-axis closes upon itself. A more appropriate independent
variable for this problem is the angular position on the ring given by, φ = x/R. The
Schrödinger equation would then read

3.4 Angular Momentum
97
−
ℏ2
2M R2
d2ψ(φ)
dφ2
= Eψ(φ).
(3.56)
The kinetic energy of a body rotating in the xy-plane can be expressed as
E = L2
z
2I ,
(3.57)
where I = M R2 is the moment of inertia and Lz, the z-component of angular
momentum. (Since L = r × p, if r and p lie in the x–y plane, L points in the z-
direction.) The structure of Eq. (3.56) suggests that this angular momentum operator
is given by
Lz = −iℏd
dφ
(3.58)
This result will follow from a more general derivation later. The Schrödinger equation
(3.56) can now be written more compactly as
ψ′′(φ) + m2ψ(φ) = 0
(3.59)
where
m2 ≡2I E/ℏ2
(3.60)
(Please do not confuse this symbol m with mass!) Possible solutions to (3.56) are
ψ(φ) = const e±imφ
(3.61)
In order for this wavefunction to be physically acceptable, it must be single-valued.
Since φ increased by any multiple of 2π represents the same point on the ring, we
must have ψ(φ + 2π) = ψ(φ), and therefore
eim(φ+2π) = eimφ.
(3.62)
This requires that e2πim = 1, which is true only is m is an integer: m = 0,
±1, ±2, . . . . Using (3.60), this gives the quantized energy values
Em = ℏ2
2I m2.
(3.63)
Thus, in contrast to the particle-in-a-box, the eigenfunctions corresponding to +m
and −m in Eq. (3.61) are linearly independent, so both must be included. Therefore
all eigenvalues, except E0, are twofold (doubly) degenerate. The eigenfunctions can
therefore be written simply as const eimφ, with m running over all integer values. The
normalized eigenfunctions are

98
3
The Schrödinger Equation
ψm(φ) =
1
√
2π
eimφ,
m = 0, ±1, ±2, . . .
(3.64)
and can be veriﬁed to satisfy the complex generalization of the normalization con-
dition
 2π
0
ψm(φ)∗ψm(φ) dφ = 1
(3.65)
with the complex conjugate ψm(φ)∗= (2π)−1/2 e−imφ. It is easy to show that the
functions ψm(φ) and ψm′(φ) are orthogonal for m ̸= m′. We thus have the orthonor-
mality relations
 2π
0
ψm(φ)∗ψm′(φ) dφ = δm,m′.
(3.66)
The solutions (3.64) are also eigenfunctions of the angular momentum operator
(3.58), with
Lzψm(φ) = mℏψm(φ),
m = 0, ±1, ±2, . . .
(3.67)
This is an instance of a fundamental result in quantum mechanics, that any measured
component of orbital angular momentum is restricted to integral multiples of ℏ. The
formulas of the Bohr theory of the hydrogen atom (Chap.1) can be derived from this
assumption alone.
3.4.2
Angular Momentum Operators
In classical mechanics a particle at point r = (x, y, z) with momentum p =
(px, py, pz) has an orbital angular momentum L = (Lx, L y, Lz) with respect to
the origin (0, 0, 0) given by L = r × p. The Cartesian components of L can thereby
be written
Lx = ypz −zpy,
L y = zpx −xpz,
Lz = xpy −ypx.
(3.68)
Recall the linear momentum operators in quantum mechanics:
px = −iℏ∂
∂x ,
py = −iℏ∂
∂y ,
pz = −iℏ∂
∂z .
(3.69)
When applied to a wave function ψ(x, y, z), the expression ypzψ implies that we
must ﬁrst apply the operator pz to ψ and then multiply the result by y, etc. We thereby
obtain the operators for the 3 components of angular momentum

3.4 Angular Momentum
99
Lx = −iℏ

y ∂
∂z −z ∂
∂y

,
L y = −iℏ

z ∂
∂x −x ∂
∂z

,
Lz = −iℏ

x ∂
∂y −y ∂
∂x

.
(3.70)
We have already found an alternative expression Lz = −iℏ∂
∂φ , namely, Eq. (3.58), in
terms of the angle φ, which is actually one of the spherical polar coordinates (r, θ, φ)
in which r can be expressed. The eigenvalues of Lz were found to be equal to mℏ
(m = 0, ±1, ±2, . . . ). It would then be expected that the eigenvalues of Lx, L y are
likewise integer multiples of ℏ.
The components of the angular momentum obey the following commutation
relations2
[L y, Lz] = L yLz −LzL y = iℏLx,
[Lz, Lx] = LzLx −Lx Lz = iℏL y,
(3.71)
[Lx, L y] = Lx L y −L yLx = iℏLz.
Since no two of the angular momentum components Lx, L y, Lz commute, it fol-
lows that one cannot know the eigenvalues of more than one component (with one
exception: when the total angular momentum equals 0). Proof of the commutation
relations follows from the sequence of steps:
[Lx, L y] = [ypz −zpy, zpx −xpz] = y[pz, z]px + [z, pz]pyx =
−iℏ[ypx −xpy] = iℏLz,
(3.72)
with analogs for the other two commutators. By contrast, different components of
coordinates or momenta have been found to be mutually commutative (for example
pyx = xpy, px py = py px, etc.).
3.4.3
Eigenvalues and Eigenfunctions
Another important set of commutation relations involves the square of the total
angular momentum, L2 = L2
x + L2
y + L2
z, for example,
[L2, Lz] = [L2
x, Lz] + [L2
y, Lz] + [L2
z, Lz] =
[Lx, Lz]Lx + Lx[Lx, Lz] + [L y, Lz]L y + L y[L y, Lz] =
iℏ(−Lx L y −L yLx + L yLx + Lx L y) = 0,
(3.73)
2An interesting mnemonic is the symbolic vector formula: L×L = iℏL. The Cartesian components
then give the three commutation relations.

100
3
The Schrödinger Equation
and analogously for Lx and L y. We have used the commutator identity [X2, Y] =
[X, Y]X + X[X, Y]. Thus, the square of the total angular momentum commutes with
each of its components:
[L2, Lx] = [L2, L y] = [L2, Lz] = 0.
(3.74)
It follows, therefore, that there exist simultaneous eigenstates of L2 and one compo-
nent, generally chosen as Lz. Let us denote the corresponding eigenvectors by |l, m⟩,
and write the eigenvalue equations
Lz|l, m⟩= mℏ|l, m⟩
and
L2|l, m⟩= λℏ2|l, m⟩
(3.75)
with λ remaining to be determined.
At this point we introduce the operators
L+ = Lx + i L y,
L−= Lx −i L y,
(3.76)
which,wewillseeinamoment,areraisingandloweringoperatorsfortheeigenvalues
of Lz. It is easy to see that L2 commutes with L+, since it commutes with both Lx
and L y. Therefore
L2L+|l, m⟩= L+L2|l, m⟩= λℏ2L+|l, m⟩,
(3.77)
using the eigenvalue equation for L2, Eq. (3.75). We can then write: L2(L+|l, m⟩) =
λℏ2(L+|l, m⟩), which shows that L+|l, m⟩is an eigenvector of L2 with the same
eigenvalue λℏ2 as |l, m⟩. Thus, the operator L+ applied to |l, m⟩does not change the
magnitude of the angular momentum.
Consider now the commutator [Lz, L+]
[Lz, L+] = [Lz, Lx] + i[Lz, L y] = iℏL y + i(−iℏ)Lx = ℏ(i L y + Lx) = ℏL+.
(3.78)
Operating on the eigenvector |l, m⟩:
[Lz, L+]|l, m⟩= LzL+|l, m⟩−L+Lz|l, m⟩= ℏL+|l, m⟩,
Lz(L+|l, m⟩) −mℏ(L+|l, m⟩) = ℏ(L+|l, m⟩),
Lz(L+|l, m⟩) = (m + 1)ℏ(L+|l, m⟩).
(3.79)
Evidently, L+|l, m⟩is an eigenvector of Lz with the eigenvalue (m + 1)ℏ, thus the
designation of L+ as a raising operator, meaning that
L+|l, m⟩= const|l, m + 1⟩.
(3.80)
Analogously, L−is a lowering operator, with
L−|l, m⟩= const|l, m −1⟩.
(3.81)

3.4 Angular Momentum
101
Suppose that the quantum number l is now deﬁned as the maximum allowed value
of m for a given eigenvalue λℏ2 of L2. (Correspondingly, −l would be the minimum
value of m.) Since there is no higher possible value of m, the raising operator on |l,l⟩
should annihilate the vector:
L+|l,l⟩= 0.
(3.82)
Now here is an identity you would never ordinarily think of:
L−L+ = L2
x + L2
y + i(Lx L y −L yLx) = L2 −L2
z + i(iℏ)Lz.
(3.83)
Thus
L2 = L−L+ + L2
z + ℏLz.
(3.84)
Applying this to |l,l⟩
L2|l,l⟩= L−L+|l,l⟩+ L2
z|l,l⟩+ ℏLz|l,l⟩,
(3.85)
giving
λℏ2|l,l⟩= 0 + l2ℏ2|l,l⟩+ lℏ2|l,l⟩.
(3.86)
Finally, we can identify
λ = l2 + l = l(l + 1).
(3.87)
The eigenvalues and eigenvectors for orbital angular momentum can now be
summarized:
L2|l, m⟩= l(l + 1)ℏ2|l, m⟩,
l = 0, 1, 2, . . .
Lz|l, m⟩= mℏ|l, m⟩,
m = 0, ±1, ±2, . . . , ±l.
(3.88)
Incidentally, l is usually denoted the angular momentum quantum number, since it
determines the magnitude of the angular momentum, while m is called the mag-
netic quantum number, since it gives the component of angular momentum along an
external magnetic ﬁeld.
The magnitude of the total angular momentum |L| = √l(l + 1)ℏis greater than its
maximum observable component in any direction, namely lℏ. The quantum mechan-
ical behavior of the angular momentum and its components can be represented by a
vector model, as shown in Fig.3.6. The angular momentum vector L can be pictured
as precessing about the z-axis, with its z-component Lz constant. The components
Lx and L y ﬂuctuate in the course of precession, mirroring the fact that the system
is not in an eigenstate of either, as implied by the commutation relations. There
are 2l + 1 possible values for Lz, with eigenvalues mℏ(m = 0, ±1, ±2, . . . , ±l),
equally spaced between +lℏand −lℏ. This discreteness in the allowed directions of
the angular momentum vector is called space quantization.

102
3
The Schrödinger Equation
Fig. 3.6 Vector model for
angular momentum, showing
the case l = 2
3.4.4
Matrix Representations
In Sect.2.2, it was shown that operators and eigenvectors can be represented by
matrices. We will illustrate for the states of a system with l = 1. There are three
eigenstates, with eigenvalues m = 1, 0, −1. These can evidently be represented by
three-dimensional column vectors, with
[1, 1⟩=

1
0
0

,
|1, 0⟩=

0
1
0

,
|1, −1⟩=

0
0
1

.
(3.89)
In a representation in which Lz is diagonal, the three angular momentum operators
can be represented by the matrices:
Lx = ℏ

0
1
√
2 0
1
√
2 0
1
√
2
0
1
√
2 0

,
L y = ℏ

0 −i√
2
0
i√
2
0
−i√
2
0
i√
2
0

,
Lz = ℏ

1 0 0
0 0 0
0 0 −1

,
(3.90)
and also
L2 = ℏ2

2 0 0
0 2 0
0 0 2

.
(3.91)
You can verify that these matrices satisfy the commutation relations and the eigen-
value equations. Note also that all of these matrices are Hermitian (L = L†), with
Li, j = L∗
j,i, as required by the postulates of quantum mechanics for all observables.
3.4.5
Electron Spin
We consider brieﬂy the angular momentum associated with electron spin. This will
be indispensable in our later work on Bell’s theorem and quantum computers. Many

3.4 Angular Momentum
103
atomic spectral lines appear, under sufﬁciently high resolution, to be closely spaced
doublets, for example, the 17.2cm−1 splitting of the yellow sodium D lines. Uhlen-
beck and Goudsmit suggested in 1925 that such doublets were due to an intrin-
sic angular momentum possessed by the electron (in addition to its orbital angular
momentum) that could be oriented in just two possible ways. This property, known as
spin, occurs as well in other elementary particles. Spin and orbital angular momenta
are roughly analogous to the daily and annual motions, respectively, of the Earth
around the Sun. To distinguish the spin angular momentum from the orbital, we des-
ignate the quantum numbers as s and ms, in place of l and m. For the electron, the
quantum number s always has the value 1
2, while ms can have one of two values, ± 1
2.
The electron is said to be an elementary particle of spin 1
2. The proton and neutron
also have spins 1
2 and belong to the classiﬁcation of particles called fermions, which
are governed by the Pauli exclusion principle. Other particles, including the photon,
have integer values of spin and are classiﬁed as bosons. These do not obey the Pauli
principle, so that an arbitrary number can occupy the same quantum state. A com-
plete theory of spin requires relativistic quantum mechanics. For our purposes, it is
sufﬁcient to recognize the two possible internal states of the electron, which can be
called spin-up and spin-down. Electron spin plays an essential role in determining
the possible electronic states of atoms and molecules.
The two spin states can be designated
 1
2, 1
2

and
 1
2, −1
2

. They obey the angular
momentum eigenvalue equations
S21
2, ±1
2

= 3
4ℏ21
2, ±1
2

,
Sz
1
2, ±1
2

= ±1
2ℏ
1
2, ±1
2

.
(3.92)
Note that s(s+1) = 1
2( 1
2 +1) = 3
4. Spin eigenvectors can alternatively be represented
by two-dimensional column vectors (actually spinors):
1
2, 1
2

=

1
0
 ,
1
2, −1
2

=

0
1
 ,
(3.93)
and spin operators by 2 × 2 matrices:
Sx = ℏ
2

0 1
1 0
 ,
Sy = ℏ
2

0 −i
i 0
 ,
Sz = ℏ
2

1 0
0 −1
 ,
S2 = 3
4ℏ2

1 0
0 1
 .
(3.94)
These are the famous Pauli spin matrices. These matrices (or operators) obey com-
mutation relations completely analogous to Eqs.(3.71) and (3.74).
3.4.6
Abstract Theory of Angular Momentum
A completely general theory of angular momentum can be based on a set of commuta-
tion relations, not necessarily connected to either orbital or spin angular momentum.

104
3
The Schrödinger Equation
Suppose we begin with a set of operators J1, J2, J3, J 2 obeying the commutation
relations:
[J 2, Ji] = 0,
[J1, J2] = iℏJ3, et cyc,
i = 1, 2, 3,
(3.95)
where et cyc means all cyclic permutations of (1, 2, 3). A more elegant way to write
these commutations makes use of the permutation symbol or Levi-Civita symbol,
εi jk, which is equal to +1 if (i, j, k) is an even permutation of (1, 2, 3), −1 if it is
an odd permutation, and 0 otherwise. More explicitly,
εi jk =
⎧
⎪⎨
⎪⎩
+1 if (i, j, k) is (1, 2, 3), (2, 3, 1) or (3, 1, 2),
−1 if (i, j, k) is (3, 2, 1), (1, 3, 2) or (2, 1, 3),
0
if i = j or j = k or k = i
(3.96)
The commutation relations are now:
[Ji, Jj] = iℏεi jk Jk.
(3.97)
The eigenvalue equations can now be derived by the same sequence of manipulations
leading to Eqs.(3.88). The one generalization is that the quantum numbers j and m
can now be odd half-integers, as well as integers, just so the sequence −j to j can
be spanned by a ﬁnite number of integer jumps. We ﬁnd then:
J 2| j, m⟩= j( j + 1)ℏ2| j, m⟩,
j = 0, 1
2, 1, 3
2, 2, . . .
J3| j, m⟩= mℏ| j, m⟩,
m = −j, −j + 1, . . . , j.
(3.98)
3.5
The Hydrogen Atom
Historically, the hydrogen atom has played a major role in the development of the
quantum theory, as described in Chap.1. With successive reﬁnements of our theories,
through nonrelativistic, then relativistic quantum mechanics, quantum electrodynam-
ics up to the current standard model based on quantum ﬁeld theory, the hydrogen atom
has provided a deﬁnitive test of each new theory. In several ways, the hydrogen atom
is fundamental to our understanding of the Universe. Hydrogen comprises over 90%
of the atoms in the visible matter of the Universe (not counting the overwhelming
prevalence of mysterious dark matter).
The time-independent Schrödinger equation for an electron, of mass m and charge
−e, in a hydrogenlike atom takes the form:
−ℏ2
2m ∇2ψ(r) −Ze2
r ψ(r) = E ψ(r),
(3.99)

3.5 The Hydrogen Atom
105
where Z is the atomic number of the nucleus. It is simple to generalize the problem
from the hydrogen atom (Z = 1) to all one-electron (hydrogenlike) ions. Thus
Z = 2 for He+, Z = 3 for Li2+, and so on. The potential energy for the attractive
Coulomb interaction between an electron of charge −e and a nucleus of charge
+Ze is given by V (r) = (Ze)(−e)/r where r is the interparticle distance. (We
use the Gaussian system of units, since, in SI units, the additional factor 1/4πε0, is
extraneous in applications to atomic phenomena.) A force dependent only on r, the
magnitude of r, is known as a central force. In Cartesian coordinates, the potential
energy would take the form V (x, y, z) = −Ze2/

x2 + y2 + z2, which would make
the Schrödinger equation rather difﬁcult to solve. It is much more convenient to use
spherical coordinates, (r, θ, φ), in which the potential energy takes the simplest form
V (r) = −Ze2/r. It should be noted that the nuclear kinetic energy has not been taken
into account. For simplicity, the nuclear mass M, which is at least 1836 times the
electron mass, can be approximated as inﬁnite, thus implying zero nuclear kinetic
energy. (A correction for ﬁnite nuclear mass can be made by using the reduced mass
of the electron, μ = mM/(m + M), which is of the order of 1 part per 1000 smaller
than m.)
3.5.1
Spherical Polar Coordinates
Following is a brief review of this coordinate system, sufﬁcient for our present pur-
poses. The three Cartesian coordinates can be expressed in terms of spherical coor-
dinates as follows:
x = r sin θ cos φ,
y = r sin θ sin φ,
z = r cos θ,
(3.100)
which can be readily be deduced from Fig.3.7. Spherical coordinates are closely
analogous to the geographical coordinate system, which locates points by latitude,
longitude and altitude. Referring to the familiar globe of the world, r represents the
radius of the globe, with the range 0 ≤r < ∞. The azimuthal angle θ is the angle
between the vector r and the z-axis or “north pole,” with the range 0 ≤θ ≤π. Thus
Fig. 3.7 Spherical
coordinates (r, θ, φ); r is the
length of the vector r, while
θ and φ are the central
angles of the shaded sectors

106
3
The Schrödinger Equation
θ = 0 points to the “north pole,” θ = π, to the “south pole” and θ = π/2 runs around
the “equator.” The circles of constant θ on the surface of a sphere are analogous to the
parallels of latitude on the globe (although the geographic conventions are different,
with the equator at 0◦latitude, while the poles are at 90◦N and S latitude). The polar
angle φ measures the rotation of the vector r around the z-axis, with 0 ≤φ < 2π,
counterclockwise from the x-axis. The loci of constant φ on the surface of a sphere
are great circles through both poles. These clearly correspond to meridians in the
geographic speciﬁcation of longitude (measured in degrees, 0◦to 180◦E and W of
the Greenwich Meridian).
Integration of a function over all space in spherical coordinates takes the form:
 ∞
0
 π
0
 2π
0
F(r, θ, φ)r2 sin θ dr dθ dφ.
(3.101)
For a spherically symmetric function F(r), independent of θ or φ, this integral
simpliﬁes to
 ∞
0
F(r) 4πr2 dr,
(3.102)
as implied by the division of space into spherical shells of area 4πr2 and thickness dr.
3.5.2
Solution of the Schrödinger Equation
The Laplacian operator in spherical coordinates is given by
∇2 = 1
r2
∂
∂r r2 ∂
∂r +
1
r2 sin θ
∂
∂θ sin θ ∂
∂θ +
1
r2 sin2 θ
∂2
∂φ2
(3.103)
Thus the hydrogenic Schrödinger equation, in all its glory, looks like this:
−ℏ2
2m
 1
r2
∂
∂r r2 ∂
∂r +
1
r2 sin θ
∂
∂θ sin θ ∂
∂θ +
1
r2 sin2 θ
∂2
∂φ2

ψ(r, θ, φ)
−Ze2
r ψ(r, θ.φ) = Eψ(r, θ, φ).
(3.104)
The long expression within the brackets following −ℏ2/2m represents the total
kinetic energy of the electron. This corresponds, in classical mechanics, to the kinetic
energy part of the Hamiltonian in spherical coordinates:
Ekin = p2
r
2m +
L2
2mr2 ,
(3.105)

3.5 The Hydrogen Atom
107
where pr is the momentum in the radial direction, while L is the angular momentum.
The rotational part of the electron’s kinetic energy can be expressed Erot = L2/2I
(see Eq.3.57), where the relevant moment of inertia is given by I = mr2. Clearly,
the ﬁrst term in the Laplacian (containing r alone) must correspond to the radial part
of the kinetic energy:
Hrad = −ℏ2
2m
1
r2
∂
∂r r2 ∂
∂r = −ℏ2
2m
 ∂2
∂r2 + 2
r
∂
∂r

,
(3.106)
while the remaining two terms represent angular or rotational motion:
Hrot = −ℏ2
2m

1
r2 sin θ
∂
∂θ sin θ ∂
∂θ +
1
r2 sin2 θ
∂2
∂φ2

.
(3.107)
The relation Hrot = L2/2mr2 identiﬁes the angular momentum operator, in spherical
coordinates:
L2 = −ℏ2

1
sin θ
∂
∂θ sin θ ∂
∂θ +
1
sin2 θ
∂2
∂φ2

.
(3.108)
The eigenvalue equation for angular momentum (3.88) in Dirac notation,
L2|l, m⟩= l(l + 1)ℏ2|l, m⟩,
(3.109)
can be expressed in terms of wavefunctions and differential operators as
−ℏ2

1
sin θ
∂
∂θ sin θ ∂
∂θ +
1
sin2 θ
∂2
∂φ2

Ylm(θ, φ) = ℏ2l(l + 1)Ylm(θ, φ). (3.110)
The eigenfunctions Ylm(θ, φ) are known as spherical harmonics, which also occur
in many other applications of mathematical physics. The quantum number l is often
speciﬁed by a code that originated in early atomic physics: l = 0, 1, 2, 3, . . . are
designated s, p, d, f, . . . states, respectively. For an s-state, Y00(θ, φ) = 1/
√
4π;
the wavefunction has no dependence on the angles θ or φ, only on r. Thus an s-state
is spherically symmetrical.
The hydrogenic Schrödinger equation (3.104) can evidently be simpliﬁed by sep-
aration of variables, with
ψ(r, θ, φ) = Rnl(r)Ylm(θ, φ),
(3.111)
where n is the principal quantum number, n = 1, 2, 3, . . . , with the same mean-
ing as in the Bohr theory. For a given n, the angular momentum quantum number
l has the possible values l = 0, 1, 2, . . . , n −1. As a short cut, we can use the
known energies from the Bohr theory: En = −Z2e4m/2n2ℏ2 = −Z2e2/2n2a0
The ground state, with n = 1, can admit only l = 0. It is designated the 1s-state,

108
3
The Schrödinger Equation
with a spherically symmetrical wavefunction ψ(r). The ground-state energy equals
E1 = E1s = −Z2e2/2a0.
After some algebraic reduction, we obtain an ordinary differential equation for
the radial function Rnl(r):
−ℏ2
2m
d2Rnl
dr2
+ 2
r
d Rnl
dr
−l(l + 1)
r2
Rnl

−Ze2
r
Rnl = En Rnl.
(3.112)
It is convenient, in atomic and molecular applications, to introduce atomic units,
obtained by setting ℏ= m = e = 1. The unit of length is the bohr, equal to the Bohr
radius a0 = ℏ2/me2 ≈0.529 × 10−10 m. The unit of energy is the hartree, equal
to e2/a0 ≈27.211 eV. Thus, for the ground-state energy E1s = −Z2/2 hartrees.
Setting l = 0 for an s-state, the radial equation for the ground state wavefunction
now simpliﬁes to:
1
2 R′′(r) + 1
r R′(r) + Z
r R(r) = Z2
2 R(r),
(3.113)
It is often useful, as a ﬁrst step, to obtain an asymptotic solution of a differential
equation, in this case for large values of r. Thus, neglecting the two terms containing
1
r , the equation reduces to
R′′(r) ≈Z2R(r)
(3.114)
A solution is R(r) ≈e−Zr. An alternative solution e+Zr is rejected since it increases
without limit as r →∞. We are very fortunate to ﬁnd that this asymptotic solution
is also an exact solution to Eq. (3.113): R1s(r) = Ae−Zr. To determine the normal-
ization constant A, such that the total probability of ﬁnding the electron somewhere
is equal to 1, we calculate
 ∞
0
[R1s(r)]2 r2dr = A2
 ∞
0
e−2Zr r2dr = A2
4Z3 = 1.
(3.115)
This gives A = 2Z3/2 and
R1s(r) = 2Z3/2e−Zr,
(3.116)
or, since Y00 = 1/
√
4π,
ψ1s(r) = Z3/2
√π e−Zr.
(3.117)
We have made use of the deﬁnite integral:
 ∞
0
rne−αr dr =
n!
αn+1 .
(3.118)

3.5 The Hydrogen Atom
109
Fig. 3.8 Ground-state wavefunction of the hydrogen atom. In order to simulate the cusp at the origin
in three dimension, we have shown the behavior of ψ1s(r) both on the positive and “negative” r
axes
Fig. 3.9 Density plot of the
hydrogen 1s wavefunction.
The nucleus is shown as a
black dot in the center
A one-dimensional projection of ψ1s(r) is shown in Fig. 3.8 and a three-dimensional
density plot of the wavefunction are simulated in Fig.3.9. Note the exponential
decrease from the maximum value at the nucleus. The 1s-wavefunction has no nodes
(loci where the function equals zero), in common with the ground states of the particle
in a box and harmonic oscillator. As we have seen, higher-energy states are associated
with an increasing number of nodes. The 2s, 3s, . . . states have radial nodes, spheres
onwhichψ = 0,while p, d, f, . . . stateshavetheangularnodesofthecorresponding
spherical harmonics Ylm, which are surfaces through the origin.
3.5.3
Atomic Structure
In many-electron atoms, to a reasonable level of approximation, each individual
electron can be pictured as occupying an atomic orbital (AO).3 This provides a
3Technically, since electrons are indistinguishable particles, every electron is equally associated
with every occupied atomic orbital. Expressed another way, the electrons in an atom or molecule
have a cardinality but no ordinality.

110
3
The Schrödinger Equation
Fig. 3.10 Schematic images of some hydrogenic atomic orbitals. The wavefunctions are positive
in the blue areas and negative in the yellow areas
foundation for much of quantum chemistry. (The term “orbital” is an adaptation from
“orbit” in the Bohr theory, recognizing that an electron is described by a probability
distribution rather than a classical trajectory.) The AOs have the same designations as
hydrogenicfunctions,1s, 2s, 2p, . . . ,arehaveverysimilarshapes.Someofthelower
energyAOsarepicturedinFig.3.10.Thesearehighlyschematicrepresentationssince
the actual wavefunctions fall off exponentially. These ﬁgures convey a general idea of
the shape of the orbitals and of their nodal surfaces, boundaries between the positive
(blue) and negative (yellow) regions of the wavefunction. Each AO is described by
a unique set of four quantum numbers: n,l, ml and ms. The ﬁrst three belong to
the wavefunction ψnlm(r, θ, φ); the fourth is the electron spin orientation ms = ± 1
2.
According to the Pauli exclusion principle, no two electrons can share the same set
of four quantum numbers. According to the Aufbau principle, the ground state of
an atom is constructed conceptually by successively ﬁlling orbitals in the order of
increasing energy. Given the multiplicity of values of ml = 0, ±1, ±2, . . . , ±l and of

3.5 The Hydrogen Atom
111
ms = ± 1
2, a set of AOs with quantum numbers n,l constitute a subshell, containing,
at most, 2(2l + 1) electrons: 2, 6, 10, …, respectively, for ns, np, nd, . . . . The Pauli
principle and the Aufbau principle provide a rational understanding of the structure
of the Periodic Table. As an example, potassium (K) with atomic number Z = 19
has a ground-state electronic conﬁguration written 1s22s22p63s23p64s1. Note that
4s subshell is open (not complete), which accounts for the relative ease with which
this electron can be removed, to leave a K+ ion. The remaining 18 electrons form a
closed shell conﬁguration, which tends to bestow enhanced chemical stability.
3.6
Time Evolution and Collapse of the Wavefunction
3.6.1
The Evolution Operator
The time-dependent Schrödinger equation (TDSE), Eq. (3.13), shows how the Hamil-
tonian H governs the time evolution of a quantum system. In Dirac notation, the
TDSE can be written
iℏd|Ψ (t)⟩
dt
= H|Ψ (t)⟩.
(3.119)
We now introduce an operator U(t) which maps (or “rotates”) |Ψ (0)⟩into |Ψ (t)⟩,
such that
|Ψ (t)⟩= U(t)|Ψ (0)⟩.
(3.120)
Substituting this into the TDSE, we obtain
iℏd
dt U(t)|Ψ (0)⟩= HU(t)|Ψ (0)⟩.
(3.121)
Since this applies to an arbitrary function |Ψ (0)⟩, the relation can be reduced to an
operator equation
iℏd
dt U(t) = HU(t),
(3.122)
with the initial condition U(0) = I (the identity operator). If this were a differential
equation involving ordinary functions, the solution would then be:
U(t) = e−i Ht/ℏ.
(3.123)
This can also be considered the formal solution to the corresponding operator equa-
tion. The exponential implicitly represents the power series operator expansion:
e−i Ht/ℏ= I +

−i
ℏHt

+ 1
2!

−i
ℏHt
2
+ 1
3!

−i
ℏHt
3
+ . . .
(3.124)

112
3
The Schrödinger Equation
The adjoint operator U(t)† is equal to e+i H †t/ℏ. Since the Hamiltonian is Hermitian,
H † = H, it follows that U(t)† = U(t)−1. Thus U(t) is a unitary operator, which is
known as the evolution operator or propagator, since it governs the development of
the quantum system with time. Applying the evolution operator to an eigenfunction
of H, denoted ψn or |n⟩, we ﬁnd
U(t)ψn = e−i Ht/ℏψn = e−i Ent/ℏψn.
(3.125)
Since H kψn = Ek
nψn, the exponential series for H, Eq. (3.124) turns into the corre-
sponding series for En. This agrees with the form of the wavefunction for a stationary
state: Ψ = ψ e−i Et/ℏ, which we obtained in Sect.3.1.
Let us now apply this formalism to the simplest possible case, a two-dimensional
Hilbert space. The Hamiltonian can then be represented by a 2 × 2 matrix in the
orthonormal basis of the eigenvectors |ψ1⟩, |ψ2⟩, with the corresponding eigenvalues
E1, E2. Since Hi j = ⟨ψi|H|ψ j⟩= E j⟨ψi|ψ j⟩, H, in this basis, is represented by
the simple diagonal matrix:
H =

E1 0
0 E2
 .
(3.126)
All powers H 2, H 3, etc. are then also diagonal matrices:
H 2 =

E2
1 0
0 E2
2
 ,
H 3 =

E3
1 0
0 E3
2
 ,
. . .
(3.127)
It follows that the evolution operator is represented by the matrix:
U(t) = e−i Ht/ℏ=

e−i E1t/ℏ
0
0
e−i E2t/ℏ
 .
(3.128)
This result can be generalized to a Hilbert space of any dimension.
The derivative of an n×n matrix A with respect to a parameter t can be denoted by
a matrix B, whose elements are the derivatives of the corresponding matrix elements
of A. Thus
Bi,k = d Aik
dt
i, k = 1, 2, . . . , n
(3.129)
In the case of the matrix U(t) we have then:
iℏdU
dt =

E1 e−i E1t/ℏ
0
0
E2 e−i E2t/ℏ

(3.130)
This is evidently the 2 × 2 matrix form of the operator relation (3.122)
iℏdU
dt = HU.
(3.131)

3.6 Time Evolution and Collapse of the Wavefunction
113
When applied to |ψ(0)⟩, the state at t = 0, this produces |ψ(t)⟩, a solution of the
TDSE. From an operational point of view, the Hamiltonian H can thereby be pictured
as the generator of time evolution of a quantum system.
3.6.2
Schrödinger and Heisenberg Pictures
Thus far, we have followed a formulation of QM referred to as the Schrödinger
picture. Its distinguishing features are state vectors |Ψ (t)⟩depending on time and
satisfying the TDSE, but operators which are ﬁxed in time (apart from cases in
which there is explicit time dependence). The time evolution of a quantum system
is then carried entirely by the state vectors |Ψ (t)⟩. In abstract geometrical terms,
Schrödinger picture can be associated with a coordinate system in Hilbert space
in which dynamical variables are ﬁxed but state vectors are moving. Possibilities
for alternative formulations exist, however, since both operators and state vectors
are abstract quantities not directly accessible to measurement. Quantities which do
have objective reality are scalars in Hilbert space: eigenvalues, probability densities,
expectation values and transition probabilities.
Consider now a Dirac bracket expression such as f (t) = ⟨Φ(t)|A|Ψ (t)⟩. Now
introduce the evolution operator, so that |Ψ (t)⟩= U(t)|Ψ (0)⟩and ⟨Φ(t)| =
⟨Φ(0)|U †(t). The bracket expression transforms as follows
f (t) = ⟨Φ(t)|A|Ψ (t)⟩= ⟨Φ(0)|U †(t)AU(t)|Ψ (0)⟩= ⟨Φ(0)|A(t)|Ψ (0)⟩,
(3.132)
where
A(t) = U †(t)AU(t) = ei Ht/ℏAe−i Ht/ℏ.
(3.133)
Here, the time-independent operator A in the Schrödinger picture is transformed to
a time-dependent operator A(t) in what is known as the Heisenberg picture. Often
these alternative representations of an operator are distinguished by the notation AS
and AH. In the Heisenberg picture, it is the operators that now evolve with time, while
the state vectors remain as a ﬁxed, time-independent basis. The focus on operators in
Hilbert space, and their matrix representations, closely resembles the formulation of
matrix mechanics. And, in addition, like classical mechanics, deals with equations
of motion for dynamical variables.
Noting that H and U(t) commute for a Hamiltonian which has no explicit time
dependence ([H,U(t)] = 0), it follows that the Hamiltonian is the same in both
Schrödinger and Heisenberg pictures: HH = U †(t)HSU(t) = HS.
The time dependence of an observable, represented by an operator in Heisenberg
picture, such as A(t) in Eq. (3.133), follows from Eq. (3.131) and its conjugate, in
the following sequence of steps:

114
3
The Schrödinger Equation
d
dt A(t) = d
dt

U †(t)AU(t)

=
 d
dt U +(t)

AU(t) + U †(t)A d
dt U(t) =
−(iℏ)−1HU †(t)AU(t) + U(t)†A(iℏ)−1HU(t) = (iℏ)−1
A(t)H −H A(t)

.
(3.134)
We obtain thereby the Heisenberg equation of motion:
iℏd
dt A(t) =

A(t), H

,
(3.135)
showing more explicitly how the Hamiltonian is the generator of the time evolution
of a quantum system. An observable which commutes with the Hamiltonian, so that

A(t), H

= 0, must be constant in time: d A/dt = 0. Such a quantity is known as
a constant of the motion.
A very interesting consequence of the Heisenberg equation of motion is Ehren-
fest’s theorem, which shows that quantum mechanical expectation values obey New-
ton’s classical equations of motion. Let us illustrate this by considering a particle in
one dimension with Hamiltonian H = p2/2m + V (x). The Heisenberg equations
for x(t) and p(t) are given by
iℏdx
dt =

x, H

,
iℏdp
dt =

p, H

.
(3.136)
The commutators can be evaluated in the following steps:

x, H

= 1
2m

x, p2
= 1
2m

p

x, p

+

x, p

p

= iℏp
m ,
(3.137)

p, H

= pV (x) −V (x)p = −iℏdV
dx .
(3.138)
We ﬁnd then
dx
dt = p
m
and
dp
dt = −dV
dx .
(3.139)
Analogous relations can be derived for the expectation values x = ⟨x⟩and p = ⟨p⟩:
d⟨x⟩
dt
= ⟨p⟩
m
and
d⟨p⟩
dt
=

−dV
dx

= F,
(3.140)
where F can be identiﬁed with the classical force. The result is a quantum general-
ization of Newton’s second law:
F = m d2⟨x⟩
dt2 .
(3.141)

3.6 Time Evolution and Collapse of the Wavefunction
115
The TDSE describes the evolution of a quantum system, represented by the state
vector |Ψ (t)⟩in Hilbert space, in a perfectly deterministic way, as represented by
the unitary evolution operator U(t). This deterministic behavior is quite analogous
to the way Newton’s laws govern the motion of a classical system subject to internal
or external forces. Ehrenfest’s theorem above, in fact, gives an explicit connection
between classical and quantum behavior. In general, when physical objects approach
macroscopic dimensions, QM reduces to classical mechanics (apart from certain
low-temperature phenomena, including superconductivity and Bose–Einstein con-
densation).
3.6.3
Collapse of the Wavefunction
In contrast to the unitary deterministic evolution of a quantum system, there is the
phenomenon called collapse (or reduction) of the wavefunction. This is what happens
when a measurement is made on the system, or when the system is subjected to
a perturbation which suddenly changes the Hamiltonian. A collapse can also be
associated with an unpredictable random event, such as the radioactive decay of a
nucleus. Before collapse, a state vector might consist of a superposition of a set of
basis vectors in Hilbert space, something like
|Ψ ⟩=

n
cn|Φn⟩,
(3.142)
where the |Φn⟩are eigenfunctions of some dynamical variable Λ, such that
Λ|Ψ ⟩= λn|Φn⟩.
(3.143)
If |Ψ ⟩is normalized and {|Φn⟩} is an orthonormal set:
⟨Ψ |Ψ ⟩=

m
⟨Φm|c∗
m
 
n
cn|Φn⟩

=

n,m
c∗
mcn⟨Φm|Φn⟩=

n,m
c∗
mcnδm,n =

n
|cn|2 = 1.
(3.144)
The expectation value of Λ in the state |Ψ ⟩, meaning the average over a large number
of independent measurements, is given by
⟨Ψ |Λ|Ψ ⟩=

n
|cn|2λn.
(3.145)
The probability of observing the result λn is evidently given by Pn = |cn|2. And
the sum of probabilities, as it should, adds up to 1:  
n Pn = 1. The situation can

116
3
The Schrödinger Equation
be interpreted as follows. Suppose a system in a state |Ψ ⟩is happily evolving in
accordance with the TDSE. But then someone decides to make a measurement of the
observable Λ. This causes the state vector |Ψ ⟩to collapse into one of the eigenstates
of Λ, say |Φn⟩, while the measurement registers a value λn. It cannot be predicted
which eigenstate results from the collapse, but the probability of observing λn is
equal to |cn|2. It is fairly obvious that there is no way in which continuous unitary
time evolution can produce an instantaneous transition from a superposition to one
of its components. Collapse is, in fact, an irreversible process, akin to the interaction
of a thermodynamic system with its environment.
It should be mentioned that there have been some attempts to include the measure-
ment apparatus in an extended quantum system. Quoting (Grifﬁths 2002, pp. 246):
“…after all, what is special about a quantum measurement? Any real measurement
apparatus is constructed out of aggregates of particles to which the laws of QM
apply, so the apparatus ought to be described by those laws, and not used to provide
an excuse for their breakdown.”
Collapse of the wavefunction, the second possible mode of evolution of a quan-
tum system, has created controversy since the inception of quantum mechanics. In
contrast to the TDSE, the mechanism of collapse had to be added to the theory as
an ad hoc postulate. The replacement of deterministic outcomes by random events,
following only a probabilistic distribution, has long been one of the most contro-
versial epistemological aspects of quantum mechanics. Einstein described the time
evolution of a state in QM as resting on two “legs,” one very solid, but the other much
weaker. Despite the unquestionable experimental success of QM, two aspects—the
irreducible probabilistic character and the existence of two types of time evolution—
have caused much intense opposition to the traditional (Copenhagen) interpretation
of QM, as originally developed by Bohr, Heisenberg, and Dirac.
Fig. 3.11 Does God play dice with the Universe?

3.6 Time Evolution and Collapse of the Wavefunction
117
Fig. 3.12 The 1927 Solvay Congress on the quantum theory. Colorized version from the American
Physical Society historical collection
To reiterate, in QM it is not possible to obtain more detailed knowledge that
can replace probability with certainty. This interpretation of the meaning of the
Schrödinger wavefunction provides the foundation of the Copenhagen interpretation
of QM, which sufﬁces for most practicing scientists nowadays. The most eminent
critic of the probabilistic interpretation of QM was none other than Albert Einstein,
as epitomized in his famous phrase: “God does not play dice with the Universe!” (see
Fig.3.11). By some accounts, Niels Bohr replied with the rejoinder: “Stop telling
God what to do!”
Figure3.12 is a portrait of the participants in the Fifth Solvay International Con-
ference in 1927, including all of the founding fathers of quantum mechanics. They
came together to contemplate the foundations of the newly formulated theory. Here
the long-running dialog between Niels Bohr and Albert Einstein ﬁrst began.
3.7
Philosophical Issues in Quantum Mechanics
The philosophical inclinations of a number of scientists has shaped attitudes regard-
ing the orthodox interpretation of quantum mechanics. Three alternative philosophi-
cal viewpoints have been espoused by physicists who worry about such things: these
are often classiﬁed as Neopositivism, Realism and Idealism:
(1) Neopositivism: The Copenhagen interpretation of QM is in complete agree-
ment with the ideas of Neopositivism, which considers metaphysically meaningless
the question of what actually is the individual trajectory of an electron or a photon.
QM avoids talking about particles “in themselves,” but provides only ways of com-
puting the probabilities that a measurement will give a certain result. The only things
we can talk about are the results of our measurements. An indication of the inﬂu-

118
3
The Schrödinger Equation
ence of positivism on the orthodox interpretation is the word “observable” chosen to
denote any dynamical variable.
(2) Realism: The strongest adversaries of the orthodox interpretation of QM have
been the realists. Among them, there are renowned physicists, including Einstein,
Bohm, and de Broglie. As Einstein once asked Abraham Pais: “Do you really believe
that the Moon is not there when nobody looks?”
(3) Idealism: (Von Neumann 1932; Stapp 2001) The idealists are more willing
to accept the Copenhagen interpretation, albeit with an important stipulation. For
them the state Ψ of a physical system is a mental construct. Therefore they do not
ﬁnd it strange at all that the state makes a “sudden jump” when we carry out a
measurement, because at the moment in which we become aware of the result of that
measurement, our knowledge of the physical system abruptly changes. Quantum
state reduction is therefore a conscious act. Even their point of view is, under certain
circumstances, paradoxical. Regarding this we will describe the well-known paradox
of “Schrödinger’s cat.”
Let us imagine a cat enclosed in a sealed box, along with a vial of cyanide and
a mechanism, driven by a Geiger counter, that can break the vial when the decay of
an atom in a radioactive sample is detected. An atom’s decay is a random event, so
that its precise time cannot be predicted. Only its half-life is known. Assume that the
experiment is run for a length of time such that a decay will occur with a probability
of 50%. At the end of this time, is the cat alive or dead? If the “reduction” of the
state Ψ of the cat happens only when an external observer opens the container (when
the observer becomes aware of the result of the experiment) the cat remains in a
superposition state—it is half alive and half dead (see Fig.3.13) until the container is
opened. Probably the cat would greatly object to this interpretation, since he knows
if he is alive (and of course he would object even more strongly to participating in
the experiment).
Some physicists (including de Broglie and Bohm) tried to eliminate the probabilis-
tic aspect of QM introducing some type of “hidden variables” that would determine
the result of a measurement. This would be analogous to statistical mechanics for
atoms and molecules. We cannot see the detailed motions of the atoms with our
eyes, but their statistical behavior explains the laws of thermodynamics. However,
these theories have not been met with general acceptance. For the reader who has
the patience to read Chap.5 we will introduce Bell’s inequality (see, e.g., Bell 1987),
which would be valid for a hidden variable theory satisfying relativity, but would be
violated by QM. Since experiments (Aspect et al. 1981) have conﬁrmed the exis-
tence of quantum entanglement that violates Bell’s inequality, the acceptance of the
orthodox interpretation is further supported. To again quote Grifﬁths (2002), pp. 334:
“In summary, the basic lesson to be learned from the Bell inequalities is that it is
difﬁcult to construct a plausible hidden variable theory which will mimic the sorts
of correlations predicted by quantum theory and conﬁrmed by experiment”. Such a
theory must either exhibit peculiar nonlocality which violates relativity, or else incor-
porate inﬂuences which travel backwards in time, counter to everyday experience.
This seems a rather high price to pay just to have a theory which is more “classical”
than ordinary QM.

3.7 Philosophical Issues in Quantum Mechanics
119
Fig. 3.13 Schrödinger’s cat
Of course, most physicists do not believe that the current interpretation of QM
will survive forever. Among other things, QM relies strongly upon linearity, while
modern physics has uncovered a preponderance of nonlinear phenomena in nature.
Also, it is recognized that quantum mechanics remains incomplete until it can be
coherently incorporated into a “Theory of Everything,” which also contains general
relativity. In fact, Penrose has proposed that quantum gravity is involved in the loss
of coherence of a quantum state, which can purportedly occur whenever space-time
curvature increases to a critical level (Penrose 1996). Probably the most popular
current viewpoint is the hypothesis of decoherence, which we shall discuss further
in Chap.5. Among other things, decoherence explains why a superposition state of
macroscopic objects is generally extremely unstable: this helps to clarify the relation
between classical and quantum mechanics. Some progress has recently been made
by the consistent histories formalism of Gell-Mann, Grifﬁths, Hartle, and Omnes,
(see Grifﬁths 2002, Omnes 1994, Zurek 1991), but it seems that the situation is still
very ﬂuid and far from being satisfactorily resolved.
We might also note that a number of even more exotic interpretations of quan-
tum mechanics have been suggested. Everett and Wheeler once suggested the many
worlds interpretation of quantum mechanics, in which each random event causes
the splitting of the entire Universe into disconnected parallel Universes, in each of
which, one possible outcome becomes the reality. David Deutsch (1997) believes that
the implicit large-scale parallel processing by a quantum computer can be explained
only by the many worlds interpretation of QM. Needless to say, not many people are
willing to accept such a metaphysically unwieldy view of reality. Most scientists are
content to apply the highly successful computational mechanisms of quantum theory
to their work, without worrying unduly about its philosophical underpinnings. As
Feynman put it, “Shut up and calculate!” Much like most of us happily using our com-
puters without acquiring a detailed knowledge of either semiconductor technology
or operating system programming.

120
3
The Schrödinger Equation
The dichotomy of appearance and reality is, in fact, not limited to the quantum
theory, but pervades much of modern science. It applies notably to neuroscience,
regarding the origin of consciousness. In our daily lives, we intuitively assume that
our perceptions, visual, auditory, tactile, etc., actually represent the “real world.” This
simulation has evidently been a reasonably successful one for the human race. Oth-
erwise natural selection would have weeded us out by now. But philosophers, going
back to Plato/Aristotle, have recognized that our perceptions provide merely a model
of external reality (recall Plato’s Parable of the Cave). The most elegant formulation
of the dichotomy was given by Immanuel Kant in his Critique of Pure Reason. Kant
distinguished the separate realms of phenomena and noumena. Phenomena are the
experiences through our senses; noumena are the underlying things which actually
constitute reality. Since the thing in itself (Ding an sich) is, by supposition, entirely
beyond our capabilities, we must be completely unaware of the noumenal realm.
This should provide a healthy dose of modesty for the quantum theorist! Possibly
the best summary of these ideas was expressed in some scribbled grafﬁti one of us
(SMB) once encountered: “Reality is a crutch.”
We end this chapter with a few thoughts of Feynman (1982), on the prospects
of QM becoming part of a consistent and aesthetically beautiful structure. Einstein
thought that quantum mechanics was incomplete. But Einstein was wrong, because
“spooky action at a distance” has now been shown to be real. Where does Feynman
enter the story? Partly because he earned a Nobel Prize for his contributions to
quantum mechanics, but also because he expressed some of his thoughts with a
sublimely poetic perspective, such as the following4:
We have always had a great deal of difﬁculty
understanding the world view
that quantum mechanics represents.
At least I do,
because I’m an old enough man
that I haven’t got to the point
that this stuff is obvious to me.
Okay, I still get nervous with it....
You know how it always is,
every new idea,
it takes a generation or two
until it becomes obvious
that there’s no real problem.
I cannot deﬁne the real problem,
therefore I suspect there’s no real problem,
but I’m not sure
there’s no real problem.
4See also Mermin, Physics Today, April 1985, pp. 38–47.

Chapter 4
New Adventures: Isotropic Vectors,
Rotations, Spinors, and Groups
Abstract Some more specialized mathematical topics are introduced, including
isotropic vectors, rotations, spinors, and Lie groups. The concept of invariance in the
objective world is discussed. The stereographic projection is introduced to describe
the behavior of spinors. The Lie groups SO(3) and SU(2) are studied in detail.
Keywords Isotropic vector · Spinor · Stereographic projection · Lie groups ·
SO(3) · SU(2).
According to many scientiﬁc thinkers, notably Henri Poincaré, intuitive pictures are
essential for the deeper understanding of scientiﬁc principles. This is particularly
true for the subjects covered in this chapter, in which geometrical realizations play
an essential role. We refer to Felix Klein’s classic Erlangen program (Klein 1872),
which characterizes the properties of different geometries. The ideas of Einstein,
Dirac, and Nozick, are then extended to provide a more explicit meaning of the con-
cept of the “objective world.” We will then introduce isotropic vectors, vectors which
are orthogonal to the rotation axis yet remain invariant under rotation. Intuitively, an
apparent contradiction, but resolved when complex vector components are admitted.
Finally, the spin of elementary particles is connected to isotropic vectors by appli-
cation of stereographic projections. The correspondence between “rotations” of the
spinors associated with the SU(2) group and rotations of the physical objects by the
SO(3) group is analyzed, with particular attention to inﬁnitesimal rotations.
In this chapter, we will use symbols of both types: −→
OP and v to denote vectors in
physical space. Since spinors are quantum mechanical attributes, we will use Dirac
notation to represent spin states of particles.
4.1
Invariance and the Objective World
In this section, before resuming the physical and mathematical treatment of our
subject, we will discuss some important epistemological considerations connected
with the concept of invariance. Important contributions were made by Klein, Dirac,
Einstein, and Nozick.
© Springer International Publishing AG 2017
G. Fano and S.M. Blinder, Twenty-First Century Quantum Mechanics:
Hilbert Space to Quantum Computers, UNITEXT for Physics,
DOI 10.1007/978-3-319-58732-5_4
121

122
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
The geometrical properties of a ﬁgure are never properties of a single object, but
can be considered to belong to a class of objects. For example, the property of a
square, wherein the length of a diagonal is equal to the length of a side multiplied by
√
2, does not change if we translate or rotate the square, or if we shrink or enlarge it.
The same is true for the circle, and in general for all the ﬁgures in elementary geom-
etry. The remarkable intuition of Felix Klein, encapsulated in his famous Erlangen
program, is based on classiﬁcation and characterization of a geometry by a group
G of transformations (translations, rotations, and changes of scale for the case of
elementary geometry), and a study of the properties of the ﬁgures that are invariant
with respect to these transformations. Only such properties are meaningful, while all
others are irrelevant for that geometry.
Given a group G of transformations, we can say that two ﬁgures (for example two
triangles or two polygons) A and B are equivalent if there exists a transformation of
G that maps A into B; we write A ∼B. In general, such equivalence is
(1) Reﬂexive: A ∼A.
(2) Symmetric: If A ∼B, B ∼A.
(3) Transitive: If A ∼B and B ∼C, then A ∼C.
From property (1) it follows that the group G contains the identity transformation I,
which leaves any ﬁgure unchanged: IA = A for any A. From property (2) it follows
that for any element g ∈G that sends A into B, there exists a corresponding element
denoted by g−1 ∈G which sends B into A (see Fig.4.1); g−1 is called inverse of g.
Finally, from (3) it follows that if B = g1A and C = g2B, there exists a transformation
denoted by g2g1 that sends directly A into C. Thus g2g1A = C; g2g1 is called product
of g2 and g1 (see Fig.4.2). The existence of the identity I, the inverse g−1, and the
closure of product g2g1 (meaning that it is also a member of the group) characterize
the mathematical properties of a group. (Technically, another property is needed: the
associative property: g1(g2g3) = (g1g2)g3). In general the commutative property
does not hold: it is not necessarily true that g1g2 = g2g1.
An elementary group used in physics is the group of translations. Denoting by
gv the operation of translating a physical object in the v direction a distance |v| we
Fig. 4.1 The group element
g sends A into B; the inverse
g−1 sends B into A

4.1 Invariance and the Objective World
123
Fig. 4.2 g1 sends A in B; g2
sends B in C. The product
g2g1 sends A in C
Fig. 4.3 The translation
vectors v and w adds
according to the
parallelogram’s rule
have (see Fig.4.3) gvgw = gv+w; the identity of the group is gO, and the inverse of
gv is g−v. All quantities used in elementary geometry, such as lengths, angles, areas,
volumes, are invariants with respect to the group of all translations and rotations;
this “big” group is called the Euclidean group.
In our daily lives, we encounter other groups: for example, let us project a ﬁgure
F lying in a plane π from a point P (not belonging to π) to another plane π′. This
is called a perspective projection. It results in a new ﬁgure F′, shown in Fig.4.4.
This procedure can be iterated by repeating the projection from different points to
different planes. A new group of transformations is obtained, from the initial to the
ﬁnal plane. This is called the projective group. Lengths, angles, areas are not invariant
for operations in this group; triangles remain triangles, but equilateral triangles do not
remain equilateral; squares become quadrilaterals; circles are transformed in other
conic sections. In fact, conics always transform to conics. Projections are common

124
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
Fig. 4.4 Perspective
projection of a ﬁgure from
the plane π to the plane π′
in everyday life. If we walk along a long corridor, it appears from our viewpoint
to be a parallelepiped, with the four lines of intersection of the walls with the ﬂoor
and the ceiling appearing to converge to a point. There is some kind of projectivity
from the ﬂoor and the ceiling onto our retinas. A classic result which applies to
both a given ﬁgure and its projection is Brianchon’s theorem: if a hexagon ABCDEF
circumscribes a conic, the lines AD, BE, CF connecting opposite vertices intersect
at a single point P, as shown in Fig.4.5; this remains valid even when projecting the
hexagon onto another plane.
Henri Poincaré wrote: “La geometrie est avant tout l’etude analytique d’un
groupe” (Geometry is, from the most fundamental point of view, the analytic study
of a group). Changing the group varies the geometrical properties which come into
play. In this way, we can have metric, linear, projective, and topological properties
Fig. 4.5 Brianchon’s
theorem: in the hexagon
ABCDEF circumscribed
about a conic, the diagonals
AD, BE, CF intersect at a
single point P

4.1 Invariance and the Objective World
125
of geometrical objects. Another very important aspect concerns our observations of
the physical world. Consider a cube-shaped object, and suppose that we move it
three meters to the east or, what amounts to the same thing, the observer moves three
meters to the west; in the ﬁrst case we have performed an active transformation, in
the second a passive transformation, in which it is the reference frame which moves.
In either case, the transformation belongs to the translation group. Distances between
any two vertices of the cube remain invariant. The same happens if we rotate the cube,
or, equivalently, if we turn our head. Many other properties, including mass, size,
and color, also remain unchanged under translational or rotational transformations.
This need for the observer to “look for invariants” in the observed world is of
such generality that, in our opinion, it is inherent also in the brain of animals. Let us
imagine a gazelle who sees two lions, motionless but ready to pounce. The gazelle
quickly glances at the ﬁrst lion, and then at the second; in doing so, she turns her
head. But there must be something in her brain that enables her to realize that even if
she turns her head (so that her picture of the world changes), the ﬁrst lion is still there,
somehow remaining invariant. If we wanted to build a robot with visual sensors, able
to distinguish objects even when his “eyes” are moving, probably an efﬁcient way
would be to teach him to apply to the input of every visual observation the appropriate
mathematical transformations; he will thus be able to compare images obtained at
different instants, keeping in mind some invariant (or nearly invariant) aspects of the
object. “Smart missiles” operate this way, but we doubt that Nature does things the
same way. However, there must be something “invariant” in relationships among the
various images. These considerations bring us to propose two fundamental concepts
(1) Variations of images.
(2) Existence of common elements, or invariants, as emphasized in Klein’s formu-
lation of possible geometries.
According to the philosopher Robert Nozick (2001), the deep root of objectivity
is the invariance under different transformations. He says that an objective fact must
be accessible from different points of view, and there is an intersubjective agreement
among them. Before Nozick, Dirac wrote: “The important things in the world appear
as the invariants … of these transformations.” In our opinion, Nozick was perfectly
right. For example, when we sleep, our dreams lack this type of “invariance.” Nozick
gave an appealingly convincing meaning to the concept of the “objective world.” It
is interesting to recall that, about 2500 years ago, two great Greek philosophers,
Heraclitus and Parmenides, afﬁrmed the importance of these two conceptual ele-
ments: the former said panta rhei, “everything ﬂows,” while the latter stressed the
“being, timeless, uniform, and unchanging nature of things.” After these currents
of thought, Plato/Aristotle tried to reconcile being with becoming by means of the
notion of eidos, essence. The world would be formed by stable structures in the midst
of continuous unpredictable change. But only in the modern formulation of geometry
(Klein) and the physical laws (Einstein, Dirac), has a most fruitful and consistent
synthesis of the two elements emerged.

126
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
4.2
Isotropic Vectors
We begin this section by considering a somewhat counterintuitive mathematical
object. We have seen that points (x, y) in the Cartesian plane can be considered as
“endpoints” of real vectors OP = (x, y). Now consider the equation
x2 + y2 = 0,
(4.1)
which, in the real number ﬁeld, has only the trivial solution x = 0, y = 0. But using
complex numbers, (4.1) can be factored using
x2 + y2 = x2 + y2 −ixy + ixy = (x + iy)(x −iy) = 0.
(4.2)
It follows that all points on the complex straight lines
y = ±ix
(4.3)
belong to the circle of zero radius (4.1)! Of course, the “magic” enters with the use
of complex coordinates; still it is amazing that an inﬁnitesimal circle can split into
two straight lines.
Let us now consider two vectors z1, z2, belonging, respectively, to the two lines
(4.3)
z1 = (1, i),
z2 = (1, −i).
(4.4)
(We do not denote these vectors by z1, z2 since, being complex, they do not belong
to our physical space). Note that each z2 = 0 (z2 not to be confused with z∗z). These
complex vectors have the very interesting property of being invariant under rotation.
All vectors can be rotated, but z1, z2 remain ﬁxed. Applying the rotation matrix (see
Chap.2) to z1, we ﬁnd:
R z1 =


cos θ −sin θ
sin θ
cos θ




1
i

 =


cos θ −i sin θ
sin θ + i cos θ

 =
(cos θ −i sin θ)


1
i

 = e−iθ z1.
(4.5)
We see that z1 and z2 are eigenvectors of the rotation matrix for any value of θ, with
corresponding eigenvalues e∓iθ, which are just phase factors of magnitude 1; z1 and
z2 are called isotropic vectors.1,2
1A useful account of isotropic vectors and spinors, by their inventor, is found in Cartan (1966).
2Isotropic vectors can be pictured as having a direction, but zero magnitude. In four-dimensional
Minkowski spacetime of special relativity, there occur null or lightlike 4-vectors. For example,
x2 + y2 + z2 −c2t2 = 0 describes the path of a light ray. It might be surmised that a light ray has a
direction, but zero magnitude.

4.2 Isotropic Vectors
127
If we remain in the real plane R2, or in its complex generalization C2 (two-
component complex vectors), there are no other invariant vectors with respect to the
rotation matrix. But if we consider rotations in physical three-dimensional space R3,
there is another invariant direction, that of the rotation axis. For example, considering
the rotation Rz in the x–y plane
Rz =


cos θ −sin θ 0
sin θ
cos θ 0
0
0
1


.
(4.6)
The rotation is about the z axis, and the isotropic vectors Z1, Z2 are (we use capital
letters to indicate that these are now three-dimensional):
Z1 = (1, i, 0),
Z2 = (1, −i, 0).
(4.7)
In the following we will see that isotropic vectors are closely related to the represen-
tation of spin for elementary particles.
A random philosophical observation: humans existed for hundreds of thousands
of years before ﬁnding a technical application for a rotation axis, namely, the wheel;
mathematicians understood the importance of the isotropic vectors Z1, Z2 only a
century ago. But Nature knew all about them since the beginning of time, implicitly
using them in the rotations of stars and planets and in the spin of particles.
4.3
The Stereographic Projection
An elegant way to introduce the quantum mechanical spin of particles is to establish a
correspondence between the points P with coordinates (x, y, z) on a sphere of radius
1, satisfying the equation
x2 + y2 + z2 = 1,
(4.8)
and points in the complex plane. We will also see that there is a close correspondence
between the two isotropic directions, Z1, Z2 in Eq. (4.7) and the representation of
spin states, which show analogous behavior under rotation. Also, as we shall see, the
mathematical description of spin will necessarily involve complex variables.
Let O(0, 0, 0) be the center of a sphere, N(0, 0, 1) the north pole and S(0, 0, −1)
the south pole (see Fig.4.6). Let P′(x′, y′, 0) be the intersection of the line SP with
the equatorial plane z = 0, and Q(0, 0, z) the projection of P(x, y, z) on the z axis.
P′ is called the stereographic projection3 of P. From the similar triangles SOP′, SQP
we ﬁnd:
3In complex analysis, the inverse transformation is considered: the extended complex plane (includ-
ing the point at inﬁnity) can be projected onto the Riemann sphere.

128
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
Fig. 4.6 Stereographic
projection of the unit sphere
from the south pole S onto
the plane z = 0; it sends the
northern hemisphere onto the
region inside the unit circle,
the southern hemisphere
onto the region outside the
unit circle; the equator
coincides with the circle.
The closer P is to S, the more
distant is the image P′ from
O in the shaded plane
x′
x = y′
y = SO
SQ =
1
1 + z.
(4.9)
Now introduce, in the plane z = 0, the complex variable ζ
ζ = x′ + iy′ = x + iy
1 + z ,
(4.10)
It is useful to write ζ as the ratio of two complex numbers
ζ = φ
ψ ,
φ = α(x + iy),
ψ = α(1 + z),
(4.11)
where α is a constant to be determined. We might perhaps anticipate that a vector
(ψ, φ) might represent the quantum mechanical spin state associated with the fun-
damental particles of matter: electrons, protons, neutrons, etc. The term spin implies
rotation, since the pioneers of quantum theory originally imagined the electron as a
tiny rotating sphere. In our case, the rotation axis is parallel to P(x, y, z). For example,
if the rotation is about the z-axis, one isotropic vector can be


1
0

, corresponding to
the spin-up state. The spin state is represented by a spinor


ψ
φ

, belonging to C2,

4.3 The Stereographic Projection
129
the two-dimensional complex vector space. Two vectors |u⟩, |v⟩form an orthonormal
basis in C2 if they are of unit length and orthogonal:
⟨u|u⟩= ⟨v|v⟩= 1,
⟨u|v⟩= 0.
(4.12)
Since quantum states are represented by vectors of unit length, the spinor |Ψ ⟩=


ψ
φ

 must fulﬁll the condition
⟨Ψ |Ψ ⟩= ψ∗ψ + φ∗φ = |ψ|2 + |φ|2 = 1.
(4.13)
Using (4.8) and (4.11), we ﬁnd
|ψ|2 + |φ|2 = |α|2
x2 + y2 + (1 + z)2
= |α|2(2 + 2z) = 1,
(4.14)
which determines the constant α
|α| =
1
√2(1 + z).
(4.15)
to within a phase factor eiϕ. Taking the complex conjugate of (4.11) we have
ψ∗= α∗(1 + z),
φ∗= α∗(x −iy).
(4.16)
From Eqs.(4.11) and (4.14), the following relations between the spinor |Ψ ⟩=


ψ
φ


and the vector −→
OP = (x, y, z) can be derived4:
x = ψφ∗+ ψ∗φ,
y = i(ψφ∗−ψ∗φ),
z = ψψ∗−φφ∗.
(4.17)
Note that while the spinor (ψ, φ) uniquely determines −→
OP(x, y, z), the converse is
not true, since α is determined only up to a phase factor eiϕ. In particular, the spinor
|Ψ ⟩= (ψ, φ) and the spinor −|Ψ ⟩= (−ψ, −φ) correspond to the same vector
−→
OP(x, y, z).
At the beginning of this section we showed that, to the point P(x, y, z) of the sphere
of radius 1, there corresponds (up to a phase factor eiϕ) a complex spinor |Ψ ⟩=


ψ
φ


of norm 1. It is easy to verify that |Ψ ⟩is an eigenvector of the Hermitian matrix
4By elementary calculations, using (4.8):
(1) |α|2
(1 + z)(x −iy) + (1 + z)(x + iy)

= 2|α|2(1 + z)x = x;
(2) i|α|2
(1 + z)(x −iy) −(1 + z)(x + iy)

= 2|α|2(1 + z)y = y;
(3) |α|2
(1+z)2−x2−y2
= |α|2
(1+z2+2z−x2−y2
= |α|2
x2+y2+z2+z2+2z−x2−y2
=
2|α|2(1 + z)z = z.

130
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
H = H(−→
OP) =


z
x −iy
x + iy
−z

 ,
(4.18)
with the eigenvalue +1:
H|Ψ ⟩=


z
x −iy
x + iy
−z




ψ
φ

 =


zψ + (x −iy)φ
(x + iy)ψ −zφ

 =
α


z(1 + z) + x2 + y2
(x + iy)(1 + z) −z(x + iy)

 = α


1 + z
x + iy

 =


ψ
φ

 = |Ψ ⟩.
(4.19)
Let us denote by |Φ⟩= (X, Y) the second normalized eigenvector of H; |Φ⟩must
fulﬁll the conditions
⟨Φ|Φ⟩= 1,
⟨Ψ |Φ⟩= 0.
(4.20)
Thus Xψ∗+ Yφ∗= 0, X∗X + Y ∗Y = 1, and we can set:
X = φ∗,
Y = −ψ∗,
and thus
|Φ⟩=


φ∗
−ψ∗

 .
(4.21)
Clearly, H|Φ⟩= −|Φ⟩; so that the eigenvalue of |Φ⟩equals −1.
The matrix H represents a physical observable, the projection of the spin in the
direction −→
OP = (x, y, z). The possible results of a measurement are +1 or −1. In
the former case, after the measurement the spin state is Ψ , we can say that the spin
is parallel to −→
OP; in the latter case, the spin state is |Φ⟩, and the spin is antiparallel
to −→
OP. This interpretation is consistent with the following: changing −→
OP in −−→
OP we
have:
H(−−→
OP) =


−z
−x + iy
−x −iy
z

 = −H(−→
OP),
(4.22)
thus the eigenvalues are reversed
H(−−→
OP)|Ψ ⟩= −|Ψ ⟩,
H(−−→
OP)|Φ⟩= |Φ⟩.
(4.23)
If x = y = 0, z = 1, −→
OP coincides with the north pole −→
ON, and H is diagonal
H(−→
ON) =


1 0
0 −1

 .
(4.24)
The eigenvectors are e1 = (1, 0) and e2 = (0, 1). Suppose now we measure H(−→
ON)
on an arbitrary spinor |Ψ ⟩= (ψ, φ). The probabilities p1, p2 of obtaining the results
+1 and −1 are respectively
|⟨e1|Ψ ⟩|2 = |ψ|2,
|⟨e2|Ψ ⟩|2 = |φ|2.
(4.25)

4.3 The Stereographic Projection
131
From (4.11) and (4.15), we see that the probabilities p1 and p2 depend only on z
p1 = |ψ|2 = 1 + z
2
,
p2 = |φ|2 = 1 −z
2
.
(4.26)
This result is reasonable: if −→
OP = −→
ON, z = 1, so that p1 = 1 and p2 = 0; if
−→
OP = −→
OS (south pole), z = −1, p1 = 0 and p2 = 1. Finally, if −→
OP lies somewhere
on the equatorial circle, z = 0 and the two probabilities are equal: p1 = p2 = 1
2.
As mentioned at the beginning of this section, we can prove that there is a corre-
spondence between isotropic vectors and spinors. First, let us generalize the concept
of isotropic vectors to an arbitrary plane. The equation
x2 + y2 + z2 = 0
(4.27)
admits only the solution x = y = z = 0 in the real ﬁeld. However in the complex
ﬁeld there is an inﬁnite number of solutions. In the plane z = 0, we ﬁnd the invariant
vectors Z1, Z2, from Eq. (4.7). For example, x = 3, y = 4, z = 5i, etc. All these
vectors determine an isotropic direction. Let us now consider a plane π through the
origin, and let X1, X2 be two orthonormal vectors belonging to π. Let n be a unit
vector orthogonal to π (see Fig.4.7). Therefore {X1, X2, n} forms an orthonormal
basis. Since both sets {e1, e2, e3} and {X1, X2, X3} are orthonormal bases, we can
use the following correspondence between vectors related to the plane z = 0 and
vectors belonging to π (Table4.1).
Fig. 4.7 The axis n of a
rotation in the plane π, and
two orthonormal vectors x1,
x2 in the plane
Table 4.1 Relationship between vectors
Plane z = 0
normal e3 = (0, 0, 1)
Plane π
normal n
e1 = (1, 0, 0), e2(0, 1, 0)
X1, X2
Z1 = e1 + ie2; Z2 = e1 −ie2
Z1 = X1 + iX2; Z2 = X1 −iX2

132
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
Z1 = X1 + iX2 and Z2 = X1 −iX2 belong to π since X1 and X2 do, while Z1 and
Z2 are isotropic directions in the plane π. Indeed we can write, using the ordinary
(not Hermitian) scalar product
(Z1, Z1) = (X1 + iX2, X1 + iX2) =
(X1, X1) + i(X1, X2) + i(X2, X1) −(X2, X2) = +1 −1 = 0,
(4.28)
and analogously (Z2, Z2) = 0. As an example:, let n be the vector
1
√
3(1, 1, 1), and
R = (x, y, z) an arbitrary vector. The condition that R belongs to π is (n, R) = 0, or
x + y + z = 0.
(4.29)
We can choose:
X1 =
1
√
2
(−1, 1, 0),
X2 =
1
√
6
(1, 1, −2).
(4.30)
Thus the isotropic directions of π can be chosen as
Z1,2 =

−1
√
2
±
i
√
6
,
1
√
2
±
i
√
6
, ∓2i

(4.31)
Returning to the general case, we identify the unit vector n = (n1, n2, n3) with the
vector −→
OP to the sphere of radius 1 in the stereographic projection (see Fig.4.6). We
still denote by π the plane through the origin orthogonal to n, and by Z1 = (a, b, c),
Z2 = (a∗, b∗, c∗) the two isotropic vectors of π. We prove the following:
Theorem 4.1 Suppose the spin of a particle is parallel to the direction n =
(n1, n2, n3) of physical space. Then the two components ψ, φ of the corresponding
spinor are related to the isotropic directions of π by the following simple formulas:
ψ2 = 1
2(a −ib),
φ2 = −1
2(a + ib),
−2ψφ = c
(4.32)
Proof Clearly (4.32) is equivalent to
a = ψ2 −φ2,
b = i(ψ2 + φ2),
c = −2ψφ.
(4.33)
The theorem can be proved in two steps
(1) Show that the vector (a, b, c), as deﬁned by Eq. (4.33), is isotropic;
(2) Show that it belongs to π.
Step (1) follows easily, since
a2 + b2 + c2 = (ψ2 −φ2)2 −(ψ2 + φ2)2 + 4ψ2φ2 = 0
(4.34)

4.3 The Stereographic Projection
133
In order to prove Step (2), we compute the scalar product of (a, b, c) with (n1, n2, n3);
but ﬁrst let us slightly modify (4.11), using |α| =
1
√2(1+z). Since now (x, y, z) =
(n1, n2, n3), we have
ψ =
1
√2(1 + n3)(1 + n3),
φ =
1
√2(1 + n3)(n1 + in2).
(4.35)
From Eqs.(4.35) and (4.33) we have
a = ψ2 −φ2 =
1
2(1 + n3)

(1 + n3)2 −(n2
1 −n2
2 + 2in1n2)

,
(4.36)
b = i(ψ2 + φ2) =
i
2(1 + n3)

(1 + n3)2 + (n2
1 −n2
2 + 2in1n2)

,
(4.37)
c = −2ψφ =
1
2(1 + n3)

−2(1 + n3)(n1 + in2)

.
(4.38)
Neglecting the common factor
1
2(1+n3), it is tedious but elementary to multiply Eqs.
(4.36)–(4.38) by n1, n2, n3, respectively, add the three results, and prove that both
the real and the imaginary part of (n, Z1) = an1 + bn2 + cn3 vanish. Thus (a, b, c)
is an isotropic vector belonging to π. The Theorem is proved. Since, in formulas
(4.32) and (4.33), the squares ψ2, φ2 are related linearly with a, b, c, it is sometimes
surmised that “spinors are square roots of vectors.”5
Let us next consider what happens to the spinor (ψ, φ) when we perform a rotation
R in physical space. In the simplest case is R = Rz (Eq.(4.6)), a rotation by an angle
θ in the xy-plane
Rz =


cos θ −sin θ 0
sin θ
cos θ 0
0
0
1


.
(4.39)
From (4.7) we know that:
Z1 =


1
i
0


=


a
b
c


,
Z2 =


1
−i
0


=


a∗
b∗
c∗


,
(4.40)
and from (4.32) we ﬁnd the vectors corresponding to the spinors


ψ1
φ1

 ,


ψ2
φ2

:


ψ2
1
φ2
1

 =


a−ib
2
−a+ib
2

 =


1
0

 ,


ψ2
2
φ2
2

 =


a∗−ib∗
2
−a∗+ib∗
2

 =


0
−1

 . (4.41)
5Note that a two-dimensional vector can be represented by a complex number z = x + iy = reiθ.
The square root is √z = √x + iy = √reiθ/2, containing the half-angle, characteristic of spinors.

134
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
Since Z1 and Z2 are invariant under rotation, we have (see (4.5)):
RzZ1 = e−iθ Z1,
RzZ2 = eiθ Z2.
(4.42)
Thus the effect of Rz is to multiply


ψ2
1
φ2
1

 and


ψ2
2
φ2
2

 by e−iθ and eiθ respectively;
consequently the spinors


ψ1
φ1

 and


ψ2
φ2

 will be multiplied by e∓iθ/2. This result
is general: A rotation of angle θ in physical space, corresponds a “rotation” of θ/2
in spinor space. In order to “prove” this statement, let us do some “experimental
mathematics” by examining other relevant particular cases (which will be useful in
the sequel).
Let Rx, Ry represent rotations by angle θ in the y–z and z–y planes, respectively
Rx =


1
0
0
0 cos θ −sin θ
0 sin θ
cos θ


,
Ry =


cos θ 0 sin θ
0
1
0
−sin θ 0 cos θ


(4.43)
These relations can be summarized in a table
Table4.2, it is very simple to check the eigenvalue equations (4.5) for R = Rx
and R = Ry; the eigenvalues are always e∓iθ, and the eigenvectors are the isotropic
vectors. The values of ψ2 and φ2 shown in the Table follow immediately. Since ψ2
and φ2 depend linearly on a and b, if we perform a rotation they will be multiplied
by eiθ and everything works as in the case of Rz. The spin-up spinor


ψ
φ

 turns
out to be multiplied by e−iθ/2 and the spin-down spinor


φ∗
−ψ∗

 by eiθ/2. In the last
column of Table4.2, three particular cases of the observable H appear. We recall that
H represents the spin components in the n = (n1, n2, n3) direction. For the three
cases: n = (1, 0, 0), n = (0, 1, 0), n = (0, 0, 1), the corresponding H matrices are
the famous Pauli spin matrices σx, σy, σz, respectively
σx =


0 1
1 0

 ,
σy =


0 −i
i 0

 ,
σz =


1 0
0 −1

 .
(4.44)
Considering σx, σy, σz as the components of a vector σ, we can write formally:
H = n·σ = n1σx +n1σy+n3σz. Thus σx, σy, σz represent the spin components in the
directions of the three axes, and H represents the spin component in the n direction.
Of course these components are not numbers, but matrices. The eigenvalues of the
spin matrices are ±1 (see Eq.(4.19)) and the eigenvectors are the corresponding
spinors for spin-up and spin-down states.
It is instructive to compare the representation of orthogonal states in real three-
dimensional space to that in Hilbert space. The two opposite spatial orientations
of a spin- 1
2 particle, up (↑) and down (↓), are 180◦apart. But in Hilbert space,

4.3 The Stereographic Projection
135
Table 4.2 Rotations and spinors
Rotation
axis n
Rotation
matrix
Isotropic
vector Z1
ψ2 = a−ib
2
φ2 = −a−ib
2
Spin-up spinor
|Φ1⟩= (ψ, φ)
Spin-down spinor
|Φ2⟩= (φ∗, −ψ∗)
matrix H
H =


n3
n1 −in2
n1 + in2
−n3




1
0
0


Rx


0
1
i


−i
2
−i
2
1
2


1 −i
1 −i


1
2


1 + i
−1 −i


σx =


0 1
1 0




0
1
0


Ry


−i
0
1


−i
2
+ i
2
1
2


1 −i
1 + i


1
2


1 −i
−1 −i


σy =


0 −i
i 0




0
0
1


Rz


1
i
0


1
0


1
0




0
−1


σz =


1 0
0 −1



136
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
orthogonal vectors or spinors are oriented perpendicularly, 90◦apart. This accounts
for the occurrence of half-angles (such as θ/2) in formulas involving spinors.
4.3.1
Spinors in Spherical Coordinates
An instructive alternative approach to the preceding results can be found by express-
ing n = (n1, n2, n3) in spherical polar coordinates. Since n lies on the unit sphere,
we ﬁnd, for its components, n1 = sin θ cos ϕ, n2 = sin θ sin ϕ, n3 = cos θ. Note
also the combinations: n1 ±in2 = sin θ e±iϕ. The Hermitian operator H in Eq. (4.18)
can be expressed in spherical coordinates as
H = n · σ =


n3
n1 −in2
n1 + in2
−n3

 =


cos θ
sin θ e−iϕ
sin θ eiϕ −cos θ

 .
(4.45)
The eigenvalues of the spin, in any direction, have previously found to be ±1, which
we also call spin-up (↑) and spin-down (↓), respectively. Now let |Ψ (θ) ↑⟩=


ψ
φ


be an eigenvector of H with the eigenvalue +1, so that


cos θ
sin θ e−iϕ
sin θ eiϕ −cos θ




ψ
φ

 =


ψ
φ

 .
(4.46)
Expanding out the matrix equation, we ﬁnd
(cos θ)ψ + (sin θ e−iϕ)φ = ψ,
(sin θ eiϕ)ψ −(cos θ)φ = φ.
(4.47)
The second equation can be rearranged to
(sin θ eiϕ)ψ −(1 + cos θ)φ = 0.
(4.48)
An obvious solution is ψ = const (1 + cos θ), φ = const sin θ eiϕ. The constant
can be determined by the normalization condition |ψ|2 + |φ|2 = 1, which leads to
const = ±1/√2 + 2 cos θ. Choosing the + sign, we can write
ψ =
1 + cos θ
√2 + 2 cos θ
and
φ =
sin θ eiϕ
√2 + 2 cos θ .
(4.49)
We now make use of two half-angle trigonometric identities
	
1 + cos θ
2
= cos θ
2
and
sin θ = 2 sin θ
2 cos θ
2,
(4.50)

4.3 The Stereographic Projection
137
which simpliﬁes Eq. (4.49) to
ψ = cos θ
2,
φ = sin θ
2 eiϕ.
(4.51)
Finally, the spinor for the eigenvalue +1 (spin-up ↑) can be written:
|Ψ (θ) ↑⟩=


cos(θ/2)
sin(θ/2)eiϕ

 .
(4.52)
By an analogous analysis for the eigenvalue −1 (spin-down ↓), it can be shown that
|Ψ (θ) ↓⟩=


sin(θ/2)
−cos(θ/2)eiϕ

 .
(4.53)
It is very clear that the spinors (4.52) and (4.53) are mutually orthogonal.
For this Hilbert space, the basis spinors are the states with spin-up | ↑⟩and spin-
down | ↓⟩along the axis with θ = 0
| ↑⟩=


1
0


and
| ↓⟩=


0
1

 .
(4.54)
The spinors (4.52) and (4.53) can thereby be expressed as the linear combinations
|Ψ (θ) ↑⟩= cos θ
2| ↑⟩+sin θ
2eiϕ| ↓⟩, |Ψ (θ) ↓⟩= sin θ
2| ↑⟩−cos θ
2eiϕ| ↓⟩. (4.55)
In a measurement of the z spin component, the probabilities of observing spin-up
and spin-down in the state |Ψ (θ) ↑⟩are, respectively,
p(↑) = |⟨↑|Ψ (θ)⟩|2 = cos2 θ
2
and
p(↓) = |⟨↓|Ψ (θ)⟩|2 = sin2 θ
2.
(4.56)
It should be noted that these relations apply to a single electron spin. In the following
chapter, we will be dealing with analogous measurements in a two-electron system.
4.4
Lie Groups: SO(3) and Vector Rotation, SU(2)
and Spinor Rotation
We know that 3 × 3 rotation matrices leave invariant the scalar product of vectors
in the physical space R3; this set of matrices comprise the group SO(3). S stands
for special meaning that the matrices have determinant +1. As a consequence, the
group does not include any transformations that map an object into its mirror image
in any plane. Similarly, the 2×2 complex matrices that leave invariant the Hermitian

138
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
scalar product between spinors (normalized vectors in C2) constitute a group called
SU(2). The norms (lengths) of both types of vectors is left invariant by their respective
transformations. A simple and instructive way to study the relation between rotations
in physical space and “rotations” in spinor space is to consider inﬁnitesimal rotations:
rotations that differ inﬁnitesimally from the identity. Recall that the identity matrix
I is deﬁned, in any number of dimensions, by Iv = v for any v. The 2 × 2 and 3 × 3
identity matrices are:
I2 =


1 0
0 1

 ,
I3 =


1 0 0
0 1 0
0 0 1


.
(4.57)
Let us consider ﬁrst the two-dimensional case. Let R(θ) denote the rotation matrix
R(θ) =


cos θ −sin θ
sin θ
cos θ

 .
(4.58)
Recall the series expansions:
cos θ = 1 −θ2
2! + θ4
4! −. . . ,
sin θ = θ −θ3
3! + θ5
5! −. . .
(4.59)
As θ →0, cos θ →1 and sin θ →0. We can safely use the approximations
cos δθ ≈1 and sin δθ ≈0 as long as δθ is inﬁnitesimal. Thus, given a vector
v =


x
y

 in the plane, we can write
R v ≃


1 −δθ
δθ
1




x
y

 =


1 0
0 1




x
y

 + δθ


0 −1
1 0




x
y

 ≃(I2 + Λ0δθ)v,
(4.60)
where Λ0 is the derivative dR
dθ computed at θ = 0
Λ0 =


0 −1
1 0

 ,
(4.61)
Note that Λ0v =


−y
x

, thus ⟨v|Λ0v⟩= 0, so that Λ0v is orthogonal to v.
Let us now examine the geometrical meaning of these formulas. For any value
of θ, the vector R(θ)v is obtained by a rotation of the vector v by an angle θ. But
for inﬁnitesimal δθ, R(δθ)v −v is tangent to the circle of radius |v| at the point v
(see Fig.4.8). This is completely analogous to the behavior of the velocity vector
for a particle in circular motion: tangent to the circle and normal to the radius. The
case of an inﬁnitesimal rotation Rz(δθ) around the z axis is entirely analogous. With
v = (x, y, z), we have

4.4 Lie Groups: SO(3) and Vector Rotation, SU(2) and Spinor Rotation
139
Fig. 4.8 For small δθ,
R(δθ)v −v is “almost”
tangent to the circle of radius
|v| at the point v
Rz(δθ) v ≃


1 −δθ 0
δθ
1
0
0
0
1




x
y
z


= (I3 + Λ3δθ)v,
(4.62)
where
Λ3 =


0 −1 0
1 0 0
0 0 0


.
(4.63)
The vector Λ3v = (−y, x, 0) is orthogonal to v = (x, y, z) and can be imagined to be
tangent to the circle traced out by R(θ)v as θ varies between 0 and 2π (see Fig.4.9).
We call Λ3 the inﬁnitesimal rotation operator (or generator) about the z axis. We
can repeat the same arguments for the cases of the x and y axis (see Figs.4.10 and
4.11). In this way we ﬁnd the inﬁnitesimal operators Λ1, Λ2:
Rx(δθ) v ≃


1 0
0
0 1 −δθ
0 δθ
1


v = (I3 + Λ1δθ)v,
Λ1 =


0 0 0
0 0 −1
0 1 0


.
(4.64)
Ry(δθ) v ≃


1
0 δθ
0
1 0
−δθ 0 1


v = (I3 + Λ2δθ)v.
Λ2 =


0 0 1
0 0 0
−1 0 0


(4.65)
Let us now consider the general case of a rotation about an axis directed along the

140
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
Fig. 4.9 The vector Λ3v for
a rotation Rz around the z
axis
Fig. 4.10 The vector Λ1v
for a rotation Rx around the x
axis
unit vector n = (n1, n2, n3). We assume again that δθ is inﬁnitesimal. The following
theorem assures that it is “reasonable” to write R(δθ) ≃I3 + Λδθ, where
Λ =


0
−n3 n2
n3
0
−n1
−n2 n1
0


= n1Λ1 + n2Λ2 + n3Λ3
(4.66)
Theorem 4.2 For any v = (x, y, z), the vector Λv is orthogonal both to v and the
rotation axis n. The rotation from v to Λv is “seen” as counterclockwise from n.

4.4 Lie Groups: SO(3) and Vector Rotation, SU(2) and Spinor Rotation
141
Fig. 4.11 The vector Λ2v
for a rotation Ry around the y
axis
Proof We have
Λv =


0
−n3 n2
n3
0
−n1
−n2 n1
0




x
y
z


=


−n3y + n2z
n3x −n1z
−n2x + n1y


.
(4.67)
By the deﬁnition of scalar product, we have
v · Λv = x(−n3y + n2z) + y(n3x −n1z) + z(−n2x + n1y) = 0,
(4.68)
n · Λv = n1(−n3y + n2z) + n2(n3x −n1z) + n3(−n2x + n1y) = 0.
(4.69)
With regard to the last part of the Theorem, it is sufﬁcient to note that the general
case n = (n1, n2, n3) can be transformed continuously to n = (0, 0, 1), where the
property holds (see also Figs.4.9, 4.10 and 4.11). Remark: The Theorem can be
shown more directly by noting that Λv = n × v. We have however chosen to show
the elementary calculations in detail.
For all the possible axis n, the relative positions of v, Λv and n are the same as
in the three particular cases n = (1, 0, 0), n = (0, 1, 0), n = (0, 0, 1). The reader
might wonder if an inﬁnitesimal rotation R(δθ) about n can always be written as
R(δθ) ≃I3 + Λδθ = I3 + δθ(n1Λ1 + n2Λ2 + n3Λ3)
(4.70)
This conjecture turns out to be true, although we will not give a rigorous proof.
Now that we have learned about inﬁnitesimal rotations in three dimensions, we
turn to the analogous case for two complex dimensions. Since normalized two-
dimensional vectors of C2 represent physical states, we will use Dirac notation. Let
us consider a general 2 × 2 complex matrix
U =


a b
c d

 .
(4.71)

142
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
U maps the two orthonormal basis vectors |i⟩=


1
0

, | j⟩=


0
1

, to the vectors
U|i⟩=


a
c

 , U| j⟩=


b
d

. Let us require that, under U, the Hermitian scalar
product remains invariant; since ⟨i|i⟩= ⟨j| j⟩= 1, ⟨i| j⟩= 0, the same relations
must hold for |Ui⟩, |Uj⟩
⟨Ui|Ui⟩= a∗a + c∗c = 1,
⟨Uj|Uj⟩= b∗b + d∗d = 1,
⟨Uj|Ui⟩= b∗a + d∗c = 0.
(4.72)
From these equations it follows that a possible solution for the matrix A is given by6
U =


a
b
−b∗a∗


(4.73)
with the condition:
|a|2 + |b|2 = 1.
(4.74)
Let us denote by SU(2) the set of 2 × 2 complex matrices of the form (4.73) obeying
the condition (4.74). This leads to the following:
Lemma 4.1 A matrix U belonging to SU(2) leaves invariant the Hermitian norm of
any vector.
Proof Let |r⟩=


x
y

, then U|r⟩=


ax + by
−b∗x + a∗y

, and
⟨Ur|Ur⟩= (ax + by)(a∗x∗+ b∗y∗) + (−b∗x + a∗y)(−bx∗+ ay∗) =
|x|2(aa∗+ bb∗) + |y|2(bb∗+ aa∗)+
xy∗(ab∗−b∗a) + yx∗(ba∗−a∗b) = |x|2 + |y|2.
(4.75)
In order to prove that SU(2) is a group, one can verify, by explicit calculation, that:
(1) If U1 ∈SU(2), U2 ∈SU(2), then U1U2 ∈SU(2).
(2) The identity I2 ∈SU(2).
(3) The inverse U−1 ∈SU(2), etc.
However we prefer to focus on the invariance of the norm, using the following
identities:
|U2(U1r)| = |U1r| = |r|,
|I2r| = |r|,
(4.76)
6Setting A = |a|2, B = |b|2, C = |c|2 and D = |d|2, Eq.(4.72) can be written as A = 1 −C,
B = 1 −D; multiplying these two equations we have AB = 1 −D −C + DC; but BA = DC, thus
D + C = 1. Finally, adding A = 1 −C and B = 1 −D we ﬁnd A + B = 2 −(D + C) = 1, and
(4.74) is proved. It is then simple to verify that if c = −b∗and d = a∗, Eq.(4.72) are satisﬁed.

4.4 Lie Groups: SO(3) and Vector Rotation, SU(2) and Spinor Rotation
143
etc. Deﬁning SU(2) as the set of 2 × 2 complex matrices that leave the Hermitian
norm of vectors invariant, it follows from (4.76) that SU(2) is a group. Note that the
same reasoning can be followed using the concept of Hermitian scalar product of
two vectors. Invariance is the key idea connected with the group concept.
And now a nice geometrical result: The set of matrices SU(2) can be represented
as a 3-sphere of unit radius in four-dimensional space R4 (a 3-sphere, also called
a hypersphere, is the four-dimensional analog of a sphere; sometimes we will skip
the label “3”). In fact the matrix U (4.73) depends upon the two complex numbers
a = a1+ia2, b = b1+ib2; condition (4.74) in terms of the four numbers a1, a2, b1, b2
becomes:
a2
1 + a2
2 + b2
1 + b2
2 = 1
(4.77)
which is the equation of the 3-sphere with unit radius and center at the point O =
(0, 0, 0, 0). Note that U depends on just three parameters, since the four real numbers
must satisfy one additional condition. To any point on the sphere there corresponds a
group element; conversely to any element of SU(2) there corresponds a point on the
sphere. For example, the identity I2 corresponds to a = 1, b = 0, so that the point
a1 = 1, a2 = 0, b1 = 0, b2 = 0 still corresponds to I2). As we have anticipated, it is
useful to consider very small displacements from I2. Geometrically, this corresponds
to a very small neighborhood of points on the sphere (4.77) around I2 = (1, 0, 0, 0).
In the following, we denote by ε1, ε2, ε3, inﬁnitesimally small real numbers. Let
us consider, instead of the sphere (4.77) in four-dimensional space, which we are
not able to draw, the more accessible sphere x2 + y2 + z2 = 1, in three-dimensional
space. Denote by −→
ON = (0, 0, 1) the vector from the origin to the north pole. Vec-
tors like (ε1, ε2, 1) = (0, 0, 1) + (ε1, ε2, 0) have their endpoints on the sphere
in a neighborhood of N, since the vector (ε1, ε2, 0) is orthogonal to the z axis
(see Fig.4.12). By analogy, it is clear that four-dimensional vectors (1, ε3, ε2, ε1)
belong to the sphere (4.77) in a neighborhood of the point (1, 0, 0, 0). In fact,
1 + ε2
1 + ε2
2 + ε2
3 differs from 1 by second-order inﬁnitesimals. Since for these
vectors a1 = 1, a2 = ε3, b1 = ε2, b2 = ε1, the corresponding matrix U ∈SU(2)
is:
U =


1 + iε3
ε2 + iε1
−ε2 + iε1 1 −iε3

 =


1 0
0 1

 +i


ε3
ε1 −iε2
ε1 + iε2
−ε3

 = I2 +iE (4.78)
Setting:
|ε| =

ε2
1 + ε2
2 + ε2
3,
x = ε1
|ε|, y = ε2
|ε|, z = ε3
|ε|,
(4.79)
the matrix E becomes equal to |ε|H (see (4.18))
E = |ε|


z
x −iy
x + iy
−z

 = |ε|H
(4.80)

144
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
Fig. 4.12 A neighborhood
of the north pole N. The
point (ε1, ε2, 1) belongs to
the plane tangent to the
sphere at the north pole
and x2 + y2 + z2 = 1 as it should. Note also that if −→
OP = (x, y, z) coincides with
(1, 0, 0), (0, 1, 0), (0, 0, 1), respectively, while H becomes one of the Pauli spin
matrices:


0 1
1 0

 ,


0 −i
i 0

 ,


1 0
0 −1


(4.81)
which represent the spin component in the three-axis direction. It follows that H =
xσx + yσy + zσz. The matrix U (4.78) in the neighborhood of the identity becomes:
U ≃I2 + i|ε|H = I2 + i|ε|(xσx + yσy + zσz).
(4.82)
Equations (4.70) and (4.82) look quite similar δθ and ε are inﬁnitesimals, x2 + y2 +
z2 = 1 and n2
1 + n2
2 + n2
3 = 1; but we are about to discover another remarkable
similarity. Recall that the commutator of two matrices A, B is given by

A, B

=
AB −BA. Let us compute the commutator of the inﬁnitesimal operators Λ1, Λ2, Λ3
of the rotation group. From Eqs. (4.63)–(4.65), we easily ﬁnd

Λ1, Λ2

= Λ1Λ2 −Λ2Λ1 = Λ3,

Λ2, Λ3

= Λ2Λ3 −Λ3Λ2 = Λ1,

Λ3, Λ1

= Λ3Λ1 −Λ1Λ3 = Λ2.
(4.83)

4.4 Lie Groups: SO(3) and Vector Rotation, SU(2) and Spinor Rotation
145
A condensed way of writing these three commutation relations is

Λ1, Λ2

= Λ3, et cyc,
(4.84)
where et cyc means that the relation holds when 1, 2, 3 are cyclically permuted (to
3, 1, 2 and 2, 3, 1). In Sect.3.4, the analogous commutation relations for the compo-
nents of angular momentum were shown to be

J1, J2

= iℏJ3, et cyc,
(4.85)
looking quite similar to those for Λi. The main difference is in the domain of the
operators: for the operators Λi here, it is the physical space R3, while for the compo-
nents of angular momentum, it is the Hilbert space of states of the system. Moreover,
the Λi operators are dimensionless, while the angular momentum operators Ji have
the same dimension as ℏ. Comparing the commutation relations, we can identify
Ji = iℏΛi.
(4.86)
The commutation relations for the Pauli spin matrices σx, σy, σz of the complex
group SU(2) (see Eq.4.82) are given by

σx, σy

= σx σy −σy σx = 2iσz, et cyc
(4.87)
These evidently are related to angular momentum operators by
J1 = ℏ
2σx,
J2 = ℏ
2σy,
J3 = ℏ
2σz.
(4.88)
The factors ℏ/2 evidently reﬂect the fact that these represent spin- 1
2 particles. From
now on, for compactness in notation, we will be using units with ℏ= 1.
In summary, we ﬁnd that in the neighborhood of the identity an element of the
3 × 3 rotation group can be written
R(δθ) ≃I3 + δθ(n1Λ1 + n2Λ2 + n3Λ3) = I3 −iδθ(n1J1 + n2J2 + n3J3), (4.89)
and an element U of SU(2) can be written
U ≃I2 −iδθ
2 (n1σx + n2σy + n3σz) .
(4.90)
The inﬁnitesimal rotations (4.89) in R3 and (4.90) in C2 show a one-to-one corre-
spondence, provided we remain close to the identity. However, we will see later that
this is no longer globally true for the full groups SO(3) and SU(2).
Accordingly, we can state

146
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
Theorem 4.3 In the neighborhood of the identity, the operators U(R) preserve the
group structure.
Proof We need to prove that U(R) sends products into products, the identity I3 to the
identity I2, the inverse to the inverse. Consider two inﬁnitesimal rotations R1(δα),
R2(δβ), and let n = (n1, n2, n3), m = (m1, m2, m3) denote the two unit vectors along
the rotation axis. We have:
R1 ≃I3 −iδα(n1J1 + n2J2 + n3J3), R2 ≃I3 −Iδβ(m1J1 + m2J2 + m3J3). (4.91)
Since δα, δβ are inﬁnitesimal, we can safely neglect higher order terms containing
δα δβ. Furthermore I3I3 = I3. Thus
R1R2 ≃I3 −i

(δα n1 +δβ m1)J1 +(δα n2 +δβ m2)J2 +(δα n3 +δβ m3)J3

. (4.92)
By Eq. (4.90) we have
U(R1) ≃I2 −iδα
2 (n1σ1 + n2σ2 + n3σ3),
U(R2) ≃I2 −iδβ
2 (m1σ1 + m2σ2 + m3σ3).
(4.93)
Again, neglecting terms containing the product δα δβ, we ﬁnd
U(R1)U(R2) ≃I2 −i
2

(δα n1 + δβ m1)σ1 +
(δα n2 + δβ m2)σ2 + (δα n3 + δβ m3)σ3

= U(R1R2).
(4.94)
Therefore U maps “products into products”. If the angle δθ is zero, R = I3 and
U(R) = I2 (recall that I2, I3 are the identity operators). From (4.92) we see that
for n = m and δβ = −δα, R1R2 = I3, thus R2 = R−1
1 . By the same argument
U(R1)U(R2) = I2, so that U(R2) = U(R1)−1 and the Theorem is proved.
If the correspondence U(R) were to preserve the group properties for the entire
rotation group SO(3), we would say that the matrices U(R) form a representation
of SO(3). Actually we have proven the Theorem only in the neighborhood of the
identity. A natural question: is (4.94) valid for all elements of the rotation group?
The answer is afﬁrmative, but given the heuristic nature of our approach, we will just
show that it is plausible that U(R1)U(R2) = U(R1R2) for all R1, R2. We know that
the rotation R(θ) about the z axis is (see Eq.(4.39))
Rz =


cos θ −sin θ 0
sin θ
cos θ 0
0
0
1


(4.95)

4.4 Lie Groups: SO(3) and Vector Rotation, SU(2) and Spinor Rotation
147
Fig. 4.13 Geometrical proof
that the sum of two rotations
of 3π/2 is equivalent to a
rotation of π
Note that θ can be any real number; however Rz(θ ± 2π) = Rz(θ ± 4π) = · · · =
Rz(θ), and in general Rz(θ ±2kπ) = Rz(θ) for all integer k. The matrices Rz(θ) form
a group that we will call Gz. Of course,
Rz(φ) Rz(θ) = Rz(φ + θ)
(4.96)
since by performing two successive rotations about the same axis the rotation angles
areadditive.DifferentmatricesRz(θ)areobtainedonlyfor0 ≤θ < 2π.Forexample,
Rz( 3π
2 )Rz( 3π
2 ) = Rz(3π) = Rz(π) (see Fig.4.13). Let us now consider two different
representations of the group Gz: the ﬁrst is simply the set of matrices
D(θ) =


cos θ −sin θ
sin θ
cos θ


(4.97)
and the second is obtained by associating with Rz(θ) the matrix:
F(θ) =


exp(−iθ/2)
0
0
exp(iθ/2)


(4.98)
Both set of matrices D and F satisfy the relations
D(θ)D(φ) = D(θ + φ),
D(θ)−1 = D(−θ),
D(0) = I
F(θ)F(φ) = F(θ + φ),
F(θ)−1 = F(−θ),
F(0) = I
(4.99)
For very small δθ, F(δθ) becomes

148
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
F(δθ) =


1 −iδθ/2
0
0
1 + iδθ/2


(4.100)
which coincides with U(Rz) ∈SU(2), as it should (see Eq.(4.90)). In the ﬁrst case
the mapping between Rz(θ) and D(θ) is one to one. We say that the representation D
is faithful (D is isomorphic with Rz). By contrast, in the second case (which is what
happens for the group SU(2)) to one matrix Rz(θ) there correspond two matrices,
±F(θ). For example, Rz(0) = Rz(2π) = I3, while:
F(0) =


1 0
0 1

 = I2,
F(2π) =


e−iπ 0
0
eiπ

 =


−1 0
0 −1

 = −I2
(4.101)
Let us now prove that the set Fz of matrices F(θ), with 0 ≤θ ≤4π is the
subgroup (a subset which is also a group) of SU(2) and it corresponds to the group
Gz of rotations about the z axis. For a simple proof, we ask the reader to use his
imagination, and try to answer the question: where are the points on the sphere (see
Eq.(4.77)) a2
1 + a2
2 + b2
1 + b2
2 = 1 which correspond to the set Fz? These points are,
in fact, characterized by the equations
b1 = b2 = 0 (since b = b1 + ib2 = 0)
(4.102)
a1 = cos θ
2,
a2 = −sin θ
2

since e−iθ/2 = cos θ
2 −i sin θ
2

(4.103)
Fig. 4.14 The reader is
asked to “imagine” the ﬁgure
in four dimensions! The
equations of the circle Γ are:
b1 = b2 = 0, a2
1 + a2
2 = 1.
The arrows indicate the
directions of increasing θ

4.4 Lie Groups: SO(3) and Vector Rotation, SU(2) and Spinor Rotation
149
When θ varies from 0 to 4π, the point (a1, a2, b1, b2) = (cos θ
2, sin θ
2, 0, 0) moves
along the circle Γ of equation a2
1 + a2
2 = 1 (and of course b1 = b2 = 0). An attempt
to draw the circle is shown in Fig.4.14. We also note that
F(0) = F(4π) =


1 0
0 1

 = I2
(4.104)
and the corresponding point on the circle Γ is N, the “north pole” of the sphere.
However
F(2π) =


e−iπ 0
0
eiπ

 =


−1 0
0 −1

 = −I2
(4.105)
and the corresponding point is S, the “south pole”, since a1 = −1, a2 = 0. Therefore
when θ varies from 0 to 2π, the rotation Rz(θ) runs over the whole subgroup Gz,
while in four dimensions the corresponding point describes only half of the circle Γ ,
from N to S. When θ varies from 2π to 4π, also the second semicircle is covered.
It is easy to prove that not only N and S, but any pair of endpoints of a diameter of
the circle Γ (antipodes) correspond to the same element Rz(θ) of Gz (see the points
A and B of Fig.4.15). Clearly,
F(θ + 2π) =


e−i(θ+2π)/2
0
0
ei(θ+2π)/2

 = F(θ)


−1 0
0 −1

 = −F(θ), (4.106)
while Rz(θ + 2π) = Rz(θ). This result is completely general: no matter which
direction we choose for the rotation axis, adding 2π to the rotation angle does not
change the matrix R but merely changes the sign of the matrix U(R). In formulas
R(θ + 2π) = R(θ),
U

R(θ + 2π)

= −U

R(θ)

.
(4.107)
Therefore, to two matrices ±U(R), there corresponds one rotation R.
The behavior under rotation is the characteristic feature distinguishing spinors
from vectors. A vector will return to its initial orientation after a rotation by 2π,
while a spinor will be transformed to its opposite orientation. We need a rotation of
4π to return a spinor to its initial state. There is an amusing analogy for a particle
moving on a Möbius band. After one circuit (2π) the particle will ﬁnd itself on the
opposite side of the band from where it started. Only after a second circuit (4π) does
the particle return to its starting point.
To “visualize” the whole rotation group SO(3) is much more difﬁcult than visu-
alizing the four-dimensional sphere that represents SU(2). To explain, consider a
solid sphere S of radius π in our physical space R3. A point P(x, y, z) belongs
to S if x2 + y2 + z2 ≤π2, where the origin O is at (0, 0, 0). To each vector
−→
OP, we associate an element of SO(3) with rotation angle θ equal to the distance
±|−→
OP| = ±

x2 + y2 + z2, and rotation axis along −→
OP. Hence if −→
OP = (x, y, z)
corresponds to a rotation of angle θ ≤π, −−→
OP = (−x, −y, −z) corresponds to a

150
4
New Adventures: Isotropic Vectors, Rotations, Spinors, and Groups
Fig. 4.15 The point A
corresponds to a rotation of
π around the axis OA, while
the point B corresponds to a
rotation of −π around
OB = −OA. Thus the two
rotations coincide
rotation of angle −θ. Since rotations of angle +π and −π are identical, we identify
the endpoints A, B of a diameter of length 2π (see Fig.4.15). A and B are called
antipodal points. With this convention, points of the solid ball S are in one-to-one
correspondence with the elements of the rotation group SO(3). However S is con-
nected but not simply connected; this means that there are closed loops that cannot
be shrunk to a point (similar to what can happen for circles on a torus). For instance,
consider the path going from points A, B of Fig.4.15, which is a closed path since
A ≡B. If one makes the same identiﬁcation for all the diameters of S one obtains a
bizarre set, with an inﬁnite number of such loops. Of course each loop corresponds
to a subgroup of rotations of a given axis and angles −π ≤θ ≤+π.
To summarize, an n-dimensional Lie group G “lives” on a differentiable manifold,
a continuous and smooth surface in some topological space. The elements g of G
depend upon n parameters x1, x2, . . . , xn. If g1 ∈G, g2 ∈G, the parameters of
the product g1g2 must be smooth functions of the parameters of g1, g2; the same
must hold for the inverse. Usually one adopts the convention that (0, 0, . . . , 0) are
the parameters of the identity I. Near the identity a point g of the manifold can be
expressed in the form, analogous to (4.89)
g = I + x1T1 + x2T2 + · · · + xnTn
(4.108)
where the T1, T2, . . . , Tn are the inﬁnitesimal generators of the group, as we have
seen in the cases of SO(3) and SU(2). These “vectors” span the “plane” tangent to the
manifold at the point I. They can be multiplied, and the commutators TiTj−TjTi must
remain in this “plane,” so that they can be written as a linear combination of the Ti7:
7The Ti are said to belong to a Lie algebra.

4.4 Lie Groups: SO(3) and Vector Rotation, SU(2) and Spinor Rotation
151

Ti, Tj

=
n

k
cijk Tk.
(4.109)
The angular momentum components provide a simple example of such commutation
relations. The structure constants cijk determine the local structure of the group, but
the global behavior of a Lie group G is not determined by its local structure. G can
even be a multiply-connected set, such that, given two points g1 ∈G, g2 ∈G, there
is no continuous path8 connecting g1 and g2. One such case is the Lorentz group,
which contains four connected components.
We note that there are other Lie groups of importance in theoretical physics.
For example, the group SU(3), complex matrices which leave invariant the Her-
mitian scalar product in three dimensions and do not change the sign of volumes,
is the basis of quantum chromodynamics. This underlies the theory of strong inter-
actions, part of the standard model of elementary particles. Another example is the
Lie group SO(3,1), the Lorentz group, which governs the behavior of relativistic
transformations.
8A path or curve g = g(τ), 0 ≤τ ≤1 on a Lie group is a mapping from the set 0 ≤τ ≤1 and the
subset {g(τ)} of G. The path is continuous if the parameters of g(τ) are continuous functions of τ.

Chapter 5
Quantum Entanglement and Bell’s Theorem
Abstract Adescriptionofquantumentanglementanditsapplications.Bell’sinequal-
ities and Bell’s theorem are described, along with their implications for local reality
and hidden variables. Other topics: applications using electron spin and photon polar-
ization, Aspect’s experiments, decoherence of quantum states.
Keywords Entanglement · EPR experiment · Bell’s theorem · Local reality ·
Aspect’s experiments · Decoherence
5.1
Product States in Hilbert Space
Let us consider a composite system of two electrons, a and b. The state of electron
a is represented by the vector |A⟩belonging to the Hilbert space HA, and the state
of electron b is represented by the vector |B⟩in the Hilbert space HB. How can
we construct the Hilbert space H of the “global states” representing both electrons?
For simplicity we neglect the positions of the two electrons, and consider only their
spins. Then |A⟩and |B⟩can be represented by the two-component complex vectors:
|A⟩=


a1
a2

 ∈C2,
|B⟩=


b1
b2

 ∈C2,
HA = HB = C2.
(5.1)
A description of the composite system involves the set of all possible pairs of the
two states |A⟩, |B⟩. Such a global state can be represented by a tensor product (or
simply product) of |A⟩, |B⟩, denoted by |A⟩⊗|B⟩. Given two product states:
|Ψ1⟩= |A1⟩⊗|B1⟩,
|Ψ2⟩= |A2⟩⊗|B2⟩,
(5.2)
we can deﬁne the scalar product ⟨Ψ2|Ψ1⟩by
⟨Ψ2|Ψ1⟩= ⟨A2|A1⟩⟨B2|B1⟩.
(5.3)
© Springer International Publishing AG 2017
G. Fano and S.M. Blinder, Twenty-First Century Quantum Mechanics:
Hilbert Space to Quantum Computers, UNITEXT for Physics,
DOI 10.1007/978-3-319-58732-5_5
153

154
5
Quantum Entanglement and Bell’s Theorem
Since HA and HB are two copies of C2, we can use the same basis vectors in both
spaces. Let us denote by |A ↑⟩=


1
0

, |A ↓⟩=


0
1

 the basis vectors in HA, and
analogously by |B ↑⟩=


1
0

, |B ↓⟩=


0
1

 the basis vectors in HB. It is easy to
verify that the following product states
| ↑↑⟩= |A ↑⟩⊗|B ↑⟩,
| ↑↓⟩= |A ↑⟩⊗|B ↓⟩,
| ↓↑⟩= |A ↓⟩⊗|B ↑⟩,
| ↓↓⟩= |A ↓⟩⊗|B ↓⟩,
(5.4)
are orthonormal. Indeed using the deﬁnition (5.3), we have
⟨↑↑| ↑↑⟩= ⟨A ↑|A ↑⟩⟨B ↑|B ↑⟩= |A ↑|2 |B ↑|2 = 1 × 1 = 1,
⟨↑↑| ↑↓⟩= ⟨A ↑|A ↑⟩⟨B ↑|B ↓⟩= 1 × 0 = 0,
⟨↑↑| ↓↑⟩= ⟨A ↑|A ↓⟩⟨B ↑|B ↑⟩= 0 × 1 = 0, etc.
(5.5)
The Hilbert space H of the composite system is also called the tensor product of HA
and HB, denoted by HA ⊗HB. An element |Ψ ⟩∈H is a linear combination with
complex (although possibly real) coefﬁcients of the basis vectors (5.4):
|Ψ ⟩= c11| ↑↑⟩+ c12| ↑↓⟩+ c21| ↓↑⟩+ c22| ↓↓⟩.
(5.6)
We presume that the coefﬁcients ci j fulﬁll the normalization condition:
2

i, j=1
|ci, j|2 = |c11|2 + |c12|2 + |c21|2 + |c22|2 = 1.
(5.7)
We designate by |Ψ ⟩the state of the composite system. The dimension of H is 4.
If we had chosen spaces HA, HB of dimension n, m, respectively, the dimension of
HA ⊗HB would have been n × m. As an example, suppose HA = C2 and HB = C3;
a basis in the product space consists of the following set of 6 vectors:
|v11⟩=


1
0

 ⊗


1
0
0


,
|v12⟩=


1
0

 ⊗


0
1
0


,
|v13⟩=


1
0

 ⊗


0
0
1


,
|v21⟩=


0
1

 ⊗


1
0
0


,
|v22⟩=


0
1

 ⊗


0
1
0


,
|v23⟩=


0
1

 ⊗


0
0
1


.
(5.8)
To return to the case of the spins A, B of two electrons, we assume that the two
spins are in a superposition state, such as

5.1 Product States in Hilbert Space
155
|A⟩= a1|A ↑⟩+ a2|A ↓⟩,
|B⟩= b1|B ↑⟩+ b2|B ↓⟩.
(5.9)
By the distributive property, the product state |A⟩⊗|B⟩becomes
|A⟩⊗|B⟩=

a1|A ↑⟩+ a2|A ↓⟩

⊗

b1|B ↑⟩+ b2|B ↓⟩

=
a1b1|A ↑⟩⊗|B ↑⟩+ a1b2|A ↑⟩⊗|B ↓⟩+ a2b1|A ↓⟩⊗|B ↑⟩+ a2b2|A ↓⟩⊗|B ↓⟩.
(5.10)
Comparing (5.6), (5.9), we have
c11 = a1b1,
c12 = a1b2,
c21 = a2b1,
c22 = a2b2.
(5.11)
The question then arises: are all vectors Ψ ∈H of the form |A⟩⊗|B⟩? The answer is
no. Before giving a formal proof, we note that the simplest intuitive picture of |A⟩⊗
|B⟩is that of two independent particles, since |A⟩∈HA, |B⟩∈HB. However, there
exists other states |Ψ ⟩∈H, representing particle pairs which are not independent.
To see this, note that (5.11) implies that
c11c22 = c12c21,
(5.12)
which is therefore a necessary condition1 for the vector |Ψ ⟩to be a product state.
States that do not fulﬁll the condition (5.12) include the following (see Eq.5.4):
|Ψ0,0⟩=
1
√
2

| ↑↓⟩−| ↓↑⟩

,
|Ψ1,0⟩=
1
√
2

| ↑↑⟩+ | ↓↓⟩

,
(5.13)
where
1
√
2 is a normalization factor. For the state |Ψ0,0⟩: c11c22 = 0, c12c21 = −1
2,
while for the state |Ψ1,0⟩, c11c22 = 1
2, c12c21 = 0.
Nonfactorizing states, states that cannot be written in a product form, are said to be
entangled (a term introduced by Schrödinger: Verschränkung). For example, |Ψ0,0⟩
and |Ψ1,0⟩in Eq. (5.4) are entangled, in fact maximally entangled. These are called
Bell states, for reasons which will become apparent later. Entanglement is a central
concept in our understanding of quantum mechanics and is also the fundamental
principle underlying quantum computing.
A metaphoric representation of quantum entanglement might be Indra’s net, as
shown in Fig.5.1. In Buddhist and Hindu tradition, Indra’s net is an inﬁnite array of
strands of jewels. The surface of each jewel reﬂects the inﬁnity of all the other jewels,
to symbolize a cosmos in which every part is mutually interconnected to every other
part.
1The condition c11c22 = c12c21 is also sufﬁcient for the vector |Ψ ⟩to be a product state, assuming
that c11 + c22 ̸= 0. The product state

|A ↑⟩+ c21
c11
|A ↓⟩

⊗

c11|B ↑⟩+c12|B ↓⟩

= c11| ↑↑⟩+ c12| ↑↓⟩+ c21| ↓↑⟩+ c21c12
c11
| ↓↓⟩
coincides with the state (5.6).

156
5
Quantum Entanglement and Bell’s Theorem
Fig. 5.1 Indra’s net. (https://www.scienceandnonduality.com/the-indras-net/)
A product of Hilbert spaces can be extended to three or more component spaces:
given three Hilbert spaces HA, HB, HC, we deﬁne
HA ⊗HB ⊗HC = (HA ⊗HB) ⊗HC = HA ⊗(HB ⊗HC).
(5.14)
For example, for a composite system of three electron spins, since each spin state is
an element in a copy of C2, an orthonormal basis in HA ⊗HB ⊗HC is provided by
|A ↑⟩⊗|B ↑⟩⊗|C ↑⟩, |A ↑⟩⊗|B ↑⟩⊗|C ↓⟩, etc. With an obvious extension of
the notation (5.4), a basis is given by
| ↑↑↑⟩, | ↑↑↓⟩, | ↑↓↑⟩, | ↑↓↓⟩, | ↓↑↑⟩, | ↓↑↓⟩, | ↓↓↑⟩, | ↓↓↓⟩.
(5.15)
If OA denotes a linear Hermitian operator acting on HA, and OB an operator acting
on HB, we deﬁne an operator OA⊗OB, called a tensor product, acting on the product
states according to the following rule:
(OA ⊗OB)(|A⟩⊗|B⟩) = OA|A⟩⊗OB|B⟩.
(5.16)
One can imagine that OA ⊗OB acts separately on the spaces HA, HB, and the
results are combined to produce a product state. Given two basis {|Ai⟩∈HA, i =
1, 2, . . . , m}, {|B j⟩∈HB, j = 1, 2, . . . , n)}, the action of OA ⊗OB on a general
linear combination |Ψ ⟩= 
i j ci j |Ai⟩⊗|B j⟩is given by
(OA ⊗OB) |Ψ ⟩=

i j
ci j OA |Ai⟩⊗OB |B j⟩.
(5.17)

5.1 Product States in Hilbert Space
157
The product of two tensor products, OA1 ⊗OB1, OA2 ⊗OB2, is given by
(OA1 ⊗OB1)(OA2 ⊗OB2) = (OA1 OA2) ⊗(OB1 OB2).
(5.18)
The next step is to ﬁnd the matrix representing (OA ⊗OB): given a 2 × 2 matrix M
operating on the C2 space:
M =


M11 M12
M21 M22

 ,
(5.19)
we denote by |e1⟩=


1
0

,
|e2⟩=


0
1

, the standard orthonormal basis vectors;
then
M|e1⟩=


M11
M21

 ,
M|e2⟩=


M12
M22

 .
(5.20)
Therefore,
M11 = ⟨e1|M|e1⟩, M21 = ⟨e2|M|e1⟩, M12 = ⟨e1|M|e2⟩, M22 = ⟨e2|M|e2⟩,
(5.21)
which can be written as
Mi j = ⟨ei|M|e j⟩,
i, j = 1, 2.
(5.22)
Equation(5.22) can be generalized to arbitrary dimension n, such that |e1⟩=
(1, 0, 0, ...0), |e2⟩= (0, 1, 0, ...0), . . . , with i, j = 1, 2, . . . , n.
Suppose now that OA is represented by a 2 ⊗2 matrix ai j = ⟨Ai|OA|A j⟩, i, j =
1, 2, where |A1⟩=


1
0

, |A2⟩=


0
1

 denote, for example, spin-up and spin-
down states. Analogously, the operator OB is represented by a 2 ⊗2 matrix bi j =
⟨Bi|OB|B j⟩, i, j = 1, 2. Let us compute the matrix elements of OA ⊗OB in the
orthonormal basis |Ai⟩⊗|B j⟩. By (5.16) we can write
(OA ⊗OB)(|Ai⟩⊗|B j⟩) = OA|Ai⟩⊗OB|B j⟩,
i, j = 1, 2.
(5.23)
Let us now take the scalar product of this vector with |Am⟩⊗|Bn⟩, m, n = 1, 2.
Using (5.1), (5.2) we ﬁnd the 4 × 4 matrix that represents OA ⊗OB:
Cmn,i j = ⟨Am|OA|Ai⟩⟨Bn|OB|B j⟩= amibnj
for
m, n, i, j = 1, 2.
(5.24)
The matrix C is also called the tensor product or Kronecker product of OA, OB.
Ordering the basis |Ai⟩⊗|B j⟩as follows:
|A1⟩⊗|B1⟩,
|A1⟩⊗|B2⟩,
|A2⟩⊗|B1⟩,
|A2⟩⊗|B2⟩,
(5.25)
the matrix C is given by

158
5
Quantum Entanglement and Bell’s Theorem

a11

b11 b12
b21 b22
 a12

b11 b12
b21 b22

a21

b11 b12
b21 b22
 a22

b11 b12
b21 b22


=

a11b11 a11b12 a12b11 a12b12
a11b21 a11b22 a12b21 a12b22
a21b11 a21b12 a22b11 a22b12
a21b21 a21b22 a22b21 a22b22

.
(5.26)
An operator OA acting on a state |A⟩⊗|B⟩of a composite system can be denoted
OA ⊗I, with the operator OB written as I ⊗OB. Physicists prefer often to skip the
direct product notation, since it is generally obvious on which part of the composite
system an operator is acting.
We next consider the very fundamental example of an entangled state of two
electrons a, b:
|Ψ0,0⟩=
1
√
2

| ↑↓⟩−| ↓↑⟩

.
(5.27)
The following operator represents the sum of the z-components of the spins of the
two electrons:
Σz = σzA ⊗I + I ⊗σzB =

1 0
0 −1
 ⊗I + I ⊗

1 0
0 −1
 .
(5.28)
We have
σzA

1
0

A
=

1
0

A
,
σzA

0
1

A
= −

0
1

A
,
σzB

1
0

B
=

1
0

B
,
σzB

0
1

B
= −

0
1

B
.
(5.29)
Therefore, recalling that | ↑↓⟩=

1
0

A
⊗

0
1

B
, | ↓↑⟩=

0
1

A
⊗

1
0

B
, we ﬁnd
Σz|Ψ00⟩=
1
√
2

| ↑↓⟩−| ↑↓⟩+ | ↓↑⟩−| ↓↑⟩

= 0.
(5.30)
This is quite reasonable, since the z spin components of | ↑↓⟩and | ↓↑⟩sum to zero.
We ﬁnd a similar result after changing the direction of the spin projection from z
to r = (x, y, z). Deﬁne the following observable (see Eq.4.18):
Σr =

z
x −iy
x + iy
−z

A
⊗IB + IA ⊗

z
x −iy
x + iy
−z

B
,
(5.31)
representing the projection of the total spin in the r direction. We have

5.1 Product States in Hilbert Space
159
Σr| ↑↓⟩=

z
x −iy
x + iy
−z
A

1
0
A
⊗

0
1
B
+

1
0
A
⊗

z
x −iy
x + iy
−z
B

0
1
B
=

z
x + iy
A
⊗

0
1
B
+

1
0
A
⊗

x −iy
−z
B
=
(z)| ↑↓⟩+ (x + iy)| ↓↓⟩+ (x −iy)| ↑↑⟩+ (−z)| ↑↓⟩.
(5.32)
Analogously,
Σr | ↓↑⟩=

z
x −iy
x + i
−z

A

0
1

A
⊗

1
0

B
+

0
1

A
⊗

z
x −iy
x + iy
−z

B

1
0

B
=

x −iy
−z

A
⊗

1
0

B
+

0
1

A
⊗

z
x + iy

B
=
(x −iy)| ↑↑⟩+ (−z)| ↓↑⟩+ (z)| ↓↑⟩+ (x + iy)| ↓↓⟩.
(5.33)
Therefore, Σr|Ψ00⟩=
1
√
2Σr (| ↑↓⟩−| ↓↑⟩) = 0; thus |Ψ00⟩is an eigenstate of
Σr corresponding to the eigenvalue 0 for all values of x, y, z. Physically, this means
that if we measure the total spin for the two-electron state |Ψ00⟩, we obtain the value
0, independent of the direction of r. The state |Ψ00⟩is called the singlet state. The
second entangled state of (5.13), |Ψ1,0⟩=
1
√
2(| ↑↓⟩+ | ↓↑⟩) is called the triplet
state. It is a composite of the three states labeled by two indexes S, M with S = 1
and M = 1, 0, −1:
|Ψ1,1⟩= | ↑↑⟩,
|Ψ1,0⟩=
1
√
2

| ↑↓⟩+ | ↑↓⟩

,
|Ψ1,−1⟩= | ↓↓⟩.
(5.34)
In general, for n particles with spin 1
2, S denotes the maximum total spin of the
system. The maximum is reached when all spins are aligned, with S = 2n. In the case
of two electrons, S = 1
2 + 1
2 = 1. The index M is a quantum number denoting the
projection of the total spin on the z-axis. From a semiclassical point of view, we can
imagine that the two aligned spins have only three possible orientations with respect
to the z-axis (see Fig.5.2). The analogous picture for the singlet state is shown in
Fig.5.3. It is easy to verify that |Ψ1,M⟩is eigenvector of the operator Σz (see 5.28)
corresponding to the eigenvalue M:
Σz|Ψ1,M⟩= (σzA ⊗I + I ⊗σzB)|Ψ1,M⟩= M|Ψ1,M⟩for
M = 1, 0, −1. (5.35)
When S isaninteger,thepossiblevaluesof M are S, S−1, . . . , 0, −1, . . . , −S;2S+1
values in all. For example, for the case of 4 aligned electron spins, S = 4 × 1
2 = 2
and the 5 eigenvalues of the operator Σz are M = 2, 1, 0, −1, −2. In (Fig.5.4)
the possible orientations of the aligned spins with respect to the z-axis are shown.
A similar picture can be imagined for the possible z-components of the angular
momentum of one electron in a D state, with a total angular momentum L = 2.
We have considered here the speciﬁc case of particles with spin- 1
2, since this is the
simplest mathematically, yet the most relevant for the following discussion of the
foundations of quantum mechanics.

160
5
Quantum Entanglement and Bell’s Theorem
Fig. 5.2 Semiclassical
picture of the three possible
orientations, with respect to
the z-axis, of two aligned
spins, S = 1
Fig. 5.3 Semiclassical
picture of a singlet state of
two spins, S = 1
2
5.2
Bohm’s Version of the Einstein–Podolsky–Rosen
Experiment
A more practical version of the EPR experiment was suggested by Bohm (1951),
basedoncorrelationsbetweenelectronspinstates,ratherthanpositionsandmomenta.
It is useful then to consider the entangled singlet state |Ψ00⟩of two electrons, a and
b, adding a more complete description of the system by taking account, as well, of
the spatial part of the wavefunction Ξ(rA, rB). We have in mind a situation in which
the two electrons are initially at a single point, say r = 0, and then move apart in the
direction of two detectors. Here, RA, RB designate two points in the physical space
R3. The wave function Ξ gives the probability amplitude of ﬁnding the electron a
near the point RA and the electron b near the point RB. For two small volumes ΔVA
and ΔVB around the points RA, RB, |Ξ(rA, rB)|2 ΔVA ΔVB gives the probability of
ﬁnding electron a inside ΔVA and electron b inside ΔVB. We assume that the distance

5.2 Bohm’s Version of the Einstein–Podolsky–Rosen Experiment
161
|RA −RB| is macroscopic (recall that one meter is about 2 × 1010 atomic units). We
can combine the spatial description provided by the wave function Ξ(rA, rB) with
the spin state description by a simple product of the space and spin wavefunctions.
Technically, the Hilbert space of the system is now the tensor product of the Hilbert
space of spatial wave functions times the Hilbert space of the spin states. Assuming
that the spin state is a singlet, the total wave function of the system is then given by
Ξ(rA, rB) × 1
√
2

|A ↑⟩⊗|B ↓⟩−|A ↓⟩⊗|B ↑⟩

,
(5.36)
where |A ↑⟩=


1
0


A
, |B ↓⟩=


0
1


B
, etc. Suppose tentatively that the space part
of the two-electron wavefunction Ξ(rA, rB) can be factorized onto the product of
separate one-electron functions f (rA) g(rB), in such a way that electron a is located
near RA, while electron b is near RB, as shown in Fig.5.4. This, however, violates
one of the fundamental tenets of QM, that electrons are indistinguishable particles.
Electrons a and b must each be equally associated with rA and rB. This can be
realized by writing the spatial wavefunction as the sum:
Ξ(rA, rB) =
1
√
2

f (rA)g(rB) + g(rA) f (rb)
	
.
(5.37)
The complete wavefunction for the singlet state, including both space and spin con-
tributions, is then, as sketched in Fig. 5.5,
Fig. 5.4 Semiclassical
picture of four aligned spins,
S = 2

162
5
Quantum Entanglement and Bell’s Theorem
Fig. 5.5 The function Ξ(rA, rB) is of signiﬁcant magnitude only when rA ≈RA and rB ≈RB
|Ψ ⟩=
1
√
2

f (rA)g(rB) + g(rA) f (rB)

× 1
√
2

|A ↑⟩⊗|B ↓⟩−|A ↓⟩⊗|B ↑⟩

.
(5.38)
Note that the total wavefunction is antisymmetric (i.e., it changes sign) with exchange
of electron labels A and B. This is true for all fermions (in particular, particles of
spin 1
2), and leads to the Pauli exclusion principle for many-electron systems.
For a triplet spin state, the three possible wavefunctions are instead
|Ψ ⟩=
1
√
2

f (rA)g(rB) −g(rA) f (rB)

×
⎧
⎪⎪⎨
⎪⎪⎩
|A ↑⟩⊗|B ↑⟩
1
√
2
A ↑⟩⊗|B ↓⟩+ |A ↓⟩⊗|B ↑⟩
|A ↓⟩⊗|B ↓⟩
(5.39)
Here, the antisymmetry (minus sign) is contained in the space factor.
In both the original EPR and Bohm’s version of the Gedankenexperiment, the two
particles enter two detectors, say at rA = D and rB = −D. Thus the spatial part of
the wavefunction Ξ(D, −D) reduces to a constant factor and can be neglected. From
now on, the wavefunction |Ψ ⟩will refer just to the spin part.
Suppose now that we measure the spin component of one of the electrons along
the z-axis. Since the wave function |Ψ ⟩contains only the terms |A ↑⟩⊗|B ↓⟩and
|A ↓⟩⊗|B ↑⟩, if the measurement of the A spin shows “up,” we can infer that the
two-particle spin state has collapsed to the state |A ↑⟩⊗|B ↓⟩. If the A spin shows
“down,” the collapsed spin state must be |A ↓⟩⊗|B ↑⟩. Thus a measurement of
the spin state of one particle gives us precise information on the spin state of the
other particle: B is “down” if A is “up” and “up” if A is “down.” There is a perfect
correlation between the measurements of the spin A and the measurement of the
spin B. However, as J. S. Bell pointed out, this is not a simple correlation like those
we encounter in everyday life. For example, if you ﬁnd that you have with you only
one glove, say the left one, you immediately know that you have forgotten the right
glove at home. But in the case of the electrons, before the measurement, the spin

5.2 Bohm’s Version of the Einstein–Podolsky–Rosen Experiment
163
state is a superposition of (|A ↑⟩⊗|B ↓⟩and |A ↓⟩⊗|B ↑⟩(see Eq.5.38), and
only after the measurement is there the instantaneous collapse into |A ↑⟩⊗|B ↓⟩or
|A ↓⟩⊗|B ↑⟩. Since the two electrons are macroscopically separated, it seems as
some “spooky action at a distance” has occurred. The “message” of the A particle to
the B particle, something like “my spin is down, your spin must be up” is evidently
propagated faster than the speed of light, in contradiction to the central tenet of the
theory of relativity.
Remarkably the situation is even more paradoxical. Actually the singlet state Ψ00
is rotationally invariant, and nothing prevents us from measuring the spin projections
in an arbitrary direction, say (x, y, z). From Eqs. (4.18), (4.19), (4.21), we recall that
the up and down spinors corresponding to the (x, y, z) direction are given by
|Ψ1⟩=


ψ
φ

 = α


1 + z
x + iy

 ,
|Ψ2⟩=


φ∗
−ψ∗

 = α∗


x −iy
−(1 + z)

 .
(5.40)
Let us compute the singlet state corresponding to the new direction. Since the system
is rotationally invariant we do not expect anything different. We have
|Ψ1A⟩⊗|Ψ2B⟩−|Ψ2A⟩⊗|Ψ1B⟩=
|α|2


1 + z
x + iy


A
⊗


x −iy
−(1 + z)


B
−|α|2


x −iy
−(1 + z)


A
⊗


1 + z
x + iy


B
.
(5.41)
Since C2 ⊗C2 = C4, (5.41) becomes the four-component vector:
|α|2


(1 + z)(x −iy) −(x −iy)(1 + z)
−(1 + z)2 −(x2 + y2)
x2 + y2 + (1 + z)2
−(x + iy)(1 + z) + (1 + z)(x + iy)


= |α|2(x2 + y2 + z2 + 2z + 1)


0
−1
1
0


.
(5.42)
Since the state vectors |Ψ1⟩and |Ψ2⟩are normalized, |α|2(x2 + y2 +z2+2z+1) = 1,
and we obtain


1
0


A
⊗


0
1


B
−


0
1


A
⊗


1
0


B
= |A ↑⟩⊗|B ↓⟩−|A ↓⟩⊗|B ↑⟩= |Ψ00⟩, (5.43)
which is the same as the singlet state with respect to the z-axis. Evidently, the sin-
glet state does not depend on the choice of axis (x, y, z). However, measuring spin
components of the particles A and B in two different directions, say (0, 0, z) and
(x, 0, 0), there is no longer a simple correlation of the results. This is so since the
operators
σz =


1 0
0 −1

 ,
σx =


0 1
1 0

 ,
(5.44)

164
5
Quantum Entanglement and Bell’s Theorem
representing the spin projections in the z- and x-directions, do not commute. Indeed
the eigenstates


1
0

,


0
1

 of σz do not coincide with those of σx, which are, in
fact,
1
√
2


1
1

,
1
√
2


1
−1

. In conclusion, excluding the possibility of superluminal,
instantaneous communications, we remain unable to answer the question: How does
particle B “know” which component of the spin of A we measured?
5.3
Hidden Variables and Bell’s Inequality
Before proceeding, let us say a few words about the historical development and
philosophical implications of concepts such as the wave–particle duality, entangled
states, etc. Einstein believed that distant objects cannot instantaneously inﬂuence
one another; rather, every object is acted upon only by its contiguous surroundings.
This principle is called locality. In his words: “The following idea characterizes the
relative independence of objects far apart in space, A and B: external inﬂuence on A
has no direct inﬂuence on B.” This is known as the principle of local action, which
forms the basis of classical and quantum ﬁeld theories; for example, electromagnetic
waves do not propagate instantaneously, but only at a velocity less than or equal to
the vacuum speed of light c. Were it not for localization, formulation of empirical
laws for ﬁnite systems would not be possible.
We recall from Sect.3.7 that Einstein’s epistemological orientation can be clas-
siﬁed as realistic: he considered that physical entities, including possibly the wave-
function, possessed inherent properties regardless of whether they are being observed
or not. Pais (1982) relates “I recall that during one walk Einstein suddenly stopped,
turned to me and asked whether I really believed that the Moon exists only when I
look at it.” In their famous paper, Einstein, Podolsky and Rosen (EPR) (Einstein et al.
1935) wrote “If, without in any way disturbing a system, we can predict with certainty
the value of a physical quantity, then there exists an element of physical reality corre-
sponding to this physical quantity.” Therefore, for the case of the entangled states just
considered, it appears that Einstein’s belief was that, prior to the measurement of the
spin of particle B, the spin was already aligned in the observed direction. The combi-
nation of the locality principle and realism is called local realism. However, without
entering too deeply into a discussion of epistemology or ontology, one might ask
“What about believing in the existence of systems, spins before their measurement,
or moons, or even entire universes, no one will ever see?”
We saw in Sect.3.6 that the “collapse of the wavefunction” gives rise to a multi-
tude of problems. Does the collapse happen when a detector records a result? Or, it is
perhaps just something in the observer’s mind when he becomes aware of the result
of a measurement? Since animals have sense organs as we do, would the observa-
tion of a cat, or a bacterium, be sufﬁcient to produce the collapse? And why does
the wavefunction follows two different types of temporal evolution, one linear and
continuous, governed by the time-dependent Schrödinger equation, and the other

5.3 Hidden Variables and Bell’s Inequality
165
Table 5.1 Hypothetical particles with instruction sets
Instruction set
Result of the measurement
of σz
Result of the measurement
of σx
(z+, x+)
+1
+1
(z+, x−)
+1
−1
(z−, x+)
−1
+1
(z−, x−)
−1
−1
nonlinear and discontinuous? In order to ﬁnd a solution to these problems, Einstein
and others thought that there had to be some unknown hidden variables, not yet acces-
sible to experiment; these variables were supposed to predetermine, in some way,
the results of our measurements. We have seen in Chap.1 that classical statistical
mechanics, taking the average of the motion of a multitude of molecules, explains
the behavior of thermodynamic quantities, such as pressure or temperature; in an
analogous way a hypothetical new theory of hidden variables should explain both
the corpuscular and wave-like behavior of particles, and the paradoxical properties
of entangled states.
Let us see how the existence of hidden variables could avoid faster-than-light
propagation of signals between two spin- 1
2 particles A, B considered above, making
it possible, for example, for the particle B to have a spin aligned parallel, opposite
to the measured direction of the spin of A. (Alternatively, for photons, the two
possible states represent vertical and horizontal polarization.) Imagine that each
particle carries a hidden “set of instructions” which determines the outcome of any
measurement. For example, considering only the observables σz, σx, we have four
types of “instruction sets,” producing four variants of the particles (Table5.1).
In this way, there is no need for superluminal actions at a distance, and the realistic
picture of the world would be saved. In an analogous way, the assumption of hidden
variables could, in principle, provide an resolution of the wave–particle duality. All
right then; can we expect that sooner or later the hidden variables will be discovered?
After all, our understanding of molecular motion came many years after the interrela-
tionships among thermodynamic quantities were known. However, this expectation
fails. An ingenious inequality proposed by Bell (1964) enabled experimental tests
to verify whether or not a local deterministic interpretation of quantum mechanics
is possible. There are several variants of Bell’s inequality. We will present here a
version due to Wigner,2 which is perhaps the simplest.
Consider three unit vectors a, b, c in three-dimensional space, and the possible
results of measurement of the spin projections σ · a, σ · b, σ · c, where σ · a =
σxxa + σy ya + σzza, etc., together with the corresponding “instruction sets.” In
Table5.2, we show a population of NA pairs of particles, all pairs coupled in a singlet
state, and partitioned into eight groups of N1, N2, N3, . . . , N8 pairs (capital letters
A, B denote the two particles of a pair, lower case letters a, b, c denote unit vectors
2EP Wigner (1970), Am J Phys 38:1005–1009.

166
5
Quantum Entanglement and Bell’s Theorem
Table 5.2 Results of spin measurements
Population
Instr. set of
particle A
Instr. set of
particle B
σ A · a
σ A.b
σ A · c
σ B · a
σ B.b
σ B · c
N1
(a+, b+, c+)
(a−, b−, c−)
+1
+1
+1
−1
−1
−1
N2
(a+, b+, c−)
(a−, b−, c+)
+1
+1
−1
−1
−1
+1
N3
(a+, b−, c+)
(a−, b+, c−)
+1
−1
+1
−1
+1
−1
N4
(a+, b−, c−)
(a−, b+, c+)
+1
−1
−1
−1
+1
+1
N5
(a−, b+, c+)
(a+, b−, c−)
−1
+1
+1
+1
−1
−1
N6
(a−, b+, c−)
(a+, b−, c+)
−1
+1
−1
+1
−1
+1
N7
(a−, b−, c+)
(a+, b+, c−)
−1
−1
+1
+1
+1
−1
N8
(a−, b−, c−)
(a+, b+, c+)
−1
−1
−1
+1
+1
+1
in physical space). Of course, in all cases σ A · a = - σ B · a, σ A · b = - σ B · b, etc. Let
us now suppose that
σ A · a = σ B · b = +1.
(5.45)
Reading from Table5.2, we see that only the groups of N3 and N4 pairs fulﬁll this
condition. Choosing a pair at random, the probability that (5.45) is veriﬁed is given
by
P(a+, b+) = N3 + N4
N
.
(5.46)
The probability that σ A · b = σ B · c = +1 is given by
P(b+, c+) = N2 + N6
N
,
(5.47)
and the probability that σ A · a = σ B · c = +1 is
P(a+, c+) = N2 + N4
N
.
(5.48)
From (5.46), (5.47), (5.48) it follows that
P(a+, b+) + P(b+, c+) −P(a+, c+) = N3 + N6
N
≥0.
(5.49)
Therefore, the following “triangle inequality” holds:
P(a+, b+) + P(b+, c+) ≥P(a+, c+).
(5.50)
Let us now compute the corresponding quantum mechanical results. Consider a
singlet state of two-electron spins A and B, denoted |Ψ0,0⟩. By virtue of its rotational

5.3 Hidden Variables and Bell’s Inequality
167
symmetry, this can be expressed in terms of quantization about any axis. Let us
consider the two directions a and b. The two alternative forms are given by
|Ψ0,0⟩=
1
√
2

|Aa ↑⟩|Ba ↓⟩−|Aa ↓⟩|Ba ↑⟩

=
1
√
2

|Ab ↑⟩|Bb ↓⟩−|Ab ↓⟩|Bb ↑⟩

.
(5.51)
Recalling Eqs. (4.52) and (4.53), the b basis functions can be expressed in terms of
the a basis using analogous relations. We require just the transformations for spin
B:
|Bb ↑⟩= cos θab
2 |Ba ↑⟩+ sin θab
2 |Bb ↓⟩,
|Bb ↓⟩= −sin θab
2 |Ba ↑⟩+ cos θab
2 |Bb ↓⟩,
(5.52)
where θab is the angle between the directions a and b. Now, substituting (5.52) into
(5.51), we obtain
|Ψ0,0⟩=
1
√
2

−sin θab
2 |Ab ↑⟩|Ba ↑⟩+ cos θab
2 |Ab ↑⟩|Bb ↓⟩
−cos θab
2 |Ab ↓⟩|Ba ↑⟩−sin θab
2 |Ab ↓⟩|Bb ↓⟩

.
(5.53)
The wave function can be interpreted as a superposition of four possible outcomes.
The amplitude for the joint event of particle A registering spin-up in direction a and
particle B registering spin-up in direction b is equal to −1
√
2 sin θab
2 . The probability
of this event, which we designate P QM(a+, b+), is then given by the square of the
amplitude 1
2 sin2 θab
2 . The four probabilities, which are listed in the last column of
Table5.2, can then be found:
P QM(a+, b+) = P QM(a−, b−) = 1
2 sin2 θab
2 ,
P QM(a+, b−) = P QM(a−, b+) = 1
2 cos2 θab
2 .
(5.54)
These four probabilities add up to 1, as they should. Analogous results will be found
for the combinations involving b and c, a and c.
Assuming that the three vectors a, b, c are in anticlockwise order around the z-
axis, we ﬁnd, for the angles, θac = θab + θbc. We have now found the quantum
analogs of the classical probabilities in Eq. (5.50), namely,
P QM(a+, b+) = 1
2 sin2 θab
2 ,
P QM(b+, c+) = 1
2 sin2 θbc
2 ,
P QM(a+, c+) = 1
2 sin2 θab + θbc
2
.
(5.55)

168
5
Quantum Entanglement and Bell’s Theorem
You can show that, for 0 ≤θ1, θ2 ≤π
2 ,
sin2 θ1 + θ2
2
≥sin2 θ1
2 + sin2 θ2
2 .
(5.56)
Therefore
P QM(a+, c+) ≥P QM(a+, b+) + P QM(b+, c+),
(5.57)
which is the exact reverse of Bell’s inequality (5.50). Although there are certain
combinations of angles for which the inequality (5.57) fails and Bell’s inequality
is satisﬁed, the fact that Bell’s inequality can be violated at all is very compelling
evidence that quantum mechanics is inconsistent with any physical theory based on
local realism. We arrive thereby at Bell’s theorem.
Theorem 5.1 Bell’s inequality (5.50) is violated by quantum mechanics.
We have thus proved that no discrete hidden variable of the type considered by
Wigner, no simple “instruction sets” for particles A and B, can account for the
quantum mechanical results. This means that quantum mechanics predicts greater
than expected correlations between events that are out of range by classical causality.
Let us illustrate with a particular example. Let θab = θbc = π/6, so that θac =
π/3, as shown in Fig.5.6. Then P QM(a+, b+) = P QM(b+, c+) ≈0.0335 and
P QM(a+, c+) = 0.125. Thus 0.125 > 0.0335 + 0.0335, and the inequality (5.57) is
veriﬁed.
Fig. 5.6 Three vectors a, b, c which violate Bell’s inequality

5.4 Generalized Bell’s Inequality
169
5.4
Generalized Bell’s Inequality
Wigner’s proof can easily be generalized, even when the set of “hidden variables” is
very large, including the case when its description requires one or more continuous
variables. Bell’s inequality still remains valid. For the proof we must continue to
conform to the locality principle: no “message” can be instantly transmitted from
one particle of the pair to the other. For simplicity, consider the case of a single
continuous hidden variable λ associated with the pair. The probability ρ(λ) of the
value λ for the hidden variable must satisfy the condition:

ρ(λ)dλ = 1,
(5.58)
since the total probability must equal 1. With the integral running over the set of all
possible values of λ, the average ⟨F⟩of a quantity F(λ) is given by
⟨F⟩=

F(λ)ρ(λ)dλ.
(5.59)
Denoting by m, M, the minimum and maximum values of F, we have
m = m

ρ(λ)dλ ≤

F(λ)ρ(λ)dλ ≤M

ρ(λ)dλ = M.
(5.60)
Of course, m ≤⟨F⟩≤M. The quantum mechanical analog of the average is the
expectation value ⟨Ψ |F|Ψ ⟩, where |Ψ ⟩represents the state of the system.
Let us now deﬁne a quantum mechanical correlation function. Given a state |Ψ ⟩
of a pair of particles A, B, with spin directions a, b, the quantum correlation function
is written E QM(a, b), as the expectation value of the product of the two commuting
operators σ A · a, σ B · b, given by
E QM(a, b) = ⟨Ψ |(σ A · a) (σ B · b)|Ψ ⟩.
(5.61)
Thecorrespondingclassicalcorrelationfunction,assumingthatthequantummechan-
ical results can be obtained by taking the average over the hidden variable λ:
E(a, b) =

α(a, λ) β(b, λ)ρ(λ)dλ,
(5.62)
where α(a, λ) = ±1, β(b, λ) = ±1 are the results of the measurements of the spin
projections of the a and b particles in the a, b directions, respectively. The analogous
quantum mechanical values α(a, λ), β(b, λ) are the eigenvalues of the operators
σ A · a, σ B · b.
Before proving the generalized Bell’s inequality, we make use of the result:
Lemma 5.1 Let |Ψ ⟩be a singlet state of two particles; then E QM(a, b) is given by

170
5
Quantum Entanglement and Bell’s Theorem
Table 5.3 Quantum mechanical results
Eigenvectors
Eigenvalues Q
Probabilities
| ↑↑⟩= |Aa ↑⟩⊗|Bb ↑⟩
(+1) (+1) = +1
P QM(a+, b+) =
|⟨↑↑|Ψ ⟩|2 = 1
2 sin2 θab
2
| ↑↓⟩= |Aa ↑⟩⊗|Bb ↓⟩
(+1) (−1) = −1
P QM(a+, b−) =
|⟨↑↓|Ψ ⟩|2 = 1
2 cos2 θab
2
| ↓↑⟩= |Aa ↓⟩⊗|Bb ↑⟩
(−1) (+1) = −1
P QM(a−, b+) =
|⟨↓↑|Ψ ⟩|2 = 1
2 cos2 θab
2
| ↓↓⟩= |Aa ↓⟩⊗|Bb ↓⟩
(−1) (−1) = +1
P QM(a−, b−) =
|⟨↓↓|Ψ ⟩|2 = 1
2 sin2 θab
2
E QM(a, b) = −a · b.
(5.63)
Proof To compute the expectation value of the operator Q = (σ A · a)(σ B · b) in
the singlet state |Ψ ⟩, we use the quantum mechanical formula to ﬁnd the expectation
value of an observable F; we multiply the eigenvalues of F by their probabili-
ties and sum the results. The eigenvalues of the operators σ A · a, σ B · b are ±1;
the eigenvectors and eigenvalues of the product Q = (σ A · a)(σ B · b) are shown
in Table5.3. In Eq.(5.54), we gave the probabilities as functions of the angle θab:
P QM(a+, b+) = 1
2 sin2 θab
2 and P QM(a+, b−) = 1
2 cos2 θab
2 . Multiplying the eigen-
values by the probabilities, we obtain ﬁnally
E QM(a, b) = P QM(a+, b+) −P QM(a+, b−)
−P QM(a−, b+) + P QM(a−, b−) = sin2 θ
2 −cos2 θ
2 = −cos θ,
(5.64)
where θ is the angle between a and b. Since a · b = |a||b| cos θ, and |a| = |b| = 1;
the lemma is proved.
We can now prove the generalization of Bell’s theorem.
Theorem 5.2 No local hidden variables theory can reproduce the quantum mechan-
ical values of the correlation function.
Proof Let
E(a, b) be the “classical” correlation function (see Eq.5.62), which
should reproduce E QM(a, b). Consider the hidden variable expression
S = E(a, b) + E(a, b′) + E(a′, b) −E(a′, b′) =

ρ(λ)

α(a)β(b) + α(a)β(b′) + α(a′)β(b) −α(a′)β(b′)

dλ,
(5.65)
where α(a) = α(a, λ), β(b) = β(b, λ). We have
S =

ρ(λ)

α(a) + α(a′)

β(b) +

α(a) −α(a′)

β(b′)

dλ.
(5.66)

5.4 Generalized Bell’s Inequality
171
Four cases are possible:
(1) α(a) = +1 and β(b) = +1, then E = +1
(2) α(a) = +1 and β(b) = −1, then E = −1
(3) α(a) = −1 and β(b) = +1, then E = −1
(4) α(a) = −1 and β(b) = −1, then E = +1
Comparing with (5.60) and choosing F(λ) equal to α(a)β(b), we see that the mini-
mum and maximum of S are m = −2 and M = +2, so that
−2 ≤S ≤+2.
(5.67)
This was the form of Bell’s formula tested by Clauser, Horne, Shimony and Holt
(CHSH) (Clauser et al. 1969). This inequality has been proved assuming that the
correlation functions are averages over some unknown hidden variables. But it is
easy to prove that inequality (5.67) is violated in quantum mechanics. Let E QM be
the quantum analog of E (see Eq.5.65):
SQM = E QM(a, b)+E QM(a, b′) + E QM(a′, b) −E QM(a′, b′) =
−a · b −a · b′ −a′ · b + a′ · b′,
(5.68)
and assume that the pair is in a singlet state. Since (5.67) holds for any choice of a,
b, a′, b′, we can adopt the particular choice suggested by Mermin (1985), which is
particularly suitable to dramatize the counterintuitive aspects of quantum mechanics.
Consider three coplanar unit vectors x, u, v (see Fig.5.7) with coordinates:
Fig. 5.7 Mermin’s choice of
a, b, a′, b′

172
5
Quantum Entanglement and Bell’s Theorem
Fig. 5.8 The choice by Clauser and Shimony for a, b, a′, b′
x = (1, 0),
u =

−1
2,
√
3
2

,
v =

−1
2, −
√
3
2

.
(5.69)
Using the elementary rule x · u = x1u1 + x2u2, etc., we have
x · u = x · v = u · v = −1
2.
(5.70)
Mermin suggests the choice a = u, b = v, a′ = b′ = x. Then, using the Lemma
and Eq.(5.68), we ﬁnd
SQM = −u · v −u · x −x · v + x · x = 1
2 + 1
2 + 1
2 + 1 = 2.5 > 2.
(5.71)
Therefore, the inequality (5.67) is violated, and the theorem is proved.
Clearly, many different choices for a, b. a′, b′ are possible. The optimal choice
has been suggested by Clauser and Shimony, namely a = (1, 0), b =

1
√
2,
1
√
2

,
a′ = (0, 1), b′ =

1
√
2, −1
√
2

, as shown in Fig.5.8. With this choice, SQM = 2
√
2 >
2, so that Bell’s inequality is maximally violated.
The beauty and signiﬁcance of Bell’s inequality lies not only in its elegant mathe-
matical formulation, but also in the fact that it permits experimental veriﬁcation. One
could argue that it is not that extraordinary for a mathematical formula concerning
physical quantities can be tested experimentally. But the remarkable fact here is that
we are dealing with an answer to an almost “metaphysical” question: we are ask-
ing: “Do hidden variables in the sense of Bell’s inequality exist?” or, equivalently,
“Does God play dice?” In simpler terms, do the fundamental laws of Nature contain
a primary, irreducible, and unavoidable probabilistic aspect?
Before describing the very elegant experiments that conclusively provide an
answer to this question, let us review one of the most extraordinary accomplish-

5.4 Generalized Bell’s Inequality
173
ments of the human intellect, namely, Maxwell’s discovery of the equations of the
electromagnetic ﬁeld. These equations, which revealed the fundamental nature of
light, will help us to understand in greater depth the crucial experiments associated
with Bell’s inequality.
5.5
Maxwell’s Equations, the Nature of Light, and All That
Let us begin by describing two experiments which were instrumental in the develop-
ment of electromagnetic theory. (1) Hans Christian Ørsted discovered that an electric
current ﬂowing through a wire produces a magnetic ﬁeld circulating around the wire,
which he mapped using a compass. This was the ﬁrst observed connection between
electricity and magnetism. The phenomenon is illustrated in Fig.5.9. If the wire
is wound into a helix, the superposition of the magnetic ﬁeld ringlets produces a
solenoidal magnetic ﬁeld (similar to that of a bar magnet). If the coils of wire are
wound around a soft iron core and connected to an AC power supply, the result is an
electromagnet, with its ﬁeld oscillating sinusoidally at the same frequency as the cur-
rent, as shown in Fig.5.10. (2) As shown in Fig.5.11, we insert a permanent magnet
into a solenoid connected to a sensitive galvanometer. When the magnet is moved
inside the solenoid, the galvanometer indicates a current ﬂow. We conclude that a
magnetic ﬁeld B which varies in time can generate an electric ﬁeld E (which moves
the electrons in the wires of the solenoid). This phenomenon, magnetic induction,
was ﬁrst discovered by Michael Faraday. The three-dimensional vector ﬁelds E and
B exist at all the points in space. These two experiments described above can be
represented qualitatively by the differential relations3:
(1) ∇× B = μ0ε0
∂E
∂t
(2) ∇× E = −∂B
∂t .
(5.72)
We omit the full details, but it can be surmised that the curl operator ∇× is associate
with the circulation of a vector ﬁeld, while ∂
∂t represents a variation with time. In both
of the above equations, the electric ﬁeld produces a current in the same direction. Here
ε0 represents the electric permittivity of free space, and μ0, the magnetic permeability
of free space.
These and many other experiments show that the spatial and temporal variations of
E and B are closely interconnected; this is true not only inside wires and solenoids, but
also in empty space. Maxwell produced a synthesis of the work of his several brilliant
predecessors, including, Faraday, Coulomb, Ampere, Gauss, Ørsted. He proposed a
set of equations which describe the spacial and temporal interrelationships between
the electric and magnetic ﬁelds. By manipulating these equations, Maxwell derived
an equation describing the propagation of waves, a phenomenon which was already
familiar, but in different contexts. This had the form of the wave equation, which can
3These are, in fact, the 3rd and 4th of Maxwell’s equation in free space. The 1st and 2nd are ∇·E = 0
and ∇· B = 0.

174
5
Quantum Entanglement and Bell’s Theorem
Fig. 5.9 An electric current
I in a straight wire produces
a circulating magnetic ﬁeld
B. The right-hand rule
determines the relative
orientations of I and B
Fig. 5.10 A solenoidal
electromagnet
represent, for example, waves on the surface of a lake produced by a falling stone
(see Fig.1.1) or pressure variations in the air produced by sound.
The wave equation for E can be derived from Eq.(5.72). Applying ∂
∂t to (1) and
∇× to (2) and adding, we obtain
∇2E −ε0μ0
∂2E
∂t2 = 0.
(5.73)
Reversing the operations on (1) and (2), we obtain an analogous equation for B. From
analogies with other wave equations, (5.73) can be recognized as a description of
waves propagating with velocity c = 1/√ε0μ0. Since the values of ε0 and μ0 were
known, Maxwell found c ≃300, 000km/s. At that time it was possible to measure
the speed of light, with results approximating this value. Maxwell concluded that
light consists of propagating electromagnetic waves, one of the most extraordinary

5.5 Maxwell’s Equations, the Nature of Light, and All That
175
Fig. 5.11 A magnet moving inside a solenoid induces a current ﬂow, detected by a galvanometer
achievements in the history of science. Maxwell’s epoch-making discovery had thus
succeeded in unifying the diverse phenomena of electricity, magnetism, and optics.
Let us consider ﬁrst the electromagnetic wave equation for the simple case of
a wave propagating in vacuum, in the positive z-direction, with the electric ﬁeld
E directed along the x-axis, and the magnetic ﬁeld B directed along the y-axis, as
shown in Fig.5.12. The wave equation for the electric-ﬁeld component Ex is given
by
∂2Ex
∂z2
= 1
c2
∂2Ex
∂t2 .
(5.74)
Fig. 5.12 A transverse electromagnetic wave with E parallel to the x-axis

176
5
Quantum Entanglement and Bell’s Theorem
where t represents the time. An identical wave equation holds for the magnetic-ﬁeld
component By:
∂2By
∂z2 = 1
c2
∂2By
∂t2 .
(5.75)
Two comments are in order. Man has been able to discover a law so remote
from everyday experience, in view of the enormously high speed of light and the
microscopically small dimension of its wavelength. Yet, the nature of light is the same
throughout all the known universe (which extends outward at least 14 billion light
years). Furthermore, light is so important for us, that we would be blind if it did not
exist.Evenforthosewithasecularperspective,itisfascinatingthatinGenesis,among
the ﬁrst words spoken by God are “Let there be light.” After Maxwell’s discovery,
further exploration revealed the entire spectrum of electromagnetic waves. Typical
values of the wavelengths (in meters) are the following: radio 103 m, microwave
10−2 m, infrared 10−5 m, visible 5 × 10−7 m, ultraviolet 10−8 m, X-rays 10−10 m,
gamma rays 10−12 m. It is, of course, superﬂuous to mention the vast number of
technical applications of electromagnetic waves in modern life.
Returning to the wave equation (5.74), it is easy to verify that it can be satisﬁed
by a simple periodic solution of the form
Ey = E0
y cos
2π
λ (z −ct)

,
(5.76)
where E0
y is a constant. Indeed we have
∂2Ey
∂z2
= −
2π
λ
2
Ey,
∂2Ey
∂t2
= −
2πc
λ
2
Ey,
(5.77)
so that
∂2Ey
∂z2 −1
c2
∂2Ey
∂t2
= 0,
(5.78)
which is the one-dimensional wave equation. Since replacing z in (5.76) by z + λ
gives the same value of Ey, the solution is periodic in space with the wavelength λ
representing the distance between two successive maxima (or minima or zeros) of
the wave. Since the propagation velocity is c, the period of oscillation is T = λ
c .
Therefore, the frequency ν = 2πω = 1
T . The two particular solutions of the wave
equations (5.74), (5.75) represent (1) E parallel to the x-axis and B parallel to the
y-axis (see Fig.5.12) and (2) E parallel to the y-axis and B parallel to the x-axis (see
Fig.5.13). If k is the vector along the propagation direction, then in both cases, E,
B, k form a right-handed system. In fact, k = const E × B. The plane containing the
vectors E and k is called the plane of polarization. Since wave equations are linear,
a more general solution can be obtained taking a linear combination of (1) and (2).
From now on, we can focus just on the electric ﬁeld in these waves, since the
accompanying perpendicular magnetic ﬁeld is then determined by Maxwell’s equa-
tions. We write the particular solutions (1), (2), respectively, in the following form:

5.5 Maxwell’s Equations, the Nature of Light, and All That
177
Fig. 5.13 A transverse electromagnetic wave with E parallel to the y-axis
Ex = A cos
2π
λ (ct −z) + α)

,
Ey = B cos
2π
λ (ct −z) + β)

,
(5.79)
where A, B are constants determining the intensity of the ﬁeld. Since there is no
restriction for the two components to be in phase, α and β are not, in general, equal.
Taking the sum of the particular solutions (Ex, 0, 0) and (0, Ey, 0) we obtain the
vector E(t) = (Ex, Ey, 0) which represents the electric ﬁeld of a light wave. It is
convenient to deﬁne the radian frequency
ω = 2π
λ c.
(5.80)
The variation of E for a ﬁxed value of z, say z = 0, is then given by
Ex = A cos(ωt + α),
Ey = B cos(ωt + β).
(5.81)
Clearly, E lies in a plane orthogonal to the direction of propagation.
5.6
Light Polarization and the Spin of the Photon
Before discussing the general case, let us see what happens if α = β. Then from
(5.81) we have, for Ey ̸= 0:

178
5
Quantum Entanglement and Bell’s Theorem
Ex
Ey
= A
B .
(5.82)
Equation (5.82) represents a straight line in the plane Ex, Ey; actually when t varies,
E varies along a segment of the straight line with |Ex| ≤A, |Ey| ≤B. These
inequalities, together with (5.82), describe linearly polarized light. For the more
general case, let us introduce the variables ex = Ex
A , ey = Ey
B , such that
ex = cos(ωt + α) = cos ωt cos α −sin ωt sin α,
ey = cos(ωt + β) = cos ωt cos β −sin ωt sin β.
(5.83)
Solving these equations for cos ωt, sin ωt, we obtain
cos ωt =
ex sin β−ey sin α
cos α sin β −cos β sin α = ex sin β−ey sin α
sin(β−α)
sin ωt =
ex cos β−ey cos α
cos α sin β −cos β sin α = ex cos β−ey cos α
sin(β−α)
.
(5.84)
Squaring, then adding the two equations, and multiplying by sin2(β −α), we obtain
sin2(β−α) = e2
x+e2
y−2exey(sin β sin α+cos β cos α) = e2
x+e2
y−2exey cos(β−α).
(5.85)
Therefore, in the plane z = 0, the point E = (Ex, Ey) traces out a conic:
 Ex
A
2
+
 Ey
B
2
−2 Ex Ey
A B
cos(β −α) = sin2(β −α).
(5.86)
This is the equation of an ellipse; the light is then described as elliptically polar-
ized. Figure5.14 shows different ellipses and degenerate line segments obtained by
varying β −α. An important particular case occurs when A = B, and β −α =
(2k + 1) π
2 , with integer k; then cos(β −α) = 0 and sin2(β −α) = 1. Equation
(5.85) becomes the equation of a circle of radius A:
E2
x + E2
y = A2.
(5.87)
In this case, the light is circularly polarized: left-circularly polarized if the vector
E, seen from the propagation direction k (the light ray coming toward you), rotates
anticlockwise, and right-circularly polarized if it rotates clockwise.
Fig. 5.14 Ellipses and degenerate line segments obtained by varying the angle β −α

5.6 Light Polarization and the Spin of the Photon
179
We now introduce the concept of the spin of the photon, implying, in essence, that
a light quantum carries angular momentum. Let us see how the polarization plane
changes under a rotation Rz around the k axis; Rz can be written using Eq. (4.39):
Rz(θ) =


cos θ −sin θ 0
sin θ
cos θ 0
0
0
1


,
(5.88)
where θ is the rotation angle about the z-axis (0 ≤θ < 2π). As expected, Rz(2π) =
Rz(0) = I3. We know from Eqs. (4.62), (4.63) that for small δθ, Rz(δθ) ≃I3 −
iδθ J3 where J3 = i3 (using units with ℏ= 1). J3 is the z-component of angular
momentum and the generator for rotation about the z-axis and I3 is the identity
matrix in three dimensions. Note that the behavior of Rz is analogous to that of a
wavefunction Ψ (θ) under inﬁnitesimal rotations; we can write
Ψ (θ + δθ) ≃Ψ (θ) + dΨ
dθ δθ = Ψ (θ) −iδθ J3Ψ (θ).
(5.89)
As in Chap.4, we are applying the group of rotations about the z-axis. Only now,
the vector space is different: J3 acts in the physical 3D space R3, while earlier, J3
acted in the Hilbert space of spinor wavefunctions Ψ . However, the operations of
the rotation group SO(3) in the two cases are isomorphic and we can use the same
matrix representations. A 3 × 3 matrix representation for angular momentum was
given in Sect.3.4.4. Replacing L by J, this corresponds to an angular momentum
with J = 1, in a basis with J3 diagonalized. The three eigenvalues M = −1, 0, +1
then appear in the diagonal of the matrix:
J3 =


1 0 0
0 0 0
0 0 −1


.
(5.90)
From this, we can conclude that the photon has an intrinsic angular momentum
J = 1, and it is a spin-1 particle. By contrast, we had found that the spin wave-
functions for particles including electrons, protons, and neutrons transform under
rotations according to the SU(2) group. We found the relations Ji = 1
2σi, consistent
with our classiﬁcation of these as spin- 1
2 particles.
5.7
The Hilbert Space of One Photon and Aspect’s
Experiment
5.7.1
Photon Polarization
The eigenvalue 0 of J3 corresponds to the eigenvector e3 = (0, 0, 1). Physically, it
would represent a longitudinal component of the electric ﬁeld, one directed along the

180
5
Quantum Entanglement and Bell’s Theorem
propagationdirection.SinceinfreespaceE isalwaystransverse,thusorthogonaltok,
longitudinal electric ﬁelds occur only in constrained geometries, such as waveguides.
Our concern is only with the transverse ﬁelds of electromagnetic radiation in free
space. By specifying only the wavelength λ and the propagation direction k of the
ﬁeld, a “small” Hilbert space C2 is sufﬁcient to describe the possible states of one
photon. For a photon in free space, corresponding to a transverse ﬁeld, E = (Ex, Ey)
is given by
Ex = A cos(kz −ωt + α) = A Re

ei(kz−ωt+α)	
,
Ey = B cos(kz −ωt + β) = B Re

ei(kz−ωt+β)	
.
(5.91)
We can deﬁne, using E =

E2x + E2y:
a = A
E eiα,
b = B
E eiβ,
(5.92)
so that
|a|2 + |b|2 = A2|eiα|2 + B2|eiβ|2
A2 + B2
= 1,
(5.93)
with


a
b

 representing a unit vector in the Hilbert space C2. This represents the
quantum state of the photon. Note that this a two-dimensional vector, and not a
spinor. The vector


1
0

 corresponds to vertical polarization (E directed along the x-
axis), and


0
1

 corresponds to horizontal polarization (E directed along the y-axis).
In general, the electric ﬁeld can be written as
E(z, t) = E Re


a
b

 ei(kz−ωt)

.
(5.94)
Given the state


a
b

 of the photon, Eq. (5.94) gives the corresponding electric
ﬁeld. If a and b are real, we have Ex = Ea cos(kz −ωt), Ey = Eb cos(kz −ωt),
with
Ex
Ey
= a
b ,
(5.95)
showing that the photon is linearly polarized. More generally, for complex a =
a1 + ia2, b = b1 + ib2, we have, from (5.94):

5.7 The Hilbert Space of One Photon and Aspect’s Experiment
181
Ex = E Re

(a1 + ia2)(cos(kz −ωt) + i sin(kz −ωt)
	
=
E

a1 cos(kz −ωt) −a2 sin(kz −ωt)
	
,
Ey = E Re

(b1 + ib2)(cos(kz −ωt) + i sin(kz −ωt)
	
=
E

b1 cos(kz −ωt) −b2 sin(kz −ωt)
	
.
(5.96)
For the particular case, with a = a1 =
1
√
2, b = ib2 =
i√
2, we have, from Eq. (5.96),
that
Ex =
1
√
2 E cos(kz −ωt) =
1
√
2 E cos(ωt −kz),
Ey = −1
√
2 E sin(kz −ωt) =
1
√
2 E sin(ωt −kz).
(5.97)
Here E2
x + E2
y = E2, and the photon is circularly polarized; more precisely, left-
circularly polarized (see Fig.5.14). Alternatively, with a = a1 =
1
√
2, b = ib2 =
−i√
2, the photon turns out to be right-circularly polarized. In the general case with
a, b, complex and |a|2 + |b|2 = 1, the photon is elliptically polarized.
The two-dimensional vectors


a
b

 representing photon polarization (known as
Jones vectors) include the following special cases of vertical and horizontal polar-
ization:
|V ⟩=


1
0

 ,
|H⟩=


0
1

 .
(5.98)
More relevant to the representation of photon angular momentum are the left- and
right-circularly polarized states:
|L⟩=
1
√
2


1
i

 ,
|R⟩=
1
√
2


1
−i

 .
(5.99)
The operator for the z-component of angular momentum can be taken from the ﬁrst
2 ⊗2 block of 3 in Eq. (4.63). Note that this is the direction of the propagation
vector k. We can write
J3 = i


0 −1
1 0

 =


0 −i
i 0

 .
(5.100)
It is then simple to verify that


0 −i
i 0




1
±i

 = ±


1
±i

 ,
(5.101)
showing that |L⟩and |R⟩are eigenvectors of J3 with eigenvalues ±1, respectively.
The eigenvector for J3 = 0 is missing, since this would correspond to the nonexistent
longitudinal polarization.

182
5
Quantum Entanglement and Bell’s Theorem
The two-photon state is described by the wavefunction
|Ψ0⟩=
1
√
2

|RA⟩⊗|L B⟩+ |RB⟩⊗|L A⟩

.
(5.102)
Since J3|L⟩= |L⟩and J3|R⟩= −|R⟩, the single photon states |L⟩, |R⟩correspond to
angular momentum eigenvectors with J3 = +1, J3 = −1, respectively, representing
left- and right-circularly polarized photons.
5.7.2
Aspect’s Experiment
We now describe a famous experiment which actually attempts to answer the “meta-
physical” question of quantum realism. In 1981–1982 Alain Aspect and collaborators
performed deﬁnitive tests of Bell’s inequality (Aspect et al. 1981). They used a cas-
cade emission of two photons A, B, from electronic transitions from an excited level
of calcium atoms, as shown in Fig.5.15. The lifetime of the intermediate state is only
5 ns; this interval of time is so small that we can assume that the two photons are
emitted simultaneously (light travels 30cm in one nanosecond).
A diagram of the experiment is shown in Fig.5.16. The two photons A, B are
emitted by the source S in the state |Ψ0⟩. After traveling a distance L they are incident
on a pair of two-channel polarizers PA, PB, each of which can convert a circularly
polarized photon to either a vertical or a horizontal polarization. The directions of
two polarizers are randomly changed approximately every 20 ns. Photons exiting the
polarizers can be detected by four photomultipliers D±, located as shown in Fig.5.16.
(A photomultiplier is an extremely sensitive phototube that multiplies the very weak
current produced by light about 100 million times.)
When the photons strike one of the polarizers P (with polarization directions a±,
b±), they can either pass straight through or be deﬂected in the orthogonal direc-
tion; in the latter case they are detected by the photomultipliers D−(with polariza-
tion directions a−, b−). The two paths (transmission or reﬂection) occur with equal
probabilities 1
2. Finally, an electronic counter module CM monitors the coincidences
(a+, b+), (a+, b−), (a−, b+), and (a−, b−). Thus the correlation coefﬁcient E(a, b)
(see 5.65, 5.68) for the hidden variables and the corresponding quantum mechanical
Fig. 5.15 Cascade emission
of two photons (greenand
blue) by calcium atom after
laser excitation. The photons,
entangled with opposite
circular polarizations, are
ejected in opposite directions

5.7 The Hilbert Space of One Photon and Aspect’s Experiment
183
Fig. 5.16 Experimental apparatus for testing Bell’s inequality
expressions can be measured, and Bell’s inequality (5.67) thereby tested. As we
anticipated earlier, the quantum mechanical prediction is in agreement with the mea-
surement, with the CHSH parameter S = E(a, b) + E(a, b′) + E(a′, b) −E(a′, b′)
for many choices of a, a′ for the polarizer PA, and b, b′ for the polarizer PB. Note
that the distance L between the source S and the polarizers was 6m or longer.4 Due
to the rapid switching of PA, PB, no signal with speed less than or equal to that of
light can “inform” the polarizer PB (or the detector near PB) of the direction of the
vector a chosen by the polarizer PA. The same goes for the path (D+ or D−) chosen
by the photon.
The experimental result gave a value of Sexp = 2.70 ± 0.05, in remarkable agree-
ment with the prediction of quantum mechanics. We conclude this brief description
with a quote by Alain Aspect5:
The experimental violation of Bell’s inequality conﬁrms that a pair of entangled photons
separated by hundreds of meters must be considered a single non-separable object, it is
impossible to assign local physical reality to the state of each photon.
The conclusion that can be drawn from these experiments can be formalized as
Bell’s theorem: No local realistic physical theory can reproduce the predictions of
quantum mechanics. Local realism is the worldview in which physical properties
of objects exist independently of their measurement and where interactions among
objects cannot travel faster than the speed of light. Bell’s theorem states that this
4The distance 2L was increased up to 400m by Weihs et al. (1998) Phys Rev Lett 81:5039–
5043. Entangled photons were transmitted over 144km by Zeilinger et al. (2007) Proc of SPIE
6780:67800B.
5Aspect (1999) Bell’s inequality test: more ideal than ever. Nature 398:189–190.

184
5
Quantum Entanglement and Bell’s Theorem
worldview is incompatible with the predictions of quantum mechanics.6 Particle
physicist Henry Stapp believes that “Bell’s theorem is the most profound discovery
of science.” (Stapp 1975).
5.8
Measurement and Decoherence
As we described in Chap.3, there exist two different modes of evolution of the wave-
function |Ψ (t)⟩. The ﬁrst, linear and continuous, is governed by the time-dependent
Schrödinger equation, while the second, called “collapse of the wavefunction,” is
nonlinear and random. This inescapable duality has long been a perplexing enigma.
When does the collapse of the wave function actually occur? Is it when a conscious
observer “takes note” of the new state? Or, perhaps more reasonably, when an inan-
imate physical mechanism triggers the “quantum jump”? To try to answer these and
similar questions, consider a microscopic system S, a measurement apparatus (or
detector) M and the environment E, consisting of the enormous number of atoms
and photons that surround the measuring apparatus. According to the deﬁnition of
Zurek (2002): “Environments can be external (such as particles of air or photons that
scatter off, say, the apparatus pointer) or internal (such as collections of phonons or
other excitations in the materials from which an apparatus is constructed).” It follows
from this deﬁnition that the boundary between M and E is somewhat nebulous and
largely dependent on our arbitrary choice. The part of the environment that does not
contribute signiﬁcantly to the evolution of the state of the apparatus can be ignored.
M is a macroscopic object, but often the interaction with S involves one of its micro-
scopic components (Doplicher 2012). The enormous number of degrees of freedom
necessary to describe both M and E causes the interaction with S to give rise to an
irreversible process, somewhat similar to the situation in statistical thermodynamics.
In principle, we can regard M and E as intrinsic parts of a composite quantum
mechanical system, even if it is not possible to exactly solve the time-dependent
Schrödinger equation for a realistic system with so many degrees of freedom. For
simplicity, assume that S can be in only one of two states, for example, the states
J3 = ±1 of a photon. To these states there correspond the vectors |m ↑⟩, |m ↓⟩of the
detector M; we will call these pointer states since they allow us to read the result of
a measurement on S. Attempting to treat the apparatus M as a quantum mechanical
system might be tricky, since M is usually pictured as a device governed by classical
mechanics. It is easy to prove that ⟨m ↑|m ↓⟩= 0. If the normalized vectors |m ↑⟩,
|m ↓⟩correspond to different positions of a pointer, then displacement of each of the
6Scrupulous analysis of these tests of Bell’s theorem identiﬁed two possible “loopholes” to their
universal validity. The locality loophole arises from the possibility that, if the measurements are too
slow, the photon detectors might be communicating with one another in some way (by a yet unknown
mechanism). The detection loophole is the possibility that the observed events might represent a
skewed sample of all the emitted photon pairs, since detectors are less than 100% efﬁcient. However,
in late 2015, three research groups (at Delft University of Technology, University of Vienna and
NIST) have succeeded in carrying out “loophole-free” Bell tests.

5.8 Measurement and Decoherence
185
molecules in the pointer by just a few millimeters certainly produces orthogonality,
since the product of the two wavefunctions vanishes everywhere. Assume now that
the system S is in a superposition state |φs⟩:
|φs⟩= a| ↑⟩+ b| ↓⟩
(5.103)
and the state of the detector is initially |m ↓⟩. After the measurement, the state of
the composite system S, M, becomes
|φc⟩= a| ↑⟩⊗|m ↑⟩+ b| ↓⟩⊗|m ↓⟩.
(5.104)
The density matrix corresponding to this state is
ρc = |φc⟩⟨φc| = (a| ↑⟩⊗|m ↑⟩+ b| ↓⟩⊗|m ↓⟩)(a∗⟨↑| ⊗⟨m ↑| + b∗⟨↓| ⊗⟨m ↓|) =
|a|2| ↑⟩⟨↑| ⊗|m ↑⟩⟨m ↑| + |b|2| ↓⟩⟨↓| ⊗|m ↓⟩⟨m ↓|+
ab∗| ↑⟩⟨↓| ⊗|m ↑⟩⟨m ↓| + ba∗| ↓⟩⟨↑| ⊗|m ↓⟩⟨m ↑|.
(5.105)
Let us denote by |up⟩the state | ↑⟩⊗|m ↑⟩and by |down⟩the state | ↓⟩⊗|m ↓⟩.
Since |Ψc⟩is a superposition of |up⟩and |down⟩, the following block of the matrix
representing ρc = |Ψc⟩⟨Ψc| contains the non-diagonal elements ab∗and ba∗:


⟨up|ρc|up⟩
⟨up|ρc|down⟩
⟨down|ρc|up⟩⟨down |ρc|down⟩

 =


|a|2 ab∗
ba∗|b|2

 .
(5.106)
Suppose now that we want to discard the quantum description of the apparatus M,
leaving unaltered the probabilities of the | ↑⟩and | ↓⟩states. A simple way to do it
is just to take the expectation value of ρc over the two states |m ↑⟩, |m ↓⟩, and sum
the results. This is equivalent to taking a partial trace of ρc with respect to a basis
of M. This corresponds to performing an average over the effects of M. The result,
taking into account the orthonormality of |m ↑⟩and |m ↓⟩, is a new density matrix
ρr acting on the Hilbert space of the system S:
ρr = ⟨m ↑|ρc|m ↑⟩+ ⟨m ↓|ρc|m ↓⟩= |a|2| ↑⟩⟨↑| + |b|2| ↓⟩⟨↓|.
(5.107)
The matrix ρr is represented by the following block:


⟨↑|ρr| ↑⟩⟨↑|ρr| ↓⟩
⟨↓|ρr| ↑⟩⟨↓|ρr| ↓⟩

 =


|a|2
0
0
|b|2

 ,
(5.108)
where the non-diagonal matrix elements of (5.107) have disappeared; ρr is called
a reduced density matrix (Von Neumann 1932). It has the advantage of allowing a
simple interpretation of the probabilities, |a|2 for the | ↑⟩state, and |b|2 for the | ↓⟩
state, in agreement with Born’s interpretation of probability in quantum mechanics.
Furthermore, no superposition of |m ↑⟩and |m ↓⟩appears. This seems reasonable,

186
5
Quantum Entanglement and Bell’s Theorem
since nobody has ever seen a half-alive and half-dead cat (we will come back to this
later in connection with quantum superposition of macroscopic objects).
We recognize that a spontaneous evolution of ρc to ρr (or, more precisely, of ρc
to ρr ⊗I)7 is impossible. To prove this, we note that ρ2
c = ρc, since
ρ2
c = |φc⟩⟨φc||φc⟩⟨φc| = |φc⟩⟨φc| = ρc.
(5.109)
Denote by U(t), the unitary operator for time evolution according to the time-
dependent Schrödinger equation. Since |φc(t)⟩= U(t)|φc⟩, it is evident that
ρc(t) = U(t)ρcU(t)−1 (note that the time evolution of the density matrix differs
from the time evolution of observables). Then, ρc(t)2 = ρc(t), since
ρc(t)2 = U(t)ρcU(t)−1U(t)ρcU(t)−1 = U(t)ρ2
cU(t)−1 = U(t)ρcU(t)−1 = ρc(t).
(5.110)
But Eq. (5.110) does not hold for ρr, since
ρ2
r = |a|4| ↑⟩⟨↑| + |b|4| ↓⟩⟨↓| ̸= ρr,
(5.111)
which completes the proof.
Physicists have tentatively discovered a possible effect that gives rise to the tran-
sition ρc →ρr. This effect is called decoherence; much work remains in order to
formulate a theory of decoherence on a rigorous mathematical basis. The general
idea is the following: in the description of the complete system, including S, M,
and the environment E, assume that the state |E ↑⟩of the environment is associated
to the pair | ↑⟩, |m ↑⟩, and the state |E ↓⟩of the environment is associated to the
pair | ↓⟩, |m ↓⟩. Furthermore ⟨E ↑|E ↓⟩= 0 (we will come back in a moment
to show that this is reasonable). Of course, we can always normalize the two states:
⟨E ↑|E ↑⟩= ⟨E ↓|E ↓⟩= 1. The wave function of the global system is now
|Ψ ⟩= a| ↑⟩⊗|m ↑⟩⊗|E ↑⟩+ b| ↓⟩⊗|m ↓⟩⊗|E ↓⟩= a|UP⟩+ b|DOWN⟩,
(5.112)
where |UP⟩= | ↑⟩⊗|m ↑⟩⊗|E ↑⟩and |DOWN⟩= | ↓⟩⊗|m ↓⟩⊗|E ↓⟩. Recall
that |up⟩= | ↑⟩⊗|m ↑⟩, |down⟩= | ↓⟩⊗|m ↓⟩; in |up⟩and |down⟩(lower case),
the state of E does not appear. Since the states |E ↑⟩, |E ↓⟩are orthogonal, we
can repeat the same reasoning as before, tracing over8 the degrees of freedom of the
environment. The result is the following reduced density matrix:
ρR = |a|2|up⟩⟨up| + |b|2|down⟩⟨down|,
(5.113)
in which no superposition term appears.
7I denotes the identity in the Hilbert space of the measuring apparatus.
8Taking the expectation values on |E ↑⟩and |E ↓⟩and summing the results.

5.8 Measurement and Decoherence
187
We are, however, faced with two crucial issues:
(1) Why are the two states of the environment |E ↑⟩and |E ↓⟩orthogonal to each
other?
(2) What is the order of magnitude of the time needed for the superposition terms to
disappear, to give a reduced density matrix (5.113)?
We can answer question (1) with an simpliﬁed argument in which we neglect the
effect of Fermi–Dirac statistics (the antisymmetry of the electronic wavefunctions),
which does not change the essentials of the argument. Consider a macroscopic system
of N particles, for example, N molecules of a gas. Let us denote by |E⟩, |F⟩two
quantum states of the gas that are assumed to be product states:
|E⟩= |e1⟩⊗|e2⟩. . . ⊗|eN⟩,
|F⟩= | f1⟩⊗| f2⟩. . . ⊗| fN⟩,
(5.114)
where |ei⟩, | fi⟩are normalized states of the ith molecule. The scalar product ⟨F|E⟩=
⟨f1|e1⟩⟨f2|e2⟩. . . ⟨fN|eN⟩contains an enormous number of factors whose absolute
value is less or equal to 1, since by Schwarz’s inequality:
|⟨fi|ei⟩|2 ≤⟨fi| fi⟩⟨ei|ei⟩= 1.
(5.115)
Thus, choosing the factors |⟨fi|ei⟩| in the interval [0, 1] at random, one obtains a
vanishingly small result. Furthermore, the states |ei⟩, | fi⟩correspond to displaced
positions of the ith molecule, giving a physical reason for the scalar product ⟨fi|ei⟩to
be small. The weak point of this argument is that its validity is restricted to product
states. A more general state can consist of a huge linear combination of product
states. A deeper analysis of the interaction between the system S and the macroscopic
systems M and E is needed, which we will not attempt here. In conclusion then, there
is a general belief that we can safely use the reduced density matrix ρR, in which only
diagonal matrix elements appear. It is also quite difﬁcult to answer question (2) in a
rigorous way. However, many particular solvable models have been examined, with
the result that the decoherence time between macroscopically separated positions is
shown to be extremely small.
Consider a very simple solvable model that describes the interaction of a two-state
apparatus M (or a microscopic part of M) with a very large number N of spins in
the environment E. We denote by |m ↑⟩, |m ↓⟩the two states of M, and by |k ↑⟩,
|k ↓⟩the two states of the kth environmental spin. Let L M be the space spanned by
|m ↑⟩, |m ↓⟩, and Lk, the space spanned by |k ↑⟩, |k ↓⟩. We deﬁne the third spin
component σM and the third spin component σk by the same matrix:
σM = σk =


1 0
0 −1

 .
(5.116)

188
5
Quantum Entanglement and Bell’s Theorem
This matrix represents an operator acting on L M, while σk represents an operator
acting on Lk. The matrix is the same, but they act in different spaces. The coupling
Hamiltonian HM E is given by
HM E =

k
gk σM ⊗σk,
(5.117)
wherethe gk arecouplingconstants.AnalternativewaytowritethesameHamiltonian
deﬁnes the projection operators (Zurek 2003)
PM↑= |m ↑⟩⟨m ↑|, PM↓= |m ↓⟩⟨m ↓|, Pk↑= |k ↑⟩⟨k ↑|, Pk↓= |k ↓⟩⟨k ↓|,
(5.118)
so that the interaction Hamiltonian becomes
HM E = (PM↑−PM↓) ⊗

k
gk(Pk↑−Pk↓).
(5.119)
The initial state of M and E is
|Ψ (0)⟩= (a|m ↑⟩+ b|m ↓⟩) ⊗

k
⊗(αk|k ↑⟩+ βk|k ↓⟩).
(5.120)
Since |Ψ (0)⟩is normalized, |a|2 + |b|2 = |αk|2 + |βk|2 = 1 ∀k. To obtain |Ψ (t)⟩,
applytheevolutionoperatore−i HM Et/ℏto|Ψ (0)⟩.Insodoing,weneglecttheevolution
due to the free (non-interacting) Hamiltonians for M and E.
The operators σk commute, since they act on different factors of a tensor product; it
follows that the operators σM ⊗σk also commute. If A and B commute, the following
simple exponential operator formula is valid:
eA+B = eAeB.
(5.121)
The identity (5.121) can be demonstrated by series expansions of the exponentials.
The algebraic steps are the same as if A, B were real or complex numbers. Using
(5.121), we can write the evolution operator e−i HM Et/ℏin the form:
e−i HM Et/ℏ= e−i(

k σM⊗σk)t/ℏ=

k
e−igkσM⊗σkt/ℏ.
(5.122)
Consider now the four-dimensional space Lk spanned by the vectors
|m ↑⟩⊗|k ↑⟩, |m ↑⟩⊗|k ↓⟩, |m ↓⟩⊗|k ↑⟩, |m ↓⟩⊗|k ↓⟩.
(5.123)
The matrix representing σM ⊗σk, an operator acting on Lk, is diagonal, with matrix
elements +1, −1, −1, +1. Therefore, the operator e−iσM⊗σkgkt/ℏis represented by
the matrix:

5.8 Measurement and Decoherence
189


e−igkt/ℏ
0
0
0
0
eigkt/ℏ
0
0
0
0
eigkt/ℏ
0
0
0
0
e−igkt/ℏ


.
(5.124)
The initial state |Ψ (0)⟩of M and E (see 5.120) can be written as the tensor product:
|Ψ (0)⟩= 
k ⊗

aαk|m ↑⟩⊗|k ↑+aβk|m ↑⟩⊗|k ↓⟩+
bαk|m ↓⟩⊗|k ↑⟩+ bβk|m ↓⟩⊗|k ↓⟩

= 
k ⊗|vk⟩,
(5.125)
where the components of |vk⟩∈Lk are (aαk, aβk, bαk, bβk). Since time evolution
does not mix the spaces Lk, we obtain |Ψ (t)⟩by simply applying the matrix (5.124)
to |vk⟩and writing the resulting tensor product. This gives
|Ψ (t)⟩= ⊗k

e−igkt/ℏaαk |m ↑⟩⊗|k ↑⟩+ eigkt/ℏaβk |m ↑⟩⊗|k ↓⟩+
eigkt/ℏbαk |m ↓⟩⊗|k ↑⟩+ e−igkt/ℏbβk|m ↓⟩⊗|k ↓⟩

=
a|m ↑⟩⊗|E ↑(t)⟩+ b|m ↓⟩⊗|E ↓(t)⟩,
(5.126)
where
|E ↑(t)⟩= ⊗N
k

αke−igkt/ℏ|k ↑⟩+ βke
itgk
ℏ|k ↓⟩

,
|E ↓(t)⟩= ⊗N
k

αkeigkt/ℏ|k ↑⟩+ βke−igkt/ℏ|k ↓⟩

.
(5.127)
Clearly then, |E ↓(t)⟩= |E ↑(−t)⟩. Denoting by E↑↑= |E ↑(t)⟩⟨E ↑(t)|,
E↑↓= |E ↑(t)⟩⟨E ↓(t)|, E↓↑= |E ↓(t)⟩⟨E ↑(t)|, and E↓↓= |E ↓(t)⟩⟨E ↓
(t)|, respectively, the four operators appearing in the expression for the density matrix
ρ = |Ψ (t)⟩⟨Ψ (t)|, we can write
ρ =

a |m ↑⟩⊗|E ↑(t)⟩+ b |m ↓⟩⊗|E ↓(t)⟩

×

a∗⟨m ↑| ⊗⟨E ↑(t)| + b∗⟨m ↓| ⊗⟨E ↓(t)|

=
|a|2|m ↑⟩⟨m ↑|E ↑↑+ab∗|m ↑⟩⟨m ↓|E ↑↓+
ba∗|m ↓⟩⟨m ↑|E ↓↑+|b|2 |m ↓⟩⟨m ↓|E ↓↓.
(5.128)
In order to compute the reduced density matrix, taking the trace over all E, we
will make use of the following:
Lemma 5.2 Suppose that lk denotes the two-dimensional space spanned by |k ↑⟩,
|k ↓⟩, and L E denotes the product space 
k ⊗lk. Given two vectors in L E, |v⟩=
|v1⟩⊗|v2⟩. . . ⊗|vN⟩, |w⟩= |w1⟩⊗|w2⟩. . . ⊗|wN⟩, where |vk⟩, |wk⟩belong to lk,
we consider the operator A = |v⟩⟨w|. It follows then that

190
5
Quantum Entanglement and Bell’s Theorem
TrE A =

k

⟨k ↑|v⟩⟨w|k ↑⟩+ ⟨k ↓|v⟩⟨w|k ↓⟩

=

k
⟨wk|vk⟩.
(5.129)
We will just prove the Lemma for N = 3, the generalization to arbitrary N being
straightforward. It is convenient to denote by |k, 1⟩, |k, 2⟩the vectors |k ↑⟩, |k ↓⟩,
for k = 1, 2, 3. A generic vector |vk⟩∈lk can be written as |vk⟩= vk,1|k, 1⟩+
vk,2|k, 2⟩. The same notation holds for |wk⟩= wk,1|k, 1⟩+wk,2|k, 2⟩. Denote by A the
operator |v⟩⟨w|; since for any |x⟩, A|x⟩= |v⟩⟨w|x⟩, the deﬁnition of Hermitian scalar
product implies that numerical coefﬁcients in the “functional” ⟨w| can be extracted,
remembering to take the complex conjugate as appropriate. Thus the operator |v⟩⟨w|
can be written as
A = |v⟩⟨w| =
2

i, j,p=1
2

l,m,n=1
v1,iv2, jv3,p (w1,l w2,m w3,n)∗|1, i⟩|2, j⟩|3, p⟩⟨1,l|⟨2, m|⟨3, n|.
(5.130)
Now substituting Eq. (5.130) into the following expression for the trace:
TrE A =
2

r=1
2

s=1
2

t=1
⟨1,r| ⊗⟨2, s| ⊗⟨3, t|A|1,r⟩⊗|2, s⟩⊗|3, t⟩,
(5.131)
results in the following scalar products:
⟨1,r|1, i⟩, ⟨2, s|2, j⟩, ⟨3, t|3, p⟩, ⟨1,l|1,r⟩, ⟨2, m|2, s⟩, ⟨3, n|3, t⟩.
(5.132)
Since the vectors |k1⟩, |k2⟩are orthogonal for any value of k, we have the equalities
i = r = l, j = s = m, p = t = n. Thus (5.131) becomes
TrE A =
2

i=1
v1iw∗
1i
2

j=1
v2 jw∗
2 j
2

p=1
v3pw∗
3p = ⟨w1|v1⟩⟨w2|v2⟩⟨w3|v3⟩,
(5.133)
and the lemma is proven.
In order to compute TrE E↑↓, let us specialize |w⟩= |v⟩= |E ↑(t)⟩, and
apply the lemma. Since ⟨wk|vk⟩= ⟨vk|vk⟩= |vk|2 = |αk|2 + |βk|2 = 1, we obtain
TrE E↑↑= N
k=1 1 = 1. In the same way it can be shown that TrE E↓↓= 1.
The analogous computation for the operator E↑↓= |E ↑(t)⟩⟨E ↓(t)| is more
interesting: the trace Trk over the two states |k ↑⟩, |k ↓⟩gives
Trk
 
αke−itgk
ℏ|k ↑⟩+ βke
itgk
ℏ|k ↓⟩
 
α∗
ke−itgk
ℏ⟨k ↑| + β∗
k e
itgk
ℏ⟨k ↓|
 
=
e−igkt/ℏαk e−igkt/ℏα∗
k + eigkt/ℏβk eigkt/ℏβ∗
k =
|αk|2 
cos 2gkt
ℏ
−i sin 2gkt
ℏ

+ |βk|2 
cos 2gkt
ℏ
+ i sin 2gkt
ℏ

=
cos 2gkt
ℏ
+ i

|βk|2 −|αk|2
sin 2gkt
ℏ. (5.134)

5.8 Measurement and Decoherence
191
Denoting by z(t) the trace of E↑↓over the whole environment, we have
z(t) =TrE |E ↑(t)⟩⟨E ↓(t)| = ⟨E ↓(t)|E ↑(t)⟩=
N

k

cos 2gkt
ℏ
+ i(|βk|2 −|αk|2) sin 2gkt
ℏ

=
N

k
fk.
(5.135)
Therefore, tracing over the whole environment, we obtain from (5.128) the reduced
density matrix:
ρR(t) = TrE ρ = |a|2|m ↑⟩⟨m ↑| + |b|2|m ↓⟩⟨m ↓|+
z(t) a b∗|m ↑⟩⟨m ↓| + z(t)∗a∗b |m ↓⟩⟨m ↑|.
(5.136)
We see that z(t) appears in the two non-diagonal matrix elements of ρR. The square
of the modulus of fk then works out to
| fk|2 =

cos 2gkt
ℏ
2
+

β2
k −α2
k
2 
sin 2gkt
ℏ
2
=

cos 2gkt
ℏ
2
+

β4
k + 2β2
k α2
k + α4
k
 
sin 2gkt
ℏ
2
−4β2
k α2
k

sin 2gkt
ℏ
2
.
(5.137)
But β4
k + 2β2
k α2
k + α4
k = (β2
k + α2
k)2 = 1. Therefore,
|z(t)|2 =
N

k=1

1 −4|αk|2|βk|2

sin 2gkt
ℏ
2
.
(5.138)
Setting |αk| = cos θk, |βk| = sin θk we see that
| fk|2 = 1 −sin2(2θk) sin2
2gkt
ℏ

< 1.
(5.139)
Thus it is not surprising that for large N, |z(t)|2, as a product of many factors less
than 1, becomes very small, and the reduced density matrix ρR becomes practically
diagonal. At the same time, from (5.135), we see that the states |E ↑(t)⟩and
|E ↓(t)⟩become practically orthogonal.
For a simple particular case, set s = sin θk, independent of k, and gk = g.
Then from (5.138), it is clear that the function |z(t)| becomes periodic, with period
T = h/2g:
|z(t)|2 =

1 −s2 sin2
2gt
ℏ
N
.
(5.140)

192
5
Quantum Entanglement and Bell’s Theorem
Supposing further that gt/ℏis very small, so that sin(2gt/ℏ) ≃2gt/ℏ, we can write
|z(t)|2 ≃

1 −4g2t2s2/ℏ2N .
(5.141)
For large N, we can approximate

1 −x
N
N
≃e−x,
(5.142)
where x
=
(4g2t2s2/ℏ2)N. Thus N
k=1 | fk|2
=
e−(4g2t2s2/ℏ2)N and z(t)
=
e−(2g2t2s2/ℏ2)N.ThewidthΔoftheGaussianisgivenbyΔ = ℏ/
√
2gs
√
N.Neglecting
√
2s, which is of the order of the unity, Δ ≃ℏ/g
√
N. If we choose g of the order of
the hyperﬁne transition energy of cesium-133, g ≃6×10−24 J, we have ℏ
2g ≃10−11
s. Thus in order to be able to use the approximation sin(2gkt/ℏ) ≃2 gt/ℏ, we must
limit ourselves to extremely short times, say, t << 10−11 s. Of course, if the model
simulates a macroscopic system, N can be taken to be large, of the order of Avo-
gadro’s number 6 × 1023. Then
√
N = 8 × 1011 and the width Δ ≃10−22 s is
indeed many orders of magnitude smaller than t << 10−11 s. Since z(t) is a periodic
function with period T = h/2g ≃6 × 1011s, z(t) can be pictured as a series of
very narrow Gaussians, with Δ very small, separated by time intervals of period T .
Therefore, the model predicts decoherence, since the off-diagonal matrix elements
of ρR are, in most cases, essentially vanishing. A slightly more realistic model is
obtained assuming that the environment is “disordered,” meaning that the coupling
constants are randomly distributed. But this does not change the conclusions.
Other models have been proposed. In the beautiful book by Omnes (1994), a
macroscopic oscillator (such as a pendulum) interacts with an environment of micro-
scopic oscillators (phonons). Omitting the details, we describe only the main result.
Let the macroscopic oscillator be initially in a superposition of two quantum states,
corresponding to positions x1, x2, with |x1 −x2| ≃1 micron. We assume also that
the pendulum’s mass m is 1g, and its period 1s, the damping time T due to friction is
very large, say, of the order of 1h. Then the frequency ω is 2π and the characteristic
decoherence time is of the order of
4ℏT

mω2
|x2 −x1|2

≃10−20 s,
(5.143)
which shows the extreme instability of a quantum superposition of the states of a
macroscopic object.
However, it is possible, albeit with some difﬁculty, to obtain superpositions of
macroscopic states, which are interesting objects of study and have possible technical
applications. There are two important examples of such superposition states, which
resemble one another, as they describe macroscopic objects made up of a huge
number of microscopic systems, all in the same quantum state. The ﬁrst example
is a Bose–Einstein condensate, in which the microscopic objects are atoms in their
ground state. In a Bose–Einstein condensate, the atoms lose their individuality, and

5.8 Measurement and Decoherence
193
the whole system can be described by an eikonal wavefunction √ρ eiα, with density ρ
and phase α. When two condensates have different phases, interference effects can be
observed. The second example is a Josephson junction, consisting of supercurrents,
separated by a thin barrier. The microscopic objects that constitute the supercurrents
are Cooper pairs of electrons. A Cooper pair consists two electrons, with their spins
coupled in a singlet state. If r1, σ1, r2, σ2 denote positions and spins of the two
electrons, the wave function of one pair is given by
Ψ (r1, σ1; r2, σ2) = eiθ 1
√
2

|1 ↑⟩|2 ↓⟩−|1 ↓⟩|2 ↑⟩

φ(|r1 −r2|),
(5.144)
where θ is a phase that is usually unobservable. In order to add a constant momentum
ℏk to the pair, multiply Eq. (5.144) by eiℏk·R, where R = r1+r2
2
is the center of mass
of the pair.
In 1962, Josephson predicted that if the overall phase of the state is θ1 on the right
of the junction, and θ2 on the left, a supercurrent can ﬂow through the junction by
tunneling of Cooper pairs. The supercurrent can be detected experimentally since it
induces a magnetic ﬁeld. An important technical application of the Josephson effect
is a device called a SQUID (superconducting quantum interference device) which
is sensitive enough to detect extremely weak magnetic ﬁelds, of magnitude 10−17
tesla or less; by comparison, the magnetic ﬁeld of the Earth ranges from 25 to 65
microtesla, and the magnetic ﬁeld produced by the human brain is of the order of
10−12 tesla.

Chapter 6
Digital and Quantum Computers
Abstract The fundamentals of digital and quantum computers are presented. Binary
numbers, modular arithmetic, and Boolean algebra are reviewed. Logic gates for both
classic and quantum computers are introduced and combined in some simple circuits
for carrying out useful computations. The possibility for efﬁcient factoring of large
numbers using quantum computers is discussed in detail. This requires a lengthy
detour into number theory. The most obvious application is to cryptography and
secure communication.
Keywords Binary number · Boolean algebra · Logic gates · Quantum computer ·
Modular arithmetic · Number theory · Cryptography · RSA
6.1
Binary Number System
Before dealing with quantum computers, we will review some basic features of con-
ventional digital computers. Computers are devices that can manipulate and transmit
bits of information. A bit (binary digit) is a unit of information that can assume just
two possible values, for example, an electrical signal that can have two different volt-
ages. We will indicate the two values by 1 and 0. The algebra that admits only bits as
variables is called a Boolean algebra, which we will discuss in the next section. The
ﬁrst and most simple example of application of binary digits consists of the binary
numbers, which only use the digits 1 and 0 (as opposed to decimal numbers, that use
the digits 0, 1, 2, 3, 4, 5, 6, 7, 8, 9). Let us show a few examples, limiting ourselves
to numbers with 4 digits. In the decimal number system,
a3a2a1a0 = a3103 + a2102 + a1101 + a0100.
(6.1)
For example, 2014 = 2 × 1000 + 0 × 100 + 1 × 10 + 4 × 1. We write this, for
brevity, as 201410. In the binary number system,
b3b2b1b0 = b323 + b222 + b121 + b020.
(6.2)
© Springer International Publishing AG 2017
G. Fano and S.M. Blinder, Twenty-First Century Quantum Mechanics:
Hilbert Space to Quantum Computers, UNITEXT for Physics,
DOI 10.1007/978-3-319-58732-5_6
195

196
6
Digital and Quantum Computers
Table 6.1 Binary numbers
Binary
Decimal
000
0
001
1
010
2
011
3
100
4
101
5
110
6
111
7
The binary number 1101 = 1 × 23 + 1 × 22 + 0 × 2 + 1 × 20 = 13. An n-digit
binary number bnbn−1 . . . b2b1b0 is equal to n−1
j=0 b j2 j. For example, the binary
numbers with three digits are listed in Table6.1. If you want, you can omit the zeros
to the left, and write simply 0, 1, 10, 11, 100, 101, 110, 111.
Bits are also called logical variables. The reason for this name is that simple
propositions can be true or false, so the digits 1 and 0 are sometimes referred to
as true or false. For example, the propositions “Rome is in Italy” or “5 is a prime
number” are true, the propositions “Paris is in Italy” and “10 is a prime number” are
false.
6.2
Boolean Algebra
As in the case of a real function of real variables, you can deﬁne a binary function
or operation from n bits to one bit; thus the value of a binary function is 1 or 0. The
simplest and most relevant cases are those with n = 1 or n = 2. If n = 1, the most
important operation is negation, denoted by NOT. The result of the negation of the
bit a is denoted by a. The truth table for NOT(a) = a is shown in Table6.2. For
n = 2, with a and b representing two logical variables, the basic operations are as
follows:
(1) The logical product AND of a and b, also called conjunction; it is denoted by
aANDb or a ∧b; when there are many logical operations to perform, we will write,
in simpliﬁed notation, ab. Its value is 1 only if both a and b are 1. The truth table is
Table6.3.
Table 6.2 NOT
a
a
1
0
0
1

6.2 Boolean Algebra
197
Table 6.3 AND
a
b
a ∧b
1
1
1
1
0
0
0
1
0
0
0
0
Table 6.4 OR
a
b
a ∨b
1
1
1
1
0
1
0
1
1
0
0
0
Table 6.5 XOR
a
b
a ⊕b
1
1
0
1
0
1
0
1
1
0
0
0
(2) The logical sum OR of a and b, also called disjunction; it is denoted by aORb or
a ∨b. Its value is 1 if at least one of the two bits a, b is equal to 1. The truth table of
OR is Table6.4.
The algebra of logical variables 1, 0 with the three operations AND, OR, NOT
and their associated truth tables, is called Boolean algebra. Besides the three basic
operations there are other operations that can be obtained by combinations. For
example, the operation XOR, called exclusive or, and denoted by a ⊕b, is shown
in Table6.5. From the truth table of XOR we see that in the last three cases a ⊕b
coincides with the usual arithmetic sum, while 1 ⊕1 = 0 in the ﬁrst case; now
recallingthatthenumber2iswritten10inbinarynotation,weseethata ⊕b coincides
with the last digit obtained by adding two bits. Other relevant operations are obtained
by applying the NOT operation (negation) to the operations AND, OR, XOR. In this
way, we obtain the operations NAND, NOR, XNOR, whose truth tables are shown
in Table6.6.
The logical product ∧and the logical sum ∨are similar, but not identical, to the
usual numerical sums and products; the basic laws that are the same for both logical
and numerical variables are as follows:
(1) a ∨b = b ∨a,
a ∧b = b ∧a (commutativity)
(2) a ∨(b ∨c) = (a ∨b) ∨c,
a ∧(b ∧c) = (a ∧b) ∧c (associativity)
(3) a ∧(b ∨c) = (a ∧b) ∨(a ∧c) (distributivity)
(4) a ∨0 = a (identity for the sum)
(5) a ∧1 = a (identity for the product)
(6) a ∧0 = 0 (annihilator for the product)

198
6
Digital and Quantum Computers
Table 6.6 Boolean truth tables
NAND
NOR
XNOR
a
b
a ∧b
1
1
0
1
0
1
0
1
1
0
0
1
a
b
a ∨b
1
1
0
1
0
0
1
1
0
0
0
1
a
b
a ⊕b
1
1
1
1
0
0
0
1
0
0
0
1
Laws that hold only for Boolean algebra are:
(7) a ∨a = a,
a ∧a = a (idempotence)
(8) a ∧(a ∨b) = a,
a ∨(a ∧b) = a (absorption)
(9) a ∨(b ∧c) = (a ∨b) ∧(a ∨c) (distributivity of ∨over ∧)
(10) a ∨1 = 1. Note, for example, that if a = 1, laws (7) and (10) are incorrect in
ordinary arithmetic, since 1 + 1 = 2. One must be careful in using the simpliﬁed
forms, since, for example, the seventh law becomes a + a = a and aa = a. Laws
(1) through (10) can be easily checked using the truth tables for ∨and ∧. Properties
of the negation that sends a to a are as follows:
(1) a ∧a = 0,
a ∨a = 1 (complementation)
(2) a = a (double negation)
(3) a ∧b = a ∨b,
a ∨b = a ∧b (De Morgan’s laws).
6.2.1
Venn Diagrams
There is another way to check the validity of the laws on logical variables, the method
of Venn diagrams; this approach appeals to our visual intuition, as well as to logic.
Given two subsets A, B of a set S, it is possible to deﬁne the union
A ∪B and
the intersection A ∩B. Furthermore, the set of points of S not belonging to A is
called the complement of A and denoted by ∁A. Let us show some examples: A
and B indicate two circles, included in the rectangle S; φ is the void (or empty)
set (see Fig.6.1). It is simple to verify that the algebra of sets is a Boolean algebra.
In fact there is a close correspondence between subsets of S (denoted by capital
letters A, B, C, X, Y, Z, . . .) and logical variables (denoted by a, b, c, x, y, z, . . .).
The interior of a set A corresponds to the value a = 1, the exterior to the value
a = 0. The three last rows of Table6.7 justify the correspondence of the sets S and
φ, respectively, with 1 and 0 (see Fig.6.1). In Fig.6.2, Venn diagrams corresponding
to XOR, NAND, etc., are shown. Venn diagrams can be drawn for any number of
regions. For example, drawing three circles A, B, C, we can visualize the distributive
law A ∩(B ∪C) = (A ∩B) ∪(A ∩C) (see Fig.6.3).

6.2 Boolean Algebra
199
Fig. 6.1 The shaded area of the rectangle represents the whole space S, the unshaded rectangle
represents the empty set φ
Table 6.7 Logical variables
Sets
Logical variables
A, B, C..
a, b, c..
A ∩B
a ∧b
A ∪B
a ∨b
∁A
a
S
1
φ
0
A ∩∁A = φ
a ∧a = 0
Consider again three circles (see Fig.6.4) included in a rectangle. Given the one-
to-one correspondence between regions and logical variables, we can associate three
variables a, b, c with the three circles; then the rectangle is partitioned into 23 = 8
regions, andwecanassociatewitheachregionalogical product inwhichthevariables
a, b, c appear once either in the complemented or uncomplemented form.
The 8 products of all 3 variables, in direct or complemented form, are called
minterms. For example, a ∧b ∧c, a ∧b ∧c, …(or in simpliﬁed notation a b c,
a b c, …). Any logical function f of a, b, c can be written as a sum of subsets of
minterms. For example,
b ∧c = (a ∧b ∧c) ∨(a ∧b ∧c).
(6.3)
In the general case of n variables a1, a2, . . . , an, the number of minterms is 2n.
The corresponding 23 logical sums a ∨b ∨c, a ∨b ∨c, . . ., are called maxterms. A

200
6
Digital and Quantum Computers
Fig. 6.2 Venn diagrams corresponding to XOR, NAND, NOR, and XNOR
Fig. 6.3 The darker area is
the region A ∩B ∩C
maxterm is obtained from a minterm by replacing the symbol ∧with ∨. Some logical
functions are simpler using minterms, while others are simpler using maxterms. A
minterm is equal to 1 on exactly one row of the truth table, while a maxterm is equal
to 0 on exactly one row.

6.3 Classical Computers
201
Fig. 6.4 Sets (and bits) are
denoted by simpliﬁed
notation. For example
a b c = a ∧b ∧c, etc.
6.3
Classical Computers
6.3.1
Logic Gates
A logic gate is a physical device implementing a Boolean logical operation. On
a circuit diagram the elementary gates corresponding to the operations AND, OR,
NAND, etc., have two incoming wires and one outgoing wire; for example, the higher
voltage of a wire corresponds to 1, while the lower voltage corresponds to 0. Denoting
by x, y the two input variables, commonly used symbols are shown in Fig.6.5. The
symbol corresponding to the negation has one input and one output wire, as shown
in Fig.6.6. We note that the function x ⊕y can be obtained by means of the circuit
shown in Fig.6.7. Of course, the same logical function can be realized with different
circuits. The skill of the computer engineer consists in creating the optimal designs.
We have already noted that the logical operation x ⊕y appears in the arithmetic
sum of two bits; however, in executing such a sum, there is a second operation that
we have to perform, namely the carry. For example, suppose you want to add the
binary numbers 101 and 111 (510 and 710):
1 0 1
1 1 1
1 1 0 0
Let us denote by S the arithmetic sum x ⊕y of two bits x, y, and by C the carry.
Since the value of the carry is 1 if x = y = 1, and it is 0 otherwise, it coincides with
the logical product x ∧y. Therefore,

202
6
Digital and Quantum Computers
Fig. 6.5 Logic gates with two inputs and one output
Fig. 6.6 Symbol of the negation gate
Fig. 6.7 A circuit implementing the x ⊕y operation
S = x ⊕y,
C = x ∧y.
(6.4)
Let us examine the above sum of 101 and 111: adding the ﬁrst digits 1+1 from the
right, we get S = 0 and carryover C = 1; for the second digits we must add three
numbers 0, 1, and the carry C = 1. Finally, we do the sum 1+1+1 and get 11.
How can we devise a digital circuit capable of performing these operations? Two
simplecircuitsareemployed:thehalf-adderandthefull-adder.Ahalf-adder(denoted
by the symbol HA) is a digital circuit with two input bits x, y and two outputs S, C.
It can be implemented as shown in Fig.6.8. We have seen in the previous example,
5 + 7 in binary digits, that it is necessary to sum three bits x, y, z. The circuit that

6.3 Classical Computers
203
Fig. 6.8 Half-adder
Table 6.8 Full-adder
x
y
z
S10
S2
S
C
0
0
0
0
0
0
0
0
0
1
1
1
1
0
0
1
0
1
1
1
0
0
1
1
2
10
0
1
1
0
0
1
1
1
0
1
0
1
2
10
0
1
1
1
0
2
10
0
1
1
1
1
3
11
1
1
performs this operation is called a full-adder (denoted by the symbol FA). Usually x
and y denote two bits to be added, and z is the carry from a previous sum. In the truth
Table6.8, S10 and S2 are the arithmetic sums written in decimal and binary form,
respectively; S is the last signiﬁcant bit of x + y + z and C denotes the new carry.
Unlike the half-adder, the full-adder has three inputs x, y, z and two outputs S, C.
Let us use the simpliﬁed notation (x ∧y becomes simply xy, and x ∨y becomes
x + y).Thefunction x ⊕y is x y + x y.Sisthearithmeticsum(x ⊕y) ⊕z.However,
it would be incorrect to write S = x ∨y ∨z = x + y + z. Rather, we have
S = z ⊕(x ⊕y) = z(x y + x y) + z(x y + x y) = z(x + y)(x + y) + zx y + z x y,
(6.5)
where we have used the De Morgan law ab = a + b. Since xx = yy = 0, we have
S = zx y + zyx + zx y + zx y = xyz + x yz + x yz + x yz.
(6.6)
We see that S is the sum of four minterms, corresponding to the values 111, 100,
010, and 001 of the full-adder table. Clearly, the four minterms vanish for several
triples. This suggests writing the minterms directly corresponding to the carry C.

204
6
Digital and Quantum Computers
From Table6.8, we see that the triples corresponding to C = 1 are 011, 101, 110,
and 111. Thus we have
C = x yz + x yz + xyz + xyz.
(6.7)
Using the identity a + a = a with a = xyz:
C = x yz + x yz + xyz + xyz + xyz + xyz =
(x + x)yz + x(y + y)z + xy(z + z) = yz + xz + xy.
(6.8)
The Venn diagrams shown in Fig.6.9 can help to understand the meaning of formulas
(6.5) and (6.6). Next, we construct a digital circuit with three input digits x, y, z and
two outputs S, C (see (6.4) and (6.6)). A possible realization is shown in Fig.6.10. A
circuit which can perform the sum of two binary numbers, each of four digits, such
as
a3 a2 a1 a0
b3 b2 b1 b0
C4 S3 S2 S1 S0
can be easily constructed using FA gates. We can imagine a hypothetical carry C0 = 0
entering in the circuit before adding the digits a0, b0. Then a digital circuit with four
full-adders, shown in Fig.6.12, carries out the sum.
Fig. 6.9 The dashed area
corresponds to the carry
C = xy + xz + yz

6.3 Classical Computers
205
Fig. 6.10 Full-adder
Fig. 6.11 The inputs x, y of a full-adder can enter from different sides
Fig. 6.12 A circuit implementing a 4-digit adder
6.3.2
Binary Multiplication
AND, half-adder, and full-adder logic gates can be easily connected to build a binary
multiplier. As an example, consider the simple multiplication 6 × 6 = 36. Using
binary numbers, the computation is the following:

206
6
Digital and Quantum Computers
1 1 0
1 1 0
0 0 0
1 1 0
1 1 0
1 0 0 1 0 0
In the general case of two 3-bit integers, we can write, using the simpliﬁed notation,
a2 a1 a0
b2 b1 b0
a2b0 a1b0 a0b0
a2b1 a1b1 a0b1
a2b2 a1b2 a0b2
S5 S4 S3 S2 S1 S0
All the products a0b0, a1b0, . . . , contain AND operations. The products of the second
and third row are shifted to the left as in ordinary decimal multiplication. The ﬁnal
result is obtained by taking the sum of the elements of a column, using half-adder and
full-adder logic gates. A possible realization of the circuit is shown in Fig.6.13. Let
us do a simple check, taking the square of the binary number 111 (710); our circuit
must perform the binary multiplication:
1 1 1
1 1 1
1 1 1
1 1 1
1 1 1
1 1 0 0 0 1
Fig. 6.13 A circuit implementing a 3-digit multiplier

6.3 Classical Computers
207
All the products aib j (i, j = 1, 2, 3) are equal to 1; also the carries C1, C2, . . . , C6
are equal to 1. Let us see how this happens: all gates HA of Fig.6.13 have two outputs:
a sum 0 and a carry 1. Therefore, C1 = C2 = C3 = 1. Furthermore, S0 = a0b0 = 1
and S1 = 0. Now consider the ﬁrst FA from the right: it has three inputs, C1 = 1,
a2b0 = 1, and a bit 0 coming from the second HA; the two outputs are the sum
S2 = 0 and the carry C4 = 1. The second FA has three input, C2 = C4 = 1 and a
bit 0 coming from the third HA; the two outputs are the sum S3 = 0 and the carry
C5 = 1. Finally, the inputs of the last FA are C3 = C5 = a2b2 = 1 and the outputs
are S4 = 1 and C6 = S5 = 1. Thus the result 110001 (4910) is obtained.
6.3.3
A Living Computer
An interesting educational experiment can be performed in a school classroom to
illustrate how a computer works. We build a “living computer” with children as logic
gates: if a child raises his arm, this corresponds to the bit 1; if he keeps his arm
lowered, this corresponds to the bit 0. For example, in order to simulate the circuit of
Fig.6.12, we need 4 children to indicate the number a3 a2 a1 a0, and 4 other children
for the number b3 b2 b1 b0. Then we teach other children to build logic gates, as
follows: to simulate an AND gate, a child is to look at two companions, say Dick
and Jane, and raise one arm only if both Dick and Jane both raise one arm. Similarly
to simulate a XOR gate, another child must watch two other companions, and raise
his arm if only one of them raises his arm, and so on. Thereby a full-adder can be
simulated with 5 children. Adding the ﬁrst child to represent the bit C0 = 0, we see
that a school class of 29 children is sufﬁcient to simulate the circuit of Fig.6.12.1
In this section, we have given a simpliﬁed description of the basic operations of
a classical digital computer; the next step would be a discussion of memory cells,
CPUs, etc., but we stop here. We turn, instead, to consider the fundamental principles
of quantum computation.
6.4
Quantum Computation
Digital computers, as we have seen, are based on the established principles of clas-
sical logic (although the contributions of quantum theory, such as transistors, have
been indispensable). Since about 1980, a new paradigm of computation, based more
directly on quantum physics, has been proposed (Feynman 1985), potentially with
exponentially greater power than classical computers.
1GF has personally done this educational experiment; an interesting result was that after the children
had understood what they had to do, the information could run very fast through the “computer”
and the correct result was rapidly obtained.

208
6
Digital and Quantum Computers
The structure of quantum computation is based on a very simple concept: the
replacementoftheelementaryunitofinformation,thebit,withthequbit,amuchmore
complex object which, in principle, can contain an enormous amount of information.
The qubit can, however, be fairly simply deﬁned as follows:
Deﬁnition 6.1 A qubit is a normalized quantum state vector belonging to a complex
two-dimensional Hilbert space.
Thus, from a mathematical point of view, a qubit is simply an element of C2 of norm
1. Choosing the C2 basis vectors,
|0⟩=

1
0
 ,
|1⟩=

0
1

(6.9)
a generic element of C2 can be written as a complex linear combination of two
classical states:
|Ψ ⟩= α|0⟩+ β|1⟩,
(6.10)
where α and β are complex numbers. But a qubit should be regarded as an entirely
different type of linear combination, which does not correspond to any well-deﬁned
classical entity. The norm |Ψ | is assumed equal to 1; therefore, α, β must obey the
normalization condition:
|α|2 + |β|2 = 1.
(6.11)
Note, incidentally, that by setting α = a1 + ia2, β = b1 + ib2 (where a1, a2, b1, b2
are real numbers), Eq.(6.11) becomes a2
1 + a2
2 + b2
1 + b2
2 = 1, which represents a
3-sphere in R4. In Eq.(4.55), we found a parametrization, in terms of two angles, for
a two-state quantum system. This also applies nicely to an arbitrary qubit:
|Ψ ⟩= cos θ
2|0⟩+ sin θ
2 eiφ|1⟩.
(6.12)
The Bloch sphere, shown in Fig.6.14, provides a useful geometrical representation of
a qubit. In contrast to the Riemann sphere (used in our stereographic projection from
the complex plane), antipodal points represent orthogonal states, rather than just
negatives of the state vector. On the Bloch sphere, |0⟩is mapped onto the north pole
(θ = 0) and |1⟩onto the south pole (θ = π). The equator, with θ = π/2, contains
four additional cardinal points, with φ = 0, π/2, π, 3π/2, corresponding to

|0⟩+
|1⟩

/
√
2,

|0⟩+ i|1⟩

/
√
2,

|0⟩−|1⟩

/
√
2,

|0⟩−i|1⟩

/
√
2, respectively. There
is a one-to-one correspondence between qubit states and points on the Bloch sphere.
Different physical systems can serve as realizations of a qubit: |0⟩and |1⟩can
represent the two polarization states of a photon, the different alignments of an
electron or nuclear spin, or even two atomic orbitals. Since θ and φ are real numbers,
over a continuous range, a qubit can contain a vast amount of information. Quoting
Nielsen and Chuang (Nielson and Chuang 2000, p. 15), “Paradoxically, there are an
inﬁnite number of points on the unit sphere, so that, in principle, one could store

6.4 Quantum Computation
209
Fig. 6.14 Bloch sphere. The qubit |Ψ ⟩and the six cardinal points are marked with red dots
an entire text of Shakespeare in the inﬁnite binary expansion of θ.” However, a
measurement of the qubit Eq.(6.12) will give only one of two possible results. For
example, if we make a measurement on the system represented by the matrix
Z =


1 0
0 −1

 ,
(6.13)
the possible results are ±1, so that the measurement collapses the qubit to |0⟩or |1⟩.
We next consider the case of multiple qubits. The Hilbert space C2n of n qubits
is the tensor product of n copies of C2, namely, C2 ⊗C2, . . . , ⊗C2, n times. A
useful basis in C2n is the computational basis, with |0⟩=

1
0
 , |1⟩=

0
1
 , an
orthonormal basis in each space C2. The computational basis is provided by the 2n
product states:
|i1, i2, . . . , in⟩= |i1⟩⊗|i2⟩⊗· · · ⊗|in⟩,
(6.14)
where (i1, i2, . . . , in) is a binary number with n bits. For example, in the space
C2 ⊗C2, the four basis vectors are
|0 0⟩= |0⟩⊗|0⟩,
|0 1⟩= |0⟩⊗|1⟩,
|1 0⟩= |1⟩⊗|0⟩,
|1 1⟩= |1⟩⊗|1⟩.
(6.15)

210
6
Digital and Quantum Computers
Using the notation,

α1
α2
 ⊗

β1
β2

=

α1β1
α1β2
α2β1
α2β2

,
(6.16)
we have
|0 0⟩=

1
0
0
0

,
|0 1⟩=

0
1
0
0

,
|1 0⟩=

0
0
1
0

,
|1 1⟩=

0
0
0
1

.
(6.17)
6.4.1
Quantum Gates
Once we have replaced bits with qubits, we can ask can we now construct quantum
gates, analogs of logic gates for qubits? Let us consider the case of a single qubit; we
are immediately aware of a major difference compared to digital computing: while
there is only one single-bit logic gate, namely, the NOT gate, multiple single-qubit
quantum gates are possible. A single-qubit quantum gate transforms the qubit

α
β

into the qubit

α′
β′
. To satisfy Eq.(6.11), we must have
|α′|2 + |β′|2 = |α|2 + |β|2 = 1,
(6.18)
so that the norm of the state

α
β
 is invariant. Since we want to preserve linearity,
there is only one class of operators that can serve as quantum gates, namely unitary
operators (see Eq.2.121). We recall that unitary operators U are a generalization of
orthogonal operators for rotations, with complex matrix elements. They leave the
norm invariant, so that |UΨ | = |Ψ | ∀Ψ .
The path of each qubit in a quantum computer circuit is represented by a sin-
gle horizontal line —— which usually connects a sequence of gates. The qubit is
understood to move along the “quantum wire” from left to right. A wire carrying a
classical bit, 0 or 1, usually after a measurement, is indicated by a double line ====.
In Table6.9, matrices representing some examples of single-qubit quantum gates
are shown; these examples are relevant in the design of quantum circuits. Some
comments are in order:
(1) The Hadamard gate H maps the qubits |0⟩=

1
0
, |1⟩=

0
1
, respectively,
to the superposition states:

6.4 Quantum Computation
211
Table 6.9 Single-qubit quantum gates
Name
Symbol
Matrix
Hadamard
1
√
2


1 1
1 −1


Pauli X


0 1
1 0


Pauli Z


1 0
0 −1


π
2 -phase


1 0
0 i


π
4 -phase


1
0
0 eiπ/4


Measurement
H|0⟩=
1
√
2

|0⟩+ |1⟩

=
1
√
2

1
1
 ,
H|1⟩=
1
√
2

|0⟩−|1⟩

=
1
√
2

1
−1
 .
(6.19)
Needless to say, this is something entirely different from the classical case, since the
“bits” 0 and 1 are being mixed. The two superpositions in Eq.(6.19) can be deﬁned
as an alternative pair of basis functions (sometimes called the Hadamard basis):
|+⟩=
1
√
2

|0⟩+ |1⟩

and |−⟩=
1
√
2

|0⟩−|1⟩

.
(6.20)
(2) The quantum gate X maps the qubit

α
β
 to

β
α
. Since X2 = 1, X is some-
what analogous, but not identical, to the classical NOT gate.
(3) The quantum gates T, S, Z change only the phase of β. The variation of the
phase is π/4 for T, since eiπ/4 =
1
√
2(1 + i), π/2 for S, since eiπ/2 = i and π for Z,
since eiπ = −1. Thus
T2 = S,
S2 = Z,
Z2 = I.
(6.21)

212
6
Digital and Quantum Computers
Table 6.10 CNOT
Input
Output
|00⟩
|00⟩
|01⟩
|01⟩
|10⟩
|11⟩
|11⟩
|10⟩
Given their resemblance to Pauli spin matrices, X and Z are called Pauli gates.
Next we consider some two-qubit gates. Two qubits gates operate in the C2 ⊗C2
space. Thus they can be represented by 4 × 4 unitary matrices. Since the inverse of
the unitary matrix U is the matrix U †, quantum gates are reversible, in contrast to
classical logic gates. For a quantum gate, the input can be deduced from the output.
But for a classical XOR gate a ⊕b, for the output 1, we do not know whether the input
was |10⟩or |01⟩. The output does not identify the input. Some essential two-qubit
gates are the following:
(1) The CNOT (controlled-NOT) gate. We denote the two input qubits by a, b. The
ﬁrst qubit a is called the control qubit, the second b the target qubit. This target qubit
ﬂips if and only if a = 1. If a = 0 the second qubit remains unchanged. Table6.10 is
the truth table for CNOT: In a circuit, the CNOT gate is denoted by the symbol shown
in Fig.6.15. This symbol is easy to remember since for classical bits the sum a ⊕b
is the negation of b only if a = 1. The unitary matrix corresponding to the CNOT
gate has the following representation in the computational basis (see Eq.(6.14)):
U =


1 0 0 0
0 1 0 0
0 0 0 1
0 0 1 0


.
(6.22)
In fact, U leaves the states |00⟩, |01⟩invariant, but swaps the states |10⟩and |11⟩. If
we exchange the control and target qubits, we obtain the circuit shown in Fig.6.16.
The corresponding matrix is
U ′ =


0 1 0 0
1 0 0 0
0 0 1 0
0 0 0 1


(6.23)
where now the states left invariant by U ′ are |10⟩and |11⟩.
Quitegenerally,controlledgatesacton2qubits,withthecontrolqubitdetermining
some operation on the target qubit. If the single-qubit gate V is represented by the
2 × 2 matrix:
V =


V11 V12
V21 V22

 ,
(6.24)

6.4 Quantum Computation
213
Fig. 6.15 CNOT gate. The
black dot represents the
control qubit
Fig. 6.16 The CNOT gate
with lower control qubit
Fig. 6.17 The gate V is
applied only to |b⟩, with |a⟩
left unchanged
the symbol of the controlled-V gate is shown in Fig.6.17. The corresponding matrix
is
U =


1 0 0
0
0 1 0
0
0 0 V11 V12
0 0 V21 V22


.
(6.25)
Since
U|00⟩= |00⟩, U|01⟩= |01⟩, U|10⟩= |1⟩⊗V |0⟩, U|11⟩= |1⟩⊗V |1⟩,
(6.26)
we see that V is applied to |b⟩only if |a⟩= |1⟩. The controlled-V gate should not be
confused with the gate shownin Fig.6.19, which is represented by the matrix I ⊗V .

214
6
Digital and Quantum Computers
Fig. 6.18 The controlled-V
gate with lower control qubit
Fig. 6.19 Circuit
representing the matrix
I ⊗V
Exchanging the control and target qubits we obtain the inverted controlled gate in
Fig.6.18, which is represented by the matrix:
U ′ =


1 0 0 0
0 V11 0 V12
0 0 1 0
0 V21 0 V22


.
(6.27)
(2) Using the rules described above, one can write the matrices UT, US, UZ cor-
responding, respectively, to the gates controlled-T, controlled-S, and controlled-Z,
shown in Figs.6.20, 6.21 and 6.22, as follows:
UT =


1 0 0
0
0 1 0
0
0 0 1
0
0 0 0 eiπ/4


,
US =


1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 i


,
UZ =


1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 −1


.
(6.28)
Fig. 6.20 Controlled-T gate

6.4 Quantum Computation
215
Fig. 6.21 Controlled-S gate
Fig. 6.22 Controlled-Z gate
Fig. 6.23 The swap gate
(3) The swap gate: this quantum gate swaps the states of the two input qubits, as
shown in Fig.6.23 and Eq.(6.29).
U =


1 0 0 0
0 0 1 0
0 1 0 0
0 0 0 1


.
(6.29)
It is easy to verify the equivalence of the swap gate with the sequence of CNOT
operationsshowninFig.6.24;infact,ifa andb denoteclassicalbits,a ⊕(a ⊕b) = b
and b ⊕(a ⊕b) = a. The same result follows from matrix multiplication:


1 0 0 0
0 1 0 0
0 0 0 1
0 0 1 0


×


1 0 0 0
0 0 0 1
0 0 1 0
0 1 0 0


×


1 0 0 0
0 1 0 0
0 0 0 1
0 0 1 0


=


1 0 0 0
0 0 1 0
0 1 0 0
0 0 0 1


.
(6.30)

216
6
Digital and Quantum Computers
Fig. 6.24 The swap gate is equivalent to a sequence of CNOT operations
6.5
Deutsch’s Algorithm
To explore the potentially greater computational power of a quantum computer, as
compared to a classical computer, David Deutsch2 proposed a highly contrived but
simple algorithm. Consider four possible functions of a single-bit (or basis qubit),
x = 0 or 1, which produce a single-bit result y = 0 or 1, as follows: f1(x) = 0,
f2(x) = 1, f3(x) = x, f4(x) = x. The ﬁrst two functions are classiﬁed as “constant”
(with f (0) = f (1)), while the last two are described as “balanced” (with f (0) ̸=
f (1)). Suppose now that a classical computer, idealized as a “black box”, can perform
the computation
x →
f
→y.
(6.31)
If it is desired to identify the function as one of f1, f2, f3, f4, it is necessary to run
the classical program twice, with inputs x = 0 and x = 1.3
The key element of the circuit for running Deutsch’s algorithm is the Cf gate, a
modiﬁcation of the CNOT gate (Fig.6.15) in which the target qubit |y⟩is output as
|y ⊕f (x)⟩(rather than |y ⊕x⟩for the standard CNOT). This is shown in Fig.6.25.
Fig. 6.25 Deutsch Cf gate. For inputs |00⟩, |01⟩, |10⟩, |11⟩, the outputs are |0 f (0)⟩, |0 f (0)⟩,
|1 f (1)⟩, |1 f (1)⟩, respectively
2Deutsch D (1985) Quantum Theory, the Church-Turing Principle and the Universal Quantum
Computer, Proceedings of the Royal Society of London A 400: 97–117.
3For example, with the input x = 0, suppose we ﬁnd f (x) = 1. Then f can be either f2 or f4. We
need a second run with x = 1 to determine which alternative is correct.

6.5 Deutsch’s Algorithm
217
Fig. 6.26 Circuit for Deutsch’s algorithm.The reading 0 or 1 identiﬁes f (x) as constant or balanced,
respectively
The black box for evaluating the function f (x) is assumed to be a component part of
the circuit for this gate. Figure6.26 shows the circuit for Deutsch’s algorithm. The
input 2-qubit state is ψ0 = |0⟩⊗|1⟩= |01⟩. After the action of the two Hadamard
gates, this becomes
ψ1 = 1
2

|00⟩−|01⟩+ |10⟩−|11⟩

.
(6.32)
After the Deutsch Cf gate,
ψ2 = 1
2

| 0 f (0)⟩−|0 f (0)⟩+ |1 f (1)⟩−|1 f (1)⟩

=
1
2

|0⟩⊗

| f (0)⟩−| f (0)⟩

+ |1⟩⊗

| f (1)⟩−| f (1)⟩

.
(6.33)
We now consider the two possible cases. If f (x) is constant, f (0) = f (1). But
if f (x) is balanced, f (0) ̸= f (1); since f is a binary function, this implies that
f (0) = f (1) and f (1) = f (0). The two cases for ψ2 can be simpliﬁed to
ψconst
2
=
1
√
2

|0⟩+ |1⟩

⊗1
√
2

| f (0)⟩−| f (0)⟩

ψbal
2
=
1
√
2

|0⟩−|1⟩

⊗1
√
2

| f (0)⟩−| f (1)⟩

.
(6.34)
Next, the Hadamard gate applied to the ﬁrst qubit gives
H 1
√
2

|0⟩+ |1⟩

= |0⟩
or
H 1
√
2

|0⟩−|1⟩

= |1⟩.
(6.35)
Finally, a measurement on the ﬁrst qubit, giving 0 or 1, identiﬁes f (x) as constant
or balanced, respectively. The second qubit is ignored. Thus, we have shown that
using Deutsch’s algorithm on a quantum computer, it is possible to identify f as
constant or balanced in just a single run. This might not appear very impressive, but it

218
6
Digital and Quantum Computers
represents a proof of principle, suggesting that a classical computation of complexity,
say O(N), might be accomplished by a quantum computation of complexity O(
√
N)
or O(log N). This becomes highly signiﬁcant for N of the order of thousands or
millions.
6.6
Bell States
The superpositions |Φ±⟩=
1
√
2

|00⟩± |11⟩

and |Ψ ±⟩=
1
√
2

|01⟩± |10⟩

are called
Bell (or EPR) states (see Eq.5.13). These maximally entangled 2-qubit states form
an orthonormal basis for C4. Bell states can be produced by the circuit shown in
Fig.6.27. The corresponding operator matrix can be obtained applying ﬁrst H ⊗I,
and then the matrix Eq.(6.22) representing the action of the CNOT gate:
1
√
2


1 0 0 0
0 1 0 0
0 0 0 1
0 0 1 0


×


1 0 1
0
0 1 0
1
1 0 −1 0
0 1 0 −1


=
1
√
2


1 0 1
0
0 1 0
1
0 1 0 −1
1 0 −1 0


.
(6.36)
Recall that products of matrices are evaluated in the order right to left. Thus,
in the product XY of two matrices representing quantum gates, Y operates ﬁrst.
Applying the operator (6.36) to the computational basis produces one of the Bell
states. Speciﬁcally, the inputs |00⟩, |10⟩, |01⟩, |11⟩produce the Bell states |Φ+⟩,
|Φ−⟩, |Ψ +⟩, |Ψ −⟩, respectively.
Fig. 6.27 Circuit producing
Bell states
Fig. 6.28 Circuit to detangle
a Bell state

6.6 Bell States
219
The 2-qubit circuit shown in Fig.6.28 essentially reverses the creation of a Bell
state. The corresponding operator can be obtained by ﬁrst applying the matrix (6.22),
representing the gate CNOT, and then H ⊗I. The result is as follows:
1
√
2


1 0 1
0
0 1 0
1
1 0 −1 0
0 1 0 −1


×


1 0 0 0
0 1 0 0
0 0 0 1
0 0 1 0


=
1
√
2


1 0 0
1
0 1 1
0
1 0 0 −1
0 1 −1 0


.
(6.37)
You can thereby show that input of a Bell state |Φ+⟩, |Ψ +⟩, |Φ−⟩, |Ψ −⟩produces
the output |00⟩, |01⟩, |10⟩, |11⟩, respectively. The Bell state has thus become “detan-
gled.”
Suppose Alice and Bob share a known Bell state, each possessing one qubit. It
is now possible for Alice to transmit two classical bits to Bob by sending him just
a single qubit. This is known as superdense coding. As shown in Fig.6.29, the Bell
state |Φ+⟩is ﬁrst created, beginning with the input |00⟩, using the partial circuit
of Fig.6.27. One qubit is sent to Alice and the other to Bob. Alice then moves her
qubit through one of four gates, I, X, Z, or XZ, enclosed by the rectangular box,
and transmits the result to Bob. Including the qubit originally sent to him, Bob is
now in possession of both qubits of one of the four Bell states |Φ+⟩, |Ψ +⟩, |Φ−⟩, or
|Ψ −⟩. After using the partial circuit in Fig.6.28, Bob’s two measurements results in
one of the disentangled states |00⟩, |01⟩, |10⟩or |11⟩, respectively. Each of these is
equivalent to two classical bits. The central steps in the superdense coding procedure
have made use of the following transformations:
I|Φ+⟩= |Φ+⟩,
X|Φ+⟩= X 1
√
2

|00⟩+ |11⟩

=
1
√
2

|10⟩+ |01⟩

= |Ψ +⟩,
Z|Φ+⟩= Z 1
√
2

|00⟩+ |11⟩

=
1
√
2

|00⟩−|11⟩

= |Φ−⟩,
X Z|Φ+⟩= X Z 1
√
2

|00⟩+ |11⟩

=
1
√
2

|10⟩−|01⟩

= |Ψ −⟩.
(6.38)
Fig. 6.29 Superdense coding

220
6
Digital and Quantum Computers
6.7
Quantum Teleportation
It is now possible to construct a circuit able to teleport the information contained in a
quantum qubit, even over great distances.4 However this must be accompanied by the
conventional transmission of two classical bits. Suppose now that Alice wants to send
Bob some wonderful special qubit, represented by the superposition |Ψ ⟩=

α
β
.
To accomplish this teleportation, Alice and Bob must again be simultaneously in
possession of an entangled pair in one of the Bell states, with each holding (but not
measuring) one spin. The procedure involves manipulation of three spins. Initially,
spin 1 is Alice’s |Ψ ⟩. From the Bell pair, Alice holds spin 2, while Bob holds spin
3: we denote these as |BELL⟩A and |BELL⟩B, respectively. After the teleportation
is complete, spin 3 will be in the state |Ψ ⟩. We still will not know the value of the
coefﬁcients α and β, but the state of spin 1, which was in initially in Alice’s lab will
have been transferred to spin 3, which is in Bob’s lab. A circuit that can perform this
teleportation is shown in Fig.6.30.
The initial state of the composite quantum system can be represented by
|Ψ0⟩= |Ψ ⟩⊗|BELL⟩.
(6.39)
The two top lines in Fig.6.30 pertain to Alice, while the bottom line pertains to Bob.
The input qubit of the upper line is |Ψ ⟩, and we use the Bell state
|BELL⟩=
1
√
2

|00⟩+ |11⟩

,
(6.40)
which is the input to the two bottom lines. Denoting by |i jk⟩(i, j, k = 0, 1), the
tensor product |i⟩⊗| j⟩⊗|k⟩, where |i⟩, | j⟩, |k⟩are basis qubits corresponding to
the top, middle and bottom lines, respectively, we have
Fig. 6.30 Circuit implementing teleportation
4Bennett CH, Brassard G, Crépeau C, Jozsa R, Peres A, Wootters WK (1993) Teleporting an
Unknown Quantum State via Dual Classical and Einstein-Podolsky-Rosen Channels. Phys Rev
Lett 70:1895–1899.

6.7 Quantum Teleportation
221
|Ψ0⟩=

α|0⟩+ β|1⟩

⊗
1
√
2

|00⟩+ |11⟩

=
1
√
2

α|000⟩+ α|011⟩+ β|100⟩+ β|111⟩

=
1
√
2

α|00⟩+ β|10⟩

⊗|0⟩+
1
√
2

α|01⟩+ β|11⟩

⊗|1⟩=
1
√
2

α
0
β
0

⊗|0⟩+
1
√
2

0
α
0
β

⊗|1⟩,
(6.41)
where the four components vectors refer to Alice’s qubits. Alice then successively
applies the CNOT gate, followed by the transformation H ⊗I, on the ﬁrst two qubits.
This is represented by the matrix (6.37), which operates on |Ψ0⟩. Since the third qubit
remains unaltered, we obtain the following state:
1
2

α
β
α
−β

⊗|0⟩+ 1
2

β
α
−β
α

⊗|1⟩=
1
2

α|000⟩+ β|010⟩+ α|100⟩−β|110⟩+ β|001⟩+ α|011⟩−β|101⟩+ α|111⟩

=
1
2
	
|00⟩⊗

α
β
 + |01⟩⊗

β
α
 + |10⟩⊗

α
−β
 + |11⟩⊗

−β
α


.
(6.42)
After Alice performs measurements on her two qubits, the global wave function
collapses into one of four unentangled states, |00⟩, |01⟩, |10⟩or |11⟩, each with a
probability 1
4. She then sends the result to Bob, by email, telephone, etc. If the
message is |00⟩, Bob knows that his qubit is the desired result

α
β
. If the message
is |01⟩, his qubit is

β
α
, but he can then apply the Pauli gate X, to recover

α
β
.
Analogously, if the message is |10⟩, Bob applies the gate Z; if the message is |11⟩,
Bob applies Z X =

0 1
−1 0
. The end result is that the qubit |Ψ ⟩, which initially
belonged to Alice, now belongs to Bob. The qubit has been teleported.
Since the collapse of the wavefunction occurs instantaneously, you may wonder
if the quantum information contained in the qubit has, in fact, traveled at inﬁnite
speed; but the answer is no, because Alice also had to send Bob two bits by a
classical channel, possibly electromagnetic signals, which cannot travel faster than
light.
Note also that once Alice’s qubit has been teleported, it has been destroyed. She
has not been able to keep a “carbon copy.” This is a consequence of the no-cloning
theorem. Suppose there exists a magical linear unitary operator C which can copy
Alice’s special qubit |Ψ ⟩= α|0⟩+ β|1⟩onto a “scratch” qubit, which we designate
as | ⟩. This would involve the following hypothetical operation:

222
6
Digital and Quantum Computers
C(α|0⟩+ β|1⟩) ⊗| ⟩= (α|0⟩+ β|1⟩) ⊗(α|0⟩+ β|1⟩) =
α2|00⟩+ αβ|01⟩+ βα|10⟩+ β2|11⟩.
(6.43)
But C should also be able to clone a basis qubit: C|0⟩⊗| ⟩= |0⟩⊗|0⟩= |00⟩and
C|1⟩⊗| ⟩= |1⟩⊗|1⟩= |11⟩, so that we should also have
C(α|0⟩+ β|1⟩) ⊗| ⟩= α|00⟩+ β|11⟩.
(6.44)
But the two alternative formulas for C|Ψ ⟩are inconsistent, so that the attempted
cloning must be impossible. This proves the no-cloning theorem.
6.8
The Toffoli Logic Gate
The circuit for the Toffoli gate is shown in Fig.6.31. In the classical Toffoli gate,
there are two control bits a and b, which remains unaltered. The third bit c ﬂips if,
and only if, a = b = 1, as shown in Table6.11. This gate is also called a controlled–
controlled-NOT gate (CCNOT).
Fig. 6.31 Toffoli gate
Table 6.11 Toffoli gate
a
b
c
a′
b′
c′
0
0
0
0
0
0
0
0
1
0
0
1
0
1
0
0
1
0
0
1
1
0
1
1
1
0
0
1
0
0
1
0
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
0

6.8 The Toffoli Logic Gate
223
Fig. 6.32 Different gates constructed using Toffoli gate; left to right AND, NAND, XOR, XOR
Fig. 6.33 NOT gate
obtained from Toffoli gate
We turn now to the quantum Toffoli gate. The circuit is the same as that for the
classical gate, but the bits a, b, c ⊕ab are now replaced by the corresponding qubits
|a⟩, |b⟩, |c ⊕ab⟩of the computational basis. From Table6.11, we can ﬁnd the unitary
matrix representing the quantum Toffoli gate:
UTof =


1 0 0 0 0 0 0 0
0 1 0 0 0 0 0 0
0 0 1 0 0 0 0 0
0 0 0 1 0 0 0 0
0 0 0 0 1 0 0 0
0 0 0 0 0 1 0 0
0 0 0 0 0 0 0 1
0 0 0 0 0 0 1 0


.
(6.45)
To build a circuit for the logic sum aORb, recall the fourth De Morgan law
aORb = a ∨b = (a ∧b).
(6.46)
Theorem 6.1 The Toffoli gate is universal: NOR, AND, and OR gates can be con-
structed using only CCNOT gates.
Proof The AND gate can be obtained by setting c = 0, since 0 ⊕a ∧b = a ∧b =
a AND b. The NAND gate can be obtained by setting c = 1, since 1 ⊕a ∧b =
a ∧b = a NAND b. The XOR gate can be obtained by setting either a = 1 or b = 1
(see the third and fourth circuits of Fig.6.32). The one-bit NOT gate is equivalent to
the Toffoli gate with a = b = 1 (see Fig.6.33). Thus the theorem is proved.

224
6
Digital and Quantum Computers
Since the Toffoli gate is universal, by Theorem6.1, all classical computations can,
in principle, be performed by a quantum computer (apart from inevitable practical
difﬁculties).
6.9
Quantum Fourier Transform
The quantum Fourier transform is closely analogous to the well-known discrete
Fourier transform (DFT), independent of quantum computation. A set of N complex
numbers f j ( j = 0, 1, . . . , N −1) can be transformed into another set of N complex
numbers Fk (k = 0, 1, . . . , N −1) by the following relations:
Fk =
1
√
N
N−1

j=0
f je2πikj/N.
(6.47)
The inverse DFT is then given by f j =
1
√
N
N−1
k=0 Fke−2πi jk/N. Note that if the f j
are regarded as coordinates of a vector f and the Fk, coordinates of a vector F, then
we can write F = DFT f, where DFT acts as a unitary operator. A quantum Fourier
transform QFT is equivalent to a DFT on the amplitudes of a quantum state, whereby
QFT
N−1

j=0
α j| j⟩=
N−1

k=0
βk|k⟩,
with
βk =
1
√
N
N−1

j=0
α je2πikj/N.
(6.48)
This is reminiscent of the transformation of a Schrödinger wavefunction ψ(x) to
momentum representation φ(p).
A quantum Fourier transform can be carried out by a series of unitary operations
on the computational basis {| j⟩}. The result is a new basis set, composed of linear
combinations of the original basis vectors. Let N be a positive integer; the complex
number ωN = e2πi/N can be represented as a unit vector in the complex plane, making
an angle 2π/N with the real axis. The quantum Fourier transform is then represented
by the following matrix:
U jk = Ukj =
1
√
N
ω jk
N
for j, k = 0, 1, 2, . . . , N −1.
(6.49)
The action of U on the vector | j⟩is then given by
U| j⟩=
N−1

k=0
Ukj |k⟩.
(6.50)
Let us prove that the matrix U is unitary:

6.9 Quantum Fourier Transform
225
(U †U) jl =
N−1

k=0
U †
jkUkl = 1
N
N−1

k=0
ω−jk+kl
N
= 1
N
N−1

k=0
ωk(l−j)
N
,
j,l = 0, 1, 2, . . . , N −1.
(6.51)
If j = l, ωk(l−j)
N
= ω0
N = 1 and the sum (6.51) is equal to 1
N N = 1. If, instead, j ̸= l,
expression (6.51) becomes a sum of unit vectors from the origin to the vertices of a
regular polygon of N sides, which sum to zero (see Fig.6.34). Therefore (U †U) jl =
δ jl, so that U †U = I. It is interesting to note that the Fourier transform of every
vector | j⟩is an equally weighted superposition of all the computational basis states,
since, from Eq.(6.49), |U jk|2 = 1/N. A pure basis state in Hilbert space, say an
energy eigenstate, exhibits a behavior somewhat similar to a classical system, in
that the measurement of energy gives a reproducible result. By contrast, Fourier-
transformedstatesaremaximalsuperpositions,andresultsofmeasurementarehighly
probabilistic; this might be described as “extreme quantum” behavior.
Further manipulations take a more compact form if N equals a power of 2: N =
2n, where n is integer. Let | j⟩
( j = 0, 1, . . . , N −1) denote an element of the
computational basis for a system of N qubits; then the following theorem holds:
Theorem 6.2 The state U| j⟩can be written as the product state:
U| j⟩=
N−1

k=0
Ukj|k⟩=
1
√
2n ⊗n−1
r=0

|0⟩+ ω2r j
N |1⟩

.
(6.52)
Proof We will demonstrate the theorem for the case n = 3 (N = 8), but the argument
can easily be extended to arbitrary n. Write k as the binary number k1k2k3, and the
state |k⟩as the product state |k1⟩⊗|k2⟩⊗|k3⟩. Then k = 4k1 + 2k2 + k3, and we
have
U| j⟩=
1
√
8
7
k=0 ωkj
8 |k⟩=
1
√
8
1
k1=0
1
k2=0
1
k3=0 ω(4k1+2k2+k3) j
8
|k1⟩⊗|k2⟩⊗|k3⟩=
1
√
8
1
k1=0 ω4k1 j
8
|k1⟩

⊗
1
k2=0 ω2k2 j
8
|k2⟩

⊗
1
k3=0 ωk3 j
8 |k3⟩

=
1
√
8

|0⟩+ ω4 j
8 |1⟩

⊗

|0⟩+ ω2 j
8 |1⟩

⊗

|0⟩+ ω j
8|1⟩

.
(6.53)
Fig. 6.34 The vectors
representing the N th roots of
unity in the complex plane
sum to zero:
N−1
k=0 e2πik/N = 0. These
could be the vertices of an
N-pointed star polygon

226
6
Digital and Quantum Computers
Thus the theorem is proved for the case n = 3.
Writing j as the binary number j1 j2 j3, recall that the basis state | j⟩can be written
as the product
| j⟩= | j1⟩⊗| j2⟩⊗| j3⟩.
(6.54)
Noting that ω8
8 = 1, it is implied that
ω4 j
8 = ω4(4 j1+2 j2+ j3)
8
= ω4 j3
8 ,
ω2 j
8 = ω2(4 j1+2 j2+ j3)
8
= ω4 j2+2 j3
8
,
ω j
8 = ω4 j1+2 j2+ j3
8
.
(6.55)
Thus Eq.(6.53) simpliﬁes to
U| j⟩=
1
√
8

|0⟩+ ω4 j3
8 |1⟩

⊗

|0⟩+ ω4 j2+2 j3
8
|1⟩

⊗

|0⟩+ ω4 j1+2 j2+ j3
8
|1⟩

.
(6.56)
The last expression will help us to ﬁnd a circuit implementing the quantum Fourier
transform. Using the original form for the matrix Ukj (Eq.6.49) and the identities
ω8
8 = 1,
ω9
8 = ω8,
ω10
8 = ω2
8,
ω11
8 = ω3
8,
etc.,
(6.57)
we ﬁnd (for simplicity, writing ω8 = ω)
U =
1
√
8


1 1
1
1
1
1
1
1
1 ω ω2 ω3 ω4 ω5 ω6 ω7
1 ω2 ω4 ω6 1 ω2 ω4 ω6
1 ω3 ω6 ω ω4 ω7 ω2 ω5
1 ω4 1 ω4 1 ω4 1 ω4
1 ω5 ω2 ω7 ω4 ω ω6 ω3
1 ω6 ω4 ω2 1 ω6 ω4 ω2
1 ω7 ω6 ω5 ω4 ω3 ω2 ω


.
(6.58)
An efﬁcient realization of a circuit for implementing the quantum Fourier trans-
form circuit is shown in Fig.6.35. In order to prove that the circuit implements the
operator U in (6.58), we begin with the following.
Lemma 6.1 Partial circuit 1 of Fig.6.36 sends the input state | j1⟩⊗| j2⟩into the
state:

|0⟩+ ω4 j1+2 j2|1⟩

⊗| j2⟩.
(6.59)
Proof The ﬁrst gate operates only on the ﬁrst qubit leaving the second qubit
unchanged; therefore the action on | j1⟩⊗| j2⟩is represented by the tensor product
H ⊗I, which gives the following matrix:

6.9 Quantum Fourier Transform
227
Fig. 6.35 Circuit implementing the quantum Fourier transform for n = 3, N = 8
Fig. 6.36 Partial circuit 1
H ⊗I =
1
√
2


1 1
1 ω4

 ⊗


1 0
0 1

 =
1
√
2


1 0 1
0
0 1 0
1
1 0 ω4 0
0 1 0 ω4


.
(6.60)
Note that ω4 = −1 and ω2 = i. The controlled-S′ gate5 is represented by the matrix
(see Eq.(6.28)):
S′ =


1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 ω


.
(6.61)
Denoting by V , the product of the matrices S′(H ⊗I), we ﬁnd
V =
1
√
2


1 0
1
0
0 1
0
1
1 0 ω4 0
0 ω2 0 ω6


.
(6.62)
Thus V maps the states of the computational basis into the states (omitting the ⊗
symbol):
5For a single-qubit phase-shift gate, R(φ) =


1 0
0 eiφ

, which includes S, T, and Z, we ﬁnd
R(φ)|0⟩= |0⟩, R(φ)|1⟩= eiφ|1⟩. For the corresponding two-qubit controlled gate R′(φ), it follows
that R′(φ)|00⟩= |00⟩, R′(φ)|01⟩= |01⟩, R′(φ)|10⟩= |10⟩, R′(φ)|11⟩= eiφ|11⟩, whichever is
the control qubit.

228
6
Digital and Quantum Computers
Fig. 6.37 Partial circuit 2
V

|0⟩|0⟩

=
1
√
2

|0⟩|0⟩+ |1⟩|0⟩

=
1
√
2

|0⟩+ |1⟩

|0⟩,
V

|0⟩|1⟩

=
1
√
2

|0⟩|1⟩+ ω2|1⟩|1⟩

=
1
√
2

|0⟩+ ω2|1⟩

|1⟩,
V

|1⟩|0⟩

=
1
√
2

|0⟩|0⟩+ ω4|1⟩|0⟩

=
1
√
2

|0⟩+ ω4|1⟩

|0⟩,
V

|1⟩|1⟩

=
1
√
2

|0⟩|1⟩+ ω6|1⟩|1⟩

=
1
√
2

|0⟩+ ω6|1⟩

|1⟩,
(6.63)
as in the four cases 4 j1 + 2 j2 = 0, 2, 4, 6, respectively; thus the lemma is proved.
Let us consider now the inverted controlled-T gate of Fig.6.38. If the partial circuit
had been the circuit 2 of Fig.6.37, then the corresponding matrix would be


1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 ω


⊗


1 0
0 1

 =


1 0 0 0 0 0 0 0
0 1 0 0 0 0 0 0
0 0 1 0 0 0 0 0
0 0 0 1 0 0 0 0
0 0 0 0 1 0 0 0
0 0 0 0 0 1 0 0
0 0 0 0 0 0 ω 0
0 0 0 0 0 0 0 ω


.
(6.64)
To get the correct result, just swap the j2, j3 qubits:


1 0 0 0 0 0 0 0
0 1 0 0 0 0 0 0
0 0 1 0 0 0 0 0
0 0 0 1 0 0 0 0
0 0 0 0 1 0 0 0
0 0 0 0 0 ω 0 0
0 0 0 0 0 0 1 0
0 0 0 0 0 0 0 ω


.
(6.65)
The matrix (6.65) maps the state | j1⟩| j2⟩| j3⟩into the state

|0⟩+ ω j3|1⟩

| j2⟩| j3⟩.
Therefore, the partial circuit of Fig.6.38 maps | j1⟩into the qubit

6.9 Quantum Fourier Transform
229
Fig. 6.38 Partial circuit 3
1
√
2

|0⟩+ ω4 j1+2 j2+ j3|1⟩

.
(6.66)
Considernowtheremainingpartofthecircuit,partialcircuit4ofFig.6.39.Making
use of the Lemma6.1, we see that | j2⟩is mapped into
1
√
2

|0⟩+ ω4 j2+2 j3|1⟩

.
(6.67)
Finally, applying H to the third qubit, we get the following output:
1
√
2

|0⟩+ ω4 j3|1⟩

.
(6.68)
The tensor product of Eqs.(6.66)–(6.68) is, using Eq.(6.55),
1
√
8

|0⟩+ ω4 j1+2 j2+ j3|1⟩

⊗

|0⟩+ ω4 j2+2 j3|1⟩

⊗

|0⟩+ ω4 j3|1⟩

=
1
√
8

|0⟩+ ω j|1⟩

⊗

|0⟩+ ω2 j|1⟩

⊗

|0⟩+ ω4 j|1⟩

.
(6.69)
Using (6.57) in (6.69), we see that the order of the ﬁrst and third qubits is reversed.
After applying the SWAP gate, we obtain the ﬁnal result:
U| j⟩=
1
√
8

|0⟩+ ω4 j|1⟩

⊗

|0⟩+ ω2 j|1⟩

⊗

|0⟩+ ω j|1⟩

.
(6.70)
Thus, the circuit of Fig.6.35 implements the quantum Fourier transform in the case
n = 3, N = 8. The circuit can be generalized to arbitrary n, using ωN = e2πi/2n.
Fig. 6.39 Partial circuit 4

230
6
Digital and Quantum Computers
6.9.1
Phase Estimation
An important application of the quantum Fourier transform is phase estimation. Let
U be a 2m × 2m unitary matrix and |u⟩∈C2m, an eigenvector. Suppose that both U
and |u⟩are known. We can then write
U |u⟩= eiϕ |u⟩,
(6.71)
recalling that the eigenvalues of a unitary matrix are complex numbers of unit mag-
nitude. The objective now is to estimate the phase ϕ to an accuracy of n bits. The
method is to subject the ﬁrst n qubits of the eigenvector |u⟩to a series of controlled
operators, involving powers of U, followed by an inverse quantum Fourier transform.
As shown in Fig.6.40, the input of the ﬁrst register consists of n qubits, all prepared
in the state |0⟩. The input of the second register contains the row of m qubits, which
represent the state |u⟩. For simplicity, the circuit implementing the phase estima-
tion shown in Fig.6.40 pertains to the particular case m = 3, n = 3. The H gates
map the qubits |0⟩into
1
√
2

|0⟩+ |1⟩

; then the controlled U 2 j (for j = 0, 1, 2) maps
the qubits |0⟩+ |1⟩into the qubits |0⟩+ ei2 jϕ|1⟩. In this way the output of the ﬁrst
register is the product state:
|OUT⟩=
1
√
8

|0⟩+ e4iϕ|1⟩

⊗

|0⟩+ e2iϕ|1⟩

⊗

|0⟩+ eiϕ|1⟩

.
(6.72)
Denoting by y the binary number [y2y1y0]2 = 4y2 + 2y1 + y0, and by |y⟩, the
corresponding state in the computational basis, the state |OUT⟩can be written as
Fig. 6.40 A circuit implementing phase estimation

6.9 Quantum Fourier Transform
231
|OUT⟩=
1
√
8
1

y2=0
1

y1=0
1

y0=0
ei(4y2+2y1+y0)ϕ|y2⟩⊗|y1⟩⊗|y0⟩=
1
√
8
7

y=0
eiϕy|y⟩.
(6.73)
In the general case of n qubits, we would have obtained
|OUT⟩=
1
√
2n
2n−1

y=0
eiϕy|y⟩.
(6.74)
Given the integer n, the real number
ϕ
2π (0 ≤ϕ < 2π) can be written as a multiple
of 1
2n plus a remainder:
ϕ
2π
=
p
2n + δ,
(6.75)
where p is an integer (0 ≤p < 2n) and
|δ| ≤
1
2n+1 .
(6.76)
In essence, p gives an estimation of the phase accurate to 1 part in 2n. Note that δ
can be positive or negative (or zero). Consider the following two cases:
(1) δ = 0. Then the state |OUT⟩is given by
|OUT⟩=
1
√
2n
2n−1

y=0
e2πipy/2n|y⟩=
1
√
2n
2n−1

y=0
ωpy
2n |y⟩.
(6.77)
The angle ϕ can be found by applying the inverse of the quantum Fourier transform
UF, with the matrix
(U −1
F ) jk = (U †
F) jk =
1
√
2n ω−jk
2n .
(6.78)
Using Dirac notation and the identities 2n−1
j=0 | j⟩⟨j| = 2n−1
k=0 |k⟩⟨k| = I, we
can write
U −1
F |OUT⟩=
2n−1

j=0
2n−1

k=0
| j⟩⟨j|U −1
F |k⟩⟨k|OUT ⟩.
(6.79)
Since ⟨k|OUT⟩= eiϕk = ωpk
2n , we have
U −1
F |OUT⟩=
2n−1

j=0
2n−1

k=0
| j⟩(U −1
F ) jk
1
√
2n ωpk
2n =
1
2n
2n−1

j=0
2n−1

k=0
ω(p−j)k
2n
| j⟩. (6.80)

232
6
Digital and Quantum Computers
If j = p,
1
2n
2n−1
k=0 1 = 1; if j ̸= p the sum 2n−1
k=0
ω(p−j)k
2n
vanishes because the
unit vectors ω(p−j)k
2n
form a star polygon in the complex plane, as shown in Fig.6.34.
Thus
U −1
F |OUT⟩= |p⟩.
(6.81)
In the circuit of Fig.6.40, the number p is represented by the bits p2 p1 p0 labeling
the qubits in the computational basis. Thus, the output of the “ﬁrst register” gives the
bits p2 p1 p0. This simpliﬁed example shows how the circuit approximates the phase
as ϕ ≃2πp/2n when δ = 0.
(2) δ ̸= 0. From Eqs.(6.74) and (6.75) we get
|OUT⟩=
1
√
2n
2n−1

y=0
e2πi(p/2n+δ)y|y⟩=
1
√
2n
2n−1

y=0
ωky
2n e2πiδy |y⟩.
(6.82)
Applying the inverse quantum Fourier transform,
U −1
F |OUT⟩=
1
2n
2n−1

j=0
2n−1

k=0
ω(p−j)k
2n
e2πiδk | j⟩.
(6.83)
Projecting this state onto the vector |p⟩, only the term with j = p survives: thus the
probability amplitude |cp| = |⟨p|U −1
F |OUT⟩| is given by
|cp| =
1
2n

2n−1

k=0
e2πiδk
 =
1
2n

2n−1

k=0
αk
 ,
(6.84)
where α = e2πiδ.
The sum of the geometric series 2n−1
k=0 αk equals α2n −1
α−1 . Therefore,
|cp| = 1
2n

α2n −1
α −1
 = 1
2n

e2πiδ2n −1
e2πiδ −1
 .
(6.85)
For any value of θ (see Fig.6.41),
|eiθ −1| = 2
sin θ
2
 ,
(6.86)
so that Eq.(6.85) becomes
|cp| =
1
2n

sin(πδ2n)
sin(πδ)
 .
(6.87)

6.9 Quantum Fourier Transform
233
Fig. 6.41 Geometrical proof of Eq.(6.86); |eiθ −1| is the distance between the points (cos θ, sin θ)
and (1, 0) of R2
A rigorous evaluation of the function (6.87) for small θ and large values of N = 2n
would be tedious. However, since the denominator sin πδ can be well approximated
by πδ, the resulting function sin(πδN)
πδN
can be expressed as a series expansion:
|cp| ≃1 −π2δ2N 2
3!
+ π4δ4N 4
5!
−· · · ,
(6.88)
which is rapidly convergent since |δ|N ≤1
2, by Eq.(6.76). From Eq.(6.88), we see
that the width of the maximum at δ = 0 is very small, of the order of 1
N . Of course,
since the numerator of (6.87) is periodic, a graph would show other extraneous
maxima, corresponding to |δ| =
1
2N ,
3
2N ,
5
2N , . . ..
6.10
Some Results from Number Theory
One of the conjectured applications of quantum computers is quantum cryptography,
which would enable absolutely secure communication using unbreakable codes.
All of the methods of quantum cryptography are based on results from number
theory, possibly the “purest” branch of pure mathematics. To the dismay of many
mathematicians, notably G.H. Hardy, number theory has surprisingly turned out to
have a signiﬁcant number of practical applications.
6.10.1
The Euclidean Algorithm
Given two positive integers a, n, we denote by gcd(a, n) the greatest common divisor
of a, n. For example, gcd(8, 12) = 4, gcd(24, 60) = 12, gcd(8, 27) = 1.
Deﬁnition 6.2 Two numbers a, n are said to be coprime if they do not have any
common divisors. This is equivalent to saying that gcd(a, n) = 1.

234
6
Digital and Quantum Computers
For example, the pairs (8, 27), (9, 28), (13, 19) consist of coprime numbers. Two
prime numbers are always coprime. A method for ﬁnding the gcd of two integers has
been known since antiquity, for 2300 years and possibly longer. This is the Euclidean
algorithm, based on successive divisions with remainder. Let n and a be two integers,
with n > a > 0. Let q1 equal the number of times n contains a; thus
n = q1a + r1 with 0 ≤r1 < a.
(6.89)
If the remainder r1 vanishes, n is a multiple of a and gcd(a, n) = a. But if r1 does
not vanish, we perform a second division, dividing a by r1. Every factor that divides
n and a, also divides r1, since r1 = n −q1a. But then gcd(r1, a) = gcd(a, n); since
r1 < a < n, ﬁnding gcd(r1, a) is easier than ﬁnding gcd(a, n). Once performed, the
division of a by r1 gives the new remainder r2:
a = q2r1 + r2 with 0 ≤r2 < r1
(6.90)
and again if r2 = 0, gcd(r1, a) = gcd(a, n) = r1. But even if r2 ̸= 0, the task is easier,
and
gcd(r2,r1) = gcd(r1, a) = gcd(a, n).
(6.91)
Iterating the procedure, we have r1 = q3r2 + r3 with 0 ≤r3 < r2 < r1, etc. Finally,
the value of
gcd(a, n)
is given by the last nonzero remainder. For example,
you want to ﬁnd the gcd(9207, 4203). From Table6.12, we see that r4 = 0. Thus
gcd(9207, 4203) = r3 = 9.
6.10.2
Bezout’s Lemma
This is a byproduct of the Euclidean algorithm for the gcd of two integers. Suppose
a, b are two positive integers; then there exist two integers X, Y (one positive, one
negative) such that
gcd(a, b) = Xa + Yb.
(6.92)
Proof Denote by  the set of integers Xa + Yb, with X, Y integers. Now carry
out the procedure given in Table6.12, for the case r4 = 0. In the general case, the
sequence r1 > r2 > r3 . . . cannot be inﬁnite since ri ≥0 (i = 1, 2, 3, . . .). Let us
prove that r3 = gcd(a, b) ∈. Note that  is a linear set: any linear combination
of elements of  with integer coefﬁcients also belongs to . From Table6.12 (1), it
follows that r1 = b −q1a ∈. From (2), r2 = a −q2r1 ∈. From (3), r3 = r1 −
q3r2 ∈. Since, in our case, r4 = 0,
r3 = gcd(a, b). This line of reasoning can

6.10 Some Results from Number Theory
235
Table 6.12 Euclidean
algorithm
(1)
n = q1a + r1
9207 = 4203 × 2 + 801
(2)
a = q2r1 + r2
4203 = 801 × 5 + 198
(3)
r1 = q3r2 + r3
801 = 198 × 4 + 9
(4)
r2 = q4r3 + 0
198 = 9 × 22 + 0
be generalized to any number of remainders r1,r2,r3, . . ., which proves Bezout’s
lemma.6
6.10.3
Modular Arithmetic
Think about a clock display: the motion of the hour hand is periodic, because if s
denotes the “distance” traveled, and r the position (hour) of the hand, we can write
(taking 1h as unit) as
s = r + 12k,
k ≥0,
(6.93)
where k is an integer. This is illustrated in Fig.6.42. For example, the values s = 14,
s = 26, and s = 38 correspond to the same position r = 2. Eq.(6.93) can also be
written as
s = r(mod 12)
or
s ∼= r (mod 12).
(6.94)
We say “s is equal to r modulo 12” or “s is equivalent (or congruent) to r modulo
12,” and we will use the symbol ∼= in place of = to denote this equivalence. We led to
consider clock arithmetic when carrying out the usual operations of sum and product
of the paths s, and then reading the result on the clock display. For example, we can
write
3 + 9 ∼= 0(mod 12), 3 + 8 ∼= 11(mod 12), 6 + 15 ∼= 9(mod 12),
4 × 4 ∼= 4(mod 12), 4 × 5 ∼= 8(mod 12), etc.
(6.95)
These relations are special cases of modular arithmetic, which is a generalization of
clock arithmetic in which 12 is replaced by an arbitrary integer n > 0. Given two
integers a, b, we will write
a ∼= b (mod n).
(6.96)
if the difference a −b is an integer multiple of n. For example 5 + 5 ∼= 3(mod 7),
15 ∼= 39(mod 6), etc.
6It is also possible to prove that gcd(a, b) is the smallest positive integer belonging to . Furthermore,
given an element of , the coefﬁcients X, Y are not unique. For example, if a = 2, b = 4, the number
6 can be written as 6 = a + b, 6 = 2b −a, 6 = 3b −3a, etc.

236
6
Digital and Quantum Computers
Fig. 6.42 s and r are
equivalent in modular
arithmetic
Many of the usual properties of addition, subtraction, and multiplication still hold
in modular arithmetic: for example, if
a1 ∼= b1 (mod n) and a2 ∼= b2 (mod n),
(6.97)
then
a1 + a2 ∼= b1 + b2 (mod n) and a1a2 ∼= b1b2 (mod n).
(6.98)
Given an integer r, the set {r,r ± n,r ± 2n,r ± 3n, . . .} is called the congruence
class or residue class of r modulo n, and is denoted by r or rn. In the above case
(clock arithmetic), the elements of r12 are all values of s such that s −r is a multiple
of 12. The set of these classes is denoted by Zn (other notations are Z/nZ or Z/n).
For example, 312 = {3, 15, −9, 27, −21, . . .}, 54 = {5, 9, 1, 13, −3, 17, . . .}. Since
a class is determined by one of its elements, we have
Zn = {1, 2, . . . , n}.
(6.99)
Sums and products of two elements of Zn must, of course, be performed modulo n.
This is shown in the multiplication tables of Z12 and Z7.
From Table6.13 we see that
1 × 1 ∼= 5 × 5 ∼= 7 × 7 ∼= 11 × 11 ∼= 1(mod 12).
(6.100)
Therefore, the (multiplicative) inverses of 1, 5, 7, 11 modulo 12 exist and are given by
1
−1 ∼= 1(mod 12), 5
−1 ∼= 5(mod 12), 7
−1 ∼= 7(mod 12), 11
−1 ∼= 11(mod 12).
(6.101)
However, the remaining elements 2, 3, 4, etc. do not admit inverses. The only num-
bers equal to 1 in the multiplication table of Z12 lie on the diagonal and correspond
to 1 × 1, 5 × 5, 7 × 7, and 11 × 11.

6.10 Some Results from Number Theory
237
Table 6.13 Multiplication table for Z12
1
2
3
4
5
6
7
8
9
10
11
12
2
4
6
8
10
12
2
4
6
8
10
12
3
6
9
12
3
6
9
12
3
6
9
12
4
8
12
4
8
12
4
8
12
4
8
12
5
10
3
8
1
6
11
4
9
2
7
12
6
12
6
12
6
12
6
12
6
12
6
12
7
2
9
4
11
6
1
8
3
10
5
12
8
4
12
8
4
12
8
4
12
8
4
12
9
6
3
12
9
6
3
12
9
6
3
12
10
8
6
4
2
12
10
8
6
4
2
12
11
10
9
8
7
6
5
4
3
2
1
12
12
12
12
12
12
12
12
12
12
12
12
12
Consider now the multiplication Table6.14 of Z7; here the situation is different.
We have
1 × 1 ∼= 2 × 4 ∼= 3 × 5 ∼= 4 × 2 ∼= 5 × 3 ∼= 6 × 6 ∼= 1(mod 7).
(6.102)
All of the elements of Z7 admit inverses (except 7 since 7 ∼= 0):
1
−1 ∼= 1(mod 7), 2
−1 ∼= 4(mod 7), 3
−1 ∼= 5(mod 7),
4
−1 ∼= 2 (mod 7), 5
−1 ∼= 3 (mod 7), 6
−1 ∼= 6 (mod 7).
(6.103)
We are led to the following theorem:
Theorem 6.3 Let n be an integer greater than 1. A necessary and sufﬁcient condition
for an element a ∈Zn to admit an inverse modulo n is that a and n are coprime.
Proof Let us ﬁrst show that the condition is necessary. Assume, to the contrary, that
a and n have a common factor n1:
Table 6.14 Multiplication
table for Z7
1
2
3
4
5
6
7
2
4
6
1
3
5
7
3
6
2
5
1
4
7
4
1
5
2
6
3
7
5
3
1
6
4
2
7
6
5
4
3
2
1
7
7
7
7
7
7
7
7

238
6
Digital and Quantum Computers
n = n1n2,
a = rn1.
(6.104)
Since n ∼= 0(mod n) it follows that
n1an2 ∼= 0(mod n),
an2 ∼= rn1n2 ∼= 0(mod n).
(6.105)
Multiplying the last equality by a−1, we would get n2 ∼= 0. Thus a and n cannot
have a common factor n1. Let us now prove sufﬁciency: we assume that gcd(a, n) =
1; from the discussion of the Euclidean algorithm we learned that gcd(a, n) can be
written as a linear combination with integer coefﬁcients X, Y:
Xa + Yn = 1,
Xa = 1 −Yn.
(6.106)
It follows that Xa ∼= 1(mod n); thus the inverse X ∼= a−1(mod n) exists and the
proof is complete.
From Theorem6.3, it follows that if n = p is a prime number, all the elements of
Zp admit an inverse: for example, we have seen from the multiplication table of Z7
that all classes 1, 2, 3, 4, 5, 6 admit an inverse modulo 7.
6.10.4
Fermat’s Little Theorem
One of the fundamental results of modular arithmetic (derived by Pierre de Fermat,
1640) is the following7:
Theorem 6.4 Let p be a prime number; for any integer a,
a p ∼= a(mod p).
(6.107)
If a is not a multiple of p (so that a ≇0), then
a p−1 ∼= 1(mod p).
(6.108)
Proof (for simplicity, we will omit the overlining.) Identifying an element a and its
class a, we can regard a as an element of Zp. Consider the multiples of a:
a, 2a, 3a, . . . , (p −1)a,
(6.109)
and let r ≤p −1, s ≤p −1, with two integers r ̸= s; it is not possible that ra ∼=
sa (mod p), since this would imply r ∼= s (mod p), so that r = s. Thus the classes
7This is not as famous as “Fermat’s last theorem” (concerning xn + yn = zn), but his “little”
theorem has been far more useful in applications of number theory. The converse of Fermat’s little
theorem is not true. It holds for many values of p which are not prime; these are known as Fermat
pseudoprimes.

6.10 Some Results from Number Theory
239
Table 6.15 Multiplication
table for Z∗
12
1
5
7
11
5
1
11
7
7
11
1
5
11
7
5
1
a, 2a, 3a, . . . , (p −1)a are all different (we can imagine that the corresponding
hours of a clock with p hours are all different): ra ̸= sa (mod p). It follows that the
above classes coincide, in some order, with the classes 1, 2, 3, . . . , (p −1), so that
a, 2a, 3a, . . . , (p −1)a occupy all the hour marks of the clock display. Then there
exists a permutation k1, k2, . . . , kp−1 of the numbers 1, 2, 3, . . . , (p −1) such that
k1a ∼= 1(mod p),
k2a ∼= 2(mod p),
kp−1a ∼= (p −1)(mod p)
(6.110)
Multiplying all these equalities, we get
k1k2kp−1 ∼= 1, 2, 3, . . . , (p −1)(mod p),
(6.111)
so that
(p −1)! a p−1 ∼= (p −1)!(mod p).
(6.112)
Thus Eq.(6.108) is proved. Multiplying both sides of Eq.(6.108) by a, we get a p ∼=
a(mod p). For example, let a = 3, p = 7; from the multiplication Table6.15 of Z7
we ﬁnd
a ∼= 3, a2 ∼= 2, a3 ∼= 6, a4 ∼= 4, a5 ∼= 5, a6 ∼= 1.
(6.113)
Fermat’s little theorem clariﬁes the structure of Zp, when p is prime. What can
we say about the structure of Zn, when n is an arbitrary integer? We know that in
order for an element a ∈Zn to admit an inverse modulo n, it is necessary that a
and n be coprime. Obviously then, we remove from Zn all elements that have some
common factor with n, and limit ourselves to the set Z∗
n, of the numbers a coprime
with n. More precisely, Z∗
n is the set of congruence classes a modulo n such that n
and a are coprime. The set Z∗
n thus obtained is a “clock” more interesting than Zn
from the mathematical point of view. As we shall see in more detail below, the set Z∗
n
is a multiplicative group. For example, let n = 12 and consider only the numbers 1,
5, 7, 11 that are coprime with 12. These numbers have the multiplication Table6.15
(modulo 12):
This table can be obtained from that of Z12 simply by deleting rows and columns
corresponding to multiples of 2 or 3. In this particular case, each element is its own
inverse, although this is not true in general.
The number of elements of Z∗
n is called the totient or Euler function, denoted
by φ(n). Note that the element 1 is, by deﬁnition, always included. For example,
if n = 12, φ(n) = 4. If p is prime, all the elements of Zp are coprime with p and
therefore φ(p) = p −1. For example, φ(7) = 6. The multiplication table of Z∗
7 can
be obtained from the table of Z7 by deleting the last row and the last column. If

240
6
Digital and Quantum Computers
p is prime, the positive integers less than pα and coprime to pα are all the pα −1
elements of Zpα except the multiples p, 2p, 3p, . . . , (pα −1)p. For example, if
p = 3, α = 2 the elements not coprime with 9 are 3 and 6. If p = 3, α = 3 the
elements not coprime with 27 are 3, 6, 9, 12, 15, 18, 21, 24. Thus φ(32) = 8 −2 = 6,
φ(33) = 26 −8 = 18. In general the number of elements of Zpα is pα−1; therefore,
φ(pα) = (pα −1) −(pα−1 −1) = pα −pα−1.
(6.114)
An important property of the totient function φ is that, if a and b are coprime, then
(see next section)
φ(ab) = φ(a)φ(b).
(6.115)
6.10.5
Chinese Remainder Theorem
This classic result is needed to prove Eq.(6.115):
Theorem 6.5 Let m1, m2, . . . , mn be positive integers that are mutually coprime,
and let M be the product M = m1 m2 . . . mn. The system of equations
x = a1(mod m1),
x = a2(mod m2),
...
x = an(mod mn),
(6.116)
admits solutions. If x, y are two solutions, x ∼= y (mod M).
Proof (forsimplicity,weconsiderthecasen = 3.)Set Mi = M/mi,(i = 1, 2, . . . , n);
in this case, M1 = m2m3, M2 = m1m3 and M3 = m1m2. Note that mi and Mi are
relatively prime. Therefore, we can deﬁne the inverses M−1
i
, such that Mi M−1
i
=
1 (mod mi): We can now verify that a solution to Eq.(6.116) can be expressed in the
following form:
x = a1M−1
1 (mod M1) + a2M−1
2 (mod M2) + a3M3M−1
3 (mod M3).
(6.117)
Re-expressing this as a congruence (mod m1) we have
x ∼= a1M1M−1
1 (mod m1) + a2M2M−1
2 (mod m1) + a3M−1
3 (mod m1).
(6.118)
But M1M−1
1 (mod m1) = 1, while the two last terms vanish (mod m1), since each
contains a factor m1. Therefore,
x = a1(mod m1).
(6.119)

6.10 Some Results from Number Theory
241
Similarly, it can be veriﬁed that x = a2(mod m2), x = a3(mod m3). Now let x and
y be two solutions of the system of Eq.(6.116). The difference x −y satisﬁes the
equations:
x −y = 0(mod m1),
x −y = 0(mod m2),
...
x −y = 0(mod mn).
(6.120)
Then x −y is a multiple of m1, m2, . . . , mn and therefore a multiple of M =
m1m2 . . . mn. The theorem is proved.
As an example, suppose we want to solve the system of two equations:
x = 2(mod 12),
x = 5(mod 7).
(6.121)
Then m1 = 12, m2 = 7, M = 12 × 7 = 84, M1 = M/m1 = 7, M2 = M/m2 =
12. From the multiplication Table6.13 for Z12 we see that M−1
1
= 7−1(mod 12) = 7.
Since 12 ∼= 5(mod 7), from Table6.14 for Z7, we ﬁnd that M−1
2
∼= 12−1 ∼= 5−1 ∼=
3(mod 7). Then
x = 2 × 7 × 7 + 5 × 3 × 12 = 278 (mod 84).
(6.122)
We can remove multiples of 84 from the solution. Then we ﬁnd
x = 278 −3 × 84 = 26 (mod 84).
(6.123)
Indeed, 26 = 2 + 12 × 2 = 5 + 7 × 3.
Let us now prove Eq.(6.115) for the totient φ. For simplicity, we ﬁrst consider
the same case as the last example: in the “clock” Z∗
12 there are four elements (1, 5, 7,
11), and in the “clock” Z∗
7 there are six elements (1, 2, 3, 4, 5, 6), so that φ(12) = 4
and φ(7) = 6. There is a one-to-one correspondence between the pairs a1 ∈Z∗
12,
a2 ∈Z∗
7 and the elements of the “big clock” Z∗
12×7 = Z∗
84. In fact, since 12 and 7 are
coprime, if an element y ∈Z∗
12×7, this means that gcd(y, 12) = 1, gcd(y, 7) = 1, so
y ∈Z∗
12 and y ∈Z∗
7, and vice versa, if y ∈Z∗
12, y ∈Z∗
7, gcd(y, 12) = gcd(y, 7) = 1,
then y ∈Z∗
12×7. Some doubt might remain that given a1 ∈Z∗
12, a2 ∈Z∗
7, there are
many elements y ∈Z∗
12×7 satisfying the following equations:
y = a1 (mod 17),
y = a2 (mod 7).
(6.124)
But, by the Chinese remainder theorem, this is not possible. Since the number of
possible pairs a1, a2 is φ(12)φ(7), it follows that Z∗
12×7 has φ(12)φ(7) elements.
Clearly, the proof can be generalized to any pair a, b of coprime numbers, showing
that Eq.(6.115) has general validity. If n = pα1
1 pα2
2 . . . pαk
k is the prime factorization
of an arbitrary integer n, Eqs.(6.114) and (6.115), imply

242
6
Digital and Quantum Computers
φ(n) =
k
j=1
φ(p
α j
j ) =
k
j=1

p
α j
j −p
α j−1
j

.
(6.125)
We will next discuss an important property of the totient function φ, which leads to
a generalization of Fermat’s little theorem. This involves some results from group
theory.
6.10.6
More Group Theory
Recall that for a ﬁnite group G, the order of the group is the number of elements of
G. A subgroup H is a proper subset of G which is also a group. A beautiful result
due to Lagrange is the following:
Theorem 6.6 If H is a subgroup of a ﬁnite group G, the order of H divides the
order of G.
Proof Let G be the group
G = {e, g2, g3, . . . , gn}
(6.126)
and H the subgroup
H = {e, h2, h3, . . . , hm},
m < n,
(6.127)
where e denotes the identity element of H, which coincides with the identity element
of G. Now let g be an element of G not belonging to H. The following set
Hg = {g, h2g, h3g, . . . , hmg}
(6.128)
is called a right coset Hg. The set
gH = {g, gh2, gh3, . . . , ghm}
(6.129)
is correspondingly called a left coset gH. Of course, in the case of a commuta-
tive group, the right cosets and the left cosets coincide.8 Since we are dealing with
commutative groups, gH = Hg, we can omit the modiﬁers “right” and “left.” Two
elements gh j and ghk ( j ̸= k) of a coset cannot coincide since gh j = ghk would
imply that h j = hk. Therefore, all cosets have m distinct elements. A coset is never a
group since it does not contain the identity e (if gh j = e j, then g = h−1
j
∈H). The
coset gH has void intersection with H, so that ghk /∈H.
8More generally, this is true if H is a normal subgroup.

6.10 Some Results from Number Theory
243
Fig. 6.43 Diagram showing
a subgroup H of the group G
and the cosets gH and g′H.
The dashed arrow shows the
mapping f : ghk →g′hk
between cosets
Now consider a second element g′ ∈G not belonging to H; deﬁne the following
mapping f from the coset gH to the coset g′H:
f : gH →g′H.
(6.130)
Let us take an element ghk ∈gH (see Fig.6.43). We have
f (ghk) = g′g−1ghk = g′hk.
(6.131)
The inverse mapping f −1 exists since
f −1(g′hk) = gg′−1g′hk = ghk.
(6.132)
Both gH and g′H have m elements; therefore f is bijective (one-to-one). Fur-
thermore, if g′H and gH have a common element, they must coincide. Suppose
g′hk = gh j, so g′ = gh jh−1
k , and g′hr = g(h jh−1
k hr). The right-hand side of the
last equality ∈gH (since the expression in parenthesis ∈H), therefore the left-hand
side does too. Thus we have shown that g′H = gH. Evidently then, the group G can
be partitioned into the subgroup H and all the cosets; both H and its cosets contain
m elements. Thus, the order of G must be a multiple of m, which completes the proof
of Lagrange’s theorem. For example, consider the multiplication Table6.16 of Z∗
9,
which consists of the elements {1, 2, 4, 5, 7, 8} which are coprime to 9. The elements
{1, 4, 7} form a subgroup of 3 elements; and indeed 3 is a submultiple of 9.
The totient φ satisﬁes Euler’s totient theorem, stated as follows:
Theorem 6.7 If a, n are coprime positive integers, then
aφ(n) ∼= 1(mod n).
(6.133)

244
6
Digital and Quantum Computers
Table 6.16 Multiplication
table for Z∗
9
1
2
4
5
7
8
2
4
8
1
5
7
4
8
7
2
1
5
5
1
2
7
8
4
7
5
1
8
4
2
8
7
5
4
2
1
Proof The proof follows easily from Lagrange’s theorem. Choose any a ∈Z∗
n, then
the elements {a, a2, a3, . . . , am}(mod n) form a subgroup of m elements of Zn.
Therefore there exists an integer k such that φ(n) = km, and we can write
aφ(n) = akm ∼= 1k = 1
(6.134)
andthetheoremisproved.Forexample,forZ∗
9,wechoosea = 2,sothat2φ(9) = 26 =
64 ∼= 1(mod 9). When n is prime, say equal to p, Euler’s totient theorem reduces to
Fermat’s little theorem, since φ(p) = p −1, a p−1 ∼= 1(mod p).
6.10.7
Factorization of Large Numbers
While it is reasonably easy to decompose a number N, a few digits long, into its prime
factors, the computational complexity increases superexponentially as N increases
in size.9 The following derivations are quite intricate and the reader has the option
of proceeding directly to the conclusion and summary at the end of this subsection.
In principle, factorization is equivalent to “order ﬁnding.”
Deﬁnition 6.3 Given n > 0, and a ∈Z∗
n, the least positive integer r such that ar ∼=
1(mod n) is called the “order of a modulo n.”
Examples: if n = 12, the order of 5 is 2, since 52 = 25 ∼= 1(mod 12); if n = 9, the
order of 7 is 3 since the powers of 7 are 7, 72 ∼= 4, 73 ∼= 1(mod 9). Clearly, the
order of an element a divides the order of the group Z∗
n, while the powers of a form
a subgroup of Z∗
n. The equation
x2
∼= 1(mod n)
(6.135)
has the “trivial solutions” x ∼= 1(mod n) and x ∼= −1(mod n). The relation between
factoring numbers and order ﬁnding can be seen from the following lemma:
Lemma 6.2 A nontrivial solution of Eq.(6.135) has the property that at least one
of gcd(x-1,n) and gcd(x+1,n) divides n.
9It is easy to multiply prime numbers but much more difﬁcult to factorize a product. As a simple
exercise, ﬁnd the prime factors of 323, then check the result by multiplying the factors.

6.10 Some Results from Number Theory
245
Proof Equation(6.135) is equivalent to
(x + 1) (x −1) ∼= 0(mod n).
(6.136)
Let us limit ourselves to the ﬁrst “clock display.” Having excluded the solutions x = 1
and x = −1, we have 0 < x −1 < x + 1 < n. Therefore, gcd(x −1, n) < n and
gcd(x + 1, n) < n. Since Eq.(6.135) is equivalent to (x + 1)(x −1) = kn, (with
k ≥1), gcd(x −1, n) and gcd(x + 1, n) cannot both be equal to 1 because this would
imply n = 1. Therefore at least one of the numbers, gcd(x −1, n) or gcd(x + 1, n),
is a nontrivial factor of n, possibly both. Example: Let x = 11, n = 15; x + 1 = 12
and x −1 = 10. In fact, gcd(12, 15) = 3 and gcd(10, 15) = 5 are both nontrivial
factors of 15. Of course, if n is a prime number, gcd(x −1, n) and gcd(x + 1, n)
are equal to 1 for all 1 < x < n −1. Therefore, if n is large, the search for a factor
using only Eq.(6.136) can be very time consuming. We should therefore seek a more
efﬁcient probabilistic method.
Deﬁnition 6.4 A group G of order n is called cyclic if there is an element g ∈G
such that G = {g, g2, g3, . . . , gn}, with gn = e.
The element g is called a generator of the group. Clearly, a cyclic group is Abelian
since gmgn = gngm. The group Z∗
p, where p is prime, is cyclic, with p −1 elements
{g, g2, g3, . . . , g p−1}, since g p = g. Next, we need the following theorem.
Theorem 6.8 Let p be an odd prime greater than 2, and α a positive integer. Then
the group Z∗
pα is cyclic.
An elegant proof of this beautiful Theorem is given in the appendix: for p = 3, α =
2, the group Z∗
9 consists of six elements 2, 22, 23, 24 ∼= 7, 25 ∼= 5, 26 ∼= 1.
For an odd prime, the group Z∗
pα, with the generator g, has φ(pα) elements:
{g, g2, g3, . . . , gφ(pα) ∼= 1}.
In what follows, we are given two integers a, b, if a divides b we write a|b, if this
is not true, we write a ∤b. Consider an element gk ∈Z∗
pα, and let r be the order of
gk modulo pα. We need the following lemma.
Lemma 6.3 The set Z∗
pα can be partitioned into two equal sets: the ﬁrst consisting of
the elements gk with k odd and such that 2d|r; the second consisting of the elements
gk with k even and 2d ∤r.
Proof Consider the element gk with k odd. From (gk)r = gkr ∼= 1(mod pα) and
from gφ(pα) ∼= 1 (mod pα), it follows that kr ≥φ(pα) since φ(pα) is the order of
g ∈Z∗
pα. Now if kr > φ(pα), we could perform the division of kr by φ(pα) and write
kr = qφ(pα) + s with 0 ≤s < φ(pα); it would follow that gkr = gqφ(pα)gs ∼=
gs ∼= 1 (mod pα). Then s = 0 because φ(pα) is of the order of g. So kr = qφ(pα)
and, since k is odd, the factor 2d must be contained in r: 2d|r. Consider now the case
when k is even. Then g
k
2 φ(pα) ∼= 1(mod pα); since φ(pα)
2
≥r, we divide φ(pα)
2
by r
and write φ(pα)
2
= qr + s, with s < r. It follows that gk(qr+s) ∼= (gk)s ∼= 1(mod pα).

246
6
Digital and Quantum Computers
Thus, s = 0, since the order of gk is r and r| φ(pα)
2
. If now 2d|r, from φ(pα) = 2qr
it would follow that φ(pα) is a multiple of 2d+1, contrary to the hypothesis. We
conclude then that 2d ∤r.
The simplest example is provided by the multiplication Table6.17 of Z∗
9. Since
9 = 32, we have p = 3, α = 2 φ(32) = 6, g = 2, 2d = 2, d = 1. The order r of
the element gk (mod 9) is shown in Table6.17 (of course, 24 ∼= 7 and 25 ∼= 5 modulo
9, etc.). From the table we see that if k is odd, r is even, and if k is even, r is odd;
therefore if k is odd, 2d = 2 and 2|r, if k is even 2d ∤r. In the general case, choosing
an element gk ∈Zpα at random, the probability is 1
2 that 2d divides r, and 1
2 that 2d
does not divide r.
The following theorem concerns the prime factorization N = pα1
1 pα2
2 . . . pαm
m of
an odd integer N. For simplicity, we will treat the case m = 2, but generalization to
arbitrary values of m is straightforward.
Theorem 6.9 Let N = pα1
1 pα2
2 with primes p1, p2. Choosing at random a number
x ∈Z∗
N, the probability that the order r of x is even is p ≥3
4.
Proof Consider the following equations:
x = a1(mod pα1
1 ),
x = a2 (mod pα2
2 ).
(6.137)
Applying the Chinese remainder theorem, a random choice x ∈Z∗
N is equivalent
to a random choice a1 ∈Z∗
p
α1
1 , a2 ∈Z∗
p
α2
2 . Denoting by r1, r2 the orders of a1, a2,
respectively, let us prove ﬁrst that r1|r and r2|r. There exist three integers a, b, c such
that
xr = 1 + pα1
1 pα2
2
= 1 + bpα1
1 ,
b = apα2
2 ,
xr = 1 + pα1
1 pα2
2
= 1 + cpα2
2 ,
c = apα1
1 .
(6.138)
However ar
1 ∼= xr(mod pα1
1 ) and ar
2 ∼= xr(mod pα2
2 ). Therefore, from Eq.(6.138) it
follows that
ar
1 ∼= 1(mod pα1
1 ),
ar
2 ∼= 1(mod pα2
2 ).
(6.139)
Then r must be a multiple of r1 and r2, that is, r1|r, r2|r. It follows that if r is odd,
both r1 and r2 are odd. Now, what is the probability that r1 is odd? At ﬁrst sight, from
Lemma6.3 it would appear that this probability is 1
2, but this is true only if φ(pα1
1 )
is even but not divisible by 2d with d > 1. Note that the same property follows for
p1 −1 which is a factor of φ(pα1
1 ) = p(α1−1)
1
(p −1). If, for example, 2d = 4, and
4|(p −1), it is possible that r1 is even but not a multiple of 4. In this way, the number
Table 6.17 Multiplication
table for Z∗
9
k
1
2
3
4
5
6
gk (mod 9)
2
4
8
7
5
1
r
6
3
2
3
6
1
kr
6
6
6
12
30
6

6.10 Some Results from Number Theory
247
Table 6.18 Multiplication
table for Z∗
5
1
2
3
4
2
4
1
3
3
1
4
2
4
3
2
1
of cases for which r1 is even would be greater than φ(pα1
1 )/2. A simple example
showing this possibility is the following: choose p1 = 5, α1 = 1, then φ(p1) = 4.
The multiplication Table6.18 shows that the orders of 1, 2, 3, 4 are, respectively,
r1 = 1, r2 = 4, r3 = 4, r4 = 2. In this elementary example, we see that the order r is
even in 3 cases out of 4, but only in 2 cases 4|r. Because the argument is of general
nature (applying also to pα2
2 and r2), we have
Probability{r1 odd} ≤1
2,
Probability{r2 odd} ≤1
2
(6.140)
and therefore Probability{r odd} ≤1
4, thus proving the theorem.
Inconclusionandsummary,tofactorizealargenumber N,thefollowingalgorithm
has a high probability of success:
(1) If N is even, a factor is 2 and we start from N/2.
(2) Randomly choose x in the interval 1 < x < N −1.
(3) Compute y = gcd(x, N); if y > 1, then y is a factor of N.
(4) If y = 1, x and N are coprime, then compute the order r of x modulo N.
(5) If r is odd, choose another x.
(6) If r is even, compute gcd(xr/2 −1, N) and gcd(xr/2 + 1, N). According to
Lemma6.2, at least one of these two numbers is a nontrivial factor of N.
Two elementary examples: Example (1): N = 21, p1 = 3,
p2 = 7. Table6.19
shows,foreachvalueof x inrange1 < x < 20,thevaluesofr,r/2,and xr/2(mod 21),
when r is even.
Note that for x = 2, xr/2 ∼= 8, xr/2 −1 = 7, and 7|N; analogously for xr/2 ∼= 13,
xr/2 + 1 = 14, and gcd(14, 21) = 7; instead, if xr/2 ∼= 20 ∼= −1 (mod N), xr/2 +
1 = N is a trivial factor of N. Example (2): N = 35, p1 = 5, p2 = 7. Table6.20
shows, for 1 < x < 34, the values of r, r/2 and xr/2(mod 35), when r is even.
Table 6.19 Factorization for N = 21
x
2
4
5
8
10
11
13
16
17
19
20
r
6
3
6
2
6
6
2
3
6
6
2
r/2
3
3
1
3
3
1
3
3
1
xr/2(mod 21)
8
20
8
13
18
13
20
13
20

248
6
Digital and Quantum Computers
Table 6.20 Factorization for N = 35
x
2
3
4 6
8
9 11 12 13 16 17 18 19 22 23 24 26 27 29 31 32 33
r
12 12
6 2
4
6
3 12
4
3 12 12
6
4 12
6
6
4
2
6 12 12
r/2
6
6
3 1
2
3
6
2
6
6
3
2
6
3
3
2
1
3
6
6
xr/2(mod 35) 29 29 29 6
29 29
29 29
29 29 34 29 29 34
6 29 29
6 29 29
From Table6.20, we see that, quite frequently, xr/2 ∼= 29; then xr/2 −1 = 28,
and gcd(28, 35) = 7. In three cases xr/2 ∼= 6: then xr/2 + 1 = 7, xr/2 −1 = 5, both
factors of 35. Finally, for xr/2 ∼= 34 we obtain the trivial factor xr/2 + 1 = 35.
When, as is necessary in effective cryptography, N is very large, gcd(xr/2 ± 1, N)
can be computed using the Euclidean algorithm. Then the algorithm (1) …(6) can
be used only if we have an efﬁcient method of ﬁnding the order r.
6.10.8
Quantum Order Finding
We consider next a quantum algorithm (essentially Shor’s algorithm10) for ﬁnding the
order; this algorithm is, at least in principle, much more efﬁcient than any algorithm
performed by a classical computer.
Let N be a positive integer that can be written in binary notation with L digits.
More precisely, we assume 2L−1 < N < 2L. Consider the M-dimensional Hilbert
space CM, with M = 2L. In this space we take a canonical basis whose elements are
labeled by an integer y ≤M. For any x coprime with N and such that 1 < x < N,
we deﬁne a unitary operator Ux from CM to CM as follows:
Ux|y⟩=

|xy(mod N)⟩if 1 ≤y ≤N −1,
|y⟩otherwise.
(6.141)
Example: Let N = 5, x = 2, L = 3, M = 8. The relevant part of the matrix U2 is
the ﬁrst 4 × 4 block:
U2 =


0 0 1 0 0 0 0 0
1 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0
0 1 0 0 0 0 0 0
0 0 0 0 1 0 0 0
0 0 0 0 0 1 0 0
0 0 0 0 0 0 1 0
0 0 0 0 0 0 0 1


.
(6.142)
Since our “clock” has now N = 5 elements, we have U2|1⟩= |2⟩, U2|2⟩= |4⟩,
U2|3⟩= |6 (mod 5)⟩= |1⟩, U2|4⟩= |8 (mod 5)⟩= |3⟩, U2|y⟩= |y⟩for
10Shor P W (1997) Polynomial-time Algorithms for Prime Factorization and Discrete Logarithms
on a Quantum Computer Siam J Comp 26:1484–1509.

6.10 Some Results from Number Theory
249
5 ≤y ≤8. We see in this example (which we claim is generally valid) that the
matrix Ux performs a permutation of the basis vectors. Therefore, when N is large,
these matrices represent permutations of the numbers of a huge “clock with N hours.”
At ﬁrst glance it might seem that the calculation of the order r implies the compu-
tation of very large powers of enormous matrices. Fortunately, there is a better proce-
dure, which exploits some properties of the eigenstates of Ux. For any 0 ≤s ≤r −1,
we deﬁne the state:
|us⟩=
1
√r
r−1

k=0
e−2πisk
r |xk(mod N)⟩.
(6.143)
We require the following lemma.
Lemma 6.4 |us⟩is an eigenstate of Ux corresponding to the eigenvalue e
2πis
r .
Proof First note that
Ux|us⟩=
1
√r
r−1

k=0
e−2πisk
r Ux|xk(mod N)⟩=
1
√r
r−1

k=0
e−2πisk
r |xk+s(mod N)⟩.
(6.144)
Setting h = k + 1,
Ux|us⟩=
1
√r
r
h=1 e−2πish
r e
2πis
r |xh(mod N)⟩=
e
2πis
r
1
√r
r
h=1 e−2πish
r |xh(mod N)⟩=
e
2πis
r
1
√r
r−1
h=0 e−2πish
r |xh(mod N)⟩= e
2πis
r |us⟩,
(6.145)
where, in the last sum, we used the fact that the terms with h = 0 and h = r are both
equal to |1⟩, which proves the lemma.
TheoperatorUx isunitary,sinceitperformsapermutationofanorthonormalbasis;
in fact, the eigenvalues λs = e
2πis
r
have moduli |λs| = 1 and the eigenvectors |us⟩are
orthonormal. A useful identity satisﬁed by the eigenvectors |us⟩is the following:
1
√r
r−1

s=0
|us⟩= |1⟩.
(6.146)
To prove Eq.(6.146), note that
1
√r
r−1

s=0
|us⟩=
1
√r
r−1

s=0
1
√r
r−1

k=0
e−2πisk
r
|xk mod N⟩.
(6.147)
We ﬁrst do the sum Sk = r−1
s=0 e−2πisk
r
and denote by zk = e−2πik
r , k = 0, 1, 2, . . . ,
r −1, the r solutions of the equation zr = 1. If k ̸= 0, the sum Sk vanishes:

250
6
Digital and Quantum Computers
Sk = 1 + zk + z2
k + z3
k + · · · + zr−1
k
= zr
k −1
zk −1 =
0
zk −1 = 0.
(6.148)
If k = 0, S0 = r−1
s=0 1 = r, and we can write
1
√r
r−1

s=0
|us⟩=
1
√r
1
√r r |x0(mod N)⟩= |1⟩.
(6.149)
Thus Eq.(6.146) is proved. However, the state |1⟩is not an eigenvector of Ux but
rather a sum of eigenvectors. Let us see what happens if we apply the phase estimation
algorithm and implement the circuit shown in Fig.6.40 with U = Ux, |u⟩= |1⟩, and
φ = 2πs
r ; then eiφy = ei 2πs
r y. Thereby Eq.(6.74) gives the following output:
|OUT2⟩=
1
√r
r−1

s=0
1
√
2n
2n−1

y=0
ei 2πs
r y |y⟩⊗|us⟩.
(6.150)
Let us see how we can now get information about the order r. Setting,
|v( s
r )⟩=
1
√
2n
2n−1

y=0
ei 2πs
r y |y⟩,
(6.151)
Equation(6.150) becomes
|OUT2⟩=
1
√r
r−1

s=0
|v( s
r )⟩⊗|us⟩.
(6.152)
Now let us apply the inverse Fourier transform U −1
F
to |v( s
r )⟩. Using Eq.(6.79) we
ﬁnd
U −1
F |v( s
r )⟩= 2n−1
y=0
2n−1
k=0 |y⟩⟨y|U −1
F |k⟩⟨k|v( s
r )⟩=
2n−1
y=0
2n−1
k=0
1
√
2n ω−yk
2n
1
√
2n ei 2πs
r k |y⟩= 2n−1
y=0
1
2n
2n−1
k=0 e2πik( s
r −y
2n )|y⟩,
(6.153)
since ω2n = e
2πi
2n . Expression (6.153) is the output of the ﬁrst register of the quantum
circuit shown in Fig.6.44.
Suppose now that we measure the state (6.153) by taking its projection onto the
state |b⟩, where 1 ≤b ≤2n is a binary number. The probability amplitude |cb| for
obtaining the result b is given by
cb
 =
 < b|UF−1|v( s
r )⟩
 =
1
2n

2n−1

k=0
e2πik( s
r −b
2n )
 .
(6.154)

6.10 Some Results from Number Theory
251
Fig. 6.44 The second register (the lower lines) corresponds to the eigenstate |1⟩=
1
√r
r−1
s=0 |us⟩∈C M
Setting δ = s
r −b
2n , α = e2πiδ, the last expression becomes identical with Eq.(6.84),
and can be approximated in the same way. If b
2n = s
r , |cb| is equal to 1. Otherwise,
when | b
2n = s
r | = δ
′ <
1
2n , the behavior of |cb| is given by Eq.(6.88):
|cb| ≃1 −1
6 π2δ
′2.
(6.155)
This method would then give a good approximation for s
r . The width of the maximum
of |cb| for δ
′ = 0 is of the order of 1
2n .
Before proceeding with the description of an algorithm (continued fractions) to
ﬁnd the order r, let us brieﬂy review the various quantities involved:
(1) The number of the qubits measured by the quantum circuit is n.
(2) The measured result b satisﬁes b ≤2n.
(3) Our “clock” has N “hours” since the operator Ux sends the vector
|y⟩
to
|xy(mod N)⟩.
(4) N can be written with L binary digits, so that 2L−1 ≤N ≤2L.
(5) The order r obeys the inequality r ≤n. Therefore, r ≤N ≤2L. Our choice of
n depends on the computing power of the apparatus, the larger n, the more accurate
the result. From (5), we have 2r2 ≤22L+1. If we choose n = 2L + 1, we ﬁnd the
following inequality, which will be useful below:
2r2
≤2n.
(6.156)

252
6
Digital and Quantum Computers
6.10.9
Continued Fractions
These are expressions of the following form:
x = a0 +
1
a1 +
1
a2 +
1
a3 + · · ·
(6.157)
where a0, a1, a2, . . . are positive integers. Continued fractions have the following
properties (stated without proof):
(1) A continued fraction is ﬁnite if and only if x is a rational number.
(2) The continued fraction of an irrational number is unique.
(3) The continued fraction of a rational number is unique except for alternative ways
of writing the last term.
The continued fraction representing a number x can be constructed by iteration
with the following steps:
(a) Take the integer part a of the number x.
(b) Write the fractional part d of x as a fraction 1/ 1
d .
For example, the irrational number π = 3.1415926 . . . , which we approximate by
3.141, is to be expressed as a ﬁnite continued fraction. We carry out the successive
steps:
π ≃3.141 = 3 + 141
1000 = 3 +
1
1000
141
= 3 +
1
7 + 13
141
=
3 +
1
7 +
1
141
13
= 3 +
1
7 +
1
10+ 11
13
= 3 +
1
7 +
1
10+
1
1+
1
5+ 1
2
(6.158)
Neglecting the last fraction 1
2, we obtain the approximation π =
1448
461 ≃3.14099.
Note that, since the continued fractions expansion is essentially unique, it can be
applied to reduce a fraction to lowest terms.
We state, again without proof, a theorem on continued fractions:
Theorem 6.10 Suppose s/r is a rational number such that
s
r −φ
 ≤
1
2r2 ,
(6.159)
then the continued fraction expansion of φ is equal to s
r .
Let us apply the theorem, setting φ = b
2n where b is the number measured by the
quantum circuit of Fig.6.44. Changing b by one unit, changes φ to
1
2n ; then from

6.10 Some Results from Number Theory
253
Eq.(6.156), it follows that 1
2n ≤
1
2r2 , so the condition (6.159) is satisﬁed, which allows
us to determine the fraction s
r and then the order r.
6.10.10
Prime Number Theorem
Consider now the following question: Does there exist an expression for the asymp-
toticdistributionofprimenumbers?Or,roughlyspeaking,forlarge x,canweevaluate
the probability p(x) that a number chosen in a neighborhood of x is prime? This
question is addressed by the prime number theorem, which we state without proof:
Theorem 6.11 Let x a positive real number, and let π(x) equal the number of prime
numbers less than x. We have, in the limit as x →∞:
lim
x→∞
π(x)
(
x
loge x ) = 1.
(6.160)
Therefore, for large x we can write
π(x) ≃
x
loge x ,
(6.161)
an approximation conjectured independently by Legendre and Gauss.
We recognize, of course, that
x
loge x is a continuous differentiable function, while
π(x) is stepwise discontinuous. For example, for x = 109, it is known that π(x) =
50847534. Since loge x ≃20.72326584, π(x)/
x
loge x ≃1.0537, which does not differ
very much from 1. Let x be an integer randomly chosen in a neighborhood of 109 (we
do not choose 109 itself, which is not a prime). We want to evaluate approximately the
probability p(x) that x is prime. Consider the function y(x) =
x
loge x ; we know from
the prime number theorem that y(x) is a good approximation of π(x) for large x.
We have
dy
dx =
1
loge x + x d
dx
	
1
loge x

=
1
loge x −
1
(loge x)2 , ≃
1
loge x ,
(6.162)
since for large x, (loge x)−2 is negligible compared to (loge x)−1
(for x = 109,
the two numbers are, respectively, 0.0023 and 0.0482). We can imagine the prime
numbers as points lying on the positive real axis. A ﬁrst approximation of the density
of these points is given by Eq.(6.162). Choosing an interval {x, x + Δx} such that
1 << Δx << x, we can say that an approximate value of the number Δπ of primes
contained in the range Δx is given by
Δπ = Δπ
Δx Δx ≃dy
dx Δx ≃
1
loge x Δx.
(6.163)

254
6
Digital and Quantum Computers
Therefore the probability p(x) that x is prime is
p(x) ≃Δπ
Δx ≃
1
loge x .
(6.164)
For example, for x ≃109, p(x) ≃0.048, and for x ≃2L = 2100, p(x) ≃0.0144.
There exist primality tests to determine whether a number is prime or not. One
of the best known is the Miller–Rabin test,11 which takes about O(L3) operations
for a number with L bits. Assuming that L = 100, O(L3) = O(106), we see that
the order of magnitude of the number of trials necessary to ﬁnd a prime with 100
bits is
106
p(2100) ≃
106
0.0144 ≃6.9 × 107, so such a calculation is within current capability.
It is much more difﬁcult to ﬁnd a prime with 1000 bits, which involves about 1011
operations.
There exist methods that produce large primes, such as the progression (Perichon,
2010)12:
p = f (n) = 43142746595714191 + 5283234035979900 n for n = 0, 1, 2, . . . , 25
(6.165)
but these are dangerous to use as prime factors to encrypt a message, because they
are too well known.
6.11
Quantum Cryptography
Since time immemorial, people have been exchanging encrypted messages, which are
devised so as to be understood only by the sender and recipient; even if a message
were intercepted, it would hopefully remain incomprehensible to a third person.
The science of cryptography deals with the design of efﬁcient methods to create
such ciphers. During the Second World War, the use of encrypted messages became
essential for tactical military and naval communications. Thanks to the brilliant work
of the Cambridge mathematician Alan Turing, messages encrypted by the Germans
(using the Enigma machine) were deciphered by the Allies, which certainly shortened
the war.
A message can be conveniently schematized as an integer M smaller than a max-
imum NMAX (recall that the letters a, b, c, …can be coded as integers, such as 1,
2, 3, …). The encrypted message E(M) is an integer, obtained by applying to M a
complicated operator E, usually exceedingly nonlinear. The inverse operation D is
deﬁned by
D[E(M)] = M,
∀M < NMAX.
(6.166)
11Miller GL (1976) Journal of Computer and System Sciences 13:300; Rabin MO (1980) Journal
of Number Theory 12:128.
12Euler noted in 1772 that the quadratic polynomial pn = n2 + n + 41 is prime for all n < 40.

6.11 Quantum Cryptography
255
The inverse operator D must exist, but must be very difﬁcult to ﬁnd, making it
almost impossible to decipher the message. In the past several years, methods have
been proposed in which both the encrypted message E(M) and the operator E can
be made publicly available, while the plaintext M remains almost impossible to
retrieve. The best known of these methods was invented in 1978 by Rivest, Shamir,
and Adleman (RSA) (Rivest et al. 1978). The RSA algorithm is so powerful because
a classical computer might be able to determine the operation D only after running
an astronomically long period of time. However, a quantum computer could, in
principle, decrypt the message much more rapidly.
6.11.1
RSA Cryptography
A message can be compactly modeled as an integer M written in binary digits. We
also agreed to denote by E(M) the encrypted message. A trivial method to encrypt
M consists in choosing an integer C and put E(M) = M + C; clearly in this case
the decryption is obtained simply by M = E(M) −C.
The RSA method is based on the existence of two ciphers, or distinct keys, one
public P and one secret S. Everyone can have access to the key P. Suppose that among
them is Bob, who wants to send a secret love letter to Alice. He wants only her to be
able to decipher the message; to do this, Alice knows the secret key S (and only she
knows it). As a less romantic example, Bob might be an account holder in a bank of
which Alice is the director.
Let us see how Alice can make it almost impossible for a “spy” who has gained
possession of the ciphertext E(M) to read the original message M. Alice can do the
following:
(1) Choose two extremely large primes p, q.
(2) Compute their product n = pq, and the totient φ(n) = (p −1)(q −1).
(3)Chooseatrandomasmalloddintegere,suchthatgcd(e, φ(n)) = 1(thatis,e, φ(n)
must be coprime).
(4) Compute d, the multiplicative inverse of e ∈Z∗
n, such that de=ed=1(mod φ(n)).
The public key P is the pair (e, n); the secret key is simply the number d. The message
M is encrypted by Bob in the following way:
E(M) ∼= Me(mod n).
(6.167)
From the above deﬁnition, it follows that if the integer e were very large, the calcu-
lation of E(M) would be almost impossible by classical computation.
Let us prove that Alice can decrypt E(M), simply raising it to the power d
modulo n. Consider the simplest case, in which M is coprime with n. We have
E(M)d ∼= Med(mod n).
(6.168)
But, by virtue of step (4) above, ed = 1 + kφ(n), where k is any integer. Therefore

256
6
Digital and Quantum Computers
E(M)d ∼= M1+kφ(n)(mod n) = M Mkφ(n) (mod n).
(6.169)
Now apply Eq.(6.133) for the totient, with a = M. We obtain Mφ(n) ∼= 1(mod n);
then Eq.(6.169) becomes
E(M)d ∼= M1k(mod n) = M,
(6.170)
since M < n. This can also be written as
M ∼= E(M)d(mod n).
(6.171)
In the case in which M and n are not coprime, for example p|M but q ∤M, then
M ∼= 0(mod p) and therefore,
Med ∼= 0 ∼= M(mod P).
(6.172)
From q ∤M follows that Mq−1 ∼= 1 by Fermat’s little theorem. Then,
Med = M1+kφ(n) = M Mk(p−1)(q−1) ∼= M(mod q).
(6.173)
From Eqs.(6.172) and (6.173), and applying the Chinese remainder theorem, we
deduce that
Med ∼= M(mod pq) ∼= M(mod n).
(6.174)
We cannot have both p|M,
q|M, because that would imply n|M, while we
know that n > M. Therefore, the simple operation of raising to the d power can
decipherthemessage E(M).Suchanoperationwouldbeeasyforamoderncomputer.
Suppose, for example, that the number of binary digits of n is 100. So n ≤2L =
2100 ≃1.2676 × 1030. How many operations will we have to perform? Since d < n,
d has no more than 100 binary digits. We can write
d = d0 + 2d1 + 4d2 + · · · + 2L−1dL−1 = (d0, d1, d2, . . . , dL−1).
(6.175)
Therefore, setting x = E(M), we can readily compute the powers x2, x4 = (x2)2,
x8 = (x4)2, . . . modulo n. In this way we can compute, for any x < n:
xd(mod n) = xd0(mod n)x2d1(mod n)x4d2 (mod n) . . . x2L−1dL−1(mod n), (6.176)
performing L −1 multiplications modulo n. Now, each multiplication of two num-
bers of L bits involves approximately L2 operations. The order of magnitude of
the number of operations to compute the expression (6.176) is then O(L3) = 106,
which is easy for a modern computer. Note that even if E(M) is 103 bits long, the
decryption can still be done without difﬁculty. As pointed out by Nielsen and Chuang:

6.11 Quantum Cryptography
257
Fig. 6.45 Transmission of
message from Bob to Alice
using RSA encryption.
Publicly available
information is shown in
green, private information, in
red
“the main bottleneck is the generation of the numbers p and q,” that must be very,
very large.
A simple example of the RSA procedure is illustrated in Fig.6.45. Let the secret
prime factors be p = p200 = 1223 and q = p150 = 863. Then, n = 1223 × 863 =
1055449 and φ(n) = (p −1)(q −1) = 1053364. Also choose e = 17. Thus the
public key is (1055449, 17). The private key d is the smallest integer satisfying de ∼=
1 (mod φ(n)), which gives d = 309813. Suppose Bob wishes to transmit the plaintext
message“A&B”;convertedtoASCIIcodethismightberepresentedby M = 653866.
The encrypted message (ciphertext) is then given by E(M) ∼= Me(mod n) = 22136,
which can be openly transmitted to Alice. She decodes the message using M ∼=
E(M)d(mod n) = 653866, which is the ASCII code for A&B.
6.11.2
Code Breaking
It is, of course, relevant to explore the possibilities of breaking RSA encryption:
how can we decrypt a message Me(mod n) knowing only e and n? We will describe
two possible methods, the ﬁrst based on order ﬁnding, the second on factoring the
number n; both methods are very difﬁcult to implement on a classical computer
(recalling that n is very very large).
(1) Method based on order ﬁnding. Suppose we know the order r, the smallest
integer such that
(Me)r ∼= 1(mod n).
(6.177)
Assume Me and n are coprime. Otherwise, n can be factored and we can go to step
(2). By Euler’s theorem for the totient, we have
(Me)φ(n) ∼= 1(mod n).
(6.178)

258
6
Digital and Quantum Computers
From Eqs.(6.177) and (6.178) it follows r|φ(n). We also know by Alice’s choice (3)
that gcd(e, φ(n)) = 1. Since r is a factor of φ(n), it will also be true that
gcd(e,r) = 1. Noting Eqs.(6.171) and (6.174), e admits an inverse d′(mod r),
given by
ed′ = 1 + kr.
(6.179)
Then to decrypt the message Me, just raise it to the power d′; in fact we can write
(Me)d′(mod n) = M1+kr(mod n) ∼= M Mkr(mod n) ∼= M(Mr)k(mod n) ∼= M1k = M.
(6.180)
(2) Method based on factoring. Suppose we succeed in factoring n, then we know
p and q. By simple multiplication we ﬁnd φ(n) = (p −1)(q −1) and then we get d
by solving the equation de ∼= 1(mod φ(n)). Knowing d, we can decrypt the original
message by raising Me to the d power (see Eq.6.174)13:
(Me)d ∼= M(mod n).
(6.181)
Perhaps the reader will wonder whether it is possible to ﬁnd r simply raising Me to
a large number of powers m(mod n), which involves computing:
(Me)m(mod n)
for
m = 2, 3, . . . , n,
(6.182)
until the result 1(mod n) is obtained. In principle, this is possible, but in practice,
when n is very large, the calculation becomes prohibitively long. If, however, we
know the exponent d in advance and we want to compute (Me)d, just use the method
of repeated squaring (see Eq.6.176), so that the number of operations will be reduced
from order n to order log2 n.
Based on what we discussed in the preceding pages on factoring numbers and
quantum order ﬁnding, if we had a quantum computer able to calculate the powers
Ux, Ux 2, Ux 4, . . . ,Ux 2L with L ≃1000, we could solve the problem of deciphering
encrypted messages in use today.
Appendix
We now present a proof of Theorem 6.8 on p.245. As a preliminary:
Remark 6.1 The condition for g to be a generator is equivalent to the equality of
the orders of g and G. Moreover, if g is an element of order d then the group H
generated by g is isomorphic to Z/d.
13It is possible to prove that d = d
′(mod r).

Appendix
259
Proof We denote by |G| the order of G, and by o(g) the order of g. Let g be any
element of G, and let m = o(g). Choosing two integers a, b, such that 1 ≤a < b ≤
m, the powers ga, gb are distinct, since from ga = gb it will follow gbg−a = gb−a =
e. But this is absurd since b −a < m. In other words, the powers g, g2, . . . , gm = e
are all distinct elements of the group H generated by g, which therefore has at least
m elements. On the other hand, if we continue to multiply by g, the higher powers
gm+1 = g, gm+2 = g2, . . . repeat cyclically. This means that the elements listed
above cover the whole H, so that |H| = m. Saying that g generates G is equivalent
to the identity H = G, and because G is ﬁnite this is equivalent to |G| = |H| = m.
Moreover, if a = b (mod m), then one can write a = b + hm for some integer
h, so ga = (gm)hgb, and because gm = e one has ga = gb. This is to say that, if
we think of a as an element of Z/m, the element ga is well posed. This gives a
bijection between H and Z/m. Also, because ga+b = gagb, the bijection respects
the operations, so it is an isomorphism.
Next, we address the theorem itself:
Theorem 6.8 Suppose that p > 2 is a prime, and that α is a positive integer. Then
the multiplicative group

Z/pα∗is cyclic.
In order to prove the theorem we will need an additional property of Z/p. This
object belongs to a particular class of rings, called ﬁelds, which enjoy many useful
properties, one of which is given by the next lemma. (Roughly speaking, a ﬁeld is
a set on which are deﬁned addition, subtraction and multiplication, for example, the
real numbers: R or and the complex numbers C. See also footnote on p. xxx.)
Lemma 6.5 If F is a ﬁeld and r is a positive integer, then there exist at most r
distinct values of x ∈F satisfying xr = 1.
In R the equation xr = 1 has exactly one solution if r is odd, and two solutions if
it is even; in C it is well known that the equation has exactly r solutions, namely the
complex roots of unity. When F = Z/p, the lemma states that there exist at most r
distinct (modulo p) solutions of the equation
xr ≡1
(mod p)
(6.183)
In the course of the proof of Theorem 6.8 we will also make use of the following
two lemmas:
Lemma 6.6 Let G be an abelian group, g and h elements of G, of order respectively
a and b. If a and b are coprime, the order of gh is ab.
Proof Since (gh)ab = gabhab = (ga)b(hb)a = e · e = e, ab is a multiple of the order
m of gh. We need to prove that m = ab. From (gh)m = e it follows gm = h−m. We
denote by X the order o(gm) = o(h−m). From Lagrange’s theorem (Theorem 6.6)
and 1 = (ga)m = (gm)a it follows that X|a. Analogously X|b, and if a and b are
coprime, X = e. Then:
e = (gm)X = gm,
e = (h−m)X = h−m,
(6.184)

260
6
Digital and Quantum Computers
that is gm = hm = e, thus a|m and b|m. Therefore, m must contain all prime factors
of a and all prime factors of b, and because all these factors are distinct, ab|m, thus
m ≥ab. On the other hand, since m|ab, m ≤ab. It follows that m = ab and the
lemma is proved.
Lemma 6.7 Let G be an abelian group, g ∈G and o(g) = m, and d a divisor of
m, then o[gm/d] = d.
Proof [gm/d]d = gm = e . We need to prove that it is not possible for [gm/d]l = e
with l < d. Indeed if 1 ≤l < d, from gml/d = e, it would follow gm′ = e with m′ =
ml/d < m, i.e. o(g) < m, in contradiction to the assumption. The lemma is proved.
Finally, we can turn to the proof of Theorem 6.8:
Proof Our goal is to show that there exists an integer z whose order modulo pα
equals the order of (Z/pα)∗, which is φ(pα) = (p −1)pα−1. We shall ﬁrst argue
that the conclusion holds if the two following conditions are fulﬁlled:
• There exists an element x ∈(Z/pα)∗of order pα−1;
• There exists an element y ∈(Z/pα)∗of order p −1.
In this case, the orders of x and y are coprime, because the only prime factor of
pα−1 is p, which does not divide p −1. Lemma 6.6 implies then that xy has order
(p −1)pα−1 and is therefore a generator, as desired.
Now we need to prove the two conditions above. For the ﬁrst, we argue by induc-
tion that, for every non-negative integer h, the highest power of p that divides
(p + 1)ph −1 is ph+1. If this is true, for h = α −1 it follows that pα divides
(p + 1)pα−1 −1, which is to say that (p + 1)pα−1 = 1 (mod pα). On the other hand,
for h < α −1 this implies that pα does not divide (p + 1)ph −1. Therefore, the
order of p + 1 modulo pα is pα−1, and one can choose x = p + 1.
Note that the statement above is trivial for h = 0, as the highest power of p
dividing (1 −p)p0 −1 is clearly p itself. If the statement holds for h, then there
exists some integer a, prime with p, such that
(p + 1)ph = 1 + aph+1.
(6.185)
One can then use Newton’s binomial theorem for the expansion:
(p + 1)ph+1 = (1 + aph+1)p =
p

j=0
	p
j

a j p j(h+1).
(6.186)
The summand corresponding to j = 0 equals 1, and by separating the ﬁrst few terms
of the sum one can write:

Appendix
261
(p + 1)ph+1 −1 = paph+1 + p(p −1)
2
a2 p j(h+1) +
p

j=3
	p
j

a j p j(h+1) =
= aph+2 + a(p −1)
2
p j(h+1)+1 +
p

j=3
	p
j

a j p j(h+1).
(6.187)
It is easily seen that ph+3 divides all the summands in this expression except for the
ﬁrst, which is only divisible by ph+2. This proves that the whole sum is divisible by
ph+2, but not by ph+3, which completes the induction, and the existence of x.
The last point to check is that there exists y of order (p −1). We shall ﬁrst prove
this for α = 1, and then deduce the general result from this case. Our aim is now to
show that there exists an element of (Z/p)∗of order p −1: to this end we shall count
the elements of lower order and show that they are fewer than |(Z/p)∗|. First of all,
note that if there are elements in (Z/p)∗of order d, then by Lagrange’s theorem,
d|(p −1). Given such a d, we claim that the number hd of elements of order d is at
most φ(d). The claim is clearly veriﬁed if there are no such elements; otherwise let
g be an element of order d. By our remark above, the subgroup ⟨g⟩generated by g
has exactly d elements, and since they all belong to a group of order d they all satisfy
the equation xd = e. Lemma 6.5, on the other hand, implies that this equation has
at most d solutions in Z/p, and therefore they are exactly the elements of ⟨g⟩. This
shows that all the elements of order d in (Z/p)∗are all contained in ⟨g⟩, and therefore
they can be characterised as the generators of this subgroup. Again according to the
remark, ⟨g⟩can be seen as a copy of Z/d, which has exactly φ(d) generators. This
proves that either hd = 0 or hd = φ(d); in either case hd ≤φ(d). Therefore, the
total number of elements of (Z/p)∗which are not generators is:

d|(p−1)
d<p−1
hd ≤

d|(p−1)
d<p−1
φ(d)
(6.188)
For example, if p = 11, p −1 = 10, the divisors d are 1, 2, 5, 10, and the orders hd
are:
h(1) = 1 (only the element 1)
h(2) = 1 (only the element 10)
h(5) = 4 (elements 3, 4, 5, 9)
h(10) = 4 (elements 2, 6, 7, 8)
The generators of G are the elements 2, 6, 7, 8 as their order is 10.
To conclude the case α = 1 it is enough to establish that the sum on the right
hand side is strictly smaller than p −1. This can be done by comparison with the
cyclic group Z/(p −1). Indeed, ﬁx d < p −1, which divides p −1, and let a =
(p −1)/d. The subgroup ⟨a⟩of Z/(p −1) generated by a is a cyclic group of
order d, and has therefore φ(d) generators. On the other hand, if k is any other
element of Z/(p −1) of order d one has that dk = 0 (mod p −1), which means
k = 0 (mod a), so that a|k. Therefore ⟨a⟩contains all the elements of order d in

262
6
Digital and Quantum Computers
Z/(p −1), so there are exactly φ(d). This means that the sum on the right-hand side
of (6.188) gives an exact count of the number of elements of Z/(p −1) of order
lower than p −1, which is to say the elements of this group which do not generate
it. But since this group is cyclic, and hence it does have generators, the value of this
sum has to be smaller than the order of Z/(p −1). This proves that the number of
elements of (Z/p)∗which are not generators is smaller than the order of the group,
thus a generator has to exist. To conclude the proof for α > 1, let ˜y be an integer
which generates (Z/p)∗, which has been established to exist. Note that the condition
˜yn = 1 (mod pα) means that pα|( ˜yn −1), so in particular p|( ˜yn −1) and therefore
˜yn = 1 (mod p). This proves that the order of ˜y modulo pα is a multiple of that
modulo p, which is p −1. Furthermore, o( ˜y) divides the order of (Z/pα)∗, which is
(p −1)pα−1. It follows that o( ˜y) is of the form (p −1)pl for some 0 ≤l < α. If we
put y = ˜y pl, it is clear that y p−1 = ˜y(p−1)pl = 1 modulo pα, and if n < (p −1) then
yn ̸= 1 modulo pα because npl < (p −1)pl, which is the order of ˜y. This proves
that o(y) = p −1 and establishes the second point. Thus, Theorem 6.8 is proved.

Bibliography
Accardi L (1995) Can mathematics help solving the interpretational problems of quantum theory?
Il Nuovo Cimento 110B:685–721
Aspect A, Grangier P, Roger G (1981) Experimental tests of realistic local theories via Bell’s
theorem. Phys Rev Lett 47:460–463; Aspect A, Dalibard J, Roger G (1982) Experimental test of
Bell’s inequalities using time-varying analyzers. Phys Rev Lett 49:1804–1807
Avogadro A (1834) Nouvelles recherches sur la chaleur speciﬁque des corps solides et liquides.
Crochard, Paris
Bell JS (1964) On the Einstein–Podolsky–Rosen Paradox. Physics 1:195–2001
Bell JS (1987) Speakable and unspeakable in quantum mechanics. Cambridge University Press,
Cambridge
Bohm D (1951) Quantum Theory. Prentice-Hall, Englewood Cliffs NJ, Sections 5:19
Bohr N (1913) On the constitution of atoms and molecules. Philos Mag 26:1–25, 476–502, 857–875
Boltzman L (2005) Fisica e probabilit (a cura di Massimiliano Badino). Edizioni Melquades, Milano
Born M (1926) Zur Quantenmechanik der Stossvorgänge. Zeits Phys 37:863–867
Blinder SM (2004) Introduction of quantum mechanics in chemistry, materials science, and biology.
Elsevier, Amsterdam
Bragg WH, Bragg WL (1913) The reﬂection of X-rays by crystals. Proc Roy Soc A 88:428–438
Cartan E (1966) English translation: theory of spinors. MIT Press, Cambridge
Clauser JF, Horne MA, Shimony A, Holt RA (1969) Proposed experiment to test local hidden-
variable theories. Phys Rev Lett 23:880–884
Compton AH (1923) A quantum theory of the scattering of x-rays by light elements. Phys Rev
21:483–502
Daneri A, Loinger A, Prosperi GM (1962) Quantum theory of measurement and ergodicity condi-
tions. Nucl Phys 33:297–319
Davisson CJ, Germer LH (1927) Diffraction of electrons by a crystal of nickel. Phys Rev 30:705–740
De Broglie L (1924) Recherches sur la théorie des quanta. Ph.D. thesis, University of Paris
Deutch D (1997) The fabric of reality. Viking, New York
Dirac PAM (1958) The Principles of quantum mechanics. Oxford University Press, Oxford Chap.
II, Sec. 10
Doplicher S (2012) The Measurement process in local quantum theory and the EPR paradox.
arXiv:0908.0480v1
Einstein A (1906) Zur Theorie der Lichterzeugung und Lichtabsorption. Annalen der Physik
20:199–206
Einstein A, Podolski B, Rosen N (1935) Can quantum-mechanical description of physical reality
be considered complete? Phys Rev 47:777–780
© Springer International Publishing AG 2017
G. Fano and S.M. Blinder, Twenty-First Century Quantum Mechanics:
Hilbert Space to Quantum Computers, UNITEXT for Physics,
DOI 10.1007/978-3-319-58732-5
263

264
Bibliography
Fano G (1971) Mathematical methods of quantum mechanics. McGraw-Hill, New York
Feynman RP (1948) Space-time approach to non-relativistic quantum mechanics. Rev Mod Phys
20:367–387
Feynman RP (1951) the concept of probability in quantum mechanics. In: Proceeding II Berkeley
symposium in mathematical statistics and probability, pp 533–541
Feynman RP, Leighton RB, Sands M (1965-1966) Lectures on physics, vol III. Addison-Wesley,
Reading, Chaps 2-6
Feynman RP (1982) Simulating physics with computers. Int J Theor Phys 21:467–488
Feynman RP (1985) Quantum mechanical computers. Opt News 11:11–20, reprinted in Foundations
of Physics (1986) 16:507-531
Fraunhofer J (1817) Bestimmung des Brechungs- und des Farbenzerstreuungs- Vermögens
verschiedener Glasarten, in Bezug auf die Vervollkommnung achromatischer Fernröhre.
Denkschriften der Munich Akademie der Wissenschaften, München 5:193–226
Ghirardi GC, Rimini A, Weber T (1986) Uniﬁed dynamics for microscopic and macroscopic sys-
tems. Phys Rev D 34:470–491
Grifﬁths RB (2002) Consistent quantum theory. Cambridge University Press, Cambridge
Heisenberg W (1925) Über quantentheoretische Umdeutung kinematischer und mechanischer
Beziehungen. Zeits Phys 33:879–893
Kellert SH (1993) In the wake of chaos: unpredictable order in dynamical systems. University of
Chicago Press, Chicago
Kirchhoff RB (1894) Vorlesungen über matematische Physik. Teubner, Leipzig
Klein F (1872) Vergleichende Betrachtungen über neuere geometrische Forschungen. Erlan-
gen 1872; English translation: A comparative review of recent researches in geometry.
arXiv:0807.3161
Kuhn TS (1996) The structure of scientiﬁc revolutions, 3rd edn. University of Chicago Press,
Chicago
Landau LD, Lifshitz EM (1959) Statistical physics. Pergamon Press, London
London F, Bauer E, (1939) La theorie de l’observation en mécanique quantique. English translation
in Wheeler JA, Zurek WH, (eds) (1983) Quantum Theory and Measurement. Princeton University
Press, Princeton, pp 217–259
Merli PG, Missiroli GF, Pozzi G (1976) On the statistical aspect of electron interference phenomena.
Am J Phys 44:306–307
Mermin ND (1985) Is the moon there when nobody looks? Reality and the quantum theory. Phys
Today 38:38–47
Millikan RA (1913) On the elementary electric charge and the avogadro constant. Phys Rev 2:109–
143
Nielson MA, Chuang IL (2000) Quantum computation and quantum information. Cambridge Uni-
versity Press, Cambridge
Nozick R (2001) Invariances: the structure of the objective world. Harvard University Press, Cam-
bridge
Omnes R (1994) The interpretation of quantum mechanics., Princeton series in physicsPrinceton
University press, Princeton
Pais A (1982) Subtle is the lord: the science and the life of Albert Einstein. Oxford University Press,
New York, p 456
Paz JP, Zurek WH (2002) Enviroment-induced decoherence and the transition from quantum to
classical. Lect Notes Phys 587:77–148
Penrose R (1996) On gravity’s role in quantum state reduction. General Relat Gravit 28:581–600
Planck M (1900) Zur Theorie des Gestzes der Energieverteilung im Normalspectrum. Verhandlun-
gen der Deutchen Physikalisken Gesellschaft 2:237–45
Rayleigh JWS (1905) The dynamical theory of gases and radiation. Nature 72:54–55, reprinted in
Rayleigh’s Scientiﬁc Paper, vol 5, Cambridge, UK
Rivest R, Shamir A, Adleman L (1978) A method for obtaining digital signatures and public-key
cryptosystems. Commun ACM 21:120–126

Bibliography
265
Rutherford E (1911) The scattering of α and β particles by matter and the structure of the atom.
Philos Mag Ser 6 21(125):669–688
Rydberg JR (1890) On the structure of the line-spectra of the chemical elements. Philos Mag
29:331–337
Schrödinger E (1926) An undulatory theory of the mechanics of atoms and molecules. Phys Rev
28:1049–70
Schiff LI (1955) Quantum mechanics, 3rd edn. McGraw-Hill, New York
Stapp HP (1975) Bell’s theorem and world process. Nuovo Cim B 29:270–276
Stapp HP (2001) Quantum theory and the role of mind in nature. Found Phys 31:1465–1499
Thomson JJ (1893) Notes on recent researches in electricity and magnetism: intended as a sequel
to Professor Clerk-Maxwell’s ‘Treatise on Electricity and Magnetism’. Oxford University Press,
Oxford, UK, pp.xvi and 578
Young T (1807) A course of lectures on natural philosophy and the mechanical arts. Thoemmes
Press, London, Republished 2002
Von Neumann J, (1932) Mathematische Grundlagen der Quantenmechanik. Springer, Berlin; Eng-
lish translation, (1955) Mathematical foundations of quantum mechanics. Princeton University
Press, Princeton NJ
Von Laue M (1913) Röntgenstrahlinterferenzen. Physikalische Zeitschrift 14:1075–1079
Zurek WH (1991) Decoherence and the transition from quantum to classical. Phys Today 44:36–44
Zurek WH (2003) Decoherence, eigenselection, and the quantum origins of the classical. Rev Mod
Phys 75:715

Index
A
Adder
Full-adder, 202–207
Half-adder, 202, 205, 207
Angular momentum, 96
operators, 98
quantum number, 101
total, 99
Annihilation operator, 93, 96
Antibonding orbital, 39
Anticommutator, 94
Antipodal points, 150
Argument of a complex number, 74
Aspect’s experiment, 182, 183
Atomic orbital, 109
Average
of random variable, 21
Average of observable, 59
Avogadro’s number, 21, 192
Azimuthal angle θ, 106
B
Bell
Bell’s inequality, 118, 164, 172, 183
Bell states, 155, 218
Bell’s theorem, 153, 168, 184
generalized Bell’s inequality, 169
Wigner’s version, 165
Bezout’s lemma, 234
Binary
function, 196
numbers, 195
Blackbody, 5
Bloch sphere, 208
Bohr
atomic model, 11, 12
radius a0, 108
Boltzmann
constant kB, 22
distribution, 30
Bonding orbital, 38
Boolean algebra, 195, 196
Born interpretation, 33
Bose–Einstein condensate, 192
Bosons, 103
Bound states, 81
Bragg formula, 10
Brianchon’s theorem, 124
C
Carry, 201
Central force, 105
Chinese remainder theorem, 240, 242, 246,
256
Class of objects, 122
Classical computers, 201
Clauser–Shimony optimal choice, 172
Clock arithmetic, 235
Closed shell, 111
Code breaking, 257
Commutative property, 122
Commutator, 57, 144
Complement of a set, 198
Complex
conjugate, 73
modulus, 73
plane, 72
real, imaginary parts, 72
© Springer International Publishing AG 2017
G. Fano and S.M. Blinder, Twenty-First Century Quantum Mechanics:
Hilbert Space to Quantum Computers, UNITEXT for Physics,
DOI 10.1007/978-3-319-58732-5
267

268
Index
variables, 70
Compton effect, 7
Computational basis, 209, 212
Congruence class, 236
Conjunction, 196
Consistent histories formalism, 119
Constant of motion, 114
Constructive interference, 3
Continued fractions, 252
Continuous spectrum, 80
Cooper pairs, 193
Copenhagen interpretation, 117
Coprime numbers, 234, 255–257
Correlation function, 169
Creation operator, 93, 96
Crookes tube, 8
D
Davisson and Germer experiment, 10, 11
De Broglie formula, 9
Decoherence, 119, 184, 186, 187, 192
Delta function, 82
De Morgan’s laws, 198, 203, 223
Density matrix, 61
Destructive interference, 3
Detection loophole, 184
Deutsch’s algorithm, 216–218
Diagonal matrix, 56
Digital computers, 195
Dirac, 32
bra-ket notation, 75
Copenhagen interpretation of quantum
mechanics, 116
formalism of quantum mechanics, 69
Hilbert space, 36
Discrete Fourier Transform (DFT), 224
Disjunction, 197
Distance between two functions, 67
E
Ehrenfest’s theorem, 114
Eidos, 125
Eigenvalues and eigenvectors, 56
angular momentum, 97, 99
particle in a box, 91
Einstein-Podolsky-Rosen
(EPR)
experi-
ment, 164
Bohm’s version, 160
Electric ﬁeld E, 173
longitudinal and transverse components,
179
Electron interference, 33
Energy levels of the atoms, 13, 15
Entangled states, 155
Environment, 184, 187
Erlangen program, 121
Euclidean algorithm, 234, 238, 248
Euclidean group, 123
Euler totient function, 240, 241
Evolution operator, 111
Expectation value of observable, 59
F
Factorization of large numbers, 244–248,
257
Faithful representation, 148
Fermat’s little theorem, 238
Fermions, 103
Feynman poem, 120
Fraunhofer, 12
Frequency ν, 3, 176
G
Gates
CCNOT, 222
classical Toffoli gate, 222
inverted controlled, 214
logic gates, 201, 202
quantum Toffoli gate, 222–224
swap gate, 214, 230
controlled-NOT quantum gate, 212
controlled quantum gates, 213
Hadamard gate H, 210
Pauli X,Z, 212
T,S,Z gates, 211, 214
Gaussian distribution, 25, 31
Generator
of a group, 245
of a rotation, 139
Ground state, 90, 95
Group
cyclic, 74, 245
deﬁnition, 122, 239
Lagrange’s theorem, 242
order, 242
subgroup, 242
Zn, 236
H
Hamiltonian, 86
operator, 88
Harmonic oscillator
eigenvalues and eigenfunctions, 94

Index
269
ground state, 95
raising, lowering operators, 94
Hartree unit of energy, 108
Heisenberg
equation of motion, 114
picture, 61, 113
uncertainty principle, 35, 83, 84
Helmholtz, 8
Heraclitus, 125
Hermitian scalar product, 76
Hidden variables, 32, 41, 118, 164, 165
Hilbert space
deﬁnition, 36
rigged, 82
toy Hilbert space, 37, 58
Hindenberg disaster, 11
Hydrogen atom, 104
Hypersphere, 143
I
Idempotent, 63
Imaginary part of complex number, 72
Imaginary unit, 72
Indistinguishable particles, 161
Indra’s net, 156
Instruction set, 165, 168
Invariance, 122, 123
K
Keys, secret and public, 255
Kirchhoff, 5
Kronecker product, 157
L
Laming, 8
Laplacian operator, 87
in spherical coordinates, 106
Left coset, 242, 244
Levi-Civita symbol, 104
Lie
algebra, 150
group, 150
groups SO(3) and SU(2), 137, 138, 145,
149
inﬁnitesimal generators of Lie group,
150
structure constants of Lie group, 151
Light
circularly polarized, 178
elliptically polarized, 178
lightlike 4-vectors, 126
linearly polarized, 178
nature of, 176
quanta, 6
speed of c, 6
Linear
combination of functions, 64
combination of vectors, 45
subspace, 46
Living computer, 207
Locality, 164
Locality loophole, 184
Logical
exclusive or XOR, 197
NAND, NOR, XNOR, 197
negation NOT, 197
product AND, 197
sum OR, 197
variables, 196
M
Magnetic
ﬁeld B, 176
induction, 173
quantum number, 101
Many worlds interpretation of QM, 119
Matrix
angular momentum, 102
Hermitian, 78
identity I, 50, 53, 77
inverse, 53
mechanics, 49
null, 50
rotation, 50, 60, 126
self-adjoint, 78
sum, 51
symmetric, 55
trace, 61
Maxterm, 200
Maxwell–Boltzmann distribution, 31
Maxwell’s equations, 32, 173
Measurement, 115
Miller–Rabin test, 254
Millikan, 8
Minterm, 200
Modular arithmetic, 235
Moral certainty, 24
Multiply-connected set, 151
N
No-cloning theorem, 222
Norm of a function, 66

270
Index
Null matrix, 50
Number theory, 233
O
Observables, 58
Oil drop experiment, 8
Operator, 49
adjoint, 77
Hamiltonian, 88
identity I, 78, 122
inﬁnitesimal rotation, 139
inverse, 122
lowering, 93, 100
product, 122
raising, 93, 100
sum, 147
unitary, 78, 112
Order ﬁnding, 244, 245, 248
Orthogonal functions, 68
Orthonormal
basis, 48
functions, 68, 92
P
Pais, 118, 164
Panta rhei, 125
Parmenides, 125
Particle
in a box, 88
in a ring, 96
momentum, 17, 70, 79, 83
position, 59, 70, 79, 83
Pauli
exclusion principle, 110
spin matrices, 103, 134
Period T, 3
Perspective projection, 123
Phase estimation, 230
Philosophical issues in QM, 117
idealism, 118
neopositivism, 117
phenomena and noumena, 120
realism, 118
Photoelectric effect, 6
Photons, 7
Planck
constant h, 6
constant (reduced) ℏ, 80
distribution function, 6
Planck–Einstein relation, ε = hν, 9
Plane of polarization, 176
Pointer states, 184
Polar angle φ, 106
Potential well, 89
Primality testing, 254
Prime number theorem, 253, 254
Principal quantum number, 14, 107
Principle of local action, 164
Probability, 17
cloud, 34, 36
density, 63
distribution in phase space, 17
standard deviation σ, 19
variance of a distribution σ 2, 19
wave, 33
Projection of a vector, 47, 54
Propagation velocity, 3
Q
Quantum
computation, 207
cryptography, 233, 254
entanglement, 155
Fourier transform, 224, 227
gates, 210
gravity, 119
inverse Fourier transform, 230
order ﬁnding, 248
state of the photon, 180
Qubit, 208
control, 212, 213
measurement, 209
target, 212
R
Radial function Rnl(r), 108
Radial nodes, 109
Raising operator, 93, 100
Random variable, 19
Rayleigh–Jeans, 5
Reduced density matrix, 186
Reduced mass, 105
Register, 230, 232, 250, 251
Representation of SO(3), 146
Residue class, 236
Riemann sphere, 127
Right coset, 242
Rivest, Shamir, and Adelman (RSA), 255,
257
Rotation matrix, 60, 126
eigenvalues and eigenvectors, 126
Rotations and spinors, 137
Rutherford’s experiments, 11

Index
271
Rydberg constant, 13, 15
S
Scalar product
of functions, 65
of vectors, 47
Schrödinger
equation, 32, 33, 85
picture, 60, 113
Schrödinger’s cat, 118
time-dependent equation (TDSE), 60,
87, 111, 113, 164
time-independent equation (TISE), 88
Schuster, 8
Semiclassical picture, 155, 161
Set of instructions, 165
Sets
intersection, 17, 198
union, 17, 198
Shor’s algorithm, 248
Solenoidal electromagnet, 173, 174
Space quantization, 101
Speed of light c, 6
Spherical
coordinates, 105
harmonics, 107
Spin, 128
of electrons, protons and neutrons, 103
of photon, 179
parallel, antiparallel, 130, 132
up, down states, 103, 128, 136, 137, 163
Spinor, 128
in spherical coordinates, 136
SQUID, 193
Stapp, 184
State
bound, 81
ground, 90
maximally entangled, 155
mixed, 63
1s, 108, 109
product state, 153, 154, 187
pure, 63
singlet, 159, 163
spin, 128, 136, 137, 162
stationary, 87
superposition, 210
triplet, 159
vectors, 58
Statistical mechanics, 16
Stereographic projection, 127
Subshell, 111
Superdense coding, 219, 220
T
Teleportation, 220
Tensor product, 153–157, 161, 209
Thomson, 8, 11
Toffoli logic gate, 222, 224
Totient, 240–243, 255–257
Trace of a matrix, 61
Translation, 122
Turing, 254
V
Vector
column, 47
components, 37
isotropic, 126, 127
Jones, 181
length, 46
real vector space, 44
row, 47
space, 37, 43
unit, 46
Venn diagram, 198–200
Von Laue, 9
W
Wave equation, 86, 175, 176
Wavefunction, 63
antisymmetric, 162
collapse, 115, 164, 184
Wavelength λ, 2, 176
Wavepacket, 81
Y
Youngs’ experiment, 3, 5
Z
Zero point energy, 90

