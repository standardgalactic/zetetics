
NONLINEAR 
DYNAMICS AND  
CHAOS


NONLINEAR 
DYNAMICS AND  
CHAOS
With Applications to  
Physics, Biology, Chemistry,  
and Engineering
Steven H. Strogatz
Boca Raton  London  New York
CRC Press is an imprint of the
Taylor & Francis Group, an informa business
A CH APMAN & HALL BOOK

Every effort has been made to secure required permissions for all text, images, maps, and 
other art reprinted in this volume.
A CIP catalog record for the print version of this book is available from the Library of 
Congress
ISBN 13: 978-0-8133-4910-7 (pbk)
Text design by Robert B. Kern 
Set in Times LT Std by TIPS Technical Publishing, Inc.
First published 2015 by Westview Press
Published 2018 by CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
CRC Press is an imprint of the Taylor & Francis Group, an informa business
Copyright © 2015 by Steven H. Strogatz
No claim to original U.S. Government works
This book contains information obtained from authentic and highly regarded sources. Reasonable 
efforts have been made to publish reliable data and information, but the author and publisher cannot 
assume responsibility for the validity of all materials or the consequences of their use. The authors and 
publishers have attempted to trace the copyright holders of all material reproduced in this publication 
and apologize to copyright holders if permission to publish in this form has not been obtained. If any 
copyright material has not been acknowledged please write and let us know so we may rectify in any 
future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, 
transmitted, or utilized in any form by any electronic, mechanical, or other means, now known or 
hereafter invented, including photocopying, microfilming, and recording, or in any information 
storage or retrieval system, without written permission from the publishers.
For permission to photocopy or use material electronically from this work, please access www. 
copyright.com (http://www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 
222 Rosewood Drive, Danvers, MA 01923, 978-750-8400. CCC is a not-for-profit organization that 
provides licenses and registration for a variety of users. For organizations that have been granted a 
photocopy license by the CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are 
used only for identification and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com

V
 
CONTENTS
Preface to the Second Edition ix
Preface to the First Edition xi
 
1 
Overview 1
1.0 
Chaos, Fractals, and Dynamics 1
1.1 
Capsule History of Dynamics 2
1.2 
The Importance of Being Nonlinear 4
1.3 
A Dynamical View of the World 9
Part I One-Dimensional Flows
 
2 
Flows on the Line 15
2.0 
Introduction 15
2.1 
A Geometric Way of Thinking 16
2.2 
Fixed Points and Stability 18
2.3 
Population Growth 21
2.4 
Linear Stability Analysis 24
2.5 
Existence and Uniqueness 26
2.6 
Impossibility of Oscillations 28
2.7 
Potentials 30
2.8 
Solving Equations on the Computer 32
Exercises for Chapter 2 36
 
3 
Bifurcations 45
3.0 
Introduction 45
3.1 
Saddle-Node Bifurcation 46
3.2 
Transcritical Bifurcation 51
3.3 
Laser Threshold 54
3.4 
Pitchfork Bifurcation 56

VI 
3.5 
Overdamped Bead on a Rotating Hoop 62
3.6 
Imperfect Bifurcations and Catastrophes 70
3.7 
Insect Outbreak 74
Exercises for Chapter 3 80
 
4 
Flows on the Circle 95
4.0 
Introduction 95
4.1 
Examples and Definitions 95
4.2 
Uniform Oscillator 97
4.3 
Nonuniform Oscillator 98
4.4 
Overdamped Pendulum 103
4.5 
Fireflies 105
4.6 
Superconducting Josephson Junctions 109
Exercises for Chapter 4 115
Part II Two-Dimensional Flows
 
5 
Linear Systems 125
5.0 
Introduction 125
5.1 
Definitions and Examples 125
5.2 
Classification of Linear Systems 131
5.3 
Love Affairs 139
Exercises for Chapter 5 142
 
6 
Phase Plane 146
6.0 
Introduction 146
6.1 
Phase Portraits 146
6.2 
Existence, Uniqueness, and Topological 
Consequences 149
6.3 
Fixed Points and Linearization 151
6.4 
Rabbits versus Sheep 156
6.5 
Conservative Systems 160
6.6 
Reversible Systems 164
6.7 
Pendulum 168
6.8 
Index Theory 174
Exercises for Chapter 6 181
 
7 
Limit Cycles 198
7.0 
Introduction 198
7.1 
Examples 199
7.2 
Ruling Out Closed Orbits 201
7.3 
Poincaré−Bendixson Theorem 205
7.4 
Liénard Systems 212
7.5 
Relaxation Oscillations 213

VII
 
7.6 
Weakly Nonlinear Oscillators 217
Exercises for Chapter 7 230
 
8 
Bifurcations Revisited 244
8.0 
Introduction 244
8.1 
Saddle-Node, Transcritical, and Pitchfork 
Bifurcations 244
8.2 
Hopf Bifurcations 251
8.3 
Oscillating Chemical Reactions 257
8.4 
Global Bifurcations of Cycles 264
8.5 
Hysteresis in the Driven Pendulum and Josephson 
Junction 268
8.6 
Coupled Oscillators and Quasiperiodicity 276
8.7 
Poincaré Maps 281
Exercises for Chapter 8 287
Part III Chaos
 
9 
Lorenz Equations 309
9.0 
Introduction 309
9.1 
A Chaotic Waterwheel 310
9.2 
Simple Properties of the Lorenz Equations 319
9.3 
Chaos on a Strange Attractor 325
9.4 
Lorenz Map 333
9.5 
Exploring Parameter Space 337
9.6 
Using Chaos to Send Secret Messages 342
Exercises for Chapter 9 348
 
10 
One-Dimensional Maps 355
10.0 Introduction 355
10.1 Fixed Points and Cobwebs 356
10.2 Logistic Map: Numerics 360
10.3 Logistic Map: Analysis 364
10.4 Periodic Windows 368
10.5 Liapunov Exponent 373
10.6 Universality and Experiments 376
10.7 Renormalization 386
Exercises for Chapter 10 394
 
11 
Fractals 405
11.0 Introduction 405
11.1 Countable and Uncountable Sets 406
11.2 Cantor Set 408
11.3 Dimension of Self-Similar Fractals 411

VIII 
11.4 Box Dimension 416
11.5 Pointwise and Correlation Dimensions 418
Exercises for Chapter 11 423
 
12 
Strange Attractors 429
12.0 Introduction 429
12.1 The Simplest Examples 429
12.2 Hénon Map 435
12.3 Rössler System 440
12.4 Chemical Chaos and Attractor Reconstruction 443
12.5 Forced Double-Well Oscillator 447
Exercises for Chapter 12 454
Answers to Selected Exercises 460
References 470
Author Index 483
Subject Index 487

IX
PREFACE TO THE SECOND EDITION
PREFACE TO THE SECOND 
EDITION
Welcome to this second edition of Nonlinear Dynamics and Chaos, now avail-
able in e-book format as well as traditional print. 
In the twenty years since this book first appeared, the ideas and techniques 
of nonlinear dynamics and chaos have found application in such exciting new 
fields as systems biology, evolutionary game theory, and sociophysics. To give 
you a taste of these recent developments, I’ve added about twenty substantial 
new exercises that I hope will entice you to learn more. The fields and applica-
tions include (with the associated exercises listed in parentheses):
Animal behavior: calling rhythms of Japanese tree frogs (8.6.9)
Classical mechanics: driven pendulum with quadratic damping (8.5.5)
Ecology: predator-prey model; periodic harvesting (7.2.18, 8.5.4)
Evolutionary biology: survival of the fittest (2.3.5, 6.4.8)
Evolutionary game theory: rock-paper-scissors (6.5.20, 7.3.12)
Linguistics: language death (2.3.6)
Prebiotic chemistry: hypercycles (6.4.10)
Psychology and literature: love dynamics in Gone with the Wind (7.2.19)
Macroeconomics: Keynesian cross model of a national economy (6.4.9)
Mathematics: repeated exponentiation (10.4.11)
Neuroscience: binocular rivalry in visual perception (8.1.14, 8.2.17) 
Sociophysics: opinion dynamics (6.4.11, 8.1.15)
Systems biology: protein dynamics (3.7.7, 3.7.8)
Thanks to my colleagues Danny Abrams, Bob Behringer, Dirk Brockmann, 
Michael Elowitz, Roy Goodman, Jeff Hasty, Chad Higdon-Topaz, Mogens 
Jensen, Nancy Kopell, Tanya Leise, Govind Menon, Richard Murray, Mary 

X 
PREFACE TO THE SECOND EDITION
Silber, Jim Sochacki, Jean-Luc Thiffeault, John Tyson, Chris Wiggins, and 
Mary Lou Zeeman for their suggestions about possible new exercises. I am 
especially grateful to Bard Ermentrout for devising the exercises about 
Japanese tree frogs (8.6.9) and binocular rivalry (8.1.14, 8.2.17), and to Jordi 
Garcia-Ojalvo for sharing his exercises about systems biology (3.7.7, 3.7.8).
In all other respects, the aims, organization, and text of the first edition 
have been left intact, except for a few corrections and updates here and there. 
Thanks to all the teachers and students who wrote in with suggestions. 
It has been a pleasure to work with Sue Caulfield, Priscilla McGeehon, and 
Cathleen Tetro at Westview Press. Many thanks for your guidance and atten-
tion to detail.
Finally, all my love goes out to my wife Carole, daughters Leah and Jo, and 
dog Murray, for putting up with my distracted air and making me laugh. 
Steven H. Strogatz 
Ithaca, New York 
2014

XI
PREFACE TO THE FIRST EDITION
PREFACE TO THE FIRST EDITION
This textbook is aimed at newcomers to nonlinear dynamics and chaos, espe-
cially students taking a first course in the subject. It is based on a one-semester 
course I’ve taught for the past several years at MIT. My goal is to explain the 
mathematics as clearly as possible, and to show how it can be used to under-
stand some of the wonders of the nonlinear world. 
The mathematical treatment is friendly and informal, but still careful. 
Analyti cal methods, concrete examples, and geometric intuition are stressed. 
The theory is developed systematically, starting with first-order differential 
equations and their bifurcations, followed by phase plane analysis, limit cycles 
and their bifurcations, and culminating with the Lorenz equations, chaos, iter-
ated maps, period doubling, renormalization, fractals, and strange attractors. 
A unique feature of the book is its emphasis on applications. These include 
me chanical vibrations, lasers, biological rhythms, superconducting circuits, 
insect outbreaks, chemical oscillators, genetic control systems, chaotic water-
wheels, and even a technique for using chaos to send secret messages. In each 
case, the sci entific background is explained at an elementary level and closely 
integrated with the mathematical theory. 
Prerequisites 
The essential prerequisite is single-variable calculus, including curve-
sketch ing, Taylor series, and separable differential equations. In a few places, 
multivari able calculus (partial derivatives, Jacobian matrix, divergence theo-
rem) and linear algebra (eigenvalues and eigenvectors) are used. Fourier analy-
sis is not assumed, and is developed where needed. Introductory physics is used 
throughout. Other scientific prerequisites would depend on the applications 
considered, but in all cases, a first course should be adequate preparation. 

XII 
PREFACE TO THE FIRST EDITION
Possible Courses 
The book could be used for several types of courses: 
• A broad introduction to nonlinear dynamics, for students with no prior 
expo sure to the subject. (This is the kind of course I have taught.) Here 
one goes straight through the whole book, covering the core material at 
the beginning of each chapter, selecting a few applications to discuss in 
depth and giving light treatment to the more advanced theoretical topics 
or skipping them alto gether. A reasonable schedule is seven weeks on 
Chapters 1-8, and five or six weeks on Chapters 9-12. Make sure there’s 
enough time left in the semester to get to chaos, maps, and fractals. 
• A traditional course on nonlinear ordinary differential equations, but 
with more emphasis on applications and less on perturbation theory than 
usual. Such a course would focus on Chapters 1-8. 
• A modern course on bifurcations, chaos, fractals, and their applications, 
for students who have already been exposed to phase plane analysis. 
Topics would be selected mainly from Chapters 3, 4, and 8-12. 
For any of these courses, the students should be assigned homework from 
the exercises at the end of each chapter. They could also do computer projects; 
build chaotic circuits and mechanical systems; or look up some of the refer-
ences to get a taste of current research. This can be an exciting course to teach, 
as well as to take. I hope you enjoy it. 
Conventions 
Equations are numbered consecutively within each section. For instance, 
when we’re working in Section 5.4, the third equation is called (3) or Equation 
(3), but elsewhere it is called (5.4.3) or Equation (5.4.3). Figures, examples, and 
exercises are always called by their full names, e.g., Exercise 1.2.3. Examples 
and proofs end with a loud thump, denoted by the symbol ■. 
Acknowledgments 
Thanks to the National Science Foundation for financial support. For help 
with the book, thanks to Diana Dabby, Partha Saha, and Shinya Watanabe 
(students); Jihad Touma and Rodney Worthing (teaching assistants); Andy 
Christian, Jim Crutchfield, Kevin Cuomo, Frank DeSimone, Roger Eckhardt, 
Dana Hobson, and Thanos Siapas (for providing figures); Bob Devaney, Irv 
Epstein, Danny Kaplan, Willem Malkus, Charlie Marcus, Paul Matthews, 

XIII
PREFACE TO THE FIRST EDITION
Arthur Mattuck, Rennie Mirollo, Peter Renz, Dan Rockmore, Gil Strang, 
Howard Stone, John Tyson, Kurt Wiesenfeld, Art Winfree, and Mary Lou 
Zeeman (friends and colleagues who gave ad vice); and to my editor Jack 
Repcheck, Lynne Reed, Production Supervisor, and all the other helpful peo-
ple at Addison-Wesley. Finally, thanks to my family and Elisabeth for their 
love and encouragement. 
Steven H. Strogatz 
Cambridge, Massachusetts 
1994


1
1.0 CHAOS, FRACTALS, AND DYNAMICS
1
OVERVIEW
1.0 Chaos, Fractals, and Dynamics
There is a tremendous fascination today with chaos and fractals. James Gleick’s 
book Chaos (Gleick 1987) was a bestseller for months—an amazing accomplish-
ment for a book about mathematics and science. Picture books like The Beauty 
of Fractals by Peitgen and Richter (1986) can be found on coffee tables in living 
rooms everywhere. It seems that even nonmathematical people are captivated by 
the infinite patterns found in fractals (Figure 1.0.1). Perhaps most important of 
all, chaos and fractals represent hands-on mathematics that is alive and changing. 
You can turn on a home computer and create stunning mathematical images that 
no one has ever seen before.
The aesthetic appeal of chaos and fractals may explain why so many people 
have become intrigued by these ideas. But maybe you feel the urge to go deeper—
to learn the mathematics behind the pictures, and to see how the ideas can be 
applied to problems in science and engi-
neering. If so, this is a textbook for you.
The style of the book is informal (as 
you can see), with an emphasis on con-
crete examples and geometric thinking, 
rather than proofs and abstract argu-
ments. It is also an extremely “applied” 
book—virtually every idea is illustrated 
by some application to science or engi-
neering. In many cases, the applications 
are drawn from the recent research liter-
ature. Of course, one problem with such 
an applied approach is that not every-
one is an expert in physics and biology 
Figure 1.0.1

2 
OVERVIEW
and fluid mechanics . . . so the science as well as the mathematics will need to be 
explained from scratch. But that should be fun, and it can be instructive to see the 
connections among different fields. 
Before we start, we should agree about something: chaos and fractals are part 
of an even grander subject known as dynamics. This is the subject that deals with 
change, with systems that evolve in time. Whether the system in question settles 
down to equilibrium, keeps repeating in cycles, or does something more com-
plicated, it is dynamics that we use to analyze the behavior. You have probably 
been exposed to dynamical ideas in various places—in courses in differential 
equations, classical mechanics, chemical kinetics, population biology, and so on. 
Viewed from the perspective of dynamics, all of these subjects can be placed in a 
common framework, as we discuss at the end of this chapter.
Our study of dynamics begins in earnest in Chapter 2. But before digging in, 
we present two overviews of the subject, one historical and one logical. Our treat-
ment is intuitive; careful definitions will come later. This chapter concludes with 
a “dynamical view of the world,” a framework that will guide our studies for the 
rest of the book.
1.1 Capsule History of Dynamics
Although dynamics is an interdisciplinary subject today, it was originally a branch 
of physics. The subject began in the mid-1600s, when Newton invented differen-
tial equations, discovered his laws of motion and universal gravitation, and com-
bined them to explain Kepler’s laws of planetary motion. Specifically, Newton 
solved the two-body problem—the problem of calculating the motion of the earth 
around the sun, given the inverse-square law of gravitational attraction between 
them. Subsequent generations of mathematicians and physicists tried to extend 
Newton’s analytical methods to the three-body problem (e.g., sun, earth, and 
moon) but curiously this problem turned out to be much more difficult to solve. 
After decades of effort, it was eventually realized that the three-body problem was 
essentially impossible to solve, in the sense of obtaining explicit formulas for the 
motions of the three bodies. At this point the situation seemed hopeless.
The breakthrough came with the work of Poincaré in the late 1800s. He intro-
duced a new point of view that emphasized qualitative rather than quantitative 
questions. For example, instead of asking for the exact positions of the planets at 
all times, he asked “Is the solar system stable forever, or will some planets even-
tually fly off to infinity?” Poincaré developed a powerful geometric approach to 
analyzing such questions. That approach has flowered into the modern subject 
of dynamics, with applications reaching far beyond celestial mechanics. Poincaré 
was also the first person to glimpse the possibility of chaos, in which a determinis-
tic system exhibits aperiodic behavior that depends sensitively on the initial condi-
tions, thereby rendering long-term prediction impossible.

3
1.1 CAPSULE HISTORY OF DYNAMICS
But chaos remained in the background in the first half of the twentieth century; 
instead dynamics was largely concerned with nonlinear oscillators and their appli-
cations in physics and engineering. Nonlinear oscillators played a vital role in the 
development of such technologies as radio, radar, phase-locked loops, and lasers. 
On the theoretical side, nonlinear oscillators also stimulated the invention of new 
mathematical techniques—pioneers in this area include van der Pol, Andronov, 
Littlewood, Cartwright, Levinson, and Smale. Meanwhile, in a separate develop-
ment, Poincaré’s geometric methods were being extended to yield a much deeper 
understanding of classical mechanics, thanks to the work of Birkhoff and later 
Kolmogorov, Arnol’d, and Moser.
The invention of the high-speed computer in the 1950s was a watershed in the 
history of dynamics. The computer allowed one to experiment with equations in 
a way that was impossible before, and thereby to develop some intuition about 
nonlinear systems. Such experiments led to Lorenz’s discovery in 1963 of chaotic 
motion on a strange attractor. He studied a simplified model of convection rolls in 
the atmosphere to gain insight into the notorious unpredictability of the weather. 
Lorenz found that the solutions to his equations never settled down to equilibrium 
or to a periodic state—instead they continued to oscillate in an irregular, aperi-
odic fashion. Moreover, if he started his simulations from two slightly different 
initial conditions, the resulting behaviors would soon become totally different. 
The implication was that the system was inherently unpredictable—tiny errors 
in measuring the current state of the atmosphere (or any other chaotic system) 
would be amplified rapidly, eventually leading to embarrassing forecasts. But 
Lorenz also showed that there was structure in the chaos—when plotted in three 
dimensions, the solutions to his equations fell onto a butterfly-shaped set of points 
(Figure 1.1.1). He argued that this set had to be “an infinite complex of surfaces”—
today we would regard it as an example of a fractal.
x
z
Figure 1.1.1

4 
OVERVIEW
Lorenz’s work had little impact until the 1970s, the boom years for chaos. 
Here are some of the main developments of that glorious decade. In 1971, Ruelle 
and Takens proposed a new theory for the onset of turbulence in fluids, based 
on abstract considerations about strange attractors. A few years later, May found 
examples of chaos in iterated mappings arising in population biology, and wrote 
an influential review article that stressed the pedagogical importance of studying 
simple nonlinear systems, to counterbalance the often misleading linear intuition 
fostered by traditional education. Next came the most surprising discovery of all, 
due to the physicist Feigenbaum. He discovered that there are certain universal 
laws governing the transition from regular to chaotic behavior; roughly speaking, 
completely different systems can go chaotic in the same way. His work established 
a link between chaos and phase transitions, and enticed a generation of physicists 
to the study of dynamics. Finally, experimentalists such as Gollub, Libchaber, 
Swinney, Linsay, Moon, and Westervelt tested the new ideas about chaos in exper-
iments on fluids, chemical reactions, electronic circuits, mechanical oscillators, 
and semiconductors.
Although chaos stole the spotlight, there were two other major developments in 
dynamics in the 1970s. Mandelbrot codified and popularized fractals, produced 
magnificent computer graphics of them, and showed how they could be applied in 
a variety of subjects. And in the emerging area of mathematical biology, Winfree 
applied the geometric methods of dynamics to biological oscillations, especially 
circadian (roughly 24-hour) rhythms and heart rhythms.
By the 1980s many people were working on dynamics, with contributions too 
numerous to list. Table 1.1.1 summarizes this history.
1.2 The Importance of Being Nonlinear
Now we turn from history to the logical structure of dynamics. First we need to 
introduce some terminology and make some distinctions.
There are two main types of dynamical systems: differential equations and iter-
ated maps (also known as difference equations). Differential equations describe 
the evolution of systems in continuous time, whereas iterated maps arise in prob-
lems where time is discrete. Differential equations are used much more widely in 
science and engineering, and we shall therefore concentrate on them. Later in the 
book we will see that iterated maps can also be very useful, both for providing sim-
ple examples of chaos, and also as tools for analyzing periodic or chaotic solutions 
of differential equations.
Now confining our attention to differential equations, the main distinction is 
between ordinary and partial differential equations. For instance, the equation for 
a damped harmonic oscillator

5
1.2 THE IMPORTANCE OF BEING NONLINEAR
m d x
dt
b dx
dt
kx
2
2
0
+
+
=
 
(1)
is an ordinary differential equation, because it involves only ordinary derivatives 
dx / dt and d  2x / dt  2. That is, there is only one independent variable, the time t. In 
contrast, the heat equation
∂
∂= ∂
∂
u
t
u
x
2
2
Dynamics — A Capsule History
1666
Newton
Invention of calculus, explanation of planetary 
motion
1700s
Flowering of calculus and classical mechanics
1800s
Analytical studies of planetary motion
1890s
Poincaré
Geometric approach, nightmares of chaos
1920–1950
Nonlinear oscillators in physics and engineering, 
invention of radio, radar, laser
1920–1960
Birkhoff
Complex behavior in Hamiltonian mechanics 
Kolmogorov
Arnol’d
Moser
1963
Lorenz
Strange attractor in simple model of convection
1970s
Ruelle & Takens
Turbulence and chaos
May
Chaos in logistic map
Feigenbaum
Universality and renormalization, connection 
between chaos and phase transitions
Experimental studies of chaos
Winfree
Nonlinear oscillators in biology
Mandelbrot
Fractals
1980s
Widespread interest in chaos, fractals, oscillators, 
and their applications
Table 1.1.1

6 
OVERVIEW
is a partial differential equation—it has both time t and space x as independent 
variables. Our concern in this book is with purely temporal behavior, and so we 
deal with ordinary differential equations almost exclusively.
A very general framework for ordinary differential equations is provided by the 
system

…


…
x
f x
x
x
f
x
x
n
n
n
n
1
1
1
1


(
,
,
)
(
,
,
).
 
(2)
Here the overdots denote differentiation with respect to t. Thus x
dx dt
i
i
w
/
. The 
variables x1, … , xn might represent concentrations of chemicals in a reactor, pop-
ulations of different species in an ecosystem, or the positions and velocities of the 
planets in the solar system. The functions f1, … , fn are determined by the problem 
at hand. 
For example, the damped oscillator (1) can be rewritten in the form of (2), 
thanks to the following trick: we introduce new variables x1  x and x
x
2   . Then 
x
x
1 
2, from the definitions, and



x
x
b
m x
k
m x
b
m x
k
m x
2
2
1
=
= −
−
= −
−
from the definitions and the governing equation (1). Hence the equivalent system 
(2) is


x
x
x
b
m x
k
m x
1
2
2
1
=
= −
−
2
.
This system is said to be linear, because all the xi on the right-hand side appear 
to the first power only. Otherwise the system would be nonlinear. Typical nonlinear 
terms are products, powers, and functions of the xi , such as x1 x2, ( x1 )3, or cos x2.
For example, the swinging of a pendulum is governed by the equation
x
g
L
x
+
=
sin
,0
where x is the angle of the pendulum from vertical, g is the acceleration due to 
gravity, and L is the length of the pendulum. The equivalent system is nonlinear:

7
1.2 THE IMPORTANCE OF BEING NONLINEAR


x
x
x
g
L
x
1
2
2
1
=
= −
sin
.
Nonlinearity makes the pendulum equation very difficult to solve analytically. 
The usual way around this is to fudge, by invoking the small angle approximation 
sin x x x for x  1. This converts the problem to a linear one, which can then be 
solved easily. But by restricting to small x, we’re throwing out some of the physics, 
like motions where the pendulum whirls over the top. Is it really necessary to make 
such drastic approximations?
It turns out that the pendulum equation can be solved analytically, in terms of 
elliptic functions. But there ought to be an easier way. After all, the motion of the 
pendulum is simple: at low energy, it swings back and forth, and at high energy 
it whirls over the top. There should be some way of extracting this information 
from the system directly. This is the sort of problem we’ll learn how to solve, using 
geometric methods.
Here’s the rough idea. Suppose we happen to know a solution to the pendulum 
system, for a particular initial condition. This solution would be a pair of func-
tions x1(t) and x2(t), representing the position and velocity of the pendulum. If we 
construct an abstract space with coordinates (x1, x2 ), then the solution ( x1(t), x2(t)) 
corresponds to a point moving along a curve in this space (Figure 1.2.1).
x2
(x1(t), x2(t))
(x1(0), x2(0))
x1
Figure 1.2.1
This curve is called a trajectory, and the space is called the phase space for the 
system. The phase space is completely filled with trajectories, since each point can 
serve as an initial condition.
Our goal is to run this construction in reverse: given the system, we want to 
draw the trajectories, and thereby extract information about the solutions. In 

8 
OVERVIEW
many cases, geometric reasoning will allow us to draw the trajectories without 
actually solving the system!
Some terminology: the phase space for the general system (2) is the space with 
coordinates x1, … , xn. Because this space is n-dimensional, we will refer to (2) as 
an n-dimensional system or an nth-order system. Thus n represents the dimension 
of the phase space.
Nonautonomous Systems
You might worry that (2) is not general enough because it doesn’t include any 
explicit time dependence. How do we deal with time-dependent or nonautonomous 
equations like the forced harmonic oscillator mx
bx
kx
F
t


+
+
=
cos ?  In this 
case too there’s an easy trick that allows us to rewrite the system in the form (2). We 
let x1  x and x
x
2   as before but now we introduce x3  t. Then x3
1
  and so 
the equivalent system is



x
x
x
m
kx
bx
F
x
x
1
2
2
1
2
3
3
1
1
=
=
−
−
+
=
(
cos
)  
(3)
which is an example of a three-dimensional system. Similarly, an nth-order 
time-dependent equation is a special case of an (n  1)-dimensional system. By 
this trick, we can always remove any time dependence by adding an extra dimen-
sion to the system.
The virtue of this change of variables is that it allows us to visualize a phase 
space with trajectories frozen in it. Otherwise, if we allowed explicit time depen-
dence, the vectors and the trajectories would always be wiggling—this would ruin 
the geometric picture we’re trying to build. A more physical motivation is that the 
state of the forced harmonic oscillator is truly three-dimensional: we need to know 
three numbers, x, x , and t, to predict the future, given the present. So a three-di-
mensional phase space is natural.
The cost, however, is that some of our terminology is nontraditional. For exam-
ple, the forced harmonic oscillator would traditionally be regarded as a second-or-
der linear equation, whereas we will regard it as a third-order nonlinear system, 
since (3) is nonlinear, thanks to the cosine term. As we’ll see later in the book, 
forced oscillators have many of the properties associated with nonlinear systems, 
and so there are genuine conceptual advantages to our choice of language.
Why Are Nonlinear Problems So Hard?
As we’ve mentioned earlier, most nonlinear systems are impossible to solve 
analytically. Why are nonlinear systems so much harder to analyze than linear 
ones? The essential difference is that linear systems can be broken down into parts. 
Then each part can be solved separately and finally recombined to get the answer. 

9
1.3 A DYNAMICAL VIEW OF THE WORLD
This idea allows a fantastic simplification of complex problems, and underlies 
such methods as normal modes, Laplace transforms, superposition arguments, 
and Fourier analysis. In this sense, a linear system is precisely equal to the sum of 
its parts.
But many things in nature don’t act this way. Whenever parts of a system inter-
fere, or cooperate, or compete, there are nonlinear interactions going on. Most of 
everyday life is nonlinear, and the principle of superposition fails spectacularly. 
If you listen to your two favorite songs at the same time, you won’t get double 
the pleasure! Within the realm of physics, nonlinearity is vital to the operation 
of a laser, the formation of turbulence in a fluid, and the superconductivity of 
Josephson junctions.
1.3 A Dynamical View of the World
Now that we have established the ideas of nonlinearity and phase space, we can 
present a framework for dynamics and its applications. Our goal is to show the 
logical structure of the entire subject. The framework presented in Figure 1.3.1 will 
guide our studies thoughout this book.
The framework has two axes. One axis tells us the number of variables needed 
to characterize the state of the system. Equivalently, this number is the dimension 
of the phase space. The other axis tells us whether the system is linear or nonlinear.
For example, consider the exponential growth of a population of organisms. 
This system is described by the first-order differential equation x
rx

 where x 
is the population at time t and r is the growth rate. We place this system in the 
column labeled “n  1” because one piece of information—the current value of the 
population x—is sufficient to predict the population at any later time. The system 
is also classified as linear because the differential equation x
rx

 is linear in x.
As a second example, consider the swinging of a pendulum, governed by
x
g
L
x
+
=
sin
.0
In contrast to the previous example, the state of this system is given by two vari-
ables: its current angle x and angular velocity x . (Think of it this way: we need 
the initial values of both x and x  to determine the solution uniquely. For example, 
if we knew only x, we wouldn’t know which way the pendulum was swinging.) 
Because two variables are needed to specify the state, the pendulum belongs in 
the n  2 column of Figure 1.3.1. Moreover, the system is nonlinear, as discussed 
in the previous section. Hence the pendulum is in the lower, nonlinear half of the 
n  2 column.
One can continue to classify systems in this way, and the result will be some-
thing like the framework shown here. Admittedly, some aspects of the picture are 

10 
OVERVIEW
Continuum 
 
Exponential growth 
RC circuit 
 Radioactive decay
 
Oscillations 
Linear oscillator 
Civil engineering,
Collective phenomena 
Coupled harmonic oscillators
 
Waves and patterns 
Elasticity 
Mass and spring 
structures 
Solid-state physics 
Wave equations 
RLC circuit 
2-body problem 
(Kepler, Newton)
Electrical engineering 
Molecular dynamics 
Equilibrium statistical 
mechanics
Electromagnetism (Maxwell) 
Quantum mechanics 
(Schrödinger, Heisenberg, Dirac)
 
Heat and diffusion 
Acoustics 
Viscous fluids 
The frontier
Chaos
 
Spatio-temporal complexity
 
Fixed points 
Pendulum 
Strange attractors
 
Coupled nonlinear oscillators
 
Nonlinear waves (shocks, solitons)
Bifurcations 
Anharmonic oscillators
(Lorenz) 
Lasers, nonlinear optics 
Plasmas 
Overdamped systems, 
relaxational dynamics
Limit cycles
Biological oscillators
 
3-body problem (Poincaré) 
Chemical kinetics 
Nonequilibrium statistical 
mechanics 
Earthquakes 
General relativity (Einstein) 
Logistic equation 
for single species 
(neurons, heart cells) 
Predator-prey cycles 
Nonlinear electronics 
(van der Pol, Josephson)
 
Iterated maps (Feigenbaum)
 
Fractals
(Mandelbrot)
Forced nonlinear oscillators 
(Levinson, Smale)
Nonlinear solid-state physics 
(semiconductors) 
Josephson arrays 
Heart cell synchronization 
Neural networks 
Quantum field theory 
Reaction-diffusion,
biological and chemical waves
 
Fibrillation
Practical uses of chaos 
Quantum chaos ?
 
 
Immune system 
Ecosystems 
Economics 
Turbulent fluids (Navier-Stokes) 
Life
Number of variables
Nonlinearity
Linear
Nonlinear
Growth, decay, or 
equilibrium
n = 1
n = 2
n ≥ 3
n >> 1
Epilepsy
Figure 1.3.1

11
1.3 A DYNAMICAL VIEW OF THE WORLD
debatable. You might think that some topics should be added, or placed differ-
ently, or even that more axes are needed—the point is to think about classifying 
systems on the basis of their dynamics.
There are some striking patterns in Figure 1.3.1. All the simplest systems occur 
in the upper left-hand corner. These are the small linear systems that we learn 
about in the first few years of college. Roughly speaking, these linear systems 
exhibit growth, decay, or equilibrium when n  1, or oscillations when n  2. The 
italicized phrases in Figure 1.3.1 indicate that these broad classes of phenomena 
first arise in this part of the diagram. For example, an RC circuit has n  1 and 
cannot oscillate, whereas an RLC circuit has n  2 and can oscillate.
The next most familiar part of the picture is the upper right-hand corner. This 
is the domain of classical applied mathematics and mathematical physics where 
the linear partial differential equations live. Here we find Maxwell’s equations 
of electricity and magnetism, the heat equation, Schrödinger’s wave equation in 
quantum mechanics, and so on. These partial differential equations involve an 
infinite “continuum” of variables because each point in space contributes addi-
tional degrees of freedom. Even though these systems are large, they are tractable, 
thanks to such linear techniques as Fourier analysis and transform methods.
In contrast, the lower half of Figure 1.3.1—the nonlinear half—is often ignored 
or deferred to later courses. But no more! In this book we start in the lower left cor-
ner and systematically head to the right. As we increase the phase space dimension 
from n  1 to n  3, we encounter new phenomena at every step, from fixed points 
and bifurcations when n  1, to nonlinear oscillations when n  2, and finally 
chaos and fractals when n  3. In all cases, a geometric approach proves to be 
very powerful, and gives us most of the information we want, even though we usu-
ally can’t solve the equations in the traditional sense of finding a formula for the 
answer. Our journey will also take us to some of the most exciting parts of modern 
science, such as mathematical biology and condensed-matter physics.
You’ll notice that the framework also contains a region forbiddingly marked 
“The frontier.” It’s like in those old maps of the world, where the mapmakers 
wrote, “Here be dragons” on the unexplored parts of the globe. These topics are 
not completely unexplored, of course, but it is fair to say that they lie at the limits 
of current understanding. The problems are very hard, because they are both large 
and nonlinear. The resulting behavior is typically complicated in both space and 
time, as in the motion of a turbulent fluid or the patterns of electrical activity in a 
fibrillating heart. Toward the end of the book we will touch on some of these prob-
lems—they will certainly pose challenges for years to come.


 
Part I
ONE-DIMENSIONAL FLOWS


15
2.0 INTRODUCTION
2
FLOWS ON THE LINE
2.0 Introduction
In Chapter 1, we introduced the general system



x
f x
x
x
f
x
x
n
n
n
n
1
1
1
1


(
, ... ,
)
(
, ... ,
)
and mentioned that its solutions could be visualized as trajectories flowing through 
an n-dimensional phase space with coordinates ( x1, … , xn ). At the moment, this 
idea probably strikes you as a mind-bending abstraction. So let’s start slowly, 
beginning here on earth with the simple case n  1. Then we get a single equation 
of the form
x
f x

( ).
Here x ( t ) is a real-valued function of time t, and f  ( x ) is a smooth real-valued func-
tion of x. We’ll call such equations one-dimensional or first-order systems.
Before there’s any chance of confusion, let’s dispense with two fussy points of 
terminology:
1. The word system is being used here in the sense of a dynamical system, 
not in the classical sense of a collection of two or more equations. Thus 
a single equation can be a “system.”
2. We do not allow f to depend explicitly on time. Time-dependent or 
“nonautonomous” equations of the form x
f x t

( , ) are more com-
plicated, because one needs two pieces of information, x and t, to pre-
dict the future state of the system. Thus x
f x t

( , ) should really be 
regarded as a two-dimensional or second-order system, and will there-
fore be discussed later in the book.

16 
FLOWS ON THE LINE
2.1 A Geometric Way of Thinking
Pictures are often more helpful than formulas for analyzing nonlinear systems. 
Here we illustrate this point by a simple example. Along the way we will introduce 
one of the most basic techniques of dynamics: interpreting a differential equation 
as a vector field.
Consider the following nonlinear differential equation:
x
x
 sin . 
(1)
To emphasize our point about formulas versus pictures, we have chosen one of 
the few nonlinear equations that can be solved in closed form. We separate the 
variables and then integrate:
dt
dx
x
 sin
,
which implies
t
x dx
x
x
C
=
= −
+
+
∫csc
csc
cot
.
 
ln
To evaluate the constant C, suppose that x  x0 at t  0. Then C  ln | csc x0  
cot x0 |. Hence the solution is
t
x
x
x
x
=
+
+
ln csc
cot
csc
cot
.
0
0
 
(2)
This result is exact, but a headache to interpret. For example, can you answer the 
following questions?
1. Suppose x0  Q / 4; describe the qualitative features of the solution x ( t ) 
for all t > 0. In particular, what happens as t l d?
2. For an arbitrary initial condition x0, what is the behavior of x ( t ) as 
t ld?
Think about these questions for a while, to see that formula (2) is not transparent.
In contrast, a graphical analysis of (1) is clear and simple, as shown in 
Figure 2.1.1. We think of t as time, x as the position of an imaginary particle mov-
ing along the real line, and x  as the velocity of that particle. Then the differential 
equation x
x
 sin
 represents a vector field on the line: it dictates the velocity vec-
tor x  at each x. To sketch the vector field, it is convenient to plot x  versus x, and 
then draw arrows on the x-axis to indicate the corresponding velocity vector at 
each x. The arrows point to the right when x  0  and to the left when x  0 .

17
2.1 A GEOMETRIC WAY OF THINKING
x˙
x
π
2π
Figure 2.1.1
Here’s a more physical way to think about the vector field: imagine that fluid 
is flowing steadily along the x-axis with a velocity that varies from place to place, 
according to the rule x
x
 sin
. As shown in Figure 2.1.1, the flow is to the right 
when x  0  and to the left when x  0. At points where x  0,  there is no flow; 
such points are therefore called fixed points. You can see that there are two kinds 
of fixed points in Figure 2.1.1: solid black dots represent stable fixed points (often 
called attractors or sinks, because the flow is toward them) and open circles repre-
sent unstable fixed points (also known as repellers or sources).
Armed with this picture, we can now easily understand the solutions to the dif-
ferential equation x
x
 sin . We just start our imaginary particle at x0 and watch 
how it is carried along by the flow.
This approach allows us to answer the questions above as follows:
1. Figure 2.1.1 shows that a particle starting at x0  Q / 4 moves to the 
right faster and faster until it crosses x  Q / 2 (where sin x reaches 
its maximum). Then the particle starts slowing down and eventually 
approaches the stable fixed point x  Q from the left. Thus, the quali-
tative form of the solution is as shown in Figure 2.1.2.
Note that the curve is concave up at first, and then concave down; 
this corresponds to the initial acceleration for x  Q / 2, followed by the 
deceleration toward x  Q.
2. The same reasoning applies to any initial condition x0. Figure 2.1.1 
shows that if x  0  initially, the particle heads to the right and asymp-
totically approaches the near-
est stable fixed point. Similarly, 
if x  0  initially, the particle 
approaches the nearest stable 
fixed point to its left. If x  0,  
then x remains constant. The 
qualitative form of the solu-
tion for any initial condition is 
sketched in Figure 2.1.3.
x
4
t
–π
π
Figure 2.1.2

18 
FLOWS ON THE LINE
x
t
0
π
−π
−2π
2π
Figure 2.1.3
In all honesty, we should admit that a picture can’t tell us certain quantitative 
things: for instance, we don’t know the time at which the speed x  is greatest. But 
in many cases qualitative information is what we care about, and then pictures are 
fine.
2.2 Fixed Points and Stability
The ideas developed in the last section can be extended to any one-dimensional 
system x
f x

( ). We just need to draw the graph of f  ( x ) and then use it to sketch 
the vector field on the real line (the x-axis in Figure 2.2.1).
x˙
x
f(x)
Figure 2.2.1

19
2.2 FIXED POINTS AND STABILITY
As before, we imagine that a fluid is flowing along the real line with a local velocity 
f  ( x ). This imaginary fluid is called the phase fluid, and the real line is the phase 
space. The flow is to the right where f  ( x ) > 0 and to the left where f  ( x )  0. To 
find the solution to x
f x

( )  starting from an arbitrary initial condition x0, we 
place an imaginary particle (known as a phase point) at x0 and watch how it is 
carried along by the flow. As time goes on, the phase point moves along the x-axis 
according to some function x ( t ). This function is called the trajectory based at x0, 
and it represents the solution of the differential equation starting from the initial 
condition x0. A picture like Figure 2.2.1, which shows all the qualitatively different 
trajectories of the system, is called a phase portrait.
The appearance of the phase portrait is controlled by the fixed points x*, defined 
by f  ( x*)  0; they correspond to stagnation points of the flow. In Figure 2.2.1, the 
solid black dot is a stable fixed point (the local flow is toward it) and the open dot 
is an unstable fixed point (the flow is away from it).
In terms of the original differential equation, fixed points represent equilibrium 
solutions (sometimes called steady, constant, or rest solutions, since if x  x* ini-
tially, then x ( t )  x* for all time). An equilibrium is defined to be stable if all suf-
ficiently small disturbances away from it damp out in time. Thus stable equilibria 
are represented geometrically by stable fixed points. Conversely, unstable equilib-
ria, in which disturbances grow in time, are represented by unstable fixed points.
EXAMPLE 2.2.1:
Find all fixed points for x
x
=
−
2
1, and classify their stability.
Solution: Here f  ( x )  x2 – 1. To find the fixed points, we set f  ( x*)  0 and solve 
for x*. Thus x*  o1. To determine stability, we plot x2 –1 and then sketch the 
vector field (Figure 2.2.2). The flow is to the right where x2 – 1 > 0 and to the left 
where x2 – 1  0. Thus x*  –1 is stable, and x*  1 is unstable. 
x˙
x
f(x) =  x2 − 1
Figure 2.2.2

20 
FLOWS ON THE LINE
Note that the definition of stable equilibrium is based on small disturbances; 
certain large disturbances may fail to decay. In Example 2.2.1, all small distur-
bances to x*  –1 will decay, but a large disturbance that sends x to the right 
of x  1 will not decay—in fact, the phase point will be repelled out to d. To 
emphasize this aspect of stability, we sometimes say that x*  –1 is locally stable, 
but not globally stable.
EXAMPLE 2.2.2:
Consider the electrical circuit shown in Figure 2.2.3. A resistor R and a capacitor 
C are in series with a battery of constant dc voltage V0. Suppose that the switch 
is closed at t  0, and that there is no charge on the capacitor initially. Let Q ( t ) 
denote the charge on the capacitor at time t p 0. Sketch the graph of Q ( t ).
Solution: This type of circuit problem 
is probably familiar to you. It is governed 
by linear equations and can be solved 
analytically, but we prefer to illustrate 
the geometric approach.
First we write the circuit equations. 
As we go around the circuit, the total 
voltage drop must equal zero; hence 
–V0  RI  Q / C  0, where I is the cur-
rent flowing through the resistor. This 
current causes charge to accumulate on 
the capacitor at a rate Q
I
 . Hence
−
+
+
=
=
=
−
V
RQ
Q C
Q
f Q
V
R
Q
RC
0
0
0


  or
(
)
.
The graph of f  ( Q ) is a straight line with a negative slope (Figure 2.2.4). The corre-
sponding vector field has a fixed point where f  ( Q )  0, which occurs at Q*  CV0. 
The flow is to the right where f  ( Q ) > 0 and 
to the left where f  ( Q )  0. Thus the flow is 
always toward Q*—it is a stable fixed point. 
In fact, it is globally stable, in the sense that it 
is approached from all initial conditions.
To sketch Q ( t ), we start a phase point at 
the origin of Figure 2.2.4 and imagine how 
it would move. The flow carries the phase 
point monotonically toward Q*. Its speed Q  
I
R
C
V0
+
−
Figure 2.2.3
Q˙
f(Q)
Q*
Q
Figure 2.2.4

21
2.3 POPULATION GROWTH
decreases linearly as it approaches the fixed point; therefore Q ( t ) is increasing and 
concave down, as shown in Figure 2.2.5. 
EXAMPLE 2.2.3:
Sketch the phase portrait corresponding 
to x
x
x
=
−cos , and determine the sta-
bility of all the fixed points. 
Solution: One approach would be to 
plot the function f  ( x )  x – cos x and 
then sketch the associated vector field. 
This method is valid, but it requires you 
to figure out what the graph of x – cos x 
looks like.
There’s an easier solution, which exploits the fact that we know how to graph 
y  x and y  cos x separately. We plot both graphs on the same axes and then 
observe that they intersect in exactly one point (Figure 2.2.6).
y = cos x
y = x
x
x*
Figure 2.2.6
This intersection corresponds to a fixed point, since x*  cos x* and therefore 
f  ( x*)  0. Moreover, when the line lies above the cosine curve, we have x > cos 
x and so x  0 : the flow is to the right. Similarly, the flow is to the left where the 
line is below the cosine curve. Hence x* is the only fixed point, and it is unstable. 
Note that we can classify the stability of x*, even though we don’t have a formula 
for x* itself! 
2.3 Population Growth
The simplest model for the growth of a population of organisms is N
rN

,  
where N ( t ) is the population at time t, and r  0 is the growth rate. This model 
Q
t
CV0
Figure 2.2.5

22 
FLOWS ON THE LINE
predicts exponential growth: 
N ( t )  N0ert, where N0 is the 
population at t  0.
Of course such exponen-
tial growth cannot go on for-
ever. To model the effects of 
overcrowding 
and 
limited 
resources, population biolo-
gists and demographers often 
assume that the per capita 
growth rate 
N N  decreases 
when N becomes sufficiently 
large, as shown in Figure 2.3.1. 
For small N, the growth 
rate equals r, just as before. 
However, 
for 
populations 
larger than a certain carrying 
capacity K, the growth rate 
actually becomes negative; the 
death rate is higher than the 
birth rate.
A mathematically conve-
nient way to incorporate these ideas is to assume that the per capita growth rate 
N N  decreases linearly with N (Figure 2.3.2).
This leads to the logistic equation
N
rN
N
K
=
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
1
first suggested to describe the growth of human populations by Verhulst in 1838. 
This equation can be solved analytically (Exercise 2.3.1) but once again we prefer 
a graphical approach. We plot N  versus N to see what the vector field looks like. 
Note that we plot only N p 0, since it makes no sense to think about a negative 
population (Figure 2.3.3). Fixed points occur at N*  0 and N*  K, as found by 
setting N  0  and solving for N. By looking at the flow in Figure 2.3.3, we see that 
N*  0 is an unstable fixed point and N*  K is a stable fixed point. In biological 
terms, N  0 is an unstable equilibrium: a small population will grow exponen-
tially fast and run away from N  0. On the other hand, if N is disturbed slightly 
from K, the disturbance will decay monotonically and N ( t ) l K as t l d.
In fact, Figure 2.3.3 shows that if we start a phase point at any N0 > 0, it will 
always flow toward N  K. Hence the population always approaches the carrying 
capacity.
The only exception is if N0  0; then there’s nobody around to start reproducing, 
and so N  0 for all time. (The model does not allow for spontaneous generation!)
Growth rate
r
K
N
Figure 2.3.1
Growth rate
r
K
N
Figure 2.3.2

23
2.3 POPULATION GROWTH
N˙
K/2
K
N
Figure 2.3.3
Figure 2.3.3 also allows us to deduce the qualitative shape of the solutions. 
For example, if N0  K / 2, the phase point moves faster and faster until it crosses 
N  K / 2, where the parabola in Figure 2.3.3 reaches its maximum. Then the phase 
point slows down and eventually creeps toward N  K. In biological terms, this 
means that the population initially grows in an accelerating fashion, and the graph 
of N ( t ) is concave up. But after N  K / 2, the derivative N  begins to decrease, and 
so N ( t ) is concave down as it asymptotes to the horizontal line N  K (Figure 2.3.4). 
Thus the graph of N ( t ) is S-shaped or sigmoid for N0  K / 2.
N
K/2
K
t
Figure 2.3.4
Something qualitatively different occurs if the initial condition N0 lies between 
K / 2 and K; now the solutions are decelerating from the start. Hence these solutions 
are concave down for all t. If the population initially exceeds the carrying capacity 
( N0 > K ), then N ( t ) decreases toward N  K and is concave up. Finally, if N0  0 
or N0  K, then the population stays constant.
Critique of the Logistic Model
Before leaving this example, we should make a few comments about the biolog-
ical validity of the logistic equation. The algebraic form of the model is not to be 
taken literally. The model should really be regarded as a metaphor for populations 
that have a tendency to grow from zero population up to some carrying capacity K.

24 
FLOWS ON THE LINE
Originally a much stricter interpretation was proposed, and the model was 
argued to be a universal law of growth (Pearl 1927). The logistic equation was 
tested in laboratory experiments in which colonies of bacteria, yeast, or other 
simple organisms were grown in conditions of constant climate, food supply, and 
absence of predators. For a good review of this literature, see Krebs (1972, pp. 
190–200). These experiments often yielded sigmoid growth curves, in some cases 
with an impressive match to the logistic predictions.
On the other hand, the agreement was much worse for fruit flies, flour beetles, 
and other organisms that have complex life cycles involving eggs, larvae, pupae, 
and adults. In these organisms, the predicted asymptotic approach to a steady 
carrying capacity was never observed—instead the populations exhibited large, 
persistent fluctuations after an initial period of logistic growth. See Krebs (1972) 
for a discussion of the possible causes of these fluctuations, including age structure 
and time-delayed effects of overcrowding in the population.
For further reading on population biology, see Pielou (1969) or May (1981). 
Edelstein–Keshet (1988) and Murray (2002, 2003) are excellent textbooks on math-
ematical biology in general.
2.4 Linear Stability Analysis
So far we have relied on graphical methods to determine the stability of fixed 
points. Frequently one would like to have a more quantitative measure of stability, 
such as the rate of decay to a stable fixed point. This sort of information may be 
obtained by linearizing about a fixed point, as we now explain.
Let x* be a fixed point, and let I ( t )  x ( t ) – x* be a small perturbation away 
from x*. To see whether the perturbation grows or decays, we derive a differential 
equation for I. Differentiation yields


I =
−
=
d
dt x
x
x
(
*)
,
since x* is constant. Thus 

I
I
=
=
=
+
x
f x
f x
( )
( *
). Now using Taylor’s expan-
sion we obtain
f  ( x*  I )  f  ( x*)  I f ′ ( x*)  O ( I2 )  ,
where O ( I2 ) denotes quadratically small terms in I. Finally, note that f  ( x*)  0 
since x* is a fixed point. Hence
I
I
I
=
+
f
x
O
′( *)
(
).
2
Now if f ′( x*) v 0, the O ( I2 ) terms are negligible and we may write the 
approximation

25
2.4 LINEAR STABILITY ANALYSIS
I
I
≈
′
f
x
( *) .
This is a linear equation in I, and is called the linearization about x*. It shows that 
the perturbation I ( t ) grows exponentially if f ′( x*)  0 and decays if f ′( x*)  0. If 
f ′( x*)  0, the O ( I2) terms are not negligible and a nonlinear analysis is needed 
to determine stability, as discussed in Example 2.4.3 below.
The upshot is that the slope f ′( x*) at the fixed point determines its stability. If 
you look back at the earlier examples, you’ll see that the slope was always negative 
at a stable fixed point. The importance of the sign of f ′( x*) was clear from our 
graphical approach; the new feature is that now we have a measure of how stable 
a fixed point is—that’s determined by the magnitude of f ′( x*). This magnitude 
plays the role of an exponential growth or decay rate. Its reciprocal 1 / | f ′( x*)| is 
a characteristic time scale; it determines the time required for x ( t ) to vary signifi-
cantly in the neighborhood of x*.
EXAMPLE 2.4.1:
Using linear stability analysis, determine the stability of the fixed points for 
x
x
 sin .
Solution: The fixed points occur where f  ( x )  sin x  0. Thus x*  kQ, where 
k is an integer. Then
′
=
= −
⎧
⎨⎪⎪
⎩⎪⎪
f
x
k
k
k
( *)
cos
,
Q
1   even
1,  odd.
Hence x* is unstable if k is even and stable if k is odd. This agrees with the results 
shown in Figure 2.1.1. 
EXAMPLE 2.4.2:
Classify the fixed points of the logistic equation, using linear stability analysis, and 
find the characteristic time scale in each case.
Solution: Here f N
rN
N
K
(
) =
−
(
)
1
, with fixed points N*  0 and N*  K. Then 
′
= −
f
N
r
rN
K
(
)
2
 and so f ′(0)  r and f ′( K )  –r. Hence N*  0 is unstable and 
N*  K is stable, as found earlier by graphical arguments. In either case, the char-
acteristic time scale is 1
1
f
N
r
′(
*)
.

 
EXAMPLE 2.4.3:
What can be said about the stability of a fixed point when f ′( x*)  0 ? 
Solution: Nothing can be said in general. The stability is best determined on 
a case-by-case basis, using graphical methods. Consider the following examples:
(a) x
x
= −
3  
(b) x
x

3  
(c) x
x

2  
(d) x  0

26 
FLOWS ON THE LINE
Each of these systems has a fixed point x*  0 with f ′( x*)  0. However the stabil-
ity is different in each case. Figure 2.4.1 shows that (a) is stable and (b) is unstable. 
Case (c) is a hybrid case we’ll call half-stable, since the fixed point is attracting from 
the left and repelling from the right. We therefore indicate this type of fixed point 
by a half-filled circle. Case (d) is a whole line of fixed points; perturbations neither 
grow nor decay.
These examples may seem artificial, but we will see that they arise naturally in the 
context of bifurcations—more about that later. 
2.5 Existence and Uniqueness
Our treatment of vector fields has been very informal. In particular, we have taken 
a cavalier attitude toward questions of existence and uniqueness of solutions to 
the system x
f x

( ). That’s in keeping with the “applied” spirit of this book. 
Nevertheless, we should be aware of what can go wrong in pathological cases.
x˙
x˙
x˙
x˙
x
x
x
(d)
(b)
(a)
(c)
x
Figure 2.4.

27
2.5 EXISTENCE AND UNIQUENESS
EXAMPLE 2.5.1:
Show that the solution to x
x

1 3
/  starting from x0  0 is not unique.
Solution: The point x  0 is a fixed point, so one obvious solution is x ( t )  0 
for all t. The surprising fact is that there is another solution. To find it we separate 
variables and integrate:
x
dx
dt
−
= ∫
∫
1 3
/
so 3
2
2 3
x
t
C
/
.
= +
 Imposing the initial condition x (0)  0 yields C  0. Hence 
x t
t
( )
/
=(
)
2
3
3 2  is also a solution! 
When uniqueness fails, our geometric approach collapses because the phase 
point doesn’t know how to move; if a phase point were started at the origin, would 
it stay there or would it move according to x t
t
( )
/
=(
)
2
3
3 2 ? (Or as my friends in 
elementary school used to say when discussing the problem of the irresistible force 
and the immovable object, perhaps the phase point would explode!)
Actually, the situation in Example 2.5.1 is even worse than we’ve let on—there 
are infinitely many solutions starting from the 
same initial condition (Exercise 2.5.4).
What’s the source of the non-uniqueness? 
A hint comes from looking at the vector field 
(Figure  2.5.1). We see that the fixed point 
x*    0 is very unstable—the slope f ′(0) is 
infinite. 
Chastened by this example, we state a the-
orem that provides sufficient conditions for 
existence and uniqueness of solutions to x
f x

( ).
Existence and Uniqueness Theorem: Consider the initial value problem 
x
f x

( ),  
x (0)  x0  .
Suppose that f ( x ) and f ′( x ) are continuous on an open interval R of the x-axis, 
and suppose that x0 is a point in R. Then the initial value problem has a solution 
x ( t ) on some time interval (U, U) about t  0, and the solution is unique.
For proofs of the existence and uniqueness theorem, see Borrelli and Coleman 
(1987), Lin and Segel (1988), or virtually any text on ordinary differential equations.
This theorem says that if f ( x ) is smooth enough, then solutions exist and are 
unique. Even so, there’s no guarantee that solutions exist forever, as shown by the 
next example. 
x˙
x
Figure 2.5.1

28 
FLOWS ON THE LINE
EXAMPLE 2.5.2:
Discuss the existence and uniqueness of solutions to the initial value problem 
x
x
= +
1
2,  x (0)  x0. Do solutions exist for all time?
Solution: Here f ( x )  1  x2. This function is continuous and has a continuous 
derivative for all x. Hence the theorem tells us that solutions exist and are unique 
for any initial condition x0. But the theorem does not say that the solutions exist for 
all time; they are only guaranteed to exist in a (possibly very short) time interval 
around t  0.
For example, consider the case where x (0)  0. Then the problem can be solved 
analytically by separation of variables:
dx
x
dt
1
2
+
=
∫
∫
,
which yields
tan–1 x  t  C.
The initial condition x (0)  0 implies C  0. Hence x ( t )  tan t is the solution. 
But notice that this solution exists only for –Q / 2  t  Q / 2, because x ( t ) l od 
as t l oQ / 2. Outside of that time interval, there is no solution to the initial value 
problem for x0  0. 
The amazing thing about Example 2.5.2 is that the system has solutions that 
reach infinity in finite time. This phenomenon is called blow-up. As the name 
suggests, it is of physical relevance in models of combustion and other runaway 
processes.
There are various ways to extend the existence and uniqueness theorem. One 
can allow f to depend on time t, or on several variables x1, … , xn. One of the most 
useful generalizations will be discussed later in Section 6.2.
From now on, we will not worry about issues of existence and uniqueness—our 
vector fields will typically be smooth enough to avoid trouble. If we happen to 
come across a more dangerous example, we’ll deal with it then.
2.6 Impossibility of Oscillations
Fixed points dominate the dynamics of first-order systems. In all our examples 
so far, all trajectories either approached a fixed point, or diverged to od. In fact, 
those are the only things that can happen for a vector field on the real line. The rea-
son is that trajectories are forced to increase or decrease monotonically, or remain 
constant (Figure 2.6.1). To put it more geometrically, the phase point never reverses 
direction.

29
2.6 IMPOSSIBILITY OF OSCILLATIONS
x˙
x
Figure 2.6.1
Thus, if a fixed point is regarded as an equilibrium solution, the approach to 
equilibrium is always monotonic—overshoot and damped oscillations can never 
occur in a first-order system. For the same reason, undamped oscillations are 
impossible. Hence there are no periodic solutions to x
f x

( ).
These general results are fundamentally topological in origin. They reflect the 
fact that x
f x

( )  corresponds to flow on a line. If you flow monotonically on a 
line, you’ll never come back to your starting place—that’s why periodic solutions 
are impossible. (Of course, if we were dealing with a circle rather than a line, we 
could eventually return to our starting place. Thus vector fields on the circle can 
exhibit periodic solutions, as we discuss in Chapter 4.)
Mechanical Analog: Overdamped Systems
It may seem surprising that solutions to x
f x

( )  can’t oscillate. But this 
result becomes obvious if we think in terms of a mechanical analog. We regard 
x
f x

( )  as a limiting case of Newton’s law, in the limit where the “inertia term” 
mx is negligible. 
For example, suppose a mass m is attached to a nonlinear spring whose restor-
ing force is F  ( x ), where x is the displacement from the origin. Furthermore, sup-
pose that the mass is immersed in a vat of very viscous fluid, like honey or motor 
oil (Figure 2.6.2), so that it is subject to a damping force bx . Then Newton’s law is 
mx
bx
F x


+
=
( ).
If the viscous damping is strong compared 
to the inertia term bx
mx


>>
(
), the system 
should behave like bx
F x
 
( ),  or equivalently 
x
f x

( ) , where f  ( x )  b–1F  ( x ). In this over 
damped limit, the behavior of the mechanical 
system is clear. The mass prefers to sit at a sta-
ble equilibrium, where f  ( x )  0 and f ′( x )  0. 
If displaced a bit, the mass is slowly dragged 
back to equilibrium by the restoring force. No 
overshoot can occur, because the damping is 
honey
m
F(x)
Figure 2.6.2

30 
FLOWS ON THE LINE
enormous. And undamped oscillations are out of the question! These conclusions 
agree with those obtained earlier by geometric reasoning.
Actually, we should confess that this argument contains a slight swindle. The 
neglect of the inertia term mx is valid, but only after a rapid initial transient 
during which the inertia and damping terms are of comparable size. An honest 
discussion of this point requires more machinery than we have available. We’ll 
return to this matter in Section 3.5.
2.7 Potentials
There’s another way to visualize the dynamics of the first-order system x
f x

( ), 
based on the physical idea of potential energy. We picture a particle sliding down 
the walls of a potential well, where the potential V ( x ) is defined by
f x
dV
dx
( )
.
= −
As before, you should imagine that the particle is heavily damped—its inertia 
is completely negligible compared to the damping force and the force due to the 
potential. For example, suppose that the particle has to slog through a thick layer 
of goo that covers the walls of the potential (Figure 2.7.1).
V(x)
goo
x
Figure 2.7.1
The negative sign in the definition of V follows the standard convention in physics; 
it implies that the particle always moves “downhill” as the motion proceeds. To 
see this, we think of x as a function of t, and then calculate the time-derivative of 
V ( x ( t )). Using the chain rule, we obtain 

31
2.7 POTENTIALS
dV
dt
dV
dx
dx
dt

.
Now for a first-order system,
dx
dt
dV
dx
= −
,
since x
f x
dV dx
=
= −
( )
,
/
 by the definition of the potential. Hence,
dV
dt
dV
dx
= −⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟≤
2
0.
Thus V ( t ) decreases along trajectories, and so the particle always moves toward 
lower potential. Of course, if the particle happens to be at an equilibrium point 
where dV / dx  0, then V remains constant. This is to be expected, since dV / dx  0 
implies x  0;  equilibria occur at the fixed points of the vector field. Note that local 
minima of V ( x ) correspond to stable fixed points, as we’d expect intuitively, and 
local maxima correspond to unstable fixed points.
EXAMPLE 2.7.1:
Graph the potential for the system x
x
= −, and iden-
tify all the equilibrium points.
Solution: We need to find V ( x ) such that 
–dV / dx  –x. The general solution is V x
x
C
( )
,
=
+
1
2
2
 
where C is an arbitrary constant. (It always happens 
that the potential is only defined up to an additive 
constant. For convenience, we usually choose C  0.) 
The graph of V ( x ) is shown in Figure 2.7.2. The only equilibrium point occurs at 
x  0, and it’s stable. 
EXAMPLE 2.7.2:
Graph the potential for the system x
x
x
=
−
3, and 
identify all equilibrium points.
Solution: Solving –dV / dx    x – x3 yields 
V
x
x
C
= −
+
+
1
2
2
1
4
4
.  Once again we set C    0. 
Figure 2.7.3 shows the graph of V. The local minima 
at x    ±1 correspond to stable equilibria, and the 
local maximum at x  0 corresponds to an unstable equilibrium. The potential 
shown in Figure 2.7.3 is often called a double-well potential, and the system is said 
to be bistable, since it has two stable equilibria. 
V(x)
x
Figure 2.7.2
V(x)
x
−1
1
Figure 2.7.3

32 
FLOWS ON THE LINE
2.8 Solving Equations on the Computer
Throughout this chapter we have used graphical and analytical methods to ana-
lyze first-order systems. Every budding dynamicist should master a third tool: 
numerical methods. In the old days, numerical methods were impractical because 
they required enormous amounts of tedious hand-calculation. But all that has 
changed, thanks to the computer. Computers enable us to approximate the solu-
tions to analytically intractable problems, and also to visualize those solutions. In 
this section we take our first look at dynamics on the computer, in the context of 
numerical integration of x
f x

( ).
Numerical integration is a vast subject. We will barely scratch the surface. See 
Chapter 17 of Press et al. (2007) for an excellent treatment.
Euler’s Method
The problem can be posed this way: given the differential equation x
f x

( ), 
subject to the condition x  x0 at t  t0, find a systematic way to approximate the 
solution x ( t ).
Suppose we use the vector field interpretation of x
f x

( ) . That is, we think of 
a fluid flowing steadily on the x-axis, with velocity f  ( x ) at the location x. Imagine 
we’re riding along with a phase point being carried downstream by the fluid. 
Initially we’re at x0, and the local velocity is f  ( x0). If we flow for a short time %t, 
we’ll have moved a distance f  ( x0)%t, because distance  rate q time. Of course, 
that’s not quite right, because our velocity was changing a little bit throughout the 
step. But over a sufficiently small step, the velocity will be nearly constant and our 
approximation should be reasonably good. Hence our new position x ( t0  %t  ) is 
approximately x0  f  ( x0) %t. Let’s call this approximation x1. Thus
x ( t0  %t ) x x1  x0  f  ( x0)%t  .
Now we iterate. Our approximation has taken us to a new location x1 ; our new 
velocity is f  ( x1) ; we step forward to x2  x1  f  ( x1) %t ; and so on. In general, the 
update rule is
xn+1  xn  f  ( xn) %t  .
This is the simplest possible numerical integration scheme. It is known as Euler’s 
method.
Euler’s method can be visualized by plotting x versus t (Figure 2.8.1). The curve 
shows the exact solution x ( t ), and the open dots show its values x ( tn ) at the dis-
crete times tn  t0  n%t. The black dots show the approximate values given by the 
Euler method. As you can see, the approximation gets bad in a hurry unless %t is 
extremely small. Hence Euler’s method is not recommended in practice, but it con-
tains the conceptual essence of the more accurate methods to be discussed next. 

33
2.8 SOLVING EQUATIONS ON THE COMPUTER
Euler
exact
x1
x0
x(t1)
t0
t1
t2
Figure 2.8.1
Refinements
One problem with the Euler method is that it estimates the derivative only at the 
left end of the time interval between tn and tn+1. A more sensible approach would 
be to use the average derivative across this interval. This is the idea behind the 
improved Euler method. We first take a trial step across the interval, using the Euler 
method. This produces a trial value x
x
f x
t
n
n
n
+ =
+
1
(
)
;
Δ
 the tilde above the x 
indicates that this is a tentative step, used only as a probe. Now that we’ve esti-
mated the derivative on both ends of the interval, we average f  ( xn ) and f xn
(
),
 1
 
and use that to take the real step across the interval. Thus the improved Euler 
method is
x
x
f x
t
n
n
n
+ =
+
1
(
)Δ  
 
 
 
(the trial step)
x
x
f x
f x
t
n
n
n
n
+
+
=
+
+
⎡⎣
⎤⎦
1
1
2
1
(
)
(
)

Δ . 
 
(the real step)
This method is more accurate than the Euler method, in the sense that it tends to 
make a smaller error E  |x ( tn ) – xn| for a given stepsize %t. In both cases, the error 
E l 0 as %t l 0, but the error decreases faster for the improved Euler method. 
One can show that E r %t for the Euler method, but E r (%t )2 for the improved 
Euler method (Exercises 2.8.7 and 2.8.8). In the jargon of numerical analysis, the 
Euler method is first order, whereas the improved Euler method is second order.
Methods of third, fourth, and even higher orders have been concocted, but 
you should realize that higher order methods are not necessarily superior. Higher 
order methods require more calculations and function evaluations, so there’s a 
computational cost associated with them. In practice, a good balance is achieved 
by the fourth-order Runge–Kutta method. To find xn+1 in terms of xn , this method 
first requires us to calculate the following four numbers (cunningly chosen, as 
you’ll see in Exercise 2.8.9):

34 
FLOWS ON THE LINE
k
f x
t
k
f x
k
t
k
f x
k
t
k
f x
k
t
n
n
n
n
1
2
1
2
1
3
1
2
2
4
3
=
=
+
=
+
=
+
(
)
(
)
(
)
(
)
.
Δ
Δ
Δ
Δ
Then xn+1 is given by
x
x
k
k
k
k
n
n
+ =
+
+
+
+
1
1
6
1
2
3
4
2
2
(
).
This method generally gives accurate results without requiring an excessively 
small stepsize %t. Of course, some problems are nastier, and may require small 
steps in certain time intervals, while permitting very large steps elsewhere. In such 
cases, you may want to use a Runge–Kutta routine with an automatic stepsize 
control; see Press et al. (2007) for details.
Now that computers are so fast, you may wonder why we don’t just pick a tiny 
%t once and for all. The trouble is that excessively many computations will occur, 
and each one carries a penalty in the form of round-off error. Computers don’t have 
infinite accuracy—they don’t distinguish between numbers that differ by some 
small amount E. For numbers of order 1, typically E x 10–7 for single precision and 
E x 10–16 for double precision. Round-off error occurs during every calculation, 
and will begin to accumulate in a serious way if %t is too small. See Hubbard and 
West (1991) for a good discussion.
Practical Matters
You have several options if you want to solve differential equations on the com-
puter. If you like to do things yourself, you can write your own numerical integra-
tion routines in your favorite programming language, and plot the results using 
whatever graphics programs are available. The information given above should be 
enough to get you started. For further guidance, consult Press et al. (2007).
A second option is to use existing packages for numerical methods. Matlab, 
Mathematica, and Maple all have programs for solving ordinary differential equa-
tions and graphing their solutions.
The final option is for people who want to explore dynamics, not computing. 
Dynamical systems software is available for personal computers. All you have to 
do is type in the equations and the parameters; the program solves the equations 
numerically and plots the results. Some recommended programs are PPlane (writ-
ten by John Polking and available online as a Java applet; this is a pleasant choice 
for beginners) and XPP (by Bard Ermentrout, available on many platforms includ-
ing iPhone and iPad; this is a more powerful tool for researchers and serious users).

35
2.8 SOLVING EQUATIONS ON THE COMPUTER
EXAMPLE 2.8.1:
Solve the system x
x
x
=
−
(
)
1
 numerically.
Solution: This is a logistic equation (Section 2.3) with parameters r  1, K  1. 
Previously we gave a rough sketch of the solutions, based on geometric arguments; 
now we can draw a more quantitative picture.
As a first step, we plot the slope field for the system in the ( t, x ) plane (Figure 2.8.2). 
Here the equation x
x
x
=
−
(
)
1
is being interpreted in a new way: for each point 
( t, x ), the equation gives the slope dx / dt of the solution passing through that point. 
The slopes are indicated by little line segments in Figure 2.8.2.
Finding a solution now becomes a problem of drawing a curve that is always 
tangent to the local slope. Figure 2.8.3 shows four solutions starting from various 
points in the ( t, x ) plane.
2
1
0
5
10
t
x
Figure 2.8.2
2
1
0
5
10
t
x
Figure 2.8.3
These numerical solutions were computed using the Runge–Kutta method with 
a stepsize %t  0.1. The solutions have the shape expected from Section 2.3. 
Computers are indispensable for studying dynamical systems. We will use them 
liberally throughout this book, and you should do likewise.

36 
FLOWS ON THE LINE
EXERCISES FOR CHAPTER 2
2.1 
A Geometric Way of Thinking
In the next three exercises, interpret x
x
 sin
 as a flow on the line.
2.1.1 
Find all the fixed points of the flow.
2.1.2 
At which points x does the flow have greatest velocity to the right?
2.1.3 
a) Find the flow’s acceleration x  as a function of x.
b) Find the points where the flow has maximum positive acceleration.
2.1.4 
(Exact solution of x
x
 sin
) As shown in the text, x
x
 sin
has the solu-
tion t  ln | (csc x0  cot x0) / (csc x  cot x ) |, where x0= x (0) is the initial value of x.
a) Given the specific initial condition x0  Q / 4, show that the solution above can 
be inverted to obtain
x t
et
( )
tan
.
=
+
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
−
2
1
2
1
 
Conclude that x ( t ) l Q as t l d, as claimed in Section 2.1. (You need to be 
good with trigonometric identities to solve this problem.)
b) Try to find the analytical solution for x ( t ), given an arbitrary initial condition 
x0.
2.1.5 
(A mechanical analog)
a) Find a mechanical system that is approximately governed by x
x
 sin
.
b) Using your physical intuition, explain why it now becomes obvious that x*  0 
is an unstable fixed point and x*  Q is stable.
2.2 
Fixed Points and Stability
Analyze the following equations graphically. In each case, sketch the vector field 
on the real line, find all the fixed points, classify their stability, and sketch the 
graph of x ( t ) for different initial conditions. Then try for a few minutes to obtain 
the analytical solution for x ( t ); if you get stuck, don’t try for too long since in sev-
eral cases it’s impossible to solve the equation in closed form!
2.2.1 
x
x
=
−
4
16
2
 
 
2.2.2 
x
x
= −
1
14
2.2.3 
x
x
x
=
−
3  
 
2.2.4 
x
e
x
x
=
−sin
2.2.5 
x
x
= +
1
1
2 cos
  
2.2.6 
x
x
= −
1
2cos

37
EXERCISES
2.2.7 
x
e
x
x
=
−cos
 (Hint: Sketch the graphs of ex and cos x on the same axes, 
and look for intersections. You won’t be able to find the fixed points explicitly, but 
you can still find the qualitative behavior.)
2.2.8 
(Working backwards, from flows to equations) Given an equation
x
f x

( ) , we know how to sketch the corresponding flow on the real line. Here 
you are asked to solve the opposite problem: For the phase portrait shown in 
Figure 1, find an equation that is consistent with it. (There are an infinite number 
of correct answers—and wrong ones too.)
–1
0
2
Figure 1
2.2.9 
(Backwards again, now from solutions to equations) Find an equation 
x
f x

( )  whose solutions x ( t) are consistent with those shown in Figure 2.
x
t
1
−1
0
Figure 2
2.2.10 
(Fixed points) For each of (a)–(e), find an equation x
f x

( )  with the 
stated properties, or if there are no examples, explain why not. (In all cases, assume 
that f  ( x ) is a smooth function.)
a) Every real number is a fixed point.
b) Every integer is a fixed point, and there are no others.
c) There are precisely three fixed points, and all of them are stable.
d) There are no fixed points.
e) There are precisely 100 fixed points.
2.2.11 
(Analytical solution for charging capacitor) Obtain the analytical solu-
tion of the initial value problem Q
V
R
Q
RC
=
−
0
, with Q ( 0)  0, which arose in 
Example 2.2.2.

38 
FLOWS ON THE LINE
2.2.12 
(A nonlinear resistor) Suppose the 
resistor in Example 2.2.2 is replaced by a nonlinear 
resistor. In other words, this resistor does not have 
a linear relation between voltage and current. Such 
nonlinearity arises in certain solid-state devices. 
Instead of IR  V / R, suppose we have IR  g ( V ), 
where g ( V ) has the shape shown in Figure 3.
Redo Example 2.2.2 in this case. Derive the cir-
cuit equations, find all the fixed points, and ana-
lyze their stability. What qualitative effects does 
the nonlinearity introduce (if any)?
2.2.13 
(Terminal velocity) The velocity v ( t ) of a skydiver falling to the ground is 
governed by mv
mg
kv
 =
−
2, where m is the mass of the skydiver, g is the accelera-
tion due to gravity, and k > 0 is a constant related to the amount of air resistance.
a) Obtain the analytical solution for v ( t ), assuming that v (0)  0.
b) Find the limit of v ( t ) as t l d. This limiting velocity is called the terminal 
velocity. (Beware of bad jokes about the word terminal and parachutes that fail 
to open.)
c) Give a graphical analysis of this problem, and thereby re-derive a formula for 
the terminal velocity.
d) An experimental study (Carlson et al. 1942) confirmed that the equation 
mv
mg
kv
 =
−
2 gives a good quantitative fit to data on human skydivers. Six 
men were dropped from altitudes varying from 10,600 feet to 31,400 feet to a 
terminal altitude of 2,100 feet, at which they opened their parachutes. The long 
free fall from 31,400 to 2,100 feet took 116 seconds. The average weight of the 
men and their equipment was 261.2 pounds. In these units, g  32.2 ft / sec2. 
Compute the average velocity Vavg .
e) Using the data given here, estimate the terminal velocity, and the value of the 
drag constant k. (Hints: First you need to find an exact formula for s ( t ), the 
distance fallen, where s (0)  0, s
v

, and v ( t ) is known from part (a). You 
should get s t
V
g
gt
V
( )
ln cosh
,
=
(
)
2
 where V is the terminal velocity. Then solve 
for V graphically or numerically, using s  29,300, t  116, and g  32.2.)
A slicker way to estimate V is to suppose V x Vavg, as a rough first approxi-
mation. Then show that gt / V x 15. Since gt / V >> 1, we may use the approxima-
tion ln(cosh x ) x x – ln 2 for x >> 1. Derive this approximation and then use it 
to obtain an analytical estimate of V. Then k follows from part (b). This analysis 
is from Davis (1962).
2.3 
Population Growth
2.3.1 
(Exact solution of logistic equation) There are two ways to solve the logis-
tic equation N
rN
N K
=
−
(
)
1
 analytically for an arbitrary initial condition 
N0.
I
V
g(V)
Figure 3

39
EXERCISES
a) Separate variables and integrate, using partial fractions.
b) Make the change of variables x  1 / N. Then derive and solve the resulting dif-
ferential equation for x.
2.3.2 
(Autocatalysis) Consider the model chemical reaction
A
X
X
k
k
+
⎯
→
⎯
←
⎯
⎯
−
1
1
2
in which one molecule of X combines with one molecule of A to form two mole-
cules of X. This means that the chemical X stimulates its own production, a pro-
cess called autocatalysis. This positive feedback process leads to a chain reaction, 
which eventually is limited by a “back reaction” in which 2X returns to A  X.
According to the law of mass action of chemical kinetics, the rate of an elemen-
tary reaction is proportional to the product of the concentrations of the reactants. 
We denote the concentrations by lowercase letters x  [X] and a  [A]. Assume 
that there’s an enormous surplus of chemical A, so that its concentration a can be 
regarded as constant. Then the equation for the kinetics of x is
x
k ax
k x
=
−
−
1
1
2
where k1 and k–1 are positive parameters called rate constants.
a) Find all the fixed points of this equation and classify their stability.
b) Sketch the graph of x ( t ) for various initial values x0.
2.3.3 
(Tumor growth) The growth of cancerous tumors can be modeled by the 
Gompertz law N
aN
bN
= −
ln(
), where N ( t ) is proportional to the number of 
cells in the tumor, and a, b > 0 are parameters.
a) Interpret a and b biologically.
b) Sketch the vector field and then graph N ( t ) for various initial values.
The predictions of this simple model agree surprisingly well with data on tumor 
growth, as long as N is not too small; see Aroesty et al. (1973) and Newton (1980) 
for examples.
2.3.4 
(The Allee effect) For certain species of organisms, the effective growth 
rate N N  is highest at intermediate N. This is called the Allee effect (Edelstein–
Keshet 1988). For example, imagine that it is too hard to find mates when N is very 
small, and there is too much competition for food and other resources when N is 
large.
a) Show that N N
r
a N
b
= −
−
(
)2 provides an example of the Allee effect, if r, a, 
and b satisfy certain constraints, to be determined.
b) Find all the fixed points of the system and classify their stability.
c) Sketch the solutions N ( t ) for different initial conditions.
d) Compare the solutions N ( t ) to those found for the logistic equation. What are 
the qualitative differences, if any?

40 
FLOWS ON THE LINE
2.3.5 
(Dominance of the fittest) Suppose X and Y are two species that repro-
duce exponentially fast: X
aX

 and Y
bY

, respectively, with initial conditions 
X Y
0
0
0
,

 and growth rates a
b

 0 . Here X is “fitter” than Y in the sense that 
it reproduces faster, as reflected by the inequalitya
b

. So we’d expect X to keep 
increasing its share of the total population X
Y

 as t →∞. The goal of this exer-
cise is to demonstrate this intuitive result, first analytically and then geometrically. 
a)  Let x t
X t
X t
Y t
( )
( ) [
( )
( )]
=
+
 denote X’s share of the total population. By solv-
ing for X t( )  and Y t( ), show that x t( )  increases monotonically and approaches 
1 as t →∞.
b)  Alternatively, we can arrive at the same conclusions by deriving a differential 
equation for x t( ) . To do so, take the time derivative of x t
X t
X t
Y t
( )
( ) [
( )
( )]
=
+
 
using the quotient and chain rules. Then substitute for X  and Y  and thereby 
show that x t( )  obeys the logistic equation x
a
b x
x
=
−
−
(
) (
)
1
. Explain why 
this implies that x t( )  increases monotonically and approaches 1 as t →∞.
2.3.6 
(Language death) Thousands of the world’s languages are vanishing at 
an alarming rate, with 90 percent of them being expected to disappear by the end 
of this century. Abrams and Strogatz (2003) proposed the following model of lan-
guage competition, and compared it to historical data on the decline of Welsh, 
Scottish Gaelic, Quechua (the most common surviving indigenous language in the 
Americas), and other endangered languages. 
Let X and Y denote two languages competing for speakers in a given society. 
The proportion of the population speaking X evolves according to 
x
x P
xP
Y X
XY
=
−
−
(
)
1
where 0
1
b
b
x
 is the current fraction of the population speaking X, 1x  is 
the complementary fraction speaking Y, and PY X  is the rate at which individuals 
switch from Y to X. This deliberately idealized model assumes that the population 
is well mixed (meaning that it lacks all spatial and social structure) and that all 
speakers are monolingual. 
Next, the model posits that the attractiveness of a language increases with 
both its number of speakers and its perceived status, as quantified by a parameter 
0
1
b b
s
 that reflects the social or economic opportunities afforded to its speak-
ers. Specifically, assume that P
sx
Y X
a

 and, by symmetry, P
s
x
XY
a
=
−
−
(
)(
)
1
1
, 
where the exponent a 1 is an adjustable parameter. Then the model becomes
x
s
x x
s x
x
a
a
=
−
−
−
−
(
)
(
) (
)
1
1
1
.
a) Show that this equation for x  has three fixed points. 
b) Show that for all a 1, the fixed points at x  0  and x 1 are both stable.
c) Show that the third fixed point, 0
1


x*
, is unstable.

41
EXERCISES
This model therefore predicts that two languages cannot coexist stably—one 
will eventually drive the other to extinction. For a review of generalizations of the 
model that allow for bilingualism, social structure, etc., see Castellano et al. (2009).
2.4 
Linear Stability Analysis
Use linear stability analysis to classify the fixed points of the following systems. 
If linear stability analysis fails because f
x
′
∗
(
)
,
 0  use a graphical argument to 
decide the stability.
2.4.1 
x
x
x
=
−
(
)
1
 
 
2.4.2 
x
x
x
x
=
−
−
(
)(
)
1
2
2.4.3 
x
x
 tan
 
 
2.4.4 
x
x
x
=
−
2 6
(
)
2.4.5 
x
e
x
= −
−
1
2  
 
2.4.6 
x
x
 ln
2.4.7 
x
ax
x
=
−
3, where a can be positive, negative, or zero. Discuss all three 
cases.
2.4.8 
Using linear stability analysis, classify the fixed points of the Gompertz 
model of tumor growth N
aN
bN
= −
ln(
) . (As in Exercise 2.3.3, N ( t ) is propor-
tional to the number of cells in the tumor and a,b  0 are parameters.)
2.4.9 
(Critical slowing down) In statistical mechanics, the phenomenon of 
“critical slowing down” is a signature of a second-order phase transition. At the 
transition, the system relaxes to equilibrium much more slowly than usual. Here’s 
a mathematical version of the effect:
a) Obtain the analytical solution to x
x
= −
3  for an arbitrary initial condition. 
Show that x t( ) l 0 as t l d but that the decay is not exponential. ( You 
should find that the decay is a much slower algebraic function of t.)
b) To get some intuition about the slowness of the decay, make a numerically accu-
rate plot of the solution for the initial condition x0  10, for 0 b t b10. Then, on 
the same graph, plot the solution to x
x
= − for the same initial condition.
2.5 
Existence and Uniqueness
2.5.1 
(Reaching a fixed point in a finite time) A particle travels on the half-line 
x p 0 with a velocity given by x
xc
= −
,  where c is real and constant.
a) Find all values of c such that the origin x  0 is a stable fixed point.
b) Now assume that c is chosen such that x  0 is stable. Can the particle ever 
reach the origin in a finite time? Specifically, how long does it take for the parti-
cle to travel from x  1 to x  0, as a function of c ?
2.5.2 
(“Blow-up”: Reaching infinity in a finite time) Show that the solution 
to x
x
= +
1
10 escapes to d in a finite time, starting from any initial condition. 
(Hint: Don’t try to find an exact solution; instead, compare the solutions to those 
of x
x
= +
1
2 .)

42 
FLOWS ON THE LINE
2.5.3 
Consider the equation x
rx
x
=
+
3,  where r  0 is fixed. Show that x ( t ) l 
od in finite time, starting from any initial condition x0 v 0.
2.5.4 
(Infinitely many solutions with the same initial condition) Show that 
the initial value problem x
x
x


1 3
0
0
,
( )
,
 
 has an infinite number of solutions. 
(Hint: Construct a solution that stays at x  0 until some arbitrary time t0, after 
which it takes off.)
2.5.5 
(A general example of non-uniqueness) Consider the initial value problem
x
x
x
p q


,
( )
,
 
0
0  where p and q are positive integers with no common factors.
a) Show that there are an infinite number of solutions for x ( t ) if p  q.
b) Show that there is a unique solution if p > q.
2.5.6 
(The leaky bucket) The following example (Hubbard and West 1991, 
p. 159) shows that in some physical situations, non-uniqueness is natural and obvi-
ous, not pathological.
Consider a water bucket with a hole in the bottom. If you see an empty bucket 
with a puddle beneath it, can you figure out when the bucket was full? No, of course 
not! It could have finished emptying a minute ago, ten minutes ago, or whatever. 
The solution to the corresponding differential equation must be non-unique when 
integrated backwards in time.
Here’s a crude model of the situation. Let h ( t )  height of the water remaining 
in the bucket at time t; a  area of the hole; A  cross-sectional area of the bucket 
(assumed constant); v ( t )  velocity of the water passing through the hole.
a) Show that av t
Ah t
( )
( ).


What physical law are you invoking?
b) To derive an additional equation, use conservation of energy. First, find the 
change in potential energy in the system, assuming that the height of the water 
in the bucket decreases by an amount %hand that the water has density S. Then 
find the kinetic energy transported out of the bucket by the escaping water. 
Finally, assuming all the potential energy is converted into kinetic energy, 
derive the equation v2  2gh.
c) Combining (b) and (c), show h
C h
= −
, where C
g a
A
=
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
2
.
d) Given h (0)  0 (bucket empty at t  0), show that the solution for h ( t ) is non-
unique in backwards time, i.e., for t  0.
2.6 
Impossibility of Oscillations
2.6.1 
Explain this paradox: a simple harmonic oscillator mx
kx
 = −
is a system 
that oscillates in one dimension (along the x-axis). But the text says one-dimensional 
systems can’t oscillate.
2.6.2 
(No periodic solutions to x
f x

( ) ) Here’s an analytic proof that peri-
odic solutions are impossible for a vector field on a line. Suppose on the contrary 
that x ( t ) is a nontrivial periodic solution, i.e., x ( t )  x ( t  T ) for some T  0, 

43
EXERCISES
and x ( t ) v x ( t  s ) for all 0  s  T. Derive a contradiction by considering 
f x
dt
dx
dt
t
t
T
( )
.
+
∫
2.7 
Potentials
For each of the following vector fields, plot the potential function V ( x ) and iden-
tify all the equilibrium points and their stability.
2.7.1 
x
x
x
=
−
(
)
1
 
 
2.7.2 
x  3
2.7.3 
x
x
 sin
 
 
2.7.4 
x
x
=
+
2
sin
2.7.5 
x
x
= −sinh
 
 
2.7.6 
x
r
x
x
= +
−
3,  for various values of r.
2.7.7 
(Another proof that solutions to x
f x

( ) can’t oscillate) Let x
f x

( )  
be a vector field on the line. Use the existence of a potential function V ( x ) to show 
that solutions x ( t ) cannot oscillate.
2.8 
Solving Equations on the Computer
2.8.1 
(Slope field) The slope is constant along horizontal lines in Figure 2.8.2. 
Why should we have expected this?
2.8.2 
Sketch the slope field for the following differential equations. Then “inte-
grate” the equation manually by drawing trajectories that are everywhere parallel 
to the local slope.
a) x
x

 
b) x
x
= −
1
2  
c) x
x
x
= −
−
1
4
1(
)  
d) x
x
 sin
2.8.3 
(Calibrating the Euler method) The goal of this problem is to test the 
Euler method on the initial value problem x
x
= −, x (0)  1.
a) Solve the problem analytically. What is the exact value of x (1)?
b) Using the Euler method with step size %t 1, estimate x (1) numerically—call 
the result ˆ( )
x 1 . Then repeat, using %t  10–n, for n  1, 2, 3, 4.
c) Plot the error E
x
x
=
−
ˆ( )
( )
1
1 as a function of %t. Then plot ln E vs. ln t. 
Explain the results.
2.8.4 
Redo Exercise 2.8.3, using the improved Euler method.
2.8.5 
Redo Exercise 2.8.3, using the Runge–Kutta method.
2.8.6 
(Analytically intractable problem) Consider the initial value problem 
x
x
e
x
x
=
+
=
−,
( )
 
0
0 . In contrast to Exercise 2.8.3, this problem can’t be solved 
analytically.
a) Sketch the solution x ( t ) for t p 0.
b) Using some analytical arguments, obtain rigorous bounds on the value of x at 
t  1. In other words, prove that a  x (1)  b, for a, b to be determined. By being 
clever, try to make a and b as close together as possible. (Hint: Bound the given 
vector field by approximate vector fields that can be integrated analytically.)

44 
FLOWS ON THE LINE
c) Now for the numerical part: Using the Euler method, compute x at t  1, cor-
rect to three decimal places. How small does the stepsize need to be to obtain 
the desired accuracy? (Give the order of magnitude, not the exact number.)
d) Repeat part (b), now using the Runge–Kutta method. Compare the results for 
stepsizes %t  1, %t  0.1, and %t  0.01.
2.8.7 
(Error estimate for Euler method) In this question you’ll use Taylor series 
expansions to estimate the error in taking one step by the Euler method. The 
exact solution and the Euler approximation both start at x  x0 when t  t0. We 
want to compare the exact value x ( t1) w x ( t0  %t ) with the Euler approximation 
x
x
f x
t
1
0
0
=
+
(
)Δ .
a) Expand x ( t1)  x ( t0 %t ) as a Taylor series in %t, through terms of O ( %t  2). 
Express your answer solely in terms of x0, %t, and f and its derivatives at x0.
b) Show that the local error x t
x
( )
1
1

 _ C ( %t )2 and give an explicit expression 
for the constant C. (Generally one is more interested in the global error incurred 
after integrating over a time interval of fixed length T  n%t. Since each step 
produces an O ( %t )2 error, and we take n  T / %t  O ( %t  –1) steps, the global 
error x t
x
n
n
( )
 is O ( %t ), as claimed in the text.)
2.8.8 
(Error estimate for the improved Euler method) Use the Taylor series 
arguments of Exercise 2.8.7 to show that the local error for the improved Euler 
method is O ( %t  3).
2.8.9 
(Error estimate for Runge–Kutta) Show that the Runge–Kutta method 
produces a local error of size O ( %t  5). (Warning: This calculation involves massive 
amounts of algebra, but if you do it correctly, you’ll be rewarded by seeing many 
wonderful cancellations. Teach yourself Mathematica, Maple, or some other sym-
bolic manipulation language, and do the problem on the computer.)

45
3.0 INTRODUCTION
3
BIFURCATIONS
3.0 Introduction
As we’ve seen in Chapter 2, the dynamics of vector fields on the line is very limited: 
all solutions either settle down to equilibrium or head out to od. Given the triv-
iality of the dynamics, what’s interesting about one-dimensional systems? Answer: 
Dependence on parameters. The qualitative structure of the flow can change as 
parameters are varied. In particular, fixed points can be created or destroyed, or 
their stability can change. These qualitative changes in the dynamics are called 
bifurcations, and the parameter values at which they occur are called bifurca-
tion points.
Bifurcations are important scientifically—they provide models of transitions 
and instabilities as some control parameter is varied. For example, consider the 
buckling of a beam. If a small weight is placed on top of the beam in Figure 3.0.1, 
the beam can support the load and remain vertical. But if the load is too heavy, 
the vertical position becomes unstable, and the beam may buckle.
weight
beam
beam ''buckles''
Figure 3.0.1
Here the weight plays the role of the control parameter, and the deflection of the 
beam from vertical plays the role of the dynamical variable x.

46 
BIFURCATIONS
One of the main goals of this book is to help you develop a solid and practi-
cal understanding of bifurcations. This chapter introduces the simplest examples: 
bifurcations of fixed points for flows on the line. We’ll use these bifurcations to 
model such dramatic phenomena as the onset of coherent radiation in a laser and 
the outbreak of an insect population. (In later chapters, when we step up to two- 
and three-dimensional phase spaces, we’ll explore additional types of bifurcations 
and their scientific applications.)
We begin with the most fundamental bifurcation of all.
3.1 Saddle-Node Bifurcation
The saddle-node bifurcation is the basic mechanism by which fixed points are 
created and destroyed. As a parameter is varied, two fixed points move toward each 
other, collide, and mutually annihilate.
The prototypical example of a saddle-node bifurcation is given by the first-order 
system
x
r
x
= +
2  
(1)
where r is a parameter, which may be positive, negative, or zero. When r is nega-
tive, there are two fixed points, one stable and one unstable (Figure 3.1.1a).
x˙
x˙
x˙
x
x
x
(a)  r < 0
(b)  r = 0
(c)  r > 0
Figure 3.1.1
As r approaches 0 from below, the parabola moves up and the two fixed points 
move toward each other. When r = 0, the fixed points coalesce into a half-stable 
fixed point at x* = 0 (Figure 3.1.1b). This type of fixed point is extremely del-
icate—it vanishes as soon as r  0, and now there are no fixed points at all 
(Figure 3.1.1c).
In this example, we say that a bifurcation occurred at r = 0, since the vector 
fields for r  0 and r  0 are qualitatively different.
Graphical Conventions
There are several other ways to depict a saddle-node bifurcation. We can show 
a stack of vector fields for discrete values of r (Figure 3.1.2).

47
3.1 SADDLE-NODE BIFURCATION
This representation emphasizes the 
dependence of the fixed points on r. In 
the limit of a continuous stack of vec-
tor fields, we have a picture like 
Figure  3.1.3. The curve shown is 
r = x 2, i.e., x  0,  which gives the 
fixed points for different r. To distin-
guish between stable and unstable 
fixed points, we use a solid line for sta-
ble points and a broken line for unsta-
ble ones.
However, the most common way to depict the bifurcation is to invert the axes 
of Figure 3.1.3. The rationale is that r plays the role of an independent variable, 
and so should be plotted horizontally (Figure 3.1.4). The drawback is that now 
the x-axis has to be plotted vertically, which looks strange at first. Arrows are 
sometimes included in the picture, but not always. This picture is called the bifur-
cation diagram for the saddle-node 
bifurcation.
Terminology
Bifurcation theory is rife with 
conflicting terminology. The sub-
ject really hasn’t settled down yet, 
and different people use different 
words for the same thing. For exam-
ple, the saddle-node bifurcation is 
sometimes called a fold bifurcation 
(because the curve in Figure 3.1.4 
 r > 0
 r = 0
 r < 0
 x 
Figure 3.1.2
stable
unstable
r
x
Figure 3.1.3
stable
unstable
r
x
Figure 3.1.4

48 
BIFURCATIONS
has a fold in it) or a turning-point bifurcation (because the point ( x,r ) = (0,0) is a 
“turning point.”) Admittedly, the term saddle-node doesn’t make much sense for 
vector fields on the line. The name derives from a completely analogous bifur-
cation seen in a higher-dimensional context, such as vector fields on the plane, 
where fixed points known as saddles and nodes can collide and annihilate (see 
Section 8.1).
The prize for most inventive terminology must go to Abraham and Shaw (1988), 
who write of a blue sky bifurcation. This term comes from viewing a saddle-node 
bifurcation in the other direction: a pair of fixed points appears “out of the clear 
blue sky” as a parameter is varied. For example, the vector field
x
r
x
= −
2  
(2)
has no fixed points for r  0, but then one materializes when r = 0 and splits into 
two when r  0 (Figure 3.1.5). Incidentally, this example also explains why we use 
the word “bifurcation”: it means “splitting into two branches.”
r > 0
r = 0
r < 0
x
x
x
Figure 3.1.5
EXAMPLE 3.1.1:
Give a linear stability analysis of the fixed points in Figure 3.1.5.
Solution: The fixed points for x
f x
r
x
=
= −
( )
2 are given by x
r
* = ±
. There 
are two fixed points for r  0, and none for r  0. To determine linear stability, we 
compute f ′( x* ) = 2x*. Thus x
r
* = +
 is stable, since f ′( x* )  0. Similarly 
x
r
* = −
is unstable. At the bifurcation point r = 0, we find f ′( x* ) = 0; the lin-
earization vanishes when the fixed points coalesce. ■
EXAMPLE 3.1.2:
Show that the first-order system x
r
x
e
x
= −−
−undergoes a saddle-node bifurca-
tion as r is varied, and find the value of r at the bifurcation point. 
Solution: The fixed points satisfy f  ( x ) = r  x  e x = 0. But now we run into a 
difficulty—in contrast to Example 3.1.1, we can’t find the fixed points explicitly as 
a function of r. Instead we adopt a geometric approach. One method would be to 
graph the function f  ( x ) = r  x e x for different values of r, look for its roots x *, 
and then sketch the vector field on the x-axis. This method is fine, but there’s an 
easier way. The point is that the two functions r  x and e x have much more famil-
iar graphs than their difference r  x  e x. So we plot r x and e x on the same 

49
3.1 SADDLE-NODE BIFURCATION
picture (Figure 3.1.6a). Where the line r  x intersects the curve e x, we have 
r  x = e x and so f  ( x ) = 0. Thus, intersections of the line and the curve correspond 
to fixed points for the system. This picture also allows us to read off the direction of 
flow on the x-axis: the flow is to the right where the line lies above the curve, since 
r  x  ex and therefore x > 0 . Hence, the fixed point on the right is stable, and 
the one on the left is unstable.
Now imagine we start decreasing the parameter r. The line r x slides down 
and the fixed points approach each other. At some critical value r = rc   , the line 
becomes tangent to the curve and the fixed points coalesce in a saddle-node bifur-
cation (Figure 3.1.6b). For r below this critical value, the line lies below the curve 
and there are no fixed points (Figure 3.1.6c).
(a)
(b)
(c)
x
x
x
r − x
e
 − x
Figure 3.1.6
To find the bifurcation point rc   , we impose the condition that the graphs of 
r x and e x intersect tangentially. Thus we demand equality of the functions and 
their derivatives:
ex = r x
and
d
dx e
d
dx r
x
x
−=
−
(
).
The second equation implies e x = 1, so x = 0. Then the first equation yields 
r   1. Hence the bifurcation point is rc = 1, and the bifurcation occurs at x = 0. ■
Normal Forms
In a certain sense, the examples x
r
x
= −
2 or x
r
x
= +
2  are representative of 
all saddle-node bifurcations; that’s why we called them “prototypical.” The idea is 
that, close to a saddle-node bifurcation, the dynamics typically look like x
r
x
= −
2
or x
r
x
= +
2.

50 
BIFURCATIONS
For instance, consider Example 3.1.2 near the bifurcation at x = 0 and r = 1. 
Using the Taylor expansion for e x about x = 0, we find
x
r
x
e
r
x
x
x
r
x
x
= −−
= −−−
+
+
⎡
⎣
⎢⎢
⎤
⎦
⎥⎥
=
−
−
+
−
1
2
1
2
2
2
!
...
(
)
...
to leading order in x. This has the same algebraic form as x
r
x
= −
2,  and can be 
made to agree exactly by appropriate rescalings of x and r.
It’s easy to understand why saddle-node bifurcations typically have this alge-
braic form. We just ask ourselves: how can two fixed points of x
f x

( ) collide 
and disappear as a parameter r is varied? Graphically, fixed points occur where the 
graph of f  ( x ) intersects the x-axis. For a saddle-node bifurcation to be possible, 
we need two nearby roots of f  ( x ); this means f  ( x ) must look locally “bowl-
shaped” or parabolic (Figure 3.1.7).
f(x)
x
x˙
r < rc
r > rc
f(x) looks
parabolic in here
Figure 3.1.7
Now we use a microscope to zoom in on the behavior near the bifurcation. As 
r varies, we see a parabola intersecting the x-axis, then becoming tangent to it, 
and then failing to intersect. This is exactly the scenario in the prototypical 
Figure 3.1.1. 
Here’s a more algebraic version of the same argument. We regard f as a function 
of both x and r, and examine the behavior of x
f x r

( , ) near the bifurcation at 
x  x * and r = rc   . Taylor’s expansion yields
x
f x r
f x
r
x
x
f
x
r
r
f
r
c
x
r
c
x
r
c
c
=
=
+
−
∂
∂
+
−
∂
∂
+
( , )
( *,
)
(
*)
(
)
(
( *,
)
( *,
)
1
2 x
x
f
x
x
rc
−
∂
∂
+
*)
...
( *,
)
2
2
2

51
3.2 TRANSCRITICAL BIFURCATION
where we have neglected quadratic terms in ( r  rc  ) and cubic terms in ( x  x * ). 
Two of the terms in this equation vanish: f  ( x *, rc   ) = 0 since x * is a fixed point, and 
∂
∂
=
∗
f
x
x
rc
(
,
)
0 by the tangency condition of a saddle-node bifurcation. Thus


x
a r
r
b x
x
c
=
−
+
−
+
(
)
(
*)2
 
(3)
where a = s
s
f
x
x
rc
( *,
) and b
f
x
x
rc
= ∂
∂
∗
1
2
2
2
(
,
) Equation (3) agrees with the form 
of our prototypical examples. (We are assuming that a, b v 0, which is the typical 
case; for instance, it would be a very special situation if the second derivative 
s
s
2
2
f
x  also happened to vanish at the fixed point.)
What we have been calling prototypical examples are more conventionally 
known as normal forms for the saddle-node bifurcation. There is much, much 
more to normal forms than we have indicated here. We will be seeing their 
importance throughout this book. For a more detailed and precise discussion, see 
Guckenheimer and Holmes (1983) or Wiggins (1990).
3.2 Transcritical Bifurcation
There are certain scientific situations where a fixed point must exist for all values of 
a parameter and can never be destroyed. For example, in the logistic equation and 
other simple models for the growth of a single species, there is a fixed point at 
zero population, regardless of the value of the growth rate. However, such a fixed 
point may change its stability as the parameter is varied. The transcritical bifurca-
tion is the standard mechanism for such changes in stability. 
The normal form for a transcritical bifurcation is
x
rx
x
=
−
2. 
(1)
This looks like the logistic equation of Section 2.3, but now we allow x and r to be 
either positive or negative.
Figure 3.2.1 shows the vector field as r varies. Note that there is a fixed point 
at x * = 0 for all values of r.
x˙
x
x
x
x˙
x˙
(a)  r < 0
(b)  r = 0
(c)  r > 0
Figure 3.2.1

52 
BIFURCATIONS
For r  0, there is an unstable fixed point at x * = r and a stable fixed point at x *  0. 
As r increases, the unstable fixed point approaches the origin, and coalesces with it 
when r = 0. Finally, when r  0, the origin has become unstable, and x * = r is now 
stable. Some people say that an exchange of stabilities has taken place between the 
two fixed points.
Please note the important difference between the saddle-node and transcritical 
bifurcations: in the transcritical case, the two fixed points don’t disappear after the 
bifurcation—instead they just switch their stability.
Figure 3.2.2 shows the bifurcation diagram for the transcritical bifurcation. As 
in Figure 3.1.4, the parameter r is regarded as the independent variable, and the 
fixed points x * = 0 and x * = r are shown as dependent variables.
x
r
unstable
unstable
stable
stable
Figure 3.2.2
EXAMPLE 3.2.1:
Show that the first-order system x
x
x
a
e
bx
=
−
−
−
−
(
)
(
)
1
1
2
undergoes a transcriti-
cal bifurcation at x = 0 when the parameters a, b satisfy a certain equation, to be 
determined. (This equation defines a bifurcation curve in the ( a, b ) parameter 
space.) Then find an approximate formula for the fixed point that bifurcates from 
x = 0, assuming that the parameters are close to the bifurcation curve.
Solution: Note that x = 0 is a fixed point for all ( a, b ). This makes it plausible 
that the fixed point will bifurcate transcritically, if it bifurcates at all. For small 
x, we find
1
1
1
1
2
2
2
3
1
2
2
2
3
−
= −−
+
+
⎡⎣⎢
⎤⎦⎥
=
−
+
−
e
bx
b x
O x
bx
b x
O x
bx
(
)
(
)
and so
x
x
a bx
b x
O x
ab x
ab
x
O x
=
−
−
+
=
−
+
+
(
)
(
)
(
)
(
)
(
).
1
2
2
2
3
1
2
2
2
3
1

53
3.2 TRANSCRITICAL BIFURCATION
Hence a transcritical bifurcation occurs when ab = 1; this is the equation for the 
bifurcation curve. The nonzero fixed point is given by the solution of 
1
0
1
2
2
−
+
≈
ab
ab
x
(
)
, i.e.,
x
ab
ab
*
(
)
≈
−
2
1
2
.
This formula is approximately correct only if x * is small, since our series expan-
sions are based on the assumption of small x. Thus the formula holds only when 
ab  is close to 1, which means that the parameters must be close to the bifurcation 
curve. ■
EXAMPLE 3.2.2:
Analyze the dynamics of x
r
x
x
=
+
−
ln
1 near x = 1, and show that the system 
undergoes a transcritical bifurcation at a certain value of r. Then find new vari-
ables X and R such that the system reduces to the approximate normal form 
X
RX
X
≈
−
2 near the bifurcation.
Solution: First note that x = 1 is a fixed point for all values of r. Since we are 
interested in the dynamics near this fixed point, we introduce a new variable 
u = x  1, where u is small. Then


u
x
r
u
u
r u
u
O u
u
r
u
ru
O u
=
=
+
+
=
−
+
⎡⎣⎢
⎤⎦⎥+
≈
+
−
+
ln(
)
(
)
(
)
(
).
1
1
1
2
2
3
1
2
2
3
Hence a transcritical bifurcation occurs at rc = 1.
To put this equation into normal form, we first need to get rid of the coefficient 
of u2. Let u = av, where a will be chosen later. Then the equation for v is
v
r
v
ra v
O v
=
+
−
+
(
)
(
)
(
).
1
1
2
2
3
So if we choose a = 2  /  r, the equation becomes
v
r
v
v
O v
=
+
−
+
(
)
(
).
1
2
3
Now if we let R = r 1 and X = v, we have achieved the approximate normal form
X
RX
X
≈
−
2 , where cubic terms of order O (X 3) have been neglected. In terms of 
the original variables, X
v
u a
r x
=
=
=
−
1
2
1
(
) . ■
To be a bit more accurate, the theory of normal forms assures us that we can 
find a change of variables such that the system becomes X
RX
X
=
−
2 , with 

54 
BIFURCATIONS
strict, rather than approximate, equality. Our solution above gives an approxima-
tion to the necessary change of variables. For careful treatments of normal form 
theory, see the books of Guckenheimer and Holmes (1983), Wiggins (1990), or 
Manneville (1990).
3.3 Laser Threshold
Now it’s time to apply our mathematics to a scientific example. We analyze an 
extremely simplified model for a laser, following the treatment given by Haken (1983).
Physical Background
We are going to consider a particular type of laser known as a solid-state 
laser, which consists of a collection of special “laser-active” atoms embedded in 
a solid-state matrix, bounded by partially reflecting mirrors at either end. An 
external energy source is used to excite or “pump” the atoms out of their ground 
states (Figure 3.3.1).
pump
mirror
active material
laser light
Figure 3.3.1
Each atom can be thought of as a little antenna radiating energy. When the pump-
ing is relatively weak, the laser acts just like an ordinary lamp: the excited atoms 
oscillate independently of one another and emit randomly phased light waves.
Now suppose we increase the strength of the pumping. At first nothing different 
happens, but then suddenly, when the pump strength exceeds a certain threshold, 
the atoms begin to oscillate in phase—the lamp has turned into a laser. Now the 
trillions of little antennas act like one giant antenna and produce a beam of radi-
ation that is much more coherent and intense than that produced below the laser 
threshold.
This sudden onset of coherence is amazing, considering that the atoms are being 
excited completely at random by the pump! Hence the process is self-organizing: 
the coherence develops because of a cooperative interaction among the atoms 
themselves.

55
3.3 LASER THRESHOLD
Model
A proper explanation of the laser phenomenon would require us to delve into 
quantum mechanics. See Milonni and Eberly (1988) for an intuitive discussion.
Instead we consider a simplified model of the essential physics (Haken 1983, p. 
127). The dynamical variable is the number of photons n ( t ) in the laser field. Its 
rate of change is given by
n
GnN
kn
=
−
=
−
gain
loss
.
The gain term comes from the process of stimulated emission, in which photons 
stimulate excited atoms to emit additional photons. Because this process occurs 
via random encounters between photons and excited atoms, it occurs at a rate pro-
portional to n and to the number of excited atoms, denoted by N ( t ). The param-
eter G  0 is known as the gain coefficient. The loss term models the escape of 
photons through the endfaces of the laser. The parameter k  0 is a rate constant; 
its reciprocal U = 1 / k represents the typical lifetime of a photon in the laser.
Now comes the key physical idea: after an excited atom emits a photon, it 
drops down to a lower energy level and is no longer excited. Thus N decreases 
by the emission of photons. To capture this effect, we need to write an equation 
relating N to n. Suppose that in the absence of laser action, the pump keeps the 
number of excited atoms fixed at N0. Then the actual number of excited atoms will 
be reduced by the laser process. Specifically, we assume
N t
N
n
( )
,
=
−
0
B
where B  0 is the rate at which atoms drop back to their ground states. Then
n
Gn N
n
kn
GN
k n
G n
=
−
−
=
−
−
(
)
(
)
(
)
.
0
0
2
B
B
We’re finally on familiar ground—this is a first-order system for n ( t ). 
Figure 3.3.2 shows the corresponding vector field for different values of the pump 
strength N0. Note that only positive values of n are physically meaningful.
n
N0 < k/G
N0 =k/G
N0 >k/G
n
n
n˙
n˙
n˙
Figure 3.3.2

56 
BIFURCATIONS
When N0  k / G, the fixed point at n * = 0 is stable. This means that there is no 
stimulated emission and the laser acts like a lamp. As the pump strength N0 is 
increased, the system undergoes a transcritical bifurcation when N0 = k / G. For 
N0    k / G, the origin loses stability and a stable fixed point appears at 
n
GN
k
G
*
(
)
=
−
0
B
> 0 , corresponding to spontaneous laser action. Thus 
N0 = k / G can be interpreted as the laser threshold in this model. Figure 3.3.3 sum-
marizes our results.
n
N0
k/G
lamp
0
laser
Figure 3.3.3
Although this model correctly predicts the existence of a threshold, it ignores 
the dynamics of the excited atoms, the existence of spontaneous emission, and 
several other complications. See Exercises 3.3.1 and 3.3.2 for improved models.
3.4 Pitchfork Bifurcation
We turn now to a third kind of bifurcation, the so-called pitchfork bifurcation. 
This bifurcation is common in physical problems that have a symmetry. For exam-
ple, many problems have a spatial symmetry between left and right. In such cases, 
fixed points tend to appear and disappear in symmetrical pairs. In the buckling 
example of Figure 3.0.1, the beam is stable in the vertical position if the load is 
small. In this case there is a stable fixed point corresponding to zero deflection. But 
if the load exceeds the buckling threshold, the beam may buckle to either the left or 
the right. The vertical position has gone unstable, and two new symmetrical fixed 
points, corresponding to left- and right-buckled configurations, have been born.
There are two very different types of pitchfork bifurcation. The simpler type is 
called supercritical, and will be discussed first.
Supercritical Pitchfork Bifurcation
The normal form of the supercritical pitchfork bifurcation is
x
rx
x
=
−
3 . 
(1)

57
3.4 PITCHFORK BIFURCATION
Note that this equation is invariant under the change of variables x l x. That 
is, if we replace x by x and then cancel the resulting minus signs on both sides of 
the equation, we get (1) back again. This invariance is the mathematical expression 
of the left-right symmetry mentioned earlier. (More technically, one says that the 
vector field is equivariant, but we’ll use the more familiar language.)
Figure 3.4.1 shows the vector field for different values of r.
x˙
x˙
x˙
x
x
x
(a)  r < 0
(b)  r = 0
(c)  r > 0
Figure 3.4.1
When r  0, the origin is the only fixed point, and it is stable. When r = 0, the origin 
is still stable, but much more weakly so, since the linearization vanishes. Now solu-
tions no longer decay exponentially fast—instead the decay is a much slower alge-
braic function of time (recall Exercise 2.4.9). This lethargic decay is called critical 
slowing down in the physics literature. Finally, when r  0, the origin has become 
unstable. Two new stable fixed points appear on either side of the origin, symmet-
rically located at x
r
* = ±
. 
The reason for the term “pitchfork” becomes clear when we plot the bifurcation 
diagram (Figure 3.4.2). Actually, pitchfork trifurcation might be a better word!
x
stable
stable
stable
unstable
r
Figure 3.4.2

58 
BIFURCATIONS
EXAMPLE 3.4.1:
Equations similar to x
x
x
= −+C tanh
 arise in statistical mechanical models of 
magnets and neural networks (see Exercise 3.6.7 and Palmer 1989). Show that 
this equation undergoes a supercritical pitchfork bifurcation as C is varied. Then 
give a numerically accurate plot of the fixed points for each C.
Solution: We use the strategy of Example 3.1.2 to find the fixed points. The 
graphs of y = x and y = C tanh x are shown in Figure 3.4.3; their intersections cor-
respond to fixed points. The key thing to realize is that as C increases, the tanh 
curve becomes steeper at the origin (its slope there is C ). Hence for C  1 the origin 
is the only fixed point. A pitchfork bifurcation occurs at C = 1, x * = 0, when the 
tanh curve develops a slope of 1 at the origin. Finally, when C  1, two new stable 
fixed points appear, and the origin becomes unstable.
x
x
x
x
β > 1
β = 1
β < 1
β tanh x
Figure 3.4.3
Now we want to compute the fixed points x * for each C. Of course, one fixed 
point always occurs at x * = 0; we are looking for the other, nontrivial fixed points. 
One approach is to solve the equation x * = C tanh x * numerically, using the 
Newton–Raphson method or some other root-finding scheme. (See Press et 
al. (2007) for a friendly and informative discussion of numerical methods.) But 
there’s an easier way, which comes 
from changing our point of view. 
Instead of studying the dependence 
of x * on C, we think of x * as the 
independent variable, and then com-
pute C = x * / tanh x *. This gives us a 
table of pairs ( x *, C). For each pair, 
we plot C horizontally and x * verti-
cally. This yields the bifurcation dia-
gram (Figure 3.4.4).
The shortcut used here exploits 
the fact that f  ( x, C ) = x  C tanh x 
depends more simply on C than on x. 
6
x
4
2
0
-2
-4
-6
0
1
2
3
4
β
Figure 3.4.4

59
3.4 PITCHFORK BIFURCATION
This is frequently the case in bifurcation problems—the dependence on the con-
trol parameter is usually simpler than the dependence on x. ■
EXAMPLE 3.4.2:
Plot the potential V ( x ) for the system x
rx
x
=
−
3 , for the cases r  0, r = 0, and 
r  0.
Solution: Recall from Section 2.7 that the potential for x
f x

( )  is defined by 
f  ( x ) = dV / dx. Hence we need to solve dV / dx = rx  x 3. Integration yields
V x
rx
x
( ) = −
+
1
2
2
1
4
4 , where we neglect the arbitrary constant of integration. 
The corresponding graphs are shown in Figure 3.4.5.
V
V
V
x
x
x
r > 0
r = 0
r < 0
Figure 3.4.5
When r  0, there is a quadratic minimum at the origin. At the bifurcation value 
r = 0, the minimum becomes a much flatter quartic. For r  0, a local maximum 
appears at the origin, and a symmetric pair of minima occur to either side of it. ■
Subcritical Pitchfork Bifurcation
In the supercritical case x
rx
x
=
−
3  discussed above, the cubic term is stabiliz-
ing: it acts as a restoring force that pulls x ( t ) back toward x = 0. If instead the 
cubic term were destabilizing, as in
x
rx
x
=
+
3,  
(2)
then we’d have a subcritical pitchfork bifurcation. Figure 3.4.6 shows the bifurca-
tion diagram.

60 
BIFURCATIONS
x
unstable
unstable
unstable
stable
r
Figure 3.4.6
Compared to Figure 3.4.2, the pitchfork is inverted. The nonzero fixed points 
x
r
* = ± − are unstable, and exist only below the bifurcation ( r  0), which moti-
vates the term “subcritical.” More importantly, the origin is stable for r  0 and 
unstable for r  0, as in the supercritical case, but now the instability for r  0 
is not opposed by the cubic term—in fact the cubic term lends a helping hand in 
driving the trajectories out to infinity! This effect leads to blow-up: one can show 
that x t( ) →±∞ in finite time, starting from any initial condition x0 v 0 
(Exercise 2.5.3). 
In real physical systems, such an explosive instability is usually opposed by the 
stabilizing influence of higher-order terms. Assuming that the system is still sym-
metric under x l x, the first stabilizing term must be x 5. Thus the canonical 
example of a system with a subcritical pitchfork bifurcation is
x
rx
x
x
=
+
−
3
5. 
(3)
There’s no loss in generality in assuming that the coefficients of x 3 and x 5 are 1 
(Exercise 3.5.8).
The detailed analysis of (3) is left to 
you (Exercises 3.4.14 and 3.4.15). But 
we will summarize the main results 
here. Figure  3.4.7 shows the bifurca-
tion diagram for (3). For small x, the 
picture looks just like Figure 3.4.6: the 
origin is locally stable for r  0, and 
two backward-bending branches of 
unstable fixed points bifurcate from 
the origin when r = 0. The new feature, 
due to the x 5 term, is that the unstable 
x
0
0
r
r
s
Figure 3.4.7

61
3.4 PITCHFORK BIFURCATION
branches turn around and become stable at r = rs  , where rs  0. These stable 
large-amplitude branches exist for all r  rs.
There are several things to note about Figure 3.4.7:
1. In the range rs  r  0, two qualitatively different stable states coex-
ist, namely the origin and the large-amplitude fixed points. The initial 
condition x0 determines which fixed point is approached as t l d. 
One consequence is that the origin is stable to small perturbations, 
but not to large ones—in this sense the origin is locally stable, but not 
globally stable.
2. The existence of different stable states allows for the possibility of 
jumps and hysteresis as r is varied. Suppose we start the system in the 
state x* = 0, and then slowly increase the parameter r (indicated by 
an arrow along the r-axis of Figure 3.4.8).
x
0
0
r
r
s
Figure 3.4.8
Then the state remains at the origin until r = 0, when the origin loses 
stability. Now the slightest nudge will cause the state to jump to one 
of the large-amplitude branches. With further increases of r, the state 
moves out along the large-amplitude branch. If r is now decreased, the 
state remains on the large-amplitude branch, even when r is decreased 
below 0! We have to lower r even further (down past rs ) to get the state 
to jump back to the origin. This lack of reversibility as a parameter is 
varied is called hysteresis. 
3. The bifurcation at rs is a saddle-node bifurcation, in which stable 
and unstable fixed points are born “out of the clear blue sky” as r is 
increased (see Section 3.1).
Terminology
As usual in bifurcation theory, there are several other names for the bifur-
cations discussed here. The supercritical pitchfork is sometimes called a forward 
bifurcation, and is closely related to a continuous or second-order phase transition 

62 
BIFURCATIONS
in statistical mechanics. The subcritical bifurcation is sometimes called an inverted 
or backward bifurcation, and is related to discontinuous or first-order phase tran-
sitions. In the engineering literature, the supercritical bifurcation is sometimes 
called soft or safe, because the nonzero fixed points are born at small ampli-
tude; in contrast, the subcritical bifurcation is hard or dangerous, because of 
the jump from zero to large amplitude.
3.5 Overdamped Bead on a Rotating Hoop
In this section we analyze a classic problem from first-year physics, the bead on a 
rotating hoop. This problem provides an example of a bifurcation in a mechanical 
system. It also illustrates the subtleties involved in replacing Newton’s law, which 
is a second-order equation, by a simpler first-order equation.
The mechanical system is shown in Figure 3.5.1. A bead of mass m slides along 
a wire hoop of radius r. The hoop is constrained to rotate at a constant angular 
velocity X about its vertical axis. The problem is to analyze the motion of the bead, 
given that it is acted on by both gravitational and centrifugal forces. This is the 
usual statement of the problem, but now we want to add a 
new twist: suppose that there’s also a frictional force on the 
bead that opposes its motion. To be specific, imagine that 
the whole system is immersed in a vat of molasses or some 
other very viscous fluid, and that the friction is due to viscous 
damping.
Let G be the angle between the bead and the downward 
vertical direction. By convention, we restrict G to the range 
Q  G b Q, so there’s only one angle for each point on the 
hoop. Also, let S = r sinG denote the distance of the bead 
from the vertical axis. Then the coordinates are as shown in 
Figure 3.5.2.
Now we write Newton’s law for the bead. There’s a down-
ward gravitational force mg, a sideways centrifugal force 
mSX2, and a tangential damping force b G. (The constants g 
and b are taken to be positive; negative signs will be added 
later as needed.) The hoop is assumed to be rigid, so we only 
have to resolve the forces along the tangential direction, as 
shown in Figure 3.5.3. After substituting S = r sinG in the cen-
trifugal term, and recalling that the tangential acceleration is 
rG,  we obtain the governing equation
mr
b
mg
mr


φ
φ
φ
ω
φ
φ
= −
−
+
sin
sin
cos .
2
 
(1)
ω
m
Figure 3.5.1
r
ρ
φ
Figure 3.5.2

63
3.5 OVERDAMPED BEAD ON A ROTATING HOOP
This is a second-order differential equa-
tion, since the second derivative G  is the 
highest one that appears. We are not yet 
equipped to analyze second-order equa-
tions, so we would like to find some con-
ditions under which we can safely neglect 
the mrG term. Then (1) reduces to a 
first-order equation, and we can apply our 
machinery to it.
Of course, this is a dicey business: we 
can’t just neglect terms because we feel 
like it! But we will for now, and then at the end of this section we’ll try to find a 
regime where our approximation is valid.
Analysis of the First-Order System
Our concern now is with the first-order system 
b
mg
mr
mg
r
g
φ
φ
ω
φ
φ
φ
ω
φ
= −
+
=
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
sin
sin
cos
sin
cos
.
2
2
1
 
(2)
The fixed points of (2) correspond to equilibrium positions for the bead. What’s 
your intuition about where such equilibria can occur? We would expect the bead to 
remain at rest if placed at the top or the bottom of the hoop. Can other fixed points 
occur? And what about stability? Is the bottom always stable?
Equation (2) shows that there are always fixed points where sin G = 0, namely 
G* = 0 (the bottom of the hoop) and G* = Q (the top). The more interesting result is 
that there are two additional fixed points if 
r
g
X2
1
 ,
that is, if the hoop is spinning fast enough. These fixed points satisfy 
G* = ocos1 ( g / rX2 ). To visualize them, we introduce a parameter 
γ
ω
 r
g
2
and solve cos G* = 1 / H graphically. We plot cos G vs. G, and look for intersections 
with the constant function l / H, shown as a horizontal line in Figure 3.5.4. For H  1 
there are no intersections, whereas for H  1 there is a symmetrical pair of inter-
sections to either side of G* = 0.
ρ
ρω
ω
ρ
˙
b
mg
m
2
2
m
r
mg sin
cos
φ
φ
φ
φ
φ
φ
Figure 3.5.3

64 
BIFURCATIONS
− π
 π
γ < 1
1/γ,
γ > 1
γ = 1
φ
φ
cos
Figure 3.5.4
As H l d, these intersections approach oQ / 2. Figure 3.5.5 plots the fixed points 
on the hoop for the cases H  1 and H  1.
γ < 1
γ > 1
top
bottom
bottom
top
Figure 3.5.5
To summarize our results so far, let’s plot all the fixed points as a function of 
the parameter H (Figure 3.5.6). As usual, solid lines denote stable fixed points and 
broken lines denote unstable fixed points.
π
γ
0
0
1
2
3
−π
φ
Figure 3.5.6

65
3.5 OVERDAMPED BEAD ON A ROTATING HOOP
We now see that a supercritical pitchfork bifurcation occurs at H = 1. It’s left to you 
to check the stability of the fixed points, using linear stability analysis or graphical 
methods (Exercise 3.5.2).
Here’s the physical interpretation of the results: When H  1, the hoop is rotat-
ing slowly and the centrifugal force is too weak to balance the force of gravity. 
Thus the bead slides down to the bottom and stays there. But if H  1, the hoop 
is spinning fast enough that the bottom becomes unstable. Since the centrifugal 
force grows as the bead moves farther from the bottom, any slight displacement of 
the bead will be amplified. The bead is therefore pushed up the hoop until gravity 
balances the centrifugal force; this balance occurs at G* = ocos1 ( g / rX2 ). Which 
of these two fixed points is actually selected depends on the initial disturbance. 
Even though the two fixed points are entirely symmetrical, an asymmetry in the 
initial conditions will lead to one of them being chosen—physicists sometimes 
refer to these as symmetry-broken solutions. In other words, the solution has less 
symmetry than the governing equation.
What is the symmetry of the governing equation? Clearly the left and right 
halves of the hoop are physically equivalent—this is reflected by the invariance 
of (1) and (2) under the change of variables G lGAs we mentioned in Section 
3.4, pitchfork bifurcations are to be expected in situations where such a symmetry 
exists.
Dimensional Analysis and Scaling
Now we need to address the question: When is it valid to neglect the inertia 
term mrG  in (1)? At first sight the limit m l 0 looks promising, but then we notice 
that we’re throwing out the baby with the bathwater: the centrifugal and gravita-
tional terms vanish in this limit too! So we have to be more careful.
In problems like this, it is helpful to express the equation in dimensionless form 
(at present, all the terms in (1) have the dimensions of force.) The advantage of a 
dimensionless formulation is that we know how to define small—it means “much 
less than 1.” Furthermore, nondimensionalizing the equation reduces the number 
of parameters by lumping them together into dimensionless groups. This reduction 
always simplifies the analysis. For an excellent introduction to dimensional analy-
sis, see Lin and Segel (1988).
There are often several ways to nondimensionalize an equation, and the best 
choice might not be clear at first. Therefore we proceed in a flexible fashion. We 
define a dimensionless time U by
U  t
T
where T is a characteristic time scale to be chosen later. When T is chosen correctly, 
the new derivatives dG / dU and d 2G / dU2 should be O (1), i.e., of order unity. To express 
these new derivatives in terms of the old ones, we use the chain rule:

66 
BIFURCATIONS
φ
φ
φ
τ
τ
φ
τ



d
dt
d
d
d
dt
T
d
d
1
and similarly
φ
φ
τ
 1
2
2
2
T
d
d
.
(The easy way to remember these formulas is to formally substitute T U for t.) 
Hence (1) becomes
mr
T
d
d
b
T
d
d
mg
mr
2
2
2
2
φ
τ
φ
τ
φ
ω
φ
φ
= −
−
+
sin
sin
cos .
Now since this equation is a balance of forces, we nondimensionalize it by dividing 
by a force mg. This yields the dimensionless equation
r
gT
d
d
b
mgT
d
d
r
g
2
2
2
2
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
= −
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
−
+
⎛
⎝
⎜⎜
φ
τ
φ
τ
φ
ω
sin
⎜⎜
⎞
⎠
⎟⎟⎟⎟sin
cos .
φ
φ  
(3)
Each of the terms in parentheses is a dimensionless group. We recognize the group 
rX2 / g in the last term—that’s our old friend H from earlier in the section.
We are interested in the regime where the left-hand side of (3) is negligible com-
pared to all the other terms, and where all the terms on the right-hand side are of 
comparable size. Since the derivatives are O (1) by assumption, and sin G x O (1), 
we see that we need
b
mgT
O
r
gT
≈
<<
( ),
.
1
1
2
 and 
The first of these requirements sets the time scale T : a natural choice is
T
b
mg

.
Then the condition r / gT  2  1 becomes
r
g
mg
b
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟<<
2
1, 
(4)
or equivalently,
b 2  m 2gr.

67
3.5 OVERDAMPED BEAD ON A ROTATING HOOP
This can be interpreted as saying that the damping is very strong, or that the mass 
is very small, now in a precise sense.
The condition (4) motivates us to introduce a dimensionless group
F  m gr
b
2
2
. 
(5)
Then (3) becomes
ε
φ
τ
φ
τ
φ
γ
φ
φ
d
d
d
d
2
2 = −
−
+
sin
sin
cos .  
(6)
As advertised, the dimensionless Equation (6) is simpler than (1): the five parame-
ters m, g, r, X, and b have been replaced by two dimensionless groups H and F. 
In summary, our dimensional analysis suggests that in the overdamped limit 
F l 0, (6) should be well approximated by the first-order system
d
d
f
φ
τ
φ

( ) 
(7)
where
f ( )
sin
sin
cos
sin
( cos
).
φ
φ
γ
φ
φ
φ γ
φ
= −
+
=
−1
A Paradox
Unfortunately, there is something fundamentally wrong with our idea of replacing 
a second-order equation by a first-order equation. The trouble is that a second-order 
equation requires two initial conditions, whereas a first-order equation has only 
one. In our case, the bead’s motion is determined by its initial position and veloc-
ity. These two quantities can be chosen completely independent of each other. But 
that’s not true for the first-order system: given the initial position, the initial veloc-
ity is dictated by the equation dG / dU = f  ( G). Thus the solution to the first-order 
system will not, in general, be able to satisfy both initial conditions.
We seem to have run into a paradox. Is (7) valid in the overdamped limit 
or not? If it is valid, how can we satisfy the two arbitrary initial conditions 
demanded by (6)?
The resolution of the paradox requires us to analyze the second-order sys-
tem (6). We haven’t dealt with second-order systems before—that’s the subject of 
Chapter 5. But read on if you’re curious; some simple ideas are all we need to finish 
the problem.

68 
BIFURCATIONS
Phase Plane Analysis
Throughout Chapters 2 and 3, we have exploited the idea that a first-order system 
x
f x

( )  can be regarded as a vector field on a line. By analogy, the second-order 
system (6) can be regarded as a vector field on a plane, the so-called phase plane.
The plane is spanned by two axes, one for the angle G and one for the angular 
velocity dG / dU. To simplify the notation, let
Ω =
≡
φ
φ
τ
′
d
d
/
where prime denotes differentiation with respect to U. Then an initial condition 
for (6) corresponds to a point ( G0, 80 ) in the phase plane (Figure 3.5.7). As time 
evolves, the phase point ( G( t ), 8( t )) moves around in the phase plane along a tra-
jectory determined by the solution to (6).
(   (0), Ω(0 ))
(   (τ ), Ω(τ))
Ω
φ
φ
φ
Figure 3.5.7
Our goal now is to see what those trajectories actually look like. As before, the 
key idea is that the differential equation can be interpreted as a vector field on the 
phase space. To convert (6) into a vector field, we first rewrite it as
ε
φ
′ =
−
Ω
Ω
f ( )
.
Along with the definition Ga = 8, this yields the vector field
Ga = 8
(8a)
′ =
−
Ω
Ω
1
ε
φ
( ( )
).
f
 
(8b)
We interpret the vector (
,
G′
′)
8  at the point ( G, 8) as the local velocity of a phase 
fluid flowing steadily on the plane. Note that the velocity vector now has two 
components, one in the G-direction and one in the 8-direction. To visualize the 
trajectories, we just imagine how the phase point would move as it is carried along 
by the phase fluid.

69
3.5 OVERDAMPED BEAD ON A ROTATING HOOP
In general, the pattern of trajectories would be difficult to picture, but the pres-
ent case is simple because we are only interested in the limit F l 0. In this limit, all 
trajectories slam straight up or down onto the curve C defined by f  ( G) = 8, and then 
slowly ooze along this curve until they reach a fixed point (Figure 3.5.8).
2π
Ω
−2π
φ
φ
C: f (  ) − Ω = 0
Figure 3.5.8
To arrive at this striking conclusion, let’s do an order-of-magnitude calculation. 
Suppose that the phase point lies off the curve C. For instance, suppose ( G, 8) lies 
an O (1) distance below the curve C, i.e., 8  f  ( G) and f  ( G)  8 x O (1). Then (8b) 
shows that 8a is enormously positive: 8a x O (1 / F)  1. Thus the phase point zaps 
like lightning up to the region where  f  ( G)  8 x O ( F). In the limit F l 0, this 
region is indistinguishable from C. Once the phase point is on C, it evolves accord-
ing to 8 x f  ( G); that is, it approximately satisfies the first-order equation 
G
G
′  f ( ).
Our conclusion is that a typical trajectory is made of two parts: a rapid initial 
transient, during which the phase point zaps onto the curve where Ga = f  ( G), 
followed by a much slower drift along this curve.
Now we see how the paradox is resolved: The second-order system (6) does 
behave like the first-order system (7), but only after a rapid initial transient. 
During this transient, it is not correct to neglect the term Fd 2G / dU2. The problem 
with our earlier approach is that we used only a single time scale T = b / mg ; this 
time scale is characteristic of the slow drift process, but not of the rapid transient 
(Exercise 3.5.5).

70 
BIFURCATIONS
A Singular Limit
The difficulty we have encountered here occurs throughout science and engi-
neering. In some limit of interest (here, the limit of strong damping), the term con-
taining the highest order derivative drops out of the governing equation. Then the 
initial conditions or boundary conditions can’t be satisfied. Such a limit is often 
called singular. For example, in fluid mechanics, the limit of high Reynolds num-
ber is a singular limit; it accounts for the presence of extremely thin “boundary 
layers” in the flow over airplane wings. In our problem, the rapid transient played 
the role of a boundary layer—it is a thin layer of time that occurs near the bound-
ary t = 0.
The branch of mathematics that deals with singular limits is called singular 
perturbation theory. See Jordan and Smith (1987) or Lin and Segel (1988) for an 
introduction. Another problem with a singular limit will be discussed briefly in 
Section 7.5.
3.6 Imperfect Bifurcations and Catastrophes
As we mentioned earlier, pitchfork bifurcations are common in problems that 
have a symmetry. For example, in the problem of the bead on a rotating hoop 
(Section 3.5), there was a perfect symmetry between the left and right sides of 
the hoop. But in many real-world circumstances, the symmetry is only approxi-
mate—an imperfection leads to a slight difference between left and right. We 
now want to see what happens when such imperfections are present. 
For example, consider the system
x
h
rx
x
=
+
−
3.  
(1)
If h = 0, we have the normal form for a supercritical pitchfork bifurcation, and 
there’s a perfect symmetry between x and x. But this symmetry is broken when 
h v 0; for this reason we refer to h as an imperfection parameter.
Equation (1) is a bit harder to analyze than other bifurcation problems we’ve 
considered previously, because we have two independent parameters to worry 
about ( h and r ). To keep things straight, we’ll think of r as fixed, and then examine 
the effects of varying h. The first step is to analyze the fixed points of (1). These 
can be found explicitly, but we’d have to invoke the messy formula for the roots 
of a cubic equation. It’s clearer to use a graphical approach, as in Example 3.1.2. 
We plot the graphs of y = rx  x 3 and y = h on the same axes, and look for 
intersections (Figure 3.6.1). These intersections occur at the fixed points of (1). 
When r b 0, the cubic is monotonically decreasing, and so it intersects the hori-
zontal line y = h in exactly one point (Figure 3.6.1a). The more interesting case is 
r  0; then one, two, or three intersections are possible, depending on the value of 
h (Figure 3.6.1b).

71
3.6 IMPERFECT BIFURCATIONS AND CATASTROPHES
y = rx − x3
y =  − h
x
x
(a)  r ≤ 0
(b)  r > 0
|h| > hc (r)
|h| = hc (r)
|h| < hc (r)
Figure 3.6.1
The critical case occurs when the horizontal line is just tangent to either the 
local minimum or maximum of the cubic; then we have a saddle-node bifurcation. 
To find the values of h at which this bifurcation occurs, note that the cubic has a 
local maximum when d
dx rx
x
r
x
(
)
.
−
= −
=
3
2
3
0  Hence 
x
r
max 
3,
and the value of the cubic at the local maximum is 
rx
x
r
r
max
max
(
)
.
−
=
3
2
3
3
Similarly, the value at the minimum is the negative of this quantity. Hence 
saddle-node bifurcations occur when h = ohc ( r ) , where
h r
r
r
c( )
.
 2
2
3
Equation (1) has three fixed points for |h|  hc( r ) and one fixed point for |h|  hc ( r ). 
To summarize the results so far, we plot the bifurcation curves h = ohc( r ) in the 
( r, h ) plane (Figure 3.6.2). Note that the two bifurcation curves meet tangentially 
at ( r, h ) = (0,0); such a point is called a cusp point. We also label the regions that 
correspond to different numbers of fixed points. Saddle-node bifurcations occur 
all along the boundary of the regions, except at the cusp point, where we have 
a codimension-2 bifurcation. (This fancy terminology essentially means that we 
have had to tune two parameters, h and r, to achieve this type of bifurcation. Until 
now, all our bifurcations could be achieved by tuning a single parameter, and were 
therefore codimension-1 bifurcations.)

72 
BIFURCATIONS
2
2
r
hc (r)
h
− hc (r)
1
1 fixed point
3 fixed points
1
0
0
−1
−1
−2
−2
Figure 3.6.2
Pictures like Figure 3.6.2 will prove very useful in our future work. We will refer 
to such pictures as stability diagrams. They show the different types of behavior 
that occur as we move around in parameter space (here, the ( r, h ) plane).
Now let’s present our results in a more familiar way by showing the bifurca-
tion diagram of x * vs. r , for fixed h (Figure 3.6.3).
x
(a) h = 0
(b) h ≠ 0
x
r
r
Figure 3.6.3
When h = 0 we have the usual pitchfork diagram (Figure 3.6.3a) but when h v 0, 
the pitchfork disconnects into two pieces (Figure 3.6.3b). The upper piece con-
sists entirely of stable fixed points, whereas the lower piece has both stable and 
unstable branches. As we increase r from negative values, there’s no longer a sharp 
transition at r = 0; the fixed point simply glides smoothly along the upper branch. 
Furthermore, the lower branch of stable points is not accessible unless we make a 
fairly large disturbance.
Alternatively, we could plot x * vs. h, for fixed r (Figure 3.6.4).

73
3.6 IMPERFECT BIFURCATIONS AND CATASTROPHES
x
x
h
h
(b) r > 0
(a) r ≤ 0
Figure 3.6.4
When r b 0 there’s one stable fixed point for each h (Figure 3.6.4a). However, when 
r  0 there are three fixed points when |h|  hc( r ), and one otherwise (Figure 3.6.4b). 
In the triple-valued region, the middle branch is unstable and the upper and lower 
branches are stable. Note that these graphs look like Figure 3.6.1 rotated by 90°.
There is one last way to plot the results, 
which may appeal to you if you like to pic-
ture things in three dimensions. This method 
of presentation contains all of the others as 
cross sections or projections. If we plot the 
fixed points x * above the ( r, h ) plane, we 
get the cusp catastrophe surface shown in 
Figure 3.6.5. The surface folds over on itself 
in certain places. The projection of these 
folds onto the ( r, h ) plane yields the bifurca-
tion curves shown in Figure  3.6.2. A cross 
section at fixed h yields Figure 3.6.3, and a 
cross section at fixed r yields Figure 3.6.4.
The term catastrophe is motivated by the 
fact that as parameters change, the state of 
the system can be carried over the edge of the 
upper surface, after which it drops discon-
tinuously to the lower surface (Figure 3.6.6). 
This jump could be truly catastrophic for the 
equilibrium of a bridge or a building. We will 
see scientific examples of catastrophes in the 
context of insect outbreaks (Section 3.7) and 
in the following example from mechanics.
For more about catastrophe theory, see Zeeman (1977) or Poston and Stewart 
(1978). Incidentally, there was a violent controversy about this subject in the late 
1970s. If you like watching fights, have a look at Zahler and Sussman (1977) and 
Kolata (1977).
x
h
r
Figure 3.6.5
x
h
r
Figure 3.6.6

74 
BIFURCATIONS
Bead on a Tilted Wire
As a simple example of imperfect bifurcation and catastrophe, consider the fol-
lowing mechanical system (Figure 3.6.7).
g
m
k
a
x
wire
θ
Figure 3.6.7
A bead of mass m is constrained to slide along a straight wire inclined at an angle 
R with respect to the horizontal. The mass is attached to a spring of stiffness k and 
relaxed length L0  , and is also acted on by gravity. We choose coordinates along the 
wire so that x = 0 occurs at the point closest to the support point of the spring; let 
a be the distance between this support point and the wire.
In Exercises 3.5.4 and 3.6.5, you are asked to analyze the equilibrium positions 
of the bead. But first let’s get some physical intuition. When the wire is horizontal 
( R = 0), there is perfect symmetry between the left and right sides of the wire, and 
x = 0 is always an equilibrium position. The stability of this equilibrium depends 
on the relative sizes of L0 and a : if L0  a, the spring is in tension and so the 
equilibrium should be stable. But if L0  a, the spring is compressed and so we 
expect an unstable equilibrium at x = 0 and a pair of stable equilibria to either side 
of it. Exercise 3.5.4 deals with this simple case.
The problem becomes more interesting when we tilt the wire ( R v 0). For small 
tilting, we expect that there are still three equilibria if L0  a. However if the 
tilt becomes too steep, perhaps you can see intuitively that the uphill equilibrium 
might suddenly disappear, causing the bead to jump catastrophically to the down-
hill equilibrium. You might even want to build this mechanical system and try it. 
Exercise 3.6.5 asks you to work through the mathematical details.
3.7 Insect Outbreak
For a biological example of bifurcation and catastrophe, we turn now to a model 
for the sudden outbreak of an insect called the spruce budworm. This insect is 
a serious pest in eastern Canada, where it attacks the leaves of the balsam fir tree. 
When an outbreak occurs, the budworms can defoliate and kill most of the fir trees 
in the forest in about four years.

75
3.7 INSECT OUTBREAK
Ludwig et al. (1978) proposed and analyzed an elegant model of the interaction 
between budworms and the forest. They simplified the problem by exploiting a 
separation of time scales: the budworm population evolves on a fast time scale 
(they can increase their density fivefold in a year, so they have a characteristic 
time scale of months), whereas the trees grow and die on a slow time scale (they 
can completely replace their foliage in about 7–10 years, and their life span in the 
absence of budworms is 100–150 years.) Thus, as far as the budworm dynamics are 
concerned, the forest variables may be treated as constants. At the end of the anal-
ysis, we will allow the forest variables to drift very slowly—this drift ultimately 
triggers an outbreak.
Model
The proposed model for the budworm population dynamics is
N
RN
N
K
p N
=
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟−
1
(
).
In the absence of predators, the budworm population N ( t ) is assumed to grow 
logistically with growth rate R and carrying capacity K. The carrying capacity 
depends on the amount of foliage left on the trees, and so it is a slowly drifting 
parameter; at this stage we treat it as fixed. 
The term p ( N ) represents the death rate 
due to predation, chiefly by birds, and 
is assumed to have the shape shown in 
Figure 3.7.1. There is almost no predation 
when budworms are scarce; the birds seek 
food elsewhere. However, once the popula-
tion exceeds a certain critical level N = A, 
the predation turns on sharply and then 
saturates (the birds are eating as fast as they can). Ludwig et al. (1978) assumed the 
specific form 
p N
BN
A
N
(
) =
+
2
2
2
where A, B  0. Thus the full model is
N
RN
N
K
BN
A
N
=
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟−
+
1
2
2
2 .  
(1)
We now have several questions to answer. What do we mean by an “outbreak” 
in the context of this model? The idea must be that, as parameters drift, the bud-
worm population suddenly jumps from a low to a high level. But what do we 
B
A
N
 p(N )
Figure 3.7.1

76 
BIFURCATIONS
mean by “low” and “high,” and are there solutions with this character? To answer 
these questions, it is convenient to recast the model into a dimensionless form, 
as in Section 3.5.
Dimensionless Formulation
The model (1) has four parameters: R, K, A, and B. As usual, there are various 
ways to nondimensionalize the system. For example, both A and K have the same 
dimension as N, and so either N / A or N / K could serve as a dimensionless popu-
lation level. It often takes some trial and error to find the best choice. In this case, 
our heuristic will be to scale the equation so that all the dimensionless groups are 
pushed into the logistic part of the dynamics, with none in the predation part. 
This turns out to ease the graphical analysis of the fixed points.
To get rid of the parameters in the predation term, we divide (1) by B and 
then let
x = N / A, 
which yields
A
B
dx
dt
R
B Ax
Ax
K
x
x
=
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟−+
1
1
2
2 .  
(2)
Equation (2) suggests that we should introduce a dimensionless time U and dimen-
sionless groups r and k, as follows:
U 


Bt
A
r
RA
B
k
K
A
,
,
.
Then (2) becomes
dx
d
rx
x
k
x
x
U =
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟−+
1
1
2
2 ,  
(3)
which is our final dimensionless form. Here r and k are the dimensionless growth 
rate and carrying capacity, respectively.
Analysis of Fixed Points
Equation (3) has a fixed point at x * = 0; it is always unstable (Exercise 3.7.1). The 
intuitive explanation is that the predation is extremely weak for small x, and so the 
budworm population grows exponentially for x near zero.
The other fixed points of (3) are given by the solutions of
r
x
k
x
x
1
1
2
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟= +
.  
(4)

77
3.7 INSECT OUTBREAK
This equation is easy to analyze graph-
ically—we simply graph the right- and 
left-hand sides of (4), and look for inter-
sections (Figure 3.7.2). The left-hand side 
of (4) represents a straight line with 
x-intercept equal to k and a y-intercept 
equal to r, and the right-hand side rep-
resents a curve that is independent of 
the parameters! Hence, as we vary the 
parameters r and k, the line moves but 
the curve doesn’t—this convenient prop-
erty is what motivated our choice of nondimensionalization.
Figure 3.7.2 shows that if k is sufficiently small, there is exactly one intersection 
for any r  0. However, for large k, we can have one, two, or three intersections, 
depending on the value of r (Figure 3.7.3). Let’s suppose that there are three inter-
sections a, b, and c. As we decrease 
r with k fixed, the line rotates coun-
terclockwise about k. Then the 
fixed points b and c approach each 
other and eventually coalesce in a 
saddle-node bifurcation when the 
line intersects the curve tangentially 
(dashed line in Figure 3.7.3). After the 
bifurcation, the only remaining fixed 
point is a (in addition to x * = 0, of 
course). Similarly, a and b can collide 
and annihilate as r is increased.
To determine the stability of the fixed points, we recall that x * = 0 is unstable, 
and also observe that the stability type must alternate as we move along the 
x-axis.
Hence a is stable, b is unsta-
ble, and c is stable. Thus, for r 
and k in the range correspond-
ing to three positive fixed points, 
the vector field is qualitatively 
like that shown in Figure  3.7.4. 
The smaller stable fixed point 
a is called the refuge level of the 
budworm population, while the 
larger stable point c is the out-
break level. From the point of view of pest control, one would like to keep the 
population at a and away from c. The fate of the system is determined by the initial 
r
k
x
1+x2
x
Figure 3.7.2
r
x
k
c
b
a
Figure 3.7.3
dx
a
b
c
x
dτ
Figure 3.7.4

78 
BIFURCATIONS
condition x 0 ; an outbreak occurs if and only if x0  b. In this sense the unstable 
equilibrium b plays the role of a threshold.
An outbreak can also be triggered by a saddle-node bifurcation. If the param-
eters r and k drift in such a way that the fixed point a disappears, then the popula-
tion will jump suddenly to the outbreak level c. The situation is made worse by 
the hysteresis effect—even if the parameters are restored to their values before the 
outbreak, the population will not drop back to the refuge level.
Calculating the Bifurcation Curves
Now we compute the curves in ( k, r ) space where the system undergoes 
saddle-node bifurcations. The calculation is somewhat harder than that in 
Section 3.6: we will not be able to write r explicitly as a function of k, for exam-
ple. Instead, the bifurcation curves will be written in the parametric form ( k ( x ), 
r ( x )), where x runs through all positive values. (Please don’t be confused by this 
traditional terminology—one would call x the “parameter” in these parametric 
equations, even though r and k are themselves parameters in a different sense.)
As discussed earlier, the condition for a saddle-node bifurcation is that the line 
r (1  x / k ) intersects the curve x / (1  x 2) tangentially. Thus we require both
r
x
k
x
x
1
1
2
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟= +
 
(5)
and
d
dx r
x
k
d
dx
x
x
1
1
2
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
⎡
⎣
⎢⎢
⎤
⎦
⎥⎥=
+
⎡
⎣
⎢⎢
⎤
⎦
⎥⎥. 
(6)
After differentiation, (6) reduces to
−
=
−
+
r
k
x
x
1
1
2
2
2
(
) . 
(7)
We substitute this expression for r / k into (5), which allows us to express r solely in 
terms of x. The result is
r
x
x
=
+
2
1
3
2
2
(
) .  
(8)
Then inserting (8) into (7) yields 
k
x
x
=
−
2
1
3
2
.  
(9)
The condition k  0 implies that x must be restricted to the range x  1.

79
3.7 INSECT OUTBREAK
Together (8) and (9) define the bifurcation curves. For each x  1, we plot the 
corresponding point (k ( x ), r ( x )) in the ( k, r ) plane. The resulting curves are shown 
in Figure 3.7.5. (Exercise 3.7.2 deals with some of the analytical properties of these 
curves.)
r
k
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
0
10
refuge
bistable
outbreak
20
30
40
Figure 3.7.5
The different regions in Figure 3.7.5 are labeled according to the stable fixed points 
that exist. The refuge level a is the only stable state for low r, and the outbreak level 
c is the only stable state for large r. In the bistable region, both stable states exist.
The stability diagram is very similar to Figure 3.6.2. It too can be regarded 
as the projection of a cusp catastrophe surface, as schematically illustrated in 
Figure 3.7.6. You are hereby challenged to graph the surface accurately!
x
r
k
refuge
outbreak
Figure 3.7.6
Comparison with Observations
Now we need to decide on biologically plausible values of the dimensionless 
groups r = RA / B and k = K / A. A complication is that these parameters may drift 

80 
BIFURCATIONS
slowly as the condition of the forest changes. According to Ludwig et al. (1978), r 
increases as the forest grows, while k remains fixed.
They reason as follows: let S denote the average size of the trees, interpreted as the 
total surface area of the branches in a stand. Then the carrying capacity K should 
be proportional to the available foliage, so K
K S
=
′ . Similarly, the half-saturation 
parameter A in the predation term should be proportional to S; predators such as 
birds search units of foliage, not acres of forest, and so the relevant quantity Aa must 
have the dimensions of budworms per unit of branch area. Hence A = AaS and 
therefore
r
RA
B S
k
K
A
=
′
=
′
′
,
. 
(10)
The experimental observations suggest that for a young forest, typically k x 300 
and r  1 / 2 so the parameters lie in the bistable region. The budworm population is 
kept down by the birds, which find it easy to search the small number of branches per 
acre. However, as the forest grows, S increases and therefore the point ( k, r ) drifts 
upward in parameter space toward the outbreak region of Figure 3.7.5. Ludwig et al. 
(1978) estimate that r x 1 for a fully mature forest, which lies dangerously in the 
outbreak region. After an outbreak occurs, the fir trees die and the forest is taken 
over by birch trees. But they are less efficient at using nutrients and eventually the fir 
trees come back—this recovery takes about 50–100 years (Murray 2002).
We conclude by mentioning some of the approximations in the model presented 
here. The tree dynamics have been neglected; see Ludwig et al. (1978) for a discussion 
of this longer time-scale behavior. We’ve also neglected the spatial distribution of 
budworms and their possible dispersal—see Ludwig et al. (1979) and Murray (2002) 
for treatments of this aspect of the problem.
EXERCISES FOR CHAPTER 3
3.1 Saddle-Node Bifurcation
For each of the following exercises, sketch all the qualitatively different vector 
fields that occur as r is varied. Show that a saddle-node bifurcation occurs at a 
critical value of r, to be determined. Finally, sketch the bifurcation diagram of 
fixed points x* versus r.
3.1.1 
x
rx
x
= +
+
1
2   
 
3.1.2 
x
r
x
= −cosh
3.1.3 
x
r
x
x
= +
−
+
(
)
ln 1
 
 
3.1.4 
x
r
x
x
x
= +
−
+
1
2
1
/ (
)
3.1.5 
(Unusual bifurcations) In discussing the normal form of the saddle-node 
bifurcation, we mentioned the assumption that a
f
r
x
rc
= ∂
∂
=
(
)
/
|
*,
0 . To see what 

81
EXERCISES
can happen if a
f
r
x
rc
= ∂
∂
≠
(
)
/
|
*,
0 , sketch the vector fields for the following exam-
ples, and then plot the fixed points as a function of r.
(a) x
r
x
=
−
2
2
(b) x
r
x
=
+
2
2
3.2 Transcritical Bifurcation
For each of the following exercises, sketch all the qualitatively different vector 
fields that occur as r is varied. Show that a transcritical bifurcation occurs at 
a critical value of r, to be determined. Finally, sketch the bifurcation diagram of 
fixed points x * vs. r.
3.2.1 
x
rx
x
=
+
2  
 
 
3.2.2 
x
rx
x
=
−
+
ln(
)
1
3.2.3 
x
x
rx
x
=
−
−
(
)
1
 
 
3.2.4 
x
x r
ex
=
−
(
)
3.2.5 
(Chemical kinetics) Consider the chemical reaction system
A
X
X
X
B
C
k
k
k
+
⎯
→
⎯
←
⎯
⎯
+
⎯→
⎯
−
1
1
2
2
.
This is a generalization of Exercise 2.3.2; the new feature is that X is used up in the 
production of C .
a) Assuming that both A and B are kept at constant concentrations a and b, show 
that the law of mass action leads to an equation of the form x
c x
c x
=
−
1
2
2 , 
where x is the concentration of X, and c1 and c2 are constants to be 
determined.
b) Show that x * = 0 is stable when k2b  k1a, and explain why this makes sense 
chemically.
3.3 Laser Threshold
3.3.1 
(An improved model of a laser) In the simple laser model considered 
in Section 3.3, we wrote an algebraic equation relating N, the number of excited 
atoms, to n, the number of laser photons. In more realistic models, this would 
be replaced by a differential equation. For instance, Milonni and Eberly (1988) 
show that after certain reasonable approximations, quantum mechanics leads to 
the system


n
GnN
kn
N
GnN
fN
p
=
−
= −
−
+ .
Here G is the gain coefficient for stimulated emission, k is the decay rate due to loss 
of photons by mirror transmission, scattering, etc., f is the decay rate for sponta-
neous emission, and p is the pump strength. All parameters are positive, except p, 
which can have either sign.

82 
BIFURCATIONS
This two-dimensional system will be analyzed in Exercise 8.1.13. For now, let’s 
convert it to a one-dimensional system, as follows.
a) Suppose that N relaxes much more rapidly than n. Then we may make the 
quasi-static approximation N x 0. Given this approximation, express N ( t ) in 
terms of n ( t ) and derive a first-order system for n. (This procedure is often 
called adiabatic elimination, and one says that the evolution of N ( t ) is slaved to 
that of n ( t ). See Haken (1983).)
b) Show that n * = 0 becomes unstable for p  pc  , where pc is to be determined.
c) What type of bifurcation occurs at the laser threshold pc ?
d) (Hard question) For what range of parameters is it valid to make the approxi-
mation used in (a)?
3.3.2 
(Maxwell-Bloch equations) The Maxwell-Bloch equations provide an 
even more sophisticated model for a laser. These equations describe the dynamics 
of the electric field E, the mean polarization P of the atoms, and the population 
inversion D:



E
P
E
P
ED
P
D
D
EP
=
−
=
−
=
+ −
−
κ
γ
γ λ
λ
(
)
(
)
(
)
1
2
1
where L is the decay rate in the laser cavity due to beam transmission, H1 and H2 are 
decay rates of the atomic polarization and population inversion, respectively, and l 
is a pumping energy parameter. The parameter l may be positive, negative, or zero; 
all the other parameters are positive.
These equations are similar to the Lorenz equations and can exhibit chaotic 
behavior (Haken 1983, Weiss and Vilaseca 1991). However, many practical lasers 
do not operate in the chaotic regime. In the simplest case H1, H2  L; then P and 
D relax rapidly to steady values, and hence may be adiabatically eliminated, as 
follows.
a) Assuming P x 0, D x 0,  express P and D in terms of E, and thereby derive a 
first-order equation for the evolution of E.
b) Find all the fixed points of the equation for E .
c) Draw the bifurcation diagram of E * vs. M. (Be sure to distinguish between sta-
ble and unstable branches.)
3.4 Pitchfork Bifurcation
In the following exercises, sketch all the qualitatively different vector fields that 
occur as r is varied. Show that a pitchfork bifurcation occurs at a critical value 
of r (to be determined) and classify the bifurcation as supercritical or subcritical. 
Finally, sketch the bifurcation diagram of x * vs. r.

83
EXERCISES
3.4.1 
x
rx
x
=
+ 4
3  
 
3.4.2 
x
rx
x
=
−sinh
3.4.3 
x
rx
x
=
−4
3  
 
3.4.4 
x
x
rx
x
=
+ +
1
2
The next exercises are designed to test your ability to distinguish among the vari-
ous types of bifurcations—it’s easy to confuse them! In each case, find the values 
of r at which bifurcations occur, and classify those as saddle-node, transcritical, 
supercritical pitchfork, or subcritical pitchfork. Finally, sketch the bifurcation dia-
gram of fixed points x * vs. r.
3.4.5 
x
r
x
= −3
2  
 
3.4.6 
x
rx
x
x
=
−+
1
3.4.7 
x
re
x
= −
−
5
2  
 
3.4.8 
x
rx
x
x
=
−+
1
2
3.4.9 
x
x
rx
=
+tanh(
)  
3.4.10 
x
rx
x
x
=
+ +
3
2
1
3.4.11 
(An interesting bifurcation diagram) Consider the system x
rx
x
=
−sin .
a) For the case r = 0, find and classify all the fixed points, and sketch the vector 
field.
b) Show that when r  1, there is only one fixed point. What kind of fixed point is 
it?
c) As r decreases from d to 0, classify all the bifurcations that occur.
d) For 0  r  1, find an approximate formula for values of r at which bifur-
cations occur.
e) Now classify all the bifurcations that occur as r decreases from 0 to d.
f) Plot the bifurcation diagram for d  r  d, and indicate the stability of the 
various branches of fixed points.
3.4.12 
(“Quadfurcation”) With tongue in cheek, we pointed out that the pitch-
fork bifurcation could be called a “trifurcation,” since three branches of fixed 
points appear for r  0. Can you construct an example of a “quadfurcation,” in 
which x
f x r

( , )  has no fixed points for r  0 and four branches of fixed points 
for r  0? Extend your results to the case of an arbitrary number of branches, if 
possible.
3.4.13 
(Computer work on bifurcation diagrams) For the vector fields below, 
use a computer to obtain a quantitatively accurate plot of the values of x * vs. r, 
where 0 b r b 3. In each case, there’s an easy way to do this, and a harder way using 
the Newton-Raphson method.
a) x
r
x
e
x
= −−
− 
b) 
x
x
e
rx
= −−
−
1
3.4.14 
(Subcritical pitchfork) Consider the system x
rx
x
x
=
+
−
3
5,  which 
exhibits a subcritical pitchfork bifurcation.

84 
BIFURCATIONS
a) Find algebraic expressions for all the fixed points as r varies.
b) Sketch the vector fields as r varies. Be sure to indicate all the fixed points and 
their stability.
c) Calculate rs, the parameter value at which the nonzero fixed points are born in a 
saddle-node bifurcation.
3.4.15 
(First-order phase transition) Consider the potential V ( x ) for the system 
x
rx
x
x
=
+
−
3
5. Calculate rc, where rc is defined by the condition that V has three 
equally deep wells, i.e., the values of V at the three local minima are equal.
(Note: In equilibrium statistical mechanics, one says that a first-order phase 
transition occurs at r = rc  . For this value of r, there is equal probability of finding 
the system in the state corresponding to any of the three minima. The freezing of 
water into ice is the most familiar example of a first-order phase transition.)
3.4.16 
(Potentials) In parts (a)(c), let V ( x ) be the potential, in the sense that 
x
dV dx
= −
. Sketch the potential as a function of r. Be sure to show all the qual-
itatively different cases, including bifurcation values of r.
a) (Saddle-node) x
r
x
= −
2
b) (Transcritical) x
rx
x
=
−
2
c) (Subcritical pitchfork) x
rx
x
x
=
+
−
3
5
3.5 Overdamped Bead on a Rotating Hoop
3.5.1 
Consider the bead on the rotating hoop discussed in Section 3.5. Explain 
in physical terms why the bead cannot have an equilibrium position with G  Q / 2.
3.5.2 
Do the linear stability analysis for all the fixed points for Equation (3.5.7), 
and confirm that Figure 3.5.6 is correct.
3.5.3 
Show that Equation (3.5.7) reduces to d
d
A
B
O
φ
τ
φ
φ
φ
=
−
+
3
5
(
)  near 
G = 0. Find A and B.
3.5.4 
(Bead on a horizontal wire) A bead of mass m is constrained to slide along 
a straight horizontal wire. A spring of relaxed length L0 and spring constant k is 
attached to the mass and to a support point a distance h from the wire (Figure 1).
wire
x
m
k
h
Figure 1

85
EXERCISES
Finally, suppose that the motion of the bead is opposed by a viscous damping 
force b x .
a) Write Newton’s law for the motion of the bead.
b) Find all possible equilibria, i.e., fixed points, as functions of k, h, m, b, and L0.
c) Suppose m = 0. Classify the stability of all the fixed points, and draw a bifurca-
tion diagram.
d) If m v 0, how small does m have to be to be considered negligible? In what sense 
is it negligible?
3.5.5 
(Time scale for the rapid transient) While considering the bead on the 
rotating hoop, we used phase plane analysis to show that the equation
ε
φ
τ
φ
τ
φ
d
d
d
d
f
2
2 +
=
( )
has solutions that rapidly relax to the curve where d
d
f
φ
τ
φ

( ).
a) Estimate the time scale Tfast for this rapid transient in terms of F, and then 
express Tfast in terms of the original dimensional quantities m, g, r, X, and b.
b) Rescale the original differential equation, using Tfast as the characteristic time 
scale, instead of Tslow = b / mg. Which terms in the equation are negligible on this 
time scale?
c) Show that Tfast  Tslow  if F  1. (In this sense, the time scales Tfast and Tslow are 
widely separated.)
3.5.6 
(A model problem about singular limits) Consider the linear differential 
equation
F

x
x
x
+
+
= 0,
subject to the initial conditions x (0) = 1, x( )
.
0
0

a) Solve the problem analytically for all F  0.
b) Now suppose F  1. Show that there are two widely separated time scales in 
the problem, and estimate them in terms of F.
c) Graph the solution x ( t ) for F  1, and indicate the two time scales on the 
graph.
d) What do you conclude about the validity of replacing F

x
x
x
+
+
= 0  with its 
singular limit x
x
+
= 0 ?
e) Give two physical analogs of this problem, one involving a mechanical system, 
and another involving an electrical circuit. In each case, find the dimensionless 
combination of parameters corresponding to F, and state the physical meaning 
of the limit F  1.
3.5.7 
(Nondimensionalizing the logistic equation) Consider the logistic equa-
tion N
rN
N K
=
−
(
/
)
1
, with initial condition N (0) = N0 .

86 
BIFURCATIONS
a) This system has three dimensional parameters r, K, and N0  . Find the dimen-
sions of each of these parameters.
b) Show that the system can be rewritten in the dimensionless form
dx
d
x
x
U =
−
(
),
1
 x (0) = x0
for appropriate choices of the dimensionless variables x, x0, and U.
c) Find a different nondimensionalization in terms of variables u and U, where u is 
chosen such that the initial condition is always u0 = 1.
d) Can you think of any advantage of one nondimensionalization over the other?
3.5.8 
(Nondimensionalizing the subcritical pitchfork) The first-order system 
u
au
bu
cu
=
+
−
3
5,  where b, c  0, has a subcritical pitchfork bifurcation at 
a = 0. Show that this equation can be rewritten as
dx
d
rx
x
x
U =
+
−
3
5
where x = u / U, U = t / T, and U, T, and r are to be determined in terms of a, b, and c.
3.6 Imperfect Bifurcations and Catastrophes
3.6.1 
(Warm-up question about imperfect bifurcation) Does Figure 3.6.3b cor-
respond to h  0 or to h  0?
3.6.2 
(Imperfect transcritical bifurcation) Consider the system x
h
rx
x
=
+
−
2.  
When h = 0, this system undergoes a transcritical bifurcation at r = 0. Our goal is 
to see how the bifurcation diagram of x * vs. r is affected by the imperfection 
parameter h.
a) Plot the bifurcation diagram for x
h
rx
x
=
+
−
2, for h  0, h = 0, and h  0.
b) Sketch the regions in the ( r, h ) plane that correspond to qualitatively different 
vector fields, and identify the bifurcations that occur on the boundaries of 
those regions.
c) Plot the potential V ( x ) corresponding to all the different regions in the ( r, h ) 
plane.
3.6.3 
(A perturbation to the supercritical pitchfork) Consider the system 
x
rx
ax
x
=
+
−
2
3,  where d  a  d. When a = 0, we have the normal form for 
the supercritical pitchfork. The goal of this exercise is to study the effects of the 
new parameter a.
a) For each a, there is a bifurcation diagram of x * vs. r. As a varies, these bifurca-
tion diagrams can undergo qualitative changes. Sketch all the qualitatively 
different bifurcation diagrams that can be obtained by varying a.

87
EXERCISES
b) Summarize your results by plotting the regions in the ( r, a ) plane that corre-
spond to qualitatively different classes of vector fields. Bifurcations occur on 
the boundaries of these regions; identify the types of bifurcations that occur.
3.6.4 
(Imperfect saddle-node) What happens if you add a small imperfection to 
a system that has a saddle-node bifurcation?
3.6.5 
(Mechanical example of imperfect bifurcation and catastrophe) Consider 
the bead on a tilted wire discussed at the end of Section 3.6.
a) Show that the equilibrium positions of the bead satisfy
mg
kx
L
x
a
sin
.
R =
−
+
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟
1
0
2
2
b) Show that this equilibrium equation can be written in dimensionless form as
1
1
2
−
=
+
h
u
R
u
 
 
for appropriate choices of R, h, and u.
c) Give a graphical analysis of the dimensionless equation for the cases R  1 and 
R  1. How many equilibria can exist in each case?
d) Let r = R  1. Show that the equilibrium equation reduces to h
ru
u
+
−
≈
1
2
3
0  
for small r, h, and u.
e) Find an approximate formula for the saddle-node bifurcation curves in the 
limit of small r, h, and u.
f) Show that the exact equations for the bifurcation curves can be written in para-
metric form as
h ( u ) = u3, 
R ( u ) = (l  u2 )3 / 2,
 
where d  u  d. (Hint: You may want to look at Section 3.7.) Check that 
this result reduces to the approximate result in part (d).
g) Give a numerically accurate plot of the bifurcation curves in the ( r, h ) plane.
h) Interpret your results physically, in terms of the original dimensional variables.
3.6.6 
(Patterns in fluids) Ahlers (1989) gives a fascinating review of experi-
ments on one-dimensional patterns in fluid systems. In many cases, the patterns 
first emerge via supercritical or subcritical pitchfork bifurcations from a spa-
tially uniform state. Near the bifurcation, the dynamics of the amplitude of the 
patterns are given approximately by τ
ε
A
A
gA
=
−
3  in the supercritical case, or 
τ
ε
A
A
gA
kA
=
−
−
3
5  in the subcritical case. Here A ( t ) is the amplitude, U is a 
typical time scale, and F is a small dimensionless parameter that measures the 
distance from the bifurcation. The parameter g  0 in the supercritical case, 

88 
BIFURCATIONS
whereas g  0 and k  0 in the subcritical case. (In this context, the equation 
τ
ε
A
A
gA
=
−
3  is often called the Landau equation.)
a) Dubois and Bergé (1978) studied the supercritical bifurcation that arises in 
Rayleigh-Bénard convection, and showed experimentally that the steady-
state amplitude depended on F according to the power law A* r FC, where 
C = 0.50 o0.01. What does the Landau equation predict?
b) The equation τ
ε
A
A
gA
kA
=
−
−
3
5  is said to undergo a tricritical bifurcation 
when g = 0; this case is the borderline between supercritical and subcritical 
bifurcations. Find the relation between A * and F when g = 0.
c) In experiments on Taylor–Couette vortex flow, Aitta et al. (1985) were able to 
change the parameter g continuously from positive to negative by varying the 
aspect ratio of their experimental set-up. Assuming that the equation is modi-
fied to τ
ε
A
h
A
gA
kA
=
+
−
−
3
5,  where h  0 is a slight imperfection, sketch 
the bifurcation diagram of A * vs. F in the three cases g  0, g = 0, and g  0 . 
Then look up the actual data in Aitta et al. (1985, Figure 2) or see Ahlers (1989, 
Figure 15).
d) In the experiments of part (c), the amplitude A ( t) was found to evolve toward a 
steady state in the manner shown in Figure 2 (redrawn from Ahlers (1989), 
Figure 18). The results are for the imperfect subcritical case g  0, h v 0. In the 
experiments, the parameter F was switched at t = 0 from a negative value to a 
positive value Ff  . In Figure 2, Ff increases from the bottom to the top.
A
t
large
f
ε
fε
small
Figure 2
Explain intuitively why the curves have this strange shape. Why do the curves for 
large Ff go almost straight up to their steady state, whereas the curves for small Ff 
rise to a plateau before increasing sharply to their final level? (Hint: Graph A  vs. 
A for different Ff  .)
3.6.7 
(Simple model of a magnet) A magnet can be modeled as an enormous 
collection of electronic spins. In the simplest model, known as the Ising model, 
the spins can point only up or down, and are assigned the values Si = ol, for 
i = 1, … , N  1. For quantum mechanical reasons, the spins like to point in the 

89
EXERCISES
same direction as their neighbors; on the other hand, the randomizing effects of 
temperature tend to disrupt any such alignment.
An important macroscopic property of the magnet is its average spin or 
magnetization
m
S
N
i
i
N
=
=∑
1
1
.
At high temperature the spins point in random directions and so m x 0; the mate-
rial is in the paramagnetic state. As the temperature is lowered, m remains near 
zero until a critical temperature Tc is reached. Then a phase transition occurs and 
the material spontaneously magnetizes. Now m  0; we have a ferromagnet.
But the symmetry between up and down spins means that there are two possible 
ferromagnetic states. This symmetry can be broken by applying an external mag-
netic field h, which favors either the up or down direction. Then, in an approxima-
tion called mean-field theory, the equation governing the equilibrium value of m is
h = T tanh1 m  Jnm
where J and n are constants; J  0 is the ferromagnetic coupling strength and n is 
the number of neighbors of each spin (Ma 1985, p. 459).
a) Analyze the solutions m * of h = T tanh1 m  Jnm , using a graphical approach.
b) For the special case h = 0, find the critical temperature Tc at which a phase tran-
sition occurs.
3.7 Insect Outbreak
3.7.1 
(Warm-up question about insect outbreak model) Show that the fixed 
point x * = 0 is always unstable for Equation (3.7.3).
3.7.2 
(Bifurcation curves for insect outbreak model)
a) Using Equations (3.7.8) and (3.7.9), sketch r ( x ) and k ( x ) vs. x. Determine the 
limiting behavior of r ( x ) and k ( x ) as x l 1 and x l d.
b) Find the exact values of r, k, and x at the cusp point shown in Figure 3.7.5.
3.7.3 
(A model of a fishery) The equation N
rN
H
N
K
=
−
(
)−
1
 provides an 
extremely simple model of a fishery. In the absence of fishing, the population is 
assumed to grow logistically. The effects of fishing are modeled by the term H, 
which says that fish are caught or “harvested” at a constant rate H  0, indepen-
dent of their population N. (This assumes that the fishermen aren’t worried about 
fishing the population dry—they simply catch the same number of fish every day.)
a) Show that the system can be rewritten in dimensionless form as
dx
d
x
x
h
U =
−
−
(
)
,
1
 

90 
BIFURCATIONS
for suitably defined dimensionless quantities x, U, and h.
b) Plot the vector field for different values of h.
c) Show that a bifurcation occurs at a certain value hc  , and classify this bifurcation.
d) Discuss the long-term behavior of the fish population for h  hc and h  hc  , 
and give the biological interpretation in each case.
There’s something silly about this model—the population can become negative! A 
better model would have a fixed point at zero population for all values of H. See the 
next exercise for such an improvement.
3.7.4 
(Improved model of a fishery) A refinement of the model in the last exer-
cise is
N
rN
N
K
H
N
A
N
=
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟−
+
1
where H  0 and A  0. This model is more realistic in two respects: it has a fixed 
point at N = 0 for all values of the parameters, and the rate at which fish are caught 
decreases with N. This is plausible—when fewer fish are available, it is harder to 
find them and so the daily catch drops.
a) Give a biological interpretation of the parameter A; what does it measure?
b) Show that the system can be rewritten in dimensionless form as
dx
d
x
x
h
x
a
x
U =
−
−
+
(
)
,
1
for suitably defined dimensionless quantities x, U, a, and h.
c) Show that the system can have one, two, or three fixed points, depending on the 
values of a and h. Classify the stability of the fixed points in each case.
d) Analyze the dynamics near x = 0 and show that a bifurcation occurs when 
h = a. What type of bifurcation is it?
e) Show that another bifurcation occurs when h
a
=
+
1
4
2
1
(
) ,  for a  ac , where ac 
is to be determined. Classify this bifurcation.
f) Plot the stability diagram of the system in ( a, h ) parameter space. Can hystere-
sis occur in any of the stability regions?
3.7.5 
(A biochemical switch) Zebra stripes and butterfly wing patterns are two 
of the most spectacular examples of biological pattern formation. Explaining the 
development of these patterns is one of the outstanding problems of biology; see 
Murray (2003) for an excellent review.
As one ingredient in a model of pattern formation, Lewis et al. (1977) consid-
ered a simple example of a biochemical switch, in which a gene G is activated by a 
biochemical signal substance S. For example, the gene may normally be inactive 
but can be “switched on” to produce a pigment or other gene product when the 

91
EXERCISES
concentration of S exceeds a certain threshold. Let g ( t ) denote the concentration 
of the gene product, and assume that the concentration s0 of S is fixed. The model is
g
k s
k g
k g
k
g
=
−
+
+
1 0
2
3
2
4
2
2
where the k’s are positive constants. The production of g is stimulated by s0 at a 
rate k1, and by an autocatalytic or positive feedback process (the nonlinear term). 
There is also a linear degradation of g at a rate k2.
a) Show that the system can be put in the dimensionless form
dx
d
s
rx
x
x
U = −
+ +
2
2
1
where r  0 and s p 0 are dimensionless groups.
b) Show that if s = 0, there are two positive fixed points x * if r  rc  , where rc is to 
be determined.
c) Assume that initially there is no gene product, i.e., g (0) = 0, and suppose s is 
slowly increased from zero (the activating signal is turned on); what happens 
to g ( t ) ? What happens if s then goes back to zero? Does the gene turn off 
again?
d) Find parametric equations for the bifurcation curves in ( r, s ) space, and classify 
the bifurcations that occur.
e) Use the computer to give a quantitatively accurate plot of the stability diagram 
in ( r, s ) space.
For further discussion of this model, see Lewis et al. (1977); Edelstein–Keshet 
(1988), Section 7.5; or Murray (2002), Chapter 6.
3.7.6 
(Model of an epidemic) In pioneering work in epidemiology, Kermack 
and McKendrick (1927) proposed the following simple model for the evolution 
of an epidemic. Suppose that the population can be divided into three classes: 
x ( t ) = number of healthy people; y ( t ) = number of sick people; z ( t ) = number of 
dead people. Assume that the total population remains constant in size, except 
for deaths due to the epidemic. (That is, the epidemic evolves so rapidly that we 
can ignore the slower changes in the populations due to births, emigration, or 
deaths by other causes.)
Then the model is



x
kxy
y
kxy
ly
z
ly
= −
=
−
=
where k and l are positive constants. The equations are based on two assumptions:

92 
BIFURCATIONS
(i) Healthy people get sick at a rate proportional to the product of x and y. This 
would be true if healthy and sick people encounter each other at a rate propor-
tional to their numbers, and if there were a constant probability that each such 
encounter would lead to transmission of the disease.
(ii)  Sick people die at a constant rate l.
The goal of this exercise is to reduce the model, which is a third-order system, to 
a first-order system that can analyzed by our methods. (In Chapter 6 we will see a 
simpler analysis.)
a) Show that x  y  z = N, where N is constant.
b) Use the x  and z  equation to show that x t
x
kz t
l
( )
exp(
( )
),
=
−
0
 where 
x0 = x (0).
c) Show that z satisfies the first-order equation z
l N
z
x
kz l
=
−−
−
[
exp(
/ )].
0
d) Show that this equation can be nondimensionalized to
du
d
a
bu
e
u
U =
−
−
−
by an appropriate rescaling.
e) Show that a p 1 and b  0.
f) Determine the number of fixed points u* and classify their stability.
g) Show that the maximum of u t( ) occurs at the same time as the maximum of 
both z t( ) and y ( t ). (This time is called the peak of the epidemic, denoted tpeak  . 
At this time, there are more sick people and a higher daily death rate than at 
any other time.)
h) Show that if b  1, then u t( ) is increasing at t = 0 and reaches its maximum at 
some time tpeak  0. Thus things get worse before they get better. (The term 
epidemic is reserved for this case.) Show that u t( ) eventually decreases to 0.
i) On the other hand, show that tpeak = 0 if b  1. (Hence no epidemic occurs if 
b  1.)
j) The condition b = 1 is the threshold condition for an epidemic to occur. Can you 
give a biological interpretation of this condition?
k) Kermack and McKendrick showed that their model gave a good fit to data 
from the Bombay plague of 1906. How would you improve the model to make it 
more appropriate for AIDS? Which assumptions need revising? 
For an introduction to models of epidemics, see Murray (2002), Chapter 10, or 
Edelstein–Keshet (1988). Models of AIDS are discussed by Murray (2002) and 
May and Anderson (1987). An excellent review and commentary on the Kermack–
McKendrick papers is given by Anderson (1991).

93
EXERCISES
The next two exercises involve applications of nonlinear dynamics to systems biol-
ogy, and were kindly suggested by Jordi Garcia-Ojalvo.
3.7.7 
(Hysteretic activation)  Consider a protein that activates its own tran-
scription in a positive feedback loop, while its promoter has a certain level of basal 
expression:
p
p
K
p
p
n
n
n
=
+
+
−
α
β
δ
.
Here B  is the basal transcription rate, C  is the maximal transcription rate, K is 
the activation coefficient, and E  is the decay rate of the protein. To ease the analy-
sis, assume that n is large ( n 1). 
a)  Sketch the graph of the nonlinear function g p
p
K
p
n
n
n
( )
/ (
)
=
+
C
 for n 1. 
What simple shape does it approach as n →∞?
b)  The right hand side of the equation for p  can be rewritten as g p
h p
( )
( )

, 
where h p
p
( ) =
−
δ
α . Use this decomposition to plot the phase portrait for the 
system for the following three cases: (i) δ
α
β
K −
>
, (ii) δ
α
β
K −
=
/ 2 , and 
(iii) δ
α
K −
< 0 . 
c)  From now on, assume δ
β
K 
. Plot the bifurcation diagram for the system. Be 
sure to indicate clearly how the location and stability of the fixed points p*  
vary with respect to B .
d)  Discuss how the level of protein p behaves if B  is very slowly increased from 
B  0  to α
δ
 K , and then very slowly decreased back to B  0 .  Show that 
such a pulsed stimulation leads to hysteresis.
3.7.8 
(Irreversible response to a transient stimulus)  Many types of molecules 
within cells can be turned on and off by adding phosphate groups to them, a pro-
cess known as phosphorylation. The addition of the phosphate group changes the 
conformation of the molecule to which it is bound, in effect flipping a switch and 
thereby altering the molecule’s activity. This is one of the most common ways that 
cells control a diverse array of important processes, ranging from enzyme activ-
ity to cellular reproduction, movement, signaling, and metabolism. The reverse 
reaction, in which a phosphate group is removed, is called dephosphorylation. For 
further information, see Hardie (1999) and Alon (2006). 
To illustrate how a cell’s fate can be determined irreversibly by a transient stim-
ulus, Xiong and Ferrell (2003) considered a model of a phosphorylation/dephos-
phorylation cycle in which phosphorylation is induced in two different ways: by a 
stimulus signal S, and by the phosphorylated protein itself via a positive feedback 
loop. Assuming that the latter process is cooperative, the dynamics of the phos-
phorylated protein are governed by

94 
BIFURCATIONS
A
k SA
A
K
A
k A
p
p
p
n
n
p
n
d
p
=
+
+
−
C
.
Here A  is the concentration of the unphosphorylated protein and Ap  is the con-
centration of the phosphorylated protein. We’ll assume that the total protein con-
centration, A
A
A
T
p
=
+
, is constant. In the model, kp  is the activation 
(phosphorylation) rate and kd  is the inactivation (dephosphorylation) rate. For 
simplicity, we’ll consider the convenient special case n 1, K
AT

/ 2 , and 
C  k A
d
T .
a) Nondimensionalize the system by rewriting it in terms of the dimensionless 
quantities x
A
K
p

/
, U  k t
d , s
k S k
p
d

/
, and b
k K
d
 C / (
) .
b)  Assume first that there is no stimulus so s  0 . Plot the phase portrait of the 
system.
c) Plot all the qualitatively different phase portraits that can occur for a constant 
stimulus s  0 . 
d)  Taking into account the behavior of the fixed points that you calculated in part 
(b), plot the bifurcation diagram of the system for increasing stimulus s. 
e)  Show that the system is irreversible in the following sense: if the cell starts with 
no phosphorylated proteins and no stimulus, then the protein activates if a suffi-
ciently large stimulus is applied—but it does not deactivate if s is later decreased 
back to 0.
f)  Repeat the analysis above, but this time for a value of C  k A
d
T . What hap-
pens with the reversibility in this case?

95
4.1 EXAMPLES AND DEFINITIONS
4
FLOWS ON THE CIRCLE
4.0 Introduction
So far we’ve concentrated on the equation x
f x

( ), which we visualized as a 
vector field on the line. Now it’s time to consider a new kind of differential equa-
tion and its corresponding phase space. This equation,
R
R
 f ( ),
corresponds to a vector field on the circle. Here R is a point on the circle and R  is the 
velocity vector at that point, determined by the rule R
R
 f ( ). Like the line, the 
circle is one-dimensional, but it has an important new property: by flowing in one 
direction, a particle can eventually return to its starting place (Figure 4.0.1). Thus 
periodic solutions become possible for the first time in this book! To put it another 
way, vector fields on the circle provide the most basic model of sys-
tems that can oscillate.
However, in all other respects, flows on the circle are similar to 
flows on the line, so this will be a short chapter. We will discuss 
the dynamics of some simple oscillators, and then show that these 
equations arise in a wide variety of applications. For example, the 
flashing of fireflies and the voltage oscillations of superconduct-
ing Josephson junctions have been modeled by the same equation, 
even though their oscillation frequencies differ by about ten orders of magnitude!
4.1 Examples and Definitions
Let’s begin with some examples, and then give a more careful definition of vector 
fields on the circle.
Figure 4.0.1

96 
FLOWS ON THE CIRCLE
EXAMPLE 4.1.1:
Sketch the vector field on the circle corresponding to R
R
 sin .
Solution: We assign coordinates to the circle in the usual way, with R  0  in the 
direction of “east,” and with R increasing counterclockwise.
To sketch the vector field, we first find the fixed points, defined by R  0.  These 
occur at R*  0 and R*  Q. To determine their stability, note that sin R  0 on the 
upper semicircle. Hence R  0, so the flow is counterclockwise. Similarly, the flow 
is clockwise on the lower semicircle, where R  0. Hence R*  Q is stable and 
R*  0 is unstable, as shown in Figure 4.1.1.
Actually, we’ve seen this example before—it’s 
given in Section 2.1. There we regarded x
x
 sin
 
as a vector field on the line. Compare Figure 2.1.1 
with Figure 4.1.1 and notice how much clearer it 
is to think of this system as a vector field on the 
circle. ■
EXAMPLE 4.1.2:
Explain why R
R

 cannot be regarded as a vector field on the circle, for R in the 
range d  R  d.
Solution: The velocity is not uniquely defined. For example, R  0 and R  2Q 
are two labels for the same point on the circle, but the first label implies a velocity 
of 0 at that point, while the second implies a velocity of 2Q. ■
If we try to avoid this non-uniqueness by restricting R to the range Q  Rb Q, 
then the velocity vector jumps discontinuously at the point corresponding to R  Q. 
Try as we might, there’s no way to consider R
R

 as a smooth vector field on the 
entire circle.
Of course, there’s no problem regarding R
R

 as a vector field on the line, 
because then R  0 and R  2Q are different points, and so there’s no conflict about 
how to define the velocity at each of them.
Example 4.1.2 suggests how to define vector fields on the circle. Here’s a geo-
metric definition: A vector field on the circle is a rule that assigns a unique velocity 
vector to each point on the circle.
In practice, such vector fields arise when we have a first-order system R
R
 f ( ) , 
where f  ( R) is a real-valued, 2Q-periodic function. That is, f  ( R  2Q)  f  ( R) for all 
real R. Moreover, we assume (as usual) that f  ( R) is smooth enough to guarantee 
existence and uniqueness of solutions. Although this system could be regarded as 
a special case of a vector field on the line, it is usually clearer to think of it as a 
vector field on the circle (as in Example 4.1.1). This means that we don’t distinguish 
θ
θ
0
π
*
*
=
=
Figure 4.1.1

97
4.2 UNIFORM OSCILLATOR
between R’s that differ by an integer multiple of 2Q. Here’s where the periodicity of 
f  ( R ) becomes important—it ensures that the velocity R  is uniquely defined at each 
point R on the circle, in the sense that R  is the same, whether we call that point R or 
R  2Q, or R  2Qk for any integer k.
4.2 Uniform Oscillator
A point on a circle is often called an angle or a phase. Then the simplest oscillator 
of all is one in which the phase R changes uniformly:
θ
ω

where X is a constant. The solution is
R( t )  Xt  R0  ,
which corresponds to uniform motion around the circle at an angular frequency X. 
This solution is periodic, in the sense that R( t ) changes by 2Q, and therefore returns 
to the same point on the circle, after a time T  2Q / X. We call T the period of the 
oscillation.
Notice that we have said nothing about the amplitude of the oscillation. There 
really is no amplitude variable in our system. If we had an amplitude as well as a 
phase variable, we’d be in a two-dimensional phase space; this situation is more com-
plicated and will be discussed later in the book. (Or if you prefer, you can imagine 
that the oscillation occurs at some fixed amplitude, corresponding to the radius of 
our circular phase space. In any case, amplitude plays no role in the dynamics.)
EXAMPLE 4.2.1:
Two joggers, Speedy and Pokey, are running at a steady pace around a circular 
track. It takes Speedy T1 seconds to run once around the track, whereas it takes 
Pokey T2  T1 seconds. Of course, Speedy will periodically overtake Pokey; how 
long does it take for Speedy to lap Pokey once, assuming that they start together?
Solution: Let R1( t ) be Speedy’s position on the track. Then θ
ω
1
1

 where 
X1  2Q  /  T1. This equation says that Speedy runs at a steady pace and completes 
a  circuit every T1 seconds. Similarly, suppose that 
θ
ω
π
2
2
2
2


T  for Pokey.
The condition for Speedy to lap Pokey is that the angle 
between them has increased by 2Q. Thus if we define the 
phase difference G  R1  R2, we want to find how long it 
takes for G to increase by 2Q (Figure 4.2.1). By subtraction 
we find 


φ
θ
θ
ω
ω
=
−
=
−
1
2
1
2. Thus G increases by 2Q after 
a time
θ
φ
θ 2
1
Figure 4.2.1

98 
FLOWS ON THE CIRCLE
T
T
T
lap =
−
=
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
−
2
1
1
1
2
1
2
1
π
ω
ω
. ■
Example 4.2.1 illustrates an effect called the beat phenomenon. Two noninter-
acting oscillators with different frequencies will periodically go in and out of phase 
with each other. You may have heard this effect on a Sunday morning: sometimes 
the bells of two different churches will ring simultaneously, then slowly drift apart, 
and then eventually ring together again. If the oscillators interact (for example, if 
the two joggers try to stay together or the bell ringers can hear each other), then we 
can get more interesting effects, as we will see in Section 4.5 on the flashing rhythm 
of fireflies.
4.3 Nonuniform Oscillator
The equation
θ
ω
θ
=
−asin
 
(1)
arises in many different branches of science and engineering. Here is a partial list:
Electronics (phase-locked loops)
Biology (oscillating neurons, firefly flashing rhythm, human sleep-wake 
cycle) 
Condensed-matter physics (Josephson junction, charge-density waves) 
Mechanics (Overdamped pendulum driven by a constant torque)
Some of these applications will be discussed later in this chapter and in the 
exercises.
To analyze (1), we assume that X  0 and a p 0 for 
convenience; the results for negative X and a are sim-
ilar. A typical graph of f  ( R )  X  a sin R is shown 
in Figure 4.3.1. Note that X is the mean and a is the 
amplitude.
Vector Fields
If a  0, (1) reduces to the uniform oscillator. The 
parameter a introduces a nonuniformity in the flow 
around the circle: the flow is fastest at R  –Q  /  2 and 
slowest at R  Q  /  2 (Figure 4.3.2a). This nonuniformity 
becomes more pronounced as a increases. When a is 
slightly less than X, the oscillation is very jerky: the phase point R( t ) takes a long 
time to pass through a bottleneck near R  Q  /  2, after which it zips around the rest 
of the circle on a much faster time scale. When a  X, the system stops oscillating 
ω
θ
−π 2
θ
.
π 2
a
Figure 4.3.1

99
4.3 NONUNIFORM OSCILLATOR
altogether: a half-stable fixed point has been born in a saddle-node bifurcation at 
R  Q  /  2 (Figure 4.3.2b). Finally, when a X, the half-stable fixed point splits into a 
stable and unstable fixed point (Figure 4.3.2c). All trajectories are attracted to the 
stable fixed point as t l d.
θ
θ
π 2
slow passage
through here
(bottleneck)
(a) a <
=
ω
(b) a
ω
(c) a > ω
.
Figure 4.3.2
The same information can be shown by plotting the vector fields on the circle 
(Figure 4.3.3).
slow
fast
π
θ
2
=
(a) a <
=
ω
(b) a
ω
(c) a > ω
Figure 4.3.3
EXAMPLE 4.3.1:
Use linear stability analysis to classify the fixed points of (1) for a  X.
Solution: The fixed points R * satisfy
sin *
θ
ω

a ,                       cos *
(
)
θ
ω
= ±
−
1
2
a
.
Their linear stability is determined by
′
= −
=
−
f
a
a
a
( *)
cos *
(
) .
θ
θ
ω
B
1
2

100 
FLOWS ON THE CIRCLE
Thus the fixed point with cos R*  0 is the stable one, since 
′
f ( *)
θ
  0. This agrees 
with Figure 4.3.2c. ■
Oscillation Period
For a  X, the period of the oscillation can be found analytically, as follows: the 
time required for R to change by 2Q is given by
T
dt
dt
d d
d
a
=
=
=
−
∫
∫
∫
θ
θ
θ
ω
θ
π
π
0
2
0
2
sin
where we have used (1) to replace dt  /  dR. This integral can be evaluated by complex 
variable methods, or by the substitution u  tan .
R
2  (See Exercise 4.3.2 for details.) 
The result is
T
a
=
−
2
2
2
π
ω
.  
(2)
Figure 4.3.4 shows the graph of T as a function of a.
T
a
π
2
ω
ω
Figure 4.3.4
When a  0, Equation (2) reduces to T  2Q / X, the familiar result for a uniform 
oscillator. The period increases with a and diverges as a approaches X from below 
(we denote this limit by a l X– ).
We can estimate the order of the divergence by noting that
X
X
X
X
X
2
2
2
−
=
+
−
≈
−
a
a
a
a
as a l X–. Hence
T
a
≈
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟
−
π
ω
ω
2
1
, 
(3)

101
4.3 NONUNIFORM OSCILLATOR
which shows that T  blows up like ( ac  a )–1  /  2, where ac  X. Now let’s explain the 
origin of this square-root scaling law.
Ghosts and Bottlenecks
The square-root scaling law found above is a very general feature of systems that 
are close to a saddle-node bifurcation. Just after the fixed points collide, there is a 
saddle-node remnant or ghost that leads to slow passage through a bottleneck.
For example, consider θ
ω
θ
=
−asin
 for decreasing values of a, starting with 
a  X. As a decreases, the two fixed points approach each other, collide, and dis-
appear (this sequence was shown earlier in Figure 4.3.3, except now you have to 
read from right to left.) For a slightly less than X, the fixed points near Q / 2 no lon-
ger exist, but they still make themselves felt through a saddle-node ghost 
(Figure 4.3.5).
θ
θ
.
bottleneck
due to ghost
Figure 4.3.5
A graph of R( )t  would have the shape shown in Figure 4.3.6. Notice how the 
trajectory spends practically all its time getting through the bottleneck.
θ
T
t
bottleneck
Figure 4.3.6
Now we want to derive a general scaling law for the time required to pass 
through a bottleneck. The only thing that matters is the behavior of R  in the 
immediate vicinity of the minimum, since the time spent there dominates all other 
time scales in the problem. Generically, R  looks parabolic near its minimum. Then 
the problem simplifies tremendously: the dynamics can be reduced to the normal 

102 
FLOWS ON THE CIRCLE
form for a saddle-node bifurcation! By a local rescaling of space, we can rewrite 
the vector field as
x
r
x
= +
2
where r is proportional to the distance from the bifurcation, and 0  r  1. The 
graph of x  is shown in Figure 4.3.7.
x
x
0
.
Figure 4.3.7
To estimate the time spent in the bottleneck, we calculate the time taken for x to 
go from d (all the way on one side of the bottleneck) to d (all the way on the 
other side). The result is
T
dx
r
x
r
bottleneck ≈
+
=
−∞
∞
∫
2
Q , 
(4)
which shows the generality of the square-root scaling law. (Exercise 4.3.1 reminds 
you how to evaluate the integral in (4).)
EXAMPLE 4.3.2:
Estimate the period of θ
ω
θ
=
−asin
in the limit a l X–, using the normal form 
method instead of the exact result.
Solution: The period will be essentially the time required to get through the 
bottleneck. To estimate this time, we use a Taylor expansion about R  Q / 2, where 
the bottleneck occurs. Let G  R – Q/2, where G is small. Then


φ
ω
φ
ω
φ
ω
φ
π
=
−
+
=
−
=
−+
+
a
a
a
a
sin(
)
cos
2
1
2
2
which is close to the desired normal form. If we let
x
a
r
a
=
=
−
(
)
,
2 1 2φ
ω
then(
)
2
1 2
2
a
x
r
x
 ≈+
, to leading order in x. Separating variables yields

103
4.4 OVERDAMPED PENDULUM
T
a
dx
r
x
a
r
≈
+
=
−∞
∞
∫
(
)
(
)
.
2
2
1 2
2
1 2 Q
Now we substitute r  X a . Furthermore, since a l X– , we may replace 2 / a by 
2 / X. Hence
T
a
≈
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟
−
π
ω
ω
2
1
,
which agrees with (3). ■
4.4 Overdamped Pendulum
We now consider a simple mechanical example of a nonuniform oscillator: an over-
damped pendulum driven by a constant torque. Let R denote the angle between the 
pendulum and the downward vertical, and suppose that R increases counterclock-
wise (Figure 4.4.1).
Γ
g
m
L
θ
Figure 4.4.1
Then Newton’s law yields
mL
b
mgL
2

R
R
R
+
+
=
sin
Γ  
(1)
where m is the mass and L is the length of the pendulum, b is a viscous damping 
constant, g is the acceleration due to gravity, and ( is a constant applied torque. 
All of these parameters are positive. In particular, (  0 implies that the applied 
torque drives the pendulum counterclockwise, as shown in Figure 4.4.1.
Equation (1) is a second-order system, but in the overdamped limit of extremely 
large b, it may be approximated by a first-order system (see Section  3.5 and 
Exercise 4.4.1). In this limit the inertia term mL2R  is negligible and so (1) becomes
b
mgL
R
R
+
=
sin
Γ . 
(2)

104 
FLOWS ON THE CIRCLE
To think about this problem physically, you should imagine that the pendulum 
is immersed in molasses. The torque ( enables the pendulum to plow through its 
viscous surroundings. Please realize that this is the opposite limit from the familiar 
frictionless case in which energy is conserved, and the pendulum swings back and 
forth forever. In the present case, energy is lost to damping and pumped in by the 
applied torque.
To analyze (2), we first nondimensionalize it. Dividing by mgL yields
b
mgL
mgL
R
R
=
−
Γ
sin .
Hence, if we let
τ = mgL
b
t
mgL
,
γ =
Γ
 
(3)
then
′ =
−
θ
γ
θ
sin
 
(4)
where ′ =
θ
θ
τ
d
d
. 
The dimensionless group H is the ratio of the applied torque to the maximum 
gravitational torque. If H  1 then the applied torque can never be balanced by the 
gravitational torque and the pendulum will overturn continually. The rotation rate 
is nonuniform, since gravity helps the applied torque on one side and opposes it on 
the other (Figure 4.4.2).
fast
slow
γ
θ
Figure 4.4.2
As H l 1+, the pendulum takes longer and longer to climb past R  Q / 2 on the 
slow side. When H  1 a fixed point appears at R *  Q / 2, and then splits into two 
when H  1 (Figure 4.4.3). On physical grounds, it’s clear that the lower of the two 
equilibrium positions is the stable one.

105
4.5 FIREFLIES
γ
Figure 4.4.3
As H decreases, the two fixed points move farther apart. Finally, when H  0, the 
applied torque vanishes and there is an unstable equilibrium at the top (inverted 
pendulum) and a stable equilibrium at the bottom.
4.5 Fireflies
Fireflies provide one of the most spectacular examples of synchronization in 
nature. In some parts of southeast Asia, thousands of male fireflies gather in trees 
at night and flash on and off in unison. Meanwhile the female fireflies cruise over-
head, looking for males with a handsome light.
To really appreciate this amazing display, you have to see a movie or videotape 
of it. A good example is shown in David Attenborough’s (1992) television series 
The Trials of Life, in the episode called “Talking to Strangers.” See Buck and Buck 
(1976) for a beautifully written introduction to synchronous fireflies, and Buck 
(1988) for a comprehensive review. For mathematical models of synchronous fire-
flies, see Mirollo and Strogatz (1990) and Ermentrout (1991).
How does the synchrony occur? Certainly the fireflies don’t start out synchro-
nized; they arrive in the trees at dusk, and the synchrony builds up gradually as 
the night goes on. The key is that the fireflies influence each other: When one firefly 
sees the flash of another, it slows down or speeds up so as to flash more nearly in 
phase on the next cycle.
Hanson (1978) studied this effect experimentally, by periodically flashing a light 
at a firefly and watching it try to synchronize. For a range of periods close to the 
firefly’s natural period (about 0.9 sec), the firefly was able to match its frequency to 
the periodic stimulus. In this case, one says that the firefly had been entrained by 
the stimulus. However, if the stimulus was too fast or too slow, the firefly could not 
keep up and entrainment was lost—then a kind of beat phenomenon occurred. 
But in contrast to the simple beat phenomenon of Section 4.2, the phase differ-
ence between stimulus and firefly did not increase uniformly. The phase difference 
increased slowly during part of the beat cycle, as the firefly struggled in vain to 
synchronize, and then it increased rapidly through 2Q, after which the firefly tried 
again on the next beat cycle. This process is called phase walkthrough or phase drift.

106 
FLOWS ON THE CIRCLE
Model
Ermentrout and Rinzel (1984) proposed a simple model of the firefly’s flashing 
rhythm and its response to stimuli. Suppose that R( )t  is the phase of the firefly’s 
flashing rhythm, where R  0 corresponds to the instant when a flash is emitted. 
Assume that in the absence of stimuli, the firefly goes through its cycle at a fre-
quency X, according to θ
ω

.
Now suppose there’s a periodic stimulus whose phase 2  satisfies
Θ
Ω
=
, 
(1)
where 2   0 corresponds to the flash of the stimulus. We model the firefly’s 
response to this stimulus as follows: If the stimulus is ahead in the cycle, then we 
assume that the firefly speeds up in an attempt to synchronize. Conversely, the 
firefly slows down if it’s flashing too early. A simple model that incorporates these 
assumptions is
θ
ω
θ
=
+
−
Asin(
)
Θ
 
(2)
where A  0. For example, if 2 is ahead of R (i.e., 0  2  R  Q ) the firefly speeds 
up (
).
θ
ω

 The resetting strength A measures the firefly’s ability to modify its 
instantaneous frequency.
Analysis
To see whether entrainment can occur, we look at the dynamics of the phase 
difference G  2  R. Subtracting (2) from (1) yields



φ
θ
ω
φ
=
−=
−
−
Θ
Ω
Asin
, 
(3)
which is a nonuniform oscillator equation for G  ( t ). Equation (3) can be nondimen-
sionalized by introducing
τ
μ
ω
=
=
−
At
A
,
.
Ω
 
(4)
Then
′ =
−
φ
μ
φ
sin
 
(5)
where ′ =
φ
φ
τ
d
d
/
. The dimensionless group N is a measure of the frequency dif-
ference, relative to the resetting strength. When N is small, the frequencies are rel-
atively close together and we expect that entrainment should be possible. This is 
confirmed by Figure 4.5.1, where we plot the vector fields for (5), for different val-
ues of N p 0. (The case N  0 is similar.)

107
4.5 FIREFLIES
φ′
φ
(a) μ
μ
μ
=0
(b)
(c)
0
1
1
<
>
<
Figure 4.5.1
When N  0, all trajectories flow toward a stable fixed point at G*  0 
(Figure 4.5.1a). Thus the firefly eventually entrains with zero phase difference in the 
case 8  X. In other words, the firefly and the stimulus flash simultaneously if the 
firefly is driven at its natural frequency.
Figure 4.5.1b shows that for 0  N  1, the curve in Figure 4.5.1a lifts up and 
the stable and unstable fixed points move closer together. All trajectories are 
still attracted to a stable fixed point, but now G*  0. Since the phase difference 
approaches a constant, one says that the firefly’s rhythm is phase-locked to the 
stimulus.
Phase-locking means that the firefly and the stimulus run with the same instan-
taneous frequency, although they no longer flash in unison. The result G*  0 
implies that the stimulus flashes ahead of the firefly in each cycle. This makes 
sense—we assumed N  0, which means that 8  X; the stimulus is inherently 
faster than the firefly, and drives it faster than it wants to go. Thus the firefly falls 
behind. But it never gets lapped—it always lags in phase by a constant amount G*.
If we continue to increase N, the stable and unstable fixed points eventually 
coalesce in a saddle-node bifurcation at N  1. For N  1 both fixed points have 
disappeared and now phase-locking is lost; the phase difference G increases indefi-
nitely, corresponding to phase drift (Figure 4.5.1c). (Of course, once G reaches 2Q the 
oscillators are in phase again.) Notice that the phases don’t separate at a uniform 
rate, in qualitative agreement with the experiments of Hanson (1978): G increases 
most slowly when it passes under the minimum of the sine wave in Figure 4.5.1c, at 
G  Q / 2, and most rapidly when it passes under the maximum at G  Q / 2.
The model makes a number of specific and testable predictions. Entrainment is 
predicted to be possible only within a symmetric interval of driving frequencies, 
specifically X – A b 8 b X  A. This interval is called the range of entrainment 
(Figure 4.5.2).

108 
FLOWS ON THE CIRCLE
range of
entrainment
A
A
0
Ω
ω
ω
ω
+
−
Figure 4.5.2
By measuring the range of entrainment experimentally, one can nail down the 
value of the parameter A. Then the model makes a rigid prediction for the phase 
difference during entrainment, namely
sin *
φ
ω
=
−
Ω
A
 
(6)
where Q / 2 b G* b Q / 2 corresponds to the stable fixed point of (3).
Moreover, for N  1, the period of phase drift may be predicted as follows. The 
time required for G to change by 2Q is given by
T
dt
dt
d
d
d
A
drift =
=
=
−
−
∫
∫
∫
φ
φ
φ
ω
φ
π
π
0
2
0
2
Ω
sin
.
To evaluate this integral, we invoke (2) of Section 4.3, which yields
T
A
drift =
−
−
2
2
2
π
ω
(
)
.
Ω
 
(7)
Since A and X are presumably fixed properties of the firefly, the predictions (6) and 
(7) could be tested simply by varying the drive frequency 8. Such experiments have 
yet to be done.
Actually, the biological reality about synchronous fireflies is more complicated. 
The model presented here is reasonable for certain species, such as Pteroptyx cri-
bellata, which behave as if A and X were fixed. However, the species that is best at 
synchronizing, Pteroptyx malaccae, is actually able to shift its frequency X toward 
the drive frequency 8 (Hanson 1978). In this way it is able to achieve nearly zero 
phase difference, even when driven at periods that differ from its natural period by 
o15 percent! A model of this remarkable effect has been presented by Ermentrout 
(1991).

109
4.6 SUPERCONDUCTING JOSEPHSON JUNCTIONS
4.6 Superconducting Josephson Junctions
Josephson junctions are superconducting devices that are capable of generating 
voltage oscillations of extraordinarily high frequency, typically 10 10  10 11 cycles 
per second. They have great technological promise as amplifiers, voltage stan-
dards, detectors, mixers, and fast switching devices for digital circuits. Josephson 
junctions can detect electric potentials as small as one quadrillionth of a volt, and 
they have been used to detect far-infrared radiation from distant galaxies. For an 
introduction to Josephson junctions, as well as superconductivity more generally, 
see Van Duzer and Turner (1981).
Although quantum mechanics is required to explain the origin of the Josephson 
effect, we can nevertheless describe the dynamics of Josephson junctions in classical 
terms. Josephson junctions have been particularly useful for experimental studies of 
nonlinear dynamics, because the equation governing a single junction is the same as 
that for a pendulum! In this section we will study the dynamics of a single junction 
in the overdamped limit. In later sections we will discuss underdamped junctions, as 
well as arrays of enormous numbers of junctions coupled together.
Physical Background
A Josephson junction consists of two closely spaced superconductors separated 
by a weak connection (Figure 4.6.1). This connection may be provided by an insu-
lator, a normal metal, a semiconductor, a weakened superconductor, or some 
other material that weakly couples the two superconductors. The two supercon-
ducting regions may be characterized by quantum mechanical wave functions 
ψ
φ
1
1
ei  
and 
ψ
φ
2
2
ei
respectively. 
Normally a much more compli-
cated description would be neces-
sary because there are ~10 23 
electrons to deal with, but in the 
superconducting ground state, 
these electrons form “Cooper 
pairs” that can be described by a 
single macroscopic wave function. 
This implies an astonishing degree 
of coherence among the electrons. The Cooper pairs act like a miniature version of 
synchronous fireflies: they all adopt the same phase, because this turns out to min-
imize the energy of the superconductor.
As a 22-year-old graduate student, Brian Josephson (1962) suggested that it 
should be possible for a current to pass between the two superconductors, even if 
there were no voltage difference between them. Although this behavior would be 
impossible classically, it could occur because of quantum mechanical tunneling of 
Cooper pairs across the junction. An observation of this “Josephson effect” was 
made by Anderson and Rowell in 1963.
ψ
ψ
φ
φ
1
superconductor #1
weak coupling
superconductor #2
2
1
2
e
e
i
i
Figure 4.6.1

110 
FLOWS ON THE CIRCLE
Incidentally, Josephson won the Nobel Prize in 1973, after which he lost interest 
in mainstream physics and was rarely heard from again. See Josephson (1982) for 
an interview in which he reminisces about his early work and discusses his more 
recent interests in transcendental meditation, consciousness, language, and even 
psychic spoon-bending and paranormal phenomena.
The Josephson Relations
We now give a more quantitative discussion of the Josephson effect. Suppose 
that a Josephson junction is connected to a dc current source (Figure 4.6.2), so that 
a constant current I  0 is driven through the 
junction. Using quantum mechanics, one can 
show that if this current is less than a certain 
critical current Ic  , no voltage will be devel-
oped across the junction; that is, the junction 
acts as if it had zero resistance! However, the 
phases of the two superconductors will be 
driven apart to a constant phase difference 
G  G2 – G1 , where G satisfies the Josephson current-phase relation
I  Ic  sinG. 
(1)
Equation (1) implies that the phase difference increases as the bias current I 
increases.
When I  exceeds Ic  , a constant phase difference can no longer be maintained 
and a voltage develops across the junction. The phases on the two sides of the 
junction begin to slip with respect to each other, with the rate of slippage governed 
by the Josephson voltage-phase relation
V
e
 ℏ
2 G. 
(2)
Here V ( t ) is the instantaneous voltage across the junction, =  is Planck’s constant 
divided by 2Q, and e is the charge on the electron. For an elementary derivation of 
the Josephson relations (1) and (2), see Feynman’s argument (Feynman et al. (1965), 
Vol. III), also reproduced in Van Duzer and Turner (1981).
Equivalent Circuit and Pendulum Analog
The relation (1) applies only to the supercurrent carried by the electron pairs. In 
general, the total current passing through the junction will also contain contribu-
tions from a displacement current and an ordinary current. Representing the dis-
placement current by a capacitor, and the ordinary current by a resistor, we arrive 
at the equivalent circuit shown in Figure 4.6.3, first analyzed by Stewart (1968) and 
McCumber (1968).
I
I sin
c
f
Figure 4.6.2

111
4.6 SUPERCONDUCTING JOSEPHSON JUNCTIONS
I
R
C
V
Figure 4.6.3
Now we apply Kirchhoff’s voltage and current laws. For this parallel circuit, the 
voltage drop across each branch must be equal, and hence all the voltages are 
equal to V, the voltage across the junction. Hence the current through the capaci-
tor equals CV  and the current through the resistor equals V / R. The sum of these 
currents and the supercurrent Ic sinG must equal the bias current I ; hence
CV
V
R
I
I
c
 +
+
=
sin
.
G
 
(3)
Equation (3) may be rewritten solely in terms of the phase difference G, thanks to 
(2). The result is
ℏ

ℏ

C
e
eR
I
I
c
2
2
G
G
G
+
+
=
sin
,  
(4)
which is precisely analogous to the equation governing a damped pendulum driven 
by a constant torque! In the notation of Section 4.4, the pendulum equation is
mL
b
mgL
2

R
R
R
+
+
=
sin
.
Γ
Hence the analogies are as follows:
Pendulum
Josephson junction
Angle R
Phase difference G
Angular velocity R
Voltage ℏ
2e G
Mass m
Capacitance C
Applied torque (  
Bias current I
Damping constant b
Conductance 1 / R
Maximum gravitational torque mgL 
Critical current Ic
This mechanical analog has often proved useful in visualizing the dynamics of 
Josephson junctions. Sullivan and Zimmerman (1971) actually constructed such a 
mechanical analog, and measured the average rotation rate of the pendulum as a 

112 
FLOWS ON THE CIRCLE
function of the applied torque; this is the analog of the physically important I  V 
curve (current–voltage curve) for the Josephson junction.
Typical Parameter Values
Before analyzing (4), we mention some typical parameter values for Josephson 
junctions. The critical current is typically in the range Ic x 1 NA – 1 mA, and a 
typical voltage is IcR x 1 mV.  Since 2e / h x 4.83 q 10 14 Hz / V, a typical frequency 
is on the order of 10 11 Hz. Finally, a typical length scale for Josephson junctions 
is around 1 Nm, but this depends on the geometry and the type of coupling used.
Dimensionless Formulation
If we divide (4) by Ic and define a dimensionless time
U  2eI R t
c
=
,  
(5)
we obtain the dimensionless equation
βφ
φ
φ
′′ + ′ +
=
sin
I
Ic
 
(6)
where ′ =
φ
φ
d
dτ. The dimensionless group C is defined by
C  2
2
eI R C
c
=
.
and is called the McCumber parameter. It may be thought of as a dimensionless 
capacitance. Depending on the size, the geometry, and the type of coupling used 
in the Josephson junction, the value of C can range from C x 10–6 to much larger 
values ( C x10 6 ).
We are not yet prepared to analyze (6) in general. For now, let’s restrict our-
selves to the overdamped limit C  1. Then the term βφaa may be neglected after 
a rapid initial transient, as discussed in Section 3.5, and so (6) reduces to a nonuni-
form oscillator:
′ =
−
G
G
I
Ic
sin . 
(7)
As we know from Section 4.3, the solutions of (7) tend to a stable fixed point when 
I  Ic  , and vary periodically when I  Ic  .

113
4.6 SUPERCONDUCTING JOSEPHSON JUNCTIONS
EXAMPLE 4.6.1:
Find the current–voltage curve analytically in the overdamped limit. In other 
words, find the average value of the voltage V § as a function of the constant 
applied current I, assuming that all transients have decayed and the system has 
reached steady-state operation. Then plot V § vs. I .
Solution: It is sufficient to find 〈
〉
G′ ,  since 〈〉=
〈〉
V
e
(
)
ℏ

2
G  from the voltage-phase 
relation (2), and

ℏ
φ
φ
τ
φ
τ
φ
=
=
=
′
d
dt
d
dt
d
d
eI R
c
2
,
from the definition of U in (5); hence
V
I R
c
=
′
G . 
(8)
There are two cases to consider. When I b Ic  , all solutions of (7) approach a fixed 
point G*  sin–1( I / Ic  ), where Q / 2 b G* b  Q / 2 . Thus ′ =
G
0  in steady state, and 
so 〈〉=
≤
V
I
Ic
0 for 
.
When I  Ic  , all solutions of (7) are periodic with period
T
I Ic
=
−
2
1
2
Q
(
)
, 
(9)
where the period is obtained from (2) of Section 4.3, and time is measured in units 
of U. We compute 〈′〉
G
 by taking the average over one cycle:
〈′〉=
=
∫
∫
φ
φ
τ
τ
φ
π
π
1
1
2
0
0
2
T
d
d
d
T
d
T
T
=
. 
(10)
Combining (8)–(10) yields
〈〉=
−
>
V
I R
I I
I
I
c
c
c
(
)
.
2
1
for 
In summary, we have found
for 
for 
I
I
V
I R
I I
I
I
c
c
c
c
≤
〈〉=
−
>
⎧
⎨
⎪⎪⎪
⎩⎪⎪⎪
0
1
2
(
)
.
 
(11)
The I–V curve (11) is shown in Figure 4.6.4.

114 
FLOWS ON THE CIRCLE
V/RI
3
2
1
0
0
1
2
3
I/I
V= IR
c
c
Figure 4.6.4
As I increases, the voltage remains zero until I  Ic  ; then V§ rises sharply and 
eventually asymptotes to the Ohmic behavior V§ x IR for I  Ic . ■
The analysis given in Example 4.6.1 applies only to the overdamped limit 
C  1. The behavior of the system becomes much more interesting if C is not 
negligible. In particular, the I–V curve can be hysteretic, as shown in Figure 4.6.5. 
As the bias current is increased slowly from I  0, the voltage remains at V  0 
until I  Ic. Then the voltage jumps up to a nonzero value, as shown by the upward 
arrow in Figure 4.6.5. The voltage increases with further increases of I. However, if 
we now slowly decrease I, the voltage doesn’t drop back to zero at Ic —we have to 
go below Ic before the voltage returns to zero.
V/RI
1
2
3
0
0
1
2
3
I/I
c
c
Figure 4.6.5
The hysteresis comes about because the system has inertia when C v 0. We can 
make sense of this by thinking in terms of the pendulum analog. The critical cur-
rent Ic is analogous to the critical torque (c needed to get the pendulum overturn-
ing. Once the pendulum has started whirling, its inertia keeps it going so that even 

115
EXERCISES
if the torque is lowered below (c  , the rotation continues. The torque has to be low-
ered even further before the pendulum will fail to make it over the top.
In more mathematical terms, we’ll show in Section  8.5 that this hysteresis 
occurs because a stable fixed point coexists with a stable periodic solution. We have 
never seen anything like this before! For vector fields on the line, only fixed points 
can exist; for vector fields on the circle, both fixed points and periodic solutions can 
exist, but not simultaneously. Here we see just one example of the new kinds of phe-
nomena that can occur in two-dimensional systems. It’s time to take the plunge.
EXERCISES FOR CHAPTER 4
4.1 Examples and Definitions
4.1.1 
For which real values of  a  does the equation R
R
 sin(
)
a
 give a 
well-defined vector field on the circle?
For each of the following vector fields, find and classify all the fixed points, and 
sketch the phase portrait on the circle.
4.1.2 
R
R
= +
1
2cos  
4.1.3  
R
R
 sin2
4.1.4  
R
R
 sin3
 
4.1.5  
R
R
R
=
+
sin
cos
4.1.6  
R
R
= +
3
2
cos
 
4.1.7  
R
R
 sink  where k is a positive integer.
4.1.8 
(Potentials for vector fields on the circle)
a) Consider the vector field on the circle given by R
R
 cos . Show that this system 
has a single-valued potential V ( R ), i.e., for each point on the circle, there is a 
well-defined value of V such that R
R
= −dV d .  (As usual, R and R  2Qk are to 
be regarded as the same point on the circle, for each integer k .)
b) Now consider R 1. Show that there is no single-valued potential V ( R ) for this 
vector field on the circle.
c) What’s the general rule? When does R
R
 f ( )  have a single-valued potential?
4.1.9 
In Exercises 2.6.2 and 2.7.7, you were asked to give two analytical proofs 
that periodic solutions are impossible for vector fields on the line. Review these 
arguments and explain why they don’t carry over to vector fields on the circle. 
Specifically which parts of the argument fail?
4.2 Uniform Oscillator
4.2.1 
(Church bells) The bells of two different churches are ringing. One bell 
rings every 3 seconds, and the other rings every 4 seconds. Assume that the bells 
have just rung at the same time. How long will it be until the next time they ring 
together? Answer the question in two ways: using common sense, and using the 
method of Example 4.2.1.

116 
FLOWS ON THE CIRCLE
4.2.2 
(Beats arising from linear superpositions) Graph x ( t )  sin 8t  sin 9t for 
–20  t  20. You should find that the amplitude of the oscillations is modulated—
it grows and decays periodically.
a) What is the period of the amplitude modulations?
b) Solve this problem analytically, using a trigonometric identity that converts 
sums of sines and cosines to products of sines and cosines.
(In the old days, this beat phenomenon was used to tune musical instru-
ments. You would strike a tuning fork at the same time as you played the desired 
note on the instrument. The combined sound A1 sin X1t A2 sin X2t would get 
louder and softer as the two vibrations went in and out of phase. Each maxi-
mum of total amplitude is called a beat. When the time between beats is long, 
the instrument is nearly in tune.)
4.2.3 
(The clock problem) Here’s an old chestnut from high school algebra: At 
12:00, the hour hand and minute hand of a clock are perfectly aligned. When is the 
next time they will be aligned? (Solve the problem by the methods of this section, 
and also by some alternative approach of your choosing.)
4.3 Nonuniform Oscillator
4.3.1 
As shown in the text, the time required to pass through a saddle-node 
bottleneck is approximately T
dx
r
x
bottleneck =
+
−∞
∞
∫
2 . To evaluate this integral, let 
x
r

tanR , use the identity 1  tan2 R  sec2 R, and change the limits of integra-
tion appropriately. Thereby show that T
r
bottleneck  Q
.
4.3.2 
The oscillation period for the nonuniform oscillator is given by the inte-
gral T
d
a
=
−
−∫
θ
ω
θ
π
π
sin ,  where X  a  0. Evaluate this integral as follows.
a) Let u  tan R
2  . Solve for R and then express dR in terms of u and du .
b) Show thatsin
(
)
R =
+
2
1
2
u
u
. (Hint: Draw a right triangle with base 1 and 
height u . Then R
2 is the angle opposite the side of length u, since u  tan R
2  by 
definition. Finally, invoke the half-angle formula sin
sin cos .
R
R
R
 2
2
2 )
c) Show that u l od as R l oQ, and use that fact to rewrite the limits of 
integration.
d) Express T as an integral with respect to u.
e) Finally, complete the square in the denominator of the integrand of (d), and 
reduce the integral to the one studied in Exercise 4.3.1, for a suitable choice of x 
and r.
For each of the following questions, draw the phase portrait as function of the 
control parameter N. Classify the bifurcations that occur as N varies, and find all 
the bifurcation values of N.

117
EXERCISES
4.3.3 
θ
μ
θ
θ
=
−
sin
sin2  
 
4.3.4  
θ
θ
μ
θ
=
+
sin
cos
4.3.5 
θ
μ
θ
θ
=
+
+
cos
cos2  
 
4.3.6  
θ
μ
θ
θ
=
+
+
sin
cos2
4.3.7 
θ
θ
μ
θ
=
+
sin
sin
 
 
 
4.3.8 
θ
θ
μ
θ
= +
sin
sin
2
1
4.3.9 
(Alternative derivation of scaling law) For systems close to a saddle-node 
bifurcation, the scaling law T
O r
bottleneck ~
(
)
1 2  can also be derived as follows.
a) Suppose that x has a characteristic scale O ra
(
), where a is unknown for now. 
Then x
r u
a

,  where u ~ O (1). Similarly, supposet
rb

U , with U ~ O (1). Show 
that x
r
x
= +
2  is thereby transformed to r
du
d
r
r u
a
b
a
−
= +
τ
2
2 .
b) Assume that all terms in the equation have the same order with respect to r, and 
thereby derive a  1
2 , b = −1
2 .
4.3.10 
(Nongeneric scaling laws) In deriving the square-root scaling law for the 
time spent passing through a bottleneck, we assumed that x had a quadratic 
minimum. This is the generic case, but what if the minimum were of higher 
order? Suppose that the bottleneck is governed by x
r
x n
= +
2 , where n  1 is an 
integer. Using the method of Exercise 4.3.9, show that T
crb
bottleneck x
, and deter-
mine b and c.
(It’s acceptable to leave c in the form of a definite integral. If you know complex 
variables and residue theory, you should be able to evaluate c exactly by integrat-
ing around the boundary of the pie-slice z
re
n
r
R
i
=
≤
≤
≤≤
{
}
θ
θ
π
:
,
0
0
 and 
letting R l d.)
4.4 Overdamped Pendulum
4.4.1 
(Validity of overdamped limit) Find the conditions under which it is valid 
to approximate the equation mL
b
mgL
2

R
R
R
+
+
=
sin
Γ  by its overdamped limit 
b
mgL
R
R
+
=
sin
Γ .
4.4.2 
(Understanding sin R ( t )) By imagining the rotational motion of an over-
damped pendulum, sketch sin R ( t ) vs. t for a typical solution of ′ =
R
R
γ −sin . 
How does the shape of the waveform depend on H? Make a series of graphs for 
different H, including the limiting cases H x 1 and H  1. For the pendulum, what 
physical quantity is proportional to sin R ( t ) ?
4.4.3 
(Understanding R( ))
t
 Redo Exercise 4.4.2, but now for R( )t  instead of 
sin ( )
R t .
4.4.4 
(Torsional spring) Suppose that our overdamped pendulum is con-
nected to a torsional spring. As the pendulum rotates, the spring winds up and 

118 
FLOWS ON THE CIRCLE
generates an opposing torque kR. Then the equation of motion becomes 
b
mgL
k
R
R
R
+
=
−
sin
Γ
.
a) Does this equation give a well-defined vector field on the circle?
b) Nondimensionalize the equation.
c) What does the pendulum do in the long run?
d) Show that many bifurcations occur as k is varied from 0 to d. What kind of 
bifurcations are they?
4.5 Fireflies
4.5.1 
(Triangle wave) In the firefly model, the sinusoidal form of the firefly’s 
response function was chosen somewhat arbitrarily. Consider the alternative 
model 

Θ
Ω
Θ
=
=
+
−
,
(
)
θ
ω
θ
Af
, where f is given now by a triangle wave, not a 
sine wave. Specifically, let
f ( )
,
,
φ
φ
φ
π
φ
φ
π
π
π
π
=
−
≤
≤
−
≤
≤
⎧
⎨
⎪⎪
⎩⎪⎪
2
2
2
3
2
on the interval −≤
≤
π
π
φ
2
3
2 , and extend f periodically outside this interval.
a) Graph f  ( G ).
b) Find the range of entrainment.
c) Assuming that the firefly is phase-locked to the stimulus, find a formula for the 
phase difference G *.
d) Find a formula for Tdrift.
4.5.2 
(General response function) Redo as much of the previous exercise as 
possible, assuming only that f  ( G ) is a smooth, 2Q-periodic function with a single 
maximum and minimum on the interval –Q b G b Q.
4.5.3 
(Excitable systems) Suppose you stimulate a neuron by injecting it with 
a pulse of current. If the stimulus is small, nothing dramatic happens: the neu-
ron increases its membrane potential slightly, and then relaxes back to its resting 
potential. However, if the stimulus exceeds a certain threshold, the neuron will 
“fire” and produce a large voltage spike before returning to rest. Surprisingly, the 
size of the spike doesn’t depend much on the size of the stimulus—anything above 
threshold will elicit essentially the same response.
Similar phenomena are found in other types of cells and even in some chemical 
reactions (Winfree 1980, Rinzel and Ermentrout 1989, Murray 2002). These sys-
tems are called excitable. The term is hard to define precisely, but roughly speak-
ing, an excitable system is characterized by two properties: (1) it has a unique, 
globally attracting rest state, and (2) a large enough stimulus can send the system 
on a long excursion through phase space before it returns to the resting state.

119
EXERCISES
This exercise deals with the simplest caricature of an excitable system. Let 
θ
μ
θ
=
+sin , where N is slightly less than 1.
a) Show that the system satisfies the two properties mentioned above. What object 
plays the role of the “rest state”? And the “threshold”?
b) Let V ( t )  cos R( t ). Sketch V ( t ) for various initial conditions. (Here V is analo-
gous to the neuron’s membrane potential, and the initial conditions correspond 
to different perturbations from the rest state.)
4.6 Superconducting Josephson Junctions
4.6.1 
(Current and voltage oscillations) Consider a Josephson junction in the 
overdamped limit C  0.
a) Sketch the supercurrent Ic sin G ( t ) as a function of t, assuming first that I / Ic is 
slightly greater than 1, and then assuming that I / Ic  1. (Hint: In each case, 
visualize the flow on the circle, as given by Equation (4.6.7).)
b) Sketch the instantaneous voltage V ( t ) for the two cases considered in (a).
4.6.2 
(Computer work) Check your qualitative solution to Exercise  4.6.1 by 
integrating Equation (4.6.7) numerically, and plotting the graphs of Ic sin G ( t ) and 
V ( t ).
4.6.3 
(Washboard potential) Here’s another way to visualize the dynamics of 
an overdamped Josephson junction. As in Section 2.7, imagine a particle sliding 
down a suitable potential.
a) Find the potential function corresponding to Equation (4.6.7). Show that it is 
not a single-valued function on the circle.
b) Graph the potential as a function of G, for various values of I / Ic . Here G is to be 
regarded as a real number, not an angle.
c) What is the effect of increasing I ?
The potential in (b) is often called the “washboard potential” (Van Duzer 
and Turner 1981, p. 179) because its shape is reminiscent of a tilted, corrugated 
washboard.
4.6.4 
(Resistively loaded array) Arrays of coupled Josephson junctions raise 
many fascinating questions. Their dynamics are not yet understood in detail. The 
questions are technologically important because arrays can produce much greater 
power output than a single junction, and also because arrays provide a reasonable 
model of the (still mysterious) high-temperature superconductors. For an intro-
duction to some of the dynamical questions of interest, see Tsang et al. (1991) and 
Strogatz and Mirollo (1993).
Figure 1 shows an array of two identical overdamped Josephson junctions. The 
junctions are in series with each other, and in parallel with a resistive “load” R.

120 
FLOWS ON THE CIRCLE
I
I
I
φ
φ
b
a
2
1
r
r
R
R
Figure 1
The goal of this exercise is to derive the governing equations for this circuit. In 
particular, we want to find differential equations for G1 and G2.
a) Write an equation relating the dc bias current Ib to the current Ia flowing through 
the array and the current IR flowing through the load resistor.
b) Let V1 and V2 denote the voltages across the first and second Josephson junc-
tions. Show that Ia  Ic sin G1  V1 / r and Ia  Ic sin G2  V2 / r.
c) Let k  1, 2 . Express Vk in terms of Gk.
d) Using the results above, along with Kirchhoff’s voltage law, show that 
I
I
er
eR
k
b
c
k
k
=
+
+
+
(
)
=
sin
,
.
G
G
G
G
ℏ

ℏ


2
2
1 2
1
2
for
 
e) The equations in part (d) can be written in more standard form as equations for 
Gk , as follows. Add the equations for k  1, 2, and use the result to eliminate the 
term 

G
G
1
2
+
(
).  Show that the resulting equations take the form 
G
G
G
k
k
j
j
a
K
=
+
+
=∑
Ω
sin
sin
,
1
2
 
and write down explicit expressions for the parameters 8, a, K.
4.6.5 
(N junctions, resistive load) Generalize Exercise 4.6.4 as follows. Instead 
of the two Josephson junctions in Figure 1, consider an array of N junctions in 
series. As before, assume the array is in parallel with a resistive load R, and that 
the junctions are identical, overdamped, and driven by a constant bias current Ib . 
Show that the governing equations can be written in dimensionless form as
d
d
a
k
N
k
k
N
j
j
N
φ
τ
φ
φ
=
+
+
=
=∑
Ω
sin
sin
,
,...,
,
1
1
1
 for 

121
EXERCISES
and write down explicit expressions for the dimensionless groups 8 and a and 
the dimensionless time U. (See Example 8.7.4 and Tsang et al. (1991) for further 
discussion.)
4.6.6 
(N junctions, RLC load) Generalize Exercise 4.6.4 to the case where there 
are N junctions in series, and where the load is a resistor R in series with a capac-
itor C and an inductor L. Write differential equations for Gk and for Q, where Q is 
the charge on the load capacitor. (See Strogatz and Mirollo 1993.)


 
Part II
TWO-DIMENSIONAL FLOWS


125
5.1 DEFINITIONS AND EXAMPLES
5
LINEAR SYSTEMS
5.0 Introduction
As we’ve seen, in one-dimensional phase spaces the flow is extremely confined—
all trajectories are forced to move monotonically or remain constant. In higher- 
dimensional phase spaces, trajectories have much more room to maneuver, and 
so a wider range of dynamical behavior becomes possible. Rather than attack all 
this complexity at once, we begin with the simplest class of higher-dimensional 
systems, namely linear systems in two dimensions. These systems are interesting 
in their own right, and, as we’ll see later, they also play an important role in the 
classification of fixed points of nonlinear systems. We begin with some definitions 
and examples.
5.1 Definitions and Examples
A two-dimensional linear system is a system of the form
x
ax
by
=
+
y
cx
dy
=
+
where a, b, c, d are parameters. If we use boldface to denote vectors, this system 
can be written more compactly in matrix form as
x
x
 A ,
where
A
a
b
c
d
x
y
=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
 and  = 
x
.

126 
LINEAR SYSTEMS
Such a system is linear in the sense that if x1 and x2 are solutions, then so is any 
linear combination c1x1  c2x2. Notice that x = 0  when x = 0 , so x* = 0  is always 
a fixed point for any choice of A.
The solutions of x =
x
A  can be visualized as trajectories moving on the ( x, y ) 
plane, in this context called the phase plane. Our first example presents the phase 
plane analysis of a familiar system.
EXAMPLE 5.1.1:
As discussed in elementary physics courses, the vibrations of a mass hanging from 
a linear spring are governed by the linear differential equation
mx
kx
+
= 0  
(1)
where m is the mass, k is the spring constant, and x is the displacement of the mass 
from equilibrium (Figure 5.1.1). Give a phase plane analysis of this simple harmonic 
oscillator.
Solution: As you probably recall, it’s easy to solve (1) ana-
lytically in terms of sines and cosines. But that’s precisely what 
makes linear equations so special! For the nonlinear equations 
of ultimate interest to us, it’s usually impossible to find an ana-
lytical solution. We want to develop methods for deducing the 
behavior of equations like (1) without actually solving them.
The motion in the phase plane is determined by a vector field 
that comes from the differential equation (1). To find this vector 
field, we note that the state of the system is characterized by its 
current position x and velocity v; if we know the values of both 
x and v, then (1) uniquely determines the future states of the 
system. Therefore we rewrite (1) in terms of x and v, as follows:
x
v

 
(2a)
v
x
k
m
= −
. 
(2b)
Equation (2a) is just the definition of velocity, and (2b) is the differential equation 
(1) rewritten in terms of v. To simplify the notation, let X 2  k / m. Then (2) becomes
x
v

 
(3a)
v
x
= −X2 .  
(3b)
The system (3) assigns a vector ( , )
( ,
)
 
x v
v
x
=
−X2
 at each point (x, v ), and therefore 
represents a vector field on the phase plane.
x
k
m
Figure 5.1.1

127
5.1 DEFINITIONS AND EXAMPLES
For example, let’s see what the vector field looks like when we’re on the x-axis. 
Then v  0 and so  
x v
x
,
( ,
).
(
)=
−
0
2
X
 Hence the vectors point vertically down-
ward for positive x and vertically upward for negative x (Figure 5.1.2). As x gets 
larger in magnitude, the vectors (0, X2x ) get longer. Similarly, on the v-axis, 
the vector field is  
x v
v
,
,
,
(
)=(
)
0
 which points to the right when v  0 and to the left 
when v  0. As we move around in phase space, the vectors change direction as 
shown in Figure 5.1.2.
Just as in Chapter 2, it is helpful to 
visualize the vector field in terms of the 
motion of an imaginary fluid. In the 
present case, we imagine that a fluid is 
flowing steadily on the phase plane 
with 
a 
local 
velocity 
given 
by 
( , )
( ,
).
 
x v
v
x
=
−X2
 Then, to find the tra-
jectory starting at ( x0, v0 ), we place an 
imaginary particle or phase point at 
( x0,  v0 ) and watch how it is carried 
around by the flow.
The flow in Figure 5.1.2 swirls about 
the origin. The origin is special, like the 
eye of a hurricane: a phase point placed there would remain motionless, because 
( , )
( , )
 
x v  0 0  when ( x, v )  (0, 0); hence the origin is a fixed point. But a phase 
point starting anywhere else would circulate around the origin and eventually 
return to its starting point. Such trajectories form closed orbits, as shown in 
Figure 5.1.3. Figure 5.1.3 is called the phase portrait of the system—it shows the 
overall picture of trajectories in phase space.
What do fixed points and closed 
orbits have to do with the original prob-
lem of a mass on a spring? The answers 
are beautifully simple. The fixed point 
( x, v )  (0, 0) corresponds to static equi-
librium of the system: the mass is at rest at 
its equilibrium position and will remain 
there forever, since the spring is relaxed. 
The closed orbits have a more interest-
ing interpretation: they correspond to 
periodic motions, i.e., oscillations of the 
mass. To see this, just look at some points 
on a closed orbit (Figure 5.1.4). When the 
displacement x is most negative, the velocity v is zero; this corresponds to one 
extreme of the oscillation, where the spring is most compressed (Figure 5.1.4).
v
x
Figure 5.1.2
v
x
Figure 5.1.3

128 
LINEAR SYSTEMS
x = 0
(a)
(a)
(b)
(b)
(c)
v
x
(c)
(d)
(d)
Figure 5.1.4
In the next instant as the phase point flows along the orbit, it is carried to points 
where x has increased and v is now positive; the mass is being pushed back toward 
its equilibrium position. But by the time the mass has reached x  0, it has a large 
positive velocity (Figure 5.1.4b) and so it overshoots x  0. The mass eventually 
comes to rest at the other end of its swing, where x is most positive and v is zero 
again (Figure 5.1.4c). Then the mass gets pulled up again and eventually completes 
the cycle (Figure 5.1.4d).
The shape of the closed orbits also has an interesting physical interpretation. 
The orbits in Figures 5.1.3 and 5.1.4 are actually ellipses given by the equation 
X2x 2  v 2  C, where C p 0 is a constant. In Exercise 5.1.1, you are asked to derive 
this geometric result, and to show that it is equivalent to conservation of energy. ■
EXAMPLE 5.1.2:
Solve the linear system x
x
 A ,  where A
a
=
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
0
0
1 . Graph the phase portrait as 
a varies from d to d, showing the qualitatively different cases. 
Solution: The system is


x
y
a
x
y
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟=
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
0
0
1
.
Matrix multiplication yields

129
5.1 DEFINITIONS AND EXAMPLES
x
ax

y
y
= −
which shows that the two equations are uncoupled; there’s no x in the y-equation 
and vice versa. In this simple case, each equation may be solved separately. The 
solution is
x ( t )  x0e a t 
(1a)
y ( t )  y0e t. 
(1b)
The phase portraits for different values of a are shown in Figure 5.1.5. In each case, 
y ( t ) decays exponentially. When a  0, x ( t ) also decays exponentially and so all 
trajectories approach the origin as t l d. However, the direction of approach 
depends on the size of a compared to 1.
(a) a < −1
(b) a = −1
(c) =1 <a<0
(e) a>0
(d) a=0
Figure 5.1.5
In Figure 5.1.5a, we have a  1, which implies that x( t ) decays more rapidly 
than y ( t ). The trajectories approach the origin tangent to the slower direction 
(here, the y-direction). The intuitive explanation is that when a is very negative, the 
trajectory slams horizontally onto the y-axis, because the decay of x ( t ) is almost 
instantaneous. Then the trajectory dawdles along the y-axis toward the origin, and 
so the approach is tangent to the y-axis. On the other hand, if we look backwards 

130 
LINEAR SYSTEMS
along a trajectory ( t l d), then the trajectories all become parallel to the faster 
decaying direction (here, the x-direction). These conclusions are easily proved by 
looking at the slope dy dx
y x
/
/
 
  along the trajectories; see Exercise 5.1.2. In 
Figure 5.1.5a, the fixed point x*  0 is called a stable node.
Figure 5.1.5b shows the case a  1. Equation (1) shows that y ( t )  / x ( t )  y0 / x0 
constant, and so all trajectories are straight lines through the origin. This is a very 
special case—it occurs because the decay rates in the two directions are precisely 
equal. In this case, x* is called a symmetrical node or star.
When 1  a  0, we again have a node, but now the trajectories approach x* 
along the x-direction, which is the more slowly decaying direction for this range of 
a (Figure 5.1.5c).
Something dramatic happens when a  0 (Figure 5.1.5d). Now (1a) becomes 
x ( t ) w x0 and so there’s an entire line of fixed points along the x-axis. All trajecto-
ries approach these fixed points along vertical lines.
Finally when B  0 (Figure 5.1.5e), x* becomes unstable, due to the exponential 
growth in the x-direction. Most trajectories veer away from x* and head out to 
infinity. An exception occurs if the trajectory starts on the y-axis; then it walks 
a tightrope to the origin. In forward time, the trajectories are asymptotic to the 
x-axis; in backward time, to the y-axis. Here x*  0 is called a saddle point. The 
y-axis is called the stable manifold of the saddle point x*, defined as the set of initial 
conditions x0 such that x( t ) l x* as t l d. Likewise, the unstable manifold of x* 
is the set of initial conditions such that x( t ) l x* as t l d. Here the unstable 
manifold is the x-axis. Note that a typical trajectory asymptotically approaches 
the unstable manifold as t ld, and approaches the stable manifold as t l d. 
This sounds backwards, but it’s right! ■
Stability Language
It’s useful to introduce some language that allows us to discuss the stability of 
different types of fixed points. This language will be especially useful when we 
analyze fixed points of nonlinear systems. For now we’ll be informal; precise defi-
nitions of the different types of stability will be given in Exercise 5.1.10.
We say that x*  0 is an attracting fixed point in Figures 5.1.5a–c; all trajectories 
that start near x* approach it as t l d. That is, x( t ) l x* as t l d. In fact x* 
attracts all trajectories in the phase plane, so it could be called globally attracting.
There’s a completely different notion of stability which relates to the behav-
ior of trajectories for all time, not just as t l d. We say that a fixed point x* is 
Liapunov stable if all trajectories that start sufficiently close to x* remain close to it 
for all time. In Figures 5.1.5a–d, the origin is Liapunov stable.
Figure 5.1.5d shows that a fixed point can be Liapunov stable but not attracting. 
This situation comes up often enough that there is a special name for it. When a 
fixed point is Liapunov stable but not attracting, it is called neutrally stable. Nearby 
trajectories are neither attracted to nor repelled from a neutrally stable point. As a 
second example, the equilibrium point of the simple harmonic oscillator 

131
5.2 CLASSIFICATION OF LINEAR SYSTEMS
(Figure 5.1.3) is neutrally stable. Neutral stability is commonly encountered in 
mechanical systems in the absence of friction. Conversely, it’s possible for a fixed 
point to be attracting but not Liapunov stable; thus, neither notion of stability 
implies the other. An example is given by the following vector field on the circle: 
R
R
= −
1
cos
 (Figure 5.1.6). Here R*  0 attracts all trajectories as t l d, but it is 
not Liapunov stable; there are trajectories that start infini-
tesimally close to R* but go on a very large excursion before 
returning to R*.
However, in practice the two types of stability often 
occur together. If a fixed point is both Liapunov stable and 
attracting, we’ll call it stable, or sometimes asymptotically 
stable.
Finally, x* is unstable in Figure 5.1.5e, because it is nei-
ther attracting nor Liapunov stable. 
A graphical convention: we’ll use open dots to denote unstable fixed points, and 
solid black dots to denote Liapunov stable fixed points. This convention is consis-
tent with that used in previous chapters.
5.2 Classification of Linear Systems
The examples in the last section had the special feature that two of the entries in 
the matrix A were zero. Now we want to study the general case of an arbitrary 
2 q 2 matrix, with the aim of classifying all the possible phase portraits that can 
occur.
Example 5.1.2 provides a clue about how to proceed. Recall that the x and y 
axes played a crucial geometric role. They determined the direction of the trajecto-
ries as t l od. They also contained special straight-line trajectories: a trajectory 
starting on one of the coordinate axes stayed on that axis forever, and exhibited 
simple exponential growth or decay along it.
For the general case, we would like to find the analog of these straight-line tra-
jectories. That is, we seek trajectories of the form
x( t )  e Mt v  , 
(2)
where v v 0 is some fixed vector to be determined, and M is a growth rate, also to be 
determined. If such solutions exist, they correspond to exponential motion along 
the line spanned by the vector v.
To find the conditions on v and M, we substitute x( t )  eMtv into x =
x
A , and 
obtain MeMt v  eMtA v. Canceling the nonzero scalar factor eMt yields
A v  Mv  , 
(3)
Figure 5.1.6

132 
LINEAR SYSTEMS
which says that the desired straight line solutions exist if v is an eigenvector of A with 
corresponding eigenvalue M. In this case we call the solution (2) an eigensolution.
Let’s recall how to find eigenvalues and eigenvectors. (If your memory needs 
more refreshing, see any text on linear algebra.) In general, the eigenvalues of a 
matrix A are given by the characteristic equation det( A  MI )  0, where I is the 
identity matrix. For a 2 q 2 matrix
A
a
b
c
d
=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟,
the characteristic equation becomes
det
.
a
b
c
d
−
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟=
M
M
0
Expanding the determinant yields
M2  UM  %  0 
(4)
where
U  trace( A )  a  d,
%  det( A )  ad  bc.
Then
λ
τ
τ
1
2
4
2
=
+
−Δ , λ
τ
τ
2
2
4
2
=
−
−Δ  
(5)
are the solutions of the quadratic equation (4). In other words, the eigenvalues 
depend only on the trace and determinant of the matrix A.
The typical situation is for the eigenvalues to be distinct: M1 v M2. In this case, a 
theorem of linear algebra states that the corresponding eigenvectors v1 and v2 are 
linearly independent, and hence span the entire 
plane (Figure  5.2.1). In particular, any initial 
condition x0 can be written as a linear combi-
nation of eigenvectors, say x0  c1v1  c2v2. This 
observation allows us to write down the general 
solution for x( t )—it is simply
x( )
.
t
c e
c e
t
t
=
+
1
1
2
2
1
2
M
M
v
v  
(6)
Why is this the general solution? First of all, it is 
a linear combination of solutions to x
x
 A ,  
c2 2
v
c1 1
v
x0
1 1
2 2
v
=c v +c
Figure 5.2.1

133
5.2 CLASSIFICATION OF LINEAR SYSTEMS
and hence is itself a solution. Second, it satisfies the initial condition x(0)  x0, and 
so by the existence and uniqueness theorem, it is the only solution. (See Section 6.2 
for a general statement of the existence and uniqueness theorem.)
EXAMPLE 5.2.1:
Solve the initial value problem x
x
y
=
+ ,  y
x
y
=
−
4
2 , subject to the initial con-
dition ( x0 , y0 )  (2, 3).
Solution: The corresponding matrix equation is


x
y
x
y
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟=
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
1
1
4
2
.
First we find the eigenvalues of the matrix A. The matrix has U  1 and %  6, 
so the characteristic equation is M2  M  6  0. Hence
M1  2, M2  3.
Next we find the eigenvectors. Given an eigenvalue M, the corresponding eigen-
vector v  ( v1  , v2 ) satisfies
1
1
4
2
0
0
1
2
−
−−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
M
M
v
v
.
For M1  2, this yield −
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
1
1
4
4
0
0
1
2
v
v
,  which has a nontrivial solution 
( v1, v2 )  (1, 1), or any scalar multiple thereof. (Of course, any multiple of an eigen-
vector is always an eigenvector; we try to pick the simplest multiple, but any one 
will do.) Similarly, for M2  3, the eigenvector equation becomes 4
1
4
1
0
0
1
2
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
v
v
,  
which has a nontrivial solution ( v1  , v2 )  (1, 4). In summary,
v
v
1
2
1
1
1
4
=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
= −
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
,
.
Next we write the general solution as a linear combination of eigensolutions. 
From (6), the general solution is
x( )
.
t
c
e
c
e
t
t
=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
+
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
−
1
2
2
3
1
1
1
4
 
(7)
Finally, we compute c1 and c2 to satisfy the initial condition ( x0, y0 )  (2, 3). At 
t  0, (7) becomes

134 
LINEAR SYSTEMS
2
3
1
1
1
4
1
2
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟+
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
c
c
,
which is equivalent to the algebraic system
   2  c1  c2   ,
3  c1  4c2   .
The solution is c1  1, c2  1. Substituting back into (7) yields
x ( t )  e2t e 3t   ,
y ( t )  e2t  4e 3t
for the solution to the initial value problem. ■
Whew! Fortunately we don’t need to go through all this to draw the phase por-
trait of a linear system. All we need to know are the eigenvectors and eigenvalues.
EXAMPLE 5.2.2:
Draw the phase portrait for the system of Example 5.2.1.
Solution: The system has eigenvalues M1  2, M2  3. Hence the first eigenso-
lution grows exponentially, and the second eigensolution decays. This means the 
origin is a saddle point. Its stable manifold is the line spanned by the eigenvector 
v2  (1, 4), corresponding to the decaying eigensolution. Similarly, the unstable 
manifold is the line spanned by v1  (1, 1). As with all saddle points, a typical tra-
jectory approaches the unstable manifold as t l d, and the stable manifold as 
t l d. Figure 5.2.2 shows the phase portrait. ■
y
x
Figure 5.2.2

135
5.2 CLASSIFICATION OF LINEAR SYSTEMS
EXAMPLE 5.2.3:
Sketch a typical phase portrait for the case M2  M  0.
Solution: First suppose M2  M1  0. Then both eigensolutions decay exponen-
tially. The fixed point is a stable node, as in Figures 5.1.5a and 5.1.5c, except now 
the eigenvectors are not mutually per-
pendicular, in general. Trajectories 
typically approach the origin tangent 
to the slow eigendirection, defined as 
the direction spanned by the eigen-
vector with the smaller |M|. In back-
wards time ( t l d), the trajectories 
become parallel to the fast eigendi-
rection. Figure 5.2.3 shows the phase 
portrait. (If we reverse all the arrows 
in Figure  5.2.3, we obtain a typical 
phase portrait for an unstable node.) ■
EXAMPLE 5.2.4:
What happens if the eigenvalues are complex numbers?
Solution: If the eigenvalues are complex, the fixed point is either a center 
(Figure 5.2.4a) or a spiral (Figure 5.2.4b). We’ve already seen an example of a 
center in the simple harmonic 
oscillator of Section 5.1; the ori-
gin is surrounded by a family of 
closed orbits. Note that centers 
are neutrally stable, since nearby 
trajectories are neither attracted 
to nor repelled from the fixed 
point. A spiral would occur if 
the harmonic oscillator were 
lightly damped. Then the tra-
jectory would just fail to close, 
because the oscillator loses a bit of energy on each cycle.
To justify these statements, recall that the eigenvalues are
λ
τ
τ
1 2
1
2
2
4
,
.
=
±
−
(
)
Δ
 Thus complex eigenvalues occur when
U2  4%  0   .
y
x
slow eigendirection
fast eigendirection
Figure 5.2.3
(a)
(b)
center
spiral
Figure 5.2.4

136 
LINEAR SYSTEMS
To simplify the notation, let’s write the eigenvalues as
M1,2  Bo iX
where
B  U / 2, ω
τ
=
−
1
2
2
4Δ
.
By assumption, X v 0. Then the eigenvalues are distinct and so the general solution 
is still given by
x( )
.
t
c e
c e
t
t
=
+
1
1
2
2
1
2
M
M
v
v
But now the c’s and v’s are complex, since the M’s are. This means that x( t ) involves 
linear combinations of e ( BoiX ) t. By Euler’s formula, eiXt  cos Xt  i sin Xt. Hence 
x( t ) is a combination of terms involving eBt cos Xt and eBt sin Xt. Such terms repre-
sent exponentially decaying oscillations if B  Re( M )  0 and growing oscillations if 
B  0. The corresponding fixed points are stable and unstable spirals, respectively. 
Figure 5.2.4b shows the stable case.
If the eigenvalues are pure imaginary (B  0), then all the solutions are periodic 
with period T  2QX. The oscillations have fixed amplitude and the fixed point 
is a center.
For both centers and spirals, it’s easy to determine whether the rotation is clock-
wise or counterclockwise; just compute a few vectors in the vector field and the 
sense of rotation should be obvious. ■
EXAMPLE 5.2.5:
In our analysis of the general case, we have been assuming that the eigenvalues are 
distinct. What happens if the eigenvalues are equal ?
Solution: Suppose M1  M2  M. There are two possibilities: either there are two 
independent eigenvectors corresponding to M, or there’s only one.
If there are two independent eigenvectors, then they span the plane and so every 
vector is an eigenvector with this same eigenvalue M. To see this, write an arbitrary 
vector x0 as a linear combination of the two eigenvec-
tors: x0  c1v1  c2v2. Then
A x0 A ( c1v1  c2v2 )  c1Mv1  c2Mv2  Mx0
so x0 is also an eigenvector with eigenvalue M. Since 
multiplication by A simply stretches every vector by a 
factor M, the matrix must be a multiple of the identity:
A =
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
M
M
0
0
.
Figure 5.2.5

137
5.2 CLASSIFICATION OF LINEAR SYSTEMS
Then if M v 0, all trajectories are straight lines through the origin (x( t )  e Mt x0 ) 
and the fixed point is a star node (Figure 5.2.5). On the other hand, if M  0, the 
whole plane is filled with fixed points! (No surprise—the system is x  0. )
The other possibility is that there’s only one eigenvector (more accurately, the 
eigenspace corresponding to M is one-dimensional.) For example, any matrix of the 
form A
b
=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
M
M
0
, with b v 0 has only a one-dimensional eigenspace (Exercise 5.2.11).
When there’s only one eigendirection, the fixed point is a degenerate node. A 
typical phase portrait is shown in Figure 5.2.6. As t l d and also as t l d, 
all trajectories become parallel to the one available eigendirection.
eigendirection
Figure 5.2.6
A good way to think about the degenerate node is to imagine that it has been 
created by deforming an ordinary node. The ordinary node has two independent 
eigendirections; all trajectories are parallel to the slow eigendirection as t l d, 
and to the fast eigendirection as t l d (Figure 5.2.7a).
fast
slow
node
(a)
degenerate node
(b)
Figure 5.2.7
Now suppose we start changing the parameters of the system in such a way that the 
two eigendirections are scissored together. Then some of the trajectories will get 
squashed in the collapsing region between the two eigendirections, while the sur-
viving trajectories get pulled around to form the degenerate node (Figure 5.2.7b). 

138 
LINEAR SYSTEMS
Another way to get intuition about this case is to realize that the degenerate 
node is on the borderline between a spiral and a node. The trajectories are trying to 
wind around in a spiral, but they don’t quite make it. ■
Classification of Fixed Points
By now you’re probably tired of all the examples and ready for a simple classifi-
cation scheme. Happily, there is one. We can show the type and stability of all the 
different fixed points on a single diagram (Figure 5.2.8).
saddle points
unstable nodes
unstable spirals
2
4
0
−
=
stable spirals
stable nodes
centers
stars, degenerate nodes
non-isolated
fixed points
τ
τ
Δ
Δ
Figure 5.2.8
The axes are the trace U and the determinant % of the matrix A. All of the infor-
mation in the diagram is implied by the following formulas:
λ
τ
τ
1 2
1
2
2
4
,
,
=
±
−
(
)
Δ   %  M1M2   ,  U  M1  M2   .
The first equation is just (5). The second and third can be obtained by writing the 
characteristic equation in the form ( M  M1 )( M  M2 )  M2  UM  %  0.
To arrive at Figure 5.2.8, we make the following observations:
If %  0, the eigenvalues are real and have opposite signs; hence the fixed point 
is a saddle point.
If %  0, the eigenvalues are either real with the same sign (nodes), or com-
plex conjugate (spirals and centers). Nodes satisfy U2  4%  0 and spirals satisfy 
U2  4%  0. The parabola U2  4%  0 is the borderline between nodes and spi-
rals; star nodes and degenerate nodes live on this parabola. The stability of the 
nodes and spirals is determined by U. When U  0, both eigenvalues have nega-
tive real parts, so the fixed point is stable. Unstable spirals and nodes have U  0. 
Neutrally stable centers live on the borderline U  0, where the eigenvalues are 
purely imaginary.

139
5.3 LOVE AFFAIRS
If %  0, at least one of the eigenvalues is zero. Then the origin is not an isolated 
fixed point. There is either a whole line of fixed points, as in Figure 5.1.5d, or a 
plane of fixed points, if A  0.
Figure 5.2.8 shows that saddle points, nodes, and spirals are the major types of 
fixed points; they occur in large open regions of the ( %,U) plane. Centers, stars, 
degenerate nodes, and non-isolated fixed points are borderline cases that occur 
along curves in the ( %,U) plane. Of these borderline cases, centers are by far the 
most important. They occur very commonly in frictionless mechanical systems 
where energy is conserved.
EXAMPLE 5.2.6:
Classify the fixed point x*  0 for the system x
x
 A , where A =
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
1
2
3
4 .
Solution: The matrix has %  2; hence the fixed point is a saddle point. ■
EXAMPLE 5.2.7:
Redo Example 5.2.6 for A =
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
2
1
3
4 .
Solution: Now %  5 and U  6. Since %  0 and U2  4%  16  0, the fixed 
point is a node. It is unstable, since U  0. ■
5.3 Love Affairs
To arouse your interest in the classification of linear systems, we now discuss a 
simple model for the dynamics of love affairs (Strogatz 1988). The following story 
illustrates the idea.
Romeo is in love with Juliet, but in our version of this story, Juliet is a fickle 
lover. The more Romeo loves her, the more Juliet wants to run away and hide. But 
when Romeo gets discouraged and backs off, Juliet begins to find him strangely 
attractive. Romeo, on the other hand, tends to echo her: he warms up when she 
loves him, and grows cold when she hates him.
Let
R ( t )  Romeo’s love / hate for Juliet at time t 
J ( t )  Juliet’s love / hate for Romeo at time t.

140 
LINEAR SYSTEMS
Positive values of R, J signify love, negative values signify hate. Then a model for 
their star-crossed romance is
R
aJ

J
bR
= −
where the parameters a and b are positive, to be 
consistent with the story.
The sad outcome of their affair is, of course, a 
neverending cycle of love and hate; the governing 
system has a center at ( R, J )  (0, 0). At least they 
manage to achieve simultaneous love one-quarter 
of the time (Figure 5.3.1).
Now consider the forecast for lovers governed 
by the general linear system
R
aR
bJ
=
+
J
cR
dJ
=
+
where the parameters a, b, c, d may have either sign. A choice of signs specifies the 
romantic styles. As named by one of my students, the choice a  0, b  0 means 
that Romeo is an “eager beaver”—he gets excited by Juliet’s love for him, and 
is further spurred on by his own affectionate feelings for her. It’s entertaining to 
name the other three romantic styles, and to predict the outcomes for the var-
ious pairings. For example, can a “cautious lover” ( a  0, b  0) find true love 
with an eager beaver? These and other pressing questions will be considered in the 
exercises.
EXAMPLE 5.3.1:
What happens when two identically cautious lovers get together? 
Solution: The system is
R
aR
bJ
=
+
J
bR
aJ
=
+
with a  0, b  0. Here a is a measure of cautiousness (they each try to avoid 
throwing themselves at the other) and b is a measure of responsiveness (they both 
get excited by the other’s advances). We might suspect that the outcome depends 
on the relative size of a and b. Let’s see what happens. 
J
R
Figure 5.3.1

141
5.3 LOVE AFFAIRS
The corresponding matrix is
A
a
b
b
a
=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
which has
U  2a  0   ,  
%  a2  b2   ,  
U2  4%  4b2  0   .
Hence the fixed point ( R, J )  (0, 0) is a saddle point if a2  b2 and a stable node if 
a2  b2. The eigenvalues and corresponding eigenvectors are
M1  a  b   ,  
v1  (1, 1)   ,  
M2  a  b   ,  
v2  (l, l).
Since a  b  a  b, the eigenvector (1, 1) spans the unstable manifold when the 
origin is a saddle point, and it spans the slow eigendirection when the origin is a 
stable node. Figure 5.3.2 shows the phase portrait for the two cases.
J
J
R
b
b
>
a
a <
2
2
2
2
R
Figure 5.3.2
If a2  b2, the relationship always fizzles out to mutual indifference. The lesson 
seems to be that excessive caution can lead to apathy.
If a2  b2, the lovers are more daring, or perhaps more sensitive to each other. 
Now the relationship is explosive. Depending on their feelings initially, their rela-
tionship either becomes a love fest or a war. In either case, all trajectories approach 
the line R  J , so their feelings are eventually mutual. ■

142 
LINEAR SYSTEMS
EXERCISES FOR CHAPTER 5
5.1 Definitions and Examples
5.1.1 
(Ellipses and energy conservation for the harmonic oscillator) Consider 
the harmonic oscillator x
v
 ,  v
x
= −X2 .
a) Show that the orbits are given by ellipses X2x2  v2  C, where C is any 
non-negative constant. (Hint: Divide the x equation by the v  equation, sepa-
rate the v’s from the x’s, and integrate the resulting separable equation.)
b) Show that this condition is equivalent to conservation of energy.
5.1.2 
Consider the system x
ax

, y
y
= −, where a  1. Show that all trajec-
tories become parallel to the y-direction as t l d, and parallel to the x-direction 
as t l d. (Hint: Examine the slope dy dx
y x
/
/ .
 
 )
Write the following systems in matrix form.
5.1.3 


x
y y
x
= −
= −
, 
  
5.1.4 


x
x
y y
y
x
=
−
=
−
3
2
2
, 
5.1.5 


x
y
x
y
=
=
+
0, 
  
5.1.6 


x
x y
x
y
=
=
+
, 
5
Sketch the vector field for the following systems. Indicate the length and direction 
of the vectors with reasonable accuracy. Sketch some typical trajectories.
5.1.7 


x
x y
x
y
=
=
+
, 
 
 
 
5.1.8 


x
y y
x
= −
=
2 , 
5.1.9 
Consider the system 

x
y y
x
= −
= −
,
.
 
a) Sketch the vector field.
b) Show that the trajectories of the system are hyperbolas of the form x2  y2  C. 
(Hint: Show that the governing equations imply xx
yy


−
= 0  and then inte-
grate both sides.)
c) The origin is a saddle point; find equations for its stable and unstable manifolds. 
d) The system can be decoupled and solved as follows. Introduce new variables u 
and v, where u  x  y, v  x  y. Then rewrite the system in terms of u and v. 
Solve for u ( t ) and v ( t ), starting from an arbitrary initial condition ( u0 , v0 ).
e) What are the equations for the stable and unstable manifolds in terms of u 
and v?
f) Finally, using the answer to (d), write the general solution for x ( t ) and y ( t ), 
starting from an initial condition ( x0 , y0 ).
5.1.10 
(Attracting and Liapunov stable) Here are the official definitions of the 
various types of stability. Consider a fixed point x* of a system x
f
 ( ).
x
We say that x* is attracting if there is a E  0 such that lim
t→∞x
x*
( ) =
t
 whenever 
||x(0)  x*||  E. In other words, any trajectory that starts within a distance E of x* 
is guaranteed to converge to x* eventually. As shown schematically in Figure 1, 
trajectories that start nearby are allowed to stray from x* in the short run, but they 
must approach x* in the long run.

143
EXERCISES
In contrast, Liapunov stability requires that nearby trajectories remain close for 
all time. We say that x* is Liapunov stable if for each F  0, there is a E  0 such that 
||x( t )  x*||  F whenever t p 0 and ||x(0)  x*||  E. Thus, trajectories that start 
within E of x* remain within F of x* for all positive time (Figure 1):
radius
radius
Attracting
Liapunov stable
radius
(0)
(0)
x
x
x
x
*
*
=
=
=
δ
ε
δ
Figure 1
Finally, x* is asymptotically stable if it is both attracting and Liapunov stable.
For each of the following systems, decide whether the origin is attracting, 
Liapunov stable, asymptotically stable, or none of the above.
a) 


x
y y
x
=
= −
,
.
 
4
 
 
b) 


x
y y
x


2 , 
c) 


x
y
x


0, 
 
 
d) 


x
y
y
=
= −
0, 
e) 


x
x y
y
= −
= −
, 
5  
 
f)  


x
x y
y


, 
5.1.11 
(Stability proofs) Prove that your answers to 5.1.10 are correct, using the 
definitions of the different types of stability. (You must produce a suitable E to 
prove that the origin is attracting, or a suitable E( F) to prove Liapunov stability.)
5.1.12 
(Closed orbits from symmetry arguments) Give a simple proof that orbits 
are closed for the simple harmonic oscillator x
v

, v
x
= −, using only the sym-
metry properties of the vector field. (Hint: Consider a trajectory that starts on the 
v-axis at (0, v0 ), and suppose that the trajectory intersects the x-axis at ( x, 0). 
Then use symmetry arguments to find the subsequent intersections with the v-axis 
and x-axis.)
5.1.13 
Why do you think a “saddle point” is called by that name? What’s the 
connection to real saddles (the kind used on horses)?
5.2 Classification of Linear Systems
5.2.1 
Consider the system x
x
y
=
−
4
, y
x
y
=
+
2
.
a) Write the system as x
x
 A . Show that the characteristic polynomial is 
M2  5M  6, and find the eigenvalues and eigenvectors of A.

144 
LINEAR SYSTEMS
b) Find the general solution of the system.
c) Classify the fixed point at the origin.
d) Solve the system subject to the initial condition ( x0, y0 )  (3, 4).
5.2.2 
(Complex eigenvalues) This exercise leads you through the solution of a 
linear system where the eigenvalues are complex. The system is x
x
y
=
−,  
y
x
y
=
+ .
a) Find A and show that it has eigenvalues M1  1  i, M2  1  i  , with eigenvec-
tors v1  ( i , 1), v2  (i , 1) . (Note that the eigenvalues are complex conjugates, 
and so are the eigenvectors—this is always the case for real A with complex 
eigenvalues.)
b) The general solution is x( )
.
t
c e
c e
t
t
=
+
1
1
2
2
1
2
M
M
v
v  So in one sense we’re done! 
But this way of writing x( t ) involves complex coefficients and looks unfamiliar. 
Express x( t ) purely in terms of real-valued functions. (Hint: Use eiXt  cos Xt 
i sin Xt to rewrite x( t ) in terms of sines and cosines, and then separate the terms 
that have a prefactor of i from those that don’t.)
Plot the phase portrait and classify the fixed point of the following linear systems. 
If the eigenvectors are real, indicate them in your sketch.
5.2.3 


x
y y
x
y
=
= −
−
, 
2
3  
 
5.2.4  

x
x
y y
x
y
=
+
= −−
5
10 , 
5.2.5 


x
x
y y
x
y
=
−
=
−
3
4 , 
 
 
5.2.6  

x
x
y y
x
y
= −
+
=
−
3
2 , 
2
5.2.7 


x
x
y y
x
y
=
+
= −
−
5
2
17
5
, 
 
5.2.8  

x
x
y y
x
y
= −
+
= −
+
3
4 , 
2
3
5.2.9 


x
x
y y
x
y
=
−
=
−
4
3
8
6
, 
  
5.2.10 


x
y y
x
y
=
= −−
,
.
 
2
5.2.11 
Show that any matrix of the form A
b
=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
M
M
0
, with b v 0 has only a 
one-dimensional eigenspace corresponding to the eigenvalue M. Then solve the 
system x
x
 A
and sketch the phase portrait.
5.2.12 
(LRC circuit) Consider the circuit equation LI
RI
I C


+
+
=
/
,0  where L, 
C  0 and R p 0.
a) Rewrite the equation as a two-dimensional linear system.
b) Show that the origin is asymptotically stable if R  0 and neutrally stable if 
R  0.
c) Classify the fixed point at the origin, depending on whether R2C  4L is posi-
tive, negative, or zero, and sketch the phase portrait in all three cases.
5.2.13 
(Damped harmonic oscillator) The motion of a damped harmonic oscil-
lator is described by mx
bx
kx


+
+
= 0, where b  0 is the damping constant.
a) Rewrite the equation as a two-dimensional linear system.
b) Classify the fixed point at the origin and sketch the phase portrait. Be sure to 
show all the different cases that can occur, depending on the relative sizes of the 
parameters.

145
EXERCISES
c) How do your results relate to the standard notions of overdamped, critically 
damped, and underdamped vibrations?
5.2.14 
(A project about random systems) Suppose we pick a linear system at ran-
dom; what’s the probability that the origin will be, say, an unstable spiral? To be 
more specific, consider the system x
x
 A ,  where A
a
b
c
d
=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟. Suppose we pick 
the entries a,b,c,d independently and at random from a uniform distribution on 
the interval [ 1, 1]. Find the probabilities of all the different kinds of fixed points.
To check your answers (or if you hit an analytical roadblock), try the Monte 
Carlo method. Generate millions of random matrices on the computer and have 
the machine count the relative frequency of saddles, unstable spirals, etc.
Are the answers the same if you use a normal distribution instead of a uniform 
distribution?
5.3 Love Affairs
5.3.1 
(Name-calling) Suggest names for the four romantic styles, determined 
by the signs of a and b in R
aR
bJ
=
+
.
5.3.2 
Consider the affair described by 

R
J J
R
J
=
= −
+
,
.
 
a) Characterize the romantic styles of Romeo and Juliet.
b) Classify the fixed point at the origin. What does this imply for the affair?
c) Sketch R ( t ) and J ( t ) as functions of t, assuming R (0)  1, J (0)  0.
In each of the following problems, predict the course of the love affair, depending 
on the signs and relative sizes of a and b.
5.3.3 
(Out of touch with their own feelings) Suppose Romeo and Juliet react to 
each other, but not to themselves: 

R
aJ J
bR


,
.
 
 What happens?
5.3.4 
(Fire and water) Do opposites attract? Analyze 

R
aR
bJ J
bR
aJ
=
+
= −
−
,
.
 
5.3.5 
(Peas in a pod) If Romeo and Juliet are romantic clones 
(
,
),


R
aR
bJ J
bR
aJ
=
+
=
+
 
 should they expect boredom or bliss?
5.3.6 
(Romeo the robot) Nothing could ever change the way Romeo feels about 
Juliet: 

R
J
aR
bJ
=
=
+
0,
.
 
 Does Juliet end up loving him or hating him?

146 
PHASE PLANE
6
PHASE PLANE
6.0 
Introduction
This chapter begins our study of two-dimensional nonlinear systems. First we con-
sider some of their general properties. Then we classify the kinds of fixed points 
that can arise, building on our knowledge of linear systems (Chapter 5). The the-
ory is further developed through a series of examples from biology (competition 
between two species) and physics (conservative systems, reversible systems, and 
the pendulum). The chapter concludes with a discussion of index theory, a topo-
logical method that provides global information about the phase portrait.
This chapter is mainly about fixed points. The next two chapters will discuss 
closed orbits and bifurcations in two-dimensional systems.
6.1 Phase Portraits
The general form of a vector field on the phase plane is 
x
f x x
1
1
1
2

(
,
)
x
f
x x
2
2
1
2
  (
,
)
where f1 and f2 are given functions. This system can be written more compactly in 
vector notation as
x  f x
( )
where x  ( x1, x2 ) and f (x)  ( f1(x), f2 (x)). Here x represents a point in the phase 
plane, and x  is the velocity vector at that point. By flowing along the vector field, 

147
6.1 PHASE PORTRAITS
a phase point traces out a solution x( t ), corresponding 
to a trajectory winding through the phase plane 
(Figure 6.1.1). Furthermore, the entire phase plane is 
filled with trajectories, since each point can play the 
role of an initial condition.
For nonlinear systems, there’s typically no hope of 
finding the trajectories analytically. Even when explicit formulas are available, 
they are often too complicated to provide much insight. Instead we will try to 
determine the qualitative behavior of the solutions. Our goal is to find the system’s 
phase portrait directly from the properties of f (x). An enormous variety of phase 
portraits is possible; one example is shown in Figure 6.1.2.
A
C
B
D
Figure 6.1.2
Some of the most salient features of any phase portrait are:
1. The fixed points, like A, B, and C in Figure 6.1.2. Fixed points satisfy 
f (x* )  0, and correspond to steady states or equilibria of the system.
2. The closed orbits, like D in Figure 6.1.2. These correspond to periodic 
solutions, i.e., solutions for which x
x
(
)
( )
t
T
t
+
=
 for all t, for some 
T0.
3. The arrangement of trajectories near the fixed points and closed orbits. 
For example, the flow pattern near A and C is similar, and different 
from that near B.
4. The stability or instability of the fixed points and closed orbits. Here, 
the fixed points A, B, and C are unstable, because nearby trajectories 
tend to move away from them, whereas the closed orbit D is stable.
Numerical Computation of Phase Portraits
Sometimes we are also interested in quantitative aspects of the phase portrait. 
Fortunately, numerical integration of x
f
 ( )
x  is not much harder than that of 
x
f x

( ) . The numerical methods of Section 2.8 still work, as long as we replace 
X
X˙
(t)
Figure 6.1.1

148 
PHASE PLANE
the numbers x and f  ( x ) by the vectors x and f (x). We will always use the Runge-
Kutta method, which in vector form is
x
x
k
k
k
k
n
n
+ =
+
+
+
+
(
)
1
I
2
3
4
2
2
1
6
where
k
f x
k
f x
k
k
f x
k
k
f x
k
1
1
2
3
=
=
+
=
+
=
+
(
)
(
)
(
)
(
)
.
n
n
n
n
Δ
Δ
Δ
Δ
t
t
t
t
2
1
2
3
1
2
4
A stepsize %t  0.1 usually provides sufficient accuracy for our purposes.
When plotting the phase portrait, it often helps to see a grid of representative 
vectors in the vector field. Unfortunately, the arrowheads and different lengths of 
the vectors tend to clutter such pictures. A plot of the direction field is clearer: short 
line segments are used to indicate the local direction of flow.
EXAMPLE 6.1.1:
Consider the system x
x
e
y
=
+
−, y
y
= −. First use qualitative arguments to 
obtain information about the phase portrait. Then, using a computer, plot the 
direction field. Finally, use the Runge-Kutta method to compute several trajecto-
ries, and plot them on the phase plane.
Solution: First we find the fixed points by solving x  0 , y  0  simultaneously. 
The only solution is ( x*, y* )  (1, 0). To determine its stability, note that y ( t ) l 0 
as t l d, since the solution to y
y
= − is y ( t )  y0e t. Hence e y l 1 and so in the 
long run, the equation for x becomes x
x
≈
+1; this has exponentially growing 
solutions, which suggests that the fixed point is unstable. In fact, if we restrict our 
attention to initial conditions on the x-axis, then y0  0 and so y ( t )  0 for all time. 
Hence the flow on the x-axis is governed strictly by x
x
=
+1. Therefore the fixed 
point is unstable.
To sketch the phase portrait, it is helpful to plot the nullclines, defined as the 
curves where either x  0  or y  0 . The nullclines indicate where the flow is 
purely horizontal or vertical (Figure 6.1.3). For example, the flow is horizontal 
where y  0 , and since y
y
= −, this occurs on the line y  0. Along this line, the 
flow is to the right where x
x
=
+ >
1
0 , that is, where x  1.
Similarly, the flow is vertical where x
x
e
y
=
+
=
−
0, which occurs on the curve 
shown in Figure 6.1.3. On the upper part of the curve where y  0, the flow is down-
ward, since y  0.

149
6.2 EXISTENCE, UNIQUENESS, AND TOPOLOGICAL CONSEQUENCES
x
y
.
.
x
y
.
x
x
.
.
x
y
y
.
.
x
y
.
.
y.
0
<
<
<
>
>
<
>
>
=
=
0
0
0
0
0
0
0
0
0
Figure 6.1.3
The nullclines also partition the plane into regions where x  and y have various 
signs. Some of the typical vectors are sketched above in Figure 6.1.3. Even with the 
limited information obtained so far, Figure 6.1.3 gives a good sense of the overall 
flow pattern.
Now we use the computer to finish the problem. The direction field is indicated 
by the line segments in Figure 6.1.4, and several trajectories are shown. Note how 
the trajectories always follow the local slope.
y
x
Figure 6.1.4
The fixed point is now seen to be a nonlinear version of a saddle point. ■
6.2 Existence, Uniqueness, and Topological 
Consequences
We have been a bit optimistic so far—at this stage, we have no guarantee that the 
general nonlinear system x
f
 ( )
x  even has solutions! Fortunately the existence 
and uniqueness theorem given in Section 2.5 can be generalized to two-dimensional 

150 
PHASE PLANE
systems. We state the result for n-dimensional systems, since no extra effort is 
involved:
Existence and Uniqueness Theorem: Consider the initial value problem 
x
f
 ( )
x , x (0)  x0. Suppose that f is continuous and that all its partial derivatives 
sfi / sxj , i, j  1, . . . , n, are continuous for x in some open connected set D  Rn. 
Then for x0  D, the initial value problem has a solution x ( t ) on some time 
interval (U, U ) about t  0, and the solution is unique.
In other words, existence and uniqueness of solutions are guaranteed if f is contin-
uously differentiable. The proof of the theorem is similar to that for the case n  1, 
and can be found in most texts on differential equations. Stronger versions of the 
theorem are available, but this one suffices for most applications.
From now on, we’ll assume that all our vector fields are smooth enough to 
ensure the existence and uniqueness of solutions, starting from any point in phase 
space.
The existence and uniqueness theorem has an important corollary: different 
trajectories never intersect. If two trajectories did intersect, then there would be two 
solutions starting from the same point (the crossing point), and this would violate 
the uniqueness part of the theorem. In more intuitive language, a trajectory can’t 
move in two directions at once.
Because trajectories can’t intersect, phase por-
traits always have a well-groomed look to them. 
Otherwise they might degenerate into a snarl 
of criss-crossed curves (Figure  6.2.1). The exis-
tence and uniqueness theorem prevents this from 
happening.
In two-dimensional phase spaces (as opposed 
to higher-dimensional phase spaces), these results 
have especially strong topological consequences. For example, suppose there is a 
closed orbit C in the phase plane. Then any trajectory starting inside C is trapped 
in there forever (Figure 6.2.2).
What is the fate of such a bounded trajectory? If there are fixed points inside 
C, then of course the trajectory might eventually approach one of them. But what 
if there aren’t any fixed points? Your intuition may 
tell you that the trajectory can’t meander around 
forever—if so, you’re right. For vector fields on the 
plane, the Poincaré-Bendixson theorem states that if 
a trajectory is confined to a closed, bounded region 
and there are no fixed points in the region, then the 
trajectory must eventually approach a closed orbit. 
We’ll discuss this important theorem in Section 7.3.
Figure 6.2.1
C
Figure 6.2.2

151
6.3 FIXED POINTS AND LINEARIZATION
But that part of our story comes later. First we must become better acquainted 
with fixed points.
6.3 Fixed Points and Linearization
In this section we extend the linearization technique developed earlier for one- 
dimensional systems (Section 2.4). The hope is that we can approximate the phase 
portrait near a fixed point by that of a corresponding linear system.
Linearized System
Consider the system
x
f x y

( , )
y
g x y

( , )
and suppose that ( x*, y*) is a fixed point, i.e.,
f  ( x*, y*)  0, 
g( x*, y*)  0. 
Let
u  x  x *, 
v  y  y *
denote the components of a small disturbance from the fixed point. To see whether 
the disturbance grows or decays, we need to derive differential equations for u and 
v. Let’s do the u-equation first:


u
x

  
 
 
 
(since x * is a constant)
   =
+
+
f x
u y
v
( *
, *
)  
 
 
(by substitution)
   =
+
∂
∂+ ∂
∂+
f x
y
u
f
x
v f
y
O u v
uv
( *, *)
(
,
,
)
2
2
 (Taylor series expansion)
   =
∂
∂+ ∂
∂+
u
f
x
v f
y
O u v
uv
(
,
,
)
2
2
 
 
(since f  ( x*, y*) 0).
To simplify the notation, we have written sf / sx and sf / sy, but please remem-
ber that these partial derivatives are to be evaluated at the fixed point ( x*, y*); 
thus they are numbers, not functions. Also, the shorthand notation O ( u2, v2, uv ) 
denotes quadratic terms in u and v. Since u and v are small, these quadratic terms 
are extremely small.

152 
PHASE PLANE
Similarly we find
v
u
g
x
v g
y
O u v
uv
=
∂
∂+ ∂
∂+
(
,
,
).
2
2
Hence the disturbance ( u, v ) evolves according to


u
v
u
v
f
x
f
y
g
x
g
y
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟=
⎛
⎝
⎜⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟⎟
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
∂
∂
∂
∂
∂
∂
∂
∂
⎟⎟⎟⎟  quadratic terms. 
(1)
The matrix
A
f
x
f
y
g
x
g
y
x
y
=
⎛
⎝
⎜⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟⎟
∂
∂
∂
∂
∂
∂
∂
∂
( *, *)
is called the Jacobian matrix at the fixed point ( x*, y*). It is the multivariable ana-
log of the derivative f
x
′( *)  seen in Section 2.4.
Now since the quadratic terms in (1) are tiny, it’s tempting to neglect them alto-
gether. If we do that, we obtain the linearized system


u
v
u
v
f
x
f
y
g
x
g
y
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟=
⎛
⎝
⎜⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟⎟
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
∂
∂
∂
∂
∂
∂
∂
∂
⎟⎟⎟⎟ 
(2)
whose dynamics can be analyzed by the methods of Section 5.2.
The Effect of Small Nonlinear Terms
Is it really safe to neglect the quadratic terms in (1)? In other words, does the 
linearized system give a qualitatively correct picture of the phase portrait near 
( x*, y*) ? The answer is yes, as long as the fixed point for the linearized system is not 
one of the borderline cases discussed in Section 5.2. In other words, if the linearized 
system predicts a saddle, node, or a spiral, then the fixed point really is a saddle, 
node, or spiral for the original nonlinear system. See Andronov et al. (1973) for a 
proof of this result, and Example 6.3.1 for a concrete illustration.
The borderline cases (centers, degenerate nodes, stars, or non-isolated fixed 
points) are much more delicate. They can be altered by small nonlinear terms, as 
we’ll see in Example 6.3.2 and in Exercise 6.3.11.
EXAMPLE 6.3.1:
Find all the fixed points of the system x
x
x
= −+
3 , y
y
= −2
, and use lineariza-
tion to classify them. Then check your conclusions by deriving the phase portrait 
for the full nonlinear system.

153
6.3 FIXED POINTS AND LINEARIZATION
Solution: Fixed points occur where x  0  and y  0  simultaneously. Hence we 
need x  0 or x  o1, and y  0. Thus, there are three fixed points: (0, 0), (1, 0), and 
(1, 0). The Jacobian matrix at a general point ( x, y ) is
A
x
x
x
x
y
y
x
y
y
=
⎛
⎝
⎜⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟
= −+
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟
∂
∂
∂
∂
∂
∂
∂
∂




1
3
0
0
2
2
⎟.
Next we evaluate A at the fixed points. At (0, 0) , we find A = −
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
1
0
0
2 , so (0, 0) is 
a stable node. At (o1, 0), A =
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
2
0
0
2 , so both (1, 0) and (1, 0) are saddle points.
Now because stable nodes and saddle points are not borderline cases, we can 
be certain that the fixed points for the full nonlinear system have been predicted 
correctly.
This conclusion can be checked explicitly for the nonlinear system, since the x 
and y equations are uncoupled; the system is essentially two independent first-order 
systems at right angles to each other. In the y-direction, all trajectories decay expo-
nentially to y  0. In the x-direction, the trajectories are attracted to x  0 and 
repelled from x  o1. The vertical lines x  0 and x  o1 are invariant, because 
x  0  on them; hence any trajectory that starts on these lines stays on them for-
ever. Similarly, y  0 is an invariant horizontal line. As a final observation, we note 
that the phase portrait must be symmetric in both the x and y axes, since the equa-
tions are invariant under the transformations x l x and y l y. Putting all this 
information together, we arrive at the phase portrait shown in Figure 6.3.1.
y
x
Figure 6.3.1
This picture confirms that (0, 0) is a stable node, and (o1, 0) are saddles, as 
expected from the linearization. ■
The next example shows that small nonlinear terms can change a center into a 
spiral.

154 
PHASE PLANE
EXAMPLE 6.3.2:
Consider the system
x
y
ax x
y
= −+
+
(
)
2
2
y
x
ay x
y
=
+
+
 
(
)
2
2
where a is a parameter. Show that the linearized system incorrectly predicts that 
the origin is a center for all values of a, whereas in fact the origin is a stable spiral 
if a  0 and an unstable spiral if a  0.
Solution: To obtain the linearization about ( x*, y*)  (0, 0), we can either com-
pute the Jacobian matrix directly from the definition, or we can take the following 
shortcut. For any system with a fixed point at the origin, x and y represent devia-
tions from the fixed point, since u  x  x*  x and v  y  y*  y; hence we can 
linearize by simply omitting nonlinear terms in x and y . Thus the linearized sys-
tem is x
y
= −, y
x

. The Jacobian is
A =
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
0
1
1
0
which has U  0, %  1  0, so the origin is always a center, according to the 
linearization.
To analyze the nonlinear system, we change variables to polar coordinates. Let 
x  r cos R, y  r sin R. To derive a differential equation for r, we note x2  y2  r2, 
so xx
yy
rr



+
=
. Substituting for x  and y yields
rr
x
y
ax x
y
y x
ay x
y
a x
y
ar
 =
−+
+
(
) +
+
+
(
)
=
+
=
(
)
(
)
.
2
4
2
2
2
2
2
2
 
(
)
Hence r
ar

3.  In Exercise 6.3.12, you are asked to derive the following differential 
equation for R:



R =
−
xy
yx
r2
.
After substituting for x  and y we find R 1. Thus in polar coordinates the orig-
inal system becomes


r
ar


3
R
1.
 

155
6.3 FIXED POINTS AND LINEARIZATION
The system is easy to analyze in this form, because the radial and angular 
motions are independent. All trajectories rotate about the origin with constant 
angular velocity R 1.
The radial motion depends on a, as shown in Figure 6.3.2.
a < 0
a = 0
a > 0
Figure 6.3.2
If a  0, then r ( t ) l 0 monotonically as t l d. In this case, the origin is a 
stable spiral. (However, note that the decay is extremely slow, as suggested by the 
computer-generated trajectories shown in Figure 6.3.2.) If a  0, then r ( t )  r0  for 
all t and the origin is a center. Finally, if a  0 , then r ( t ) ld monotonically and 
the origin is an unstable spiral.
We can see now why centers are so delicate: all trajectories are required to close 
perfectly after one cycle. The slightest miss converts the center into a spiral. ■
Similarly, stars and degenerate nodes can be altered by small nonlinearities, 
but unlike centers, their stability doesn’t change. For example, a stable star may 
be changed into a stable spiral (Exercise 6.3.11) but not into an unstable spiral. 
This is plausible, given the classification of linear systems in Figure 5.2.8: stars and 
degenerate nodes live squarely in the stable or unstable region, whereas centers live 
on the razor’s edge between stability and instability.
If we’re only interested in stability, and not in the detailed geometry of the tra-
jectories, then we can classify fixed points more coarsely as follows:
Robust cases:
Repellers (also called sources): both eigenvalues have positive real part. 
Attractors (also called sinks): both eigenvalues have negative real part. 
Saddles: one eigenvalue is positive and one is negative.
Marginal cases:
Centers: both eigenvalues are pure imaginary.
Higher-order and non-isolated fixed points: at least one eigenvalue is 
zero.
Thus, from the point of view of stability, the marginal cases are those where at least 
one eigenvalue satisfies Re ( M )  0.

156 
PHASE PLANE
Hyperbolic Fixed Points, Topological Equivalence, and 
Structural Stability
If Re ( M ) v 0 for both eigenvalues, the fixed point is often called hyperbolic. (This 
is an unfortunate name—it sounds like it should mean “saddle point”—but it has 
become standard.) Hyperbolic fixed points are sturdy; their stability type is unaf-
fected by small nonlinear terms. Nonhyperbolic fixed points are the fragile ones.
We’ve already seen a simple instance of hyperbolicity in the context of vector 
fields on the line. In Section 2.4 we saw that the stability of a fixed point was 
accurately predicted by the linearization, as long as f
x
′( *)
.
v 0  This condition is 
the exact analog of Re ( M ) v 0.
These ideas also generalize neatly to higher-order systems. A fixed point of an 
nth-order system is hyperbolic if all the eigenvalues of the linearization lie off the 
imaginary axis, i.e., Re ( Mi ) v 0 for i  1, ...,  n. The important Hartman-Grobman 
theorem states that the local phase portrait near a hyperbolic fixed point is “topo-
logically equivalent” to the phase portrait of the linearization; in particular, the 
stability type of the fixed point is faithfully captured by the linearization. Here 
topologically equivalent means that there is a homeomorphism (a continuous defor-
mation with a continuous inverse) that maps one local phase portrait onto the 
other, such that trajectories map onto trajectories and the sense of time (the direc-
tion of the arrows) is preserved.
Intuitively, two phase portraits are topologically equivalent if one is a distorted ver-
sion of the other. Bending and warping are allowed, but not ripping, so closed orbits 
must remain closed, trajectories connecting saddle points must not be broken, etc.
Hyperbolic fixed points also illustrate the important general notion of struc-
tural stability. A phase portrait is structurally stable if its topology cannot be 
changed by an arbitrarily small perturbation to the vector field. For instance, the 
phase portrait of a saddle point is structurally stable, but that of a center is not: 
an arbitrarily small amount of damping converts the center to a spiral.
6.4 Rabbits versus Sheep
In the next few sections we’ll consider some simple examples of phase plane anal-
ysis. We begin with the classic Lotka-Volterra model of competition between two 
species, here imagined to be rabbits and sheep. Suppose that both species are 
competing for the same food supply (grass) and the amount available is limited. 
Furthermore, ignore all other complications, like predators, seasonal effects, and 
other sources of food. Then there are two main effects we should consider:
1. Each species would grow to its carrying capacity in the absence of the 
other. This can be modeled by assuming logistic growth for each spe-
cies (recall Section 2.3). Rabbits have a legendary ability to repro-
duce, so perhaps we should assign them a higher intrinsic growth rate.

157
6.4 RABBITS VERSUS SHEEP
2. When rabbits and sheep encounter each other, trouble starts. 
Sometimes the rabbit gets to eat, but more usually the sheep nudges the 
rabbit aside and starts nibbling (on the grass, that is). We’ll assume that 
these conflicts occur at a rate proportional to the size of each popula-
tion. (If there were twice as many sheep, the odds of a rabbit encoun-
tering a sheep would be twice as great.) Furthermore, we assume that 
the conflicts reduce the growth rate for each species, but the effect is 
more severe for the rabbits.
A specific model that incorporates these assumptions is


x
x
x
y
y
y
x
y
=
−−
=
−−
(
)
(
)
3
2
2
where
x ( t )  population of rabbits,
y ( t )  population of sheep
and x, y p 0. The coefficients have been chosen to reflect this scenario, but are 
otherwise arbitrary. In the exercises, you’ll be asked to study what happens if the 
coefficients are changed.
To find the fixed points for the system, we solve x  0  and y  0  simultane-
ously. Four fixed points are obtained: (0, 0), (0, 2), (3, 0), and (1, 1). To classify them, 
we compute the Jacobian:
A
x
y
x
y
x
y
x
x
x
y
y
x
y
y
=
⎛
⎝
⎜⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟
=
−
−
−
−
−−
⎛
⎝
⎜
∂
∂
∂
∂
∂
∂
∂
∂




3
2
2
2
2
2
⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟.
Now consider the four fixed points in turn:
( , ) :
.
0 0
3
0
0
2
Then A =
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
The eigenvalues are M  3, 2 so (0, 0) is an unstable node. Trajectories leave 
the origin parallel to the eigenvector for M  2, i.e. tangential 
to v  (0, 1), which spans the y-axis. (Recall the general rule: at 
a node, trajectories are tangential to the slow eigendirection, 
which is the eigendirection with the smallest |M|.) Thus, the phase 
portrait near (0, 0) looks like Figure 6.4.1.
( , ) :
.
0
1
0
2
2
2
Then A = −
−
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
y
x
Figure 6.4.1

158 
PHASE PLANE
This matrix has eigenvalues M  1, 2, as can be seen from 
inspection, since the matrix is triangular. Hence the fixed point 
is a stable node. Trajectories approach along the eigendirec-
tion associated with M  1; you can check that this direction 
is spanned by v  (l, 2). Figure 6.4.2 shows the phase portrait 
near the fixed point (0, 2).
(3, 0): Then A = −
−
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
3
6
0
1  and M 3, 1.
This is also a stable node. The trajectories approach along 
the slow eigendirection spanned by v  (3, 1), as shown in 
Figure 6.4.3.
(1, 1): Then A = −
−
−
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
1
2
1
1 , which has U  2, %  l, and 
M = −±
1
2.
Hence this is a saddle point. As you can check, the phase por-
trait near (1, 1) is as shown in Figure 6.4.4.
Combining Figures 6.4.1–6.4.4, we get Figure 6.4.5, which 
already conveys a good sense of the entire phase portrait. 
Furthermore, notice that the x and y axes contain straight-line 
trajectories, since x  0  when x  0, and y  0  when y  0.
Now we use common sense to fill in the rest 
of the phase portrait (Figure 6.4.6). For example, 
some of the trajectories starting near the origin 
must go to the stable node on the x-axis, while 
others must go to the stable node on the y-axis. 
In between, there must be a special trajectory that 
can’t decide which way to turn, and so it dives into 
the saddle point. This trajectory is part of the sta-
ble manifold of the saddle, drawn with a heavy line 
in Figure 6.4.6.
The other branch of the stable manifold con-
sists of a trajectory coming in “from infinity.” A 
computer-generated phase portrait (Figure 6.4.7) 
confirms our sketch.
y
x
Figure 6.4.2
y
x
Figure 6.4.3
y
x
Figure 6.4.4
y
x
Figure 6.4.5
y
x
stable
manifold
Figure 6.4.6

159
6.4 RABBITS VERSUS SHEEP
sheep
rabbits
2
1
1
2
3
Figure 6.4.7
The phase portrait has an interesting biological interpretation. It shows that 
one species generally drives the other to extinction. Trajectories starting below the 
stable manifold lead to eventual extinction of the sheep, while those starting above 
lead to eventual extinction of the rabbits. This dichotomy occurs in other mod-
els of competition and has led biologists to formulate the principle of competitive 
exclusion, which states that two species competing for the same limited resource 
typically cannot coexist. See Pianka (1981) for a biological discussion, and Pielou 
(1969), Edelstein-Keshet (1988), or Murray (2002) for additional references and 
analysis.
Our example also illustrates some general mathematical concepts. Given an 
attracting fixed point x*, we define its basin of attraction to be the set of initial 
conditions x0 such that x ( t ) l x* as t l d. For instance, the basin of attraction 
for the node at (3, 0) consists of all the points lying below the stable manifold of the 
saddle. This basin is shown as the shaded region in Figure 6.4.8.
sheep
rabbits
basin boundary =
basin for (3, 0)
stable manifold of saddle
3
2
1
1
2
Figure 6.4.8
Because the stable manifold separates the basins for the two nodes, it is called 
the basin boundary. For the same reason, the two trajectories that comprise the 

160 
PHASE PLANE
stable manifold are traditionally called separatrices. Basins and their boundaries 
are important because they partition the phase space into regions of different long-
term behavior.
6.5 Conservative Systems
Newton’s law F  ma is the source of many important second-order systems. For 
example, consider a particle of mass m moving along the x-axis, subject to a non-
linear force F ( x ). Then the equation of motion is
mx
F x
 =
( ).
Notice that we are assuming that F is independent of both x  and t; hence there is 
no damping or friction of any kind, and there is no time-dependent driving force.
Under these assumptions, we can show that energy is conserved, as follows. Let 
V ( x ) denote the potential energy, defined by F  ( x )  dV / dx. Then
mx
dV
dx
+
= 0. 
(1)
Now comes a trick worth remembering: multiply both sides by x  and notice that 
the left-hand side becomes an exact time-derivative!
mxx
dV
dx x
d
dt
mx
V x



+
=
⇒
+
⎡⎣⎢
⎤⎦⎥=
0
0
1
2
2
( )
where we’ve used the chain rule
d
dtV x t
dV
dx
dx
dt
( ( )) 
in reverse. Hence, for a given solution x ( t ), the total energy
E
mx
V x
=
+
1
2
2
( )
is constant as a function of time. The energy is often called a conserved quantity, 
a constant of motion, or a first integral. Systems for which a conserved quantity 
exists are called conservative systems.
Let’s be a bit more general and precise. Given a system x
f x
 ( ), a conserved 
quantity is a real-valued continuous function E(x) that is constant on trajectories, 
i.e. dE / dt  0. To avoid trivial examples, we also require that E (x) be nonconstant 
on every open set. Otherwise a constant function like E (x) w 0 would qualify as a 
conserved quantity for every system, and so every system would be conservative! 
Our caveat rules out this silliness.

161
6.5 CONSERVATIVE SYSTEMS
The first example points out a basic fact about conservative systems.
EXAMPLE 6.5.1:
Show that a conservative system cannot have any attracting fixed points.
Solution: Suppose x* were an attracting fixed point. Then all points in its basin 
of attraction would have to be at the same energy E (x*) (because energy is constant 
on trajectories and all trajectories in the basin flow to x*). Hence E (x) must be a con-
stant function for x in the basin. But this contradicts our definition of a conservative 
system, in which we required that E (x) be nonconstant on all open sets. ■
If attracting fixed points can’t occur, then what kind of fixed points can occur? 
One generally finds saddles and centers, as in the next example.
EXAMPLE 6.5.2:
Consider a particle of mass m  1 moving in a double-well potential 
V x
x
x
( ) = −
+
1
2
2
1
4
4 . Find and classify all the equilibrium points for the system. 
Then plot the phase portrait and interpret the results physically.
Solution: The force is dV / dx  x  x3, so the equation of motion is
x
x
x
=
−
3 .
This can be rewritten as the vector field
x
y

y
x
x
=
−
3
where y represents the particle’s velocity. Equilibrium points occur where 
 
x y
,
(
)  (0, 0). Hence the equilibria are ( x*, y*)  (0, 0) and (o1, 0). To classify 
these fixed points we compute the Jacobian:
A
x
=
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
0
1
1
3
0
2
.
At (0, 0), we have %  1, so the origin is a saddle point. But when ( x*, y*) 
(o1, 0), we find U  0 , %  2; hence these equilibria are predicted to be centers. 
At this point you should be hearing warning bells—in Section 6.3 we saw that 
small nonlinear terms can easily destroy a center predicted by the linear approxi-
mation. But that’s not the case here, because of energy conservation. The trajecto-
ries are closed curves defined by the contours of constant energy, i.e.,
E
y
x
x
=
−
+
=
1
2
2
1
2
2
1
4
4
constant.

162 
PHASE PLANE
Figure 6.5.1 shows the trajectories corresponding to different values of E. To 
decide which way the arrows point along the trajectories, we simply compute the 
vector ( , )
 
x y  at a few convenient locations. For example, x  0 and y 0 on the 
positive y-axis, so the motion is to the right. The orientation of neighboring trajec-
tories follows by continuity.
As expected, the system has a saddle point at (0, 0) and centers at (1, 0) and 
(1, 0). Each of the neutrally stable centers is surrounded by a family of small 
closed orbits. There are also large 
closed orbits that encircle all three 
fixed points.
Thus solutions of the system are 
typically periodic, except for the equi-
librium solutions and two very special 
trajectories: these are the trajectories 
that appear to start and end at the 
origin. More precisely, these trajecto-
ries approach the origin as t l od. 
Trajectories that start and end at the 
same fixed point are called homoclinic orbits. They are common in conservative 
systems, but are rare otherwise. Notice that a homoclinic orbit does not corre-
spond to a periodic solution, because the trajectory takes forever trying to reach 
the fixed point.
Finally, let’s connect the phase portrait to the motion of an undamped particle 
in a double-well potential (Figure 6.5.2).
The neutrally stable equilibria correspond to the 
particle at rest at the bottom of one of the wells, and 
the small closed orbits represent small oscillations 
about these equilibria. The large orbits represent 
more energetic oscillations that repeatedly take the 
particle back and forth over the hump. Do you see 
what the saddle point and the homoclinic orbits 
mean physically? ■
EXAMPLE 6.5.3:
Sketch the graph of the energy function E( x, y ) for Example 6.5.2.
Solution: The graph of E ( x, y ) is shown in Figure 6.5.3. The energy E is plotted 
above each point ( x, y ) of the phase plane. The resulting surface is often called the 
energy surface for the system.
Figure 6.5.2
y
x
Figure 6.5.1

163
6.5 CONSERVATIVE SYSTEMS
E
y
x
Figure 6.5.3
Figure 6.5.3 shows that the local minima of E project down to centers in the 
phase plane. Contours of slightly higher energy correspond to the small orbits 
surrounding the centers. The saddle point and its homoclinic orbits lie at even 
higher energy, and the large orbits that encircle all three fixed points are the most 
energetic of all.
It’s sometimes helpful to think of the flow as occurring on the energy surface 
itself, rather than in the phase plane. But notice—the trajectories must maintain a 
constant height E, so they would run around the surface, not down it. ■
Nonlinear Centers
Centers are ordinarily very delicate but, as the examples above suggest, they 
are much more robust when the system is conservative. We now present a theorem 
about nonlinear centers in second-order conservative systems.
The theorem says that centers occur at the local minima of the energy func-
tion. This is physically plausible—one expects neutrally stable equilibria and small 
oscillations to occur at the bottom of any potential well, no matter what its shape.
Theorem 6.5.1: (Nonlinear centers for conservative systems) Consider the 
system x
f x
 ( ) , where x  ( x, y )  R2, and f is continuously differentiable. 
Suppose there exists a conserved quantity E (x) and suppose that x* is an isolated 
fixed point (i.e., there are no other fixed points in a small neighborhood surround-
ing x*). If x* is a local minimum of E, then all trajectories sufficiently close to x* 
are closed.
Ideas behind the proof: Since E is constant on trajectories, each trajectory 
is contained in some contour of E. Near a local maximum or minimum, the con-
tours are closed. (We won’t prove this, but Figure 6.5.3 should make it seem obvi-
ous.) The only remaining question is whether the trajectory actually goes all the 
way around the contour or whether it stops at a fixed point on the contour. But 
because we’re assuming that x* is an isolated fixed point, there cannot be any fixed 

164 
PHASE PLANE
points on contours sufficiently close to x*. Hence all trajectories in a sufficiently 
small neighborhood of x* are closed orbits, and therefore x* is a center. ■
Two remarks about this result:
1. The theorem is valid for local maxima of E also. Just replace the 
function E  by E, and maxima get converted to minima; then 
Theorem 6.5.1 applies.
2. We need to assume that x* is isolated. Otherwise there are counterex-
amples due to fixed points on the energy contour—see Exercise 6.5.12.
Another theorem about nonlinear centers will be presented in the next section.
6.6 Reversible Systems
Many mechanical systems have time-reversal symmetry. This means that their 
dynamics look the same whether time runs forward or backward. For example, if 
you were watching a movie of an undamped pendulum swinging back and forth, 
you wouldn’t see any physical absurdities if the movie were run backward.
In fact, any mechanical system of the form mx
F x
 
( )  is symmetric under 
time reversal. If we make the change of variables t l t, the second derivative x
stays the same and so the equation is unchanged. Of course, the velocity x would 
be reversed. Let’s see what this means in the phase plane. The equivalent system is


x
y
y
F x
m

 1
( )
where y is the velocity. If we make the change of variables t l t and y l y, 
both equations stay the same. Hence if ( x ( t ), y ( t )) is a solution, then so is ( x ( t ), 
y ( t )). Therefore every trajectory has a twin: they differ only by time-reversal 
and a reflection in the x-axis (Figure 6.6.1).
y
x
Figure 6.6.1
The trajectory above the x-axis looks just like the one below the x-axis, except the 
arrows are reversed.

165
6.6 REVERSIBLE SYSTEMS
More generally, let’s define a reversible system to be any second-order system 
that is invariant under t l t and y l y. For example, any system of the form


x
f x y
y
g x y


( , )
( , ),
where f is odd in y and g is even in y (i.e., f  ( x, y )  f  ( x, y ) and g ( x , y )  g ( x, y )) 
is reversible.
Reversible systems are different from conservative systems, but they have many 
of the same properties. For instance, the next theorem shows that centers are 
robust in reversible systems as well.
Theorem 6.6.1: (Nonlinear centers for reversible systems) Suppose the ori-
gin x*  0 is a linear center for the continuously differentiable system


x
f x y
y
g x y


( , )
( , ),
and suppose that the system is reversible. Then sufficiently close to the origin, all 
trajectories are closed curves.
Ideas behind the proof: Consider a trajectory that 
starts on the positive x-axis near the origin (Figure 6.6.2). 
Sufficiently near the origin, the flow swirls around the 
origin, thanks to the dominant influence of the lin-
ear center, and so the trajectory eventually intersects 
the negative x-axis. (This is the step where our proof 
lacks rigor, but the claim should seem plausible.) Now 
we use reversibility. By reflecting the trajectory across 
the x-axis, and changing the sign of t, we obtain a twin 
trajectory with the same endpoints but with its arrow 
reversed (Figure 6.6.3).
Together the two trajectories form a closed orbit, as 
desired. Hence all trajectories sufficiently close to the 
origin are closed. ■
EXAMPLE 6.6.1:
Show that the system
 


x
y
y
y
x
y
=
−
= −−
3
2
y
x
Figure 6.6.2
y
x
Figure 6.6.3

166 
PHASE PLANE
has a nonlinear center at the origin, and plot the phase portrait.
Solution: We’ll show that the hypotheses of the theorem are satisfied. The 
Jacobian at the origin is
A = −
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
0
1
1
0 .
This has U  0, %  0, so the origin is a linear center. Furthermore, the system 
is reversible, since the equations are invariant under the transformation t l t, 
y l y. By Theorem 6.6.1, the origin is a nonlinear center.
The other fixed points of the system are (1, 1) and (1, 1). They are saddle 
points, as is easily checked by computing the linearization. A computer-generated 
phase portrait is shown in Figure 6.6.4. It looks like some exotic sea creature, per-
haps a manta ray. The reversibility symmetry is apparent. The trajectories above 
the x-axis have twins below the x-axis, with arrows reversed.
y
x
Figure 6.6.4
Notice that the twin saddle points are joined by a pair of trajectories. They are 
called heteroclinic trajectories or saddle connections. Like homoclinic orbits, het-
eroclinic trajectories are much more common in reversible or conservative systems 
than in other types of systems. ■
Although we have relied on the computer to plot Figure 6.6.4, it can be sketched 
on the basis of qualitative reasoning alone. For example, the existence of the het-
eroclinic trajectories can be deduced rigorously using reversibility arguments 
(Exercise 6.6.6). The next example illustrates the spirit of such arguments.

167
6.6 REVERSIBLE SYSTEMS
EXAMPLE 6.6.2:
Using reversibility arguments alone, show that the system


x
y
y
x
x
=
=
−
2
has a homoclinic orbit in the half-plane x p 0.
Solution: Consider the unstable manifold of the saddle point at the origin. This 
manifold leaves the origin along the vector (1, 1), since this is the unstable eigen- 
direction for the linearization. Hence, close to the origin, part of the unstable man-
ifold lies in the first quadrant x, y  0. Now imagine a phase point with coordi-
nates ( x ( t ), y ( t )) moving along the unstable manifold, starting from x, y small and 
positive. At first, x ( t ) must increase since x
y
=
> 0.  Also, y ( t ) increases initially, 
since y
x
x
=
−
>
2
0  for small x. Thus the phase 
point moves up and to the right. Its horizontal veloc-
ity is continually increasing, so at some time it must 
cross the vertical line x  1. Then y  0  so y ( t ) 
decreases, eventually reaching y  0. Figure  6.6.5 
shows the situation.
Now, by reversibility, there must be a twin trajec-
tory with the same endpoints but with arrow reversed 
(Figure 6.6.6). Together the two trajectories form the 
desired homoclinic orbit. ■
There is a more general definition of reversibility 
which extends nicely to higher-order systems. 
Consider any mapping R (x) of the phase space to 
itself that satisfies R2 (x)  x. In other words, if the 
mapping is applied twice, all points go back to where 
they started. In our two-dimensional examples, a 
reflection about the x-axis (or any axis through the origin) has this property. Then 
the system x
f x
 ( ) is reversible if it is invariant under the change of variables 
t l t, x l R (x).
Our next example illustrates this more general notion of reversibility, and also 
highlights the main difference between reversible and conservative systems.
EXAMPLE 6.6.3:
Show that the system


x
x
y
y
y
x
= −
−
= −
−
2
2
cos
cos
cos
cos
y
x
1
Figure 6.6.5
y
x
1
Figure 6.6.6

168 
PHASE PLANE
is reversible, but not conservative. Then plot the phase portrait.
Solution: The system is invariant under the change of variables t l t, x l x, 
and y l y. Hence the system is reversible, with R (x, y )  (x, y ) in the preced-
ing notation.
To show that the system is not conservative, it suffices to show that it has an 
attracting fixed point. (Recall that a conservative system can never have an attract-
ing fixed point—see Example 6.5.1.)
The fixed points satisfy 2 cos x  cos y and 2 cos y  cos x. Solving these 
equations simultaneously yields cos x*  cos y*  0. Hence there are four fixed 
points, given by ( *, *)
(
,
)
x
y
= ±
±
Q
Q
2
2 .
We claim that ( *, *)
(
,
)
x
y
= −
−
Q
Q
2
2  is an attracting fixed point. The Jacobian 
there is
A
x
y
x
y
=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟= −
−
−
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
2
2
2
1
1
2
sin
*
sin *
sin
*
sin *
,
which has U  4, %  3, U2  4%  4. Therefore the fixed point is a stable node. 
This shows that the system is not conservative.
The other three fixed points can be 
shown to be an unstable node and two sad-
dles. A computer-generated phase portrait 
is shown in Figure 6.6.7. To see the revers-
ibility symmetry, compare the dynamics at 
any two points ( x, y ) and R ( x,  y ) 
( x, y ). The trajectories look the same, 
but the arrows are reversed. In particular, 
the stable node at (
,
)


Q
Q
2
2  is the twin of 
the unstable node at ( , )
Q
Q
2
2 . ■
The system in Example 6.6.3 is closely 
related to a model of two superconducting 
Josephson junctions coupled through a resistive load (Tsang et al. 1991). For fur-
ther discussion, see Exercise 6.6.9 and Example 8.7.4. Reversible, nonconservative 
systems also arise in the context of lasers (Politi et al. 1986) and fluid flows (Stone, 
Nadim, and Strogatz 1991 and Exercise 6.6.8).
6.7 Pendulum
Do you remember the first nonlinear system you ever studied in school? It was 
probably the pendulum. But in elementary courses, the pendulum’s essential non-
linearity is sidestepped by the small-angle approximation sin R x R. Enough of 
y
x
Figure 6.6.7

169
6.7 PENDULUM
that! In this section we use phase plane methods to analyze the pendulum, even in 
the dreaded large-angle regime where the pendulum whirls over the top.
In the absence of damping and external driving, the motion of a pendulum is 
governed by
d
dt
g
L
2
2
0
R
R
+
=
sin
 
(1)
where R is the angle from the downward vertical, g is the 
acceleration due to gravity, and L is the length of the pendu-
lum (Figure 6.7.1).
We nondimensionalize (1) by introducing a frequency 
X 
g L  and a dimensionless time τ  ωt. Then the 
equation becomes
R
R
+
=
sin
0  
(2)
where the overdot denotes differentiation with respect to U. The corresponding 
system in the phase plane is
R  v  
(3a)
v = −sinR  
(3b)
where v is the (dimensionless) angular velocity.
The fixed points are ( R*, v*)  ( kQ, 0), where k is any integer. There’s no physical 
difference between angles that differ by 2Q, so we’ll concentrate on the two fixed 
points (0, 0) and ( Q, 0). At (0, 0), the Jacobian is
A = −
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
0 1
1 0
so the origin is a linear center.
In fact, the origin is a nonlinear center, for two reasons. First, the system (3) is 
reversible: the equations are invariant under the transformation U l U , v l v . 
Then Theorem 6.6.1 implies that the origin is a nonlinear center.
Second, the system is also conservative. Multiplying (2) by R  and integrating 
yields
 

R R
R
R
R
(
sin )
cos
+
=
⇒
−
=
0
1
2
2
constant.
The energy function
E
v
v
( , )
cos
R
R
=
−
1
2
2
 
(4)
m
g
L
θ
Figure 6.7.1

170 
PHASE PLANE
has a local minimum at (0, 0), since E
v
≈
+
−
1
2
2
2
1
(
)
R
 for small ( R, v ). Hence 
Theorem 6.5.1 provides a second proof that the origin is a nonlinear center. (This 
argument also shows that the closed orbits are approximately circular, with 
R 2  v2 x 2( E 1).)
Now that we’ve beaten the origin to death, consider the fixed point at ( Q, 0). The 
Jacobian is
A =
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
0
1
1
0 .
The characteristic equation is M2  1  0. Therefore M1  1, M2  1; the fixed point 
is a saddle. The corresponding eigenvectors are v1  (1, 1) and v2  (1 , 1). 
The phase portrait near the fixed points can be sketched from the information 
obtained so far (Figure 6.7.2).
v
θ
Figure 6.7.2
To fill in the picture, we include the energy contours E
v
=
−
1
2
2
cosR  for different 
values of E. The resulting phase portrait is shown in Figure 6.7.3. The picture is 
periodic in the R-direction, as we’d expect.
v
θ
Figure 6.7.3
Now for the physical interpretation. The center corresponds to a state of neu-
trally stable equilibrium, with the pendulum at rest and hanging straight down. 
This is the lowest possible energy state ( E  1). The small orbits surrounding 
the center represent small oscillations about equilibrium, traditionally called 

171
6.7 PENDULUM
librations. As E increases, the orbits grow. The critical case is E  1, corresponding 
to the heteroclinic trajectories joining the saddles in Figure 6.7.3. The saddles rep-
resent an inverted pendulum at rest; hence the heteroclinic trajectories represent 
delicate motions in which the pendulum slows to a halt precisely as it approaches 
the inverted position. For E  1, the pendulum whirls repeatedly over the top. 
These rotations should also be regarded as periodic solutions, since R  Q and 
R  Q are the same physical position.
Cylindrical Phase Space
The phase portrait for the pendulum is more illuminating when wrapped onto 
the surface of a cylinder (Figure 6.7.4). In fact, a cylinder is the natural phase space 
for the pendulum, because it incorporates the fundamental geometric difference 
between v and R: the angular velocity v is a real number, whereas R is an angle.
v
E
E
E
E
E
1
1
−1
1
1
>
=
=
=
>
θ
Figure 6.7.4
There are several advantages to the cylindrical representation. Now the peri-
odic whirling motions look periodic—they are the closed orbits that encircle the 
cylinder for E  1. Also, it becomes obvious that the saddle points in Figure 6.7.3 
are all the same physical state (an inverted pendulum at rest). The heteroclinic tra-
jectories of Figure 6.7.3 become homoclinic orbits on the cylinder.
There is an obvious symmetry between the top and bottom half of Figure 6.7.4. 
For example, both homoclinic orbits have the same energy and shape. To highlight 
this symmetry, it is interesting (if a bit mind-boggling at first) to plot the energy 
vertically instead of the angular velocity v (Figure 6.7.5). Then the orbits on the 
cylinder remain at constant height, while the cylinder gets bent into a U-tube. The 
two arms of the tube are distinguished by the sense of rotation of the pendulum, 

172 
PHASE PLANE
either clockwise or counterclockwise. At low energies, this distinction no longer 
exists; the pendulum oscillates to and fro. The homoclinic orbits lie at E  1, the 
borderline between rotations and librations.
clockwise
whirling
rotations
librations
E
E
1
−1
=
=
counterclockwise
whirling
Figure 6.7.5
At first you might think that the trajectories are drawn incorrectly on one of the 
arms of the U-tube. It might seem that the arrows for clockwise and counterclock-
wise motions should go in opposite directions. But if you think about the coordi-
nate system shown in Figure 6.7.6, you’ll see that the picture is correct.
bottom
top
0
0
0
0
0
top
bottom
v increasing
v
v
v
=
=
=
=
=
=
=
=
bend and
stretch
θ
θ
θ
θ
θ
θ
θ
π
π
π
θ
θ
Figure 6.7.6
The point is that the direction of increasing R has reversed when the bot-
tom of the cylinder is bent around to form the U-tube. (Please understand that 
Figure 6.7.6 shows the coordinate system, not the actual trajectories; the trajecto-
ries were shown in Figure 6.7.5.)

173
6.7 PENDULUM
Damping
Now let’s return to the phase plane, and suppose that we add a small amount of 
linear damping to the pendulum. The governing equation becomes


R
R
R
+
+
=
b
sin
0
where b  0 is the damping strength. Then centers become stable spirals while sad-
dles remain saddles. A computer-generated phase portrait is shown in Figure 6.7.7.
Figure 6.7.7
The picture on the U-tube is clearer. All trajectories continually lose altitude, 
except for the fixed points (Figure 6.7.8).
clockwise
whirling
rotations
librations
E
E
1
−1
=
=
counterclockwise
whirling
Figure 6.7.8
We can see this explicitly by computing the change in energy along a trajectory:
dE
d
d
d
b
τ
τ
θ
θ
θ θ
θ
θ
=
−
(
)=
+
= −
≤
1
2
2
2
0

 

cos
(
sin )
.

174 
PHASE PLANE
Hence E decreases monotonically along trajectories, except at fixed points where 
R w 0.
The trajectory shown in Figure 6.7.8 has the following physical interpretation: 
the pendulum is initially whirling clockwise. As it loses energy, it has a harder time 
rotating over the top. The corresponding trajectory spirals down the arm of the 
U-tube until E  1; then the pendulum doesn’t have enough energy to whirl, and 
so it settles down into a small oscillation about the bottom. Eventually the motion 
damps and the pendulum comes to rest at its stable equilibrium.
This example shows how far we can go with pictures—without invoking any 
difficult formulas, we were able to extract all the important features of the pen-
dulum’s dynamics. It would be much more difficult to obtain these results analyt-
ically, and much more confusing to interpret the formulas, even if we could find 
them.
6.8 Index Theory
In Section 6.3 we learned how to linearize a system about a fixed point. Linearization 
is a prime example of a local method: it gives us a detailed microscopic view of the 
trajectories near a fixed point, but it can’t tell us what happens to the trajectories 
after they leave that tiny neighborhood. Furthermore, if the vector field starts with 
quadratic or higher-order terms, the linearization tells us nothing.
In this section we discuss index theory, a method that provides global informa-
tion about the phase portrait. It enables us to answer such questions as: Must a 
closed trajectory always encircle a fixed point? If so, what types of fixed points are 
permitted? What types of fixed points can coalesce in bifurcations? The method 
also yields information about the trajectories near higher-order fixed points. 
Finally, we can sometimes use index arguments to rule out the possibility of closed 
orbits in certain parts of the phase plane.
The Index of a Closed Curve
The index of a closed curve C is an integer that measures the winding of the 
vector field on C. The index also provides information about any fixed points that 
might happen to lie inside the curve, as we’ll see.
This idea may remind you of a concept in electrostatics. In that subject, one 
often introduces a hypothetical closed surface (a “Gaussian surface”) to probe 
a configuration of electric charges. By studying the behavior of the electric field 
on the surface, one can determine the total amount of charge inside the surface. 
Amazingly, the behavior on the surface tells us what’s happening far away inside 
the surface! In the present context, the electric field is analogous to our vector field, 
the Gaussian surface is analogous to the curve C, and the total charge is analogous 
to the index. 

175
6.8 INDEX THEORY
Now let’s make these notions precise. Suppose that x
f x
 ( ) is a smooth vector 
field on the phase plane. Consider a closed curve C (Figure 6.8.1). This curve is not 
necessarily a trajectory—it’s simply a loop that we’re putting in the phase plane to 
probe the behavior of the vector field. We also assume that C is a “simple closed 
curve” (i.e., it doesn’t intersect itself) and that it 
doesn’t pass through any fixed points of the system. 
Then at each point x on C, the vector field 
 
x  ( , )
x y  
makes a well-defined angle G =
−
tan
(
)
1  
y x  with the 
positive x-axis (Figure 6.8.1).
As x moves counterclockwise around C, the 
angle G changes continuously since the vector field is 
smooth. Also, when x returns to its starting place, G 
returns to its original direction. Hence, over one cir-
cuit, G has changed by an integer multiple of 2Q. Let 
[G]C be the net change in G over one circuit. Then the index of the closed curve C 
with respect to the vector field f is defined as
IC
C
=
[ ]
1
2π φ
.
Thus, IC is the net number of counterclockwise revolutions made by the vector field 
as x moves once counterclockwise around C.
To compute the index, we do not need to know the vector field everywhere; we 
only need to know it along C. The first two examples illustrate this point.
EXAMPLE 6.8.1:
Given that the vector field varies along C as shown in Figure 6.8.2, find IC .
Solution: As we traverse C once counterclockwise, the vectors rotate through 
one full turn in the same sense. Hence IC  1.
If you have trouble visualizing this, here’s a foolproof method. Number the 
vectors in counterclockwise order, starting anywhere on C (Figure 6.8.3a). Then 
transport these vectors (without rotation!) such that their tails lie at a common 
origin (Figure 6.8.3b). The index equals the net number of counterclockwise revo-
lutions made by the numbered vectors.
C
Figure 6.8.2
C
(x, y)
. .
φ
Figure 6.8.1

176 
PHASE PLANE
(a)
3
2
7
8
1
2
3
4
5
6
1
8
7
6
5
4
C
(b)
Figure 6.8.3
As Figure  6.8.3b shows, the vectors rotate once counterclockwise as we go in 
increasing order from vector #1 to vector #8. Hence IC  1. ■
EXAMPLE 6.8.2:
Given the vector field on the closed curve shown in Figure 6.8.4a, compute IC .
(a)
(b)
2
3
4
5
6
7
8
1
1
8
7
6
5
4
3
2
C
Figure 6.8.4
Solution: We use the same construction as in Example 6.8.1. As we make one 
circuit around C, the vectors rotate through one full turn, but now in the opposite 
sense. In other words, the vectors on C rotate clockwise as we go around C coun-
terclockwise. This is clear from Figure 6.8.4b; the vectors rotate clockwise as we go 
in increasing order from vector #1 to vector #8. Therefore IC  1. ■
In many cases, we are given equations for the vector field, rather than a pic-
ture of it. Then we have to draw the picture ourselves, and repeat the steps above. 
Sometimes this can be confusing, as in the next example.
EXAMPLE 6.8.3:
Given the vector field 

x
x y
y
x
y
=
=
−
2
2
2
,
, find IC  , where C is the unit circle 
x2  y2  l.

177
6.8 INDEX THEORY
Solution: To get a clear picture of the vector field, it is sufficient to consider a 
few conveniently chosen points on C. For instance, at ( x, y )  (1, 0), the vector is 
(  
x y
,
)  ( x2y, x2  y2 )  (0, 1). This vector is labeled #1 in Figure 6.8.5a. Now we 
move counterclockwise around C, computing vectors as we go. At ( , )
( , ),
x y 
1
2 1 1  
we have ( , )
( , ),
 
x y 
1
2 2 1 0  labeled #2. The remaining vectors are found similarly. 
Notice that different points on the circle may be associated with the same vec-
tor; for example, vector #3 and #7 are both (0, 1).
(a)
(b)
C
8
7
6
5
4
3
2
1, 9
6, 8
2, 4
3, 7
1, 5, 9
Figure 6.8.5
Now we translate the vectors over to Figure 6.8.5b. As we move from #1 to #9 
in order, the vectors rotate 180° clockwise between #1 and #3, then swing back 
360° counterclockwise between #3 and #7, and finally rotate 180° clockwise again 
between #7 and #9 as we complete the circuit of C. Thus φ
π
π
π
[ ] = −+
−
=
C
2
0  
and therefore IC  0. ■
We plotted nine vectors in this example, but you may want to plot more to see 
the variation of the vector field in finer detail.
Properties of the Index
Now we list some of the most important properties of the index.
1. Suppose that C can be continuously deformed into 
a
C  without pass-
ing through a fixed point. Then I
I
C
C
=
′.
This property has an elegant proof: Our assumptions imply that as 
we deform C into Ca, the index IC varies continuously. But IC is an inte-
ger—hence it can’t change without jumping! (To put it more formally, 
if an integer-valued function is continuous, it must be constant.)
As you think about this argument, try to see where we used the 
assumption that the intermediate curves don’t pass through any fixed 
points.
2. If C doesn’t enclose any fixed points, then IC  0.

178 
PHASE PLANE
Proof: By property (1), we can shrink C to a tiny circle without 
changing the index. But G is essentially constant on such a circle, 
because all the vectors point in nearly the same direction, thanks 
to the assumed smoothness of the vector field (Figure 6.8.6). Hence  
[G]C  0 and therefore IC  0.
Figure 6.8.6
3. If we reverse all the arrows in the vector field by changing t l t, the 
index is unchanged.
Proof: All angles change from G to G  Q. Hence [G ]C stays the same.
4. Suppose that the closed curve C is actually a trajectory for the system, 
i.e., C is a closed orbit. Then IC  1.
We won’t prove this, but it should be clear from geometric intuition 
(Figure 6.8.7).
C
Figure 6.8.7
Notice that the vector field is everywhere tangent to C, because C is a trajectory. 
Hence, as x winds around C once, the tangent vector also rotates once in the same 
sense.
Index of a Point
The properties above are useful in several ways. Perhaps most importantly, they 
allow us to define the index of a fixed point, as follows.
Suppose x* is an isolated fixed point. Then the index I of x* is defined as IC, 
where C is any closed curve that encloses x* and no other fixed points. By property 
(1) above, IC is independent of C and is therefore a property of x* alone. Therefore 
we may drop the subscript C and use the notation I for the index of a point.
EXAMPLE 6.8.4:
Find the index of a stable node, an unstable node, and a saddle point.

179
6.8 INDEX THEORY
Solution: The vector field near a stable node looks like the vector field of 
Example 6.8.1. Hence I  1. The index is also 1 for an unstable node, because 
the only difference is that all the arrows are reversed; by property (3), this doesn’t 
change the index! (This observation shows that the index is not related to stability, 
per se.) Finally, I  1 for a saddle point, because the vector field resembles that 
discussed in Example 6.8.2. ■
In Exercise 6.8.1, you are asked to show that spirals, centers, degenerate nodes 
and stars all have I  1. Thus, a saddle point is truly a different animal from all 
the other familiar types of isolated fixed points.
The index of a curve is related in a beautifully simple way to the indices of the 
fixed points inside it. This is the content of the following theorem.
Theorem 6.8.1: If a closed curve C surrounds n isolated fixed points x1*, . . . , 
xn*, then
IC  I1  I2  . . .  In 
where Ik is the index of xk*, for k  1, . . . , n .
Ideas behind the proof: The argument is a familiar one, and comes up in 
multivariable calculus, complex variables, electrostatics, and various other sub-
jects. We think of C as a balloon and suck most of the air out of it, being careful 
not to hit any of the fixed points. The result of this deformation is a new closed 
curve (, consisting of n small circles H1, . . . , Hn about the fixed points, and two-way 
bridges connecting these cir-
cles (Figure 6.8.8). 
Note that I(  IC, by prop-
erty (1), since we didn’t cross 
any fixed points during the 
deformation. Now let’s com-
pute I( by considering [G]( . 
There are contributions to [G]( 
from the small circles and from 
the two-way bridges. The key 
point is that the contributions from the bridges cancel out: as we move around (, 
each bridge is traversed once in one direction, and later in the opposite direction. 
Thus we only need to consider the contributions from the small circles. On Hk, the 
angle G changes by [ G] Hk  2Q Ik, by definition of Ik. Hence
I
I
k
k
k
n
k
n
Γ
Γ
=
[ ] =
[ ]
=
=
=
∑
∑
1
2
1
2
1
1
π
π
γ
φ
φ
and since I(  IC, we’ re done. ■
C
X
k
k
γ

Figure 6.8.8

180 
PHASE PLANE
This theorem is reminiscent of Gauss’s law in electrostatics, namely that the 
electric flux through a surface is proportional to the total charge enclosed. See 
Exercise 6.8.12 for a further exploration of this analogy between index and charge.
Theorem 6.8.2: Any closed orbit in the phase plane must enclose fixed 
points whose indices sum to 1.
Proof: Let C denote the closed orbit. From property (4) above, IC  1. 
Then Theorem 6.8.1 implies 
Ik
k
n
= +
=∑
1
1
. ■
Theorem 6.8.2 has many practical consequences. For instance, it implies that 
there is always at least one fixed point inside any closed orbit in the phase plane 
(as you may have noticed on your own). If there is only one fixed point inside, it 
cannot be a saddle point. Furthermore, Theorem 6.8.2 can sometimes be used 
to rule out the possible occurrence of closed trajectories, as seen in the following 
examples.
EXAMPLE 6.8.5:
Show that closed orbits are impossible for the “rabbit vs. sheep” system


x
x
x
y
y
y
x
y
=
−−
=
−−
(
)
(
)
3
2
2
studied in Section 6.4. Here x, y p 0.
Solution: As shown previously, the system has four fixed points: (0, 0)  unsta-
ble node; (0, 2) and (3, 0)  stable nodes; and (1, 1)  saddle point. The index at each 
of these points is shown in Figure 6.8.9. 
Now suppose that the system had a closed trajectory. Where could it lie? There 
are three qualitatively different locations, indicated by the dotted curves C1, C2, 
C3. They can be ruled out as follows: orbits 
like C1 are impossible because they don’t 
enclose any fixed points, and orbits like 
C2 violate the requirement that the indices 
inside must sum to 1. But what is wrong 
with orbits like C3, which satisfy the index 
requirement? The trouble is that such orbits 
always cross the x-axis or the y-axis, and 
these axes contain straight-line trajectories. 
Hence C3 violates the rule that trajectories 
can’t cross (recall Section 6.2). ■
y
C
C
x
C
3
1
−1
+1
+1
+1
2
Figure 6.8.9

181
EXERCISES
EXAMPLE 6.8.6:
Show that the system 

x
xe
y
x
y
x
=
= +
+
−,
1
2  has no closed orbits.
Solution: This system has no fixed points: if x  0 , then x  0 and so 
y
y
= +
≠
1
0
2
. By Theorem 6.8.2, closed orbits cannot exist. ■
EXERCISES FOR CHAPTER 6
6.1 Phase Portraits
For each of the following systems, find the fixed points. Then sketch the null-
clines, the vector field, and a plausible phase portrait.
6.1.1 


x
x
y
y
ex
=
−
= −
,
1
 
 
6.1.2 


x
x
x
y
y
=
−
= −
3,
6.1.3  


x
x x
y
y
y
x
y
=
−
=
−
(
),
(
)
2
 
6.1.4  


x
y
y
x
y
=
=
+
−
,
(
)
1
1
6.1.5  


x
x
x
y
y
x
y
=
−−
=
−
(
),
2
 
6.1.6  


x
x
y
y
x
y
=
−
=
−
2
,
6.1.7 
(Nullcline vs. stable manifold) There’s a confusing aspect of Example 6.1.1. 
The nullcline x  0 in Figure 6.1.3 has a similar shape and location as the stable 
manifold of the saddle, shown in Figure 6.1.4. But they’re not the same curve! To 
clarify the relation between the two curves, sketch both of them on the same phase 
portrait.
(Computer work) Plot computer-generated phase portraits of the following 
systems.
6.1.8 
(van der Pol oscillator) 

x
y
y
x
y
x
=
= −+
−
,
(
)
1
2
6.1.9 
(Dipole fixed point) 

x
xy
y
y
x
=
=
−
2
2
2
,
6.1.10 
(Two-eyed 
monster) 


x
y
y
y
x
y
xy
y
=
+
= −
+
−
+
2
1
2
1
5
6
5
2
,
 
(from 
Borrelli and Coleman 1987, p. 385.)
6.1.11 
(Parrot) 


x
y
y
y
x
y
xy
y
=
+
= −+
−
+
2
1
5
6
5
2
,
 
(from 
Borrelli 
and 
Coleman 1987, p. 384.)
6.1.12 
(Saddle connections) A certain system is known to have exactly two 
fixed points, both of which are saddles. Sketch phase portraits in which
a) there is a single trajectory that connects the saddles;
b) there is no trajectory that connects the saddles.
6.1.13 
Draw a phase portrait that has exactly three closed orbits and one fixed 
point.
6.1.14 
(Series approximation for the stable manifold of a saddle point) Recall the 
system 

x
x
e
y
y
y
=
+
= −
−,
 from Example 6.1.1. We showed that this system has 
one fixed point, a saddle at (1, 0). Its unstable manifold is the x-axis, but its stable 

182 
PHASE PLANE
manifold is a curve that is harder to find. The goal of this exercise is to approxi-
mate this unknown curve.
a) Let ( x, y ) be a point on the stable manifold, and assume that ( x, y ) is close to 
(1, 0). Introduce a new variable u  x  1, and write the stable manifold as 
y  a1u  a2u2 O( u3 ). To determine the coefficients, derive two expressions for 
dy / du and equate them.
b) Check that your analytical result produces a curve with the same shape as the 
stable manifold shown in Figure 6.1.4.
6.2 Existence, Uniqueness, and Topological Consequences
6.2.1 
We claimed that different trajectories can never intersect. But in many 
phase portraits, different trajectories appear to intersect at a fixed point. Is there a 
contradiction here?
6.2.2 
Consider the system 

x
y
y
x
x
y
y
=
= −+
−
−
,
(
) .
1
2
2
a) Let D be the open disk x2  y2  4. Verify that the system satisfies the hypothe-
ses of the existence and uniqueness theorem throughout the domain D.
b) By substitution, show that x ( t )  sin t, y ( t )  cos t is an exact solution of the 
system.
c) Now consider a different solution, in this case starting from the initial condition 
x
y
( )
,
( )
0
0
0
1
2


. Without doing any calculations, explain why this solution 
must satisfy x ( t )2  y ( t )2  1 for all t  d.
6.3 Fixed Points and Linearization
For each of the following systems, find the fixed points, classify them, sketch the 
neighboring trajectories, and try to fill in the rest of the phase portrait.
6.3.1  


x
x
y
y
x
=
−
=
−
,
2
4  
 
6.3.2  


x
y
y
x
x
=
=
−
sin ,
3
6.3.3 


x
y
e
y
x
y
x
= +
−
=
−
−
1
3
,
 
6.3.4  


x
y
x
x
y
y
=
+
−
= −
3,
6.3.5  


x
y
y
x


sin ,
cos
 
 
6.3.6  


x
xy
y
x
y
=
−
=
−
1
3
,
6.3.7 
For each of the nonlinear systems above, plot a computer-generated 
phase portrait and compare to your approximate sketch.
6.3.8 
(Gravitational equilibrium) A particle moves along a line joining two sta-
tionary masses, m1 and m2, which are separated by a fixed distance a. Let x denote 
the distance of the particle from m1.
a) Show that x
Gm
x
a
Gm
x
=
−
−
2
2
1
2
(
)
, where G is the gravitational constant.
b) Find the particle’s equilibrium position. Is it stable or unstable?
6.3.9 
Consider the system 

x
y
x
y
y
y
x
=
−
=
−−
3
3
4
3
,
.
a) Find all the fixed points and classify them.
b) Show that the line x  y is invariant, i.e., any trajectory that starts on it stays on it.

183
EXERCISES
c) Show that x t
y t
( )
( )
−
→0 as t l d for all other trajectories. (Hint: Form a 
differential equation for x  y.)
d) Sketch the phase portrait.
e) If you have access to a computer, plot an accurate phase portrait on the square 
domain 20 b x, y b 20. (To avoid numerical instability, you’ll need to use a 
fairly small step size, because of the strong cubic nonlinearity.) Notice the tra-
jectories seem to approach a certain curve as t l d; can you explain this 
behavior intuitively, and perhaps find an approximate equation for this curve?
6.3.10 
(Dealing with a fixed point for which linearization is inconclusive) The 
goal of this exercise is to sketch the phase portrait for 

x
xy
y
x
y
=
=
−
,
.
2
a) Show that the linearization predicts that the origin is a non-isolated fixed point.
b) Show that the origin is in fact an isolated fixed point.
c) Is the origin repelling, attracting, a saddle, or what? Sketch the vector field 
along the nullclines and at other points in the phase plane. Use this information 
to sketch the phase portrait.
d) Plot a computer-generated phase portrait to check your answer to (c).
(Note: This problem can also be solved by a method called center manifold the-
ory, as explained in Wiggins (1990) and Guckenheimer and Holmes (1983).)
6.3.11 
(Nonlinear terms can change a star into a spiral) Here’s another example 
that shows that borderline fixed points are sensitive to nonlinear terms. Consider 
the system in polar coordinates given by 

r
r
r
= −
=
,
ln .
R
1
a) Find r ( t ) and R( t ) explicitly, given an initial condition ( ,
)
r0
0R
.
b) Show that r ( t ) l 0 and |R( t )| l d as t l d. Therefore the origin is a stable 
spiral for the nonlinear system.
c) Write the system in x, y coordinates.
d) Show that the linearized system about the origin is 

x
x
y
y
= −
= −
,
. Thus the 
origin is a stable star for the linearized system.
6.3.12 
(Polar coordinates) Using the identity R  tan1 ( y / x ), show that 



R =
−
(
)
.
xy
yx
r2
6.3.13 
(Another linear center that’s actually a nonlinear spiral) Consider the sys-
tem 

x
y
x
y
x
= −−
=
3,
.  Show that the origin is a spiral, although the lineariza-
tion predicts a center.
6.3.14 
Classify the fixed point at the origin for the system x
y
ax
= −+
3, 
y
x
ay
=
+
3,  for all real values of the parameter a.
6.3.15 
Consider the system 

r
r
r
=
−
= −
(
),
cos
1
1
2
R
R  where r, R represent polar 
coordinates. Sketch the phase portrait and thereby show that the fixed point 
r*  1, R*  0 is attracting but not Liapunov stable.

184 
PHASE PLANE
6.3.16 
 (Saddle switching and structural stability) Consider the system 


x
a
x
xy
y
y
x
=
+
−
=
−
−
2
2
2
1
,
,  where a is a parameter.
a) Sketch the phase portrait for a  0. Show that there is a trajectory connecting 
two saddle points. (Such a trajectory is called a saddle connection.)
b) With the aid of a computer if necessary, sketch the phase portrait for a  0 and 
a  0.
Notice that for a v 0, the phase portrait has a different topological character: 
the saddles are no longer connected by a trajectory. The point of this exercise is 
that the phase portrait in (a) is not structurally stable, since its topology can be 
changed by an arbitrarily small perturbation a.
6.3.17 
(Nasty fixed point) The system 

x
xy
x y
y
y
y
x
xy
=
−
+
=
+
−
2
3
2
3
2
,
 
has a nasty higher-order fixed point at the origin. Using polar coordinates or oth-
erwise, sketch the phase portrait.
6.4 Rabbits versus Sheep
Consider the following “rabbits vs. sheep” problems, where x, y p 0. Find the fixed 
points, investigate their stability, draw the nullclines, and sketch plausible phase 
portraits. Indicate the basins of attraction of any stable fixed points.
6.4.1 


x
x
x
y
y
y
x
y
=
−−
=
−−
(
),
(
)
3
2
6.4.2 


x
x
x
y
y
y
x
y
=
−
−
=
−−
(
),
(
)
3
2
2
6.4.3 


x
x
x
y
y
y
x
y
=
−
−
=
−−
(
),
(
)
3
2
2
2
The next three exercises deal with competition models of increasing complexity. 
We assume N1, N2 p 0 in all cases.
6.4.4 
The simplest model is 

N
rN
bN N
N
r N
b N N
1
1
1
1
2
2
2
2
2
1
2
=
−
=
−
,
.
a) In what way is this model less realistic than the one considered in the text?
b) Show that by suitable rescalings of N1  , N2  , and t, the model can be nondimen-
sionalized to xa  x (1  y ), ya  y ( S  x ). Find a formula for the dimension-
less group S.
c) Sketch the nullclines and vector field for the system in (b).
d) Draw the phase portrait, and comment on the biological implications.
e) Show that (almost) all trajectories are curves of the form S ln x  x  ln y  y  C. 
(Hint: Derive a differential equation for dx / dy, and separate the variables.) 
Which trajectories are not of the stated form?
6.4.5 
Now suppose that species #1 has a finite carrying capacity K1. Thus


N
rN
N
K
b N N
N
r N
b N N
1
1
1
1
1
1
1
2
2
2
2
2
1
2
1
=
−
−
=
−
(
)
.

185
EXERCISES
Nondimensionalize the model and analyze it. Show that there are two qualitatively 
different kinds of phase portrait, depending on the size of K1. (Hint: Draw the 
nullclines.) Describe the long-term behavior in each case.
6.4.6 
Finally, suppose that both species have finite carrying capacities:


N
rN
N
K
b N N
N
r N
N
K
b N N
1
1
1
1
1
1
1
2
2
2
2
2
2
2
1
2
1
1
=
−
−
=
−
−
(
)
(
)
.
a) Nondimensionalize the model. How many dimensionless groups are needed?
b) Show that there are four qualitatively different phase portraits, as far as long-
term behavior is concerned.
c) Find conditions under which the two species can stably coexist. Explain 
the biological meaning of these conditions. (Hint: The carrying capacities 
reflect the competition within a species, whereas the b’s reflect the competition 
between species.)
6.4.7 
(Two-mode laser) According to Haken (1983, p. 129), a two-mode laser 
produces two different kinds of photons with numbers n1 and n2. By analogy 
with the simple laser model discussed in Section 3.3, the rate equations are


n
G Nn
K n
n
G Nn
K n
1
1
1
1 1
2
2
2
2
2
=
−
=
−
where N ( t )  N0  B1n1 B2n2 is the number of excited atoms. The parameters G1, 
G2, k1, k2, B1, B2, N0 are all positive.
a) Discuss the stability of the fixed point n1*  n2*  0.
b) Find and classify any other fixed points that may exist.
c) Depending on the values of the various parameters, how many qualitatively 
different phase portraits can occur? For each case, what does the model predict 
about the long-term behavior of the laser?
6.4.8 
The system x
ax
x
c
=
−G
, y
by
y
c
=
−G , where G ≡
+
ax
by
c
c , has been 
used to model the evolutionary dynamics of two interacting species (Nowak 2006).  
Here x and y denote the relative abundances of the species, and a, b, c > 0 are 
parameters. The unusual feature of this model is the exponent c in the growth law 
for each species. The goal of this question is to explore how the value of c affects 
the system’s long-term dynamics.
a)  Show that if the initial conditions satisfy x
y
0
0
1
+
= , then x t
y t
( )
( )
+
=1 for 
all t; hence, any trajectory that starts on this line stays on it forever. (Assume 
here and in the other parts of this problem that x0  and y0  are non-negative.)
b)  Show that all trajectories starting in the positive quadrant are attracted to the 
invariant line x
y
+
=1 found in part (a). Thus, the analysis of the system’s 

186 
PHASE PLANE
long-term dynamics boils down to figuring out how trajectories flow along this 
invariant line.
c) Draw the phase portrait in the ( , )
x y  plane for the simple case c 1.  How does 
the long-term behavior of the system depend on the relative sizes of a and b ?
d) How does the phase portrait change when c 1? 
e) Finally, what happens when c 1?
6.4.9 
(Model of a national economy)  The following exercise is adapted from 
Exercise 2.24 in Jordan and Smith (1987). A simple model of a national economy, 
based on what economists call the “Keynesian cross,” is given by I
I
C
=
−B
, 
C
I
C
G
=
−
−
C(
) , where I p 0 is the national income, C p 0  is the rate of con-
sumer spending, and G p 0  is the rate of government spending. The parameters 
B  and C  satisfy 1<
< ∞
B
 and 1≤
< ∞
C
. 
a) Show that if the rate of government spending G  is constant, there is a fixed point 
for the model, and hence an equilibrium state for the economy. Classify this 
fixed point as a function of B  and C. In the limiting case where C 1, show 
that the economy is predicted to oscillate.
b) Next, assume that government spending increases linearly with the national 
income: G
G
kI
=
+
0
, where k  0 . Determine under what conditions there is 
an economically sensible equilibrium, meaning one in the first quadrant I p 0, 
C p 0 . Show that this kind of equilibrium ceases to exist if k  exceeds a critical 
value kc , to be determined. How is the economy predicted to behave when 
k
kc

?
c)  Finally, suppose government expenditures grow quadratically with the national 
income: G
G
kI
=
+
0
2 . Show that the system can have two, one, or no fixed 
points in the first quadrant, depending on how big G0  is. Discuss the implica-
tions for the economy in the various cases by interpreting the phase portraits.
6.4.10 
(Hypercycle equation)  In Eigen and Schuster’s (1978) model of pre-biotic 
evolution, a group of n p 2 RNA molecules or other self-reproducing chemical 
units are imagined to catalyze each other’s replication in a closed feedback loop, 
with one molecule serving as the catalyst for the next. Eigen and Schuster consid-
ered a variety of hypothetical reaction schemes, the simplest of which, in dimen-
sionless form, is
x
x x
x x
i
i
i
j
j
j
n
=
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟
−
−
=∑
1
1
1
 ,    i
n
1 2
, ,
,
!
, 
where the indices are reduced modulo n, so that x
xn
0 
. Here xi  denotes the rela-
tive frequency of molecule i. From now on, let’s focus on the case where n  2 , and 
assume xi  0  for all i.

187
EXERCISES
a)  Show that for 
n  2 , the system reduces to 
x
x x
x x
1
1
2
1
2
2
=
−
(
), 
x
x x
x x
2
2
1
1
2
2
=
−
(
) .
b)  Find and classify all the fixed points. (Remember we’re assuming xi  0  for all i.)
c)  Let u
x
x
=
+
1
2 . By deriving and analyzing a differential equation for u  in 
terms of u and x x
1
2 , prove that u t( ) l1 as t →∞.
d)  Let v
x
x
=
−
1
2 . Prove that v t( ) l 0  as t →∞.
e)  By combining the results of parts (c) and (d), prove that ( ( ), ( ))
( , )
x t
y t
l
1
2
1
2 .
f)  Using a computer, draw the phase portrait. You’ll see something striking, 
something that cries out for explanation. Explain it analytically. 
For larger values of n, the dynamics of the hypercycle equation become much 
richer—see Chapter 12 in Hofbauer and Sigmund (1998).
6.4.11 
(Leftists, rightists, centrists) Vasquez and Redner (2004, p. 8489) mention 
a highly simplified model of political opinion dynamics consisting of a population 
of leftists, rightists, and centrists. The leftists and rightists never talk to each other; 
they are too far apart politically to even begin a dialogue. But they do talk to the 
centrists—this is how opinion change occurs. Whenever an extremist of either 
type talks with a centrist, one of them convinces the other to change his or her 
mind, with the winner depending on the sign of a parameter r. If r  0 , the extrem-
ist always wins and persuades the centrist to move to that end of the spectrum. If 
r  0 , the centrist always wins and pulls the extremist to the middle. The model’s 
governing equations are



x
rxz
y
ryz
z
rxz
ryz
=
=
= −
−
where x, y, and z are the relative fractions of rightists, leftists, and centrists, respec-
tively, in the population.
a)  Show that the set x
y
z
+
+
=1  is invariant. 
b)  Analyze the long-term behavior predicted by the model for both positive and 
negative values of r.
c)  Interpret the results in political terms.
6.5 Conservative Systems
6.5.1 
Consider the system x
x
x
=
−
3
.
a) Find all the equilibrium points and classify them.
b) Find a conserved quantity.
c) Sketch the phase portrait.
6.5.2 
Consider the system x
x
x
=
−
2.
a) Find and classify the equilibrium points.
b) Sketch the phase portrait.

188 
PHASE PLANE
c) Find an equation for the homoclinic orbit that separates closed and nonclosed 
trajectories.
6.5.3 
Find a conserved quantity for the system x
a
ex
=
−
, and sketch the 
phase portrait for a  0, a  0, and a  0.
6.5.4 
Sketch the phase portrait for the system x
ax
x
=
−
2  for a  0, a  0, and 
a  0.
6.5.5 
Investigate the stability of the equilibrium points of the system 
x
x
a x
a
=
−
−
(
)(
)
2
 for all real values of the parameter a. (Hints: It might help to 
graph the right-hand side. An alternative is to rewrite the equation as x
V
x
= −′( )  
for a suitable potential energy function V and then use your intuition about parti-
cles moving in potentials.)
6.5.6 
(Epidemic model revisited) In Exercise 3.7.6, you analyzed the Kermack
McKendrick model of an epidemic by reducing it to a certain first-order sys-
tem. In this problem you’ll see how much easier the analysis becomes in the phase 
plane. As before, let x ( t ) p 0 denote the size of the healthy population and y ( t ) p 0 
denote the size of the sick population. Then the model is


x
kxy
y
kxy
ly
= −
=
−
,
where k,A   0. (The equation for z ( t ), the number of deaths, plays no role in the 
x, y dynamics so we omit it.)
a) Find and classify all the fixed points.
b) Sketch the nullclines and the vector field.
c) Find a conserved quantity for the system. (Hint: Form a differential equation 
for dy / dx. Separate the variables and integrate both sides.)
d) Plot the phase portrait. What happens as t l d ?
e) Let ( x0, y0 ) be the initial condition. An epidemic is said to occur if y ( t ) increases 
initially. Under what condition does an epidemic occur?
6.5.7 
(General relativity and planetary orbits) The relativistic equation for the 
orbit of a planet around the sun is
d u
d
u
u
2
2
2
θ
α
ε
+
=
+
where u 1 / r and r, R are the polar coordinates of the planet in its plane of motion. 
The parameter B is positive and can be found explicitly from classical Newtonian 
mechanics; the term F u2 is Einstein’s correction. Here F is a very small positive 
parameter. 
a) Rewrite the equation as a system in the ( u, v ) phase plane, where v  du / dR.
b) Find all the equilibrium points of the system.

189
EXERCISES
c) Show that one of the equilibria is a center in the ( u, v ) phase plane, according to 
the linearization. Is it a nonlinear center?
d) Show that the equilibrium point found in (c) corresponds to a circular planetary 
orbit.
Hamiltonian systems are fundamental to classical mechanics; they provide an 
equivalent but more geometric version of Newton’s laws. They are also central 
to celestial mechanics and plasma physics, where dissipation can sometimes be 
neglected on the time scales of interest. The theory of Hamiltonian systems is deep 
and beautiful, but perhaps too specialized and subtle for a first course on nonlin-
ear dynamics. See Arnold (1978), Lichtenberg and Lieberman (1992), Tabor (1989), 
or Hénon (1983) for introductions.
Here’s the simplest instance of a Hamiltonian system. Let H ( p, q ) be a smooth, 
real-valued function of two variables. The variable q is the “generalized coordi-
nate” and p is the “conjugate momentum.” (In some physical settings, H could 
also depend explicitly on time t, but we’ll ignore that possibility.) Then a system of 
the form


q
H
p
p
H
q
= ∂
∂
= −∂
∂
,
is called a Hamiltonian system and the function H is called the Hamiltonian. The 
equations for q and p are called Hamilton’s equations. 
The next three exercises concern Hamiltonian systems.
6.5.8 
(Harmonic oscillator) For a simple harmonic oscillator of mass m, spring 
constant k, displacement x, and momentum p, the Hamiltonian is H
p
m
kx
=
+
2
2
2
2 .
 
Write out Hamilton’s equations explicitly. Show that one equation gives the usual 
definition of momentum and the other is equivalent to F  ma. Verify that H is 
the total energy.
6.5.9 
Show that for any Hamiltonian system, H ( x, p ) is a conserved quantity. 
(Hint: Show H  0  by applying the chain rule and invoking Hamilton’s equa-
tions.) Hence the trajectories lie on the contour curves H ( x, p )  C.
6.5.10 
(Inverse-square law) A particle moves in a plane under the influence of an 
inverse-square force. It is governed by the Hamiltonian H p r
p
h
r
k
r
( , ) =
+
−
2
2
2
2
2
 
where r  0 is the distance from the origin and p is the radial momentum. The 
parameters h and k are the angular momentum and the force constant, 
respectively. 
a) Suppose k  0, corresponding to an attractive force like gravity. Sketch 
the phase portrait in the ( r, p ) plane. (Hint: Graph the “effective potential” 
V ( r )  h2 / 2r2  k / r and then look for intersections with horizontal lines of 

190 
PHASE PLANE
height E . Use this information to sketch the contour curves H ( p, r )  E for 
various positive and negative values of E .)
b) Show that the trajectories are closed if k2 / 2h2  E  0, in which case the par-
ticle is “captured” by the force. What happens if E  0 ? What about E  0 ?
c) If k  0 (as in electric repulsion), show that there are no periodic orbits. 
6.5.11 
(Basins for damped double-well oscillator) Suppose we add a small 
amount of damping to the double-well oscillator of Example 6.5.2. The new system 
is 

x
y y
by
x
x
=
= −
+
−
,
,
3  where 0  b  1. Sketch the basin of attraction for 
the stable fixed point ( x*, y*)  (1, 0). Make the picture large enough so that the 
global structure of the basin is clearly indicated.
6.5.12 
(Why we need to assume isolated minima in Theorem 6.5.1) Consider the 
system 

x
xy
y
x
=
= −
,
2 .
a) Show that E  x2  y2 is conserved.
b) Show that the origin is a fixed point, but not an isolated fixed point.
c) Since E has a local minimum at the origin, one might have thought that the ori-
gin has to be a center. But that would be a misuse of Theorem 6.5.1; the theorem 
does not apply here because the origin is not an isolated fixed point. Show that 
in fact the origin is not surrounded by closed orbits, and sketch the actual phase 
portrait.
6.5.13 
(Nonlinear centers)
a) Show that the Duffing equation x
x
x
+
+
=
F
3
0  has a nonlinear center at the 
origin for all F  0.
b) If F  0, show that all trajectories near the origin are closed. What about 
trajectories that are far from the origin?
6.5.14 
(Glider) Consider a glider flying at speed v at an angle R to the horizontal. 
Its motion is governed approximately by the dimensionless equations


v
Dv
v
v
= −
−
= −
+
sin
cos
R
R
R
2
2
where the trigonometric terms represent the effects of gravity and the v2 terms 
represent the effects of drag and lift.
a) Suppose there is no drag ( D  0). Show that v3  3v cos R is a conserved quan-
tity. Sketch the phase portrait in this case. Interpret your results physically—
what does the flight path of the glider look like?
b) Investigate the case of positive drag ( D  0).
In the next four exercises, we return to the problem of a bead on a rotating 
hoop, discussed in Section 3.5. Recall that the bead’s motion is governed by 
mr
b
mg
mr


φ
φ
φ
ω
φ
φ
= −
−
+
sin
sin
cos .
2

191
EXERCISES
Previously, we could only treat the overdamped limit. The next four exercises deal 
with the dynamics more generally.
6.5.15 
(Frictionless bead) Consider the undamped case b  0.
a) Show that the equation can be nondimensionalized to G´  sin G (cos G  H1 ), 
where H  rX2 / g as before, and prime denotes differentiation with respect to 
dimensionless time U  X t.
b) Draw all the qualitatively different phase portraits as H varies.
c) What do the phase portraits imply about the physical motion of the bead?
6.5.16 
(Small oscillations of the bead) Return to the original dimensional vari-
ables. Show that when b  0 and X is sufficiently large, the system has a symmet-
ric pair of stable equilibria. Find the approximate frequency of small oscillations 
about these equilibria. (Please express your answer with respect to t, not U.)
6.5.17 
(A puzzling constant of motion for the bead) Find a conserved quantity 
when b  0. You might think that it’s essentially the bead’s total energy, but it 
isn’t! Show explicitly that the bead’s kinetic plus potential energy is not conserved. 
Does this make sense physically? Can you find a physical interpretation for the 
conserved quantity? (Hint: Think about reference frames and moving constraints.)
6.5.18 
(General case for the bead) Finally, allow the damping b to be arbitrary. 
Define an appropriate dimensionless version of b, and plot all the qualitatively 
different phase portraits that occur as b and H vary.
6.5.19 
(Rabbits vs. foxes) The model 

R
aR
bRF
F
cF
dRF
=
−
= −
+
,
 is the 
Lotka-Volterra predator-prey model. Here R ( t ) is the number of rabbits, F  ( t ) is the 
number of foxes, and a, b, c, d  0 are parameters.
a) Discuss the biological meaning of each of the terms in the model. Comment on 
any unrealistic assumptions.
b) Show that the model can be recast in dimensionless form as x
x
y
′ =
−
(
),
1
 
′
(
1).
y
y x
N


c) Find a conserved quantity in terms of the dimensionless variables.
d) Show that the model predicts cycles in the populations of both species, for 
almost all initial conditions.
This model is popular with many textbook writers because it’s simple, but 
some are beguiled into taking it too seriously. Mathematical biologists dismiss the 
Lotka-Volterra model because it is not structurally stable, and because real pred-
ator-prey cycles typically have a characteristic amplitude. In other words, realistic 
models should predict a single closed orbit, or perhaps finitely many, but not a 
continuous family of neutrally stable cycles. See the discussions in May (1972), 
Edelstein-Keshet (1988), or Murray (2002).
6.5.20 
(Rock-paper-scissors)  In the children’s hand game of rock-paper-scissors, 
rock beats scissors (by smashing it); scissors beats paper (by cutting it); and paper 

192 
PHASE PLANE
beats rock (by covering it). In a biological setting, analogs of this non-transitive 
competition occur among certain types of bacteria (Kirkup and Riley 2004) and 
lizards (Sinervo and Lively 1996). 
Consider the following idealized model for three competing species locked in a 
life-and-death game of rock-paper-scissors:



P
P R
S
R
R S
P
S
S P
R
=
−
=
−
=
−
(
)
(
)
(
),
where P, R, and S (all positive, of course) are the sizes of the paper, rock, and scis-
sors populations.
a)  Write a few sentences explaining the various terms in these equations. Be sure 
to comment on why a given term has a plus or minus sign in front of it. You 
don’t have to write much—just enough to demonstrate that you understand 
how the form of the equations reflects the rock-paper-scissors story. Also, state 
some of the biological assumptions being made here implicitly.
b)  Show that P
R
S


 is a conserved quantity. 
c)  Show that PRS  is also conserved.
d)  How does the system behave as t →∞? Prove that your answer is correct. 
(Hint: Visualize the level sets of the functions E P R S
P
R
S
1( ,
, ) =
+
+
 and 
E
P R S
PRS
2( ,
, ) 
 in the three-dimensional ( ,
, )
P R S  space. What can you 
infer from the fact that all trajectories must simultaneously lie in level sets of 
both functions?) 
6.6 Reversible Systems
Show that each of the following systems is reversible, and sketch the phase portrait.
6.6.1 


x
y
x
y
y
=
−
= −
(
),
1
1
2
2
6.6.2 


x
y
y
x
y


,
cos
6.6.3 
(Wallpaper) Consider the system 

x
y
y
x


sin ,
sin .
a) Show that the system is reversible.
b) Find and classify all the fixed points.
c) Show that the lines y  ox are invariant (any trajectory that starts on them 
stays on them forever).
d) Sketch the phase portrait.
6.6.4 
(Computer explorations) For each of the following reversible systems, try 
to sketch the phase portrait by hand. Then use a computer to check your sketch. If 
the computer reveals patterns you hadn’t anticipated, try to explain them.
a) 

x
x
x
+
+
=
( )2
3  b) 

x
y
y
y
x
y
=
−
=
3,
cos
  c) 

x
y
y
y
x
=
=
−
sin ,
2

193
EXERCISES
6.6.5 
Consider equations of the form 

x
f x
g x
+
+
=
( )
( )
,0  where f is an even 
function, and both f and g are smooth.
a) Show that the equation is invariant under the pure time-reversal symmetry 
t l t.
b) Show that the equilibrium points cannot be stable nodes or spirals.
6.6.6 
(Manta ray) Use qualitative arguments to deduce the “manta ray” phase 
portrait of Example 6.6.1.
a) Plot the nullclines x  0  and y  0.
b) Find the sign of  
x y
,
 in different regions of the plane.
c) Calculate the eigenvalues and eigenvectors of the saddle points at (1, o1).
d) Consider the unstable manifold of (1, 1). By making an argument about the 
signs of  
x y
, ,  prove that this unstable manifold intersects the negative x-axis. 
Then use reversibility to prove the existence of a heteroclinic trajectory con-
necting (1, 1) to (1, 1).
e) Using similar arguments, prove that another heteroclinic trajectory exists, and 
sketch several other trajectories to fill in the phase portrait.
6.6.7 
(Oscillator with both positive and negative damping) Show that the sys-
tem 

x
xx
x
+
+
= 0  is reversible and plot the phase portrait.
6.6.8 
(Reversible system on a cylinder) While studying chaotic streamlines 
inside a drop immersed in a steady Stokes flow, Stone et al. (1991) encountered the 
system


x
x x
x
=
−
=
−
−
⎡
⎣⎢
⎤
⎦⎥
2
4
1
2
1
2
1
8 2
1
(
)sin ,
cos
cos
φ
φ
β
φ
φ
where 0 b x b 1 and Q b G b Q
Since the system is 2Q-periodic in G, it may be considered as a vector field on 
a cylinder. (See Section 6.7 for another vector field on a cylinder.) The x-axis runs 
along the cylinder, and the G-axis wraps around it. Note that the cylindrical phase 
space is finite, with edges given by the circles x  0 and x  1.
a) Show that the system is reversible.
b) Verify that for 
9
8 2
1
2


C
, the system has three fixed points on the cylinder, 
one of which is a saddle. Show that this saddle is connected to itself by a homo-
clinic orbit that winds around the waist of the cylinder. Using reversibility, 
prove that there is a band of closed orbits sandwiched between the circle x  0 
and the homoclinic orbit. Sketch the phase portrait on the cylinder, and check 
your results by numerical integration.
c) Show that as C l
1
2  from above, the saddle point moves toward the circle 
x  0, and the homoclinic orbit tightens like a noose. Show that all the closed 
orbits disappear when C 
1
2 .
d) For 0
1
2


C
, show that there are two saddle points on the edge x  0. Plot 
the phase portrait on the cylinder.

194 
PHASE PLANE
6.6.9 
(Josephson junction array) As discussed in Exercises 4.6.4 and 4.6.5, the 
equations
d
d
a
k
k
k
N
j
N
j
φ
τ
φ
φ
=
+
+
=
=∑
Ω
sin
sin
, ,
1
1
1 2
, for 
arise as the dimensionless circuit equations for a resistively loaded array of 
Josephson junctions.
a) Let θ
φ
π
k
k
=
−2 , and show that the resulting system for Rk is reversible.
b) Show that there are four fixed points (mod 2Q) when Ω (
)
a +
<
1
1, and none 
when Ω (
)
a +
>
1
1.
c) Using the computer, explore the various phase portraits that occur for a  1, as 
8 varies over the interval 0 b 8 b 3.
For more about this system, see Tsang et al. (1991).
6.6.10 
Is the origin a nonlinear center for the system 

x
y
x
y
x
= −−
=
2,
?
6.6.11 
(Rotational dynamics and a phase portrait on a sphere) The rotational 
dynamics of an object in a shear flow are governed by


θ
φ
θ
φ
φ
φ
θ
=
=
+
cot
cos ,
(cos
sin
)sin ,
2
2
A
where R and G are spherical coordinates that describe the orientation of the object. 
Our convention here is that −<
≤
π
θ
π  is the “longitude,” i.e., the angle around 
the z-axis, and −≤
≤
π
π
φ
2
2  is the “latitude,” i.e., the angle measured northward 
from the equator. The parameter A depends on the shape of the object.
a) Show that the equations are reversible in two ways: under t l t, R l R and 
under t l t, G l G.
b) Investigate the phase portraits when A is positive, zero, and negative. You may 
sketch the phase portraits as Mercator projections (treating R and G as rectan-
gular coordinates), but it’s better to visualize the motion on the sphere, if you 
can.
c) Relate your results to the tumbling motion of an object in a shear flow. What 
happens to the orientation of the object as t l d ?
6.7 Pendulum
6.7.1 
(Damped pendulum) Find and classify the fixed points of 
 

R
R
R
+
+
=
b
sin
0  for all b  0, and plot the phase portraits for the qualitatively 
different cases.
6.7.2 
(Pendulum driven by constant torque) The equation θ
θ
γ
+
=
sin
 
describes the dynamics of an undamped pendulum driven by a constant torque, 
or an undamped Josephson junction driven by a constant bias current.
a) Find all the equilibrium points and classify them as H varies.

195
EXERCISES
b) Sketch the nullclines and the vector field.
c) Is the system conservative? If so, find a conserved quantity. Is the system 
reversible?
d) Sketch the phase portrait on the plane as H varies.
e) Find the approximate frequency of small oscillations about any centers in the 
phase portrait.
6.7.3 
(Nonlinear damping) Analyze 

R
R R
R
+
+
+
=
(
cos )
sin
,
1
0
a
 for all a p 0.
6.7.4 
(Period of the pendulum) Suppose a pendulum governed by R
R
+
=
sin
0  
is swinging with an amplitude B. Using some tricky manipulations, we are going 
to derive a formula for T ( B ), the period of the pendulum.
a) Using conservation of energy, show that θ
θ
α
2
2
=
−
(cos
cos
)  and hence that
T
d
=
−
[
]
∫
4
2
1 2
0
θ
θ
α
α
(cos
cos
)
.
b) Using the half-angle formula, show that T
d
=
−
⎡⎣⎢
⎤⎦⎥
∫
4
4
2 1
2
2 1
2
1 2
0
θ
α
θ
α
(sin
sin
)
.
/
c) The formulas in parts (a) and (b) have the disadvantage that B appears in both 
the integrand and the upper limit of integration. To remove the B-dependence 
from the limits of integration, we introduce a new angle G that runs from 0 to Q
2
when R runs from 0 to B. Specifically, let (sin
)sin
sin
.
1
2
1
2
α
φ
θ

 Using this sub-
stitution, rewrite (b) as an integral with respect to G. Thereby derive the exact 
result
T
d
K
=
=
∫
4
4
1
2
2 1
2
0
2
φ
θ
α
π
cos
(sin
),
where the complete elliptic integral of the first kind is defined as
K m
d
m
m
(
)
(
sin
)
,
.
=
−
≤
≤
∫
φ
φ
π
1
0
1
2
1 2
0
2
 for 
d) By expanding the elliptic integral using the binomial series and integrating 
term-by-term, show that
T
O
( )
(
)
.
α
π
α
α
α
=
+
+
⎡⎣⎢
⎤⎦⎥
<<
2
1
1
1
16
2
4
 for 
Note that larger swings take longer.
6.7.5 
(Numerical solution for the period) Redo Exercise 6.7.4 using either 
numerical integration of the differential equation, or numerical evaluation of the 
elliptic integral. Specifically, compute the period T ( B ), where B runs from 0 to 
180° in steps of 10°.

196 
PHASE PLANE
6.8 Index Theory
6.8.1 
Show that each of the following fixed points has an index equal to 1.
a) stable spiral b) unstable spiral c) center d) star e) degenerate node
(Unusual fixed points) For each of the following systems, locate the fixed points 
and calculate the index. (Hint: Draw a small closed curve C around the fixed point 
and examine the variation of the vector field on C.)
6.8.2 


x
x
y
y


2,
  
6.8.3 


x
y
x
y
x
=
−
=
,
2
6.8.4 


x
y
y
x


3,
  
6.8.5 


x
xy
y
x
y
=
=
+
,
6.8.6 
A closed orbit in the phase plane encircles S saddles, N nodes, F spi-
rals, and C centers, all of the usual type. Show that N  F  C  1  S.
6.8.7 
(Ruling out closed orbits) Use index theory to show that the system 


x
x
y
x
y
y x
=
−−
=
−
(
),
(
)
4
1
2
 has no closed orbits.
6.8.8 
A smooth vector field on the phase plane is known to have exactly three 
closed orbits. Two of the cycles, say C1 and C2, lie inside the third cycle C3. 
However, C1 does not lie inside C2, nor vice-versa.
a) Sketch the arrangement of the three cycles.
b) Show that there must be at least one fixed point in the region bounded by C1, C2, 
C3.
6.8.9 
A smooth vector field on the phase plane is known to have exactly two 
closed trajectories, one of which lies inside the other. The inner cycle runs clock-
wise, and the outer one runs counterclockwise. True or False: There must be at 
least one fixed point in the region between the cycles. If true, prove it. If false, 
provide a simple counterexample.
6.8.10 
(Open-ended question for the topologically minded) Does Theorem 6.8.2 
hold for surfaces other than the plane? Check its validity for various types of closed 
orbits on a torus, cylinder, and sphere.
6.8.11 
 (Complex vector fields) Let z  x  iy. Explore the complex vector fields 
z
zk

 and z
z
k
 ( ) ,  where k  0 is an integer and z
x
iy
=
−
 is the complex 
conjugate of z.
a) Write the vector fields in both Cartesian and polar coordinates, for the cases 
k  1, 2, 3.
b) Show that the origin is the only fixed point, and compute its index.
c) Generalize your results to arbitrary integer k  0.
6.8.12 
(“Matter and antimatter”) There’s an intriguing analogy between bifur-
cations of fixed points and collisions of particles and anti-particles. Let’s explore 
this in the context of index theory. For example, a two-dimensional version of the 
saddle-node bifurcation is given by 

x
a
x
y
y
=
+
= −
2,
, where a is a parameter.
a) Find and classify all the fixed points as a varies from d to d.

197
EXERCISES
b) Show that the sum of the indices of all the fixed points is conserved as a varies.
c) State and prove a generalization of this result, for systems of the form 
x
f x
 ( , ),
a
 where x  R2 and a is a parameter.
6.8.13 
(Integral formula for the index of a curve) Consider a smooth vector field 


x
f x y
y
g x y


( , ),
( , )  on the plane, and let C be a simple closed curve that 
does not pass through any fixed points. As usual, let G =
−
tan
(
)
1  
y x  as in 
Figure 6.8.1.
a) Show that dG  ( f dg  g df ) / ( f 2  g2 ). 
b) Derive the integral formula
I
f dg
g df
f
g
C
C
=
−
+
∫
1
2
2
2
Q
.
v
6.8.14 Consider the family of linear systems 
x
x
y
=
−
cos
sin
B
B , 
y
x
y
=
+
sin
cos ,
B
B  where B is a parameter that runs over the range 0 b B b Q.
Let C be a simple closed curve that does not pass through the origin.
a) Classify the fixed point at the origin as a function of B.
b) Using the integral derived in Exercise 6.8.13, show that IC is independent of B.
c) Let C be a circle centered at the origin. Compute IC  explicitly by evaluating the 
integral for any convenient choice of B.

198 
LIMIT CYCLES
7
LIMIT CYCLES
7.0 Introduction
A limit cycle is an isolated closed trajectory. Isolated means that neighboring 
trajectories are not closed; they spiral either toward or away from the limit cycle 
(Figure 7.0.1).
stable
limit cycle
unstable
limit cycle
half-stable
limit cycle
Figure 7.0.1
If all neighboring trajectories approach the limit cycle, we say the limit cycle is 
stable or attracting. Otherwise the limit cycle is unstable, or in exceptional cases, 
half-stable.
Stable limit cycles are very important scientifically—they model systems that 
exhibit self-sustained oscillations. In other words, these systems oscillate even in 
the absence of external periodic forcing. Of the countless examples that could be 
given, we mention only a few: the beating of a heart; the periodic firing of a pace-
maker neuron; daily rhythms in human body temperature and hormone secretion; 
chemical reactions that oscillate spontaneously; and dangerous self-excited vibra-
tions in bridges and airplane wings. In each case, there is a standard oscillation 
of some preferred period, waveform, and amplitude. If the system is perturbed 
slightly, it always returns to the standard cycle.

199
7.1 EXAMPLES
Limit cycles are inherently nonlinear phenomena; they can’t occur in linear sys-
tems. Of course, a linear system x
x
 A
 can have closed orbits, but they won’t be 
isolated; if x( t ) is a periodic solution, then so is cx( t ) for any constant c v 0. Hence 
x( t ) is surrounded by a one-parameter family of closed orbits (Figure  7.0.2). 
Consequently, the amplitude of a linear oscillation 
is set entirely by its initial conditions; any slight dis-
turbance to the amplitude will persist forever. In 
contrast, limit cycle oscillations are determined by 
the structure of the system itself.
The next section presents two examples of sys-
tems with limit cycles. In the first case, the limit 
cycle is obvious by inspection, but normally it’s 
difficult to tell whether a given system has a limit 
cycle, or indeed any closed orbits, from the govern-
ing equations alone. Sections 7.2-7.4 present some 
techniques for ruling out closed orbits or for prov-
ing their existence. The remainder of the chapter discusses analytical methods for 
approximating the shape and period of a closed orbit and for studying its stability.
7.1 Examples
It’s straightforward to construct examples of limit cycles if we use polar coordinates.
EXAMPLE 7.1.1: A SIMPLE LIMIT CYCLE
Consider the system


r
r
r
=
−
=
(
),
1
1
2
R
 
(1)
where r p 0. The radial and angular dynamics are uncoupled and so can be ana-
lyzed separately. Treating r
r
r
=
−
(
)
1
2  as a vector field on the line, we see that 
r*  0 is an unstable fixed point and r*  1 is stable (Figure 7.1.1).
r
r
1
.
Figure 7.1.1
cx(t)
x(t)
Figure 7.0.2

200 
LIMIT CYCLES
Hence, back in the phase plane, all tra-
jectories (except r*    0) approach the 
unit circle r*  1 monotonically. Since 
the motion in the R-direction is simply 
rotation at constant angular velocity, 
we see that all trajectories spiral asymp-
totically toward a limit cycle at r    1 
(Figure 7.1.2).
It is also instructive to plot solu-
tions as functions of t. For instance, in 
Figure 7.1.3 we plot x ( t )  r ( t ) cosR ( t ) 
for a trajectory starting outside the limit 
cycle. As expected, the solution settles down to a sinusoidal oscillation of constant 
amplitude, corresponding to the limit cycle solution x ( t )  cos ( t  R0 ) of (1). ■
x
t
2
0
25
−2
Figure 7.1.3
EXAMPLE 7.1.2: VAN DER POL OSCILLATOR
A less transparent example, but one that played a central role in the development 
of nonlinear dynamics, is given by the van der Pol equation
2
(
1)
0
x
x
x
x
N






 
(2)
where N p 0 is a parameter. Historically, this equation arose in connection with the 
nonlinear electrical circuits used in the first radios (see Exercise 7.1.6 for the cir-
cuit). Equation (2) looks like a simple harmonic oscillator, but with a nonlinear 
damping term 
2
(
1) .
x
x
N

  This term acts like ordinary positive damping for |x|  
1, but like negative damping for |x| l. In other words, it causes large-amplitude 
oscillations to decay, but it pumps them back up if they become too small.
As you might guess, the system eventually settles into a self-sustained oscilla-
tion where the energy dissipated over one cycle balances the energy pumped in. 
y
x
Figure 7.1.2

201
7.2 RULING OUT CLOSED ORBITS
This idea can be made rigorous, and with quite a bit of work, one can prove that 
the van der Pol equation has a unique, stable limit cycle for each N  0. This result 
follows from a more general theorem discussed in Section 7.4.
To give a concrete illustration, suppose we numerically integrate (2) for N  1.5, 
starting from ( , )
x x   (0.5, 0) at t  0. Figure 7.1.4 plots the solution in the phase 
plane and Figure 7.1.5 shows the graph of x ( t ). Now, in contrast to Example 7.1.1, 
the limit cycle is not a circle and the stable waveform is not a sine wave. ■
x
3
3
−3
−3
.
x
Figure 7.1.4
  
x
t
3
0
10
20
−3
Figure 7.1.5
7.2 Ruling Out Closed Orbits
Suppose we have a strong suspicion, based on numerical evidence or otherwise, 
that a particular system has no periodic solutions. How could we prove this? In the 
last chapter we mentioned one method, based on index theory (see Examples 6.8.5 
and 6.8.6). Now we present three other ways of ruling out closed orbits. They are 
of limited applicability, but they’re worth knowing about, in case you get lucky.
Gradient Systems
Suppose the system can be written in the form x = −∇V,  for some continu-
ously differentiable, single-valued scalar function V (x). Such a system is called a 
gradient system with potential function V.
Theorem 7.2.1: Closed orbits are impossible in gradient systems.
Proof: Suppose there were a closed orbit. We obtain a contradiction by 
considering the change in V after one circuit. On the one hand, %V  0 since V is 
single-valued. But on the other hand,

202 
LIMIT CYCLES
ΔV
dV
dt dt
V
dt
dt
T
T
T
=
=
∇⋅
= −
<
∫
∫
∫
0
0
2
0
0
(
)


x
x
(unless x w 0,  in which case the trajectory is a fixed point, not a closed orbit). This 
contradiction shows that closed orbits can’t exist in gradient systems. ■
The trouble with Theorem 7.2.1 is that most two-dimensional systems are not 
gradient systems. (Although, curiously, all vector fields on the line are gradient 
systems; this gives another explanation for the absence of oscillations noted in 
Sections 2.6 and 2.7.)
EXAMPLE 7.2.1:
Show that there are no closed orbits for the system x
y
 sin ,  y
x
y

cos .
Solution: The system is a gradient system with potential function V ( x,y )  
–x sin y, since x
V
x
= −∂
∂ and y
V
y
= −∂
∂. By Theorem 7.2.1, there are no 
closed orbits. ■
How can you tell whether a system is a gradient system? And if it is, how do you 
find its potential function V ? See Exercises 7.2.5 and 7.2.6.
Even if the system is not a gradient system, similar techniques may still work, as 
in the following example. We examine the change in an energy-like function after 
one circuit around the putative closed orbit, and derive a contradiction.
EXAMPLE 7.2.2:
Show that the nonlinearly damped oscillator 

x
x
x
+
+
=
( )3
0  has no periodic 
solutions.
Solution: Suppose that there were a periodic solution x ( t ) of period T. Consider 
the energy function E x x
x
x
,
(
).


(
)=
+
1
2
2
2
 After one cycle, x and x  return to their 
starting values, and therefore %E  0 around any closed orbit.
On the other hand, ΔE
Edt
T
= ∫

0
. If we can show this integral is nonzero, 
we’ve reached a contradiction. Note that 





E
x x
x
x
x
x
=
+
(
)=
−
= −
≤
(
)
.
3
4
0  
Therefore ΔE
x
dt
T
= −
≤
∫
( )
,
 4
0
0  with equality only if x w 0.  But x w 0  would 
mean the trajectory is a fixed point, contrary to the original assumption that it’s a 

203
7.2 RULING OUT CLOSED ORBITS
closed orbit. Thus %E is strictly negative, which contradicts %E  0. Hence there 
are no periodic solutions. ■
Liapunov Functions
Even for systems that have nothing to do with mechanics, it is occasionally pos-
sible to construct an energy-like function that decreases along trajectories. Such a 
function is called a Liapunov function. If a Liapunov function exists, then closed 
orbits are forbidden, by the same reasoning as in Example 7.2.2.
To be more precise, consider a system x
f x
 ( )  with a fixed point at x*. Suppose 
that we can find a Liapunov function, i.e., a continuously differentiable, real-valued 
function V (x) with the following properties: 
1. V (x)  0 for all x v x*, and V (x*)  0. (We say that V is positive definite.)
2. V  0  for all x v x*. (All trajectories flow “downhill” toward x*.)
Then x* is globally asymptotically stable: for all initial conditions, x( t ) l x* as 
t l d. In particular the system has no closed orbits. (For a proof, see Jordan and 
Smith 1987.)
The intuition is that all trajectories move monotonically down the graph of V (x) 
toward x* (Figure 7.2.1).
x (t)
x*
V(x)
Figure 7.2.1
The solutions can’t get stuck anywhere else because if they did, V would stop 
changing, but by assumption, V  0  everywhere except at x*.
Unfortunately, there is no systematic way to construct Liapunov functions. 
Divine inspiration is usually required, although sometimes one can work back-
wards. Sums of squares occasionally work, as in the following example.
EXAMPLE 7.2.3:
By constructing a Liapunov function, show that the system x
x
y
= −+ 4 ,  
y
x
y
= −−
3  has no closed orbits.
Solution: Consider V ( x,y )  x2 ay2, where a is a parameter to be chosen later.
Then 


V
xx
ayy
x
x
y
ay
x
y
x
a xy
ay
=
+
=
−+
+
−−
= −
+
−
−
2
2
2
2
2
2
2
3
2
4
(
)
(
)
(
)
4
8 
. 

204 
LIMIT CYCLES
If we choose a  4, the xy term disappears and V
x
y
= −
−
2
2
4
8
.  By inspection, 
V  0 and V  0  for all ( x,y ) v (0,0). Hence V  x2  4y2 is a Liapunov function 
and so there are no closed orbits. In fact, all trajectories approach the origin as 
t  l d. ■
Dulac’s Criterion
The third method for ruling out closed orbits is based on Green’s theorem, and 
is known as Dulac’s criterion.
Dulac’s Criterion: Let x
f
 ( )
x  be a continuously differentiable vector 
field defined on a simply connected subset R of the plane. If there exists a continu-
ously differentiable, real-valued function g (x) such that  ∇⋅(
)
gx  has one sign 
throughout R, then there are no closed orbits lying entirely in R.
Proof: Suppose there were a closed orbit C lying entirely in the region R. 
Let A denote the region inside C (Figure 7.2.2). Then Green’s theorem yields
∇⋅
=
⋅
∫
∫∫
(
)
g
dA
g
d
C
A


ℓ

x
x n 
where n is the outward normal and dA  is the element of arc length along C. Look 
first at the double integral on the left: it must be nonzero, since ∇⋅(
)
gx  has one 
sign in R. On the other hand, the line integral on the right equals zero since 
x n
⋅
= 0  everywhere, by the assumption that C is a trajectory (the tangent vector 
x  is orthogonal to n). This contradiction implies that no such C can exist. ■
n
x.
C
R
A
Figure 7.2.2
Dulac’s criterion suffers from the same drawback as Liapunov’s method: there 
is no algorithm for finding g (x). Candidates that occasionally work are g  1, 
1 / xayb, eax, and eay.
EXAMPLE 7.2.4:
Show that the system x
x
x
y
=
−−
(
),
2
 y
y
x
x
=
−
−
(
)
4
 3
2
 has no closed orbits 
in the positive quadrant x, y  0.

205
7.3 POINCARÉ-BENDIXSON THEOREM
Solution: A hunch tells us to pick g  1 / xy. Then
∇⋅
= ∂
∂
+ ∂
∂
= ∂
∂
−−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟+ ∂
∂
−
−
(
)
(
)
(
)
g
x gx
y gy
x
x
y
y
y
x
x



x
2
4
3
2
x
y
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
= −
<
1
0
/
.
Since the region x, y  0 is simply connected and g and f satisfy the required 
smoothness conditions, Dulac’s criterion implies there are no closed orbits in the 
positive quadrant. ■
EXAMPLE 7.2.5:
Show that the system x
y
 , y
x
y
x
y
= −−
+
+
2
2  has no closed orbits. 
Solution: Let g  e2x. Then ∇⋅(
)= −
+
−+
= −
<
−
−
−
g
e
y
e
y
e
x
x
x
x
2
1
2
2
2
2
0
(
)
.  
By Dulac’s criterion, there are no closed orbits. ■
7.3 Poincaré−Bendixson Theorem
Now that we know how to rule out closed orbits, we turn to the opposite task: 
finding methods to establish that closed orbits exist in particular systems. The fol-
lowing theorem is one of the few results in this direction. It is also one of the key 
theoretical results in nonlinear dynamics, because it implies that chaos can’t occur 
in the phase plane, as discussed briefly at the end of this section.
Poincaré−Bendixson Theorem: Suppose that:
(1) 
R is a closed, bounded subset of the plane;
(2) 
x
f x
 ( )  is a continuously differentiable vector field on an open set con-
taining R;
(3) 
R does not contain any fixed points; and
(4) 
There exists a trajectory C that is “confined” in R, in the sense that it 
starts in R and stays in R for all future time (Figure 7.3.1).
Then either C is a closed orbit, or it spirals 
toward a closed orbit as t l d. In either 
case, R contains a closed orbit (shown as a 
heavy curve in Figure 7.3.1).
The proof of this theorem is subtle, 
and requires some advanced ideas from 
R
P
C
Figure 7.3.1

206 
LIMIT CYCLES
topology. For details, see Perko (1991), Coddington and Levinson (1955), Hurewicz 
(1958), or Cesari (1963).
In Figure 7.3.1, we have drawn R as a ring-shaped region because any closed 
orbit must encircle a fixed point ( P in Figure 7.3.1) and no fixed points are allowed 
in R.
When applying the Poincaré-Bendixson theorem, it’s easy to satisfy conditions 
(l)–(3); condition (4) is the tough one. How can we be sure that a confined trajectory 
C exists? The standard trick is to construct a trapping region R, i.e., a closed con-
nected set such that the vector field points “inward” everywhere on the boundary 
of R (Figure 7.3.2). Then all trajectories 
in R are confined. If we can also arrange 
that there are no fixed points in R, then 
the Poincaré-Bendixson theorem ensures 
that R contains a closed orbit.
The Poincaré-Bendixson theorem can 
be difficult to apply in practice. One con-
venient case occurs when the system has 
a simple representation in polar coordi-
nates, as in the following example.
EXAMPLE 7.3.1:
Consider the system


r
r
r
r
=
−
+
=
(
)
cos
.
1
1
2
μ
θ
θ
 
(1)
When N  0, there’s a stable limit cycle at r  1, as discussed in Example 7.1.1. Show 
that a closed orbit still exists for N  0, as long as N is sufficiently small.
Solution: We seek two concentric circles with radii rmin and rmax, such that r  0  
on the outer circle and r  0  on the inner circle. Then the annulus 0  rmin 
b r    b  rmax will be our desired trapping region. Note that there are no fixed points 
in the annulus since R  0; hence if rmin and rmax can be found, the Poincaré-
Bendixson theorem will imply the existence of a closed orbit.
To find rmin, we require 
2
(l 
)
cos
0
r
r
r
μr
R





 for all R. Since cos R p –1, a 
sufficient condition for rmin is 1 – r2 – N  0. Hence any 
min
1
r
μ


 will work, as 
long as N  1 so that the square root makes sense. We should choose rmin as large as 
possible, to hem in the limit cycle as tightly as we can. For instance, we could pick 
min
0.999 1
.
r
μ


 (Even 
min
1
r
μ


 works, but more careful reasoning is 
required.) By a similar argument, the flow is inward on the outer circle if 
max
1.00l 1
.
r
μ


R
Figure 7.3.2

207
7.3 POINCARÉ-BENDIXSON THEOREM
Therefore a closed orbit exists for all N  1, and it lies somewhere in the annulus 
0.999 1
1.001 1
.
μ
r
μ

 

 ■
The estimates used in Example 7.3.1 are conservative. In fact, the closed orbit 
can exist even if N p 1. Figure 7.3.3 shows a computer-generated phase portrait of 
(1) for N  1. In Exercise 7.3.8, you’re asked to explore what happens for larger N, 
and in particular, whether there’s a critical N beyond which the closed orbit disap-
pears. It’s also possible to obtain some analytical insight about the closed orbit for 
small N (Exercise 7.3.9).
x
y
1
1
limit
cycle
−1
−1
Figure 7.3.3
When polar coordinates are inconvenient, we may still be able to find an appro-
priate trapping region by examining the system’s nullclines, as in the next example.
EXAMPLE 7.3.2:
In the fundamental biochemical process called glycolysis, living cells obtain energy 
by breaking down sugar. In intact yeast cells as well as in yeast or muscle extracts, 
glycolysis can proceed in an oscillatory fashion, with the concentrations of various 
intermediates waxing and waning with a period of several minutes. For reviews, 
see Chance et al. (1973) or Goldbeter (1980).
A simple model of these oscillations has been proposed by Sel’kov (1968). In 
dimensionless form, the equations are


x
x
ay
x y
y
b
ay
x y
= −+
+
=
−
−
2
2

208 
LIMIT CYCLES
where x and y are the concentrations of ADP (adenosine diphosphate) and F6P 
(fructose-6-phosphate), and a,b  0 are kinetic parameters. Construct a trapping 
region for this system.
Solution: First we find the nullclines. The first equation shows that x  0  on 
the curve y  x / ( a  x2 ) and the second equation shows that y  0  on the curve 
y  b / ( a  x2 ). These nullclines are sketched in Figure 7.3.4, along with some rep-
resentative vectors.
y
x
x
x
0
0
0
0
y
y
,
<
<
>
<
.
.
.
0
y>
0
y<
.
.
x
0
>
.
x
0
>
.
y
y
=
=
x/(a+x2)
b / (a+x2)
Figure 7.3.4
How did we know how to sketch these vectors? By definition, the arrows are verti-
cal on the x  0  nullcline, and horizontal on the y  0  nullcline. The direction of 
flow is determined by the signs of x  and y. For instance, in the region above both 
nullclines, the governing equations imply x  0  and y  0 , so the arrows point 
down and to the right, as shown in Figure 7.3.4.
Now consider the region bounded by the dashed line shown in Figure 7.3.5. We 
claim that it’s a trapping region. To verify this, we have to show that all the vectors 
on the boundary point into the box. On the horizontal and vertical sides, there’s no 
problem: the claim follows from Figure 7.3.4. The tricky part of the construction 
is the diagonal line of slope –1 extending from the point ( b, b / a ) to the nullcline 
y  x / ( a  x2 ). Where did this come from?

209
7.3 POINCARÉ-BENDIXSON THEOREM
b / (a+x2)
x/ (a+x2)
y=
=
y
x
y
b
(b, b/a)
b/a
Figure 7.3.5
To get the right intuition, consider x  and y in the limit of very large x. Then 
x
x y
x
2
 and y
x y
≈−
2
, so 

y x
dy dx
/
=
≈−1 along trajectories. Hence the vec-
tor field at large x is roughly parallel to the diagonal line. This suggests that in a 
more precise calculation, we should compare the sizes of x  and y , for some 
sufficiently large x.
In particular, consider 

x
y
−−
(
). We find


x
y
x
ay
x y
b
ay
x y
b
x
−−
= −
+
+
+
−
−
=
−
(
)
(
)
.
2
2
Hence
−>
>


y
x
x
b
if 
.
This inequality implies that the vector field points inward on the diagonal line in 
Figure 7.3.5, because dy / dx is more negative than –1, and therefore the vectors are 
steeper than the diagonal line. Thus the region is a trapping region, as claimed. ■
Can we conclude that there is a closed orbit inside the trapping region? No! 
There is a fixed point in the region (at the intersection of the nullclines), and so the 
conditions of the Poincaré−Bendixson theorem are not satisfied. But if this fixed 
point is a repeller, then we can prove the existence of a closed orbit by considering 

210 
LIMIT CYCLES
the modified “punctured” region shown in Figure 7.3.6. (The hole is infinitesimal, 
but drawn larger for clarity.)
y
x
Figure 7.3.6
The repeller drives all neighboring trajectories into the shaded region, and since 
this region is free of fixed points, the Poincaré-Bendixson theorem applies. 
Now we find conditions under which the fixed point is a repeller.
EXAMPLE 7.3.3:
Once again, consider the glycolytic oscillator x
x
ay
x y
= −+
+
2 ,  y
b
ay
x y
=
−
− 
2
 
of Example 7.3.2. Prove that a closed orbit exists if a and b satisfy an appropriate 
condition, to be determined. (As before, a,b  0.)
Solution: By the argument above, it suffices to find conditions under which the 
fixed point is a repeller, i.e., an unstable node or spiral. In general, the Jacobian is
A
xy
a
x
xy
a
x
= −+
+
−
−
+
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
1
2
2
2
2
(
)
.
After some algebra, we find that at the fixed point
x
b
y
b
a
b
*
,
*
,
=
=
+
2
the Jacobian has determinant %  a  b2  0 and trace

211
7.3 POINCARÉ-BENDIXSON THEOREM
U = −
+
−
+
+
+
b
a
b
a
a
a
b
4
2
2
2
2
1
(
)
(
).
Hence the fixed point is unstable for U  0, and stable for U  0. The dividing line 
U  0 occurs when
b
a
a
2
1
2 1
2
1
8
=
−
±
−
(
).
This defines a curve in ( a,b ) space, as shown in Figure 7.3.7.
b
a
1.2
1
0.8
0.6
stable
limit cycle
stable
fixed point
0.4
0.2
0
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
Figure 7.3.7
For parameters in the region corresponding to U  0, we are guaranteed that the 
system has a closed orbit—numerical integration shows that it is actually a stable 
limit cycle. Figure 7.3.8 shows a computer-generated phase portrait for the typical 
case a  0.08, b  0.6. ■
y
x
2
2
3
1
1
Figure 7.3.8

212 
LIMIT CYCLES
No Chaos in the Phase Plane
The Poincaré-Bendixson theorem is one of the central results of nonlinear 
dynamics. It says that the dynamical possibilities in the phase plane are very lim-
ited: if a trajectory is confined to a closed, bounded region that contains no fixed 
points, then the trajectory must eventually approach a closed orbit. Nothing more 
complicated is possible.
This result depends crucially on the two-dimensionality of the plane. In 
higher-dimensional systems ( n p 3), the Poincaré-Bendixson theorem no longer 
applies, and something radically new can happen: trajectories may wander around 
forever in a bounded region without settling down to a fixed point or a closed orbit. 
In some cases, the trajectories are attracted to a complex geometric object called a 
strange attractor, a fractal set on which the motion is aperiodic and sensitive to tiny 
changes in the initial conditions. This sensitivity makes the motion unpredictable 
in the long run. We are now face to face with chaos. We’ll discuss this fascinating 
topic soon enough, but for now you should appreciate that the Poincaré-Bendixson 
theorem implies that chaos can never occur in the phase plane.
7.4 Liénard Systems
In the early days of nonlinear dynamics, say from about 1920 to 1950, there was a 
great deal of research on nonlinear oscillations. The work was initially motivated 
by the development of radio and vacuum tube technology, and later it took on a 
mathematical life of its own. It was found that many oscillating circuits could be 
modeled by second-order differential equations of the form


x
f x x
g x
+
+
=
( )
( )
,0  
(1)
now known as Liénard’s equation. This equation is a generalization of the van der 
Pol oscillator 
2
(
1)
0
x
μ x
x
x






 mentioned in Section 7.1. It can also be 
interpreted mechanically as the equation of motion for a unit mass subject to a 
nonlinear damping force f x x
( )   and a nonlinear restoring force g x
( ).
Liénard’s equation is equivalent to the system


x
y
y
g x
f x y
=
= −
−
( )
( ) . 
(2)
The following theorem states that this system has a unique, stable limit cycle under 
appropriate hypotheses on f and g. For a proof, see Jordan and Smith (1987), 
Grimshaw (1990), or Perko (1991).
Liénard’s Theorem: Suppose that f  ( x ) and g ( x ) satisfy the following 
conditions:

213
7.5 RELAXATION OSCILLATIONS
(1) 
f  ( x ) and g ( x ) are continuously differentiable for all x;
(2) 
g ( –x )  –g ( x ) for all x (i.e., g ( x ) is an odd function);
(3) 
g ( x )  0 for x  0;
(4) 
f  ( –x )  f  ( x ) for all x (i.e., f  ( x ) is an even function);
(5) 
The odd function F x
f u du
x
( )
( )
= ∫0
 has exactly one positive zero at 
x  a, is negative for 0  x  a, is positive and nondecreasing for x  a, 
and F  ( x ) l d as x l d. 
Then the system (2) has a unique, stable limit cycle surrounding the origin in the 
phase plane.
This result should seem plausible. The assumptions on g ( x ) mean that the 
restoring force acts like an ordinary spring, and tends to reduce any displacement, 
whereas the assumptions on f  ( x ) imply that the damping is negative at small |x| 
and positive at large |x|. Since small oscillations are pumped up and large oscilla-
tions are damped down, it is not surprising that the system tends to settle into a 
self-sustained oscillation of some intermediate amplitude.
EXAMPLE 7.4.1:
Show that the van der Pol equation has a unique, stable limit cycle.
Solution: The van der Pol equation 
2
(
1)
0
x
μ x
x
x






 has f  ( x )  N ( x2 – 1) 
and g ( x )  x, so conditions (1)–(4) of Liénard’s theorem are clearly satisfied. To 
check condition (5), notice that
	

3
2
1
1
3
3
( )
(
3).
F x
x
x
x x
N
N




Hence condition (5) is satisfied for a 
3.  Thus the van der Pol equation has a 
unique, stable limit cycle. ■
There are several other classical results about the existence of periodic solu-
tions for Liénard’s equation and its relatives. See Stoker (1950), Minorsky (1962) 
Andronov et al. (1973), and Jordan and Smith (1987).
7.5 Relaxation Oscillations
It’s time to change gears. So far in this chapter, we have focused on a qualitative 
question: Given a particular two-dimensional system, does it have any periodic 
solutions? Now we ask a quantitative question: Given that a closed orbit exists, 
what can we say about its shape and period? In general, such problems can’t be 
solved exactly but we can still obtain useful approximations if some parameter is 
large or small.

214 
LIMIT CYCLES
We begin by considering the van der Pol equation 
2
(
1)
0
x
x
x
x
N






for N  1. In this strongly nonlinear limit, we’ll see that the limit cycle consists of 
an extremely slow buildup followed by a sudden discharge, followed by another 
slow buildup, and so on. Oscillations of this type are often called relaxation oscil-
lations, because the “stress” accumulated during the slow buildup is “relaxed” 
during the sudden discharge. Relaxation oscillations occur in many other scientific 
contexts, from the stick-slip oscillations of a bowed violin string to the periodic 
firing of nerve cells driven by a constant current (Edelstein−Keshet 1988, Murray 
2002, Rinzel and Ermentrout 1989).
EXAMPLE 7.5.1:
Give a phase plane analysis of the van der Pol equation for N  1. 
Solution: It proves convenient to introduce different phase plane variables from 
the usual “ x
y

, y . . .”. To motivate the new variables, notice that
	

2
3
1
3
(
1)
.
d
x
x x
x
x
x
dt
N
N  
¯





¡
°
¢
±



So if we let
3
1
3
( )
,
( ),
F x
x
x
w
x
F x
N





 
(1)
the van der Pol equation implies that
2
(
1)
.
w
x
x x
x
N



 



 
(2)
Hence the van der Pol equation is equivalent to (1), (2), which may be rewritten as
( )
.
x
w
F x
w
x
N


 


 
(3)
One further change of variables is helpful. If we let 
w
y
N

then (3) becomes
<
>
1
( )
.
x
y
F x
y
x
N
N


 


 
(4)

215
7.5 RELAXATION OSCILLATIONS
Now consider a typical trajectory in the ( x,y ) phase plane. The nullclines are 
the key to understanding the motion. We claim that all trajectories behave like that 
shown in Figure 7.5.1; starting from any point except the origin, the trajectory zaps 
horizontally onto the cubic nullcline y  F  ( x ). Then it crawls down the nullcline 
until it comes to the knee (point B in Figure 7.5.1), after which it zaps over to the 
other branch of the cubic at C. This is followed by another crawl along the cubic 
until the trajectory reaches the next jumping-off point at D, and the motion con-
tinues periodically after that.
x
y
y
F
=
D
C
A
(x)
B
slow
slow
fast
fast
Figure 7.5.1
To justify this picture, suppose that the initial condition is not too close to the 
cubic nullcline, i.e., suppose y – F  ( x ) _ O (1). Then (4) implies |
|
( )
1
x
O N
_


 
whereas 
1
|
|
(
)
1;
y
O N
_


 hence the velocity is enormous in the horizontal 
direction and tiny in the vertical direction, so trajectories move practically hori-
zontally. If the initial condition is above the nullcline, then y – F  ( x ) 0 and there-
fore x  0; thus the trajectory moves sideways toward the nullcline. However, once 
the trajectory gets so close that y – F  ( x ) _ O ( N2 ), then x  and y become compa-
rable, both being O ( N1 ). What happens then? The trajectory crosses the nullcline 
vertically, as shown in Figure 7.5.1, and then moves slowly along the backside of 
the branch, with a velocity of size O ( N1 ), until it reaches the knee and can jump 
sideways again. ■
This analysis shows that the limit cycle has two widely separated time scales: 
the crawls require %t _ O ( N ) and the jumps require %t _ O ( N–1 ). Both time 
scales are apparent in the waveform of x ( t ) shown in Figure 7.5.2, obtained by 
numerical integration of the van der Pol equation for N  10 and initial condition 
( x0  , y0 )  (2,0).

216 
LIMIT CYCLES
4
20
40
O
O
(μ)
(μ−1)
x
t
4
−
Figure 7.5.2
EXAMPLE 7.5.2:
Estimate the period of the limit cycle for the van der Pol equation for N  1. 
Solution: The period T is essentially the time required to travel along the two 
slow branches, since the time spent in the jumps is negligible for large N. By symme-
try, the time spent on each branch is the same. Hence T
dt
t
t
A
B
≈∫
2
. To derive an 
expression for dt, note that on the slow branches, y x F  ( x ) and thus
dy
dt
F
x dx
dt
x
dx
dt
≈
′
=
−
( )
(
)
.
2
1
But since dy / dt  –x / N from (4), we find dx / dt  –x / N ( x2 – 1). Therefore
2
(
1)
x
dt
dx
x
N

x 
 
(5)
on a slow branch. As you can check (Exercise 7.5.1), the positive branch begins at 
xA  2 and ends at xB  1. Hence
2
2
1
2
2
1
2
(
1)
2
ln
[3
2ln2],
2
x
T
x
dx
x
x
N
N
N
 
¯

¡
°
x





¡
°
¢
±
¨
 (6)
which is O ( N ) as expected. ■
The formula (6) can be refined. With much more work, one can show that 
T x N[3 –2 ln2]  2BN1  /  3 . . . , where B x 2.338 is the smallest root of Ai ( –B )  0. 
Here Ai ( x ) is a special function called the Airy function. This correction term 
comes from an estimate of the time required to turn the corner between the jumps 

217
7.6 WEAKLY NONLINEAR OSCILLATORS
and the crawls. See Grimshaw (1990, pp. 161–163) for a readable derivation of this 
wonderful formula, discovered by Mary Cartwright (1952). See also Stoker (1950) 
for more about relaxation oscillations.
One last remark: We have seen that a relaxation oscillation has two time scales 
that operate sequentially—a slow buildup is followed by a fast discharge. In the 
next section we will encounter problems where two time scales operate concur-
rently, and that makes the problems a bit more subtle.
7.6 Weakly Nonlinear Oscillators
This section deals with equations of the form 


x
x
h x x
+
+
=
F ( , )
0  
(1)
where 0 b F  1 and h x x
, 
(
) is an arbitrary smooth function. Such equations 
represent small perturbations of the linear oscillator x
x
+
= 0  and are therefore 
called weakly nonlinear oscillators. Two fundamental examples are the van der Pol 
equation


x
x
x
x
+
+
−
=
F(
)
,
2
1
0  
(2)
(now in the limit of small nonlinearity), and the Duffing equation
x
x
x
+
+
=
F
3
0. 
(3)
To illustrate the kinds of phenomena that can arise, Figure 7.6.1 shows a comput-
er-generated solution of the van der Pol equation in the ( , )
x x  phase plane, for 
F  0.1 and an initial condition close to the origin. The trajectory is a slowly wind-
ing spiral; it takes many cycles for the amplitude to grow substantially. Eventually 
the trajectory asymptotes to an approximately circular limit cycle whose radius is 
close to 2.
3
3
3
−
−
3
x
x.
Figure 7.6.1

218 
LIMIT CYCLES
We’d like to be able to predict the shape, period, and radius of this limit cycle. 
Our analysis will exploit the fact that the oscillator is “close to” a simple harmonic 
oscillator, which we understand completely.
Regular Perturbation Theory and Its Failure
As a first approach, we seek solutions of (1) in the form of a power series in F. 
Thus if x ( t, F ) is a solution, we expand it as
x ( t, F )  x0 ( t )  Fx1 ( t )  F2x2 ( t ) . . . , 
(4)
where the unknown functions xk ( t ) are to be determined from the governing equa-
tion and the initial conditions. The hope is that all the important information is 
captured by the first few terms—ideally, the first two—and that the higher-order 
terms represent only tiny corrections. This technique is called regular perturbation 
theory. It works well on certain classes of problems (for instance, Exercise 7.3.9), 
but as we’ll see, it runs into trouble here.
To expose the source of the difficulties, we begin with a practice problem that 
can be solved exactly. Consider the weakly damped linear oscillator


x
x
x
+
+
=
2
0
F
, 
(5)
with initial conditions
x (0)  0, x 0
( )=1.  
(6)
Using the techniques of Chapter 5, we find the exact solution
x t
e
t
t
( , )
(
)
sin (
)
.
F
F
F
F
=
−
−
⎡⎣⎢
⎤⎦⎥
−
−
1
1
2
1 2
2 1 2
 
(7)
Now let’s solve the same problem using perturbation theory. Substitution of (4) 
into (5) yields
d
dt
x
x
d
dt x
x
x
x
2
2
0
1
0
1
0
1
2
0
(
)
(
)
(
)
.
+
+
+
+
+
+
+
+
=
F
F
F
F
. . .
. . .
. . .
 
(8)
If we group the terms according to powers of F, we get
[
]
[
]
(
)
.



x
x
x
x
x
O
0
0
1
0
1
2
2
0
+
+
+
+
+
=
F
F
 
(9)
Since (9) is supposed to hold for all sufficiently small F, the coefficients of each 
power of F must vanish separately. Thus we find
O
x
x
( ) :
1
0
0
0
 +
=
 
(10)
O
x
x
x
( ) :
.
F


1
0
1
2
0
+
+
=
 
(11)

219
7.6 WEAKLY NONLINEAR OSCILLATORS
(We’re ignoring the O ( F2 ) and higher equations, in the optimistic spirit mentioned 
earlier.)
The appropriate initial conditions for these equations come from (6). At t  0, 
(4) implies that 0  x0 (0)  Fx1 (0) . . . ; this holds for all F, so
x0 (0)  0,  x1 (0)  0. 
(12)
By applying a similar argument to x( )
0  we obtain
x0 0
( ) 1, x1( )
.
0
0

 
(13)
Now we solve the initial-value problems one by one; they fall like dominoes. 
The solution of (10), subject to the initial conditions x0 (0)  0, x0 0
( ) 1, is
x0 ( t )  sin t. 
(14)
Plugging this solution into (11) gives
x
x
t
1
1
2
+
= −cos . 
(15)
Here’s the first sign of trouble: the right-hand side of (15) is a resonant forcing. The 
solution of (15) subject to x1 (0)  0, x1( )
0
0

 is
x1 ( t )  –t sin t, 
(16)
which is a secular term, i.e., a term that grows without bound as t l d. 
In summary, the solution of (5), (6) according to perturbation theory is
x ( t, F )  sin t – Ft sin t  O ( F2 ). 
(17)
How does this compare with the exact solution (7)? In Exercise 7.6.1, you are asked 
to show that the two formulas agree in the following sense: If (7) is expanded as 
power series in F, the first two terms are given by (17). In fact, (17) is the beginning 
of a convergent series expansion for the true solution. For any fixed t, (17) provides 
a good approximation as long as F is small enough—specifically, we need Ft  1 
so that the correction term (which is actually O ( F2t2 ) ) is negligible.
But normally we are interested in the behavior for fixed F, not fixed t. In that 
case we can only expect the perturbation approximation to work for times t  
O (1 / F ). To illustrate this limitation, Figure 7.6.2 plots the exact solution (7) and the 
perturbation series (17) for F  0.1. As expected, the perturbation series works 
reasonably well if t  1
10
F 
,  but it breaks down after that.

220 
LIMIT CYCLES
3
2
x
t
1
exact
perturbation
theory
0
−1
−2
−3
0
10
20
30
40
50
Figure 7.6.2
In many situations we’d like our approximation to capture the true solution’s qual-
itative behavior for all t, or at least for large t. By this criterion, (17) is a failure, as 
Figure 7.6.2 makes obvious. There are two major problems:
1. The true solution (7) exhibits two time scales: a fast time t _ O (1) for the 
sinusoidal oscillations and a slow time t _ 1 / F over which the ampli-
tude decays. Equation (17) completely misrepresents the slow time 
scale behavior. In particular, because of the secular term t sin t, (17) 
falsely suggests that the solution grows with time whereas we know 
from (7) that the amplitude A  (l – F2 )–1 / 2 e–Ft decays exponentially.
The discrepancy occurs because e–Ft  1 – Ft  O ( F2t2 ), so to this 
order in F, it appears (incorrectly) that the amplitude increases with t. 
To get the correct result, we’d need to calculate an infinite number of 
terms in the series. That’s worthless; we want series approximations 
that work well with just one or two terms.
2. The frequency of the oscillations in (7) is ω
ε
ε
=
−
≈−
(
)
,
/
l
2
2
1 2
1
2
1
 
which is shifted slightly from the frequency X  1 of (17). After a very 
long time t _ O (1 / F2 ), this frequency error will have a significant 
cumulative effect. Note that this is a third, super-slow time scale!
Two-Timing
The elementary example above reveals a more general truth: There are going to 
be (at least) two time scales in weakly nonlinear oscillators. We’ve already met this 
phenomenon in Figure 7.6.1, where the amplitude of the spiral grew very slowly 
compared to the cycle time. An analytical method called two-timing builds in the 
fact of two time scales from the start, and produces better approximations than 

221
7.6 WEAKLY NONLINEAR OSCILLATORS
regular perturbation theory. In fact, more than two times can be used, but we’ll 
stick to the simplest case.
To apply two-timing to (1), let U  t denote the fast O (1) time, and let T  Ft 
denote the slow time. We’ll treat these two times as if they were independent vari-
ables. In particular, functions of the slow time T will be regarded as constants on 
the fast time scale U. It’s hard to justify this idea rigorously, but it works! (Here’s 
an analogy: it’s like saying that your height is constant on the time scale of a day. 
Of course, over many months or years your height can change dramatically, espe-
cially if you’re an infant or a pubescent teenager, but over one day your height stays 
constant, to a good approximation.)
Now we turn to the mechanics of the method. We expand the solution of (1) as 
a series
x ( t, F )  x0 ( U, T )  Fx1 ( U, T )  O ( F2 ). 
(18)
The time derivatives in (1) are transformed using the chain rule:
x
dx
dt
x
x
T
T
t
x
x
T
=
= ∂
∂+ ∂
∂
∂
∂
= ∂
∂+
∂
∂
τ
τ
ε
. 
(19)
A subscript notation for differentiation is more compact; thus we write (19) as
x
x
x
T
= ∂
+ ∂
τ
ε
. 
(20)
After substituting (18) into (20) and collecting powers of F, we find
x
x
x
x
O
T
= ∂
+
∂
+ ∂
(
)+
τ
τ
ε
ε
0
0
1
 
2
(
).  
(21)
Similarly,
x
x
x
x
O
T
= ∂
+
∂
+ ∂
+
ττ
ττ
τ
ε
ε
0
0
(
)
(
).
1
2
2
 
(22)
To illustrate the method, let’s apply it to our earlier test problem.
EXAMPLE 7.6.1:
Use two-timing to approximate the solution to the damped linear oscillator 


x
x
x
+
+
=
2
0
F
, with initial conditions x (0)  0, x( )
.
0 1
Solution: After substituting (21) and (22) for x and x , we get
sUUx0  F ( sUUxl  2s5Ux0 )  2FsUx0  x0  Fx1  O ( F2 )  0. (23)
Collecting powers of F yields a pair of differential equations:
O (1): sUUx0  x0 0 
(24)
O ( F ): sUUxl  2 sTUx0  2sUx0  x1  0. 
(25)

222 
LIMIT CYCLES
Equation (24) is just a simple harmonic oscillator. Its general solution is
x0  A sin U  B cos U, 
(26)
but now comes the interesting part: The “constants” A and B are actually functions 
of the slow time T. Here we are invoking the above-mentioned ideas that U and T 
should be regarded as independent variables, with functions of T behaving like 
constants on the fast time scale U.
To determine A ( T ) and B ( T ), we need to go to the next order of F. Substituting 
(26) into (25) gives
sUUx1  x1  –2( sTUx0  sUx0 )
 –2( Aa  A )cos U  2( Ba  B )sin U 
(27)
where the prime denotes differentiation with respect to T.
Now we face the same predicament that ruined us after (15). As in that case, 
the right-hand side of (27) is a resonant forcing that will produce secular terms like 
U sinU and U cosU in the solution for x1. These terms would lead to a convergent but 
useless series expansion for x. Since we want an approximation free from secular 
terms, we set the coefficients of the resonant terms to zero—this manuever is char-
acteristic of all two-timing calculations. Here it yields
Aa  A  0 
(28)
Ba  B  0. 
(29)
The solutions of (28) and (29) are
A ( T )  A (0) eT 
B ( T )  B (0) eT.
The last step is to find the initial values A (0) and B (0). They are determined by 
(18), (26), and the given initial conditions x (0)  0, x( )
0 1, as follows. Equation 
(18) gives 0  x (0)  x0 (0,0)  Fx1 (0,0)  O ( F2 ). To satisfy this equation for all 
sufficiently small F, we must have
x0 (0,0)  0 
(30)
and x1 (0,0)  0. Similarly,
1
0
0 0
0 0
0 0
0
0
1
2
=
= ∂
+
∂
+∂
(
)+
x
x
x
x
O
T
( )
( , )
( , )
( , )
(
)
τ
τ
ε
ε
so
sUx0 (0, 0)  1  
(31)

223
7.6 WEAKLY NONLINEAR OSCILLATORS
and sTx0 (0, 0)  sUx1 (0, 0)  0. Combining (26) and (30) we find B (0)  0; hence 
B ( T ) w 0. Similarly, (26) and (31) imply A (0)  1, so A ( T )  eT. Thus (26) becomes
x0 ( U, T )  eT sin U. 
(32)
Hence
x  eT sin U  O ( F )
 e–Ft sin t  O ( F ) 
(33)
is the approximate solution predicted by two-timing. ■
Figure 7.6.3 compares the two-timing solution (33) to the exact solution (7) for 
F  0.1. The two curves are almost indistinguishable, even though F is not terribly 
small. This is a characteristic feature of the method—it often works better than it 
has any right to.
1
0.5
0
−0.5
−1
0
10
20
30
40
50
exact
two timing
t
x
Figure 7.6.3
If we wanted to go further with Example 7.6.1, we could either solve for x1 and 
higher-order corrections, or introduce a super-slow time |  F2t to investigate 
the long-term phase shift caused by the O ( F2 ) error in frequency. But Figure 7.6.3 
shows that we already have a good approximation.
OK, enough practice problems! Now that we have calibrated the method, let’s 
unleash it on a genuine nonlinear problem.
EXAMPLE 7.6.2:
Use two-timing to show that the van der Pol oscillator (2) has a stable limit cycle 
that is nearly circular, with a radius  2  O ( F ) and a frequency X  1  O ( F2 ).

224 
LIMIT CYCLES
Solution: The equation is 

x
x
x
x
+
+
−
=
F(
)
.
2
0
1
 Using (21) and (22) and col-
lecting powers of F, we find the following equations:
O (l): sUUx0  x0  0 
(34)
O ( F ): sUUx1  x1  –2sUT x0 – ( x0
2 – l) sUx0. 
(35)
As always, the O (1) equation is a simple harmonic oscillator. Its general solution 
can be written as (26), or alternatively, as
x0  r ( T ) cos ( U  G ( T ) ) 
(36)
where r ( T ) and G ( T ) are the slowly-varying amplitude and phase of x0.
To find equations governing r and G, we insert (36) into (35). This yields
sUUxl  x1  –2( ra sin ( U  G )  rGa cos ( U  G ) ) 
– r sin ( U  G ) [ r2 cos2 ( U  G ) – l ]. 
(37)
As before, we need to avoid resonant terms on the right-hand side. These are 
terms proportional to cos ( U  G ) and sin ( U  G ). Some terms of this form already 
appear explicitly in (37). But—and this is the important point—there is also a res-
onant term lurking in sin ( U  G ) cos2 ( U  G ), because of the trigonometric identity
sin(
)
sin
sin3
2
τ
τ
τ
+
+
=
+
+
+
φ
φ
φ
τ
φ
cos (
)
[
(
)
(
)].
1
4
 
(38)
(Exercise 7.6.10 reminds you how to derive such identities, but usually we won’t 
need them—shortcuts are available, as we’ll see.) After substituting (38) into (37), 
we get
∂
+
= −
′ + −
⎡⎣⎢
⎤⎦⎥
+
(
)
+ −
′
+
−
ττ
τ
φ
φ
τ
φ
x
x
r
r
r
r
r
1
1
1
4
3
1
4
3
2
2
sin
[
] cos(
)
sin33(
).
τ
φ
+
 
(39)
To avoid secular terms, we require
−
′ + −
=
2
3
r
r
r
1
4
0  
(40)
–2rGa  0. 
(41)
First consider (40). It may be rewritten as a vector field
′ =
−
r
r
r
1
8 (
)
4
2  
(42)
on the half-line r p 0. Following the methods of Chapter 2 or Example 7.1.1, we 
see that r*  0 is an unstable fixed point and r*  2 is a stable fixed point. Hence 

225
7.6 WEAKLY NONLINEAR OSCILLATORS
r ( T ) l 2 as T l d. Secondly, (41) implies Ga  0, so G ( T )  G0 for some constant 
G0. Hence x0 ( U, T ) l 2cos ( U  G0 ) and therefore
x ( t ) l 2 cos ( t G0 )  O ( F ) 
(43)
as t l d. Thus x ( t ) approaches a stable limit cycle of radius  2  O ( F ).
To find the frequency implied by (43), let R  t  G ( T ) denote the argument of 
the cosine. Then the angular frequency X is given by
ω
θ
φ
εφ
=
= +
= +
′ =
d
dt
d
dT
dT
dt
1
1
1,  
(44)
through first order in F. Hence X  1  O ( F2 ) ; if we want an explicit formula for 
this O ( F2 ) correction term, we’d need to introduce a super-slow time |  F2t, or we 
could use the Poincaré-Lindstedt method, as discussed in the exercises. ■
Averaged Equations
The same steps occur again and again in problems about weakly nonlinear 
oscillators. We can save time by deriving some general formulas. 
Consider the equation for a general weakly nonlinear oscillator:


x
x
h x x
+
+
(
)=
F
,
.0  
(45)
The usual two-timing substitutions give
O (l): sUUx0  x0  0 
(46)
O ( F ): sUUx1  x1  –2sUTx0 – h 
(47)
where now h  h ( x0 , sUx0 ). As in Example 7.6.2, the solution of the O (1) equation is
x0  r ( T ) cos ( U G ( T ) ). 
(48)
Our goal is to derive differential equations for ra and Ga, analogous to (40) and 
(41). We’ll find these equations by insisting, as usual, that there be no terms pro-
portional to cos ( U  G ) and sin ( U  G ) on the right-hand side of (47). Substituting 
(48) into (47), we see that this right-hand side is
2 [ ra sin ( U  G )  rGa cos ( t  G ) ]  h 
(49)
where now h  h ( r cos ( U  G ), – r sin ( U  G ) ).
To extract the terms in h proportional to cos ( U  G ) and sin ( U  G ), we bor-
row some ideas from Fourier analysis. (If you’re unfamiliar with Fourier analysis, 
don’t worry—we’ll derive all that we need in Exercise 7.6.12.) Notice that h is a 
2Q-periodic function of U  G. Let
R  U  G.

226 
LIMIT CYCLES
Fourier analysis tells us that h ( R ) can be written as a Fourier series
h
a
k
b
k
k
k
k
k
( )
cos
sin
R
R
R
=
+
=
∞
=
∞
∑
∑
1
0
 
(50)
where the Fourier coefficients are given by
a
h
d
a
h
k d
k
b
h
k d
k
k
k
0
1
2
0
2
1
0
2
1
1
=
=
≥
=
∫
∫
π
π
π
π
π
θ
θ
θ
θ θ
θ
θ θ
( )
( ) cos
,
( ) sin
,
≥
∫
1
0
2
.
π
 
(51)
Hence (49) becomes
2
1
0
r
r
a
k
b
k
k
k
k
k
′
′
sin
cos
cos
sin
.
θ
φ
θ
θ
θ
+
[
]−
−
=
∞
=
∞
∑
∑
 
(52)
The only resonant terms in (52) are [ 2ra – b1 ] sin R and [ 2rGa – a1 ] cos R. Therefore, 
to avoid secular terms we need ra  b1 / 2 and rGa  a / 2. Using the expressions in 
(51) for a1 and b1, we obtain
′ =
≡〈
〉
′ =
≡〈
〉
∫
∫
r
h
d
h
r
h
d
h
1
2
0
2
1
2
0
2
π
π
π
π
θ
θ θ
θ
φ
θ
θ θ
θ
( )sin
sin
( )cos
cos
 
(53)
where the angled brackets 〈⋅〉 denote an average over one cycle of R.
The equations in (53) are called the averaged or slow-time equations. To use 
them, we write out h  h ( r cos ( U  G ), –r sin ( U  G ) )  h ( r cosR, –r sinR ) explic-
itly, and then compute the relevant averages over the fast variable R, treating the 
slow variable r as constant. Here are some averages that appear often:
〈
〉=〈
〉=
〈
〉=
〈
〉=〈
〉=
〈
〉=〈
+
+
cos
sin
,
sin cos
,
cos
sin
,
cos
sin
0
0
0
3
3
2
1
2
n
n 1
2
2
1
2
4
4
3
8
2
2
1
8
0
〉=
〈
〉=〈
〉=
〈
〉=〈
〉=
〈
〉=
〈
,
cos
sin
,
cos
sin
,
cos sin
,
cos2
2
13 5
2
1
2 4 6
2
1
n
n
n
n
n
〉=〈
〉=
≥
⋅⋅
−
⋅⋅
sin
,
.
(
)
(
)
!
!
 
 
 
 
 
 
 
 
 
(54)
Other averages can either be derived from these, or found by direct integration. 
For instance,

227
7.6 WEAKLY NONLINEAR OSCILLATORS
2
4
2
4
4
6
3
15
1
8
48
16
cos sin
(1
sin )sin
sin
sin




 

and
cos sin
cos
sin
cos
.
3
1
2
3
1
2
4
0
2
0
2
0
=
= −
⎡⎣⎢
⎤⎦⎥
=
∫
π
π
π
π
θ
θ θ
θ
d
EXAMPLE 7.6.3:
Consider the van der Pol equation 

x
x
x
x
+
+
−
=
F(
)
,
2
1
0  subject to the initial 
conditions x (0)  1, x( )
.
0
0

 Find the averaged equations, and then solve them 
to obtain an approximate formula for x ( t, F ). Compare your result to a numerical 
solution of the full equation, for F  0.1.
Solution: The van der Pol equation has h
x
x
r
r
=
−
−
−
).
=
(
)
cos
)(
sin
(
2
2
2
1
1

R
R
 
Hence (53) becomes
′ =
=
−
−
=
−
=
−
r
h
r
r
r
r
r
sin
(
cos
)(
sin )sin
sin
cos
sin
R
R
R
R
R
R
R
2
2
2
3
2
2
1
2
1
1
8
3r
and
r
h
r
r
r
r
′ =
=
−
−
=
−
=
−
φ
θ
θ
θ
θ
θ
θ
θ
θ
cos
(
cos
)(
sin )cos
sin
cos
cos
sin
2
2
3
3
1
0
0
0
= .
These equations match those found in Example 7.6.2, as they should.
The initial conditions x (0)  1 and x( )
0
0

 imply r
x
x
( )
( )
( )
0
0
0
1
2
2
≈
+
=

 
and φ
τ
( )
tan
( )
( )
.
0
0
0
0
0
0
1
≈
(
)−
=
−
=
−
x
x
 Since Ga  0, we find G ( T ) w 0. To 
find r ( T ), we solve ′ =
−
r
r
r
1
2
1
8
3 subject to r (0)  l. The differential equation sep-
arates to
8
4
2
dr
r
r
dT
(
)
.
−
= ∫
∫
After integrating by partial fractions and using r (0)  1, we find
r ( T )  2(l  3eT )l / 2. 
(55)

228 
LIMIT CYCLES
Hence
x t
x
T
O
e
t
O
t
( , )
( ,
)
( )
cos
( ).
ε
τ
ε
ε
ε
∼
+
=
+
+
−
0
2
1
3
 
(56)
Equation (56) describes the transient dynamics of the oscillator as it spirals out to 
its limit cycle. Notice that r ( T ) l 2 as T l d, as in Example 7.6.2.
In Figure 7.6.4 we plot the “exact” solution of the van der Pol equation, obtained 
by numerical integration for F  0.1 and initial conditions x (0)  1, x( )
.
0
0

 For 
comparison, the slowly-varying amplitude r ( T ) predicted by (55) is also shown. 
The agreement is striking. Alternatively, we could have plotted the whole solution 
(56) instead of just its envelope; then the two curves would be virtually indistin-
guishable, like those in Figure 7.6.3. ■
3
2
envelope predicted
by averaging theory
exact solution
1
0
−1
−2
−3
0
10
20
30
40
50
t
x
Figure 7.6.4
Now we consider an example in which the frequency of an oscillator depends 
on its amplitude. This is a common phenomenon, and one that is intrinsically non-
linear—it cannot occur for linear oscillators.
EXAMPLE 7.6.4:
Find an approximate relation between the amplitude and frequency of the Duffing 
oscillator x
x
x
+
+
=
F
3
0, where F can have either sign. Interpret the results 
physically.
Solution: Here h  x3  r3 cos3 R. Equation (53) becomes

229
7.6 WEAKLY NONLINEAR OSCILLATORS
′ =
=
=
r
h
r
sin
sin
R
R
R
3
3
cos
0
and
r
h
r
r
′ =
=
=
φ
θ
θ
cos
.
3 cos4
3
8
3
Hence r ( T ) w a, for some constant a, and ′ =
G
3
8
2
a .  As in Example 7.6.2, the fre-
quency X is given by 
ω
εφ
ε
ε
= +
′ = +
+
1
1
3
8
2
2
a
O(
). 
(57)
Now for the physical interpretation. The Duffing equation describes the 
undamped motion of a unit mass attached to a nonlinear spring with restoring 
force F  ( x )  –x – Fx3. We can use our intuition about ordinary linear springs if we 
write F  ( x )  –kx, where the spring stiffness is now dependent on x :
k  k ( x )  1  Fx2.
Suppose F  0. Then the spring gets stiffer as the displacement x increases—this 
is called a hardening spring. On physical grounds we’d expect it to increase the fre-
quency of the oscillations, consistent with (57). For F  0 we have a softening spring, 
exemplified by the pendulum (Exercise 7.6.15).
It also makes sense that ra  0. The Duffing equation is a conservative sys-
tem and for all F sufficiently small, it has a nonlinear center at the origin (Exercise 
6.5.13). Since all orbits close to the origin are periodic, there can be no long-term 
change in amplitude, consistent with ra  0. ■
Validity of Two-Timing
We conclude with a few comments about the validity of the two-timing method. 
The rule of thumb is that the one-term approximation x0 will be within O ( F ) of the 
true solution x for all times up to and including t _ O (1 / F ), assuming that both x 
and x0 start from the same initial condition. If x is a periodic solution, the situation 
is even better: x0 remains within O ( F ) of x for all t.
But for precise statements and rigorous results about these matters, and for 
discussions of the subtleties that can occur, you should consult more advanced 
treatments, such as Guckenheimer and Holmes (1983) or Grimshaw (1990). Those 
authors use the method of averaging, an alternative approach that yields the same 
results as two-timing. See Exercise 7.6.25 for an introduction to this powerful 
technique.
Also, we have been very loose about the sense in which our formulas approxi-
mate the true solutions. The relevant notion is that of asymptotic approximation. 
For introductions to asymptotics, see Lin and Segel (1988) or Bender and Orszag 
(1978).

230 
LIMIT CYCLES
EXERCISES FOR CHAPTER 7
7.1 Examples
Sketch the phase portrait for each of the following systems. (As usual, r, R denote 
polar coordinates.)
7.1.1 


r
r
r
=
−
=
3
4
1
, R
 
 
7.1.2 


r
r
r
r
=
−
−
=
(
)(
),
1
9
 
1
2
2
R
7.1.3 


r
r
r
r
r
=
−
−
=
−
(
)(
),
l
4
 
2
2
2
2
R
 
7.1.4 


r
r
r


sin , 
l
R
7.1.5 
(From polar to Cartesian coordinates) Show that the system r
r
r
=
−
(
),
l
2
 
R 1 is equivalent to 


x
x
y
x x
y
y
x
y
y x
y
=
−−
+
=
+
−
+
(
),
(
),
2
2
2
2
where x  r cosR, y  r sinR. (Hint: 


x
r
r
r
d
dt
=
=
−
( cos )
cos
sin .)
R
R
R
R
7.1.6 
(Circuit for van der Pol oscillator) Figure 1 shows the “tetrode multivibra-
tor” circuit used in the earliest commercial radios and analyzed by van der Pol. In 
van der Pol’s day, the active element was a vacuum 
tube; today it would be a semiconductor device. It 
acts like an ordinary resistor when I is high, but like 
a negative resistor (energy source) when I is low. Its 
current-voltage characteristic V  f ( I ) resembles a 
cubic function, as discussed below.
Suppose a source of current is attached to the 
circuit and then withdrawn. What equations govern 
the subsequent evolution of the current and the var-
ious voltages?
a) Let V  V32  –V23 denote the voltage drop from point 3 to point 2 in the circuit. 
Show that V
I C
= −/
 and V
LI
f I
=
+

( ).
b) Show that the equations in (a) are equivalent to
dw
d
x
dx
d
w
F x
τ
τ
μ
= −
=
−
,
( )
where x  L1 / 2I,  w  C1 / 2 V,  U   ( LC )1 / 2 t, and F  ( x )  f  ( L1 / 2x ).
In Section 7.5, we’ll see that this system for ( w, x ) is equivalent to the van der Pol 
equation, if F x
x
x
( )
.
=
−
1
3
3
 Thus the circuit produces self-sustained oscillations.
7.1.7 
(Waveform) Consider the system r
r
r
=
−
(
),
4
2
 R 1,  and let x ( t )  
r ( t ) cos R ( t ). Given the initial condition x (0)  0.1, y (0)  0, sketch the approxi-
mate waveform of x ( t ), without obtaining an explicit expression for it.
L
C
V =
I
2
1
4
2
3
f (I )
Figure 1

231
EXERCISES
7.1.8 
(A circular limit cycle) Consider 


x
ax x
x
x
+
+
−
+
=
(
)
,
2
0
2
1
 where 
a  0.
a) Find and classify all the fixed points.
b) Show that the system has a circular limit cycle, and find its amplitude and 
period.
c) Determine the stability of the limit cycle.
d) Give an argument which shows that the limit cycle is unique, i.e., there are no 
other periodic trajectories.
7.1.9 
(Circular pursuit problem) A dog at the center of a circular pond sees a 
duck swimming along the edge. The dog chases the duck by always swimming 
straight toward it. In other words, the dog’s velocity vector always lies along the 
line connecting it to the duck. Meanwhile, the duck takes evasive action by swim-
ming around the circumference as fast as it can, always moving counterclockwise. 
a) Assuming the pond has unit radius and both animals swim at the same con-
stant speed, derive a pair of differential equations for the path of the dog. (Hint: 
Use the coordinate system shown in Figure 2 and find equations for dR / dR and 
dG / dR.) Analyze the system. Can you solve it explicitly? Does the dog ever catch 
the duck?
b) Now suppose the dog swims k times faster 
than the duck. Derive the differential equations 
for the dog’s path.
c) If k  1
2 , what does the dog end up doing in 
the long run?
Note: This problem has a long and intriguing 
history, dating back to the mid-1800s at least. It 
is much more difficult than similar pursuit prob-
lems—there is no known solution for the path 
of the dog in part (a), in terms of elementary 
functions. See Davis (1962, pp. 113–125) and 
Nahin (2007) for nice analyses and guides  to 
the literature.
7.2 Ruling Out Closed Orbits
Plot the phase portraits of the following gradient systems x = −∇V.
7.2.1 
V  x2 y2 
7.2.2 
V  x2  y2 
7.2.3 
V  ex sin y
7.2.4 
Show that all vector fields on the line are gradient systems. Is the same 
true of vector fields on the circle?
7.2.5 
Let x
f x y
=
(
)
,
,  y
g x y

( , )  be a smooth vector field defined on the 
phase plane.
a) Show that if this is a gradient system, then sf  / sy  sg / sx.
b) Is the condition in (a) also sufficient?
φ
θ
R
duck
dog
Figure 2

232 
LIMIT CYCLES
7.2.6 
Given that a system is a gradient system, here’s how to find its potential 
function V. Suppose that x
f x y
=
(
)
,
,  y
g x y

( , ).  Then x = −∇V  implies 
f  ( x,y )  –sV / sx and g ( x,y )  –sV / sy. These two equations may be “partially 
integrated” to find V. Use this procedure to find V for the following gradient 
systems.
a) 

x
y
y
x
y
xy
x
=
+
=
+
2
2
cos ,
sin
b) 

x
x
e
y
xe
y
y
=
−−
= −
3
1
2
2
2
2
,
7.2.7 
Consider the system 

x
y
xy y
x
x
y
=
+
=
+
−
2
2
2
,
.
 
a) Show that sf  / sy  sg / sx. (Then Exercise 7.2.5(a) implies this is a gradient 
system.)
b) Find V.
c) Sketch the phase portrait.
7.2.8 
Show that the trajectories of a gradient system always cross the equipo-
tentials at right angles (except at fixed points).
7.2.9 
For each of the following systems, decide whether it is a gradient system. 
If so, find V and sketch the phase portrait. On a separate graph, sketch the equi-
potentials V  constant. (If the system is not a gradient system, go on to the next 
question.)
a) 

x
y
x y
y
x
xy
=
+
= −+
2
2
,
b) 

x
x
y
y


2
8
,
c) x
xe
y
ye
x
y
x
y
= −
= −
+
+
2
,
2
2
2
2
2
7.2.10 
Show that the system 
3
3
,  
–
x
y
x
y
x
y


 


 has no closed orbits, by 
constructing a Liapunov function V  ax2  by2 with suitable a, b.
7.2.11 
Show that V  ax2  2bxy  cy2 is positive definite if and only if a  0 and 
ac  b2  0. (This is a useful criterion that allows us to test for positive definiteness 
when the quadratic form V includes a “cross term” 2bxy.)
7.2.12 
Show that x
x
y
y
= −+
−
2
3
2
4, y
x
y
xy
= −−
+
 has no periodic solu-
tions. (Hint: Choose a, m, and n such that V  xm ayn is a Liapunov function.)
7.2.13 
Recall the competition model


N
rN
N
K
b N N
N
r N
N
K
b N N
1
1
1
1
1
1
1
2
2
2
2
2
2
2
1
2
1
1
=
−
−
=
−
−
(
)
,
(
)
,
 
of Exercise 6.4.6. Using Dulac’s criterion with the weighting function g  ( N1N2 )1, 
show that the system has no periodic orbits in the first quadrant N1, N2  0.
7.2.14 
Consider 

x
x
y
y
y x
=
−−
=
−
(
)
2
1
2
,
.
  
a) Show that there are three fixed points and classify them.
b) By considering the three straight lines through pairs of fixed points, show that 
there are no closed orbits.
c) Sketch the phase portrait.

233
EXERCISES
7.2.15 
Consider the system x
x
x
y
=
−−
(
),
2
 y
y
x
x
=
−
−
(
).
4
3
2
 We know 
from Example 7.2.4 that this system has no closed orbits.
a) Find the three fixed points and classify them.
b) Sketch the phase portrait.
7.2.16 
If R is not simply connected, then the conclusion of Dulac’s criterion is no 
longer valid. Find a counterexample.
7.2.17 
Assume the hypotheses of Dulac’s criterion, except now suppose that R 
is topologically equivalent to an annulus, i.e., it has exactly one hole in it. Using 
Green’s theorem, show that there exists at most one closed orbit in R. (This result 
can be useful sometimes as a way of proving that a closed orbit is unique.)
7.2.18 
Consider the predator-prey model 
x
rx
x
x
x y
=
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟−+
1
2
2
1
,     y
y
x
x y
= −+ +
2
1
where r  0  and x y
,
p 0 . Prove this system has no closed orbits by invoking 
Dulac’s criterion with the function g x y
x
x
y
( , ) = +
−
1
1
B
 for a suitable choice of B  
(Hofbauer and Sigmund 1998).
7.2.19 
(Modeling the love story in “Gone with the Wind”) Rinaldi et al. (2013) 
have modeled the stormy love affair between Scarlett O’Hara and Rhett Butler 
with the system 
R
R
A
kSe
S
S
= −
+
+
−,       S
S
A
kRe
R
R
= −+
+
−. 
Here R denotes Rhett’s love for Scarlett, and S denotes Scarlett’s love for Rhett. 
The parameters AR , AS , and k  are all positive. 
a)  Interpret the three terms on the right hand side of each equation. What do they 
mean, romantically speaking? In particular, what does the functional form of 
the third terms, kSe
S
  and kRe
R
 , signify about how Rhett and Scarlett react 
to each other’s endearments? 
b)  Show that all trajectories that begin in the first quadrant R S
,
p 0  stay in the 
first quadrant forever, and interpret that result psychologically.
c)  Using Dulac’s criterion, prove that the model has no periodic solutions. (Hint: 
The simplest g you can think of will work.)
d)  Using a computer, plot the phase portrait for the system, assuming parameter 
values AS 1 2. , AR 1, and k 15 . Assuming that Rhett and Scarlett are 
indifferent when they meet, so that R
S
( )
( )
0
0
0


, plot the predicted trajec-
tory for what happens in the first stage of their relationship. 
Check out Rinaldi et al. (2013)—and the movie itself—if you’re curious about 
the later twists and turns in this epic romance.

234 
LIMIT CYCLES
7.3 Poincaré−Bendixson Theorem
7.3.1 
Consider x
x
y
x x
y
=
−−
+
(
),
2
5
2
 y
x
y
y x
y
=
+
−
+
 
 
2
(
).
2
a) Classify the fixed point at the origin.
b) Rewrite the system in polar coordinates, using 
rr
xx
yy



=
+
 and 



R =
−
(
)
xy
yx
r
/
.
2
c) Determine the circle of maximum radius, r1, centered on the origin such that all 
trajectories have a radially outward component on it.
d) Determine the circle of minimum radius, r2, centered on the origin such that all 
trajectories have a radially inward component on it.
e) Prove that the system has a limit cycle somewhere in the trapping region 
r1 br br2.
7.3.2 
Using numerical integration, compute the limit cycle of Exercise 7.3.1 and 
verify that it lies in the trapping region you constructed.
7.3.3 
Show that the system x
x
y
x
=
−−
3 , y
x
y
y
=
+
−
 
 
3 has a periodic 
solution.
7.3.4 
Consider the system


x
x
x
y
y
x
y
y
x
y
x
x
=
−
−
−
+
(
)
=
−
−
+
+
(
)
(
)
,
(
)
.
1
4
1
l
4
2
l
2
2
2
2
1
2
a) Show that the origin is an unstable fixed point.
b) By considering V , where V
x
y
=
−
−
(
) ,
l
4
2
2
2  show that all trajectories 
approach the ellipse 4x2  y2  1 as t ld.
7.3.5 
Show that the system x
x
y
x x
y
= −−
+
+
(
),
2
2
2
 y
x
y
y x
y
=
−
+
+
(
)
2
2
2
 
has at least one periodic solution.
7.3.6 
Consider the oscillator equation 
 
x
F x x x
x
+
+
=
( , )
,0  where F x x
( , )  0  
if r ba and F x x
( , )  0  if r pb, where r
x
x
2
2
2
=
+  .
a) Give a physical interpretation of the assumptions on F.
b) Show that there is at least one closed orbit in the region a r b.
7.3.7 
Consider x
y
ax
b
r
=
+
−
−
(
),
1
2
2
 y
x
ay
r
= −+
−
(
),
l
2
 where a and b are 
parameters (
,
)
0
0
1
2
<
≤
≤
<
a
b
1  
 and r2  x2  y2.
a) Rewrite the system in polar coordinates.
b) Prove that there is at least one limit cycle, and that if there are several, they all 
have the same period T ( a, b ).
c) Prove that for b  0 there is only one limit cycle.
7.3.8 
Recall the system 
2
(l
)
cos , 
1
r
r
r
r
N
R R






 of Example 7.3.1. Using 
the computer, plot the phase portrait for various values of N  0. Is there a critical 
value Nc at which the closed orbit ceases to exist? If so, estimate it. If not, prove that 
a closed orbit exists for all N  0.

235
EXERCISES
7.3.9 
(Series approximation for a closed orbit) In Example 7.3.1, we used the 
Poincaré−Bendixson Theorem to prove that the system 
2
(l
)
cos ,
r
r
r
r
N
R



 
R 1 has a closed orbit in the annulus 1
1
r
N
N

 

 for all N  1.
a) To approximate the shape r ( R ) of the orbit for N  1, assume a power series 
solution of the form r ( R )  1  Nr1 ( R )  O ( N2 ). Substitute the series into a 
differential equation for dr / dR. Neglect all O ( N2 ) terms, and thereby derive a 
simple differential equation for r1 ( R ). Solve this equation explicitly for r1 ( R ). 
(The approximation technique used here is called regular perturbation theory; 
see Section 7.6.)
b) Find the maximum and minimum r on your approximate orbit, and hence show 
that it lies in the annulus 1
1
,
r
N
N

 

 as expected.
c) Use a computer to calculate r ( R ) numerically for various small N, and plot the 
results on the same graph as your analytical approximation for r ( R ). How does 
the maximum error depend on N?
7.3.10 
Consider the two-dimensional system x
x
x
=
−
A
r2 , where r  ||x|| and A 
is a 2 q 2 constant real matrix with complex eigenvalues B o iX. Prove that there 
exists at least one limit cycle for B  0 and that there are none for B  0.
7.3.11 
(Cycle graphs) Suppose x
f x
 ( )  is a smooth vector field on R2. An 
improved version of the Poincaré-Bendixson theorem states that if a trajectory is 
trapped in a compact region, then it must approach a fixed point, a closed orbit, or 
something exotic called a cycle graph (an invariant set containing a finite number 
of fixed points connected by a finite number of trajectories, all oriented either 
clockwise or counterclockwise). Cycle graphs are rare in practice; here’s a con-
trived but simple example.
a) Plot the phase portrait for the system


r
r
r
r
r
r
r
=
−
+
−
⎡⎣⎢
⎤⎦⎥
=
+
−
(
)
sin
(
cos
)
sin
(
cos
)
1
1
1
2
2
2
2
2
2
2
2
2
2
R
R
R
R
R
2
 
where r,R are polar coordinates. (Hint: Note the common factor in the two 
equations; examine where it vanishes.)
b) Sketch x vs. t for a trajectory starting away from the unit circle. What happens 
as t l d?
7.3.12 
(A heteroclinic cycle in rock-paper-scissors) The three-dimensional 
system 



P
P
aR
S
a
PR
RS
PS
R
R
aS
P
a
PR
RS
PS
S
=
−
−
−
+
+
[
]
=
−
−
−
+
+
[
]
(
)
(
)(
)
(
)
(
)(
)
1
1
=
−
−
−
+
+
[
]
S
aP
R
a
PR
RS
PS
(
)
(
)(
) ,
1

236 
LIMIT CYCLES
where the parameter a  0, is a generalization of the rock-paper-scissors model 
studied in Exercise 6.5.20. Previously, we studied the special case a 1 and showed 
that the system had two conserved quantities,
E P R S
P
R
S
1( ,
, ) =
+
+
,         E
P R S
PRS
2( ,
, ) 
. 
For a v1 it turns out that the system above has a cycle graph, or what is more 
commonly known nowadays as a heteroclinic cycle. With a few deft strokes, we 
can use the functions E1  and E2  to prove that a heteroclinic cycle exists (Sigmund 
2010, p. 42). The point of this exercise is to provide a more natural instance of a 
cycle graph than that in Exercise 7.3.11.
a)  Show that for the system above, E
E
a
PR
RS
PS
1
1
1
1
=
−
−
+
+
(
)(
)(
) . Hence, 
E1  is no longer conserved everywhere, but it is conserved if we restrict attention 
to the set where E1
1
 . This set, defined by all ordered triples of real numbers 
( ,
, )
P R S  such that P
R
S
+
+
=1, is invariant; any trajectory that starts on it 
stays on it forever. Describe this set geometrically; what simple shape is it? 
b)  Consider a subset of the set in (a), defined by the condition that P R S
,
,
p 0  in 
addition to P
R
S
+
+
=1. Show that this subset, which we’ll call T, is also 
invariant. What simple shape is it?
From now on, we’ll restrict attention to the dynamics on the set T. 
c) Show that the boundary of T consists of three fixed points connected by three 
trajectories, all oriented in the same sense, and hence is a cycle graph (hetero-
clinic cycle).
d)  Show that E
a
E
P
R
R
S
S
P
2
2
2
2
2
1
2
=
−
−
+
−
+
−
⎡⎣⎢
⎤⎦⎥
(
)
(
)
(
)
(
)
.
e)  Using the results of parts (b)–(d), show that E2  vanishes at the boundary of T 
and at the interior fixed point ( *, *, *)
( , , )
P
R
S
 1
3 1 1 1 .
f) Explain why the previous results imply that for a 1, the interior fixed point 
attracts all trajectories on the interior of T. 
g) Finally, show that for a 1, the heteroclinic cycle attracts all trajectories that 
start in the interior of T (except, of course, for the interior fixed point itself).
7.4 Liénard Systems
7.4.1 
Show that the equation 
2
(
1)
tanh
0,
x
x
x
x
N






 for N  0, has exactly 
one periodic solution, and classify its stability.
7.4.2 
Consider the equation 
4
(
1)
0.
x
x
x
x
N






a) Prove that the system has a unique stable limit cycle if N  0.
b) Using a computer, plot the phase portrait for the case N  1.
c) If N  0, does the system still have a limit cycle? If so, is it stable or unstable?

237
EXERCISES
7.5 Relaxation Oscillations
7.5.1 
For the van der Pol oscillator with N  1, show that the positive branch 
of the cubic nullcline begins at xA  2 and ends at xB  1.
7.5.2 
In Example 7.5.1, we used a tricky phase plane (often called the Liénard 
plane) to analyze the van der Pol oscillator for N  1. Try to redo the analysis in 
the standard phase plane where 
2
, 
(
1).
x
y y
x
x
N

  



 What is the advantage 
of the Liénard plane?
7.5.3 
Estimate the period of the limit cycle of 

x
k x
x
x
+
−
(
) +
=
2
4
1 for 
k  1.
7.5.4 
(Piecewise-linear nullclines) Consider the equation 
( )
0,
x
f x x
x
N





 
where f  ( x )  –1 for |x|  1 and f  ( x )  1 for |x| p 1.
a) Show that the system is equivalent to 
(
( )), 
/ ,
x
y
F x
y
x
N
N


 


 where F  ( x ) 
is the piecewise-linear function
F x
x
x
x
x
x
x
( )
,
,
|
|
,
.
=
+
≤−
−
≤
−
≥
⎧
⎨
⎪⎪⎪⎪
⎩
⎪⎪⎪⎪
2
1
1
2
1
b) Graph the nullclines.
c) Show that the system exhibits relaxation oscillations for N  1, and plot the 
limit cycle in the ( x, y ) plane.
d) Estimate the period of the limit cycle for N  1.
7.5.5 
Consider the equation 
	

l
0.
x
x
x
x
N






 Find the approximate 
period of the limit cycle for N  1.
7.5.6 
(Biased van der Pol) Suppose the van der Pol oscillator is biased by a con-
stant force: 
2
(
1)
,
x
x
x
x
a
N






 where a can be positive, negative, or zero. 
(Assume N  0 as usual.)
a) Find and classify all the fixed points.
b) Plot the nullclines in the Liénard plane. Show that if they intersect on the middle 
branch of the cubic nullcline, the corresponding fixed point is unstable.
c) For N  1, show that the system has a stable limit cycle if and only if |a|  ac, 
where ac is to be determined. (Hint: Use the Liénard plane.)
d) Sketch the phase portrait for a slightly greater than ac. Show that the system is 
excitable (it has a globally attracting fixed point, but certain disturbances can 
send the system on a long excursion through phase space before returning to the 
fixed point; compare Exercise 4.5.3.)
This system is closely related to the Fitzhugh-Nagumo model of neural activity; 
see Murray (2002) or Edelstein-Keshet (1988) for an introduction.

238 
LIMIT CYCLES
7.5.7 
(Cell cycle) Tyson (1991) proposed an elegant model of the cell division 
cycle, based on interactions between the proteins cdc2 and cyclin. He showed that 
the model’s mathematical essence is contained in the following set of dimension-
less equations:


u
b v
u
u
u
v
c
u
=
−
+
−
= −
(
)(
)
,
,
B
2
where u is proportional to the concentration of the active form of a cdc2-cyclin 
complex, and v is proportional to the total cyclin concentration (monomers and 
dimers). The parameters b  1 and B  1 are fixed and satisfy 8Bb  1, and c 
is adjustable. 
a) Sketch the nullclines.
b) Show that the system exhibits relaxation oscillations for c1  c  c2, where c1 and 
c2 are to be determined approximately. (It is too hard to find c1 and c2 exactly, 
but a good approximation can be achieved if you assume 8Bb  1.)
c) Show that the system is excitable if c is slightly less than c1.
7.6 
Weakly Nonlinear Oscillators
7.6.1 
Show that if (7.6.7) is expanded as a power series in F, we recover (7.6.17).
7.6.2 
(Calibrating regular perturbation theory) Consider the initial value prob-
lem x
x
x
+
+
=
F
0, with x (0)  1, x( )
.
0
0

a) Obtain the exact solution to the problem.
b) Using regular perturbation theory, find x0, x1, and x2 in the series expansion 
x t
x t
x t
x t
O
,
( )
( )
( )
(
).
F
F
F
F
(
)=
+
+
+
0
1
2
2
3
c) Does the perturbation solution contain secular terms? Did you expect to see 
any? Why?
7.6.3 
(More calibration) Consider the initial value problem x
x
+
= F,  with 
x (0)  1, x( )
.
0
0

a) Solve the problem exactly.
b) Using regular perturbation theory, find x0, x1, and x2 in the series expansion 
x t
x t
x t
x t
O
( , )
( )
( )
( )
(
).
F
F
F
F
=
+
+
+
0
2
2
3
1
c) Explain why the perturbation solution does or doesn’t contain secular terms.
For each of the following systems 

x
x
h x x
+
+
(
)=
F
,
,0  with 0  F  1, calculate 
the averaged equations (7.6.53) and analyze the long-term behavior of the system. 
Find the amplitude and frequency of any limit cycles for the original system. If 
possible, solve the averaged equations explicitly for x ( t, F ), given the initial condi-
tions x (0)  a, x( )
.
0
0

7.6.4 
h x x
x
, 
(
)=
 
 
7.6.5 
h x x
xx
( , )


2
7.6.6 
h x x
xx
, 

(
)=
 
 
7.6.7 
h x x
x
x
( , )
(
)


=
−
4
1
7.6.8 
h x x
x
x
( , )
(|
|
)


=
−1
 
7.6.9 
h x x
x
x
( , )
(
)


=
−
2
l
3

239
EXERCISES
7.6.10 
Derive the identity sinR
R
R
R
 cos
sin 
sin 3
2 =
+
[
]
1
4
 as follows: Use the 
complex representations
cos
,
sin
,
R
R
R
R
R
R
=
+
=
−
−
−
e
e
e
e
i
i
i
i
i
2
2
multiply everything out, and then collect terms. This is always the most straight-
forward method of deriving such identities, and you don’t have to remember any 
others.
7.6.11 
(Higher harmonics) Notice the third harmonic sin 3 ( U  G ) in Equation 
(7.6.39). The generation of higher harmonics is a characteristic feature of nonlinear 
systems. To find the effect of such terms, return to Example 7.6.2 and solve for x1, 
assuming that the original system had initial conditions x (0)  2, x( )
.
0
0

7.6.12 
(Deriving the Fourier coefficients) This exercise leads you through the 
derivation of the formulas (7.6.51) for the Fourier coefficients. For convenience, let 
brackets denote the average of a function: 
f
f
d
( )
( )
θ
θ
θ
π
π
≡
∫
1
2
0
2
 for any 
2Q-periodic function f. Let k and m be arbitrary integers.
a) Using integration by parts, complex exponentials, trig identities, or otherwise, 
derive the orthogonality relations
cos
0, for all 
k
m
k m
R
R
sin
,
;

cos
sin
k
m
k
m
R
R
R
R
cos
sin
,

 0  for all k v m; 
cos
sin
,
.
2
2
1
2
0
k
k
k
R
R
=
=
≠
 for 
b) To find ak for k v 0, multiply both sides of (7.6.50) by cos mR and average both 
sides term by term over the interval [0, 2Q]. Now using the orthogonality rela-
tions from part (a), show that all the terms on the right-hand side cancel out, 
except the k  m term! Deduce that h
k
ak
( )cos
,
R
R  1
2
 which is equivalent to 
the formula for ak in (7.6.51).
c) Similarly, derive the formulas for bk and a0.
7.6.13 
(Exact period of a conservative oscillator) Consider the Duffing oscillator 
x
x
x
+
+
=
F
3
0, where 0  F 1, x (0)  a, and x( )
.
0
0

a) Using conservation of energy, express the oscillation period T ( F ) as a certain 
integral.
b) Expand the integrand as a power series in F, and integrate term by term to 
obtain an approximate formula T ( F )  c0 c1F  c2F2 O ( F3 ). Find c0, c1, c2 
and check that c0, c1 are consistent with (7.6.57).

240 
LIMIT CYCLES
7.6.14 
(Computer test of two-timing) Consider the equation 

x
x
x
+
+
=
F
3
0.
a) Derive the averaged equations.
b) Given the initial conditions x (0)  a, x( )
,
0
0

 solve the averaged equations 
and thereby find an approximate formula for x ( t,F ).
c) Solve 

x
x
x
+
+
=
F
3
0  numerically for a  1, F  2, 0 b t b 50, and plot the 
result on the same graph as your answer to part (b). Notice the impressive 
agreement, even though F is not small!
7.6.15 
(Pendulum) Consider the pendulum equation x
x
+
=
sin
.0
a) Using the method of Example 7.6.4, show that the frequency of small oscilla-
tions of amplitude a  1 is given by X ≈−
1
1
16
2
a . (Hint: sin
,
x
x
x
≈
−1
6
3  
where 1
6
3
x  is a “small” perturbation.)
b) Is this formula for X consistent with the exact results obtained in Exercise 6.7.4?
7.6.16 
(Amplitude of the van der Pol oscillator via Green’s theorem) Here’s 
another way to determine the radius of the nearly circular limit cycle of the van der 
Pol oscillator 

x
x x
x
+
−
+
=
F (
)
,
2
0
1
 in the limit F  1. Assume that the limit 
cycle is a circle of unknown radius a about the origin, and invoke the normal form 
of Green’s theorem (i.e., the 2-D divergence theorem):
v⋅
=
∇⋅
∫
∫∫
n
v
dl
dA
C
A
v
where C is the cycle and A is the region enclosed. By substituting v
x



 
( , )
x y  
and evaluating the integrals, show that a x 2.
7.6.17 
(Playing on a swing) A simple model for a child playing on a swing is 
x
t
x
+
+
+
=
(
cos
)sin
l
2
εγ
ε
0
where F and H are parameters, and 0  F 1. The variable x measures the angle 
between the swing and the downward vertical. The term l  FH  Fcos 2t models 
the effects of gravity and the periodic pumping of the child’s legs at approximately 
twice the natural frequency of the swing. The question is: Starting near the fixed 
point x  0 , x  0,  can the child get the swing going by pumping her legs this 
way, or does she need a push?
a) For small x, the equation may be replaced by x
t x
+
+
+
=
(
cos
)
.
l
2
εγ
ε
0  Show 
that the averaged equations (7.6.53) become
′ =
′ =
+
r
r
1
4
1
2
1
2
2
2
sin
,
(
cos
),
φ
φ
γ
φ
where x  r cos R  r ( T ) cos ( t G ( T )), x
r
r T
t
T
= −
= −
+
sin
(
)sin(
(
)),
θ
φ
 and 
prime denotes differentiation with respect to slow time T Ft. Hint: To average 
terms like cos 2t cosR sinR over one cycle of R, recall that t  RG and use trig 
identities:

241
EXERCISES
cos
cos sin
cos(
)sin
(cos
cos
sin
sin
)s
2
2
2
2
2
2
2
2
1
2
1
2
t
θ
θ
θ
φ
θ
θ
φ
θ
φ
=
−
=
+
in
sin
.
2
2
1
4
θ
φ
=
b) Show that the fixed point r  0 is unstable to exponentially growing oscillations, 
i.e., r ( T )  r0ekT with k 0, if |H|  Hc where Hc is to be determined. (Hint: For r 
near 0, a
G  ra so G equilibrates relatively rapidly.)
c) For |H|  Hc, write a formula for the growth rate k in terms of H.
d) How do the solutions to the averaged equations behave if |H|  Hc?
e) Interpret the results physically.
7.6.18 
(Mathieu equation and a super-slow time scale) Consider the Mathieu 
equation x
a
t x
+
+
=
(
cos )
F
0  with a x l. Using two-timing with a slow time 
T    F2t, show that the solution becomes unbounded as t l d if 
1
2
−
+
≤
≤+
+
1
12
4
5
12
2
4
1
F
F
F
F
O
a
O
(
)
(
).
7.6.19 
(Poincaré-Lindstedt method) This exercise guides you through an 
improved version of perturbation theory known as the Poincaré-Lindstedt method. 
Consider the Duffing equation x
x
x
+
+
=
F
3
0, where 0  F 1, x (0)  a, and 
x( )
.
0
0

 We know from phase plane analysis that the true solution x ( t, F ) is peri-
odic; our goal is to find an approximate formula for x ( t, F ) that is valid for all t. 
The key idea is to regard the frequency X as unknown in advance, and to solve for 
it by demanding that x ( t, F ) contains no secular terms.
a) Define a new time U  Xt such that the solution has period 2Q with respect to U. 
Show that the equation transforms to X2x´  x  Fx3  0.
b) Let x ( U, F )  x0 ( U )  Fx1 ( U )  F2x2 ( U )  O ( F3 ) and X  l  FX1 F2X2  O ( F3 ). 
(We know already that X0  1 since the solution has frequency X  1 when 
F  0.) Substitute these series into the differential equation and collect powers 
of F. Show that
O
x
x
O
x
x
x
x
1
 
 
( )
′′+
=
′′+
= −
′′−
:
( ) :
.
0
0
1
1
1
0
0
3
0
2
ε
ω
c) Show that the initial conditions become x0 (0)  a, x0 0
0
( )
;

 x
x
k
k
( )
( )
0
0
0



 
for all k 0.
d) Solve the O (1) equation for x0.
e) Show that after substitution of x0 and the use of a trigonometric identity, the 
O ( F ) equation becomes 
′′+
=
−
−
x
x
a
a
a
1
1
1
3
4
3
1
4
3
2
3
(
)cos
cos
.
ω
τ
τ  Hence, to 
avoid secular terms, we need X1
3
8
2
 a .
f) Solve for x1.
Two comments: (1) This exercise shows that the Duffing oscillator has a fre-
quency that depends on amplitude: ω
ε
ε
= +
+
1
3
8
2
2
a
O(
), in agreement with 

242 
LIMIT CYCLES
(7.6.57). (2) The Poincaré-Lindstedt method is good for approximating periodic 
solutions, but that’s all it can do; if you want to explore transients or non-periodic 
solutions, you can’t use this method. Use two-timing or averaging theory instead.
7.6.20 
Show that if we had used regular perturbation to solve Exercise 7.6.19, we 
would have obtained x t
a
t
a
t
t
t
t
O
( , )
cos
[
sin
(cos
cos )]
(
).
F
F
F
=
+
−
+
−
+
3
3
8
1
32
2
3
 
Why is this solution inferior?
7.6.21 
Using the Poincaré-Lindstedt method, show that the frequency of the 
limit cycle for the van der Pol oscillator 

x
x
x
x
+
−
+
=
F(
)
2
1
0  is given by 
ω
ε
ε
= −
+
1
1
16
2
3
O(
).
7.6.22 
(Asymmetric spring) Use the Poincaré-Lindstedt method to find the first 
few terms in the expansion for the solution of x
x
x
+
+
=
F
2
0,  with x (0)  a, 
x( )
.
0
0

 Show that the center of oscillation is at x
a
x 1
2
2
F
,  approximately.
7.6.23 
Find the approximate relation between amplitude and frequency for the 
periodic solutions of 

x
xx
x
−
+
=
F
0.
7.6.24 
(Computer algebra) Using Mathematica, Maple, or some other computer 
algebra package, apply the Poincaré-Lindstedt method to the problem 
x
x
x
+
−
=
F
3
0,  with x (0)  a, and x( )
.
0
0

 Find the frequency X of periodic 
solutions, up to and including the O ( F3 ) term.
7.6.25 
(The method of averaging) Consider the weakly nonlinear oscillator 


x
x
h x x t
+
+
=
F ( , , )
.0  Let x ( t )  r ( t ) cos ( t  G ( t )), x
r t
t
t
= −
+
( )sin(
( )).
G
 This 
change of variables should be regarded as a definition of r ( t ) and G ( t ).
a) Show that r
h
t
=
+
ε
φ
sin(
), r
h
t
φ
ε
φ
=
+
cos(
).  (Hence r and G are slowly 
varying for 0  F  1, and thus x ( t ) is a sinusoidal oscillation modulated by a 
slowly drifting amplitude and phase.)
b) Let r
t
r t
r
d
t
t
( )
( )
( )
=
=
−
+
∫
1
2π
π
π
τ
τ  denote the running average of r over one 
cycle of the sinusoidal oscillation. Show that d r
dt
dr dt
/
,

 i.e., it doesn’t 
matter whether we differentiate or time-average first.
c) Show that d r
dt
h r
t
r
t
t
t
/
[ cos(
),
sin(
), ] sin(
) .
=
+
−
+
+
ε
φ
φ
θ
d) The result of part (c) is exact, but not helpful because the left-hand side involves 
r  whereas the right-hand side involves r. Now comes the key approximation: 
replace r and G by their averages over one cycle. Show that r t
r t
O
( )
( )
( )
=
+
F  
and φ
φ
ε
( )
( )
( ),
t
t
O
=
+
 and therefore
dr
dt
h r
t
r
t
t
t
O
rd
dt
h r
/
[ cos(
),
sin(
), ] sin(
)
(
)
/
[ c
=
+
−
+
+
+
=
ε
φ
φ
φ
ε
φ
ε
2
os(
),
sin(
), ] cos(
)
(
)
t
r
t
t
t
O
+
−
+
+
+
φ
φ
φ
ε2
where the barred quantities are to be treated as constants inside the averages. These 
equations are just the averaged equations (7.6.53), derived by a different approach 

243
EXERCISES
in the text. It is customary to drop the overbars; one usually doesn’t distinguish 
between slowly varying quantities and their averages.
7.6.26 
(Calibrating the method of averaging) Consider the equation 
x
x
t
= −F sin
,
2
 with 0 b F  1 and x  x0 at t  0.
a) Find the exact solution to the equation.
b) Let x t
x
d
t
t
( )
( )
.
=
−
+
∫
1
2π
π
π
τ
τ  Show that x t
x t
O
( )
( )
( ).
=
+
F  Use the method of 
averaging to find an approximate differential equation satisfied by x , and 
solve it. 
c) Compare the results of parts (a) and (b); how large is the error incurred by 
averaging?

244 
BIFURCATIONS REVISITED
8
BIFURCATIONS REVISITED
8.0 Introduction
This chapter extends our earlier work on bifurcations (Chapter 3). As we move up 
from one-dimensional to two-dimensional systems, we still find that fixed points 
can be created or destroyed or destabilized as parameters are varied—but now the 
same is true of closed orbits as well. Thus we can begin to describe the ways in which 
oscillations can be turned on or off.
In this broader context, what exactly do we mean by a bifurcation? The usual 
definition involves the concept of “topological equivalence” (Section 6.3): if the 
phase portrait changes its topological structure as a parameter is varied, we say 
that a bifurcation has occurred. Examples include changes in the number or sta-
bility of fixed points, closed orbits, or saddle connections as a parameter is varied.
This chapter is organized as follows: for each bifurcation, we start with a sim-
ple prototypical example, and then graduate to more challenging examples, either 
briefly or in separate sections. Models of genetic switches, chemical oscillators, 
driven pendula and Josephson junctions are used to illustrate the theory.
8.1 Saddle-Node, Transcritical, and Pitchfork 
Bifurcations
The bifurcations of fixed points discussed in Chapter 3 have analogs in two 
dimensions (and indeed, in all dimensions). Yet it turns out that nothing really 
new happens when more dimensions are added—all the action is confined to a 
one-dimensional subspace along which the bifurcations occur, while in the extra 
dimensions the flow is either simple attraction or repulsion from that subspace, as 
we’ll see below.

245
8.1 SADDLE-NODE, TRANSCRITICAL, AND PITCHFORK BIFURCATIONS
Saddle-Node Bifurcation
The saddle-node bifurcation is the basic mechanism for the creation and 
destruction of fixed points. Here’s the prototypical example in two dimensions:
2
x
x
N



y
y
= −.  
(1)
In the x-direction we see the bifurcation behavior discussed in Section 3.1, while in 
the y-direction the motion is exponentially damped.
Consider the phase portrait as N varies. For N  0, Figure 8.1.1 shows that there 
are two fixed points, a stable node at ( *, *)
(
,0)
x
y
N

 and a saddle at (
,0).
N

 
As N decreases, the saddle and node approach each other, then collide when N  0, 
and finally disappear when N  0.
x
y
x
0
0
0
=
<
>
x
ghost
μ
μ
μ
Figure 8.1.1
Even after the fixed points have annihilated each other, they continue to influ-
ence the flow—as in Section 4.3, they leave a ghost, a bottleneck region that sucks 
trajectories in and delays them before allowing passage out the other side. For 
the same reasons as in Section 4.3, the time spent in the bottleneck generically 
increases as ( N  Nc )1 / 2, where Nc is  the value at which the saddle-node bifurca-
tion occurs. Some applications of this scaling law in condensed-matter physics are 
discussed by Strogatz and Westervelt 
(1989). 
Figure 8.1.1 is representative of the 
following 
more 
general 
situation. 
Consider a two-dimensional system 
x
f x y

( , ), y
g x y

( ,
)
 
 that depends 
on a parameter N. Suppose that for 
some value of N the nullclines intersect 
as shown in Figure 8.1.2. Notice that 
each intersection corresponds to a fixed 
point since x  0  and y  0  simultane-
x
y
.
.
=
=
0
0
Figure 8.1.2

246 
BIFURCATIONS REVISITED
ously. Thus, to see how the fixed points move as N changes, we just have to watch 
the intersections. Now suppose that the nullclines pull away from each other as N 
varies, becoming tangent at N  Nc  . Then the fixed points approach each other and 
collide when N  Nc  ; after the nullclines pull apart, there are no intersections and 
the fixed points disappear with a bang. The point is that all saddle-node bifurca-
tions have this character locally.
EXAMPLE 8.1.1:
The following system has been discussed by Griffith (1971) as a model for a 
genetic control system. The activity of a certain gene is assumed to be directly 
induced by two copies of the protein for which it codes. In other words, the gene 
is stimulated by its own product, potentially leading to an autocatalytic feedback 
process. In dimensionless form, the equations are


x
ax
y
y
x
x
by
= −
+
= +
−
2
2
1
where x and y are proportional to the concentrations of the protein and the mes-
senger RNA from which it is translated, respectively, and a, b 0 are parameters 
that govern the rate of degradation of x and y.
Show that the system has three fixed points when a  ac , where ac is to be deter-
mined. Show that two of these fixed points coalesce in a saddle-node bifurca-
tion when a  ac . Then sketch the phase portrait for a  ac , and give a biological 
interpretation.
Solution: The nullclines are given by the line y  ax and the sigmoidal curve
y
x
b
x
=
+
2
2
1(
)
as sketched in Figure 8.1.3. Now suppose we vary a while holding b fixed. This 
is simple to visualize, since a is the slope of the line. For small a there are three 
intersections, as in Figure 8.1.3. 
As a increases, the top two inter-
sections approach each other and 
collide when the line intersects the 
curve tangentially. For larger values 
of a, those fixed points disappear, 
leaving the origin as the only fixed 
point.
y
y
y
x2
x2)
+
1(
b
ax
x
=
=
Figure 8.1.3

247
8.1 SADDLE-NODE, TRANSCRITICAL, AND PITCHFORK BIFURCATIONS
To find ac  , we compute the fixed points directly and find where they coalesce. The 
nullclines intersect when
ax
x
b
x
=
+
2
2
1(
).
One solution is x*  0, in which case y*  0. The other intersections satisfy the 
quadratic equation
ab (1  x2 )  x  
(2)
which has two solutions
x
a b
ab
* = ±
−
1
1
4
2
2
2
if 1  4a2 b2  0, i.e., 2ab  1. These solutions coalesce when 2ab  1. Hence
ac  1 / 2b.
For future reference, note that the fixed point x*  1 at the bifurcation.
The nullclines (Figure 8.1.4) provide a lot of information about the phase por-
trait for a ac . The vector field is vertical on the line y  ax and horizontal on the 
sigmoidal curve. Other arrows can be sketched by noting the signs of x  and y. It 
appears that the middle fixed point is a saddle and the other two are sinks. To con-
firm this, we turn now to the classification of the fixed points.
y
x
Figure 8.1.4
The Jacobian matrix at ( x, y ) is
A
a
b
x
x
=
−
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟
+
1
2
1
2 2
(
)
.

248 
BIFURCATIONS REVISITED
A has trace U  ( a  b ) 0 so all the fixed points are either sinks or saddles, 
depending on the value of the determinant %. At (0,0), %  ab  0, so the origin is 
always a stable fixed point. In fact, it is a stable node, since U2 4%  ( a  b ) 2 
0 (except in the degenerate case a  b, which we disregard). At the other two fixed 
points, % looks messy but it can be simplified using (2). We find
Δ =
−
+
(
)
=
−+
⎡
⎣
⎢⎢
⎤
⎦
⎥⎥=
−
+
⎡
⎣
ab
x
x
ab
x
ab
x
x
2
1
1
2
1
1
1
2
2
2
2
2
*
( *)
( *)
( *)
( *)
⎢⎢
⎤
⎦
⎥⎥.
So %  0 for the “middle” fixed point, which has 0  x*  1; this is a saddle point. 
The fixed point with x*  1 is always a stable node, since %  ab and therefore 
U2  4%( a  b ) 2 0.
The phase portrait is plotted in Figure 8.1.5. By looking back at Figure 8.1.4, 
we can see that the unstable manifold of the saddle is necessarily trapped in the 
narrow channel between the two nullclines. More importantly, the stable manifold 
separates the plane into two regions, each a basin of attraction for a sink.
y
x
Figure 8.1.5
The biological interpretation is that the system can act like a biochemical switch, 
but only if the mRNA and protein degrade slowly enough—specifically, their 
decay rates must satisfy ab 1 / 2. In this case, there are two stable steady states: 
one at the origin, meaning that the gene is silent and there is no protein around to 
turn it on; and one where x and y are large, meaning that the gene is active and 
sustained by the high level of protein. The stable manifold of the saddle acts like a 
threshold; it determines whether the gene turns on or off, depending on the initial 
values of x and y. ■ 
As advertised, the flow in Figure 8.1.5 is qualitatively similar to that in the ide-
alized Figure 8.1.1. All trajectories relax rapidly onto the unstable manifold of the 
saddle, which plays a completely analogous role to the x-axis in Figure 8.1.1.
Thus, in many respects, the bifurcation is a fundamentally one-dimensional 
event, with the fixed points sliding toward each other along the unstable manifold 

249
8.1 SADDLE-NODE, TRANSCRITICAL, AND PITCHFORK BIFURCATIONS
like beads on a string. This is why we spent so much time looking at bifurcations 
in one-dimensional systems—they’re the building blocks of analogous bifurca-
tions in higher dimensions. (The fundamental role of one-dimensional systems 
can be justified rigorously by “center manifold theory”—see Wiggins (1990) for an 
introduction.)
Transcritical and Pitchfork Bifurcations
Using the same idea as above, we can also construct prototypical examples of 
transcritical and pitchfork bifurcations at a stable fixed point. In the x-direction 
the dynamics are given by the normal forms discussed in Chapter 3, and in the 
y-direction the motion is exponentially damped. This yields the following examples:
2,
x
x
x
y
y
N


 


 
(transcritical)
3,
x
x
x
y
y
N


 


 
(supercritical pitchfork)
3,
x
x
x
y
y
N


 


 
(subcritical pitchfork)
The analysis in each case follows the same pattern, so we’ll discuss only the super-
critical pitchfork, and leave the other two cases as exercises.
EXAMPLE 8.1.2:
Plot the phase portraits for the supercritical pitchfork system 
3
–
,
x
x
x
N


y
y
= −, for N  0 , N  0, and N  0.
Solution: For N  0, the only fixed point is a stable node at the origin. For N  0, 
the origin is still stable, but now we have very slow (algebraic) decay along the 
x-direction instead of exponential decay; this is the phenomenon of “critical slow-
ing down” discussed in Section 3.4 and Exercise 2.4.9. For N  0, the origin loses 
stability and gives birth to two new stable fixed points symmetrically located at 
	

*, *
(
,0).
x
y
N
 o
 By computing the Jacobian at each point, you can check 
that the origin is a saddle and the other two fixed points are stable nodes. The 
phase portraits are shown in Figure 8.1.6. ■
0
0
0
=
>
<
μ
μ
μ
y
x
Figure 8.1.6

250 
BIFURCATIONS REVISITED
As mentioned in Chapter 3, pitchfork bifurcations are common in systems that 
have a symmetry. Here’s an example.
EXAMPLE 8.1.3:
Show that a supercritical pitchfork bifurcation occurs at the origin in the system
sin
x
x
y
x
y
x
y
N







and determine the bifurcation value Nc . Plot the phase portrait near the origin for 
Nslightly greater than Nc.
Solution: The system is invariant under the change of variables x lx, y l y, 
so the phase portrait must be symmetric under reflection through the origin. The 
origin is a fixed point for all N, and its Jacobian is
1
1
1
1
A
N

¬

­

­

­

­



®
which has U  N and %  ( N 2). Hence the origin is a stable fixed point if 
N  2 and a saddle if N  2. This suggests that a pitchfork bifurcation occurs 
at Nc  2. To confirm this, we seek a symmetric pair of fixed points close to the 
origin for N close to Nc. (Note that at this stage we don’t know whether the bifur-
cation is sub- or supercritical.) The fixed points satisfy y  x and hence ( N  1) x 
sin x  0. One solution is x  0, but we’ve found that already. Now suppose x is 
small and nonzero, and expand the sine as a power series. Then
3
5
(
1)
(
)
0.
3!
x
x
x
O x
N 




After dividing through by x and neglecting higher-order terms, we get 
2
2
6
0.
x
N  
x
 Hence there is a pair of fixed points with 
*
6(
2)
x
N
x o

 for 
N slightly greater than 2. Thus a supercritical pitchfork bifurcation occurs at 
Nc  2. (If the bifurcation had been subcritical, the pair of fixed points would 
exist when the origin was stable, not after it has become a saddle.) Because the 
bifurcation is supercritical, we know the new fixed points are stable without even 
checking.
To draw the phase portrait near (0,0) for N slightly greater than 2 , it’s helpful 
to find the eigenvectors of the Jacobian at the origin. This can be done exactly, but 
a simple approximation is that the Jacobian is close to that at the bifurcation. Thus
A ≈−
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
1
1
1
1

251
8.2 HOPF BIFURCATIONS
which has eigenvectors (1,1) and (1,1), with eigenvalues M  0 and M  2, respec-
tively. For N slightly greater than 2 , the origin becomes a saddle and so the zero 
eigenvalue becomes slightly positive. This information implies the phase portrait 
shown in Figure 8.1.7.
y
x
Figure 8.1.7
Note that because of the approximations we’ve made, this picture is only valid 
locally in both parameter and phase space—if we’re not near the origin and if N is 
not close to Nc, all bets are off. ■
In all of the examples above, the bifurcation occurs when %  0, or equiva-
lently, when one of the eigenvalues equals zero. More generally, the saddle-node, 
transcritical, and pitchfork bifurcations are all examples of zero-eigenvalue bifur-
cations. (There are other examples, but these are the most common.) Such bifurca-
tions always involve the collision of two or more fixed points.
In the next section we’ll consider a fundamentally new kind of bifurcation, one 
that has no counterpart in one-dimensional systems. It provides a way for a fixed 
point to lose stability without colliding with any other fixed points.
8.2 Hopf Bifurcations
Suppose a two-dimensional system has a stable fixed point. What are all the pos-
sible ways it could lose stability as a parameter N varies? The eigenvalues of the 
Jacobian are the key. If the fixed point is stable, the eigenvalues M1, M2 must both 
lie in the left half-plane Re M  0. Since the M’s satisfy a quadratic equation with 

252 
BIFURCATIONS REVISITED
real coefficients, there are two possible pictures: either the eigenvalues are both 
real and negative (Figure 8.2.1a) or they are complex conjugates (Figure 8.2.1b). To 
destabilize the fixed point, we need one or both of the eigenvalues to cross into the 
right half-plane as N varies.
(a)
(b)
Re
Re λ
λ
λ
λ
Im
Im
Figure 8.2.1
In Section 8.1 we explored the cases in which a real eigenvalue passes through 
M  0. These were just our old friends from Chapter 3, namely the saddle-node, 
transcritical, and pitchfork bifurcations. Now we consider the other possible sce-
nario, in which two complex conjugate eigenvalues simultaneously cross the imag-
inary axis into the right half-plane.
Supercritical Hopf Bifurcation
Suppose we have a physical system that settles down to equilibrium through 
exponentially damped oscillations. In other words, small disturbances decay after 
“ringing” for a while (Figure 8.2.2a). Now suppose that the decay rate depends on 
a control parameter N. If the decay becomes slower and slower and finally changes 
to growth at a critical value Nc , the equilibrium state will lose stability. In many 
cases the resulting motion is a small-amplitude, sinusoidal, limit cycle oscillation 
about the former steady state (Figure 8.2.2b). Then we say that the system has 
undergone a supercritical Hopf bifurcation.
In terms of the flow in phase 
space, a supercritical Hopf bifur-
cation occurs when a stable spiral 
changes into an unstable spiral 
surrounded by a small, nearly 
elliptical limit cycle. Hopf bifur-
cations can occur in phase spaces 
(a)
c
c
μ
μ
μ
μ
<
>
(b)
Figure 8.2.2

253
8.2 HOPF BIFURCATIONS
of any dimension n p 2, but as in the rest of this chapter, we’ll restrict ourselves to 
two dimensions.
A simple example of a supercritical Hopf bifurcation is given by the following 
system:
3
2.
r
r
r
br
N
R
X






There are three parameters: N controls the stability of the fixed point at the origin, 
X gives the frequency of infinitesimal oscillations, and b determines the depen-
dence of frequency on amplitude for larger amplitude oscillations.
Figure 8.2.3 plots the phase portraits for N above and below the bifurcation. 
When N  0 the origin r  0 is a stable spiral whose sense of rotation depends on 
the sign of X. For N  0 the origin is still a stable spiral, though a very weak one: the 
decay is only algebraically fast. (This case was shown in Figure 6.3.2. Recall that 
the linearization wrongly predicts a center at the origin.) Finally, for N  0 there is 
an unstable spiral at the origin and a stable circular limit cycle at 
.
r
N

μ
μ
0
<
>0
Figure 8.2.3
To see how the eigenvalues behave during the bifurcation, we rewrite the system 
in Cartesian coordinates; this makes it easier to find the Jacobian. We write x 
r cos R, y  r sin R. Then
	

	

3
2
2
2
2
2
cos
sin
(
)cos
(
)sin
[
]
[
]
cubic terms
x
r
r
r
r
r
br
x
y
x
b x
y
y
x
y
R
R
R
N
R
X
R
N
X
N
X


















and similarly
cubic terms.
y
x
y
X
N




So the Jacobian at the origin is

254 
BIFURCATIONS REVISITED
,
A
N
X
X
N

¬
 ­

­

­

­

®
which has eigenvalues
M  N o iX
As expected, the eigenvalues cross the imaginary axis from left to right as N 
increases from negative to positive values.
Rules of Thumb
Our idealized case illustrates two rules that hold generically for supercritical Hopf 
bifurcations:
1. The size of the limit cycle grows continuously from zero, and increases 
proportional to 
–
,
c
N
N
 for N close to Nc.
2. The frequency of the limit cycle is given approximately by X  Im M, 
evaluated at N  Nc. This formula is exact at the birth of the limit cycle, 
and correct within O ( N Nc) for N close to Nc. The period is therefore 
(2
Im )
(
).
c
T
O
Q
M
N
N



But our idealized example also has some artifactual properties. First, in Hopf 
bifurcations encountered in practice, the limit cycle is elliptical, not circular, and 
its shape becomes distorted as N moves away from the bifurcation point. Our 
example is only typical topologically, not geometrically. Second, in our idealized 
case the eigenvalues move on horizontal lines as N varies, i.e., Im M is strictly inde-
pendent of N. Normally, the eigenvalues would follow a curvy path and cross the 
imaginary axis with nonzero slope (Figure 8.2.4).
Re
Im λ
λ
λ
λ
(μ)
(μ )
Figure 8.2.4

255
8.2 HOPF BIFURCATIONS
Subcritical Hopf Bifurcation
Like pitchfork bifurcations, Hopf bifurcations come in both super- and subcrit-
ical varieties. The subcritical case is always much more dramatic, and potentially 
dangerous in engineering applications. After the bifurcation, the trajectories must 
jump to a distant attractor, which may be a fixed point, another limit cycle, infin-
ity, or—in three and higher dimensions—a chaotic attractor. We’ll see a concrete 
example of this last, most interesting case when we study the Lorenz equations 
(Chapter 9). 
But for now, consider the two-dimensional example
3
5
2.
r
r
r
r
br
N
R
X







The important difference from the earlier supercritical case is that the cubic term 
r 3 is now destabilizing; it helps to drive trajectories away from the origin.
The phase portraits are shown in Figure 8.2.5. For N  0 there are two attrac-
tors, a stable limit cycle and a stable fixed point at the origin. Between them lies an 
unstable cycle, shown as a dashed curve in Figure 8.2.5; it’s the player to watch in 
this scenario. As N increases, the unstable cycle tightens like a noose around the 
fixed point. A subcritical Hopf bifurcation occurs at N  0, where the unstable cycle 
shrinks to zero amplitude and engulfs the origin, rendering it unstable. For N  0, 
the large-amplitude limit cycle is suddenly the only attractor in town. Solutions 
that used to remain near the origin are now forced to grow into large-amplitude 
oscillations.
μ
μ
0
<
>0
Figure 8.2.5
Note that the system exhibits hysteresis: once large-amplitude oscillations have 
begun, they cannot be turned off by bringing N back to zero. In fact, the large 
oscillations will persist until N   where the stable and unstable cycles collide 
and annihilate. This destruction of the large-amplitude cycle occurs via another 
type of bifurcation, to be discussed in Section 8.4.

256 
BIFURCATIONS REVISITED
Subcritical Hopf bifurcations occur in the dynamics of nerve cells (Rinzel and 
Ermentrout 1989), in aeroelastic flutter and other vibrations of airplane wings 
(Dowell and Ilgamova 1988, Thompson and Stewart 1986), and in instabilities of 
fluid flows (Drazin and Reid 1981).
Subcritical, Supercritical, or Degenerate Bifurcation?
Given that a Hopf bifurcation occurs, how can we tell if it’s sub- or supercriti-
cal? The linearization doesn’t provide a distinction: in both cases, a pair of eigen-
values moves from the left to the right half-plane.
An analytical criterion exists, but it can be difficult to use (see Exercises 8.2.12–
15 for some tractable cases). A quick and dirty approach is to use the computer. 
If a small, attracting limit cycle appears immediately after the fixed point goes 
unstable, and if its amplitude shrinks back to zero as the parameter is reversed, 
the bifurcation is supercritical; otherwise, it’s probably subcritical, in which case 
the nearest attractor might be far from the fixed point, and the system may exhibit 
hysteresis as the parameter is reversed. Of course, computer experiments are 
not proofs and you should check the numerics carefully before making any firm 
conclusions.
Finally, you should also be aware of a degenerate Hopf bifurcation. An example 
is given by the damped pendulum 
sin
0.
x
x
x
N





 As we change the damping 
N from positive to negative, the fixed point at the origin changes from a stable to an 
unstable spiral. However at N  0 we do not have a true Hopf bifurcation because 
there are no limit cycles on either side of the bifurcation. Instead, at N  0 we have 
a continuous band of closed orbits surrounding the origin. These are not limit 
cycles! (Recall that a limit cycle is an isolated closed orbit.)
This degenerate case typically arises when a nonconservative system suddenly 
becomes conservative at the bifurcation point. Then the fixed point becomes a 
nonlinear center, rather than the weak spiral required by a Hopf bifurcation. See 
Exercise 8.2.11 for another example.
EXAMPLE 8.2.1:
Consider the system 
2,
x
x
y
xy
N




 
3.
y
x
y
y
N




 Show that a Hopf 
bifurcation occurs at the origin as N varies. Is the bifurcation subcritical, supercrit-
ical, or degenerate?
Solution: The Jacobian at the origin is 
1 ,
1
A
N
N

¬
 ­

­

­

­

®
 which has U    2N, 
%  N2  1  0, and M  N o i. Hence, as N increases through zero, the origin 
changes from a stable spiral to an unstable spiral. This suggests that some kind of 
Hopf bifurcation takes place at N  0.

257
8.3 OSCILLATING CHEMICAL REACTIONS
To decide whether the bifurcation is subcritical, supercritical, or degenerate, 
we use simple reasoning and numerical integration. If we transform the system to 
polar coordinates, we find that
2,
r
r
ry
N



as you should check. Hence 
.
r
r
N
p

 This implies that for N  0, r ( t ) grows at least 
as fast as r0 eNt. In other words, all trajectories are repelled out to infinity! So there 
are certainly no closed orbits for N  0. In particular, the unstable spiral is not 
surrounded by a stable limit cycle; hence the bifurcation cannot be supercritical.
Could the bifurcation be degenerate? That would require that the origin be a 
nonlinear center when N  0. But r  is strictly positive away from the x-axis, so 
closed orbits are still impossible.
By process of elimination, we expect that the bifurcation is subcritical. This 
is confirmed by Figure 8.2.6, which is a computer-generated phase portrait for 
N  0.2.
y
x
1
1
1
1
−
−
Figure 8.2.6
Note that an unstable limit cycle surrounds the stable fixed point, just as we expect 
in a subcritical bifurcation. Furthermore, the cycle is nearly elliptical and sur-
rounds a gently winding spiral—these are typical features of either kind of Hopf 
bifurcation. ■
8.3 Oscillating Chemical Reactions
For an application of Hopf bifurcations, we now consider a class of experimen-
tal systems known as chemical oscillators. These systems are remarkable, both 
for their spectacular behavior and for the story behind their discovery. After pre-
senting this background information, we analyze a simple model for oscillations 
in the chlorine dioxide–iodine–malonic acid reaction. The definitive reference 

258 
BIFURCATIONS REVISITED
on chemical oscillations is the book edited by Field and Burger (1985). See also 
Epstein et al. (1983), Winfree (1987b) and Murray (2002).
Belousov’s “Supposedly Discovered Discovery”
In the early 1950s the Russian biochemist Boris Belousov was trying to create 
a test tube caricature of the Krebs cycle, a metabolic process that occurs in living 
cells. When he mixed citric acid and bromate ions in a solution of sulfuric acid, 
and in the presence of a cerium catalyst, he observed to his astonishment that the 
mixture became yellow, then faded to colorless after about a minute, then returned 
to yellow a minute later, then became colorless again, and continued to oscillate 
dozens of times before finally reaching equilibrium after about an hour.
Today it comes as no surprise that chemical reactions can oscillate sponta-
neously—such reactions have become a standard demonstration in chemistry 
classes, and you may have seen one yourself. (For recipes, see Winfree (1980).) But 
in Belousov’s day, his discovery was so radical that he couldn’t get his work pub-
lished. It was thought that all solutions of chemical reagents must go monotoni-
cally to equilibrium, because of the laws of thermodynamics. Belousov’s paper 
was rejected by one journal after another. According to Winfree (1987b, p.161), 
one editor even added a snide remark about Belousov’s “supposedly discovered 
discovery” to the rejection letter.
Belousov finally managed to publish a brief abstract in the obscure proceed-
ings of a Russian medical meeting (Belousov 1959), although his colleagues weren’t 
aware of it until years later. Nevertheless, word of his amazing reaction circulated 
among Moscow chemists in the late 1950s, and in 1961 a graduate student named 
Zhabotinsky was assigned by his adviser to look into it. Zhabotinsky confirmed 
that Belousov was right all along, and brought this work to light at an interna-
tional conference in Prague in 1968, one of the few times that Western and Soviet 
scientists were allowed to meet. At that time there was a great deal of interest in 
biological and biochemical oscillations (Chance et al. 1973) and the BZ reaction, 
as it came to be called, was seen as a manageable model of those more complex 
systems.
The analogy to biology turned out to be surprisingly close: Zaikin and 
Zhabotinsky (1970) and Winfree (1972) observed beautiful propagating waves of 
oxidation in thin unstirred layers of BZ reagent, and found that these waves anni-
hilate upon collision, just like waves of excitation in neural or cardiac tissue. The 
waves always take the shape of expanding concentric rings or spirals (Color plate 
1). Spiral waves are now recognized to be a ubiquitous feature of chemical, biolog-
ical, and physical excitable media; in particular, spiral waves and their three-di-
mensional analogs, “scroll waves”, appear to be implicated in certain cardiac 
arrhythmias, a problem of great medical importance (Winfree 1987b).
Boris Belousov would be pleased to see what he started.

259
8.3 OSCILLATING CHEMICAL REACTIONS
In 1980, he and Zhabotinsky were awarded the Lenin Prize, the Soviet Union’s 
highest medal, for their pioneering work on oscillating reactions. Unfortunately, 
Belousov had passed away ten years earlier.
For more about the history of the BZ reaction, see Winfree (1984, 1987b). An 
English translation of Belousov’s original paper from 1951 appears in Field and 
Burger (1985).
Chlorine Dioxide–lodine–Malonic Acid Reaction
The mechanisms of chemical oscillations can be very complex. The BZ reac-
tion is thought to involve more than twenty elementary reaction steps, but luckily 
many of them equilibrate rapidly—this allows the kinetics to be reduced to as few 
as three differential equations. See Tyson (1985) for this reduced system and its 
analysis.
In a similar spirit, Lengyel et al. (1990) have proposed and analyzed a particu-
larly elegant model of another oscillating reaction, the chlorine dioxide-iodine-ma-
lonic acid (C1O2-I2-MA) reaction. Their experiments show that the following three 
reactions and empirical rate laws capture the behavior of the system:
MA+I
IMA
I
H
I
MA I
I
2
2
2
2
→
+
+
[
] = −
[
][
]
+[
]
−
+;
d
dt
k
k
a
b
1
1
 
(1)
ClO
I
ClO
I
ClO
ClO
I
2
2
1
2
2
2
2
2
+
→
+
[
] = −
[
]⎡⎣⎢
⎤⎦⎥
−
−
−
;
d
dt
k
 
(2)
ClO
I
H
Cl
I
H O;
2
2
2
4
4
2
2
−
−
+
−
+
+
→
+
+
d
dt
k
k
a
b
ClO
ClO
I
H
ClO
2
3
2
3
2
−
−
−
+
−
⎡⎣⎢
⎤⎦⎥= −
⎡⎣⎢
⎤⎦⎥⎡⎣⎢
⎤⎦⎥⎡⎣⎢
⎤⎦⎥−
⎡⎣⎢
⎤⎦⎥[
]
⎡⎣⎢
⎤⎦⎥
+ ⎡⎣⎢
⎤⎦⎥
−
−
I
I
I
2
2
u
 (3)
Typical values of the concentrations and kinetic parameters are given in Lengyel et 
al. (1990) and Lengyel and Epstein (1991).
Numerical integrations of (l)–(3) show that the model exhibits oscillations that 
closely resemble those observed experimentally. However this model is still too 
complicated to handle analytically. To simplify it, Lengyel et al. (1990) use a result 
found in their simulations: Three of the reactants (MA, I2, and ClO2 ) vary much 
more slowly than the intermediates I– and C1O2
–, which change by several orders 
of magnitude during an oscillation period. By approximating the concentrations 
of the slow reactants as constants and making other reasonable simplifications, 
they reduce the system to a two-variable model. (Of course, since this approxima-
tion neglects the slow consumption of the reactants, the model will be unable to 
account for the eventual approach to equilibrium.) After suitable nondimension-
alization, the model becomes

260 
BIFURCATIONS REVISITED
x
a
x
xy
x
=
−−+
4
1
2  
(4)
y
bx
y
x
=
−+
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
1
1
2  
(5)
where x and y are the dimensionless concentrations of I– and C1O2
–. The param-
eters a, b 0 depend on the empirical rate constants and on the concentrations 
assumed for the slow reactants.
We begin the analysis of (4), (5) by constructing a trapping region and applying 
the Poincaré−Bendixson theorem. Then we’ll show that the chemical oscillations 
arise from a supercritical Hopf bifurcation.
EXAMPLE 8.3.1:
Prove that the system (4), (5) has a closed orbit in the positive quadrant x,y  0 
if a and b satisfy certain constraints, to be determined.
Solution: As in Example 7.3.2, the nullclines help us to construct a trapping 
region. Equation (4) shows that x  0 on the curve
y
a
x
x
x
=
−
+
(
)(
)
1
4
2
 
(6)
and (5) shows that y  0  on the y-axis and on the parabola y  1  x2. These null-
clines are sketched in Figure 8.3.1, along with some representative vectors.
y
x
y
y.
.
.
.
x
x
0
=
0
>
0
0
<
=
Figure 8.3.1
(We’ve taken some pedagogical license with Figure 8.3.1; the curvature of the null-
cline (6) has been exaggerated to highlight its shape, and to give us more room to 
draw the vectors.)

261
8.3 OSCILLATING CHEMICAL REACTIONS
Now consider the dashed box shown in Figure 8.3.2. It’s a trapping region 
because all the vectors on the boundary point into the box.
y
x
x. =0
=0
y.
Figure 8.3.2
We can’t apply the Poincaré−Bendixson theorem yet, because there’s a fixed point
x
a
y
x
a
*
,
*
( *)
(
)
=
= +
= +
5
1
1
5
2
2
inside the box at the intersection of the nullclines. But now we argue as in 
Example 7.3.3: if the fixed point turns out to be a repeller, we can apply the Poincaré-
Bendixson theorem to the “punctured” box obtained by removing the fixed point.
All that remains is to see under what conditions (if any) the fixed point is a 
repeller. The Jacobian at ( x*, y* ) is
1
1
3
5
4
2
2
2
2
+
−
−
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟
( *)
( *)
*
( *)
*
.
x
x
x
b x
bx
(We’ve used the relation y*  1  ( x* ) 2 to simplify some of the entries in the 
Jacobian.) The determinant and trace are given by
Δ = +
>
=
−−
+
5
1
0
3
5
1
2
2
2
bx
x
x
bx
x
*
( *)
,
( *)
*
( *)
.
U
We’re in luck—since %  0, the fixed point is never a saddle. Hence ( x*, y* ) is a 
repeller if U  0, i.e., if
b
b
a
a
c
<
≡
−
3
5
25
. 
(7)
When (7) holds, the Poincaré-Bendixson theorem implies the existence of a closed 
orbit somewhere in the punctured box. ■

262 
BIFURCATIONS REVISITED
EXAMPLE 8.3.2:
Using numerical integration, show that a Hopf bifurcation occurs at b  bc and 
decide whether the bifurcation is sub- or supercritical.
Solution: The analytical results above show that as b decreases through bc , the 
fixed point changes from a stable spiral to an unstable spiral; this is the signature 
of a Hopf bifurcation. Figure 8.3.3 plots two typical phase portraits. (Here we have 
chosen a  10; then (7) implies bc  3.5.) When b  bc , all trajectories spiral into 
the stable fixed point (Figure 8.3.3a), while for b  bc they are attracted to a stable 
limit cycle (Figure 8.3.3b).
y
y
(a)
(b)
8
10
8
6
4
2
1
2
3
4
stable
limit cycle
a
10
2
=
=
b
a
10
4
=
=
b
6
4
2
1
2
3
4
x
x
Figure 8.3.3
Hence the bifurcation is supercritical—after the fixed point loses stability, it is sur-
rounded by a stable limit cycle. Moreover, by plotting phase portraits as b l bc 
from below, we could confirm that the limit cycle shrinks continuously to a point, 
as required. ■
Our results are summarized in the stability diagram in Figure 8.3.4. The bound-
ary between the two regions is given by the Hopf bifurcation locus b  3a / 525 / a.
b
a
20
30
40
50
10
0
0
10
20
30
40
50
stable
fixed point
stable
limit cycle
Figure 8.3.4

263
8.3 OSCILLATING CHEMICAL REACTIONS
EXAMPLE 8.3.3:
Approximate the period of the limit cycle for b slightly less than bc.
Solution: The frequency is approximated by the imaginary part of the eigenval-
ues at the bifurcation. As usual, the eigenvalues satisfy M2  UM  % 0. Since U  0 
and %  0 at b  bc, we find
M = ±i Δ.
But at bc,
Δ = +
=
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
+
=
−
5
1
5 3
5
25
5
1
5
15
2
2
2
b x
x
a
a
a
a
a
c *
( *)
(
)
625
25
2
a +
.
Hence X ≈
=
−
+
⎡⎣⎢
⎤⎦⎥
Δ1 2
2
2
1 2
15
625
25
(
) (
)
a
a
 and therefore 
T
a
a
=
=
+
−
⎡⎣⎢
⎤⎦⎥
2
2
25
15
625
2
2
1 2
π ω
π (
) (
)
.
A graph of T ( a ) is shown in Figure 8.3.5. As a
T
→∞
→
≈
,
.
.
2
15
1 63
Q
 ■
T
2.5
3.0
2.0
1.5
1.0
0
20
40
60
80
100
a
Figure 8.3.5

264 
BIFURCATIONS REVISITED
8.4 Global Bifurcations of Cycles
In two-dimensional systems, there are four common ways in which limit cycles are 
created or destroyed. The Hopf bifurcation is the most famous, but the other three 
deserve their day in the sun. They are harder to detect because they involve large 
regions of the phase plane rather than just the neighborhood of a single fixed point. 
Hence they are called global bifurcations. In this section we offer some prototypical 
examples of global bifurcations, and then compare them to one another and to the 
Hopf bifurcation. A few of their scientific applications are discussed in Sections 8.5 
and 8.6 and in the exercises.
Saddle-node Bifurcation of Cycles
A bifurcation in which two limit cycles coalesce and annihilate is called a fold 
or saddle-node bifurcation of cycles, by analogy with the related bifurcation of fixed 
points. An example occurs in the system
3
5
2
r
r
r
r
br
N
R
X







studied in Section 8.2. There we were interested in the subcritical Hopf bifurcation 
at N  0; now we concentrate on the dynamics for N  0.
It is helpful to regard the radial equation 
3
5
r
r
r
r
N




 as a one-dimensional 
system. As you should check, this system undergoes a saddle-node bifurcation of 
fixed points at Nc  –1/4. Now returning to the two-dimensional system, these 
fixed points correspond to circular limit cycles. Figure 8.4.1 plots the “radial phase 
portraits” and the corresponding behavior in the phase plane.
r
r
r
r
r
.
.
r.
0
=
>
>
<
μ
μ
μc
μc
μc
μ
Figure 8.4.1

265
8.4 GLOBAL BIFURCATIONS OF CYCLES
At Nc a half-stable cycle is born out of the clear blue sky. As N increases it splits into 
a pair of limit cycles, one stable, one unstable. Viewed in the other direction, a sta-
ble and unstable cycle collide and disappear as N decreases through Nc . Notice that 
the origin remains stable throughout; it does not participate in this bifurcation.
For future reference, note that at birth the cycle has O (1) amplitude, in contrast 
to the Hopf bifurcation, where the limit cycle has small amplitude proportional to 
( N  Nc ) 1 / 2.
Infinite-period Bifurcation
Consider the system
2
(1
)
sin
r
r
r
R
N
R






where Np0. This system combines two one-dimensional systems that we have 
studied previously in Chapters 3 and 4. In the radial direction, all trajectories 
(except r*  0) approach the unit circle monotonically as t l d. In the angular 
direction, the motion is everywhere counterclockwise if N  1, whereas there are 
two invariant rays defined by sin R  N if N  1. Hence as N decreases through 
Nc  1, the phase portraits change as in Figure 8.4.2.
slow
fast
μ
1
>
μ
1
<
Figure 8.4.2
As N  decreases, the limit cycle r  1 develops a bottleneck at R  π / 2 that becomes 
increasingly severe as N l 1+. The oscillation period lengthens and finally 
becomes infinite at Nc  1, when a fixed point appears on the circle; hence the term 
infinite-period bifurcation. For N  1, the fixed point splits into a saddle and a node.
As the bifurcation is approached, the amplitude of the oscillation stays O (1) 
but the period increases like ( N − Nc ) −1 / 2, for the reasons discussed in Section 4.3.

266 
BIFURCATIONS REVISITED
Homoclinic Bifurcation
In this scenario, part of a limit cycle moves closer and closer to a saddle point. 
At the bifurcation the cycle touches the saddle point and becomes a homoclinic 
orbit. This is another kind of infinite-period bifurcation; to avoid confusion, we’ll 
call it a saddle-loop or homoclinic bifurcation.
It is hard to find an analytically transparent example, so we resort to the com-
puter. Consider the system
2
.
x
y
y
y
x
x
xy
N







Figure 8.4.3 plots a series of phase portraits before, during, and after the bifurca-
tion; only the important features are shown.
Numerically, the bifurcation is found to occur at Nc x 0.8645. For N < Nc, 
say N  0.92, a stable limit cycle passes close to a saddle point at the origin 
(Figure 8.4.3a). As N increases to Nc, the limit cycle swells (Figure 8.4.3b) and bangs 
into the saddle, creating a homoclinic orbit (Figure 8.4.3c). Once N  Nc , the saddle 
connection breaks and the loop is destroyed (Figure 8.4.3d).
y
(a)
(c)
(d)
(b)
y
y
y
x
x
x
x
1
1
–
1
–
Figure 8.4.3
The key to this bifurcation is the behavior of the unstable manifold of the 
saddle. Look at the branch of the unstable manifold that leaves the origin to the 

267
8.4 GLOBAL BIFURCATIONS OF CYCLES
northeast: after it loops around, it either hits the origin (Figure 8.4.3c) or veers off 
to one side or the other (Figures 8.4.3a, d).
Scaling Laws
For each of the bifurcations given here, there are characteristic scaling laws that 
govern the amplitude and period of the limit cycle as the bifurcation is approached. 
Let N denote some dimensionless measure of the distance from the bifurcation, 
and assume that N  1. The generic scaling laws for bifurcations of cycles in 
two-dimensional systems are given in Table 7.4.1.
Amplitude of  
stable limit cycle
Period of cycle
Supercritical Hopf
O ( N1 / 2 )
O (1)
Saddle-node bifurcation of cycles
O (1)
O (1)
Infinite-period
O (1)
O ( N1 / 2 )
Homoclinic
O ( 1)
O (ln N )
Table 8.4.1
All of these laws have been explained previously, except those for the homoclinic 
bifurcation. The scaling of the period in that case is obtained by estimating the 
time required for a trajectory to pass by a saddle point (see Exercise 8.4.12 and 
Gaspard 1990).
Exceptions to these rules can occur, but only if there is some symmetry or other 
special feature that renders the problem nongeneric, as in the following example.
EXAMPLE 8.4.1:
The van der Pol oscillator 

x
x x
x
+
−
+
=
F (
)
2
1
0  does not seem to fit anywhere in 
Table 7.4.1. At F  0, the eigenvalues at the origin are pure imaginary ( M  oi ), 
suggesting that a Hopf bifurcation occurs at F  0. But we know from Section 7.6 
that for 0  F  1, the system has a limit cycle of amplitude r x 2. Thus the cycle 
is born “full grown,” not with size O ( F1 / 2 ) as predicted by the scaling law. What’s 
the explanation?
Solution: The bifurcation at F  0 is degenerate. The nonlinear term F xx2  van-
ishes at precisely the same parameter value as the eigenvalues cross the imaginary 
axis. That’s a nongeneric coincidence if there ever was one!
We can rescale x to remove this degeneracy. Write the equation as 



x
x
x x
x
+
+
−
=
F
F
2
0 . Let u2  F x2 to remove the F-dependence of the nonlinear 
term. Then u  F1 / 2x and the equation becomes
2
0.
u
u
u u
u
F
 






268 
BIFURCATIONS REVISITED
Now the nonlinear term is not destroyed when the eigenvalues become pure imag-
inary. From Section 7.6 the limit cycle solution is x ( t,F ) x 2 cost for 0  F  1. In 
terms of u this becomes
u t
t
( , )
cos .
F
F
≈(
)
2
Hence the amplitude grows like F1 / 2, just as expected for a Hopf bifurcation. ■
The scaling laws given here were derived by thinking about prototypical exam-
ples in two-dimensional systems. In higher-dimensional phase spaces, the corre-
sponding bifurcations obey the same scaling laws, but with two caveats: (1) Many 
additional bifurcations of limit cycles become possible; thus our table is no longer 
exhaustive. (2) The homoclinic bifurcation becomes much more subtle to analyze. 
It often creates chaotic dynamics in its aftermath (Guckenheimer and Holmes 
1983, Wiggins 1990).
All of this begs the question: Why should you care about these scaling laws? 
Suppose you’re an experimental scientist and the system you’re studying exhibits a 
stable limit cycle oscillation. Now suppose you change a control parameter and the 
oscillation stops. By examining the scaling of the period and amplitude near this 
bifurcation, you can learn something about the system’s dynamics (which are usu-
ally not known precisely, if at all). In this way, possible models can be eliminated 
or supported. For an example in physical chemistry, see Gaspard (1990).
8.5 Hysteresis in the Driven Pendulum and 
Josephson Junction
This section deals with a physical problem in which both homoclinic and 
infinite-period bifurcations arise. The problem was introduced back in Sections 4.4 
and 4.6. At that time we were studying the dynamics of a damped pendulum 
driven by a constant torque, or equivalently, its high-tech analog, a superconduct-
ing Josephson junction driven by a constant current. Because we weren’t ready for 
two-dimensional systems, we reduced both problems to vector fields on the circle 
by looking at the heavily overdamped limit of negligible mass (for the pendulum) or 
negligible capacitance (for the Josephson junction).
Now we’re ready to tackle the full two-dimensional problem. As we claimed 
at the end of Section 4.6, for sufficiently weak damping the pendulum and the 
Josephson junction can exhibit intriguing hysteresis effects, thanks to the coexis-
tence of a stable limit cycle and a stable fixed point. In physical terms, the pendu-
lum can settle into either a rotating solution where it whirls over the top, or a stable 
rest state where gravity balances the applied torque. The final state depends on the 
initial conditions. Our goal now is to understand how this bistability comes about.

269
8.5 HYSTERESIS IN THE DRIVEN PENDULUM AND JOSEPHSON JUNCTION
We will phrase our discussion in terms of the Josephson junction, but will men-
tion the pendulum analog whenever it seems helpful.
Governing Equations
As explained in Section 4.6, the governing equation for the Josephson junction 
is
ℏ

ℏ

C
e
eR
I
I
c
B
2
2
G
G
G
+
+
=
sin
 
(1)
where =  is Planck’s constant divided by 2Q, e is the charge on the electron, IB is the 
constant bias current, C, R, and Ic are the junction’s capacitance, resistance, and 
critical current, and G ( t ) is the phase difference across the junction.
To highlight the role of damping, we nondimensionalize (1) differently from in 
Section 4.6. Let

ℏ
ℏ
t
eI
C
t
I
I
I
eI R C
c
B
c
c
=⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
=
=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
2
2
1 2
2
1 2
,
,
.
B
 
(2)
Then (1) becomes
′′
′ +
=
φ
αφ
φ
+
sin
I  
(3)
where B and I are the dimensionless damping and applied current, and the prime 
denotes differentiation with respect to t . Here B  0 on physical grounds, and we 
may choose I p 0 without loss of generality (otherwise, redefine G l −G ). 
Let y  Ga. Then the system becomes
′ =
′ =
−
−
φ
φ
α
y
y
I
y
sin
.
 
(4)
As in Section 6.7 the phase space is a cylinder, since G is an angular variable and y 
is a real number (best thought of as an angular velocity).
Fixed Points
The fixed points of (4) satisfy y*  0 and sin G*   I. Hence there are two fixed 
points on the cylinder if I  1, and none if I  1. When the fixed points exist, one is 
a saddle and other is a sink, since the Jacobian
A = −
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
0
1
cos
*
φ
α

270 
BIFURCATIONS REVISITED
has U  −B  0 and Δ =
= ±
−
cos *
.
G
1
2
I
When %  0, we have a stable node if 
τ
α
2
2
2
4
4 1
0
−
=
−
−
>
Δ
I
, i.e., if the damping is strong enough or if I is close to 
1; otherwise the sink is a stable spiral. At I  1 the stable node and the saddle 
coalesce in a saddle-node bifurcation of fixed points.
Existence of a Closed Orbit
What happens when I  1 ? There are no more fixed points available; something 
new has to happen. We claim that all trajectories are attracted to a unique, stable 
limit cycle.
The first step is to show that a periodic solution exists. The argument uses a 
clever idea introduced by Poincaré long ago. Watch carefully—this idea will come 
up frequently in our later work.
Consider the nullcline y  B–1 ( I − sinG ) where ya  0. The flow is downward 
above the nullcline and upward below it (Figure 8.5.1).
y
y
y
(I−sin   )
α
φ
φ
–1
=
=
y2
y =y1
Figure 8.5.1
In particular, all trajectories eventually enter the strip y1 by b y2 (Figure 8.5.1), 
and stay in there forever. (Here y1 and y2 are any fixed numbers such that 
0  y1  ( I  1) / B and y2  ( I  1) / B.) Inside the strip, the flow is always to the 
right, because y  0 implies G a  0.
Also, since G  0 and G  2Q are equivalent on the cylinder, we may as well con-
fine our attention to the rectangular box 0 b G b 2Q , y1 by by2. This box contains 
all the information about the long-term behavior 
of the flow (Figure 8.5.2).
Now consider a trajectory that starts at a 
height y on the left side of the box, and follow it 
until it intersects the right side of the box at some 
new height P ( y ), as shown in Figure 8.5.2. The 
mapping from y to P ( y ) is called the Poincaré 
map. It tells us how the height of a trajectory 
changes after one lap around the cylinder 
(Figure 8.5.3).
y
(y)
2π
φ
P
=y2
y= y1
0
Figure 8.5.2

271
8.5 HYSTERESIS IN THE DRIVEN PENDULUM AND JOSEPHSON JUNCTION
The Poincaré map is also called the first-return map, because 
if a trajectory starts at a height y on the line G  0 (mod 2Q ), then 
P ( y ) is its height when it returns to that line for the first time.
Now comes the key point: we can’t compute P ( y ) explicitly, 
but if we can show that there’s a point y* such that P ( y* )  y *, 
then the corresponding trajectory will be a closed orbit (because it 
returns to the same location on the cylinder after one lap).
To show that such a y* must exist, we need to know what the 
graph of P ( y ) looks like, at least roughly. Consider a trajectory 
that starts at y  y1, G  0. We claim that
P ( y1 )  y1.
This follows because the flow is strictly upward at first, and the trajectory can 
never return to the line y  y1, since the flow is everywhere upward on that line 
(recall Figures 8.5.1 and 8.5.2). By the same kind of argument,
P ( y2 )  y2 .
Furthermore, P ( y ) is a continuous function. This follows from the theorem that 
solutions of differential equations depend continuously on initial conditions, if the 
vector field is smooth enough.
And finally, P ( y ) is a monotonic function. (By drawing pictures, you can con-
vince yourself that if P ( y ) were not monotonic, two trajectories would cross—
and that’s forbidden.) Taken together, these results imply that P ( y ) has the shape 
shown in Figure 8.5.4.
y
P(y)
y(0)
y2
y1
y*
(2π)
Figure 8.5.4
By the intermediate value theorem (or common sense), the graph of P ( y ) must 
cross the 45° diagonal somewhere; that intersection is our desired y*.
y
(mod 2π)
P(y)
= 0
φ
Figure 8.5.3

272 
BIFURCATIONS REVISITED
Uniqueness of the Limit Cycle
The argument above proves the existence of a closed orbit, and almost proves its 
uniqueness. But we haven’t excluded the possibility that P ( y ) w y on some inter-
val, in which case there would be a band of infinitely many closed orbits.
To nail down the uniqueness part of our claim, we recall from Section 6.7 that 
there are two topologically different kinds of periodic orbits on a cylinder: libra-
tions and rotations (Figure 8.5.5).
y
y
libration
rotation
φ
φ
Figure 8.5.5
For I  1, librations are impossible because any libration must encircle a fixed 
point, by index theory—but there are no fixed points when I  1. Hence we only 
need to consider rotations.
Suppose there were two different rotations. The phase portrait on the cylinder 
would have to look like Figure 8.5.6.
y
y (   )
(   )
y
U
L
φ
φ
φ
Figure 8.5.6
One of the rotations would have to lie strictly above the other because trajectories 
can’t cross. Let yU ( G ) and yL ( G ) denote the “upper” and “lower” rotations, where 
yU  ( G ) yL ( G ) for all G.
The existence of two such rotations leads to a contradiction, as shown by the 
following energy argument. Let
E
y
=
−
1
2
2
cos .
G  
(5)

273
8.5 HYSTERESIS IN THE DRIVEN PENDULUM AND JOSEPHSON JUNCTION
After one circuit around any rotation y ( G ), the change in energy %E must vanish. 
Hence
0
0
2
=
= ∫
ΔE
dE
d
d
φ
φ
π
. 
(6)
But (5) implies
dE
d
y dy
d
G
G
G
=
+sin
 
(7)
and
dy
d
y
I
y
y
φ
φ
φ
α
=
′
′ =
−
−
sin
, 
(8)
from (4). Substituting (8) into (7) gives dE / dG   I − By. Thus (6) implies
0
0
2
=
−
∫
(
)
I
y d
α
φ
π
on any rotation y ( G ). Equivalently, any rotation must satisfy
y
d
I
( )
.
φ
φ
π
α
π
=
∫
2
0
2
 
(9)
But since yU ( G ) yL ( G ),
y
d
y
d
U
L
( )
( )
,
φ
φ
φ
φ
π
π
> ∫
∫
0
2
0
2
and so (9) can’t hold for both rotations.
This contradiction proves that the rotation for I  1 is unique, as claimed.
Homoclinic Bifurcation
Suppose we slowly decrease I, starting from some value I  1. What happens to 
the rotating solution? Think about the pendulum: as the driving torque is reduced, 
the pendulum struggles more and more to make it over the top. At some criti-
cal value Ic  1, the torque is insufficient to overcome gravity and damping, and 
the pendulum can no longer whirl. Then the rotation disappears and all solutions 
damp out to the rest state.
Our goal now is to visualize the corresponding bifurcation in phase space. In 
Exercise 8.5.2, you’re asked to show (by numerical computation of the phase por-
trait) that if B is sufficiently small, the stable limit cycle is destroyed in a homoclinic 

274 
BIFURCATIONS REVISITED
bifurcation (Section 8.4). The following schematic drawings summarize the results 
you should get.
First suppose Ic  I  1. The system is bistable: a sink coexists with a stable limit 
cycle (Figure 8.5.7).
y
stable limit cycle
stable 
manifold
of saddle
U
Figure 8.5.7
Keep your eye on the trajectory labeled U in Figure 8.5.7. It is a branch of the 
unstable manifold of the saddle. As t l d, U asymptotically approaches the sta-
ble limit cycle.
As I decreases, the stable limit cycle moves down and squeezes U closer to 
the stable manifold of the saddle. When I  Ic , the limit cycle merges with U in a 
homoclinic bifurcation. Now U is a homoclinic orbit—it joins the saddle to itself 
(Figure 8.5.8).
y
U =homoclinic orbit
Figure 8.5.8
Finally, when I  Ic the saddle connection breaks and U spirals into the sink 
(Figure 8.5.9).





275
8.5 HYSTERESIS IN THE DRIVEN PENDULUM AND JOSEPHSON JUNCTION
The scenario described here is valid only if the 
dimensionless damping B is sufficiently small. 
We know that something different has to happen 
for large B. After all, when B is infinite we are in 
the overdamped limit studied in Section 4.6. Our 
analysis there showed that the periodic solution 
is destroyed by an infinite-period bifurcation (a 
saddle and a node are born on the former limit 
cycle). So it’s plausible that an infinite-period 
bifurcation should also occur if B is large but 
finite. These intuitive ideas are confirmed by 
numerical integration (Exercise 8.5.2). 
Putting it all together, we arrive at the stability diagram shown in Figure 8.5.10. 
Three types of bifurcations occur: homoclinic and infinite-period bifurcations of 
periodic orbits, and a saddle-node bifurcation of fixed points.
I
α
1.5
2.0
1.0
0.5
0.0
0.0
0.5
stable limit cycle
stable fixed point
bistable
homoclinic
infinite-period
saddle-node
1.0
1.5
2.0
Figure 8.5.10
Our argument leading to Figure 8.5.10 has been heuristic. For rigorous proofs, 
see Levi et al. (1978). Also, Guckenheimer and Holmes (1983, p. 202) derive an 
analytical approximation for the homoclinic bifurcation curve for B  1, using 
an advanced technique known as Melnikov’s method. They show that the bifur-
cation curve is tangent to the line I  4B / Q as B l 0. Even if B is not so small, this 
approximation works nicely, thanks to the straightness of the homoclinic bifurca-
tion curve in Figure 8.5.10.
Hysteretic Current-Voltage Curve
Figure 8.5.10 explains why lightly damped Josephson junctions have hysteretic 
I  V curves. Suppose B is small and I is initially below the homoclinic bifurcation 
(thick line in Figure 8.5.10). Then the junction will be operating at the stable fixed 
y
U
Figure 8.5.9

276 
BIFURCATIONS REVISITED
point, corresponding to the zero-voltage state. As I is increased, nothing changes 
until I exceeds 1. Then the stable fixed point disappears in a saddle-node bifurca-
tion, and the junction jumps into a nonzero voltage state (the limit cycle).
If I is brought back down, the limit cycle persists below I  1 but its frequency 
tends to zero continuously as Ic is approached. Specifically, the frequency tends to 
zero like [ln( I  Ic )]–1, just as expected from the scaling law discussed in Section 
8.4. Now recall from Section 4.6 that the junction’s dc-voltage is proportional to 
its oscillation frequency. Hence, the voltage also returns to zero continuously as 
I l Ic
+ (Figure 8.5.11).
‹ ›
V
3
3
2
2
1
0
0
I
I
1
c
Figure 8.5.11
In practice, the voltage appears to jump discontinuously back to zero, but that 
is to be expected because [ln( I  Ic )]–1 has infinite derivatives of all orders at Ic ! 
(See Exercise 8.5.1.) The steepness of the curve makes it impossible to resolve the 
continuous return to zero. For instance, in experiments on pendula, Sullivan and 
Zimmerman (1971) measured the mechanical analog of the I – V curve—namely, 
the curve relating the rotation rate to the applied torque. Their data show a jump 
back to zero rotation rate at the bifurcation.
8.6 Coupled Oscillators and Quasiperiodicity
Besides the plane and the cylinder, another important two-dimensional phase 
space is the torus. It is the natural phase space for systems of the form


R
R R
R
R R
1
1
1
2
2
2
1
2


f
f
( ,
)
( ,
)
where f1 and f2 are periodic in both arguments.
For instance, a simple model of coupled oscillators is given by

277
8.6 COUPLED OSCILLATORS AND QUASIPERIODICITY


θ
ω
θ
θ
θ
ω
θ
θ
1
1
1
2
1
2
2
2
1
2
=
+
−
=
+
−
K
K
sin(
)
sin(
),
 
(1)
where R1 , R2 are the phases of the oscillators, X1, X2  0 are their natural frequencies, 
and K1, K2 p0 are coupling constants. Equation (1) has been used to model the 
interaction between human circadian rhythms and the sleep-wake cycle (Strogatz 
1986, 1987).
An intuitive way to think about (1) is to imagine two friends jogging on a cir-
cular track. Here R1 ( t ), R2 ( t ) represent their positions on the track, and X1, X2 are 
proportional to their preferred running speeds. If they were uncoupled, then each 
would run at his or her preferred speed and the faster one would periodically over-
take the slower one (as in Example 4.2.1). But these are friends—they want to run 
around together! So they need to compromise, with each adjusting his or her speed 
as necessary. If their preferred speeds are too different, 
phase-locking will be impossible and they may want to 
find new running partners.
Here we consider (1) more abstractly, to illustrate 
some general features of flows on the torus and also to 
provide an example of a saddle-node bifurcation of 
cycles (Section 8.4). To visualize the flow, imagine two 
points running around a circle at instantaneous rates 


R R
1
2
,
 (Figure 8.6.1). Alternatively, we could imagine a 
single point tracing out a trajectory on a torus with coor-
dinates R1, R2 (Figure 8.6.2). The coordinates are analogous to latitude and 
longitude.
θ
θ
2
coordinate system
1
Figure 8.6.2
But since the curved surface of a torus makes it hard to draw phase portraits, we 
prefer to use an equivalent representation: a square with periodic boundary condi-
tions. Then if a trajectory runs off an edge, it magically reappears on the opposite 
edge, as in some video games (Figure 8.6.3).
θ1
2
θ
Figure 8.6.1

278 
BIFURCATIONS REVISITED
θ
π
π
θ
2
2
2
0
1
Figure 8.6.3
Uncoupled System
Even the seemingly trivial case of uncoupled oscillators ( K1, K2  0) holds some 
surprises. Then (1) reduces to 

θ
ω
θ
ω
1
1
2
2


,
.  The corresponding trajectories on 
the square are straight lines with constant slope dR2 / dR1  X2 / X1. There are two 
qualitatively different cases, depending on whether the slope is a rational or an 
irrational number.
If the slope is rational, then X1  / X2  p / q for some integers p, q with no common 
factors. In this case all trajectories are closed orbits on the torus, because R1 com-
pletes p revolutions in the same time that R2 completes q revolutions. For example, 
Figure 8.6.4 shows a trajectory on the square with p  3, q  2.
θ
θ
2
1
Figure 8.6.4
When plotted on the torus, the same trajectory gives . . . a trefoil knot !  Figure 8.6.5 
shows a trefoil, alongside a top view of a torus with a trefoil wound around it.

279
8.6 COUPLED OSCILLATORS AND QUASIPERIODICITY
trefoil knot
end here,
two-thirds of
a revolution around the torus
start here,
on outer equator
θ2
Figure 8.6.5
Do you see why this knot corresponds to p  3, q  2 ? Follow the knotted tra-
jectory in Figure 8.6.5, and count the number of revolutions made by R2 during the 
time that R1 makes one revolution, where R1 is latitude and R2 is longitude. Starting 
on the outer equator, the trajectory moves onto the top surface, dives into the hole, 
travels along the bottom surface, and then reappears on the outer equator, two-
thirds of the way around the torus. Thus R2 makes two-thirds of a revolution while 
R1 makes one revolution; hence p  3, q  2.
In fact the trajectories are always knotted if p, q p 2 have no common factors. 
The resulting curves are called p:q torus knots.
The second possibility is that the slope is irrational (Figure 8.6.6). Then the flow 
is said to be quasiperiodic. Every trajectory winds around endlessly on the torus, 
never intersecting itself and yet never quite closing.
How can we be sure the trajectories never close? 
Any closed trajectory necessarily makes an inte-
ger number of revolutions in both R1 and R2; hence 
the slope would have to be rational, contrary to 
assumption.
Furthermore, when the slope is irrational, each 
trajectory is dense on the torus: in other words, each 
trajectory comes arbitrarily close to any given point 
on the torus. This is not to say that the trajectory 
passes through each point; it just comes arbitrarily 
close (Exercise 8.6.3).
Quasiperiodicity is significant because it is a new type of long-term behavior. 
Unlike the earlier entries (fixed point, closed orbit, homoclinic and heteroclinic 
orbits and cycles), quasiperiodicity occurs only on the torus.
Coupled System
Now consider (1) in the coupled case where K1, K2  0. The dynamics can be 
deciphered by looking at the phase difference G  R1  R2. Then (1) yields
θ
π
π
θ
2
2
2
0
1
Figure 8.6.6

280 
BIFURCATIONS REVISITED



φ
θ
θ
ω
ω
φ
=
−
=
−
−
+
1
2
1
2
1
2
(
)sin
,
K
K
 
(2)
which is just the nonuniform oscillator studied in Section 4.3. By drawing the stan-
dard picture (Figure 8.6.7), we see that there are two fixed points for (2) if | X1 X2 | 
 K1  K2 and none if | 
 X1   X2 |  Kl  K2. A saddle-node bifurcation occurs when 
| X1   X2 |  Kl  K2.
φ
φ
.
Figure 8.6.7
Suppose for now that there are two fixed points, defined implicitly by 
sin *
.
φ
ω
ω
=
−
+
1
2
1
2
K
K
As Figure 8.6.7 shows, all trajectories of (2) asymptotically approach the stable 
fixed point. Therefore, back on the torus, the trajectories of (1) approach a stable 
phase-locked solution in which the oscillators are separated by a constant phase 
difference  G *. The phase-locked solution is periodic; in fact, both oscillators run at 
a constant frequency given by ω
θ
θ
ω
φ
*
sin
*
=
=
=
+


1
2
2
2
K
. Substituting for 
sinG * yields
X
X
X
*
.
=
+
+
K
K
K
K
1
2
2
1
1
2
This is called the compromise frequency because it lies between the natural fre-
quencies of the two oscillators (Figure 8.6.8).
ω
ω
ω
ω
ω
Δ
Δ
2
2
*
1
1
Figure 8.6.8

281
8.7 POINCARÉ MAPS
The compromise is not generally halfway; instead the frequencies are shifted by an 
amount proportional to the coupling strengths, as shown by the identity
Δ
Δ
X
X
X
X
X
X
1
2
1
2
1
2
≡
−
−
=
*
*
.
K
K
Now we’re ready to plot the phase portrait on the torus (Figure 8.6.9). The sta-
ble and unstable locked solutions appear as diagonal lines of slope 1, since 


θ
θ
ω
1
2


*.
θ
π
π
θ
2
2
2
0
1
Figure 8.6.9
If we pull the natural frequencies apart, say by detuning one of the oscillators, then 
the locked solutions approach each other and coalesce when | X1  X2 |  K1  K2. 
Thus the locked solution is destroyed in a saddle-node bifurcation of cycles 
(Section 8.4). After the bifurcation, the flow is like that in the uncoupled case studied 
earlier: we have either quasiperiodic or rational flow, depending on the parameters. 
The only difference is that now the trajectories on the square are curvy, not straight.
8.7 Poincaré Maps
In Section 8.5 we used a Poincaré map to prove the existence of a periodic orbit 
for the driven pendulum and Josephson junction. Now we discuss Poincaré maps 
more generally.
Poincaré maps are useful for studying 
swirling flows, such as the flow near a peri-
odic orbit (or as we’ll see later, the flow in 
some 
chaotic 
systems). 
Consider 
an 
n-dimensional system x
f x
 ( ) . Let S be an 
n  1 
dimensional 
surface 
of 
section 
(Figure 8.7.1). S is required to be transverse 
to the flow, i.e., all trajectories starting on S 
flow through it, not parallel to it.
s
x
x
x
k+1
k
*
Figure 8.7.1

282 
BIFURCATIONS REVISITED
The Poincaré map P is a mapping from S to itself, obtained by following trajec-
tories from one intersection with S to the next. If xk  S denotes the kth intersec-
tion, then the Poincaré map is defined by
xk+1 P ( xk ).
Suppose that x* is a fixed point of P, i.e., P (x* )  x*. Then a trajectory starting at 
x* returns to x* after some time T, and is therefore a closed orbit for the original 
system x
f x
 ( ). Moreover, by looking at the behavior of P near this fixed point, 
we can determine the stability of the closed orbit. Thus the Poincaré map converts 
problems about closed orbits (which are difficult) into problems about fixed points 
of a mapping (which are easier in principle, though not always in practice). The 
snag is that it’s typically impossible to find a formula for P. For the sake of illustra-
tion, we begin with two examples for which P can be computed explicitly.
EXAMPLE 8.7.1:
Consider the vector field given in polar coordinates by 

r
r
r
=
−
=
(
),
1
1
2
R
. Let 
S be the positive x-axis, and compute the Poincaré map. Show that the system has 
a unique periodic orbit and classify its stability.
Solution: Let r0 be an initial condition on S. Since R 1, the first return to S 
occurs after a time of flight  t  2Q. Then r1  P ( r0 ), where r1 satisfies
dr
r
r
dt
r
r
(
)
.
1
2
2
0
2
0
1
−
=
=
∫
∫
Q
Q
Evaluation of the integral (Exercise 8.7.1) yields r
e
r
1
4
0
2
1 2
1
1
=
+
−
⎡⎣⎢
⎤⎦⎥
−
−
−
Q(
)
.  Hence 
P r
e
r
( )
(
)
=
+
−
⎡⎣⎢
⎤⎦⎥
−
−
−
1
1
4
2
1 2
Q
. The graph of P is plotted in Figure 8.7.2.
r2
1
P
P
=
(r )
(r)
r1
0
0
1
2
=1
*
r
r
r
r
r
P
= (r )
Figure 8.7.2
A fixed point occurs at r*  1 where the graph intersects the 45° line. The cobweb 
construction in Figure 8.7.2 enables us to iterate the map graphically. Given an 

283
8.7 POINCARÉ MAPS
input rk, draw a vertical line until it intersects the graph of P; that height is the 
output rk1. To iterate, we make rk1 the new input by drawing a horizontal line until 
it intersects the 45° diagonal line. Then repeat the process. Convince yourself that 
this construction works; we’ll be using it often.
The cobweb shows that the fixed point r*  1 is stable and unique. No surprise, 
since we knew from Example 7.1.1 that this system has a stable limit cycle at r  1. ■
EXAMPLE 8.7.2:
A sinusoidally forced RC-circuit can be written in dimensionless form as 
x
x
A
t
+
=
sin
,
X  where X  0. Using a Poincaré map, show that this system has a 
unique, globally stable limit cycle.
Solution: This is one of the few time-dependent systems we’ve discussed in this 
book. Such systems can always be made time-independent by adding a new vari-
able. Here we introduce R  Xt and regard the system as a vector field on a cylinder: 


θ
ω
θ
=
+
=
,
sin
x
x
A
. Any vertical line on the cylinder is an appropriate section 
S; we choose S  {( R, x ): R  0 mod 2Q}. Consider an initial condition on S given 
by R (0)  0, x (0)  x0. Then the time of flight between successive intersections is 
t  2Q / X . In physical terms, we strobe the system once per drive cycle and look at 
the consecutive values of x.
To compute P, we need to solve the differential equation. Its general solution is 
a sum of homogeneous and particular solutions: x t
c e
c
t
c
t
t
( )
sin
cos
.
=
+
+
−
1
2
3
X
X  
The constants c2 and c3 can be found explicitly, but the important point is that they 
depend on A and X but not on the initial condition x0; only c1, depends on x0 . To 
make the dependence on x0 explicit, observe that at t  0 , x  x0  c1  c3. Thus
x t
x
c e
c
t
c
t
t
( )
(
)
sin
cos
.
=
−
+
+
−
0
3
2
3
X
X
Then P is defined by x1  P ( x0 )  x (2Q  / X ). Substitution yields
P x
x
x
c e
c
x e
c
(
)
(
)
(
)
0
0
3
2
3
0
2
4
2
=
=
−
+
=
+
−
−
π ω
π ω
π ω
where c4  c3 (1  e2Q / X ).
The graph of P is a straight line with a slope e2Q / X  1 as shown in Figure 8.7.3.

284 
BIFURCATIONS REVISITED
P x
x
x
*
( )
Figure 8.7.3
Since P has slope less than 1, it intersects the diagonal at a unique point. 
Furthermore, the cobweb shows that the deviation of xk from the fixed point is 
reduced by a constant factor with each iteration. Hence the fixed point is unique 
and globally stable.
In physical terms, the circuit always settles into the same forced oscillation, 
regardless of the initial conditions. This is a familiar result from elementary phys-
ics, looked at in a new way. ■
Linear Stability of Periodic Orbits
Now consider the general case: Given a system x
f x
 ( ) with a closed orbit, 
how can we tell whether the orbit is stable is not? Equivalently, we ask whether the 
corresponding fixed point x* of the Poincaré map is stable. Let v0 be an infinitesi-
mal perturbation such that x* v0 is in S. Then after the first return to S,
x
v
x
v
x
x
v
v
*
( *
)
( *)
( *)
+
=
+
=
+[
]
+ (
)
1
0
0
0
2
P
P
DP
O
where DP (x* ) is an ( n  1) q ( n  1) matrix called the linearized Poincaré map at 
x*. Since x*  P (x* ), we get
v1  [DP (x* )]v0
assuming that we can neglect the small O
v0
2
(
)  terms.
The desired stability criterion is expressed in terms of the eigenvalues Mj of 
DP (x* ) : The closed orbit is linearly stable if and only if  | Mj |  1 for all j  1, . . . , n−1.

285
8.7 POINCARÉ MAPS
To understand this criterion, consider the generic case where there are no 
repeated eigenvalues. Then there is a basis of eigenvectors e j
{ } and so we can 
write v
e
0
1
1
=
=
−
∑vj
j
j
n
 for some scalars vj. Hence
v
x
e
e
1
1
1
1
1
=(
)
=
=
−
=
−
∑
∑
DP
v
v
j
j
j
j
j
j
n
j
n
( *)
.
M
Iterating the linearized map k times gives
v
e
k
j
j
k
j
j
n
v
=
=
−
∑
(
)
.
M
1
1
Hence, if all | Mj |  1, then || vk || l 0 geometrically fast. This proves that x* is lin-
early stable. Conversely, if | Mj |  1 for some j, then perturbations along ej grow, so 
x* is unstable. A borderline case occurs when the largest eigenvalue has magnitude 
| Mm |  1; this occurs at bifurcations of periodic orbits, and then a nonlinear stabil-
ity analysis is required.
The Mj are called the characteristic or Floquet multipliers of the periodic orbit. 
(Strictly speaking, these are the nontrivial multipliers; there is always an additional 
trivial multiplier M w 1 corresponding to perturbations along the periodic orbit. 
We have ignored such perturbations since they just amount to time-translation.)
In general, the characteristic multipliers can only be found by numerical inte-
gration (see Exercise 8.7.10). The following examples are two of the rare exceptions.
EXAMPLE 8.7.3:
Find the characteristic multiplier for the limit cycle of Example 8.7.1.
Solution: We linearize about the fixed point r*  1 of the Poincaré map. Let 
r  l  I , where I is infinitesimal. Then 

r =
=
+
−
+
I
I
I
(
)(
(
) )
1
1
1
2 . After neglect-
ing O ( I2 ) terms, we get I
I
= −2 . Thus I
I
( )
.
t
e
t
=
−
0
2  After a time of flight t  2Q, 
the new perturbation is η
η
π
1
4
0
=
−
e
. Hence e–4Q is the characteristic multiplier. 
Since | e–4Q |  1, the limit cycle is linearly stable. ■
For this simple two-dimensional system, the linearized Poincaré map degener-
ates to a 1 q 1 matrix, i.e., a number. Exercise 8.7.1 asks you to show explicitly that 
P r
e
′( *)
,
=
−4Q  as expected from the general theory above.
Our final example comes from an analysis of coupled Josephson junctions.

286 
BIFURCATIONS REVISITED
EXAMPLE 8.7.4:
The N-dimensional system
G
G
G
i
i
N
j
j
N
a
=
+
+
=∑
Ω
sin
sin
,
1
1
 
(1)
for i 1, . . . , N, describes the dynamics of a series array of overdamped Josephson 
junctions in parallel with a resistive load (Tsang et al. 1991). For technological rea-
sons, there is great interest in the solution where all the junctions oscillate in phase. 
This in-phase solution is given by G
G
G
G
1
2
( )
( )
( )
*( ),
t
t
t
t
N




. . .
where G*( t ) 
denotes the common waveform. Find conditions under which the in-phase solu-
tion is periodic, and calculate the characteristic multipliers of this solution. 
Solution: For the in-phase solution, all N equations reduce to
d
dt
a
G
G
*
(
)sin
*.
=
+
+
Ω
1
 
(2)
This has a periodic solution (on the circle) if and only if | 8|  | a 1 |. To determine 
the stability of the in-phase solution, let φ
φ
η
i
i
t
t
t
( )
*( )
( ),
=
+
 where the Ii ( t ) are 
infinitesimal perturbations. Then substituting Gi into (1) and dropping quadratic 
terms in I yields
η
φ
η
φ
η
i
i
N
j
j
N
a
t
t
=[
]
+[
]
=∑
cos
*( )
cos
*( )
.
1
1
 
(3)
We don’t have G* ( t ) explicitly, but that doesn’t matter, thanks to two tricks. First, 
the linear system decouples if we change variables to
1
1
1
,
,
1...,
1.
N
j
N
j
i
i
i
i
N
N
I
Y
I
I








Then ξ
φ
ξ
i
i
a
t
=[
]
cos
*( )
.  Separation of variables yields
d
a
t dt
a
d
a
i
i
ξ
ξ
φ
φ
φ
φ
=[
]
= [
]
+
+
cos
*( )
cos
*
*
(
)sin
*,
Ω
1
where we’ve used (2) to eliminate dt. (That was the second trick.)
Now we compute the change in the perturbations after one circuit around the 
closed orbit G*:

287
EXERCISES
d
a
d
a
T
a
a
i
i
i
i
ξ
ξ
φ
φ
φ
ξ
ξ
π
v∫
∫
=
[
]
+
+
⇒
=
+
cos
*
*
(
)sin
*
(
)
( )
Ω
1
0
1
0
2
 ln
 ln Ω+
+
[
]
=
(
)sin
*
.
a
1
0
0
2
φ
π
Hence Yi  ( T )  Yi (0). Similarly, we can show that N ( T )  N (0). Thus Ii  ( T )  Ii  (0) 
for all i; all perturbations are unchanged after one cycle! Therefore all the charac-
teristic multipliers Mj  1. ■
This calculation shows that the in-phase state is (linearly) neutrally stable. 
That’s discouraging technologically—one would like the array to lock into coher-
ent oscillation, thereby greatly increasing the output power over that available 
from a single junction.
Since the calculation above is based on linearization, you might wonder whether 
the neglected nonlinear terms could stabilize the in-phase state. In fact they don’t: 
a reversibility argument shows that the in-phase state is not attracting, even if the 
nonlinear terms are kept (Exercise 8.7.11).
EXERCISES FOR CHAPTER 8
8.1 Saddle-Node, Transcritical, and Pitchfork Bifurcations
8.1.1 
For the following prototypical examples, plot the phase portraits as N 
varies:
a) 
2,
x
x
x
y
y
N


 


 (transcritical bifurcation)
b) 
3,
x
x
x
y
y
N


 


 (subcritical pitchfork bifurcation)
For each of the following systems, find the eigenvalues at the stable fixed point as a 
function of N, and show that one of the eigenvalues tends to zero as N l 0 .
8.1.2 
2,
x
x
y
y
N


 


8.1.3 
2,
x
x
x
y
y
N


 


8.1.4 
3,
x
x
x
y
y
N


 


8.1.5 
True or false: at any zero-eigenvalue bifurcation in two dimensions, the 
nullclines always intersect tangentially. (Hint: Consider the geometrical meaning 
of the rows in the Jacobian matrix.)
8.1.6 
Consider the system 
2
2 ,
.
x
y
x
y
x
y
N







a) Sketch the nullclines.
b) Find and classify the bifurcations that occur as N varies.
c) Sketch the phase portrait as a function of N.

288 
BIFURCATIONS REVISITED
8.1.7 
Find and classify all bifurcations for the system 
x
y
ax
=
−
,
y
by
x
x
= −
+
+
(
).
1
8.1.8 
(Bead on rotating hoop, revisited) In Section 3.5, we derived the following 
dimensionless equation for the motion of a bead on a rotating hoop:
ε
φ
τ
φ
τ
φ
γ
φ
φ
d
d
d
d
2
2 = −
−
+
sin
sin
cos .
Here F  0 is proportional to the mass of the bead, and H  0 is related to the spin 
rate of the hoop. Previously we restricted our attention to the overdamped limit 
F l 0.
a) Now allow any F  0. Find and classify all bifurcations that occur as F and H 
vary.
b) Plot the stability diagram in the positive quadrant of the F,H plane.
8.1.9 
Plot the stability diagram for the system 

x
bx
kx
x
+
−
+
=
3
0, where b 
and k can be positive, negative, or zero. Label the bifurcation curves in the ( b, k ) 
plane.
8.1.10 
(Budworms vs. the forest) Ludwig et al. (1978) proposed a model for the 
effects of spruce budworm on the balsam fir forest. In Section 3.7, we considered 
the dynamics of the budworm population; now we turn to the dynamics of the 
forest. The condition of the forest is assumed to be characterized by S ( t ), the aver-
age size of the trees, and E ( t ), the “energy reserve” (a generalized measure of the 
forest’s health). In the presence of a constant budworm population B, the forest 
dynamics are given by


S
r S
S
K
K
E
E
r E
E
K
P B
S
S
S
E
E
E
=
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
=
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟−
1
1
,
,
where rS, rE, KS, KE, P 0 are parameters.
a) Interpret the terms in the model biologically.
b) Nondimensionalize the system.
c) Sketch the nullclines. Show that there are two fixed points if B is small, and 
none if B is large. What type of bifurcation occurs at the critical value of B?
d) Sketch the phase portrait for both large and small values of B.
8.1.11 
In a study of isothermal autocatalytic reactions, Gray and Scott (1985) 
considered a hypothetical reaction whose kinetics are given in dimensionless form 
by


u
a
u
uv
v
uv
a
k v
=
−
−
=
−
+
(
)
,
(
) ,
1
2
2

289
EXERCISES
where a, k  0 are parameters. Show that saddle-node bifurcations occur at 
k
a
a
= −± 1
2
.
8.1.12 
(Interacting bar magnets) Consider the system


R
R
R
R
R
R
R
R
1
1
2
1
2
2
1
2
=
−
−
=
−
−
K
K
sin(
)
sin
sin(
)
sin
 
where K p 0. For a rough physical interpretation, suppose that two bar magnets 
are confined to a plane, but are free to rotate about a common pin joint, as shown 
in Figure 1. Let R1, R2 denote the angular orientations of the north poles of the mag-
nets. Then the term K sin( R2  R1 ) represents a repulsive force that tries to keep 
the two north poles 180° apart. This repulsion is opposed by the sinR terms, which 
model external magnets that pull the north poles of both bar magnets to the east. 
If the inertia of the magnets is negligible compared to viscous damping, then the 
equations above are a decent approximation to the true dynamics.
S
S
N
N
N
S
θ
θ
1
2
Figure 1
a) Find and classify all the fixed points of the system.
b) Show that a bifurcation occurs at K  1
2 .  What type of bifurcation is it? (Hint: 
Recall that sin( a  b )  cos b sin a − sin b cos a.)
c) Show that the system is a “gradient” system, in the sense that R
R
i
i
V
= −∂
∂
 
for some potential function V ( R1,R2 ), to be determined.
d) Use part (c) to prove that the system has no periodic orbits.
e) Sketch the phase portrait for 0
1
2


K
, and then for K  1
2 .
8.1.13 
(Laser model) In Exercise 3.3.1 we introduced the laser model


n
GnN
kn
N
GnN
fN
p
=
−
= −
−
+
where N ( t ) is the number of excited atoms and n ( t ) is the number of photons in 
the laser field. The parameter G is the gain coefficient for stimulated emission, k is 
the decay rate due to loss of photons by mirror transmission, scattering, etc., f is 
the decay rate for spontaneous emission, and p is the pump strength. All param-
eters are positive, except p, which can have either sign. For more information, see 
Milonni and Eberly (1988).

290 
BIFURCATIONS REVISITED
a) Nondimensionalize the system.
b) Find and classify all the fixed points.
c) Sketch all the qualitatively different phase portraits that occur as the dimen-
sionless parameters are varied.
d) Plot the stability diagram for the system. What types of bifurcation occur?
8.1.14 
(Binocular rivalry)  Normally when you look at something, your left and 
right eyes see images that are very similar. (Try closing one eye, then the other; 
the resulting views look almost the same, except for the disparity caused by the 
spacing between your eyes.) But what would happen if two completely different 
images were shown to your left and right eyes simultaneously? What would you 
see? A combination of both images? Experiments like this have been performed for 
hundreds of years (Wade 1996), and the results are amazing: your brain typically 
perceives one image for a few seconds, then the other, then the first again, and so 
on. This switching phenomenon is known as binocular rivalry. 
Mathematical models of binocular rivalry often posit that there are two neu-
ral populations corresponding to the brain’s representations of the two competing 
images.  These populations battle with each other for dominance—each tends to 
suppress the other. The following exercise, kindly suggested by Bard Ermentrout, 
involves the analysis of a minimal model for such neuronal competition. 
Let x1 and x2  denote the averaged firing rates (essentially, the activity levels) of 
the two populations of neurons. Assume 
x
x
F I
bx
1
1
2
= −
+
−
(
) , 
x
x
F I
bx
2
2
1
= −
+
−
(
) ,
where the gain function is given by F x
e
x
( )
(
)
=
+
−
1 1
, I is the strength of the input 
stimulus (in this case, the stimuli are the images; note that each is assumed to be 
equally potent), and b is the strength of the mutual antagonism.
a)  Sketch the phase plane for various values of I and b (both positive). 
b)  Show that the symmetric fixed point, x
x
x
1
2
*
*
*


, is always a solution (in 
other words, it exists for all positive values of I and b), and show that it is unique. 
c)  Show that at a sufficiently large value of b, the symmetric solution loses stability 
at a pitchfork bifurcation. Which type of pitchfork bifurcation is it? 
For a refinement of this model that allows for rhythmic switching between the 
two perceived images, see Exercise 8.2.17. For more elaborate models and a com-
parative study of their bifurcation structure, see Shpiro et al. (2007).
8.1.15 
(The power of true believers)  Sometimes a small band of unwavering 
advocates can win an entire population over to their point of view, as in the case 
of the civil rights or women’s suffrage movements in the United States. Consider 
the following stylized model of such situations, which was studied by Marvel et al. 
(2012) and inspired by the earlier work of Xie et al. (2011). 
The population is divided into four non-overlapping groups. An initially small 
group of true believers holds opinion A (for example, that women deserve the right 

291
EXERCISES
to vote) and they are committed to this belief. Nothing that anyone says or does 
can change their minds. Another group of people currently agrees with them, but 
they are uncommitted to A. If someone argues for the opposing position, B, an 
uncommitted A-believer instantly becomes an AB, meaning someone who sees 
the merit in both positions. Likewise, B-believers instantly turn into members of 
the AB subpopulation when confronted with an argument for A. The people in 
the AB group, being fence-sitters, don’t try to persuade anyone of anything. And 
they can be pushed to either side with the slightest nudge; when confronted with 
an argument for A—or for B—they join that camp. At each time step, we select 
two people at random and have one of them act as an advocate and the other as a 
listener. Assuming the members of the four groups mix with each other at random, 
the governing equations for the dynamics are


n
p
n
n
n n
n
n n
p
n
n
A
A
AB
A
B
B
B
AB
A
AB
=
+
−
=
−
+
(
)
(
)
where n
p
n
n
AB
A
B
= −
+
−
1
(
)
. Here the parameter p denotes the unchanging frac-
tion of true believers in the population. The time-dependent variables nA , nB , and 
nAB  are the current fractions in the A, B, and AB subpopulations. 
a)  Interpret and justify the form of the various terms in the governing equations. 
b)  Assume that initially everyone believes in B, except for the true believers in A. 
Thus, n
p
B( )
0
1
= −
, and n
n
A
AB
( )
( )
0
0
0


. Numerically integrate the sys-
tem until it reaches equilibrium. Show that the final state changes discontinu-
ously as a function of p. Specifically, show there is a critical fraction of true 
believers (call it pc ) such that for p
pc

, most people still accept B, whereas for 
p
pc

, everyone comes around to A. 
c)  Show analytically that pc = −
≈
1
3 2
0 134
/
.
. Thus, in this model, only about 
13% of the population needs to be unwavering advocates to get everyone else to 
agree with them eventually.
d)  What type of bifurcation occurs at pc ?
8.2 Hopf Bifurcations
8.2.1 
Consider the biased van der Pol oscillator 
2
(
1)
.
x
x
x
x
a
N






 Find 
the curves in ( N, a ) space at which Hopf bifurcations occur.
The next three exercises deal with the system 
2,
x
y
x
xy
N
  


2.
y
x
y
x
N




8.2.2 
By calculating the linearization at the origin, show that the system 
2
2
,
x
y
x
xy
y
x
y
x
N
N
  






 has pure imaginary eigenvalues when N  0.

292 
BIFURCATIONS REVISITED
8.2.3 
(Computer work) By plotting phase portraits on the computer, show that 
the system 
2
2
,
x
y
x
xy
y
x
y
x
N
N
  






 undergoes a Hopf bifurcation at 
N  0. Is it subcritical, supercritical, or degenerate?
8.2.4 
(A heuristic analysis) The system 
2
2
,
x
y
x
xy
y
x
y
x
N
N
  






 
can be analyzed in a rough, intuitive way as follows.
a) Rewrite the system in polar coordinates.
b) Show that if r << 1, then R x1 and 
3
1
8
. . . ,
r
r
r
N
x



 where the terms omit-
ted are oscillatory and have essentially zero time-average around one cycle.
c) The formulas in part (b) suggest the presence of an unstable limit cycle of radius 
8
r
N
x

 for N  0. Confirm that prediction numerically. (Since we assumed 
that r  1, the prediction is expected to hold only if | N|  1.)
The reasoning above is shaky. See Drazin (1992, pp. 188-190) for a proper anal-
ysis via the Poincaré-Lindstedt method.
For each of the following systems, a Hopf bifurcation occurs at the origin when 
N  0. Using a computer, plot the phase portrait and determine whether the bifur-
cation is subcritical or supercritical.
8.2.5 
2
,
x
y
x
y
x
y
x y
N
N


  



8.2.6 
3
3
,
2
x
x
y
x
y
x
y
y
N
N



  



8.2.7 
2
2
,
2
x
x
y
x
y
x
y
x
N
N



  



8.2.8 
(Predator-prey model) Odell (1980) considered the system


x
x x
x
y
y
y x
a
=
−
−
[
]
=
−
(
)
,
(
),
1
where x p 0 is the dimensionless population of the prey, y p 0 is the dimensionless 
population of the predator, and a p 0 is a control parameter.
a) Sketch the nullclines in the first quadrant x, y p 0.
b) Show that the fixed points are (0, 0), (1, 0), and ( a, a a2 ), and classify them.
c) Sketch the phase portrait for a  1, and show that the predators go extinct.
d) Show that a Hopf bifurcation occurs at ac  1
2 . Is it subcritical or 
supercritical?
e) Estimate the frequency of limit cycle oscillations for a near the bifurcation.
f) Sketch all the topologically different phase portraits for 0  a  1.
The article by Odell (1980) is worth looking up. It is an outstanding pedagogical 
introduction to the Hopf bifurcation and phase plane analysis in general.
8.2.9 
Consider the predator-prey model


x
x b
x
y
x
y
y
x
x
ay
=
−−+
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
=
+
−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
1
1
,
,

293
EXERCISES
where x, y p 0 are the populations and a, b 0 are parameters.
a) Sketch the nullclines and discuss the bifurcations that occur as b varies.
b) Show that a positive fixed point x*  0, y*  0 exists for all a, b  0. (Don’t try 
to find the fixed point explicitly; use a graphical argument instead.)
c) Show that a Hopf bifurcation occurs at the positive fixed point if
a
a
b
b
b
c
=
=
−
+
4
2
2
2
(
)
(
)
and b  2. (Hint: A necessary condition for a Hopf bifurcation to occur is U  0, 
where U is the trace of the Jacobian matrix at the fixed point. Show that U  0 
if and only if 2x*  b − 2. Then use the fixed point conditions to express ac in 
terms of x*. Finally, substitute x*  ( b − 2) / 2 into the expression for ac and 
you’re done.)
d) Using a computer, check the validity of the expression in (c) and determine 
whether the bifurcation is subcritical or supercritical. Plot typical phase por-
traits above and below the Hopf bifurcation.
8.2.10 
(Bacterial respiration) Fairén and Velarde (1979) considered a model for 
respiration in a bacterial culture. The equations are


x
B
x
xy
qx
y
A
xy
qx
=
−−+
=
−+
1
1
2
2
,
where x and y are the levels of nutrient and oxygen, respectively, and A, B, q  0 
are parameters. Investigate the dynamics of this model. As a start, find all the 
fixed points and classify them. Then consider the nullclines and try to construct 
a trapping region. Can you find conditions on A, B, q under which the system has 
a stable limit cycle? Use numerical integration, the Poincaré-Bendixson theorem, 
results about Hopf bifurcations, or whatever else seems useful. (This question is 
deliberately open-ended and could serve as a class project; see how far you can go.)
8.2.11 
(Degenerate bifurcation, not Hopf) Consider the damped Duffing oscil-
lator 
3
0.
x
x
x
x
N






a) Show that the origin changes from a stable to an unstable spiral as N decreases 
though zero.
b) Plot the phase portraits for N  0, N  0, and N  0, and show that the bifurca-
tion at N  0 is a degenerate version of the Hopf bifurcation.
8.2.12 
(Analytical criterion to decide if a Hopf bifurcation is subcritical or 
supercritical) Any system at a Hopf bifurcation can be put into the following form 
by suitable changes of variables:


x
y
f x y
y
x
g x y
= −
+
=
+
X
X
( , ),
( , ),

294 
BIFURCATIONS REVISITED
where f and g contain only higher-order nonlinear terms that vanish at the ori-
gin. As shown by Guckenheimer and Holmes (1983, pp. 152-156), one can decide 
whether the bifurcation is subcritical or supercritical by calculating the sign of the 
following quantity:
16
1
a
f
f
g
g
f
f
f
g
g
g
f g
xxx
xyy
xxy
yyy
xy
xx
yy
xy
xx
yy
xx
xx
=
+
+
+
+
+
−
+
−
X
(
)
(
)
+
⎡⎣⎢
⎤⎦⎥
f g
yy
yy
where the subscripts denote partial derivatives evaluated at (0,0). The criterion is: 
If a  0, the bifurcation is supercritical; if a  0, the bifurcation is subcritical.
a) Calculate a for the system 

x
y
xy
y
x
x
= −+
=
−
2
2
,
.
b) Use part (a) to decide which type of Hopf bifurcation occurs for 
2
2
,
x
y
x
xy
y
x
y
x
N
N
  






 at N    0. (Compare the results of 
Exercises 8.2.2-8.2.4.)
(You might be wondering what a measures. Roughly speaking, a is the coeffi-
cient of the cubic term in the equation r
ar

3  governing the radial dynamics at 
the bifurcation. Here r is a slightly transformed version of the usual polar coordi-
nate. For details, see Guckenheimer and Holmes (1983) or Grimshaw (1990).)
For each of the following systems, a Hopf bifurcation occurs at the origin when 
N  0. Use the analytical criterion of Exercise 8.2.12 to decide if the bifurcation is 
sub- or supercritical. Confirm your conclusions on the computer.
8.2.13 
2
,
x
y
x
y
x
y
x y
N
N


  



8.2.14 
3
3
,
2
x
x
y
x
y
x
y
y
N
N



  



8.2.15 
2
2
,
2
x
x
y
x
y
x
y
x
N
N



  



8.2.16 
In Example 8.2.1, we argued that the system 
2,
x
x
y
xy
N




 
3
y
x
y
y
N




undergoes a subcritical Hopf bifurcation at N  0. Use the analyt-
ical criterion to confirm that the bifurcation is subcritical.
8.2.17 
(Binocular rivalry revisited) Exercise 8.1.14 introduced a minimal model 
of binocular rivalry, a remarkable visual phenomenon in which, when two differ-
ent images are presented to the left and right eyes, the brain perceives only one 
image at a time. First one image wins, then the other, then the first again, and so 
on, with the winning image alternating every few seconds. The model studied in 
Exercise 8.1.14 could account for the complete suppression of one image by the 
other, but not for the rhythmic alternation between them. Now we extend that 
model to allow for the observed oscillations. (Many thanks to Bard Ermentrout 
for creating and sharing this exercise and the earlier Exercise 8.1.14.)
Let x1 and x2  denote the activity levels of the two populations of neurons cod-
ing for the two images, as in Exercise 8.1.14, but now assume the neurons get tired 

295
EXERCISES
after winning a while, as adaptation builds up. The governing equations then 
become 




x
x
F I
bx
gy
y
y
x
T
x
x
F I
bx
gy
y
1
1
2
1
1
1
1
2
2
1
2
2
= −
+
−
−
= −
+
= −
+
−
−
=
(
)
(
) /
(
)
(
) /
−
+
y
x
T
2
2
where the y-variables represent adaptation building up on a time scale T and pro-
voking tiredness with strength g in their associated neuronal population. As in 
Exercise 8.1.14, the gain function is given by F x
e
x
( )
(
)
=
+
−
1 1
, I is the strength of 
the input stimuli (the images), and b is the strength of the mutual antagonism 
between the neuronal populations. This is now a four-dimensional system, but its 
key stability properties can be inferred from two-dimensional calculations as 
follows. 
a)  Show that x
y
x
y
u
1
1
2
2
*
*
*
*




 is a fixed point for all choices of parame-
ters and that u is uniquely defined. 
b)  Show that the stability matrix (the Jacobian) for the linearization about this 
fixed point has the form
−
−
−
−
−
−
−
−
⎛
⎝
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟⎟⎟⎟⎟
c
c
c
d
d
c
c
c
d
d
1
2
3
1
1
3
1
2
1
1
0
0
0
0
0
0
⎟⎟⎟⎟
 .
We can write this in block-matrix form as
 A
B
B
A
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
where A and B are 2
2
q  matrices. Show that the four eigenvalues of the 4
4
q
 
block matrix are given by the eigenvalues of A
B

 and A
B

.
c)  Show that the eigenvalues of A
B

 are all negative, by considering the trace 
and determinant of this matrix.
d) Show that depending on the sizes of g and T, the matrix A
B

 can have either 
a negative determinant (leading to a pitchfork bifurcation of u ) or a positive 
trace (resulting in a Hopf bifurcation). 
e)  Using a computer, show that the Hopf bifurcation can be supercritical; the 
resulting stable limit cycle mimics the oscillations we’re trying to explain. (Hint: 
When looking for trajectories that approach a stable limit cycle, be sure to use 
initial conditions that are different for populations 1 and 2. In other words, 
break the symmetry by starting with x
x
1
2
v
 and y
y
1
2
v
.)

296 
BIFURCATIONS REVISITED
8.3 Oscillating Chemical Reactions
8.3.1 
(Brusselator) The Brusselator is a simple model of a hypothetical chem-
ical oscillator, named after the home of the scientists who proposed it. (This is 
a common joke played by the chemical oscillator community; there is also the 
“Oregonator,” “Palo Altonator,” etc.) In dimensionless form, its kinetics are


x
b
x
ax y
y
bx
ax y
= −
+
+
=
−
1
1
2
2
(
)
where a, b 0 are parameters and x, y p 0 are dimensionless concentrations.
a) Find all the fixed points, and use the Jacobian to classify them.
b) Sketch the nullclines, and thereby construct a trapping region for the flow.
c) Show that a Hopf bifurcation occurs at some parameter value b  bc, where bc 
is to be determined.
d) Does the limit cycle exist for b bc or b bc ? Explain, using the Poincaré-
Bendixson theorem.
e) Find the approximate period of the limit cycle for b x bc.
8.3.2 
Schnackenberg (1979) considered the following hypothetical model of a 
chemical oscillator:
X
A
B
Y
X
Y
X
k
k
k
k
1
1
2
3
2
3
−
⎯
→
⎯
←
⎯
⎯
⎯→
⎯
+
⎯→
⎯
,
,
.
After using the Law of Mass Action and nondimensionalizing, Schnackenberg 
reduced the system to


x
a
x
x y
y
b
x y
=
−
+
=
−
2
2
where a, b  0 are parameters and x, y  0 are dimensionless concentrations.
a) Show that all trajectories eventually enter a certain trapping region, to be deter-
mined. Make the trapping region as small as possible. (Hint: Examine the ratio 
 
y x  for large x.)
b) Show that the system has a unique fixed point, and classify it.
c) Show that the system undergoes a Hopf bifurcation when b  a  ( a  b ) 3.
d) Is the Hopf bifurcation subcritical or supercritical? Use a computer to decide.
e) Plot the stability diagram in a, b space. (Hint: It is a bit confusing to plot the 
curve b  a  ( a  b ) 3, since this requires analyzing a cubic. As in Section 3.7, 
the parametric form of the bifurcation curve comes to the rescue. Show that the 
bifurcation curve can be expressed as
a
x
x
b
x
x
=
−
(
)
=
+
(
)
1
2
2
1
2
2
1
1
*
( *)
,
*
( *)

297
EXERCISES
where x*  0 is the x-coordinate of the fixed point. Then plot the bifurcation curve 
from these parametric equations. This trick is discussed in Murray (2002).)
8.3.3 
(Relaxation limit of a chemical oscillator) Analyze the model for the chlo-
rine dioxide−iodine−malonic acid oscillator, (8.3.4), (8.3.5), in the limit b  1. 
Sketch the limit cycle in the phase plane and estimate its period.
8.4 Global Bifurcations of Cycles
8.4.1 
Consider the system 
2
(1
),
sin
r
r
r
R
N
R






 for N slightly greater 
than 1. Let x  r cosR and y  r sinR. Sketch the waveforms of x ( t ) and y ( t ). (These 
are typical of what one might see experimentally for a system on the verge of an 
infinite-period bifurcation.)
8.4.2 
Discuss the bifurcations of the system 
(
sin ),
r
r
r
N



 R 1 as N varies.
8.4.3 
(Homoclinic bifurcation) Using numerical integration, find the value of N 
at which the system 
2
2
,
2
x
x
y
x
y
x
y
x
N
N



  



 undergoes a homoclinic 
bifurcation. Sketch the phase portrait just above and below the bifurcation.
8.4.4 
(Second-order phase-locked loop) Using a computer, explore the phase 
portrait of 
(1
cos )
sin
0
R
N
R R
R






 for N p 0. For some values of N, you should 
find that the system has a stable limit cycle. Classify the bifurcations that create 
and destroy the cycle as N increases from 0.
Exercises 8.4.5-8.4.11 deal with the forced Duffing oscillator in the limit where 
the forcing, detuning, damping, and nonlinearity are all weak:


x
x
bx
kx
ax
F
t
+
+
+
−
−
=
F(
cos )
,
3
0
where 0  F  1, b  0 is the nonlinearity, k  0 is the damping, a is the detuning, 
and F  0 is the forcing strength. This system is a small perturbation of a harmonic 
oscillator, and can therefore be handled with the methods of Section 7.6. We have 
postponed the problem until now because saddle-node bifurcations of cycles arise 
in its analysis.
8.4.5 
(Averaged equations) Show that the averaged equations (7.6.53) for the 
system are
r
kr
F
a
br
F
r
′
′
= −
+
= −
−
+
1
2
1
8
2
4
4
3
(
sin ),
(
cos ),
G
G
G
where x  r cos( t  G ), x
r
t
= −
+
sin(
),
G
 and prime denotes differentiation with 
respect to slow time T  F t, as usual. (If you skipped Section 7.6, accept these 
equations on faith.)
8.4.6 
(Correspondence between averaged and original systems) Show that fixed 
points for the averaged system correspond to phase-locked periodic solutions for 

298 
BIFURCATIONS REVISITED
the original forced oscillator. Show further that saddle-node bifurcations of fixed 
points for the averaged system correspond to saddle-node bifurcations of cycles 
for the oscillator.
8.4.7 
(No periodic solutions for averaged system) Regard ( r,G ) as polar coordi-
nates in the phase plane. Show that the averaged system has no closed orbits. (Hint: 
Use Dulac’s criterion with g ( r,G ) w 1. Let xa    ( ra, rGa ). Compute 
∇
′
′ +
′
∂
∂
∂
∂
.
(
)
(
)
x = 1
1
r
r
r
rr
r
G
G
 and show that it has one sign.)
8.4.8 
(No sources for averaged system) The result of the previous exercise shows 
that we only need to study the fixed points of the averaged system to determine 
its long-term behavior. Explain why the divergence calculation above also implies 
that the fixed points cannot be sources; only sinks and saddles are possible.
8.4.9 
(Resonance curves and cusp catastrophe) In this exercise you are asked 
to determine how the equilibrium amplitude of the driven oscillations depends on 
the other parameters.
a) Show that the fixed points satisfy r
k
br
a
F
2
2
3
4
2
2
2
+
−
⎡⎣⎢
⎤⎦⎥=
(
)
.
b) From now on, assume that k and F are fixed. Graph r vs. a for the linear oscil-
lator ( b  0). This is the familiar resonance curve.
c) Graph r vs. a for the nonlinear oscillator ( b v 0). Show that the curve is 
single-valued for small nonlinearity, say b  bc, but triple-valued for large 
nonlinearity ( b bc ), and find an explicit formula for bc. (Thus we obtain the 
intriguing conclusion that the driven oscillator can have three limit cycles for 
some values of a and b !)
d) Show that if r is plotted as a surface above the ( a, b ) plane, the result is a cusp 
catastrophe surface (recall Section 3.6).
8.4.10 
Now for the hard part: analyze the bifurcations of the averaged system.
a) Plot the nullclines r′ = 0 and Ga  0 in the phase plane, and study how their 
intersections change as the detuning a is increased from negative values to large 
positive values.
b) Assuming that b  bc , show that as a increases, the number of stable fixed points 
changes from one to two and then back to one again.
8.4.11 
(Numerical exploration) Fix the parameters k
b
F



1
2
4
3
,
,
.
a) Using numerical integration, plot the phase portrait for the averaged system 
with a increasing from negative to positive values.
b) Show that for a  2.8, there are two stable fixed points.
c) Go back to the original forced Duffing equation. Numerically integrate it and 
plot x ( t ) as a increases slowly from a  –1 to a  5, and then decreases slowly 
back to a  –1. You should see a dramatic hysteresis effect with the limit cycle 
oscillation suddenly jumping up in amplitude at one value of a, and then back 
down at another.

299
EXERCISES
8.4.12 
(Scaling near a homoclinic bifurcation) To find how the period of a closed 
orbit scales as a homoclinic bifurcation is approached, we estimate the time it 
takes for a trajectory to pass by a saddle point (this time is much longer than all 
others in the problem). Suppose the system is given locally by 

x
x
y
y
u
s
≈
≈−
M
M
,
. 
Let a trajectory pass through the point ( N, 1), where N  1 is the distance from 
the stable manifold. How long does it take until the trajectory has escaped from 
the saddle, say out to x ( t ) x 1? (See Gaspard (1990) for a detailed discussion.)
8.5 Hysteresis in the Driven Pendulum and Josephson Junction
8.5.1 
Show that [ln( I  Ic )]–1 has infinite derivatives of all orders at Ic. (Hint: 
Consider f  ( I )  (ln I ) –1 and try to derive a formula for f   ( n1) ( I ) in terms of f   ( n ) ( I ), 
where f   ( n ) ( I ) denotes the nth derivative of f  ( I ).)
8.5.2 
Consider the driven pendulum φ
αφ
φ
″
′
+
+
=
sin
I . By numerical com-
putation of the phase portrait, verify that if B is fixed and sufficiently small, the 
system’s stable limit cycle is destroyed in a homoclinic bifurcation as I decreases. 
Show that if B is too large, the bifurcation is an infinite-period bifurcation instead.
8.5.3 
(Logistic equation with periodically varying carrying capacity) Consider 
the logistic equation N
rN
N K t
=
−
(
( )),
1
 where the carrying capacity is positive, 
smooth, and T-periodic in t.
a) Using a Poincaré map argument like that in the text, show that the system has at 
least one stable limit cycle of period T, contained in the strip Kmin b N b Kmax.
b) Is the cycle necessarily unique?
8.5.4 
(Logistic equation with sinusoidal harvesting)  In Exercise 3.7.3 you were 
asked to consider a simple model of a fishery with constant harvesting. Now con-
sider a generalization in which the harvesting varies periodically in time, perhaps 
due to daily or seasonal variations. To keep things simple, assume the periodic 
harvesting is purely sinusoidal (Benardete et al. 2008). Then, if the fish population 
grows logistically in the absence of harvesting, the model is given in dimensionless 
form by x
rx
x
h
t
=
−
−
+
(
)
(
sin )
1
1
B
. Assume that r h
,
 0  and 0
1


B
.
a) Show that if h
r
 / 4  the system has no periodic solutions, even though the fish 
are being harvested periodically with period T  2Q . What happens to the fish 
population in this case?
b) By using a Poincaré map argument like that in the text, show that if 
h
r
<
+
4 1
(
)
B   , there exists a 2Q-periodic solution—in fact, a stable limit 
cycle—in the strip 1 2
1
/


x
. Similarly, show there exists an unstable limit 
cycle in the strip 0
1 2


x
/
. Interpret your results biologically.
c)  What happens in between cases (a) and (b), i.e., for 
r
h
r
4 1
4
(
)
+
<
<
B
?

300 
BIFURCATIONS REVISITED
8.5.5 
(Driven pendulum with quadratic damping)  Consider a pendulum 
driven by a constant torque and damped by air resistance.  In dimensionless form, 
the governing equation is

 
θ
αθ θ
θ
+
+
=
sin
F
where B  0  and F  0  are the dimensionless damping strength and torque, 
respectively.  The new feature here is that we assume the damping is quadratic, 
rather than linear, in the velocity v  R . This is more realistic if the damping is 
primarily due to drag, but the trouble is that the damping becomes nonlinear, 
which normally would make the analysis harder. But as you’ll see, the pleasant 
surprise here is that quadratic damping actually makes the system easier—in fact, 
it becomes explicitly solvable!
a) Find and classify the fixed points in the ( , )
R v  phase plane. If you find a center 
according to the linearization, decide whether this borderline case is truly a 
nonlinear center, a stable spiral, or an unstable spiral. (Hint: Find a local 
Liapunov function in the neighborhood of the fixed point.) 
b) For F 1, prove that the system has a stable limit cycle (where we now regard 
the phase space as a cylinder rather than a plane). Then prove that this limit 
cycle is unique.
Remarkably, exact formulas for the limit cycle and the homoclinic bifurcation 
curve can be found (Pedersen and Saermark 1973); this is one of the advantages 
of the quadratically damped case. However, the solution involves some tricky 
changes of variables. Here’s how it works: 
c) In the region v  0 , R( )t  increases monotonically. Therefore it can be inverted 
formally to yield t( )
R .  Now regard R  as a new independent (time-like) vari-
able, and introduce the new dependent variable u
v
 1
2
2 . Use the chain rule 
(carefully, showing all your steps) to deduce that du
dR
R
 .
d) Hence, 
in 
the 
region 
v  0 , 
the 
pendulum 
equation 
becomes 
du
d
u
F
θ
α
θ
+
+
=
2
sin
 , which is a linear equation in u( )
R . Assuming that this 
equation is correct (even if you were unable to derive it), find an exact formula 
for the limit cycle when F 1.
e) Now decrease F while keeping B  fixed. Show that the limit cycle undergoes a 
homoclinic bifurcation at some critical value of F, call it F
Fc

( )
B , and give 
an exact formula for the bifurcation curve Fc( )
B .

301
EXERCISES
8.6 Coupled Oscillators and Quasiperiodicity
8.6.1 
(“Oscillator death” and bifurcations on a torus) In a paper on systems of 
neural oscillators, Ermentrout and Kopell (1990) illustrated the notion of “oscilla-
tor death” with the following model:


θ
ω
θ
θ
θ
ω
θ
θ
1
1
1
2
2
2
2
1
=
+
=
+
sin
cos
,
sin
cos
,
where X1, X2 p 0.
a) Sketch all the qualitatively different phase portraits that arise as X1, X2 vary.
b) Find the curves in X1, X2 parameter space along which bifurcations occur, and 
classify the various bifurcations.
c) Plot the stability diagram in X1, X2 parameter space.
8.6.2 
Reconsider the system (8.6.1):


θ
ω
θ
θ
θ
ω
θ
θ
1
1
1
2
1
2
2
2
1
2
=
+
−
=
+
−
K
K
sin(
),
sin(
).
a) Show that the system has no fixed points, given that X1, X2  0 and K1, K2 0.
b) Find a conserved quantity for the system. (Hint: Solve for sin( R2 – R1 ) in two ways. 
The existence of a conserved quantity shows that this system is a non-generic 
flow on the torus; normally there would not be any conserved quantities.)
c) Suppose that K1  K2. Show that the system can be nondimensionalized to
d
d
a
d
d
a
θ
θ
θ
θ
ω
θ
θ
1
2
1
2
1
2
1
τ
τ
= +
−
=
+
−
sin(
),
sin(
).
d) Find the winding number lim
( )
( )
τ
θ
θ
→∞
1
2
τ
τ  analytically. (Hint: Evaluate the 
long-time averages〈
+
〉
d
d
(
)
θ
θ
1
2
τ  and 〈
−
〉
d
d
(
)
θ
θ
1
2
τ , where the brackets are 
defined by 〈〉≡
→∞∫
f
f
d
T
T
T
lim
( )
.
1
0
U
U  For another approach, see Guckenheimer 
and Holmes (1983, p. 299).)
8.6.3 
(Irrational flow yields dense orbits) Consider the flow on the torus given 
by 

θ
ω θ
ω
1
1
2
2


,
, where X1 / X2 is irrational. Show each trajectory is dense; i.e., 
given any point p on the torus, any initial condition q, and any F  0, there is some 
t  d such that the trajectory starting at q passes within a distance F of p.
8.6.4 
Consider the system


R
R
R
R
R
R
R
R
1
1
2
1
2
2
1
2
=
−
+
−
=
+
+
−
E
K
E
K
sin
sin(
),
sin
sin(
)
where E, K p 0.
a) Find and classify all the fixed points.
b) Show that if E is large enough, the system has periodic solutions on the torus. 
What type of bifurcation creates the periodic solutions?

302 
BIFURCATIONS REVISITED
c) Find the bifurcation curve in ( E, K ) space at which these periodic solutions are 
created.
A generalization of this system to N  1 phases has been proposed as a model 
of switching in charge-density waves (Strogatz et al. 1988, 1989).
8.6.5 
(Plotting Lissajous figures) Using a computer, plot the curve whose para-
metric equations are x t
t
y t
t
( )
sin ,
( )
sin
,


X  for the following rational and irra-
tional values of the parameter X :
(a) X  3 
 
(b) X  2
3  
 
(c) X  5
3
(d) X 
2  
 
(e) X  Q 
 
(f) X =
+
1
2 1
5
(
).
The resulting curves are called Lissajous figures. In the old days they were dis-
played on oscilloscopes by using two ac signals of different frequencies as inputs.
8.6.6 
(Explaining Lissajous figures) Lissajous figures are one way to visualize 
the knots and quasiperiodicity discussed in the text. To see this, consider a pair of 
uncoupled harmonic oscillators described by the four-dimensional system 
x
x
+
= 0,  y
y
+
=
X2
0 .
a) Show that if x  A ( t ) sin R ( t ), y  B ( t ) sin G ( t ), then 

A
B

 0  (so A, B are 
constants) and R 1, θ
ω

.
b) Explain why (a) implies that trajectories are typically confined to two-dimen-
sional tori in a four-dimensional phase space.
c) How are the Lissajous figures related to the trajectories of this system?
8.6.7 
(Mechanical example of quasiperiodicity) The equations
mr
h
mr
k
h
mr


=
−
=
2
3
2
,
R
govern the motion of a mass m subject to a central force of constant strength k  0. 
Here r, R are polar coordinates and h  0 is a constant (the angular momentum of 
the particle).
a) Show that the system has a solution r  r0, θ
ωθ

, corresponding to uniform 
circular motion at a radius r0 and frequency X R. Find formulas for r0 and X R.
b) Find the frequency Xr of small radial oscillations about the circular orbit.
c) Show that these small radial oscillations correspond to quasiperiodic motion 
by calculating the winding number Xr / X R.
d) Show by a geometric argument that the motion is either periodic or quasiperi-
odic for any amplitude of radial oscillation. (To say it in a more interesting way, 
the motion is never chaotic.)
e) Can you think of a mechanical realization of this system?
8.6.8 
Solve the equations of Exercise 8.6.7 on a computer, and plot the particle’s 
path in the plane with polar coordinates r, R.

303
EXERCISES
8.6.9 
(Japanese tree frogs) Many thanks to Bard Ermentrout for suggesting the 
following exercise. An isolated male Japanese tree frog will call nearly periodically. 
When two frogs are placed close together (say, 50 cm apart), they can hear each 
other calling and tend to adjust their croak rhythms so that they call in alternation, 
half a cycle apart—a form of phase-locking known as antiphase synchronization. 
So what happens when three frogs interact? This situation frustrates them; 
there’s no way all three can get half a cycle away from everyone else. Aihara et al. 
(2011) found experimentally that in this case, the three frogs settle into one of two 
distinctive patterns (and they occasionally seem to switch between them, probably 
due to noise in the environment). One stable pattern involves a pair of frogs calling 
in unison, with the third frog calling approximately half a cycle out of phase from 
both of them. The other stable pattern has the three frogs maximally out of sync, 
with each calling one-third of a cycle apart from the other two. 
Aihara et al. (2011) explored a coupled oscillator model of these phenomena, the 
essence of which is contained in the following systems for two frogs,


θ
ω
θ
θ
θ
ω
θ
θ
1
2
1
2
1
2
=
+
−
=
+
−
H
H
(
)
(
),
and three frogs,



θ
ω
θ
θ
θ
θ
θ
ω
θ
θ
θ
θ
θ
ω
θ
θ
1
2
1
3
1
2
1
2
3
2
3
1
=
+
−
+
−
=
+
−
+
−
=
+
−
H
H
H
H
H
(
)
(
)
(
)
(
)
(
3
2
3
)
(
).
+
−
H θ
θ
Here Ri  denotes the phase of the calling rhythm of frog i, and the function H 
quantifies the interaction between any two of them. For simplicity we’ll assume all 
the frogs are identically coupled (same H for all of them) and have identical natural 
frequencies X . Furthermore, assume that H is odd, smooth, and 2Q-periodic.
a)  Rewrite the systems for both two and three frogs in terms of the phase differ-
ences φ
θ
θ
=
−
1
2  and ψ
θ
θ
=
−
2
3 . 
b) Show that the experimental results for two frogs are consistent with the simplest 
possible interaction function, H x
a
x
( )
sin

, if the sign of a is chosen appro-
priately. But then show that this simple H cannot account for the three-frog 
results.
c) Next, consider more complicated interaction functions of the form 
H x
a
x
b
x
( )
sin
sin
=
+
2
. For the three-frog model, use a computer to plot the 
phase portraits in the ( ,
)
φ ψ  plane for various values of a and b. Show that for 
suitable choices of a and b, you can explain all the experimental results for two 
and three frogs. That is, you can find a domain in the ( , )
a b  parameter space for 
which the system has:

304 
BIFURCATIONS REVISITED
i) a stable antiphase solution for the two-frog model;
ii) a stable phase-locked solution for the three-frog model, in which 
frogs 1 and 2 are in sync and approximately Q  out of phase from 
frog 3;
iii) a co-existing stable phase-locked solution with the three frogs one-
third of a cycle apart.
d) Show numerically that adding a small even periodic component to H does not 
alter these results qualitatively. 
Caveat: The three-frog model studied here is more symmetrical than that con-
sidered by Aihara et al. (2011). They assumed unequal coupling strengths because 
in their experiments one frog was positioned midway between the other two. The 
frogs at either end therefore interacted less strongly with each other than with the 
frog in the middle. 
8.7 Poincaré Maps
8.7.1 
Use partial fractions to evaluate the integral 
dr
r
r
r
r
(
)
1
2
0
1
−
∫
 that arises in 
Example 8.7.1, and show that r1   [l  e4Q ( r0
2 – 1)]–1 / 2. Then confirm that 
Pa ( r* )  e–4Q, as expected from Example 8.7.3.
8.7.2 
Consider the vector field on the cylinder given by R 1,  y
ay

. Define 
an appropriate Poincaré map and find a formula for it. Show that the system has a 
periodic orbit. Classify its stability for all real values of a.
8.7.3 
(Overdamped system forced by a square wave) Consider an overdamped 
linear oscillator (or an RC-circuit) forced by a square wave. The system can be 
nondimensionalized to x
x
F t
+
=
( ), where F  ( t ) is a square wave of period T. To 
be more specific, suppose
F t
A
t
T
A
T
t
T
( )
,
/
,
/
= +
< <
−
< <
⎧
⎨⎪⎪
⎩⎪⎪
0
2
2
for t  (0, T ), and then F  ( t ) is periodically repeated for all other t. The goal is to 
show that all trajectories of the system approach a unique periodic solution. We 
could try to solve for x ( t ) but that gets a little messy. Here’s an approach based on 
the Poincaré map—the idea is to “strobe” the system once per cycle.
a) Let x (0)  x0. Show that x ( T )  x0e–T – A (l – e–T / 2 ) 2.
b) Show that the system has a unique periodic solution, and that it satisfies x0 
A tanh( T / 4).
c) Interpret the limits of x ( T ) as T l 0 and T l d. Explain why they’re plausible.

305
EXERCISES
d) Let x1  x ( T ), and define the Poincaré map P by x1  P ( x0 ). More generally, 
xn 1  P ( xn ). Plot the graph of P.
e) Using a cobweb picture, show that P has a globally stable fixed point. (Hence 
the original system eventually settles into a periodic response to the forcing.)
8.7.4 
A Poincaré map for the system x
x
A
t
+
=
sinX  was shown in Figure 8.7.3, 
for a particular choice of parameters. Given that X  0, can you deduce the sign of 
A ? If not, explain why not.
8.7.5 
(Another driven overdamped system) By considering an appropriate 
Poincaré map, prove that the system R
R
+
=
sin
sint  has at least two periodic solu-
tions. Can you say anything about their stability? (Hint: Regard the system as a 
vector field on a cylinder: t 1, R
R
=
−
sin
sin .
t
 Sketch the nullclines and thereby 
infer the shape of certain key trajectories that can be used to bound the periodic 
solutions. For instance, sketch the trajectory that passes through ( , )
( , ).
t θ
π
π

2
2
)
8.7.6 
Give a mechanical interpretation of the system R
R
+
=
sin
sint  consid-
ered in the previous exercise.
8.7.7 
(Computer work) Plot a computer-generated phase portrait of the system 
t 1, R
R
=
−
sin
sin .
t
 Check that your results agree with your answer to 
Exercise 8.7.5.
8.7.8 
Consider the system x
x
F t
+
=
( ), where F  ( t ) is a smooth, T-periodic 
function. Is it true that the system necessarily has a stable T-periodic solution x ( t )? 
If so, prove it; if not, find an F that provides a counterexample.
8.7.9 
Consider the vector field given in polar coordinates by r
r
r
= − 2, R 1.
a) Compute the Poincaré map from S to itself, where S is the positive x-axis.
b) Show that the system has a unique periodic orbit and classify its stability.
c) Find the characteristic multiplier for the periodic orbit.
8.7.10 
Explain how to find Floquet multipliers numerically, starting from per-
turbations along the coordinate directions.
8.7.11 
(Reversibility and the in-phase periodic state of a Josephson array) Use 
a reversibility argument to prove that the in-phase periodic state of (8.7.1) is not 
attracting, even if the nonlinear terms are kept.
8.7.12 
(Globally coupled oscillators) Consider the following system of N identi-
cal oscillators:
R
R
R
i
i
K
N
j
j
N
f
f
=
+
=∑
(
)
(
),
1
  for i  1, . . . , N,

306 
BIFURCATIONS REVISITED
where K  0 and f  ( R ) is smooth and 2Q-periodic. Assume that f  ( R )  0 for all R so 
that the in-phase solution is periodic. By calculating the linearized Poincaré map 
as in Example 8.7.4, show that all the characteristic multipliers equal 1.
Thus the neutral stability found in Example 8.7.4 holds for a broader class of 
oscillator arrays. In particular, the reversibility of the system is not essential. This 
example is from Tsang et al. (1991).

 
PART III
CHAOS


309
9.0 INTRODUCTION
9
LORENZ EQUATIONS
9.0 Introduction
We begin our study of chaos with the Lorenz equations



x
y
x
y
rx
y
xz
z
xy
bz
=
−
=
−−
=
−
T(
)
.
 
Here T r, b  0 are parameters. Ed Lorenz (1963) derived this three-dimensional 
system from a drastically simplified model of convection rolls in the atmosphere. 
The same equations also arise in models of lasers and dynamos, and as we’ll see 
in Section 9.1, they exactly describe the motion of a certain waterwheel (you might 
like to build one yourself).
Lorenz discovered that this simple-looking deterministic system could have 
extremely erratic dynamics: over a wide range of parameters, the solutions oscil-
late irregularly, never exactly repeating but always remaining in a bounded region 
of phase space. When he plotted the trajectories in three dimensions, he discov-
ered that they settled onto a complicated set, now called a strange attractor. Unlike 
stable fixed points and limit cycles, the strange attractor is not a point or a curve or 
even a surface—it’s a fractal, with a fractional dimension between 2 and 3.
In this chapter we’ll follow the beautiful chain of reasoning that led Lorenz to 
his discoveries. Our goal is to get a feel for his strange attractor and the chaotic 
motion that occurs on it.
Lorenz’s paper (Lorenz 1963) is deep, prescient, and surprisingly readable—
look it up! It is also reprinted in Cvitanovic (1989a) and Hao (1990). For a capti-
vating history of Lorenz’s work and that of other chaotic heroes, see Gleick (1987).

310 
LORENZ EQUATIONS
9.1 A Chaotic Waterwheel
A neat mechanical model of the Lorenz equations was invented by Willem Malkus 
and Lou Howard at MIT in the 1970s. The simplest version is a toy waterwheel 
with leaky paper cups suspended from its rim (Figure 9.1.1).
(a)
(b)
(c)
Figure 9.1.1
Water is poured in steadily from the top. If the flow rate is too slow, the top cups 
never fill up enough to overcome friction, so the wheel remains motionless. For 
faster inflow, the top cup gets heavy enough to start the wheel turning (Figure 
9.1.1a). Eventually the wheel settles into a steady rotation in one direction or the 
other (Figure 9.1.1b). By symmetry, rotation in either direction is equally possible; 
the outcome depends on the initial conditions.
By increasing the flow rate still further, we can destabilize the steady rotation. 
Then the motion becomes chaotic: the wheel rotates one way for a few turns, then 
some of the cups get too full and the wheel doesn’t have enough inertia to carry 
them over the top, so the wheel slows down and may even reverse its direction 
(Figure 9.1.1c). Then it spins the other way for a while. The wheel keeps chang-
ing direction erratically. Spectators have been known to place bets (small ones, of 
course) on which way it will be turning after a minute.
Figure 9.1.2 shows Malkus’s more sophisticated set-up that is used nowadays 
at MIT.

311
9.1 A CHAOTIC WATERWHEEL
(top view)
hole at bottom
of chamber
water pumped
into manifold
manifold
(perforated hose)
waterwheel
screw to
adjust tilt
stand
brake
chamber
water
column
base
(side view)
Figure 9.1.2
The wheel sits on a table top. It rotates in a plane that is tilted slightly from the hor-
izontal (unlike an ordinary waterwheel, which rotates in a vertical plane). Water 
is pumped up into an overhanging manifold and then sprayed out through dozens 
of small nozzles. The nozzles direct the water into separate chambers around the 
rim of the wheel. The chambers are transparent, and the water has food coloring 

312 
LORENZ EQUATIONS
in it, so the distribution of water around the rim is easy to see. The water leaks out 
through a small hole at the bottom of each chamber, and then collects underneath 
the wheel, where it is pumped back up through the nozzles. This system provides 
a steady input of water.
The parameters can be changed in two ways. A brake on the wheel can be 
adjusted to add more or less friction. The tilt of the wheel can be varied by turning 
a screw that props the wheel up; this alters the effective strength of gravity.
A sensor measures the wheel’s angular velocity X ( t ), and sends the data to a 
strip chart recorder which then plots X ( t ) in real time. Figure 9.1.3 shows a record 
of X ( t ) when the wheel is rotating chaotically. Notice once again the irregular 
sequence of reversals.
t
ω
Figure 9.1.3
We want to explain where this chaos comes from, and to understand the bifur-
cations that cause the wheel to go from static equilibrium to steady rotation to 
irregular reversals.
Notation
Here are the coordinates, variables and parameters that describe the wheel’s 
motion (Figure 9.1.4):
Q
(top view)
θ
Figure 9.1.4

313
9.1 A CHAOTIC WATERWHEEL
Rangle in the lab frame (not the frame attached to the wheel)
R  0 j 12:00 in the lab frame
X ( t )  angular velocity of the wheel (increases counterclockwise, as 
does R ) 
m ( R, t )  mass distribution of water around the rim of the wheel, defined 
such that the mass between R1 and R2 is M ( t ) = 
m
t d
( , )
R
R
R
R
1
2
¨
Q ( R )  inflow (rate at which water is pumped in by the nozzles above 
position R ) 
r  radius of the wheel 
K  leakage rate
v  rotational damping rate 
I  moment of inertia of the wheel
The unknowns are m ( R, t ) and X ( t ). Our first task is to derive equations gov-
erning their evolution.
Conservation of Mass
To find the equation for conservation of mass, we use a standard argument. 
You may have encountered it if you’ve studied fluids, electrostatics, or chemical 
engineering. Consider any sector [R1, R2] fixed in space (Figure 9.1.5).
ω
ω
Δ
Δ
1
2
t
t
θ
θ
Figure 9.1.5
The mass in that sector is M t
m
t d
( )
( , )
= ∫
R
R
R
R
1
2
. After an infinitesimal time %t, 
what is the change in mass %M? There are four contributions: 
1. The mass pumped in by the nozzles is 
Qd
t
R
R
R
1
2
∫
⎡
⎣⎢⎢
⎤
⎦⎥⎥Δ .
2. The mass that leaks out is −
⎡
⎣⎢⎢
⎤
⎦⎥⎥
∫
Km d
t
 R
R
R
1
2
Δ . Notice the factor of m in 
the integral; it implies that leakage occurs at a rate proportional to the 
mass of water in the chamber—more water implies a larger pressure 

314 
LORENZ EQUATIONS
head and therefore faster leakage. Although this is plausible physically, 
the fluid mechanics of leakage is complicated, and other rules are con-
ceivable as well. The real justification for the rule above is that it agrees 
with direct measurements on the waterwheel itself, to a good approxi-
mation. (For experts on fluids: to achieve this linear relation between 
outflow and pressure head, Malkus attached thin tubes to the holes at 
the bottom of each chamber. Then the outflow is essentially Poiseuille 
flow in a pipe.)
3. As the wheel rotates, it carries a new block of water into our observa-
tion sector. That block has mass m
t
(
)
,
θ ω
1
%  because it has angular 
width X%t (Figure 9.1.5), and m(
)
R1  is its mass per unit angle. 
4. Similarly, the mass carried out of the sector is −m
t
(
)
.
θ
ω
2
Δ
Hence,
Δ
Δ
Δ
Δ
M
t
Qd
Km d
m
t
m
t
=
−
⎡
⎣⎢⎢
⎤
⎦⎥⎥+
−
∫
∫
θ
θ
θ ω
θ
ω
θ
θ
θ
θ
1
2
1
2
1
2
(
)
(
)
. (1) 
To convert (1) to a differential equation, we put the transport terms inside the inte-
gral, using m ( R1 ) – m ( R2 ) = −
∂
∂
∫
m d
R
R
R
R
1
2
. Then we divide by %t and let %t l 0. 
The result is
dM
dt
Q
Km
d
m
=
−
−
∂
∂
∫
(
)
.
ω
θ
θ
θ
θ
1
2
But by definition of M, 
dM
dt
m
t d
=
∂
∂
∫
R
R
R
.
1
2
Hence
∂
=
−
−
∫
∫
∂
∂
m
dt d
Q
Km
d
m
θ
θ
θ
θ
θ
θ
ω
θ
1
2
1
2 (
)
.
Since this holds for all R1 and R2, we must have
∂
∂
=
−
−
∂
∂
m
t
Q
Km
m
ω
θ .  
(2)
Equation (2) is often called the continuity equation. Notice that it is a partial 
differential equation, unlike all the others considered so far in this book. We’ll 
worry about how to analyze it later; we still need an equation that tells us how X ( t ) 
evolves.

315
9.1 A CHAOTIC WATERWHEEL
Torque Balance
The rotation of the wheel is governed by Newton’s law F  ma, expressed as a 
balance between the applied torques and the rate of change of angular momentum. 
Let I denote the moment of inertia of the wheel. Note that in general I depends on 
t, because the distribution of water does. But this complication disappears if we 
wait long enough: as t l d, one can show that I ( t ) l constant (Exercise 9.1.1). 
Hence, after the transients decay, the equation of motion is
I X   damping torque  gravitational torque.
There are two sources of damping: viscous damping due to the heavy oil in the 
brake, and a more subtle “inertial” damping caused by a spin-up effect—the water 
enters the wheel at zero angular velocity but is spun up to angular velocity X before 
it leaks out. Both of these effects produce torques proportional to X, so we have
damping torque  –vX,
where v  0. The negative sign means that the damping opposes the motion.
The gravitational torque is like that of an inverted pendulum, since water is 
pumped in at the top of wheel (Figure 9.1.6).
g
(top view)
d
θ
θ
Figure 9.1.6
In an infinitesimal sector dR, the mass dM  mdR. This mass element produces a 
torque
dU  ( dM ) gr sinR  mgr sinR dR.
To check that the sign is correct, observe that when sinR  0 the torque tends to 
increase X, just as in an inverted pendulum. Here g is the effective gravitational 
constant, given by g  g0 sin B where 
g0 is the usual gravitational constant 
and B is the tilt of the wheel from hor-
izontal (Figure 9.1.7). Integration over 
all mass elements yields
g
α
(side view)
wheel
0
Figure 9.1.7

316 
LORENZ EQUATIONS
gravitational torque =
∫
gr
m
t
d
( , )sin
.
θ
θ θ
π
0
2
Putting it all together, we obtain the torque balance equation
I
v
gr
m
t
d
ω
ω
θ
θ θ
π
= −
+ ∫
( , )sin
.
0
2
 
(3)
This is called an integro-differential equation because it involves both derivatives 
and integrals.
Amplitude Equations
Equations (2) and (3) completely specify the evolution of the system. Given the 
current values of m ( R, t ) and X ( t ), (2) tells us how to update m and (3) tells us how 
to update X. So no further equations are needed.
If (2) and (3) truly describe the waterwheel’s behavior, there must be some pretty 
complicated motions hidden in there. How can we extract them? The equations 
appear much more intimidating than anything we’ve studied so far.
A miracle occurs if we use Fourier analysis to rewrite the system. Watch!
Since m ( R, t ) is periodic in R, we can write it as a Fourier series
m
t
a t
n
b t
n
n
n
n
( , )
sin
cos
.
R
R
R
=
+
[
]
=
∞
∑
( )
( )
0
 
(4)
By substituting this expression into (2) and (3), we’ll obtain a set of amplitude equa-
tions, ordinary differential equations for the amplitudes an, bn of the different har-
monics or modes. But first we must also write the inflow as a Fourier series:
Q
q
n
n
n
( )
cos
.
R
R
=
=
∞
∑
0
 
(5)
There are no sin nR terms in the series because water is added symmetrically at the 
top of the wheel; the same inflow occurs at R and –R. (In this respect, the water-
wheel is unlike an ordinary, real-world waterwheel where asymmetry is used to 
drive the wheel in the same direction at all times.) 
Substituting the series for m and Q into (2), we get
∂
∂
+
⎡
⎣
⎢⎢
⎤
⎦
⎥⎥= −
∂
∂
+
=
∞
∑
t
a t
n
b t
n
a t
n
b t
n
n
n
n
n
( )sin
( )cos
( )sin
(
θ
θ
ω
θ
θ
0
)cos
cos
( )sin
( )cos
n
q
n
K
a t
n
b t
n
n
n
n
n
n
n
θ
θ
θ
θ
=
∞
=
∞
=
∑
∑
⎡
⎣
⎢⎢
⎤
⎦
⎥⎥
+
−
+
0
0
0
∞
∑
⎡
⎣
⎢⎢
⎤
⎦
⎥⎥.

317
9.1 A CHAOTIC WATERWHEEL
Now carry out the differentiations on both sides, and collect terms. By orthogo-
nality of the functions sin nR, cos nR, we can equate the coefficients of each har-
monic separately. For instance, the coefficient of sin nR on the left-hand side is an,
and on the right it is n b
Ka
n
n
X

. Hence
a
n b
Ka
n
n
n
=
−
X
. 
(6)
Similarly, matching coefficients of cos nR yields
b
n a
Kb
q
n
n
n
n
= −
−
+
X
.  
(7)
Both (6) and (7) hold for all n  0, 1, . . . .
Next we rewrite (3) in terms of Fourier series. Get ready for the miracle. When 
we substitute (4) into (3), only one term survives in the integral, by orthogonality:
I
v
gr
a t
n
b t
n
d
v
n
n
n
ω
ω
θ
θ
θ θ
ω
π
= −
+
+
⎡
⎣
⎢⎢
⎤
⎦
⎥⎥
= −
=
∞
∑
∫
( )sin
( )cos
sin
0
0
2
+
= −
+
∫
gr
a
d
v
gra
1
2
0
2
1
sin
.
θ θ
ω
π
π
 
(8)
Hence, only a1 enters the differential equation for X . But then (6) and (7) imply 
that a1, b1, and X form a closed system—these three variables are decoupled from all 
the other an, bn, n v 1! The resulting equations are



a
b
Ka
b
a
Kb
q
v
gra
I
1
1
1
1
1
1
1
1
=
−
= −
−
+
= −
+
ω
ω
ω
ω
π
(
)
.
 
(9)
(If you’re curious about the higher modes an, bn, n v 1, see Exercise 9.1.2.)
We’ve simplified our problem tremendously: the original pair of integro-partial 
differential equations (2), (3) has boiled down to the three-dimensional system 
(9). It turns out that (9) is equivalent to the Lorenz equations! (See Exercise 9.1.3.) 
Before we turn to that more famous system, let’s try to understand a little about 
(9). No one has ever fully understood it—its behavior is fantastically complex—but 
we can say something.
Fixed Points
We begin by finding the fixed points of (9). For notational convenience, the 
usual asterisks will be omitted in the intermediate steps.
Setting all the derivatives equal to zero yields
a1  Xb1 / K 
(10)

318 
LORENZ EQUATIONS
Xa1  q1 – Kb1 
(11)
a1  vX / Qgr. 
(12)
Now solve for b1 by eliminating a1 from (10) and (11):
b
Kq
K
1
1
2
2
=
+
X
.
Equating (10) and (12) yields Xb1 / K  vX / Qgr. Hence X  0 or
b1  Kv / Qgr. 
(14)
Thus, there are two kinds of fixed point to consider:
1. If X  0, then a1  0 and b1  q1 / K. This fixed point
( a1*, b1*, X* )  (0, q l /K,0) 
(15)
corresponds to a state of no rotation; the wheel is at rest, with inflow 
balanced by leakage. We’re not saying that this state is stable, just that 
it exists; stability calculations will come later.
2. If X v 0, then (13) and (14) imply b1    Kq1 / ( X2  K2 )    Kv / Qgr. 
Since K v 0, we get q1 / ( X2  K2 )  v / Qgr. Hence
( *)
.
ω
π
2
1
2
=
−
grq
v
K
 
(16)
If the right-hand side of (16) is positive, there are two solutions, ±X*, 
corresponding to steady rotation in either direction. These solutions 
exist if and only if
Qgrq
K v
1
2
1
 . 
(17)
The dimensionless group in (17) is called the Rayleigh number. It measures how 
hard we’re driving the system, relative to the dissipation. More precisely, the ratio 
in (17) expresses a competition between g and q1 (gravity and inflow, which tend to 
spin the wheel), and K and v (leakage and damping, which tend to stop the wheel). 
So it makes sense that steady rotation is possible only if the Rayleigh number is 
large enough.
The Rayleigh number appears in other parts of fluid mechanics, notably con-
vection, in which a layer of fluid is heated from below. There it is proportional to the 
difference in temperature from bottom to top. For small temperature gradients, 
heat is conducted vertically but the fluid remains motionless. When the Rayleigh 
number increases past a critical value, an instability occurs—the hot fluid is less 

319
9.2 SIMPLE PROPERTIES OF THE LORENZ EQUATIONS
dense and begins to rise, while the cold fluid on top begins to sink. This sets up 
a pattern of convection rolls, completely analogous to the steady rotation of our 
waterwheel. With further increases of the Rayleigh number, the rolls become wavy 
and eventually chaotic.
The analogy to the waterwheel breaks down at still higher Rayleigh numbers, 
when turbulence develops and the convective motion becomes complex in space 
as well as time (Drazin and Reid 1981, Bergé et al. 1984, Manneville 1990). In con-
trast, the waterwheel settles into a pendulum-like pattern of reversals, turning 
once to the left, then back to the right, and so on indefinitely (see Example 9.5.2).
9.2 Simple Properties of the Lorenz Equations
In this section we’ll follow in Lorenz’s footsteps. He took the analysis as far as pos-
sible using standard techniques, but at a certain stage he found himself confronted 
with what seemed like a paradox. One by one he had eliminated all the known pos-
sibilities for the long-term behavior of his system: he showed that in a certain range 
of parameters, there could be no stable fixed points and no stable limit cycles, yet 
he also proved that all trajectories remain confined to a bounded region and are 
eventually attracted to a set of zero volume. What could that set be? And how do 
the trajectories move on it? As we’ll see in the next section, that set is the strange 
attractor, and the motion on it is chaotic.
But first we want to see how Lorenz ruled out the more traditional possibilities. 
As Sherlock Holmes said in The Sign of Four, “When you have eliminated the 
impossible, whatever remains, however improbable, must be the truth.”
The Lorenz equations are



x
y
x
y
rx
y
xz
z
xy
bz
=
−
=
−−
=
−
T(
)
.
 
(1)
Here T, r, b  0 are parameters: T is the Prandtl number, r is the Rayleigh number, 
and b has no name. (In the convection problem it is related to the aspect ratio of 
the rolls.)
Nonlinearity
The system (1) has only two nonlinearities, the quadratic terms xy and xz. This 
should remind you of the waterwheel equations (9.1.9), which had two nonlineari-
ties, Xa1 and Xb1. See Exercise 9.1.3 for the change of variables that transforms the 
waterwheel equations into the Lorenz equations.

320 
LORENZ EQUATIONS
Symmetry
There is an important symmetry in the Lorenz equations. If we replace 
( x,y ) l ( –x,–y ) in (1), the equations stay the same. Hence, if ( x ( t ), y ( t ), z ( t )) is a 
solution, so is ( –x ( t ), –y ( t ), z ( t )). In other words, all solutions are either symmet-
ric themselves, or have a symmetric partner.
Volume Contraction
The Lorenz system is dissipative: volumes in phase space contract under the 
flow. To see this, we must first ask: how do volumes evolve?
Let’s answer the question in general, for any three-dimensional system x
f x
 ( ). 
Pick an arbitrary closed surface S ( t ) of volume V ( t ) in phase space. Think of the 
points on S as initial conditions for trajectories, and let them evolve for an infini-
tesimal time dt. Then S evolves into a new surface S ( t  dt ); what is its volume 
V ( t  dt )?
Figure 9.2.1 shows a side view of the volume.
n
f
S(t+dt)
S(t)
V(t)
Figure 9.2.1
Let n denote the outward normal on S. Since f is the instantaneous velocity of the 
points, f ¸n is the outward normal component of velocity. Therefore in time dt a 
patch of area dA sweeps out a volume ( f ¸n dt ) dA, as shown in Figure 9.2.2.
f.n dt
dA
{
Figure 9.2.2

321
9.2 SIMPLE PROPERTIES OF THE LORENZ EQUATIONS
Hence
V ( t  dt )  V ( t )  (volume swept out by tiny patches of surface, 
integrated over all patches),
so we obtain
V t
dt
V t
dt dA
S
(
)
( )
.
+
=
+
⋅
∫(
)
f n
Hence
V
V t
dt
V t
dt
dA
S
=
+
−
=
⋅
∫
(
)
( )
.
f n
Finally, we rewrite the integral above by the divergence theorem, and get
V
dV
V
=
∇⋅
∫
f
. 
(2)
For the Lorenz system,
∇⋅= ∂
∂
−
[
]+ ∂
∂
−−
[
]+ ∂
∂
−
[
]
= −−−<
f
x
y
x
y rx
y
xz
z xy
bz
b
T
T
(
)
.
1
0
Since the divergence is constant, (2) reduces to V
b V
= −
+ +
(
) ,
T
1
 which has solu-
tion V ( t )  V (0) e–( T 1  b )t. Thus volumes in phase space shrink exponentially fast.
Hence, if we start with an enormous solid blob of initial conditions, it eventually 
shrinks to a limiting set of zero volume, like a balloon with the air being sucked 
out of it. All trajectories starting in the blob end up somewhere in this limiting set; 
later we’ll see it consists of fixed points, limit cycles, or for some parameter values, 
a strange attractor.
Volume contraction imposes strong constraints on the possible solutions of the 
Lorenz equations, as illustrated by the next two examples.
EXAMPLE 9.2.1:
Show that there are no quasiperiodic solutions of the Lorenz equations.
Solution: We give a proof by contradiction. If there were a quasiperiodic solu-
tion, it would have to lie on the surface of a torus, as discussed in Section 8.6, and 
this torus would be invariant under the flow. Hence the volume inside the torus 
would be constant in time. But this contradicts the fact that all volumes shrink 
exponentially fast. ■

322 
LORENZ EQUATIONS
EXAMPLE 9.2.2:
Show that it is impossible for the Lorenz system to have either repelling fixed points 
or repelling closed orbits. (By repelling, we mean that all trajectories starting near 
the fixed point or closed orbit are driven away from it.)
Solution: Repellers are incompatible with volume contraction because they 
are sources of volume, in the following sense. Suppose we encase a repeller with 
a closed surface of initial conditions nearby in phase space. (Specifically, pick a 
small sphere around a fixed point, or a thin tube around a closed orbit.) A short 
time later, the surface will have expanded as the corresponding trajectories are 
driven away. Thus the volume inside the surface would increase. This contradicts 
the fact that all volumes contract. ■
By process of elimination, we conclude that all fixed points must be sinks or 
saddles, and closed orbits (if they exist) must be stable or saddle-like. For the case 
of fixed points, we now verify these general conclusions explicitly.
Fixed Points
Like the waterwheel, the Lorenz system (1) has two types of fixed points. The 
origin ( x*, y*, z* )  (0, 0, 0) is a fixed point for all values of the parameters. It is like 
the motionless state of the waterwheel. For r  1, there is also a symmetric pair of 
fixed points x
y
b r
*
*
(
),
=
= ±
−1  z*  r – 1. Lorenz called them C and C–. They 
represent left- or right-turning convection rolls (analogous to the steady rotations 
of the waterwheel). As r l 1, C and C– coalesce with the origin in a pitchfork 
bifurcation.
Linear Stability of the Origin
The linearization at the origin is x
y
x
=
−
(
)
T
, y
rx
y
=
−,  z
bz
= −
,  obtained 
by omitting the xy and xz nonlinearities in (1). The equation for z is decoupled and 
shows that z ( t ) l 0 exponentially fast. The other two directions are governed by 
the system


x
y
r
x
y
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟= −
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
T
T
1
,
with trace U  –T – 1  0 and determinant %  T (l – r ). If r  1, the origin is a 
saddle point because %  0. Note that this is a new type of saddle for us, since the 
full system is three-dimensional. Including the decaying z-direction, the saddle 
has one outgoing and two incoming directions. If r  1, all directions are incoming 
and the origin is a sink. Specifically, since U2 – 4%  ( T  1) 2 – 4T (l – r )  ( T – 1) 2 
 4Tr  0, the origin is a stable node for r  1.

323
9.2 SIMPLE PROPERTIES OF THE LORENZ EQUATIONS
Global Stability of the Origin
Actually, for r  1, we can show that every trajectory approaches the origin as 
t l d; the origin is globally stable. Hence there can be no limit cycles or chaos for 
r  1.
The proof involves the construction of a Liapunov function, a smooth, positive 
definite function that decreases along trajectories. As discussed in Section 7.2, a 
Liapunov function is a generalization of an energy function for a classical mechan-
ical system—in the presence of friction or other dissipation, the energy decreases 
monotonically. There is no systematic way to concoct Liapunov functions, but 
often it is wise to try expressions involving sums of squares.
Here, consider V x y z
x
y
z
( , , )
.
=
+
+
1
2
2
T
2
 The surfaces of constant V are con-
centric ellipsoids about the origin (Figure 9.2.3).
z
y
x
V= const
Figure 9.2.3
The idea is to show that if r  1 and ( x,y,z ) v (0,0,0), then V  0  along trajectories. 
This would imply that the trajectory keeps moving to lower V, and hence pene-
trates smaller and smaller ellipsoids as t l d. But V is bounded below by 0, so 
V ( x (t )) l 0 and hence x ( t ) l 0, as desired. 
Now calculate:
1
2
1
2
2
2
1




V
xx
yy
zz
yx
x
ryx
y
xyz
zxy
bz
r
xy
=
+
+
=
−
+
−
−
+
−
=
+
−
T
(
)
(
)
(
)
(
)
x
y
bz
2
2
2
−
−
.
Completing the square in the first two terms gives
1
2
1
2
2
1
2
2
2
2
1
V
x
y
y
bz
r
r
= −
−
⎡⎣
⎤⎦−−
⎡⎣⎢
⎤⎦⎥
−
+
+
(
)
.
We claim that the right-hand side is strictly negative if r  1 and ( x,y,z ) v (0,0,0). It 
is certainly not positive, since it is a negative sum of squares. But could V  0?  

324 
LORENZ EQUATIONS
That would require each of the terms on the right to vanish separately. Hence 
y  0, z  0, from the second two terms on the right-hand side. (Because of the 
assumption r  1, the coefficient of y2 is nonzero.) Thus the first term reduces to 
–x2, which vanishes only if x  0.
The upshot is that V  0  implies ( x, y, z )  (0, 0, 0). Otherwise V  0.  Hence 
the claim is established, and therefore the origin is globally stable for r  1.
Stability of C+ and C–
Now suppose r  1, so that C  and C – exist. The calculation of their stability is 
left as Exercise 9.2.1. It turns out that they are linearly stable for
1
3
1
< <
=
+ +
−−
r
r
b
b
H
T T
T
(
)
(assuming also that T– b – 1  0). We use a subscript H because C and C – lose 
stability in a Hopf bifurcation at r  rH.
What happens immediately after the bifurcation, for r slightly greater than rH ? 
You might suppose that C and C – would each be surrounded by a small stable 
limit cycle. That would occur if the Hopf bifurcation were supercritical. But actu-
ally it’s subcritical—the limit cycles are unstable and exist only for r  rH . This 
requires a difficult calculation; see Marsden and McCracken (1976) or Drazin 
(1992, Q8.2 on p. 277).
Here’s the intuitive picture. For r  rH the phase portrait near C is shown sche-
matically in Figure 9.2.4.
saddle cycle
unstable manifold
of saddle cycle
C+
Figure 9.2.4
The fixed point is stable. It is encircled by a saddle cycle, a new type of unstable 
limit cycle that is possible only in phase spaces of three or more dimensions. The 
cycle has a two-dimensional unstable manifold (the sheet in Figure 9.2.4), and a 
two-dimensional stable manifold (not shown). As r l rH from below, the cycle 

325
9.3 CHAOS ON A STRANGE ATTRACTOR
shrinks down around the fixed point. At the Hopf bifurcation, the fixed point 
absorbs the saddle cycle and changes into a saddle point. For r  rH there are no 
attractors in the neighborhood.
So for r  rH trajectories must fly away to a distant attractor. But what can it be? 
A partial bifurcation diagram for the system, based on the results so far, shows no 
hint of any stable objects for r  rH (Figure 9.2.5).
r
x
+
−
C
C
1
origin
unstable
cycle
0
r
r
=
=
rH
Figure 9.2.5
Could it be that all trajectories are repelled out to infinity? No; we can prove that all 
trajectories eventually enter and remain in a certain large ellipsoid (Exercise 9.2.2). 
Could there be some stable limit cycles that we’re unaware of? Possibly, but Lorenz 
gave a persuasive argument that for r slightly greater than rH , any limit cycles 
would have to be unstable (see Section 9.4).
So the trajectories must have a bizarre kind of long-term behavior. Like balls in 
a pinball machine, they are repelled from one unstable object after another. At the 
same time, they are confined to a bounded set of zero volume, yet they manage to 
move on this set forever without intersecting themselves or others.
In the next section we’ll see how the trajectories get out of this conundrum.
9.3 Chaos on a Strange Attractor
Lorenz used numerical integration to see what the trajectories would do in the 
long run. He studied the particular case T  10, b  8
3 , r  28. This value of r is just 
past the Hopf bifurcation value rH  T ( T  b  3) / ( T – b – 1) x 24.74, so he knew 
that something strange had to occur. Of course, strange things could occur for 
another reason—the electromechanical computers of those days were unreliable 
and difficult to use, so Lorenz had to interpret his numerical results with caution.

326 
LORENZ EQUATIONS
He began integrating from the initial condition (0, 1, 0), close to the saddle point 
at the origin. Figure 9.3.1 plots y ( t ) for the resulting solution.
y
t
Figure 9.3.1
After an initial transient, the solution settles into an irregular oscillation that per-
sists as t l d, but never repeats exactly. The motion is aperiodic.
Lorenz discovered that a wonderful structure emerges if the solution is visual-
ized as a trajectory in phase space. For instance, when x( t ) is plotted against z ( t ), 
a butterfly pattern appears (Figure 9.3.2).
z
x
Figure 9.3.2

327
9.3 CHAOS ON A STRANGE ATTRACTOR
The trajectory appears to cross itself repeatedly, but that’s just an artifact of pro-
jecting the three-dimensional trajectory onto a two-dimensional plane. In three 
dimensions no self-intersections occur.
Let’s try to understand Figure 9.3.2 in detail. The trajectory starts near the 
origin, then swings to the right, and then dives into the center of a spiral on the 
left. After a very slow spiral outward, the trajectory shoots back over to the right 
side, spirals around a few times, shoots over to the left, spirals around, and so on 
indefinitely. The number of circuits made on either side varies unpredictably from 
one cycle to the next. In fact, the sequence of the number of circuits has many of 
the characteristics of a random sequence. Physically, the switches between left and 
right correspond to the irregular reversals of the waterwheel that we observed in 
Section 9.1.
When the trajectory is viewed in all three dimensions, rather than in a 
two-dimensional projection, it appears to settle onto an exquisitely thin set that 
looks like a pair of butterfly wings. Figure 9.3.3 shows a schematic of this strange 
attractor (a term coined by Ruelle and Takens (1971)). This limiting set is the 
attracting set of zero volume whose existence was deduced in Section 9.2.
Figure 9.3.3 Abraham and Shaw (1983), p. 88
What is the geometrical structure of the strange attractor? Figure 9.3.3 suggests 
that it is a pair of surfaces that merge into one in the lower portion of Figure 9.3.3. 
But how can this be, when the uniqueness theorem (Section 6.2) tells us that tra-
jectories can’t cross or merge? Lorenz (1963) gives a lovely explanation—the two 
surfaces only appear to merge. The illusion is caused by the strong volume con-
traction of the flow, and insufficient numerical resolution. But watch where that 
idea leads him:
It would seem, then, that the two surfaces merely appear to merge, and 
remain distinct surfaces. Following these surfaces along a path parallel to 
a trajectory, and circling C  and C –, we see that each surface is really a 
pair of surfaces, so that, where they appear to merge, there are really four 
surfaces. Continuing this process for another circuit, we see that there are 

328 
LORENZ EQUATIONS
really eight surfaces, etc., and we finally conclude that there is an infinite 
complex of surfaces, each extremely close to one or the other of two merg-
ing surfaces.
Today this “infinite complex of surfaces” would be called a fractal. It is a set of 
points with zero volume but infinite surface area. In fact, numerical experiments 
suggest that it has a dimension of about 2.05! (See Example 11.5.1.) The amazing 
geometric properties of fractals and strange attractors will be discussed in detail in 
Chapters 11 and 12. But first we want to examine chaos a bit more closely.
Exponential Divergence of Nearby Trajectories
The motion on the attractor exhibits sensitive dependence on initial conditions. 
This means that two trajectories starting very close together will rapidly diverge 
from each other, and thereafter have totally different futures. Color Plate 2 vividly 
illustrates this divergence by plotting the evolution of a small red blob of 10,000 
nearby initial conditions. The blob eventually spreads over the whole attractor. 
Hence nearby trajectories can end up anywhere on the attractor! The practical 
implication is that long-term prediction becomes impossible in a system like this, 
where small uncertainties are amplified enormously fast.
Let’s make these ideas more precise. Suppose that we let transients decay, so 
that a trajectory is “on” the attractor. Suppose x( t ) is a point on the attractor at 
time t, and consider a nearby point, say x( t )  E ( t ), where E is a tiny separation 
vector of initial length ||E  0 ||  10–15, say (Figure 9.3.4).
x
x
+
δ
δ
(t)
(t)
(t)
(t)
Figure 9.3.4
Now watch how E ( t ) grows. In numerical studies of the Lorenz attractor, one finds 
that
|| E ( t ) || _ || E0 || eMt
where M x 0.9. Hence neighboring trajectories separate exponentially fast. 
Equivalently, if we plot ln ||E ( t ) || versus t, we find a curve that is close to a straight 
line with a positive slope of M (Figure 9.3.5).

329
9.3 CHAOS ON A STRANGE ATTRACTOR
ln
slope =
t
δ
λ
|| ||
Figure 9.3.5
We need to add some qualifications:
1. The curve is never exactly straight. It has wiggles because the strength 
of the exponential divergence varies somewhat along the attractor.
2. The exponential divergence must stop when the separation is compa-
rable to the “diameter” of the attractor—the trajectories obviously 
can’t get any farther apart than that. This explains the leveling off or 
saturation of the curve in Figure 9.3.5.
3. The number M is often called the Liapunov exponent, although this is a 
sloppy use of the term, for two reasons:
First, there are actually n different Liapunov exponents for an 
n-dimensional system, defined as follows. Consider the evolution of an 
infinitesimal sphere of perturbed initial conditions. During its evolu-
tion, the sphere will become distorted into an infinitesimal ellipsoid. 
Let Ek ( t ), k  1, . . . , n, denote the length of the kth principal axis of 
the ellipsoid. Then δ
δ
λ
k
k
t
t
e
k
( )
( )
,
_
0
 where the Mk are the Liapunov 
exponents. For large t, the diameter of the ellipsoid is controlled by 
the most positive Mk. Thus our M is actually the largest Liapunov 
exponent.
Second, M depends (slightly) on which trajectory we study. We 
should average over many different points on the same trajectory to 
get the true value of M.
When a system has a positive Liapunov exponent, there is a time horizon beyond 
which prediction breaks down, as shown schematically in Figure 9.3.6. (See 
Lighthill 1986 for a nice discussion.) Suppose we measure the initial conditions of 
an experimental system very accurately. Of course, no measurement is perfect—
there is always some error ||E0 || between our estimate and the true initial state.

330 
LORENZ EQUATIONS
t
t
t
=
=
0
2 initial conditions,
almost indistinguishable
prediction
fails out here
horizon
Figure 9.3.6
After a time t, the discrepancy grows to || E ( t ) || _ || E0 || eMt. Let a be a measure of our 
tolerance, i.e., if a prediction is within a of the true state, we consider it acceptable. 
Then our prediction becomes intolerable when ||E ( t ) || p a; this occurs after a time
t
O
a
horizon ∼
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟
1
0
λ
δ
ln
.
The logarithmic dependence on ||E0|| is what hurts us. No matter how hard we 
work to reduce the initial measurement error, we can’t predict longer than a few 
multiples of 1 / M. The next example is intended to give you a quantitative feel for 
this effect.
EXAMPLE 9.3.1:
Suppose we’re trying to predict the future state of a chaotic system to within a 
tolerance of a  10–3. Given that our estimate of the initial state is uncertain to 
within ||E0||  10–7, for about how long can we predict the state of the system, while 
remaining within the tolerance? Now suppose we buy the finest instrumentation, 
recruit the best graduate students, etc., and somehow manage to measure the ini-
tial state a million times better, i.e., we improve our initial error to ||E0 ||  10–13. How 
much longer can we predict?
Solution: The original prediction has
thorizon ≈
=
=
−
−
1
10
10
1
10
4
10
3
7
4
M
M
M
ln
ln(
)
ln
.
The improved prediction has
thorizon ≈
=
=
−
−
1
10
10
1
10
10
10
3
13
10
M
M
M
ln
ln(
)
ln
.
Thus, after a millionfold improvement in our initial uncertainty, we can predict 
only 10 / 4  2.5 times longer! ■

331
9.3 CHAOS ON A STRANGE ATTRACTOR
Such calculations demonstrate the futility of trying to predict the detailed long-
term behavior of a chaotic system. Lorenz suggested that this is what makes long-
term weather prediction so difficult.
Defining Chaos
No definition of the term chaos is universally accepted yet, but almost everyone 
would agree on the three ingredients used in the following working definition:
Chaos is aperiodic long-term behavior in a deterministic system that exhibits 
sensitive dependence on initial conditions.
1. “Aperiodic long-term behavior” means that there are trajectories 
which do not settle down to fixed points, periodic orbits, or quasipe-
riodic orbits as t l d. For practical reasons, we should require that 
such trajectories are not too rare. For instance, we could insist that 
there be an open set of initial conditions leading to aperiodic trajecto-
ries, or perhaps that such trajectories should occur with nonzero prob-
ability, given a random initial condition.
2. “Deterministic” means that the system has no random or noisy 
inputs or parameters. The irregular behavior arises from the system’s 
nonlinearity, rather than from noisy driving forces.
3. “Sensitive dependence on initial conditions” means that nearby tra-
jectories separate exponentially fast, i.e., the system has a positive 
Liapunov exponent.
EXAMPLE 9.3.2:
Some people think that chaos is just a fancy word for instability. For instance, 
the system x
x

 is deterministic and shows exponential separation of nearby tra-
jectories. Should we call this system chaotic?
Solution: No. Trajectories are repelled to infinity, and never return. So infinity 
acts like an attracting fixed point. Chaotic behavior should be aperiodic, and that 
excludes fixed points as well as periodic behavior. ■
Defining Attractor and Strange Attractor
The term attractor is also difficult to define in a rigorous way. We want a defi-
nition that is broad enough to include all the natural candidates, but restrictive 
enough to exclude the imposters. There is still disagreement about what the exact 
definition should be. See Guckenheimer and Holmes (1983, p. 256), Eckmann and 
Ruelle (1985), and Milnor (1985) for discussions of the subtleties involved.
Loosely speaking, an attractor is a set to which all neighboring trajectories con-
verge. Stable fixed points and stable limit cycles are examples. More precisely, we 
define an attractor to be a closed set A with the following properties:

332 
LORENZ EQUATIONS
1. A is an invariant set: any trajectory x( t ) that starts in A stays in A for 
all time.
2. A attracts an open set of initial conditions: there is an open set U con-
taining A such that if x (0)  U, then the distance from x ( t ) to A tends 
to zero as t l d. This means that A attracts all trajectories that start 
sufficiently close to it. The largest such U is called the basin of attrac-
tion of A.
3. A is minimal: there is no proper subset of A that satisfies conditions 1 
and 2.
EXAMPLE 9.3.3:
Consider the system x
x
x
=
−
3, y
y
= −. Let I denote the interval –1 b x b 1, 
y  0. Is I an invariant set? Does it attract an open set of initial conditions? Is it an 
attractor?
Solution: The phase portrait is shown in Figure 9.3.7. There are stable fixed 
points at the endpoints (o1,0) of I and a saddle point at the origin. Figure 9.3.7 
shows that I is an invariant set; any trajectory that starts in I stays in I forever. (In 
fact the whole x-axis is an invariant set, since if y (0)  0, then y ( t )  0 for all t.) So 
condition 1 is satisfied.
y
x
Figure 9.3.7
Moreover, I certainly attracts an open set of initial conditions—it attracts all 
trajectories in the xy plane. So condition 2 is also satisfied.
But I is not an attractor because it is not minimal. The stable fixed points (o1,0) 
are proper subsets of I that also satisfy properties 1 and 2. These points are the 
only attractors for the system. ■

333
9.4 LORENZ MAP
There is an important moral to Example 9.3.3. Even if a certain set attracts 
all trajectories, it may fail to be an attractor because it may not be minimal—it 
may contain one or more smaller attractors.
The same could be true for the Lorenz equations. Although all trajectories are 
attracted to a bounded set of zero volume, that set is not necessarily an attractor, 
since it might not be minimal. Doubts about this delicate issue lingered for many 
years, but were eventually laid to rest in 1999, as we’ll discuss in Section 9.4.
Finally, we define a strange attractor to be an attractor that exhibits sensitive 
dependence on initial conditions. Strange attractors were originally called strange 
because they are often fractal sets. Nowadays this geometric property is regarded 
as less important than the dynamical property of sensitive dependence on initial 
conditions. The terms chaotic attractor and fractal attractor are used when one 
wishes to emphasize one or the other of those aspects.
9.4 Lorenz Map
Lorenz (1963) found a beautiful way to analyze the dynamics on his strange attrac-
tor. He directs our attention to a particular view of the attractor (Figure 9.4.1), 
z
y
Figure 9.4.1
and then he writes:

334 
LORENZ EQUATIONS
the trajectory apparently leaves one spiral only after exceeding some 
critical distance from the center. Moreover, the extent to which this 
distance is exceeded appears to determine the point at which the next 
spiral is entered; this in turn seems to determine the number of cir-
cuits to be executed before changing spirals again. It therefore seems 
that some single feature of a given circuit should predict the same fea-
ture of the following circuit.
The “single feature” that he focuses on is zn, the nth local maximum of z ( t ) 
(Figure 9.4.2).
z
z
z
n
t
n+1
Figure 9.4.2
Lorenz’s idea is that zn should predict zn. To check this, he numerically integrated 
the equations for a long time, then measured the local maxima of z ( t ), and finally 
plotted znl vs. zn. As shown in Figure 9.4.3, the data from the chaotic time series 
appear to fall neatly on a curve—there is almost no “thickness” to the graph!
zn
zn
+1
50
50
45
45
40
40
35
35
30
30
25
25
Figure 9.4.3

335
9.4 LORENZ MAP
By this ingenious trick, Lorenz was able to extract order from chaos. The func-
tion zn1  f  ( zn ) shown in Figure 9.4.3 is now called the Lorenz map. It tells us a lot 
about the dynamics on the attractor: given z0, we can predict z1 by z1  f  ( z0 ), and 
then use that information to predict z2  f  ( z1 ), and so on, bootstrapping our way 
forward in time by iteration. The analysis of this iterated map is going to lead us to 
a striking conclusion, but first we should make a few clarifications.
First, the graph in Figure 9.4.3 is not actually a curve. It does have some thick-
ness. So strictly speaking, f  ( z ) is not a well-defined function, because there can be 
more than one output znl for a given input zn. On the other hand, the thickness is 
so small, and there is so much to be gained by treating the graph as a curve, that we 
will simply make this approximation, keeping in mind that the subsequent analy-
sis is plausible but not rigorous.
Second, the Lorenz map may remind you of a Poincaré map (Section 8.7). In 
both cases we’re trying to simplify the analysis of a differential equation by reduc-
ing it to an iterated map of some kind. But there’s an important distinction: To 
construct a Poincaré map for a three-dimensional flow, we compute a trajectory’s 
successive intersections with a two-dimensional surface. The Poincaré map takes 
a point on that surface, specified by two coordinates, and then tells us how those 
two coordinates change after the first return to the surface. The Lorenz map is 
different because it characterizes the trajectory by only one number, not two. This 
simpler approach works only if the attractor is very “flat,” i.e., close to two-dimen-
sional, as the Lorenz attractor is.
Ruling Out Stable Limit Cycles
How do we know that the Lorenz attractor is not just a stable limit cycle in 
disguise? Playing devil’s advocate, a skeptic might say, “Sure, the trajectories don’t 
ever seem to repeat, but maybe you haven’t integrated long enough. Eventually 
the trajectories will settle down into a periodic behavior—it just happens that the 
period is incredibly long, much longer than you’ve tried in your computer. Prove 
me wrong.”
Although he couldn’t come up with a rigorous refutation, Lorenz was able to 
give a plausible counterargument that stable limit cycles do not, in fact, occur for 
the parameter values he studied.
His argument goes like this: The key observation is that the graph in Figure 9.4.3 
satisfies
| f  a ( z ) |  1 
(1)
everywhere. This property ultimately implies that if any limit cycles exist, they are 
necessarily unstable.
To see why, we start by analyzing the fixed points of the map f. These are points 
z* such that f  ( z* )  z*, in which case zn  znl  zn2  . . . . Figure 9.4.3 shows that 
there is one fixed point, where the 45° diagonal intersects the graph. It represents a 
closed orbit that looks like that shown in Figure 9.4.4.

336 
LORENZ EQUATIONS
z
y
Figure 9.4.4
To show that this closed orbit is unstable, consider a slightly perturbed trajec-
tory that has zn  z* In, where In is small. After linearization as usual, we find 
In+1 x f a ( z* )In. Since | f a ( z* )|  1, by the key property (1), we get
| In+1 |  | In |.
Hence the deviation In grows with each iteration, and so the original closed orbit 
is unstable.
Now we generalize the argument slightly to show that all closed orbits are 
unstable.
EXAMPLE 9.4.1:
Given the Lorenz map approximation zn1  f  ( zn ), with | f  a ( z ) |  1 for all z, 
show that all closed orbits are unstable.
Solution: Think about the sequence {zn} corresponding to an arbitrary closed 
orbit. It might be a complicated sequence, but since we know that the orbit eventu-
ally closes, the sequence must eventually repeat. Hence znp  zn, for some integer 
p p 1. (Here p is the period of the sequence, and zn is a period-p point.)
Now to prove that the corresponding closed orbit is unstable, consider the fate 
of a small deviation In, and look at it after p iterations, when the cycle is complete. 
We’ll show that |Inp |  | In |, which implies that the deviation has grown and the 
closed orbit is unstable.
To estimate Inp, go one step at a time. After one iteration, Inl x f  a ( zn ) In, by 
linearization about zn. Similarly, after two iterations,
I
I
I
I
n
n
n
n
n
n
n
n
f
z
f
z
f
z
f
z
f
z
+
+
+
+
+
≈
′
≈
′
′
⎡⎣
⎤⎦
=
′
′
⎡⎣
⎤⎦
2
1
1
1
1
(
)
(
)
(
)
(
)
(
)
n.

337
9.5 EXPLORING PARAMETER SPACE
Hence after p iterations,
I
I
n
p
n
k
k
p
n
f
z
+
+
=
−
≈
′
⎡
⎣
⎢⎢
⎤
⎦
⎥⎥
∏
(
)
.
0
1
 
(2)
In (2), each of the factors in the product has absolute value greater than 1, because 
| f  a ( z ) |  1 for all z. Hence | Inp |  | In |, which proves that the closed orbit is 
unstable. ■
Still, since the Lorenz map is not a well-defined function (because, as we’ve 
seen, its graph has some thickness to it), this sort of argument wouldn’t convince 
our hypothetical skeptic. The matter was finally laid to rest in 1999, when a grad-
uate student named Warwick Tucker proved that the Lorenz equations do, in fact, 
have a strange attractor (Tucker 1999, 2002). See Stewart (2000) and Viana (2000) 
for readable accounts of this milestone. 
Why does Tucker’s proof matter? Because it dispels any lingering concerns that 
our simulations are deceiving us. Those concerns are serious and justified. After 
all, how sure can we be of the trajectories we see in the computer, when any little 
error in numerical integration is bound to grow exponentially fast? Tucker’s theo-
rem reassures us that, despite these inevitable numerical errors, the strange attrac-
tor and the chaotic motion that we see on it are genuine properties of the Lorenz 
equations themselves.
9.5 Exploring Parameter Space
So far we have concentrated on the particular parameter values T  10, b  8
3 , 
r  28, as in Lorenz (1963). What happens if we change the parameters? It’s like a 
walk through the jungle—one can find exotic limit cycles tied in knots, pairs of 
limit cycles linked through each other, intermittent chaos, noisy periodicity, as 
well as strange attractors (Sparrow 1982, Jackson 1990). You should do some 
exploring on your own, perhaps starting with some of the exercises.
There is a vast three-dimensional parameter space to be explored, and much 
remains to be discovered. To simplify matters, many investigators have kept T  10 
and b  8
3  while varying r. In this section we give a glimpse of some of the phe-
nomena observed in numerical experiments. See Sparrow (1982) for the definitive 
treatment.
The behavior for small values of r is summarized in Figure 9.5.1.

338 
LORENZ EQUATIONS
x
unstable
limit cycle
stable
origin
stable fixed points
13.926
24.06
24.74=
1
transient chaos
strange attractor
r
C
C
,
+
−
rH
Figure 9.5.1
Much of this picture is familiar. The origin is globally stable for r  1. At r  1 the 
origin loses stability by a supercritical pitchfork bifurcation, and a symmetric pair 
of attracting fixed points is born (in our schematic, only one of the pair is shown). 
At rH  24.74 the fixed points lose stability by absorbing an unstable limit cycle in 
a subcritical Hopf bifurcation.
Now for the new results. As we decrease r from rH , the unstable limit cycles 
expand and pass precariously close to the saddle point at the origin. At r x 13.926 
the cycles touch the saddle point and become homoclinic orbits; hence we have a 
homoclinic bifurcation. (See Section 8.4 for the much simpler homoclinic bifurca-
tions that occur in two-dimensional systems.) Below r  13.926 there are no limit 
cycles. Viewed in the other direction, we could say that a pair of unstable limit 
cycles are created as r increases through r  13.926.
This homoclinic bifurcation has many ramifications for the dynamics, but its 
analysis is too advanced for us—see Sparrow’s (1982) discussion of “homoclinic 
explosions.” The main conclusion is that an amazingly complicated invariant set 
is born at r  13.926, along with the unstable limit cycles. This set is a thicket of 
infinitely many saddle-cycles and aperiodic orbits. It is not an attractor and is not 
observable directly, but it generates sensitive dependence on initial conditions in 
its neighborhood. Trajectories can get hung up near this set, somewhat like wan-
dering in a maze. Then they rattle around chaotically for a while, but eventually 
escape and settle down to C or C–. The time spent wandering near the set gets 
longer and longer as r increases. Finally, at r  24.06 the time spent wandering 
becomes infinite and the set becomes a strange attractor (Yorke and Yorke 1979).

339
9.5 EXPLORING PARAMETER SPACE
EXAMPLE 9.5.1:
Show numerically that the Lorenz equations can exhibit transient chaos when 
r  21 (with T  10 and b  8
3  as usual).
Solution: After experimenting with a few different initial conditions, it is easy to 
find solutions like that shown in Figure 9.5.2.
z
x
Figure 9.5.2
At first the trajectory seems to be tracing out a strange attractor, but eventually 
it stays on the right and spirals down toward the stable fixed point C. (Recall 
that both C and C– are still stable at r  21.) The time series of y vs. t shows the 
same result: an initially erratic solution ultimately damps down to equilibrium 
(Figure 9.5.3).

340 
LORENZ EQUATIONS
y
t
Figure 9.5.3
Other names used for transient chaos are metastable chaos (Kaplan and Yorke 
1979) or pre-turbulence (Yorke and Yorke 1979, Sparrow 1982). ■
By our definition, the dynamics in Example 9.5.1 are not “chaotic,” because the 
long-term behavior is not aperiodic. On the other hand, the dynamics do exhibit 
sensitive dependence on initial conditions—if we had chosen a slightly different 
initial condition, the trajectory could easily have ended up at C– instead of C. 
Thus the system’s behavior is unpredictable, at least for certain initial conditions.
Transient chaos shows that a deterministic system can be unpredictable, even 
if its final states are very simple. In particular, you don’t need strange attractors 
to generate effectively random behavior. Of course, this is familiar from everyday 
experience—many games of “chance” used in gambling are essentially demon-
strations of transient chaos. For instance, think about rolling dice. A crazily-roll-
ing die always stops in one of six stable equilibrium positions. The problem with 
predicting the outcome is that the final position depends sensitively on the initial 
orientation and velocity (assuming the initial velocity is large enough).
Before we leave the regime of small r, we note one other interesting implica-
tion of Figure 9.5.1: for 24.06  r  24.74, there are two types of attractors: fixed 
points and a strange attractor. This coexistence means that we can have hystere-
sis between chaos and equilibrium by varying r slowly back and forth past these 
two endpoints (Exercise 9.5.4). It also means that a large enough perturbation can 
knock a steadily rotating waterwheel into permanent chaos; this is reminiscent (in 
spirit, though not detail) of fluid flows that mysteriously become turbulent even 
though the basic laminar flow is still linearly stable (Drazin and Reid 1981).
The next example shows that the dynamics become simple again when r is suf-
ficiently large.

341
9.5 EXPLORING PARAMETER SPACE
EXAMPLE 9.5.2:
Describe the long-term dynamics for large values of r, for T    10, b  8
3.  
Interpret the results in terms of the motion of the waterwheel of Section 9.1.
Solution: Numerical simulations indicate that the system has a globally attract-
ing limit cycle for all r  313 (Sparrow 1982). In Figures 9.5.4 and 9.5.5 we plot a 
typical solution for r  350; note the approach to the limit cycle.
z
x
Figure 9.5.4
y
t
Figure 9.5.5

342 
LORENZ EQUATIONS
This solution predicts that the waterwheel should ultimately rock back and forth 
like a pendulum, turning once to the right, then back to the left, and so on. This is 
observed experimentally. ■
In the limit r l d one can obtain many analytical results about the Lorenz 
equations. For instance, Robbins (1979) used perturbation methods to character-
ize the limit cycle at large r. For the first steps in her calculation, see Exercise 9.5.5. 
For more details, see Chapter 7 in Sparrow (1982).
The story is much more complicated for r between 28 and 313. For most values 
of r one finds chaos, but there are also small windows of periodic behavior inter-
spersed. The three largest windows are 99.524. . .  r  100.795. . .; 145 r 166; 
and r  214.4. The alternating pattern of chaotic and periodic regimes resembles 
that seen in the logistic map (Chapter 10), and so we will defer further discussion 
until then.
9.6 Using Chaos to Send Secret Messages
One of the most exciting recent developments in nonlinear dynamics is the real-
ization that chaos can be useful. Normally one thinks of chaos as a fascinating 
curiosity at best, and a nuisance at worst, something to be avoided or engineered 
away. But since about 1990, people have found ways to exploit chaos to do some 
marvelous and practical things. For an introduction to this subject, see Vohra et 
al. (1992).
One application involves “private communications.” Suppose you want to send 
a secret message to a friend or business partner. Naturally you should use a code, 
so that even if an enemy is eavesdropping, he will have trouble making sense of the 
message. This is an old problem—people have been making (and breaking) codes 
for as long as there have been secrets worth keeping.
Kevin Cuomo and Alan Oppenheim (1992, 1993) implemented a new approach 
to this problem, building on Pecora and Carroll’s (1990) discovery of synchronized 
chaos. Here’s the strategy: When you transmit the message to your friend, you also 
“mask” it with much louder chaos. An outside listener only hears the chaos, which 
sounds like meaningless noise. But now suppose that your friend has a magic 
receiver that perfectly reproduces the chaos—then he can subtract off the chaotic 
mask and listen to the message!
Cuomo’s Demonstration
Kevin Cuomo was a student in my course on nonlinear dynamics, and at the 
end of the semester he treated our class to a live demonstration of his approach. 
First he showed us how to make the chaotic mask, using an electronic implemen-
tation of the Lorenz equations (Figure 9.6.1). The circuit involves resistors, capac-
itors, operational amplifiers, and analog multiplier chips.

343
9.6 USING CHAOS TO SEND SECRET MESSAGES
R
R
R
R
R
C
C
C
u
R
R
R
R
R
R
R
R
R
R
R
R
R
R
R
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
1
−
−
−
−
−
−
−
−
+
+
+
+
+
+
×
×
+
+
1
2
3
2
3
4
5
6
8
7
v
w
Figure 9.6.1 Cuomo and Oppenheim (1993), p. 66
The voltages u, v, w at three different points in the circuit are proportional to 
Lorenz’s x, y, z. Thus the circuit acts like an analog computer for the Lorenz equa-
tions. Oscilloscope traces of u ( t ) vs. w ( t ), for example, confirmed that the circuit 
was following the familiar Lorenz attractor. Then, by hooking up the circuit to 
a loudspeaker, Cuomo enabled us to hear the chaos—it sounds like static on the 
radio. 
The hard part is to make a receiver that can synchronize perfectly to the chaotic 
transmitter. In Cuomo’s set-up, the receiver is an identical Lorenz circuit, driven 
in a certain clever way by the transmitter. We’ll get into the details later, but for 
now let’s content ourselves with the experimental fact that synchronized chaos 
does occur. Figure 9.6.2 plots the receiver variables ur ( t ) and vr ( t ) against their 
transmitter counterparts u ( t ) and v ( t ).
3
0
0
3
3
u
u
v
r
r
(t)
v(t)
(t)
(t)
(a)
(b)
3
3
0
3
3
0
3
−−
−
−
Figure 9.6.2 Courtesy of Kevin Cuomo

344 
LORENZ EQUATIONS
The 45° trace on the oscilloscope indicates that the synchronization is nearly per-
fect, despite the fact that both circuits are running chaotically. The synchronization 
is also quite stable: the data in Figure 9.6.2 reflect a time span of several minutes, 
whereas without the drive the circuits would decorrelate in about 1 millisecond.
Cuomo brought the house down when he showed us how to use the circuits 
to mask a message, which he chose to be a recording of the hit song “Emotions” 
by Mariah Carey. (One student, apparently with different taste in music, asked 
“Is that the signal or the noise?”) After playing the original version of the song, 
Cuomo played the masked version. Listening to the hiss, one had absolutely no 
sense that there was a song buried underneath. Yet when this masked message was 
sent to the receiver, its output synchronized almost perfectly to the original chaos, 
and after instant electronic subtraction, we heard Mariah Carey again! The song 
sounded fuzzy, but easily understandable.
Figures 9.6.3 and 9.6.4 illustrate the system’s performance more quantitatively 
on a test sentence from a different source. Figure 9.6.3a is a segment of speech from 
the sentence “He has the bluest eyes,” obtained by sampling the speech waveform 
at a 48 kHz rate and with 16-bit resolution. This signal was then masked by much 
louder chaos. The power spectra in Figure 9.6.4 show that the chaos is about 20 
decibels louder than the message, with coverage over its whole frequency range. 
Finally, the unmasked message at the receiver is shown in Figure 9.6.3b. The orig-
inal speech is recovered with only a tiny amount of distortion (most visible as the 
increased noise on the flat parts of the record).
0.5
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
0
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
0
−0.5
0.5
(a)
TIME (sec)
0
−0.5
Figure 9.6.3 Cuomo and Oppenheim (1993), p. 67

345
9.6 USING CHAOS TO SEND SECRET MESSAGES
20
Chaotic Masking
Spectrum
Speech Spectrum
Frequency (kHz)
20
40
60
0
3
6
0
−
−
−
Figure 9.6.4 Cuomo and Oppenheim (1993), p. 68
Proof of Synchronization
The signal-masking method discussed above was made possible by the concep-
tual breakthrough of Pecora and Carroll (1990). Before their work, many people 
would have doubted that two chaotic systems could be made to synchronize. After 
all, chaotic systems are sensitive to slight changes in initial condition, so one might 
expect any errors between the transmitter and receiver to grow exponentially. 
But Pecora and Carroll (1990) found a way around these concerns. Cuomo and 
Oppenheim (1992, 1993) simplified and clarified the argument; we discuss their 
approach now.
The receiver circuit is shown in Figure 9.6.5.
R
R
R
R
R
C
C
C
u
u
drive signal
r
R
R
R
R
R
R
R
R
R
R
R
R
R
R
R
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
1
−
+
−
+
−
−
−
−
−
−
+
+
+
+
×
×
+
+
1
2
3
2
3
4
5
6
8
7
vr
wr
Figure 9.6.5 Courtesy of Kevin Cuomo

346 
LORENZ EQUATIONS
It is identical to the transmitter, except that the drive signal u ( t ) replaces the 
receiver signal ur ( t ) at a crucial place in the circuit (compare Figure 9.6.1). To see 
what effect this has on the dynamics, we write down the governing equations for 
both the transmitter and the receiver. Using Kirchhoff ’s laws and appropriate 
nondimensionalizations (Cuomo and Oppenheim 1992), we get



u
v
u
v
ru
v
uw
w
uv
bw
=
−
=
−−
=
−
T(
)
20
5
 
(1)
as the dynamics of the transmitter. These are just the Lorenz equations, written in 
terms of scaled variables
u
x
v
y
w
z



1
10
1
10
1
20
,
,
.
(This scaling is irrelevant mathematically, but it keeps the variables in a more 
favorable range for electronic implementation, if one unit is supposed to corre-
spond to one volt. Otherwise the wide dynamic range of the solutions exceeds typ-
ical power supply limits.)
The receiver variables evolve according to



u
v
u
v
ru t
v
u t w
w
u t v
bw
r
r
r
r
r
r
r
r
r
=
−
=
−
−
=
−
T(
)
( )
( )
( )
20
5
 
(2)
where we have written u ( t ) to emphasize that the receiver is driven by the chaotic 
signal u ( t ) coming from the transmitter.
The astonishing result is that the receiver asymptotically approaches perfect syn-
chrony with the transmitter, starting from any initial conditions! To be precise, let
d  ( u, v, w )  state of the transmitter or “driver” 
r  ( ur, vr, wr )  state of the receiver 
e  d – r  error signal
The claim is that e ( t ) l 0 as t l d, for all initial conditions.
Why is this astonishing? Because at each instant the receiver has only partial 
information about the state of the transmitter—it is driven solely by u ( t ), yet 
somehow it manages to reconstruct the other two transmitter variables v ( t ) and 
w ( t ) as well.
The proof is given in the following example.

347
9.6 USING CHAOS TO SEND SECRET MESSAGES
EXAMPLE 9.6.1:
By defining an appropriate Liapunov function, show that e ( t ) l 0 as t l d. 
Solution: First we write the equations governing the error dynamics. Subtracting 
(2) from (1) yields



e
e
e
e
e
u t e
e
u t e
be
1
2
1
2
2
3
3
2
3
20
5
=
−
= −
−
=
−
T(
)
( )
( )
This is a linear system for e ( t ), but it has a chaotic time-dependent coefficient u ( t ) 
in two terms. The idea is to construct a Liapunov function in such a way that the 
chaos cancels out. Here’s how: Multiply the second equation by e2 and the third by 
4e3 and add. Then
e e
e e
e
u t e e
u t e e
be
e
be
2
2
3 3
2
3
2
3
2
4
2
2
4


+
= −
−
+
−
= −
−
2
2
3
2
2
3
2
0
0
4
( )
( )
 
(3)
and so the chaotic term disappears!
The left-hand side of (3) is 1
2
2
2
3
2
4
d
dt e
e
+
(
). This suggests the form of a Liapunov 
function. As in Cuomo and Oppenheim (1992), we define the function
E
t
e
e
e
( , )
(
).
e
=
+
+
1
2
1
1
T
2
2
2
3
2
4
E is certainly positive definite, since it is a sum of squares (as always, we assume 
T  0). To show E is a Liapunov function, we must show it decreases along trajec-
tories. We’ve already computed the time-derivative of the second two terms, so 
concentrate on the first term, shown in brackets below:




E
e e
e e
e e
e
e e
e
be
= ⎡⎣
⎤⎦+
+
= −
−
⎡⎣⎢
⎤⎦⎥−
−
1
1 1
2
2
3 3
1
2
1 2
2
2
3
2
4
4
T
.
Now complete the square for the term in brackets:
E
e
e
e
e
be
e
e
e
be
= −
−
⎡⎣
⎤⎦+(
) −
−
= −
−
⎡⎣
⎤⎦−
−
1
1
2
2
2
1
2
2
2
2
2
3
2
1
1
2
2
2
3
4
2
2
4
4
3
2.
Hence E b 0 , with equality only if e  0. Therefore E is a Liapunov function, and 
so e  0 is globally asymptotically stable. ■
A stronger result is possible: one can show that e( t ) decays exponentially fast 
(Cuomo, Oppenheim, and Strogatz 1993; see Exercise 9.6.1). This is important, 
because rapid synchronization is necessary for the desired application.

348 
LORENZ EQUATIONS
We should be clear about what we have and haven’t proven. Example 9.6.1 
shows only that the receiver will synchronize to the transmitter if the drive signal 
is u ( t ). This does not prove that the signal-masking approach will work. For that 
application, the drive is a mixture u ( t )  m ( t ) where m ( t ) is the message and 
u ( t )  m ( t ) is the mask. We have no proof that the receiver will regenerate u ( t ) 
precisely. In fact, it doesn’t—that’s why Mariah Carey sounded a little fuzzy. So it’s 
still something of a mathematical mystery as to why the approach works as well as 
it does. But the proof is in the listening!
In the years since the work of Pecora and Carroll (1990) and Cuomo and 
Oppenheim (1992), many other researchers have looked at the pros and cons of 
using synchronized chaos for communications. Some of the most intriguing devel-
opments include communication schemes based on synchronized chaotic lasers, 
which allow much faster transmission rates than electronic circuits (Van Wiggeren 
and Roy 1998, Argyris et al. 2005), and countermeasures for decrypting messages 
cloaked in chaos (Short 1994, Short 1996, Geddes et al. 1999).
EXERCISES FOR CHAPTER 9
9.1 A Chaotic Waterwheel
9.1.1 
(Waterwheel’s moment of inertia approaches a constant) For the water-
wheel of Section 9.1, show that I ( t ) l constant as t l d, as follows:
a) The total moment of inertia is a sum I  Iwheel  Iwater, where Iwheel depends only 
on the apparatus itself, and not on the distribution of water around the rim. 
Express Iwater in terms of M
m
t d
= ∫
( , )
.
θ
θ
π
0
2
b) Show that M satisfies 
M
Q
KM
=
−
total
, where Q
Q
d
total = ∫
( )
.
θ
θ
π
0
2
c) Show that I ( t ) l constant as t l d, and find the value of the constant.
9.1.2 
(Behavior of higher modes) In the text, we showed that three of the 
waterwheel equations decoupled from all the rest. How do the remaining modes 
behave?
a) If Q ( R )  q1 cosR, the answer is simple: show that for n v1, all modes an, bn l 0 
as t l d.
b) What do you think happens for a more general Q
q
n
n
n
( )
cos
R
R
=
=
∞
∑
0
?
Part (b) is challenging; see how far you can get. For the state of current knowl-
edge, see Kolar and Gumbs (1992).
9.1.3 
(Deriving the Lorenz equations from the waterwheel) Find a change of 
variables that converts the waterwheel equations

349
EXERCISES



a
b
Ka
b
a
q
Kb
v
I
gr
I
a
1
1
1
1
1
1
1
1
=
−
= −
+
−
= −
+
ω
ω
ω
ω
π
into the Lorenz equations



x
y
x
y
rx
xz
y
z
xy
bz
=
−
=
−
−
=
−
T(
)
where T, b, r  0 are parameters. (This can turn into a messy calculation—it helps 
to be thoughtful and systematic. You should find that x is like X, y is like a1, and z 
is like b1.) Also, show that when the waterwheel equations are translated into the 
Lorenz equations, the Lorenz parameter b turns out to be b  1. (So the water-
wheel equations are not quite as general as the Lorenz equations.) Express the 
Prandtl and Rayleigh numbers T and r in terms of the waterwheel parameters.
9.1.4 
(Laser model) As mentioned in Exercise 3.3.2, the Maxwell-Bloch equa-
tions for a laser are



E
P
E
P
ED
p
D
D
EP
=
−
=
−
=
+ −
−
κ
γ
γ λ
λ
(
)
(
)
(
).
1
2
1
a) Show that the non-lasing state (the fixed point with E*  0) loses stability above 
a threshold value of M, to be determined. Classify the bifurcation at this laser 
threshold.
b) Find a change of variables that transforms the system into the Lorenz system. 
The Lorenz equations also arise in models of geomagnetic dynamos (Robbins 
1977) and thermoconvection in a circular tube (Malkus 1972). See Jackson (1990, 
vol. 2, Sections 7.5 and 7.6) for an introduction to these systems.
9.1.5 
(Research project on asymmetric waterwheel) Our derivation of the 
waterwheel equations assumed that the water is pumped in symmetrically at 
the top. Investigate the asymmetric case. Modify Q ( R ) in (9.1.5) appropriately. 
Show that a closed set of three equations is still obtained, but that (9.1.9) includes 
a new term. Redo as much of the analysis in this chapter as possible. You should 
be able to solve for the fixed points and show that the pitchfork bifurcation is 
replaced by an imperfect bifurcation (Section 3.6). After that, you’re on your own! 
This problem has not yet been addressed in the literature.

350 
LORENZ EQUATIONS
9.2 Simple Properties of the Lorenz Equations
9.2.1 
(Parameter where Hopf bifurcation occurs)
a) For the Lorenz equations, show that the characteristic equation for the eigen-
values of the Jacobian matrix at C, C– is
λ
σ
λ
σ
λ
σ
3
2
1
1
+
+ +
+
+
+
−
=
(
)
(
)
(
)
.
b
r
b
b
r
2
0
b) By seeking solutions of the form M  iX, where X is real, show that there is a pair 
of pure imaginary eigenvalues when r
r
b
b
H
=
=
+ +
−−
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
T T
T
3
1 .  Explain why we 
need to assume T  b  1. 
c) Find the third eigenvalue.
9.2.2 
(An ellipsoidal trapping region for the Lorenz equations) Show that there 
is a certain ellipsoidal region E of the form rx 2  Ty 2  T ( z – 2r )2 b C such that 
all trajectories of the Lorenz equations eventually enter E and stay in there forever. 
For a much stiffer challenge, try to obtain the smallest possible value of C with this 
property.
9.2.3 
(A spherical trapping region) Show that all trajectories eventually enter 
and remain inside a large sphere S of the form x 2  y 2  ( z – r – T )2  C, for C suf-
ficiently large. (Hint: Show that x 2  y 2 ( z – r – T )2 decreases along trajectories 
for all ( x,y,z ) outside a certain fixed ellipsoid. Then pick C large enough so that the 
sphere S encloses this ellipsoid.)
9.2.4 
(z-axis is invariant) Show that the z-axis is an invariant line for the Lorenz 
equations. In other words, a trajectory that starts on the z-axis stays on it forever.
9.2.5 
(Stability diagram) Using the analytical results obtained about bifur-
cations in the Lorenz equations, give a partial sketch of the stability diagram. 
Specifically, assume b  1 as in the waterwheel, and then plot the pitchfork and 
Hopf bifurcation curves in the ( T, r ) parameter plane. As always, assume T, r p 0. 
(For a numerical computation of the stability diagram, including chaotic regions, 
see Kolar and Gumbs (1992).)
9.2.6 
(Rikitake model of geomagnetic reversals) Consider the system



x
vx
zy
y
vy
z
a x
z
xy
= −
+
= −
+
−
= −
(
)
1
where a, v  0 are parameters.
a) Show that the system is dissipative.
b) Show that the fixed points may be written in parametric form as x*  ok, 
y*  ok–1, z*  vk2, where v ( k2 –k–2 )  a.
c) Classify the fixed points.

351
EXERCISES
These equations were proposed by Rikitake (1958) as a model for the self-gen-
eration of the Earth’s magnetic field by large current-carrying eddies in the core. 
Computer experiments show that the model exhibits chaotic solutions for some 
parameter values. These solutions are loosely analogous to the irregular reversals 
of the Earth’s magnetic field inferred from geological data. See Cox (1982) for the 
geophysical background.
9.3 Chaos on a Strange Attractor
9.3.1 
(Quasiperiodicity v chaos) The trajectories of the quasiperiodic system 
θ
ω
1 
1, θ
ω
2 
2,  ( X / X irrational) are not periodic.
a) Why isn’t this system considered chaotic?
b) Without using a computer, find the largest Liapunov exponent for the system.
(Numerical experiments) For each of the values of r given below, use a computer to 
explore the dynamics of the Lorenz system, assuming T  10 and b  8 / 3 as usual. 
In each case, plot x ( t ), y ( t ), and x vs. z. You should investigate the consequences 
of choosing different initial conditions and lengths of integration. Also, in some 
cases you may want to ignore the transient behavior, and plot only the sustained 
long-term behavior.
9.3.2 
r  10 
 
 
 
9.3.3 
r  22 (transient chaos)
9.3.4 
r  24.5  
 
 
9.3.5 
r  100 (surprise)
 
(chaos and stable point co-exist)
9.3.6 
r  126.52 
 
 
9.3.7 
r  400
9.3.8 
(Practice with the definition of an attractor) Consider the following famil-
iar system in polar coordinates: r
r
r
=
−
(
),
l
2
 R 1. Let D be the disk x 2  y 2 b 1.
a) Is D an invariant set?
b) Does D attract an open set of initial conditions?
c) Is D an attractor? If not, why not? If so, find its basin of attraction.
d) Repeat part (c) for the circle x 2  y 2  1.
9.3.9 
(Exponential divergence) Using numerical integration of two nearby tra-
jectories, estimate the largest Liapunov exponent for the Lorenz system, assuming 
that the parameters have their standard values r  28, T  10, b  8 / 3.
9.3.10 
(Time horizon) To illustrate the “time horizon” after which prediction 
becomes impossible, numerically integrate the Lorenz equations for r    28, 
T  10, b  8 / 3. Start two trajectories from nearby initial conditions, and plot x ( t ) 
for both of them on the same graph.
9.4 Lorenz Map
9.4.1 
(Computer work) Using numerical integration, compute the Lorenz map 
for r  28, T  10, b  8 3.

352 
LORENZ EQUATIONS
9.4.2 
(Tent map, as model of Lorenz map) Consider the map
x
x
x
x
x
n
n
n
n
n
+ =
≤
≤
−
≤
≤
⎧
⎨
⎪⎪
⎩⎪⎪
1
1
2
1
2
2
0
2
2
1
,
,
as a simple analytical model of the Lorenz map.
a) Why is it called the “tent map”?
b) Find all the fixed points, and classify their stability.
c) Show that the map has a period-2 orbit. Is it stable or unstable?
d) Can you find any period-3 points? How about period-4? If so, are the corre-
sponding periodic orbits stable or unstable?
9.5 Exploring Parameter Space
(Numerical experiments) For each of the values of r given below, use a computer 
to explore the dynamics of the Lorenz system, assuming T  10 and b  8 3 as 
usual. In each case, plot x ( t ), y ( t ), and x vs. z.
9.5.1 
r  166.3 (intermittent chaos)
9.5.2 
r  212 (noisy periodicity)
9.5.3 
the interval 145  r  166 (period-doubling)
9.5.4 
(Hysteresis between a fixed point and a strange attractor) Consider the 
Lorenz equations with T  10 and b  8 / 3. Suppose that we slowly “turn the r 
knob” up and down. Specifically, let r  24.4  sin Xt, where X is small compared 
to typical orbital frequencies on the attractor. Numerically integrate the equa-
tions, and plot the solutions in whatever way seems most revealing. You should see 
a striking hysteresis effect between an equilibrium and a chaotic state.
9.5.5 
(Lorenz equations for large r ) Consider the Lorenz equations in the limit 
r l d. By taking the limit in a certain way, all the dissipative terms in the equa-
tions can be removed (Robbins 1979, Sparrow 1982).
a) Let F  r –1 / 2, so that r l d corresponds to F l 0. Find a change of variables 
involving F such that as F l 0, the equations become
Xa  Y
Ya  –XZ
Za  XY.
b) Find two conserved quantities (i.e., constants of the motion) for the new system.
c) Show that the new system is volume-preserving (i.e., the volume of an arbitrary 
blob of “phase fluid” is conserved by the time-evolution of the system, even 
though the shape of the blob may change dramatically.)
d) Explain physically why the Lorenz equations might be expected to show some 
conservative features in the limit r l d.

353
EXERCISES
e) Solve the system in part (a) numerically. What is the long-term behavior? Does 
it agree with the behavior seen in the Lorenz equations for large r?
9.5.6 
(Transient chaos) Example 9.5.1 shows that the Lorenz system can exhibit 
transient chaos for r  21, T  10, b  8
3. However, not all trajectories behave this 
way. Using numerical integration, find three different initial conditions for which 
there is transient chaos, and three others for which there isn’t. Give a rule of thumb 
which predicts whether an initial condition will lead to transient chaos or not.
9.6 Using Chaos to Send Secret Messages
9.6.1 
(Exponentially fast synchronization) The Liapunov function of Example 9.6.1 
shows that the synchronization error e( t ) tends to zero as t l d, but it does not 
provide information about the rate of convergence. Sharpen the argument to show 
that the synchronization error e ( t ) decays exponentially fast.
a) Prove that V
e
e
=
+
1
2
2
2
3
2
2
 decays exponentially fast, by showing V
kV
≤−
,  
for some constant k  0 to be determined.
b) Show that part (a) implies that e2 ( t ), e3 ( t ) l 0 exponentially fast.
c) Finally show that e1 ( t ) l 0 exponentially fast.
9.6.2 
(Pecora and Carroll’s approach) In the pioneering work of Pecora and 
Carroll (1990), one of the receiver variables is simply set equal to the corresponding 
transmitter variable. For instance, if x ( t ) is used as the transmitter drive signal, 
then the receiver equations are
x ( t )  x ( t )
y
rx t
y
x t z
r
r
r
=
−
−
( )
( )
z
x t y
bz
r
r
r
=
−
( )
where the first equation is not a differential equation. Their numerical simulations 
and a heuristic argument suggested that yr ( t ) l y ( t ) and zr ( t ) l z ( t ) as t ld, 
even if there were differences in the initial conditions.
Here is a simple proof of that result, due to He and Vaidya (1992).
a) Show that the error dynamics are
e
e
e
x t e
e
x t e
be
1
2
2
3
3
2
3
0
≡
= −
−
=
−


( )
( )
where e1  x – xr, e2  y – yr, and e
z
zr
3 =
−
.
b) Show that V
e
e
=
+
2
2
3
2  is a Liapunov function.
c) What do you conclude?

354 
LORENZ EQUATIONS
9.6.3 
(Computer experiments on synchronized chaos) Let x, y, z be governed 
by the Lorenz equations with r  60, T  10, b  8 / 3. Let xr , yr , zr be governed by 
the system in Exercise 9.6.2. Choose different initial conditions for y and yr, and 
similarly for z and zr , and then start integrating numerically.
a) Plot y ( t ) and yr ( t ) on the same graph. With any luck, the two time series should 
eventually merge, even though both are chaotic.
b) Plot the ( y,z ) projection of both trajectories.
9.6.4 
(Some drives don’t work) Suppose z ( t ) were the drive signal in Exercise 9.6.2, 
instead of x ( t ). In other words, we replace zr by z ( t ) everywhere in the receiver 
equations, and watch how xr and yr evolve.
a) Show numerically that the receiver does not synchronize in this case.
b) What if y ( t ) were the drive?
9.6.5 
(Masking) In their signal-masking approach, Cuomo and Oppenheim 
(1992, 1993) use the following receiver dynamics:



x
y
x
y
rs t
y
s t z
z
s t y
bz
r
r
r
r
r
r
r
r
r
=
−
=
−
−
=
−
T(
)
( )
( )
( )
where s ( t )  x ( t )  m ( t ), and m ( t ) is the low-power message added to the much 
stronger chaotic mask x ( t ). If the receiver has synchronized with the drive, then 
xr ( t ) x x ( t ) and so m ( t ) may be recovered as ˆ ( )
( )
( ).
m t
s t
x t
r
=
−
 Test this 
approach numerically, using a sine wave for m ( t ). How close is the estimate ˆ ( )
m t  
to the actual message m ( t )? How does the error depend on the frequency of the 
sine wave?
9.6.6 
(Lorenz circuit) Derive the circuit equations for the transmitter circuit 
shown in Figures 9.6.1.

355
10.0 INTRODUCTION
10
ONE-DIMENSIONAL MAPS
10.0 Introduction
This chapter deals with a new class of dynamical systems in which time is discrete, 
rather than continuous. These systems are known variously as difference equa-
tions, recursion relations, iterated maps, or simply maps.
For instance, suppose you repeatedly press the cosine button on your cal-
culator, starting from some number x0. Then the successive readouts are 
x1 cos x0, x2 cos x1, and so on. Set your calculator to radian mode and try 
it. Can you explain the surprising result that emerges after many iterations?
The rule xnl cos xn is an example of a one-dimensional map, so-called because 
the points xn belong to the one-dimensional space of real numbers. The sequence 
x0, x1, x2, . . . is called the orbit starting from x0.
Maps arise in various ways:
1. As tools for analyzing differential equations. We have already encoun-
tered maps in this role. For instance, Poincaré maps allowed us to 
prove the existence of a periodic solution for the driven pendulum and 
Josephson junction (Section 8.5), and to analyze the stability of peri-
odic solutions in general (Section 8.7). The Lorenz map (Section 9.4) 
provided strong evidence that the Lorenz attractor is truly strange, 
and is not just a long-period limit cycle.
2. As models of natural phenomena. In some scientific contexts it is natu-
ral to regard time as discrete. This is the case in digital electronics, in 
parts of economics and finance theory, in impulsively driven mechani-
cal systems, and in the study of certain animal populations where suc-
cessive generations do not overlap.
3. As simple examples of chaos. Maps are interesting to study in their own 
right, as mathematical laboratories for chaos. Indeed, maps are capable 

356 
ONE-DIMENSIONAL MAPS
of much wilder behavior than differential equations because the points 
xn hop along their orbits rather than flow continuously (Figure 10.0.1).
x
x
x
0
2
1
Figure 10.0.1
The study of maps is still in its infancy, but exciting progress has been made 
in the last few decades, thanks to the growing availability of calculators, then 
computers, and now computer graphics. Maps are easy and fast to simulate on 
digital computers where time is inherently discrete. Such computer experiments 
have revealed a number of unexpected and beautiful patterns, which in turn have 
stimulated new theoretical developments. Most surprisingly, maps have generated 
a number of successful predictions about the routes to chaos in semiconductors, 
convecting fluids, heart cells, lasers, and chemical oscillators.
We discuss some of the properties of maps and the techniques for analyzing 
them in Sections 10.1–10.5. The emphasis is on period-doubling and chaos in the 
logistic map. Section 10.6 introduces the amazing idea of universality, and summa-
rizes experimental tests of the theory. Section 10.7 is an attempt to convey the basic 
ideas of Feigenbaum’s renormalization technique.
As usual, our approach will be intuitive. For rigorous treatments of 
one-dimensional maps, see Devaney (1989) and Collet and Eckmann (1980).
10.1 Fixed Points and Cobwebs
In this section we develop some tools for analyzing one-dimensional maps of the 
form xnl f  ( xn ) , where  f  is a smooth function from the real line to itself.
A Pedantic Point
When we say “map,” do we mean the function  f  or the difference equation 
xn1 f  ( xn ) ? Following common usage, we’ll call both of them maps. If you’re 
disturbed by this, you must be a pure mathematician . . . or should consider 
becoming one!
Fixed Points and Linear Stability
Suppose x * satisfies  f  ( x * )  x *. Then x * is a fixed point, for if xn x * then 
xn 1 f  ( xn )  f  ( x * )   x  * ; hence the orbit remains at x * for all future iterations.
To determine the stability of x *, we consider a nearby orbit xn x *In and 
ask whether the orbit is attracted to or repelled from x *. That is, does the deviation 
In grow or decay as n increases? Substitution yields

357
10.1 FIXED POINTS AND COBWEBS
x
x
f x
f x
f x
O
n
n
n
n
n
*
( *
)
( *)
( *)
(
).
+
=
=
+
=
+
+
+
+
I
I
I
I
1
1
2
′
But since  f  ( x * )  x *, this equation reduces to
I
I
I
n
n
n
f
x
O
+ =
+
1
2
′( *)
(
).
Suppose we can safely neglect the O ( In
2 )  terms. Then we obtain the linearized map 
I
I
n
n
f
x
+ =
1
′( *)
 with eigenvalue or multiplier M 
a
f
x
( *) . The solution of this lin-
ear map can be found explicitly by writing a few terms: I1 MI0, I2 MI1 M2I0, 
and so in general In MnI0. If |  M| |
a
f
x
( *) |1, then In l 0 as n l d and the 
fixed point x * is linearly stable. Conversely, if |
a
f
x
( *) | 1 the fixed point is unsta-
ble. Although these conclusions about local stability are based on linearization, 
they can be proven to hold for the original nonlinear map. But the linearization 
tells us nothing about the marginal case |
a
f
x
( *) | 1; then the neglected O ( In
2 ) 
terms determine the local stability. (All of these results have parallels for differen-
tial equations—recall Section 2.4.)
EXAMPLE 10.1.1:
Find the fixed points for the map xn1 xn
2 and determine their stability.
Solution: The fixed points satisfy x *  ( x * ) 2. Hence x * 0 or x * 1. The 
multiplier is M 
a
f
x
( *) 2x *. The fixed point x * 0 is stable since |  M | 0 1, 
and x * 1 is unstable since | M| 2 1. ■
Try Example 10.1.1 on a hand calculator by pressing the x2 button over and over. 
You’ll see that for sufficiently small x0, the convergence to x * 0 is extremely 
rapid. Fixed points with multiplier M 0 are called superstable because perturba-
tions decay like I
I
n
n
~
(
)
0
2 , which is much faster than the usual η
λ η
n
n
~
0  at an 
ordinary stable point.
Cobwebs
In Section  8.7 we introduced the cobweb construction for iterating a map 
(Figure 10.1.1).

358 
ONE-DIMENSIONAL MAPS
x
x
x
x
x
0
1
2
x
f
=
=
(
)
n
n
xn+1
n
x
x
n
n
+1
2
1
Figure 10.1.1
Given xnl f  ( xn )  and an initial condition x0, draw a vertical line until it inter-
sects the graph of  f  ; that height is the output x1. At this stage we could return to 
the horizontal axis and repeat the procedure to get x2 from x1, but it is more con-
venient simply to trace a horizontal line till it intersects the diagonal line xnl xn, 
and then move vertically to the curve again. Repeat the process n times to generate 
the first n points in the orbit.
Cobwebs are useful because they allow us to see global behavior at a glance, 
thereby supplementing the local information available from the linearization. 
Cobwebs become even more valuable when linear analysis fails, as in the next 
example.
EXAMPLE 10.1.2:
Consider the map xnl sinxn. Show that the stability of the fixed point x *  0 
is not determined by the linearization. Then use a cobweb to show that x * 0 is 
stable—in fact, globally stable.
Solution: The multiplier at x * 0 is  f a ( 0 )  cos ( 0 )  1, which is a marginal 
case where linear analysis is inconclusive. However, the cobweb of Figure 10.1.2 
shows that x * 0 is locally stable; the orbit slowly rattles down the narrow chan-
nel, and heads monotonically for the fixed point. (A similar picture is obtained for  
x0 0. ) 
To see that the stability is global, we have to show that all orbits satisfy xn l 0. 
But for any x0, the first iterate is sent immediately to the interval 1 bx1 b1 since 
| sinx |  b1. The cobweb in that interval looks qualitatively like Figure 10.1.2, so 
convergence is assured. ■

359
10.1 FIXED POINTS AND COBWEBS
n
x +1
n
x
x
x
n
n
+1 =sin
Figure 10.1.2
Finally, let’s answer the riddle posed in Section 10.0.
EXAMPLE 10.1.3:
Given xn1 cos xn, how does xn behave as n l d?
Solution: If you tried this on your calculator, you found that xn l0.739. . . , 
no matter where you started. What is this bizarre number? It’s the unique solu-
tion of the transcendental equation x cos x, and it corresponds to a fixed point 
of the map. Figure 10.1.3 shows that a typical orbit spirals into the fixed point 
x * 0.739 . . . as n ld. ■
n
n
x
x
x*
+1
n
n
x +1 = cos x
Figure 10.1.3
The spiraling motion implies that xn converges to x * through damped oscillations. 
That is characteristic of fixed points with M 0. In contrast, at stable fixed points 
with M 0 the convergence is monotonic.

360 
ONE-DIMENSIONAL MAPS
10.2 Logistic Map: Numerics
In a fascinating and influential review article, Robert May (1976) emphasized that 
even simple nonlinear maps could have very complicated dynamics. The article 
ends memorably with “an evangelical plea for the introduction of these difference 
equations into elementary mathematics courses, so that students’ intuition may be 
enriched by seeing the wild things that simple nonlinear equations can do.” 
May illustrated his point with the logistic map
x
rx
x
n
n
n
+ =
−
1
1(
) , 
(1)
a discrete-time analog of the logistic equation for population growth (Section 2.3). 
Here xn p 0 is a dimensionless measure of the population in the nth generation and 
r p 0 is the intrinsic growth rate. As shown in Figure 10.2.1, the graph of (1) is a 
parabola with a maximum value of r / 4 at x  1
2  . We restrict the control parame-
ter r to the range 0 br b4 so that (1) maps the interval 0 bx b1 into itself. (The 
behavior is much less interesting for other values of x and r—see Exercise 10.2.1.)
n
x
r
4
1
0
1
n
x
+1
Figure 10.2.1
Period-Doubling
Suppose we fix r, choose some initial population x0, and then use (1) to generate 
the subsequent xn. What happens?
For small growth rate r 1, the population always goes extinct: xn l0 as 
n ld. This gloomy result can be proven by cobwebbing (Exercise 10.2.2).
For 1 r3 the population grows and eventually reaches a nonzero steady 
state (Figure 10.2.2). The results are plotted here as a time series of xn vs. n. To 
make the sequence clearer, we have connected the discrete points  ( n, xn )  by line 
segments, but remember that only the corners of the jagged curves are meaningful.

361
10.2 LOGISTIC MAP: NUMERICS
1.0
2.8
0.5
10
20
30
40
50
r
xn
n
=
Figure 10.2.2
For larger r, say r 3.3, the population builds up again but now oscillates about the 
former steady state, alternating between a large population in one generation and 
a smaller population in the next (Figure 10.2.3). This type of oscillation, in which 
xn repeats every two iterations, is called a period-2 cycle.
1.0
3.3
0.5
10
20
30
40
50
r
xn
n
=
Figure 10.2.3
At still larger r, say r 3.5, the population approaches a cycle that now repeats 
every four generations; the previous cycle has doubled its period to period-4 
(Figure 10.2.4).
1.0
3.5
0.5
10
20
30
40
50
r
xn
n
=
Figure 10.2.4

362 
ONE-DIMENSIONAL MAPS
Further period-doublings to cycles of period 8, 16, 32, . . . , occur as r increases. 
Specifically, let rn denote the value of r where a 2n-cycle first appears. Then com-
puter experiments reveal that
r1 3 
(period 2 is born)
r2 3.449 . . .  
4
r3 3.54409 . . .  
8
r4 3.5644 . . .  
16
r5 3.568759 . . . 
32
#  
#
rd 3.569946 . . . 
d
Note that the successive bifurcations come faster and faster. Ultimately the rn con-
verge to a limiting value rd. The convergence is essentially geometric: in the limit 
of large n, the distance between successive transitions shrinks by a constant factor
E =
−
−
=
−
+
→∞
lim
.
.
r
r
r
r
n
n
n
n
n
1
1
4 669  . . .
We’ll have a lot more to say about this number in Section 10.6.
Chaos and Periodic Windows
According to Gleick (1987, p. 69), May wrote the logistic map on a corridor 
blackboard as a problem for his graduate students and asked, “What the Christ 
happens for r rd?” The answer turns out to be complicated: For many values of 
r, the sequence {xn} never settles down to a fixed point or a periodic orbit—instead 
the long-term behavior is aperiodic, as in Figure 10.2.5. This is a discrete-time 
version of the chaos we encountered earlier in our study of the Lorenz equations 
(Chapter 9).
1.0
3.9
0.5
10
20
30
40
50
r
xn
n
=
Figure 10.2.5
The corresponding cobweb diagram is impressively complex (Figure 10.2.6).

363
10.2 LOGISTIC MAP: NUMERICS
3.9
r
x
x
1
+
n
n
=
Figure 10.2.6
You might guess that the system would become more and more chaotic as r 
increases, but in fact the dynamics are more subtle than that. To see the long-term 
behavior for all values of r at once, we plot the orbit diagram, a magnificent picture 
that has become an icon of nonlinear dynamics (Figure 10.2.7). Figure 10.2.7 plots 
the system’s attractor as a function of r. To generate the orbit diagram for yourself, 
you’ll need to write a computer program with two “loops.” First, choose a value of 
r. Then generate an orbit starting from some random initial condition x0. Iterate 
for 300 cycles or so, to allow the system to settle down to its eventual behavior. 
Once the transients have decayed, plot many points, say x301, . . . , x600 above that 
r. Then move to an adjacent value of r and repeat, eventually sweeping across the 
whole picture.
Figure 10.2.7 shows the most interesting part of the diagram, in the region 
3.4 br b4. At r 3.4, the attractor is a period-2 cycle, as indicated by the two 
branches. As r increases, both branches split simultaneously, yielding a period-4 
cycle. This splitting is the period-doubling bifurcation mentioned earlier. A cascade 
of further period-doublings occurs as r increases, yielding period-8, period-16, and 
so on, until at r rd x 3.57, the map becomes chaotic and the attractor changes 
from a finite to an infinite set of points.
For r rd the orbit diagram reveals an unexpected mixture of order and chaos, 
with periodic windows interspersed between chaotic clouds of dots. The large win-
dow beginning near r x 3.83 contains a stable period-3 cycle. A blow-up of part of 
the period-3 window is shown in the lower panel of Figure 10.2.7. Fantastically, a 
copy of the orbit diagram reappears in miniature!

364 
ONE-DIMENSIONAL MAPS
1.0
0.0
0.18
0.13
3.847
3.857
3.85
3.4
3.7
4.0
r
x
x
r
Figure 10.2.7 Campbell  ( 1979 ) , p. 35, courtesy of Roger Eckhardt
10.3 Logistic Map: Analysis
The numerical results of the last section raise many tantalizing questions. Let’s try 
to answer a few of the more straightforward ones.
EXAMPLE 10.3.1:
Consider the logistic map xnl rxn ( 1  xn )  for 0 bxn b1 and 0 br b4. Find 
all the fixed points and determine their stability.
Solution: The fixed points satisfy x * f  ( x * )  rx *  ( 1  x * ) . Hence x * 0 or 
l r  ( l  x * ) , i.e., x
r
* = −
1
1 . The origin is a fixed point for all r, whereas x
r
* = −
1
1  
is in the range of allowable x only if r p 1.
Stability depends on the multiplier f a ( x * )  r  2rx *. Since f a ( 0 )  r, the 
origin is stable for r l and unstable for r 1. At the other fixed point, 

365
10.3 LOGISTIC MAP: ANALYSIS
f
x
r
r
r
r
′( *)
(
)
.
= −
−
=
−
2 1
2
1
 Hence x
r
* = −
1
1  is stable for 1  ( 2  r )  1, i.e., 
for 1 r 3. It is unstable for r 3. ■
The results of Example 10.3.1 are clarified by a graphical analysis (Figure 10.3.1). 
For r 1 the parabola lies below the diagonal, and the origin is the only fixed 
point. As r increases, the parabola gets taller, becoming tangent to the diagonal at 
r 1. For r 1 the parabola intersects the diagonal in a second fixed point 
x
r
* = −
1
1 , while the origin loses stability. Thus we see that x* bifurcates from the 
origin in a transcritical bifurcation at r 1 (borrowing a term used earlier for dif-
ferential equations).
1
*
1
1
>
r
r
r
x
x
x
+1
n
n
=
<
Figure 10.3.1
Figure 10.3.1 also suggests how x * itself loses stability. As r increases beyond 1, 
the slope at x * gets increasingly steep. Example 10.3.1 shows that the critical slope 
a
f
x
( *)1 is attained when r 3. The resulting bifurcation is called a flip 
bifurcation.
Flip bifurcations are often associated with period-doubling. In the logistic map, 
the flip bifurcation at r 3 does indeed spawn a 2-cycle, as shown in the next 
example.
EXAMPLE 10.3.2:
Show that the logistic map has a 2-cycle for all r 3.
Solution: A 2-cycle exists if and only if there are two points p and q such 
that  f  ( p )  q and  f  ( q )  p. Equivalently, such a p must satisfy  f  ( f  ( p ) )  p, 
where  f  ( x )  rx ( 1  x ) . Hence p is a fixed point of the second-iterate map 

366 
ONE-DIMENSIONAL MAPS
f 2  ( x )  wf  ( f  ( x ) ) . Since  f  ( x )  is a quadratic polynomial, f 2 ( x )  is a quartic poly-
nomial. Its graph for r 3 is shown in Figure 10.3.2.
f
p
q
x
x*
x
(   )
2
Figure 10.3.2
To find p and q, we need to solve for the points where the graph intersects the diag-
onal, i.e., we need to solve the fourth-degree equation f 2 ( x )  x. That sounds 
hard until you realize that the fixed points x * 0 and x
r
* = −
1
1  are trivial solu-
tions of this equation. (They satisfy  f  ( x * )  x *, so f 2 ( x * )  x * automatically.) 
After factoring out the fixed points, the problem reduces to solving a quadratic 
equation.
We outline the algebra involved in the rest of the solution. Expansion of the 
equation f 2 ( x )   x 0 gives r2x ( 1  x ) [1  rx ( 1  x ) ]  x 0. After factoring 
out x and x
r


(
)
1
1  by long division, and solving the resulting quadratic equa-
tion, we obtain a pair of roots
p q
r
r
r
r
,
(
)(
) ,
=
+ ±
−
+
1
3
1
2
which are real for r 3. Thus a 2-cycle exists for all r 3, as claimed. At r 3, the 
roots coincide and equal x
r
*
,
= −=
1
1
2
3  which shows that the 2-cycle bifurcates 
continuously from x *. For r 3 the roots are complex, which means that a 2-cycle 
doesn’t exist. ■
A cobweb diagram reveals how flip bifurcations can give rise to period-doubling. 
Consider any map  f , and look at the local picture near a fixed point where 
a
f
x
( *)x 1 (Figure 10.3.3).

367
10.3 LOGISTIC MAP: ANALYSIS
x
x
x*
+1
slope
1
≈−
n
n
Figure 10.3.3
If the graph of  f  is concave down near x *, the cobweb tends to produce a small, 
stable 2-cycle close to the fixed point. But like pitchfork bifurcations, flip bifurca-
tions can also be subcritical, in which case the 2-cycle exists below the bifurcation 
and is unstable—see Exercise 10.3.11.
The next example shows how to determine the stability of a 2-cycle.
EXAMPLE 10.3.3:
Show that the 2-cycle of Example 10.3.2 is stable for 3
1
6
3 449
< < +
=
r
.
....   
( This explains the values of r1 and r2 found numerically in Section 10.2.)
Solution: Our analysis follows a strategy that is worth remembering: To analyze 
the stability of a cycle, reduce the problem to a question about the stability of a 
fixed point, as follows. Both p and q are solutions of f 2 ( x )  x, as pointed out in 
Example 10.3.2; hence p and q are fixed points of the second-iterate map f  ( x ) . The 
original 2-cycle is stable precisely if p and q are stable fixed points for f .
Now we’re on familiar ground. To determine whether p is a stable fixed point of 
f , we compute the multiplier
M 



d
dx
x
p
f f x
f
f p
f
p
f
q f
p
( ( ( )))
( ( ))
( )
( )
( ).
′
′
′
′
(Note that the same M is obtained at x q, by the symmetry of the final term 
above. Hence, when the p and q branches bifurcate, they must do so simultane-
ously. We noticed such a simultaneous splitting in our numerical observations of 
Section 10.2.)

368 
ONE-DIMENSIONAL MAPS
After carrying out the differentiations and substituting for p and q, we obtain
M =
−
−
=
−
+
+
[
]
=
−
+
+
+
⎡⎣⎢
⎤
r
q r
p
r
p
q
pq
r
r
r
r
r
(
) (
)
(
)
(
)
(
)
1
2
1
2
1
2
4
1
2
1
4
1
2
2
2
⎦⎥
=
+
−
4
2
2
r
r .
Therefore the 2-cycle is linearly stable for 4
2
1
2
+
+
<
r
r
,i.e., for 3
1
6
< < +
r
. ■
Figure 10.3.4 shows a partial bifurcation diagram for the logistic map, based on 
our results so far. Bifurcation diagrams are different from orbit diagrams in that 
unstable objects are shown as well; orbit diagrams show only the attractors.
x
+
1
3
r
1
6
Figure 10.3.4
Our analytical methods are becoming unwieldy. A few more exact results can be 
obtained (see the exercises), but such results are hard to come by. To elucidate the 
behavior in the interesting region where r rd, we are going to rely mainly on 
graphical and numerical arguments.
10.4 Periodic Windows
One of the most intriguing features of the orbit diagram (Figure 10.2.7) is the 
occurrence of periodic windows for r rd. The period-3 window that occurs near 
3.8284 . . . br b3.8415 . . . is the most conspicuous. Suddenly, against a backdrop 
of chaos, a stable 3-cycle appears out of the blue. Our first goal in this section is 
to understand how this 3-cycle is created. (The same mechanism accounts for the 
creation of all the other windows, so it suffices to consider this simplest case.)
First, some notation. Let f  ( x ) rx ( 1  x )  so that the logistic map is 
xn1  f  ( xn ) .

369
10.4 PERIODIC WINDOWS
Then xn2 f   ( f   ( xn ))  or more simply, xn2  f 2 ( xn ) . Similarly, xn3  f 3 ( xn ) .
The third-iterate map f 3 ( x )  is the key to understanding the birth of the 
period-3 cycle. Any point p in a period-3 cycle repeats every three iterates, by defi-
nition, so such points satisfy p  f 3 ( p )  and are therefore fixed points of the 
third-iterate map. Unfortunately, since f 3 ( x )  is an eighth-degree polynomial, we 
cannot solve for the fixed points explicitly. But a graph provides sufficient insight. 
Figure 10.4.1 plots f 3 ( x )  for r 3.835.
x
f 3(   )
0.8
0.6
0.4
0.2
0
0
0.2
0.4
0.6
0.8
1
x
1
Figure 10.4.1
Intersections between the graph and the diagonal line correspond to solutions of 
f 3 ( x )  x. There are eight solutions, six of interest to us and marked with dots, 
and two imposters that are not genuine period-3; they are actually fixed points, or 
period-1 points for which  f   ( x * )  x *. The black dots in Figure 10.4.1 correspond 
to a stable period-3 cycle; note that the slope of f 3 ( x )  is shallow at these points, 
consistent with the stability of the cycle. In contrast, the slope exceeds 1 at the cycle 
marked by the open dots; this 3-cycle is therefore unstable.
Now suppose we decrease r toward the chaotic regime. Then the graph in 
Figure 10.4.1 changes shape—the hills move down and the valleys rise up. The 
curve therefore pulls away from the diagonal. Figure  10.4.2 shows that when 
r 3.8, the six marked intersections have vanished. Hence, for some intermediate 
value between r 3.8 and r 3.835, the graph of f 3 ( x )  must have become tan-
gent to the diagonal. At this critical value of r, the stable and unstable period-3 
cycles coalesce and annihilate in a tangent bifurcation. This transition defines the 
beginning of the periodic window.

370 
ONE-DIMENSIONAL MAPS
x
f 3(   )
0.8
0.6
0.4
0.2
0
0
0.2
0.4
0.6
0.8
1
x
1
Figure 10.4.2
One can show analytically that the value of r at the tangent bifurcation is 
1
8
3 8284
+
= .
... (Myrberg 1958). This beautiful result is often mentioned in 
textbooks and articles—but always without proof. Given the resemblance of this 
result to the 1
6

 encountered in Example 10.3.3, I’d always assumed it should 
be comparably easy to derive, and once assigned it as a routine homework prob-
lem. Oops! It turns out to be a bear. See Exercise 10.4.10 for hints, and Saha and 
Strogatz (1994) for Partha Saha’s solution, the most elementary one my class could 
find. Maybe you can do better; if so, let me know!
Intermittency
For r just below the period-3 window, the system exhibits an interesting kind of 
chaos. Figure 10.4.3 shows a typical orbit for r 3.8282.
x
1
nearly
chaos
r =3.8282
period-3
0
0
50
n
100
150
n
Figure 10.4.3
Part of the orbit looks like a stable 3-cycle, as indicated by the black dots. But this 
is spooky since the 3-cycle no longer exists! We’re seeing the ghost of the 3-cycle.

371
10.4 PERIODIC WINDOWS
We should not be surprised to see ghosts—they always occur near saddle-node 
bifurcations (Sections 4.3 and 8.1) and indeed, a tangent bifurcation is just a 
saddle-node bifurcation by another name. But the new wrinkle is that the orbit 
returns to the ghostly 3-cycle repeatedly, with intermittent bouts of chaos between 
visits. Accordingly, this phenomenon is known as intermittency (Pomeau and 
Manneville 1980).
Figure 10.4.4 shows the geometry underlying intermittency.
x
f 3(   )
0.8
0.6
(a)
(b)
0.4
0.2
0
0
0.2
0.4
0.6
0.8
1
x
1
Figure 10.4.4
In Figure 10.4.4a, notice the three narrow channels between the diagonal and the 
graph of f 3 ( x ) . These channels were formed in the aftermath of the tangent 
bifurcation, as the hills and valleys of f 3 ( x )  pulled away from the diagonal. Now 
focus on the channel in the small box of Figure 10.4.4a, enlarged in Figure 10.4.4b. 
The orbit takes many iterations to squeeze through the channel. Hence f 3 ( xn ) x xn 
during the passage, and so the orbit looks like a 3-cycle; this explains why we see a 
ghost.
Eventually, the orbit escapes from the channel. Then it bounces around chaot-
ically until fate sends it back into a channel at some unpredictable later time and 
place.
Intermittency is not just a curiosity of the logistic map. It arises commonly in 
systems where the transition from periodic to chaotic behavior takes place by a 
saddle-node bifurcation of cycles. For instance, Exercise 10.4.8 shows that inter-
mittency can occur in the Lorenz equations. (In fact, it was discovered there; see 
Pomeau and Manneville 1980).
In experimental systems, intermittency appears as nearly periodic motion 
interrupted by occasional irregular bursts. The time between bursts is statistically 
distributed, much like a random variable, even though the system is completely 
deterministic. As the control parameter is moved farther away from the periodic 
window, the bursts become more frequent until the system is fully chaotic. This 
progression is known as the intermittency route to chaos.

372 
ONE-DIMENSIONAL MAPS
Figure  10.4.5 shows an experimental example of the intermittency route to 
chaos in a laser.
0
5
10
Time 
s
(
)
μ
Figure 10.4.5
The intensity of the emitted laser light is plotted as a function of time. In the lowest 
panel of Figure 10.4.5, the laser is pulsing periodically. A bifurcation to intermit-
tency occurs as the system’s control parameter (the tilt of the mirror in the laser 
cavity) is varied. Moving from bottom to top of Figure 10.4.5, we see that the cha-
otic bursts occur increasingly often.
For a nice review of intermittency in fluids and chemical reactions, see Bergé 
et al. (1984). Those authors also review two other types of intermittency (the kind 
considered here is Type I intermittency) and give a much more detailed treatment 
of intermittency in general.
Period-Doubling in the Window
We commented at the end of Section 10.2 that a copy of the orbit diagram 
appears in miniature in the period-3 window. The explanation has to do with hills 
and valleys again. Just after the stable 3-cycle is created in the tangent bifurcation, 
the slope at the black dots in Figure 10.4.1 is close to1. As we increase r, the hills 
rise and the valleys sink. The slope of f 3 ( x ) at the black dots decreases steadily 

373
10.5 LIAPUNOV EXPONENT
from 1 and eventually reaches 1. When this occurs, a flip bifurcation causes 
each of the black dots to split in two; the 3-cycle doubles its period and becomes a 
6-cycle. The same mechanism operates here as in the original period-doubling cas-
cade, but now produces orbits of period 3 •2n. A similar period-doubling cascade 
can be found in all of the periodic windows.
10.5 Liapunov Exponent
We have seen that the logistic map can exhibit aperiodic orbits for certain param-
eter values, but how do we know that this is really chaos? To be called “chaotic,” 
a system should also show sensitive dependence on initial conditions, in the sense 
that neighboring orbits separate exponentially fast, on average. In Section 9.3 we 
quantified sensitive dependence by defining the Liapunov exponent for a chaotic 
differental equation. Now we extend the definition to one-dimensional maps.
Here’s the intuition. Given some initial condition x0, consider a nearby point 
x0 E0, where the initial separation E 0 is extremely small. Let E n be the separation 
after n iterates. If | E n | x | E 0 | enM, then M is called the Liapunov exponent. A positive 
Liapunov exponent is a signature of chaos.
A more precise and computationally useful formula for M can be derived. By 
taking logarithms and noting that E n = f  n ( x0 E 0 )   f  n ( x0 ) , we obtain
λ
δ
δ
δ
δ
≈
=
+
−
=
1
1
1
0
0
0
0
0
0
n
n
f
x
f
x
n
f
x
n
n
n
n
ln
ln
(
)
(
)
ln (
) (
)
′
where we’ve taken the limit E0 l 0 in the last step. The term inside the logarithm 
can be expanded by the chain rule:
(
) (
)
(
) .
f
x
f
x
n
i
i
n
′
′
0
0
1
=
=
−
∏
(We’ve already seen this formula in Example 9.4.1, where it was derived by heuris-
tic reasoning about multipliers, and in Example 10.3.3, for the special case n 2.) 
Hence
M ≈
=
=
−
=
−
∏
∑
1
1
0
1
0
1
n
f
x
n
f
x
i
i
n
i
i
n
ln
(
)
ln
(
).
′
′

374 
ONE-DIMENSIONAL MAPS
If this expression has a limit as n ld, we define that limit to be the Liapunov 
exponent for the orbit starting at x0:
M =
⎧
⎨⎪⎪
⎩⎪⎪
⎫
⎬⎪⎪
⎭⎪⎪
→∞
=
−
∑
lim
ln
(
) .
n
n
f
xi
i
n
1
0
1
′
Note that M depends on x0. However, it is the same for all x0 in the basin of attrac-
tion of a given attractor. For stable fixed points and cycles, M is negative; for chaotic 
attractors, M is positive.
The next two examples deal with special cases where M can be found analytically.
EXAMPLE 10.5.1:
Suppose that  f  has a stable p-cycle containing the point x0. Show that the 
Liapunov exponent M 0. If the cycle is superstable, show that M d.
Solution: As usual, we convert questions about p-cycles of  f  into questions 
about fixed points of  f  p. Since x0 is an element of a p-cycle, x0 is a fixed point of  f   p. 
By assumption, the cycle is stable; hence the multiplier (
) (
)
.
f
x
p ′
0
1

 Therefore 
ln (
) (
)
ln( )
,
f
x
p ′
0
1
0
<
=
a result that we’ll use in a moment.
Next observe that for a p-cycle,
M =
⎧
⎨⎪⎪
⎩⎪⎪
⎫
⎬⎪⎪
⎭⎪⎪
=
→∞
=
−
=
−
∑
∑
lim
ln
(
)
ln
(
)
n
n
f
x
p
f
x
i
i
n
i
i
p
1
1
0
1
0
1
′
′
since the same p terms keep appearing in the infinite sum. Finally, using the chain 
rule in reverse, we obtain
1
1
0
0
0
1
p
f
x
p
f
x
i
p
i
p
ln
(
)
ln (
) (
)
,
′
′
=
<
=
−
∑
as desired. If the cycle is superstable, then (
) (
)
f
x
p ′
0
0

 by definition, and thus 
M =
= −∞
1
0
p ln( )
.  ■
The second example concerns the tent map, defined by
f x
rx
x
r
rx
x
( )
,
,
=
≤
≤
−
≤
≤
⎧
⎨
⎪⎪
⎩⎪⎪
0
1
1
2
1
2
for 0 br b2 and 0 bx b1 (Figure 10.5.1).

375
10.5 LIAPUNOV EXPONENT
x
x
2
1
0
1
r
n
n
+1
Figure 10.5.1
Because it is piecewise linear, the tent map is far easier to analyze than the logistic 
map.
EXAMPLE 10.5.2:
Show that M ln r for the tent map, independent of the initial condition x0.
Solution: Since f a ( x )  o r for all x, we find M =
⎧
⎨⎪⎪
⎩⎪⎪
⎫
⎬⎪⎪
⎭⎪⎪
→∞
=
−
∑
lim
ln
(
)
n
n
f
xi
i
n
1
0
1
′
ln r.■
Example 10.5.2 suggests that the tent map has chaotic solutions for all r 1, since 
M ln r 0. In fact, the dynamics of the tent map can be understood in detail, 
even in the chaotic regime; see Devaney (1989).
In general, one needs to use a computer to calculate Liapunov exponents. The 
next example outlines such a calculation for the logistic map.
EXAMPLE 10.5.3:
Describe a numerical scheme to compute M for the logistic map 
  f  ( x )  rx ( 1  x ) . Graph the results as a function of the control parameter r, for 
3brb4.
Solution: Fix some value of r. Then, starting from a random initial condition, 
iterate the map long enough to allow transients to decay, say 300 iterates or so. 
Next compute a large number of additional iterates, say 10,000. You only need to 
store the current value of xn, not all the previous iterates. Compute 
ln
(
)
ln
f
x
r
rx
n
n
′
=
−2
 and add it to the sum of the previous logarithms. The 
Liapunov exponent is then obtained by dividing the grand total by 10,000. Repeat 
this procedure for the next r, and so on. The end result should look like Figure 10.5.2.

376 
ONE-DIMENSIONAL MAPS
1·0
0·5
r
λ
−0·5
−1·0
3·0
3·2
3·4 
3·6
3·8
4·0
0
Figure 10.5.2 Olsen and Degn  ( 1985 ) , p. 175
Comparing this graph to the orbit diagram (Figure 10.2.7), we notice that M 
remains negative for r
r
<
≈
∞
3 57
.
, and approaches zero at the period-doubling 
bifurcations. The negative spikes correspond to the 2n-cycles. The onset of chaos is 
visible near r x 3.57, where M first becomes positive. For r 3.57 the Liapunov 
exponent generally increases, except for the dips caused by the windows of peri-
odic behavior. Note the large dip due to the period-3 window near r 3.83. ■
Actually, all the dips in Figure 10.5.2 should drop down to M d , because a 
superstable cycle is guaranteed to occur somewhere near the middle of each dip, 
and such cycles have M d, by Example 10.5.1. This part of the spike is too nar-
row to be resolved in Figure 10.5.2.
10.6 Universality and Experiments
This section deals with some of the most astonishing results in all of nonlinear 
dynamics. The ideas are best introduced by way of an example.
EXAMPLE 10.6.1:
Plot the graph of the sine map xn + 1 r sinQxn for 0 br b1 and 0 bx b1, and 
compare it to the logistic map. Then plot the orbit diagrams for both maps, and list 
some similarities and differences.
Solution: The graph of the sine map is shown in Figure 10.6.1.

377
10.6 UNIVERSALITY AND EXPERIMENTS
x
x
r
1
0
1
n
n
+1
Figure 10.6.1
It has the same shape as the graph of the logistic map. Both curves are smooth, 
concave down, and have a single maximum. Such maps are called unimodal.
Figure 10.6.2 shows the orbit diagrams for the sine map (top panel) and the 
logistic map (bottom panel). The resemblance is incredible. Note that both dia-
grams have the same vertical scale, but that the horizontal axis of the sine map 
diagram is scaled by a factor of 4. This normalization is appropriate because the 
maximum of r sinQx is r, whereas that of rx ( 1  x )  is 1
4 r .
Figure 10.6.2 shows that the qualitative dynamics of the two maps are identical. 
They both undergo period-doubling routes to chaos, followed by periodic win-
dows interwoven with chaotic bands. Even more remarkably, the periodic win-
dows occur in the same order, and with the same relative sizes. For instance, the 
period-3 window is the largest in both cases, and the next largest windows preced-
ing it are period-5 and period-6.
But there are quantitative differences. For instance, the period-doubling bifur-
cations occur later in the logistic map, and the periodic windows are thinner. ■
Qualitative Universality: The U-sequence
Example 10.6.1 illustrates a powerful theorem due to Metropolis et al. (1973). 
They considered all unimodal maps of the form xn1 r f  ( xn ) , where  f  ( x )  also 
satisfies  f  ( 0 )  f  ( 1 )  0. (For the precise conditions, see their original paper.) 
Metropolis et al. proved that as r is varied, the order in which stable periodic 
solutions appear is independent of the unimodal map being iterated. That is, the 
periodic attractors always occur in the same sequence, now called the universal or 
U-sequence. This amazing result implies that the algebraic form of  f  ( x )  is irrele-
vant; only its overall shape matters.
Up to period 6, the U-sequence is
1, 2, 2q2, 6, 5, 3, 2q3, 5, 6, 4, 6, 5, 6.

378 
ONE-DIMENSIONAL MAPS
1.000000
0.750000
0.625000
0.500000
0.375000
0.250000
0.125000
0.000000
0.000000
2.800000
3.040000
3.280000
3.520000
3.760000
4.000000
1.000000
0.940000
0.880000
0.820000
0.760000
0.700000
0.875000
1.000000
0.750000
0.625000
0.500000
0.375000
0.250000
0.125000
0.875000
Figure 10.6.2 Courtesy of Andy Christian
The beginning of this sequence is familiar: periods 1, 2, and 2 q 2 are the first 
stages in the period-doubling scenario. (The later period-doublings give periods 
greater than 6, so they are omitted here.) Next, periods 6, 5, 3 correspond to the 
large windows mentioned in the discussion of Figure 10.6.2. Period 2 q 3 is the 
first period-doubling of the period-3 cycle. The later cycles 5, 6, 4, 6, 5, 6 are less 

379
10.6 UNIVERSALITY AND EXPERIMENTS
familiar; they occur in tiny windows and easy to miss (see Exercise 10.6.5 for their 
locations in the logistic map).
The U-sequence has been found in experiments on the Belousov-Zhabotinsky 
chemical reaction. Simoyi et al. (1982) studied the reaction in a continuously stirred 
flow reactor and found a regime in which periodic and chaotic states alternate as 
the flow rate is increased. Within the experimental resolution, the periodic states 
occurred in the exact order predicted by the U-sequence. See Section 12.4 for more 
details of these experiments.
The U-sequence is qualitative; it dictates the order, but not the precise parameter 
values, at which periodic attractors occur. We turn now to Mitchell Feigenbaum’s 
celebrated discovery of quantitative universality in one-dimensional maps.
Quantitative Universality
You should read the dramatic story behind this work in Gleick (1987), and 
also see Feigenbaum (1980; reprinted in Cvitanovic 1989a) for his own reminis-
cences. The original technical papers are Feigenbaum (1978, 1979)—published 
only after being rejected by other journals. These papers are fairly heavy reading; 
see Feigenbaum (1980), Schuster (1989) and Cvitanovic (1989b) for more accessible 
expositions.
Here’s a capsule history. Around 1975, Feigenbaum began to study period-doubling 
in the logistic map. First he developed a complicated (and now forgotten) “generating 
function theory” to predict rn, the value of r where a 2n-cycle first appears. To check 
his theory numerically, and not being fluent with large computers, he programmed 
his handheld calculator to compute the first several rn. As the calculator chugged 
along, Feigenbaum had time to guess where the next bifurcation would occur. He 
noticed a simple rule: the rn converged geometrically, with the distance between suc-
cessive transitions shrinking by a constant factor of about 4.669.
Feigenbaum (1980) recounts what happened next:
I spent part of a day trying to fit the convergence rate value, 4.669, to 
the mathematical constants I knew. The task was fruitless, save for the 
fact that it made the number memorable.
At this point I was reminded by Paul Stein that period-doubling 
isn’t a unique property of the quadratic map but also occurs, for exam-
ple, in xn1 r sin Qxn. However my generating function theory rested 
heavily on the fact that the nonlinearity was simply quadratic and not 
transcendental. Accordingly, my interest in the problem waned.
Perhaps a month later I decided to compute the rn’s in the transcen-
dental case numerically. This problem was even slower to compute 
than the quadratic one. Again, it became apparent that the rn’s con-
verged geometrically, and altogether amazingly, the convergence rate 
was the same 4.669 that I remembered by virtue of my efforts to fit it.

380 
ONE-DIMENSIONAL MAPS
In fact, the same convergence rate appears no matter what unimodal map is iter-
ated ! In this sense, the number 
E =
−
−
=
→∞
−
+
lim
.
...
n
r
r
r
r
n
n
n
n
1
1
4 669
is universal. It is a new mathematical constant, as basic to period-doubling as Q is 
to circles.
Figure  10.6.3 schematically illustrates the meaning of E. Let % n rn  rn + 1 
denote the distance between consecutive bifurcation values. Then %n / % n + 1 lE 
as n ld.
x
Δ
Δ
x
d
r
d
m
n
n
n
n
+
+
1
1
Figure 10.6.3
There is also universal scaling in the x-direction. It is harder to state precisely 
because the pitchforks have varying widths, even at the same value of r. (Look 
back at the orbit diagrams in Figure 10.6.2 to confirm this.) To take account of this 
nonuniformity, we define a standard x-scale as follows: Let xm denote the maxi-
mum of  f , and let dn denote the distance from xm to the nearest point in a 2n-cycle 
(Figure 10.6.3).
Then the ratio dn / dn + 1 tends to a universal limit as n ld:
d
d
n
n+
→
= −
1
2 5029
B
.
... ,

381
10.6 UNIVERSALITY AND EXPERIMENTS
independent of the precise form of  f . Here the negative sign indicates that 
the nearest point in the 2n-cycle is alternately above and below xm, as shown in 
Figure 10.6.3. Thus the dn are alternately positive and negative.
Feigenbaum went on to develop a beautiful theory that explained why B and E 
are universal (Feigenbaum 1979). He borrowed the idea of renormalization from 
statistical physics, and thereby found an analogy between B, E and the universal 
exponents observed in experiments on second-order phase transitions in magnets, 
fluids, and other physical systems (Ma 1976). In Section 10.7, we give a brief look at 
this renormalization theory.
Experimental Tests
Since Feigenbaum’s work, sequences of period-doubling bifurcations have been 
measured in a variety of experimental systems. For instance, in the convection 
experiment of Libchaber et al. (1982), a box containing liquid mercury is heated 
from below. The control parameter is the Rayleigh number R, a dimensionless 
measure of the externally imposed temperature gradient from bottom to top. For 
R less than a critical value Rc, heat is conducted upward while the fluid remains 
motionless. But for R Rc, the motionless state becomes unstable and convection 
occurs—hot fluid rises on one side, loses its heat at the top, and descends on the 
other side, setting up a pattern of counterrotating cylindrical rolls (Figure 10.6.4).
cold
hot
Figure 10.6.4
For R just slightly above Rc, the rolls are straight and the motion is steady. 
Furthermore, at any fixed location in space, the temperature is constant. With 
more heating, another instability sets in. A wave propagates back and forth along 
each roll, causing the temperature to oscillate at each point.
In traditional experiments of this sort, one keeps turning up the heat, caus-
ing further instabilities to occur until eventually the roll structure is destroyed 
and the system becomes turbulent. Libchaber et al. (1982) wanted to be able to 
increase the heat without destabilizing the spatial structure. That’s why they chose 
mercury—then the roll structure could be stabilized by applying a dc magnetic 
field to the whole system. Mercury has a high electrical conductivity, so there is a 
strong tendency for the rolls to align with the field, thereby retaining their spatial 

382 
ONE-DIMENSIONAL MAPS
organization. There are further niceties in the experimental design, but they need 
not concern us; see Libchaber et al. (1982) or Bergé et al. (1984).
Now for the experimental results. Figure 10.6.5 shows that this system under-
goes a sequence of period-doublings as the Rayleigh number is increased.
R
c
R
3.47
3.52
3.62
3.65
0
50
100
T s
(   )
150
200
Figure 10.6.5 Libchaber et al.  ( 1982 ) , p.213
Each time series shows the temperature variations at one point in the fluid. For 
R Rc  3 47
.
, the temperature varies periodically. This may be regarded as the 
basic period-1 state. When R is increased to R Rc  3 52
.
, the successive tempera-
ture maxima are no longer equal; the odd peaks are a little higher than before, and 
the even peaks are a little lower. This is the period-2 state. Further increases in R 
generate additional period-doublings, as shown in the lower two time series in 
Figure 10.6.5.
By carefully measuring the values of R at the period-doubling bifurcations, 
Libchaber et al. (1982) arrived at a value of E 4.4 o 0.1, in reasonable agreement 
with the theoretical result E x 4.699.
Table 10.6.1, adapted from Cvitanovic (1989b), summarizes the results from a 
few experiments on fluid convection and nonlinear electronic circuits. The experi-
mental estimates of E are shown along with the errors quoted by the experimental-
ists; thus 4.3 (8) means 4.3 o 0.8.

383
10.6 UNIVERSALITY AND EXPERIMENTS
Experiment
Number of period 
doublings
E
Authors
Hydrodynamic
water 
4
4.3(8)
Giglio et al. (1981)
mercury
4
4.4(1)
Libchaber et al. (1982)
Electronic
diode
4
4.5(6)
Linsay (1981)
diode
5
4.3(1)
Testa et al. (1982)
transistor
4
4.7(3)
Arecchi and Lisi (1982)
Josephson simul.
3
4.5(3)
Yeh and Kao (1982)
Table 10.6.1
It is important to understand that these measurements are difficult. Since E x 5, 
each successive bifurcation requires about a fivefold improvement in the exper-
imenter’s ability to measure the external control parameter. Also, experimental 
noise tends to blur the structure of high-period orbits, so it is hard to tell precisely 
when a bifurcation has occurred. In practice, one cannot measure more than about 
five period-doublings. Given these difficulties, the agreement between theory and 
experiment is impressive.
Period-doubling has also been measured in laser, chemical, and acoustic sys-
tems, in addition to those listed here. See Cvitanovic (1989b) for references.
What Do 1-D Maps Have to Do with Science?
The predictive power of Feigenbaum’s theory may strike you as mysterious. 
How can the theory work, given that it includes none of the physics of real systems 
like convecting fluids or electronic circuits? And real systems often have tremen-
dously many degrees of freedom—how can all that complexity be captured by a 
one-dimensional map? Finally, real systems evolve in continuous time, so how can 
a theory based on discrete-time maps work so well?
To work toward the answer, let’s begin with a system that is simpler than a con-
vecting fluid, yet (seemingly) more complicated than a one-dimensional map. The 
system is a set of three differential equations concocted by Rössler (1976) to exhibit 
the simplest possible strange attractor. The Rössler system is



x
y
z
y
x
ay
z
b
z x
c
= −−
=
+
=
+
−
(
)
where a, b, and c are parameters. This system contains only one nonlinear term, 
zx, and is even simpler than the Lorenz system ( Chapter  9), which has two 
nonlinearities.

384 
ONE-DIMENSIONAL MAPS
Figure 10.6.6 shows two-dimensional projections of the system’s attractor for 
different values of c (with a b 0.2 held fixed).
14
14
4
5
14
x
x
x
x
14
c
c
c
c
2.5
3.5
=
=
=
=
+
+
+
−
−
−
−
−
−
−
−
14
+
14
14
14
14
14
14
14
14
14
14
14
+
+
+
14
y
y
y
y
+
Figure 10.6.6 Olsen and Degn  ( 1985 ) , p.185
At c 2.5 the attractor is a simple limit cycle. As c is increased to 3.5, the limit 
cycle goes around twice before closing, and its period is approximately twice that 
of the original cycle. This is what period-doubling looks like in a continuous-time 
system! In fact, somewhere between c 2.5 and 3.5, a period-doubling bifurcation 
of cycles must have occurred. (As Figure 10.6.6 suggests, such a bifurcation can 
occur only in three or higher dimensions, since the limit cycle needs room to avoid 
crossing itself.) Another period-doubling bifurcation creates the four-loop cycle 
shown at c 4. After an infinite cascade of further period-doublings, one obtains 
the strange attractor shown at c 5.
To compare these results to those obtained for one-dimensional maps, we use 
Lorenz’s trick for obtaining a map from a flow (Section 9.4). For a given value of 
c, we record the successive local maxima of x ( t )  for a trajectory on the strange 
attractor. Then we plot xn1 vs. xn, where xn denotes the nth local maximum. This 

385
10.6 UNIVERSALITY AND EXPERIMENTS
Lorenz map for c 5 is shown in Figure 10.6.7. The data points fall very nearly on 
a one-dimensional curve. Note the uncanny resemblance to the logistic map!
14
5
=
c
0
0
14
x
x
max
max
(n+1)
(n)
Figure 10.6.7 Olsen and Degn  ( 1985 ) , p.186
We can even compute an orbit diagram for the Rössler system. Now we allow 
all values of c, not just those where the system is chaotic. Above each c, we plot all 
the local maxima xn on the attractor for that value of c. The number of different 
maxima tells us the “period” of the attractor. For instance, at c 3.5 the attractor 
is period-2 (Figure 10.6.6), and hence there are two local maxima of x ( t ) . Both of 
these points are graphed above c 3.5 in Figure 10.6.8. We proceed in this way for 
all values of c, thereby sweeping out the orbit diagram.

386 
ONE-DIMENSIONAL MAPS
xmax
14
6·0
0
2·5
c
Figure 10.6.8 Olsen and Degn  ( 1985 ) , p.186
This orbit diagram allows us to keep track of the bifurcations in the Rössler sys-
tem. We see the period-doubling route to chaos and the large period-3 window—
all our old friends are here.
Now we can see why certain physical systems are governed by Feigenbaum’s 
universality theory—if the system’s Lorenz map is nearly one-dimensional and 
unimodal, then the theory applies. This is certainly the case for the Rössler sys-
tem, and probably for Libchaber’s convecting mercury. But not all systems have 
one-dimensional Lorenz maps. For the Lorenz map to be almost one-dimensional, 
the strange attractor has to be very flat, i.e., only slightly more than two-dimen-
sional. This requires that the system be highly dissipative; only two or three degrees 
of freedom are truly active, and the rest follow along slavishly. (Incidentally, that’s 
another reason why Libchaber et al. (1982) applied a magnetic field; it increases 
the damping in the system, and thereby favors a low-dimensional brand of chaos.) 
So while the theory works for some mildly chaotic systems, it does not apply to 
fully turbulent fluids or fibrillating hearts, where there are many active degrees of 
freedom corresponding to complicated behavior in space as well as time. We are 
still a long way from understanding such systems.
10.7 Renormalization
In this section we give an intuitive introduction to Feigenbaum’s (1979) renormal-
ization theory for period-doubling. For nice expositions at a higher mathematical 
level than that presented here, see Feigenbaum (1980), Collet and Eckmann (1980), 
Schuster (1989), Drazin (1992), and Cvitanovic (1989b).

387
10.7 RENORMALIZATION
First we introduce some notation. Let  f  ( x, r )  denote a unimodal map that 
undergoes a period-doubling route to chaos as r increases, and suppose that xm is 
the maximum of  f . Let rn denote the value of r at which a 2n-cycle is born, and let 
Rn denote the value of r at which the 2n-cycle is superstable.
Feigenbaum phrased his analysis in terms of the superstable cycles, so let’s get 
some practice with them.
EXAMPLE 10.7.1:
Find R0 and R1 for the map  f  ( x, r )  r  x2.
Solution: At R0 the map has a superstable fixed point, by definition. The 
fixed point condition is x * R0   ( x * ) 2 and the superstability condition is 
M ( s f  / sx ) xx * 0. Since s f  / sx –2x, we must have x * 0, i.e., the fixed 
point is the maximum of  f . Substituting x * 0 into the fixed point condition 
yields R00.
At R1 the map has a superstable 2-cycle. Let p and q denote the points of the 
cycle. Superstability requires that the multiplier M  ( 2p )  ( 2q )  0, so the point 
x 0 must be one of the points in the 2-cycle. Then the period-2 condition 
f 2( 0, R1 )  = 0 implies R1   ( R1 ) 2 0. Hence R1 1 (since the other root gives a 
fixed point, not a 2-cycle). ■
Example 10.7.1 illustrates a general rule: A superstable cycle of a unimodal 
map always contains xm as one of its points. Consequently, there is a simple 
graphical way to locate Rn (Figure 10.7.1). We draw a horizontal line at height 
xm ; then Rn occurs where this line intersects the figtree portion of the orbit dia-
gram (Feigenbaum f igtree in German). Note that Rn lies between rn and rn + 1. 
Numerical experiments show that the spacing between successive Rn also shrinks 
by the universal factor E x 4.669.
The renormalization theory is based on the self-similarity of the figtree—the 
twigs look like the earlier branches, except they are scaled down in both the x and 
r directions. This structure reflects the endless repetition of the same dynamical 
processes; a 2n-cycle is born, then becomes superstable, and then loses stability in 
a period-doubling bifurcation.
To express the self-similarity mathematically, we compare  f  with its second 
iterate f 2  at corresponding values of r, and then “renormalize” one map into the 
other. Specifically, look at the graphs of  f  ( x, R0 )  and f 2( x, R1 )  (Figure 10.7.2, a 
and b).

388 
ONE-DIMENSIONAL MAPS
x
r
r
r
r
R
R
xm
1
1
2
2
3
Figure 10.7.1
f
f
xm
(a)
(b)
(c)
xm
2
(x,R0)
(x,R1)
Figure 10.7.2
This is a fair comparison because the maps have the same stability properties: xm is 
a superstable f ixed point f or both of them. Please notice that to obtain Figure 10.7.2b, 
we took the second iterate of f  and increased r from R0 to R1. This r-shifting is a 
basic part of the renormalization procedure.
The small box of Figure 10.7.2b is reproduced in Figure 10.7.2c. The key point is 
that Figure 10.7.2c looks practically identical to Figure 10.7.2a, except for a change 
of scale and a reversal of both axes. From the point of view of dynamics, the two 
maps are very similar—cobweb diagrams starting from corresponding points 
would look almost the same.
Now we need to convert these qualitative observations into formulas. A help-
ful first step is to translate the origin of x to xm, by redefining x as x  xm. This 

389
10.7 RENORMALIZATION
redefinition of x dictates that we also subtract xm from  f , since  f  ( x n, r )   xnl. 
The translated graphs are shown in Figure 10.7.3a and 10.7.3b.
f (x,R0)
f
f
2
2
(x,R1)
, R1
x
iterate
2.5...
−
rescale by
α
α
α
=
(a)
(b)
(c)
Figure 10.7.3
Next, to make Figure 10.7.3b look like Figure 10.7.3a, we blow it up by a factor 
| B| > 1 in both directions, and also invert it by replacing  ( x, y )  by  ( x, y ) . Both 
operations can be accomplished in one step if we define the scale factor B to be 
negative. As you are asked to show in Exercise 10.7.2, rescaling by B is equivalent 
to replacing f 2  ( x, R1 )  by B f
x
R
2
1
(
,
).
B
Finally, the resemblance between 
Figure 10.7.3a and Figure 10.7.3c shows that
f x R
f
x R
( ,
)
,
.
0
2
1
≈
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
B
B
In summary,  f  has been renormalized by taking its second iterate, rescaling 
x
x
l
B, and shifting r to the next superstable value.
There is no reason to stop at f 2. For instance, we can renormalize f 2  to gen-
erate f 4; it too has a superstable fixed point if we shift r to R2. The same reasoning 
as above yields
f
x R
f
x
R
2
1
4
2
2
B
B
B
,
,
.
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟≈
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
When expressed in terms of the original map  f  ( x, R0 ) , this equation becomes
f x R
f
x R
( ,
)
,
.
0
2
4
2
2
≈
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
B
B
After renormalizing n times we get
f x R
f
x
R
n
n
n
n
( ,
)
,
.
(
)
0
2
≈
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
B
B

390 
ONE-DIMENSIONAL MAPS
Feigenbaum found numerically that
lim
,
( ),
(
)
n
n
n
n
f
x R
g
x
n
→∞
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟=
B
B
2
0
 
 (1)
where g0 ( x )  is a universal function with a superstable fixed point. The limiting 
function exists only if B is chosen correctly, specifically, B 2.5029. . . .
Here “universal” means that the limiting function g0 ( x )  is independent of the 
original  f  (almost). This seems incredible at first, but the form of (1) suggests the 
explanation: g0 ( x )  depends on  f  only through its behavior near x 0, since that’s 
all that survives in the argument x
n
B  as nld. With each renormalization, 
we’re blowing up a smaller and smaller neighborhood of the maximum of  f , so 
practically all information about the global shape of  f  is lost.
One caveat: The order of the maximum is never forgotten. Hence a more precise 
statement is that g0 ( x )  is universal for all  f  with a quadratic maximum (the generic 
case). A different g0 ( x )  is found for  f  ’s with a fourth-degree maximum, etc.
To obtain other universal functions gi  ( x ) , start with  f ( x, Ri )  instead of  f ( x, R0 ) :
g x
f
x
R
i
n
n
n
i
n
n
( )
lim
,
.
(
)
=
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
→∞
+
B
B
2
Here gi ( x )  is a universal function with a superstable 2i-cycle. The case where we 
start with Ri Rd (at the onset of chaos) is the most interesting and important, 
since then
f x R
f
x R
( ,
)
,
.
∞
∞
≈
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
B
B
2
For once, we don’t have to shift r when we renormalize! The limiting function 
gd ( x ) , usually called g ( x ) , satisfies
g x
g
x
( )
.
=
⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟
B
B
2
 
(2)
This is a functional equation for g ( x )  and the universal scale factor B. It is self-ref-
erential: g ( x )  is defined in terms of itself.
The functional equation is not complete until we specify boundary conditions 
on g ( x ) . After the shift of origin, all our unimodal  f ’s have a maximum at x 0, 
so we require ga ( 0 )  0. Also, we can set g ( 0 )  1 without loss of generality. (This 
just defines the scale for x; if g ( x )  is a solution of  ( 2), so is
(
),
g x
N
N  with the same 
B. See Exercise 10.7.3.)

391
10.7 RENORMALIZATION
Now we solve for g ( x )  and B. At x 0 the functional equation gives 
g ( 0 )  B g ( g ( 0 )  ) . But g ( 0 )  1, so 1 Bg ( l ) . Hence,
B 1
1
g ( ) ,
which shows that B is determined by g ( x ) . No one has ever found a closed form 
solution for g ( x ) , so we resort to a power series solution
g ( x )  1 c2x2 c4x4 . . .
 (which assumes that the maximum is quadratic). The coefficients are determined 
by substituting the power series into (2) and matching like powers of x. Feigenbaum 
(1979) used a seven-term expansion, and found c2 x 1.5276, c4 x 0.1048, along 
with B x 2.5029. Thus the renormalization theory has succeeded in explaining 
the value of B observed numerically.
The theory also explains the value of E. Unfortunately, that part of the story 
requires more sophisticated apparatus than we are prepared to discuss (operators 
in function space, Frechet derivatives, etc.). Instead we turn now to a concrete 
example of renormalization. The calculations are only approximate, but they can 
be done explicitly, using algebra instead of functional equations.
Renormalization for Pedestrians
The following pedagogical calculation is intended to clarify the renormaliza-
tion process. As a bonus, it gives closed form approximations for B and E. Our 
treatment is modified from May and Oster (1980) and Helleman (1980).
Let  f  ( x,N )  be any unimodal map that undergoes a period-doubling route to 
chaos. Suppose that the variables are defined such that the period-2 cycle is born 
at x 0 when N 0. Then for both x and N close to 0, the map is approximated by
2
1
(1
)
... ,
n
n
n
x
x
ax
N
   


since the eigenvalue is 1 at the bifurcation. (We are going to neglect all higher 
order terms in x and N; that’s why our results will be only approximate.) Without 
loss of generality we can set a 1 by rescaling x
x a
l
.  So locally our map has 
the normal form
2
1
(1
)
....
n
n
n
x
x
x
N
   


 
(3)
Here’s the idea: for N 0, there exist period-2 points, say p and q. As N increases, p 
and q themselves will eventually period-double. When this happens, the dynamics 
of f 2  near p will necessarily be approximated by a map with the same algebraic 
form as (3), since all maps have this form near a period-doubling bifurcation. Our 
strategy is to calculate the map governing the dynamics of f 2  near p, and renor-
malize it to look like (3). This defines a renormalization iteration, which in turn 
leads to a prediction of B and E.

392 
ONE-DIMENSIONAL MAPS
First, we find p and q. By definition of period-2, p is mapped to q and q to p. 
Hence (3) yields
p  ( 1 N ) q q2, 
q  ( 1 N ) p p2 .
By subtracting one of these equations from the other, and factoring out p  q, 
we find that p q N. Then multiplying the equations together and simplifying 
yields pq  N. Hence
2
2
4
4
,
.
2
2
p
q
N
N
N
N
N
N






Now shift the origin to p and look at the local dynamics. Let
2
( )
(1
)
.
f x
x
x
N
  

Then p is a fixed point of f 2 . Expand p
f
p
n
n
+
=
+
+
I
I
1
2(
)  in powers of the small 
deviation In. After some algebra (Exercise 10.7.10) and neglecting higher order 
terms as usual, we get
2
2
1
(1
4
)
. . .
n
n
n
C
I
N
N
I
I
 




 
(4)
where
2
2
4
3
4
.
C
N
N
N
N




 
(5)
As promised, the I-map (4) has the same algebraic form as the original map (3)! We 
can renormalize (4) into (3) by rescaling I and by defining a new N. (Note: The need 
for both of these steps was anticipated in the abstract version of renormalization 
discussed earlier. We have to rescale the state variable I and shift the bifurcation 
parameter N.)
To rescale I, let x
C
n
n

I . Then (4) becomes
2
2
1
(1
4
)
....
n
n
n
x
x
x
N
N
 







 
(6)
This matches (3) almost perfectly. All that remains is to define a new parameter N  
by 
2
(1
)
(1
4
).
N
N
N
 




 Then (6) achieves the desired form
2
1
(1
)
...
n
n
n
x
x
x
N
   






 
(7)
where the renormalized parameter N  is given by
2
4
2.
N
N
N




 
(8)

393
10.7 RENORMALIZATION
When 
0
N 

 the renormalized map (7) undergoes a flip bifurcation. Equivalently, 
the 2-cycle for the original map loses stability and creates a 4-cycle. This brings us 
to the end of the first period-doubling.
EXAMPLE 10.7.2:
Using (8), calculate the value of N at which the original map (3) gives birth to a 
period-4 cycle. Compare your result to the value r2
1
6
= +
 found for the logistic 
map in Example 10.3.3.
Solution: The period-4 solution is born when 
2
4
2
0
N
N
N





. Solving 
this quadratic equation yields 
2
6
N   
. (The other solution is negative and 
is not relevant.) Now recall that the origin of N was defined such that N 0 at 
the birth of period-2, which occurs at r 3 for the logistic map. Hence 
r2
3
2
6
1
6
= + −+
= +
(
)
, 
which 
recovers 
the 
result 
obtained 
in 
Example 10.3.3. ■
Because (7) has the same form as the original map, we can do the same analy-
sis all over again, now regarding (7) as the fundamental map. In other words, we 
can renormalize ad infinitum! This allows us to bootstrap our way to the onset of 
chaos, using only the renormalization transformation (8).
Let Nk denote the parameter value at which the original map (3) gives birth 
to a 2k-cycle. By definition of N, we have 
1
0
N  ; by Example 10.7.2, 
2
2
6
0.449
N   
x
. In general, the Nk satisfy
2
1
4
2
k
k
k
N
N
N
 


. 
(9)
At first it looks like we have the subscripts backwards, but think about it, using 
Example 10.7.2 as a guide. To obtain N2, we set 
1
0 (
)
N
N



 in (8) and then solved 
for N. Similarly, to obtain Nk, we set 
1
k
N
N 


 in (8) and then solve for N.
To convert (9) into a forward iteration, solve for Nk in terms of Nk1:
1
2 6
k
k
N
N 
 

 . 
(10)
Exercise 10.7.11 asks you to give a cobweb analysis of (10), starting from the initial 
condition N1 0. You’ll find that Nk l N*, where N*0 is a stable fixed point cor-
responding to the onset of chaos.
EXAMPLE 10.7.3:
Find N*.
Solution: It is slightly easier to work with (9). The fixed point satisfies 
N*   ( N* ) 2 4N* 2, and is given by

394 
ONE-DIMENSIONAL MAPS
	

1
2
*
3
17
0.56.
N 
 
x
 
(11)
Incidentally, this gives a remarkably accurate prediction of rd for the logistic map. 
Recall that N 0 corresponds to the birth of period-2, which occurs at r 3 for 
the logistic map. Thus N* corresponds to rd x 3.56 whereas the actual numerical 
result is rd x 3.57 ! ■
Finally we get to see how E and B make their entry. For k 1, the Nk should 
converge geometrically to N* at a rate given by the universal constant E. Hence 
δ
μ
μ
μ
μ
≈
−
−
−
(
*) (
*).
k
k
1
 As k ld, this ratio tends to 0 0  and therefore may 
be evaluated by L’Hôpital’s rule. The result is
δ
μ
μ
μ
μ
μ
≈
=
+
−
=
d
d
k
k
1
2
4
*
*
where we have used (9) in calculating the derivative. Finally, we substitute for N* 
using (11) and obtain
E ≈+
≈
1
17
5 12
.
.
This estimate is about 10 percent larger than the true E x 4.67, which is not bad 
considering our approximations.
To find the approximate B, note that we used C as a rescaling parameter when 
we defined x
C
n
n

I .  Hence C plays the role of B. Substitution of N* into (5) yields
C = +
−
+
⎡
⎣
⎢⎢⎢
⎤
⎦
⎥⎥⎥
≈−
1
17
2
3 1
17
2
2 24
1 2
/
.
,
which is also within 10 percent of the actual value B x 2.50.
EXERCISES FOR CHAPTER 10
Note: Many of these exercises ask you to use a computer. Feel free to write your 
own programs, or to use commercially available software. 
10.1 Fixed Points and Cobwebs
(Calculator experiments) Use a pocket calculator to explore the following maps. 
Start with some number and then keep pressing the appropriate function key; 
what happens? Then try a different number—is the eventual pattern the same? 

395
EXERCISES
If possible, explain your results mathematically, using a cobweb or some other 
argument.
10.1.1 
x
x
n
n
+ =
1
 
 
10.1.2 
x
x
n
n
+ =
1
3
10.1.3 
xn1 exp xn 
 
10.1.4 
xn1 ln xn
10.1.5 
xn1 cot xn 
 
10.1.6 
xn1 tan xn
10.1.7 
xn1 sinh xn 
 
10.1.8 
xn1 tanh xn
10.1.9 
Analyze the map xn1 2xn /  ( 1 xn )  for both positive and negative xn.
10.1.10 Show that the map x
x
n
n
+ = +
1
1
sin
1
2
 has a unique fixed point. Is it stable?
10.1.11 (Cubic map) Consider the map xn1 3xn  xn
3 .
a) Find all the fixed points and classify their stability.
b) Draw a cobweb starting at x0 1.9.
c) Draw a cobweb starting at x0 2.1.
d) Try to explain the dramatic difference between the orbits found in parts (b) and 
(c). For instance, can you prove that the orbit in (b) will remain bounded for all 
n? Or that | xn | ld in (c)?
10.1.12 (Newton’s method) Suppose you want to find the roots of an equation 
g ( x ) 0. Then Newton’s method says you should consider the map xn1 f  ( xn ) , 
where
f x
x
g x
g x
n
n
n
n
(
)
(
)
(
).
=
−
′
a) To calibrate the method, write down the “Newton map” xnl f  ( xn )  for the 
equation g ( x )  x2  4 0.
b) Show that the Newton map has fixed points at x * ±2.
c) Show that these fixed points are superstable.
d) Iterate the map numerically, starting from x0 1. Notice the extremely rapid 
convergence to the right answer!
10.1.13 (Newton’s method and superstability) Generalize Exercise 10.1.12 as fol-
lows. Show that (under appropriate circumstances, to be stated) the roots of an 
equation g ( x )  0 always correspond to superstable fixed points of the Newton 
map xnO f  ( xn ) , where 
f x
x
g x
g
x
n
n
n
n
(
)
(
)
(
).
=
−
′
(This explains why 
Newton’s method converges so fast—if it converges at all.)
10.1.14 Prove that x * 0 is a globally stable fixed point for the map 
xn1  sin xn. (Hint: Draw the line xn1 xn on your cobweb diagram, in 
addition to the usual line xn1 xn.)

396 
ONE-DIMENSIONAL MAPS
10.2 Logistic Map: Numerics
10.2.1 
Consider the logistic map for all real x and for any r 1.
a) Show that if xn 1 for some n, then subsequent iterations diverge toward d. 
(For the application to population biology, this means the population goes 
extinct.)
b) Given the result of part (a), explain why it is sensible to restrict r and x to the 
intervals r  [0,4] and x  [0,1].
10.2.2 
Use a cobweb to show that x * 0 is globally stable for 0 br b1 in the 
logistic map.
10.2.3 
Compute the orbit diagram for the logistic map.
Plot the orbit diagram for each of the following maps. Be sure to use a large enough 
range for both r and x to include the main features of interest. Also, try different 
initial conditions, just in case it matters.
10.2.4 
x
x e
n
n
r
xn
+
−
−
=
1
l(
)  (Standard period-doubling route to chaos)
10.2.5 
x
e
n
rxn
+
−
=
1
 (One period-doubling bifurcation and the show is over)
10.2.6 
xn1 r cos xn (Period-doubling and chaos galore)
10.2.7 
xn1 r tan xn (Nasty mess)
10.2.8 
x
rx
x
n
n
n
+ =
−
1
3  (Attractors sometimes come in symmetric pairs)
10.3 Logistic Map: Analysis
10.3.1 
(Superstable fixed point) Find the value of r at which the logistic map has 
a superstable fixed point.
10.3.2 
(Superstable 2-cycle) Let p and q be points in a 2-cycle for the logistic map.
a) Show that if the cycle is superstable, then either p  1
2  or q  1
2 .  (In other 
words, the point where the map takes on its maximum must be one of the points 
in the 2-cycle.)
b) Find the value of r at which the logistic map has a superstable 2-cycle.
10.3.3 
Analyze the long-term behavior of the map x
rx
x
n
n
n
+ =
+
1
1(
),
2
 where 
r 0. Find and classify all fixed points as a function of r. Can there be periodic 
solutions? Chaos?
10.3.4 
(Quadratic map) Consider the quadratic map x
x
c
n
n
+ =
+
1
2
.
a) Find and classify all the fixed points as a function of c.
b) Find the values of c at which the fixed points bifurcate, and classify those 
bifurcations.

397
EXERCISES
c) For which values of c is there a stable 2-cycle? When is it superstable?
d) Plot a partial bifurcation diagram for the map. Indicate the fixed points, the 
2-cycles, and their stability.
10.3.5 
(Conjugacy) Show that the logistic map xnO rxn ( 1  xn )  can be trans-
formed into the quadratic map y
y
c
n
n
+ =
+
l
2
 by a linear change of variables, 
xn ayn b, where a, b are to be determined.
(One says that the logistic and quadratic maps are “conjugate.” More generally, 
a conjugacy is a change of variables that transforms one map into another. If two 
maps are conjugate, they are equivalent as far as their dynamics are concerned; 
you just have to translate from one set of variables to the other. Strictly speaking, 
the transformation should be a homeomorphism, so that all topological features 
are preserved.)
10.3.6 
(Cubic map) Consider the cubic map xnO f  ( xn ) , where  f  ( xn )  rxn  xn
3 .
a) Find the fixed points. For which values of r do they exist? For which values are 
they stable?
b) To find the 2-cycles of the map, suppose that  f  ( p )  q and  f  ( q )  p. Show 
that p, q are roots of the equation x ( x2  r 1 )  ( x2  r  1 )  ( x4  rx2 1 )  0 
and use this to find all the 2-cycles.
c) Determine the stability of the 2-cycles as a function of r.
d) Plot a partial bifurcation diagram, based on the information obtained.
10.3.7 
(A chaotic map that can be analyzed completely) Consider the decimal 
shift map on the unit interval given by
xn + 1 10xn (mod 1).
As usual, “mod 1” means that we look only at the noninteger part of x. For exam-
ple, 2.63 (mod 1) 0.63.
a) Draw the graph of the map.
b) Find all the fixed points. (Hint: Write xn in decimal form.)
c) Show that the map has periodic points of all periods, but that all of them are 
unstable. (For the first part, it suffices to give an explicit example of a period-p 
point, for each integer p 1.)
d) Show that the map has infinitely many aperiodic orbits.
e) By considering the rate of separation between two nearby orbits, show that the 
map has sensitive dependence on initial conditions.
10.3.8 
(Dense orbit for the decimal shift map) Consider a map of the unit inter-
val into itself. An orbit {xn} is said to be “dense” if it eventually gets arbitrarily 
close to every point in the interval. Such an orbit has to hop around rather crazily! 
More precisely, given any F 0 and any point p  [0,1], the orbit {xn} is dense if 
there is some finite n such that | xn  p | F.
Explicitly construct a dense orbit for the decimal shift map xn + 1 10xn (mod 1).

398 
ONE-DIMENSIONAL MAPS
10.3.9 
(Binary shift map) Show that the binary shift map xn 2xn (mod 1) has 
sensitive dependence on initial conditions, infinitely many periodic and aperiodic 
orbits, and a dense orbit. (Hint: Redo Exercises 10.3.7 and 10.3.8, but write xn as a 
binary number, not a decimal.)
10.3.10 (Exact solutions for the logistic map with r 4) The previous exercise 
shows that the orbits of the binary shift map can be wild. Now we are going to see 
that this same wildness occurs in the logistic map when r 4.
a) Let {Rn} be an orbit of the binary shift map Rnl 2Rn (mod 1), and define a new 
sequence {xn} by xn sin2 ( QRn ) . Show that xn1 4xn ( 1  xn ) , no matter what 
R0 we started with. Hence any such orbit is an exact solution of the logistic map 
with r 4 !
b) Graph the time series xn vs. n, for various choices of R0.
10.3.11 (Subcritical flip) Let xn f  ( xn ) , where  f  ( x )   ( 1 r ) x  x2  2x3.
a) Classify the linear stability of the fixed point x * 0.
b) Show that a flip bifurcation occurs at x * 0 when r 0.
c) By considering the first few terms in the Taylor series for f 2  ( x )  or otherwise, 
show that there is an unstable 2-cycle for r 0, and that this cycle coalesces with 
x * 0 as r l0 from below.
d) What is the long-term behavior of orbits that start near x * 0, both for r 0 
and r 0?
10.3.12 (Numerics of superstable cycles) Let Rn denote the value of r at which the 
logistic map has a superstable cycle of period 2n.
a) Write an implicit but exact formula for Rn in terms of the point x  1
2  and the 
function  f  ( x, r )  rx ( 1  x ) .
b) Using a computer and the result of part  ( a), find R2, R3, . . . ,R7 to five significant 
figures.
c) Evaluate R
R
R
R
6
5
7
6


.
10.3.13 (Tantalizing patterns) The orbit diagram of the logistic map (Figure 10.2.7) 
exhibits some striking features that are rarely discussed in books.
a) There are several smooth, dark tracks of points running through the chaotic 
part of the diagram. What are these curves? (Hint: Think about  f  ( xm, r ) , where 
xm  1
2  is the point at which  f  is maximized.)
b) Can you find the exact value of r at the corner of the “big wedge”? (Hint: Several 
of the dark tracks in part (b) intersect at this corner.)
10.4 Periodic Windows
10.4.1 
(Exponential map) Consider the map xn r exp xn for r 0.
a) Analyze the map by drawing a cobweb.

399
EXERCISES
b) Show that a tangent bifurcation occurs at r
e
1
.
c) Sketch the time series xn vs. n for r just above and just below r
e
1
.
10.4.2 
Analyze the map x
rx
x
n
n
n
+ =
+
1
2
2
(
).
l 
 Find and classify all the bifurca-
tions and draw the bifurcation diagram. Can this system exhibit intermittency?
10.4.3 
(A superstable 3-cycle) The map x
rx
n
n
+ = −
1
1
2  has a superstable 3-cycle 
at a certain value of r. Find a cubic equation for this r.
10.4.4 
Approximate the value of r at which the logistic map has a superstable 
3-cycle. Please give a numerical approximation that is accurate to at least four 
places after the decimal point.
10.4.5 
(Band merging and crisis) Show numerically that the period-doubling 
bifurcations of the 3-cycle for the logistic map accumulate near r 3.8495. . . , 
to form three small chaotic bands. Show that these chaotic bands merge near 
r 3.857. . . to form a much larger attractor that nearly fills an interval.
This discontinuous jump in the size of an attractor is an example of a crisis 
(Grebogi, Ott, and Yorke 1983a).
10.4.6 
(A superstable cycle) Consider the logistic map with r 3.7389149. Plot 
the cobweb diagram, starting from x0
1
2

 (the maximum of the map). You should 
find a superstable cycle. What is its period?
10.4.7 
(Iteration patterns) Superstable cycles for the logistic map can be charac-
terized by a string of R’s and L’s, as follows. By convention, we start the cycle at 
x0
1
2
 . Then if the nth iterate xn lies to the right of x0
1
2
 , the nth letter in the 
string is an R; otherwise it’s an L. (No letter is used if xn  1
2 ,  since the superstable 
cycle is then complete.) The string is called the symbol sequence or iteration pattern 
for the superstable cycle (Metropolis et al. 1973).
a) Show that for the logistic map with r > +
l
5,  the first two letters are always 
RL.
b) What is the iteration pattern for the orbit you found in Exercise 10.4.6?
10.4.8 
(Intermittency in the Lorenz equations) Solve the Lorenz equations 
numerically for T 10, b  8
3 , and r near 166.
a) Show that if r 166, all trajectories are attracted to a stable limit cycle. Plot 
both the xz projection of the cycle, and the time series x ( t ) .
b) Show that if r 166.2, the trajectory looks like the old limit cycle for much of 
the time, but occasionally it is interrupted by chaotic bursts. This is the signa-
ture of intermittency.
c) Show that as r increases, the bursts become more frequent and last longer.
10.4.9 
(Period-doubling in the Lorenz equations) Solve the Lorenz equations 
numerically for T 10, b  8
3 , and r 148.5. You should find a stable limit cycle. 
Then repeat the experiment for r 147.5 to see a period-doubled version of this 

400 
ONE-DIMENSIONAL MAPS
cycle. (When plotting your results, discard the initial transient, and use the xy pro-
jections of the attractors.)
10.4.10 (The birth of period 3) This is a hard exercise. The goal is to show that the 
period-3 cycle of the logistic map is born in a tangent bifurcation at 
r = +
=
l
3 8284
8
.
.... Here are a few vague hints. There are four unknowns: the 
three period-3 points a, b, c and the bifurcation value r. There are also four equa-
tions:  f  ( a )  b,  f  ( b )  c,  f  ( c )  a, and the tangent bifurcation condition. Try 
to eliminate a, b, c (which we don’t care about anyway) and get an equation for r 
alone. It may help to shift coordinates so that the map has its maximum at x 0 
rather than x  1
2 . Also, you may want to change variables again to symmetric 
polynomials involving sums of products of a, b, c. See Saha and Strogatz (1995) for 
one solution, probably not the most elegant one!
10.4.11 (Repeated exponentiation) Let a  0 be an arbitrary positive real num-
ber, and consider the following sequence: 
x
a
x
a
x
a
a
aa
1
2
3



(
)
 
and so on, where the general term is x
a
n
xn
+ =
1
. Analyze the long-term behavior of 
the sequence xn
{
} as n →∞, given that x
a
1 
, and then discuss how that long-
term behavior depends on a. For instance, show that for certain values of a, the 
terms xn  tend to some limiting value. How does that limit depend on a ? For 
which values of a  is the long-term behavior more complicated? What happens 
then? 
After you finish exploring these questions on your own, you may want to con-
sult Knoebel (1981) and Rippon (1983) for a taste of the extensive history surround-
ing iterated exponentials, going all the way back to Euler (1777).
10.5 Liapunov Exponent
10.5.1 
Calculate the Liapunov exponent for the linear map xn1 rxn.
10.5.2 
Calculate the Liapunov exponent for the decimal shift map xn1 10xn 
(mod 1).
10.5.3 
Analyze the dynamics of the tent map for r b1 .
10.5.4 
(No windows for the tent map) Prove that, in contrast to the logistic map, 
the tent map does not have periodic windows interspersed with chaos.
10.5.5 
Plot the orbit diagram for the tent map.

401
EXERCISES
10.5.6 
Using a computer, compute and plot the Liapunov exponent as a function 
of r for the sine map xn1 r sin Qxn, for 0 bxn b1 and 0 br b1.
10.5.7 
The graph in Figure 10.5.2 suggests that M 0 at each period-doubling 
bifurcation value rn. Show analytically that this is correct.
10.6 Universality and Experiments
The first two exercises deal with the sine map xn1 r sin Qxn, where 0 r b1 and 
x  [0,1]. The goal is to learn about some of the practical problems that come up 
when one tries to estimate E numerically.
10.6.1 
(Naive approach)
a) At each of 200 equally spaced r values, plot x700 through x1000 vertically above 
r, starting from some random initial condition x0. Check your orbit diagram 
against Figure 10.6.2 to be sure your program is working.
b) Now go to finer resolution near the period-doubling bifurcations, and estimate 
rn, for n 1, 2, . . . , 6. Try to achieve five significant figures of accuracy.
c) Use the numbers from (b) to estimate the Feigenbaum ratio r
r
r
r
n
n
n
n
−
−
−
+
1
1
.
(Note: To get accurate estimates in part (b), you need to be clever, or careful, or 
both. As you probably found, a straightforward approach is hampered by “critical 
slowing down”—the convergence to a cycle becomes unbearably slow when that 
cycle is on the verge of period-doubling. This makes it hard to decide precisely 
where the bifurcation occurs. To achieve the desired accuracy, you may have to 
use double precision arithmetic, and about 104 iterates. But maybe you can find a 
shortcut by reformulating the problem.)
10.6.2 
(Superstable cycles to the rescue) The “critical slowing down” encoun-
tered in the previous problem is avoided if we compute Rn instead of rn. Here Rn 
denotes the value of r at which the sine map has a superstable cycle of period 2n.
a) Explain why it should be possible to compute Rn more easily and accurately 
than rn.
b) Compute the first six Rn ’s and use them to estimate E.
If you’re interested in knowing the best way to compute E, see Briggs (1991) for 
the state of the art.
10.6.3 
(Qualitative universality of patterns) The U-sequence dictates the order-
ing of the windows, but it actually says more: it dictates the iteration pattern within 
each window. (See Exercise  10.4.7 for the definition of iteration patterns.) For 
instance, consider the large period-6 window for the logistic and sine maps, visible 
in Figure 10.6.2.
a) For both maps, plot the cobweb for the corresponding superstable 6-cycle, 
given that it occurs at r 3.6275575 for the logistic map and r 0.8811406 for 
the sine map. (This cycle acts as a representative for the whole window.)
b) Find the iteration pattern for both cycles, and confirm that they match.

402 
ONE-DIMENSIONAL MAPS
10.6.4 
(Period 4) Consider the iteration patterns of all possible period-4 orbits 
for the logistic map, or any other unimodal map governed by the U-sequence.
a) Show that only two patterns are possible for period-4 orbits: RLL and RLR.
b) Show that the period-4 orbit with pattern RLL always occurs after RLR, i.e., at 
a larger value of r.
10.6.5 
(Unfamiliar later cycles) The final superstable cycles of periods 5, 6, 4, 6, 
5, 6 in the logistic map occur at approximately the following values of r: 3.9057065, 
3.9375364, 3.9602701, 3.9777664, 3.9902670, 3.9975831 (Metropolis et al. 1973). 
Notice that they’re all near the end of the orbit diagram. They have tiny windows 
around them and tend to be overlooked.
a) Plot the cobwebs for these cycles.
b) Did you find it hard to obtain the cycles of periods 5 and 6? If so, can you 
explain why this trouble occurred?
10.6.6 
(A trick for locating superstable cycles) Hao and Zheng (1989) give an 
amusing algorithm for finding a superstable cycle with a specified iteration pat-
tern. The idea works for any unimodal map, but for convenience, consider the map 
x
r
x
n
n
+ = −
1
2,  for 0 br b2. Define two functions R y
r
y L y
r
y
( )
,
( )
.
=
−
= −
−
 
 
These are the right and left branches of the inverse map.
a) For instance, suppose we want to find the r corresponding to the superstable 
5-cycle with pattern RLLR. Then Hao and Zheng show that this amounts to 
solving the equation r RLLR ( 0 ) . Show that when this equation is written out 
explicitly, it becomes
r
r
r
r
r
=
+
+
−
.
b) Solve this equation numerically by iterating the map
r
r
r
r
r
n
n
n
n
n
+ =
+
+
−
1
,
starting from any reasonable guess, e.g., r0 2 . Show numerically that rn con-
verges rapidly to 1.860782522. . . .
c) Verify that the answer to (b) yields a cycle with the desired pattern.
10.7 Renormalization
10.7.1 
(Hands on the functional equation) The functional equation 
g ( x )   Bg2 ( x / B )  arose in our renormalization analysis of period-doubling. Let’s 

403
EXERCISES
approximate its solution by brute force, assuming that g ( x )  is even and has a qua-
dratic maximum at x 0.
a) Suppose g ( x )  x 1 c2x2 for small x. Solve for c2 and B. (Neglect O ( x4 )  terms.)
b) Now assume g ( x )  x 1 c2x2 c4x4, and use Mathematica, Maple, Macsyma 
(or hand calculation) to solve for B, c2, c4. Compare your approximate results to 
the “exact” values B x 2.5029 . . . , c2 x 1.527 . . . , c4 x 0.1048 . . . .
10.7.2 
Given a map yn1 f  (yn ) , rewrite the map in terms of a rescaled variable 
xn Byn. Use this to show that rescaling and inversion converts f 2  ( x, R1 )  into 
B f 2 ( x / B, R1 ) , as claimed in the text.
10.7.3 
Show that if g is a solution of the functional equation, so is Ng ( x / N ) , with 
the same B.
10.7.4 
(Wildness of the universal function g (x ) ) Near the origin g ( x )  is roughly 
parabolic, but elsewhere it must be rather wild. In fact, the function g ( x )  has 
infinitely many wiggles as x ranges over the real line. Verify these statements by 
demonstrating that g ( x )  crosses the lines y ±x infinitely many times. (Hint: 
Show that if x * is a fixed point of g ( x ) , then so is Bx *.)
10.7.5 
(Crudest possible estimate of B ) Let  f  ( x, r )  r  x2.
a) Write down explicit expressions for  f  ( x, R0 )  and B f 2 ( x / B, R1 ) .
b) The two functions in (a) are supposed to resemble each other near the origin, 
if B is chosen correctly. (That’s the idea behind Figure 10.7.3.) Show the O ( x2 ) 
coefficients of the two functions agree if B 2.
10.7.6 
(Improved estimate of B) Redo Exercise  10.7.5 to one higher order: 
Let  f  ( x, r )  r  x2 again, but now compare B f 2( x / B, R1 )  to B2 f 4 ( x / B2 , R2 ) 
and match the coefficients of the lowest powers of x. What value of B is obtained 
in this way?
10.7.7 
(Quartic maxima) Develop the renormalization theory for functions with 
a fourth-degree maximum, e.g.,  f  ( x, r )  r  x4. What approximate value of B is 
predicted by the methods of Exercises 10.7.1 and 10.7.5? Estimate the first few terms 
in the power series for the universal function g ( x ) . By numerical experimentation, 
estimate the new value of E for the quartic case.
See Briggs (1991) for precise values of B and E for this fourth-degree case, as well 
as for all other integer degrees between 2 and 12.
10.7.8 
(Renormalization approach to intermittency: algebraic version) Consider 
the map xn1 f  ( xn, r ) , where  f  ( xn, r )  r x  x2. This is the normal form 
for any map close to a tangent bifurcation.
a) Show that the map undergoes a tangent bifurcation at the origin when r 0.
b) Suppose r is small and positive. By drawing a cobweb, show that a typical orbit 
takes many iterations to pass through the bottleneck at the origin.

404 
ONE-DIMENSIONAL MAPS
c) Let N ( r )  denote the typical number of iterations of  f  required for an orbit to 
get through the bottleneck. Our goal is to see how N ( r )  scales with r as r l0. 
We use a renormalization idea: Near the origin, f 2 looks like a rescaled version 
of  f , and hence it too has a bottleneck there. Show that it takes approximately 
1
2 N r( )  iterations for orbits of f 2  to pass through the bottleneck.
d) Expand f 2( x,r )  and keep only the terms through O ( x2 ) . Rescale x and r to put 
this new map into the desired normal form  F  ( X,R )  x R X  X 2. Show 
that this renormalization implies the recursive relation
1
2 N r( )  xN ( 4r ) .
e) Show that the equation in (d) has solutions N ( r )  arb and solve for b.
10.7.9 
(Renormalization approach to intermittency: functional version) Show 
that if the renormalization procedure in Exercise 10.7.8 is done exactly, we are led 
to the functional equation
g ( x )  Bg2 ( x / B ) 
(just as in the case of period-doubling!) but with new boundary conditions appro-
priate to the tangent bifurcation:
g ( 0 )  0, ga ( 0 )  l.
Unlike the period-doubling case, this functional equation can be solved explicitly 
(Hirsch et al. 1982).
a) Verify that a solution is B 2, g ( x )  x /  ( 1 ax ) , with a arbitrary.
b) Explain why B 2 is almost obvious, in retrospect. (Hint: Draw cobwebs for 
both g and g2 for an orbit passing through the bottleneck. Both cobwebs look 
like staircases; compare the lengths of their steps.)
10.7.10 Fill in the missing algebraic steps in the concrete renormalization calcula-
tion for period-doubling. Let  f  ( x )  ( 1 N ) x x2. Expand p Inl f   2 ( p In ) 
in powers of the small deviation In, using the fact that p is a fixed point of f 2 . 
Thereby confirm that (10.7.4) and (10.7.5) are correct.
10.7.11 Give a cobweb analysis of (10.7.10), starting from the initial condition 
N1 0. Show that Nk lN*, where N* 0 is a stable fixed point corresponding to 
the onset of chaos.

405
11.0 INTRODUCTION
11
FRACTALS
11.0 Introduction
Back in Chapter 9, we found that the solutions of the Lorenz equations settle down 
to a complicated set in phase space. This set is the strange attractor. As Lorenz 
(1963) realized, the geometry of this set must be very peculiar, something like 
an “infinite complex of surfaces.” In this chapter we develop the ideas needed to 
describe such strange sets more precisely. The tools come from fractal geometry.
Roughly speaking, fractals are complex geometric shapes with fine structure at 
arbitrarily small scales. Usually they have some degree of self-similarity. In other 
words, if we magnify a tiny part of a fractal, we will see features reminiscent of 
the whole. Sometimes the similarity is exact; more often it is only approximate or 
statistical.
Fractals are of great interest because of their exquisite combination of beauty, 
complexity, and endless structure. They are reminiscent of natural objects like 
mountains, clouds, coastlines, blood vessel networks, and even broccoli, in a way 
that classical shapes like cones and squares can’t match. They have also turned out 
to be useful in scientific applications ranging from computer graphics and image 
compression to the structural mechanics of cracks and the fluid mechanics of vis-
cous fingering.
Our goals in this chapter are modest. We want to become familiar with the sim-
plest fractals and to understand the various notions of fractal dimension. These ideas 
will be used in Chapter 12 to clarify the geometric structure of strange attractors.
Unfortunately, we will not be able to delve into the scientific applications of 
fractals, nor the lovely mathematical theory behind them. For the clearest intro-
duction to the theory and applications of fractals, see Falconer (1990). The books 
of Mandelbrot (1982), Peitgen and Richter (1986), Barnsley (1988), Feder (1988), 
and Schroeder (1991) are also recommended for their many fascinating pictures 
and examples.

406 
FRACTALS
11.1 Countable and Uncountable Sets
This section reviews the parts of set theory that we’ll need in later discussions of 
fractals. You may be familiar with this material already; if not, read on.
Are some infinities larger than others? Surprisingly, the answer is yes. In the late 
1800s, Georg Cantor invented a clever way to compare different infinite sets. Two 
sets X and Y are said to have the same cardinality (or number of elements) if there is 
an invertible mapping that pairs each element x  X with precisely one y  Y. Such 
a mapping is called a one-to-one correspondence; it’s like a buddy system, where 
every x has a buddy y, and no one in either set is left out or counted twice.
A familiar infinite set is the set of natural numbers N {1,2,3,4, . . .}. This set 
provides a basis for comparison—if another set X can be put into one-to-one cor-
respondence with the natural numbers, then X is said to be countable. Otherwise 
X is uncountable.
These definitions lead to some surprising conclusions, as the following exam-
ples show.
EXAMPLE 11.1.1:
Show that the set of even natural numbers E {2,4,6, . . .} is countable.
Solution: We need to find a one-to-one correspondence between E and N. Such 
a correspondence is given by the invertible mapping that pairs each natural num-
ber n with the even number 2n; thus l j 2, 2 j 4, 3 j 6, and so on.
Hence there are exactly as many even numbers as natural numbers. You might 
have thought that there would be only half as many, since all the odd numbers are 
missing! ■
There is an equivalent characterization of countable sets which is frequently 
useful. A set X is countable if it can be written as a list {x1, x2, x3, . . .}, with every 
x  X appearing somewhere in the list. In other words, given any x, there is some 
finite n such that xn x.
A convenient way to exhibit such a list is to give an algorithm that systemati-
cally counts the elements of X. This strategy is used in the next two examples.
EXAMPLE 11.1.2:
Show that the integers are countable.
Solution: Here’s an algorithm for listing all the integers: We start with 0 and 
then work in order of increasing absolute value. Thus the list is {0, 1, 1, 2, 2, 3, 
–3, . . .}. Any particular integer appears eventually, so the integers are countable. ■

407
11.1 COUNTABLE AND UNCOUNTABLE SETS
EXAMPLE 11.1.3:
Show that the positive rational numbers are countable.
Solution: Here’s a wrong way: we start listing the numbers 1
1
1
2
1
3
1
4
, , , ... in order. 
Unfortunately we never finish the 1
n ’s and so numbers like 2
3  are never counted!
The right way is to make a table where the pq-th entry is p / q. Then the rationals 
can be counted by the weaving procedure shown in Figure 11.1.1. Any given p  /  q is 
reached after a finite number of steps, so the rationals are countable. ■
1
1
1
1
1
1
1
2
2
2
2
2
2
2
3
3
3
3
3
3
3
4
4
4
Figure 11.1.1
Now we consider our first example of an uncountable set.
EXAMPLE 11.1.4:
Let X denote the set of all real numbers between 0 and 1. Show that X is 
uncountable.
Solution: The proof is by contradiction. If X were countable, we could list all 
the real numbers between 0 and 1 as a set {x1, x2, x3, . . .}. Rewrite these numbers 
in decimal form:
x1 0.x11x12x13x14…
x2 0.x21x22x23x24…
x3 0.x31x32x33x34…
#
where xij denotes the jth digit of the real number xi .
To obtain a contradiction, we’ll show that there’s a number r between 0 and 1 
that is not on the list. Hence any list is necessarily incomplete, and so the reals are 
uncountable.

408 
FRACTALS
We construct r as follows: its first digit is anything other than x11, the first digit of 
x1. Similarly, its second digit is anything other than the second digit of x2. In gen-
eral, the nth digit of r is xnn,  defined as any digit other than xnn. Then we claim that 
the number r
x x x

11
22
33...  is not on the list. Why not? It can’t be equal to x1, 
because it differs from x1 in the first decimal place. Similarly, r differs from x2 in 
the second decimal place, from x3 in the third decimal place, and so on. Hence r is 
not on the list, and thus X is uncountable. ■
This argument (devised by Cantor) is called the diagonal argument, because r is 
constructed by changing the diagonal entries xnn in the matrix of digits [ xij  ].
11.2 Cantor Set
Now we turn to another of Cantor’s creations, a fractal known as the Cantor set. It 
is simple and therefore pedagogically useful, but it is also much more than that—
as we’ll see in Chapter 12, the Cantor set is intimately related to the geometry of 
strange attractors.
Figure 11.2.1 shows how to construct the Cantor set.
0
1
S
S
S
S
S
S
1
Cantor Set C
0
1
2
0
1
2
3
4
∞
3
3
Figure 11.2.1
We start with the closed interval S0 [ 0, 1 ] and remove its open middle third, i.e., 
we delete the interval ( , )
1
3
2
3  and leave the endpoints behind. This produces the 
pair of closed intervals shown as S1. Then we remove the open middle thirds of 
those two intervals to produce S2, and so on. The limiting set C Sd is the Cantor 
set. It is difficult to visualize, but Figure 11.2.1 suggests that it consists of an infinite 
number of infinitesimal pieces, separated by gaps of various sizes.
Fractal Properties of the Cantor Set
The Cantor set C has several properties that are typical of fractals more 
generally:

409
11.2 CANTOR SET
1. C has structure at arbitrarily small scales. If we enlarge part of C 
repeatedly, we continue to see a complex pattern of points separated 
by gaps of various sizes. This structure is neverending, like worlds 
within worlds. In contrast, when we look at a smooth curve or sur-
face under repeated magnification, the picture becomes more and 
more featureless.
2. C is self-similar. It contains smaller copies of itself at all scales. For 
instance, if we take the left part of C (the part contained in the interval 
0 1
3,
⎡⎣
⎤⎦ ) and enlarge it by a factor of three, we get C back again. Similarly, 
the parts of C in each of the four intervals of S2 are geometrically sim-
ilar to C, except scaled down by a factor of nine.
If you’re having trouble seeing the self-similarity, it may help to 
think about the sets Sn rather than the mind-boggling set Sd. Focus 
on the left half of S2—it looks just like S1, except three times smaller. 
Similarly, the left half of S3 is S2, reduced by a factor of three. In 
general, the left half of Sn + 1 looks like all of Sn, scaled down by three. 
Now set n d. The conclusion is that the left half of Sd looks like Sd, 
scaled down by three, just as we claimed earlier.
Warning: The strict self-similarity of the Cantor set is found only 
in the simplest fractals. More general fractals are only approximately 
self-similar.
3. The dimension of C is not an integer. As we’ll show in Section 11.3, its 
dimension is actually ln 2ln 3 x 0.63! The idea of a noninteger dimen-
sion is bewildering at first, but it turns out to be a natural generaliza-
tion of our intuitive ideas about dimension, and provides a very useful 
tool for quantifying the structure of fractals.
Two other properties of the Cantor set are worth noting, although they are not 
fractal properties as such: C has measure zero and it consists of uncountably many 
points. These properties are clarified in the examples below.
EXAMPLE 11.2.1:
Show that the measure of the Cantor set is zero, in the sense that it can be cov-
ered by intervals whose total length is arbitrarily small.
Solution: Figure 11.2.1 shows that each set Sn completely covers all the sets that 
come after it in the construction. Hence the Cantor set C Sd is covered by each 
of the sets Sn. So the total length of the Cantor set must be less than the total length 
of Sn, for any n. Let Ln denote the length of Sn. Then from Figure 11.2.1 we see that 
L0 1, L1  2
3 , L2
2
3
2
3
2
3
2
=( )( )=( ) ,  and in general, Ln
n
=( )
2
3
. Since Ln l0 as 
n ld, the Cantor set has a total length of zero. ■

410 
FRACTALS
Example 11.2.1 suggests that the Cantor set is “small” in some sense. On the 
other hand, it contains tremendously many points—uncountably many, in fact. To 
see this, we first develop an elegant characterization of the Cantor set.
EXAMPLE 11.2.2:
Show that the Cantor set C consists of all points c  [ 0, 1 ] that have no 1’s in 
their base-3 expansion.
Solution: The idea of expanding numbers in different bases may be unfamiliar, 
unless you were one of those children who was taught “New Math” in elementary 
school. Now you finally get to see why base-3 is useful!
First let’s remember how to write an arbitrary number x  [ 0,1 ] in base-3. We 
expand in powers of 1 / 3: thus if x
a
a
a
=
+
+
+
1
2
2
3
3
3
3
3
. . . ,  then x .a1a2a3 . . . in 
base-3, where the digits an are 0, 1, or 2. This expansion has a nice geometric inter-
pretation (Figure 11.2.2).
.0...
.00...
.01...
.02...
.20...
.21...
.22...
.1...
.2...
Figure 11.2.2
If we imagine that [ 0,1 ] is divided into three equal pieces, then the first digit a1 tells 
us whether x is in the left, middle, or right piece. For instance, all numbers with 
a1 0 are in the left piece. (Ordinary base-10 works the same way, except that we 
divide [ 0,1 ] into ten pieces instead of three.) The second digit a2 provides more 
refined information: it tells us whether x is in the left, middle, or right third of a 
given piece. For instance, points of the form x .01. . . are in the middle part of the 
left third of [ 0,1 ], as shown in Figure 11.2.2.
Now think about the base-3 expansion of points in the Cantor set C. We deleted 
the middle third of [ 0,1 ] at the first stage of constructing C; this removed all points 
whose first digit is 1. So those points can’t be in C. The points left over (the only 
ones with a chance of ultimately being in C ) must have 0 or 2 as their first digit. 
Similarly, points whose second digit is 1 were deleted at the next stage in the con-
struction. By repeating this argument, we see that C consists of all points whose 
base-3 expansion contains no l’s, as claimed. ■

411
11.3 DIMENSION OF SELF-SIMILAR FRACTALS
There’s still a fussy point to be addressed. What about endpoints like 
1
3
000
 .
...
1
? It’s in the Cantor set, yet it has a 1 in its base-3 expansion. Does this 
contradict what we said above? No, because this point can also be written solely in 
terms of 0’s and 2’s, as follows: 1
3
000
0


.
. . .
.
....
1
  
2222
 By this trick, each point 
in the Cantor set can be written such that no l’s appear in its base-3 expansion, as 
claimed.
Now for the payoff.
EXAMPLE 11.2.3:
Show that the Cantor set is uncountable.
Solution: This is just a rewrite of the Cantor diagonal argument of Example 11.1.4, 
so we’ll be brief. Suppose there were a list {c1, c2 , c3, . . .} of all points in C . To show 
that C is uncountable, we produce a point c  that is in C but not on the list. Let cij 
denote the jth digit in the base-3 expansion of ci. Define c
c c

11 22 ... ,  where the 
overbar means we switch 0’s and 2’s: thus cnn  0  if cnn 2 and cnn  2  if cnn 0. 
Then c  is in C, since it’s written solely with 0’s and 2’s, but c  is not on the list, since 
it differs from cn in the nth digit. This contradicts the original assumption that the 
list is complete. Hence C is uncountable. ■
11.3 Dimension of Self-Similar Fractals
What is the “dimension” of a set of points? For familiar geometric objects, the 
answer is clear—lines and smooth curves are one-dimensional, planes and smooth 
surfaces are two-dimensional, solids are three-dimensional, and so on. If forced 
to give a definition, we could say that the dimension is the minimum number of 
coordinates needed to describe every point in the set. For instance, a smooth curve 
is one-dimensional because every point on it is determined by one number, the arc 
length from some fixed reference point on the curve.
But when we try to apply this definition to fractals, we quickly run into para-
doxes. Consider the von Koch curve, defined recursively in Figure 11.3.1.
We start with a line segment S0. To generate S1, we delete the middle third of S0 
and replace it with the other two sides of an equilateral triangle. Subsequent stages 
are generated recursively by the same rule: Sn is obtained by replacing the middle 
third of each line segment in Sn1 by the other two sides of an equilateral triangle. 
The limiting set K Sd is the von Koch curve.

412 
FRACTALS
S
S
von Koch curve K
S
S
S
0
1
2
3
4
Figure 11.3.1
A Paradox
What is the dimension of the von Koch curve? Since it’s a curve, you might be 
tempted to say it’s one-dimensional. But the trouble is that K has infinite arc length! 
To see this, observe that if the length of S0 is L0, then the length of S1 is L
L
1
4
3
0

,  
because S1 contains four segments, each of length 1
3
0
L .  The length increases by a 
factor of 4
3  at each stage of the construction, so Ln
n
 ( )
4
3
L0 ld as n ld.
Moreover, the arc length between any two points on K is infinite, by similar rea-
soning. Hence points on K aren’t determined by their arc length from a particular 
point, because every point is infinitely far from every other!
This suggests that K is more than one-dimensional. But would we really want to 
say that K is two-dimensional? It certainly doesn’t seem to have any “area.” So the 
dimension should be between 1 and 2, whatever that means.
With this paradox as motivation, we now consider some improved notions of 
dimension that can cope with fractals.

413
11.3 DIMENSION OF SELF-SIMILAR FRACTALS
Similarity Dimension
The simplest fractals are self-similar, i.e., they are made of scaled-down copies 
of themselves, all the way down to arbitrarily small scales. The dimension of such 
fractals can be defined by extending an elementary observation about classical 
self-similar sets like line segments, squares, or cubes. For instance, consider the 
square region shown in Figure 11.3.2.
m
r
=
= 2
4
m
m
number of copies
scale factor
r
r
=
=
=
= 3
9
Figure 11.3.2
If we shrink the square by a factor of 2 in each direction, it takes four of the small 
squares to equal the whole. Or if we scale the original square down by a factor of 3, 
then nine small squares are required. In general, if we reduce the linear dimensions 
of the square region by a factor of r, it takes r2 of the smaller squares to equal the 
original.
Now suppose we play the same game with a solid cube. The results are differ-
ent: if we scale the cube down by a factor of 2, it takes eight of the smaller cubes to 
make up the original. In general, if the cube is scaled down by r, we need r3 of the 
smaller cubes to make up the larger one.
The exponents 2 and 3 are no accident; they reflect the two-dimensionality of the 
square and the three-dimensionality of the cube. This connection between dimen-
sions and exponents suggests the following definition. Suppose that a self-similar 
set is composed of m copies of itself scaled down by a factor of r. Then the similar-
ity dimension d is the exponent defined by m r d, or equivalently,
d
m
r
 ln
ln
.
This formula is easy to use, since m and r are usually clear from inspection.
EXAMPLE 11.3.1:
Find the similarity dimension of the Cantor set C.

414 
FRACTALS
Solution: As shown in Figure 11.3.3, C is composed of two copies of itself, each 
scaled down by a factor of 3.
The left half of the Cantor set
is the original Cantor set,
scaled down by a factor of 3
[0, 1]
C
Figure 11.3.3
So m 2 when r 3. Therefore d ln 2ln 3 x 0.63. ■
In the next example we confirm our earlier intuition that the von Koch curve 
should have a dimension between 1 and 2.
EXAMPLE 11.3.2:
Show that the von Koch curve has a similarity dimension of ln 4ln 3 x 1.26.
Solution: The curve is made up of four equal pieces, each of which is similar 
to the original curve but is scaled down by a factor of 3 in both directions. One of 
these pieces is indicated by the arrows in Figure 11.3.4.
Figure 11.3.4
Hence m 4 when r 3, and therefore d ln 4ln 3. ■
More General Cantor Sets
Other self-similar fractals can be generated by changing the recursive proce-
dure. For instance, to obtain a new kind of Cantor set, divide an interval into five 
equal pieces, delete the second and fourth subintervals, and then repeat this pro-
cess indefinitely (Figure 11.3.5).
Figure 11.3.5

415
11.3 DIMENSION OF SELF-SIMILAR FRACTALS
We call the limiting set the even-fifths Cantor set, since the even fifths are removed 
at each stage. (Similarly, the standard Cantor set of Section 11.2 is often called the 
middle-thirds Cantor set.)
EXAMPLE 11.3.3:
Find the similarity dimension of the even-fifths Cantor set.
Solution: Let the original interval be denoted S0, and let Sn denote the nth stage 
of the construction. If we scale Sn down by a factor of five, we get one third of the 
set Sn1. Now setting n d, we see that the even-fifths Cantor set Sd is made of 
three copies of itself, shrunken by a factor of 5. Hence m 3 when r  5, and so 
d ln 3ln 5. ■
There are so many different Cantor-like sets that mathematicians have 
abstracted their essence in the following definition. A closed set S is called a topo-
logical Cantor set if it satisfies the following properties:
1. S is “totally disconnected.” This means that S contains no connected 
subsets (other than single points). In this sense, all points in S are 
separated from each other. For the middle-thirds Cantor set and other 
subsets of the real line, this condition simply says that S contains no 
intervals.
2. On the other hand, S contains no “isolated points.” This means that 
every point in S has a neighbor arbitrarily close by—given any point 
p  S and any small distance F 0, there is some other point q  S 
within a distance F of p.
The paradoxical aspects of Cantor sets arise because the first property says 
that points in S are spread apart, whereas the second property says they’re packed 
together! In Exercise 11.3.6, you’re asked to check that the middle-thirds Cantor set 
satisfies both properties.
Notice that the definition says nothing about self-similarity or dimension. 
These notions are geometric rather than topological; they depend on concepts of 
distance, volume, and so on, which are too rigid for some purposes. Topological 
features are more robust than geometric ones. For instance, if we continuously 
deform a self-similar Cantor set, we can easily destroy its self-similarity but prop-
erties 1 and 2 will persist. When we study strange attractors in Chapter 12, we’ll 
see that the cross sections of strange attractors are often topological Cantor sets, 
although they are not necessarily self-similar.

416 
FRACTALS
11.4 Box Dimension
To deal with fractals that are not self-similar, we need to generalize our notion 
of dimension still further. Various definitions have been proposed; see Falconer 
(1990) for a lucid discussion. All the definitions share the idea of “measurement at a 
scale F”—roughly speaking, we measure the set in a way that ignores irregularities 
of size less than F, and then study how the measurements vary as F l 0.
Definition of Box Dimension
One kind of measurement involves covering the set with boxes of size  F 
(Figure 11.4.1).
N
N
2
L
A
{
ε
ε
ε
ε
ε
∝
∝
(   ) 
(   ) 
Figure 11.4.1
Let S be a subset of D-dimensional Euclidean space, and let N ( F ) be the minimum 
number of D-dimensional cubes of side F needed to cover S. How does N ( F ) depend 
on F? To get some intuition, consider the classical sets shown in Figure 11.4.1. For 
a smooth curve of length L, N ( F ) r L / F; for a planar region of area A bounded by 
a smooth curve, N ( F ) r A / F2. The key observation is that the dimension of the set 
equals the exponent d in the power law N ( F ) r 1 / Fd.
This power law also holds for most fractal sets S, except that d is no longer an 
integer. By analogy with the classical case, we interpret d as a dimension, usually 
called the capacity or box dimension of S. An equivalent definition is
d
N
=
→
lim ln
( )
ln( / ) ,
F
F
F
0
1
 if the limit exists.
EXAMPLE 11.4.1:
Find the box dimension of the Cantor set.
Solution: Recall that the Cantor set is covered by each of the sets Sn used in its 
construction (Figure 11.2.1). Each Sn consists of 2 n intervals of length  ( 1 / 3 ) n, so if 
we pick F  ( 1 / 3 ) n, we need all 2 n of these intervals to cover the Cantor set. Hence 
N 2 n when F  ( 1 / 3 ) n. Since F l0 as n ld, we find 

417
11.4 BOX DIMENSION
d
N
n
n
n
n
=
=
=
=
→
lim ln
( )
ln( / )
ln(
)
ln(
)
ln
ln
ln
ln
F
F
F
0
1
2
3
2
3
2
3
in agreement with the similarity dimension found in Example 11.3.1. ■
This solution illustrates a helpful trick. We used a discrete sequence F   ( 1 / 3 ) n 
that tends to zero as n ld, even though the definition of box dimension says that 
we should let F l0 continuously. If F v  ( 1 / 3 ) n, the covering will be slightly waste-
ful— some boxes hang over the edge of the set—but the limiting value of d is the 
same.
EXAMPLE 11.4.2:
A fractal that is not self-similar is constructed as follows. A square region is 
divided into nine equal squares, and then one of the small squares is selected at 
random and discarded. Then the process is repeated on each of the eight remain-
ing small squares, and so on. What is the box dimension of the limiting set?
Solution: Figure 11.4.2 shows the first two stages in a typical realization of this 
random construction.
S
S
1
2
Figure 11.4.2
Pick the unit of length to equal the side of the original square. Then S1 is covered 
(with no wastage) by N 8 squares of side F  1
3.  Similarly, S2 is covered by N 82 
squares of side F  ( ) .
1
3
2  In general, N 8n when F  ( ) .
1
3
n  Hence
d
N
n
n
n
n
=
=
=
=
→
lim ln
( )
ln( / )
ln(
)
ln(
)
ln
ln
ln
ln .
F
F
F
0
1
8
3
8
3
8
3  ■
Critique of Box Dimension
When computing the box dimension, it is not always easy to find a minimal 
cover. There’s an equivalent way to compute the box dimension that avoids this 
problem. We cover the set with a square mesh of boxes of side F, count the number 
of occupied boxes N ( F ), and then compute d as before.
Even with this improvement, the box dimension is rarely used in practice. Its com-
putation requires too much storage space and computer time, compared to other 

418 
FRACTALS
types of fractal dimension (see below). The box dimension also suffers from some 
mathematical drawbacks. For example, its value is not always what it should be: the 
set of rational numbers between 0 and 1 can be proven to have a box dimension of 1 
(Falconer 1990, p. 44), even though the set has only countably many points.
Falconer (1990) discusses other fractal dimensions, the most important of which 
is the Hausdorff dimension. It is more subtle than the box dimension. The main con-
ceptual difference is that the Hausdorff dimension uses coverings by small sets of 
varying sizes, not just boxes of fixed size F. It has nicer mathematical properties than 
the box dimension, but unfortunately it is even harder to compute numerically.
11.5 Pointwise and Correlation Dimensions
Now it’s time to return to dynamics. Suppose that we’re studying a chaotic system 
that settles down to a strange attractor in phase space. Given that strange attrac-
tors typically have fractal microstructure (as we’ll see in Chapter 12), how could we 
estimate the fractal dimension?
First we generate a set of very many points {xi , i l, . . . , n} on the attractor 
by letting the system evolve for a long time (after taking care to discard the initial 
transient, as usual). To get better statistics, we could repeat this procedure for sev-
eral different trajectories. In practice, however, almost all trajectories on a strange 
attractor have the same long-term statistics so it’s sufficient to run one trajectory 
for an extremely long time. Now that we have many points on the attractor, we 
could try computing the box dimension, but that approach is impractical, as men-
tioned earlier.
Grassberger and Procaccia (1983) proposed a more efficient approach that has 
become standard. Fix a point x on the attractor A. Let Nx ( F) denote the number 
of points on A inside a ball of radius F about x (Figure 11.5.1).
Ball of radius
centered at x
ε
Figure 11.5.1

419
11.5 POINTWISE AND CORRELATION DIMENSIONS
Most of the points in the ball are unrelated to the immediate portion of the trajec-
tory through x; instead they come from later parts that just happen to pass close 
to x. Thus Nx ( F ) measures how frequently a typical trajectory visits an F neighbor-
hood of x.
Now vary F. As F increases, the number of points in the ball typically grows as 
a power law:
Nx ( F ) r Fd,
where d is called the pointwise dimension at x. The pointwise dimension can depend 
significantly on x; it will be smaller in rarefied regions of the attractor. To get an 
overall dimension of A, one averages Nx ( F ) over many x. The resulting quantity 
C ( F ) is found empirically to scale as
C ( F ) r Fd,
where d is called the correlation dimension.
The correlation dimension takes account of the density of points on the attrac-
tor, and thus differs from the box dimension, which weights all occupied boxes 
equally, no matter how many points they contain. (Mathematically speaking, the 
correlation dimension involves an invariant measure supported on a fractal, not 
just the fractal itself.) In general, dcorrelation bdbox, although they are usually very 
close (Grassberger and Procaccia 1983).
To estimate d, one plots log C ( F ) vs. log F. If the relation C ( F ) r Fd were valid 
for all F, we’d find a straight line of slope d. In practice, the power law holds only 
over an intermediate range of F (Figure 11.5.2).
ln
slope
ln
C
d
ε
≈
Figure 11.5.2
The curve saturates at large F because the F-balls engulf the whole attractor and so 
Nx ( F ) can grow no further. On the other hand, at extremely small F, the only point 
in each F-ball is x itself. So the power law is expected to hold only in the scaling 
region where
(minimum separation of points on A) F (diameter of A).

420 
FRACTALS
EXAMPLE 11.5.1:
Estimate the correlation dimension of the Lorenz attractor, for the standard 
parameter values r 28, T 10, b  8
3.
Solution: Figure 11.5.3 shows the results of Grassberger and Procaccia (1983). 
(Note that in their notation, the radius of the balls is A and the correlation dimen-
sion is v.) A line of slope dcorr 2.05 o 0.01 gives an excellent fit to the data, except 
for large F, where the expected saturation occurs.
0
−5
−10
−15
−20
−25
0
5 
10
arbitrary
15
log
Lorenz
2.05 .01
±
eqs
v =
log
C(1)
2
2
0
0
(
(
)
)
1/1
1
Figure 11.5.3 Grassberger and Procaccia  (1983 ) , p.196
These results were obtained by numerically integrating the system with a Runge–
Kutta method. The time step was 0.25, and 15,000 points were computed. 
Grassberger and Procaccia also report that the convergence was rapid; the cor-
relation dimension could be estimated to within o5 percent using only a few thou-
sand points. ■
EXAMPLE 11.5.2:
Consider the logistic map xn1 rxn ( 1  xn ) at the parameter value 
r  rd  3.5699456 . . . , corresponding to the onset of chaos. Show that the  

421
11.5 POINTWISE AND CORRELATION DIMENSIONS
attractor is a Cantor-like set, although it is not strictly self-similar. Then compute 
its correlation dimension numerically.
Solution: We visualize the attractor by building it up recursively. Roughly 
speaking, the attractor looks like a 2 n-cycle, for n 1. Figure 11.5.4 schemati-
cally shows some typical 2 n-cycles for small values of n.
x
r
Figure 11.5.4
The dots in the left panel of Figure  11.5.4 represent the superstable 2 n-cycles. 
The right panel shows the corresponding values of x. As n ld, the resulting set 
approaches a topological Cantor set, with points separated by gaps of various sizes. 
But the set is not strictly self-similar—the gaps scale by different factors depend-
ing on their location. In other words, some of the “wishbones” in the orbit dia-
gram are wider than others at the same r. (We commented on this nonuniformity in 
Section 10.6, after viewing the computer-generated orbit diagrams of Figure 10.6.2.) 
The correlation dimension of the limiting set has been estimated by Grassberger 
and Procaccia (1983). They generated a single trajectory of 30,000 points, starting 
from x0
1
2
 . Their plot of log C ( F ) vs. log F is well fit by a straight line of slope 
dcorr 0.500 o 0.005 (Figure 11.5.5).
Log C(l)
2
−10
10
20
30
40
−20
0
0
Logistic
map
r
3.56994
r
=
=
∞
arbitrary
Log2
0
0
(
(
)
)
1/1
1
v = 0.500 ±.005
Figure 11.5.5 Grassberger and Procaccia  (1983 ), p.193

422 
FRACTALS
This is smaller than the box dimension dbox x 0.538 (Grassberger 1981), as 
expected. ■
For very small F, the data in Figure  11.5.5 deviate from a straight line. 
Grassberger and Procaccia (1983) attribute this deviation to residual correlations 
among the xn’s on their single trajectory. These correlations would be negligible if 
the map were strongly chaotic, but for a system at the onset of chaos (like this one), 
the correlations are visible at small scales. To extend the scaling region, one could 
use a larger number of points or more than one trajectory.
Multifractals
We conclude by mentioning a more refined concept, although we cannot go into 
details. In the logistic attractor of Example 11.5.2, the scaling varies from place to 
place, unlike in the middle-thirds Cantor set, where there is a uniform scaling by 
1
3  everywhere. Thus we cannot completely characterize the logistic attractor by its 
dimension, or any other single number—we need some kind of distribution func-
tion that tells us how the dimension varies across the attractor. Sets of this type are 
called multifractals.
The notion of pointwise dimension allows us to quantify the local variations 
in scaling. Given a multifractal A, let SB be the subset of A consisting of all points 
with pointwise dimension B. If B is a typical scaling factor on A, then it will be 
represented often, so SB will be a relatively large set; if B is unusual, then SB will 
be a small set. To be more quantitative, we note that each SB is itself a fractal, so it 
makes sense to measure its “size” by its fractal dimension. Thus, let  f ( B ) denote 
the dimension of SB. Then  f  ( B ) is called the multifractal spectrum of A or the 
spectrum of scaling indices (Halsey et al. 1986).
Roughly speaking, you can think of the multifractal as an interwoven set of 
fractals of different dimensions B, where  f  ( B ) measures their relative weights. 
Since very large and very small B are unlikely, the shape of  f  ( B ) typically looks 
like Figure 11.5.6. The maximum value of  f  ( B ) turns out to be the box dimension 
(Halsey et al. 1986).
f
dbox
(α)
α
Figure 11.5.6
For systems at the onset of chaos, multifractals lead to a more powerful version of 
the universality theory mentioned in Section 10.6. The universal quantity is now a 

423
EXERCISES
function  f  ( B ), rather than a single number; it therefore offers much more informa-
tion, and the possibility of more stringent tests. The theory’s predictions have been 
checked for a variety of experimental systems at the onset of chaos, with striking 
success. See Glazier and Libchaber (1988) for a review. On the other hand, we still 
lack a rigorous mathematical theory of multifractals; see Falconer (1990) for a dis-
cussion of the issues.
EXERCISES FOR CHAPTER 11
11.1 Countable and Uncountable Sets
11.1.1 
Why doesn’t the diagonal argument used in Example 11.1.4 show that 
the rationals are also uncountable? (After all, rationals can be represented as 
decimals.)
11.1.2 
Show that the set of odd integers is countable.
11.1.3 
Are the irrational numbers countable or uncountable? Prove your answer.
11.1.4 
Consider the set of all real numbers whose decimal expansion con-
tains only 2’s and 7’s. Using Cantor’s diagonal argument, show that this set is 
uncountable.
11.1.5 
Consider the set of integer lattice points in three-dimensional space, 
i.e., points of the form  ( p,q,r ), where p, q, and r are integers. Show that this set is 
countable.
11.1.6 
(10x mod 1) Consider the decimal shift map xn1 10xn (mod 1).
a) Show that the map has countably many periodic orbits, all of which are unstable.
b) Show that the map has uncountably many aperiodic orbits.
c) An “eventually-fixed point” of a map is a point that iterates to a fixed point 
after a finite number of steps. Thus xn1 xn for all n N, where N is some 
positive integer. Is the number of eventually-fixed points for the decimal shift 
map countable or uncountable?
11.1.7 
Show that the binary shift map xn + 1 2xn (mod 1) has countably many 
periodic orbits and uncountably many aperiodic orbits.
11.2 Cantor Set
11.2.1 
(Cantor set has measure zero) Here’s another way to show that the Cantor 
set has zero total length. In the first stage of construction of the Cantor set, we 
removed an interval of length 1
3  from the unit interval [ 0,1 ]. At the next stage we 
removed two intervals, each of length 1
9 . By summing an appropriate infinite 

424 
FRACTALS
series, show that the total length of all the intervals removed is 1, and hence the 
leftovers (the Cantor set) must have length zero.
11.2.2 
Show that the rational numbers have zero measure. (Hint: Make a list of 
the rationals. Cover the first number with an interval of length F, cover the second 
with an interval of length 1
2 F. Now take it from there.)
11.2.3 
Show that any countable subset of the real line has zero measure. (This 
generalizes the result of the previous question.)
11.2.4 
Consider the set of irrational numbers between 0 and 1.
a) What is the measure of the set?
b) Is it countable or uncountable?
c) Is it totally disconnected?
d) Does it contain any isolated points?
11.2.5 
(Base-3 and the Cantor set)
a) Find the base-3 expansion of 1 / 2.
b) Find a one-to-one correspondence between the Cantor set C and the interval 
[ 0,1 ]. In other words, find an invertible mapping that pairs each point c  C with 
precisely one x  [ 0,1 ].
c) Some of my students have thought that the Cantor set is “all endpoints”—they 
claimed that any point in the set is the endpoint of some sub-interval involved 
in the construction of the set. Show that this is false by explicitly identifying a 
point in C that is not an endpoint.
11.2.6 
(Devil’s staircase) Suppose that we pick a point at random from the Cantor 
set. What’s the probability that this point lies to the left of x, where 0 bx b1 
is some fixed number? The answer is given by a function P ( x ) called the devil’s 
staircase.
a) It is easiest to visualize P ( x ) by building it up in stages. First consider the set S0 
in Figure 11.2.1. Let P0 ( x ) denote the probability that a randomly chosen point 
in S0 lies to the left of x. Show that P0 ( x ) x.
b) Now consider S1 and define P1 ( x ) analogously. Draw the graph of P1 ( x ).  (Hint: 
It should have a plateau in the middle.)
c) Draw the graphs of Pn ( x ), for n 2,3,4. Be careful about the widths and heights 
of the plateaus.
d) The limiting function Pd ( x ) is the devil’s staircase. Is it continuous? What 
would a graph of its derivative look like?
Like other fractal concepts, the devil’s staircase was long regarded as a 
mathematical curiosity. But recently it has arisen in physics, in connection 
with mode-locking of nonlinear oscillators. See Bak (1986) for an entertaining 
introduction.

425
EXERCISES
11.3 Dimension of Self-Similar Fractals
11.3.1 
(Middle-halves Cantor set) Construct a new kind of Cantor set by remov-
ing the middle half of each sub-interval, rather than the middle third.
a) Find the similarity dimension of the set.
b) Find the measure of the set.
11.3.2 
(Generalized Cantor set) Consider a generalized Cantor set in which we 
begin by removing an open interval of length 0 a 1 from the middle of [ 0,1 ]. 
At subsequent stages, we remove an open middle interval (whose length is the 
same fraction a) from each of the remaining intervals, and so on. Find the similar-
ity dimension of the limiting set.
11.3.3 
(Generalization of even-fifths Cantor set) The “even-sevenths Cantor set” 
is constructed as follows: divide [ 0,1 ] into seven equal pieces; delete pieces 2, 4, and 
6; and repeat on sub-intervals.
a) Find the similarity dimension of the set.
b) Generalize the construction to any odd number of pieces, with the even ones 
deleted. Find the similarity dimension of this generalized Cantor set.
11.3.4 
(No odd digits) Find the similarity dimension of the subset of [ 0,1 ] con-
sisting of real numbers with only even digits in their decimal expansion.
11.3.5 
(No 8’s) Find the similarity dimension of the subset of [ 0,1 ] consisting of 
real numbers that can be written without the digit 8 appearing anywhere in their 
decimal expansion.
11.3.6 
Show that the middle-thirds Cantor set contains no intervals. But also 
show that no point in the set is isolated.
11.3.7 
(Snowflake) To construct the famous fractal known as the von Koch snow-
flake curve, use an equilateral triangle for S0. Then do the von Koch procedure of 
Figure 11.3.1 on each of the three sides.
a) Show that S1 looks like a star of David.
b) Draw S2 and S3.
c) The snowflake is the limiting curve S Sd. Show that it has infinite arc length.
d) Find the area of the region enclosed by S.
e) Find the similarity dimension of S.
The snowflake curve is continuous but nowhere differentiable—loosely speak-
ing, it is “all corners”!
11.3.8 
(Sierpinski carpet) Consider the process shown in Figure 1. The closed 
unit box is divided into nine equal boxes, and the open central box is deleted. 

426 
FRACTALS
Then this process is repeated for each of the eight remaining sub-boxes, and so on. 
Figure 1 shows the first two stages.
a) Sketch the next stage S3.
b) Find the similarity dimension of the limiting fractal, known as the Sierpinski 
carpet.
c) Show that the Sierpinski carpet has zero area.
S
S
1
2
Figure 1
11.3.9 
(Sponges) Generalize the previous exercise to three dimensions—start 
with a solid cube, and divide it into 27 equal sub-cubes. Delete the central cube on 
each face, along with the central cube. (If you prefer, you could imagine drilling 
three mutually orthogonal square holes through the centers of the faces.) Infinite 
iteration of this process yields a fractal called the Menger sponge. Find its similar-
ity dimension. Repeat for the Menger hypersponge in N dimensions, if you dare.
11.3.10 (Fat fractal) A fat fractal is a fractal with a nonzero measure. Here’s a 
simple example: start with the unit interval [ 0,1 ] and delete the open middle 1 / 2, 
1 / 4, 1 / 8, etc., of each remaining sub-interval. (Thus a smaller and smaller fraction 
is removed at each stage, in contrast to the middle-thirds Cantor set, where we 
always remove 1 / 3 of what’s left.)
a) Show that the limiting set is a topological Cantor set.
b) Show that the measure of the limiting set is greater than zero. Find its exact 
value if you can, or else just find a lower bound for it.
Fat fractals answer a fascinating question about the logistic map. Farmer (1985) 
has shown numerically that the set of parameter values for which chaos occurs is 
a fat fractal. In particular, if r is chosen at random between rd and r 4, there is 
about an 89% chance that the map will be chaotic. Farmer’s analysis also suggests 
that the odds of making a mistake (calling an orbit chaotic when it’s actually peri-
odic) are about one in a million, if we use double precision arithmetic!
11.4 Box Dimension
Find the box dimension of the following sets.
11.4.1 
von Koch snowflake (see Exercise 11.3.7)

427
EXERCISES
11.4.2 
Sierpinski carpet (see Exercise 11.3.8)
11.4.3 
Menger sponge (see Exercise 11.3.9)
11.4.4 
The Cartesian product of the middle-thirds Cantor set with itself.
11.4.5 
Menger hypersponge (see Exercise 11.3.9)
11.4.6 
(A strange repeller for the tent map) The tent map on the interval [ 0,1 ] is 
defined by xn1 f  ( xn ), where
f x
rx
x
r
x
x
( )
,
(
),
=
≤
≤
−
≤
≤
⎧
⎨
⎪⎪
⎩⎪⎪
        
0
1
1
1
2
1
2
and r 0. In this exercise we assume r 2. Then some points get mapped outside 
the interval [ 0,1 ]. If  f  ( x0 ) 1 then we say that x0 has “escaped” after one itera-
tion. Similarly, if  f  n ( x0 ) 1 for some finite n, but  f  k ( x0 )  [ 0,1 ] for all k n, then 
we say that x0 has escaped after n iterations.
a) Find the set of initial conditions x0 that escape after one or two iterations.
b) Describe the set of x0 that never escape.
c) Find the box dimension of the set of x0 that never escape. (This set is called the 
invariant set.)
d) Show that the Liapunov exponent is positive at each point in the invariant set. 
The invariant set is called a strange repeller, for several reasons: it has a fractal 
structure; it repels all nearby points that are not in the set; and points in the set hop 
around chaotically under iteration of the tent map.
11.4.7 
(A lopsided fractal) Divide the closed unit interval [ 0,1 ] into four quar-
ters. Delete the open second quarter from the left. This produces a set S1. Repeat 
this construction indefinitely; i.e., generate Sn1 from Sn by deleting the second 
quarter of each of the intervals in Sn.
a) Sketch the sets S1, . . . ,S4.
b) Compute the box dimension of the limiting set Sd.
c) Is Sd self-similar?
11.4.8 
(A thought question about random fractals) Redo the previous question, 
except add an element of randomness to the process: to generate Sn + 1 from Sn, 
flip a coin; if the result is heads, delete the second quarter of every interval in Sn; if 
tails, delete the third quarter. The limiting set is an example of a random fractal.
a) Can you find the box dimension of this set? Does this question even make sense? 
In other words, might the answer depend on the particular sequence of heads 
and tails that happen to come up?
b) Now suppose if tails comes up, we delete the first quarter. Could this make a 
difference? For instance, what if we had a long string of tails?
See Falconer (1990, Chapter 15) for a discussion of random fractals.

428 
FRACTALS
11.4.9 
(Fractal cheese) A fractal slice of swiss cheese is constructed as follows: 
The unit square is divided into p 2 squares, and m 2 squares are chosen at random 
and discarded. (Here p m 1, and p, m are positive integers.) The process is 
repeated for each remaining square (side 1 / p ). Assuming that this process is 
repeated indefinitely, find the box dimension of the resulting fractal. (Notice that 
the resulting fractal may or may not be self-similar, depending on which squares 
are removed at each stage. Nevertheless, we are still able to calculate the box 
dimension.)
11.4.10 (Fat fractal) Show that the fat fractal constructed in Exercise 11.3.10 has 
box dimension equal to 1.
11.5 Pointwise and Correlation Dimensions
11.5.1 
(Project) Write a program to compute the correlation dimension of the 
Lorenz attractor. Reproduce the results in Figure 11.5.3. Then try other values of 
r. How does the dimension depend on r?

429
12.1 THE SIMPLEST EXAMPLES
12
STRANGE ATTRACTORS
12.0 Introduction
Our work in the previous three chapters has revealed quite a bit about chaotic sys-
tems, but something important is missing: intuition. We know what happens but 
not why it happens. For instance, we don’t know what causes sensitive dependence 
on initial conditions, nor how a differential equation can generate a fractal attrac-
tor. Our first goal is to understand such things in a simple, geometric way.
These same issues confronted scientists in the mid-1970s. At the time, the only 
known examples of strange attractors were the Lorenz attractor (1963) and some 
mathematical constructions of Smale  (1967). Thus there was a need for other 
concrete examples, preferably as transparent as possible. These were supplied by 
Hénon (1976) and Rössler (1976), using the intuitive concepts of stretching and 
folding. These topics are discussed in Sections 12.1–12.3. The chapter concludes 
with experimental examples of strange attractors from chemistry and mechanics. 
In addition to their inherent interest, these examples illustrate the techniques of 
attractor reconstruction and Poincaré sections, two standard methods for analyz-
ing experimental data from chaotic systems.
12.1 The Simplest Examples
Strange attractors have two properties that seem hard to reconcile. Trajectories on 
the attractor remain confined to a bounded region of phase space, yet they sepa-
rate from their neighbors exponentially fast (at least initially). How can trajectories 
diverge endlessly and yet stay bounded?
The basic mechanism involves repeated stretching and folding. Consider a small 
blob of initial conditions in phase space (Figure 12.1.1).

430 
STRANGE ATTRACTORS
Figure 12.1.1
A strange attractor typically arises when the flow contracts the blob in some direc-
tions (reflecting the dissipation in the system) and stretches it in others (leading to 
sensitive dependence on initial conditions). The stretching cannot go on forever—
the distorted blob must be folded back on itself to remain in the bounded region. 
To illustrate the effects of stretching and folding, we consider a domestic 
example. 
Making Pastry
Figure 12.1.2 shows a process used to make filo pastry or croissant.
dough
flatten and stretch
re-inject
fold
Figure 12.1.2
The dough is rolled out and flattened, then folded over, then rolled out again, and 
so on. After many repetitions, the end product is a flaky, layered structure—the 
culinary analog of a fractal attractor.
Furthermore, the process shown in Figure 12.1.2 automatically generates sensi-
tive dependence on initial conditions. Suppose that a small drop of food coloring 
is put in the dough, representing nearby initial conditions. After many iterations 
of stretching, folding, and re-injection, the coloring will be spread throughout the 
dough.
Figure 12.1.3 presents a more detailed view of this pastry map, here modeled as 
a continuous mapping of a rectangle into itself.

431
12.1 THE SIMPLEST EXAMPLES
c
c
d
d
a
S1
S2
S3
a
b
b
'
'
'
'
Figure 12.1.3
The rectangle abcd is flattened, stretched, and folded into the horseshoe aabacada, 
also shown as S1. In the same way, S1 is itself flattened, stretched, and folded into 
S2, and so on. As we go from one stage to the next, the layers become thinner and 
there are twice as many of them.
Now try to picture the limiting set Sd. It consists of infinitely many smooth 
layers, separated by gaps of various sizes. In fact, a vertical cross section through 
the middle of Sd would resemble a Cantor set! Thus Sd is (locally) the product of 
a smooth curve with a Cantor set. The fractal structure of the attractor is a conse-
quence of the stretching and folding that created Sd in the first place.
Terminology
The transformation shown in Figure 12.1.3 is normally called a horseshoe map, 
but we have avoided that name because it encourages confusion with another 
horseshoe map (the Smale horseshoe), which has very different properties. In par-
ticular, Smale’s horseshoe map does not have a strange attractor; its invariant set 
is more like a strange saddle. The Smale horseshoe is fundamental to rigorous 
discussions of chaos, but its analysis and significance are best deferred to a more 
advanced course. See Exercise 12.1.7 for an introduction, and Guckenheimer and 
Holmes (1983) or Arrowsmith and Place (1990) for detailed treatments.
Because we want to reserve the word horseshoe for Smale’s mapping, we have 
used the name pastry map for the mapping above. A better name would be “the 
baker’s map” but that name is already taken by the map in the following example.
EXAMPLE 12.1.1:
The baker’s map B of the square 0 bx bl, 0 by bl to itself is given by

432 
STRANGE ATTRACTORS
(
,
)
(
,
)
(
,
x
y
x
ay
x
x
ay
n
n
n
n
n
n
n
+
+
=
≤
≤
−
+
1
1
1
2
1
2
2
0
2
1
 
           
for 
 
)
for 1
2
1
≤
≤
⎧
⎨
⎪⎪
⎩⎪⎪
xn
where a is a parameter in the range 0
1
2
<
≤
a
.  Illustrate the geometric action of B 
by showing its effect on a face drawn in the unit square.
Solution: The reluctant experimental subject is shown in Figure 12.1.4a.
(a)
1
0
1
1
2
a
0
(c)
(b)
2
cut and 
stack
flatten and stretch
Figure 12.1.4
As we’ll see momentarily, the transformation may be regarded as a product of two 
simpler transformations. First the square is stretched and flattened into a 2 q a 
rectangle (Figure 12.1.4b). Then the rectangle is cut in half, yielding two 1 q a rect-
angles, and the right half is stacked on top of the left half such that its base is at the 
level y  1
2  (Figure 12.1.4c).
Why is this procedure equivalent to the formulas for B? First consider the left 
half of the square, where 0
1
2
b
b
xn
. Here (
,
)
(
,
)
x
y
x
ay
n
n
n
n
+
+
=
1
1
2
 
, so the hori-
zontal direction is stretched by 2 and the vertical direction is contracted by a, as 
claimed. The same is true for the right half of the rectangle, except that the image 
is shifted left by 1 and up by 1
2 ,  since (
,
)
(
,
)
(
, ).
x
y
x
ay
n
n
n
n
+
+
=
+ −
1
1
1
2
2
1
 
 This shift 
is equivalent to the stacking just claimed. ■
The baker’s map exhibits sensitive dependence on initial conditions, thanks to 
the stretching in the x-direction. It has many chaotic orbits—uncountably many, 
in fact. These and other dynamical properties of the baker’s map are discussed in 
the exercises.
The next example shows that, like the pastry map, the baker’s map has a strange 
attractor with a Cantor-like cross section.

433
12.1 THE SIMPLEST EXAMPLES
EXAMPLE 12.1.2:
Show that for a  1
2 , the baker’s map has a fractal attractor A that attracts all 
orbits. More precisely, show that there is a set A such that for any initial condi-
tion  ( x0, y0 ), the distance from Bn ( x0, y0 ) to A converges to zero as n ld.
Solution: First we construct the attractor. Let S denote the square 0 bx b1, 
0 by b1; this includes all possible initial conditions. The first three images of S 
under the map B are shown as shaded regions in Figure 12.1.5.
B
0
a
1
2
2 + a
1
S)
(
B
S)
(
2
B
S)
(
3
Figure 12.1.5
The first image B ( S ) consists of two strips of height a, as we know from 
Example 12.1.1. Then B ( S ) is flattened, stretched, cut, and stacked to yield B 2 ( S ). 
Now we have four strips of height a 2. Continuing in this way, we see that B n ( S ) 
consists of 2n horizontal strips of height an. The limiting set A Bd ( S ) is a fractal. 
Topologically, it is a Cantor set of line segments.
A technical point: How we can be sure that there actually is a “limiting set”? 
We invoke a standard theorem from point-set topology. Observe that the suc-
cessive images of the square are nested inside each other like Chinese boxes: 
B n + 1 ( S )  B n ( S ) for all n. Moreover each B n ( S ) is a compact set. The theo-
rem (Munkres 1975) assures us that the countable intersection of a nested fam-
ily of compact sets is a non-empty compact set—this set is our A. Furthermore, 
A  B n ( S ) for all n.
The nesting property also helps us to show that A attracts all orbits. The point 
B n ( x0, y0 ) lies somewhere in one of the strips of B n ( S ), and all points in these strips 
are within a distance a n of A, because A is contained in B n ( S ). Since a n l0 as 
n ld, the distance from B n ( x0, y0 ) to A tends to zero as n ld, as required. ■
EXAMPLE 12.1.3:
Find the box dimension of the attractor for the baker’s map with a  1
2 .

434 
STRANGE ATTRACTORS
Solution: The attractor A is approximated by B n ( S ), which consists of 2 n 
strips of height a n and length 1. Now cover A with square boxes of side F a n 
(Figure 12.1.6).
a
0
1
{
n
Figure 12.1.6
Since the strips have length 1, it takes about a n boxes to cover each of them. There 
are 2 n strips altogether, so N x a n q 2 n  ( a / 2 ) n. Thus
d
N
a
a
a
n
n
n
=
=
= +
→
→
−
−
lim ln
ln( )
lim ln[( / )
]
ln(
)
ln
ln .
F
F
0
1
0
1
2
2
1
As a check, note that d l2 as a l 1
2 ; this makes sense because the attractor fills 
an increasingly large portion of square S as a l 1
2 . ■
The Importance of Dissipation
For a  1
2 , the baker’s map shrinks areas in phase space. Given any region R in 
the square,
area ( B ( R )) area ( R ).
This result follows from elementary geometry. The baker’s map elongates R by a 
factor of 2 and flattens it by a factor of a, so area ( B ( R )) 2a q area ( R ). Since 
a  1
2  by assumption, area ( B ( R )) area ( R ) as required. (Note that the cutting 
operation does not change the region’s area.)
Area contraction is the analog of the volume contraction that we found for the 
Lorenz equations in Section 9.2. As in that case, it yields several conclusions. For 
instance, the attractor A for the baker’s map must have zero area. Also, the baker’s 
map cannot have any repelling fixed points, since such points would expand area 
elements in their neighborhood.
In contrast, when a  1
2  the baker’s map is area-preserving: area ( B ( R )) 
area ( R ). Now the square S is mapped onto itself, with no gaps between the 
strips. The map has qualitatively different dynamics in this case. Transients never 

435
12.2 HÉNON MAP
decay—the orbits shuffle around endlessly in the square but never settle down to a 
lower-dimensional attractor. This is a kind of chaos that we have not seen before!
This distinction between a  1
2  and a  1
2  exemplifies a broader theme in non-
linear dynamics. In general, if a map or flow contracts volumes in phase space, it 
is called dissipative. Dissipative systems commonly arise as models of physical sit-
uations involving friction, viscosity, or some other process that dissipates energy. 
In contrast, area-preserving maps are associated with conservative systems, par-
ticularly with the Hamiltonian systems of classical mechanics.
The distinction is crucial because area-preserving maps cannot have attractors 
(strange or otherwise). As defined in Section 9.3, an “attractor” should attract all 
orbits starting in a sufficiently small open set containing it; that requirement is 
incompatible with area-preservation.
Several of the exercises give a taste of the new phenomena that arise in 
area-preserving maps. To learn more about the fascinating world of Hamiltonian 
chaos, see the review articles by Jensen (1987) or Hénon (1983), or the books by 
Tabor (1989) or Lichtenberg and Lieberman (1992).
12.2 Hénon Map
In this section we discuss another two-dimensional map with a strange attractor. It 
was devised by the theoretical astronomer Michel Hénon (1976) to illuminate the 
microstructure of strange attractors.
According to Gleick (1987, p. 149), Hénon became interested in the problem 
after hearing a lecture by the physicist Yves Pomeau, in which Pomeau described 
the numerical difficulties he had encountered in trying to resolve the tightly packed 
sheets of the Lorenz attractor. The difficulties stem from the rapid volume contrac-
tion in the Lorenz system: after one circuit around the attractor, a volume in phase 
space is typically squashed by a factor of about 14,000 (Lorenz 1963).
Hénon had a clever idea. Instead of tackling the Lorenz system directly, he 
sought a mapping that captured its essential features but which also had an adjust-
able amount of dissipation. Hénon chose to study mappings rather than differ-
ential equations because maps are faster to simulate and their solutions can be 
followed more accurately and for a longer time.
The Hénon map is given by
x
y
ax
y
bx
n
n
n
n
n
+
+
=
+ −
=
1
2
1
1
,
,  
(1)
where a and b are adjustable parameters. Hénon (1976) arrived at this map by 
an elegant line of reasoning. To simulate the stretching and folding that occurs 
in the Lorenz system, he considered the following chain of transformations 
(Figure 12.2.1).

436 
STRANGE ATTRACTORS
y
y
y
y
x
x
(a)
(b)
(c)
(d)
x
x
′
′′
′′
′′
′′′
′′′
Figure 12.2.1
Start with a rectangular region elongated along the x-axis (Figure 12.2.1a). Stretch 
and fold the rectangle by applying the transformation
T a:  xa x, 
ya 1 y  ax 2.
(The primes denote iteration, not differentiation.) The bottom and top of the rect-
angle get mapped to parabolas (Figure 12.2.1b). The parameter a controls the fold-
ing. Now fold the region even more by contracting Figure 12.2.1b along the x-axis:
′′
′′ =
′
′′ =
′
T
x
bx
y
y
:
,
where 1 b 1. This produces Figure 12.2.1c. Finally, come back to the orienta-
tion along the x-axis by reflecting across the line y x (Figure 12.2.1d):
′′′
′′′ =
′′
′′′ =
′′
T
x
y
y
x
:
,
.
Then the composite transformation T
T T T
=
′′′
′′
′  yields the Hénon mapping (1), 
where we use the notation  ( xn, yn ) for  ( x, y ) and  ( xn1, yn+ 1 ) for (
,
).
aaa
aaa
x
y
Elementary Properties of the Hénon Map
As desired, the Hénon map captures several essential properties of the Lorenz 
system. (These properties will be verified in the examples below and in the 
exercises.)
1. The Hénon map is invertible. This property is the counterpart of the 
fact that in the Lorenz system, there is a unique trajectory through 
each point in phase space. In particular, each point has a unique 
past. In this respect the Hénon map is superior to the logistic map, its 
one-dimensional analog. The logistic map stretches and folds the unit 
interval, but it is not invertible since all points (except the maximum) 
come from two pre-images.
2. The Hénon map is dissipative. It contracts areas, and does so at the 
same rate everywhere in phase space. This property is the analog of 
constant negative divergence in the Lorenz system.

437
12.2 HÉNON MAP
3. For certain parameter values, the Hénon map has a trapping region. 
In other words, there is a region R that gets mapped inside itself 
(Figure  12.2.2). As in the Lorenz system, the strange attractor is 
enclosed in the trapping region.
0.6
0.4
0.2
0
−0.2
−0.4
−0.6
−1.5
−1
−0.5
0
0.5
1
1.5
T(R)
R
x
y
Figure 12.2.2
The next property highlights an important difference between the 
Hénon map and the Lorenz system.
4. Some trajectories of the Hénon map escape to infinity. In contrast, all 
trajectories of the Lorenz system are bounded; they all eventually enter 
and stay inside a certain large ellipsoid (Exercise 9.2.2). But it is not 
surprising that the Hénon map has some unbounded trajectories; far 
from the origin, the quadratic term in (1) dominates and repels orbits 
to infinity. Similar behavior occurs in the logistic map—recall that 
orbits starting outside the unit interval eventually become unbounded.
Now we verify properties 1 and 2. For 3 and 4, see Exercises 12.2.9 and 12.2.10.
EXAMPLE 12.2.1:
Show that the Hénon map T is invertible if b v 0, and find the inverse T 1.
Solution: We solve (1) for xn and yn, given xn1 and yn1. Algebra yields 
xn b 1yn1,  yn xn1 1 ab 2 ( yn1 ) 2. Thus T1 exists for all b v 0. ■

438 
STRANGE ATTRACTORS
EXAMPLE 12.2.2:
Show that the Hénon map contracts areas if 1 b 1.
Solution: To decide whether an arbitrary two-dimensional map xnl   f  ( x n, yn ), 
yn1 g ( xn, yn ) is area-contracting, we compute the determinant of its Jacobian 
matrix
J =
⎛
⎝
⎜⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟⎟⎟
∂
∂
∂
∂
∂
∂
∂
∂
f
x
f
y
g
x
g
y
.
If | det J ( x, y )| 1 for all  ( x, y ), the map is area-contracting.
This rule follows from a fact of multivariable calculus: if J is the Jacobian of 
a two-dimensional map T, then T maps an infinitesimal rectangle at  ( x, y ) with 
area dxdy into an infinitesimal parallelogram with area | det J ( x, y )| dx dy. Thus if 
| det J ( x, y )| 1 everywhere, the map is area-contracting.
For the Hénon map, we have  f  ( x, y ) 1  ax2 y and g ( x, y ) bx. Therefore
J = −
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
2
1
0
ax
b
and det J ( x, y )b for all ( x, y ). Hence the map is area-contracting for 
1 b 1, as claimed. In particular, the area of any region is reduced by a con-
stant factor of | b | with each iteration. ■
Choosing Parameters
The next step is to choose suitable values of the parameters. As Hénon (1976) 
explains, b should not be too close to zero, or else the area contraction will be 
excessive and the fine structure of the attractor will be invisible. But if b is too 
large, the folding won’t be strong enough. (Recall that b plays two roles: it con-
trols the dissipation and produces extra folding in going from Figure 12.2.1b to 
Figure 12.2.1c.) A good choice is b 0.3.
To find a good value of a, Hénon had to do some exploring. If a is too small 
or too large, all trajectories escape to infinity; there is no attractor in these cases. 
(This is reminiscent of the logistic map, where almost all trajectories escape to 
infinity unless 0 br b4.) For intermediate values of a, the trajectories either 
escape to infinity or approach an attractor, depending on the initial conditions. As 
a increases through this range, the attractor changes from a stable fixed point to 
a stable 2-cycle. The system then undergoes a period-doubling route to chaos, fol-
lowed by chaos intermingled with periodic windows. Hénon picked a 1.4, well 
into the chaotic region.

439
12.2 HÉNON MAP
Zooming In on a Strange Attractor
In a striking series of plots, Hénon provided the first direct visualization of the 
fractal structure of a strange attractor. He set a 1.4, b 0.3 and generated the 
attractor by computing ten thousand successive iterates of (1), starting from the 
origin. You really must try this for yourself on a computer. The effect is eerie—the 
points  ( xn, yn ) hop around erratically, but soon the attractor begins to take form, 
“like a ghost out of the mist” (Gleick 1987, p. 150).
The attractor is bent like a boomerang and is made of many parallel curves 
(Figure 12.2.3a).
0.4
0.3
(a)
0.2
0.1
0
−0.1
−0.2
−0.3
−0.4
0.21
0.20
0.19
0.18
0.17
0.16
0.15
0.55
0.60
0.65
0.70
0.625
0.630
0.635
0.640
0.185
0.186
0.187
0.188
0.189
0.190
0.191
(b)
(c)
−1.5
−1.0
−0.5
0
0.5
1.0
1.5
Figure 12.2.3 Hénon  ( 1976 ), pp 74–76
Figure 12.2.3b is an enlargement of the small square of Figure 12.2.3a. The charac-
teristic fine structure of the attractor begins to emerge. There seem to be six paral-
lel curves: a lone curve near the middle of the frame, then two closely spaced curves 
above it, and then three more. If we zoom in on those three curves (Figure 12.2.3c), 
it becomes clear that they are actually six curves, grouped one, two, three, exactly 
as before! And those curves are themselves made of thinner curves in the same 
pattern, and so on. The self-similarity continues to arbitrarily small scales.

440 
STRANGE ATTRACTORS
The Unstable Manifold of the Saddle Point
Figure 12.2.3 suggests that the Hénon attractor is Cantor-like in the transverse 
direction, but smooth in the longitudinal direction. There’s a reason for this. The 
attractor is closely related to a locally smooth object—the unstable manifold of a 
saddle point that sits on the edge of the attractor. To be more precise, Benedicks 
and Carleson (1991) have proven that the attractor is the closure of a branch of the 
unstable manifold; see also Simó (1979).
Hobson (1993) developed a method for computing this unstable manifold to 
very high accuracy. As expected, it is indistinguishable from the strange attrac-
tor. Hobson also presents some enlargements of less familiar parts of the Hénon 
attractor, one of which looks like Saturn’s rings (Figure 12.2.4).
0.382
0.381
0.38
−1.285
−1.28
−1.275
Figure 12.2.4 Courtesy of Dana Hobson
12.3 Rössler System
So far we have used two-dimensional maps to help us understand how stretch-
ing and folding can generate strange attractors. Now we return to differential 
equations. 
In the culinary spirit of the pastry map and the baker’s map, Otto Rössler (1976) 
found inspiration in a taffy-pulling machine. By pondering its action, he was led 
to a system of three differential equations with a simpler strange attractor than 
Lorenz’s. The Rössler system has only one quadratic nonlinearity xz:



x
y
z
y
x
ay
z
b
z x
c
= −−
=
+
=
+
−
(
).
 
(1)

441
12.3 RÖSSLER SYSTEM
We first met this system in Section 10.6, where we saw that it undergoes a peri-
od-doubling route to chaos as c is increased.
Numerical integration shows that 
this system has a strange attractor for 
a b 0.2, c 5.7 (Figure 12.3.1). A 
schematic version of the attractor is 
shown in Figure 12.3.2. Neighboring 
trajectories separate by spiraling out 
(“stretching”), then cross without 
intersecting by going into the third 
dimension (“folding”) and then cir-
culate back near their starting places 
(“re-injection”). We can now see why 
three dimensions are needed for a 
flow to be chaotic.
Let’s consider the schematic pic-
ture in more detail, following the 
visual approach of Abraham and 
Shaw (1983). Our goal is to construct 
a geometric model of the Rössler 
attractor, guided by the stretching, folding, and re-injection seen in numerical 
integrations of the system.
Figure 12.3.3a shows the flow near a typical trajectory. In one direction there’s 
compression toward the attractor, 
and in the other direction there’s 
divergence along the attractor. 
Figure  12.3.3b highlights the 
sheet on which there’s sensitive 
dependence on initial condi-
tions. These are the expanding 
directions along which stretch-
ing takes place. Next the flow 
folds the wide part of the sheet 
in two and then bends it around 
so that it nearly joins the narrow 
part (Figure 12.3.4a). Overall, the 
flow has taken the single sheet 
and produced two sheets after 
one circuit. Repeating the process, those two sheets produce four (Figure 12.3.4b) 
and then those produce eight (Figure 12.3.4c), and so on.
y
x
Figure 12.3.1
Figure 12.3.2 Abraham and Shaw  ( 1983 ), p. 121

442 
STRANGE ATTRACTORS
(a)
(b)
trajectory
divergence
along attractor
compression
toward attractor
Figure 12.3.3
(a)
(b)
(c)
Figure 12.3.4 Abraham and Shaw  ( 1983 ), pp 122–123
In effect, the flow is acting like the pastry transformation, and the phase space is 
acting like the dough! Ultimately the flow generates an infinite complex of tightly 
packed surfaces: the strange attractor. 
Figure 12.3.5 shows a Poincaré section of the attractor. We slice the attractor 
with a plane, thereby exposing its cross section. 
(In the same way, biologists examine complex 
three-dimensional structures by slicing them and 
preparing slides.) If we take a further one-dimen-
sional slice or Lorenz section through the Poincaré 
section, we find an infinite set of points separated 
by gaps of various sizes.
This pattern of dots and gaps is a topological 
Cantor set. Since each dot corresponds to one 
layer of the complex, our model of the Rössler 
attractor is a Cantor set of surfaces. More pre-
cisely, the attractor is locally topologically equiv-
alent to the Cartesian product of a ribbon and 
a Cantor set. This is precisely the structure we 
would expect, based on our earlier work with the 
pastry map.
LORENZ
POINCARÉ
Figure 12.3.5 Abraham and 
Shaw  ( 1983 ), p. 123

443
12.4 CHEMICAL CHAOS AND ATTRACTOR RECONSTRUCTION
12.4 Chemical Chaos and Attractor Reconstruction
In this section we describe some beautiful experiments on the Belousov-
Zhabotinsky chemical reaction. The results show that strange attractors really 
do occur in nature, not just in mathematics. For more about chemical chaos, see 
Argoul et al. (1987).
In the BZ reaction, malonic acid is oxidized in an acidic medium by bromate 
ions, with or without a catalyst (usually cerous or ferrous ions). It has been known 
since the 1950s that this reaction can exhibit limit-cycle oscillations, as discussed 
in Section 8.3. By the 1970s, it became natural to inquire whether the BZ reaction 
could also become chaotic under appropriate conditions. Chemical chaos was first 
reported by Schmitz, Graziani, and Hudson (1977), but their results left room for 
skepticism—some chemists suspected that the observed complex dynamics might 
be due instead to uncontrolled fluctuations in experimental control parameters. 
What was needed was some demonstration that the dynamics obeyed the newly 
emerging laws of chaos.
The elegant work of Roux, Simoyi, Wolf, and Swinney established the reality 
of chemical chaos (Simoyi et al. 1982, Roux et al. 1983). They conducted an exper-
iment on the BZ reaction in a “continuous flow stirred tank reactor.” In this stan-
dard set-up, fresh chemicals are pumped through the reactor at a constant rate to 
replenish the reactants and to keep the system far from equilibrium. The flow rate 
acts as a control parameter. The reaction is also stirred continuously to mix the 
chemicals. This enforces spatial homogeneity, thereby reducing the effective num-
ber of degrees of freedom. The behavior of the reaction is monitored by measuring 
B ( t ), the concentration of bromide ions.
Figure 12.4.1 shows a time series measured by Roux et al. (1983). At first glance 
the behavior looks periodic, but it really isn’t—the amplitude is erratic. Roux et al. 
(1983) argued that this aperiodicity corresponds to chaotic motion on a strange 
attractor, and is not merely random behavior caused by imperfect experimental 
control.
BROMIDE ION POTENTIAL (mV)
170
185
0
6
12
18
24
30
TIME (MINUTES)
Figure 12.4.1 Roux et al.  ( 1983 ), p. 258

444 
STRANGE ATTRACTORS
The first step in their argument is almost magical. Put yourself in their shoes—
how could you demonstrate the presence of an underlying strange attractor, given 
that you only measure a single time series B ( t )? It seems that there isn’t enough 
information. Ideally, to characterize the motion in phase space, you would like to 
simultaneously measure the varying concentrations of all the other chemical spe-
cies involved in the reaction. But that’s virtually impossible, since there are at least 
twenty other chemical species, not to mention the ones that are unknown.
Roux et al. (1983) exploited a surprising data-analysis technique, now known 
as attractor reconstruction (Packard et al. 1980, Takens 1981). The claim is that 
for systems governed by an attractor, the dynamics in the full phase space can be 
reconstructed from measurements of just a single time series! Somehow that single 
variable carries sufficient information about all the others.The method is based on 
time delays. For instance, define a two-dimensional vector x ( t )  ( B ( t ), B ( t U )) 
for some delay U 0. Then the time series B ( t ) generates a trajectory x ( t ) in a 
two-dimensional phase space. Figure 12.4.2 shows the result of this procedure 
when applied to the data of Figure 12.4.1, using U 8.8 seconds. The experimental 
data trace out a strange attractor that looks remarkably like the Rössler attractor!
Roux et al. (1983) also considered the attractor in three dimensions, by defin-
ing the three-dimensional vector x ( t )  ( B ( t ), B ( t U ), B ( t 2U )). To obtain a 
Poincaré section of the attractor, they computed the intersections of the orbits x ( t ) 
with a fixed plane approximately normal to the orbits (shown in projection as a 
dashed line in Figure 12.4.2). Within the experimental resolution, the data fall on a 
one-dimensional curve. Hence the chaotic trajectories are confined to an approxi-
mately two-dimensional sheet.
Roux et al. then constructed an approx-
imate one-dimensional map that gov-
erns the dynamics on the attractor. Let 
X1, X2, . . . , Xn, Xn1 , . . . denote succes-
sive values of B ( t U ) at points where the 
orbit x ( t ) crosses the dashed line shown in 
Figure 12.4.2. A plot of Xn1 vs. Xn yields the 
result shown in Figure 12.4.3. The data fall 
on a smooth one-dimensional map, within 
experimental resolution. This confirms that 
the observed aperiodic behavior is governed 
by deterministic laws: Given Xn, the map 
determines Xn1.
Furthermore, the map is unimodal, like 
the logistic map. This suggests that the cha-
otic state shown in Figure 12.4.1 may be reached by a period-doubling scenario. 
Indeed such period-doublings were found experimentally (Coffman et al. 1987), as 
shown in Figure 12.4.4.
B(ti)
B(ti+T)
Figure 12.4.2 Roux et al.  ( 1983 ), p. 262

445
12.4 CHEMICAL CHAOS AND ATTRACTOR RECONSTRUCTION
The final nail in the coffin was the demon-
stration that the chemical system obeys the 
U-sequence expected for unimodal maps 
(Section 10.6). In the regime past the onset 
of chaos, Roux et al. (1983) observed many 
distinct periodic windows. As the flow rate 
was varied, the periodic states occurred in 
precisely the order predicted by universality 
theory.
Taken together, these results demon-
strate that deterministic chaos can occur 
in a nonequilibrium chemical system. The 
most remarkable thing is that the results can 
be understood (to a large extent) in terms 
of one-dimensional maps, even though the 
chemical kinetics are at least twenty-dimensional. Such is the power of universal-
ity theory.
But let’s not get carried away. The universality theory works only because the 
attractor is nearly a two-dimensional surface. This low dimensionality results from 
the continuous stirring of the reaction, along with strong dissipation in the kinet-
ics themselves. Higher-dimensional phenomena like chemical turbulence remain 
beyond the limits of the theory.
(a)
(b)
(c)
2
20   minutes
2
1
2
Figure 12.4.4 Coffman et al.  ( 1987 ), p. 123
Comments on Attractor Reconstruction
The key to the analysis of Roux et al. (1983) is the attractor reconstruction. 
There are at least two issues to worry about when implementing the method.
Xn
n
+1
X
Figure 12.4.3 Roux et al.  ( 1983 ), p. 262

446 
STRANGE ATTRACTORS
First, how does one choose the embedding dimension, i.e., the number of delays? 
Should the time series be converted to a vector with two components, or three, or 
more? Roughly speaking, one needs enough delays so that the underlying attractor 
can disentangle itself in phase space. The usual approach is to increase the embed-
ding dimension and then compute the correlation dimensions of the resulting 
attractors. The computed values will keep increasing until the embedding dimen-
sion is large enough; then there’s enough room for the attractor and the estimated 
correlation dimension will level off at the “true” value.
Unfortunately, the method breaks down once the embedding dimension is too 
large; the sparsity of data in phase space causes statistical sampling problems. This 
limits our ability to estimate the dimension of high-dimensional attractors. For 
further discussion, see Grassberger and Procaccia (1983), Eckmann and Ruelle 
(1985), and Moon (1992).
A second issue concerns the optimal value of the delay U. For real data (which 
are always contaminated by noise), the optimum is typically around one-tenth to 
one-half the mean orbital period around the attractor. See Fraser and Swinney 
(1986) for details.
The following simple example suggests why some delays are better than others.
EXAMPLE 12.4.1:
Suppose that an experimental system has a limit-cycle attractor. Given that 
one of its variables has a time series x ( t ) sin t, plot the time-delayed trajectory 
x ( t )  ( x ( t ), x ( t U )) for different values of U. Which value of U would be best if 
the data were noisy?
Solution: Figure 12.4.5 shows x ( t ) for three values of U. For 0
2


τ
π ,  the tra-
jectory is an ellipse with its long axis on the diagonal (Figure  12.4.5a). When 
τ
π
 2 ,  x ( t ) traces out a circle (Figure 12.4.5b). This makes sense since x ( t ) sin t 
and y t
t
t
( )
cos ;
=
+
=
sin(
)
Q
2
 these are the parametric equations of a circle. For 
larger U we find ellipses again, but now with their long axes along the line y x 
(Figure 12.4.5c).
x(t+τ)
x(t)
−1
−1
−1
−1
0
(a)
(b)
(c)
1
−1
0
1
−1
0
1
0
0
0
1
1
1
π
π
π
=
=
=
/6
/6
5
/2
τ
τ
τ
Figure 12.4.5

447
12.5 FORCED DOUBLE-WELL OSCILLATOR
Note that in each case the method gives a closed curve, which is a topologically 
faithful reconstruction of the system’s underlying attractor (a limit cycle).
For this system the optimum delay is τ
π
 2 ,  i.e., one-quarter of the natural 
orbital period, since the reconstructed attractor is then as “open” as possible. 
Narrower cigar-shaped attractors would be more easily blurred by noise. ■
In the exercises, you’re asked to do similar calibrations of the method using 
quasiperiodic data as well as time series from the Lorenz and Rössler attractors.
Many people find it mysterious that information about the attractor can be 
extracted from a single time series. Even Ed Lorenz was impressed by the method. 
When my dynamics class asked him to name the development in nonlinear dynam-
ics that surprised him the most, he cited attractor reconstruction.
In principle, attractor reconstruction can distinguish low-dimensional chaos 
from noise: as we increase the embedding dimension, the computed correlation 
dimension levels off for chaos, but keeps increasing for noise (see Eckmann and 
Ruelle (1985) for examples). Armed with this technique, many optimists have asked 
questions like, Is there any evidence for deterministic chaos in stock market prices, 
brain waves, heart rhythms, or sunspots? If so, there may be simple laws waiting to 
be discovered (and in the case of the stock market, fortunes to be made). Beware: 
Much of this research is dubious. For a sensible discussion, along with a state-of-
the-art method for distinguishing chaos from noise, see Kaplan and Glass (1993).
12.5 Forced Double-Well Oscillator
So far, all of our examples of strange attractors have come from autonomous sys-
tems, in which the governing equations have no explicit time-dependence. As soon 
as we consider forced oscillators and other nonautonomous systems, strange attrac-
tors start turning up everywhere. That is why we have ignored driven systems until 
now—we simply didn’t have the tools to deal with them.
This section provides a glimpse of some of the phenomena that arise in a par-
ticular forced oscillator, the driven double-well oscillator studied by Francis Moon 
and his colleagues at Cornell. For more information about this system, see Moon 
and Holmes (1979), Holmes (1979), Guckenheimer and Holmes (1983), Moon and 
Li (1985), and Moon (1992). For introductions to the vast subject of forced non-
linear oscillations, see Jordan and Smith (1987), Moon (1992), Thompson and 
Stewart (1986), and Guckenheimer and Holmes (1983).

448 
STRANGE ATTRACTORS
Magneto-Elastic Mechanical System
Moon and Holmes (1979) studied the mechanical system shown in Figure 12.5.1.
periodic
forcing
beam
rigid frame
magnet
x
Figure 12.5.1
A slender steel beam is clamped in a rigid framework. Two permanent magnets 
at the base pull the beam in opposite directions. The magnets are so strong that 
the beam buckles to one side or the other; either configuration is locally stable. 
These buckled states are separated by an energy barrier, corresponding to the 
unstable equilibrium in which the beam is straight and poised halfway between 
the magnets.
To drive the system out of its stable equilibrium, the whole apparatus is shaken 
from side to side with an electromagnetic vibration generator. The goal is to under-
stand the forced vibrations of the beam as measured by x ( t ), the displacement of 
the tip from the midline of the magnets.
For weak forcing, the beam is observed to vibrate slightly while staying near 
one or the other magnet, but as the forcing is slowly increased, there is a sudden 
point at which the beam begins whipping back and forth erratically. The irregular 
motion is sustained and can be observed for hours—tens of thousands of drive 
cycles.
Double-Well Analog
The magneto-elastic system is representative of a wide class of driven bistable 
systems. An easier system to visualize is a damped particle in a double-well poten-
tial (Figure 12.5.2). Here the two wells correspond to the two buckled states of the 
beam, separated by the hump at x 0.

449
12.5 FORCED DOUBLE-WELL OSCILLATOR
periodic
forcing
x =0
x
Figure 12.5.2
Suppose the well is shaken periodically from side to side. On physical grounds, 
what might we expect? If the shaking is weak, the particle should stay near the 
bottom of a well, jiggling slightly. For stronger shaking, the particle’s excursions 
become larger. We can imagine that there are (at least) two types of stable oscilla-
tion: a small-amplitude, low-energy oscillation about the bottom of a well; and a 
large-amplitude, high-energy oscillation in which the particle goes back and forth 
over the hump, sampling one well and then the other. The choice between these 
oscillations probably depends on the initial conditions. Finally, when the shaking 
is extremely strong, the particle is always flung back and forth across the hump, for 
any initial conditions.
We can also anticipate an intermediate case that seems complicated. If the par-
ticle has barely enough energy to climb to the top of the hump, and if the forcing 
and damping are balanced in a way that keeps the system in this precarious state, 
then the particle may sometimes fall one way, sometimes the other, depending on 
the precise timing of the forcing. This case seems potentially chaotic.
Model and Simulations
Moon and Holmes (1979) modeled their system with the dimensionless equation


x
x
x
x
F
t
+
−
+
=
δ
ω
3
cos
 
(1)
where E 0 is the damping constant,  F  is the forcing strength, and X is the forcing 
frequency. Equation (1) can also be viewed as Newton’s law for a particle in a dou-
ble-well potential of the form V x
x
x
( )
.
=
−
1
4
4
1
2
2  In both cases, the force  F  cos Xt 
is an inertial force that arises from the oscillation of the coordinate system; recall 
that x is defined as the displacement relative to the moving frame, not the lab frame.
The mathematical analysis of (1) requires some advanced techniques from 
global bifurcation theory; see Holmes (1979) or Section 2.2 of Guckenheimer and 

450 
STRANGE ATTRACTORS
Holmes (1983). Our more modest goal is to gain some insight into (1) through 
numerical simulations.
In all the simulations below, we fix 
E 0.25, X l, 
while varying the forcing strength  F .
EXAMPLE 12.5.1:
By plotting x ( t ), show that (1) has several stable limit cycles for  F  0.18. 
Solution: Using numerical integration, we obtain the time series shown in 
Figure 12.5.3.
x
t
Figure 12.5.3
The solutions converge straightforwardly to periodic solutions. There are two 
other limit cycles in addition to the two shown here. There might be others, but 
they are harder to detect. Physically, all these solutions correspond to oscillations 
confined to a single well. ■
The next example shows that at much larger forcing, the dynamics become 
complicated.
EXAMPLE 12.5.2:
Compute x ( t ) and the velocity y t
x t
( )
( ),
 
 for  F  0.40 and initial condi-
tions  ( x0, y0 )  ( 0, 0 ). Then plot x ( t ) vs. y ( t ).
Solution: The aperiodic appearance of x ( t ) and y ( t ) (Figure 12.5.4) suggests 
that the system is chaotic, at least for these initial conditions. Note that x changes 
sign repeatedly; the particle crosses the hump repeatedly, as expected for strong 
forcing.

451
12.5 FORCED DOUBLE-WELL OSCILLATOR
x
t
t
y
Figure 12.5.4
The plot of x ( t ) vs. y ( t ) is messy and hard to interpret (Figure 12.5.5). ■
y
x
Figure 12.5.5
Note that Figure 12.5.5 is not a true phase portrait, because the system is nonauto-
nomous. As we mentioned in Section 1.2, the state of the system is given by  ( x, y, t ), 
not  ( x, y ) alone, since all three variables are needed to compute the system’s sub-
sequent evolution. Figure 12.5.5 should be regarded as a two-dimensional projec-
tion of a three-dimensional trajectory. The tangled appearance of the projection is 
typical for nonautonomous systems.
Much more insight can be gained from a Poincaré section, obtained by plot-
ting  ( x ( t ), y ( t )) whenever t is an integer multiple of 2Q. In physical terms, we 
“strobe” the system at the same phase in each drive cycle. Figure 12.5.6 shows the 
Poincaré section for the system of Example 12.5.1.

452 
STRANGE ATTRACTORS
1.0
−2.0
2.0
−1.0
Figure 12.5.6 Guckenheimer and Holmes  ( 1983 ), p. 90
Now the tangle resolves itself—the points fall on a fractal set, which we interpret 
as a cross section of a strange attractor for (1). The successive points  ( x ( t ), y ( t )) 
are found to hop erratically over the attractor, and the system exhibits sensitive 
dependence on initial conditions, just as we’d expect.
These results suggest that the model is capable of reproducing the sustained 
chaos observed in the beam experiments. Figure 12.5.7 shows that there is good 
qualitative agreement between the experimental data (Figure 12.5.7a) and numer-
ical simulations (Figure 12.5.7b).
(a)
(b)
Time
Time
Figure 12.5.7 Guckenheimer and Holmes  ( 1983 ), p. 84
Transient Chaos
Even when (1) has no strange attractors, it can still exhibit complicated dynam-
ics (Moon and Li 1985). For instance, consider a regime in which two or more 
stable limit cycles coexist. Then, as shown in the next example, there can be tran-
sient chaos before the system settles down. Furthermore the choice of final state 
depends sensitively on initial conditions (Grebogi et al. 1983b).
EXAMPLE 12.5.3:
For  F  0.25, find two nearby trajectories that both exhibit transient chaos 
before finally converging to different periodic attractors.

453
12.5 FORCED DOUBLE-WELL OSCILLATOR
Solution: To find suitable initial conditions, we could use trial and error, or we 
could guess that transient chaos might occur near the ghost of the strange attrac-
tor of Figure 12.5.6. For instance, the point  ( x0, y0 )  ( 0.2, 0.1 ) leads to the time 
series shown in Figure 12.5.8a.
x
x
(a)
(b)
t
t
Figure 12.5.8
After a chaotic transient, the solution approaches a periodic state with x 0. 
Physically, this solution describes a particle that goes back and forth over the 
hump a few times before settling into small oscillations at the bottom of the well on 
the right. But if we change x0 slightly to x0 0.195, the particle eventually oscillates 
in the left well (Figure 12.5.8b). ■
Fractal Basin Boundaries
Example 12.5.3 shows that it can be hard to predict the final state of the system, 
even when that state is simple. This sensitivity to initial conditions is conveyed more 
vividly by the following graphical method. Each initial condition in a 900 q 900 
grid is color-coded according to its fate. If the trajectory starting at  ( x0, y0 ) ends up 
in the left well, we place a blue dot at  ( x0, y0 ); if the trajectory ends up in the right 
well, we place a red dot.
Color plate 3 shows the computer-generated result for (1). The blue and red 
regions are essentially cross sections of the basins of attraction for the two attrac-
tors, to the accuracy of the grid. Color plate 3 shows large patches in which all 
the points are colored red, and others in which all the points are colored blue. 
In between, however, the slightest change in initial conditions leads to alterna-
tions in the final state reached. In fact, if we magnify these regions, we see further 
intermingling of red and blue, down to arbitrarily small scales. Thus the bound-
ary between the basins is a fractal. Near the basin boundary, long-term prediction 
becomes essentially impossible, because the final state of the system is exquisitely 
sensitive to tiny changes in initial condition (Color plate 4).

454 
STRANGE ATTRACTORS
EXERCISES FOR CHAPTER 12
12.1 The Simplest Examples
12.1.1 
(Uncoupled linear map) Consider the linear map xn1 axn, yn1 byn, 
where a, b are real parameters. Draw all the possible patterns of orbits near the 
origin, depending on the signs and sizes of a and b.
12.1.2 
(Stability criterion) Consider the linear map xn1 axn byn, 
yn1 cxn dyn, where a, b, c, d are real parameters. Find conditions on the 
parameters which ensure that the origin is globally asymptotically stable, 
i.e.,  ( xn, yn ) l ( 0, 0 ) as n ld, for all initial conditions.
12.1.3 
Sketch the face of Figure 12.1.4 after one more iteration of the baker’s 
map.
12.1.4 
(Vertical gaps) Let B be the baker’s map with a  1
2 . Figure 12.1.5 shows 
that the set B 2 ( S ) consists of horizontal strips separated by vertical gaps of differ-
ent sizes.
a) Find the size of the largest and smallest gaps in the set B 2 ( S ).
b) Redo part (a) for B 3 ( S ).
c) Finally, answer the question in general for Bn ( S ).
12.1.5 
(Area-preserving baker’s map) Consider the dynamics of the baker’s map 
in the area-preserving case a  1
2 .
a) Given that  ( x, y )  ( .a1a2a3 . . . , .b1b2b3 . . . ) is the binary representation of an 
arbitrary point in the square, write down the binary representation of B ( x, y ). 
(Hint: The answer should look nice.)
b) Using part (a) or otherwise, show that B has a period-2 orbit, and sketch its 
location in the unit square.
c) Show that B has countably many periodic orbits.
d) Show that B has uncountably many aperiodic orbits.
e) Are there any dense orbits? If so, write one down explicitly. If not, explain why 
not.
12.1.6 
Study the baker’s map on a computer for the case a  1
2 . Starting from a 
random initial condition, plot the first ten iterates and label them.
12.1.7 
(Smale horseshoe) Figure 1 illustrates the mapping known as the Smale 
horseshoe (Smale 1967).

455
EXERCISES
flatten and
stretch
re-inject
fold
slice off the
overhanging parts
b
′
′
′
′
′
′
′
′
b
d
d
c
c
a
a
c
c
c
a
a
a
b
b
b
d
d
d
Figure 1
Notice the crucial difference between this map and that shown in Figure 12.1.3: 
here the horseshoe hangs over the edge of the original square. The overhanging 
parts are lopped off before the next iteration proceeds.
a) The square at the lower left of Figure 1 contains two shaded horizontal strips. 
Find the points in the original square that map to these strips. (These are the 
points that survive one iteration, in the sense that they still remain in the square.)
b) Show that after the next round of the mapping, the square on the lower left con-
tains four horizontal strips. Find where they came from in the original square. 
(These are the points that survive two iterations.)
c) Describe the set of points in the original square that survive forever.
The horseshoe arises naturally in the analysis of transient chaos in differen-
tial equations. Roughly speaking, the Poincaré map of such systems can often be 
approximated by the horseshoe. During the time the orbit remains in a certain 
region corresponding to the square above, the stretching and folding of the map 
causes chaos. However, almost all orbits get mapped out of this region eventually 
(into the “overhang”), and then they escape to some distant part of phase space; 
this is why the chaos is only transient. See Guckenheimer and Holmes (1983) or 
Arrowsmith and Place (1990) for introductions to the mathematics of horseshoes.
12.1.8 
(Hénon’s area-preserving quadratic map) The map
x
x
y
x
y
x
y
x
n
n
n
n
n
n
n
n
+
+
=
−
−
=
+
−
1
2
1
2
cos
(
)sin
sin
(
)cos
B
B
B
B

456 
STRANGE ATTRACTORS
illustrates many of the remarkable properties of area-preserving maps (Hénon 
1969, 1983). Here 0 bB bQ is a parameter.
a) Verify that the map is area-preserving.
b) Find the inverse mapping.
c) Explore the map on the computer for various B. For instance, try cos B 0.24, 
and use initial conditions in the square 1 bx, y b1. You should be able to 
find a lovely chain of five islands surrounding the five points of a period-5 cycle. 
Then zoom in on the neighborhood of the point x 0.57, y 0.16. You’ll see 
smaller islands, and maybe even smaller islands around them! The complexity 
extends all the way down to finer and finer scales. If you modify the parameter 
to cosB 0.22, you’ll still see a prominent chain of five islands, but it’s now 
surrounded by a noticeable chaotic sea.
This mixture of regularity and chaos is typical for area-preserving maps (and 
for Hamiltonian systems, their continuous-time counterpart).
12.1.9 
(The standard map) The map
xn1 xn yn1,  yn1 yn k sin xn
is called the standard map because it arises in many different physical contexts, 
ranging from the dynamics of periodically kicked oscillators to the motion of 
charged particles perturbed by a broad spectrum of oscillating fields (Jensen 1987, 
Lichtenberg and Lieberman 1992). The variables x, y, and the governing equations 
are all to be evaluated modulo 2Q. The nonlinearity parameter k p 0 is a measure 
of how hard the system is being driven.
a) Show that the map is area-preserving for all k.
b) Plot various orbits for k 0. (This corresponds to the integrable limit of the 
system.)
c) Using a computer, plot the phase portrait for k 0.5. Most orbits should still 
look regular.
d) Show that for k 1, the phase portrait contains both islands and chaos.
e) Show that at k 2, the chaotic sea has engulfed almost all the islands.
12.2 Hénon Map
12.2.1 
Show that the product mapping 
aaa
aa
a
T
T T  is equivalent to the formulas 
in (12.2.1), as claimed in the text.
12.2.2 
Show that the transformations 
a
T  and 
aaa
T
 are area-preserving, but 
aa
T
 
is not.
12.2.3 
Redraw Figure 12.2.1, using an ellipse instead of a rectangle as the test 
shape.
a) Sketch the successive images of the ellipse under the maps 
a
aa
aaa
T
T
T
,
,

b) Represent the ellipse parametrically and draw accurate plots on a computer.

457
EXERCISES
The next three exercises deal with the fixed points of the Hénon map.
12.2.4 
Find all the fixed points of the Hénon map and show that they exist only 
if a a0, where a0 is to be determined.
12.2.5 
Calculate the Jacobian matrix of the Hénon map and find its eigenvalues.
12.2.6 
A fixed point of a map is linearly stable if and only if all eigenvalues of the 
Jacobian satisfy | M| 1. Determine the stability of the fixed points of the Hénon 
map, as a function of a and b. Show that one fixed point is always unstable, while 
the other is stable for a slightly larger than a0  . Show that this fixed point loses sta-
bility in a flip bifurcation  ( M 1 ) at a
b
1
3
4
2
=
−
(
) .
1
12.2.7 
(2-cycle) Consider the Hénon map with 1 b 1. Show that the map 
has a 2-cycle for a
a
b
>
=
−
1
3
4
2
(
) .
1
 For which values of a is the 2-cycle stable?
12.2.8 
(Numerical experiments) Explore numerically what happens in the 
Hénon map for other values of a, still keeping b 0.3.
a) Show that period-doubling can occur, leading to the onset of chaos at a x 1.06.
b) Describe the attractor for a 1.3 .
12.2.9 
(Invariant set for the Hénon map) Consider the Hénon map T with the 
standard parameter values a 1.4, b 0.3. Let Q denote the quadrilateral with 
vertices (1.33, 0.42), (1.32, 0.133), (1.245, 0.14), (1.06, 0.5).
a) Plot Q and its image T ( Q ). (Hint: Represent the edges of Q using the parametric 
equations for a line segment. These segments are mapped to arcs of parabolas.)
b) Prove T ( Q ) is contained in Q .
12.2.10 Some orbits of the Hénon map escape to infinity. Find one that you can 
prove diverges.
12.2.11 Show that for a certain choice of parameters, the Hénon map reduces to 
an effectively one-dimensional map.
12.2.12 Suppose we change the sign of b. Is there any difference in the dynamics?
12.2.13 (Computer project) Explore the area-preserving Hénon map  ( b 1 ). 
The following exercises deal with the Lozi map
xn1 1 yn  a | xn | , 
yn1 bxn ,
where a, b are real parameters, with 1 b 1 (Lozi 1978). Note its similarity to 
the Hénon map. The Lozi map is notable for being one of the first systems proven to 
have a strange attractor (Misiurewicz 1980). This was later achieved for the Hénon 
map (Benedicks and Carleson 1991) and for the Lorenz equations (Tucker 1999, 
2002).
12.2.14 In the style of Figure 12.2.1, plot the image of a rectangle under the Lozi 
map.

458 
STRANGE ATTRACTORS
12.2.15 Show that the Lozi map contracts areas if 1 b 1.
12.2.16 Find and classify the fixed points of the Lozi map.
12.2.17 Find and classify the 2-cycles of the Lozi map.
12.2.18 Show numerically that the Lozi map has a strange attractor when a 1.7, 
b 0.5.
12.3 Rössler System
12.3.1 
(Numerical experiments) Explore the Rössler system numerically. Fix 
b 2, c 4, and increase a in small steps from 0 to 0.4.
a) Find the approximate value of a at the Hopf bifurcation and at the first 
period-doubling bifurcation.
b) For each a, plot the attractor, using whatever projection looks best. Also plot 
the time series z ( t ).
12.3.2 
(Analysis) Find the fixed points of the Rössler system, and state when they 
exist. Try to classify them. Plot a partial bifurcation diagram of x * vs. c, for fixed 
a, b. Can you find a trapping region for the system?
12.3.3 
The Rössler system has only one nonlinear term, yet it is much harder to 
analyze than the Lorenz system, which has two. What makes the Rössler system 
less tractable?
12.4 Chemical Chaos and Attractor Reconstruction
12.4.1 
Prove that the time-delayed trajectory in Figure 12.4.5 traces an ellipse for 
0
2


τ
π .
12.4.2 
(Quasiperiodic data) Plot the time-delayed trajectory  ( x ( t ), x ( t U )) for 
the signal x t
t
t
( )
sin
sin(
),
=
+
3
2
 for various values of U. Does the reconstructed 
attractor appear to be a torus as expected? Which U seems optimal? Try repeating 
the process with three-dimensional embeddings; i.e., use  ( x ( t ), x ( t U), 
x ( t 2U )).
12.4.3 
Numerically integrate the Rössler system for a 0.4, b 2, c 4, and 
obtain a long time series for x ( t ). Then use the attractor-reconstruction method 
for various values of the delay and plot  ( x ( t ), x ( t U )). Find a value of U for which 
the reconstructed attractor looks similar to the actual Rössler attractor. How does 
that U compare to typical orbital periods of the system?
12.4.4 
Redo the previous exercise for the Lorenz equations with the standard 
parameters r 28, b 8 / 3, T 10.

459
EXERCISES
12.5 Forced Double-Well Oscillator
12.5.1 
(Basins for the unforced oscillator) Sketch the basins for the weakly 
damped double-well oscillator (12.5.1) in the unforced case when  F  0. How does 
their shape depend on the size of the damping? What happens to the basins as the 
damping tends to zero? What implications does this have for the predictability of 
the unforced system?
12.5.2 
(Coexisting chaos and limit cycle) Consider the double-well oscillator 
(12.5.1) with parameters E 0.15,  F  0.3, and X 1. Show numerically that the 
system has at least two coexisting attractors: a large limit cycle and a smaller 
strange attractor. Plot both in a Poincaré section.
12.5.3 
(Ueda attractor) Consider the system 

x
kx
x
B
t
+
+
=
3
cos , with k 0.1, 
B 12. Show numerically that the system has a strange attractor, and plot its 
Poincaré section.
12.5.4 
(Chaos in the damped driven pendulum) Consider the forced pendulum 


R
R
R
+
+
=
b
F
t
sin
cos ,  with b 0.22,  F  2.7 (Grebogi et al. 1987).
a) Starting from any reasonable initial condition, use numerical integration to 
compute R( )t . Show that the time series has an erratic appearance, and inter-
pret it in terms of the pendulum’s motion.
b) Plot the Poincaré section by strobing the system whenever t 2Qk, where k is an 
integer.
c) Zoom in on part of the strange attractor found in part (b). Enlarge a region that 
reveals the Cantor-like cross section of the attractor.
12.5.5 
(Fractal basin boundaries in the damped driven pendulum) Consider the 
pendulum of the previous exercise, but now let b 0.2,  F  2 (Grebogi et al. 1987).
a) Show that there are two stable fixed points in the Poincaré section. Describe the 
corresponding motion of the pendulum in each case.
b) Compute the basins for each fixed point. Use a reasonably fine grid of initial 
conditions, and then integrate from each one until the trajectory has settled 
down to one of the fixed points. (You’ll need to establish a criterion to decide 
whether convergence has occurred.) Show that the boundary between the 
basins looks like a fractal.

460 
ANSWERS TO SELECTED QUESTIONS
ANSWERS TO SELECTED 
EXERCISES
Chapter 2
2.1.1 
sin x 0 at x * nQ, for integer n
2.1.3 
( a) 


x
x
x
x x
x
x
x
d
dt
d
dt





( )
(sin )
(cos )
cos
sin
sin
1
2
2
2.2.1 
x * 2, unstable; x * 2, stable
2.2.10 
(a) x  0  (b) x
x
 sinQ  (c) impossible: between any two stable fixed 
points, there must be an unstable one (assuming that the vector field is smooth). 
(d) x 1
2.2.13 
( a )   v
rm
k
e
e
e
e
r
gk m
rt
rt
rt
rt
=
−
+
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
=
−
−
,
/
.
where
 ( b)   mg k
/
 
( d) Vavg 29,300 / 116 x 253 ft / s 172 mph (e) V x 265 ft / s
2.3.2 
x * 0, unstable; x * k1a / k1, stable
2.4.5 
x * 0, f a( x * )  0, half-stable by graphical analysis
2.4.6 
x * 1, f a ( x * )  1, unstable
2.5.1 
 ( 1  c ) 1
2.5.6 
(a) Conservation of mass—the volume of water flowing through the hole 
equals the volume of water lost from the bucket. Equating the time derivatives of 
these two volumes yields av t
Ah t
( )
( ).


 (b) Change in 
P E
change in K E
(
)
2
. .
[
]
[
(
)]
. .
.
=
=
=
=
= (
)
Δ
Δ
Δ
Δ
m gh
A
h gh
m v
A h v
S
S
1
2
1
2
2  
Hence v2 2gh.
2.6.2 
On the one hand, 
f x
dt
f x dx
dx
dt
t
t
T
x t
x t
T
( )
( )
.
( )
(
)
+
+
∫
∫
=
= 0  The first 
equality follows from the chain rule, and the second from the assumption that 

461
ANSWERS TO SELECTED EXERCISES
x ( t )  x ( tT ) . On the other hand, 
f x
dt
dt
dx
dt
t
t
T
dx
dt
t
t
T
( )
(
)
+
+
∫
∫
=
>
2
0  by 
assumption that T 0 and dx
dt  does not vanish identically.
2.7.5 
V ( x )  cosh x; equilibrium x * 0, stable
2.8.1 
The equation is time-independent so the slope is determined solely by x.
2.8.6 
(b) From Taylor’s series, we find x
e
x
x
O x
x
+
= +
−
+
−
l
1
2
2
1
6
3
4
(
).  
Graphical analysis shows that 1
1
≤
=
+
≤+
−
x
x
e
x
x
1
2
2  for all x. Integration 
then yields t
x t
t
b
b
( )
2
2
 tan( /
). Hence 1
l
12 8
≤
≤
≈
x( )
tan( /
)
.
.
1
2
2
0
 
(c) A step size of order 104 is needed, and yields xEuler(l )  1.15361. (d) A step size 
%t 1 gives three-decimal accuracy: %t 1ºxRK ( 1 ) 1.1536059; %t 0.1º
xRK ( 1 )  1.1536389; %t 0.01ºxRK ( l )  1.1536390.
2.8.7 
(a) x ( t1 )  x ( t0 %t )  x ( t0 )  %t x  ( t0 )   1
2   ( %t ) 2 x  ( t0 )  
O ( %t ) 3 x0 %t  f  ( x0 )   1
2   ( %t ) 2 f a  ( x0 )   f  ( x0 )  O ( %t ) 3, where we’ve 
made use of x  f  ( x )  and x   f a( x ) x  f a( x )  f  ( x ) .  
(b)  x t
x
t
f
x
f x
O
t
( )
(
)
(
) (
)
(
) .
1
1
1
2
2
0
0
3
−
=
′
+
Δ
Δ
 Hence C
f
x
f x
=
′
1
2
0
0
(
) (
).
Chapter 3
3.1.1 
rc o2
3.2.3 
rc 1
3.3.1 
(a) n
Gnp
f
Gn
kn
=
+
−
 (c) transcritical
3.4.4 
rc 1, subcritical pitchfork
3.4.11 
(b) x * 0 , unstable  (c) rc 1, subcritical pitchfork; infinitely many 
saddle-node bifurcations occur as r decreases from 1 to 0 (use graphical analysis). 
(d) rc ≈
+
(
)
⎡⎣
⎤⎦
4
1
1
n
Q
2
_
 for integer n 1.
3.4.15 
rc 3 / 16
3.5.4 
(a) mx
bx
kx
L
h
x


+
+
−
+
=
(
/ (
)
)
/
1
0
0
2
2 1 2
 (d) m b2 / k
3.5.5 
(a) Tfast mr / b
3.5.7 
(b) x N / K,  x0N0 / K,  U rt
3.6.5 
(b) u x / a, R L0 / a, h mg sin R / ka. (c) R l, unique fixed point; 
R 1, one, two, or three fixed points, depending on h.
3.7.2 
(b) Cusp at x  3
3.7.4 
(d) transcritical  (e) saddle-node
3.7.5 
(b) rc  1
2  (d) saddle-node curves at rc 2x /  ( 1 x2 ) 2 ,  
sc x2 ( 1x2 )  /  ( 1 x2 ) 2

462 
ANSWERS TO SELECTED EXERCISES
Chapter 4
4.1.1 
a integer. For a well-defined vector field on the circle, we need  
sin ( a ( R2Qk)) sin ( aR )  for all integer k . Hence 2Qka 2Qn, for some integer 
n . Thus ka integer, for all integer k . This is possible only if a is itself an integer.
4.1.3 
Unstable fixed points: R* 0, Q. Stable fixed points: R* oQ / 2.
4.2.1 
12 seconds
4.2.3 
12 / 11 hours later, i.e., at approximately 1:05 and 27 seconds. This 
problem can be solved in many ways. One method is based on Example 4.2.1. It 
takes the minute hand T1 1 hr and the hour hand T2 12 hrs to complete one 
revolution around the clockface. Hence the time required for the minute hand to 
lap the hour hand is T  ( 1 1
12  ) 1  12
11  hrs.
4.3.2 
(a) dR 2 du /  ( 1u2 )   (d) T 2 
du
u
au
X
X
2
2
−
+
−∞
∞
∫
  (e) x ua / X, 
r1  a2 / X2, T
dx
r
x
r
a
=
+
=
=
−
−∞
∞
∫
2
2
2
2
2
2
ω
π
ω
π
ω
 
.
4.3.10 
b
c
du
u
n
n
n
n
=
−
=
+
=
−∞
∞
∫
1
2
2
1
1
2
,
sin(
/
).
 
 
Q
Q
4.4.1 
b2 m2gL3, approximation valid after an initial transient 
4.5.1 
(b) ω
π
−
≤
Ω
2 A
4.6.4 
(a) Ib = Ia + IR 
(c) Vk = ℏ
2e
k
G
4.6.5 
Let R0R / N. Then 8 IbR0 / Icr,  a ( R0r )  / r, 
U =
+
[
/ (
)] .
2
2
0
eI r
R
r t
c
=
4.6.6 
Kirchhoff’s current law gives =
2
1
er
d
dt
I
dQ
dt
I
k
k
c
k
b
G
G
+
+
=
=
sin
,
,
 
 . . . ,
N, and Kirchhoff’s voltage law gives
L d Q
dt
R dQ
dt
Q
C
e
d
dt
j
j
N
2
2
1
2
+
+
=
=∑
=
 G .
Chapter 5
5.1.9 
(c) x y, stable manifold; x y, unstable manifold
5.1.10 
(d) Liapunov stable (e) asymptotically stable
5.2.1 
(a) M 1
2
1
2
1
2
3
1 2
1 1
1
2
=
=
=
=
=
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
,
,
( , ),
( , ).
( )
 
 
 
 (b) 
M
v
v
x t
c
e2
2
3
1
1
t
t
c
e
+
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
.
(c) unstable node (d) x e2t 2e3t,  y 2e2t 2e3t
5.2.2 
x ( t ) C1et cos
sin
sin
cos
t
t
C e
t
t
t
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟+
−
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
2

463
ANSWERS TO SELECTED EXERCISES
5.2.3 
stable node
5.2.5 
degenerate node
5.2.7 
center
5.2.9 
non-isolated fixed point
5.3.1 
a 0, b 0: Narcissistic Nerd, Better Latent than Never, Flirting Fink, 
Likes to Tease but not to Please. a 0, b 0: Bashful Budder, Lackluster Libido 
Lover. a, b0: Hermit, Malevolent Misanthrope (Answers suggested by my stu-
dents and also by students in Peter Christopher’s class at Worcester Polytechnic 
Institute.)
Chapter 6
6.1.1 
saddle point at  ( 0, 0 ) 
6.1.5 
stable spiral at  ( 1,1 ) , saddle point at  ( 0,0 ) , y-axis is invariant.
6.3.3 
 ( 0,0 ) , saddle point
6.3.6 
 ( 1,1 ) , stable node;  ( 1,1 ) , saddle point
6.3.8 
(b) unstable
6.3.9 
(a) stable node at ( 0,0 ) , saddle points at o ( 2,2 ) .
6.4.1 
Unstable node at  ( 0,0 ) , stable node at  ( 3,0 ) , saddle point at  ( 0,2 ) . Null-
clines are parallel diagonal lines. All trajectories end up at  ( 3,0 ) , except those 
starting on the y-axis.
6.4.2 
All trajectories approach  ( 1,1 ) , except those starting on the axes.
6.4.4 
(a) Each species grows exponentially in the absence of the other. 
(b) x b2N1 / r1, y b1N2 / r1, U r1t, S r2 / r1. (d) saddle point at  ( S,l ) . Almost all 
trajectories approach the axes. Hence one or the other species dies out.
6.5.1 
(a) center at  ( 0,0 ) , saddles at  ( o1,0 )  (b) 1
2
2
1
2
2
1
4
4
x
x
x
C
+
−
=
6.5.2 
(c) y2 x2 2
3 x3
6.5.6 
(e) Epidemic occurs if x0 ℓ / k .
6.6.1 
Reversible, since equations invariant under t lt, y ly.
6.6.10 
Yes. The linearization predicts a center and the system is reversible: 
t lt, x lx. A variant of Theorem 6.6.1 shows the system has a nonlinear 
center.
6.7.2 
(e) Small oscillations have angular frequency  ( 1  H2 ) l / 4 for 1 H 1.
6.8.2 
fixed point at  ( 0,0 ) , index I 0.

464 
ANSWERS TO SELECTED EXERCISES
6.8.7 
 ( 2,0 )  and  ( 0,0 ) , saddles;  ( 1,3 ) , stable spiral;  ( 2,0 ) , stable node. 
Coordinate axes are invariant. A closed orbit would have to encircle the node or 
the spiral. But such a cycle can’t encircle the node (cycle would cross the x-axis: 
forbidden). Similarly, cycle can’t encircle the spiral, since spiral is joined to saddle 
at  ( 2,0 )  by a branch of saddle’s unstable manifold, and cycle can’t cross this 
trajectory.
6.8.9 
False. Counterexample: use polar coordinates and consider 
r
r r
r
=
−
−
(
)(
)
2
l
 9
2
, R =
−
r2
4. This has all the required properties but there 
are no fixed points between the cycles r 1 and r 3, since r v 0  in that region.
6.8.11 
(c) For z
zk

,  the origin has index k. To see this, let z reiR. Then 
zk rkeikR. Hence G kR and the result follows. Similarly, the origin has index k 
for z
z
k
=( ) .
Chapter 7
7.1.8 
(b) Period T 2Q (c) stable
7.1.9 
(b) RGa cos G  R, Ra sin G  k, where prime denotes differentia-
tion with respect to the central angle R. (c) The dog asymptotically approaches a 
circle for which R
k
=
−
=
1
2
3
4.
7.2.5 
(b) Yes, as long as the vector field is smooth everywhere, i.e., there are no 
singularities.
7.2.9 
(c) V ex
y
2
2
 ,  equipotentials are circles x2 y2 C.
7.2.10 
Any a, b 0 with a b suffices.
7.2.12 
a l, m 2, n 4
7.3.1 
(a) unstable spiral (b) r
r
r
r
=
−
−
(
)
l
sin2
2
2
2R  (c) r1
1
2
707
=
≈.
 
(d) r2 1 (e) No fixed points inside the trapping region, so Poincaré-Bendixson 
implies the existence of limit cycle.
7.3.7 
(a) r
ar
r
b
=
−
−
(
)
1
2
2
2
cos R , R
R
= −+
1
2
absin
.  (b) There is at least 
one limit cycle in the annular trapping region 1
2
1
−
≤≤
b
r
,  by the Poincaré-
Bendixson theorem. Period of any such cycle is T 
dt
d
d
ab
T a b
dt
d
=
=
−+
=
∫
∫
∫
(
)
sin
( , ).
θ
π
θ
θ
θ
v
v
 
1
2
0
2
7.3.9 
(a) 
2
2
1
5
5
( )
1
( cos
sin )
(
).
r
O
R
N
R
R
N
 


  
(b) 
2
2
max
min
5
1
(
),
1
(
).
5
r
O
r
O
N
N
N
N
 

 


465
ANSWERS TO SELECTED EXERCISES
7.4.1 
Use Liénard’s theorem.
7.5.2 
In the Liénard plane, the limit cycle converges to a fixed shape as 
N l d; that’s not true in the usual phase plane.
7.5.4 
(d) T x ( 2 1n 3 ) N.
7.5.5 
	

2
2
ln 1
2
T
N
 
¯
x


¡
°
¢
±
7.6.7 
′ =
−
r
r
r
1
2
1
8
4
1(
) , stable limit cycle at r 81 / 423 / 4, frequency 
X 1O ( F2 ) .
7.6.8 
′ =
−
r
r
r
1
2
4
3
1(
)
Q
, stable limit cycle at r  3
4 Q , ω
ε
= +
1
2
O(
)
7.6.9 
′ =
−
r
r
r
1
16
3
2
6
(
) , stable limit cycle at r
O
=
= +
6
1
, 
(
)
2
ω
ε
7.6.14 
(b) x t
a
t
t
( , )
(
)
cos
F
F

−
−
+
2
3
4
1 2
7.6.17 
(b) Hc  1
2  (c) k =
−
1
4
2
1
4H  (d) If H  1
2 , then Ga 0 for all G, and 
r ( T )  is periodic. In fact, r( )
(
cos
)
φ
γ
φ
∝
+
−
1
2
1
2
, so if r is small initially, r ( G )  
remains close to 0 for all time.
7.6.19 
(d) x
a
x
a
0
1
1
32
3
3
=
=
−
cos
( )
(cos
cos )
U
U
U
 f  
7.6.22 
x
a
t
a
t
t
O
a
O
=
+
−
−
+
= −
+
cos
(
cos
cos
)
(
),
(
)
ω
ε
ω
ω
ε
ω
ε
ε
1
6
2
2
5
12
2
2
3
3
2
2
1
 
7.6.24 
ω
ε
ε
ε
ε
= −
−
−
+
1
3
8
2
21
256
2
4
81
2048
3
6
4
a
a
a
O(
)
Chapter 8
8.1.3 
1
2
, 
1
M
N
M
 
 
8.1.6 
(b) Nc 1; saddle-node bifurcation
8.1.13 
(a) One nondimensionalization is dx / dt x ( y1 ) , dy / dt xyay b, 
where U kt, x Gn / k, y GN / k, a f  / k, b pG / k2.  (d) Transcritical bifurca-
tion when a b .
8.2.3 
subcritical
8.2.5 
supercritical
8.2.8 
(d) supercritical
8.2.12 
(a) a  1
8  (b) subcritical
8.3.1 
(a) x * 1, y* b / a, U b ( 1 a ) , % a 0 . Fixed point is stable if 
b 1 a , unstable if b 1 a , and linear center if b 1a. (c )  bc 1 a 
(d) b bc (e) T  2Q / a
8.4.3 
N x 0.066 o0.001

466 
ANSWERS TO SELECTED EXERCISES
8.4.4 
Cycle created by supercritical Hopf bifurcation at N 1, destroyed by 
homoclinic bifurcation at N 3.72 o 0.01.
8.4.9 
( )
c  b
k
F
c  32 3
27
3
2
8.4.12 
1
(
ln(1
)).
u
t
O M
N

_
8.5.4 
(d) u
F
( )
cos
sin
θ
α
α
θ
α
α
θ
=
+ +
−+
2
1
1
4
2
1
4
2
2
. ( e) Fc( )
B
B
B
=
+
2
1
4
2 .
8.6.2 
(d) If | 1 X | | 2a |, then lim
( ) /
( )
(
) / (
)
τ
φ
φ
θ τ
θ τ
ω
ω
ω
ω
→∞
=
+
+
+
−
1
2
1
1
, 
where ω
ω
φ =
−
−
(
)
(
)
/
1
4
2
2 1 2
a
. On the other hand, if | lX| b| 2a |, phase-locking 
occurs and lim
( ) /
( )
τ
θ τ
θ τ
→∞
=
1
2
1.
8.6.6 
(c) Lissajous figures are planar projections of the motion. The motion in 
the four-dimensional space ( x, x, y, y )  is projected onto the plane  ( x, y ) . The 
parameter X is a winding number, since it is a ratio of two frequencies. For 
rational winding numbers, the trajectories on the torus are knotted. When 
projected onto the xy plane they appear as closed curves with self-crossings (like 
a shadow of a knot).
8.6.7 
(a) r0  ( h2 / mk ) 1 / 3, X R h / mr0
2 (c) Xr / X R  3 , which is irrational. 
(e) Two masses are connected by a string of fixed length. The first mass plays the 
role of the particle; it moves on a frictionless, horizontal “air table.” It is con-
nected to the second mass by a string that passes through a hole in the center of 
the table. This second mass hangs below the table, bobbing up and down and 
supplying the constant force of its weight. This mechanical system obeys the 
equations given in the text, after some rescaling.
8.7.2 
a 0 , stable; a 0, neutral; a 0 , unstable
8.7.4 
A 0
8.7.9 
(b) stable  (c) e2Q
Chapter 9
9.1.2 
d
dt
n
n
n
n
n
n
n
n
a
b
a a
b b
K a
b
(
)
(
)
(
)
2
2
2
2
2
2
+
=
+
= −
+


. Thus 
(
)
a
b
e
n
n
Kt
2
2
2
0
+
∝
→
−
 as t ld.
9.1.3 
Let a1 By, b1 Cz q1 / K, X Hx, and t = TU, and solve for the 
coefficients by matching the Lorenz and waterwheel equations. Find T 1 / K, 
H oK. Picking H K yields BKv / Qgr, C Kv / Qgr. Also T v / KI, Rayleigh 
r Q grq1 / K2v.

467
ANSWERS TO SELECTED EXERCISES
9.1.4 
(a)   degenerate pitchfork (b)   Let B [b ( r1 )  ]1 / 2. Then 
t
t
E
x P
y D
r
z
b
r
laser
Lorenz  
 
 
=
=
=
= −
=
=
= −
(
/
)
,
,
,
,
/ ,
/ ,
σ κ
α
α
γ
κ σ γ
κ
σ λ
1
2
1.
9.2.1 
(b) If T b 1, then C and C are stable for all r 0. (c) If r rH , 
then M  ( T b 1 ) .
9.2.2 
Pick C so large that x
br
y
br
z
r
r
2
2
2
2
2
1
+
+
−
>
(
)
 everywhere on the bound-
ary of E.
9.3.8 
(a) yes (b) yes
9.4.2 
(b) x *  2
3 ; unstable (c) x
x
1
2
5
2
4
5


, 
; 2-cycle is unstable.
9.5.5 
(a) X Fx, Y FTy, Z T ( Fz1 ),  U t / F
9.5.6 
Transient chaos does not occur if the trajectory starts close enough to 
C or C.
9.6.1 
(a) V
kV
≤−
 for any k min ( 2, 2b ) . Integration then yields 
0 bV ( t )  bV0ekt. (b)  1
2
2
2
0
e
V
V e
kt
≤
<
−, so e2 ( t )  ( 2V0 ) 1 / 2ekt / 2. Similarly, 
e3 ( t )  bO ( ekt / 2 ) .  (c) Integration of e
e
e
1
 
=
−
(
)
T
2
1 , combined with 
e2 ( t )  bO ( ekt / 2 ) , implies e t
O e
O e
t
kt
1
2
( )
max
(
),
(
)
/
≤
{
}
−
−
T
. So all components of 
e ( t )  decay exponentially fast.
9.6.6 
According to Cuomo and Oppenheim (1992, 1993),


u
R C
R
R v
R
R
R
R
R
u
v
R
=
−
+
+
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
⎡
⎣
⎢⎢⎢
⎤
⎦
⎥⎥⎥
=
1
1
1
5
1
4
1
3
2
3
4
1
15
,
C
R
R
R
R
R
R
R
R
R
2
11
10
11
12
8
12
9
7
6
1
1
+
⎡
⎣
⎢⎢
+
+
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
+
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟−
−
⎤
⎦
⎥⎥⎥
=
−
+
+
u
R
R v
R
R uw
w
R C
R
R
uv
R
R
R
R
12
8
12
9
20
3
19
16
18
17
18
19
1
1
,

R
w
16
⎛
⎝
⎜⎜⎜⎜
⎞
⎠
⎟⎟⎟⎟
⎡
⎣
⎢⎢⎢
⎤
⎦
⎥⎥⎥
.
Chapter 10
10.1.1 
xn l1 as n ld , for all x0 0
10.1.10 Yes
10.1.13 Differentiation yields M =
=
f
x
g x
g
x
g x
′
′′
′
( *)
( *)
( *)
( *) .
2  Hence 
g ( x * )  0 implies M 0 (unless g x
′( *) = 0  too; this nongeneric case requires 
separate treatment).
10.3.2 
(b) l 5
10.3.7 
(d) Any orbit starting at an irrational number x0 will be aperiodic, since 
the decimal expansion of an irrational number never repeats.
10.3.12 (a) The maximum of the map occurs at x  1
2 . A superstable cycle of 
period 2n occurs when this point is an element of a 2n-cycle, or equivalently, a 
fixed point of f
x r
n
(
)( , ).
2
 Hence the desired formula for Rn is f
R
n
n
(
)( ,
)
.
2
1
2
1
2


468 
ANSWERS TO SELECTED EXERCISES
10.3.13 (a) The curves are f
r
k ( , )
1
2
 vs. r, for k 1, 2, . . . Intuitively, points near 
xm  1
2  get mapped to almost the same value, since the slope equals zero at xm . 
So there is a high density of points near the iterates f k ( )
1
2  of the maximum. 
(b) The corner of the big wedge occurs when f
f
3
1
2
4
1
2
( )
( )

, as is clear from the 
graphs of part (a). Hence  f  ( u )  u, where u
f

3
1
2( ) . So u must equal the fixed 
point 1
1
 r . The solution of f
r
r
3
1
2
1
1
( , ) = − can be obtained exactly as 
r =
+
+
+
+
=
−
2
3
8
3
1 3
2
3
1 3
19
297
19
297
3 67857
(
)
(
)
.
/
/
. . .
10.4.4 
3.8318741. . .
10.4.7 
(b) RLRR
10.4.11 For 0 <
<
−
a
e
e , xn  tends to a stable 2-cycle; for e
a
e
−<
<1, x
x
n l
* 
where x*  is the unique root of x
ax
*
*

; for 1
1


a
e
e
/ , xn  tends to the smaller 
root of x
ax

; and for a
e
e

1/ , xn →∞.
10.5.3 
The origin is globally stable for r 1, by cobwebbing. There is an inter-
val of marginally stable fixed points for r 1.
10.5.4 
The Liapunov exponent is necessarily negative in a periodic window. 
But since M ln r 0 for all r 1, there can be no periodic windows after the 
onset of chaos.
10.6.1 
(b) r1 x 0.71994, r2 x 0.83326, r3 x 0.85861, r4 x 0.86408, r5 x 0.86526, 
r6 x 0.86551.
10.7.1 
(a) B = −−
= −
1
3
2 732
.
. . . , c2 B / 2 1.366. . . (b) Solve  
B = ( 1 + c2 + c4 ) 1,  c2 = 2B1−
−
= +
−
−
1
2
4
1
2
1
2
1
B
B
B
, c
 simultaneously. 
Relevant root is B = 2.53403. . . , c2  =  1.52224. . . , c4 = 0.12761. . .
10.7.8 
(e) b l / 2
10.7.9 
(b) The steps in the cobweb staircase for g 2 are twice as long, so B 2.
Chapter 11
11.1.3 
uncountable
11.1.6 
(a) x0  is rational  the corresponding orbit is periodic
11.2.1 
1
3
2
9
4
27
1
3
1
1
1
2
3
+
+
+
=⎛
⎝
⎜⎜⎜
⎞
⎠
⎟⎟⎟−
=
...
11.2.4 
Measure 1; uncountable.
11.2.4 
(b) Hint: Write x  [0, 1 ] in binary, i.e., base-2.
11.3.1 
(a) d ln 2 / ln 4
1
2

11.3.4 
ln 5 / ln l0

469
ANSWERS TO SELECTED EXERCISES
11.4.1 
ln 4 / ln 3
11.4.2 
ln 8 / ln 3
11.4.9 
ln ( p2 m2 )  / ln p
Chapter 12
12.1.5 
(a) B ( x, y )   ( .a2a3a4 . . . , .alb1b2b3 . . . ) . To describe the dynamics more 
transparently, associate the symbol . . .b3b2b1.a1a2a3 . . . with  ( x, y )  by simply 
placing x and y back-to-back. Then in this notation, B ( x,y )  . . .b3b2b1a1.
a2a3 . . . . In other words, B just shifts the binary point one place to the right. 
(b) In the notation above, . . .1010.1010 . . . and . . .0101.0101 . . . are the only 
period-2 points. They correspond to ( , )
2
3
1
3  and ( , )
1
3
2
3 . (d) Pick x = irrational, 
y anything.
12.1.8 
(b) xnxn1 cos B + yn1 sin B,  ynxn1 sin Byn1 cos B

 ( xn1 cos Byn1  sin B ) 2
12.2.4 
x * ( 2a ) 1 b
b
a
y
bx
a
b
−±
−
+
⎡
⎣⎢
⎤
⎦⎥
=
= −
−
1
1
4
1
2
0
1
4
2
(
)
,
*
*,
(
)
12.2.5 
M = −
±
+
ax
ax
b
*
(
*)2
12.2.15 det J b
12.3.3 
The Rössler system lacks the symmetry of the Lorenz system. 
12.5.1 
The basins become thinner as the damping decreases.

470 
REFERENCES
REFERENCES
Abraham, R. H., and Shaw, C. D. (1983) Dynamics: The Geometry of Behavior. 
Part 2: Chaotic Behavior (Aerial Press, Santa Cruz, CA).
Abraham, R. H., and Shaw, C. D. (1988) Dynamics: The Geometry of Behavior. 
Part 4: Bifurcation Behavior (Aerial Press, Santa Cruz, CA).
Abrams, D. M., and Strogatz, S. H. (2003) Modelling the dynamics of language 
death. Nature 424, 900.
Ahlers, G. (1989) Experiments on bifurcations and one-dimensional patterns in 
nonlinear systems far from equilibrium. In D. L. Stein, ed. Lectures in 
the Sciences of Complexity (Addison-Wesley, Reading, MA).
Aihara, I., Takeda, R., Mizumoto, T., Otsuka, T., Takahashi, T., Okuno, H. 
G., and Aihara, K. (2011) Complex and transitive synchronization in a 
frustrated system of calling frogs. Phys. Rev. E 83, 031913.
Aitta, A., Ahlers, G., and Cannell, D. S. (1985) Tricritical phenomena in rotat-
ing Taylor-Couette flow. Phys. Rev. Lett. 54, 673.
Alon, U. (2006) An Introduction to Systems Biology: Design Principles of Biolog-
ical Circuits (Chapman & Hall/CRC Mathematical & Computational 
Biology, Taylor & Francis, Boca Raton, FL).
Anderson, P. W., and Rowell, J. M. (1963) Probable observation of the Joseph-
son superconducting tunneling effect. Phys. Rev. Lett. 10, 230.
Anderson, R. M. (1991) The Kermack-McKendrick epidemic threshold theo-
rem. Bull. Math. Biol 53, 3.
Andronov, A. A., Leontovich, E. A., Gordon, I. I., and Maier, A. G. (1973) Qual-
itative Theory of Second-Order Dynamic Systems (Wiley, New York).
Arecchi, F. T., and Lisi, F. (1982) Hopping mechanism generating 1/f noise in 
nonlinear systems. Phys. Rev. Lett. 49, 94.
Argoul, F., Arneodo, A., Richetti, P., Roux, J. C. and Swinney, H. L. (1987) 
Chemical chaos: From hints to confirmation. Acc. Chem. Res. 20, 436.

471
REFERENCES
Argyris, A., Syvridis, D., Larger, L., Annovazzi-Lodi, V., Colet, P., Fischer, 
I., Garcia-Ojalvo, J., Mirasso, C. R., Pesquera, L., and Shore, K. A. 
(2005) Chaos-based communications at high bit rates using commercial 
fibre-optic links. Nature 438, 343.
Arnold, V. I. (1978) Mathematical Methods of Classical Mechanics (Springer, 
New York).
Aroesty, J., Lincoln, T., Shapiro, N., and Boccia, G. (1973) Tumor growth and 
chemotherapy: mathematical methods, computer simulations, and ex-
perimental foundations. Math. Biosci. 17, 243.
Arrowsmith, D. K., and Place, C. M. (1990) An Introduction to Dynamical Sys-
tems (Cambridge University Press, Cambridge, England).
Attenborough, D. (1992) The Trials of Life. For synchronous fireflies, see the 
episode entitled “Talking to Strangers,” available on videotape from 
Ambrose Video Publishing, 1290 Avenue of the Americas, Suite 2245, 
New York, NY 10104.
Bak, P. (1986) The devil’s staircase. Phys. Today, Dec. 1986, 38.
Barnsley, M. F. (1988) Fractals Everywhere (Academic Press, Orlando, FL).
Belousov, B. P. (1959) Oscillation reaction and its mechanism (in Russian). 
Sbornik Referatov po Radiacioni Medicine, p. 145. 1958 Meeting.
Benardete, D. M., Noonburg, V. W., and Pollina, B. (2008) Qualitative tools for 
studying periodic solutions and bifurcations as applied to the periodi-
cally harvested logistic equation. Amer. Math. Monthly 115, 202.
Bender, C. M., and Orszag, S. A. (1978) Advanced Mathematical Methods for 
Scientists and Engineers (McGraw-Hill, New York).
Benedicks, M., and Carleson, L. (1991) The dynamics of the Hénon map. Annals 
of Math. 133, 73.
Bergé, P., Pomeau, Y., and Vidal, C. (1984) Order Within Chaos: Towards a De-
terministic Approach to Turbulence (Wiley, New York).
Borrelli, R. L., and Coleman, C. S. (1987) Differential Equations: A Modeling 
Approach (Prentice-Hall, Englewood Cliffs, NJ).
Briggs, K. (1991) A precise calculation of the Feigenbaum constants. Mathemat-
ics of Computation 57, 435.
Buck, J. (1988) Synchronous rhythmic flashing of fireflies. II. Quart. Rev. Biol. 
63, 265.
Buck, J., and Buck, E. (1976) Synchronous fireflies. Sci. Am. 234, May, 74.
Campbell, D. (1979) An introduction to nonlinear dynamics. In D. L. Stein, ed. 
Lectures in the Sciences of Complexity (Addison-Wesley, Reading, MA).
Carlson, A. J., Ivy, A. C, Krasno, L. R., and Andrews, A. H. (1942) The physi-
ology of free fall through the air: delayed parachute jumps. Quart. Bull. 
Northwestern Univ. Med. School 16, 254 (cited in Davis 1962).
Cartwright, M. L. (1952) Van der Pol’s equation for relaxation oscillations. Con-
tributions to Nonlinear Oscillations, Vol. 2, Princeton, 3.

472 
REFERENCES
Castellano, C., Fortunato, S., and Loreto, V. (2009) Statistical physics of social 
dynamics. Reviews of Modern Physics 81, 591.
Cesari, L. (1963) Asymptotic Behavior and Stability Problems in Ordinary Differ-
ential Equations (Academic, New York).
Chance, B., Pye, E. K., Ghosh, A. K., and Hess, B., eds. (1973) Biological and 
Biochemical Oscillators (Academic Press, New York).
Coddington, E. A., and Levinson, N. (1955) Theory of Ordinary Differential 
Equations (McGraw-Hill, New York).
Coffman, K. G., McCormick, W. D., Simoyi, R. H., and Swinney, H. L. (1987) 
Universality, multiplicity, and the effect of iron impurities in the 
Belousov-Zhabotinskii reaction. J. Chem. Phys. 86, 119.
Collet, P., and Eckmann, J.-P. (1980) Iterated Maps of the Interval as Dynamical 
Systems (Birkhauser, Boston).
Cox, A. (1982) Magnetostratigraphic time scale. In W. B. Harland et al., eds. Geo-
logic Time Scale (Cambridge University Press, Cambridge, England).
Crutchfield, J. P., Farmer, J. D., Packard, N. H., and Shaw, R. S. (1986) Chaos. 
Sci. Am. 254, December, 46.
Cuomo, K. M., and Oppenheim, A. V. (1992) Synchronized chaotic circuits and 
systems for communications. MIT Research Laboratory of Electronics 
Technical Report No. 575.
Cuomo, K. M., and Oppenheim, A. V. (1993) Circuit implementation of syn-
chronized chaos, with applications to communications. Phys. Rev. Lett. 
71, 65.
Cuomo, K. M., Oppenheim, A. V., and Strogatz, S. H. (1993) Synchronization 
of Lorenz-based chaotic circuits with applications to communications. 
IEEE Trans. Circuits and Systems II-Analog and Digital Signal Process-
ing 40, 626.
Cvitanovic, P., ed. (1989a) Universality in Chaos, 2nd ed. (Adam Hilger, Bristol 
and New York). 
Cvitanovic, P. (1989b) Universality in chaos. In P. Cvitanovic, ed. Universality in 
Chaos, 2nd ed. (Adam Hilger, Bristol and New York). 
Davis, H. T. (1962) Introduction to Nonlinear Differential and Integral Equations 
(Dover, New York). 
Devaney, R. L. (1989) An Introduction to Chaotic Dynamical Systems, 2nd ed. 
(Addison-Wesley, Redwood City, CA). 
Dowell, E. H., and Ilgamova, M. (1988) Studies in Nonlinear Aeroelasticity 
(Springer, New York). 
Drazin, P. G. (1992) Nonlinear Systems (Cambridge University Press, Cam-
bridge, England). 
Drazin, P. G., and Reid, W. H. (1981) Hydrodynamic Stability (Cambridge Uni-
versity Press, Cambridge, England). 

473
REFERENCES
Dubois, M., and Bergé, P. (1978) Experimental study of the velocity field in 
Rayleigh-Bénard convection. J. Fluid Mech. 85, 641. 
Eckmann, J.-P., and Ruelle, D. (1985) Ergodic theory of chaos and strange at-
tractors. Rev. Mod. Phys. 57, 617. 
Edelstein−Keshet, L. (1988) Mathematical Models in Biology (Random House, 
New York). 
Eigen, M. and Schuster, P. (1978) The hypercycle: A principle of natural self-or-
ganization. Part B: The abstract hypercycle. Naturwissenschaften 65, 7.
Epstein, I. R., Kustin, K., De Kepper, P., and Orban, M. (1983) Oscillating 
chemical reactions. Sci. Am. 248(3), 112. 
Ermentrout, G. B. (1991) An adaptive model for synchrony in the firefly Pterop-
tyx malaccae. J. Math. Biol. 29, 571. 
Ermentrout, G. B., and Kopell, N. (1990) Oscillator death in systems of coupled 
neural oscillators. SIAM J. Appl. Math. 50, 125. 
Ermentrout, G. B., and Rinzel, J. (1984) Beyond a pacemaker’s entrainment lim-
it: phase walk-through. Am. J. Physiol. 246, R102. 
Euler, L. (1777) De formulis exponentialibus replicatus. Opera Omnia, Series 
Primus XV, 268; Acta Academiae Scientiarum Petropolitanae 1, 38.
Fairén, V., and Velarde, M. G. (1979) Time-periodic oscillations in a model for 
the respiratory process of a bacterial culture. J. Math. Biol. 9, 147. 
Falconer, K. (1990) Fractal Geometry: Mathematical Foundations and Applica-
tions (Wiley, Chichester, England). 
Farmer, J. D. (1985) Sensitive dependence on parameters in nonlinear dynamics. 
Phys. Rev. Lett. 55, 351. 
Feder, J. (1988) Fractals (Plenum, New York).
Feigenbaum, M. J. (1978) Quantitative universality for a class of nonlinear 
transformations. J. Stat. Phys. 19, 25. 
Feigenbaum, M. J. (1979) The universal metric properties of nonlinear transfor-
mations. J. Stat. Phys. 21, 69. 
Feigenbaum, M. J. (1980) Universal behavior in nonlinear systems. Los Alamos 
Sci. 1, 4. 
Feynman, R. P., Leighton, R. B., and Sands, M. (1965) The Feynman Lectures on 
Physics (Addison-Wesley, Reading, MA). 
Field, R., and Burger, M., eds. (1985) Oscillations and Traveling Waves in Chem-
ical Systems (Wiley, New York). 
Firth, W. J. (1986) Instabilities and chaos in lasers and optical resonators. In A. 
V. Holden, ed. Chaos (Princeton University Press, Princeton, NJ).
Fraser, A. M. and Swinney, H. L. (1986) Independent coordinates for strange 
attractors from mutual information. Phys. Rev. A 33, 1134.
Gaspard, P. (1990) Measurement of the instability rate of a far-from-equilibrium 
steady state at an infinite period bifurcation. J. Phys. Chem. 94, 1.

474 
REFERENCES
Geddes, J. B., Short, K. M., and Black, K. (1999) Extraction of signals from 
chaotic laser data. Phys. Rev. Lett. 83, 5389.
Giglio, M., Musazzi, S., and Perini, V. (1981) Transition to chaotic behavior 
via a reproducible sequence of period-doubling bifurcations. Phys. Rev. 
Lett. 47, 243.
Glass, L. (1977) Patterns of supernumerary limb regeneration. Science 198, 321.
Glazier, J. A., and Libchaber, A. (1988) Quasiperiodicity and dynamical systems: 
an experimentalist’s view. IEEE Trans. on Circuits and Systems 35, 790.
Gleick, J. (1987) Chaos: Making a New Science (Viking, New York).
Goldbeter, A. (1980) Models for oscillations and excitability in biochemical sys-
tems. In L. A. Segel, ed., Mathematical Models in Molecular and Cellu-
lar Biology (Cambridge University Press, Cambridge, England).
Grassberger, P. (1981) On the Hausdorff dimension of fractal attractors. J. Stat. 
Phys. 26, 173.
Grassberger, P., and Procaccia, I. (1983) Measuring the strangeness of strange 
attractors. Physica D 9, 189.
Gray, P., and Scott, S. K. (1985) Sustained oscillations and other exotic patterns 
of behavior in isothermal reactions. J. Phys. Chem. 89, 22.
Grebogi, C., Ott, E., and Yorke, J. A. (1983a) Crises, sudden changes in chaotic 
attractors and transient chaos. Physica D 7, 181.
Grebogi, C., Ott, E., and Yorke, J. A. (1983b) Fractal basin boundaries, long-
lived chaotic transients, and unstable-unstable pair bifurcation. Phys. 
Rev. Lett. 50, 935.
Grebogi, C., Ott, E., and Yorke, J. A. (1987) Chaos, strange attractors, and frac-
tal basin boundaries in nonlinear dynamics. Science 238, 632.
Griffith, J. S. (1971) Mathematical Neurobiology (Academic Press, New York).
Grimshaw, R. (1990) Nonlinear Ordinary Differential Equations (Blackwell, Ox-
ford, England).
Guckenheimer, J., and Holmes, P. (1983) Nonlinear Oscillations, Dynamical Sys-
tems, and Bifurcations of Vector Fields (Springer, New York).
Haken, H. (1983) Synergetics, 3rd ed. (Springer, Berlin).
Halsey, T., Jensen, M. H., Kadanoff, L. P., Procaccia, I. and Shraiman, B. I. 
(1986) Fractal measures and their singularities: the characterization of 
strange sets. Phys. Rev. A 33, 1141.
Hanson, F. E. (1978) Comparative studies of firefly pacemakers. Federation 
Proc. 37, 2158.
Hao, Bai-Lin, ed. (1990) Chaos II (World Scientific, Singapore).
Hao, Bai-Lin, and Zheng, W.-M. (1989) Symbolic dynamics of unimodal maps 
revisited. Int. J. Mod. Phys. B 3, 235.
Hardie, D. G., ed. (1999) Protein Phosphorylation: A Practical Approach (Oxford 
University Press, Oxford/New York).
Harrison, R. G., and Biswas, D. J. (1986) Chaos in light. Nature 321, 504.

475
REFERENCES
He, R., and Vaidya, P. G. (1992) Analysis and synthesis of synchronous periodic 
and chaotic systems. Phys. Rev. A 46, 7387.
Helleman, R. H. G. (1980) Self-generated chaotic behavior in nonlinear mechan-
ics. In E. G. D. Cohen, ed. Fundamental Problems in Statistical Mechan-
ics 5, 165.
Hénon, M. (1969) Numerical study of quadratic area-preserving mappings. 
Quart. Appl. Math. 27, 291. 
Hénon, M. (1976) A two-dimensional mapping with a strange attractor. Com-
mun. Math. Phys. 50, 69. 
Hénon, M. (1983) Numerical exploration of Hamiltonian systems. In G. Iooss, 
R. H. G. Helleman, and R. Stora, eds. Chaotic Behavior of Determinis-
tic Systems (North-Holland, Amsterdam). 
Hirsch, J. E., Nauenberg, M., and Scalapino, D. J. (1982) Intermittency in the 
presence of noise: a renormalization group formulation. Phys. Lett. A 
87, 391. 
Hobson, D. (1993) An efficient method for computing invariant manifolds of 
planar maps. J. Comp. Phys. 104, 14. 
Hofbauer, J., and Sigmund, K. (1998) Evolutionary Games and Population Dy-
namics (Cambridge University Press, Cambridge, UK).
Holmes, P. (1979) A nonlinear oscillator with a strange attractor. Phil. Trans. 
Roy. Soc. A 292, 419. 
Hubbard, J. H., and West, B. H. (1991) Differential Equations: A Dynamical Sys-
tems Approach, Part I (Springer, New York). 
Hurewicz, W. (1958) Lectures on Ordinary Differential Equations (MIT Press, 
Cambridge, MA). 
Jackson, E. A. (1990) Perspectives of Nonlinear Dynamics, Vols. 1 and 2 (Cam-
bridge University Press, Cambridge, England). 
Jensen, R. V. (1987) Classical chaos. Am. Scientist 75, 168. 
Jordan, D. W., and Smith, P. (1987) Nonlinear Ordinary Differential Equations, 
2nd ed. (Oxford University Press, Oxford, England). 
Josephson, B. D. (1962) Possible new effects in superconductive tunneling. Phys. 
Lett. 1, 251. 
Josephson, B. D. (1982) Interview. Omni, July 1982, p. 87. 
Kaplan, D. T., and Glass, L. (1993) Coarse-grained embeddings of time series: 
random walks, Gaussian random processes, and deterministic chaos. 
Physica D 64, 431. 
Kaplan, J. L., and Yorke, J. A. (1979) Preturbulence: A regime observed in a fluid 
flow model of Lorenz. Commun. Math. Phys. 67, 93. 
Kermack, W. O., and McKendrick, A. G. (1927) Contributions to the mathemat-
ical theory of epidemics—I. Proc. Roy. Soc. 115A, 700. 
Kirkup, B. C., and Riley, M. A. (2004) Antibiotic-mediated antagonism leads to 
a bacterial game of rock–paper–scissors in vivo. Nature 428, 412.

476 
REFERENCES
Knoebel, R. A. (1981) Exponentials reiterated. Amer. Math. Monthly 88, 235.
Kocak, H. (1989) Differential and Difference Equations Through Computer Ex-
periments, 2nd ed. (Springer, New York).
Kolar, M., and Gumbs, G. (1992) Theory for the experimental observation of 
chaos in a rotating waterwheel. Phys. Rev. A 45, 626. 
Kolata, G. B. (1977) Catastrophe theory: the emperor has no clothes. Science 
196, 287. 
Krebs, C. J. (1972) Ecology: The Experimental Analysis of Distribution and Abun-
dance (Harper and Row, New York). 
Lengyel, I., and Epstein, I. R. (1991) Modeling of Turing structures in the 
chlorite-iodide-malonic acid-starch reaction. Science 251, 650. 
Lengyel, I., Rabai, G., and Epstein, I. R. (1990) Experimental and modeling 
study of oscillations in the chlorine dioxide-iodine-malonic acid reac-
tion. J. Am. Chem. Soc. 112, 9104.
Levi, M., Hoppensteadt, F., and Miranker, W. (1978) Dynamics of the Joseph-
son junction. Quart. Appl. Math. 35, 167.
Lewis, J., Slack, J. M. W., and Wolpert, L. (1977) Thresholds in development. J. 
Theor. Biol. 65, 579.
Libchaber, A., Laroche, C., and Fauve, S. (1982) Period doubling cascade in 
mercury, a quantitative measurement. J. Physique Lett. 43, L211.
Lichtenberg, A. J., and Lieberman, M. A. (1992) Regular and Chaotic Dynamics, 
2nd ed. (Springer, New York).
Lighthill, J. (1986) The recently recognized failure of predictability in Newto-
nian dynamics. Proc. Roy. Soc. Lond. A 407, 35.
Lin, C. C., and Segel, L. (1988) Mathematics Applied to Deterministic Problems 
in the Natural Sciences (SIAM, Philadelphia).
Linsay, P. (1981) Period doubling and chaotic behavior in a driven anharmonic 
oscillator. Phys. Rev. Lett. 47, 1349.
Lorenz, E. N. (1963) Deterministic nonperiodic flow. J. Atmos. Sci. 20, 130.
Lozi, R. (1978) Un attracteur étrange du type attracteur de Hénon. J. Phys. 
(Paris) 39 (C5), 9.
Ludwig, D., Jones, D. D., and Holling, C. S. (1978) Qualitative analysis of insect 
outbreak systems: the spruce budworm and forest. J. Anim. Ecol. 47, 
315.
Ludwig, D., Aronson, D. G., and Weinberger, H. F. (1979) Spatial patterning of 
the spruce budworm. J. Math. Biol. 8, 217.
Ma, S.-K. (1976) Modern Theory of Critical Phenomena (Benjamin/Cummings, 
Reading, MA).
Ma, S.-K. (1985) Statistical Mechanics (World Scientific, Singapore).
Malkus, W. V. R. (1972) Non-periodic convection at high and low Prandtl num-
ber. Mémoires Société Royale des Sciences de Liége, Series 6, Vol. 4, 125.

477
REFERENCES
Mandelbrot, B. B. (1982) The Fractal Geometry of Nature (Freeman, San 
Francisco).
Manneville, P. (1990) Dissipative Structures and Weak Turbulence (Academic, 
Boston).
Marsden, J. E., and McCracken, M. (1976) The Hopf Bifurcation and Its Appli-
cations (Springer, New York).
Marvel, S. A., Hong, H., Papush, A., and Strogatz, S. H. (2012) Encouraging 
moderation: Clues from a simple model of ideological conflict. Phys. 
Rev. Lett. 109, 118702.
May, R. M. (1972) Limit cycles in predator-prey communities. Science 177, 900.
May, R. M. (1976) Simple mathematical models with very complicated dynam-
ics. Nature 261, 459.
May, R. M. (1981) Theoretical Ecology: Principles and Applications, 2nd ed. 
(Blackwell, Oxford, England).
May, R. M., and Anderson, R. M. (1987) Transmission dynamics of HIV infec-
tion. Nature 326, 137.
May, R. M., and Oster, G. F. (1980) Period-doubling and the onset of turbu-
lence: an analytic estimate of the Feigenbaum ratio. Phys. Lett. A 78, 1.
McCumber, D. E. (1968) Effect of ac impedance on dc voltage-current charac-
teristics of superconductor weak-link junctions. J. Appl. Phys. 39, 3113.
Metropolis, N., Stein, M. L., and Stein, P. R. (1973) On finite limit sets for trans-
formations on the unit interval. J. Combin. Theor. 15, 25.
Milnor, J. (1985) On the concept of attractor. Commun. Math. Phys. 99, 177.
Milonni, P. W., and Eberly, J. H. (1988) Lasers (Wiley, New York).
Minorsky, N. (1962) Nonlinear Oscillations (Van Nostrand, Princeton, NJ).
Mirollo, R. E., and Strogatz, S. H. (1990) Synchronization of pulse-coupled bi-
ological oscillators. SIAM J. Appl. Math. 50, 1645. 
Misiurewicz, M. (1980) Strange attractors for the Lozi mappings. Ann. N. Y. 
Acad. Sci. 357, 348.
Moon, F. C. (1992) Chaotic and Fractal Dynamics: An Introduction for Applied 
Scientists and Engineers (Wiley, New York). 
Moon, F. C., and Holmes, P. J. (1979) A magnetoelastic strange attractor. J. 
Sound. Vib. 65, 275. 
Moon, F. C, and Li, G.-X. (1985) Fractal basin boundaries and homoclinic or-
bits for periodic motion in a two-well potential. Phys. Rev. Lett. 55, 
1439. 
Moore-Ede, M. C, Sulzman, F. M., and Fuller, C. A. (1982) The Clocks That 
Time Us (Harvard University Press, Cambridge, MA). 
Munkres, J. R. (1975) Topology: A First Course (Prentice-Hall, Englewood Cliffs, 
NJ).
Murray, J. D. (2002) Mathematical Biology. I: An Introduction, 3rd edition 
(Springer, New York). 

478 
REFERENCES
Murray, J. D. (2003) Mathematical Biology. II: Spatial Models and Biomedical 
Applications, 3rd edition (Springer, New York).
Myrberg, P. J. (1958) Iteration von Quadratwurzeloperationen. Annals Acad. 
Sci. Fennicae A I Math. 259, 1. 
Nahin, P. J. (2007) Chases and Escapes: The Mathematics of Pursuit and Evasion 
(Princeton University Press, Princeton, NJ).
Nayfeh, A. (1973) Perturbation Methods (Wiley, New York). 
Newton, C. M. (1980) Biomathematics in oncology: modelling of cellular sys-
tems. Ann. Rev. Biophys. Bioeng. 9, 541. 
Nowak, M. A. (2006) Evolutionary Dynamics: Exploring the Equations of Life 
(Belknap/Harvard, Cambridge, MA).
Odell, G. M. (1980) Qualitative theory of systems of ordinary differential equa-
tions, including phase plane analysis and the use of the Hopf bifurca-
tion theorem. Appendix A.3. In L. A. Segel, ed., Mathematical Models 
in Molecular and Cellular Biology (Cambridge University Press, Cam-
bridge, England). 
Olsen, L. F., and Degn, H. (1985) Chaos in biological systems. Quart. Rev. Bio-
phys. 18, 165. 
Packard, N. H., Crutchfield, J. P., Farmer, J. D., and Shaw, R. S. (1980) Geome-
try from a time series. Phys. Rev. Lett. 45, 712. 
Palmer, R. (1989) Broken ergodicity. In D. L. Stein, ed. Lectures in the Sciences 
of Complexity (Addison-Wesley, Reading, MA). 
Pearl, R. (1927) The growth of populations. Quart. Rev. Biol. 2, 532. 
Pecora, L. M., and Carroll, T. L. (1990) Synchronization in chaotic systems. 
Phys. Rev. Lett. 64, 821. 
Pedersen, N. F. and Saermark, K. (1973) Analytical solution for a Joseph-
son-junction model with capacitance. Physica 69, 572.
Peitgen, H.-O., and Richter, P. H. (1986) The Beauty of Fractals (Springer, New 
York). 
Perko, L. (1991) Differential Equations and Dynamical Systems (Springer, New 
York). 
Pianka, E. R. (1981) Competition and niche theory. In R. M. May, ed. Theoret-
ical Ecology: Principles and Applications (Blackwell, Oxford, England). 
Pielou, E. C. (1969) An Introduction to Mathematical Ecology (Wiley-Interscience, 
New York). 
Politi, A., Oppo, G. L., and Badii, R. (1986) Coexistence of conservative and dis-
sipative behavior in reversible dynamical systems. Phys. Rev. A 33, 4055. 
Pomeau, Y., and Manneville, P. (1980) Intermittent transition to turbulence in 
dissipative dynamical systems. Commun. Math. Phys. 74, 189.
Poston, T., and Stewart, I. (1978) Catastrophe Theory and Its Applications (Pit-
man, London).

479
REFERENCES
Press, W. H., Teukolsky, S. A., Vetterling, W. T., and Flannery, B. P. (2007) Nu-
merical Recipes: The Art of Scientific Computing, 3rd edition (Cam-
bridge University Press, Cambridge, England).
Rikitake, T. (1958) Oscillations of a system of disk dynamos. Proc. Camb. Phil 
Soc. 54, 89.
Rinaldi, S., Della Rossa, F.,  and Landi, P. (2013) A mathematical model of 
‘‘Gone with the Wind.’’ Physica A 392, 3231.
Rinzel, J., and Ermentrout, G. B. (1989) Analysis of neural excitability and os-
cillations. In C. Koch and I. Segev, eds. Methods in Neuronal Modeling: 
From Synapses to Networks (MIT Press, Cambridge, MA).
Rippon, P. J. (1983) Infinite exponentials. Math. Gazette 67 (441), 189.
Robbins, K. A. (1977) A new approach to subcritical instability and turbulent 
transitions in a simple dynamo. Math. Proc. Camb. Phil. Soc. 82, 309.
Robbins, K. A. (1979) Periodic solutions and bifurcation structure at high r in 
the Lorenz system. SIAM J. Appl. Math. 36, 457.
Rössler, O. E. (1976) An equation for continuous chaos. Phys. Lett. A 57, 397.
Roux, J. C., Simoyi, R. H., and Swinney, H. L. (1983) Observation of a strange 
attractor. Physica D 8, 257.
Ruelle, D., and Takens, F. (1971) On the nature of turbulence. Commun. Math. 
Phys. 20, 167.
Saha, P., and Strogatz, S. H. (1995) The birth of period three. Math. Mag. 68(1), 
42.
Schmitz, R. A., Graziani, K. R., and Hudson, J. L. (1977) Experimental evi-
dence of chaotic states in the Belousov-Zhabotinskii reaction. J. Chem. 
Phys. 67, 3040.
Schnackenberg, J. (1979) Simple chemical reaction systems with limit cycle be-
havior. J. Theor. Biol. 81, 389.
Schroeder, M. (1991) Fractals, Chaos, Power Laws (Freeman, New York).
Schuster, H. G. (1989) Deterministic Chaos, 2nd ed. (VCH, Weinheim, Germany).
Sel’kov, E. E. (1968) Self-oscillations in glycolysis. A simple kinetic model. Eur. 
J. Biochem. 4, 79.
Short, K. M. (1994) Steps toward unmasking secure communications. Int. J. Bi-
furcation Chaos 4, 959.
Short, K. M. (1996) Unmasking a modulated chaos communications scheme. 
Int. J. Bifurcation Chaos 6, 367.
Shpiro, A., Curtu, R., Rinzel, J., and Rubin, N. (2007) Dynamical characteristics 
common to neuronal competition models. J. Neurophysiol. 97, 462.
Sigmund, K. (2010) The Calculus of Selfishness (Princeton University Press, 
Princeton, NJ).
Simó, C. (1979) On the Hénon-Pomeau attractor. J. Stat. Phys. 21, 465.
Simoyi, R. H., Wolf, A., and Swinney, H. L. (1982) One-dimensional dynamics 
in a multicomponent chemical reaction. Phys. Rev. Lett. 49, 245.

480 
REFERENCES
Sinervo, B., and Lively, C. M. (1996) The rock–paper–scissors game and the 
evolution of alternative male strategies. Nature 380, 240.
Smale, S. (1967) Differentiable dynamical systems. Bull. Am. Math. Soc. 73, 747.
Sparrow, C. (1982) The Lorenz Equations: Bifurcations, Chaos, and Strange At-
tractors (Springer, New York) Appl. Math. Sci. 41.
Stewart, I. (2000) The Lorenz attractor exists. Nature 406, 948.
Stewart, W. C. (1968) Current-voltage characteristics of Josephson junctions. 
Appl. Phys. Lett. 12, 277.
Stoker, J. J. (1950) Nonlinear Vibrations (Wiley, New York).
Stone, H. A., Nadim, A., and Strogatz, S. H. (1991) Chaotic streamlines inside 
drops immersed in steady Stokes flows. J. Fluid Mech. 232, 629.
Strogatz, S. H. (1985) Yeast oscillations, Belousov-Zhabotinsky waves, and the 
nonretraction theorem. Math. Intelligencer 7 (2), 9.
Strogatz, S. H. (1986) The Mathematical Structure of the Human Sleep-Wake 
Cycle. Lecture Notes in Biomathematics, Vol. 69. (Springer, New York).
Strogatz, S. H. (1987) Human sleep and circadian rhythms: a simple model based 
on two coupled oscillators. J. Math. Biol. 25, 327.
Strogatz, S. H. (1988) Love affairs and differential equations. Math. Magazine 
61, 35.
Strogatz, S. H., Marcus, C. M., Westervelt, R. M., and Mirollo, R. E. (1988) 
Simple model of collective transport with phase slippage. Phys. Rev. 
Lett. 61, 2380.
Strogatz, S. H., Marcus, C. M., Westervelt, R. M., and Mirollo, R. E. (1989) 
Collective dynamics of coupled oscillators with random pinning. Phys-
ica D 36, 23.
Strogatz, S. H., and Mirollo, R. E. (1993) Splay states in globally coupled Jo-
sephson arrays: analytical prediction of Floquet multipliers. Phys. Rev. 
E 47, 220.
Strogatz, S. H., and Westervelt, R. M. (1989) Predicted power laws for delayed 
switching of charge-density waves. Phys. Rev. B 40, 10501.
Sullivan, D. B., and Zimmerman, J. E. (1971) Mechanical analogs of time depen-
dent Josephson phenomena. Am. J. Phys. 39, 1504.
Tabor, M. (1989) Chaos and Integrability in Nonlinear Dynamics: An Introduc-
tion (Wiley-Interscience, New York).
Takens, F. (1981) Detecting strange attractors in turbulence. Lect. Notes in 
Math. 898, 366.
Testa, J. S., Perez, J., and Jeffries, C. (1982) Evidence for universal chaotic behav-
ior of a driven nonlinear oscillator. Phys. Rev. Lett. 48, 714.
Thompson, J. M. T., and Stewart, H. B. (1986) Nonlinear Dynamics and Chaos 
(Wiley, Chichester, England).
Tsang, K. Y., Mirollo, R. E., Strogatz, S. H., and Wiesenfeld, K. (1991) Dynam-
ics of a globally coupled oscillator array. Physica D 48, 102.

481
REFERENCES
Tucker, W. (1999) The Lorenz attractor exists. C. R. Acad. Sci. 328, 1197.
Tucker, W. (2002) A rigorous ODE solver and Smale’s 14th problem. Found. 
Comput. Math. 2, 53.
Tyson, J. J. (1985) A quantitative account of oscillations, bistability, and trav-
elling waves in the BelousovZhabotinskii reaction. In R. J. Field and 
M. Burger, eds. Oscillations and Traveling Waves in Chemical Systems 
(Wiley, New York).
Tyson, J. J. (1991) Modeling the cell division cycle: cdc2 and cyclin interactions. 
Proc. Natl. Acad. Sci. USA 88, 7328.
Van Duzer, T., and Turner, C. W. (1981) Principles of Superconductive Devices 
and Circuits (Elsevier, New York).
Van Wiggeren, G. D. and Roy, R. (1998) Communications with chaotic lasers. 
Science 279, 1198.
Vasquez, F., and Redner, S. (2004) Ultimate fate of constrained voters. J. Phys. 
A: Math. Gen. 37, 8479.
Viana, M. (2000) What’s new on Lorenz strange attractors? Math. Intelligencer 
22 (3),  6.
Vohra, S., Spano, M., Shlesinger, M., Pecora, L., and Ditto, W. (1992) Pro-
ceedings of the First Experimental Chaos Conference (World Scientific, 
Singapore).
Wade, N. J. (1996) Descriptions of visual phenomena from Aristotle to Wheat-
stone. Perception 25, 1137.
Weiss, C. O., and Vilaseca, R. (1991) Dynamics of Lasers (VCH, Weinheim, 
Germany).
Wiggins, S. (1990) Introduction to Applied Nonlinear Dynamical Systems and 
Chaos (Springer, New York).
Winfree, A. T. (1972) Spiral waves of chemical activity. Science 175, 634.
Winfree, A. T. (1974) Rotating chemical reactions. Sci. Amer. 230 (6), 82.
Winfree, A. T. (1980) The Geometry of Biological Time (Springer, New York).
Winfree, A. T. (1984) The prehistory of the BelousovZhabotinsky reaction. J. 
Chem. Educ. 61, 661.
Winfree, A. T. (1987a) The Timing of Biological Clocks (Scientific American 
Library).
Winfree, A. T. (1987b) When Time Breaks Down (Princeton University Press, 
Princeton, NJ).
Winfree, A. T., and Strogatz, S. H. (1984) Organizing centers for three-dimensional 
chemical waves. Nature 311, 611.
Xie, J., Sreenivasan, S., Korniss, G., Zhang, W., Lim, C., and Szymanski, B. K. 
(2011) Social consensus through the influence of committed minorities. 
Phys. Rev. E 84, 011130.
Xiong, W., and Ferrell, J. E., Jr. (2003) A positive-feedback-based bistable ‘mem-
ory module’ that governs a cell fate decision. Nature 426, 460.

482 
REFERENCES
Yeh, W. J., and Kao, Y. H. (1982) Universal scaling and chaotic behavior of a 
Josephson junction analog. Phys. Rev. Lett. 49, 1888.
Yorke, E. D., and Yorke, J. A. (1979) Metastable chaos: Transition to sustained 
chaotic behavior in the Lorenz model. J. Stat. Phys. 21, 263.
Zahler, R. S., and Sussman, H. J. (1977) Claims and accomplishments of applied 
catastrophe theory. Nature 269, 759.
Zaikin, A. N., and Zhabotinsky, A. M. (1970) Concentration wave propagation 
in two-dimensional liquid-phase self-organizing system. Nature 225, 535.
Zeeman, E. C. (1977) Catastrophe Theory: Selected Papers 19721977 
(Addison-Wesley, Reading, MA).

483
AUTHOR INDEX
AUTHOR INDEX
Abraham and Shaw (1983), 441
Abraham and Shaw (1988), 48
Abrams and Strogatz (2003), 40
Ahlers (1989), 87, 88
Aihara et al. (2011), 303–304
Aitta et al. (1985), 88
Alon (2006), 93
Anderson and Rowell (1963), 109
Anderson (1991), 92
Andronov et al. (1973), 152, 213
Arecchi and Lisi (1982), 383
Argoul et al. (1987), 443
Argyris et al. (2005), 348
Arnold (1978), 189
Aroesty et al. (1973), 39
Arrowsmith and Place (1990), 431
Attenborough (1992), 105
Bak (1986), 424
Barnsley (1988), 405
Belousov (1959), 258
Benardete et al. (2008), 299
Bender and Orszag (1978), 229
Benedicks and Carleson (1991), 
Bergé et al. (1984), 372, 382
Borrelli and Coleman (1987), 27
Briggs (1991), 401, 403
Buck (1988), 105
Buck and Buck (1976), 105
Campbell (1979), 364
Carlson et al. (1942), 38
Cartwright (1952), 217
Castellano et al. (2009), 41
Cesari (1963), 206
Chance et al. (1973), 207
Coddington and Levinson (1955), 206
Coffman et al. (1987), 444
Collet and Eckmann (1980), 356, 386
Cox (1982), 351
Crutchfield et al. (1986), Plate 2
Cuomo and Oppenheim (1992), 347, 
348
Cuomo and Oppenheim (1993), 
343–345
Cuomo et al. (1993), 347
Cvitanovic (1989a), 309 
Cvitanovic (1989b), 379, 382, 383, 386
Davis (1962), 38
Devaney (1989), 356, 375 
Dowell and Ilgamova (1988), 255 
Drazin (1992), 386
Drazin and Reid (1981), 255, 319, 340 
Dubois and Bergé (1978), 88

484 
AUTHOR INDEX
Eckmann and Ruelle (1985), 338, 452, 
453
Edelstein–Keshet (1988), 24, 91, 92, 
159, 191, 237
Eigen and Schuster (1978), 186
Epstein et al. (1983), 258
Ermentrout (1991), 105, 108
Ermentrout and Kopell (1990), 301
Ermentrout and Rinzel (1984), 106
Euler (1777), 400
Fairén and Velarde (1979), 293
Falconer (1990), 405, 416, 418, 423
Farmer (1985), 426
Feder (1988), 405
Feigenbaum (1978), 377 
Feigenbaum (1979), 391
Feigenbaum (1980), 379, 386
Feynman et al. (1965), 110
Field and Burger (1985), 258, 259
Fraser and Swinney (1986), 446
Gaspard (1990), 268, 299
Geddes et al. (1999), 348
Giglio et al. (1981), 383
Glazier and Libchaber (1988), 423
Gleick (1987), 309, 379
Goldbeter (1980), 207
Grassberger (1981), 422
Grassberger and Procaccia (1983), 
418, 420, 421, 422, 446
Gray and Scott (1985), 288
Grebogi et al. (1983a), 398 
Grebogi et al. (1983b), 452 
Grebogi et al. (1987), 458 
Griffith (1971), 246
Grimshaw (1990), 212, 229, 294
Guckenheimer and Holmes (1983), 
51, 54, 183, 229, 294, 431, 447, 
450, 455
Haken (1983), 54, 82
Halsey et al. (1986), 422
Hanson (1978), 105, 107
Hao (1990), 309
Hao and Zheng (1989), 402
Hardie (1999), 93
Harrison and Biswas (1986), 372
He and Vaidya (1992), 353
Helleman (1980), 391
Hénon (1969), 456
Hénon (1976), 429, 435, 438
Hénon (1983), 189, 435
Hirsch et al. (1982), 386
Hobson (1993), 440
Hofbauer and Sigmund (1998), 187, 
233
Holmes (1979), 447, 448, 449
Hubbard and West (1991), 34, 42
Hubbard and West (1992), 34, 181, 
394, 450
Hurewicz (1958), 206
Jackson (1990), 337, 349
Jensen (1987), 435, 456
Jordan and Smith (1987), 70, 203, 
212, 213, 448 
Josephson (1962), 110 
Josephson (1982), 110 
Kaplan and Glass (1993), 447
Kaplan and Yorke (1979), 340
Kermack and McKendrick (1927), 92
Kirkup and Riley (2004), 192
Knoebel (1981), 400
Kocak (1989), 34
Kolar and Gumbs (1992), 348, 350
Kolata (1977), 74
Krebs (1972), 24
Lengyel and Epstein (1991), 259 
Lengyel et al. (1990), 259 
Levi et al. (1978), 275 
Lewis et al. (1977), 91, 92 
Libchaber et al. (1982), 381–383, 386 

485
AUTHOR INDEX
Lichtenberg and Lieberman (1992), 
189, 435, 456 
Lighthill (1986), 329 
Lin and Segel (1988), 27, 65, 70, 230 
Linsay (1981), 383 
Lorenz (1963), 309, 327, 333, 337, 
405, 429, 435 
Lozi (1978), 457 
Ludwig et al. (1978), 75, 80, 288 
Ludwig et al. (1979), 80
Ma (1976), 381
Ma (1985), 91
Malkus (1972), 349
Mandelbrot (1982), 405
Manneville (1990), 54, 319
Marsden and McCracken (1976), 324
Marvel et al. (2012), 290
May (1972), 192
May (1976), 360
May (1981), 24
May and Anderson (1987), 93
May and Oster (1980), 390
McCumber (1968), 110
Metropolis et al. (1973), 377, 398, 402
Milnor (1985), 331
Minorsky (1962), 213
Milonni and Eberly (1988), 54, 82, 
289
Mirollo and Strogatz (1990), 105
Misiurewicz (1980), 457
Moon (1992), 445, 448
Moon and Holmes (1979), 448, 449
Moon and Li (1985), 448, 452, Plate 3
Munkres (1975), 433
Murray (2002), 24, 80, 91–93, 118, 
160, 192, 214, 237, 257, 294 
Murray (2003), 90
Myrberg (1958), 370
Newton (1980), 39
Nowak (2006), 185
Odell (1980), 290, 291
Olsen and Degn (1985), 376, 384386
Packard et al. (1980), 444
Palmer (1989), 58
Pearl (1927), 24
Pecora and Carroll (1990), 342, 345, 
353
Pedersen and Saermark (1973), 300
Peitgen and Richter (1986), 1, 405
Perko (1991), 206, 212
Pianka (1981), 169
Pielou (1969), 24, 160
Politi et al. (1986), 168
Pomeau and Manneville (1980), 371
Poston and Stewart (1978), 73
Press et al. (2007), 32, 34, 58
Rikitake (1958), 350
Rinaldi et al. (2013), 233
Rinzel and Ermentrout (1989), 118, 
214, 255
Robbins (1977), 349
Robbins (1979), 342, 352
Rössler (1976), 383, 429, 440
Roux et al. (1983), 443445
Ruelle and Takens (1971), 327
Saha and Strogatz (1995), 370, 399 
Schmitz et al. (1977), 443 
Schnackenberg (1979), 293 
Schroeder (1991), 405 
Schuster (1989), 379, 386 
Sel’kov (1968), 207 
Shpiro et al. (2007), 290
Sigmund (2010), 233, 236
Simó (1979), 440 
Simoyi et al. (1982), 379, 443 
Short (1994), 348
Short (1996), 348
Sinervo and Lively (1996), 192
Smale (1967), 429, 454 
Sparrow (1982), 337342, 352 

486 
AUTHOR INDEX
Stewart (1968), 110 
Stewart (2000), 337
Stoker (1950), 213, 217
Stone et al. (1991), 168, 193
Strogatz (1986), 277
Strogatz (1987), 277
Strogatz (1988), 38
Strogatz et al. (1988), 297
Strogatz et al. (1989), 297
Strogatz and Mirollo (1993), 119, 121
Strogatz and Westervelt (1989), 245
Sullivan and Zimmerman (1971), 111, 
276
Tabor (1989), 189, 435
Takens (1981), 444
Testa et al. (1982), 383
Thompson and Stewart (1986), 255, 
448
Tsang et al. (1991), 119, 121, 168, 193, 
286, 300 
Tucker (1999), 337
Tucker (2002), 337
Tyson (1985), 259 
Tyson (1991), 237
Van Duzer and Turner (1981), 110, 
110, 119 
Van Wiggeren and Roy (1998), 348
Vasquez and Redner (2004), 187
Viana (2000), 337
Vohra et al. (1992), 342
Weiss and Vilaseca (1991), 83
Wiggins (1990), 51, 54, 183, 249, 268
Winfree (1972), 258
Winfree (1974), Plate 1
Winfree (1980), 118, 258
Winfree (1984), 258
Winfree (1987b), 257, 258
Xie et al. (2011), 290
Xiong and Ferrell (2003), 93
Yeh and Kao (1982), 383
Yorke and Yorke (1979), 338, 340
Zahler and Sussman (1977), 74 
Zaikin and Zhabotinsky (1970), 258 
Zeeman (1977), 73

487
SUBJECT INDEX
SUBJECT INDEX
acceleration, 36 
adiabatic elimination, 81
ADP, 208
aeroelastic flutter, 255 
age structure, 24 
AIDS, 92 
air resistance, 38 
airplane wings
boundary layers, 70
vibrations of, 255 
Airy function, 216 
algebraic decay
and critical slowing down, 41, 57
and Hopf bifurcation, 253
and pitchfork bifurcation, 249 
algebraic renormalization, 390, 404 
Allee effect, 39 
amplitude
of fluid pattern, 87
of oscillation, 97
slowly varying, 224 
amplitude equations, 316 
amplitude-dependent frequency
for Duffing oscillator, 229, 232, 
241
for Hopf bifurcation, 253
for pendulum, 195, 239, 241 
angle, 97
angular frequency, 97
angular momentum, 189, 298, 314 
angular velocity, 169 
antiphase synchronization, 303
aperiodic, 3, 326, 330, 362
area-preserving map, 434, 456
baker’s map, 454
Hénon, 455, 456
standard map, 456 
array of Josephson junctions, 119, 
193, 286, 300 
arrhythmia, 258 
aspect ratio, 88 
asymmetric spring, 242 
asymptotic approximation, 230 
asymptotic stability, 131, 144
and Liapunov functions, 203
precise definition of, 144 
atmosphere, 3, 309 
attracting
but not Liapunov stable, 131, 184
precise definition of, 143 
attracting fixed point, 130
impossible for conservative sys-
tem, 161, 167
robustness of, 155 

488 
SUBJECT INDEX
attracting limit cycle, 198 
attractor 
definition of, 331, 351
impossible for area-preserving 
map, 435
in one-dimensional system, 17 
attractor basin, 160 
attractor reconstruction, 444
comments on, 445
for BZ chemical reaction, 444
for Lorenz system, 457
for Rössler system, 457 
Lorenz impressed by, 447
autocatalysis, 39, 91, 246, 288
average spin, 88
averaged equations, 226, 238 
derivation by averaging, 242 
derivation by two-timing, 226 
for forced Duffing oscillator, 294
for van der Pol oscillator, 227 
for weakly nonlinear oscillators, 
226
averages, table of, 226
averaging, method of, 230, 242
averaging theory, 242
back reaction, 39
backward bifurcation, 62
backwards time, 130
bacteria, growth of, 24
bacterial respiration, 291
baker’s map, 432, 454
balsam fir tree, 288
band merging, 398
band of closed orbits, 193
bar magnets, 289
base-3 numbers, 410
basin of attraction, 160, 190, 248, 331
basin boundary, fractal, 453, 458, 
Plate 3
bead on a horizontal wire, 84
bead on a rotating hoop, 62, 84, 191
bifurcations for, 288
frictionless, 191
general case, 191
puzzling constant of motion, 191
small oscillations of, 191 
bead on a tilted wire, 74, 87 
beam, forced vibrations of, 448 
beat phenomenon, 98, 105, 116 
beaver, eager, 141 
bells, 98, 115 
Belousov-Zhabotinsky reaction, 258, 
443
attractor reconstruction for, 444
chaos in, 443
period-doubling in, 444
reduction to 1-D map, 444
scroll waves, front cover
spiral waves, Plate 1
U-sequence, 379, 444 
bias current, 110, 194
bifurcation, 45, 244
backward, 62
blue sky, 48
codimension-1, 71
codimension-2, 71
dangerous, 62
definition of, 45, 244
degenerate Hopf, 256, 292
flip, 365
fold, 48
forward, 61
global, 264, 294
homoclinic (saddle-loop), 266, 
273–275, 294, 296
Hopf, 251, 290
imperfect, 70
in 2-D systems, 244
infinite-period, 266, 294
inverted, 62
of periodic orbits, 264
period-doubling, 360
pitchfork, 56, 249, 287

489
SUBJECT INDEX
saddle-node, 46, 80, 245, 287
saddle-node, of cycles, 265, 294
safe, 62
soft, 62
subcritical Hopf, 290
subcritical pitchfork, 287
supercritical Hopf, 290
supercritical pitchfork, 287
tangent, 369
transcritical, 51, 80, 249, 287
transcritical (for a map), 365
turning-point, 48
unusual, 80
zero-eigenvalue, 251 
bifurcation curves, 52, 77, 293
for driven pendulum and Joseph-
son junction, 275
for imperfect bifurcation, 71
for insect outbreak model, 89 
bifurcation diagram, 47
Lorenz system, 325, 338
vs. orbit diagram, 368 
bifurcation point, 45 
binary shift map, 397, 423 
binocular rivalry 290, 294
biochemical oscillations, 207, 258
biochemical switch, 90, 93, 248 
biological oscillations, 4, 258 
birch trees, 80
birds, as predators of budworms, 75
bistability, 31, 79, 275, 448
blow-up, 28, 41, 60
blue sky bifurcation, 48
boldface as vector notation, 125, 146
Bombay plague, 92
borderline fixed point, 138
sensitive to nonlinear terms, 152, 
183 
bottleneck, 99, 101, 116, 245, 266
at tangent bifurcation, 371
time spent in, 101 
boundary layers, and singular limits, 70 
box dimension, 416, 426
critique of, 417
of fractal that is not self-similar, 
417 
brain waves, 447 
brake, for waterwheel, 312 
bridges, for calculating index, 179 
bromate, 258 
bromide ions, 443 
Brusselator, 293 
buckling, 45, 56, 448 
buddy system, 406 
budworm, 74, 288 
bursts, intermittent, 371
butterfly wing patterns, 90 
butterfly wings and Lorenz attractor, 
327 
BZ reaction 
see Belousov-Zhabotinsky reaction
cancer, 39 
Cantor set, 408
base-3 representation, 410, 424
box dimension, 416
devil’s staircase, 424
even-fifths, 415
even-sevenths, 425
fine structure, 409
fractal properties, 408
measure zero, 409, 423
middle-halves, 425
no 1’s in base-3 expansion, 410
not all endpoints, 424
self-similarity, 409
similarity dimension, 414
topological, 415
uncountable, 411, 424 
capacitor, charging process, 20, 37 
capacity, see box dimension
cardiac arrhythmia, 258 
cardinality, 406 
carrying capacity, 22, 296 

490 
SUBJECT INDEX
Cartesian coordinates vs. polar, 231 
catastrophe, 73, 86
and bead on tilted wire, 74, 87
and forced Duffing oscillator, 295
and imperfect bifurcation, 73
and insect outbreak, 74, 79 
catastrophe theory, 73 
cdc2 protein, 237 
celestial mechanics, 189 
cell division cycle, 237 
cells, Krebs cycle in, 258 
center, 136, 162
altered by nonlinearity, 154, 183
and Hopf bifurcation, 253
marginality of, 155 
center manifold theory, 183, 249 
centrifugal force, 62 
centrist, 187
cerium, 258 
chain of islands, 456 
chambers, for waterwheel, 311 
chaos, 3, 330, Plate 2
aesthetic appeal of, 1
and private communications, 342
definition of, 3, 330
difficulty of long-term prediction, 
327
impossible in 2-D systems, 212
in area-preserving maps, 435, 456
in forced vibrations, 448
in Hamiltonian systems, 435
in lasers, 82
in logistic map, 362
in Lorenz system, 325
in waterwheel, 312
intermittency route to, 371
metastable, 340
period-doubling route, to 362
sound of, 343
synchronization of, 342
transient, 338,351,452
usefulness of, 342
vs. instability, 331
vs. noise, 447 
chaotic attractor, 332 
chaotic sea, 456 
chaotic streamlines, 193 
chaotic waterwheel, 310
characteristic equation, 132, 349
characteristic multipliers, 285, 300
characteristic time scale, 66
charge, analogous to index, 174, 180, 
196
charge-density waves, 98, 297
chase problem, 232
cheese, fractal, 426
chemical chaos, 443
chemical kinetics, 39, 80, 259, 288, 
293
chemical oscillator, 257, 293
Belousov-Zhabotinsky reaction, 
258
Brusselator, 293
CIMA reaction, 259, 293
stability diagram, 263, 293 
chemical turbulence, 445 
chemical waves, 258, Plate 1, front 
cover 
church bells, 98, 115 
CIMA reaction, 259, 293 
circadian rhythms, 198, 277 
circle, as phase space, 95 
circuit
experiments on period-doubling, 
383
forced RC, 283
Josephson array, 119
Josephson junction, 110
oscillating, 212
RC, 20
van der Pol, 231 
circular tube, convection in, 349 
citric acid, 258
civil rights, 290

491
SUBJECT INDEX
classification of fixed points, 138 
clock problem, 116 
closed orbits, 127, 147
isolated, 198, 256
perturbation series for, 235
saddle cycle, 324
continuous band of, 193
existence of, 205, 213, 236
linear oscillations vs. limit cycles, 
199
ruled out by Dulac’s criterion, 204, 
233
ruled out by gradient system, 201
ruled out by index theory, 180, 195
ruled out by Liapunov function, 
203, 233
stability via Poincare map, 284, 300
uniqueness of, 213, 236 
cobweb diagram, 282, 299, 357, 394 
codes, secret, 342 
codimension-1 bifurcation, 71 
codimension-2 bifurcation, 71
coherence, 110
coherent solution, for Josephson 
array, 286, 300 
communications, private, 342 
compact sets, 433 
competition model, 156, 169, 184
competitive exclusion, principle of, 169 
complete elliptic integral, 195 
complex conjugate, 196 
complex eigenvalues, 235, 252 
complex exponentials, 238 
complex variables, 100, 117, 179 
complex vector field, 196 
compromise frequency, 280
computer, solving differential equa-
tions with, 32, 148 
computer algebra
and numerical integrators, 34
and order of numerical integration 
schemes, 44
and Poincaré-Lindstedt method, 242 
conjugacy, of maps, 396 
conjugate momentum, 189 
consciousness, 110 
conservation of energy, 128, 142, 160
and period of Duffing oscillator, 239 
conservation of mass, 313, 314 
conservative system, 161, 186
and degenerate Hopf bifurcation, 
256
no attracting fixed points for, 161, 
167
vs. reversible system, 167 
conserved quantity, 161, 186, 192, 
297, 352 
constant of motion, 161, 352 
constant solution, 19 
consumer spending, 186
continuity equation, for waterwheel, 
314 
continuous flow stirred tank reactor, 
443 
continuous transition, 61 
contour, of constant energy, 162 
contour integral, 117 
control parameter, 45 
convection, 87, 318
experiments on period-doubling, 
383
in a circular tube, 349
in mercury, 381 
convection rolls, 3, 309, 319 
Cooper pairs, 110 
correlation dimension, 419
and attractor reconstruction, 447
for logistic attractor at onset of 
chaos, 420
for Lorenz attractor, 420, 427
scaling region, 419
vs. box dimension, 419 
cosine map, 355, 359
countable set, 406, 423 

492 
SUBJECT INDEX
coupled oscillators, 277, 296, 303 
cover, of a set, 416 
crisis, 398 
critical current, 110 
critical slowing down, 41, 249
at period-doubling, 401
at pitchfork bifurcation, 57 
critical temperature, 88 
croissant, 430 
cubic map, 394, 396 
cubic nullcline, 215, 237 
cubic term
destabilizing in subcritical bifurca-
tion, 59, 255
stabilizing in supercritical bifurca-
tion, 59 
current bias, 110 
current-voltage curve, 112, 275 
cusp catastrophe, 73
for forced Duffing oscillator, 295
for insect outbreak model, 79 
cusp point, 71 
cycle graph, 235 
in rock-paper-scissors game, 235
cyclin, 237
cylinder, 171, 193, 269 
cylindrical phase space, 171, 193, 269, 
283
daily rhythms, 198
damped harmonic oscillator, 218, 221
damped oscillations, in a map, 359
damped pendulum, 172, 194, 256
damping
inertial, 315
negative, 200
nonlinear, 194, 212
quadratic, 300
viscous, 315 
damping force, 62 
dangerous bifurcation, 62, 254 
data analysis, 444 
decay rate, 25
decimal shift map, 396, 423 
degenerate Hopf bifurcation, 256, 292 
degenerate node, 136, 138 
delay, for attractor reconstruction, 444, 
445
dense, 279, 297 
dense orbit, 397, 455 
determinant, 132, 138 
deterministic, 331 
detuning, 294 
developmental biology, 90 
devil’s staircase, 424 
diagonal argument, 408, 423 
dice, and transient chaos, 340
difference equation, 5, 355 
differential equation, 5
as a vector field, 16, 68 
digital circuits, 110 
dimension 
box, 416
classical definition, 411
correlation, 419
embedding, 445
fractal, 413, 416, 419
Hausdorff, 418
of phase space, 8, 9
pointwise, 419
similarity, 413 
dimensional analysis, 65, 76, 85 
dimensionless group, 65, 76, 104, 112 
direction field, 148 
disconnected, totally, 415 
discontinuous transition, 62 
discrete time, 355 
displacement current, 110 
dissipative, 320, 351 
dissipative map, 435
distribution of water, for waterwheel, 
311 
divergence theorem, 240, 321 
dog vs. duck, 232 

493
SUBJECT INDEX
double-well oscillator
basins for, 458
damped, 190
forced, 447 
double-well potential, 31, 161, 448 
dough, as analog of phase space, 430 
drag and lift, 190
dragons, as symbol of the unknown, 11 
driven double-well oscillator, 447, 458,
Plates 3, 4
driven Duffing oscillator, 294, 447 
driven Josephson junction, 268 
driven pendulum (constant torque), 268
existence of closed orbit, 270
homoclinic bifurcation in, 273, 296 
hysteresis in, 276 
infinite-period bifurcation in, 275 
quadratic damping in, 300
saddle-node bifurcation in, 270
stability diagram, 275 
uniqueness of closed orbit, 271
driven pendulum (oscillating torque), 
458
drop, flow in a, 193
duck vs. dog, 232
Duffing equation, 217
Duffing oscillator
amplitude-dependent frequency, 
229 
and Poincaré-Lindstedt method, 
241 
by regular perturbation theory, 241 
exact period, 239 
periodically forced, 294, 447
Dulac’s criterion 204, 233
and forced Duffing oscillator, 295
and model of love dynamics, 233
and predator-prey model, 233
dynamical view of the world, 9
dynamics, 2, 9
dynamos, and Lorenz equations, 309, 
349
eager beaver, 141
economy, 186
eddies, 350
effective potential, 190
eigendirection, slow and fast, 135
eigensolution, 132
eigenvalues
and bifurcations, 251
and hyperbolicity, 156
complex, 136, 144, 235
definition of, 132
equal, 136
imaginary at Hopf bifurcation, 
254
of linearized Poincaré map, 284, 
300
of 1-D map, 357 
eigenvector, definition of, 132 
Einstein’s correction, 188
electric field, 82 
electric flux, 180 
electric repulsion, 190 
electronic spins, 88 
electrostatics, 174, 179, 313 
ellipses, 128, 142 
elliptic functions, 7
elliptic integral, 195 
embedding dimension, 445 
empirical rate laws, 259 
energy, 161
as coordinate on U-tube, 171 
energy contour, 162, 170 
energy surface, 163 
entrainment, 105, 108 
enzyme, 93
epidemic, 91, 92, 188 
equilibrium, 19, 31, 127, 147 
equivariant, 57 
error
global, 44
local, 44
of numerical scheme, 33

494 
SUBJECT INDEX
round-off, 34 
error dynamics, for synchronized 
chaos, 346 
error signal, 346 
ESP, 110 
Euler method, 32
calibration of, 43
improved, 33 
Euler’s formula, 136 
evangelical plea, 360 
even function, 213 
even-fifths Cantor set, 415 
eventually-fixed point, 423 
evolutionary dynamics, 40, 185
exact derivative, 161 
exchange of stabilities, 52 
excitable system, 118, 237, Plate 1 
existence and uniqueness theorem
for n-dimensional systems, 149, 
182
for 1-D systems, 26, 27 
existence of closed orbit, 205, 213, 236
by Poincare-Bendixson theorem, 
205
by Poincaré map, 270, 299
for driven pendulum, 270 
existence of solutions, for only finite 
time, 28 
experiments
chemical oscillators, 257, 379, 443
convection in mercury, 381
driven pendulum, 276
fireflies, 105
fluid patterns, 87
forced double-well oscillator, 447, 
452
lasers, 372
period-doubling, 381
private communications, 342
synchronized chaos, 342 
exponential divergence, 327, 351, 
Plate 2 
exponential growth of populations, 
9, 22 
exponential map, 398
F6P, in glycolysis, 208
face, to visualize a map, 432, 454
failure, of perturbation theory, 220
far-infrared, 110
fast eigendirection, 135
fast time scale, 220
fat fractal, 426, 427
Feigenbaum constants
experimental measurement of, 381
from algebraic renormalization 
(crude), 393
from functional renormalization 
(exact), 390
numerical computation of, 362, 
379, 401 
ferromagnet, 88 
fibrillation, 11,386 
figtree, 387
filo pastry, analog of strange attrac-
tor, 430 
fir tree, 75, 288 
fireflies, 95, 105, 109, 118 
first integral, 161 
first-order phase transition, 62, 83 
first-order system, 15, 63 
first-return map, 271
see Poincaré map 
fishery, 89
Fitzhugh-Nagumo model, 237 
fixed points, 17, 19, 127, 147
attracting, 130
classification of, 138
half-stable, 26
higher-order, 174, 195
hyperbolic, 156
line of, 130, 138
linear stability of, 24, 151
marginal, 155

495
SUBJECT INDEX
non-isolated, 138
of a map, 335, 356, 394
plane filled with, 136, 138
repelling, 322
robust, 155
stable, 17, 19, 131
superstable, 357
unstable, 17, 19, 131 
flashing rhythm, of fireflies, 105 
flight path, of glider, 190 
flip bifurcation, 365
in Hénon map, 457
in logistic map, 365
subcritical, 367, 397 
Floquet multipliers, 285, 300
flour beetles, 24 
flow, 17,95 
fluid flow
chaotic waterwheel, 310
convection, 87, 318, 349, 381
in a spherical drop, 168, 193
patterns in, 87
tumbling object in shear flow, 194
subcritical Hopf bifurcation, 255 
flutter, 255
flux, 180
fold bifurcation, 48 
fold bifurcation of cycles, 265 
forced double-well oscillator, 447, 458,
Plates 3, 4 
forced Duffing oscillator, 294, 447 
forced oscillators, 447, 456, 458 
forest, 75, 288 
forward bifurcation, 61 
Fourier series, 226, 238, 239, 316 
foxes vs. rabbits, 191 
fractal, 405, 408
characteristic properties, 408, 409
cross-section of strange attractor, 
439, 452
example that is not self-similar, 
417
Lorenz attractor as, 309, 327, 420, 427 
fractal attractor, 332 
fractal basin boundary, 453, Plate 3
forced double-well oscillator, 453
forced pendulum, 458 
fractal dimensions
box,416
correlation, 419
Hausdorff, 418
pointwise, 419
similarity, 413 
framework for dynamics, 9 
freezing of ice, 84 
frequency, dependence on amplitude
see amplitude-dependent frequency 
frequency difference, 106 
frogs, 303
frontier, 11 
fruitflies, 24 
functional equation, 390, 402
for intermittency, 404
for period-doubling, 390, 402
gain coefficient, for a laser, 55, 81, 289 
galaxies, 110
games of chance, and transient chaos, 
340
Gauss’s law, 180
Gaussian surface, 174
gene, 90, 246
general relativity, 188
generalized Cantor set, 414
see topological Cantor set 
generalized coordinate, 189 
genetic control system, 246 
geology, 350 
geomagnetic dynamo, and Lorenz 
equations, 349
geomagnetic reversals, 350 
geometric approach, development of, 3 
ghost, of saddle-node, 101, 245, 266, 
370 

496 
SUBJECT INDEX
glider, 190 
global bifurcations of cycles, 264, 294
homoclinic (saddle-loop), 266
infinite-period, 266
period-doubling, 386
saddle-node, 265
scaling laws, 267 
global error, 44 
global stability, 20
and Lorenz equations, 323
from cobweb diagram, 358 
globally attracting, 130 
globally coupled oscillators, 300 
glycolysis, model of, 207 
Gompertz law of tumor growth, 39 
Gone with the Wind, 233
goo, 30
government spending, 235
gradient system, 201, 232, 289 
graphic (cycle graph), 235 
Grassberger-Procaccia dimension
see correlation dimension 
gravitation, 2, 182, 189 
gravitational force, 62 
Green’s theorem, 204, 234, 240 
growth rate, 25
half-stable, 26
fixed point, 46, 99
limit cycle, 198, 265 
Hamilton’s equations, 189
Hamiltonian chaos, 435 
Hamiltonian system, 189, 456 
hand calculator, Feigenbaum’s, 379 
hardening spring, 230
harmonic oscillator, 126, 145, 189 
perturbation of, 217, 294 
weakly damped, 218
harmonics, 316
Hartman-Grobman theorem, 156
harvesting, 89, 90, 299
Hausdorff dimension, 418
heart rhythms, 198, 258, 447
heat equation, 6
Hénon area-preserving map, 455
Hénon map, 435, 456
heteroclinic cycle, 235
heteroclinic trajectory, 167, 171, 192
high-temperature superconductors, 
119
higher harmonics, from nonlinearity, 
238
higher modes, 348
higher-order equations, rewriting, 6
higher-order fixed point, 155, 174, 
177, 183
higher-order term, elimination of, 80
homeomorphism, 156
homoclinic bifurcation, 266, 294, 300 
in Lorenz equations, 338 
in driven pendulum, 268, 273, 296, 
300
scaling law, 296 
subtle in higher dimensions, 268
homoclinic orbit, 162, 171, 188, 193
Hopf bifurcation, 251, 290 
analytical criterion, 256, 292 
degenerate, 256, 292 
in chemical oscillator, 263, 293 
in Lorenz equations, 349 
subcritical vs. supercritical, 256, 292
horizon, for prediction, 329, 351
hormone secretion, 198
horseshoe, 431, 454
human circadian rhythms, 277
human populations, 22
hyperbolas, 143
hyperbolic fixed point, 156
hypercycle, 186
hysteresis, 61 
between equilibrium and chaos, 
340, 352 
in driven pendulum, 268, 276 
in forced Duffing oscillator, 296

497
SUBJECT INDEX
in hydrodynamic stability, 340 
in insect outbreak model, 77 
in Josephson junction, 114, 275 
in Lorenz equations, 340, 352 
in subcritical Hopf bifurcation, 255 
in subcritical pitchfork bifurca-
tion, 61
hysteric activation, 93
imperfect bifurcation, 70, 86
and cusp catastrophe, 73
bifurcation diagram for, 72
in a mechanical system, 74, 87
in asymmetric waterwheel, 349 
imperfection parameter, 70 
impossibility of oscillations, 28, 42
false for flows on the circle, 115 
improved Euler method, 33, 43 
in-phase solution, 286, 300 
index, 174, 195
analogous to charge, 180, 196
integral formula, 196
of a closed curve, 174
of a point, 178
properties of, 177
unrelated to stability, 178 
inertia, and hysteresis, 114 
inertia term
negligible in overdamped limit, 29
validity of neglecting, 65 
inertial damping, in waterwheel, 315 
infinite complex of surfaces, 327 
infinite-period bifurcation, 266, 294
in driven pendulum, 268, 275, 296 
infinity, different types, 406 
inflow, 313 
initial conditions
and singular limits, 67
sensitive dependence on, 327 
initial transient, 69, 85 
initial value problem, 27, 150 
insect outbreak, 74, 89, 288 
insulator, 110 
integer lattice points, 423 
integral, first, 161 
integral formula, for index, 196 
integration step size, 32 
integro-differential equation, 316 
intermediate value theorem, 271 
intermittency, 371, 398
experimental signature, of 371
in lasers, 372
in logistic map, 371
in Lorenz equations, 398, 399
renormalization theory for, 403
Type I, 371 
intermittent chaos, 337, 352 
invariance, under change of variables, 
57
invariant line, 153, 183, 350
invariant measure, 419
invariant ray, 266
invariant set, 331, 338
inverse-square law, 2, 189
inversion, 82
inverted bifurcation, 62
inverted pendulum, 170, 315
irrational frequency ratio, 278, 297
irreversible response, 93
Ising model, 88
island chain, 456
isolated closed trajectory, 198, 256
isolated point, 415, 424
isothermal autocatalytic reaction, 288
iterated exponentiation, 400
iterated map, see map
iteration pattern
for superstable cycle, 398
and U-sequence, 401 
I-V (current-voltage) curve, 112, 231, 
275
Jacobian matrix, 152
Japanese tree frogs, 303

498 
SUBJECT INDEX
joggers, 97, 277
Josephson arrays, 119, 193, 286, 300
Josephson effect, observation of, 110
Josephson junction, 95, 109, 119 
driven by constant current, 268 
example of reversible system, 168 
pendulum analog, 111, 276 
typical parameter values, 112 
undamped, 194
Josephson relations, 110
Juliet and Romeo, 139, 145
jump phenomenon, 61
and forced Duffing oscillator, 296 
and relaxation oscillation, 215 
at subcritical Hopf bifurcation, 
254 
for subcritical pitchfork bifurca-
tion, 61
Kermack-McKendrick model, 91, 188
Keynesian cross, 186
Kirchhoff ’s laws, 111, 120, 346
knot, 278, 298
knotted limit cycles, 337
knotted trajectory, 279, 298
Koch curve, see von Koch curve
Krebs cycle, 257
lag, for attractor reconstruction, 444 
laminar flow, 340 
Landau equation, 87
language, 110
language death, 40
Laplace transforms, 9
large-amplitude branches, 60
large-angle regime, 168
laser, 54, 81, 186, 289, 309, 349, 372
improved model of, 81, 289
intermittent chaos in, 372
Lorenz equations, 82, 309, 349
Maxwell-Bloch equations, 82, 349
reversible system, 168
simplest model of, 54
threshold, 54, 81, 289, 349
two-mode, 186
vs. lamp, 54 
latitude, 194, 277 
law of mass action, 39, 80, 293 
leakage rate, 313
leaky bucket, and non-uniqueness, 42 
leftist, 187
Lenin Prize, 258
Liapunov exponent, 329, 351, 373, 
399 
Liapunov function, 203
definition of, 203
for Lorenz equations, 323
for synchronized chaos, 346, 353
ruling out closed orbits, 203, 233 
Liapunov stable, 131, 143 
libration, 170, 272 
Liénard plane, 236 
Liénard system, 212, 236 
lifetime, of photon in a laser, 55 
lift and drag, 190 
limit cycles, 198, 218, 254
examples, 199
existence of, 205, 212
global bifurcations of, 264
Hopf bifurcation, 251
in weakly nonlinear oscillators, 
217
ruling out, 201
van der Pol, 200, 214 
limited resources, 22, 156, 169 
line of fixed points, 138 
linear, 6, 126 
linear map, 454
linear partial differential equations, 11 
linear stability analysis
of fixed point of a map, 356
for 1-D systems, 24
for 2-D systems, 151 
linear system, 6, 125
linearization

499
SUBJECT INDEX
fails for borderline cases, 152, 154, 
183, 358
fails for higher-order fixed points, 
174, 183
for 1 -D maps, 356
for 1-D systems, 25
for 2-D systems, 151
of Poincaré map, 284, 300
predicts center at Hopf bifurca-
tion, 253
reliable for hyperbolic fixed points, 
156 
linearized map, 357 
linearized Poincaré map, 284, 300 
linearized system, 152 
linked limit cycles, 337 
Lissajous figures, 298 
lizards, 191
load, 119 
local, 174 
local error, 44 
locally stable, 20
locking, of a driven oscillator, 108 
logistic attractor, at onset of chaos, 
420 
logistic differential equation, 22
experimental tests of, 24
with periodic carrying capacity, 
296 
with sinusoidal harvesting, 299
logistic growth, 22, 24 
logistic map, 360, 364, 395
bifurcation diagram (partial), 368
chaos in, 362
exact solution for r = 4, 397
fat fractal, 426
fixed points, 364
flip bifurcation, 365
intermittency, 371
Liapunov exponent, 375
numerical experiments, 360
orbit diagram, 363
period-doubling, 360
periodic windows, 368
probability of chaos in, 426
superstable fixed point, 395
superstable two-cycle, 395
time series, 360
transcritical bifurcation, 365
two-cycle, 365 
longitude, 194, 277 
lopsided fractal, 426 
Lorenz attractor, 3, 325, Plate 2
as a fractal, 309, 327, 420, 427
as infinite complex of surfaces, 327
fractal dimension, 327, 420
not proven to be an attractor, 332
schematic, 327 
Lorenz equations, 309
and dynamos, 349
and lasers, 82, 349
and private communications, 342
and subcritical Hopf bifurcation, 
255
argument against stable limit 
cycles, 335
attracting set of zero volume, 321
bifurcation diagram (partial), 325, 
338
boundedness of solutions, 325, 
350
chaos in, 326
circuit for, 342
dissipative, 320
exploring parameter space, 337
fixed points, 322
global stability of origin, 323
homoclinic explosion, 338
in limit of high r, 342, 352
intermittency, 371, 398
largest Liapunov exponent, 329
linear stability of origin, 322
no quasiperiodicity, 321
no repellers, 322

500 
SUBJECT INDEX
numerical experiments, 351
period-doubling in, 399
periodic windows, 342
pitchfork bifurcation, 322
sensitive dependence, 327
strange attractor, 327
subcritical Hopf bifurcation, 324, 
349
symmetry, 320
synchronized chaos in, 342
trapping region, 350
volume contraction, 320
waterwheel as mechanical analog, 
317, 319, 348 
Lorenz map, 333, 351, 355
for Rössler system, 385
vs. Poincaré map, 335 
Lorenz section, 442 
Lorenz system, see Lorenz equations 
Lotka-Volterra competition model, 
156, 184 
Lotka-Volterra predator-prey model, 
191, 192 
love affairs, 139, 145, 233
low Reynolds number, 193 
Lozi map, 457
magnets, 58, 88, 289, 448 
magnetic field
in convection experiments, 382, 
386
reversal of the Earth’s, 350 
magnetization, 88
magneto-elastic oscillator
see forced double-well oscillator 
manifold, for waterwheel, 311 
manta ray, 167, 192 
map
area-preserving, 434, 456
baker’s, 432,454
binary shift, 397
cosine, 355, 359
cubic, 394, 396
decimal shift, 396
exponential, 398
fixed point of, 356
Hénon, 435, 456
linear, 454
logistic, 360
Lorenz, 333, 351, 355
Lozi, 457
one-dimensional, 355
pastry, 430
Poincaré, 270, 281, 298, 355
quadratic, 396
second-iterate, 365
sine, 376
Smale horseshoe, 431, 454
standard, 456
tent, 351, 374
unimodal, 377 
mapmakers, 11
marginal fixed point, 155, 357 
mask, 342, 348 
mass action, law of, 39, 293 
mass distribution, for waterwheel, 313 
Mathieu equation, 240 
matrix form, 125 
matter and antimatter, 196 
Maxwell’s equations, 11 
Maxwell-Bloch equations, 82, 349 
McCumber parameter, 112 
mean polarization, 82 
mean-field theory, 89 
measure, of a subset of the line, 409 
mechanical analog, 29, 111, 310
mechanical system
bead on a rotating hoop, 62
bead on a tilted wire, 74, 87
chaotic waterwheel, 310
driven pendulum, 268
magneto-elastic, 447
overdamped pendulum, 103
undamped pendulum, 168 

501
SUBJECT INDEX
medicine, 258 
Melnikov method, 275
membrane potential, 118 
Menger hypersponge, 426 
Menger sponge, 426 
Mercator projection, 194 
mercury, convection in, 381 
message, secret, 342, 347 
messenger RNA (mRNA), 246
metabolism, 207, 257 
method of averaging, 230, 242
middle-thirds Cantor set, see Cantor 
set 
minimal, 331 
minimal cover, 416 
miracle, 316, 317
mode-locking, and devil’s staircase, 424 
modes, 316 
modulated, 116 
moment of inertia, waterwheel, 313, 
315, 348 
momentum, 189 
monster, two-eyed, 181 
Monte Carlo method, 145 
multifractals, 422, 423
multiple time scales, 220 
multiplier, 285, 300, 357
importance of sign of, 359
of 1-Dmap, 357
characteristic, 285, 300
Floquet, 285, 300 
multivariable calculus, 179, 438 
muscle extracts, 207 
musical instruments, tuned by beats, 
116
n-dimensional system, 8,15, 150, 281 
natural numbers, 406 
negative damping, 200
negative resistor, 231 
nested sets, 433 
neural networks, 58
neural oscillators, 296 
neural tissue, 258 
neuronal populations, 290, 294
neurons, 118
and subcritical Hopf bifurcation, 
255
Fitzhugh-Nagumo model of, 237
oscillating, 98, 214, 296
pacemaker, 198 
neutrally stable, 131, 162 
neutrally stable cycles
different from limit cycles, 199, 
256
in predator-prey model, 192 
Newton’s method, 394
Newton-Raphson method, 58, 83 
Nobel Prize, 110 
node
degenerate, 136
stable, 130, 135
star, 130, 136
symmetrical, 130
unstable, 135 
noise vs. chaos, 447 
noisy periodicity, 337, 352 
non-isolated fixed point, marginality 
of, 155 
non-uniqueness of solutions, 27,41 
nonautonomous system, 8
as higher-order system, 15, 283
forced double-well oscillator, 447
forced RC-circuit, 283 
nondimensionalization, 65, 76, 85, 
104, 169 
noninteracting oscillators, 97 
nonlinear center, 189, 190, 230
and degenerate Hopf bifurcation, 
256
for conservative system, 162, 164
for pendulum, 169
for reversible system, 165 
nonlinear damping, 200, 212 

502 
SUBJECT INDEX
nonlinear problems, intractability of, 
8 
nonlinear resistor, 37 
nonlinear restoring force, 212, 230 
nonlinear terms, 6 
nonuniform oscillator, 98, 116, 280
biological example, 106
electronic example, 110
mechanical example, 103 
noose, 193, 255 
normal form, 49
obtained by changing variables, 
53, 80
pitchfork bifurcation, 56
saddle-node bifurcation, 46, 102
transcritical bifurcation, 80 
normal modes, 9 
nozzles, for waterwheel, 311 
nth-order system, 8 
nullclines, 148,287, 291
and trapping regions, 208, 260, 
293
cubic, 215, 237
for chemical oscillator, 260, 293
intersect at fixed point, 245
piecewise-linear, 236
vs. stable manifold, 181 
numerical integration, 32, 33, 147, 148 
numerical method, 33, 147, 148
order of, 33
software for, 34
O (big “oh”) notation, 24, 151
odd function, 213
one-dimensional (1-D) map, 355 
for BZ attractor, 444 
linear stability analysis, 356 
relation to real chaotic system, 383
one-dimensional (1-D) system, 15
one-to-one correspondence, 406
opinion change, 187, 290
orbit, for a map, 355
orbit diagram, 395 
construction of, 376 
for logistic map, 363 
sine map vs. logistic map, 378
vs. bifurcation diagram, 368
order
of maximum of a map, 390 
of numerical method, 33, 43
ordinary differential equation, 6
Oregonator, 293
orientational dynamics, 194
orthogonality, 317
orthogonality relations, 239
oscillating chemical reaction, 293
see chemical oscillator
oscillator 
damped harmonic, 145 
double-well, 190 
Duffing, 217 
forced double-well, 447 
forced pendulum, 268, 458 
limit cycle, 198
magneto-elastic, 447
nonuniform, 98
pendulum, 103, 168
piecewise-linear, 236
relaxation, 214, 236
self-sustained, 198
simple harmonic, 126
uniform, 97
van der Pol, 181, 200
weakly nonlinear, 217, 238 
oscillator death, 296 
oscillators, coupled, 277 
oscillators, globally coupled, 300 
oscilloscope, 298, 343 
outbreak, insect, 74, 77, 288 
overdamped bead on a rotating hoop, 
62, 84
see bead on a rotating hoop 
overdamped limit, 29, 67, 103
for Josephson junction, 112

503
SUBJECT INDEX
validity of, 30 
overdamped pendulum, 103, 117 
overdot, as time derivative, 6
pacemaker neuron, 198
Palo Altonator, 293
parachute, 38
paramagnet, 89
parameter, control, 45
parameter shifting, in renormaliza-
tion, 388, 391, 402 
parameter space, 52,72 
parametric equations, 78 
parametric form of bifurcation curves, 
78, 91, 293 
paranormal phenomena, 110 
parrot, 181 
partial differential equation, 6
conservation of mass for water-
wheel, 314
linear, 11 
partial fractions, 298 
particle, 16
pastry map, analog of strange attrac-
tor, 430 
pattern formation, biological, 90 
patterns in fluids, 87 
peak, of an epidemic, 92 
pendulum, 98, 168, 194, 300
and Lorenz equations, 341
as analog of Josephson junction, 
111
as conservative system, 169
as reversible system, 169
chaos in, 458
damped, 172, 194
driven by constant torque, 194, 
268, 300
elliptic integral for period, 195
fractal basin boundaries in, 458
frequency obtained by two-timing, 
239
inverted, 105
overdamped, 98, 103, 117
period of, 194
periodically forced, 458
solution by elliptic functions, 7
undamped, 168 
per capita growth rate, 22 
period, 97
chemical oscillator, 264, 293
Duffing oscillator, 230, 239
nonuniform oscillator, 100
pendulum, 194
periodic point for a map, 336
piecewise-linear oscillator, 237
van der Pol oscillator, 216, 225, 
241 
period-doubling, 360, 362
experimental tests, 381
in BZ chemical reaction, 444
in logistic map (analysis), 365
in logistic map (numerics), 360
in Lorenz equations, 352, 399
in Rössler system, 385
renormalization theory, 386, 402 
period-doubling bifurcation of cycles, 
384
period-four cycle, 361, 392 
period-p point, 336 
period-three window, 368
and intermittency, 371
birth of, 368, 399
in Rössler system, 386
orbit diagram, 363
period-doubling at end of, 372 
period-two cycle, 361 
periodic boundary conditions, 277 
periodic motion, 127 
periodic point, 336 
periodic solutions, 97, 147
existence of, 205, 213, 236
stability via Poincaré map, 284, 
300

504 
SUBJECT INDEX
uniqueness of, 213, 236
uniqueness via Dulac, 234
periodic windows, 363, 368, 398
for logistic map, 363, 368
in Lorenz equations, 342 
perturbation series, 219 
perturbation theory, regular, 218, 238 
perturbation theory, singular, 70 
phase, 97, 277
slowly varying, 224 
phase difference, 97, 108, 279 
phase drift, 106, 109 
phase fluid, 19 
phase plane, 68, 126, 146 
phase point, 19, 28, 68, 127 
phase portrait, 19, 127, 146 
phase space, 7, 19
circle, 95
cylinder, 171, 193, 269
line, 19
plane, 126
sphere, 194
torus, 276 
phase space dimension, 9 
phase space reconstruction
see attractor reconstruction 
phase walk-through, 106 
phase-locked, 108, 118,280 
phase-locked loop, 3, 98, 294 
phase-locking
in forced Duffing oscillator, 295
of joggers, 277 
phosphorylation, 93
photons, 55, 81, 289 
pictures vs. formulas, 16, 174 
pie-slice contour, 117 
piecewise-linear oscillator, 236 
pigment, 90 
pinball machine, 325 
pipe flow, 314
pitchfork bifurcation, 56, 82, 249 
plague, 92
Planck’s constant, 110 
plane of fixed points, 138 
planetary orbits, 188, 189 
plasma physics, 189 
plea, evangelical, 360 
Poincare map, 270, 281, 298, 355
and stability of closed orbits, 284, 
300
definition of, 281
fixed points yield closed orbits, 
282
for forced logistic equation, 296, 
299
in driven pendulum, 270
linearized, 284, 300
simple examples, 282
strobe analogy, 283, 299
time of flight, 282 
Poincaré section, 281, 442
BZ chemical reaction, 444
forced double-well oscillator, 451 
Poincaré-Bendixson theorem, 150, 
205, 234
and chemical oscillator, 260, 293
and glycolytic oscillator, 210
implies no chaos in phase plane, 
212
statement of, 205 
Poincaré-Lindstedt method, 225, 241, 
290 
pointwise dimension, 419 
Poiseuille flow in a pipe, 314 
Pokey, 97 
polar coordinates, 154, 183
and limit cycles, 199
and trapping regions, 206, 234
vs. Cartesian, 231 
polarization, 82 
political opinion dynamics, 187
population growth, 21 
population inversion, 82 
positive definite, 203, 233 

505
SUBJECT INDEX
positive feedback, 91 
potential, 30, 84, 115
double-well, 31, 448
effective, 190
for gradient system, 201, 232
for subcritical pitchfork, 83, 84
for supercritical pitchfork, 59
sign convention for, 30 
potential energy, 160, 188 
potential well, 30
power law, and fractal dimension, 416 
power spectrum, 344 
Prandtl number, 319, 349 
pre-biotic evolution, 186
pre-turbulence, 340 
predation, 75 
predator-prey model, 191, 233
and Hopf bifurcation, 290, 291 
pressure head, 313 
prey, 191
principle of competitive exclusion, 
169 
private communications, 342 
probability
of different fixed points, 145
of chaos in logistic map, 426 
protein, 93, 246
psychic spoon-bending, 110 
pump, for a laser, 54, 81, 289 
punctured region, 210, 261, 293 
pursuit problem, 232
quadfurcation, 83
quadratic damping, 300
quadratic map, 396
quadratic maximum, 390
quadratically small terms, 151
qualitative universality, 377
quantitative universality, 379
quantum mechanics, 11, 110
quartic maximum, 403
quasi-static approximation, 81
quasiperiodic, 279
quasiperiodicity, 296
and attractor reconstruction, 457 
different from chaos, 350 
impossible for Lorenz system, 321 
largest Liapunov exponent, 351 
mechanical example, 298
r-shifting, in renormalization, 388, 
391 
rabbits vs. foxes, 191 
rabbits vs. sheep, 156, 184
no closed orbits, 180 
radial dynamics, 199, 265, 292 
radial momentum, 189
radio, 3, 212, 231
random behavior as transient chaos, 
340 
random fractal, 426 
random sequence, 310, 327 
range of entrainment, 109, 118 
rate constants, 39, 260 
rate laws, empirical, 259 
rational frequency ratio, 278 
Rayleigh number
as temperature gradient, 381
for Lorenz equations, 319
for waterwheel, 318, 349 
Rayleigh-Bénard convection, 87
RC circuit, 20
driven by sine wave, 283
driven by square wave, 299 
reaching a fixed point in a finite time, 41 
receiver circuit, 345 
recursion relation, 355
refuge, 77
regular perturbation theory, 218, 238
can’t handle two time scales, 220
for Duffing oscillator, 241
to approximate closed orbit, 235 
relativity, 188 
relaxation limit, 294 

506 
SUBJECT INDEX
relaxation oscillator, 214, 236
cell cycle, 237
chemical example, 294
period of van der Pol, 216
piecewise-linear, 236 
renormalization, 386, 402
algebraic, 390, 404
for pedestrians, 390, 404
functional, 389
in statistical physics, 381 
renormalization transformation, 389 
repeated exponentiation, 400
repeller 
impossible for Lorenz system, 322
in one-dimensional system, 17
robustness of, 155 
rescaling, 388, 391, 402 
resetting strength, 106 
residue theory, 117 
resistor, negative, 231 
resistor, nonlinear, 37 
resonance curves, for forced Duffing, 
295 
resonant forcing, 219 
resonant term, elimination of, 222 
respiration, 291 
rest solution, 19 
resting potential, 118 
restoring force, nonlinear, 212 
return map, see Poincare map 
reversals
of Earth’s magnetic field, 350
of waterwheel, 310, 319 
reversibility, for Josephson array, 300 
reversible system, 165, 192, 193
coupled Josephson junctions, 168, 
193
fluid flow in a spherical drop, 168, 
193
general definition of, 167
Josephson array, 300
laser, 168
undamped pendulum, 169
vs. conservative system, 167 
rightist, 187
Rikitake model of geomagnetic rever-
sals, 350
ringing, 252
RNA, 246
robust fixed points, 155 
rock-paper-scissors, 191, 235
rolls, convection, 381 
romance, star-crossed, 139 
romantic styles, 141, 145
Romeo and Juliet, 139, 145 
root-finding scheme, 58
Rössler attractor, 441, 444 
Rössler system, 383, 440, 457
Lorenz map, 385
period-doubling, 384
strange attractor (schematic), 441 
rotation, 171, 272 
rotational damping rate, 313 
rotational dynamics, 193 
round-off error, 34 
routes to chaos
intermittency, 371
period-doubling, 362, 381 
ruling out closed orbits, 201, 233
by Dulac’s criterion, 204, 233
by gradient system, 201
by index theory, 180, 196
by Liapunov function, 203, 233 
Runge-Kutta method, 33, 147
calibration of, 43
for higher-dimensional systems, 147
for 1-D systems, 33 
running average, 242
saddle connection, 167, 181, 184
saddle connection bifurcation, 184, 266, 
274
saddle cycle, 324
saddle point, 130, 134

507
SUBJECT INDEX
saddle switching, 184
saddle-node bifurcation, 46, 80
bifurcation diagram for, 47
ghosts and bottlenecks, 101, 245
graphical representation of, 46
in autocatalytic reaction, 289
in driven pendulum, 270
in fireflies, 108
in genetic control system, 246
in imperfect bifurcation, 71
in insect outbreak model, 77
in overdamped pendulum, 104
in nonuniform oscillator, 99
in 2-D systems, 245, 287
normal form, 49, 102, 245
ofcycles, 265, 277, 281
remnant of, 101
tangential intersection at, 49, 77 
saddle-node bifurcation of cycles, 
265, 277
in coupled oscillators, 281
in forced Duffing oscillator, 294
intermittency, 371 
safe bifurcation, 62 
saturation, 329
Saturn’s rings, and Henon attractor, 
440 
scale factor, universal, 388, 403 
scaling, 65, 76, 85 
scaling law, 117
and fractal dimension, 416
for global bifurcations of cycles, 
267
near saddle-node, 101, 245
nongeneric, 117
square-root, 101, 245 
scaling region, 419 
Schrödinger equation, 11 
scroll wave, 258, front cover 
sea, chaotic, 456 
sea creature, 167 
second-iterate map, 365
and renormalization, 387, 403 
second-order differential equation, 63 
second-order phase transition, 41
and supercritical pitchfork, 61
and universality, 381 
second-order system, 15
replaced by first-order system, 29, 
63, 103 
secret messages, 342 
secular term, 219
eliminated by Poincare-Lindstedt, 
241
eliminated by two-timing, 222 
secure communications, 342 
self-excited vibration, 198 
self-similarity, 405
as basis for renormalization, 387
of Cantor set, 409
offigtree, 387
of fractals, 405 
self-sustained oscillation, 198, 231 
semiconductor, 110, 231 
semistable fixed point, 26 
sensitive dependence, 3, 327, Plate 2
as positive Liapunov exponent, 
331
due to fractal basin boundaries, 
453
due to stretching and folding, 430
in binary shift map, 397
in decimal shift map, 396, 397
in Lorenz system, 327
in Rossler system, 441 
separation of time scales, 85 
separation of variables, 16 
separation vector, 328 
separatrices, 160 
sets, 406 
shear flow, 193 
sheep vs. rabbits, 156 
Sherlock Holmes, 319 
Sierpinski carpet, 425, 426 

508 
SUBJECT INDEX
sigmoid growth curve, 23 
signal masking, 342, 354 
similarity dimension, 413 
simple closed curve, 175 
simple harmonic oscillator, 126, 189 
sine map, 376, 399 
singular limit, 69, 214 
singular perturbation theory, 70 
sink, 17, 155 
sinusoidal oscillation, 200
and Hopf bifurcation, 252 
SIR epidemic model 91, 188 
skydiving, experimental data, 38 
slaving, 81
sleep-wake cycle, 277 
slope field, 35 
slow branch, 216 
slow eigendirection, 135, 156 
slow time scale, 220 
slow-time equations, 226 
slowing down, critical, 41 
slowly-varying amplitude and phase, 
224, 242 
Smale horseshoe, 431, 454
and transient chaos, 455
definition of, 454
invariant set is strange saddle, 431
vs. pastry map, 431 
small nonlinear terms, effect of, 152, 
183 
small-angle approximation, 7, 168 
snide remark, by editor to Belousov, 
258 
snowflake curve, 425 
soft bifurcation, 62 
softening spring, 230 
software for dynamical systems, 34 
solar system, 2
solid-state device, 38
solid-state laser, 54
source, 17, 155
speech, masking with chaos, 344
Speedy, 97
sphere, as phase space, 194
spherical coordinates, 194
spherical drop, Stokes flow in a, 193
spike, 118
spins, 89
spiral, 136
and Hopf bifurcation, 252
as perturbation of a center, 154, 
183
as perturbation of a star, 183 
spiral waves, 258, Plate 1 
sponge, Menger, 426 
spontaneous emission
decay rate for, 81, 289
ignored in simple laser model, 56 
spontaneous generation, 22 
spontaneous magnetization, 89 
spoon-bending, psychic, 110 
spring
asymmetric, 242
hardening, 230
softening, 230 
spring constant, 126 
spruce budworm, 74, 288 
square wave, 299 
square-root scaling law, 101, 117, 245
applications in physics, 245
derivation of, 102
for infinite-period bifurcation, 266
stability, 131, 143, 144
asymptotic, 131
cases where linearization fails, 25, 
358
different types of, 130
global, 20
graphical conventions, 131
Liapunov, 131
linear, 24, 155, 284
linear, for a 2-D map, 457
local, 20
neutral, 131

509
SUBJECT INDEX
of closed orbits, 198, 284
of cycles in 1-D maps, 367
of fixed point of a flow, 131, 143, 
144
of fixed point of a map, 356
structural, 156
stability diagram, 72
stable, see stability
stable manifold, 130, 135, 169
as basin boundary, 160, 248
as threshold, 248
series approximation for, 181
vs. nullcline, 181 
stagnation point, 19 
standard map, 456 
star node, 130, 136
altered by small nonlinearity, 183 
state, 8, 126 
steady solution, 19 
steady states, 147 
step, 32
stepsize, 33, 148 
stepsize control, automatic, 34 
stick-slip oscillation, 214 
stimulated emission, 55, 81, 289 
stock market, dubious link to chaos, 
447 
Stokes flow, 193 
straight-line trajectories, 131 
strange attractor, 309, 331, 332
and uniqueness of solutions, 327
chemical example, 444
definition of, 332
discovery of, 3
for baker’s map, 433
for Lorenz equations, 327
for pastry map, 431
forced double-well oscillator, 452
fractal structure, 430, 435
impossible in 2-D flow, 212, 441
proven for Lozi and Henon maps, 
457
Rossler system, 441 
strange repeller, for tent map, 426 
streamlines, chaotic, 193 
stretching and folding, 429, 430
in Hénon map, 435
in Rössler attractor, 441
in Smale horseshoe, 455 
strongly nonlinear, 214, 236 
structural stability, 156, 184 
subcritical flip bifurcation, 397 
subcritical Hopf bifurcation, 254, 
255, 290
in Lorenz equations, 255, 324, 349 
subcritical pitchfork bifurcation, 59, 
82, 249
bifurcation diagram for, 59
in fluid patterns, 87
in 2-D systems, 249, 287
prototypical example of, 60 
superconducting devices, 109 
superconductors, 109 
supercritical Hopf bifurcation, 252, 
290
frequency of limit cycle, 254, 264, 
293
in chemical oscillator, 263, 293
scaling of limit cycle amplitude, 
254
simple example, 253 
supercritical pitchfork bifurcation, 56, 
82, 249
bifurcation diagram for, 57
for bead on rotating hoop, 65
in fluid patterns, 87
in Lorenz system, 322
in 2-D systems, 249, 287 
supercurrent, 110 
superposition, 9 
superslow time scale, 220 
superstable cycles, 374, 387
and logistic attractor at onset of 
chaos, 421

510 
SUBJECT INDEX
and renormalization, 387, 403
contain critical point of the map, 387
numerical virtues of, 401
numerics, 397
with specified iteration pattern, 
402 
superstable fixed point, 357, 395
and Newton’s method, 394 
supertracks, 398
supposedly discovered discovery, 258 
surface of section, 281 
swing, playing on a, 240 
switch, 90
biochemical, 93, 248
genetic, 244 
switching devices, 110 
symbol sequence, 398, 401 
symbolic manipulation programs, 34, 
44, 242
symmetric pair of fixed points, 57 
symmetry, 171
and pitchfork bifurcation, 56, 249
in Lorenz equations, 320
time-reversal, 164 
symmetry-breaking, 65 
synchronization, 105
of chaos, 344
of coupled oscillators, 280
of fireflies, 105
of Japanese tree frogs, 303
synchronized chaos, 342
circuit for, 344
experimental demonstration, 343
Liapunov function, 346, 353
numerical experiments, 353
some drives fail, 353 
system, 15
systems biology, 93
tangent bifurcation, 369, 371, 398, 399 
Taylor series, 44, 50, 102 
Taylor-Couette vortex flow, 88 
temperature, 89, 198 
temperature gradient, 318, 381 
tent map
as model of Lorenz map, 351
Liapunov exponent, 374
no windows, 399
orbit diagram, 399
strange repeller, 426 
terminal velocity, 38 
tetration, 400
tetrode multivibrator, 231 
three-body problem, 2 
three-cycle, birth of, 368 
threshold, 78, 90, 119, 248 
time
continuous for flows, 5
discrete for maps, 5, 355 
time horizon, 329, 351 
time of flight, for a Poincaré map, 282 
time scale, 25, 65, 85
dominant, 101
super-slow, 240
fast and slow, 220
separation of, 69, 75, 215 
time series, for a 1-D map, 360 
time-dependent system
see nonautonomous system 
time-reversal symmetry, 164 
topological Cantor set, 415
cross-section of Hénon attractor, 
439
cross-section of pastry attractor, 431
cross-section of Rossler attractor, 
442
cross-section of strange attractor, 
415
logistic attractor at onset of chaos, 
421 
topological consequences
of uniqueness of solutions, 150, 182 
topological equivalence, 156 
torque, 105, 194 

511
SUBJECT INDEX
torque balance, 314
torsional spring, 117
torus, 276
torus knot, 279
total energy, 161
totally disconnected, 415, 424
trace, 132, 138, 277
tracks, in orbit diagram of logistic 
map, 398
trajectories never intersect, 150, 182
trajectory, 7, 19, 68
as contour for conservative sys-
tem, 162, 170
straight-line, 131
tangent to slope field, 35 
transcendental meditation, 110 
transcription, 93
transcritical bifurcation, 51, 80, 249
as exchange of stabilities, 52
bifurcation diagram for, 52
imperfect, 86
in logistic map, 365
in 2-D systems, 249, 287
laser threshold as example of, 56 
transient, 69, 85 
transient chaos, 338, 340, 452
in forced double-well oscillator, 
452
in games of chance, 340
in Lorenz equations, 338, 352
in Smale horseshoe, 455 
transmitter circuit, 343, 354 
trapping region, 206, 234, 291, 293
and nullclines, 208, 260, 293
and Poincaré-Bendixson theorem, 
206
for chemical oscillator, 260, 293
for glycolytic oscillator, 208
for Hénon map, 457
for Lorenz equations, 350 
tree dynamics, 75, 80, 288 
tree frogs, 303
trefoil knot, 278, 298 
triangle wave, 118
tricritical bifurcation, in fluid patterns, 
87 
trifurcation, 57, 83 
trigonometric identities, 224, 238 
true believers, 290
tumbling in a shear flow, 193, 194 
tumor growth, 39 
tuning fork, 116 
tunneling, 110 
turbulence, 11
at high Rayleigh number, 319, 381
delayed in convecting mercury, 381
not predicted by waterwheel equa-
tions, 319
Ruelle-Takens theory, 3
spatio-temporal complexity of, 386 
turning-point bifurcation, 48 
twin trajectory, 165 
two-body problem, 2 
two-cycle, 365 
two-dimensional system, 15, 125, 146
impossibility of chaos, 212
two-eyed monster, 181 
two-mode laser, 186 
two-timing, 220, 239
derivation of averaged equations, 
225
examples, 221
validity of, 230
U-sequence, 377
and iteration patterns, 401
in BZ chemical reaction, 379, 444
in 1-D maps, 377 
U-tube, pendulum dynamics on, 171 
Ueda attractor, 458 
uncountable set, 406, 407, 423
Cantor set, 411
diagonal argument, 408
real numbers, 407 

512 
SUBJECT INDEX
uncoupled equations, 129 
uniform oscillator, 97, 115 
unimodal map, 377, 444 
uniqueness of closed orbit, 213, 236
in driven pendulum, 271
via Dulac, 234 
uniqueness of solutions, 26, 27, 150
and Lorenz attractor, 327
theorem, 27, 150 
universal, definition of, 390 
universal constants, see Feigenbaum 
constants 
universal function, 390, 402
wildness of, 403 
universal routes to chaos, 3 
universality, 376
discovery of, 379
intuitive explanation for, 390
qualitative, 377
quantitative, 379 
unstable, 131
unstable fixed point, 17, 357 
unstable limit cycle, 198
in Lorenz equations, 324, 336
in subcritical Hopf bifurcation, 
255
unstable manifold, 130, 135
and homoclinic bifurcation, 266, 
274 
unusual bifurcations, 80 
unusual fixed point, 195
vacuum tube, 212, 231 
van der Pol equation, 200 
van der Pol oscillator, 181, 200
amplitude via Green’s theorem, 
240
as relaxation oscillator, 214, 237
averaged equations, 227
biased, 237, 290
circuit for, 231
degenerate bifurcation in, 267
limit cycle for weakly nonlinear, 
225
period in relaxation limit, 216
shape of limit cycle, 201
solved by two-timing, 224
unique stable limit cycle, 201, 213
waveform, 201 
vector, 125 
vector field, 16, 126, 127
on the circle, 95, 115
on the complex plane, 196
on the cylinder, 171, 193, 269
on the line, 16
on the plane, 126, 127, 146 
vector notation, boldface, 125, 146 
velocity vector, 16, 127, 146 
vibration, forced, 448 
video games, 277 
violin string, 214 
viscous damping, 315 
visual perception, 290, 294
voltage oscillations, 109 
voltage standard, 110 
volume contraction
formula for contraction rate, 321
in Lorenz equations, 320
in Rikitake model, 350 
volume preserving, 352 
von Koch curve, 411
infinite arc length, 412
similarity dimension, 414 
von Koch snowflake, 425
walk-through, phase, 106
wallpaper, 192
washboard potential, 119
waterwheel, chaotic, 310 
amplitude equations, 316 
asymmetrically driven, 349 
moment of inertia, 315, 348 
dynamics of higher modes, 348 
equations of motion, 314, 315 

513
SUBJECT INDEX
equivalent to Lorenz, 317, 348 
notation for, 312 
schematic diagram of, 311 
stability diagram (partial), 350 
unlike normal waterwheel, 316
wave functions, 110
waves, chemical, 258, Plate 1
weakly nonlinear oscillator, 217, 237
weather, unpredictability of, 3, 330
wedge, in logistic orbit diagram, 398
whirling pendulum, 168
widely separated time scales, 85, 215
winding number, 297, 298
windows, periodic, 363, 368
yeast, 24, 207
zebra stripes, 90 
zero resistance, 110 
zero-eigenvalue bifurcation, 251, 287 
Zhabotinsky reaction, 258

