Vol.:(0123456789)
Japanese Journal of Statistics and Data Science (2021) 4:1–19
https://doi.org/10.1007/s42081-021-00121-3
1 3
SURVEY ARTICLE (INVITED)
Information criteria and cross validation for Bayesian 
inference in regular and singular cases
Sumio Watanabe1 
Received: 28 February 2021 / Revised: 30 March 2021 / Accepted: 31 March 2021 /  
Published online: 11 May 2021 
© The Author(s) 2021
Abstract
In data science, an unknown information source is estimated by a predictive distri-
bution defined from a statistical model and a prior. In an older Bayesian framework, 
it was explained that the Bayesian predictive distribution should be the best on the 
assumption that a statistical model is convinced to be correct and a prior is given by 
a subjective belief in a small world. However, such a restricted treatment of Bayes-
ian inference cannot be applied to highly complicated statistical models and learning 
machines in a large world. In 1980, a new scientific paradigm of Bayesian inference 
was proposed by Akaike, in which both a model and a prior are candidate systems 
and they had better be designed by mathematical procedures so that the predictive 
distribution is the better approximation of unknown information source. Nowadays, 
Akaike’s proposal is widely accepted in statistics, data science, and machine learn-
ing. In this paper, in order to establish a mathematical foundation for developing a 
measure of a statistical model and a prior, we show the relation among the gener-
alization loss, the information criteria, and the cross-validation loss, then compare 
them from three different points of view. First, their performances are compared in 
singular problems where the posterior distribution is far from any normal distribu-
tion. Second, they are studied in the case when a leverage sample point is contained 
in data. And last, their stochastic properties are clarified when they are used for the 
prior optimization problem. The mathematical and experimental comparison shows 
the equivalence and the difference among them, which we expect useful in practical 
applications.
Keywords  Information criterion · Cross validation · Bayesian model choice
 *	 Sumio Watanabe 
	
swatanab@c.titech.ac.jp
1	
Department of Mathematical and Computing Science, Tokyo Institute of Technology, 2‑12‑1 
OOOkayama, Meguro‑ku, Tokyo, W8‑42, 152‑8552, Japan

2	
Japanese Journal of Statistics and Data Science (2021) 4:1–19
1 3
1  Introduction
In data science, we estimate an unknown information source by a predictive dis-
tribution defined from a statistical model and a prior. In an older framework of 
Bayesian statistics in the 20th century, it was assumed that a statistical model is 
convinced to be correct and a prior is given by a subjective belief, resulting that 
the predictive distribution is believed to be subjectively optimal solution without 
any check or test. However, such a restricted treatment of Bayesian inference can-
not be the foundation of today’s data science in the real world, because almost all 
statistical models and learning machines are different from the data generating 
distributions, and their priors are chosen not by any a priori knowledge or subjec-
tive belief, but by the mathematical laws for the minimum generalization loss, the 
maximum marginal likelihood, or other optimization methods.
In statistics, a new paradigm was already proposed by Akaike (1980a, 1980b) 
that both a statistical model and a prior are understood as only candidate systems 
and they had better be optimized so that the predictive distributions are controlled 
to be the better approximations of the unknown probability distribution. Also it 
was proposed by Good (1952); Gelman et al. (2013); Gelman and Shalizi (2013) 
that the marginal likelihood or the predictive distribution had better be checked 
and tested because Bayesian confirmation theory does not ensure the predictive 
distribution is suitable for the unknown distribution when a statistical model is 
too simple or too redundant. Nowadays, their proposal is widely accepted in sta-
tistics, data science, and machine learning, on which many statistical systems 
and learning machines are being applied to scientific and practical problems. For 
example, see  Antonia Amaral Turkman et  al. (2019); Congdon (2019); Hobbs 
et al. (2015); Korner-Nievergelt (2015); Lambert (2018); Martin (2016); McEl-
reath (2020); Reich and Ghosh (2019); Wang et al. (2018).
In this paper, to develop the scientific evaluation measures of both a statisti-
cal model and a prior, we study the mathematical relation among the generaliza-
tion loss, the information criteria AIC by Akaike (1974), DIC by Spiegelhalter 
et al. (2002), WAIC by Watanabe (2010), and the leave-one-out cross-validation 
loss by Gelfand et al. (1992); Vehtari and Lampinen (2002) in Bayesian inference 
from the following three points of view.
First, they are compared in the singular condition that the posterior distribution 
can not be approximated by any normal distribution. In many statistical models 
which have hierarchical structures or latent variables, the posterior distributions 
can not be approximated by any normal distribution, even asymptotically. In such 
cases, the generalization loss can not be estimated by information criteria AIC or 
DIC, however, it can be estimated by WAIC and the cross validation.
Second, they are studied in the case when a leverage sample point is contained in 
data. If a sample consists of independently and identically distributed random varia-
bles, then information criteria and the leave-one-out cross-validation loss are asymp-
totically equivalent, however, if otherwise, they are not. If a conditional probability 
is estimated using not an i.i.d. input sample, then there are cases when information 
criteria are better estimators of generalization loss than the cross-validation loss.

3
1 3
Japanese Journal of Statistics and Data Science (2021) 4:1–19	
And last, their properties are clarified when they are used for the prior optimiza-
tion problem. Information criteria and cross validation loss can be understood as 
the evaluation measures of the prior design. Minimization of WAIC and leave-one-
out cross validation loss makes the average generalization loss, however, it does not 
minimize the generalization loss as a random variable.
This paper consists of five sections. In the second section, we define the gen-
eralization loss, the information criteria, and the cross-validation loss. In the third 
section, they are compared from the three different points of view. In the fourth sec-
tion, their statistical difference is discussed, and in the last section, we conclude the 
paper.
2  Definitions of information criteria
In this section, we define the generalization loss, information criteria, and cross 
validation.
2.1  Definitions of statistical inference
Let q(x) be a probability density function of x ∈ℝN and X1 , X2 , ..., Xn be an i.i.d. 
sample, in other words, a sample is a set of independent random variables whose 
probability density function is q(x). In this paper, we mainly study i.i.d. cases. For 
the case when a sample is not i.i.d., see the Sect. 3.2. The cross validation procedure 
needs the i.i.d. condition, whereas information criteria can be used in several not 
i.i.d. cases as shown in Watanabe (2021).
A statistical inference is defined by a map
where p∗(x) is an estimated probability density function on ℝN , which is often 
called a predictive distribution. There are many procedures in statistical inference, 
for example, the maximum likelihood method, the maximum a posteriori (MAP) 
method, the Bayesian method, the sparse estimation method, and so on. In this 
paper, we study the Bayesian method.
Let p(x|w) and 휑(w) be a statistical model and a prior, respectively, where w ∈ℝd 
is a parameter. In the maximum likelihood method, the predictive distribution is 
defined by p∗(x) = p(x|w∗) , where w∗ is the maximum likelihood estimator. In the 
MAP method, the maximum likelihood estimator is replaced by the maximum a 
posteriori estimator. In the Bayesian method, the posterior distribution is defined by
where Zn is a normalizing constant referred to as the marginal likelihood. For an 
arbitrary function of f(w), let 피w[f(w)] and 핍w[f(w)] denote the posterior average and 
Xn = (X1, X2, … , Xn) ↦p∗(x),
(1)
p(w|Xn) = 1
Zn
휑(w)
n
∏
i=1
p(Xi|w),

4	
Japanese Journal of Statistics and Data Science (2021) 4:1–19
1 3
the posterior variance of f(w), respectively. The Bayesian predictive distribution is 
defined by
Note that, in data science, we do not know whether a statistical model and a prior 
are appropriate or not.
For a given predictive distribution p∗(x) , its generalization loss Gn is defined by
Since Xn is a random variable, Gn is also a random variable. Then minimizing Gn is 
equivalent to minimizing Kullback-Leibler divergence K(q||p∗) , where
Hence the generalization loss Gn gives the quantitative evaluation of a pair of a 
model and a prior according to the Kullback-Leibler divergence, however, since q(x) 
is unknown in general, we need mathematical theory to estimate Gn . The training 
loss Tn is defined by
The generalization loss Gn can not be estimated by Tn , because the expectation 
values of Gn and Tn are not equal to each other. If a more complicated model is 
employed, then the training loss decreases, but the generalization loss may increase.
Remark  It is shown by the Bayesian decision theory that, if w is generated from 
some true Φ(w) and if Xn is generated from some true ∏n
i=1 P(Xiw) , then the expec-
tation value of the generalization loss is made smallest if and only if 휙(w) = Φ(w) 
and p(x|w) = P(x|w) . However, in almost all situations of statistical inference, both 
the true prior and the true model are unknown, hence the decision theory can not be 
the base of Bayesian inference of unknown information source q(x) in a real world. 
If q(x) is located outside of a set of statistical model, then min max theory can not be 
used for designing the prior.
2.2  Asymptotic generalization loss
In this subsection, we explain the asymptotic behavior of the generalization loss of 
Bayesian inference. We need several mathematical definitions. Let W0 ⊂ℝd be the set 
of all parameters that minimize
(2)
p∗(x) = p(x|Xn) = 피w[p(x|w)].
(3)
Gn = −∫q(x) log p∗(x)dx.
K(q||p∗) = ∫q(x) log q(x)
p∗(x)dx.
Tn = −1
n
n
∑
i=1
log p∗(Xi).
L(w) = −∫q(x) log p(x|w)dx.

5
1 3
Japanese Journal of Statistics and Data Science (2021) 4:1–19	
If there exists w0 ∈W0 such that q(x) = p(x|w0) , then an unknown distribution q(x) 
is said to be realizable by a statistical model p(x|w). If W0 consists of a single ele-
ment w0 and the Hessian matrix
is positive definite, then q(x) is said to be regular for p(x|w). Many statistically 
asymptotic theories assume the regularity condition, however, if a statistical model 
has a hierarchical structure or latent variables, then regularity condition is not satis-
fied. In fact, neural networks, normal mixtures, hidden Markov models, matrix fac-
torizations, latent Dirichlet allocations, and so on do not satisfy the regularity condi-
tion, resulting that their posterior distributions are far from any normal distribution. 
Even in such singular cases, the generalization performance of Bayesian inference is 
clarified based on algebraic geometry by Watanabe (2009).
Let Ln(w) be the empirical log loss function,
We assume that, for an arbitrary parameter w0 ∈W0 , p(x|w0) represents the same 
probability density function. Note that, if the unknown distribution is realizable by a 
statistical model, then L(w0) and Ln(w0) are equal to the entropy S and the empirical 
entropy Sn of q(x), respectively.
Even if an unknown distribution q(x) is neither realizable by nor regular for a sta-
tistical model, it is proved by singular learning theory in Watanabe (2009, 2018) that 
there exists a random variable 휉n such that
which satisfies the convergence in distribution 휉n →휉 . We need the zeta function of 
Bayesian statistics for z ∈ℂ by
It is proved based on the resolution theorem in Hironaka (1964) that 휁(z) is a hol-
omorphic function in ℜ(z) > 0 which can be analytically continued to the unique 
meromorphic function onto the entire complex plane, whose poles are all real and 
negative values. Let (−휆(w0)) be the largest pole of the zeta function. Then, by using 
algebraic geometry, it is proved that
Therefore,
Jij =
휕2L
휕wi휕wj
(w0)
Ln(w) = −1
n
n
∑
i=1
log p(Xi|w).
Gn = Ln(w0) + 휉n∕n,
휁(z) = ∫(L(w) −L(w0))z휑(w)dw.
lim
n→∞피[휉n] = 피[휉] = 휆(w0).
(4)
피[Gn] = L(w0) + 휆(w0)∕n + o(1∕n).

6	
Japanese Journal of Statistics and Data Science (2021) 4:1–19
1 3
This equation shows that the generalization loss is the sum of the bias L(w0) and 
the variance 휆(w0)∕n . If an unknown distribution is regular for a statistical model, 
then 휆(w0) = d∕2 , where d is the dimension of the parameter space, if otherwise, 
휆(w0) ≤d∕2 with an assumption 𝜑(w0) > 0 for some w0 ∈W0 . The constant 휆(w0) 
is referred to as the real log canonical threshold, which is a birational invariant, in 
other words, the generalization loss of Bayes inference is determined by algebro-
geometric structure of a statistical model.
Concrete values of them were found in the matrix factorization by Aoyagi and 
Watanabe (2005), the Poisson mixture by  Sato and Watanabe (2019), the latent 
Dirichlet allocation by  Hayashi (2021), and many statistical models and learning 
machines such as Yamazaki and Watanabe (2003); Yamazaki (2016); Yamazaki and 
Kaji (2013); Zwiernik (2011); Watanabe (2009). They are useful in the design of 
Markov chain Monte Calro by Nagata and Watanabe (2008) and the singular Bayes-
ian information criterion by Drton and Plummer (2017).
Remark  From the mathematical point of view, the real log canonical thresh-
old 휆(w0) can be understood as a volume dimension of the neighborhood of a set 
{w ; L(w) −L(w0) = 0} . In fact, it is proved in Watanabe (2009) that
The prediction accuracy of Bayes inference is determined by the volume of the set 
of the almost optimal parameters.
2.3  Information criteria and cross validation
In this subsection, we introduce several information criteria to estimate the gener-
alization loss. For the other information criteria to estimate the marginal likelihood, 
see Sect.  4. The asymptotic behavior of the generalization loss was clarified by 
Eq.(3), however, the real log canonical threshold depends on the unknown distribu-
tion, resulting that w0 is also unknown, hence it cannot be directly applied to practi-
cal problems.
Remark  In this paper, we study the scale of information criteria and cross validation 
as estimators of the generalization loss 피[Gn] . In many practical problems, it should 
be remarked that their scales are defined so as to estimate 2n × 피[Gn] , according to 
the Akaike’s pioneer work.
The concept of the information criterion was firstly proposed by Akaike (1974). 
The definition of AIC is given by
𝜆(w0) = lim
𝜀→+0
1
log 𝜀log
(
∫L(w)−L(w0)<𝜀
𝜑(w)dw
)
.
AIC = Tn + d∕n,

7
1 3
Japanese Journal of Statistics and Data Science (2021) 4:1–19	
which is called Akaike information criterion (AIC). At first, AIC was made for esti-
mating the generalization loss of the maximum likelihood method, but it can be 
employed in Bayes, because if the unknown distribution is realizable by and regu-
lar for a statistical model, then the order of the difference between the above AIC 
and AIC using the maximum likelihood estimator is smaller than 1/n. For Bayesian 
estimation, the deviance information criterion (DIC) was proposed by Spiegelhalter 
et al. (2002),
by which the Bayesian generalization loss can be estimated, if an unknown distribu-
tion is realizable by and regular for a statistical model. The widely applicable infor-
mation criterion (WAIC) was proposed by
The value 핍w[log p(Xi|w)] shows the fluctuation of log p(Xi|w) according to the pos-
terior distribution. The mathematical relation between the generalization loss and 
this value is shown by using the functionally partial integration over the limit Gauss-
ian process of the empirical process in Watanabe (2009). This relation has the same 
mathematical structure as the fluctuation-dissipation theorem which shows the cor-
respondence from the system is equal to the fluctuation of the system.
The leave-one-out cross-validation loss in Gelfand et al. (1992); Vehtari and Lamp-
inen (2002); Vehtari et al. (2017) is defined by
where Xn ⧵Xi is the sample which does not contain Xi . If the posterior distribution is 
precisely realized, then LOO can be numerically approximated by using the impor-
tance sampling cross-validation loss,
Even if an unknown distribution is unrealizable by or singular for a statistical 
model, the generalization loss can be estimated by WAIC, LOO, and ISCV. Note 
that AIC, DIC, and WAIC are calculated numerically using Markov chain Monte 
Carlo (MCMC) method, if the posterior variance V(i) = 핍w[log p(Xi|w)] is finite, 
The value V(i) shows the leverage of a sample point Xi which will be discussed 
in Sect.  3.2. Note that LOO needs n different posterior distributions for Xn ⧵Xi , 
whereas ISCV can be calculated by one posterior distribution for Xn . However, in 
ISCV, the average 피w[1∕p(Xi|w)] or variance 핍w[1∕p(Xi|w)] may be larger or infi-
nite if a leverage sample point is contained, which was proved by Peruggia (1997); 
Epifani et al. (2008), resulting that the posterior calculation by MCMC method fails, 
DIC =1
n
n
∑
i=1
log p(Xi|피w[w]) −2
n
n
∑
i=1
피w
[log p(Xi|w)],
WAIC =Tn + 1
n
n
∑
i=1
핍w
[log p(Xi|w)].
LOO = −1
n
n
∑
i=1
log p(Xi|Xn ⧵Xi),
ISCV =1
n
n
∑
i=1
log 피w
[1∕p(Xi|w)].

8	
Japanese Journal of Statistics and Data Science (2021) 4:1–19
1 3
and a numerical improvement was developed by Gelman et al. (2014). The differ-
ence of information criteria and the leave-one-out cross validation in influential 
observation cases is explained in Sect. 3.2.
3  Comparison of information criteria and cross validation
In this section, we compare information criteria and cross validation loss in three 
different problems, that is to say, (1) in singular posterior cases, (2) in influential 
observation cases, and (3) in hyperparameter optimization cases.
3.1  Regular and singular cases
Firstly, we compare information criteria and leave-one-out cross-validation loss in 
regular and singular cases.
Regular Cases. If an unknown distribution q(x) is realizable by and regular for a 
statistical model p(x|w), then the posterior distribution can be approximated by a 
normal distribution when the sample size n tends to infinity. On such a regularity 
condition, AIC, DIC, WAIC, LOO, and ISCV are asymptotically equivalent to each 
other as random variables. That is to say,
They are all asymptotically unbiased estimators of the generalization loss,
However, the generalization loss and AIC have asymptotically inverse correlation as 
is shown by Watanabe (2018),
and DIC, WAIC, LOO, and ISCV satisfy the same equation as Eq.(5). This prop-
erty strongly affects the model selection procedures by AIC, DIC, WAIC, LOO, and 
ISCV, which is the weak point of both the information criteria and the cross-valida-
tion loss. It should be emphasized that, since Eq.(5) is not trivial, many users of the 
information criteria and the cross validation loss may not be aware of such a risk.
Singular Cases. In general, the posterior distribution can not be approximated by 
any normal distribution even if the sample size tends to infinity in Watanabe (2018). 
AIC = DIC + op(1∕n) = WAIC + op(1∕n)
= ISCV + op(1∕n) = LOO + op(1∕n).
피[Gn] = 피[AIC] + o(1∕n) = 피[DIC] + o(1∕n) = 피[WAIC] + o(1∕n)
= 피[LOO] + o(1∕n) = 피[ISCV] + o(1∕n).
(5)
(Gn −L(w0)) + (AIC −Ln(w0)) = d
n + op(1∕n)

9
1 3
Japanese Journal of Statistics and Data Science (2021) 4:1–19	
Even if the posterior distribution is far from any normal distribution, it was proved 
in Watanabe (2010) that
and that
In such singular cases, neither AIC nor DIC satisfies these equations. In singular 
cases, the posterior expectation value of the parameter 피w[w] in DIC is not appropri-
ate for statistical inference. The generalization loss and WAIC have asymptotically 
inverse correlation as is shown by Watanabe (2010),
and both LOO and ISCV satisfy the same equation as Eq.(7). In singular cases, the 
real log canonical threshold 휆(w0) is not larger than the regular cases. Hence, even 
if a statistical model p(x|w) is redundant for an information source q(x), the increase 
of the Bayesian generalization loss is smaller than the regular cases, which is one 
of the good properties of Bayesian inference. In the model selection problem, we 
should remark the fact that the increases of WAIC, LOO, and ISCV are also smaller 
than the regular cases.
Example 1  (Normal mixture in regular and singular cases). Let us compare AIC, 
DIC, WAIC, and ISCV in regular and singular cases. A normal distribution of 
x ∈ℝN which has a mean bk and a variance and 1∕sk is denoted by
We study a statistical model and a prior given in the following equations, where 
w = (a, b, s) is a parameter, a = {ak} , b = {bk} , and s = {sk},
Here K is the number of components in the statistical model. Note that the mix-
ture ratio a = {ak} satisfies ak ≥0 and ∑
k ak = 1 , and (훼, r, 휌, 휇) is a hyperparam-
eter. A normal mixture is a typical singular model, because if a model is redundant, 
then W0 is a set with singularities as pointed out by Yamazaki and Watanabe (2003). 
Let us show simple experimental results for regular and singular cases as is shown 
WAIC = LOO + Op(1∕n2),
(6)
피[Gn] = 피[WAIC] + O(1∕n2) = 피[LOO] + O(1∕n2).
(7)
(Gn −L(w0)) + (WAIC −Ln(w0)) = 2휆(w0)
n
+ op(1∕n),
N(xbk, sk) =
 sk
2휋
N∕2
exp

−sk‖x −bk‖2
2

.
p(xw) =
K

k=1
ak N(xbk, sk),
휑(a, b, s) ∝
K

k=1
(ak)훼−1(sk)r exp(−(sk∕2)(휌+ 휇‖bk‖2)).

10
	
Japanese Journal of Statistics and Data Science (2021) 4:1–19
1 3
in Watanabe (2021). An experiment was set as N = 3 , n = 100 , r = N∕2 , 훼= 1 , and 
휌= 휇= 1 . A distribution q(x) was set as p(x|w0),
where b10 = (3, 0, 0) , b20 = (0, 3, 0) , b30 = (3, 0, 0) , b40 = (−1, −1, −1) . For a regular 
case, K0 = 4 was used, whereas, for a singular case, K0 = 2 was used. These two dis-
tributions were estimated by a normal mixture of K = 4 components. The posterior 
distributions were approximated by using the Gibbs sampler of the simultaneous dis-
tribution of the parameter and latent variable. In Table 1, means and standard devia-
tions of Gn −S , AIC −Sn , DIC −Sn , WAIC −Sn and ISCV −Sn are shown which 
were calculated by using 100 independent trials, where S = L(w0) and Sn = Ln(w0) 
are entropy and empirical entropy of p(x|w0) . In the regular case, all information 
criteria and ISCV could approximate the generalization loss, whereas, in the singu-
lar case, averages of AIC and DIC were larger and smaller than the generalization 
loss, respectively, whereas averages of WAIC and ISCV were almost equal to the 
generalization loss. The sample size n = 100 is not sufficiently large according to 
the asymptotic theory, however, information criteria and cross validation loss were 
almost equal to each other.
3.2  Influential observation
It is often assumed that a sample is independently and identically distributed (i.i.d.) 
in theoretical studies of information criteria. Such an i.i.d. condition is necessary for 
the use of the cross validation loss, however, information criteria can be employed in 
several not i.i.d. cases, for example, conditional independent cases.
In this subsection, we study the statistical inference of a conditional probability 
density for dependent inputs. Assume that xn = {xi;i = 1, 2, … , n} is not a set of 
random variables but a constant sequence and that {Yi;i = 1, 2, … , n} is a set of an 
p(x|w0) = (1∕K0)
K0
∑
k=1
N(x|bk0, 1),
Table 1   Means and standard deviations of information criteria in regular and singular cases
A normal mixture of four components was used as a statistical model, and two different distributions 
were estimated. In a singular case, AIC and DIC were larger and smaller than the generalization loss, 
respectively. WAIC and ISCV could estimate the generalization loss even if the posterior distribution was 
singular
Case
M/S
Gn −S
AIC −Sn
DIC −Sn
WAIC −Sn
ISCV −Sn
Regular
MEAN
0.0930
0.1232
0.1011
0.0993
0.0998
Regular
STD
0.0326
0.0264
0.0394
0.0262
0.0263
Singular
MEAN
0.0612
0.1491
– 0.4357
0.0584
0.0586
Singular
STD
0.0262
0.0302
0.3794
0.0255
0.0256

11
1 3
Japanese Journal of Statistics and Data Science (2021) 4:1–19	
independent random variables whose probability distribution is ∏n
i=1 q(yixi) . In this 
situation, the posterior average 피w[ ] and the variance 핍w[ ] are defined by the pos-
terior distribution
The generalization and training losses are defined by
The information criteria and leave-one-out cross-validation loss are defined by the 
same way as foregoing equations,
Note that, if xn is independent and identically distributed (i.i.d.), then 
피[ISCV] = 피[Gn−1] by definition, whereas, if otherwise, 피[ISCV] ≠피[Gn−1] . For 
example, if xn is fixed or dependent, ISCV is not an unbiased estimator of the gener-
alization loss in general. On the other hand, even for a fixed xn , information criteria 
are asymptotically unbiased estimators of the generalization loss if the sample size 
is sufficiently large. If an unknown distribution is realizable by and regular for a 
statistical model, then AIC, DIC, and WAIC can be employed, which is shown by 
Watanabe (2018).
Example 2  (Influential observation in linear regression) We study a simple regres-
sion model of x, y ∈ℝ and a prior 휑(w),
p(w|xn, Yn) = 1
Zn
휑(w)
n
∏
i=1
p(Yi|xi, w).
Gn = −1
n
n
∑
i=1 ∫q(yi|xi) log 피w[p(yi|xi, w)]dyi,
Tn = −1
n
n
∑
i=1
log 피w[p(Yi|xi, w)].
(8)
AIC =Tn + d
n,
(9)
DIC = 1
n
n
∑
i=1
log p(Yi|xi, 피w[w]) −2
n
n
∑
i=1
피w[log p(Yi|xi, w)],
(10)
WAIC = Tn + 1
n
n
∑
i=1
핍w[log p(Yi|xi, w)],
(11)
ISCV = 1
n
n
∑
i=1
log 피w[1∕p(Yi|xi, w)].
(12)
p(y|x, a, s) =(s∕(2휋))1∕2 exp(−(s∕2)(y −ax)2),

12
	
Japanese Journal of Statistics and Data Science (2021) 4:1–19
1 3
where a ∈ℝ, s > 0 are parameters and 휇= 0.01 is a hyperparamater. Let the sample 
size n = 10 , and we set the xn as xi = i∕10
(i = 1, 2, … , 9) and
We compare information criteria and importance sampling leave-one-out cross-val-
idation loss for two cases x10 = 4 , which is a leverage sample point, and x10 = 1 , 
which is not. A regression problem in which a leverage sample point is contained 
is often called an influential observation problem. The output Yn are independently 
taken from ∏
i p(yixi, a0, s0) , where a0 = 0.1 , 1∕s0 = 0.01 . Then S and Sn are condi-
tional entropy and empirical one, respectively. The average and standard deviations 
of the generalization loss, information criteria, and importance sampling leave-one-
out cross-validation loss are shown in Table.2. In an influential observation case, the 
posterior average and variance of 피w[1∕p(Yi|Xi, w)] are larger or infinite by Peruggia 
(1997); Epifani et al. (2008), and both the average and variance of the 피[ISCV] were 
larger than that of the generalization loss, where the averages of information criteria 
were asymptotically equal to that of generalization loss. In general, whether a sam-
ple point is leverage one or not depends on not only a sample point itself but also a 
statistical model. The author would like to recommend that both information criteria 
and cross validation had better be calculated and compared. If they are different, a 
leverage sample point is contained in the data, which can be found because it makes 
the functional variance
larger than the other sample points, which is shown in Watanabe (2018).
Example 3  (High dimensional regression) We study a high dimensional regression 
model of y ∈ℝ , x, a ∈ℝM and a prior 휑(a),
(13)
휑(a, s|휇) ∝s exp(−(휇∕2)s(1 + a2)),
x10 = 1 or 4.
V(i) = 핍w
[log p(Yi|xi, w)].
(14)
p(y|x, a) = (1∕(2휋))1∕2 exp(−(1∕2)(y −a ⋅x)2),
(15)
휑(a) ∝exp(−(1∕2)‖a‖2)).
Table 2   Means and standard deviations of information criteria for fixed inputs
The case x10 = 4 is a leverage sample point, which is the influential observation, but x10 = 1 is not. 
Cross-validation loss can not be used if an input is a leverage sample point
Case
Gn −S
AIC −Sn
DIC −Sn
WAIC −Sn
ISCV −Sn
Ordinary
MEAN
0.1033
0.1095
0.0764
0.1015
0.1178
Ordinary
STD
0.1250
0.1068
0.1091
0.1199
0.1261
Leverage
MEAN
0.0959
0.1270
0.0770
0.0869
0.1274
Leverage
STD
0.1142
0.1121
0.1133
0.1217
0.1332

13
1 3
Japanese Journal of Statistics and Data Science (2021) 4:1–19	
In this example, we study the difference of two generalization losses,
The first one G(1)
n  is the generalization loss for the case {(Xi, Yi)} is the set of inde-
pendent random variables subject to q(x)q(y|x), whereas the second one G(2)
n  is that 
for the case {(Yi|xi)} is the set of conditionally independent random variables subject 
to q(yi|xi) for given {xi} . If M∕n →0 , then G(1)
n −G(2)
n →0 , however, if otherwise, 
then G(1)
n ≠G(2)
n  . Two entropies are defined by
Information criteria AIC, DIC, WAIC, and ISCV are defined by the same way as 
Eqs.(8)–(11). LOO is defined by
In the experiment, {xi} was independently taken from
and 
fixed. 
{Yi} 
was 
independently 
taken 
from 
p(y|xi, a0) , 
where 
a0 = (1, 1, ..., 1) ∈ℝM . The sample size n = 50 was fixed, and the dimension M 
was set as M = 10, 20, 50, 100, 200 . In high dimensional cases, we can not assume 
that n is sufficiently large and there are many leverage sample points. Two different 
generalization losses were calculated. In Table 3, GE1 and GE2 denote G(1)
n −S(1) 
and G(2)
n −S(2) , respectively. LOO, ISCV, WAIC, DIC, and AIC show the values of 
LOO-Sn , ISCV-Sn , WAIC-Sn , DIC-Sn , and AIC-Sn , respectively. Note that the empir-
ical entropy does not depned on the assumption of inputs. In the experiment, LOO 
and WAIC estimated averages of GE1 and GE2, respectively. The standard devia-
tions of LOO were larger than other criteria. In a high dimensional case, ISCV was 
not equal to LOO, because the posterior average in ISCV by MCMC was not calcu-
lated precisely.
G(1)
n = −∫∫q(x)q(y|x) log 피a[p(y|x, a)]dxdy,
G(2)
n = −1
n
n
∑
i=1 ∫q(y|xi) log 피a[p(y|xi, a)]dy.
S(1) = −∫∫q(x)q(y|x) log q(y|x)dxdy,
S(2) = −1
n
n
∑
i=1 ∫q(yi|xi) log q(yi|xi)dyi.
LOO = −1
n
n
∑
i=1
log p(Yi|Xi, Xn ⧵Xi, Yn ⧵Yi).
q(x) =
1
(2휋)M∕2 exp

−‖x‖2
2


14
	
Japanese Journal of Statistics and Data Science (2021) 4:1–19
1 3
3.3  Prior optimization problem
In this subsection, we study a prior optimization problem in regular cases. That is 
to say, for a fixed statistical model, the generalization loss, information criteria, and 
cross-validation loss are understood as functionals of priors, and their minimization 
problem is studied.
In this section, a candidate prior 휑(w) is assumed to be a general nonnegative 
function of a parameter w ∈ℝd which may be improper, that is to say ∫휑(w)dw 
may be infinite. Even in such cases, the posterior and predictive distributions can be 
defined by the same equations as Eqs. (1), (2). Let G(휑) , WAIC(휑) , and LOO(휑) be 
the generalization loss, WAIC, and the leave-one-out cross-validation loss which are 
functionals of a candidate prior 휑(w).
Remark  In this subsection, we assume the regularity condition that an unknown 
distribution is regular for a statistical model, however, it may be unrealizable by a 
statistical model. The general theory for singular cases is not yet constructed. If a 
posterior distribution is singular, then it has the phase transition according to hyper-
parameter control as is explained in Watanabe (2018), in other words, the asymp-
totic support of the posterior distribution drastically changes at some critical value 
of the hyperparameter.
Let 휑0(w) be an arbitrary fixed prior. For example, one can choose 휑0(w) = 1 for 
an arbitrary w. For a given candidate prior 휑(w) , we define
휙(w) = 휑(w)∕휑0(w).
Table 3   Means and standard deviations in a high dimensional regression problem. M is the dimension of 
x and n is a sample size
Two kinds of generalization losses GE1 and GE2 are defined, which are estimated by LOO, ISCV, 
WAIC, DIC, and AIC. the experimental result shows that LOO and WAIC estimated GE1 and GE2, 
respectively. Standard deviation of LOO was larger than other criteria
M
n
GE1
GE2
LOO
ISCV
WAIC
DIC
AIC
Mean
10
50
0.112
0.090
0.108
0.108
0.099
0.096
0.127
Mean
20
50
0.226
0.156
0.246
0.242
0.193
0.200
0.298
Mean
50
50
1.014
0.312
1.044
0.682
0.340
0.432
0.847
Mean
100
50
1.965
0.344
1.974
0.753
0.344
0.488
1.844
Mean
200
50
2.500
0.350
2.531
0.751
0.336
0.486
3.836
Std
10
50
0.050
0.037
0.055
0.055
0.054
0.046
0.046
Std
20
50
0.069
0.046
0.076
0.076
0.070
0.061
0.063
Std
50
50
0.160
0.050
0.223
0.151
0.114
0.103
0.102
Std
100
50
0.067
0.054
0.169
0.116
0.101
0.101
0.100
Std
200
50
0.038
0.056
0.158
0.122
0.112
0.111
0.111

15
1 3
Japanese Journal of Statistics and Data Science (2021) 4:1–19	
If 휑0(w) ≡1 is chosen, then 휙(w) = 휑(w) . Assume that the posterior distribution can 
be approximated by a normal distribution. Then it was proved in Watanabe (2018) 
that there exists a function M(휙, w) of 휙(w) and w which satisfies
Also it was proved in Watanabe (2018) that there exists a function M(휙, w) of 휙(w) 
and w which satisfies
The concrete forms of M(휙, w) and M(휙, w) are defined by using higher order 
differentials of the log density function log p(x|w) , which are given in Watanabe 
(2018). They satisfy
It should be emphasized that the generalization loss as a random variable has differ-
ent behavior from the information criteria and leave-one-out cross-validation loss.
Hence minimization of WAIC or LOO makes the average generalization loss asymp-
totically, however, it does not minimize the generalization loss as a random variable. 
Note that minimization of AIC or DIC does not minimize the generalization loss as 
either the average or the random variable.
(16)
피[G(휑)] = 피[G(휑0)] + M(휙, w0)
n2
+ o
( 1
n2
)
,
(17)
피[LOO(휑)] = 피[G(휑0)] + d∕2 + M(휙, w0)
n2
+ o
( 1
n2
)
,
(18)
피[WAIC(휑)] = 피[G(휑0)] + d∕2 + M(휙, w0)
n2
+ o
( 1
n2
)
.
(19)
LOO(𝜑) = LOO(𝜑0) + M(𝜙, ̂w)
n2
+ Op
( 1
n3
)
,
(20)
WAIC(𝜑) = WAIC(𝜑0) + M(𝜙, ̂w)
n2
+ Op
( 1
n3
)
.
(21)
M(𝜙, ̂w) = M(𝜙, w0) + Op
( 1
n1∕2
)
,
(22)
M(𝜙, 피w[w]) = M(𝜙, ̂w) + Op
(1
n
)
,
(23)
피[M(𝜙, ̂w)] = M(𝜙, w0) + O
(1
n
)
.
(24)
G(휑) = G(휑0) + Op
( 1
n3∕2
)
.

16
	
Japanese Journal of Statistics and Data Science (2021) 4:1–19
1 3
Example 4  (Prior Optimization in linear regression) A simple regression model 
of x, y ∈ℝ same as Eqs.(12) and (13) in Example.2 is studied. In this example, xn 
is independently taken from the standard normal distribution, and Yn is also inde-
pendently taken from p(yi|xi, a0, s0) , where n = 10 , a0 = 0.1 , and 1∕s0 = 0.01 . The 
generalization loss, AIC, DIC, WAIC, and importance samping leave-one-out cross-
validation loss of 50 candidate hyperparameters 0 < 𝜇≤0.2 were compared, and 
the hyperparameters which made them smallest were obtained for 100 independent 
samples. They are shown in Table 4. Note that
which were different. By using WAIC or ISCV, the former was estimated, whereas 
it was not estimated by AIC or DIC. Based on the higher order equivalence, WAIC 
and ISCV can be used for prior optimization for the average generalization loss. In 
the experiment, the variance by WAIC was smaller than that of ISCV.
4  Discussion: WBIC as an extension of BIC
In the previous sections, we studied the information criteria and leave-one-out cross-
validation loss as estimators of the generalization loss. In this discussion, we com-
pare the AIC type criteria with BIC ones.
Before discussion, we summarize the statistical property of the marginal likeli-
hood. The marginal likelihood Zn is defined by Eq.(1), which can be understood as 
an estimated probability density of Xn by a statistical model and a prior, because it 
satisfies ∫Zndxn = 1 . The free energy Fn , which is equal to the minus log marginal 
likelihood, is also defined by
Then its expectation value is equal to
argmin 피[G(휑)] = 0.048,
피[argmin G(휑)] = 0.036,
Fn = −log Zn.
피[Fn] = nS + ∫q(xn) log q(xn)
p(xn)dxn,
Table 4   Means and standard deviations of hyperparameters which made the generalization loss, AIC, 
DIC, WAIC, and the leave-one-out cross validation loss smallest
The optimal hyperparameter that minimizes the average generalization loss was estimated by WAIC or 
the leave-one-out cross-validation loss
휇
argmin G
argmin AIC
argmin DIC
armin WAIC
argmin ISCV
Mean
0.0368
0.0086
0.0276
0.0489
0.0524
STD
0.0287
0.0059
0.0160
0.0276
0.0303

17
1 3
Japanese Journal of Statistics and Data Science (2021) 4:1–19	
where S is the entropy of q(x), q(xn) = ∏n
i=1 q(xi) and p(xn) = Zn . Hence the expec-
tation value of the free energy is smallest if and only if the Kullback-Leibler diver-
gence between q(xn) and p(xn) is smallest. Moreover, it is immediately derived that
Its asymptotic value is given by
where 휆(w0) is the real log canonical threshold. If the posterior distribution can be 
approximated by a normal distribution, then 휆(w0) = d∕2 and Fn is asymptotically 
approximated by BIC in Schwarz (1978). Even in singular cases, Fn can be esti-
mated by sBIC in Drton and Plummer (2017) and WBIC in Watanabe (2013).
Let us compare the information criteria and the marginal likelihood from two differ-
ent points of view. For short description, the information criteria AIC, DIC, WAIC, and 
LOO are referred to as AICs, whereas BIC, sBIC, WBIC, and the free energy are BICs.
First, we compare AICs and BICs from the viewpoint of model selection consist-
ency. Let P = {pk(x|wk) ; k = 1, 2, … , K} be a set of candidate statistical models. 
Assume that there exists a statistical model in P by which q(x) is realizable. The set 
of models P0 is defined by the set of all statistical models in P by which q(x) is realiz-
able. For a given q(x), the statistical model p ∈P0 that has the smallest real log canoni-
cal threshold is called the smallest true model. A model selection criterion is called to 
have the model selection consistency if and only if the probability that the smallest true 
model is chosen converges to one as the sample size tends to infinity. The asymptotic 
properties of AICs and BICs are given by
If q(x) is unrealizable by p(x|w), then the convergence in probability holds,
If q(x) is realizable by p(x|w), then in both regular and singular cases, n(Tn −Sn) 
converges to a random variable in distribution in Watanabe (2009, 2018). In AICs, 
the penalty term has the same order as the standard deviation of Tn −Sn , whereas in 
BICs, it is larger than that of Tn −Sn . It follows that AICs do not have model selec-
tion consistency but BICs have, in both regular and singular cases.
Second, we study AICs and BICs from the viewpoint of asymptotic efficiency. 
Assume that q(x) is not realizable by any model in P . Then the optimal model for effi-
ciency is defined by the model that minimizes 피[Gn] , which depends on the sample 
size n. Remark that consistency is defined for the case n →∞ whereas efficiency is for 
finite n. A model selection criterion is said to have more efficiency if and only if 피[Gn] 
is made smaller. If BICs are employed, then the penalty term is too large for the smaller 
generalization loss, hence AICs have more efficiency than BICs, in both regular and 
singular cases. In practical applications of data science, appropriate information criteria 
had better be employed according to the purpose of the data analysis.
피[Gn] = 피[Fn+1] −피[Fn].
Fn = nLn(w0) + 휆(w0) log n + op(log n),
AICs = Tn + Op(1∕n),
BICs∕n = Tn + 휆(w0) log n∕n + op(log n∕n).
Tn −Sn →minwKL(q(x)||p(x|w)) > 0.

18
	
Japanese Journal of Statistics and Data Science (2021) 4:1–19
1 3
5  Conclusion
Information criteria and leave-one-out cross-validation loss in Bayesian modeling 
are studied, and three points are clarified. First, if the posterior distribution is far 
from any normal distribution, then AIC and DIC cannot be used for model evalua-
tion, whereas WAIC and leave-one-out cross-validation loss can be employed. Sec-
ond, if inputs in a sample are not independent, then leave-one-out cross-validation 
loss is not an asymptotic unbiased estimator of the generalization loss. And last, in 
the hyperparameter optimization problem, WAIC and leave-one-out cross-validation 
loss can be used for minimum average generalization loss.
Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, 
which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as 
you give appropriate credit to the original author(s) and the source, provide a link to the Creative Com-
mons licence, and indicate if changes were made. The images or other third party material in this article 
are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the 
material. If material is not included in the article’s Creative Commons licence and your intended use is 
not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission 
directly from the copyright holder. To view a copy of this licence, visit http://​creat​iveco​mmons.​org/​licen​
ses/​by/4.​0/.
References
Akaike, H. (1974). A new look at the statistical model identification. IEEE Transactions on Automatic 
Control. 19,60
Akaike, H. (1980). Likelihood and Bayes procedure. Bayesian Statistics. 143–166.
Akaike, H. (1980). On the transition of the paradigm of statistical inference. The proceedings of the Insti-
tute of Statistical Mathematics, 27, 5–12.
Antonia Amaral Turkman, M., Carlos Daniel, P., & Peter, M. (2019). Computational Bayesian statistics, 
Cambridge University Press
Aoyagi, M., & Watanabe, S. (2005). Stochastic complexities of reduced rank regression in Bayesian esti-
mation. Neural Networks, 18, 924–933.
Congdon, P. D. (2019). Bayesian hierarchical models. Boca Raton: CRC Press.
Drton, M., & Plummer, M. (2017). A Bayesian information criterion for singular models. Journal of the 
Royal Statistical Society, Series B, 56, 1–38.
Epifani, I., MacEchern, S. N., & Peruggia, M. (2008). Case-Deletion importance sampling estimators: 
Central limit theorems and related results. Electric Journal of Statistics, 2, 774–806.
Gelfand, A. E., Dey, D. K., & Chang, H. (1992). Model determination using predictive distributions with 
implementation via sampling-based method. Technical Report, Department of statistics, Stanford 
University, Vol.462, pp. 147–167
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian data 
analysis III. Boca Raton: CRC Press.
Gelman, A., Hwang, J., & Vehtari, A. (2014). Understanding predictive information criteria for Bayesian 
models. Statistics and Computing, 24, 997–1016.
Gelman, A., & Shalizi, C. S. (2013). Philosophy and the practice of Bayesian statistics. British Journal of 
Mathematical and Statistical Psychology., 66, 8–38.
Good, I. J. (1952). Rational decisions. Journal of the Royal Statistical Society, Series B, 14, 107–114.
Hayashi, N. (2021). The exact asymptotic form of Bayesian generalization error in latent Dirichlet alloca-
tion. Vol.137, pp.127–137

19
1 3
Japanese Journal of Statistics and Data Science (2021) 4:1–19	
Hironaka, H. (1964). Resolution of singularities of an algebraic variety over a field of characteristic zero. 
I. II Annals of Mathematics, 79, 109–326.
Hobbs, N. T., Mevin, B., & Hooten, M. B. (2015). Bayesian models: A statistical primer for ecologists. 
Princeton: Princeton University Press.
Korner-Nievergelt, F., et al. (2015). Bayesian data analysis in ecology using linear models with R, BUGS, 
and Stan. Cambridge: Academic Press.
Lambert, B. (2018). A student’s guide to Bayesian statistics, SAGE,
Martin, O. (2016). Bayesian analysis with Python. Birmingham: Packt Publishing Ltd.
McElreath, S. (2020). Statistical Rethinking: A Bayesian course with examples in R and STAN (2nd ed.). 
Boca Raton: CRC Press.
Nagata, K., & Watanabe, S. (2008). Asymptotic behavior of exchange ratio in exchange Monte Carlo 
method. Neural Networks, 21(7), 980–988.
Peruggia, M. (1997). On the variability of case-detection importance sampling weights in the Bayesian 
linear model. Journal of American Statistical Association, 92, 199–207.
Reich, B. J., & Ghosh, S. K. (2019). Bayesian statistical methods. Boca Raton: CRC Press.
Sato, K., & Watanabe, S. (2019). Bayesian generalization error of Poisson mixture and simplex Vander-
monde matrix type singularity. arXiv:​1912.​13289
Schwarz, G. (1978). Estimating the dimension of a model. Vol. 6, Np.2 Annals of Statistics, pp.461–464.
Spiegelhalter, D. J., Best, N. G., & CarlinBP, Linde A. (2002). Bayesian measures of model complexity 
and fit. Journal of Royal Statistical Society Series B, 64(4), 583–639.
Vehtari, A., Gelman, A., & Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out 
cross-validation and WAIC. Statistics and computing, 27(5), 1413–1432.
Vehtari, A., & Lampinen, J. (2002). Bayesian model assessment and comparison using cross-validation 
predictive densities. Neural Computation, 14(10), 2439–2468.
Wang, X., Ryan, Y. Y., & Faraway, J. J. (2018). Bayesian regression modeling with INLA. Boca Raton: 
CRC Press.
Watanabe, S. (2018). Higher order equivalence of Bayes cross validation and WAIC. Springer Proceed-
ings in Mathematics and Statistics, Information Geometry and Its Applications, pp.47–73
Watanabe, S. (2021). WAIC and WBIC for mixture models. Behaviormetrika. https://​doi.​org/​10.​1007/​
s41237-​021-​00133-z.
Watanabe, S. (2009). Algebraic geometry and statistical learning theory. Cambridge: Cambridge Univer-
sity Press.
Watanabe, S. (2010). Asymptotic equivalence of Bayes cross validation and widely applicable informa-
tion criterion in singular learning theory. Journal of Machine Learning Research, 11, 3571–3594.
Watanabe, S. (2013). A widely applicable Bayesian information criterion. Journal of Machine Learning 
Research, 14, 867–897.
Watanabe, S. (2018). Mathematical theory of Bayesian statistics. Boca Raton: CRC Press.
Yamazaki, K. (2016). Asymptotic accuracy of Bayes estimation for latent variables with redundancy. 
Machine Learning, 102, 1–28.
Yamazaki, K., & Kaji, D. (2013). Comparing two Bayes methods based on the free energy functions in 
Bernoulli mixtures. Neural Networks, 44, 36–43.
Yamazaki, K., & Watanabe, S. (2003). Singularities in mixture models and upper bounds of stochastic 
complexity. International Journal of Neural Networks, 16(7), 1029–1038.
Zwiernik, P. (2011). An asymptotic behaviour of the marginal likelihood for general Markov models. The 
Journal of Machine Learning Research, 12, 3283–3310.
Publisher’s Note  Springer Nature remains neutral with regard to jurisdictional claims in published 
maps and institutional affiliations.

