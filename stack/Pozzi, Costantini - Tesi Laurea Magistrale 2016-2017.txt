POLITECNICO DI MILANO
Corso di Laurea Magistrale in Ingegneria Informatica
Dipartimento di Elettronica, Informazione e Bioingegneria
Fault analysis of a complex electrical
distribution system with Bayesian
networks and Markov chains
Relatore: Prof. Francesco Amigoni
Correlatore: Dr. Mirjana Mazuran
Tesi di Laurea Magistrale di:
Alessandro Pozzi, matricola 852358
Lorenzo Costantini, matricola 852599
Anno Accademico 2016-2017


Sommario
Non è insolito che aziende o grandi organizzazioni abbiano a che fare
con sistemi complessi, per esempio con infrastrutture composte da una
estesa rete di componenti che interagiscono l’uno con l’altro. Più il
sistema si sviluppa con il tempo, più diventa diﬃcile tener traccia delle
correlazioni tra i componenti e mantenere un modello complessivo del
suo funzionamento. Queste correlazioni diventano rilevanti quando si
presentano delle anomalie, in quanto guasti e comportamenti inaspet-
tati di alcuni componenti possono inﬂuenzarne altri, causando una
propagazione di irregolarità. In genere, in queste situazioni, vi è la
disponibilità di una grande quantità di dati, che possono essere us-
ati per apprendere un modello del sistema senza l’ausilio di esperti.
In questo lavoro, ci concentriamo su una infrastruttura elettrica com-
plessa e distribuita e proponiamo metodi per costruire modelli delle
correlazioni fra i componenti elettrici a partire dai dati. In particolare,
i modelli rappresentano cosa succede prima o dopo le irregolarità ri-
portate dal sistema. Consideriamo due classi di modelli, reti Bayesiane
e catene di Markov, e, nel corso della tesi, discuteremo della loro ef-
ﬁcacia, implementando miglioramenti pensati per il nostro contesto e
mostrando diverse regolarità fra i componenti della speciﬁca infrastrut-
tura elettrica considerata che sono stati in grado di identiﬁcare.
i


Abstract
In several contexts, companies and institutions may have to deal with
complex systems, with an infrastructure composed of an extended net-
work of components that interact with each other. The more the sys-
tem grows over time, the harder becomes to keep track of the correla-
tions among the components and of the overall model of the system.
Knowing these correlations is relevant when some anomalies occur, be-
cause failures and unexpected behaviours of some components can af-
fect other components, causing the propagation of irregularities. These
situations are often characterized by the presence of an high quantity of
data, which can be used to directly learn a model of the system without
the help of an human expert. In this work, we focus on a complex and
distributed electrical infrastructure and we build data-driven models
with the aim of identifying correlations between electrical components
that represent what happens before or after some irregularities reported
by the system. We consider two types of models, namely Bayesian net-
works and Markov chains, and through the thesis we will discuss their
eﬀectiveness, propose context-speciﬁc improvements, and show recur-
rent patterns they were able to ﬁnd between the components of the
electrical infrastructure we consider.
iii


Alle nostre famiglie.
v


Contents
Sommario
i
Abstract
iii
1
Introduction
9
2
State of the art
13
2.1
Approaches to anomaly detection . . . . . . . . . . . . .
13
2.2
Bayesian networks
. . . . . . . . . . . . . . . . . . . . .
16
2.2.1
Model . . . . . . . . . . . . . . . . . . . . . . . .
16
2.2.2
Inference
. . . . . . . . . . . . . . . . . . . . . .
20
2.2.3
Learning . . . . . . . . . . . . . . . . . . . . . . .
23
2.2.4
Variations to the Bayesian model . . . . . . . . .
26
2.2.5
Applications . . . . . . . . . . . . . . . . . . . . .
28
2.3
Markov chains . . . . . . . . . . . . . . . . . . . . . . . .
28
3
Problem setting
33
3.1
The technical infrastructure . . . . . . . . . . . . . . . .
33
3.2
The event log . . . . . . . . . . . . . . . . . . . . . . . .
34
3.3
Formal setting
. . . . . . . . . . . . . . . . . . . . . . .
35
3.4
Scope and techniques . . . . . . . . . . . . . . . . . . . .
38
3.5
Libraries . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
4
The Bayesian network model
43
4.1
Pre-processing of data . . . . . . . . . . . . . . . . . . .
43
1

4.1.1
The reference devices . . . . . . . . . . . . . . . .
43
4.1.2
The analysis window . . . . . . . . . . . . . . . .
44
4.1.3
The training set generation
. . . . . . . . . . . .
45
4.1.4
Adding new ﬁelds . . . . . . . . . . . . . . . . . .
63
4.2
Model generation . . . . . . . . . . . . . . . . . . . . . .
64
4.2.1
Variables choice . . . . . . . . . . . . . . . . . . .
64
4.2.2
Network generation and interpretation . . . . . .
70
4.3
Post-processing . . . . . . . . . . . . . . . . . . . . . . .
74
4.3.1
Inference labels . . . . . . . . . . . . . . . . . . .
74
4.3.2
Reference device
. . . . . . . . . . . . . . . . . .
77
4.3.3
Locations . . . . . . . . . . . . . . . . . . . . . .
78
4.3.4
Devices information
. . . . . . . . . . . . . . . .
78
4.3.5
Inference network . . . . . . . . . . . . . . . . . .
79
5
The Markov chain model
83
5.1
Preprocessing of data . . . . . . . . . . . . . . . . . . . .
83
5.1.1
Timestamps and analysis window . . . . . . . . .
83
5.1.2
Training sequences generation . . . . . . . . . . .
84
5.2
Model generation . . . . . . . . . . . . . . . . . . . . . .
89
5.2.1
The choice of states
. . . . . . . . . . . . . . . .
89
5.2.2
State diagram generation and interpretation . . .
92
5.3
Postprocessing
. . . . . . . . . . . . . . . . . . . . . . .
93
5.3.1
Arc coloring and edge ﬁltering
. . . . . . . . . .
93
5.3.2
Temporal labels . . . . . . . . . . . . . . . . . . .
94
5.3.3
Locations and device information . . . . . . . . .
96
5.3.4
Reference device
. . . . . . . . . . . . . . . . . .
96
6
Examples of use
101
6.1
Summary of methods . . . . . . . . . . . . . . . . . . . . 101
6.2
The inﬂuence of duplicates . . . . . . . . . . . . . . . . . 103
6.3
The use of diﬀerent variable selection criteria
. . . . . . 105
6.4
The use of diﬀerent additional ﬁelds
. . . . . . . . . . . 110
6.5
The window of analysis
. . . . . . . . . . . . . . . . . . 115
6.6
A comparison between models . . . . . . . . . . . . . . . 119
2

6.7
Networks with multiple reference device
. . . . . . . . . 122
7
Conclusions and future development
125
7.1
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . 125
7.2
Future development
. . . . . . . . . . . . . . . . . . . . 127
Bibliography
131
3


List of Figures
2.1
A Bayesian network taken from [1]. . . . . . . . . . . . .
17
2.2
The Bayesian network shown in Figure 2.1 with the par-
tial CPD attached to the nodes [1].
. . . . . . . . . . .
18
2.3
Another example of Bayesian Network related to a med-
ical setting, taken from [2]. . . . . . . . . . . . . . . . . .
20
2.4
A 2-TBN taken from [2]. . . . . . . . . . . . . . . . . . .
27
2.5
A simple example of Markov chain with 3 states, taken
from [3]. . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
2.6
The transition matrix of the Markov chain in Figure 2.5.
29
3.1
The ﬁelds of the event log with a single entry. . . . . . .
34
3.2
The timeline of some events happening after a times-
tamp i.
. . . . . . . . . . . . . . . . . . . . . . . . . . .
36
3.3
The timeline with events happening before a timestamp i. 38
3.4
Example of log needed to apply process mining. . . . . .
40
4.1
A fragment of the event log with the timestamp i (in
black) and i + 1 (in blue). . . . . . . . . . . . . . . . . .
46
4.2
A portion of the log with events of device ECC01/5DX
extremely close one to the other.
. . . . . . . . . . . . .
47
4.3
The log shown in Figure 4.2 with the addition of “tag”
and “description”. . . . . . . . . . . . . . . . . . . . . . .
48
4.4
A portion of the log with devices EHD20/BE, EHS60/BE,
EKD203/5E.
. . . . . . . . . . . . . . . . . . . . . . . .
49
4

4.5
A portion of the log with 3 devices: EMD1A*9, EMD2A*9
and EMD3A*9. . . . . . . . . . . . . . . . . . . . . . . .
51
4.6
Fixed distance clustering applied to Ei
c events following
timestamp i=2016-01-08 09:30:40.287 of the reference
device EMC001*9 . . . . . . . . . . . . . . . . . . . . . .
54
4.7
Other results from the application of ﬁxed distance clus-
tering with fd = 5 seconds. . . . . . . . . . . . . . . . .
55
4.8
Average based clustering applied to events following times-
tamp i=2016-01-08 09:30:40.287 of the reference device
EMC001*9
. . . . . . . . . . . . . . . . . . . . . . . . .
57
4.9
An extract of the application of average based clustering
to events following timestamp i=2016-01-20 06:00:19.437
of the reference device EMC001*9. . . . . . . . . . . . .
57
4.10 An extract of clustering results using the separation cri-
terion based on average plus standard deviation of tem-
poral diﬀerences of consecutive events
. . . . . . . . . .
58
4.11 A detail of the separation between clusters in an event
sequence of device EMC001*9.
. . . . . . . . . . . . . .
60
4.12 On the left, a sequence of events separated in cluster
with the criterion of average plus standard deviation.
On the right, the same sequence separated with mean
shift. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
4.13 Results from the application of DBSCAN to device EMC001*9. 62
4.14 The Bayesian network based on the reference device
EMC001*9 with priority L2 and no duplicates.
. . . . .
71
4.15 The Bayesian network based on the reference device
ESS11/5H with priority L1 and no duplicates. . . . . . .
72
4.16 The Bayesian network of device EMC001*9, with prior-
ity L1, no duplicates and the addition an inference label
on the edges.
. . . . . . . . . . . . . . . . . . . . . . . .
74
4.17 The Bayesian network of device EMC001*9, with prior-
ity L1, no duplicates and the addition double inference
labels on the edges. . . . . . . . . . . . . . . . . . . . . .
76
5

4.18 The Bayesian network of device EMC001*9, with prior-
ity L2, no duplicates, the double inference labels on the
edges and the reference device.
. . . . . . . . . . . . . .
77
4.19 The Bayesian network of device ESS1*84, with priority
L1, no duplicates, the double inference labels and the
device locations.
. . . . . . . . . . . . . . . . . . . . . .
79
4.20 The Bayesian network of device EXS106/2X, with pri-
ority L1, no duplicates, the double inference labels and
the occurrences. . . . . . . . . . . . . . . . . . . . . . . .
80
4.21 The Bayesian network of device ECD1*62, with priority
L1, no duplicates, the double inference labels and the
devices information.
. . . . . . . . . . . . . . . . . . . .
81
4.22 The inference network of device EMC001*9, with prior-
ity L2 (without duplicates). . . . . . . . . . . . . . . . .
82
5.1
An example of timeline with some events related to two
timestamps i (in black) and i + 1 (in blue).
. . . . . . .
87
5.2
Markov chain based on the reference device EHS60/BE
with priority L1 using conﬁdence criterion. . . . . . . . .
92
5.3
Markov chain based on the reference device EHS60/BE
with priority L1 using conﬁdence criterion, with red arcs
and 0.15 as minimum threshold for edge visualization.
.
94
5.4
Markov chain with temporal labels based on the refer-
ence device EMC001*9 with priority L2, using temporal
criterion based only on minimum standard deviation . .
95
5.5
Markov chain in Figure 5.4 with additional information.
97
5.6
The Markov chain in Figure 5.4 with the addition of the
locations of devices.
. . . . . . . . . . . . . . . . . . . .
98
5.7
The Markov chain in Figure 5.4 with the addition of the
reference device.
. . . . . . . . . . . . . . . . . . . . . .
99
5.8
The Markov chain related to what happens before the
events with priority L3 of the reference device EHS60/BE,
with the graphical addition of the reference device. . . . 100
6

6.1
Comparison of candidate variables with duplicates (on
the left) and without duplicates (on the right) for the
reference device EHS60/BE with priority L1.
. . . . . . 103
6.2
Two Bayesian networks related to the device EHS60/BE:
one (on the left) with duplicates and the other (on the
right) without duplicates.
. . . . . . . . . . . . . . . . . 104
6.3
Bayesian network of reference device ERD15*45, with
priority L2 and variable selection method based on the
occurrences. . . . . . . . . . . . . . . . . . . . . . . . . . 106
6.4
Bayesian network of reference device ERD15*45, with
priority L2 and variable selection method based on the
conﬁdence. . . . . . . . . . . . . . . . . . . . . . . . . . . 107
6.5
Markov chain related to the device EHS60/BE with pri-
ority L1, with states selected with the close pairs crite-
rion and “tag” as additional ﬁeld. . . . . . . . . . . . . . 108
6.6
Markov chain related to the device EHS60/BE with pri-
ority L1, with states selected with the occurrences cri-
terion and “tag” as additional ﬁeld. . . . . . . . . . . . . 109
6.7
An extract of a Markov chain with 150 states, built on
the events before a set of given timestamps, with an
analysis window of 5 minutes. . . . . . . . . . . . . . . . 110
6.8
The Bayesian network of reference device EMC001*9
with priority L3, no duplicates, the graphical postpro-
cessing of the reference device and the addition of the
ﬁeld “level of priority”. . . . . . . . . . . . . . . . . . . . 111
6.9
Markov chain related to the device EHS60/BE with pri-
ority L1, with states selected with the occurrences” cri-
terion, with “description” as additional ﬁeld. . . . . . . . 113
6.10 Markov chain related to the device EHS60/BE with pri-
ority L1, with states selected with the close pairs crite-
rion and “state” as additional ﬁeld. . . . . . . . . . . . . 114
7

6.11 Markov chain related to the device EHS60/BE with pri-
ority L1, with states selected with the close pairs crite-
rion and “level of priority” as additional ﬁeld.
. . . . . . 114
6.12 A graph that puts in relation the number of events (af-
ter the timestamps) with the dimension of the analysis
window. This graph considers only events of reference
devices with priority L1. . . . . . . . . . . . . . . . . . . 116
6.13 A graph that puts in relation the number of events (af-
ter the timestamps) with the dimension of the analysis
window. This graph considers only events of reference
devices with priority L2. . . . . . . . . . . . . . . . . . . 117
6.14 A graph that puts in relation the number of events (be-
fore the timestamps) with the dimension of the analysis
window. This graph considers only events of reference
devices with priority L1. . . . . . . . . . . . . . . . . . . 118
6.15 Two models related to the reference device EXS106/2X,
with priority L1. On the left, the Bayesian network (gen-
erated without duplicates). On the right, the Markov
chain (with visualization threshold set to 0.15). . . . . . 120
6.16 The Markov chain on the right of Figure 6.15 with the
addition of the reference device. . . . . . . . . . . . . . . 121
6.17 The Bayesian network of the reference device EHS60/BE,
generated without duplicates, priority L1 and the fre-
quency criterion.
. . . . . . . . . . . . . . . . . . . . . . 123
6.18 The Bayesian network generated from the multiple refer-
ence devices in Figure 6.17, generated with no duplicates.124
8

Chapter 1
Introduction
In several contexts, companies and institutions have to deal with large
technical infrastructures, often composed of multiple subsystems that
interact and inﬂuence each other in a network of rich, complex intercon-
nections. Examples include prominently the electrical infrastructures
and the information infrastructures. When the infrastructure grows
over time and new subsystems are added and integrated with legacy
units, it becomes increasingly harder to keep track of the correlations
between the subsystems in a coherent and updated model of the in-
frastructure. The importance of these correlations is remarkable from
the point of view of the reliability and availability of the infrastruc-
ture. For example, knowing which components will be likely aﬀected
by the failure of other components can save time and resources. A
manual analysis of the relationships between these components would
result in an unreadable breakdown structure, extremely hard to man-
age. An automated analysis based on data collected during the opera-
tion of the infrastructure, instead, could allow to identify correlations
between components. It is especially important to ﬁnd out and ana-
lyze irregularities that may propagate to the rest of the system, often
called anomalies. All the methods which try to automatically identify
anomalies from data are part of a ﬁeld of study called anomaly detec-
tion [4].

In this thesis, we focus on a complex electrical infrastructure with the
aim of identifying correlations between electrical components related
to the detection of anomalies.
These components, which are called
devices, regularly report events in a log. Our objective is to gener-
ate models based on Artiﬁcial Intelligence approaches to analyze the
correlations between the devices by observing the events reported on
the log. In particular, we will focus on Bayesian networks and Markov
chains. Bayesian networks are a probabilistic graphical model [2] that
allows us to identify the relationships among some variables; Markov
chains are stochastic models [3] that we will use to capture the tempo-
ral sequentiality of events.
Throughout the thesis we analyze the potential and the diﬃculties in
the use of these models in our applicative context, such as the prob-
lem of identifying a temporal period that determines the boundary in
which two events in the log can be considered to be correlated, or the
issue of duplicated events in the training phase of the model gener-
ation. We pay particular attention to the variable selection criteria,
which are essential to determine which correlations we could ﬁnd. We
also propose some graphical techniques that can be applied after the
model creation in order to improve the immediacy and clarity of its
fruition by an human operator. Moreover, through this thesis we will
show the results of our models to demonstrate their eﬀectiveness in
ﬁnding frequent patterns in the sequences of events in the log which
are related to faults.
In the literature, anomaly detection has been applied to a great
variety of contexts, from intrusion detection in security systems [5]
to electrical power systems [6], with techniques that go from graph
matching [7] to deep neural networks [8]. Probabilistic graphical mod-
els like Bayesian networks [2] are not often used in fault analysis, but
applications are not lacking. For example, they have been utilized to
predict the probability of failures based on live data [9], and special-
ized models to be used in failure prediction have been discussed in [10].
10

Markov chains have been employed in failure detection [11] and for de-
tecting anomalies in event logs [12]. However, diﬀerently from most
approaches to anomaly detection, our models do not learn the nomi-
nal behaviour of the system and use it to predict unusual anomalous
deviations, instead they capture what happens before or after a set of
some anomalous events.
The thesis is structured as follows:
• Chapter 2 (State of the art). In this chapter we present the
state of the art on the topics relevant to our work, and we illus-
trate in detail the modelling techniques we are going to use.
• Chapter 3 (Problem setting). In this chapter we describe and
formalize our problem and we justify the choices of the techniques
we employ to solve it.
• Chapter 4 (The Bayesian network model). In this chapter we
show the process followed to generate a Bayesian network that
represents correlations between components and we discuss its
meaning and eﬀectiveness.
• Chapter 5 (The Markov chain model). In this chapter we
present the steps needed to build a Markov chain and we interpret
it, with a structure that follows the one of Chapter 4.
• Chapter 6 (Examples of use). In this chapter show how to use
the models generated, according to the diﬀerent assumptions on
the problem discussed in Chapters 3, 4, and 5.
• Chapter 7 (Conclusion and future development). In this
chapter we brieﬂy summarize the thesis and discuss possible fu-
ture developments that could improve our work.
11


Chapter 2
State of the art
In this section we present the state of the art of the techniques relevant
to our thesis. In Section 2.1 we show the main approaches to anomaly
detection, a problem that shares some similarities with the one that
we tackle in this work. In Section 2.2 we present the Bayesian network
model and in Section 2.3 the Markov chain model.
2.1
Approaches to anomaly detection
Anomaly detection consists in identifying non standard behaviour of
systems. The usual approach to perform this task consists in the con-
struction of a model of the system’s nominal behaviour. Consequently,
this model allows also to detect when the system does not follow the
normal behaviour. Anomaly detection is often a very important task
because the anomalies discovered from the application of a model or
from data analysis may be useful for many application domain con-
texts. The nominal model can be generated with the help of an expert
who already knows the conditions under which the system can be said
to follow a regular functioning, or alternatively the data collected from
the system can help to discover patterns that determine the correct
and incorrect system behaviour. Outlier detection is sometimes used
as a synonym for anomaly detection in data mining applications that

aim to discover data points that are signiﬁcantly diﬀerent from the
norm. We can distinguish two main paradigms to anomaly detection:
model-based and data-driven.
Model-based approaches require some degree of prior knowledge
about the system. A model can be represented analytically or qualita-
tively and a discussion on these two classes of model-based approaches
is given in [13] and [14]. Analytical methods, like parameter estimation,
parity space estimation, observer-based estimation, have in common
the creation of the residual signal, which is the diﬀerence between the
measurement of the system and its estimation. The task of these math-
ematical methods is to design a residual signal which is zero or near to
zero when no anomaly occurs while it should diﬀer distinctly from zero
otherwise [15]. Many qualitative model based techniques have been
applied to Fault Detection, Isolation and Recovery (FDIR) problems:
fault trees and statecharts [16], fault propagation models [17], directed
graphs [18], expert systems [19] and many other variants. A common
strategy of these qualitative methods is to model the behaviour of the
system with abstraction hierarchies or causal relationships. The model
built in this way should capture the regularity of the behaviour of the
system. Model-based techniques have been successfully applied also for
the diagnosis of electrical power systems: a probabilistic model-based
approach to perform this task, which exploits Bayesian networks and
arithmetic circuits, has been proposed in [20]. However, it is not always
possible to use a model-based technique. Sometimes there is no human
expert who really knows how the entire system works; if there is one,
modelling may be a lengthy and expensive process with a high risk of
human error. In these cases, we can resort to data-driven approaches.
Data-driven approaches are techniques that allow to automatically
build a model by learning it from some data coming from the system.
For example, these data may be in the form of a log of events, or
a sequence of non-nominal values assumed by components. A data-
driven approach to anomaly detection in an electrical power system is
presented in [6]. The work aims at learning, using an autoassociative
14

neural network, the nominal behaviour of the low level subcomponents
of the system, and then use this model to identify anomalies that occur
at any level of the system. Anomaly detection has also been applied
to detect vulnerabilities and security threats in power system control
centers. Instead of relying on intrusion detection systems, in [5] the
nominal data ﬂow and control operations of the system are modelled
with a rough sets classiﬁcation algorithm. Variations in the standard
behaviour of the system are captured with the model and are an in-
dication of a possible security threat.
Anomaly detection has been
applied in security context also in [7], where a graph-matching ap-
proach is applied to detect cyber attacks to smart grids. In [21] two
machine learning methods were used to detect abnormal behaviours in
a network of webcams and in a set of IP traﬃc statistics.
Most of today’s information systems use a system log to record sys-
tem states and signiﬁcant events, which provides detailed information
about the history of processes and can help to debug failures. How-
ever, because of the high number of entries produced by some systems,
it can be extremely diﬃcult to extract consistent information about
the points of failure and the general behaviour of the system. This has
prompted various studies aimed to identify anomalies by examining the
data log. Deeplog [8] oﬀers a data-driven approach to identify online
attacks that views log entries as elements of a sequence which follow
a speciﬁc grammar rules. A deep neural network automatically learns
a model of the log patterns from the normal execution and is then
able to report as anomalies any deviations from the standard system
execution.
Process mining [22, 23] is an approach to event logs that focuses on
discover, analyze, and improve business processes. These techniques
are based on the assumption that each event refers to a speciﬁc activ-
ity (i.e., a well-deﬁned step in some process) and belongs to a process
instance. Additional informations such as the timestamp of the event
of the device initiating the activity can be used by the technique. In
general, there are three types of process mining analysis that can be
15

executed: discovery, conformance, enhancement. Discovery produces a
model from the log, without access to any prior knowledge on the sys-
tem. Conformance allows to check if an already existing process model
represents correctly the reality as shown in the log. Enhancement al-
lows to improve an existing model using the information obtained from
the event log. Process mining can also be adapted to perform anomaly
detection. In [24] it is shown how the process mining framework ProM
[25] can detect anomalous process traces.
The approaches to anomaly detection described in the literature
and presented in this section cannot be directly applied to our prob-
lem. We have to exclude the application of model-based approaches
since the electrical infrastructure we analyze is really complex and it
would be a very diﬃcult task to create a complete model for its nomi-
nal behaviour. Moreover, there is no human expert who knows every-
thing about the electrical system, because it was built incrementally
over many years. So, the objective of this thesis is to analyze failures
and their consequences in terms of correlations between the electrical
components. We cannot also apply directly most of the data-driven
approaches presented, because they focus on building a model of the
nominal behaviour of the system, although directly from data and with-
out the contribution of a human expert. Most of the data entries of
the log at our disposal are instances of irregularities of the system,
with diﬀerent levels of priority. Therefore we cannot build a nominal
model from data since we do not have data that follows a standard
behaviour. Instead, we model correlations about diﬀerent faults. We
will adopt Bayesian networks and Markov chains as tools to discover
these correlations.
2.2
Bayesian networks
2.2.1
Model
Bayesian Networks are graphical probabilistic models that allow to
graphically represent the dependence and independence probabilistic
16

relationships between some variables. They are generally used in con-
texts in which it is necessary to model a reality that presents some
degree of uncertainty, that is captured by the model with probabilities.
Graphically, a Bayesian Network is a directed acyclic graph (DAG), in
which each node represents a variable of the system and the edges be-
tween variables represents the direct inﬂuence among them. Figure 2.1
shows a simple Bayesian Network that correlates symptoms, illnesses
and life style. For example, the variables “Exercise” and “Diet” directly
inﬂuence the chance of “Heart Disease”, while the “Heartburn” depends
only by the “Diet”.
Figure 2.1: A Bayesian network taken from [1].
Each of the variables in Figure 2.1 has a domain that indicates
the values they can assume. For example, the variable “Exercise” has
{Y es, No} as domain, while “Blood Pressure” can assume the values
{High, Low}. Each variable in the model is also associated with a con-
ditional probability distribution (CPD). Formally, the CPD of a variable
Y given the variable X is the probability distribution of Y when X is
observed to be a speciﬁc value. As shown in Figure 2.2, the CPD for a
node X speciﬁes the probability distribution over the values of X given
17

all the possible assignment of values to its parents. The complete CPD
tables are not shown in the picture, but every missing probability can
be easily computed from the others.
Figure 2.2: The Bayesian network shown in Figure 2.1 with the partial CPD
attached to the nodes [1].
If a variable has no parents, the associated CPD turns into a
marginal distribution. For example, the probability of the “Diet” being
“Healthy” is 0.25, while the probability of it being “Unhealthy” is 0.75.
These probabilities are expressed with the notation:
P(Healthy) = 0.25
(2.1)
P(Unhealthy) = 0.75
(2.2)
The conditional probability of the “Heart Disease” being “Yes” given
the values of “Exercise” and “Diet” is expressed as:
P(Heart Disease = Yes | Exercise = Yes,
Diet = Healthy) = 0.25
(2.3)
18

Variables in Bayesian networks may have relation of dependence or
independence with one to another. In general, a connection between
two variables represents direct dependence, which means that variables
always depend from their parents. However, observing the values of
a variable may turn a dependence relation into a independence rela-
tionship: this is the concept of conditional independence. Referring to
Figure 2.1, we can say that the “Blood Pressure” is conditionally inde-
pendent from “Exercise”, “Diet”, “Heartburn” and “Chest Pain” given
that we have observed the “Heart Disease”:
(Blood Pressure ⊥Exercise, Diet, Heartburn, Chest Pain
| Heart Disease)
(2.4)
Intuitively this reasoning makes sense, since the “Blood Pressure” de-
pends directly only from the “Heart Disease”, and once we have ob-
served it any information from the other variables will not change our
beliefs about the “Blood Pressure”. This, however, does not mean that
observing the values of a variable’s parent makes that variable inde-
pendent from all the others. For example, knowing the “Exercise” and
“Diet” of a person does not make the “Heart Disease” independent from
the “Blood Pressure”, because information about the person’s blood
pressure can change our beliefs of how likely he is to have an heart dis-
ease. A more general pattern that emerges from these considerations
is that in a Bayesian network, each variable is independent from its
non-descendants given that we have observed its parents [2].
While dependencies and independencies can be precisely identiﬁed,
the same can not be said about causality. An edge in the Bayesian
network of the type A →B can imply causality (i.e., that A causes
B), but it in general it simply means that there is a correlation between
A and B. Representing causality is not easy, especially if the network
structure has been learned automatically from the data.
Moreover,
even if we think that we have built a causal Bayesian network, there
might be variables that we can’t observe and we are not aware of, that
can induce us to think a correlation as causal when the actual causal
relation is with these hidden variables. Such variables are also called
19

latent variables [2]. In general, a Bayesian network with a causal rela-
tionship among connected variables tends to have a sparser structure
than pure “correlation” networks, but this does not inﬂuence the result
of the standard probabilistic queries that we execute on our model. In
fact, in this sense, it is not important if our model is causal or not, as
long as the underlying distribution is represented correctly.
2.2.2
Inference
Answering queries to ﬁnd out how probable is for some variables to
assume certain values, possibly having observed the values assumed by
other variables of the network (which are treated as evidence), is one
of the main advantages and capabilities of Bayesian models.
Figure 2.3: Another example of Bayesian Network related to a medical setting,
taken from [2].
In Figure 2.3 we can see how a query related to all the variables
in the domain can be factorized exploiting the known independencies
among the variables, following the edges from the root to the leaves.
The factorization in Figure 2.3 is a scheme to be adopted regardless
of the values associated to each variable.
A value to each variable
has to be obviously associated to perform a query and the following
20

joint query shows a possible instantiation of the scheme in the previous
ﬁgure.
P(Season = Winter, Flu = True, Hayfever = False,
Congestion = False, Muscle Pain = False)
(2.5)
A joint query calculates the joint probability of multiple values. The
query in Equation (2.5) returns the probability of the 5 events joined
in a logic “AND”. A joint query can be rewritten as a product of con-
ditional probability queries, as shown before in Figure 2.3. This type
of query is useful to discover the probability of an event knowing that
another event has occurred, and it’s written in the following form:
P(X = x | E = e)
(2.6)
X is a generic variable that can assume the value x and E = e is a set of
assignment of values e to variables E (i.e., the evidence, or the observed
variables). Without the factorization mechanism provided by Bayesian
networks it would be hard to ask queries to discover information from
domains composed of many variables, which can be easily encountered
in a real world setting. Exploiting independencies can greatly reduce
the probability space, which corresponds to the possible assignments to
the variables of the domain. In this way the number of nonredundant
parameters needed to deﬁne high dimensional joint distributions can be
greatly reduced. Rather than encode the probability of every possible
assignment in our domain, we can break up the distribution into smaller
factors, each of them over a much smaller space of possibilities, and
then deﬁne the joint distribution as a product of these factors [2].
A diﬀerent kind of query is the Maximum a Posteriori (MAP)
query:
MAP(X | E = e) = argmax
x
P(X=x | E=e)
(2.7)
The MAP query returns the most likely assignment of values x to the
variables X. Of course, we can answer some of these queries directly
by looking at the CPD, but in most of the cases this is not the most
21

practicable or convenient approach. Another possible type of queries
are the intervention queries, which can tell us what happens to a cer-
tain variable when we manipulate the values of other variables. For
example, given some evidence, we can ask how would have changed
the probability of seeing a speciﬁc variable-value assignment if we had
observed another variable. These kind of queries are strongly related
to the causal meaning of edges and therefore make sense only in causal
Bayesian networks.
The act of answering queries is called inference.
There are two
approaches to inference: exact inference and approximate inference.
In exact inference, we analytically compute the conditional probabil-
ity distribution over the variables and we obtain the exact probabili-
ties. Unfortunately, exact inference is a NP-hard problem and therefore
there is no algorithm that can perform it eﬃciently in all the network
conﬁgurations. For a faster, but less precise solution, we must resort
to approximate inference, which is still an NP-hard problem in the
worst case. However, many real-world applications can be tackled very
eﬀectively using exact or approximate inference [2]. One of the most
popular exact inference method is the variable elimination algorithm,
which computes the result of a query in the most eﬃcient way, starting
from the factorized representation and distributing sums over prod-
ucts. If we deﬁne a set X of variables of the domain, and a subset of
variables Y ⊂X involved in a query, the factors related to the vari-
ables in the complementary subset X −Y have to be summed, i.e.,
marginalized out of the distribution.
The choice of the elimination
ordering of the variables in order to minimize the computational time
is one of key points in exact inference algorithms and its complexity
is NP-hard, and can be tackled by using greedy algorithms. Dynamic
programming can also be used to compute the innermost summations
ﬁrst, to avoid redundant computations [9]. Another method to perform
exact inference is the clique tree algorithm that uses message passing
in a preconstructed clique tree (or junction tree), a data structure for
exact inference. Messages are passed between the cliques in the tree
22

until all cliques agree on the same marginal beliefs of any variable they
share [2].
Most of the algorithms that perform approximate inference adopt
either a sampling or message passing approach. Sampling consists in
approximating the probability of events by drawing samples from sam-
pling distributions deﬁned over the Bayesian network (conceptually
similar to performing simulations). The value of the probabilities are
then directly based on the occurrences of the events in the simulations.
Sampling algorithms may diﬀer in the way they generate samples and
weight them to compute the event probabilities. Some examples of
these techniques are importance sampling and Markov chain Monte
Carlo methods [2]. On the other hand, message passing algorithms
like belief propagation are based on the idea of passing messages along
the nodes of the network until a stable belief state is reached, which
corresponds to probability values that often provide a good approxi-
mation of the inference query results. This algorithm diﬀers from the
clique tree algorithm described for the exact inference because it re-
laxes some constraints for the construction of the tree, which in this
case is a network called “cluster graph”. For this reason the results
obtained from this process are approximated [2].
2.2.3
Learning
Bayesian networks can be built manually, usually with the help of an
expert, or automatically, by learning only the parameters or both the
structure and the parameters directly from the data. Two of the main
approaches to learn the structure of the network are constraint based
algorithms and search-and-score based algorithms.
Constraint based methods look for the structure of the model that
better explains all the conditional dependencies and independencies
identiﬁed in the data with a statistical test. The disadvantage of these
methods is that they can be sensitive to failures in individual indepen-
dence tests. It suﬃces that one of these tests returns a wrong answer to
mislead the network construction procedure. As a consequence, they
23

are also less reliable when the number of samples is small.
On the contrary, search-and-score based algorithms utilize an heuris-
tic based on a score function to search in the hypothesis space of all
potential models and ﬁnd the one that better ﬁts the given data. The
score function is what measures the ﬁt to the data. Since this space is
super-exponential in the number of variables, the problem is NP-hard
and exact searches are infeasible in most instances. Local search al-
gorithms as hill climbing, tabu search, simulated annealing and many
others are usually used for this purpose. Those methods start from a
candidate solution, which can also be a completely disconnected DAG,
and iteratively modify it by adding or deleting an edge or inverting its
direction, trying to build graphs with an increasing score value that
is given by a score function. One of the disadvantages of score based
methods is that they may incur in local maxima.
With respect to
constraint based methods they consider the entire network structure
at once and they are less sensitive to the individual failures problems.
The choice of adding or not an edge is less constrained by variable
dependencies and is more dependent from the global network score.
The scoring functions used by the search methods can be Bayesian
scoring function or based on information theory scoring function. K2
score, Bd score and Bdeu score are some of the most used Bayesian
scoring functions. Starting from a prior probability distribution on the
possible networks, they compute the posterior probability distribution
p(G|D) conditioned to the available data D, where G is the graph. The
best network is the one that maximizes such posterior probability. In
this case the probabilities for each training instance are evaluated in
incremental order, and they contribute both to the evaluation of the
model and to the ﬁnal model score. The probabilities calculated for the
m-th instance during the learning phase are inﬂuenced by the param-
eters learned from the ﬁrst m −1 instances using Bayesian estimation.
The m-th instance is used as a test case [2], and it becomes possible to
train the model using all the available data, without the need to split
data for doing training and testing, which can be an important issue
24

if we have limited amounts of data to learn from.
Scoring functions based on information theory are based on the mini-
mum description lenght (MDL) principle, which establishes an appro-
priate trade-oﬀbetween complexity and precision. This idea can be
translated in the following family of scoring functions dependent on
f(N), a non-negative penalization function [26]:
g(G : D) =
n
X
i=1
qi
X
j=1
ri
X
k=1
Nijklog
Nijk
Nij

−C(G)f(N)
(2.8)
ri is the number of states of the variable Xi; the number of possible
conﬁgurations of the parent set PaG(Xi) of Xi is qi; wij, j = 1, ...qi,
represents a conﬁguration of PaG(Xi); Nijk is the number of instances
in the data set D where the variable Xi takes the value xik and the
set of variables PaG(Xi) take the value wij; Nij is the number of
instances in the data set where the variables in PaG(Xi) take their
j-th conﬁguration wij; Nij can also be written as Pri
k=1 Nijk; the total
number of instances in D is N. C(G) is the network complexity. It is
proportional to the description length of the network and it is deﬁned
as the number of free parameters of the factorized joint probability
distribution [26]:
C(G) =
n
X
i=1
(ri −1)qi
(2.9)
Equation (2.8) can generate some famous scoring functions like AIC
score (f(N) = 1), BIC score (f(N) =
1
2) and maximum likelihood
score (f(N) = 0). AIC and BIC scores select the network structure
that best ﬁts the data, penalized by the number of parameters which
are necessary to specify the joint distribution. The network complexity
term C(G) is what implements the tradeoﬀbetween complexity and
precision. The maximum likelihood score, instead, is not useful for
learning the structure of a Bayesian network. In this case, the network
complexity term C(G) becomes no more relevant and simpler networks
25

are never preferred over more complex ones. So, the choice of maximum
likelihood score for structure learning causes the problem of overﬁtting.
On the contrary, both AIC/BIC scores and the scores of the family
of Bayesian scoring functions lead to the creation of networks which
do not overﬁt. An important feature of both Bayesian and AIC/BIC
score functions is that they are consistent: with a limited amount of
data, simple structures with fewer edges have the highest scores; as
the number of samples grows, more complex structures are preferred
and asymptotically; with an inﬁnite amount of data, the true model is
selected [2]. A way to interpret scoring functions based on information
theory is that they attempt to minimize the conditional entropy of
each variable given its parents. So, they allow to search for the parent
set of each variable that gives as much information as possible about
this variable, or which most restricts the distribution. The addition
of a penalization term is necessary because the minimum conditional
entropy is always obtained after adding all the possible variables to the
parent set [26].
Once we have the Bayesian network model, we can use other learn-
ing techniques to learn the value of the parameters (i.e., the conditional
probabilities of the variables). Usually the aim is to ﬁnd the Maximum
Likelihood Estimation (MLE) of the parameters, which are the values
that maximize the likelihood of the data.
As in the case of inference, the learning task becomes more diﬃcult
as the number of variables increases. Even the number of values that
each variable can take contributes to the increased complexity. Clearly,
continuous variables are harder to deal with than discrete variables.
2.2.4
Variations to the Bayesian model
Several models have been proposed over the years to extend and adapt
Bayesian networks to diﬀerent contexts with respect to the ones they
were typically used in. For example, dynamic Bayesian networks are
able to deal with the concept of time. In particular, they represent
26

the dependencies of the variables from previous values of the vari-
ables by using time slices, where each time slice is conditionally de-
pendent from the previous one. A dynamic Bayesian network is often
called 2-TBN because it is a temporal Bayesian network (TBN) com-
posed by two time slices. An example is shown in Figure 2.4 taken
from [2]. Another variation of the Bayesian model is the probabilis-
Figure 2.4: A 2-TBN taken from [2].
tic relational model (PRM). This representation extends the Bayesian
networks by introducing classes, attributes, objects, and relationships
among them. PRMs are able to model much more rich realities than
standard Bayesian networks, but are also much more complex from a
computational point of view, especially if the number of variables is
high [2].
27

2.2.5
Applications
Bayesian networks have been widely used in practical applications. For
several years, a Bayesian network was at the core of the VISTA system,
a decision-theoretic system used in NASA mission control, predicting
the probability of failures and advising the actions to take based on
live data [9]. In [27] Kennet shows Bayesian networks case studies that
range from biotechnology to web services and customer satisfaction
surveys. [28] presents an overview of Bayesian networks applications
in dependability, risk analysis, maintenance contexts and shows how
both studies and practical applications of this methods are growing
over time. [29] shows Bayesian networks applications in agriculture
and suggests future developments of the techniques in that ﬁeld.
A general scheme to utilize Bayesian networks in failure diagnosis has
been presented by [30], while an expansion of the Bayesian model called
“failure prediction Bayesian networks model” is discussed in [10] with
the speciﬁc purpose of predicting failures. In [31] a Dynamic Bayesian
network is used to model the causal relationships of faults in a petro-
chemical system; [32] shows how to build a causal Bayesian network
that can be used in safety analysis.
2.3
Markov chains
A Markov chain is a stochastic model that represents the evolution of
a process composed of a set of states S = {s0, s1, s2, ...}. The process
starts in one of these states and proceeds with a sequence of steps or
transitions, where each step consists in transitioning from the current
state to a new state, which could also coincide with the current state.
The probability of this transition is called transition probability and is
deﬁned as psisj, where si, sj ∈S. The dependence of the transitions on
the current state only - and not on any previous state - is called Markov
property.
In order for the Markov chain to be valid, the transition
28

probabilities must be such that:
X
sj
(psisj) = 1
∀i ∈S
(2.10)
The transition probabilities can be compactly represented with a tran-
sition matrix. Graphically, a Markov chain is a state diagram where
every edge between states is a transition. In Figure 2.5 we show an ex-
ample of Markov chain and in Figure 2.6 the corresponding transition
matrix.
Figure 2.5: A simple example of Markov chain with 3 states, taken from [3].
Figure 2.6: The transition matrix of the Markov chain in Figure 2.5.
Besides being able to show the evolution of a system and predict
the probability of an immediate transition, Markov chains also allow
29

to predict the probability of a sequence seq of states. To do this, we
just have to compute the following:
p(seq) =
n−1
Y
i=1
p(si|si−1)
(2.11)
Where i is the index of the state in the given sequence, n is the length
of the sequence (that starts from index i = 0) and p(si|si−1) is the
conditional probability of si given si−1, which corresponds to the tran-
sition probability psi−1si. For example, in reference to Figure 2.5, the
probability of seeing the sequence seq = [1,2,2,3,3] is:
p(seq) = 1
3 · 1
2 · 1
2 · 1 = 0.075
(2.12)
When we do not know the transition probabilities, we can learn
them automatically, provided that we have data in the form of se-
quences of states. This is a simple task, since to ﬁnd pij we just have
to count the number of times that from the state i we observed a transi-
tion to state j, and divide this value by the number of total transitions
that had i as starting point.
Despite being a quite simple model with respect to other graphical
methods, Markov chains have found several interesting applications.
One of the ﬁrst applications is shown as an example by Markov him-
self [33] and consists in training the chain’s transition probabilities on
sequences of letters that compose a text, allowing to ﬁnd the proba-
bility of vowel after a consonant, the probability of a consonant after
a vowel, and so on. This application is also at the roots of automatic
names generators that can be found in web sites and online multiplayer
games. Markov chains are also part of Google’s PageRank algorithm
[34], which views web pages as states and links as transitions between
them. In [11], Markov chains are used to perform fault detection by us-
ing a distributed group of agents whose individual transition matrices
are exchanged and weighted based on other agent transition matrices.
This exchange is used to reach a consensus about the state of the sys-
tem and detect faults. In [12] Markov chains have also been used to
30

model the nominal behaviour of an event log and detect anomalous log
entries as deviations from the standard model. A similar approach was
taken in [35], where Markov chains were used to detect intrusion in
computer systems by learning the sequences of actions that normally
are performed on the system, and using them do detect the irregular
actions that are performed when an intrusion is in progress.
31


Chapter 3
Problem setting
In this chapter we formalize the aspects of the problem we have worked
on. In Section 3.1 we illustrate the main components of the system, in
Section 3.2 we describe the format of the event log, and in Section 3.3
we formalize the problem setting. In Section 3.4 we describe more in
detail the scope of this work and justify the choice of the techniques we
have decided to utilize. In Section 3.5 we introduce the libraries chosen
to learn and manipulate the models presented in this document.
3.1
The technical infrastructure
Our work is focused on a system composed of a large number of com-
ponents that are called devices, each associated to a speciﬁc subsystem
and location. During their operation, devices can raise alarms and di-
agnostic messages that are recorded in databases and that can be seen
as events in a log. In this document, we will call device any kind of
component that have reported an event in the log. Since the electri-
cal system analyzed in this work has grown in complexity over time,
with new components and areas progressively added and integrated
within the existing infrastructure, it has become increasingly hard to
keep track of speciﬁc correlations between devices in a global coherent
model. A failure of a device, for example, could propagate and cause

failures of other components or aﬀect an entire subsystem. While a
human expert could manually identify some of the aﬀected devices, a
tool able to automatically pinpoint the devices that lead to a failure
and the devices that are aﬀected by a failure could be extremely helpful
to support the human experts, improve the overall understanding of
the system, and facilitates its management.
3.2
The event log
We now show the structure of the event log. Each entry of the log is an
event that is bound to a speciﬁc device of the system. Fields entries are
ﬁlled automatically by the supervisory and monitoring system. Figure
3.1 shows a single entry of the log with the portion of the headers that
are relevant to our analysis.
Figure 3.1: The ﬁelds of the event log with a single entry.
• Time: It indicates the timestamp at which the event occurred.
• H0: It denotes the geographical area where the device that gen-
erated this entry is situated.
• H1: It deﬁnes the system contained in H0.
• H2: It deﬁnes the subsystem involved.
• Device: It’s a unique identiﬁer for the device that has reported
the alarm. We refer to this column when we talk about the name
of the device.
• Tag, Description, State: These ﬁelds provide additional infor-
mation on the event that was reported, for example on the state
of the device that generated the event.
34

• Action: It determines if the alarm is becoming active or is ter-
minated.
• AlarmPriority: The level of priority of this event: ranges from
0 to 130. The higher this value, the more relevant this event.
The “time” and the “device” identiﬁer are the ﬁelds that are essential to
our models. In all the queries done in our work, the entries will always
be in ascending chronological order with respect to the timestamp in
order to take into account temporal correlations among events. “Ac-
tion” will be used only to select the events that are becoming active.
The numerical value of “alarmPriority” has been discretized into a cat-
egorical variable level of priority, which takes four possible values:
L0, L1, L2 and L3. L0 events are the ones with the lowest “AlarmPri-
ority” value and range from 0 to 20, L1 events go from 21 to 59, L2
from 60 to 99 and L3 events are the most critical ones and range from
100 to 130. Apart from “time”, “device” and “action”, all the other ﬁelds
can be integrated in diﬀerent parts of the models and allow to deepen
the analysis on a speciﬁc aspect of the correlation between devices.
3.3
Formal setting
Each one of the models that we will build is related to a single set
of timestamps T = {t1, t2, t3, ..., tn} that correspond to some relevant
situations that have happened in the system. These relevant situations
could be system failures, alarms risen by speciﬁc devices, or simply time
instants that an operator believes to be interesting. For most of our
work we will obtain the set T by extracting the timestamps of events
of speciﬁc devices dref, that we call reference devices. The choice of the
reference device and of its timestamps will be discussed in detail in the
next chapter. In general, a reference device dref reports in the log a
series of events Eref = {e1, e2, e3, ..., en}. Since each event ei ∈Eref is
bound to an unique timestamp, we can easily ﬁnd the set of timestamps
T at which events in Eref occur.
35

In relation to the event log structure illustrated in Section 3.2, we
deﬁne a function for each of the log’s ﬁelds, with the same name of
such ﬁelds, that, given an event, returns the content of a ﬁeld of that
event. Given E as the set of all events in the log, in Equations (3.1) -
(3.4) some of these functions are shown.
tag: E →String
(3.1)
timestamp: E →Date
(3.2)
state: E →String
(3.3)
alarmPriority: E →N
(3.4)
We call these functions ﬁeld functions and we say they belong to a set
F of ﬁeld functions. For example, the function tag(e) applied to the
event e shown in Figure 3.1 returns the string “Ust”. Additionally, we
introduce a function events(d) that, given a device d, returns all the
events of that device:
events(d) = {e ∈E | device(e) = d}
(3.5)
We now consider a single timestamp i ∈T, in the speciﬁc case in which
we want to build a model that correlates alarms happening after the
anomalies. We will reference Figure 3.2 for the following discussion.
Since the timestamp i is a speciﬁc instant that can be identiﬁed in the
Figure 3.2: The timeline of some events happening after a timestamp i.
timeline of events reported in the log, it will generally be followed by
36

events that can be related to any device d in the system. Let’s deﬁne
these events as eik
dj, where dj is the device that reported the event
e, i indicates that this event is currently considered in relation with
the timestamp i and k is a progressive integer number that uniquely
identiﬁes this event in the database. We now consider a time window
W, called analysis window, that starts from the timestamp i and ends
W time after. All the events eik
dj that lie inside this window are part
of the set Ei
c, that is the set of events correlated to timestamp i, as
shown in Equation (3.6).
Ei
c =

e ∈E | timestamp(e) ≥i,
timestamp(e) ≤i + W
	
(3.6)
In the example, Ei
c = {eik
d1, ei(k+1)
d2
, ei(k+2)
d3
, ei(k+3)
d4
}. If we repeat this
procedure for each timestamp i ∈T, we can build a set Ec called
correlation set:
Ec =
n[
i=1
Ei
c
(3.7)
All the devices dj related to at least an event eik
dj ∈Ec compose the set
C that we call candidate devices.
The same reasoning and naming convention can be easily repeated for
the case in which we want to analyze events that happened before the
anomalies. The main diﬀerence is that we will now talk of a correlation
window −W. The composition of the set Ei
c for this case is deﬁned in
Equation (3.8) and an example of the timeline is shown in Figure 3.3.
Ei
c =

e ∈E | timestamp(e) ≤i,
timestamp(e) ≥i −W
	
(3.8)
37

Figure 3.3: The timeline with events happening before a timestamp i.
3.4
Scope and techniques
As explained in Section 2.1, diﬀerently from many other approaches to
fault prediction and anomaly detection, in our work we do not build a
nominal model of the system and then use it to identify anomalies and
predict faults. Instead, we build models that represent what happens
before or after speciﬁc events like alarms, failures, or simply instants
of interest and we use it to predict correlated events that will rise in
the near future or to detect previous events that caused the anomaly in
the ﬁrst place. More in detail, we generate two types of models over a
subset of variables V ⊂C for each set of timestamps T at our disposal.
We will see how these models complete each other and allow to obtain
interesting information about the correlation between devices.
The ﬁrst type of models chosen for our work is Bayesian network.
Probabilistic graphical models like Bayesian networks oﬀer the possi-
bility to learn a model, to perform inference on it, and to represent
it graphically, and there are few frameworks which oﬀer these three
opportunities together. Despite more complex models like the ones de-
scribed in Section 2.2.4 exist, we believe that a standard Bayesian net-
work is more ﬁt in this context. For example, because of the availability
of temporal data, one could think that using a Dynamic Bayesian net-
work could be a good approach.
However, to apply a DBN in our
38

setting, we would need edges that link variables not only between con-
secutive time slices but also among non consecutive ones. This would
make the model extremely complex, both in the number of variables
and in the number of edges.
The second type of models chosen is Markov chain. The reason be-
hind this choice is mainly because of its capability to describe sequen-
tiality of events. In fact, as we will see in the next chapter, Bayesian
networks can capture correlations and allow for complex inference but
lack the capability of deﬁning a temporal order of such correlations.
The fact that we are dealing with an event log provides both advan-
tages and disadvantages. First of all, since every event ever happened
is reported, there is a high amount of information available. Hopefully,
every cause of every failure and all correlations between devices are
present in the data. However, the obvious consequence is that having
too much data makes information hard to extract. Correlations may
indeed be present in the log, but they could be well hidden behind
hundreds of non correlated events and noise. As described in Section
2.1, process mining is a technique specialized in processing data logs
that is becoming more and more popular. However, it does not suits
our problem very well. In fact, our log entries do not deﬁne the pro-
cesses to which they belong; moreover, even if we could identify some
general processes we would need to specify the precise steps that com-
pose each process, which in many instances is impossible to do because
of the non-deterministic nature of the electrical system’s components.
Ultimately, processes and their step are two minimal requirements of
process mining that are not met in the context of our problem.
The table in Figure 3.4 taken from [36] is an example of workﬂow
log which allows to perform process mining. Each event should refer
to a case (process instance) and to a task, i.e., a well-deﬁned step in
the process. Our log unfortunately does not deﬁne any of these two
required information.
The use of data mining techniques like association rules [37] and
classiﬁcation rules [38] has been also discussed and tried as a part of a
39

Figure 3.4: Example of log needed to apply process mining.
previous, preliminary approach to the problem discussed in this work,
but results of these techniques proved to be less successful than the
compact, readable probabilistic model of the Bayesian networks. A
similar motivation can be applied in favor of the use of Markov chains
graphical representation of temporal sequences with respect to the list
of frequent sequences obtained using sequential pattern mining [39].
3.5
Libraries
We have built Bayesian networks with the help of a Python library
called “Pgmpy” which implements algorithms for exact inference (vari-
able elimination, belief propagation), for performing probabilistic and
MAP queries, and for both search-and-score based and constraint-
based learning. The search strategies implemented are hill climbing
and exhaustive search, while Bic, Bdeu, and K2 are the score metrics
available [40]. To generate the Bayesian models shown in this doc-
ument we have used hill climbing with the Bic scoring method and
variable elimination to perform inference. For what concerns Markov
chains we have used the “Pomegranate” Python library [41]. It allows
to learn Markov chains from data and to calculate the probability of
any sequence given in input by an user. The graph visualization of
40

both Bayesian networks and Markov chains have been performed with
the “Graphviz” library [42], while the well-known clustering algorithms
that will be used in the next chapter have been implemented with
scikit-learn [43].
41


Chapter 4
The Bayesian network model
In this chapter we show the steps to build a Bayesian network that
can represent correlations between devices. In Section 4.1 we describe
all the preliminary choices and passages needed to build the model.
In Section 4.2 we generate the structure of the network and train its
parameters, while in Section 4.3 we show some graphical alterations
that make the Bayesian networks more meaningful in our context. The
methods presented in the chapter are summarized in the Table 6.1 in
Section 6.1.
4.1
Pre-processing of data
4.1.1
The reference devices
As we anticipated in Section 3.3, for most of our work we will extract
the set T considering some devices that we call “reference devices”. A
reference device is a device in the electrical system that is interesting
according to some criterion. For example, it could be a device that
holds some importance for the infrastructure because of its critical role
in the system, or it could be a device that frequently reports events in
the log and an analysis is needed to understand its behaviour. A gen-
eral technique that we will use to identify interesting devices without

resorting to an expert guide is to select devices that have the highest
number of events within the analysis window W after or before each of
their own events. We can also ﬁnd the devices that are followed by the
highest number of events with a speciﬁc “level of priority”, which can
be considered as components of critical importance if the priority level
is high. It is obviously true that the sole quantity of reports after the
events of a reference device could not be enough to denote that device
as interesting, but behind this choice there is also a practical reason:
in order to build an eﬀective prediction model we need an high number
of data to perform the training phase.
In general, when we select a reference device for our analysis we will
always consider only its events with one of the four “levels of prior-
ity”. This means that the set of timestamps T will be composed only
by events with a certain priority. This choice is important because
the consequence of an event with priority “L0” is, for example, usually
unrelated to the consequence of an event of priority “L2”.
4.1.1.1
Multiple reference devices
Sometimes we might be interested in analyzing the correlation between
a group of devices D without having at disposal a set T of timestamps.
In this case we can compose T by taking all the timestamps of all the
events in D:
T =
[
ed∈events(d),d∈D
timestamp(ed)
(4.1)
Of course, to actually perform the analysis of correlations on these
devices we need to select them as variables in our network (V = D).
4.1.2
The analysis window
An important parameter to choose is the length of the analysis win-
dow W. This value determines how many events we will save in the
itemsets Ei
c and, as a consequence, which candidate devices C will be
available to be used as variables in our models. Unless we are given a
44

speciﬁc itemset T and some prior knowledge on the devices that could
be correlated, the choice of W has to be made by taking an informed
guess based on the data distribution. Preliminary analysis on the event
log suggested that a value between 1 and 10 minutes could be appro-
priate. For the rest of this document we will assume W = 5 minutes,
and every network shown is to be considered as generated after the
timestamps, unless otherwise speciﬁed. We will discuss the validity of
this decision in Chapter 6.
4.1.3
The training set generation
In order to build the training set that will be used to generate the
structure and set the parameters of the Bayesian network, we must
ﬁrst deﬁne what is a variable in this model. In its simplest form, a
variable in our Bayesian networks is a device and can assume binary
values: 1 or 0. Among all the possible candidates in C, we have chosen
a subset V that will become the variables of our model, i.e., the nodes
of the Bayesian network. Details on how this choice is performed are
shown in Section 4.2.1. For now, let’s assume that we already have V .
In Section 3.3 we showed how the sets Ei
c contain all the events related
to a timestamp i ∈T within the analysis window W. Since each event
eik
dj ∈Ei
c is associated to one and only one device dj, we can create
the set Ci = {d1, d2, ..., dm} that contains all the devices that appear
in events after or before a single timestamp i. Now we can deﬁne our
training set S with the example in Equation (4.2):
S =
d1
d2
..
dk
..
dm


















1
1
1
1
0
1
0
2
0
0
1
0
1
0
..
..
..
..
..
..
..
i
0
0
0
0
1
1
..
..
..
..
..
..
..
n
1
1
1
0
0
1
(4.2)
45

We see that each row of the training set S is a training instance related
a speciﬁc timestamp i ∈T. For simplicity, we used natural numbers
instead of timestamps in the example.
Each column of S, instead,
is related to a single device dj ∈V . A cell (i, dj) contains 1 if the
device dj was found in Ci and 0 otherwise. When it is not otherwise
speciﬁed, all the methods presented refer to this technique to generate
the itemset and all the networks shown in the following are trained
with the above approach.
4.1.3.1
The duplicate problem
If we just apply the training set generation method previously de-
scribed to all the timestamps in T, we may duplicate some of our
data. Consider the example shown in Figure 4.1. Here, two times-
Figure 4.1: A fragment of the event log with the timestamp i (in black) and
i + 1 (in blue).
tamps i, i + 1 ∈T are such that their temporal distance is less than
W, which means that some of the events in the sets Ei
c and Ei+1
c
are
overlapping (Ei
c ∩Ei+1
c
/= {}). In particular, in the example we have:
Ei
c = {eik
d1, ei(k+1)
d2
, ei(k+2)
d3
}
Ei+1
c
= {e(i+1)(k+1)
d2
, e(i+1)(k+2)
d3
, e(i+1)(k+3)
d4
}
(4.3)
46

but because of the equivalence:
ei(k+1)
d2
= e(i+1)(k+1)
d2
ei(k+2)
d3
= e(i+1)(k+2)
d3
(4.4)
we have that the two sets have the events related to the devices d2
and d3 in common. This overlap happens quite frequently in the data
we used in our experiments, sometimes with events duplicated up to
dozens of times. A device aﬀected by this behaviour is shown in Figure
4.2. The technical reason for this is actually not surprising. For ex-
ample, when a device reports an anomaly, it might report other events
shortly after, that diﬀer in the content of other ﬁelds - like “tag” or
“state” - which specify some other details about the ﬁrst event or con-
sequent anomalies. Figure 4.3 shows the same device of Figure 4.2 with
the ﬁelds “tag” and “description”.
From the point of view of the training phase, we have that d2 and
Figure 4.2: A portion of the log with events of device ECC01/5DX extremely
close one to the other.
d3 are seen together two times instead of one, which increases the be-
lief that they should be correlated. This results in Bayesian networks
with CPD probabilities much biased than without duplicates. On the
other hand, eliminating the duplicates from the timestamp t + 1 may
excessively weaken the correlations. In relation to Figure 4.1, consider
the training set S1 with duplicates in Equation (4.5) and S2 without
47

Figure 4.3: The log shown in Figure 4.2 with the addition of “tag” and “descrip-
tion”.
duplicates in Equation (4.6). Suppose that D = {d1, d2, d3, d4}.
S1 =
d1
d2
d3
d4


i
1
1
1
0
i + 1
0
1
1
1
(4.5)
S2 =
d1
d2
d3
d4


i
1
1
1
0
i + 1
0
0
0
1
(4.6)
The second row of matrix S2 shows a training instance in which no
correlation between d4 and d3 or d4 and d2 is present, even if in the
timeline it appears that d4 could be correlated with them.
Now consider the extract of the event log shown in Figure 4.4, whose
events happen all within a 2 minutes interval. Of the three devices
shown, consider EHS60/BE as reference device, so that its 7 events’
timestamps are all in the set T.
For simplicity, let’s denote device
EKD203/5E as d203 and device EHD20/BE as d20. Without duplicates,
48

Figure 4.4:
A portion of the log with devices EHD20/BE, EHS60/BE,
EKD203/5E.
we would obtain the following training set in Equation (4.7):
S1 =
d20
d203






















1
1
1
2
0
0
3
0
0
4
0
0
5
0
0
6
0
0
7
0
0
(4.7)
which shows only a correlation between d20 and d203.
In the other
6 timestamps d20 is always 0 because it has been already considered
after the ﬁrst timestamp. The training set with duplicates, instead, is
49

in Equation (4.8):
S1 =
d20
d203






















1
1
1
2
1
0
3
1
0
4
1
0
5
1
0
6
1
0
7
1
0
(4.8)
Now d20 appears alone 6 times, with no correlations with d203. The
immediate consequence is that in this example the introduction of du-
plicates weakens the relationship between the two devices.
In fact,
without duplicates, we see that when d20 reports an event, d203 always
reports an event. With the duplicates, when d20 reports an event, in
most of the cases (6 over 7) d203 does not report any event.
The conclusion of all the previous considerations is that by ignoring
the duplicates we can still ﬁnd all the correlations with the possible
downside of making some of them stronger and some of them weaker;
by eliminating the duplicates we may weaken some correlations with
the advantage of not over-representing any of them. These two ap-
proaches are both valid, and can lead to slightly diﬀerent networks. In
the rest of the document, we will always specify when we are using one
solution or the other.
Sometimes, however, neither of the two approaches above can tackle
the duplicate problem. Consider the devices shown in Figure 4.5. After
a quick inspection we can easily see that the events of these three
devices seem to always appear together, usually even in the very same
timestamp. Regardless of how trivial this correlation might be (as the
names of the devices suggests), we can notice that the four groups of
triplets are all happening in an interval of less than 5 minutes (the
length of our window of analysis). If one of the timestamps i ∈T was
to be right before the ﬁrst event shown in the log, we would obtain
50

Figure 4.5: A portion of the log with 3 devices: EMD1A*9, EMD2A*9 and
EMD3A*9.
a single training instance with all 3 devices set to 1, independently
from the duplicate approach taken.
But the log suggests that this
correlation happened 4 times, so we now believe that there should be
4 training instances related to the timestamp i, instead of only one.
Unfortunately, there is no way to smartly solve this problem with the
current training set generation technique, unless we resort to another
approach: clustering.
4.1.3.2
Clustering
Clustering can be seen as both a way to reduce the duplicate problem
explained in the previous paragraph as well as a diﬀerent way in which
we see correlations between devices. Instead of assuming all events
happened within 5 minutes as correlated, we now suppose that corre-
lated events appear in groups, and in the same window of analysis we
may ﬁnd multiple groups such that a device in each group is correlated
to devices appearing in the same group but not with devices appearing
in other groups. This approach is also based on an important assump-
tion: that the correlation between non consecutive events in the same
cluster does not depend by how temporally far away are such events,
but only by their belonging to the same cluster. This means that with
clustering methods we could put in the same itemset two events e1
and e2 that are 1 minute apart from each other, provided that there’s
51

a high number of events between them; and at the same time put in
diﬀerent clusters events e2 and e3 that are only 10 seconds one from
the other. It might seem incorrect at ﬁrst, but it could be ﬁne if we
consider the electrical infrastructure that lies beneath the generation
of these events. Particular states of devices, possibly caused by ex-
ternal events, can cause a sequence of alarms and anomalies all very
close to each other, even a few milliseconds apart. When the sequence
is over, another one may trigger, possibly for diﬀerent reasons. Obvi-
ously there’s the possibility that the new sequence of frequent events is
actually related to the previous one, or to a speciﬁc device in such se-
quence, but we can assume that devices in such new sequence have an
higher chance to be correlated among them than to be correlated with
devices in the previous sequence. Training set generation with cluster-
ing can therefore produce quite diﬀerent results than the one deﬁned
in Section 4.1.3, and might identify a whole new set of correlations.
In order to adopt the clustering approach we directly apply clus-
tering techniques to the events Ec
i for all i. Until now the number of
rows of the training set S coincides with the cardinality of T, because
all the events inside the window W starting from a timestamp i are
saved in the same itemset Ci. We can redeﬁne the generation of the
itemsets by dividing every set of events Ei
c in smaller subgroups Eil
c ,
where l identiﬁes a cluster and takes values from 1 up to qi, which is the
number of clusters found in the event set Ei
c. The value of qi cannot
be known in advance and will be provided directly by the clustering
technique used.
We now deﬁne Q as the total number of clusters across all timestamps:
Q =
X
i∈T
qi
(4.9)
Similarly to what we have done for the itemsets generation in Sec-
tion 4.1.3, since each event eik
dj ∈Ec
l is associated to only one device
dj, we can build a set of devices Cil = {d1, d2, ..., dm} that contains all
the devices related to the timestamp i that appear in a cluster l. While
52

the number of columns of the training set S remains m, the number
of rows will be Q, which is greater or equal than n. Each row of the
training set S is not anymore related to a speciﬁc timestamp i ∈T,
but to a speciﬁc cluster. A cell of S, (il, dj), contains 1 if the device
dj is found in Cil and 0 otherwise.
Now that we have deﬁned the way in which the training set is com-
posed, we must decide how the actual clustering will be performed.
Generally, we consider in the same cluster the events that happen con-
secutively one after another in a time interval that is considerably
smaller than time intervals between non consecutive devices. To reach
this objective we have tested diﬀerent clustering algorithms: from sim-
ple techniques based on average and standard deviations of temporal
distances between consecutive events to well-known clustering algo-
rithms like DBSCAN and Mean Shift.
Fixed distance
The simplest method consists in separating events
in the Ei
c sets in such a way that the temporal distance between the
last event of the cluster l and the ﬁrst event of the cluster l + 1 is
bigger than a predeﬁned value, for example 5 seconds. Inside a cluster,
every event is not more temporally distant from its predecessor and
successor than the value chosen. We call this method ﬁxed distance
clustering. In Figure 4.6 and 4.7 we show some results obtained with
this algorithm using 5 seconds as ﬁxed distance fd.
We can see in
Figure 4.6 how the 5 seconds limit sometimes separates events that
we might want to keep in the same cluster, like the ones happened at
9:31:38 and 9:31:44. In fact, the time interval between these two events
is closer with respect to the time intervals between the other events in
Figure 4.6, in particular the last four which are more distant than 30
seconds. For this reason, we are convinced that the events happened
at 9:31:38 and 9:31:44 are more likely to be correlated with each other
given the higher average temporal distance between the neighboring
events. Following this assumption, we think that the last four events
are not correlated to each other because their time distance is higher
53

Figure 4.6: Fixed distance clustering applied to Ei
c events following timestamp
i=2016-01-08 09:30:40.287 of the reference device EMC001*9
than the events preceding them in Figure 4.6, and so we think that the
ﬁxed distance clustering has made the correct decision of separating
these four events in four diﬀerent clusters. We also see that there are
many events related to device ECC001*23, which presents the duplicate
behaviour described in Section 4.1.3.1. Creating many clusters that
contain just a few devices has a strong impact on the learning phase of
Bayesian model as well as the inference process, because the training
set matrix S will be sparser, composed by many rows with few 1 and
many 0. In the example, the standard training set generation of Section
4.1.3 would have produced a single itemset Ci (with i = 2016 −01 −
0809 : 30 : 40.287) containing a 1 for each of the devices shown in
the image (supposing that they all belong to V ).
With clustering
we now have 10 training instances that almost all contain only one
element, that therefore cannot properly model any correlation between
devices. Figure 4.7 shows an example of an instance in which ﬁxed
distance clustering provides good results because most of the events
happen only a few seconds one after the other. Of course it is possible
54

Figure 4.7: Other results from the application of ﬁxed distance clustering with
fd = 5 seconds.
that a more correct representation of correlations should have kept
all the shown events in the same cluster, instead of separating them
between timestamps 6 : 02 : 07 and 6 : 02 : 17. Or maybe, given the
event density in a short time, the events that happen together in a
timespan of less than 0.5 seconds should have been grouped separately
and the right fd value could have been lower. If we don’t know a precise
temporal value under which two devices can inﬂuence each other, the
ﬁxed distance clustering method has to be discarded or improved by
choosing a dynamic threshold for the separation, directly dependent
from the particular data available.
Average and standard deviation
Instead of choosing a ﬁxed tem-
poral value as a separation criterion, we could use some statistical mea-
sures like average and standard deviation. Given two events e1, e2 ∈Ei
c
we now formally deﬁne the temporal distance between them de1,e2:
de1,e2 = timestamp(e2) −timestamp(e1)
(4.10)
and the Boolean function cons(e1, e2) that returns true if e2 is imme-
diately after e1 in the event log.
The set Di of temporal distances
55

between events related to a timestamp i is deﬁned as:
Di =
[
cons(e1,e2),e1,e2∈Eic
de1,e2
∀i ∈T
(4.11)
We can now compute the average avg(Ei
c) of the entire set of events
Ei
c:
avg(Ei
c) =
P
d∈Di
d
|Di|
(4.12)
and the standard deviation stdev(Ei
c):
stdev(Ei
c) =
v
u
u
t
P
d∈Di
(d −avg(Eic))2
|Di|
(4.13)
We now follow the same clustering procedure of the ﬁxed distance
clustering, with the only diﬀerence that we substitute the ﬁxed distance
fd with the function avg(Ei
c). We call the new algorithm average based
clustering. This new algorithm applied to the same data in Figure 4.6
provides much better results than ﬁxed distance clustering, as shown in
Figure 4.8. In Figure 4.6 the data was excessively divided into clusters
because the average time interval between event occurrences was much
higher than the value fd chosen, while with the average separation
data are compacted when this is reasonable. Average based clustering,
instead, does not perform well when the values in the set Di tend to
assume similar values, like in Figure 4.9, that shows only a signiﬁcative
part of the events in the set Ei
c clustered according to the average based
technique, where i=2016-01-20 06:00:19.437. An high number of events
related to that timestamp are registered, and the value of avg(Ei
c) is
0.28 seconds, which is too low. A little change in the density of events
inside the same set Ei
c can lead to an excessive separation of some of
the events inside a huge set, a part of which has been shown in Figure
4.9. Average based clustering is still a great improvement with respect
to the ﬁxed distance clustering, but we need a more robust separation
criterion. A solution could be the use of k · avg(Ei
c), with k ∈Q+.
56

Figure 4.8:
Average based clustering applied to events following timestamp
i=2016-01-08 09:30:40.287 of the reference device EMC001*9
Figure 4.9: An extract of the application of average based clustering to events fol-
lowing timestamp i=2016-01-20 06:00:19.437 of the reference device EMC001*9.
However, this poses the problem of tuning the parameter k. For some
i ∈T, the choice of k = 1 could perform better in creating meaningful
clusters than k = 2 and vice versa.
We can introduce instead an additional modiﬁcation of the algo-
rithm that takes avg(Ei
c) + stdev(Ei
c) as separation criterion. The use
57

of the stdev(Ei
c) is important because the more the temporal distance
values are variable, the more the algorithm groups together temporally
distant events. On the contrary, if the temporal diﬀerences are regu-
lar, the avg(Ei
c) term becomes more relevant. The criterion based on
the sum avg(Ei
c) + stdev(Ei
c) experimentally performs better than any
ﬁxed numerical value and is more stable and statistically meaningful
than separation approaches based only on k · avg(Ei
c), with k ∈Q+.
Figure 4.10 shows a portion of a clustering procedure performed after
Figure 4.10: An extract of clustering results using the separation criterion based
on average plus standard deviation of temporal diﬀerences of consecutive events
the timestamp 2016 −01 −2006 : 00 : 19.437 of the reference device
EMC001*9. In the window W after such timestamp an high number of
events have been reported, and the overall average and standard devi-
ation have been strongly inﬂuenced by them. It is interesting to take a
look at the statistical measures avg(Ei
c), stdev(Ei
c), and their sum. The
value of the standard deviation (2.08 seconds) is much higher than the
average (0.37 seconds). This provides the robustness that the average
based criterion lacks when the value of avg(Ei
c) tends to 0, as we have
seen in Figure 4.9.
Of course, using average plus standard deviation to separate the
clusters does not exclude the possibility to use some multipliers k1 and
k2 (with k1, k2 ∈Q+) to change the weights of these two statistical
58

measures. For example, we could compute the separation distance as
k1 · avg(Ei
c) + k2 · stdev(Ei
c). Unfortunately, there is no way to tell
in advance which values of k1 and k2 we should choose, especially
because they strongly depend on the interpretation that we give to the
correlation between devices producing events in the same cluster. If
we want to have just a few, big clusters with a separation distance
that include in the same cluster events that are not regular, we should
settle for high values (for example: from 2 to 5).
Otherwise, if we
believe that correlations between devices are very temporarily close
to the preceding devices, we should use a low value of weights (for
example: 1 or 1.5).
A consequence of using this clustering technique is that the correla-
tion between two events e1 and e2, distant in time more than the value
of avg(Ei
c)+stdev(Ei
c), depends from the presence of other events hap-
pened between e1 and e2. If the same temporal distance between e1
and e2 was encountered in another Ei
c, the devices related to these two
events would have been put into diﬀerent clusters, because the tempo-
ral value that determines a division in cluster changes with respect to
i. This occurs also for ﬁxed distance clustering where the separation
value doesn’t depend on i, because long chains of events close in time
to each other can create correlations between devices that otherwise
wouldn’t be recognized as correlated by the algorithm. The creation
of such chains is actually not a problem in our context, because we are
modelling the behaviour of anomalies and we expect that a fault could
cause a sequence of other faults and irregularities.
Mean shift
The Mean Shift algorithm is a mode-seeking algorithm
for clustering. The reason of the name mode-seeking comes from the
fact that these techniques search for the mathematical mode in a set of
data. Mean Shift identiﬁes all the modes (local maxima) in a surface
derived from a kernel density estimate function [44]. The local maxima
of the surface coincide with regions with a high density of data points.
The number of local maxima, dynamically found by the algorithm,
59

corresponds to the number of clusters. Each data point is part of the
basin of attraction of one and only one maximum among all the maxima
found by the algorithm. Points in the same basin of attraction are part
of the same cluster [45]. In standard implementations of mean shift,
like the one that we tested, points on the borderline of high density
areas are not marked as noise. This can lead to confusing separations
between events, like the one showed in Figure 4.11. In this image, the
membership of an event to a cluster is denoted by an arrow followed
by the number of the cluster (that starts from 0). As we can see, the
algorithm separates the events of devices EFG107*9 and EFG103*9
that are 2.86 seconds one from the other, but it keeps in the same
cluster ECC001/15A and EFG103*9 which are 6.21 seconds distant.
In the interpretation of the correlations as a chain of temporal close
events, EFG103*9 should be removed from cluster 2.
This strange
Figure 4.11: A detail of the separation between clusters in an event sequence of
device EMC001*9.
behaviour is actually perfectly normal if we consider that the events
shown in the ﬁgure are at the boundaries of clusters 0 and 2. A point
in such position is not assigned to a cluster or another based on the
distance to its immediate neighbours, but in which basin of attraction
of the kernel density function estimate it lies into. For this reason,
mean shift does not seem to be an eﬀective algorithm to use in our
setting.
A direct comparison with the clustering based on average
plus standard deviation shows that this last method provides a more
meaningful separation between clusters. An example is shown in Figure
4.12
We can see how Mean Shift is not even able to separate the last
event visualized in Figure 4.11, which is registered 23.18 seconds after
60

Figure 4.12: On the left, a sequence of events separated in cluster with the
criterion of average plus standard deviation. On the right, the same sequence
separated with mean shift.
its predecessor in the log, an high value both per se and by considering
the other temporal distances in the same in that sequence.
DBSCAN
Another well-known clustering algorithm is DBSCAN: it
falls under the density-based clustering algorithms and considers clus-
ters as high density areas, separated by low density areas. The ob-
jective of this algorithm is similar to that of Mean Shift, although the
implementation is very diﬀerent. In order to ﬁnd these areas, DBSCAN
identiﬁes the core samples, which are the data points that contain at
least m other points in an ϵ radius. In our case, points are the events
eik
dj ∈Ei
c and the ϵ radius becomes a linear distance over the only di-
mension considered for this problem: the time. Points that are not core
points but are contained in the radius of at least another core point
are called border points. With respect to the Mean Shift algorithm,
DBSCAN performs better in outlier detection, because the algorithm
identiﬁes anomalies by design. These points are called noise points,
and are the points which are neither core nor border points [46]. Clus-
ters are composed by core and border points which have the property
of being density connected. The deﬁnition of density connectivity is
61

based on density reachability and direct density reachability. A pair
of points p and q are density-connected if they are commonly density-
reachable from another point o. A point p is density-reachable from
a point q if there is a chain of points p1, . . . , pn, with p1 = q, pn = p
such that pi+1 is directly density-reachable from pi. Finally, a point q
is directly density-reachable from a point p if p is a core point and q is
in p’s ϵ-neighborhood, which is the set of all points within a radius of
ϵ from the point p.
If we set m = 1, we obtain the same results we would get by using the
ﬁxed distance clustering with ϵ as the ﬁxed temporal value to deter-
mine the clusters separation. This similarity suggests that DBSCAN
maintains the same problem of that algorithm, which is the dependence
from highly arbitrary parameters chosen by the user. Increasing m, the
number of clusters decreases and the density of the clusters increases.
In Figure 4.13 we show a result of DBSCAN application with m=2
and ϵ=12 seconds. The events denoted with a “-1” have been classiﬁed
Figure 4.13: Results from the application of DBSCAN to device EMC001*9.
as noise points and therefore we will consider them as itemsets of size
equal to 1. In this case the other non-noise events are all density con-
nected and they form a single cluster, deﬁned by the group of events
with the “0” label.
Even if DBSCAN behavies better than mean shift thanks to the noise
handling, it is still too ideal in our context because it’s a density based
62

clustering technique, which does not take into account the sequential
distance of consecutive events. Moreover, as a consequence of the fact
that the ϵ parameter is ﬁxed, DBSCAN has problems in handling vary-
ing densities, a characteristic observable also in our data, for many Eil
c .
Our algorithm presented in this section and based on average plus stan-
dard deviation is more suited to cope with this problem. Overall, the
best algorithm found so far to perform this task is the one based on
average plus standard deviation, which we will use to generate all the
clustering-based networks of this document unless otherwise speciﬁed.
4.1.4
Adding new ﬁelds
As we have seen in our discussion on the duplicate problem, the infor-
mation contained in ﬁelds like “tag” or “state” can be useful to eliminate
the ambiguity of temporally-close events that refer to the same device.
Another obvious advantage is that they provide speciﬁc information
about the devices that we are correlating, and therefore they allow to
specialize our analysis. For this reason, we found out that adding new
ﬁelds is something that is useful to do after having already generated
a Bayesian network with only simple devices as variables. This allows
us at ﬁrst to get an handle of the general correlation between two de-
vices, so that later we can see if such correlation is present only when
particular values of some ﬁelds appear, or if it is generally valid.
For example, we may ﬁnd out that two devices d1 and d2 often report
events in the same W intervals. Later, we can generate a network by
attaching the “level of priority” to these devices. We then discover that
every time d1 reports an event of high priority, d2 reports an event of
medium priority; instead, when d1 reports an event of any other prior-
ity level, d2 does not generate any event.
Instead of building a set of candidate devices Ci, we now have to
generate a set of pairs C′
i ∀i ∈T, starting as usual from Ei
c. Each pair
in C′
i is of the type (dj, f(eik
dj)), where i and k are generic indexes for
timestamp and event, and f is a function in a subset of the ﬁeld func-
tions: f ∈F ′ ⊂F. This means that f(eik
dj) represents an additional
63

ﬁeld of the log that is related to events of dj. The variables in our
network will now become pairs. An example of the training set built in
this way is shown in the Equation (4.14), where we used the notation
tagi to denote a speciﬁc value assumed by the ﬁeld “tag”.
S =
(d1, tag9)
(d2, tag2)
(d2, tag3)
(d3, tag7)




i
1
1
0
0
i + 1
0
0
1
1
i + 2
1
0
1
1
(4.14)
An immediate consequence is that now the same variable can appear
in the Bayesian network more than once, but with diﬀerent values of
the ﬁeld f associated. The main downside is that now networks will
involve more variables. The more specialized the ﬁeld we decide to add,
the more variables are needed to show the same interactions between
devices. In the event log illustrated in Section 3.2 there are four ﬁelds
that could be used: “tag”, “state”, “description”, and the discretized
“level of priority”. These four ﬁelds compose the set F ′.
4.2
Model generation
4.2.1
Variables choice
Once we have generated the set C of candidate variables, we must use
a criterion to extract the set V of variables that will actually be part
of the Bayesian network. Many choices are possible, and they often
depend on which aspect of the devices we want to focus on.
4.2.1.1
Manual selection and device exclusion
When we already know the name of some devices of which we want
to ﬁnd the correlations, we can manually ﬁll the set V . If we chose
the timestamps T by extracting them from multiple reference devices,
we would have to select these reference devices as variables if we want
64

to perform the analysis on their correlations. Whenever T is obtained
from a single reference device, instead, we must remove the reference
device from the set of candidate devices C, otherwise it would appear
in every line of the training set and generate an obvious but biased
correlation with every other device in the Bayesian network.
4.2.1.2
Occurrences and support
A simple criterion is to select devices that appear more frequently in
Ec, that is, the devices with the highest number of events within W
minutes of all the timestamps i ∈T. The number of occurrences occ(d)
of each device d can be computed as:
occ(d) =
X
i
pi(d)
(4.15)
where d ∈C and pi(d) is a function deﬁned as:
pi(d) =
(
1
d ∈Ci
0
otherwise
(4.16)
After ranking the occurrences of the devices, we can pick the ﬁrst m
of them. This is called occurrences variable selection criterion. Alter-
natively, we can compute the support sup(d) of each device dj ∈C as:
sup(d) =
P
i
pi(d)
|T|
(4.17)
and select the devices dj that have a support suppdj greater than a
value s. With this last method, called support criterion, we can be
sure to not exclude variables that most frequently appear after the
timestamps i ∈T.
4.2.1.3
Temporal criteria
In some instances we might be interested in devices that appear with a
temporal regularity after - or before - the timestamps in T. To simplify,
65

we will now assume we are building a network on what happens after
the timestamps. For example, consider a device d1 whose events are
observed to be reported always 10 seconds after some speciﬁc times-
tamps of the set T. The timestamps after which the events of d1 appear
are part of the set P, that is such that P ⊂T. Our suspicion is that
device d1 is bound to events in P in a temporal sense. To follow the
direction of this consideration, we introduce two new variable selection
criteria: average and standard deviation.
With the average criterion we select devices whose events, on av-
erage, appear closest to the timestamps i. In detail, we compute the
average avg as:
avg(d) =
P
e∈Ec,d=device(e)
timestamp(e) −i
P
e∈Ec,d=device(e)
1
(4.18)
and then pick the m devices with lowest average, or devices with the
average lower than a certain value s. This method, however, does not
consider how spread the events are around the average. It’s not a good
choice if we are interested in selecting devices that when they appear
in the log after a timestamp i they do it after a regular time interval,
but it’s the best choice if we want to ﬁnd the most rapid devices to
be inﬂuenced on average by events with timestamps in T. To keep the
spread into account we can use the standard deviation criterion, which
consists in computing the standard deviation stdev of each device:
stdev(d) =
v
u
u
u
u
t
P
e∈Ec,d=device(e)
(timestamp(e) −avg(d))2
P
e∈Ec,d=device(e)
1
(4.19)
and taking the m devices with lowest stdev, or the devices with stdev
lower than a certain value s. With this criterion we can select vari-
ables that appear with regularity around the same instant of time, but
without knowing if they will appear close or far from the timestamps
in T. If we are interested in devices that regularly appear immediately
66

after each i ∈T, we can combine the last two approaches and take
the devices d with lowest avg(d) + stdev(d) (criterion of average plus
standard deviation).
If temporal criteria based on average are chosen it is not wise to
choose an high value for the analysis window W. If we are interested
in ﬁnding devices that usually appear regularly after a short amount of
time, increasing the value of W will cause a greater exposure to noise
with a progressively lower probability of ﬁnding new correlations. The
noise in this case are the occurrences of devices that usually appear reg-
ularly within W of the timestamps in T but that with the enlargement
of the window could be found again past W, causing an unexpected
increase in the average and standard deviation values. These new oc-
currences could lead to a non-negligible modiﬁcation of the average and
standard deviation values of the devices. However, the noise problem
for this criteria becomes less important if an high amount of data is
available and if strong temporal correlations are actually present.
A condition that must be applied to temporal criteria is that the se-
lected devices need to have the number of occurrences above a mini-
mum threshold. If this threshold is not suﬃciently high, the criteria
are biased towards choosing devices with low occurrences because it is
easier to have low average and low standard deviation with fewer data.
On the contrary, if the threshold is too high, the variables chosen will
often be the same selected by the occurrence or support criterion, fail-
ing to ﬁnd devices with the behaviour desired.
4.2.1.4
Conﬁdence
We now introduce another criterion of variable selection that we call
conﬁdence. The idea is to select variables that, in the entire event log,
appear more times in the analysis window of the timestamps i ∈T
and less times in any other part of the log. This means that we are
selecting variables that are strongly correlated with the timestamps.
To ﬁnd these variables we must compute the conﬁdence conf(d) for
67

each device d ∈C as:
conf(d) =
P
i∈T
pi(d)
P
e∈E,d=device(e)
1
(4.20)
where the function pi(d) has been deﬁned in Equation (4.16). Note
that since the numerator in Equation (4.20) is the number of times
in which the device d has appeared at least once after every Ei
c and
the denominator is the total number of events of device d in the entire
log, the values of conf(d) might never reach 1, even if the device d
always appears near to the timestamps in T. Another possibility is
to change the numerator to be the total number of times in which d
was found within W from the timestamp. In this case, however, the
conﬁdence value can become higher than 1 because of the duplicate
problem and can lead to give more weights to devices that have events
often duplicated. Indeed, these considerations share many similarities
with the two approaches to the duplicate problem presented in Sec-
tion 4.1.3.1. For the rest of this document we will use the version of
conﬁdence in Equation (4.20). The devices chosen with the conﬁdence
criterion needs to have a value of the denominator of Equation (4.20)
higher than a minimum threshold. The reason for this choice is similar
to what we have said for the temporal criteria. In fact, it is easy to get
high conﬁdence results if the total occurrences of a device in the entire
log are only a few, while it is harder to obtain an high conﬁdence value
if the denominator is an high number.
4.2.1.5
Variable selection with preprocessing variations
All the presented variable selection criteria can be used with the ad-
dition of new ﬁelds to variables as explained in Section 4.1.4. Instead
of computing support, average, standard deviation, and conﬁdence of
single devices, we just have to compute these values for pairs of the
type (device, additional ﬁeld). If we selected the timestamps T using
multiple reference devices, then we can not apply temporal criteria and
68

the conﬁdence criterion since they are implicitly based on the presence
of a single reference device.
In general, conﬁdence and temporal criteria can beneﬁt from this new
variable representation. From a temporal point of view, coupling de-
vices and additional ﬁelds can increase our chances of ﬁnding regular
variables, i.e., variables that steadily appear in the same temporal po-
sition before or after the timestamps in T. It’s instead harder to ﬁnd
devices that activates after regular temporal intervals for any value of
their additional ﬁelds.
The variable selection criteria described in this section assume that
clustering has not been applied. Both temporal and conﬁdence criteria
ﬁnd devices with particular properties related to timestamps i ∈T and
can still be applied to the itemsets generated by clustering methods.
Clustering with the conﬁdence criterion needs only a small modiﬁcation
to Equation (4.20), to avoid the use of pi(d) in the numerator, since
this function is deﬁned on the itemsets Ci that are not present when
we perform clustering. This is only a formal rewriting, and the results
obtained from the application of the Equation (4.22) and from the
Equation (4.20) are the same.
We deﬁne ﬁrst the set devi as d =
device(e), e ∈Ei
c, in order to deﬁne the index wi(d) as:
wi(d) =
(
1
d ∈devi
0
otherwise
(4.21)
The new conﬁdence criterion formula for clustering is:
conf(d) =
P
i∈T
wi(d)
P
e∈E,d=device(e)
1
(4.22)
So, if we choose to apply any clustering technique presented in Section
4.1.3.2 together with temporal or conﬁdence criteria, the variables of
the model V would be the same as those chosen without the application
of clustering.
69

Instead, occurrence and support criterion with clustering techniques
can be rewritten in two ways. The ﬁrst way doesn’t impact the variable
selection process but only the training set S row values:
occ(d) =
X
i
wi(d)
(4.23)
sup(d) =
P
i
wi(d)
|T|
(4.24)
These are the new formulations for Equations 4.15 and 4.17, respec-
tively, and they have to be used in the same way as described in Section
4.2.1.2. The other way to count occurrences and support exploiting
clustering allows also to improve the variable selection mechanism and
consists in computing occ(d) and sup(d) with respect to Cil instead of
Ci. This alternative formula for occ(d) is:
occ(d) =
X
l
pl(d)
(4.25)
where d ∈C and pl(d) is a function deﬁned as:
pl(d) =
(
1
d ∈Cil
0
otherwise
(4.26)
while sup(d) is modiﬁed as:
sup(d) =
P
l
pl(d)
Q
(4.27)
This second formulation is the one we have implemented in our work.
4.2.2
Network generation and interpretation
Once we have selected the variables V and we have built the training
set S, we have everything is needed to generate structure and parame-
ters of our network. In the networks that we will show in the rest of this
70

document, we will always assume that we are using the support vari-
able selection method, the training set generation described in Section
4.1.3, and that we are looking for correlations after the timestamps
of a reference device, unless otherwise speciﬁed.
Figure 4.14 shows
a Bayesian network generated with the timestamps of the reference
device EMC001*9, considering only reference events with priority L2,
with duplicate elimination.
This network graphically indicates that
Figure 4.14: The Bayesian network based on the reference device EMC001*9
with priority L2 and no duplicates.
there are four correlations between the devices.
To understand the
strength of such correlations, we must look at the CPDs of the nodes
(pointed with a dotted line). For example, from the CPDs we see that
the probability of EMD311*9 being 1 given that its parent EMD210*9
is 1 is around 91%. We also notice that the CPD of EMD210*9 is
71

equal to the one of EMD311*9, which suggests us that these two de-
vices (and EMD104*9) probably appear always together. The CPD
of node EMD104*9, since it has no parents, shows the probability of
seeing or not seeing an event of that device in an itemset, i.e., after
the timestamps of the reference device, inside the analysis window W.
Of course, CPD tables oﬀer useful information, but they do not tell
us everything immediately. For example, we do not know which is the
probability of seeing device EMD104*9 when we have seen EMD311*9.
By performing probabilistic inference on the network we obtain the an-
swer of this question: 83.1%.
Now consider the network in Figure 4.15. Here we notice that the re-
Figure 4.15: The Bayesian network based on the reference device ESS11/5H
with priority L1 and no duplicates.
lation between devices ECC01/5DX and EAS11/8H is not one of the
correlations we are looking for. In fact, by looking at the CPD of the
node ECC01/5DX we see that the probability of it being 1 while its
parent is 1 is quite low, around 14.3%. So we deduce that the edge
72

between these two nodes does not represent any correlation. Indeed,
the two devices almost seem to be in a mutually exclusive relation-
ship. Even if it might sound counterintuitive at ﬁrst, it is clear that
an edge in the Bayesian network does not imply correlation (in the
sense deﬁned by our problem) because the Bayesian model can not
grasp the meaning of the diﬀerence between the values “1” and “0”, and
just looks for patterns between variables. Despite this consideration,
the network is far from useless. Inference can still be used to ﬁnd the
most likely answer of the appearance (1) or not appearance (0) of the
devices in the window W. Graphically, however, the network structure
becomes much less reliable. We will propose a solution to this problem
in Section 4.3.1.
Suppose now that we have a network like the one in Figure 4.14,
with edges that actually represent strong correlations between nodes.
We now ask ourselves which is the the meaning of these edges. Does
an arrow from device EMD104*9 to EMD210*9 imply that the ﬁrst is
the cause of the other? Or does it mean that the ﬁrst usually appear
after the other? The answer to both of these question is no. Because of
the way in which the training set is built, that is, without considering
the temporal order of appearance of the devices, the resulting network
provide no meaning in a causal sense. What we can say when looking
at a strong correlation is that, for example, EMD210*9 appears with
high probability when also EMD104*9 has appeared.
Or, more in
detail, an event of EMD210*9 appears with probability 91% within 5
minutes of an event of EMC001*9 of priority L2 when also an event
of EMD104*9 has appeared. Moreover, if we do not perform inference
on speciﬁc pairs of variables, we can not say anything about variables
that are not directly connected with an edge. This problem will also
be addressed in the next section.
73

4.3
Post-processing
4.3.1
Inference labels
As we explained in the previous section, an edge between two devices
does not necessarily imply correlation, at least in the context of our
problem. However, by looking at the CPDs and performing inference
we can deduce which variables are correlated. Since our models must
be interpreted directly by an user, to make the Bayesian networks
more meaningful we present a graphical variation based on inference.
In Figure 4.16 we show a Bayesian network with the introduction of
labels on the edges. We have also marked strong correlations in red. We
call these labels ﬁrst inference labels, because they show the result of
particular inference queries over the nodes. In detail, given two devices
Figure 4.16: The Bayesian network of device EMC001*9, with priority L1, no
duplicates and the addition an inference label on the edges.
d1 and d2 and an edge e that connects them, with d2 being the parent of
d1, the ﬁrst inference label shows the result of the probabilistic query:
74

p(d1 = 1 | d2 = 1)
(4.28)
In our context, these labels tell us which is the probability of seeing an
event of the device d1 when we have already seen an event of d2. They
are equivalent to the CPD probabilities of having the node value equal
to 1 when the parent is 1, and for this reason we could also call them
CPD labels. In fact, since the most important information given by
the CPDs in our problem are the values in the cells whose variables in
rows and columns take only the “1” values, it makes sense to graphically
represent only that probability. The networks represented in this way
provide the information in which we are interested in a much more
immediate way.
The CPDs are still used to perform inference and
conditional probabilities which involve some “0” as values of variables
can still be discovered with it, if necessary.
These CPD labels, however, shows us the probability of an event only
in one direction. To check which is the probability of the parent when
an event of the son has been observed, we must compute the following
query:
p(d2 = 1 | d1 = 1)
(4.29)
The result of these new queries can be attached to the edges of the
network, separated by the symbol “|” from the ﬁrst inference labels.
We call these new labels second inference labels and we say that net-
works like the one in Figure 4.17 has the graphical addition of double
inference labels. The double inference labels allow to understand if a
correlation is more relevant in one direction or the other. For exam-
ple, it might happen that when device d2 appears, d1 rarely reports
events; instead if d1 appears then d2 always appears. In this case we
could be tempted to say that most likely d1 is the cause of d2. Indeed,
in some instances we might be correct, assuming that the event of a
device does not have multiple causes. However, it is easy to see that
this is not true in general. Imagine that we know for sure that there is
a device d3 that causes the independent appearance of d1 and d2, and
another device d4 that causes only the activation of d2. Suppose that
75

Figure 4.17: The Bayesian network of device EMC001*9, with priority L1, no
duplicates and the addition double inference labels on the edges.
d3 and d4 were not included in the network because of the variable
selection criteria we choose. Now, we ﬁnally understand why d1 and d2
are always seen together, and we also understand why the appearance
of d2 (when caused by d4) does not imply that we will see d1. This
problem has been brieﬂy discussed in Section 2.2.1, where these hidden
variables have been called latent variables. Moreover, because of the
non-temporal nature of our training set, we do not know if a device
will appear before or after another correlated device. In the previous
example, there are no constraints that impose the appearance of d1
before d2 or vice versa, and our reasoning with respect to d3 and d4
remains valid either way.
At the light of these considerations we will generally consider our
Bayesian networks as non causal, and therefore we will not perform
intervention queries, which we have discussed in Section 2.2.2.
76

4.3.2
Reference device
When we use a reference device to extract the timestamps, our net-
work assumes a diﬀerent meaning. We are no longer ﬁnding device
correlations before or after some key time instants, but after or be-
fore a speciﬁc device has generated an event, which is correlated to
all the devices in the network, even if such device does not appear in
the network. In this case it could be interesting to visually show such
reference device, in order to immediately identify its relationship with
the rest of the network. Figure 4.18 shows the same network in Fig-
ure 4.14 with the addition of a node with blue edges that represents
the reference device and its connections with the other nodes. We call
Figure 4.18: The Bayesian network of device EMC001*9, with priority L2, no
duplicates, the double inference labels on the edges and the reference device.
the node of device EMC001*9 reference node. Obviously it is not part
77

of the Bayesian model and it provides, with labels on the blue edges,
the probability of seeing all the other devices in the network after its
events. For example, the probability of seeing an event of EBS112*10
after an event of EMC001*9 is 48%.
4.3.3
Locations
There are many ways in which the Bayesian model can be graphically
altered in order to integrate additional information found in the event
log. We tried this approach with the ﬁelds “H0” and “H1”: we showed
“H0” as a rectangular box enclosing a subgraph and labeled with the
locations of the devices, and “H1” by coloring the nodes belonging
to that location and showing the correspondence in a legend.
The
intention behind this graphical addition is to allow the user to quickly
identify interesting correlations, like relationships between far away
devices in diﬀerent areas that should not interfere with each other, or
to simply localize the position of correlated devices.
4.3.4
Devices information
An interesting information that is related to the validity of the found
correlations is the number of times in which each device is present
in the training set.
In Figure 4.20, we added this information in a
box around each node. As we can see, this network has a fairly low
number of occurrences.
The inference labels, however, tell us that
between the devices there are good correlations that are quite unlikely
to be all due to noise. Anyway, by looking at the occurrences an user
could decide how much does she want to trust the network. Beside
occurrences, another useful addition to our networks is the average and
standard deviation of the diﬀerence between the timestamps at which
the events of the devices appear with respect to the timestamp of the
initial event of the reference device. These values are the same as those
illustrated in Section 4.2.1.3. They can be used to graphically evaluate
the temporal placement of the devices, for example after choosing a
78

Figure 4.19: The Bayesian network of device ESS1*84, with priority L1, no
duplicates, the double inference labels and the device locations.
temporal variable selection criteria, or they can prompt the generation
of a new network based on these criteria. In Figure 4.21 an example
of these additional device information is shown.
4.3.5
Inference network
Since the correct interpretation of our Bayesian networks is strongly
based on the result of inference queries, we could argue that all that
really matters is the inference. Following this consideration we built
79

Figure 4.20: The Bayesian network of device EXS106/2X, with priority L1, no
duplicates, the double inference labels and the occurrences.
a type of network, that we call inference network, in which every con-
nection between every pair of variable is possible, provided that at
least one of the two inference labels computed between those pairs is
greater than a given parameter. Changing such parameter allows us
to generate inference networks with an high or low threshold for the
relevance of the correlations we want to visualize. Figure 4.22 shows
the inference network of the Bayesian model in Figure 4.14. In this
case, we used a relatively high threshold in order to avoid showing too
many edges. One of the advantages of this representation is that the
user can immediately identify which appearances of devices can lead
to other highly likely appearances, without having to manually per-
form the inference queries. In other situations, instead, we might have
generated Bayesian networks with an high number of variables, which
normally turn out to be hard to evaluate graphically. In this cases we
80

Figure 4.21: The Bayesian network of device ECD1*62, with priority L1, no
duplicates, the double inference labels and the devices information.
can reduce the number of edges shown by using an inference network
that ﬁlters out all the edges with low values of inference labels.
81

Figure 4.22: The inference network of device EMC001*9, with priority L2 (with-
out duplicates).
82

Chapter 5
The Markov chain model
This chapter illustrates the work done on the Markov chain model with
a structure that mirrors that of Chapter 4. As we will see, many tech-
niques used in preprocessing and postprocessing of Bayesian networks
are applicable also in Markov chains. In Section 5.1 we deal with the
preprocessing phase, in Section 5.2 we explain the interpretation of this
model, in Section 5.3 the possible graphical additions. A summary of
the methods presented in this chapter will be reported in the Table 6.1
in Section 6.1.
5.1
Preprocessing of data
5.1.1
Timestamps and analysis window
The selection of the set of timestamps T for Markov chains can be
performed by taking into account the same choices that we discussed
in Section 4.1.
We can extract T starting from a reference device,
a set of multiple reference devices, or we can directly obtain it from
a human expert. The same considerations also hold for the analysis
window, which we still consider set to W = 5 minutes.

5.1.2
Training sequences generation
In order to generate the Markov chain model, we must ﬁrst generate
the sequences of states that we will use in the training phase to learn
the transition probabilities. Assuming that we already selected, among
all the candidate devices C, the set of states V ⊂C that we want to
represent in the model (such choice is addressed in Section 5.2.1), we
now have to deﬁne the training sequences. Each training sequence is a
vector ⃗Pi of variable length associated to a speciﬁc timestamp i ∈T,
where each element of ⃗Pi is a device dj ∈V .
To build a sequence ⃗Pi in the case in which we want to model what
happens after the timestamps, we must ﬁrst consider the event set Ei
c,
scan all the events e ∈Ei
c in chronological order from i to i + W and
save in a vector ⃗Bi the devices dj such that dj = device(e). Devices
dj are saved into ⃗Bi keeping the chronological order of the events to
which they refer to. By repeating this procedure for each i ∈T we
obtain the multiset B = { ⃗Bi|i ∈T}, which admits possible identical
sequences. The criteria to select the states to save in V are applied to
this multiset.
The major diﬀerences between a set Ci, generated in the preprocess-
ing phase for the learning of Bayesian networks, and a vector ⃗Bi, are
that the latter admits the presence of duplicate devices and takes into
account the ordering of its elements.
Once we have at disposal the set V , the training multiset P = {⃗Pi|i ∈
T} is generated by ﬁltering the sequences ⃗Bi ∈B ∀i, eliminating all
the occurrences of the devices dj /∈V . The ﬁltering procedure does
not modify the relative ordering of the devices which form ⃗Pi.
Equation (5.1) shows an example of training sequences of the multiset
P where V = {d1, d2, d3, d4, d5} and T = {1, 2, 3}. We notice that
sequences have a variable length that simply depends from how many
events of the devices in V were present after the timestamps inside the
84

analysis window W.
P1 =
h
d2
d4
d2
d4
i
P2 =
h
d1
d3
d5
i
P2 =
h
d1
d3
d4
d5
d4
d5
i
(5.1)
If we include in V all the devices of our dataset there would be no
need to apply variable ﬁltering: the multisets B and P would be equal
and the generated model will represent direct transitions probabilities.
In this case, sequences of adjacent devices in vectors ⃗Bi would cor-
respond to the devices with temporally consecutive log entries in the
database. Unfortunately it is impossible to visualize hundreds or thou-
sands of variables and their transition probabilities in a graph, but if
there is no need to visualize the entire state diagram, it could be feasi-
ble to learn a model with a huge number of variables. As we have seen
in Section 2.3, the training of a Markov chain is not computationally
expensive. As reported in Pomegranate’s documentation [41], there
are no latent factors to train and so no expectation maximization or
iterative algorithms are needed to train anything. For each sequence,
maximum likelihood estimates are used to update the parameters of
the distributions. The calculation of the probability of a sequence of
variables is fast too, because it consists in the computation of simple
products.
This would be a way to get information from the model
when we cannot visualize it.
However, what commonly happens it is that the analysis performed
on a graphically displayable set of variables V (i.e., a low number
of variables) generally shows relative transitions probabilities.
The
sequence of variables inside ⃗Pi, in fact, represents the relative ordering
of the variables in V inside the corresponding vector ⃗Bi, while the
vector ⃗Bi contains the true, unﬁltered ordering. This discrepancy can
lead to misinterpretations of the transition probabilities. We will call
this problem the ﬁltering problem.
85

These problems, however, do not decrease the usefulness of the
Markov chain model. If we generate a Bayesian network and a Markov
chain based on the same subset of variables V , we can discover infor-
mation about the temporal relative order of activation of two variables
d1 and d2 that are strongly correlated in the Bayesian network. If by
looking at the Markov chain we see that the probability of the transi-
tion from the state corresponding to d1 to the state corresponding to
d2 is much higher than the probability of the inverted transition from
d2 to d1, we gain a much more reliable information about the causality
of the relationship than what we could discover from the same situa-
tion with a Bayesian network. We will show in Section 6.6 an example
of a Bayesian network and a Markov chain applied on the same data
and subset of variables. Moreover, suppose that there exists a frequent
activation of events of two devices d1 and d2, where d2 registers its
events usually 20 seconds after d1. It is possible that in many cases
this correlation is not recognized by the Markov chain which considers
all the variables in the log, because other devices could have registered
events that have little or no relation to the frequent process regard-
ing d1 and d2. An analysis based on the relative temporal ordering
of devices could instead highlight better the presence of this frequent
pattern.
5.1.2.1
Duplicates
The duplicate problems that we have seen in the Bayesian model can
be present also in the training sequences of Markov chains, but lead to
diﬀerent consequences. We consider the timeline we used to illustrate
the duplicate problem in Section 4.1.3.1, which we report again in
Figure 5.1 for better clarity. If we do not modify our algorithm to
handle the duplicates, we obtain the sequences in Equation (5.2):
⃗Pi =
h
d1
d2
d3
i
⃗
Pi+1 =
h
d2
d3
d4
i
(5.2)
86

Figure 5.1: An example of timeline with some events related to two timestamps
i (in black) and i + 1 (in blue).
Since, as explained in Section 2.3, Markov chains do have the Markov
property, what determines the transition probability to a device (i.e.,
a state) is just the device the immediately before it in the sequence.
In Equation (5.2) the pair d2, d3 is present twice, instead of only one
time as the timeline shows. This means that the transition probability
from d2 to d3 is higher than it should be.
Let’s now consider the same sequences generated by removing the du-
plicates (that is, by considering each event only once):
⃗Pi =
h
d1
d2
d3
i
⃗
Pi+1 =
h
d4
i
(5.3)
Now the problem is that we lose the transition between d3 and d4. We
can lose at most one transition for each pair of timestamps i and i + 1,
that is, we may lose in total a maximum of |T| −1 transitions. In
Markov models with a total number of transitions considerably greater
than |T| −1, the impact of such loss is minimized. In comparison,
in the Bayesian networks the approach based on duplicate elimination
can make us lose up to |V | −1 correlations (where each correlation
is a pair of variables both set to 1 in the same training instance) for
each pair of consecutive timestamps, for a total (in the worst case) of
(|V | −1) · (|T| −1).
87

Moreover, there is a way to completely eliminate all the disadvantages
when we remove duplicates in Markov chains. If we detect that we are
going to lose a transition because of the overlaps between two times-
tamps, we can add such transition as a single sequence in the training
sequences. In the example, we just have to add [d3 d4]. Equivalently,
we could also merge the two sequences and obtain a single sequence
[d1 d2 d3 d4]. This new approach can be deﬁned as “perfect solution”
and every Markov chain shown in the following has been generated in
this way. The latter “perfect” implementation based on the sequence
merging is preferable to the former, because we have to consider that
the vectors ⃗Bi to which we are referring to in these examples will be
ﬁltered to create the training sequences ⃗Pi. If only one device between
d3 and d4 is not selected as a variable of the model V , the addition of
the sequence [d3 d4] will not change any probability of the model to
be learned. If instead, for example, d1, d4 ∈V and d2, d3 /∈V , the
sequence merging approach provides to the training procedure a new
example of transition from d1 to d4.
5.1.2.2
Clustering
As we explained in the previous section, the relevant information in
a Markov chain is given by consecutive devices. By applying cluster-
ing, we divide the sequences in multiple, shorter sequences. This can
be done with the same metodologies explained in Section 4.1.3.2. Be-
sides the set Cil that deﬁnes the candidate variables of each cluster
l ∈{1, qi}, we deﬁne the vector ⃗
Bil and the corresponding ﬁltered vec-
tor ⃗Pil.
Breaking a sequence related to a timestamp i ∈T in qi parts means
that we are losing qi −1 transitions during the learning process. The
best case scenario would be the situation in which we manage to break
the sequences in the correct position that separates two groups of events
that have nothing to do with each other.
Clustering also helps with the ﬁltering problem, since it naturally sep-
arates long chains and can avoid the situation in which two devices
88

that are temporally far away are consecutive after the ﬁltering of the
vector ⃗Bi.
Conservative applications of clustering which tend to create few se-
quences containing many devices could be a good option for the Markov
chain setting. For example, a choice could be the criterion based on
average and standard deviation.
5.1.2.3
Adding new ﬁelds
The addition of new ﬁelds in the log can be done in a way very similar
to the one described in Section 4.1.4. Following the same approach,
we build a new set C′
i that replaces Ci and contains pairs of the type
(dj, f(eik
dj)). To build the set ⃗Bi, as done in Section 5.1.2, we have to
scan all the events e ∈Ei
c in chronological order from i to i + W, and
save the pairs (dj, f(e)) such that dj = device(e). Of course, the se-
quences obtained at the end of the training sequences generation will be
composed by pairs too. This addition allows to specialize the Markov
chain in ﬁnding transitions between precise states of the devices. As
for Bayesian networks, the four ﬁelds “tag”, “state”, “description”, and
“level of priority” can all be used freely, with the same considerations.
5.2
Model generation
5.2.1
The choice of states
The selection of states for the set V follows the same principles and
methods in Section 4.2.1. First of all, the occurrences of the devices
d ∈C can be computed as occ(d):
occ(d) =
X
i∈T
| ⃗Bi|−1
X
k=0
b( ⃗Bi[k], d)
(5.4)
89

where b(dj, d) is a Boolean function that compares two devices:
b(dj, d) =
(
1
dj = d
0
otherwise
(5.5)
The deﬁnition in Equation 5.4 allow us to use the occurrences method
in this model. The support criterion, instead, is not deﬁned for Markov
chains. Instead, we introduce the frequency criterion, which computes
freq(d):
freq(d) = occ(d)
|T|
(5.6)
freq(d) can assume values greater than 1 because the numerator in
Equation (5.6), diﬀerently from the support criterion in the Bayesian
model, does count multiple appearances of the same device for each
timestamp i ∈T. The result of the frequency method, however, is
conceptually similar to the support: it allows to select devices that
exceed a relative frequency threshold.
The temporal criteria can be applied exactly as explained in Section
4.2.1 because they do not operate on sequences, but directly on the set
Ec. The same holds for the conﬁdence criterion.
We now introduce a new criterion called close pairs that allows to
select devices that frequently appear one after the other. First of all
we deﬁne a function pairs(da, db) that returns the number of times in
which two devices da and db were found one next to the other in the
sequences:
pairs(da, db) =
X
i∈T
| ⃗Bi|−2
X
k=0
z( ⃗Bi[k], ⃗Bi[k + 1], da, db)
(5.7)
where the function z(dj, dh, da, db) is deﬁned as:
z(dj, dh, da, db) =







1
(dj = da AND dh = db) OR
(dj = db AND dh = da)
0
otherwise
(5.8)
90

Now we compute pairs(da, db) for all the devices (da, db) ∈D × D with
da /= db, and we rank the results. The criterion consists in taking all
the devices that appear in the m pairs with most occurrences. This
method inherently looks for devices that have a strong temporal order
of activation and generates transitions that represents more truthfully
what happens in terms of event reporting in the log. As explained in
Section 5.1.2, the ﬁltering problem of the vectors ⃗Bi that produces ⃗Pi
causes sequences to lose most of their elements and alters the overall
structure of the chain by putting as consecutive two devices that might
have been separate by other events. The main way to avoid this is to
select an high number of states; this method instead tries to bypass
the problem by selecting devices that are immediately adjacent in the
log and that will result in real direct transition among them.
However, it is not guaranteed that all the chosen devices will appear
in adjacent positions in the log. For example, we may select a pair
of devices d1, d2 that often appear at the beginning of the analysis
window W, and a pair d3, d4 that usually appear at the end of W.
If these are the only variables we select, our sequences will inevitably
contain transitions between elements of the ﬁrst pair to elements of
the second pair, even if they are temporally afar. This is just another
consequence of the ﬁltering problem and we could also try to resolve it
performing clustering. Anyway, the transitions between devices of dif-
ferent frequent pairs should have low probabilities because the number
of transitions between elements of the same pair have high occurrences
by design. In the best case in which all the frequent pairs come from
a chain of activations that involves diﬀerent devices, we would exploit
at best the advantages of the close pairs criterion.
As we did for Bayesian networks, these state selection criteria can
be applied with the addition of new ﬁelds and clustering, with trivial
modiﬁcations of the equations that mirror the ones in Section 4.1.4.
91

5.2.2
State diagram generation and interpretation
After the selection of the variables V and the application of the ﬁltering
process, we are ready to train the Markov chain.
The multiset of
sequences P is the only input needed to learn a Markov chain. In the
networks that we will show in the rest of the document, we will always
assume that we are looking for correlations after the timestamps of a
reference device and that when we apply clustering we use the method
based on average plus standard deviation, unless otherwise speciﬁed.
Figure 5.2: Markov chain based on the reference device EHS60/BE with priority
L1 using conﬁdence criterion.
The network in Figure 5.2 shows four devices selected with the
conﬁdence criterion. We can verify that the learning algorithm of the
Pomegranate library creates consistent Markov chains because the sum
of all the outgoing transition probabilities is 1 for every state. In some
cases the sum is almost 1 only because of the approximation to the
92

second digit used for a clearer visualization. The possible presence of
sequences of the same devices lead to the creation of self-loops. For
example, EHT3/BE has an high probability on its self-loop.
When no self-loops are present we can deduce that there is not even
an example in the training multiset P which presents consecutive ap-
pearances of the same devices. It would be interesting to perform an
analysis considering states with additional ﬁelds, to discover the order
of activation of tags or descriptions related to events of EHT3/BE.
Some conclusions that we can draw from the state diagram in Figure
5.2 are that after seeing an event of device EKD102/1H is very likely,
within the window W, to see an event of device EKD108/8HM, after
which we have some probability to see EKD104/6HM and then again
EKD108/8HM, in a loop with probabilities equal to 50% and 67%. On
the contrary, if we see EHT3/BE we most likely will keep seeing events
of the same device.
5.3
Postprocessing
As we did for the Bayesian model in Section 4.3, we can extend the
graphical representation of Markov chains to include additional infor-
mation that can help with our analysis.
5.3.1
Arc coloring and edge ﬁltering
With more than 4 variables, too many edges are drawn and the visu-
alization like the one in Figure 5.2 is no more clear. In Figure 5.3 we
represent the same network of Figure 5.2 without drawing the edges
with a probability lower than 0.15 and coloring in red the edges with
a probability greater than 0.5.
With this choice, the network loses
the property of Equation (2.10) in Section 2.3, but we can ﬁnd more
easily frequent activations of devices, like the arc from EKD102/1H to
EKD108/8HM which has an high probability (0.8).
If we decide to visualize more variables, the minimum threshold for
drawing an edge could be increased. We have tried to increase it to
93

Figure 5.3: Markov chain based on the reference device EHS60/BE with priority
L1 using conﬁdence criterion, with red arcs and 0.15 as minimum threshold for
edge visualization.
reach the value 0.33, which we suggest as a maximum value for the
threshold. We suppose that if a device d1 is followed by another device
d2 more than a third of the times, this shouldn’t be considered as pure
noise but it could be a signiﬁcative correlation.
5.3.2
Temporal labels
Since Markov chains provide a way to observe the sequentiality between
events reported by some devices, we realized that it could be useful
to visualize the temporal distance between every pair of device in the
network. The state diagram in Figure 5.4 shows a Markov chain where,
after the transition probability on each edge, are reported between
parenthesis two values in seconds. Consider an edge that goes from a
94

Figure 5.4: Markov chain with temporal labels based on the reference device
EMC001*9 with priority L2, using temporal criterion based only on minimum
standard deviation
device d1 to another device d2. The ﬁrst value in the parenthesis is the
average time of the appearance of the events of d2 after the events of
d1, while the second value is the standard deviation of the same time
of appearances.
States in Figure 5.4 have been selected with the temporal criterion
based on minimum standard deviation with respect to the timestamps
of events of the reference device EMC001*9, with priority L2.
We
notice how the values of average and standard deviation of the time
elapsed between two events of adjacent devices in a sequence are low
too: the average ranges from a minimum of 3.2 seconds to a maximum
of 21.4 seconds and the standard deviation from 8.1 to 23.4 seconds.
The transition probability values are generally high and we can spot
a cycle in the diagram which involves only red arcs with just one of
the four arcs having a probability lower than 0.8. However from this
representation we cannot know which is the ﬁrst and last device of
95

such frequent cycle. There are many reasons to believe that we could
have found a signiﬁcant correlation but we have to know on how many
occurrences this network is based on to be conﬁrmed.
5.3.3
Locations and device information
The addition of locations and information about the occurrences, av-
erage, and standard deviation to the state diagram is straightforward
and follows the same considerations done in Section 4.3.3 and Section
4.3.4. In Figure 5.5, we generate the same network in Figure 5.4 with
additional statistics for every state. We can now verify if the corre-
lations found in Figure 5.4 are based on a suﬃcient number of data.
In each box that surrounds a device d we can also see how many sec-
onds, after the events of the reference device, the events of device d
appear in average (“Avg”), and the standard deviation (“St.Dev.”) of
the time interval of the same appearances. We expect the latter to be
relatively low since the represented devices has been chosen with the
criterion of minimum standard deviation. In this Markov chain, the
minimum occurrence threshold to take into consideration the selection
of a device as a state was set to 5 occurrences. We ﬁnd out that the
strong correlations we found are actually based on few data, but the
similar values of occurrences, average, and standard deviation suggest
the possible presence of dependencies among these devices.
Figure 5.6 shows the value of the ﬁelds “H0” and “H1” for each state,
with the same graphical conventions seen for Bayesian networks, ap-
plied to the same network of Figure 5.4. From this image we discover
that all the four devices share the same area “H0” (“Meyrin Jura”), and
sub-area “H1” (“ME9”).
5.3.4
Reference device
Another graphical addition is the reference device, as we did already in
Bayesian networks. However, here the edges that connect the reference
device node to the other states show labels that do not represent the
96

Figure 5.5: Markov chain in Figure 5.4 with additional information.
support of such states, but the probability of seeing a state as the ﬁrst
after the event of the reference device, or as last before the event of
the reference device. In Figure 5.7 we show the Markov chain based on
the same network in Figure 5.4 with the reference device. As we can
see, that EMD104*9 is the ﬁrst device of the training sequences ⃗Pi ∈P
for 64 % of the cases. When it is not the ﬁrst device of a sequence, it
always appears after EMD311*9. We underline that a device that is
the ﬁrst appeared in the sequence ⃗Pi may not necessarily be the ﬁrst
device in the correspondent unﬁltered sequence ⃗Bi.
Figure 5.8 shows a Markov chain that represents what happens
before the timestamps of the reference device EHS60/BE with priority
97

Figure 5.6: The Markov chain in Figure 5.4 with the addition of the locations of
devices.
L3. In this case, we see that EHD33/BE is the only device to report
an event before EHS60/BE. This means that EHD33/BE is also a sink
for the network: every sequence ⃗Pi terminates with this device.
98

Figure 5.7: The Markov chain in Figure 5.4 with the addition of the reference
device.
99

Figure 5.8: The Markov chain related to what happens before the events with
priority L3 of the reference device EHS60/BE, with the graphical addition of the
reference device.
100

Chapter 6
Examples of use
In this chapter we show some Bayesian networks and Markov chains
from which we can draw interesting conclusions. First, in Section 6.1
we summarize the main methods presented in Chapter 4 and Chapter 5.
In Section 6.2 we show how much, in practice, the presence or absence
of duplicates can inﬂuence our Bayesian networks. In Section 6.3 we
provide a comparison of models built with diﬀerent variable selection
criteria, while in Section 6.4 we show and comment some models with
additional ﬁelds attached. In Section 6.5 we discuss about the value
of the analysis window W.
In Section 6.6 we compare the results
of the Bayesian model and Markov chains with a practical example.
In Section 6.7 we show an example of a network based on multiple
reference devices and discuss its utility.
6.1
Summary of methods
Before showing some examples of use of our models, we summarize the
main methods presented in Chapter 4 and Chapter 5. In Table 6.1 we
show such techniques, split up in the three parts: preprocessing, model
generation, and postprocessing.
101

Phase
Method
Section
(BN)
Section
(MC)
Preprocessing
Timestamp
selection
Manual
4.1.1
5.1.1
Reference device
4.1.1
5.1.1
Multiple reference
devices
4.1.1.1
5.1.1
Training set or
training sequences
generation
Standard
4.1.3
5.1.2
Duplicate handling
4.1.3.1
5.1.2.1
Clustering
4.1.3.2
5.1.2.2
Additional ﬁelds
4.1.4
5.1.2.3
Model generation
Selection of
states and
variables
Occurrences
4.2.1.2
5.2.1
Support
4.2.1.2
×
Frequency
×
5.2.1
Temporal
4.2.1.3
5.2.1
Conﬁdence
4.2.1.4
5.2.1
Close pairs
×
5.2.1
Postprocessing
Graphical
additions
Inference labels
4.3.1
×
Reference device
4.3.2
5.3.4
Temporal labels
×
5.3.2
Locations
4.3.3
5.3.3
Device information
4.3.4
5.3.3
Alternative
representation
Inference network
4.3.5
×
Table 6.1: Summary of the main methods for preprocessing, model generation
and post processing.
Next to each method we indicate the section in which it was explained
102

for the Bayesian networks (BN) and Markov chains (MC). Any cell
containing a cross in the “Section” columns indicates that the corre-
sponding method cannot be used with that model (BN or MC).
6.2
The inﬂuence of duplicates
To understand the impact of the duplicates on Bayesian networks we
show some examples of how the number of occurrences of candidate
variables changes with respect to the removal of duplicates. In Figure
6.1 we see on the left a list of candidates variables found with the dupli-
cates, and on the right the list without duplicates. Both lists are related
to the timestamps extracted from the reference device EHS60/BE, with
priority L1. Besides each device, the ﬁrst number indicates the support
with respect to the reference device; the second number indicates the
number of occurrences in the training set. The two lists are partial
rankings and they show only the top positions. As we can see, even
Figure 6.1: Comparison of candidate variables with duplicates (on the left) and
without duplicates (on the right) for the reference device EHS60/BE with priority
L1.
in a network with a relatively low number of variables, there might
be a considerable number of duplicates. Occurrences of devices like
EHT1/BE and EHT2/BE are more than doubled, while most of the
103

other device occurrences are increased. Moreover, some devices in one
of the two rankings are not present in the other, which shows how the
duplicates can alter the variables we pick with this criterion.
Now we generate two Bayesian networks on the 6 devices under-
lined in red and compare results in the case with duplicates and without
duplicates. The two networks are shown in Figure 6.2. Consider the
Figure 6.2: Two Bayesian networks related to the device EHS60/BE: one (on the
left) with duplicates and the other (on the right) without duplicates.
relationship between devices EHT1/BE, EHT2/BE and EHT3/BE. In
both networks, these devices are connected by the same edges, but
the probabilities on the inference labels are higher with the duplicates.
As we discussed in Section 4.1.3.1, making some correlations stronger
is one of the consequences of keeping the duplicates. However, there
is also the possibility that the network without duplicates is under-
representing such correlations. Either way, the strong correlations be-
tween these devices are evident in both cases.
Now focus on the devices ECE001/BE, EKD203/5E and EHD20/BE.
Again, they show the same relationship among them in both networks.
The diﬀerence is that now the inference values without duplicates are
104

always higher than the ones with duplicates. This means that most
likely the network with duplicates is weakening these correlations by
duplicating some rows and making some of these devices appear in
training rows alone, without correlations. Indeed, this very situation
happens between EHD20/BE and EKD203/5E and was shown in Fig-
ure 4.4 of Section 4.1.3.1.
6.3
The use of diﬀerent variable selection crite-
ria
Not all the criteria explained in Section 4.2.1 and Section 5.2.1 lead
to good models for all the timestamps sets T. For example, consider
the Bayesian network in Figure 6.3, built according to the reference
device ERD15*45 with priority L2. This network was generated by
choosing the devices with the highest number of occurrences. As the
ﬁgure shows, no relevant correlations were found, therefore the depen-
dencies between the nodes are not based on a high probability of the
simultaneous presence of the devices in the itemsets, but on the other
CPD values. For example, the inspection of the CPD shows us that
when ETZ755*43 is 0, ECC001*3 is almost always 0. All the other
correlations in the network are of the type 0 - 0 as well, which is the
pattern the Bayesian model is trying to reproduce with connections
between the nodes in ﬁgure. We may suppose that there are no regu-
lar correlations at all with respect to this reference device. However,
if we change variable selection method we may ﬁnd something inter-
esting. In Figure 6.4 we found a single correlation between devices
EBD1.01*50 and EBD1.09*50, using the conﬁdence variable selection
method. By selecting the devices that report more events within the
analysis window of ERD15*45 than in the rest of the log, we acciden-
tally found two devices with a low standard deviation and very similar
average. The number of occurrences is not very high, but the temporal
regularity of these events could be considered enough to suppose that
this correlation is valid.
105

Figure 6.3: Bayesian network of reference device ERD15*45, with priority L2 and
variable selection method based on the occurrences.
The next example shows the application of diﬀerent variable selec-
tion criteria for Markov chains. In Section 5.2.1 we have deﬁned the
close pairs criterion, which can be utilized exclusively for the Markov
chain model. We now show the Markov chain based on the reference
device EHS60/BE with priority L1 obtained with the close pairs cri-
terion (Figure 6.5), and we compare it to the one obtained with the
occurrences criterion (Figure 6.6). Both ﬁgures consider events hap-
pened not more than 5 minutes after the corresponding timestamp of
the reference device, and arcs with probability lower than 0.25 have
not been represented. These Markov chains, as well as all the others in
the rest of this section, have been generated using clustering for the se-
quences generation. The clustering method chosen is based as usual on
average plus standard deviation and the states of the network present
106

Figure 6.4: Bayesian network of reference device ERD15*45, with priority L2 and
variable selection method based on the conﬁdence.
the additional ﬁeld “tag”. For every state, the name of the device and
the value of the additional ﬁeld are separated by “--”.
We see that the close pairs criterion manages to ﬁnd interesting tran-
sitions probabilities that links the states EBS1/65 -- A15, EBS1/56 --
A30 and EBS1/56 -- A15. Those three devices are not selected by the
occurrences criterion because they all have only 11 occurrences. The
cycle related to the three states links similar tags and device names.
Both the tag values start with "A" followed by a number and the names
of the devices (EBS1/65 and EBS1/56) diﬀers only in their numerical
part. The more variables we choose to represent, the more these two
criteria give us similar networks, because the occurrences criterion in-
creasingly takes into account less frequent devices which could have
interesting patterns.
We have also said in Section 5.2.1 that the close pairs criterion gen-
erally creates networks where there are groups of devices highly related
among them, with little relation among states of the diﬀerent groups.
This is a consequence of the design and implementation of the crite-
rion. The eﬀect is not particularly visible in these two networks because
many states with variable names that starts with “EHH” are selected
107

Figure 6.5: Markov chain related to the device EHS60/BE with priority L1, with
states selected with the close pairs criterion and “tag” as additional ﬁeld.
by both criteria. The group of “EHH” devices with their tags have
many more occurrences compared to the other devices not selected by
the occurrences criterion. Even if there is not a strong pattern in their
consecutive appearances they manage to be at the top of the ranking of
pairs for the close pairs criterion. A possible solution to this problem
is discussed in Section 7.2, proposing a new way to rank pairs based
on conﬁdence.
We can spot in Figure 6.5 two distinct groups: the one with the states
EBS1/65 -- A15, EBS1/56 -- A30 and EBS1/56 -- A15, and the other
group composed of all the other devices. The latter group is not com-
pletely connected because we have set an high minimum threshold for
edge visualization (0.25).
108

Figure 6.6: Markov chain related to the device EHS60/BE with priority L1, with
states selected with the occurrences criterion and “tag” as additional ﬁeld.
Most of the networks shown up to this point describe what hap-
pens after the events of a reference device. It can also be useful to
analyze events happened right before a set of timestamps, to discover
which devices may have been responsible for an abnormal behaviour,
and Figure 6.7 is an example of such networks. It is based on a thresh-
old value equal to 0.33 and shows how Markov chains becomes more
and more disconnected as the threshold value increases; the result re-
sembles a collection of rules. The network has been generated with
the occurrences criterion by selecting a total of 150 states, with the
addition of the “tag” as additional ﬁeld. The probabilities shown in
this Markov chain are close to describe the real adjacency relations be-
tween consecutive rows in the log (as we anticipated in Section 5.1.2),
because of the huge number of variables considered in the analysis.
109

Figure 6.7: An extract of a Markov chain with 150 states, built on the events
before a set of given timestamps, with an analysis window of 5 minutes.
6.4
The use of diﬀerent additional ﬁelds
We have seen in Figures 6.5 and 6.6 that by considering the “tag” ﬁeld
we get more speciﬁc information that could let us understand better the
reasons behind the presence of some frequent transitions (in Markov
chains) or strong correlations (in Bayesian networks). A person who
knows how these devices work and what the codes in the “tag” ﬁeld
represent can possibly detect the problem, isolate it and solve it in
a faster way.
So we can say that the networks based on the “tag”
ﬁeld are more useful from the fault detection perspective with respect
to the networks based on the device name only. Until now we have
presented models based on device names and their “tag” ﬁeld, but our
implementation allows the use of diﬀerent additional ﬁelds.
In Figure 6.8 we show a Bayesian network based on the events after
110

the reference device EMC001*9 with the “level of priority” equal to L3,
which is the highest of our discretized priority levels. As we can notice
Figure 6.8: The Bayesian network of reference device EMC001*9 with priority
L3, no duplicates, the graphical postprocessing of the reference device and the
addition of the ﬁeld “level of priority”.
in the picture, the fact that we are considering reference events with
high priority does not necessarily mean that the events of the devices in
the network will have an high priority too. Most of the nodes, in fact,
have the lowest priority level (L0), while the nodes related to the same
device EBS11*12 has a medium chance (46%) to appear after an L3
event of EMC001*9 with priority L1 or L2. Independently by which of
the two priorities we see ﬁrst, we know (thanks to the inference labels)
that we could see the other with a probability of 93%.
We now show diﬀerent additional ﬁelds applied to the same set of
111

events on which the network in Figure 6.5 is based, and we comment the
results obtained from the use of these ﬁelds in Markov chain models.
Figure 6.9 is the ﬁrst variation of the network in Figure 6.5 that we
present. It is based on the additional ﬁeld “description” instead of “tag”.
We see that the structure of the network, the name of the devices
selected, and the probabilities on the edges have not changed. The
only diﬀerence is the name of the additional ﬁeld after the separator
“--”.
The nodes of this state diagram share the same behaviour of
the other corresponding nodes shown in Figures 6.5 and 6.9.
This
indicates that “description” and “tag” provide information at a similar
level of detail, at least in this case. In some of the “description” values
we can even see references to other device names, to corresponding
tags, or to voltage values. Description values usually give a semantic
interpretation to the tag values to which they are related to, and they
can help to understand better the scenario of the events happened if
we do not know the meaning of “tag” values. It even seems that there
exists a one to one correspondence between values of “description” and
“tag”, but we have then veriﬁed that it is not true in general. Diﬀerent
descriptions can correspond to a single tag and vice versa.
Figure 6.10 shows that the use of the “state” ﬁeld changes the network
structure. The occurrences of the states are higher than those of the
tags in Figure 6.5. For this reason and from the names of the states, we
can deduce that in this case the information provided by the “state”
ﬁeld is more general with respect to “description” and “tag”. In the
example in Figure 6.10, the “state” reports a generic “Fault” in almost
all the nodes, grouping together all the diﬀerent information provided
by “tag” and “description”, which explained in more detail the nature
of the fault for each device.
In Figure 6.11 we show the Markov chain based on the “level of priority”
as additional ﬁeld. We see that the networks in Figure 6.10 and Figure
6.11 share the same device names and occurrences. In this particular
case we have found a perfect correspondence between the “state” and
“level of priority” values, but, again, this is not true in general. The
112

Figure 6.9: Markov chain related to the device EHS60/BE with priority L1, with
states selected with the occurrences” criterion, with “description” as additional
ﬁeld.
possible values of the “level of priority” are only four, while “state” can
assume many more values.
113

Figure 6.10: Markov chain related to the device EHS60/BE with priority L1, with
states selected with the close pairs criterion and “state” as additional ﬁeld.
Figure 6.11: Markov chain related to the device EHS60/BE with priority L1, with
states selected with the close pairs criterion and “level of priority” as additional
ﬁeld.
114

6.5
The window of analysis
Often in this document we assumed a value of W equal to 5 minutes.
However, in general, there might not be a perfect length for the window.
An analysis can be repeated many times with multiple W values and
lead to diﬀerent valid conclusions. For example, there might be some
devices that are inﬂuenced by the anomaly happened at the timestamps
T only after an interval greater than 5 minutes; others might regularly
appear within 1 minute but they might not be chosen by the variable
selection method if the window is too large. Clearly, the eﬀectiveness of
the size of the window is also bound to the preprocessing and variable
selection technique chosen. For example, if our goal is to use temporal
criteria to ﬁnd devices that appear immediately after (or before) the
timestamps, we should keep W as small as possible to reduce the noise
(as mentioned in Section 4.2.1.3).
If we want to ﬁnd devices with
the highest number of occurrences, we can keep the window relatively
large since the variable ranking should not be excessively aﬀected by
the introduction of noise.
However, we should also be particularly
careful when enlarging the window because timestamps close to each
other may start to overlap, leading to more duplications of events.
Regarding the timestamps extracted from reference devices we no-
ticed that the distribution of data follows some regular patterns. After
a timestamp, most of the events are reported in the very ﬁrst min-
utes. With W of one or two minutes, ranking of variables may change
signiﬁcantly. Then, the more we increase the window, the more are
the chances that the number of events will start to stabilize. An image
with the trends of some of the devices utilized for our analysis is shown
in Figure 6.12. The graph shows on the vertical axis the number of
events reported after the timestamps of a reference device with pri-
ority L1, while on the horizontal axis there is the size of the window
W. Each line is related to a single reference device. The number of
events are calculated for every device exactly every minute, starting
from W = 1. As we can see in the graph, a good amount of events
are already reported in the ﬁrst minute. Most of the spikes tends to
115

Figure 6.12: A graph that puts in relation the number of events (after the
timestamps) with the dimension of the analysis window. This graph considers
only events of reference devices with priority L1.
happen before 5 minutes. One of these spikes, for example the one of
device EXS4/8X, happens between 3 and 4 minutes. For these devices,
setting increasingly larger values of W over 5 minutes should not pro-
vide much diﬀerent models. However, setting a value of W larger than
5 minutes does not seem a good idea by looking at the graph, since
it is more probable to include noise in the analysis than to consider
new interesting data. On the other hand, if we choose a low value of
W, we risk to leave out possible signiﬁcant correlations. The choice of
W = 5 is a good compromise in most cases because we reduce to the
minimum the possibility of ignoring relevant data, while managing to
116

keep a rather low the value of W.
The graph for events of reference devices with priority L2 is shown
in Figure 6.13. The graphs based on priority L1 and L2 of the ref-
Figure 6.13: A graph that puts in relation the number of events (after the
timestamps) with the dimension of the analysis window. This graph considers
only events of reference devices with priority L2.
erence devices present similar trends for most of the devices, apart
for EHS60/BE. We can even spot the same interesting spike of the
EXS4/8X trend between W = 3 and W = 4.
Even in this case,
W = 5 seems a good choice considering the general trend of all de-
vices. However for some speciﬁc devices, other values of W may be
more appropriated. We see that some devices stabilize their trends
sooner than 5 minutes, while the trends of EMC001*9, and in minor
117

part of EXS106/2X and ESS11/5H, continue to grow at a non negligi-
ble rate even after 9 minutes.
The situation before the timestamps extracted from a reference
device is similar. Figure 6.14 shows the graph for the number of events
before some reference devices with events of priority L1. The more
the analysis window size increases, the more we move further in the
past. At the value of minutes equal to 10 we are actually looking at
a correlation window of W = −10 minutes. As we can see, for W
Figure 6.14: A graph that puts in relation the number of events (before the
timestamps) with the dimension of the analysis window. This graph considers
only events of reference devices with priority L1.
around 5 minutes the number of events does not increase very much
anymore. Is not surprising that the highest number of events reported
118

is between 0 and -1 minutes, since we can suppose that immediately
before an important event of a reference device other events could have
been reported, maybe related to the same fault that caused the event
of the reference device in the ﬁrst place.
6.6
A comparison between models
As we discussed in Section 5.1.2, Markov chains could be used to dis-
cover the temporal order of activation of some variables that were found
to be correlated in a Bayesian network. In Figure 6.15 we show a direct
comparison between the two models, both generated on the same set V
of devices related to the reference device EXS106/2X with priority L1.
First of all, we notice that the general structure of the two networks
is similar. EBS1/22 acts as a point of separation between EBS132/2X
and the rest of the network. The devices that form a sequence of con-
nections between EBS1/22 and ESS10/1DX in the Bayesian network
are present also in the Markov chain, but there are transitions that
break the sequence by connecting them directly to EBS11/22. More-
over, the order of the devices in the sequence is not the same.
This is not a contradiction with respect to the Bayesian model results.
In fact, since the sequence in the Bayesian network is composed of
quite high inference label values, it is perfectly normal that a parent
node (like EBS1/22) may have a strong direct correlation (of the type
1-1) with a node that is not a direct child (like ESS10/1DX), which
explains why the same connections are present in the Markov chain
and why some nodes are swapped.
Moreover, this is also one of the main reasons why we do not see high
values of transition probabilities between devices that have high corre-
lations in the Bayesian network. The model on the left of Figure 6.15,
in fact, does not take the order of devices into consideration. While
looking at the Markov chain, instead, we discover such order and we re-
alize that devices between EBS1/22 and ESS10/1DX (in the Bayesian
network) do not always appear in that precise order, otherwise we
119

Figure 6.15: Two models related to the reference device EXS106/2X, with priority
L1. On the left, the Bayesian network (generated without duplicates). On the
right, the Markov chain (with visualization threshold set to 0.15).
would have seen a chain of devices having transitions with probabili-
ties equal to 1. Sometimes, the same device reports more events (for
example the device EBS1/28, that has a self-loop with probability 0.39)
or the chain restarts from EBS1/22 (see for example the transition be-
tween EBS1/28 and EBS1/22, or the transition between EXS311*80
and EBS1/22). All these factors cause the probability of transitions
between devices in the sequence to decrease and be much lower than
the inference labels.
120

In the previous discussion we often talked about a sequence of de-
vices, that is meaningful only in the Markov chain model. However,
we do not know from which device this chain can actually start. With
the addition of the reference device (in Figure 6.16) we discover this
information. We see that EBS1/22, which seemed a device that could
Figure 6.16: The Markov chain on the right of Figure 6.15 with the addition of
the reference device.
121

have started the chain, is actually almost never (6%) the ﬁrst after an
event of EXS106/2X with priority L1. Instead, we see that almost half
of the times EBS132/2X appears as ﬁrst, while EBS1/28 is the sec-
ond most likely (24%) device, which is also part of the chain between
EBS1/22 and EXS311*80. We also notice that EXS311*80 never ap-
pears as ﬁrst device after EXS106/2X, which means that its activation
could be caused by the devices in the network (like ESS11*13), and
not by EXS106/2X.
6.7
Networks with multiple reference device
In Section 4.1.1.1 we have introduced the possibility of extracting
timestamps from multiple reference devices, that also become the de-
vices in the set V that we see in our network. This technique is useful
when we want to focus the analysis on the relationship between a set
of devices, without any dependence from a single reference device or
arbitrary chosen timestamps. Consider the Bayesian network of the ref-
erence device EHS60/BE generated with the frequency criterion and
priority L1, shown in Figure 6.17. We notice that all devices in the
network appear after an event of priority L1 of EHS60/BE with proba-
bilities that range from 33% to 41%. We also see that the correlations
between nodes are very high. At this point we may wonder if such
correlations are valid only after EHS60/BE or they actually are inde-
pendent from the reference device. To ﬁnd out this, we select the ﬁve
variables of the Bayesian network as the multiple reference devices,
from which we extract the timestamp set T. Since we want to focus on
these devices only, we manually select them to compose the set V . We
consider events of all priority levels. Figure 6.18 shows the result of
this procedure. We notice that the network does not present any valid
correlation. So, it seems that the correlations between these devices
are not valid in general. The values of the inference labels that we see
in the network are really low, but not always equal to zero. This is not
a surprise, since we expect that the correlations found in Figure 6.17
122

Figure 6.17: The Bayesian network of the reference device EHS60/BE, generated
without duplicates, priority L1 and the frequency criterion.
should be found also with the multiple reference devices setting. In the
network based on multiple reference devices, however, the number of
occurrences of events that are not correlated is much higher than the
occurrences of correlated devices found also in the original network.
The diﬀerence in the number of occurrences explains the absence of
123

Figure 6.18: The Bayesian network generated from the multiple reference devices
in Figure 6.17, generated with no duplicates.
relevant correlations in Figure 6.18. If the networks in Figure 6.17 and
in Figure 6.18 were similar, even if based on a signiﬁcantly diﬀerent
amount of occurrences for the same devices, we would have concluded
that the presence of the reference device would not have been relevant
to describe the behaviour of the other variables of the network. Great
diﬀerences between those networks, instead, prove that the results in
Figure 6.17 are useful to describe what happens after the events of
“EHS60/BE” with priority L1, and that they don’t represent general
trends in the data that are also valid when “EHS60/BE” does not reg-
ister events in the log.
124

Chapter 7
Conclusions and future
development
In this chapter we wrap up the main conclusions of our work (in Section
7.1) and propose some improvements that could enhance the eﬀective-
ness of our analysis (in Section 7.2).
7.1
Conclusions
In this work we have shown how Bayesian networks and Markov chains
can be applied in a data-driven context to analyze and predict the
eﬀect of anomalies. Speciﬁcally, we have studied the relationship be-
tween the components of a complex electrical infrastructure, starting
from the events generated directly by these components. Diﬀerently
from most of the approaches to this topic, our models are not built
on the nominal behaviour of the system but on the anomalous events
that are reported on the system’s log. The ﬁrst and simplest model we
have introduced for this purpose is a Bayesian network with variables
based on the device names. Through our discussion in Section 4.2, we
realized that Bayesian networks can be useful to detect correlations
between devices but are not appropriate to reason about the temporal
causality of events. With the presentation of preprocessing techniques

and variable selection criteria, we have shown how the results of this
model can be generated to ﬁt the focus of our analysis. After testing
diﬀerent conﬁgurations we have drawn some conclusions. For exam-
ple, we found out that the networks based on tags and device names
are generally the most useful, in that they allow to gain much more
speciﬁc insights on the events occurred to the devices. The temporal
variable selection criteria, instead, is a good way to introduce temporal
constraints on the variables we show in the network.
However, to expand our tools and really take into account time and
sequentiality we introduced a second model, the Markov chains. This
new model naturally deals with the time dimension and allowed us to
extract information complementary to the ones found with Bayesian
networks, which can help to identify possible causes and consequences
in the correlations learned with Bayesian networks based on the same
devices and set of timestamps. The presentation of these two mod-
els followed a parallel structure, sharing many preprocessing, variable
selection, and postprocessing techniques, making it easier to compare
them.
A great eﬀort has been put to increase the quality of the data used
for the model learning, in order to create networks whose probabili-
ties were closest as possible to the real values. This explains the focus
on the preprocessing techniques like duplicate elimination for Bayesian
networks, device ﬁltering for Markov chains, and clustering for both
models.
The clarity of visualization of the generated models is an-
other recurrent theme of this work. Several post-processing options
have been developed in order to facilitate the extraction of the most
relevant information in a short time. Clear visualization capabilities,
however, come with a cost: we cannot select all the devices that could
be correlated, which is the reason why we had to develop criteria to
choose the most relevant subset of variables to analyze.
126

7.2
Future development
Many of the ideas applied in this work can be developed even further.
We have seen the beneﬁts obtained with a more speciﬁc representation
of variables based on the name of the device and additional ﬁelds like
“tag” or “description”. We could extend this representation also to the
reference device, which in our analysis was constrained to be a device
with events of a particular priority level. The choice of a reference
device based on tags instead of the level of priority seems a promising
approach. With this modiﬁcation, criteria based on temporal distance
and conﬁdence with respect to timestamps can hopefully ﬁnd even
more precise patterns.
The close pairs criterion for Markov chains showed a ﬁrst approach
based on the adjacency of variables in sequences, which is at the basis
of what determines the usefulness of the model generated. For this
reason, we believe it is worth to try diﬀerent approaches following this
direction. We have seen in Section 6.3 that the actual version of the
close pairs criterion is biased on the selection of devices with an high
number of occurrences. The ranking of the variables could be modi-
ﬁed applying the reasoning done for the conﬁdence criterion described
in Section 4.2.1.4 to the adjacent elements in Markov chains’ training
sequences. The close pairs criterion ranks the pairs on the basis of the
number of times they appear as consecutive in the training sequences.
If that number is divided by the number of occurrences of the ﬁrst
element of the pair, we would create a close pairs criterion based on
conﬁdence. It would search directly for all the highest values of tran-
sition probabilities and would select the devices which are sources or
destinations of the edges with the highest probability.
A threshold
value in order to consider only variables with a minimum number of
occurrences is needed to avoid a bias for less frequent variables, for the
same reasons explained for the conﬁdence criterion in Section 4.2.1.4.
A temporal approach for the selection of variables for Markov chains
based on the minimum average time of appearance between adjacent
devices in the training sequences can be tried too. Average, standard
127

deviation of time intervals, or the sum of both can be chosen as criteria
with the same advantages and disadvantages shown in Section 4.2.1.3
for Bayesian networks and the relation with the timestamps i. We can
call this criterion temporal close pairs.
Another promising direction of research for this problem regards
the change of the Boolean values currently used in the domain of vari-
ables in Bayesian networks. Instead of embedding an additional ﬁeld in
the variable name, as done in this work, it could be useful to represent
the nodes of the network always with the device names, and use the
values assumed by their additional ﬁelds as domains of the variables.
For example, a variable could assume 4 values that correspond to its
four diﬀerent tags reported in the log. Many advantages come with
this approach: it becomes possible to represent all the pairs of device
names and additional ﬁelds for every device considered for the analysis;
encoding the same amount of information in a Bayesian network with
a Boolean representation of values would take a much larger number
of nodes. The structure of the Bayesian networks learned could change
completely and the independence tests between the same devices could
give very diﬀerent results. With this new formalization of the prob-
lem, the complexity would be transferred to the CPD tables. A possible
disadvantage could be the increase of network complexity. The time
to learn the network structure may also increase when adding more
values in the domains, but at the same time we could be able to rep-
resent more information with less nodes, so further research is needed
to understand the performance loss or gain with respect to our current
representation.
However, it would be impossible to use inference labels for visualiza-
tion, since a lot of interesting probabilities could be found inside a
single CPD, and inference queries would become the only way to get
information from the model. Another problem is related to the num-
ber of samples for the pairs of devices and additional ﬁelds like tag or
description, as shown in Section 6.4. A way to cope with both prob-
lems of the CPD complexity and data samples is, assuming to consider
128

tags as additional ﬁeld values, to use the most frequent tags as values
for the variables, and to group all the other possible values with few
examples in a single value called “Other values”.
In this work, the analysis of the results of our models have been
done manually.
Correlations and inference must be performed on
Bayesian networks, while sequentiality and temporality must be ob-
served in Markov chains. An operator who wants to use these models
must have a minimum level of knowledge on how these techniques
work, or otherwise he/she might misinterpret the results. A possible
improvement in this sense is to create a framework that automatically
derives the consequences of an anomaly as soon as it happens, and that
integrates the results from our models (and possibly additional data
analysis) to give the operator information that do not depend by the
displayability and readability of the models.
129


Bibliography
[1] Machine
learning
and
data
mining
by
Pier
Luca
Lanzi.
http://www.lourenco.ws/
pier-luca-lanzi-follow-machine-learning-and-data-mining/
13-nearest-neighbor-and-bayesian-classifiers.
Accessed:
11-03-2018.
[2] Daphne Koller and Nir Friedman. Probabilistic graphical models:
principles and techniques. MIT press, 2009.
[3] Anders Tolver. An introduction to Markov chains. 2016. Depart-
ment of Mathematical Sciences, University of Copenhagen.
[4] Varun Chandola, Arindam Banerjee, and Vipin Kumar. Anomaly
detection: A survey. ACM Comput. Surv., 41(3):15:1–15:58, July
2009.
[5] Maurilio P. Coutinho, Germano Lambert-Torres, L.E.Borges
da Silva, HG. Martins, Horst Lazarek, and J. Cabral Neto.
Anomaly detection in power system control center critical infras-
tructures using rough classiﬁcation algorithm. In Proceedings of
the 3rd IEEE International Conference on Digital Ecosystems and
Technologies, DEST’09, pages 733–738. IEEE, 2009.
[6] Marco Martinelli, Enrico Tronci, Giovanni Dipoppa, and Clau-
dio Balducelli.
Electric power system anomaly detection using
neural networks. In Proceedings of the International Conference
on Knowledge-Based and Intelligent Information and Engineering
Systems, pages 1242–1248. Springer, 2004.
[7] Adnan Anwar and Abdun Naser Mahmood. Anomaly detection in
131

electric network database of smart grid: graph matching approach.
Electric Power Systems Research, 133:51–62, 2016.
[8] Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. Deeplog:
Anomaly detection and diagnosis from system logs through deep
learning. In Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security, CCS ’17, pages 1285–
1298, New York, NY, USA, 2017.
[9] Kevin Murphy.
A brief introduction to graphical models and
Bayesian networks.
https://www.cs.ubc.ca/~murphyk/Bayes/
bnintro.html#appl, 1998. Accessed: 11-03-2018.
[10] Zhiqiang Cai, Shudong Sun, Shubin Si, and Ning Wang. Research
of failure prediction Bayesian network model. In Proceedings of
the 2009 16th International Conference on Industrial Engineering
and Engineering Management, pages 2021–2025, Oct 2009.
[11] Dejan P. Jovanović and Philip K. Pollett. Distributed Fault Detec-
tion Using Consensus of Markov Chains, pages 85–105. Springer
Netherlands, Dordrecht, 2014.
[12] Abida Haque,
Alexandra DeLucia,
and Elisabeth Baseman.
Markov chain modeling for anomaly detection in high performance
computing system logs, 11 2017.
[13] Venkat Venkatasubramanian, Raghunathan Rengaswamy, Kewen
Yin, and Surya N. Kavuri. A review of process fault detection and
diagnosis: Part i: Quantitative model-based methods. Computers
Chemical Engineering, 27(3):293 – 311, 2003.
[14] Venkat Venkatasubramanian, Raghunathan Rengaswamy, and
Surya N. Kavuri. A review of process fault detection and diagno-
sis: Part ii: Qualitative models and search strategies. Computers
Chemical Engineering, 27(3):313 – 326, 2003.
[15] Hongyu Wang, Zuohua Tian, Songjiao Shi, and Zhenxin Weng.
Fault detection and isolation scheme based on parity space method
for discrete time-delay system. In Wei Zhang, editor, Fault Detec-
tion, chapter 5. InTech, 2010.
132

[16] Yiannis Papadopoulos. Model-based system monitoring and di-
agnosis of failures using statecharts and fault trees.
Reliability
Engineering System Safety, 81(3):325 – 341, 2003.
[17] William J. Puglia and Bahman Ateﬁ. Examination of issues re-
lated to the development and implementation of real-time opera-
tional safety monitoring tools in the nuclear power industry. Re-
liability Engineering System Safety, 49(2):189 – 199, 1995.
[18] Claire Palmer and Paul W.H. Chung. Verifying signed directed
graph models for process plants. Computers Chemical Engineer-
ing, 23:S391 – S394, 1999.
[19] Lioun Wee Chen and Mohammad Modarres. Hierarchical decision
process for fault administration. Computers Chemical Engineer-
ing, 16(5):425 – 448, 1992.
[20] Ole J. Mengshoel, Mark Chavira, Keith Cascio, Scott Poll, Adnan
Darwiche, and Serdar Uckun. Probabilistic model-based diagno-
sis: An electrical power system case study.
Proceedings of the
IEEE Transactions on Systems, Man, and Cybernetics - Part A:
Systems and Humans, 40(5):874–885, Sept 2010.
[21] Tarem Ahmed, Boris Oreshkin, and Mark Coates. Machine learn-
ing approaches to network anomaly detection. In Proceedings of
the 2Nd USENIX Workshop on Tackling Computer Systems Prob-
lems with Machine Learning Techniques, SYSML’07, pages 7:1–
7:6, Berkeley, CA, USA, 2007.
[22] Wil van der Aalst.
Process mining: Overview and opportuni-
ties.
ACM Transactions on Management Information Systems,
3(2):7:1–7:17, July 2012.
[23] Wil
van
der
Aalst,
Arya
Adriansyah,
Ana
Karla
Alves
de Medeiros, Franco Arcieri, Thomas Baier, Tobias Blickle, Ja-
gadeesh Chandra Bose, Peter van den Brand, Ronald Brandt-
jen, Joos Buijs, Andrea Burattin, Josep Carmona, Malu Castel-
lanos, Jan Claes, Jonathan Cook, Nicola Costantini, Francisco
Curbera, Ernesto Damiani, Massimiliano de Leoni, Pavlos Delias,
Boudewijn F. van Dongen, Marlon Dumas, Schahram Dustdar,
133

Dirk Fahland, Diogo R. Ferreira, Walid Gaaloul, Frank van Geﬀen,
Sukriti Goel, Christian Günther, Antonella Guzzo, Paul Harmon,
Arthur ter Hofstede, John Hoogland, Jon Espen Ingvaldsen, Koki
Kato, Rudolf Kuhn, Akhil Kumar, Marcello La Rosa, Fabrizio
Maggi, Donato Malerba, Ronny S. Mans, Alberto Manuel, Martin
McCreesh, Paola Mello, Jan Mendling, Marco Montali, Hamid R.
Motahari-Nezhad, Michael zur Muehlen, Jorge Munoz-Gama,
Luigi Pontieri, Joel Ribeiro, Anne Rozinat, Hugo Seguel Pérez,
Ricardo Seguel Pérez, Marcos Sepúlveda, Jim Sinur, Pnina Sof-
fer, Minseok Song, Alessandro Sperduti, Giovanni Stilo, Casper
Stoel, Keith Swenson, Maurizio Talamo, Wei Tan, Chris Turner,
Jan Vanthienen, George Varvaressos, Eric Verbeek, Marc Verdonk,
Roberto Vigo, Jianmin Wang, Barbara Weber, Matthias Weidlich,
Ton Weijters, Lijie Wen, Michael Westergaard, and Moe Wynn.
Process mining manifesto.
In Florian Daniel, Kamel Barkaoui,
and Schahram Dustdar, editors, Business Process Management
Workshops, pages 169–194, Berlin, Heidelberg, 2012. Springer.
[24] Fábio Bezerra, Jacques Wainer, and W. M. P. van der Aalst.
Anomaly detection using process mining. In Terry Halpin, John
Krogstie, Selmin Nurcan, Erik Proper, Rainer Schmidt, Pnina Sof-
fer, and Roland Ukor, editors, Enterprise, Business-Process and
Information Systems Modeling, pages 149–161, Berlin, Heidelberg,
2009. Springer.
[25] Boudewijn F. van Dongen, Ana Karla A. de Medeiros, Henricus
M. W. Verbeek, A. J. M. M. Weijters, and Wil M. P. van der Aalst.
The prom framework: A new era in process mining tool support.
In Gianfranco Ciardo and Philippe Darondeau, editors, Applica-
tions and Theory of Petri Nets 2005, pages 444–454, Berlin, Hei-
delberg, 2005. Springer.
[26] Luis M. de Campos.
A scoring function for learning Bayesian
networks based on mutual information and conditional indepen-
dence tests.
Journal of Machine Learning Research, (7):2149–
2187, 2006.
134

[27] Ron Kenett. Applications of Bayesian networks. 10 2012. Nea-
man Institute for National Policy Research, the Technion; Insti-
tute for Drug Research, School of Pharmacy, Hebrew University.
[28] Philippe Weber, Gabriela Medina-Oliva, Christophe. Simon, and
Benoit Iung. Overview on Bayesian networks applications for de-
pendability, risk analysis and maintenance areas. Engineering Ap-
plications of Artiﬁcial Intelligence, 25(4):671–682, June 2012.
[29] Brett Drury, Jorge Valverde-Rebaza, Maria-Fernanda Moura, and
Alneu de Andrade Lopes. A survey of the applications of Bayesian
networks in agriculture. Engineering Applications of Artiﬁcial In-
telligence, 65:29 – 42, 2017.
[30] Baoping Cai, Lei Huang, and Min Xie.
Bayesian networks in
fault diagnosis.
IEEE Transactions on Industrial Informatics,
13(5):2227–2240, Oct 2017.
[31] Jinqiu Hu, Laibin Zhang, Zhansheng Cai, Yu Wang, and Anqi
Wang. Fault propagation behavior study and root cause reasoning
with dynamic Bayesian network based framework. Process Safety
and Environmental Protection, 97:25 – 36, 2015.
[32] M. Nyberg. Failure propagation modeling for safety analysis using
causal bayesian networks.
In 2013 Conference on Control and
Fault-Tolerant Systems (SysTol), pages 91–97, Oct 2013.
[33] Philipp Von Hilgers and Amy N Langville. The ﬁve greatest ap-
plications of markov chains. In Proceedings of the Markov An-
niversary Meeting, Boston Press, Boston, MA. Citeseer, 2006.
[34] Prerna Rai and Arvind Lal. Google pagerank algorithm: Markov
chain model and hidden markov model. International Journal of
Computer Applications, 138(9):9–13, 2016.
[35] Nong Ye. A markov chain model of temporal behavior for anomaly
detection. In In Proceedings of the 2000 IEEE Workshop on In-
formation Assurance and Security, pages 171–174, 2000.
[36] Wil Van der Aalst, Ton Weijters, and Laura Maruster.
Work-
ﬂow mining: Discovering process models from event logs. IEEE
135

Transactions on Knowledge and Data Engineering, 16(9):1128–
1142, 2004.
[37] Dion H. Goh and Rebecca P. Ang. An introduction to association
rule mining: An application in counseling and help-seeking be-
havior of adolescents. Behavior Research Methods, 39(2):259–266,
May 2007.
[38] Classiﬁcation
rules
-
slide
by
professor
Pier
Luca
Lanzi.
https://www.slideshare.net/pierluca.lanzi/
machine-learning-and-data-mining-12-classification-rules.
Accessed: 18-03-2018.
[39] Wei Shen, Jianyong Wang, and Jiawei Han. Sequential Pattern
Mining, pages 261–282. Springer International Publishing, Cham,
2014.
[40] Pgmpy 0.1.2 documentation. http://pgmpy.org/. Accessed: 18-
03-2018.
[41] Pomegranate’s
documentation.
http://pomegranate.
readthedocs.io/en/latest/MarkovChain.html.
Accessed:
18-03-2018.
[42] Graphviz’s oﬃcial website.
http://www.graphviz.org/.
Ac-
cessed: 18-03-2018.
[43] Scikit-learn’s oﬃcial website.
http://scikit-learn.org.
Ac-
cessed: 18-03-2018.
[44] Yizong Cheng.
Mean shift, mode seeking, and clustering.
IEEE transactions on pattern analysis and machine intelligence,
17(8):790–799, 1995.
[45] Mean shift clustering.
http://homepages.inf.ed.ac.uk/rbf/
CVonline/LOCAL_COPIES/TUZEL1/MeanShift.pdf. Accessed: 20-
03-2018.
[46] Dbscan:
Density-based spatial clustering of applications with
noise.
http://www.cs.fsu.edu/~ackerman/CIS5930/notes/
DBSCAN.pdf. Accessed: 19-03-2018.
136

