Adaptive Behavior
Article
Adaptive Behavior
2023, Vol. 31(1) 35–49
© The Author(s) 2022
Article reuse guidelines:
sagepub.com/journals-permissions
DOI: 10.1177/10597123211066155
journals.sagepub.com/home/adb
Self-organisation, (M, R)–systems and
enactive cognitive science
Tomasz Korbak1,2
Abstract
The notion of self-organisation plays a major role in enactive cognitive science. In this paper, I review several formal models
of self-organisation that various approaches in modern cognitive science rely upon. I then focus on Rosen’s account of self-
organisation as closure to efﬁcient cause and his argument that models of systems closed to efﬁcient cause – (M, R)
systems – are uncomputable. Despite being sometimes relied on by enactivists this argument is problematic it rests on
assumptions unacceptable for enactivists: that living systems can be modelled as time-invariant and material-independent. I
then argue that there exists a simple and philosophically appealing reparametrisation of (M, R)–systems that accounts for
the temporal dimensions of life but renders Rosen’s argument invalid.
Keywords
Self-organisation, relational biology, closure to efﬁcient cause, enactivism, Markov blankets
Handling Editor: Matthew Egbert, University of Auckland, New Zealand
The notion of self-organisation plays a major role in en-
active cognitive science. In this paper, I review several
formal models of self-organisation that various approaches
in modern cognitive science rely upon. I then focus on
Rosen’s account of self-organization as closure to efﬁcient
cause and his argument that models of systems closed to
efﬁcient cause – (M, R)–systems – are uncomputable.
Despite being sometimes relied on by enactivists (e.g.
(Thompson 2010)), this argument is problematic as it rests
on assumptions unacceptable for enactivists: that living
systems can be modelled as time-invariant and material-
independent. I then argue that there exists a simple and
philosophically appealing reparametrisation of (M, R)–
systems that accounts for the temporal dimensions of life
but renders Rosen’s argument invalid. While Rosen’s ar-
gument has received valid criticism before (e.g. (Gatherer
and Galpin 2013; Palmer et al. 2016)), I present an attack
motivated by the philosophical principles of enactive and
dynamical systems cognitive science itself: relation biology,
Rosen’s modelling approach, in incongruent with dynam-
ical and enactivist concern about temporal, path-dependent
unfolding and embodiment. My attack exposes and obvious
but surprisingly overlooked disregard for those dimensions
in relational biology. Furthermore, my discussion hopefully
provides additional insights about the relation between (M,
R)–systems and other accounts in theoretical biology and
cognitive science such as the dynamical systems approach
(Kelso 1995) and the free energy principle (Friston 2013).
The paper is structured as follows. In the ﬁrst section, I
review several conceptual models of self-organisation and
argue that an account of self-organisation as second-order
feedback uniﬁes them in a relatively non-controversial
manner. In the second section, I review the role played
by these conceptual models of self-organization in various
approaches in cognitive science. I argue that enactive
cognitive scientists frequently require self-organisation to
play an explanatory role similar to the roles computation-
alists philosophers of cognitive science ascribe to repre-
sentation. In the third section, I present in more detail
Rosen’s relational biology and his account of self-
organisation as closure to efﬁcient cause. I then formu-
late his argument that models of systems closed to efﬁcient
cause – (M, R)–systems – are uncomputable. In the fourth
section, I provide more historical context to Rosen’s ar-
gument and the inﬂuence his argument and his way of
thinking about living systems had on modern enactivism.
Finally, in the ﬁfth section I point out a deep, irreconcilable
tension in Rosen’s argument and his relational biology in
1Institute of Philosophy and Sociology, Polish Academy of Sciences,
Warszawa, Poland
2Department of Informatics, University of Sussex, Falmer, UK
Corresponding author:
Tomasz Korbak, Department of Informatics, University of Sussex,
Brighton, Falmer BN1 9RH, UK.
Email: tomasz.korbak@gmail.com

general: is fails to account for the temporal nature of life.
If one assumes living systems to be dynamical systems (as
modern enactivists do), the argument turns out to be invalid
in a trivial way. Therefore, it should be rejected. I end the
paper with some general remarks about the uses and misuses
of formal limitative results in philosophy.
Formal models of self-organisation
Self-organisation is among the basic notions of modern
systems biology (Bechtel 2007; Hofmeyr 2007). Despite
being invoked extensively by the cybernetic grandfathers of
cognitive science (McCulloch and Pitts 1943; Ashby 1947),
serious philosophical arguments casting self-organisation as
an explanans for cognitive science started only with the
advent of dynamicism (Port and Van Gelder 1995) and
enactivism (Varela et al. 1974; Thompson 2010). Intuitively,
self-organisation is usually understood as spontaneous
change in organisation of a system or the emergence of
novel constraints on the dynamics of a system. There is,
however, no single agreed upon deﬁnition of self-
organisation, which prompts some philosophers to treat-
ing it not as a natural kind but acknowledging the existence
of multiple concepts of self-organisation linked by family
resemblance (Collier 2004).
I will start with seven different conceptual models of self-
organisation. The list below is a list of conceptual models
(Barandiaran and Chemero 2009) or holistic models
(Downey 2018), that is: formalising an idea without a
pretence of empirical validity with respect to any class
of empirical phenomena. Conceptual models should
not be confused with generic models (describing the
rules governing certain class of phenomena), functional
models (maintaining functional validity) or mechanistic
models (maintaining a mapping between observables
and variables in the model). However, the usefulness of
such a model guides the evaluation of empirical and
heuristic validity of conceptual models. Moreover, here
I focus on inﬂuential historical models, delaying the
discussion of their modern incarnations to the next
section.
(A1) Ashby’s homeostat, a mechanical model of the brain as
a self-organising dynamical system, was an aftermath
of the ﬁrst modern and formal notion of a self-
organising dynamical system endowed with an at-
tractor in its phase space (Ashby 1947). This model was
one of the cornerstones of cybernetics (Wiener 2019)
and started thinking about self-organisation as an ad-
vanced form of regulation.
(A2) Dissipative structures in non-equilibrium thermody-
namics, which maintain low entropy and stable steady
state due to exchanging energy with the environment.
The thermodynamic model of dissipative structure
was proposed by Nicolis and Prigogine (1977). It is
a model of simple chemical oscillation (such as
Belousov–Zhabotinsky reaction or Rayleigh–B´enard
convection) but can also be treated as a minimal
thermodynamic model of a living system.
(A3) McCulloch and Pitts’s (1943) model of recurrent
neural networks based on Boolean gates. It was the
ﬁrst attempt of a computational explanation of cog-
nitive processes (Piccinini 2004) by designing a
propositional calculus in which a neural event can be
represented by a proposition about temporal ante-
cedents of the neural event. Kleene (1956) has later
shown that the formal model presented by McCulloch
and Pitts is equivalent to ﬁnite state automata. A
crucial property of this model is the ability to rep-
resent network with closed loops, which generate
self-sustaining neural activity. As such, it was a
predecessor of Hebbian learning.
(A4) Varela and Maturana’s model of an autopoietic system
(Varela et al. 1974; Maturana and Varela 1980). As a
minimal model of a living system, an autopoietic system
is characterised by two conditions (i) possessing a spatial
boundary and (ii) possessing a network of mutually
sustaining processes. This model was a cornerstone
of research in artiﬁcial life (Froese and Ziemke 2009)
and was widely discussed in cognitive science as
determining the necessary (and, according to some,
sufﬁcient) conditions of being a cognitive system
(Thompson 2010).
(A5) Rosen’s (1991) model of a system closed to efﬁcient
cause. Closure to efﬁcient cause is feature of relational
models, that is, models composed of morphisms in the
category theoretic sense. A relational model is closed
to efﬁcient cause if every morphism included in the
model is an endpoint of another morphism in the
model. An obvious biological interpretation of this
formal model is metabolic activity of a living system,
autonomously sustaining crucial processes. The re-
lational way of thinking about life and understanding
of self-organisation in terms of closure to efﬁcient
cause turned out to be very inﬂuential in modern
systems biology (Bechtel 2007; Hofmeyr 2007).
(A6) Kauffman’s (1969; 1993) model of autocatalytic
networks. Using random Boolean networks, Kauff-
man has shown that for a sufﬁciently large number of
catalytic dependencies, stable and self-sustaining
cycles will arise. This allows for formal modelling
of autocatalysis, a primary mechanism for meta-
bolism and gene expression regulation.
(A7) Dynamical systems theory is an umbrella term for a
family of related approaches, including bifurcation
theory, fractal geometry and ergodic theory. One
philosophically inﬂuential model was Bak et al.’s
(1987)
concept
of
self-organising
criticality:
a
36
Adaptive Behavior 31(1)

phenomenon arising in dynamical systems with at-
tractors that are a critical state (a state such that an
inﬁnitesimal change in some parameter causes a large
change in the dynamics). Self-organising criticality
can be applied to model multiple physical and bi-
ological systems. Other curious phenomena studied
through the lens of dynamical systems include
chaos, invariance and metastability.
(A8) G´anti’s (2003) chemoton is a minimal model of a
protocell that continuously sustains three processes:
metabolism, self-replication and a boundary (a bi-
lipid cell membrane). Originally formulated in 1971,
it shares many principles with (A2) and (A6): the
focus on thermodynamic openness (with (A2)) and
on the role of autocatalytic networks of chemical
reactions (with (A6)). In contrast with these
models and similarly to (A5), G´anti’s account also
focused on modelling self-replication (ﬁssion of
protocells).
What are the common traits of models (A1)–(A8)? Do
they all denote the same class of systems? There seems to be
one fundamental distinction between different kinds of
self-organisation, sometimes cast as a difference be-
tween self-organisation and self-assembly. It seems that
there are some phenomena that can maintain a steady
state through feedback, but lack resilience, that is, ‘the
ability to recover from perturbation; the ability to re-
store or repair or bounce back after a change due to
an outside force’ (Meadows 2008). Such phenomena
include crystals, tornados, B´enard cells and candle
ﬂames. They would instantiate model (A2) and prob-
ably also models (A3) and (A7). Other accounts of self-
organisation – those requiring resilience, such as (A1)
and (A4)–(A6) – would rule them out. This distinction
reappears multiple times in the literature with little
consistency in terminology. For instance, Friston and
Stephan (2007) distinguish self-organising systems
(like normal snowﬂakes) and adaptive systems (like
imaginary snowﬂakes endowed with wings, able to
avoid melting – a phase transition). In a similar vein,
Bickhard (2009) distinguishes self-maintenant systems
(like a candle ﬂame maintaining combustion threshold
temperature and inducing convection, which brings
fresh oxygen) and recursively self-maintenant systems
(that maintain self-maintenance). Furthermore, en-
activists distinguish autonomous systems as those ‘com-
posed of processes that generate and sustain that system as
a unit’ Thompson (2010). It is not a coincidence that the
distinction between self-assembly (self-organisation in the
weak sense) and self-organisation in the stronger sense
mirrors the distinction between self-organisation in non-
living systems and biological self-organisation. In the rest
of the paper, by ‘self-organisation’ I will mean the stronger
sense of the notion, reserving ‘self-assembly’ for self-
organisation in non-living systems.
I am not going to assume a speciﬁc formal model of self-
organisation. For the purpose of this paper, I will assume a
broad, substrate-independent account of self-organisation as
second-order feedback or multi-level constraining. These
are two complementary views of on what distinguishes self-
organisation from self-assembly. According to the ﬁrst
view, there must be at least two nested feedback loops in the
system operating on distinct time-scales: one accounting for
adaptability to changing conditions and the second ac-
counting for resilience. As an example, consider a senso-
rimotor loop of a bacterium embedded in a loop of its
metabolism. An alternative way of capturing this notion is to
say that self-organisation happens when entities from mi-
croscopic level of description of a system impose con-
straints on the dynamics of macroscopic level of description
(Pattee 2012; Ra˛czaszek-Leonardi 2012).
Self-organisation in cognitive science
Models (A1)–(A8) are formal models of biological and
physical phenomena and lack immediate connections to
cognitive models. However, if they are adequate models of
biological phenomena, then – assuming that cognition is
embodied (Bechtel and Mundale 1999) or that there is a
deep continuity between life and mind (Thompson 2010) –
they should be adequate to describe at least some aspects of
cognition.
(B1) Dynamicism. This paradigm was shaped in opposition
to the symbolic approach in cognitive science and
attempts at building explanations of cognition in terms
of dynamical systems theory, focusing on the temporal
and situated character of cognition. The cornerstones
of dynamicism are Smith and Thelen (2003), Kelso
(1995), Buhrmann et al. (2013) and Chemero (2009).
Dynamicism draws mainly from (A7), although
Chemero and Turvey (2008) explicate the notion of
sensorimotor loop and affordances in terms of Rosen’s
(1991) model (A5), and cybernetics (A1) is an im-
portant frame of reference for dynamically oriented
behavioural roboticists (Beer 1990).
(B2) Neurodynamics. This approach arose from research on
electrophysiology of the brain and explores the notions
of synchrony and desynchronisations as its main ex-
planantia (Skarda and Freeman 1987; Kelso 1995;
Freeman 2000). It employs mainly (A7) but also (A1)
and (A3).
(B3) Autopoietic enactivism started out from the bio-
logical model of autopoiesis (A4), trying to account
for cognition in terms of metabolism (Varela et al.
1974). Later sense-making has become the central
notion, which – in addition to autopoiesis – requires
Korbak
37

adaptivity (Thompson and Stapleton 2009; Thompson
2010). Finally, recently, autopoietic enactivists stress
that cognitive systems are essentially precarious and
interactive, which entails material and energetic
openness (Ruiz-Mirazo and Moreno 2004; Barandiaran
and Moreno 2008).
(B4) Active inference is an approach in computational
neuroscience and artiﬁcial intelligence. It assumes
cognitive systems are prediction machines employing
probabilistic models of them and their environments
and trying to minimise prediction errors of these
models via perceptual inference, action or learning.
The mathematical structure of this model is inspired
by (A1), (A2), (A4) and (A7) (Friston 2013; Clark
2016; Buckley et al. 2017).
Most approaches in cognitive science that build on the
concept of self-organisation, such as sensorimotor en-
activism (O’Regan and No¨e 2001), autopoietic en-
activism (Thompson 2010), neurodynamics (Freeman
2000) and radical embodied cognitive science (Chemero
2009), distance themselves from computationalism and
representationalism. Chemero (2009) claims that self-
organisation is a notion able to replace the computa-
tionalist notion of planning and model a cognitive
system as ‘regular but not regulated’. This regularity
would be due to self-organisation (here in the sense of
(A2) (Chemero 2008, pp. 274–275). Indeed, in many
biological contexts, self-organisation does a good job
replacing global control with full information about the
system (a classical example may be ants following a
pheromone trail (Mitchell 2011) instead of computa-
tional mapping, planning and localisation).
One could ask whether there could be a computationalist
or mechanistic account of self-organisation. The earliest
cybernetics models (A1) and (A3) seem to be exactly that.
Historically, however, arguments against mechanism in
philosophy of biology were based on notions similar to self-
organisation (such as epigenesis, homeostasis, feedback,
closure to efﬁcient cause or endogenous activity, cf.
(Huneman 2007)). To analyse this apparent disconnect
between mechanistic and non-mechanistic accounts of self-
organisation in more detail, in the rest of the paper, I will
focus on Rosen’s model (A5) and his argument against
mechanism based upon this model. This argument received
some interest in cognitive science in dynamicist (B1) and
enactivit (B3) circles (Thompson 2010; Nasuto and Hayashi
2016) but on a closer look reveals problematic assumptions
that are in strike contrast with (B1) and (B3), namely:
substrate-independence and ahistoricity of living systems.
This exempliﬁes the more general problem of how to
reconcile the teleological (usually rendered as atemporal)
and the historical (inherently time-ordered) aspects of self-
organisation in a single model. Rosen’s concept of efﬁcient
causation (to be introduced in the following section) is
designed to capture the teleology but fails to capture the
temporal character of living systems, fundamental to (A1). I
will argue, however, that it is not a general fact about
self-organisation that it implies ahistoricity but a
property of a particular modelling approach (A5). This
case study should reveal a surprisingly intricate rela-
tionship between formal models of self-organisation in
theoretical biology (A1)–(A8) and recent approaches in
cognitive science (A1)–(B4). In particular, (A5) violates
the premises of (B1) and (B3) that frequently build on
(A5). The implication of my criticism is that (A5) as a
formal model of self-organisation does not live up to the
requirements posed by modern enactive and dynamical
systems cognitive science while other models, such as
(A1) or (A7), do.
Rosen’s argument
Overview
Robert Rosen famously claimed that living systems are not
Turing-computable (e.g. (Rosen 2000, p. 325)). Based on
category theory, he developed relational biology, an original
formal framework for modelling the organisational properties
of life and provided a formal argument that a peculiar property
manifested by living systems – closure to efﬁcient cause –
prevents them from being simulable by a Turing machine.
Thus, life cannot be accounted for mechanistically, but only
within some theory richer than contemporary physics.
The structure of Rosen’s argument is as follows:
·
(T1) All living systems manifest the property of
closure to efﬁcient cause.
·
(T2) If a system is closed to efﬁcient cause, at least
some of its models are not Turing-computable.
·
(T3) If mechanism concerning biology is true, every
model of a living system can be simulated on a Turing
machine.
·
(T4) Therefore, mechanism is false.
Let us now discuss each premise (T1)–(T3) separately.
(T1), though very non-trivial, is now considered Rosen’s
crucial contribution to mainstream biology and was recently
found valuable in systems biology (Hofmeyr 2007). The
concept of closure to efﬁcient cause is to be understood in
terms of Rosen’s relational models which is discussed in the
next section.
The premise (T2) is the heart of Rosen’s argument. Rosen
claimed
that
‘organisms
possess
noncomputable,
un-
formalizable models’ (Rosen 2000, p. 4) and that ‘any material
realization of the (M, R)–systems must have noncomputable
models’ (Rosen 2000, p. 269). A crucial distinction here is the
one
between
simulation
and
modelling.
For
Rosen,
38
Adaptive Behavior 31(1)

‘simulation’ denotes a formalization of a mathematical system
of interest allowing determining the truth or falsity of certain
facts about the system in a ﬁnite number of steps. More
formally, ‘Simulability, is property of a mathematical system,
pertaining to the replacement of semantics (external referents)
by syntax’ (Rosen 1993, p. 370). Turing machines – the
dominant model of computation in theoretical computer sci-
ence (Turing 1937) – are one of the systems which allow for
formalizing the notion of simulability. One can simulate a
system if there is a Turing machine that can decide the truth or
falsity of some claims about the systems. On the other hand,
‘modelling’ is a broader term denoting a relation of corre-
spondence or homomorphism between an external system and
a representation thereof (Rosen 2000, p. 49). Therefore, only
some models are simulable. The important claim that Rosen
puts forward is that there will be facts about living systems that
cannot be simulated (because of some of their properties –
closure to efﬁcient cause – cannot be simulated) but can be
modelled. Therefore, some models of living systems (e.g. (M,
R)–systems) will not be simulable and, in consequence, Tu-
ring-computable.
(T3) is Rosen’s deﬁnition of a mechanism (a class of
phenomena) and of mechanism (a philosophical claim).
Rosen understands mechanism (the claim) by analogy to the
Church-Turing thesis (Copeland 2020), a hypothesis about
the nature of computable functions stating that a function
can be effectively calculated by a method if and only if it is
computable by a Turing machine. This leads to his deﬁnition
of a mechanism (a class of phenomena): ‘Let us call a
system satisfying Church’s Thesis (i.e., such that every
model is simulable) a simple system or mechanism’ (Rosen
1993, p. 370). Elsewhere, Rosen states that:
‘[t]he idea that every model of a material system must be
simulable or computable is at least tacitly regarded in most
quarters as synonymous with science itself; it is a material
version of Church’s Thesis (i.e., effective means computable).
[…] I call a material system with only computable models a
simple system, or mechanism. A system that is not simple in this
sense I call complex. A complex system must thus have
noncomputable models’ (Rosen 1993, p. 325; emphasis
original).
Rosen account of mechanism (the claim) seems to be
roughly compatible with modern concepts of mechanism.
For instance, according to Bechtel and Abrahamsen (2005).
a mechanism is ‘a structure performing a function in virtue
of its components parts, component operations, and their
organization. The orchestrated functioning of the mecha-
nism is responsible for one or more phenomena’. Though
Rosen’s notion of simulability is conceptually different
from the notion of mechanism, it seems to be at least a fair
operationalisation of the latter. Krajewski (2020) provides
a brief discussion of the interrelations between these
concepts.
Let us now sup up the argument. (T1) and (T2) jointly
imply that at least some models of living systems are not
Turing computable. This, in conjunction with (T3), implies
that (T4) mechanism is false. In the rest of the paper, I will
focus on the most controversial premise, namely, (T2).
Following others (Gatherer and Galpin 2013; Palmer et al.
2016), I will show that closure to efﬁcient cause does not
imply existence of non-simulable models. Before that,
however, I will spend more time explicating (T1) and
presenting in more detail the concept of closure to efﬁcient
cause and the broader framework in which it is deﬁned,
relation biology.
Category theory
Relational modelling is introduced as an alternative to the
‘reductionist account inherited from Newton’ (Rosen 1991,
p. 117), which generally means all state-space-based models
with some recursively deﬁned transition function. A
mechanistic (reductionist) model aggregates constituent
particle and provides empirically guided description of law
governing the interactions of these. Or, to put in bluntly:
‘In empirical terms, then, the very ﬁrst step in the analysis of an
organized system (e.g. our cell) is to destroy that organization.
That is, we kill the cell, sonicate it, osmotically rupture it, or do
some other drastic thing to it’. (Rosen 1991, p. 118)
Importantly, Rosen rejects a particular mode of scientiﬁc
explanation rather than scientiﬁc knowledge altogether. It is
the relational framework that can be seen as a blueprint for
some ideal, richer physics to be developed in the future – a
theory that could account for self-organising living systems.
While a mechanistic (reductionist) model aggregates con-
stituent particles and provides an empirically guided but
organization-insensitive description of laws governing the
interactions of these, a relational model focuses instead on
the organisational level of a system in question.
According to Rosen, relational models are built of
components, instead than particles, where component is to
be singled out functionally, in terms of its role in the model.
What is more, they can acquire novel (emergent) properties
in the context of a system, unlike particles in reductionist
models. Formally, a component is to be understood as a
mapping
f : A →B
While a mapping is often thought as a binary relation,
Rosen notes (1991, p. 221) that this formula actually
consists of four ingredients:
Korbak
39

·
A is the domain of the mapping;
·
B is the range of the mapping;
·
f is the name of the mapping;
·
→is the name of a ternary relation between f, A and B.
The inﬂuence on the system in which component f is
embedded is here expressed in speciﬁc arguments in the
domain A. Larger relational models can be built through
mapping composition, for example, f◦g. Moreover, since a
mapping can be easily interpreted extensionally as a set of
ordered pairs in the form (argument and value), one can
deﬁne a mapping whose output is another mapping. Let
denote the set of mappings from A to B. Thus, we can deﬁne
a mapping f◦ψ composed of
f : X →Y
and
ψ : Y →HðX,YÞ
Note, however, that this time f 2 HðX,YÞ, that is f is
part of the output of ψ. Diagrammatically, we will express
this on Figure 1.
We now see that a graph representation of a relational
model can contain cycles.
Rosen grounds his relational biology in category
theory – which can be seen as a general mathematical theory
of structures and systems of structures, and – possibly –
providing an alternate (to set theory) way of formalising the
foundations of mathematics (Marquis 2008).1 A category is
traditionally deﬁned as consisting of a class of objects O, and
a class of morphisms (mappings and arrows) M between
objects of O, such that for every object there exists an identity
morphism, and for every two morphisms there exists a
composition of these (i.e. morphisms are associative). Sets
and mappings between sets trivially meet these requirements,
but it should be noted that they are also met by ordered sets
and monotonous mappings, groups and group homomor-
phisms, vector spaces and linear transformations, as well as
topological spaces and continuous functions (and so on).
The concept of a mapping on which relational biology is
grounded is precisely the category-theoretic concept of
morphism. Therefore, Rosen’s argument, if it is sound, is
general enough to encompass all kinds of mathematical
structures (and formal or computational models). On the
other hand, the reader may ﬁnd Rosen’s argument more
comprehensible when understanding it in terms of ZFC set
theory; no signiﬁcant loose in generality will take place. For
instance, Chemero and Turvey (2008) use hypersets and
mappings between them to explicate the concept of closure
to efﬁcient cause. Hyperset theory is a variant of set theory
where the axiom of regularity is substituted with its ne-
gation; thus, there exists a set V such it is itself its only
element, that is, V = {V}. However, the work of Chemero
and Turvey has received valid criticism from other authors,
for example (C´ardenas et al. 2010). In particular, Chemero
and Turvey’s account of closure does not include an output
of a self-organising system: it only receives environmental
input, but nothing comes out of it. According to C´ardenas
et al. (2010), this clearly ‘violates the law of conservation of
matter, because the […] cycle is a bottomless pit into which
all the reactants disappear, with nothing coming out’. This
failure exempliﬁes a fundamental property of living
systems – thermodynamic and material openness – which is
indeed a major shortcomings of many purely physical
models of living systems. As I will explain later, Rosen’s
relational biology sidesteps that problem.
Causation in relational models
Before elucidating what it takes for a relational model to be
closed to efﬁcient cause, it is reasonable to ponder how
Rosen’s formal models are to be interpreted in the biological
domain. Rosen wrote surprisingly little on what biological
entities mappings correspond to. Hofmeyr (2007), though,
provides an elegant biochemical interpretation in terms of
metabolic pathways. On this account, a mapping f: A →B
corresponds to a chemical reaction, with A being a reagent,
B being a product and f itself being an enzyme catalysing the
reaction. Since enzyme can itself be a product, the system
depicted in Figure 1 can easily be interpreted as a simple
catalytic cycle, an instance of a paradigmatic class of
mechanisms in biochemistry. Kauffman’s (1969) model
(A3) presents an account or the origins of life in terms of
autocatalytic networks very much in the vein of this
interpretation.)
An important feature of relational models is that the
notion of ﬁnal cause can be expressed relationally. This is
supposed to be unlike state-space-based models, with time
as their independent variable; since these are time-
asymmetric, the effect must always precede the cause.
This constraint is not present in time-invariant relational
models, which therefore support multiple modes of cau-
sation very much in the vein of Aristotle’s doctrine of four
causes. Let us get back to the Figure 1 and ponder the
question ‘why Y?’. According to Rosen, there are three
answers: Y’s material cause is X, Y’s efﬁcient cause is f and
Y’s ﬁnal cause is H (X, Y). (In the current setting, Aristotle’s
Figure 1. While solid arrow as previously indicates a mapping,
dotted arrow represents that f 2 HðX,YÞ, that is, f ¼ ψðyÞ for
some ψ 2 Y. This corresponds to the relations of material
causation and efﬁcient causation, respectively.
40
Adaptive Behavior 31(1)

formal cause is identical with efﬁcient cause, although
Hofmeyr (2007) proposes the information encoded in
mRNA to be interpreted as a formal cause for given a bi-
ological structure and presents a formalisation of this
account.)
While relational models indeed provide an interesting
approach to biological functions that recently gains atten-
tion in systems biology, it is highly disputable that tele-
onomy cannot be ascribed in dynamical models unfolding
in real time. All it takes to avoid the problem of temporal
asymmetry of ﬁnal causation is to take long-scale system’s
dynamics under consideration. This approach was probably
pioneered by Rosenblueth et al. (1943), who explicate the
concept of purposeful behaviour in terms of negative
feedback. Another approach to determine biological func-
tion is to consider what given component was selected for in
its evolutionary history (Millikan 2002).
Closure to efﬁcient cause
A crucial feature of f is that its efﬁcient cause lies in the
system itself, or to use Rosen’s phrase, it is entailed from
within the system. ψ on the other hand is only materially and
ﬁnally caused from within the system, but still requires
some external component as its efﬁcient cause; it is not
entailed. (This may mean some enzyme produced by some
other system that enables reaction ψ to take place). Gen-
erally, the more components are entailed by the system
itself, the more is the system autonomous. The corner case
where all system’s components are entailed from within the
system is what Rosen calls the property of closure to ef-
ﬁcient cause.
The system depicted on Figure 1 could be extended by
deﬁning a third component θ efﬁciently causing ψ and
making sure that this component is efﬁciently caused by ψ.
Such a model is displayed on Figure 2.
In this system, Yis the material cause of H (X, Y), the ﬁnal
cause of X and the efﬁcient cause of θ. The system consists
of three mappings (f, ψ, θ), and each of these is entailed by
a product of one of the others. This means that f, ψ and θ, as
we selected them, are closed to efﬁcient cause.
Biologically, mapping f can be interpreted as metabolic
activity and mapping ψ as activity maintaining f, termed
‘repair’ by Rosen. θ enables the self-replication of the entire
system. Thus, systems sharing the relation structure de-
picted on Figure 2 are called metabolism-repair systems, or
(M, R)–systems.
Note also that while the mappings on the Diagram 2 are
entailed from within the system, there is still one unentailed
object, that is, X. Although Rosen does not emphasise this
point, it is quite deliberate that X has to be provided from
outside of the system. This corresponds to the fact that
living systems are thermodynamically and materially open,
that is, they must consume energy to maintain their exis-
tence. Indeed, thermodynamic openness is a fundamental
property of several models of self-organisation mentioned
earlier, for example, (A2), (A4) and (A8).
According to Rosen, systems closed to efﬁcient cause
cannot be described in terms of states and transitions be-
tween them. Therefore, some of their models are not re-
cursively enumerable, which also means they are not output
of any computable function. Those models are not simu-
lable in the sense described earlier that their activity cannot
be simulated by a Turing machine.
Instead of narrating Rosen’s circuitous argument in full
detail, I will follow Chu and Ho’s 2006 summary. Let us
assume that the system depicted on Figure 2 is indeed a
mechanism, that is, it can be completely speciﬁed in terms
of states and a recursively deﬁned transition function
between them. Therefore, all of its components (f, ψ, θ)
can be speciﬁed in three corresponding sets of states J, K,
L. Now take ψ and the corresponding set of states L. ψ has
at least two functional roles, namely, its output H (X, Y)
materially causes HðY,HðX,YÞ (hence also θ) and efﬁ-
ciently causes f. From the assumption that L completely
speciﬁes ψ, we must be able to extract information about
these two roles from L. That is, L can be partitioned as L =
{L0, L00}, where both L0 and L00 consist of states encoding
each functional role of ψ. But if the property of closure to
efﬁcient cause is to hold, each of these functional roles is
to be maintained by some other component, meaning that
HðY,HðX,YÞ has to be split into two as well. Hence in-
ﬁnite regress looms. But on the assumption that ψ is to be
speciﬁed by a ﬁnite set of state, there could be no inﬁnite
regress. Hence the assumption is false, and the system
depicted on the Figure 2 is not Turing-computable.
This argument has received serious criticism from nu-
merous authors. For instance, Chu and Ho (2006) accuse
Rosen of using an unrealistic assumption that functions are
always localised into corresponding organs (i.e. one indi-
visible component cannot have several functional roles).
Consequently, Rosen at least shows that this assumption
does not hold for neither mechanism nor living systems,
which is quite trivial. Louie (2007) defended Rosen from
Chu and Ho’s criticism by accusing them of misinterpreting
Rosen by using incorrect deﬁnitions (for instance, for the
term
‘mechanism’).
I
do
not
ﬁnd
Louie’s
defense
Figure 2. A relational model made of three mappings, each of
which is entailed by a product of one of the others.
Korbak
41

compelling for two reasons. First, a large portion of Chu and
Ho’s criticism concerned the biological plausibility of
Rosen’s modelling assumptions (e.g. about how to map
morphisms to biological activities) not only the formalism
itself. Louie claims decidedly that
‘[a]ll Rosen’s theorems have been mathematically proven
(although Rosen’s presentations are not in the ordinary form of
deﬁnition-lemma-theorem-proof-corollary that one ﬁnds in
conventional mathematics journals). Indeed, no logical fallacy
in Rosen’s arguments has ever been demonstrated. Counter-
examples cannot exist for proven theorems’. (Louie 2007,
p. 294, p. 294)
While it is true that proven theorems have no counter-
examples, this only pertains actual proofs, not arguments
expressed in a mathematical language. An argument ceases
to be a formal proof as soon as it leaves the realms of pure
mathematics: it has to be backed up with some mapping
from mathematical objects onto empirical ones and the
validity of such a mapping is, at least partly, an empirical
question. As far as Rosen wants (M, R)–systems to pertain to
biological reality rather than just other mathematical ob-
jects, he must do the hermeneutic work of translating be-
tween mathematical objects and biological entities. This
work is not purely formal in nature and can be subject to
criticism.
A second problem with Louie’s defense is that coun-
terexamples have been found. There are several demon-
strations how (M, R)–systems can be expressed as
computable in several models of computation. This includes
Gatherer and Galpin (2013) demonstrating the comput-
ability of (M, R)–systems in process algebra, Mossio et al.
(2009) in lambda calculus and Palmer et al. (2016) using
stream X-machines. In this paper, I will take another route in
criticising this argument: instead of mounting formal an
argument in a particular model of computation, I will attack
Rosen’s model on philosophical grounds. Concretely, I will
show that abstracting away from time is the crucial and
untenable assumption. Before that, however, I will take a
broader, philosophical look at relational biology from a
historical perspective to trace back what went wrong.
Philosophical origins of relational biology
The concept of living organisms as having peculiar, circular
causal structure dates back to Immanuel Kant. Actually,
Kant himself took an epistemological stance on the teleo-
nomic character and mechanistic intractability of biological
complexity, that is, he considered them as regulative
principles of scientiﬁc explanation rather than constitutive
of some biological reality. The aim of his philosophy of
biology outlined in the Critique of the Power of Judgment
(Kant 1790) was to defend the notion of natural purpose
against critiques of both empiricists (Hume) and rationalists
(Spinoza) on the one hand and liberate it out of theological
commitments on the other. According to Kant, organism
must be conceived as organised and purposive beings; the
natural purposes have to be presupposed rather than in-
stantiated in reality. His views, however, inspired an entire
research program in 19th century biology and historically,
what Kant took as regulative, biologist saw more as con-
stitutive (Huneman 2007). He also emphasised the self-
organising character of living organisms:
‘In such a product of nature every part not only exists by means
of the other parts, but is thought as existing for the sake of the
others and the whole, that is as an (organic) instrument. Thus,
however, it might be an artiﬁcial instrument, and so might be
represented only as a purpose that is possible in general; but
also its parts are all organs reciprocally producing each other.
This can never be the case with artiﬁcial instruments, but only
with nature which supplies all the material for instruments
(even for those of art). Only a product of such a kind can be
called a natural purpose, and this because it is an organized and
self-organizing being’. (Kant 1790)
This passage clearly shows the link between Kant’s and
Rosen’s accounts of life. The property of closure to efﬁcient
cause in relational models can be seen as a formalisation of
Kant’s intuition that living organism’s parts reciprocally
produce each other. In other words, every constituent process
is conditioned by some other process in the system. Thus, the
natural purpose of given traits of an organism is to be found in
the organism itself, not elsewhere (i.e. in the mind of its
creator, divine or not). This way of thinking about biology
clearly diverges from both the mechanists (Descartes or La
Mettrie) and natural theologists (Paley). Living creatures are
autonomous, that is, they themselves shape their organisation
rather than relying on some external design.
Kant’s position towards the possibility of a mechanistic
explanation of life was therefore ambiguous. He seemed to
assume that living systems possess an inherent teleological
component that could not be derived from Newtonian
physics. Therefore, biologists must add this assumption ad
hoc to mount a teleological explanation. Kant famously
exclaimed that ‘there will never be a Newton of the blade of
grass’. (Ironically, it was Rosen who was posthumously
dubbed ‘the Newton of biology’ (Mikulecky 2001).) On the
other hand, this limitative claim was probably epistemo-
logical rather than ontological: it pertained the limitation of
our minds. Curiously, it was just half a century after the
Third Critique when a reasonable reductive account of
natural purposes in terms of physical processes (natural
history) was proposed by Darwin.
42
Adaptive Behavior 31(1)

An inﬂuential continuation of Kant’s account is the idea
of autopoiesis (Varela et al. 1974; Maturana and Varela
1980). (Actually, Varela in his last published paper (Weber
and Varela 2002) himself dubs Kant as the grandfather of the
theory of autopoiesis). Autopoietic system, argued to be a
minimal model of living creature, is an organized system
characterised by two properties:
(a)
it continuously realises the networks of processes
that maintain its existence and
(b)
it has a concrete spatial boundary (speciﬁed by the
topological domain of its realization as a network).
It is often argued that property (a) (sometimes termed
‘operational closure’) is roughly equivalent to the property
of closure to efﬁcient cause (C´ardenas et al. 2010). How-
ever, Varela and Maturana not only from the very beginning
characterise an autopoietic system as a (special kind of)
machine, but also introduced the concept of autopoietic
systems as a framework for computer simulations of living
processes. The concept of autopoiesis later turned out to be
very inﬂuential in the ﬁeld of artiﬁcial life (Froese and
Ziemke 2009). This very fact sheds serious doubts on
whether (M, R)–systems are indeed not computable.
What can be considered as the contribution of the
Kantian heritage to current biology is the bringing out the
concept of (biological) autonomy (Bechtel 2007). Ac-
cording to contemporary enactivists, ‘[a]n autonomous
system is a system composed of processes that generate and
sustain that system as a unity and thereby also deﬁne an
environment for the system. Autonomy can be characterized
abstractly in formal terms or concretely in terms of its
energetic and thermodynamic requirements’ (Thompson
2010, p. 44-45). This concept slightly differs as it
stresses the role of environment in the functioning of a
system: autonomy certainly does not imply isolation (nei-
ther causal, nor energetic or material); this aspect is de-
veloped further by Ruiz-Mirazo et al. (2004)). Also, note
that the property that every constituent process is condi-
tioned by some other process in the system is to be in-
terpreted recursively: a given process is conditioned by
some earlier process and there need not be an inﬁnite loop as
far as some external explanation of the origins of the ﬁrst
process is provided. A similar recursive treatment of the
concept of self-organization can be found in (Bickhard
2009).
It is, furthermore, worthwhile to point out here that the
distinction Rosen makes between reductionist and relational
models is hardly congruent with the distinction between
dynamical and mechanistic explanation in contemporary
philosophy of science. His criticism of reductionist mod-
elling
shares
some
points
with
early
functionalism
Cummins (1975); namely:
(i)
rejection of covering-law model of explanation,
(ii)
introduction of the concept of function (understood
as a causal role in a given system) and
(iii)
assuming strong substrate neutrality and abstract-
ing away from material constitution of a system
under consideration (‘throwing away the matter
and keeping the organisation’, to use Rosen’s
(1991, p. 120) phrase).
It should also be stressed that the mechanistic (reduc-
tionist) explanation Rosen rejects is very unlike contem-
porary neomechanicism (Machamer et al. 2000; Bechtel
2011)), which at least since (Bechtel 2007) appreciates
system-wide organisation level as well. Actually, as Bechtel
(2007) points out, it is somewhat ironic for the antimech-
anist movement of Rosen et consortes to have sprung in the
early second half of the 20th century, because philosophers
of science recognised the concept of mechanism as an
adequate model of biological explanation as late as in the
2000s. Furthermore, Rosen seems to be committed to the
view of mechanistic explanation as ‘analysing down to a
family of constituent particles’. But if the palette of
available bottom-level explanantia is so drastically narrow
to encompass only geometrico-mechanical activities (as
termed by (Machamer et al. 2000; Bechtel 2011, p. 14), then
not only living systems but also an arbitrary material system
could not be accounted for mechanistically. In other words,
it seems to be Cartesian mechanism Rosen is ﬁghting with
and Cartesian mechanism is known to be false (even, or
foremost) for physics at least since 19th century, when the
existence and role of energetic and electromagnetic activ-
ities were recognised.
It is probably not the kind of mistake an educated
physicist like Rosen would make, and one could argue ‘the
Newtonian picture’ is a deliberately chosen simplistic ex-
ample of mechanistic explanation and ‘constituent particles’
are to be understood in a broad sense. Still, however, Rosen
explicitly assumes that mechanistic explanation must bot-
tom down to some universal basic level (constituent par-
ticles ‘are to be further fractionated’, ibidem), while
contemporary mechanists argue this basic level is highly
domain-dependent and generally a working neuroscientist
can, should and actually does abstract away from the level
of elementary particles (Machamer et al. 2000). (Note that it
is very much in the vein of Rosen’s relational framework.) To
sum up, Rosen sees mechanistic explanation as committed
to strong explanatory reductionism (‘greedy reductionism’,
to use Dennett’s (1995) phrase) and his alternative – rela-
tional modelling – shows remarkable similarities to what is
known as mechanism today.
Lastly and even more ironically, since dynamical sys-
tems are by deﬁnition space-state based systems, they are
ﬁrst and foremost to fall under Rosen’s criticism, if it were
sound. Thus, the dynamical systems approach in cognitive
Korbak
43

science (Port and Van Gelder 1995; Kelso 1995) is to be
rejected even sooner than computationalism it tries to un-
dermine. Nowadays, however, it is dynamicism that de-
velops the notions of self-organisation, affordance and
complexity in a Rosenian way and explicitly draws the
notion of autonomy from closure to efﬁcient cause
(Chemero and Turvey (2008); Chemero (2008)). It is dy-
namicism, also, that provides a cogent critique of Rosen’s
approach: relational models, being time-invariant, do not
capture essentially temporal features of life, such as ad-
aptivity, development and evolution. For instance, Mont´evil
(2020) argues convincingly that living systems, as opposed
to non-living physical systems, are inherently historical.
They require speciﬁc methods and epistemology to ac-
commodate their historicity, even when we study how or-
ganisms behave here and now. While physics postulates
invariance in order to explain changes, in biology we cannot
postulate invariance behind changes because invariances
are limited to constraints whose validity can be ascertained
only given a particular time and time-scale (Mont´evil 2020,
p. 8). Thus, a time-invariance mode of explanation espoused
by relational biology will necessarily miss the essence of
living systems.
What is more, as relational models abstract away from
the material underpinnings of living systems, they are
unable to account for certain constraints on how its com-
ponents perform their functions (Clark 1997). The latter
point could be elaborated as to undermine the concept of
abstract, materially neutral modelling altogether: at least in
psychology the assumption that cognitive activity can be
explained ignoring its neural substrate has turned out to be
false (Bechtel and Mundale 1999).
All in all, situating Rosen in contemporary debates in the
philosophy of science suggests that he anticipated con-
temporary neomechanism rather than mounted a successful
attack against it. His variety of functionalism is not faultless,
but undoubtedly played an important role in recognising the
speciﬁcity of complex living systems and importance of
usually overlooked organisational level of description
of living systems. It seems, however, that the anachronism
of Rosen’s philosophical commitments does not affect the
evaluation of his argument. It rests not on the curiosities of
the relational framework, but on a speciﬁc (circular) causal
structure of certain models and as such may be formulated
even if the relational approach is misguided.
It’s about time
There is one crucial dimension of life that relational biology
leaves behind: time. Obviously, this is by design: it is time-
invariance that allows for ﬁnal causation as morphism in the
direction opposite to material causation. It is this design
feature that supposedly makes models of (M, R)–systems
uncomputable. I will argue, however, that it is just a feature
of a particular formal representation of self-organising
systems, not their essential property. Computations over
systems composed of interdependent components are om-
nipresent in computer science and machine learning. It is
also quite trivial to compute with self-referring objects. On a
machine code level, there is nothing mysterious for a
memory location to store its own address. All it takes to
compute with self-referring objects is an algorithm that
avoids unwanted inﬁnite loops by witless bookkeeping of
visited states.
There are numerous algorithms in modern machine
learning that exploit self-reference in a non-trivial way to
optimise functions deﬁned in a circular way. The usual
strategy when dealing with such a circular dependence
between two variables, A and B, is to apply an iterative
procedure, ﬁrst pretending that A is ﬁxed and optimize for B,
and then the other way around. For instance, such a problem
arises in probabilistic inference for latent variable models,
when the optimal parameters (i.e. a maximum likelihood
solution) depend on the value of a latent variable, and the
expectation of the latent variable in turn depends on the
parameters. Because the variables and parameters depend
on each other, there will be no closed form solution for this
distribution. However, it can be computed approximately
via an iterative procedure. One theoretically principled
scheme
is
the
expectation
maximisation
algorithm
(Dempster et al. 1977). Here, one compute the expected
value of latent variables at time-step t based on previous
values of parameters from time-step t  1. Then, one can
compute the maximum likelihood parameters at time-step t
based on those latent variables and increment the counter t.
One other example of an equation with a circular structure is
the Bellman equation, recursively linking the value of a
given state to other state accessible from it. Here again, the
now-classic dynamic programming solution consists of it-
eratively exploiting dependence in one direction.
The common pattern is parametrising the system in terms
of discrete (or continuous) time-steps t to removing the
circular dependence. Let us consider a similar para-
metrisation of an (M, R)–system on Figure 2. First, we index
each give variable X, Y, H (X, Y), H(Y, H(H, Y)), f, ψ and θ
with an index t. Then, we draw solid arrows between se-
lected pairs of variables sharing an index and dotted arrows
between selected pairs of arrows with different indices (such
Figure 3. Unrolling a cyclic graph of an (M, R)–system into a time-
indexed chain.
44
Adaptive Behavior 31(1)

as the input of an arrow is associated with t  1 and the
output of an arrow with t). This guarantees that there is no
circular dependence: for a morphism, its input will always
have index equal or earlier than its output. This rewriting
can be applied recursively, effectively unrolling the circular
dependencies of (M, R)–systems into a chain of linear
dependencies, as displayed on Figure 3. Note that again
there is no input to X, because it stands for the environ-
mental input to the system.
While one may argue that time-indexing does not really
capture Rosen’s intended interpretation of these compo-
nents, there is little justiﬁcation for such an interpretation.
Rosen does not really provide a concrete biological inter-
pretation of these components, and the graphical model I
provided seems to capture the essential architecture of self-
organisation (nested feedback loops governed by utility)
and the philosophical intuitions behind it (autonomy)
equally well. There is little justiﬁcation for deliberately
choosing a formal model just because it manifests irre-
movable, inconvenient properties.
The proposed reparametrisation of (M, R)–systems has
beneﬁts on its own as it invites powerful probabilistic in-
terpretations. Highlighting the analogy with expectation
maximisation, one can try to reinterpret the (M, R)–system
as a graphical model, that is, treating each component as a
random variable and each solid line as a random variable
and each dotted line as dependence. For notational con-
venience, let us deﬁne Z = H (X, Y) and C = H(Y, H(H, Y)) =
H(Y, Z). The corresponding probabilistic graphical model is
displayed on Figure 4.
Then the problem of simulating an (M, R)-system re-
duces to inferring the join distribution p (ψ1, f1, θ1, X1, Y1,
Z1, C1, …, ft, ψt, θt, Xt, Yt, Zt, Ct). This distribution can then
be decomposed as
∏
t
½pðXtÞpðftjXt,Zt1ÞpðYtjψtÞ
pðψtjYt,Ct1ÞpðZjψtÞpðθtjZt,Yt1ÞpðCtjθtÞ
This particular dependency structure enables using a
simple inference algorithm to infer the joint distribution:
ancestral sampling. We can just start with an initial distri-
bution over X1 and keep inferring the conditional proba-
bility of each variable using its conditioning set. The further
reason this probabilistic graphical model reparametrisation
is interesting is that it exposes the connection with active
inference, a framework described in Section 2. According to
inference, living systems are generative models trying to
probabilistically model both its internal states and its en-
vironments. Mathematically, they can be seen as probabi-
listic graphical models with a particular dependency
structure known as a Markov blanket. The Markov blanket
of a random variable A is the set of random variables given
which A is conditionally independent from all other random
variables in the system. This property has recently attracted
much philosophical interest leading to accounts of self-
organisation in terms of Markov blankets developed as-
suming (B4), for example (Friston 2013; Clark 2017;
Korbak 2021). The dependence structure embodied in the
probabilistic reparametrisation of (M, R)–systems induces
three such Markov blankets:
1.
The set {ψt1, θt1, ft, Zt1} is a Markov blanket of
Z.
2.
The set {ψt1, ft1, θt, Yt1} is a Markov blanket of
Y.
3.
The set {θt1, ψt, Yt} is a Markov blanket of C.
This fact once again reveals a deep similarity between
different formal models of self-organisation, built using
different sets of assumptions.
To summarise, Rosen claimed that (M, R)–systems are
not computable because each component of the system
depends on other components. I have argued that this ar-
gument is misguided because a simple reformulation of (M,
R)–systems is possible that both (i) captures all the bio-
logical and philosophical intuitions regarding the notion of
self-organisation and (ii) can implement computations
under an iterative scheme. In other words, (M, R)–systems
are not only computable but also tractable (i.e. computable
in practice). Finally, I have shown that – via the graphical
model formulation – (M, R)–systems are linked in important
family of models of self-organisation assuming the free
energy principle – a paradigm widely discussed in con-
temporary theoretical biology and cognitive science.
Closing thoughts
When Rosen makes a point that biology is more general
than physics because it deals with systems that physics
cannot account for, he refers to the G¨odel’s incompleteness
theorem (Rosen 1991, p. 7-10). Mechanical inexplicability
of life is likened to the impossibility of providing a complete
axiomatisation for a sufﬁciently rich and consistent theory,
such as Peano arithmetic. The connection, however, is even
deeper since Rosen aims at making a philosophical point
based on certain metamathematical limitative results. A
similar anti-mechanist argument was famously mounted by
Lucas (1961). According to Lucas, no machine is equivalent
to human mind because the mind can recognize the truth of a
Figure 4. A probabilistic graphical model corresponding to the
unrolled (M, R)–system from Figure 3.
Korbak
45

G¨odel sentence for this machine, but the machine – due to
G¨odel’s theorem – either cannot recognise it or is self-
contradictory (and recognises an arbitrary sentence as
true). In both cases, human mind outperforms the machine.
This argument, however, is highly questionable because
G¨odel himself doubted that similar conclusion about
mathematical intuition can be derived from his theorem
with no further assumptions. Krajewski (2020) offers a
compelling analysis of Lucas’ argument, showing that
every argument following his way of thinking is either
circular or inconsistent.
Both Rosen’s and Lucas’ argument are part of a philo-
sophical project of recognising certain limitations of science
or some unusual complexity of certain natural systems,
based on their formal properties. This strategy was neatly
summarized by Hofstadter:
‘All the limitative Theorems of metamathematics and the theory
of computation suggest that once the ability to represent your
own structure has reached a certain critical point, that is the kiss
of death: it guarantees that you can never represent yourself
totally. Incompleteness G¨odel’s Theorem, Church’s Undecid-
ability Theorem, Turing’s Halting Problem, Tarski’s Truth
Theorem – all have the ﬂavor of some ancient fairy tale which
warns you that ‘To seek self-knowledge is to embark on a
journey which... will always be incomplete, cannot be charted on
any map, will never halt, cannot be described‘.’ (Hofstadter
1979)
On this view, the self-referencing nature of self-
organising systems is supposed to impose fundamental
limitations on some modes of explanation of such systems.
Similarly, Rosen’s argument may be interpreted as using the
fact that there are functions that are not computable (a
consequence of the undecidability of Turing’s halting
problem). While this is indeed true, Rosen fails to show that
his (M, R)–systems are indeed to be interpreted as non-
computable functions. As I intended to show in the previous
section, circular causation does not bring about any actual
inﬁnity into system’s description. An (M, R)–system can
very well be described in a non-circular way by unrolling
along the temporal dimension. Furthermore, I argued that
this simple reformulation both (i) captures all the biological
and philosophical intuitions regarding the notion of self-
organisation and (ii) can implement a computation under an
iterative scheme. The ﬂaw in Rosen’s argument is thus
remarkably similar to that in Lucas’: circularity is an ir-
reducible property of (M, R)–systems only if it is pre-
supposed from the very beginning.
Acknowledgements
The author thanks Marcin Miłkowski for feedback on earlier drafts
of this paper.
Declaration of conﬂicting interests
The author(s) declared no potential conﬂicts of interest with re-
spect to the research, authorship, and/or publication of this article.
Funding
The author(s) disclosed receipt of the following ﬁnancial support
for the research, authorship, and/or publication of this article: This
research was funded by the Ministry of Science and Higher Ed-
ucation (Poland) research Grant DI2015010945 as part of ‘Dia-
mentowy Grant’ programme.
ORCID iD
Tomasz Korbak https://orcid.org/0000-0002-6258-2013
Note
1. Category theory proved useful for formalizing certain as-
pects of living systems in other contexts across theoretical
biology. For one comprehensive approach, see (Ehresmann and
Vanbremeersch 2007).
References
Ashby, WR (1947). Principles of the self-organizing dynamic
system. The Journal of General Psychology, 37(2), 125–128.
https://doi.org/10.1080/00221309.1947.9918144
Bak, P, Tang, C, & Wiesenfeld, K (1987). Self-organized criti-
cality: An explanation of the 1/f noise. Physical Review
Letters, 59(4), 381–384. https://doi.org/10.1103/PhysRev
Lett.59.381
Barandiaran, X. E., & Chemero, A. (2009). Animats in the
modeling ecosystem. Adaptive Behavior, 17(4), 287–292.
https://doi.org/10.1177/1059712309340847
Barandiaran, X., & Moreno, A. (2008). Adaptivity: From meta-
bolism to behavior. Adaptive Behavior, 16(5), 325–344.
https://doi.org/10.1177/1059712308093868
Bechtel, W. (2007). Biological mechanisms: organized to maintain
autonomy. In: Systems Biology (pp. 269–302). Elsevier.
https://doi.org/10.1016/b978-044452085-2/50014-0
Bechtel, W. (2011). Mechanism and Biological Explanation.
Philosophy of Science, 78(4), 533–557. https://doi.org/10.
1086/661513
Bechtel, W, & Abrahamsen, A (2005). Explanation: A mechanist
alternative. Studies in History and Philosophy of Science Part
C: Studies in History and Philosophy of Biological and
Biomedical Sciences, 36(2), 421–441. https://doi.org/10.
1016/j.shpsc.2005.03.010
Bechtel, W., & Mundale, J. (1999). Multiple realizability revisited:
Linking cognitive and neural states. Philosophy of Science,
66(2), 175–207. https://doi.org/10.1086/392683
Beer, R. D. (1990). Intelligence as adaptive behavior: An ex-
periment in computational neuroethology in perspectives in
artiﬁcial intelligence (6). Boston: Academic Press.
46
Adaptive Behavior 31(1)

Bickhard, M. H. (2009). The interactivist model. Synthese, 166(3),
547–591. https://doi.org/10.1007/s11229-008-9375-x
Buckley, C. L., Kim, C. S., McGregor, S., & Seth, A. K. (2017).
The free energy principle for action and perception: A
mathematical review. Journal of Mathematical Psychology,
81(1), 55–79. https://doi.org/10.1016/j.jmp.2017.09.004
Buhrmann, T, Di Paolo, EA, & Barandiaran, X (2013). A dy-
namical systems account of sensorimotor contingencies.
Frontiers in Psychology, 4(1), 285. https://doi.org/10.3389/
fpsyg.2013.00285
C´ardenas, ML, Letelier, JC, Gutierrez, C, Cornish-Bowden, A, &
Soto-Andrade, J (2010). Closure to efﬁcient causation,
computability and artiﬁcial life. Journal of Theoretical Bi-
ology, 263(1), 79–92. https://doi.org/10.1016/j.jtbi.2009.11.
010
Chemero, A. (2008). Self-Organization, Writ Large. Ecological
Psychology, 20(3), 257–269. https://doi.org/10.1080/104074
10802189372
Chemero,
A.
(2009).
Radical
embodied
cognitive
science
(p. ocn305412024). MIT PressOCLC.
Chemero, A., & Turvey, M. T. (2008). Autonomy and hypersets.
Bio Systems, 91(2), 320–330. https://doi.org/10.1016/j.bio
systems.2007.05.010
Chu, D., & Ho, W. K. (2006). A category theoretical argument
against the possibility of artiﬁcial life: Robert Rosen’s central
proof revisited. Artiﬁcial Life, 12(1), 117–134. https://doi.org/
10.1162/106454606775186392
Clark, A. (1997). Being there: Putting brain, body, and world
together again. MIT Press.
Clark, A. (2016). Surﬁng uncertainty: Prediction, action, and the
embodied mind. Oxford University Press.
Clark, A. (2017). How to knit your own Markov blanket. Technical
report, Theoretical Philosophy/MIND Group – JGU Mainz.
Collier, J. (2004). Fundamental properties of self-organization
[unpublished manuscript].
Copeland, B. J. (2020). The church-turing thesis. In E. N. Zalta (Ed),
The Stanford Encyclopedia of Philosophy (Summer 2020
edition). Metaphysics Research Lab, Stanford University.
Cummins, R. (1975). Functional analysis. The Journal of Phi-
losophy, 72(20), 741. https://doi.org/10.2307/2024640
Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum
likelihood from incomplete data via the EM algorithm.
Journal of the Royal Statistical Society. Series B (Method-
ological), 39(1), 1–22. https://doi.org/10.1111/j.2517-6161.
1977.tb01600.x Royal Statistical Society, Wiley.
Dennett, D. C. (1995). Darwin’s dangerous idea: Evolution and
the meanings of life. Simon & Schuster.
Downey, A. (2018). Think complexity: Complexity science and
computational modeling (p. 1043913738). OCLC.
Ehresmann, A., & Vanbremeersch, J. (2007). Memory Evolutive
systems; hierarchy, Emergence, cognition. ISSN. Elsevier
Science.
Freeman, W. J. (2000). Neurodynamics: An exploration in
mesoscopic brain dynamics. Perspectives in neural com-
puting. Springer.
Friston, K. (2013). Life as we know it. Journal of The Royal
Society Interface, 10(86), 20130475. https://doi.org/10.1098/
rsif.2013.0475
Friston, K. J., & Stephan, K. E. (2007). Free-Energy and the brain.
Synthese, 159(3), 417–458. https://doi.org/10.1007/s11229-
007-9237-y
Froese, T., & Ziemke, T. (2009). Enactive artiﬁcial intelligence:
Investigating the systemic organization of life and mind.
Artiﬁcial Intelligence, 173(3–4), 466–500. https://doi.org/10.
1016/j.artint.2008.12.001
G´anti, T. (1971/2003). Chemoton theory: Theory of living systems.
Mathematical and computational chemistry. Springer US.
Gatherer, D., & Galpin, V. (2013). Rosen’s (M,R) system in
process algebra. BMC Systems Biology, 7(1), 128. https://doi.
org/10.1186/1752-0509-7-128
Hofmeyr, J.-H. S. (2007). The biochemical factory that autono-
mously fabricates itself: A systems biological view of the
living cell Systems Biology (pp. 217-242). Elsevier. https://
doi.org/10.1016/b978-044452085-2/50012-7
Hofstadter, D. R. (1979). G¨odel, Escher, Bach: An eternal golden
braid (20th anniversary ed edition). Basic Books.
Huneman, P. (Ed), (2007). Understanding purpose: Kant and the
philosophy of biology. In North American Kant society
studies in philosophy(8, p. ocm82367701). University of
Rochester PressOCLC
Kant, I. (1790). Critique of the power of judgment (p. 967410622).
OCLC.
Kauffman, SA (1969). Metabolic stability and epigenesis in
randomly constructed genetic nets. Journal of Theoretical
Biology, 22(3), 437–467. https://doi.org/10.1016/0022-5193
(69)90015-0
Kauffman, S. A. (1993). The origins of order: Self-organization
and selection in evolution. Oxford University Press.
Kelso, J. A. S. (1995). Dynamic patterns: The self-organization of
brain and behavior. MIT Press.
Kleene, S. C. (1956). Representation of events in nerve nets and
ﬁnite automata. In C. E. Shannon & J. McCarthy (Eds),
Automata Studies (pp. 3–42). Princeton University Press.
https://doi.org/10.1515/9781400882618-002
Korbak, T. (2021). Computational enactivism under the free en-
ergy principle. Synthese, 198(3), 2743–2763. https://doi.org/
10.1007/s11229-019-02243-4
Krajewski, S. (2020). On the anti-mechanist arguments based on
G¨odel’s Theorem. Studia Semiotyczne, 34(1), 9–56. https://
doi.org/10.26333/sts.xxxiv1.02
Louie, A. H. (2007). A living system must have noncomputable
models. Artiﬁcial Life, 13(3), 293-297. https://doi.org/10.
1162/artl.2007.13.3.293
Lucas, J. R. (1961). Minds, machines and g¨odel. Philosophy, 36(137),
112–127. https://doi.org/10.1017/s0031819100057983
Korbak
47

Machamer, P., Darden, L., & Craver, C. F. (2000). Thinking about
mechanisms. Philosophy of Science, 67(1), 1–25. https://doi.
org/10.1086/392759
Marquis, J.-P. (2008). Category theory. In The Stanford Ency-
clopedia of Philosophy, E. N. Zalta (Ed.). https://plato.s-
tanford.edu/entries/category-theory/
Maturana, H. R., & Varela, F. J. (1980). Autopoiesis and cognition:
The realization of the living, volume 42 of Boston studies in
the philosophy and history of science. Springer Netherlands.
McCulloch, W. S., & Pitts, W. (1943). A logical calculus of the
ideas immanent in nervous activity. The Bulletin of Mathe-
matical Biophysics, 5(4), 115–133. https://doi.org/10.1007/
bf02478259
Meadows, D. H. (2008). Thinking in systems: A primer
(p. 225871309). Chelsea Green Pub. OCLC.
Mikulecky, D. C. (2001). Robert Rosen (1934–1998): a snapshot
of biology’s Newton. Computers & Chemistry, 25(4),
317–327. https://doi.org/10.1016/s0097-8485(01)00079-1
Millikan, R. (2002). Biofunctions: Two paradigms. In A. Ariew
(Ed), Functions (pp. 113–143). Oxford University Press.
Mitchell, M. (2011). Complexity: A guided tour (paperback ed
edition, 1, p. 870195766). Oxford: Oxford Univ. PressOCLC.
Mont´evil, M. (2020). Historicity at the heart of biology. Theory in
biosciences. https://montevil.org/publications/articles/2020-
Montevil-Historicity-Heart-Biology/
Mossio, M., Longo, G., & Stewart, J. (2009). A computable ex-
pression of closure to efﬁcient causation. Journal of Theo-
retical Biology, 257(3), 489–498. https://doi.org/10.1016/j.
jtbi.2008.12.012
Nasuto, S. J., & Hayashi, Y. (2016). Anticipation: Beyond syn-
thetic biology and cognitive robotics. Bio Systems, 148(1),
22–31. What Synthetic Biology can offer to Artiﬁcial In-
telligence. https://doi.org/10.1016/j.biosystems.2016.07.011
Nicolis, G., & Prigogine, I. (1977). Self-organization in non-
equilibrium systems: From dissipative structures to order
through ﬂuctuations. Wiley.
O’Regan, J. K., & No¨e, A. (2001). A sensorimotor account of
vision and visual consciousness. Behavioral and Brain Sci-
ences, 24(5), 939-973.
Palmer, M. L., Williams, R. A., & Gatherer, D. (2016). Rosen’s
(M,R) system as an X-machine. Journal of Theoretical Bi-
ology, 408(Supp 1), 97–104. https://doi.org/10.1016/j.jtbi.
2016.08.007
Pattee, H. H. (2012). How does a molecule become a message?
LAWS, LANGUAGE and LIFE (volume 7, pp. 55-67).
Springer Netherlands. Series Title: Biosemiotics. https://doi.
org/10.1007/978-94-007-5161-3_3
Piccinini, G. (2004). The ﬁrst computational theory of mind and
brain: a close look at mcculloch and pitts’s “logical calcu-
lus of ideas immanent in nervous activity”. Synthese, 141(2),
175–215. https://doi.org/10.1023/b:synt.0000043018.52445.3e
Port, R. F., & Van Gelder, T. (Eds), (1995). Mind as motion:
explorations in the dynamics of cognition. MIT Press.
Ra˛czaszek-Leonardi, J. (2012). Language as a system of replicable
constraints. In LAWS, LANGUAGE and LIFE (Vol. 7,
pp. 295-333). Dordrecht.: Springer Netherlands. Series Title:
Biosemiotics.
Rosen, R. (1991). Life itself: A comprehensive inquiry into the
nature, origin, and fabrication of life. Complexity in eco-
logical systems series (p. 254407824). New York: Columbia
Univ. PressOCLC.
Rosen, R. (1993). On models and modeling. Applied mathematics
and computation, 56(2–3), 359–372. https://doi.org/10.1016/
0096-3003(93)90128-2
Rosen, R. (2000). Essays on life itself. Columbia University Press.
Rosenblueth, A., Wiener, N., & Bigelow, J. (1943). Behavior,
purpose and teleology. Philosophy of Science, 10(1), 18–24.
https://doi.org/10.1086/286788
Ruiz-Mirazo, K., & Moreno, A. (2004). Basic autonomy as a
fundamental step in the synthesis of life. Artiﬁcial Life, 10(3),
235–259. https://doi.org/10.1162/1064546041255584
Ruiz-Mirazo, K., Peretó, J., & Moreno, A. (2004). A universal
deﬁnition of life: Autonomy and open-ended evolution.
Origins of Life and Evolution of the Biosphere: The Journal of the
International Society for the Study of the Origin of Life, 34(3),
323–346. https://doi.org/10.1023/b:orig.0000016440.53346.dc
Skarda, C. A., & Freeman, W. J. (1987). How brains make chaos in
order to make sense of the world. Behavioral and Brain Sciences,
10(2), 161–173. https://doi.org/10.1017/s0140525x00047336
Smith, L. B., & Thelen, E. (2003). Development as a dynamic
system. Trends in Cognitive Sciences, 7(8), 343–348. https://
doi.org/10.1016/s1364-6613(03)00156-6
Thompson, E. (2010). Mind in life: Biology, phenomenology, and
the sciences of mind (paperback ed edition, 1, p. 839038747).
Cambridge, Mass: Belknap Press of Harvard Univ. Press-
harvard univ. pressOCLC.
Thompson, E., & Stapleton, M. (2009). Making sense of sense-
making: Reﬂections on enactive and extended mind theories.
Topoi, 28(1), 23–30. https://doi.org/10.1007/s11245-008-9043-2
Turing, A. M. (1937). On computable numbers, with an application
to the entscheidungsproblem. Proceedings of the London
Mathematical Society, s2-42(1), 230–265. https://doi.org/10.
1112/plms/s2-42.1.230
Varela, F. G., Maturana, H. R., & Uribe, R. (1974). Autopoiesis:
The organization of living systems, its characterization and a
model. Bio Systems, 5(4), 187–196. https://doi.org/10.1016/
0303-2647(74)90031-8
Weber, A., & Varela, F. J. (2002). Life after Kant: Natural purposes
and the autopoietic foundations of biological individuality.
Phenomenology and the Cognitive Sciences, 1(2), 97–125.
https://doi.org/10.1023/a:1020368120174
Wiener, N. (2019). Cybernetics: Or, control and communication in
the animal and the machine (second editionreissue edition).
The MIT Press.
48
Adaptive Behavior 31(1)

Author Biography
Tomasz Korbak is a PhD student at the Department of Informatics, University of Sussex working on deep rein-
forcement learning, generative models and computational neuroscience with Dr. Chris Buckley and Prof. Anil Seth.
Previously, he was a researcher at the Institute of Philosophy and Sociology, Polish Academy of Sciences working with
Prof. Marcin Miłkowski and a research assistant at the Human Interactivity and Language Lab, Faculty of Psychology,
University of Warsaw working with Prof. Joanna Ra˛czaszek-Leonardi. He is interested in biologically-inspired and
probabilistic approaches to artiﬁcial intelligence and recently focuses on control as inference and controllable gen-
erative modeling.
Korbak
49

