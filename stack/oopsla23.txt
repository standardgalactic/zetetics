295
Greedy Implicit Bounded Quantification
CHEN CUI, The University of Hong Kong, China
SHENGYI JIANG, The University of Hong Kong, China
BRUNO C. D. S. OLIVEIRA, The University of Hong Kong, China
Mainstream object-oriented programming languages such as Java, Scala, C#, or TypeScript have polymorphic
type systems with subtyping and bounded quantification. Bounded quantification, despite being a pervasive
and widely used feature, has attracted little research work on type-inference algorithms to support it. A
notable exception is local type inference, which is the basis of most current implementations of type inference
for mainstream languages. However, support for bounded quantification in local type inference has important
restrictions, and its non-algorithmic specification is complex.
In this paper, we present a variant of kernel ğ¹â‰¤, which is the canonical calculus with bounded quantification,
with implicit polymorphism. Our variant, called ğ¹ğ‘
â‰¤, comes with a declarative and an algorithmic formulation
of the type system. The declarative type system is based on previous work on bidirectional typing for
predicative higher-rank polymorphism and a greedy approach to implicit instantiation. This allows for a clear
declarative specification where programs require few type annotations and enables implicit polymorphism
where applications omit type parameters. Just as local type inference, explicit type applications are also
available in ğ¹ğ‘
â‰¤if desired. This is useful to deal with impredicative instantiations, which would not be allowed
otherwise in ğ¹ğ‘
â‰¤. Due to the support for impredicative instantiations, we can obtain a completeness result
with respect to kernel ğ¹â‰¤, showing that all the well-typed kernel ğ¹â‰¤programs can type-check in ğ¹ğ‘
â‰¤. The
corresponding algorithmic version of the type system is shown to be sound, complete, and decidable. All the
results have been mechanically formalized in the Abella theorem prover.
CCS Concepts: â€¢ Theory of computation â†’Type theory.
Additional Key Words and Phrases: Bounded Quantification, Mechanical Formalization, Type Inference
ACM Reference Format:
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira. 2023. Greedy Implicit Bounded Quantification. Proc.
ACM Program. Lang. 7, OOPSLA2, Article 295 (October 2023), 29 pages. https://doi.org/10.1145/3622871
1
INTRODUCTION
Bounded quantification [Cardelli and Wegner 1985] is an extension of parametric polymorphism,
where type variables can have subtyping bounds. Mainstream object-oriented programming lan-
guages such as Java, Scala, C#, or TypeScript have polymorphic type systems with subtyping and
bounded quantification. The canonical calculus for bounded quantification is ğ¹â‰¤[Cardelli et al.
1991; Cardelli and Wegner 1985; Curien and Ghelli 1992], which is an extension of System ğ¹[Girard
1972; Reynolds 1974] with subtyping and bounded quantifiers. Like System ğ¹, polymorphism in
ğ¹â‰¤is explicit, which means that explicit type applications are necessary to instantiate the type
arguments of polymorphic functions. There are two well-known variants of ğ¹â‰¤in the literature.
Authorsâ€™ addresses: Chen Cui, ccui@cs.hku.hk, The University of Hong Kong, Department of Computer Science, Hong
Kong, China; Shengyi Jiang, shengyi.jiang@outlook.com, The University of Hong Kong, Department of Computer Science,
Hong Kong, China; Bruno C. d. S. Oliveira, bruno@cs.hku.hk, The University of Hong Kong, Department of Computer
Science, Hong Kong, China.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses,
contact the owner/author(s).
Â© 2023 Copyright held by the owner/author(s).
2475-1421/2023/10-ART295
https://doi.org/10.1145/3622871
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:2
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
The full variant of ğ¹â‰¤[Curien and Ghelli 1992] is the more expressive one but, unfortunately, it
is well-known that subtyping for full ğ¹â‰¤is undecidable [Pierce 1992]. The other variant is ker-
nel ğ¹â‰¤[Cardelli and Wegner 1985], which is the most well-known and used decidable variant of ğ¹â‰¤.
Since we are interested in decidable type systems in this paper, we will focus on kernel ğ¹â‰¤.
A practical drawback of explicit polymorphism in System ğ¹or ğ¹â‰¤is that programs require too
much type information to type check. Therefore, to make programming languages with (bounded)
parametric polymorphism practical, implicit polymorphism is needed. For System ğ¹, there have been
many proposals for global type inference with implicit polymorphism [Dunfield and Krishnaswami
2013; Le Botlan and RÃ©my 2003; Leijen 2008; Odersky and LÃ¤ufer 1996; Peyton Jones et al. 2007;
Serrano et al. 2018; Vytiniotis et al. 2008], typically designed as extensions of the Hindley-Milner
type system (HM) [Hindley 1969; Milner 1978]. One well-known strand of work is type systems
with predicative Higher Ranked Polymorphism (HRP). In the context of HRP, predicative means
that instantiations can only be monotypes, which are types that are not polymorphic. This imposes a
restriction compared to System ğ¹, where instantiations can also be polymorphic types. Nonetheless,
predicative HRP has been shown to work quite well in practice for many applications since most
instantiations required in practice use monotypes.
One extension to predicative HRP is to combine implicit instantiation with explicit type applica-
tions. Eisenberg et al. [2016] proposed extensions to both HM and a predictive HRP system with
predicative explicit type applications. With explicit type applications, programmers can choose
their own instantiations by using type applications similar to System ğ¹. A complication that arises
in combining implicit instantiation with explicit type applications is that the usual predicative
subtyping relation for HRP, due to Odersky and LÃ¤ufer [1996], is incompatible with explicit type
applications. Eisenberg et al. [2016] proposed modified subtyping relations that are compatible
with predicative explicit type applications. More recently, Zhao and Oliveira [2022] proposed to
extend a predicative HRP type system, called ğ¹ğ‘’
â‰¤, with impredicative explicit type applications. The
impredicativity of explicit type applications requires further changes to the HRP subtyping relation.
There is little work on predicative HRP type inference with bounded quantification. Zhao
and Oliveira consider a subtyping relation with top and bottom types, but ğ¹ğ‘’
â‰¤does not have
bounded quantification. Cardelli [1993] implemented a type-inference algorithm for ğ¹â‰¤, but did not
formally study it. The only formal study that we are aware of supporting bounded quantification
is by Sequeira [1998], who has studied a calculus called MLâˆ€â‰¤: a System ğ¹variant with bounded
quantification. The kind of type inference supported by Sequeiraâ€™s work is quite ambitious since
MLâˆ€â‰¤supports let generalization and the inference of principal types, just as HM. However,
as Sequeira admits, his algorithm is impractical because it infers subtyping constraints without
simplification. For example, he notes that the type inferred for a quicksort algorithm has around
300 constraints. Thus, many inferred types are too large and difficult to understand for humans.
The de facto technique to deal with type inference for languages with bounded quantification
is local type inference [Odersky et al. 2001; Pierce and Turner 2000]. Unlike HM and global type
inference HRP approaches, local type inference does not employ long-distance constraints such
as unification variables and only employs a local constraint solver to infer type arguments in
polymorphic applications. This is less powerful than global approaches but, as argued by Pierce
and Turner, has the advantage of scaling up to features that are hard to deal with using global
type-inference approaches. For instance, local type inference techniques can deal with subtyping
and impredicative instantiations. Despite the technical differences, both (predicative) HRP and
local type inference target the problem of type inference for higher-rank polymorphic languages.
Moreover, local type inference complements implicit polymorphism with support for explicit type
applications, like some predicative HRP approaches. Programmers can explicitly provide type
instantiations when automatic (implicit) inference fails to find them.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:3
Local type inference has more modest goals regarding type inference compared to HM-style
inference and many HRP type-inference approaches. In particular, local type inference does not
provide any mechanism to infer the types of arguments for (top-level) functions and does not have
to deal with the question of finding principal types for polymorphic functions. In this way, the issues
with Sequeiraâ€™s approach are a non-issue for local type inference since all polymorphic functions
are given explicit type annotations. While local type inference has shown its value in practice, it
has some important limitations that were identified by Hosoya and Pierce [1999]; Pierce and Turner
[2000]: hard-to-synthesize arguments; no best argument; and no support for interdependent bounds. In
particular, for bounded quantification Pierce and Turner did not know how to extend the algorithm
to support interdependent bounds such as âˆ€(ğ‘â‰¤âŠ¤). âˆ€(ğ‘â‰¤ğ‘). Â· Â· Â· where the type variable ğ‘is
bounded by another type variable ğ‘. Thus, their algorithm cannot infer such implicit instantiations.
In Section 2.2 we will discuss these limitations in more detail. Especially in the presence of bounded
quantification, local type inference requires a complex specification that makes it hard to predict
when instantiations will be successfully inferred.
In this paper, we present a variant of kernel ğ¹â‰¤, called ğ¹ğ‘
â‰¤, with implicit predicative polymorphism
as well as explicit impredicative type applications. The declarative type system of ğ¹ğ‘
â‰¤is simple
and clear. ğ¹ğ‘
â‰¤extends Zhao and Oliveiraâ€™s ğ¹ğ‘’
â‰¤calculus with bounded quantification. In the design
of ğ¹ğ‘’
â‰¤, the authors follow a philosophy similar to local type inference but instead advocate for a
more modest form of global type inference: i.e., no let generalization or automatic inference of
(top-level) polymorphic functions is allowed. Moreover, easy (predicative) instantiations can always
be guessed automatically, but hard (impredicative) instantiations require explicit type applications.
They call this a more modest form of global type inference elementary type inference. ğ¹ğ‘
â‰¤adopts a
similar philosophy. Furthermore, implicit instantiations in ğ¹ğ‘
â‰¤support interdependent bounds and
deal with other weaknesses of local type inference, and ğ¹ğ‘
â‰¤can type check all kernel ğ¹â‰¤programs.
In ğ¹ğ‘
â‰¤, a critical question is what is a monotype? The approach for finding implicit instantiations
is greedy [Cardelli 1993]. That is, once an instantiation is found, ğ¹ğ‘
â‰¤commits to that instantiation,
regardless of other possible instantiations that can be found later. This greedy approach follows
previous predicative HRP approaches, which have the property that monotype subtyping implies
equality of monotypes. This ensures that if a monotype works for the first instantiation, it also
works for the subsequent instantiations. However, without care, the property easily breaks in the
presence of more expressive subtyping relations. In addition, it turns out that in ğ¹ğ‘
â‰¤, if all the type
variables are considered monotypes, the transitivity of subtyping is lost! Thus, while typically
monotypes are defined in a purely syntactic way, this is not the case in ğ¹ğ‘
â‰¤. In particular, whether or
not type variables are considered to be monotypes depends on their bounds. With careful crafting
of what constitutes a monotype, we can ensure that the greedy approach is always successful and
the transitivity of subtyping is preserved.
The algorithmic version of the type system is shown to be sound, complete, and decidable. We
introduce two new algorithmic techniques: polytype splitting and worklist substitutions. Polytype
splitting is a simple technique where functional existential (or unification) variables are only split
into two existential variables if they unify with a polytype. Polytype splitting has the property that
the number of splits is statically determined, which helps derive a simpler measure for decidability.
Worklist substitutions simplify the presentation and proofs of the algorithmic system by dealing
with necessary reorderings that arise from widening the scope of existential variables. We also
discuss a variant with a more general notion of monotype. The declarative system of this system
still preserves all the desirable properties, but the greedy algorithm is no longer complete. All the
results have been mechanically formalized in the Abella theorem prover.
In summary, the contributions of this paper are:
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:4
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
â€¢ A declarative bidirectional type system with predicative implicit bounded quantification
and impredicative explicit type applications. The declarative type system guesses monotypes.
Monotypes are unconventional in that they require a non-syntactic formulation due to the
presence of bounds in type variables.
â€¢ An algorithmic formulation of the type system, which is shown to be sound, complete
and decidable with respect to the declarative formulation. The algorithm employs a worklist
formulation inspired by Zhao et al. [2019]â€™s work.
â€¢ New algorithmic techniques: We introduce two new algorithmic techniques: polytype splitting
and worklist substitutions. Both techniques are helpful in providing a simple algorithm, and they
also simplify some of the key proofs, in particular decidability.
â€¢ A variant of ğ¹ğ‘
â‰¤with monotype subtyping: In Section 5, we present a variant of ğ¹ğ‘
â‰¤that
deals with subtyping between monotypes during implicit instantiation. This variant has a more
general notion of monotypes, and infers more instantiations at the cost of completeness.
â€¢ Completeness with respect to kernel ğ¹â‰¤: ğ¹ğ‘
â‰¤â€™s type system is shown to be complete with
respect to kernel ğ¹â‰¤. In other words, all the programs that type check in ğ¹â‰¤also type check in
ğ¹ğ‘
â‰¤.
â€¢ Mechanical formalization and implementation: All the calculi and proofs in this paper
have been mechanically formalized in the Abella theorem prover [Gacek 2008]. We also have
a simple Haskell implementation, which type checks all the ğ¹ğ‘
â‰¤examples in this paper. The
supplementary materials, including the implementation, proofs, and the extended version of
the paper are available at: https://doi.org/10.5281/zenodo.8202095.
2
OVERVIEW
We start with a background on implicit (predicative) higher-rank polymorphic (HRP) type inference
and elementary type inference [Zhao and Oliveira 2022]. Then, we discuss the limitations of
local type inference and its variants in dealing with languages with ğ¹â‰¤features and bounded
quantification. Finally, we illustrate the key ideas in our work that address some of these limitations
and discuss technical innovations over previous work.
2.1
Background: Predicative and Elementary Type Inference
Higher-rank polymorphism for languages Ã  la System ğ¹allows universal types to appear in arbitrary
positions in types, which lifts restrictions of top-level universal types in the Hindley-Milner type
system. The ğ¹ğ‘’
â‰¤calculus [Zhao and Oliveira 2022] additionally supports impredicative instantiation
by explicit type applications provided by the programmer, which allows it to type-check all the
programs typable in System ğ¹. There are several important design principles of ğ¹ğ‘’
â‰¤that are in place
to preserve properties such as subsumption and inferring all easy instantiations.
HRP subtyping and explicit type applications. The introduction of explicit type applications
invalidates some subtyping rules commonly used in predicative HRP systems, and in particular in
the well-known subtyping relation for HRP by Odersky and LÃ¤ufer [1996]. The two key rules in
Odersky and LÃ¤uferâ€™s subtyping relation are:
Î¨ âŠ¢ğœ
Î¨ âŠ¢[ğœ/ğ‘]ğ´â‰¤ğµ
Î¨ âŠ¢âˆ€ğ‘. ğ´â‰¤ğµ
â‰¤âˆ€L
Î¨,ğ‘âŠ¢ğ´â‰¤ğµ
Î¨ âŠ¢ğ´â‰¤âˆ€ğ‘. ğµ
â‰¤âˆ€R
These rules enable order-irrelevant universal quantifiers. For instance, both of the following
subtyping relations hold: âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘â‰¤âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘and âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘â‰¤âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘. Thus,
ğœ†ğ‘¥. ğ‘¥3 can be checked against both (âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘) â†’Bool and (âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘) â†’Bool, by in-
stantiating ğ‘and ğ‘to Int and Bool, respectively. However, explicit type applications create problems.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:5
Type variables
ğ‘,ğ‘
Subtype variables
Ëœğ‘, Ëœğ‘
Types
ğ´, ğµ,ğ¶
::=
1 | ğ‘| âˆ€ğ‘. ğ´| ğ´â†’ğµ| Ëœğ‘| âŠ¤| âŠ¥
Monotypes
ğœ, ğœ
::=
1 | ğ‘| ğœâ†’ğœ
Contexts
Î¨
::=
Â· | Î¨,ğ‘| Î¨,ğ‘¥: ğ´| Î¨, Ëœğ‘
Î¨ âŠ¢ğ´â‰¤ğµ
ğ´is a subtype of ğµ
Î¨ âŠ¢1 â‰¤1
â‰¤Unit
Î¨ âŠ¢ğ´â‰¤âŠ¤
â‰¤âŠ¤
Î¨ âŠ¢âŠ¥â‰¤ğ´
â‰¤âŠ¥
ğ‘âˆˆÎ¨
Î¨ âŠ¢ğ‘â‰¤ğ‘
â‰¤Var
Ëœğ‘âˆˆÎ¨
Î¨ âŠ¢Ëœğ‘â‰¤Ëœğ‘
â‰¤SVar
Î¨ âŠ¢ğœ
Î¨ âŠ¢[ğœ/ğ‘]ğ´â‰¤ğµ
ğµis not a âˆ€type
Î¨ âŠ¢âˆ€ğ‘. ğ´â‰¤ğµ
â‰¤âˆ€L
Î¨, Ëœğ‘âŠ¢[ Ëœğ‘/ğ‘]ğ´â‰¤[ Ëœğ‘/ğ‘]ğµ
Î¨ âŠ¢âˆ€ğ‘. ğ´â‰¤âˆ€ğ‘. ğµ
â‰¤âˆ€
Î¨ âŠ¢ğµ1 â‰¤ğ´1
Î¨ âŠ¢ğ´2 â‰¤ğµ2
Î¨ âŠ¢ğ´1 â†’ğ´2 â‰¤ğµ1 â†’ğµ2
â‰¤â†’
Fig. 1. Declarative Syntax and Subtyping Rules of ğ¹ğ‘’
â‰¤.
Consider another expression with an explicit type application: ğœ†ğ‘¥. (ğ‘¥@Int 3). This expression can
be checked against (âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘) â†’Bool, but ğœ†ğ‘¥. (ğ‘¥@Int 3) â‡(âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘) â†’Bool does
not hold. The problem is that the type application instantiates the wrong universal quantifier in
the latter expression.
In addition, the possibility of impredicative explicit instantiations introduces two subtler problems.
Firstly, impredicative type applications, such as ğ‘“@(âˆ€ğ‘. ğ‘â†’ğ‘), also interact with the subtyping
relation. As shown by Zhao and Oliveira, some impredicative type applications break important
stability-of-type-substitutions lemma for subtyping if no restrictions are imposed. Secondly, unused
type variables in universal quantifiers (for instance, âˆ€ğ‘. ğ¼ğ‘›ğ‘¡) are equally problematic. We refer to
Zhao and Oliveiraâ€™s work for more details on these issues.
Subtyping in ğ¹ğ‘’
â‰¤. To address abovementioned problems, ğ¹ğ‘’
â‰¤imposes three restrictions compared
to Odersky and LÃ¤uferâ€™s subtyping relation. Subtyping for ğ¹ğ‘’
â‰¤is shown in Figure 1. The first
restriction is to replace â‰¤âˆ€R with a more restrictive rule (â‰¤âˆ€) that only allows comparing two
universal quantifiers. This has the consequence of making the order of the universal quantifiers
relevant, forbidding subtyping statements such as âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘â‰¤âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘. The second
restriction is to introduce a new sort of variables, Ëœğ‘, called subtype variables, which is used by the
new rule â‰¤âˆ€. A subtype variable is not a monotype, contrary to the conventional type variable ğ‘,
therefore it cannot be instantiated with rule â‰¤âˆ€L. This restriction is key to ensuring that the stability
of type substitutions lemma for subtyping holds. The final restriction is to add two additional
checks in well-formedness, to ensure no unused variables in universal types.
Î¨,ğ‘âŠ¢ğ´
ğ‘âˆˆFV(ğ´)
Î¨ âŠ¢âˆ€ğ‘. ğ´
Î¨,ğ‘âŠ¢ğ´
Î¨,ğ‘âŠ¢ğ‘’
ğ‘âˆˆFV(ğ´)
Î¨ âŠ¢Î›ğ‘. ğ‘’: ğ´
No inference of âŠ¤and âŠ¥. ğ¹ğ‘’
â‰¤does not support implicit instantiation of type âŠ¥and âŠ¤, by treating
them as non-monotypes. There are two reasons for this. The first reason is technical: allowing
unification with âŠ¤and âŠ¥introduces considerable complications in the unification procedure. Even
a simple bğ›¼â‰¤bğ›½and bğ›½â‰¤bğ›¼â†’1, produced by âˆ€ğ‘. (ğ‘â†’ğ‘â†’1) â†’1 â‰¤(âˆ€ğ‘. ğ‘â†’ğ‘) â†’1, can have
infinitely many solutions by picking bğ›¼= bğ›½= âŠ¥| âŠ¤â†’1 | âŠ¤â†’âŠ¥| Â· Â· Â· and no one is the best.
The second reason is practical: inference of âŠ¤and âŠ¥types can often mask type errors. For
instance, ğœ†ğ‘“. (ğ‘“+ ğ‘“1) can be typed with the type âŠ¥â†’Int, but it is likely to be a programmerâ€™s
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:6
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
error: possibly the programmer forgot an argument in the first occurrence of ğ‘“. When programmers
are certain that they need a type involving âŠ¤or âŠ¥, they can inform the type-inference algorithm
using type annotations or explicit type applications. Section 2.2 shows more examples that illustrate
some undesirable consequences of enabling the inference of âŠ¤and âŠ¥.
ğ¹ğ‘’
â‰¤uses the same greedy solving strategy for implicit instantiation as previous predicative
HRP systems [Dunfield and Krishnaswami 2013; Odersky and LÃ¤ufer 1996]. Moreover (like other
HRP systems), ğ¹ğ‘’
â‰¤guarantees that monotype instantiations can always be inferred. There is a
folklore property for such a greedy solving of implicit instantiations on predicative HRP systems
to work: subtyping between monotypes implies equality of monotypes, or formally speaking,
ğœ1 â‰¤ğœ2 â†’ğœ1 = ğœ2. This property is helpful in establishing the completeness of an algorithmic
system with respect to its declarative specification. Suppose that there are two instantiation
judgments (or unification judgments) bğ›¼â‰¤ğœ1 and bğ›¼â‰¤ğœ2 produced by the algorithm, and the
declarative specification could guess a ğœthat satisfies ğœâ‰¤ğœ1 and ğœâ‰¤ğœ2. This means that ğœ1 = ğœ2 and
the order of unification makes no difference. Note also that the fact that âŠ¥and âŠ¤are not monotypes
in ğ¹ğ‘’
â‰¤is also crucial for this property to hold. However, this property requires a delicate definition
of monotype after bounded quantification is introduced, and we will revisit this in Section 2.3.
2.2
A Tour of Local Type Inference
Local type inference is the most widely used technique for languages with bounded quantification.
To better compare with our work, we will examine a series of examples in Scala 2, which provides
a state-of-the-art implementation of (colored) local type inference [Plociniczak 2016]. Note that the
implementation in Scala 2 contains some improvements compared to the algorithms formalized
by calculi with local type inference [Odersky et al. 2001; Pierce and Turner 2000], enabling more
programs to type-check. We will point out such cases explicitly in the following discussion. Despite
such improvements, well-known limitations of local type inference can still be identified in Scala 21,
including hard-to-synthesize arguments, no best argument, and no support for interdependent bounds.
For readers unfamiliar with the Scala syntax, we explain a few important pieces of syntax first. In
Scala types, => denotes the function type constructor. For instance, Int => Int denotes a function
type whose argument and output are both integers. Variables in square brackets ([A]) are universal
variables, possibly with an extra bound ([A <: Int]) for bounded quantification. At the term level,
=> is part of the syntax of lambda abstractions. For instance, x => x + 1 is the syntax for the
lambda abstraction that increments its argument by one.
Hard-to-synthesize arguments. Local type inference employs two techniques to synthesize types:
local type argument synthesis and bidirectional type checking. But circumstances exist when none
of them can be applied, e.g., when a higher-order function is applied to an anonymous function.
def map[A, B](f: A => B, xs: List[A]): List[B] = ...
def mapPlus1: List[Int] = map(x => 1 + x, List(1, 2, 3))
// fails to type check!
To workaround this issue, the programmer can choose to provide type annotations to the function
argument (as in mapPlus2 ) or provide all the instantiations directly (as in mapPlus3).
def mapPlus2: List[Int] = map((x: Int) => 1 + x, List(1, 2, 3))
def mapPlus3: List[Int] = map[Int, Int](x => 1 + x, List(1, 2, 3))
Another more language-dependent solution is to swap the order of two arguments in the
definition of map as shown below. Because the type-inference algorithm in Scala proceeds left-to-
right, the type information in the first argument helps infer the second one.
1We do not use Scala 3 because its approach to type inference [Martres 2023] seems to be a hybrid combination of local type
inference and some other techniques, which have not been formaly studied. Thus Scala 2 type inference remains more
faithful to the original work [Odersky et al. 2001; Pierce and Turner 2000].
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:7
def map2[A, B](xs: List[A], f: A => B): List[B] = ...
def map2Plus: List[Int] = map2(List(1, 2, 3), x => 1 + x)
No support for interdependent bounds. The only formalized variant of local type inference sup-
porting bounded quantification that we are aware of is by Pierce and Turner [2000]. However, their
work forbids the inference of type arguments with interdependent bounds because they could not
find a complete algorithm that deals with such bounds. Scala 2 does provide some basic support for
interdependent bounds instead of forbidding them, but type checking still fails frequently. This
reveals the difficulty of achieving a complete algorithm that can always succeed in such cases. A
simple example of failing to find instantiations of interdependent bounds in Scala is:
def idFun[A, B <: A => A](x: B): A => A = x
def idInt1: Int => Int = x => x
def idInt2 = idFun(idInt1)
// fails to type check!
In the above example, A and B are instantiated to âŠ¥(i.e. Nothing in Scala) and Int â†’Int. The
instantiation does not conform to the bounded quantification ğµâ‰¤ğ´â†’ğ´since Int â†’Int â‰¤âŠ¥â†’âŠ¥
is not true. This incorrect instantiation found by Scala causes it to reject the program.
No best argument. When the type variable to instantiate appears invariantly in the output type,
but the constraints are not enough to decide a unique instantiation, local type inference fails to
provide any instantiations. Scala still infers a type in such cases, but the type can be meaningless.
For example, the type of id is inferred as âŠ¥â†’âŠ¥in Scala. Thus, id cannot be applied further.
def snd[A]: Int => A => A = x => y => y
def id = snd(1)
Preference for uncurried functions. Local type inference prefers a fully uncurried style in poly-
morphic applications to obtain more constraints of type variables to obtain a precise instantiation.
Sometimes, type checking will fail after making the function curried.
def fst1[A, B](x: A, y: B): A = x
def idInt2: Int => Int = fst1(x => x, 4)
def fst2[A, B]: A => B => A = x => y => x
def idInt3: Int => Int = fst2(x => x)(4)
// fails to type check!
Inference of âŠ¤and âŠ¥. Local type inference can output âŠ¤and âŠ¥directly as a result of constraint
solving, which can often hide possible type errors. Consider:
def fst3[A](x: A, y: A): A = x
def val = fst3(1, true)
The polymorphic function fst3 has type âˆ€ğ‘. ğ‘â†’ğ‘â†’ğ‘and ğ‘is instantiated to âŠ¤(i.e. Any
in Scala) in fst3(1, true) by Scala. It enables applying the function to two values with different
types, which usually contradicts the intention of specifying two arguments with the same type ğ´.
Inferring âŠ¥may allow some programs with other possible type errors to type check. For example:
def fPlus[A](f: A => Int, g: A => Int): A => Int = x => f(x) + g(x)
def useless = fPlus((x: Int) => x + 1, (y: Boolean) => 5)
The inferred type of useless is âŠ¥â†’Int2. Although the type of fPlus expects two functions of
type ğ´â†’Int, the application of fPlus in useless provides two functions with different domain
types. In practice, this situation could correspond to a programmer unintentionally providing two
library functions with different types to the function (perhaps because he did not recall the correct
2To be precise, here Scala 2 infers Int & Boolean â†’Int, since it supports intersection types. However, this intersection
type is morally equivalent to âŠ¥in Scala: we cannot build a value of that type. In a system without intersection types, we
would expect that âŠ¥â†’Int is inferred.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:8
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
types). Note that the instantiation of A is valid here, but it is unlikely to correspond to what the
programmer would expect.
We should remark that, especially in the presence of downcasts, there are situations where
inference of âŠ¤and âŠ¥can be useful. So, there is also an argument for supporting the inference
of such types. For instance, programmers may wish to build a generic container and performing
downcast when extracting its elements. In the example below, ls is inferred to type List[Any] in
Scala without any annotations.
val ls = List(1, 2, "3")
Disabling the implicit inference of âŠ¤would require more boilerplate in such cases, as we would
need to provide type annotations or explicit type instantiations. However, for languages without
downcasts, inference of âŠ¤and âŠ¥would have much more limited benefits, while hiding many
possible type errors that could be caught by other type inference disciplines (such as Hindley-
Milner). Thus, for languages without downcasts, forbidding inference of âŠ¤and âŠ¥seems quite
reasonable. Moreover, this tension between powerful type inference and early detection of errors
has even led language designers to allow programmers to disable the inference of top types. For
instance, Scala has a flag -Xlint:infer-any to disable the implicit inference of âŠ¤.
Higher-rank type inference. The subtyping relation employed in local type inference is basically
the same as ğ¹â‰¤. However, this is restrictive and prohibits type-checking many programs with
higher-rank types. The definition of g is valid in Scala 3 (but not in Scala 2, which does not support
higher-rank types), but the application g(k) is still rejected by Scala 3 because it would require â‰¤âˆ€L
in the subtyping relation (Int â†’Int) â†’Int â‰¤(âˆ€(ğ‘â‰¤Int). ğ‘â†’ğ‘) â†’Int.
def k(f: (Int => Int)) = 1
def g(f: ([A <: Int] => A => A) => Int) = 1
def f = g(k)
// fails to type check!
2.3
Key Ideas in our Work
Comparing Local Type Inference with ğ¹ğ‘
â‰¤. Table 1 shows examples in Section 2.2 that behave
differently in ğ¹ğ‘
â‰¤. With global type inference, ğ¹ğ‘
â‰¤is capable of dealing with long-distance constraints.
Therefore, ğ¹ğ‘
â‰¤can type the application examples mentioned in Section 2.2 without annotations,
which fail in local type inference. For instance, the map example works well in ğ¹ğ‘
â‰¤. In addition, since
ğ¹ğ‘
â‰¤does not infer âŠ¤and âŠ¥, the applications involving fst3 and fPlus fail. Higher-rank polymorphic
examples, such as g, are also accepted. In ğ¹ğ‘
â‰¤interdependent bounds are not problematic, so the
application of idFun works and finds the correct instantiation.
A restriction in ğ¹ğ‘
â‰¤is that it cannot infer instantiations using type variables with monotype
bounds. The following code type checks in Scala, while it is rejected in ğ¹ğ‘
â‰¤:
def idBnd[A <: Int](x: A) = fst1(x, x)
In ğ¹ğ‘
â‰¤, an explicit type application (fst1 @ğ‘ğ‘¥ğ‘¥) is needed, when the instantiation is a type variable
a with the monotype bound like Int. Section 5 shows a variant of ğ¹ğ‘
â‰¤that can accept this program,
and in general can infer more instantiations, but loses completeness. However, note that if the
bound of a is Top in fst1 ğ‘¥ğ‘¥, the implicit instantiation still succeeds because in that case a is
considered to be a monotype.
In what follows we discuss the key ideas and design decisions in ğ¹ğ‘
â‰¤, starting by motivating its
definition of monotypes, followed by other key technical ideas.
Non-syntactic monotypes. Previous works [Dunfield and Krishnaswami 2013; Odersky and LÃ¤ufer
1996; Peyton Jones et al. 2007; Zhao and Oliveira 2022] on predicative HRP determine monotypes
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:9
Table 1. Examples used in the comparison of local type inference with ğ¹ğ‘
â‰¤
ğ¹ğ‘
â‰¤program
Accepted or not
let map: âˆ€(ğ‘â‰¤âŠ¤). âˆ€(ğ‘â‰¤âŠ¤). (ğ‘â†’ğ‘) â†’[ğ‘] â†’[ğ‘] = ...
in map (ğœ†ğ‘¥. ğ‘¥+ 1) [1, 2, 3]
âœ“
let idFun: âˆ€(ğ‘â‰¤âŠ¤). âˆ€(ğ‘â‰¤ğ‘â†’ğ‘). ğ‘â†’ğ‘â†’ğ‘= Î›ğ‘. Î›ğ‘. ğœ†ğ‘¥. ğ‘¥,
idInt: Int â†’Int = ğœ†ğ‘¥. ğ‘¥in idFun idInt
âœ“
let snd: âˆ€(ğ‘â‰¤âŠ¤). Int â†’(ğ‘â†’ğ‘) â†’ğ‘â†’ğ‘= Î›ğ‘. ğœ†ğ‘¥. ğœ†ğ‘¦. ğ‘¦
in snd 1
âœ“
let fst3: âˆ€(ğ‘â‰¤âŠ¤). ğ‘â†’ğ‘â†’ğ‘= Î›ğ‘. ğœ†ğ‘¥. ğœ†ğ‘¦. ğ‘¥
in fst3 1 true
âœ—
let fPlus: âˆ€(ğ‘â‰¤âŠ¤). (ğ‘â†’Int) â†’(ğ‘â†’Int) â†’Int =
Î›ğ‘. ğœ†ğ‘“. ğœ†ğ‘”. ğœ†ğ‘¥. ğ‘“ğ‘¥+ ğ‘”ğ‘¥
in fPlus ((ğœ†ğ‘¥. ğ‘¥+ 1) : Int â†’Int) ((ğœ†ğ‘¦. 5) : Bool â†’Int)
âœ—
let k: (Int â†’Int) â†’Int = ğœ†ğ‘“. 1,
g: ((âˆ€(ğ‘â‰¤Int). ğ‘â†’ğ‘) â†’Int) â†’Int = ğœ†ğ‘“. 1 in g k
âœ“
let fst1: âˆ€(ğ‘â‰¤âŠ¤). âˆ€(ğ‘â‰¤âŠ¤). ğ‘â†’ğ‘â†’ğ‘= Î›ğ‘. Î›ğ‘. ğœ†ğ‘¥. ğœ†ğ‘¦. ğ‘¥
in (Î›ğ‘. ğœ†ğ‘¥. fst1 ğ‘¥ğ‘¥) : âˆ€(ğ‘â‰¤Int). ğ‘â†’ğ‘
âœ—
... in (Î›ğ‘. ğœ†ğ‘¥. fst1 @ğ‘ğ‘¥ğ‘¥) : âˆ€(ğ‘â‰¤Int). ğ‘â†’ğ‘
âœ“
... in (Î›ğ‘. ğœ†ğ‘¥. fst1 ğ‘¥ğ‘¥) : âˆ€(ğ‘â‰¤âŠ¤). ğ‘â†’ğ‘
âœ“
syntactically. In particular, they treat all type variables as monotypes. Simply adopting the same
idea in a system extending the subtyping relation in Figure 1 with bounded quantification would
break subtyping transitivity. The reader can look at the subtyping relation in Figure 2, which
provides such an extension and simply assume, for the sake of our argument, that all type variables
are monotypes. A counterexample that illustrates that transitivity does not hold is described next.
Let ğ´= âˆ€(ğ‘â‰¤âŠ¤). ğ‘, ğµ= ğ‘,ğ¶= âˆ€(ğ‘â‰¤1). ğ‘â†’1 and Î¨ = Â·,ğ‘â‰¤âˆ€(ğ‘â‰¤1). ğ‘â†’1. Both Î¨ âŠ¢ğ´â‰¤ğµ
and Î¨ âŠ¢ğµâ‰¤ğ¶hold as shown in the following derivations. But Î¨ âŠ¢ğ´â‰¤ğ¶is invalid because the
two bounds (âŠ¤and 1) are not equivalent, which is required by kernel ğ¹â‰¤when comparing bounds.
â€¢ Î¨ âŠ¢ğ´â‰¤ğµ:
ğ‘â‰¤âˆ€(ğ‘â‰¤1). ğ‘â†’1 âŠ¢ğ‘â‰¤âŠ¤
ğ‘â‰¤âˆ€(ğ‘â‰¤1). ğ‘â†’1 âŠ¢ğ‘â‰¤ğ‘
ğ‘â‰¤âˆ€(ğ‘â‰¤1). ğ‘â†’1 âŠ¢âˆ€(ğ‘â‰¤âŠ¤). ğ‘â‰¤ğ‘
by â‰¤âˆ€L
â€¢ Î¨ âŠ¢ğµâ‰¤ğ¶:
ğ‘â‰¤âˆ€(ğ‘<: 1). ğ‘â†’1 âŠ¢ğ‘â‰¤âˆ€(ğ‘<: 1). ğ‘â†’1 by â‰¤VarTrans
â€¢ Î¨ âŠ¢ğ´Ì¸â‰¤ğ¶:
âˆ€(ğ‘â‰¤âŠ¤). ğ‘Ì¸â‰¤âˆ€(ğ‘<: 1). ğ‘â†’1
The reason is the interplay between rule â‰¤âˆ€L and â‰¤VarTrans: type variables are used as mono-
types for instantiation in rule â‰¤âˆ€L, but they can be transformed into universal types using the
â‰¤VarTrans and used in other subtyping judgments. Similar problems happen if a type variable with
bound âŠ¥is used as a monotype. To avoid breaking transitivity, we need to regard type variables
with such bounds as non-monotypes to forbid instantiating such type variables with rule â‰¤âˆ€L.
Can we then regard type variables with a monotype or âŠ¤bound as monotypes? For transitivity,
and other essential properties such as type safety and soundness of the algorithmic system, such a
definition of monotypes is fine (as shown in Section 5.1). Sadly, with greedy instantiation, monotype
bounds are still problematic for a different reason. Recall the important property to ensure that
greedy instantiations always work: Î¨ âŠ¢ğœ1 â‰¤ğœ2 implies ğœ1 = ğœ2. This property is broken if we
treat type variables with a monotype bound as a monotype. The counterexample is obvious,
Â·,ğ‘â‰¤1 âŠ¢ğ‘â‰¤1, but ğ‘â‰ 1. Allowing monotypes to include type variables with bounds other than âŠ¤
results in an incomplete greedy algorithm. To solve the abovementioned issues, all type variables
with bound other than âŠ¤are considered non-monotypes, i.e., they cannot be implicitly instantiated
with rule â‰¤âˆ€L. In other words, our definition of monotypes is no longer purely syntactic.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:10
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
Matching and type-application inferenceâ€“judgments. An important property that our completeness
result depends on is a subsumption theorem. The proof of the subsumption theorem needs us to
generalize the lemma to all kinds of judgments first and then prove them simultaneously. With
many new cases added due to bounded quantification, the proof becomes complex. We develop two
new kinds of judgment, namely matching and type application inference, to disentangle the proof.
The matching judgment is inspired by Siek et al. [2015] to replace the application inference used by
Zhao and Oliveira [2022] and Dunfield and Krishnaswami [2013]. The type-application inferenceâ€“
judgment unifies all the cases with type application and reduces the number of cases in inference
judgments. These two judgments are defined independently from checking and inference judgments,
and their metatheory can be established independently. With the help of these two judgments and
their independently proved metatheory, our final generalized lemma for subsumption only requires
a 2-fold mutual induction with much fewer cases rather than a potential 4-fold mutual induction.
Polytype splitting and decidability. Previous works on type inference for implicit HRP [Dunfield
and Krishnaswami 2013; Zhao and Oliveira 2022; Zhao et al. 2019] adopt the following (simplified)
rule when comparing an existential (unification) variable with an arrow type in subtyping: split an
existential variable into two fresh ones to solve the domain and codomain type separately.
bğ›¼â‰¤ğ´â†’ğµ
reduces to
bğ›¼1 â†’bğ›¼2 â‰¤ğ´â†’ğµ
when bğ›¼âˆ‰ğ¹ğ‘‰(ğ´â†’ğµ)
This rule poses difficulties in proving decidability because it increases the number of existential
variables by one without decreasing any other measures instantly. To solve this issue, previous
work employs concepts such as instantiation judgments bğ›¼â‰¤ğ´and ğ´â‰¤bğ›¼and prove (1) each
reduction procedure of these instantiation judgments is decidable because the type size decreases;
(2) after an instantiation judgment is fully reduced, the overall measure will also decrease. This
intermediate decision procedure, that each instantiation judgment will reduce the overall measure
after an indefinite number of steps, creates complexity in the decidability proof.
We observe that it is unnecessary to split the existential variable when ğ´â†’ğµis a monotype.
Instead, we can always solve bğ›¼using the monotype ğ´â†’ğµdirectly, i.e., substitute every occurrence
of bğ›¼with ğ´â†’ğµ, and split only when ğ´â†’ğµis a polytype. This modification, named polytype
splitting, allows us to develop a measure | Â· |â†’to track the maximum possible number of splits of
a type statically. With the help of this new measure, the entire measure of our algorithm always
decreases after a constant number of reduction steps, so the proof of decidability is greatly simplified.
Another challenge is to combine the measure used to prove the decidability of kernel ğ¹â‰¤with
that of worklist algorithms. The weight measure for ğ¹â‰¤[Pierce 2002], is not compatible with the
existential variables in worklists: the weight could increase arbitrarily after solving an existential
with a monotype. To address this challenge, we develop a lexicographic group of four measures on
the worklist. The first three in the group are (almost) unaffected by existential-variable solving,
and the last one is a simplified version of the weight.
Worklist substitution. A complication that arises in HRP type-inference algorithms is that exis-
tential (unification) variables sometimes need to have their scope widened. However, changing
the scope of an existential variable may require changing the scope of other existential variables
recursively. To help with this process and simplify the type-inference algorithm, we employ a
revised substitution procedure to deal with the variable insertion, removal, and worklist reordering
after solving an existential variable with another monotype. The rules and notations for the type-
inference algorithm can be presented more concisely and clearly since the scope management for
existential variables is encapsulated within the worklist substitution. The lemmas related to these
cases in the soundness, completeness, and decidability proof can also be stated in a unified manner
to provide more intuition on the properties of our system.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:11
3
DECLARATIVE SYSTEM
This section introduces a declarative type system for ğ¹ğ‘
â‰¤, which serves as a specification for the
algorithmic version that will be presented in Section 4. The type system extends Zhao and Oliveira
[2022]â€™s ğ¹ğ‘’
â‰¤type system by adding bounded quantification [Cardelli and Wegner 1985]. Several
important properties of the subtyping and typing relation are stated and discussed, especially the
transitivity of subtyping and the subsumption of typing, which are significantly complicated by
the addition of bounded quantification.
3.1
Syntax, Monotypes, and Well-Formedness
Type variables
ğ‘,ğ‘
Types
ğ´, ğµ,ğ¶
::=
1 | ğ‘| âˆ€(ğ‘â‰¤ğµ). ğ´| ğ´â†’ğµ| âŠ¤| âŠ¥
Expressions
ğ‘’,ğ‘¡
::=
ğ‘¥| () | ğœ†ğ‘¥. ğ‘’| ğ‘’1 ğ‘’2 | (ğ‘’: ğ´) | ğ‘’@ğ´| Î›(ğ‘â‰¤ğµ). ğ‘’: ğ´
Typing contexts
Î”
::=
Â· | Î”,ğ‘¥: ğ´| Î”,ğ‘â‰¤ğ´
Subtyping contexts
Î¨
::=
Î” | Î¨,ğ‘â‰²ğ´
The syntax of ğ¹ğ‘
â‰¤is shown above. Compared to ğ¹ğ‘’
â‰¤, universal types âˆ€(ğ‘â‰¤ğµ). ğ´and type
abstractions Î›(ğ‘â‰¤ğµ). ğ‘’: ğ´now incorporate a bound ğµto support bounded quantification. Type
application (ğ‘’@ğ´) is inherited from ğ¹ğ‘’
â‰¤. The remaining expression and type syntax is standard.
Differently from ğ¹ğ‘’
â‰¤, there are two kinds of contexts in ğ¹ğ‘
â‰¤: typing context Î” and subtyping
context Î¨. This change is to enforce some expected invariants. Firstly, subtype variables should
not occur in typing and typing contexts. Secondly, only subtype variables will be added to the
context in subtyping. Thus, a subtyping context should be a typing context prefix followed by
a collection of subtype variables. Consequently, the bound of a type variable cannot depend on
a subtype variable. Despite having no major consequences for the formalization in terms of the
properties of the system, none of these invariants are enforced in ğ¹ğ‘’
â‰¤. In contrast, they are enforced
in ğ¹ğ‘
â‰¤. With this new design, ğ¹ğ‘
â‰¤distinguishes type variables from subtype variables by the entries
in the contexts (ğ‘â‰¤ğ´or ğ‘â‰²ğ´) rather than by a syntactic distinction of ğ‘and Ëœğ‘as in ğ¹ğ‘’
â‰¤. The
entries also keep track of the bound for (sub)type variables. For convenience, we sometimes use the
notation ğ‘<â‰ƒğ´to represent both ğ‘â‰¤ğ´and ğ‘â‰²ğ´entries in subtyping contexts. The key syntactic
differences to ğ¹ğ‘’
â‰¤are marked in gray.
Monotypes. The definition of monotypes plays a central role in ğ¹ğ‘
â‰¤, and it requires significant
changes in comparison to previous calculi with predicative implicit instantiation [Dunfield and
Krishnaswami 2013, 2019; Odersky and LÃ¤ufer 1996; Peyton Jones et al. 2007]. Monotypes are no
longer defined syntactically due to the presence of bounds. Instead, we need a dedicated judgment
to decide whether a type variable is a monotype or not: only unbounded type variables (the upper
bound is âŠ¤) are allowed. The new monotype relation needs to take the context Î¨ as input to perform
the bound lookup. The remaining cases of the monotype definition are standard, as shown in the
top part of Figure 2. For brevity, we will use conventional symbols ğœ, ğœto represent monotypes in
Î¨ âŠ¢ğ‘šğœand sometimes omit Î¨ when it is clear what the context is.
Well-formedness. Well-formedness (listed in the extended version of the paper) ensures the well-
scopedness of binders. After adding bounded quantification, we need to check the well-formedness
of the bounds in certain rules. We also inherit the free-variable checks in Zhao and Oliveira [2022]
to ensure that the polymorphic type âˆ€(ğ‘â‰¤ğµ). ğ´is indeed polymorphic. It is worth noting that if
the type variable appears in the bound of a nested universal type, it also passes the free-variable
check, i.e., the type âˆ€(ğ‘â‰¤âŠ¤). âˆ€(ğ‘â‰¤ğ‘). ğ‘â†’ğ‘is regarded as a well-formed type in ğ¹ğ‘
â‰¤.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:12
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
Î¨ âŠ¢ğ‘šğ´
A is a monotype
Î¨ âŠ¢ğ‘š1
MUnit
Î¨ âŠ¢ğ‘šğ´
Î¨ âŠ¢ğ‘šğµ
Î¨ âŠ¢ğ‘šğ´â†’ğµ
Mâ†’
ğ‘â‰¤âŠ¤âˆˆÎ¨
Î¨ âŠ¢ğ‘šğ‘
MTVar
Î¨ âŠ¢ğ´â‰¤ğµ
A is a subtype of B
Î¨ âŠ¢1 â‰¤1
â‰¤Unit
Î¨ âŠ¢ğ´â‰¤âŠ¤
â‰¤âŠ¤
Î¨ âŠ¢âŠ¥â‰¤ğ´
â‰¤âŠ¥
ğ‘<â‰ƒğµâˆˆÎ¨
Î¨ âŠ¢ğ‘â‰¤ğ‘
â‰¤Var
ğ‘<â‰ƒğµâˆˆÎ¨
Î¨ âŠ¢ğµâ‰¤ğ´
Î¨ âŠ¢ğ‘â‰¤ğ´
â‰¤VarTrans
Î¨ âŠ¢ğµ1 â‰¤ğ´1
Î¨ âŠ¢ğ´2 â‰¤ğµ2
Î¨ âŠ¢ğ´1 â†’ğ´2 â‰¤ğµ1 â†’ğµ2
â‰¤â†’
Î¨ âŠ¢ğœ
Î¨ âŠ¢ğ‘šğœâ‰¤ğµ
Î¨ âŠ¢[ğœ/ğ‘]ğ´â‰¤ğ¶
ğ¶is not a âˆ€type
Î¨ âŠ¢âˆ€(ğ‘â‰¤ğµ). ğ´â‰¤ğ¶
â‰¤âˆ€L
Î¨ âŠ¢ğµ1 â‰¤ğµ2
Î¨ âŠ¢ğµ2 â‰¤ğµ1
Î¨,ğ‘â‰²ğµ2 âŠ¢ğ´1 â‰¤ğ´2
Î¨ âŠ¢âˆ€(ğ‘â‰¤ğµ1). ğ´1 â‰¤âˆ€(ğ‘â‰¤ğµ2). ğ´2
â‰¤âˆ€
Fig. 2. Declarative Monotype and Subtyping
3.2
Subtyping
Figure 2 shows the rules of subtyping relation. Most rules are inherited from ğ¹ğ‘’
â‰¤. Rules â‰¤âŠ¤, â‰¤âŠ¥
and â‰¤â†’are standard subtyping rules for calculi with âŠ¤, âŠ¥and function types. Rule â‰¤Var is
the reflexivity rule for (sub)type variables. The remaining rules are key to supporting bounded
quantification. Rule â‰¤âˆ€L states that a universal type is a subtype of another (non-universal) type ğ¶
as long as we can find a monotype ğœthat satisfies the bound ğµ, such that the instantiated body is
the subtype of ğ¶. This rule differs from previous rules in the literature [Dunfield and Krishnaswami
2013; Zhao and Oliveira 2022] in that the monotype is not only required to be well-formed but
also a subtype of the bound ğµ. By checking that Î¨ âŠ¢ğœâ‰¤ğµ, we prevent incorrect instantiations
that do not satisfy the bounds. Rule â‰¤âˆ€states that two universal types are subtypes if their bodies
are subtypes and their bounds are mutual subtypes of each other. This rule is adopted from the
equivalent type variant of kernel ğ¹â‰¤[Pierce 2002; Zhou et al. 2023] to support more flexible bound
comparison. Since we include bottom types, the subtyping relation is not antisymmetric like the
original ğ¹â‰¤, e.g., a type variable with a bottom bound and the bottom type are subtypes of each
other. Thus, the rule used here is more adequate. The extra condition â€œğ¶is not a âˆ€typeâ€ in rule
â‰¤âˆ€L ensures that rule â‰¤âˆ€always takes priority when both sides are universal types. Finally, rule
â‰¤VarTrans allows comparing a (sub)type variable with a type ğ´as long as its bound ğµcan be
compared with this type. It is a standard rule in a type system with bounded quantification. The
reflexivity and transitivity property hold for this subtyping relation:
Theorem 3.1 (Subtyping Reflexivity). Given Î¨ âŠ¢ğ´, Î¨ âŠ¢ğ´â‰¤ğ´.
Theorem 3.2 (Subtyping Transitivity). Given Î¨ âŠ¢ğ´, Î¨ âŠ¢ğµ, and Î¨ âŠ¢ğ¶, if Î¨ âŠ¢ğ´â‰¤ğµ, and
Î¨ âŠ¢ğµâ‰¤ğ¶then Î¨ âŠ¢ğ´â‰¤ğ¶.
3.3
Typing
The top part of Figure 3 shows the declarative type system with the checking and inference judg-
ments. Most rules are standard in existing bidirectional type systems with higher-rank predicative
type inference [Dunfield and Krishnaswami 2013]. However, there are a few differences.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:13
Firstly, we do not include a rule that checks against a universal type:
Î”,ğ‘âŠ¢ğ‘’â‡ğ´
Î” âŠ¢ğ‘’â‡âˆ€ğ‘. ğ´
Here, we omit bounded quantification for a clearer comparison with previous work. Such a rule is
common in previous work [Dunfield and Krishnaswami 2013; Zhao and Oliveira 2022]. It allows
implicit definitions of polymorphic functions, where type variables do not need to be explicitly
bound at the term level. We drop this checking rule because it seems more appropriate for type
systems where the order of bound universal variables is irrelevant, which is not the case in ğ¹ğ‘
â‰¤.
Consider the following checking judgment that holds with the above rule:
Â· âŠ¢Î›ğ‘.(Î›ğ‘.(ğœ†ğ‘¥. ğœ†ğ‘¦. .ğ‘¥) : âˆ€ğ‘.ğ‘â†’ğ‘â†’ğ‘) : âˆ€ğ‘.âˆ€ğ‘.ğ‘â†’ğ‘â†’ğ‘â‡âˆ€ğ‘.âˆ€ğ‘.ğ‘â†’ğ‘â†’ğ‘
However, âˆ€ğ‘.âˆ€ğ‘.ğ‘â†’ğ‘â†’ğ‘is not a subtype of âˆ€ğ‘.âˆ€ğ‘.ğ‘â†’ğ‘â†’ğ‘according to the subtyping rela-
tion since the order of the binders matters in ğ¹ğ‘
â‰¤. In ğ¹ğ‘
â‰¤, explicit type abstractions (Î›(ğ‘â‰¤ğµ). ğ‘’: ğ´)
are the only way to define polymorphic functions, aligning better with calculi with local type
inference and with languages like Scala or Java. The consequence of removing this rule is that
lambda expressions annotated with a forall type are no longer accepted, e.g., ğœ†ğ‘¥. ğ‘¥: âˆ€ğ‘. ğ‘â†’ğ‘.
Programmers must explicitly convert such expressions to Î› expressions. Since explicit type abstrac-
tion is more powerful than the implicit one by allowing scoped type variables [Peyton Jones and
Shields 2004; Zhao et al. 2019], no expressivity is lost.
Secondly, rule â‡â†’âŠ¤is added to check a lambda expression against âŠ¤. In ğ¹ğ‘’
â‰¤, there is a rule that
allows any well-formed expression to check against the top type. So, some peculiar expressions,
which seem nonsensical, e.g. () () : âŠ¤, can also be type checked. The ğ¹ğ‘’
â‰¤rule is type safe, since no
information can be extracted from an expression annotated with âŠ¤. However, we believe it is more
intuitive to completely reject any nonsensical expressions in ğ¹ğ‘
â‰¤. Therefore, in rule â‡â†’âŠ¤, we use
the greatest function type in the subtyping lattice (âŠ¥â†’âŠ¤) to type-check the lambda expression.
This allows us to prevent nonsensical lambda expressions from being accepted when checked
against âŠ¤. Checking the remaining expressions against âŠ¤, including (), ğ‘¥, ğ‘’: ğ´, Î›(ğ‘â‰¤ğµ). ğ‘’: ğ´,
and ğ‘’1 ğ‘’2 is now handled by the subsumption rule.
Finally, there are two new judgments. The inference of application depends on the matching
judgment Î” âŠ¢ğ´âŠ²ğµâ†’ğ¶. Note that this judgment differs from the judgment used in ğ¹ğ‘’
â‰¤or Dunfield
and Krishnaswami [2013]. In addition, the inference of type applications is unified into a single
rule â‡’TApp and depends on the new type-application inferenceâ€“judgment Î” âŠ¢ğ´â—¦ğµâ‡’â‡’ğ¶. Both
of these judgments are discussed next.
Matching. The matching judgment Î” âŠ¢ğ´âŠ²ğµâ†’ğ¶in Figure 3 states that a type ğ´can be regarded
as an arrow type ğµâ†’ğ¶, and thus a term of type ğ´can be applied to another term of type ğµand
have the result type be ğ¶. It was first proposed by Siek et al. [2015] and extended to polymorphic
types [Xie et al. 2019] by guessing instantiations until reaching an arrow type. The rules âŠ²âˆ€and
âŠ²â†’are similar to those in Xie et al. [2019]. In rule âŠ²âˆ€, a monotype ğœthat satisfies the bound is
guessed, and the judgment is applied to the instantiated universal type recursively.
Rule âŠ²âŠ¥and âŠ²Var are newly added to support âŠ¥and bounded quantification. Since a term of
type âŠ¥can be applied to any well-typed term, and the result type is still âŠ¥, âŠ¥should match âŠ¤â†’âŠ¥,
the least function type in the subtyping lattice, as stated in âŠ²âŠ¥. With bounded quantification, it is
also possible for type variables to match an arrow type. This case is dealt with by rule âŠ²Var, which
states that as long as the bound of a type variable can match an arrow type, the type variable itself
can match this arrow type.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:14
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
Î” âŠ¢ğ‘’â‡”ğ´
ğ‘’is checked against/infers ğ´
(ğ‘¥: ğ´) âˆˆÎ”
Î” âŠ¢ğ‘¥â‡’ğ´
â‡’Var
Î” âŠ¢ğ‘’â‡’ğ´
Î” âŠ¢ğ´â‰¤ğµ
Î” âŠ¢ğ‘’â‡ğµ
â‡Sub
Î” âŠ¢ğ´
Î” âŠ¢ğ‘’â‡ğ´
Î” âŠ¢(ğ‘’: ğ´) â‡’ğ´
â‡’Anno
Î” âŠ¢ğœâ†’ğœ
Î”,ğ‘¥: ğœâŠ¢ğ‘’â‡ğœ
Î” âŠ¢ğœ†ğ‘¥. ğ‘’â‡’ğœâ†’ğœ
â‡’â†’Mono
Î”,ğ‘¥: ğ´âŠ¢ğ‘’â‡ğµ
Î” âŠ¢ğœ†ğ‘¥. ğ‘’â‡ğ´â†’ğµ
â‡â†’
Î”,ğ‘¥: âŠ¥âŠ¢ğ‘’â‡âŠ¤
Î” âŠ¢ğœ†ğ‘¥. ğ‘’â‡âŠ¤
â‡â†’âŠ¤
Î” âŠ¢() â‡’1
â‡’Unit
Î”,ğ‘â‰¤ğµâŠ¢ğ‘’â‡ğ´
Î” âŠ¢ğµ
ğ‘âˆˆFV(ğ´)
Î” âŠ¢Î›(ğ‘â‰¤ğµ). ğ‘’: ğ´â‡’âˆ€(ğ‘â‰¤ğµ). ğ´
â‡’Î›
Î” âŠ¢ğ‘’1 â‡’ğ´
Î” âŠ¢ğ´âŠ²ğµâ†’ğ¶
Î” âŠ¢ğ‘’2 â‡ğµ
Î” âŠ¢ğ‘’1 ğ‘’2 â‡’ğ¶
â‡’App
Î” âŠ¢ğ‘’â‡’ğ´
Î” âŠ¢ğ´â—¦ğµâ‡’â‡’ğ¶
Î” âŠ¢ğµ
Î” âŠ¢ğ‘’@ ğµâ‡’ğ¶
â‡’TApp
Î” âŠ¢ğ´âŠ²ğµâ†’ğ¶
A matches an arrow type ğµâ†’ğ¶
Î” âŠ¢âŠ¥âŠ²âŠ¤â†’âŠ¥
âŠ²âŠ¥
Î” âŠ¢ğ´â†’ğµâŠ²ğ´â†’ğµ
âŠ²â†’
Î” âŠ¢ğœâ‰¤ğµ
Î” âŠ¢ğœ
Î” âŠ¢[ğœ/ğ‘]ğ´âŠ²ğ¶â†’ğ·
Î” âŠ¢âˆ€(ğ‘â‰¤ğµ). ğ´âŠ²ğ¶â†’ğ·
âŠ²âˆ€
ğ‘â‰¤ğ¶âˆˆÎ”
Î” âŠ¢ğ¶âŠ²ğ´â†’ğµ
Î” âŠ¢ğ‘âŠ²ğ´â†’ğµ
âŠ²Var
Î” âŠ¢ğ´â—¦ğµâ‡’â‡’ğ¶
A type-applied to B infers C
Î” âŠ¢âŠ¥â—¦ğ´â‡’â‡’âŠ¥
â—¦â‡’â‡’âŠ¥
Î” âŠ¢ğ¶â‰¤ğµ
Î” âŠ¢âˆ€(ğ‘â‰¤ğµ). ğ´â—¦ğ¶â‡’â‡’[ğ¶/ğ‘]ğ´
â—¦â‡’â‡’âˆ€
ğ‘â‰¤ğ¶âˆˆÎ”
Î” âŠ¢ğ¶â—¦ğ´â‡’â‡’ğµ
Î” âŠ¢ğ‘â—¦ğ´â‡’â‡’ğµ
â—¦â‡’â‡’Var
Fig. 3. Matching and Type-Application Inference.
The key reason to use matching instead of the application-inference judgment, Î” âŠ¢ğ´â€¢ ğ‘’â‡’â‡’ğ¶
due to Dunfield and Krishnaswami [2013], is that the matching judgment is a pure type-level
relation and, thus, independent of the checking and inference rules. On the contrary, the application
inference judgment, which is also used in ğ¹ğ‘’
â‰¤, is mutually defined together with the checking
and inference judgments. Unfortunately, in a system with bounded quantification, this becomes
problematic as properties such as subsumption become much more entangled with other properties,
making proofs difficult. By decoupling matching from inference and checking, we are able to prove
many properties for matching independently, greatly simplifying our proofs.
Type application inference. The type-application inferenceâ€“judgment Î” âŠ¢ğ´â—¦ğµâ‡’â‡’ğ¶at the
bottom of Figure 6 states that a type ğ´can be regarded as a universal or âŠ¥type so that it can be
type-applied to type ğµ, and the result type isğ¶. This judgment generalizes the two rules âŠ¥@ ğ´â‡’âŠ¥
and âˆ€ğ‘.ğ´@ ğµâ‡’[ğµ/ğ‘]ğ´used by Zhao and Oliveira [2022]. It can be easily extended to support
new cases, i.e. rule â—¦â‡’â‡’Var, that is added due to bounded quantification. This rule allows type-level
variables to be type-applied when their bounds can be type-applied. Type-application inference is
also a pure type-level relation independent of checking and inference rules.
Checking subsumption. An important property that holds for the typing relation is:
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:15
Theorem 3.3 (Checking Subsumption). Given âˆ†âŠ¢B, if âˆ†âŠ¢e â‡A and âˆ†âŠ¢A â‰¤B, then âˆ†âŠ¢e â‡B.
3.4
Metatheory
In this section, we discuss the most interesting aspects of the metatheory of the declarative type
system. In particular, we discuss the challenges that emerge after the introduction of bounded
quantification.
Subtyping Transitivity. The proof of subtyping transitivity proceeds by induction on the first
subtyping relation. The tricky case is the â‰¤âˆ€rule, i.e. Î¨ âŠ¢âˆ€(ğ‘â‰¤ğ·1). ğ´â‰¤âˆ€(ğ‘â‰¤ğ·2). ğµâ‰¤ğ¶. When
ğ¶is also a universal type âˆ€(ğ‘â‰¤ğ·3). ğ¶â€², a subtyping narrowing lemma is required to replace the
bound ğ·2 with the equivalent type ğ·3 in the â‰¤âˆ€derivation Î¨,ğ‘â‰²ğ·2 âŠ¢ğ´â‰¤ğµ. This is similar to the
transitivity proof in the algorithmic version of full ğ¹<: without a built-in transitivity rule [Pierce
2002]. When ğ¶is not a universal type, with the rule â‰¤âˆ€L, there exists ğœs.t. Î¨ âŠ¢ğœâ‰¤ğ·3 and
Î¨ âŠ¢[ğœ/ğ‘]ğµâ‰¤ğ¶, and thus we need a subtyping stability lemma to substitute ğ‘with ğœin the above
â‰¤âˆ€derivation. Both the narrowing and stability lemmas are mutually dependent on the transitivity
lemma and must be proven simultaneously. In the proofs of both lemmas, the transitivity has to be
applied when ğ´is a subtype variable due to the rule â‰¤VarTrans.
Lemma 3.4 (Subtyping Narrowing and Stability). Given all types and contexts well-formed,
(1) If Î¨1, a â‰²D, Î¨2 âŠ¢A â‰¤B and Î¨1 âŠ¢C â‰¤D, then Î¨1, a â‰²C, Î¨2 âŠ¢A â‰¤B.
(2) If Î¨1, a â‰²D, Î¨2 âŠ¢A â‰¤B and Î¨1 âŠ¢C â‰¤D, then Î¨1, [C/a]Î¨2 âŠ¢[C/a]A â‰¤[C/a]B.
Subsumption. To prove the subsumption lemma, we first prove the subsumption lemmas for
matching and the type-application inferenceâ€“judgment independently.
Lemma 3.5 (Matching and Type-Application Inferenceâ€“Subsumption). Given all types and
contexts well-formed,
(1) If âˆ†âŠ¢A âŠ²B â†’C and âˆ†âŠ¢Aâ€² â‰¤A, then âˆƒBâ€², Câ€² s.t. Î” âŠ¢ğ´â€² âŠ²ğµâ€² â†’ğ¶â€² and âˆ†âŠ¢Bâ€² â†’Câ€² â‰¤B â†’C.
(2) If âˆ†âŠ¢A â—¦B â‡’â‡’C and âˆ†âŠ¢Aâ€² â‰¤A, then âˆƒCâ€² s.t. âˆ†âŠ¢Aâ€² â—¦B â‡’â‡’Câ€² and âˆ†âŠ¢Câ€² â‰¤C.
With the above two lemmas proved, we then adopt the proof technique used by Zhao et al. to
prove the subsumption lemma, which generalizes the subsumption theorem by (1) extending the
property to both checking and inference judgments; (2) introducing a sub-context relation Î”â€² <: Î”.
The sub-context is defined on typing context only and requires the bound of corresponding type
variables in Î” and Î”â€² to be the same.
Î”â€² <: Î”
Sub-context
Â· <: Â·
Î”â€² <: Î”
Î”â€²,ğ‘â‰¤ğ´<: Î”,ğ‘â‰¤ğ´
Î”â€² <: Î”
Î” âŠ¢ğ´â‰¤ğµ
Î”â€²,ğ‘¥: ğ´<: Î”,ğ‘¥: ğµ
The most general form of the subsumption lemma is:
Lemma 3.6 (Checking and Inference Subsumption). Given âˆ†â€² <: âˆ†
(1) if âˆ†âŠ¢e â‡A, âˆ†âŠ¢Aâ€², and âˆ†âŠ¢A â‰¤Aâ€², then âˆ†â€² âŠ¢e â‡Aâ€²;
(2) if âˆ†âŠ¢e â‡’A, then âˆƒAâ€² s.t. âˆ†âŠ¢Aâ€² â‰¤A and âˆ†â€² âŠ¢e â‡’Aâ€².
It is not hard to observe that if Î”â€² <: Î”, any matching and type application judgment that holds
in Î” also holds in Î”â€² and vice versa since the changes in the bound of variables ğ‘¥do not affect these
two pure type-level judgments. Thus, the subsumption proved for matching and type-application
inference can be used in the proof this generalized lemma with the premise Î”â€² <: Î”.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:16
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
The form of our subsumption lemmas is simpler than that used by Dunfield and Krishnaswami
[2013]; Zhao and Oliveira [2022]. The primary source of simplification comes from the use of the
matching judgment, inspired by the work of [Xie et al. 2019]. The metatheory of the matching
judgment can be developed independently of checking and inference. We initially tried to use the
same approach as Zhao and Oliveira, but the proof became too intricate due to several mutual
dependencies between various lemmas.
Type Safety and Completeness to kernel ğ¹â‰¤. The type safety of our type system is derived via an
elaboration to System ğ¹by taking a coercive interpretation [Breazu-Tannen et al. 1991]: a proof of
subtyping relation ğ‘: ğ´â‰¤ğµis elaborated into a term ğ‘’: |ğ´| â†’|ğµ| (| Â· | indicates type translation).
The translation of types and contexts to mitigate the syntax gap is adopted from Curien and Ghelli
[1992]. Specifically, âˆ€(ğ‘â‰¤ğµ). ğ´is translated to âˆ€ğ‘. (ğ‘â†’|ğµ|) â†’|ğ´|, and ğ‘â‰¤ğµin Î¨ is translated
to two entries ğ‘and ğ‘: |ğ‘| â†’|ğµ| in |Î¨|. We also prove that all kernel ğ¹â‰¤programs can type check
in our system after adjusting the annotations.
The extended version of the paper contains the detailed definition of elaboration, translation,
and annotation decoration, and discussion.
Theorem 3.7 (Type Soundness by Elaboration to System ğ¹). If âˆ†âŠ¢e â‡”A â†©â†’ğ‘’â€² then
|âˆ†| âŠ¢F eâ€² : |A|
Theorem 3.8 (Type completeness w.r.t. kernel ğ¹â‰¤). If âˆ†âŠ¢Fâ‰¤e : A then âˆƒeâ€², s.t. âŒŠeâŒ‹= âŒŠeâ€²âŒ‹, i.e.,
e and eâ€² only differ on annotations, and âˆ†âŠ¢eâ€² â‡’A.
4
ALGORITHMIC SYSTEM
This section introduces an algorithmic system that implements the specification of ğ¹ğ‘
â‰¤presented in
Section 3 using the worklist approach [Zhao et al. 2019]. This algorithmic system is proven to be
sound and complete with respect to the declarative system and is decidable.
4.1
Syntax, Well-Formedness, and Notation
Type variables
ğ‘,ğ‘
Existential variables
bğ›¼, bğ›½
Algorithmic types
ğ´, ğµ,ğ¶
::=
1 | ğ‘| âˆ€(ğ‘â‰¤ğµ). ğ´| ğ´â†’ğµ| âŠ¤| âŠ¥| bğ›¼
Judgment
ğœ”
::=
ğ´â‰¤ğµ| ğ‘’â‡ğ´| ğ‘’â‡’ğ‘ğœ”| ğ´â—¦ğµâ‡’â‡’ğ‘ğœ”| ğ´âŠ²ğ‘,ğ‘ğœ”|
ğ´â†’ğµâ€¢ ğ‘’â‡’â‡’ğ‘ğœ”
Algorithmic worklist
Î“
::=
Â· | Î“,ğ‘<â‰ƒğ´| Î“, bğ›¼| Î“,ğ‘¥: ğ´| Î“ âŠ©ğœ”
Compared with the declarative syntax, the syntax of algorithmic expressions remains unchanged.
The syntax of algorithmic types is extended with a new sort of variable: existential variables (bğ›¼, bğ›½).
Existential variables are used as placeholders for monotype guesses in several rules and will be
unified with another monotype during the reduction of the worklist. Existential variables are
also regarded as monotypes. The (sub)type variables in the worklist are modified to incorporate
a bound, similar to the modifications made to the declarative context. The syntactic differences
to ğ¹ğ‘’
â‰¤are marked with gray shades. A worklist Î“ is an ordered collection of both (type) variable
declarations (with bindings) and judgments, so it combines traditional contexts and judgment into a
single sort. The ordered nature helps with precise scope management, which simplifies mechanical
formalization. Unlike the declarative system, there is only one kind of worklist that deals with both
subtyping and typing judgments.
Judgments. There are six kinds of judgments in the algorithmic system. Four of them are inherited
from ğ¹ğ‘’
â‰¤: subtyping (ğ´â‰¤ğµ), checking (ğ‘’â‡ğ´), inference (ğ‘’â‡’ğ‘ğœ”) and type-application inference
(ğ´â—¦ğµâ‡’â‡’ğ‘ğœ”). The matching judgment (ğ´âŠ²ğ‘,ğ‘ğœ”) and its accompanying application inference
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:17
{ğœ/bğ›¼}Î“
Substitute bğ›¼by ğœin Î“
{ğœ/bğ›¼}(Î“, bğ›¼)
=1 Î“
{ğœ/bğ›¼}(Î“, bğ›½)
=2 {ğœ/bğ›¼}Î“, bğ›½
when bğ›½âˆ‰ğ¹ğ‘‰(ğœ)
{ğœ/bğ›¼}(Î“1, bğ›¼, Î“2, bğ›½)
=3 {ğœ/bğ›¼}(Î“1, bğ›½, bğ›¼, Î“2)
when bğ›½âˆˆğ¹ğ‘‰(ğœ)
{ğœ/bğ›¼}(Î“,ğ‘<â‰ƒğ´)
=4 {ğœ/bğ›¼}Î“,ğ‘<â‰ƒ[ğœ/bğ›¼]ğ´
when ğ‘âˆ‰ğ¹ğ‘‰(ğœ)
{ğœ/bğ›¼}(Î“,ğ‘¥: ğ´)
=5 {ğœ/bğ›¼}Î“,ğ‘¥: [ğœ/bğ›¼]ğ´
{ğœ/bğ›¼}(Î“ âŠ©ğœ”)
=6 {ğœ/bğ›¼}Î“ âŠ©[ğœ/bğ›¼]ğœ”
Fig. 4. Worklist Substitution
judgment (ğ´â†’ğµâ€¢ ğ‘’â‡’â‡’ğ‘ğœ”) are new. The syntax of subtyping and checking judgments is simple
since they either succeed or fail. The syntax of inference, type-application inference, matching,
and application-inference judgments is represented using a continuation-passing style [Zhao et al.
2019] (i.e., with a subsequent judgment ğœ”and a subscript type variable ğ‘). These judgments return
a type that will be used in subsequent judgments ğœ”, but the type may still be unknown when ğœ”
is created, so the type variable ğ‘serves as a placeholder in the subsequent judgment and will be
substituted to a concrete type once it is known.
Miscellaneous rules and notations.
â€¢ There are several well-formedness judgments. Firstly, âŠ¢Î“ checks that worklist Î“ is well-formed.
Secondly, Î“ âŠ¢ğ´checks that the type ğ´is well-formed in Î“. Finally, Î“ âŠ¢ğœ”checks that judgment ğœ”
is well-formed in Î“. The well-formedness definitions are mostly standard, but they also enforce
the distinctions between subtyping and typing contexts discussed in Section 3. The detailed rules
can be found in the extended version of the paper.
â€¢ Worklist reduction Î“ âˆ’â†’Î“â€²: pops the last entry in the worklist Î“, processes according to the
rules, and possibly pushes multiple simplified judgments back to get a new worklist Î“â€². Î“ âˆ’â†’âˆ—Î“â€²
denotes multiple reduction steps, and a worklist Î“ is accepted by the algorithm iff the worklist
processes all the work until nothing is left (Î“ âˆ’â†’âˆ—Â·).
â€¢ Worklist substitution {ğœ/bğ›¼}Î“, replaces all the references to the existential variable bğ›¼in the
worklist Î“ with a monotype ğœand removes the existential variable bğ›¼. The existential variables
in ğœneed to be moved before the original position of bğ›¼to maintain the well-formedness of
the worklist. Figure 4 shows the algorithmic procedure. It traverses the worklist from head to
tail until the declaration of bğ›¼is reached. Rule 1 is the base case where the declaration of bğ›¼is
reached, and bğ›¼is removed to finish the worklist substitution. Rules 2 and 3 deal with reaching
existential variables different from bğ›¼. If bğ›½does not appear in ğœ, we continue the substitution
on the remaining worklist. If bğ›½appears in ğœ, we need to move bğ›½to the front of bğ›¼to keep the
well-formedness of ğœin the remaining substitution. Rule 4 deals with reaching (sub)type variables.
Unlike existential variables, (sub)type variables cannot be moved [Dunfield and Krishnaswami
2013]. So, we need to check that the current (sub)type variable does not appear in ğœ. Rules 5 and
6 deal with variables and judgments by replacing every reference to bğ›¼with ğœand continuing on
the remaining worklist.
4.2
Algorithmic Rules
All the reduction rules are defined in a single relation but for clarity of presentation, we separate
them into three parts: garbage collection, subtyping, and typing. Compared with the declarative
rules, there are two general differences in the algorithmic reduction rules:
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:18
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
â€¢ All the well-formedness checks of types in the declarative rules are dropped since we instead
require the input worklist to be well-formed, which guarantees that the algorithm only deals
with well-formed expressions and type annotations. Note that every reduction rule preserves
the well-formedness of the worklist.
â€¢ In the declarative system, if a declarative rule has multiple judgments as premises, they are
checked separately. These judgments are pushed into a single worklist and reduced jointly in
the algorithmic system. The order of pushing these judgments is deterministic for each rule,
though the order may sometimes make no difference.
Garbage Collection (Rules 1-3). The scoping mechanism of the ordered worklist ensures that if
the worklist is well-formed, these variables can never be referred to by any entries that appear
before them. Thus, it is safe to remove them if they are the last entry in the worklist.
Î“,ğ‘â‰¤ğ´âˆ’â†’1 Î“
Î“, bğ›¼âˆ’â†’2 Î“
Î“,ğ‘¥: ğ´âˆ’â†’3 Î“
The garbage collection of (type) variables is intuitive. The garbage collection of the existential
variable bğ›¼means that this existential variable is under-constrained and can be solved to any
monotype (and trivially, to 1).
Subtyping (Rules 4-16, Figure 5). These 13 rules can be classified into two categories, where the
first contains rules 4-12, and the second contains rules 13-16.
Rules in the first category are similar to their declarative counterparts. Rule 6 is added since we
have a new sort of variables in the algorithmic system. The side conditions ğµâ‰ âŠ¤, ğµâ‰ ğ‘and ğ´â‰ âŠ¤
in rule 7 prevent the overlapping with rules 5, 8 and 14, respectively. The most significant changes
are in rule 11, where an existential variable bğ›¼is introduced instead of guessing the monotype ğœ
instantiation in its declarative counterpart rule â‰¤âˆ€L. The subtyping judgment Î¨ âŠ¢ğœâ‰¤ğµ, which
tests if the monotype satisfies the bounds, is also transformed accordingly to bğ›¼â‰¤ğµ, then added
to the worklist. In rules 10, 11, and 12, multiple new entries are pushed back to the worklist. The
side-condition ğ¶â‰ âŠ¤in rule 11 prevents the overlapping with the rule 8. Though in rule 12, ğµ1 and
ğµ2 are pushed back after ğ‘â‰²ğµ1, the solving scope of the existential variables in them does not
change because subtype variables are not monotypes, and cannot be used in implicit instantiation.
Another subtle difference is that the idea of â€œequivalent typeâ€ is enriched in rule 12 compared to rule
â‰¤âˆ€in that two types that contain existential variables can also be equivalent but not syntactically
equal, e.g., bğ›¼1 â†’1 and (1 â†’1) â†’bğ›¼2 with bğ›¼1 and bğ›¼2 finally solved to 1 â†’1 and 1.
The rules in the second category solve the existential variables. This set of rules is quite different
from those used in previous work [Zhao and Oliveira 2022; Zhao et al. 2019] where: (1) they only
solve existential variables to a basic monotype (i.e., another existential variable, type variable,
and unit type); (2) they always split an existential variable into two fresh existential variables
when it is compared with an arrow type. This new set of rules solves existential variables to
arbitrary monotypes by employing polytype splitting: existential variables are only split into two
when compared with a polytype (or non-monotype) arrow type. Since bğ›¼1 and bğ›¼2 are fresh, the
consequence of the worklist substitution in rules 15 and 16 is equivalent to inserting bğ›¼1, bğ›¼2 before
bğ›¼, replacing every reference to bğ›¼in Î“ by bğ›¼1 â†’bğ›¼2, and removing bğ›¼. The occurs-check condition
in all four rules prevents the possible non-termination of the algorithm caused by judgments like
bğ›¼â‰¤1 â†’bğ›¼. In rules 13 and 14, this check also prevents overlapping with rule 6 since bğ›¼â‰¤bğ›¼fails
such a check. The side condition ğœâ‰ bğ›½in rule 14 ensures that rule 13 takes priority when comparing
two different existential variables. Compared with the rules of ğ¹ğ‘’
â‰¤, the new formulation has fewer
rules and simplifies the proof of decidability, which will be discussed in detail in the Section 4.3.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:19
Î“ âŠ©1 â‰¤1 âˆ’â†’4 Î“
Î“ âŠ©ğ‘â‰¤ğ‘âˆ’â†’5 Î“
Î“ âŠ©bğ›¼â‰¤bğ›¼âˆ’â†’6 Î“
Î“ âŠ©ğ‘â‰¤ğµâˆ’â†’7 Î“ âŠ©ğ´â‰¤ğµ
Î“ âŠ©ğ´â‰¤âŠ¤âˆ’â†’8 Î“
Î“ âŠ©âŠ¥â‰¤ğ´âˆ’â†’9 Î“
Î“ âŠ©ğ´1 â†’ğ´2 â‰¤ğµ1 â†’ğµ2 âˆ’â†’10 Î“ âŠ©ğ´2 â‰¤ğµ2 âŠ©ğµ1 â‰¤ğ´1
Î“ âŠ©âˆ€(ğ‘â‰¤ğµ). ğ´â‰¤ğ¶âˆ’â†’11 Î“, bğ›¼âŠ©bğ›¼â‰¤ğµâŠ©[bğ›¼/ğ‘]ğ´â‰¤ğ¶
Î“ âŠ©âˆ€(ğ‘â‰¤ğµ1). ğ´1 â‰¤âˆ€(ğ‘â‰¤ğµ2). ğ´2 âˆ’â†’12 Î“,ğ‘â‰²ğµ1 âŠ©ğµ2 â‰¤ğµ1 âŠ©ğµ1 â‰¤ğµ2 âŠ©ğ´1 â‰¤ğ´2
Î“ âŠ©bğ›¼â‰¤ğœâˆ’â†’13 {ğœ/bğ›¼}Î“
Î“ âŠ©ğœâ‰¤bğ›¼âˆ’â†’14 {ğœ/bğ›¼}Î“
Î“ âŠ©bğ›¼â‰¤ğ´â†’ğµâˆ’â†’15 {bğ›¼1 â†’bğ›¼2/bğ›¼}(Î“, bğ›¼1, bğ›¼2) âŠ©bğ›¼1 â†’bğ›¼2 â‰¤ğ´â†’ğµ
Î“ âŠ©ğ´â†’ğµâ‰¤bğ›¼âˆ’â†’16 {bğ›¼1 â†’bğ›¼2/bğ›¼}(Î“, bğ›¼1, bğ›¼2) âŠ©ğ´â†’ğµâ‰¤bğ›¼1 â†’bğ›¼2
when ğ‘<â‰ƒğ´âˆˆÎ“ âˆ§ğ´â‰ âŠ¤âˆ§ğµâ‰ âŠ¤âˆ§ğµâ‰ ğ‘
when ğ¶is not a âˆ€type âˆ§ğ¶â‰ âŠ¤
when Î“ âŠ¢ğ‘šğœâˆ§bğ›¼âˆ‰ğ¹ğ‘‰(ğœ)
when Î“ âŠ¢ğ‘šğœâˆ§bğ›¼âˆ‰ğ¹ğ‘‰(ğœ) âˆ§ğœâ‰ bğ›½
when Î“ âŠ¬ğ‘š(ğ´â†’ğµ) âˆ§bğ›¼âˆ‰ğ¹ğ‘‰(ğ´â†’ğµ)
when Î“ âŠ¬ğ‘š(ğ´â†’ğµ) âˆ§bğ›¼âˆ‰ğ¹ğ‘‰(ğ´â†’ğµ)
Fig. 5. Reduction Rules of Algorithmic Subtyping
Typing (Rules 17-36, Figure 6). Rules 17-20 deal with checking, rules 21-26 deal with inference,
rules 28-32 deal with application inference and rules 34-36 deal with type inference judgments.
Rules 17-19 are the algorithmic counterparts of â‡Sub, â‡â†’and â‡â†’âŠ¤. The premise of the
inference judgment in â‡Sub is modified to the continuation-passing style. The side condition
ğ‘’â‰ ğœ†ğ‘¥. ğ‘’â€² in 17 prevents the overlapping with the rule 19. Rule 20 is added for existential variables.
An existential variable can be used to check a lambda expression iff it can finally be resolved to
an arrow type, so we split it into two fresh existential variables and process the worklist with the
worklist substitution.
Rules 21-27 are the algorithmic counterparts of â‡’Var, â‡’Anno, â‡’Î›, â‡’Unit, â‡’App, â‡’TApp and
â‡’â†’Mono. Rules 21-24 are the base cases where the type is fully determined from the expression,
so we replace the placeholder ğ‘in ğœ”with the type. Rules 22 and 23 also push ğ‘’â‡ğ´to the
worklist to check the expression ğ‘’has type ğ´. Rules 25 and 26 infer the result of (type) application
by inferring the type of ğ‘’1 and leaving the remaining work to matching and (type) application-
inference judgments. Rule 27 creates two fresh existential variables bğ›¼, bğ›½to solve the unknown
monotype of the lambda expression by replacing the placeholder ğ‘with bğ›¼â†’bğ›½in ğœ”and checking
the body against bğ›½.
Rules 28-31 are the algorithmic counterparts of âŠ²â†’, âŠ²âˆ€, âŠ²âŠ¥, and âŠ²Var. Rules 28 and 29 are two
base cases where an arrow type is known (by viewing âŠ¥as âŠ¤â†’âŠ¥). The placeholder ğ‘,ğ‘in ğœ”
is then replaced with the domain and codomain of this known arrow type. The modification of
rule 30 of introducing an existential variable bğ›¼is similar to that of rule 11. This bğ›¼will finally be
unified with a monotype that satisfies the bound. Rule 32 is added for existential variables. Since
this existential variable must match an arrow type, we split it into two fresh variables and process
the worklist with the worklist substitution. Rule 33 checks whether an expression of the arrow
type ğ´â†’ğµsolved by the matching can be applied to another expression ğ‘’by adding a checking
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:20
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
Î“ âŠ©ğ‘’â‡ğµâˆ’â†’17 Î“ âŠ©ğ‘’â‡’ğ‘ğ‘â‰¤ğµ
when ğ‘’â‰ ğœ†ğ‘¥. ğ‘’â€²
Î“ âŠ©ğœ†ğ‘¥. ğ‘’â‡ğ´â†’ğµâˆ’â†’18 Î“,ğ‘¥: ğ´âŠ©ğ‘’â‡ğµ
Î“ âŠ©ğœ†ğ‘¥. ğ‘’â‡âŠ¤âˆ’â†’19 Î“,ğ‘¥: âŠ¥âŠ¢ğ‘’â‡âŠ¤
Î“ âŠ©ğœ†ğ‘¥. ğ‘’â‡bğ›¼âˆ’â†’20 {bğ›¼1 â†’bğ›¼2/bğ›¼}(Î“, bğ›¼1, bğ›¼2 âŠ©ğœ†ğ‘¥. ğ‘’â‡bğ›¼)
Î“ âŠ©ğ‘¥â‡’ğ‘ğœ”âˆ’â†’21 Î“ âŠ©[ğ´/ğ‘]ğœ”
when ğ‘¥: ğ´âˆˆÎ“
Î“ âŠ©ğ‘’: ğ´â‡’ğ‘ğœ”âˆ’â†’22 Î“ âŠ©[ğ´/ğ‘]ğœ”âŠ©ğ‘’â‡ğ´
Î“ âŠ©(Î›(ğ‘â‰¤ğµ). ğ‘’: ğ´) â‡’ğ‘ğœ”âˆ’â†’23 Î“ âŠ©([âˆ€(ğ‘â‰¤ğµ). ğ´/ğ‘]ğœ”),ğ‘â‰¤ğµâŠ©ğ‘’â‡ğ´
Î“ âŠ©() â‡’ğ‘ğœ”âˆ’â†’24 Î“ âŠ©[1/ğ‘]ğœ”
Î“ âŠ©ğ‘’1 ğ‘’2 â‡’ğ‘ğœ”âˆ’â†’25 Î“ âŠ©ğ‘’1 â‡’ğ‘(ğ‘âŠ²ğ‘,ğ‘‘(ğ‘â†’ğ‘‘â€¢ ğ‘’2 â‡’â‡’ğ‘ğœ”))
Î“ âŠ©ğ‘’@ğ´â‡’ğ‘ğœ”âˆ’â†’26 Î“ âŠ©ğ‘’â‡’ğ‘(ğ‘â—¦ğ´â‡’â‡’ğ‘ğœ”)
Î“ âŠ©ğœ†ğ‘¥. ğ‘’â‡’ğ‘ğœ”âˆ’â†’27 Î“, bğ›¼, bğ›½âŠ©([bğ›¼â†’bğ›½/ğ‘]ğœ”),ğ‘¥: bğ›¼âŠ©ğ‘’â‡bğ›½
Î“ âŠ©ğ´â†’ğµâŠ²ğ‘,ğ‘ğœ”âˆ’â†’28 Î“ âŠ©[ğ´/ğ‘, ğµ/ğ‘]ğœ”
Î“ âŠ©âŠ¥âŠ²ğ‘,ğ‘ğœ”âˆ’â†’29 Î“ âŠ©[âŠ¤/ğ‘, âŠ¥/ğ‘]ğœ”
Î“ âŠ©âˆ€(ğ‘â‰¤ğµ). ğ´âŠ²ğ‘,ğ‘ğœ”âˆ’â†’30 Î“, bğ›¼âŠ©bğ›¼â‰¤ğµâŠ©[bğ›¼/ğ‘]ğ´âŠ²ğ‘,ğ‘ğœ”
Î“ âŠ©ğ‘âŠ²ğ‘,ğ‘ğœ”âˆ’â†’31 Î“ âŠ©ğ´âŠ²ğ‘,ğ‘ğœ”
when ğ‘â‰¤ğ´âˆˆÎ“
Î“ âŠ©bğ›¼âŠ²ğ‘,ğ‘ğœ”âˆ’â†’32 {bğ›¼1 â†’bğ›¼2/bğ›¼}(Î“, bğ›¼1, bğ›¼2 âŠ©bğ›¼âŠ²ğ‘,ğ‘ğœ”)
Î“ âŠ©ğ´â†’ğµâ€¢ ğ‘’â‡’â‡’ğ‘ğœ”âˆ’â†’33 Î“ âŠ©[ğµ/ğ‘]ğœ”âŠ©ğ‘’â‡ğ´
Î“ âŠ©âˆ€(ğ‘â‰¤ğµ). ğ´â—¦ğ¶â‡’â‡’ğ‘ğœ”âˆ’â†’34 Î“ âŠ©ğ¶â‰¤ğµâŠ©[([ğ¶/ğ‘]ğ´)/ğ‘]ğœ”
Î“ âŠ©âŠ¥â—¦ğ´â‡’â‡’ğ‘ğœ”âˆ’â†’35 Î“ âŠ©[âŠ¥/ğ‘]ğœ”
Î“ âŠ©ğ‘â—¦ğµâ‡’â‡’ğ‘ğœ”âˆ’â†’36 Î“ âŠ©ğ´â—¦ğµâ‡’â‡’ğ‘ğœ”
when ğ‘â‰¤ğ´âˆˆÎ“
Fig. 6. Reduction Rules of Algorithmic Typing
judgment ğ‘’â‡ğ´to the worklist, and then replacing the placeholder ğ‘in ğœ”with the result of the
application ğµ. The reintroduction of the application-inference judgments in this rule is because
the matching output ğ‘and ğ‘‘in rule 25 are used in two separate judgments: ğ‘in ğ‘’2 â‡ğ‘, and ğ‘‘in
[ğ‘‘/ğ‘]ğœ”. Since the inner judgment ğœ”can only pass the information about the placeholder ğ‘in our
continuation passing syntax, an extra judgment is necessary to distribute ğ‘and ğ‘‘.
Rules 34-36 are the algorithmic counterparts of â—¦â‡’â‡’âˆ€, â—¦â‡’â‡’âŠ¥, and â—¦â‡’â‡’Var respectively. Rules
34 and 35 are two base cases where the result of the type application can be fully determined, so
we replace the placeholder ğ‘in ğœ”with this known result type. There is no new rule for existential
variables because a monotype can never be type-applied under the monotype definition.
4.3
Metatheory
To help formalize the correspondence between the declarative and algorithmic systems, we adopt
the approach used by Zhao et al. [2019], which adds another intermediate system defined by a set
of reduction rules on the declarative worklist Î©. The syntax of Î© is the same as the algorithmic
worklist except all types in its judgments and variable declarations are declarative types. Similar to
the notations in the algorithmic worklist, âŠ¢Î©, Î© âŠ¢ğ´and Î© âŠ¢ğœ”denote the well-formedness.
There are two sets of reduction rules for this intermediate system, declarative reduction Î© âˆ’â†’Î©â€²
and declarative worklist reduction Î© âˆ’â†’ğ‘Î©â€², for soundness and completeness proofs, respectively.
Î© âˆ’â†’Î©â€² is a rephrasing of the declarative judgments using the worklist style, while Î© âˆ’â†’ğ‘Î©â€²
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:21
mimics the algorithmic reduction rules but still guesses the monotype ğœinstead of introducing
existential variables. The detailed rules of well-formedness and reduction of the declarative worklist
can be found in the extended version of this paper. Î© âˆ’â†’âˆ—Â· and Î© âˆ’â†’âˆ—
ğ‘Â· are proved equivalent:
Theorem 4.1 (Eqivalence of Declarative Reduction). âˆ€â„¦, if âŠ¢â„¦, then â„¦âˆ’â†’âˆ—Â· iff â„¦âˆ’â†’âˆ—
a Â·.
Soundness and Completeness. Soundness and completeness are built on worklist instantiation [Zhao
et al. 2019], which converts an algorithmic worklist Î“ to a declarative worklist Î© by replacing all
existential variables bğ›¼in Î“ with a well-formed monotype ğœin Î©.
Î“ â‡Î©
Î© is instantiated to Î“
Î© â‡Î©
â‡Î©
Î© âŠ¢ğœ
Î©, [ğœ/bğ›¼]Î“ â‡Î©
Î©, bğ›¼, Î“ â‡Î©
â‡bğ›¼
Their formal statement is standard as described in the following two theorems. The quantifier in
the two lemmas is different because worklist instantiation is a non-deterministic relation.
Theorem 4.2 (Soundness). If âŠ¢Î“ and Î“ âˆ’â†’âˆ—Â·, then âˆƒâ„¦, s.t. Î“ â‡â„¦and â„¦âˆ’â†’âˆ—Â·.
Theorem 4.3 (Completeness). If â„¦âˆ’â†’âˆ—
a Â·, then âˆ€Î“, if âŠ¢Î“ and Î“ â‡â„¦, then Î“ âˆ’â†’âˆ—Â·.
The proof proceeds by induction of the derivation of Î“ âˆ’â†’âˆ—Â· and Î© âˆ’â†’âˆ—
ğ‘Â·, respectively.
Compared with the previous proof, there are two differences. First, existential-variable solving is all
dealt with by worklist substitution. The corresponding cases on the proof are unified, all depending
on the instantiation-consistency lemma that worklist substitution preserves instantiation. We prove
the lemma by induction on an equivalent tail-recursive version of the worklist substitution.
Lemma 4.4 (Instantiation Consistency).
(1) If {ğœ/bğ›¼}Î“ â‡â„¦, then Î“ â‡â„¦;
(2) If Î“ âŠ©bğ›¼â‰¤ğœâ‡â„¦âŠ©ğœâ€² â‰¤ğœâ€² or Î“ âŠ©ğœâ‰¤bğ›¼â‡â„¦âŠ©ğœâ€² â‰¤ğœâ€², then {ğœ/bğ›¼}Î“ â‡â„¦.
Secondly, the case â‰¤â†’of the completeness proof relies on a property to ensure the occurrence-
check condition in rules 13-16 is satisfied, enabling the reduction on the algorithmic worklist to
continue. The proof of this lemma in ğ¹ğ‘’
â‰¤was based on the contradiction between the following
two properties (1) if ğ´â†’ğµcontains bğ›¼, ğ´1 â†’ğµ1 contains strictly more arrows that ğ¶and (2) if
Î© âŠ©ğœâ‰¤ğ´, ğœhas more arrows than ğ´. Fortunately, the above two properties still hold in ğ¹ğ‘
â‰¤by just
counting the arrows in bounds (the number of arrows of a (sub)type variable is still zero).
Lemma 4.5 (Prune Transfer for Instantiation). If (Î“ âŠ©bğ›¼â‰¤A â†’B) â‡(â„¦âŠ©C â‰¤A1 â†’B1)
and â„¦âŠ¢C â‰¤A1 â†’B1, then bğ›¼âˆ‰FV (A) âˆªFV (B).
Confluence and Determinism. To demonstrate the greedy nature of the algorithmic approach (i.e.,
it always picks the first instantiation and does not backtrack), we show that the algorithmic system
is confluent and deterministic. These properties suggest that the algorithm can be implemented in
an efficient way.
Theorem 4.6 (Algorithmic-Reduction Determinism). Given âŠ¢Î“, if Î“ âˆ’â†’Î“1 and Î“ âˆ’â†’Î“2,
then Î“1 = Î“2 (up to ğ›¼-equivalance).
Corollary 4.7 (Confluence). Given âŠ¢Î“, if Î“ âˆ’â†’âˆ—Î“1 and Î“ âˆ’â†’âˆ—Î“2, then âˆƒÎ“3, Î“4 s.t. Î“1 âˆ’â†’âˆ—Î“3
and Î“2 âˆ’â†’âˆ—Î“4 and Î“3 = Î“4 (up to ğ›¼-equivalance).
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:22
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
Confluence is a direct corollary of Lemma 4.6, proved by induction on the derivation of Î“ âˆ’â†’âˆ—Î“1.
Removing some side-conditions would make the algorithm non-deterministic, but could still retain
confluence. Most of the restrictions that can be dropped, while retaining confluence, are checks that
a type cannot be âŠ¤. For instance, we do not need ğµâ‰ âŠ¤in rule 7 or ğ¶â‰ âŠ¤in rule 11. Besides, ğœâ‰ bğ›½
in rule 14 can also be dropped. The more interesting restriction that we believe can be dropped is
the monotype restriction in rules 15 and 16. All the other conditions seem necessary not to get into
any stuck state. We conjecture that the removal of restrictions preserves confluence (while losing
determinism), but we did not formally study that version of the algorithm.
Decidability. The decidability proof is based on a lexicographic group of four measures on the
worklist Î“:

|Î“|ğ‘’, |Î“|ğœ”, 2|Î“|â†’+ |Î“|âˆ€+ |Î“|bğ›¼, |Î“|ğ‘¤

. |Î“|ğ‘’, |Î“|ğœ”, |Î“|â†’, |Î“|âˆ€, |Î“|bğ›¼, |Î“|ğ‘¤are the term size,
number of judgments, number of splits, number of âˆ€, number of existential-variable declarations,
and a simplified version of weight, of the worklist, respectively. Compared with the measure used
by ğ¹ğ‘’
â‰¤, the key innovation is |Î“|â†’, which statically computes the number of maximum splits of a
type ğ´, assuming it is compared with an existential variable in subtyping. All the detailed measure
definitions are in the extended version of this paper. The |Â·|â†’and |Â·|âˆ€measures enjoy the desirable
property of remaining unchanged after substituting an existential variable with any monotype,
implying that both existential-variable solving and worklist instantiation will not affect them.
Using |Â·|â†’enables us to reduce the number of measures required for the decidability proof. In
ğ¹ğ‘’
â‰¤, a tuple of 6 different measures (instead of 4) is needed. It also solves the complication in the
decidability proof when comparing existential variables with an arrow type in subtyping. Zhao
et al. uses an instantiation decidability lemma to state that their measure will finally decrease after
an indefinite number of steps after they split an existential variable by observing how worklist
reduction behaves on instantiation judgments. Instead, in our rules 15 and 16, |Î“|â†’decreases by
one, and |Î“|bğ›¼increases by one after a two-step reduction, so the whole measure decreases.
The most interesting case in our decidability proof is the rule 12, where the rebounding happens
for the ğ‘in ğ´2 during the reduction from |âˆ€(ğ‘â‰¤ğµ2). ğ´2|Î“
â†’to |ğ´2|Î“,ğ‘â‰²ğµ1
â†’
. To proceed with the proof,
we need to first find some connections between the measures before and after the rebounding
based on the condition that ğµ1 and ğµ2 are equivalent.
According to the definition of |Â·|Î“
â†’, we can prove that if two declarative types ğ´and ğµare
equivalent, then |ğ´|Î©
â†’= |ğµ|Î©
â†’and |ğ´|Î©
âˆ€= |ğµ|Î©
âˆ€both hold.
Lemma 4.8 (| Â· |â†’and | Â· |âˆ€Eqality of Eqivalent Declarative Type).
Given âŠ¢â„¦âŠ©A â‰¤B âŠ©B â‰¤A, if â„¦âŠ©A â‰¤B âŠ©B â‰¤A âˆ’â†’âˆ—Â·, then |A|â„¦
â†’= |B|â„¦
â†’and |A|â„¦
âˆ€= |B|â„¦
âˆ€.
Using soundness, completeness, and the property that |Â·|â†’and |Â·|âˆ€remains unchanged under
worklist instantiation, we can transfer this property to the algorithmic system.
Lemma 4.9 (| Â· |â†’and | Â· |âˆ€Eqality of Eqivalent Algorithmic Type).
Given âŠ¢Î“ âŠ©A â‰¤B âŠ©B â‰¤A, if Î“ âŠ©A â‰¤B âŠ©B â‰¤A âˆ’â†’âˆ—Â·, then |A|Î“
â†’= |B|Î“
â†’and |A|Î“
âˆ€= |B|Î“
âˆ€.
Then, we apply the induction hypothesis on Î“1 : Î“,ğ‘â‰²ğµ1 âŠ©ğµ2 â‰¤ğµ1 âŠ©ğµ1 â‰¤ğµ2 to get that Î“1
reduces or not. If Î“1 does not reduce, based on the algorithmic-reduction weakeningâ€“lemma (++
is the worklist concatenation), Î“1 âŠ©ğ´1 â‰¤ğ´2 does not reduce either. The algorithmic-reduction
weakeningâ€“lemma is also proved by transferring the declarative-reduction weakeningâ€“lemma
using soundness and completeness.
Lemma 4.10 (Algorithmic-Reduction Weakening). Given âŠ¢Î“1 ++ Î“2, if Î“1 ++ Î“2 âˆ’â†’âˆ—Â·, then
Î“1 âˆ’â†’âˆ—Â·
Otherwise, if Î“1 reduces, we can now utilize the equality property of | Â· |â†’and | Â· |âˆ€to know
these two measures of the body ğ´2 are not affected by the rebounding on equivalent types and the
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:23
overall measure decreases. For the remaining cases, the measures are also guaranteed to decrease
after a constant number of steps, so the decidability proof of our system can be finalized in a
straightforward manner. We can now establish the decidability theorem for both algorithmic and
declarative systems.
Theorem 4.11 (Algorithmic Decidability). Given âŠ¢Î“, it is decidable whether Î“ âˆ’â†’âˆ—Â· or not.
Corollary 4.12 (Declarative Decidability). Given âŠ¢â„¦, it is decidable whether â„¦âˆ’â†’âˆ—Â· or not.
One remark is that the dependence of the decidability proof on soundness and completeness
limits the applicability of the proof technique to other variants or extensions of the system where
completeness is lost. We discuss one such variant in Section 5. The dependence on the measure
equality of algorithmic types can be possibly removed by modifying the algorithm to avoid re-
bounding in the first place. However, such a change to the algorithm seems non-trivial. Another
choice is to prove the equality properties directly on the algorithmic system. The dependence on
the algorithmic-reduction weakening is difficult to remove and proving the lemma directly seems
to require a simultaneous proof with the decidability itself. Abellaâ€™s lack of handy mathematical
reasoning already resulted in a complicated decidability proof, so we did not attempt a direct
proof for either of the properties. Exploring solutions to simplifying the proof and removing the
dependence on soundness and completeness is left for future work.
5
EXPLORING THE DESIGN SPACE
In this section, we revisit some design decisions of ğ¹ğ‘
â‰¤and present a sound variant of ğ¹ğ‘
â‰¤that
supports subtyping between monotypes, at the cost of completeness.
5.1
ğ¹ğ‘
â‰¤with Monotype Subtyping
The inference algorithm of ğ¹ğ‘
â‰¤, as presented in the earlier sections of the paper, relies on the
equality of monotypes. Consequently, implicit instantiation cannot employ subtyping between
monotypes, which can be limiting, since subtyping between monotypes is pervasive in object-
oriented languages. Equality of monotypes is basically imposed by the desire to obtain a complete
type-inference algorithm, and the choice of greedy instantiation. Gladly, it is possible to generalize
our definition of monotypes to allow for monotype subtyping, while still having a sound type
inference algorithm.
More inference without completeness. We can broaden our definition of monotypes to get more
type inference. We consider type variables bounded by monotypes to be themselves monotypes in
our new variant of ğ¹ğ‘
â‰¤. This is achieved by adding the following rule to the definition of monotypes
in Figure 2:
ğ‘â‰¤ğ´âˆˆÎ¨
Î¨ âŠ¢ğ‘šğ´
Î¨ âŠ¢ğ‘šğ‘
MTVarRec
With this rule, we can accept more programs where implicit instantiation can use type variables
with (monotype) bounds. This rule also makes the definition of monotypes even less syntactic as
now we need to recursively analyze the bounds of type variables to determine whether a type
variable is a monotype or not. In this design, we still obtain a sound algorithm with respect to
the declarative specification, but completeness is lost. The algorithmic system behaves similarly
to the implementation by Cardelli [1993], where the success or failure of type inference becomes
less predictable. An example that illustrates the loss of completeness is the subtyping judgment
Â·,ğ‘â‰¤1 âŠ©âˆ€(ğ‘â‰¤1). ğ‘â†’ğ‘â†’ğ‘â‰¤1 â†’ğ‘â†’ğ‘, which is accepted by the new declarative system by
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:24
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
instantiating ğ‘with ğ‘(as b is regarded as a monotype in the new definition). However, it is rejected
by algorithmic reduction because the algorithm will solve bğ›¼to 1 after a two-step reduction.
Â·,ğ‘â‰¤1 âŠ©âˆ€(ğ‘â‰¤1). ğ‘â†’ğ‘â†’ğ‘â‰¤1 â†’ğ‘â†’ğ‘âˆ’â†’âˆ—Â·,ğ‘â‰¤1, bğ›¼âŠ©bğ›¼â†’bğ›¼â‰¤ğ‘â†’ğ‘âŠ©1 â‰¤bğ›¼
Nominal subtyping. The previous example hints for how our algorithm can be extended to deal
with nominal subtyping, which is common in OOP languages. In mainstream OOP languages, class
hierarchies can be defined, introducing subtyping relations between classes. For instance we can
add Circle and Shape classes, where Circle <: Shape. Here Circle and Shape would be two
monotypes, and it would be desirable to account for the subtyping relation between those types to
enable implicit instantiation.
We can emulate what would happen after extending the calculus with nominal subtyping via
bounded quantification. With the new MTVarRec rule, we can model examples involving a Circle
and Shape type with a subtyping relation between them. For instance, consider the following two
subtyping statements:
(1) Â·, Shape â‰¤âŠ¤, Circle â‰¤Shape âŠ©âˆ€(ğ‘â‰¤Shape). ğ‘â†’ğ‘â†’ğ‘â‰¤Shape â†’Circle â†’Shape
(2) Â·, Shape â‰¤âŠ¤, Circle â‰¤Shape âŠ©âˆ€(ğ‘â‰¤Shape). ğ‘â†’ğ‘â†’ğ‘â‰¤Circle â†’Shape â†’Shape
By viewing Shape and Circle just as regular (bounded) type variables, the first statement succeeds
as greedy instantiation picks Shape, leading to Shape â†’Shape â†’Shape â‰¤Shape â†’Circle â†’
Shape, which is valid. In contrast, the second statement fails as greedy instantiation results in
Circle â†’Circle â†’Circle â‰¤Circle â†’Shape â†’Shape, which is invalid. This behavior
closely parallels the behavior of instantiation in Scala 2 concerning curried functions:
trait Shape
trait Circle extends Shape
def poly2[A] : A => A => A = x => y => x
def ex1 = poly2 (new Shape {}) (new Circle{})
// Accepted
def ex2 = poly2 (new Circle{}) (new Shape{})
// Fails: instantiation picks Circle
In Scala 2, ex1 is accepted, while ex2 fails, since Scala (greedily) picks Circle for the instantiation
of A. This example illustrates the left-to-right bias of Scala 2 type inference. Scala 3 seems to employ
a hybrid algorithm that combines local type inference with other techniques and can accept ex2.
Unfortunately, this algorithm is undocumented, and it is hard to make a precise comparison against
it. The behavior in Scala 2 should be consistent with local type inference and algorithms employed
in other OOP languages. Of course, for uncurried functions, Scala 2 employs local type inference
techniques, which collect subtyping constraints for all the arguments. Thus, both of the examples
with uncurried functions below succeed:
def poly[A](x : A, y : A) : A = x
def ex3 = poly(new Shape {}, new Circle{})
// Accepted
def ex4 = poly(new Circle{}, new Shape {})
// Accepted
The primary limitation of our greedy algorithm, compared to the algorithms employed in Scala
2, is the absence of specialized support for uncurried functions. This limitation is still important,
given that mainstream OOP languages use uncurried functions by default. However, it is worth
mentioning that many implicit instantiations should still work correctly with our algorithm, even
with uncurried functions.
Metatheory results and practicality. The algorithmic rules of this variant are the same, except
that the side condition ğ´â‰ âŠ¤in rule 7 is changed to (Î“ âŠ¬ğ‘šğ‘) âˆ¨(ğµis not a existential variable)
for determinism. We have formalized this variant and proved all the same results that we have
presented for ğ¹ğ‘
â‰¤, except for completeness and decidability. Completeness does not hold, as our
earlier example shows. We conjecture that the algorithm will terminate, but since our current proof
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:25
of decidability relies on the completeness, we cannot adapt it to obtain a proof of termination
for the algorithm. Despite being incomplete, we believe that this variant of ğ¹ğ‘
â‰¤would work well
in practice. Cardelli [1993] has observed that his greedy algorithm works well in practice, and
other researchers [Mercer et al. 2022; Pierce and Turner 2000] corroborated Cardelliâ€™s opinion
on the greedy approach. In fact, Scalaâ€™s type-inference algorithm is itself (partly) greedy, and the
â€œleft-to-rightâ€ bias of Scala in doing type inference and instantiation is well-known. Seasoned Scala
programmers are aware of the left-to-right bias of the algorithm and exploit it in the design of
Scala programs3. Thus, we think that this variant of ğ¹ğ‘
â‰¤could work well, without causing much
confusion to programmers, despite its bias in the instantiation order.
5.2
Other Possible Extensions
Complete type inference with monotype subtyping. One alternative way to obtain more type
inference while preserving completeness would be to use a non-greedy algorithm instead. The
greediness of our algorithm shows up in rules such as:
Î“ âŠ©bğ›¼â‰¤ğœâˆ’â†’13 {ğœ/bğ›¼}Î“
when bğ›¼âˆ‰ğ¹ğ‘‰(ğœ)
Here, once an existential variable is found to be a subtype of a monotype ğœ, we immediately solve it
to that monotype by substituting bğ›¼by ğœin the remaining worklist. A non-greedy algorithm cannot
employ substitution directly and should, instead, collect subtyping constraints. For instance, instead
of an entry Î“, bğ›¼in the worklist, we could have, Î“,ğ´â‰¤bğ›¼â‰¤ğµ, where ğ´and ğµare lower and upper
bounds, respectively, of bğ›¼. In a rule such as the above, instead of substituting bğ›¼by ğœ, we would need
to update the upper bound of bğ›¼in the worklist. This change in the algorithm would be non-trivial
and require many modifications, as well as changes in the metatheory. With this change, we would
be able to delay instantiation until all the constraints have been collected. In turn, this would avoid
the bias of the (incomplete) greedy algorithm in Section 5.1. We are interested in exploring this
idea in the future, but have not developed an algorithm and metatheory yet.
Let polymorphism. Another way to get more inference with the current design of ğ¹ğ‘
â‰¤is to add
let polymorphism. We believe that ğ¹ğ‘
â‰¤has interesting properties that would make this easier than
previous designs attempting to add HM-style type inference in languages with subtyping. Our
definition of monotypes in Figure 2 forbids all bounded type variables (i.e., the bound can only be âŠ¤).
While this is quite conservative for some programs with subtyping, it does have some advantages.
If generalization is applied to a monotype containing existential type variables, then all those
existential type variables would have to be unbounded if generalized. This would mean that no
simplification of polymorphic constraints would be needed, since there could be no bounds for
generalized type variables.
A problem in adapting this idea to ğ¹ğ‘
â‰¤is that, in the current design, the order of type variables in
universal quantification is relevant. But, for let generalization, we should have order-irrelevant
universal quantification. Fortunately, Eisenberg et al. [2016] has studied a related problem and
proposed a solution that enables both order-relevant quantifiers (which can use explicit type
applications), as well as order-irrelevant quantifiers, which enable HM-style let polymorphism (but
cannot use explicit type applications). Eisenberg et al.â€™s approach is currently implemented in the
GHC Haskell compiler. We believe that a similar design could be adopted for ğ¹ğ‘
â‰¤.
6
RELATED WORK
Local type inference. Local type inference has been shown to work in the presence of bounded
quantification by Pierce and Turner [2000], albeit with some limitations as discussed in Section 2.
3See, for example: https://discuss.daml.com/t/scala-inference-rules-of-thumb/2242.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:26
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
Despite its success and impact, local type inference has only been studied formally in restricted
settings, which are basically variants of System ğ¹and ğ¹â‰¤. Many of the extensions of local type
inference used in practical implementations have not been formally studied. Colored local type
inference [Odersky et al. 2001] enables the propagation of partial type information by coloring
inherited and synthesized types according to their directions of propagation in the syntax tree. The
algorithm was also adopted by Plociniczak [2016] to analyze the type errors and it is the basis of
the type-inference algorithm in Scala 2. Section 2 gives an extensive overview of (colored) local
type inference, and compares it to ğ¹ğ‘
â‰¤.
The treatment of curried applications is limited in local type inference, possibly hindering
its usability for (functional) languages where curried applications are common. Spine-local type
inference [Jenkins and Stump 2018] takes an approach that utilizes the type information from the
application spine to address this limitation, improving type inference for curried applications. An
example that illustrates this limitation of local type inference, due to Jenkins and Stump, is:
pair : âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘â†’(ğ‘Ã— ğ‘) âŠ©pair (ğœ†ğ‘¥.ğ‘¥) 0 : (Int â†’Int) Ã— Int â‡’(Int â†’Int) Ã— Int
Even if full types (Int â†’Int) Ã— Int are provided in a type annotation, the above program fails to
type-check with classic local type inference because the type of the first argument ğœ†ğ‘¥.ğ‘¥cannot be
inferred. Jenkins and Stump propose a form of contextual type-argument inference, which allows
the propagation of constraints in curried-function applications, accepting the above example. ğ¹ğ‘
â‰¤
treats curried and uncurried applications uniformly with existential variables, naturally solving
the problem. In the above example, ğ¹ğ‘
â‰¤will generate bğ›¼and bğ›½, which later will be instantiated to
Int â†’Int and Int during constraint solving. In addition, in ğ¹ğ‘
â‰¤, even the expression without
the annotation (pair (ğœ†ğ‘¥.ğ‘¥) 0) can type-check due to ğ¹ğ‘
â‰¤â€™s global approach to type-inference.
In contrast, without type annotations, pair (ğœ†ğ‘¥.ğ‘¥) 0 would be rejected using (spine) local type
inference approaches. However, since ğ¹ğ‘
â‰¤only solves existential variables to monotypes, spine-local
type inference accepts some examples that are rejected in ğ¹ğ‘
â‰¤:
pair : âˆ€ğ‘. âˆ€ğ‘. ğ‘â†’ğ‘â†’(ğ‘Ã— ğ‘) âŠ©pair (ğœ†ğ‘¥.ğ‘¥) 0 : (âˆ€ğ‘. ğ‘â†’ğ‘) Ã— Int â‡’(âˆ€ğ‘. ğ‘â†’ğ‘) Ã— Int
ğ¹ğ‘
â‰¤requires explicit instantiation for the above example since the type that should be inferred
is a polytype, âˆ€ğ‘. ğ‘â†’ğ‘. Mercer et al. [2022] proposed a local type-inference algorithm for an
impredicative polarized call-by-push-value variant of System ğ¹. The proposed algorithm is formally
proved to be decidable. Quick Look [Serrano et al. 2020], adopted in GHC 9, provides impredicative
inference, but subtyping of function types is treated invariantly.
Unlike our work, these recent developments adopting ideas of local type inference focus on
traditional System ğ¹, and do not consider bounded quantification or top and bottom types.
Global type inference with bounded quantification. Global type inference employs long-distance
constraints via unification variables. Cardelli [1993]â€™s ğ¹â‰¤implementation provides a heuristic
global type-inference algorithm that is not formally studied. It introduces unification variables
to support long-distance constraints. Impredicative instantiation is implemented by unifying the
unification variable with the first type constraint it encounters. In other words, Cardelli adopts a
greedy approach, like our work. Type variables are directly instantiated to their bounds. However,
the algorithm is not complete in the sense that the success of its greedy solving scheme depends
on the order of candidate instantiations. On the other hand, ğ¹ğ‘
â‰¤is guaranteed to find the correct
solution meeting our declarative specification, yielding a more predictable behavior. ğ¹ğ‘
â‰¤achieves
this by distinguishing monotypes, which can always be guessed, from more general polytypes that
require explicit type applications.
Sequeira [1998] studied a predicative variant of System ğ¹with bounded quantification, named
ğ‘€ğ¿âˆ€â‰¤. MLâˆ€â‰¤is not an extension of ğ¹â‰¤and employs some different rules. In particular, there
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:27
are at least two important restrictions. Firstly, MLâˆ€â‰¤is predicative and does not support explicit
type applications. Thus, it cannot encode impredicative instantiations of ğ¹â‰¤. Secondly, the bounds
for type variables are restricted to monotypes, whereas ğ¹â‰¤supports unrestricted bounds. ğ‘€ğ¿âˆ€â‰¤
is more ambitious than our work in the sense that it aims at complete Hindley-Milner style
inference, whereas we do not support let generalization or inference of principal types. Another
important issue, which was left unsolved in ğ‘€ğ¿âˆ€â‰¤, is that it does not address the issue of simplifying
constraints. This results in an impractical system where the inferred types can be too hard for
humans to understand due to the number of constraints on types.
Type inference with subtyping and MLSub. The conventional approach to tackle type inference
in HM extended with subtyping is collecting the constraint set and simplifying it using finite
automata [Eifrig et al. 1995a,b; Pottier 1998]. ğ‘€ğ¿ğ¹[RÃ©my and Yakobowski 2008] extends the syntax
of System ğ¹with flexible quantification âˆ€(ğ‘â‰¥ğµ). ğ´and rigid quantification âˆ€(ğ‘= ğµ). ğ´to help
track the information for possible instantiations, requiring annotations on variables with divergent
impredicative instantiations only. Similarly to Quick Look, HMF [Leijen 2008] also restricts the
subtyping of the function type to be invariant. MLsub [Dolan and Mycroft 2017; Parreaux 2020] has
the more ambitious goal to have complete inference of principal types with (first-order, or rank-1)
polymorphic functions. To obtain the principality of inference and subsumption in the presence
of subtyping, MLsub builds an initial distributive lattice over type with a specific group of type
constructors: equi-recursive, union, and intersection types. MLstruct [Parreaux and Chau 2022]
extends MLsub by supporting first-class union and intersection types with a new boolean algebra
over types. ğ¹ğ‘
â‰¤, has more modest goals in terms of type inference. Full inference for System ğ¹and
ğ¹â‰¤without type annotations, is undecidable, so the techniques of MLsub and its variants cannot be
used directly. More generally MLsub/struct address first-order polymorphism only, whereas ğ¹ğ‘
â‰¤
deals with higher-order polymorphism, and also supports impredicative explicit type applications.
Nevertheless, we expect that several of the techniques developed in MLSub/struct will prove to be
useful in the future to improve partial type inference methods.
7
CONCLUSION
Type inference is vital in polymorphic programming languages to alleviate the burden of writing
type annotations everywhere. However, it remains controversial how to balance the expressiveness
of the language and the ability to obtain a practical and effective type inference algorithm. In this
paper, we propose ğ¹ğ‘
â‰¤, which extends elementary type inference and ğ¹ğ‘’
â‰¤to bounded quantification,
and inherits ğ¹ğ‘’
â‰¤â€™s modest approach to global type inference. With a careful design of what should be
regarded as monotypes, we obtain a predictable and easy-to-implement algorithm that is sound and
complete with respect to the declarative system. Meanwhile, instantiations involving polytypes are
still available using explicit type applications. Thus, ğ¹ğ‘
â‰¤can express all kernel ğ¹â‰¤programs. We also
study a variant of ğ¹ğ‘
â‰¤that can infer types for more programs at the cost of completeness. This variant
supports monotype subtyping, and has a left-to-right bias with respect to instantiation, which is
similar to the bias that exists in languages like Scala. Thus we believe that, despite incompleteness,
this variant can be used in practical type-inference algorithms.
ACKNOWLEDGMENTS
We are grateful to the anonymous reviewers for their valuable comments, to Yaoda Zhou for his
helpful feedback on the draft, and especially to Jinxu Zhao for his help in the earlier designs of ğ¹ğ‘
â‰¤.
The research is supported by the Practical Type Inference with Bounded Quantification and Union
and Intersection Types collaboration project (TC20230508031) between Huawei and The University
of Hong Kong and project number 17209821 of Hong Kong Research Grants Council.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

295:28
Chen Cui, Shengyi Jiang, and Bruno C. d. S. Oliveira
REFERENCES
Val Breazu-Tannen, Thierry Coquand, Carl A. Gunter, and Andre Scedrov. 1991. Inheritance as implicit coercion. Information
and Computation 93, 1 (1991), 172â€“221.
https://doi.org/10.1016/0890-5401(91)90055-7 Selections from 1989 IEEE
Symposium on Logic in Computer Science.
Luca Cardelli. 1993. An Implementation of ğ¹<:. Technical Report. SRC Research Reports, Digital Equipment Corporation.
Luca Cardelli, Simone Martini, John C. Mitchell, and Andre Scedrov. 1991. An Extension of System F with Subtyping. In
Proceedings of the International Conference on Theoretical Aspects of Computer Software (TACS â€™91). Springer-Verlag, Berlin,
Heidelberg, 750â€“770.
Luca Cardelli and Peter Wegner. 1985. On Understanding Types, Data Abstraction, and Polymorphism. ACM Comput. Surv.
17, 4 (dec 1985), 471â€“523. https://doi.org/10.1145/6041.6042
Pierre-Louis Curien and Giorgio Ghelli. 1992. Coherence of subsumption, minimum typing and type-checking in Fâ‰¤.
Mathematical Structures in Computer Science 2, 1 (1992), 55â€“91. https://doi.org/10.1017/S0960129500001134
Stephen Dolan and Alan Mycroft. 2017. Polymorphism, Subtyping, and Type Inference in MLsub. In Proceedings of the
44th ACM SIGPLAN Symposium on Principles of Programming Languages (Paris, France) (POPL 2017). Association for
Computing Machinery, New York, NY, USA, 60â€“72. https://doi.org/10.1145/3009837.3009882
Jana Dunfield and Neelakantan R. Krishnaswami. 2013. Complete and Easy Bidirectional Typechecking for Higher-rank
Polymorphism. In Proceedings of the 18th ACM SIGPLAN International Conference on Functional Programming (ICFP â€™13).
Jana Dunfield and Neelakantan R. Krishnaswami. 2019. Sound and Complete Bidirectional Typechecking for Higher-Rank
Polymorphism with Existentials and Indexed Types. PACMPL POPL (Jan. 2019). http://arxiv.org/abs/1601.05106.
Jonathan Eifrig, Scott Smith, and Valery Trifonov. 1995a. Sound Polymorphic Type Inference for Objects (OOPSLA â€™95).
Association for Computing Machinery, New York, NY, USA, 169â€“184. https://doi.org/10.1145/217838.217858
Jonathan Eifrig, Scott Smith, and Valery Trifonov. 1995b. Type Inference for Recursively Constrained Types and its
Application to OOP. Electronic Notes in Theoretical Computer Science 1 (1995), 132â€“153. https://doi.org/10.1016/S1571-
0661(04)80008-2 MFPS XI, Mathematical Foundations of Programming Semantics, Eleventh Annual Conference.
Richard A. Eisenberg, Stephanie Weirich, and Hamidhasan G. Ahmed. 2016. Visible Type Application. In European Symposium
on Programming (ESOP). 229â€“254.
Andrew Gacek. 2008. The Abella Interactive Theorem Prover (System Description). In Proceedings of IJCAR 2008 (Lecture
Notes in Artificial Intelligence).
Jean-Yves Girard. 1972. InterprÃ©tation fonctionnelle et elimination des coupures de lâ€™arithmÃ©tique dâ€™ordre supÃ©rieur. ThÃ¨se
dâ€™Ã©tat. UniversitÃ© de Paris 7.
Roger Hindley. 1969. The principal type-scheme of an object in combinatory logic. Transactions of the american mathematical
society 146 (1969), 29â€“60.
Haruo Hosoya and Benjamin C. Pierce. 1999. How Good is Local Type Inference? Technical Report MS-CIS-99-17. University
of Pennsylvania.
Christopher Jenkins and Aaron Stump. 2018. Spine-Local Type Inference. In Proceedings of the 30th Symposium on Imple-
mentation and Application of Functional Languages (Lowell, MA, USA) (IFL 2018). Association for Computing Machinery,
New York, NY, USA, 37â€“48. https://doi.org/10.1145/3310232.3310233
Didier Le Botlan and Didier RÃ©my. 2003. MLF: Raising ML to the Power of System F. In Proceedings of the Eighth ACM
SIGPLAN International Conference on Functional Programming (ICFP â€™03).
Daan Leijen. 2008. HMF: Simple Type Inference for First-class Polymorphism. In Proceedings of the 13th ACM SIGPLAN
International Conference on Functional Programming (ICFP â€™08).
Guillaume AndrÃ© Fradji Martres. 2023. Type-Preserving Compilation of Class-Based Languages. (2023), 153.
https:
//doi.org/10.5075/epfl-thesis-8218
Henry Mercer, Cameron Ramsay, and Neel Krishnaswami. 2022. Implicit Polarized F: local type inference for impredicativity.
arXiv:2203.01835 [cs.PL]
Robin Milner. 1978. A theory of type polymorphism in programming. Journal of computer and system sciences 17, 3 (1978),
348â€“375.
Martin Odersky and Konstantin LÃ¤ufer. 1996. Putting Type Annotations to Work. In Proceedings of the 23rd ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages (POPL â€™96).
Martin Odersky, Christoph Zenger, and Matthias Zenger. 2001. Colored Local Type Inference. In Proceedings of the 28th
ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL â€™01). Association for Computing
Machinery, New York, NY, USA, 41â€“53.
Lionel Parreaux. 2020. The Simple Essence of Algebraic Subtyping: Principal Type Inference with Subtyping Made Easy
(Functional Pearl). Proc. ACM Program. Lang. 4, ICFP, Article 124 (Aug. 2020), 28 pages. https://doi.org/10.1145/3409006
Lionel Parreaux and Chun Yin Chau. 2022. MLstruct: Principal Type Inference in a Boolean Algebra of Structural Types.
Proc. ACM Program. Lang. 6, OOPSLA2, Article 141 (oct 2022), 30 pages. https://doi.org/10.1145/3563304
Simon Peyton Jones and Mark Shields. 2004. Lexically scoped type variables. (March 2004). Draft.
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

Greedy Implicit Bounded Quantification
295:29
Simon Peyton Jones, Dimitrios Vytiniotis, Stephanie Weirich, and Mark Shields. 2007. Practical type inference for arbitrary-
rank types. Journal of functional programming 17, 1 (2007), 1â€“82.
Benjamin C. Pierce. 1992. Bounded Quantification is Undecidable. In Proceedings of the 19th ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages (Albuquerque, New Mexico, USA) (POPL â€™92). Association for
Computing Machinery, New York, NY, USA, 305â€“315. https://doi.org/10.1145/143165.143228
Benjamin C. Pierce. 2002. Types and Programming Languages (1st ed.). The MIT Press.
Benjamin C. Pierce and David N. Turner. 2000. Local Type Inference. ACM Trans. Program. Lang. Syst. 22, 1 (Jan. 2000),
1â€“44.
Hubert Plociniczak. 2016. Decrypting Local Type Inference. Ph. D. Dissertation. EPFL.
FranÃ§ois Pottier. 1998. Type inference in the presence of subtyping: from theory to practice. Ph. D. Dissertation. INRIA.
Didier RÃ©my and Boris Yakobowski. 2008. From ML to MLF: Graphic Type Constraints with Efficient Type Inference. In
Proceedings of the 13th ACM SIGPLAN International Conference on Functional Programming (Victoria, BC, Canada) (ICFP
â€™08). Association for Computing Machinery, New York, NY, USA, 63â€“74. https://doi.org/10.1145/1411204.1411216
John C. Reynolds. 1974. Towards a theory of type structure. In Programming Symposium, B. Robinet (Ed.). Springer Berlin
Heidelberg, Berlin, Heidelberg, 408â€“425.
Dilip Sequeira. 1998. Type inference with bounded quantification. Ph. D. Dissertation. University of Edinburgh.
Alejandro Serrano, Jurriaan Hage, Simon Peyton Jones, and Dimitrios Vytiniotis. 2020. A Quick Look at Impredicativity.
Proc. ACM Program. Lang. 4, ICFP, Article 89 (Aug. 2020), 29 pages.
Alejandro Serrano, Jurriaan Hage, Dimitrios Vytiniotis, and Simon Peyton Jones. 2018. Guarded Impredicative Polymorphism.
In Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 2018).
Jeremy G. Siek, Michael M. Vitousek, Matteo Cimini, and John Tang Boyland. 2015. Refined Criteria for Gradual Typing. In
1st Summit on Advances in Programming Languages (SNAPL 2015) (Leibniz International Proceedings in Informatics (LIPIcs),
Vol. 32), Thomas Ball, Rastislav Bodik, Shriram Krishnamurthi, Benjamin S. Lerner, and Greg Morrisett (Eds.). Schloss
Dagstuhlâ€“Leibniz-Zentrum fuer Informatik, Dagstuhl, Germany, 274â€“293. https://doi.org/10.4230/LIPIcs.SNAPL.2015.274
Dimitrios Vytiniotis, Stephanie Weirich, and Simon Peyton Jones. 2008. FPH: First-class Polymorphism for Haskell. In
Proceedings of the 13th ACM SIGPLAN International Conference on Functional Programming (ICFP â€™08).
Ningning Xie, Xuan Bi, Bruno C. D. S. Oliveira, and Tom Schrijvers. 2019. Consistent Subtyping for All. ACM Trans. Program.
Lang. Syst. 42, 1, Article 2 (nov 2019), 79 pages. https://doi.org/10.1145/3310339
Jinxu Zhao and Bruno C. d. S. Oliveira. 2022. Elementary Type Inference. In 36th European Conference on Object-Oriented
Programming (ECOOP 2022) (Leibniz International Proceedings in Informatics (LIPIcs), Vol. 222), Karim Ali and Jan Vitek
(Eds.). Schloss Dagstuhl â€“ Leibniz-Zentrum fÃ¼r Informatik, Dagstuhl, Germany, 2:1â€“2:28. https://doi.org/10.4230/LIPIcs.
ECOOP.2022.2
Jinxu Zhao, Bruno C. d. S. Oliveira, and Tom Schrijvers. 2019. A Mechanical Formalization of Higher-Ranked Polymorphic
Type Inference. Proc. ACM Program. Lang. 3, ICFP, Article 112 (July 2019).
Litao Zhou, Yaoda Zhou, and Bruno C. d. S. Oliveira. 2023. Recursive Subtyping for All. Proc. ACM Program. Lang. 7, POPL,
Article 48 (jan 2023), 30 pages. https://doi.org/10.1145/3571241
Received 2023-04-14; accepted 2023-08-27
Proc. ACM Program. Lang., Vol. 7, No. OOPSLA2, Article 295. Publication date: October 2023.

