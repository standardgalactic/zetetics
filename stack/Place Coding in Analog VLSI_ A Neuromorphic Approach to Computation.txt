PLACE CODING IN ANALOG VLSI 

PLACE CODING IN 
ANALOGVLSI 
A Neuromorphic Approach to 
Computation 
by 
OLIVER LANDOLT 
CSEMSA 
SPRINGER-SCIENCE+BUSINESS MEDIA, B.V. 

A C.I.P. Catalogue record for this book is available from the Library of Congress. 
ISBN 978-1-4613-7610-1 
ISBN 978-1-4615-5701-2 (eBook) 
DOI 10.1007/978-1-4615-5701-2 
Printed on acid-free paper 
AII Rights Reserved 
© 1998 Springer Science+Business Media Dordrecht 
Originally published by Kluwer Academic Publishers in 1998 
Softcover reprint of the hardcover 1st edition 1998 
No part of the material protected by this copyright notice may be reproduced or 
utilized in any form or by any means, electronic or mechanical, 
including photocopying, recording or by any information storage and 
retrieval system, without written permission from the copyright owner. 

To Joelle 

Contents 
Preface 
ix 
Foreword 
xi 
PART I: CONCEPTS 
Introduction 
3 
Discrete place coding 
11 
Continuous place coding 
29 
PARTTI: CIRCUITS 
Fuzzy rule chip 
71 
Incremental oculo-motor control chip 
105 
Saccadic oculo-motor control chip 
133 
PART III: PERSPECTIVES 
Extensions 
173 
Conclusion 
197 
References 
205 
Index 
209 

Preface 
The central topic of this book is an uncommon way to represent numbers 
in a computational system. Instead of relying on a single voltage or current 
as in conventional analog circuits, or on a pattern of binary signals as in 
digital circuits, numbers are encoded by the location of a small spot of 
activity in a cellular array. This representation convention is called place 
coding. The underlying principle is strongly related to the way information 
is encoded in topological maps, which are widespread neural structures 
found in natural brains. It is also related to existing technical concepts, 
especially in the field of fuzzy logic, and some types of artificial neural 
networks. Potential advantages of place coding for hardware design include 
the possibility of implementing a wide variety of functions of possibly 
several variables by application of a straightforward procedure. Another 
interesting feature of place coding is that computational accuracy and 
immunity to many kinds of perturbations depend on the number of cells in 
the map, and can be improved to theoretically arbitrary levels by increasing 
map size. This feature implies a reduction of the noise-limited absolute 
minimum power consumption of analog circuits based on place-coding, 
compared to conventional analog circuits. 
In a theoretical part of this book, a formal definition of place coding 
applicable to engineering is given. It expresses quantitatively the 
relationship between an activity spot on a map and the value it represents. In 
addition, a procedure is described for the synthesis of circuits creating a 
specific relation between two or more maps. This procedure is justified on 
the basis of the elementary mathematical concepts of sets and relations (both 
classical and fuzzy). In a second part of this book, three analog integrated 
circuits based on place coding are described, which demonstrate the 
ix 

x 
Place coding in analog VLSI 
applicability of this approach in hardware design. Two of them are based on 
original current-mode functional blocks exploiting recently discovered 
properties of the MOS transistor. Measurement results are presented for the 
three chips. A third part of the book introduces possible extensions of the 
concept of place coding, and ways to apply it to difficult computational 
problems. 
The present book results from contributions of many people and a few 
organizations which I am deeply grateful to. Above all, I wish to thank Eric 
Vittoz for sharing his deep understanding and experience of semiconductor 
devices and analog circuit design, and for supervising this work. Many 
colleague engineers have also contributed to this work, including 
Alessandro Mortara, Philippe Venier, Friedrich Heitger, Patrick Debergh, 
Xavier Arreguit, Pierre Marchal, Steve Gyger, Pascal Pilloud, Eduardo 
Franzi, Pierre-Fran~ois Ruedi, David Ruffieux, Peter Masa, Pascal Heim, 
William Beaudot, Mark Wezelenburg and Laurent Loeffel. Special thanks 
are due to Rita Studer for her friendly secretarial talents, and to Michel 
Perdrix for taking chip photographs. The work described herein has been 
carried out at the company CSEM SA in the frame of internal research 
projects funded by Swiss government resources. The author thanks CSEM 
for letting him incorporate these research results into his doctoral thesis [1], 
which this book is based on. 
Oliver D. Landolt 
CSEM, Neuchtltel, Switzerland 

Foreword 
Microelectronics is a superb technology. Considering its steady 
explosive growth, the number of transistors per chip can reasonably be 
expected to exceed several billion in the early 2000s. This dramatic potential 
for large complexity threatens all present approaches in circuit architectures, 
design methodologies and design tools with obsolescence. Moreover, the 
search for maximum processing speed and the generalized need for reducing 
power dissipation and supply voltage tend to blur the traditional distinction 
between digital and analog circuits. Built-in distributed redundancy will be 
needed to produce reliable billion-transistor circuits at low cost. Solving 
new tasks of perception or evaluation will require massively parallel 
architectures to collectively process large sets of continuously varying data, 
which can be incomplete, fuzzy or partially incoherent. To address all these 
issues, designers of integrated circuits need to be creative in proposing and 
exploring new approaches. 
This book intends to contribute to this challenge. It introduces a new 
concept, inspired from neurobiology, for representing and for processing 
data. It identifies and explores the properties of this representation, and 
shows that it combines the advantages of analog and digital techniques. A 
formalism is proposed and a methodology is developed for the VLSI 
implementation of any arbitrary non-linear function. The resulting 
processing hardware is essentially a large but dense passive network of links 
and cells operating in current mode, which is easily amenable to automatic 
synthesis. The validity of the concept is supported by several examples of 
working VLSI chips. Reading is made easy and pleasant by the intuitive 
explanations which are added to the rigorous demonstrations. 
xi 

xu 
Place coding in analog VLSI 
This book introduces new viewpoints and new ideas which might have a 
real practical impact on the future of microelectronic systems. A very 
refreshing technical reading which should inspire creative electronic 
engineers for further exploration. 
Prof Eric A. Vittoz 
CSEM, Neuchatel, Switzerland 
April 1998 

PART I 
CONCEPTS 

Chapter 1 
Introduction 
The subject of this book is a particular way to represent values in a 
computational system, and a particular way to carry out computation using 
this representation. It is nearly mandatory to introduce work on such a topic 
by defining what representations and computation actually are. However 
common these concepts, defining them formally turns out to be an elusive 
task. A tentative formulation of such a definition, relevant to the scope of 
this book, is given in the following. A more extended discussion of these 
concepts can be found in [2]. 
1.1 Representation and computation 
Many engineering problems consist of creating a specific relationship 
between a set of physical quantities. For instance, if the problem is to make 
one car follow another car at a constant distance, the considered physical 
quantities are the positions in space of two cars, and the required 
relationship is that their distance in space remains constant over time. Some 
problems have a rather simple and direct solution. ill the above example, the 
two cars could be tied together by a rigid bar and the problem would be 
solved. However, in many problems, such a trivial solution does not exist or 
is unpractical for some reason. For instance, the rigid bar solution would not 
be convenient to keep a distance of 200 meters between the cars. This is 
most likely to be true if the required relationship involves many physical 
quantities, quantities of several different natures or quantities which cannot 
directly be accessed by the system (e.g. the velocity of a remote object). An 
often successful approach in this case is to transpose the problem from the 
original physical domain to an intermediate, more convenient domain where 
all quantities to be processed are of the same physical nature (e.g. electrical) 
and located spatially close together. The requested relationship can be 
3 
O. Landolt, Place Coding in Analog VLSI
© Springer Science+Business Media Dordrecht 1998

4 
Place coding in analog VLSI 
created between the intermediate quantItIes, and extended to the original 
quantities by means of transducers providing conversion between the 
original and intermediate quantities. In the above example, the distance 
between the two cars could be converted into an electrical signal by a sensor 
located in the second car. An electronic system could compute an electrical 
representation of the appropriate throttle pedal position as a function of this 
representation of the distance (and possibly some other considerations as 
well). This electrical result could be converted into an actual pedal position 
by an actuator. Alternatively, the whole process could be implemented by a 
human driver as well. In this case, his eyes would play the role of the sensor, 
the intermediate representation would be the state of a part of his nervous 
system, and the muscles in his leg and foot would serve as an actuator. 
The 
intermediate 
quantItIes 
mentioned 
above 
will 
be 
called 
representations of the original quantities. A set of physical quantities can be 
considered as a representation of some other set of physical quantities if 
there exists an unambiguous relationship between the original and the 
representation. 
The process of enforcing a specific relationship between representations 
of some quantities will be called computation. In the common case where 
some quantities are given as inputs and fully determine some other 
quantities which are outputs of the system, computation actually consists of 
evaluating a function. 
1.2 Electronic computation 
1.2.1 Representations in electronic systems 
The vast majority of present man-made computational systems relies on 
semiconductor-based electronic circuits. Representations used in such 
circuits fall essentially into two broad categories - analog and digital. 
In analog circuits, a value is represented by a single electrical quantity, 
which is usually the potential of a node or the current in a branch of the 
circuit. The relationship between the value and the magnitude of the 
electrical quantity is usually linear, or otherwise some invertible non-linear 
function. For instance, log-domain circuits [3][4] are a noteworthy class of 
analog circuits based on a non-linear representation. This one-to-one 
correspondence between the actual quantities and their representations has 
several implications. The range of values which can be represented in an 
analog way is fundamentally restricted. For instance, the voltage range 
which a node can take is essentially limited by the power supply voltage at 
the upper end, and intrinsic noise sources at the lower end. In addition, 
perturbations affecting the electrical quantity alter the represented quantity 

1. Introduction 
5 
by the same relative amount if the representation is linear, or by some 
signal-dependent amount in the non-linear case. 
In digital circuits, a single number is represented by a set of several 
electrical quantities (usually voltages) which can take only one of two states. 
The relationship between the represented number and the pattern of states is 
usually given by the binary numeral system. Digital representation has 
several benefits. First, perturbations affecting the electrical signals do not 
affect the represented quantity (unless they are strong enough to flip their 
binary state). In addition, the range of values which can be represented 
(dynamic range) is extensible at will by increasing the number of electrical 
signals involved in the representation. 
1.2.2 Computation in electronic systems 
The way computation is carried out depends strongly on the 
representation of the processed information. It is neither useful, nor possible 
to discuss exhaustively the many ways computation can be carried out by 
means of electronic circuits. The next few lines simply point out some key 
features of the two classes of circuits - analog and digital - matching the two 
representations introduced above. Later, these features will be compared to 
the properties of circuits based on place coding, which is an alternative 
representation convention discussed in the remaining chapters of this book. 
With an analog representation, computation relies on the constitutive 
relations of available devices in a given technology, i.e. the relationship 
between voltages and currents at their accesses, and on physical laws ruling 
electrical circuits. A circuit combining several devices solves a particular 
computational problem if the relationship between some of the electrical 
quantities which characterize its state matches the given problem. The 
complexity of the circuit needed to solve a particular computational 
problem, measured by the number of devices the circuit is made of, depends 
very strongly on the required transfer function. Sometimes, by luck, the 
target function matches the constitutive relation of an available component 
exactly, in which case the circuit is extremely simple. Only a slight change 
in the target function can lead to an extremely complex circuit. A serious 
difficulty related to analog circuits is the absence of a systematic synthesis 
methodology, except for some particular classes of functions (e.g. temporal 
filters). This makes every new function a fresh design challenge. 
With a digital representation, computation relies entirely on logical 
operations, because any transformation of a set of binary signals into 
another set of binary signals can be split into a combination of elementary 
logical operations. Whatever the function, a digital circuit can be found by 
applying a systematic procedure. A limit to this purely combinatory 

6 
Place coding in analog VLSI 
approach is circuit complexity, measured in terms of the number of logic 
gates needed to implement the function. For instance, to compute a function 
of a single variable, if both the input and output are represented by a 32-bit 
digital code, the digital circuit must generally implement 32 Boolean 
functions of 32 variables. The combinatory approach generally leads to a 
prohibitively complex circuit, except for low resolutions, or for some 
particular functions where each output bit depends on only a few input bits 
(e.g. multiplication by 2, which is just a bit shift; an addition is fairly simple 
too if auxiliary variables - carries - are introduced). The usual solution 
consists of taking a sequential approach. With the help of mathematics, an 
algorithm can be found to evaluate most functions by application of a 
succession of computational steps relying on operators which can be 
implemented by a reasonably complex circuit. For instance, the product 
between two numbers represented digitally can be computed by a succession 
of additions and logical operations. 
1.3 Natural computation 
Living organisms distinguish from inert matter by the remarkable feature 
that they actively remain self-like, meaning that they spend energy to keep 
their general form and function unchanged (at the individual level, group 
level or ultimately species level). For that purpose, they act on their 
environment in a variety of ways, such as ingesting or rejecting substances 
or forms of energy, sometimes moving around in quest of such substances. 
Many of these actions are triggered in response to complex combinations of 
external or internal conditions, therefore many living organisms have to 
maintain some kind of representation of their surrounding or their own 
internal state, and carry out computations to determine the proper actions to 
take. For comparison purposes with electronic computational systems, it is 
interesting to investigate what kind of representations these organisms rely 
on, and how they process information. 
1.3.1 Representations in neural systems 
In virtually any animal, networks of neural cells provide the hardware 
support of internal representations, and the computational medium for 
processing sensory inputs and determining actions. The state of a single 
neural cell is characterized by a unipolar, bounded quantity called its 
activity, which is usually measurable by the rate at which the cell generates 
action potentials (electrical pulses). Research in neurobiology has provided 
some insight into the representation conventions and computational 
techniques used in biological neural networks. Many different coding 

i. introduction 
7 
schemes appear to be used in such networks, even within the nervous system 
of a single individual. 
At the scale of a single neural cell, straightforward analog coding 
(§ 1.2.1) can be found, especially at the receptor level of sensory systems. 
With this coding scheme, activity of a receptor neuron directly represents 
the magnitude of a stimulus of some nature, e.g. light intensity [5] or 
mechanical stretch [6]. Adaptation of the receptor is often used to overcome 
dynamic range shortcomings of neural cells. 
In other instances, the representation of a variable no longer relies upon 
the activity of a single cell, but rather on the pattern of activity of a 
population of neural cells, hence the name population coding. There are 
several ways a pattern of activity can encode the value of a variable. One 
possible coding scheme, based on recruitment, consists of representing 
stimulus intensity by the number of active cells in the population, whereas 
the location of these cells is essentially irrelevant. This scheme is found 
naturally in neural structures responsible for muscle control, because the 
force of muscle contraction happens to be modulated by recruitment of 
individual muscle fibers (in combination with plain analog coding) [7]. 
In some populations of neurons, activity of a particular cell does not 
directly reflect the magnitude of a variable, but rather the degree of 
matching between the actual stimulus! and some "preferred stimulus" which 
this cell is tuned for. Different cells in the population have different 
preferred stimuli. Sometimes, populations are organized in such a way that 
cells with similar preferences are located close together, and there is a 
systematic shift of the preferred stimulus across the population. The range of 
stimuli over which a particular cell exhibits some degree of activity, 
characterized by a tuning curve, typically overlaps broadly the preferred 
stimuli of neighbor cells. Such neural structures are called topological maps. 
With this organization, application of a particular stimulus results in a 
contiguous patch of active cells, the location of which characterizes the 
stimulus, hence the name place coding given to this representation 
convention (the same or similar concepts are designated by a variety of other 
names as well, such as space coding, vector coding, coarse coding or 
labeled-line coding). 
Neurobiological research has revealed topological maps in most sensory 
systems of the brain, and in several motor areas too. The most familiar 
topological map has been discovered in the visual cortex of cats [8] and 
monkeys [9]. Two dimensions of this area reproduce the topology of the 
This description applies to the representation of sensory information. In other contexts, the 
term "stimulus" should be replaced by the appropriate term designating the nature of the 
represented quantity. 

8 
Place coding in analog VLSI 
retina (retinotopic mapping), whereas the third dimension contains columns 
of neurons tuned to different feature orientations. Each column can be 
considered as a map representing an angle, which is a scalar quantity, 
whereby the pattern of activity is generally a single contiguous spot of 
activity in conformance with the place coding concept outlined above. Maps 
of movement directions have also been discovered in area MT of the visual 
cortex [10]. Examples of maps can be found in motor systems too. The 
superior colliculus (optic tectum in non-mammals) contains a map of eye 
movements [11]. Here, the location of a spot of activity encodes the 
direction and magnitude of a subsequent saccade (quick movement) of the 
eyeball. By the way, the superior colliculus also contains visual and auditory 
maps aligned with the eye movement maps, which suggest that the 
mechanism by which an animal orients its eyes toward either a visual event, 
or the source of a sound, is hardwired in this area. 
Many topological maps encode information of a more complex nature 
than just a scalar. For instance, in the somatic areas of the cortex (sense of 
touch), topological maps of the body surface exist, but complex patterns can 
occur if the skin is stimulated in multiple places [12]. In the auditory system 
(especially in the inferior colliculus), several other topological maps of this 
kind are known as well [13]. One of them represents interaural delay versus 
frequency. Another one represents interaural intensity difference versus 
frequency. A third one, computed on the basis of the first two, maps the 
spatial location of sound sources. The nature of sound and the possible 
coexistence of several sound sources make the patterns of activity on these 
maps more complex than a single contiguous cluster. 
1.3.2 Computation in neural systems 
A consequence of the existence of numerous representation conventions 
in different parts of the brain is that many different ways to carry out 
computation can be found in neural structures. In some cases, micro-circuits 
made of only a few neurons have been identified, which operate on analog 
coding in much the same way as analog electronic circuits (§ 1.2.2). An 
example out of many is the circuit responsible for skin reflexes in the leech 
[6][14]. In neural structures known to use popUlation coding, detailed 
connection patterns responsible for computation have seldom been 
identified with certainty, because of the compact arrangement and intricate 
wiring of neural structures, and also because of the limitations of available 
experimental methods. In some cases, hypothetical micro-circuits have been 
inferred from functional features of neural cells and their afferents (neurons 
which stimulate their inputs). The primary visual cortex is an example of 
this situation. Most neurons in this area are selective to edge orientation in 

J. Introduction 
9 
the retina image, and sometimes also to the direction of motion. Neurons in 
the immediately preceding stage in the visual pathway, which is the lateral 
geniculate nucleus (LGN) , have isotropic receptive fields which are 
indifferent to the direction of motion. Therefore, orientation and motion 
selectivity must somehow arise from the pattern of reciprocal connections 
between the LGN and the visual cortex, or within the cortex. The detailed 
neural circuits producing this selectivity are still unknown, but plausible 
solutions have been postulated [15]. 
In the auditory pathway, a succession of topological maps are involved in 
the spatial localization of sound sources as mentioned before. An outline of 
the interconnection pattern between two successive maps in the pathway is 
given in [13], which relies partially on verified facts [16][17], and partially 
on deductions. This description suggests a fairly natural principle for 
carrying out computation with such maps: neural cells from two different 
maps are connected together if their respective "preferred stimuli" are 
related to each other from a computational point of view. This principle will 
be the basis of the analog circuits described in the subsequent chapters of 
this book. 
1.4 Bio-inspiration in electronics 
Many biological systems can solve computational problems considered 
extremely difficult in technical fields, and they can do it with unmatched 
speed and power dissipation. For example, an ordinary fly can extract 
relevant information about the location of obstacles, predators or mates, 
from two eyes made of only a few thousand pixels. It can do so continuously 
with a latency of only a few tens of milliseconds, with a nervous system 
which fits in less than a cubic millimeter. Of course, there are other tasks, 
like adding huge lists of numbers, which computers can carry out much 
better than brains. These facts suggest that there may be novel ways to build 
artificial computational systems, with better performance than classical 
electronic systems for tasks in which living organisms excel and computers 
do poorly. Inspiration can be taken from neural structures as far as their 
operation is understood. Even partial knowledge of biological principles can 
lead to interesting technical solutions, because sometimes common sense 
and technical skills can fill in the voids left by neuroscience. 
It makes sense to reproduce biological structures in electronics only as 
far as the technologies available for building artificial systems are similar 
enough to biological hardware that the advantages of biological systems are 
preserved in their artificial equivalents. Although electronic circuits and 
biological neural networks differ in many ways, they are similar in several 
important aspects [18]. The most obvious one is that they both use electrical 

10 
Place coding in analog VLSI 
signals to represent information, and transmit these signals by means of 
wires. These common features support the hope that many architecture-level 
and circuit-level characteristics of biological systems may be good solutions 
for electronic circuits as well. 
This book investigates place coding in the context of analog circuit 
design. It describes an attempt to build circuits in which signals are encoded 
by the location of an activity spot in an array of cells ("map"), and in which 
processing occurs by means of networks of interconnections ("links") 
between several such maps. It is worth emphasizing that the primary 
intention of this book is to promote a useful circuit design technique for 
engineering purposes. One should not consider the circuits presented in this 
report as models of biological systems, because only some high-level aspects 
of these circuits draw on neurobiology. These circuits may capture some 
operating principles of some parts of the brain, but implementation details 
are unlikely to match neural structures. 

Chapter 2 
Discrete place coding 
2.1 Introduction 
The purpose of this chapter is to define the concept of a map, and define 
a way to encode discrete numbers in the activation pattern of a map. This 
representation convention will be called discrete place coding. In addition, 
the concept of a link is defined as a mean to relate the activation patterns of 
several different maps. A procedure is described to build a circuit from the 
specification of any relation between two or more maps. 
Ultimately, we are interested in processing continuous signals instead of 
discrete ones, although maps themselves must necessarily remain discrete. 
Continuity can be achieved by generalizing the representation convention, 
which will be called continuous place coding in this case. Discrete place 
coding is introduced first because it is conceptually simpler, and because 
values represented this way can always be processed exactly by means of 
links. Processing of values represented by continuous place coding is only 
approximate, and the operating conditions in which this technique offers a 
satisfactory accuracy are quite subtle. Therefore, presentation of the 
continuous version is postponed to Chapter 3. Remarkably, the difference 
between the discrete and the continuous version is solely in the 
representation convention: the circuit implementation and its design 
procedure is identical in both cases. 
11 
O. Landolt, Place Coding in Analog VLSI
© Springer Science+Business Media Dordrecht 1998

12 
Place coding in analog VLSJ 
2.2 Mathematical reminder 
2.2.1 Preliminary comment 
The elementary mathematical concepts reminded in the following are 
well known to most readers. The purpose of this section is to define the 
terminology, graphical representations and notations which will be used 
later in this chapter. Some concepts of fuzzy sets theory are also reminded, 
as they can conveniently be used to define some coding conventions and 
describe the operation of some circuits presented subsequently. In the 
particular class of circuits considered in this chapter, every element can be 
identified directly to a particular mathematical object defined in the present 
section. 
2.2.2 Relations and functions 
Let X and Y be two sets, the elements of which are denoted Xi and Yj 
respectively, where the subscripts i andj are indices. The product set XxY is 
the set of all possible ordered pairs (Xi. Yj), called tuples, made of elements 
of X and Y. A binary relation R is defined by [19] 
1. its source set X 
2. its destination set Y 
3. its graph G, which is a subset of XxY 
The relation is called "binary" because it relates elements of two 
different sets. If a particular tuple (Xi. Yj) belongs to G, Yj is said to be an 
image of Xi by relation R, and Xi is called a pre image of Yj by R. The image 
set Y' of a particular subset X' of X is the union of all images of the 
elements of X': 
(2.1) 
A relation can be represented in several ways. For instance, in the left of 
Figure 2.1, X and Y appear as elliptic shapes containing black dots 
representing their elements, and each tuple belonging to graph G is 
represented as an arrow from an element of X to its image in Y. A second 
possible representation, shown in the right of the same figure, is a table with 
a column for each element of X and a row for each element of Y. Tuples 
(Xi, Yj) belonging to G are indicated by a 1 in the related cell of the table. 

2. Discrete place coding 
13 
x 
y 
Y7 
0 
0 
0 
1 
0 
0 
Y6 
0 
0 
0 
0 
1 
1 
Y5 
0 
1 
0 
0 
0 
1 
Y4 
0 
0 
0 
1 
0 
0 
Y3 
0 
1 
0 
0 
0 
0 
Y2 
1 
1 
1 
0 
0 
0 
Yl 
1 
0 
0 
0 
0 
0 
xl 
Xz 
x3 
x4 Xs \; 
Figure 2.1. Representations of a relation between X and Y. 
Afunction f is a particular relation where each element of X has exactly 
one image in Y. To express that the image of a particular Xi is yj, one can 
write Yj = f(xJ An example function is given in Figure 2.2. 
x 
y 
Y7 
0 
0 
0 
1 
0 
0 
Y6 
0 
0 
0 
0 
1 
1 
Y5 
0 
0 
0 
0 
0 
0 
Y4 
0 
0 
0 
0 
0 
0 
Y3 
0 
1 
0 
0 
0 
0 
Y2 
1 
0 
1 
0 
0 
0 
Yl 
0 
0 
0 
0 
0 
0 
xl 
Xz 
x3 
x4 Xs \; 
Figure 2.2. Representations of a function of X taking its values in Y. 
Binary relations can be extended to relations between N sets XJ .. .xN 
(N)2). In this case, the graph G of the relation is a subset of XJx ... xXN , i.e. a 
set of N-tuples (Xli, ... ,XNj). 
2.2.3 Fuzzy subsets 
In classical mathematics, a particular element x of the universe of 
discourse U either belongs or does not belong to a particular set X. Fuzzy 
sets theory [20][21] has introduced the concept of a graded degree of 
membership of an element x to a set X, which can vary continuously from 0 
(if x does not belong at all to X) to 1 (if x belongs completely to X). Afuzzy 

14 
Place coding in analog VLSI 
subset X of the universe of discourse U is defined as a set of tuples (xj, /.li), 
where XjE U and /.liE [0; 1]. The relation between the elements of U and their 
degree of membership in X is described by a membership function defined 
by its source set U, its destination set [0; 1], and its graph which is the set of 
(xj, !J.J Classical set operators like intersection, union or complement can be 
generalized to fuzzy sets by defining the relationship between the 
membership functions of the operands and the membership function of the 
result. For instance, if A is a fuzzy subset of X defined by its membership 
function !J.A(X), where XE X, the complement A of A in X is defined by 
(2.2) 
Binary operators such as intersection and union can be extended to fuzzy 
sets in more than one way. If A and B are fuzzy subsets of X, the 
membership function of the intersection and union of A and B can be 
written respectively 
(2.3) 
(2.4) 
where t and s are functions meeting a number of criteria. Function t must 
be a t-norm which is defined by the following conditions [21]: 
t(O,!J.) = 0 
(2.5) 
t(1, !J.) = !J. 
(2.6) 
monotonicity: 
!J.A~1lc and !J.B~!J.D => t(!J.A, !J.B) ~ t(llc, !J.D) 
(2.7) 
commutativity: 
t(!J.A, !J.B) = t(!J.B, !J.A) 
(2.8) 
associativity: 
t(!J.A, t(!J.B, Ilc» = t(t(!J.A, !J.B), Ilc) 
(2.9) 
A 
common 
choice 
for 
defining the 
intersection 
operator 
IS 
t(!J.A, !J.B) = MIN(!J.A, !J.B). Similarly, function s must be an s-norm or t-
conorm, which is defined by the following conditions [21]: 
s(O, !J.) = !J. 
(2.10) 

2. Discrete place coding 
15 
s(1,~)=1 
(2.11) 
monotonicity: 
~A~~ and ~B~~D => S(~A' ~B) ~ s(~, ~D) 
(2.12) 
commutativity: 
S(~A' ~B) = S(~B' ~A) 
(2.13) 
associativity: 
S(~A' S(~B' ~» = S(S(~A' ~B)' ~) 
(2.14) 
A 
common 
choice 
for 
defining 
the 
union 
operator 
IS 
S(~A' ~B) = MAX(~A' ~B)' 
2.2.4 Fuzzy logic 
Boolean logic can be generalized into fuzzy logic in a similar way as 
classical sets generalize to fuzzy sets. Fuzzy logic variables can take graded 
values ranging from 0 to 1, instead of just one of two values. Logic 
operators like negation, AND and OR can be extended to operate on such 
continuous variables. Negation is defined as the complement to 1 of the 
operand, whereas AND and OR can be extended in more than one way. The 
fuzzy logic AND operator, denoted /\ in equations, can be any t-norm as 
defined above, whereas OR (noted v) can be any s-norm. Popular choices 
for AND and OR are the MIN and MAX operators: 
a/\ b = MIN(a,b) 
avb=MAX(a,b) 
(2.15) 
Fuzzy logic gates can be implemented as electronic circuits processing 
analog signals. In this case, the choice of a particular t-norm and s-norm can 
be made in such a way to optimize the implementation efficiency of fuzzy 
logic gates. The operators of choice for some analog circuits are 
ab 
a/\b=--
a+b 
avb=a+b 
(2.16) 
because these expressions match the combination of resistors in series 
and in parallel (see Chapter 4). It should be noted that these operators do not 
strictly fulfill the conditions given in §2.2.3 to be a t-norm and an s-norm, 
because Equ. (2.6) and Equ. (2.11) are not verified. Despite of this, these 
operators still have suitable properties for many applications (Sect. 2.4). 

16 
Place coding in analog VLS] 
2.2.5 Fuzzy relations 
A fuzzy relation R between two classical sets is defined, similarly to a 
classical binary relation, by its source set X, its destination set Y, and its 
graph G which is afuzzy subset of XxY. In other words, the graph is a set of 
tuples (Xi, yj, !lij), where XiE X, yjE Y and !lijE [0; 1]. The graph can be 
described by a membership function ~R(X, y) such that !lij = ~R(Xi' yj). A 
fuzzy relation can be represented for instance by a set of weighted arrows, 
or a 2D array specifying the degrees of membership ~ij (Figure 2.3). 
x 
y 
Y7 
0 
0 
0 
1 
0 
0 
Y6 
0 
0 
0 
0 
1 0.6 
Ys 
0 0.1 0 
0 
0 0.5 
Y4 
0 
0 
0 0.8 0 
0 
Y3 
0 0.6 0 
0 
0 
0 
Y2 0.8 0.1 0.3 0 
0 
0 
YI 0.2 0 
0 
0 
0 
0 
XI 
~ x3 
x4 Xs "6 
Figure 2.3. Representations of a fuzzy relation between two sets X and Y. 
The image set Y' of a particular (possibly fuzzy) subset X' of X is 
defined by its membership function ~Y" which has the following relationship 
to the membership functions of X' and the relation R: 
~Y' (y j) = Y(~X' (Xi) 1\ ~R (Xi ,y j)) 
(2.17) 
I 
where ~x' is the membership function of X', and 1\ and v denote at-norm 
and an s-norm as defined previously. In other words, the degree of 
membership of a particular Yj to Y' is the (fuzzy) logical product between the 
degree of membership of its pre image Xi to X' and the degree of membership 
of the tuple (Xi. Yj) to the graph of the relation. If a particular Yj has more 
than one preimage, ~y{yj) is the (fuzzy) logical sum of the individual 
contributions. 

2. Discrete place coding 
17 
2.3 Definition of discrete place coding 
The next two paragraphs define two variations of discrete place coding. 
They distinguish by the nature of the code. In the first case, it is a set of 
binary (Boolean) variables, whereas in the second case, it is a set of graded 
(fuzzy) variables. 
2.3.1 Discrete place coding with binary patterns 
A particular element Xi in a set X of N elements can be represented 
unambiguously by an N-bit digital code with only one bit set to 1, whereas 
all other bits are set to O. Each element is associated by convention with one 
particular bit in the code. Since an element is identified by the location of 
the 1 in the code, and since every digit in the code can take only one of two 
states, this representation convention will be called discrete place coding 
with binary patterns. Obviously, only elements of a discrete set can be 
represented by a code of finite length. 
In the following, we will consider mostly sets of numbers, therefore 
place coding will be used as a mean to represent numbers. Place coding of 
vectors will also be considered (in which case X is a set of vectors instead of 
numbers). Generally speaking, place coding would also be suitable to 
represent other things than number or vectors, such as colors or arbitrary 
objects. 
X 
element 
code (activation pattern) 
Xl 
100000 
x2 
010000 
x3 
001000 
x.t 
000100 
Xs 
000010 
X(j 
000001 
Figure 2.4. Representation of the elements of a set by binary place coding. 
Discrete place coding can be generalized in a straightforward way to 
represent subsets of X, and not only single elements. A subset is represented 
by a digital code with a 1 for every element which belongs to the subset, and 
a 0 at all other positions. The possibility of representing subsets and not 
only single elements makes place coding suitable to compute relations in the 

18 
Place coding in analog VLSl 
general sense (and not strictly functions). As will be shown later (Sect. 7.S 
and 7.6), this can be useful to carry out computation in the presence of 
ambiguity. 
2.3.2 Discrete place coding with graded patterns 
Place coding can readily be generalized to represent fuzzy subsets of a 
discrete set X and not only classical subsets or single elements of X. For this 
purpose, every component of the code is allowed to take any value between 
o and 1, instead of a binary value only. In this case, each component of the 
code indicates the degree of membership of the related element to the fuzzy 
subset. This coding convention will be called discrete place coding with 
graded patterns. Although it relies on analog components, it is restricted to 
represent subsets of discrete sets. 
It will be shown later (Chap. 3) that continuous values for the 
components of a code can also be used to overcome the fundamentally 
discrete nature of place coding. If X is a discrete set of real numbers, a 
representation convention based on graded codes can be defined to represent 
even real numbers which do not belong to X, thereby enabling computation 
with real numbers based on codes of finite length. This coding convention, 
defined in Chapter 3, will be called continuous place coding. Like discrete 
place coding in its graded variation, continuous place coding relies on an 
ordered set of real numbers between 0 and 1, but the two codes are different 
in purpose and must therefore be distinguished. 
2.3.3 Maps and related concepts 
Discrete place coding is defined above on the basis of an ordered set of 
numbers between 0 and 1, without any reference to a physical embodiment. 
A piece of hardware carrying place-coded representations of numbers or 
vectors will be called a map. More specifically, a map is a cellular array 
made of N elements called nodes, each of which is characterized by its 
activation state which can be either binary or graded. In the latter case, the 
term activation grade will also be used. The state of all nodes of a map is 
collectively designated as the activation pattern on the map. Each node is 
related by convention to a particular element in a discrete set of N numbers 
or vectors. This element will be called the associated value (or associated 
vector) of the node. A map will be called a scalar map or a vector map 
depending on the nature of the elements in the set. 
The definition of a map does not require that the physical organization of 
nodes matches the topology of the represented quantity. In other words, it is 
not strictly necessary that nodes with similar associated values are located 

2. Discrete place coding 
19 
physically close together. The existence of a "population" of N nodes with 
different associated values is sufficient to make a distinction between N 
elements of a set. In real circuits however, it is often most efficient from the 
interconnection point of view to lay the map out in an ordered fashion. Such 
organized maps will be called topological maps. Of course, this concept 
makes sense only if the represented quantity has some intrinsic order. As 
mentioned already in §2.3.1, discrete place coding can possibly be used to 
represent elements in sets of objects of arbitrary nature, not only numbers. 
In this work, we will consider only maps made of electrical circuits, but 
other implementation media might also prove suitable (such as optical, 
mechanical, chemical, ... ). 
2.4 Synthesis of relations by networks of links 
2.4.1 Synthesis of binary relations 
Given a binary relation R between two discrete sets X and Y, we are 
interested in building a circuit which produces the image set of a subset of 
X. If both the input and output of the circuit are maps (matching X and Y in 
size), such a circuit can be found by a straightforward procedure. For every 
tuple (Xi. Yj) belonging to the graph of R, a connection must be drawn 
between the node associated to Xi and the node associated to yj. Whenever 
several connections converge toward the same output node, a logic OR gate 
must be inserted to combine these multiple contributions into a single 
activation state. It is easy to see that the operation of this circuit matches 
Equ. (2.1). By definition, if R is a function, exactly one connection leaves 
each node of X. The example circuit shown in Figure 2.5 implements the 
function defined in Figure 2.2. The connection between a node Xi in the 
input map and a node Yj in the output map will be called a link (Xi, yj). The 
set of links between two maps will be collectively designated as a network 
of links. The same procedure remains valid to build circuits working with 
graded activation states (i.e. fuzzy subsets). The binary logic OR gates must 
be replaced by their fuzzy counterparts, but all other things remain the same. 
2.4.2 Comments 
a) Superfluous nodes 
In principle, it can happen that some elements of Y do not have a 
preimage in X. In this case, the activation state of the related nodes in the 
output map is always zero, hence the ground connections visible in Figure 
2.5. In practice however, it is not useful to include such nodes in a map, 
because any links taking them as inputs will remain permanently inactive 

20 
Place coding in analog VLSI 
and useless. Therefore, Y is better restricted to the subset of its elements 
which do have a preimage in X. In particular, when implementing a 
function, Y should not have more elements than X, otherwise the output 
map will necessarily include some superfluous nodes. 
-------
Vy1 
.L 
Vy2 
Vy3 
I Vy4 
.L T Vy5 
J: + 
I Vy6 
v y7 
--------
Figure 2.5. Example circuit implementing the function defined in Figure 2.2 using binary 
place coding to represent the input and output values. The input binary activation pattern is 
applied by a set of voltage sources V xl" V x6' 
b) Computing with only wires 
In a bijection, by definition, every element of X has exactly one image in 
Y, and every element of Y has exactly one preimage in X. In this case, the 
network of links is just a set of independent wires, consequently the input 
and output set of electrical quantities are exactly identical (except 
sometimes for their order). It seems like a paradox that computation can be 
carried out without changing any signal on the physical level. Does such a 
network really do anything? Conceptually, it does. Each wire connects a 
node associated to an element of X to a node associated to an element of Y. 
However, this point of view does not dissipate the paradox, because these 
associations are apparently purely an abstract convention. Considering the 
network of links alone, nothing physical reveals explicitly which element is 
associated to which node, or even the nature of the represented quantity. 
To understand how computation is possible with only wires, instead of 
considering the network of links alone, one should also consider the device 
which produces the input pattern (e.g. a sensor array) and the device which 
uses the output pattern (e.g. an actuator array). The sensors of the input 
array differ by the input value they detect, and the actuators differ by the 
magnitude of the action they produce. The network of links determines 

2. Discrete place coding 
21 
which sensor is connected to which actuator. At the level of the whole 
system, it is obvious that different connection topologies between the sensor 
and actuator arrays can produce different relations between the measured 
quantity and the action it triggers, even if the electrical signals representing 
activity are not altered the least in the computational process. In fact, 
considering a complete system, the values associated to nodes are not just an 
abstraction. At least at the external inputs and outputs of the computational 
system, the characteristics of the transducers - or conversion circuits from/to 
other representations - implicitly determine the associated values. In tum, 
these values determine the associated values of internal nodes of the 
computational system by propagation through the networks of links. 
Thereby, even a network made of only wires really does alter its input 
representation, even if electrical signals are conserved. 
2.4.3 Conversion between scalar and vector maps 
a) Combination of several scalar maps 
In the definition of a map (§2.3.3), it has been mentioned that a map can 
represent either scalars or vectors. In some circumstances, it may be 
necessary to combine several scalar maps into a single vector map. For 
instance, a circuit implementing a function of several variables can be 
synthesized by exactly the same procedure as for binary relations (§ 2.4.1) if 
the input map is a vector map of a multidimensional input space. The 
construction of a circuit combining two scalar maps U and V into a vector 
map X is illustrated by the example in Figure 2.6. The elements of X are 
tuples of the form (uj, Vj), as defined in Figure 2.7. The node of map X 
associated to input vector (uj, Vj) must be active whenever Ui is present on 
map U and Vj is present on map V. Therefore, the circuit is an array of logic 
gates combining every possible pair of input nodes by an AND operation. 
Figure 2.6. Circuit implementation of the combination of two maps U and V into a vector 
map X. Each element of X is a particular pair of elements Uj and Vj. 

22 
Place coding in analog VLSI 
Figure 2.7. Sets U and V and their product set X to be used in example circuits to follow. 
b) Dissociation of a vector map 
If a vector function is synthesized by the procedure described in §2.4.1, 
the output map Y is a vector map. In some cases, it might be necessary to 
split this vector map into several scalar maps representing the components 
of this vector independently. Such an operation might also be necessary if 
some transducer inherently delivers a vector map in an application where 
independent scalar maps would be preferable. For example, an image sensor 
illuminated by a light spot on dark background can be considered as a vector 
map, as each component of its output pattern is related to a location on the 
pixel array, which is a quantity of two-dimensional nature. To recover the 
location in the form of two scalar coordinates, some circuit is needed to 
dissociate the vector map into two scalar maps. The construction of a circuit 
splitting a vector map X into two scalar maps U and V is illustrated by the 
example in Figure 2.8. The elements of X are defined in Figure 2.7 as in the 
previous example. 
Figure 2.B. Dissociation of a vector map X into two scalar maps U and V. The definitions of 
the sets are identical to the example in Figure 2.6. The connections between one particular 
element of X and the related elements of U and V are shown in bold to improve readability. 

2. Discrete place coding 
23 
The node of U associated with a particular value Uj must be connected to 
any input node associated with a vector with a matching first component. A 
similar rule holds for map V. Considering again the image sensor example, 
the dissociation process consists of projecting the spot of activity onto the 
horizontal and the vertical axis of the image plane. 
Combining scalar maps and dissociating a vector map are both possible 
with graded activation states, if the Boolean logic gates shown in the 
schematics are replaced by their fuzzy counterparts. 
2.4.4 Synthesis of relations between multiple sets 
Relations between more than two sets, which include in particular 
functions of several variables and vector functions, can be synthesized by 
associating three functional blocks. In a first stage, all scalar input maps 
must be combined into a single vector map by a circuit constructed as 
described in §2.4.3a. The relation between this vector space and the output 
vector space is actually a binary relation, which can be implemented by a 
network of links generated by the procedure described in §2.4.1. Last, the 
resulting vector map must be dissociated into several scalar maps as 
explained in §2.4.3b. 
I XI ~~~~n 
I 
X2 
I 
~-----
scalar 
maps 
vector 
map 
vector 
map 
dissociation 
scalar 
maps 
Figure 2.9. Architecture for the synthesis of relations between more than two sets. 
If N is the total number of sets involved in the relation, a link is an N-
tuple of the form (Xli. X2j, X3k. ... , Ylm, Y2n, •.• ). In a network built in 
accordance with the architecture shown in Figure 2.9, a single link circuit 
has the schematic shown in Figure 2.10 (valid in the particular case of three 
input maps and two output maps). Each input of the AND gate is connected 
to a node in one of the input maps. This gate detects the presence of a 
particular input vector. The output of this gate is connected to one node of 
each output map, thereby defining an output vector. The complete network 

24 
Place coding in analog VLSl 
of links is made of an array of such link circuits, plus a relation-dependent 
number of OR gates combining signals converging onto the same output 
node. 
link 
Xli 
--~I~-~-------------: 
I 1- _____________ I 
Figure 2.10. Circuit schematic of a single link in a network implementing a relation between 
five different sets (three input sets and two output sets). The presence of an OR gate between 
the outputs of such a link and the output node is necessary only if several links converge onto 
the same output node. 
2.4.5 Comment 
In principle, functions of any number of variables can be implemented by 
a single-stage network constructed as described above. However, the 
number of links grows tremendously with the number of input variables. As 
far as possible, a function of several variables should be split into a nested 
combination of lower-dimensional functions, which can be implemented by 
several networks oflinks in cascade. 
2.4.6 Synthesis of fuzzy relations 
A circuit implementation of a fuzzy relation R can be found by a similar 
procedure as for a classical relation, except that each link is weighted by a 
constant factor. For binary relations, a two-input fuzzy logic AND gate is 
required for every link, with one of its inputs connected to an input node, 
and the other input tied to a constant signal representing its weight, i.e. the 
degree of membership of this link to the graph of the relation. An example is 
shown in Figure 2.11. It is easy to verify that this circuit operates 
consistently with Equ. (2.17), which defines mathematically the evaluation 
of a fuzzy relation. If R is a relation between more than two sets, an AND 
gate is required for every link anyway (§2.4.4). In this case, a fuzzy relation 
can be implemented by applying the weight of each link to an additional 
input to this AND gate. 
At this stage, the concept of a fuzzy relation may seem essentially a 
mathematical curiosity. However, its usefulness will appear after the 

2. Discrete place coding 
25 
definition of continuous place coding (§3.3.3). Networks of weighted links 
enable the implementation of truly continuous functions in a similar way as 
graded activation patterns enable the representation of continuous variables. 
x 
y 
Vy2 
Figure 2.11. Example fuzzy relation between two sets X and Y. and its hardware 
implementation using place coding to represent the input and output variables. External 
inputs and outputs are labeled V xi or Vyj• The weight of each link is indicated as a logical 
value (to be multiplied by the full scale voltage in a real circuit). The tilde on logic gates 
reminds that they process fuzzy logic variables (i.e. graded signals). 
2.5 Discussion 
2.5.1 Summary of features 
From the previous sections in this chapter, a number of specific features 
of maps and networks of links emerge, which are summarized and 
commented in the present paragraph. It must be emphasized that this 

26 
Place coding in analog VLSJ 
summary applies to a discrete use of these structures only. Maps and links 
have different properties when used with continuous place coding 
(Chapter 3). 
1. A straightforward procedure can be applied to implement any relation 
between any number of sets. 
2. Discrete place coding can represent subsets and not only single elements 
3. The number of nodes required for the representation of an element or 
subset of a set is equal to the total number of elements in that set. 
4. The number of links required to implement a particular relation is equal 
to the number of N-tuples which belong to the graph of that relation. 
The first feature is not specific to place coding. With digital coding, 
synthesis of arbitrary functions (but not relations in a more general sense) is 
possible too. However, it is mentioned here because this statement will 
remain true in the case of continuous place coding, and in this context, it 
will be a decisive advantage. 
The second feature is remarkable since not many representations of 
numbers support the representation of subsets without making the 
computational means significantly more complex. Data structures like lists 
can be used in computers, but they are not well suited for hardwired 
combinatory processing of subsets. Actually, exactly the same network of 
links can handle single numbers and subsets correctly. However, the interest 
of this feature is tempered by the fact that it is far less common to process 
sets than single numbers in computational systems. 
The last two features mentioned in the above list are the main limitations 
of discrete place coding. Processing of finely quantized (i.e. nearly 
continuous) values is made unpractical by the linear increase of map size 
with the number of quantization levels. Systems based on conventional 
digital coding also grow with the number of quantization levels, but the 
number of bits grows only logarithmically instead of linearly. 
2.5.2 Relationship to look-up tables 
A network of links is similar to a look-up table in the sense that both 
structures implement a hardwired combinatory function. There are some 
differences however. A look-up table is a general-purpose hardware device 
which can be programmed for a particular function. A network of links is a 
general-purpose concept, but each embodiment is a custom circuit based on 
random logic. A more important difference lies in the way signals are 
encoded. In a look-up table, both input and output are packed digital codes 
(Figure 2.12). Internally however, the input word is decoded in such a way 
to select a single memory cell which contains the output word. The output of 
the decoder is actually a binary place code. 

2. Discrete place coding 
decoder o o o 
01 1 
1 o o o o 
memoty 
001 
010 
1 10 
101 
100 
1 1 1 
000 
010 
27 
Figure 2.12. Example of a discrete look-up table. The decoder and storage array are 
represented separately to show that the intennediate signals can actually be considered as a 
discrete place code. 
input I 
- - - - - - - - --I 
1-------------1 
I 
r 
: 
outputj" _________ _ 
1 
---- ______ 1 
1 
1 
input 2: 
----------1 
: 
1 -------------.1 
"place coding" 
'-----------
Figure 2.13. Cascaded look-up tables considered from an alternative point of view. 
The similarities and differences between networks of links and look-up 
tables can best be seen while considering a circuit made of several cascaded 
look-up tables as illustrated in Figure 2.13. If conceptual borders between 
successive layers are placed as shown in dashed lines, this circuit can be 
considered to process signals represented by discrete place coding, while 
packed digital codes are just an internal intermediate signal in each block. 
An implementation based on networks of links would be functionally 
identical to the illustrated one, but the content of each block would be a 
custom circuit, possibly more efficient than a memory array and a decoder. 

28 
Place coding in analog VLSI 
2.5.3 Applicability 
As was mentioned already in Sect. 2.1, this chapter is not meant to 
advocate the use of discrete place coding as such, but rather as a first step in 
explaining continuous place coding. Therefore, the question of whether 
discrete place coding can lead to better circuits than other discrete 
representations will not be investigated in detail. Given the fast increase of 
circuit complexity with input space dimension and resolution, discrete place 
coding is expected to yield simpler circuits than digital coding only in some 
particular cases. The most obvious specific capability of discrete place 
coding is the representation and processing of sets, unlike digital coding 
which inherently designates only single elements. Although it is unusual to 
consider sets as the basic element of representation, it can be useful to do so 
in some cases. For instance, the "solution" of an ill-posed problem is not a 
single value, but rather the set of all values compatible with the available 
data, given the constraints of the problem. Discrete place coding provides a 
way to hard wire the computational process leading from the input data to 
the set of possible solutions in a single feedforward pass. 
Perception systems, both natural and artificial, are a noteworthy class of 
computational systems required to solve underdetermined problems. This is 
due to the nature of sensory input, which is usually a projection of a high-
dimensional physical reality onto a lower-dimensional sensor array, which 
makes the recovery of the original high-dimensional reality ambiguous. In 
most cases, incoming sensory data merely restricts the set of possible 
interpretations, without completely determining a single solution. To 
minimize ambiguity, it is useful to rely on several different cues producing 
different sets of plausible solutions, and intersect these sets. For instance, 
for depth perception based on vision, a set of plausible interpretations 
derived from stereopsis could be intersected with interpretations inferred 
from motion parallax. Discrete place coding could provide a framework for 
hardwiring the relationships between sensory inputs and sets of compatible 
interpretations. Set operations like intersection could then easily be 
implemented by logical operations between the resulting place-coded 
patterns. This approach will be developed in some more detail in Sect. 7.6. 

Chapter 3 
Continuous place coding 
3.1 Introduction 
The present chapter discusses a generalization of discrete place coding 
enabling the representation of any real number in a bounded range by a 
pattern of finite size. This representation convention is based on graded 
activation patterns as defined in §2.3.2. Section 3.2 introduces this 
continuous version of place coding, first in an intuitive way, then by a 
formal definition. Section 3.3 examines under which conditions networks of 
links introduced in the discrete case (§2.4.1) qualify to carry out 
computation in the continuous case. Section 3.4 investigates the properties 
of continuous place coding from an analog circuit design perspective. In 
particular, the effect of various types of perturbations on the represented 
value is studied. 
3.2 Definition of continuous place coding 
3.2.1 Intuitive approach 
Let us assume we are interested in representing real numbers belonging 
to the interval X = [1; 5]. Let us consider also a finite subset X' of X 
containing all integer numbers which belong to X, i.e. X' = {I, 2, 3, 4, 5}. 
Each element of X' can be represented by a 5-component discrete place code 
(§ 2.3.1) as shown in Table 3.1. 
29 
O. Landolt, Place Coding in Analog VLSI
© Springer Science+Business Media Dordrecht 1998

30 
Place coding in analog VLSl 
Table 3.1. Discrete place coding representation of integers from I to 5 
number 
representation 
2 
3 
4 
5 
10000 
01000 
00100 
00010 
00001 
It sounds intuitively reasonable to represent an intermediate number 
between 2 and 3 by an "intermediate" code between (0 1 0 0 0) and 
(00 1 00), using graded instead of binary activation states. For instance, the 
activation pattern (00.50.500) could be accepted as a representation of 
2.5, and (00.8 0.2 0 0) could represent another number closer to 2, such as 
2.2. The meaning of "intermediate", when applied to activation patterns, can 
best be viewed geometrically. A 5-component code can be considered as a 
vector J.lx = (f..!xl f..!x2 f..!x3 Ilx4 Ilx5), which can be represented as a point in a 5-
dimensional unit hypercube. Binary place codes representing the integer 
numbers belonging to X' are located at apexes of this hypercube. 
"Intermediate" patterns between two of these binary codes are points located 
somewhere on a short path between the related apexes. When such a path is 
followed continuously, one component of the activation pattern decreases 
continuously from 1 to 0, whereas another component increases from 0 to 1. 
Ilx3 
6' 
o 
(0 1 1 00) 
x=3 
I 
o 
--------------------r-
S 
x=2 
-+-----------.:e--I~ Ilx2 
(00000) 
(01000) 
Figure 3.1. Planar cut through a unit hypercube containing all possible graded activation 
patterns. Points close to (0 1 000) are related to x values near 2, whereas points close to 
(00 I 00) represent x values near 3. A few sample points on the diagonal are labeled with 
their related x value. 

3. Continuous place coding 
31 
Let us consider only patterns with all components zero except ~x2 and 
~x3. All patterns of this kind are geometrically located in a square 
(Figure 3.1) delimited by the origin and the points (0 1 0 0 0), (0 0 1 0 0) 
and (0 I I 0 0). One expects that patterns changing from (0 1 0 0 0) to 
(0 0 1 0 0) along a continuous path represent numbers from 2 to 3 in a 
continuous succession, but the detail of which point in the square represents 
which real number is open for choice. 
A complete definition of a representation convention for real numbers 
involves the specification of the function f relating activation patterns flx to 
the real numbers x they represent: 
(3.1) 
Since continuous place coding is meant to be a generalization of discrete 
place coding, f is constrained to meet the following conditions: 
f( (1 0 0 0 0» = 1 
f( (0 1 0 0 0» = 2 
f«O 0 1 0 0» = 3 
f«O 0 0 1 0» = 4 
f«O 0 0 0 1» = 5 
(3.2) 
In addition, as suggested before, it sounds reasonable to request that f 
should be continuous. In the next paragraph, continuous place coding will be 
defined on the basis of one particular function f matching these conditions. 
3.2.2 Formal definition 
Let X be a continuous range of real numbers, and X' a finite subset of M 
elements of X, including at least the boundaries of X. The elements of X' are 
noted x\. Let flx be a non-null vector of M components denoted ~xi taking 
their values in the range [0; 1]. The representation convention called 
continuous place coding is defined by the following relation between an 
element x of X and its code flx: 
M 
I~Xi'X'i 
x = f(~x) = =i=,-,;-lM-=---
I~xi 
i=l 
(3.3) 

32 
Place coding in analog VLSI 
In a mechanical analogy, x is the center of gravity of a system made of M 
dot bodies of mass I1xi and location X'i. With the help of this analogy, the 
graphical representation of a pattern shown in Figure 3.2 may give a better 
intuitive feeling of the relationship between a pattern and the represented 
value. 
Ilx2 
Ilx3 
Ilxl 
Ilx4 
Ilx5 
0 
x'l 
x' 2 
x'3 
x4 
x'5 
Figure 3.2. Graphical representation of a pattern and its center of gravity, which indicates 
which value the pattern represents in the sense of continuous place coding. 
Obviously, function f defined in Equ. (3.3) meets the conditions to be a 
valid generalization of binary place coding: if all the I1xi are zero except a 
single I1xk which is 1, then x is equal to Xk. Equally obviously, the 
relationship between x and J.1x is continuous. 
Continuous place coding can readily be generalized to represent vectors 
instead of just scalars. In the vector case, the same definition as above is 
valid, but X is a continuous subset of a multi-dimensional space, and X' a 
discrete set of vectors belonging to X. 
3.2.3 Membership functions 
There are several different patterns representing the same real number. 
Given a pattern, the related x is known unambiguously by evaluating (3.3), 
but the reverse is not true. In other words, f is not invertible. The conversion 
of a given x into a pattern involves the choice of one particular pattern 
among a set of possibilities. This operation can be described by a vector 
function g(x), the components of which are the pattern: 
(3.4) 

3. Continuous place coding 
33 
For g to be a valid "inverse" of f, it must match the following criterion: 
x=f(g(x)) 
(3.5) 
Since there are many different g which fulfill this condition, additional 
constraints can be added to restrain the choice. As we intend to generalize 
discrete place coding, we choose arbitrarily that if x is equal to an element 
of X', g(x) should be the binary place code representing this particular 
element. In addition, we constrain each component gi(X) to be continuous 
and decrease monotonically with the absolute difference between x and x'j, 
so that the produced activation patterns conform to the intuitive approach 
presented in §3.2.1. There are still several functions meeting all of these 
conditions. Taking again the example introduced in §3.2.1, one possible set 
of functions gb) is shown in Figure 3.3. Each function gi(X) can be 
considered as a membership function defining a fuzzy subset of X. 
1 
I ~(x) 
O-r--~-------¥~-----¥~----~------~~~x 
1 
2 
3 
4 
5 
Figure 3.3. Example set of functions glx) which produces an activation pattern representing x 
which is consistent with the definition of continuous place coding. One of the membership 
functions is shown in bold for better visibility. 
In a graphical representation, valid functions gk(X) can be recognized as 
they are continuous, evaluate to 1 for x = Xk and to 0 for x = Xi with i '# k. It 
is generally more difficult to ascertain visually that Equ. (3.5) is verified. 
3.2.4 Maps and related concepts 
As in the discrete case (§2.3.3), a map is the hardware support of a place-
coded representation, and is defined as a cellular array of nodes. The state of 
each node is characterized by an activation grade, which is one component 
/lxi of the vector f.lx. This vector is designated as the activation pattern on the 
map. Each element X'i of X' is called the preferred value of the i'th node of 
the map. In the continuous case, "preferred value" is more appropriate than 

34 
Place coding in analog VLSI 
"associated value" which is used in the discrete case, because nodes are 
broadly tuned to some value rather than strictly related to a single value. 
Fundamentally, continuous place coding makes sense only for the 
representation of ordered quantities such as numbers or vectors, because it is 
based on an averaging process. Spatial relationships between the preferred 
values of nodes in space X can conceptually be transferred to the nodes 
themselves, and serve to define a topology in the map. Two particular nodes 
can be considered to be distant or close depending on the distance between 
their preferred values in X. In a scalar map, two nodes will be called 
neighbors if their preferred values are in immediate succession in X. In 
vector maps, if the preferred values are chosen on a Cartesian grid, nodes 
are neighbors if their preferred values are located at the apexes of the same 
unit hyper-cube of the grid (Figure 3.4). If preferred values are spread out 
arbitrarily in a multi-dimensional space, then the concept of neighborhood is 
much more difficult to define. However, Cartesian grids arise naturally from 
the combination of several scalar maps into a vector map by the circuit 
described in §2.4.3a. 
x X X 
x 8 8 
)(~ 
o 0 
X 
o 0 
X 
Figure 3.4. Neighborhood in maps of a one-dimensional, two-dimensional and three-
dimensional space. Crosses indicate preferred values. Nodes, the preferred values of which 
are indicated by circled crosses, are all neighbors of each other. 
In a hardware implementation of a map, it is not strictly necessary, from 
a functional point of view, that the physical topology (layout) of the map 
matches its conceptual topology. In other words, it is not strictly necessary 
that nodes with similar preferred values are located close together in the 
physical implementation. By the way, in a planar electronic circuit, it is not 
possible to reproduce all neighborhood relationships exactly for spaces of 
three or more dimensions. However, in practice, a topological organization 
of a map (at least for two of its dimensions) usually turns out to be the most 
efficient layout, minimizing the length and complexity of interconnections. 

3. Continuous place coding 
35 
3.2.5 Comments 
a) Map size 
If X is a set of real numbers, any element of X can be represented by 
continuous place coding as long as X' includes at least two elements, which 
are the boundaries of X. Similarly, if X is a set of points in a multi-
dimensional space with boundaries shaped as a hypercube, any element of X 
can be represented as long as X' includes all apexes of this hypercube. 
Larger subsets X' do not extend the representation range of continuous place 
coding. However, motivations for increasing the size of X' are twofold. 
First, for processing by a network of links, the more elements belong to X', 
the more flexibility is available to approximate the target function, as will be 
seen in Section 3.3. Second, with many elements in X', the representation 
relies more on the location of the active components of the pattern, and less 
on the actual activation grades, thereby reducing the influence of 
perturbations. This statement is justified quantitatively in Section 3.4. 
b) Representation of subsets 
A specific feature of discrete place coding is that subsets can be 
represented, and not only single elements (§2.3.1). For continuous place 
coding, it follows from the definition that only single numbers or vectors 
can be encoded and not subsets, because the center of gravity of J1x is always 
a single element. There is room for a slight improvement of this situation if 
J1x is the sum of several distinct, easily-segmentable activation patches. In 
this case, one could consider that the center of gravity of each activation 
patch is an individual member of a discrete set. 
3.2.6 Pattern features 
Although there are many patterns J1x representing the same value x, it 
will be seen in Section 3.3 that some of them are more suitable than others 
for processing by networks of links. Therefore, it is useful at this point to 
define some parameters characterizing the extent of activation patterns on a 
map. They will be used to express the operating condition of networks of 
links in the context of continuous place coding. 
Given an activation pattern J1x, the smallest uninterrupted interval of X 
which contains all the X'i with non-zero activation grades ~xi will be called 
the pattern range. It can be an ordinary interval or a higher-dimensional 
geometric shape (hypercube) depending on whether X is a set of scalars or 
vectors. 
The length of the pattern range (or its volume in higher dimensions) will 
be called the pattern spread. It must be emphasized that according to this 

36 
Place coding in analog VLSI 
definition, spread is a quantity of the same nature as x. Pattern spread is not 
a count of the number of active nodes, but really the space which the pattern 
occupies in X. 
In contrast, the pattern size is the number of nodes, the preferred values 
of which belong to the pattern range. It is not necessarily equal to the 
number of active nodes: some nodes in the middle of the activation pattern 
may be inactive, but they are still counted in the pattern size. 
f.lx2 
f.lx3 
f.lxl 
f.lx4 
f.lx5 
0 
x 
x' I 
x' 2 
x' 3 
x' 4 
x' 5 
I 
I 
pattern range 
... pattern spread • 
Figure 3.5. Illustration of the concepts of pattern range and pattern spread: the pattern range 
is the smallest interval of X which encloses the active components entirely; the pattern spread 
is the length of this interval. 
For the representation of a real number x in the interval [x\; X\+l]' the 
minimum possible pattern size is two, and the minimum spread is X'i+l-X\. 
Patterns with a minimum spread will be called tight patterns, and the others 
will be called loose patterns. In a tight pattern, all active nodes are 
neighbors of each other (§3.2.4). Patterns produced by evaluation of a vector 
function g(x) compliant with the conditions given in §3.2.3 are necessarily 
tight. 
3.3 Function synthesis by networks of links 
3.3.1 Discretization of continuous functions 
Let us consider a continuous function y = f(x), where x and y belong to 
X and Y respectively, both of which are continuous sets of real numbers. Let 
us consider a discrete subset X' of X and a discrete subset Y' of Y. The 
elements of X' and Y' are denoted x\ and Y'j respectively. The number of 
elements in X' and Y' are independene. A discrete function f can be defined 
I However, it is not useful to have more elements in Y' than in X' (see §2.4.2a), 

3. Continuous place coding 
37 
by relating each x\ with the Y'j nearest to f(X'i). In other words, f' is obtained 
by sampling and quantizing f. The number of elements in X' determines the 
density of samples in X, which is conceptually similar to the sampling rate 
in temporal signals. The number of elements in Y' determines the 
quantization step, hence the magnitude of quantization errors. An example 
of a continuous function f and the related discrete function f is given in 
Figure 3.6. In this example, both X and Y are uniformly sampled, but in 
general, non-uniform intervals between successive elements of X' or Y' are 
also an option. A network of links implementing a discrete function f' can 
be synthesized by the procedure described in §2.4.1. With fuzzy logic gates 
instead of Boolean gates, this network can process graded activation patterns 
(§2.3.2). In the context of discrete place coding, operation of this circuit has 
been discussed already. In the present section, operation of the same 
network of links in the context of continuous place coding will be 
investigated. 
f(x) 
• 
f(x) 
x' 1 
Figure 3.6. Example of a continuous target function f and its discrete approximation f 
obtained by sampling and quantization. 
3.3.2 Transfer function 
It seems natural to define the transfer function of a network of links, in 
the context of continuous place coding, as the relationship between the 
centers of gravity of its input and output patterns. However, this definition is 
not always valid. It follows from the definition of continuous place coding 
that several different activation patterns can represent the same value. The 
problem is that if different patterns with the same center of gravity are 
applied to the input map of a network of links, the resulting output patterns 

38 
Place coding in analog VLSJ 
do not generally have the same center of gravity. If different representations 
of the same input value produce different output values, then the operation 
of the network cannot properly be characterized by a function. However, it 
will be shown in the remaining of this paragraph that the magnitude of the 
variations of the output value can be kept within narrow limits by restricting 
the extent of the activation pattern on the input map. It is therefore still 
possible to design a network in such a way that its behavior can at least 
approximately be characterized by a transfer function. 
This matter will be discussed on the basis of geometrical arguments. The 
plot in Figure 3.7 shows again the continuous function f(x) depicted in 
Figure 3.6, together with its discrete approximation f(x). The large dots 
representing f'(x) can also be considered as a representation of the network 
of links which implements f(x), since a link is defined as a tuple (x' j, y'j) in 
§2.4.1. Below the plot is shown an arbitrary activation pattern extending 
over four nodes, and its center of gravity is marked by a vertical dashed line. 
If this pattern is applied to the input of the network of links, then four links 
contribute to produce the output pattern shown on the left, namely (x' 4, y' 6), 
(x' 5, y' 6), (x' 6, y' 5), and (x' 7, y' 4). The center of gravity of the output pattern, 
marked by a horizontal dashed line, is the result of the computation. The 
intersection point between the two dashed lines could also be determined by 
computing the center of gravity of the four dots (x' 4, y' 6), (x' 5, y' 6), 
(x' 6, y' 5), and (x' 7, y' 4) in the (x, y) plane, where the weight of each dot is 
the activation grade of the related input node. The coordinates of this 
intersection point yield the input and output values x and y. This point of 
view reveals the locus of possible associations which the network can make 
between input and output values: whatever the activation grades of the 
active nodes, the point (x, y) is necessarily located within a convex polygon 
whose apexes are the points characterizing the active links. This polygon is 
shown explicitly in Figure 3.7 (triangle in dark gray). With four nodes, it is 
generally a quadrilateral, but in this example it is a triangle because three of 
the points are aligned. 
Given a maximum pattern size of N, such a polygon can be defined for 
every possible group of N consecutive nodes in the input map. The union of 
all these polygons determines a band in the (x, y) plane, which contains all 
possible (x, y) pairs which the network of links can produce when input 
patterns are no more than N nodes in size. This band will be called the 
transfer band of the network. It is shown in gray in Figure 3.7 for N = 4. 
The thickness of the band at a particular location x indicates the range over 
which y can possibly vary for different input patterns representing this 
value x. 

3. Continuous place coding 
y 
Y'(i 
y's 
39 
Figure 3.7. Illustration of the concept of transfer band for a maximum pattern size of four 
nodes. Up to this size, whatever the input pattern, the output value produced by the network 
of links implementing f(x) lies within the band shown in gray. 
Y 
Y'6 
Y'5 
Y'4 
Y'3 
Y'2 
Y'I 
x' 
x' 
x' 
I 
2 
3 
x 
Figure 3.8. Continuous transfer function f'(x) implemented by a network of links if the input 
patterns are tight. 

40 
Place coding in analog VLSI 
Obviously, the shape and thickness of the transfer band depends on the 
maximum allowed pattern size. If patterns are required to be tight (N = 2), 
the polygons degenerate into straight segments joining successive discrete 
points. Consequently, the transfer band shrinks into a continuous transfer 
function f'(x) which linearly interpolates the discrete points defined by rex) 
(Figure 3.8). By increasing the maximum pattern size N, the thickness of the 
transfer band increases too. The band for a size N is necessarily a subset of 
the band for a size N+ 1, because the set of patterns of maximum size N is 
included in the set of patterns of maximum size N+ 1. As long as the transfer 
band remains narrow with respect to some accuracy specification, the 
behavior of the network can still be described at least approximately by the 
transfer function f'(x). 
3.3.3 Operating conditions 
A network of links processing continuous place-coded patterns is 
expected to implement a sufficiently accurate approximation of the target 
function f(x) on one hand, and to operate fairly consistently on the other 
hand, meaning that it should deliver about the same result when presented 
with different representations of the same input value. 
The accuracy expectation constrains primarily the density of samples 
and the number of quantization levels, hence the size of the input and output 
maps. Abundant literature is available on how to sample and quantize a 
function in such a way to make its later reconstruction possible [22]. Put 
simply, the condition for an accurate reconstruction by linear interpolation is 
that the interval between successive sampling points X'j and X\+l must be 
small enough that the target function f(x) remains approximately linear in 
the interval [x'j, X'j+l]. 
The consistency expectation can be met by two different approaches. The 
most obvious solution is to use only one of the possible activation patterns 
for each value of x at the input of a network. By constraining uniqueness of 
representation at the input, the whole issue of consistency vanishes. If the 
input pattern is delivered directly by a sensor array, or a circuit converting a 
signal from another representation into continuous place coding, uniqueness 
will usually inherently be satisfied, because such devices can usually be 
characterized by membership functions (§3.2.3). In the case where the input 
pattern is delivered by another network of links, uniqueness is more difficult 
to guarantee. In general, a network must be expected to produce a variety of 
different output patterns for the same output value. 
A second approach to ensure consistency is to restrict pattern size to 
such a level that the transfer band remains acceptably narrow (§3.3.2), or 
ideally even shrinks into a line. As mentioned earlier, a sufficient condition 

3. Continuous place coding 
41 
to get a transfer band of null thickness is that the input patterns are tight. 
Luckily, the necessary condition to get such a band is less constraining. As 
long as the input pattern range is entirely enclosed in an interval where the 
discrete function f(x) is linear, the polygon constructed with the active 
links (§3.3.2) degenerates into a line. Thus, in every linear portion of f(x), 
input patterns may be loose to some extent without disrupting the transfer 
function into a thicker band. It is noteworthy that the critical pattern feature 
is its spread and not its size (§3.2.6). Within a linear portion of f(x), if the 
sampling density is increased by a factor of two for instance, then the 
acceptable pattern size increases by the same factor, but the acceptable 
spread remains the same. 
If the expectation on consistency is relaxed in such a way to tolerate 
some limited amount of variations in the response of a network of links, then 
the operating condition of a network of links can be expressed as follows: 
the spread of the input pattern must be small enough that the target function 
remains approximately linear over the pattern range. This statement 
indicates a trend, not a hard limit. The tolerable amount of non-linearity 
over the pattern range must be determined on the basis of accuracy and 
consistency specifications. This operating condition for consistency includes 
the condition for accuracy given at the beginning of this paragraph, which 
was expressed as an upper limit to the sampling interval. Indeed, the 
minimum possible pattern spread is the sampling interval, therefore the 
condition on accuracy is automatically fulfilled if the condition on 
consistency is. 
The conclusion of this paragraph is that an ordinary network of links, 
constructed by exactly the same procedure as in the discrete place coding 
case, can be used to carry out computation with variables represented by the 
continuous place coding convention. For this purpose, it is necessary to 
ensure that a sufficient number of samples of the target function are 
embodied by the network. It is also necessary to limit the spread of input 
activation patterns. It is in principle always feasible to make the input map 
large enough that the actual transfer function is an acceptable approximation 
of the target function, at least with tight patterns. 
3.3.4 Suppression of quantization 
The quantization step described in §3.3.1 is necessary if each node of 
map X' is connected to exactly one node of map Y', as in a classical 
network. To keep the quantization error small, it may be necessary to use 
large output maps. Alternatively, quantization errors can be suppressed by 
using weighted links (§2.4.6) instead of ordinary (unweighted) ones. If the 
image f(X'i) of a particular value X'i is intermediate between two elements y'j 

42 
Place coding in analog VLSI 
and Y'j+t. the related input node can be connected to both output nodes, with 
relative weights reflecting a continuous place-coded representation of the 
exact output value f(X'i), instead of the closest discrete match. In fact, the 
network obtained by this way implements a fuzzy relation as described in 
§2.4.6. The accuracy improvement gained by this technique is illustrated in 
Figure 3.9, which should be compared to Figure 3.8. The significant 
mismatch between f(x) and f'(x) in the interval [x' 2, x' 4] is due to an 
insufficient density of sample points in this interval, given the steepness of 
f(x). Because of this, even the tightest possible input pattern has an 
excessive pattern range enclosing a significantly non-linear portion of f(x). 
Y 
Y'6 
f(x) 
• f(x) 
Y'5 
f'(x) 
Y'4 
Y'3 
y'2 
y'} 
x 
x' 1 
x' 2 
x' 3 
x' 4 
x' 5 
x' 6 
x' 7 
x' 8 
x' 9 
x'lO 
Figure 3.9. Accuracy improvement due to the introduction of weighted links. The vertical 
distance between a point (x'j, f(x' J) and the two horizontal lines y'j and y'j+l immediately 
above and below it determines the weights of the links (x'j, y') and (x\, y'j+l)' 
3.3.5 Pattern divergence 
The influence of pattern spread on performance of a network of links has 
been discussed in §3.3.2 and §3.3.3. Tight patterns have been described as 
optimum for accurate matching between the target function and the actual 
transfer function of the network. However, if a tight pattern is applied to the 
input of a network of links, the output pattern is not always tight itself. 
Therefore, in a computational system made of several cascaded networks, 
pattern spread is likely to increase over successive stages. The occurrence 
and magnitude of this phenomenon, which will be called pattern divergence, 
depends on the design of the networks of links. Pattern divergence can 
become a nuisance if pattern spread becomes large enough that the operating 
condition given in §3.3.3 is not fulfilled to a satisfactory degree anymore. 

3. Continuous place coding 
43 
Let us consider a subset of a network of links ("subnetwork"), made only 
of links starting from a small group of input nodes which are all neighbors 
of each other (§3.2.4). Such a group is made of two nodes in a scalar map, or 
2D nodes in a vector map, where D is the dimension of the vectors. This 
subnetwork will be called convergent if all links from that group converge 
toward the same output node. It will be called conservative if all output 
nodes connected to members of that group are neighbors of each other. 
Otherwise, the subnetwork will be called divergent. A network of links 
generally has different convergence properties in different locations of the 
input map. These concepts are illustrated by Figure 3.10. 
y 
... ---..... 
I 
-, 
I 
' 
I 
" 
: 
'~ , 
y's 
I 
, 
; 
'~ 
, 
" 
I 
.... 
I 
~, 
, 
.... , 
I 
.... 
I 
.. 
~' 
................. 
" 
... " 
~ ~ ~ ~ ~ ~ ~ ~ 4 
~o 
I = I < I < I > 
I = I = I = I = I > 
I 
Figure 3.10. lllustration of convergence properties of a network of links for a function of a 
single variable. For every interval [x';, X'i+!l, a symbol indicates whether the network 
implementing the discrete function rex) is convergent (», conservative (=) or divergent «) in 
this interval. 
If a tight input pattern is applied to a network in a convergent or 
conservative area, then the output pattern is tight too. If such a pattern is 
applied to a divergent area, then the output pattern is loose. There are 
several ways to deal with pattern divergence. In favorable cases, it is not 
necessary to avoid it at all. One possible reason for this could be that the 
divergent network is not followed by another network of links, but by some 
transducer or converter into another type of representation instead. Another 
possible reason is that divergence is moderate enough that the resulting 
loose patterns still comply with the operating condition of subsequent 
networks of links (§3.3.3). In cases where pattern divergence must be 
compensated for, a special type of network, which actively "sharpens" loose 

44 
Place coding in analog VLSI 
patterns, can be inserted into the computational flow at every spot where 
pattern spread would be unacceptable. One possible circuit based on a 
combination of lateral and recurrent connections is described in Section 7.4. 
An alternative approach to avoid pattern divergence problems is to make 
networks of links conservative by design. As the example in Figure 3.10 
suggests, a network is divergent in areas where the density of "sampling 
points" X'i in X is insufficient, given the steepness of the target function 
f(x). In the case of a function of a single variable, it is possible to select first 
the elements of Y' (i.e. the quantization levels in Y), then include in X' all 
elements of X which are a preimage of an element of Y'. This leads 
generally to a non-uniform sampling of X. By construction, the network of 
links which implements the discrete relation between X' and Y' does not 
cause patterns to diverge. Figure 3.11 provides a graphical illustration of 
this approach. 
y 
~ 
-
-- - f(x) 
I ~ 
• f(x) 
'" 
-- f'(x) 
y's 
~ 
I 
~ 
/ 
~ -
y'2 
.. x 
x' 1 
Xl 
x's 
x' 7 
X'g 
x'9 
x'lO 
x'll 
Figure 3.11. Choice of sampling points leading to a non-divergent network of links. 
In practice, non-uniform sampling of X can be annoying to implement. In 
a multilayer system where the sampling points X' of one layer are actually 
the quantization levels Y' of the previous layer in the computational flow, 
applying the above approach recursively may lead to odd sample densities at 
the primary inputs of the system. 
A sufficient condition to avoid pattern divergence is that the sample 
density is high enough to accommodate the steepest gradient of the target 
function. This fact enables to keep the sample density uniform over X while 
avoiding pattern divergence, at the cost of using a larger input map than 
strictly necessary. This approach is illustrated by Figure 3.12. This figure 
can be used to illustrate a side effect of a high sample density due to 

3. Continuous place coding 
45 
quantization of f(x). In parts of the function with only a moderate gradient, 
the network of links is typically convergent. Thereby, the continuous 
approximation f"(x) of the target function remains constant in these 
intervals, resulting in a partial loss of the benefit of the inherent 
interpolative property of continuous place coding. This problem can be 
avoided by using networks of weighted links (§3.3.4) instead of unweighted 
ones. 
Y 
Y'6 
y's 
Y'4 
Y'3 
Y'2 
y'\ 
x 
x' I x' 4 
Figure 3.12. Pattern divergence avoidance using a high uniform sample density determined 
by the steepest gradient in f(x). This example shows the side effect of a high sample density 
due to quantization ("staircase" in parts of f(x) with a moderate steepness). This artifact can 
be avoided by using weighted links. 
3.4 Analog design perspective 
3.4.1 Preliminary 
So far in this chapter, continuous place coding has been discussed in 
terms of dimensionless, perturbation-free activation patterns. This 
representation convention is intended to be implemented in analog circuits, 
therefore some issues related specifically to analog design must be 
discussed. An important matter is the effect of perturbations on place-coded 
values. In common analog circuits, the represented quantity is simply 
proportional to an electrical quantity (usually voltage or current), which is 
processed by the circuit. For instance, if an analog circuit computes some 
function of an absolute pressure ranging from 0 to 100KPa, this pressure 
could be represented by a voltage between 0 and IV. Obviously, in this case, 
any perturbation affecting the voltage alters the pressure value used for 

46 
Place coding in analog VLSI 
computation by the same relative amount, therefore this distinction between 
the representing and the represented quantity is usually not even made. In 
the case of continuous place coding, the value used for computation is 
determined by the center of gravity of activation grades, which are in tum 
represented by electrical quantities. The effect of electrical perturbations on 
the represented quantity is less obvious than in the analog coding case. A 
first-order analysis of the effect of such perturbations is made in the next 
few paragraphs, and applied to determine the specific impact of several 
types of perturbations occurring in analog circuits (process parameter 
spread, noise, ... ). The results enable a translation of system-level to circuit-
level specifications for analog design of networks of links. 
To restrict the scope of the study, the perturbation analysis applies to 
scalar maps only. In addition, activation patterns are assumed to be tight, 
and the sum of activation grades over the whole map is assumed to be 
normalized to 1. The consequence of the tightness assumption is that only 
two nodes have a non-zero activation grade, and these nodes are neighbors 
in the map. If the related preferred values are denoted X'k and X'k+\' the 
represented value x is enclosed in the interval [X'k; X'k+l]. The normalization 
assumption, combined with the definition of continuous place coding (Equ. 
(3.3», determines the activation grades Ilxk and Ilxk+l of these nodes: 
X'k+l-X 
Ilxk = 
I 
I 
xk+l-x k 
x-x'k 
Ilxk+l = 
I 
I 
xk+l-x k 
(3.6) 
Many results given in the remaining of this section depend on the 
particular choice of preferred values X'i in the interval X. In several 
instances, the general results will be evaluated for two particular 
distributions of x'j, for better understanding of their implications: 
Uniform sampling: 
X = [0; xmax ] 
i-I 
(3.7) 
X'i =--·xmax 
M-l 
X = [1; xmax ] 
i-I 
Logarithmic sampling: 
x'.=(x 
)M-I 
(3.8) 
1 
max 
In the above equations, M is the number of nodes in the map, and the 
node index i ranges from 1 to M. These symbols retain the same meaning 
throughout the remaining of this chapter. 

3. Continuous place coding 
47 
3.4.2 First order effect of activation perturbations 
The impact of perturbations on the represented value can be established 
quantitatively by a first-order analysis. Starting with Equ. (3.3) which 
defines continuous place coding, the first-order development of the 
represented value x in the presence of perturbations can be written 
af 
Xpert == X + L -a-' ~).Lxi 
i 
).Lxi 
(3.9) 
In this equation, xpert is the perturbed value, x is the perturbation-free 
represented value, and ~Jlxi are small incremental changes affecting the 
activation grades Jlxi. The partial derivatives are evaluated for the 
perturbation-free activation pattern. From this equation, the following result 
can be derived: 
(3.10) 
The effect of several perturbation types can be evaluated on the basis of 
this equation (§3.4.3 and following). Independently from the cause of the 
perturbation, Equ. (3.10) shows already that the impact of variations of an 
activation grade increases with the distance between its preferred value X'j 
and the represented value x. As far as a source of perturbation alters only 
active nodes, it is clear that the tighter the activation pattern, the less 
sensitive it will be to this type of perturbation. Remarkably, as was already 
the case for accuracy and consistency (§3.3.3), it is not so much the number 
of active nodes as the "volume" occupied by the activation pattern in the 
input space (i.e. pattern spread) which determines sensitivity to 
perturbations. Since the present section addresses tight patterns only, the 
actual performance must be expected to degrade in circuits where loose 
patterns are allowed. However, Equ. (3.10) suggests that the degradation 
should be progressive and not dramatic with increasing pattern spread. 
3.4.3 Perturbation models 
Different perturbation sources create activation errors ~Jlxi with different 
statistical properties. In general, activation errors depend on time, on 
activation grade and on space (the space variable being the position in the 
map, denoted by the node index i). However, the study will be restricted to a 
few particular cases where ~Jlxi depends on only some of these variables. 

48 
Place coding in analog VLSJ 
Table 3.2 defines perturbation types which will be considered. Possible 
causes mentioned in this table typically apply to current-mode circuits, and 
are not exhaustive. 
Table 3.2. Perturbation types and their features 
designation 
features of ~!lxi 
possible cause 
offset 
- constant in time 
junction leakage 
- changing in space (characterized by average 
and standard deviation) 
- independent of activation grade 
scale error 
-
constant in time 
threshold voltage and 
- changing in space (characterized by average 
transconductance factor 
and standard deviation) 
mismatch in current 
-
magnitude proportional to activation grade 
mirrors 
noise 
- changing in time (null average, characterized 
flicker and shot noise in 
by power spectral density) 
transistor channel or 
-
statistical features constant in space 
collector current 
- relationship to activation grade depends on 
noise origin 
3.4.4 Offsets 
The effect of the (spatial) average component of 
~Ilxi will be 
distinguished from the effect of its purely random component. The average 
component will be called a systematic offset and the other a random offset. 
a) Systematic offset 
A systematic offset affects all nodes of a map identically, therefore ~Ilxi 
can be written just ~Ilx. Equ. (3.10) turns into 
(3.11) 
Assuming uniform sampling as defined in Equ. (3.7), the sum can be 
calculated and substituted in the above equation, which yields: 
( Xmax 
) 
~X= M·~Jlx· -2-- x 
(3.12) 
This shows that a systematic offset in activation grades creates an offset 
and a gain error for x (Figure 3.13). The error is close to zero if x is close to 

3. Continuous place coding 
49 
the middle of the map. The upper bound of the error, expressed relatively to 
the full scale of x, is given by 
1L\x1 
MILl~xl 
-- < -'----'-
xmax -
2 
(3.13) 
The error magnitude is proportional to the size of the map, therefore LlJlx 
must be very small if large maps must be implemented. With logarithmic 
sampling as defined in Equ. (3.8), the offset is different but the trend is the 
same. 
o 
I 
I 
I 
I I Xmax x 
Figure 3.13. Error resulting from a systematic offset, plotted as a function of x (qualitative). 
A numerical example can help appreciating the significance of this 
result. Given a map with M = 100 nodes, if the error on x must be kept 
lower than 1% of Xmax, then Ll~x must be lower than 115000. If activation 
grades are represented by currents, junction leakage is likely to be the 
dominant source of systematic offset, and constrain the choice of the current 
intensity representing an activation grade of 1. For an implementation where 
leakage is 1 pA for each node in the map, the error on x is less than 1 % of 
Xmax if the full scale activation grade is at least 5nA. 
b) Random offset 
If LlJlxi is a random variable with a null average, the variance of x can be 
calculated from Equ. (3.10) as a function of the variance of LlJlxi (assuming 
statistical independence between the LlJlxi): 
(3.14) 

50 
Place coding in analog VLS] 
Assuming uniform sampling, the sum can be calculated and substituted 
in the above equation, which yields: 
(3.15) 
The coefficient a. is minimum if the pattern is in the middle of the map 
(x = xmax/2), and reaches its highest value on the boundaries of the map 
(x = 0 or x = xmax). This relationship between location and perturbation 
magnitude is illustrated by Figure 3.14. 
Figure 3.14. Error resulting from a random offset (qualitative). The envelope of the gray zone 
indicates the standard deviation of the error as a function of x. 
The fact that perturbations are less harmful in the middle than at the 
boundaries of the range could be exploitable in some applications. For a 
minimum-size map (M = 2), a. ranges from 1/4 to 112, whereas if M gets 
much larger than 1, a. ranges from 1/12 to 1/3. To get rid of the dependency 
of a. in x, a. can be approximated by its upper bound. With this 
simplification, the standard deviation of Lh expressed relatively to the full 
scale can be written 
(3.16) 
The approximate equality holds for M» 1, i.e. nearly always. For 
M = 100, the standard deviation of random offsets affecting activation 
grades must be less than about 1/580 to keep the standard deviation of the 
represented quantity below 1 % of xmax• For instance, if activation grades are 

3. Continuous place coding 
51 
represented by voltages with random offsets of 1mV (standard deviation), an 
activation grade of 1 must be represented by a voltage of at least 580mV to 
meet the above condition. 
These results apply to offsets only, which are additive in nature, meaning 
the magnitude of ~/lxi does not depend on /lxi. This implies that all nodes of 
a map contribute to errors, including completely inactive nodes. With larger 
maps, it is increasingly difficult to keep the contributions of the two active 
nodes dominant over the background activity of many allegedly inactive 
nodes. 
3.4.5 Scale errors 
Scale errors are characterized by the fact that the magnitude of ~/lxi is 
proportional to /lxi. Therefore, perturbation statistics are characterized by the 
(spatial) average and standard deviation of relative activation errors, which 
are defined by 
~/lxi 
~r/lxi =--
/lxi 
(3.17) 
The effect of the average component of ~r/lxi will be distinguished from 
the effect of its purely random component. The average component will be 
called a systematic scale error and the other a random scale error. 
a) Systematic scale error 
If all activation components in a pattern are scaled by the same factor, 
the center of gravity of the pattern remains unchanged. Therefore, one 
expects to find a complete insensitivity of x to systematic scale errors. This 
fact can be verified analytically on the basis of (3.10), with ~r/lxi = ~r/lx 
identical for the whole map: 
&= ~r/lx '[r/l~i 'X'i,-X' r::]=o 
=x 
=1 
(3.18) 
We state without demonstration that this property remains valid beyond 
the first-order approximation, without the tight pattern assumption and 
without the pattern normalization assumption. 

52 
Place coding in analog VLSJ 
b) Random scale error 
Using the fact that only two activation components differ from zero, and 
using the notation introduced in §3.4.1, Equ. (3.10) can be written 
(3.19) 
If ~rllxk and ~rllxk+l are random variables with a null average and a 
variance (}"2(~rf..l,J, the variance of & can be written as follows (assuming 
statistical independence between ~rllxk and ~rllxk+l): 
(3.20) 
Substitution of (3.6) into this equation leads to 
(}"2(&) = K(x). (}"2(~rf..lx) 
K(x) = 2((x - X',k)· (X'~+1-X))2 
x k+l-x k 
(3.21) 
K(x) is zero at the boundaries of the range [X'k; x'k+ll and maximum in 
the middle (Figure 3.15). This implies that x is completely insensitive to 
random scale errors if x is any of the x';. 
This result was intuitively expectable: if a pattern is made of only one 
active component, its center of gravity remains unchanged even under large 
perturbations of this single activation grade. The maximum of K(x) can be 
taken as an upper bound to the variance of &: 
(3.22) 
This equation shows that the influence of random scale errors in the 
activation grades can be reduced by increasing the sample density in X, 
hence map size if the full range Xmax is given a priori. This result shows that 
in circuits based on place coding, if random scale errors are dominant, 
accuracy can be traded for circuit area. This is an interesting property, since 
scale errors are expected to be the dominant perturbation type in current-
mode implementations. 

3. Continuous place coding 
53 
Figure 3.15. Error resulting from a random scale error (qualitative). The envelope of the gray 
zone indicates the standard deviation of the error as a function of x. 
For uniform sampling, the standard deviation of .:h, expressed relatively 
to the full scale Xmax, can be written 
(3.23) 
The standard deviation of the absolute error on x depends only on map 
size and perturbation magnitude. A numerical example can help 
understanding the implications of this expression. For a map with 100 nodes 
(M = 100), if the activation grades are affected by random scale errors with 
a standard deviation cr(L\!lx) = 25%, the standard deviation of x is about 
0.09% of full scale. 
With logarithmic sampling, the size of the interval [X'k; X'k+l] is 
approximately proportional to x. Equation (3.22) turns into the following 
expression: 
(3.24) 
In this case, the standard deviation of the relative error on x depends 
only on map size and perturbation magnitude. Let us consider a map with 
100 nodes (M = 100) representing a scalar x which can vary over 5 decades 
(xmax = 100'000). In this case, if activation grades are affected by random 
scale errors with a standard deviation cr(Llr/lx) = 25%, the standard deviation 
of the relative error affecting x is about 1.1 %. 

54 
Place coding in analog VLSI 
3.4.6 Noise 
a) Preliminary 
In the present paragraph, we consider a circuit consisting of M current 
sources made of a single saturated MOS transistor. The channel currents Ii 
of these devices, controlled by their gate voltage, represent the activation 
grades of the nodes: 
I· 
Ilxi =_1_ 
I max 
(3.25) 
In this equation, Imax is the full-scale current representing an activation 
grade of 1. We shall assume that all devices operate in weak inversion and 
that their gate voltages are noiseless, which means that only the inherent 
noise sources of these transistors are taken into account, not the 
contributions of previous stages. We are interested in determining the effect 
of intrinsic noise sources of the MOS transistor onto the represented value x. 
Obviously, the results will apply only to a specific class of implementations 
of continuous place coding. However, by similarity, it is easy to adapt these 
results for bipolar transistors, for voltage-mode implementations or for 
taking noise contributions from previous stages into account. 
Activation perturbations ~Ilxi due to noise and their effect ~ on the 
represented value generally depend on frequency, and are therefore 
characterized by their power spectral density (PSD): 
(3.26) 
Assuming statistical independence between noise sources associated 
with different activation grades, Equ. (3.10) can be rewritten as follows: 
(3.27) 
Given the bandwidth B of the activation grade signals, Sx can be 
integrated over frequency to get the total power P" of noise added to x. 

3. Continuous place coding 
55 
Subsequently in this paragraph, results will be expressed in this form for 
white noise sources. 
b) Shot noise 
Shot noise results in channel current variations, the PSD of which can be 
written [23]: 
SI = 2qI 
(3.28) 
where q is the elementary charge. These current fluctuations result in 
activation grade variations characterized by: 
S . = 2q~xi 
~l 
I max 
(3.29) 
Since S~i is proportional to activation grade, the sum in Equ. (3.27) has 
only two non-zero terms: 
Sx = 2q~xk . (X'k-x)2 + 2q~xk+l . (X'k+l-X)2 
I max 
Imax 
(3.30) 
Substitution of (3.6) into this equation leads to 
(3.31) 
An upper bound to Sx is given by 
(3.32) 
If the signal bandwidth of the activation grades is limited by a single pole 
at frequency B, then the integrated noise power added to x can be written 
(3.33) 

56 
Place coding in analog VLSI 
The plot in Figure 3.15, originally intended to illustrate random scale 
errors, applies to this case too (except for the nature of the vertical axis). 
With uniform sampling, the expression above becomes 
2 
P < 1t. qB. xmax 
x -
2 
4 Imax (M-l) 
(3.34) 
Noise power can be decreased either by increasing the current range Imax' 
or by increasing map size. Similarly to the case of random scale errors 
(§3.4.5b), larger maps result in smaller intervals between sample points x\, 
thereby reducing the magnitude of the perturbation on x produced by a given 
perturbation on a !lxi. 
In the case of uniform sampling, noise power is independent of x. In 
some instances, it may be preferable to make noise power proportional to 
signal power in order to get a constant signal-to-noise ratio over a possibly 
large range of x. This can be achieved by choosing logarithmic sampling 
(Equ. (3.8», which makes the intervals X\+l-X\ roughly proportional to x. 
In this case, noise power is 
P ::; 1t. qB . (M-lr;-- _1)2 .x2 
x 
4 I 
V A max 
max 
(3.35) 
With logarithmic sampling, it remains true that noise power can be 
reduced by increasing map size or current range. 
c) Flicker noise 
Flicker noise results in channel current variations, the PSD of which can 
be written [23]: 
A 
2 
S1 =-·1 
f 
(3.36) 
In the expression of SJ, f is frequency and I the average channel current. 
Among the various constants lumped into A, p is a constant specific to the 
fabrication process, Wand L are the dimensions of the device, and n is a 
slope factor involved in the relationship between gate voltage and mobile 
charge density in the channel [24]. These current fluctuations result in 
activation grade variations characterized by: 

3. Continuous place coding 
57 
(3.37) 
Substitution of (3.6) and (3.37) into (3.27) yields 
(3.38) 
An upper bound to Sx is given by 
( , 
, )2 
S < A . -,-X--=-k +.;,,;l:....-_X-=k:.!..-
X -
f 
8 
(3.39) 
Again, this relationship can be illustrated by Figure 3.15 as far as the 
dependency on x is concerned. For uniform sampling, the above equation 
becomes 
2 
S < A. 
xmax 
x - f 8(M-1)2 
(3.40) 
The PSD of flicker noise can be reduced by increasing map size, but 
unlike shot noise, it does not depend on the current range lmax. With 
logarithmic sampling, Equ. (3.39) turns into the following expression: 
(3.41) 
3.4.7 Fundamental limit to power dissipation 
a) Preliminary 
It is interesting to determine the theoretical minimum power dissipation 
in circuits using place coding, for comparison with conventional analog 
circuits. The lowest possible power consumption is reached in circuits 
where only changes of node states requires dissipation of energy, whereas 
no energy is dissipated at all in steady state. In the inductor-less world of 
integrated circuits, this is possible only if activation grades are represented 
by voltages across capacitors. In this section, we consider a set of M 

58 
Place coding in analog VLSI 
capacitors as a map, the activation grades J..lxi of which can vary from zero to 
the power supply voltage V max. Changes in J..lxi are assumed to be mediated 
by 100% current-efficient sources, meaning that any charge drawn from the 
power supply by one of these sources flows into the related capacitor during 
an increase of its activation grade. It is assumed that during a decrease of an 
activation grade, the excessive energy on the capacitor is dissipated and not 
recycled. In a first step, we shall determine how much energy has to be 
delivered by the power supply as x travels a complete period of a waveform 
of given peak-to-peak amplitude. The amount of energy depends on the 
power supply voltage. In a second step, we shall determine how far the 
supply voltage can be reduced while meeting a given signal-to-noise ratio 
specification. Together, these two results determine a fundamental minimum 
to the power consumption of a circuit based on place coding. The same 
approach has been applied before [25] to conventional analog circuits, 
which makes a comparison possible. 
b) Power dissipated during a cycle of x 
If x changes from an initial value XA = x\ to a final value XB = X\+l 
(where X'k and X\+l are the preferred values of two consecutive nodes), the 
activation grade J..lxk decreases from V max down to zero whereas J..lxk+l raises 
from zero to V max, as Equ. (3.6) shows. This change results in a shift by one 
node of the activation pattern on the map. During this transition, the power 
supply delivers an amount of energy CVma/. If a continuous change in x 
produces a shift of the activation pattern by K nodes on the map, then the 
total amount of energy E drawn from the power supply is KCV ma/. In 
general, the starting value XA or the final value XB do not necessarily match 
one of the preferred values x' j. The total energy in the general case depends 
on the particular distribution of sampling points x\ For uniform sampling 
(Equ. (3.7», the general expression can be shown to be 
(3.42) 
The energy drawn from the power supply is the same no matter whether 
x changes from XA to XB or reverse. If x varies periodically in time over a 
peak-to-peak range extending from XA to XB, then the amount of energy 
delivered by the power supply over a single period is twice the amount in 
the above equation. If the waveform of frequency f spans the whole range of 
x, then XA = 0 and XB = Xmax, and the average power dissipation becomes 
p= 2(M-l)· f· CV~ax 
(3.43) 

3. Continuous place coding 
59 
As an illustration, for a map size M = 100, a frequency f = 1 KHz, a 
capacitance to ground C = 1 pF and a power supply voltage Y max = 1 Y, 
power dissipation is about 200nW. 
Here we consider continuous changes of x only, meaning that during a 
transition from XA to XB, patterns representing all intermediate values of x 
are successively present on the map. With place coding, it would be possible 
to make this transition in a more direct and economical way from the power 
consumption point of view, but a comparison with conventional analog 
circuits would not be fair in this case. 
c) Thermal noise 
Thermal noise adds to voltages Yi representing activation grades. The 
power of noise affecting each individual voltage is given by 
PV=kT 
C 
(3.44) 
These voltage fluctuations result in activation grade variations 
characterized by: 
~ _ 
kT 
f.l- Cy2 
max 
(3.45) 
Noise power is independent of Ilxj, therefore it is the same for all nodes 
of the map (including inactive ones). The power Px of the noise component 
affecting x can be calculated from Equ. (3.27) in the same way as random 
offsets (§3.4.4b). For uniform sampling, the result is 
= k; .M.(X2-Xmax.X+2M-Ix~ax) 
CYmax 
6M-6 
(3.46) 
The noise power Px depends on x. The worst-case Px is reached for x = 0 
or x = Xmax. This upper bound is 
P < 
kT 
x - Cy2 
max 
M(2M - 1) 
2 
_ 
kT 
M 
2 
. 
·X 
---=--·-·x 
6M-6 
max - CV2 
3 
max 
max 
(3.47) 

60 
Place coding in analog VLSI 
The rightmost expression is valid as far as M» 1, i.e. nearly always. 
Noise power decreases with increasing voltage range V max and increasing 
capacitance C (hence decreasing bandwidth). Noise power increases for 
larger maps. This is a consequence of the additive nature of thermal noise in 
a voltage-mode implementation of a map. Just like for offsets, it is 
increasingly difficult to make the two active components of a map dominant 
if the number of inactive but still noisy components gets larger. 
d) Minimum power supply voltage 
If x(t) is a sine wave peaking at zero and Xmax, the signal-to-noise ratio 
SNR can be written 
2 
SNR= xmax 18 
Px 
6M-6 
8M(2M-l) 
2 
CVmax 
kT 
(3.48) 
The smallest possible power supply voltage V max to meet a given SNR 
specification with a given map size M is 
2 
M(2M-l) kT 
V 
=8 
·-·SNR 
max 
6M-6 
C 
(3.49) 
For M = 100, C = IpF, T = 300K and a SNR of 40dB, the smallest 
possible V max is about 105m V. 
e) Minimum power dissipation in a place-coded circuit 
The smallest possible power consumption for the place-coded 
representation of a sine wave of frequency f spanning the range [0, xmax] can 
be determined by combining (3.43) and (3.49): 
I 
M(2M-l) 
I 
P min = 
3 
. 8kT· f . SNR 
(3.50) 
This expression is valid for uniform sampling. For other sample 
distributions, the result may differ by a multiplying constant. For M = 100, 
f = 1KHz, T = 300K and a SNR of 40dB, Pmin is about 2.2nW. The minimum 
power consumption in the conventional analog case is [25] 
Pmin = 8kT· f ·SNR 
(3.51) 

3. Continuous place coding 
61 
In both cases, minimum power consumption is proportional to frequency 
and SNR. In the case of place coding, minimum power is multiplied by a 
quadratic function of the map size. In other words, the larger the map, the 
larger the minimum voltage swing for activation grades, hence the larger the 
power consumption. The reason for this dependency is that thermal noise 
contributes additively to activation grades represented by voltages, and it 
has been shown before that place coding is not tolerant to such perturbations 
(§3.4.4). A dominant contribution to the center of gravity of the pattern must 
be made by only one or two active components against nearly M additional 
inactive but still noisy components. In a voltage-mode place-coding circuit 
where dynamic power consumption due to node capacitors in the map 
dominates, power dissipation degrades with increasing map size. The 
degradation is even quadratic with M. One of the M's comes from the fact 
that M electrical nodes are charged and uncharged at every cycle 
(Equ. (3.43». The other M is due to the fact that M noise sources contribute 
independently to the total noise (Equ. (3.46». 
f) Comment 
The above results speak against circuits based on place-coding as far as 
power consumption is concerned, since the fundamental limits are always 
worse that the limits of conventional analog circuits. However, the trend 
reverses with current-mode implementations as will be shown later (§3.4.8): 
in this case, the minimum power consumption decreases with increasing 
map size. One could argue that current-mode circuits are not suitable for 
lowest power consumption because it is inherently impossible to cancel 
static power consumption completely. This argument is considerably 
weakened by the fact that it is most difficult in practice to build voltage-
mode circuits whose power consumption approaches the fundamental limit 
even remotely. This argument is also invalidated in systems where signals 
change most of the time. The minimum power supply voltage derived above 
takes only signal-to-noise requirements into consideration. This relation 
typically yields supply voltages of a few tens of millivolts. In practice, the 
smallest possible power supply voltage is also constrained by the transfer 
characteristics of available semiconductor devices (such as the threshold 
voltage of MOS transistors), which make power supply voltages well below 
1 V impractical. 
3.4.8 Power dissipation in current mode operation 
A similar approach as in the previous paragraph is applied to current-
mode circuits, because in this mode of operation, place-coding circuits have 
interesting potential advantages over conventional analog circuits. 

62 
Place coding in analog VLSI 
a) Conventional analog circuit 
We consider a current source delivering a sine wave spanning the current 
range [0, Irnax1: 
l(t)=.!lmax . (1+ sin rot) 
2 
(3.52) 
This current source is powered at a constant supply voltage V max chosen 
as the lowest value at which the current source can operate (which is 
implementation-dependent). The average power drawn from the supply is 
1 
P=-Vmax . 1 max 
2 
(3.53) 
Dynamic power consumption is assumed negligible. A reduction of the 
full scale current lmax results in a reduction of power dissipation at the cost 
of an increase of shot noise power relative to signal power (§3.4.6b). Power 
dissipation can be minimized by choosing the smallest possible lmax for 
which some signal-to-noise ratio specification can be met. Assuming that the 
signal bandwidth is limited by a single pole at frequency B, the integrated 
power PN of shot noise added to I(t) is 
1t 
PN =-B·q·1 
2 
max 
(3.54) 
which leads to the following expression for the signal-to-noise ratio 
SNR: 
(3.55) 
For a specific SNR, the minimum power consumption is 
Pmin =2n·qVmax ·B·SNR 
(3.56) 
This expression is roughly similar to the minimum power expression 
found in the voltage-mode case (Equ. (3.51): both results are proportional 
to SNR; proportionality to frequency in voltage mode becomes a 
proportionality to signal bandwidth in the current-mode case; the "energy 
quantum" kT becomes q V max in current mode. As an illustration, for 

3. Continuous place coding 
63 
V max == 1 V, B == 1 KHz and a SNR of 40dB, the minimum power P min is about 
lOpW. 
It is interesting to point out that the voltage mode minimum power 
depends on frequency, whereas the above expression does not. This might 
suggest the existence of a frequency threshold, beyond which the current-
mode circuit consumes less power than the voltage-mode one. This 
threshold frequency flim can be calculated by equating (3.51) with (3.56), 
which yields 
(3.57) 
Unfortunately, unless the power supply voltage Vmax is lower than UT, 
which is hardly possible in practice, the threshold frequency lies beyond the 
bandwidth of the current-mode circuit. Even for a sine wave at frequency 
f == B, the minimum power consumption of the current-mode circuit exceeds 
the voltage-mode minimum consumption by a factor in the order of V max/UT 
(= 40 for V max == IV and T == 300K). 
b) Place coding circuit 
We consider a circuit where activation grades are represented by currents 
Ii ranging from zero to lmax. The current sources which deliver these signals 
are powered at a constant supply voltage V max chosen as the lowest value at 
which the current sources can operate (which is implementation-dependent). 
Whatever x and however fast the pattern changes, the total current drawn 
from the power supply remains always equal to lmax, since it has been 
assumed in the preliminary paragraph of this section (§3.4.1) that the sum of 
activation grades over the map is normalized to 1. The power consumption 
of this circuit is therefore 
P == Vmax . I max 
(3.58) 
The full scale current lmax can be reduced only as far as the effect of shot 
noise remains acceptable (see Equ. (3.34)). For uniform sampling, if x is a 
sine wave peaking at zero and xmax, the signal-to-noise ratio SNR can be 
written 
2 
SNR == xmax /8 == (M _ 1)2 Imax 
Px 
21t·qB 
(3.59) 
For a specific SNR, the fundamental minimum of power consumption is 

64 
Place coding in analog VLSI 
p. =21t.qVmax ·B.SNR 
mm 
()2 
M-l 
(3.60) 
With place coding in current mode, unlike voltage mode, the minimum 
power decreases quadratically with map size. This result was expectable, as 
it was shown in §3.4.5 that larger maps tolerate multiplicative perturbations 
better, which makes higher shot noise levels acceptable and enables 
reducing lmax. For M = 100 and otherwise the same parameter values as in 
the previous example, Pmin is about IfW. As in conventional current-mode 
circuits, minimum power does not depend on frequency. A remarkable 
property of current-mode place coding circuits is that it is possible to find 
operating conditions under which their fundamental power consumption 
limits are lower than the fundamental limits of conventional analog circuits. 
The threshold frequency above which this is true can be calculated by 
equating (3.51) with (3.60): 
f. -
1t 
VmaxB 
hm -
2 
4(M-l) 
UT 
(3.61) 
This threshold frequency is lower than the bandwidth of the activation 
grade signals if the following condition is true: 
(3.62) 
For V max = IV and T = 300K, M must be at least 7 to keep flim lower than 
B. For M = 100 and B = 1KHz as in the previous examples, flim is 
about 3.1Hz. 
Other considerations than signal-to-noise ratio might prevent reaching 
the above power consumption limit. At very low currents, it may not be 
possible to meet bandwidth specifications, as transconductances are 
proportional to current (in bipolar transistors and MOS transistors in weak 
inversion) while parasitic capacitances remain essentially constant in a 
given technology. Another serious practical limitation is the existence of 
junction leakage currents which add to activation grades, and which large 
maps are sensitive to (§3.4.4). 

3. Continuous place coding 
65 
3.4.9 Bandwidth 
The signal representing an activation grade is necessarily limited in 
bandwidth. Let us assume that its frequency range is limited by a single pole 
at frequency B. A step change from any activation pattern to any other will 
occur with a time constant 't = 1I2rrB. Therefore, the represented value, 
which is the center of gravity of the pattern, will also settle within a time 
delay of a few 'to However, the transient evolution of x in time can usually 
not be described by an exponential function, therefore the concept of 
bandwidth as defined in linear systems is not directly applicable to maps. 
The purpose of distinguishing settling time from bandwidth can be 
illustrated by a particular example. If x is a sine wave of frequency f, the 
activation pattern moves on the map at this frequency. The activation grades 
are periodic signals with the same frequency as the pattern, but they are not 
sine waves, therefore they will contain harmonics at integer multiples of f. 
To prevent distortion, the frequency of the sine wave must remain well 
below the bandwidth B of the activation grade signals. It should be noted 
that the margin between B and system bandwidth must increase with larger 
maps, because activation grades must vary faster and nodes remain active 
for a shorter time. 
3.4.10 Implications 
The main results presented in this section can be summarized as follows: 
1. Place coding is sensitive to additive perturbations of any kind, and this 
sensitivity increases with the number of nodes. This statement applies to 
fixed perturbations (offsets) and noise in some implementations. A map 
must therefore be implemented in such a way to minimize offsets and 
additive noise. 
2. Place coding is completely insensitive to global scale variations of 
activation grades. 
3. Place 
coding 
is 
sensitive 
to 
multiplicative 
perturbations 
(i.e. 
perturbations which magnitude is proportional to activation grade), but 
this sensitivity decreases with the number of nodes. In principle, the 
effect of such perturbations can therefore be reduced to arbitrary limits 
by dimensioning the map properly. 
4. The fundamental limit to power consumption is less favorable for 
voltage-mode place-coding circuits than for a conventional analog 
circuits, and it degrades with increasing map size. 
5. The fundamental limit to power consumption specific to current-mode 
circuits is more favorable for place coding than for a conventional analog 

66 
Place coding in analog VLSI 
representation. The minimum power consumption decreases for larger 
maps. 
6. There exists a threshold frequency (dependent on map size and supply 
voltage) above which the fundamental limit to power consumption is 
lower for current-mode place coding circuits than for conventional 
analog circuits, including voltage-mode circuits. 
These properties speak in favor of current-mode implementations of 
place coding, because the dominant perturbation types in analog circuits 
have multiplicative effects on currents, but additive effects on voltages. This 
statement applies in particular to threshold voltage and transconductance 
factor spread in MOS transistors, flicker and shot noise, and specific current 
spread in bipolar transistors. Assuming a current-mode implementation, the 
following remarks can be added to the list: 
1. For a given noise level affecting the activation grades, the signal-to-noise 
ratio of the represented value improves with map size. It is usually better 
than the signal-to-noise ratio of the activation grades themselves. 
Therefore, there is no fundamental restriction to the dynamic range 
which continuous place coding can support, as far as the hardware cost 
of increasing map size remains acceptable. 
2. With logarithmic sampling, for a given map size and activation noise 
level, the signal-to-noise ratio of the represented quantity remains 
constant over the whole dynamic range. This is an inherent "analog 
floating point" feature [26][27]. This feature is also present in log-
domain circuits [3][4]. It is interesting that "log-domain" features can be 
obtained merely by choosing preferred values appropriately, which is 
purely a matter of convention and does not cost anything specific from a 
hardware point of view. 
3. With logarithmic sampling, the number of nodes in a map increases 
logarithmically with dynamic range if the signal-to-noise ratio is kept 
constant. With conventional digital coding, the hardware cost of 
increasing dynamic range is also logarithmic, but with a constant 
resolution. 
3.4.11 Cancellation of additive perturbations 
The key feature which makes current-mode circuits better than voltage-
mode for place coding is that the magnitude of the dominant types of 
perturbations drops to zero for inactive nodes. Thereby, nodes which must 
be inactive have really no influence on the result. Other implementation 
solutions may have the same property (e.g. representing activity by the 
frequency of a pulse stream). It must be noted however that a simple change 
in the definition of continuous place coding could dramatically improve 

3. Continuous place coding 
67 
performance of voltage-mode place coding circuits or other implementations 
where additive perturbations are dominant. Instead of taking activation 
grades directly as weights in the center of gravity computation (Equ. (3.3)), 
weights could result from a threshold operation or any other non-linear 
operation canceling the influence of weak: activation grades. As long as 
additive perturbations remain small with respect to the full scale, noise 
contributions of inactive nodes can be canceled by such a mean, at the cost 
of a modest distortion of the represented quantity. 
3.5 Discussion 
3.5.1 Recapitulation of features 
In the present chapter, continuous place coding has been defined as a 
representation convention supporting continuous ranges of real numbers. 
Interesting features of this representation in the context of analog circuits 
have been summarized in §3.4.1D. Other features valid in a more general 
context are reminded in the following: 
1. Real numbers are encoded by the center of gravity of a graded activation 
pattern made of a finite number of components. 
2. Compared to discrete place coding, the possibility of representing 
subsets instead of only scalars or vectors is lost. 
3. Any real number in a bounded range can be represented on a map with 
two nodes or more. By increasing the map size, sensitivity to many types 
of perturbations can be decreased to an arbitrary level, and accuracy of 
the target function approximation increases. 
4. A network of links designed to implement a discrete function 
interpolates this function continuously if the input and output patterns 
are considered from the point of view of continuous place coding. This 
statement is valid as far as the pattern spread at the input of the network 
is small enough that the function remains approximately linear in the 
pattern range. 
S. Within the accuracy limitations inherent to interpolation-based systems, 
a circuit implementation of any function can be constructed by 
application of a straightforward procedure. 
6. Pattern spread is the key parameter determining performance of a 
network of links in terms of: 
-
matching between the intended and the actual transfer function 
-
consistency of the response to different representations of the same 
input value 
-
sensitivity to perturbations 

68 
Place coding in analog VLSI 
For tight patterns, pattern spread is equal to the sampling interval, in 
which case some of these results can be interpreted in the light of the 
sampling theorem [22]. 
Continuous place coding has some properties in common with symbolic 
representations like digital coding, and some other properties in common 
with an analog representation. 
3.5.2 Related representations 
Continuous place coding is somewhat related to several other 
representation conventions used in the context of artificial neural networks 
(see [28] for a review). In the particular case where patterns are tight, 
continuous place coding is equivalent to a representation convention called 
interpolation coding [29]. This representation has been originally proposed 
as a high-level model of biological neural systems. Its properties have been 
studied from a mathematical point of view, with much similar conclusions 
as given in the present chapter. However, the computational means proposed 
in [29] to process interpolation-coded data differs from networks of links. In 
addition, this work on interpolation coding does not seem to have led to 
dedicated hardware implementations. 

PART II 
CIRCUITS 

Chapter 4 
Fuzzy rule chip 
4.1 Preliminary 
The first few chapters of this book have described place coding and 
networks of links as a mean of carrying out computation. We have assumed 
the existence of some conversion devices turning a conventional 
representation of input signals into place-coded activation patterns. We have 
addressed the problem of processing these patterns across multiple layers of 
interconnections. We have also assumed the existence of some devices 
turning the final output pattern into a conventional representation (or an 
action). The simplest system of this kind would be made of a single layer of 
links, immediately preceded and followed by conversion devices translating 
conventional representations to place coding and reverse. It turns out that 
this minimal system is structurally and functionally equivalent to a parallel 
implementation of a set of fuzzy rules. This chapter describes a prototype 
integrated circuit which implements such a single-layer network of links 
with associated representation converters, hence the qualification "fuzzy 
rule circuit" used in the chapter heading. The presented circuit has been 
designed with the intention to reduce silicon area and power consumption as 
much as possible. The core of the described fuzzy rule circuit is a 
combination of functional blocks made of linear resistors, which can be 
implemented efficiently in MOS technology by application of the concepts 
of pseudo-voltage and pseudo-conductance [30][31]. 
After a brief reminder on the concept of fuzzy rule, the main circuit 
elements are described in terms of linear resistors. The MOS transistor 
implementation is described subsequently, followed by measurement results. 
The chip has been used to synthesize a specific non-linear dynamic 
behavior. A description of the synthesis procedure followed for the design 
71 
O. Landolt, Place Coding in Analog VLSI
© Springer Science+Business Media Dordrecht 1998

72 
Place coding in analog VLSI 
of its transfer function is given, since it might be applied to other problems 
as well. 
4.2 Reminder on fuzzy rules 
The following reminder on the concept of fuzzy rule is strongly 
condensed, since this is not a central topic in this work. A more elaborated 
and rigorous introduction can be found in [21] or [32]. 
4.2.1 Expression and evaluation 
A fuzzy rule is an expression of the form 
IF <condition on input variables>, THEN <assignment to output variables> 
The condition part defines a subset of an input space (possibly multi-
dimensional) where the rule applies. This subset is fuzzy, meaning that a 
particular point of the input space may belong only partially to this subset. A 
membership function, taking its values from 0 to 1, defines to which degree 
every point in input space belongs to this subset. In other words, it defines 
the "degree of truth" of the condition as a function of position in the input 
space. The assignment part of the rule specifies the values which one or 
several output variables should take when the condition part is true. Rules 
are intended to be used in sets, where different rules apply to different 
subsets of the input space with some overlap between their respective 
(fuzzy) domains of validity. A set of rules is a piecewise description of a 
function, much similar to a look-up table. Because their respective domains 
overlap, areas in input space exist where several rules apply. In these areas, 
output variables are assigned a weighted combination of the values 
associated to valid rules, the weight being the "degree of truth" of their 
respective condition parts. 
Conditions are made of one or several elementary statements, combined 
by logical operators. An elementary statement defines a (fuzzy) range of a 
single input variable expressed by a linguistic label, e.g. "Xl is small". A 
complete condition is a logical combination of elementary statements 
applying to different inputs, e.g. "Xl is small and X2 is medium". For such a 
linguistic expression to be fully defined, the meaning of every label used in 
it must be made explicit by a membership function of the input variable it 
applies to. For instance, label "small" in the previous example must be 
defined by a membership function of Xl describing unambiguously to which 
degree each possible value of Xl can reasonably be called "small". 

4. Fuzzy rule chip 
73 
A set of fuzzy rules can be evaluated for a particular combination of 
input values. This process consists of determining the "degree of truth" of 
the condition part of each rule, then combining the output assignment values 
of all rules in a center of gravity computation, where the weight of each rule 
is its "degree of truth". 
4.2.2 Generic fuzzy controller 
A fuzzy controller is a piece of hardware which implements a set of 
fuzzy rules. There are many different ways to build a fuzzy controller. In the 
case of a parallel implementation (i.e. a distinct circuit element is allocated 
to each rule), a typical architecture is shown in Figure 4.1. This schematic 
shows a set of nine rules with two inputs. Each input has three labels 
embodied by membership function circuits. A rule circuit itself comprises a 
logic gate combining elementary degrees of membership into the degree of 
truth of a complete condition. In addition, it contains some kind of memory 
to store the output value to be assigned when the condition is true, as well as 
some element contributing to the center of gravity computation together 
with other rule circuits. Rule circuits are organized in a regular array, 
whereby a same label (membership function circuit) is used in the condition 
part of several rules in different combinations with other labels. 
Figure 4.1. Generic architecture of a parallel implementation of a fuzzy controller. 

74 
Place coding in analog VLSI 
In some sets of rules, several different rules have the same output value 
in their assignment part, i.e. the content of their memory is identical. In such 
a case, a functionally equivalent version of the above architecture, shown in 
Figure 4.2, can be more efficient. The center of gravity part of rules with 
identical output assignments can be merged together, provided that their 
respective weights are summed. This results in an array made of one cell per 
distinct memory value, dedicated to the computation of a center of gravity. It 
is distinct from the array of rule circuits, of which only the fuzzy logic gates 
are left compared to Figure 4.1. The output of each gate contributes 
additively to the weight of the relevant center of gravity unit (these 
connections are not shown explicitly in Figure 4.2). 
----~ 
'------
Figure 4.2. Alternative fuzzy controller architecture where center-of-gravity elements with the 
same memory content are shared among several rules. 
4.2.3 Relationship to place coding 
The relationship between a parallel implementation of a set of fuzzy 
rules and a network of links processing place-coded patterns is visible in 
Figure 4.2. Each set of membership function circuits can be considered as a 
conversion device between a scalar representation of an input signal into a 
place-coded representation. The array of logic AND gates together with the 
summing elements of the center-of-gravity array is actually a network of 
links. The center-of-gravity array can be considered as a conversion device 
turning the place-coded output pattern into a scalar output signal. 
Consequently, a set of fuzzy rules can be considered to be functionally 
identical and structurally similar to a network of links immediately preceded 
and followed by converters giving its inputs and outputs a "scalar" 

4. Fuzzy rule chip 
75 
appearance. Therefore, although this chapter is about an analog fuzzy 
controller chip, the circuit blocks described in it are relevant to the 
implementation of networks of links in a more general context. 
4.3 Conductance-based approach 
4.3.1 Key elements 
a) Fuzzy AND gate 
A two-input fuzzy logic AND gate can be built with two controlled 
resistors in series, as shown in Figure 4.3. The states of the input variables a 
and b are represented by the conductance values Ga and Gb respectively, 
which range from ° 
to some maximum value Gmax representing a grade of 1. 
The result of the operation is represented by the total conductance Gy of the 
branch. The fuzzy operator implemented by this circuit has the form 
1 
aAb=-l--l 
-+-
a 
b 
(4.1) 
While G. and Gb span the range [0, Gmax], the result Gy spans only 
[0, Gmax/2]. This discrepancy between the scales of input and output signals 
is not a problem for the intended use of this fuzzy logic gate, as we are only 
interested in the relative weights of different rules. However, for this reason, 
the operator above is not a strictly valid fuzzy AND from a theoretical point 
of view (see §2.2.4). 
Figure 4.3. Two-input fuzzy AND gate made of controlled resistors. 
The conductances G. and Gb can be single devices directly controlled by 
an electrical signal, or can themselves be combinations of several controlled 
resistors implementing a logical subexpression. In other words, with this 
resistive approach, nesting occurs by substitution of a single resistor in a 
gate by a more complex combination of resistors. In particular, AND gates 

76 
Place coding in analog VLSI 
with more than two inputs are obtained by connecting the matching number 
of controlled resistors in series. 
Similarly, fuzzy OR gates can be obtained by using parallel combinations 
of controlled resistors instead of series. In this case, the OR operator is 
actually an algebraic sum. 
b) Normalization 
Computation of a center of gravity reduces to a simple weighted sum if 
the total weight in the system is normalized to a constant: 
(4.2) 
k 
Normalization of a set of N weights can be carried out by means of the 
resistive circuit shown in Figure 4.4. Each input weight is encoded as the 
conductance Gi of a linear resistor. By application of Kirchhoff's laws, the 
current across each resistor can be shown to be 
G· 
Ii = I~k .10 
(4.3) 
k 
Obviously, the sum of branch currents Ii over the whole network is equal 
to the constant current 10, while relative branch currents match the relative 
conductance values. To compute a center of gravity, each individual Ik 
remains to be multiplied by its associated constant Ak, and the result must be 
summed over the whole network. 
Figure 4.4. Normalization to a constant total current by a network of controlled resistors. 

4. Fuzzy rule chip 
77 
c) Multiplication by a constant 
A current can be multiplied by a positive constant A ranging from 0 to 1 
by the resistive circuit shown in Figure 4.5. The coefficient is determined by 
the ratio between conductances GI and G2• If II is considered as the output 
signal, then 
1 
A= 
G 
1+_2 
Gl 
(4.4) 
This coefficient can be tuned continuously either by device geometry 
(hard-wired value), or by electrical control of these conductances (stored 
value). In the former case however, a large dynamic range for A necessarily 
requests a large device size. 
Figure 4.5. Multiplication of a current by a constant factor (hardwired in device geometry or 
controlled by an analog memory cell). 
An alternative resistive network shown in Figure 4.6 carries out a similar 
operation, but the coefficient is determined digitally. This circuit is a 
classical D/A converter based on an Rl2R ladder [33]. Depending on the bit 
states of the digital code representing A, the current across each vertical 
branch is added either to II> or to I2• If II is the output current and if A is an 
N-bit digital word whose bits are noted bk, then 
(4.5) 
Connections can be either hardwired as in Figure 4.6, or made by 
switches controlled by some type of digital memory cell. With this circuit, 

78 
Place coding in analog VLSI 
the cost of a high dynamic range for A is lower than with the circuit in 
Figure 4.5, because the total resistance grows only logarithmically with the 
dynamic range. 
Figure 4.6. Multiplication of a current by a constant factor represented digitally (hardwired in 
interconnections or controlled by digital memory). 
d) Weighted sum 
A weighted sum can be implemented by using one of the multiplier 
circuits described above for every term in the sum, and adding their results 
by connecting their outputs together onto a common node. In the particular 
case where coefficients are represented digitally, a simplification is possible 
which leads to a lower resistor count. Noticing that a D/A conversion is 
itself a weighted sum with constant coefficients (see Equ. (4.5», one can 
switch the summation order so that only a single Rl2R ladder is needed: 
(4.6) 
In these equations, bik designates bit number k of coefficient Ai. The 
expression on the right is a sum of N currents weighted by successive 
powers of two, which can be computed by a single Rl2R ladder. The terms 
of this sum are N global sums of currents Ii multiplied by a binary weight bik. 
Such a binary multiplication simply consists of connecting a particular Ii to a 
global node or not. The price to pay for sharing a single Rl2R ladder for all 
terms of a weighted sum is that N copies of each Ii are needed instead of 
only one. However, duplicating a current N times requires fewer resources 
than a D/A conversion. The resistive circuit shown in Figure 4.7 splits its 

4. Fuzzy rule chip 
79 
input current into N equal parts, which is equivalent of duplicating it, except 
for a constant scaling factor N. 
}.i 
~ 
Z 
Figure 4.7. Circuit splitting a current into N equal fractions. 
The global Rl2R ladder is slightly different from the local one, as can be 
seen in Figure 4.8, because its function is to sum several different currents 
weighted by successive powers of two, whereas the local version takes only 
a single input current and splits it several times into equal fractions. 
Figure 4.8. Rl2R ladder computing a sum of currents weighted by successive powers of two. 
4.3.2 Rule circuit 
A rule circuit (Figure 4.9) is obtained by properly combining the 
elements described in the previous paragraph. A rule circuit with M inputs 
comprises M controlled resistors in series which embody an AND gate as 
described in §4.3.1a. The conductance of each resistor is determined by a 
membership function circuit (not shown). One end of this resistor string is 
connected to a global node "ref' together with all other rules in the set, 

80 
Place coding in analog VLSI 
whereas the other end is connected to an internal node "g". A global source 
delivers a constant current 10 onto node "ref'. This arrangement has the 
structure of a normalizer as described in §4.3.1b, therefore the current 
flowing across the resistor string of a particular rule is proportional to the 
equivalent conductance of this string, while the sum of currents is 
normalized to 10. Ideally, the potential of the internal node "g" of the rule 
circuit should remain at ground level. With linear resistors, this condition 
can be met approximately by making the conductance of the parallel 
resistors (bottom of Figure 4.9) much larger than the highest possible 
conductance of the AND gate. With a MOS transistor implementation, node 
"g" can easily be kept at a constant potential as will be shown in §4.3.3. 
ref 
in! -1------"1 
H 
z 
outo 
outN_l 
Figure 4.9. Complete fuzzy rule circuit based on linear resistors. 
The second part of the rule circuit is made of N resistors of equal and 
constant value, where N is the number of bits of a digital coefficient 
associated to the rule. These elements split the current across the AND gate 
(which represents the normalized weight of the rule) into N equal fractions, 
in order to compute a weighted sum of digital coefficients as explained in 
§4.3.1d. 
Figure 4.10 shows how the digital coefficient associated to each rule is 
encoded in the connection pattern between its outputs and N global wires. If 
bit k of a coefficient is 1, then output k of the related rule circuit is 
connected to the global wire number k, else it is connected to ground. The 

4. Fuzzy rule chip 
81 
total current collected by the global wires matches the expressions shown on 
top of Figure 4.8. The global wires remain to be connected to an RJ2R 
ladder as shown in the same figure. 
N-] 
N-2 
1 
o 
I 
ref 
-I 
rule 
,.5 
circuit 
-
M 
out 
N-I N-2 ... 1 
110Y'" I 
~!~ 
T 
ref 
-
1 
rule 
,.5 
circuit 
-
M 
out 
0 
N-I N-2 ... 1 
O} 
O} I ... 1 
I 
ref 
-I 
rule 
:.5 
circuit 
-
M 
out 
0 
N-I N-2 ... 1 
0 
I 
Oyl ... O}O} 
Figure 4.10. Combination of several rule circuits. Global nodes include a line distributing the 
reference current 10, and N output lines collecting bitwise weighted sums. 
4.3.3 Resistive circuits in MOS technology 
The present paragraph is a reminder of some concepts introduced in [30], 
which will extensively be used throughout the remaining of this chapter. 
a) Pseudo-voltage and pseudo-conductance 
The channel current of a MOS transistor can be written in the following 
form [30][24]: 
(4.7) 
In this equation, V G is the gate voltage, V A and VB are the voltages at 
both ends A and B of the channel, and I is defined positive when it flows 
from A to B. All voltages are referred to the local substrate of the transistor. 
In addition, the specific current Is is defined as 
(4.8) 

82 
Place coding in analog VLSI 
In this equation, UT is the thermal potential kT/q, 
~ is the 
transconductance factor of the transistor and n is a slope factor relating the 
gate voltage VG to the pinch-off voltage Vp of the device [24]. Equation 
(4.7) is valid in all operating modes of the transistor. Analytical 
formulations of f valid over the whole current range can be rather intricate, 
but asymptotically, f tends to follow quite simple laws at both ends of the 
current range. In strong inversion (I »Is), f can be written 
for V <Vp 
(4.9) 
otherwise 
In weak inversion (I « Is), it can be written 
(4.10) 
In (4.9) and (4.10), Vp designates the pinch-off voltage [24], which is 
approximately given by 
(4.11) 
The general equation (4.7) for the channel current of a MOS transistor 
can be expressed in the following alternative form 
* (* 
*) 
I=G . VA -VB 
(4.12) 
where G* is defined as 
(4.13) 
and V A * and V B* are obtained by applying the following transform to V A 
and VB respectively: 
V* = ±Vo . f(VG' V) 
(- for n-channel, + for p-channel) 
(4.14) 

4. Fuzzy rule chip 
83 
In the last two equations, Vo is an arbitrary scaling voltage introduced to 
give G* the dimension of a conductance, and V A * and VB* the dimension of 
a voltage. The quantity defined by Equ. (4.13) is called a pseudo-
conductance, whereas the quantity defined by Equ. (4.14) is called a 
pseudo-voltage. The channel current of a MOS transistor is linearly related 
to the pseudo-voltage across its channel, just like the current flowing 
through a resistor is linearly related to the (conventional) voltage across its 
terminals. A circuit made of several MOS transistors interconnected by their 
sources and drains behaves like a network of linear resistors of constant 
value in the pseudo-voltage domain, under the condition that all transistors 
have the same gate voltage VG (so that the transform (4.14) is the same for 
all devices). As will be seen in part c) of the present paragraph, the pseudo-
conductance can even be electrically modulated by the gate voltage in weak 
inversion. Consequently, a resistive network can be implemented in MOS 
technology by replacing each resistor by a single MOS transistor. This 
possibility can be used to implement the rule circuit described in §4.3.2. 
b) Pseudo-ground 
The relation (4.14) between conventional voltages and pseudo-voltages 
is non-linear, and the pseudo-voltage tends asymptotically toward zero for 
large conventional voltages. The pseudo-voltage is virtually zero if V 
substantially exceeds the pinch-off voltage Vp (Equ. (4.11». This is obvious 
in the asymptotic expressions given in Equ. (4.9) and (4.10), and remains 
true in intermediate operating modes. Pseudo-ground, i.e. a null pseudo-
voltage, is therefore reached not only at a single conventional voltage, but at 
any voltage substantially larger than V p. This means that the pseudo-voltage 
domain equivalent of a grounded linear resistor is a saturated transistor. This 
is a very convenient feature, since the current flowing through such a 
"pseudo-grounded" device can be sensed without resorting to an active 
virtual ground as in the conventional voltage domain. A transistor which 
behaves like a grounded linear pseudo-conductance, when viewed from the 
"non-pinched" end, looks like a current source from the other end. 
c) Controlled pseudo-conductance 
In weak inversion, f(V G, V) can be written as the product of a function 
depending only on V G and another function depending only on V, due to the 
exponential nature of f (see Equ. (4.10». It may be interesting in this case to 
redefine pseudo-voltage V* and pseudo-conductance G* in a different way 
from above, without impairing the validity of Equ. (4.12): 

84 
Place coding in analog VLSJ 
(4.15) 
* 
(-V) 
V =±Voexp UT 
(- for n-channel, + for p-channel) 
(4.16) 
With these definitions, G* depends on the gate voltage V G, therefore the 
pseudo-conductance of a device in weak inversion can be electrically 
controlled. On the other hand, the non-linear relationship between V and V* 
does not depend on V G, therefore it is not necessary that the gate voltages of 
all transistors are equal in a circuit. If V G is applied by means of a diode-
connected transistor as shown in Figure 4.11, G* can be controlled by a 
current in a temperature-independent way: 
(4.17) 
By restricting the operating mode of all transistors to the weak inversion 
domain, increased flexibility is available for implementing resistive circuits. 
Circuits relying on electrically controlled resistors, like the fuzzy AND gate 
described in §4.3.1a, are required to operate in weak inversion. 
Figure 4.11. Current-controlled pseudo-conductance. 
4.3.4 Features 
The present section has described a fuzzy rule circuit in terms of linear 
resistors, and gives a hint on how this circuit can be translated into aMOS 
transistor circuit by using the concepts of pseudo-voltage and pseudo-
conductance. Before entering implementation details, interesting features of 
this rule circuit can be emphasized: 

4. Fuzzy rule chip 
85 
It is made of a low number of transistors, because most devices are used 
for multiple purposes. For instance, transistors in the AND gate also 
serve for the normalization function. Similarly, transistors in the Rl2R 
ladder are shared among all rule circuits. 
-
Current from a single source Io is made available to all rules without 
current mirrors or other causes of errors. Even over large distances, 
process parameter gradients, supply voltage gradients or device 
mismatch cannot influence scaling of the output signals of the rule 
circuit. 
-
If a rule has a zero weight (i.e. if any input of the AND gate is zero), 
current across the rule circuit is also zero, therefore no power is 
dissipated in rule circuits which do not contribute to computation at a 
given time. 
4.4 Structural description of the chip 
4.4.1 Block schematic 
The integrated circuit described in the present chapter incorporates the 
elements depicted in Figure 4.12. The chip has two voltage-mode inputs VxI 
and V x2 applied to two sets of membership function circuits (8 for V xl and 
10 for V d, the purpose of which is to tum their scalar input voltage into a 
place-coded representation. An array of 8 by 10 elements contains a rule 
circuit for every pair of nodes in the maps of Vx1 and Vx2• A total of 11 bits 
of digital coefficients are hard-wired in every rule circuit, therefore the rule 
array has 11 outputs too. These signals are combined together or otherwise 
post-processed in an output conditioning stage, delivering 5 final current-
mode output signals. In addition, the chip contains a bias circuit block which 
among other things generates a set of reference voltages which determine 
the locations of membership function peaks. 
A die photograph is shown in Figure 4.13. The chip has been integrated 
using a 2J.1m CMOS n-well process with a single polysilicon layer and two 
metal layers. The chip core dimensions are 1200J.1m by l100J.1m whereas the 
total die size is 1600J.1m by 1500J.1m. The rule array has a size of 800J.1m by 
700J.1m. The die has been mounted on a 16-pin DIL ceramic package. 
The next few paragraphs give transistor-level implementation details of 
the various blocks mentioned above. Most schematics are obtained simply 
by replacing resistors by transistors in figures of the previous section, and 
will therefore not be commented in detail again. Some other parts which 
have not been described yet will be discussed in some more detail. 

86 
Place coding in analog VLSI 
Vx2-----+I 
vxl 
Idxl 
eo 
Idx2 
::: 
·2 
0 . .:: 
Ih 
IOx8 rule array 
:.a 
::: 
0 u 
'5 
Iv 
.9-
::I 
0 
Iz 
00 
bias and reference circuits 
Figure 4.12. Block schematic of the prototype chip. 
Figure 4. J 3. Micrograph of the prototype integrated circuit. 

4. Fuzzy rule chip 
87 
4.4.2 Membership function circuit 
The purpose of a membership function circuit is to control a pseudo-
conductance G* as a function of an external input Vx (which can be either 
Vx1 or Vd, in such a way that G* is maximum when Vx is equal to the 
preferred value Vr of the membership function circuit, and decreases down 
to zero with increasing absolute difference between Vx and Yr. Figure 4.14 
shows a schematic of the membership function circuit used in the described 
chip (inside the large dashed box). This block is very similar to one of the 
"bump circuits" proposed in [34]. Voltage Va shifts the source potential of 
Nl and N2 up with respect to ground, in order to keep rule circuits properly 
biased. Differential pair PIIP2, biased in weak inversion, splits a constant 
current Ibiasl delivered by P3 into two fractions depending on the differential 
voltage Vx-Vr. Neglecting the presence of N3 and N4 for a start, the channel 
currents of Nl and N2 are sigmoidal functions of the input voltage (see 
Figure 4.15). 
(4.18) 
IN2 = 
t~ V J 
l+exp _ 
x -
r 
nUT 
Transistors N5 and N6 are part of a rule circuit (not shown entirely), and 
embody a controlled resistor of the fuzzy AND gate. Their pseudo-
conductance is proportional to the currents across Nl and N2 respectively, 
therefore they are also related to the differential input voltage by a sigmoidal 
law. The equivalent pseudo-conductance G* of N5 and N6 in series is a 
"bump" function: 
G* = Ibiasl . 
1 
2V 
V -V 
o 1 + cosh 
x 
r 
(4.19) 
nUT 
The relationship between G* and Vx-Vr is plotted in bold in Figure 4.15. 
It must be noted that input voltages are scaled to nUT. 

88 
Place coding in analog VLSI 
Vdd 
r 
Vbias1 I 
I 
I 
P2 
I 
HVr 
G* 
I 
Nl 
va 
~Ibias2 
Ibias2~ 
Figure 4.14. Schematic of a "bump" membership function circuit. 
-4 
-3 
-2 
-1 
2 
3 
4 
5 
Figure 4.15. Thin continuous lines: channel current of Nl and N2 normalized to Ibiasl • Thick 
continuous line: equivalent pseudo-conductance of N5 and N6 in series, normalized to its 
maximum value. Thick dashed line: threshold set by applying Ibias2• The actual membership 
function is the part of the bump above this threshold. 

4. Fuzzy rule chip 
89 
Transistors N3 and N4 subtract a constant current from the channel 
currents of PI and P2 for two purposes. First, they provide a discharge path 
for the gates of Nl, N5, N2 and N6. Self-discharge across diode-connected 
devices Nl and N2 can be exceedingly slow at low current levels, resulting 
in a long delay before a pseudo-conductance is completely off again after 
being turned on. Second, they narrow the width of the membership function. 
Although the "bump" drops to less than 20% of its peak value within 3nUT 
of differential voltage, a non-negligible activation grade remains over a wide 
input voltage range. Subtracting a small current Ibias2 (e.g. 15% of the 
channel current of P3 as in Figure 4.15) makes the membership function 
reach zero for a finite voltage difference. In the described prototype chip, 
this threshold can be set externally, enabling some limited tuning of the 
membership function width. 
4.4.3 Rule circuit 
A schematic of the rule circuit is shown in Figure 4.16. It is obtained 
directly from the linear resistor schematic in Figure 4.9 with a number of 
inputs M = 2 and a number of output bits N = 11. Each controlled resistor in 
Figure 4.9 requires two transistor instead of one because of the particular 
membership function circuit design (§4.4.2). The gates of Nla and NIb are 
controlled by a membership function of V x\' whereas N2a and N2b depend 
on V x2. Transistors Nla and NIb of an entire row of the rule array are 
controlled by the same unit, as are transistors N2a and N2b of an entire 
column. Bias voltage V G must be set high enough to saturate Nla. To get a 
ratio of at least 100 between the forward and reverse current across Nla in 
any case, the following condition must be met: 
(4.20) 
The highest possible gate voltage Via of Nla is determined by bias 
current Ibiasl and bias voltage Vain the membership function circuit. 
Transistors Nla, NIb, N2a and N2b have been chosen wide and short to 
keep them as deeply as possible in weak inversion, else the linear pseudo-
conductance model for weak inversion (§4.3.3c) is not valid. Simulations 
show that if these transistors are in strong inversion, the circuit does not 
interpolate smoothly anymore, but rather produces a "staircase-looking" 
transfer function. The other devices in Figure 4.16, which have a constant 
pseudo-conductance, have been chosen long and narrow in order to 
minimize second order effects which might affect the distribution of current 
among them. 

90 
Place coding in analog VLSI 
Via -----------1 
V lb -----------1 
V2a -----------1 
V2b----------~1 
ref 
Figure 4.16. Transistor-level schematic of a rule circuit. 
4.4.4 Output conditioning 
The eleven current components delivered by the rule circuit array 
determine five final output signals (Figure 4.17). Two unipolar signals Ih and 
Iv are obtained by combining respectively four and two components by 
means of Rl2R networks made of n-channel transistors, as explained in 
§4.3.1d. An additional component determines a third unipolar signal Iz by 
itself. All three output currents are delivered to bonding pads via p-channel 
current mirrors in order to offer an output voltage range from ground to 
nearly the positive supply rail. 
234 
5 
6 
7 
8 
9 
10 
11 
Rl2R 
Rl2R 
Figure 4.17. Block schematic of the output conditioning stage. 

4. Fuzzy rule chip 
91 
The last two pairs of components are subtracted from one another by a 
combination of current mirrors, yielding bipolar signals Ltxl and Ltx2. The 
purpose of these five output signals will be clarified subsequently when the 
function ofthe chip will be described (Section 4.5). 
4.4.5 Bias and reference 
The chip contains a circuit generating the necessary bias currents from 
an external reference voltage and several reference resistors, which will not 
be described here. It also contains means to generate 10 equally spaced 
voltages which define the preferred values of the membership function 
circuits (voltage Vr in Figure 4.14). The eight first voltages are common to 
both inputs. It has been mentioned in §4.4.2 that input voltages are scaled to 
nUT, which means that the membership function width is proportional to 
absolute temperature. It is necessary that the preferred values are also scaled 
to nUT in order to keep the degree of overlap between successive 
membership functions constant. The circuit depicted in Figure 4.18 is a 
voltage follower affected by an intentional offset of a constant multiple of 
nUT. Due to a geometrical ratio of 4 in current mirror PIIP2, output voltage 
Vrk+l exceed input voltage V rk by the following amount: 
(4.21) 
This equation assumes that the differential pair is biased in weak 
inversion, and that no current is drawn from the output. Of course, a random 
offset component adds to this voltage difference. It has been kept much 
lower than the intentional offset by dimensioning Nl and N2 generously and 
drawing the layout carefully. Eighteen of these circuits in cascade, with the 
first input connected to a reference voltage a few hundred millivolts above 
ground, deliver the preferred values of all membership function circuits. 
Only the output of every other stage is used, because the required voltage 
difference between successive preferred values is twice the voltage across a 
single stage. The peaks of two successive membership functions are 
therefore about 2.8·nUT apart. Going back to Figure 4.15, it can be seen that 
with this interval, at the peak of a particular membership function, the 
previous and next membership functions are active to about 20% of their 
peak value if the threshold current Ibias2 is zero. The intended operating mode 
is to set Ibias2 to about 20% of Ibiash so that the residual activity of a particular 
node of the map is just about zero at the preferred value of the next node. 

92 
Place coding in analog VLSI 
Figure 4.18. Floating voltage source used for generation of reference voltages. 
Voltages generated by this setup are also used to bias the rule circuit and 
Rl2R ladders in such a way that saturation of transistors is guaranteed 
wherever needed. As seen in Equ. (4.20), the minimum voltage for 
saturation is also expressed as a multiple of nUT, therefore using these 
reference voltages helps meet this condition with a minimum voltage 
margin. 
4.5 State-space dynamics synthesis 
4.5.1 Preliminary 
The primary purpose of the described prototype chip is to demonstrate 
that the resistor-based approach outlined in Section 4.3 really works when 
implemented with MOS transistors. However, designing a prototype 
requires the selection of a non-linear function which the chip should 
approximate. As a toy problem, an experimental synthesis of non-linear 
dynamic behavior has been chosen. More specifically, the selected goal is to 
create a system with a cyclic attractor of arbitrary shape, which evolves over 
time in such a way that its trajectory "draws" a message in state space. The 
present section is not really relevant to circuit design issues related to place 
coding, but is necessary to describe how the non-linear function of the chip 
has been designed, and what the chip actually does. 
4.5.2 Synthesis procedure 
Dynamic systems can be described by a set of equations of the form 

4. Fuzzy rule chip 
{X=f(X,U) 
y = g(x) 
93 
(4.22) 
In this equation, x is the state vector, u an external input vector and y the 
output vector of the system. Function f defines the direction of evolution in 
state space from every possible state and for every input vector. Weare 
interested in producing a specific cyclic attractor, i.e. a steady oscillation, 
therefore our projected system has no input vector u. An electronic system 
with a dynamic behavior specified in this form can be given the general 
structure shown in Figure 4.19 (for a two-dimensional state space and three 
external output signals). The box in this figure has a non-linear static 
transfer function matching f and g. In the absence of u, both f and g are 
functions of only x, therefore they can be merged into a single function, 
whereby x and y become different components of a single output vector. If 
state vector x is represented by voltages and x is represented by currents, 
then the integrators are simply grounded capacitors. 
Ylt-----+ 
g 
Y21-----+ 
Y3!-----+ 
Figure 4.19. Architecture for the synthesis of a dynamic behavior specified by state equations. 
The box has a static transfer function. 
With a set of fuzzy rules, we can specify a particular vector x and a 
particular vector y at a finite number of points in state space located on a 
Cartesian grid. Evolution from states located off grid is determined by 
interpolation from the closest nodes of the grid. A two-dimensional state 
space with bounded values for both components can be mapped by a 
rectangular array with a number of rows and columns matching the number 
of membership functions defined for each input component. Function f can 
be represented by drawing vector x as an arrow in each cell of the array. 

94 
Place coding in analog VLSI 
The state can be made to evolve along a specific path by orienting these 
arrows properly. The general idea is illustrated by Figure 4.20. 
a) 
b) 
~ 
-+ ~ ~ ~ ~ ~ ~ 
'" 
,1f rr ,1f ,1f ,1f '" 
I~ " 
,1f " ~ " " 
+- l~ " 
,1f ,,~ ~ "'t\ , I~ " 
,1f ..... " " 
,1f , 
'" " 
t ~ r<: + t 1\ ,,+-
Figure 4.20. Example state-space design of a particular cyclic attractor. a) Evolution vectors 
tangent to attractor (state may not remain on intended track). b) Evolution vectors with an 
additional component nonnal to the attractor (keeps state on the intended track). 
To create a stable cyclic attractor, two conditions must be fulfilled. First, 
in every cell which the state might cross, vector x must have a component 
tangent to the intended trajectory in order to produce an evolution in the 
intended direction (Figure 4.20a). In addition, cells on either side of the 
trajectory must create a component normal to the path in order to keep the 
state on the intended track (Figure 4.20b). If the second condition is not met, 
interactions between neighbor cells with conflicting evolution vectors may 
create "traps" (stable attractor points) and prevent the system from 
oscillating as intended. Any attractor shape can be created by this approach, 
within "resolution" limits set by the number of available cells. 
4.5.3 Demonstration function 
A closed trajectory in state space cannot cross itself, because in every 
state there is only one associated direction of evolution. To generate vector 
signals which follow an arbitrary path in a multidimensional space including 
crossings, the actual state space can be used only to create an oscillation, but 
shaping of the final output signals must be made by means of output 
function g (see Egu. (4.22». This approach has been applied to design a 
waveform generator chip which displays the four-letter message "CSEM"l 
on the screen of a cathode-ray tube. As was already shown in Figure 4.12, 
the architecture of the chip matches precisely the example in Figure 4.19. Its 
1 This is the acronym of Centre Suisse d'Electronique et de Microtechnique SA, Neuchatel, 
Switzerland, which is the company where this work has been carried out. 

4. Fuzzy rule chip 
95 
two voltage-mode inputs V xl and V x2 are state variables, and two of its 
current-mode outputs I.ix, and I.Jxz are meant to be integrated on capacitors 
and fed back to the inputs. Function f has been designed to create a 
trajectory which "scans" state space in order to successively activate every 
rule in the array. Two of the remaining outputs (~ and Iv) are the coordinates 
of a point in a plane, and are intended to drive the deflectors of a cathode-
ray tube (of an oscilloscope for instance). These coordinates are chosen at 
the breakpoints of a "piecewise straight" path drawing the intended message 
(large dots in Figure 4.21). Points are associated to rules in such a way that 
the output vector reaches these points in the correct sequence (bold line in 
Figure 4.21), given the trajectory in state space. The inherent interpolation 
mechanism of the circuit ensures that an approximately straight path is 
followed between these points, thereby leaving a visible trail on the screen. 
The described system can basically generate only a closed and 
continuous path. To make the message readable, it is necessary to disable 
display on segments joining two letters or while the beam flies back to the 
start of the message at the end of the cycle (dashed lines in Figure 4.21). 
This is the purpose of the Iz output signal, which is intended to modulate 
intensity of the light spot (z-axis on an oscilloscope). The output vector 
(lh, Iv, Iz) can be considered to follow a closed path in a 3D space. One level 
of the Iz axis is the "visible layer" whereas another level is the "hidden 
layer". Wherever a discontinuity in the display is necessary, the continuous 
path simply changes layer. By analogy with a pen plotter, one can consider 
the Iz signal to drive the "pen" up or down. 
~~ 
2 
b 
a 
q 
.P 
I 
m 
h 
f 
\ 
, 
~ / 
\ 
\ 
, 
\ 
\ 
r 
s \ 
0 
n 
3 
, 
g 
\ 
\u 
t 
k 
j 
i 
e 
c 
d .. ... 
o 
o 
2 
3 
4567891011 
Figure 4.21. Path followed by the output vector (Ih, Iv) for a complete cycle in state space. 
The large dots identified by a letter are coordinates hard-wired in rule cells. 

96 
Place coding in analog VLSI 
... ~ ~ ~ ~ ~ ~ ~ ~ + 
_u_e_ e 
5 
n 
1 1_1-
.If + .If .If .If .If .If .If ... J/ 
ja_a_e. e 
~ 
n 
1 1_1-
.If "- + J/ J/ J/ J/ J/ + J/ 
IU 
U 
n 
n 
I~ 
1 
KI 
J 
J_J_ 
.If "- ~ .. "- "- "- "- "- .. 
c 
c 
n 
n 
nIl 
KI 
J I 
J_J_ 
.If "-
~ + ~ ~ ~ ~ ~ + 
ID 
ID 
0 
0 
0_1-'_1-'1 
'I 
r 
r 
.If "- ... .If .If .If .If .If ... II' 
a a 0 
0 
o_P_PI 
'I 
r 
r 
.If .. J/ J/ J/ J/ J/ J/ + J/ 
a_a. a_u_u_u_u 
1 
s 
S 
+ "- "- "- "- "- "- "- "- .. 
a_a. a_u_u_u_u 
L 
s 
S I 
Vx2 
Figure 4.22. Symbolic representation of the coefficients associated to all rules in the chip. 
The full memory content of the rule array integrated on the prototype 
chip is shown in Figure 4.22. Each cell in this table contains a symbolic 
description of the coefficients stored in one rule circuit of the chip. An 
arrow shows the evolution vector (outputs Im) and Irua in Figure 4.12). A 
letter indicates the point in Figure 4.21 whose coordinates are encoded in 
the rule. The lower right square of a table entry is white if the light spot is 
made visible by that rule, or black if the light spot is hidden. 
4.6 Measurement results 
4.6.1 Bias conditions 
Bias conditions of the chip can be set externally by means of a reference 
voltage and several resistors. Measurement results reported in this section 
have been obtained in the bias conditions shown in Table 4.1 (symbols refer 
to illustrations in Sections 4.3 and 4.4). 
Table 4.1. Bias conditions summary 
description 
power supply voltage 
normalizer global current for rule array 
membership function circuit bias current 
membership function circuit threshold current 
voltage reference bias current 
symbol 
Vdd 
10 
I biasl 
I bias2 
Ibias3 
value 
1.8V 
44nA 
6.4nA 
450pA 
9.lnA 

4. Fuzzy rule chip 
97 
4.6.2 Power consumption 
Power consumption is essentially static. The following relation, 
established by inspection of detailed transistor-level schematics, is a slightly 
pessimistic estimate of the total current drawn from the power supply: 
Idd =5.10 +20·lbiasl +60·lbias2 +21·lbias3 
(4.23) 
The multiplying constant in front of each component are due not only to 
duplication of some circuit cells (e.g. membership function circuits), but 
also to the existence of some current mirrors and current conveyors in the 
bias circuitry. The total current drawn from the power supply, obtained by 
calculation and by measurements on five different chips, is shown in 
Table 4.2. 
Table 4.2. Calculated and measured power consumption 
quantity 
supply current Idd 
power dissipation P dd @ 1.8V 
calculated 
567nA 
1.02/lW 
measured 
470nA 
846nW 
Variations from chip to chip do not exceed 5%. The discrepancy between 
calculated and measured results is due to a simplification made in 
establishing Equ. (4.23). Power dissipation of the various blocks in the chip 
can be inferred from the schematics: 
Table 4.3. Contributions of the different functional blocks to power consumption 
block 
power 
% of total 
rule circuit array 
80n W 
9.5% 
output conditioning 
80nW 
9.5% 
membership functions 
205nW 
24.3% 
bias and reference 
480nW 
56.7% 
This table suggests that by a more efficient design of the bias elements, a 
substantial factor could still be gained in power consumption at no 
performance loss. 
The smallest possible supply voltage under which all measured chips still 
work is between 1.7V and 1.8V at room temperature. The existence of 10 
membership functions, with regularly spaced preferred values generated 
with the circuit described in §4.4.5, implies a voltage span of 
18·1n4·nUT = IV for the input signal. A higher voltage is needed in practice 
to ensure saturation of some critical transistors. 

98 
Place coding in analog VLSI 
4.6.3 Static transfer function 
The static transfer function of the chip has been measured by sweeping 
input voltages V xl and V x2 over the range of interest, and measuring the five 
output currents of the chip. Given the large time needed to sweep the whole 
2D state space with sufficient resolution, and given the difficulty to exploit 
the resulting data in a sensible way, only a few cross-sections of the transfer 
function have been acquired in detail. A cross section is obtained by keeping 
one input constant and sweeping the other over the range of interest. All 
measurements have been repeated for five different chips. Figure 4.23 shows 
typical results together with the calculated curve and the transistor-level 
simulation result. 
4 
3.5 
3 
2.5 
; - -:- - .. -
2 
, 
,'I I 
I •• I 
I 
I 
I 
I 
I 
I ,,' I ••• 
. 
. 
'. " 
. 
. 
: 
: 
: I." ~~~~~::=:s:~ 
1.5 • I'f, "'"' ,"P', ~ ... ,"P. 
I. 
0.5 
,: 
,.' ~ I I 
I I I ': I 
I ••• I : 
-
-: calculated 
, , , ,. simulated 
-:measured 
0.3 
0.41 
0.52 
0.63 
0.74 
0.85 
0.97 
1.08 
1.19 
1.3 
Vx1 [V] 
Figure 4.23. Cross-section of the static transfer function (Ih versus V xl for constant V x2)' This 
plot shows measurements from five different chips, calculations based on a linear resistive 
model, and transistor-level simulations with the EKV MOSFET model [24]. Vertical grid 
lines show the preferred values of the membership functions ofVx!' 
Matching between simulated and measured results is fair. Discrepancies 
can be classified into several categories depending whether they affect the 
transfer function locally or globally, and whether they are systematic or 
random. Local random variations are observed in areas where the transfer 
function should ideally be constant over a range spanning several rules. This 
shows that despite the fact that the same coefficient is hardwired in several 

4. Fuzzy rule chip 
99 
rules, the actual output they produce is slightly different. The only possible 
origin of this perturbation is mismatch in the rule circuit (Figure 4.16), 
because all other circuit parts would affect the transfer function globally. 
More specifically, the cause must be that the transistors splitting the rule 
current into eleven fractions are not perfectly matched, and produce unequal 
fractions which differ randomly from rule to rule. To evaluate this effect 
quantitatively, the standard deviation of output currents of the chip has been 
calculated over an interval where they should ideally remain constant. The 
result indicates approximately how accurate the current splitter part of the 
rule circuits is. This evaluation has been made for signals I.Jxl and 1.Jx2, 
because they have a large constant range in the measured cross-section of 
the static transfer function. For both signals and on five different chips, 
standard deviations between 2.4% and 2.8% have been found. This accuracy 
matches expectations, given that the MOS transistors splitting the rule 
current operate in weak inversion. In the described bias conditions, the 
inversion coefficient [24] of these devices is about 115 when a rule circuit is 
crossed by the entire normalization current 10. These transistors are 41lm 
wide and 20llm long. 
In addition to local random variations, observation of Figure 4.23 reveals 
substantial scale variations in the static transfer functions of different chips. 
To quantify these variations, the curve of each chip has been averaged over 
the measurement range, and the standard deviation of these averages has 
been calculated. For output signal Ih shown in Figure 4.23, a standard 
deviation of about 10% has been found. For the other output signals, the 
standard deviation ranges from 6% to 12%. One possible cause of scaling 
errors is device mismatch in the mirror which delivers the normalization 
current 10 to the rule array, resulting in a random scale error even if 10 is 
originally generated from the same external reference voltage and reference 
resistor. Another potential cause is accuracy limitations of the Rl2R ladder. 
A third possible cause is device mismatch in current mirrors of the output 
conditioning block. It is difficult to distinguish the contributions of these 
different error sources, except for the latter, because output current mirrors 
can be bypassed by means of switches built in for that purpose. The same 
cross-section of the transfer function as shown in Figure 4.23 has been 
measured again without these mirrors. Results plotted in Figure 4.24 show 
that the chip-to-chip dispersion is significantly reduced in this case. A 
similar procedure as before leads to a standard deviation of 4% of the 
averages of the shown curves, and 2.4% to 4% for the other output signals 
of the chip. These results lead to the conclusion that the sole fact that the 
output current is mirrored contributes a substantial fraction of scale 
dispersion. Increasing device size in these mirrors would be a simple way to 
improve reproducibility of the transfer function. 

100 
4.5 
4 
3.5 
3 
~2.5 
0 
~ 2 
1.5 
0.5 
Place coding in analog VLSI 
-
-:calculated 
, , , ':simulated 
-:measured 
OL-__ 
~ 
__ 
~ 
____ 
~ 
__ 
~ 
____ 
~ 
__ 
~ 
____ -L ____ L-__ -L __ ~ 
0.3 
0041 
0.52 
0.63 
0.74 
0.85 
0.97 
1.08 
1.19 
1.3 
Vxl [V] 
Figure 4.24. Cross-section of the static transfer function measured while bypassing the output 
interface (Ih versus V xl for constant V x2). This plot shows measurements from five different 
chips, calculations based on a linear resistive model, and transistor-level simulations with the 
EKV MOSFET model [24]. Vertical grid lines show the preferred values of the membership 
functions ofVxl. 
4.6.4 State space orbit 
When its outputs LIxl and Idx2 are loaded by 100pF capacitors to ground 
and fed back to its inputs V xl and V x2, the chip oscillates as expected at a 
frequency of about 6Hz (in the bias conditions described in §4.6.1). The 
orbit in state space has been measured by acquiring simultaneously both 
state voltages versus time by means of a digital storage oscilloscope. These 
waveforms are then displayed in the plane (Vx], Yd. Results from five 
different chips together with behavioral simulation results are plotted in 
Figure 4.25. The trajectory matches expectations and is fairly reproducible 
from chip to chip. At sharp turns, an overshoot is visible in the measured 
orbit. It is due to internal dynamics of the chip, which is completely 
neglected in the calculated curve. 

4. Fuzzy rule chip 
1.2 
1.1 
0.9 
0.8 
;> 
~0.7 
>< > 
0.6 
0.5 
0.4 
0.3 
0.2L-------~------~------~------~------~------~ 
0.2 
0.4 
0.6 
0.8 
Vxl [Vl 
1.2 
1.4 
101 
Figure 4.25. Measured state-space orbit of the oscillating chip, together with the orbit 
expected from simulation (bold dashed line). 
4.6.5 Output space trajectory 
In the same conditions and with the same method as in §4.6.4, output 
currents Ih and Iv have been measured. The trajectory of the output vector 
(lh, Iv) over several cycles is plotted in Figure 4.26, together with the 
simulated trajectory. This plot has been drawn without taking output Iz of 
the chip into account, because the intensity modulation input of the 
oscilloscope used for measurements affects directly the cathode ray tube, 
and not the digital acquisition process. Consequently, this plot shows a 
continuous path instead of four well-separated letters, although the blanking 
process driven by output Iz of the chip has been found to work correctly on 
screen. The measured path matches the expected path in shape. The most 
obvious cause of discrepancy is a scale error already discussed in §4.6.3. In 
addition, mismatch in rule circuits produces small random errors in the 
locations of breakpoints of the trace, resulting in skewed segments. To be 
honest, the result does not look very attractive from a graphical point of 
view, but except for these expected accuracy limitations, the chip is fully 
functional. 

102 
Place coding in analog VLSI 
10 --- ~ 
,---
, 
\ 
7 
6 
~ 
0 
5 
~ 
4 
3 
2 
-----
0 
0 
2 
3 
4 
5 
6 
7 
8 
9 
IhlIO [%] 
Figure 4.26. Measured trajectory of the output vector (Ib, Iv), together with the trajectory 
expected from simulation (bold dashed line). 
4.6.6 Bandwidth 
The overall bandwidth of the chip has been measured by applying a 
small-amplitude sinusoidal voltage to one of the inputs and measuring one 
of the output currents over a range of frequencies. The amplitude of the 
output sine wave (normalized to its low-frequency value) as well as the 
phase shift with respect to the input signal are shown in Figure 4.27. The 
small-signal bandwidth is about 1.5KHz. 
Due to the strongly non-linear nature of the chip and its static transfer 
function, this measurement alone does not yield a complete picture of the 
internal dynamics of the chip. A second type of measurement made on this 
device consists of applying an input voltage step spanning the whole input 
range, and measuring the settling time of the output signals. The response 
was found to be similar to a single-pole linear system, and settles with a 
time constant of about 165J.ls. This time constant is consistent with the 
small-signal result. Transistor-level simulations suggest that the limiting 
factors are the output nodes of the membership function circuits, which are 
rather high impedance due to the low bias current Ibias]' and are loaded by 
gate capacitances of a whole row or column of rule circuits. 

4. Fuzzy rule chip 
103 
~ 0 
~ 
c.. 
8 -20 . 
os 
_~L-~~~~~ 
__ ~~~~~~~~~~ 
__ ~~~~ 
101 
10' 
.. 
o .......... . 
. . ~ .... ,- .. '" -, -~ -......... -.. ' ... ~ ........ ,' ... -.... -.. ,- ,-. 
-200~~~~~~--~~~~~~~~~~--~~~~ 
101 
102 
103 
10' 
frequency [Hz] 
Figure 4.27. Measured small-signal transferfunction of the chip. 
4.7 Comments 
The approach based on a network of pseudo-conductances for the 
implementation of fuzzy rules has been proven valid by the described 
prototype chip. It yields a fairly dense and low-power implementation of a 
set of fuzzy rules. Accuracy (or rather reproducibility) of the transfer 
function is somewhat limited by device mismatch, as is the case for most 
current-mode weak inversion circuits. It has been shown that accuracy can 
be significantly improved by giving up output current mirrors, but in this 
case a larger supply voltage is needed if a substantial voltage swing is 
required at the outputs. Conservative dimensioning of some critical 
transistors, or using more accurate mirror structures (see e.g. [35]) would 
also improve accuracy. 
It has been noted already that fuzzy rules are actually a network of links 
embedded in interface circuits which convert a conventional scalar 
representation to and from place coding. An examination of the schematics 
reveals that most of the transistors are actually devoted to these conversion 
tasks. They include the membership function circuits with their voltage 
references, the current splitter part of rule circuits, and Rl2R ladders. For the 
implementation of networks of links processing place-coded maps directly, 

104 
Place coding in analog VLSI 
the described circuits can be stripped down to their very bone, which is the 
fuzzy AND gate described in §4.3.1a. This approach has been used for the 
design of another integrated circuit which is described in Chapter 5. 

Chapter 5 
Incremental oculo-motor control chip 
5.1 Preliminary 
Place coding and networks of links, defined in the first few chapters of 
this book, have been applied to a control problem involving an optical light 
deflection system. In association with a retina chip [36], this optical system 
is intended to emulate the functionality of a mobile eye, hence the name 
"oculo-motor system". The purpose of the control chip is to drive two 
motors of the light deflection system under permanent visual feedback. The 
system as a whole is intended to implement a set of oculo-motor reflex 
functions like tracking of moving objects or compensation of ego-motion in 
order to facilitate and improve visual perception. 
A brief description of the light deflection system is given in the next 
section, as well as some equations modeling its operation. A detailed 
description of the integrated circuit which implements the control function 
follows, together with measurement results. 
5.2 Light deflection system 
5.2.1 Optical system 
The light deflection systeml is made of two transparent and flat disks 
with a grating on one side, mounted perpendicularly to the optical axis of a 
lens. Each disk can rotate without restriction around this axis, independently 
1 The author gratefully acknowledges the contributions of his colleagues Patrick Debergh, 
who has conceived and developed the light deflection system, and Friedrich Heitger, who 
has designed and built the mechanical construction operating it. 
105 
O. Landolt, Place Coding in Analog VLSI
© Springer Science+Business Media Dordrecht 1998

106 
Place coding in analog VLSI 
from the other. A spatial period of the grating is a flat strip tilted with 
respect to the unstructured side of the disk, and can therefore be considered 
as a small prism. As a whole, each micro-prism grating acts on light 
essentially like a single large prism, except that it takes much less space. For 
simplicity, operation of this system will be described by replacing these 
gratings conceptually by two conventional prisms. 
retina 
lens 
rotating miC~ 
prism gratings 
Figure 5.1. Schematic of the light deflection system together with its retina. 
A prism deflects a light ray by an angle which depends on the built-in 
prism angle, on relative refractive indices of air and the material the prism is 
made of, and on the incidence angle of the ray. Consequently, in the system 
shown in Figure 5.1, the light ray hitting the center of the retina 
perpendicularly generally originates from a point located off-axis. Although 
a single fixed prism cannot have an adjustable deflection angle, with two 
mobile prisms, any magnitude and direction of deflection within some 
boundary can be selected, because the two contributions may combine either 
constructively or destructively depending on the relative prism orientations. 
Therefore, the illustrated system can be used to shift the direction of gaze of 
the retina freely within a solid angle extending symmetrically around the 
optical axis of the lens. The advantage of this system over many "mobile 
eye" constructions is that only two small, passive optical elements have to 
move, whereas most of the components are fixed. This eliminates the burden 
of connecting numerous electrical signals to a moving part, and makes it 
easier to achieve fast movements than with a larger and heavier mobile 
element. The drawback of this solution is a poor image quality for common 
optical standards, due to various types of aberrations introduced by the 
prisms. However, for common standards, an electronic retina has a low 
resolution anyway, because the combination of light receptors and electronic 
components in the focal plane allows only for a limited number of pixels. 

5. Incremental oculo-motor control chip 
107 
For this reason, an optical front-end of moderate quality can be acceptable. 
Simulations and measurements have showed that aberrations introduced by 
the light deflection system do not degrade excessively the imaging 
properties of the retina intended to be used in this system [36]. 
5.2.2 Deflection of the central ray 
For the design of a control chip, the relationship between prism 
orientations and the direction and magnitude of deflection must be 
established. For this purpose, we calculate the path of the light ray which 
strikes the center of the retina perpendicularly, as it is refracted along the 
successive air/prism interfaces. 
lens 
prism I 
prism 2 
y 
--1~x 
1ft 
retina 
I 
I 
\ 
I 
I 
I 
\ 
plan'eA 
planeB ·planeC 
plane D 
Figure 5.2. Definition of symbols for calculation of the path of the central ray. 
Figure 5.2 defines some notations used in the following. We choose a 
Cartesian coordinate system such that an observer's eye located at the retina 
and watching straight along the optical axis would see the x axis extending 
horizontally to the right, the y axis pointing vertically upwards, and the z 
axis coming straight to him. The central light ray crosses two planes of both 
prisms. For each prism, one of these planes is perpendicular to the optical 
axis, whereas the other one is tilted by an angle ~ with respect to the first. 
These four planes which the light ray crosses are denoted A to D, and their 
unit-length perpendicular vectors are PA to PD. They divide space into five 
regions numbered 0 to 4. In each of these regions, the light ray travels 
straight, and its direction is noted by a unit-length vector ko to k4. By 
definition, the central ray we are interested in has a final direction given by: 

108 
Place coding in analog VLSI 
(5.1) 
Calculating the deflection of the central light ray consists of applying 
four times successively the general equation of refraction at a planar 
interface. For plane A, it writes 
(5.2) 
In this equation, nair is the refractive index of air, and nprism the index of 
the material the prisms are made of. The above equation would look much 
simpler in a well-chosen coordinate system in the plane containing the ray, 
but since the ray does not remain in a single plane while it travels across the 
optical system, this more general formulation is necessary. Since planes B 
and C are parallel, refraction across these planes cancels out, therefore 
(5.3) 
The gap between planes Band C produces only a small lateral shift of 
the light ray. The refraction at plane D can be written 
(5.4) 
We define the direction of gaze by two angles. The deflection magnitude 
o is the angle between k4 and the z axis: 
(5.5) 
The symbol ez denotes a unit vector parallel to the z axis. The deflection 
direction a is the angle between the x axis and the projection of ~ onto 
plane (x, y): 

5. Incremental oculo-motor control chip 
109 
(5.6) 
The symbols ex and ey are unit vectors parallel to axes x and y 
respectively. The equations given so far in this paragraph can be combined 
to calculate the magnitude 8 and direction ex of deflection as a function of 
plane orientations PA and Po. Since each prism has only one degree of 
freedom, which is rotation around axis z, it is preferable to express the result 
as a function of prism orientation angles <PI and <P2. These quantities are 
defined as the angle between vector ex and some reference vector tied to the 
mobile grating. For both prisms, the chosen reference vector is the direction 
of "steepest descent" on the tilted prism plane. For prism 1, this vector is the 
projection of PA onto plane B. For prism 2, it is the opposite vector to the 
projection of Po onto plane C. With these conventions, the relationship 
between <Ph <P2, PA and Po is 
[
COS <P1 sin ~1 
P A = sin <PI sin ~ 
cos~ 
[
- cos <P2 sin ~1 
PD = -sin <P2 sin ~ 
cos~ 
(5.7) 
The symbol ~ is the prism angle. By multiple substitutions of above 
equations into each other, an analytical expression can be found, which 
relates prism orientations <PI and <P2 to the direction of gaze of the retina: 
(5.8) 
The analytical expression of function f will not be written in detail 
because it is rather intricate. For the purpose of numerical computation and 
simulation, it suffices to evaluate equations (5.7), (5.2), (5.4), (5.5) and (5.6) 
successively. 
5.2.3 Graphical illustration 
Graphics can provide a better intuitive understanding of the relationship 
between prism orientations and deflection angles. The polar plots in Figure 
5.3 show the locus of directions of gaze obtained when one of the prisms 
remains fixed in orientation 0°, and the second prism makes a full revolution 

110 
Place coding in analog VLSI 
around the z axis. The radial coordinate in these plots is the deflection 
magnitude <5, whereas the angular coordinate is the deflection direction a.. IT 
one prism has an orientation of 0° and the other an orientation of 180°, then 
planes A and D (see Figure 5.2) are parallel, resulting in the cancellation of 
refraction at these two interfaces, therefore the direction of gaze is straight 
ahead. At the other extreme, if both prisms have the same orientation, their 
contributions cumulate, resulting in a maximum deflection of about 45° 
(calculated with a prism angle ~ = 30° and a refractive index nprism = 1.492). 
At intermediate orientations of the mobile prism, the direction of gaze 
travels along an egg-shaped curve with a radial axis of symmetry. The shape 
of this curve is different for the two prisms, as a comparison between the 
left and right plots shows. IT the orientation of the fixed prism differs from 
0°, then the egg-shaped locus rotates around the origin of this plot, but 
remains unchanged in shape. The direction of the axis of symmetry of the 
egg matches the orientation of the fixed prism. 
<pl=OO: 
9050 
12Q.······:· .. ·· .. 60 
." 
. 40 
'. 
. 
.' 
: 30 .... . 
15()" 
.' 
.' .:. " ... ' ". 
'. 30 
18atT!J!180",'.'; "\ ° 
. . " 
" ,  
. 
21d-:' 
..... ' . 
·330 
. . ~ .. . 
240··· .... : ...... '300 
270 
<p2=O°: 
9050 
12.Q ...... ': '40 .... ~.o 
: 30'" .'. 
15Q;· ... ·· .. 
:20.',. 
',30 
.~·1~· 
.... :·-:·:·:.··. 
18a~ 
.. ~1., •.. " ".:, i:t:=18
0.",) , .) ° 
21<1. 
. ..... . 
. . 
".' . 
240" ..... : .... ··"300 
270 
·330 
Figure 5.3. Deflection angles versus prism orientations. The radial coordinate is deflection 
magnitude, whereas the angular coordinate is deflection direction. The left plot shows the 
locus of directions of gaze when prism 2 rotates over a full cycle while prism 1 remains fixed. 
The plot on the right is similar, but prism 1 rotates while prism 2 remains in place. 
The loci shown in Figure 5.3 can be used to determine graphically the 
direction of gaze for an arbitrary combination of prism orientations. For this 
purpose, both loci can be drawn on the same polar plot, with orientations 
matching the given prism orientations. The direction of gaze is the 
intersection of both loci. An example is given in Figure 5.4. 

5. Incremental oculo-motor control chip 
III 
120 
....... 
60 
: 40 
: 30 
150 .. 
30 
: 20 
10" 
180:· .... 
o 
210 
240 
300 
270 
Figure 5.4. Graphical determination of the direction of gaze for <PI = 45° and <P2 = 120°. 
Considering this graphical solution, a few properties of the described 
light deflection system can be noticed: 
-
Rotating both prisms by an identical amount without altering their 
relative orientations results purely in a change of deflection direction by 
the same amount, but not a change of deflection magnitude. A radial 
change in the direction of gaze can occur only by bringing the prism 
orientations closer together or by pulling them further apart. 
There are generally two solutions to get a particular direction of gaze. 
Given one solution, the second can roughly be found by swapping the 
orientations of the two prisms. This swap does not provide the exact 
solution because the two egg-shaped loci are not identical. 
There are exceptions to the above rule. The two solutions merge into a 
single one at the maximum deflection angle. A second exception is the 
origin: as long as the two prisms have opposite orientations, light is not 
deflected whatever their actual orientation. 

112 
Place coding in analog VLSI 
An obvious consequence of these remarks is that function f introduced in 
Equ. (5.8) is not invertible. The above properties have significant 
implications on the design of the control chip. 
5.2.4 Control problem 
There are several ways the described light deflection system may be 
used, which differ by the coordinate system under which displacement 
requests are made. In the tracking case, given a visible target point, the 
control system must find out which minute change (d<p], d<p2) in prism 
orientations produces a minute shift (dx, dy) of the center of the visual field, 
straight in the direction of the target. The method used to calculate 
(d<ph d<p2) is based on the first-order development of function f, defined by 
Equ. (5.8), around the current prism orientations: 
(5.9) 
where f" and fs are the components of vector function f. The control 
action is determined by inverting this linear approximation (if the inverse 
exists): 
(5.10) 
At null deflection and at maximum deflection, the first-order 
approximation cannot be inverted. The best control action in these situations 
is determined empirically. In addition to Equ. (5.10), the relationship 
between retina coordinates (x, y) and deflection angles (a,o) must be taken 
into account to compute the control function. This relationship is invertible, 
and can easily be established if image deformations due to the prisms are 
neglected. 
The control chip described in the remaining of this chapter implements a 
non-linear function g depending on current prism orientations <PI and <P2, and 
on the angle e of vector (dx, dy). Thereby, it considers only the direction of 

5. Incremental oculo-motor control chip 
113 
the requested shift of gaze, not its magnitude. It computes a vector 
(b<pt, b<P2), which is parallel to vector (d<pt, d<p2), but normalized to 
approximately unit length. 
(5.11) 
Because of the circular symmetry of the light deflection system, it is 
possible to reduce this function of three variables into three functions of 
only two variables, which reduces the number of links needed to implement 
this function. What the chip actually computes is 
(5.12) 
5.3 Description of the chip 
5.3.1 Architecture 
The architecture of the chip is shown in Figure 5.5. The input layer is 
made of three independent maps. A map with 8 nodes receives the 
direction e of displacement requests from a visual perception system. Two 
other maps with 16 nodes receive place-coded stimulations from two 
external sensors detecting the current prism orientations <PI and <P2. External 
signal sources must stimulate these three maps consistently with the place 
coding convention. A more explicit specification of the input variable 
representation expected by the chip is shown in Figure 5.6 for the e map. 
Each plot in this graph shows the activation grade Ilk required for one 
particular node as a function of the desired e value. Membership functions 
for the <PI and <P2 maps are similar to these, except that there are 16 nodes 
instead of 8 for a complete cycle. 
Computation relies on three networks of links. Two of them implement 
an angular difference of the form <pi-e, whereas the third one implements the 
actual non-linear mapping (function g defined in Equ. (5.12)). The two 
angular difference networks are identical in all respects. The third network 
differs in the topology of the interconnections, but its operation principle is 
very similar. These networks are described in the next two paragraphs. 

114 
Place coding in analog VLSI 
+ olPJ. -
failure 
+ &t2 -
Figure 5.5. Architecture of the chip. The number of nodes in the input and intermediate layers 
has been reduced by a factor of 2 in this drawing for the sake of clarity. The purpose of the 
"failure" output signal is explained in §5.3.3. 
I 
(wrap 
around) 
Figure 5.6. Stimulation grade versus represented value for the e map. One of the membership 
functions is shown in bold for clarity. Since e is an angle, the leftmost half-triangle belongs to 
the same membership function as the rightmost one. 
An analog integrated circuit implementing this architecture has been 
fabricated in a O.71lm CMOS technology (Figure 5.7). The area of a single 
angular difference network is 250llm by 280llm. The non-linear mapping 
network takes 650llm by 7001lm. The chip core is less than 2mm2 large, 
including some auxiliary elements incorporated to simplify testing. 

5. Incremental oculo-motor control chip 
115 
Figure 5.7. Micrograph of the chip core. 
Stimulation grades applied from outside the chip are represented by the 
frequency of pulse streams. In order to reduce the number of pins, a non-
arbitrated address-event approach [37] has been selected as a time-
multiplexing scheme to stimulate input maps. This communication protocol 
has been used already for the implementation of some vision chips 
[36]-[40], making the interface between these chips and the reported circuit 
trivial. Interfacing more conventional circuits can be somewhat more 
tedious, therefore a block performing a digital/place-coding conversion has 
been incorporated on-chip. It generates a pattern of events on an address 
bus, representing its digital input number with the place coding convention. 
This block helps applying well-controlled test patterns at the input maps of 
the networks of links. 
5.3.2 Angular difference network 
The structure of an angular difference network is shown in Figure 5.8. It 
conforms to the general structure of a network of links described in §2.4.4. 
The inputs of the circuit are two maps, and its body is an array of identical 
cells made of two controlled resistors in series. The activation grade of each 
input node, denoted I.l.opi for the <p map and I.l.ei for the e map, determines the 
conductance of one resistor in all cells located in a single row or column of 
the array. The conductance is proportional to the activation grade, and 
therefore spans a range from 0 to some maximum value representing I. Each 
cell has the function of a fuzzy AND gate, as already described in §4.3.1a. 
One end of each cell in the array is connected to a global voltage source +V. 

116 
Place coding in analog VLSI 
The other end is connected to one node of the output map, which is 
maintained at ground potential. A cell with a preferred value (<Pi, 9j) is 
connected to the output node whose preferred value is dk = <Pi-9j. The output 
map dimension and preferred values have been chosen in such a way that a 
perfectly matching output node exists for all (<pi. 9j) pairs. The total current 
flowing onto each output node is proportional to the sum of conductances gij 
of array cells connected to it, and represents the activation grade of this 
node. By construction, a particular output node is stimulated in response to 
any combination of input values with an angular difference close to its 
preferred value. The activation grade depends on the degree of similarity 
between the actual and preferred angular difference. Consequently, the 
activation pattern on the output map is a place-coded representation of the 
angular difference between <p and 9. This map can be used as an input to a 
subsequent network of links based on a similar operation principle, which is 
done in the described chip. 
d1 
IlBl 
~ 
d2 
~ 
d3 
e map 
1lB2 
~ 
d map 
dI5 
~ 
dI6 
~ 
Figure 5.8. Resistive implementation of the angular difference network. At one end of each 
pair of resistors, an arrow stands for a connection (not shown explicitly) to one node of the 
output map shown at the right. 

5. Incremental oculo-motor control chip 
117 
The simulated transfer function of the angular difference network is 
shown in Figure 5.9. In this simulation, 6 is zero and <p is swept over 360°. 
For every <p value, the stimulation pattern resulting from the chosen 
membership functions (similar to Figure 5.6) has been applied to the 
network. The upper plot in Figure 5.9 shows the center of gravity of the 
output pattern together with the exact function (straight line with unit slope). 
On a large scale, agreement is good, but some ripples are discernible in the 
transfer function plot. The bottom plot shows the difference between the 
actual and ideal transfer functions on a magnified portion of the axis. 
Agreement is perfect (i.e. the error curve crosses the horizontal axis) 
wherever the input variables match exactly a pair of preferred values in the 
input maps. At these points, a single node in each input map is stimulated, 
whereby only one cell in the array and one output node are active. No 
perturbation of the activation grade can possibly alter the center of gravity 
of the output pattern in this case. At other points, the transfer function relies 
on relative activation grades. The non-linear activation grade combination 
performed in the array (Equ. (5.12)) results in ripples in the transfer 
function. If 6 takes values other than zero, the ripples in the transfer function 
can change somewhat in shape and amplitude. In the worst case, the error 
remains less than 7.5°. 
180r---~--~--~--~----~--'----r--~ 
135 .............. . 
90 
45 
o 
'0 -45 
-90 
-135 
-180~--~--~--~--~----~--~--~--~ 
-180 -135 
-90 
-45 
90 
135 
180 
10r-----,---------~----------~----~ 
8 
6 
4 
2 
~ -~ 
-4 
-6 
-8 
· 
. 
. 
.............................................. 
· 
. 
. 
· 
. 
........ : .............. : .............. : ...... . 
.............................................. 
· 
. 
. 
................. - ..... : .............. : _ .. -
. 
. 
-10~----~----------~----------~----~ 
-22.5 
22.5 
Figure 5.9. Simulated transfer function of the angular difference network. 

118 
Place coding in analog VLSI 
The resistive network shown in Figure 5.8 is implemented by an array of 
MOS transistors biased in weak inversion, resulting in a circuit closely 
related to the fuzzy rule circuit described in Chapter 4. A fragment of the 
angular difference network in its MOS transistor version is shown in Figure 
5.10. Input currents representing activation grades flow into the diode-
connected MOS transistors on the left and top of the schematic. The 
resulting gate voltages control the pseudo-conductance of a set of transistors 
in a row or column of the array. One end of each array cell is connected to 
ground (which is a non-zero pseudo-voltage) whereas the other end is 
connected to a current mirror input with a node potential high enough to 
keep the upper MOS of the array cell saturated (which corresponds to a 
pseudo-ground). The outputs of the current mirrors are directly connected to 
the inputs of the next processing layer, which is implemented by a similar 
MOS transistor array. 
Figure 5.10. Fragment of a MOS transistor array implementing the angular difference 
network. 
By connecting one end of each array cell to a global current source - as 
in the fuzzy rule chip - instead of ground, it would have been possible to 
normalize the output pattern to a constant total activity. It is often an 
advantage to have a normalized pattern, but in this chip, it is desirable that 
the prisms do not move in the absence of stimulations on the e map. Giving 
up the normalization is a simple way to disable the networks if all input 
nodes are inactive. 

5. Incremental oculo-motor control chip 
119 
5.3.3 Non-linear mapping network 
The network of links which implements function g introduced in 
Equ. (5.12) relies on the same operating principle as the angular difference 
network. The two maps dl and d2 resulting from the angular difference layer 
are applied to a 16 by 16 array of cells. Each of these cells is associated to 
one of 16 possible output vectors (0<j>1> 0<j>2) representing prism orientation 
increments. Associations are determined at design time by evaluating 
numerically Equ. (5.12), and picking the closest matching vector in the 
available set. Since the chip is intended to drive two stepper motors, it has to 
deliver independent output signals for 0<j>1 and 0<p2, coded by pulse 
frequencies, with a separate channel for positive and negative values. To 
fulfill this requirement, the circuit schematic for array cells (Figure 5.11) is 
slightly more complicated than in the angular difference network. In 
addition to a pair of controlled pseudo-conductances in series, a set of four 
additional constant pseudo-conductances splits the activation current into 
four equal fractions. Some of these fractions contribute to 0<j>1 and the 
remaining ones contribute to 0<j>2. The number of fractions connected to one 
or the other output determines the relative magnitudes of &PI and 0<j>2. The 
sign of each output component is determined by connecting these fractions 
to either the positive or the negative node. A total of 16 different output 
vectors (0<j>1> 0<j>2) can be hardwired with this array cell (Figure 5.12). 
Current intensities at the outputs of the network encode the relative prism 
angular velocities producing a displacement of the direction of gaze in the 
specified direction e. 
Figure 5.11. Array cell for the non-linear mapping network. 

120 
Place coding in analog VLSI 
&J>2 
-1 
-1 
Figure 5.12. Available choices for output vectors associated to an array cell. 
For some prism orientations, it is not possible to move further in the 
requested direction e, because the optical system has already reached the 
maximum possible deflection in this direction. Links which handle these 
input combinations project to an additional "failure" signal (shown in Figure 
5.5) which warns the system of this condition. For instance, this signal 
might trigger a saccade bringing the direction of gaze back to the center if a 
tracked object leaves the accessible visual field. Alternatively, this signal 
could enable "head" motions (or displacements of whatever mobile element 
the oculo-motor system is mounted onto) in order to keep the target in sight 
if the light deflection system alone is not sufficient anymore. 
5.3.4 Frequency/current converter 
Stimulations are applied to the chip by means of two input buses, using 
the address-event communication protocol described in [37]. One bus 
transmits stimulations to maps <PI and <P2, and an independent bus transmits 
inputs to map e. The receiver circuit of each node is made of a logic gate 
detecting the address associated to this node, and a linear frequency-to-
current converter (in short: FIl converter). The rate at which a specific 
address appears on the bus determines the activation grade of the related 
node. A slightly simplified schematic of the F/I converter is shown in 
Figure 5.13. 

5. Incremental oculo-motor control chip 
Vpu1 
Cc 
600fFT 
Figure 5.13. Schematic ofthe frequency-to-current converter circuit. 
121 
This schematic is a variation of the circuit published in [41], differing 
from the original circuit in that a passive grounded capacitor Cb replaces an 
active integrator. In the absence of a pulse, Vpul is low, therefore switch Sl 
is on and switches S2 and S3 are off. During this phase, C. is precharged to 
a constant voltage V ref, Cb remains in a constant state (as far as leakage 
currents are negligible) and Ce discharges by the effect of the channel 
current of Nl. The gate voltage V G of N1 and N2 is controlled by the 
voltage stored on Cb, therefore the discharge current remains constant and is 
proportional to the output current lout. At the occurrence of a pulse, the state 
of all switches is inverted, whereby all three capacitors are shorted together, 
leading to a redistribution of charge until the voltages across the three 
capacitors are identical. At the time the pulse disappears, the circuit enters 
the first phase again, and Ce discharges starting from this new initial 
condition. Neglecting leakage, the main state variable V G of this circuit is 
updated only as pulses occur, and so is the output current lout. The state 
evolution can be described in discrete time by calculating the net charge ~Qb 
added to Cb during each update: 
(5.13) 
In this equation, V G designates the voltage across Cb before the update, 
and Ve similarly designates the initial voltage across Ce. The charge 
contributed by Ce is proportional to both the output current lout and the time 
T = lIf elapsed since the last update: 
C . (v'G - V ) = lout . T = lout 
c 
c 
K 
Kf 
(5.14) 
In this equation, K is the ratio between the dimensions WIL of Nl and 
N2. Given a pulse frequency f, successive updates lead to a stable operating 

122 
Place coding in analog VLSI 
point (if the capacitors are properly dimensioned), characterized by the 
condition ~Qb = o. This condition is reached when the average current 
drawn on source V ref is equal to the channel current of N1. This leads to 
(5.15) 
ill this expression, V G and lout are related by the transfer characteristic of 
transistor Nl. However, over a wide current range, (Vrer-VG) can easily be 
made nearly constant by choosing a large V ref, e.g. V ref = 5V. Thereby, the 
relationship between lout and f can be made nearly linear. In reality, this 
relationship saturates at high frequencies, and the output current tends to an 
asymptotic value reached when the gate voltage V G is equal to V ref. 
Output transistor N2 shown in Figure 5.13 has been drawn only to help 
explaining the circuit. On the chip, gate voltage V G is used directly to 
control pseudo-conductances in the angular difference network of links 
described in §5.3.2. 
ill the original version of this FII converter [41], an active integrator 
replacing Cb creates a virtual ground between switches S2 and S3, and V G is 
driven by the output of this integrator. This makes the charge update 
(Equ. (5.13» independent from V G, therefore the relationship between lout 
and f is truly linear. However, since the communication scheme relies on 
short pulse durations (in the order of lOOns), this integrator has to deliver a 
high peak current (typically exceeding lOJ.LA) during updates to complete 
the charge balance within the pulse duration. Therefore, this integrator must 
either by biased at a high current, or have a fast class AB output stage. This 
leads either to a high power consumption, or to a complex circuit, both of 
which are difficult to conciliate with the existence of a large array of such 
receivers. This drawback has motivated the selection of a passive grounded 
capacitor instead of a true integrator, given that a high linearity is not 
necessary for processing activation grades in the context of place coding. 
Another recognized problem with the original F/I converter is that it reacts 
slowly to a decrease in the incoming pulse frequency, because its state is 
updated only when a pulse occurs. Convergence takes several pulses 
whatever the time interval in between. ill particular, if a pulse train suddenly 
stops, the output current might remain high until leakage discharges Cb to a 
significant degree. ill this design, this situation has been improved somewhat 
by actively discharging Cb by means of an additional transistor (not shown 
in Figure 5.13) if no pulse occurs during quite a long time. 

5. Incremental oculo-motor control chip 
123 
5.3.5 Current/frequency converter 
The outputs of the non-linear mapping network (§5.3.3) are represented 
by currents, whereas the external outputs of the chip need to be pulse 
streams. The conversion is made by the linear current-to-frequency (I/F) 
converter circuit shown in Figure 5.14. 
N4 
Figure 5.14. Schematic of the current-to-frequency converter circuit. 
The association of PI, N1 and N3 is an inverter with a threshold 
depending on the logic state at the gate of N3. If this state is low, N3 is 
blocked and the threshold is determined by the saturation current of Nl, set 
to a few nanoamperes by bias. If the state is high, then the threshold is 
determined by the much larger saturation current of N3. The output of this 
"variable threshold" inverter is inverted again by P21N2, and the output is 
the control signal for N3. This is a positive feedback, leading to a hysteresis 
in the transfer relation. A current-controlled oscillator is built around this 
Schmitt-trigger by means of a capacitor C, which integrates input current lin, 
and a transistor N4 which discharges C whenever the output of the Schmitt-
trigger goes high. Dimensions of N4 are chosen for a pulse duration of about 
50ns. The same I/F converter is used also in the digital/place-coding 
converter incorporated on chip. 
5.3.6 Digital/place-coding converter 
The digital/place-coding converter circuit generates an activation pattern, 
conforming to the membership functions shown in Figure 5.6, as a function 
of a digital input code. The pattern is encoded as pulse streams multiplexed 

124 
Place coding in analog VLSI 
on a bus, following the conventions of the address-event communication 
scheme described in [37]. Depending on the state of a configuration bit, the 
output bus is either sent off-chip, or applied directly to the input maps of the 
networks of links on the same chip. The converter circuit uses the fact that 
the triangular membership functions shown in Figure 5.6 sum to one 
whatever the represented value, and that no more than two nodes are active 
simultaneously. Considering only the interval between two successive 
preferred values, the functions to be implemented are actually a linear rising 
curve going from zero to one, and its complement to one. Such a 
characteristic can be implemented with a conventional current-mode D/A 
converter, which naturally has complementary outputs. To create several 
membership functions, the lower bits of the digital code can be applied to a 
single D/A converter, whereas the higher bits can be decoded digitally to 
deliver the two analog signals to the correct pair of outputs (Figure 5.15). 
DIA 
iI10 
/ 
"'"'-
1JL lJlll 
Figure 5.15. Block schematic of the digital/place-coding converter. This circuit generates 
eight triangular membership functions from a 6-bit digital code. 
For a pulse frequency representation of activation grades, both outputs of 
the DI A converter can be applied to IIF converters. Sending these pulse 
streams to the correct outputs can be done by a fully digital decoder. Each 
output of the decoder controls a set of switches which pull some lines of a 
communication bus high when they are on. Different outputs pull different 
lines high depending on the address associated to the related node of the 
map. 

5. Incremental oculo-motor control chip 
125 
5.4 Measurement results 
5.4.1 Static transfer function 
The static transfer function of the chip has been measured by applying a 
constant activation pattern to map e (usually the representation of e == 0°), 
and sweeping the pattern on maps (j>! and <pz over the full range of 
combinations in discrete steps (32 steps per turn). For every combination, 
the frequencies of all output pulse streams have been measured. An 
exhaustive 3D scan would not have been useful, because the non-linear 
mapping function has only two dimensions as can be seen in Equ. (5.12). 
For other e values, the transfer function is simply shifted along a diagonal 
line as a consequence of the angular difference computation. The measured 
transfer function is shown in Figure 5.16. 
Figure 5.16. Measured and calculated increments (<><Pl> <><P2) as a function of <PI and <pz for 
e = 0°. Both angles are swept over 360° in 32 steps each. The increments are shown as little 
segments starting at the related point (<pI> <pz). 

126 
Place coding in analog VLSJ 
Table 5.1. Error distribution statistics 
average error 
0.34° 
standard deviation 
2.6° 
maximum error 
To represent this function of two variables, little segments starting at 
every acquisition point (</>1. </>2) show the direction of vector (0</>1. 0</>2) at 
this location. On this same plot, the calculated transfer function has been 
superimposed with the same representation. Agreement is good to the extent 
that in may parts of this figure, the measured and calculated increment 
vectors cannot be distinguished. As a quantitative measure of error, the 
angular difference between the measured and calculated increment vectors 
has been computed for every data point. Statistical parameters of the error 
distribution are given in Table 5.1. 
292.5 
b' 
~ 270 
9-
247.5 
225 
45 
Figure 5.17. Measured and calculated increments (15<p\o 15<Jl2) as a function of <PI and <Jl2 for 
6 = 0°. Both angles are swept over 90° in 32 steps each. The increments are shown as little 
segments starting at the related point (<p\o <P2)' 

5. Incremental oculo-motor control chip 
127 
The same measurement procedure has been repeated with finer steps for 
CPI and CP2 but over a smaller range (32 steps over 90°). The measured and 
calculated results are shown in Figure 5.17. The error distribution in this 
case is summarized in Table 5.2. 
Table 5.2. Error distribution statistics 
average error 
0.680 
standard deviation 
3.20 
maximum error 
13.10 
Results are slightly better in the first case, because 25% of the 
measurement points happen to match activation patterns with only one 
active node. Accuracy does not rely on interpolation at these points, 
therefore the error distribution is slightly biased in a favorable way. In the 
second measurement, a vast majority of data points rely on the inherent 
interpolation mechanism of place coding, and are therefore subject to 
slightly higher errors. 
5.4.2 Frequency/current converter 
The gate of a MOS transistor with grounded source has been connected 
to the output of an F/I converter (§5.3.4) to enable an independent 
characterization of this circuit. The drain current of this transistor, available 
on an external pad, has been measured as a function of frequency. The W IL 
ratio of this device exceeds the WIL ratio of transistor Nl (see Figure 5.13) 
of the FIl converter by a factor of about 280, in order to avoid trouble when 
driving this small current off-chip. The transfer function of the circuit, 
measured over the frequency range of interest with a pulse duration of l~s 
and a reference voltage Vref = 5V, is shown in Figure 5.18. 
The lower limit of the frequency range is about 3Hz. At this frequency, 
the drain current of Nl is in the picoampere range, and presumably leakage 
currents get dominant and pull the gate down to ground. The observed 
residual current below this frequency might arise from any leakage source 
between the drain of the "sense transistor" and the measurement instrument 
(most likely junction leakage in electrostatic discharge protection structures 
of the pad). This lower frequency limit leaves a perfectly reasonable 
dynamic range for a full scale of 1KHz. 
For the considered application, higher frequencies than shown in Figure 
5.18 are not needed, but it may be interesting to note that this circuit still 
works fine up to lOMHz, which is the highest frequency which the available 
instrument could generate (pulse width was reduced to 50ns for this 
experiment). 

128 
luA 
••••••• ', ••••• : :: ••••••• :. ,0, ,', 
IOnA 
lOOpA 
IpA 
1Hz 
o 
• 
• 
•• 
. ',' '0'::: ::."" 
10Hz 
100Hz 
f 
Place coding in analog VLSI 
'0':: :::.' ... ',' 
1KHz 
10KHz 
Figure 5.18. Measured transfer function of the FII converter, with a pulse width of IllS and a 
reference voltage V ref = 5V. 
5.4.3 Current/frequency converter 
One of the IIF converters (§5.3.5) from the digital/place-coding converter 
(§5.3.6) has been measured independently. For this purpose, a suitable 
digital input code has been applied in order to activate only one oscillator, 
and the reference current of the DI A converter has been swept over a large 
range. The measured pulse duration is about 60ns. The measured transfer 
function is shown in Figure 5.19. 
This circuit works down to a fairly low input current (nearly 1 pA), which 
is impressive considering that the externally generated reference current is 
reduced by a factor of 50 inside the chip before it reaches the IIF converter. 
This suggest either that the CMOS process used to fabricate the chip has 
very low leakage, or that by some luck, leakage contributions of opposite 
signs compensate for each other. Reproducibility .of the above transfer 
function has been checked for five chips, all of which showed the same 
dynamic range. Of course, this evidence is not strong enough to base 
commercial products on the assumption that such low leakage will routinely 
be available. The prototype chips delivered by the foundry may come from 
an excellent wafer. 

5. Incremental oculo-motor control chip 
129 
100KHzr---~----~----~----'-----~----~--------~ 
10KHz .......................................................... . 
1KHz ............. . 
.... 
100Hz ....... . 
10Hz 
. 
. 
........ '" ............. ',' ............ . 
1Hz 
lOOmHz~~--~----~----~-----L----~----~----~~--~ 
IpA 
loopA 
lOnA 
Iref 
luA 
Figure 5.19. Measured transfer function of the I/F converter. 
l00uA 
450r-----~-------.------~------_r------_r------~ 
400 
350 
300 
N'250 
E£ 
.... 200 
150 
100 
50 
64 
128 
192 
input code 
256 
320 
384 
Figure 5.20. Measured membership functions characterizing the digital/place-coding 
converter. Only a few of the 16 membership functions are shown. The peak frequency is 
tunable by means of an external bias current. 

130 
Place coding in analog VLSI 
5.4.4 DigitaJlplace-coding converter 
Operation of the digital/place-coding converter (§5.3.6) has been 
checked by measuring the frequency of occurrence of each address on the 
bus for a constant digital input code. By incrementing the code in small 
steps and repeating this operation, the complete membership functions have 
been measured. The result (shown in Figure 5.20) matches expectations. 
5.4.5 Power consumption 
With a supply voltage of 5V and in nominal bias conditions, the power 
consumption of the chip has been measured both in idle state (no 
stimulations applied to map 8) and in operation (stimulation of map 8 at a 
total frequency of 1KHz). Results are shown in Table 5.3. 
Table 5.3. Measured power consumption 
quantity 
idle 
in operation 
supply current Idd 
5.IJ..LA 
5.8J..LA 
power dissipation Pdd @ 5V 
25.5/:lW 
29/:lW 
The difference in consumption between the idle and active state is 
mainly due to the fact that networks of links do not consume any current in 
absence of stimulations. There is also a dynamic power component due to 
the five output JJF converters, but it is probably negligible. Some static 
current is consumed in an on-chip current reference and other bias circuit 
elements. The largest part of static power (an estimated 95%) is dissipated 
in pull-up transistors in the decoder of the digital/place-coding converter. To 
save area, half-gates with pull-ups have been used in this circuit. 
Retrospectively, this design choice appears regrettable, since this high 
contribution to power consumption conceals the true potential of networks 
of links in terms of low power operation. However, a low power 
consumption is not necessary for the target application. 
5.5 Discussion 
The integrated circuit presented in this chapter demonstrates a useful 
application of networks of links. It is fully functional, and it implements the 
target non-linear function with a very satisfactory accuracy. It also 
demonstrates how such networks can be turned into area-efficient MOS 
transistor arrays by taking the pseudo-conductance point of view. The 
described type of array is applicable whatever the network of links, provided 
that array dimensions are adapted to the dimensions of the input maps, and 

5. Incremental oculo-motor control chip 
131 
that routing between array cells and output nodes is made to match the 
required network topology. 
An essential difference between this circuit and the fuzzy controller chip 
described in Chapter 4 is that it is made of several cascaded networks, and 
thereby demonstrates that the output pattern emerging from a network of 
links can directly be applied to the input of a subsequent network without 
additional conversion. Membership function circuits, center of gravity 
computation circuits or other types of interfaces are required only if a 
change in the representation convention is made. 
In both this chip and the circuit described in Chapter 4, there is still room 
for optimization. In the networks of links, transistors have been dimensioned 
very conservatively (10 to 30 times the minimum width, 3 to 4 times the 
minimum length) to ensure that they behave like linear controlled pseudo-
conductances. However, in the place coding context, it is likely that the 
overall behavior of these chips would not change much with small (possibly 
minimum size) devices. The detailed behavior of each fuzzy AND gate 
would change because of various second-order effects in the transistors, and 
thereby the gates might not be completely symmetric anymore with respect 
to their inputs, but this distortion might be acceptable. If these assertions 
tum out to be true, then an aggressive optimization may lead to a 
considerable reduction of circuit area. 
Similarly, there seems to be room for optimization from the power 
consumption point of view. First, in both chips, the networks of links 
actually operate in "deep submicrowatt" power dissipation conditions, but 
this performance is concealed by more power-hungry on-chip peripherals. It 
should be relatively easy to reduce this overhead substantially (except 
maybe for I/O parts). In addition, even in the networks of links, current 
intensity has been chosen conservatively from a few tens to several 
hundreds of nanoamperes, which is still way above the real limits set by 
junction leakage, speed or noise (§3.4.8b). 

Chapter 6 
Saccadic oculo-motor control chip 
6.1 Preliminary 
The present chapter describes an integrated circuit intended to control 
the same light deflection system (oculo-motor system) as described in 
Sect. 5.2, but in a different operating mode. Instead of shifting the direction 
of gaze incrementally under permanent visual control as in Chap. 5, this chip 
computes directly the final prism orientations matching a specified direction 
of gaze picked somewhere within the accessible field, and generates a 
saccade (quick shift of the prism orientations) making this point the center 
of the retina image. The target point is specified in a fixed coordinate system 
tied to the rigid mechanical structure which the oculo-motor system is 
mounted onto. This coordinate system will be called head-centered by 
analogy with animal anatomy. This chip and the incremental control chip 
(Chap. 5) differ in accuracy and speed, and are intended for different 
purposes. The saccade control chip implements an inverse model of the 
oculo-motor system, and computes the required prism orientations open-
loop. Thereby, the final prism orientations are known even before motion is 
initiated, therefore the mechanical parts can move at top speed. However, 
accuracy limitations of the model affect directly the final deflection angle. 
The chip has been designed to ensure that the target point is visible after a 
saccade, but its maps are not fine-grained to pixel accuracy. It would be 
prohibitively expensive to create a pixel-accurate mapping of the whole field 
accessible by eye movements, since this field is by definition considerably 
larger than the retina visual field. It should be noted that the target point 
does not need to be initially visible for computation of prism orientations. 
The primary purpose of this chip is saccadic exploration of the accessible 
visual field, guided by the degree of interest or saliency of the various areas 
133 
O. Landolt, Place Coding in Analog VLSI
© Springer Science+Business Media Dordrecht 1998

134 
Place coding in analog VLSI 
in this field. In contrast, in the incremental control chip, the target is 
designated in retina coordinates, which makes sense only for visible targets. 
Prism movements occur under permanent visual feedback, which means that 
velocity is limited by the latency of the control loop, which includes the 
retina, some visual processing chips, the incremental control chip itself, and 
the data transmission channels in between. However, control of the direction 
of gaze is accurate to the pixel or beyond, because control actions are based 
on the observed position error on the retina. The purpose of the incremental 
chip is to implement accurate fine-tuning functions, like image stabilization 
or binocular vergence control. 
6.2 Problem statement 
6.2.1 Hard-wired model of the deflection system 
As stated above, the primary purpose of the described chip is to compute 
prism orientations <1'1 and <1'2 as a function of a desired direction of gaze 
specified by its deflection direction a and deflection magnitude ~ (§5.2.2). 
However, as was noted in §5.2.3, there are generally two possible 
combinations of prism orientations (<1'1. <1'2) for every direction of gaze 
(a, ~). The chip must be able to select one of the two solutions, in such a 
way to minimize the distance that the two prisms must travel from their 
current orientations. Depending on the current state of the light deflection 
system, the request of a saccade to a same target (ex,~) can trigger one 
response or the other. In other words, the chip must implement a hysteretic 
relation between a pair of two-dimensional spaces. The selected approach 
consists of computing the new prism orientations as a function of not only 
the direction of gaze, but also the current prism orientations (<1'10, <1'20). 
Besides transforming directions of gaze into prism orientations, the chip 
must also implement the reverse transform, i.e. it must compute the current 
direction of gaze (an, ~o) on the basis of the current prism orientations 
(<1'10, <1'20). This feature is necessary because both chips (incremental and 
saccadic control) are ultimately intended to be used together. While control 
is left to the incremental system, the direction of gaze can shift, and it is 
necessary to keep track of it in head-centered coordinates, otherwise it is 
difficult to relate visible objects in the retina image to locations in space. 
6.2.2 Time-sharing between multiple targets 
A real visual scene has usually not only a single interesting point, but 
several different locations worth looking at. It would be even more adequate 
to consider that every possible direction of gaze can be given a degree of 

6. Saccadic oculo-motor control chip 
135 
interest (or saliency), therefore a visual scene is characterized by a 
continuous "distribution of saliency". Saccadic exploration of the visual 
scene is actually a time-sharing mechanism for the retina and the related 
visual processing resources. For maximum system efficiency, the time 
allocation mechanism should be based on the distribution of saliency instead 
of a systematic scan or random search. 
To implement saliency-based saccadic exploration, the saccade control 
chip must be able to take a saliency distribution as an input, instead of just a 
single direction of gaze. The chip is expected to show the appropriate 
dynamic behavior even when a steady distribution of interest is applied to it. 
It must ensure that every point with at least some degree of interest is 
observed from time to time, and that the frequency of visits to each point is 
properly related to its saliency. 
6.3 Operating principles 
6.3.1 Bi-directional maps 
The chip contains mainly three maps and a network of links relating 
them (Figure 6.1). The largest map represents directions of gaze (hence the 
name visual map). It is a vector map made of about 900 nodes, the preferred 
values of which are picked on a hexagonal grid in the (a, 0) polar plane (see 
§5.2.2 and §5.2.3). It would not have been possible to use two independent 
scalar maps for a and 0, because the input is not just a single direction of 
gaze, but a saliency distribution possibly extending over the whole visual 
field. Since the locus of directions of gaze accessible to the light deflection 
system is a disk in the (a, 0) polar plane, the boundary of the visual map has 
a circular shape as Figure 6.1 suggests. The other two maps, called motor 
maps, represent prism orientation angles <PI and <P2 respectively. Both are 
made of 64 nodes, the preferred angles of which are evenly distributed 
over 360°. 
The peculiar thing about this chip is that all three maps are bi-
directional, i.e. they all serve both for input and output. The reason for 
choosing a bi-directional network architecture is that the chip must 
implement both a forward and a reverse model of the light deflection system 
(§6.2.1). An alternative way of thinking of this architecture is that all three 
maps are duplicate, where one instance is an input map and the other 
instance an output map (Figure 6.2). Both instances of a map have the same 
dimension and preferred values. The chip can therefore be considered to 
have three input maps and three output maps, and operate in the 
conventional unidirectional fashion. 

136 
Place coding in analog VLSI 
visual map 
DODD 
0000000 
0000000000 
00000000000 
0000000000 
00000000000 
0000000000 
00000000000 
0000000000 
0000000 
DODD 
network of links 
motor map 1 
motor map 2 
Figure 6.1. Maps involved in the saccade control chip . 
motor map 1 
(input) 
U' 
..... ;:: 
;:: 
~ 
U' 
visual map 
0 
(input) DO DL..T 
..... 
...... 
motor map 2 
(input) 
..... 
~ 
::!" 
;:: 
~ 
.. 
.. 
.. 
network 
of links 
.... ::: 
.;:; 
.;:; .-
motor map 1 
(output) 
...... o 
visual map 
DO (output) 
~O 
. ..... 
...... 
.......,...., 
. ...... 
...... 
..... 
.;:; .-
motor map 2 
(output) 
Figure 6.2. Conceptual split of three bi-directional maps into six unidirectional maps. 
The input part of the visual map receives a saliency distribution, which is 
an indirect way to specify requested directions of gaze. The output part of 
this map represents the actual direction of gaze. Symmetrically, the input 
part of both motor maps carries an activation pattern representing the 

6. Saccadic oculo-motor control chip 
137 
current prism orientations. Nodes in these maps are characterized by a very 
wide membership function, peaking at the preferred prism orientation, 
reaching zero only at the exactly opposite orientation, and smoothly varying 
in between (Figure 6.3), Thereby, the activation grade of each node in these 
maps can be considered as a conventional analog representation of the 
complement to one of the absolute difference between the preferred and 
actual prism orientations. 
o~------~--------------~~~--------+-· 
o 
<Po 
Figure 6.3. Membership function characterizing a node of the motor input map having a 
preferred prism orientation of <Po. 
The output part of the motor maps represents the requested prism 
orientations. Their output patterns remain constant while the oculo-motor 
system stares at some location, and change abruptly to some new value 
whenever a saccade is generated. For the system to work, two independent 
servo loops (not incorporated on this chip) must make the two prisms follow 
saccade requests from the chip as quickly as possible. 
6.3.2 Interactive combination of maps 
Before a function of several variables can be computed by a network of 
links, the original scalar input maps must be combined into a single vector 
map, as explained in §2.4.4. A circuit performing this operation has been 
described in §2.4.3a. If contiguous activation spots are applied to all input 
scalar maps, then this circuit produces a contiguous activation spot at the 
proper place on the vector map. This circuit relies on an array of AND gates, 
but there are other options to get a qualitatively similar result. In the present 
paragraph, an alternative circuit is described, which relies on a summing 
operator combined with a threshold. The principle of this circuit is 
illustrated by Figure 6.4. This example involves the same maps as defined in 
Figure 2.7. 

138 
Place coding in analog VLSI 
Vl~-+ __ ------~~--------~--------~ 
v3nr------------~--------__ --------~ 
Figure 6.4. Circuit combining two scalar maps U and V into a single vector map X, based on 
a summation operator and a global threshold. 
Each circuit element in this array sums the activation grades of one node 
of map U and one node of map V. Thereby, if a node of map U is active, all 
cells in the related column get some degree of stimulation. Similarly, with 
an active node in map V, all cells in a row are stimulated at the matching 
degree. The strongest total stimulation is received by cells which get 
activation from both inputs. By setting a global threshold at least as high as 
the strongest activation grade available in any single node of maps U and V, 
all cells which get stimulation from only one input are inhibited. The output 
activation grade of each cell is the fraction of its total stimulation which 
exceeds the global threshold. With this circuit, as with the array of AND 
gates, the output pattern is a localized activation spot on map X representing 
approximately the expected vector. 
In the simplest version of this circuit, the threshold is constant. For cells 
with N positive inputs, the threshold must be at least N-l to ascertain that a 
cell can exceed the threshold only if it is stimulated by all its inputs to some 
degree (which is a distinctive property of AND gates, even in fuzzy logic). 
With a large N, this makes the cell very selective, because to reach the 
threshold, all inputs must be active by a grade of (N-l)/N on average, which 
tends toward 1 with increasing N. An alternative option is to make the 
threshold adaptive on the basis of some criterion ensuring that some 
activation pattern of limited extent can always subsist on the output map. 
One possible adaptation scheme is the "winner-take-all" (WT A) operation, 
which consists of setting the threshold in such a way that exactly one cell in 
the array has an active output, namely the cell with the strongest total 

6. Saccadic oculo-motor control chip 
139 
stimulation. This scheme obviously leads to a quantization of the 
represented vector. 
In the saccadic control chip, maps are combined by the circuit described 
in this paragraph instead of an array of AND gates, for reasons which will 
be clarified later in this chapter. The WT A operator has been selected as an 
adaptive threshold mechanism, because the generation of saccades requires 
taking "hard" decisions. If two locations on the visual map are interesting to 
a similar degree, it is necessary to select only one of the two as a saccade 
target. A compromise, i.e. staring at some location midway between the two 
interesting points, would be the worst solution. 
6.3.3 Bi-directionallinks 
In this chip, a link is a cell with a bi-directional connection to one node 
in each of the three maps (Figure 6.5a). In conformance with the operating 
principle of networks of links, the preferred prism orientations of the two 
motor nodes match the preferred direction of gaze of the visual node to 
which the link is connected, but for a small quantization error. The bi-
directional connections can also be thought of as two independent 
unidirectional connections (Figure 6.5b). 
a) 
motor 
node 1 
visual node 
motor 
node 2 
b) 
visual node 
_t~:~. __ , ____ -----t---
motor 
node 1 
motor 
node 2 
Figure 6.5. Simplified schematic of a cell of the network of links. a) Abstract representation 
with bi-directional connections. b) More detailed schematic. Each bi-directional connection is 
actually made of two unidirectional wires. The body of a link cell is essentially a sum-plus-
threshold element. 
The input stimulation from the visual node is the degree of interest of its 
preferred direction of gaze. The stimulation from each motor node is a 
measure of the proximity between its preferred orientation and the current 
prism orientation (§6.3.1). By adding all three contributions, the degree of 
interest of a visual spot is biased by the travel distance to reach this spot -

140 
Place coding in analog VLSI 
the closer the spot in terms of prism movements, the more interesting it is. 
Since there are two possible solutions for every direction of gaze, two link 
cells get exactly the same degree of stimulation from the visual side. The 
bias due to contributions from the motor side creates a difference in total 
stimulation between these pairs of link cells. The winner-take-all (WTA) 
mechanism selects the link cell with the strongest total stimulation. The 
purpose of this competition is both to select the most interesting location 
from the visual point of view, and to select the best combination of prism 
orientations to reach it. 
The output of the link cell is connected to a node in each of the output 
maps. The input and the output connection of a link cell to a map are both 
directed to the same node in this map. Thereby, the pattern on the visual 
output map represents the currently selected direction of gaze, and the 
patterns on the two motor maps represent the prism orientations which two 
low-level servo loops must enforce in order to let the visual system stare at 
the selected point. On all three output maps, the representation is discrete 
place coding, because the WT A lets only a single node of each map be 
active. 
6.3.4 Virtual links over an event-driven bus 
a) Implementation options 
Originally, the link cell shown in Figure 6.5 was intended to be 
implemented by current-mode circuits. The considered approach was to use 
a single wire for each bi-directional connection, getting inputs as currents, 
and making the output state available as a voltage on these wires. However, 
this solution leads to a fairly complex routing problem due to the large 
number of links. Instead, an alternative approach has been devised, which 
consists of replacing one-to-one wires by a time-division multiplexed global 
bus based on an event-driven transmission scheme [37][42][43]. It is not 
clear whether the routing area savings offered by this solution outbalance 
the transmission management overhead or not, but the appeal of trying out 
something new motivated the selection of this approach anyway. 
b) Virtual links 
A network of virtual links consists of a bus over which address pulses 
transit. The operating principle of a network of virtual links is illustrated by 
Figure 6.6. Activation grades on the input map X are encoded by the 
frequency of pulse streams, symbolically represented above the active 
nodes. Pulses must be very brief, and streams on different nodes must not be 
synchronized. In idle state, all the lines of the bus are low. Every time a 
pulse appears on an input node, the associated encoder applies a specific 

6. Saccadic oculo-motor control chip 
141 
address onto the bus, then releases the bus as soon as the input pulse 
disappears. In the output map Y, a decoder circuit tuned to detect a specific 
address on the bus is associated to each node. Every time an address is 
briefly flashed onto the bus by some input encoder, the output decoder tuned 
to detect this address applies a pulse to its output node. Thereby, the pulse 
stream present on an input node is reproduced on one or several output 
nodes as would a private wire exist between them. 
l.L 
lJlJUl 
l.L 
J.lli 
Figure 6.6. Illustration of the principle of virtual links. 
A potential problem is the possibility of collisions between addresses, if 
pulses occur simultaneously on two different nodes. One way of dealing 
with them is to include an arbitration mechanism in the communication 
scheme [42][43]. Another solution, which has been chosen for the described 
chip, is to select address codes carefully so that collisions can produce only 
unused addresses [37]. With this scheme, colliding pulses are lost, but at 
least no unwanted output node can be activated. Pulse losses only result in 
an attenuation of activation grades. Collision rates can be kept low by a 
careful choice of pulse duration and frequency range for the representation 
of activation grades. 
On large maps with complex interconnections, it might be more 
economical from a circuit area point of view to share a low number of global 
bus lines among all links than to draw a private wire for each link. Another 
reason to use virtual links is that event-driven buses are used anyway for 
interchip communication in some types of computational systems [36]-[40]. 
It is obviously possible to combine the functions of communication and 

142 
Place coding in analog VLSI 
computation by using virtual links, in the case where two maps are located 
on different chips. 
c) Address selection issues 
In a network of virtual links, if all connections are one-to-one, address 
selection is straightforward. Each sender must be given a unique arbitrary 
address, then the addresses of the different receivers must be chosen in such 
a way to create the required virtual links. In this case, the "sender's address" 
and the "receiver's address" are the same thing. In the presence of divergent 
or convergent links, some caution must be exercised. If a pulse emitted by a 
sender must reach more than one receiver (divergence), then the same 
procedure as in the one-to-one case produces a working solution. In this 
case, the bus transmits the "sender's address", and multiple receivers can 
listen to it. With this procedure however, if several senders need to stimulate 
the same output node (convergence), the receiver would have to decode 
several different addresses. It is usually more economical to invert the 
procedure in this case: the receivers should be given unique addresses, then 
the senders should be configured with suitable addresses to create the 
required connection topology. In other words, in the convergent case, the 
bus should transmit the "receiver's address" instead of the sender's. If the 
network contains both convergent and divergent links, then the receivers 
must be made receptive to several addresses, or several distinct buses must 
be used. 
It should be noted that if several senders stimulate the same receiver, the 
average frequency of the resulting spike train is the sum of the incoming 
frequencies (but for some possible collisions). This spike train is generally 
not periodical, even if the original contributions are. It is not simple to 
combine converging spike trains by another operator than a sum. For this 
reason, the sum-plus-threshold approach for combining several maps 
(§6.3.2) is a natural solution to use in the context of virtual links. 
6.3.5 Saccade dynamics 
The time-sharing functionality described in §6.2.2 is obtained by 
inserting an integrator between each node of the visual map and the link 
cells connected to it, as shown in Figure 6.7. In a first phase of the 
description, the existence of spatial diffusion blocks in this circuit will be 
ignored. Stimulations received by the visual node, which represent the 
degree of interest of a particular location in the visual field, are applied to 
the input of the integrator. Its output state is the activation grade transmitted 
to the link cells related to this visual node. By this setup, the activation 
grade increases in time at a rate dependent on the degree of interest of the 

6. Saccadic oculo-motor control chip 
143 
preferred location of the visual node. Thereby, it reflects the product 
between the saliency of this location and the time elapsed since the last time 
this location has been gazed at. Sooner or later, the activation grade will 
reach such a level that one of the links connected to this visual node will 
win the competition, thereby making the oculo-motor system jump to this 
location by a saccade - the higher the saliency, the sooner this location will 
win. When this happens, the output line from the link cell to the visual node 
is activated in order to inform the system of the current direction of gaze. As 
shown in Figure 6.7, the same signal also contributes negatively to the 
integration of visual stimulations, thereby effectively decreasing the 
activation grade of the visual node which is currently winning. Sooner or 
later, the degree of stimulation will have decreased enough that another link 
in the network wins the competition - the less interesting the winning point, 
the sooner the next saccade. 
visual node 
link cell 
Figure 6.7. Temporal integration and spatial diffusion in the visual map. 
The visual map is fine-grained enough that the retina image includes the 
preferred locations of several of its nodes. It is therefore better to use a 
spatial local average of activation grades instead of individual grades in the 
competition for the next saccade, so that the degree of interest of the whole 
prospective retina image, rather than only its central pixel, is taken into 
account. Similarly, the decrease of activation grades should not occur only 
in the winning node of the visual map, but also in those of its neighbors 
whose preferred locations are visible on the retina image. The two spatial 

144 
Place coding in analog VLSl 
diffusion elements shown in Figure 6.7 provide local excitation and 
inhibition within the visual map for this purpose. 
The described principle underlying saccade generation has strong 
similarities with the attentional shift mechanism described in [44]. However, 
the two structures are slightly different in purpose. The circuit presented in 
[44] is intended as an attentional mechanism within a map of visual 
information, but not for moving an eye mechanically. Therefore, this circuit 
implements purely a selection process, but not a mapping between visual 
and motor coordinates. Another difference exists in the way the dynamic 
behavior is obtained. In the present approach, the saliency of a node is 
increased until the node wins. In [44], when a node wins, an inhibition-of-
return signal is set high, then slowly fades away as time goes by. 
6.4 Implementation details 
6.4.1 Prototype chip 
An integrated circuit has been designed, which implements the operating 
principles described in Sect. 6.3. The prototype chip has been fabricated in a 
O.5J.lm CMOS technology. It contains about 160K transistors and 15K 
capacitors. The die is about 9mm by 5mm large, and it is housed in a 84-pin 
LCC package. Implementation details of this chip are given in the remaining 
of this section. 
Figure 6.S. Micrograph of the saccadic oculo-motor control chip. 

6. Saccadic oculo-motor control chip 
145 
6.4.2 Bus organization 
Every link cell is connected to one node in each of the three maps. 
Connections to visual nodes are made by private wires, because link cells 
and visual node circuits are located close together. Connections to motor 
nodes are implemented by bi-directional virtual links (§6.3.4), because the 
two motor maps are physically located outside of the array of link cells. 
Virtual links are also used to communicate visual information from outside 
the chip to the visual map and reverse. 
Each motor node is connected to several link cells, thus the 
interconnection network is divergent from motor nodes to link cells, 
whereas it is convergent in the opposite direction. It is best in this case to 
give motor nodes a unique address, and use this address in both transmission 
directions (§6.3.4c). To send a pulse to all related link cells, a motor node 
emits its own address on the bus. The other way round, a link cell which 
sends a spike to a motor node emits the address of the destination node on 
the bus. A link cell cannot send a pulse simultaneously to both motor maps 
over the same bus, because the addresses of the two destination nodes are 
generally different and would collide. To avoid this problem, an 
independent bus has been used for each map (Figure 6.9), so that whenever 
a link cell emits a spike, it can address all maps simultaneously without 
collision by applying appropriate codes on their respective buses. 
visual bus 
link cell 
motor map 1 
motor map 2 
Figure 6.9. Event-driven buses on the chip. Only one link cell is shown, but all other have the 
same bus connections. They differ only by their addresses. 

146 
Place coding in analog VLSI 
All three buses are bi-directional, i.e. the same bus lines serve for both 
transmission directions. From motor nodes to link cells, addresses are 
transmitted as voltage pulses, while in the other direction, current pulses are 
used to avoid self-stimulation of the link cells. This choice keeps link cells 
as simple as possible. The burden of turning current pulses into voltage 
pulses is borne by a set of bus line termination circuits (§6.4.7) outside of 
the array oflink cells. 
The visual bus is driven out of the chip directly in its bi-directional form, 
for two-way communication with other elements of the oculo-motor system. 
In contrast, the two motor buses are accessed from outside the chip via two 
unidirectional ports each, which are combined internally by means of a bi-
directional bus transceiver (Figure 6.10). This choice is motivated by the 
fact that the sensors detecting the current prism orientations deliver this 
information in a conventional digital form, and must therefore be converted 
to place coding on chip. 
r -
-
-
I 
sensor 
on chip 
oifchip-
Figure 6.10. External interface to the bi-directional motor bus. The bus in dark gray carries 
conventional digital codes, whereas the lighter buses are event driven and transmit place-
coded information. 
6.4.3 Layout topology 
The chip is organized as an array of cells laid out following the topology 
of the visual map. Each cell in this array is made of a visual node (Figure 
6.7) and the two link cells which are connected to it. Thereby, the visual 
map and the network of links are interleaved in the array. Because of this 
visuotopic layout, the event-driven bus which conveys visual information in 
and out of the chip can be implemented as originally proposed in [37]: 
instead of running the visual bus across the whole array, this bus is split into 
two halves and decoded at the periphery of the array into a row and column 

6. Saccadic oculo-motor control chip 
147 
selection signal (Figure 6.11). Array cells combine the row and the column 
selection signals in order to determine whether a pulse is addressed to them. 
Symmetrically, to send data outside, a visual node applies a pulse to both a 
row and a column emission line. At the terminations of these lines, this 
pulse is turned into a row and a column address on the visual bus. 
column address encoders/decoders 
.. -----~ ...... -... -~---
, 
r-~+_--+_--~---r---r~-, 
Figure 6.11. Chip topology. Each array cell is made of a visual node and two links. 
6.4.4 Array cell 
A block schematic of a single cell of the array outlined in Figure 6.11 is 
shown in Figure 6.12. It is made of two identical link cells and a visual node 
circuit (of which only the integrator is shown for clarity). In each link cell, 
logic gates decode the addresses present on the two motor buses (top of the 
schematic). Their outputs are high whenever the expected address is present 
on the bus. An OR gate combines the output signals of both decoders. 
Thereby, the pulse streams sent to this link cell via either motor bus are 
summed in frequency. A frequency-to-current (F/I) converter turns this pulse 
stream into a continuous analog signal. An input pulse from the visual bus is 
detected by combining the row and column selection lines by an AND gate. 
The resulting spike train is integrated into an analog signal representing the 
activation grade of the visual node. The sum of this signal and the current 
delivered by the FII converter is the total stimulation received by the link 
cell. This stimulation is applied to the input of a winner-take-all (WTA) 
element. This block interacts with the WT A elements of all other links in the 
array. The output of the WTA element with the highest input stimulation 
takes a logical high state. In the link cell, this signal enables an oscillator 
which generates brief pulses at a constant rate. Every time a spike is 
generated, a current pulse is applied onto some lines in both motor buses, 
thereby forming the addresses of the motor nodes related to the winning link 
cell. In addition, the row and the column output lines toward the visual bus 
are pulled high at the same time, thereby signaling the winning direction of 

148 
Place coding in analog VLSI 
gaze. Last, the output of the oscillator also contributes to discharge the 
integrator in order to decrease the degree of interest of the winning location 
(§6.3.5). 
link cell 
visual 
column 
link cell 
visual =:t:1+f::t==+:t+~=+:t==~==::;::=:t:1+f::t==+:t+~= 
row 
1 _______ _ 
Figure 6.12. Block schematic of an array cell. The motor buses on the top and the bottom of 
this schematic are actually the same. They have been split for convenience. 
6.4.5 Saliency integrator 
A schematic of the integrator circuit used in the visual nodes is shown in 
Figure 6.13. The inputs of this circuit are two digital-level pulse trains. In 
idle state, transistors PI and N2 are on and the other two are off, whereby 
voltage Vb is equal to a reference voltage V ref while V c is at the ground 
potential. If a pulse is applied to input "pos", then PI is turned off and Nl 

6. Saccadic oculo-motor control chip 
149 
on, whereby charge sharing occurs between Ca and Cb• When the voltage 
settles, the following amount of charge has been added to Ca: 
(6.1) 
In this equation, Va denotes the initial potential of the output node, and 
Ca' is the equivalent capacitance to ground of the output node, which 
includes Ca as well as the contributions of the neighbor cells, via the 
horizontal capacitive connections shown on the right of the schematic. In an 
ideal integrator, the amount of charge dropped onto the output node should 
be independent from the potential of this node, so that the output keeps 
increasing indefinitely at a steady rate in response to a sustained stimulation 
of the positive input. Instead, with this circuit, Va converges exponentially 
toward an asymptotic value of V ref. However, if the normal operating range 
of Va is well below V ref, then the circuit behaves essentially like an 
integrator. Besides, the power supply restricts the voltage range of a "true" 
integrator anyway, therefore the existence of a saturation level is not a 
limitation. 
pos -----1 __ ------, 
Figure 6.13. Schematic of the integrator block. The six capacitors on the right are connected 
to node Va of the six nearest neighbors in the hexagonal visual map. 
The negative input works in a similar way as the positive one, except that 
the reference voltage is ground in this case. The amount of charge removed 
from the output node at every pulse can be written 

150 
Place coding in analog VLSI 
Ca'Cc 
AQ =-
·V =-C ·V 
a 
C'C 
a 
c 
a 
a + c 
(6.2) 
In response to a sustained stimulation of the negative input, the output 
voltage Va converges exponentially toward ground voltage. Instead of 
complementary transistors like for the positive input, two n-channel devices 
with an inverter have been used as switches in this case, because the 
reference voltage is ground. A p-channel transistor would remain blocked in 
this situation. 
It is more common to use an active op-amp based circuit than the 
described passive circuit to build an integrator. The reason for this choice is 
that due to the brevity of input pulses, an op-amp would have to deliver a 
large peak current to complete charge sharing within the duration of a pulse. 
It would therefore need to be biased at a large current, resulting in a large 
power consumption, especially considering that there are 900 instances of 
this integrator on chip. Similar considerations have previously led to choose 
a passive solution for the implementation of a frequency-to-current 
converter (§5.3.4). 
Capacitive connections to neighbor cells, shown on the right of the 
schematic, create a diffusion network, whereby activation grades are 
spatially low-pass filtered (§6.3.5). The spatial diffusion block which 
precedes the negative integrator input in Figure 6.7 will not be described in 
detail. It is made of a non-linear diffusion network [45] spreading out pulses 
isotropically over a finite spatial extent. The same solution has been used 
before for the implementation of orientation-tuned spatial filters [40]. 
6.4.6 Winner-take-all 
The winner-take-all (WTA) operation is performed in voltage mode in 
order to avoid the influence of device parameter gradients over the surface 
of the chip. The implementation of the voltage-mode WT A cell (Figure 
6.14) has been inspired by its popular current-mode counterpart [46]. Input 
voltage Va is the activation grade delivered by the integrator circuit (Figure 
6.13). The amplifier constructed around the differential pair PIIP2 compares 
Va with the voltage V wta of a global node common to all other WT A cells. If 
Va is larger than V wla, then the gate voltage of N3 increases, thereby 
contributing to increase V wla. Otherwise, the gate voltage of N3 drops down 
to ground, whereby N3 blocks and stops influencing the competition. A 
network of WTA cells settles in a state where only the cell with the highest 
Va can keep N3 active. A current of intensity Iwta, delivered by a global pull-
down current source connected to V wla (not shown), flows entirely across 

6. Saccadic oculo-motor control chip 
151 
transistor N3 of the winning cell. The drain current of N3 therefore signals 
whether a specific cell has won the competition or not. The result is 
converted into a digital voltage signal "win" by means of a simple current 
comparison. This final output is capacitively coupled to the input node Vain 
order to create a hysteresis. By this mean, this node gets an extra boost when 
the "win" signal rises, which ensures that it remains a winner for some 
minimum amount of time. This prevents the saccade target from flipping at 
an excessive frequency in situations where several nodes have very similar 
degrees of interest [47]. 
bias --(fi--------CI 
2 
: 
P3 
P4 
win 
PI 
Figure 6.14. Schematic of the voltage-mode WTA cell. 
An additional current-mode input lmot is used to create a controlled offset 
in the amplifier. This current is drawn by the frequency-to-current converter 
of the link cell (Figure 6.12), and is therefore proportional to the stimulation 
frequency coming from the motor nodes. The amplifier behaves as would an 
offset be added to the input voltage Va, which results in a bias of the 
competition favoring directions of gaze which can be reached by smaller 
prism movements. 
6.4.7 Bi-directional bus transceiver 
Link cells decode incoming addresses on the motor buses by 
conventional logic gates, therefore the sender must apply codes at supply 
voltage levels onto the bus for transmission. To send information back, link 
cells apply an address onto the bus by shorting some lines to the positive 
power rail by means of an encoder made of p-channel transistors (Figure 
6.15). Bus line terminations keep these lines essentially at ground potential 
in the absence of incoming voltage pulses, therefore a negative pulse on the 

152 
Place coding in analog VLSI 
gates of these transistors results in a strong current pulse on the bus lines 
they are connected to. The bi-directional bus transceivers which terminate 
the lines are responsible for the detection of such current pulses and their 
conversion into logic signals at conventional voltage levels. 
J~ J~ 
'1L 
'1L 
bus 
J~ ~[ 
'1L 
o 
1 
o 
o 
o 
1 
Figure 6.15. Encoder circuit of a link cell. The drains are connected to the bus lines whose 
logic state is I in the address code. 
The principle of the receiver part of a transceiver is illustrated by Figure 
6.16. Bus lines are shorted to ground by a small resistance R. In the presence 
of a current pulse, the potential of the bus line increases slightly, and this 
event is detected by a voltage comparator. The resistance value is chosen in 
such a way that the time constant of the bus line, determined otherwise by 
the parasitic capacitance C which cannot be acted upon, remains acceptable 
(i.e. in the nanosecond range). In the saccade control chip, the estimated 
parasitic capacitance is 20pF, which leads to a resistance of 200n for a time 
constant of 40s. The resistance in tum determines the current intensity 
during a pulse, in order to obtain a detectable voltage increase. This voltage 
must however remain lower than the threshold voltage of an n-channel MOS 
transistor, so that the logic gates taking input on the bus remain completely 
off. The nominal current intensity is 1rnA, which yields a voltage swing of 
200m V and a threshold voltage of 100m V. The transistors of the encoder 
circuit (Figure 6.15) are dimensioned to deliver this current when their gate 
is pulled down to ground level. 
This passive approach based on a grounded resistor for the detection of 
current pulses has been preferred over an actively maintained virtual ground, 
because the latter approach would need very fast amplifiers to follow 
current pulses lasting only a few tens of nanoseconds. This would not only 

6. Saccadic oculo-motor control chip 
153 
lead to a challenging design, but also inevitably to a high power 
consumption. 
I .... 
in--------.J '_---, 
~ .... "'" 
I 
out---C 
1----..... --.. ,-- bus line 
o : , 
c ::::: 
, , : ' . 
. ' 
Figure 6.16. Principle of the current pulse receiver. 
This receiver circuit must be combined with a transmitter part (a simple 
digital driver in fact) in such a way that the two parts do not interfere in any 
damaging way. In particular, resistor R should not load the transmitter while 
it attempts to pull the bus line high. A schematic of the selected solution is 
shown in Figure 6.17. In this circuit, the transmitter is a simple inverting 
buffer. In idle state, the n-channel device pulls the bus line to ground, but its 
channel still has some resistance. This device is dimensioned in such a way 
that its channel resistance in this state matches the required value R for the 
receiver circuit. While the transmitter emits a pulse, this device is turned off 
as in every CMOS inverter, and thereby R does not interfere with the 
transmitter. The receiver part operates as explained above. However, 
whenever a pulse is applied to the bus line by the transmitter, the output of 
the comparator goes high as would a current pulse be received, and thereby 
erroneously reflects the external input pulse back to the external output. 
This problem cannot be solved in a purely combinatory way, because the 
bus line remains high some short time after the input pulse of the transmitter 
disappears. Instead, a simple state machine must be used to discriminate 
comparator output spikes due to incoming current pulses from spikes due to 
the transmitter itself. The schematic of this sequential logic circuit is given 
in Figure 6.18. If a pulse is applied to the input in of the transmitter and the 
state machine, then a flag is set, which inhibits the output of this circuit. 
Shortly after this, the bus line necessarily goes high, and the comparator 
output comp becomes active (i.e. low). The flag remains set, even if the 
input pulse disappears, as long as the bus line does not go low again. In 
contrast, if comp becomes active without first being preceded by a pulse on 
in , then the output of this circuit reflects the comparator output (but for an 
inversion). 

154 
out 
in 
state 
machine 
comp 
Place coding in analog VLSI 
I . 
I 
I 
bus line 
C ::::: 
I 
I 
I • 
• p 
Figure 6.17. Simplified schematic of the bus transceiver circuit. 
out 
Figure 6.18. Schematic of the sequential circuit which discriminates pulses sent by link cells 
from pulses sent by the transmitter. 
The bi-directional bus transceiver described in the present paragraph is 
the central element in the implementation of bi-directional virtual links. It is 
used for both motor buses on the saccade control chip. The visual bus relies 
on the same principle, but since the other end of the transmission channel is 
external to the described integrated circuit, only half the elements have been 
incorporated on chip. 

6. Saccadic oculo-motor control chip 
155 
6.4.8 Digital/place-coding converter 
The current prism orientations, delivered in a conventional digital form 
by external sensors, are converted into a place-coded activation pattern on 
chip (Figure 6.10). This circuit is implemented in much the same way as the 
digital/place-coding converter incorporated on the incremental control chip 
(§5.3.6). However, for the motor map, membership functions must be very 
broad, ideally like the one shown in Figure 6.3. The principle of the selected 
circuit is illustrated by Figure 6.19. 
digital input 
place-coded output pattern (address-event bus) 
Figure 6.19. Block schematic of the digital/place-coding converter. 
The sensor delivers a 10-bit digital representation of the current prism 
orientation. Since the motor map has 64 nodes, the six most significant bits 
are applied to a decoder, whereas the remaining four bits are applied to a 
digital/analog (O/A) converter. This block splits a constant reference current 
lref into two fractions in conformance with the digital input code. The 
decoder switches these two currents onto a pair of consecutive outputs 
depending on the digital input code. Globally, the set of currents available at 
the 64 outputs of the decoder is a tight activation pattern representing the 
prism orientation. These currents are applied to a resistive ladder network 
which diffuses the pattern. This ladder is implemented by a network of MOS 
transistors by applying the concept of pseudo-conductance [30][31]. The 
resulting loose current pattern is applied to a set of current-to-frequency 

156 
Place coding in analog VLS] 
(I/F) converters, each of which generate a stream of brief pulses at a 
frequency proportional to the activation grade. These pulses are encoded 
onto a bus in conformance with the principle of a non-arbitrated event-
driven communication scheme. The events on this bus are reflected onto the 
bi-directional motor bus via the bus transceiver. 
Using a resistive network to spread out the tight activation pattern results 
in a membership function as shown in Figure 6.20. Device geometry has 
been dimensioned in such a way that the residual activation grade at the 
lowest point is about 10% of full scale. This membership function is only an 
approximation of the ideal curve depicted in Figure 6.3, but it has its most 
important features. The shape of this curve makes the discrimination of 
angles very remote from the current prism orientation difficult. However, it 
should be reminded that the activation pattern on the motor input map is 
used only to favor combinations of prism orientations requiring the smallest 
displacement for the observation of a given target point. The worst possible 
consequence of a low discrimination capability at large angular differences 
is that a non-optimal combination of prism orientations may be selected now 
and then. This may result in a slightly longer settling time than optimal for 
some long saccades, but will definitely not disrupt system functionality. 
1 
o~------~----------------~----------~~ 
o 
<Po 
Figure 6.20. Membership function characterizing a node of the motor input map with a 
preferred prism orientation of !po. The exponential decay is characteristic of resistive diffusion 
networks. 
6.5 Measurement results 
6.5.1 Test environment 
The saccadic oculo-motor control chip has been characterized in a test 
environment emulating the outputs of a saliency detector and two prism 
orientation sensors. A digital pattern generator has been used to periodically 
flash the address of every node to be stimulated onto the visual input bus, 
with a frequency matching the degree of interest of the related spot. The 

6. Saccadic oculo-motor control chip 
157 
signals emulating prism orientation sensors were controlled by a personal 
computer via conventional digital ports, since digital/place-coding 
converters are available on chip for these inputs (§6.4.2). The response of 
the chip has been measured by means of a logic analyzer recording the flow 
of events delivered by one or several of its event-driven output buses 
(§6.4.2). After acquisition, the data streams were transferred to a computer 
for analysis. The memory depth of the logic analyzer restricted the duration 
of recording to typically 160 saccades when measuring the visual output 
bus. Whenever it was necessary to acquire more data for computing 
statistically significant results, several recordings have been run, resulting in 
an overall recording fragmented in time with gaps of several seconds. A 
limitation of the test set-up is that the signals which emulate prism 
orientation sensors were not updated in real time when a saccade was 
generated by the chip, as they would have been if a real mechanical system 
would have driven the prisms to the specified target orientations in response 
to a saccade request. This fact has some implications on the dynamic 
behavior displayed by the saccadic control chip. 
6.5.2 Power consumption 
The chip operates on a 5V supply voltage. In the absence of visual input 
stimulations, the measured current consumption is 1.26mA, which 
corresponds to 6.3mW. It should be noted that even without visual 
stimulations, the chip is not idle, because the two internal motor buses 
conveying current prism orientations remain permanently active. Power 
consumption has been found to depend only moderately on visual 
stimulation conditions. 
6.5.3 DigitaUplace-coding converter 
The digitaUplace-coding converters (§6.4.8) have been measured by 
applying a constant word on both digital inputs representing current prism 
orientations, and by recording the address streams on both motor output 
buses simultaneously until at least 50'000 valid addresses were observed on 
each bus. The frequency of occurrence of each address has been computed 
and plotted against the sending node number in the corresponding motor 
map (Figure 6.21). Overall, the result matches expectations, as can be seen 
by comparison with Figure 6.20. However, some variations due to device 
mismatch are discernible. 
By repeating this measurement with different input values, the activation 
patterns shifts on the map without significantly changing shape. The scale of 

158 
Place coding in analog VLSI 
the pattern, i.e. the peak frequency of the activation grades, can be 
controlled by an external bias current. 
2500r---:----:---.---.----~==~==~~~ 
2000 
~ i 1500 
§ 
'.g 1000 
> 
.~ 
500 .. 
. ........... 'F' 
-: 
/ 
/ 
-
prism 1: 1350 
-
- prism 2: 2450 
...... 
~. \ ...... : ... . 
I: \ 
1 
\ 
.. I. 
..\ .... : .. 
/ 
\ 
\ : 
\: 
.\ .. 
:\ 
. "' 
OL---~----~----L---~----~----L---~--~ 
o 
8 
16 
24 
32 
40 
48 
56 
64 
cell number 
Figure 6.21. Measured activation patterns on the two motor buses. The legend shows the 
current prism orientation applied to the chip for this measurement. 
6.5.4 Stimulation of two visual nodes at equal rates 
Two nodes of the visual map located symmetrically with respect to the 
center have been stimulated at a frequency of 1KHz each. Prism orientation 
inputs representing CPl = 1800 and CP2 = 00 respectively have been applied, 
which corresponds to a direction of gaze straight along the optical axis of 
the lens, i.e. null deflection. With this choice, the two nodes which are 
stimulated from the visual side get an equal amount of stimulation from the 
motor maps, because for reaching either point, prism rotations of equal 
magnitude are required from the initial direction of gaze. The event stream 
on the visual output bus has been recorded and processed to detect changes 
in the direction of gaze. In these conditions, periodic saccades between the 
two stimulated points have been observed. Saccades to unstimulated 
locations never occurred. Recording was carried on over a total acquisition 
time of 3 minutes (gaps for data transfer to the computer not induded). In 
every block of continuous data, the number of saccades toward each visual 
node has been counted, and the fixation time on each node until the next 
saccade has been determined. The first and last saccade of every data block 

6. Saccadic oculo-motor control chip 
159 
have been discarded, since they might have been truncated by the onset or 
termination of acquisition. The results of this measurement are shown in 
Table 6.1. The first two columns of this table indicate the location of the 
stimulated points on the visual map (which has a total of 35 rows and 31 
columns). 
Table 6.1. Saccade parameters measured while stimulating two visual nodes 
row 
column 
number of hits 
average fixation time 
standard deviation 
9 
16 
653 
120.4ms 
17.4ms 
27 
16 
653 
154.1ms 
17.8ms 
Instead of a strictly equal fixation time for both locations as would 
ideally be expected, the duty cycle of the periodic behavior is rather 44%. 
The origin of this difference is device mismatch within the link. cells, and 
mismatch in stimulation intensity from the motor maps. 
This measurement has been repeated for ten different node pairs located 
symmetrically with respect to the map, but at different radial positions. 
Periodic saccades between the two stimulated locations have always been 
observed. The average period has been found to differ slightly in different 
node pairs. On average, a period of 383ms has been measured, with a 
standard deviation of 68rns. This variation is partially due to the fact that the 
amount of stimulation received from the motor maps is not the same in all 
node pairs. Another reason is the effect of device mismatch in link. cells and 
motor maps. 
6.5.5 Effect of stimulation frequency 
The experiment described in §6.5.4 has been repeated for different 
stimulation frequencies. At every frequency, events have been recorded 
from the visual output bus until at least 70 hits were observed for each 
location. The period and duty cycle of the alternation between the two 
stimulated spots have been calculated from this data. The results are plotted 
in Figure 6.22. In this figure, vertical error bars indicate the standard 
deviation of each data point. It can be seen that within an operating range 
extending from a few hertz to IMHz, the period of saccades is inversely 
proportional to stimulation frequency. 
This experiment shows that fixation time can be tuned over a large range 
by means of stimulation frequency. In an application, fixation time must be 
long enough to let the mechanical system reach its final state, and the 
available visual processing hardware extract the information it needs. A 
conflicting requirement is that this time should be as short as possible in 
order to cover the visual field as quickly as possible. With the saccadic 

160 
Place coding in analog VLSI 
control chip, the average fixation time can be selected from less than 0.5ms 
up to 15s. This operating range is wide enough to accommodate a number of 
visual processing systems and mechanical devices. 
lOs 
Is 
"8 'R lOOms 
lOms .. , ........ : ..... . 
1ms 
.... '.' ............ . 
. ....... . 
. '.' ' ... ', ~ ,', t.·· 
:", ~ : .•. : . . : . 
10~s~~~~~~~~~~~~~~~~~~~~~~ 
1Hz 
10Hz 
100Hz 
1KHz 
10KHz 
stimulation frequency 
80% 
............... . 
0) 
~ 60% 
.... 
u o 
.g 40% 
20% ... '.' .•.•...................... '.', ............. ,. 
0% 
1Hz 
10Hz 
100Hz 
1KHz 
10KHz 
stimulation frequency 
100KHz 
1MHz 
100KHz 
IMHz 
Figure 6.22. Period of saccadic movements between two nodes versus stimulation rate. 
6.5.6 Stimulation of two visual nodes at different rates 
The same two visual nodes as in §6.5.4 have been stimulated at unequal 
rates. The frequency ratio has been shifted in small steps from 1150 to 50 
while keeping the total frequency constantly at 2KHz. The period and duty 
cycle of saccades have been measured as in previous experiments. The result 
plotted in Figure 6.23 shows that the chip takes saliency properly into 
account to allocate fixation time. Even with large differences in saliency, the 
less interesting locations are not completely neglected. 

6. Saccadic oculo-motor control chip 
lOs 
.... 
' .. : . " 
: :-:.:. :', . : ...... . 
"0 
·8 
Is 
<.) 
0. 
~ 
u 
;>. 
u 
;>. 
;:; 
"0 
lOOms 10-2 
100% 
80% 
60% 
40% 
20% 
0% 10-2 
10° 
stimulation ratio 
10° 
stimulation ratio 
161 
101 
101 
Figure 6.23. Measured saccade period and duty cycle versus the ratio of stimulation 
frequencies of two visual nodes. 
6.5.7 Saccade generation with four stimulated nodes 
When more than two visual nodes are stimulated, the dynamics of 
saccade generation becomes more complex and therefore more difficult to 
characterize. The sequence of saccades and fixation times is usually not 
obviously periodic, or at least the period - if any - is long enough that it 
cannot be detected merely by on-line observation or simple inspection of 
recorded data. As an illustration, a particular case has been selected where 
four nodes of the visual map are stimulated at a frequency of 1 KHz. The 
nodes have been picked in such a way that they get the same stimulation rate 
from the motor maps when the prism orientation inputs are kept constantly 
at <PI = 1800 and <P2 = 00 (null deflection). Event streams at the three output 
buses of the chip have been recorded for 3 minutes. This data has been post-

162 
Place coding in analog VLSI 
processed to detect changes in the direction of gaze, resulting in a sequence 
of saccades. 
Measurement results can be summarized in several different ways. 
Figure 6.24 shows saccades in terms of directions of gaze. On this plot, each 
saccade is represented by a straight segment joining the initial and final 
directions of gaze. Multiple saccades involving the same pair of points 
cannot be distinguished, because the related segments overlap. It can be seen 
however that every possible transition between two of the four stimulated 
nodes has occurred during the observation time. This behavior is likely to 
change slightly when the chip is used in conjunction with a real mechanical 
device instead of a test environment emulating it. Prism orientation inputs 
were kept constant during this measurement, whereas in a real system they 
would change at every saccade in order to reflect the newly selected prism 
orientations. In this case, since these inputs are used to bias the competition 
in favor of nearby locations (in terms of prism travel distance), saccades 
toward neighbor points will be more likely than saccades toward remote 
locations. This behavior has been demonstrated in simulations [1], but could 
not be checked in measurements because of limitations of the test 
environment (§6.S.1). 
'. - ,' ..... 
Figure 6.24. Saccades occurring between four points stimulated with the same intensity. 
Table 6.2 provides another view on the recorded data, namely the 
number of times every stimulated visual node has been visited, and the 
fixation time of every location. Nodes are identified by a letter matching the 

6. Saccadic oculo-motor control chip 
163 
labels shown in Figure 6.24. It can be seen that the number of hits is 
approximately equal for all nodes. Average fixation times differ somewhat, 
even if the stimulation conditions of all four nodes have been made as 
symmetric as possible. The origin of this dispersion is believed to be device 
mismatch. The standard deviation of fixation times is high in relative terms, 
showing that the dynamic behavior of the saccadic control chip is very 
irregular with the selected stimulation pattern. 
Table 6.2. Saccade statistics in the case where four visual nodes are egually stimulated 
visual node 
number of hits 
average fixation time 
standard deviation 
A 
436 
133ms 
57.4ms 
B 
443 
88.2ms 
56.3ms 
C 
418 
106.4ms 
55.4ms 
D 
434 
86.9ms 
54.3ms 
Figure 6.25 illustrates the temporal aspect of the dynamic behavior. The 
horizontal axis of this plot is time. On the vertical axis, an arbitrary value 
has been assigned to each of the four stimulated visual nodes. The amplitude 
of the curve drawn in this diagram indicates the winning location at every 
time. Only a fragment of a few seconds from the total recording lasting 
3 minutes is shown. Generally, the four stimulated points are visited in the 
same sequence for some time, then the order of visits flips to another 
sequence. In the selected fragment, several such sequence changes occur in 
close succession. Fixation times are typically irregular from one cycle to the 
other. 
D 
c 
B 
A 
8 
L..... 
--' 
'--
-
8.5 
-
r--
, 
-
'--
9 
9.5 
0-
-
-
10 
time [s] 
r--
-
-
10.5 
.---
'---
r--
-
11 
11.5 
12 
Figure 6.25. Fragment of the temporal recording of saccades. The vertical axis is used to 
distinguish stimulated nodes. 

164 
Place coding in analog VLSI 
Because of the complexity and wide variety of dynamic behaviors 
displayed by the chip depending on stimulation patterns, this behavior 
cannot easily be characterized in quantitative terms. At least, the 
experimental results reported in the present paragraph confirm that the 
functionality of the chip in terms of saccade generation fulfills the general 
requirement of attending the points of interest successively within a time 
frame compatible both with visual processing needs and mechanical 
capabilities of the oculo-motor system. 
6.5.8 Effect of spatial diffusion 
As described in §6.3.5, visual nodes are coupled to their nearest 
neighbors in both excitatory and inhibitory fashion. The purpose of the 
excitatory coupling is to average activation grades of the visual map locally, 
so that the saliency of extended areas instead of individual saliencies are 
taken into account for the saccade target selection process. In the described 
chip, this coupling is determined by a capacitive network, and is therefore 
constant. The inhibitory coupling is intended to decrease the activation 
grade in the vicinity of the currently observed point, in order to discourage 
saccades toward already visible locations. The area covered by this 
inhibition can be tuned electrically. The effect of these two mechanisms has 
been tested by stimulating extended areas of different sizes on the visual 
map, and recording saccades occurring between these spots with and 
without the lateral inhibitory coupling. More specifically, four different 
spots were stimulated simultaneously, one of which was made of a single 
node whereas the other three comprised a central node with its first, second 
and third nearest neighbors respectively. All visual nodes belonging to a 
same spot have been stimulated at the same frequency calculated in such a 
way that the total stimulation rate received by each spot is 1 KHz. The four 
spots have been located symmetrically with respect to the center of the 
visual map, so that they get similar amounts of stimulation from the motor 
maps. Prism orientation inputs were set to <PI = 1800 and <P2 = 00 (null 
deflection), as in most experiments reported in the present section. Saccades 
have been recorded for 3 minutes in each experiment. 
Results obtained while the inhibitory coupling was completely 
suppressed are shown graphically in Figure 6.26. Without coupling, all 
stimulated points participate independently in the saccade generation 
process. Consistently with expectations, every stimulated node has been 
attended several times over the recording duration. By counting the number 
of hits of every visual node, it has been found that the distribution of hits is 
fairly even over each spot. 

6. Saccadic oculo-motor control chip 
165 
120" 
, .. ~ : ' , ~ 
150" .' 
ISO"> . , . -:, .. , 
210" " 
• 
, 
~ .', • 
A 
• 
300~ 
27ff 
Figure 6.26. Saccades recorded while the inhibitory coupling was suppressed. 
To get a more quantitative view of the data, saccades have been sorted 
by source spot and destination spot. The number of saccades found in every 
possible combination of sources and destinations is given in Table 6.3. In 
this table, diagonal terms indicate intra-spot saccades. As can be seen, such 
saccades are as frequent as saccades between different spots, which is again 
consistent with the fact that all nodes compete for attention independently of 
each other. Overall, the four spots get approximately the same number of 
hits, if only inter-spot saccades are counted (Table 6.4). 
Table 6.3. Saccades sorted b source and destination sot, without inhibito 
destination spot radius 
source s ot radius 
0 
1 
2 
3 
0 
0 
145 
112 
31 
96 
97 
115 
101 
2 
61 
88 
139 
169 
3 
132 
78 
93 
105 
Table 6.4. Hit rate of every spot without inhibitory coupling 
spot radius 
number of hits 
o 
289 
1 
2 
3 
312 
319 
304 

166 
Place coding in analog VLSI 
The same experiment has been repeated while inhibitory coupling 
between visual nodes was active. The spatial extent of this coupling is 
tunable by means of an external bias voltage, but since there is no simple 
way to measure this spatial extent, several values have been tried, and the 
most interesting bias condition has been selected after viewing the results. 
The outcome of 3 minutes of acquisition is shown in Figure 6.27. In contrast 
with the previous case, saccades no longer reach every stimulated visual 
node. On the largest spot, it is even possible to distinguish three main 
saccade target areas located as far as possible from each other, presumably 
because the extent of lateral inhibition is sufficient to prevent saccades in 
the intermediate area. 
90" 
120" 
, ' 
~ . " ... ~ 
00" 
150" :' 
180">· .. ·>·· . 
300" 
270" 
Figure 6.27. Saccades recorded while the inhibitory coupling was present. 
A summary of measured saccade parameters is available in Table 6.5 and 
in Table 6.6. Unlike the previous case, not a single intra-spot saccade has 
been observed, which demonstrates that the inhibitory coupling fulfills its 
purpose. 
Table 6.5. Saccades sorted b source and destination sot, with inhibito 
destination spot radius 
source s ot radius 
0 
1 
2 
3 
o 
0 
92 
29 
20 
1 
77 
0 
25 
20 
2 
24 
17 
0 
24 
3 
41 
12 
11 
0 

6. Saccadic oculo-motor control chip 
Table 6.6. Hit rate of every spot with inhibitory coupling 
spot radius 
o 
1 
2 
3 
number of hits 
142 
123 
65 
64 
167 
The total number of saccades is lower than in the previous case despite 
the fact that the recording time was the same. The reduction is stronger in 
larger spots, resulting in an unbalanced number of hits between the four 
spots. This result was expectable because inhibition subtracts from visual 
stimulation (§6.3.5). Since saccade frequency depends on the visual 
stimulation rate (§6.5.5), a higher inhibition results in less frequent 
saccades. 
6.5.9 Travel distance minimization 
As explained in §5.2.3, there are two possible combinations of prism 
orientations for most directions of gaze. Whenever the control chip 
generates a saccade, it should select the solution requiring the smallest prism 
displacements (§6.2.1). To check this feature, a systematic scan of the visual 
input map has been carried out while keeping the prism orientation inputs 
constant. The scan consisted of stimulating four different visual nodes 
simultaneously at a rate of 5KHz each in order to produce fast saccades. 
While each set of nodes was stimulated, the event streams at the three output 
buses of the chip have been recorded for 20 seconds. Correspondence 
between events on the visual output map and the two motor output maps has 
been established on the basis of coincidence, since a pulse generated by a 
link cell is applied to the three output buses simultaneously (§6.4.4). Prism 
orientations delivered by the chip at its motor output buses have been 
compared to the expected responses in order to determine which of the two 
solutions the chip has selected. For most nodes, only one solution has been 
observed, but in a few cases, both solutions showed up in alternation. 
The result of a first scan, carried out with prism orientation inputs set at 
<PI = 1800 and <P2 = 00 (null deflection), is displayed on the right of 
Figure 6.28. To represent the results graphically, one of the two links 
connected to each visual node has arbitrarily been tagged "A" and the other 
one "B". The graph shown in this figure reproduces the topology of the 
visual map, whereby each node is represented by a dark or light hexagon 
depending on whether link A or B was found active when this visual node 
was stimulated. A filling pattern has been used to indicate nodes where both 
solutions have been detected during the recording time. A similar plot 
placed on the left of the figure shows the response expected from 

168 
Place coding in analog VLSI 
calculations based on a behavioral model of the chip. In the calculated plot, 
nodes have been marked as "A & B" if the stimulation rates received by 
links A and B from the motor maps differ by less than 30%. The measured 
results match expectations fairly well. In 9.8% of the nodes, both solutions 
have been observed despite the fact that one of them was clearly optimum. 
A non-optimum solution alone never occurred. 
eA 
08 
$A&B 
•••••••••••••••••••••••••••••• 
···.·1.·.·.·1.·.·.·1.·.·.·.·.·.·.·.·.·.·.·.·.·.·.·.· .... ~ 
::~~I!!:j[j:jll::~~~r, ... ~ ... ~ ... ~ ... ~( ... ~ ... ~ ... ~ ... ~ ... 'ff~!!!:~!:~!::l~jl"l': 
Figure 6.28. Selection of optimal solution for saccade generation, with constant prism 
orientation inputs (<PI = 180° and <P2 = 0°). Left: calculated response. Right: measured 
response. 
The same experiment has been repeated with another combination of 
prism orientations, namely <PI = 45° and <P2 = 326°, which corresponds to a 
deflection of 28° to the left of the optical axis of the lens. The result, plotted 
with the same graphical conventions, is shown in Figure 6.29. Again, 
calculations and measurements are overall consistent. The error rate is 
slightly higher in this case. For 10.2% of the nodes, in response to visual 
stimulation, both solutions occur while only one of them is clearly optimal. 
In 1.9% of the nodes, only the non-optimum solution occurs. These nodes 
are located in areas required very large prism displacements with respect to 
the "current" prism orientations applied to the inputs. 
These results demonstrate that the saccade optimization feature is 
essentially functional. Non-optimal trajectories are selected mainly in areas 
where there is little difference in prism travel distance, therefore the loss in 
displacement time is only moderate. Errors also occur when the total prism 
displacement is large anyway. A lower discrimination capability for larger 
travel distances was predictable from the shape of the activation patterns on 
the motor maps (Figure 6.20). The slope of these patterns is steepest in the 
immediate vicinity of the current prism orientation, but nearly flat at the 

6. Saccadic oculo-motor control chip 
169 
opposite orientation. In the flat area, variations due to device mismatch can 
dominate the intentional variations indicating prism travel distance. In any 
case, selecting the wrong solution results only in a non-minimum delay, but 
is never fatal to the functionality of the oculo-motor system. 
eA 
OB 
*A&B 
Figure 6.29. Selection of optimal solution for saccade generation, with constant prism 
orientation inputs (<PI = 45° and <P2 = 326°). Left: calculated response. Right: measured 
response. 
6.6 Discussion 
The implementation of a network of links described in this chapter 
differs substantially from the approaches presented in Chapters 4 and 5. 
First of all, the representation of activation grades has moved from current 
intensities to pulse frequencies. A consequence of this change is the 
introduction of a "sum-plus-threshold" operator for the combination of 
maps, instead of controlled conductances in series. These features give this 
implementation a more "neuron-like" flavor, since spikes, sums and 
saturating non-linearities all belong to the functional repertoire of both 
biological and artificial neural networks. If the electronic version of place 
coding defined in this book is anyhow relevant to neurobiology, then the 
similarities are likely to show up in this sort of implementation, rather than 
with controlled conductances in series operating in continuous time. 
Bi-directional operation and dynamic behavior are additional novelties 
introduced in this chip compared to the previously described ones. Dynamic 
behavior arises from the manipulation of activation grades by temporal 
integration. This chip is also a first implementation of a hysteretic relation 
by place coding. Other possible approaches to introduce temporal behavior 
in networks of links will be introduced in Sect. 7.2, and a more general 

170 
Place coding in analog VLSI 
discussion on how to get hysteresis from such a network will be given in 
Sect. 7.5. 

PART III 
PERSPECTIVES 

Chapter 7 
Extensions 
7.1 Preliminary 
Chapters 2 and 3 have defined place coding, identified some properties 
of this representation and introduced networks of links as a way to carry out 
computation with place coding. These theoretical elements have been 
applied in Chapters 4 and 5 to the design of analog integrated circuits 
computing static functions, which means that any combination of input 
values completely determines an output value, and that the function does not 
depend on time. The chip described in Chapter 6 has shown already that 
computation with place coding and networks of links is not restricted to 
static functions. Further in this vein, the present chapter describes some 
ways to extend the basic concepts in order to address more general 
problems. The reader is warned that the present chapter is essentially an 
outlook on possible extensions of the concepts without illustration by real 
hardware implementations. The following classes of computational 
problems will be discussed: 
a) Functions of time 
In principle, place coding can represent physical quantities of any nature, 
including time. However, time requests special attention for several reasons. 
On one hand, the unbounded nature of time can be a problem for functions 
which depend explicitly on time. On the other hand, implicit functions of 
time, i.e. functions which depend not only on present signal values but also 
on values from the past, cannot be implemented with the basic version of 
networks of links, because dynamic aspects lack completely in the concept 
of link. Section 7.2 suggests techniques to circumvent this limitation. 
173 
O. Landolt, Place Coding in Analog VLSI
© Springer Science+Business Media Dordrecht 1998

174 
Place coding in analog VLSI 
b) Sparse networks 
Networks of links as described so far in this book map every possible 
combination of input nodes to the related output nodes. The number of links 
required for an exhaustive mapping grows to the power of the number of 
input maps, making the single-layer implementation of functions of more 
than four or five variables impractical (except if every map has only very 
few nodes). As previously mentioned, the problem can often, but not always, 
be solved by splitting the overall function in a hierarchy of smaller 
networks. Another possible approach is to give up exhaustive mapping and 
implement only the most important links. Several ways to shrink network 
size without sacrificing too much functionality are explained in Section 7.3. 
c) Pattern sharpening 
As explained in §3.3.5, networks of links may deliver loose patterns at 
their outputs, which may cause accuracy problems when such patterns are 
used as inputs to subsequent networks. To improve this situation, it is 
possible to build a network which turns a loose activation pattern into a 
tighter one without altering its center of gravity substantially. A variation of 
this network uses recurrent self-excitation to provide a satisfactory pattern in 
a single processing layer. This topic is discussed in Section 7.4. 
d) Relations with hysteresis 
If more than one output state can occur in response to the same 
combination of input values, the relationship cannot be called a function 
anymore. With networks of links, it is possible to associate more than one 
output value to a single combination of input values, but in this case, the 
outputs will all be active together. To get a true hysteretic behavior, it is 
necessary to add a mechanism which selects one of the possible output 
states on the basis of history. This can be achieved by feeding back the 
output as an additional input to the network, as will be explained in detail in 
Section 7.5. 
e) Constraint solving (systems of equations) 
Many computational problems cannot be split into a feedforward 
succession of function evaluations. Sometimes, several interdependent 
variables must be determined concurrently by intersecting several sets of 
possible solutions in a multi-dimensional space (which is equivalent to 
solving a system of equations in the analytical domain). Given the 
possibility offered by place coding to represent subsets, a special type of 
network can find all solutions of a set of constraints in one feedforward 
pass. This technique will be described in Section 7.6. 

7. Extensions 
175 
7.2 Functions of time 
7.2.1 Explicit functions of time 
A time interval, or rather the time elapsed since the occurrence of a 
particular event, can be represented by place coding just like any other 
quantity. For this purpose, a map must be built in such a way that the 
activation pattern shifts smoothly over time from one end to the other end of 
the map. The activation grade of each node is a membership function of 
time, i.e. a time-varying signal with a peak at the preferred time interval 
associated to this node (§3.2.3). Figure 7.1 shows an example of such 
waveforms in the case of triangular membership functions. 
~Tl (t) 
o 
Figure 7.1. Waveform of activation grades for several nodes in a map coding a time interval 
starting at the occurrence of an event (at t = 0 in this figure). One of the waveforms is shown 
in bold for clarity. 
One possible way to create such waveforms with proper shifts in time for 
successive nodes of a map is a cascade of monostable circuit elements, each 
of which produces a single triangular pulse (Figure 7.2). One of these 
circuits has three possible states, namely idle, rising and falling. During the 
idle state, its activation grade is zero. When triggered, the circuit enters the 
rising state during which the activation grade increases progressively in time 
(e.g. by charging a capacitor with a constant current). When this signal 
reaches the grade 1, the circuit flips by itself into the falling state while 
triggering the next circuit in the cascade. It returns idle when reaching the 
activation grade O. The timing is illustrated in Figure 7.3. The operating 
principle of this circuit reminds of a delay line, but works with pulses only. 
The activation pattern produced by the whole circuit is effectively 
shifting in time over the map at a speed determined by the rising rates of the 
monostable cells. The pattern can be used as an input to a network of links 
computing an explicit function of the time delay and possibly other 

176 
Place coding in analog VLSI 
variables. For a practical implementation, it remains to decide how the 
circuit should behave in case a new event occurs while a pattern is still 
present on the map. 
event 
.9 mono- '" 
.9 mono- '" 
" mono- '" 
" mono- '" 
0 
0 
.-
0 
:~ stable 
0 
OJ) stable "5 
OJ) stable 
OJ) 
OJ) stable 
OJ) 
OJ) 
"5 
'5 
5 
'5 
5 
'E 
J.1 
J.1 
J.1 
J.1 
J.1TI (t) 
J.1T2(t) 
J.1T3 (t) 
~4(t) 
Figure 7.2. Cascade of analog monostable circuits producing a shifting pattern. 
trig in 
~ t 
trig out 
• 
t 
idle 
I 
I 
I 
I 
rising 
falling 
I 
• 
t 
idle 
Figure 7.3. Timing diagram characterizing one monostable circuit. 
It should be possible to extend this idea to generate periodic patterns by 
using a ring topology. In principle, a sustained oscillation should occur if the 
last monostable in the cascade triggers the first one. However, additional 
elements would be needed to ensure that the pattern shifting in an endless 
loop remains tight, i.e. that only a single spot of activation can exist on the 
map. 
7.2.2 Implicit functions of time 
Implicit functions of time are functions of both present and past values of 
the same signal (or signals). Circuit implementations of such functions must 
obviously resort to some kind of storage elements. A possible solution is 
shown in Figure 7.4 for a function of a single signal at two different times 
(present value and one value from the past). This architecture is based on a 
delay cell for each node of the input map (with the same delay for all 
nodes). The original and delayed pattern are two independent inputs to a 

7. Extensions 
177 
network of links, the internal dynamics of which are assumed negligible 
with respect to the pattern delay time. For instance, this circuit could 
compute an approximation of the time derivative of the input signal. For this 
purpose, the network of links should compute the difference between its two 
inputs. 
~ 
"5 
0-
.S 
.. .... 
delay 
"5 
cells 
network of links 3-
LflS'\ 
:::: 
... 
0 
---+c: : 
I 
I 
N 
I 
I 
"5 
I 
I 
0-
I 
I 
.S 
I 
I 
I 
\ 
I 
.... __ .1 
Figure 7.4. Place coding circuit implementation of an implicit function of time. 
If more than one value from the past has to be taken into account, this 
architecture can be generalized by feeding each activation signal of the input 
map into a delay line. Several past states of the activation pattern can be 
picked in parallel at the relevant stage of the delay lines and fed into a 
network of links. 
7.2.3 Comments 
Although networks of links are not inherently dynamic systems (i.e. their 
internal delays are rather parasitic than part of their function), the two 
examples given in this section show that useful dynamic behavior can be 
obtained by combining them with delay elements. An operating condition is 
that intentional delays must be significantly longer than parasitic delays in 
the network. In analog integrated circuits, delays can be created by means of 
capacitor-based functional blocks. In some implementation media, it might 
be sufficient to adjust the length and cross-section of wires properly to 
create the required temporal shift between two input maps of a network. 
This statement applies to biological neurons. 

178 
Place coding in analog VLSI 
7.3 Sparse networks 
7.3.1 Preliminary 
According to the basic concept, a network of links which implements a 
function of N variables connects every possible combination of N nodes 
from different input maps to some node of the output map. The number of 
links grows quickly with N, which may lead to impractical network sizes. 
An obvious caution one should take is to avoid larger map sizes than really 
necessary for meeting performance specifications. Another advisable step 
already mentioned previously is to split a function of several variables into a 
hierarchy of smaller networks whenever possible. The present section 
discusses an additional option, which is to depart from exhaustive mapping 
and implement only a subset of links. The applicability of this approach is of 
course strongly dependent on the particular function of the network. The 
present section is a short list of situations where a simplification is possible, 
and hints on how to make the network more efficient in these cases. The 
issue of network optimization has not been worked out in great detail as of 
this writing, therefore this section can by no means be considered complete. 
Its primary purpose is to attract attention on the fact that networks of links 
constructed by the basic procedure are not necessarily optimal from the 
start. 
7.3.2 Unused nodes 
Depending on the choice of map sizes and on the procedure used to 
generate a network of links, it can happen that some nodes in the output map 
remain unused, i.e. unconnected to any link. This is likely to happen in 
divergent parts of a network (§3.3.5). If the network is generated by 
software (which is always advisable to do, since generating a network is a 
very tedious, though simple job), such unused nodes may go unnoticed. If 
the output map serves as the input to a subsequent network, links taking one 
of their inputs on an unused node will be permanently inactive, therefore 
completely useless. An advisable optimization step in the design of a 
network is to check for unused nodes and remove the related links. 
7.3.3 Correlated input signals 
Some applications may require to compute a function of several 
variables which are not completely independent. Consequently, some 
combinations of values simply never occur, which implies that some links in 

7. Extensions 
179 
the network will never be activated. Links which handle these combinations 
can be removed from the network without altering its operation. 
7.3.4 Convergent links 
In areas where a function implemented by a network of links remains 
nearly constant, several input nodes project to the same output node. This is 
true in particular for saturating functions, which tend to a constant 
asymptote for increasing input values. In this case, the input map can be 
simplified by merging all input nodes connected to the same output value 
into a single node with an extended range of preferred values. In other 
words, it is not useful to make a distinction between several input values 
which later project onto the same output value anyway. This simplification 
in the input map results in the replacement of a set of convergent links by 
only one link. Of course, merging input nodes is not possible if these nodes 
are connected to several different links, not all of which are convergent. 
7.3.5 Unbalanced distribution of links 
In general, not all output nodes of a network have the same number of 
links connected to them. If the distribution of links among output nodes is 
strongly unbalanced in favor of one particular node, a significant reduction 
of the number of links is possible by removing this node and all the links 
projecting to it. The preferred value of this node must be made the default 
output value, meaning that a null output pattern must be interpreted as a 
representation of this value. This approach is particularly relevant for 
cognitive functions, where usually only a few combinations of input values 
lead to the recognition of an expected pattern, whereas most input 
combinations are considered as meaningless patterns. With a network of 
links, this would mean that most links project to the output node associated 
to the "meaningless" class. Removal of this node yields considerable 
savings. The only functional difference is that in the absence of a 
meaningful input pattern, the output map remains complete inactive instead 
of having the "meaningless" node active. The cost of this simplification is 
that one cannot discriminate anymore whether no stimulation is applied to 
the input maps, or whether a meaningless stimulation is applied. However, 
in many cases, this discrimination is irrelevant, either because some pattern 
is always applied to the inputs, or because the actions triggered in both cases 
are the same. 

180 
Place coding in analog VLSI 
7.4 Pattern sharpening 
In §3.3.5, while discussing ways to avoid pattern divergence, mention 
was made of the fact that loose patterns could actively be turned into tighter 
patterns by a special kind of network of links. The present section describes 
one possible way to build such a network. For simplicity, we consider only 
the case of a scalar map with a uniform distribution of preferred values, but 
the proposed solution can be extended to other situations as well. 
7.4.1 Feedforward network 
The central element in the proposed solution is the network depicted in 
Figure 7.5. The input in this example is a map of sevenl nodes with 
preferred values X'I to x' 7. The input pattern is applied to both inputs of a 
network of links, which is represented by an array in the center of the 
drawing. As in every network of links, each input combination is connected 
to a particular output node. In Figure 7.5, a number in each array cell 
identifies its destination in the output map shown on the right. Some links 
are connected directly to an output node with unit weight, and some are 
connected to two consecutive nodes with 50% weight each. The final output 
map has the same size and preferred values as the input map. 
x' 7 
x' 1 
L 
-
'---
I 
1 
2 
3 
4 
5 
6 
7 
I I 
2 
3 
3 
4 
4 
5 
5 
6 
6 
7 
7 8 
8 
9 
4 
5 
5 
6 
6 
7 
7 
8 
8 
9 
9 10 
10 11 
6 
7 
8 
9 
10 
11 
12 
7 
8 
9 
10 
11 
12 
13 
1--=71 
2 --<:::=::: 
3--=~ 
4--<~ 
5-~~ 
6 --<:::=::: 
7--=~ 
8--<~ 
9-~~ 
10--<~ 
11-~~ 
12 --<:::=::: 
13--=""'t 
Figure 7.5. Two-input network of links with the same pattern applied to both inputs. Each 
cell in the array is a two-input fuzzy AND gate, the output of which is connected to one node 
of the map on the right. The destination node of each gate is identified by a number. 
1 Arbitrary choice. 

7. Extensions 
181 
The network of links is constructed in such a way that each combination 
of input nodes (x'j, x'D projects to the output node, the preferred value of 
which is the average of x' j and X'j. A study of this network in a succession of 
particular cases may help to understand how it works: 
If only a single node X'j of the input map is active, then a single link 
located on the diagonal of the array is activated. By construction, this 
link projects to the output node with a preferred value x\, therefore the 
pattern remains unchanged. 
If exactly two nodes X'j and X'j of the input map are active to some 
degree, then four links in the network are active, which handle the 
combinations (x'j, X'j), (x'j, X'j), (x'j, x\) and (x'j, X'j). Both links 
handling the cross-combinations between X'j and X'j project to the same 
node, the preferred value of which is the average of x' j and x' j. The other 
two links project to X'j and X'j themselves, thereby contributing to keep 
the original components in place in the output map. The strength of the 
cross-combination components in the output map dominates the other by 
a factor of two, because two links stimulate it. Therefore, no matter how 
remote the two active input components may be, this network produces a 
pattern with a peak component close to the center of gravity of the 
original pattern, while the original components remain, but with a lower 
grade relative to the total activation grade in the output pattern. 
-
For other input patterns, the qualitative analysis is more complex, 
because the output pattern is a combination a contributions from every 
possible pair of active input nodes. Simulations show that the resulting 
pattern is always tighter than the original one. 
It may be instructive to show a quite different schematic describing the 
same network. Figure 7.6 shows the input (top left) and output (bottom) 
maps with their preferred value, and a dashed box encloses the combination 
of gates which implements all links projecting to output node x' 4 (output 
component number 7 in Figure 7.5). Links to output nodes other than x' 4 are 
implemented by essentially similar combinations of gates, but they are not 
shown for the sake of clarity. A separate AND gate exists for an input 
combination (x\, X'j) and the symmetrical combination (x'j, x\), which gives 
these pairs a double weight compared to the single self-connection (x' 4, x' 4). 
This self-connection should in principle be an AND gate with the same 
signal at both inputs, but this is functionally equivalent to a simple 
connection as drawn. A weight factor a has been added to this connection, 
because it can be functionally interesting to reduce further the influence of 
this link compared to the other links (see later in this paragraph). 

182 
Place coding in analog VLSJ 
X'IO--_------------------. 
x'2o--+_---lf-------------, 
x'30--+_--........ - __ ------. 
x'4 O--+_--........ -----lf---, 
x's o--+_--t_-----lf-+-+--, 
x'6 O--+_--............. ----lf-+--+~-+_...., 
x'7 o--+_-..-t_-+----lf-+--+~-+__+-t_..., 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
l ________ _ ---------
2 
3 
4 
S 
6 
7 
8 
9 
10 
11 
12 
13 
Figure 7.6. Gate-level schematic of the same network of links as shown in Figure 7.5. Only 
the links projecting to one particular output node are shown for the sake of clarity. 
It must be said that the described network conserves the center of gravity 
of the applied pattern only approximately. For graded patterns with several 
active components, the relative magnitudes of these components may be 
altered somewhat due to the non-linear transfer characteristic of fuzzy logic 
gates. Besides, original components from a loose input pattern are clearly 
still strongly present in the output pattern. A desirable improvement to the 
network described above is to weaken these residues. For this purpose, it is 
necessary to reduce the weight a. of the direct component (see Figure 7.6) to 
a small fraction (e.g. 1 %) of the weight of cross-components. Thereby, in 
response to a loose pattern with two active components for instance, the 
network yields a strong peak close to its center of gravity, and much weaker 
residual components at the original locations due to the attenuation by a.. To 
avoid excessive attenuation of the input pattern in case the input pattern is 
already tight (no cross-components), the output pattern is normalized to a 
total activation grade of 1. Simulation results are shown in Figure 7.7 for 
two different input patterns. For a two-component pattern (on the left), the 
output has essentially one peak at the center of gravity, with a very small 
residual activation at the locations of the original peaks (I % of the original 

7. Extensions 
183 
strength). A three-component input pattern (on the right of the figure) 
produces one large peak for every pair of active input nodes, but overall, the 
output pattern is tighter than the original one. 
::1. 
::1. 
0'1 
0.6 
0.4 
0.2 
o 
0'1 
0.6 
0.4 
0.2 
o 
input 
input 
5 
10 
15 
20 
25 
30 
5 
10 
15 
20 
25 
30 
output 
output 
5 
10 
15 
20 
25 
30 
5 
10 
15 
20 
25 
30 
Figure 7.7. Simulated output of the feedforward pattern sharpening network for two different 
input patterns (left and right). Dashed lines indicate the center of gravity of each pattern. 
7.4.2 Recurrent network 
The output pattern shown on the right of Figure 7.7 could be improved 
by using it as an input to the same feedforward network. Instead of using 
several successive layers to progressively sharpen the pattern further, it is 
possible to feed the result back as an input to the same layer. One way of 
implementing such a recurrent scheme could be to update the input pattern 
in discrete time, by replacing it by the present output pattern in regular time 
intervals long enough to let the feedforward network settle. With this 
algorithmic approach, the original input pattern would be set as the initial 
state of the system, which would converge into a final tight pattern after 
some number of iterations. Instead, we shall describe a truly continuous-
time solution in which the output pattern, multiplied by some factor ~ 
ranging from 0 to 1, is added to the original input pattern, which is itself 
multiplied by the complementary factor 1-~ (Figure 7.8). If ~ is chosen close 
to 1, then the recurrent contribution strongly dominates the original input 
contribution in the input pattern of the feedforward network. This recurrent 
network therefore behaves approximately like the discrete-time iterative 
network. Despite the positive feedback, self-excitation cannot sustain 
activation in the absence of an applied input pattern as long as ~ is smaller 
than 1. 

184 
Place coding in analog VLSI 
pattern sharpening network 
Figure 7.B. Schematic of the recurrent scheme. The rectangle represents the feedforward 
pattern sharpening network described previously. 
Simulation results for the same input patterns as in Figure 7.7 are shown 
in Figure 7.9 for (3 = 95%. These plots show that the recurrent network 
produces a graded "bell-shaped" pattern which is approximately symmetric 
and peaks near the center of gravity of the original pattern. The width of the 
output distribution depends on the spread of the original pattern. This 
recurrent network does generally not produce strictly tight patterns, but its 
output is always a single, contiguous distribution with a maximum at the 
correct place. In applications where this is not completely satisfactory, it 
would be possible to go from there to a truly tight pattern. A winner-take-all 
is the most obvious solution, but it introduces quantization. Searching for 
less damaging variations of an adaptive threshold scheme would be an 
interesting development of this approach in the future. 
The described recurrent network is reminiscent of a structure called 
cortical amplifier [48], but is specifically tailored to produce a local spot of 
activity. Cortical amplifiers are designed to evoke arbitrary patterns stored 
in interconnection weights, in a similar fashion as an associative memory. 
However, an attempt to use cortical amplifiers as a pattern sharpening 
network was hindered by some problems. In a software simulation, it was 
found difficult to identify operating conditions where a cortical amplifier 
reliably produces satisfactory results. The proposed network seems to 
perform better, at the cost of a more complex circuitry in the feedforward 
pass. 

7. Extensions 
185 
input 
input 
~ :: I : : 11111 : : I ~:~ I : II: I!:II: : I 
5 
10 
15 
20 
25 
30 
5 
10 
15 
20 
25 
30 
output 
output 
~::I : : I: : I 
~:~l : I: : I 
5 
10 
15 
20 
25 
30 
5 
10 
15 
20 
25 
30 
Figure 7.9. Simulated output of the recurrent pattern sharpening network for two different 
input patterns (left and right). Dashed lines indicate the center of gravity of each pattern. 
7.5 Hysteretic relations 
7.5.1 Preliminary observations 
A circuit with a hysteretic transfer relation is characterized by the fact 
that the output can take several different possible states in response to the 
same input value. Which of the possible solutions is present at a given time 
depends on history. This dependency on the past is static, meaning that the 
effect of the past remains forever instead of vanishing gradually like 
capacitive effects for instance. Feedforward networks of links as discussed 
so far do not exhibit hysteresis, but it is possible to build combinations of 
networks which do. To find out how, we first consider a simple hysteretic 
circuit, depicted in Figure 7.10, made of a current source and a non-linear 
resistor. Evolution of voltage V over time is expressed by the following 
differential equation, where C is the parasitic capacitance shown in dotted 
lines in Figure 7.10: 
CV = lin - f(V) 
(7.1) 
In this equation, V designates the temporal derivative of V. Voltage V 
increases if lin exceeds the current across the non-linear resistor, else it 
decreases. In graphical terms (see the right of Figure 7.10), V shifts to the 
right if feY) is below the horizontal dashed line marking I = lin, and shifts to 
the left otherwise. If lin is in the interval [lA, IB], two different sections of the 
graph I = feY) yield stable operating points, spanning two different intervals 

186 
Place coding in analog VLSI 
of V called domains later in this section, identified by the circled figures 1 
and 2. Assuming that V is initially in the stable state located in domain 1, if 
lin changes in time without ever exceeding IB' V will necessarily remain in 
the same domain. If lin becomes larger than IB, and only in this case, V 
increases until it stabilizes in domain 2. It will then remain there until the 
solution in domain 2 disappears as lin becomes smaller than IA• 
1 
1 c: 
••• 
. ,. 
, 
1 
1 
1 
1 I, 
, 
l=f(V) 
v 
+ 
l=f(V) 
~------~----~----~·V 
(i) 
!(i) 
Figure 7.10. Simple hysteretic circuit. The input is current lin whereas the output is voltage V. 
The characteristic of the non-linear resistor is shown on the right. 
These observations lead to the following conclusions: 
-
The described hysteretic relation is actually a function of the input lin and 
the present state of the output V. 
-
A similar hysteretic transfer relation can be implemented by a two-input 
network of links, if the output map is fed back to one of its inputs. 
7.5.2 Implementation with place coding 
A hysteretic relation between two maps can be created by the 
combination of networks shown in Figure 7.11. The feedforward network of 
links (on top) determines the output pattern y on the basis of x and a coarse 
representation of the current value of y. This coarse representation is 
actually the domain to which y currently belongs, which is determined by 
the feedback network (bottom of the figure). Therefore, the domain map has 
as many nodes as there are possible output values in response to the same 
input value x (two in the previous example). Except when y is close to a 
domain boundary, the pattern on the domain map is discrete, in the sense 
that only one node is active. Intuitively, one can consider the domain map as 
a selector switching different sets of links between x and y depending on the 
current domain. As long as x remains in the hysteretic range of the relation, 
the set of links for a particular domain associates the nodes of x with nodes 

7. Extensions 
187 
of Y which belong to the same domain. Outside of this range, the 
relationship between x and y does not depend on the present domain. 
Thereby, as in the previous example, the output y can move to another 
domain only when the input value leaves the hysteretic range. Details on 
how to build the networks are given in the case of a specific example . 
.. ... 
x 
.. 
.. 
~ 
.. 
network of links 
. y 
_ .. ... 
.. 
domai n -. 
'---
~ 
"'"--
network of links 
.: -
Figure 7.11. Combination of networks creating a hysteretic relation between x and y. 
7.5.3 Example: wide-range arc cosine 
The topic of the present section is illustrated by the description of a 
particular network built after the principle introduced in the previous 
paragraph. The purpose of this circuit is to "invert" a non-invertible 
function!. More specifically, given the amplitude x of a sine wave as shown 
on the left of Figure 7.12, the circuit determines the phase angle <I> in the 
range -1t to +1t. Would the phase angle range be restricted to only a half 
period, the solution would be a simple non-linear function of a single 
variable. In the case of a full period, there is a sign ambiguity on the phase, 
which can be raised only by taking history into account. The correct sign 
depends on whether the considered state of x has been reached by upper or 
by lower values. Deriving the signal in time dynamically might help solving 
the problem, but this solution would be troublesome at low frequencies and 
near the peaks of the sine wave, were the rate of change is very low. We 
! 
The reader is warned that the circuit whose description follows serves illustration purposes 
only. I am not sure whether it could be useful for anything practical... 

188 
Place coding in analog VLSI 
shall consider a static solution, conslstmg of an implementation of the 
hysteretic relation plotted on the right of Figure 7.12. It is worth reminding 
that -1t and +1t are the same angle, therefore the shown relation is actually a 
closed curve (drawn on the surface of a tube, this plot would not seem to be 
discontinuous). Arrows indicate the assumed direction of change (phase is 
necessarily increasing since time only grows). The origin of phase was 
chosen at the positive peak of the sine wave, therefore the circuit actually 
computes the "inverse" of a cosine function, i.e. a wide-range arc cos 
function. 
Figure 7.12. Input wavefonn (left) and hysteretic transfer relation (right) of a circuit which 
computes the phase angle from the amplitude of a sine wave. 
Let us represent both x and <1> by maps made of 20 nodes, the preferred 
values of which are uniformly distributed over the full range: 
X'i = -l+{i-l).~ 
<1>\ = -n+{i-l). ~~ 
where i= 1..20 
(7.2) 
The selected map size ensures that interpolation errors inherent to a 
network of links remain less than 5% of full scale in the worst case. The 
domain map has necessarily two nodes, which preferred values d'l and d' 2 
are respectively "I" and "2" (which have a symbolical rather than numerical 
meaning). The feedforward network is a set of links connecting each 
possible pair of nodes from map x and domain map d to a node of map <1>. 
The circuit is a twentyfold repetition of the cell shown in Figure 7.13 (one 
instance per i value). 

7. Extensions 
~d2 ~dl 
~xi-------+----~ 
<1>' a == +arc cos( x' i ) 
<1>' b == -arccos(x' i) 
Figure 7.13. Element of the network of links for one node of map x. 
189 
The equations on the right mean that the output of each fuzzy AND gate 
is connected to the node of map <1>, the preferred value of which matches the 
indicated expression best. It is assumed that the arc cos expressions are 
evaluated in the range [0, 1t]. By construction, it is clear that the shown 
circuit element selects either the positive or the negative phase angle 
depending on the domain which <I> currently belongs to. 
The feedback network is simpler. Nodes from map <I> with a positive or 
null preferred angle project to the domain map node associated with domain 
"I". The remaining nodes project to domain "2". Operation of the whole 
circuit will be explained on the basis of the curves shown in Figure 7.14. 
These plots result from a behavioral-level simulation of the described 
system. If x is initially equal to 1, then <I> takes the value 0 whatever the state 
of the domain map, since both domains agree on the phase angle at this 
point. The domain map quickly settles to 1 under the action of the feedback 
network of links, because <1>::: 0 belongs to domain 1. As time goes by, the 
amplitude of the sine wave decreases. The feedforward network of links 
determines the phase by means of the inverse cosine function hardwired in 
it, and gives it a positive sign consistent with domain 1. As x reaches -1, the 
output node representing <I> ::: ±1t becomes active, which makes the domain 
map gradually flip to state 2, because this phase angle belongs to domain 2. 
The flip does not create a discontinuity in <1>, because both domains agree on 
the phase angle at this amplitude. The apparent discontinuity in the bottom 
graph is only due to the common "wrap around" problem in the 
representation of angles in a Cartesian plot. On maps using place coding, 
there is no wrap-around discontinuity. In the second half of the period, the 
circuit operates in a similar way. Following the domain change operated 
when x reached -1, phase angles are reported with a negative sign by the 

190 
Place coding in analog VLSI 
feedforward network. The domain map flips back to state 1 when x reaches 
the value + 1 again. 
K IS::Z::S::ZI 
o 
0.5 
I 
1.5 
2 
~ -:~ 
o 
0.5 
I 
1.5 
2 
time [s] 
Figure 7.14. Simulated transfer relation between the input map x and the output map ~. The 
input sine wave has a frequency of 1Hz. The middle plot shows the state of the domain map. 
A small imperfection in the linearity of the phase plot near domain 
transitions is due to the fact that the domain map state changes gradually (as 
always with continuous place coding). While both nodes of the domain are 
activated to a significant degree, the phase angle computed by the 
feedforward network is a combination of contributions from both domains, 
resulting in values slightly shifted towards O. For this particular problem, it 
would be better to implement a sharp transition by adding a competition 
between the two nodes of the domain map. The transition would also be 
sharper with a larger number of nodes in maps x and <1>. 
7.6 Constraint solving 
7.6.1 Problem statement 
In their basic form, networks of links evaluate functions, i.e. they 
evaluate an initially unknown variable depending on one or several known 

7. Extensions 
191 
variables. However, some computational problems require the determination 
of several unknowns which depend on each other. Analytically, such 
problems can be expressed as a system of equations. 
fl(XI, ... ,XN,AI, ... ,AM)= 0 
f2(XI, ... ,XN,A}. ... ,AM)= 0 
(7.3) 
In the above equations, Xi are unknowns and Aj are known parameters. 
Each equation expresses a constraint which the variables Xi must satisfy. In 
some instances, analytical manipUlations can turn the original set of 
equations into an equivalent set of the form 
Xl =fl'(A}. ... ,AM) 
x2 = f2'(x}.A1,···,AM) 
(7.4) 
Thereby, the unknowns can be determined by a succession of function 
evaluations, which can be implemented by ordinary networks of links. 
However, it is not always possible to put a system of equations completely 
in this form, in which case the remaining equations must be solved 
concurrently. 
7.6.2 D1ustration: data fusion in visual perception 
An example problem picked from the visual perception field might help 
to better understand the motivation for solving constraints. The intensity of 
light reaching a particular photoreceptor on a retina depends on many 
things, including illumination intensity, reflectance of the surface seen by 
this part of the retina, orientation of this surface with respect to the light 
source and the retina, and distance between the surface and the eye, to 
mention just a few. The goal of a visual perception system is to recover 
relevant properties of the observed surroundings as accurately as possible 
from the pattern of illumination received by the eye. 

192 
Place coding in analog VLSI 
The problem is made difficult by the fact that primary visual cues are 
generally ambiguous, meaning that more than one interpretation is 
compatible with a given observation. For instance, if light intensity received 
by the considered pixel changes in time, this change may be caused either by 
a variation of illumination intensity, or a movement of the observed surface. 
Movements may as well be shifts as rotations, and several possible 
directions and velocities may be compatible with the observed change. In 
general, the real origin of the observation will even be a mixture of such 
causes in unknown proportions. For this reason, the actual change in the 
"real world state" cannot be computed from the observation of a temporal 
intensity change. The only certain knowledge that can be drawn from this 
observation is a constraint on what the changes in the real scene might be. A 
specific observed rate of change is compatible only with some specific 
translation or angular velocities, possibly combined with some specific rates 
of illumination change. Mathematically, this constraint could be expressed 
as an equation relating all the mentioned unknown properties of the real 
scene to the observed rate of change of light intensity, which would be a 
parameter of known value in this equation. 
A constraint alone is only a small step toward solving a visual perception 
problem. However, additional observations can be gathered, which 
introduce additional constraints contributing to narrow the range of possible 
interpretations of the visual scene (this general idea is often called "data 
fusion"). If a problem is defined by several constraints, none of which 
completely determines one of the unknowns by itself, then the 
computational process leading to the answer consists of solving the set of 
constraints concurrently. 
7.6.3 Hardware implementation 
The most widespread approach available today for solving a set of 
equations relies on a sequential processor implementing a numerical 
algorithm derived from mathematical considerations. However, it is also 
possible to build custom hardware to solve specific constraint-based 
problems. An elegant way to design analog circuits for this purpose has been 
devised by Harris [49], but his approach suffers serious drawbacks. First of 
all, every constraint is embodied in the transfer function of a circuit 
(constraint box) using a conventional analog representation, which makes 
implementation a fresh challenge for every new equation. Second, constraint 
boxes yield only a single solution, and not the set of all solutions compatible 
with a given set of constraints. Last, stability issues in such networks are 
unclear in the case of strongly non-linear constraints. The next paragraph 
outlines a way to solve a set of constraints in a discrete place coding context 

7. Extensions 
193 
by means of networks of links. It illustrates one specific advantage of 
discrete place coding, namely the capability of representing subsets, which 
is available neither in conventional analog or digital coding, nor in 
continuous place coding. 
7.6.4 Constraint solver based on place coding 
A possible way to solve a set of equations with networks of links will be 
explained on a particular example. Let us assume we wish to find two 
numbers Xl and X2 which meet the two constraints expressed as the 
following system of equations: 
{
Xl = A· s~n(2nx2) 
x2=B,xI+C 
(7.5) 
In these equations, A, B and C are known parameters which can be either 
external inputs, or variables already evaluated as a function of some external 
inputs. These parameters are not constants, because in this case it would be 
uninteresting to build a dedicated circuit to solve this set of equations (such 
a circuit would have no inputs, but only outputs with a constant state). A 
graphical solution to these constraints is shown in Figure 7.15 for A = B = 1 
and C = -0.5. The sine-shaped curve represents graphically the locus of 
(Xl. X2) tuples which satisfy the first constraint, whereas the parabolic curve 
is the locus of solutions to the second constraint. Solutions to the system of 
equations are at the cross-points between these two curves. It is important to 
recognize that each locus is a subset of the plane (Xl. X2), and that the set of 
solutions is the intersection of these two subsets. 
It has been noted already in §2.3.1 that discrete place coding can be used 
to represent subsets. The general idea behind the architecture described in 
the following is to implement each constraint (equation) by a network of 
links producing an activation pattern representing the locus of points which 
meet this constraint. This pattern is applied to a map covering the space of 
unknowns, i.e. the (Xl. X2) plane in the above example. This map intersects 
all patterns it gets from the incoming networks of links. The output pattern 
of the map represents the set of solutions to the system of equations. A 
combination of networks solving the system of equations (7.5) is illustrated 
in Figure 7.16. 

194 
0.8 
0.6 
0.4 
0.2 
<'I 
>< 
-0.2 
-0.4 
-0.5 
o 
xl 
Place coding in analog VLSI 
0.5 
Figure 7.15. Graphical solution to a system of two equations in two unknowns. 
x 
++ 
X 
r--~ 
~++ 
X 
~ 
+X 
X 
~ 
+ 
X 
X 
< ~I~ + +~+ 
~ 
~r 
X +++ 
X 
r 
X 
+~+ 
~ 
X 
X 
+ 
X 
X 
+ 
X 
X 
+ 
x x+++ 
lIE + 
mapC 
Figure 7.16. Combination of networks solving the set of equations (7.5). 

7. Extensions 
195 
The inputs of the circuit are three maps representing parameters A, B and 
C, because the system of equations is solved as a function of these 
parameters. The output of the circuit is a map representing (Xl. X2) tuples. In 
principle, this map could be further split into two independent maps of XI 
and X2 respectively (see §2.4.3). However, existence of multiple solutions 
(as is the case with the selected example) would result in multiple peaks in 
maps XI and X2, and there would be no way to know the correspondence 
between peaks of these two independent maps. Each node of map A is 
connected to every node of map (XI. X2) which satisfies the first equation in 
(7.5) within a tolerance range accounting for the discrete nature of the map. 
In Figure 7.16, a "+" sign identifies nodes related to a particular value of A. 
The second equation in (7.5) has two parameters B and C, each combination 
of which produces a different set of possible solutions on map (x!. X2). 
Therefore, in a first step, the two scalar maps B and C are combined into a 
vector map (B, C) as explained in §2.4.3. Each node in this map projects in 
tum to the set of (XI. X2) cells meeting the second constraint for the related 
combination of B and C. In addition to the usual OR gates combining 
multiple links originating from the same map, each node in map (x!. X2) 
incorporates a two-input AND gate which combines the total contribution 
from map A with the total contribution from map (B, C). Thereby, a node is 
active only if it is stimulated by both stimulation sources to some degree, 
which happens if the associated tuple (x!. X2) belongs to the intersection of 
the loci. The mentioned AND gates can be either binary or fuzzy, depending 
on whether binary or graded place coding is used. 
7.6.5 Comments 
With discrete place coding (§2.3.1), subsets of a discrete set can be 
represented and processed exactly, therefore the above architecture can 
solve sets of equations accurately when they involve only discrete variables. 
It is less clear whether this combination of networks still yields satisfactory 
results when XI and X2 are allowed to vary continuously. An answer to this 
question would require a deeper study of this structure. 
It is interesting to note that the proposed architecture also works with 
underconstrained or overconstrained systems of equations. There is no 
request that the number of networks projecting their links on the output map 
matches the number of unknowns. In the underconstrained case, the output 
pattern will simply be a set, comprising several solutions in general. If the 
number of constraints exceeds the number of unknowns, there might still be 
one or several solutions if the equations are consistent, otherwise the set of 
solutions is empty (null output pattern). 

Chapter 8 
Conclusion 
8.1 Recapitulation of key points 
8.1.1 Place coding 
In this book, two ways to represent and process information by analog 
circuits have been discussed. In both cases, information is encoded in the 
activation pattern on a map, i.e. the distribution of currents or voltages in an 
array of electrical nodes. 
Discrete place coding (Chap. 2) can be used to represent either single 
elements or subsets of a discrete set. With this coding scheme, the number 
of nodes in the map matches the number of elements in the set. An element 
is associated by convention to each node. The activation pattern 
representing a particular element is obtained by activating the node related 
to this element, and leaving all other nodes inactive. A subset is represented 
by activating all nodes related to elements which are enclosed in the subset. 
Continuous place coding (Chap. 3) can be used to represent numbers or 
vectors in a continuous range. Each node of the map is associated by 
convention to a preferred value picked in this range. The represented 
number or vector is the center of gravity of the activation pattern on the 
map, where the activation grade of each node is the weight of its preferred 
value. With continuous activation grades, the center of gravity can take any 
value within a bounded range, whatever the number of nodes in the map. 
With this coding scheme, map size determines accuracy and immunity to 
perturbations, but not resolution1• 
1 People with a background in optics might misinterpret this statement. "Resolution" 
designates the quantization step in the coding scheme. In this sense, resolution is infinite 
for analog and continuous place coding circuits. 
197 
O. Landolt, Place Coding in Analog VLSI
© Springer Science+Business Media Dordrecht 1998

198 
Place coding in analog VLSI 
8.1.2 Networks of links 
With both variations of place coding, computation can be carried out by 
the same mean, which is a network of links. In the simplest case (§2.4.1), a 
link is just a wire connecting a node of an input map to a node of an output 
map. In the case of several input or output maps, a link is a circuit cell 
combining the activities of one node of each input map and delivering the 
result to one node of each output map (§2.4.4). The construction of a 
network of links implementing a given function is ruled by a simple 
principle, expressed here in the case of a single input and output map: 
A pair of nodes of the input and the output map must be connected 
by a link if their preferred values are related by the function. 
In the discrete case, such a network implements the target function 
exactly. In the continuous case, a network of links is characterized by a 
continuous transfer function which interpolates the discrete pairs of 
preferred values embodied by the links (§3.3.2). This approximation of the 
target function can be satisfactory only if there are enough nodes in the 
maps, and if the input pattern is made of a sufficiently small spot of activity. 
The operating condition of a network of links with continuous place coding 
can be expressed as follows (§3.3.3): 
The spread of the input pattern must be small enough that the target 
function remains approximately linear over the pattern range. 
The definitions of pattern spread and pattern range can be found in 
§3.2.6. This operating condition expresses a trend, and not a hard boundary. 
Operation of the network degrades progressively in accuracy with increasing 
pattern spread. 
8.1.3 Properties 
The initial motivation for investigating place coding is that it enables a 
systematic synthesis of a wide variety of non-linear functions of possibly 
several variables. Provided that the target function is continuous, a network 
of links can approximate it with an accuracy limited only by map size, and 
the construction of such a network is straightforward. This property 
contrasts sharply with conventional analog circuit design, which is rather an 
"art" relying on skills which take long to learn. 

8. Conclusion 
199 
Continuous place coding has the additional property that the impact of 
many types of perturbations on the represented number or vector can be 
decreased to arbitrary limits by increasing map size. This statement applies 
to perturbations which affect only active nodes, but not to perturbations 
which make nodes influence the center of gravity while they should have a 
null weight. Fortunately, for current-mode implementations, the traditionally 
dominant perturbation sources are of this type (device mismatch, noise). A 
direct consequence of this property is that if the map is large enough, the 
signal-to-noise ratio (SNR) of currents representing activation grades can be 
substantially lower than the SNR of the represented number or vector. It can 
even be pushed to arbitrarily low levels by increasing map size. This fact 
implies that a given system SNR can in principle be achieved with less 
power than with a conventional analog representation. Thereby, the limiting 
factor of power consumption is no longer noise, but other factors such as 
speed, leakage currents or silicon area cost. 
8.1.4 Circuits 
Three integrated circuits applying the concepts summarized above have 
been designed, fabricated and successfully tested. 
1. A fuzzy rule circuit (Chap. 4) implements a single network of 80 links 
computing a function of two variables. The chip contains a set of 
membership function circuits and resources for the computation of a 
center of gravity, whereby the external signals appear as conventional 
analog quantities. The link circuit relies on a combination of MOS 
transistors exploited as controlled pseudo-conductances. It operates in 
current mode. 
2. An incremental control chip (Chap. 5) is made of two stages of networks 
totaling 512 links. It computes a non-linear function of three variables 
intended for the control of an oculo-motor system. The link circuit 
implementation is closely related to the current-mode circuit used for 
fuzzy rules. External inputs and outputs are represented by pulse 
frequency modulation. 
3. A saccade control chip (Chap. 6) intended for the same oculo-motor 
system is made of a single layer of about 1800 bidirectional links. It 
implements both a forward and a reverse mapping between a pair of two-
dimensional spaces. Activation grades are represented by pulse 
frequency modulation both internally and externally, and the network of 
links is implemented by communication channels multiplexed on a 
common bus ("virtual links"). Communication on this bus is based on a 
non-arbitrated event-driven scheme. 

200 
Place coding in analog VLSI 
8.2 Application domains 
The concepts and circuits introduced in this book contribute to simplify 
the design and possibly enhance performance of circuits carrying out analog 
computation. In this context, "computation" must be understood as an 
operation which alters the information content of the electrical 
representation, or relates representations of several different things. The 
place coding approach does not address signal conditioning problems, such 
as amplification, filtering or (de)modulation of a signal. The input of a 
network of links must be a clean activation pattern from the start, delivered 
by some suitable sensor array or conversion circuit. 
The general nature of the addressed problem implies the existence of a 
fairly broad spectrum of prospective applications. However, given the 
popularity of digital design techniques (especially microprocessor-based 
solutions), an alternative approach is likely to be applied only in such areas 
where it can bring a substantial improvement over existing solutions. A few 
potential application fields are listed in the following. 
-
Control and/or monitoring in battery-operated systems: As two of the 
described chips demonstrate (Chap. 5 and 6), networks of links can 
implement hard-wired models of non-linear systems for the purpose of 
control and/or monitoring (e.g. failure detection). Such a circuit can be 
expected to outperform a microprocessor-based circuit in terms of power 
consumption and/or circuit area, and would therefore lend itself to very 
power-critical applications such as implantable medical devices or other 
portable instruments. 
-
Functional blocks within perception systems: The similarity between 
place coding and the representation strategies found in biological neural 
networks (Sect. 8.3) is an obvious reason to apply place coding to the 
implementation of perception systems. In a few cases, sensory pathways 
in neural systems are even understood to a degree that they might be 
built, on the basis of data available in the neurobiological literature [13], 
with only a modest additional conceptual effort. 
-
Sensor arrays: One of the properties of continuous place coding is that a 
set of low-dynamic range electrical signals can encode a high-dynamic 
range variable (Sect. 3.4). This property could be exploited as a strategy 
to build sensors, by combining a number of cheap sensors tuned to 
different portions of the range, instead of a single high-performance 
device. If such a sensor array can be fabricated directly on a single 
substrate by micromachining techniques, then the whole array might cost 
even less than a single sophisticated device. 
The idea of place-coded sensor arrays is obvious in itself, but not 
frequently applied. Ideally, the individual sensors should be characterized by 

8. Conclusion 
201 
a membership function with a peak at the preferred value. If it is only 
possible to build sensors with a monotonic characteristic, then an electronic 
combination of the sensor outputs with their complement to the saturation 
value can be used to get a peaking characteristic. An example is the 
membership function circuit described in §4.4.2, which combines two 
complementary sigmoidal curves into a single membership function (Figure 
4.15). 
Some examples of sensor arrays can be found in the literature, whose 
operating principle reminds of place coding. For instance, the solar 
illumination monitoring chip described in [50] is a sun position sensor 
inherently based on place coding, even if it has originally been designed 
without this concept. This chip has an optical front-end built in such a way 
that the location of the brightest spot of light shining onto its surface 
encodes the position of the sun. The circuit needs only to transduce light 
into electric currents by an array of photodiodes to obtain an electrical 
place-coded representation of the sun location. This representation is 
subsequently converted into conventional analog coding by a center-of-
gravity computation circuit. Instead, it would have been possible to hardwire 
some function by a network of links taking directly the activation pattern as 
an input. Examples of micro-mechanical sensor arrays can also be found 
[51]-[53], whose principle can be understood in terms of place coding. 
There are additional reasons to advocate the development of place-coded 
sensors and actuators. In the chips described in Chap. 4 and 5, it is easy to 
see that conversion between place coding and a conventional analog or 
digital representation takes up a large part of the chip area and power 
consumption, while within the realm of place coding, the circuits are 
relatively efficient in both respects. Besides, it has been reminded already 
that the conventional analog representation is more limited in terms of 
dynamic range than place coding. For all these reasons, a computational 
system based on conventional analog sensors followed by conversion 
circuits will not fully exploit the potential of the place coding approach. 
Instead, it would be preferable to implement sensor arrays delivering 
directly a place-coded activation pattern. It is interesting to note that this 
approach has been taken by biological systems in many instances [54]. 
8.3 Biological relevance 
The concepts and circuits presented in this book have not been intended 
as a model of biological neural systems. Therefore, no serious attempt has 
been made to clarify to which extent this technical version of place coding 
matches computational paradigms found in nature. However, to avoid 
leaving this question completely unaddressed, a small list of features of 

202 
Place coding in analog VLSI 
artificial place-coded circuits which are fairly widespread in natural neural 
systems too is given in the following. 
1. Information is encoded as a pattern of activity in a population of cells. 
Each cell in such a population is broadly tuned to some preferred 
stimulus. The population is often organized in space in conformance 
with the topology of the represented quantity. Many examples can be 
found in the sensory pathways of the nervous system [54][13]. Other 
examples have been discovered in motor areas too [11]. 
2. The effective dynamic range available at the system level can widely 
exceed the capabilities of any single unit in the system. For instance, the 
frequency range supported by the human auditory system is much higher 
than the range of firing rates of any single neuron [55]. 
3. The number of cells devoted to represent a particular range of values 
grows with accuracy requirements. For instance, in the auditory cortex of 
the mustache bat, a disproportionately large area of the tonotopic map is 
devoted to frequencies around 61 KHz compared to the remaining of the 
frequency axis [6]. These bats tum out to emit sounds at about 61KHz 
for echolocation purposes. For navigation and hunting, they must be able 
to detect Doppler shifts between the emitted sound and its echo, which 
requires a high acuity. Another example is the large area devoted to lips 
and fingers in the human somatosensory cortex [6]. 
4. Computation relies on a dense network of interconnections. On a deeper 
level, at least one source [13] reports connection topologies (in the 
auditory pathway of the bam owl) which remind of the principle 
governing the construction of a network of links (§8.1.2). However, a 
more thorough study of literature would be necessary to find out whether 
this principle applies to some other neural structures too. 
5. In a more specific register, it is worth mentioning that more than once in 
the biological literature, the weighted sum (or center of gravity) of 
preferred values has been proposed as a model relating the pattern of 
activity on a map and the represented quantity. For instance, the 
weighted sum of the pattern in a population of motor cortical neurons of 
monkey has been found to match the direction and amplitude of a 
subsequent arm movement [56]. A similar model has been reported for 
eyeball saccades and the superior colliculus of monkey [57]. This can be 
related to the center-of-gravity operation which is the fundamental 
feature of continuous place coding (§3.2.2). 
There are also a number of differences between biological neural 
networks and electronic circuits based on place coding. Natural neural 
systems are adaptive, whereas networks of links are not. The latter are 
intended to address problems in which the target function is known from the 
start, remains constant over time, and can either be computed numerically or 

8. Conclusion 
203 
measured on a model. The topology of a network of links can be generated 
in one shot, instead of evolved by training. The shortcoming is of course that 
the network does not adapt to changing environments in this case. It might 
be possible to find ways to evolve or train a network of links, but this issue 
is not addressed by this book. 
Another important difference is that the class of problems addressed by 
circuit implementations of place coding is much simpler than the 
computational problems solved by most biological maps. In many cases, the 
latter process patterns which do not represent just a scalar or a low-
dimensional vector, but rather a continuous distribution. For instance, most 
sounds cannot be characterized by a single number, but rather by a spectrum 
over a continuous frequency range. Activation patterns on tonotopic maps in 
the auditory pathway are therefore more complex than a single spot of 
activity. Likewise, the pattern of activity on retina cones tuned to different 
ranges of wavelength encodes continuous light spectra, and not a single 
number. Similar observations apply to all other sensory modalities. The 
activation patterns on such maps could be called continuous place coding 
only for some particular types of stimulations, e.g. pure-tone sounds for 
audition, or monochromatic light for photoreceptors. 
The above list of similarities between place-coded circuits and neural 
systems makes it somewhat plausible that the former may capture some 
aspects of the mechanisms involved in natural computation. However, such 
a relationship, if any, remains to be demonstrated by hard facts. It is 
interesting to note that the networks of links discussed in this book are 
substantially different from most popular artificial neural network models 
[58]. These models have their own set of similarities and discrepancies with 
biological neural networks, and probably also capture some (other) aspects 
of natural computation. 

References 
[I] O. Landolt, Analog computation with place coding, Ph. D. thesis No. 1760, EPFL, 
Lausanne, 1998 
[2] 
P. Churchland, T. Sejnowski, The computational brain, MIT Press, Cambridge, 
Massachussets, 1993 
[3] 
E. Seevinck, "Companding current-mode integrator: a new circuit principle for 
continuous-time monolithic filters", Electronics Letters, Vol. 26, No. 24, November 
1990,pp.2046-2047 
[4] 
D. R. Frey, "Log-domain filtering: an approach to current-mode filtering", lEE 
proceedings-G, Vol. 140, No.6, December 1993, pp. 406-416 
[5] 
J.E. Dowling, The retina - an approachable part of the brain, Belknap Press, 
Cambridge MA, 1987 
[6] 
G. Shepherd, Neurobiology, 2nd ed., New York: Oxford University Press, 1988 
[7] 
C. Ghez, "Muscles: effectors of the motor systems", in: E. Kandel, J. Schwartz and T. 
Jessel (ed), Principles of Neural Science, 3rd ed., Prentice-Hall, 1991, pp. 548-563 
[8] 
D. H. Hubel, T. N. Wiesel, "Shape and arrangements of columns in cat's striate cortex", 
Journal of Physiology London, Vol. 165, 1963, pp. 559-568 
[9] 
D. H. Hubel, T. N. Wiesel, "Receptive fields and functional architecture of monkey 
striate cortex", Journal of Physiology, Vol. 195, 1968, pp. 215-243 
[10] T. D. Albright, "Direction and orientation selectivity of neurons in visual area MT of the 
macaque", Journal of Neurophysiology, Vol. 53,1984, pp. 43-49 
[II] D. L. Sparks, "Translation of sensory signals into commands for control of saccadic eye 
movements: role of primate superior colliculus", Physiological Reviews, Vol. 66, No. I, 
January 1986, pp. 118-171 
[12] E. Kandel, T. Jessel, "Touch", in: E. Kandel, J. Schwartz and T. Jessel (ed), Principles 
of Neural Science, 3rd ed., Prentice-Hall, 1991 
[13] E. I. Knudsen, S. du Lac, S. D. Esterly, "Computational maps in the brain", Ann. Rev. 
Neurosci., 10, 1987, pp. 41-65 
[14] S. W. Kuffler, J. G. Nicholls, A. R. Martin, From neuron to brain, 2nd ed., Sunderland, 
MA: Sinauer, 1984 
[15] D. H. Hubel, Eye, brain and vision, Scientific American Library, 1988 
[16] E. I. Knudsen, "Subdivisions of the inferior colliculus in the bam owl (TytoAlba)", 
Journal of Compo Neurol., Vol. 218, 1983, pp. 174-186 
[17] H. Wagner, T. T. Takahashi, M. Konishi, "Representation of interaural time difference 
in the central nucleus of the bam owl's inferior colliculus", Journal of Neuroscience, 
Vol. 7, No. 10, October 1987, pp. 3105-3116 
[18] C. Mead, Analog VLSI and Neural Systems, Addison Wesley, 1989 
[19] Commission romande de mathematiques, Fundamentum de mathimatiques (16)-
Notions elementaires, Editions du Tricorne, Geneva, 1982 
[20] L. A. Zadeh, "Fuzzy sets", Information and Control 8, 1965, pp. 338-353 
[21] H. J. Zimmermann, Fuzzy Sets Theory - and Its Applications, 2nd ed., Kluwer Academic 
Publishers, 1991 
[22] F. de Coulon, Thiorie et traitement des signaux, Traite d'Electricite vol. VI, Editions 
Georgi,1984 
[23] Y. Tsividis, Operation and modelling of the MOS transistor, McGraw-Hill, 1987 
205 

206 
Place coding in analog VLSI 
[24] C. Enz, F. Krummenacher, E. Vittoz, "An analytical MOS transistor model valid in all 
regions of operation and dedicated to low-voltage and low-current applications", Analog 
Integrated Circuits and Signal Processing, Vol. 8, No.1, 1995, pp. 83-114 
[25] E. Vittoz, "Future of analog in the VLSI environment", Proc. Int. Symposium on 
Circuits and Systems, 1990, pp. 1372-1375 
[26) E. Blumenkrantz, "The analog floating-point technique", Proc. IEEE Symp. Low-Power 
Electron., San Jose, October 1995, pp. 72-73 
[27] Y. Tsividis, "Externally linear, time-variant systems and their application to companding 
signal processors", IEEE Trans. Circ. and Syst. II, Vol. 44, No.2, February 1997, pp. 
65-85 
[28) T.O. Jackson, "Data input and output representations", in: E. Fiesler, R. Beale (ed), 
Handbook of neural computation, release 97/l, lOP Publishing and Oxford Univ. Press, 
1997 
[29) D.H. Ballard, "Interpolation coding: a represention for numbers in neural models", 
Biological Cybernetics, Vol. 57,1987, pp. 389-402 
[30) E. Vittoz, X. Arreguit, "Linear networks based on transistors", Electronics Letters, 
Vol. 29, No.3, February 1993, pp. 297-298 
[31) E. Vittoz, "Pseudo-resistive networks and their applications to analog collective 
computation", Proc. 6th Int. Conf. on Microelectronics for Neural Networks and Fuzzy 
Systems, Dresden, September 1997 
[32) J. Godjevac, A methodfor the design ofneuro-fuzzy controllers: an application in robot 
learning, Ph. D. thesis No 1602, EPFL, Lausanne, 1997 
[33] J. Millman, Microelectronics: digital and analog circuits and systems, McGraw-Hili, 
1979 
[34) T. Delbruck, '''Bump' circuits for computing similarity and dissimilarity of analog 
voltages", Proc. Int. Joint Conf. Neural Networks, Vol. I, 1991, pp. 1-475-479 
[35] E. Vittoz, G. Wegmann, "Dynamic current mirrors", in Analogue IC design: the current-
mode approach (ed. C. Toumazou, f.J. Lidgey, D.G. Haigh), Peter Peregrinus, London, 
1990,ch.7 
[36) P. Venier, "A contrast sensitive silicon retina based on conductance modulation in a 
diffusion network", Proc. 6th Int. Conf. on Microelectronics for Neural Networks and 
Fuzzy Systems, Dresden, September 1997 
[37] A. Mortara, Communication techniques for analog VLSI perceptive systems, Ph. D. 
thesis No. 1329, EPFL, Lausanne, 1995 
[38) A. Mortara, "A pulsed communication/computation framework for analog VLSI 
perceptive systems", Analog Integrated Circuits and Signal Processing, Vol. 13, No. 112, 
1997, pp. 93-101 
[39] A. Mortara, E. Vittoz, P. Venier, "A communication scheme for analog VLSI perceptive 
systems", IEEE Journal of Solid-State Circuits, Vol. 30, No.6, June 1995, pp. 660-669 
[40] P. Venier, A. Mortara, X. Arreguit, E. Vittoz, "An integrated cortical layer for 
orientation enhancement", IEEE Journal of Solid-State Circuits, Vol. 32, No.2, 
February 1997 
[41] A. Mortara, E. Vittoz, P. Heim, "Simple PFM demodulator to be used by analogue 
artificial neural networks which communicate through pulses", Electronics Letters, 
Vol. 29, No.4, February 1993, pp. 345-346 
[42] M. Mahowald, VLSI analogs of neuronal visual processing: a synthesis ofform and 
function, Ph. D. thesis, Caltech, Pasadena, 1992 
[43] K. Boahen, "Retinomorphic vision systems II: communication channel design", Proc. 
IEEE Int. Symp. Circuits and Systems, Atlanta, May 1996 

References 
207 
[44] T.G. Morris, "Analog VLSI circuits for covert attentional shifts", Proc. 5th Int. Conf. on 
Microelectronics for Neural Networks and Fuzzy Systems, Lausanne, February 1996, 
pp.30-37 
[45] P. Heim, B. Hochet, E. Vittoz, "Generation of learning neighbourhood in Kohonen 
feature map by means of simple nonlinear network", Electronics Letters, January 1991, 
Vol. 27, No 3, pp. 275-277 
[46] J. Lazzaro, S. Ryckebusch, M.A. Mahowald and C. Mead, "Winner-Take-All networks 
of order N complexity", Proc. 1988 IEEE conference on neural information processing -
natural and synthetic, Denver, 1988, pp. 703-711 
[47] S.P. De Weerth, T.G. Morris, "CMOS current-mode winner-take-all circuit with 
distributed hysteresis", Electronics Letters, Vol. 31, No. 13, 1995, pp. 1051-1053 
[48] R.I. Douglas, M.A. Mahowald, K.A.C. Martin, "Hybrid analog-digital architectures for 
neuromorphic systems", Proc. IEEE Conf. on Neural Networks, Orlando, June 1994, pp. 
1848-1853 
[49] J. Harris, Analog models for early vision, Ph. D. thesis, Caltech, Pasadena, 1991 
[50] P. Venier, O. Landolt, P. Debergh, X. Arreguit, "Analog CMOS photosensitive array for 
solar illumination monitoring", Proc. IEEE Int. Solid-State Circuits Conf., San 
Francisco, February 1996, pp. 96-98 
[51] D. Haronian, N.C. MacDonald, "A microelectromechanics-based frequency-signature 
sensor", Sensors and Actuators A, Vol. 53,1996, pp. 288-298 
[52] J. Noetzel, T. TfZlnnesen, W. Benecke, J. Binder, G. Mader, "Quasianalog accelerometer 
using microswitch array", Proc. 8th Int. Conf. Solid-State Sensors and Actuators, 
Stockholm, June 1995, pp. 671-674 
[53] W.E. Nelson, "Digital accelerometer", European patent application No. 0 567 938 AI, 
April 1993 
[54] J. H. Martin, "Coding and processing of sensory information", in: E. Kandel, J. 
Schwartz and T. Jessel (ed), Principles of Neural Science, Prentice-Hall, 1991, pp. 329-
340 
[55] J.P. Kelly, "Hearing", in: E. Kandel, J. Schwartz and T. Jessel (ed), Principles of Neural 
Science, Prentice-Hall, 1991, pp. 481-499 
[56] A.P. Georgopoulos, A.B. Schwartz, R.E. Kettner, "Neuronal population coding of 
movement direction", Science, Vol. 233, September 1986, pp. 1416-1419 
[57] J. Van Gisbergen, A. Van Opstal, A. Tax, "Collicular ensemble coding of saccades 
based on vector summation", Neuroscience, Vol. 21, No.2, 1987, pp. 541-555 
[58] E. Fiesler, R. Beale (ed), Handbook of neural computation, release 9711, lOP Publishing 
and Oxford Univ. Press, 1997 

Index 
Absolute difference 137 
Accuracy 40; 42; 133 
Activation 
grade 18; 33 
pattern 11; 18; 33 
pattern (binary) 17 
pattern (graded) 18; 29; 37 
perturbation 47 
state 18 
Activity 6; 33 
patternof7; 18 
Adaptation 7 
Adaptive 202 
Address 142 
Address-event 115; 120 
bus 140; 145 
Ambiguity 28; 192 
Amplifier 
cortical 184 
Analog 4 
circuit 4 
design 45 
representation 5 
AND 15 
gate 75; 79; 115; 131; 137; 189 
Angular difference 113; 115 
ANN See Artificial neural networks 
Application 200 
Arbitration 141 
Array 
209 
of cells 115 
of sensors 200 
Array cell 119 
Artificial neural networks 68; 203 
Associated 
value 18; 34 
vector 18 
Associative memory 184 
Attention 144 
Attractor 94 
cyclic 93 
Audition 203 
Band 
transfer 38 
Bandwidth 65; 102 
Bat 202 
Behavior 
dynamic 163 
Bias 91; 96 
Bi-directional 
bus 151 
link 139 
map 135 
network 135 
Bijection 20 
Binary relation 12; 19 
Bio-inspiration 9 
Biology 201 
Bump circuit 87 
Bus 145 

210 
address-event 140; 145 
bi-directional 151 
event-driven 140; 145 
motor 146 
transcei ver 151 
visual 146 
Cell 116 
link 147 
Center of gravity 32; 73; 76; 202 
Centroid 32 
Charge sharing 149 
Circuit 
analog 4 
bump 87 
digital 5 
log-domain 4 
membership function 87 
rule 73; 79; 89 
Code 
intermediate 30 
Coding 
discrete place 17 
interpolation 68 
labeled-line 7 
place 7; 11; 29; 31 
population 7; 8 
space 7 
vector 7 
Colliculus 
inferior 8 
superior 8 
Collision 141; 145 
Combination 21 
Communication 115; 120; 141 
Comparator 152 
Computation 3; 5; 202 
neura18 
Conditioning 
signa1200 
Conductance 
pseudo 83 
Conservative network 43 
Consistency 40 
Constraint 191; 192 
box 192 
solving 174; 190 
Consumption 57; 61; 97; 130; 157 
power 97 
Place coding in analog VLSI 
Continuous place coding 11; 18; 29; 31 ; 
197 
Control 200 
action 112 
problem 112 
Controller 
fuzzy 73 
Convergence 142; 145 
Convergent link 179 
Convergent network 43 
Conversion 74 
Converter 74 
current/frequency 123; 128 
digital/place coding 123; 130; 146; 
155; 157 
F/I 120; 127; 151 
frequency/current 120; 127; 151 
I/F 123; 128 
Coordinate 13 3 
head-centered 133 
retina 134 
Correlated signals 178 
Correspondence 167 
Cortex 202 
auditory 202 
Cortical amplifier 184 
Coupling 164 
CSEM94 
Cue 28 
Current 
pulse 152 
specific 81 
Current/frequency converter 123; 128 
Current-mode 48; 61 
Cyclic attractor 93 
0/ A converter 77 
Data fusion 191 
Default value 179 
Deflection 
central ray 107 
direction 108 
magnitude 108 
system 105 
Degree 
of interest 133; 135; 142 
of membership 13 
of saliency 133 
Delay 177 

Index 
Demonstration 94 
Density 
of samples 37; 42 
sampling 44 
Depth perception 28 
Destination set 12 
Difference 
absolute 137 
angular 113; 115 
Diffusion 156 
spatial 164 
Digita15 
circuit 5 
representation 5 
Direction 
of deflection 108 
of gaze 108; 133 
Discrete 
place coding 11; 17; 18; 193; 197 
set 18 
Discretization 36 
Discrimination 168 
Dissipation 57; 61; 97; 130; 157 
power 97 
Dissociation 22 
Distance 
travel 167 
Distribution of saliency 135 
Divergence 142; 145 
pattern 42; 180 
Divergent network 43 
Domain 186 
Duty cycle 159 
Dynamic behavior 163 
Dynamic range 201 
Dynamics 
non-linear 92 
Echolocation 202 
Equation 
solving 174 
system of 191 
Error 
scale 48; 51; 52 
Event-driven 115; 120 
bus 140; 145 
Excitatory 164 
Explicit 175 
Exploration 135 
saccadic 133 
Eye 105 
FII converter 120; 127; 151 
Failure 120 
detection 200 
Feature 
pattern 35 
Feedback 183; 186 
Feedforward 180; 186 
Firing rate 202 
Fixation time 158; 159; 163 
Flicker noise 56 
Frequency 
stimulation 159 
211 
Frequency/current converter 120; 127; 
151 
Function 12; 13 
membership 14; 32; 72; 175; 201 
of time 175 
static 173 
synthesis 36 
time 173 
transfer 37; 40; 98; 117; 125; 192 
Fusion 
data 191 
Fuzzy 
AND gate 75 
controller 73 
gate 115 
logic 15 
OR gate 76 
relation 16; 24; 42 
rule 71; 72 
set 13 
sets 12 
subset 13 
Gate 
AND 79; 115; 131; 137; 189 
AND (fuzzy) 75 
fuzzy 115 
OR (fuzzy) 76 
Gaze 
direction of 108; 133 
Generation 
saccade 161 
Grade 
activation 18; 33 

212 
Graded 
activation pattern 29; 37 
Graph 12 
Grating 106 
Gravity 
center of32 
Ground 
pseudo 83 
Head-centered coordinates 133 
Hit 163 
Hysteresis 174; 185 
Hysteretic relation 134; 185 
IIF converter 123; 128 
Image 12 
set 12; 16 
Implicit 176 
Inferior colliculus 8 
Inhibition-of-return 144 
Inhibitory 164 
Integrator 122; 142; 147; 148 
Interactive map 137 
Interconnection 34; 141; 202 
Interest 
degree of 133; 135; 142 
Intermediate code 30 
Interpolation 40 
coding 68 
linear 40 
Interpretation 28 
Intersection 14; 28 
Inversion 
strong 82 
weak 82; 83 
Label 72 
Labeled-line coding 7 
Lateral 
excitation 164 
inhibition 164 
Layout 34 
Learning 203 
Light deflection system 105 
Linear 
interpolation 40 
resistor 71; 83 
Link 11; 19; 23 
bi-directional 139 
Place coding in analog VLSI 
cell 147 
convergent 179 
network 19; 37; 74; 113; 181; 198 
virtual 140; 145 
weighted 25; 41; 45 
Locus 193 
Logarithmic sampling 46; 66 
Log-domain circuit 4; 66 
Logic 
fuzzy 15 
Logic analyzer 157 
Look-up table 26 
Loose pattern 36; 43; 174 
Magnitude of deflection 108 
Map 11; 18; 33; 113 
bi-directional 135 
motor 135 
scalar 18; 21 
size 35 
tonotopic 203 
topological 7; 19 
vector 18; 22 
visual 135 
Mapping 113; 119 
MAX 15 
Meaningless 179 
Measurement 96; 125; 156 
Membership 
degree of 13 
function 14; 32; 72; 175; 201 
function (circuit) 87 
Micrograph 85; 115; 144 
Micromachining 200 
Micro-mechanical sensor 201 
Micro-prism grating 106 
MIN 14; 15 
Mismatch 99; 169 
Mobile eye 105 
Monitoring 200 
Monostable 176 
MOS transistor 82 
Motion parallax 28 
Motor 
bus 146 
map 135 
Multiplication 77 
Neighbor 34 

Index 
Network 
bi-directional 135 
conservative 43 
convergent 43 
divergent 43 
neural 68 
oflinks 19; 37; 74; 113; 181; 198 
recurrent 183 
resistive 116; 156 
size 178 
sparse 174; 178 
Neural 
computation 202 
networks 68; 203 
Neurobiology 200 
Node 18; 33 
superfluous 19 
unused 178 
Noise 48; 54 
Ilf 56 
flicker 56 
shot 55 
Thermal 59 
Non-linear dynamics 92 
Normalization 76; 118; 182 
Ocu1o-motor system 105; 133 
Offset 48; 151 
random 49 
systematic 48 
Operating condition 40 
Operator 14 
AND 15; 75 
MAX 15 
MIN 14; 15 
OR 15; 76 
sum 137 
Optic tectum 8 
Optical system 105 
Optimization 168 
OR 15 
gate 76 
Orbit 100 
Oscillation 93 
Parallax 28 
Parallel 73 
Parameter 193 
Pattern 
activation 18; 33 
divergence 42; 180 
feature 35 
generator 156 
loose 36; 43; 174 
of activity 7; 18 
range 35; 41; 42 
sharpening 43; 174; 180 
size 36; 40 
spread 35; 41; 42; 47 
tight 36; 42; 43; 174 
Perception 28; 200 
depth 28 
visual 191 
Periodic 161 
Perturbation 
activation 47 
model 47 
source 47 
Photograph 85; 115; 144 
Pinch-off voltage 82 
Place coding 7 
continuous 11; 18; 29; 31; 197 
discrete 11; 17; 18; 193; 197 
Polar coordinates 109 
Population 202 
coding 7; 8 
Power 
consumption 57; 97; 130; 157 
dissipation 57; 130; 157 
spectral density 54; 56 
Preferred 
stimulus 7 
value 33 
Preimage 12 
Prism grating 106 
Prism orientation 133 
Procedure 
synthesis 92 
Projection 23 
Protocol 120 
PSD See Power spectral density 
Pseudo-conductance 83; 118 
controlled 83 
Pseudo-ground 83; 118 
Pseudo-voltage 83; 118 
Pulse 
current 152 
stream 115; 140 
213 

214 
Quantization 37; 40; 45 
suppression 41 
R12R ladder 77; 78; 79 
Random 
offset 49 
scale error 52 
Range 
pattern 35; 41; 42 
Rate 
sampling 37 
Receiver 142; 153 
Recruitment 7 
Recurrent network 183 
Reference 91 
Relation 12 
binary 12 
fuzzy 16; 24; 42 
hysteretic 134; 185 
synthesis 23; 24 
Representation 3 
analog 5 
digital 5 
neural 6 
place coding 7 
subset 17; 26; 35 
vector 32 
Resistive 
circuit 81 
network 116; 156 
Resistor 
linear 71 ; 83 
Retina 106; 133; 143; 191 
coordinates 134 
Routing 140 
Rule 
circuit 73; 79; 89 
fuzzy 71; 72 
Saccade 8; 133; 144; 158 
generation 161 
Saccadic exploration 133 
Saliency 133; 135; 143; 148; 164 
degree of 133 
distribution 135 
Sampling 37; 68 
density 40; 42; 44 
logarithmic 46; 66 
Place coding in analog VLSI 
rate 37 
uniform 46 
Scalar map 18; 21 
Scale error 48; 51; 52 
Scan 167 
Selector 186 
Self-excitation 183 
Sender 142 
Sensor 155 
array 200 
micro-mechanical 201 
Servo loop 137; 140 
Set 
destination 12 
discrete 18 
fuzzy 13 
image 12; 16 
source 12 
Settling time 156 
Sharpen 43 
Sharpening 
pattern 174; 180 
Shot noise 55 
Signal conditioning 200 
Simulation 117 
Sine wave 187 
Size 
map 35 
network 178 
pattern 36; 40 
spot 164 
S-norm 14 
Solar illumination 201 
Solving 
constraint 174; 190 
equation 174 
Source set 12 
Space coding 7 
Sparse network 174; 178 
Spatial diffusion 164 
Specific current 81 
Spot size 164 
Spread 
pattern 35; 41; 42; 47 
State 
acti vation 18 
State-space 92; 93; 100 
Static function 173 
Stereopsis 28 

Index 
Stimulation frequency 159 
Stimulus 
preferred 7 
Strong inversion 82 
Subset 35; 193 
representation 17; 26; 193 
Sum 142 
operator 137 
weighted 78; 80 
Superfluous node 19 
Superior colliculus 8 
Suppression of quantization 41 
Synthesis 
binary relation 19 
function 36 
non-linear dynamics 92 
procedure 92 
relation 23; 24 
System 
light deflection 105 
oculo-motor 105; 133 
of equations 191 
optical 105 
Systematic 
offset 48 
scale error 51 
Table look-up 26 
T-conorm 14 
Thermal noise 59 
Threshold 67; 152; 169 
Tight pattern 36; 42; 43; 174 
Time 
delay 177 
fixation 158; 159; 163 
function of 173; 175 
Time-sharing 135; 142 
T-norm 14 
Tonotopic map 203 
Topological map 7; 19 
Topology 34; 146 
Tracking 112 
Training 203 
Trajectory 94; 100 
Transfer 
band 38 
function 37; 40; 98; 117; 125; 192 
Transistor 82 
Transmitter 153 
Trap 94 
Travel distance 167 
Tuning curve 7 
Tuple 12 
Uniform sampling 46 
Union 14 
Unused node 178 
Value 
associated 18; 34 
default 179 
preferred 33 
Vector 
associated 18 
map 18; 22 
representation 32 
Vector coding 7 
Virtual link 140; 145 
Vision 28 
Visual 
bus 146 
map 135 
perception 191 
Voltage 
pinch-off 82 
pseudo 83 
Weak inversion 82; 83 
Weight 25; 45 
Weighted 
link 41 
sum 78; 80 
Winner-Take-All 138; 147; 150 
Wire 20 
WTA See Winner-take-all 
215 

