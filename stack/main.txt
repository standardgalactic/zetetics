Diss. ETH No. 24584
Bayesian Uncertainty Quantiﬁcation
for Data-Driven Applications in
Engineering and Life Sciences
A thesis submitted to attain degree of
DOCTOR OF SCIENCES of ETH ZURICH
(Dr. sc. ETH Zurich)
presented by
LINA KULAKOVA
Specialist in Mathematics, Lomonosov Moscow State University
born on December 1, 1990
citizen of Russia
accepted on the recommendation of
Prof. Dr. Petros Koumoutsakos, examiner
Prof. Dr. Costas Papadimitriou, co-examiner
2017


Abstract
The world is quickly moving towards using computer modeling and simulations in
various branches of science and engineering.
The computational methods found
their way to biology, chemistry, physics, social sciences and many other ﬁelds.
Simulations allow the researchers to study phenomena which can not be directly
observed in the experiments.
In order to be trustworthy, the simulations must
go through a thorough process of data-driven validation.
Often, an adjustment
of the free parameters of the computational model is required for it to match the
experimental observations.
One of the possibilities to ﬁnd the right model parameters is an optimization with
respect to the quantities of interest which one wishes to reproduce in the simulation.
The amount of information which can be extracted from this deterministic approach
is, however, very limited. The parameters sensitivity or their mutual correlations,
which are crucial for making robust predictions, are not available in this approach.
The solution to this problem lies in the area of probability, speciﬁcally in the
Bayesian methodology. The value of the Bayesian approach in the modern com-
putational science can hardly be overestimated. It updates the prior beliefs about
the model parameters, expressed in the form of a probability distribution, using the
available experimental data. This approach takes into account all the uncertainties
arising in the inference process: the experimental, the modeling and the simulation
ones, thus providing a reliable result. Blending together the simulation and the ex-
periment outcomes, it constructs a conditional distribution of the model parameters
given the observational data. From this distribution, one can extract the uncertainty
bounds, the correlations, the sensitivities etc. for each of the parameters, as well as
for any quantity of interest which can be computed using the calibrated model.
All these useful features, however, come with a price of an excessive computa-
iii

tional cost, since the Bayesian inference requires a large number of model evalua-
tions to construct the parameters distribution. There exist two main approaches
to deal with the high cost issue while keeping the simulation itself untouched. The
ﬁrst option is to use a cheap replacement of the simulation – a surrogate model –
constructed via interpolation or similar methods. The second (non-exclusive) pos-
sibility is to apply high performance computing techniques to eﬃciently exploit the
available hardware architectures and reduce the time to solution.
Both options require a ﬂexible and robust computational platform. A framework
Π4U, which meets both requirements, was recently developed in our lab.
Π4U
contains state of the art high performance computing implementations of algorithms
for optimization, Bayesian uncertainty quantiﬁcation and propagation.
In this thesis, we extend the Π4U framework to include the lacking inference
tools, such as an algorithm for the approximate Bayesian inference, surrogate mod-
els, visualization tools and a sensitivity tool.
We then use the extended frame-
work to perform the Bayesian uncertainty quantiﬁcation and propagation in ﬁne-
and coarse-grained molecular dynamics and dissipative particle dynamics. The sys-
tematic Bayesian approach allows us to enhance the predictive capabilities of the
particle-based models and gain new insights into the century-old force-ﬁelds.
iv

R´esum´e
Le monde se bouget rapidement `a l’utilisation de la mod´elisation d’ordinateur et des
simulation automatis´ee dans diverses branches de la science et de l’ing´enierie. Les
m´ethodes de calcul ont trouv´e leur chemin vers la biologie, la chimie, la physique,
les sciences sociales et vers des nombreux autres domaines.
Les simulations permettent aux chercheurs d’´etudier des ph´enom`enes qui ne peu-
vent pas ˆetre observ´es directement dans les exp´eriences. Pour ˆetre ﬁable, les simula-
tions doivent passer par un processus fastidieux, ax´e sur les donn´ees, de validation.
Un ajustement des param`etres libres du mod`ele de calcul est souvent n´ecessaire
pour qu’il corresponde aux donn´ees d’observation. Le processus de validation est
un jeu interactif de donn´ees et de mod`eles: apr`es s’assurer que le mod`ele reproduit
bien les ph´enom`enes qui peuvent ˆetre mesur´es exp´erimentalement, on peut l’utiliser
pour pr´edire de nouvelles quantit´es et eﬀets.
Une des possibilit´es pour trouver les bons param`etres de mod`ele est une opti-
misation avec en ce qui concerne les quantit´es d’int`erˆet. La quantit`e d’information
qui peut ˆetre d´eriv´ee de cette approche d´eterministe est, cependant, tr`es limit´e. La
sensibilit´e des param`etres ou leurs corr´elations mutuelles, qui sont cruciales pour
faire des pr´edictions robustes, ne sont pas disponibles dans cette approche.
La solution `a ce probl`eme r´eside dans le domaine de la probabilit´e, en parti-
culier dans le m´ethodologie bay´esienne. La valeur de l’approche bay´esienne dans
la science computationnelle moderne peut diﬃcilement ˆetre surestim´ee. Elle met `a
jour les croyances ant´erieures sur les param`etres du mod`ele, exprim´es sous la forme
d’une distribution de probabilit´e, en utilisant des donn´ees exp´erimentales. Cette ap-
proche prend en compte toutes les incertitudes d´ecoulant du processus d’inf´erence:
l’exp´erimental, la mod´elisation et la simulation ceux, fournissant ainsi un r´esultat
ﬁable. En m´elangeant la simulation et les r´esultats de l’exp´erience, elle construit
v

une distribution conditionnelle des param`etres du mod`ele. A partir de cette dis-
tribution, on peut extraire l’incertitude limites, les corr´elations, les sensibilit´es etc.
pour chacun des param`etres, ainsi que pour chaque quantit d’int´erˆet qui peut ˆetre
calcul´ee en utilisant le mod`ele calibr´e.
Cependant, toutes ces caract´eristiques utiles ont un coˆut de calcul excessif, car
l’inf´erence bay´esienne n´ecessite un grand nombre d’´evaluations de mod`ele, pour
construire la distribution des param`etres. Il existe deux approches principales pour
faire face `a la question de coˆut ´elev´e, en gardant la simulation elle-mˆeme intacte.
Le premi`ere option est `a utiliser un remplacement bon march´e de la simulation – un
mod`ele de substitution – construit par interpolation ou par des m´ethodes similaires.
La deuxi`eme possibilit´e (non exclusive) est d’exploiter eﬃcacement architectures
mat´erielles disponibles et r´eduire le temps de solution.
Les deux options n´ecessitent une plateforme de calcul ﬂexible et robuste. Un
cadre Π4U, qui r´epond aux deux exigences, a ´et´e r´ecemment d´evelopp´e dans notre
laboratoire. Π4U contient des impl´ementations informatiques hautes performances
d’algorithmes pour l’optimisation, la quantiﬁcation et la propagation des incerti-
tudes bay´esiennes. Dans cette th`ese, nous ´etendons le cadre Π4U pour inclure des
outils d’inf´erence manquantes, tels qu’un algorithme pour l’inf´erence bay´esienne ap-
proximative, des mod`eles de substitution, des outils de visualisation et un outil de
sensibilit´e. Nous utilisons ensuite le cadre ´etendu pour eﬀectuer la quantiﬁcation
et la propagation de l’incertitude bay´esienne dans la dynamique mol´eculaire et la
dynamique des particules dissipatives.
L’approche syst´ematique bay´esienne nous
permet d’am´eliorer les capacit´es pr´edictives des mod`eles `a base de particules de tae
et d’acqu´erir de nouvelles connaissances sur les champs de force tr`es vieux.
vi

Acknowledgments
I wish to thank my supervisor, Petros Koumoutsakos, for the inspirational ideas
he shared with me and the possibility to work in a place full of amazing people,
with an atmosphere which was always encouraging me to pursue my scientiﬁc goals.
I would also like to thank my co-supervisor, Costas Papadimitriou, for providing
great advice throughout my PhD studies.
Special thanks to Sergey, for all the cool and enlightening discussions on science,
programming, philosophy and many other topics.
I am also thankful to all of the lab members, present ans past, for their passion
to computational science, which was always a source of inspiration for me. I am
especially thankful to Panos A. and Panos H. as they endorsed my interest in the
Bayesian statistics and High Performance Computing which eventually became the
main theme of this thesis.
I wish to thank my friends Pesho, Yury, Diana and Olek for their moral support
during my academic journey. I am also grateful to Chakri and Athena for brightening
up the days in the lab.
I thank all my tango friends for the great joy of dancing they shared with me.
I am endlessly grateful to my parents and the whole family for their unconditional
trust and support.
vii


Notations
Abbreviations
ABC
Approximate Bayesian Computation
ABC-SubSim
Approximate Bayesian Computation Subset Simulation
BASIS
Bayesian Annealed Sequential Importance Sampling
BMU
Bayesian Model Updating
CG
Coarse-Grained
CMA-ES
Covariance Matrix Adaptation – Evolution Strategy
CSE
Computational Science and Engineering
CoV
Coeﬃcient of Variation
DEM
Discrete Element Method
DPD
Dissipative Particle Dynamics
ELM
Extreme Learning Machine
FD
Force-Displacement
HB
Hierarchical Bayesian
LJ
Lennard-Jones
MCMC
Markov Chain Monte Carlo
MD
Molecular Dynamics
MH
Metropolis-Hastings
MLP
Multi-Layer Perceptron
MPI
Message-Passing Interface
NC
Nascent (protein) Chain
NN
Neural Network
PDF
Probability Density Function
PMF
Potential Mean Force
QoI
Quantity of Interest
ix

RDF
Radial Distribution Function
SubSim
Subset Simulation
TMCMC
Transitional Markov Chain Monte Carlo
TTF
Tank-Treading Frequency
UQ
Uncertainty Quantiﬁcation
UQ+P
Uncertainty Quantiﬁcation and Propagation
Assumptions
All the probability distributions have PDFs.
Conventions
We denote scalars with small regular letters, vectors with small bold letters,
matrices with capital bold letters.
The length of the vector v is denoted as v.
Each of the sample plots is created in the same way. Diagonal: histograms of
marginal distributions of parameters. Above the diagonal: projection of posterior
samples on all pairs of 2-d parameter spaces colored by discrepancy/log-likelihood.
Below the diagonal: 2-d probability densities constructed via a bivariate kernel
estimate.
Common symbols
ϑ
vector of stochastic model parameters
ψ
vector of stochastic model hyper-parameters
P(·)
probability
p(·)
PDF
x

Contents
1
Introduction
1
1.1
Bayesian Uncertainty Quantiﬁcation and Its Challenges
. . . . . . .
4
1.2
Large-Scale Models and High Performance Computing . . . . . . . .
6
1.3
This Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
I
Theory
11
2
Bayesian Inference
13
2.1
Parameters Calibration
. . . . . . . . . . . . . . . . . . . . . . . . .
14
2.2
Stochastic Model Selection . . . . . . . . . . . . . . . . . . . . . . . .
15
2.3
Forward Uncertainty Propagation . . . . . . . . . . . . . . . . . . . .
15
2.4
Algorithms
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
3
Approximate Bayesian Inference
19
3.1
Parameters Calibration
. . . . . . . . . . . . . . . . . . . . . . . . .
19
3.2
Stochastic Model Selection . . . . . . . . . . . . . . . . . . . . . . . .
20
3.3
Forward Uncertainty Propagation . . . . . . . . . . . . . . . . . . . .
20
3.4
Algorithms
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
4
Hierarchical Bayesian Inference
25
4.1
Parameters Calibration
. . . . . . . . . . . . . . . . . . . . . . . . .
26
4.2
Stochastic Model Selection . . . . . . . . . . . . . . . . . . . . . . . .
29
4.3
Forward Uncertainty Propagation . . . . . . . . . . . . . . . . . . . .
29
4.3.1
Propagation for the same QoI . . . . . . . . . . . . . . . . . .
29
xi

4.3.2
Propagation for a new QoI
. . . . . . . . . . . . . . . . . . .
30
4.4
Algorithms
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
5
Implementation
33
5.1
Π4U Framework
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
5.2
Structure of Π4U algorithms
. . . . . . . . . . . . . . . . . . . . . .
35
5.3
Improving MH Sampling . . . . . . . . . . . . . . . . . . . . . . . . .
38
5.4
Surrogates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
5.4.1
Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
5.4.2
Surrogates with Bayesian inference algorithms
. . . . . . . .
41
5.4.3
Available surrogates in Π4U . . . . . . . . . . . . . . . . . . .
43
5.5
HPC Aspects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
5.5.1
ABC-SubSim . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
5.5.2
Surrogates . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
5.6
Clusters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
II
Applications
49
6
Helium Modeling
51
6.1
Parameters Calibration
. . . . . . . . . . . . . . . . . . . . . . . . .
52
6.2
Discrepancy Model Selection
. . . . . . . . . . . . . . . . . . . . . .
56
6.3
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
7
Argon Modeling
59
7.1
Computational Model Description
. . . . . . . . . . . . . . . . . . .
60
7.2
Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
7.3
Parameters Calibration
. . . . . . . . . . . . . . . . . . . . . . . . .
62
7.3.1
Calibration of LJ 6-12 . . . . . . . . . . . . . . . . . . . . . .
62
7.3.2
Calibration of LJ 6-p . . . . . . . . . . . . . . . . . . . . . . .
65
7.3.3
Comparison of LJ 6-12 and LJ 6-p . . . . . . . . . . . . . . .
69
7.4
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
8
Translocon Modeling
77
8.1
Computational Model
. . . . . . . . . . . . . . . . . . . . . . . . . .
77
8.2
Parameters Calibration
. . . . . . . . . . . . . . . . . . . . . . . . .
78
xii

8.3
Forward Uncertainty Propagation . . . . . . . . . . . . . . . . . . . .
83
8.4
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
9
Blood Modeling
87
9.1
Computational Model
. . . . . . . . . . . . . . . . . . . . . . . . . .
87
9.1.1
Solvent
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
9.1.2
RBC model . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
9.1.3
Simulation Setup . . . . . . . . . . . . . . . . . . . . . . . . .
92
9.2
RBC Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
9.3
Red Blood Cell Stretching . . . . . . . . . . . . . . . . . . . . . . . .
92
9.3.1
Parameters Calibration
. . . . . . . . . . . . . . . . . . . . .
94
9.3.2
Forward Uncertainty Propagation
. . . . . . . . . . . . . . .
98
9.4
Red Blood Cell in Shear Flow . . . . . . . . . . . . . . . . . . . . . .
99
9.4.1
Parameter Calibration . . . . . . . . . . . . . . . . . . . . . .
100
9.4.2
Forward Uncertainty Propagation
. . . . . . . . . . . . . . .
103
9.5
High performance computing
. . . . . . . . . . . . . . . . . . . . . .
106
III
Conclusions and Outlook
109
10 Conclusions and Outlook
111
10.1 Π4U Framework
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
111
10.2 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
112
Appendix
119
A ABC for Likelihood-Driven Bayesian Inference
119
A.1 Computational Model
. . . . . . . . . . . . . . . . . . . . . . . . . .
119
A.2 Parameter Calibration . . . . . . . . . . . . . . . . . . . . . . . . . .
121
B RBC Parameters Sensitivity
125
C Argon LJ Parameters
127
C.1
Hyper-parameter models for hierarchical inference
. . . . . . . . . .
127
C.2
Posterior PDFs for LJ 6-12 and LJ 6-p . . . . . . . . . . . . . . . . .
129
xiii

D LAMMPS Scripts for the MD Simulations
137
D.1 Helium . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
137
D.2 Argon . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
139
xiv

Chapter 1
Introduction
Computational science is a rapidly growing multidisciplinary ﬁeld. It deals with
complex physical problems using advanced computing techniques. In the core of
this area of science lies the development of computational models and computer
simulations techniques to understand natural systems by making their complexity
tractable.
Here and further, the computational model is a representation of the
mathematical description of a given system in a computer (see Fig. 1.1).
One of the sub-branches of the computational science is computational science
and engineering (CSE), a relatively new discipline that aims at developing and ap-
plying computational models and simulations representing physical reality of engi-
neering and life sciences. The development process is often coupled with the usage
of high performance computing, which allows to simulate large and complex sys-
tems. CSE is nowadays the third method of the scientiﬁc discovery, together with
the theory and the experiments. Computer simulations provides the capability to
obtain results and observe processes that are either inaccessible in the experiments
or exhibit an extremely high ﬁnancial cost. Its importance in many ﬁelds of study
can hardly be overestimated, while constant progress in the hardware technologies
and software algorithms makes the computer simulations spread wider every day.
The way the computational models are constructed, however, allows for a num-
ber of uncertainties, such as the modeling, the experimental, the parameter and the
numerical ones (see Fig. 1.1). The modeling uncertainty accounts for our imper-
fect understanding of the physical laws, meaning that the equations we use may
1

2
 
 
Physical reality
Predicted value
and uncertainty
Experimental
data
Mathematical
model
Computational
model
Computational
model
parameters
experimental errors
modeling errors
numerical errors
parameter errors
VALIDATION
VERIFICATION
CALIBRATION
Figure 1.1: Schematic representation of the inference process. Red arrows show the
origins of errors. Blue dashed arrows show the information and errors ﬂow.

3
not account for certain eﬀects, making the model simpler, but less accurate. The
experimental uncertainty is arising in the process of data collection during experi-
mental studies. It appears due to the ﬁnite precision of the measurement devices or
due to some uncontrollable environmental conditions. The parameter uncertainty
is attributed to those parameters of the computational model which are not known
exactly, an example being material properties or the local free-fall acceleration. Fi-
nally, the numerical uncertainty appears when the physical laws are translated into
a computer.
An example of this kind of uncertainty is the discretization of the
partial diﬀerential equations or numerical integration.
Uncertainties can be classiﬁed into two categories: aleatoric and epistemic un-
certainty. Aleatoric, or statistical, uncertainty corresponds to unknowns that diﬀer
each time the experiment is run. An example of such an uncertainty is the uncer-
tainty in the ﬁnal position of an arrow shot with a mechanical bow. Each time we
shoot the same arrow with the exactly same initial conditions: the same accelera-
tion, altitude, direction. However, the random vibrations of the arrow shaft prevent
it from hitting the same point in the end of its ﬂights. These vibrations cannot
be determined suﬃciently accurately to eliminate the resulting uncertainty in the
ﬁnal arrow position. It should be noticed that the speculations above rely on the
ﬁnite precision of the modern measurement devices, and the current inability to
eliminate the uncertainty in the arrow vibrations does not prove the existence of
the uncertainty which cannot be eliminated with good enough measurements. The
other type of uncertainty is epistemic, or systematic, uncertainty. It appears due to
properties which could be learned, but are unknown in practice. An example of the
situation when such an uncertainty is present is a simulation with a model which
neglects certain eﬀects, such as measuring the acceleration of gravity without taking
into account the air resistance.
The majority of applications contain both types of uncertainties.
Reduction
in the epistemic uncertainty can be achieved by gaining a better understanding
of the system, process or mechanism. The uncertainty quantiﬁcation (UQ) aims
at reducing epistemic uncertainties to the aleatoric ones, which can be treated by
statistical tools. The present work focuses on the Bayesian approach to quantifying
the uncertainties.

4
1.1
Bayesian Uncertainty Quantiﬁcation and Its Challenges
Bayesian Uncertainty Quantiﬁcation (UQ) is a method of statistical inference. Here,
“inference” is the process of deducing properties of the probability distribution of the
parameters ϑ of a computational model M by analysis of the available experimental
data d. Bayesian UQ uses Bayes’ theorem to update beliefs about the underlying
parameter distribution in the presence of new information:
p(ϑ | d, M) = p(d | ϑ, M) p(ϑ | M)
p(d | M)
.
(1.1)
The term on the left is called “posterior distribution”. It describes the updated
beliefs about the parameter distribution after observing the data. The Bayes’ theo-
rem states that, in order to compute the posterior distribution, one should “reweigh”
the prior beliefs p(ϑ | M) with the likelihood p(d | ϑ, M). The prior distribution
summarizes all the information available to the researcher before observing any data.
This information usually includes expert opinions or physical constraints. The like-
lihood, on the other hand, speciﬁes the probability of observing the experimental
data d given a set of parameters ϑ. The likelihood incorporates the assumptions
made about the data collection process and the feasibility of the model, such as:
what kind of uncertainties were present in the experiment and simulation or how
well does the model with the best parameters ﬁt the data. The choice of the prior
and the formulation of the likelihood is discussed in detail in Part I.
The last term of the Bayes’ theorem is the denominator on the right hand side.
This term is called “model evidence” and is computed as a normalisation constant:
p(d | M) =
Z
p(d | ϑ, M) p(ϑ | M) dϑ .
(1.2)
The model evidence is used to select the most probable model M among the com-
peting ones.
The Bayes’ theorem was ﬁrst stated by Thomas Bayes (1701-1761) in 1763 in
his treatise “An Essay towards solving a Problem in the Doctrine of Chances”. The
modern formulation of the Bayes rule appeared in 1812 in “Th´eorie analytique des
probabilit´es” of Pierre-Simon Laplace.
Although the theorem was formulated a long time ago, it is only recently, after
almost 200 years, that it is gaining an attention of numerous scientists and engineers.
The reason for that lies in the model evidence.

1.1. Bayesian Uncertainty Quantiﬁcation and Its Challenges
5
As was discussed above, the evidence is computed as an integral over the param-
eter space. The dimensionality of this space depends on the problem and in general
can be quite high. Integration in high-dimensional spaces is a challenging problem,
since the quadrature schemes need a large number of points to work with a suﬃcient
accuracy. Although there exist methods, which avoid the curse of dimensionality,
such as techniques of the Monte Carlo family [73], they still require a signiﬁcant
amount of points to converge.
A solution is oﬀered by the Markov Chain Monte Carlo (MCMC) method [53, 49].
It is able to sample probability distributions known up to a normalizing constant,
which is precisely the case in the Bayesian inference. The advantage of this method,
as compared to the integration approach, is that it only focuses on the area of
non-zero probability, thus not wasting precious points.
However, MCMC method is also not able to completely eliminate the problem of
high computational cost associated with the Bayesian inference. Each point in the
parameter space used by the MCMC algorithm required evaluating the likelihood,
which can be an expensive computation by itself, an example being a full molecular
dynamics simulation. The ways of eliminating the high computational cost of the
Bayesian inference are discussed in Chapter 5.
Another problem with the MCMC method arises in case of complex posterior
distributions: multi-modal, peaked or the ones with unidentiﬁable manifolds. The
algorithm in this case can get trapped in one of the peaks or fail to sample the
whole manifold. Hence, the modern MCMC-based sampling algorithms went quite
far away from the original version [22, 16], focusing on various population-based
annealing schemes [29, 26, 23].
Nevertheless, none of the algorithms acts perfectly in each situation, and the
researchers try to target diﬀerent sampling problems separately. One part of the
research addresses the sampling of the complex PDFs [21], including multi-modal
distributions [90, 108], cases with unidentiﬁable manifolds [14, 74], high-dimensional
distributions [24, 120]. Another part of the research is concentrated on developing
algorithms for special types of models (e.g. stochastic models [115, 13, 104, 124])
and data (e.g. multiple data sets [110, 75, 54, 129]).
The state-of-the-art algorithms for Bayesian inference will be further discussed
in Chapter 2.
Even more diﬃculties arise when one starts challenging the assumptions of the

6
classical Bayesian inference. For example, what happens if the model under consid-
eration is stochastic? Or what is a meaningful way of using several diﬀerent datasets
in one calibration? The answers to these and other questions will be discussed in
Part I.
1.2
Large-Scale Models and High Performance Computing
An increasing number of areas are now using computer-aided modeling. The soft-
ware serves diﬀerent purposes and runs on various architectures. The simulations
are written in virtually all the existing programming languages. The hardware ar-
chitectures also vary: single-core and multi-core CPUs, GPUs, and hybrid clusters.
The parallelisation and communication methods are numerous: Message Passing
Interface (MPI), CUDA, OpenMP, POSIX threads, and many libraries.
In such a complex world, it becomes a necessity to have a uniﬁed framework
for Bayesian inference. A non-exhaustive list of options includes packages devel-
oped for a speciﬁc ﬁeld: BEAST [34], BAli-Phy [114], DIYABC [27] – phylogeny,
BioBayes [122] – systems biology, MultiNest [44] – cosmology, BayesSDT [81] – sig-
nal detection theory, and general purpose packages: MCMCpack [87], Stan [51],
BUGS [89], NIMBLE [28].
The special purpose packages lack generality, and the mentioned general purpose
packages target computationally inexpensive models (running up to several minutes
on one CPU) and are not suitable for heavy parallel computations. That is why we
use a general-purpose High Performance Computing (HPC) framework Π4U [60, 59],
which meets both requirements. This framework can be compiled and run on any
architecture from a laptop to a hybrid-cluster in a platform-agnostic way. With a
help of task-based parallel library TORC [58], Π4U performs job scheduling and
adaptive load balancing. A transparent C-based interface allows the user to call any
kind of a simulation engine on any architecture.
In this thesis we shall give examples of using Π4U coupled with LAMMPS [1, 93]
simulation which uses MPI parallelisation and a single-core python script.
The
applications which are studied in this thesis run up to several hours on 8 CPUs
(argon simulations) or 2 hours on a GPU (blood cells simulations).

1.3. This Thesis
7
1.3
This Thesis
Throughout this thesis we present a consistent approach to Bayesian inference for
various large-scale models. We discuss both the algorithmic and the implementation
challenges and present ways to address them.
This thesis contains two main achievements.
The ﬁrst one is extending our
in-house open-source high performance computing framework Π4U with sampling
algorithms for approximate Bayesian computations, surrogate models and additional
auxiliary tools.
The second one is enhancing the predictive capabilities of four
particle-based computational models from engineering and life sciences with the
help of Π4U.
This thesis consists of three main parts, brieﬂy introduced here.
Part I: Theory
In this part, we present the general Bayesian inference theory and its implemen-
tation inside the Π4U library. We consider the Bayesian Model Updating (BMU),
the Approximate Bayesian Computation (ABC) and the Hierarchical Bayesian (HB)
inference. For each of these cases we present the necessary background for the pa-
rameter calibration, model selection and forward uncertainty propagation, including
the algorithms needed for each of the inferences. We then present an overview of
Π4U, which incorporates all the algorithms needed for the Bayesian inference. We
continue by discussing methods for improving sampling and reducing the compu-
tational cost of the Bayesian inference. This is when the surrogate models come
into play. After giving a general context of the surrogate usage within the Bayesian
inference, we demonstrate two types of surrogate models recently added to the Π4U
framework: Gaussian process-based and neural network-based. Finally, we give the
speciﬁcations of the computational platforms used in the calculations throughout
this thesis.
Part II: Applications
This part gives a description of the four particle-based models from life sciences
and engineering, which we improved using various types of the Bayesian inference.
The models are the following: molecular dynamics simulations of helium and argon,

8
coarse-grained modeling of proteins integration/translocation into a cell membrane,
dissipative particle dynamics simulations of a red blood cell.
Helium Modeling
This chapter addresses a problem of calibrating MD force-
ﬁelds using stochastic quantities with non-Gaussian ﬂuctuations as data. We infer
the Lennard-Jones (LJ) potential well depth and the well location parameters for
helium using the data on Boltzmann factor distribution over time. It is known from
the statistical physics, that the Boltzmann factor exhibits non-Gaussian ﬂuctuations,
therefore we are not able to formulate the likelihood, and we instead apply the ABC.
Using three diﬀerent functions describing the discrepancy between the data and the
simulation outcome, we conclude that the mean and variance-based discrepancy,
which mimics the likelihood-driven Bayesian inference, is not able to reduce the prior
uncertainty in the LJ parameters. In accordance with the work of Shell [109], we
observe that for the MD quantities of interest with unknown ﬂuctuations, a natural
choice of the discrepancy measure is the relative entropy. The result of this chapter
is thus an approach to MD calibrations using data with arbitrary ﬂuctuations: we
suggest applying ABC with relative entropy as discrepancy function.
Argon Modeling
In this chapter, we focus on identifying parameters of an MD
force-ﬁeld using many sets of data.
This time we choose argon as a target and
consider data on its Radial Distribution Function (RDF) for six diﬀerent thermody-
namic conditions. We use a modiﬁed LJ 6-p potential and infer its well depth and
well location parameters, as well as the repulsion exponent p. This modiﬁcation is
inspired by the fact that, unlike the value 6 for the attraction exponent, the power
12 for the repulsive term has no theoretical justiﬁcation. Following the methodol-
ogy from Ref. [129], we apply the Hierarchical Bayesian (HB) techniques to treat
the distinct datasets appropriately. Our results demonstrate that the adjusted re-
pulsive exponent of 6.5 improves the prediction of the RDF, density and diﬀusion
coeﬃcient for liquid argon and saturated argon vapour. At the same time, we show
that the diﬀerent thermodynamic states, such as liquid, saturated vapour or gas,
should be simulated with diﬀerent parameters. The result of this chapter is thus
the improvement of the LJ potential for argon with the use of the HB inference.
Translocon Modeling
This chapter contains an example of a Bayesian inference
in a relatively high-dimensional parameter space.
We calibrate a coarse-grained

1.3. This Thesis
9
model of a transmembrane channel, called “translocon”. The model describes the
process of protein translation by a ribosome and its further movement through the
translocon. There are four model parameters describing two diﬀerent LJ integrations
and ﬁve geometrical parameters.
Due to a relatively high dimensionality of the
problem, we develop a sequence of structural model which assess diﬀerent sets of
the translocon parameters. Using Bayesian model selection, we choose the most
plausible structural model.
With this model, we predict the probability for the
newly produced protein to be integrated into the cell membrane (versus it being
translocated inside the cell). The translocon model with the calibrated parameters
shows a considerably better agreement with the experiments.
The result of this
chapter is a demonstration of an approach to calibrating models with a number of
parameters challenging for the Bayesian inference. With this approach, we have
signiﬁcantly improved the coarse-grained translocon model from Ref. [91].
Red Blood Cell Modeling
In this chapter, an inference based purely on sur-
rogates constructed oﬀ-line is considered. We calibrate a coarse-grained dissipative
particle dynamics-based model of red blood cell from Ref. [97]. We employ exper-
imental data on the cell behavior when stretched with optical tweezers and when
placed in a simple shear ﬂow. Using the sensitivity analysis, we discover which pa-
rameters are active in each of the experiments. Pre-computing the results of the
simulations on a grid formed from the sensitive parameters, we construct polynomial
approximations of the results for all the parameter space. In the further inference,
only these surrogates are used. The inference outcome demonstrates a good agree-
ment with the experiments for the considered red blood cell model. The result of
this chapter is an example of a very accurate Bayesian inference performed with sur-
rogates only. Speciﬁcally, we have calibrated a red blood cell model from Ref. [97]
and showed that it reproduces well the considered experimental data.
Part III: Conclusions and Outlook
This chapter presents the main results of the thesis for both implementation and
applications. We conclude with discussing the open issues and possible directions
of the future work.

10
Appendix
The Appendix consists of four chapters. The ﬁrst chapter presents the use of ABC
for the likelihood-driven case. The second chapter displays the parameter sensitivity
plots for the blood cell. The third chapter provides the hyper-prior models used for
the hierarchical inference of argon and gives the sampling results of the individual
Bayesian inference for each of the thermodynamic conditions. The fourth chapter
contains the LAMMPS scripts used for helium and argon computations.

Part I
Theory
11


Chapter 2
Bayesian Inference
Building computational models in various branches of science goes through many
stages: conducting an experiment demonstrating some phenomenon, proposing its
mathematical explanation (mathematical model), simulating the phenomenon in a
computer (computational model), which includes adjustment of the computational
model in order for it to best reproduce the experiment. Each of the stages introduces
an uncertainty in the resulting computational model. The experimental uncertainty
comes from the conditions of the experiment which cannot be controlled: human
factor, environmental factor, intrinsic stochasticity of the system etc. The model
uncertainty accounts for our imperfect understanding of the physical world, point-
ing out that the best existing mathematical model is often, if not always, only an
approximation of the physical reality. The computational uncertainty comes from
the simulations and incorporates the numerical errors introduced into the mathe-
matical model. The sampling uncertainty appears in the model adjustment process
and is related to the fact that many parameters may have an equal probability of
producing an outcome equal to the experimental one.
The Bayesian approach aims at calibrating all the uncertainties appearing in the
computational model adjustment process for making robust predictions with this
model. The approach is probability-based and provides a distribution over a space
of the possible parameters of the computational model. Using a uniﬁed theory, it
can answer all kinds of probability-related questions concerning the computational
model, its parameters and predictions, including selecting the most probable param-
13

14
Chapter 2. Bayesian Inference
eters for a given model or the most probable model out of a set of the competing
ones.
This chapter contains the theory needed for the likelihood-driven Bayesian un-
certainty quantiﬁcation of the parameters ϑ of a computational model M given the
data d.
2.1
Parameters Calibration
Bayesian inference allows to calibrate the computational model parameters given
data on some QoI. This is accomplished using Bayes’ theorem and a prediction
error equation Eq. (2.1) used to formulate the likelihood function:



y
= f(ϑ) + ζe + ζm + ζc ,
ζξ
∼N(0, Σξ),
ξ ∈{e, m, c} ,
(2.1)
where f(ϑ) is the outcome of the computational model with parameters ϑ, y is
the stochastic model prediction, ζe is the experimental (measurement) error, ζm is
the model error, ζc is the computational (simulation) error, Σξ are the covariance
matrices of the multivariate Gaussian distributions N(ζξ | 0, Σξ) , assumed for each
of the error terms ζξ. The graph corresponding to the Eq. (2.1) is referred to as
stochastic model and is denoted by M. Using the prediction error equation Eq. (2.1)
and the experimental data d, one can compute the likelihood p(y = d | ϑ):
p(d | ϑ, M) = N(d | f(ϑ), Σe + Σm + Σc, M) .
(2.2)
After having computed the likelihood function, Bayes’ theorem allows to obtain
the posterior distribution of the model parameters ϑ:
p(ϑ | d, M) = p(d | ϑ, M) p(ϑ | M)
p(d | M)
,
(2.3)
where p(ϑ | M) is the prior probability density function (PDF) of the parameters ϑ
and p(d | M) is the normalization constant called model evidence, given by
p(d | M) =
Z
p(d | ϑ, M) p(ϑ | M)dϑ .
(2.4)

2.2. Stochastic Model Selection
15
2.2
Stochastic Model Selection
The Bayesian framework allows one to select from a set of competing stochastic
models M(k), k = 1, . . . , K a model M(j) which ﬁts the data best. The criterion for
the model selection comes from the Bayes’ theorem, which computes the probability
of a stochastic model M(k) as
P(M(k) | d) = p(d | M(k)) P(M(k))
p(d)
,
(2.5)
where p(M(k)) is the prior PDF of the model M(k) and p(d | M(k)) is computed
by Eq. (2.4).
According to Eq. (2.5), the best model of the competing models
M(k), k = 1, . . . , K is the one with the highest probability.
2.3
Forward Uncertainty Propagation
The uncertainty in the model parameters can be further propagated into a QoI q(ϑ)
using the following formula [6, 60]:
p(q | d, M) =
Z
p(q, ϑ | d, M)dϑ
=
Z
p(q | ϑ, M) p(ϑ | d, M)dϑ
≈1
Ns
Ns
X
k=1
p(q | ϑk, M) , where ϑk ∼p(ϑ | d, M) .
(2.6)
According to the prediction error equation (Eq. (2.1)), the conditional distribu-
tion p(q | ϑk, M) is Gaussian with mean q(ϑ) and covariance matrix Σm+Σc, where
the matrix Σm is known only for the QoI that was used in the inference process,
i.e. for q(ϑ) ≡f(ϑ). For other QoIs this matrix is usually set to zero, such that
only the parameter uncertainty and the computational uncertainty contribute to the
uncertainty of q(ϑ).
2.4
Algorithms
In order to compute the posterior distribution p(ϑ | d, M) (see Eq. (2.3)), one needs
to deal with the evidence p(d | M), which requires evaluating a high-dimensional
integral (Eq. (2.4)).
To overcome this problem, available Markov Chain Monte

16
Chapter 2. Bayesian Inference
Carlo (MCMC) methods can be used to eﬃciently generate samples from the pos-
terior distribution [65, 53, 49, 52, 95].
In our work we use the unbiased version
of the Transitional Markov Chain Monte Carlo (TMCMC) algorithm [26], called
BASIS [106]. The pseudocode for both algorithms is given in Algorithm 1 (the con-
ditioning on model M is omitted). An additional helpful feature of the TMCMC
(and, consequently, BASIS) is that the model evidence is computed as a by-product
during the run.
Algorithm 1 TMCMC/BASIS
// Initialization
Select the population size N
Set the model evidence: E = 1
Sample ϑn from the prior p(ϑ), n = 1, . . . , N
// Main loop
for (α = 0; α ≤1; α = α + δα) do
1. Evaluate plausibility weights wn = p(d | ϑn)δα, where δα > 0 is chosen such
that the CoV of the weights equals to the prescribed value (usually 1)
2. Select distinct samples sℓ= ϑnℓ, with probability ˜wℓ= wnℓ/ PN
n=1 wn as
leaders for the next stage. The selection process continues until PL
ℓ=1 cℓ= N,
where cℓis the number of times the sample ϑnℓgets selected and L is the
number of samples sℓ.
3. Simulate Markov chains:
for (ℓ= 1; ℓ≤L; ℓ= ℓ+ 1) do
TMCMC: Run MH starting from sℓto produce cℓsamples.
BASIS: Run cℓMHs starting from sℓto produce 1 sample each. The proposal
covariance Σℓis user-deﬁned (see Section 5.3 for details). The probability of
acceptance for the sample ϑ′ obtained from the sample ϑ is
r(ϑ, ϑ′) = min

1, p(ϑ′) p(d | ϑ′)δα
p(ϑ) p(d | ϑ)δα

.
(2.7)
end for
4. Replace ϑn, n = 1, . . . , N with these newly produced samples
5. Update the evidence: E = E PN
n=1 wn/N
end for

2.4. Algorithms
17
BASIS hinges on accurate tuning of its parameters, especially of the proposal
covariance inside the Metropolis-Hastings. This issue is addressed in Chapter 5.


Chapter 3
Approximate Bayesian Inference
This chapter contains the theory needed for the likelihood-free Bayesian uncertainty
quantiﬁcation of the parameters ϑ of a computational model M given the data d.
In many cases the likelihood function can be theoretically or computationally
intractable, as in the case of stochastic reaction networks [85] and stochastic models
in general. To remedy this, the Approximate Bayesian Computation (ABC) [85, 99]
framework was introduced as a likelihood-free counterpart of the classical Bayesian
inference methodology. Examples of its widespread usage include stochastic popu-
lation models in ecology [107, 117, 12], biology [123, 101] and chemistry [83].
The inference performed in ABC relaxes the need to formulate a likelihood for
a probabilistic prediction error model [15], so that one can use summary statistics
of the QoI to calibrate the model parameters. This is achieved as the likelihood
is replaced with a discrepancy measure that compares predictions of a stochastic
model to observed data [119].
3.1
Parameters Calibration
The main idea of ABC is to estimate the joint PDF p(ϑ, y | d, M) of the parameter
set ϑ and the stochastic model prediction y. This can be done by applying Bayes’
Theorem and the chain rule:
p(ϑ, y | d, M) = p(ϑ | M) p(y | ϑ, M) p(d | ϑ, y, M)
p(d | M)
,
(3.1)
19

20
Chapter 3.
Approximate Bayesian Inference
where p(d | ϑ, y, M) is approximated as
p(d | ϑ, y, M) ≈P(ρ(y, d) ≤δ | y, M)
(3.2)
for an arbitrary value of δ ≥0 and some discrepancy function ρ(·, ·) assigning smaller
values for pairs (y, d) in which the arguments are closer to each other. Note that
P(ρ(y, d) ≤δ | y, M), as a function of y, can only take value 0 or 1. For δ →∞, the
approximate posterior equals the prior since the approximate likelihood contribution
is ﬂat. As δ →0 the approximate posterior tends to the exact one.
Using Eq. (3.2), the approximate joint posterior PDF (3.1) reads:
pδ(ϑ, y | d, M) = p(ϑ | M) p(y | ϑ, M) P(ρ(y, d) ≤δ | y, M)
p(d | M)
∝p(ϑ | M) p(y | ϑ, M) P(ρ(y, d) ≤δ | y, M) .
(3.3)
Finally, the approximate posterior PDF pδ(ϑ | d, M) can be obtained by marginal-
ization of Eq. (3.3) with respect to y.
It is worth noticing that ABC can be also used with the likelihood-based stochas-
tic forward model (Eq. (2.1)) introducing however an additional uniformly dis-
tributed error term which depends on the discrepancy function and the tolerance
δ [127]. An example of such a use and its comparison with TMCMC is given in
Appendix A.
3.2
Stochastic Model Selection
The model selection for the exact Bayesian inference makes use of the model evidence
(see Eq. (3.4)). In case of ABC, the model evidence can only be approximated:
p(d | M) ≈P((ϑ, y) | ρ(y, d) ≤δ, M)
=
Z
P((ϑ, y) | ρ(y, d) ≤δ, M) p(y | ϑ, M) p(ϑ | M) dϑdy ,
(3.4)
The bigger the δ, the larger the error of the model evidence in ABC, which is a
well-known limitation of this approach [30, 103].
3.3
Forward Uncertainty Propagation
The forward uncertainty propagation is done in the same way as for the exact
Bayesian inference (see Eq. (2.6)) with a replacement of the posterior p(ϑ | d, M)
with the approximate posterior pδ(ϑ | d, M).

3.4. Algorithms
21
3.4
Algorithms
A wide variety of stochastic methods exist for the posterior inference in ABC. A
non-exhaustive list can be found in [12, 25, 113].
In order to deal with complex posterior PDF supports and peaked distributions,
an extension has been proposed to the established algorithm Subset Simulation (Sub-
Sim) [10] used for estimating rare events. For the ABC framework, the rare event is
to ﬁnd samples in the parameter space, such that the corresponding computational
model outcome is close enough to the experimental measurements. The correspond-
ing algorithm, named ABC-SubSim [25], can be used for posterior sampling within
the ABC framework. Its pseudocode is given in Algorithm 2 (the conditioning on
model M is omitted). Note that in order to obtain the marginal approximate pos-
terior PDF pδ(ϑ | d), the algorithm simply needs to take the ϑ-components of the
generated samples.
As in the case of TMCMC/BASIS, the model evidence is computed as a side-
product of the ABC-SubSim run.
Additionally, ABC-SubSim allows for perfect
sampling parallelization (assuming that the run time of the simulation does not de-
pend on the input parameters), as all the Markov chains have the same length.
The
parameters of choice for ABC-SubSim are the spread of the proposal covariance and
the length of Markov chains. The former can be chosen as in the TMCMC/BASIS
(see Chapter 5), the latter is recommended to be set to 5 [25].
A new problem, as compared to TMCMC/BASIS, is the stopping criterion.
There is no rigid convergence criterion for the termination of ABC-SubSim, thus
leaving us with empirical and computational insights. Some of the heuristics which
can be used are:
1) reaching a speciﬁed change in the tolerance,
2) reaching a speciﬁed change in some QoI,
3) reaching a speciﬁed acceptance rate in the MH.
If the QoI is the stochastic model prediction y, the criterion 1) provides an estimate
on how much the approximation of the QoI improved, which coincides with the
criterion 2). The stopping criterion 3) comes into play when samples get rejected
not because of getting in the area of big discrepancy values in the ϑ-space, but
because of the natural variability of y. In that case tuning the proposal covariance

22
Chapter 3.
Approximate Bayesian Inference
Algorithm 2 ABC-SubSim
// Initialization
Select the population size N and the Markov chain length c, s.t. L = N/c is
integer
Set the model evidence: E = 1
Sample ϑn from the prior p(ϑ) and yn from p(y | ϑ), n = 1, . . . , N
// Main loop
while stopping conditions are not met do
1. Evaluate discrepancies ρn, n = 1, . . . , N and renumber the samples s.t. their
discrepancies are sorted in the ascending order; set δ = 1
2 (ρL + ρL+1).
2. Select samples sℓ= (ϑℓ, yℓ), ℓ= 1, . . . , L as leaders for the next stage
3. Simulate Markov chains:
for (ℓ= 1; ℓ≤L; i = i + 1) do
Run MH starting from sℓto produce c samples. The proposal covariance Σℓ
is user-deﬁned (see Section 5.3 for details). The probability of acceptance for
the sample (ϑ′, y′) obtained from the sample (ϑ, y) is
r(ϑ, ϑ′) = min

1, p(ϑ′)
p(ϑ)

P(ρ(y′, d) ≤δ | y′) .
(3.5)
end for
4. Replace (ϑn, yn), n = 1, . . . , N with these newly produced samples
5. Update the evidence: E = E/c
end while
Report the ﬁnal tolerance δ

3.4. Algorithms
23
matrix does not help since even for a ﬁxed ϑ from a good region some samples y
can have a too high discrepancy to be accepted at the current stage.


Chapter 4
Hierarchical Bayesian Inference
This chapter contains the theory needed for the likelihood-driven hierarchical Bayesian
uncertainty quantiﬁcation of the parameters ϑ of a computational model M given
a collection of datasets #»d.
In certain cases the data may come split in several datasets. One example of
such a situation is when many research groups conduct the same experiment. Then
the observed dependency can have the same functional form, but the underlying pa-
rameters may be diﬀerent (see Fig. 4.1 for an example). Another possibility occurs
in personalized medicine, where the parameter variability is attributed to the indi-
vidual characteristics of a patient. Finally, the datasets may correspond to diﬀerent
input variables x of the model, one of the examples being pressure and temperature
of a system in molecular dynamics. In such cases it is desirable to distinguish the
uncertainty which is due to the variability between diﬀerent datasets (groups, ther-
modynamic conditions, patients) from the uncertainty encoded in each individual
dataset. This diﬀerentiation is useful for making predictions for the future, having
observed some data in the beginning of the time line. An example can be predicting
the slope of the linear model in Fig. 4.1 if we know points up to x = 1. Not taking
into account the variability of the slopes between diﬀerent datasets, we will make
a prediction with wide errorbars from the biggest slope to the smallest, instead of
noticing that we can predict the linear ﬁt almost perfectly from some initial points.
The methodology, which distinguishes the individual variability of parameters
from the collective one, is called “Hierarchical Bayesian (HB) inference”. In this
25

26
Chapter 4.
Hierarchical Bayesian Inference
chapter, we describe an approach to the HB inference proposed in Ref. [129].








Figure 4.1: A synthetic example of a hierarchical data structure. All the datasets
exhibit a linear behavior y = ϑx with diﬀerent slopes ϑ. The hyper-parameter ψ
governs the prior distribution of the slopes: p(ϑ | ψ) = U(ϑ; ψ1, ψ2).
4.1
Parameters Calibration
We consider a case when data for the QoI f(ϑ) comes split in K diﬀerent datasets:
#»d = {d(1), . . . , d(K)}. The likelihood in the probabilistic model M(k) corresponding
to the dataset k is assumed to be N(d(k) | f(ϑ(k)), Σ(k)), where Σ(k) is user-deﬁned.
We also assume that the probability of ϑ(k) depends on a hyper-parameter ψ ∈RNψ
and is given by a PDF p(ϑ | ψ, M), where M corresponds to the graph describing
the relations between ψ, ϑ(k) and d(k), see Fig. 4.2.
Our goal is to obtain samples from the posterior distributions p(ϑ(k) | #»d, M):
p(ϑ(k) | #»d, M) =
Z
p(ϑ(k) | ψ, #»d, M) p(ψ | #»d, M) dψ .
(4.1)
The dependency assumptions from Fig. 4.2 allow to simplify:
p(ϑ(k) | ψ, #»d, M) = p(ϑ(k) | ψ, d(k), M) ,
(4.2)
and Eq. (4.1) can be rewritten using the Bayes’ theorem:
p(ϑ(k) | #»d, M) =
Z p(d(k) | ϑ(k), ψ, M) p(ϑ(k) | ψ, M)
p(d(k) | ψ, M)
p(ψ | #»d, M) dψ .
(4.3)

4.1. Parameters Calibration
27
ψ
ϑ(1)
ϑ(k)
ϑ(K)
d(K)
d(k)
d(1)
…
…
…
…
ϑnew
ynew
y(k)
new
Mnew
M(1)
M(k)
M(K)
Figure 4.2: Hierarchical Bayesian network.
Since, from Fig. 4.2 we have
p(d(k) | ϑ(k), ψ, M) = p(d(k) | ϑ(k), M) ,
(4.4)
Eq. (4.3) simpliﬁes to
p(ϑ(k) | #»d, M) =
p(d(k) | ϑ(k), M)
Z p(ϑ(k) | ψ, M)
p(d(k) | ψ, M) p(ψ | #»d, M) dψ .
(4.5)
Finally, as suggested in Ref. [129], the posterior distribution Eq. (4.1) can be ap-
proximated as
p(ϑ(k) | #»d, M) ≈p(d(k) | ϑ(k), M)
Nsψ
Nsψ
X
i=1
p(ϑ(k) | ψi, M)
p(d(k) | ψi, M) ,
(4.6)
where Nsψ is suﬃciently large, ψi ∼p(ψ | #»d, M) and p(ϑ(k) | ψi, M) is a user-
deﬁned PDF called “hyper-prior”.
We see that, in order to obtain samples ϑ(k), we ﬁrst have to sample the proba-
bility distribution p(ψ | #»d, M). According to Bayes’ theorem, we write
p(ψ | #»d, M) = p(#»d | ψ, M) p(ψ | M)
p(#»d | M)
,
(4.7)

28
Chapter 4.
Hierarchical Bayesian Inference
where p(ψ | M) is the prior PDF on ψ and p(#»d | M) is the normalizing constant.
Exploiting the dependency assumption of Fig. 4.2, we see that
p(#»d | ψ, M) =
K
Y
k=1
p(d(k) | ψ, M) .
(4.8)
The likelihood of k-th dataset is expressed according to the total probability theorem
as
p(d(k) | ψ, M) =
Z
p(d(k), ϑ(k) | ψ, M) dϑ(k) ,
(4.9)
which can be written, using the chain rule, as
p(d(k) | ψ, M) =
Z
p(d(k) | ϑ(k), ψ, M) p(ϑ(k) | ψ, M) dϑ(k) .
(4.10)
According to Eq. (4.4), one can simplify Eq. (4.13) to
p(d(k) | ψ, M) =
Z
p(d(k) | ϑ(k), M) p(ϑ(k) | ψ, M) dϑ(k) .
(4.11)
Here we introduce the model M(k) described in Fig. 4.2. The posterior distribution
of this model will be used as instrumental density for importance sampling. Under
the modeling assumption p(d(k) | ϑ(k), M) = p(d(k) | ϑ(k), M(k)) (see [129]) and the
use of the Bayes’ theorem, Eq. (4.9) is written as
p(d(k) | ψ, M) =
Z p(ϑ(k) | d(k), M(k)) p(d(k) | M(k))
p(ϑ(k) | M(k))
p(ϑ(k) | ψ, M) dϑ(k) , (4.12)
or, equivalently, as
p(d(k) | ψ, M) = p(d(k) | M(k))
Z p(ϑ(k) | ψ, M)
p(ϑ(k) | M(k)) p(ϑ(k) | d(k), M(k)) dϑ(k) . (4.13)
Referring again to Ref. [129], one approximates Eq. (4.9) as
p(d(k) | ψ, M) ≈p(d(k) | M(k))
Nsϑ
Nsϑ
X
i=1
p(ϑ(k)
i
| ψ, M)
p(ϑ(k)
i
| M(k))
,
(4.14)
where ϑ(k)
i
∼p(ϑ(k) | d(k), M(k)), Nsϑ is suﬃciently large and can be diﬀerent
for each dataset d(k).
The advantage of this approach is that the likelihoods
p(d(k) | ϑ(k), M(k)), k = 1, . . . , K, which are the most expensive part of the compu-
tations, are not re-evaluated for each ψ.

4.2. Stochastic Model Selection
29
The ﬁnal formula for the posterior probability of the hyper-parameters will thus
look as follows:
p(ψ | #»d, M) ≈p(ψ | M)
p(#»d | M)
K
Y
k=1
p(d(k) | M(k))
Nsϑ
Nsϑ
X
i=1
p(ϑ(k)
i
| ψ, M)
p(ϑ(k)
i
| M(k))
,
(4.15)
where ϑ(k)
i
∼p(ϑ(k) | d(k), M(k)), Nsϑ is suﬃciently large and can be diﬀerent for
each dataset d(k).
4.2
Stochastic Model Selection
In the case of hierarchical inference, one can select the model M, which reduces
to selecting the most probable model for the hyper-prior PDF p(ϑ | ψ, M) in the
hyper-parameter inference Eq. (4.7). This selection is performed in the same way
as for the non-hierarchical Bayesian inference in Chapter 2.
4.3
Forward Uncertainty Propagation
The uncertainty propagation for HB case has two cases:
1) propagation for the same QoI – case y(k)
new on Fig. 4.2,
2) propagation for a new QoI – case ynew on Fig. 4.2.
4.3.1
Propagation for the same QoI
The predictive distribution of the QoI that was used in the calibration process (y(k)
new
on Fig. 4.2), can be computed in the following way:
p(y(k)
new | #»d, M) =
Z
p(y(k)
new, ϑ(k) | #»d, M) dϑ(k)
=
Z
p(y(k)
new | ϑ(k), #»d, M) p(ϑ(k) | #»d, M) dϑ(k) .
(4.16)
Since the knowledge of ϑ(k) breaks the dependence between the data #»d and the
prediction y(k)
new, Eq. (4.16) simpliﬁes to
p(y(k)
new | #»d, M) =
Z
p(y(k)
new | ϑ(k), M) p(ϑ(k) | #»d, M) dϑ(k) ,
(4.17)

30
Chapter 4.
Hierarchical Bayesian Inference
which, in turn, can be approximated by
p(y(k)
new | #»d, M) ≈
Npo
X
i=1
p(y(k)
new | ϑ(k)
i
, M) ,
(4.18)
where Npo is suﬃciently large and ϑ(k)
i
∼p(ϑ(k) | #»d, M), which can be computed
from Eq. (4.6).
Note that the hyper-parameter vector ψ enters into Eq. (4.18)
indirectly through the full dataset #»d.
4.3.2
Propagation for a new QoI
The predictive distribution of a QoI that was not used in the calibration process
(ynew on Fig. 4.2), can be computed in the following way:
p(ynew | #»d, M) =
Z
p(ynew, ϑnew | #»d, M) dϑnew ,
(4.19)
which, according to the chain rule, is equivalent to
p(ynew | #»d, M) =
Z
p(ynew | ϑnew, #»d, M) p(ϑnew | #»d, M) dϑnew .
(4.20)
Knowing ϑnew makes the data #»d and the prediction ynew independent, simplifying
Eq. (4.20) to
p(ynew | #»d, M) =
Z
p(ynew | ϑnew, M) p(ϑnew | #»d, M) dϑnew ,
(4.21)
which can be ﬁnally approximated as
p(ynew | #»d, M) ≈
Npn
X
i=1
p(ynew | ϑnew,i, M) ,
(4.22)
where ϑnew,i ∼p(ϑnew | #»d, M) and Npn is suﬃciently large.
The last distribution we need, p(ϑnew | #»d, M), can be computed as
p(ϑnew | #»d, M) =
Z
p(ϑnew, ψ | #»d, M) dψ ,
(4.23)
which, by the chain rule, is equivalent to
p(ϑnew | #»d, M) =
Z
p(ϑnew | ψ, #»d, M) p(ψ | #»d, M) dψ .
(4.24)

4.4. Algorithms
31
If ψ is known, #»d is independent of ϑnew (see Fig. 4.2)), and we get
p(ϑnew | #»d, M) =
Z
p(ϑnew | ψ, M) p(ψ | #»d, M) dψ .
(4.25)
Finally, the right hand side of Eq. (4.25) gets approximated in the same way as all
the other integrals:
p(ϑnew | #»d, M) ≈
Npϑ
X
i=1
p(ϑnew | ψi, M) ,
(4.26)
where Npϑ is suﬃciently large and ψi ∼p(ψ | #»d, M), which is computed according to
Eq. (4.7). In this case, the hyper-parameter vector ψ enters into the approximation
directly.
4.4
Algorithms
The overall procedure for performing the HB inference can now be summarized as
follows.
1. Sample the parameters distributions p(ϑ(k) | d(k), M(k)), k = 1, . . . , K. This
step is an inference procedure discussed in detail in Chapter 2, we use BA-
SIS [106] to sample from the distributions involving one set of data d(k):
p(ϑ(k) | d(k), M(k)), k = 1, . . . , K. We save the evidences p(d(k) | ϑ(k), M(k))
of the models M(k) computed by BASIS as a by-product of the run to use
them at the step 2.
2. Sample the hyper-parameter distribution p(ψ | #»d, M) using BASIS and Bayes’
theorem formulation from Eq. (4.7). Recall that the likelihood p(#»d | ψ, M) is
computed from Eq. (4.8) and further approximated using Eq. (4.14).
The
latter requires computing a sum for each hyper-parameter ψ, which involves
two priors (hierarchical and non-hierarchical) – analytical functions – and the
evidences, which were evaluated at step 1.
3. Sample the updated parameters distributions p(ϑ(k) | #»d, M), k = 1, . . . , K
using BASIS and the approximation from Eq. (4.6). In this approximation,
the multiplier outside the sum p(d(k) | ϑ(k), M) is a standard non-hierarchical
likelihood. The sum together with a multiplier 1/Nsψ can be considered as an

32
Chapter 4.
Hierarchical Bayesian Inference
improper prior (i.e. such that it does not integrate to 1), which is not a problem
for MCMC methods. The sum itself involves computing the hyper-prior – an
analytical function – and the term p(d(k) | ψi, M), which is computed using
Eq. (4.14), in the same way as discussed in step 2.
The hyper-parameter
ψi is generated from the distribution p(ψ | #»d, M) sampled in step 1. Since
the terms p(d(k) | ψi, M) do not involve ϑ, they can be precomputed for a
set of samples ψi, i = 1, . . . , Nsϑ before sampling the updated parameters
distributions p(ϑ(k) | #»d, M(k)) to reduce the computational eﬀort.
4. Propagate the uncertainty into a QoI. The propagation for the same QoI y(k)
new
(see Eq. (4.18)) requires sampling from the distribution p(ϑ(k) | #»d, M), which
was computed at step 3. The propagation for the new QoI ynew (see Eq. (4.22))
requires sampling from the distribution p(ϑnew | #»d, M), which is approximated
by a sum of hyper-priors – analytical functions – in Eq. (4.26).
The com-
ponents of the sum require, in turn, sampling from p(ψ | #»d, M), which was
discussed in step 2.
Note that BASIS in the above procedure can be replaced by any other sampling
algorithm. The only additional requirement is that the algorithm, which is used at
step 1., should be able to compute the evidence of a model.

Chapter 5
Implementation
5.1
Π4U Framework
For the Bayesian Uncertainty Quantiﬁcation and Propagation, we employ our in-
house open-source high performance computing framework Π4U [60]. Π4U is platform-
agnostic and can eﬃciently exploit massively parallel computer architectures. With
a help of the task-parallel library for clusters TORC [58], Π4U extracts and sched-
ules the parallelism of the Bayesian inference algorithms. Π4U exhibits both ease of
programming and transparent load balancing through the task stealing mechanism.
To support this mechanism, TORC maintains a pool of available work chunks and
automatically manages the access of tasks to this pool. Additionally, Π4U enables
multiple levels of parallelisation, which come in play naturally in the Bayesian infer-
ence: 1) diﬀerent Markov chains are independent and can be processed in parallel, 2)
each likelihood evaluation may require multiple simulation runs, 2) each simulation
run can also be a parallel program.
Π4U has been used for inferences in molecular dynamics, granular materials and
structural dynamics [60, 59, 80] and has shown excellent performance and scalability,
which is discussed more in detail further in this chapter.
From the user prospective, the framework is easy to work with. The user pro-
vides a C function which returns the log-likelihood value (“ﬁtfun”) and adjusts the
conﬁguration ﬁle (the population size, the prior information, the dimensionality
etc.). The “ﬁtfun” function can call any external simulation engine inside, parallel
or sequential. If one wishes to use this function for the forward uncertainty propa-
33

34
Chapter 5.
Implementation
gation, it should also store the simulation output in a special array. After this, Π4U
is ready to run.
Currently, Π4U has ﬁve algorithms for the main problems of the Bayesian UQ:
1) TMCMC [26] and BASIS [106] algorithms for the exact Bayesian inference,
2) ABC-SubSim [25] algorithm for the approximate Bayesian inference,
3) Subset Simulation [10] algorithm for rare events sampling,
4) CMA-ES [63] algorithm for optimization,
three surrogate models:
1) kriging surrogate,
2) multilayer perceptron surrogate,
3) extreme learning machine surrogate,
and a number of helper tools:
1) sensitivity tool,
2) uncertainty propagation tool,
3) samples visualization tool,
4) propagation visualization tool.
The surrogates are described more in detail later in this chapter.
Sensitivity tool
For this tool, the user provides a point ϑr, at which he wishes
to check the sensitivity, selects the number of steps in each direction (M) and the
size of the step (δk, in percents). The sensitivity tool spawns parallel jobs in all
the directions from a reference point, i.e. each of the submitted simulations will be
evaluated at a point
ϑ :



ϑi = ϑr,i,
if i ̸= k ,
ϑk = ϑr,k + mδk,
otherwise ,
(5.1)
where i, k = 1, . . . , Nϑ, m = −M, −M +1, . . . , 0, . . . , M −1, M. The quantity under
sensitivity analysis can be either the log-likelihood, or a user-deﬁned QoI.

5.2. Structure of Π4U algorithms
35
Propagation tool
This tool is able to run parallel simulations using each line
from a given ﬁle as a parameter vector. The points are samples from the posterior
distribution. The tool utilizes the output array of the “ﬁtfun” to obtain the result
of the simulation. Thus, in order for the tool to run properly, the user should save
the outcome of the simulation.
Samples visualization tool
The samples visualization tool takes an putput ﬁle
of an inference algorithm (TMCMC, BASIS or ABC-SubSim) to produce an image
of samples projected onto 2-d subspaces of the parameter space colored by the log-
likelihood. The ﬁgure is amended with 1-d histograms of the marginal posteriors
and the 2-d kernel histograms of each pair or parameters. The tool is written in R
and can be adjusted to generate diﬀerent sizes of ﬁgures, colors, fonts etc.
Propagation visualization tool
This tool generates a ﬁgure containing quan-
tiles of the propagated QoI. The tool is written in MATLAB, which allows users to
modify the ﬁgure properties.
5.2
Structure of Π4U algorithms
All of the algorithms currently implemented inside Π4U follow the same scheme,
shown in Algorithm 3.
Such a similarity allows for modular implementation,
planned for the future. The next four paragraphs give speciﬁcations for each of the
algorithms with respect to the general scheme.
TMCMC (BASIS)
The algorithm-speciﬁc settings for TMCMC (BASIS) are
the following:
I-1. α = 0, E = 1
M-1. Evaluate plausibility weights wn = p(d | ϑn)δα, where δα > 0 is chosen such
that the CoV of the weights equals to the prescribed value (usually 1)
M-2. ˜wℓ= wnℓ/ PN
n=1 wn and cℓis the number of times that ϑnℓwas selected
M-3. r(ϑ, ϑ′) = min
n
1, p(ϑ′)/p(ϑ) (p(d | ϑ′)/p(d | ϑ))δαo
and Σℓis discussed be-
low
M-5. α = α + δα, E = E PN
n=1 wn/N

36
Chapter 5.
Implementation
Algorithm 3 Typical Π4U algorithm
// Initialization
I-1. Select the population size N and algorithm-speciﬁc constants and variables
I-2. Sample ϑn from the prior p(ϑ), n = 1, . . . , N
// Main loop
while stopping conditions S are not met do
M-1. Evaluate auxiliary quantities
M-2. Select samples sℓ= ϑnℓas leaders for the next stage with algorithm-
speciﬁc probability ˜wℓ.
Each of the leaders will generate cℓsamples (also
algorithm-speciﬁc).
M-3. Simulate Markov chains:
for (ℓ= 1; ℓ≤L; i = i + 1) do
Do cℓsteps of MH starting from sℓ. MH proposal covariance Σℓand proba-
bility of acceptance r(ϑ, ϑ′) are algorithm-speciﬁc.
end for
M-4. Replace ϑn, n = 1, . . . , N with these newly produced samples
M-5. Update variables
end while

5.2. Structure of Π4U algorithms
37
BASIS
The algorithm-speciﬁc settings for BASIS are the same as for TMCMC,
except that we run cℓMHs with the chain length 1 from each of the leaders.
ABC-SubSim
The algorithm-speciﬁc settings for ABC-SubSim are the following:
ϑ is augmented with the random variable describing the output QoI: ϑ ←(ϑ, y) ,
and
I-1. E = 1, choose c such that L = N/c is integer
M-1. Evaluate discrepancies ρn, n = 1, . . . , N and renumber the samples s.t. their
discrepancies are sorted in the ascending order.
Set δ = (ρL + ρL+1) /2 .
M-2. ˜wn = I{ρn ≤δ} and cℓ= c
M-3. r(ϑ, ϑ′) = min {1, p(ϑ′)/p(ϑ)} I{ρ(y′, d) ≤δ} and Σℓis discussed below
M-5. E = E/c
SubSim
The algorithm-speciﬁc settings for SubSim are the following:
I-1. Choose the current level b, choose c such that L = N/c is integer
M-2. ˜wn = I{yn ≥b} and cℓ= c
M-3. r(ϑ, ϑ′) = I{y′ ≥b} and Σℓis discussed below
M-5. Update b (see [10])
CMA-ES
The algorithm-speciﬁc settings for CMA-ES are the following:
I-1. Initialize pc = pσ = 0, Σ = I, ⟨x⟩, σ (see [64]).
M-2. Select µ best points, cℓ= 1
M-3. 1 (accept everything)
M-5. Update pc = pσ = 0, Σ = I, ⟨x⟩, σ (see [64]).

38
Chapter 5.
Implementation
5.3
Improving MH Sampling
The three out of four algorithms in Π4U hinge on accurate tuning of the MH proposal
covariance. A matrix which allows for big jumps leads to the low sample acceptance
rate, while a matrix which forces small steps leads to the ineﬃcient exploration of
the parameter space by the algorithm and might lead to stagnation.
The original TMCMC uses the covariance matrix from the previous stage scaled
with some factor. We have observed that for some distributions with unidentiﬁable
manifolds this approach leads to low acceptance rates and requires many samples
to converge.
One approach to resolve this issue is to adjust the scaling factor of the covariance
matrix based on the MH acceptance rate calculated on a Markov chain of a small
length, as proposed for ABC-SubSim in Ref. [25]. This method, however, fails to
generate a good covariance matrix for skewed posterior distributions, such as the
Rosenbrock function.
Thus, we have decided to focus on another way of creating the proposal co-
variance distribution, which makes use of the local geometry in the neighborhood
of each chain leader. Our approach is to compute the sample covariance matrix
in a rectangular region around the leader. The size of the region is adjusted au-
tomatically, starting from a very small neighborhood, until the calculated sample
covariance matrix of this region is positive deﬁnite.
The local covariance idea was tested on the 2-d Rosenbrock function using BASIS
with 8000 samples per stage. As it can be seen in Fig. 5.1, the sampling of the BASIS
is greatly improved with the local covariance. Taking into account these promising
results, we now employ the local covariance for all the MH-based algorithms in Π4U.
5.4
Surrogates
Large-scale models often exhibit exceedingly high computational cost, which makes
it nearly impossible to perform Bayesian calibration requiring thousands of simu-
lation runs. In such a situation, lightweight surrogate models can be used instead
of the real function evaluations. Although they introduce an additional layer of ap-
proximation, surrogates allow to use much more samples in the inference and thus
decrease the sampling error, as compared to the true model evaluations. This, to-
gether with a careful control of the approximation error, makes surrogates a useful

5.4. Surrogates
39
(a) Global covariance (scale = 0.2 [26]).
(b) Local covariance.














	
	
(c) Analytical plot.
Figure 5.1: 8000 BASIS samples from the Rosenbrock function.

40
Chapter 5.
Implementation
tool which can provide a reasonable estimate of the posterior PDF.
5.4.1
Methodology
The surrogate can be built oﬀ-line, when one ﬁrst obtains a low-order model and
then runs inference with it, or on-line, when one re-builds the surrogate on the
ﬂy during the inference. Another choice to be made is building a local surrogate
for each point based on the neighborhood information or building a global one
for all the points. The Markov chains in the TMCMC, BASIS and ABC-SubSim
are of a local nature, which suggests that one should choose a local surrogate. In
addition, the local approximation is cheaper and more accurate around the chain
leader than the global one. We choose to approximate the log-likelihood of a given
sample instead of approximating the result of the simulation, as the latter may be
high-dimensional and thus more troublesome to handle. Having all this in mind, we
follow the methodology proposed in Ref. [8] to implement the on-line local surrogates
approximating the log-likelihood in Π4U.
The current implementation of the surrogates in Π4U proceeds for each Markov
chain leader as follows:
1. Find the leader’s neighbors in a predeﬁned domain
2. Build a surrogate for the current chain using the neighbors found at step 1
3. For each sample produced by the Markov chain, evaluate the surrogate
4. Decide whether to use or not the surrogate outcome. If not, then evaluate the
full model and use its outcome.
In our implementation we look for neighbors in a rectangular region equal to a user-
deﬁned percentage of the full domain. If the speciﬁed percentage is larger or equal
than 100%, the algorithm optimizes the computations by building the surrogate
only once per algorithm stage, as the interpolating surface will be the same for all
the leaders.
To make a decision about using or not the value proposed by the surrogate model,
we again refer to Ref. [8]. We apply two criteria: 1) the relative error of the surrogate
approximation is smaller than 1% (when available), 2) the value predicted by the
surrogate lies within the 5%-95% quantile range of all the real model evaluations.

5.4. Surrogates
41
5.4.2
Surrogates with Bayesian inference algorithms
Three of the algorithms implemented in Π4U, ABC-SubSim, BASIS and TMCMC,
share algorithmic similarities that encourage the usage of surrogates. More precisely,
in all the three algorithms, the newly generated samples lie inside (or very close
to) the convex hull of the samples from the previous stages, which is schematically
illustrated in Fig. 5.2a. The two samples domains are nested, with the samples drawn
at stage k populating the region inside the blue boundary, and the samples generated
at stage (k + 1) populating the domain inside the red curve. Chains generated at
stage (k + 1) from the leader samples located in the red domain produce samples
aiming at populating this domain. Note that there exist blue samples (generated up
to stage k) that contain in their convex hull the red chain. This property, however,
can be broken if the ABC-SubSim/TMCMC/BASIS annealing goes too fast or if
the number of samples per stage is too small.
This algorithmic feature was exploited in Ref. [9] to introduce kriging surrogates
within TMCMC. The full model evaluations from previous TMCMC stages (blue
samples in Fig. 5.2a) were gathered at the neighborhood of each leader (red points
with blue boundary in Fig. 5.2a) to become kriging support points. After that, the
inference was continued, but the log-likelihood value in each of the points proposed
by MH was replaced by a surrogate prediction, which was used or not according to
the rules discussed in the previous section. As a result, the authors observed up to
one order of magnitude reduction of the number of full model evaluations required.
We thus conclude that the same concept can be readily applied to ABC-SubSim and
TMCMC/BASIS with any kind of an interpolation algorithm supporting irregular
grids.
The property discussed above breaks however for the SubSim and CMA-ES,
as these algorithms try to explore regions of low probability/low ﬁtness function
values, as shown in Fig. 5.2b. Each chain generated using SubSim/CMA-ES, drawn
with arrows, can be located outside of the convex hull of the samples generated
from SubSim/CMA-ES up to stage k. This prevents any interpolation method from
building accurate estimates, since there is no enough support points from previous
stages in the region of interest. We thus are limited to building oﬀ-line surrogate
models on a ﬁne enough grid to cover the whole region of interest in the parameter
space.

42
Chapter 5.
Implementation
k
k + 1
(a) ABC-SubSim and TMCMC. For BASIS the chains have lengths 1 and may start from
the same leader.
k
k + 1
(b) SubSim and CMA-ES.
Figure 5.2: Schematic representation of intermediate domains at stages k (dashed
blue line) and (k + 1) (dashed red line), samples up to stage k (blue dots and red
dots with blue border), chains generated from the leader samples at the stage k
(red dots and red dots with blue border) for various algorithms. Black dots indicate
samples which were proposed, but rejected by the algorithm.

5.5. HPC Aspects
43
5.4.3
Available surrogates in Π4U
Having assessed the necessity of the surrogates in Π4U, we have implemented them
for TMCMC and BASIS. Their implementation with ABC-SubSim is scheduled for
the future. Π4U now supports three surrogate models: kriging [78, 112], Multi-Layer
Perceptron (MLP) [66] and Extreme Learning Machine (ELM) [71].
The kriging surrogate is implemented using the open-source gplib library [2].
The multilayer perceptron and the extreme learning machine implementation use
the open-source OpenANN library [3].
We have used the surrogate-aided Bayesian inference for a two-dimensional Him-
melblau function using each of these surrogates. Fig. 5.3 presents the posterior PDFs
of four runs: a run with real model evaluations only, a run with kriging as a surro-
gate, a run with MLP (1 layer, 32 neurons) as a surrogate, and a run with ELM (1
layer, 512 neurons) as a surrogate.
There is no visible diﬀerence in the surrogate-aided and surrogate-free inferences.
For more in-depth investigation of the eﬀect of the surrogates on the performance
of the BASIS, we have performed a series of runs with diﬀerent support size of the
surrogate and diﬀerent surrogate models. Table 5.1 presents the results of the BASIS
runs using surrogates. We observe that the error of the ELM decreases with the
increase of the percentage D of the domain used to build the surrogate. The best
result in terms of accuracy-time trade-oﬀis achieved with a global interpolation.
The error of MLP decreases for D < 8% and increases when D is bigger than 8%,
which suggests the overﬁtting issues. The error of the kriging surrogate consistently
decreases with the increase of D. This series of experiments suggests that the global
ELM surrogate is the best option in terms of both time and accuracy. However, more
tests are required to address the high-dimensional distributions and those with the
unidentiﬁable manifolds.
5.5
HPC Aspects
In this section we discuss the performance of the newly implemented ABC-SubSim
algorithm and surrogate techniques.

44
Chapter 5.
Implementation
(a) No surrogates.
(b) Kriging surrogate.
(c) MLP surrogate (1 layer, 32 neurons).
(d) ELM surrogate (1 layer, 512 neurons).
Figure 5.3: Posterior PDFs of the 2-d Himmelblau function. The population size is
8000. Each of the surrogates uses 8% of the domain to build the approximation.

5.5. HPC Aspects
45
Table 5.1: Results of the BASIS inference of the Himmelblau function using the
surrogates: percentage D of the domain used to build surrogate, posterior mean
value m(ϑ) of the parameter ϑ, 5%-95% quantiles q(ϑ) of the posterior PDF of
the parameter ϑ, percentage S of surrogate points, average surrogate evaluation
time T in seconds, average error E computed as the absolute diﬀerence between
the surrogate and the real model evaluation. The population size was chosen to be
2000.
D m(ϑ1) q(ϑ1)
m(ϑ2) q(ϑ2)
S
T
E
No surr.
– 1.113
[-3.796, 3.795] 0.376
[-3.277, 3.414] –
–
–
ELM
4% 0.930
[-3.907, 3.963] 0.245
[-3.344, 3.461] 64% 0.11
280.00%
ELM
8% 1.102
[-3.818, 3.960] 0.235
[-3.435, 3.409] 65% 0.25
102.00%
ELM
16% 1.158
[-3.906, 3.795] 0.126
[-3.380, 3.376] 64% 0.55
25.00%
ELM
32% 1.242
[-3.818, 3.796] 0.238
[-3.329, 3.332] 64% 1.3
0.86%
ELM
100% 0.852
[-3.898, 3.833] 0.320
[-3.402, 3.335] 71% 0.024
0.43%
MLP
4% 1.130
[-3.990, 4.153] 0.056
[-3.633, 3.450] 90% 0.047
100.0%
MLP
8% 0.792
[-3.932, 3.861] 0.107
[-3.460, 3.397] 48% 1.2
1.7%
MLP
16% 1.021
[-3.944, 3.910] 0.196
[-3.465, 3.223] 48% 2.8
2.4%
MLP
32% 1.203
[-3.847, 3.945] 0.102
[-3.325, 3.300] 48% 5.6
2.8%
MLP
100% 1.247
[-3.921, 3.897] 0.154
[-3.277, 3.224] 64% 0.018
188.0%
Kriging
4% 1.150
[-3.828, 3.828] 0.183
[-3.321, 3.293] 30% 0.10
4.400%
Kriging
8% 1.189
[-3.897, 3.806] 0.261
[-3.321, 3.308] 42% 0.64
2.800%
Kriging
16% 1.589
[-3.816, 3.913] 0.219
[-3.307, 3.302] 45% 0.45
0.410%
Kriging
32% 1.549
[-3.687, 3.908] 0.324
[-3.297, 3.344] 36% 3.89
0.013%
Kriging 100% 1.326
[-3.833, 3.933] 0.140
[-3.376, 3.286] 39% 0.75
0.049%

46
Chapter 5.
Implementation
5.5.1
ABC-SubSim
As a test case for the ABC-SubSim, we consider an MD simulation of helium,
described in detail in Chapter 6.
The inference in this case uses MPI-parallel LAMMPS and runs on 512 compute
nodes of the Piz Daint. TORC is initialized with two MPI workers per node resulting
in 1024 workers in total. Each LAMMPS simulation utilizes 4 cores, making the full
use of each compute node.
The three discrepancies considered for this inference problem give similar out-
comes, and we thus only present results for one of them – the quantile-based dis-
crepancy. Table 5.2 summarizes the parallel performance of ABC-SubSim. We see
that the scheduling mechanism of TORC is working extremely well, as the parallel
eﬃciency reaches 95-96%, despite the high variance of the simulation run times. The
eﬃciency of the initialization phase (stage 0) is 95% as 15360 function evaluations
are evenly distributed among the 1024 workers. The considerably lower eﬃciency of
63% at the stage 1 is explained by the existence of chains with high total running
times, which is due to the small number of chains available to each worker (3072
chains in total, 3 chains per worker). For the stage 2, the eﬃciency increases to 89%,
and further reaches the plateau of 95% on stages 3-7. The average load imbalance
on this plateau is approximately 8% computed as the mean over the stages 3-7 of
(Tmax −Tavg)/Tmax, where Tmax and Tavg are the maximum and average time (in
seconds) workers spent during a given stage.
5.5.2
Surrogates
We have applied the on-line local kriging surrogate to the argon inference problem
described in detail in Chapter 7. The interpolation was constructed in the neigh-
borhood of each chain leader deﬁned as 16% of the domain size in each direction. A
total of 28% of the log-likelihood evaluations were accepted surrogate runs resulting
in a speedup of 28% computed as:
1 −Ts · Ns + Tr · Nr
Tr · N
= 1 −1.3 · 10000 + 797.1 · 8596
797.1 · 12000
,
(5.2)
where Ts is the average runtime of the surrogate, Ns is the total number of the
surrogate evaluations (both accepted and rejected), Tr is the average runtime of the
real model evaluation, Nr is the total number of the real model evaluations, N is

5.6. Clusters
47
Table 5.2: Detailed per-stage performance results of ABC-SubSim with 1024 workers
on the Piz Daint cluster: Tm – mean simulation time, Ts – standard deviation of the
simulation times, Tt – sum of the execution times of all simulations, Tw – wall-clock
time per stage. All the times are measured in seconds.
Stage Tm Ts Tt
Tw
Speedup Eﬃciency Load imbalance
0
83
84 1267610 1307 970
95%
5%
1
132 95 2025660 3147 644
63%
37%
2
66
6
1014480 1114 911
89%
28%
3
64
3
988523
1012 977
95%
7%
4
64
3
987557
1006 981
96%
8%
5
64
3
989781
1012 978
95%
9%
6
65
3
991197
1016 975
95%
9%
7
65
3
996400
1021 976
95%
8%
the total number of samples per stage equal to the number of accepted surrogate
evaluations plus the number of real model evaluations. All the times are given in
seconds.
5.6
Clusters
All the inferences described in this thesis were performed with the open-source high
performance computing library Π4U compiled on Brutus cluster of the Swiss Federal
Institute of Technology (ETH) Zurich and Piz Daint cluster of the Swiss National
Supercomputing Center (CSCS), Lugano.
On Brutus, we use nodes with four 12-core AMD Opteron 6174 CPUs of the
Magny-Cours family. The operating frequency of each of the 12 cores is 2.2 GHz.
On Piz Daint, we use 8-core Intel Xeon E5-2670 CPUs operating at 2.6 GHz and
NVIDIA Tesla P100 GPUs.


Part II
Applications
49


Chapter 6
Helium Modeling
In this chapter we apply the Approximate Bayesian Inference to Molecular Dynamics
(MD). The results described here were published in Ref. [80].
MD is a popular method for investigating properties of materials at atomistic
scale. MD simulations integrate Newton’s equation of motion for the atoms in the
system, and use their trajectories and forces to estimate QoIs. In this chapter, we
focus on QoIs in the form of moments of a statistical distribution averaged over time
and atoms. Before MD simulations can be used, one must assign a functional form
to the interatomic interactions. These interactions are commonly referred to as a
Force-Field (FF).
There have been several recent works examining the usage of Bayesian inference
in MD-FF calibration [5, 7, 20, 19, 102, 84, 39].
The underlying assumption in
these works is Gaussianity of the ﬂuctuations of the target properties (diﬀusion
coeﬃcients, radial distribution functions, etc.) [5, 39]. However, it is often the case
in MD that some thermodynamical properties of interest do not follow a Gaussian
distribution, and the ﬁrst two moments are then not suﬃcient for the full QoI
description. In this case a natural choice is to apply ABC with a more involved
discrepancy, than the mean and variance-based one. Shell [109] suggests that the
most relevant target for calibrating molecular models is the relative entropy of the
two MD ensembles. We employ the relative entropy as discrepancy in the ABC
inference and demonstrate its increased capability of inferring the LJ parameters,
as compared to the discrepancy based on the ﬁrst two moments.
51

52
Chapter 6. Helium Modeling
6.1
Parameters Calibration
We consider the calibration of the Lennard-Jones potential parameters of helium
using the likelihood-free Bayesian inference. The Lennard-Jones potential is given
by
V (r; σ, ε) = 4ε
σ
r
12
−
σ
r
6
,
(6.1)
where ε is the depth of the potential well, σ is the ﬁnite distance at which the
inter-particle potential is zero, and r is the distance between the particles.
The
parameters ε and σ are material-speciﬁc.
ε is measured in 10−21 J, σ and r are measured in nanometers (10−9 m). Boltz-
mann factor fB is measured in 1015 kg−1.
We are interested in calibrating the LJ parameters of helium using the data on
the Boltzmann factor distribution over time:
fB =

exp

−H
kBT

,
(6.2)
where H is the enthalpy of the system of helium atoms, T is the temperature of the
system, kB is the Boltzmann constant, and ⟨·⟩denotes the ensemble average. The
ensemble average indicates that H is measured for all interacting atoms at each time
instance. We generated synthetic Boltzmann factor data using LAMMPS [98, 1] for
a system of 1000 atoms equilibrated for 2 ns and simulated for 20 ns in the NPT
ensemble [111] with a time step of 2 fs and ε = 0.141, σ = 0.2556 (see Fig. 6.1),
which are the LJ parameters values taken from [121]. The system used for calibration
consists of 1000 atoms and is equilibrated for 2 ns, following a production run in the
NPT ensemble for another 5 ns with a 2 fs time step. The LAMMPS script used
in the inference is given in Appendix D.2. We note that the model cannot replicate
the target data exactly due to the smaller sampling time. This is a typical situation
in MD, where the calibration is done with limited resources.
The distribution of the Boltzmann factor is non-Gaussian due to its statistical
thermodynamics deﬁnition, which results in a heavy tail in Fig. 6.1. Exploiting the
ﬂexibility of ABC, we employ 3 diﬀerent discrepancy functions to capture higher
order moments of the distribution, and compare the results.

6.1. Parameters Calibration
53









	





Figure 6.1: Data: distribution of the Boltzmann factor fB over time of a helium
system with 1000 atoms, σ = 0.2556, ε = 0.141.
The ﬁrst discrepancy function makes use of the ﬁrst two moments of the Boltz-
mann factor distribution:
ρ(y, z) =
  ¯y −¯z
¯y
2
+
sy −sz
sy
2!1/2
,
(6.3)
where ¯
X denotes a sample mean and sX denotes the sample standard deviation
of the quantity X. Since the mean and the variance form a suﬃcient statistic of
the Gaussian distribution, this discrepancy mimics the likelihood-driven approach
which usually assumes Gaussianity of the ﬂuctuations.
The second choice for the discrepancy is based on the quintiles (5-quantiles) q
of the data sets:
ρ(y, z) =
 
4
X
k=1
qk(y) −qk(z)
qk(y)
2!1/2
.
(6.4)
The ﬁnal option is:
ρ(y, z) =
Z
pz(t) log pz(t)
py(t)dt,
(6.5)

54
Chapter 6. Helium Modeling
which is a relative entropy (also called Kullback-Leibler divergence) of the PDF
pz(·) of z and the PDF py(·) of y. The involved PDFs are computed by a kernel
density estimate.
Note that the Kullback-Leibler divergence depends on the order of arguments,
and one should take care to not commute the target data with the simulations result.
The motivation behind the use of the relative entropy as a discrepancy measure
comes from the work of Shell [109]. He treats it as a natural way of comparing the
two MD ensembles. It is worth noticing that in the case of Gaussian distributed
QoI, the relative entropy relaxes to accurate estimation of its mean and variance.
We ran the calibrations using 15360 samples per stage.
In every case ABC-
SubSim stopped because of the acceptance-based criterion (the acceptance rate
dropped below 5%). A full MD simulation was run for every sample in the parame-
ters space requiring a signiﬁcant amount of computational work. For this inference
problem, an additional load imbalance is introduced to the algorithm, as simulations
with smaller values of σ require considerably more time, as compared to those with
larger values of σ. Since the relative expected run time is known a priori, we help
Π4U by applying the Longest Processing Time algorithm [56], which means that
the tasks with higher execution time are processed ﬁrst. More precisely, we sort
the samples according to the values of σ before giving the simulation runs to the
workers. Our large scale parallel runs on Piz Daint supercomputer show an excellent
parallelization eﬃciency of up to 95% with the load imbalance of approximately 8%
(see Table 5.2 for details).
Analyzing the results, we observe that the outcome of calibration for each dis-
crepancy function diﬀers from the two others both in terms of the most probable
parameters and their associated uncertainty, see Table 6.1 and Fig. 6.2.
Under the stochastic model class MG which assumes the Gaussianity of the
Boltzmann factor distribution, the parameter ε is unidentiﬁable, as the approximate
posterior PDF spans across all the prior range (Fig. 6.2a). To explain this eﬀect, we
checked the contributions of the fractions (¯y −¯z)/¯y and (sy −sz)/sz from Eq. (6.3)
to the discrepancy. We observed that a typical contribution of the mean diﬀerence
is around 3%, while for the variance diﬀerence it is around 97%. Together with
the observation that the standard deviation of the Boltzmann factor distribution
appears to be insensitive to changes in ε, we obtain a reasonable explanation of the
unidentiﬁability of ε.

6.1. Parameters Calibration
55
(a) Gaussian discrepancy.
(b) Quantile discrepancy.
(c) Relative entropy discrepancy.
Figure 6.2: Calibration results for the LJ parameters of helium using ABC-SubSim
with diﬀerent discrepancies (see Notations). Green circles on the bottom-left sub-
plots indicate parameters for which the data were created.

56
Chapter 6. Helium Modeling
Table 6.1: Values of the LJ parameters ϑ ∈{σ, ε} of helium: prior bounds p(ϑ), pos-
terior MPVs b(ϑ), posterior 5%-95% quantiles q(ϑ), number of stages S, achieved tol-
erances δ for three discrepancy models: MG – Gaussian (Eq. (6.3)), MQ – quantile-
based (Eq. (6.4)), MKL – Kullback-Leibler (Eq. (6.5)).
Model p(σ)
b(σ)
q(σ)
p(ε)
b(ε)
q(ε)
S δ
MG
[0.1,0.8] 0.245 [0.203, 0.300] [0.01, 1] 0.423 [0.049, 0.899] 4 3.4×10−3
MQ
[0.1,0.8] 0.259 [0.247, 0.269] [0.01, 1] 0.138 [0.123, 0.159] 7 9.6×10−6
MKL
[0.1,0.8] 0.279 [0.251, 0.304] [0.01, 1] 0.117 [0.087, 0.156] 6 6.7×10−2
Inspection of Fig. 6.1 reveals the skewed nature of the Boltzmann factor distribu-
tion, which is neglected when modeled with a Gaussian distribution. The diﬀerence
in the posterior distributions obtained using the other two discrepancies, as com-
pared to the Gaussian one, lies mainly in their ability to reduce the uncertainty of
both ε and σ (see Fig. 6.2b, Fig. 6.2c). There is no signiﬁcant diﬀerence between the
quantile and the relative entropy results, except that the quantile setting is arguably
more robust.
6.2
Discrepancy Model Selection
The inference with discrepancy models MQ and MKL identiﬁed the force-ﬁeld pa-
rameters, employing a full MD run per sample, while MG resulted in a wide posterior
distribution that spans across the entire prior range. This happened because, in the
Gaussian case, we have reduced the information regarding the ensemble PDF of
the QoI into 2 numbers, the mean and variance, which are not enough to uniquely
identify the LJ potential values. This is a typical approach however in potential
calibration and hierarchical coarse graining strategies [96] in MD, where the values
of the QoI (e.g. intermolecular forces) are taken to be the ensemble averages of
the coarse and ﬁne molecular models to be matched.
On the other hand, ABC
equipped with a relative entropy discrepancy provides a natural framework [109]
for the development of eﬃcient parallel sampling algorithms. ABC-SubSim imple-
mented herein provided accurate identiﬁcation of the force ﬁeld parameters when
using thermodynamic ensemble target data in MD. This is achieved by exploiting
the full non-Gaussian description of the QoI, contrary to Ref. [5, 20, 39].

6.3. Discussion
57
Based on the ABC model selection criterion (Eq. (3.4)) applied to ABC-SubSim,
the Gaussian model should be chosen as the best one, as it required the least number
of stages to converge. However, the Gaussian setting resulted in the unidentiﬁable
manifold for ε, while the two other settings were able to reduce its prior uncertainty.
Recalling that the evidence computed in ABC, and in particular by ABC-SubSim, is
only an approximation of the true evidence, we conclude that in this case the error
of the formula is too big to make any conclusions. The issues of the model selection
in the context of ABC are discussed in detail in Ref. [50, 104].
6.3
Discussion
We have addressed a problem of calibrating the LJ potential of helium using data
with non-Gaussian ﬂuctuations.
Using the ABC inference, we have assessed the
eﬀect of changing the discrepancy between the data and the simulation outcome on
the resulting LJ parameters distribution. Our results show that assuming the Gaus-
sianity of the ﬂuctuations leads to an unidentiﬁable manifold in ε, while relaxing this
assumption allows to reduce the prior uncertainty in both LJ parameters. Following
the works of Shell [109], we made one of the discrepancies to be the Kullback-Leibler
divergence (the relative entropy), which he considers as a natural way of comparing
two thermodynamical ensembles. Our results conﬁrm that this setting allows for
quite precise calibration of the LJ potential.


Chapter 7
Argon Modeling
The Lennard-Jones (LJ) potential is one of the most popular force-ﬁelds in Molec-
ular Dynamics (MD) simulations, a widespread computational method for studying
atomistic phenomena. Although it has been subject to numerous calibrations, its
repulsion exponent often does not get involved into these studies. In this chapter
we investigate the inﬂuence of the repulsion exponent on the behavior of argon and
demonstrate that this parameter has a power to enhance the predictive capabilities
of MD simulations.
LJ potential force depends on the inter-atomic distance r and consists of an
attractive and a repulsive parts.
The attractive term −r−q models the Van der
Waals interactions and the repulsive term r−p models the Pauli repulsion at short
ranges due to overlapping electron orbitals. There exists a theoretical justiﬁcation
for setting the attractive exponent q = 6 [72], however there is none for the repulsive
exponent p = 12. The latter was chosen to be the square of the attractive term to
ease the computations. In the past, several (discrete) values of the exponent p of
the LJ 6-p potential, ranging from 10 to 20, have been considered [48]. The values
of pressure and viscosity for various thermodynamic conditions were studied with a
condition that p = 12 is the best choice for this type of data.
Two more parameters control the shape of the potential: σ is related to the
location of the potential well and ε controls the well depth.
These parameters
have been the subject of numerous calibration studies [11, 100, 105, 126], including
Bayesian ones [20, 6].
59

60
Chapter 7. Argon Modeling
Here we employ a hierarchical Bayesian (HB) technique to infer the parameters
(ε, σ, p) of the LJ 6-p potential in a systematic way for a number of thermodynamic
conditions, following Ref. [128, 129]. HB inference allows information to ﬂow be-
tween the diﬀerent data sets leading to more robust and accurate predictions for the
model parameters. In our studies, we use experimental data from Radial Distribu-
tion Function (RDF) and data from quantum simulations of argon. The RDFs are
measured for liquid argon at ﬁve diﬀerent temperature-pressure pairs and one case
of a saturated argon vapor.
We perform the HB calibration using the RDFs for the classical LJ 6-12 and
the modiﬁed LJ 6-p potentials and present rigorous model selection, which prefers
LJ 6-p. After that, robust posterior predictions for the RDF, diﬀusion coeﬃcient
and density are made using both potentials, where the LJ 6-p demonstrate superior
quality of results. The value of the repulsion exponent found for LJ 6-p is close to
6.5 for most of the thermodynamic conditions, largely deviating from the widely
used 12.
Finally, we calibrate the LJ 6-p using data on quantum dimer scans of argon,
which describe the behavior of the argon gas. This calibration suggests a repulsion
exponent p = 12.7, which is much closer to the conventional value of p = 12.
However, the predictions of this potential for all the quantities considered (in the
liquid and saturated vapor states) are inferior to those obtained from the LJ 6-6.5.
We conclude with the two main results: 1) adjusting the repulsive exponent of LJ
6-p can boost its predictive capabilities, 2) the calibration has to be done, however,
for each thermodynamic state separately. We remark that our results have been
obtained in the case of a very simple system, potentially suggesting even greater
improvements for more complex simulations.
7.1
Computational Model Description
We perform MD simulations of argon using LAMMPS package [98, 1]. The argon
atoms are modeled as spheres which interact with LJ 6-p potential:
VLJ(r; ε, σ, p) = 4ε
σ
r
p
−
σ
r
6
,
(7.1)
where r is the distance between the interacting atoms and p is the repulsion exponent
usually taken to be 12. The parameters ε, σ and p are to be chosen according to

7.2. Notations
61
the available measurements. As the Lennard-Jones interactions quickly decay with
the distance, an additional computational parameter rc is usually introduced. This
parameter deﬁnes a cut-oﬀdistance at which the potential is set to zero. Here, we
set rc = 2.5σ. The thermodynamic state of the system is deﬁned by the temperature
and the pressure of the argon atoms. We ensure that argon is in the liquid/vapor
state by checking the self-diﬀusion coeﬃcient and the density. The simulation starts
with energy minimization followed by 5 × 106 steps, of 2 fs, in an NPT ensemble.
Then the RDF is computed in the production run consisting of 105 NVE integration
steps of 2 fs each.
The boundary conditions are periodic in each direction, the
domain contains 666 argon atoms. The self-diﬀusion coeﬃcient is calculated via the
mean-squared displacement of the atoms, the RDF is discretized using 100 bins.
The LAMMPS script used in the inference is given in Appendix D.2. The units
used in the current work are given in Table 7.1.
Table 7.1: Units used in this chapter.
name
notation real
Temperature
T
K
Pressure
P
atm
Distance
r
˚A
LJ well depth
ε
kcal/mol
LJ well location
σ
˚A
LJ repulsion exponent p
–
RDF model error
σn
–
Density
ρ
g/cm3
Diﬀusion coeﬃcient
D
cm2/s
7.2
Notations
The calibration of LJ 6-12 using RDF data is denoted as B12,R. The inference using
RDF data with LJ 6-p is denoted as Bp,R. The corresponding HB inferences are
denoted as HB12,R and HBp,R. The RDFs are computed for 6 temperature/pressure
pairs (T, P).
We denote the pairs as: L1 = (84.4, 0.8), L2 = (91.8, 1.8), L3 =
(126.7, 18.3), L4 = (144.1, 37.7), L5 = (149.3, 46.8), V = (149.3, 43.8), where L

62
Chapter 7. Argon Modeling
stands for “liquid” and V stands for “vapor”. The corresponding datasets (RDFs)
are denoted as RLi for liquid and RV for vapor.
The calibration using quantum dimer calculations with LJ 6-p is denoted as
Bp,Q. The corresponding dataset is denoted as Q.
The experimentally measured RDFs are taken from Ref. [36].
The quantum
dimer energy calculations come from Ref. [62]. For the forward predictions, we use
data on density and diﬀusion coeﬃcient. The reference values for density (ρ) are
experimental measurements taken from Ref. [36]. The reference values for diﬀusion
coeﬃcient (D) are computed analytically using the equations from Ref. [76].
7.3
Parameters Calibration
This section describes the inferences we performed and their results. We always use
BASIS algorithm [106] with 2000 samples per stage for LJ 6-12 and 4000 samples
per stage for LJ 6-p. The parallelisation is made with MPI and internal worker
threads of the Π4U library. Each LAMMPS simulation is also run in parallel with 8
MPI processes. In order to reduce the computational cost of the simulations, we use
the kriging surrogate inside Π4U with 16% of the domain used for the interpolation
surface construction.
All the data we use comes without errorbars, and the simulation also gives
an exact result, which allows to specify the prediction error equation Eq. (2.1)
as following:
Σe = Σc = 0, Σm = σ2
nI ,
(7.2)
where the model error σn is to be inferred.
7.3.1
Calibration of LJ 6-12
Bayesian inference
We present results of parameter calibration for ε, σ, σn, with
p ﬁxed to 12. We use uniform prior for each of the parameters and each of the
datasets RLi, RV : ϑ ∈[0.05, 3] × [3, 4] × [0, 1].
Fig. 7.1 presents the most probable values (MPVs) of the inferred parameters
along with their 5%-95% quantiles. The results are only presented for four out of six
datasets as the LJ 6-12 potential failed to simulate the liquid argon for conditions
L1 and L2. We observe a large diﬀerence in the values of ε for liquid and vapor,
which implies that one cannot perform the simulations using the same parameters

7.3. Parameters Calibration
63
L3
L4
L5
V
0.1
0.2
0.3
L3
L4
L5
V
3
3.2
3.4
3.6
Figure 7.1: Posterior parameter values: MPVs along with 5%-95% quantiles ob-
tained in B12,R (light red), HB12,R (dark red). Horizontal lines indicate the refer-
ence values: Ref. [11] (yellow), Ref. [126] (red), Ref. [100, 105] (blue).

64
Chapter 7. Argon Modeling
for the two phases. We deﬁne the uncertainty in a parameter as the ratio of the
5%-95% quantile spread to the MPV. Thus deﬁned uncertainty varies from 14% to
20% for ε depending on the dataset, while σ is identiﬁed more precisely with an
uncertainty of 2%-6%. Such a diﬀerence in the uncertainties is attributed to the
type of data used in the inference process. The location of the RDF peak, which
gives a substantial contribution to the sum of squared errors in the log-likelihood,
is more sensitive to σ. On the other hand, ε aﬀects the height of the RDF peak,
which has a smaller contribution to the log-likelihood.
We note that the values which we obtained in the calibration process are close
to those found in literature (see Table 7.2, Fig. 7.1).
Table 7.2: LJ parameters for argon used in literature. The last row shows the data
used for ﬁtting. Notations: T (temperature), P (pressure), ρ (density), B (second
virial coeﬃcient), E (energy), TP (gas-liquid transition pressure), L (latent heat of
evaporation).
Ref. [100] Ref. [11]
Ref. [105]
Ref. [126]
ε
0.2385
0.2824
0.2381
0.2498
σ
3.4000
3.3605
3.4050
3.3450
T
94.4
86.64 - 168.86
137.77
88 - 127
ρ
1.374
0.435 - 1.479
0.156, 0.972 0.283 - 3.897
Phase liquid
gas, liquid, solid gas + liquid gas + liquid
Data
RDF
P, E
TP, ρ, L
P, B
The full set of the MPVs and distribution quantiles for each dataset RLi, RV is
given in Table 7.3. The full posterior distributions are shown in Figs. C.1 and C.2.
HB inference
Next, we infer the parameters of LJ 6-12 using the HB approach
described in Chapter 4.
We choose the hyper-prior p(ϑi | ψ) using Bayesian model selection, according to
which the most probable prior model is uniform (see Appendix C.1 for details). The
values of the LJ parameters are presented in Fig. 7.1 (dark red). The MPVs and the
quantiles of the parameters are almost the same as in the B12,R, which means that
for each dataset yi ∈{RL1, . . . , RL5, RV } no information about the parameters can
be extracted from the other datasets.

7.3. Parameters Calibration
65
The full set of the MPVs and distribution quantiles for each dataset RLi, RV is
given in Table 7.3.
Table 7.3: Posterior values of each parameter ϑ ∈{ε, σ, σn} of LJ 6-12: MPV b(ϑ)
and 5%-95% quantiles q(ϑ).
b(ε)
q(ε)
b(σ)
q(σ)
b(σn) q(σn)
B12,R
L3 0.286 [0.284, 0.323] 3.305 [3.250, 3.332] 0.168 [0.158, 0.314]
L4 0.255 [0.254, 0.266] 3.314 [3.301, 3.353] 0.089 [0.080, 0.140]
L5 0.263 [0.255, 0.309] 3.266 [3.110, 3.536] 0.317 [0.292, 0.586]
V
0.144 [0.083, 0.184] 3.109 [3.029, 3.213] 0.147 [0.119, 0.304]
HB12,R
L3 0.283 [0.283, 0.303] 3.300 [3.226, 3.327] 0.177 [0.156, 0.310]
L4 0.253 [0.254, 0.267] 3.333 [3.301, 3.367] 0.073 [0.073, 0.147]
L5 0.262 [0.256, 0.296] 3.269 [3.108, 3.523] 0.337 [0.301, 0.579]
V
0.190 [0.140, 0.242] 3.075 [3.001, 3.229] 0.180 [0.192, 0.385]
7.3.2
Calibration of LJ 6-p
Bayesian inference using RDF
We now include the LJ exponent p into the
parameter set ϑ. As in the LJ 6-12 case, we choose a uniform prior with wide enough
bounds: [0.05, 10] × [3, 4] × [6.01, 15] × [0, 1]. The bounds for ε were increased, as
compared to LJ 6-12 case, after a test run of the sampling algorithm. As will be
seen later, this is due to a strong negative correlation between ε and p.
Being a more ﬂexible potential, LJ 6-p can simulate a wider range of thermody-
namic conditions, including L1 and L2, which result in the values of LJ parameters
similar to those obtained for the other three liquid conditions. The 95% quantile
of p, as well as its MPV, is for four out of six RDF datasets below 7.5 and for all
the datasets below 10, which is much smaller than the conventional 12. This can
be explained by the fact that the repulsion energies predicted by the standard 6-12
LJ potential are very high for the liquids. The conﬁgurations with such energies
happen with probability close to zero, and the MD simulation is not able to sample
them.
As in the LJ 6-12 case, the parameter ε exhibits signiﬁcant variation within
each dataset RLi, RV (uncertainty 110%-216%, computed the same way as for LJ

66
Chapter 7. Argon Modeling
6-12), while p and σ are well-deﬁned with the uncertainty of 5%-30% and 1%-
6%, respectively. In addition, ε diﬀers substantially among the RDF datasets, but
always in accordance with p: the higher the p, the lower the ε (see Fig. 7.3). Notably,
parameters inferred using L3 −L5 and Q (see below) lie in the same manifold, while
those calibrated using L1 −L2 sample a diﬀerent manifold and those inferred from
V lie in yet another manifold. This result gives grounds for future studies of other
thermodynamic conditions and their eﬀect on p −ε relation.
Once again, we observe the non-transferability of the LJ parameters from liquid
to vapor simulations: the values of σ lie in disjoint domains for Li and V (see
Fig. 7.2).
HB inference using RDF
We proceed by calibrating the LJ 6-p parameters
using the HB approach from Chapter 4. Details for the selection of the hyper-prior
can be found in Appendix C.1, according to which the most probable hyper-prior
model is the uniform one.
We observe that the uncertainty in ε gets signiﬁcantly reduced for conditions
L1, L2, L5 and V (see Fig. 7.2) indicating that the inference beneﬁted from the
information contained in the two remaining datasets RL3 and RL4 with narrow
posterior distributions of ε (Figs. C.3 to C.5). On the other hand, the uncertainty
in ε for L3 and L4 increases adjusting to the wide ranges in the other four cases.
A similar situation can be seen for p, where narrow distributions for L1, L3, L5,
V shift the posterior values for L2 and L4. The RDF is, as discussed above, very
sensitive to the changes in σ, which controls the location of the LJ potential well,
and therefore σ is well determined for each of the datasets RLi, RV and extracts
almost no information from the other data sets.
The full set of MPVs and distribution quantiles of the LJ parameters for RLi,
RV is given in Table 7.4.
Bayesian inference using quantum calculations
We examine the suitability
of the repulsion exponent 12 for gaseous argon by performing a calibration using
the calculated quantum dimer scans of argon as data.
We infer the parameters
of the LJ 6-p potential by ﬁtting it to the binding energy of the quantum dimer.
The resulting MPV 12.7 of p is much closer to the conventional 12 (see Fig. 7.2,
Table 7.4), suggesting that for the gaseous argon, unlike for the liquid one, LJ 6-12
is a reasonable choice. This drastic diﬀerence in p once again shows that the same

7.3. Parameters Calibration
67
L1
L2
L3
L4
L5
V
0
2
4
6
8
L1
L2
L3
L4
L5
V
3
3.1
3.2
3.3
3.4
3.5
L1
L2
L3
L4
L5
V
6
8
10
12
p
Figure 7.2: Posterior parameter values: MPVs along with 5%-95% quantiles ob-
tained in Bp,R (light blue), HBp,R (dark blue). Horizontal line indicates the MPVs
for Bp,Q.

68
Chapter 7. Argon Modeling
Table 7.4: Posterior values of each parameter ϑ ∈{ε, σ, p, σn} of LJ 6-p: MPV b(ϑ)
and 5%-95% quantiles q(ϑ).
b(ε)
q(ε)
b(σ) q(σ)
b(p) q(p)
b(σn) q(σn)
Bp,R
L1 2.286 [2.193, 4.79] 3.43 [3.42, 3.46] 6.64 [6.29, 6.65] 0.157 [0.185, 0.302]
L2 3.134 [0.712, 4.42] 3.37 [3.32, 3.43] 6.37 [6.29, 8.31] 0.222 [0.215, 0.518]
L3 1.250 [0.914, 2.70] 3.32 [3.30, 3.40] 6.72 [6.33, 7.07] 0.098 [0.080, 0.159]
L4 0.337 [0.322, 1.06] 3.33 [3.33, 3.40] 9.50 [6.90, 9.84] 0.057 [0.066, 0.153]
L5 5.928 [0.794, 7.32] 3.33 [3.19, 3.40] 6.12 [6.10, 7.13] 0.164 [0.168, 0.326]
V
1.065 [0.625, 3.61] 3.12 [3.04, 3.12] 6.60 [6.15, 6.92] 0.100 [0.099, 0.190]
HBp,R
L1 4.561 [3.890, 4.63] 3.45 [3.41, 3.47] 6.30 [6.30, 6.37] 0.422 [0.450, 0.602]
L2 2.081 [1.333, 3.52] 3.39 [3.34, 3.42] 6.57 [6.34, 7.05] 0.211 [0.178, 0.351]
L3 2.506 [0.941, 4.33] 3.35 [3.30, 3.38] 6.32 [6.20, 7.00] 0.093 [0.081, 0.186]
L4 2.588 [0.892, 3.68] 3.40 [3.36, 3.43] 6.34 [6.23, 7.06] 0.082 [0.075, 0.146]
L5 2.055 [0.992, 4.28] 3.25 [3.19, 3.38] 6.36 [6.17, 6.84] 0.183 [0.159, 0.316]
V
1.371 [0.582, 1.90] 3.13 [3.08, 3.19] 6.42 [6.28, 7.03] 0.111 [0.103, 0.233]
Bp,Q
0.252 [0.239, 0.26] 3.37 [3.37, 3.38] 12.7 [12.3, 13.3] 0.006 [0.006, 0.010]
LJ parameters cannot be used to simulate diﬀerent thermodynamic states, such as
liquid, saturated vapor, or gas.
The diﬀerence between the Ri and Q datasets shows up in the region of the
subspace which gets populated. The quantum dimer-based calibration prefers high
values of p, which correspond to the tails of the distributions inferred using the RDF
data. We performed a calibration with L3 and narrow prior bounds (p ∈[12, 14])
to see whether this is indeed a tail of the full posterior distribution (Fig. C.7). The
narrow posterior values of ε are below 0.34, while the values of the full posterior
start from ε = 0.90, which explains why the tails of the full distributions for Li and
V have a negligible number of samples in the region p ∈[12, 14] preferred by the
Q-based inference.
The full set of MPVs and distribution quantiles of the LJ parameters for Q is
given in Table 7.4 and the full posterior distribution is plotted in Fig. C.6.

7.3. Parameters Calibration
69
7.3.3
Comparison of LJ 6-12 and LJ 6-p
Model selection
We select between the LJ 6-12 and LJ 6-p potentials by applying
the Bayes selection procedure described in Chapter 2.
The model selection (Table 7.5) shows that LJ 6-p is signiﬁcantly better than the
LJ 6-12 for L3 and L5. Since LJ 6-12 is not able to produce a liquid for L1 and L2,
we conclude that LJ 6-p is preferred for four RDF datasets out of six. In the case
of L4 the two potentials provide results that are indistinguishable by the Bayesian
model selection. The only dataset on which the LJ 6-12 potential produces better
results (3 times more probable than LJ 6-p) is V , the vapor case. Thus, LJ 6-p is
better (or, at least, not worse) than LJ 6-12 for all the liquid cases considered. For
the vapor case, the LJ 6-p is over parametrized, as compared to LJ 6-12.
Table 7.5: Log-evidences E12,R (Ep,R) for B12,R (Bp,R).
E12,R
Ep,R
eEp,R−E12,R
L1
–
-7.05
–
L2
–
-14.8
–
L3
-9.72
2.81
2.74×105
L4
5.10
5.18
1.09
L5
-15.8
-8.76
1.18×103
V
-3.83
-4.94
3.31×10−1
LJ potentials
Studying the reasons for LJ 6-p being more plausible than LJ 6-
12, we take a closer look at the inferred shapes of the potentials.
The LJ 6-12
parameters can alter the potential shape in two ways: ε scales the whole curve, and
σ moves the potential well. LJ 6-p has one additional parameter p, which scales
the repulsive part of the potential only, making this force-ﬁeld more ﬂexible. We
observe a very stable correlation in the (p, ε) subspace (Fig. 7.3) for all the datasets
used. This result is expected as p regulates the strength of the repulsion and ε alters
the strength of both repulsion and attraction simultaneously. Since the parameters
ε and p are highly correlated, one could expect that the inference will be able to
recover values of ε for LJ 6-12 such that the resulting potential is close to the inferred
LJ 6-p. However, the eﬀect that p and ε have on the LJ potential is not entirely the

70
Chapter 7. Argon Modeling
6
8
10
12
14
p
0.3
1
3
10
Figure 7.3: Posterior samples of Bp,R projected onto (p, ε) subspace.
Red: V .
Shades of blue: Li in the temperature increasing order from the lightest to the
darkest color. Green: Q. Grid lines indicate the log-scale for ε.

7.3. Parameters Calibration
71
same. As ε acts as a scaling factor for the whole potential, it is not able to make the
potential less deep and at the same time ﬂat enough to avoid switching to the gas
phase (compare simulations with MPVs for L5, V in Fig. 7.4). The same reasoning
can be applied to explain the inability of LJ 6-12 to drive L1 and L2 to the liquid
phase: the potential is too repulsive, frustrating the liquid packing, and the system
behaves either like a gas or like a solid (note that L1 is close to the argon triple
point).
The full set of the inferred LJ 6-12 and LJ 6-p potentials is given in Fig. 7.4.
3
4
5
6
r
-0.4
-0.2
0
0.2
VLJ
L3
3
4
5
6
r
-0.4
-0.2
0
0.2
VLJ
L5
3
4
5
6
r
-0.4
-0.2
0
0.2
VLJ
L4
3
4
5
6
r
-0.4
-0.2
0
0.2
VLJ
V
Figure 7.4: Posterior LJ potentials comparison. Blue: MPVs with 5%-95% quan-
tiles from HBp,R.
Red: MPVs from HB12,R.
Green: MPVs from Bp,Q (when
applicable). Black: quantum dimer calculations (when applicable).

72
Chapter 7. Argon Modeling
Robust posterior prediction
The quality of the predictions, made for a QoI
diﬀerent than the one used for the inference, quantiﬁes the predictive power of
the model (see Section 4.3). We obtain robust predictions of the RDF, density ρ
and diﬀusion coeﬃcient D of argon by propagating the posterior LJ parameters
uncertainty into these quantities.
We measure the error ∆g of the prediction of the scalar quantity g as
∆g = 1
N
N
X
k=1
gk −rk
rk
2
,
(7.3)
where N ≤6 is the number of thermodynamic conditions for which the prediction
can be made, gk is the prediction made using the MPV and rk is the reference
value. The accuracy of the ﬁt for these computations is 0.7%. The error of the
RDF is computed as an average over all the thermodynamic conditions of the mean
squared error between the computed and the experimental RDF. The predictions
are compared on three diﬀerent sets of conditions: 1) the conditions which can be
simulated using MPVs obtained in all the three inferences HB12,R, HBp,R, and
Bp,Q (L4, L5), 2) the conditions which can be simulated using MPVs obtained in
the inferences HB12,R and HBp,R (L3 −L5, V ), 3) the conditions which can be
simulated using MPVs obtained in the inference HBp,R (L1 −L5, V ).
The predictions made using the results of HBp,R are the most accurate for all
the QoIs considered and for all but one case where HB12,R gives a better result (see
Table 7.6). On the other hand, the predictions made using the results of Bp,Q are
the least accurate for all the QoIs. Additionally, the inferences HB12,R and Bp,Q
result in LJ potentials which cannot be used to simulate all the thermodynamic
conditions. We conclude that the HBp,R produces a better LJ model than HB12,R,
and that Bp,Q does not result in a good model for liquid argon or saturated argon
vapor.
We note that the values of D diﬀer by an order of magnitude for liquid and vapor
which explains the huge deterioration of the predictions on the sets of conditions
that include V .
We observe that the dataset RL4 appears to be the most democratic one, allowing
any kind of LJ potential to ﬁt it: the classical LJ 6-12, the modiﬁed LJ 6-12.7 (from
Q), LJ 6-9.5 (from Bp,R) or LJ 6-6.3 (from HBp,R).
The MPVs of D and ρ along with the corresponding quantiles are presented in
Fig. 7.6. The same values for RDF are given in Fig. 7.5.

7.3. Parameters Calibration
73
3
4
5
6
7
8
r
0
1
2
3
4
RDF
L1
3
4
5
6
7
8
r
0
1
2
3
4
RDF
L4
3
4
5
6
7
8
r
0
1
2
3
4
RDF
L2
3
4
5
6
7
8
r
0
1
2
3
4
RDF
L5
3
4
5
6
7
8
r
0
1
2
3
4
RDF
L3
3
4
5
6
7
8
r
0
1
2
3
4
RDF
V
Figure 7.5: Robust posterior predictions of RDF. Blue: MPVs with 5%-95% quan-
tiles from HBp,R. Red: MPVs from HB12,R (when applicable). Green: MPVs from
Bp,Q (when applicable). Black: experimental data.

74
Chapter 7. Argon Modeling
L1
L2
L3
L4
L5
V
0
0.5
1
1.5
L1
L2
L3
L4
L5
V
10-5
10-4
10-3
D
Figure 7.6: Robust posterior predictions of density ρ and diﬀusion coeﬃcient D.
Blue: MPVs with 5%-95% quantiles from HBp,R. Red: MPVs with 5%-95% quan-
tiles from HB12,R (when applicable). Green: MPVs from Bp,Q (when applicable).
Grey: experimental data for ρ, analytically computed values for D.
Grid for D
shows the logarithmic scale.

7.4. Discussion
75
Table 7.6: Errors of robust posterior predictions of RDF, density and diﬀusion
coeﬃcient using LJ 6-12 and LJ 6-p.
We denote S1 = {L4, L5} (all inferences
produce the correct argon phase), S2 = {L3 −L5, V } (Bp,Q produces wrong phase),
S3 = {L1 −L5, V } (Bp,Q and HB12,R produce wrong phase).
∆RDF
∆ρ
∆D
S1
S2
S3
S1
S2
S3
S1
S2
S3
Bp,Q
0.087
–
–
0.118
–
–
0.136
–
–
HB12,R
0.071
0.050
–
0.029
0.108
–
0.009
1.573
–
HBp,R
0.016
0.024
0.027
0.011
0.068
0.049
0.043
1.230
0.898
7.4
Discussion
We have performed a systematic study of the modiﬁed 6-p Lennard-Jones potential
for liquid and gaseous argon using Hierarchical Bayesian inference with data from
experiments and quantum mechanics simulations.
Our results show that the value p = 12 of the repulsive exponent needs to be
calibrated together with the other LJ parameters. In the case of liquid argon we
obtain much better predictions with a smaller value p = 6.5, while for the gaseous
argon the classical p = 12 or slightly bigger p = 12.7 results in a better agreement
with the data.
Our results contradict the conclusion of Ref. [48], where LJ potentials with p =
10, 12, 14, 16, 18, 20 were ﬁt to viscosity and pressure data, and the potential with
p = 12 showed better agreement for diﬀerent thermodynamic conditions.
This
mismatch can be explained by the fact that diﬀerent data was used and also that
the exponents below 10, which appear to be the best according to the results of the
current study, were not tested in Ref. [48].
Taking into account the diﬀerences in ε and σ (Fig. 7.2), as well as in p, we con-
clude that one cannot use the same values of the LJ parameters for liquid, saturated
vapor and gas.
Smaller values of the repulsion exponent (p ∈(6, 9)) in the Lennard-Jones po-
tential provide better predictions for RDF (Fig. 7.5), density and diﬀusion data
(Fig. 7.6) than the conventional p = 12 or p = 12.7 inferred from the quantum cal-
ibrations. Additionally, these new LJ exponents allow to simulate a larger variety

76
Chapter 7. Argon Modeling
of thermodynamic conditions, as compared to the classical 12.
We have also examined whether the smaller exponent allows for bigger time steps
in MD simulations. However, it appears that the exponent is not a critical factor for
the stability of the system. We observed similar execution times for the simulations
with MPVs of LJ 6-12 and LJ 6-p.
From the computational point of view, usage of the kriging surrogates inside
BASIS in Π4U resulted in a speed-up of 28%.

Chapter 8
Translocon Modeling
The work described in this chapter is done in collaboration with the group of Prof.
Dr. T. F. Miller from the California Institute of Technology.
The transmembrane channel Sec translocon is an essential piece of molecular ma-
chinery for protein biosynthesis. It has two main functions: the secretion of newly
synthesized proteins across the lipid membrane, and the integration of proteins into
the membrane. Understanding the mechanisms in the translocon is necessary for
gaining insights into the early stages of the protein folding and targeting in the cell.
Available computational techniques for simulating the interactions of the translo-
con with the newly synthesized proteins, were, until recently, unable to reach the
minute-long timescales, which are of the crucial relevance for protein biosynthesis.
However, with a newly developed coarse-grained approach of Niesen et al. [91], ex-
cessively long simulations of protein biosynthesis can now be done. In this work, we
improve the proposed coarse-grained model of the translocon, enhancing its predic-
tive capabilities.
8.1
Computational Model
The coarse-grained model of interest [91] is used for simulating the protein translo-
cation and membrane integration via the Sec translocon. It features an accurate
geometry of the ribosome and Sec translocon, obtained directly from the experi-
mental observations. The model has the CG beads corresponding to the following
77

78
Chapter 8.
Translocon Modeling
elements: the translocon, the lateral gate, and the ribosome (Fig. 8.1a). The lateral
gate can be either open, or closed.
The model is fully described in Ref. [91], and in this work we only consider the
parameters of interest. These parameters can be divided into two groups: 1) pa-
rameters describing the interactions of the nascent polypeptide chain (NC) with the
translocon, 2) parameters describing the interactions of the NC with the membrane.
The interactions between the NC beads and translocon beads are modeled using the
Lennard-Jones (LJ) potential. The parameters of this interaction are diﬀerent for
the inner and outer part of the translocon (see Fig. 8.1b). The outer beads interact
with NC with the LJ parameters ε1, σ1, and the inner beads (called “conﬁned”)
use ε2, σ2. The size of the conﬁned bead region is controlled by the parameters xm
(start of the region in the vertical direction), xr (thickness of the region), and r (ra-
dius of the region in the horizontal direction), see Fig. 8.1b. The interactions of NC
with the membrane are governed by the membrane radius mr and the membrane
thickness mx (see Fig. 8.1b).
8.2
Parameters Calibration
The CG translocon model has 9 parameters: σ1, σ2, ε1, ε2, xm, xr, r, mx, mr.
In the simulations, we measure the potentials of mean force (PMF) for a bead
located at diﬀerent positions in the lateral gate. We then match the resulting force
proﬁle to that obtained using the MARTINI [86] CG force-ﬁeld.
Translocation
PMFs are calculated for homogeneous leucine (L) and aspartate (D) tripeptides in
two channel conﬁgurations, open O and closed C. This makes four cases in total:
DC, DO, LC, LO. The data used for calibration is presented on Fig. 8.2a.
In order to construct the model which best represents the experimental data and
provides reasonable predictions, we build a sequence of models M1−M5 of diﬀerent
complexity and select the best of them given the data. The best model is then used
in predictive simulations. The unchangeable parameters of models M1 −M4 are
obtained from physical considerations. All the parameters of M5, which are not used
in the inference, are set to their posterior MPVs obtained in optimization. Leaving
the membrane parameters free allows to pick consistent values for the location of the
lipid bilayer for all four target proﬁles in the hierarchical Bayesian inference. The
parameters of all the models and their prior values are summarized in Table 8.1,
Table 8.2.

8.2. Parameters Calibration
79
y
Lateral gate
Translocon
Membrane
Nascent chain
Ribosome
x
(a) Nascent polypeptide chain, produced by the ribosome, goes through the open lateral
gate.
xm
xr
r
x
y
mr
mx
(b) Conﬁned bead region and geometrical parameters of the model.
Figure 8.1: Schematic representation of the coarse-grained model of the Sec translo-
con.

80
Chapter 8.
Translocon Modeling











	



	
(a) Data: PMF proﬁles obtained using MARTINI interactions.











	



	
(b) Posterior MPVs of M5 compared to the data.
Figure 8.2: Bayesian inference using PMF proﬁles.

8.2. Parameters Calibration
81
Table 8.1: Parameters of M1 −M4. Parameters under inference are given with
their uniform prior bounds. For the parameters not used in the inference, the values
are given. The values on the left side of the slash (’/’) are for the D substrate, while
the values on the right side correspond to the L substrate.
σ1
σ2
ε1
ε2
xm
xr
r
mx
mr
M1 [0.8, 1.5] [0.8, 1.5] [0.3, 10] [0.3, 10] -0.1/0.3 1.2/0.7 2.2/1.5
2
1.5
M2 [0.8, 1.5] [0.8, 1.5] [0.3, 10] [0.3, 10]
[-2, 2]
[0, 4]
[0, 4]
2
1.5
M3 [0.8, 1.5] [0.8, 1.5] [0.3, 10] [0.3, 10] -0.1/0.3 1.2/0.7 2.2/1.5 [1.5, 2.5] [1.5, 2.5]
M4 [0.8, 1.5] [0.8, 1.5] [0.3, 10] [0.3, 10]
[-2, 2]
[0, 4]
[0, 4]
[1.5, 2.5] [1.5, 2.5]
Table 8.2: Parameters of M5.
Parameters under inference are given with their
uniform prior bounds. For the parameters not used in the inference, the values are
given.
σ1
σ2
ε1
ε2
xm
xr
r
mx
mr
DC
1.13
1.19
0.54
0.68
-0.06
2.05
2.31
[1.5, 2.5]
[1.5, 2.5]
DO
0.91
1.13
0.66
0.30
-0.23
3.61
1.83
[1.5, 2.5]
[1.5, 2.5]
LC
0.80
0.82
0.42
1.93
0.57
0.38
3.39
[1.5, 2.5]
[1.5, 2.5]
LO
1.00
1.18
0.38
0.85
-0.40
1.41
2.81
[1.5, 2.5]
[1.5, 2.5]

82
Chapter 8.
Translocon Modeling
We use BASIS algorithm [106] and the HB approach from Ref. [129] to perform
all the inferences in this chapter.
The optimization is done with the CMA-ES
algorithm [64, 63]. All of the algorithms are implemented in our framework Π4U [60].
In the Bayesian inference, we assume the following covariance matrices in the
prediction error equation Eq. (2.1):
Σc = 0, Σe = diag(σ2
m,i), Σm = σ2I ,
(8.1)
where σm,i are the error bars of the data (Fig. 8.2a) and σ is to be inferred. Ac-
cording to the results of the Bayesian inference, the M5 greatly outperforms all the
other models in all the cases (see Table 8.3).
Table 8.3: Log-likelihood values of all the models.
DC
DO
LC
LO
M1
-120.12
-87.76
-75.74
-69.35
M2
-71.82
-65.88
-80.28
-58.49
M3
-115.33
-75.23
-66.90
-67.83
M4
-71.62
-59.62
-66.36
-51.28
M5
-45.54
-38.88
-38.51
-22.66
In the HB inference, we use the uniform hyper-prior model with wide enough
bounds.
The hierarchical calibration has identiﬁed the most probable posterior
values and the quantiles of the parameters of this model (Table 8.4). The PMF
proﬁle obtained using MPVs ﬁts the data well (see Fig. 8.2b). The most probable
parameters of M5 improve the original ﬁt in all the cases (compare to Fig. 2B from
Ref. [91], especially for x < 0 in the DC setting and −1 < x < 1 in the LO setting).
We note that the model error parameter σ is of the order of 25% of the typical value
of the PMF.
Table 8.4: Posterior information obtained in the HB inference for each of the pa-
rameters ϑ ∈{mx, mr, σ} of M5: MPV b(ϑ), 5%-95% quantiles q(ϑ).
b(mx)
q(mx)
b(mr)
q(mr)
b(σ)
q(σ)
M5
1.99
[1.64, 2.49]
2.03
[1.79, 2.49]
0.55
[0.21, 0.90]

8.3. Forward Uncertainty Propagation
83
8.3
Forward Uncertainty Propagation
The proteins generated by the ribosome can behave in two diﬀerent ways: they
either translocate across the lipid membrane by passing the translocon, or integrate
into the membrane via the translocon lateral gate. The probability of integration
of polypeptide segments is, to some extent, governed by the dynamics of protein
synthesis [77, 55]. We use M5 to predict the probability of protein integration into
the lipid membrane. The experimental data comes from the work of Hessa et al. [68].
We observe that the result of M5 (Fig. 8.3a) is almost indistinguishable from
the one of the original model in Ref. [91], Fig.4B.
In order to improve the ﬁt, we have decided to scale the MARTINI PMF proﬁles.
Fig. 8.3b presents the results obtained using the force proﬁles scaled by 50% and
80%. We found that the higher scaling factors lead to very long trajectories due to
high barriers for the translocation of charged residues. Against the expectations,
the results remain almost the same, as compared to the unscaled proﬁles.
As a next step, we have tried to scale only the MARTINI proﬁles corresponding
to the D substrate. This allowed us to assess the eﬀect of changing the barrier for
translocation of a aspartate, while leaving the hydrophobic leucine (L substrate) un-
aﬀected. Now, the computed probability of integration shows an excellent match to
the experimental one for the MARTINI PMF of aspartate scaled by 50% (Fig. 8.3c).
The parameters of M5 used in this setting are reported in Table 8.5.
We see (Fig. 8.4) that the diﬀerence in the old M5 and the new M5 parameters
lies in the ε2 and the geometrical parameters (the thickness of the conﬁned bead
region xr and its radius r, the radius and thickness of the membrane mr and mx).
8.4
Discussion
We have considered a coarse-grained model of a transmembrane channel Sec translo-
con. By applying the optimization and sampling algorithms from the Π4U frame-
work, we have considerably improved the model performance in terms of its resem-
blance of the MARTINI PMF proﬁles. We have applied the updated model to the
simulation of protein integration/translocation, however the diﬀerence with the ex-
perimental observations was unsatisfactory. We have further investigated the model
and discovered that changing the barrier for translocation of the hydrophilic D sub-
strate (aspartate), while leaving the hydrophobic L substrate (leucine) unaﬀected,

84
Chapter 8.
Translocon Modeling






	

	
		


	
(a) Original PMF.






	

	
		







(b) Scaled PMF.






	

	
		







(c) Scaled D in PMF.
Figure 8.3: Predictions of probability of integration using M5 and diﬀerent MAR-
TINI PMF datasets. The simulation results are given in the order of increasing the
scaling coeﬃcient from the lightest to the darkest color. All the datasets are ﬁtted
with a hyperbolic tangent.

8.4. Discussion
85
Table 8.5: Information about the parameters of M5 obtained using the data with
D proﬁles scaled by 50%.
(a) Values of the parameters of M5 not used in the inference.
σ1
σ2
ε1
ε2
xm
xr
r
DC
1.03
1.06
0.45
0.91
-0.16
1.66
2.57
DO
0.94
0.90
0.44
0.78
-0.21
3.88
1.82
LC
0.87
0.82
0.43
2.24
0.51
0.37
1.64
LO
0.98
1.18
0.39
0.86
-0.30
1.22
2.86
(b) Posterior information gathered in the HB inference for each of the parameters ϑ ∈
{mx, mr, σ} of M5: MPV b(ϑ), 5%-95% quantiles q(ϑ).
b(mx)
q(mx)
b(mr)
q(mr)
b(σ)
q(σ)
M5
1.55
[1.54, 2.43]
1.81
[1.65, 2.42]
0.42
[0.2, 1]













	







Figure 8.4: Parameters of M5 for the original MARTINI PMF datasets (ﬁlled cir-
cles) and D-scaled datasets (empty circles).

86
Chapter 8.
Translocon Modeling
provides an extremely good match to the experimentally observed probabilities of
integration. In terms of the model parameters, this result was obtained by adjust-
ing the conﬁned bead region size and the interactions of its atoms with the nascent
protein chain.

Chapter 9
Blood Modeling
This chapter aims at studying the behavior of one red blood cell (RBC) under
various conditions. We investigate the Dissipative Particle Dynamics-based RBC
model of Li et al. [82] using experimental data on RBC in stretching and in a simple
shear ﬂow. The ﬁne-grain particle-based RBC model was ﬁrst proposed by Discher
et al. [31] and further developed by Li et al. [82]. In this thesis we use a coarse-grain
representation of this model developed by Pivkin et al. [97] and further studied by
Fedosov et al. [41, 40].
9.1
Computational Model
Our method of choice for RBC modeling is Dissipative Particle Dynamics (DPD), a
powerful mesoscale simulation method allowing the investigation of various atomistic
systems on a coarse-grained level. Because of the coarse representation, it is possible
to study larger and more complex systems with DPD, as compared to Molecular
Dynamics (MD).
The chosen blood model consists of two essential parts: the solvent and the
RBCs. The solvent is modeled using DPD described in Section 9.1.1. The RBCs
are modeled as a mesh of DPD particles connected with springs which interact with
potentials given in Section 9.1.2.
87

88
Chapter 9. Blood Modeling
9.1.1
Solvent
Dissipative particle dynamics (DPD) is a multi-particle model. A pairwise force acts
on each particle Fij [57, 70, 37] and change its velocity (vi) and position (ri):
dri
dt = vi,
dvi
dt = 1
m
X
j̸=i
Fij .
(9.1)
The force Fij consists of three parts: conservative force F C
ij , dissipative force F D
ij
and random force F R
ij
Fij = F C
ij + F D
ij + F R
ij .
(9.2)
The forces are
F D
ij = −mγswD(rij)(eij · vij)eij,
(9.3)
F R
ij = mσswR(rij)θseij,
(9.4)
F C
ij = asσswC(rij)eij. ,
(9.5)
where the weighting functions wD(rij) and wR(rij) as well as dissipation coeﬃ-
cient γs and random coeﬃcient σs are related so that they satisfy the ﬂuctuation-
dissipation balance [37]
wD(rij) = (wR(rij))2,
γs =
σ2
s
2kBT .
(9.6)
We deﬁne rij = ri −rj, rij = ||rij|| and eij = rij/rij as relative position,
distance and unit vector between two particles i and j. kB is the Boltzmann constant
and T is the temperature. vij = vi −vj is the relative velocity, and θs is a Gaussian
random variable with the properties [57]
θs(t) = 0,
θs(t)θkl(t′) = (δikδjl + δilδjk)δ(t −t′) .
(9.7)
We choose standard weighting functions wD(rij), wR(rij) and wC(rij) [57]
wD(rij) = (wR(rij))2 = (wC(rij))2 =






1 −rij
rc
2
, rij < rc
0, rij ≥rc
.
(9.8)

9.1. Computational Model
89
9.1.2
RBC model
We use the RBC model proposed in [82]. Within this model the RBC membrane, as
well as the internal and external ﬂuids, are modeled with DPD particles. An RBC
is represented by a set of Nv vertexes that form a 2-d triangulated network with Ns
edges and Nt triangles (see Fig. 9.1).
Figure 9.1: RBC membrane.
The conditions imposed on the cell are: volume and area conservation, bend-
ing constraints, and prescribed spring behavior. Thus, the forces acting on each
membrane particle from the other membrane particles are given by the following
sum [92]:
F cell =
N
X
n=1
F dihedral,1
n
+ F dihedral,2
n
+ F triangle
n
+ F bond
n
,
(9.9)
where n is the index of a neighboring vertex, N is the number of neighbors of the
vertex under consideration.
The force components are [40]:
F dihedral,1
n
= βn,n+1
ξn × an+1 + ξn+1 × an
ξnξn+1
−cos θn,n+1
ξn × an
ξ2n
+ ξn+1 × an+1
ξ2
n+1

,
(9.10)
representing the bending force due to the angle between the triangles with vertexes
(0, n, n + 1) and (0, n + 1, n + 2).

90
Chapter 9. Blood Modeling
F dihedral,2
n
= βn,n+N
ξn+N × an
ξnξn+N
−cos θn,n+N ξn × an
ξ2n

,
(9.11)
representing the bending force due to the angle between the triangles with vertexes
(0, n, n + 1) and (n, n + N, n + 1).
Here, ri is the radius-vector of the particle i, ai = ri −ri+1, ξi is the outer
normal of the triangle (0, i, i + 1) for i <= N and of the triangle (i −N, i, i −N + 1)
for i >= N, θs is the instantaneous angle between ξi and ξj (see Fig. 9.2), and
βs = kb sin θs cos θ0 −cos θs sin θ0
√
1 −cos2 θs
,
(9.12)
where
θ0 = arccos
√
3(Nv −2) −5π
√
3(Nv −2) −3π

(9.13)
is the equilibrium angle and the bending constant kb is user-deﬁned.
4
r3
(0, 0, 0)
3
5
6
2
7
8
0
1
a4
b5
θ1,7
9
10
11
12
A6
ξ2
Figure 9.2: RBC: Interactions of a single vertex.

9.1. Computational Model
91
The component
F triangle
n
= kd A0 −An
A0
ξn × an
4An
(9.14)
+ ka Atot
0
−Atot
Atot
0
ξn × an
4An
(9.15)
+ kv V tot
0
−V tot
V tot
0
ξn + (r0 + rn + rn+1) × an
18
(9.16)
consists of the area conservation force for the triangle (0, n, n + 1), the global area
conservation force and the volume conservation force, respectively. Here, Atot
0
(V tot
0
)
is the target RBC area (volume) deﬁned from experiments, Atot (V tot) is the instan-
taneous RBC area (volume). A0 = Atot
0 /Nt is the target area of each triangle, An is
the instantaneous area of the triangle (0, n, n + 1), Nt = 2(Nv −2). The constants
kd, ka, kv are user-deﬁned.
Finally, the bond force of the spring (0, n) consists of the worm-like chain force,
dissipative force and random force, given by
F bond
n
= −kBT
p

1
4(1 −xn)2 −1
4 + xn

+ kp
b2n
(9.17)
−γC(3vij + (vij · eij) eij)
(9.18)
+ 2
p
3kBTγCdW S
ij eij ,
(9.19)
where kB is the Boltzmann constant, T is the system temperature, bn = ||rn −r0||.
The matrix in the random component is dW S
ij = dW S
ij −tr[dW S
ij]1/3, where dWij
is a random matrix of independent Wiener increments and dW S
ij is its symmetric
part: dW S
ij = (dWij +dW T
ij )/2. Other parameters are computed from the following
relations:
xn = bnx0/l0,
(9.20)
kp = kBT(4x2
0 −9x0 + 6)l2
0
4(x0 −1)2p
,
(9.21)
where l0 =
q
4A0/
√
3 is the spring equilibrium length. The parameters x0, p and
γC are user-deﬁned.

92
Chapter 9. Blood Modeling
9.1.3
Simulation Setup
The default parameter values are the following: Nv = 498, as = 5, γs = 15,
kBT = 0.1, rc = 1.5, x0 = 0.45, p = 2 × 10−3, γC = 10, ka = 5000, kd = 200,
kb = 100, kv = 5000. Unlike in MD, the DPD units are not directly connected to
the physical units. We thus have to match the simulation and the experiment in
some other way, e.g. through characteristic non-dimensional numbers.
9.2
RBC Parameters
The parameters of the RBC model to be calibrated are the inverse maximum spring
extension x0, the spring persistence length (p), the membrane viscosity (γC) and
the membrane bending rigidity (kb). The area and volume conservation constants
should be big enough for the membrane and the RBC itself to be incompressible.
There have been several studies of the membrane parameters of the chosen RBC
model [41, 82]. In Ref. [82] the authors adjust one of the derived parameters of
the model to ﬁt the stretching data. In Refs. [41, 40] the authors study various
experiments, including stretching, placing RBC in a shear ﬂow, and attaching a
micro-bead to it. The obtained parameters provide a good ﬁt for the experimental
data, however no uncertainty bounds are provided.
We consider two experiments: stretching of an RBC and its rotation in a simple
shear, which allow us to infer all the RBC parameters, except for the bending
constant kb.
9.3
Red Blood Cell Stretching
We analyze the elongation of the RBC subject to various stretching forces. The
experimental data comes from Ref. [116] and is depicted in Fig. 9.3. The stretching
force is measured in pN.
We choose 2% of the membrane vertexes from two opposite sides of the blood cell
to apply the stretching force. To measure the RBC diameters, we bring the cell to
its principal axes and determine the maximum and minimum coordinates in the two
directions of interest. For obtaining the maximum (minimum) coordinate, we take
an average value over the 7 vertexes with the maximum (minimum) coordinates.
The number is chosen to be the typical degree of a vertex in the triangulation plus

9.3. Red Blood Cell Stretching
93
0
50
100
150
200
stretching force
4
6
8
10
12
14
16
18
20
RBC diameters
Figure 9.3: Experimental values of the axial and transverse diameters of an RBC
stretched with optical tweezers [116].
one (the vertex itself).
Before doing the parameter calibration, we did the resolution study and the
sensitivity analysis of the RBC parameters. We observe that 500 vertexes is enough
to resolve the stretching experiment (see Fig. 9.4), which is in agreement with the
results of Ref. [41].
Figure 9.4: Stretching of RBCs at diﬀerent resolutions. Yellow: Nv ∼500, red:
Nv ∼2000, blue: Nv ∼8000.
Investigating the eﬀect of the various RBC parameters onto the axial and trans-
verse RBC diameters, we found that only the spring parameters p and x0 change
the model behavior, see Fig. B.1, Fig. B.2.

94
Chapter 9. Blood Modeling
To relate the DPD simulation to the physical reality, one needs to choose unit
scaling. The time scale does not play a role in this setting. The length scale is also
of no importance, as one can normalize the data (axial and transverse diameters)
to the RBC size under zero stretching force. According to the form of the bond
force (Eq. (9.17)), setting the force scale is equivalent to changing p. We thus set
an arbitrary force (mass) scale to 0.025 pN, meaning that one DPD unit of force
corresponds to 0.025 pN.
9.3.1
Parameters Calibration
In order to reduce the computational eﬀort, we will construct and use a surrogate
model. The sensitivity analysis has shown that only the bond force parameters aﬀect
the result of the stretching procedure, thus the surrogate should only depend on p
and x0. As was noticed above, the persistence spring length p linearly rescales the
force acting on the spring. For this reason, one can compute the axial and transverse
diameters for one value of p only (and multiple forces and values of x0) and obtain
the diameters for a diﬀerent p by linear scaling. Now, the surrogate only depends
on one parameter and can be constructed by a simple polynomial interpolation.
We ran the stretching experiment for the values of x0 ranging from 0.3 to 0.6
and ﬁtted the diameters for each of the cases using the following functional form:
f(x) = a + (1 −a)e−tx ,
(9.22)
where x takes the values of force and a and t are the ﬁtting parameters. The result
of one of the ﬁtting is presented on Fig. 9.5.
Now, we build an approximation for the parameters of the ﬁtting function for
diﬀerent values of x0. We use polynomials up to degree 5, their coeﬃcients are given
in Table 9.1. The plots of the approximations are given on Fig. 9.6. These approx-
imations are only intended to be used for interpolation. They prescribe a relatively
simple functional form which provides an almost linear interpolation between the
data points. From the Eq. (9.22), it is evident that for p′, which is diﬀerent from p
for which the approximation was computed, one needs to rescale t as t′ = t · p/p′.

9.3. Red Blood Cell Stretching
95
















	

	


	


Figure 9.5: Example of ﬁtting the RBC diameters under stretching with the function
from Eq. (9.22).
Table 9.1: Coeﬃcients of the polynomial approximation of parameters a, t from
Eq. (9.22) as a function of x0. Coeﬃcient ci corresponds to degree i.
c0
c1
c2
c3
c4
c5
a (axial)
5.6
-11.07
7.38
0.0
0.0
0.0
t (axial, x0 < 0.325)
0.01448
-0.00222
0.0
0.0
0.0
0.0
t (axial, x0 ≥0.325)
0.0212
-0.0268
0.0123
0.0
0.0
0.0
a (transverse)
-16.465
208.7
-1010.7
2387.8
-2746.0
1233.7
t (transverse)
0.339
-2.378
6.456
-7.72
3.393
0.0

96
Chapter 9. Blood Modeling










	
(a) Parameter a for the axial diameter.







	



(b) Parameter t for the axial diameter.









(c) Parameter a for the transverse diameter.









	
(d) Parameter t for the transverse diameter.
Figure 9.6: Approximation of the ﬁtting function (Eq. (9.22)) parameters.
We assume the following terms in the prediction error equation Eq. (2.1):
Σe,η = diag(σ2
e,η,i),
(9.23)
Σm,η = σ2
ηI,
(9.24)
Σc,η = diag(σ2
c,η,i) ,
(9.25)
where η ∈[a, t] indicates the axial and transverse diameters. The index i corresponds
to the diﬀerent stretching forces. The values of σa,e,i and σt,e,i are the errorbars
from Fig. 9.3. The computational errors are negligibly small, as compared to the
experimental ones, and we take σa,c,i = σt,c,i = 0. The model errors σa and σt are
to be inferred.
Not possessing any information about the model parameters, we assume the
uniform prior with wide enough bounds (see Table 9.2). We perform the calibration
using TMCMC with 10’000 samples per stage. The algorithm converges in 5 stages,

9.3. Red Blood Cell Stretching
97
taking about a minute for a serial run.
After running the inference, we observe an unidentiﬁable manifold in the (x0, p)
space, Fig. 9.7. This shows that the spring parameters should be changed simulta-
neously in order to obtain the correct model behavior. This is an expected result,
since p is inversely proportional to the strength of the spring, while increasing x0,
on the contrary, makes the spring stronger. Both p and x0 are well-deﬁned given
the stretching data, with a preference for medium values of x0 and small values of p.
We note that the model errors σa, σt are small compared to the experimental error
(0.4±0.3 vs 1.2±0.4 for the axial diameter and 0.3±0.2 vs 0.7±0.1 for the transverse
diameter).
Figure 9.7: Results of parameter calibration of the RBC membrane parameters using
TMCMC (see Notations).

98
Chapter 9. Blood Modeling
Table 9.2: Prior and posterior information on the spring parameters of the RBC
membrane model.
Prior bounds
Posterior MPV
Posterior 5%-95% quantiles
x0
[0.3, 0.6]
0.457
[0.332, 0.484]
p
[0.001, 5]×10−2
0.136×10−2
[0.101, 0.391]×10−2
σa
[10−6, 1]
0.019
[0.015, 0.554]
σt
[10−6, 1]
0.052
[0.037, 0.675]
9.3.2
Forward Uncertainty Propagation
We propagate the sampling and model uncertainty into the diameters of the RBC
under stretching and into the frequency of the RBC rotation in the shear ﬂow using
Eq. (2.6).
The quantiles of the robust posterior distribution for the diameters are given on
Fig. 9.9.
0
50
100
150
200
stretching force
4
6
8
10
12
14
16
18
20
RBC diameters
Figure 9.8: Posterior predictions of RBC diameters under stretching.
Red line:
experimental data, blue line: posterior MPV, blue area: 5%-95% quantiles.
There exist three diﬀerent behaviors of RBCs in shear ﬂow. For low shear rates
RBCs tumble [35], for medium shear rate they swing [4], and for high shear rates
cells tank-tread [118]. As the experimental data is available for tumbling and tank-

9.4. Red Blood Cell in Shear Flow
99
treading, we propagate the uncertainty in the RBC parameters to these two modes.
The quantiles of the robust posterior distribution are given on the Fig. 9.9.
0
5
10
15
20
normalized shear rate
0
2
4
6
8
10
12
14
16
18
20
B  (A + A-1)
(a) Tumbling mode.
0
1000
2000
3000
4000
5000
6000
7000
normalized shear rate
0
500
1000
1500
normalized TTF
(b) Tank-treading mode.
Figure 9.9: Posterior predictions of the frequency of RBC in shear ﬂow. Calibration
using the data on stretching. Original model. Red line/crosses: experimental data,
blue line: mean and 5%-95% quantiles of the predictions. Data from [35] and [118].
Predictions made by the model are very accurate for tumbling. This good ﬁt
can be explained by the simplicity of the motion: in this case an RBC rotates as a
solid body. On the other hand, the predictions for a more complex movement, such
as tank-treading, are inferior. The slope of the line is not predicted correctly and
the point at ≈140s−1 does not lie close to the line. The next section investigates
this issue.
9.4
Red Blood Cell in Shear Flow
There exist several experimental datasets describing tank-treading of a single RBC [118,
45, 46, 47]. The data consists of the RBC tank-treading frequency (TTF) measured
for various shear rates, see Fig. 9.10. To put all the data on one plot, we rescale the
reported shear rate multiplying it by viscosity. The shear rate is measured in 1/s.

100
Chapter 9. Blood Modeling
The TTF is measured in rad/s. A linear ﬁt describes well all of the experiments,
although for certain cases the exponential ﬁt provides slightly better results [47]. We
see a signiﬁcant variation in the slopes of the linear ﬁts of TTF (Table 9.3). There-
fore, we have decided to focus on the dataset of Fischer (1980), since it exhibits the
smallest error of the linear ﬁt (0.5%).







	

	












Figure 9.10: RBC tank-treading frequency in the shear ﬂow along with the linear
ﬁt. The shear rate is normalized with the viscosity of the solvent. The experiments
are listed in the order of viscosity increase (from blue to red).
We adjust the solvent parameters to match the viscosity contrast of the chosen
dataset. We set γi = 5, γo = 11.5, where the subscript o corresponds to the solvent
outside the RBC, and i corresponds to the solvent inside the RBC.
9.4.1
Parameter Calibration
Following the same approach as for the stretching, we perform a local sensitivity
analysis to determine which parameters aﬀect the TTF. We found that 3 parameters
are sensitive: the two spring parameters x0 and p and the membrane viscosity
parameter γC (see Fig. B.3, Fig. B.4). Since the spring parameters were already
calibrated in the stretching experiment, we proceed with determining the membrane
viscosity.
Before doing the calibration, we found it necessary to increase the local area
conservation parameter, as otherwise the triangles were collapsing at high shear

9.4. Red Blood Cell in Shear Flow
101
Table 9.3: Linear ﬁts and their errors for RBC tank-treading frequency in the shear
ﬂow.
Reference
Viscosity (cP)
Slope
Error
Fischer (1978)
11.0
0.140
8.15%
Fischer (1978)
18.0
0.153
4.02%
Fischer (1980)
23.0
0.185
0.50%
Fischer (2007)
28.9
0.175
3.27%
Fischer (1978)
31.0
0.152
2.51%
Tran-Son-Tay (1984)
35.0
0.217
0.88%
Fischer (1978)
59.0
0.161
3.29%
rates (see Fig. 9.11). This appeared to also be the reason of the non-linear behavior
in Fig. 9.9b.
Figure 9.11: Collapse of the triangles at shear rate 12 in DPD units. Left: kd = 200,
right: kd = 5000.
After that, we have performed a resolution study, which suggested that, as for
the stretching, 500 points is enough to resolve the RBC rotation (see Fig. 9.12).
In order to speed up the computations, we construct a surrogate model which re-
places the expensive runs of the shear ﬂow simulation. Since we have only one param-
eter, we constructed a simple interpolating polynomial (referred to as “surrogate”),
see Fig. 9.13. The coeﬃcients of the surrogate are c0 = 0.196, c1 = −6.88 × 10−4,
c2 = 3.96 × 10−6. As before, ci corresponds to the degree i. The variance of the
residuals of the ﬁt is 8.46×10−3.
Since there is only one measurement, the prediction error equation covariances,

102
Chapter 9. Blood Modeling
Figure 9.12: Resolution study of RBC in shear ﬂow.
Yellow: Nv ∼500, red:
Nv ∼2000.








	






	
Figure 9.13: Approximation of the TTF as a function of γC.

9.4. Red Blood Cell in Shear Flow
103
Table 9.4: Prior and posterior information about the parameters of the RBC mem-
brane in the shear ﬂow experiment.
Prior bounds
Posterior MPV
Posterior 5%-95% quantiles
γC
[0, 60]
17.8
[3.62, 53.5]
σ
[0.01, 100]×10−4
7.66×10−4
[5.94, 95.3]×10−4
as deﬁned in Eq. (2.1), simplify to:
Σe = σ2
e, Σm = σ2, Σc = σ2
c ,
(9.26)
The experimental error in this case (measured as the error of the TTF ﬁt) is
negligibly small, and thus σe = 0.
The computational error is taken from the
surrogate ﬁt, σc = 8.46 × 10−3. The model error σ is to be inferred.
Using this surrogate, we run TMCMC with 10’000 samples per stage. In this
case, we have decided to limit the model error to 0.01, so that it is close to the
other error terms. We observe that the prior range for γC does not get signiﬁcantly
reduced, but the shape of the distribution changes (see Fig. 9.14). The inference has
identiﬁed the posterior most probable value of the membrane viscosity parameter
(see Table 9.4), which can be used in the further RBC model investigation.
9.4.2
Forward Uncertainty Propagation
We now propagate the posterior uncertainty in γC into the tank-treading motion of
a single RBC, see Fig. 9.15. The prediction is now linear, unlike in Fig. 9.9b. We
observe that the spread of the uncertainty increases for high shear rates. This is a
natural consequence of the uncertainty in the TTF slope.
To further investigate the predictive capabilities of the considered RBC model,
we study its behavior in the shear ﬂow at low shear rates. This setup was fully
studied by Dupire et al. [35], who observed the following qualitative behavior. At
very low shear rates, the cell performs a ﬂipping motion (Fl), characterized by the
rotation of its axes in the direction of the ﬂow and swinging of the axis orthogonal
to the ﬂow (see Fig. 9.16).
When the shear rate is increased, the cell selects from the wheel-like (W) and the
frisbee-like (Fr) motions, which are followed by the tank-treading (TT) as the shear

104
Chapter 9. Blood Modeling
Figure 9.14: Posterior distribution of the RBC membrane viscosity parameter γC
obtained with TMCMC (see Notations).
0
2000
4000
6000
8000
10000
12000
normalized shear rate
0
500
1000
1500
2000
2500
normalized TTF
Figure 9.15: Robust posterior quantiles of TTF obtained after calibrating the mem-
brane viscosity parameter. Red line: experimental data, blue line: posterior MPV,
blue area: 5%-95% quantiles of the predictions.

9.4. Red Blood Cell in Shear Flow
105
(a) Flipping.
(b) Wheel-like motion.
(c) Frisbee-like motion.
Figure 9.16: Schematic representation of RBC motion in various shear rates.
rate is further increased. In the W and Fr types of motions one of the cell’s axes
orthogonal to the ﬂow direction is ﬁxed and the other two are rotating in a plane
(see Fig. 9.16). In all the types of motion, except for the TT, the RBC behaves like
a solid object, meaning that it’s almost not deformed.
If the cell is placed in a high shear rate subject to a further decrease of the shear
rate, the sequence of transformations is slightly diﬀerent. First, the cell tank-treads,
after which it enters the intermittent regime of Fl-TT, followed by W and ﬁnally
pure Fl.
It turns out that the paths which the cell takes while deforming from Fl to TT
with the increase of the shear rate and from TT to Fl with the decrease of the shear
rate, diﬀer not only qualitatively, but also quantitatively. The authors in Ref. [35]
have also measured the critical stresses, required to trigger the solid-to-ﬂuid and
ﬂuid-to-solid RBC transformations. The values found are 0.099 Pa and 0.297 Pa,
which is in agreement with the observations of Abkarian et al. [4], where is critical
stress was found to be of the order of 0.1 Pa.
We use the most probable posterior parameters, calibrated using the stretching
diameters and the TTF, to run the RBC model in the shear rate varying from low
to high and vice versa. Our model reproduces all the qualitative features of the
RBC behavior. It gives the correct sequence of transformations for both directions
of shear rate changes and correctly identiﬁes the presence of hysteresis. However,
the predicted critical stress is approximately 3 times higher than that observed in
the experiments ( 0.3 Pa instead of 0.1 Pa).

106
Chapter 9. Blood Modeling
On the other hand, the UQ-based calibration gives us a whole distribution of
the possible model parameters. The less likely parameters in the area of low x0
values result in a critical stress equal or even smaller than the experimental one,
while keeping the right sequence of transformations and the hysteresis. This eﬀect
can be explained by the changes in the membrane shear modulus. The area of small
values of x0 in the RBC parameter distribution corresponds to the low values of
the membrane shear modulus, which means a highly deformable cell. As a result,
such a cell needs less stress to become ﬂuid-like. At the same time, a more soft cell
stretches easier, which means that its axial and transverse diameters (see Fig. 9.9)
are not optimal.
This shows that optimizing the parameters with respect to a given experiment
is sometimes too restrictive and not suﬃcient to make a consistent model, while a
more relaxed Bayesian methodology allows to ﬁnd a compromise between diﬀerent
experimental data sets.
9.5
High performance computing
This section presents estimates on the speed-up gained with a help of the surrogates.
We performed our computations on Piz Daint cluster of the Swiss National Su-
percomputing Center (CSCS). The BASIS algorithm was run inside the Π4U frame-
work [60]. The blood cell was simulated using the uDeviceX code [?], implemented
with CUDA.
An average time needed for one stretching run on one GPU is 1 minute. We
have performed 13 runs to build the surrogates, spending in total 13 GPU-minutes.
The run-time of BASIS with 10’000 samples and these surrogates was 1.5 minutes
(6 stages) on a single CPU. Its run-time with full model evaluations with the same
number of samples would have been 10’000 minutes per stage, making the total run-
time to be 60’000 minutes, or 1’000 hours on one GPU. The approximate speed-up
is thus 60000/(13 + 1.5) ≈4138 times.
A similar situation arises for shear ﬂow. An average time needed for one shear
ﬂow run on one GPU is 1.4 hours. We have performed 31 runs to build the sur-
rogates, spending in total 43.4 GPU-hours. The run-time of BASIS with 10’000
samples and these surrogates was 15 seconds (2 stages) on a single CPU, which is
negligibly small, as compared to the surrogate construction time. Its run-time with
full model evaluations with the same number of samples would have been 14’000

9.5. High performance computing
107
hours per stage, making the total run-time to be 28’000 hours on one GPU. The
approximate speed-up is thus 28000/43.4 ≈645 times.


Part III
Conclusions and Outlook
109


Chapter 10
Conclusions and Outlook
10.1
Π4U Framework
This thesis presents the following extensions of the Π4U framework:
1) ABC-SubSim algorithm,
2) kriging- and neural network-based surrogates,
3) visualization tools,
4) sensitivity tool.
The Π4U framework is a great tool for running parameter calibration and un-
certainty propagation in cases where performance is a concern. Its adaptive load
balancing and easy coupling with any external software makes Π4U the key frame-
work in the area of HPC-aware Bayesian computations.
The availability of the visualization tools gives a possibility to immediately re-
view and analyze the results. Additional inference tools, such as optimization, sen-
sitivity tool or surrogates, help to get insights into the parameter space geometry
before running the full inference.
The Π4U framework is currently at an intensive development stage. The recent
contributions include: python and MATLAB bindings, multi-objective optimization,
surrogates. Optimal experimental design algorithms are now under development.
However, there is plenty of work to be done, mainly in bringing the framework and
the potential user together.
111

112
Chapter 10.
Conclusions and Outlook
There now exist several branches containing diﬀerent features (e.g. the code for
surrogates is separated from the main branch) which in the future are to be merged
into one. Since all the algorithms use the same target function (the likelihood),
we would ideally like to have a tool to conﬁgure the run by specifying the options,
such as which algorithm to use or which surrogate to use. Based on the algorithmic
similarities outlined in Chapter 5, such a modiﬁcation should be possible. At the
moment the conﬁguration ﬁle only exists for TMCMC and BASIS.
We have recently added a user manual on Π4U, and we are planning to create
a full documentation and the developer guide.
The best possibility to promote
the Π4U framework would probably be to create a website for it and make a user
interface. At the moment, the description of the code and a latest stable code release
can be obtained at cse-lab.ethz.ch/software/Pi4U.
Within this thesis, we have demonstrated the use of the various tools of the Π4U
framework in applications to large-scale problems in Life Sciences and Engineering
discussed in the next section.
The tools we have used are: the sensitivity tool,
the sampling algorithms (TMCMC, BASIS and ABC-SubSim), the optimization
algorithm (CMA-ES), the forward uncertainty propagation tool, the visualization
tools (for samples and model predictions).
10.2
Applications
We have considered four applications of the Bayesian uncertainty quantiﬁcation:
blood, helium, argon and translocon.
Helium Modeling
We have illustrated the application of Subset Simulation for
Bayesian inference in the context of ABC by calibrating the potential well depth
and the well location parameters of the Lennard-Jones potential of helium. The
data was chosen to be the Boltzmann factor distribution over time. Since the data
follows a non-Gaussian distribution, the likelihood can not be formulated, and we
instead applied the ABC.
The ABC inference requires formulating a discrepancy function. To check the
eﬀect of the Gaussian assumption, usual for the likelihood-driven Bayesian uncer-
tainty quantiﬁcation, we have formulated three diﬀerent discrepancies, one of which
is based on the suﬃcient statistics of the Gaussian distribution (mean and variance).
We found that the mean and variance-based discrepancy is not able to reduce the

10.2. Applications
113
uncertainty in the LJ well depth parameter. This suggests that the exact Bayesian
calibration can not replace the ABC, which deﬁnitely has its place among the other
inferences.
When the Gaussian discrepancy was not able to identify the LJ parameters,
we looked into the other two discrepancies: the quantile-based and the relative
entropy. Both of them were able to correctly identify the most probable values and
to reduce the prior uncertainty.
Shell [109] stated that for the MD ensembles a
relative entropy is a natural choice of the discrepancy measure, which is conﬁrmed
by our computations.
The ABC calibration approach is very intuitive, as it only utilizes the comparison
between the data and the simulation outcome. Equipped with a Kullback-Leibler
(relative entropy), ABC provides a direct link to the MD ensemble averaging of
thermodynamic QoIs, resulting in a natural framework for calibration of any types
of force-ﬁelds.
In all of the inferences, we used the full MD simulations. All the inferences were
made on the Piz Daint cluster of CSCS. The LAMMPS script used in the inference
is given in Appendix D.1.
Argon Modeling
We have addressed the problem of calibrating not only the
potential well depth and the well location LJ parameters, but also the repulsion
exponent, which is usually taken to be 12. The target substance was argon and
the calibration data was the radial distribution function (RDF) at six diﬀerent
thermodynamic conditions, among which ﬁve described a liquid argon and one an
argon vapor.
We performed two types of inferences: one with the repulsion exponent ﬁxed to
12, and the other with the free exponent. To assess whether including the exponent
into the calibration set improves the argon model, we have performed several tests:
Bayesian model selection for the cases with a free and a ﬁxed exponent, forward
predictions for the RDF, density and diﬀusion coeﬃcient.
Our results show that including the repulsive exponent into the calibration set
improves the predictions for all the tests and most of the thermodynamic conditions
considered. This outcome is as well supported by the model selection: the structural
model with a free exponent is in four out of six cases better than the ﬁxed exponent
model, in one case they are equally good and in one more case (the only vapor case)
the model with a free exponent is over parameterized.

114
Chapter 10.
Conclusions and Outlook
Since there are several datasets, we perform a hierarchical Bayesian inference
which allows us to split the uncertainty due to parameter variability inside one set
and the uncertainty due to parameter variability among diﬀerent datasets. After ap-
plying the Bayesian inference, we observe the uncertainty reduction in the majority
of the predictions.
In all of the inferences, we used the kriging surrogates to reduce the computa-
tional cost, resulting in a speed-up of 28%. All the inferences were computed on
the Brutus cluster of ETHZ. The LAMMPS script used in the inference is given
in Appendix D.2.
Translocon Modeling
The last example of a Bayesian inference is quantifying
the uncertainties in the coarse-grained translocon model from Ref. [91].
The model contains three main parts: the ribosome, the translocon, and the
protein chain produced by the ribosome. The translocon, in turn, is built from two
types of particles: the normal and the conﬁned one, having diﬀerent LJ interactions
with the nascent protein chain.
The data used for calibration comes from another coarse-grained simulation
which uses the MARTINI force ﬁeld [86]. This simulation computes the force ex-
erted by the translocon onto a bead moved through the channel. Two types of beads
are possible: D, the aspartate, and L, the leucine, and two types of the translocon
conﬁgurations: open and closed, making it four simulations in total.
There are nine parameters of interest in this model: the two sets of LJ parameters
and ﬁve parameters describing the geometry of the translocon and its conﬁned bead
region. Due to a relatively high dimensionality of the problem, we have considered a
number of structural models which assess diﬀerent sets of the translocon parameters.
Using Bayesian model selection, we chose the most plausible structural model. This
model has two parameters: the cell membrane thickness and the translocon width,
while the values of all the other parameters are set to their posterior most probable
values for each of the four MARTINI cases.
The best model was further used for the forward predictions. We have obtained
a closer match for all the four MARTINI force proﬁles, as compared to the original
parameter values from Ref. [91].
We further predicted the probability for the nascent protein chain to be inte-
grated into the cell membrane (versus it being translocated inside the cell), but got
the same result as the original model. This gave us an idea to try diﬀerent scal-

10.2. Applications
115
ings of the MARTINI force proﬁles, allowing for lower barriers for translocation of
either aspartate (D) only, or both substances simultaneously Finally, we found that
scaling the proﬁle for the D substrate by 50% gives an excellent match with the
experimental results.
The potential use of the model includes investigating phenomena, such as po-
sition dependence of the biological hydrophobicity scale [69] and the dependence
of the hydrophobicity on the amino-acid residues ﬂanking the transmembrane do-
mains [67]. Considering these new experiments may aﬀect the already calibrated pa-
rameters and activate the currently insensitive ones, changing the translocon model.
All the inferences were computed on the Piz Daint cluster of CSCS.
Blood Modeling
We have studied a coarse-grained, particle-based model of a
red blood cell from Ref. [40]. The RBC in this model is represented by 500 DPD
particles connected with springs.
Using experimental data on the cell behavior under stretching and in a simple
shear ﬂow, we have calibrated three out of four RBC parameters. The ﬁrst two
parameter, the inverse maximum spring extension and the persistence length of
the spring, were calibrated in the stretching experiment.
The third parameter,
the membrane viscosity, was calibrated in the shear ﬂow experiment. The fourth
parameter, the bending rigidity of the cell membrane, did not aﬀect the results of
either of the two experiments.
To calibrate all the parameters, we used an exact non-hierarchical Bayesian infer-
ence with the BASIS algorithm. In all of the inferences, we constructed polynomial-
based surrogates to reduce the computational cost. All the inferences were made on
the Piz Daint cluster of CSCS. The code used for the simulations is called uDeviceX
and is available at github.com/udevicex.
Our uncertainty propagation results show that the RBC model of Pivkin et
al. [97] provides good agreement with the experiments. The Bayesian UQ method-
ology helped us to identify the RBC membrane parameters which provide a com-
promise between matching the stretching data and the shear ﬂow data.
The future work has several direction:
1) ﬁnish the calibration of the RBC model using an experiment sensitive to
changes in the membrane bending rigidity kb (e.g. micropipette aspiration [38,
32, 31]),

116
Chapter 10.
Conclusions and Outlook
2) calibrate the interactions between the blood cells using measurements of the
whole blood viscosity as a function of the shear rate [125, 88, 43],
3) simulate RBCs behavior in realistic blood vessel geometries,
4) include other elements in the blood model (such as white blood cells [42],
platelets [130] and circulating tumor cells).
Another possible extension of the current blood cell model is introduction of a
cytoskeleton [94], which better represents the actual geometry of an RBC.

Appendix
117


Appendix A
ABC for Likelihood-Driven Bayesian
Inference
This chapter presents a comparison of ABC-SubSim and TMCMC used on the same
problem from the likelihood-driven Bayesian inference.
A.1
Computational Model
The application is calibration of a Force-Displacement (FD) model for steel particles.
We use a 2-d Discrete Element Method (DEM) simulation [17] of the collision of a
particle with a wall, both made of steel. The particle and the wall are represented
by 2-d disks.
The steel properties used in the simulation are the following: Young’s modulus
E = 2.10 × 1010 Pa, Poisson ratio ν = 0.3, disk radius Ri = 0.02225 m, mass
m = 0.3538 kg. The wall disk radius is taken big enough for the curvature of the
wall to be neglected.
At the heart of DEM lies the FD model of the steel particles.
This model
updates the rotational and translational components of a particle movement taking
into account pairwise collisions with other particles and obstacles. According to the
results of Ref. [61], the best model for the normal component of the collision force
is the extended non-linear model [79]:
F n = −knξ3/2
ij
−γn ˙ξijξαn
ij ,
(A.1)
119

120
Appendix A. ABC for Likelihood-Driven Bayesian Inference
where ξij = Ri + Rj −||ri −rj|| is the mutual compression between particles i
and j, the damping coeﬃcient γn and the power αn are model parameters, and the
material property spring constant kn is given by
kn = 2
3
E
(1 −ν)2
s
RiRj
Ri + Rj .
(A.2)
The tangential component of the force is computed according to a modiﬁcation of
the original Cundall and Strack model [18]:
F t = −|ktξt
ij|sign(ξt
ij) .
(A.3)
ξt
ij is the elongation of an imaginary tangential spring from time τ0 (beginning of
the collision) to time τ1 (force evaluation time):
ξt
ij =
τ1
Z
τ0
vt
ij(τ) Θ

µ|F n|
kt
−
τ1
Z
τ0
vt
ij(τ) dτ

dτ ,
(A.4)
where Θ(·) is the Heaviside step function, vt
ij is the relative tangential velocity
between the two particles at their contact point, the imaginary tangential spring
stiﬀness kt and the friction coeﬃcient µ are model parameters. Further details on
the simulation setup can be found in [61].
ri
rj
Rj
Ri
⇠ij
i
j
Figure A.1: Schematic representation of a collision between particles i and j.

A.2. Parameter Calibration
121
A.2
Parameter Calibration
Summarizing the discussion above, the model under consideration has 4 parameters
to be calibrated: the friction coeﬃcient µ, the power αn, the damping coeﬃcient
γn, and the stiﬀness of the imaginary tangential spring kt.
The calibration data comes from Ref. [33] and consists of the normal and the
tangential coeﬃcients of restitution cn
j , ct
j, j = 1, . . . , 6 along with their uncertainties
u(cn
j ), u(ct
j) at diﬀerent impact angles, see Table A.1.
Table A.1: Experimentally measured normal and tangential coeﬃcients of restitu-
tion cn
j , ct
j and their uncertainties u(cn
j ), u(ct
j), j = 1, . . . , 6 depending on the impact
angle φ. Data from [33].
φ (deg)
ct
j
u(ct
j)
cn
j
u(cn
j )
10
0.523
0.010
0.890
0.020
20
0.524
0.014
0.892
0.015
30
0.637
0.044
0.918
0.014
40
0.779
0.013
0.896
0.005
50
0.846
0.024
0.918
0.013
60
0.886
0.024
0.874
0.033
We specialize the components of the prediction error equation Eq. (2.1) as fol-
lows:
Σc = 0 ,
(A.5)
Σe =
 
diag
 u(cn
j )

0
0
diag
 u(ct
j)

!2
,
(A.6)
Σm = σ2
 
diag
 cn
j

0
0
diag
 ct
j

!2
.
(A.7)
In the approximate Bayesian inference, we select a Euclidean discrepancy: ρ(y, d) =
||y −d||2, which resembles the log-likelihood of the likelihood-driven setup. The
model error σ2 is unknown, and we extend the parameter vector to include it:
ϑ = (µ, αn, γn, kt, σ2).
We set the prior PDF to be uniform with large enough
bounds so that they do not aﬀect the inference.

122
Appendix A. ABC for Likelihood-Driven Bayesian Inference
We compare the results of the Bayesian inference using TMCMC and ABC-
SubSim with 50’000 samples per stage each in Table A.2 and Fig. A.2, Fig. A.3.
ABC-SubSim halts with a tolerance equal to 0.06.
Table
A.2:
Prior
and
posterior
information
about
the
parameters
ϑ
∈
{µ, αn, γn, kt, σ2} for ABC-SubSim (A) and TMCMC (T): uniform prior bounds
p(ϑ), posterior MPVs b(ϑ), 5%-95% posterior quantiles q(ϑ), scale s(ϑ).
p(µ)
b(µ)
q(µ)
s(µ)
p(αn)
b(αn) q(αn)
s(αn)
A [5, 20]
10.6
[10.2, 11.1]
×10−2 [1.5, 5.5] 3.99
[2.40, 5.00]
×10−1
T
[5, 20]
10.5
[9.78, 11.2]
×10−2 [1.5, 5.5] 4.24
[2.53, 5.12]
×10−1
p(γn)
b(γn) q(γn)
s(γn)
p(kt)
b(kt)
q(kt)
s(kt)
A [0.1, 10] 4.26
[0.757, 8.54] ×104
[0.1, 1.5] 0.987 [0.335, 1.19] ×100
T
[0.1, 10] 5.09
[0.843, 9.35] ×104
[0.1, 1.5] 0.983 [0.334, 1.19] ×100
p(σ2)
b(σ2) q(σ2)
s(σ2)
A [0, 10]
4.73
[0.431, 9.39] ×10−5
T
[0, 10]
5.06
[0.725, 9.30] ×10−5
The DEM calibration problem turns out to be extremely challenging for the
sampling algorithms, as it contains both an unidentiﬁable manifold (in (αn, γn)
subspace) and a bi-modality (in kt parameter). Nevertheless, TMCMC and ABC-
SubSim algorithms capture both features and give almost identical results. In ac-
cordance with the results of Wilkinson [127], an additional uniformly distributed
prediction error arises in the domain ρ(y, d) ≤δ = 0.06 for ABC-SubSim. How-
ever, this error appears to be small enough for the quantitative discrepancies in the
inference results of the two algorithms to be negligible.
We thus conclude that ABC-SubSim provides a reasonable alternative to TM-
CMC for Bayesian likelihood-driven inference. Its usage however appears to be more
suitable in the cases when the likelihood is intractable.

A.2. Parameter Calibration
123
Figure A.2: Results of parameter calibration of the DEM problem using 50000 ABC-
SubSim samples (see Notations), δ = 0.06. The scaling factors for the parameters
are given in Table A.2.

124
Appendix A. ABC for Likelihood-Driven Bayesian Inference
Figure A.3: Results of parameter calibration of the DEM problem using 50000
TMCMC samples (see Notations). The scaling factors for the parameters are given
in Table A.2.

Appendix B
RBC Parameters Sensitivity
This appendix presents the results of the sensitivity analysis of the RBC model in
stretching and shear ﬂow. Every ﬁgure displays a set of values of one parameter of
the RBC membrane model and the corresponding values of the QoI along with 95%
conﬁdence intervals. The reference point conﬁdence intervals are shown as dashed
lines. The 1% deviations from the reference values are shown as solid lines. We
consider a given parameter sensitive if there is a visible trend in the QoI.
14
15
16
17
axial
0.43
0.44
0.45
0.46
0.47
x0
4.4
4.6
4.8
5
transverse
15.2
15.4
15.6
axial
1.9
1.95
2
2.05
2.1
p
×10-3
4.55
4.6
4.65
4.7
transverse
Figure B.1: Eﬀect of the spring parameters in the stretching experiment.
125

126
Appendix B. RBC Parameters Sensitivity
15.2
15.4
15.6
axial
38
39
40
41
42
kb
4.55
4.6
4.65
4.7
transverse
15.2
15.4
15.6
axial
28.5
29
29.5
30
30.5
31
31.5
γC
4.55
4.6
4.65
4.7
transverse
Figure B.2: Eﬀect of the bending rigidity parameter kb and of the membrane vis-
cosity parameter γC in the stretching experiment.
0.43
0.44
0.45
0.46
0.47
x0
0.18
0.185
0.19
0.195
0.2
0.205
frequency
0.48
0.49
0.5
0.51
0.52
p
0.186
0.188
0.19
0.192
0.194
0.196
0.198
0.2
0.202
frequency
x 10-2
Figure B.3: Eﬀect of the spring parameters in the shear ﬂow experiment.
38
39
40
41
42
kb
0.188
0.19
0.192
0.194
0.196
0.198
0.2
0.202
frequency
28.5
29
29.5
30
30.5
31
31.5
γC
0.19
0.195
0.2
frequency
Figure B.4: Eﬀect of the bending rigidity parameter kb and of the membrane vis-
cosity parameter γC in the shear ﬂow experiment.

Appendix C
Argon LJ Parameters
C.1
Hyper-parameter models for hierarchical inference
Inference for LJ 6-12
We assume that,
p(ϑ | ψ, M) =
3
Y
j=1
p(ϑj | ψ, M) ,
(C.1)
and we consider the following two models:
1) uniform: p(ϑj | ψ, M) = U(ϑj | ψ2j−1, ψ2j−1 + ψ2j), where U(ξ|a, b) is the uni-
form distribution of ξ with parameters a, b and M is set to U,
2) log-normal: p(ϑj | ψ, M) = L(ϑj | ψ2j−1, ψ2j), where L(ξ|a, b) is the log-normal
distribution of ξ with parameters a, b and M is set to L.
The prior distribution on the hyper-parameters is modeled as independent uniform,
p(ψ | M) =
6
Y
j=1
U(ψj | aM
j , bM
j ) ,
(C.2)
where M ∈{U, L} and the constants aM
j , bM
j
are given in Table C.1, along with
the values of the log-evidences for the two models. The model U is according to the
Bayesian model selection criterion, an order of magnitude more plausible and thus
will be used for the further inference.
127

128
Appendix C. Argon LJ Parameters
Table C.1:
HB12,R inference:
lower bound and width for each of the hyper-
parameters deﬁned in Eq. (C.2). Log-evidences for each hyper-prior model at the
last row.
M = U
M = L
[aM
1 , bM
1 ] [0.0, 3.0] [-1.000, 2.0]
[aM
2 , bM
2 ] [0.0, 7.0] [ 0.001, 2.5]
[aM
3 , bM
3 ] [3.0, 3.4] [-3.000, 0.5]
[aM
4 , bM
4 ] [0.0, 2.0] [ 0.001, 4.0]
[aM
5 , bM
5 ] [0.0, 0.2] [-3.500, 0.5]
[aM
6 , bM
6 ] [0.0, 1.0] [ 0.001, 2.5]
Log-ev.
-19.1401 -22.0198
Inference for LJ 6-p
We assume
p(ϑ | ψ, M) =
4
Y
j=1
p(ϑj | ψ, M)
(C.3)
and consider the following three models:
1) uniform: p(ϑj | ψ, U) = U(ϑj | ψ2j−1, ψ2j−1 + ψ2j), where U(ξ|a, b) is the uni-
form distribution of ξ with parameters a, b and M is set to U,
2) log-normal: p(ϑj | ψ, M) = L(ϑj | ψ2j−1, ψ2j), where L(ξ|a, b) is the log-normal
distribution of ξ with parameters a, b and M is set to L,
3) truncated normal: p(ϑj | ψ, M) = T (ϑj | ψ2j−1, ψ2j), where T (ξ|a, b) is the
truncated normal distribution of ξ with parameters a, b and M is set to T .
The prior distribution on the hyper-parameters is modeled as independent uniform,
p(ψ | M) =
8
Y
j=1
p(ψj | M) =
8
Y
j=1
U(ψj | aM
j , bM
j ) ,
(C.4)
where M ∈{U, L, T } and the constants aM
j , bM
j
are given in Table C.2, along with
the values of the log-evidences for the three models. As it can be seen, the uniform
model is the most plausible one.

C.2. Posterior PDFs for LJ 6-12 and LJ 6-p
129
Table C.2:
HBp,R inference:
lower bound and width for each of the hyper-
parameters deﬁned in Eq. (C.4). Log-evidences for each hyper-prior model at the
last row.
M = U
M = L
M = T
[aM
1 , bM
1 ] [0.0, 3.00] [-1.000, 2.0] [0.0500, 10.0]
[aM
2 , bM
2 ] [0.0, 7.00] [ 0.001, 2.5] [0.0010, 3.30]
[aM
3 , bM
3 ] [3.0, 3.40] [-3.000, 0.5] [3.0000, 4.00]
[aM
4 , bM
4 ] [0.0, 2.00] [ 0.001, 4.0] [0.0010, 0.30]
[aM
5 , bM
5 ] [6.0, 7.00] [-2.500, 1.5] [6.0000, 12.0]
[aM
6 , bM
6 ] [0.0, 10.0] [ 0.001, 2.5] [0.0010, 2.00]
[aM
7 , bM
7 ] [0.0, 0.20] [-3.500, 0.5] [0.0001, 1.00]
[aM
8 , bM
8 ] [0.0, 1.00] [ 0.001, 2.5] [0.0010, 0.30]
Log-ev.
-24.0202
-27.3889
-25.3927
C.2
Posterior PDFs for LJ 6-12 and LJ 6-p
This section presents the posterior distributions for LJ 6-12 and LJ 6-p potentials
obtained in non-hierarchical BASIS runs for each thermodynamic condition, as well
as, the distribution for the quantum dimer-based Bayesian inference. Each plot con-
tains all the BASIS samples of the last stage and it consists of the following parts:
histograms of marginal distributions of parameters are shown on the diagonal, pro-
jections of the samples to all pair 2-d subspaces in the parameter space colored by
the log-likelihood values are given above the diagonal, the corresponding densities
constructed via a bivariate kernel estimate are depicted below the diagonal. Green
circle shows the parameters from Ref. [100, 105], green square indicates the param-
eters from Ref. [11], and green triangle marks the parameters from Ref. [126].

130
Appendix C. Argon LJ Parameters
Figure C.1: LJ parameters distributions obtained in B12,R for L3 (top) and L4
(bottom).

C.2. Posterior PDFs for LJ 6-12 and LJ 6-p
131
Figure C.2: LJ parameters distributions obtained in B12,R for L5 (top) and V
(bottom).

132
Appendix C. Argon LJ Parameters
Figure C.3: LJ parameters distributions obtained in Bp,R for L1 (top) and L2
(bottom).

C.2. Posterior PDFs for LJ 6-12 and LJ 6-p
133
Figure C.4: LJ parameters distributions obtained in Bp,R for L3 (top) and L4
(bottom).

134
Appendix C. Argon LJ Parameters
Figure C.5: LJ parameters distributions obtained in Bp,R for L5 (top) and V (bot-
tom).

C.2. Posterior PDFs for LJ 6-12 and LJ 6-p
135
Figure C.6: LJ parameters distribution obtained in Bp,Q.

136
Appendix C. Argon LJ Parameters
Figure C.7: LJ parameters distribution obtained in Bp,R for L3 with the prior for p
restricted to [12, 14].

Appendix D
LAMMPS Scripts for the MD
Simulations
D.1
Helium
This section presents a script used for running the ABC inference for helium.
1
# Variables
2
variable
m
equal 6.646476e-6
# mass
3
variable
R
equal 2077.1488
# gas constant
4
variable
P
equal 101325e-6
# pressure
5
variable
T
equal 300
# temperature
6
variable
rho
equal 2*($P/($T*$R))
# initial density
7
variable
cut
equal 2.5*${sigma}
# LJ cutoff
8
variable
nc
equal 10
# cells per dimension
9
variable
dL
equal ($m/${rho})^(1./3.) # length of one cell
10
variable
L
equal ${dL}*${nc}
# domain length
11
variable
seed equal 1
# rnd seed for velocity
12
variable
dt
equal 2e-6
# time step
13
variable
nt1
equal 1e6
# steps (equilibration)
14
variable
nt2
equal 2.5e6
# steps (production)
15
variable
td
equal 1e3*${dt}
# temperature damping
137

138
Appendix D. LAMMPS Scripts for the MD Simulations
16
variable
pd
equal 1e4*${dt}
# pressure damping
17
variable
kb
equal 0.0138
# Boltzmann constant
18
variable
fb
equal exp(-enthalpy/(${kb}*temp))
19
# Boltzmann factor
20
21
# Initialization:
22
# 1) general
23
units
nano
24
atom_style
atomic
# interatomic forces
25
# 2) geometry
26
boundary
p p p
# periodic in xyz
27
lattice
sc ${dL}
28
region
box block 0 $L 0 $L 0 $L units box
29
create_box
1 box
30
# 3) create atoms
31
create_atoms
1 box
32
mass
* $m
33
velocity
all create $T ${seed} mom yes rot yes dist gaussian
34
# 4) LJ interactions
35
pair_style
lj/cut ${cut}
36
pair_coeff
* * ${eps} ${sigma}
37
# 5) relaxation process
38
neighbor
0.1 bin
39
neigh_modify
delay 0 every 1 check yes
40
minimize
0.0 1.0e-8 1000 100000
41
42
# Equilibration run
43
reset_timestep 0
44
timestep
${dt}
45
fix
1 all npt temp $T $T ${td} iso $P $P ${pd}
46
thermo_style
custom temp press vol pe etotal density
47
thermo
1000
48
run
${nt1}
49

D.2. Argon
139
50
# Production run
51
reset_timestep 0
52
timestep
${dt}
53
fix
2 all npt temp $T $T ${td} iso $P $P ${pd}
54
thermo_style
custom temp press vol pe etotal v_fb
55
thermo_modify
norm yes
56
thermo
1000
57
run
${nt2}
D.2
Argon
This section presents a script used for running the HB inference for argon.
1
# Variables (‘sigma‘, ‘eps‘, ‘D‘ [density], ‘P‘ [pressure],
2
# ‘T‘ [temperature] are input parameters)
3
variable
m
equal 39.95
# mass
4
variable
rho equal 25
# lattice density
5
variable
L
equal "40.0 * v_sigma" # domain length
6
variable
nt1 equal 100000
# steps (NPT, 1)
7
variable
nt2 equal 100000
# steps (NPT, 2) [loop 50]
8
variable
nt3 equal 100000
# steps (NVE)
9
variable
nlj equal 1000
# LJ interpolation points
10
11
# Initialization
12
# 1) general
13
units
real
14
atom_style
atomic
# interatomic forces
15
# 2) geometry
16
boundary
p p p
# periodic in xyz
17
lattice
fcc ${rho}
18
region box
block
0 $L
0 $L
0 $L
19
create_box
1 box # number of atom types
20
# 3) create atoms
21
create_atoms 1 box
22
mass
* $m

140
Appendix D. LAMMPS Scripts for the MD Simulations
23
velocity
all create $T ${seed} rot yes dist gaussian
24
# 4) LJ interactions
25
pair_style
table linear ${nlj}
26
pair_coeff
* *
lj.tab.txt LJ
# tabulated LJ in file
27
# 5) relaxation process
28
neighbor
${sigma}
bin
29
atom_modify
map array sort 10 6
30
minimize
0.0 1.0e-8 1000 100000
31
32
# NPT integration
33
neigh_modify
delay 1
34
reset_timestep 0
35
timestep
1
36
thermo
1000
37
thermo_style
custom step temp press etotal vol density
38
fix
1 all npt temp ${T} ${T} 20 iso ${P} ${P} 20
39
run
${nt1}
40
41
# NPT integration-2 (bigger time step)
42
neigh_modify
delay 5
43
reset_timestep 0
44
timestep
2
45
thermo
1000
46
thermo_style
custom step temp press etotal vol density
47
fix
2 all npt temp ${T} ${T} 100 iso ${P} ${P} 1000
48
fix
LMOM all momentum 100 linear 1 1 1
49
50
# Conditional run
51
variable
d equal density
52
label
loop
53
variable
a loop 50
54
if
"$d > $D" then "jump SELF break"
55
run
${nt2}
56
next
a

D.2. Argon
141
57
jump
SELF loop
58
label
break
59
run
10000
# finalize
60
61
# Production run (NVE)
62
reset_timestep 0
63
timestep
2
64
fix
3 all nve
65
compute
RDF all rdf 100
66
fix
RDF all ave/time 1 ${nt3} ${nt3} c_RDF file rdf.txt
67
mode vector
68
compute
MSD all msd com yes
69
fix
MSD all vector 10 c_MSD[4]
70
variable
dc equal slope(f_MSD)/6/(10*dt) # diffusion coefficient
71
thermo
1000
72
thermo_style
custom step temp press etotal vol density v_dc c_MSD[4]
73
run
${nt3}
In this script, we conditionally run the NPT integration (lines 41-59) until argon
reaches the desired phase (liquid or vapor). For some parameter sets this may never
happen, and the run should be rejected.
The tabulated version of the LJ potential is precomputed with an external script,
after that LAMMPS reads it (line 26) and constructs a linear interpolation (line 25).
The diﬀusion coeﬃcient is computed using the mean square displacement (lines
67-69).


List of Figures
1.1
Schematic representation of the inference process. Red arrows show
the origins of errors. Blue dashed arrows show the information and
errors ﬂow.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
4.1
A synthetic example of a hierarchical data structure. All the datasets
exhibit a linear behavior y = ϑx with diﬀerent slopes ϑ. The hyper-
parameter ψ governs the prior distribution of the slopes: p(ϑ | ψ) =
U(ϑ; ψ1, ψ2). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
4.2
Hierarchical Bayesian network.
. . . . . . . . . . . . . . . . . . . . .
27
5.1
8000 BASIS samples from the Rosenbrock function. . . . . . . . . . .
39
5.2
Schematic representation of intermediate domains at stages k (dashed
blue line) and (k + 1) (dashed red line), samples up to stage k (blue
dots and red dots with blue border), chains generated from the leader
samples at the stage k (red dots and red dots with blue border) for
various algorithms. Black dots indicate samples which were proposed,
but rejected by the algorithm. . . . . . . . . . . . . . . . . . . . . . .
42
5.3
Posterior PDFs of the 2-d Himmelblau function. The population size
is 8000. Each of the surrogates uses 8% of the domain to build the
approximation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
6.1
Data: distribution of the Boltzmann factor fB over time of a helium
system with 1000 atoms, σ = 0.2556, ε = 0.141. . . . . . . . . . . . .
53
143

144
List of Figures
6.2
Calibration results for the LJ parameters of helium using ABC-SubSim
with diﬀerent discrepancies (see Notations).
Green circles on the
bottom-left subplots indicate parameters for which the data were cre-
ated. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
7.1
Posterior parameter values: MPVs along with 5%-95% quantiles ob-
tained in B12,R (light red), HB12,R (dark red).
Horizontal lines
indicate the reference values:
Ref. [11] (yellow), Ref. [126] (red),
Ref. [100, 105] (blue).
. . . . . . . . . . . . . . . . . . . . . . . . . .
63
7.2
Posterior parameter values: MPVs along with 5%-95% quantiles ob-
tained in Bp,R (light blue), HBp,R (dark blue). Horizontal line indi-
cates the MPVs for Bp,Q.
. . . . . . . . . . . . . . . . . . . . . . . .
67
7.3
Posterior samples of Bp,R projected onto (p, ε) subspace. Red: V .
Shades of blue: Li in the temperature increasing order from the light-
est to the darkest color. Green: Q. Grid lines indicate the log-scale
for ε. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
7.4
Posterior LJ potentials comparison. Blue: MPVs with 5%-95% quan-
tiles from HBp,R. Red: MPVs from HB12,R. Green: MPVs from
Bp,Q (when applicable). Black: quantum dimer calculations (when
applicable). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
7.5
Robust posterior predictions of RDF. Blue:
MPVs with 5%-95%
quantiles from HBp,R. Red: MPVs from HB12,R (when applicable).
Green: MPVs from Bp,Q (when applicable). Black: experimental data. 73
7.6
Robust posterior predictions of density ρ and diﬀusion coeﬃcient D.
Blue: MPVs with 5%-95% quantiles from HBp,R. Red: MPVs with
5%-95% quantiles from HB12,R (when applicable).
Green: MPVs
from Bp,Q (when applicable). Grey: experimental data for ρ, ana-
lytically computed values for D. Grid for D shows the logarithmic
scale. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
74
8.1
Schematic representation of the coarse-grained model of the Sec translo-
con.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
8.2
Bayesian inference using PMF proﬁles. . . . . . . . . . . . . . . . . .
80

List of Figures
145
8.3
Predictions of probability of integration using M5 and diﬀerent MAR-
TINI PMF datasets. The simulation results are given in the order
of increasing the scaling coeﬃcient from the lightest to the darkest
color. All the datasets are ﬁtted with a hyperbolic tangent. . . . . .
84
8.4
Parameters of M5 for the original MARTINI PMF datasets (ﬁlled
circles) and D-scaled datasets (empty circles). . . . . . . . . . . . . .
85
9.1
RBC membrane.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
9.2
RBC: Interactions of a single vertex. . . . . . . . . . . . . . . . . . .
90
9.3
Experimental values of the axial and transverse diameters of an RBC
stretched with optical tweezers [116]. . . . . . . . . . . . . . . . . . .
93
9.4
Stretching of RBCs at diﬀerent resolutions. Yellow: Nv ∼500, red:
Nv ∼2000, blue: Nv ∼8000.
. . . . . . . . . . . . . . . . . . . . . .
93
9.5
Example of ﬁtting the RBC diameters under stretching with the func-
tion from Eq. (9.22). . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
9.6
Approximation of the ﬁtting function (Eq. (9.22)) parameters. . . . .
96
9.7
Results of parameter calibration of the RBC membrane parameters
using TMCMC (see Notations). . . . . . . . . . . . . . . . . . . . . .
97
9.8
Posterior predictions of RBC diameters under stretching. Red line:
experimental data, blue line: posterior MPV, blue area: 5%-95%
quantiles.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
98
9.9
Posterior predictions of the frequency of RBC in shear ﬂow. Calibra-
tion using the data on stretching. Original model. Red line/crosses:
experimental data, blue line: mean and 5%-95% quantiles of the pre-
dictions. Data from [35] and [118]. . . . . . . . . . . . . . . . . . . .
99
9.10 RBC tank-treading frequency in the shear ﬂow along with the linear
ﬁt. The shear rate is normalized with the viscosity of the solvent.
The experiments are listed in the order of viscosity increase (from
blue to red). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
100
9.11 Collapse of the triangles at shear rate 12 in DPD units. Left: kd =
200, right: kd = 5000.
. . . . . . . . . . . . . . . . . . . . . . . . . .
101
9.12 Resolution study of RBC in shear ﬂow.
Yellow: Nv ∼500, red:
Nv ∼2000.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
102
9.13 Approximation of the TTF as a function of γC. . . . . . . . . . . . .
102

146
List of Figures
9.14 Posterior distribution of the RBC membrane viscosity parameter γC
obtained with TMCMC (see Notations). . . . . . . . . . . . . . . . .
104
9.15 Robust posterior quantiles of TTF obtained after calibrating the
membrane viscosity parameter.
Red line: experimental data, blue
line: posterior MPV, blue area: 5%-95% quantiles of the predictions.
104
9.16 Schematic representation of RBC motion in various shear rates. . . .
105
A.1 Schematic representation of a collision between particles i and j.
. .
120
A.2 Results of parameter calibration of the DEM problem using 50000
ABC-SubSim samples (see Notations), δ = 0.06. The scaling factors
for the parameters are given in Table A.2. . . . . . . . . . . . . . . .
123
A.3 Results of parameter calibration of the DEM problem using 50000
TMCMC samples (see Notations). The scaling factors for the param-
eters are given in Table A.2. . . . . . . . . . . . . . . . . . . . . . . .
124
B.1
Eﬀect of the spring parameters in the stretching experiment.
. . . .
125
B.2
Eﬀect of the bending rigidity parameter kb and of the membrane
viscosity parameter γC in the stretching experiment. . . . . . . . . .
126
B.3
Eﬀect of the spring parameters in the shear ﬂow experiment.
. . . .
126
B.4
Eﬀect of the bending rigidity parameter kb and of the membrane
viscosity parameter γC in the shear ﬂow experiment. . . . . . . . . .
126
C.1
LJ parameters distributions obtained in B12,R for L3 (top) and L4
(bottom). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
130
C.2
LJ parameters distributions obtained in B12,R for L5 (top) and V
(bottom). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
131
C.3
LJ parameters distributions obtained in Bp,R for L1 (top) and L2
(bottom). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
132
C.4
LJ parameters distributions obtained in Bp,R for L3 (top) and L4
(bottom). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
133
C.5
LJ parameters distributions obtained in Bp,R for L5 (top) and V
(bottom). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
134
C.6
LJ parameters distribution obtained in Bp,Q.
. . . . . . . . . . . . .
135
C.7
LJ parameters distribution obtained in Bp,R for L3 with the prior for
p restricted to [12, 14]. . . . . . . . . . . . . . . . . . . . . . . . . . .
136

List of Tables
5.1
Results of the BASIS inference of the Himmelblau function using
the surrogates: percentage D of the domain used to build surrogate,
posterior mean value m(ϑ) of the parameter ϑ, 5%-95% quantiles q(ϑ)
of the posterior PDF of the parameter ϑ, percentage S of surrogate
points, average surrogate evaluation time T in seconds, average error
E computed as the absolute diﬀerence between the surrogate and the
real model evaluation. The population size was chosen to be 2000.
.
45
5.2
Detailed per-stage performance results of ABC-SubSim with 1024
workers on the Piz Daint cluster: Tm – mean simulation time, Ts –
standard deviation of the simulation times, Tt – sum of the execution
times of all simulations, Tw – wall-clock time per stage. All the times
are measured in seconds. . . . . . . . . . . . . . . . . . . . . . . . . .
47
6.1
Values of the LJ parameters ϑ ∈{σ, ε} of helium: prior bounds p(ϑ),
posterior MPVs b(ϑ), posterior 5%-95% quantiles q(ϑ), number of
stages S, achieved tolerances δ for three discrepancy models: MG
– Gaussian (Eq. (6.3)), MQ – quantile-based (Eq. (6.4)), MKL –
Kullback-Leibler (Eq. (6.5)). . . . . . . . . . . . . . . . . . . . . . . .
56
7.1
Units used in this chapter. . . . . . . . . . . . . . . . . . . . . . . . .
61
7.2
LJ parameters for argon used in literature. The last row shows the
data used for ﬁtting. Notations: T (temperature), P (pressure), ρ
(density), B (second virial coeﬃcient), E (energy), TP (gas-liquid
transition pressure), L (latent heat of evaporation). . . . . . . . . . .
64
147

148
List of Tables
7.3
Posterior values of each parameter ϑ ∈{ε, σ, σn} of LJ 6-12: MPV
b(ϑ) and 5%-95% quantiles q(ϑ).
. . . . . . . . . . . . . . . . . . . .
65
7.4
Posterior values of each parameter ϑ ∈{ε, σ, p, σn} of LJ 6-p: MPV
b(ϑ) and 5%-95% quantiles q(ϑ).
. . . . . . . . . . . . . . . . . . . .
68
7.5
Log-evidences E12,R (Ep,R) for B12,R (Bp,R).
. . . . . . . . . . . . .
69
7.6
Errors of robust posterior predictions of RDF, density and diﬀusion
coeﬃcient using LJ 6-12 and LJ 6-p. We denote S1 = {L4, L5} (all
inferences produce the correct argon phase), S2 = {L3 −L5, V } (Bp,Q
produces wrong phase), S3 = {L1−L5, V } (Bp,Q and HB12,R produce
wrong phase). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
8.1
Parameters of M1 −M4. Parameters under inference are given with
their uniform prior bounds. For the parameters not used in the infer-
ence, the values are given. The values on the left side of the slash (’/’)
are for the D substrate, while the values on the right side correspond
to the L substrate. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
8.2
Parameters of M5. Parameters under inference are given with their
uniform prior bounds. For the parameters not used in the inference,
the values are given. . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
8.3
Log-likelihood values of all the models. . . . . . . . . . . . . . . . . .
82
8.4
Posterior information obtained in the HB inference for each of the
parameters ϑ ∈{mx, mr, σ} of M5: MPV b(ϑ), 5%-95% quantiles q(ϑ). 82
8.5
Information about the parameters of M5 obtained using the data
with D proﬁles scaled by 50%.
. . . . . . . . . . . . . . . . . . . . .
85
9.1
Coeﬃcients of the polynomial approximation of parameters a, t from
Eq. (9.22) as a function of x0. Coeﬃcient ci corresponds to degree i.
95
9.2
Prior and posterior information on the spring parameters of the RBC
membrane model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
98
9.3
Linear ﬁts and their errors for RBC tank-treading frequency in the
shear ﬂow. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
101
9.4
Prior and posterior information about the parameters of the RBC
membrane in the shear ﬂow experiment. . . . . . . . . . . . . . . . .
103

List of Tables
149
A.1 Experimentally measured normal and tangential coeﬃcients of resti-
tution cn
j , ct
j and their uncertainties u(cn
j ), u(ct
j), j = 1, . . . , 6 de-
pending on the impact angle φ. Data from [33]. . . . . . . . . . . . .
121
A.2 Prior and posterior information about the parameters ϑ ∈{µ, αn, γn, kt, σ2}
for ABC-SubSim (A) and TMCMC (T): uniform prior bounds p(ϑ),
posterior MPVs b(ϑ), 5%-95% posterior quantiles q(ϑ), scale s(ϑ).
.
122
C.1
HB12,R inference: lower bound and width for each of the hyper-
parameters deﬁned in Eq. (C.2). Log-evidences for each hyper-prior
model at the last row. . . . . . . . . . . . . . . . . . . . . . . . . . .
128
C.2
HBp,R inference:
lower bound and width for each of the hyper-
parameters deﬁned in Eq. (C.4). Log-evidences for each hyper-prior
model at the last row. . . . . . . . . . . . . . . . . . . . . . . . . . .
129


Bibliography
[1] http://lammps.sandia.gov.
[2] https://github.com/pin3da/gplib.
[3] https://github.com/OpenANN/OpenANN.
[4] M. Abkarian, M. Faivre, and A. Viallat. Swinging of red blood cells under
shear ﬂow. Phys. Rev. Lett., 98:188302, 2007.
[5] P. Angelikopoulos, C. Papadimitriou, and P. Koumoutsakos.
Bayesian un-
certainty quantication and propagation in molecular dynamics simulations:
a high performance computing framework. J. Chem. Phys., 137(14):144103,
2012.
[6] P. Angelikopoulos, C. Papadimitriou, and P. Koumoutsakos. Bayesian uncer-
tainty quantiﬁcation and propagation in molecular dynamics simulations: A
high performance computing framework. J. Chem. Phys., 137:144103, 2012.
[7] P. Angelikopoulos, C. Papadimitriou, and P. Koumoutsakos. Data driven, pre-
dictive molecular dynamics for nanoscale ﬂow simulations under uncertainty.
J. Phys. Chem. B, 117(47):14808–14816, 2014/12/01 2013.
[8] P. Angelikopoulos, C. Papadimitriou, and P. Koumoutsakos. X-tmcmc: Adap-
tive kriging for bayesian inverse modeling. Comp. Meth. Appl. Mech. Eng.,
289:409–428, 2015.
[9] P. Angelikopoulos, C. Papadimitriou, and P. Koumoutsakos.
X-TMCMC:
Adaptive kriging for Bayesian inverse modeling. Comp. Meth. Appl. Mech.
Eng., 289:409–428, 6 2015.
151

152
Bibliography
[10] S.-K. Au and J. L. Beck.
Estimation of small failure probabilities in high
dimensions by subset simulation. Prob. Eng. Mech., 16(4):263–277, 2001.
[11] J. A. Barker, R. A. Fisher, and R. O. Watts. Liquid argon: Monte Carlo and
molecular dynamics calculations. Mol. Phys., 21:657–673, 1971.
[12] M. A. Beaumont. Approximate Bayesian computation in evolution and ecol-
ogy. Annu. Rev. Ecol. Evol. Syst., 41(1):379–406, 2014/12/01 2010.
[13] M. A. Beaumont, J. M. Cornuet, J. M. Marin, and C. P. Robert. Adaptive
approximate Bayesian computation. Biometrika, 96(4):983–990, 2009.
[14] J. L. Beck and S. K. Au. Probabilistic system identiﬁcation with unidentiﬁ-
able models. In Proceedings of the 8th International Conference on Structural
Safety and Reliability, Balkema, 2001.
[15] J. L. Beck and L. S. Katafygiotis. Updating models and their uncertainties. I:
Bayesian statistical framework. J. Eng. Mech.-ASCE, 124(4):455–461, April
1998.
[16] W. Betz, I. Papaioannou, and D. Straub. Transitional Markov chain Monte
Carlo: observations and improvements. Journal of Engineering Mechanics,
142(5):04016016, 2016.
[17] N. Bicanic. Discrete Element Methods, volume 1 of Encyclopedia of Compu-
tational Mechanics. Wiley, 2004.
[18] L. Brendel and S. Dippel. Lasting contacts in molecular dynamics simulations,
pages 31–33. Physics of Dry Granular Media. Kluwer Academic Publishers,
1998.
[19] F. Cailliez, A. Bourasseau, and P. Pernot. Calibration of forceﬁelds for molec-
ular simulation: Sequential design of computer experiments for building cost-
eﬃcient kriging metamodels. J. Comp. Chem., 35(2):130–149, 2014.
[20] F. Cailliez and P. Pernot.
Statistical approaches to forceﬁeld calibra-
tion and prediction uncertainty in molecular simulation.
J. Chem. Phys.,
134(5):054124, 2011.

Bibliography
153
[21] B. Calderhead and M. Girolami. Statistical analysis of nonlinear dynamical
systems using diﬀerential geometric sampling methods. Interface focus, page
rsfs20110051, 2011.
[22] O. Capp´e, S. J. Godsill, and E. Moulines. An overview of existing methods
and recent advances in sequential Monte Carlo. In Proceedings of the IEEE
95.5, pages 899–924, 2007.
[23] O. Capp´e, A. Guillin, J. M. Marin, and C. P. Robert. Population Monte Carlo.
J. Comp. Graph. Stat., 13(4):907–929, 2004.
[24] S. H. Cheung and J. L. Beck. Bayesian model updating using hybrid Monte
Carlo simulation with application to structural dynamic models with many
uncertain parameters. J. Eng. Mech., 135(4):243–255, 2009.
[25] M. Chiachio, J. L. Beck, J. Chiachio, and G. Rus. Approximate Bayesian com-
putation by subset simulation. SIAM J. Sci. Comput., 36(3):A1339–A1358,
2014/10/03 2014.
[26] J. Ching and Y. Chen. Transitional Markov chain Monte Carlo method for
Bayesian model updating, model class selection, and model averaging. J. Eng.
Mech., 133(7):816–832, 2007.
[27] J.-M. Cornuet, P. Pudlo, J. Veyssier, A. Dehne-Garcia, M. Gautier, R. Leblois,
J.-M. Marin, and A. Estoup. DIYABC v2. 0: a software to make approxi-
mate Bayesian computation inferences about population history using single
nucleotide polymorphism, DNA sequence and microsatellite data. Bioinfor-
matics 30, 8:1187–1189, 2014.
[28] P. de Valpine, D. Turek, C. J. Paciorek, C. Anderson-Bergman, D. T. Lang,
and R. Bodik. Programming with models: writing statistical algorithms for
general model structures with NIMBLE. Journal of Computational and Graph-
ical Statistics, 26(2):403–413, 2017.
[29] P. Del Moral, A. Doucet, and A. Jasra. Sequential Monte Carlo samplers. J.
R. Stat. Soc. Series B Stat. Methodol., 68(3):411–436, 2006.
[30] X. Didelot, R. G. Everitt, A. M. Johansen, and D. J. Lawson. Likelihood-free
estimation of model evidence. Bayesian analysis, 6(1):49–76, 2011.

154
Bibliography
[31] D. E. Discher, D. H. Boal, and S. K. Boey. Simulations of the erythrocyte
cytoskeleton at large deformation. ii. Micropipette aspiration. Biophys. J.,
75(3):1584–1597, 1998.
[32] D. E. Discher, N. Mohandas, and E. A. Evans. Molecular maps of red cell
deformation: hidden elasticity and in situ connectivity. Science, New Series,
266(5187):1032–1035, 1994.
[33] H. Dong and M. H. Moys. Experimental study of oblique impacts with initial
spin. Powd. Technol., 161(1):22–31, 2006.
[34] A. J. Drummond and A. Rambaut. BEAST: Bayesian evolutionary analysis
by sampling trees. BMC evolutionary biology, 7(1):214, 2007.
[35] J. Dupire, M. Socol, and A. Viallat. Full dynamics of a red blood cell in shear
ﬂow. PNAS, 109(51):20808–20813, 2012.
[36] A. Eisenstein and N. S. Gingrich. The diﬀraction of X-rays by Argon in the
liquid, vapor, and critical regions. Phys. Rev., 62:261–270, 1942.
[37] P. Espa˜nol and P. Warren. Statistical Mechanics of Dissipative Particle Dy-
namics. EPL (Europhysics Letters), 30(4):191, May 1995.
[38] E. A. EVANS. Bending elastic modulus of red blood cell membrane derived
from buckling instability in micropipet aspiration tests. Biophys. J., 43:27–30,
July 1983.
[39] K. Farrell, J. T. Oden, and D. Faghihi. A bayesian framework for adaptive
selection, calibration, and validation of coarse-grained models of atomistic
systems. J. Comput. Phys., 295(0):189–208, 8 2015.
[40] D. A. Fedosov. Multiscale modeling of blood ﬂow and soft matter. PhD thesis,
Brown University, 2010.
[41] D. A. Fedosov, B. Caswell, and G. E. Karniadakis. A multiscale red blood cell
model with accurate mechanics, rheology, and dynamics. Biophysical Journal,
98:2215–2225, May 2010.
[42] D. A. Fedosov and G. Gompper. White blood cell margination in microcircu-
lation. Soft Matter, 10(17):2961–2970, 2014.

Bibliography
155
[43] D. A. Fedosov, W. Pan, B. Caswell, G. Gompper, and G. E. Karniadakis.
Predicting human blood viscosity in silico. PNAS, 108(29):11772–11777, 2011.
[44] F. Feroz, M. P. Hobson, and M. Bridges. MultiNest: an eﬃcient and robust
Bayesian inference tool for cosmology and particle physics. Monthly Notices
of the Royal Astronomical Society, 398(4):1601–1614, 2009.
[45] T. M. Fischer.
The red cellas a ﬂuid droplet: Tank tread-like motion of
the human erythrocyte membrane in shear ﬂow. Science, 202(4370):894–896,
November 1978.
[46] T. M. Fischer. On the energy dissipation in a tank-treading human red blood
cell. Biophys. J., 32:863–868, November 1980.
[47] T. M. Fischer. Tank-tread frequency of the red cell membrane: Dependence on
the viscosity of the suspending medium. Biophys. J., 93:2553–2561, October
2007.
[48] G. Galli´ero, C. Boned, A. Baylaucq, and F. Montel. Molecular dynamics com-
parative study of lennard-jones a-6 and exponential α-6 potentials: Applica-
tion to real simple ﬂuids (viscosity and pressure). Phys. Rev. E, 73:061201–1,
2006.
[49] D. Gamerman and H. F. Lopes. Markov chain Monte Carlo: stochastic sim-
ulation for Bayesian inference. CRC Press, 2006.
[50] A. E. Gelfand and D. K. Dey. Bayesian model choice: asymptotics and exact
calculations. J. R. Stat. Soc. Series B Stat. Methodol., 56(3):501–514, 1994.
[51] A. Gelman, D. Lee, and J. Guo. Stan: A probabilistic programming language
for Bayesian inference and optimization. J. Edu. Behav. Stat., 40(5):530–543,
2015.
[52] C. J. Geyer. Practical Markov chain Monte Carlo. Statistical Science, pages
473–483, 1992.
[53] W. R. Gilks. Markov chain Monte Carlo. John Wiley and Sons, Ltd., 2005.
[54] W. R. Gilks, S. Richardson, and D. Spiegelhalter, editors. Markov chain Monte
Carlo in practice. CRC press, 1995.

156
Bibliography
[55] V. Goder and S. M. Molecular mechanism of signal sequence orientation in
the endoplasmic reticulum. EMBO J., 22(14):3645–3653, 2003.
[56] R. Graham.
Bounds on multiprocessing timing anomalies.
SIAM J. App.
Math., 17(2):416–429, 1969.
[57] R. D. Groot and P. B. Warren. Dissipative particle dynamics: Bridging the
gap between atomistic and mesoscopic simulation. The Journal of Chemical
Physics, 107(11):4423–4435, Sept. 1997.
[58] P. Hadjidoukas, E. Lappas, and V. Dimakopoulos.
A runtime library for
platform-independent task parallelism ,. In 20th Euromicro International Con-
ference on Parallel, Distributed and Network-Based Processing (PDP), pages
229–236. IEEE Computer Society, Munich, Germany, 2012.
[59] P. E. Hadjidoukas, P. Angelikopoulos, L. Kulakova, C. Papadimitriou, and
P. Koumoutsakos. Exploiting Task-Based Parallelism in Bayesian Uncertainty
Quantiﬁcation, volume 9233 of LNCS, pages 532–544. Springer Berlin Heidel-
berg, 2015.
[60] P. E. Hadjidoukas, P. Angelikopoulos, C. Papadimitriou, and P. Koumout-
sakos. Π4U: A high performance computing framework for Bayesian uncer-
tainty quantiﬁcation of complex models. J. Comput. Phys., 284(1):1–21, 2015.
[61] P. E. Hadjidoukas, P. Angelikopoulos, D. Rossinelli, D. Alexeev, C. Papadim-
itriou, and P. Koumoutsakos. Bayesian uncertainty quantiﬁcation and prop-
agation for discrete element simulations of granular materials. Comp. Meth.
Appl. Mech. Eng., 282:218–238, 12 2014.
[62] A. M. Halpern and T. Haute. Structural and thermodynamic properties of
the argon dimer a computational chemistry exercise in quantum and statistical
mechanics. J. Chem. Educ., 87(2), 2010.
[63] N. Hansen, S. D. M¨uller, and P. Koumoutsakos. Reducing the time complexity
of the derandomized evolution strategy with covariance matrix adaptation
(CMA-ES). Evolutionary computation, 11(1):1–18, 2003.
[64] N. Hansen and A. Ostermeier. Completely derandomized self-adaptation in
evolution strategies. Evolutionary computation, 9(2), 2001.

Bibliography
157
[65] W. K. Hastings. Monte Carlo sampling methods using Markov chains and
their applications. Biometrika, 57(1):97–109, 1970.
[66] S. Haykin. Neural networks: a comprehensive foundation. Prentice Hall PTR,
1994.
[67] L. Hedin, K. ¨Ojemalm, A. Bernsel, A. Hennerdal, K. Illerg˚ard, K. Enquist, and
et al. Membrane insertion of marginally hydrophobic transmembrane helices
depends on sequence context. Journal of Molecular Biology, 396(1):221–229,
2010.
[68] T. Hessa, H. Kim, K. Bihlmaier, C. Lundin, J. Boekel, H. Andersson, I. Nils-
son, S. H. White, and G. von Heijne. Recognition of transmembrane helices
by the endoplasmic reticulum translocon. Nature, 433(7024):377–381, 2005.
[69] T. Hessa, N. M. Meindl-Beinker, A. Bernsel, H. Kim, Y. Sato, M. Lerch-Bader,
and et al. Molecular code for transmembrane-helix recognition by the Sec61
translocon. Nature, 450(7172):1026–1030, 2007.
[70] P. J. Hoogerbrugge and J. M. V. A. Koelman. Simulating Microscopic Hydro-
dynamic Phenomena with Dissipative Particle Dynamics. EPL (Europhysics
Letters), 19(3):155, June 1992.
[71] G.-B. Huang, Q.-Y. Zhu, and C.-K. Siew. Extreme learning machine: theory
and applications. Neurocomputing, 70(1):489–501, 2006.
[72] J. E. Jones. On the determination of molecular ﬁelds. ii. from the equation of
state of a gas. Proceedings of the Royal Society of London A: Mathematical,
Physical and Engineering Sciences, 106(738):463–477, 1924.
[73] M. H. Kalos and P. A. Whitlock. Monte Carlo Methods. Wiley-VCH, 2008.
[74] L. S. Katafygiotis and H. Lam.
Tangential projection algorithm for mani-
fold representation in unidentiﬁable model updating problems.
Earthquake
engineering & structural dynamics, 31(4):791–812, 2002.
[75] C. Kemp, A. Perfors, and J. B. Tenenbaum. Learning overhypotheses with
hierarchical Bayesian models. Developmental science, 10(3):307–321, 2007.

158
Bibliography
[76] J. Kestin, K. Knierim, E. A. Mason, B. Najaﬁ, S. T. Ro, and M. Waldman.
Equilibrium and transport properties of the noble gases and their mixtures at
low density. J. Phys. Chem. Ref. Data, 13:229–303, 1984.
[77] L. Kocik, T. Junne, and M. Spiess.
Orientation of internal signal-anchor
sequences at the sec61 translocon. J. Mol. Biol., 424(5):368–378, 2012.
[78] D. Krige. A statistical approach to some mine valuations and allied problems
at the witwatersrand. Master’s thesis, University of Witwatersrand, 1951.
[79] H. Kruggel-Emden, S. Wirtz, and V. Scherer. A study on tangential force
laws applicable to the discrete element method (DEM) for materials with
viscoelastic or plastic behavior. Chem. Eng. Sci., 63(6):1523–1541, 2008.
[80] L. Kulakova, P. Angelikopoulos, P. E. Hadjidoukas, C. Papadimitriou, and
P. Koumoutsakos. Approximate Bayesian computation for granular and molec-
ular dynamics simulations. In Proceedings of the Platform for Advanced Sci-
entiﬁc Computing Conference, page 4. ACM, 2016.
[81] M. D. Lee. BayesSDT: Software for Bayesian inference with signal detection
theory. Behavior Research Methods, 40(2):450–456, 2008.
[82] J. Li, M. Dao, C. Lim, and S. Suresh.
Spectrin-level modeling of the cy-
toskeleton and optical tweezers stretching of the erythrocyte.
Biophys. J.,
88(5):3707–3719, 2005.
[83] J. S. Lopes, M. Arenas, D. Posada, and M. A. Beaumont. Coestimation of
recombination, substitution and molecular adaptation rates by approximate
Bayesian computation. Heredity, 112(3):255–264, March 2014.
[84] P. Marepalli, J. Y. Murthy, B. Qiu, and X. Ruan. Quantifying uncertainty
in multiscale heat conduction calculations. J. Heat Transfer, 136(11):111301–
111301, 08 2014.
[85] P. Marjoram, J. Molitor, V. Plagnol, and S. Tavar´e. Markov chain Monte Carlo
without likelihoods.
Proc. Natl. Ac. Am., 100(26):15324–15328, December
2003.

Bibliography
159
[86] S. J. Marrink, A. H. de Vries, and A. E. Mark. Coarse grained model for
semiquantitative lipid simulations.
The Journal of Physical Chemistry B,
108(2):750–760, 2004.
[87] A. D. Martin, K. M. Quinn, and J. H. Park.
MCMCpack: Markov chain
Monte Carlo in R. J. Stat. Soft., 42(9):1–21, 2011.
[88] E. W. Merrill, E. R. Gilliland, G. Cokelet, H. Shin, A. Britten, and R. E. Wells.
Rheology of human blood, near and at zero ﬂow: eﬀects of temperature and
hematocrit level. Biophys. J., 3(3):199–213, 1963.
[89] R. Meyer and J. Yu. BUGS for a bayesian analysis of stochastic volatility
models. The Econometrics Journal, 3(2):198–215, 2000.
[90] R. M. Neal. Sampling from multimodal distributions using tempered transi-
tions. Statistics and computing, 6(4):353–366, 1996.
[91] M. J. Niesen,
C. Y. Wang,
R. C. Van Lehn,
and T. F. Miller III.
Structurally detailed coarse-grained model for Sec-facilitated co-translational
protein translocation and membrane integration.
PLoS Computat. Biol.,
13(3):e1005427, 2017.
[92] W. Pan, I. V. Pivkin, and G. E. Karniadakis. Single-particle hydrodynamics
in DPD: A new formulation. Europhys. Lett., 84(1):10012, 2008.
[93] M. L. Parks, P. Seleson, S. J. Plimpton, S. A. Silling, and R. B. Lehoucq.
Peridynamics with lammps: A user guide, v0. 3 beta. Sandia Report, pages
2011–8253, 2011.
[94] Z. Peng, X. Li, I. V. Pivkin, M. Dao, G. E. Karniadakis, and S. Suresh. Lipid
bilayer and cytoskeletal interactions in a red blood cell. PNAS, 110(33):13356–
13361, 2013.
[95] P. H. Peskun.
Optimum Monte Carlo sampling using Markov chains.
Biometrika, 60(3):607–612, 1973.
[96] C. Peter and K. Kremer. Multiscale simulation of soft matter systems. Faraday
Discuss., 144:9–24, 2010.

160
Bibliography
[97] I. V. Pivkin and G. E. Karniadakis. Accurate coarse-grained modeling of red
blood cells. Phys. Rev. Lett., 101(11):118105, 2008.
[98] S. Plimpton. Fast parallel algorithms for short-range molecular dynamics. J.
Comput. Phys., 117(1):1–19, March 1995.
[99] J. K. Pritchard, M. T. Seielstad, A. Perez-Lezaun, and M. W. Feldman. Popu-
lation growth of human y chromosomes: A study of y chromosome microsatel-
lites. Mol. Biol. Evol., 16(12):1791–1798, December 1999.
[100] A. Rahman. Correlations in the motion of atoms in liquid argon. Phys. Rev.,
136:A405–A411, 1964.
[101] A. Rau, F. Jaﬀrezic, J.-L. Foulley, and R. W. Doerge. Reverse engineering gene
regulatory networks using approximate Bayesian computation. Stat. Comput.,
22(6):1257–1271, November 2012.
[102] F. Rizzi, H. Najm, B. Debusschere, K. Sargsyan, M. Salloum, H. Adal-
steinsson, and O. Knio. Uncertainty quantiﬁcation in MD simulations. part
II: Bayesian inference of force-ﬁeld parameters.
SIAM Multi. Mod. Sim.,
10(4):1460–1492, 2012.
[103] C. P. Robert and G. Casella.
Monte Carlo Statistical Methods Springer.
Springer, New York, 2004.
[104] C. P. Robert, J. M. Cornuet, J. M. Marin, and N. S. Pillai. Lack of conﬁdence
in approximate Bayesian computation model choice. PNAS, 108(37):15112–
15117, 2011.
[105] L. A. Rowley, D. Nicholson, and N. G. Parsonage. Monte Carlo grand canon-
ical ensemble calculation in a gas-liquid transition region for 12-6 argon. J.
Comp. Phys., 17:401–414, 1975.
[106] W. S., A. P., P. C., and K. P.
Bayesian Annealed Sequential Importance
Sampling (BASIS): an unbiased version of Transitional Markov Chain Monte
Carlo. ASCE-ASME Journal of Risk and Uncertainty in Engineering Systems,
Part B: Mechanical Engineering, 2017.

Bibliography
161
[107] K. Scranton, J. Knape, and P. de Valpine. An approximate Bayesian com-
putation approach to parameter estimation in a stochastic stage-structured
population model. Ecology, 95(5):1418–1428, May 2014.
[108] J. R. Shaw, M. Bridges, and M. P. Hobson. Eﬃcient Bayesian inference for
multimodal problems in cosmology. Monthly Notices of the Royal Astronomical
Society, 378(4):1365–1370, 2007.
[109] M. S. Shell. The relative entropy is fundamental to multiscale and inverse
thermodynamic problems. J. Chem. Phys., 129(14):144108, 2008.
[110] L. Shi and T. L. Griﬃths. Neural implementation of hierarchical Bayesian
inference by importance sampling. Advances in neural information processing
systems, pages 1669–1677, 2009.
[111] W. Shinoda, M. Shiga, and M. Mikami. Rapid estimation of elastic constants
by molecular dynamics simulation under constant stress. Phys. Rev. B, 69(13),
April 2004.
[112] M. L. Stein. Statistical Interpolation of Spatial Data: Some Theory for Kriging.
Springer, New York, 1999.
[113] D. Straub and I. Papaioannou. Bayesian updating with structural reliability
methods. J. Eng. Mech.-ASCE, 141(3):04014134, 2015/06/03 2014.
[114] M. A. Suchard and B. D. Redelings. BAli-Phy: simultaneous Bayesian infer-
ence of alignment and phylogeny. Bioinformatics, 22(16):2047–2048, 2006.
[115] M. Sunn˚aker, A. G. Busetto, E. Numminen, J. Corander, M. Foll, and
C. Dessimoz. Approximate Bayesian computation. PLoS computational bi-
ology, 9(1):e1002803, 2013.
[116] S. Suresh, J. Spatz, J. P. Mills, A. Micoulet, M. Dao, C. T. Lim, M. Beil,
and T. Seuﬀerlein. Connections between single-cell biomechanics and human
disease states: gastrointestinal cancer and malaria. Acta Biomater., 1:15–30,
2005.
[117] D. A. Tallmon, G. Luikart, and M. A. Beaumont. Comparative evaluation
of a new eﬀective population size estimator based on approximate Bayesian
computation. Genetics, 167(2):977–988, June 2004.

162
Bibliography
[118] R. Tran-Son-Tay, S. P. Sutera, and P. R. Rao. Determination of red blood cell
membrane viscosity from rheoscopic observations of tank-threading motion.
Biophys. J., 46:65–72, 1984.
[119] B. M. Turner and T. Van Zandt. A tutorial on approximate Bayesian compu-
tation. J. Math. Psychol., 56(2):69–85, April 2012.
[120] M. K. Vakilzadeh, V. Yaghoubi, A. T. Johansson, and T. Abrahamsson. Man-
ifold Metropolis adjusted Langevin algorithm for high-dimensional Bayesian
FE model updating in structural dynamics. In Proceedings of the 9th interna-
tional conference on structural dynamics, EURODYN, 2014.
[121] S. W. Van Sciver. Helium cryogenics, page 63. Springer Science & Business
Media, 2012.
[122] V. Vyshemirsky and M. Girolami. BioBayes: a software package for Bayesian
inference in systems biology. Bioinformatics, 24(17):1933–1934, 2008.
[123] K. Walters. Parameter estimation for an immortal model of colonic stem cell
division using approximate Bayesian computation. J. Theor. Biol., 306:104–
114, August 2012.
[124] D. Wegmann, C. Leuenberger, and L. Excoﬃer.
Eﬃcient approximate
Bayesian computation coupled with Markov chain Monte Carlo without like-
lihood. Genetics, 182(4):1207–1218, 2009.
[125] R. E. Wells Jr and E. W. Merrill.
Inﬂuence of ﬂow properties of blood
upon viscosity-hematocrit relationships.
Journal of Clinical Investigation,
41(8):1591, 1962.
[126] J. A. White. Lennard-jones as a model for argon and test of extended renor-
malization group calculations. J. Chem. Phys., 111:9352–9356, 1999.
[127] R. D. D. Wilkinson.
Approximate Bayesian computation (ABC) gives ex-
act results under the assumption of model error.
Stat. Appl. Genet. Mol.,
12(2):129–141, Jan. 2013.
[128] S. Wu, P. Angelikopoulos, C. Papadimitriou, R. Moser, and P. Koumout-
sakos. A hierarchical Bayesian framework for force ﬁeld selection in molecular
dynamics simulations. Phil. Trans. R. Soc. A, 374:20150032, 2015.

Bibliography
163
[129] S. Wu, P. Angelikopoulos, G. Tauriello, C. Papadimitriou, and P. Koumout-
sakos. Fusing heterogeneous data for the calibration of molecular dynamics
force ﬁelds using hierarchical Bayesian models. J. Chem. Phys., 145:244112,
2016.
[130] H. Zhao and E. S. Shaqfeh. Shear-induced platelet margination in a microchan-
nel. Physical Review E, 83(6):061924, 2011.


Own Publications
1. Kulakova L., Arampatzis G., Angelikopoulos P., Hadjidoukas P. E., Papadim-
itriou C., Koumoutsakos P. Experimental Data over Quantum Mechanics Sim-
ulations for Inferring the Repulsive Exponent of the Lennard-Jones Potential
in Molecular Dynamics. Accepted for publication in Scientiﬁc Reports (2017)
2. Kulakova L., Angelikopoulos P., Hadjidoukas P. E., Papadimitriou C., Koumout-
sakos P. Approximate Bayesian Computation for Granular and Molecular Dy-
namics Simulations. Proceedings of the Platform for Advanced Scientiﬁc Com-
puting Conference PASC’16 (2016)
3. Hadjidoukas P.E., Angelikopoulos P., Kulakova L., Papadimitriou C., Koumout-
sakos P. Exploiting Task-Based Parallelism in Bayesian Uncertainty Quantiﬁ-
cation. Lecture Notes in Computer Science, 9233, 532 (2015)
165


Curriculum Vitae
Name: Lina Kulakova
Citizen of: Nizhny Novgorod, Russia
Born: December 1, 1990, Nizhny Novgorod, USSR
2013-2017: Researcher and teaching assistant at the Computational Science
and Engineering Lab, ETH Zurich, under the supervision of Prof.
Dr. Petros Koumoutsakos
2008-2013 Diploma in Moscow State University, Russia
167

